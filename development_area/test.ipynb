{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 5\n",
      "Sample documents:\n",
      "  0: The art of computer programming algorithms and data structures\n",
      "  1: Learning python programming for beginners\n",
      "  2: Introduction to machine learning and artificial intelligence\n",
      "  3: The great gatsby a novel of American literature\n",
      "  4: Pride and prejudice a classic romance novel\n",
      "Creating term-document matrix...\n",
      "Term-document matrix shape: (5, 22)\n",
      "Sample of term-document matrix (first 3x3):\n",
      "[[0.42066906 0.         0.42066906]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "Performing SVD...\n",
      "U matrix shape: (22, 2)\n",
      "Sigma diagonal values: [1.06768646 1.10646849]\n",
      "Vt matrix shape: (2, 5)\n",
      "Sample of U matrix (first 3x3):\n",
      "[[ 0.00000000e+00  1.80633601e-01]\n",
      " [-3.07094483e-01 -3.88510644e-16]\n",
      " [-8.74856979e-17  1.80633601e-01]]\n",
      "Sample of Vt matrix (first 3x3):\n",
      "[[-2.22044605e-16 -8.83772253e-16 -9.06507549e-16]\n",
      " [ 4.75113115e-01  7.07106781e-01  5.23705574e-01]]\n",
      "Document vectors shape: (5, 2)\n",
      "Sample of document vectors (first 3x3):\n",
      "[[-2.37074019e-16  5.25697691e-01]\n",
      " [-9.43591670e-16  7.82391372e-01]\n",
      " [-9.67865838e-16  5.79463715e-01]]\n",
      "\n",
      "Processing query: 'idf idf'\n",
      "Query vector shape: (1, 22)\n",
      "Non-zero elements in query vector: 0\n",
      "Query vector as array (truncated):\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "U shape: (22, 2)\n",
      "Sigma shape: (2,)\n",
      "Query LSI vector shape: (1, 2)\n",
      "Query LSI vector (truncated):\n",
      "[0. 0.]\n",
      "Similarities shape: (1, 5)\n",
      "All similarities: [0. 0. 0. 0. 0.]\n",
      "Top 5 indices: [4 3 2 1 0]\n",
      "Top 5 similarities: [0. 0. 0. 0. 0.]\n",
      "\n",
      "Query: idf idf\n",
      "\n",
      "Most similar books:\n",
      "Similarity: 0.0000 - Book: Pride and prejudice a classic romance novel\n",
      "Similarity: 0.0000 - Book: The great gatsby a novel of American literature\n",
      "Similarity: 0.0000 - Book: Introduction to machine learning and artificial intelligence\n",
      "Similarity: 0.0000 - Book: Learning python programming for beginners\n",
      "Similarity: 0.0000 - Book: The art of computer programming algorithms and data structures\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "import pandas as pd\n",
    "\n",
    "class LSIModel:\n",
    "    def __init__(self, n_components=100):\n",
    "        \"\"\"\n",
    "        Initialize the LSI model.\n",
    "        n_components: Number of dimensions to keep in the SVD\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                                        max_features=10000)\n",
    "        \n",
    "    def fit(self, documents):\n",
    "        \"\"\"\n",
    "        Fit the LSI model to a collection of documents.\n",
    "        \"\"\"\n",
    "        # Create term-document matrix with TF-IDF weighting\n",
    "        print(\"Creating term-document matrix...\")\n",
    "        X = self.vectorizer.fit_transform(documents)\n",
    "        print(f\"Term-document matrix shape: {X.shape}\")\n",
    "        print(f\"Sample of term-document matrix (first 3x3):\\n{X[:3,:3].toarray()}\")\n",
    "        \n",
    "        # Perform truncated SVD\n",
    "        print(\"Performing SVD...\")\n",
    "        # Note: We transpose X to get the correct orientation\n",
    "        U, Sigma, Vt = svds(X.T, k=self.n_components)\n",
    "        \n",
    "        print(f\"U matrix shape: {U.shape}\")\n",
    "        print(f\"Sigma diagonal values: {Sigma}\")\n",
    "        print(f\"Vt matrix shape: {Vt.shape}\")\n",
    "        \n",
    "        # Visualize a small portion of the matrices\n",
    "        print(f\"Sample of U matrix (first 3x3):\\n{U[:3,:3]}\")\n",
    "        print(f\"Sample of Vt matrix (first 3x3):\\n{Vt[:3,:3]}\")\n",
    "        \n",
    "        # Store the LSI components\n",
    "        self.U = U\n",
    "        self.Sigma = Sigma\n",
    "        self.Vt = Vt\n",
    "        self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Calculate document vectors in reduced space\n",
    "        self.doc_vectors = (Vt.T * Sigma)\n",
    "        print(f\"Document vectors shape: {self.doc_vectors.shape}\")\n",
    "        print(f\"Sample of document vectors (first 3x3):\\n{self.doc_vectors[:3,:3]}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "\n",
    "    def transform_query(self, query):\n",
    "        \"\"\"\n",
    "        Transform a text query into the LSI space.\n",
    "        \"\"\"\n",
    "        # Convert query to TF-IDF vector\n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        \n",
    "        # For debugging, let's print the shapes\n",
    "        print(f\"Query vector shape: {query_vec.shape}\")\n",
    "        print(f\"Non-zero elements in query vector: {query_vec.nnz}\")\n",
    "        print(f\"Query vector as array (truncated):\\n{query_vec.toarray()[0][:10]}\")\n",
    "        print(f\"U shape: {self.U.shape}\")\n",
    "        print(f\"Sigma shape: {self.Sigma.shape}\")\n",
    "        \n",
    "        # Project into LSI space\n",
    "        # Note: U needs to be transposed for correct multiplication\n",
    "        query_lsi = query_vec.toarray() @ self.U @ np.diag(1/self.Sigma)\n",
    "        \n",
    "        print(f\"Query LSI vector shape: {query_lsi.shape}\")\n",
    "        print(f\"Query LSI vector (truncated):\\n{query_lsi[0][:5]}\")\n",
    "        \n",
    "        return query_lsi\n",
    "\n",
    "    \n",
    "    def find_similar_books(self, query, n=5):\n",
    "        \"\"\"\n",
    "        Find the n most similar books to a query.\n",
    "        \n",
    "        query: Text string representing the search query\n",
    "        n: Number of similar books to return\n",
    "        \"\"\"\n",
    "        # Transform query to LSI space\n",
    "        query_lsi = self.transform_query(query)\n",
    "        \n",
    "        # Calculate cosine similarities\n",
    "        similarities = np.dot(query_lsi, self.doc_vectors.T)\n",
    "        print(f\"Similarities shape: {similarities.shape}\")\n",
    "        print(f\"All similarities: {similarities.flatten()}\")\n",
    "        \n",
    "        # Get top n similar documents\n",
    "        top_indices = np.argsort(similarities.flatten())[-n:][::-1]\n",
    "        top_similarities = similarities.flatten()[top_indices]\n",
    "        \n",
    "        print(f\"Top {n} indices: {top_indices}\")\n",
    "        print(f\"Top {n} similarities: {top_similarities}\")\n",
    "        \n",
    "        return top_indices, top_similarities\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample book data (in practice, this would be your actual book dataset)\n",
    "    books = [\n",
    "        \"The art of computer programming algorithms and data structures\",\n",
    "        \"Learning python programming for beginners\",\n",
    "        \"Introduction to machine learning and artificial intelligence\",\n",
    "        \"The great gatsby a novel of American literature\",\n",
    "        \"Pride and prejudice a classic romance novel\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Number of documents: {len(books)}\")\n",
    "    print(\"Sample documents:\")\n",
    "    for i, book in enumerate(books):\n",
    "        print(f\"  {i}: {book}\")\n",
    "    \n",
    "    # Create and fit the LSI model\n",
    "    lsi = LSIModel(n_components=2)\n",
    "    lsi.fit(books)\n",
    "    \n",
    "    # Example query\n",
    "    query = \"idf idf\"\n",
    "    print(f\"\\nProcessing query: '{query}'\")\n",
    "    indices, similarities = lsi.find_similar_books(query)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\\nMost similar books:\")\n",
    "    for idx, sim in zip(indices, similarities):\n",
    "        print(f\"Similarity: {sim:.4f} - Book: {books[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI Academic Search Engine\n",
    "\n",
    "A modular academic paper search engine using Latent Semantic Indexing (LSI) with multiple relevance-boosting enhancements. This system efficiently processes large academic paper datasets (up to 160GB) on standard hardware.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Field-Weighted LSI**: Enhanced document representation with field-specific weights\n",
    "- **Keyword Extraction**: Automatic keyword identification using BERT-based models\n",
    "- **Temporal Relevance**: Configurable recency preference for search results\n",
    "- **Metadata Filtering**: Support for field-specific queries (author, year, journal)\n",
    "- **Query Expansion**: Automatic enhancement of queries with relevant terms\n",
    "- **Memory Efficiency**: Designed to handle large datasets on consumer hardware\n",
    "- **GPU Acceleration**: Optimized for systems with GPU support\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "![System Architecture](https://i.imgur.com/PlwWtqI.png)\n",
    "\n",
    "### 1. Document Processor\n",
    "\n",
    "The Document Processor handles the extraction and normalization of academic papers from JSON format.\n",
    "\n",
    "**Key Features:**\n",
    "- JSON document parsing with robust error handling\n",
    "- Text normalization and tokenization\n",
    "- Field extraction (title, abstract, full text)\n",
    "- Efficient batch processing for large datasets\n",
    "- Memory-efficient streaming interface\n",
    "\n",
    "**Code Example:**\n",
    "```python\n",
    "processor = DocumentProcessor(data_dir=\"./data\", batch_size=1000)\n",
    "for batch in processor.batch_document_generator():\n",
    "    # Process each batch\n",
    "    print(f\"Processing batch of {len(batch)} documents\")\n",
    "```\n",
    "\n",
    "### 2. Indexing Engine\n",
    "\n",
    "The Indexing Engine creates the LSI representation of documents using field-weighted TF-IDF matrices and dimensionality reduction.\n",
    "\n",
    "**Key Features:**\n",
    "- Field-weighted TF-IDF matrices (title: 3.0×, abstract: 1.5×, body: 1.0×)\n",
    "- Truncated SVD for dimensionality reduction (150 dimensions)\n",
    "- Memory-mapped vector storage using HDF5\n",
    "- Incremental indexing capability\n",
    "- Efficient sparse matrix operations\n",
    "\n",
    "**Code Example:**\n",
    "```python\n",
    "engine = IndexingEngine(\n",
    "    index_dir=\"./index\",\n",
    "    n_components=150,\n",
    "    field_weights={'title': 3.0, 'abstract': 1.5, 'full_text': 1.0}\n",
    ")\n",
    "doc_vectors, term_vectors = engine.fit_transform(documents)\n",
    "```\n",
    "\n",
    "### 3. Enhancement Modules\n",
    "\n",
    "#### 3.1 KeyBERT Keyword Extraction\n",
    "\n",
    "Extracts key phrases from documents using BERT-based semantic representations.\n",
    "\n",
    "**Key Features:**\n",
    "- Uses lightweight BERT models optimized for keyword extraction\n",
    "- Extracts multi-word phrases (1-3 words)\n",
    "- Configurable number of keywords per document\n",
    "- GPU-accelerated with memory optimization\n",
    "- Provides relevance boosting based on keyword matching\n",
    "\n",
    "**Code Example:**\n",
    "```python\n",
    "extractor = KeywordExtractor(\n",
    "    index_dir=\"./index\",\n",
    "    model_name=\"all-MiniLM-L6-v2\",  # Small but effective model\n",
    "    top_n=5\n",
    ")\n",
    "keywords = extractor.extract_keywords(documents)\n",
    "```\n",
    "\n",
    "#### 3.2 Temporal Relevance Adjuster\n",
    "\n",
    "Adjusts document relevance based on publication year with configurable recency preference.\n",
    "\n",
    "**Key Features:**\n",
    "- User-controllable recency preference (0.0 to 1.0)\n",
    "- Normalized age-based boosting\n",
    "- Pre-computed year indexing\n",
    "- Configurable maximum age factor\n",
    "- Year range filtering support\n",
    "\n",
    "**Code Example:**\n",
    "```python\n",
    "adjuster = TemporalRelevanceAdjuster(\n",
    "    index_dir=\"./index\",\n",
    "    default_recency_preference=0.3\n",
    ")\n",
    "results = adjuster.apply_temporal_boost(results, recency_preference=0.5)\n",
    "```\n",
    "\n",
    "### 4. Query Processor\n",
    "\n",
    "The Query Processor handles search requests, combining LSI similarity with enhancement factors.\n",
    "\n",
    "**Key Features:**\n",
    "- Query normalization and field filter extraction\n",
    "- Projection of queries into LSI space\n",
    "- Cosine similarity calculation\n",
    "- Integration of enhancement factors\n",
    "- Field-specific filtering (year, author, journal)\n",
    "- Query expansion capability\n",
    "\n",
    "**Code Example:**\n",
    "```python\n",
    "processor = QueryProcessor(\n",
    "    indexing_engine=indexing_engine,\n",
    "    keyword_extractor=keyword_extractor,\n",
    "    temporal_adjuster=temporal_adjuster\n",
    ")\n",
    "results = processor.search(\n",
    "    query=\"neural networks author:\\\"Smith\\\" year:\\\"2015-2022\\\"\",\n",
    "    recency_preference=0.3,\n",
    "    use_query_expansion=True\n",
    ")\n",
    "```\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "# Clone repository\n",
    "git clone https://github.com/username/lsi-academic-search.git\n",
    "cd lsi-academic-search\n",
    "\n",
    "# Create virtual environment\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n",
    "\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Requirements\n",
    "\n",
    "```\n",
    "numpy>=1.20.0\n",
    "scipy>=1.6.0\n",
    "scikit-learn>=0.24.0\n",
    "h5py>=3.1.0\n",
    "keybert>=0.5.0\n",
    "sentence-transformers>=2.0.0\n",
    "torch>=1.8.0\n",
    "tqdm>=4.60.0\n",
    "joblib>=1.0.0\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Creating Sample Data (for testing)\n",
    "\n",
    "```bash\n",
    "python main_demo.py --create_samples --num_samples 100\n",
    "```\n",
    "\n",
    "### Building the Index\n",
    "\n",
    "```bash\n",
    "python main_demo.py --data_dir ./data --index_dir ./index --build_index\n",
    "```\n",
    "\n",
    "### Running Searches\n",
    "\n",
    "```bash\n",
    "# Basic search\n",
    "python main_demo.py --query \"machine learning neural networks\"\n",
    "\n",
    "# With adjusted recency preference (0.0-1.0)\n",
    "python main_demo.py --query \"information retrieval\" --recency 0.7\n",
    "\n",
    "# With field filters\n",
    "python main_demo.py --query \"machine learning year:\\\"2018-2023\\\" author:\\\"Smith\\\"\"\n",
    "```\n",
    "\n",
    "## Configuration Options\n",
    "\n",
    "The search engine can be configured through several parameters:\n",
    "\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|---------|\n",
    "| `lsi_components` | Number of LSI dimensions | 150 |\n",
    "| `field_weights` | Weights for document fields | `{'title': 3.0, 'abstract': 1.5, 'full_text': 1.0}` |\n",
    "| `batch_size` | Documents per processing batch | 1000 |\n",
    "| `keybert_model` | Model for keyword extraction | \"all-MiniLM-L6-v2\" |\n",
    "| `recency_preference` | Default temporal boosting strength | 0.3 |\n",
    "| `max_results` | Maximum results returned | 100 |\n",
    "\n",
    "## Performance Considerations\n",
    "\n",
    "- **Memory Usage**: The system is designed to work with 16GB RAM by processing documents in batches\n",
    "- **Disk Space**: Index storage requires approximately 10-15% of the original dataset size\n",
    "- **GPU Acceleration**: KeyBERT extraction is significantly faster with GPU support\n",
    "- **Scalability**: Can handle datasets up to 160GB with appropriate batch sizing\n",
    "\n",
    "## Future Extensions\n",
    "\n",
    "- **Citation Network Analysis**: Integrate citation relationships for relevance boosting\n",
    "- **User Feedback Integration**: Incorporate click data to improve ranking\n",
    "- **Multilingual Support**: Add cross-language search capabilities\n",
    "- **Faceted Search Interface**: Develop a web UI with interactive filters\n",
    "- **Incremental Updates**: Support for adding new papers without full reindexing\n",
    "\n",
    "## License\n",
    "\n",
    "MIT\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "This project incorporates ideas from several academic papers:\n",
    "- Deerwester et al. (1990) \"Indexing by Latent Semantic Analysis\"\n",
    "- Grootendorst (2020) \"KeyBERT: Minimal keyword extraction with BERT\"\n",
    "\n",
    "\n",
    "# Academic Papers for LSI Search Engine Project\n",
    "\n",
    "\n",
    "\n",
    "## Markdown Table Format\n",
    "\n",
    "| Paper Title | Authors | Overview | Relevance to LSI Search Engine Project |\n",
    "|-------------|---------|----------|---------------------------------------|\n",
    "| Indexing by Latent Semantic Analysis | Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer, Richard Harshman | This seminal paper introduces Latent Semantic Indexing (LSI) as a technique to overcome the limitations of keyword matching in information retrieval. The authors describe how singular value decomposition (SVD) can be used to uncover latent semantic structure in term-document matrices, addressing problems of synonymy and polysemy in text retrieval. | This paper provides the theoretical foundation for the entire LSI academic search engine project. The core indexing engine described in the project directly implements the SVD-based dimensionality reduction (using 150 dimensions) on the term-document matrices, as outlined in this paper. The field-weighted approach in the project extends the basic LSI model. |\n",
    "| An Introduction to Latent Semantic Analysis | Thomas K. Landauer, Peter W. Foltz, Darrell Laham | This paper explains the theoretical foundations and practical applications of LSA in a more accessible manner. It covers how LSA extracts and represents the contextual-usage meaning of words through statistical computations on large text corpora. | The paper's explanation of how LSA represents both terms and documents in the same semantic space directly informs the query processing module of the search engine. The project's implementation of cosine similarity for matching queries to documents is based on principles described here. |\n",
    "| Using Latent Semantic Analysis to Improve Access to Textual Information | Susan T. Dumais, George W. Furnas, Thomas K. Landauer, Scott Deerwester | This paper demonstrates practical applications of LSI in information retrieval systems. It shows how LSI can overcome vocabulary mismatch problems between queries and documents, producing more accurate and comprehensive search results. | The system architecture of the LSI academic search engine, particularly the document processor and indexing engine components, draws heavily from the practical implementation guidance in this paper. The project's TF-IDF matrices preprocessing step before applying SVD follows the approach described here. |\n",
    "| Using Linear Algebra for Intelligent Information Retrieval | Michael W. Berry, Susan T. Dumais, Gavin W. O'Brien | This paper provides a comprehensive mathematical treatment of LSI, focusing on the linear algebra aspects. It details SVD implementation, updating procedures for existing LSI databases, and applications of LSI in various contexts. | The paper's discussion of SVD updating techniques directly informs the incremental indexing capability of the project's indexing engine. The memory-efficient storage using HDF5 addresses some of the computational challenges described in this paper. |\n",
    "| Self-supervised Contextual Keyword and Keyphrase Retrieval with Self-Labelling | Prafull Sharma, Yingbo Li | This paper presents a novel approach for keyword and keyphrase extraction using BERT-based models and contextual features. It introduces a self-supervised method that doesn't require manual labeling of training data. | This paper directly relates to the KeyBERT keyword extraction enhancement module in the search engine. The project implements BERT-based semantic representations for extracting key phrases from documents, which follows the approach outlined in this paper. |\n",
    "| Document Length Normalization | Amit Singhal, Gerard Salton, Mandar Mitra, Chris Buckley | This paper addresses the issue of document length bias in retrieval systems. It introduces pivoted cosine normalization to account for the observation that longer documents tend to have a higher probability of relevance in certain collections. | The field-weighted TF-IDF matrices in the project's indexing engine (with title weighted 3.0×, abstract 1.5×, full text 1.0×) implement a form of document length normalization that aligns with the principles discussed in this paper. |\n",
    "| Information Retrieval and the Semantic Web | D.B. Mirajkar, D.G. Chougule, K.K. Awale, S.B. Sagare | This paper discusses the intersection of information retrieval and semantic web technologies. It explores how traditional IR systems can be adapted to handle semantic web documents and annotations. | While the LSI search engine project doesn't explicitly incorporate semantic web technologies, the paper's discussion of enhancing retrieval with semantic information relates to the project's enhancement modules. |\n",
    "\n",
    "Both formats can be easily copied and pasted into your preferred editing tool. The XML format can be imported into MS Word, and the markdown table can be copied directly into most text editors or word processors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

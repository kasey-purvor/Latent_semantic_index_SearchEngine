{"doi":"10.1136\/bmj.d5886","coreId":"177342","oai":"oai:aura.abdn.ac.uk:2164\/2145","identifiers":["oai:aura.abdn.ac.uk:2164\/2145","10.1136\/bmj.d5886"],"title":"Impact of CONSORT extension for cluster randomised trials on quality of reporting and study methodology : review of random sample of 300 trials, 2000-8","authors":["Ivers, N M","Taljaard, M","Dixon, S","Bennett, C","McRae, A","Taleban, J","Skea, Z","Brehaut, J C","Boruch, R F","Eccles, M P","Grimshaw, J M","Weijer, C","Zwarenstein, M","Donner, A"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":["University of Aberdeen, Medicine, Medical Sciences & Nutrition, Institute of Applied Health Sciences"],"datePublished":"2011-09-26","abstract":"Peer reviewedPublisher PD","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:aura.abdn.ac.uk:2164\/2145<\/identifier><datestamp>\n                2018-01-02T00:05:21Z<\/datestamp><setSpec>\n                com_2164_632<\/setSpec><setSpec>\n                com_2164_364<\/setSpec><setSpec>\n                com_2164_330<\/setSpec><setSpec>\n                com_2164_705<\/setSpec><setSpec>\n                col_2164_633<\/setSpec><setSpec>\n                col_2164_706<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nImpact of CONSORT extension for cluster randomised trials on quality of reporting and study methodology : review of random sample of 300 trials, 2000-8<\/dc:title><dc:creator>\nIvers, N M<\/dc:creator><dc:creator>\nTaljaard, M<\/dc:creator><dc:creator>\nDixon, S<\/dc:creator><dc:creator>\nBennett, C<\/dc:creator><dc:creator>\nMcRae, A<\/dc:creator><dc:creator>\nTaleban, J<\/dc:creator><dc:creator>\nSkea, Z<\/dc:creator><dc:creator>\nBrehaut, J C<\/dc:creator><dc:creator>\nBoruch, R F<\/dc:creator><dc:creator>\nEccles, M P<\/dc:creator><dc:creator>\nGrimshaw, J M<\/dc:creator><dc:creator>\nWeijer, C<\/dc:creator><dc:creator>\nZwarenstein, M<\/dc:creator><dc:creator>\nDonner, A<\/dc:creator><dc:contributor>\nUniversity of Aberdeen, Medicine, Medical Sciences & Nutrition, Institute of Applied Health Sciences<\/dc:contributor><dc:subject>\nR Medicine<\/dc:subject><dc:subject>\nR<\/dc:subject><dc:description>\nPeer reviewed<\/dc:description><dc:description>\nPublisher PDF<\/dc:description><dc:date>\n2011-10-14T09:18:03Z<\/dc:date><dc:date>\n2011-10-14T09:18:03Z<\/dc:date><dc:date>\n2011-09-26<\/dc:date><dc:type>\nJournal article<\/dc:type><dc:identifier>\nIvers , N M , Taljaard , M , Dixon , S , Bennett , C , McRae , A , Taleban , J , Skea , Z , Brehaut , J C , Boruch , R F , Eccles , M P , Grimshaw , J M , Weijer , C , Zwarenstein , M & Donner , A 2011 , ' Impact of CONSORT extension for cluster randomised trials on quality of reporting and study methodology : review of random sample of 300 trials, 2000-8 ' British Medical Journal , vol 343 , no. - , d5886 . DOI: 10.1136\/bmj.d5886<\/dc:identifier><dc:identifier>\n0959-8146<\/dc:identifier><dc:identifier>\nPURE: 6248424<\/dc:identifier><dc:identifier>\nPURE UUID: c5573b2c-7cb0-48c8-a5e8-db69752346bd<\/dc:identifier><dc:identifier>\nScopus: 84857380136<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2164\/2145<\/dc:identifier><dc:identifier>\nhttp:\/\/dx.doi.org\/ 10.1136\/bmj.d5886<\/dc:identifier><dc:language>\neng<\/dc:language><dc:relation>\nBritish Medical Journal<\/dc:relation><dc:rights>\n\u00a9 2011 BMJ Publishing Group Ltd<\/dc:rights><dc:format>\n14<\/dc:format>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["0959-8146","issn:0959-8146"]}],"language":{"code":"en","id":9,"name":"English"},"relations":["British Medical Journal"],"year":2011,"topics":["R Medicine","R"],"subject":["Journal article"],"fullText":"Impact of CONSORT extension for cluster randomised\ntrials on quality of reporting and study methodology:\nreview of random sample of 300 trials, 2000-8\nOPEN ACCESS\nNM Ivers family physician 1, M Taljaard scientist 2, S Dixon postdoctoral fellow 3, C Bennett research\ncoordinator 2, A McRae research director 4, J Taleban PhD candidate 5, Z Skea research fellow 6, J\nC Brehaut scientist 2, R F Boruch professor of education and statistics 7, M P Eccles professor of\nclinical effectiveness 8, J M Grimshaw senior scientist 2, C Weijer professor of philosophy and\nmedicine 9, M Zwarenstein senior scientist 10, A Donner professor of epidemiology and biostatistics 11\n1Women\u2019s College Hospital, 76 Grenville Street, Toronto, ON, Canada M5S 1B2; 2Ottawa Hospital Research Institute, Clinical Epidemiology Program,\nOttawa Hospital, Civic Campus, 1053 Carling Avenue, Ottawa, ON; 3Department of Epidemiology and Biostatistics, Schulich School of Medicine\nand Density, University of Western Ontario, London, ON; 4Division of Emergency Medicine, University of Calgary, Foothills Medical Centre, 1403-29\nStreet NW, Calgary, AB; 5Department of Epidemiology and Biostatistics, University of Western Ontario, London, ON; 6Health Services Research\nUnit, Health Sciences Building, University of Aberdeen, Foresterhill, Aberdeen AB25 2ZD, UK; 7Graduate School of Education, University of\nPennsylvania, 3700 Walnut Street, Philadelphia, PA 19104, USA; 8Institute of Health and Society, Newcastle University, Baddiley-Clark Building,\nNewcastle upon Tyne; 9Rotman Institute of Philosophy, Department of Philosophy, University of Western Ontario, London, ON; 10Institute for Clinical\nEvaluative Sciences and Sunnybrook Research Institute, G106 - 2075 Bayview Avenue, Toronto, ON; 11Schulich School of Medicine and Dentistry,\nKresge Building, University of Western Ontario, London, ON\nAbstract\nObjective To assess the impact of the 2004 extension of the CONSORT\nguidelines on the reporting and methodological quality of cluster\nrandomised trials.\nDesign Methodological review of 300 randomly sampled cluster\nrandomised trials. Two reviewers independently abstracted 14 criteria\nrelated to quality of reporting and four methodological criteria specific\nto cluster randomised trials. We compared manuscripts published before\nCONSORT (2000-4) with those published after CONSORT (2005-8).\nWe also investigated differences by journal impact factor, type of journal,\nand trial setting.\nData sources A validated Medline search strategy.\nEligibility criteria for selecting studies Cluster randomised trials\npublished in English language journals, 2000-8.\nResults There were significant improvements in five of 14 reporting\ncriteria: identification as cluster randomised; justification for cluster\nrandomisation; reporting whether outcome assessments were blind;\nreporting the number of clusters randomised; and reporting the number\nof clusters lost to follow-up. No significant improvements were found in\nadherence to methodological criteria. Trials conducted in clinical rather\nthan non-clinical settings and studies published in medical journals with\nhigher impact factor or general medical journals were more likely to\nadhere to recommended reporting and methodological criteria overall,\nbut there was no evidence that improvements after publication of the\nCONSORT extension for cluster trials were more likely in trials conducted\nin clinical settings nor in trials published in either general medical journals\nor in higher impact factor journals.\nConclusion The quality of reporting of cluster randomised trials improved\nin only a few aspects since the publication of the extension of CONSORT\nfor cluster randomised trials, and no improvements at all were observed\nin essential methodological features. Overall, the adherence to reporting\nand methodological guidelines for cluster randomised trials remains\nsuboptimal, and further efforts are needed to improve both reporting and\nmethodology.\nIntroduction\nIn recent years, increasing attention has been paid to the\nimportance of good reporting practices as they relate to the\npotential utility of a manuscript.1 The CONSORT (consolidated\nstandards of reporting trials) statement, originally published in\n1996 and updated in 2001 and 2010, provides authors and editors\nwith a checklist for a minimum set of recommendations for\nCorrespondence to: N M Ivers noah.ivers@utoronto.ca\nExtra material as supplied by authors (see http:\/\/www.bmj.com\/content\/343\/bmj.d5886\/suppl\/DC1)\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 1 of 14\nResearch\nRESEARCH\nreporting the trial design, analysis, and results.2Although certain\ninadequacies remain common, the quality of reporting of\nrandomised controlled trials in medical journals seems to be\nimproving over time.3A recent systematic review indicated that\nthe CONSORT statement has played an important role in this\nprogression.4\nUnfortunately, reviews of published cluster randomised trials\n(see box 1) have repeatedly found important shortcomings in\ntheir methodological conduct and reporting.5-18 For example, a\nreview of 152 cluster randomised trials published 1997-2000\nfound that most of them did not adhere to recommendedmethods\nfor cluster randomised trials.8 To help address this problem, an\nextension for the original CONSORT guideline, specifically\naddressing the unique methodological features of cluster\nrandomised trials, was published in 2004.19 In this extension,\nthe authors altered the recommendations for 15 of 22 items on\nthe original CONSORT checklist to emphasise the additional\nrequirements for adequatemethodological conduct and reporting\nof cluster randomised trials. Encouragingly, a review of 34\nprimary care trials published in seven major medical journals\nduring the two years after the extension found that most trials\nproperly accounted for clustering in the sample size and in the\nanalysis.7 Nevertheless, that review still found that cluster\nrandomised trials often had suboptimal reporting to the extent\nthat both internal and external validity were uncertain.7 For\nexample, blinding of participants was not reported clearly in\n33% and blinding of outcome assessors was not reported clearly\nin 38%. Such factors are included in the CONSORT checklist\nfor a good reason: lack of blinding can lead to substantially\ninflated estimates of effect,20 21 making clear reporting essential\nfor interpretation. Although blinding of participants is often\nimpossible in cluster randomised trials, especially in those\nevaluating interventions to change behaviour, we believe that\ninability to blind trial participants should not be invoked as an\nexcuse for poor reporting.\nGiven that cluster trials are increasingly common but carry\nunique risks for bias, adequate reporting is evenmore important.\nThe CONSORT extension for cluster randomised trials might\nhave had a positive impact on reporting; our group has recently\nshown that more reports of cluster randomised trials now\nmention the clustered nature of the trial in the title or abstract,\nor both.22 We performed a secondary analysis of data originally\nabstracted to investigate the unique ethical issues that arise as\na result of randomising groups rather than individuals.23 Using\ndata from a random sample of published cluster randomised\ntrials from 2000-8, we examined trends in the reporting quality\nof these trials. In addition to investigating whether there was\nan improvement in reporting of certain items recommended by\nthe CONSORT extension, we assessed whether there were\nimprovements in essential methodological requirements for\ncluster randomised trials. To do so, we made a distinction\nbetween reporting in the manuscript (such as presence of a\nsample size calculation) and proper methodological conduct\n(such as accounting for the intracluster correlation in that\ncalculation). Finally, we examined whether trends in trial\nreporting and methods varied according to characteristics of the\nstudy or journal.\nMethods\nSearch strategy and article selection\nWe used a previously published electronic search strategy (box\n2) to identify reports of cluster randomised trials in health\nresearch, published in English language journals from 2000 to\n2008.22 As described in more detail elsewhere,22 23 the search\nstrategy was derived and validated with an ideal set of cluster\nrandomised trials identified frommanual examination of a large\nsample of health journals, as well as an independent sample of\ncluster randomised trials included in previously published\nreviews. The sensitivity of the search strategy against the ideal\nset of trials, defined as the proportion of cluster randomised\ntrials that are retrieved by the search, was 90.1%.\nReports identified by the search strategy were sorted in random\norder with a computer generated random number, and two\nreviewers (MT and CB) screened titles and abstracts of reports\n(as well as full text when necessary) to identify cluster\nrandomised trials that met our eligibility criteria. Both reviewers\ninitially screened reports to assess agreement in the identification\nof eligible trials. After reaching satisfactory agreement (defined\nas \u03ba\u22650.85), reports were screened independently until the target\nsample size of 300 trials was reached (fig 1)\u21d3. An article was\nincluded if it was clearly the main report of a cluster randomised\ntrial. We excluded studies identified by the trial authors as\n\u201cpilot\u201d or \u201cfeasibility\u201d studies, trial protocols, trials randomising\nhouseholds or dyads of different individuals, short\ncommunications or conference proceedings, trials with further\nallocation of individuals within clusters, those using\nquasi-randomised designs, and studies that reported only\nbaseline findings or secondary analyses of trials. We considered\na study as a \u201csecondary analysis\u201d if it was identified as such by\nthe study authors, referenced the main publication elsewhere,\nor presented only secondary outcomes.\nData abstraction\nThe research team developed and pilot tested the data abstraction\ninstrument used for the larger project examining ethical issues\nin cluster randomised trials. This was then applied to a sample\nof 21 cluster randomised trials to calibrate reviewers. Six\nreviewers (MT, AMcR, CB, SD, JT, ZS) independently\nabstracted these 21 trials. Differences were identified and\nresolved by discussion. The rest of the trials were then abstracted\nindependently by rotating pairs of reviewers. After each set of\n20 trials had been abstracted, discrepancies were reviewedwithin\nthe pair and resolved by consensus. If differences could not be\nresolved, one reviewer (MT) was the arbitrator.\nOutcomes\nSimilar to the approach taken in a previous review,8 we\nconsidered criteria relating to both reporting andmethodological\nquality of the trials. Reporting quality was assessed on the basis\nof the presence or absence of a subset of criteria in the\nCONSORT extension to cluster randomised trials;\nmethodological quality was assessed on the basis of four\nmethodological requirements specific to the conduct of such\ntrials. These are related to the criteria described in the\nCONSORT extension checklist, but they have been abstracted\nto assess appropriateness of trial conduct rather than simply\ntrial reporting. Table 1\u21d3 compares the criteria in the CONSORT\nchecklist and the variables assessed as outcomes in the present\nstudy.\nReporting criteria\nAlthough there are 22 items listed in the CONSORT reporting\nchecklist for cluster randomised trials, some are difficult to\nabstract in a standardised fashion and others can be broken down\ninto multiple variables. As part of the larger project investigating\nethical issues in cluster randomised trials, we abstracted 14\nCONSORT related reporting variables. The choice not to\nabstract all CONSORT criteria represented a compromise\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 2 of 14\nRESEARCH\nBox 1 Brief description of cluster randomised trials\n\u2022 Cluster randomised trials differ from classic (individual level) randomised controlled trials in that the unit of randomisation\nincludes a group (or cluster) of patients\u2014such as a medical practice, hospital, or entire community\u2014rather than an\nindividual patient\n\u2022 Cluster randomised trials are often done for pragmatic purposes (such as in public health trials where the intervention\nis directed at the whole community) or to avoid contamination of the treatment arm (such as in health services trials\nwhere patients in the intervention group share a healthcare provider)\n\u2022 Individuals nested within a cluster might bemore similar than individuals from other clusters; this \u201cintracluster correlation\u201d\nmust be accounted for in the design and analysis\n\u2022 Failing to account for the intracluster correlation in the calculation of the sample size can lead to an underpowered\ntrial, and failing to account for it during the analysis can lead to spuriously significant results\n\u2022 Numerous other challenges separate cluster randomised trials from individual level trials (for example, loss to follow-up\nof clusters can substantially reduce power compared with loss of individuals)\nBox 2: Medline search strategy to identify cluster randomised trials\n1. randomized controlled trial.pt.\n2. animals\/\n3. humans\/\n4. 2 NOT (2 AND 3)\n5. 1 NOT 4\n6. cluster$ adj2 randomi$.tw.\n7. ((communit$ adj2 intervention$) OR (communit$ adj2 randomi$)).tw.\n8. group$ randomi$.tw.\n9. 6 OR 7 OR 8\n10. intervention?.tw.\n11. cluster analysis\/\n12. health promotion\/\n13. program evaluation\/\n14. health education\/\n15. 10 OR 11 OR 12 OR 13 OR 14\n16. 9 OR 15\n17. 16 AND 5\nbetween comprehensiveness and feasibility, given the large\nsample size involved. For every trial report, we classed each of\nthe following criteria as \u201creported\u201d or \u201cnot reported\u201d:\n\u2022 Clear identification of cluster randomised in the title or\nabstract of the report\n\u2022 Explicit provision of a rationale or justification for using\na clustered design (such as avoidance of contamination)\n\u2022 Reporting of clearly defined primary outcome measures\n\u2022 Presentation of calculation of sample size\n\u2022 Identification of who enrolled participants in the trial\n(excluding trials with no enrolment of participants\u2014for\nexample, trials using data from secondary sources only)\n\u2022 Reporting of the blinding of participants\n\u2022 Reporting of the blinding of administrators or outcome\nassessors, or both\n\u2022 Presentation of a clearly defined approach to analysis\n\u2022 Reporting of the number of clusters randomised to each\narm\n\u2022 Reporting of the number of clusters that withdrew\n\u2022 Reporting of the number of clusters that were lost to\nfollow-up\n\u2022 Reporting of the size of clusters in each arm\n\u2022 Reporting of the number of individuals lost to follow-up\n\u2022 Reporting of an estimated intracluster correlation\n(excluding trials using a pair matched design or those where\nthe analysis was at the cluster level).\nMethodological criteria\nWe abstracted four criteria related to the appropriate conduct\nof a cluster randomised trial:\n\u2022 Whether or not the sample size calculation (if reported)\naccounted for clustering.24A trial was classified as meeting\nthe sample size requirement if the sample size calculation\nwas presented and clearly accounted for clustering (such\nas by using the intracluster correlation, coefficient of\nvariation, or cluster level summary statistics).\n\u2022 Whether or not the analysis accounted for clustering.24 A\ntrial was classified as meeting the analysis requirement if\nthe method of analysis was reported and was clearly\nappropriate for the clustered design (such as by adjusting\nfor the intracluster correlation, using a mixed effects\nregression analysis, or using cluster level summary\nstatistics).\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 3 of 14\nRESEARCH\n\u2022 Whether any attempt was made beyond simple\n(unrestricted) randomisation to attain balance at\nbaseline\u2014cluster randomised trials have a greater risk of\nchance imbalances at baseline compared with trials\nrandomising individual patients because of the limited\nnumber of clusters that can feasibly be randomised in any\none trial. Restricted randomisation (using stratification,\npair matching, or minimisation) to limit the chance of\nbaseline imbalances is therefore recommended.19\n\u2022 As in a previous review,8we abstracted whether the number\nof clusters randomised per arm was greater than four as\ntrials randomising fewer than four clusters per arm might\nbe severely limited in their statistical power.25 Unlike each\nof the variables above, this criterion was not explicitly\nrecommended in the CONSORT extension for cluster trials.\nStudy and journal characteristics\nWe assessed the study setting as well as the type of journal and\nits impact factor for each manuscript. To distinguish between\ntrials conducted in clinical settings or non-clinical settings we\nassessed the unit of allocation. We classified the study setting\nas \u201cclinical\u201d when the unit of allocation was a healthcare\nprovider, teams of healthcare providers, or healthcare\norganisations (such as a primary care practice or group of\npractices, hospital or hospital wards, nursing home) or if the\ntrial was conducted in a healthcare organisation; the remainder\nof the trials (such as those randomising schools or classrooms;\nresidential areas; worksites; and sports teams, clubs, churches,\nor other social groups) were classified as \u201cnon-clinical.\u201d We\nobtained journal impact factors from journal citation reports\n(ISI Web of Science, 2009). When a journal\u2019s ranking was\nunavailable, we used the impact ranking of the open access\nSMImago journal and country rank database, if available.26 This\nranking is calculated with a similar formula and is strongly\ncorrelated with the journal citation impact factor.27 We used\njournal citation reports from ISI Web of Knowledge to identify\ngeneral medical journals according to those classified as\n\u201cmedicine, general and internal.\u201d\nAnalysis\nResults were summarised with frequencies and percentages for\ncategorical variables and medians and interquartile ranges for\ncontinuous or ordinal variables. For our primary objective of\ndeterminingwhether there has been an improvement in reporting\nand methodological quality over time, we compared the\nproportions of manuscripts meeting the recommended criteria\npublished before CONSORT (2000-4) with those published\nafter CONSORT (2005-6 and 2007-8) using Cochran-Armitage\ntests for trend. As seen in figure 2\u21d3, the number of citations of\nthe extension increased linearly over this timeframe, and we\ntherefore chose two cut-off points to account for the expected\ngradual dissemination of the guidelines over time. To quantify\nthe magnitude of change in adherence over time, we calculated\nthe absolute change in the proportion of trials meeting each\nrecommendation from before to after CONSORT, together with\n95% asymptotic confidence intervals (or exact confidence\nintervals in the case of small expected frequencies). We also\ncreated a summary score for the 14 reporting criteria,\nrepresenting the proportion of items adhered to in the report.\nDifferences in the summary score over time were analysed with\none way analysis of variation (ANOVA) with publication year\nas a three level categorical variable. For our secondary objective\n(to investigate variations in adherence to reporting and\nmethodological criteria according to study or journal\ncharacteristics) we repeated the above analyses after classifying\ntrial setting as clinical versus non-clinical and after classifying\njournals as higher (above the median) versus lower impact\nfactors and as general medical journals versus other. All analyses\nwere carried out with SAS v.9.2 with a level of significance set\nat \u03b1=0.05.\nResults\nTable 2 shows characteristics of the 300 randomly selected trials\nincluded in the review\u21d3. Trials were published in 150 different\njournals; 103 (34%) were published in general medical journals.\nJournal impact factors ranged from 0.45 to 50; the median\nimpact factor was 2.9. The median impact factor of the general\nmedical journals was 9.2.\nTable 3\u21d3 shows the percentage of trials that met each of the\nreporting criteria before and after CONSORT, together with the\ntests for trend and confidence intervals for absolute change in\nadherence. Five of the 14 reporting criteria showed a significant\ntrend for improvement: reporting on loss of clusters to follow-up\n(P=0.01); identification as \u201ccluster randomised\u201d in title or\nabstract (P=0.038); providing a justification for the clustered\ndesign (P=0.038); reporting whether or not outcome assessors\nhad been blinded (P=0.019); and reporting of the number of\nclusters randomised (P=0.035). Among these criteria, the\nabsolute improvement in adherence ranged from 6.6% (95%\nconfidence interval \u22121.1% to 14.3%) for reporting of number\nof clusters randomised to 13.9% (3.1% to 24.7%) for reporting\nwhether outcome assessors were blinded. Notably, there was\nno improvement in the proportion of trials clearly identifying\na primary outcome, with fewer than half of trials overall meeting\nthis important criterion; moreover, about half of trials overall\nfailed to report a sample size calculation and this does not seem\nto have improved over time. Based on the summary score, there\nwas minimal improvement in overall reporting, with papers\nfrom 2000-4 reporting a mean of 60% of criteria, those from\n2005-6 reporting 62%, and those from 2007-8 reporting 66%\n(P=0.09 for trend).\nWe found no trend over time in the methodological criteria that\nwe chose to abstract. Overall, 56% of trials used restricted\nrandomisation, 70% accounted for clustering in analysis, 60%\nof those presenting sample size calculations accounted for\nclustering in the design, and 86% allocated more than four\nclusters per arm.\nTables 4, 5, and 6 show the results of our secondary analyses,\nwhich examined the role of study and publication characteristics\non improvement in quality of reporting and methodological\nconduct before and after the publication of the CONSORT\nextension for cluster randomised trials. In particular, table 4\nshows that general medical journals performed at a higher\nstandard overall for nearly every criterion with the exception\nof justification for clustering\u21d3. When considering the change\nfrom before to after CONSORT, the general medical journals\nshowed significant improvement in only one criterion: reporting\nof number of clusters lost to follow-up (absolute improvement\n17%, 3% to 31%). No significant improvements in any of the\nmethodological criteria were observed in trials published in\neither the general medical or other journals. Based on the\nsummary score, trials published in general medical journals\nreported a mean of 66.5% of criteria before and amean of 71.6%\nof criteria after the CONSORT extension was published\n(absolute improvement 5%, \u22121.7% to 12%), while trials\npublished in other journals reported a mean of 56% before and\n60% after (absolute improvement 4.3%, \u22121.1% to 9.7%).\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 4 of 14\nRESEARCH\nTable 5\u21d3 shows similar findings: higher impact journals tended\nto score better in most reporting and methodological criteria.\nHigher impact factor journals showed significant improvements\nin two of 14 reporting criteria and in one of four methodological\ncriteria, while lower impact factor journals improved in two\nreporting criteria. Based on the summary score, trials published\nin higher impact factor journals reported a mean of 66.0% of\ncriteria before and a mean of 68.3% of criteria after the\nCONSORT extension was published (absolute improvement\n2.2%, \u22123.6% to 8.3%), while trials published in lower impact\nfactor journals reported a mean of 54.4% before and 59.2% after\n(absolute improvement 4.8%, \u22121.4% to 11.0%).\nThe results in table 6\u21d3 follow the same pattern: trials conducted\nin clinical settings tended to meet more of the reporting and\nmethodological criteria than trials conducted in non-clinical\nsettings. Trials from clinical settings showed significant\nimprovements in one reporting criterion and onemethodological\ncriterion, while the trials from non-clinical settings did not show\nsignificant improvements in any of the criteria. Based on the\nsummary score, trials conducted in clinical settings reported a\nmean of 63.3% of criteria before and a mean of 67.8% of criteria\nafter the CONSORT extension was published (absolute\nimprovement 4.6%, \u22121.1% to 10.3%), while trials published in\nnon-clinical settings reported amean of 55.3% before and 58.2%\nafter (absolute improvement 2.9%, \u22123.7% to 9.4%).\nDiscussion\nStatement of principal findings\nThere have been significant improvements over time in only\nfive of 14 CONSORT related reporting criteria for cluster\nrandomised trials. In particular, reporting whether outcome\nassessments were blind, as well as the number of clusters\nrandomised, withdrawn, and lost to follow-up per arm has\nconsiderable implications for assessment of internal validity.28\nAlthough the absolute improvements were small, the trends\nrepresent an important accomplishment because through\nimproved clarity of reporting, readers canmake better judgments\nregarding the risks of bias for any given study.1 While this\nprogress is welcome, the pace remains slow, and there remains\nconsiderable room for further improvement. The findings from\nour review suggest that future updates of the CONSORT\nextension for cluster trials should be accompanied by additional\ninterventions to help investigators and editors improve the\nstandards of these trials.\nOf the five reporting criteria that had a greater than 75%\nadherence rate, four can easily be summarised in a well prepared\ncluster-patient flow diagram or in a table summarising baseline\ndata for cluster and individual level variables, or both.Moreover,\nof the five criteria that showed significant improvements over\ntime, two related to flow of clusters-patients (reporting of\nnumbers of clusters randomised and lost to follow-up).\nTherefore, encouraging the use of such flow diagrams (as\nrecommended by the CONSORT extension) seems to have been\nsuccessful in improving reporting of enrolment and losses of\npatients and clusters. Even for trials conducted in clinical\nsettings and published in journals with higher impact factors,\nhowever, there remains a great need for further improvements\nin other reporting criteria, possibly through the development of\nsimilar devices within manuscripts that facilitate the\ncommunication of key information. Studies conducted in clinical\nrather than non-clinical settings and published in general medical\nand other higher impact journals were more likely to meet the\ncriteria for both reporting and methodological conduct, but the\nstandards of these studies failed to improve significantly in\nmany areas after the CONSORT extension was published.More\nstringent editorial policies might be required to bring about\nsubstantial improvement. Although journal editorial policies\nthat promote CONSORT are associated with improved\nreporting,29 a recent survey of 165 high impact journals found\nthat only 3% refer to the extension to cluster trials in the online\ninstructions for authors.30\nSome CONSORT related variables might be poorly reported\nbecause they are deemed unnecessary by investigators or editors.\nFor example, justification for conducting a cluster level\nrandomisation might be considered unnecessary in cases when\nthe intervention itself is at the level of the cluster. In a post hoc\nanalysis in which we excluded trials with interventions solely\nat the cluster level (n=99), however, the proportion reporting a\njustification remained low (33%). We agree with the authors of\nCONSORT that explicit justification is important because cluster\nrandomised trials involve unique methodological challenges\nthat require special attention during the design and analysis.19\nFor example, the intracluster correlation must be accounted for\nin both the sample size calculation and analysis; failure to clearly\nreport whether this has been done leads to questions regarding\nthe validity of the findings. Unfortunately, we found no evidence\nof significant improvement over time in four keymethodological\ncriteria. Indeed, the methodological quality of cluster\nrandomised trial reports after publication of the CONSORT\nextension remains disappointingly poor; this is especially true\nfor trials published in specialty (non-general) medicine journals.\nComparison with literature\nMany previous authors have noted problems with the design,\nanalysis, and reporting of cluster randomised trials. For example,\nthe reporting of an intracluster correlation represents an\nimportant contribution to the literature, allowing future studies\nto plan for adequate power. Only 18% of the 300 manuscripts\nthat we reviewed, however, reported an intracluster correlation\n(or 16% after we excluded trials with a pair matched design or\nthose with analysis at the cluster level). This is higher than\nprevious estimates of 4%8 and 8%.5 Our finding that only 31%\nof manuscripts provided a clear justification for using a cluster\nrandomised design also seems positive in light of the previous\nfinding from a review of 152 cluster randomised trials published\nfrom 1997 to 2000, which found that only 14% justified the use\nof a clustered design.8 In contrast, we found that only 50%\nreported clearly whether administrators or participants were\nblinded, and only 38% reported whether outcome assessors were\nblinded, whereas a previous review of 34 cluster randomised\ntrials in primary care published in 2004 or 2005 found that 67%\nand 62% clearly reported whether participants or outcome\nassessors were blinded, respectively.7Nevertheless, our findings\nindicate that the reporting of blinding of outcome assessment\ncould be improving over time. This is encouraging as blinding\nplays an essential role in any assessment of internal validity or\nrisk of bias, or both. Intriguingly, reporting of blinding might\nbe superior in cluster randomised trials than in individually\nrandomised trials; a recent review of 144 trials from 55 high\nimpact factor (median 7.67) journals found that only 25%\nadequately reported blinding.31\nAbout 40% of the trials in our review that reported a sample\nsize calculation failed to account for clustering, while 30% failed\nto account for clustering in the analysis. Improvement over time\nin these crucial aspects was suggested by a previous review that\nassessed 18 trials12 published from 1983 to 2003 and was also\nobserved in an (unpublished) overview of methodological\nreviews that assessed the quality of cluster randomised trials\npublished from 1973 to 2008.32 Still, inappropriate analytical\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 5 of 14\nRESEARCH\nmethods that inflate the risk of type 1 and type 2 error remain\ncommon in cluster randomised trials in various clinical\nspecialties.5-8 13-15\nWe found that only 86% of trials allocated a minimum of four\nclusters to each arm of the study. Past reviews of 152 cluster\nrandomised trials in primary care and 60 trials in public health\nfound that 91%8 and 92%6 of trials, respectively, met this\ncriterion, but a review of 75 cluster randomised trials in cancer\ncare found that only 67% had sufficient numbers of clusters per\narm.5 This might reflect the challenge of recruiting clusters\nrather than individuals, but the ability to make valid inferences\nregarding intervention effects in studies with few clusters is\nseverely compromised.When further recruitment is impossible,\ninvestigators should consider other design options.33The reviews\nfocusing on public health and on cancer trials each found 5%\nof studies allocated only one cluster per arm. In our study, 10\ntrials (3%) had only one cluster per arm. Investigators should\nrecognise that in trials with only one cluster per arm, the\nintervention effect is completely confounded by the cluster\neffect.\nLow numbers of clusters increase the likelihood of cluster level\ndifferences between study arms. Furthermore, clustering itself\ncan make it difficult to achieve balance across arms for\nindividual level variables when only simple randomisation is\nused to allocate clusters.34 In our review, 41% of the trials used\nsimple randomisation rather than an allocation technique more\nlikely to achieve balance at baseline. Previous reviews found\nthat trials used simple randomisation rather than stratification\nor matching techniques 40%5 to 46%8 of the time. The\nCONSORT extension for cluster randomised trials warns against\nthe risk of baseline imbalance from use of simple\nrandomisation,19 and, although matching could overcome this\nproblem, it leads to difficulties in estimating intracluster\ncorrelations and can complicate analyses.10 Although we did\nnot actually assess for imbalance at baseline, one previous\nreview found that three of 36 cluster randomised trials published\nin the BMJ, Lancet, andNew England Journal of Medicine from\n1997 to 2002 had evidence for cluster imbalance, while in 15\nthe adequacy of balance was deemed unclear.13 This indicates\nthe need for investigators (and editors) to strongly consider the\nvalue of allocation techniques other than simple randomisation\nto achieve baseline balance in cluster randomised trials.35\nStrengths and weaknesses of the study\nAny study that does not consider the entire population could be\nsusceptible to selection bias; it is plausible that different\nconclusions would be found by looking at a different sample.\nWe mitigated this risk in our study by abstracting what is (to\nour knowledge) the largest ever sample of cluster randomised\ntrials for a methodological review and the first to use a search\nstrategy that aimed to produce a sample of cluster trials\nrepresentative of all Medline publications. This search strategy\nhad a sensitivity of 90%, meaning that the random sample used\nin this study was representative of most cluster randomised trials\nin health research published in Medline from 2000 to 2008. If\nthe 10% of cluster randomised trials not identified by our search\nstrategy were systematically different with respect to reporting\nor methodological quality, however, this could bias our results.\nIn particular, as trials that are not clearly identified as \u201ccluster\nrandomised\u201d in titles and abstracts of reports might also be less\nlikely to adhere to recommended methodological and reporting\nstandards, our results might overestimate the proportion of trials\nadhering to these standards. Although the sample was large\nrelative to previous methodological reviews, it was determined\nby the objectives of the larger study focusing on ethical issues\nin cluster trials and we were therefore not specifically powered\nto detect small improvements in reporting. In particular,\nassuming the most conservative estimate of adherence of 50%\nbefore CONSORT, improvements to 60% and 70% adherence\nafter CONSORT (2005-6 and 2007-8, respectively) would have\nbeen required to allow 80% probability of detecting a significant\ntrend. Naturally, similar limitations extend to the secondary\nanalyses involving subgroups defined by study or journal\ncharacteristics.\nWe used a unique summary score for adherence to 14\nCONSORT based reporting variables relevant to cluster\nrandomised trials. We believe this is helpful because it provides\na sense of overall quality of reporting, but we do not intend to\nsuggest by providing this score that each criterion is of equal\nimportance. Although similar summary scores have been used\nbefore in other reviews of reporting standards,4 readers should\nnote this caveat in addition to the other known limitations of\nquality scales.36 Furthermore, we acknowledge the risk of\nspurious findings associated withmultiple testing in our analyses\nand recommend that significant results be interpreted cautiously.\nFinally, there are numerous criteria that we did not abstract in\nthis review that could have important implications with respect\nto internal or external validity, such as baseline imbalances for\nclusters and participants, as well as risks of identification and\nrecruitment bias. The extension to CONSORT for cluster\nrandomised trials might have resulted in improvements in\nreporting for criteria other than those that we abstracted. It is\nalso likely that the extension had a greater impact in journals\nthat actively endorsed (and explicitly enforced) the guideline.\nUnfortunately, we were unable to evaluate this because of the\ndifficulty in determining when CONSORT extensions were\nendorsed by each journal or how they were enforced.\nImplications\nAlthough we observed some improvement over time related to\nthe publication of the CONSORT extension, we found an\nongoing need for attention to the proper reporting and\nmethodological conduct in cluster randomised trials. As the\nextension to CONSORT for cluster randomised trials was\npublished in a general medical journal, investigators conducting\ntrials in non-clinical settings or publishing in other journal\ncategories (such as public health journals) might not have been\naware of the extension, thus leading to the relatively poorer\nperformance observed in this group. Themost recent CONSORT\nguidelines for individual level randomised controlled trials were\npublished in a wide range of clinical journals. Future updates\nfor the CONSORT extension to cluster trials should consider a\nsimilar (or even broader) approach.\nThe slow uptake of guidelines into practice is a problem that\nextends beyond the clinic and into the realm of publication. It\nseems likely that more than the publication of the CONSORT\nguideline is required to assist editors and investigators in proper\nconduct and reporting of cluster randomised trials. Improved\ncollaboration with guideline developers and new tools to support\nthe efforts of editors and investigators should be made available\nto support the publication of more transparent and higher quality\ncluster randomised trial manuscripts.\nWe thank the editors as well as the reviewers, Sandra Eldridge and\nCarol Coupland, for their insightful comments, which have led to\nsubstantial improvements on an earlier version of this manuscript.\nContributors: NMI, MT, CW, JMG, JCB, MPE, AD, ZS, and RFB\ncontributed to the conception and design of the study. NMI drafted the\narticle and is guarantor. MT conducted the analysis of the data. All\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 6 of 14\nRESEARCH\nWhat is already known on this topic\nPrevious methodological reviews have noted poor reporting of cluster randomised trials and have also found that the\nmethods used often fail to properly account for the clustered nature of the data\nAn extension to the consolidated standards of reporting trials (CONSORT) specific for cluster randomised trials was\npublished in 2004\nWhat this study adds\nReporting and methodological conduct of cluster randomised trials remains suboptimal\nThe extension to CONSORT for cluster randomised trials led to some improvements in reporting but not in methodological\nconduct\nMore than guidelines\/checklists are needed to support investigators and editors in publishing cluster randomised trials\nthat provide adequate information to properly assess internal and external validity\nauthors contributed to the interpretation of the data, commented on the\nfirst draft, revised the article critically for important intellectual content,\nand approved the final version. All authors had full access to all of the\ndata (including statistical reports and tables) in the study and can take\nresponsibility for the integrity of the data and the accuracy of the data\nanalysis.\nFunding: This study was funded by operating grants MOP85066 and\nMOP89790 from the Canadian Institutes of Health Research. The\nfunding agency had no role in the study design, collection, analysis or\ninterpretation of data, writing of the manuscript or in the decision to\nsubmit the manuscript for publication. NMI and AMcR both hold a\nfellowship award from the Canadian Institutes of Health Research. JMG\nand CW both hold Canada Research Chairs.\nCompeting interests: All authors have completed the ICMJE uniform\ndisclosure form at www.icmje.org\/coi_disclosure.pdf (available on\nrequest from the corresponding author) and declare: no support from\nany organisation for the submitted work; no financial relationships with\nany organisations that might have an interest in the submitted work in\nthe previous three years; no other relationships or activities that could\nappear to have influenced the submitted work.\nEthical approval: Not required.\nData sharing: Technical appendix, statistical code, and dataset are\navailable from the corresponding author.\n1 Simera I, Moher D, Hirst A, Hoey J, Schulz KF, Altman DG. Transparent and accurate\nreporting increases reliability, utility, and impact of your research: reporting guidelines\nand the EQUATOR Network. BMC Med 2010;8:24.\n2 Moher D, Hopewell S, Schulz KF, Montori V, Gotzsche PC, Devereaux PJ, et al.\nCONSORT 2010 explanation and elaboration: updated guidelines for reporting parallel\ngroup randomised trials. J Clin Epidemiol 2010;63:e1-37.\n3 Hopewell S, Dutton S, Yu LM, Chan AW, Altman DG. The quality of reports of randomised\ntrials in 2000 and 2006: comparative study of articles indexed in PubMed. BMJ\n2010;340:c723.\n4 Plint AC, Moher D, Morrison A, Schulz K, Altman DG, Hill C, et al. Does the CONSORT\nchecklist improve the quality of reports of randomised controlled trials? A systematic\nreview. Med J Aust 2006;185:263-7.\n5 Murray DM, Pals SL, Blitstein JL, Alfano CM, Lehman J. Design and analysis of\ngroup-randomized trials in cancer: a review of current practices. J Natl Cancer Inst\n2008;100:483-91.\n6 Varnell SP, Murray DM, Janega JB, Blitstein JL. Design and analysis of group-randomized\ntrials: a review of recent practices. Am J Public Health 2004;94:393-9.\n7 Eldridge S, Ashby D, Bennett C, Wakelin M, Feder G. Internal and external validity of\ncluster randomised trials: systematic review of recent trials. BMJ 2008;336:876-80.\n8 Eldridge SM, Ashby D, Feder GS, Rudnicka AR, Ukoumunne OC. Lessons for cluster\nrandomized trials in the twenty-first century: a systematic review of trials in primary care.\nClin Trials 2004;1:80-90.\n9 Hahn S, Puffer S, Torgerson DJ, Watson J. Methodological bias in cluster randomised\ntrials. BMC Med Res Methodol 2005;5:10.\n10 Donner A, Klar N. Pitfalls of and controversies in cluster randomization trials. Am J Public\nHealth 2004;94:416-22.\n11 Donner A, Brown KS, Brasher P. A methodological review of non-therapeutic intervention\ntrials employing cluster randomization, 1979-1989. Int J Epidemiol 1990;19:795-800.\n12 Bland JM. Cluster randomised trials in the medical literature: two bibliometric surveys.\nBMC Med Res Methodol 2004;4:21.\n13 Puffer S, Torgerson D, Watson J. Evidence for risk of bias in cluster randomised trials:\nreview of recent trials published in three general medical journals. BMJ 2003;327:785-9.\n14 Handlos LN, Chakraborty H, Sen PK. Evaluation of cluster-randomized trials on maternal\nand child health research in developing countries. Trop Med Int Health 2009;14:947-56.\n15 Bowater RJ, Abdelmalik SM, Lilford RJ. The methodological quality of cluster randomised\ncontrolled trials for managing tropical parasitic disease: a review of trials published from\n1998 to 2007. Trans R Soc Trop Med Hyg 2009;103:429-36.\n16 Isaakidis P, Ioannidis JP. Evaluation of cluster randomized controlled trials in sub-Saharan\nAfrica. Am J Epidemiol 2003;158:921-6.\n17 Simpson JM, Klar N, Donnor A. Accounting for cluster randomization: a review of primary\nprevention trials, 1990 through 1993. Am J Public Health 1995;85:1378-83.\n18 Chuang JH, Hripcsak G, Jenders RA. Considering clustering: a methodological review of\nclinical decision support system studies. Proc AMIA Symp 2000:146-50.\n19 Campbell MK, Elbourne DR, Altman DG, CONSORT group. CONSORT statement:\nextension to cluster randomised trials. BMJ 2004;328:702-8.\n20 Chalmers TC, Celano P, Sacks HS, Smith H Jr. Bias in treatment assignment in controlled\nclinical trials. N Engl J Med 1983;309:1358-61.\n21 Schulz KF, Chalmers I, Hayes RJ, Altman DG. Empirical evidence of bias. Dimensions\nof methodological quality associated with estimates of treatment effects in controlled trials.\nJAMA 1995;273:408-12.\n22 Taljaard M, McGowan J, Grimshaw JM, Brehaut JC, McRae A, Eccles MP, et al. Electronic\nsearch strategies to identify reports of cluster randomized trials in MEDLINE: low precision\nwill improve with adherence to reporting standards. BMCMed Res Methodol 2010;10:15.\n23 Taljaard M, McRae AD, Weijer C, Bennett C, Dixon S, Taleban J, et al. Inadequate\nreporting of research ethics review and informed consent in cluster randomised trials:\nreview of random sample of published trials. BMJ 2011;342:d2496.\n24 Donner A, Klar N. Design and analysis of cluster randomization trials in health research.\nOxford University Press, 2000.\n25 Donner A, Klar N. Methods for comparing event rates in intervention studies when the\nunit of allocation is a cluster. Am J Epidemiol 1994;140:279-301.\n26 SJR\u2014SCImago Journal and Country Rank. Science analysis. 2011. www.scimagojr.com.\n27 Falagas ME, Kouranos VD, Arencibia-Jorge R, Karageorgopoulos DE. Comparison of\nSCImago journal rank indicator with journal impact factor. FASEB J 2008;22:2623-8.\n28 Higgins JPT, Altman DG. Assessing risk of bias in included studies. In: Higgins JPT,\nGreen S, eds. Cochrane handbook for systematic reviews of interventions. Version 5.0.2.\nCochrane Collaboration, 2009.\n29 Devereaux PJ, Manns BJ, Ghali WA, Quan H, Guyatt GH. The reporting of methodological\nfactors in randomized controlled trials and the association with a journal policy to promote\nadherence to the consolidated standards of reporting trials (CONSORT) checklist.Control\nClin Trials 2002;23:380-8.\n30 Hopewell S, Altman DG, Moher D, Schulz KF. Endorsement of the CONSORT statement\nby high impact factor medical journals: a survey of journal editors and journal \u201cinstructions\nto authors.\u201dTrials 2008;9:20.\n31 Reveiz L, Cortes-Jofre M, Asenjo Lobos C, Nicita G, Ciapponi A, Garcia-Dieguez M, et\nal. Influence of trial registration on reporting quality of randomized trials: study from highest\nranked journals. J Clin Epidemiol 2010;63:1216-22.\n32 Rotondi R. Selected topics in the meta-analysis of cluster randomized trials: aspects of\nevidence-synthesis and experimental design [PhD thesis]. University of Western Ontario,\n2010.\n33 Shadish WR. Experimental and quasi-experimental designs for generalized causal\ninference.Houghton Mifflin Company, 2002.\n34 Glynn RJ, Brookhart MA, StedmanM, Avorn J, Solomon DH. Design of cluster-randomized\ntrials of quality improvement interventions aimed at medical care providers. Med Care\n2007;45(10 suppl 2):S38-43.\n35 Raab GM, Butcher I. Balance in cluster randomized trials. Stat Med 2001;20:351-65.\n36 Moher D, Jadad AR, Nichol G, Penman M, Tugwell P, Walsh S. Assessing the quality of\nrandomized controlled trials: an annotated bibliography of scales and checklists. Control\nClin Trials 1995;16:62-73.\nAccepted: 09 August 2011\nCite this as: BMJ 2011;343:d5886\nThis is an open-access article distributed under the terms of the Creative Commons\nAttribution Non-commercial License, which permits use, distribution, and reproduction in\nany medium, provided the original work is properly cited, the use is non commercial and\nis otherwise in compliance with the license. See: http:\/\/creativecommons.org\/licenses\/by-\nnc\/2.0\/ and http:\/\/creativecommons.org\/licenses\/by-nc\/2.0\/legalcode.\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 7 of 14\nRESEARCH\nTables\nTable 1| Comparison of recommendations in extension to CONSORT for cluster randomised trials and variables abstracted for present\nstudy\nDescription of variable abstracted for this review\nCriterion included in present\nstudy?CONSORT criterion\nClearly identified as cluster randomised trial in title or\nabstract\nYes (reporting)1) Specify that allocation was based on clusters\nJustification provided for using clustered designYes (reporting)2) Rationale for using cluster design\n\u2014No3) Eligibility criteria for participants and clusters\n\u2014No5) Interventions intended for individual level, cluster level, or both\n\u2014No5) Specific objectives for individual level, cluster level, or both\nPrimary outcome identified clearlyYes (reporting)6) Report outcome measures for individual level, cluster level, or both\nSample size calculation presentedYes (reporting)7) How total sample size was determined including method of\ncalculation, No of clusters, cluster size, coefficient of intracluster\ncorrelation\nAccounted for clustering in sample sizeYes (methodology)\nUsed stratification\/matching\/minimisationYes (methodology)8) Method used to generate random allocation sequence\n\u2014No9) Method used to implement random allocation sequence\nIdentified who enrolled patientsYes (reporting)10) Who generated allocation sequence and enrolled and assigned\nparticipants\nReported on blinding of outcome assessors; reported\non blinding of participants\/administrators\nYes (reporting)11) Whether participants, those administering interventions, and those\nassessing outcomes were blinded to group assignment\nReported methods of analysisYes (reporting)12) Statistical methods used to compare groups for primary outcome(s)\nindicating how clustering was taken into account\nAccounted for clustering in analysisYes (methodology)\nReported No of clusters randomised; reported No of\nindividuals lost to follow-up; reported No of clusters lost\nto follow-up; reported No of clusters withdrew; reported\nsize of clusters in each arm\nYes (reporting)13) Flow of clusters and individual participants through each stage\n\u2014No14) Dates defining periods of recruitment and follow up\n\u2014No15) Baseline information for each group for individual and cluster levels\nSimilar to 13 aboveYes (reporting)16) No of clusters and participants in each group included in each\nanalysis and whether analysis was by intention to treat\nAllocated minimum of four clusters per armYes (methodology)\nReported intracluster correlationYes (reporting)17) For each outcome, summary of results for each group for individual\nor cluster level, and coefficient of intracluster correlation.\n\u2014No18) Address multiplicity by reporting any other analyses performed\n\u2014No19) All important adverse events or side effects in each intervention\ngroup\n\u2014No20) Interpretation of results (internal validity)\n\u2014No21) Generalisability (external validity)\n\u2014No22) Interpretation in context of current evidence\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 8 of 14\nRESEARCH\nTable 2| Characteristics of 300 cluster randomised trials included in review of studies for compliance with CONSORT extension. Figures\nare numbers (percentage) of trials unless stated otherwise\nDataCharacteristic\nPublication year:\n139 (46)2000-4\n93 (31)2005-6\n68 (23)2007-8\nJournal impact factor (n=294):\n2.9 (2.1-5.1)Median (IQR)\n0.45-50.0Range\nCountry of study recruitment:\n114 (38)USA\n50 (17)UK or Ireland\n16 (5)Canada\n16 (5)Australia or New Zealand\n104 (35)Other\nClinical setting (unit of allocation):\n81 (27)Medical practices or clinics\n41 (14)Individual health professionals\n25 (8)Hospitals, hospital units, hospital wards\n16 (5)Nursing homes or wards\n6 (2)Other (such as postal codes of family practices)\nNon-clinical setting (unit of allocation):\n66 (22)Schools or classrooms\n39 (13)Residential areas (such as villages, districts, housing units)\n16 (5)Worksites\n10 (3)Sports teams, clubs, churches, other social groups\nNo of clusters randomised (n=285):\n21.0 (12-52)Median (IQR)\n2-605Range\nAverage cluster size (n=271):\n33.9 (12.5-88.5)Median (IQR)\n1.7-122 855Range\nNo of participants per arm (n=290):\n329 (143-866)Median (IQR)\n20-614 275Range\nIQR=interquartile range.\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 9 of 14\nRESEARCH\nTable 3| Adherence (number (percentage)) to standard criteria for reporting and methodology for cluster randomised trials, overall and\nbefore and after publication of CONSORT extension for cluster randomised trials\nAbsolute change in %\nadherence (before to after)\n(95% CI)\nP value for\ntrend\nAfter (2007-8,\nn=68)\nAfter (2005-6,\nn=93)\nBefore (2000-4,\nn=139)Overall (n=300)\nCriteria related to quality of reporting\n11.0 (\u22120.3 to 22.2)0.03839 (57)47 (50.5)59 (43)145 (48)Clearly identified as clustered in title\nor abstract\n8.8 (\u22121.6 to 19.2)0.03828 (41)29 (31.2)37 (27)94 (31)Justification provided for using\ncluster design\n13.9 (3.1 to 24.7)0.01931 (46)40 (43.0)42 (30)113 (38)Reported on blinding of outcome\nassessors\n\u22122.7 (\u221214.1 to 8.6)0.29229 (43)50 (53.8)72 (52)151 (50)Reported on blinding of\nparticipants\/administrators\n4.5 (\u22126.9 to 15.8)0.28436 (53)43 (46.2)62 (45)141 (47)Primary outcome identified clearly\n\u22121.4 (\u221212.7 to 9.9)0.48343 (63)44 (47.3)77 (55)164 (55)Sample size calculation presented\n\u22123.6 (\u221216.4 to 9.2)0.67434 (57)41 (55.4)59 (60)134 (58)Identified who enrolled participants*\n6.6 (\u22121.1 to 14.3)0.03564 (94)81 (87.1)116 (84)261 (87)Reported No of clusters randomised\n13.3 (3.9 to 22.6)0.01058 (85)78 (83.9)99 (71)235 (78)Reported No of clusters lost to\nfollow-up\n4.8 (\u22123.3 to 12.9)0.07863 (93)78 (83.9)115 (83)256 (85)Reported No of clusters that\nwithdrew\n5.9 (\u22121.7 to 13.5)0.08163 (93)82 (88.2)117 (84)262 (87)Reported size of clusters in each\narm\n\u22124.5 (\u221214.1 to 5.1)0.86054 (79)65 (69.9)109 (78)228 (76)Reported No of individuals lost to\nfollow-up\n2.9 (\u22122.7 to 8.6)0.45664 (94)89 (95.7)128 (92)281 (94)Reported methods of analysis\n\u221210.2 (\u221220.3 to 0)0.32310 (18)4 (6.2)21 (22)35 (16)Reported intracluster correlation\u2020\n3.5 (\u22120.8 to 7.8)0.09266.1 (16.9)61.5 (19.9)59.9 (19.6)61.8 (19.2)Mean (SD) summary score\nCriteria relating to methodological quality\n7.2 (\u22124.1 to 18.5)0.27240 (59)55 (59.1)72 (52)167 (56)Used restricted randomisation\n0.4 (\u22127.8 to 8.6)0.86757 (86)76 (85.4)111 (85)244 (86)Allocated minimum of four clusters\nper arm\u2021\n\u22129.9 (\u221224.8 to 4.9)0.66228 (65)21 (47.7)51 (66)100 (61)Accounted for clustering in sample\nsize\u00a7\n\u22124.2 (\u221214.6 to 6.2)0.47446 (68)63 (67.7)100 (72)209 (70)Accounted for clustering in analysis\n*Excludes 67 trials with no participant enrolment.\n\u2020Excludes 84 trials with pair matched designs or primary analysis at cluster level.\n\u2021Excludes 15 studies with unclear number of clusters.\n\u00a7Excludes 136 trials with no sample size calculation presented.\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 10 of 14\nRESEARCH\nTable 4| Change in adherence (number (percentage)) to standard criteria for reporting and methodology for cluster randomised trials by\njournal type, before and after publication of CONSORT extension for cluster randomised trials\nOther journalsGeneral medical journals\nAbsolute change in\nadherence (before to\nafter) (95% CI)\nAfter (2005-8,\nn=113)\nBefore (2000-4,\nn=84)\nAbsolute change in\nadherence (before to\nafter) (95% CI)\nAfter (2005-8,\nn=48)\nBefore (2000-4,\nn=55)\nCriteria related to quality of reporting\n11.2 (\u22122.6 to 25.0)53 (47)30 (36)16.0 (\u22122.6 to 34.6)33 (69)29 (53)Clearly identified as clustered\nin title or abstract\n7.7 (\u22125.4 to 20.8)41 (36)24 (29)9.7 (\u22127.7 to 27.1)16 (33)13 (24)Justification provided for using\ncluster design\n15.1 (2.3 to 27.9)44 (39)20 (24)16.3 (\u22122.8 to 35.3)27 (56)22 (40)Reported on blinding of\noutcome assessors\n\u22121.9 (\u221215.9 to 12.2)49 (43)38 (45)0.7 (\u221218.1 to 19.5)30 (63)34 (62)Reported on blinding of\nparticipants\/administrators\n5.3 (\u22128.3 to 18.9)45 (40)29 (35)10.8 (\u22127.4 to 29.1)34 (71)33 (60)Primary outcome identified\nclearly\n\u22121.9 (\u221216.0 to 12.2)53 (47)41 (49)5.4 (\u221212.6 to 23.4)34 (71)36 (66)Sample size calculation\npresented\n1.0 (\u221214.8 to 16.8)51 (53)33 (52)\u22129.4 (\u221230.6 to 11.7)24 (65)26 (74)Identified who enrolled\nparticipants*\n7.2 (\u22122.7 to 17.2)101 (89)69 (82)6.2 (\u22126.0 to 18.4)44 (93)47 (86)Reported No of clusters\nrandomised\n12.4 (0.2 to 24.6)92 (81)58 (69)17.1 (3.2 to 31.0)44 (93)41 (75)Reported No of clusters lost to\nfollow-up\n4.9 (\u22125.7 to 15.5)97 (86)68 (81)6.2 (\u22126.0 to 18.4)44 (93)47 (86)Reported No of clusters that\nwithdrew\n7.2 (\u22122.7 to 17.2)101 (89)69 (82)4.4 (\u22127.4 to 16.2)44 (93)48 (87)Reported size of clusters in\neach arm\n\u22122.1 (\u221214.7 to 10.4)81 (72)62 (74)\u22126.3 (\u221221.2 to 8.5)38 (79)47 (86)Reported No of individuals lost\nto follow-up\n2.1 (\u22125.3 to 9.5)106 (94)77 (92)5.2 (\u22122.8 to 13.2)47 (98)51 (93)Reported methods of analysis\n\u22126.9 (\u221223.0 to 9.5)9 (11)11 (18)\u221216.0 (\u221238.7 to 7.7)5 (14)10 (30)Reported intracluster\ncorrelation\u2020\n4.3 (\u22121.1 to 9.7)60.0 (18.6)55.7 (19.5)5.1 (\u22121.7 to 12.0)71.6 (16.7)66.5 (18.1)Mean (SD) summary score\nCriteria relating to methodological quality\n12.9 (\u22121.1 to 26.9)63 (56)36 (43)1.2 (\u221217.1 to 19.5)32 (67)36 (66)Used restricted randomisation\n\u22120.7 (\u221211.7 to 10.3)89 (82)64 (83)4.9 (\u22126.1 to 16.0)44 (94)47 (89)Allocated minimum of four\nclusters per arm\u2021\n\u22122.9 (\u221214.9 to 9.1)25 (22)21 (25)\u22124.6 (\u221223.9 to 14.8)24 (50)30 (55)Accounted for clustering in\nsample size\u00a7\n\u22125.0 (\u221218.7 to 8.7)67 (59)54 (64)3.9 (\u22129.7 to 17.4)42 (88)46 (84)Accounted for clustering in\nanalysis\n*Excludes 67 trials with no participant enrolment.\n\u2020Excludes 84 trials with pair matched designs or primary analysis at cluster level.\n\u2021Excludes 15 studies with unclear number of clusters.\n\u00a7Excludes 136 trials with no sample size calculation presented.\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 11 of 14\nRESEARCH\nTable 5| Change in adherence (number (percentage)) to standard criteria for reporting and methodology for cluster randomised trials by\njournal impact factor*, before and after publication of CONSORT extension for cluster randomised trials\nLower impact factor journalsHigher impact factor journals\nAbsolute change in\nadherence (before to\nafter) (95% CI)\nAfter (2005-8,\nn=82)\nBefore (2000-4,\nn=63)\nAbsolute change in\nadherence (before to\nafter) (95% CI)\nAfter (2005-8,\nn=78)\nBefore (2000-4,\nn=71)\nCriteria related to quality of reporting\n15.0 (\u22120.7 to 30.6)37 (45)19 (30)6.5 (\u22129.3 to 22.2)49 (63)40 (56)Clearly identified as clustered\nin title or abstract\n2.3 (\u221212.5 to 17.0)24 (29)17 (27)17.0 (2.0 to 31.9)33 (42)18 (25)Justification provided for using\ncluster design\n4.4 (\u221210.7 to 19.5)27 (33)18 (29)21.3 (5.7 to 36.9)43 (55)24 (34)Reported on blinding of\noutcome assessors\n2.4 (\u221214.0 to 18.8)41 (50)30 (48)\u22127.6 (\u221223.6 to 8.4)38 (49)40 (56)Reported on blinding of\nparticipants\/administrators\n6.1 (\u22129.5 to 21.6)31 (38)20 (32)5.2 (\u221210.6 to 21.0)48 (62)40 (56)Primary outcome identified\nclearly\n\u22128.1 (\u221224.5 to 8.2)35 (43)32 (51)3.3 (\u221212.0 to 18.6)52 (67)45 (63)Sample size calculation\npresented\n\u22122.1 (\u221221.1 to 17.0)38 (55)24 (57)\u22124.5 (\u221222.3 to 13.3)37 (58)33 (62)Identified who enrolled\nparticipants\u2020\n14.1 (1.7 to 26.4)74 (90)48 (76)\u22121.8 (\u221211.1 to 7.5)70 (90)65 (92)Reported No of clusters\nrandomised\n19.4 (5.0 to 33.9)68 (83)40 (64)7.0 (\u22125.2 to 19.3)67 (86)56 (79)Reported No of clusters lost to\nfollow-up\n9.2 (\u22123.8 to 22.2)70 (85)48 (76)\u22120.4 (\u221210.1 to 9.3)70 (90)64 (90)Reported No of clusters that\nwithdrew\n11.3 (\u22121.1 to 23.5)73 (89)49 (78)0.9 (\u22128.5 to 10.3)71 (91)64 (90)Reported size of clusters in\neach arm\n\u22122.3 (\u221217.0 to 12.5)58 (71)46 (73)\u22124.9 (\u221217.5 to 7.8)61 (78)59 (83)Reported No of individuals lost\nto follow-up\n2.2 (\u22127.0 to 11.4)76 (93)57 (91)5.8 (\u22120.7 to 12.2)77 (99)66 (93)Reported methods of analysis\n\u22123.6 (\u221223.0 to 16.0)8 (13)7 (17)\u221217.7 (\u221235.6 to 1.3)6 (10)14 (28)Reported intracluster\ncorrelation\u2021\n4.8 (\u22121.4 to 11.0)59.2 (18.3)54.4 (19.1)2.2 (\u22123.6 to 8.3)68.3 (18.0)66.0 (18.7)Mean (SD) summary score\nCriteria relating to methodological quality\n8.6 (\u22127.6 to 24.8)50 (61)33 (52)5.6 (\u221210.4 to 21.6)45 (8)37 (52)Used restricted randomisation\n\u22128.2 (\u221221.2 to 4.7)62 (78)48 (86)11.7 (2.0 to 21.3)71 (96)59 (84)Allocated minimum of four\nclusters per arm\u00a7\n\u221219.6 (\u221243.1 to 3.8)15 (43)20 (63)\u22123.5 (\u221222.2 to 15.2)34 (65)31 (69)Accounted for clustering in\nsample size\u00b6\n\u22126.7 (\u221222.9 to 9.5)44 (54)38 (60)1.6 (\u221210.6 to 13.9)65 (83)58 (82)Accounted for clustering in\nanalysis\n*Excludes six trials with no impact factor.\n\u2020Excludes 67 trials with no participant enrolment.\n\u2021Excludes 84 trials with pair matched designs or primary analysis at cluster level.\n\u00a7Excludes 15 studies with unclear number of clusters.\n\u00b6Excludes 136 trials with no sample size calculation presented.\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 12 of 14\nRESEARCH\nTable 6| Change in adherence (number (percentage)) to standard criteria for reporting and methodology for cluster randomised trials by\ntrial setting, before and after publication of CONSORT extension for cluster randomised trials\nNon-clinical settingsClinical settings\nAbsolute change in\nadherence (before to\nafter) (95% CI)\nAfter (2005-8,\nn=73)\nBefore (2000-4,\nn=58)\nAbsolute change in\nadherence (before to\nafter) (95% CI)\nAfter (2005-8,\nn=88)\nBefore (2000-4,\nn=81)\nCriteria related to quality of reporting\n12.8 (\u22123.7 to 29.3)32 (44)18 (31)10.8 (\u22124.2 to 25.7)54 (61)41 (51)Clearly identified as clustered\nin title or abstract\n10.5 (\u22124.8 to 25.7)24 (33)13 (22)7.9 (\u22126.3 to 22.1)33 (38)24 (30)Justification provided for using\ncluster design\n14.6 (\u22120.9 to 30.0)27 (37)13 (22)14.2 (\u22120.6 to 29.0)44 (50)29 (36)Reported on blinding of\noutcome assessors\n\u22120.9 (\u221217.6 to 15.8)27 (37)22 (38)\u22122.6 (\u221217.4 to 12.1)52 (59)50 (62)Reported on blinding of\nparticipants\/administrators\n\u22123.0 (\u221219.9 to 13.9)28 (38)24 (41)11.0 (\u22123.9 to 26.0)51 (58)38 (47)Primary outcome identified\nclearly\n7.0 (\u22129.5 to 23.5)29 (40)19 (33)\u22125.7 (\u221219.6 to 8.3)58 (66)58 (72)Sample size calculation\npresented\n\u22126.4 (\u221224.7 to 11.9)29 (45)26 (51)\u22122.1 (\u221219.3 to 15.1)46 (67)33 (69)Identified who enrolled\nparticipants*\n6.9 (\u22123.7 to 17.5)68 (93)50 (86)6.0 (\u22124.9 to 16.9)77 (88)66 (82)Reported No of clusters\nrandomised\n6.0 (\u22127.7 to 19.7)61 (84)45 (78)18.6 (5.9 to 31.2)75 (85)54 (67)Reported No of clusters lost to\nfollow-up\n4.2 (\u22127.0 to 15.4)66 (90)50 (86)5.0 (\u22126.4 to 16.4)75 (85)65 (80)Reported No of clusters that\nwithdrew\n7.0 (\u22126.1 to 20.1)63 (86)46 (79)5.5 (\u22123.4 to 14.4)82 (93)71 (88)Reported size of clusters in\neach arm\n\u22127.7 (\u221223.8 to 8.4)46 (63)41 (71)\u22121.0 (\u221212.2 to 10.2)73 (83)68 (84)Reported No of individuals lost\nto follow-up\n0.7 (\u22125.3 to 6.7)71 (97)56 (97)4.3 (\u22124.3 to 12.9)82 (93)72 (88.9)Reported methods of analysis\n\u221218.5 (\u221239.1 to 3.7)2 (4)8 (23)\u22125.1 (\u221221.8 to 11.9)12 (16)13 (21)Reported intracluster\ncorrelation\u2020\n2.9 (\u22123.7 to 9.4)58.2 (18.7)55.3 (18.8)4.6 (\u22121.1 to 10.3)67.8 (17.7)63.3 (19.7)Mean (SD) summary score\nCriteria relating to methodological quality\n\u22127.9 (\u221225.0 to 9.2)37 (51)34 (59)19.0 (4.3 to 33.7)58 (66)38 (47)Used restricted randomisation\n\u22122.6 (\u221214.7 to 9.6)61 (85)48 (87)2.8 (\u22128.3 to 13.8)72 (87)63 (84)Allocated minimum of four\nclusters per arm\n\u221211.6 (\u221238.2 to 14.9)18 (62)14 (74)\u221210.3 (\u221228.2 to 7.5)31 (54)37 (64)Accounted for clustering in\nsample size\u2021\n\u22126.6 (-23.3 to 10.0)43 (59)38 (66)\u22121.5 (\u221214.5 to 11.4)66 (75)62 (77)Accounted for clustering in\nanalysis\n*Excludes 67 trials with no participant enrolment.\n\u2020Excludes 84 trials with pair matched designs or primary analysis at cluster level.\n\u2021Excludes 136 trials with no sample size calculation presented.\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 13 of 14\nRESEARCH\nFigures\nFig 1 Identification of sample of 300 cluster randomised trials\nFig 2 Number of citations (assessed with SCOPUS) of CONSORT extension for cluster randomised trials by year of\npublication\nNo commercial reuse: See rights and reprints http:\/\/www.bmj.com\/permissions Subscribe: http:\/\/www.bmj.com\/subscribe\nBMJ 2011;343:d5886 doi: 10.1136\/bmj.d5886 Page 14 of 14\nRESEARCH\n"}
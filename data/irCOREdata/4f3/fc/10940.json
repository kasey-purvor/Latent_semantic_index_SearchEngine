{"doi":"10.1155\/2011","coreId":"10940","oai":"oai:eprints.lancs.ac.uk:39961","identifiers":["oai:eprints.lancs.ac.uk:39961","10.1155\/2011"],"title":"Combined data association and evolving particle filter for tracking of multiple articulated objects.","authors":["Bhaskar, Harish","Mihaylova, Lyudmila"],"enrichments":{"references":[{"id":16397155,"title":"A .Y i l m a z ,O .J a v e d ,a n dM .S h a h ,\u201c O b j e c tt r a c k i n g :as u r v e y ,","authors":[],"date":"2006","doi":null,"raw":"A .Y i l m a z ,O .J a v e d ,a n dM .S h a h ,\u201c O b j e c tt r a c k i n g :as u r v e y , \u201d ACM Computing Surveys, vol. 38, no. 4, 2006.","cites":null},{"id":745773,"title":"A data association algorithm for multiple object tracking in video sequences,\u201d","authors":[],"date":"2006","doi":"10.1049\/ic:20060565","raw":"M. H. Jaward, L. Mihaylova, N. Canagarajah, and D. Bull, \u201cA data association algorithm for multiple object tracking in video sequences,\u201d in Proceedings of the IEE Seminar on Target Tracking: Algorithms and Applications, pp. 131\u2013136, Birmingham,UK, 2006.","cites":null},{"id":16397020,"title":"A g g arwalan dQ.C ai ,\u201c H u manmot i onan al y si s:ar evi e w ,","authors":[],"date":"1999","doi":null,"raw":"J .K .A g g arwalan dQ.C ai ,\u201c H u manmot i onan al y si s:ar evi e w , \u201d Computer Vision and Image Understanding, vol. 73, no. 3, pp. 428\u2013440, 1999.","cites":null},{"id":742168,"title":"A Rao-Blackwellised unscented Kalman filter,\u201d","authors":[],"date":"2003","doi":null,"raw":null,"cites":null},{"id":739023,"title":"A survey of computer visionbased human motion capture,\u201d","authors":[],"date":"2001","doi":"10.1006\/cviu.2000.0897","raw":null,"cites":null},{"id":741237,"title":"Adaptive visual tracking and recognition using particle \ufb01lters,\u201d","authors":[],"date":"2003","doi":"10.1109\/icme.2003.1221625","raw":"S. Zhou, R. Chellappa, and B. Moghaddam, \u201cAdaptive visual tracking and recognition using particle \ufb01lters,\u201d in Proceedings of the IEEE International Conference on Multimedia & Expo (ICME \u201903), pp. 560\u2013566, July 2003.","cites":null},{"id":16397149,"title":"Bar-Shalom,\u201cExpected likelihood for tracking in clutter with particle \ufb01lters,\u201d","authors":[],"date":"2002","doi":"10.1117\/12.478507","raw":"A. Marrs,S. Maskell,andY. Bar-Shalom,\u201cExpected likelihood for tracking in clutter with particle \ufb01lters,\u201d in Signal and data Processing of Small Targets, vol.4728ofProceedings of SPIE,p p . 230\u2013239, April 2002.","cites":null},{"id":741954,"title":"Beyond the Kalman Filter: Particle Filter for Tracking Applications,","authors":[],"date":"2004","doi":"10.1109\/maes.2004.1346848","raw":null,"cites":null},{"id":740027,"title":"Beyond the Kalman Filter: ParticleFilter for Tracking Applications, Artech House,","authors":[],"date":"2004","doi":null,"raw":null,"cites":null},{"id":746029,"title":"CAVIAR test case scenarios, 2005,http:\/\/homepages.inf.ed.ac .uk\/rbf\/.","authors":[],"date":null,"doi":null,"raw":"CAVIAR test case scenarios, 2005,http:\/\/homepages.inf.ed.ac .uk\/rbf\/.","cites":null},{"id":743457,"title":"Comparison of resampling schemes for particle \ufb01ltering,\u201d","authors":[],"date":"2005","doi":"10.1109\/ispa.2005.195385","raw":"O. Cappe, R. Douc, and E. Moulines, \u201cComparison of resampling schemes for particle \ufb01ltering,\u201d in Proceedings of the 4thInternationalSymposiumon Imageand SignalProcessing and Analysis (ISPA \u201905), Croatia, 2005.","cites":null},{"id":738553,"title":"Computational studies of human motion: part 1, tracking and motion synthesis,\u201d Foundations and Trends","authors":[],"date":"2006","doi":"10.1561\/0600000005","raw":null,"cites":null},{"id":743753,"title":"Design and Analysis of Modern Tracking Systems, Artech House Radar Library,","authors":[],"date":"1999","doi":null,"raw":"S. Blackman and R. Popoli, Design and Analysis of Modern Tracking Systems, Artech House Radar Library, 1999.","cites":null},{"id":740626,"title":"Detecting moving objects, ghosts, and shadows in video streams,\u201d","authors":[],"date":"2003","doi":"10.1109\/tpami.2003.1233909","raw":"R. Cucchiara, C. Grana, M. Piccardi, and A. Prati, \u201cDetecting moving objects, ghosts, and shadows in video streams,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence,v o l . 25, no. 10, pp. 1337\u20131342, 2003.","cites":null},{"id":744629,"title":"Efficient particle filtering for multiple target tracking with application to tracking in structured images,\u201d","authors":[],"date":"2003","doi":"10.1016\/s0262-8856(03)00087-8","raw":null,"cites":null},{"id":16397250,"title":"E\ufb03cient particle \ufb01ltering for multiple target tracking with applicationtotrackinginstructured images,\u201dImageandVision","authors":[],"date":"2003","doi":"10.1016\/s0262-8856(03)00087-8","raw":"S. Maskell, M. Rollason, N. Gordon, and D. Salmond, \u201cE\ufb03cient particle \ufb01ltering for multiple target tracking with applicationtotrackinginstructured images,\u201dImageandVision Computing, vol. 21, no. 10, pp. 931\u2013939, 2003.","cites":null},{"id":744395,"title":"Engineer\u2019s guide to variable-structure multiplemodel estimation for tracking,\u201d in Multitarget-Multisensor Tracking: Applications","authors":[],"date":"2002","doi":null,"raw":"X. R. Li, \u201cEngineer\u2019s guide to variable-structure multiplemodel estimation for tracking,\u201d in Multitarget-Multisensor Tracking: Applications and Advances, Y. Bar-Shalom and W. D. Blair, Eds., vol. 3, chapter 3, pp. 499\u2013567, Artech House, Norwood, Mass,USA, 2002.","cites":null},{"id":739759,"title":"Estimation and Tracking: Principles,Techniques and Software, Artech House,","authors":[],"date":"1993","doi":"10.1109\/map.1996.491294","raw":"Y. Bar-Shalom and X. R. Li, Estimation and Tracking: Principles,Techniques and Software, Artech House, Norwood, Mass, USA, 1993.","cites":null},{"id":740155,"title":"Expected likelihood for tracking in clutter with particle filters,\u201d","authors":[],"date":"2002","doi":"10.1117\/12.478507","raw":null,"cites":null},{"id":16397024,"title":"F o r s y t h ,O .A r i k a n ,L .I k e m o t o ,J .O \u2019 B r i e n ,a n dD . Ramanan, \u201cComputational studies of human motion: part 1, tracking and motion synthesis,\u201d Foundations and Trends","authors":[],"date":"2006","doi":"10.1561\/0600000005","raw":"D .A .F o r s y t h ,O .A r i k a n ,L .I k e m o t o ,J .O \u2019 B r i e n ,a n dD . Ramanan, \u201cComputational studies of human motion: part 1, tracking and motion synthesis,\u201d Foundations and Trends in Computer Graphics and Vision, vol. 1, no. 2-3, pp. 77\u2013254, 2006.","cites":null},{"id":745398,"title":"Fast mutual exclusion,\u201d","authors":[],"date":"2004","doi":"10.1117\/12.542068","raw":null,"cites":null},{"id":746196,"title":"Finding and tracking people from the bottom up,\u201d","authors":[],"date":"2003","doi":"10.1109\/cvpr.2003.1211504","raw":"D. Ramanan and D. A. Forsyth, \u201cFinding and tracking people from the bottom up,\u201d in Proceedings of the IEEE Computer SocietyConference on Computer Vision and Pattern Recognition (CCVPR \u201903), pp. 467\u2013474, June 2003.Photograph\u0231\u00a9\u0231Turisme\u0231de\u0231Barcelona\u0231\/\u0231J.\u0231Trull\u00e0s Preliminary\u0231call\u0231for\u0231papers The 2011 European Signal Processing Conference (EUSIPCO\u022c2011) is the nineteenth in a series of conferences promoted by the European Association for Signal Processing (EURASIP, www.eurasip.org). This year edition will take place in Barcelona, capital city of Catalonia (Spain), and will be jointly organized by the Centre Tecnol\u00f2gic de Telecomunicacions de Catalunya (CTTC) and the Universitat Polit\u00e8cnica de Catalunya (UPC). EUSIPCO\u022c2011 will focus on key aspects of signal processing theory and li ti li t d b l A t f b i i ill b b d lit Organizing\u0231Committee Honorary\u0231Chair Miguel\u0231A.\u0231Lagunas\u0231(CTTC) General\u0231Chair Ana\u0231I.\u0231P\u00e9rez\u022cNeira\u0231(UPC) General\u0231Vice\u022cChair Carles\u0231Ant\u00f3n\u022cHaro\u0231(CTTC) Technical\u0231Program\u0231Chair Xavier\u0231Mestre\u0231(CTTC) Technical Program Co\u022cChairs applications as listed below. Acceptance of submissions will be based on quality, relevance and originality. Accepted papers will be published in the EUSIPCO proceedings and presented during the conference. Paper submissions, proposals for tutorials and proposals for special sessions are invited in, but not limited to, the following areas of interest. Areas of Interest \u2022 Audio and electro\u022cacoustics. \u2022 Design, implementation, and applications of signal processing systems. l d l d d Technical\u0231Program\u0231Co Chairs Javier\u0231Hernando\u0231(UPC) Montserrat\u0231Pard\u00e0s\u0231(UPC) Plenary\u0231Talks Ferran\u0231Marqu\u00e9s\u0231(UPC) Yonina\u0231Eldar\u0231(Technion) Special\u0231Sessions Ignacio\u0231Santamar\u00eda\u0231(Unversidad\u0231 de\u0231Cantabria) Mats\u0231Bengtsson\u0231(KTH) Finances Montserrat N\u00e1jar (UPC) \u2022 Multimedia signal processing and coding. \u2022 Image and multidimensional signal processing. \u2022 Signal detection and estimation. \u2022 Sensor array and multi\u022cchannel signal processing. \u2022 Sensor fusion in networked systems. \u2022 Signal processing for communications. \u2022 Medical imaging and image analysis. \u2022 Non\u022cstationary, non\u022clinear and non\u022cGaussian signal processing. Submissions Montserrat\u0231N\u00e1jar\u0231(UPC) Tutorials Daniel\u0231P.\u0231Palomar\u0231 (Hong\u0231Kong\u0231UST) Beatrice\u0231Pesquet\u022cPopescu\u0231(ENST) Publicity\u0231 Stephan\u0231Pfletschinger\u0231(CTTC) M\u00f2nica\u0231Navarro\u0231(CTTC) Publications Antonio\u0231Pascual\u0231(UPC) Carles\u0231Fern\u00e1ndez\u0231(CTTC) I d i l Li i & E hibi Submissions Procedures to submit a paper and proposals for special sessions and tutorials will be detailed at www.eusipco2011.org. Submitted papers must be camera\u022cready, no more than 5 pages long, and conforming to the standard specified on the EUSIPCO 2011 web site. First authors who are registered students can participate in the best student paper competition. Important\u0231Deadlines: P l f i l i 15 D 2010 Industrial\u0231Liaison\u0231&\u0231Exhibits Angeliki\u0231Alexiou\u0231\u0231 (University\u0231of\u0231Piraeus) Albert\u0231Sitj\u00e0\u0231(CTTC) International\u0231Liaison Ju\u0231Liu\u0231(Shandong\u0231University\u022cChina) Jinhong\u0231Yuan\u0231(UNSW\u022cAustralia) Tamas\u0231Sziranyi\u0231(SZTAKI\u0231\u022cHungary) Rich\u0231Stern\u0231(CMU\u022cUSA) Ricardo\u0231L.\u0231de\u0231Queiroz\u0231\u0231(UNB\u022cBrazil) Webpage:\u0231www.eusipco2011.org Proposals\u0231for\u0231special\u0231sessions\u0231 15\u0231Dec\u02312010 Proposals\u0231for\u0231tutorials 18\u0231Feb 2011 Electronic\u0231submission\u0231of\u0231full\u0231papers 21\u0231Feb 2011 Notification\u0231of\u0231acceptance 23\u0231May 2011 Submission\u0231of\u0231camera\u022cready\u0231papers 6\u0231Jun 2011","cites":null},{"id":16397032,"title":"Granum, \u201cA survey of computer visionbased human motion capture,\u201d","authors":[],"date":"2001","doi":null,"raw":"T. B. MoeslundandE. Granum, \u201cA survey of computer visionbased human motion capture,\u201d Computer Vision and Image Understanding, vol. 81, no. 3, pp. 231\u2013268, 2001.","cites":null},{"id":738485,"title":"Human motion analysis: a review,\u201d","authors":[],"date":"1999","doi":"10.1109\/namw.1997.609859","raw":null,"cites":null},{"id":16397232,"title":"J.Hol,T.Sh\u00a8 on,andF.Gusta\ufb00sson,\u201cOnresamplingalgorithms for particle\ufb01lters,\u201d","authors":[],"date":"2006","doi":null,"raw":"J.Hol,T.Sh\u00a8 on,andF.Gusta\ufb00sson,\u201cOnresamplingalgorithms for particle\ufb01lters,\u201d in Proceedings of the Nonlinear Statistical Signal Processing Workshop,Cambridge, UK, September, 2006.","cites":null},{"id":16397153,"title":"L\u00b4 o p e z ,A .D .S a p p a ,a n dT .G r a f , \u201cSurvey of pedestrian detection for advanced driver assistance systems,\u201d","authors":[],"date":"2010","doi":null,"raw":"D. Ger\u00b4 onimo, A. M. L\u00b4 o p e z ,A .D .S a p p a ,a n dT .G r a f , \u201cSurvey of pedestrian detection for advanced driver assistance systems,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 32, no. 7, pp. 1239\u20131258, 2010.","cites":null},{"id":745914,"title":"Multiple objectstracking using particle \ufb01lters in video sequences,\u201d","authors":[],"date":"2006","doi":"10.1109\/aero.2006.1655926","raw":"M. H. Jaward, L. Mihaylova, N. Canagarajah, and D. Bull, \u201cMultiple objectstracking using particle \ufb01lters in video sequences,\u201d in Proceedings of the IEEE Aerospace Conference, Big Sky, Mont, USA, 2006.","cites":null},{"id":745707,"title":"Multisensor multitarget mixture reduction algorithms for tracking,\u201d","authors":[],"date":"1994","doi":"10.2514\/6.1993-3704","raw":"L. Y. Pao, \u201cMultisensor multitarget mixture reduction algorithms for tracking,\u201d Journal of Guidance, Control, and Dynamics, vol. 17, no. 6, pp. 1205\u20131211, 1994.","cites":null},{"id":744697,"title":"Multitarget-Multisensor Tracking: Applications and Advances,","authors":[],"date":"2000","doi":null,"raw":null,"cites":null},{"id":16397252,"title":"Multitarget-Multisensor Tracking: Applications and Advances,v o l .3 ,A r t e c hH o u s e ,","authors":[],"date":"2000","doi":null,"raw":"Y. Bar-Shalom and W. Dale Blair, Multitarget-Multisensor Tracking: Applications and Advances,v o l .3 ,A r t e c hH o u s e , Norwood, Mass,USA, 2000.","cites":null},{"id":16397035,"title":"n d r i l u k a ,S .R o t h ,a n dB .S c h i e l e ,\u201c P e o p l e - t r a c k i n g - b y -detection and people-detection-by-tracking,\u201d","authors":[],"date":"2008","doi":"10.1109\/cvpr.2008.4587583","raw":"M .A n d r i l u k a ,S .R o t h ,a n dB .S c h i e l e ,\u201c P e o p l e - t r a c k i n g - b y -detection and people-detection-by-tracking,\u201d in Proceedings of the 26th IEEE Conference on Computer Vision and Pattern Recognition (CVPR \u201908), June 2008.12 EURASIP Journal on Image and Video Processing","cites":null},{"id":741001,"title":"Object tracking: a survey,\u201d","authors":[],"date":"2006","doi":"10.1145\/1177352.1177355","raw":null,"cites":null},{"id":743300,"title":"On populationbased simulation for static inference,\u201d","authors":[],"date":"2007","doi":"10.1007\/s11222-007-9028-9","raw":"A. Jasra, D. A. Stephens, and C. C. Holmes, \u201cOn populationbased simulation for static inference,\u201d Statistics and Computing, vol. 17, no. 3, pp. 263\u2013279, 2007.","cites":null},{"id":743674,"title":"On resampling algorithms for particlefilters,\u201d","authors":[],"date":"2006","doi":null,"raw":null,"cites":null},{"id":16397205,"title":"Particle Filter for Tracking Applications,v o l .2 ,A r t e c h House,","authors":[],"date":"2004","doi":null,"raw":"B.Ristic,S.Arulampalam,andN.Gordon,BeyondtheKalman Filter: Particle Filter for Tracking Applications,v o l .2 ,A r t e c h House, Norwood, Mass,USA, 2004.","cites":null},{"id":16397145,"title":"ParticleFilter for Tracking Applications,A r t e c hH o u s e ,","authors":[],"date":"2004","doi":null,"raw":"B.Ristic,S.Arulampalam,andN.Gordon,BeyondtheKalman Filter: ParticleFilter for Tracking Applications,A r t e c hH o u s e , London,UK, 2004.","cites":null},{"id":741485,"title":"Pedestrian protection systems: issues, survey, and challenges,\u201d","authors":[],"date":"2007","doi":"10.1109\/tits.2007.903444","raw":null,"cites":null},{"id":16397198,"title":"Pedestrian protection systems: issues,survey, andchallenges,\u201d","authors":[],"date":"2007","doi":"10.1109\/tits.2007.903444","raw":"T. Gandhi and M. M. Trivedi, \u201cPedestrian protection systems: issues,survey, andchallenges,\u201d IEEE Transactions on Intelligent Transportation Systems, vol. 8, no. 3, pp. 413\u2013430, 2007.","cites":null},{"id":742566,"title":"People tracking with anonimous and ID-sensors using Rao-Blackwellised particle \ufb01lters,\u201d","authors":[],"date":"2003","doi":null,"raw":"D. Schultz, D. Fox, and J. Hightower, \u201cPeople tracking with anonimous and ID-sensors using Rao-Blackwellised particle \ufb01lters,\u201d in Proceedings of the International Conference on Arti\ufb01cial Intelligence (IJCAI \u201903), 2003.","cites":null},{"id":739209,"title":"People-tracking-bydetection and people-detection-by-tracking,\u201d","authors":[],"date":"2008","doi":"10.1109\/cvpr.2008.4587583","raw":null,"cites":null},{"id":739370,"title":"Pictorial structures for object recognition,\u201d","authors":[],"date":"2005","doi":null,"raw":"P. F. Felzenszwalband D. P. Huttenlocher, \u201cPictorial structures for object recognition,\u201d International Journal of Computer Vision, vol. 61, no. 1, pp. 55\u201379, 2005.","cites":null},{"id":742790,"title":"Population monte carlo,\u201d","authors":[],"date":"2004","doi":"10.1198\/106186004x12803","raw":"O. Capp\u00b4 e, A. Guillin, J. M. Marin, and C. P. Robert, \u201cPopulation monte carlo,\u201d Journal of Computational and Graphical Statistics, vol. 13, no. 4, pp. 907\u2013929, 2004.","cites":null},{"id":743072,"title":"Population-based monte carlo algorithms,\u201d","authors":[],"date":"2000","doi":null,"raw":null,"cites":null},{"id":16397221,"title":"Population-based monte carlo algorithms,\u201dJournal of","authors":[],"date":"2000","doi":null,"raw":"Y. Iba and S. Co\ufb00a, \u201cPopulation-based monte carlo algorithms,\u201dJournal of Computational and Graphical Statistics,v o l . 13, no. 4, pp. 157\u20131933, 2000.","cites":null},{"id":744142,"title":"Probabilistic data association techniques for target tracking in clutter,\u201d","authors":[],"date":"2004","doi":"10.1109\/jproc.2003.823149","raw":"T. Kirubarajan and Y. Bar-Shalom, \u201cProbabilistic data association techniques for target tracking in clutter,\u201d Proceedings of the IEEE, vol. 92, no. 3, pp. 536\u2013556, 2004.","cites":null},{"id":745193,"title":"Real-time tracking of hundreds of targets with e\ufb03cient exact JPDAF implementation,\u201d in","authors":[],"date":"2006","doi":"10.1109\/icif.2006.301561","raw":"P. Horridge and S. Maskell, \u201cReal-time tracking of hundreds of targets with e\ufb03cient exact JPDAF implementation,\u201d in Proceedings of International Conference on Information Fusion, 2006.","cites":null},{"id":740750,"title":"Survey of pedestrian detection for advanced driver assistance systems,\u201d","authors":[],"date":"2010","doi":"10.1109\/tpami.2009.122","raw":null,"cites":null},{"id":742366,"title":"The over-extended Kalman \ufb01lter\u2014 use it!,\u201d","authors":[],"date":"2003","doi":null,"raw":"D. Bizup and D. Brown, \u201cThe over-extended Kalman \ufb01lter\u2014 use it!,\u201d in Proceedings of the 6th International Conference on Information Fusion, pp. 40\u201346, ISIF, Queensland, Australia, 2003.","cites":null},{"id":742714,"title":"The unscented Kalman filter ,\u201d in Kalman Filtering and Neural Networks,","authors":[],"date":"2001","doi":"10.1002\/0471221546.ch7","raw":null,"cites":null},{"id":16397214,"title":"The unscented Kalman \ufb01lter ,\u201d in Kalman Filtering and Neural Networks,S .H a y k i n","authors":[],"date":"2001","doi":"10.1002\/0471221546.ch7","raw":"E. Wan and R. van der Merwe, \u201cThe unscented Kalman \ufb01lter ,\u201d in Kalman Filtering and Neural Networks,S .H a y k i n ,E d . , chapter 7, pp. 221\u2013280, John Wiley & Sons, New York, NY, USA, 2001.","cites":null},{"id":738808,"title":"The visual analysis of human movement: a survey,\u201d","authors":[],"date":"1999","doi":"10.1006\/cviu.1998.0716","raw":"D. M. Gavrila, \u201cThe visual analysis of human movement: a survey,\u201d Computer Vision and Image Understanding, vol. 73, no. 1, pp. 82\u201398, 1999.","cites":null},{"id":743994,"title":"Tracking and identi\ufb01cation forclosely spaced objects in clutter,\u201d","authors":[],"date":"1997","doi":"10.1049\/ic:19961350","raw":"D. Salmond, D. Fisher, and N. Gordon, \u201cTracking and identi\ufb01cation forclosely spaced objects in clutter,\u201d in Proceedings of the European Control Conference, IEEE, Brussels,Belgium, July 1997.","cites":null},{"id":741700,"title":"Tracking and motion estimation of the articulated object: a hierarchical Kalman \ufb01lter approach,\u201d","authors":[],"date":"1997","doi":"10.1006\/rtim.1997.0078","raw":"S. Jung and K. Wohn, \u201cTracking and motion estimation of the articulated object: a hierarchical Kalman \ufb01lter approach,\u201d Real-Time Imaging, vol. 3, no. 6, pp. 415\u2013432, 1997.","cites":null},{"id":739571,"title":"Tracking people by learning their appearance,\u201d","authors":[],"date":"2007","doi":"10.1109\/tpami.2007.250600","raw":"D. Ramanan, D. A. Forsyth, and A. Zisserman, \u201cTracking people by learning their appearance,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence,v o l .2 9 ,n o .1 ,p p . 65\u201381, 2007.","cites":null},{"id":744934,"title":"Two-dimensional assignment with merged measurements using Lagrangian relaxation,\u201d","authors":[],"date":"2003","doi":"10.1117\/12.503834","raw":"M. Briers, S. Maskell, and M. Philpott, \u201cTwo-dimensional assignment with merged measurements using Lagrangian relaxation,\u201d in Signal Processing of Small Targets, Proceedings of SPIE, pp. 283\u2013292, 2003.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-03-15","abstract":"This paper proposes an approach for tracking multiple articulated targets using a combined data association and evolving population particle filter. A visual target is represented as a pictorial structure using a collection of parts together with a model of their geometry. Tracking multiple targets in video involves an iterative alternating scheme of selecting valid measurements belonging to a target from a clutter or other measurements that all fall within a validation gate. An algorithm with extended likelihood probabilistic data association and evolving groups of populations of particles representing a multiple-part distribution is designed. Variety in the particles is introduced using constrained genetic operators both in the sampling and resampling steps. We explore the effect of various model parameters on system performance and show that the proposed model achieves better accuracy than other widely used methods on standard datasets","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/10940.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/39961\/1\/EURASIP_2011.pdf","pdfHashValue":"b517b858d3e10a142aa374366b1977d870148219","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:39961<\/identifier><datestamp>\n      2018-01-24T03:10:06Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      7375626A656374733D54:5441<\/setSpec><setSpec>\n      7375626A656374733D41:4149<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Combined data association and evolving particle filter for tracking of multiple articulated objects.<\/dc:title><dc:creator>\n        Bhaskar, Harish<\/dc:creator><dc:creator>\n        Mihaylova, Lyudmila<\/dc:creator><dc:subject>\n        AI Indexes (General)<\/dc:subject><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:subject>\n        TA Engineering (General). Civil engineering (General)<\/dc:subject><dc:description>\n        This paper proposes an approach for tracking multiple articulated targets using a combined data association and evolving population particle filter. A visual target is represented as a pictorial structure using a collection of parts together with a model of their geometry. Tracking multiple targets in video involves an iterative alternating scheme of selecting valid measurements belonging to a target from a clutter or other measurements that all fall within a validation gate. An algorithm with extended likelihood probabilistic data association and evolving groups of populations of particles representing a multiple-part distribution is designed. Variety in the particles is introduced using constrained genetic operators both in the sampling and resampling steps. We explore the effect of various model parameters on system performance and show that the proposed model achieves better accuracy than other widely used methods on standard datasets.<\/dc:description><dc:date>\n        2011-03-15<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/39961\/1\/EURASIP_2011.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1155\/2011\/642532<\/dc:relation><dc:identifier>\n        Bhaskar, Harish and Mihaylova, Lyudmila (2011) Combined data association and evolving particle filter for tracking of multiple articulated objects. EURASIP Journal on Image and Video Processing, 2011. pp. 1-12. ISSN 1687-5176<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/39961\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1155\/2011\/642532","http:\/\/eprints.lancs.ac.uk\/39961\/"],"year":2011,"topics":["AI Indexes (General)","QA75 Electronic computers. Computer science","TA Engineering (General). Civil engineering (General)"],"subject":["Journal Article","PeerReviewed"],"fullText":"Hindawi Publishing Corporation\nEURASIP Journal on Image and Video Processing\nVolume 2011, Article ID 642532, 12 pages\ndoi:10.1155\/2011\/642532\nResearch Article\nCombined Data Association and Evolving Particle Filter for\nTracking of Multiple Articulated Objects\nHarish Bhaskar1 and Lyudmila Mihaylova2\n1Department of Computer Engineering, Khalifa University of Science Technology and Research, Sharjah Campus, UAE\n2School of Computing and Communications, InfoLab21, Lancaster University, Lancaster LA1 4WA, UK\nCorrespondence should be addressed to Harish Bhaskar, harishbhasky@gmail.com\nReceived 1 May 2010; Revised 19 November 2010; Accepted 14 January 2011\nAcademic Editor: Andreas Uhl\nCopyright \u00a9 2011 H. Bhaskar and L. Mihaylova. This is an open access article distributed under the Creative Commons\nAttribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is\nproperly cited.\nThis paper proposes an approach for tracking multiple articulated targets using a combined data association and evolving\npopulation particle filter. A visual target is represented as a pictorial structure using a collection of parts together with a model\nof their geometry. Tracking multiple targets in video involves an iterative alternating scheme of selecting valid measurements\nbelonging to a target from a clutter or other measurements that all fall within a validation gate. An algorithm with extended\nlikelihood probabilistic data association and evolving groups of populations of particles representing a multiple-part distribution\nis designed. Variety in the particles is introduced using constrained genetic operators both in the sampling and resampling steps.\nWe explore the effect of various model parameters on system performance and show that the proposed model achieves better\naccuracy than other widely used methods on standard datasets.\n1. Introduction\nTracking articulated targets is a central problem in computer\nvision, with applications including robotics and surveillance.\nThe problem of multiple articulated target tracking (MATT)\ndeals with tracking a variable number of targets, each consist-\ning of the same number of different constituent body parts,\ngiven noisy measurements at every instant of time from\na dynamic scene, and simultaneously maintaining correct\ntarget identities irrespective of any visual perturbations [1\u2013\n4]. However, these tasks are complicated by the nonrigid\nvariation within the general class of objects that we wish to\ntrack (e.g., people, animals, etc.), appearance variations of\ntargets, and the presence of occlusions. Different methods\nhave been proposed in the literature to cope with these\nchallenges, for example, [2, 5\u20137]. The pictorial structure\napproach proposed in [6] is an appealing approach for\npeople modelling in view its simplicity and generality. A\ndifferent, limb-based structure model is developed in [5],\nparticularly suited for the detection and tracking of multiple\npeople in crowded scenes.\nThe problem of MATT can be divided into the subprob-\nlems of estimation and data association. A popular approach\nto solving this estimation problem is to build linearised\nfilters such as the extended Kalman filter (EKF) [8], under\na Gaussian noise assumption. Consequently, sufficient statis-\ntics from such linearised filters are used for data association.\nHowever, with nonlinear models in the state equation and\nnon-Gaussian noise assumption, such linearised models\noften lead to inaccurate solutions or even face divergence.\nThe sequential Monte Carlo (SMC) methods, such as the\nparticle filters (PFs) [9] have proven their potential for the\nestimation of nonlinear systems, with non-Gaussian noise\nassumption and multimodal distributions.\nIn this paper, we propose an approach combining evolv-\ning population particle filtering with extended likelihood\ndata association for MATT applications. To account for the\nuncertainty in the origin of the measurement, the extended\nlikelihood data association method [10] incorporates local\nattribute information of measurements weighted by prob-\nabilistic data association (PDA) for correctly identifying\nthe measurement from the target as against the clutter.\n2 EURASIP Journal on Image and Video Processing\nOn the other hand, the evolving population particle filter,\nprovides iterative convergence of groups of particles through\na specified kernel by introducing variety in the population\nusing constrained genetic operators in both the sampling and\nresampling steps.\nOne of the main novelties of the method is that it\nconveniently integrates data association into evolving popu-\nlation particle filtering, thus allowing particles to regenerate\nboth in sampling and resampling steps by simultaneously\ndisregarding particle measurement that account for clutter\nwithin a specified validation gate. Our results suggest that\nthe proposed integrated approach can considerably improve\nperformance when compared individually to a Markov chain\nMonte Carlo (MCMC) combined data association technique\nor a generic particle filter (non-MCMC filter). Second, the\ngeometrical constraints imposed by the picture structure\nrepresenting the target are intrinsically modeled into the\nparticle regeneration process through constrained genetic\noperations. Furthermore, some of the system parameters\n(such as the size of the validation gate) are learned from the\ndata rather than specified by hand.\nThe remaining part of the paper is organised in the fol-\nlowing way. Section 2 makes an overview of related works.\nSection 3 presents the proposed approach for multiple\narticulated object tracking. Results are given in Section 4.\nFinally, conclusions are summarised in Section 5.\n2. Related Work\nMATT is a highly challenging area of research within\ncomputer vision and tracking communities. The high degree\nof freedom of multiple articulated regions together with\nthe interdependencies between them and with other targets\nrequires efficient techniques able to cope effectively with the\ndynamic changes of the objects. In general, motion tracking\nof articulated objects in video consists of two distinct steps:\ndetection and tracking. During the detection process, we aim\nto segment the human objects and their constituent body\nparts from the frames of the video sequences. In tracking,\nwe are spatially locating these detected regions in time. A\nnumber of techniques have been proposed for the detection\nand tracking phases [2, 11\u201313]. In our paper, we assume\na standard procedure applied for the detection step and\npropose a novel tracking methodology.\nTracking in recent years is often considered as a dynamic\nsystem estimation problem [14]. A number of different\ntechniques have been proposed [15] in the past to estimate\nthe variables of such dynamic systems. Some of the impor-\ntant methods include the Kalman filter [16], and unscented\nKalman filter [17]. These methods assume that the posterior\nprobability density of the system model is Gaussian. This\nassumption is more often restrictive and does not always suit\ndifferent applications. In order to cope with the nonlinearity,\nextended techniques such as unscented Kalman filter [18],\nextended Kalman filter [19], approximation grid filter, and\nparticle filters [17, 20] have been recommended. A particle\nfilter approximates the posterior state probability density\nusing a set of particles and propagating these particles over\ntime with appropriate weighting coefficients often produces\nefficient tracking. Particle filters are robust to nonlinear, non-\nGaussian systems with multi-modal distributions. However,\neven with a large population of particles, there may be no\nor little number of particles near the actual correct state.\nThe second main drawback of particle filter methods is\ndegeneracy. The problem of degeneracy refers to some par-\nticles having negligible weight as against the weight being\nconcentrated on few others. Resampling techniques are\nemployed to tackle degeneracy issues but sometimes when\napplied improperly can lead to sample impoverishment [21].\nPopulation-based methods [22\u201324] are techniques that\ngenerate a collection of samples in parallel as against single\nindependent or dependent samples. We can conveniently\ncategorize these population-based methods into (a) MCMC\ntype of methods and (b) methods based on importance\nsampling and resampling ideas. While MCMC methods are\ndirected by theoretical convergence based on iterations, sam-\npling\/resampling techniques rely on processing a number of\nsamples in parallel and sequential Monte. The population\nMCMC methods apply population moves that exchange var-\niables between population members in order to generate the\nnew target density. An example of a population move is the\nexchange move that swaps information between chains in a\npopulation. Similar types of moves are realised in the genetic\nalgorithms, with the crossover, mutation, and exchange steps.\nIn contrast, the sequential Monte Carlo methods [25] were\nconstructed to sample from a sequence of related target\ndistributions, using resampling techniques on the samples\nfrom previous target density. Commonly used resampling\ntechniques include multinomial resampling [26], residual\nresampling technique [25], and stratified resampling [25].\nOne of the other main issues of MATT applications is the\npresence of multiple parts of the body and multiple targets\nthat share similar feature characteristics, thus leading to\nuncertainty in the origin of measurements. Data association\n(DA) methods [27, 28] are used for correctly identifying the\nmeasurement that originated from the target from clutter\nof other multiple noisy measurements. It is assumed that\nthe clutter is a model of false detections whose statistical\nproperties are significantly different from those of the targets.\nData association is of crucial importance to our problem\nbecause of the requirement to relate each measurement to\nthe correct body part of the correct object of interest. There\nhas been extensive studies in data association [10, 27, 29\u201336].\nMost methods are restricted by assumptions on the number\nof targets, statistical properties of observations, and number\nof possible measurements.\nIn order to tackle the problemofMATT, it is important to\ncombine estimation techniques and data association so that\nrobust tracking is possible.\n3. The Combined Data Association with\nEvolving Population Particle Filter for\nMultiple Articulated Object Tracking\nIn our proposed technique, we formulate MATT as an\nestimation problem combined with data association. Let us\nEURASIP Journal on Image and Video Processing 3\nbegin by denoting the total number of targets in our scene\nto be \u0000. We represent each target \u03c4 as a pictorial structure\nusing a collection of n parts as in [6]. The objective of the\nproposed technique is to estimate the state vector xk,\u03c4 of\neach target \u03c4 at time instant k by recursively updating the\nposterior distribution of each target p(xk,\u03c4 | Zk) based on\na set Zk = {z1, z2, . . . , zk} of measurements at time k. The\nmovement of each target is described by a general nonlinear\nstate space model and estimated using the prediction step:\np\n(\nxk,\u03c4 | Zk\u22121\n) =\n\u222b\np\n(\nxk,\u03c4 | xk\u22121,\u03c4\n)\np\n(\nxk\u22121,\u03c4Zk\u22121\n)\ndxk\u22121,\u03c4 ,\n(1)\nand update\/filtering step\np\n(\nxk,\u03c4 | Zk\n) =\n\u222b\np\n(\nzk | xk,\u03c4\n)\np\n(\nxk,\u03c4 | Zk\u22121\n)\ndxk,\u03c4 , (2)\nwhere, p(xk,\u03c4 | xk\u22121,\u03c4) is the dynamic model of state evolu-\ntion and p(zk | xk,\u03c4) is the likelihood of any measurement zk\ngiven the state xk,\u03c4 .\nThe proposed technique is meant to track multiple\ntargets by taking into consideration the geometrical con-\nstraints of the various parts which represents the target\nbefore evaluating the marginal distribution. An evolving\npopulation Markov chain Monte Carlo (EPMCMC) filter\nis developed that encapsulates constrained evolution of the\npopulations using specific genetic operators and robust\nassociation of measurements to targets incorporating local\nattribute information using the expected likelihood data\nassociation method [10]. The developed approach can be\nsummarised as follows:\n(1) initialisation: using pictorial structure type models as\nin [7], we localise all the \u0000 targets along with the\nconfiguration of their n parts,\n(2) for iterations 1, . . . ,T,\n(a) evolve particles using constrained genetic oper-\nators as in EPMCMC filter,\n(b) the expected likelihood data association pro-\nvides an efficient solution for data association\nof each object into the particle weights of the\nEPMCMC filter.\nIn the following sections, we describe the two steps in\ndetail before outlining how they are integrated within the\nproposed framework.\n3.1. EPMCMC Filter. The EPMCMC filter algorithm pro-\nceeds in three distinct steps. The first step involves initialising\nthe populations of particles from their respective proposal\ndistributions. Let x(i)k,\u03c4 , i = 1, . . . ,N represent the population\nof particles for target \u03c4 (each particle is a configuration vector\ncontaining the position and speed of the n body parts for the\ntarget) at time instant k. So, during initialisation: x(i)k=1,\u03c4 =\n\u0393k=1,\u03c4 , where \u0393k=1,\u03c4 is the distribution of particles around the\ninitial localisation of different body parts of target \u03c4. During\ninitialisation, we also evaluate the initial weights of particles\nw(i)k=1,\u03c4(x\n(i)\nk,\u03c4) and normalise the weights to get W\n(i)\nk=1,\u03c4 .\nThe EPMCMC filter iterates between the resampling\nand sampling steps. The resampling step is usually per-\nformed only when the effective sample size (ESS) is less\nthan a predefined threshold Nthreshold and is measured as\n(\n\u2211N\ni=1 (W\n(i)\nk,\u03c4)\n2\n)\n\u22121\n. During the resampling step, we perform\nlocal evolution of particles; that is, particles from the same\npopulation belonging to the same part of the target are\ncombined iteratively using steps of crossover, mutation,\nor exchange. This approach introduces variety in particles\nby regenerating a unique and good population. Here, we\nalso recalculate weights of particles in each population\nusing a relevant likelihood metric and normalise them. An\nillustration of the genetic moves involved in the EPMCMC\nfilter is presented in Figure 1.\nIn the sampling step, we perform global evolution of\nparticles, that is, iteratively evolving particles from different\npopulations belonging to different parts of the target using\nthe steps of crossover, mutation, or exchange. However, the\nmain difference from local evolution of particles is that\nin the global evolution we enforce geometrical constraints\ninto the evolution, process. These geometrical constraints\nare derived from the pictorial structure model of the target\nand are based on the neighbourhood structure of every part\nof the target. When subjecting the particles to evolution\nusing genetic operators, we allow particles of one part to\nbe influenced by only the particles of its neighbours. For\nexample, when performing the crossover operation, between\ntwo particles xs,\u03c4 and xq,\u03c4 , we crossover chromosomes only\nbased on the neighbourhood relationships that parts share\nwith each other. That is, we restrict crossovers between the\narms of one particle to the legs of the other and encourage\ncrossovers between arms of one part together with the torso\nof the other, as these are neighbouring regions of the elastic\npictorial structure model.\nIn addition, we evaluate the likelihood of each particle\nbased on how well the image data supports the proposed\nhypothesized candidate parts. We map this support as the\nweighted summation of two subsequent terms: the first one\nindicates the goodness of fit of the part with the image data,\nand the second one measures the goodness of fit of pairs of\ncandidate parts as connected in the pictorial structure model.\nThe proposed EPMCMC filter is given in Algorithm 1,\nthe population MCMC move is presented in Algorithm 2,\nand the details for each step of the genetic algorithm\n(crossover, mutation, and exchange) are given in the next\nsubsection.\n3.1.1. Resample Moves. In the resample move step, equally\nweighted particles are chosen, and population MCMC is\napplied. We summarise the population MCMC algorithm as\nshown in Algorithm 2.\n3.1.2. Crossver. In the proposed framework, the state vector\nis represented as a string of bits. The crossover point lc is a\nrandom point on the string of bits of length l. The crossover\noperator cannot be applied to all parts of the state vector.\n4 EURASIP Journal on Image and Video Processing\nEE\nX X\nM\ni = 1, . . . ,N = 10 particles\nFigure 1: Illustration of the EP MCMC filter.\n(1) Initialisation: at k = 1 generate initial samples x(i)k,\u03c4 and their respective weights W (i)k,\u03c4 = 1\/N .\n(2) Sampling\n(i) For k = 2, . . . .\n(ii) For each sample i = 1, . . . ,N .\nDraw x(i)k,\u03c4 \u223c qk , where x(i)k,\u03c4 is the ith sample at kth time instant and qk is a known transition prior at time\ninstant k.\n(iii) Move the populations of samples by x(i)k,\u03c4 \u223c Gk(x(i)k\u22121,\u03c4), using the genetic transition kernel Gk(\u00b7) according to\ncrossover, mutation or exchange steps as described below.\n(iv) Evaluate weights w(i)k,\u03c4 (x\n(i)\nk,\u03c4 ) from the likelihood as presented in the next subsection and normalise the weights\nto obtain W (i)k,\u03c4 = w(i)k,\u03c4 \/\n\u2211N\ni=1 w\n(i)\nk,\u03c4 .\n(3) Resampling\n(i) If ESS \u2264 Nthr1 , where the ESS is measured as (\n\u2211N\ni=1(W\n(i)\nk,\u03c4)\n2)\u22121 and Nthr1 is some threshold.\n(a) For t iterations\n(a1) Resample using one of the standard resampling techniques such as residual resampling.\n(a2) Perform population MCMC based moves to samples as mentioned in Section 3.1.1.\n(a3) Recompute the weights w(i)k,\u03c4 (x\n(i)\nk,\u03c4 ) and normalise the weights to obtainW\n(i)\nk,\u03c4 .\n(b) End\n(ii) Increment the time instant k = k + 1.\n(iii) Iterate steps (2). and (3).\nAlgorithm 1: The proposed evolving population Markov chain Monte Carlo filter.\n(1) Initialisation\n(i) Select i\u2217 resampled particles from each population x(i\n\u2217)\nk,\u03c4 , where i\n\u2217 = 1, . . . ,N .\n(2) Iterate steps (2) and (3).\n(3) (a) Mutation\nPerform Mutation as illustrated in Section 3.1.3.\n(b) CrossOver or Exchange Move Perform CrossOver or Exchange moves as illustrated in Section 3.1.2\nor Section 3.1.4, respectively. Accept the move based on the Metropolis-Hastings rule, for example,\nfrom the probability min{1,A} as described in Section 3.1.4.\nAlgorithm 2: PopulationMCMC moves.\nEURASIP Journal on Image and Video Processing 5\nSome parts of the state vector may not undergo any changes,\nand thus for such components, the probability of crossover\n\u03c1c is zero. This leaves the crossover being operated only on\ncomponents that are expected to undergo random changes.\nThe crossover operator functions on two distinguished\noffsprings (paired particles), for example, xs,\u03c4 , xq,\u03c4 . The\nalgorithm for crossover is described below:\n(i) draw a uniform random number uc for every com-\nponent uc \u2248 U(0, 1), and if uc \u2264 \u03c1c, then perform\ncrossover,\n(ii) estimate a crossover point lc based on a uniform\nrandom integer between 1 and the length of the\ncomponent l,\n(iii) generate two offsprings\nxs,\u03c4 =\n(\nx1s, x2s, . . . , x(lc\u22121)s, xlcq, . . . , xdq\n)\n,\nxq,\u03c4 =\n(\nx1q, x2q, . . . , x(lc\u22121)q, xlc s, . . . , xds\n)\n,\n(3)\nwhere ds and dq refers to the length of the samples xs,\u03c4 and\nxq,\u03c4 , respectively.\nFor simplicity in the remaining derivation, we will omit\nthe index \u03c4. For crossover, the proposal distribution q(\u00b7)\ncan be expressed as a product of the proposals for the two\noffsprings\nq\n(\nxk | xs,k\u22121, xq,k\u22121\n)\n\u223c p(xs,k\u22121 | zk\u22121\n)\np\n(\nxq,k\u22121 | zk\u22121\n)\n.\n(4)\nThen, in the crossover operation, performed with the two\noffsprings xs,k and xq,k , the particle weight can be expressed\nin the form\nwcr,(i)k\n=\np\n(\nzk | x(i)s,k\n)\np\n(\nzk | x(i)q,k\n)\np\n(\nx(i)s,k | x(i)s,k\u22121\n)\np\n(\nx(i)q,k | x(i)q,k\u22121\n)\nq\n(\nx(i)s,k\u22121 | zk\u22121\n)\nq\n(\nx(i)q,k\u22121 | zk\u22121\n) .\n(5)\nThen, the recursive weights can be written as\nwcr,(i)k = wcr,(i)s,k\u22121wcr,(i)q,k\u22121Ls\n(\nzk, x\n(i)\ns,k\n)\nLq\n(\nzk, x\n(i)\nq,k\n)\n. (6)\nHere, L(i)s (zk, x\n(i)\ns,k) = p(zk | x(i)s,k) is the likelihood\nfunction for the sth offspring, L(i)q (zk, x\n(i)\nq,k) = p(zk|x(i)q,k) is\nthe likelihood function of the qth offspring and wcr,(i)s,k\u22121 and\nwcr,(i)q,k\u22121 are the weights at (k \u2212 1)th time instant, for the sth\nand qth offspring, respectively.\nHence, in the case of the crossover, where there are paired\nparticles with the same weight, we marginalise one of them\nand express the weights as a function of the proposal PDF of\nthe other PDF.\n3.1.3. Mutation. A probability of mutation \u03c1m is initially\ndefined for each component. Such a probability is chosen in\norder to make sure that components that need no stochastic\nfluctuations could be prohibited from undergoing mutation\noperation. For such components, the probability of mutation\n\u03c1m is considered zero. The components are assumed as a\nvector string of binary units. According to the proposed\nmutation mechanism,\n(i) draw a uniform random number um for every\ncomponent um \u2248 U(0, 1), and if um \u2264 \u03c1m, then\nperform mutation,\n(ii) estimate a mutation point lm based on a uniform ran-\ndom integer between 1 and length of the component\nl,\n(iii) flip the mutation point lm.\nThe weights are of the form\nwmutation,(i)k =\np\n(\nx(i)k | x(i)k\u22121\n)\nUq\n(\nx(i)k | x(i)k\u22121\n) , (7)\nwhere, U is a uniform random number. During mutation,\nsamples that undergo mutation are mutually independent.\nTherefore, the updated proposal distribution at time k is a\nfactor of the proposal distribution at the previous iteration\nk \u2212 1.\n3.1.4. Exchange. Consider two independent chains of sam-\nples, for example, xs,k and xq,k . For their target distributions\n\u03c0s and \u03c0q, respectively, the swap of information between\nthese two chains can be performed with a Metropolis-\nHastings step. The swap occurs with probability min{1,A},\nwhere\nA =\n\u03c0s\n(\nxq,k\n)\n\u03c0q\n(\nxs,k\n)\n\u03c0s\n(\nxs,k\n)\n\u03c0q\n(\nxq,k\n) . (8)\nThe genetic transition kernel combines the effectiveness\nof samples between various populations to create more\nefficient groups of samples.\n3.2. Expected Likelihood Probabilistic Data Association\n(ELPDA). Since the state vector xk,\u03c4 = {xk,\u03c4,\u03b7}n\u03b7=1 for target\n\u03c4 consists of the states for all body parts \u03b7 = 1, . . . ,n, a data\nassociation problem needs to be resolved. In our work, we\nadopt the expected likelihood data association method from\n[10]. For the set of available measurements, we assume that\none of the measurements originates from the target, and the\nrest are due to spurious clutter. In the case of tracking the\npictorial structure of the human target, colour histograms\nare used for matching and the corresponding measurement\nequation is highly nonlinear. The data association problem\nis considered with respect to the whole pictorial structure\n(the whole graph) representing the target, for example, with\nrespect to xk,\u03c4 .\nWe adapt the weights of particles w\u02dc(i)k,\u03c4(x\n(i)\nk\u22121:k) in the move\nstep of the EPMCMC filter specified in Section 3.1.\nLet mk denote the number of available measurements at\ntime step k. The measurements at time step k are denoted as\n6 EURASIP Journal on Image and Video Processing\nzk = {z jk}, where j = 0, . . . ,mk . If \u03b8 denotes any association\nevent, then \u03b8\nj\nk is a particular association event that assigns\nthe jth measurement to target \u03c4. According to [10], the\nconditional probability density function p(\u03b8\nj\nk | Zk) of the\nassociation event \u03b8\nj\nk that the jth measurement within the\nvalidation gate is the measurement that originated from the\ntarget is given by\np\n(\n\u03b8\nj\nk | Zk\n)\n= p\n(\n\u03b8\nj\nk | zk,mk ,Zk\u22121\n)\n, (9)\nfor the set of mk measurements zk that fall within the\nvalidation gate. We expand the conditional probability from\nabove using the Bayesian rule to get\np\n(\n\u03b8\nj\nk | zk,mk ,Zk\u22121\n)\n\u221d p\n(\nzk | \u03b8 jk,mk ,Zk\u22121\n)\n\u00d7 p\n(\n\u03b8\nj\nk | mk,Zk\u22121\n)\n.\n(10)\nIf the incorrect measurements have a uniform probability\ndensity function within the gating volume V\u03c4 , and with the\nassumption of a normal measurement error for a correct\nmeasurement, we can rewrite\np\n(\nzk | \u03b8 jk,mk ,Zk\u22121\n)\n=\n\u23a7\n\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a8\n\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a9\nV\u03c4\n\u2212(mk\u22121)P\u22121G N\n(\nz\nj\nk; 0; Sk\n)\n,\n\u2200 j = 1, . . . ,mk ,\nV\u2212mk\u03c4 ,\n\u2200 j = 0,\n(11)\nwhere PG is the probability of gating, Sk is the covariance\nmatrix of the innovation vector z\nj\nk. Finally, it has been shown\n[10] that the probability p(\u03b8\nj\nk | zk,mk ,Zk) of association\nevents can be computed as\np\n(\n\u03b8\nj\nk | mk,Zk\n)\n=\n\u23a7\n\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a8\n\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a9\n1\nC\n\u00d7 P(\u22121)G\n\u00d7 (PDPG)\u03bcF(mk \u2212 1)\nmkPDPG\u03bcF(mk \u2212 1) + (1\u2212 PDPG)\u03bcF(mk)\n\u00d7V\u2212(mk\u22121)\u03c4 \u00d7N (zk; 0; Sk),\n\u2200 j = 1, . . . ,mk ,\n(1\u2212 PDPG)\u03bcF(mk)\nPDPG\u03bcF(mk \u2212 1) + (1\u2212 PDPG)\u03bcF(mk) ,\n\u2200 j = 0,\n(12)\nwhere PD is the detection probability, \u03bcF is the probability\nmass function of the number of incorrect measurements,\nPDPG refers to the probability that a target is detected\nand its measurements fall within the gate, and Rk is the\nmeasurement error covariance matrix.\nFinally, we approximate the weights of the particles based\non the computed expected likelihood using\nw\u02dc(i)k,\u03c4 \u221d w\u02dc(i)k\u22121,\u03c4 \u00d7\np\n(\n\u03b80k | mk , zk\u22121\n)\nV\u2212(mk)\u03c4\nq\n(\nx(i)k,\u03c4 | x(i)k\u22121,\u03c4 , zk\n)\n+\n\u2211mk\nj=1 p\n(\n\u03b8\nj\nk | mk, zk\u22121\n)\nV\u2212(mk\u22121)\u03c4 P\u22121G\nq\n(\nx(i)k,\u03c4 | x(i)k\u22121,\u03c4 , zk\n)\n\u00d7\nN\n(\nzk, z\nj\nk,Rk\n)\np\n(\nx(i)k | x(i)k\u22121,\u03c4\n)\nq\n(\nx(i)k,\u03c4 | x(i)k\u22121,\u03c4 , zk\n) ,\n(13)\nwhere i = 1, . . . ,N .\n4. Results\nIn this section, we perform systematic experiments evaluat-\ning (1) the accuracy of our proposed EPMCMC + ELPDA\nmethod with the EPMCMC + PDA algorithm and with a\ngeneric particle filter framework with a joint probabilistic\ndata association (JPDA PF) proposed in [37, 38] and (2) the\ninfluence of the system parameters on the model including\nthe geometric constraints, number of parts being tracked,\nthe radius of the validation gate. We demonstrate our results\non videos containing human targets, where the pictorial\nstructure of the target is modeled as a graphical model of\nthe parts of the body. The transition prior is assumed to\nbe a constant velocity model [8] applied jointly with the\npictorial structure for each target. The pictorial structure is\nrepresented as rectangles for each body part, and the state\nvector consists of the position and speed for the centre of\neach body part. To evaluate the performance of the models,\nwe compute the root mean square error distance (RMSE)\nbetween the estimated center point of every part and its\nmanually labeled counterpart. The results are presented in\nthe form of a cumulative RMSE for all the targets in the\nvideo.\n4.1. Multiple People Tracking. To track multiple people\n(together with their multiple body parts) in video, we use\nthe CAVIAR [39] data set sequences. The CAVIAR dataset\ncontains over 80 video sequences with one or more targets\nmoving in real-time scenarios. We have chosen 11 videos\nfrom the data set at varying levels of complexity in terms\nof the motion characteristics, occlusion, and clutter (due\nto illumination changes). We have further divided the 11\nselected sequences in 17 short clips with varying number\nof targets. Table 1 elaborates on the chosen sequences and\nthe clips that have been extracted from these sequences\nalong with the details of the frames, number of targets, the\nlevel of occlusion, and the presence of clutter. The tracked\npeople have been manually annotated in these clips using\na maximum 10-point model consisting of the centers of\nthe head (1 point), torso (1 point), arms (2 points for\neach arm), and legs (2 points for each leg). We would like\nto particular highlight that the frames are of resolution\nEURASIP Journal on Image and Video Processing 7\n(a) Proposed model (EPMCMC + ELPDA)\n(b) Baseline model (EPMCMC + PDA)\n(c) Non-MCMC baseline model (JPDA PF)\nFigure 2: Sample video frames of the tracked body torso of two targets (trajectories presented in Figure 3).\n384 \u00d7 288 captured at 25 frames per second. The scales of\nthe human targets are fairly small in comparison with the\nresolution of the image, and thus in some of the images,\na 10-point model gives a dense set of labeled ground-truth\nwhich is unusable; therefore, in such sequences, we use a 6-\npoint model. We use the method of [7, 40] to initialise the\nmultiple body parts composed multiple targets in first frame\nof each video using the pictorial structure model. For all our\nexperiment described below unless mentioned otherwise, the\nnumber of Monte Carlo cycles is fixed to 100, the number\nof particles used is 500, and the size of the validation gate is\n15. All our experiments are conducted on an Intel Duo Core\nprocessor with 3GB RAM.\n4.2. Comparison of Proposed with Related Techniques. One\nof the main novelties of the proposed EPMCMC + ELPDA\nmethod is its integration of expected likelihood into the\nweights of EPMCMC. The following experiments compares\nthe accuracy of the proposed algorithm with the combined\nEPMCMC and PDA filter. We present the trajectories of two\ntargets tracked by both techniques in Figure 3 and sample\nimage frames from the corresponding tracked torso of the\ntwo targets in Figure 2. We also present some sample image\nframes of tracked torso\u2019s of multiple targets (four targets)\nfrom a different video sequence in Figure 4. The combined\nRMSE curves (in Figures 5 and 6) indicates that our\ntechnique has better accuracy than the baseline method. The\nmean combined RMSE values recorded for increasing Monte\nCarlo cycles are 2.5369 and 4.2667 for target 1 and 3.2547 and\n4.3737 for target 2 using the proposed and baseline strategies,\nrespectively. In terms of the computational demand, our\nalgorithm takes 3419msec on an average per image frame\nas against the combined EPMCMC and PDA methods that\ntake 2169msec (implemented in MATLAB). This is mainly\ndue to the computation of the expected likelihood of all\nmeasurements that fall within the validation gate. We have\nalso found that the cumulative error in the localisation of\nthe target reduces by approximately 39% for an increased 1.2\nseconds in the processing time. We presume that the tradeoff\nbetween the time taken for processing as against the accuracy\nof our technique acceptably good. A detailed analysis of the\ncomputation time per image frame across various different\nvideo clips is summarised in Table 1.\n8 EURASIP Journal on Image and Video Processing\n0\n50\n100\n150\n200\n250\n50\n100\n150\n200\n250\n300\n0 50\n100\n150 200\nTarget 1\nTarget 2\nTrajectory of 2 moving targets\n(sequence from CAVIAR dataset)\nFrame\nnumb\ner\nx-coordinates\ny-\nco\nor\ndi\nn\nat\nes\n(a) Proposed method (EPMCMC + ELPDA) output\n0\n50\n100\n150\n200\n250\n50\n100\n150\n200\n250\n300\n0 50\n100\n150 200\nTarget 1\nTarget 2\nTrajectory of 2 moving targets\n(sequence from CAVIAR dataset)\nFrame\nnumb\ner\nx-coordinates\ny-\nco\nor\ndi\nn\nat\nes\n(b) Baseline method (EPMCMC + PDA) output\n0\n20\n40\n60\n80\n100\n120\n140\n160\n180\n200\nTrajectory of 2 moving targets\n(sequence from CAVIAR dataset)\n250\n50\n100\n150\n200\n250\n300\n0\n50\n100\n150\n200\nFrame\nnumb\ner\nTarget 1\nTarget 2\nx-coordinates\ny-\nco\nor\ndi\nn\nat\nes\n(c) Non-MCMC baseline method (JPDA PF) output\nFigure 3: Trajectory of multiple targets (a) using proposed method (red\/blue), (b) using baseline method (magenta\/black) and (c) using\nNon-MCMC baseline method (green\/blue), the JPDA PF proposed in [37, 38].\n(a) (b) (c)\nFigure 4: Sample video frames of the tracked torso of multiple targets.\n4.3. Effect of Changing System Parameters. We study the\neffect of different changing system parameters and compare\nthem between the proposed EPMCMC + ELPDA and the\nEPMCMC + PDA model. We do not compare our results\nto the generic particle filter framework, as these parameters\nare particularly relevant to the parts-based models. First, we\nexamine the effect of increasing the number of targets being\ntracked on the performance of the models. Figure 7 suggests\nthat increasing the number of targets from 1 to 2 decreases\nthe accuracy of the proposed EPMCMC+ELPDAmodel, but\nincreasing the targets beyond this does not significantly alter\nits accuracy.\nSecondly, we investigate the effect of increasing the\nnumber of parts of each target that is used for tracking. In\nthe lower levels of the model, we have a smaller collection\nof more salient parts representing the target followed by\nEURASIP Journal on Image and Video Processing 9\nTable 1: Tabular description of the chosen video clips (B2-Browse2, BWW1-BrowseWhileWhalking1, FC-Fight Chase, FR1-FightRunway1,\nLB-LeftBag, LBx-LeftBox, MC-MeetCrowd, MWS-MeetWalkSplit, MWT1-MeetWalkTogether1, RFF-RestFallenFloor, WBS1-Walk and\nByShop1) and comparison of combined RMSE between EPMCMC + ELPDA model (Proposed), EPMCMC + PDA model (Baseline) and\nRMSE of Torso alone in generic particle filter framework (JPDA PF).\nVideo Frames Targets Occlude Clutter Proposed Baseline JPDAPF Time\nB2\n173 1 No 0 1.1821 2.0413 0.9648 3187\n198 1 Self 0 1.6669 2.3425 1.1578 3276\nBWW1 361 1 Self 1 2.1638 2.6804 1.5673 3106\nFC\n129 1 No 0 0.5187 0.9835 0.2784 3016\n178 2 Yes 0 2.7861 4.0076 3.1279 3127\nFR1 199 2 Yes 0 2.7883 3.9801 1.4531 3229\nLB\n201 3 Self 0 3.4412 7.6359 5.8763 3663\n401 3 Partial 1 3.6567 8.0015 5.1455 3841\n208 1 No 0 1.4009 2.2156 1.0151 2923\n146 1 Self 0 1.9768 3.8970 2.1412 3312\nLBx\n373 2 Partial 0 2.8990 5.7682 4.2349 3401\n370 1 Yes 1 2.5238 3.3532 2.0451 3198\nMC 282 4 Partial 0 3.8982 6.4235 6.7347 3789\nMWS 301 2 Partial 1 2.0679 4.2176 3.9567 3128\nMWT1 323 2 Partial 0 2.5003 3.9134 2.2734 3215\nRFF 388 1 Self 0 2.3027 4.5231 1.7235 3309\nWBS1 876 5 Yes 0 3.5694 9.2722 7.0163 4789\n0 10 20 30 40 50 60 70 80 90 100\n1\n2\n3\n4\n5\n6\n7\n8\nC\nom\nbi\nn\ned\nR\nM\nSE\nComparing proposed technique with baseline\nEPMCMC + PDA\nEPMCMC + ELPDA\nMonte Carlo cycles\nFigure 5: Combined RMSE versus the number of Monte Carlo\ncycles for target 1.\nincreasing number of lesser important parts. In the following\nexperiment, we examine the impact of increasing the number\nof parts representing the target by comparing the model with\nlevel one (1 part: torso), level two (2 parts: head and torso),\nlevel three (6 parts: head, torso, two hands, and two legs),\nand level four (10 parts-head, torso, four for hands, and four\nfor legs). The plot in Figure 8 suggests that increasing the\nrepresentation of the target (using a larger subset of parts)\nincreases accuracy.\nIn Figure 9, we present the results showing the effect of\nincreasing the size of the validation gate against the accuracy\n0 10 20 30 40 50 60 70 80 90 100\n1\n2\n3\n4\n5\n6\n7\n8\nC\nom\nbi\nn\ned\nR\nM\nSE\nComparing proposed technique with baseline\nEPMCMC + PDA\nEPMCMC + ELPDA\nMonte Carlo cycles\nFigure 6: Combined RMSE versus the number of Monte Carlo\ncycles for target 2.\nof EPMCMC + ELPDA technique. The cumulative RMSE\ncurves demonstrating the effect of increasing the size of\nthe validation gate indicate that with increase gate size,\naccuracy increases, but beyond this, it does not improve the\nperformance further.\nFinally, in Figure 10, we demonstrate the effect of\ngeometric constraints being enforced in the measurement of\nthe likelihood against the accuracy of EPMCMC + ELPDA\ntechnique. The cumulative RMSE curves prove beyond\ndoubt that with appropriate geometrical constraints on the\npictorial structure model accuracy increases.\n10 EURASIP Journal on Image and Video Processing\n1 1.5 2 2.5 3 3.5 4 4.5 5\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nNumber of targets being tracked\nC\nu\nm\nu\nla\nti\nve\nR\nM\nSE\nEffect of increasing number of targets on performance\nEPMCMC + PDA\nEPMCMC + ELPDA\nFigure 7: Cumulative RMSE versus the number of targets in the\nVideo.\n1 2 3 4 5 6 7 8 9 10\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\nNumber of parts of each target being tracked\nC\nu\nm\nu\nla\nti\nve\nR\nM\nSE\nEffect of increasing the number of parts of targets on performance\nEPMCMC + PDA\nEPMCMC + ELPDA\nFigure 8: Cumulative RMSE versus the number of parts represent-\ning the target.\n4.4. Failure Modes. In this subsection, we highlight some\nof common failure modes of the proposed framework. We\nattribute the missed detections of our proposed framework\nto three main conditions. First, when the object(s) of\ninterest are subject to a high degree of self occlusion due\nto articulation of body parts, our framework fails to match\nthe pictorial structure well to the image data and subse-\nquently fail during tracking. The illustrations in Figure 11(a)\nshow a scenario from our test set, where tracking multi-\nple body parts accurately was highly difficult due to the\naforementioned conditions. In such test sequences, we have\nresorted to models containing lower number of distinguish-\nable body parts. In Figure 11(b), we highlight the second\nmode of failures that are mainly caused due to rapid\nchanges in illumination conditions. Finally, we also describe\n2 4 6 8 10 12 14 16 18 20\n0\n1\n2\n3\n4\n5\n6\n7\n8\nSize of validation gate\nC\nu\nm\nu\nla\nti\nve\nR\nM\nSE\nEffect of increasing the validation gate size\non performance\nEPMCMC + ELPDA\nEPMCMC + PDA\nFigure 9: Cumulative RMSE versus the size of the validation gate.\nWith geometry\nWithout geometry\n1 2 3 4 5 6 7 8 9 10\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\n4.5\n5\nVideo sequence number\nA\nve\nra\nge\nco\nm\nbi\nn\ned\nR\nM\nSE\ner\nro\nr\nEffect of geometric constraints on performance\nFigure 10: Effect of geometric constraints on combined RMSE for\ndifferent video sequences (yellow without constraints\/brown with\nconstraints).\nconditions such as the image acquisition perspective and\nscale of the object(s) of interest as other causes for missed\ndetections in Figure 11(c).\n5. Conclusion\nWe have proposed an innovative method for combining\nextended likelihood data association with evolving popu-\nlation particle filtering for robust and accurate multiple\ntarget tracking. The evolving population filter introduces\nvariety in the population of particles by combining them\nin both the sampling and resampling steps using con-\nstrained genetic operations. The extended likelihood data\nassociation filters those measurements that belong to the\ntarget from a clutter of other noisy measurements anal-\nysed within the validation gate. System parameters such\nEURASIP Journal on Image and Video Processing 11\n(a) Complex occlusion of body parts of a single target\n(b) Object navigating in areas with rapid illumination changes\n(c) Changing the image acquisition perspective and small object scale\nFigure 11: Failure modes of the proposed EPMCMC + ELPDA model: (a) complex occlusion example; (b) rapid change in illumination\nconditions; (c) image acquisition perspectives.\nthe radius of validation gate are reestimated during each\niteration, rather than fixed empirically, resulting in a model\nthat outperforms similar recent methods on standard data-\nsets.\nAcknowledgments\nThe authors acknowledge the support of UK MOD Data\nand Information Fusion Defence Technology Centre under\nthe Tracking Cluster Project no. DIFDTC\/CSIPC1\/02. The\nauthors would also like to sincerely thank Professor Simon\nGodsill for his useful advices and discussions on sequen-\ntial population Monte Carlo methods. They acknowledge\nthe support from the (European Community\u2019s) Seventh\nFramework Programme (FP7\/2007\u20132013) under Grant no.\n238710 (Monte Carlo-based Innovative Management and\nProcessing for an Unrivalled Leap in Sensor Exploita-\ntion).\nReferences\n[1] J. K. Aggarwal and Q. Cai, \u201cHumanmotion analysis: a review,\u201d\nComputer Vision and Image Understanding, vol. 73, no. 3, pp.\n428\u2013440, 1999.\n[2] D. A. Forsyth, O. Arikan, L. Ikemoto, J. O\u2019Brien, and D.\nRamanan, \u201cComputational studies of human motion: part 1,\ntracking and motion synthesis,\u201d Foundations and Trends in\nComputer Graphics and Vision, vol. 1, no. 2-3, pp. 77\u2013254,\n2006.\n[3] D. M. Gavrila, \u201cThe visual analysis of human movement: a\nsurvey,\u201d Computer Vision and Image Understanding, vol. 73,\nno. 1, pp. 82\u201398, 1999.\n[4] T. B. Moeslund and E. Granum, \u201cA survey of computer vision-\nbased human motion capture,\u201d Computer Vision and Image\nUnderstanding, vol. 81, no. 3, pp. 231\u2013268, 2001.\n[5] M. Andriluka, S. Roth, and B. Schiele, \u201cPeople-tracking-by-\ndetection and people-detection-by-tracking,\u201d in Proceedings\nof the 26th IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR \u201908), June 2008.\n12 EURASIP Journal on Image and Video Processing\n[6] P. F. Felzenszwalb and D. P. Huttenlocher, \u201cPictorial structures\nfor object recognition,\u201d International Journal of Computer\nVision, vol. 61, no. 1, pp. 55\u201379, 2005.\n[7] D. Ramanan, D. A. Forsyth, and A. Zisserman, \u201cTracking\npeople by learning their appearance,\u201d IEEE Transactions on\nPattern Analysis and Machine Intelligence, vol. 29, no. 1, pp.\n65\u201381, 2007.\n[8] Y. Bar-Shalom and X. R. Li, Estimation and Tracking: Princi-\nples,Techniques and Software, Artech House, Norwood, Mass,\nUSA, 1993.\n[9] B. Ristic, S. Arulampalam, and N. Gordon, Beyond the Kalman\nFilter: ParticleFilter for Tracking Applications, Artech House,\nLondon, UK, 2004.\n[10] A. Marrs, S. Maskell, and Y. Bar-Shalom, \u201cExpected likelihood\nfor tracking in clutter with particle filters,\u201d in Signal and data\nProcessing of Small Targets, vol. 4728 of Proceedings of SPIE, pp.\n230\u2013239, April 2002.\n[11] R. Cucchiara, C. Grana, M. Piccardi, and A. Prati, \u201cDetecting\nmoving objects, ghosts, and shadows in video streams,\u201d IEEE\nTransactions on Pattern Analysis and Machine Intelligence, vol.\n25, no. 10, pp. 1337\u20131342, 2003.\n[12] D. Gero\u00b4nimo, A. M. Lo\u00b4pez, A. D. Sappa, and T. Graf,\n\u201cSurvey of pedestrian detection for advanced driver assistance\nsystems,\u201d IEEE Transactions on Pattern Analysis and Machine\nIntelligence, vol. 32, no. 7, pp. 1239\u20131258, 2010.\n[13] A. Yilmaz, O. Javed, and M. Shah, \u201cObject tracking: a survey,\u201d\nACM Computing Surveys, vol. 38, no. 4, 2006.\n[14] S. Zhou, R. Chellappa, and B. Moghaddam, \u201cAdaptive visual\ntracking and recognition using particle filters,\u201d in Proceedings\nof the IEEE International Conference on Multimedia & Expo\n(ICME \u201903), pp. 560\u2013566, July 2003.\n[15] T. Gandhi and M. M. Trivedi, \u201cPedestrian protection systems:\nissues, survey, and challenges,\u201d IEEE Transactions on Intelligent\nTransportation Systems, vol. 8, no. 3, pp. 413\u2013430, 2007.\n[16] S. Jung and K. Wohn, \u201cTracking and motion estimation of\nthe articulated object: a hierarchical Kalman filter approach,\u201d\nReal-Time Imaging, vol. 3, no. 6, pp. 415\u2013432, 1997.\n[17] B. Ristic, S. Arulampalam, and N. Gordon, Beyond the Kalman\nFilter: Particle Filter for Tracking Applications, vol. 2, Artech\nHouse, Norwood, Mass, USA, 2004.\n[18] M. Briers, S. Maskell, and R. Wright, \u201cA Rao-Blackwellised\nunscented Kalman filter,\u201d in Proceedings of the 6th International\nConference on Information Fusion, pp. 55\u201361, ISIF, Queens-\nland, Australia, 2003.\n[19] D. Bizup and D. Brown, \u201cThe over-extended Kalman filter\u2014\nuse it!,\u201d in Proceedings of the 6th International Conference on\nInformation Fusion, pp. 40\u201346, ISIF, Queensland, Australia,\n2003.\n[20] D. Schultz, D. Fox, and J. Hightower, \u201cPeople tracking with\nanonimous and ID-sensors using Rao-Blackwellised particle\nfilters,\u201d in Proceedings of the International Conference on\nArtificial Intelligence (IJCAI \u201903), 2003.\n[21] E. Wan and R. van der Merwe, \u201cThe unscented Kalman filter\n,\u201d in Kalman Filtering and Neural Networks, S. Haykin, Ed.,\nchapter 7, pp. 221\u2013280, John Wiley & Sons, New York, NY,\nUSA, 2001.\n[22] O. Cappe\u00b4, A. Guillin, J. M. Marin, and C. P. Robert, \u201cPopu-\nlation monte carlo,\u201d Journal of Computational and Graphical\nStatistics, vol. 13, no. 4, pp. 907\u2013929, 2004.\n[23] Y. Iba and S. Coffa, \u201cPopulation-based monte carlo algo-\nrithms,\u201d Journal of Computational and Graphical Statistics, vol.\n13, no. 4, pp. 157\u20131933, 2000.\n[24] A. Jasra, D. A. Stephens, and C. C. Holmes, \u201cOn population-\nbased simulation for static inference,\u201d Statistics and Comput-\ning, vol. 17, no. 3, pp. 263\u2013279, 2007.\n[25] O. Cappe, R. Douc, and E. Moulines, \u201cComparison of\nresampling schemes for particle filtering,\u201d in Proceedings of\nthe 4th International Symposiumon Image and Signal Processing\nand Analysis (ISPA \u201905), Croatia, 2005.\n[26] J. Hol, T. Sho\u00a8n, and F. Gustaffsson, \u201cOn resampling algorithms\nfor particlefilters,\u201d in Proceedings of the Nonlinear Statistical\nSignal Processing Workshop, Cambridge, UK, September, 2006.\n[27] S. Blackman and R. Popoli, Design and Analysis of Modern\nTracking Systems, Artech House Radar Library, 1999.\n[28] D. Salmond, D. Fisher, and N. Gordon, \u201cTracking and identi-\nfication forclosely spaced objects in clutter,\u201d in Proceedings of\nthe European Control Conference, IEEE, Brussels, Belgium, July\n1997.\n[29] T. Kirubarajan and Y. Bar-Shalom, \u201cProbabilistic data associ-\nation techniques for target tracking in clutter,\u201d Proceedings of\nthe IEEE, vol. 92, no. 3, pp. 536\u2013556, 2004.\n[30] X. R. Li, \u201cEngineer\u2019s guide to variable-structure multiple-\nmodel estimation for tracking,\u201d in Multitarget-Multisensor\nTracking: Applications and Advances, Y. Bar-Shalom and W.\nD. Blair, Eds., vol. 3, chapter 3, pp. 499\u2013567, Artech House,\nNorwood, Mass, USA, 2002.\n[31] S. Maskell, M. Rollason, N. Gordon, and D. Salmond,\n\u201cEfficient particle filtering for multiple target tracking with\napplication to tracking in structured images,\u201d Image and Vision\nComputing, vol. 21, no. 10, pp. 931\u2013939, 2003.\n[32] Y. Bar-Shalom and W. Dale Blair, Multitarget-Multisensor\nTracking: Applications and Advances, vol. 3, Artech House,\nNorwood, Mass, USA, 2000.\n[33] M. Briers, S. Maskell, and M. Philpott, \u201cTwo-dimensional\nassignment with merged measurements using Lagrangian\nrelaxation,\u201d in Signal Processing of Small Targets, Proceedings\nof SPIE, pp. 283\u2013292, 2003.\n[34] P. Horridge and S. Maskell, \u201cReal-time tracking of hundreds\nof targets with efficient exact JPDAF implementation,\u201d in\nProceedings of International Conference on Information Fusion,\n2006.\n[35] S. Maskell, M. Briers, and R. Wright, \u201cFast mutual exclusion,\u201d\nin Signal Processing of Small Targets, Proceedings of SPIE, 2004.\n[36] L. Y. Pao, \u201cMultisensor multitarget mixture reduction algo-\nrithms for tracking,\u201d Journal of Guidance, Control, and\nDynamics, vol. 17, no. 6, pp. 1205\u20131211, 1994.\n[37] M. H. Jaward, L. Mihaylova, N. Canagarajah, and D. Bull,\n\u201cA data association algorithm for multiple object tracking\nin video sequences,\u201d in Proceedings of the IEE Seminar on\nTarget Tracking: Algorithms and Applications, pp. 131\u2013136,\nBirmingham, UK, 2006.\n[38] M. H. Jaward, L. Mihaylova, N. Canagarajah, and D.\nBull, \u201cMultiple objectstracking using particle filters in video\nsequences,\u201d in Proceedings of the IEEE Aerospace Conference,\nBig Sky, Mont, USA, 2006.\n[39] CAVIAR test case scenarios, 2005,http:\/\/homepages.inf.ed.ac\n.uk\/rbf\/.\n[40] D. Ramanan and D. A. Forsyth, \u201cFinding and tracking people\nfrom the bottom up,\u201d in Proceedings of the IEEE Computer\nSociety Conference on Computer Vision and Pattern Recognition\n(CCVPR \u201903), pp. 467\u2013474, June 2003.\nPhotograph\u0231\u00a9\u0231Turisme\u0231de\u0231Barcelona\u0231\/\u0231J.\u0231Trull\u00e0s\nPreliminary\u0231call\u0231for\u0231papers\nThe 2011 European Signal Processing Conference (EUSIPCO\u022c2011) is the\nnineteenth in a series of conferences promoted by the European Association for\nSignal Processing (EURASIP, www.eurasip.org). This year edition will take place\nin Barcelona, capital city of Catalonia (Spain), and will be jointly organized by the\nCentre Tecnol\u00f2gic de Telecomunicacions de Catalunya (CTTC) and the\nUniversitat Polit\u00e8cnica de Catalunya (UPC).\nEUSIPCO\u022c2011 will focus on key aspects of signal processing theory and\nli ti li t d b l A t f b i i ill b b d lit\nOrganizing\u0231Committee\nHonorary\u0231Chair\nMiguel\u0231A.\u0231Lagunas\u0231(CTTC)\nGeneral\u0231Chair\nAna\u0231I.\u0231P\u00e9rez\u022cNeira\u0231(UPC)\nGeneral\u0231Vice\u022cChair\nCarles\u0231Ant\u00f3n\u022cHaro\u0231(CTTC)\nTechnical\u0231Program\u0231Chair\nXavier\u0231Mestre\u0231(CTTC)\nTechnical Program Co\u022cChairsapp ca ons as s e e ow. ccep ance o su m ss ons w e ase on qua y,\nrelevance and originality. Accepted papers will be published in the EUSIPCO\nproceedings and presented during the conference. Paper submissions, proposals\nfor tutorials and proposals for special sessions are invited in, but not limited to,\nthe following areas of interest.\nAreas of Interest\n\u2022 Audio and electro\u022cacoustics.\n\u2022 Design, implementation, and applications of signal processing systems.\nl d l d d\n\u0231 \u0231\nJavier\u0231Hernando\u0231(UPC)\nMontserrat\u0231Pard\u00e0s\u0231(UPC)\nPlenary\u0231Talks\nFerran\u0231Marqu\u00e9s\u0231(UPC)\nYonina\u0231Eldar\u0231(Technion)\nSpecial\u0231Sessions\nIgnacio\u0231Santamar\u00eda\u0231(Unversidad\u0231\nde\u0231Cantabria)\nMats\u0231Bengtsson\u0231(KTH)\nFinances\nMontserrat N\u00e1jar (UPC)\u2022 Mu time ia signa processing an co ing.\n\u2022 Image and multidimensional signal processing.\n\u2022 Signal detection and estimation.\n\u2022 Sensor array and multi\u022cchannel signal processing.\n\u2022 Sensor fusion in networked systems.\n\u2022 Signal processing for communications.\n\u2022 Medical imaging and image analysis.\n\u2022 Non\u022cstationary, non\u022clinear and non\u022cGaussian signal processing.\nSubmissions\n\u0231 \u0231\nTutorials\nDaniel\u0231P.\u0231Palomar\u0231\n(Hong\u0231Kong\u0231UST)\nBeatrice\u0231Pesquet\u022cPopescu\u0231(ENST)\nPublicity\u0231\nStephan\u0231Pfletschinger\u0231(CTTC)\nM\u00f2nica\u0231Navarro\u0231(CTTC)\nPublications\nAntonio\u0231Pascual\u0231(UPC)\nCarles\u0231Fern\u00e1ndez\u0231(CTTC)\nI d i l Li i & E hibi\nProcedures to submit a paper and proposals for special sessions and tutorials will\nbe detailed at www.eusipco2011.org. Submitted papers must be camera\u022cready, no\nmore than 5 pages long, and conforming to the standard specified on the\nEUSIPCO 2011 web site. First authors who are registered students can participate\nin the best student paper competition.\nImportant\u0231Deadlines:\nP l f i l i 15 D 2010\nn ustr a \u0231 a son\u0231 \u0231 x ts\nAngeliki\u0231Alexiou\u0231\u0231\n(University\u0231of\u0231Piraeus)\nAlbert\u0231Sitj\u00e0\u0231(CTTC)\nInternational\u0231Liaison\nJu\u0231Liu\u0231(Shandong\u0231University\u022cChina)\nJinhong\u0231Yuan\u0231(UNSW\u022cAustralia)\nTamas\u0231Sziranyi\u0231(SZTAKI\u0231\u022cHungary)\nRich\u0231Stern\u0231(CMU\u022cUSA)\nRicardo\u0231L.\u0231de\u0231Queiroz\u0231\u0231(UNB\u022cBrazil)\nWebpage:\u0231www.eusipco2011.org\nroposa s\u0231 or\u0231spec a \u0231sess ons\u0231 \u0231 ec\u0231\nProposals\u0231for\u0231tutorials 18\u0231Feb 2011\nElectronic\u0231submission\u0231of\u0231full\u0231papers 21\u0231Feb 2011\nNotification\u0231of\u0231acceptance 23\u0231May 2011\nSubmission\u0231of\u0231camera\u022cready\u0231papers 6\u0231Jun 2011\n"}
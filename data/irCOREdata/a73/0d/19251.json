{"doi":"10.1145\/1349822.1349834","coreId":"19251","oai":"oai:eprints.bham.ac.uk:234","identifiers":["oai:eprints.bham.ac.uk:234","10.1145\/1349822.1349834"],"title":"Crossmodal content binding in information-processing architectures","authors":["Jacobsson, Henrik"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2008","abstract":null,"downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.bham.ac.uk:234<\/identifier><datestamp>\n      2011-10-12T11:03:16Z<\/datestamp><setSpec>\n      74797065733D636F6E666572656E63655F6974656D<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Crossmodal content binding in information-processing architectures<\/dc:title><dc:creator>\n        Jacobsson, Henrik<\/dc:creator><dc:date>\n        2008<\/dc:date><dc:type>\n        Conference or Workshop Item<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.bham.ac.uk\/234\/1\/hawes.pdf<\/dc:identifier><dc:relation>\n        public<\/dc:relation><dc:relation>\n        http:\/\/eprints.bham.ac.uk\/234\/1.hassmallThumbnailVersion\/hawes.pdf<\/dc:relation><dc:relation>\n        http:\/\/dx.doi.org\/10.1145\/1349822.1349834<\/dc:relation><dc:identifier>\n        Jacobsson, Henrik (2008) Crossmodal content binding in information-processing architectures. In: UNSPECIFIED.<\/dc:identifier><dc:relation>\n        http:\/\/eprints.bham.ac.uk\/234\/<\/dc:relation><dc:language>\n        English<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["public","http:\/\/eprints.bham.ac.uk\/234\/1.hassmallThumbnailVersion\/hawes.pdf","http:\/\/dx.doi.org\/10.1145\/1349822.1349834","http:\/\/eprints.bham.ac.uk\/234\/"],"year":2008,"topics":[],"subject":["Conference or Workshop Item","NonPeerReviewed"],"fullText":"Crossmodal Content Binding in Information-Processing\nArchitectures\nHenrik Jacobsson\nLanguage Technology Lab,\nDFKI GmbH, Germany\nhenrikj@dfki.de\nNick Hawes\nSchool of Computer Science,\nUniversity of Birmingham, UK\nn.a.hawes@cs.bham.ac.uk\nGeert-Jan Kruijff\nLanguage Technology Lab,\nDFKI GmbH, Germany\ngj@dfki.de\nJeremy Wyatt\nSchool of Computer Science,\nUniversity of Birmingham, UK\nj.l.wyatt@cs.bham.ac.uk\nABSTRACT\nOperating in a physical context, an intelligent robot faces\ntwo fundamental problems. First, it needs to combine in-\nformation from its different sensors to form a representa-\ntion of the environment that is more complete than any\nrepresentation a single sensor could provide. Second, it\nneeds to combine high-level representations (such as those\nfor planning and dialogue) with sensory information, to en-\nsure that the interpretations of these symbolic representa-\ntions are grounded in the situated context. Previous ap-\nproaches to this problem have used techniques such as (low-\nlevel) information fusion, ontological reasoning, and (high-\nlevel) concept learning. This paper presents a framework in\nwhich these, and related approaches, can be used to form\na shared representation of the current state of the robot in\nrelation to its environment and other agents. Preliminary re-\nsults from an implemented system are presented to illustrate\nhow the framework supports behaviours commonly required\nof an intelligent robot.\nCategories and Subject Descriptors\nI.2.9 [Artificial Intelligence]: Robotics\nGeneral Terms\nAlgorithms, Design\n1. INTRODUCTION\nAn information-processing architecture for an intelligent\nrobot is typically composed of a large number of cooperating\nsubsystems, such as natural language analysis and produc-\ntion, vision, motoric skills, and various deliberative processes\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for profit or commercial advantage and that copies\nbear this notice and the full citation on the first page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior specific\npermission and\/or a fee.\nHRI\u201908, March 12\u201315, 2008, Amsterdam, The Netherlands.\nCopyright 2008 ACM 978-1-60558-017-3\/08\/03 ...$5.00.\nsuch as action planning. The challenge addressed in this pa-\nper is the production and maintenance of a model of the\nworld for a robot situated in \u201ceveryday\u201d scenarios involv-\ning human interaction. This requires a method for binding\ntogether representations provided by a robot\u2019s subsystems.\nIn this paper we will focus on a scenario involving a robot\nwhich is able to interact with a human and a set of objects on\na tabletop. For example, when faced with a scene containing\na red mug, a blue mug and a blue bowl, the robot may be\nasked to \u201cput the blue things to the left of the red thing\u201d.\nFor a system to be able to perform such a task, it must be\nable to build a representation that connects the (low-level\nand modality specific) information about the world with the\n(high-level and amodal) representations that can be used to\ninterpret the utterance, determine the desired world state,\nand plan behaviour. As actions derived from these processes\nmust be executed in the world, the representations must\nallow the robot to ultimately access the low-level (i.e. metric)\ninformation from which its higher-level representations are\nderived.\nAny design for a system to tackle the above task must ad-\ndress the creation of such representations, and the processes\nby which they are grounded in the robot\u2019s environment. In\naddition to this, the engineering effort of integrating the var-\nious subsystems of the robot with the representations must\nbe considered. After all, since the robot is an engineered\nsystem, every component must be put there by means of\nhuman effort.\nIn general, grounding be seen as the process of establishing\na relation between representations in two different domains.\nA special case is when one of the domains is the external\nworld, i.e. \u201creality\u201d:\nThe term grounding [denotes] the processes by\nwhich an agent relates beliefs to external physical\nobjects. Agents use grounding processes to con-\nstruct models of, predict, and react to, their ex-\nternal environment. Language grounding refers\nto processes specialised for relating words and\nspeech acts to a language user\u2019s environment via\ngrounded beliefs. [12] (p. 8)\nIn this paper we will not assume that any component of\nour system necessarily deals with reality. However, we will\n81\nassume that our robot\u2019s sensory subsystems may represent\nthings that more or less coincide with aspects of reality rel-\nevant to its current task. We also do not consider ground-\ning of only linguistic symbols, nor to physical objects alone,\nand we do not assume that all representations must relate\nto physical entities.\nIn the remainder of this paper we present a design for\na subsystem of an information-processing architecture that\nis able to bind together representations from other subsys-\ntems into a single representation shared by the entire sys-\ntem. This binding system, henceforth the binder, tackles the\nproblem of creating high-level shared representations that\nrelate back to low-level subsystem-specific representations,\nas well as addressing the engineering issue of non-intrusively\nintegrating such representations in an implemented system.\nThe following section will discuss related approaches to\nsimilar problems, and identify requirements imposed by the\ntask of creating a situated representation of the world. Fol-\nlowing this, the information-processing architecture upon\nwhich the binder operates is presented, then the binder is\nthen described in detail. This description is followed by ex-\namples of the binder\u2019s application in our implemented robot\nsystem, and a discussion about its properties in relation to\nthe our stated requirements.\n2. BACKGROUND AND MOTIVATION\nRather than attempt to address the complete spectrum of\nproblems related to building and grounding representations,\nwe will restrict the problem by addressing the requirements\nfor a situated representation of the current and future state\nable to support deliberative processes for a specific set of\nscenarios. These restrictions allow us to focus on partic-\nular properties of representations that are appropriate for\nour task domains, i.e. human-robot interaction linked to\nobject manipulation [5] and human augmented mapping of\nan office environment [19]. In these domains, we are inter-\nested in binding together content from separate information-\nprocessing subsystems to provide symbols that can be used\nfor deliberation and then action. By deliberation we mean\nprocesses that explicitly represent and reason about hypo-\nthetical world states, such as a possible interpretation of an\nutterance or a possible course of action (cf. the deliberative\nlayer of the CogAff schema [15]).\nWe can specify a number of requirements for deliberative\nand situated symbols. First, these symbols must be stable\nfor the duration of the deliberative processes they are in-\nvolved in. For example, a representation of an object from\nvision should remain stable across multiple image frames if\nthat object is to be involved in a planning process. Second,\nthese symbols must be represented at a level of abstraction\nappropriate for the processing they will be involved in. For\nexample, objects on a tabletop could be represented in a\nmetric coordinate frame or as abstracted symbols. Each of\nthese representations would be appropriate for reasoning at\na particular level of detail. The requirements of stability\nand appropriate level of detail are closely linked; the level of\ndetail of a particular representation influences its temporal\nstability. These requirements have been directly informed by\nthe requirements for representations for planning and acting\nin dynamic, uncertain worlds [18].\nFurthermore, since these symbols must be produced by\nbinding content across different concurrently active information-\nprocessing subsystems, it is unlikely that the binding of con-\ntent can happen in a synchronous manner. Perceptual sub-\nsystems are typically event driven, and to keep a representa-\ntion of the state as current as possible, it is important that\nperceptual information is processed as soon as it is gener-\nated. This is importent, for example, in the account of in-\ncremental parsing of natural language given in [2]. In this\napproach the search for possible parses of an utterance is\npruned using the context of the current scene. Therefore\nit is important that any representation of the current state\ncan be incrementally and asynchronously extended as soon\nas new information is available (i.e. anytime).\nPrevious robotic systems which are able to bind informa-\ntion from one subsystem to another typically limit this kind\nof binding to linking linguistic references to objects created\nfrom vision. The first system that might even have con-\nceivably encountered the problem was the Shakey system\n[9]. This translated a constrained set of English language\nsentences into first order predicate calculus goal statements.\nReference here was either non-specific (i.e. \u201cmove any box\u201d),\nor non-ambiguous (each referent that needed to be specifi-\ncally identified was given a unique name, e.g. \u201cdoor D\u201d). In\nmaking bindings of referents in the goal statement to the\nobjects in the world the non-specific referents allowed lazy\nbinding, so that binding was executed using a unification\nmechanism at plan execution time. This late binding was\nonly made feasible by the assumption of perceptual relia-\nbility, and by the other restrictions given above. However,\nlater systems mostly follow Shakey in their choice of a par-\nsimonious internal language that is a direct mapping onto\nthe qualities of objects that we express relatively straight-\nforwardly in language, and which are naturally stable.\nCurrent approaches, while following this choice of features\non which to bind, attempt to bind referents from vision with\nlanguage using a mixture of deterministic and probabilistic\nrepresentations, and employing varying levels of abstraction.\nFor example. Mavridis and Roy [8] have a single amodal\nworld model, but one which contains linked deterministic\ncontinuous, stochastic qualitative, and stochastic continu-\nous representations. They refer to these as being part of\nwhat they call a grounded situation model. In this case the\nlinking is thus essentially not between pairs of properties in\nvision and language, but between all pairs properties of the\nsame type (colour, position) using a probability distribution\nover the bindings between. It is, at the time of writing, not\nyet fully implemented in a robot, and as specified makes no\nattempt to deal with asynchronous changes to representa-\ntions in different parts of the system. In other systems [13,\n2] binding can occur at a very early stage in processing, al-\nlowing even information from the speech signal to influence\nvisual hypotheses for object references, and vice-versa.\nEngel and Pfleger [3] approach the problem by gathering\nall necessary data first, then generating a binding with the\nhighest possible quality. For perceptual priming this ap-\nproach may not be very fruitful. However, we would argue\nthat it would be a grave mistake to discard earlier work on\nsymbol grounding. If, for example, the systems of [12, 16,\n3, 7, 4], could be utilised in one and the same system, we\nwould truly be able to take a step forward as a community.\nTherefore non-intrusiveness is an important requirement on\nour binding system [10]. In other words, it is important to\nmake it straightforward to integrate existing systems into\nour binding approach. This requirement also holds for inte-\ngrating our approach with existing robotic subsystems. This\n82\nis in part a requirement on the interfaces to a binding sys-\ntem, they must be kept simple and generic.\nTo summarise, the main requirements we have on our\nbinder are:\n\u2022 The symbols produced should be stable,\n\u2022 they should have the appropriate level of abstraction\n(i.e. amodal and modal),\n\u2022 they must be generated in an asynchronous, incremen-\ntal, anytime manner,\n\u2022 their production must be non-intrusive with respect to\nexisting systems.\n3. THE ARCHITECTURE\nTo demonstrate our approach to binding in practise, we\nhave built a robotic system to perform tasks in our tabletop\nHRI domain. The system has been presented in previous\nwork (e.g. [5]), so we will only give a brief overview here.\nThe design of the system is based on the CoSy Architec-\nture Schema (CAS), a set of rules for designing architecture\ninstantiations in a principled manner. The schema allows\na collection of interconnected subarchitectures (SAs), each\ncontaining a collection of processing components that can\nbe connected to sensors and effectors. Each subarchitecture\nalso contains a working memory (WM), which the compo-\nnents use to share information. Only components within\na subarchitecture can write to the subarchitecture work-\ning memory, but all components can read from any work-\ning memory. We also allow for privileged components that\ncan write to any working memory (thus supporting cross-\narchitecture control mechanisms). The schema is enforced\nin our code using the CoSy Architecture Schema Toolkit\n(CAST), an open-source, multi-language implementation of\nCAS [6].\nIn our implementation we have subarchitectures for vision,\ncommunication, manipulation, planning, spatial reasoning,\ncoordination and binding. Together they create a system\nthat can learn and describe object properties in dialogue\nwith a tutor, and also carry out manipulation commands\nthat feature object descriptions based on the learnt visual\nproperties. Each subarchitecture working memory contains\nspecialised representations of the information processed by\nthe attached components. For example, the visual work-\ning memory contains regions of interest generated by a seg-\nmentor and proto-objects generated by interpreting these\nregions; the communication subarchitecture contains logical\nforms generated from parsing utterances; and the spatial\nreasoning subarchitecture contains abstractions of physical\nobjects and qualitative spatial relationships between them.\n4. THE BINDER\n4.1 Overview\nThe CAS-based architecture provides an ideal test case\nfor the development of a situated representation. Each sub-\narchitecture working memory contains specialised represen-\ntations, and a subset of these could in principle contribute\ntowards a general representation of the current state. In\nbrief, our approach to tackling this problem has two parts:\nmapping from specific to general representations, and the\nfusion of general representations. To enable specialised rep-\nresentations to contribute to the representation of the cur-\nrent state, each subarchitecture must provide a process that\nRepresentation\nSubarchitecture Internal Data\nBinding Unions\nBinding Proxies\nBinding Features\nShared\nState\nFigure 1: An illustration of how the binder medi-\nates low-level and modality specific features from\nthe SAs to form a common amodal representation of\nthe world. The SAs are only involved in generation\nof features and proxies. Everything else is handled\nby the binder processes. SAs may take into account\n(or ignore) the common representation formed by\nthe set of unified proxies. Conceptually, the top of\nthe pyramid contains less, more abstract, informa-\ntion than the base. The top level of the pyramid\nrests solidly on this base, since the features are al-\nways referred to from the unified abstracted data.\ntranslates its specialised representations into more general\nones (a process of abstraction). We refer to this process as\nthe subarchitecture\u2019s binding monitor. The binding monitor\nprovides the abstracted items of information to a separate\nbinding subarchitecture (i.e. the binder) as binding proxies.\nA proxy is essentially a bundle of subarchitecture-specific\n(modal) information about, e.g., an object, a relationship, a\ncollection of objects etc. The main constituent of a proxy is\na set of attribute-value pairs, called features (such as colour,\nontological category, connections to other proxies etc.). The\nbinder attempts to bind proxies together based on whether\ntheir defining features agree on a common description. The\nstructures that result from binding proxies are called unions,\nas they essentially contain the union of the features of the\nbound proxies. The set of unions represents the current best\nsystem wide hypothesis of the current state. This is based\non the assumption that the underlying proxies and features\nare also the best hypotheses from the corresponding subar-\nchitectures.\nThe levels of abstraction of the binder and the other sub-\narchitectures are conceptually illustrated in Figure 1. The\nfollowing sections describe in detail how the above is actually\nachieved.\n4.2 Implementation\nOur approach to generating a shared representation should\nnot limit what SAs can express (based on the the non-\nintrusiveness requirement). Therefore the set of possible\nfeatures is very broad:\nDefinition 4.1. A feature space \u03a6x \u2208 \u03a6 is any data\nformat in the space of all possible data formats, \u03a6.\n83\n\u03c6xi \u2208 \u03a6\nx denotes an instantiation of a particular\nrepresentation where x should be interpreted as any feature\nspace name. 2\nFor example, \u03c6ColourLabelred \u2208 \u03a6\nColour denotes the colour\u201cred\u201d\nin the representation space of colours (the exact implemen-\ntation of this representation is of no relevance here). In our\nCAST instantiation, \u03a6 corresponds to anything that can be\nrepresented by IDL-defined structs (including nested ones).\nInformation from the SAs is shared as a collection of prox-\nies:\nDefinition 4.2. A binding proxy is a structure\np = \u3008Fp, up\u3009 where Fp is a set of instantiated features of\ndifferent types (i.e. Fp = {\u03c6\nx1\n1 , \u03c6\nx2\n2 . . . \u03c6\nxn\nn }) and up refers\nto a binding union with which the proxy is bound (see\nbelow). 2\nThe unions should express information from proxies that,\nby all accounts (cf. Algorithm 1), refer to the same entity.\nUnions simply inherit the features of the bound proxies and\nare defined as:\nDefinition 4.3. A binding union is a structure\nu = \u3008Fu,Pu\u3009 where Pu refers to the subset of proxies\nunified by the union u and Fu is defined as the union of the\nfeatures in all proxies in Pu. 2\nThe problem for the binder is to assess whether two prox-\nies are matching or not. By matching we mean that they\nshould refer to the same thing. To do this, all new or up-\ndated proxies are compared to all unions on the basis of their\nrespective features. The basis of this comparison is that each\npair of feature types has an associated comparator function:\nDefinition 4.4. A feature comparator is a function\n\u2206 : \u03a6x \u00d7 \u03a6y \u2192 {true, false, indeterminate} returning a\nvalue corresponding to whether two feature instances are\nequivalent (or similar enough) or not. The comparator can\nalso choose to not return a definite answer if the answer is\nundefined, or the uncertainty is too big (i.e.\nindeterminate). 2\nObviously, indeterminate is the only answer most such\ncomparators can return, e.g. the comparison of a \u03a6Colour\nand a \u03a6Position is likely undefined1. However, for many\npairs of features there exist informative comparators. For\nexample, features such as linguistic concepts can be com-\npared to other concepts (with ontological reasoning [3]) or\nphysical positions can be compared to areas.\nDefinition 4.5. Two feature spaces (\u03a6x,\u03a6y) are\ncomparable iff \u2203(\u03c6xi , \u03c6\ny\nj ) \u2208 (\u03a6\nx,\u03a6y) such that\n\u2206(\u03c6xi , \u03c6\ny\nj ) 6= indeterminate. 2\nThe more pairs of features from different SAs that are com-\nparable, the more likely it is that proxies from these SAs\nwill be accurately matched.\nTo compare a proxy and a union, the corresponding fea-\nture sets are the basis for scoring:\nDefinition 4.6. The binding scorer is a function S+ :\nP \u00d7U \u2192 N where P and U denote the set of all proxies and\n1Of course, in the implementation, such undefined compara-\ntors are never invoked. Mathematically, however, this is ex-\nactly what happens.\nbestUnionsforProxy(p,U)\nInput: A proxy, p, and the set of all unions, U .\nOutput: Best union(s) with which a proxy should bind.\nbegin\nbest := \u2205;\nmax := 0;\nfor \u2200u \u2208 U do\nif S\u2212(p, u) = 0 \u2227 S+(p, u) > max then\nbest := {u};\nmax := S+(p, u);\nelse if S\u2212(p, u) = 0 \u2227 S+(p, u) = max then\nbest := best \u222a {u};\nend\nend\nreturn best;\nend\nAlgorithm 1: The algorithm which computes the\nset of best candidate unions for being bound with\na new or updated proxy (see definitions 4.1-4.6 for\nan explanation of the notations).\nunions respectively and\nS\n+(p, u) =\nX\n\u03c6x\ni\n\u2208Fp\nX\n\u03c6\ny\nj\n\u2208Fu\n\uf6be\n1 if \u2206(\u03c6xi , \u03c6\ny\nj ) = true \u2227 \u03c6\nx\ni 6= \u03c6\ny\nj\n0 otherwise\nwhere Fp and Fu are the feature sets of p and u\nrespectively. 2\nNote that identical features are not counted. This to prevent\na union getting a higher score just because it is compared\nto one of its member proxies (this would sometimes prevent\na proxy switching to a better union). The number of fea-\nture mismatches is also counted (i.e. with true replaced with\nfalse in S+). That function is here denoted S\u2212 : P\u00d7U \u2192 N.\nIt is important to state that S+ and S\u2212 are implemented\nasynchronously with respect to the comparators. Until a\ncomparator has returned an answer, S+ and S\u2212 will sim-\nply assume that the answer is neither true or false, i.e.\nindeterminate.\nS+ and S\u2212 are the basis for selecting the best among all\nunions for each new or updated proxy. This is conducted by\nthe function bestUnionsforProxy described in Algorithm 1.\nThe result of best = bestUnionsforProxy is a set of zero,\none or more unions. If |best| = 0 then a new union will be\ncreated for the proxy p alone (i.e. with all the features of p).\nIf |best| = 1, then the proxy is bound to that union.\nWhen |best| > 2 we are faced with a disambiguation prob-\nlem. To avoid deadlocks in such cases the binder selects a\nrandom union from best for binding. However, bindings are\nsticky, meaning that if an already bound proxy subsequently\nmatches a union in a larger \u201cbest\u201d-list, then it will not switch\nto any of those unions. This to avoid excess processing in,\nand signalling from, the binder. This also helps to satisfy\nour requirement for symbols to be stable as far as possible.\nDisambiguation problems cannot be solved by the binder\nitself, but it can request help from others SAs. This may\nresult, for example, in the communication SA initiating a\nclarification dialogue with a human tutor (cf. Section 5.4).\n4.3 Relations and Groups\nThe proxies and unions described so far have been as-\nsumed to roughly correspond directly to physical objects.\nThey may also correspond to more abstract entities as well.\nTo support this, two special proxy types are implemented\n84\nin a slightly different manner: proxies denoting groups of\nproxies, and proxies denoting relationships between proxies.\nSince proxies contain features that are of any representable\ntype, proxies can also have features attributable to groups\nand relations, e.g. cardinality and relative metric informa-\ntion respectively, and explicit references to relating proxies.\nCurrently we handle groups in a fairly simple yet direct way:\na special kind of\u201cgroup proxy\u201dis created exactly like an ordi-\nnary binding proxy with all the features that the members\nof the group have in common (e.g. \u201cthe blue balls to the\nleft of the mug\u201d creates a group with features \u03c6Conceptball and\n\u03c6ColourLabelblue and with a spatial relation \u03c6\nSpatialRel\nleft of -proxy to\nthe \u03c6Conceptmug -proxy. A separate process in the binding SA\n(the \u201cgroup manager\u201d) then spawns off individual proxies\nwhich inherit the features of the group proxy. Every time an\nindividual is bound to something, a new proxy is spawned2.\nTo all the other processes, the individuals appear as an end-\nless supply of normal proxies.\nRelation proxies are implemented in a similar way as stan-\ndard proxies, but with additional features indicating the\nother proxies involved in the relation. Features of relation\nproxies are thus compared using the same mechanism that\ncompares the features of standard proxies. For example,\nspatial metric features, e.g. \u03c6R\n3\n~(x,y,z)\n, could in principle be\ncompared to a linguistic feature describing the same rela-\ntion, e.g. \u03c6SpatialRelleft of . It has turned out that features that\nlink relations to normal proxies and vice versa make the scor-\ning inefficient. Therefore, a separate scoring scheme similar\nto that in definition 4.6 is used to assess how well proxies\nmatch to unions w.r.t. their relational context (but due to\nspace limitations, this is left out of the description).\n5. EXAMPLES\nTo illustrate how our binder supports a number of be-\nhaviours typically required of robots that interact with hu-\nmans, the following sections present a number of examples\ntaken from our implemented system. These examples refer\nto the implemented system and subarchitectures described\nin Section 3.\n5.1 Visual & Spatial Reference Resolution\nPerhaps the most common use of information fusion sys-\ntems is to interpret linguistic references in terms of visual\ninformation (cf. Section 2). Our binder handles this task as\nan instance of a more general problem of information fusion.\nWe will here consider the simple situation where we have a\nred object and two blue objects on the table. The objects\nare arranged in a straight line of alternating colours. The\nhuman then asks the robot to \u201cput the blue objects to the\nleft of the red objects\u201d.\nWe will start our example in the visual subarchitecture,\nwhere change detection, tracking and segmentation com-\nponents create representations of the objects in the scene.\nThese objects have 3D poses and bounding boxes and a num-\nber of slots for visual properties such as colour, shape and\nsize. These slots are filled by a recogniser that has been\npreviously trained (see Section 5.3) using input from a hu-\nman trainer [14]. For this example we assume the recogniser\n2With some obvious limitations to allow finite groups and\nto prevent excess proxies being generated when members of\ndifferent groups merge.\ncorrectly extracts the colours of the objects as red and blue.\nWhen the scene becomes stable (determined by the change\ndetector) the visual subarchitecture binding monitor creates\na proxy for each of the currently visible objects. As the vi-\nsual property recogniser processes the objects, the monitor\nupdates the proxies with features reflecting these properties.\nThis is an incremental process, so the visual proxies are up-\ndated asynchronously as the objects are processed. At this\npoint only the visual proxies are present in the binding work-\ning memory, each one is bound to its own union.\nThe presence of objects in the visual working memory is\nalso noticed by the components in the spatial subarchitec-\nture. These abstract the objects as points on the table-\ntop, and the spatial binding monitor creates a proxy for\neach. These proxies are tagged with the ID of the visual\nproxy for the corresponding object so they are bound cor-\nrectly3. Concurrently with the proxy creation, qualitative\nspatial relations between the spatial objects are added to\nworking memory. These are generated by components us-\ning potential-field-based models of spatial relations [1]. In\nour example the two blue objects are to the left and to the\nright of the red object respectively. They are both also near\nthe red object (but not near each other). As these rela-\ntions are added, the spatial binding monitor reflects them\non the binding working memory as relation proxies between\nthe spatial proxies. The binder uses these as the basis of\nrelations between the unions featuring the spatial proxies.\nThis provides our basic model of the current state.\nWhen the human speaks to the robot, a speech recognition\nmodule in the communication subarchitecture is triggered.\nThe resulting speech string is written to the communication\nworking memory. This triggers a cycle of deep sentence anal-\nysis and dialogue interpretation, yielding a structured logical\ndescription of the utterance\u2019s content. From this structure\nthe communication binding monitor generates communica-\ntion proxies for the discourse referents from the utterance\nand the relations between them. These proxies include fea-\ntures that can match against both those attached to visual\nproxies (colour, shape and size), and those attached to spa-\ntial proxies (relations based on spatial preposition). In the\nexample two proxies are generated: one normal proxy for the\nred object, and one group proxy for the blue objects. The\nbinder uses the features of these communication proxies to\nbind them into unions with the visual and spatial proxies. In\nthe example the \u03c6ColourLabelred -proxy is bound together with\nthe visual and spatial proxies relating the red object, and the\n\u03c6ColourLabelblue -proxies spawned from the corresponding group\nproxy (see Section 4.3) are bound with the remaining prox-\nies for the blue objects. This provides the system with an\ninterpretation of the utterance in terms of the visual scene.\nIn this example, the process of reference resolution in-\nvolves simply ensuring that the communication proxies re-\nferring to visual entities (i.e. those referring to objects in\nthe tabletop scenario) are bound to unions that have a vi-\nsual component. If the utterance contains spatial language,\nthen relation proxies are generated by the communication\nbinding monitor. This causes the binding process to bind\nproxies via the relations between proxies as well as the fea-\ntures of single proxies. Failure to bind proxies can trigger a\nnumber of different processes, as described in 5.4.\n3A similar, but more general, functionality could be gener-\nated by matching location-derived features.\n85\n5.2 Planning and Execution\nOnce the system has successfully interpreted an utterance,\nit must also generate some behaviour. In addition to cre-\nating proxies, the interpretation of the utterance also pro-\nduces information about the purpose of the utterance. In\nthis case the utterance is determined to be an instruction,\nand this causes the coordination subarchitecture to generate\na motive to act on the instruction. This process involves re-\ninterpreting the utterance as a planning goal in MAPL, the\nmulti-agent planning language used by the system. This in-\nterpretation is carried out by a general-purpose process that\nmaps between verbs and planning operators [1]. Once the\nsystem has a goal, the planning subarchitecture is used to\ngenerate and execute a plan to satisfy it.\nTo create a plan, the planning subarchitecture needs to\ngenerate a description of the initial state for the planner to\noperate on. This is done by translating directly from the\nbinding unions (accessed through the communication prox-\nies stemming from the utterance) and their features into ob-\njects and fact descriptions in MAPL. Once a plan has been\ncreated, the execution components in the planning subarchi-\ntecture start working through the plan triggering execution\nsteps followed by execution monitoring steps.\nIn our current system we only have actions related to ma-\nnipulation (pick up and put down), so all plan actions are\nforwarded to the manipulation subarchitecture. As the plan-\nning process used binding unions as input, the plan actions\nare also expressed in terms of these unions. The manipu-\nlation subarchitecture cannot operate on the symbolic rep-\nresentation used by the planner, but requires the detailed\nmetric information generated by processes in the visual sub-\narchitecture to support grasping. By following links from\nthe input unions in the planned action via the visual proxy\nto the object information in the visual subarchitecture, the\nmanipulation processes get access to the necessary metric\ndata. As the processes in the visual subarchitecture run\nconstantly, this metric information is always kept consis-\ntent with the world. The binding structures, however, re-\nmain stable across these changes (unless they are significant\nenough to alter the spatial relations). This example demon-\nstrates how our two-level approach to representing the cur-\nrent state of the world supports access to low-level informa-\ntion via high-level symbols, whilst allowing these symbols to\nremain stable as the low-level information they are derived\nfrom is updated.\nIn our example, the plan involves a single pair of pick and\nput actions. The blue object on the right of the scene is\nmoved to the left of the red object. The other object is al-\nready to the left of it so it is not moved. After each object\nis moved the planning subarchitecture triggers an execution\nmonitoring step. This step involves creating a new represen-\ntation of the current state from the unions on binding work-\ning memory, and comparing them to the state predicted by\nthe plan. For the monitoring step in the example to com-\nplete successfully, the unions must reflect that the moved\nblue object is now at a position to the left of the red object.\nBeing able to monitor for such abstractly-specified condi-\ntions demonstrates the benefit of generating symbolic states\non demand from a dynamically updated representation of\nthe current state.\n5.3 An Example of Interactive Learning\nOur example system learns the visual properties of ob-\njects through dialogue with a human tutor (an interaction\nthat can take many forms [17]). The tutor trains the sys-\ntem with sentences such as \u201cthis is a large red thing\u201d and\n\u201cthis is to the left of the blue thing\u201d, and the visual prop-\nerties are ultimately learnt by a continuous learning system\n[14]. Our approach to binding naturally supports the cre-\nation of training examples for this learning system. When an\nobject is placed in front of the robot, the visual subarchitec-\nture processes the object as described previously, ultimately\ncreating a visual proxy for it. When the tutor makes an\nassertion about the object (or relation), we use recency in-\nformation to bind the communication proxy for the deictic\nreference to the newest visual proxy4. The communication\nproxy contains binding features for all of the adjectives used\nin the utterance. When the visual subarchitecture binding\nmonitor is informed its proxy has been bound into a union\n(via CAST change events), it inspects the union to see what\nfeatures are present that it didn\u2019t add itself. These features\nrepresent information about the object from other modali-\nties that the visual subarchitecture can choose to learn. Cur-\nrently, we take a fixed subset of features present in the union\nand use them to generate input to our learner. In theory\nthese restrictions could be removed and features provided\nby other modalities could be used by any subarchitecture\nto learn cross-modal information. This simple way of driv-\ning cross-modal learning systems demonstrates a benefit of\nboth our approach to binding and of working on learning in\nintegrated systems.\n5.4 Generation of Clarification Events\nIt is not always possible for the binder to find unique\nbindings for proxies. For example, consider a scene with\ntwo red objects on the table which cause two visual \u03c6Colourred -\nproxies to be created and bound into separate unions. The\nhuman then asks the robot to \u201cpick up the red thing\u201d, cre-\nating a \u03c6ColourLabelred -proxy from the discourse. In this situ-\nation bestUnionsforProxy will return a set containing the\ntwo visually red unions. In the near future we plan to use\nsituations such as this as a general purpose trigger for gen-\nerating clarification behaviour. For example, consider the\ncase where the visual proxies (and thus their unions) have\nsome mismatching features that separate them (e.g. \u03c6Shaperound\nand \u03c6Shapesquare). In this case, this could lead directly to the\nsystem generating a goal to determine if the object being\nreferred to by the human has one of the mismatching fea-\ntures. In this example the robot could ask a question about\nthe distinguishing feature (e.g. \u201cdo you mean the round red\nthing?\u201d). However, in principle the general purpose nature\nof the binding system means that any subarchitecture that\ncan provide a particular binding feature could satisfy such\na request for information (i.e. not only dialogue).\nThe situation where the ambiguous unions have matching\nfeature sets raises a different type of clarification problem.\nRather than generating a need for a particular type of fea-\nture information to clarify a binding, resolving this situa-\ntion requires a direct reference to the target object to allow\nbinding. For example, the robot may have to ask \u201cwhich\nred thing do you mean?\u201d, \u201cdo you mean this one?\u201d (whilst\npointing), or \u201cdo you mean the one on the left?\u201d. Alterna-\ntively the binding system could draw on information from\n4In this instance we are using recency as a substitute for a\nmore complex process of reference resolution.\n86\nother modalities to determine things such as the likelihood of\nthe object being involved in a pick-up action (e.g. a feature\n\u03c6Reachabletrue ), or the salience of the object given the human\u2019s\nperspective on the scene. Building support for the sharing of\nsuch information via proxies allows general notion of salience\nand attention to be built into the system.\n6. DISCUSSION\nIn the following sections we discuss the properties of the\nrepresentation and binding system presented previously, in-\ncluding how it relates to our original requirements.\n6.1 Modal and Amodal Representations\nAs is apparent in the planning example above (Section\n5.2), from the point of view of a particular SA, a union is\nan amodal entity. But despite this, it also contains a set\nof modal properties some of which have semantics for par-\nticular SAs. The binder mixes amodal and modal represen-\ntations such that modality-independent proxies and unions\ncan be used for symbolic processing while at the same time\nthey contain references to modal representations, i.e., via\nthe features. Moreover, if a feature space is used which sup-\nports the ability to refer to data inside local SA WMs, data\ntypes that have not been declared as features can still be\nshared with all other SAs if required.\n6.2 Lazy Binding and Locally Stable Symbols\nIn our binder, the only thing an SA typically needs to\nkeep track of, once a binding proxy is created, is the proxy\nitself. Once created as a candidate for binding, the proxy\nindeed acts as a proxy which mediates information from its\nunion. This means that any SA-internal symbols can be\nmade isomorphic to the indexes of the proxies and the SA\ndoes not need to necessarily take into account whether the\nproxy is in a union or not.\nThis can be a very powerful simplification for many types\nof SAs. For example, consider the navigation dialogue sce-\nnario where the user tells the robot to \u201cgo to the kitchen\u201d\n[19]. Now, if the robot has yet to discover the kitchen, the\ndiscourse referent proxy containing \u03c6Conceptkitchen can not really\nbe bound to any kitchen in the map. As soon as some other\nprocess identifies and defines a kitchen in the map, the ut-\nterance\u2019s \u03c6Conceptkitchen -proxy can be bound. Whether or not this\nbinding takes place, the \u03c6Conceptkitchen -proxy remains intact and\ncan still be referred to internally in the same way. From\nthe point of view of an individual SA, unions just provide\npotentially richer descriptions of its own proxies.\n6.3 Scalability\nThe theoretical properties of the binder are irrelevant if\nit cannot be implemented in an effective way. Potentially,\nthe binder may become a bottleneck in an architecture since\nit may receive features and proxies from all involved subar-\nchitectures5. To overcome this, we have implemented the\nbinder as several smaller components, each responsible for\nbasic and well-defined tasks (e.g. invoking and collecting the\nresults of comparators, generating the unions based on fea-\nture scores etc.). All of these components can be replicated\nand put on different physical nodes, sharing the computa-\ntional load. Moreover, the feature comparisons are made\n5This is one reason why SAs should be conservative about\ngenerating proxies.\nexternally to the binder and thus the computational load is\nfurther distributed6.\nThe problem of making the binder scalable is in part ad-\ndressed by the role of abstraction in the system. The data\n\u201cclosest\u201d to the binder (i.e. the unions) are abstracted from\nthe much more abundant features (which are primarily pro-\ncessed by the SAs themselves). This means the binder only\nhas to operate on an abstracted subset of all of the informa-\ntion in the system.\n6.4 Incremental Asynchronous Binding\nAs mentioned in Section 2 it is desirable to do both early\nand anytime binding. We achieve this in our implemen-\ntation by allowing all components to operate on the data\nasynchronously. This makes binding quite efficient since any\nprocessing tasks (feature comparisons, scorings, union cre-\nation etc), will be carried out as soon as is possible.\nFor example, in Section 5.1, the visual and spatial prox-\nies are initially bound as basic object abstractions. Fol-\nlowing this, SA-specific components gradually add more in-\nformation about the objects (visual properties and spatial\nrelations), which cause the proxies, and their unions, to be\nasynchronously updated with features and relations.\nThe anytime properties of the binder also mean that any\ncomparison that is finished early may help in forming unions\nbefore any additional comparisons are made. Thus unions\nmay be formed at an early stage and then refuted if conflict-\ning information arrives later. This may create an overhead\ngiven that incorrect unions are temporarily created. SAs\nwith higher quality demands can always wait until the bind-\nings have \u201csettled\u201d.\n6.5 Demands on Subarchitectures\nFrom an engineering point of view, subarchitecture de-\nsigners have to provide a number of things to support the\nbinding process: 1. the feature definitions (if not already ex-\nisting), 2. a binding monitor component that analyses local\nSA WM content and generates and mediates proxies onto\nthe binding working memory, and 3. the comparators.\nThe comparators can be based upon any kind of compu-\ntational process from simple equivalence testing like string\nmatching to ontological, spatial or visual reasoning etc. The\ncomparators may also be learnt models and can even be\nlearnt online, on data extracted from unions, while the binder\nis operating (as presented in Section 5.3). Moreover, a com-\nparator may be context sensitive, i.e. it can take into ac-\ncount all other information on the binding WM to make its\nassessment (cf. [11]). It is also possible that the comparator\nitself triggers the SA to generate more features to complete\na proxy\u2019s description. There are many possibilities since few\nlimitations are imposed by the design of the binder.\nThe integration with the binder is fairly non-intrusive in\nthe sense that none of the things that need to be provided\nshould have any implications on any other part of the SA.\nMinimally, the SA only needs to write features and prox-\nies, and does not have to process what is happening on the\nbinder at all.\nA slightly deeper integration problem occurs when a SA\nneeds to utilise the contextual information represented by\nthe unions (e.g. for priming in incremental parsing). This is,\nhowever, arguably non-intrusive as well, as all features that\n6In the implementation some trivial comparisons are actu-\nally handled internally in the binder.\n87\nare unknown to the SA in question can safely be ignored (cf.\nsection 6.1).\nThe feature set space is also highly open-ended. An added\nfeature definition will not affect, nor depend on, the earlier\nfeatures in any way. Every subarchitecture can and will only\ndeal with the features it knows about (i.e. it is non-intrusive\nw.r.t. data formats). This means that there is a fairly low\ncost to adding features into the system.\nOne problem for some designers may be that expressive\nmodels of beliefs (e.g. Bayesian) are being robbed of their\nexpressiveness when a comparator can only return three val-\nues. This is however a better situation than the opposite.\nThere is also nothing that prevents a comparator from rea-\nsoning about degrees of belief up to the point of the final\ncomparison decision.\nIn order for the binder to perform well, the designers need\nto be conservative. For example, proxies should not be gen-\nerated excessively (for example, just to see if they will be\nbound or not) since it may disturb other SAs. And new\nfeature types should primarily only be introduced if also a\ncomparator for this feature can be defined.\nIf conservatism is not employed, the binder will not per-\nform well. Since features and comparators are representable\nin very open-ended formats, the SA designer has very few\nlimitations in what can be done. This is of course an ad-\nvantage in many cases. But many creative interpretations\nof \u201cfeatures\u201d, \u201cproxies\u201d and \u201ccomparators\u201d will simply not\nyield desired results. For example, conflicting features can\nbe inserted into a proxy, but that violates the proxy-as-best-\nhypothesis assumption.\nAnother problem is if the SAs can only provide features\nthat are SA specific and incomparable with most features\nfrom other SAs. In such cases the binder would not be able\nto form any unions. It is thus important to have comparable\nfeatures in mind when integrating SAs into an architecture.\n7. CONCLUSION\nIn this paper we presented a method for generating a sta-\nble, yet asynchronously updated, representation of the cur-\nrent state of the world for a situated information-processing\nsystem such as an intelligent robot. The amodal represen-\ntation emerges from the incremental fusion of information\nabstracted from modal data, and satisfies the requirements\nwe specified for such a system. Although our system has\nbeen fully implemented, we have yet to evaluate it experi-\nmentally. In place of this we illustrated our system with a\nnumber of examples from the scenarios we are tackling.\n8. ACKNOWLEDGEMENTS\nThis work was supported by the EU FP6 IST Cognitive\nSystems Integrated Project \u201cCoSy\u201d FP6-004250-IP.\n9. REFERENCES\n[1] M. Brenner, N. Hawes, J. Kelleher, and J. Wyatt.\nMediating between qualitative and quantitative\nrepresentations for task-orientated human-robot\ninteraction. In Proc. IJCAI \u201907, 2007.\n[2] T. Brick and M. Scheutz. Incremental natural\nlanguage processing for hri. In Proc HRI \u201907, pages\n263\u2013270, 2007.\n[3] R. Engel and N. Pfleger. Modality fusion. In\nW. Wahlster, editor, SmartKom - Foundations of\nMultimodal Dialogue Systems, Cognitive Technologies,\npages 223\u2013235. Springer, July 2006.\n[4] B. Fransen, V. Morariu, E. Martinson, S. Blisard,\nM. Marge, S. Thomas, A. Schultz, and\nD. Perzanowski. Using vision, acoustics, and natural\nlanguage for disambiguation. In Proc HRI \u201907, pages\n73\u201380, New York, NY, USA, 2007. ACM Press.\n[5] N. Hawes, A. Sloman, J. Wyatt, M. Zillich,\nH. Jacobsson, G. Kruijff, M. Brenner, G. Berginc, and\nD. Skocaj. Towards an integrated robot with multiple\ncognitive functions. In Proc. AAAI \u201907, 2007.\n[6] N. Hawes, M. Zillich, and J. Wyatt. BALT & CAST:\nMiddleware for cognitive robotics. In Proc. IEEE\nRO-MAN 2007, pages 998 \u2013 1003, August 2007.\n[7] G.-J. Kruijff, J. Kelleher, and N. Hawes. Information\nfusion for visual reference resolution in dynamic\nsituated dialogue. In E. Andre, L. Dybkjaer,\nW. Minker, H. Neumann, and M. Weber, editors,\nProc. PIT \u201906, pages 117 \u2013 128, 2006.\n[8] N. Mavridis and D. Roy. Grounded situation models\nfor robots: Where words and percepts meet. In\nIEEE\/RSJ International Conference on Intelligent\nRobots and Systems 2006, pages 4690\u20134697.\nIEEE\/RSJ, October 2006.\n[9] N. J. Nilsson. Shakey the robot. Technical Report 323,\nAI Center, SRI International, 1984.\n[10] D. L. Parnas. On the criteria to be used in\ndecomposing systems into modules. Commun. ACM,\n15(12):1053\u20131058, 1972.\n[11] D. Roy. Grounding words in perception and action:\nInsights from computational models. Trends in\nCognitive Science, 9(8):389\u201396, 2005.\n[12] D. Roy. Semiotic schemas: A framework for grounding\nlanguage in action and perception. Artificial\nIntelligence, 167(1-2):170\u2013205, 2005.\n[13] D. Roy and N. Mukherjee. Towards situated speech\nunderstanding: visual context priming of language\nmodels. Computer Speech & Language, 19(2):227\u2013248,\n2005.\n[14] D. Skoc\u02c7aj, G. Berginc, B. Ridge, A. S\u02c7timec, M. Jogan,\nO. Vanek, A. Leonardis, M. Hutter, and N. Hawes. A\nsystem for continuous learning of visual concepts. In\nInternational Conference on Computer Vision Systems\nICVS 2007, Bielefeld, Germany, 2007.\n[15] A. Sloman. Varieties of affect and the CogAff\narchitecture schema. In Proc. the AISB\u201901 Symposium\non Emotion, Cognition and Affective Computing,\npages 1\u201310, 2001.\n[16] L. Steels. Semiotic dynamics for embodied agents.\nIEEE Intelligent Systems, 21(3):32\u201338, 2006.\n[17] A. L. Thomaz. Socially Guided Machine Learning.\nPhD thesis, Massachusetts Institute of Technology,\nMay 2006.\n[18] S. Wood. Planning and Decision Making in Dynamic\nDomains. Ellis Horwood, 1993.\n[19] H. Zender, P. Jensfelt, O\u00b4scar Mart\u00b4\u0131nez Mozos,\nG.-J. M. Kruijff, and W. Burgard. An integrated\nrobotic system for spatial understanding and situated\ninteraction in indoor environments. In\nProc. AAAI \u201907.\n88\n"}
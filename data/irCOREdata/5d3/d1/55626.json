{"doi":"10.1109\/VS.2000.856860","coreId":"55626","oai":"oai:eprints.lincoln.ac.uk:1906","identifiers":["oai:eprints.lincoln.ac.uk:1906","10.1109\/VS.2000.856860"],"title":"Application of the self-organising map to trajectory classification","authors":["Owens, Jonathan","Hunter, Andrew"],"enrichments":{"references":[{"id":18437626,"title":"A Real-T ime System f or Vide o Surveillance of Unattended Outdoor Environments,\u201d","authors":[],"date":"1998","doi":"10.1109\/76.728411","raw":"Foresti, G . L .  \u201cA  Real-T ime System  f or Vide o Surveillance of Unattended Outdoor Environments,\u201d IEEE Trans. Circuits and Systems for Video Technology, vol. 8, no. 6, 1998.","cites":null},{"id":18437640,"title":"Adaptive Background Mixture Models for Real-Time Tracking,\u201d","authors":[],"date":"1999","doi":"10.1109\/cvpr.1999.784637","raw":"Stauffer, C. and Grimson, W. E. L.  \u201cAdaptive Background Mixture Models for Real-Time Tracking,\u201d Proc. of CVPR, 1999.","cites":null},{"id":18437636,"title":"Agent Orientated Annotation in Model Based Visual Surveillance,\u201d","authors":[],"date":"1998","doi":"10.1109\/iccv.1998.710817","raw":"Remagnino, P., Tan, T., and Baker, K.  \u201cAgent Orientated Annotation in Model Based Visual Surveillance,\u201d Proc. of ICCV, 1998.","cites":null},{"id":18437634,"title":"An Integrated Traffic and Pedestrian Model-Based Vision System,\u201d","authors":[],"date":"1997","doi":null,"raw":"Remagnino, P., Bumberg, A., Grove, T., Hogg, D., Tan, T., Worral, A. and Baker, K.  \u201cAn Integrated Traffic and Pedestrian Model-Based Vision System,\u201d Proc. BMVC, vol. 2, 1997.","cites":null},{"id":18437632,"title":"Comparison of Background Extraction Based Intrusion Detection Algorithms,\u201d","authors":[],"date":"1996","doi":"10.1109\/icip.1996.559548","raw":"Makarov, A.  \u201cComparison of Background Extraction Based Intrusion Detection Algorithms,\u201d IEEE Int. Conf. Image Processing, 1996.","cites":null},{"id":18437638,"title":"Illumination Independent Change Detection for Real World Sequences,\u201d","authors":[],"date":"1989","doi":"10.1016\/0734-189x(89)90039-x","raw":"Skifstad, K. and Jain, A.  \u201cIllumination Independent Change Detection for Real World Sequences,\u201d Computer Vision, Graphics, and Image Processing, vol. 46, 1989.","cites":null},{"id":18437642,"title":"Improved Classification for a Data Fusing Kohonen SelfOrganising Map Using a Dynamic Thresholding Technique,\u201d","authors":[],"date":"1999","doi":null,"raw":"Taylor, O., Tait, J. and MacIntyre, J.  \u201cImproved Classification for a Data Fusing Kohonen SelfOrganising Map Using a Dynamic Thresholding Technique,\u201d Proc. of IJCAI, vol. 2, 1999. 0-7695-0698-04\/00 $10.00  2000 IEEE","cites":null},{"id":18437628,"title":"Learning the Distribution of Object Trajectories for Event Recognition,\u201d","authors":[],"date":"1995","doi":"10.5244\/c.9.58","raw":"Johnson, N. and Hogg, D.  \u201cLearning the Distribution of Object Trajectories for Event Recognition,\u201d Proc. BMVC, vol. 2, 1995.","cites":null},{"id":18437630,"title":"Self-Organising Maps,\u201d","authors":[],"date":"1995","doi":"10.1016\/b978-044450270-4\/50008-5","raw":"Kohonen, T.  \u201cSelf-Organising Maps,\u201d SpringerVerlag, 1995.","cites":null},{"id":18437627,"title":"Using Adaptive Tracking to Classify and Monitor Activities in a Site,\u201d","authors":[],"date":null,"doi":"10.1109\/cvpr.1998.698583","raw":"Grimson, W. E. L., Stauffer, C., Romano, R. and Lee, L.  \u201cUsing Adaptive Tracking to Classify and Monitor Activities in a Site,\u201d Proc. of CVPR,","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2000-07-01","abstract":"This paper presents an approach to the problem of automatically classifying events detected by video surveillance systems; specifically, of detecting unusual or suspicious movements. Approaches to this problem typically involve building complex 3D-models in real-world coordinates\\ud\nto provide trajectory information for the classifier. In this paper we show that analysis of trajectories may be carried out in a model-free fashion, using self-organising\\ud\nfeature map neural networks to learn the characteristics of normal trajectories, and to detect novel ones. Trajectories are represented using positional and first and second order motion information, with moving-average smoothing. This allows novelty detection to be applied on a point-by-point basis in real time, and permits both instantaneous motion and whole trajectory motion to be subjected to novelty detection","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/55626.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/1906\/1\/IEEE.PDF","pdfHashValue":"4dcfd9e5befc58968cd483abc1fcda5569664414","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:1906<\/identifier><datestamp>\n      2013-03-13T08:32:55Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F47:6A6163735F47373630<\/setSpec><setSpec>\n      74797065733D636F6E666572656E63655F6974656D<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/1906\/<\/dc:relation><dc:title>\n        Application of the self-organising map to trajectory classification<\/dc:title><dc:creator>\n        Owens, Jonathan<\/dc:creator><dc:creator>\n        Hunter, Andrew<\/dc:creator><dc:subject>\n        G760 Machine Learning<\/dc:subject><dc:description>\n        This paper presents an approach to the problem of automatically classifying events detected by video surveillance systems; specifically, of detecting unusual or suspicious movements. Approaches to this problem typically involve building complex 3D-models in real-world coordinates\\ud\nto provide trajectory information for the classifier. In this paper we show that analysis of trajectories may be carried out in a model-free fashion, using self-organising\\ud\nfeature map neural networks to learn the characteristics of normal trajectories, and to detect novel ones. Trajectories are represented using positional and first and second order motion information, with moving-average smoothing. This allows novelty detection to be applied on a point-by-point basis in real time, and permits both instantaneous motion and whole trajectory motion to be subjected to novelty detection.<\/dc:description><dc:date>\n        2000-07-01<\/dc:date><dc:type>\n        Conference or Workshop contribution<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/1906\/1\/IEEE.PDF<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/1906\/2\/06980077.pdf<\/dc:identifier><dc:identifier>\n          Owens, Jonathan and Hunter, Andrew  (2000) Application of the self-organising map to trajectory classification.  In: IEE Visual Surveillance Workshop, 1 July 2000, Dublin, Ireland.  <\/dc:identifier><dc:relation>\n        http:\/\/doi.ieeecomputersociety.org\/10.1109\/VS.2000.856860<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/1906\/","http:\/\/doi.ieeecomputersociety.org\/10.1109\/VS.2000.856860"],"year":2000,"topics":["G760 Machine Learning"],"subject":["Conference or Workshop contribution","PeerReviewed"],"fullText":"1Application of the Self-Organising Map to Trajectory Classification\nJonathan Owens* and Andrew Hunter\nSchool of Computing and Engineering Technology\nUniversity of Sunderland\nEngland\nemail: {jonathan.owens, andrew.hunter}@sunderland.ac.uk\n*telephone:  +44 (0)191 515 3293\nAbstract\nThis paper presents an approach to the problem\nof automatically classifying events detected by\nvideo surveillance systems; specifically, of\ndetecting unusual or suspicious movements.\nApproaches to this problem typically involve\nbuilding complex 3D-models in real-world co-\nordinates to provide trajectory information for\nthe classifier.  In this paper we show that analysis\nof trajectories may be carried out in a model-free\nfashion, using self-organising feature map neural\nnetworks to learn the characteristics of normal\ntrajectories, and to detect novel ones.\nTrajectories are represented in 2D image co-\nordinates.  First and second order motion\ninformation is also generated, with moving-\naverage smoothing.  This allows novelty detection\nto be applied on a point-by-point basis in real\ntime, and permits both instantaneous motion and\nwhole trajectory motion to be subjected to novelty\ndetection.\n1. Introduction\nThis paper addresses the issue of detecting\nsuspicious behaviour of pedestrians using a\ncomputerised grey-scale video surveillance\nsystem.  The ultimate objective of the system is to\nact as a filter, detecting behaviour that appears out\nof the ordinary and drawing the attention of a\nhuman operator to such events.\nThe visual surveillance task is usually broken\ndown into a modular pipeline, as illustrated in\nfigure 1.  This paper is primarily concerned with\nthe implementation of the Decision Maker\nmodule, although our approach to the earlier\nstages in the pipeline is also briefly described.\nThe input to the Decision Maker module is the\ntrajectory of an object, which consists of a series\nof centroid positions.  The trajectory sequence is\nrecoded into a trajectory description vector, which\nis used as input to a Self Organising Feature Map\nneural network [4].  The neural network is trained\nto recognise normal trajectories, using video\nfootage of the target site (a car park) in normal\nuse.  During surveillance, the neural network\nidentifies abnormal behaviour (that is, object\ntrajectories unlike those encountered during the\ntraining phase) and highlights these.  Abnormal\ntrajectories may include those that enter areas that\nare not usually traversed, or those moving at\nunusual speeds or moving unusually erratically.\nA key aspect of the approach is that it is largely\n\"model-free\" \u2013 there is no explicit modelling of\nnormal or abnormal behaviour, which is instead\nlearned by the neural network.  The system may\nalso be used on a point-by-point basis, detecting\nany unusual structure in the partially complete\ntrajectories.\nPreliminary results indicate that the approach\nInput\nImage\nDecision\nMaker\nBackground\nEstimation\nObject\nExtraction\nObject\nTracking\nObject Classification \/\nModel Fitting\nFigure 1.  Typical visual surveillance processing pipeline \n0-7695-0698-04\/00 $10.00 \u0001 2000 IEEE \n2is able to detect unusual behaviour with an\nacceptable level of accuracy, although we also\nfind that it erroneously classifies some normal\nbehaviour as suspicious.  Further analysis\ndemonstrates that those normal trajectories\nclassified as abnormal are in fact not represented\nin the original training data, demonstrating that\nthe approach requires comprehensive training\ndata, and probably therefore on-line updating in a\npractical setting.  This sensitivity to training data\nis a drawback of the model-free approach.\n2. Pre-Processing Stages\nThis section discusses our approach to the\nBackground Estimation, Object Extraction,\nObject Tracking and Object Classification\/Model\nFitting stages in the pipeline.\nFirst, moving objects are identified by\nsubtraction from a background image, but\nchanges in lighting condition, movement of\nfoliage and so forth imply that it is difficult to\nidentify a static background; consequently, the\nbackground image needs to be adapted over time.\nWe generate the reference image using an\nalgorithm described by Makarov, A. [5].  The\nupdate operation performs a kind of temporal\nlow-pass filtering of the input image pixels,\nwhere only slow changes that fall below a\nthreshold are inserted into the background.  It\ncannot cope with very rapid background changes,\nsuch as clouds moving across the sun.  However,\nit is computationally light enough to be applied at\nreal-time frame rates on a standard PC.\nStauffer, C. and Grimson, W. E. L. [9],\ndescribe a more complicated, but more robust,\nmethod.  Each pixel is modelled by a mixture of\nGaussians that are continuously updated.  This\nmethod allows a multimodal representation of the\nreference image where, for example, moving\nfoliage may result in a switching between two\nluminance levels, with both belonging to the\nbackground.  Skifstad, K. and Jain, A. [8] give\ntwo methods for illumination independent object\ndetection; however, these algorithms apply to\npairwise image comparisons, rather than to the\ngeneration of an explicit reference image.\nObject extraction is performed using standard\ntechniques.  The pixels in the difference image\nnot belonging to the background are assigned to\nlabelled, connected components.  As the objective\nof this paper is to demonstrate classification of\npedestrian motion, cars were rejected at this stage\nbased upon measurements of size and aspect ratio.\nVery small objects are also rejected, and the\nproperties of the remaining objects, including the\ncentroids, are calculated.\nIn real-world scenes, a passive object tracker\nmay produce partial, noisy trajectories due to\nenvironmental interaction.  For example, a person\nmay be partially or completely occluded by\nwalking behind parked vehicles.  Object tracking\ndeals with these issues.  A common approach is to\nuse predictive tracking.  The parameters of the\nobject (e.g. size and location) are predicted for the\nnext frame (using Kalman filters [1, 2, 9] or\nsimilar approaches), and the prediction is refined\nusing the observed object.  Therefore, even if an\nobject is temporarily occluded, an estimate of its\nposition is still given using the parameter values\nin the last step.  This maintains a smooth\ntrajectory and is able to cope with object\nfusion\/separation when tracking multiple objects.\nOur system actually uses a very naive\napproach (objects are matched to the nearest\nobject in the next frame) which is suitable only\nfor low activity images without significant\nocclusion.  If two or more objects merge, for\nexample, the system will only maintain the\ntracking of one of the merged objects.  However,\nthe technique is simple enough to allow the\ntracker to be implemented along with the\nbackground generator on a standard PC.\nMost model-based systems translate the object\nposition into world co-ordinates and track\ntrajectories in that space, whereas our system uses\nimage co-ordinates (the camera is located high\nabove the car park, so that we still get reasonable\nresults).  However, our approach to trajectory\nnovelty detection is compatible with the motion\ndata produced by more sophisticated tracking\nalgorithms.\nIn some cases, an object needs to be classified\nbefore having model parameters matched to it.\nRemagnino, P. et al [6] fit a 3D model to cars and\na 2D model to people.  The 3D model aids in\ntrajectory classification, by assigning stable\norientation and dimensions to the tracked object.\nA 2D contour is fit to each pedestrian, and\nalthough the contour does not include orientation\ninformation, the centroid can be reliably tracked\neven when only part of the person is visible.\nStauffer, C. and Grimson, W. E. L. [9] use a\nbinary threshold of the time-averaged aspect ratio\nof an object to classify it as a pedestrian or\nvehicle.  In this case, classification is a post-\nprocessing step that is used to annotate the\ndatabase of recorded trajectories, rather than\nguiding a decision as to the model to fit to the\nobject.  Foresti, G. L. [1] uses a transformation\ninvariant shape description to classify tracked\n0-7695-0698-04\/00 $10.00 \u0001 2000 IEEE \n3objects by comparing them with a large database\nof pre-classified vehicles.\nAgain, our system does not include these more\nsophisticated modelling approaches, but is\ncompatible with the trajectory data produced by\nthem.\n3. Trajectory Classification\nThe Decision Maker module uses the\ntrajectories generated by the Object Tracker to\nclassify the behaviour observed in the image\nsequences.  We are particularly interested in\nclassifying behaviour that is suspicious, and may\nbe indicative of criminal intent (e.g. pedestrians\nexamining cars, speeding) or just unusual (e.g.\nparking in a non-parking area).\nA variety of approaches have been suggested\nin the literature.  Remagnino, P. et al [7] use\nBayesian belief networks.  For each object\ntracked, a belief network is assigned to examine\nthe location, heading, speed and trajectory, using\nthe image evidence to produce the most likely\ndescription of the object\u2019s behaviour.  When the\ndistance between two objects falls below a\nthreshold, a belief network is instantiated to\nexamine the interaction of the two objects, using\nthe behaviour of each object to give an\ninterpretation of the situation.  The belief\nnetworks provide a textual description of the\nscene (such as \u201cPedestrian 2 passing by Vehicle\n43\u201d) which may be classified by an operator, or a\nseparate automated system.\nAlternatively, a trajectory is commonly\nencoded by sequences of flow vectors, which\ndescribe the position and instantaneous velocity\nof the tracked object, f = [x, y, dx, dy].\nGrimson, W. E. L. et al [2] cluster trajectories\nbased on the flow vector, f, and object size.  The\nvectors are clustered by a K-means algorithm.\nThe input data is replaced by the flow vector\nassigned to the nearest cluster centre, giving a\ndiscrete description of the feature vector.  The co-\noccurrence of these descriptor states is then used\nto classify future sequences as familiar or novel.\nJohnson, N. and Hogg, D. [3] describe a\nmodel-free method for representing trajectory\ndistributions.  Flow vectors, generated from\nrecorded trajectories, are used to train the\ndistribution prototype vectors of a competitive\nneural network.  Sequences of prototype flow\nvectors are fed to a network of neurons with\nshort-term memory (STM), which retain traces of\nprevious activations, capturing the recent history\nof each flow vector in the sequence.   These time-\nsmoothed vector sequences are used to train\nanother competitive network, which can be used\nto classify future instances of learned trajectories.\nAs the traces held in the short-term memory are\ntrajectory specific, the activations must be reset to\nzero during learning to avoid interference\nbetween trajectory representations.  This implies\nthat, during classification, a separate network\nmust be instantiated for each trajectory under\nconsideration, to prevent the memory traces from\ninterfering in STM.\nWe present a novel approach to model-free\nnovelty detection, based on converting trajectories\nto a fixed length trajectory vector, which can be\nsubmitted to a Self-Organising Feature Map [4].\nThis is similar to the approach of Johnson, N. and\nHogg, D. [3] in that the neural network in essence\nlearns the distribution of training trajectories, and\nclassifies outlying trajectories as novel.  The key\ndifference is that in our network, smoothing is\nperformed as a pre-processing step, resulting in a\nsimpler network structure, which is optimised to\nwork with partial trajectories, allowing real-time\nnovelty detection.  In contrast, Johnson and\nHogg\u2019s model is primarily designed to work with\ncomplete trajectories represented in STM.\n4. Trajectory Encoding\nThe information recorded by the object tracker\nis a sequence of centroid points for each tracked\nobject, as illustrated in figures 2 and 3.  A number\nof video sequences were recorded and divided\ninto two sub-sets. The training sequences were\ncaptured during normal use at the test site.  The\ntest sequences were a deliberately produced\nmixture of normal and abnormal sequences.\nFigure 2 shows an example of a normal trajectory,\ncharacterised by relatively smooth, uni-directional\nmotion.  Figure 3 gives an example of the kind of\nerratic, unusual behaviour that we would like the\nsystem to classify as abnormal.  The trajectory\nhas the unusual characteristics of highly non-\nuniform velocity, with large direction changes.\nFor real-time use, the system needs to monitor\ntrajectories as they are generated, rather than\nwaiting until a complete path is created.  We\ntherefore seek a scheme that encodes any partial\nor complete trajectory as a fixed length vector,\nsuitable for novelty detection.\nStarting with the flow vector, f = [x, y, dx. dy],\nwe added second order information, intuitively\nmotivated by the concept that the rate of velocity\nchange could provide additional discrimination\nbetween normal and unusual behaviour.  For\nexample,  relatively low rates of velocity change\nare seen in normal pedestrian motion, while a\n0-7695-0698-04\/00 $10.00 \u0001 2000 IEEE \n4Figure 2.  An example of\na normal trajectory,\noverlaid on a frame\nfrom the sequence.\nFigure 3. (a)  An unusual\ntrajectory.  The unusual\npoints are shown in\nblack (see section 6).\nFigure 3. (b)  The same\ntrajectory as in (a) with\nnovel points detected\nusing flow vectors only.\n0-7695-0698-04\/00 $10.00 \u0001 2000 IEEE \n5pedestrian moving in between parked vehicles\nshows high rates of velocity change as the path\nreverses direction.  The position, first and second\norder elements in the vector give the\ninstantaneous characteristics of the object motion,\nso in an effort to build a vector that contains\ninformation regarding previous behaviour of the\nobject, a time-smoothing function was applied to\nthe elements in the vector.\nIt is possible to construct the vector using all\ninstantaneous elements with a smoothed value for\neach.  However, the feature vector used in the\nfollowing experiments was made up of a subset of\nthese elements,\nF = [ x, y, s(x), s(y), s(dx), s(dy), s(|d2x|), s(|d2y|) ]\nwhere the function s(.) indicates a time smoothed\naverage of the quantity, and the first and second\norder differences, dx and d2x, are given by the\nfollowing:\ndx = xt \u2013 xt\u20131, and\nd2x =  xt \u2013 2xt\u20131 + xt\u20132.\nThe smoothing function s(.) implements a\nmoving average window, and is defined as\nst(x) = (\u00b5)(st\u20131(x)) + (1\u2013\u00b5)(x) ,\nwhere \u00b5 controls the update rate of the smoothed\nvariable, and is between 0 and 1.  The feature\nvector F contains the (x, y) position together with\na \u201cshort-term memory\u201d of the recent position, and\nthe first and second order motion of the object.\nTherefore, even if an unusual trajectory falls in a\nwell-traversed location, the feature vector should\ndiffer substantially to normal vectors along the\ndimensions that have a memory of the recent\nmotion of the object (for example, the \u2018doubling-\nback\u2019 that is seen as the pedestrian in figure 3\nmoves in between parked vehicles will rarely be\nseen in normal pedestrian motion).  Each\nindividual point in the trajectory is translated into\na feature vector, and as the feature vector is of\nfixed length, it is suitable for classification by the\nneural network.\n5. The Self-Organising Feature Map\nThe self-organising feature map (SOFM), or\nKohonen network, is a two layer neural network\nthat is able to \u201clearn\u201d to represent distributions of\nthe data presented to it.\nA schematic of the network is shown in figure\n4.\nFigure 4..  The basic self-organising map\n(for clarity, only connections from the first\nunit in the input layer are shown).\nThe input layer has one unit for each element\nof the feature vector.  Each unit in the output\nlayer is joined to the input units by a set of\nconnections, which store an exemplar vector.\nDuring training, the \u2018winning\u2019 neuron is the one\nwhose weight vector is the smallest Euclidean\ndistance to the input vector.\nThe weight vector for the winning neuron is\nupdated using the following rule,\n            m(t+1) = m(t) + \u03b7 [ x(t) \u2013 m(t) ] ,\nwhere x(t) is the training example, m(t) is the\ncurrent weight vector, m(t+1) is the new weight\nvector and \u03b7 is a learning rate.  In addition to the\nwinning neuron, a number of units in its\nneighbourhood (i.e. close in position on the two\ndimensional topological grid) are also updated\nusing the above rule.\nTraining progresses through a number of\nepochs, during which the learning rate and\nneighbourhood are progressively reduced.\nTraining falls roughly into two phases: a rough\nordering phase, during which neurons in discrete\nareas of the network learn to correspond to coarse\nclusters in the data, and a fine tuning phase during\nwhich individual neurons adjust to reflect fine\ndistinctions.\nSelf-organising features maps are widely used\nfor novelty detection [10].  Advantages over\nclustering techniques include: robustness, the\nability to be used in on-line mode (i.e. learning\nadditional new normal cases when they arise), and\nthe ability to use the topological map for\nInput\nLayer\n2D Output Layer\nF[0]\nF[1]\nF[n]\n0-7695-0698-04\/00 $10.00 \u0001 2000 IEEE \n6visualisation purposes (cluster discovery and\nidentification).\nDuring surveillance, the feature vector is\nsubmitted to the SOFM, the winning neuron is\nidentified, and the Euclidean distance between the\nfeature vector and the winning neuron's exemplar\nvector is calculated. If this distance exceeds a\nthreshold value then the feature vector is\nconsidered novel, and the trajectory is identified\nas suspicious.\nThe threshold value is calculated at the end of\nthe training process, by determining the\nmaximum distance of the training vectors from\nwinning neurons.  We set the threshold to half\nthis value.  Adjusting the threshold alters the\nbalance between false positive and false negative\nerrors.  Maintaining a threshold which would\nclassify all training data correctly may lead to\ngenuinely unusual points being classified as\nnormal.  This occurs because, after training, there\nmay be normal points that have not become well\nrepresented by the network and are a significant\ndistance from the closest neuron centre.\nEnlarging the accept threshold to encompass\nthese outlying points would expand the boundary\nof normality into the regions that we would\ntypically like to classify as unusual.  Setting the\nthreshold to a fraction of the maximum value will\nensure that the network maintains sensitivity to\nnew novel data.\n6. Experimental Results\nThe feature vector F was generated from the\ntrajectory data with the following \u00b5 values for the\nsmoothing functions:\n\u2022 Position, \u00b5 = 0.9\n\u2022 First order difference, \u00b5 = 0.96\n\u2022 Second order difference, \u00b5 = 0.96\nThe higher update rate for the positional\ninformation was used to eliminate the noise\ngenerated by the tracker (cf. figs. 2 & 3) whilst\nretaining the essential shape of the trajectory.\nThe training data consisted of 206 normal\ntrajectories, containing 7,482 points.  The test set\nincluded 23 unusual trajectories and 16 normal\ntrajectories, containing 2,174 and 694 points\nrespectively.\nThe self-organising map had eight input units,\nconnected to a grid of 11x10 output units.  The\nresults can be summarised as follows:\nCorrect classifications:\n36\/39 =   92%\nUnusual trajectories correctly classified:\n23\/23 = 100%\nNormal trajectories correctly classified:\n13\/16 =   81%\nIt should be noted that a complete trajectory\nwas classified as unusual if it contained two or\nmore points classified as unusual.\nThis classification rate of 92% is good given\nthat the training set was rather small.  The effect\nof the small training set can be illustrated by\nexamining more closely one of the misclassified\nnormal trajectories.\nOne of the three normal trajectories classified\nas unusual, traced a pedestrian moving from the\ncar in the bottom left of the image to the car-park\nexit at the bottom of the image (cf. fig. 3).   Upon\nexamination of the training set, it was found that a\ntrajectory in this location and direction was only\nrepresented once in the training set.  Given the\nnature of SOFM training, the representation of a\nsingle instance of a trajectory can be\noverwhelmed by the more numerous training\nexamples.  This is indicative of the largest\nproblem with the model-free approach to novelty\ndetection \u2013 if the training data is not sufficiently\ncomprehensive, then novel but actually acceptable\nbehaviour will be classified as suspicious.  This\nimplies a requirement to update the neural\nnetwork online with newly-detected normal\ntrajectories when they occur.\nWhat features are being used by the system\nwhen detecting novel behaviour?  To examine\nmore closely the mechanism of classification, a\nseparate network was trained using the flow\nvectors, f = [x, y, dx, dy], with no time smoothing\nor second order information.\nFigure 3 shows one of the unusual trajectories\nin the test set.  Figure 3(b) shows the sixteen\npoints (out of 158 points) detected as novel when\nonly the flow vectors were used.  As most of the\ntrajectories in the training set typically traced\nvertical motion, the flow vectors describing\nlateral movement were detected as novel, and in\nparticular, lateral motion of large magnitude (fig.\n3(b)).  In other words, novel points are instances\nin which a trajectory segment was either in an\nunfamiliar orientation, or of an unfamiliar\nmagnitude (i.e. unusual speed).  However, global\nfeatures of the trajectory were not well\nrepresented using the flow vectors.  For example,\nthe erratic direction changes in between the\nparked vehicles of figure 3 was not detected to a\nsignificant degree.\n0-7695-0698-04\/00 $10.00 \u0001 2000 IEEE \n7To capture the global properties of object\nmotion, we added second order information and a\nmoving average function to the feature elements,\nas described in section 4.  Figure 3(a) shows the\nnovel points (marked in black) as detected using\nthe full feature vector.  A total of 131 out of 158\npoints were classified as novel for this trajectory.\nThe first two unusual points occur after the\npedestrian deviates slightly from his original\ncourse, but at this point the trajectory is not\noverly suspicious.  However, more points are\nclassified as unusual when the pedestrian doubles\nback on his path while moving between the\nparked vehicles.  It should be noted that the\nabsolute value of the second order changes was\nused so that the smoothed value would be\ncumulative, avoiding the possibility that an erratic\nzigzag motion could cancel out over time and\nproduce a smoothed value that tended to zero.\nAs shown in figure 3(b), if instantaneous\nmotion alone is used for classification, most\nindividual flow vectors will have been\nencountered in the training set and will therefore\nbe seen as normal.  However, the sequence in\nwhich the flow vectors occur, the global\nproperties of the object motion, should be\nconsidered to properly classify the trajectory.\n7. Conclusion\nWe have demonstrated that trajectory\nclassification is possible using a model-free\nneural network approach, provided that the\ntraining data is sufficiently representative of the\nfull range of normal behaviour.  Applying a\nmoving average window to the motion\ninformation allows the classifier to examine\nglobal information, such as the object\u2019s present\nmotion in relation to motion in the past.  This\nallows the system to detect globally unusual\nbehaviour, such as erratic direction changes\noccurring at an otherwise normal speed.\nMoreover, the system is computationally simple\nenough to be used in real-time on a standard PC.\nThe major limitation of the approach is that\nprior knowledge is difficult to build into self-\norganising networks, and the system is unable to\ndifferentiate between normal paths that have not\nbeen previously seen and genuinely suspicious\nbehaviour.\nFuture work will involve integration of the\nTrajectory Classifier with existing systems we\nhave developed to update a neural network based\nnovelty detector on-line, as \"unusual\" events are\nprocessed and labelled as normal by the user.\nIn addition, we may attempt to add a predictive\nelement to the trajectory classification.  This\nwould entail using a partial trajectory to generate\na pool of potential normal trajectories that would\nsatisfactorily complete the path being traced.\nThis set of normal paths could be refined using\nevidence obtained from the actual object motion.\nSuch a scheme would allow more robust event\ndetection.  For example, the pool of normal\ntrajectories available to the system could be\nsubject to short-term heuristic changes; a\ntrajectory considered normal during working\nhours could be removed from the normal set\nduring the hours of darkness.  In other words,\n\u201cnormality\u201d is subject to the environment.  The\npool of normal trajectories could also evolve over\nthe long-term, with trajectories that have not been\nused for some time being removed from the\nnormality set.\n8. References\n1. Foresti, G. L.  \u201cA Real-Time System for Video\nSurveillance of Unattended Outdoor\nEnvironments,\u201d IEEE Trans. Circuits and Systems\nfor Video Technology, vol. 8, no. 6, 1998.\n2. Grimson, W. E. L., Stauffer, C., Romano, R. and\nLee, L.  \u201cUsing Adaptive Tracking to Classify and\nMonitor Activities in a Site,\u201d Proc. of CVPR,\n1998.\n3. Johnson, N. and Hogg, D.  \u201cLearning the\nDistribution of Object Trajectories for Event\nRecognition,\u201d Proc. BMVC, vol. 2, 1995.\n4. Kohonen, T.  \u201cSelf-Organising Maps,\u201d Springer-\nVerlag, 1995.\n5. Makarov, A.  \u201cComparison of Background\nExtraction Based Intrusion Detection Algorithms,\u201d\nIEEE Int. Conf. Image Processing, 1996.\n6. Remagnino, P., Bumberg, A., Grove, T., Hogg,\nD., Tan, T., Worral, A. and Baker, K.  \u201cAn\nIntegrated Traffic and Pedestrian Model-Based\nVision System,\u201d Proc. BMVC, vol. 2, 1997.\n7. Remagnino, P., Tan, T., and Baker, K.  \u201cAgent\nOrientated Annotation in Model Based Visual\nSurveillance,\u201d Proc. of ICCV, 1998.\n8. Skifstad, K. and Jain, A.  \u201cIllumination\nIndependent Change Detection for Real World\nSequences,\u201d Computer Vision, Graphics, and\nImage Processing, vol. 46, 1989.\n9. Stauffer, C. and Grimson, W. E. L.  \u201cAdaptive\nBackground Mixture Models for Real-Time\nTracking,\u201d Proc. of CVPR, 1999.\n10. Taylor, O., Tait, J. and MacIntyre, J.  \u201cImproved\nClassification for a Data Fusing Kohonen Self-\nOrganising Map Using a Dynamic Thresholding\nTechnique,\u201d Proc. of IJCAI, vol. 2, 1999.\n0-7695-0698-04\/00 $10.00 \u0001 2000 IEEE \n"}
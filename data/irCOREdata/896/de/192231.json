{"doi":"10.1109\/AICCSA.2008.4493674","coreId":"192231","oai":"oai:lra.le.ac.uk:2381\/4190","identifiers":["oai:lra.le.ac.uk:2381\/4190","10.1109\/AICCSA.2008.4493674"],"title":"Development Guidelines for Dependable Real-Time Embedded Systems.","authors":["Short, Michael J."],"enrichments":{"references":[{"id":44641080,"title":"A comparison of fixed-priority and static cyclic scheduling for distributed automotive control applications. In:","authors":[],"date":"1999","doi":"10.1109\/emrts.1999.777460","raw":"Lonn, H., and Axelsson, J. (1999). A comparison of fixed-priority and static cyclic scheduling for distributed automotive control applications. In: Proc. 11th Euromicro Conf. on Real-Time Systems, York, UK, 9\u201311 June 1999, pp. 142\u2013149.","cites":null},{"id":44641112,"title":"A Tool for Checking ANSI C Programs. In: Tools and Algorithms for the Construction and Analysis of Systems (TACAS","authors":[],"date":"2004","doi":"10.1007\/978-3-540-24730-2_15","raw":"Clarke, E., Kroening, D. and Lerda, F. A Tool for Checking ANSI C Programs. In: Tools and Algorithms for the Construction and Analysis of Systems (TACAS 2004), pp. 168-176, 2004.","cites":null},{"id":44641106,"title":"Assessment of high-integrity embedded automotive control systems using hardware-inthe-loop techniques.","authors":[],"date":"2007","doi":"10.1016\/j.jss.2007.08.026","raw":"Short, M and Pont, M.J. Assessment of high-integrity embedded automotive control systems using hardware-inthe-loop techniques. Journal of Systems and Software, Article in press, 2007.","cites":null},{"id":44641098,"title":"Automatically configuring time-triggered schedulers for use with resource-constrained, single-processor embedded systems&quot;,","authors":[],"date":"2007","doi":"10.1109\/tii.2008.916053","raw":"Gendy, A.K. and Pont, M.J. &quot;Automatically configuring time-triggered schedulers for use with resource-constrained, single-processor embedded systems&quot;, IEEE Transactions on Industrial Informatics, Article in press, 2007.","cites":null},{"id":44641110,"title":"Bounded Model Checking.","authors":[],"date":"2003","doi":"10.1007\/978-3-540-45069-6_7","raw":"Biere, A. Cimatti, A., Clarke, E., Strichman, O. and Zhu. Y. Bounded Model Checking. In Advances in Computers, Vol. 58, Academic press, 2003.","cites":null},{"id":44641066,"title":"C Application Requirement Considerations,&quot;","authors":[],"date":"1993","doi":null,"raw":"SAE, &quot;Class C Application Requirement Considerations,&quot; SAE Recommended Practice J2056\/1, SAE, June 1993.","cites":null},{"id":44641076,"title":"Comparison of event-triggered and timetriggered concepts with regard to distributed control systems,\u201d","authors":[],"date":null,"doi":null,"raw":"A. Albert, \u201cComparison of event-triggered and timetriggered concepts with regard to distributed control systems,\u201d in Proceedings of Embedded World, Nurnberg, Germany, 17-19 Feb, pp. 235-252, 2004.","cites":null},{"id":44641064,"title":"Development guidelines for vehicle-based software,\u201d Motor Industry Software Reliability Report,","authors":[],"date":"1994","doi":null,"raw":"MISRA, \u201cDevelopment guidelines for vehicle-based software,\u201d Motor Industry Software Reliability Report, November 1994.","cites":null},{"id":44641094,"title":"Engineering and analysis of fixed-priority schedulers.","authors":[],"date":"1993","doi":"10.1109\/32.241774","raw":"Katcher, D. I., Arakawa, H., and Strosnider, J. K. Engineering and analysis of fixed-priority schedulers. IEEE Trans. on Software Engineering, Vol. 19, No. 9, pp. 920-934, 1993.","cites":null},{"id":44641079,"title":"Event-Triggered Versus TimeTriggered Real-Time Systems.","authors":[],"date":"1991","doi":"10.1007\/bfb0024530","raw":"Kopetz, H. (1991). Event-Triggered Versus TimeTriggered Real-Time Systems. Lecture Notes in Computer Science, Vol 563, pp 87-101. Springer-Verlag, Berlin\/New York, 1991.","cites":null},{"id":44641102,"title":"Exploring the Influence of Preemption on Dependability in Time-Triggered Embedded Systems: a Preliminary Study.","authors":[],"date":"2008","doi":"10.1109\/ecrts.2008.14","raw":"Short, M, Pont, M.J and Fang, J. Exploring the Influence of Preemption on Dependability in Time-Triggered Embedded Systems: a Preliminary Study. Paper to be presented at the 20th Euromicro Conference on Real-time Systems (ECRTS 2008).","cites":null},{"id":44641114,"title":"Fault Injection and Dependability Evaluation of Fault-Tolerant Systems.","authors":[],"date":"1993","doi":"10.1109\/12.238482","raw":"Arlat, J., Costas, A., Crouzet, Y., Laprie, J-C and Powell, D. (1993). Fault Injection and Dependability Evaluation of Fault-Tolerant Systems. IEEE Trans. Computers, Vol. 42, No. 8, pp. 913-923.","cites":null},{"id":44641073,"title":"Fault-tolerant, timetriggered communication using CAN.","authors":[],"date":"2007","doi":"10.1109\/tii.2007.898477","raw":"Short, M. and Pont, M.J. (2007). Fault-tolerant, timetriggered communication using CAN. IEEE Transactions on Industrial Informatics, Vol. 3, No. 2, pp. 131-142.","cites":null},{"id":44641072,"title":"Faulttolerant drive-By-Wire Systems,","authors":[],"date":"2002","doi":null,"raw":"Iserman, R., Schwarz, R. and Stoltz, S. (2002). Faulttolerant drive-By-Wire Systems, IEEE Control Systems Magazine, Vol. 22, No. 5, pp. 64-81, 2002.","cites":null},{"id":44641101,"title":"Fixed Priority Scheduling versus Pre-Run-Time Scheduling.","authors":[],"date":"2000","doi":null,"raw":"Xu, J. and Parnas, D.L. (2000). Fixed Priority Scheduling versus Pre-Run-Time Scheduling. Real-Time Systems, Vol. 18, pp. 7-23, 2000.","cites":null},{"id":44641068,"title":"Functional safety of electrical\/electronic\/ programmable electronic safety-related systems,","authors":[],"date":"2000","doi":"10.3403\/03263848u","raw":"IEC 61508 - Functional safety of electrical\/electronic\/ programmable electronic safety-related systems, Part 3. (2000).","cites":null},{"id":44641065,"title":"Guidelines for the use of the C language in vehicle based software. Motor Industry Software Reliability Report,","authors":[],"date":"2004","doi":null,"raw":"MISRA. (2004). Guidelines for the use of the C language in vehicle based software. Motor Industry Software Reliability Report, Released October 2004.","cites":null},{"id":44641074,"title":"Handbook - Reliability Prediction of Electronic Equipment. Department of Defence,","authors":[],"date":"1990","doi":null,"raw":"MIL-HDBK-217F. Military Handbook - Reliability Prediction of Electronic Equipment. Department of Defence, Washington DC, 1990.","cites":null},{"id":44641075,"title":"Hard real-time computing systems: predictable scheduling algorithms and applications.","authors":[],"date":"1997","doi":"10.1016\/s0898-1221(98)90205-x","raw":"Buttazo, G. (1997). Hard real-time computing systems: predictable scheduling algorithms and applications. Kluwer Publishers, Norwell, MA., 1997.","cites":null},{"id":44641096,"title":"On nonpreemptive scheduling of periodic and sporadic tasks.","authors":[],"date":"1991","doi":"10.1109\/real.1991.160366","raw":"Jeffay, K., Stanat, D.F. and Martel, C.U. On nonpreemptive scheduling of periodic and sporadic tasks. In Proceedings of the 12th IEEE Symposium on Real-Time Systems, pp. 129-139, 1991.","cites":null},{"id":44641070,"title":"Patterns for time-triggered embedded systems: Building reliable applications with the 8051 family of microcontrollers,","authors":[],"date":"2001","doi":null,"raw":"M.J. Pont, Patterns for time-triggered embedded systems: Building reliable applications with the 8051 family of microcontrollers, ACM Press \/ Addison-Wesley Publishing, 2001.","cites":null},{"id":44641062,"title":"Safety Critical Computer Systems,","authors":[],"date":"1996","doi":null,"raw":"N. Storey, Safety Critical Computer Systems, Addison Wesley Publishing, 1996.","cites":null},{"id":44641063,"title":"Safeware: System Safety and Computers,","authors":[],"date":"1995","doi":"10.1016\/0898-1221(95)90203-1","raw":"N.G. Levenson, Safeware: System Safety and Computers, Reading, M.A., Addison-Wesley, 1995.","cites":null},{"id":44641077,"title":"Scheduling and timing analysis for safety critical real-time systems,\u201d","authors":[],"date":"1998","doi":null,"raw":"I.J. Bate, \u201cScheduling and timing analysis for safety critical real-time systems,\u201d PhD. dissertation, Department of Computer Science, University of York, November 1998.","cites":null},{"id":44641104,"title":"Software-based self-testing of microprocessors.","authors":[],"date":"2006","doi":"10.1016\/j.sysarc.2005.05.004","raw":"Sosnowski, J. (2006). Software-based self-testing of microprocessors. Journal of Systems Architecture, Vol. 52, pp. 257-271, 2006.","cites":null},{"id":44641071,"title":"Specification Version 2.0, Robert Bosch GmbH,","authors":[],"date":"1991","doi":"10.1007\/springerreference_75891","raw":"Bosch, CAN Specification Version 2.0, Robert Bosch GmbH, 1991.","cites":null},{"id":44641108,"title":"The infeasibility of Quantifying the Reliability of Life-Critical Real-Time Software.","authors":[],"date":"1993","doi":"10.1109\/32.210303","raw":"Butler, R.W. and Finelli, G.B. (1993). The infeasibility of Quantifying the Reliability of Life-Critical Real-Time Software. IEEE Transactions on Software Engineering, Vol. 19, No. 1, pp. 3-12.","cites":null},{"id":44641067,"title":"The Power of Ten: Rules for Developing Safety Critical Code.","authors":[],"date":"2006","doi":"10.1109\/mc.2006.212","raw":"Holzmann, G.J. (2006). The Power of Ten: Rules for Developing Safety Critical Code. IEEE Computer, Vol. 39, No. 6, pp. 93-95, June 2006.","cites":null},{"id":44641069,"title":"Writing solid code.","authors":[],"date":"1993","doi":null,"raw":"Maguire, S. Writing solid code. Microsoft Press, 1993.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-04","abstract":"Embedded control systems play an increasing role in many safety critical system designs. The correct and dependable implementation of such systems depends on many factors, including the design of system hardware, software and fault tolerance mechanisms,\\ud\nthe choice of programming language, and also the testing, verification and validation techniques employed. In this paper, a set of guidelines for the development of dependable embedded systems is presented. Although the paper is primarily concerned with single-processor applications, extensions to multiprocessor systems are discussed where appropriate. Although the creation of dependable embedded systems cannot simply rely on the enforcement of several such rules or guidelines, experience gained\\ud\nfrom several years\u2019 experience of teaching, research and development in these areas indicates that adherence to a small, but workable, set of rules and guidelines can avoid many of the traps and pitfalls\\ud\ncommonly encountered in the creation of dependable embedded systems","downloadUrl":"http:\/\/ieeexplore.ieee.org\/.","fullTextIdentifier":"https:\/\/lra.le.ac.uk\/bitstream\/2381\/4190\/1\/MJS%20-%20AICSSA%20-%202008.pdf","pdfHashValue":"8cb6a4cfcec0a0a1d4be8035714f534854d22a29","publisher":"Institute of Electrical and Electronics Engineers (IEEE).","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:lra.le.ac.uk:2381\/4190<\/identifier><datestamp>\n                2016-03-21T09:35:02Z<\/datestamp><setSpec>\n                com_2381_171<\/setSpec><setSpec>\n                com_2381_9549<\/setSpec><setSpec>\n                col_2381_172<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nDevelopment Guidelines for Dependable Real-Time Embedded Systems.<\/dc:title><dc:creator>\nShort, Michael J.<\/dc:creator><dc:description>\nEmbedded control systems play an increasing role in many safety critical system designs. The correct and dependable implementation of such systems depends on many factors, including the design of system hardware, software and fault tolerance mechanisms,\\ud\nthe choice of programming language, and also the testing, verification and validation techniques employed. In this paper, a set of guidelines for the development of dependable embedded systems is presented. Although the paper is primarily concerned with single-processor applications, extensions to multiprocessor systems are discussed where appropriate. Although the creation of dependable embedded systems cannot simply rely on the enforcement of several such rules or guidelines, experience gained\\ud\nfrom several years\u2019 experience of teaching, research and development in these areas indicates that adherence to a small, but workable, set of rules and guidelines can avoid many of the traps and pitfalls\\ud\ncommonly encountered in the creation of dependable embedded systems.<\/dc:description><dc:date>\n2009-01-29T11:31:01Z<\/dc:date><dc:date>\n2009-01-29T11:31:01Z<\/dc:date><dc:date>\n2008-04<\/dc:date><dc:type>\nConference paper<\/dc:type><dc:identifier>\nComputer Systems and Applications - IEEE\/ACS International Conference on, AICCSA 2008, Art. No. 4493674, pp. 1032-1039.<\/dc:identifier><dc:identifier>\nhttp:\/\/ieeexplore.ieee.org\/xpl\/articleDetails.jsp?arnumber=4493674<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2381\/4190<\/dc:identifier><dc:identifier>\n10.1109\/AICCSA.2008.4493674<\/dc:identifier><dc:language>\nen<\/dc:language><dc:rights>\nThis is the author's final draft of the paper published as Computer Systems and Applications - IEEE\/ACS International Conference on, AICCSA 2008, Art. No. 4493674, pp. 1032-1039. Copyright \u00a9 2008 IEEE. The final version is available from http:\/\/ieeexplore.ieee.org\/. Doi: 10.1109\/AICCSA.2008.4493674. This material is posted here with permission of the IEEE. Such permission of the IEEE does not in any way imply IEEE endorsement of any of the University of Leicester\u2019s products or services. Internal or personal use of this material is permitted. However, permission to reprint\/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution must be obtained from the IEEE by writing to pubs-permissions@ieee.org. By choosing to view this document, you agree to all provisions of the copyright laws protecting it.<\/dc:rights><dc:publisher>\nInstitute of Electrical and Electronics Engineers (IEEE).<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2008,"topics":[],"subject":["Conference paper"],"fullText":"Paper Preprint \u2013 To Appear In: \nProceedings of the 6th IEEE AICSSA Conf. 2008 \nDevelopment Guidelines for Dependable Real-Time Embedded Systems \n \n \nMichael Short \nEmbedded Systems Laboratory, University of Leicester, Leicester, UK. \nmjs61@leicester.ac.uk \n \n \nAbstract \n \nEmbedded control systems play an increasing role \nin many safety critical system designs. The correct and \ndependable implementation of such systems depends \non many factors, including the design of system \nhardware, software and fault tolerance mechanisms, \nthe choice of programming language, and also the \ntesting, verification and validation techniques \nemployed. In this paper, a set of guidelines for the \ndevelopment of dependable embedded systems is \npresented. Although the paper is primarily concerned \nwith single-processor applications, extensions to multi-\nprocessor systems are discussed where appropriate. \nAlthough the creation of dependable embedded \nsystems cannot simply rely on the enforcement of \nseveral such rules or guidelines, experience gained \nfrom several years\u2019 experience of teaching, research \nand development in these areas indicates that \nadherence to a small, but workable, set of rules and \nguidelines can avoid many of the traps and pitfalls \ncommonly encountered in the creation of dependable \nembedded systems.  \n \n1. Introduction \n \nModern control systems are almost invariably \nimplemented using some form of embedded digital \ncomputer system. When such embedded systems are \nused in situations where their correct functioning is \nvital, special care must be taken to ensure that the \nsystem is dependable, in that it is both reliable, timely \nand functionally safe [1-7]. Special measures must \ntherefore be taken at all stages of the design process to \nensure that the required Safety Integrity Level (SIL) \nhas been achieved. The SIL of a system depends on the \nconsequences of system failures, which can be \ndetermined using risk assessment; a required \ndangerous failure rate \u03bbd is then assigned for a system \nbased on this risk. Demonstrating that the dangerous \nfailure rate for a system is at a specific level requires \nmany factors to be taken into consideration; a major \nelement in this process is the determination of \nreliability, safety, security and availability measures \nfor each sub-system and component as part of a safety \ncase. \nProspective designers of embedded systems have \nmany factors to consider \u2013 for example the choice of \nhardware \/ software architecture, programming \nlanguage and communications network - and many of \nthese decisions are known (or thought) to influence \nboth the performance and dependability of the \nresulting system (e.g. [3][4][5][6]). Some of the main \nfactors to be considered are illustrated in Figure 1. This \npaper is specifically concerned with general design \nguidelines and programming \/ testing techniques for \nuse in creating dependable real-time embedded \nsystems, programmed using a sub-set of the ANSI C \nlanguage; embedded C has become the choice of many \ndevelopers in these areas in recent years [4][6][9]. \n \n \nFigure 1. Dependable system design factors \n \nMost serous system developers use some form of \ndesign and coding guidelines, which define a set of \nground rules for the overall system design and the \nsoftware to be written. In this paper, a small \u2013 but \nhighly workable \u2013 set of rules and guidelines is \npresented. Although the creation of such systems \ncannot simply rely on the enforcement of several such \nrules or guidelines, experience gained from several \nyears\u2019 experience of teaching, research and \ndevelopment in these areas indicates that adherence to \na small, but workable, set of rules can avoid many of \nthe traps and pitfalls commonly encountered in the \ncreation of dependable embedded systems. \nThe rules and guidelines presented are divided in \nfour broad categories, and cover hardware design, \nsoftware design, programming guidelines and testing \ntechniques. In all cases the rules have been formulated \nto be consistent with much previous work in this area. \nFor example, the rules are consistent with the MISRA \ncoding guidelines [3][4] and IEC 61508 [11], and also \nmany previous works in this area \u2013 for example \n[1][2][5][6][8]. However, the discussion presented \nhere is intended to compliment these existing works, \nidentify the common best practice within them, and \nfocus their content from a real-time embedded \nperspective. \nThe remainder of the paper is organized as follows. \nIn Section II, general hardware considerations for real-\ntime embedded systems are discussed. In Section III, \nrecommendations are made for the software \narchitecture of the system. Section IV presents a \nsummary of what is considered to be the main \nrecommendations and rules applicable to the software \ndesign process. In Section V, recommendations \nregarding testing, verification and validation are \npresented. Finally in Section VI, the paper is \nconcluded. \n \n2. Hardware considerations \n \nFrom the hardware perspective, designers have the \nchoice of a number of different key system elements: \n \n\u2022 Microprocessor; \n\u2022 Memory; \n\u2022 Oscillator circuit; \n\u2022 Watchdog timer; \n\u2022 Off-chip peripherals; \n\u2022 Communication devices. \n \nA wealth of useful information regarding these \nchoices is discussed by [9]. In summary, the choice \nhardware elements is dictated by several factors, \nincluding the complexity and timing constraints of the \nsoftware functionality, required number of I\/O lines, \ncosts, and target environment. A sensible choice of \nprocessor would be to select a device with several \nyears\u2019 proven deployment, which is not likely to \nbecome discontinued in the immediate future. For \nsystems with a high SIL, then the use of specialized \nprocessor architectures is recommended. When using \ngeneral purpose processors, designers must be aware \nthat special measures must be implemented to protect \nagainst transient effects such as EMI and particle \nstrikes. Additionally, the processor may have \nundocumented test modes that may be inadvertently \ntriggered during normal operation. At the present time, \nthe 8-bit 8051 architecture, 16-bit (X)C167 \narchitecture and the 32-bit ARM-7 architectures (and \nclose variants) are good choices of general-purpose \nprocessors in a range of different performance levels. \nChoice of RAM memory will typically be dictated \nby the nature of software, with data-intensive systems \nobviously requiring larger memory requirements. \nHowever it should be remembered that when coding a \nsystem, the smaller the memory footprint, the less \nlikely the system is to suffer a data error. However, \nthere is a trade-off; in many cases sacrificing RAM \nusage will be at the expense of code execution time \nand ROM usage, which may affect the timeliness of \nthe system, to be discussed in the next section. \nFor a real-time system, the performance \u2013 and \nhence timeliness - of the system is highly dependant on \nthe availability of an accurate clock (hardware timer). \nSince such timers are almost totally reliant upon the \noscillator, then care must be taken in this aspect. The \nuse of a crystal oscillator over alternates (e.g. ceramic \nresonator) is recommended for stability reasons. For \nsystems that are to be subjected to high temperature \nfluctuations or excessive vibration, then a temperature \nand\/or vibration compensated oscillator circuit should \nbe considered. An oscillator watchdog circuit, in \nconjunction with a brownout\/reset circuit, should be \nconsidered mandatory [1][2][3][7][9]. \nThe use of a watchdog timer as a primary guard \nagainst transient faults should also be considered \nmandatory. When a general-purpose processor is to be \nemployed, then an external watchdog should be \nconsidered; as mentioned, such devices may have \nundocumented test modes that may be inadvertently \ntriggered during normal operation, in which the \nwatchdog timer is also disabled. If an external device \nis used, this condition is prevented by design. \nWhere possible, the use of on-chip peripherals for \nperforming functionality such as ADC conversion is \nrecommended, mainly to reduce the complexity of the \nsystem; and also to reduce the number of components \nand IC\u2019s in the design, which in general will decrease \nthe overall hardware failure rate. However, when cost \nor performance constraints dictate that additional \ncomponents must be employed, then the use of field-\nproven, high-reliability devices is recommended. \nIn multiprocessor systems, some form of shared \ncommunications network is employed to allow the \ndevices to communicate. In these systems, care must \nbe taken to provide fault tolerance in this medium, as it \nprovides a single point of failure. In many safety-\nrelated protocols this fault-tolerance is pre-designed \ninto the network in the form of bus-guardians, \nredundant cabling media, and fault-tolerant clock \nsynchronization. However, if a more general purpose \nnetwork is to be employed \u2013 such as the CAN protocol \n[10] or the RS-485 standard \u2013 then special \nconsiderations need to be taken to ensure fault-\ntolerance. Further details may be found in [9][11][12]. \nIn all cases, determination of the overall reliability \nof the components in the system should be performed - \nusing suitable analysis techniques [1][13] - to ensure \nthat the failure rate is commensurate with the SIL of \nthe system. \n \n3. Software considerations \n \n3.1 Design paradigm \n \nFrom the software perspective, designers may choose \nto implement a system based around four (highly inter-\nrelated) categories [14]: \n \n\u2022 Time-triggered; \n\u2022 Event-triggered; \n\u2022 Preemptive; \n\u2022 Non-preemptive (co-operative). \n \nFrom the perspective of the dependable systems \ndesigner, a wealth of previous research has argued that \nthe use of event-triggered systems should, in the main, \nbe avoided where possible. Instead, the use of time-\ntriggered techniques for both communications and task \nscheduling should be considered, as this is known to \nimprove the system predictability considerably \n[9][15][16][17][18].  \nFrom the time-triggered perspective, it is common \nto represent a real-time system as a number of \ncommunicating tasks, where each task t in the task set \n\u03c4 is represented by a four-tuple: \n ( )iiiii rdcpt ,,,=  \n(1) \n \nIn which pi is the task period, ci is the worst case \ncomputation time of the task, di is the task deadline \nand ri is the task release time, represented as whole \nintegers in suitable processor time units, for example \nmicroseconds. With such a representation, it is normal \nto assume the following: \n \niiiii pcrdp <<\u2265>= 0,0  \n(2) \n \ni.e. with the task deadline equal to its period and \nrelease time and computation time less than the period. \nDetermination of the worst case computation time c of \neach task has been well covered in the literature, and \ncan be obtained by a variety of methods loosely termed \n\u2018code profiling\u2019. When the task computation times \nhave been determined, appropriate scheduling analysis \ncan be performed. This analysis is essentially a \ndecision procedure giving a yes\/no answer as to \nwhether the schedule is feasible or not. In the case of \nthe co-operative system, tasks must run to completion \nonce dispatched. When the release times in the task set \n\u03c4 are all equal, schedulability is decided by the \nfollowing equation [14]: \n \n),,gcd( 1\n1\nn\nni\ni\ni ppc K\u2264\u2211=\n=\n \n(3) \n \nWhere gcd is the greatest common divisor of the task \nset periods, i.e. the \u2018tick\u2019 interval of the scheduler. In \nthe pre-emptive case, tasks may interrupt each other\u2019s \nexecution based on their assigned priorities. When the \npriorities are assigned inversely proportional to the \ntask periods (which is known to be an optimal priority \nassignment), schedulability is decided as follows [14]: \n \n)12(\n1\n\u2212\u2264\u2211=\n=\nn\nni\ni i\ni n\np\nc\n \n(4) \n \nAgain, with all release times assumed equal. At first \nglance it would seem then that a greater CPU \nutilization may be achieved when implementing a \nsystem pre-emptively. However, these analyses do not \ninclude scheduler overhead \u2013 which are vastly \nincreased in the latter scheduler \u2013 and do not include \nblocking terms introduced by resource conflicts and \ndeadlock avoidance mechanisms associated with the \nlatter. A fuller analysis that includes the influence of \nthese mechanisms is given by Katcher et al. [19].  \nIn both cases, when the release times of the tasks are \nfree to be chosen by the designer (a so-called \u2018offset-\nfree\u2019 task set), then the achievable CPU utilization may \nbe increased (or decreased) by a large factor, \ndepending on the choice of release times. However, the \ncomplexity problems of deciding schedulability and \nassigning effective release times to tasks increases \ndramatically with such systems, and is known to be an \nNP-Complete problem [14][20]. Details of recent \nadvances in this area, producing (in most cases) \ntractable solutions, may be found in [21].  \nIn addition, it has also been argued that co-\noperative systems are both easier to inspect and verify \n[22] and exhibit greater tolerance to transient \ndisturbances [23] than equivalent preemptive systems. \nBased on these discussions, it is therefore \nrecommended to use co-operative scheduling when \ndeveloping safety-related systems. A suitable design \nfor a portable, efficient scheduler coded in embedded \nC is given in [9]. Although this paper is primarily \nconcerned with single-processor designs, this basic \nscheduler methodology can be extended to \nmultiprocessor designs (a \u2018shared-clock\u2019 scheduler), \nand can be implemented over multiple, redundant \ncommunication networks to great effect [12]. \n \n3.2 Runtime behavior \n \nIn addition to the avocation of time-triggered, co-\noperative scheduling, it is recommended that the \nsystem possesses a minimum number of run-time \nmechanisms to mitigate the effects of transient errors. \nThese mechanisms should include the use of a \nwatchdog timer, duplex duplication of critical data \nwith comparison, sanity checks of control signals, \nmechanisms to detect task overrun, and the enabling of \nall on-chip exception traps in the target processor. \nSuch traps will normally consist of most of the \nfollowing elements: \n \n\u2022 Stack overflow; \n\u2022 Stack underflow; \n\u2022 Illegal operand; \n\u2022 Illegal word access; \n\u2022 Protected instruction fault; \n\u2022 Divide by zero; \n\u2022 Illegal bus access. \n \nIn addition, all unused areas of ROM and RAM \nmemory should be filled with (or initialized to) illegal \noperands to provide added control flow error detection.  \nOn activation of any of these traps, a full system reset \nof the microcontroller should be forced. On system \nboot-up\/reset, the microcontroller should perform \u2013 at \nminimum - the following software-based self-tests \n[24]: \n \n\u2022 Internal RAM\/register\/stack validation; \n\u2022 External RAM validation; \n\u2022 ROM checksum; \n\u2022 Peripheral test (e.g. ports, timer). \n \nIf any of these tests are failed, the microcontroller \nmust activate any appropriate warning signals and then \nenter a safe state. The overall recommended approach \nto software fault-tolerance is illustrated in Figure 2. \nThe simple techniques presented here, although \nsomewhat dependant on the implementation hardware, \ntypically allow for transient error coverage in excess of \n95% [9][23][25]. Although some researchers have \nadvocated the use of specialized (software-based) \ntransient error detection mechanisms, in general it is \nrecommended that such techniques are avoided. This is \nbecause such techniques increase the system \ncomplexity considerably and oftentimes require the use \nof automatic code generators for their implementation, \nwhich may sometimes be problematic from a safety \nperspective and may cause problems with certification. \nAlthough the use of such code generators has many \npotential benefits, to date few such generators have \nbeen certified to the appropriate levels, and \u2013 at the \npresent time - their use should proceed with caution \n[1][3][4]. \n \n \nFigure 2. Software fault-tolerance \n \n4. Code development considerations \n \nIn this section, attention is now focused on \nguidelines and recommendations for the use of the C \nlanguage in such systems, and a basic set of guidelines \nfor software development in embedded C is presented. \nAlthough defining an exhaustive list of such guidelines \nis beyond the scope of this paper, the interested reader \nis referred to [1-8]. In essence, the list that is presented \naims to employ only the well defined features of the C \nlanguage in order to create bounded, predicable, \nreadable and maintainable code. \n \n4.1 Development Tools and Processes \n \nThe choice of compiler may have a great influence \non the quality of the resulting code. Typically a well-\nsupported compiler with a favorable, documented \nperformance level should be chosen. A development \nteam should have an \u2018in-house\u2019 coding style guide \nwhich is strictly adhered to, and when appropriate, \nversion control software should be employed in \naddition to (and integrated with) the in-house \ndocumentation and release control procedures.  \nCode must always be compiled with all warnings set \nto the maximum levels, and production code must \ncompile without a single such warning. The use of the \npreprocessor should primarily be limited to simple \n#include statements, #define constants, syntactically \nmeaningful macro definitions, and header guards \u2013 \nwhich - aside from the closing #endif of a header guard \n- are to be placed at the top of a file only. Conditional \ncompilation use must be limited and never span \nmultiple files. Language extensions \u2013 e.g. inline \nassembly \u2013 must be fully encapsulated and isolated. \nThe use of \u2018lightweight\u2019 static checking and source \ncode metrics tools should be a regular part of the \ndevelopment process; the use of \u2018heavyweight\u2019 formal \nmethods tools should be considered mandatory for \nsystems with a high SIL. This will be discussed further \nin Section V. \n \n4.2 Program Flow and Looping \n \nThe call graph of an embedded control system \nprogram should ideally be acyclic, and the potential \nnumber of loops and iterations performed by any \nsingle execution of any given system task should \nalways be bounded. This is required to prevent \nrunaway code and task overruns. In practice this means \nthat several main points should be adhered to in terms \nof control flow and looping. \nOnly the simple, compound control flow statements \nprovided by the C language should be used \u2013 the use of \ngoto, setjmp or longjmp constructs is prohibited. The \nuse of either direct or indirect recursion (functions or \nchains of functions which can call themselves) should \nbe avoided - use iterative functions instead.  \nInside each task, all loops that rely directly on non-\ndeterministic input - or the results of complex data \nmanipulation - for termination must have a fixed upper \nbound (loop timeout). The three expressions in a for \nloop must only be used for loop control, and numeric \nvariables used within a for loop for iteration control \nmust not be modified in the body of the loop. At most \na single break statement may be used in any single \nloop. Finally, the controlling expressions used in for or \nwhile loops should not, either directly or indirectly, use \nany floating point types. \n \n4.3 Functions \n \nObviously, functions are an integral part of all \nembedded C programs, and their correct and consistent \nuse is required to produce reliable code. Correct use of \nfunctions will typically include the following elements. \nAll functions should have a prototype. Ideally the \nidentifier names as well as types of any arguments \nshould be provided in this prototype. Functions should \nautomatically be declared at file scope (static), unless \nthey require external linkage. Functions shall not use \nvariable (variadic) argument lists.  \nWhere possible, parameters passed to a function \nshould be tested for validity, and if a function returns \nerror information, this information should be tested. \nThe use of the standard C errno facility should be \navoided. Where the return type of a function is non-\nvoid, all possible return paths should include an \nexplicit non-void return statement. Where possible, \nthere should only be a single point of return at the end \nof the function. \n \n4.4 Memory and Variables \n \nAs with functions, variables and data - and their \nmanagement in memory - are all integral parts of an \nembedded C program. However, their correct and \nconsistent usage is required to produce reliable, \nreadable code, and to ensure that testing can proceed \nefficiently. In particular, the following elements should \nbe observed. \nAll data objects must be declared at the lowest \npossible level of scope, with appropriate linkage \n(where required). All variables must be initialized \nbefore usage. Variables must not be reused for \nmultiple, incompatible purposes, and variables in a \nlocal scope shall not use the same identifier as \nvariables with a global or file scope.  \nPrograms must avoid dynamic data allocation, and \navoid the use of (built-in) library functions that make \nuse of dynamic memory allocation (e.g. string.h). \nAdditionally, the use of pointers is riddled with \npotential traps and pitfalls - even experienced \nprogrammers can become easily confused. Therefore, \nlimit the use of pointer indirection to a maximum of \ntwo levels; ideally one in most circumstances. Pointer \narithmetic must be limited to array indexing only. \nUninitialised pointers must never be used, and where \nappropriate checked that they are not NULL before \nuse. The address of an object should never be assigned \nto a pointer with a larger scope. And finally, restrict \nthe use of function pointers to scheduler \nimplementations only. \n \n4.5 Libraries \n \nThe creation, use and re-use of code libraries are an \nessential part of most software engineering processes. \nIt makes no sense to re-engineer solutions to problems \nthat have been well tackled in the past. However, there \nare a number of key points to adhere to in this respect. \nThese include the following main elements. \nAll libraries - with available source - shall be coded \nin accordance with the \u2018in-house\u2019 coding style, and \nshall adhere (where applicable) to strict ANSI \nguidelines. For libraries without available source code \n(e.g., from third party vendors), they must have \nappropriately documented, tested and verified \nbehavior. When libraries are reused from previous \nprojects, appropriate testing and verification should be \nperformed to confirm that the code performs as \nexpected in the new context. \nReserved macro\u2019s, functions and identifiers \ncontained in standard libraries must not be redefined, \nundefined or reused in any way. Arguments to, and \nreturn values from, library functions must be checked \nfor validity. Care must be taken when using functions \nfrom the standard libraries: a list of unsuitable features \nis as follows: stdio.h, time.h, setjmp.h, errno.h: do not \nuse these libraries at all. The following functions and \nmacro\u2019s in stdlib.h and stddef.h must not be used: \noffsetof, abort, exit, getenv, setenv, system, atof, atoi, \natol, calloc, malloc, realloc and free. In the following \nsection, attention is now turned to testing, verification \nand validation. \n \n5. Testing, verification and validation \n \nThe role of testing, in any software development \nprocess, is to find and remove software defects \n(\u2018bugs\u2019) through comparisons of the expected system \nbehavior (specification) with its actual behavior. When \ndeveloping dependable systems it is often \ninappropriate, unethical or even impossible to fully test \nthe system within its natural operational environment \n[1][2][25]. In such cases, HIL simulation of the \nsystem\u2019s environment can enable developers to make \nassessments of performance without compromising \nsafety. The principle of HIL simulation of an \nembedded control system is illustrated in Figure 3.  \n \n \nFigure 3. HIL simulation principle \n \nThe embedded system outputs are fed directly to the \nsimulation, where they are sampled and used as input \nvariables. Previous papers have discussed applications \nof HIL simulation to dependable system testing (e.g. \n[23][25]); its use is therefore highly recommended. \nTypically, software verification conditions \u2013 in the \nform of pre and post conditions implemented as sanity \nchecks - should be the primary means to detect \nanomalous conditions during testing. The form of a \ntypical C sanity check is shown in Figure 4, where \n__FILE__ and __LINE__ are macro\u2019s inserted by the \npreprocessor at compile time. The sanity check density \nshould be a minimum of two per function [1][2][4][6]. \n \n#define sanity_check(c) ((c) ? (true) : \\ \ndebug(\u201c%s, %d: sanity check \u2018%s\u2019 failed\u201d, \\ \n__FILE__, __LINE__, #c), false) \n \nFigure 4. Sanity check C macro \n \nHowever in software-based systems designed to have \na failure rate less than 10-4, such as those considered in \nthis paper, testing alone is impractical (on any \nreasonable timescale) and alternate means for complete \nverification must be considered [26]. This generally \nimplies that the use of formal methods should be \nintroduced. Such techniques employ mathematical \nmethods to determine whether software meets its \nspecifications, and provide documentary evidence that \nit is free from defects. Of the available formal methods \nthat may be employed in a specific situation, formal \nmodel checking has proven to be a highly popular and \nsuccessful technique which is well suited to many \ncritical embedded applications, and integrates well to \nexisting development and testing processes [27]. \n \n5.1 Formal Model Checking \n \nThe majority of model checking algorithms use \nKripke structures to formally represent the \ncomputations of a finite-state system. Kripke structures \nare essentially graphs in which nodes represent system \nstates and edges represent possible transitions between \nstates. A model checking algorithm is an automated \nalgorithm that decides whether a given Kripke \nstructure P is a model of (satisfies) the specification \u03c8. \nIn practice a number of extremely efficient bounded \nmodel checkers for the C programming language have \nbeen developed (for example [28]); for this reason, \nformal verification \u2013 in conjunction to exhaustive \ntesting \u2013 is recommended.  \nIf these techniques are correctly employed, then \u2013 in \nconjunction with exhaustive testing - it is possible to \nprove that all sanity checks will always be passed \nunder normal operating conditions. In this case, the \nsanity check macro given in Figure 4 may then be \neasily modified to reset the processor (as opposed to \noutputting a debug message) upon detection of an \nanomaly, as shown in Figure 5. Reset is simply a \nfunction (or macro) to reset the processor, either by \nissuing a software reset signal or, for example, by \ndisabling interrupts and entering an infinite loop to \ntrigger the watchdog. This provides an additional, low \ncost and highly effective method to detect and recover \nfrom transient failures in production code. \n \n#define sanity_check(c) ((c) ? (true) : \\ \nReset(), false) \n \nFigure 5. Run-time sanity check \n \n5.2 Fault Injection Testing \n \nIn most cases, dependable systems will be \nimplemented using some form of fault tolerance \n[9][11]. In such cases, fault injection is the preferred \nmeans for extracting dependability information as part \nof system validation exercises [29]. Additionally, one \nextremely promising area of research in this area has \nconcentrated on the use of fault-injection, in \ncombination with rare events techniques and \nautomated performance monitoring, to extract fault \ncoverage information for the calibration of \ndependability models [25]. This technique, although \nexperimental, is also recommended. \n \n6. Conclusions \n \nIn this paper, a set of development guidelines has \nbeen proposed for prospective designers of dependable \nembedded systems, covering basic hardware and \nsoftware foundations, programming guidelines and \nrecommendations for software testing and verification. \nEmbedded systems developed around such principles \nare typically capable of achieving an extremely high \nlevel of safety integrity. In conclusion, although the \nguidelines are not meant to be strictly enforced, it is \nhoped that they provide a sensible set of working rules \nto assist in future development of safety-related \nembedded systems. \n \n7. References \n \n[1] N. Storey, Safety Critical Computer Systems, Addison \nWesley Publishing, 1996. \n \n[2] N.G. Levenson, Safeware: System Safety and Computers, \nReading, M.A., Addison-Wesley, 1995. \n \n[3] MISRA, \u201cDevelopment guidelines for vehicle-based \nsoftware,\u201d Motor Industry Software Reliability Report, \nNovember 1994. \n \n[4] MISRA. (2004). Guidelines for the use of the C language \nin vehicle based software. Motor Industry Software \nReliability Report, Released October 2004. \n \n[5] SAE, \"Class C Application Requirement Considerations,\" \nSAE Recommended Practice J2056\/1, SAE, June 1993.  \n \n[6] Holzmann, G.J. (2006). The Power of Ten: Rules for \nDeveloping Safety Critical Code. IEEE Computer, Vol. 39, \nNo. 6, pp. 93-95, June 2006. \n \n[7] IEC 61508 - Functional safety of electrical\/electronic\/ \nprogrammable electronic safety-related systems, Part 3. \n(2000). \n \n[8] Maguire, S. Writing solid code. Microsoft Press, 1993. \n \n[9] M.J. Pont, Patterns for time-triggered embedded systems: \nBuilding reliable applications with the 8051 family of \nmicrocontrollers, ACM Press \/ Addison-Wesley Publishing, \n2001. \n \n[10] Bosch, CAN Specification Version 2.0, Robert Bosch \nGmbH, 1991. \n \n[11] Iserman, R., Schwarz, R. and Stoltz, S. (2002). Fault-\ntolerant drive-By-Wire Systems, IEEE Control Systems \nMagazine, Vol.  22, No.  5, pp.  64-81, 2002. \n \n[12] Short, M. and Pont, M.J. (2007). Fault-tolerant, time-\ntriggered communication using CAN. IEEE Transactions on \nIndustrial Informatics, Vol. 3, No. 2, pp. 131-142. \n \n[13] MIL-HDBK-217F. Military Handbook - Reliability \nPrediction of Electronic Equipment. Department of Defence, \nWashington DC, 1990. \n \n[14] Buttazo, G. (1997). Hard real-time computing systems: \npredictable scheduling algorithms and applications. Kluwer \nPublishers, Norwell, MA., 1997. \n \n[15] A. Albert, \u201cComparison of event-triggered and time-\ntriggered concepts with regard to distributed control \nsystems,\u201d in Proceedings of Embedded World, Nurnberg, \nGermany, 17-19 Feb, pp. 235-252, 2004. \n \n[16] I.J. Bate, \u201cScheduling and timing analysis for safety \ncritical real-time systems,\u201d PhD. dissertation, Department of \nComputer Science, University of York, November 1998. \n \n[17] Kopetz, H. (1991). Event-Triggered Versus Time-\nTriggered Real-Time Systems. Lecture Notes in Computer \nScience, Vol 563, pp 87-101. Springer-Verlag, Berlin\/New \nYork, 1991. \n \n[18] Lonn, H., and Axelsson, J. (1999). A comparison of \nfixed-priority and static cyclic scheduling for distributed \nautomotive control applications. In: Proc. 11th Euromicro \nConf. on Real-Time Systems, York, UK, 9\u201311 June 1999, \npp. 142\u2013149. \n \n[19] Katcher, D. I., Arakawa, H., and Strosnider, J. K. \nEngineering and analysis of fixed-priority schedulers. IEEE \nTrans. on Software Engineering, Vol. 19, No. 9, pp. 920-934, \n1993. \n \n[20] Jeffay, K., Stanat, D.F. and Martel, C.U. On non-\npreemptive scheduling of periodic and sporadic tasks. In \nProceedings of the 12th IEEE Symposium on Real-Time \nSystems, pp. 129-139, 1991. \n \n[21] Gendy, A.K. and Pont, M.J. \"Automatically configuring \ntime-triggered schedulers for use with resource-constrained, \nsingle-processor embedded systems\", IEEE Transactions on \nIndustrial Informatics, Article in press, 2007. \n \n[22] Xu, J. and Parnas, D.L. (2000). Fixed Priority \nScheduling versus Pre-Run-Time Scheduling. Real-Time \nSystems, Vol. 18, pp. 7-23, 2000. \n \n[23] Short, M, Pont, M.J and Fang, J. Exploring the \nInfluence of Preemption on Dependability in Time-Triggered \nEmbedded Systems: a Preliminary Study. Paper to be \npresented at the 20th Euromicro Conference on Real-time \nSystems (ECRTS 2008). \n \n[24] Sosnowski, J. (2006). Software-based self-testing of \nmicroprocessors. Journal of Systems Architecture, Vol. 52, \npp. 257-271, 2006. \n \n[25] Short, M and Pont, M.J. Assessment of high-integrity \nembedded automotive control systems using hardware-in-\nthe-loop techniques. Journal of Systems and Software, \nArticle in press, 2007. \n \n[26] Butler, R.W. and Finelli, G.B. (1993). The infeasibility \nof Quantifying the Reliability of Life-Critical Real-Time \nSoftware. IEEE Transactions on Software Engineering, Vol. \n19, No. 1, pp. 3-12. \n \n[27] Biere, A. Cimatti, A., Clarke, E., Strichman, O. and \nZhu. Y. Bounded Model Checking. In Advances in \nComputers, Vol. 58, Academic press, 2003. \n \n[28] Clarke, E., Kroening, D. and Lerda, F. A Tool for \nChecking ANSI C Programs. In: Tools and Algorithms for \nthe Construction and Analysis of Systems (TACAS 2004), \npp. 168-176, 2004. \n \n[29] Arlat, J., Costas, A., Crouzet, Y., Laprie, J-C and \nPowell, D. (1993). Fault Injection and Dependability \nEvaluation of Fault-Tolerant Systems. IEEE Trans. \nComputers, Vol. 42, No. 8, pp. 913-923. \n \n \n"}
{"doi":"10.1007\/s10670-013-9541-5","coreId":"219934","oai":"oai:eprints.lse.ac.uk:37075","identifiers":["oai:eprints.lse.ac.uk:37075","10.1007\/s10670-013-9541-5"],"title":"The best Humean system for statistical mechanics","authors":["Frigg, Roman","Hoefer, Carl"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2015","abstract":"Classical statistical mechanics posits probabilities for various events to occur, and these probabilities seem to be objective chances. This does not seem to sit well with the fact that the theory\u2019s time evolution is deterministic. We argue that the tension between the two is only apparent. We present a theory of Humean objective chance and show that chances thus understood are compatible with underlying determinism and provide an interpretation of the probabilities we find in Boltzmannian statistical mechanics","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/219934.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/37075\/1\/Humean_statistical%20analysis.pdf","pdfHashValue":"cc574871def6ff50b6c39904530741c98af7db9a","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:37075<\/identifier><datestamp>\n      2017-09-06T11:07:36Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5048<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/37075\/<\/dc:relation><dc:title>\n        The best Humean system for statistical mechanics<\/dc:title><dc:creator>\n        Frigg, Roman<\/dc:creator><dc:creator>\n        Hoefer, Carl<\/dc:creator><dc:subject>\n        B Philosophy (General)<\/dc:subject><dc:subject>\n        HA Statistics<\/dc:subject><dc:description>\n        Classical statistical mechanics posits probabilities for various events to occur, and these probabilities seem to be objective chances. This does not seem to sit well with the fact that the theory\u2019s time evolution is deterministic. We argue that the tension between the two is only apparent. We present a theory of Humean objective chance and show that chances thus understood are compatible with underlying determinism and provide an interpretation of the probabilities we find in Boltzmannian statistical mechanics.<\/dc:description><dc:publisher>\n        Springer<\/dc:publisher><dc:date>\n        2015<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/37075\/1\/Humean_statistical%20analysis.pdf<\/dc:identifier><dc:identifier>\n          Frigg, Roman and Hoefer, Carl  (2015) The best Humean system for statistical mechanics.  Erkenntnis, 80 (S3).  pp. 551-574.  ISSN 0165-0106     <\/dc:identifier><dc:relation>\n        http:\/\/www.springer.com\/philosophy\/journal\/10670<\/dc:relation><dc:relation>\n        10.1007\/s10670-013-9541-5<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":null,"relations":["http:\/\/eprints.lse.ac.uk\/37075\/","http:\/\/www.springer.com\/philosophy\/journal\/10670","10.1007\/s10670-013-9541-5"],"year":2015,"topics":["B Philosophy (General)","HA Statistics"],"subject":["Article","PeerReviewed"],"fullText":"  \nRoman Frigg and Carl Hoefer \nThe best Humean system for statistical \nmechanics \n \nArticle (Accepted version) \n(Refereed) \n \n \n Original citation: \nFrigg, Roman and Hoefer, Carl (2015) The best Humean system for statistical mechanics. \nErkenntnis, 80 (S3). pp. 551-574. ISSN 0165-0106  \nDOI: 10.1007\/s10670-013-9541-5 \n \n\u00a9 2013 Springer Science+Business Media Dordrecht \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/37075\/ \nAvailable in LSE Research Online: February 2016 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final accepted version of the journal article. There may be \ndifferences between this version and the published version.  You are advised to consult the \npublisher\u2019s version if you wish to cite from it. \n \n \n \n 1 \nThe Best Humean System for Statistical Mechanics \n \n \nRoman Frigg \nDepartment of Philosophy, Logic and Scientific Method \nLondon School of Economics and Political Science \nHoughton Street \nLondon WC2A 2AE \nUnited Kingdom \nEmail: r.p.frigg@lse.ac.uk  \nPhone: +44 20 7955 7182 \nFax:     +44 20 7955 6845 \n \nCarl Hoefer \nICREA Research Professor at the Universitat Aut\u00f2noma de Barcelona \nand \nDirector, Rotman Institute of Philosophy \nUniversity of Western Ontario \nStevenson Hall 2150F \nLondon, Ontario \nCanada N6A 5B8 \nEmail: carl.hoefer@uwo.ca \nTel: +1 519 661-2111 x81291 \nFax: +1 519 661-3922 \n 2 \nAbstract \n \nClassical statistical mechanics posits probabilities for various events to occur, and these \nprobabilities seem to be objective chances. This does not seem to sit well with the fact \nthat the theory\u2019s time evolution is deterministic. We argue that the tension between the \ntwo is only apparent. We present a theory of Humean objective chance and show that \nchances thus understood are compatible with underlying determinism and provide an \ninterpretation of the probabilities we find in Boltzmannian statistical mechanics.  \n \n \n1. Introduction \n \nClassical statistical mechanics (CSM) posits probabilities for various events to occur. Yet the \ntheory\u2019s time evolution is deterministic. How can probabilities in a deterministic setting be \nunderstood? We begin by outlining our own version of Humean Objective Chance, which we \ncall THOC (Section 2). We then briefly review the main tenets of CSM and discuss how it \ndeals with probabilities (Section 3). We then argue that these probabilities fit the mould of \nTHOC; and in doing so we qualify various aspects of our approach to chance (Section 4). \nThese qualifications are best discussed in a more general setting, and so we widen the scope \nof our discussion to probabilities in non-fundamental sciences beyond CSM. This brings us to \na discussion of various presuppositions of THOC and a comparison with other approaches to \nchance (Section 5). In the last section we draw some conclusions.  \n \n \n \n 3 \n2. Humean Objective Chance  \n \nLet e be an event, for instance a coin coming up heads when flipped, and let E be the \nproposition stating that e occurs.\n1\n  The chance of E, ch(E), is a real number in the interval [0, \n1] such that:  \n \n(1) ch satisfies the axioms of probability;2 \n(2) ch is the correct plug-in for X in the Principal Principle; and \n(3) ch supervenes on the Humean Mosaic in the right way,  \n \nwhere X  is the statement that \u2018ch(E) =x\u2019. Chances thus defined are Humean Objective \nChances (HOC) \u2013 \u2018chances\u2019 for short. We call a statement like X a chance rule.3  Chances are \nlinked to setups, which are characterised by setup conditions: relative to a certain physical \nsetup condition, the chance of E is x.\n4\n In the example of the coin, the setup conditions are that \nthe coin is a (nearly) perfect short cylinder and has a homogenous mass distribution, is spun \nupwards at moderate speeds (thus avoiding that the coin decomposes), lands on a mushy \nsurface that leaves the coin intact, etc. To keep notation simple we are not introducing a \nspecial index for a setup, but it must be remembered that all chance rules are linked to a \nspecific type of setup conditions.  \n \nWe use \u2018THOC\u2019 to refer to the entire theory of chance presented in this section. We take (1) \nto be unproblematic;\n5\n (2) and (3) need unpacking. Chances are guides to action, and the most \nimportant requirement on a theory of chance is that it show how chances can do that. This \naspect of chances is enshrined in the Principal Principle (PP), which establishes a connection \nbetween chances and the credences (subjective degree of belief) a rational agent should assign \nto certain events. Roughly, PP says that a rational agent who knows the chance of e should \n 4 \nhave credence in e\u2019s occurrence equal to the chance of E, as long as the agent has no \ninadmissible knowledge relating to E\u2019s truth. More formally, PP is the rule that for all E, all X \nand all K \n  \n cr(E|X&K) = x,                 (Eq. 1)\n  \nwhere \u2018cr\u2019 stands for a rational agent\u2019s initial credence, and K is any admissible proposition.6  \n \nA crucial question is what counts as an \u2018admissible\u2019 proposition. This question has been \ndiscussed controversially, and we cannot revisit this discussion here.\n7\n Following Hoefer \n(2007), and in line with Lewis\u2019s first characterisation in his (1980), we take a proposition P to \nbe admissible with respect to an outcome-specifying proposition E for chance set-up S iff P \ncontains only the sort of information whose impact on reasonable credence about E, if any, \ncomes entirely by way of impact on credence about the chances of those outcomes. Chance is \na guide to action when information about E\u2019s truth or falsity is not available.   \n \nThe essence of the requirement of admissibility is to exclude the agent\u2019s possession of other \nknowledge relevant to the truth of E, the kind of knowledge the possession of which might \nmake it no longer sensible to set credence equal to objective chance. To use the usual (and \nsilly) example: if you have a crystal ball that you believe reliably shows you future events and \nif your crystal ball shows you the coin toss landing tails and you trust the ball\u2019s revelations, \nthen it would not be reasonable to set your credence in tails to 0.5 for that flip \u2013 you have \ninadmissible knowledge. This example helps make the notion of admissibility intuitively \nclear. It also points toward an important fact in our world: inadmissible evidence concerning \nfuture events is not something we typically have \u2013 if we did, then chances would be rather \nuseless to have. \n 5 \n \nLet us now turn to (3). The Humean Mosaic (HM) is the collection of everything that actually \nhappens; that is, all occurrent facts at all times. There is a question about what credentials \nsomething must have to be considered part of HM, and we will touch upon this question in \nSection 5.2. What matters for now is that irreducible modalities, powers, propensities, \nnecessary connections and so forth are not part of HM.\n8\n That is the \u2018Humean\u2019 in Humean \nmosaic.  \n \nSupervenience requires that chances be entailed by the overall pattern of events and processes \nin HM. A simple example of supervenience is actual frequentism (the view that probabilities \nare actual frequencies): the overall pattern of events uniquely determines the relative \nfrequency of an event (if it is well defined), and hence its probability. Note that actual \nfrequentism has no frequency tolerance: there cannot be any difference between the chance of \nA and the frequency of A. This contrasts with propensity theories, which have maximal \nfrequency tolerance, but fail to satisfy Humean supervenience. THOC strikes a balance \nbetween these extremes by requiring that chances supervene on HM, but not simply: THOC \npostulates that chances are the numbers assigned to E by probability rules that are part of a \nBest System (BS) of such rules, where \u2018best\u2019 means that the system strikes the as good a \nbalance as the actual events will allow of simplicity, strength and fit. We then say that a \nprobability rule is Humean BS-supervenient on HM (\u2018HBS-supervenes on HM\u2019, for short) iff \nit is part of a Best System. Clause (3) can now be made more precise: the function ch HBS-\nsupervenes on HM. \n \nSimplicity and strength are notoriously difficult to explicate. We present a characterisation of \nthese that is precise enough for our purposes in Section 4. Throughout section 4 we assume \nthat chance rules are formulated in a natural language, thereby ruling out grue\/blean-type \n 6 \npredicates. We reflect in Section 5.3 on how strong this assumption is and on how damaging \nresidual indeterminacies are to our project. Fortunately, fit is a less problematic concept. The \nfit of a system is a matter of the extent to which the actual course of events in HM is likely in \nlight of that system: the more likely a system regards the actual course of history as being, the \nbetter its fit. This explication of fit has certain limitations. It is only readily applicable to \ncertain simple sorts of chance system, and Humean mosaics with only finitely many chancy \nevents. For, e.g., systems with continuous chance distributions and\/or worlds with infinitely \nmany chancy events, a different approach is required; we set aside this issue because the cases \nwe are interested are covered by the current explication.\n9\n \n \n \n3. Thermodynamics and Classical Statistical Mechanics  \n \nThe behaviour of macroscopic systems like a gas in a box is to a good degree of \napproximation correctly described by thermodynamics (TD). TD introduces macrostates kM  \n(where k  is an integer which depends on the specific properties of the system, which are \ncharacterised by the values of macroscopic parameters such as temperature, pressure and \nvolume).\n10\n Macrostates pertain to the system as a whole and neither their definition nor their \nuse depends on the microscopic makeup of the system. In a world which is phenomenally \nequivalent to ours but in which there are no atoms and matter is a Cartesian continuum, the \nmacrostates of a TD system would be the same and all laws of TD would apply.  \n \nThe most important of these laws is the so-called Second Law of TD, saying that the TD \nentropy of a closed system cannot decrease. The law needs to be qualified in two ways. First, \nthe strict version of the law is only approximately true; it is an empirical fact that entropy of a \nsystem can fluctuate. Second, it is typically the case that entropy increases (as opposed to just \n 7 \nnot decrease). Taking these qualifications into account, the Second Law says that a system is \nhighly likely to exhibit thermodynamic-like behaviour (TD-like behaviour). We have TD-like \nbehaviour iff the entropy of a system that is initially prepared in a low-entropy state increases \nuntil it comes close to its maximum value and then stays there, exhibiting frequent small and \nonly rare large fluctuations away from equilibrium.\n11\n Notice the reference to \u2018highly likely\u2019 in \nthe statement of the Second Law. In effect the law introduces a probability )(TSp  that a given \nsystem S behaves in a TD-like way, and it states that the value of this probability is close to \none.   \n \nThere is an entirely different way of looking at the gas in a box. As a matter of fact, the gas is \na collection of molecules, each governed by the laws of mechanics. In what follows we \nassume these laws to be the ones of classical mechanics (CM). The microstate of a system \nconsisting of n  particles is specified by a point x  in its n6 -dimensional phase space \uf047 , \nwhich is endowed with the Lebesgue measure \uf06d . The dynamics of the system is governed by \nHamilton's equations of motion, which define a measure-preserving phase flow t\uf066  on \uf047 . \nMore precisely, \uf047\uf0ae\uf047:t\uf066  is a one-to-one mapping for every real number t  and \n)())(( RRt \uf06d\uf066\uf06d \uf03d  for every measurable region \uf047\uf0cdR . We assume that the relevant physical \nprocess begins at a particular instant 0t  and adopt the convention that )(xt\uf066  denotes the state \nof the system at time tt \uf02b0  if it was in state x  at 0t , and likewise )(Rt\uf066 ; x  is then commonly \nreferred to as the \u2018initial condition\u2019. The flow t\uf066  is deterministic and hence, together with the \ninitial condition x  of a gas completely determines the behaviour of the gas.\n12\n \n \nStatistical Mechanics (SM) aims to establish a connection between the TD way and the \nmechanical way of looking at the system and account for TD behaviour in terms of the \ndynamical laws governing the microscopic constituents of macroscopic systems and \n 8 \nprobabilistic assumptions. We now briefly review classical SM and discuss in some detail \nhow probabilities are introduced into a mechanical theory.\n13\n \n \nIt is the basic posit of Boltzmannian SM (BSM) that the kM  supervene on the system\u2019s \nmicrostates. Therefore each macrostate kM  is associated with a macroregion \uf047\uf0cd\uf047k  so that \nthe system is in macrostate kM  at t  iff its microstate x  lies within k\uf047  at t . The Boltzmann \nentropy of a macrostate is defined as ))(log()( kBkB kMS \uf047\uf03d \uf06d , where Bk  is the Boltzmann \nconstant. Since the system is only exactly in one macrostate\/macroregion at a given moment \nin time, we can define the Boltzmann entropy of the system simply as the entropy of the \ncurrent macrostate: ))(log()( tBB ktS \uf047\uf03d \uf06d , where t\uf047  is the macroregion in which the system\u2019s \nmicrostate is located at time t . It can be shown that the equilibrium state is by far the largest \nof all states (relative to the measure \uf06d ), a fact known as the dominance of the equilibrium \nstate. Since the logarithm is a monotonic function it follows that the entropy is maximal in \nequilibrium.  \n \nDeriving the (above statistical version of the) Second Law from the fundamental laws of \nmechanics and probabilistic assumptions is an important aim of SM. By assumption the \nsystems starts in a low entropy non-equilibrium macro state. That this be the case is the \nsubject matter of the so-called Past Hypothesis, and the system\u2019s low entropy macro state is \ncalled the past state.\n14\n Since the past state and the equilibrium state are of particular \nimportance, we introduce special labels and denote the former by pM  (associated with p\uf047 ) \nand the latter by eqM  (associated with eq\uf047 ).  \n \nIt is now time to introduce the concept of ergodic motion.\n15\n Metaphorically speaking, a \ntrajectory is ergodic if it evenly spreads out on the entire accessible phase space and does not, \n 9 \nfor instance, get stuck in one corner. More precisely, the motion of a system is ergodic iff for \nany set \uf047\uf0cdA , the proportion of time the trajectory spends in A  is equal to the proportion of \nthe measure that A  takes up in \uf047  in the long run (for instance, if A  occupies a quarter of \uf047 , \nthen the system spends a quarter of the time in A ). If a trajectory is ergodic, then the system \nbehaves TD-like because the dynamics will carry the system\u2019s state into eq\uf047  and will keep it \nthere most of the time (because eq\uf047  is much larger than any other macro region). The system \nwill move out of the equilibrium region every now and then and visit non-equilibrium states. \nYet since these are small compared to eq\uf047  it will only spend a small fraction of time there. \nAccordingly the entropy is close to its maximum most of the time and fluctuates away from it \nonly occasionally.  \n \nAs a matter of fact, whether or not a system\u2019s motion is ergodic depends on the initial \ncondition: some initial conditions lie on trajectories that are ergodic while others don\u2019t. This \nrealisation is the clue to introducing probabilities. Consider an arbitrary measurable subset \npC \uf047\uf0cd . We may postulate that the probability that the initial condition x  lies within C  at \ntime 0t  is \n \n)(\n)(\n)(\np\nC\nCp\n\uf047\n\uf03d\n\uf06d\n\uf06d\n ,                 (Eq. 2) \n \nwhich is well-defined because it is a fact of physics that 0)( \uf03e\uf047p\uf06d . Let us refer to this \nprinciple as the Past Hypthesis Proportionality Postulate (PHPP). We now denote by p\uf047\uf0cd\uf057  \nthe subset of all initial conditions that lie on ergodic trajectories; )(\uf057p  is  the probability that \nx  lies within \uf057  at time 0t . We then immediately get: \n \n 10 \n)()( \uf057\uf03d pTSp                           (Eq. 3) \n \nWe now see that )(TSp  has two aspects. From TD it inherits a solid connection to observable \nmatters of fact, and via SM it is connected to the fundamenal underlying mechanics. This will \nbe important in the next section.  \n \n \n4. Interpreting SM Probabilities as HOC\u2019s \n \nIt is tempting to interpret the above probabilities as epistemic probabilities. There is nothing \nchancy about a system\u2019s initial condition; there is a matter of fact about the system\u2019s \nmicrostate at 0t . One just doesn\u2019t know what this state is, and )(TSp  quantifies our ignorance \nabout the system\u2019s true microstate. But this argument is unsatisfactory. The point is simple \nand has been made by many: these probabilities stem from basic laws of physics and the \nobjective behaviour of natural systems, describe how things are, and are not rooted in what we \nfail to know (see, for instance, Redhead, 1995). \n \nWe think that this intuition is correct and now argue that )(TSp  can be interpreted as a HOC. \nThis interpretation faces an immediate challenge: how could there be chances in a world that \nobeys deterministic laws? Lewis (1986, 118-120) famously held that chance and determinism \nwere incompatible, and many share his intuition. We do not. It is instructive, though, to see \nwhat line of reasoning leads to a rejection of deterministic chance.  \n \nUnfortunately Lewis does not make the reason for his verdict explicit. Hoefer (2007, 558-9) \nprovides the following reconstruction of the incompatibilist\u2019s argument. Let Ht be the \n 11 \ncomplete history of the world up to time t; let L be the conjunction of all laws governing our \nworld; and let cht(E)=x be the non-trivial chance of E at time t (i.e. 0<x<1). Lewis regards \nhistorical facts and laws as admissible (1986, 92). PP then tells us that  \n \ncr(E | cht(E)=x & Ht & L) = x \n \nHowever, given that L is deterministic, Ht and L jointly imply E (assuming E is true; they \nimply \u00acE if E is false). Hence the axioms of probability dictate that  \n \ncr(E | cht(E)=x & Ht & L) =1. \n \nSo deterministic chances and PP as used here together with the axioms of probability, which \ncredences must satisfy, lead to a contradiction. Lewis\u2019 way to avoid this contradiction is to \ndeny that there are chances for events that are governed by deterministic laws: cht(E)=x \nsimply doesn\u2019t exist.  \n \nThis response is closely tied to Lewis\u2019 metaphysics. The world consists of a manifold of \nspacetime points, which stand in various relations to one another. These spacetime points are \nsimple particulars, meaning that they are individuals with no proper parts. Each spacetime \npoint instantiates perfectly natural monadic properties, which stand in various spatiotemporal \nrelations to one another. This ontology is based on classical physics and Lewis realised that it \nwas so austere that it may not be able to accommodate modern physics. The point in \nupholding it nevertheless, he thought, was \u2018not to support reactionary physics, but rather to \nresist philosophical arguments that there are more things in heaven and earth than physics has \ndreamt of\u2019 (1994, 474). So while he would accept adjustments to the system that are needed to \naccommodate, say, quantum theory, these adjustments would have to be such that no \n 12 \nproperties other than the properties of basic physics would be allowed into it: \u2018\u201chow things \nare\u201d is fully given by the fundamental, perfectly natural, properties and relations those things \ninstantiate\u2019 (ibid.). The question of what counts as a perfectly natural property is answered by \nphysics. So all that there is are facts about spacetime points and their spatiotemporal relations \nalong with perfectly natural properties they instantiate \u2013 all other facts are determined by \nthese basic facts. This is Lewis\u2019 physicalism, \u2018the thesis that physics \u2013 something not too \ndifferent from present-day physics, though presumably somewhat improved \u2013 is a \ncomprehensive theory of the world, complete as well as correct. The world is as physics says \nit is, and there\u2019s no more to say.\u2019 (Lewis, 1999, 33-34)  \n \nIt follows from such a view that the predicates of sciences other than fundamental physics are \nnot perfectly natural and that therefore there are no laws that are expressed in the language of, \nsay, biology, geology, or meteorology.  And Lewis, recall, advocates a Best System account \nof laws plus chances, not merely a Best System account of objective chances.  It is then clear \nwhy he resolves the problem that deterministic chances do not satisfy PP by denying that \nthere are chances for E in a deterministic world. If E is about fundamental properties, then, on \npain of contradiction, there cannot be chance laws for it in a deterministic world (the \ncontradiction being the one sketched just above). If, by contrast, E is about non-fundamental \ntypes (such as coins, macrostates, or genes) then a best system will not contain any laws for \nE-type events (and a fortiori no chance laws): a best system simply does not say anything \nabout E-type events because fundamental physics is complete and comprehensive and \neverything that can be said about everything that there is can be said in terms of fundamental \nphysics.  \n \n 13 \nWe find Lewis\u2019 approach overly restrictive. Even if there are deterministic fundamental laws, \nthere is room in a Best System approach for chance rules about events and kinds at non-\nfundamental levels. In the remainder of this section we show how this is possible. \n \nThe starting point of our argument is to deny that everything that can be said about the world \ncan be said in terms of fundamental physics. Probability rules can be formulated in terms \npertaining to different levels of discourse such as macro physics, chemistry, genetics, \nmechanical engineering and meteorology, and probability rules formulated in such terms have \nequal right to be considered for inclusion in a Best System package of rules, alongside micro-\nlevel rules. We call this view chance-rule pluralism (CRP). We provide arguments in support \nof CRP in Section 5.2. In this section we argue for the conditional claim that if we accept \nCRP, then )(TSp , and with it scads of probability rules from non-fundamental physics, \nbiology, and many other sciences, are plausibly part of a Best System. \n \nThe first step is to show that the above contradiction in terms of credences can be avoided. \nThe key to a solution is to realise that what drives the contradiction is cross level information: \nwe add information about fundamental physics to rules about coins, macro-states, and genes. \nBut such information must be inadmissible: chance rules operate at a specific level and \nevidence pertaining to more fundamental levels is inadmissible. Far from being an ad hoc \nstipulation, this requirement is a natural consequence of the definition of admissibility given \nin Section 2. Recall our characterisation of admissibility: a proposition P is admissible with \nrespect to an outcome-specifying proposition E for chance set-up S iff P contains only the sort \nof information whose impact on reasonable credence about E, if any, comes entirely by way \nof impact on credence about the chances of those outcomes. This means that the complete \nhistory Ht together with the deterministic laws L are jointly inadmissible, because they \n 14 \ndetermine what will happen and hence give information maximally relevant for credence \nabout E, and not by way of giving information about the chance of E.\n16, 17\n  \n \nSo there is no direct contradiction between deterministic laws and chance rules at higher \nlevels; only an apparent contradiction that arises if one applies PP using Lewis\u2019 understanding \nof admissibility.  If K contains no evidence pertaining to the micro level, then cr(E | cht(E)=x \n& K) = x by PP. If, by contrast, K does contain such evidence, plus the deterministic laws, \nthen cr(E | cht(E)=x & K) = 1 by the axioms of probability. But there is no contradiction \nbecause PP itself tells us that our credence ought to be equal to the chance only in the absence \nof inadmissible evidence, and it remains silent about what our credence ought to be when we \nhave inadmissible knowledge. In this case the answer is obviously 1 because E is implied by \nK.  \n \nThis does not render non-fundamental chances useless. In typical situations in which we \nobserve coins or gases, we just don\u2019t have inadmissible information, and indeed given our \nepistemic finitude, couldn\u2019t have such information, nor calculate anything based on it if we \ndid have it.  So instead, setting our credences via cht(E)=x  and PP serves us well.  \n \nThe removal of the apparent contradiction makes  non-fundamental chance rules  candidates \nfor inclusion into the Best System (it now satisfies requirements 1 and 2 for HOC\u2019s). But does \ntheir candidacy ever result in membership? We argue that it does. To this end we divide Best \nSystem approaches into two classes: those that offer a Best System account of chance alone \n(leaving non-chance laws of nature, if any, off to the side), and those that offer a unified Best \nSystem account of laws plus chances. The former approach is advocated by Hoefer (2007), \nwhile the latter has been the default approach of other Best System theorists since Lewis\u2019 \n(1994).   \n 15 \n \nUnder the chance-only Best System approach, non-fundamental chance rules obviously make \nthe cut. Since by assumption the fundamental physical laws are deterministic, there are no \nchancy fundamental laws at all, and hence nothing at the fundamental level that could \ncompete for inclusion in the Best System of chance rules. So all the chance rules that may be \nconsidered for inclusion into the Best System will be rules covering events at \u201chigher\u201d levels.   \n \nMost philosophers who favour HOC, however, want to give a unified Best System account of \nlaws and chances together, and on such an approach it may seem at first that there is a serious \nissue as to whether a Best System can contain fundamental deterministic laws and higher-\nlevel chance rules as well.  The issue is not resolved just by embracing CRP; the question is, \nwith deterministic laws in the System, how could adding any higher-level laws or rules at all \nmake the system better? \n \nTo see how this can work we need to say a bit more about how we understand simplicity and \nstrength. As indicated above, these concepts are notoriously difficult to define precisely and \nwe won\u2019t try. However, it may help to notice that the very idea of a Humean Best System \ntheory of laws involves a certain element of pragmatism and user-relativity, which makes the \nimpreciseness of simplicity and strength (and their trade-offs) less disquieting.\n18\n  A Best \nSystem is an elegant, simple, and powerful way of summarizing and systematizing the \npatterns of events in the Humean Mosaic.  But omniscient beings have no need for a System \nat all, and Laplace\u2019s demon-like super-intelligences have no need of simplicity.  A Best \nSystem is of use to finite and epistemically limited beings, such as ourselves.  It is a \u201cguide to \nlife\u201d, just as objective chance is often said to be, for the epistemically handicapped.  For a \nSystem to be the laws of nature is, for a genuine Humean, nothing more than for it to be the \nbest such guide to life that our HM allows.  And as such, the notions of simplicity and \n 16 \nstrength that are at issue in the BSA are linked to the powers and perspectives of epistemically \nhandicapped beings such as ourselves. So we think it is legitimate to rely on our own \nintuitions as we try to say something about simplicity and strength, and also to not worry \nabout whether the imprecision of these notions makes it impossible to be sure that exactly one \nBest System exists out there for our world\u2019s HM.19 \n \nWe maintain that the notions of strength and simplicity have several dimensions to them. \nStrength is a matter of how many things in HM are covered by the laws and rules of a system.  \n\u201cHow many things\u201d can refer both to tokens of events and to the types under which the tokens \nare subsumed.  So, ceteris paribus (literally: keeping all else equal), adding a rule to a system \nthat applies to 10\n9\n distinct events in HM adds more strength than adding a rule that applies to \nonly 100 events.  And adding a rule that covers 5 different types of chance setups adds more \nstrength, again ceteris paribus, than adding a rule that covers just one new kind of chance \nsetup.   \n \nOf course adding rules to a system detracts, ceteris paribus, from its simplicity.  The number \nof rules is one dimension of simplicity; we call it numerical simplicity.  But recalling that Best \nSystems are meant to be \u201cguides to life\u201d for epistemically limited beings, we maintain that \nother types of simplicity should be taken into account.  So, for example, a system that entails \ncoin flip probabilities, but only via quantum-like micro-chance laws, so that only a Laplace\u2019s \ndemon could actually calculate the chance of landing Heads, is in a sense much less simple \nthan a system that is otherwise identical, but adds a simple rule stating Pr(H)= Pr(T) = \u00bd.  \nWe call this derivation-simplicity. For a given natural language, Kolmogorov complexity \ngives one way to try to make the notion precise,\n20\n though again we stress that we are not \naiming to provide precise definitions.  Finally, and relatedly, there is simplicity of \nformulation:  assuming, again, a given natural language, then a law or chance rule that takes \n 17 \nmany pages to write down is less simple than a rule that can be compactly expressed on a \nsingle line.  \n \nLet us illustrate some of these points with an example. Consider a fictional world consisting \nof nothing but 10  coin tosses, 20 die throws and 50 spins of a roulette wheel, and assume that \nthe outcomes of these events are nicely randomly distributed in the usual way so that the usual \nclassical probabilities have good fit with the world\u2019s history. System 1 contains three separate \nrules covering coins, dice and rouletter wheels respectively; system 2 contains one rule \ncovering all gambling devices; system 3 contains one rule covering only coins and dice and \nsays nothing about roulette wheels. We then can see that system 2 has a better combination of \nsimplicity and strength than system 1, which in turn beats system 3 because the latter, while \nhaving fewer rules, also covers fewer types of chancy events and many fewer tokens.  There is \na premium for covering cases that occur frequently (leaving out roulette wheels is penalised) \nand there is a reward for having fewer rules while keeping scope constant.  \n \nBased on these notions of simplicity and strength, we now argue that non-fundamental rules \ncan be part of a Best System because a system that has these rules in them strikes a better \nbalance between simplicity and strength than ones that don\u2019t (throughout we assume that the \nsystems under considerations are on par as regards fit). The conclusion is obviously true for \nanti-reductionists: non-fundamental rules cover cases that aren\u2019t covered by fundamental \nrules. If instances covered aren\u2019t extremely rare, then strength increases significantly while \nsimplicity decreases only a little, and hence overall the system with nonfundamental \nprobability is better than the system that is restricted to fundamental rules (we return to the \nrarity issue below)   \n \n 18 \nThe more interesting case is the one in which reductionism in the sense of supervenience is \ntrue. To see how the argument plays out we first consider that case where we have \ninderministic laws at the fundamental level, for instance because the world is at bottom \nquantum mechanical (and quantum mechanics is understood in the standard way). As an \nexample consider the probability rule discussed in (Lehe, Hallatschek, and Peliti, 2012), \nspecifying how the probability of a successful mutation increases as a function of distance \nfrom the bulk of the population in species that are expanding their territorial range.\n21\n \nIntroducing such a rule into the system leaves that system\u2019s strength unchanged because, per \nsupervenience, every case covered by a non-fundamental probability rule is also covered by a \nfundamental one. At the same time there is a loss in numerical simplicity because the number \nof rules in the system increases. So the strength versus-numerical simplicity balance would \ncount against the introduction of non-fundamental rules. However, the system\u2019s derivational \nsimplicity is greatly increased. It is hugely costly to start from first principles every time one \nwants to make a prediction about a non-fundamental object like a genetic mutation in a \npopulation, and a system becomes significantly simpler if we write in rules about such \nobjects.\n22\n As already mentioned, quantifying the gain in derivational simplicity is notoriously \ndifficult. But the fact that no one has yet succeeded in deducing a single biological probability \nfrom anything like first principles, let alone from fundamental quantum theory, suggests that \nthe costs of such a derivation are indeed significant, and certainly sufficiently high to \ncompensate for the relatively small loss in numerical simplicity due to the addition of one \nextra rule.  \n \nLet us now turn to the case in which the fundamental laws are deterministic. Not only can we \nnever derive a probability rule from the micro-level laws. We also face the above problem \nthat cht(E)=x assigns a non-trivial chance to E while Ht & L imply E. Given this, how can \ncht(E)=x (with x<1) possibly be part of the Best System?   \n 19 \n \nFor reasons similar to the ones we considered above in the indeterministic case, such rules can \nearn their place in a Best System. Even though the fundamental theory and non-fundamental \nrules make different statements about HM, they cover the same setups (e.g. coins and gasses), \nwhich would count against their inclusion. However, while deterministic laws may, with the \nhelp of infinitely precise initial conditions, cover macro-level events, the derivational \nsimplicity of a system can be vastly improved, vis a vis macro-level events, by the \nintroduction of non-fundamental chance rules, with only a small cost in terms of the number \nof rules\/laws in the system.\n23\n \n \nThe only remaining questions are:  Does a proposed chance rule have good fit with the events \nin HM, and does the gain in derivational simplicity outweigh the loss of simplicity caused by \nadding an additional rule? \n \nFor statistical mechanical probabilities such as )(TSp , at least, we think the answers to both \nquestions are affirmative, though the first one is mostly empirical and depends on facts about \nthe HM which we can\u2019t claim to know with certainty.  As we have seen in Section 3, )(TSp  \nhas two aspects, one macro and one micro. The macro aspect is that it captures an observable \npattern of events. The micro aspect is that is is connected to the fundamental underlying \ntheory via its mechanical description and the probility distribution )(Cp  (which, it is worth \nemphasising, is not itself part of the fundamental theory). In effect )(Cp  expresses the \nprobability that a system\u2019s microstate is in set pC \uf047\uf0cd .  \n \nNow look at this probability from the point of view of THOC. There is a well circumscribed \nclass of objects to which a chance rule like PHPP applies (gases, etc.). Each of these is a \n 20 \nclassical system and hence has a precise initial condition x  at 0t , which, by assumption, lies \nwithin p\uf047 . Now go through the entire HM and put every single initial condition x  into p\uf047 . \nThe result of this is a swarm of points in p\uf047 . Then recall from above that THOC is essentially \na refinement of finite frequentism and chances should closely track relative frequencies \nwherever such frequencies are available. Hence the chance of an initial condition being in set \nC  given that it lies in p\uf047  is the fraction of points in set p\uf047  that lie in C  (in the same way in \nwhich the chance of heads is, or is close to, the fraction of heads in the set of all coin toss \noutcomes). But listing all points individually and checking whether they lie in C  is extremely \ncumbersome and won\u2019t make for simple system. So we have to reduce the complexity of the \nsytem by giving a simple summary of the distribution of points. To this end we approximate \nthe swarm of points with a continuous distribution (which can be done using one of the well-\nknown fitting techniques such as the method of the least mean squares or kernel dressing) and \nnormalise it. The result of this is a probability density fuction \uf072  on p\uf047 , which can be \nregarded as an expression of the \u2018initial condition density\u2019 in different subsets C  of p\uf047 .\n24\n  \n \nThe good-fit constraint now is that )(C\uf072  be equal to (or in very close agreement with) \n)(\/)( pC \uf047\uf06d\uf06d  for all subsets C  of p\uf047 . This is a non-trivial constraint. For it to be true  it has \nto be the case that the initial conditions are more or less evenly distributed over p\uf047  because \n)(\/)( pC \uf047\uf06d\uf06d  is a flat distribution over p\uf047 . If it turned out that all initial conditions were \ncrammed into one corner of p\uf047 , then Eq. 2 would have poor fit, which would preclude it \nbeing part of the Best System, despite its great simplicity. So the requirement \nr(C) \u00bb m(C) \/m(G p ) presents a real touchstone for the system. Eq. 3 is then dealt with easily. \nThis requirement has to hold for all C , a fortiori it has to hold for E  and so Eq. 3 gives the \nright chances if r(E) \u00bb m(E) \/ m(G p ). \n 21 \n \nThe second question concerns the inclusion of statistical mechanical chances in the Best \nSystem is:  is the gain in derivational simplicity\/real-use strength big enough to compensate \nthe slight loss in rule-count simplicity?  We think it is obvious that it is, given how ubiquitous \ngases and other systems covered by statistical mechanics are, in our world.  We would go \nfurther and argue that the same goes for chance rules covering things like successful \nmutations, symmetrical gambling devices, and so on.  Here an objection can be raised, \nhowever, to the effect that the Earth is such a small corner of the HM that adding rules to \ncover any type of chance setup (gene mutations, coin flips) found only on Earth can only \nmake a miniscule addition to a system\u2019s strength, an addition that therefore intuitively cannot \ncounterbalance the loss of simplicity caused by the addition of an extra rule.   \n \nAs noted before, it does not affect the question of whether statistical mechanical probabilities \nought plausibly to be part of a Best System, since the systems covered are to be found all over \nthe universe.  Let us now nevertheless offer a few remarks to try to deflate this objection as \nregards earth-only types.  In the first place, as we have seen above, the strength of a system is \nmeasured not only in terms of the number of tokens covered; it also depends on the number of \ntypes covered, and the increase in this dimension may well be dramatic once we include \nbiology. But even those who are not moved by this consideration may want to avoid the \nconclusion that the strength of a chance rule is measured by the proportion of space-time in \nwhich it is applicable.  Indeed, such weighting arguably leads to disaster for the BSA, for a \nuniverse like ours.  Astrophysicists assure us that we may well live in a universe which will \nhave an infinitely long (in time) future \u201cheat death\u201d state in which, basically, nothing happens.  \nSo the simplest and strongest system for a universe like ours \u2013 ignoring the tiny corner of \nspacetime in which interesting things actually happen \u2013 would surely be something like \n\u201cNothing happens but minor quantum fluctuations in an otherwise cold, dead, slowly \n 22 \nexpanding space.\u201d  And finally, of course, we can again invoke the fact that the Best System \napproach by its very nature should be a \u201cguide to life\u201d for epistemically limited agents \u2013 \nagents for whom, almost by definition, one corner of the HM is going to be more relevant and \nimportant than the vast regions with which they have no contact. \n \nIn this section we have argued that the standard probability rule of statistical mechanics can \nplausibly be seen as a rule that would form part of a Humean Best System for a Newtonian \nworld, despite the availability of a fully deterministic underlying dynamics. The rule would \nmerit inclusion for the dramatic simplification (derivational simplicity) it brings to the capture \nof a pervasive regularity in HM:  that most systems behave in a TD-like fashion.  In the last \nsection we turn a defense of chance-rule pluralism, and to addressing the worries some \nphilosophers may have about whether determinism and objective chance really are compatible \nafter all. \n \n \n \n5. Reverberations \n \n \n5.1 A kind of counterfeit chance? \n \nLewis famously quipped that introducing chances in a deterministic setting results in a \u2018kind \nof counterfeit chance\u2019, which is \u2018quite unlike genuine chance\u2019 (Lewis, 1986, 120). And even \nwriters more sympathetic to the cause of the determinist argue that the probabilities of SM \nand evolutionary theory should be considered a type of objective probability but not objective \n 23 \nchance. Lyon (2011), for instance, argues that they are a third type of probability which \ncoincides neither with chance nor with subjective probability. \n \nThere is no ultimate right and wrong in the use of a word, and depending on one\u2019s other \nphilosophical commitments one can reserve \u2018chance\u2019 to propensities, primitive fundamentally \nchancy laws of nature, or some kind of fundamental modality (no matter how they are \nanalysed). So our aim is not to prove authors embracing this decision wrong; our aim is to \nmake it plausible that there is no compulsion to follow them in doing so and that there is a \ndifferent and equally legitimate use of \u2018chance\u2019 that does not come with such restrictions. We \nsee our own analysis as best because it both best satisfies the desideratum of rationalizing PP, \nand lets us capture all the key uses of chance in science \u2013 and lets us do so whether or not the \nworld\u2019s fundamental physical laws are deterministic or indeterministic. \n \nTHOC is a philosophical analysis of objective chance. \u2018Objective chance\u2019 here is meant to \nrefer to our everyday folk notion of chances as objective facts, \u201cout there in the world\u201d in \nsome sense, which are representable mathematically as probabilities, and which are the kinds \nof things that gamblers, actuaries and many sorts of scientists are keen to find out about.  Like \nany folk notion (like causation, reference, justice, for example), chance is not a sharply \ndefined concept, and people will have divergent intuitions about which aspects or \nconnotations associated with it are most central. This does not invalidate philosophical \nanalysis, which aims to sharpen vague intuitions and mould them into consistent concepts. \nBut it warns us that other analyses are always possible, and for the notion of chance they are \ncurrently proliferating in the literature. The aim in this section is to explicate how THOC \ndiffers from other Humean accounts of chance and make its distinctive features explicit. We \nsee in particular THOC\u2019s closeness to scientific practice and its ability reconcile chance with \ndeterminism as virtues which render it superior to its competitors. But we acknowledge that \n 24 \nthose who cherish different aspects of chance will disagree on the relative value of the \ndifferent accounts. The aim in this section is not to adjudicate between different outlooks. The \naim is to make explicit wherein the differences lie and make it plausible that THOC is a \nlegitimate and successful analysis of our folk notion of chance.   \n \n \n5.2 Why accept chance-rule pluralism? \n \nRecall that CRP is the posit that probability rules can be formulated in terms pertaining to \ndifferent levels of discourse and probability rules formulated in such terms have equal right to \nbe considered for inclusion in a Best System package of rules, alongside rules at the \nfundamental level.\n25\n What reasons are there to adopt such a principle?  \n \nThe answer to this question depends on one\u2019s stand on reduction. Let us begin with \nantireductionism. This position comes in different versions, some of which fall under the label \nof \u2018emergentism\u2019. Antireductionists of all stripes will hold that the entities and properties at \nhigher levels cannot be reduced (or at any rate not completely) to fundamental entities and \nproperties at a fundamental level. In Anderson\u2019s famous words: more is different (1972). In \nthis vein Dupr\u00e9 insists that \u2018there is a whole hierarchy of increasingly complex things that \nreally exist, and that have causal powers that are not reducible to the mechanical combination \nof the powers of their constituents\u2019 (2006, 15). It is an obvious consequence of such a view \nthat a best system will contain chance rules for various levels.  \n \nThe more difficult question is why a reductionist would accept CRP. Like antireductionism, \nreductionism comes in different versions. The weakest version, and also most widely held, is \nthe claim that the existence and properties of entities at all levels supervenes on the facts \n 25 \nabout fundamental physical entities and their properties. Supervenience still has bite, because \nit entails that how non-fundamental entities behave is completely determined by how \nfundamental entities behave. It is important to notice, though, that the strong form of \nphysicalism envisaged by Lewis \u2013 one holding that fundamental physics is a complete theory \nand that there is no more to say about the world than what physics says \u2013 is not a consequence \nof supervenience: one can consistently hold that all higher level entities\/properties supervene \non the entities\/properties described by fundamental physics and that there theories other than \nfundamental physics are needed to provide a comprehensive description of what there is. So \nan argument over and above supervenience is needed to support that kind of physicalism.  \n \nAt this point it is instructive to notice a parallel with a long-standing debate in the philosophy \nof mind. Eliminativist materialism submits that folk psychology should not only be reduced to \nneuroscience, but actually be replaced by it: whatever can be said about metal activities can \nsaid in neuroscientific terms. The reductionism versus eliminativism debate in the philosophy \nexactly parallels the controversy around CRP, fundamental physics corresponding \nneuroscience and non-fundamental science to folk psychology. So Lewis\u2019 physicalism really \nis a form of eliminativism, and it is therefore illustrative to look at the arguments supporting \neliminativism in the philosophy of mind.  \n \nArguments in support of eliminativism typically are arguments against folk psychology. \nProponents of eliminativism argue that folk psychology is profoundly wrong and predictively \nunsuccessful because central tenets of folk psychology radically misdescribe cognitive \nprocesses, that folk psychology is not a fertile research programme, and that ordinary mental \nstates cannot in any way be reduced to, or be identified with, the brain states of neuroscience \n(see, for instance, Churchland, 1981, and ; Churchland, 1986).  \n \n 26 \nTypical arguments against elimintivism therefore take the form of a defence of folk \npsychology (see, for instance, Horgan and Woodward, 1985 ). Carrying this argument in \nsupport of eliminativism over to the case at hand would amount to arguing that non-\nfundamental theories are profoundly wrong and predictively unsuccessful, and that they form \nstagnant research programmes. That this would be hopeless enterprise becomes clear as soon \nas one starts writing a list of theories that would have to be thus discarded: statistical \nmechanics, thermodynamics, chemistry, molecular genetics, etc. Needless to say, none of \nthese theories is free of internal difficulties, but it is hard to see that these would justify a \ndismissal of, say, molecular genetics as on par with folk psychology even if one grants that \narguments against folk psychology are successful (which is by no means uncontroversial). We \nregard this position as a non-starter.  \n \nAnd things get worse for the eliminativist. Not only is the main argument in support \neliminativism unsuccessful in our context; there are reasons against it. The first is that \nsupervenience relation is one that hold between two (sets of) properties and this trivially \nimplies that there are non-fundamental properties. That, say, temperature supervenes on \naverage kinetic energy presupposes that a system has a temperature, and we can only express \nthis supervenience relation if our scientific language contains a term referring to temperature. \nOne might try to downplay the importance of non-fundamental properties by endorsing \nontological innocence, the claim that supervenient properties really are nothing over and \nabove the properties in the supervenience base and have therefore no ontological status.  \n \nBut this more is of no help. Ontological innocence is controversial (van Inwagen, 1994), and \neven if we assume, for the sake of argument, that the thesis stands, it will not help the \neliminativist. To begin with, CRP is a posit about scientific theories, not ontology. It says that \ntheories can be formulated at different levels and refer to properties at different levels; it is not \n 27 \ncommitted to the claim the properties at non-fundamental levels are in some sense sui generis. \nAnd what is more, deflating supervenient properties is successful only as long as there is a \ntype-type identity. But many non-fundamental properties are multiply realisable, meaning that \nthe same non-fundamental property can be realised by a number of distinct fundamental \nkinds. This is true not only in psychology (the classical example being pain); we find multiply \nrealised properties even in close-to-fundamental physics: temperature in gases and \ntemperature in spin systems have completely different micro-realisers. This is a problem for \nthe eliminativist because the only thing these realisers have in common is that they are \nrealisers of a certain non-fundamental property. There is no way to group these together \nwithout making reference to non-fundamental kinds, and hence not everything that can be \nsaid about these kinds can be said only in terms of the fundamental theory.\n26\n \n \nThe second argument against eliminativism is that supervenience claims by themselves do \nnothing more than assert that a certain pattern of property variation hold (you can\u2019t vary the \nsupervening properties without also varying the base properties), but they do not say why this \npattern holds and where the dependency comes from. This is widely seen as a problem, and it \nis natural to look for an explanation (Kim, 1998). Whatever such an explanation will look \nlike, it will have to make reference to the higher level properties and hence cannot be \neliminativist.  \n \nFor these reasons elimintivism as not a plausible position. Let us add a further reason for this \nconclusion, even though it is one that elimativists would dismiss as mere (and misguided) \nopinion. The point is that eliminativism is little more than a philosopher\u2019s dream. Real science \nhas never borne any resemblance to it, and there is no evidence that it ever will. In our view a \nBest System should not be entirely disconnected to how science as practised by scientists \nlooks like. Science has always operated at different levels, it is widely recognised that \n 28 \ndisciplines working at a certain level do so with a great deal of autonomy, and both methods \nand  explanatory practices are closely tied to discipline-specific domains of discourse. A \nHumean Best System approach should aim at capturing this feature of science and therefore \nought to recognise (at least in principle) chances found in all the sciences. If this is so, then \nhigher level entities form part of the Humean mosaic and certain statistical generalisations \nabout them will be part of the overall best system. And we are glad to report that even \noutspoken radical reductionists seem agree. Nobel Prize winning physicist Steven Weinberg \nfirst observes that: \u2018no one doubts that with a large enough computer we could in principle \nexplain all the properties of DNA by solving the equations of quantum mechanics for \nelectrons and the nuclei of a few common elements, whose properties are explained in turn by \nthe standard model\u2019 (Weinberg, 1993, 24-5), but immediately adds that: \u2018[t]here is no reason \nto suppose that the convergence of explanation [i.e. the solving fundamental equations to \nexplain non-fundamental properties] must lead to a convergence of scientific methods. \nThermodynamics and chaos and population biology will each continue to operate with its own \nlanguage, under its own rules, whatever we learn about elementary particles\u2019 (ibid., 33).  \n \n \n5.3 Anything goes? \n \nAn evergreen among the criticisms of HBS approaches of all stripes is that simplicity and \nstrength are psychological concepts and that this opens the flood gates for radical relativism: \nif we don\u2019t like the laws we find, we just change the way we think and get different laws. As \nnoted earlier, Lewis responded to this charge by observing that \u2018[i]f nature is kind, the best \nsystem will be robustly best \u2013 so far ahead of its rivals that it will come out first under any \nstandards of simplicity and strength and balance\u2019 (1994, 479). He adds that there is of course \nno guarantee that nature is kind, but also no evidence to the contrary. And if it turned out that \n 29 \nnature wasn\u2019t kind then we should blame the demise of a solid notion of lawhood on an \nunkind nature and not on the HBS analysis (ibid.).  \n \nWe agree with Lewis on this point and set worries about radical relativism aside. In doing so \nwe also assume that laws and chance rules are formulated in a natural language. If we allow \nartificial constructions, then indeed almost anything goes. We could, for instance, conjoin all \nchance rules in a system to form a super rule, and thereby bring n-simplicity down to a \nminimum. We know of no principled way to rule out such manoeuvres, but there is also no \nevidence that they are a serious problem for science. So we follow Lewis (1983) in assuming \nthat laws and chance rules be formulated in some natural language. Lewis thought that a \nnatural language was the language of \u2018something not too different from present-day physics, \nthough presumably somewhat improved\u2019 (Lewis, 1999, 33-34). We agree with that but would \nadd that the same move be made for non-fundamental disciplines: a natural language for \nmicro biology, for instance, would contain terms like \u2018gene\u2019 and be an improved version of \nsomething like current molecular biology.  \n \nA related criticism is that simplicity and strength are too vague to base a robust notion of law \nor chance on them. There is no denying that these concepts are bound to have a certain degree \nof vagueness to them. Does that make THOC (or related Humean accounts by Lewis, Loewer, \nCallender & Cohen and others \u2013 for all invoke the same virtues) hopelessly unclear or ill-\ndefined?  We think not, obviously, and want to make two points in support of our optimism.  \n \nFirstly, assuming that artificial constructs like the above super rule are excluded by the natural \nlanguage requirement, the vagueness pertaining to these concepts is greatly reduced. In \nparticular, derivational simplicity is non-arbitrary if one commits to a particular language. As \nwe have suggested above, it could, for instance, be measured in terms of Kolmogorov \n 30 \ncomplexity, which is an objective measure if we assume a particular language as given. The \ndetails of such proposals need more work, but we believe the situation is not as hopeless as \ncritics want us to believe.  \n \nSecondly, the prominence of the role of PP in THOC also provides a sort of guarantee that the \nimprecision of simplicity and strength can\u2019t do too much harm.  If someone interprets the \nBestness competition in such a way that the winning system is too restrictive, having little \nstrength or covering only fundamental physical interactions (say), then their version can\u2019t be \nwhat THOC aims at, because THOC aims (clause (2)) to give us the right things to plug into \nPP.  A too-restricted system would leave out potential probability rules that clearly do deserve \nto plug into PP, and do HBS-supervene on the HM, under a better understanding of \nsimplicity, strength etc.  Conversely, a too-unrestricted system would include a plethora of \nchance rules that cover, say, gerrymandered classes of objects and\/or many chance rules with \nonly one or a few instantiations in HM.  For such a profligate system, the proofs of PP \nmentioned earlier (see Hoefer 2007 and Frigg and Hoefer 2010) would fail, hence they could \nnot be what THOC aims at.  So we regard THOC as clearly \u2013 and by design \u2013 apt for \ncapturing the core of our uses of objective chance, even if the notion of \u201cBest\u201d in \u201cBest \nSystem\u201d is not definable with any great precision. \n \n \n5.4 Platitudes about chance reconsidered \n \nJonathan Schaffer (2007) formulated six platitudes about chance with the aim to convince the \nreader of the incompatibility of chance and determinism. We now revisit these platitudes from \nthe point of view of THOC. Some of these alleged platitudes in fact aren\u2019t platitudes and \nhence need not worry the compatibilist. Other platitudes can be re-interpreted so that they \n 31 \nhold true in THOC. So THOC can capture different but related platitudes to Schaffer\u2019s. This \nlends further support our claim in Section 5.1 that THOC is a legitimate analysis of our folk \nnotion of chance.  \n \nThe first of Schaffer\u2019s platitudes is no mere platitude, being precisely PP itself. Needless to \nsay, we agree with the spirit of this platitude but understand PP differently than Schaffer \nbecause we have a different notion of admissibility: Schaffer (along with Lewis) regards the \ntotal history and laws as admissible while (roughly speaking) we only regard evidence at the \nchance rule\u2019s level as admissible.  \n \nSimilar remarks pertain to the case of Schaffer\u2019s second platitude, the link between chance \nand (future) possibilities.  He starts with the Basic Chance Principle (BCP), which asserts that \nif at t there is a non-trivial objective chance of future event A occurring, then there is a \npossible world with the same history up to t, in which A has the same objective chance as it \nactually has, and in which A in fact occurs. Schaffer actually proposes a stronger version of \nthis platitude, his Realization Principle (RP) stating that this other possible world in which A \noccurs should have the same laws as our world.  \n \nTHOC denies that BCP\/RP as formulated by Schaffer is a platitude, but endorses a closely \nrelated principle that differs from Schaffer\u2019s by restricting  \u2018the same history up to t\u2019 to the \nadmissible history \u2013 in the case of statistical mechanics this is the macro-history. Thus \nunderstood, there can be branching. Of course, the proponents of BCP\/RP will reject this \nreading of \u2018same history\u2019; they mean the full history in all detail.  Fixing the precise initial \ncondition of the world rules out all but one macro history provided the underlying dynamics is \ndeterministic, and hence BCP is violated. In a view that sees chances as operating a certain \n 32 \nlevel and decrees cross level evidence as inadmissible in conjunction with laws, such a choice \nis not forced upon us.  \n \nSchaffer\u2019s next principle seems linked to the notion that chance and chanciness have \nsomething to do with the \u201copenness\u201d of the future.  His formulation of the Futurity Principle \n(FP) says that if an event has, at time t, chance strictly between zero and one, then that event \n(or its failure to occur) lie to the future of t.  All past events that occurred have chance 1 (or \nno chance); all events that might have occurred in the past but didn\u2019t now have chance 0 (or \nno chance).  \n \nThis platitude is independent of the issues surrounding determinism. THOC could be \nformulated so that it satisfy FP, and our reasons not do so have nothing to do with our views \nabout determinism and chance. One awkward aspect of FP is that it requires that we make \nsense of an objective past\/future division of all events (since we are, after all, discussing \nobjective chance). In a relativistic world, this requirement is of course highly problematic.  \nFor this reason, among others, Hoefer (2007, 554) proposes that, for events, we make our \nplatitude be \u201conce chancy, always chancy\u201d. Your coin flip of yesterday was a chancy event, \ni.e., an event assigned a non-trivial objective chance by the HOC rules in our world.  It still is \nsuch an event. Of course, your credence in the coin landing Heads is probably now either zero \nor 1 \u2013 because you have inadmissible evidence about the outcome, of course.  But the \nprobabilistic nature of a coin flip is the same, whether in your \u201cpast\u201d or your \u201cfuture\u201d. \n \nNext in line is the Lawful Magnitude Principle (LMP), which codifies the idea that \u2018chance \nvalues should fit with the values projected by the laws of nature. For instance, if the chance \nthat the coin lands heads is 0.5, then the laws should codify that value (via history-to-chance \nconditionals)\u2019 (2007, p. 126). This principle codifies the assumption that chances should in \n 33 \nthe end be derivable from fundamental, probabilistic physical laws. However, we submit that \nLM is not (or at any rate should not be) a widely held platitude about chance. There are \nchances that are not connected to fundamental laws (at least not in an obvious way). The \nchance of a particular macrostate transitions in SM, the chance of malfunctioning of a turbine, \nthe chance of cancer after being exposed to a certain amount of radiation, and the chance of \nan increase in global mean temperature of more than two degrees centigrade by 2050 are not \nconnected to fundamental laws and yet, according to THOC, are objective chances. \n \nThe Causal Transition Constraint (CTC) specifies that chances should be pushing events \naround directly, as they unfold in time. CTC stipulates that if an objective chance \u201cplays a \nrole in the causal transition from d to e\u201d, then t must be temporally between td and te.  This \nseems intended to capture the propensity theorist\u2019s conception of chance propensities as \n\u201cpartial causes\u201d helping to bring about events as time unfolds. As with LMP, we would deny \nthat this constraint has the status of a platitude, except to a person who already thinks that \n\u201cchance\u201d means \u201claw-governed primitive propensity\u201d, and furthermore thinks of propensities \nalong the lines of causal powers. It\u2019s status as platitude is also problematic because our best \nfundamental science makes no mention about of this kind of causal transitions at all.\n27\n \n \nLastly, there is the Intrinsicness Requirement (IR) which stipulates that  \u201c[i]f e\u2032 is an intrinsic \nduplicate of e, and the mereological sum of the events at t\u2032 is an intrinsic duplicate of the \nmereological sum of the events at t, then ch<pe, w, t> = ch<pe\u2032 , w, t\u2032>\u201d\n28\n (2007, p. 125). A \nmore intuitive way to read IR is as follows:  if you have the same (physically identical) set-up \nconditions at two different times, then the chances of all their corresponding possible \noutcomes must be the same.  So interpreted, THOC clearly satisfies IR when it comes to BSM \nchances. The platitude \u201csame set-up, same probabilities\u201d will only be violated by HOC\u2019s if \nHM is such that the Best System must contain some time- or space-variable chance rules, i.e. \n 34 \nrules where the rule explicitly states that the chances vary depending only on time or place in \nthe universe. There is no reason to suppose that anything like this is true in our world, and \ncertainly the phenomena falling under BSM show no such non-universality. IR does capture a \nfairly widely held platitude about objective chance, without begging any questions concerning \ndeterminism; and THOC has no trouble complying with it.  \n \nTo sum up:  THOC satisfies suitably qualified versions of PP, LMP, IR and BCP\/RP; and we \ndeny that FP and CT are platitudes about chance.  \n \n \n5.5 Reinventing the wheel? \n \nLoewer  (2001, 2004) has presented a Humean reconciliation of determinism and chance, and \nso we want to end by pointing out wherein the differences lie. To this end let us now come \nback to an assumption we made rather silently but which plays in important role in our \ndiscussion, namely that the systems under investigation are \u2018laboratory systems\u2019 like gases in \ncontainers, liquids in tanks, and solids on tables. This is what SM is mostly applied to in the \nhands of working physicists, and so there is nothing objectionable about this restriction. \nHowever, following Albert (2000), Loewer considerably extends the domain of application of \nthe theory, and treats the entire universe as one large SM system. Much of what we said about \nHOC\u2019s is independent of what one takes the relevant systems to be. There is one essential \ndifference, though, namely how we understand the Humean supervienience of probability \nrules. As we have seen above, we interpret the even distributions over the past state (which \noccur in Equations 2 and 3) as an elegant summary of actual initial conditions as they occur in \nthe HM of a world like ours. Such an interpretation is not open to those who take BSM to be a \n 35 \ntheory about the universe as a whole, since there is only exactly one initial condition of the \nuniverse.  \n \nOur take on the distributions has two advantages over Loewer\u2019s approach. First, postulating a \nprobability distribution for an event that not only happens only once in the entire history of \nthe universe, but is in fact the only probabilistic event ever, seems conceptually problematic \neven if one takes frequency tolerance seriously, and it violates our requirement of Humean \ncoherence. There is no demonstration of how the PHPP supervenes on the classical particle \nmotions in HM; if that rule, applied to numerous small subsystems of the world, does happen \nto make predictions with good fit to the patterns in HM, that is a happy accident, but not \nsomething that obviously follows from the global probability rule postulated in Loewer\u2019s \napproach. \n \nSecond, one can show that the fit of a system can be improved by choosing a peaked rather \nthan a flat (Lebesgue) distribution over \n\uf0a0\uf020\n\uf047p  (Frigg, 2008a, 2010).  A peaked distribution, \nnearly dirac-delta style, over the world\u2019s actual initial condition is, qua postulate, just as \nsimple as a flat distribution, but it will assign significantly higher probabilities to the actual \nworld\u2019s macro-state transitions, and hence give the system to which it belongs a much higher \nfit. So the best system is not one with the flat distribution but one which has a distribution that \nis peaked over the actual initial condition. This has the undesirable conclusion that the \nprobabilities defined in Equations 2 and 3 are not chances. This objection is based on the fact \nthat the distribution over the past state is not dictated by facts about initial conditions (there is \nonly one!) and hence there is a great degree of freedom in choosing the distribution. This is \nnot so if one understands the distribution to be a summary of (many!) actual initial conditions \nof systems like gases all over the Humean mosaic. If the initial conditions of these systems are \nroughly evenly distributed, then one cannot choose a peaked distribution. So that problem is \n 36 \neffectively solved in an approach focussing on small isolated systems rather than the universe \nas a whole.  \n \n \n \n6. Conclusion \n \nWe have provided a reformulation of Lewis\u2019 HBS approach to chance. Thus reformulated, \nHOC\u2019s are compatible with underlying deterministic laws and provide a viable interpretation \nof SM probabilities. A key element in the reconciliation of determinism and chance is the \nrealisation that chances are specific to a certain level. This is a consequence of CRP, which \nwe defend by drawing parallels to the situation in the philosophy of mind.  \n \n \nAcknowledgments \n \nWe would like to thank Nancy Cartwright, Jos\u00e9 D\u00edez, Jossi Berkovitz, Mathias Frisch, Barry \nLoewer, Alan H\u00e1jek, Aidan Lyon, Kristina Musholt, Huw Price, Josefa Toribio, and Eric \nWinsberg, for helpful discussions. Thanks are also due to two anonymous referees for helpful \ncomments. RF acknowledges financial support from Grant FFI2012-37354 of the Spanish \nMinistry of Science and Innovation (MICINN). CH acknowledges the generous support of \nSpanish MICINN grants FFI2008- 06418-C03-03 and FFI2011-29834-C03-03, AGAUR \ngrant SGR2009-01528, and MICINN Consolider-Ingenio grant CSD2009-00056. \n \n \n \n 37 \nReferences \nAlbert, D. (2000). Time and chance. (Cambridge\/MA and London: Harvard University Press.) \nAlbert, D. (2011). Physics and chance. (In Y. Ben-Menahem & M. Hemmo (Ed.), Probability \nin Physics (pp.  17-40).  Berlin: Springer.) \nAnderson, P. W. (1972). More is different. Science, New Series, 177, 393-396. \nBerkovitz, J., Frigg, R., & Kronz, F. (2011). The ergodic hierarchy. (In E. N. Zalta (Ed.), The \nStanford Encyclopedia of Philosophy (pp.  Summer 2011 Edition: \nhttp:\/\/plato.stanford.edu\/archives\/sum2011\/entries\/ergodic-hierarchy\/.) \nCallender, C., & Cohen, J. (2009). A better best system account of lawhood. Philosophical \nStudies, 145, 1-34. \nChurchland, P. (1986). Neurophilosophy: Toward a unified science of the mind\/brain. \n(Cambridge\/MA: MIT Press.) \nChurchland, P. M. (1981). Eliminative materialism and the propositional attitudes. Journal of \nPhilosophy, 78, 67-90. \nDizadji-Bahmani, F., Frigg, R., & Hartmann, S. (2010). Who\u2019s afraid of nagelian reduction. \nErkenntnis, 73, 393-412. \nDupr\u00e9, J. (2006). The constituents of life. http:\/\/www.umb.no\/statisk\/causci\/Spinoza lectures \nDupre.pdf.) \nEarman, J. (1986). A primer on determinsim. (Dordrecht: Reidel.) \nElga, A. (2004). Infinitesimal chances and the laws of nature. Australasian Journal of \nPhilosophy, 82, 67-76. \nFodor, J. (1974). Special sciences and the disunity of science as a working hypothesis. \nSynthese, 28, 77-115. \nFrigg, R. (2008a). Chance in Boltzmannian statistical mechanics. Philosophy of Science 75, \n670\u2013681. \n 38 \nFrigg, R. (2008b). A field guide to recent work on the foundations of statistical mechanics. (In \nD. Rickles (Ed.), The Ashgate Companion to Contemporary Philosophy of Physics \n(pp.  99-196).  London: Ashgate.) \nFrigg, R. (2010). Probability in Boltzmannian statistical mechanics. (In G. Ernst & A. \nH\u00fcttemann (Ed.), Time, Chance and Reduction. Philosophical Aspects of Statistical \nMechanics (pp.  Cambridge: Cambridge University Press.) \nFrigg, R., & Hoefer, C. (2010). Determinism and chance from a Humean perspective. (In D. \nDieks, W. Gonzalez, S. Hartmann, M. Weber, F. Stadler & T. Uebel (Ed.), The \nPresent Situation in the Philosophy of Science (pp.  351-372).  Berlin and New York: \nSpringer.) \nFrigg, R., & Werndl, C. (2011). Explaining thermodynamic-like behaviour In terms of \nepsilon-ergodicity. forthcoming in Philosophy of Science,  \nFrisch, M. (2011). From Boltzmann to Arbuthnot: higher-level laws and the best system. \nPhilosophy of Science, 78, 1001-1011. \nFrisch, M. (forthcoming). Physical fundamentalism in a Lewisian best system. (In A. Wilson \n(Ed.), Asymmetries of chance and time (pp.  Oxford: Oxford University Press.) \nGlynn, L. (2010). Deterministic chance. British Journal for the Philosophy of Science, 61, 51-\n80. \nH\u00e1jek, A. (2007). The reference class problem is your problem too. Synthese, 156,, 563-585. \nHoefer, C. (2007). The third way on objctive probability: A sceptic's guide to objective \nchance. Mind, 116, 549-596. \nHoefer, C. (2013). Consistency and admissibility. (In T. Handfield & A. Wilson (Ed.), \nAsymmetries of Chance and Time (pp.  forthcoming).  Oxford: Oxford University \nPress.) \nHorgan, T., & Woodward, J. (1985 ). Folk psychology is here to stay. Philosophical Review \n94, 197-226. \n 39 \nKim, J. (1998). The mind-body problem after fifty years. (In A. O'Hear (Ed.), Current Issues \nin Philosophy of Mind (pp.  3\u201321).  Cambridge: Cambridge University Press.) \nLavis, D. (2005). Boltzmann and Gibbs: An attempted reconciliation. Studies in History and \nPhilosophy of Modern Physics, 36, 245-73. \nLehe, R., Hallatschek, O., & Peliti, L. (2012). The rate of beneficial mutations surfing on the \nwave of a range expansion. PLoS Computatinal Biology, 8, e1002447. \nLewis, D. (1980). A subjectivist\u2019s guide to objective chance. (In R. C. Jeffrey (Ed.), Studies in \nInductive Logic and Probability. Vol. 2 (pp.  Berkeley: University of California Press, \nreprinted in Lewis 1986, 83-132, with postscripts added.) \nLewis, D. (1983). New work for a theory of universals. Australasian Journal of Philosophy, \n61, 343-377. \nLewis, D. (1986). Philosophical papers. (Oxford: Oxford University Press.) \nLewis, D. (1994). Humean supervenience debugged. Mind, 103, 473-490. \nLewis, D. (1999). Papers in metaphysics and epistemology. (Cambridge: Cambridge \nUniversity Press.) \nLoewer, B. (2001). Determinism and chance. Studies in History and Philosophy of Modern \nPhysics, 32, 609-629. \nLoewer, B. (2004). David Lewis\u2019 Humean theory of objective chance. Philosophy of Science, \n71, 1115-1125. \nLyon, A. (2011). Deterministic probability: Neither chance nor credence. Synthese, 182, 413-\n432. \nRedhead, M. (1995). From physics to metaphysics. (Cambridge: Cambridge University \nPress.) \nSchaffer, J. (2007). Deterministic chance? British Journal for the Philosophy of Science, 58, \n113-40  \n 40 \nSchrenk, M. (2008). A theory for special sciences laws. (In H. Bohse, K. Dreimann & S. \nWalter (Ed.), Selected Papers Contributed to the Sections of GAP.6, 6th International \nCongress of the Society for Analytical Philosophy (pp.  Paderborn: Mentis.) \nUffink, J. (2006). Compendium of the foundations of classical statistical physics. (In J. \nButterfield & J. Earman (Ed.), Philosophy of Physics (pp.  923-1047).  Amsterdam: \nNorth Holland.) \nvan Inwagen, P. (1994). Composition as identity. Philosophical Perspectives, 8,  \nWeinberg, S. (1993). Dreams of a final theory: The search for the fundamental laws of nature. \n(New York: Vintage.) \n \n \n \n1\n The presentation of HOC in this section is based on our (2010). The classical source is (Lewis, 1980). But as \nwe will see below, our version of HOC differs from Lewis\u2019 in important respects.  \n2\n As is well known, there are different axiomatisations of probability. Nothing in what follows depends on which \naxiomatisation we chose.  \n3\n We use this term in restrictive way: only statements having exactly that form are chance rules. Existence \nclaims, statements about upper and lower bounds, or specifications of probability intervals are not chance rules \nin our sense.  \n4\n This point has been made by Alan H\u00e1jek (2007) for propensities. His arguments readily carry over to any \nnotion of chance.  \n5\n In this we disagree with Lewis, who thought it a major problem to prove that chances satisfy the axioms of \nprobability. THOC defines chance, and a function that does not satisfy the axioms of probability cannot be a \nchance function. \n6\n Justifying PP is a thorny issue, and, unsurprisingly, one fraught with controversy. We refer the reader to our \n(2010, Section 3.4) and references therein for a discussion.  \n7\n For a discussion see Hoefer (2007, 553-5 and 558-60). Some philosophers maintain that the PP needs no \nadmissibility clause (e.g. Meacham 2010). For counter-arguments in favour of the necessity of an admissibility \nclause in PP see (Hoefer, 2013).  \n \n 41 \n \n8\n Note that even if you believe that the world does contain necessary connections, powers or propensities, it still \nalso has a HM. The HM is just the panoply of actual events understood as purely occurrent, setting aside any \nmodal aspects those events may possess. The Humean about chance then simply maintains that chance facts \nsupervene on this HM. \n9\n For a discussion of infinite sequences see (Elga, 2004). \n10\n The assumption that macrostates can be indexed by an integer k is a common idealisation in this context and \nwe follow this convention here; see (Frigg, 2008b) and references therein.  \n11\n This definition of TD-likeness is adapted from Lavis (2005). A different way reformulating the Second Law \nemerges from (Albert, 2000).  We prefer an approach based on TD-likeness for the reasons outlined in (Frigg \nand Werndl, 2011) and use it here because it\u2019s simpler than Albert\u2019s. Noting we say about chance depends on \nthis choice, though, and mutatis mutandis our account of chance can also be applied to Albert\u2019s transition \nprobabilities.  \n12\n We base our discussion on the standard possible worlds definition of determinism; see (Earman, 1986, Ch. 2).  \n13\n We restrict attention to Boltzmannian SM. For detailed discussions of that theory, as well as of the Gibbsian \napproach which we set aside here, see Frigg (2008b) and Uffink (2006).  \n14\n Note that the term \u2018Past Hypothesis\u2019 is usually reserved for approaches in which the system under \nconsideration is the entire universe; it then says that the universe came into being in a low entropy macrostate \nprovided to us by modern Big Bang cosmology. We return to the issue of the nature of systems studied in SM \nSection 5.5.  \n15\n For an accessible introduction see (Berkovitz, Frigg, and Kronz, 2011). We assume that the relevant systems \nare ergodic (Frigg and Werndl, 2011). \n16\n Note that determining what will happen is not the same as entailing that the objective chance of something \nhappening is equal to one (and mutatis mutandis for not happening and chance equal to zero). \n17\n Note that on our understanding of admissibility, it is not closed under logical conjunction, as Lewis supposed \nit to be. \n18\n While Lewis tried to supress this element of pragmatism and user-relativity as much as he could without \nactually saying much at all about simplicity and strength, other BSA advocates such as Albert (2011), Callender \nand Cohen (2009) and Schrenk (2008) have openly embraced it. \n19\n That said, we are sympathetic  with Lewis\u2019 line on this point (1994, 479): we may, not unreasonably in light of \nactual science, hope that there is one robustly Best System for our HM, or a small family of closely resembling \n \n 42 \n \ncousins, that come out as Best under any reasonable ways of cashing out and weighing up the qualities of \nsimplicity, strength and fit. \n20\n Roughly, the Kolmogorov complexity is the length of the shortest computer programme that derives a certain \nresult. With respect to a given language, the Kolmogorov complexity is an objective quantity.  \n21\n In a phenomenon known as \u2018gene surfing\u2019, genetic drift becomes a much stronger evolutionary force in \npopulations at the edge of a territorial expansion wave, because genes from the individuals at\/near the edge of \nthe wave will be disproportionately represented in the gene pool of the newly colonized regions in subsequent \ngenerations. Lehe, Hallatschek and Peliti (2012) propose (in our terms) chance rules for the fixation of a \nfavorable mutation as a function of distance of the individual in which the mutation occurs from the edge of the \ncolonization wave. \n22\n For a discussion of this point see (Frisch, 2011, forthcoming).  \n23\n This is so even if the output of the rule is merely a chance rather than a yes\/no determination. When it comes \nto the chance p(TS) , which is almost always near-1, the information conveyed to the agent is nearly as strong \nas what is entailed by (but impossible to derive from) the deterministic laws plus IC\u2019s.  \n24\n In this section our discussion idealises by pretending that the histories of all sorts of different SM systems \ncould be treated as representable via paths in a single phase space. This is an idealisation because systems with a \ndifferent particle number N have different phase spaces. We think that this is no threat to our approach. SM \nsystems such as expanding gases and cooling solids are ubiquitous in HM and there will be enough of them for \nmost N to ground a HBS supervenience claim. Those for which this is not the case (probably ones with very \nlarge N) can be treated along the lines of rare gambling devices such as dodecahedra: they will be seen as falling \ninto the same class as more common systems and a flat distribution over possible initial conditions will be the \nbest distribution in much the same way in which the 1\/n rule is the best for all gambling devices. \n25\n In section 4 we argued that if allowed to compete, some higher-level rules or laws may well deserve to make it \ninto the Best System. Here the question is the prior one, which Lewis answered negatively:  should such rules \neven be allowed to compete? \n26\n Fodor famously used multiple realisability as an argument against reduction (1974). Following (Dizadji-\nBahmani, Frigg, and Hartmann, 2010) we think that this is going too far, but multiple realisability does provide \nan argument against eliminativism. \n27\n Lyon (2011) and Glynn (2010, 25-6) argue convincingly that CTC is unacceptable in any case no matter what \nview of chance one adopts. \n \n 43 \n \n28\n In Schaffer\u2019s notation, ch<pe, w, t> is the chance in world w, assessed at time t, that the proposition pe \n(asserting that event e happens) is true.  \n"}
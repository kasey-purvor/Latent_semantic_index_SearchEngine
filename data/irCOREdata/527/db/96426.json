{"doi":"10.1214\/09-AOS702","coreId":"96426","oai":"oai:eprints.lse.ac.uk:31421","identifiers":["oai:eprints.lse.ac.uk:31421","10.1214\/09-AOS702"],"title":"Inference for stochastic volatility models using time change transformations","authors":["Kalogeropoulos, Konstantinos","Roberts, Gareth O.","Dellaportas, Petros"],"enrichments":{"references":[{"id":17287779,"title":"A closed-form solution for options with stochastic volatility. with applications to bonds and currency options. Review of Financial Studies,","authors":[],"date":"1993","doi":"10.1093\/rfs\/6.2.327","raw":"Heston, S. (1993). A closed-form solution for options with stochastic volatility. with applications to bonds and currency options. Review of Financial Studies, 6:327\u2013343.","cites":null},{"id":17287781,"title":"Bayesian estimation of continuous-time \ufb01nance models. Unpublished paper,","authors":[],"date":"1999","doi":null,"raw":"Jones, C. S. (1999). Bayesian estimation of continuous-time \ufb01nance models. Unpublished paper, Simon School of Business, University of Rochester.","cites":null},{"id":17287777,"title":"Bayesian inference for nonlinear multivariate di\ufb00usions observed with error.","authors":[],"date":"2007","doi":"10.1016\/j.csda.2007.05.019","raw":"Golightly, A. and Wilkinson, D. (2007). Bayesian inference for nonlinear multivariate di\ufb00usions observed with error. Computational Statistics and Data Analysis, 52(3), 1674\u20131693.","cites":null},{"id":17287776,"title":"Bayesian sequential inference for nonlinear multivariate di\ufb00usions.","authors":[],"date":"2006","doi":"10.1007\/s11222-006-9392-x","raw":"Golightly, A. and Wilkinson, D. (2006). Bayesian sequential inference for nonlinear multivariate di\ufb00usions. Statistics and Computing, 16:323\u2013338.","cites":null},{"id":17287760,"title":"Closed form likelihood expansions for multivariate di\ufb00usions.","authors":[],"date":"2008","doi":"10.3386\/w8956","raw":"A\u00a8 \u0131t-Sahalia, Y. (2008). Closed form likelihood expansions for multivariate di\ufb00usions. Annals of Statistics, 36:906\u2013937.","cites":null},{"id":17287785,"title":"Combined parameter and state estimation in simulation-based \ufb01ltering In Sequential Monte Carlo Methods in Practice, by","authors":[],"date":"2001","doi":"10.1007\/978-1-4757-3437-9_10","raw":"Liu, J. and West, M. (2001). Combined parameter and state estimation in simulation-based \ufb01ltering In Sequential Monte Carlo Methods in Practice, by A. Doucet, J.F.G. De Freitas and N.J. Gordon, SpringerVerlag, New York.","cites":null},{"id":17287792,"title":"Di\ufb00usions, Markov processes and martingales, 2, Ito calculus.","authors":[],"date":"1994","doi":"10.1017\/cbo9780511805141.002","raw":"Rogers, L. C. G. and Williams, D. (1994). Di\ufb00usions, Markov processes and martingales, 2, Ito calculus. Wiley, Chicester.","cites":null},{"id":17287765,"title":"E\ufb03cient likelihood based inference for observed and partially observed di\ufb00usions.","authors":[],"date":"2007","doi":"10.1111\/1468-0262.00226","raw":"Chib, S., Pitt, M. K., and Shephard, N. (2007). E\ufb03cient likelihood based inference for observed and partially observed di\ufb00usions. Submitted.","cites":null},{"id":17287761,"title":"Estimating continuous-time stochastic volatility models of the short term interest rate.","authors":[],"date":"1998","doi":"10.1016\/s0304-4076(96)01819-2","raw":"Andersen, T. G. and Lund, J. (1998). Estimating continuous-time stochastic volatility models of the short term interest rate. Journal of Econometrics, 77:343\u2013377.","cites":null},{"id":17287772,"title":"Estimating stochastic di\ufb00erential equations e\ufb03ciently by minimum chi-squared.","authors":[],"date":"1997","doi":"10.1093\/biomet\/84.1.125","raw":"Gallant, A. R. and Long, J. R. (1997). Estimating stochastic di\ufb00erential equations e\ufb03ciently by minimum chi-squared. Biometrika, 84(1):125\u2013141.","cites":null},{"id":17287762,"title":"Exact and computationally e\ufb03cient likelihood-based estimation for discretely observed di\ufb00usion processes (with discussion).","authors":[],"date":"2006","doi":"10.1111\/j.1467-9868.2006.00552.x","raw":"Beskos, A., Papaspiliopoulos, O., Roberts, G., and Fearnhead, P. (2006). Exact and computationally e\ufb03cient likelihood-based estimation for discretely observed di\ufb00usion processes (with discussion). Journal of the Royal Statistical Society: Series B (Statistical Methodology), 68(3):333\u2013382.","cites":null},{"id":17287763,"title":"Exact simulation of di\ufb00usions.","authors":[],"date":"2005","doi":"10.1214\/105051605000000485","raw":"Beskos, A. and Roberts, G. O. (2005). Exact simulation of di\ufb00usions. Ann. Appl. Probab., 15(4):2422\u20132444.","cites":null},{"id":17287788,"title":"Filtering via Simulation: Auxiliary Particle Filters.","authors":[],"date":"1999","doi":"10.2307\/2670179","raw":"Pitt, M.K. and Shephard, N. (1999). Filtering via Simulation: Auxiliary Particle Filters. Journal of the American Statistical Association, 94(446):590\u2013599.","cites":null},{"id":17287778,"title":"Indirect inference.","authors":[],"date":"1993","doi":"10.1002\/jae.3950080507","raw":"Gouri\u00b4 eroux, C., Monfort, A., and Renault, E. (1993). Indirect inference. Journal of Applied Econometrics, 8:S85\u2013S118.","cites":null},{"id":17287766,"title":"Likelihod based speci\ufb01cation analysis of continuous time models of the short term interest rate.","authors":[],"date":"2002","doi":"10.1016\/s0304-405x(03)00207-1","raw":"Durham, G. B. (2002). Likelihod based speci\ufb01cation analysis of continuous time models of the short term interest rate. Journal of Financial Economics. Forthcoming.","cites":null},{"id":17287784,"title":"Likelihood based inference for a class of multidimensional di\ufb00usions with unobserved paths.","authors":[],"date":"2007","doi":"10.1016\/j.jspi.2006.05.017","raw":"Kalogeropoulos, K. (2007). Likelihood based inference for a class of multidimensional di\ufb00usions with unobserved paths. Journal of Statistical Planning and Inference, 137:3092\u20133102 Kalogeropoulos, K., Dellaportas, P., and Roberts, G. (2007). Likelihood-based inference for correllated di\ufb00usions. Submitted.","cites":null},{"id":17287769,"title":"Likelihood inference for discretely observed non-linear di\ufb00usions.","authors":[],"date":"2001","doi":"10.1111\/1468-0262.00226","raw":"Elerian, O. S., Chib, S., and Shephard, N. (2001). Likelihood inference for discretely observed non-linear di\ufb00usions. Econometrica, 69:959\u2013993.","cites":null},{"id":17287770,"title":"Markov chain Monte Carlo analysis of di\ufb00usion models with application to \ufb01nance.","authors":[],"date":"2001","doi":"10.1198\/073500101316970403","raw":"Eraker, B. (2001). Markov chain Monte Carlo analysis of di\ufb00usion models with application to \ufb01nance. J. Bus. Econom. Statist., 19(2):177\u2013191.","cites":null},{"id":17287764,"title":"Martingale estimating functions for discretely observed di\ufb00usion processes.","authors":[],"date":"1995","doi":"10.2307\/3318679","raw":"Bibby, B. and Sorensen, M. (1995). Martingale estimating functions for discretely observed di\ufb00usion processes. Bernoulli, 1:17\u201339.","cites":null},{"id":17287758,"title":"Maximum likelihood estimation of discretely sampled di\ufb00usions: a closed form approximation approach.","authors":[],"date":"2002","doi":"10.1111\/1468-0262.00274","raw":"A\u00a8 \u0131t-Sahalia, Y. (2002). Maximum likelihood estimation of discretely sampled di\ufb00usions: a closed form approximation approach. Econometrica, 70:223\u2013262.","cites":null},{"id":17287783,"title":"Nonlinear mean reversion in the short-term interest rate. The review of \ufb01nancial studies,","authors":[],"date":"2003","doi":"10.1093\/rfs\/hhg014","raw":"Jones, C. S. (2003). Nonlinear mean reversion in the short-term interest rate. The review of \ufb01nancial studies, 16:793\u2013843.","cites":null},{"id":17287768,"title":"Numerical techniques for maximum likelihood estimation of continuous-time di\ufb00usion processes.","authors":[],"date":"2002","doi":"10.1198\/073500102288618397","raw":"Durham, G. B. and Gallant, A. R. (2002). Numerical techniques for maximum likelihood estimation of continuous-time di\ufb00usion processes. J. Bus. Econom. Statist., 20(3):297\u2013316. With comments and a reply by the authors.","cites":null},{"id":17287790,"title":"On inference for partial observed nonlinear di\ufb00usion models using the metropolis-hastings algorithm.","authors":[],"date":"2001","doi":"10.1093\/biomet\/88.3.603","raw":"Roberts, G. and Stramer, O. (2001). On inference for partial observed nonlinear di\ufb00usion models using the metropolis-hastings algorithm. Biometrika, 88(3):603\u2013621.","cites":null},{"id":17287793,"title":"Parametric inference for di\ufb00usion processes observed at discrete points in time: a survey.","authors":[],"date":"2004","doi":"10.1111\/j.1751-5823.2004.tb00241.x","raw":"20S\u00f8rensen, H. (2004). Parametric inference for di\ufb00usion processes observed at discrete points in time: a survey. International Statistical Review, 72(3):337\u2013354.","cites":null},{"id":17287771,"title":"Particle \ufb01lters for partially observed di\ufb00usions.","authors":[],"date":"2008","doi":"10.1111\/j.1467-9868.2008.00661.x","raw":"19Fearnhead, P. and Papaspiliopoulos, O. and Roberts, G.O. (2008). Particle \ufb01lters for partially observed di\ufb00usions. Journal of Royal Statistical Society: Series B (Statistical Methodology)., 70(4):755\u2013777.","cites":null},{"id":17287795,"title":"Practical \ufb01ltering for stochastic volatility models. In State Space and Unobserved Component Models, (by Harvey et al.),","authors":[],"date":"2004","doi":"10.1017\/cbo9780511617010.012","raw":"Stroud, J.R. and Polson, N.G. and Muller P. (2004). Practical \ufb01ltering for stochastic volatility models. In State Space and Unobserved Component Models, (by Harvey et al.), Cambridge University Press 236\u2013247.","cites":null},{"id":17287774,"title":"Reprojecting partially observed systems with applications to interest rate di\ufb00usions.","authors":[],"date":"1998","doi":"10.1080\/01621459.1998.10474083","raw":"Gallant, A. R. and Tauchen, G. (1998). Reprojecting partially observed systems with applications to interest rate di\ufb00usions. Journal of American Statistical Association, 93(441):10\u201324.","cites":null},{"id":17287787,"title":"Retrospective MCMC for Dirichlet process hierarchical models.","authors":[],"date":"2008","doi":"10.1093\/biomet\/asm086","raw":"Papaspiliopoulos, O. and Roberts, G. (2008). Retrospective MCMC for Dirichlet process hierarchical models. Biometrika, 95(1):169\u2013186 Pedersen, A. R. (1995). A new approach to maximum likelihood estimation for stochastic di\ufb00erential equations based on discrete observations. Scand. J. Statist., 22(1):55\u201371.","cites":null},{"id":17287786,"title":"Stochastic di\ufb00erential equations.","authors":[],"date":"2000","doi":"10.1007\/978-3-642-14394-6","raw":"Oksendal, B. (2000). Stochastic di\ufb00erential equations. Springer, 5th edition.","cites":null},{"id":17287794,"title":"Stock proce distributions with stochastic volatility: an analytic approach.","authors":[],"date":"1991","doi":"10.1093\/rfs\/4.4.727","raw":"Stein, E. M. and Stein, J. C. (1991). Stock proce distributions with stochastic volatility: an analytic approach. Review of Financial Studies, 4(4):727\u2013752.","cites":null},{"id":17287796,"title":"The calculation of posterior distributions by data augmentation.","authors":[],"date":"1987","doi":"10.2307\/2289457","raw":"Tanner, M. A. and Wong, W. H. (1987). The calculation of posterior distributions by data augmentation. Journal of the American Statistical Association, 82(398):528\u2013540.","cites":null},{"id":17287780,"title":"The pricing of options on assets with stochastic volatilities.","authors":[],"date":"1987","doi":"10.2307\/2328253","raw":"Hull, J. C. and White, A. D. (1987). The pricing of options on assets with stochastic volatilities. Journal of Finance, 42(2):281\u2013300.","cites":null},{"id":17287773,"title":"Which moments to match? Econometric Theory,","authors":[],"date":"1996","doi":"10.1017\/s0266466600006976","raw":"Gallant, A. R. and Tauchen, G. (1996). Which moments to match? Econometric Theory, 12(4):657\u2013681.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010","abstract":"We address the problem of parameter estimation for diffusion\\ud\ndriven stochastic volatility models through Markov chain Monte\\ud\nCarlo (MCMC). To avoid degeneracy issues we introduce an\\ud\ninnovative reparametrisation defined through transformations that\\ud\noperate on the time scale of the diffusion. A novel MCMC scheme\\ud\nwhich overcomes the inherent difficulties of time change\\ud\ntransformations is also presented. The algorithm is fast to\\ud\nimplement and applies to models with stochastic volatility. The\\ud\nmethodology is tested through simulation based experiments and\\ud\nillustrated on data consisting of US treasury bill rates","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/96426.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/31421\/1\/Inference_for_diffusion_models_using_time_change_transformations_%28LSERO%29.pdf","pdfHashValue":"e329eb20025b78b7e30b6042d3c3b8e248d49ecb","publisher":"IMS","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:31421<\/identifier><datestamp>\n      2014-05-30T10:41:19Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5354<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/31421\/<\/dc:relation><dc:title>\n        Inference for stochastic volatility models using time change transformations<\/dc:title><dc:creator>\n        Kalogeropoulos, Konstantinos<\/dc:creator><dc:creator>\n        Roberts, Gareth O.<\/dc:creator><dc:creator>\n        Dellaportas, Petros<\/dc:creator><dc:subject>\n        QA Mathematics<\/dc:subject><dc:description>\n        We address the problem of parameter estimation for diffusion\\ud\ndriven stochastic volatility models through Markov chain Monte\\ud\nCarlo (MCMC). To avoid degeneracy issues we introduce an\\ud\ninnovative reparametrisation defined through transformations that\\ud\noperate on the time scale of the diffusion. A novel MCMC scheme\\ud\nwhich overcomes the inherent difficulties of time change\\ud\ntransformations is also presented. The algorithm is fast to\\ud\nimplement and applies to models with stochastic volatility. The\\ud\nmethodology is tested through simulation based experiments and\\ud\nillustrated on data consisting of US treasury bill rates.<\/dc:description><dc:publisher>\n        IMS<\/dc:publisher><dc:date>\n        2010<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/31421\/1\/Inference_for_diffusion_models_using_time_change_transformations_%28LSERO%29.pdf<\/dc:identifier><dc:identifier>\n          Kalogeropoulos, Konstantinos and Roberts, Gareth O. and Dellaportas, Petros  (2010) Inference for stochastic volatility models using time change transformations.  Annals of Statistics, 38 (2).  pp. 784-807.  ISSN 0090-5364     <\/dc:identifier><dc:relation>\n        http:\/\/www.imstat.org\/aos\/<\/dc:relation><dc:relation>\n        10.1214\/09-AOS702<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/31421\/","http:\/\/www.imstat.org\/aos\/","10.1214\/09-AOS702"],"year":2010,"topics":["QA Mathematics"],"subject":["Article","PeerReviewed"],"fullText":"  \nKonstantinos Kalogeropoulos \nInference for diffusion models using time \nchange transformations \n \nArticle (Accepted version) \n(Refereed) \nOriginal citation: \nKalogeropoulos, Konstantinos and Roberts, Gareth O. and Dellaportas, Petros (2010) Inference \nfor diffusion models using time change transformations. Annals of statistics, 38 (2). pp. 784-807. \n \nDOI: 10.1214\/09-AOS702\n \n\u00a9 2007 IMS\n \nThis version available at: http:\/\/eprints.lse.ac.uk\/31421\/\n \nAvailable in LSE Research Online: January 2011 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final manuscript accepted version of the journal article, \nincorporating any revisions agreed during the peer review process.  Some differences between \nthis version and the published version may remain.  You are advised to consult the publisher\u2019s \nversion if you wish to cite from it. \nInference for stochastic volatility models using time\nchange transformations\nKonstantinos Kalogeropoulos, Gareth O. Roberts and Petros Dellaportas\nAbstract\nWe address the problem of parameter estimation for diffusion driven stochastic volatility models\nthrough Markov chain Monte Carlo (MCMC). To avoid degeneracy issues we introduce an innovative\nreparametrisation defined through transformations that operate on the time scale of the diffusion. A\nnovel MCMC scheme which overcomes the inherent difficulties of time change transformations is also\npresented. The algorithm is fast to implement and applies to models with stochastic volatility. The\nmethodology is tested through simulation based experiments and illustrated on data consisting of US\ntreasury bill rates.\n1 Introduction\nDiffusion processes provide natural models for continuous time phenomena. They are used extensively\nin diverse areas such as finance, biology and physics. A diffusion process is defined through a stochastic\ndifferential equation (SDE)\ndXt = \u00b5(t,Xt, \u03b8)dt+ \u03c3(t,Xt, \u03b8)dWt, 0 \u2264 t \u2264 T, (1)\nwhere W is standard Brownian motion. The drift \u00b5(.) and volatility \u03c3(.) reflect the instantaneous mean\nand standard deviation respectively. In this paper we assume the existence of a unique weak solution to (1),\nwhich translates into some regularity conditions (locally Lipschitz with a linear growth bound) on \u00b5(.) and\n\u03c3(.); see chapter 5 of Rogers and Williams (1994) for more details.\nThe task of inference for diffusion processes is particularly challenging and has received remarkable\nattention in the recent literature; see S\u00f8rensen (2004) for an extensive review. The main difficulty is inherent\nin the nature of diffusions which are infinite dimensional objects. However, only a finite number of points may\nbe observed and the marginal likelihood of these observations is generally unavailable in closed form. This has\nstimulated the development of various non-likelihood approaches which use indirect inference (Gourie\u00b4roux\net al., 1993), estimating functions (Bibby and Sorensen, 1995), or the efficient method of moments (Gallant\nand Tauchen, 1996); see also Gallant and Long (1997).\nMost likelihood based methods approach the likelihood function through the transition density of (1).\nDenote the observations by Yk, k = 0, . . . , n, and with tk their corresponding times. If the dimension of Yk\nequals that of X (for each k) we can use the Markov property to write the likelihood, given the initial point\nY0, as:\nL(Y, \u03b8|Y0) =\nn\u220f\nk=1\npk(Yk|Yk\u22121; \u03b8,\u2206), \u2206 = tk \u2212 tk\u22121 (2)\nThe transition densities pk(.) are not available in closed form but several approximations are available. They\nmay be analytical, see A\u0131\u00a8t-Sahalia (2002), A\u0131\u00a8t-Sahalia (2008), or simulation based, see Pedersen (1995),\nDurham and Gallant (2002). They usually approximate the likelihood in a way so that the discretisation\nerror can become arbitrarily small, although the methodology developed in Beskos et al. (2006) succeeds\nexact inference in the sense that it allows only for Monte Carlo error. A potential downside of these methods\n1\nmay be their dependence on the Markov property. In many interesting multidimensional diffusion models\nthe observation regime is different and some of their components are not observed at all.\nA famous such example is provided by stochastic volatility models, used extensively to model financial\ntime series such as equity prices (Heston, 1993; Hull and White, 1987; Stein and Stein, 1991), or interest\nrates (Andersen and Lund, 1998; Durham, 2002; Gallant and Tauchen, 1998). A stochastic volatility model\nis usually represented by a 2-dimensional diffusion(\ndXt\nd\u03b1t\n)\n=\n(\n\u00b5x(Xt, \u03b1t, \u03b8)\n\u00b5\u03b1(\u03b1t, \u03b8)\n)\ndt+\n(\n\u03c3x(\u03b1t, \u03b8) 0\n0 \u03c3\u03b1(\u03b1t, \u03b8)\n)(\ndBt\ndWt\n)\n, (3)\nwhere X denotes the observed equity (stock) log-price or the short term interest rate with volatility \u03c3x(.),\nwhich is a function of a latent diffusion \u03b1. Note that the observed process X in (3) is not Markov; the\ndistribution of a future stock price depends (besides the current price) on the current volatility which in\nturn depends on the entire price history. Nevertheless, since the 2-dimensional diffusion is Markov, state\nspace approaches are possible and may be implemented using sequential Monte Carlo techniques Pitt and\nShephard (1999), Fearnhead et al (2008). While such approaches allow for online estimation of the volatility,\nvarious implications arise regarding inference for the diffusion parameters Liu and West (2001), Stroud et al\n(2004).\nAn alternative approach to the problem adopts Bayesian inference utilising Markov chain Monte Carlo\n(MCMC) methods. Adhering to the Bayesian framework, a prior p(\u03b8) is first assigned on the parameter\nvector \u03b8. Then, given the observations Y , the posterior p(\u03b8|Y ) can be explored through data augmentation\n(Tanner and Wong, 1987), treating the unobserved paths of X (paths between observations) as missing data.\nNote that the augmented diffusion satisfies the Markov property irrespectively of the observation regime.\nHence data augmentation approaches are more general.\nInitial MCMC schemes following this programme were introduced by Jones (1999); see also Jones (2003),\nEraker (2001) and Elerian et al. (2001). However, as noted in the simulation based experiment of Elerian\net al. (2001) and established theoretically by Roberts and Stramer (2001), any such algorithm\u2019s convergence\nproperties will degenerate as the number of imputed points increases. The problem may be overcome with\nthe reparametrisation of Roberts and Stramer (2001), and this scheme may be applied in all one-dimensional\nand some multi-dimensional contexts. However this framework does not cover general multidimensional\ndiffusion models. Chib et al. (2007) and Kalogeropoulos (2007) offer appropriate reparametrisations but\nonly for a class of stochastic volatility models. Alternative reparametrisations were introduced in Golightly\nand Wilkinson (2007); see also Golightly and Wilkinson (2006) for a sequential approach.\nIn this paper we introduce a novel reparametrisation that, unlike previous MCMC approaches, operates\non the time scale of the observed diffusion rather than its path. This facilitates the construction of irreducible\nand efficient MCMC schemes, designed appropriately to accommodate the time change of the diffusion path.\nBeing a data augmentation procedure, our approach does note rely on the Markov property and can be\napplied to a much larger class of diffusions than those considered in A\u0131\u00a8t-Sahalia (2002) and Beskos et al.\n(2006). Moreover it may be coupled with the approaches of Roberts and Stramer (2001) and Chib et al.\n(2007) to handle more general models, that is almost every stochastic volatility model used in practice.\nThe paper is organized as follows: Section 2 elaborates on the need for a transformation of the diffusion\nto avoid problematic MCMC algorithms. In Section 3 we introduce a class of transformations based on\nchanging the time scale of the diffusion process. Section 4 provides the details for the corresponding non-\ntrivial MCMC implementation. The proposed methodology of the paper is tested and illustrated through\nnumerical experiments in section 5, and on US treasury bill rates in section 6. Finally, section 7 concludes\nand provides some relevant discussion.\n2 The necessity of reparametrisation\nA Bayesian data augmentation scheme bypasses a problematic sampling from the posterior pi(\u03b8|Y ) by in-\ntroducing a latent variable X that simplifies the likelihood L(Y ;X , \u03b8). It usually involves the following two\nsteps:\n2\n1. Simulate X conditional on Y and \u03b8.\n2. Simulate \u03b8 from the augmented conditional posterior which is\nproportional to L(Y ;X , \u03b8)pi(\u03b8).\nIt is not hard to adapt our problem to this setting. Y represents the observations of the price process\nX . The latent variables X introduced to simplify the likelihood evaluations are discrete skeletons of diffu-\nsion paths between observations or entirely unobserved diffusions. In other words, X is a fine partition of\nmultidimensional diffusion with drift \u00b5X(t,Xt, \u03b8) and diffusion matrix\n\u03a3X(t,Xt, \u03b8) = \u03c3(t,Xt, \u03b8) \u00d7 \u03c3(t,Xt, \u03b8)\n\u2032,\nand the augmented dataset is Xi\u03b4, i = 0, . . . , T\/\u03b4, where \u03b4 specifies the amount of augmentation. The\nlikelihood can be approximated via the Euler scheme\nLE(Y ;X , \u03b8) =\nT\/\u03b4\u220f\ni=1\np(Xi\u03b4|X(i\u22121)\u03b4), Xi\u03b4|X(i\u22121)\u03b4 \u223c N\n(\nX(i\u22121)\u03b4 + \u03b4\u00b5X (.), \u03b4\u03a3X (.)\n)\n,\nwhich is known to converge to the true likelihood L(Y ;X , \u03b8) for small \u03b4 (Pedersen, 1995).\nAnother property of diffusion processes relates \u03a3X (.) to the quadratic variation process. Specifically we\nknow that\nlim\n\u03b4\u21920\nT\/\u03b4\u2211\ni=1\n(\nXi\u03b4 \u2212X(i\u22121)\u03b4\n) (\nXi\u03b4 \u2212X(i\u22121)\u03b4\n)T\n=\n\u222b T\n0\n\u03a3X (s,Xs, \u03b8)ds a.s.\nThe solution of the equation above determines the diffusion matrix parameters. Hence, there exists\nperfect correlation between these parameters and X as \u03b4 \u2192 0. This has disastrous implications for the\nmixing and convergence of the MCMC chain as it translates into reducibility for \u03b4 \u2192 0. This issue was first\nnoted by Roberts and Stramer (2001) for scalar diffusions and also confirmed by the simulation experiment\nof Elerian et al. (2001). In fact the convergence time is of O(1\u03b4 ). This problem is not MCMC specific as it\nturns out that the convergence of its deterministic analogue, EM algorithm, is also problematic when the\namount of information in the augmented data X strongly exceeds that of the observations. In our case X\ncontains an infinite amount of information for \u03b4 \u2192 0.\nThe problem may be resolved if we apply a transformation so that the algorithm based on the trans-\nformed diffusion is no longer reducible as \u03b4 \u2192 0. Roberts and Stramer (2001) provide appropriate diffusion\ntransformations for scalar diffusions. In a multivariate context this requires a transformation to a diffusion\nwith unit volatility matrix; see for instance Kalogeropoulos et al. (2007). A\u0131\u00a8t-Sahalia (2008) terms such\ndiffusions as reducible and proves the non-reducibility of stochastic volatility models that obey (3). The\ntransformations introduced in this paper follow a slightly different route and target the time scale of the\ndiffusion. Since the construction obeys the same principles of Roberts and Stramer (2001) the convergence\ntime of the algorithm is independent of augmentation level controlled by \u03b4. Another appealing features of\nsuch a reparametrisation is the generalisation to stochastic volatility models.\n3 Time change transformations\nFor ease of illustration we first provide the time change transformation and the relevant likelihood function\nfor scalar diffusion models with constant volatility. Nevertheless, one of the main advantages of this technique\nis the applicability to general stochastic volatility models.\n3\n3.1 Scalar diffusions\nConsider a diffusion X defined through the following SDE:\ndXt = \u00b5(t,Xt, \u03b8)dt+ \u03c3dW\nX\nt , 0 < t < 1 \u03c3 > 0. (4)\nWithout loss of generality, we assume a pair of observations X0 = y0 and X1 = y1. For more data, note\nthat the same operations are possible for every pair of successive observations, and these pairs are linked\ntogether through the Markov property. We introduce the latent \u2018missing\u2019 path of X for 0 \u2264 t \u2264 1, denoted\nby Xmis, so that X = (y0, X\nmis, y1). In the spirit of Roberts and Stramer (2001), the goal is to write\nthe likelihood for \u03b8, \u03c3 with respect to a parameter-free dominating measure. Using Girsanov\u2019s theorem we\ncan get the Radon-Nikodym derivative between the law of the diffusion X, denoted by PX , and that of the\ndriftless diffusion dMt = \u03c3dW\nX\nt which represents Wiener measure and is denoted by W\nX . We write\ndPX(X)\ndWX\n= G(t,X, \u03b8, \u03c3) = exp\n{\u222b 1\n0\n\u00b5(t,Xt, \u03b8)\n\u03c32\ndXt \u2212\n1\n2\n\u222b 1\n0\n\u00b5(t,Xt, \u03b8)\n2\n\u03c32\ndt\n}\n.\nConsider the factorisation\nW\nX = WXy \u00d7 Leb(y1)\u00d7 f(y1|y0, \u03c3\n2), (5)\nwhere y1 is a Gaussian random variable, y1|y0 \u223c N (y0, \u03c32), and Leb(.) denotes Lebesgue measure. This\nnaturally factorises the measure of X as the Lebesgue density of y1 under the dominating measure, multiplied\nby the conditional dominating measure WXy . We can now write\ndPX(Xmis, y0, y1)\nd\n{\nWXy \u00d7 Leb(y)\n} = G(t,X, \u03b8, \u03c3)f(y1|y0, \u03c3),\nwhere clearly the dominating measure depends on \u03c3 since it contains WXy which represents a Brownian\nbridge with volatility \u03c3.\nTo remove this dependency on the parameter \u03c3 we consider the following time change transformation.\nLet a new time scale be\ns = \u03b71(t, \u03c3) =\n\u222b t\n0\n\u03c32d\u03c9 = t\u03c32, (6)\nand then define the new transformed diffusion U as\nUs =\n{\nX\u03b7\u221211 (s,\u03c3)\n, 0 \u2264 s \u2264 \u03c32,\nM\u03b7\u221211 (s,\u03c3)\n, s > \u03c32.\nThe definition for t > \u03c32 is needed to ensure that U is well defined for different values of \u03c32 > 0 which\nis essential in the context of a MCMC algorithm. Using standard time change properties, see for example\nOksendal (2000), the SDE for U is\ndUs =\n{\n1\n\u03c32\u00b5(s, Us, \u03b8)dt+ dW\nU\ns 0 \u2264 s \u2264 \u03c3\n2,\ndWUs , s > \u03c3\n2,\nwhere WU is another Brownian motion at the time scale s. Applying Girsanov\u2019s theorem again, the law\nof U , denoted by PU , is given through its Radon-Nikodym derivative with respect to the law WU of the\nBrownian motion WU at the time scale s:\ndPU (Umis, y0, y1)\ndWU\n= G(s, U, \u03b8, \u03c3) = exp\n{\u222b +\u221e\n0\n\u00b5(s, Us, \u03b8)\n\u03c32\ndUs \u2212\n1\n2\n\u222b +\u221e\n0\n\u00b5(s, Us, \u03b8)\n2\n\u03c34\nds\n}\n= exp\n{\u222b \u03c32\n0\n\u00b5(s, Us, \u03b8)\n\u03c32\ndUs \u2212\n1\n2\n\u222b \u03c32\n0\n\u00b5(s, Us, \u03b8)\n2\n\u03c34\nds\n}\n. (7)\n4\nBy applying the factorisation of (5) on WU at the new time scale s, the likelihood can be written as\ndPU (Umis, y0, y1)\nd\n{\nWUy \u00d7 Leb(y)\n} = G(s, U, \u03b8, \u03c3)f(y1|y0, \u03c3),\nThe dominating measure still depends on \u03c3 as it contains WUy which reflects a Brownian bridge with condi-\ntioning event U\u03c32 = y1. We therefore introduce a second transformation which applies to both the path and\nthe time scale of the diffusion process U . Consider a new time scale\nu = \u03b72(s, \u03c3) =\ns\n\u03c32(\u03c32 \u2212 s)\n, or s = \u03b7\u221212 (u, \u03c3) =\nu\u03c34\n1 + u\u03c32\n,\nand define a new diffusion Z through\nUs = (\u03c3\n2 \u2212 s)Z\u03b72(s,\u03c3) +\n(\n1\u2212\ns\n\u03c32\n)\ny0 +\ns\n\u03c32\ny1, 0 \u2264 t < \u03c3\n2. (8)\nNote that this transformation is a bijection. In the case of y0 = y1 = 0 its inverse is given by\nZu =\n1 + u\u03c32\n\u03c32\nU\u03b7\u221212 (u,\u03c3)\n, 0 \u2264 u < +\u221e.\nApplying Ito\u2019s formula and using time change properties we can also obtain the SDE of Z based on another\ndriving Brownian motion WZ operating at the time scale u:\ndZu =\n\u00b5\n(\nt, \u03c3\n2\n1+u\u03c32 \u03bd(Zu, \u03c3), \u03b8\n)\n+ \u03bd(Zu, \u03c3)\u03c3\n2\n1 + u\u03c32\ndt+ dWZu , 0 \u2264 u < +\u221e, (9)\nwhere \u03bd(Zu, \u03c3) = Us. This operation essentially transforms to a diffusion that runs from 0 to +\u221e preserving\nthe unit volatility. A third attempt to write the likelihood, now based on Z, again uses the Girsanov theorem\nand the factorisation of (5) to condition the dominating measure on y1. This writes\ndPZ(Z, y0, y1)\nd\n{\nWZy \u00d7 Leb(y)\n} = G(u, Z, \u03b8, \u03c3)f(y1|y0, \u03c3), (10)\nwhere PZ denotes the law of Z and WZy reflects the law of the driftless diffusion Z conditioned on y1.\nThe integrals in G(Z, \u03b8, \u03c3) run up to +\u221e), however the expression is finite being a bijection of the Radon-\nNikodym derivative between PU and WU given by (7). Using the following lemma, we can prove that WZy is\nthe law of the standard Brownian motion and hence the likelihood is written with respect to a dominating\nmeasure that does not depend on any parameters.\nLemma 1: Let W be a standard Brownian motion in [0, +\u221e). Consider the process defined for 0 \u2264 t \u2264 T\nBt = (T \u2212 t)Wt\/{T (T\u2212t)} + (1\u2212\nt\nT\n)y0 +\nt\nT\ny1, 0 \u2264 t < T\nThen B is a Brownian bridge from y0 at time 0 to y1 at time T .\nProof. See (Rogers and Williams, 1994, IV.40.1) for the case y0 = 0, T = 1. The extension for general y0\nand T is trivial.\nCorollary 1: The process Z is standard Brownian motion under the dominating measure. In other words\nW\nZ\ny is standard Wiener measure.\nProof. Note that WUy reflects a Brownian bridge from y0 at time 0 to y1 at time T and we obtained W\nZ\ny\nby using the transformation of Lemma 1. Since this transformation is a bijection, U is a Brownian bridge\n(under the dominating measure) if and only if Z is standard Brownian motion.\n5\nThe likelihood, given by (10), allows the construction of an irreducible MCMC scheme that alternates\nbetween updating the parameters and the diffusion process Z. For the path updates we may use the fact\nthat\ndPZy\ndWZy\n(Z|y0, y1) = G(t, Z, \u03b8, \u03c3)\nf(y1|y0, \u03c3)\nfP (y1|y0, \u03b8, \u03c3)\n\u221d G(t, Z, \u03b8, \u03c3), (11)\nwhere PZy is the law of Z conditioned on y1 and f\nP (.) is the density of y1 under P\nZ . Both PZy and f\nP (.) are\ngenerally unknown but their calculation may be avoided in a MCMC algorithm which essentially only uses\n(10) and (11). Since these expressions only require the evaluation of f(.) and G(.), which are either known or\nmay be approximated using the augmented diffusion path, the task of Bayesian inference is feasible. Details\nare presented in Section 4.\n3.2 Stochastic volatility models\nWe will first demonstrate how the case of stochastic volatility models may be brought to a similar and\nequivalent form to that of the previous section. Consider the general class of stochastic volatility models\nwith SDE given by (3) for 0 \u2264 t \u2264 t1. Without loss of generality, we may assume a pair of observations\n(X0 = y0, X1 = y1) due to the Markov property of the 2-dimensional diffusion (X,\u03b1). The likelihood can\nthen be divided into two parts: The first contains the marginal likelihood of the diffusion \u03b1 and the remaining\npart corresponds to the diffusion X conditioned on the path of \u03b1\nP\u03b8(X,\u03b1) = P\u03b8(\u03b1)P\u03b8(X |\u03b1).\nDenote the marginal likelihood for \u03b1 by L\u03b1(\u03b1, \u03b8). To overcome reducibility issues arising from the paths\nof \u03b1 one may use the reparametrisations of Chib et al. (2007) or Kalogeropoulos (2007). The relevant\ntransformations of the latter are\n\u03b2t = h1(\u03b1t, \u03b8),\n\u2202h1(\u03b1t, \u03b8)\n\u2202\u03b1t\n= {\u03c3\u03b1(\u03b1t, \u03b8)}\n\u22121 ,\n\u03b3t = \u03b2t \u2212 \u03b20, \u03b2t = h2(\u03b3t),\nand the marginal likelihood for the transformed latent diffusion \u03b3 becomes\nL\u03b3(\u03b3, \u03b8) =\ndP\ndW\n(\u03b3) = G\u03b3 (t, \u03b3, \u03b8) . (12)\nwhere W denotes Wiener measure. By letting \u03b1t = g\n\u03b8,\u03b3\nt = h\n\u22121\n1 (h2(\u03b3t), \u03b8), the SDE of X conditional on \u03b3\nbecomes:\ndXt = \u00b5x(Xt, g\n\u03b8,\u03b3\nt , \u03b8)dt+ \u03c3x(g\n\u03b8,\u03b3\nt , \u03b8)dBt, 0 \u2264 t \u2264 1.\nGiven the paths of the diffusion \u03b3t, the volatility function \u03c3x(g\n\u03b8,\u03b3\nt , \u03b8) may be viewed as a deterministic\nfunction of time and \u03b8. The situation is similar to that of the previous section. We can now introduce a new\ntime scale\ns = \u03b7(t, \u03b3, \u03b8) =\n\u222b t\n0\n\u03c32x(g\n\u03b8,\u03b3\n\u03c9 , \u03b8)d\u03c9.\nLet T be the transformation of the ending time t1, T = \u03b7(t1, \u03b3, \u03b8). We can then define U on the new time\nscale s as in (6):\nUs =\n{\nX\u03b7\u22121(s,\u03b3,\u03b8), 0 \u2264 s \u2264 T,\nM\u03b7\u22121(s,\u03b3,\u03b8), s > T.\n(13)\nThe SDE for U now becomes\n6\ndUs =\n\uf8f1\uf8f2\n\uf8f3\n\u00b5x\n(\nUs, g\n\u03b8,\u03b3\n\u03b7\u22121(s,\u03b3,\u03b8), \u03b8\n)\n\u03c32x(g\n\u03b8,\u03b3\n\u03b7\u22121(s,\u03b3,\u03b8), \u03b8)\n\uf8fc\uf8fd\n\uf8fe dt+ dWUs , 0 \u2264 s \u2264 T.\nWe obtain the Radon Nikodym derivative between the distribution of U with respect to that of the Brownian\nmotion WU ,\ndP\ndWU\n= G(s, U, \u03b3, \u03b8),\nand introduce WUy as before. The density of y1 under W\nU , denoted by f(y1|y0, \u03b3, \u03b8), is just\nf(y1|y0, \u03b3, \u03b8) \u2261 N(y0, T ).\nThe dominating measure WUy reflects a Brownian motion conditioned to equal y at a parameter depended\ntime T = \u03b7(t1, \u03b3, \u03b8). To remove this dependency we introduce another time scale\nu = \u03b72(s) =\ns\nT (T \u2212 s)\n, or s = \u03b7\u221212 (u) =\nuT 2\n1 + uT\n,\nwhich defines a second time change similar to (8)\nUt = (T \u2212 s)Zs\/{T (T\u2212s)} + (1\u2212\ns\nT\n)y0 +\ns\nT\ny1, 0 \u2264 s < T. (14)\nTherefore, the SDE for Z is now given by\ndZu =\nT\n1 + uT\n\uf8f1\uf8f2\n\uf8f3\n\u00b5\n(\nT\n1+uT \u03bd(Zu), \u03b3k(u,\u03b3,\u03b8), \u03b8\n)\n\u03c32x(\u03b3k(u,\u03b3,\u03b8), \u03b8)\n+ \u03bd(Zu)\n\uf8fc\uf8fd\n\uf8fe dt+ dWZu , 0 \u2264 u <\u221e,\nwhere k(u, \u03b3, \u03b8) denotes the initial time scale of X , t, and \u03bd(Zu) = Us.\nConditional on \u03b3, the likelihood can be written in a similar manner as in (10):\ndP\nd\n{\nWZy \u00d7 Leb(y)\n}(Z|y0, y1, \u03b3) = G(u, Z, \u03b3, \u03b8)f(y1|y0, \u03b3, \u03b8) (15)\nBy using the exact same arguments of Section 3.1, we can show that WZy reflects a standard Wiener measure\nand therefore the dominating measure is independent of parameters. To obtain the full likelihood we need\nto multiply the two parts given by (12) and (15).\n3.3 Incorporating leverage effect\nIn the previous section we made the assumption that the increments of X and \u03b3 are independent, in other\nwords we assumed no leverage effect. This assumption can be relaxed in the following way: In the presence\nof a leverage effect \u03c1, the SDE of X conditional on \u03b3 can be written as\ndXt = \u00b5x(Xt, g\n\u03b3,\u03b8\nt , \u03b8)dt+ \u03c1\u03c3x(g\n\u03b3,\u03b8\nt , \u03b8)dWt +\n\u221a\n1\u2212 \u03c12\u03c3x(g\n\u03b3,\u03b8\nt , \u03b8)dBt, 0 \u2264 t \u2264 t1,\nwhere W is the driving Brownian motion of \u03b3). Note that given \u03b3, W can be regarded as a function of \u03b3\nand its parameters \u03b8. Therefore, the term \u03c1\u03c3x(g\n\u03b3,\u03b8\nt , \u03b8)dWt can be viewed as a deterministic function of time,\nand it can be treated as part of the drift of Xt. However, this operation introduces additional problems as\nthe assumptions ensuring a weakly unique solution to the SDE of X are violated. To avoid this issue we\nintroduce the infinitesimal transformation\nXt = H(Ht, \u03c1, \u03b3, \u03b8) = Ht +\n\u222b t\n0\n\u03c1\u03c3x(g\n\u03b3,\u03b8\n\u03c9 , \u03b8)dW\u03c9 ,\n7\nwhich leads us to the following SDE for H :\ndHt = \u00b5x\n{\nH(Xt, \u03c1, \u03b3, \u03b8), g\n\u03b3,\u03b8\nt , \u03b8\n}\ndt+\n\u221a\n1\u2212 \u03c12\u03c3x(g\n\u03b3,\u03b8\nt , \u03b8)dBt, 0 \u2264 t \u2264 t1.\nWe can now proceed as before, defining U and Z based on the SDE of H in a similar manner as in (13) and\n(14) respectively.\n3.4 State dependent volatility\nConsider the family of state dependent stochastic volatility models where conditional on \u03b3, the SDE of X\nmay be written as:\ndXt = \u00b5x(Xt, g\n\u03b3,\u03b8\nt , \u03b8)dt+ \u03c31(g\n\u03b3,\u03b8\nt , \u03b8)\u03c32(Xt, \u03b8)dBt, 0 \u2264 t \u2264 t1.\nThis class contains among others, the models of Andersen and Lund (1998), Gallant and Tauchen (1998),\nDurham (2002), Eraker (2001). In order to apply the time change transformations of section 3.2, we should\nfirst transform X to X\u02d9t, through X\u02d9t = l(Xt, \u03b8), so that it takes the form of (3). Such a transformation,\nwhich may be viewed as the first transformation in Roberts and Stramer (2001), should satisfy the following\ndifferential equation\n\u2202l(Xt, \u03b8)\n\u2202Xt\n=\n1\n\u03c32(Xt, \u03b8)\n.\nThe time change transformations for U and Z may then be defined on the basis of X\u02d9 that will now have\nvolatility \u03c31(g\n\u03b3,\u03b8\nt , \u03b8). The transformation l(.) also applies to the observations y\u02d90 = l(X0, \u03b8) and y\u02d91 = l(X1, \u03b8)\nwhich may now be functions of the parameters in \u03c32(.). These parameters enter the reparametrised likelihood\nin two ways: through the density f(y1|\u03b3, \u03b8) which now should include the relevant Jacobian term, and through\nthe function \u03bd(Zu) in the drift of Z which according to (14) would depend on the transformed endpoints.\n3.5 Multivariate stochastic volatility models\nWe may use the techniques of section 3.3 to define time change transformations for multidimensional diffu-\nsions. Consider a d\u2212dimensional version of the SDE in (4) where \u03c3 now is a 2\u00d7 2 matrix ([\u03c3]ij = \u03c3ij). As\nnoted in Kalogeropoulos et al. (2007), the mapping between \u03c3 and the volatility matrix \u03c3\u03c3T should be 1-1\nin order to ensure identifiability of the \u03c3 parameters. A way to achieve this, is by allowing \u03c3 to be the lower\ntriangular matrix that produces the Cholesky decomposition of \u03c3\u03c3T . For d = 2, the SDE of such a diffusion\nis given by\ndX\n{1}\nt = \u00b5(X\n{1}\nt , X\n{2}\nt , \u03b8)dt+ \u03c311dBt,\ndX\n{2}\nt = \u00b5(X\n{1}\nt , X\n{2}\nt , \u03b8)dt+ \u03c321dBt + \u03c322dWt.\nThe time change transformations for X{1} will be exactly as in section 3.1. For X{2} note that given\nX{1} the term \u03c321dBt is now a deterministic function of time and may be treated as part of the drift. Thus,\nwe may proceed following the route of the section 3.3.\nSimilar transformations can be applied for diffusions that have, or may be transformed to have, volatility\nfunctions independent of their paths. For example we may assume two correlated price processes with\ncorrelation \u03c1x:\n[\u03c3]11 = \u03c3\n{1}\nx (g\n\u03b3,\u03b8\nt , \u03b8),\n[\u03c3]21 = \u03c1x\u03c3\n{2}\nx (g\n\u03b3,\u03b8\nt , \u03b8),\n[\u03c3]22 =\n\u221a\n1\u2212 \u03c12x\u03c3\n{2}\nx (g\n\u03b3,\u03b8\nt , \u03b8).\nWe may proceed in a similar manner for multivariate stochastic volatility models of general dimension d.\n8\n4 MCMC implementation\nThe construction of an appropriate data augmentation algorithm involves several issues. We focus on describ-\ning how to update the latent diffusion paths and the parameters that drive the time change transformations.\nThe updates of the remaining parameters include standard MCMC steps and are thus omitted. The change\nin the time scale introduces three interesting features: the presence of three time scales; the need to update\ndiffusion paths that run from 0 to +\u221e; and the fact that time scales depend on parameters. In this section\nwe present the details of a MCMC scheme that addresses the above. For ease of illustration, we start with\nthe simple case of a univariate diffusion with constant volatility\ndXt = \u00b5(t,Xt, \u03b8)dt+ \u03c3dB\nX\nt , 0 \u2264 t \u2264 1, X0 = y0, X1 = y1\nand build up to the case of stochastic volatility models (3). Note that such extensions are not hard to\nimplement since the time change transformations need only be applied to the paths of the observed diffusion\nprocess X . The updates of the transformed diffusion process \u03b3, which drives the volatility, may be carried\nout using an overlapping scheme as in Kalogeropoulos (2007).\n4.1 Three time scales\nWe introduce m intermediate points of X at equidistant times between 0 and 1, to give X = {Xi\/(m+1), i =\n0, 1, . . . ,m + 1}. In addition, we make the assumption that m is large enough for accurate likelihood\napproximations and any error induced by the time discretisation is negligible for the purposes of our analysis.\nThis assumption introduces no implications as the value of m may be set to an arbitrarily large value prior\nto the analysis.\nGiven a value of the time scale parameter \u03c3, we can get the U\u2212time points by applying (6) to each one\nof the existing points X , so that\nU\u03c32i\/(m+1) = Xi\/(m+1), i = 0, 1, . . . ,m+ 1.\nNote that it is only the times that change, the values of the diffusion remain intact. In a stochastic volatility\nmodel we would use the quantities \u222b i+1\nm+1\ni\nm+1\n\u03c32x(.)ds\nfor each pair of consecutive imputed points.\nThe points of Z are multiplied by a time factor which corrects the deviations from unit volatility. The\ntimes of the diffusion Z may be obtained by\ntZi =\n\u03c32i\/(m+ 1)\n\u03c32(\u03c32 \u2212 \u03c32i\/(m+ 1))\n, i = 0, 1, . . . ,m.\nClearly this does not apply to the last point which occurs at time +\u221e. The paths of X, or U, are thus\nmore convenient for likelihood evaluations as they only contain finite time points. They may be used instead\nexploiting the fact that the relevant transformations are bijections. However, the component of the relevant\nGibbs sampling scheme should be the diffusion process Z.\n4.2 Updating the paths of Z\nThe paths of Z may be updated using an independence sampler with the reference measure as a proposal.\nHere WZy reflects a Brownian motion at the Z\u2212time scale u, which is fixed given the current values of\nthe time-scale parameters and the paths of \u03b3 in the case of stochastic volatility models. An appropriate\nalgorithm is given by the following steps.\n\u2022 Step 1: Propose a Brownian motion on the Z\u2212time, say Z\u2217. The value at the endpoint\n(time +\u221e) is not needed.\n9\n\u2022 Step 2: Transform back to X\u2217, using (8).\n\u2022 Step 3: Accept with probability: min\n{\n1, G(X\n\u2217,\u03b8,\u03c3)\nG(X,\u03b8,\u03c3)\n}\n.\n4.3 Updating time scale parameters\nThe updates of parameters that define the time scale, such as \u03c3, are of particular interest. In almost all\ncases, their conditional posterior density is not available in closed form, and Metropolis steps are inevitable.\nHowever, every proposed value of these parameters will imply a different Z\u2212 time scale u. In other words,\nfor each potential proposed value for \u03c3 there exists a different set of Z\u2212 points needed for accurate approxi-\nmations of the likelihood the Metropolis accept-reject probabilities. In theory, this would pose no issues had\nwe been able to store an infinitely thin partition of Z, but of course this is not possible.\nWe use retrospective sampling ideas; see Papaspiliopoulos and Roberts (2008) and Beskos and Roberts\n(2005) for applications in different contexts. Under the assumption of a sufficiently fine partition of the\ntime scale of Z, all the non-recorded intermediate points contribute nothing to the likelihood and they are\nirrelevant in that respect. The set of recorded points is sufficient for likelihood approximation purposes. In\nother words, their distribution is given by the likelihood dominating measure WZy which reflects a Brownian\nmotion. Hence, they can be drawn after the proposal of the candidate value of the time scale parameter. To\nensure compatibility with the recorded partition of Z, it suffices to condition on their neighboring points.\nThis is easily done using standard Brownian bridge properties: Suppose that we want to simulate the value\nof Z at time tb which falls between the recorded values at times ta and tc, so that ta \u2264 tb \u2264 tc. Denote\nby Zta and Ztc the corresponding Z values. Under the assumption that Z is distributed according to W\nZ\ny\nbetween ta and tc we have that\nZtb | Zta , Ztc \u223c N\n{\n(tb \u2212 ta)Ztc + (tc \u2212 tb)Zta\ntc \u2212 ta\n,\n(tb \u2212 ta)(tc \u2212 tb)\ntc \u2212 ta\n}\n. (16)\nWe describe the algorithm for the case of more than two observations; denote by X0 = y0, Xt1 = y1,\n. . .Xtn = yn. The time change transformations should be applied to each pair of successive observations,\nthus giving n separate Z diffusion processes. As mentioned earlier, the diffusion processes X , or U are\nbijections of this collection of Z diffusion processes and may be used instead in a MCMC scheme. Our\nproposed algorithm for the \u03c3\u2212updates may be summarized through the following steps:\n\u2022 Step 1: Propose a candidate value for \u03c3, say \u03c3\u2217.\n\u2022 Step 2: Repeat for each pair of successive points:\n\u2013 Use (6) and (8) to get the new times associated with it.\n\u2013 Draw the values of Z retrospectively at the new times using (16).\n\u2013 Transform back to X\u2217 (which corresponds to the time between the pair\nof successive points), using (8).\n\u2022 Step 3: Form the entire path X\u2217 by appropriately joining the bits between\nsuccessive observations.\n\u2022 Step 4: Accept with probability: min\n{\n1,\nG(t,X\u2217,\u03b8,\u03c3\u2217)\n\u220fn\ni=1 f(yi|yi\u22121,\u03c3\n\u2217)\nG(t,X,\u03b8,\u03c3)\n\u220f\nn\ni=1 f(yi|yi\u22121,\u03c3\n)\n}\n.\nIn a stochastic volatility model the updates of the paths of the transformed diffusion \u03b3 may be imple-\nmented using overlapping blocks. Note that these paths drive the time u, of the diffusion process Z, and\ntherefore a similar algorithm as above should be embedded in their updates. For simplicity consider blocks\nof \u03b3 paths that correspond to times between non-successive observations. Each block is then further split\ninto sub-blocks containing intervals between successive observations, thus providing a number of separate Z\ndiffusion processes. Details are presented below:\n10\n\u2022 Step 1: Propose \u03b3\u2217 between the times of of two non-successive observations,\nyA and yB, by a Brownian bridge connecting the relevant endpoints of \u03b3.\n\u2022 Step 2: Repeat for each pair of successive points between (and\nincluding) yA and yB:\n\u2013 Use (13) and (14) to get the new times associated with it.\n\u2013 Draw the values of Z retrospectively at the new times using (16).\n\u2013 Transform back to X\u2217 (which corresponds to the time between the pair\nof successive points), using (14).\n\u2022 Step 3: Join the bits of X\u2217 to form its path between yA and yB.\n\u2022 Step 4: Accept with probability: min\n{\n1,\nG\u03b3(t,\u03b3\n\u2217,\u03b8)G(t,X\u2217,\u03b3\u2217,\u03b8)\n\u220f\nn\ni=1 f(yi|yi\u22121,\u03b3\n\u2217,\u03b8)\nG\u03b3(t,\u03b3,\u03b8)G(t,X,\u03b3,\u03b8)\n\u220f\nn\ni=1 f(yi|yi\u22121,\u03b3,\u03b8)\n}\n.\n5 Simulations\nAs discussed in section 2, appropriate reparametrisations are necessary to avoid issues regarding the mixing\nand convergence of the MCMC algorithm. In fact, the chain becomes reducible as the level of augmentation\nincreases. This is also verified by the numerical examples performed in Kalogeropoulos (2007) even in very\nsimple stochastic volatility models. In this section we present a simulation based experiment to check the\nimmunity of MCMC schemes to increasing levels of augmentation, as well as the ability of our estimation\nprocedure to retrieve the correct values of the diffusion parameters despite the fact that the series is partially\nobserved and only at a finite number of points. We simulated data from the following stochastic volatility\nmodel\ndXt = \u03bax(\u00b5x \u2212Xt)dt+ \u03c1 exp(\u03b1t\/2)dWt +\n\u221a\n1\u2212 \u03c12 exp(\u03b1t\/2)dBt,\nd\u03b1t = \u03ba\u03b1(\u00b5\u03b1 \u2212 \u03b1t)dt+ \u03c3dWt,\nwhere B and W represent independent Brownian motions, and \u03c1 reflects the correlation between the incre-\nments of X and \u03b1 (also termed as leverage effect). A high frequency Euler approximating scheme with a\nstep of 0.001 was used for the simulation of the diffusion paths. Specifically, 500, 001 points were drawn and\none value of X for every 1000 was recorded, thus forming a dataset of 501 observations of X at 0 \u2264 t \u2264 500.\nThe parameter values were set to \u03c1 = \u22120.5, \u03c3 = 0.4, \u03bax = 0.2, \u00b5x = 0.1, \u03ba\u03b1 = 0.3 and \u00b5\u03b1 = \u22120.2\nThe transformations required to construct an irreducible data augmentation scheme are listed below.\nFirst \u03b1 was transformed to \u03b3 through\n\u03b3t =\n\u03b1t \u2212 \u03b10\n\u03c3\n, 0 \u2264 t \u2264 500,\n\u03b1t = g\n\u03b3,\u03c3\nt = \u03b10 + \u03c3\u03b3t.\nGiven \u03b3, and for each pair of consecutive observation times tk\u22121 and tk (k = 1, 2, . . . , 500) on X, the following\ntransformations were applied: First, we removed the term introduced from the leverage effect\nHt = Xt \u2212\n\u222b t\ntk\u22121\n\u03c1 exp {g\u03b3,\u03c3t \/2}dWs, tk\u22121 \u2264 t \u2264 tk,\nand consequently we set\n\u03b71(t) =\n\u222b t\ntk\u22121\n(1\u2212 \u03c1)2 exp {\u03bd(\u03b3s, \u03c3, \u03b10} ds.\n11\nParameter True value Post. mean Post. SD Post 2.5% Post median Post 97.5%\n\u03bax 0.2 0.244 0.038 0.173 0.243 0.321\n\u00b5x 0.1 0.313 0.174 -0.046 0.317 0.641\n\u03ba\u03b1 0.3 0.304 0.148 0.110 0.277 0.672\n\u00b5\u03b1 -0.2 -0.268 0.107 -0.484 -0.267 -0.059\n\u03c3 0.4 0.406 0.130 0.202 0.390 0.705\n\u03c1 -0.5 0.477 0.138 -0.657 -0.491 -0.066\nTable 1: Summaries of the posterior draws for the simulation example of Section 5 for m = 50.\nThen, U and Z may be defined again from 13 and 14 respectively, but based on H rather on X . The elements\nof the MCMC scheme are Z, \u03b3, \u03b10 and the parameters (\u03bax, \u00b5x, \u03ba\u03b1, \u00b5\u03b1, \u03c1, \u03c3).\nVague priors were assigned to all of the parameters, subject to positivity constraints for \u03bax, \u03ba\u03b1, \u03c3 and for\n\u03c1 to be in (\u22121, 1). The chain was run several times for 50,000 iterations on different levels of augmentation,\nby setting the number of imputed points to 2, 30, 40 and 50. As in Kalogeropoulos (2007), it was noted that\na good choice of length of the overlapping blocks, needed for the updates of \u03b3, may improve substantially the\nmixing of the chain. We used blocks with length corresponding to 8 observations. The acceptance rate rate\nfor each block of \u03b3 was around 75% whereas the acceptance rate for each path of Z was around 95%. The time\nneeded for such a MCMC run with m = 40 was roughly 4 hours in a mid-specification PC. We also noted a\nlinear relationship between running times and m, which confirms the fact that the computational complexity\nof the algorithm is O(m) (see discussion for more). Figure 1 shows autocorrelation plots for all parameters.\nThere is no sign of any increase in the autocorrelation to raise suspicions against the irreducibility of the\nchain. This confirms the fact that convergence time of the algorithm is independent of m. Figure 2 shows\ndensity plots for all parameters and on all of m. These plots may be used to monitor the deterioration of the\ndiscretisation error. In this example, a choice of m = 2 may have been suboptimal whereas any value above\n30 seems to perform well. Also, these plots reveal good agreement with the true values of the parameters,\nwhich is also supported by Table 1.\n6 Application: US treasury bill rates\nTo illustrate the time change methodology we fit a stochastic volatility model to US treasury bill rates. The\ndataset consists of 1809 weekly observations (Wednesday) of the 3\u2212month US Treasury bill rate from the\n5th of January 1962 up to the 30th of August 1996. The data are plotted in Figure 3.\nPrevious analyses of these data include Andersen and Lund (1998), Gallant and Tauchen (1998), Durham\n(2002), Durham and Gallant (2002), Eraker (2001), and Golightly and Wilkinson (2006). Apart from some\nslight deviations the adopted stochastic volatility models consisted of the following SDE.\ndrt = (\u03b80 \u2212 \u03b81rt)dt+ r\n\u03c8\nt exp(\u03b1t\/2)dBt,\nd\u03b1t = \u03ba(\u00b5\u2212 \u03b1t)dt+ \u03c3dWt, (17)\nwith independent Brownian motions B and W . In some cases the following equivalent model was used:\ndrt = (\u03b80 \u2212 \u03b81rt)dt+ \u03c3rr\n\u03c8\nt exp(\u03b1t\/2)dBt,\nd\u03b1t = \u2212\u03ba\u03b1tdt+ \u03c3dWt. (18)\nThe model in (17) was chosen, as posterior draws of its parameters exhibit substantially less autocorrelation.\nIn line with Gallant and Tauchen (1998) and Golightly and Wilkinson (2006), we also set \u03c8 = 1. Eraker\n(2001), Durham (2002) and Durham and Gallant (2002) assume general \u2018elasticity of variance\u2019 \u03c8 but their\nestimates do not indicate a significant deviation from 1. By setting Xt = log(rt), the volatility of Xt becomes\nexp(\u03b1t\/2). Therefore the U\u2212time for two consecutive observation times tk\u22121 and tk is defined as\n12\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLag \u2212 kappax\nAC\nF\nm=2\nm=30\nm=40\nm=50\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLag \u2212 mux\nAC\nF\nm=2\nm=30\nm=40\nm=50\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLag \u2212 kappav\nAC\nF\nm=2\nm=30\nm=40\nm=50\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nLag \u2212 muv\nAC\nF\nm=2\nm=30\nm=40\nm=50\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nAC\nF\nm=2\nm=30\nm=40\nm=50\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nAC\nF\nm=2\nm=30\nm=40\nm=50\nLag - \u03c3 Lag - \u03c1\nFigure 1: Autocorrelation plots of the parameter posterior draws for different numbers of imputed points\nm = 2, 30, 40, 50. Simulation example of Section 5.\n13\n0.10 0.15 0.20 0.25 0.30 0.35\n0\n2\n4\n6\n8\n10\n12\nm=2\nm=30\nm=40\nm=50\n\u22120.4 \u22120.2 0.0 0.2 0.4 0.6 0.8 1.0\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\nm=2\nm=30\nm=40\nm=50\n0.0 0.2 0.4 0.6 0.8 1.0 1.2\n0\n1\n2\n3\n4\nkappav\nm=2\nm=30\nm=40\nm=50\n\u22120.8 \u22120.6 \u22120.4 \u22120.2 0.0 0.2\n0\n1\n2\n3\n4\nmuv\nm=2\nm=30\nm=40\nm=50\n0.0 0.2 0.4 0.6 0.8 1.0\n0\n1\n2\n3\nm=2\nm=30\nm=40\nm=50\n\u22121.0 \u22120.8 \u22120.6 \u22120.4 \u22120.2 0.0 0.2\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\nm=2\nm=30\nm=40\nm=50\n\u03bax \u00b5x\n\u03c3 \u03c1\nFigure 2: Kernel densities of the posterior draws of all the parameters for different numbers of imputed\npoints m = 2, 30, 40, 50. Simulation example of Section 5.\n14\n0 500 1000 1500\n0\n5\n10\n15\nTime in weeks from 5th January 1962\npe\nrce\nnt\nFigure 3: Weekly 3\u2212month US Treasury bill rate from the 5th of January 1962 up to the 30th of August\n1996.\n15\nParameter Post. mean Post. SD Post 2.5% Post median Post 97.5%\n\u03b80 0.130 0.238 -0.347 0.132 0.589\n\u03b81 0.013 0.057 -0.096 0.013 0.125\n\u03ba 2.403 0.620 1.319 2.360 3.745\n\u00b5 -3.966 0.211 -4.384 -3.964 -3.547\n\u03c3 2.764 0.311 2.199 2.750 3.420\nTable 2: Summaries of the posterior draws for the stochastic volatility model of Weekly 3\u2212month US\nTreasury bill rates.\n\u03b71(t) =\n\u222b t\ntk\u22121\nexp(\u03b1t)ds,\nand U and Z are given by (13) and (14) respectively. We also transformed \u03b1 to \u03b3 as in section 5:\n\u03b3t =\n\u03b1t \u2212 \u03b10\n\u03c3\n,\n\u03b1t = g\n\u03b3,\u03c3\nt = \u03b10 + \u03c3\u03b3t.\nWe constructed appropriate MCMC schemes based on Z and \u03b3 to sample from the posterior of the\nparameters \u03b80, \u03b81, \u03ba, \u00b5 and \u03c3. The time was measured in years setting the distance between successive\nWednesdays to 5\/252. Non-informative priors were assigned to all the parameters, restricting \u03ba and \u03c3 to be\npositive to ensure identifiability and eliminate the possibility of explosion. The algorithm was run for 50, 000\niterations and for m equal to 2, 10 and 20. To optimize the efficiency of the chain we set the length of the\noverlapping blocks of \u03b3 to 10 which produced an acceptance rate of 51.9%. The corresponding acceptance\nrate for Z was 98.6% .\nThe kernel density plots of the posterior parameters and likelihood (Figure 4) indicate that a discreti-\nsation corresponding to an m of 10 or 20 provide reasonable approximations. A choice of m = 2 produces\nsimilar parameter posterior draws but the log-likelihood plot (bottom right) seems to be slightly off. The\nrelevant autocorrelation plots of Figure 5 do not provide evidence of increasing autocorrelation inm. Finally,\nsummaries of the posterior draws for all the parameters are provided in Table 2. The parameters \u03ba, \u00b5 and \u03c3\nare different from 0 verifying the existence of stochastic volatility. On the other hand, there is no evidence\nto support the existence of mean reversion on the interest rate process, as \u03b80 and \u03b81 are not far from 0. The\nresults are in line with those of Durham (2002), Durham and Gallant (2002) and Golightly and Wilkinson\n(2006).\n7 Discussion\nData augmentation MCMC schemes constitute a very useful tool for likelihood-based inference on diffusion\nmodels. They may not have the appealing properties of complete elimination of the time discretisation\nerror (Beskos et al., 2006), or the closed form approximate likelihood expressions of A\u0131\u00a8t-Sahalia (2002), but\nnevertheless they give a satisfactory and very general solution to the problem. However, data augmentation\nschemes require careful construction to avoid the degeneracy issues described at the beginning of this paper.\nHere, we introduce an innovative transformation which operates by altering the time axis of the diffu-\nsion. To accommodate the special features of time change transformations we also introduce a novel efficient\nMCMC scheme which mixes rapidly and is not prohibitively computationally expensive. Our method is also\neasy to implement and introduces no additional approximation error other than that included in method-\nologies based on a discretisation of the diffusion path. Moreover it has a broad range of applications which\ninclude general stochastic volatility models.\nOne clear advantage of the time change methodology is that in its pure form produces algorithms whose\nmixing time is bounded as m goes to infinity, as in Roberts and Stramer (2001). In addition, the computing\n16\n\u22120.5 0.0 0.5 1.0\n0.0\n0.5\n1.0\n1.5\nm=2\nm=10\nm=20\n\u22120.2 \u22120.1 0.0 0.1 0.2\n0\n2\n4\n6\nm=2\nm=10\nm=20\n0 1 2 3 4 5 6\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nm=2\nm=10\nm=20\n\u22125.0 \u22124.5 \u22124.0 \u22123.5 \u22123.0 \u22122.5\n0.0\n0.5\n1.0\n1.5\n2.0\nm=2\nm=10\nm=20\n2.0 2.5 3.0 3.5 4.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4\nm=2\nm=10\nm=20\n6150 6200 6250 6300\n0.0\n00\n0.0\n05\n0.0\n10\n0.0\n15\n0.0\n20\nlog\u2212likelihood\nm=2\nm=10\nm=20\n\u03ba \u00b5\n\u03b80 \u03b81\n\u03c3\nFigure 4: Kernel densities of the posterior draws of all the parameters and the log-likelihood for different\nvalues of imputed points m = 2, 10, 20. Example on Weekly 3\u2212month US Treasury bill rates.\n17\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nAC\nF\nm=2\nm=10\nm=20\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nAC\nF\nm=2\nm=10\nm=20\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nAC\nF\nm=2\nm=10\nm=20\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nAC\nF\nm=2\nm=10\nm=20\n0 100 200 300 400 500\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nAC\nF\nm=2\nm=10\nm=20\nLag - \u03c3\nLag - \u03ba Lag - \u00b5\nLag - \u03b80 Lag - \u03b81\nFigure 5: Autocorrelation plots for the posterior draws of the model parameters for different numbers of\nimputed points m = 2, 10, 20 for the analysis of Weekly 3\u2212month US Treasury bill rates.\n18\ncost per iteration of our methods is O(m) as with other competing methods. Thus the overall computing\ncost of our approach is O(m) which compares favourably with competing methods that are typically O(m2).\nIn our experience mixing properties of the methods introduced in this paper are good in comparison with\ncompeting methods for these types of models and data. Furthermore we have found out that implementation\ncan routinely be carried out in a few hours on a mid-specification PC.\nFurther work will consider problems with state-dependent volatility and models which involve jump\ndiffusions, to which the methodology introduced here can be easily applied. Fundamental to our approach\nhere has been the introduction of a non-centered parametrisation to decouple dependence inherent in the\nmodel between missing data and volatility parameters. However non-centered constructions are not unique,\nas illustrated by the choice in the diffusion context between the state rescaling approaches of Golightly\nand Wilkinson (2007); Roberts and Stramer (2001) and the time-stretching strategy adopted here. Clearly,\nfurther work is required to investigate the relative merits of these approaches in different situations.\n8 Acknowledgements\nThis work was supported by the EPSRC grant GR\/S61577\/01 and by the Marie Curie fellowships. The\nauthors would also like to thank Omiros Papaspiliopoulos for helpful discussions.\nReferences\nA\u0131\u00a8t-Sahalia, Y. (2002). Maximum likelihood estimation of discretely sampled diffusions: a closed form\napproximation approach. Econometrica, 70:223\u2013262.\nA\u0131\u00a8t-Sahalia, Y. (2008). Closed form likelihood expansions for multivariate diffusions. Annals of Statistics,\n36:906\u2013937.\nAndersen, T. G. and Lund, J. (1998). Estimating continuous-time stochastic volatility models of the short\nterm interest rate. Journal of Econometrics, 77:343\u2013377.\nBeskos, A., Papaspiliopoulos, O., Roberts, G., and Fearnhead, P. (2006). Exact and computationally efficient\nlikelihood-based estimation for discretely observed diffusion processes (with discussion). Journal of the\nRoyal Statistical Society: Series B (Statistical Methodology), 68(3):333\u2013382.\nBeskos, A. and Roberts, G. O. (2005). Exact simulation of diffusions. Ann. Appl. Probab., 15(4):2422\u20132444.\nBibby, B. and Sorensen, M. (1995). Martingale estimating functions for discretely observed diffusion pro-\ncesses. Bernoulli, 1:17\u201339.\nChib, S., Pitt, M. K., and Shephard, N. (2007). Efficient likelihood based inference for observed and partially\nobserved diffusions. Submitted.\nDurham, G. B. (2002). Likelihod based specification analysis of continuous time models of the short term\ninterest rate. Journal of Financial Economics. Forthcoming.\nDurham, G. B. and Gallant, A. R. (2002). Numerical techniques for maximum likelihood estimation of\ncontinuous-time diffusion processes. J. Bus. Econom. Statist., 20(3):297\u2013316. With comments and a reply\nby the authors.\nElerian, O. S., Chib, S., and Shephard, N. (2001). Likelihood inference for discretely observed non-linear\ndiffusions. Econometrica, 69:959\u2013993.\nEraker, B. (2001). Markov chain Monte Carlo analysis of diffusion models with application to finance. J.\nBus. Econom. Statist., 19(2):177\u2013191.\n19\nFearnhead, P. and Papaspiliopoulos, O. and Roberts, G.O. (2008). Particle filters for partially observed\ndiffusions. Journal of Royal Statistical Society: Series B (Statistical Methodology)., 70(4):755\u2013777.\nGallant, A. R. and Long, J. R. (1997). Estimating stochastic differential equations efficiently by minimum\nchi-squared. Biometrika, 84(1):125\u2013141.\nGallant, A. R. and Tauchen, G. (1996). Which moments to match? Econometric Theory, 12(4):657\u2013681.\nGallant, A. R. and Tauchen, G. (1998). Reprojecting partially observed systems with applications to interest\nrate diffusions. Journal of American Statistical Association, 93(441):10\u201324.\nGolightly, A. and Wilkinson, D. (2006). Bayesian sequential inference for nonlinear multivariate diffusions.\nStatistics and Computing, 16:323\u2013338.\nGolightly, A. and Wilkinson, D. (2007). Bayesian inference for nonlinear multivariate diffusions observed\nwith error. Computational Statistics and Data Analysis, 52(3), 1674\u20131693.\nGourie\u00b4roux, C., Monfort, A., and Renault, E. (1993). Indirect inference. Journal of Applied Econometrics,\n8:S85\u2013S118.\nHeston, S. (1993). A closed-form solution for options with stochastic volatility. with applications to bonds\nand currency options. Review of Financial Studies, 6:327\u2013343.\nHull, J. C. and White, A. D. (1987). The pricing of options on assets with stochastic volatilities. Journal of\nFinance, 42(2):281\u2013300.\nJones, C. S. (1999). Bayesian estimation of continuous-time finance models. Unpublished paper, Simon\nSchool of Business, University of Rochester.\nJones, C. S. (2003). Nonlinear mean reversion in the short-term interest rate. The review of financial studies,\n16:793\u2013843.\nKalogeropoulos, K. (2007). Likelihood based inference for a class of multidimensional diffusions with unob-\nserved paths. Journal of Statistical Planning and Inference, 137:3092\u20133102\nKalogeropoulos, K., Dellaportas, P., and Roberts, G. (2007). Likelihood-based inference for correllated\ndiffusions. Submitted.\nLiu, J. and West, M. (2001). Combined parameter and state estimation in simulation-based filtering In\nSequential Monte Carlo Methods in Practice, by A. Doucet, J.F.G. De Freitas and N.J. Gordon, Springer-\nVerlag, New York.\nOksendal, B. (2000). Stochastic differential equations. Springer, 5th edition.\nPapaspiliopoulos, O. and Roberts, G. (2008). Retrospective MCMC for Dirichlet process hierarchical models.\nBiometrika, 95(1):169\u2013186\nPedersen, A. R. (1995). A new approach to maximum likelihood estimation for stochastic differential equa-\ntions based on discrete observations. Scand. J. Statist., 22(1):55\u201371.\nPitt, M.K. and Shephard, N. (1999). Filtering via Simulation: Auxiliary Particle Filters. Journal of the\nAmerican Statistical Association, 94(446):590\u2013599.\nRoberts, G. and Stramer, O. (2001). On inference for partial observed nonlinear diffusion models using the\nmetropolis-hastings algorithm. Biometrika, 88(3):603\u2013621.\nRogers, L. C. G. and Williams, D. (1994). Diffusions, Markov processes and martingales, 2, Ito calculus.\nWiley, Chicester.\n20\nS\u00f8rensen, H. (2004). Parametric inference for diffusion processes observed at discrete points in time: a\nsurvey. International Statistical Review, 72(3):337\u2013354.\nStein, E. M. and Stein, J. C. (1991). Stock proce distributions with stochastic volatility: an analytic\napproach. Review of Financial Studies, 4(4):727\u2013752.\nStroud, J.R. and Polson, N.G. and Muller P. (2004). Practical filtering for stochastic volatility models. In\nState Space and Unobserved Component Models, (by Harvey et al.), Cambridge University Press 236\u2013247.\nTanner, M. A. and Wong, W. H. (1987). The calculation of posterior distributions by data augmentation.\nJournal of the American Statistical Association, 82(398):528\u2013540.\n21\n"}
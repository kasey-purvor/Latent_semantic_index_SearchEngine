{"doi":"10.1108\/03055720410699928","coreId":"10792","oai":"oai:www.e-space.mmu.ac.uk:2173\/1509","identifiers":["oai:www.e-space.mmu.ac.uk:2173\/1509","10.1108\/03055720410699928"],"title":"Evaluating the Joint Information Systems Committee's Information Environment: the EDNER and EDNER+ projects","authors":["Brophy, Peter"],"enrichments":{"references":[{"id":17784770,"title":"Competing on the Eight Dimensions of Quality.","authors":[],"date":"1987","doi":null,"raw":"Garvin, D. A. (1987) Competing on the Eight Dimensions of Quality. Harvard Business Review, November-December, 108-109.","cites":null},{"id":17784768,"title":"EDNER: Formative Evaluation of the Distributed National Electronic Resource: DNER Service evaluation (Deliverable","authors":[],"date":"2001","doi":null,"raw":"Brophy P, Fisher S, Griffiths J. R. and Markland M. (2001) EDNER: Formative Evaluation of the Distributed National Electronic Resource: DNER Service evaluation (Deliverable MDA 2, EDNER Project).  Manchester: CERLIM (The Centre for Research in Library & Information Management). Available at http:\/\/www.cerlim.ac.uk\/projects\/iee\/index.php Brophy, P. (1998) It may be electronic but is it any good? Measuring the performance of electronic services. Robots to Knowbots: the wider automation agenda. Proceedings of the Victorian Association for Library Automation 9th Biennial Conference, January 28-30 1998. Melbourne, Australia: VALA, 217-230. <http:\/\/www.vala.org.au\/valaweb\/num511.pdf> Brophy, P. (2004) The Quality of Libraries. In Die effective Bibliothek.","cites":null},{"id":17784771,"title":"Evaluation of the JISC Information Environment: student perceptions of services. Information Research.","authors":[],"date":"2003","doi":null,"raw":"- 17 -Griffiths, J.R. (2003) Evaluation of the JISC Information Environment: student perceptions of services. Information Research.   http:\/\/informationr.net\/ir\/8-4\/paper160.html Griffiths, J.R. and Brophy, P. (2002) Student searching behaviour in the JISC Information Environment. Ariadne, 33. <http:\/\/www.ariadne.ac.uk\/issue33\/edner\/intro.html> Zipf, G. (1949). Human Behaviour and the Principle of Least Effort. Reading MA: Addison-Wesley. - 18 -","cites":null},{"id":17784767,"title":"Identifying user-based criteria for Web pages. Internet Research: Electronic Networking Applications and Policy,","authors":[],"date":"1997","doi":"10.1108\/10662249710187141","raw":"Abels, E.G., White, M.D. and Hahn, K. (1997) Identifying user-based criteria for Web pages. Internet Research: Electronic Networking Applications and Policy, 7(4),  252-62.","cites":null},{"id":17784769,"title":"Surfing vs. searching: the Web as a research tool.","authors":[],"date":"2001","doi":null,"raw":"M\u00fcnchen: K. G. Saur. pp. 30-46 Cmor, D. and Lippold, K. (2001).  Surfing vs. searching: the Web as a research tool. Presented at the 21 st Annual Conference of the Society for Teaching   and   Learning   in   Higher   Education.   [-Online] http:\/\/www.mun.ca\/library\/research_help\/qeii\/stlhe\/ Garvin, D. A. (1984) What Does \u201cProduct Quality\u201d Really Mean?  Sloan Management Review, 25-45.","cites":null}],"documentType":{"type":0.6666666667}},"contributors":[],"datePublished":"2006-03-08T12:18:59Z","abstract":"This article was originally published by Emerald Group Publishing.","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/10792.pdf","fullTextIdentifier":"http:\/\/hdl.handle.net\/2173\/1509","pdfHashValue":"6502872b527960a3890fa0496f59a8deaccbbe0a","publisher":"Emerald Group Publishing Ltd.","rawRecordXml":"<record><header><identifier>\noai:www.e-space.mmu.ac.uk:2173\/1509<\/identifier><datestamp>2012-03-20T02:10:50Z<\/datestamp><setSpec>hdl_2173_670<\/setSpec><setSpec>hdl_2173_682<\/setSpec><\/header><metadata><oai_dc:dc xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Evaluating the Joint Information Systems Committee's Information Environment: the EDNER and EDNER+ projects<\/dc:title><dc:creator>Brophy, Peter<\/dc:creator><dc:subject>Customer satisfaction<\/dc:subject><dc:subject>Information searches<\/dc:subject><dc:subject>Information systems<\/dc:subject><dc:subject>Quality<\/dc:subject><dc:description>Purpose: Reports on findings of work concerning the use of the JISC information environment by students, considering how information environments are related to the working environments of their users. Design\/methodology\/approach: CERLIM at Manchester Metropolitan University, partnered by CSALT (the Centre for Studies in Advanced Learning Technologies) at Lancaster University, has brought to bear perspectives from both information management and educational research. During 2003 to 2004 the scope of the evaluation was broadened to include all of the JISC development activity in the information environment area and has been extended to the further education sector: this is known as EDNER+. Findings: The use of quality attributes approaches can provide clues as to what it is about a service which is creating dissatisfaction among the users. Research limitations\/implications. Coupled with other findings about \"satisficing\" behaviours, the findings are suggestive of some of the key areas which need to be given attention. They also support a finding from this and other work in EDNER\/EDNER+, namely that to students internet search engines in general and Google in particular represent a benchmark of \"good\". Practical implications. Given that use of bibliographic services is uniformly low among undergraduate students, and that the use of OPACs is variable, IE service developers will have to work very hard to produce services which gain acceptance among this group of users. Since IE includes further education students among its target user groups, it will be critical to address the full range of attributes against the needs of this group, as well as the higher education group, in future service design. Originality\/value: Using a wide range of methodologies the team has explored the outcomes of a large number of projects funded by the JISC, as well as examining the architecture and rollout of the information environment itself.<\/dc:description><dc:description>This article was originally published by Emerald Group Publishing.<\/dc:description><dc:publisher>Emerald Group Publishing Ltd.<\/dc:publisher><dc:date>2006-03-08T12:18:59Z<\/dc:date><dc:type>Article<\/dc:type><dc:format>84992 bytes<\/dc:format><dc:format>application\/msword<\/dc:format><dc:identifier>VINE: The Journal of Information and Knowledge Management Systems, 2004, vol. 34, no. 4, pp. 143-147<\/dc:identifier><dc:identifier>0305-5728<\/dc:identifier><dc:identifier>http:\/\/hdl.handle.net\/2173\/1509<\/dc:identifier><dc:language>en<\/dc:language><dc:relation>http:\/\/www.emeraldinsight.com\/Insight\/ViewContentServlet?Filename=\/published\/emeraldfulltextarticle\/pdf\/2870340401.pdf<\/dc:relation><dc:relation>http:\/\/www.emeraldinsight.com\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/www.emeraldinsight.com\/Insight\/ViewContentServlet?Filename=\/published\/emeraldfulltextarticle\/pdf\/2870340401.pdf","http:\/\/www.emeraldinsight.com\/"],"year":2006,"topics":["Customer satisfaction","Information searches","Information systems","Quality"],"subject":["Article"],"fullText":"Evaluating the Joint Information Systems Committee\u2019s Information \nEnvironment \u2013 the EDNER and EDNER+ projects\nProfessor Peter Brophy\nDirector\nCERLIM (the Centre for Research in Library and Information Management)\nManchester Metropolitan University, UK\nEmail: p.brophy@mmu.ac.uk\nAbstract\nSince early 2000 the EDNER project has been investigating the impacts of \nthe development of the JISC Information Environment (IE) with particular \nreference to learning and teaching in higher education.\nThe consortium, led by CERLIM (the Centre for Research in Library and \nInformation Management) at the Manchester Metropolitan University, \npartnered by CSALT (the Centre for Studies in Advanced Learning \nTechnologies) at Lancaster University, has brought to bear perspectives \nfrom both information management and educational research. Using a wide \nrange of methodologies the team has explored the outcomes of a large \nnumber of projects funded by the JISC, as well as examining the \narchitecture and rollout of the Information Environment itself.  During 2003 \nto 2004 the scope of the evaluation has been broadened to include all of \nthe JISC development activity in the information environment area and has \nbeen extended to the further education sector: this is known as EDNER+.\n- 1 -In this paper the Director of the project reports on some of the findings of \nthis work concerning the use of the JISC information environment by \nstudents, seeking to place this within a broader context by considering how \ninformation environments are related to the working environments of their \nusers.  \nIntroduction\nThe Joint Information Systems Committee (JISC) works with UK higher and \nfurther education (HE and FE) institutions by providing guidance and advice; \nby funding development programmes in relevant information and \ncommunications technology (ICT) applications which support learning, \nteaching, research and administration; and by providing network and data \nservices to these communities. JISC is also a strategic advisory committee \nworking on behalf of the funding bodies for higher and further education in \nEngland, Scotland, Wales and Northern Ireland. \nIn 1999 funding was made available over three years to improve JISC \nservices with particular emphasis on learning and teaching, and a call for \nproposals was issued in JISC Circular 5\/99 (JISC, 1999) for projects to \ndevelop what was then known as Distributed National Electronic Resource \n(DNER). The DNER was described as:\na managed environment for accessing quality assured information \nresources on the Internet which are available from many sources. \nThese resources include scholarly journals, monographs, textbooks, \nabstracts, manuscripts, maps, music scores, still images, geospatial \n- 2 -images and other kinds of vector and numeric data, as well as \nmoving picture and sound collections (JISC, 1999)\nThe major foci of this call for proposals were 1) the implementation and \ndevelopment of the DNER itself, 2) enhancements to JISC services to make \nthem more appropriate for learning and teaching, and 3) evaluation studies \nrelating to the first two themes. Projects funded to develop the DNER have \nbeen described by Ingram and Grout (2002). The EDNER Project (Formative \nEvaluation of the DNER, http:\/\/www.cerlim.ac.uk\/edner) was funded to \nundertake ongoing evaluation of the developing DNER over the full three \nyears of the JISC 5\/99 Learning & Teaching and Infrastructure Programme \nperiod i.e. from 2000 to 2003. Since its successful completion in 2003 it was \nawarded a one year extension until July 2004 (EDNER+). The EDNER and \nEDNER+ Projects have been led by the Centre for Research in Library & \nInformation Management (CERLIM) at the Manchester Metropolitan \nUniversity with the Centre for Studies in Advanced Learning Technologies \n(CSALT) at Lancaster University as a partner. This paper reports on some of \nthe work from both the EDNER and EDNER+ Projects.\nMethodologies\nBecause of its nature as a wide ranging formative evaluation, \nEDNER\/EDNER+ has used a wide range of methodologies. Part of the \nchallenge of this kind of investigation has been to manage this mix so as to \nproduce coherent findings. Among the methods used have been:\n- 3 -\u00b7 Definition of the evaluation space. It rapidly became apparent that \nbefore any kind of evaluative activity could be started we needed to \ndefine what exactly was meant by the \u2018Distributed National Electronic \nResource\u2019. In particular, we needed to characterise the ways in which \nstakeholders anticipated that a \u2018resource\u2019 would impact upon the \npractice of teaching and the experience of learning. As the concept \nchanged from a \u2018national resource\u2019 to a shared \u2018Information \nEnvironment\u2019 we needed to revisit the understanding we had \ndeveloped. Here, the question was, in what ways does an information \nenvironment interact with, engage with, influence and produce \nchange within a learning and teaching space?\n\u00b7 Engagement with the individual projects and with project clusters. We \nneeded to understand \u2018what made the project tick\u2019 and, since we \nwanted also to influence projects, we wanted to challenge them to \nsurface hidden assumptions. A particularly important workshop, led \nby CSALT, involved an exercise in surfacing \u2018implicit theories of \nchange\u2019. In other words we sought to help project teams to face the \nquestion of how they assumed changed learning would occur as a \nresult of their project. An alarming number of answers seemed to \nindicate that there was a widespread assumption that \u2018improving \naccess\u2019 would of itself lead to purposive change. We challenged that \nassumption. \n\u00b7 Exploration of the information and learning environments of two \nhigher education institutions in depth. We wanted to dig beneath the \nsurface and find out, for example, how JISC services and projects \nsurfaced within institutions. We discovered, to again give an example, \nthat descriptions of services within university web sites were very \n- 4 -varied, with particularly confused examples in departmental and \nindividual sites. Libraries, it may be noted, provided the best-\nstructured web sites for accessing information resources \u2013 a finding \nthat should come as no surprise but perhaps may be greeted by \nprofessionals with some relief!\n\u00b7 We undertook targeted surveys of key stakeholders. These ranged \nfrom interviews with vice chancellors and principals, with university \nand college librarians and with subject librarians to questionnaires \ndistributed to various groups of users.\n\u00b7 In-depth experiments were undertaken with groups of undergraduate \nstudents, in each case occupying two full days of work, for which the \nstudents were paid. This part of EDNER\/EDNER+ is described more \nfully later in this paper.\n\u00b7 We worked with projects to make an assessment of the initial take-up \nand use of their products. Here we identified some of the key factors \ninhibiting use, many of which had little or nothing to do with the \nproduct\/service itself but could be as simple as the lack of online \naccess within the classroom or as complex as finding ways of \nmotivating lecturers to modify the curriculum.\n\u00b7 We undertook documentary and expert analysis in order to identify \nthe validity of assumptions and designs. This was particularly \nrelevant to the analysis of the JISC Information Architecture, which \nunderlies the IE, and which models the complex interactions between \nIE component systems.\nResults\n- 5 -The EDNER and EDNER+ projects have produced a wealth of reports. \nInitially many of these were treated as confidential to the JISC, not least \nbecause they contained insights gleaned in confidential discussions with \nprojects. However, public versions of virtually all the reports are now \navailable and can be downloaded from the project web site at \nhttp:\/\/www.cerlim.ac.uk\/projects\/iee\/index.php\nIn this paper the concentration is on the analysis of student searching \nbehaviour using a quality attributes methodology. This is described below.\nExploring student searching behaviour\nIn order to understand better the interaction between students and DNER \nresources,   EDNER   carried   out   some   detailed   testing   of   information \nsearching.   Using   a   small   group   of   approximately   40   undergraduate \nstudents,   the   project   explored   information   seeking   behaviour   with \nunstructured and structured searches \u2013 in the former the students were \nsimply asked to find information on \u2018x\u2019, while in the latter they were asked \nto use a particular DNER service cluster to find information. A quality \nattributes approach was used to guide their assessments (Brophy 2001 \u2013 \nsee also below). As with other studies (e.g. Zipf (1949), Cmor and Lippold \n(2001)) it was found that students minimize effort by turning first to Internet \nsearch engines, of which by far the most commonly-used was Google, and \noften appear to engage in \u2018satisficing\u2019 behaviour i.e. they find that readily-\navailable information resources, while incomplete and often of doubtful \nquality, are \u2018good enough\u2019. This suggests that a challenge for higher and \nfurther   education   will   be   to   ensure   that   the   value   of   quality-assured \nresources is appreciated. There are implications also for libraries\u2019 work on \n- 6 -information skills and information literacy. Further there are questions about \nhow \u2018quality assurance\u2019 is defined and operationalised in this context \u2013 \nagain these are further elaborated below. The student behaviour monitoring \nexercise   was   repeated   within   EDNER+   in   relation   to   the   broad   JISC \nInformation Environment, although the results of that part of the work are \nstill being analysed.\nWe were interested in this exercise in the \u2018quality\u2019 of services as judged by a \ngroup  of  their primary users,  but we wanted to go beyond a  simple \napproach which would rate services either by overall user satisfaction or by \nthe kind of measures used in information retrieval systems (e.g. recall and \nprecision) which tell us little about the user experience. Having been \ninterested in the approach advocated by Garvin (1984, 1987) for some time, \nwe determined to use an adapted quality attributes methodology. The idea \nbehind this is to try to break \u2018quality\u2019 down into different aspects, as \nperceived by users.\nGarvin\u2019s methodology has been used by others, notably by Abels, White and \nHahn (1997) in assessing web sites. The table below provides a comparison \nof  Garvin\u2019s  original formulation  with  that  we adopted  (Brophy  (1998); \nGriffiths and Brophy (2002); Griffiths (2003)) and that of Abels, White and \nHahn.\n- 7 -GARVIN BROPHY and \nGRIFFITHS\nABELS et al.\nPerformance, the \nprimary purpose of \nthe product or \nservice and how well \nit is achieving that \nprimary purpose.\nPerformance, \nconcerned with \nestablishing \nconfirmation that a \nservice meets its \nmost basic purpose, \nsuch as making key \ninformation sources \navailable on demand.\nPerformance based \non use, including \nease of use, and \ncontent.\nFeatures, secondary \ncharacteristics which \nadd to the service or \nproduct without \nbeing of its essence.\nFeatures: aspects of \nthe service which \nappeal to users but \nare beyond the \nessential core \nperformance \nattributes.\nFeatures such as \nlinks to other sites \nwhich might better \nanswer a particular \nquestion.\nReliability, the \nconsistency of the \nproduct or service\u2019s \nperformance in use.\nReliability, which for \ninformation services \nwould include \navailability of the \nservice. Such \nproblems as broken \nWeb links, lack of \nreliability and \nslowness in speed of \nresponse would be \nmeasured as part of \nthis attribute. \nReliability, including \nboth availability and \ncurrency\/accuracy of \ninformation provided.\n- 8 -GARVIN BROPHY and \nGRIFFITHS\nABELS et al.\nConformance, \nwhether or not the \nproduct or service \nmeets the agreed \nstandard, which may \nbe internally or \nexternally generated.\nConformance: \nwhether the service \nmeets the agreed \nstandard, including \nconformance \nquestions around the \nutilisation of \nstandards and \nprotocols such as \nXML, RDF, Dublin \nCore, OAI, Z39.50 \netc.\n(Not defined)\nDurability, the \namount of use the \nproduct or service \ncan provide before it \ndeteriorates to a \npoint where it needs \nreplacement.\nDurability, related to \nthe sustainability of \nthe information or \nlibrary service over a \nperiod of time.\n(Not defined)\nCurrency of \ninformation, that is, \nhow up to date the \ninformation provided \nis when it is \nretrieved. \n(Treated as part of \n\u201cReliability\u201d)\n- 9 -GARVIN BROPHY and \nGRIFFITHS\nABELS et al.\nServiceability, how \neasy it is to repair a \nproduct or correct a \nservice when it goes \nwrong, including the \nlevel of \ninconvenience \nexperienced by the \ncustomer.\nServiceability, which \nmay translate to the \nlevel of help \navailable to users \nduring, for example, \ninformation retrieval, \nor otherwise at the \npoint of need. The \navailability of \ninstructions and \nprompts throughout \nan online service, \ncontext sensitive \nhelp and the \nusefulness of that \nhelp could be \nmeasured in order to \nassess performance \nunder this attribute.\nServiceability \nconcerned with the \nhandling of \ncomplaints and \nconflicts, with the \naim of creating a \nhappy and satisfied \ncustomer.\nAesthetics, the \nappearance of the \nproduct or service.\nAesthetics and \nImage, related to the \nappearance and \nattractiveness of the \nservice in the \njudgement of the \nuser.\nAesthetics, \nconcerned with \nvisual attractiveness\n- 10 -GARVIN BROPHY and \nGRIFFITHS\nABELS et al.\nPerceived quality, in \nessence the \nreputation of the \nproduct or service \namong the \npopulation, \nespecially those with \nwhom the potential \ncustomer comes into \ncontact.\nPerceived Quality: \nthe user\u2019s view of \nthe service as a \nwhole and the \ninformation retrieved \nfrom it. It may be \nuseful to measure \nperceptions both \nbefore and after a \nservice is used. \nReputation, related \nto past experiences \nof the site.\nUsability, which is \nparticularly relevant \nto electronic services \nand includes issues \nof accessibility for \nthose with a \ndisability.\nStructure, which is \nconcerned with how \ninformation is \nstructured within the \nweb site\u2019s \npresentation.\nStorage capability, \nwhich is concerned \nwith whether all \nrequired information \ncan be stored in \norder to answer \nqueries which may, \nfor example, require \nan historical analysis.\n- 11 -GARVIN BROPHY and \nGRIFFITHS\nABELS et al.\nSecurity and system \nintegrity, including \nthe handling of \npayment (e.g. credit \ncard) data.\nTrust, whether users \nare wiling to disclose \npersonal information. \nClosely linked to \n\u201cSecurity and system \nintegrity\u201d.\nResponsiveness, \nwhich includes \ncourtesy and \nwillingness to be \nflexible (for example \nwith a cancelled \norder).\nProduct\/service \ndifferentiation and \ncustomization, which \nasks what is unique \nabout this particular \nweb site, not least to \ndifferentiate it from \nits competitors.\n- 12 -GARVIN BROPHY and \nGRIFFITHS\nABELS et al.\nWeb store policies, \nwhich relates to the \ncustomer-orientation \nof policies and might \ninvolve a comparison \nwith a high street \nstore.\nAssurance, \nconcerned with the \ncreation of good \ncustomer \nexperiences through \nthe knowledgability \nand courtesy of staff.\nEmpathy, which may \nbe expressed \nthrough the \navailability of \nindividualised \npersonal attention.\nThe relationship of these approaches to other methods of assessing quality \nin library and information services has been addressed elsewhere (Brophy, \n2004).\nIn the exercises with students we used eight attributes:\n\u2022 Performance\n\u2022 Features\n- 13 -\u2022 Reliability\n\u2022 Currency\n\u2022 Serviceability\n\u2022 Aesthetics\n\u2022 Perceived quality\n\u2022 Usability\nConformance and durability were not tested as they would be outwith the \nexperience and competence of end users to judge.\nWe reported on our findings from the first iteration of this exercise (related \nto the 5\/99 projects with three control services) in 2002 (Brophy, Fisher, \nGriffiths and Markland, 2002); at the time of writing this paper a second, \nsimilar exercise (related to the IE) was still being analysed.\nThe full results of this work can be accessed in the report referred to above, \nbut here we present a sample of two results to illustrate our findings and \nthe kinds of conclusions (or inferences) that might be drawn from them.\nC\nl\nu\ns\nt\ne\nr\n \nA\nC\nl\nu\ns\nt\ne\nr\n \nB\nC\nl\nu\ns\nt\ne\nr\n \nC\nC\nl\nu\ns\nt\ne\nr\n \nD\nC\nl\nu\ns\nt\ne\nr\n \nE\nC\nl\nu\ns\nt\ne\nr\n \nF\nG\no\no\ng\nl\ne\nB\nB\nC\n \nO\nn\nl\ni\nn\ne\nU\nn\ni\nv\ne\nr\ns\ni\nt\ny\n \nO\nP\nA\nC\nPerformanc\ne\n92 56 100 80 40 89 93 100 52\nAesthetics 80 40 96 62 56 89 82 85 67\nOverall \nSatisfactio\nn\n88 32 96 58 29 73 89 96 63\nTable 1: Students\u2019 assessment of the quality of services (n=27)\n- 14 -Table 1 shows the mean rating given to each of the tested services by the \nstudents for the two attributes \u2018performance\u2019 and \u2018aesthetics\u2019, together with \nthe mean overall rating. While there is a clear correlation between the \nresults for each service there are some interesting differences. Cluster B, for \nexample, was given a low overall rating of 32%, but scored 56% for \nperformance i.e. its ability to retrieve items. Cluster E had a similar overall \nrating but its aesthetics and performance scores were reversed. Cluster F \nscored highly for both performance and aesthetics, but its lower overall \nsatisfaction rating suggests other factors were not so highly rated. \nWe noted that, of the control services, both Google and BBC Online scored \nhighly for all attributes. The University OPAC was somewhat less highly \nrated.\nConclusions\nThe use of quality attributes approaches can provide clues as to what it is \nabout a service which is creating dissatisfaction among the users. Coupled \nwith other findings about satisficing behaviours, the findings are suggestive \nof some of the key areas which need to be given attention. They also \nsupport a finding from this and other work in EDNER\/EDNER+, namely that \nto students the Internet search engines in general and Google in particular \nrepresent a benchmark of \u2018good\u2019. Having found that use of bibliographic \nservices is uniformly low among undergraduate students, and that the use \nof OPACs is variable, we conclude that IE service developers will have to \nwork very hard to produce services which gain acceptance among this \ngroup of users. Since the IE includes further education students among its \ntarget user groups, it will be critical to address the full range of attributes \n- 15 -against the needs of this, as well as the higher education group, in future \nservice design.\nAcknowledgement\nI would like to express my thanks to all the staff of the EDNER and EDNER+ \nprojects, who contributed as a real team to the many different exercises in \nwhich we engaged. \n- 16 -References\nAbels, E.G., White, M.D. and Hahn, K. (1997) Identifying user-based criteria \nfor Web pages. Internet Research: Electronic Networking Applications and \nPolicy, 7(4),  252-62.\nBrophy P, Fisher S, Griffiths J. R. and Markland M. (2001) EDNER: Formative \nEvaluation of the Distributed National Electronic Resource: DNER Service \nevaluation (Deliverable MDA 2, EDNER Project).  Manchester: CERLIM (The \nCentre for Research in Library & Information Management). Available at \nhttp:\/\/www.cerlim.ac.uk\/projects\/iee\/index.php\nBrophy, P. (1998) It may be electronic but is it any good? Measuring the \nperformance of electronic services. Robots to Knowbots: the wider \nautomation agenda. Proceedings of the Victorian Association for Library \nAutomation 9th Biennial Conference, January 28-30 1998. Melbourne, \nAustralia: VALA, 217-230. <http:\/\/www.vala.org.au\/valaweb\/num511.pdf>\nBrophy, P. (2004) The Quality of Libraries. In Die effective Bibliothek. \nM\u00fcnchen: K. G. Saur. pp. 30-46\nCmor, D. and Lippold, K. (2001).  Surfing vs. searching: the Web as a \nresearch tool. Presented at the 21\nst Annual Conference of the Society for \nTeaching   and   Learning   in   Higher   Education.   [-Online] \nhttp:\/\/www.mun.ca\/library\/research_help\/qeii\/stlhe\/\nGarvin, D. A. (1984) What Does \u201cProduct Quality\u201d Really Mean?  Sloan \nManagement Review, 25-45.\nGarvin, D. A. (1987) Competing on the Eight Dimensions of Quality. Harvard \nBusiness Review, November-December, 108-109.\n- 17 -Griffiths, J.R. (2003) Evaluation of the JISC Information Environment: student \nperceptions of services. Information Research.   http:\/\/informationr.net\/ir\/8-\n4\/paper160.html \nGriffiths, J.R. and Brophy, P. (2002) Student searching behaviour in the JISC \nInformation Environment. Ariadne, 33. \n<http:\/\/www.ariadne.ac.uk\/issue33\/edner\/intro.html>\nZipf, G. (1949). Human Behaviour and the Principle of Least Effort. Reading \nMA: Addison-Wesley.\n- 18 -"}
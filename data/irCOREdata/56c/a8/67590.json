{"doi":"10.1109\/CEC.2007.4424517","coreId":"67590","oai":"oai:eprints.lancs.ac.uk:39677","identifiers":["oai:eprints.lancs.ac.uk:39677","10.1109\/CEC.2007.4424517"],"title":"Computational intelligence algorithms for risk-adjusted trading strategies.","authors":["Pavlidis, Nicos","Pavlidis, Efthymios","Epitropakis, Michael","Plagianakos, Vasilis","Vrahatis, Michael"],"enrichments":{"references":[{"id":788132,"title":"Clustering in evolutionary algorithms to ef\ufb01ciently compute simultaneously local and global minima,\u201d","authors":[],"date":"2005","doi":null,"raw":"D. Tasoulis, V. Plagianakos, and M. Vrahatis, \u201cClustering in evolutionary algorithms to ef\ufb01ciently compute simultaneously local and global minima,\u201d in IEEE Congress on Evolutionary Computation, vol. 2, Edinburgh, UK, 2005, pp. 1847\u20131854.","cites":null},{"id":785146,"title":"Currency traders and exchange rate dynamics: a survey of the us market,\u201d","authors":[],"date":"2001","doi":null,"raw":"Y.-W. Cheung and M. D. Chinn, \u201cCurrency traders and exchange rate dynamics: a survey of the us market,\u201d Journal of International Money and Finance, vol. 20, no. 4, pp. 439\u2013471, 2001.","cites":null},{"id":784903,"title":"Data-snooping, technical trading rule performance, and the bootstrap,\u201d","authors":[],"date":"1999","doi":null,"raw":"R. Sullivan, A. Timmermann, and H. White, \u201cData-snooping, technical trading rule performance, and the bootstrap,\u201d Journal of Finance, vol. 54, no. 5, pp. 1647\u20131691, 1999.","cites":null},{"id":786830,"title":"Differential evolution \u2013 a simple and ef\ufb01cient adaptive scheme for global optimization over continuous spaces,\u201d","authors":[],"date":"1997","doi":null,"raw":"R. Storn and K. Price, \u201cDifferential evolution \u2013 a simple and ef\ufb01cient adaptive scheme for global optimization over continuous spaces,\u201d Journal of Global Optimization, vol. 11, pp. 341\u2013359, 1997.","cites":null},{"id":786257,"title":"Effective retrun, risk aversion and drawdowns,\u201d","authors":[],"date":"2001","doi":null,"raw":"R. Genc \u00b8ay, M. Dacorogna, U. M\u00a8 uller, and O. Pictet, \u201cEffective retrun, risk aversion and drawdowns,\u201d Physica A, vol. 289, no. 1\u20132, pp. 229\u2013 248, 2001.","cites":null},{"id":785672,"title":"Exchange rate puzzles. a tale of switching attractors,\u201d","authors":[],"date":"2006","doi":null,"raw":"P. D. Grauwe and M. Grimaldi, \u201cExchange rate puzzles. a tale of switching attractors,\u201d European Economic Review, vol. 50, no. 1, pp. 1\u201333, 2006.","cites":null},{"id":787404,"title":"Genetic programming: An Introduction: on the automatic evolution of computer programs and its applications.","authors":[],"date":"1998","doi":null,"raw":"B. Wolfgang, P. Nordin, R. Keller, and F. Francone, Genetic programming: An Introduction: on the automatic evolution of computer programs and its applications. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1998.","cites":null},{"id":787134,"title":"Genetic Programming: On the Programming of Computers by Means of Natural Selection.","authors":[],"date":"1992","doi":null,"raw":"J. R. Koza, Genetic Programming: On the Programming of Computers by Means of Natural Selection. Cambridge, MA, USA: MIT Press, 1992.","cites":null},{"id":785956,"title":"Have trading rule pro\ufb01ts in the currency market declined over time?\u201d","authors":[],"date":"2004","doi":null,"raw":"D. Olson, \u201cHave trading rule pro\ufb01ts in the currency market declined over time?\u201d Journal of Banking and Finance, vol. 28, no. 4, pp. 85\u2013 105, 2004.","cites":null},{"id":788675,"title":"Is technical analysis in the foreign exchange market pro\ufb01table? a genetic programming approach,\u201d","authors":[],"date":"1997","doi":null,"raw":"C. J. Neely, P. A. Weller, and R. Dittmar, \u201cIs technical analysis in the foreign exchange market pro\ufb01table? a genetic programming approach,\u201d Journal of Financial and Quantitative Analysis, vol. 32, no. 4, pp. 405\u2013426, 1997.","cites":null},{"id":788699,"title":"Meteor showers or heat waves? heteroskedastic intra-daily volatility in the foreign exchange market,\u201d","authors":[],"date":"1990","doi":null,"raw":"R. F. Engle, T. Ito, and W.-L. Lin, \u201cMeteor showers or heat waves? heteroskedastic intra-daily volatility in the foreign exchange market,\u201d Econometrica, vol. 58, pp. 525\u2013542, 1990.","cites":null},{"id":788406,"title":"Mutual fund performance,\u201d","authors":[],"date":"1966","doi":null,"raw":"W. F. Sharpe, \u201cMutual fund performance,\u201d Journal of Business, vol. 39, no. 1, pp. 119\u2013138, 1966.","cites":null},{"id":789858,"title":"Numerical Recipes in Fortran 77.","authors":[],"date":"1992","doi":"10.1086\/416228","raw":"W. Press, S. Teukolsky, W. Vetterling, and B. Flannery, Numerical Recipes in Fortran 77. Cambridge University Press, 1992.","cites":null},{"id":787538,"title":"On the search properties of different crossover operators in genetic programming,\u201d in Genetic Programming","authors":[],"date":"1998","doi":null,"raw":"R. Poli and W. B. Langdon, \u201cOn the search properties of different crossover operators in genetic programming,\u201d in Genetic Programming 1998: Proceedings of the Third Annual Conference, J. R. Koza, W. Banzhaf, K. Chellapilla, K. Deb, M. Dorigo, D. B. Fogel, M. H. Garzon, D. E. Goldberg, H. Iba, and R. Riolo, Eds., 1998, pp. 293\u2013 301.","cites":null},{"id":786546,"title":"Optimization of technical rules by genetic algorithms: evidence from the madrid stock market,\u201d","authors":[],"date":"2005","doi":null,"raw":"F. Fern\u00b4 andez-Rodr\u00b4 \u0131guez, C. Gonz\u00b4 alez-Martel, and S. Sosvilla-Rivero, \u201cOptimization of technical rules by genetic algorithms: evidence from the madrid stock market,\u201d Applied Financial Economics, vol. 15, pp. 773\u2013775, 2005.","cites":null},{"id":787837,"title":"Parallel differential evolution,\u201d","authors":[],"date":"2004","doi":null,"raw":"D. K. Tasoulis, N. G. Pavlidis, V. P. Plagianakos, and M. N. Vrahatis, \u201cParallel differential evolution,\u201d in IEEE Congress on Evolutionary Computation (CEC 2004), 2004.","cites":null},{"id":789000,"title":"Quasi\u2013maximum likelihood estimation and inference in dynamic models with time varying covariances,\u201d","authors":[],"date":"1992","doi":"10.1080\/07474939208800229","raw":"T. Bollerslev and J. M. Wooldridge, \u201cQuasi\u2013maximum likelihood estimation and inference in dynamic models with time varying covariances,\u201d Econometric Reviews, vol. 11, pp. 143\u2013172, 1992.","cites":null},{"id":785409,"title":"Technical trading rule pro\ufb01tability and foreign exchange intervention,\u201d","authors":[],"date":"1999","doi":null,"raw":"B. L. Baron, \u201cTechnical trading rule pro\ufb01tability and foreign exchange intervention,\u201d Journal of International Economics, vol. 49, no. 1, pp. 125\u2013143, 1999.","cites":null},{"id":789573,"title":"The jackknife, the bootstrap and other resampling.","authors":[],"date":"1982","doi":"10.2307\/2531123","raw":"B. Efron, The jackknife, the bootstrap and other resampling. SIAM, Philadelphia, PA, 1982.","cites":null},{"id":789339,"title":"The variation of certain speculative prices,\u201d","authors":[],"date":"1963","doi":"10.1086\/294632","raw":"B. Mandelbrot, \u201cThe variation of certain speculative prices,\u201d Journal of Business, vol. 36, pp. 394\u2013419, 1963.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-01","abstract":"This paper investigates the performance of trading strategies identified through Computational Intelligence techniques. We focus on trading rules derived by Genetic Programming, as well as, Generalized Moving Average rules optimized through Differential Evolution. The performance of these rules is investigated using recently proposed risk\u2013adjusted evaluation measures and statistical testing is carried out through simulation. Overall, the moving average rules proved to be more robust, but Genetic Programming seems more promising in terms of generating higher profits and detecting novel patterns in the data","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/67590.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/39677\/1\/PavlidisPEPV%2Dfinal.pdf","pdfHashValue":"900eb1d3bbdc42618e7a4c23dc2c8dc7f24f2f6a","publisher":"IEEE","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:39677<\/identifier><datestamp>\n      2018-01-24T01:59:08Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D48:4842<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Computational intelligence algorithms for risk-adjusted trading strategies.<\/dc:title><dc:creator>\n        Pavlidis, Nicos<\/dc:creator><dc:creator>\n        Pavlidis, Efthymios<\/dc:creator><dc:creator>\n        Epitropakis, Michael<\/dc:creator><dc:creator>\n        Plagianakos, Vasilis<\/dc:creator><dc:creator>\n        Vrahatis, Michael<\/dc:creator><dc:subject>\n        HB Economic Theory<\/dc:subject><dc:description>\n        This paper investigates the performance of trading strategies identified through Computational Intelligence techniques. We focus on trading rules derived by Genetic Programming, as well as, Generalized Moving Average rules optimized through Differential Evolution. The performance of these rules is investigated using recently proposed risk\u2013adjusted evaluation measures and statistical testing is carried out through simulation. Overall, the moving average rules proved to be more robust, but Genetic Programming seems more promising in terms of generating higher profits and detecting novel patterns in the data.<\/dc:description><dc:publisher>\n        IEEE<\/dc:publisher><dc:date>\n        2008-01<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/39677\/1\/PavlidisPEPV%2Dfinal.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/CEC.2007.4424517<\/dc:relation><dc:identifier>\n        Pavlidis, Nicos and Pavlidis, Efthymios and Epitropakis, Michael and Plagianakos, Vasilis and Vrahatis, Michael (2008) Computational intelligence algorithms for risk-adjusted trading strategies. In: IEEE Congress on Evolutionary Computation CEC 2007. IEEE, Singapore, pp. 540-547. ISBN 978-1-4244-1339-3<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/39677\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/CEC.2007.4424517","http:\/\/eprints.lancs.ac.uk\/39677\/"],"year":2008,"topics":["HB Economic Theory"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"Computational Intelligence Algorithms For Risk-Adjusted\nTrading Strategies\nN.G. Pavlidis, E.G. Pavlidis, M.G. Epitropakis, V.P. Plagianakos, and M.N. Vrahatis\nAbstract\u2014 This paper investigates the performance of trad-\ning strategies identified through Computational Intelligence\ntechniques. We focus on trading rules derived by Genetic\nProgramming, as well as, Generalized Moving Average rules\noptimized through Differential Evolution. The performance of\nthese rules is investigated using recently proposed risk\u2013adjusted\nevaluation measures and statistical testing is carried out through\nsimulation. Overall, the moving average rules proved to be more\nrobust, but Genetic Programming seems more promising in\nterms of generating higher profits and detecting novel patterns\nin the data.\nI. INTRODUCTION\nTechnical Analysis (TA) focuses on the identification of\nprice patterns and trends, as well as, the use of mechanical\nrules to generate valuable economic signals (see [1] for a\nthorough description of a number of simple trading rules).\nRecent surveys [2] suggest that TA has been a major con-\nstituent of financial practice in foreign exchange markets.\nMoreover, a number of empirical as well as theoretical\nstudies [3], [4] during the past three decades suggest that\nthe application of TA in the foreign exchange market can\nyield substantial excess returns. These findings raise doubts\non the validity of the efficient market hypothesis. Olson [5],\nhowever, argues that abnormal profit opportunities arise due\nto temporary inefficiencies which are in accordance with\nan evolving market. He further argues that the returns of\nsimple trading rules over recent periods have declined, if not\ncompletely disappeared.\nIn this work, we employ Genetic Programming (GP) to\nidentify novel trading strategies based only on the informa-\ntion contained in the history of past price movements. GP\ncan be considered as a Computational Intelligence algorithm\nthat mimics the behavior of an optimizing agent in the\nforeign exchange market. In this process it is critical to\nselect a performance measure that accounts not only for the\nreturn obtained from a rule, but also penalizes rules for the\nrisk they undertake. To this end, a recently proposed risk\nsensitive measure, Xeff , is used [6]. The performance of\nthe GP identified rules is compared to that of Generalized\nMoving Average (GMA) rules [7]. The parameters of the\nGMA rules are optimized using the Differential Evolution\n(DE) algorithm [8] and the same objective function as that\nused in GP.\nN.G. Pavlidis, M.G. Epitropakis, V.P. Plagianakos, and M.N. Vra-\nhatis are with the Computational Intelligence Laboratory, Department\nof Mathematics, University of Patras, GR\u201326110 Patras, Greece (email:\n{npav,mikeagn,vpp,vrahatis}@math.upatras.gr)\nE.G. Pavlidis is with the Department of Economics, Lancaster\nUniversity Management School, Lancaster LA1 4YX, UK (email:\ne.pavlidis@lancaster.ac.uk).\nFinally, a simulation methodology is implemented to test\nthe statistical significance of the best performing strategies\nidentified through each approach. Our findings suggest that\nthe widely\u2013used moving average rules exhibit a more robust\nbehavior than that of the more complicated GP generated\nstrategies. However, the hypothesis that the performance\nof these rules can be attributed to well\u2013known statistical\nproperties of the data cannot be rejected. On the other hand,\nGP is capable of identifying patterns that cannot be explained\nby traditional stochastic processes, so as to yield excess\nreturns.\nThe remaining of this paper is organized as follows.\nSections II and III briefly describe the Genetic Program-\nming and the Differential Evolution algorithms. Section IV\nis devoted to the presentation of the generalized moving\naverage rules, while Section V presents the risk sensitive\nperformance measures. The methodology of the simulations\nand the experimental results (and their statistical analysis)\nare exhibited in Sections VI and VII. Finally, the paper ends\nwith a discussion and concluding remarks.\nII. GENETIC PROGRAMMING\nIn this Section we briefly outline the Genetic Programming\n(GP) algorithm which was applied to identify new trading\nrules. Conceptually, GP constitutes an extension of Genetic\nAlgorithms (GAs) in which individuals are no longer fixed-\nlength strings but rather computer programs expressed as\nsyntax trees [9]. GP individuals consist of function and\nterminal nodes. Terminal nodes return as output the value\nof either a constant, or an input variable, or a zero-argument\nfunction. Thus, the arity of terminal nodes is zero. The set\nof possible terminal nodes is called the terminal set, T .\nFunction nodes on the other hand, process their inputs to\ncompute an output. The function set, F , is composed of the\nstatements and functions available to GP.\nThe primary GP search operators are crossover and muta-\ntion. In crossover, one subtree from each of the two selected\nparents is exchanged between them to form two new indi-\nviduals (offsprings). The motivation is that useful building\nblocks for the solution of a problem are accumulated in the\npopulation and crossover permits the aggregation of good\nbuilding blocks into even better solutions of the problem [9].\nCrossover is the predominant GP search operator [9], [10].\nOn the other hand, mutation operates on a single individual\nby altering a random subtree. Next, we briefly describe the\nGP initialization and the GP operators (selection, crossover,\nand mutation) used in this paper.\nA. The GP Initialization\nThe individuals in the GP population are initialized by\nrecursively generating syntax trees composed of randomly\nchosen function and terminal nodes. The two established\nGP initialization methods are the grow and the full method.\nBoth methods require from the user to specify the maximum\ninitial tree depth. According to the grow method, nodes\nare selected randomly from the function and the terminal\nsets. The grow method, therefore, produces trees of irregular\nshape, since once a terminal node is inserted the path ending\nwith this node cannot be extended, even if the maximum\ninitial depth has not been reached. On the other hand, in the\nfull initialization method only function nodes are selected\nuntil the maximum initial depth is reached. Beyond that depth\nonly terminal nodes are chosen to end the branches. This\nmethod results in a balanced tree, every branch of which\nreaches the maximum initial depth.\nThe ramped half and half initialization method [9] em-\nploys both grow and full to construct a GP population.\nSpecifically, ramped half and half aims at initializing an equal\nnumber of GP individuals with maximum depth starting from\nthe minimum depth of two up to the maximum initialization\ndepth. For each depth level half the individuals are con-\nstructed using the grow, while the remaining individuals are\nconstructed using the full initialization method. To obtain\npromising candidate solutions for the evolutionary process\nit has been proposed to initialize a much larger population\n(by a factor of ten) and to select the best performing\nindividuals [9].\nB. The GP Selection Algorithm\nTo derive the individuals that will comprise the population\nof the next generation, GP initially selects individuals from\nthe current generation. The selection operators that have been\nproposed for genetic algorithms are also applicable to GP. In\nthis study, we employed the most commonly encountered\none, namely proportionate selection. We define as Ei the\nfitness of the i-th individual, where E is the function we\nwish to maximize. Then the probability of selecting the i-th\nindividual as a parent of an individual of the next generation\n(offspring) is equal to pi = Ei\/\n\u2211N\nj=1 Ej .\nC. The GP Crossover Operator\nThe primary GP search operator is crossover. Crossover\noperates on two parent individuals and yields two offsprings.\nStandard crossover randomly selects a node in each parent\ntree and then swaps the subtrees rooted at these nodes [9].\nKoza suggests to use a 90% probability of selecting as\ncrossover point a function node and to select a terminal node\nwith probability 10%. If an offspring exceeds the maximum\ndepth it is discarded and the corresponding parent individual\ntakes its place in the population of the next generation.\nStandard crossover, however, tends to produce offsprings\nthat frequently inherit most of their code from one par-\nent, and also favors local adjustments near the leaves of\nsyntax trees [11]. To overcome these limitations, Poli and\nLangdon [11] proposed the uniform crossover operator for\nGP (GPUX) inspired from the homonymous operator in GAs.\nGPUX starts by identifying a tree that represents the common\nregion between two syntax trees. Each node that lies in the\ncommon region is considered for crossover with a constant\nprobability. For nodes that lie in the interior of the common\nregion GPUX swaps the nodes without affecting the subtrees\nrooted at these nodes. On the contrary, for nodes on the\nboundary of the common region the subtrees rooted at these\nnodes are swapped.\nSince the diversity of the GP individuals is high during the\nearly stages of the algorithm, the common region between\nrandomly selected individuals tends to be relatively small\nand hence GPUX favors the global exploration of the search\nspace by swapping large subtrees near the root of the syntax\ntrees. As the population converges the operator becomes\nmore and more local, in the sense that the offsprings it\nproduces are progressively more similar to their parents. An\nexample of GPUX is provided in Fig. 1.\n>\n+\n>\n\/\nsin\ncos\n> cos\n>\nsin\n\/\n+\ncommon region\noffspring 2offspring 1\nparent 1 parent 2\nX2 X3\nif\nX3 X2\nX0 X0\n\u2212\nX0 X3 X2\n+\n1.5\nX3\nX2 X3\nif\nX2\n\u2212\nX2\n+\nX0\nX0 X3\nX01.5\nFig. 1. Uniform crossover operator for GP (GPUX).\nD. The GP Mutation Operator\nThe mutation operator in GP randomly selects a node of\nthe syntax tree and replaces the subtree rooted at the selected\nnode with a newly created tree. This type of mutation is\nknown as subtree mutation. For the creation of the trees\nemployed by the mutation operator, the grow initialization\nmethod is employed [9]. Fig. 2 illustrates the workings of\nmutation on a GP individual.\n>\nsin\n\/\nsin\n\/ >\n>\nX0\nX0 X3\n1.5\n+\nX0 X3\nX2 X3\nX3 X2\nif\nFig. 2. Subtree mutation.\nIII. DIFFERENTIAL EVOLUTION\nDifferential Evolution [8] is a stochastic parallel di-\nrect search method, capable of handling non-differentiable,\nnonlinear and multimodal objective functions. DE is a\npopulation\u2013based stochastic algorithm that exploits a popula-\ntion of potential solutions (individuals), to explore the search\nspace. The population of individuals is randomly initialized\nin the optimization domain with NP, n\u2013dimensional, vectors\nfollowing a uniform probability distribution. The population\nsize, NP, is fixed throughout the execution of the algorithm.\nAt each iteration, called generation, new vectors are\nderived by the combination of randomly chosen vectors\nfrom the current population. This operation is referred to as\nmutation and produces the mutant individuals. Each mutant\nindividual is then mixed with another, predetermined, vector\n\u2013 the target vector \u2013 through an operation called recombina-\ntion. This operation yields the trial vector. Finally, the trial\nvector undergoes the selection operator, according to which\nit is accepted as a member of the population of the next\ngeneration only if it yields a reduction in the value of the\nobjective function f relative to that of the target vector. Next\nwe briefly review the basic DE variation operators.\nA. DE Variation Operators\nThe DE search operators efficiently shuffle information\namong the individuals, enabling the search for an optimum\nto focus on the most promising regions of the solution space.\nThe first operator considered here is mutation. Specifically,\nfor each individual xig , i = 1, . . . ,NP, where g denotes the\ncurrent generation, a new individual vig (mutant individual)\nis generated according to the following equation:\nvig = x\nbest\ng + F (x\nr1\ng \u2212 x\nr2\ng ), (1)\nwhere xbestg is the best member of the previous generation;\nF > 0 is a real parameter, called mutation constant, which\ncontrols the amplification of the difference between two\nindividuals, and is used to prevent the stagnation of the search\nprocess; and r1, r2 \u2208 {1, 2, . . . , i\u2212 1, i+ 1, . . . ,NP}, are\nrandom integers mutually different and not equal to the\nrunning index i. Although there exist many different mutation\noperators [12], [13], we chose to use the one described above\nsince it is simple and has the property of fast convergence.\nHaving performed mutation, the recombination operator is\napplied to further increase the diversity of the population. The\nmutant individuals are combined with other predetermined\nindividuals, called the target individuals. Specifically, for\neach component l (l = 1, 2, . . . , n) of the mutant individual\nvig , we randomly choose a real number r in the interval\n[0, 1]. Then, we compare this number with the recombination\nconstant, CR. If r 6 CR, then we select, as the l-th\ncomponent of the trial individual uig, the l-th component of\nthe mutant individual vig . Otherwise, the l-th component of\nthe target vector xig becomes the l-th component of the trial\nvector. This operation yields the trial individual.\nFinally, the trial individual is accepted for the next gen-\neration only if it reduces the value of the objective function\n(selection operator).\nIV. GENERALIZED MOVING AVERAGE RULES\nThe simplest and most common trading rules employ\nmoving averages (MAs). An MA of length \u03b8 is defined as:\nMA(\u03b8)t =\n1\n\u03b8\n\u03b8\u22121\u2211\ni=0\nPt\u2212i, t = \u03b8, \u03b8 + 1, . . . , N.\nThe Generalized MA (GMA) rule can be represented by the\nfollowing binary indicator function [7]:\nS(\u0398)t =MA(\u03b81)t \u2212 (1 + (1\u2212 2St\u22121)\u03b83)MA(\u03b82), (2)\nwhere \u0398 = [\u03b81, \u03b82, \u03b83] are the parameters of the GMA. The\nGMA rule returns a buy signal (which is encoded as one),\nwhen Eq. (2) returns a positive number. A sell signal, on the\nother hand, corresponds to a non-positive return value and is\nencoded as zero. Typically, \u03b81 < \u03b82 and MA(\u03b81)t is called\nthe short MA, while MA(\u03b82)t is the long MA. With this\nparameter setting the GMA rule identifies an upward trend\nwhen the short MA crosses from below the long MA, and\nvice versa. Finally, \u03b83 is a parameter introduced to reduce\nthe number of false buy and sell signals.\nFerna\u00b4ndez-Rodr\u0131\u00b4guez et al. [7] employed Genetic Algo-\nrithms to determine the optimal parameter values (\u0398) for\nGMA rules. They applied applied their approach to the\nMadrid stock market. Their findings indicate that with the\nexception of zero transactions costs, the best rules are of the\nform of double MA rules. In other words, \u03b81 > 0, \u03b82 > 0,\nand \u03b83 = 0. Moreover, the annualized returns, as well as,\nthe Sharpe ratio corresponding to the best GMA rules are\nhigher than those from the corresponding risk\u2013adjusted buy\nand hold strategy. In this paper, we employ the Differential\nEvolution algorithm described above to compute and tune\nthe parameters of GMA rules.\nV. RISK SENSITIVE PERFORMANCE MEASURES\nA critical aspect for the identification of promising trading\nstrategies through Computational Intelligence techniques is\nthe performance evaluation measure. To evaluate the perfor-\nmance of an investment strategy it is necessary to measure\nnot only the increase in capital but also the risk incurred. The\nfirst performance measure to incorporate risk is the widely\u2013\nknown Sharpe ratio [14]. The Sharpe ratio is defined as:\nSI = A\u2206t\nr\u00af\u221a\n\u03c32r\n,\nwhere r\u00af is the average return, \u03c32r is the variance of the return\nseries, and A\u2206t is an annualization factor that depends on the\nfrequency at which returns are measured. Three drawbacks\nhave been associated with the Sharpe ratio [6]. Firstly, the\nvariance term is placed in the denominator, which makes\nthe ratio numerically unstable when \u03c32r is close to zero.\nSecondly, the returns are measured at one frequency, and\nhence the measure neglects the risk due to unrealized losses\nat other frequencies. Finally, the Sharpe ratio neglects the\nclustering of losses and profits.\nTo this end, Genc\u00b8ay et al. [6] have proposed two risk\nadjusted performance measures, Xeff and Reff , that rely\non the expected utility framework. The first measure, Xeff ,\nis derived from a constant risk aversion utility function\nof the form, u(x) = \u2212 exp(\u2212\u03b3x), with \u03b3 representing\nthe coefficient of risk aversion, and x denoting the wealth\nreached by unit investment. Thus:\nx(t) = R\u02dc(t)\u2212 R\u02dc(t\u2212\u2206t),\nwhere R\u02dc(t) = R(t) + ro(t), R(t) is the total return of past\ntrades up to time t, and ro(t) is the unrealized return of the\ncurrent trading model position. Assuming that x follows the\nnormal distribution with N (x\u00af, \u03c32), the expected utility is:\nE[u(x)] = \u2212 exp(\u2212\u03b3(x\u00af\u2212\n\u03b3\u03c32\n2\n)).\nThe measure, Xeff is obtained by inverting the expected\nutility:\nXeff = x\u00af\u2212\n\u03b3\u03c32\n2\n.\nTo permit the comparison between Xeff values for differ-\nent \u2206t the measure is annualized:\nXeff,ann =\n1year\n\u2206t\n(\nx\u00af\u2212\n\u03b3\u03c32\n2\n)\n. (3)\nThe measure in Eq. (3) still depends on the choice of \u2206t\nand does not reflect changes occurring at shorter and longer\nhorizons. The final form of Xeff , therefore, constitutes a\nweighted average of Xeff,ann for n different time horizons:\nXeff =\n\u2211n\ni=1 wiXeff,ann(\u2206ti)\u2211n\ni=1 wi\n. (4)\nThe weights, wi, in Eq. (4) are obtained through the follow-\ning formula:\nw(\u2206t) =\n1\n2 +\n(\nlog\n(\n\u2206t\n90days\n))2 . (5)\nThe Xeff measure of Eq. (4) is obtained assuming a constant\nrisk aversion. A more realistic assumption is that investors\nare more risk averse to the clustering of losses than they are\nto the clustering of profits. The Reff algorithm introduces\ntwo levels of risk aversion:\n\u03c1 =\n{\n\u03c1+, if \u2206R\u02dc > 0\n\u03c1\n\u2212\n, if \u2206R\u02dc < 0\n,\nwhere \u03c1\n\u2212\n> \u03c1+. The corresponding utility function is:\nu(\u2206R\u02dc) =\n\uf8f1\uf8f2\n\uf8f3\n\u2212\nexp(\u2212\u03c1+\u2206R\u02dc)\n\u03c1+\n, for \u2206R\u02dc > 0\n1\n\u03c1\n\u2212\n\u2212 1\n\u03c1+\n\u2212\nexp(\u2212\u03c1\u2212\u2206R\u02dc)\n\u03c1\n\u2212\n, for \u2206R\u02dc < 0\n.\nThe return can be obtained by inverting the utility function:\n\u2206R\u02dc =\n\uf8f1\uf8f2\n\uf8f3\n\u2212 log(\u2212\u03c1+u)\n\u03c1+\n, for u > \u2212 1\n\u03c1+\n\u2212\nlog\n\u201c\n1\u2212\n\u03c1\n\u2212\n\u03c1+\n\u2212\u03c1\n\u2212\nu\n\u201d\n\u03c1\n\u2212\n, for u < \u2212 1\n\u03c1+\n. (6)\nThe computation of the utility for one time horizon \u2206tj\nis calculated using returns, \u2206R\u02dcji, observed at different and\npotentially overlapping time intervals, \u2206tji. The mean utility\nfor \u2206tj is:\nuj =\n\u2211Nj\ni=1\u2206tjiu\n(\n\u2206R\u02dcji\n)\n\u2211Nj\ni=1\u2206tji\n=\n\u2211Nj\ni=1\u2206tjiuji\u2211Nj\ni=1\u2206tji\n. (7)\nThe mean utility of Eq. (7) can be transformed back to an\neffective return for the horizon \u2206tj , \u2206R\u02dceff,j, using Eq. (6).\nThus, the annualized \u2206R\u02dceff,j is defined as:\nReff,j =\n1year\n\u2206teff,j\n\u2206R\u02dceff,j,\nwhere \u2206teff,j =\n\u2211Nj\ni=1(\u2206tji)\n2\/\n\u2211Nj\ni=1\u2206tji. The multihori-\nzon version of Reff is as before obtained by taking a weighted\naverage of Reff,j for different time horizons:\nReff =\n\u2211n\nj=1 wjReff,j\u2211n\nj=1 wj\n,\nwith the weights, wj being determined through Eq. (5).\nVI. SIMULATION METHODOLOGY\nSimulating exchange rate return series from a Data Gen-\nerating Process (DGP), transforming them into prices and\nfeeding them into a trading model permits us to calculate\nthe probability distributions of different performance mea-\nsures [6], [15]. In turn, we can test the null hypothesis\nthat the performance of a trading rule can be attributed to\nstandard statistical properties of exchange rate series against\nthe alternative that the observed performance is due to the\ncapability of the rule in detecting patterns that are not in\naccordance with traditional DGPs. Further, comparisons can\nbe made across rules and DGPs.\nWe employ three null processes. For the first process we\nassume that prices follow a Random Walk (RW) with a\ndrift. Consequently, log returns are generated according to\nthe following equation\nrt = \u03c60 + et, (8)\nwhere \u03c60 is the sample mean, and et \u223c N (0, \u03c32). The\nsimulated series for the RW model are obtained by adding\nnormally distributed random numbers (with mean zero and\nstandard deviation equal to the sample standard deviation\nof the residuals) to the returns mean. The artificial returns\nare independent and identically distributed by construction,\nwhile the simulated price series follow a random walk with\nthe same drift and standard deviation as the original series.\nThe artificial return series are transformed into price series\nby using the first price of the sample. However, according\nto the RW model the volatility of returns is constant which\ncontrasts with the stylized fact that the foreign exchange\nmarket is characterized by time varying volatility [16]. The\npresence of serial correlation in the second moment of the\ndistribution of the exchange rate series motivates the use of\nGARCH models. GARCH models are nonlinear condition-\nally Gaussian models where the conditional variance depends\non its lagged values, as well as, on past error terms. The\nGARCH(1,1) may be written as:\nrt = \u03c60 + ut, (9)\nut = et\n\u221a\nht, where et \u223c N (0, 1),\nht = \u03c9 + \u03b1u\n2\nt\u22121 + \u03b2ht\u22121.\nThe parameter values of the GARCH(1,1) model are esti-\nmated by using a Quasi Maximum Likelihood procedure and\nthe simulated series are generated by drawing values from\nthe standard normal distribution and calculating recursively\nEq. (9). Finally, we employ an ARMA(2,1)\u2013GARCH(1,1)\nmodel so as to take into account possible serial correlation\nin both the mean and the variance:\nrt = \u03c60 + \u03c61rt\u22121 + \u03c62rt\u22122 + \u03b81ut\u22121 + ut,\nut = et\n\u221a\nht, where et \u223c N (0, 1),\nht = \u03c9 + \u03b1u\n2\nt\u22121 + \u03b2ht\u22121.\nThe same procedure as for the GARCH model is applied in\norder to simulate data.\nTable I presents descriptive statistics for the real re-\nturn series, as well as, the GARCH(1,1) and ARMA(2,1)\u2013\nGARCH(1,1) models. The p-values are reported in paren-\ntheses next to the estimate of each coefficient. For\nGARCH(1,1) and ARMA(2,1)\u2013GARCH(1,1) models the p-\nvalues were calculated using the procedure of Bolleslev and\nWooldridge [17]. A clear implication of the results is that\nboth volatility clustering and the ARMA structure are present\nin the data set. The kurtosis reported in the first column of\nTable I shows that the return series is highly leptokurtic.\nThis phenomenon was first documented by Mandelbrot [18]\nin commodity markets and it implies that the normality\nassumption is violated1. Further, the standardized residuals\nfrom the GARCH and ARMA\u2013GARCH models also appear\nto exhibit more density around the mean and fatter tails\nthan normal. It follows that a better approximation of the\ntrue DGP can be established by relaxing the normality\nassumption.\nTABLE I\nDESCRIPTIVE STATISTICS\nModel RW GARCH ARMA\u2013GARCH\n\u03c60 7.71e-05 (0.5859) 6.25e-05(0.6595) 8.79e-05 (0.5149)\n\u03c61 \u2013 \u2013 -0.96561 (0.0000)\n\u03c62 \u2013 \u2013 -0.04164 (0.0820)\n\u03b81 \u2013 \u2013 0.93178 (0.0000)\n\u03c9 \u2013 5.89e-07 (0.0295) 1.50e-06 (0.0054)\n\u03b1 \u2013 0.00996 (0.1020) 0.01584 (0.0765)\n\u03b2 \u2013 0.97263 (0.0000) 0.94184 (0.0000)\nKe -0.3107 -0.3303 -0.3270\nSe 4.5849 4.5561 4.7164\nJBe 212.1939 209.2158 246.7241\npJB 0 0 0\nBootstrapping is a widely used methodology for testing\nthe statistical significance of the performance of trading\n1The p-values corresponding to the Jarque Bera test statistic are virtually\nzero in all cases, rejecting the null hypothesis of normality\nmodels. The non-parametric procedure adopted is called re-\nsampling [19]. Resampling is in effect drawing with replace-\nment from the sample under examination. The suitability\nof this approach in the present context is due to the fact\nthat it utilizes the empirical distribution function of the data\nand therefore, it addresses issues such as leptokurtosis and\nskewness. Artificial price series are created by bootstrapping\nfrom the residuals of the RW and the standardized residuals\nof the GARCH and ARMA\u2013GARCH in order to calculate the\nprobability distributions of the performance measures under\nexamination.\nVII. PRESENTATION OF EXPERIMENTAL RESULTS\nThe dataset presently employed is the daily noon New\nYork buying rates for the US Dollar against the Japanese\nYen exchange rate from the H10 Federal Statistical Release.\nThe 5292 observations cover the period from 3\/1\/1985 to\n2\/1\/2007. In addition to the price series, a normalized series\nis also provided as input to the algorithm. The normalized\nseries is constructed by dividing each observation with the\n250-day moving average [15]. Each input pattern contains the\ncurrent price and the normalized price, while the algorithm\ncan access past prices using the non-terminal node lag. The\nmaximum lag that the algorithm is allowed to consider is 250.\nThe first 3014 patterns were assigned to the training set, the\nnext 502 patterns are assigned to the validation set, while\nthe last 1508 patterns comprised the test set. The inclusion\nof a validation set was used to alleviate the problem of\noverfitting. The fitness of an individual on the validation set\nwas only used during the assignment of the best individual\nidentified during the execution. For both GMA and GP, a\nrule was assigned as the best identified so far if it was at\nleast as good as the current best on both the training and\nthe validation set, and it improved on the performance on at\nleast one dataset (Pareto domination).\nFor GP, the terminal set, T , consisted of:\nT = {Xnt , Xt, rand},\nwhere Xnt stands for the normalized exchange rate at date t,\nXt is the non-normalized rate, and rand denotes a random\nreal constant in the interval [-1,1]. The function set, F ,\ncontained the following functions:\n\u2022 Ternary functions: if then else\n\u2022 Binary functions: +,\u2212, \u2217, \/, >,<, and, or,\nmin,max,ma, lag,\n\u2022 Unary functions: log, exp,\nwhere ma and lag denote the moving average and the lag\nof the values of the time series.\nA positive evaluation of an individual over a pattern is\nassumed to signal that the current holdings should be held\nin the base currency (in this case US Dollars), and vice versa.\nIn particular, if the system at date t, holds US Dollars and\nthe evaluation of the individual over the corresponding input\npattern is positive then all the available funds are converted\nto Yen. On the contrary, if the system holds Yen and the\nindividual evaluation is non-positive, then the amount is\nconverted to US Dollars. In all other cases, the holdings do\nnot change currency at date t.\nThe last observation of the series is always employed to\nconvert the final holdings to the base currency. A one-way\ntransaction cost equal to 0.5% and 0.125% for the training,\nand test periods, respectively, was used. A larger transactions\ncost was imposed during training to penalize rules that trade\nvery frequently. The fitness function returns the Xeff measure\nwith the parameter \u03b3 in Eq. (4) set to \u03b3 = 0.11.\nRegarding the parameters employed by the GP algorithm,\nthe maximum tree depth, D, at initialization was set to 5,\nwhile in subsequent generationsD was equal to 8. Population\nsize was 100 and the maximum number of generations was\n200. The reproduction, mutation, and crossover probabilities\nwere 0.05, 0.5, and 0.45, respectively. Finally, the probability\nof performing uniform crossover at each node of the common\nregion was 0.5. The stopping criterion for the algorithm was\nto reach the maximum number of generations. To optimize\nthe values of the constant nodes in all the GP individuals the\nHooke\u2013Jeeves [20] procedure was applied. The GP output\nwas the best individual encountered during its execution.\nRegarding the parameters employed by the DE algorithm,\nthe population size was equal to 200 and the maximum num-\nber of generation to 2000; the mutation and recombination\nconstants were set to F = 0.1 and CR = 0.3, respectively.\nTables II and III report the minimum (min), mean, maxi-\nmum (max), and the standard deviation (std) for the number\nof trades, the mean annualized return, Xeff , and Reff , of\nthe GMA rules identified through DE over 50 experiments.\nFigs. 3 and 4 illustrate the cumulated return of the best\nperforming (on the test set) GMA rule on the training and\ntest set, respectively. In each figure the evolution of the time\nseries on the corresponding data set is also plotted. In 32\ncases out of the fifty experiments the DE optimized GMA\nrule was unable to identify a trading strategy that improved\nover the simple strategy of holding the base currency over\nthe entire period. For these rules the variance of the return\nseries is zero and hence the computation of the mean and\nthe standard deviation for the Sharpe ratio is performed\nwithout taking into consideration these cases. Excluding\nthese no trade strategies, the remaining MA rules performed\nsubstantially more trades than the corresponding GP rules.\nThe best performing GMA rule was of the double MA\nform (i.e. \u03b81 > 0, \u03b82 > \u03b81, and \u03b83 = 0).\nTables IV\u2013V provide the same information for the GP\nidentified trading rules over 50 experiments, while the cu-\nmulated return of the best performing rule on the test set is\nprovided in Figs. 5 and 6.\nTABLE II\nDE\u2013GMA TRAINING SET PERFORMANCE\nmin mean max std\nnum trades: 0.000000 7.560000 38.000000 10.799017\nannualized ret: 0.000000 0.360000 3.284896 1.228251\nXeff : -0.032121 -0.006980 0.000000 0.010022\nReff : -0.042298 -0.010640 0.000000 0.014626\nSharpe Ratio: 0.071835 0.288762 0.388624 0.080077\nTABLE III\nDE\u2013GMA TEST SET PERFORMANCE\nmin mean max std\nnum trades: 0.000000 5.120000 24.000000 7.241152\nannualized ret: -0.597215 0.360000 1.812633 0.562487\nXeff : -0.035841 -0.007994 0.000116 0.013372\nReff : -0.038477 -0.008895 0.000000 0.014521\nSharpe Ratio: -0.088653 0.076804 0.297369 0.139295\n 80\n 100\n 120\n 140\n 160\n 180\n 200\n 220\n 0  200  400  600  800  1000  1200  1400  1600  1800  2000  2200  2400  2600  2800  3000  3200  3400\nYen\/Dollar Time Series\n-20\n 0\n 20\n 40\n 60\n 80\n 100\n 120\n 0  200  400  600  800  1000  1200  1400  1600  1800  2000  2200  2400  2600  2800  3000  3200\nPe\nrc\nen\nta\nge\nCumulated Return\nFig. 3. Top: Cumulated return of best performing rule on the training set.\nBottom: Evolution of time series on the training set.\n 100\n 105\n 110\n 115\n 120\n 125\n 130\n 135\n 0  200  400  600  800  1000  1200  1400  1600  1800\nYen\/Dollar Time Series\n-5\n 0\n 5\n 10\n 15\n 20\n 25\n 0  200  400  600  800  1000  1200  1400  1600\nPe\nrc\nen\nta\nge\nCumulated Return\nFig. 4. Top: Cumulated return of best performing rule on the test set.\nBottom: Evolution of time series on the test set.\nTABLE IV\nGP TRADING RULE PERFORMANCE ON THE TRAINING SET\nmin mean max std\nnum trades: 6.000000 14.100000 36.000000 7.163230\nannualized ret: 2.021642 1.000000 5.848466 1.009530\nXeff : 0.013441 0.020439 0.030558 0.004680\nReff : 0.015576 0.023328 0.036446 0.005235\nSharpe Ratio: 0.590329 0.785202 0.963684 0.089573\nTables VI and VII present the results for the simulation\nexercise for the best GP and GMA rules, respectively. For\neach of the four evaluation measures each table firstly reports\nthe realized values for the corresponding rule (Realized).\nTABLE V\nGP TRADING RULE PERFORMANCE ON THE TEST SET\nTest Set: min mean max std\ntrades: 0.00000 8.933333 32.000000 6.144769\nannualized ret: -1.633383 0.950000 2.669512 1.075628\nXeff : -0.037450 -0.018569 0.013903 0.011517\nReff : -0.048849 -0.021780 0.015108 0.013432\nSharpe Ratio: -0.451822 -0.118973 0.513813 0.242092\n 80\n 100\n 120\n 140\n 160\n 180\n 200\n 220\n 0  500  1000  1500  2000  2500  3000  3500\nYen\/Dollar Time Series\n-10\n 0\n 10\n 20\n 30\n 40\n 50\n 60\n 70\n 0  500  1000  1500  2000  2500  3000  3500\nCumulated Return\nFig. 5. Top: Cumulated return of best GP rule on the training set. Bottom:\nEvolution of time series on the training set.\nThe various p-values corresponding to the different null\nmodels for both the bootstrap and the simulation based on\nthe normality assumption are reported in the subsequent\nrows of the tables. These values are calculated using 1000\nsimulations from each DGP and are defined as the percent-\nage of times that a rule yielded a higher value for each\nperformance measure on the artificial series than on the\nreal series. Overall, the performance of the GP rule on the\nactual test set exceeds that of the optimized GMA rule with\nrespect to all measures. For the GP rule, all measures are\npositive indicating that annualized returns after transactions\ncosts cover the cost of risk taken by the model. It is also\ninteresting to note that Xeff is smaller than Reff showing that\npenalizing the clustering of profits equally with the clustering\nof losses has caused an overestimation of risk for this rule.\nThe GMA rule also generates positive annualized returns\nafter transactions costs. However, Xeff is very close to zero\nand Reff is negative, suggesting that there is a significant\nclustering of losses (see Fig 4).\nThe results indicate that the performance of the GP rule\nis also superior in terms of statistical significance. The\nnull hypothesis that the examined DGPs can explain the\nperformance of the GP rule is rejected at the five percent\nsignificance level for all measures. On the contrary the same\nnull hypothesis for the GMA rule is not rejected for any\nmeasure. The examination of the p-values of the various\nperformance measures reveals that they are higher for the\nSharpe Ratio, SI , and the annualized return for all DGPs\nfor both models. As indicated in [6] an explanation for this\nfinding is that these two measures use limited information\n 100\n 105\n 110\n 115\n 120\n 125\n 130\n 135\n 0  200  400  600  800  1000  1200  1400  1600  1800\nYen\/Dollar Time Series\n-5\n 0\n 5\n 10\n 15\n 20\n 25\n 30\n 0  200  400  600  800  1000  1200  1400  1600\nCumulated Return\nFig. 6. Top: Cumulated return of best GP rule on the test set. Bottom:\nEvolution of time series on the test set.\nfrom the entire return path.\nThe fact that the p-value of the Bootstrap ARMA\u2013GARCH\nDGP is the higher for the GP rule suggests that part of\nthe models predictability can be attributed to the ARMA\u2013\nGARCH structure of the underlying series. Finally, it is\nnoted that the normality assumption results in rejecting the\nnull hypothesis much more frequently than the bootstrap,\nespecially for the GP rule.\nTABLE VI\nBEST GP RULE PERFORMANCE\nAnnual Return Xeff Reff SI\nRealized 2.6695 1.3903 1.5108 0.5138\nBootstrap\np RW 0.04 0.026 0.026 0.046\np GARCH 0.031 0.028 0.022 0.039\np ARMA\u2013GARCH 0.045 0.035 0.036 0.037\nNormal\np RW 0.032 0.025 0.023 0.036\np GARCH 0.026 0.02 0.017 0.03\np ARMA\u2013GARCH 0.035 0.027 0.024 0.034\nTABLE VII\nBEST GMA RULE PERFORMANCE\nAnnual Return Xeff Reff SI\nRealized 1.8126 0.0116 -0.1188 0.2974\nBootstrap\np RW 0.124 0.074 0.07 0.112\np GARCH 0.117 0.079 0.061 0.106\np ARMA\u2013GARCH 0.13 0.075 0.069 0.107\nNormal\np RW 0.099 0.058 0.052 0.087\np GARCH 0.100 0.061 0.056 0.087\np ARMA\u2013GARCH 0.124 0.081 0.067 0.098\nVIII. CONCLUSIONS\nTechnical analysis has a long history in financial mar-\nkets and its application in the foreign exchange market\nis gaining ground according to the evidence accumulated\nover the past years. Along with conventional trading rules\nthere is a growing interest in the development of automated\nmethods to detect novel patterns in the data. In this paper,\nwe considered Genetic Programming to address this task\nand compared its performance to traditional moving average\nrules. The parameters of the latter were optimized through\nthe Differential Evolution algorithm.\nBoth algorithms were capable of generating highly prof-\nitable rules in the portion of the data used for training.\nOn the test set, the moving average rules proved to be\nmore robust compared to the Genetic Programming rules.\nHowever, Genetic Programming managed to create the most\nprofitable rule encountered. Moreover, a statistical evaluation\nof the properties of the best moving average rule showed\nthat the null hypothesis that its performance is attributable to\nwell\u2013known properties of the data\u2013generating process cannot\nbe rejected. The opposite held for the GP identified rule.\nAnother interesting feature of these rules was their ability to\ntake accurate positions long into the future.\nREFERENCES\n[1] R. Sullivan, A. Timmermann, and H. White, \u201cData-snooping, technical\ntrading rule performance, and the bootstrap,\u201d Journal of Finance,\nvol. 54, no. 5, pp. 1647\u20131691, 1999.\n[2] Y.-W. Cheung and M. D. Chinn, \u201cCurrency traders and exchange rate\ndynamics: a survey of the us market,\u201d Journal of International Money\nand Finance, vol. 20, no. 4, pp. 439\u2013471, 2001.\n[3] B. L. Baron, \u201cTechnical trading rule profitability and foreign exchange\nintervention,\u201d Journal of International Economics, vol. 49, no. 1, pp.\n125\u2013143, 1999.\n[4] P. D. Grauwe and M. Grimaldi, \u201cExchange rate puzzles. a tale of\nswitching attractors,\u201d European Economic Review, vol. 50, no. 1, pp.\n1\u201333, 2006.\n[5] D. Olson, \u201cHave trading rule profits in the currency market declined\nover time?\u201d Journal of Banking and Finance, vol. 28, no. 4, pp. 85\u2013\n105, 2004.\n[6] R. Genc\u00b8ay, M. Dacorogna, U. Mu\u00a8ller, and O. Pictet, \u201cEffective retrun,\nrisk aversion and drawdowns,\u201d Physica A, vol. 289, no. 1\u20132, pp. 229\u2013\n248, 2001.\n[7] F. Ferna\u00b4ndez-Rodr\u0131\u00b4guez, C. Gonza\u00b4lez-Martel, and S. Sosvilla-Rivero,\n\u201cOptimization of technical rules by genetic algorithms: evidence from\nthe madrid stock market,\u201d Applied Financial Economics, vol. 15, pp.\n773\u2013775, 2005.\n[8] R. Storn and K. Price, \u201cDifferential evolution \u2013 a simple and efficient\nadaptive scheme for global optimization over continuous spaces,\u201d\nJournal of Global Optimization, vol. 11, pp. 341\u2013359, 1997.\n[9] J. R. Koza, Genetic Programming: On the Programming of Computers\nby Means of Natural Selection. Cambridge, MA, USA: MIT Press,\n1992.\n[10] B. Wolfgang, P. Nordin, R. Keller, and F. Francone, Genetic pro-\ngramming: An Introduction: on the automatic evolution of computer\nprograms and its applications. San Francisco, CA, USA: Morgan\nKaufmann Publishers Inc., 1998.\n[11] R. Poli and W. B. Langdon, \u201cOn the search properties of different\ncrossover operators in genetic programming,\u201d in Genetic Programming\n1998: Proceedings of the Third Annual Conference, J. R. Koza,\nW. Banzhaf, K. Chellapilla, K. Deb, M. Dorigo, D. B. Fogel, M. H.\nGarzon, D. E. Goldberg, H. Iba, and R. Riolo, Eds., 1998, pp. 293\u2013\n301.\n[12] D. K. Tasoulis, N. G. Pavlidis, V. P. Plagianakos, and M. N. Vrahatis,\n\u201cParallel differential evolution,\u201d in IEEE Congress on Evolutionary\nComputation (CEC 2004), 2004.\n[13] D. Tasoulis, V. Plagianakos, and M. Vrahatis, \u201cClustering in evolution-\nary algorithms to efficiently compute simultaneously local and global\nminima,\u201d in IEEE Congress on Evolutionary Computation, vol. 2,\nEdinburgh, UK, 2005, pp. 1847\u20131854.\n[14] W. F. Sharpe, \u201cMutual fund performance,\u201d Journal of Business, vol. 39,\nno. 1, pp. 119\u2013138, 1966.\n[15] C. J. Neely, P. A. Weller, and R. Dittmar, \u201cIs technical analysis in the\nforeign exchange market profitable? a genetic programming approach,\u201d\nJournal of Financial and Quantitative Analysis, vol. 32, no. 4, pp.\n405\u2013426, 1997.\n[16] R. F. Engle, T. Ito, and W.-L. Lin, \u201cMeteor showers or heat waves?\nheteroskedastic intra-daily volatility in the foreign exchange market,\u201d\nEconometrica, vol. 58, pp. 525\u2013542, 1990.\n[17] T. Bollerslev and J. M. Wooldridge, \u201cQuasi\u2013maximum likelihood\nestimation and inference in dynamic models with time varying co-\nvariances,\u201d Econometric Reviews, vol. 11, pp. 143\u2013172, 1992.\n[18] B. Mandelbrot, \u201cThe variation of certain speculative prices,\u201d Journal\nof Business, vol. 36, pp. 394\u2013419, 1963.\n[19] B. Efron, The jackknife, the bootstrap and other resampling. SIAM,\nPhiladelphia, PA, 1982.\n[20] W. Press, S. Teukolsky, W. Vetterling, and B. Flannery, Numerical\nRecipes in Fortran 77. Cambridge University Press, 1992.\n"}
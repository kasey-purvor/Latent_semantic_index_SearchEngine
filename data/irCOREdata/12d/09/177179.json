{"doi":"10.1007\/11559221_23","coreId":"177179","oai":"oai:aura.abdn.ac.uk:2164\/750","identifiers":["oai:aura.abdn.ac.uk:2164\/750","10.1007\/11559221_23"],"title":"Arguing and negotiating in the presence of social influences","authors":["Karunatillake, N C","Jennings, N R","Rahwan, I","Norman, T J"],"enrichments":{"references":[{"id":3163,"title":"A dialogue game protocol for multi-agent argument over proposals for action. In:","authors":[],"date":"2004","doi":"10.1007\/s10458-005-1166-x","raw":"Atkinson, K., Bench-Capon, T., McBurney, P.: A dialogue game protocol for multi-agent argument over proposals for action. In: Argumentation in Multi-Agent Systems (Proc. of ArgMAS 2004). LNAI 3366, NY, USA, Springer-Verlag (2004) 149\u2013161","cites":null},{"id":3169,"title":"A dialogue-game protocol for agent purchase negotiations.","authors":[],"date":"2003","doi":"10.1023\/A:1024787301515","raw":"McBurney, P., van Eijk, R., Parsons, S., Amgoud, L.: A dialogue-game protocol for agent purchase negotiations. Autonomous Agents and Multi-Agent Systems 7 (2003) 235\u2013273","cites":null},{"id":3166,"title":"A framework for argumentation-based negotiation. In:","authors":[],"date":"1998","doi":"10.1007\/bfb0026758","raw":null,"cites":null},{"id":3170,"title":"Agents\u2019 Con\ufb02icts: New Issues. In: Con\ufb02icting Agents Con\ufb02ict Management in Multi-Agent Systems.","authors":[],"date":"2000","doi":null,"raw":"Tessier, C., Chaudron, L., M\u00a8 uller, H.J., eds.: Agents\u2019 Con\ufb02icts: New Issues. In: Con\ufb02icting Agents Con\ufb02ict Management in Multi-Agent Systems. Kluwer Academic Publishers (2000) 1\u201330","cites":null},{"id":3167,"title":"Argument, dialogue and negotiation.","authors":[],"date":"2000","doi":"10.1017\/s0012217300006430","raw":"Amgoud, L., Parson, S., Maudet, N.: Argument, dialogue and negotiation. In Horn, W., ed.: Proc. of the 14 th European Conference on Arti\ufb01cial Intelligence (ECAI\u201900), Berlin (2000) 338\u2013342","cites":null},{"id":3164,"title":"Argumentation Schemes for Presumptive Reasoning.","authors":[],"date":"1996","doi":"10.1007\/s10503-011-9232-9","raw":"Walton, D.N.: Argumentation Schemes for Presumptive Reasoning. Erlbaum, Mahwah, NJ (1996)","cites":null},{"id":3159,"title":"Argumentation-based negotiation.","authors":[],"date":"2003","doi":"10.1017\/S0269888904000098","raw":"Rahwan, I., Ramchurn, S.D., Jennings, N.R., McBurney, P., Parsons, S., Sonenberg, L.: Argumentation-based negotiation. The Knowledge Engineering Review 18 (2003) 343\u2013375","cites":null},{"id":3161,"title":"Commitments: From individual intentions to groups and organizations. In:","authors":[],"date":"1995","doi":null,"raw":"Castelfranchi, C.: Commitments: From individual intentions to groups and organizations. In: Proc. of the 1 st Int. Conf. on Multi-agent Systems (ICMAS\u201995), San Francisco, CA (1995) 41\u201348","cites":null},{"id":3171,"title":"Communication, and Fallacies. Lawrence Erlbaum Associates, Inc,","authors":[],"date":"1992","doi":null,"raw":"Eemeren, F.H. van, Grootendorst, R.: Argumentation, Communication, and Fallacies. Lawrence Erlbaum Associates, Inc, Hillsdale NJ (1992)","cites":null},{"id":3172,"title":"E.C.W.: Commitment in Dialogue: Basic Concepts of Interpersonal Reasoning. State Univ. of NY","authors":[],"date":"1995","doi":null,"raw":"Walton, D.N., Krabbe, E.C.W.: Commitment in Dialogue: Basic Concepts of Interpersonal Reasoning. State Univ. of NY (1995)","cites":null},{"id":6015215,"title":"In:","authors":[],"date":"1998","doi":null,"raw":"Sierra,C.,Jennings,N.R.,Noriega,P.,Parsons,S.: Aframeworkforargumentation-basednegotiation. In: Proc. of 4 th Int. Workshop on Agent Theories Architectures and Languages (ATAL\u201997), Rhode Island , USA (1998) 167\u2013182","cites":null},{"id":3158,"title":"N.R.: Is it worth arguing? In:","authors":[],"date":"2004","doi":"10.1007\/978-3-540-32261-0_16","raw":"Karunatillake, N.C., Jennings, N.R.: Is it worth arguing? In: Argumentation in Multi-Agent Systems (Proc. of ArgMAS 2004). LNAI 3366, NY, USA, Springer-Verlag (2004) 234\u2013250","cites":null},{"id":3165,"title":"N.R.: Using similarity criteria to make trade-offs in automated negotiations.","authors":[],"date":"2002","doi":"10.1016\/S0004-3702(02)00290-4","raw":"Faratin, P., Sierra, C., Jennings, N.R.: Using similarity criteria to make trade-offs in automated negotiations. Arti\ufb01cial Intelligence 142 (2002) 205\u2013237","cites":null},{"id":3162,"title":"On social commitment, roles and preferred goals. In:","authors":[],"date":"1998","doi":"10.1109\/icmas.1998.699035","raw":"Cavedon, L., Sonenberg, L.: On social commitment, roles and preferred goals. In: Proc. of the 3 rd Int. Conf. on Multi-Agent Systems (ICMAS\u201998). (1998) 80\u201386","cites":null},{"id":3168,"title":"Question-begging in non-cumulative systems.","authors":[],"date":"1979","doi":"10.1007\/BF00258422","raw":"MacKenzie, J.: Question-begging in non-cumulative systems. Journal of philosophical logic 8 (1979) 117\u2013133","cites":null},{"id":3160,"title":"T.J.: Argument-based negotiation in a social context. In:","authors":[],"date":"2005","doi":"10.1145\/1082473.1082758","raw":"Karunatillake, N.C., Jennings, N.R., Rahwan, I., Norman, T.J.: Argument-based negotiation in a social context. In: Proc. of the 2 nd Int. Workshop on Argumentation in Multi-Agent Systems (ArgMAS\u201905), Utrecht, The Netherlands (2005) to appear","cites":null}],"documentType":{"type":1}},"contributors":["Pechoucek, Michael","Petta, Paolo","Varga, Laszlo Z.","University of Aberdeen, Natural & Computing Sciences, Computing Science"],"datePublished":"2005","abstract":"Postprin","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"Springer-Verlag","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:aura.abdn.ac.uk:2164\/750<\/identifier><datestamp>\n                2018-01-06T07:20:07Z<\/datestamp><setSpec>\n                com_2164_673<\/setSpec><setSpec>\n                com_2164_370<\/setSpec><setSpec>\n                com_2164_331<\/setSpec><setSpec>\n                com_2164_705<\/setSpec><setSpec>\n                col_2164_674<\/setSpec><setSpec>\n                col_2164_706<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nArguing and negotiating in the presence of social influences<\/dc:title><dc:creator>\nKarunatillake, N C<\/dc:creator><dc:creator>\nJennings, N R<\/dc:creator><dc:creator>\nRahwan, I<\/dc:creator><dc:creator>\nNorman, T J<\/dc:creator><dc:contributor>\nPechoucek, Michael<\/dc:contributor><dc:contributor>\nPetta, Paolo<\/dc:contributor><dc:contributor>\nVarga, Laszlo Z.<\/dc:contributor><dc:contributor>\nUniversity of Aberdeen, Natural & Computing Sciences, Computing Science<\/dc:contributor><dc:subject>\nargumentation-based negotiation<\/dc:subject><dc:subject>\nconflict resolution<\/dc:subject><dc:subject>\nQA76 Computer software<\/dc:subject><dc:subject>\nQA76<\/dc:subject><dc:description>\nPostprint<\/dc:description><dc:date>\n2010-09-17T15:11:09Z<\/dc:date><dc:date>\n2010-09-17T15:11:09Z<\/dc:date><dc:date>\n2005<\/dc:date><dc:type>\nBook item<\/dc:type><dc:identifier>\nKarunatillake , N C , Jennings , N R , Rahwan , I & Norman , T J 2005 , Arguing and negotiating in the presence of social influences . in M Pechoucek , P Petta & L Z Varga (eds) , Multi-Agent Systems and Applications IV : Proceedings of the Fourth International Central and Eastern European Conference on Multi-Agent Systems . Lecture Notes in Computer Science , vol. 3690 , Springer-Verlag , Berlin , pp. 223-235 . DOI: 10.1007\/11559221_23<\/dc:identifier><dc:identifier>\n354029046X<\/dc:identifier><dc:identifier>\nPURE: 1237654<\/dc:identifier><dc:identifier>\nPURE UUID: 582a966f-e284-4002-9c0b-7e3341f08025<\/dc:identifier><dc:identifier>\nWOS: 000233298100023<\/dc:identifier><dc:identifier>\nScopus: 33646164430<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2164\/750<\/dc:identifier><dc:identifier>\nhttp:\/\/dx.doi.org\/10.1007\/11559221_23<\/dc:identifier><dc:language>\neng<\/dc:language><dc:relation>\nMulti-Agent Systems and Applications IV<\/dc:relation><dc:relation>\nLecture Notes in Computer Science<\/dc:relation><dc:format>\n13<\/dc:format><dc:publisher>\nSpringer-Verlag<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["Multi-Agent Systems and Applications IV","Lecture Notes in Computer Science"],"year":2005,"topics":["argumentation-based negotiation","conflict resolution","QA76 Computer software","QA76"],"subject":["Book item"],"fullText":"Arguing and Negotiating in the Presence of Social Influences?\nNishan C. Karunatillake1, Nicholas R. Jennings1, Iyad Rahwan2, and Timothy J. Norman3\n1 School of Electronics and Computer Science, University of Southampton, Southampton, UK.\n{nnc02r,nrj}@ecs.soton.ac.uk\n2 Institute of Informatics, The British University in Dubai, P.O.Box 502216 Dubai, UAE.\n(Fellow) School of Informatics, University of Edinburgh, Edinburgh, UK.\nirahwan@acm.org\n3 Department of Computing Science, University of Aberdeen, Aberdeen, UK.\ntnorman@csd.abdn.ac.uk\nAbstract. When agents operate in a society with incomplete information and with di-\nverse and conflicting influences, they may, in certain instances, lack the knowledge, the\nmotivation and\/or the capacity to enact all their commitments. However, to function as a\ncoherent society it is important for these agents to have a means to resolve such conflicts\nand to come to a mutual understanding about their actions. To this end, argumentation-\nbased negotiation provides agents with an effective means to resolve conflicts within a\nmulti-agent society. However, to engage in such argumentative encounters, agents require\nfour fundamental capabilities; a schema to reason in a social context, a mechanism to iden-\ntify a suitable set of arguments, a language and a protocol to exchange these arguments,\nand a decision making functionality to generate such dialogues. This paper presents for-\nmulations of all of these capabilities and proposes a coherent framework that allows agents\nto argue, negotiate, and, thereby, resolve conflicts within a multi-agent society.\nKey words: Argumentation-based Negotiation, Conflict Resolution.\n1 Introduction\nAutonomous agents usually operate as a multi-agent community performing actions within a\nshared social context to achieve their individual and collective objectives. In such a social con-\ntext, their actions are influenced via two broad forms of motivations. First, the internal influ-\nences reflect the intrinsic motivations that drive the individual agent to achieve its own internal\nobjectives. Second, as agents reside and operate within a social community, the social context\nitself influences their actions. Here, we categorise these latter forms as social influences. Now,\nin many cases, both these forms of influence may be present and they may give conflicting mo-\ntivations to the individual agent. For instance, an agent may be internally motivated to perform a\nspecific action, whereas, at the same time, it may also be subject to an external social influence\nnot to perform it. Also an agent may face situations where different social influences motivate\nit in a contradictory fashion (one to perform a specific action and the other not to). Moreover,\nin many cases, agents have to carry out their actions in environments with incomplete infor-\nmation. Thus, for instance, they may not be aware of the existence of all the social influences\nthat could or indeed should affect their actions and they may also lack the knowledge of certain\nspecific internal influences that drive other agents\u2019 behaviours. Therefore, when agents operate\nin a society of incomplete information with such diverse and conflicting influences, they may,\nin certain instances, lack the knowledge, the motivation and\/or the capacity to abide by all their\nsocial influences.\nHowever, to function as a coherent society it is important for these agents to have a means\nto resolve such conflicts and to come to a mutual understanding about their actions. To this end,\n? The first author is a full time PhD student funded by EPSRC under the project Information Exchange\n(GR\/S03706\/01). The authors also extend their gratitude to Pietro Panzarasa, Chris Reed, and Xudong\nLuo for their thoughts, contributions, and discussions.\nArgumentation-Based Negotiation (ABN) has been advocated as a promising means of resolv-\ning conflicts within such agent societies [1, 2]. In more detail, ABN allows agents to exchange\nadditional meta-information such as justifications, critics, and other forms of persuasive locu-\ntions within their interactions. These, in turn, allow agents to gain a wider understanding of the\ninternal and social influences affecting their counterparts, thereby making it easier to resolve\ncertain conflicts that arise due to incomplete knowledge. Furthermore, the negotiation element\nwithin ABN also provides a means for the agents to achieve mutually acceptable agreements to\nthe conflicts of interests that they may have in relation to their different influences.\nNow, one of the central features required by an agent to engage in such arguments within\na society is the ability to generate valid arguments during the course of the dialogue. We be-\nlieve this demands four fundamental capabilities: (i) a schema to reason in social settings; (ii) a\nmechanism to identify a suitable set of arguments; (iii) a language and a protocol to exchange\nthese arguments; and (iv) a decision making functionality to generate such dialogues. This pa-\nper builds upon our previous conceptual grounding [3] and formulates a coherent framework\nthat addresses all four of these issues. More specifically, apart from formulating a coherent\nschema that captures social influence in multi-agent systems (see Section 2.1) and systemati-\ncally using it, in turn, to identify social arguments to resolve conflicts within an agent society\n(see Section 2.2), this paper presents three additional contributions. First, we construct a lan-\nguage that is capable of expressing such social arguments and, which allows agents to exchange\nthem within their argumentative dialogues (see Section 3.1). Second, we define a dialogue game\nprotocol identifying the different guidelines (such as locution rules, structural rules and commit-\nment rules) which will govern these dialogues and guide its participants toward resolving their\nconflicts. Finally, we define the different decision making algorithms required by the agents to\nengage in such argumentative dialogues to resolve conflicts about their social influences (see\nSection 3.2).\n2 Model for Arguing with Social Influences\nHere we outline our ABN model that provides agents with a means to argue, negotiate, and,\nthereby, resolve their conflicts in relation to social influences. We introduce our model in two\nstages; first detailing how social influences within a society can be captured into a schema, and\nsecond explaining the different ways that agents can use this schema to systematically capture\narguments to use within their ABN in a multi-agent community.\n2.1 Capturing Social Influence\nThe notion of social commitment acts as our basic building block for capturing social influ-\nences. First introduced by Castelfranchi [4], it is one of the fundamental approaches for mod-\nelling social behaviour among agents in multi-agent systems. In essence, a social commitment\n(SCx\u2192y\u03b8 ) is a commitment by one agent x (termed the debtor) to another y (termed the creditor)\nto perform a stipulated action \u03b8.1 Having defined such, Castelfranchi further explains the con-\nsequences of a social commitment for both the agents involved. In detail, a social commitment\nresults in the debtor attaining an obligation toward the creditor, to perform the stipulated action.\nThe creditor, in turn, attains certain rights. These include the right to demand or require the per-\nformance of the action, the right to question the non-performance of the action, and, in certain\ninstances, the right to make good any losses suffered due to its non-performance. We refer to\nthese rights the creditor gains as the rights to exert influence. This notion of social commitment\nresulting in an obligation and rights to exert influence, allows us a means to capture social in-\nfluences between two agents. Thus, when a certain agent is socially committed to another to\n1 In the desire to maintain simplicity within our schema, we avoid incorporating the witness (see [4]) in\nour model (as Castelfranchi did in his subsequent expositions).\nperform a specific action, it subjects itself to the social influences of the other to perform that\naction. The ensuing obligation, on one hand, allows us to capture how an agent gets subjected to\nthe social influence of another, whereas, the rights to exert influence, on the other hand, model\nhow an agent gains the ability to exert such social influence upon another. Thereby, the notion\nof social commitment gives an elegant mechanism to capture social influence resulting between\ntwo agents.\nGiven this basic building block for modelling social influence between specific pairs of\nagents, we now proceed to explain how this notion is extended to capture social influences re-\nsulting due to factors such as roles and relationships within a wider multi-agent society (i.e.,\nthose that rely on the structure of the society, rather than the specific individuals who happen to\nbe committed to one another). Specifically, since most relationships involve the related parties\ncarrying out certain actions for each other, we can view a relationship as an encapsulation of\nsocial commitments between the associated roles. To illustrate this, consider the relationship\nbetween the roles supervisor and student. For instance, assume the relationship socially influ-\nences the student to produce and hand over his thesis to the supervisor in a timely manner. This\ninfluence we can perceive as a social commitment that exists between the roles supervisor and\nstudent (the student is socially committed to the supervisor to perform the stipulated action).\nAs a consequence of this social commitment, the student attains an obligation toward the su-\npervisor to carry out this related action. On the other hand, the supervisor gains the right to\nexert influence on the student by either demanding that he does so or through questioning his\nnon-performance. In a similar manner, the supervisor may be influenced to review and com-\nment on the thesis. This again is another social commitment associated with the relationship.\nIn this instance, it subjects the supervisor to an obligation to review the thesis while the student\ngains the right to demand its performance. In this manner, social commitment again provides\nan effective means to capture the social influences emanating through roles and relationships of\nthe society (independently of the specific agents who take on the roles). Given this descriptive\ndefinition of our model, we now formulate these notions to capture the social influences within\nmulti-agent systems as a schema (refer to Figure 1 and formulae (1) through (6)):\nDefinition 1: For nA, nR, nP , n\u0398 \u2208 N+, let:\n\u2022 A = {a1, . . . , anA} denote a finite set of agents,\n\u2022 R = {r1, . . . , rnR} denote a finite set of roles,\n\u2022 P = {p1, . . . , pnP } denote a finite set of relationships,\n\u2022 \u0398 = {\u03b81, . . . , \u03b8n\u0398} denote a finite set of actions,\n\u2022 Act : A\u00d7R denote the fact that an agent is acting a role,\n\u2022 RoleOf : R\u00d7 P denote the fact that a role is related to a relationship, and\n\u2022 In : A\u00d7R\u00d7 P denote the fact that an agent acting a role is part of a relationship.\nIf an agent acts a certain role and that role is related to a specific relationship, then that agent acting that\nrole is said to be part of that relationship (as per Cavedon and Sonenberg [5]):\nAct(a, r) \u2227 RoleOf(r, p) \u2192 In(a, r, p) (Rel. Rule)\nDefinition 2: Let SC denote a finite set of social commitments and SCx\u2192y\u03b8 \u2208 SC. Thus, as per Castel-\nfranchi, SCx\u2192y\u03b8 will result in the debtor attaining an obligation toward the creditor to perform a stipulated\naction and the creditor, in turn, attaining the right to influence the performance of that action:\nSCx\u2192y\u03b8 \u2192 [Ox\u2192y\u03b8 ]fx \u2227 [Ry\u2192x\u03b8 ]y , (S-Com Rule)\nwhere:\n- [Ox\u2192y\u03b8 ]\nf\nx\nrepresents the obligation that x attains that subjects it to an influence of a degree f (refer\nto [3] for more details) toward y to perform \u03b8 and\n- [Ry\u2192x\u03b8 ]y represents the right that y attains which gives it the ability to demand, question, and require\nx regarding the performance of \u03b8.\nDefinition 3: Let:\n\u2022 DebtorOf : (R \u222aA)\u00d7 SC denote that a role (or an agent) is the debtor in a social commitment,\n\u2022 CreditorOf : (R \u222aA)\u00d7 SC denote that a role (or an agent) is the creditor in a social commitment,\n\u2022 ActionOf :\u0398 \u00d7 SC denote that an act is associated with a social commitment, and\n\u2022 AssocWith :SC \u00d7 P denote that a social commitment is associated with a relationship.\nAn agent ai acting the role ri\nLeads it to be part of the relationship p\nWith another agent aj acting the role rj\nA social commitment SCri\u2192rj\u03b8 associated with p\n\u2013 Leads to ai attaining an obligation O toward rj ,\nWhich subjects it to an influence of degree f\nTo perform the action \u03b8\n\u2013 And, in turn, leads to aj attaining the right R toward ri\nTo demand, question, and require the performance of action \u03b8\nFig. 1. Natural Language Representation of the Schema of Social Influence.\nIf the roles associated with the relationship are both the creditor and the debtor of a particular social com-\nmitment, then we declare that social commitment is associated with the relationship (as per Section 2.1).\nApplying the Rel. Rule to a society where: ai, aj \u2208 A\u2227 ri, rj \u2208 R \u2227 p \u2208 P s.t. Act(ai, ri), Act(aj , rj),\nRoleOf(ri, p), RoleOf(rj , p) hold true, we obtain:\nAct(ai, ri) \u2227 RoleOf(ri, p) \u2192 In(ai, ri, p) (1)\nAct(aj , rj) \u2227 RoleOf(rj , p) \u2192 In(aj , rj , p). (2)\nNow, consider a social commitment SCri\u2192rj\u03b8 associated with the relationship p in this society. Applying\nthis to Definition 3 we obtain:\n(DebtorOf(ri, SC) \u2227 RoleOf(ri, p)) \u2227 (CreditorOf(rj , SC) \u2227 RoleOf(rj , p))\n\u2227 ActionOf(\u03b8, SC) \u2192 AssocWith(SCri\u2192rj\u03b8 , p). (3)\nApplying the S-Comm rule to SCri\u2192rj\u03b8 we obtain:\nSCri\u2192rj\u03b8 \u2192\n\u02c6\nOri\u2192rj\u03b8\n\u02dcf\nri\n\u2227 \u02c6Rrj\u2192ri\u03b8 \u02dcrj . (4)\nCombining (4), (1) and (3) we obtain:\nIn(ai, ri, p) \u2227 AssocWith(SCri\u2192rj\u03b8 , p) \u2192\n\u02c6\nOai\u2192rj\u03b8\n\u02dcf\nai\n. (5)\nCombining (4), (2) and (3) we obtain:\nIn(aj , rj , p) \u2227 AssocWith(SCri\u2192rj\u03b8 , p) \u2192\n\u02c6\nRaj\u2192ri\u03b8\n\u02dc\naj\n. (6)\n2.2 Capturing Social Arguments\nHaving captured the notion of social influence into a schema, here we present how agents can\nuse it to systematically identify arguments to negotiate within a society. We term these argu-\nments social arguments, not only to emphasise their ability to resolve conflicts within a society,\nbut also to highlight the fact that they use the social influence present within the system as a\ncore means in changing decisions and outcomes within the society.2 Specifically, we have iden-\ntified two major ways in which social influence can be used to change decisions and outcomes\nand thereby resolve conflicts between agents (see Figure 2).\nSocially Influencing Decisions: One way to affect an agent\u2019s decisions is by arguing about\nthe validity of that agent\u2019s practical reasoning [6, 7]. Similarly, in a social context, an agent can\naffect another agent\u2019s decisions by arguing about the validity of the other\u2019s social reasoning. In\nmore detail, agents\u2019 decisions to perform (or not to perform) actions are based on their internal\nand\/or social influences. Thus, these influences formulate the justification (or the reason) be-\nhind their decisions. Therefore, agents can affect each other\u2019s decisions indirectly by affecting\nthe social influences that determine their decisions (see Figure 2(a)). Specifically, in the case\nof actions motivated via social influences through the roles and relationships of a structured\nsociety, this justification to act (or not to act) flows from the social influence schema (see Sec-\ntion 2.1). Given this, we can further classify the ways that agents can socially influence each\nother\u2019s decisions into two broad categories:\n2 Due to space restrictions here we present only a limited subset of social arguments. For a comprehensive\nlist of arguments, together with their formal representation, refer to [3].\nSocial\nInfluences\nSocial\nInfluences\nDecisionsDecisions\nNegotiate\nArgue about Influences\n(a) Socially Influencing Decisions\nSocial\nInfluences\nSocial\nInfluences\nDecisions Decisions\nNegotiate\nIntroduce as Parameters\n(b) Negotiating Social Influence\nFig. 2. Interplay of Social Influence and Argumentation-Based Negotiation.\n1. Undercut the opponent\u2019s existing justification to perform (or not) an action by disputing\ncertain premises within the schema that motivates its opposing decision (i.e., dispute ai is\nacting role ri, dispute SC is a social commitment associated with the relationship p, dispute\n\u03b8 is the action associated with the obligation O, etc.).\n2. Rebut the opposing decision to act (or not) by,\ni. Pointing out information about an alternative schema that justifies the decision not to\nact (or act as the case may be) (i.e., point out ai is also acting role ri, point out SC is\nalso a social commitment associated with the relationship p, point out \u03b8 is the action\nassociated with the obligation O, etc.).\nii. Pointing out information about conflicts that could or should prevent the opponent\nfrom executing its opposing decision (i.e., point out conflicts between two existing\nobligations, rights, and actions).\nNegotiating Social Influence: Agents can also use social influences within their negotiations.\nMore specifically, instead of using social argumentation as a tool to affect decisions (as above),\nagents can use negotiation as a tool for \u201ctrading social influences\u201d. In other words, the social\ninfluences are incorporated as additional parameters of the negotiation object itself [8] (see Fig-\nure 2(b)). For instance, an agent can promise to (or threaten not to) undertake one or many future\nobligations if the other performs (or does not perform) a certain action. It can also promise not\nto (or threaten to) exercise certain rights to influence one or many existing obligations if the\nother performs (or does not perform) a certain action. In this manner, the agents can use their\nobligations, rights, and even the relationship itself as parameters in their negotiations.\n3 The Language, Protocol, and Decision Making Functionality\nAs mentioned in Section 1, our main objective is to formulate a society of agents that are capable\nof resolving their conflicts through argumentation-based negotiations. To this end, Section 2\nformulated a model that allows the agents to identify such arguments to resolve conflicts in\na social context. However, identifying such arguments is merely the first step. Agents also\nrequire a means to express such arguments, a mechanism to govern their interactions and guide\nthem to resolve their conflicts, and a functionality to make decisions during the course of such\ndialogues. To this end, we now present the language, the protocol, and the decision making\nalgorithms of our ABN framework.\n3.1 The Language\nThe language plays an important role in an ABN framework. It not only allows agents to express\nthe content and construct their arguments, but also provides a means to communicate and ex-\nchange them within an argumentative dialogue. Highlighting these two distinct functionalities,\nwe define the language in our framework at two levels; namely the domain language and the\ncommunication language. The former allows the agents to specify certain premises about their\nsocial context and also the conflicts that they may face while executing actions within such a\nREJECT ASSERT\nOPEN\u2212DIALOGUE PROPOSE ACCEPT CLOSE\u2212DIALOGUE\nCHALLENGE\nFig. 3. Dialogue Interaction Diagram.\ncontext. The latter, on the other hand, provides agents with a means to express these arguments\nand, thereby, engage in their discourse to resolve conflicts. Inspired by the works of Sierra et\nal. [9], this two tier definition not only allows us an elegant way of structuring the language, but\nalso provides a means to easily reuse the communication component within a different context\nmerely by replacing its domain counterpart.\nIn more detail, our domain language consists of ten elocutionary particles. Of these, eight al-\nlow the agents to describe their social context and these flow naturally from our social influence\nschema (i.e., Act, RoleOf, In, DebtorOf, CreditorOf, ActionOf, InfluenceOf, and AssocWith).\nDue to space restrictions we avoid repeating these definitions here (see Section 2.1). Further-\nmore, we define two additional predicates that provide a means to express the conflicts that the\nagents may face while executing their actions:\nDefinition 4: Let:\n\u2022 do: A \u00d7 \u0398 denote the fact that an agent is performing an action (expressed in the abbreviated form\ndo(\u03b8) when the agent is unambiguous).\n\u2022 Conflict: do(A\u00d7\u0398)\u00d7do(A\u00d7\u0398) denote the fact that performing the actions gives rise to a conflict.\nOn the other hand, our communication language consists of seven elocutionary particles (see\nTable 1). Mainly inspired form the works of Amgoud et al. [10], MacKenzie\u2019s system DC [11],\nand McBurney et al. [12], these form the building blocks of our dialogue game protocol ex-\nplained below (see Section 3.2). Furthermore, these collectively allow the agents to use both of\nour identified methods of conflict resolution; namely socially influencing decisions and nego-\ntiating social influences (see Section 2.2). Due to their integrated nature with our protocol, we\nwill detail their operational functionality and the decision making algorithms associated with\neach of these locutions alongside the protocol (see Section 3.2).\n3.2 The Protocol and the Decision Making Functionality\nGiven the language component of our ABN framework, we will now proceed to describe both\nthe protocol which governs its interaction and guides the agents to resolve their conflicts, and\nthe various decision making algorithms that would enable the individual agents to participate\nin such encounters.3 While the overall structure of our protocol is inspired from the work on\ncomputational conflicts by Tessier et al. [13], the works on pragma-dialectics proposed by van\nEemeren and Grootendorst [14], and that on dialogue games conducted by McBurney et al. [12],\nand Amgoud et al. [10] contributed greatly in defining its operational guidelines.\nMore specifically, our protocol consists of six main stages: (i) opening, (ii) conflict recog-\nnition, (iii) conflict diagnosis, (iv) conflict management, (v) agreement, and (vi) closing. The\nopening and closing stages provide the important synchronisation points for the agents involved\n3 Even though we acknowledge the importance of distinguishing the rules of encounter governed by\nthe protocol from the individual decision mechanisms required by the participants to engage in such\ndialogues (see [12]), due to space restrictions we choose to describe both these elements in this section.\nTable 1. The Protocol\nLocution Effects on CS & IS Next Valid Moves\nOPEN-DIALOGUE CS(ai)\u2190 OPEN-DIALOGUE OPEN-DIALOGUE\nCS(aj)\u2190 OPEN-DIALOGUE PROPOSE(l,m)\nPROPOSE(l,m)\nCS(ai)\u2190 PROPOSE(l,m) ACCEPT(l,m)\nREJECT(l,m)CS(aj)\u2190 PROPOSE(l,m)\nIS(aj)\u2190 Need(ai, l) \u2227 Capable(ai,m)\nACCEPT(l,m)\nCS(ai)\u2190 ACCEPT(l,m) \u2227 l \u2227m\nCLOSE-DIALOGUECS(aj)\u2190 ACCEPT(l,m) \u2227 l \u2227m\nIS(ai)\u2190 Capable(aj , l)\nREJECT(l,m) CS(ai)\u2190 REJECT(l,m)\nCS(aj)\u2190 REJECT(l,m)\nCHALLENGE(l)\nPROPOSE(l,m\u2032)\nCLOSE-DIALOGUE\nCHALLENGE(l) CS(ai)\u2190 CHALLENGE(l) ASSERT(l)\nCS(aj)\u2190 CHALLENGE(l) CHALLENGE(l)\nASSERT(l) CS(ai)\u2190 ASSERT(l)\nCS(aj)\u2190 ASSERT(l)\nPROPOSE(l,m\u2032)\nACCEPT(l,m)\nASSERT(\u00acl)\nCHALLENGE(l)\nCLOSE-DIALOGUE\nCLOSE-DIALOGUE CS(ai)\u2190 CLOSE-DIALOGUE CLOSE-DIALOGUE\nCS(aj)\u2190 CLOSE-DIALOGUE\nin the dialogue, the former indicating its commencement and the latter its termination [12]. The\nfour remaining stages not only adhere to the computational conflict work by Tessier et al.,\nbut also comply well with the pragma-dialectics model for critical discussion proposed by van\nEemeren and Grootendorst. In more detail, in the conflict recognition stage, the initial inter-\naction between the agents brings the conflict to the surface. Subsequently, the diagnosis stage\nallows the agents to establish the root cause of the conflict and also decide on how to address\nit (i.e., whether to avoid the conflict or attempt to manage and resolve it through argumenta-\ntion and negotiation [1]). Next, the conflict management stage allows the agents to argue and\nnegotiate, thus, addressing the cause of this conflict. Finally, the agreement stage brings the\nargument to an end, either with the participants agreeing on a mutually acceptable solution or\nagreeing to disagree due to the lack of such a solution. As mentioned above, these four stages\nmap seamlessly to the four stages in the pragma-dialectics model; namely confrontation, rather\ninfelicitously termed opening, argumentation, and concluding respectively.\nGiven the overall stages of our protocol, we now describe its internal operation. Our pro-\ntocol follows the tradition of dialogue games [12] where a dialogue is perceived as a game\nin which each participant make moves (termed dialogue moves) to win or tilt the favour of\nthe game toward itself. In such a context, the protocol defines the different rules for the game\nsuch as locutions rules (indicating the moves that are permitted), commitment rules (defining\nthe commitments each participant incurs with each move), and structural rules (that define the\ntypes of moves available following the previous move).4 To this end, Figure 3 depicts the over-\nall structure of our protocol and Table 1 details the different commitment rules and the valid\nlocutions that may follow each move. For ease of reference, here we address the proposing\nagent as ai and its responding counterpart as aj . The commitment rules are shown as effects\non the participants\u2019 commitment (CS) and information (IS) stores (see [10]) and l and m are\npropositions constructed in the domain language defined above. The following describes their\noperation in more detail.\nOPEN-DIALOGUE: This indicates the entry point of that agent to the dialogue. As shown in\nTable 1 this would result in an entry in either agents\u2019 commitment stores corresponding to the\ndialogical commitment [15] of having made the move (i.e., commitment to the fact that ai has\nuttered OPEN-DIALOGUE). An agent receiving an OPEN-DIALOGUE will retort back (if it\nhasn\u2019t already initiated it) by uttering the same. This would put both these agents in the opening\nstage and their negotiation over actions can commence. For simplicity, we assume that the first\n4 Note, this is not intended to be an exhaustive list of rules, but rather the most important ones in our\ncontext. For instance, if the aim of the dialogue governed by the protocol is persuasion, the win-loss\nrules specifying what counts as a winning or losing position would become a vital component.\nAlgorithm 1 Decision making algorithm for\nPROPOSE.\nAlgorithm 2 Decision making algorithm for\nACCEPT and REJECT.\n1: if (Capable(do(ai, \u03b8i)) \u2227 Baido(aj,\u03b8j) > C\nai\ndo(ai,\u03b8i)\n)\nthen\n2: PROPOSE(do(aj , \u03b8j), do(ai, \u03b8i))\n3: end if\n1: if (Capable(do(aj , \u03b8j)) \u2227 Bajdo(ai,\u03b8i) > C\naj\ndo(aj,\u03b8j)\n)\nthen\n2: ACCEPT(do(aj , \u03b8j), do(ai, \u03b8i))\n3: else\n4: REJECT(do(aj , \u03b8j), do(ai, \u03b8i))\n5: end if\nagent opening the dialogue is the one attempting to make its counterpart perform (or abstain\nfrom performing) an action.\nPROPOSE: Each such proposal is composed of two basic elements; the action \u03b8j that ai re-\nquires aj to perform and the action \u03b8i that ai is willing to perform in return. Thus, in general, a\nproposal will have the form PROPOSE(do(aj , \u03b8j), do(ai, \u03b8i)). Here, \u03b8i could be single atomic\naction (e.g., I will perform (or will not perform) a certain action in return or I will make a\npayment of a certain amount) or a composite action (e.g., I will perform action (\u03b81 and \u03b82) or\n(\u03b81 or \u03b82)). Therefore, this generic form of proposal allows the agents not only to make simple\noffers of payment over actions, but also to make simple or composite rewards and\/or threats\nover actions. In this manner, it allows the agents to negotiate and also to use social influences\nas parameters within their negotiations to resolve conflicts (see Section 2.2). Given this, Algo-\nrithm 1 highlights the decision making required to generate such a proposal. In more detail, we\nassume our agents to be self-interested, thus, the proposals that they generate need to be viable\non their behalf (i.e., the cost for ai in performing the proposed action \u03b8i (i.e., Caido(ai,\u03b8i)) should\nnot exceed the benefit it gains from aj performing the requested action \u03b8j (i.e., Baido(aj ,\u03b8j)). We\nalso assume our agents do not intentionally attempt to deceive each other with offers that they\ndo not believe feasible on their behalf. Therefore, they will only generate proposals that they\nbelieve to have the capability to honour.5 Once received, as an effect of the proposal, aj will\ngain the information that ai requires \u03b8j and that ai has the ability to perform \u03b8i (see Table 1).\nACCEPT and REJECT: Upon receiving a proposal, the agent aj may choose to either accept\nor reject it. Now, in order to make this decision, it will need to evaluate the proposal. Similar to\nabove, this evaluation is also based on two factors: aj needs to have the capability to perform\nthe requested action and the benefit of the proposal should outweigh the cost of performing the\nsuggested action (see Algorithm 2). If both these conditions are satisfied the agent will accept\nthe proposal, otherwise it will reject it. If accepted, both agents will incur commitments to\nperform their respective actions (see Table 1).\nCHALLENGE: Upon rejection of a proposal by its counterpart (aj), ai may choose to either\nforward a modified proposal (i.e., if the reason is apparent such that there can be only one\npossibility) or challenge aj\u2019s decision in order to identify the underlying reasons for rejection.\nApart from this, an agent may use CHALLENGE in two other situations (see Figure 3). First,\nan agent may challenge another\u2019s right to challenge (demand or question) its decision (see\nSection 2.1) if that right is not evident for the agent. This allows an agent to only justify its\ndecisions to others who have the right to challenge its decision. To avoid infinite deepening\nof challenges, we do not allow such challenges go beyond two levels (i.e., challenge another\u2019s\nright to challenge its own right to challenge). Second, an agent can challenge a certain assertion\n5 First, under these assumptions of self-interest and non-deceit, we believe, viability and feasibility are\nthe two most important factors to consider. Second, even though we choose to specify the algorithms\nat an abstract level that is independent of any domain, by defining how the agents evaluate these costs\nand benefits we can easily set these to reflect a given domain. Finally, even though the PROPOSE\nlocution defined above has both the elements request and reward explicitly present, either can be null.\nThis allows the agents to express proposals that are mere requests without an explicit reward (such\nas demands, pleads, and orders) and solitary rewards (such as offers, gifts, and suggestions) that they\ndeem to be viable during their negotiation.\nAlgorithm 3 Decision algorithm for CHALLENGE. Algorithm 4 Decision algorithm for ASSERT.\n\u2013 In case of REJECT(l)\n1: if (REJECT(l) \u2208 \u2206ai\u2227reason(REJECT(l)) \/\u2208 \u2206ai ) then\n2: CHALLENGE(REJECT(l))\n3: end if\n\u2013 In case of ASSERT(l)\n1: if (ASSERT(l) \u2208 \u2206ai \u2227reason(ASSERT(l)) \/\u2208 \u2206ai ) then\n2: CHALLENGE(l)\n3: end if\n\u2013 In case of CHALLENGE(l)\n1: if (CHALLENGE(l) \u2208 \u2206ai\u2227RCHALLENGE(l) \/\u2208 \u2206ai ) then\n2: CHALLENGE(CHALLENGE(l))\n3: end if\n\u2013 In case of ASSERT(\u00acl)\n1: if (\u00acl \/\u2208 \u2206ai \u2227 l \u2208 \u2206ai ) then\n2: ASSERT(l)\n3: end if\n\u2013 In case of CHALLENGE(l)\n1: if (search-Justification(l,\u2206ai )\u21d2 H) then\n2: ASSERT(H)\n3: end if\nby its counterpart if either that assertion or its contradiction is not within its knowledge (see\nAlgorithm 3 where \u2206ai denotes agent ai\u2019s knowledge-base).\nASSERT: An agent can assert some fact in two possible situations. First, if the agent is chal-\nlenged for some justification on its decision it can assert that justification. Second, if its coun-\nterpart has made an assertion (l), but the agent has justification to believe its contradiction (\u00acl),\nthen the agent can assert this to dispute its partner\u2019s assertion.6 This will allow agents to un-\ndercut and rebut each others\u2019 social reasoning, and, thereby, resolve conflicts (see Section 2.2).\nAssert can either result in the counterpart generating an alternative proposal (taking into account\nthe reason given) or accepting the proposal (convinced by the persuasion).\nCLOSE-DIALOGUE: When either the counterpart has accepted a certain proposal or the propos-\ning agent has no other feasible and worthwhile proposals to forward, an agent will utter CLOSE-\nDIALOGUE (echoed in return by its counterpart) to bring the dialogue to an end.\nHaving formulated the language, the protocol, and the decision making functions of our\nABN system, we now explain how these would interact to provide a means for the agents to\nresolve their conflicts in a social context. To this end, Figure 4 depicts an illustrative dialogue\ntaking place between Andy, an agent acting the role of a PhD student, and Ben, acting as his\nsupervisor. The case is set within a context where Andy has two distinct obligations, both toward\nBen; to finish his thesis \u03b81 and to write a journal paper \u03b82. However, due to time restrictions, we\nassume that Andy has decided to perform \u03b81 at the expense of \u03b82. This choice is in conflict with\nBen\u2019s own motivations. In this context, Figure 4 illustrates how he can socially influence (see\nSection 2.2) Andy\u2019s decision by undercutting his justification and, thereby, resolve the conflict.\nMore specifically, Figure 4 highlights two specific aspects of our language and protocol. First,\nit shows how the language component allows the agents to do a straightforward encoding of\nthe natural language locutions into its respective utterances (see locutions L1 to L8 with its\ncorresponding utterances M3 to M10). Second, it also depicts how the dialogue progresses\nthrough the six distinct stages of conflict resolution identified above.\n4 Conclusions and Future Work\nThe long term objective of our work is to formulate an agent society that can use argumentative\ndialogues to resolve their conflicts. To this end, this paper builds upon our previous conceptual\ngrounding on social arguments [3] and formulates a coherent argumentation framework that\nallows agents to use ABN to resolve conflicts in a multi-agent community. In more detail, we\nfirst define a schema that captures social influences in an agent society and then illustrates the\ndifferent ways that agents can use it to systematically identifying a suitable set of arguments to\nresolve conflicts in such a social context. Next, we formulate the language, which allows agents\n6 Our current implementation uses a simple arbitration heuristic to resolve such disputes. However, this\ncan be extended by replacing it with either a system based on the strength of justification [10] or a\nlearning heuristic based on commitment (see Section 4).\n\u03b82\n\u03b82\n\u03b82\n\u03b82 \u03b81\n\u03b82 \u03b81\n\u03b82\nConflict Recognition\nConflict Diagnosis\nConflict Management\nAgreement\nClosing\nOpening\n\u03b81\nO2\nL1 \u2212 Ben: Can you finish the journal paper?\nL2 \u2212 Andy: No, I can\u2019t.\nL3 \u2212 Ben: Why not?\nL4 \u2212 Andy: I have to finish the thesis, and I \nL5 \u2212 Ben: But you are obliged to finish the paper.\nL6 \u2212 Andy: Yes, but I am also obliged to write \nL7 \u2212 Ben: In my expert opinion, I believe it is \nL8 \u2212 Andy: I adhere to your expert opinion, \n        can\u2019t do two things together.\n        the thesis and I believe it influences me more \n        than the obligation to finish the journal paper.\n        more important at this point to finish the paper \n        than the thesis. You should change your opinion.\n        therefore I will finish the paper.\n1 1 2\n1 2 2 1\n2\n1\n1\n2\n1\nLet: O   denote the obligation to perform     (finishing his thesis) \n and f  its associated degree of influence.2\nand f  its associated degree of influence and \nO  denote the obligation to perform      (write a journal paper) \nM1  \u2212 Ben:   OPEN\u2212DIALOGUE\nM2  \u2212 Andy:  OPEN\u2212DIALOGUE\nM3  \u2212 Ben:   PROPOSE(do(    ))\nM4  \u2212 Andy:  REJECT(do(    ))\nM5  \u2212 Ben:   CHALLENGE(\u00acdo(    ))\nM6  \u2212 Andy:  ASSERT(Conflict(do(    ), do(    )))\nM8  \u2212 Andy:  ASSERT(O   & (f   > f  ))\nM9  \u2212 Ben:   ASSERT(\u00ac(f   > f  ) &  (f  > f  ))\nM10 \u2212 Andy:  ACCEPT((f   > f  ) & do(    ) & \u00acdo(    ))\nM11 \u2212 Ben:   CLOSE\u2212DIALOGUE\nM12 \u2212 Andy:  CLOSE\u2212DIALOGUE\nM7  \u2212 Ben:   ASSERT(    )\nFig. 4. Resolving Conflicts through Argumentation-based Negotiation.\nto construct and express such arguments, and the protocol that would guide the course of the\ndialogue toward resolving conflicts. Finally, we define the various decision making algorithms\nthat would enable the individual agents to participate in such argumentative encounters. Apart\nfrom the models specified in this paper, in our current work we have implemented these in a\nmulti-agent task allocation domain (specified in [1]) in order to empirically test the efficiency\nand effectiveness of these concepts. In future, we aim to expand upon our current implemen-\ntation by designing different argument selection strategies, thus, allowing the agents to adopt\ndifferent tactics in resolving conflicts in an agent society.\nReferences\n1. Karunatillake, N.C., Jennings, N.R.: Is it worth arguing? In: Argumentation in Multi-Agent Systems\n(Proc. of ArgMAS 2004). LNAI 3366, NY, USA, Springer-Verlag (2004) 234\u2013250\n2. Rahwan, I., Ramchurn, S.D., Jennings, N.R., McBurney, P., Parsons, S., Sonenberg, L.:\nArgumentation-based negotiation. The Knowledge Engineering Review 18 (2003) 343\u2013375\n3. Karunatillake, N.C., Jennings, N.R., Rahwan, I., Norman, T.J.: Argument-based negotiation in a\nsocial context. In: Proc. of the 2nd Int. Workshop on Argumentation in Multi-Agent Systems\n(ArgMAS\u201905), Utrecht, The Netherlands (2005) to appear\n4. Castelfranchi, C.: Commitments: From individual intentions to groups and organizations. In: Proc.\nof the 1st Int. Conf. on Multi-agent Systems (ICMAS\u201995), San Francisco, CA (1995) 41\u201348\n5. Cavedon, L., Sonenberg, L.: On social commitment, roles and preferred goals. In: Proc. of the 3rd\nInt. Conf. on Multi-Agent Systems (ICMAS\u201998). (1998) 80\u201386\n6. Atkinson, K., Bench-Capon, T., McBurney, P.: A dialogue game protocol for multi-agent argument\nover proposals for action. In: Argumentation in Multi-Agent Systems (Proc. of ArgMAS 2004). LNAI\n3366, NY, USA, Springer-Verlag (2004) 149\u2013161\n7. Walton, D.N.: Argumentation Schemes for Presumptive Reasoning. Erlbaum, Mahwah, NJ (1996)\n8. Faratin, P., Sierra, C., Jennings, N.R.: Using similarity criteria to make trade-offs in automated nego-\ntiations. Artificial Intelligence 142 (2002) 205\u2013237\n9. Sierra, C., Jennings, N.R., Noriega, P., Parsons, S.: A framework for argumentation-based negotiation.\nIn: Proc. of 4th Int. Workshop on Agent Theories Architectures and Languages (ATAL\u201997), Rhode\nIsland , USA (1998) 167\u2013182\n10. Amgoud, L., Parson, S., Maudet, N.: Argument, dialogue and negotiation. In Horn, W., ed.: Proc. of\nthe 14th European Conference on Artificial Intelligence (ECAI\u201900), Berlin (2000) 338\u2013342\n11. MacKenzie, J.: Question-begging in non-cumulative systems. Journal of philosophical logic 8 (1979)\n117\u2013133\n12. McBurney, P., van Eijk, R., Parsons, S., Amgoud, L.: A dialogue-game protocol for agent purchase\nnegotiations. Autonomous Agents and Multi-Agent Systems 7 (2003) 235\u2013273\n13. Tessier, C., Chaudron, L., Mu\u00a8ller, H.J., eds.: Agents\u2019 Conflicts: New Issues. In: Conflicting Agents\nConflict Management in Multi-Agent Systems. Kluwer Academic Publishers (2000) 1\u201330\n14. Eemeren, F.H. van, Grootendorst, R.: Argumentation, Communication, and Fallacies. Lawrence\nErlbaum Associates, Inc, Hillsdale NJ (1992)\n15. Walton, D.N., Krabbe, E.C.W.: Commitment in Dialogue: Basic Concepts of Interpersonal Reason-\ning. State Univ. of NY (1995)\n"}
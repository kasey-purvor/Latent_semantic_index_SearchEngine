{"doi":"10.1109\/MPRV.2003.1186726","coreId":"70410","oai":"oai:eprints.lancs.ac.uk:12211","identifiers":["oai:eprints.lancs.ac.uk:12211","10.1109\/MPRV.2003.1186726"],"title":"Preserving privacy in environments with location-based applications","authors":["Myles, Ginger","Friday, Adrian","Davies, Nigel"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2003-01","abstract":"The increase in location-based applications makes protecting personal location information a major challenge. Addressing this challenge requires a mechanism that lets users automate control of their location information, thereby minimizing the extent to which the system intrudes on their lives","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/70410.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/12211\/2\/b1056.pdf","pdfHashValue":"8bb9e36fb29afeb4b86a126e8a535cbbd7d048ef","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:12211<\/identifier><datestamp>\n      2018-01-23T02:42:28Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Preserving privacy in environments with location-based applications<\/dc:title><dc:creator>\n        Myles, Ginger<\/dc:creator><dc:creator>\n        Friday, Adrian<\/dc:creator><dc:creator>\n        Davies, Nigel<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        The increase in location-based applications makes protecting personal location information a major challenge. Addressing this challenge requires a mechanism that lets users automate control of their location information, thereby minimizing the extent to which the system intrudes on their lives.<\/dc:description><dc:date>\n        2003-01<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/MPRV.2003.1186726<\/dc:relation><dc:identifier>\n        Myles, Ginger and Friday, Adrian and Davies, Nigel (2003) Preserving privacy in environments with location-based applications. IEEE Pervasive Computing, 2 (1). pp. 56-64. ISSN 1536-1268<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/12211\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/MPRV.2003.1186726","http:\/\/eprints.lancs.ac.uk\/12211\/"],"year":2003,"topics":["QA75 Electronic computers. Computer science"],"subject":["Journal Article","PeerReviewed"],"fullText":"56 PERVASIVEcomputing Published by the IEEE CS and IEEE Communications Society   1536-1268\/03\/$17.00 \u00a9 2003 IEEE\nSECURITY & PRIVACY\nPreserving Privacy in\nEnvironments with\nLocation-Based\nApplications\nA\ns mobile devices and location systems\nsuch as the Global Positioning System\n(GPS) and phone-based technologies\nproliferate, so too does interest in\nlocation-based applications. These\napplications include tourist information systems,\nbuddy services that inform users when a friend is\nnearby, and location-based adver-\ntisements, which marketers send\nto users on the basis of their cur-\nrent locations. Such applications\nraise serious privacy issues that\ndevelopers must address, both to\nappease public concern and to\ncomply with current legislation. \nAn important first step in pro-\ntecting users\u2019 location privacy is\nnotifying them of requests for this information. For\nexample, a system might ask users to authorize\nrelease of their location information by clicking\n\u201cOK\u201d on a dialog box for each new request. Such a\nsystem would be at odds with Mark Weiser\u2019s vision\nof calm technology, however.1Weiser argues that for\ntechnology to become truly ubiquitous, it should\nmerge into the background such that it becomes a\npart of the fabric of everyday life. Thus the goal is to\nminimize technology\u2019s intrusiveness and its demands\nof users. In this article, we address these two con-\nflicting requirements of location-based systems\u2014the\nneed for users to control their location privacy and\nthe need to minimize the demands made of users.\nOur system was motivated by an extremely prac-\ntical problem\u2014that is, how to protect location infor-\nmation gathered by our groups\u2019 location-tracking\nsystems. We created LocServ2 to support the vari-\nous location-based applications developed in our\nlaboratories. LocServ is a middleware service that\nlies between location-based applications and loca-\ntion-tracking technologies. By unifying location-\ntracking technologies, LocServ lets location-based\napplications use multiple positioning systems. In\nessence, LocServ users can specify a location query\nusing any of the symbolic or geometric location\nmodels that LocServ understands, and the service\ncan resolve the queries using any number of under-\nlying technologies. Thus, LocServ allows applica-\ntions to be written in a way that is entirely inde-\npendent of the underlying location technology that\nthey use. Such a service requires mechanisms for\ncontrolling access to users\u2019 location information\nwithout repeated user intervention. We have thus\ndeveloped an extensible system that gives users fine-\ngrained control over the release of their location\ninformation. More specifically, we offer a general\nframework of components that lets users apply gen-\neral policies to control distribution of their infor-\nmation. We use factors such as the type of organi-\nzation or application requesting the data together\nThe increase in location-based applications makes protecting personal\nlocation information a major challenge. Addressing this challenge\nrequires a mechanism that lets users automate control of their location\ninformation, thereby minimizing the extent to which the system intrudes\non their lives.\nGinger Myles\nUniversity of Arizona\nAdrian Friday\nLancaster University\nNigel Davies\nUniversity of Arizona and\nLancaster Universitywith its information retention and distri-\nbution policies and, crucially, a mechanism\nfor consulting external entities such as\napplication-specific modules before releas-\ning information. \nLike the World Wide Web Consortium\u2019s\nPlatform for Privacy Preferences (P3P) and\nMarc Langheinrich\u2019s Privacy Awareness\nSystem (pawS), our system uses machine-\nreadable privacy policies and user prefer-\nences to automate the privacy management\ndecision-making process. As the sidebar,\n\u201cRelated Work on Privacy in Location-\nBased Systems\u201d explains, however, our sys-\ntem architecture and preference language\nare significantly different from those in P3P\nand pawS, reflecting the differences in\ndeployment domain. \nGeneral requirements\nThe following scenario illustrates the\nrequirements for a privacy policy system\nfor location-based applications.\nA health-care worker, Sally, carries\na mobile phone that lets her employer\nlocate her whenever she has the device.\nDuring the day, Sally visits patients\nin their homes and is pleased that her\ncompany can locate her with an accu-\nracy of about 100 meters. Her com-\npany uses this information to inform\npatients of her likely arrival times\nand to maintain her schedule without\nher having to disclose her movements\nwithin houses.\nWhen she is off-duty, Sally does\nnot want the company to track her.\nIf she must wait for a table at a\nrestaurant, however, she wants the\nrestaurant to know her location so\nthat they can find her when her table\nis ready. Of course once she leaves\nthe restaurant, she does not want the\nowners to be able to determine her\nlocation. Similarly, when Sally uses\nher mobile phone to call a cab at the\nend of the evening, she wants the\ntaxi company to determine her loca-\ntion automatically to ensure a smooth\npickup, but she does not want them\nto be able to trace her once the jour-\nney is over. \nSally is also planning a vacation,\nand when she visits, for example, the\nFunTime amusement park, she will\nlet the park management track her\nfor safety and management purposes,\nbut she does not want this informa-\ntion correlated with her identity. \nFinally, Sally uses a small set of\nlocation-based applications, includ-\ning a general information service\nthat warns her of traffic holdups in\nher area and a find-a-friend service\nthat tells her when she is within half\na mile of one of her friends. Indepen-\ndent companies provide these services,\nand Sally wants to disclose only the\nminimum amount of information\nnecessary for them to provide the\nrequired functionality. \nThis scenario also illustrates the richness\nof constraints (or preferences) users might\nwant to apply to control the distribution of\ntheir location information. In our example,\nSally restricts access to her information in\nseveral ways:\n\u2022 Organization.In most cases, Sally restricts\naccess to her location information to spe-\ncific organizations (such as her employer\nor the find-a-friend service provider).\n\u2022 Service. While Sally generally restricts\naccess to her location information to\nknown companies, she will also accept\ncertain types of information (informa-\ntion bulletins, for example) from new\ncompanies.\n\u2022 Time. Sally controls her employer\u2019s\naccess to her location information on the\nbasis of the time of day\u2014she has differ-\nent policies for work days, weekends,\nand evenings.\n\u2022 Location. Sally will let the amusement\npark management track her location\nwhile she is in the park but not when she\nleaves. Hence, their ability to obtain\nlocation information depends on her\nlocation and the relationship between\nthe company requesting the information\nand the physical space. \n\u2022 Request type. Sally restricts the type of\nquery an application can issue to obtain\nher location information. For example,\nshe provides an anonymized trace of her\nlocation in the amusement park. Fur-\nthermore, although Sally will tell the\nfind-a-friend service when she is within\na specified distance of one of her friends,\nshe does not want to tell them her exact\nlocation.\n\u2022 Context. Sally uses her calendar (or\nwork schedule) to control her employer\u2019s\naccess to her location information.\nOther forms of contextual information,\nsuch as whether or not she is alone,\ncould easily form part of her preferences.\nThis is not an exhaustive set of require-\nments for privacy preferences in ubiqui-\ntous computing environments. Indeed, a\nuser could easily add the constraint, \u201cinfor-\nmation about my child\u2019s location can only\nbe released when the child is with me or\nmy spouse.\u201d At least two additional con-\nstraints exist: the need to comply with\nexisting and emerging legislation and, as\ndiscussed previously, the desire to minimize\nuser interaction when dealing with requests\nfor location information.\nCurrent legislation\nCurrently, two important pieces of pri-\nvacy-related legislation exist: the US Pri-\nvacy Act of 1974 and the European Union\u2019s\nDirective 95\/46\/EC.3 The US Privacy Act\nof 1974 was designed for information pri-\nvacy. It gives legal substance to the idea of\nfair information practices including open-\nness and transparency (for example, no\nsecret record keeping), individual partici-\npation, collection and use limitations, rea-\nsonable security, and accountability. \nThe EU\u2019s directive addresses the protec-\ntion and movement of personal data. It\nlimits data transfer to non-EU countries to\nthose countries deemed to have an ade-\nquate level of privacy protection. It also\nrequires explicit consent\u2014that is, a user\nmust unambiguously consent to having\ntheir information collected. Like Langhein-\nrich, we recognize the difficulty of design-\nJANUARY\u2013MARCH 2003 PERVASIVEcomputing 57\nOur system uses machine-readable \nprivacy policies and user preferences \nto automate the privacy management \ndecision-making process.ing a system that guarantees compliance\nwith such laws and hence developed an\narchitecture based on trust and respect:\nproducers and consumers both state their\ninformation collection and distribution\npolicies, and we assume these statements\nare accurate. We rely on digital signatures\nto prove the statements\u2019 authenticity and\nexpect that legislation could be used to\nhold users accountable for violating their\nstated policies.\nUser interaction\nWe aimed to develop a system that\nrequired minimal ongoing user involve-\nment. In particular, we did not want users\nto have to repeatedly evaluate the accept-\nability of an application\u2019s request for loca-\ntion information. Instead, we wanted to\npush a request\u2019s acceptance or rejection to\nthe periphery and only bring a request to\nusers\u2019 attention if they had not established\na policy to handle it. The potentially large\nvolume of requests each user could be sub-\njected to on any given day made this an\nimportant design consideration. Moreover,\nwe believe user privacy should be protected\nby default; thus, the system architecture lets\na user elect to share certain information\nrather than protect specific information.\nSystem architecture \nFigure 1 shows our system\u2019s overall\narchitecture. We assume the existence of a\nlocation server (such as LocServ) that\nanswers applications\u2019 queries concerning\nusers\u2019 locations. These queries can be\nbroadly classified into types:\n\u2022 User location requests\u2014requests for the\nlocation of a specific user or users, iden-\ntified by their unique identifiers.\n\u2022 Enumeration requests\u2014requests for lists\nof users at specific locations, expressed\neither in terms of geographic or symbolic\nattributes.\n\u2022 Asynchronous requests\u2014requests for\n\u201cevent\u201d information, such as when users\nenter or leave specific areas or when\nproximity relationships are satisfied (for\nexample, tell me when Sally and Bob are\nwithin half a mile of each other).\nThe location server abstracts over the\nunderlying positioning technologies used\nto derive location, such as GPS and Active\nBat systems,4 and provides applications\nwith a common API. Users subscribe to\n58 PERVASIVEcomputing http:\/\/computer.org\/pervasive\nSECURITY & PRIVACY\nD\nespite its obvious importance, relatively little systems-oriented\nresearch has addressed privacy protection in ubiquitous com-\nputing systems. Several exceptions have informed our work.\nGeopriv \nThe Internet Engineering Task Force\u2019s Geopriv working group\nhas identified a need to \u201csecurely gather and transfer location\ninformation for location services, while at the same time protect-\ning the privacy of the individuals involved.\u201d1 The November 2002\nIETF draft describes one approach to securely transferring location\ninformation and associated privacy data. In essence, the scheme\ninvolves creating location objects that encapsulate user location\ndata and associated privacy requirements. Central to this scheme\nis the notion that location objects can be made tamper resistant\u2014\nfor example, by digitally signing them. The approach is similar to\ndigital rights management schemes designed to protect digital\nmedia from illegal redistribution.\nAt present the Geopriv proposal and our scheme are largely\northogonal. We focus on defining the management of information\nrelease and the nature of the privacy rules and preferences used to\ncontrol this release, but Geopriv does not address these issues.\nHence, Geopriv could use a subset of our system\u2019s rule sets and\noverall policy architecture as the \u201cprivacy-enabling information\u201d1\nstored in a location object. Geopriv\u2019s proposed coupling of data\nand privacy metadata offers greater accountability than our system\nwhen location information has been passed between multiple\napplications. The practicality of such a system has yet to be deter-\nmined, however.\nP3P and Appel \nTogether, P3P2 and Appel3 help Web sites announce their privacy\npractices while letting users automate their accept and reject deci-\nsions. P3P specifies an architecture comprising user agents, privacy\nreference files, and privacy policies. When users access a Web site,\ntheir user agents obtain a privacy reference file for the Web site\nusing one of several well-defined mechanisms. This file contains a list\nof mappings between URIs for the site\u2019s Web resources and URIs of\ntheir associated privacy policies. The Web agent can thus ensure that\nthe system downloads, parses, and compares the appropriate privacy\npolicy with the user\u2019s preferences prior to accessing a Web resource. \nP3P also specifies the language used to express privacy policies,\nwhile privacy preferences used to configure user agents can be\nexpressed in several forms. P3P commonly uses Appel to ensure\nthat different user agents can reuse preferences. \nP3P does not attempt to enforce or ensure privacy through\ntechnology\u2014for example, by cryptographic or anonymization\ntechniques. Instead it relies on social and legal pressures to compel\norganizations to comply with their stated policies.\npawS\npawS is a privacy awareness system for ubiquitous computing\nenvironments.4 Like P3P, pawS aims to provide users with tools that\nlet them protect their personal privacy and help others respect that\nprivacy. It is based on respect and social and legal norms rather than\nrigorous technical protection of private information. In pawS, when\na user enters an environment in which services are collecting data, a\nprivacy beacon announces the privacy policies of each service in the\nRelated Work on Privacy in Location-Based Systemsone or more location servers, registering\ntheir privacy requirements with each server.\nThese requirements take the form of sys-\ntem components called validators. Given\na request for location information and a\nprivacy policy provided by the application,\nvalidators determine whether the requested\ninformation can be released and, if so,\nwhether the location servershould impose\nJANUARY\u2013MARCH 2003 PERVASIVEcomputing 59\nenvironment. A user\u2019s privacy proxy (similar to P3P\u2019s user agents)\nchecks these policies, expressed in the same language as P3P policies,\nagainst the user\u2019s predefined privacy preferences, expressed in Appel.\nIf the policies agree, the services can collect information and users can\nutilize the services. If the policies don\u2019t agree, the system notifies the\nuser, who can choose not to use the service in question or, in extreme\ncases, leave the area in which the information collection is occurring.\nSystems analysis \nP3P and pawS are good starting points for investigations into\nprivacy-enabling schemes in ubiquitous computing, and significant\nwork has gone into making P3P comply with existing and emerg-\ning legislation in information protection and privacy. However,\nneither system can adequately support the scenarios described in\nthe article. Because P3P is designed to support Web interactions\ntypically involving e-commerce and business applications, its\nmechanisms for obtaining reference files and policy documents\nare tightly coupled with Web usage models, protocols, and\ndeployment architectures. Moreover, the policy language, while\nextensible, contains constructs for expressing information-collec-\ntion and management policies appropriate for protecting informa-\ntion disclosed during Web browsing and user-initiated online\ntransactions. Our system protects the user when arbitrary third-\nparty location-based applications require information from the\nuser\u2019s location server. Similarly, while Appel provides a good start-\ning point for expressing privacy preferences, it cannot support the\nrichness of expression necessary for autonomous evaluation of user\ncriteria in real application domains.\nOur system also differs from pawS, P3P, and Geopriv in its asso-\nciation between preferences, services, and data. Geopriv\u2019s fairly\nsimple model for associating privacy requirements with user data\nmakes it difficult to capture privacy requirements that span multi-\nple data items or do not readily fit into location objects. For exam-\nple, in Geopriv it would be difficult to specify that an application\ncan know if two people are in the same general area but cannot\nknow their individual locations. \nPhilosophically, our system is fundamentally different from\npawS. pawS lets users protect their privacy at the moment of\ninformation capture, typically when they access a service or enter\na new geographic space. In contrast, our system attempts to pro-\nvide privacy checks at the moment of information release\u2014that is,\nwhen an application makes a solicited or unsolicited request for\nlocation information. \nREFERENCES\n1. J. Cuellar, J.B. Morris Jr., and D. Mulligan, \u201cGeopriv Requirements,\u201d\nInternet draft, Nov. 2002.\n2. The Platform for Privacy Preferences 1.0 (P3P1.0) Specification, World\nWide Web Consortium, Sept. 2001, www.w3.org\/TR\/2001\/WD-P3P-\n20010928.\n3.  A P3P Preference Exchange Language 1.0 (Appel 1.0), working draft, World\nWide Web Consortium, Apr. 2002, www.w3.org\/TR\/P3P-preferences.\n4. M. Langheinrich, \u201cA Privacy Awareness System for Ubiquitous Comput-\ning Environments,\u201d Proc. Ubicomp, LNCS 2498, Springer-Verlag, 2002,\npp. 237\u2013245.\nLocation server\nPrivacy-enabling\nboundary\nSupporting location\ntechnologies\n(for example, GPS)\nValidators\nClient applications\nRequests with associated\nprivacy statements\nPrivacy policies, preferences, \nand request data\nFigure 1. Overall system architecture. \nThe location server works on top of \npositioning technologies such as GPS,\nreceiving requests for users\u2019 location\ninformation from various applications.\nSystem components called validators\ndetermine whether or not to grant the\napplications\u2019 requests.any special constraints (such as reducing\nthe location data\u2019s accuracy). Users regis-\nter a single validator with a location server\nfor each of their identifiers. Because val-\nidators can call other validators for help\nmaking decisions, however, multiple val-\nidators might be used to determine the cor-\nrect response in any given case. We assume\nthat trusted relationships exist between\nusers, their location-tracking systems, val-\nidators, and the location server.\nApplications wishing to obtain infor-\nmation about a user\u2019s location query the\nlocation server, including with the query a\nprivacy policy statement. The location\nserver consults the relevant validators\nbefore releasing any information. If neces-\nsary, the location server can require appli-\ncations to sign their privacy statements\nand, similarly, applications can require the\nlocation server to return a signed agree-\nment to these practices.\nBoth the location server and the valida-\ntors are abstract entities that can be real-\nized as integrated components of a single\nlocation technology or, as in our system,\nas a self-contained middleware service with\nassociated internal and external validators\nbalancing efficiency with extensibility.\nThus the location server in our architec-\nture simply represents the point at which\nvalidators check privacy statements from\nclient applications against users\u2019 or system\nadministrators\u2019 privacy preferences.\nExpressing privacy policies\nThird-party applications seeking a user\u2019s\nlocation first choose a location server\nresponsible for the user, typically deter-\nmined by the contact details available to the\napplication (given a phone number, for\nexample, an application might contact the\nlocation server of the user\u2019s mobile tele-\nphone provider). The application contacts\nthe location server and sends both a query\nand a statement of its privacy policy. The\nquery should be in a format the location\nserver in question understands. In our sys-\ntem, this is a proprietary LocServ format,\nbut applications could use other formats\nsuch as that proposed by the Location Inter-\noperability Forum (www.locationforum.\norg) for other types of location servers.\nTo support automatic checking of pri-\nvacy policies, developers must agree on a\ncommon scheme for describing these poli-\ncies. We use Appel, the policy specification\nlanguage proposed as part of the W3C\u2019s\nP3P specification (see the sidebar). This\nXML-based language provides a machine-\nreadable form of the privacy policies cur-\nrently found on manyWeb sites. It provides\na wide range of constructs allowing, for\nexample, Web sites to describe the infor-\nmation types they will collect, who will\nhave access to this information, and how\nlong it will be retained.\nTo address the requirements of location-\nbased applications, we extended the P3P\npolicy specification language. These exten-\nsions constitute the main differences\nbetween privacy policies related to Web\nbrowsing and e-commerce and those\nrelated to location-based applications.\nEntity. The P3P entity tag provides a mech-\nanism for describing the business and con-\ntact details of an organization providing\nWeb-based services. In our system, entities\nrepresent arbitrary third-party applications\nrequesting location information. We have\naugmented the entity tag with the fields type\nand cert (optional). An organization type\ncan be nonprofit, profit, or government.\nThe tag lets the system automatically iden-\ntify and filter course-grained application\nclasses (for example, it can place restric-\ntions on all nonprofit services). The certfield\nlets the system introduce certification\nschemes (a user might wish to only use ser-\nvices certified by a particular set of trusted\norganizations or authorities).\nPurpose. P3P\u2019s purpose tag reflects its orien-\ntation to e-commerce and Web interactions\n(representing such intentions as telemar-\nketing and Web page tailoring). We use a\nnew set of broad classifications to more\naccurately reflect the intentions of location-\nbased service providers: safety, entertain-\nment, marketing, information, service deliv-\nery, statistical analysis, and security. Safety\nservices include danger warnings in partic-\nular geographic areas or emergency service\nsupport, whereas security applications\ntrack the user for security purposes (sur-\nveillance, for example). Like P3P, our\nschema allows for arbitrary user extensions.\nRequest-initiation. In P3P-based Web\ninteractions, the user always initiates a dia-\nlogue by visiting a particular Web site and\nfollowing certain hyperlinks. In our model\napplications can request information from\nthe user\u2019s location service at any time. We\nadded a new request initiation tag and parti-\ntioned interactions into two classes: unso-\nlicited and solicited. Unsolicited interac-\ntions are not explicitly or consciously\ntriggered by the user (for example, initi-\nated speculatively as a user wanders into a\nparticular region or proximity). We assume\nsolicited interactions have been explicitly\ntriggered by some out-of-band user-initi-\nated action (requesting a taxi to his or her\ncurrent location, for example). Arbitrary\nuser data (proof) might accompany a solicited\ntag to link the request back to the instigat-\ning action. The request initiation tag also lets\nthe user block unwanted requests from\nunsolicited services.\nIn contrast to P3P, our system does not\nrequire policies to specify the data to be col-\nlected, because the system can determine it\nfrom the associated query. Because our pol-\nicy language is simply a set of extensions to\nthe current P3P language, our system can\nuse existing P3P policy specifications. Such\npolicies are unlikely to be applicable, how-\never, because they will typically specify data\nitems collected during Web-based activities\n60 PERVASIVEcomputing http:\/\/computer.org\/pervasive\nSECURITY & PRIVACY\nIn contrast to P3P, our system does not require\npolicies to specify the data to be collected\nbecause the system can determine it from the\nassociated query.(and will thus be inappropriate for queries\nissued to a location service). In addition,\nthey will not detail the application purpose\nsufficiently to let most users determine\nwhether to accept or reject the request.\nValidators and user preferences \nValidators check the acceptability of pri-\nvacy policies and determine whether the\nsystem should accept a request. As part of\nthis decision-making process, validators\ncan call other validators, creating networks\nof components that collectively determine\nwhether information should be released to\nthe application. Potential validator com-\nponents include\n\u2022 User confirmation. A simple validator\ncomponent could pass the responsibil-\nity for decision making to the user by\ndisplaying a dialog box containing a\nsummary of the requesting application\u2019s\nprivacy policy and information require-\nments. While such a validator does not\nbegin to address the desire for calm tech-\nnology, it is a useful component at the\nend of a chain of other validators when\nthe system has been unable to automat-\nically decide whether to accept a request.\n\u2022 User data and context.We can construct\nvalidators to base their decisions on data\nfrom user applications such as calendars\nor system components such as activity\nmonitors. More generally, validators let\nthe system include contextual informa-\ntion in the decision-making process.\n\u2022 External services.External validation ser-\nvices can, for example, resolve issues of\nownership of a physical space, which\nmay be a factor in determining a request\u2019s\nacceptability. Other examples of exter-\nnal services include verification of a third\nparty\u2019s reputation and checking \u201cspam\nrequest\u201d listings. \nA requirement for general-purpose val-\nidators that can make decisions based on\ninformation supplied in a request\u2019s privacy\npolicy also exists. Users could tailor these\ngeneral-purpose validators using a range of\nmechanisms including preference languages\nsuch as Appel or more general-purpose rule-\nbased languages. Our experiments suggest\nthat a simple scheme that allows constraints\nexpressed in terms of the basic attributes\nspecifiable in privacy policies (entity, pur-\npose, and so on) provides sufficient flexi-\nbility for expressing many common privacy\npreferences. Additional features include\n\u2022 Statement. The user can define a policy\nstatement for each request type sup-\nported by the location serverAPI, choos-\ning to accept the request uncondition-\nally or to impose certain time, location,\nor accuracy constraints. For example, a\nuser might accept a request to enumer-\nate all users within a given locale (pro-\nviding course-grained identification), but\nmight reject a direct request for his or\nher precise location.\n\u2022 Limit time. Users can associate time\nbounds with preferences. For example,\nusers might impose a constraint such\nthat their employers can only access their\nlocation during work hours.\n\u2022 Limit location. Users can restrict collec-\ntion of their information to specified\ngeographic areas. For example, users\nmight let a shopping mall track their\nlocation while they are in the mall, but\nwould presumably want this surveil-\nlance to stop when they leave.\n\u2022 Validator.Users can specify one or more\nURIs to external policy validators. Each\nvalidator receives a copy of the third-\nparty request and the accompanying pri-\nvacy policy statement. The validator can\nimplement any arbitrary policy on the\nuser\u2019s behalf, returning accept or reject\nresponsesto the location server evaluat-\ning the policy. Currently, our system\nallows validators to be combined using\nsimple logical operators.\n\u2022 Quality of service.Our system incorpo-\nrates a placeholder for specifying qual-\nity of service (QoS) in user preferences,\nwhich can limit the accuracy or certainty\nwith which a user can be located.\nProvisioning time and location con-\nstraints is particularly important in sup-\nporting ongoing location operations that\nyield events to a third party over time.\nUsers can register any component that pro-\nvides an appropriate interface as a valida-\ntor. Thus we do not expect just one val-\nidator type or even one mechanism for\nspecifying preferences to general-purpose\nvalidators. Hence, we are not concerned\nwith standardizing languages for express-\ning preferences, such as Appel. \nAnonymity \nProducing anonymous location informa-\ntion is a nontrivial task, and several recent\nresearch papers have attempted to address\nthis problem (see the related article, \u201cLoca-\ntion Privacy in Pervasive Computing,\u201d in\nthis issue). Our current system relies on users\nhaving multiple identifiers. More specifi-\ncally, when the system receives a location\nrequest that requires it to divulge a user\u2019s\nidentity, the user\u2019s validators are consulted\nto determine whether to return the user\u2019s\nlong-term identifier, a short-term identifier\nassociated with the user, or a new randomly\ngenerated identifier. The system can create\nthe new identifiers with new validators and\nassociated rule sets, or the new identifiers\ncan inherit the user\u2019s original configuration.\nSay FunTime\u2019s owners have registered\nwith Sally\u2019s location service to receive an\nevent whenever someone enters the park.\nBecause Sally is willing to provide them with\nthat information, but not with her identity,\nher validator sends FunTime a new identi-\nfier in response to its query. Of course, Fun-\nTime can reuse the identifier to obtain Sally\u2019s\nlocation during her visit, but the identifier\nwill eventually expire and will have no link\nJANUARY\u2013MARCH 2003 PERVASIVEcomputing 61\nProvisioning time and location constraints is\nparticularly important in supporting ongoing\nlocation operations that yield events to a third\nparty over time. back to Sally\u2019s long-term identifier.\nSuch a scheme does not, of course, pro-\nvide complete anonymity because applica-\ntions might be able to deduce the mapping\nbetween temporary and permanent iden-\ntifiers by observing movement patterns.\nProtecting against this type of attack is out-\nside the scope of this work.\nThe user\u2019s role \nValidators automate the process of check-\ning privacy policies against user preferences,\nwhether or not these preferences are an inte-\ngral part of the validator or passed to the\nvalidator as a parameter in the form of a\nconfiguration script, for example. Clearly\nwe do not expect end users to write their\nown validator components or even produce\nconfiguration scripts unaided. Instead, we\nassume that service providers and other\ntrusted organizations will provide users with\ndefault validators. For situations requiring\nnonstandard preferences, simple tools could\nhelp users create appropriate configurations.\nTo help clarify this process we created sev-\neral \u201cwizards\u201d that ask users a series of\nquestions about their location information\nprivacy preferences and then generate\nappropriate configuration scripts.\nSimilarly, we would not expect individ-\nual application writers to author their own\nprivacy policies. Rather, we expect compa-\nnies to include them in their general policy-\nmaking process as they do human-readable\nWeb privacy statements. Developers of sys-\ntems such as P3P, which attempt to provide\nsimilar support for privacy management,\nshare this view.\nControlling access to user\nlocation information: \nA demonstration\nTo illustrate how our scheme can real-\nize our original scenario, we divide the sce-\nnario into six separate interactions.\n\u2022 Sally\u2019s employer accesses her location\nduring office hours.\n\u2022 Sally\u2019s employer accesses her location\noutside of office hours but while she is\non call.\n\u2022 Sally visits a restaurant and lets them\nlocate her.\n\u2022 Sally calls a taxi and the taxi company\nobtains her location information.\n\u2022 Sally visits the FunTime amusement park.\n\u2022 Sally uses a find-a-friend service and\nlocal information providers.\nValidators and preferences\nSally\u2019s simple configuration consists of\nthree validators. The first is a general-pur-\npose validator that uses a configuration\nscript to determine whether to accept or\ndecline a request, or to require additional\nvalidators for the decision-making process.\nThis validator calls the remaining two val-\nidators\u2014one to access Sally\u2019s calendar and\nthe other to determine ownership of physi-\ncal spaces\u2014as required. Table 1 gives a rule\nbase for a general-purpose validator that\nwould meet Sally\u2019s requirements. Columns\ncorrespond to rules the system uses to allow\naccess to her location information, and rows\ncorrespond to either parameters to be\nmatched in the requesting application\u2019s pri-\nvacy policy or statements of action to be\ntaken\u2014for example, to consult an external\nvalidator. Several rows relate to parameters\nfound in conventional P3P policies as\ndetailed in the P3P specification.\n62 PERVASIVEcomputing http:\/\/computer.org\/pervasive\nSECURITY & PRIVACY\nTABLE 1\nPolicy rule base for a general-purpose validator describing Sally\u2019s preferences.\nParameter Rule 1 Rule 2 Rule 3 Rule 4 Rule 5 Rule 6\nCompany MyEmployer.com MyEmployer.com * Taxi.com * FindaFriend.com\nOrganization Commercial Commercial * Commercial Nonprofit,  Commercial\ntype government\nCertification * * * * * *\nRequest type * * Enumerate * Location,  Colocation\nasynchronous\nPurpose Safety, information, Safety, information, Safety, information, Service delivery Information Service delivery \nservice delivery,  service delivery, service delivery,\nstatistics, security,  statistics, security, security\nother other\nRetention * * Stated purpose Stated purpose Stated purpose Stated purpose\nDistribution Ours Ours Ours Ours Ours Ours\nInitiated * * * Yes * *\nValidators None References a  References a None None *\nvalidator that can  verification service\ncheck Sally\u2019s  that checks\ncalendar ownership of \nphysical locations\nLocation * * * * * *\nTime M\u2013F, 9 a.m.\u2013\n5 p.m. * * * * *\nAnonymity None None Returns a new  None None None\npseudo-identifier\n* AnyRules 1 and 2 control Sally\u2019s employer\u2019s\naccess to her location information. Rule 1\nallows the company to obtain any infor-\nmation it wants on Sally\u2019s whereabouts\nduring office hours. Rule 2 supplements\nRule 1 by ensuring that when Rule 1 rejects\na request, the system will use an additional\nvalidator to check Sally\u2019s calendar to see if\nshe is on call and hence whether to accept\nthe request.\nRule 3 lets both FunTime and the restau-\nrant access Sally\u2019s location. This rule sim-\nply states that Sally\u2019s location can be deter-\nmined by anyone who owns the physical\nspace in which Sally is located. However,\nthis information is presented in the form\nof a pseudo-identifier, thus partially con-\ncealing Sally\u2019s true identity.\nRule 4 lets the taxi company get Sally\u2019s\nlocation information when she requests\nservice. The rule specifies that the taxi com-\npany can only obtain her location infor-\nmation if she explicitly requests the service.\nSome form of information exchange would\nbe required to ensure that this condition is\nmet. Rules 5 and 6 restrict access to Sally\u2019s\nlocation on the basis of company and ser-\nvice type and company name and query\ntype, respectively.\nApplication privacy policies\nEach application that requests Sally\u2019s\nlocation information must also present a\nstatement of its privacy policy for valida-\ntors to check. Figure 2 shows an example\nprivacy policy for Sally\u2019s employer, and Fig-\nure 3 shows a policy for a local travel infor-\nmation service Sally uses. Both policies\nJANUARY\u2013MARCH 2003 PERVASIVEcomputing 63\nFigure 2. Sally\u2019s employer\u2019s statement of\nprivacy policy, illustrating indefinite\nretention of unsolicited information\naccess.\n<POLICY name=\u201cEmployer\u201d>\n<ENTITY>\n<DATA-GROUP>\n<DATA ref=\u201c#business.name\u201d>SallysEmployer.com<\/DATA>\n<DATA ref=\u201c#business.address\u201d>1 The Grindstone<\/DATA>\n<\/DATA-GROUP>\n<TYPE><profit><\/TYPE>\n<CERT><certified companies 6790><\/CERT>\n<\/ENTITY>\n<DISPUTES-GROUP>\n<DISPUTES resolution-type=\u201cindependent\u201d\nservice=\u201chttp:\/\/www.SallysEmployer.com\u201d\nverification=\u201cSallysEmployer.com\u201d\nshort-description=\u201cFor disputes please contact the management.\u201d>\n<REMEDIES><correct\/><\/REMEDIES>\n<\/DISPUTES>\n<\/DISPUTES-GROUP>\n<STATEMENT>\n<CONSEQUENCE><consequence.data><\/CONSEQUENCE>\n<PURPOSE><other-purpose><\/PURPOSE>\n<RECIPIENT><ours><\/RECIPIENT>\n<RETENTION><indefinitely><\/RETENTION>\n<REQUEST-INITIATION><unsolicited><\/REQUEST-INITIATION>\n<\/STATEMENT>\n<\/POLICY>\nFigure 3. Sample policy for a local\ninformation service that operates on a\nnonprofit basis and does not retain any of\nthe location information it obtains.\n<POLICY name=\u201cEmployer\u201d>\n<ENTITY>\n<DATA-GROUP>\n<DATA ref=\u201c#business.name\u201d>Tucson Happy-Travel Service<\/DATA>\n<DATA ref=\u201c#business.address\u201d>Tucson, AZ<\/DATA>\n<\/DATA-GROUP>\n<TYPE><nonprofit><\/TYPE>\n<CERT><certified companies 6380><\/CERT>\n<\/ENTITY>\n<DISPUTES-GROUP>\n<DISPUTES resolution-type=\u201cindependent\u201d\nservice=\u201chttp:\/\/www.thts.com\u201d\nverification=\u201cthts.com\u201d\nshort-description=\u201cFor disputes please contact the national travel service arbitration scheme.\u201d>\n<REMEDIES><correct\/><\/REMEDIES>\n<\/DISPUTES>\n<\/DISPUTES-GROUP>\n<STATEMENT>\n<CONSEQUENCE><consequence.data><\/CONSEQUENCE>\n<PURPOSE><info><\/PURPOSE>\n<RECIPIENT><ours><\/RECIPIENT>\n<RETENTION><no-retention><\/RETENTION>\n<REQUEST-INITIATION><unsolicited><\/REQUEST-INITIATION>\n<\/STATEMENT>\n<\/POLICY>contain information specified using the\nbasic P3P vocabulary and our extensions.\nPolicies for the other applications take sim-\nilar form.\nW\ne are currently implement-\ning the system described in\nthis article as part of our\nongoing research into tech-\nnologies to help create deployable perva-\nsive systems\u2014that is, systems that can be\ndeployed outside the confines of the labo-\nratory. We will use this implementation to\nsupport two application-oriented projects.\nThe first, a series of extensions to the Lan-\ncaster Guide tourist system,5is designed to\nallow individual users to create their own\ncontent for Guide. To explore user reac-\ntion to the tension between sharing their\ninformation and protecting their privacy,\nwe will allow users to choose from a series\nof privacy options. The second application-\noriented project, a system for pervasive\nhealth care based on mobile devices and\nGrid technologies, will use the privacy sys-\ntem to help reassure patients of the privacy\nof their medical data. In both cases, we are\ninterested in how users react to privacy\nissues and, in particular, whether our sys-\ntem allows users to restrict the dissemina-\ntion of their information according to their\nwishes.\nREFERENCES\n1. M. Weiser and J.S. Brown, Designing Calm\nTechnology, white paper, Dec. 1995; http:\/\/\nnano.xerox.com\/weiser\/calmtech\/calmtech.\nhtm.\n2. A. Jacobson et al., \u201cLocServ\u2014A Unifying\nLocation Service,\u201d submitted for publica-\ntion, 2002.\n3. M. Langheinrich, \u201cPrivacy by Design\u2014\nPrinciples of Privacy-Aware Ubiquitous Sys-\ntems,\u201d  Proc. Ubicomp, LCNS 2201,\nSpringer-Verlag, 2001, pp. 273\u2013291.\n4. A. Harter et al., \u201cThe Anatomy of a Con-\ntext-Aware Application,\u201d Proc. 5th Ann.\nACM\/IEEE Int\u2019l Conf. Mobile Computing\nand Networking (Mobicom), ACM Press,\n1999, pp. 59\u201368.\n5. K. Cheverst et al., \u201cExperiences of Devel-\noping and Deploying a Context-Aware\nTourist Guide: The Lancaster Guide Pro-\nject,\u201d  Proc. 6th Ann. ACM\/IEEE Int\u2019l\nConf. Mobile Computing and Networking\n(Mobicom), ACM Press, 2000, pp. 20\u201331.\nFor more information on this or any other comput-\ning topic, please visit our Digital Library at http:\/\/\ncomputer.org\/publications\/dlib.\n64 PERVASIVEcomputing http:\/\/computer.org\/pervasive\nSECURITY & PRIVACY\nthe AUTHORS\nGinger Myles is a PhD stu-\ndent in the Computer Sci-\nence Department at the \nUniversity of Arizona. Her\nresearch interests include\nprivacy and security in ubi-\nquitous computing and soft-\nware protection. She received\nher BA in mathematics from Beloit College in\nWisconsin. Contact her at the Dept. of Com-\nputer Science, Univ. of Arizona, Gould-Simpson\n721, PO Box 210077, Tucson, AZ 85721-0077;\nmylesg@cs.arizona.edu.\nAdrian Friday is a lecturer\nin the Department of Com-\nputer Science at Lancaster\nUniversity, UK, and an active\nmember of the Distributed\nMultimedia Research Group.\nHis research interests include\ndistributed-system support\nfor mobile, context-sensitive, and ubiquitous\ncomputing. He received a BSc from the Univer-\nsity of London and a PhD from Lancaster Uni-\nversity, both in computer science. He is a mem-\nber of the ACM, the IEEE, and the BCS. Contact\nhim at the Computing Dept., Faculty of Applied\nSciences, Lancaster Univ., Bailrigg, Lancashire\nLA1 4YR, UK; adrian@comp.lancs.ac.uk.\nNigel Davies is a professor\nof computer science at Lan-\ncaster University and an\nassociate professor of com-\nputer science at the Univer-\nsity of Arizona. His research\ninterests include systems\nsupport for mobile and per-\nvasive computing. Davies focuses in particular\non creating deployable systems that can be\nevaluated using end users. Davies holds a BSc\nand a PhD in computer science, both from Lan-\ncaster University. He is an associate editor of\nIEEE Transactions on Mobile Computing and IEEE\nPervasive Computing. Contact him at Comput-\ning Dept., Faculty of Applied Sciences, Lancaster\nUniv., Bailrigg, Lancashire LA1 4YR, UK; nigel@\ncomp.lancs.ac.uk.\nR\nE\nS\nU\nB\nS\nC\nR\nI\nB\nE\n \nN\nO\nW\n!\nR\nE\nS\nU\nB\nS\nC\nR\nI\nB\nE\n \nN\nO\nW\n!\nIEEE Pervasive Computing\ndelivers the latest peer-reviewed\ndevelopments in pervasive,\nmobile, and ubiquitous\ncomputing and acts as a catalyst\nfor realizing the vision of\npervasive (or ubiquitous)\ncomputing, described by Mark\nWeiser nearly a decade ago. \nIf you haven\u2019t renewed your\nsubscription, visit\nhttp:\/\/computer.org\/subscribe\nor contact our Customer Service\ndepartment:\n+1 800 272 6657\ntoll-free in the US and Canada\n+1 714 821 8380 phone\n+1 714 821 4641 fax"}
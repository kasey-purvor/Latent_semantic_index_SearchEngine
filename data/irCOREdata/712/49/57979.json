{"doi":"10.1016\/j.agrformet.2009.05.002","coreId":"57979","oai":"oai:nora.nerc.ac.uk:9438","identifiers":["oai:nora.nerc.ac.uk:9438","10.1016\/j.agrformet.2009.05.002"],"title":"The REFLEX project: Comparing different algorithms and implementations for the inversion of a terrestrial ecosystem model against eddy covariance data","authors":["Fox, Andrew","Williams, Mathew","Richardson, Andrew D.","Cameron, David","Gove, Jeffrey H.","Quaife, Tristan","Ricciuto, Daniel","Reichstein, Markus","Tomelleri, Enrico","Trudinger, Cathy M.","Van Wijk, Mark T."],"enrichments":{"references":[],"documentType":{"type":0.8888888889}},"contributors":[],"datePublished":"2009","abstract":"We describe a model-data fusion (MDF) inter-comparison project (REFLEX), which compared various algorithms for estimating carbon (C) model parameters consistent with both measured carbon fluxes and states and a simple C model. Participants were provided with the model and with both synthetic net ecosystem exchange (NEE) of CO2 and leaf area index (LAI) data, generated from the model with added noise, and observed NEE and LAI data from two eddy covariance sites. Participants endeavoured to estimate model parameters and states consistent with the model for all cases over the two years for which data were provided, and generate predictions for one additional year without observations. Nine participants contributed results using Metropolis algorithms, Kalman filters and a genetic algorithm. For the synthetic data case, parameter estimates compared well with the true values. The results of the analyses indicated that parameters linked directly to gross primary production (GPP) and ecosystem respiration, such as those related to foliage allocation and turnover, or temperature sensitivity of heterotrophic respiration, were best constrained and characterised. Poorly estimated parameters were those related to the allocation to and turnover of fine root\/wood pools. Estimates of confidence intervals varied among algorithms, but several algorithms successfully located the true values of annual fluxes from synthetic experiments within relatively narrow 90% confidence intervals, achieving >80% success rate and mean NEE confidence intervals <110 gC m\u22122 year\u22121  for the synthetic case. Annual C flux estimates generated by participants generally agreed with gap-filling approaches using half-hourly data. The estimation of ecosystem respiration and GPP through MDF agreed well with outputs from partitioning studies using half-hourly data. Confidence limits on annual NEE increased by an average of 88% in the prediction year compared to the previous year, when data were available. Confidence intervals on annual NEE increased by 30% when observed data were used instead of synthetic data, reflecting and quantifying the addition of model error. Finally, our analyses indicated that incorporating additional constraints, using data on C pools (wood, soil and fine roots) would help to reduce uncertainties for model parameters poorly served by eddy covariance data","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/57979.pdf","fullTextIdentifier":"http:\/\/nora.nerc.ac.uk\/9438\/2\/N009438JA.pdf","pdfHashValue":"72c47822c0ac7f9735e220bb9a1cd655711fcee2","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:nora.nerc.ac.uk:9438<\/identifier><datestamp>\n      2014-09-05T11:43:29Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/9438\/<\/dc:relation><dc:title>\n        The REFLEX project: Comparing different algorithms and implementations for the inversion of a terrestrial ecosystem model against eddy covariance data<\/dc:title><dc:creator>\n        Fox, Andrew<\/dc:creator><dc:creator>\n        Williams, Mathew<\/dc:creator><dc:creator>\n        Richardson, Andrew D.<\/dc:creator><dc:creator>\n        Cameron, David<\/dc:creator><dc:creator>\n        Gove, Jeffrey H.<\/dc:creator><dc:creator>\n        Quaife, Tristan<\/dc:creator><dc:creator>\n        Ricciuto, Daniel<\/dc:creator><dc:creator>\n        Reichstein, Markus<\/dc:creator><dc:creator>\n        Tomelleri, Enrico<\/dc:creator><dc:creator>\n        Trudinger, Cathy M.<\/dc:creator><dc:creator>\n        Van Wijk, Mark T.<\/dc:creator><dc:description>\n        We describe a model-data fusion (MDF) inter-comparison project (REFLEX), which compared various algorithms for estimating carbon (C) model parameters consistent with both measured carbon fluxes and states and a simple C model. Participants were provided with the model and with both synthetic net ecosystem exchange (NEE) of CO2 and leaf area index (LAI) data, generated from the model with added noise, and observed NEE and LAI data from two eddy covariance sites. Participants endeavoured to estimate model parameters and states consistent with the model for all cases over the two years for which data were provided, and generate predictions for one additional year without observations. Nine participants contributed results using Metropolis algorithms, Kalman filters and a genetic algorithm. For the synthetic data case, parameter estimates compared well with the true values. The results of the analyses indicated that parameters linked directly to gross primary production (GPP) and ecosystem respiration, such as those related to foliage allocation and turnover, or temperature sensitivity of heterotrophic respiration, were best constrained and characterised. Poorly estimated parameters were those related to the allocation to and turnover of fine root\/wood pools. Estimates of confidence intervals varied among algorithms, but several algorithms successfully located the true values of annual fluxes from synthetic experiments within relatively narrow 90% confidence intervals, achieving >80% success rate and mean NEE confidence intervals <110 gC m\u22122 year\u22121  for the synthetic case. Annual C flux estimates generated by participants generally agreed with gap-filling approaches using half-hourly data. The estimation of ecosystem respiration and GPP through MDF agreed well with outputs from partitioning studies using half-hourly data. Confidence limits on annual NEE increased by an average of 88% in the prediction year compared to the previous year, when data were available. Confidence intervals on annual NEE increased by 30% when observed data were used instead of synthetic data, reflecting and quantifying the addition of model error. Finally, our analyses indicated that incorporating additional constraints, using data on C pools (wood, soil and fine roots) would help to reduce uncertainties for model parameters poorly served by eddy covariance data.<\/dc:description><dc:publisher>\n        Elsevier<\/dc:publisher><dc:date>\n        2009<\/dc:date><dc:type>\n        Publication - Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/9438\/1\/N009438PP.pdf<\/dc:identifier><dc:identifier>\n         \n\n  Fox, Andrew; Williams, Mathew; Richardson, Andrew D.; Cameron, David; Gove, Jeffrey H.; Quaife, Tristan; Ricciuto, Daniel; Reichstein, Markus; Tomelleri, Enrico; Trudinger, Cathy M.; Van Wijk, Mark T..  2009  The REFLEX project: Comparing different algorithms and implementations for the inversion of a terrestrial ecosystem model against eddy covariance data.   Agricultural and Forest Meteorology, 149. 1597-1615.  https:\/\/doi.org\/10.1016\/j.agrformet.2009.05.002 <https:\/\/doi.org\/10.1016\/j.agrformet.2009.05.002>     \n <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1016\/j.agrformet.2009.05.002<\/dc:relation><dc:relation>\n        10.1016\/j.agrformet.2009.05.002<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/nora.nerc.ac.uk\/id\/eprint\/9438\/","http:\/\/dx.doi.org\/10.1016\/j.agrformet.2009.05.002","10.1016\/j.agrformet.2009.05.002"],"year":2009,"topics":[],"subject":["Publication - Article","PeerReviewed"],"fullText":" \nCopyright \u00a9 2009 Elsevier B.V. \n \nThis version available http:\/\/nora.nerc.ac.uk\/9438\/  \n \n \nNERC has developed NORA to enable users to access research outputs \nwholly or partially funded by NERC. Copyright and other rights for material \non this site are retained by the authors and\/or other rights owners. Users \nshould read the terms and conditions of use of this material at \nhttp:\/\/nora.nerc.ac.uk\/policies.html#access  \n \n \nThis document is the author\u2019s final manuscript version of the journal \narticle, incorporating any revisions agreed during the peer review \nprocess. Some differences between this and the publisher\u2019s version \nremain. You are advised to consult the publisher\u2019s version if you wish \nto cite from this article. \n \nwww.elsevier.com\/  \n \n \n \nArticle (refereed) \n \n \n \nFox, Andrew; Williams, Mathew; Richardson, Andrew D.; Cameron, \nDavid; Gove, Jeffrey H.; Quaife, Tristan; Ricciuto, Daniel; \nReichstein, Markus; Tomelleri, Enrico; Trudinger, Cathy M.; Van \nWijk, Mark T.. 2009 The REFLEX project: Comparing different \nalgorithms and implementations for the inversion of a terrestrial \necosystem model against eddy covariance data. Agricultural and \nForest Meteorology, 149. 1597-1615.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nContact CEH NORA team at  \nnoraceh@ceh.ac.uk \n \n \n \nThe NERC and CEH  trade marks and logos (\u2018the Trademarks\u2019) are registered trademarks of NERC in the UK and \nother countries, and may not be used without the prior written consent of the Trademark owner. \nFox, Williams et al. \n1 \nUsing model-data fusion to characterise confidence in 1 \nparameterizations, analyses and forecasts of terrestrial C dynamics 2 \n 3 \nAndrew Fox\n1\n, Mathew Williams\n2*\n, Andrew D. Richardson\n3\n, David Cameron\n4\n, Jeffrey H. 4 \nGove\n5\n, Tristan Quaife\n6\n, Daniel Ricciuto\n7\n, Markus Reichstein\n8\n, Enrico Tomelleri\n8\n, Cathy 5 \nTrudinger\n9\n and Mark T. Van Wijk\n10\n 6 \n 7 \n1\n School of Applied Maths, Centre for Terrestrial Carbon Dynamics, University of Sheffield, 8 \nSheffield, UK 9 \n2\n School of GeoSciences, Centre for Terrestrial Carbon Dynamics, University of Edinburgh, 10 \nEdinburgh, UK 11 \n3\n Complex Systems Research Center, University of New Hampshire, Durham, NH, USA 12 \n4\n Centre for Ecology and Hydrology, Bush Estate, Penicuik, Midlothian, UK 13 \n5\n USDA Forest Service, Northern Research Station, Durham, NH, USA 14 \n6\n Centre for Terrestrial Carbon Dynamics, Department of Geography, UCL, London 15 \n6\n Oak Ridge National Laboratory, Oak Ridge, TN, USA 16 \n8 \nMax Planck Institute for Biogeochemistry, Jena, Germany 17 \n9\n CSIRO Marine and Atmospheric Research, Centre for Australian Weather and Climate 18 \nResearch, Aspendale, Victoria, Australia 19 \n10\n Wageningen University, Plant Sciences, The Netherlands 20 \n 21 \nRunning title: Intercomparison of carbon dynamics model-data fusion techniques 22 \nKey words: Data assimilation, metropolis, carbon cycle, ecosystem modelling, Monte Carlo, 23 \nKalman Filter, eddy covariance, Reflex project 24 \nFox, Williams et al. \n2 \n* Correspondence to Mathew Williams, mat.williams@ed.ac.uk, +44 131 667 8631 (tel) +44 25 \n131 662 0478 (fax) 26 \n27 \nFox, Williams et al. \n3 \nAbstract 28 \nWe describe a model-data fusion inter-comparison project (REFLEX), aimed at comparing 29 \nthe strengths and weaknesses of various model-data fusion algorithms for estimating 30 \nparameters, states and fluxes of a simple ecosystem carbon cycle model. Participants were 31 \nprovided with both synthetic net ecosystem exchange (NEE) of CO2 and leaf area index (LAI) 32 \ndata, generated from a simple C model with added noise, and observed NEE and LAI data 33 \nfrom two eddy covariance observations sites within FLUXNET. Participants endeavoured to 34 \nestimate model parameters and states for all cases over the two years for which data were 35 \nprovided, and generate predictions for one additional year without observations. Nine 36 \nparticipants contributed results using Metropolis algorithms, Kalman filters and a genetic 37 \nalgorithm. For the synthetic data case, parameter estimates compared well with the true 38 \nvalues. The results of the analyses indicated that parameters linked directly to gross primary 39 \nproduction and ecosystem respiration, such as those related to foliage allocation and turnover, 40 \nor temperature sensitivity of heterotrophic respiration, were best constrained and 41 \ncharacterised. Estimates of confidence intervals varied among algorithms, but several 42 \nalgorithms successfully located the true values of annual fluxes from synthetic experiments 43 \nwithin relatively narrow 90% confidence intervals, achieving >80% success rate and mean 44 \nNEE confidence intervals <110 gC m\n-2\n yr\n-1\n for the synthetic case. For the observed data case, 45 \nthe annual C flux estimates generally agreed with gap-filling approaches using half-hourly 46 \ndata. The estimation of gross fluxes, by partitioning daily NEE data, agreed well with outputs 47 \nfrom earlier studies using half-hourly data. The study was revealing in that confidence limits 48 \non annual NEE was 88% larger in the prediction year, than in the previous year, when data 49 \nwere available. Confidence intervals on annual NEE also increased by 30% when observed 50 \ndata were used instead of synthetic data, reflecting and quantifying the addition of model 51 \nerror. Finally, our analyses indicated that incorporating additional constraints, using data on 52 \nFox, Williams et al. \n4 \nlarge, slow C pools (wood and soil) would help to reduce uncertainties for model parameters 53 \npoorly served by eddy covariance data. 54 \n55 \nFox, Williams et al. \n5 \nIntroduction 56 \nThe carbon cycle is a critical determinant of the Earth\u201fs climate, but the carbon-climate 57 \nrelationship is complicated by feedbacks between the climate, the terrestrial biosphere and the 58 \natmosphere (Heimann and Reichstein 2008). Recent model inter-comparisons have shown 59 \nthat there are significant differences among model predictions of the future C cycle at decadal 60 \ntimescales (Friedlingstein et al. 2006). The causes of these differences among models are not 61 \nwell understood, but are likely to be related to subtle differences in process representation, 62 \nwhich can have significant impacts over longer time scales.  63 \nModel-data comparison provides an opportunity to highlight areas (in space or time) of 64 \npoor process representation, and to guide model improvement. Thus, the modelling 65 \ncommunity is now seeking to test its terrestrial ecosystem models against the growing array of 66 \nobservations (Bonan 2008). One of the critical datasets to be used in evaluating ecosystem 67 \nmodels is the FLUXNET database (Baldocchi et al. 2001). FLUXNET is an international 68 \nnetwork of eddy covariance (EC) flux measurement towers. There are data sets from hundreds 69 \nof sites worldwide, some with more than a decade of data collection. However, these data are 70 \nassociated with uncertainties and complications. There are gaps in time series that must be 71 \nfilled to obtain integrated (daily to annual) flux sums (Moffat et al. 2007). Also large areas of 72 \nthe globe are poorly sampled, and measurements are affected by systematic and random errors 73 \n(Lasslop et al. 2008, Richardson et al. 2008), both of which can be large. EC towers measure 74 \nnet ecosystem exchanges (NEE) of CO2, meaning that the underlying processes of 75 \nphotosynthesis (GPP) and ecosystem respiration (Re) are not directly measured during 76 \ndaytime (Desai et al. 2008). 77 \nA meaningful comparison between models and data is complicated by the need to assess 78 \nand account for both model and observational errors. Thus, the probability of a model being 79 \ncorrect should be assessed by taking into account observational uncertainties. When 80 \nFox, Williams et al. \n6 \ncomparing a model against multiple datasets, then weighting the confidence one has in the 81 \ndifferent observations becomes critical (Raupach et al. 2005). Model uncertainty is also an 82 \nimportant factor in any comparison with data. Models may be uncertain because of how they 83 \nrepresent key processes, how initial conditions are set, or because their parameters are poorly 84 \ndetermined. Separating these causes of uncertainty is important for guiding model 85 \ndevelopment.  86 \nModel-data fusion approaches, previously used mainly in hydrology and weather 87 \nforecasting, are now being used more frequently by the terrestrial C community (Raupach et 88 \nal. 2005). Model-data fusion (MDF) combines models with observations, taking account of 89 \nmodel and observational uncertainties. In theory, MDF provides a means to cope with the 90 \nproblems arising from incomplete and noisy observational data, and uncertainty in model 91 \nprocesses, initial states and parameters. MDF combines models with observations, and 92 \nestimates of their uncertainties, to produce estimates of system dynamics with confidence 93 \nintervals (Williams et al. 2005) and to determine model parameterizations consistent with 94 \ndata. We refer to these outputs of MDF schemes as \u201canalyses\u201d hereafter. MDF can be used as 95 \na developmental tool to test hypotheses and then improve model structural representation 96 \n(Sacks et al. 2007, Stockli et al. 2008, Moore et al. in press). However, in practice, MDF 97 \nresults are conditional both on the model and data used, as well as associated uncertainties 98 \nand assumptions made about uncertainties.  99 \nThe capabilities and weaknesses of the various existing MDF approaches remain poorly 100 \nunderstood. One recent study, the OptIC experiment, used pseudo-data from a highly 101 \nsimplified test model with 4 parameters to compare parameter estimation methods (Trudinger 102 \net al. 2007). OptIC found different methods equally successful, but that the choice of the cost 103 \nfunction (quantifying the model-data mismatch) caused the most variation in the estimated 104 \nparameters. OptIC also demonstrated that the effort expended and experience of the user was 105 \nFox, Williams et al. \n7 \na factor in successful solutions. However, OptIC did not use observed data, nor did it test state 106 \nestimation or model forecast capabilities. With observed data, MDF is complicated by 107 \nobservational and model error and bias. 108 \nHere we describe the REgional FLux Estimation eXperiment. REFLEX is a model-data 109 \nfusion inter-comparison project, aimed at comparing the strengths and weaknesses of various 110 \nMDF algorithms for estimating carbon model parameters and carbon fluxes and states. 111 \nREFLEX participants fuse an existing C model with observed and synthetic daily NEE data. 112 \nThe key question addressed here is: what are the confidence intervals on model parameters 113 \ncalibrated from eddy covariance (EC) data, and on model analyses and estimates and 114 \npredictions of net C exchange and carbon stocks over multiple years? The experiment has an 115 \nexplicit focus on how different algorithms and protocols quantify the confidence intervals on 116 \nparameter estimates and model forecasts, given the same C model and a range of datasets.   117 \nIn generating analyses and predictions of C dynamics with confidence intervals, resulting 118 \nerror can be attributed to a combination of factors (Liu and Gupta 2007). Errors may be 119 \nrelated to the particular MDF algorithm employed (for instance, does the algorithm find local 120 \nor global minima)  - the algorithmic error - and the choice of subjective components of the 121 \nMDF process, including prior assumptions about the probability distributions of parameters 122 \nand initial conditions \u2013 the user error. Error may also be related to the observations, as a 123 \nfunction of instrumental precision. And models may contain errors, due to misrepresented or 124 \nmissing fundamental processes. Driver error (i.e. meteorological forcing) is likely to be small 125 \nin local studies, but is increasingly important at coarser scales due to representativeness, the 126 \nextent to which a point measurement can represent the surrounding area. The structure of 127 \nReflex allowed investigation of several of these components of error. 128 \nIn REFLEX, participants first used synthetic data, generated from the specified C model with 129 \nnoise and gaps added, to explore the capabilities of a range of users and algorithms to retrieve 130 \nFox, Williams et al. \n8 \nparameters and states consistent with the C model. This synthetic experiment dealt with 131 \nobservational and algorithmic error, and user error including assumptions related to initial 132 \nconditions and parameter priors. There was no model error or driver error. REFLEX 133 \nparticipants then went on to fuse data from eddy covariance systems and local measurements 134 \nof leaf area index (LAI) with the C model. This exercise introduced model and, to a lesser 135 \nextent, driver error, because the model used does not perfectly describe the forest ecosystem, 136 \nand because meteorological observations may contain small errors. Finally, REFLEX 137 \nparticipants used the C model in a prognostic, rather than diagnostic, mode. One year of daily 138 \ndriver data were provided to produce forecasts of C dynamics, using parameters generated in 139 \nthe diagnoses, and the forecasts were tested against withheld data, both synthetic and 140 \nobserved. 141 \nWhat is novel in this study is an explicit focus on comparing how an ensemble of MDF 142 \nalgorithms perform in terms of estimating C model states and parameters, and the 143 \nuncertainties on these quantities. By using a single common model, and both synthetic and 144 \nobserved data sets, and diagnostic and prognostic tests, we are able to generate insights into 145 \ncurrent capabilities for assessing and forecasting ecosystem C dynamics using the model-data 146 \nfusion approach  147 \nMethods 148 \nModel Description 149 \nThe requirements for the Reflex C model included simplicity, a C mass balance, a daily time 150 \nstep, and vegetation and soil C pools with time constants covering days to decades. The 151 \nmodel outputs had to include daily NEE and LAI. We selected the Data Assimilation Linked 152 \nEcosystem Carbon (DALEC) model (Williams et al. 2005), originally designed for evergreen 153 \nforests, and a modified version (DALEC-D) for deciduous forests (Figure 1). DALEC is a 154 \nFox, Williams et al. \n9 \nsimple box model of carbon pools connected via fluxes running at a daily time-step. For the 155 \nevergreen model there are five C pools representing foliage (Cf), woody stems and coarse 156 \nroots (Cw), and fine roots (Cr) along with fresh leaf and fine root litter (Clit) and soil organic 157 \nmatter and coarse woody debris (Csom). In the deciduous model there is an additional labile 158 \npool (Clab). The following assumptions were made to determine the fluxes between the C 159 \npools: 160 \n1. All C fixed during a day is expended either in autotrophic respiration or else allocated to 161 \none of the three plant tissue pools, Cf, Cw or Cr.  162 \n2. Autotrophic respiration is a constant fraction of the C fixed during a day (Waring et al. 163 \n1998). 164 \n3. Allocation fractions to vegetation pools are donor-controlled functions which have 165 \nconstant rate parameters. 166 \n4. For the deciduous model, the timing of initial leaf-out is controlled by a simple growing 167 \ndegree day accumulation, and leaf-fall by a minimum temperature threshold. The 168 \nmaximum amount of C that can be allocated to leaves is also limited by a parameter 169 \n(cfmax) 170 \n5. All C losses are via mineralization (i.e. no dissolved losses). 171 \nThe aggregated canopy model (ACM) (Williams et al. 1997) is used to calculate daily GPP in 172 \nDALEC. ACM is a \u201ebig leaf\u201f, daily time-step model that estimates GPP using a simple 173 \naggregated set of equations operating on cumulative or average values of leaf area index 174 \n(LAI), foliar nitrogen, total daily irradiance, minimum and maximum daily temperature, day 175 \nlength, atmospheric CO2 concentration, water potential gradient (\u03c8d) and total soil-plant 176 \nhydraulic resistance (rtot). ACM contains 10 parameters which have been calibrated using a 177 \nfine-scale model (the Soil-Plant-Atmosphere model (SPA), (Williams et al. 1996) across a 178 \nwide range of driving variables producing a \u201euniversal\u201f parameter set which maintains the 179 \nFox, Williams et al. \n10 \nessential behaviour of the fine-scale model but at a much reduced complexity. The sole ACM 180 \nparameter included in the optimisation is the nitrogen use efficiency parameter (a1), which 181 \ndetermines the maximum rate of carboxylation per g foliar N.  For the purposes of this 182 \nexperiment the sites were treated as being non-drought stressed. Those variables related to 183 \ndrought effects in ACM, specifically \u03c8d and rtot, were given a fixed value in accordance with 184 \nthis assumption. 185 \nDatasets 186 \nFour datasets (two synthetic and two based on actual measurements) were provided to 187 \nparticipants. Each dataset included a variety of information (Table 1), including continuous 188 \ndaily meteorological drivers, intermittent NEE and LAI data, estimates of the initial values of 189 \nthe pools of soil organic matter and wood, and input data on leaf characteristics for the GPP 190 \nmodel (Table 2). Initial conditions for foliar, fine root, litter and labile C were not provided.  191 \nSynthetic datasets were generated for three years for an evergreen (EV-SYN) and deciduous 192 \n(DE-SYN) forest, using DALEC and DALEC-D model runs, with nominal parameters, and 193 \nmeteorological driver data selected from European eddy covariance flux tower sites. Gaps 194 \nwere introduced into the synthetic NEE and LAI data time series by thinning the model 195 \noutputs to match the data availability from the real data. Noise was added to the remaining 196 \nmodel outputs to reflect measurement error, by adding Gaussian errors with a variance of 0.5 197 \ng C m\n-2\n d\n-1\n for the NEE and 10% of the truth for the LAI.  Though the half hourly 198 \nmeasurements may have non-Gaussian errors, once you start aggregating at longer time scales 199 \nthe noise on the sum\/mean becomes Gaussian. Participants were provided with the first two 200 \nyears of synthetic  observations. 201 \nFor the observed data, the sites (Loobos, Netherlands and Hesse, France) and site-years 202 \n(2000-2) were selected on the basis of relatively long, continuous records of fluxes and site 203 \nmeteorology, good quality control, and little or no drought stress. The observed data included 204 \nFox, Williams et al. \n11 \neddy covariance (EC) data, LAI data, and local meteorological data from a deciduous broad-205 \nleaf forest (identified as DE-EC) and an evergreen needle-leaf forest (EV-EC). Daily NEE 206 \nwas calculated by summing half-hourly observations, but only if >43 of the possible 48 207 \nobservations passed quality control. Missing data were filled by the daily mean of remaining 208 \ndata. It is possible that some small bias was introduced by this simple gap-filling, but for the 209 \npurposes of this study such impacts were deemed insignificant. Typical data coverage was 20-210 \n30% of days. LAI data were sparse, usually collected on just a few days. Gap-filled flux data 211 \nwere not used in this experiment, but complete daily meteorological data were required to 212 \ndrive the model, and so gap filled weather data were used. All data were obtained via the 213 \nFLUXNET site (www.fluxnet.ornl.gov), from relevant, site specific literature and\/or from site 214 \nPIs. Three sequential years of data were assembled, of which the first two years were 215 \nprovided to participants. The source of the EC data was withheld from participants. 216 \nExperiments 217 \nAll participants used DALEC and DALEC-D, the same models used to generate the synthetic 218 \ndata. The use of common reference models allowed direct comparison among MDF 219 \nalgorithms. Upper and lower bounds for the parameters of both deciduous and evergreen 220 \nversions of the model were provided (Table 3). These bounds were set broad to ensure a high 221 \nlikelihood that reasonable parameters were located in the EC experiments. Participants 222 \napplied the MDF algorithm of their choice to four experiments ( 223 \nTable 4). The first two experiments were diagnostic, testing parameter and state estimation 224 \nusing two years of incomplete daily NEE and LAI data, at both an evergreen and deciduous 225 \nsite. These data were either real, collected at a FLUXNET site (experiment 1) or artificial, 226 \nsynthesised from model output with added noise (experiment 2). The final two experiments 227 \nwere prognostic, testing forecast capability, again at the real sites (experiment 3) and the 228 \nartificial sites (experiment 4). Forecasts of daily C fluxes and pool dynamics were generated 229 \nFox, Williams et al. \n12 \nusing parameter distributions from the first two experiments, forced by a single extra year of 230 \nmeteorological data. The flux\/stock data, both observed and synthetic, for this third year were 231 \nwithheld for later assessment. 232 \nAlgorithms 233 \nA wide range of different MDF algorithms are currently applied (e.g. Raupach et al. 2005). 234 \nThey range from relatively simple Monte Carlo and grid-search approaches in which limited 235 \nnumbers of parameters can be estimated (Van Wijk and Bouten 2002, Williams et al. 2006); 236 \nlocal optimization algorithms like the Levenberg\u2013Marquardt algorithm or the Gauss-Newton 237 \nalgorithm (Janssen and Heuberger 1995, Trudinger et al. 2007, Wang et al. 2007, Van Wijk et 238 \nal. 2008); generic search algorithms that in principle can deal with large numbers of 239 \nparameters like Genetic Algorithms (Van Wijk and Bouten 2001); an algorithm based on the 240 \nMetropolis-Hastings algorithm (Metropolis et al. 1953) and using Markov Chain Monte Carlo 241 \nsamplers that recently has become popular (Vrugt et al. 2003, Braswell et al. 2005, Knorr and 242 \nKattge 2005, Van Oijen et al. 2005, Ricciuto et al. 2008); and finally algorithms like the 243 \nKalman filter that can combine parameter estimation with state updating ((Vrugt et al. 2005, 244 \nWilliams et al. 2005, Quaife et al. 2008, Trudinger et al. 2008). A key element in all of these 245 \napproaches is the quantification of the uncertainty of the parameters, which requires that 246 \nuncertainty in the measurements is quantified (Hagen et al. 2006, Richardson et al. 2006, 247 \nRichardson et al. 2008). 248 \nReflex was an open intercomparison experiment, so the algorithms employed were not 249 \nselected according to any criteria, rather they were dependent upon the community interest 250 \nand experience (Table 5). Many of the methods used Monte Carlo approaches based on the 251 \nMetropolis-Hastings algorithm or variants thereof. There were differences in the 252 \nimplementation, with various cost functions, uncertainty specifications and convergence tests 253 \nemployed. The cost function weights the difference between observations and simulated 254 \nFox, Williams et al. \n13 \nquantities, often using observation error estimates, and sometimes model error estimates. 255 \nThere was also a genetic algorithm approach, and an Ensemble Kalman Filter (EnKF). In two 256 \ncases a Metropolis approach was supplemented by a Kalman filter (one Unscented KF, one 257 \nEnKF). All the algorithms (bar the free-standing EnKF) used ~10\n5\n iterations to produce the 258 \nfull set of parameter and state estimates. Most of the algorithms assumed that prior parameter 259 \ndistributions were uniform across the range supplied. The use of a uniform prior suggests that 260 \nthe researcher has a prior belief that all setting of parameters within the range are equally 261 \nlikely. The users made a variety of assumptions about initial conditions for some state 262 \nvariables. 263 \nAnalyses 264 \nTo quantify and summarise these different approaches for parameter assessment, we 265 \ncomputed for each parameter two (EC) or three (SYN) relative-distance metrics, d1-d3. Here, 266 \nfor a given parameter, mx is algorithm x\u201fs best estimate of the parameter; CIx is\n \nthe width of 267 \nthe parameter\u201fs confidence interval for algorithm x; t is the true value of the parameter; pmax 268 \nand pmin are the pre-specified upper and lower limits on the parameter (Table 3);  is a 269 \nstandard deviation and  is a mean: 270 \nd1. Consistency among algorithms:  (m1,\u2026,m9)\/(pmax-pmin) 271 \nd2.  CI constrained by the data:  (CI1,\u2026,CI9)\/(pmax-pmin) 272 \nd3. Consistent with truth (SYN only): |t (m1,\u2026,m9)|\/(pmax-pmin) 273 \nThen the total distance is: D d1\n2 d2\n2 d3\n2  for SYN and \n2\n2\n2\n1 ddD  for EC datasets; the 274 \ncloser the value D is to zero, the better the parameter is estimated, according to this measure. 275 \nWe determined two further metrics to aid a comparison among algorithms of parameter 276 \nestimation capabilities, for the SYN cases only. Mean normalised parameter confidence 277 \nFox, Williams et al. \n14 \ninterval (d4) is similar to the d2 statistic but rates individual algorithm\u201fs mean 90% confidence 278 \nintervals across all parameters, normalised by the size of the parameter priors: 279 \nd4: n\npp\nCIn\ni ii\ni \/\n1 minmax\n  280 \nwhere CIi is\n \nthe width of the algorithm\u201fs 90% confidence interval for parameter x; n is the 281 \nnumber of parameters (11 for EV, 17 for DE), pmax i and pmin i are the pre-specified upper and 282 \nlower limits on each parameter prior.  283 \nThe metric for consistency with true parameter value (d5) is similar to the d3 statistic, but 284 \nagain rates consistency for an individual algorithm across all parameters: 285 \nd5. n\npp\nm\nt\nn\ni ii\ni \/\n1 minmax\n |t (m1,\u2026,mn)|\/(pmax-pmin) 286 \nwhere mx is parameter x\u201fs best estimate by the algorithm. 287 \n 288 \nResults 289 \nParameter estimation 290 \nEach algorithm produced sets of parameter estimates for each dataset in experiments 1 and 2, 291 \ndescribing a multi-dimensional probability density volume. Because of their high 292 \ndimensionality, these hyper-volumes are not easily described or visualised, so a range of 293 \nmetrics and methods are used. Firstly, we determined the \u201cbest\u201d parameter set estimate of 294 \neach algorithm (Figure 2), based on the minimum of the cost function (e.g. Metropolis 295 \nalgorithm) or the mean value of an ensemble (Ensemble Kalman filter). The best estimates 296 \nwere supplemented by estimates of the 90% confidence intervals on each parameter, 297 \ndetermined from the full spread of accepted parameters.  298 \nSome parameters were well constrained (Figure 2), so that the analysis resulted in a much 299 \nreduced spread in the parameter compared to the upper and lower bounds that defined the 300 \nFox, Williams et al. \n15 \nprior (Table 3). Conversely, some parameters were poorly constrained, with little reduction in 301 \nspread from the initial upper and lower bounds. In some cases there was consistency among 302 \nalgorithms in the estimates of the parameter best estimates, but not in others. For the SYN 303 \ndatasets only, it was possible to gauge how effectively the algorithms retrieved the true 304 \nparameter estimates.  305 \nThe parameter analysis for both synthetic data (Table 6) and eddy covariance data (Table 7) 306 \nrevealed that, for the both evergreen and deciduous models, turnover rate parameters such as 307 \nTs, Tl, and Tf, as well as the temperature parameter Et, were well estimated overall, across the 308 \nrange of methods. By comparison, the turnover rate parameters Td and Tw, as well as the 309 \nallocation parameter Fnrr, tended to be poorly estimated overall. In some cases the poor 310 \nestimates were scattered around the truth (Tw estimate in DE-SYN) while in others there was a 311 \nclear bias in the algorithms\u201f estimates (Tw estimate in EV-SYN). The allocation parameter Fnf 312 \nwas well-estimated for EV-SYN but biased in DE-SYN. Of those parameters used only in the 313 \ndeciduous model, Fll and Tlab were poorly estimated, whereas Flr was more successfully 314 \nestimated. 315 \nThere was a significant correlation of d1 distances between EC and SYN for EV (r=0.73, 316 \nP=0.01) but not DE (r=0.31, P=0.24). So the EV parameters that were consistently estimated 317 \n(across methods) were similar for synthetic and eddy covariance data, while this was not so 318 \nfor DE datasets, perhaps because of the greater number of parameters. There was a significant 319 \ncorrelation between EC and SYN d2 distances for both EV (r=0.87, P=0.0004) and DE (r = 320 \n0.84, P<0.0001). Thus parameters that were well constrained (low d2) by the synthetic data 321 \nwere well constrained by the eddy covariance data.  322 \nThere was a general trend for those algorithms with large parameter confidence intervals to 323 \nencompass a large fraction of true parameter values within their 90% confidence intervals 324 \n(Figure 3). For the DE case, three algorithms (E1, E2, M1) managed to generate relatively 325 \nFox, Williams et al. \n16 \nsmall and reliable confidence intervals. But the for EV case, none of the algorithms managed 326 \nto balance small confidence intervals with reliability. For the DE case, three algorithms (E1, 327 \nE2, M1) generated parameters that were most consistent with true values and also had the 328 \nsmallest confidence intervals. For the EV case there was no clear pattern among algorithms; 329 \nalthough E2 had the closest agreement with true parameters and the narrowest confidence 330 \nintervals, it had the smallest fraction of true parameters within the 90% CI, suggesting over-331 \nconfidence. 332 \nEigenvector analyses of the error covariance matrices were used to supplement the parameter 333 \nanalyses, and these suggested that the best constrained parameter was the turnover rate of 334 \nSOM, Ts. The next best constrained parameter identified was the temperature rate parameter, 335 \nEt. Turnover rate of foliage was well constrained for EV analyses. Allocation to and turnover 336 \nof roots were poorly constrained for EV analyses. The results for the DE eigenvector analyses 337 \nwere less clear, with differences between DE-EC and DE-SYN. Turnover rate of wood and 338 \nroots were least well constrained in DE-SYN, while the GDD threshold for leaf out and the 339 \nturnover rate of labile C were least well constrained in DE-EC. There was some variation in 340 \nthe eigenvectors from the different methods, due to variation in covariance matrices. Some 341 \nparameters seemed to be well constrained by some methods, but not by others. Comparison of 342 \neigenvectors with the distance metric d2 were largely, but not totally, consistent. Eigenvector 343 \nanalyses did not identify any consistent correlation features, apart from one between fraction 344 \nof GPP respired (Fg) and the NUE parameter, Pr. 345 \nFlux estimates \u2013 synthetic data 346 \nThe seasonal patterns of variation in NEE were generally well reproduced by most algorithms 347 \nacross all three years of each of the different  data sets (for example, Figure 4). For the 348 \nsynthetic datasets, where true values were known, daily NEE predictions were generally 349 \ngood. RMSE values ranged from 0.07-0.55 gC m\n-2\n d\n-1\n, with a mean over all algorithms and 350 \nFox, Williams et al. \n17 \nyears of 0.20 gC m\n-2\n d\n-1\n. These error values compared well with the noise added to the truth in 351 \norder to generate synthetic observations. Partitioning synthetic NEE into GPP and Re was 352 \ngenerally successful, with mean RMSE values over all algorithms of 0.6 gC m\n-2\n d\n-1\n in both 353 \ncases. There was no evidence that best-fit or mean predictions of fluxes deteriorated in year 3, 354 \nthe prognostic period when no data were assimilated. 355 \nFlux estimates \u2013 observed data 356 \nFor the eddy covariance (EC) datasets, the algorithms\u201f predictions were compared to 357 \nobserved NEE. In years 1 and 2, when observations were provided to participants, RMSEs 358 \nvaried from 0.7-1.8 gC m\n-2\n d\n-1\n (DE) or 0.6-0.9 gC m\n-2\n d\n-1\n (EV), with a mean value of 1.3 gC 359 \nm\n-2\n d\n-1\n for DE datasets and 0.7 gC m\n-2\n d\n-1\n for EV. In year 3, when observations were not 360 \nprovided to participants, RMSEs varied from 1.1-2.3 gC m\n-2\n d\n-1\n (DE) or 1.3-1.7 gC m\n-2\n d\n-1\n 361 \n(EV), with a mean value of 1.5 gC m\n-2\n d\n-1\n for both EC and DE datasets ( 362 \nTable 9). Thus the best NEE estimates of the algorithms tended to agree less well in the 363 \nprognostic period (year 3) compared to the assimilation period (years 1-2), though this was 364 \nmost striking for the evergreen (EV) case in this study.  365 \nFlux confidence intervals \u2013 daily data 366 \nThere was less agreement among algorithms in the assessment of 90% confidence intervals 367 \n(CI) on daily fluxes (Figure 4) than in the assessment of best estimates. There were 368 \ndifferences in confidence interval estimates both in magnitudes and in temporal variability 369 \namong algorithms. For instance, the mean daily 90% CI varied among algorithms from 0.35  - 370 \n1.92 gC m\n-2\n d\n-1\n in DE-SYN and 0.29 \u2013 2.49 gC m-2 d-1 in DE-EC. Algorithm confidence 371 \nintervals typically had large excursions during spring leaf out for DE, but the magnitude of 372 \nthese excursions varied (Figure 4). 373 \nFox, Williams et al. \n18 \nWe tested whether the 90% CI on daily analyses (years 1 and 2) and predictions (year 3) 374 \nencompassed the truth from the synthetic datasets for NEE, GPP and Re for all years, and for 375 \nobserved NEE in year 3 for the EC datasets. The days of each year which passed this test 376 \nwere counted. We expected that 85-95% of the days would pass, roughly consistent with the 377 \nmagnitude of the confidence interval, 90%. For the synthetic experiments (NEE tests are 378 \nshown in  379 \nTable 8) this was rarely the case. In some cases the fraction was 100%, which indicates that 380 \nthe daily CI were likely set too large. In other cases, the fractions were <85% suggesting that 381 \nthe CI were too small or the predictions were biased. For the eddy covariance datasets in year 382 \n3, the majority of algorithms\u201f confidence intervals on daily NEE were too narrow, with an 383 \naverage of only 40% (DE) or 20% (EV) of the observed year 3 data lying within the 90% 384 \nconfidence interval ( 385 \nTable 9). This result suggests the algorithms were over-confident in the assessments of daily 386 \nfluxes. 387 \nFlux confidence intervals \u2013 annual sums 388 \nA comparison of 90% confidence intervals on annual estimates of NEE, GPP and Re for all 389 \nyears revealed differences of up to an order of magnitude in width (Figure 5, Figure 6, Figure 390 \n7). There was no clear relationship between size of CI and algorithm type \u2013 for instance, M1 391 \nand M2 tended to have small CI compared to M3 and M4, although all used Metropolis 392 \nalgorithms. This result makes clear the importance of the user in determining the confidence 393 \ninterval, rather than the algorithm itself. The mean confidence interval size for NEE (124 gC 394 \nm\n-2\n yr\n-1\n) was ~3-fold smaller than those for GPP (389 gC m\n-2\n yr\n-1\n) and Re (387 gC m\n-2\n yr\n-1\n). A 395 \ncomparison of the mean 90% confidence intervals on annual NEE estimates (Table 10) 396 \nindicated that CI were largest during year 3, the prediction period, and smallest in year 2. Of 397 \nthe 36 cases (4 datasets  9 algorithms), 34 had larger confidence intervals on year 1 than 398 \nFox, Williams et al. \n19 \nyear 2, and 35 had larger CI on year 3 than year 2, so this pattern was general across 399 \nalgorithms and datasets. Averaged over all cases, the 90% CI in the prediction period (year 3) 400 \nwere 88% larger than in the second year of the assimilation period (year 2).  Patterns were 401 \nsimilar in comparison between outputs from observed and synthetic datasets. However, mean 402 \n90% CI across all algorithms were ~31% larger for EC datasets than for SYN datasets. 403 \nAmong algorithms, the increase in 90% CI on EC datasets compared to SYN datasets ranged 404 \nfrom 0% (E1) to 100% (E2). 405 \nTesting annual flux estimates and confidence intervals 406 \nAnnual flux outputs estimated and forecast using the synthetic datasets were compared with 407 \nthe synthetic truth. Each algorithm\u201fs annual output of NEE, GPP and Re was tested to 408 \ndetermine whether the truth lay within the 90% CI for estimates. The fraction of tests that 409 \nwere successful was compared with the mean size of the 90% confidence interval for each 410 \nspecific algorithm (Figure 5). There was evidence of a positive relationship between success 411 \nrate and confidence interval size, but some algorithms managed to contain the truth within 412 \nrelatively narrow confidence intervals. In the comparison for annual NEE, four algorithms 413 \n(E1, E2, M1, M3) produced analyses with >80% success rate and mean confidence intervals 414 \n<110 gC m\n-2\n yr\n-1\n. In the comparison against component fluxes (GPP and Re), two algorithms 415 \n(E2, M2) produced more balanced analyses, with relatively high success rates (>65%) and 416 \nnarrow confidence intervals (<300 gC m\n-2\n yr\n-1\n). M3 was always 100% successful in 417 \ncontaining the truth within its 90% confidence intervals, and this over-confidence was 418 \nbecause associated CI were the largest of all algorithms for GPP and Re. There were 419 \nsuccessful tests for prognoses in year 3 by several algorithms, indicating that predictions of C 420 \nfluxes beyond the observational period were successful also ( 421 \nTable 8). 422 \nFox, Williams et al. \n20 \nGPP and Re estimates 423 \nThe decomposition of observed NEE data into GPP and Re revealed major differences among 424 \nalgorithms, with best estimates varying by up to 900 gC m\n-2\n yr\n-1\n (Figure 6, Figure 7). 425 \nHowever there were similar patterns among algorithms across years. For instance, M4 tended 426 \nto estimate lower magnitudes of these fluxes than other algorithms. In most cases the 427 \nalgorithms ranked the GPP and Re similarly across years at each site, but not always. For 428 \ninstance, M1 and M5 ranked Re differently for DE-EC across years (Figure 6). Flux analyses 429 \nwere compared with estimates from other gap-filling and GPP-Re decomposition algorithms 430 \nusing data from the same sites (Desai et al. 2008).  In some cases there was close agreement 431 \nbetween estimates, for instance NEE at Loobos in 2000 (Figure 7), but in other, such as 432 \nLoobos in 2001, there was disagreement. 433 \nStocks 434 \nThe analyses and predictions of foliar C matched the seasonal cycles and magnitudes of the 435 \ntruth from the synthetic studies adequately (Figure 8). Predictions of year 3 foliar C in the 436 \neddy covariance datasets had a mean RMSE among algorithms of 11 gC m\n-2\n for DE and 22 437 \ngC m\n-2\n for EV. However, assessments of confidence intervals were generally poor; most 438 \nalgorithms had 90% CI either too broad or too narrow ( 439 \nTable 9). 440 \nFor the synthetic data, the algorithms reproduced the seasonal cycles in fine root biomass, but 441 \nthe magnitude of the cycles and the mean biomass varied among the algorithms by ~+50% 442 \n(data not shown). This result reflected the choice of initial conditions, or their method of 443 \nassessment, by the users. We found similar patterns in litter and labile C pools. Seasonal data 444 \non the variation in these C pools would be a useful addition to model-data fusion studies. 445 \nThere were some important differences in the analyses and predictions of the slow turnover C 446 \npools in all datasets. Csom in most analyses showed slight increases or decreases over time, but 447 \nFox, Williams et al. \n21 \nsome algorithms showed stocks doubling over three years (Figure 9). Such doublings were 448 \nunrealistic outcomes, but in these cases the algorithms were able to make these changes 449 \nconsistent with the flux observations. For Cw (Figure 10) most algorithms suggest a small 450 \nincrease in C stocks over time, but the algorithms with increasing Csom matched this with 451 \ndecreases in Cw of similar magnitude. 452 \nDiscussion 453 \nThere have been previous attempts to parameterise C models using time series of C fluxes 454 \n(Braswell et al. 2005, Knorr and Kattge 2005, Wang et al. 2007). These studies have tended to 455 \nfocus on calibrating physiological parameters, related to photosynthetic and respiration rates, 456 \nrather than parameters related to allocation and turnover of C pools. The calibration of 457 \nparameters interacting on a range of timescales and links to data over several years is thus an 458 \nimportant and novel component of REFLEX. The feedbacks between fluxes and stocks (e.g. 459 \nphotosynthesis and foliar C), and between soil organic matter and temperature, are 460 \nparticularly important determinants of NEE in the DALEC model that are investigated in 461 \nREFLEX. 462 \nParameter estimation 463 \nWe expected that parameters linked to fast-response processes that mostly determine net 464 \necosystem exchange of CO2 (NEE) would be well constrained and well characterised, while 465 \nparameters for slow processes would be poorly characterised. Our analyses largely supported 466 \nthis expectation. The turnover of litter and foliage were well estimated according to our 467 \ncriteria, and these parameters are closely associated with foliage mass and\/or gaseous 468 \nexchanges of C. We had not expected the turnover rate of SOM, a large slow turnover pool, to 469 \nbe so well constrained, but it is an important determinant of heterotrophic respiration 470 \nnevertheless. Parameters associated with the turnover of wood and allocation to roots were 471 \nFox, Williams et al. \n22 \npoorly estimated, and sometimes biased. These parameters were not directly associated with 472 \ngas exchange or leaf area, and so were only weakly constrained by NEE and LAI data.  473 \nFlux and stock estimation 474 \nThere was weak agreement among algorithms in estimations of 90% CI on NEE and its 475 \ncomponent fluxes, for all datasets. The differences in CI size were closely related to 476 \ndifferences among algorithms in parameter confidence intervals. There were considerable 477 \ndifferences in assessments among similar algorithms (e.g. Metropolis), suggesting that the 478 \nsubjective choices of convergence tests versus statistical tests, priors for the parameters, and 479 \nlikelihood function within the method were important determinants of CI. None of the 480 \nalgorithms consistently included ~90% of the synthetic true daily NEE values, or observed 481 \nEC year 3 daily NEE data, within the 90% confidence interval of the best-fit NEE (Table 482 \n8and Table 9). All algorithms at some point over- or underestimated the confidence interval. 483 \nFor annual assessments of NEE, GPP and Re, there was more success, with some algorithms 484 \nsuccessful locating the true value from synthetic experiments within relatively narrow 90% 485 \nconfidence intervals (Figure 5). 486 \nAssimilation results for annual flux predictions were in overall agreement with previous 487 \nestimates from gap-filling studies on half-hourly data (Desai et al. 2008). However, in a 488 \nnumber of cases the mean 90% CI did not include the gap-filled value (Figure 6 and Figure 489 \n7), for instance NEE in 2001 for Loobos. Some differences were to be expected, because the 490 \nREFLEX database used only a subset of the measured data (when > 90% of half-hourly 491 \nperiods were measured in a day), and the assimilation was based on daily sums rather than 492 \nhalf-hourly measurements. The general agreement in the partitioning of NEE into GPP and Re 493 \nusing daily NEE data by REFLEX and half-hourly data by Desai et al. (2008) is notable. 494 \nRespiration data can be easily extracted from hourly exchange data, but partitioning using 495 \ndaily data requires an effective GPP model, and sound predictions of foliar C. The 496 \nFox, Williams et al. \n23 \npartitioning result suggests that the DALEC GPP and phenology sub-models have worked 497 \nreasonably at the FLUXNET sites. These results indicate that daily data are effective for 498 \nmodel calibration, and that hourly resolution is not necessarily an advantage in generating 499 \npredictions of annual C exchanges. 500 \nModel error 501 \nWe expected that with EC datasets there would be an increase in parameter uncertainty, and 502 \nperhaps only 3-4 constrained parameters, because the model would misrepresent key 503 \nprocesses affecting the observations. However, we found mean similar values of d1 and d2 for 504 \nboth EC and SYN datasets (Table 6 and Table 7). There did not seem to be any improved 505 \nparameter constraint resulting in the synthetic case, where the model error was zero, as it was 506 \nknown to be valid. However, a comparison of confidence interval size on annual NEE 507 \nestimates generated from synthetic and observed data did reveal a common pattern, with 508 \nlarger CI for EC datasets. Based on the comparison between CI on SYN and EC datasets, we 509 \nconclude that the impact of model error was to increase the size of confidence intervals on 510 \nannual NEE estimates by ~31%.  511 \nPrediction error 512 \nPrediction error, determined by forcing the model for 12 months beyond the assimilation 513 \nperiod, was more complex to determine, because confidence intervals varied strongly between 514 \nyears 1 and 2 of the analysis. The only factor in common to all datasets was the lack of priors 515 \nfor initial conditions of Cf, Clit and Cr. Thus, it is likely that erroneous initial conditions and\/or 516 \nlarge uncertainties on the initial values caused larger CI in year 1. The initial pools were often 517 \nout of equilibrium with parameters, and so changed relatively quickly at first. By year two, 518 \nparameter and state equilibria for these fast C pools reduced uncertainty. For predictions in 519 \nyear 3, lacking constraint of observations, uncertainty increased. CI on predictions (year 3) 520 \nFox, Williams et al. \n24 \nwere > twice those for year 2 analyses. For the SYN experiments, the year 3 predictions 521 \namong algorithms were similarly successful to years 1 and 2 \u2013 that is, a similar fraction of 522 \n90% confidence intervals on annual flux estimates encompassed the truth. This result suggests 523 \nthat the quantification of increasing CI was reasonable. 524 \nAlgorithm assessment 525 \nWe examined the different algorithms, to determine if there were distinct winners or losers. 526 \nAll approaches produced broadly similar parameter retrievals (Figure 2) for both synthetic 527 \nand observed datasets (Table 6, Table 7). All approaches generated effective best estimates 528 \nand predictions of daily NEE, as shown by the small RMSEs. But the focus of this study was 529 \nalso on the generation of sound confidence intervals to supplement these estimates. At the 530 \ndaily time-step the results were equivocal, with a tendency for algorithms to be over- or 531 \nunder-confident (Table 8). But at the annual timescale, perhaps the most relevant for C 532 \nstudies, we found that most of the algorithms encompassed the truth within 90% CI. A 533 \ncomplementary test was to check the mean size of confidence intervals, to identify and weed 534 \nout those cases where a successful test was obtained by using very broad CI. Thus, the test of 535 \nannual NEE, GPP and Re retrievals (year 1 and 2) and predictions (year 3) against the known 536 \ntruth from the synthetic experiments (Figure 5) is perhaps the most useful judgement on the 537 \nindividual algorithms. According to this test, metropolis methods, Kalman filters and genetic 538 \nalgorithms were all capable of correctly identifying a large proportion of true fluxes with 539 \nrelatively small confidence intervals. Thus all approaches were valid, but some 540 \nimplementations were more effective in terms of this test on confidence intervals than others 541 \n(see appendix for more information on algorithms). 542 \nFor the Metropolis methods, confidence intervals on fluxes were generated as a function of 543 \nthe set of acceptable parameter sets. These parameters sets were fed into the model to produce 544 \na set of possible outcomes, that were then sampled to determine the 90% CI. Differences in 545 \nFox, Williams et al. \n25 \nthe size of the CI depend on the accept\/reject criterion employed by each algorithm in 546 \ngenerating acceptable parameter sets (Table 5). The methods employing the Kalman filter 547 \nemployed a further step, once acceptable parameter sets were determined. The state variables 548 \nof the model, including flux estimates, were updated using sequential assimilation of 549 \nobservations through the times series. This sequential updating, allowing shifts in states 550 \nthrough the model run unconnected to parameters, may be connected to the success of the 551 \nKalman filter methods (E1, E2, U1) in generating effective, but narrow confidence intervals. 552 \nSome algorithms had problems with large changes to Cw and Csom pools, which could be 553 \nmade consistent with the flux data, but are not ecologically sound in an undisturbed 554 \necosystem. This seems to be partly related to a steady state assumption being made where 555 \npool sizes are first confined to equilibrium which likely leads to a wrong initial system state, 556 \npotential biases in parameters and inflation of their confidence intervals as shown recently in 557 \na specific study by Calvalhais et al. (2008). These symptoms are, for example, also seen in the 558 \napproach M4, where a spin-up was performed. Hence, a way to estimate the initial state of the 559 \nsystem without an ad-hoc steady state assumption is crucial to successful MDF and should be 560 \nexplored further. A constraint on the annual changes in these pools based on repeated 561 \ninventories would help solve this problem. Stem inventories are likely to be easier to 562 \nundertake with quantifiable error than those on SOM, and so should be the focus for future 563 \nstudies. Nevertheless, if longer time scale are to be addressed there is a need to imposed 564 \nconstraints from soil carbon data, e.g. via chronosequences or profile data. Some algorithms 565 \ndid not explicitly include searching for initial conditions on Cf, Clab and Clit, and this caused 566 \nsome problems for e.g. E2. All algorithms need to assess their estimates of uncertainties and 567 \ndevelop new approaches for uncertainty estimates that are consistent with the observations.  568 \nThis experiment has demonstrated the value of using synthetic datasets in understanding data 569 \nassimilation problems. It is clear that even with a perfect model, existing model-data fusion 570 \nFox, Williams et al. \n26 \napproaches find it difficult to analyse parameters using synthetic, noisy and sparse datasets. 571 \nThe information content of data that can be extracted by MDF depends on data quality and 572 \ncoverage. Further synthetic studies will illuminate the relationship between data availability 573 \nand parameter constraint. It is clear that there is little consensus on how to generate 574 \nconfidence intervals, with very broad ranges among algorithms. Tests using confidence 575 \nintervals provide a useful first look at assessing the uncertainties quantified by the various 576 \nalgorithms, although representing continuous probability distributions with a confidence 577 \ninterval suffers from using an arbitrary cutoff criteria. Algorithms that are not well 578 \nconstrained by the data, and thus have wide CI's, will be more likely to contain the true value 579 \nbut this suggests they are less able to make use of all the information in the data.  580 \n 581 \nConclusions 582 \nA range of model-data fusion algorithms exist that can generate useful estimates of parameter 583 \nprobability density functions and state estimates for C models using a C model and daily net 584 \necosystem exchange data, derived either from observations or synthetically. While there was 585 \nless agreement among algorithms on the size of confidence intervals on parameter and state 586 \nestimates, some algorithms were able to make effective estimates of annual fluxes within 587 \nrelatively small CI, when compared to detailed gap-filled estimates or the synthetic \u201etruth\u201f. 588 \nOverall, algorithms generated narrower confidence intervals in analyses using synthetic data 589 \ncompared to observed data. Likewise, confidence intervals were larger by 88% for forecast 590 \nperiods than during data-fusion periods. These results suggest that some algorithms were 591 \ngenerally able to make a reasonable quantification of error propagation in prediction periods, 592 \nand of the likely size of model error, but that differences in estimated confidence intervals 593 \nsuggests further improvements are required. Further studies should explore the importance of 594 \nassumptions about parameter priors (Gaussian or uniform), and the handling of unknown 595 \nFox, Williams et al. \n27 \ninitial conditions. Exploring the growth in CI over forecast periods of multiple years also 596 \nneeds to be explored in a further study. Data on slow, large C pools should be included in 597 \nassimilation experiments, even with large confidence intervals. Such data can help constrain 598 \nthe parameters poorly served by eddy covariance data, which are those related to allocation 599 \nand turnover of wood and roots. 600 \nAcknowledgements 601 \nNERC funded much of this work through the CarbonFusion International Opportunities grant. 602 \nMW, CT, AF and AR were involved in the initial planning and discussions for REFLEX at 603 \nthe CarbonFusion meeting in Edinburgh, May2006. AF undertook the main work on setting 604 \nup the experiment, collating results, and undertaking analyses. MW initiated and managed the 605 \nexperiment, and wrote the manuscript. AR was involved in defining the analytical process and 606 \nthe parameter estimation assessment. Other authors participated in the experiment and 607 \ncontributed to the paper. We are grateful to A Granier and the Hesse research team, and to EJ 608 \nMoors and the Loobos research team, for access to their data, and the FLUXNET team for 609 \ndata processing and preparation. We are grateful to Mike Raupach and Damian Barrett for 610 \ntheir ideas and input at the start of the project, and in developing the protocol for the 611 \nexperiment outlined here. We also recognise Zhang Li\u201fs efforts and input to the analysis. Jens 612 \nKattge made useful comments on the manuscript. AR acknowledges support from the Office 613 \nof Science (BER), U.S. Department of Energy, through the Northeastern Regional Center of 614 \nthe National Institute for Climatic Change Research. 615 \nReferences 616 \nBaldocchi, D., E. Falge, L. H. Gu, R. Olson, D. Hollinger, S. Running, P. Anthoni, C. Bernhofer, K. Davis, R. 617 \nEvans, J. Fuentes, A. Goldstein, G. Katul, B. Law, X. H. Lee, Y. Malhi, T. Meyers, W. Munger, W. 618 \nOechel, K. T. P. U, K. Pilegaard, H. P. Schmid, R. Valentini, S. Verma, T. Vesala, K. Wilson, and S. 619 \nWofsy. 2001. FLUXNET: A new tool to study the temporal and spatial variability of ecosystem-scale 620 \ncarbon dioxide, water vapor, and energy flux densities. Bulletin of the American Meteorological 621 \nSociety 82:2415-2434. 622 \nFox, Williams et al. \n28 \nBonan, G. B. 2008. Forests and Climate Change: Forcings, Feedbacks, and the Climate Benefits of Forests. 623 \nScience 320:1444-1449. 624 \nBraswell, B. H., W. J. Sacks, E. Linder, and D. S. Schimel. 2005. Estimating diurnal to annual ecosystem 625 \nparameters by synthesis of a carbon flux model with eddy covariance net ecosystem exchange 626 \nobservations. Global Change Biology 11:335 - 355. 627 \nCarvalhais, N., M. Reichstein, S. J., C. G.J., J. Santos Pereira, P. Berbigier, A. Carrara, A. Granier, L. 628 \nMontagnani, D. Papale, S. Rambal, M. J. Sanz, and R. Valentini. 2008. Implications of Carbon Cycle 629 \nSteady State Assumptions for Biogeochemical Modeling Performance and Inverse Parameter Retrieval. 630 \nGlobal Biogeochemical Cycles 22, GB2007. 631 \nDesai, A. R., A. D. Richardson, A. M. Moffat, J. Kattge, D. Y. Hollinger, A. Barr, E. Falge, A. Noormets, D. 632 \nPapale, M. Reichstein, and V. J. Stauch. 2008. Cross site evaluation of eddy covariance GPP and RE 633 \ndecomposition techniques. Agricultural and Forest Meteorology 148:821-838. 634 \nFriedlingstein, P., P. Cox, R. Betts, L. Bopp, W. Von Bloh, V. Brovkin, P. Cadule, S. Doney, M. Eby, I. Fung, 635 \nG. Bala, J. John, C. Jones, F. Joos, T. Kato, M. Kawamiya, W. Knorr, K. Lindsay, H. D. Matthews, T. 636 \nRaddatz, P. Rayner, C. Reick, E. Roeckner, K. G. Schnitzler, R. Schnur, K. Strassmann, A. J. Weaver, 637 \nC. Yoshikawa, and N. Zeng. 2006. Climate-carbon cycle feedback analysis: Results from the (CMIP)-638 \nM-4 model intercomparison. Journal of Climate 19:3337-3353. 639 \nGelman, A. 1995. Bayesian data analysis. Chapman & Hall, London. 640 \nGove, J. H., and D. Y. Hollinger. 2006. Application of a dual unscented Kalman filter for simultaneous state and 641 \nparameter estimation in problems of surface-atmosphere exchange. Journal of Geophysical Research 642 \n111:doi:10.1029\/2005JD00621. 643 \nHagen, S. C., B. H. Braswell, E. Linder, S. Frolking, A. D. Richardson, and D. Hollinger. 2006. Statistical 644 \nuncertainty of eddy flux-based estimates of gross ecosystem carbon exchange at Howland Forest, 645 \nMaine. Journal of Geophysical Research 111:D08S03. 646 \nHeimann, M., and M. Reichstein. 2008. Terrestrial ecosystem carbon dynamics and climate feedbacks. Nature 647 \n451:289-292. 648 \nJanssen, P. H. M., and P. S. C. Heuberger. 1995. Calibration of process-oriented models. Ecological Modelling 649 \n83:55 - 66. 650 \nJulier, S. J., and J. K. Uhlmann. 2004. Unscented filtering and nonlinear estimation. Proc. IEEE 92:410-422. 651 \nKalman, R. E. 1960. A New Approach to Linear Filtering and Prediction Problems. Transactions of the ASME--652 \nJournal of Basic Engineering 82:35-45. 653 \nKnorr, W., and J. Kattge. 2005. Inversion of terrestrial ecosystem model parameter values against eddy 654 \ncovariance measurements by Monte Carlo sampling. Global Change Biology 11:1333-1351. 655 \nLasslop, G., M. Reichstein, J. Kattge, and D. Papale. 2008. Influences of observation errors in eddy flux data on 656 \ninverse model parameter estimation. Biogeosciences 5:1311-1324. 657 \nLiu, Y., and H. V. Gupta. 2007. Uncertainty in hydrologic modeling: Toward an integrated data assimilation 658 \nframework. Water Resources Research 43:W07401. 659 \nMetropolis, N., A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller. 1953. Equation of state 660 \ncalculations by fast computing machines. J. Chem. Phys. 21:1087\u20131092. 661 \nMoffat, A. M., D. Papale, M. Reichstein, D. Y. Hollinger, A. D. Richardson, A. G. Barr, C. Beckstein, B. H. 662 \nBraswell, G. Churkina, A. R. Desai, E. Falge, J. H. Gove, M. Heimann, D. Hui, A. J. Jarvis, J. Kattge, 663 \nA. Noormets, and V. J. Stauch. 2007. Comprehensive comparison of gap-filling techniques for eddy 664 \ncovariance net carbon fluxes. , 147: 209-232. Agricultural and Forest Meteorology 147:209-232. 665 \nMoore, D., J. Hu, W. Sacks, D. Schimel, and R. Monson. in press. Estimating transpiration and the sensitivity of 666 \ncarbon uptake to water availability in a subalpine forest using a simple ecosystem process model 667 \ninformed by measured net CO2 and H2O fluxes. Agricultural and Forest Meteorology. 668 \nMosegaard, K., and A. Tarantola. 1995. Monte-Carlo Sampling of Solutions to Inverse Problems. Journal of 669 \nGeophysical Research-Solid Earth 100:12431-12447. 670 \nQuaife, T., P. Lewis, M. De Kauwe, M. Williams, B. E. Law, M. D. Disney, and P. Bowyer. 2008. Assimilating 671 \nCanopy Reflectance data into an Ecosystem Model with an Ensemble Kalman Filter. Remote Sensing 672 \nof the Environment 111:1347-1364. 673 \nRaupach, M. R., P. J. Rayner, D. J. Barrett, R. S. DeFries, M. Heimann, D. S. Ojima, S. Quegan, and C. C. 674 \nSchmullius. 2005. Model-data synthesis in terrestrial carbon observation: methods, data requirements 675 \nand data uncertainty specifications. Global Change Biology 11:378-397. 676 \nRicciuto, D. M., K. J. Davis, and K. Keller. 2008. A Bayesian calibration of a simple carbon cycle model: The 677 \nrole of observations in estimating and reducing uncertainty. Global Biogeochemical Cycles 22:GB2030. 678 \nRichardson, A. D., D. Y. Hollinger, G. G. Burba, K. J. Davis, L. B. Flanagan, G. G. Katul, J. W. Munger, D. M. 679 \nRicciuto, P. C. Stoy, A. E. Suyker, S. B. Verma, and S. C. Wofsy. 2006. A multi-site analysis of 680 \nrandom error in tower-based measurements of carbon and energy fluxes. Agricultural and Forest 681 \nMeteorology 136:1-18. 682 \nFox, Williams et al. \n29 \nRichardson, A. D., M. D. Mahecha, E. Falge, J. Kattge, A. M. Moffat, D. Papale, M. Reichstein, V. J. Stauch, B. 683 \nH. Braswell, G. Churkina, B. Kruijt, and D. Y. Hollinger. 2008. Statistical properties of random CO2 684 \nflux measurement uncertainty inferred from model residuals. Agricultural and Forest Meteorology 685 \n148:38-50. 686 \nSacks, W. J., D. S. Schimel, and R. K. Monson. 2007. Coupling between carbon cycling and climate in a high-687 \nelevation, subalpine forest: a model-data fusion analysis. Oecologia 151:54-68. 688 \nStockli, R., D. M. Lawrence, G. Y. Niu, K. W. Oleson, P. E. Thornton, Z. L. Yang, G. B. Bonan, A. S. Denning, 689 \nand S. W. Running. 2008. Use of FLUXNET in the community land model development. Journal of 690 \nGeophysical Research-Biogeosciences 113. 691 \nTrudinger, C. M., M. R. Raupach, P. J. Rayner, and I. G. Enting. 2008. Using the Kalman filter for parameter 692 \nestimation in biogeochemical models. Environmetrics DOI: 10.1002\/env.910. 693 \nTrudinger, C. M., M. R. Raupach, P. J. Rayner, J. Kattge, Q. Liu, B. Pak, M. Reichstein, L. Renzullo, A. D. 694 \nRichardson, S. H. Roxburgh, J. Styles, Y. P. Wang, P. Briggs, D. Barrett, and S. Nikolova. 2007. OptIC 695 \nproject: An intercomparison of optimization techniques for parameter estimation in terrestrial 696 \nbiogeochemical models. Journal of Geophysical Research-Biogeosciences 112. 697 \nVan Oijen, M., J. Rougier, and R. Smith. 2005. Bayesian calibration of process-based forest models: bridging the 698 \ngap between models and data. Tree Physiology 25:915-927. 699 \nVan Wijk, M. T., and W. Bouten. 2001. Towards understanding tree root profiles: simulating hydrologically 700 \noptimal strategies for root distribution. Hydrology and Earth System Sciences 5(4):629 - 644. 701 \nVan Wijk, M. T., and W. Bouten. 2002. Simulating daily and half-hourly fluxes of forest carbon dioxide and 702 \nwater vapor exchange with a simple model of light and water use. Ecosystems 5:597-610. 703 \nVan Wijk, M. T., B. Van Putten, D. Y. Hollinger, and A. D. Richardson. 2008. Comparison of different 704 \nobjective functions for parameterization of simple respiration models. Journal of Geophysical Research 705 \n113:G03008. 706 \nVrugt, J. A., C. G. H. Diks, H. V. Gupta, W. Bouten, and J. M. Verstraten. 2005. Improved treatment of 707 \nuncertainty in hydrologic modeling: Combining the strengths of global optimization and data 708 \nassimilation. Water Resources Research 41:W01017. 709 \nVrugt, J. A., H. V. Gupta, W. Bouten, and S. Sorooshian. 2003. A shuffled complex evolution metropolis 710 \nalgorithm for optimization and uncertainty assessment of hydrologic model parameters. Water 711 \nResources Research 39:Art. no. 1201. 712 \nWang, Y. P., D. Baldocchi, R. Leuning, E. Falge, and T. Vesala. 2007. Estimating parameters in a land-surface 713 \nmodel by applying nonlinear inversion to eddy covariance flux measurements from eight FLUXNET 714 \nsites. Global Change Biology 13:652 - 670. 715 \nWaring, R. H., J. J. Landsberg, and M. Williams. 1998. Net primary production of forests: a constant fraction of 716 \ngross primary production? Tree Physiology 18:129-134. 717 \nWilliams, M., E. B. Rastetter, D. N. Fernandes, M. L. Goulden, G. R. Shaver, and L. C. Johnson. 1997. 718 \nPredicting gross primary productivity in terrestrial ecosystems. Ecological Applications 7:882-894. 719 \nWilliams, M., E. B. Rastetter, D. N. Fernandes, M. L. Goulden, S. C. Wofsy, G. R. Shaver, J. M. Melillo, J. W. 720 \nMunger, S.-M. Fan, and K. J. Nadelhoffer. 1996. Modelling the soil-plant-atmosphere continuum in a 721 \nQuercus-Acer stand at Harvard Forest: the regulation of stomatal conductance by light, nitrogen and 722 \nsoil\/plant hydraulic properties. Plant, Cell and Environment 19:911-927. 723 \nWilliams, M., P. Schwarz, B. E. Law, J. Irvine, and M. R. Kurpius. 2005. An improved analysis of forest carbon 724 \ndynamics using data assimilation. Global Change Biology 11:89-105. 725 \nWilliams, M., L. Street, M. T. V. Wijk, and G. R. Shaver. 2006. Identifying differences in carbon exchange 726 \namong arctic ecosystem types. Ecosystems 9:288-304. 727 \n 728 \n 729 \n730 \nFox, Williams et al. \n30 \nAppendix: Details of algorithms 731 \nE1: Stage 1. Parameter estimation. Parameters were initially estimated using a simple 732 \nMetropolis MCMC-type approach. (e.g. (Mosegaard and Tarantola 1995, Knorr and Kattge 733 \n2005)). Initial prior distributions were assumed to be uniform and encompass the entire 734 \npossible suggested range and so a single stage accept\/reject criterion was used based on 735 \ncomparison of model output with data alone. Initial values for Cr, Clit and Clab were 736 \nestimated in the same manner as parameters, initial values for Cf were based on first available 737 \nobservation (EV case) or set to zero (DE case). The model was initialized from a random 738 \nlocation, and step size was constant and determined as 0.001 of log-transformed parameter 739 \nrange. This was determined through \u201etuning\u201f initial runs to ensure an acceptance probability 740 \nof between 0.2 and 0.8 at each step. The number of steps required to sufficiently sample the 741 \nparameter space was assessed using the Gelman criteria (Gelman 1995)) to test convergence 742 \nbetween chains. 743 \nE1: Stage 2. State estimation. 8000 parameter sets were randomly sampled from the accepted 744 \nparameters from Stage 1. These were then used in an 8000 member Ensemble Kalman Filter 745 \n(EnKF, Evensen, 1994; Williams et al., 2005). A unique parameter set was assigned to each 746 \nensemble member with the intention this would cause divergence between ensemble members 747 \nrepresenting model error and cause a growth in state uncertainty equivalent to that inherent 748 \nfrom parameter uncertainty alone. This was done instead of adding a stochastic forcing term 749 \nat each time step. This is possibly correct in the SYN cases when model \u201estructural\u201f error is 750 \nknown to be zero, but will probably underestimate model error in the EC cases and overly 751 \nrestrict growth in state uncertainty. Nonetheless, assimilation of observations did alter the 752 \nstate variables in the resulting analysis and reduce uncertainties in state estimates even though 753 \nthese same observation data had already been used to generate the parameter sets in Stage 1 754 \nso offered little additional information to the EnKF.  755 \n 756 \nE2: Ensemble Kalman filter. This method was set up for joint estimation of states and 757 \nparameters, so parameters were included within the state vector for assimilation. Model 758 \nparameter errors were set within bounds - small enough to avoid tracking daily noise in 759 \nobservations, and large enough to shift over weekly-seasonal timescales in response to 760 \nprocess signals.  Errors on model states were set smaller than for parameters, so that 761 \nassimilation was focused on updating parameters rather than states. Initial values for all 762 \nparameters and initial conditions for Cf, Clab and Cr were estimated. After an initial 763 \nassimilation of observations, these initial parameter estimates were updated with the final 764 \nestimates from the assimilation. We assumed that Cf, Clab and Cr would be in approximate 765 \nsteady state over annual cycles, and adjusted initial values accordingly. A further EnKF 766 \nassimilation was then applied, using these updated initial parameters and initial conditions, to 767 \ngenerate final analyses.  768 \n 769 \nU1: Unscented Kalman filter. The UKF was used to provide state estimates for each of the 770 \nexperiments. The UKF (Julier and Uhlmann 2004) is a nonlinear version of the traditional 771 \nlinear Kalman filter (Kalman 1960), that uses a deterministic sampling of so-called sigma 772 \npoints in order to capture the mean and covariance of the state. Similar to other Kalman type 773 \nfilters it employs a two-step `predictor-corrector' scheme where model predictions are 774 \ncorrected by measurements as they arrive sequentially in time. At time periods where 775 \nmeasurements are missing, only the prediction step is used.  To employ the UKF, the general 776 \nnonlinear state space model was assumed, with the variants of the model taking the form of 777 \nthe state evolution equations. A linear measurement model was used in all runs. Both the state 778 \nFox, Williams et al. \n31 \nand measurement equations assume zero mean random noise processes with associated full-779 \ndimensional covariance matrices (Gove and Hollinger 2006). The later were estimated from 780 \nthe information provided. The parameter estimates used in the filter runs were arrived at via 781 \nsimulated annealing method M3. Parameters for the unscented transformation were set to 782 \n=1, =2 and =1 for all experiments (see Gove and Hollinger 2006 for an explanation). 783 \n 784 \nG1: Genetic algorithm: The implementation was from Haupt and Haupt (2004). The 785 \npopulation size was 100, and was run for 1000 iterations (generations). Initial stores Cr, Clit, 786 \nCf and Clab were estimated by the GA as additional parameters. To estimate uncertainties, the 787 \nroughly 1600 (unique) parameter sets with cost function values closest to the final best cost 788 \nfunction value were saved, and used to estimate the covariance matrix and 90% CI. 789 \n 790 \nM1: This method sought to make as few approximations as possible to Bayes Theorem, 791 \nchoosing the simplest algorithm to generate a representative sample from the posterior. We 792 \nchose the beta distribution for our prior. The Metropolis algorithm (Metropolis et al. 1953) 793 \ngenerates a chain that sequentially \u201cwalks through parameter space\u201d in such a way that the 794 \nchain of visited points is the sought-after sample from the posterior. Each new point in the 795 \nchain is found by randomly generating a multivariate normal step away from the current 796 \nvector. In this case a simple diagonal variance matrix defined this multivariate normal 797 \n\u201cproposal distribution\u201d. Whether a proposed candidate vector was accepted or not depended 798 \non the Metropolis ratio, which is the ratio of two products: likelihood times prior for the 799 \ncandidate and likelihood times prior for the current point. If the Metropolis ratio was larger 800 \nthan 1 (i.e. the candidate point has a higher posterior probability then the current point), it was 801 \nalways accepted. If the Metropolis ratio was less than 1 (i.e. the candidate was \u201cless probable\u201d 802 \nthan the current vector), the candidate could still be accepted but only with probability equal 803 \nto the Metropolis ratio. The chain was stopped when it \u201cconverged\u201d, i.e. it had explored the 804 \nparameter space adequately. Convergence was confirmed visually using the trace plots of the 805 \ndifferent parameters, i.e. plots that show how the chain moves through parameter space for 806 \neach individual parameter. If one or more of the trace plots was still showing drift towards 807 \nunexplored parts or parameter space, the chain was deemed not to have converged. 808 \n 809 \nM2: A combined optimization approach estimated model parameters and state variables.  A 810 \ngenetic algorithm, Stochastic Evolutionary Ranking Strategy (SRES) was used to find the 811 \nglobal optimum (Runarrsson and Yao, 2000). Markov chain monte carlo (MCMC) using the 812 \nMetropolis-Hastings algorithm was then used to explore the parameter space around the 813 \noptimum to estimate the full joint distribution of parameters and to estimate predictive 814 \nuncertainty.  Two chains were run for each experiment; convergence was determined by 815 \nvisually comparing the parameter PDFs from both chains.  The ranges given for p1-17 were 816 \nused as uniform distributions; no additional information was used.   The initial values of pools 817 \nCr, Clit and Clab were also estimated as model parameters, using the prior range 20-200 gC m\n-2\n 818 \nas recommended.   All observations are assumed to drawn from independent distributions. 819 \nBoth NEE and LAI errors were assumed normally distributed. 820 \n 821 \nM3: Optimization of parameters and initial values of C pools took place in three stages. First, 822 \nthe parameter and initial state space was randomly explored for 50,000 iterations, at which 823 \npoint the parameter set and initial conditions with the lowest cost function was used as the 824 \nstarting point for the Metropolis algorithm. Second, the Metropolis algorithm was 825 \nimplemented to ensure progressive down-slope movement while at the same time avoiding 826 \nlocal minima. The cost function was a weighted-sum-of-squares of both NEE and LAI 827 \ndeviations. 200,000 steps were taken in this manner. Third, reverting to the best parameter set 828 \nFox, Williams et al. \n32 \nobtained, the parameter space was explored again until 1,000 parameter sets have been 829 \naccepted as \u201calmost as good as\u201d the optimal parameter set, using a 2 test to determine the 830 \nthreshold contour (90% confidence interval) (assuming n \u2013 1 degrees of freedom for LAI and 831 \nn \u2013 p \u2013 1 degrees of freedom for NEE. These parameter sets were used to define the 832 \nuncertainty estimates on both parameters and model predictions.  833 \n  834 \nM4: Markov Chain Monte Carlo Metropolis. The algorithm adopted a global search method 835 \nwith an uniform walk in the model parameter space. The method is based on a Bayesian 836 \napproach where the comparison between model output and data is used to update our prior 837 \nknowledge of the parameter distribution. The prior distributions were considered to be 838 \nuniform. The Metropolis rules prevented the algorithm from being trapped in local minima, 839 \nallowing for changes in the searching direction. Spin-up was used to initialize the C pools (Cr, 840 \nClit and Clab); we sampled the parameters and we ran the model replicating the meteorological 841 \ndata until the total difference between one year and the other was less than 1g of C. The other 842 \nC pools were initialized as from the experiment description. 843 \n 844 \nM5. The SCEM-UA algorithm (Vrugt et al., 2003) is a modified version of the original SCE-845 \nUA global optimization algorithm (Duan et al., 1992). The algorithm is Bayesian in nature 846 \nand operates by merging the strengths of the Metropolis algorithm, controlled random search, 847 \ncompetitive evolution, and complex shuffling to continuously update the proposal distribution 848 \nand evolve the sampler to the posterior target distribution. The SCEM-UA algorithm uses the 849 \nMetropolis-Hastings (Metropolis et al., 1953) search strategy to generate a sequence of 850 \nparameter sets (\u03b81, \u03b82,..., \u03b8n) that adapts to the target posterior distribution. It starts with an 851 \ninitial population of points (parameter sets) randomly distributed throughout the feasible 852 \nparameter space defined by the prior parameter distributions. The population is partitioned 853 \ninto q complexes, and in each complex k (k = 1, 2, ..., q) a parallel sequence is launched from 854 \nthe point that exhibits the highest posterior density. A new candidate point in each sequence k 855 \nis generated using a multivariate normal distribution either centred around the current draw of 856 \nthe sequence k, or the mean of the points in complex k, augmented with the covariance 857 \nstructure induced between the points in complex k. The Metropolis-annealing criterion is used 858 \nto test whether the candidate point should be added to the current sequence. Subsequently the 859 \nnew candidate point randomly replaces an existing member of the complex. Finally, after a 860 \ncertain number of iterations new complexes are formed through a process of shuffling the old 861 \ncomplexes. The objective function used in this study is a combination of the model errors 862 \n(expressed as SSE, Sum of Squared Errors) of describing the CO2 fluxes and the Leaf Area 863 \nIndex, weighted by the error variance of each variable. 864 \n865 \nFox, Williams et al. \n33 \nTables 866 \nObservation Units Interval Source \nGlobal Radiation MJ m-2 d-1 Daily Fluxnet data portal \nMin Temperature \u00b0C Daily Fluxnet data portal \nMax temperature \u00b0C Daily Fluxnet data portal \nCO2 conc. mol mol\n-1 Daily Fluxnet data portal \nNEE g C m-2 d-1 Daily Fluxnet data portal \nLAI m2 m-2 When available References\/site PI \nFoliar N * gN m-2 leaf area Constant References\/site PI \nAboveground C mass* kg C m-2 Initial condition References\/site PI \nSOM C mass* kg C m-2 Initial condition References\/site PI \nLeaf mass per area* g C m-2 leaf area Constant References\/site PI \nTable 1. Time series data available for use in the experiments.  Data with a \u201cconstant\u201d interval are fixed 867 \nvalues throughout model runs. *Ancillary data contained in Table 2 for all experiments. 868 \n869 \nFox, Williams et al. \n34 \n 870 \nSite \n \nLatitude \n(\u00b0N) \nSoil organic matter C  \n(g C m-2)  \nAbove-ground  \nbiomass (g C m-2)  \nLeaf mass per area \n(g C m-2 leaf area) \nFoliar N (g N \nm-2 leaf area) \nEV-EC \n(Loobos) \n52 11000 9200 110 \n4.0 \nEV-SYN 50 9700 12400 110 3.8 \nDE-EC \n(Hesse) \n48 7100 8800 22 \n1.0 \nDE-SYN 51 9900 8900 22 1.1 \nTable 2. Site details, including latitude, initial conditions for large C pools, and foliage parameters. 871 \n872 \nFox, Williams et al. \n35 \n 873 \n Description Code Range (low\/high) \np1 Decomposition rate  (per day) Td 1 x 10\n-6\/0.01 \np2 Fraction of GPP respired Fg 0.2\/0.7 \np3 Fraction of NPP allocated to foliage Fnf 0.01\/0.5 \np4 Fraction of NPP2 allocated to roots Fnrr 0.01\/0.5 \np5 Turnover rate of foliage (per day) Tf 1 x 10\n-4\/0.1 \np6 Turnover rate of wood  (per day) Tw 1 x 10\n-6\/0.01 \np7 Turnover rate of roots  (per day) Tr 1 x 10\n-4\/0.01 \np8 Mineralisation rate of litter  (per day) Tl 1 x 10\n-5\/0.1 \np9 Mineralisation rate of SOM\/CWD  (per day) Ts 1 x 10\n-6\/0.01 \np10 Parameter in exponential term of temperature \ndependent rate parameter \nEt 0.05\/0.2 \np11 Nitrogen use efficiency parameter (a1) in \nACM \nPr 5\/20 \np12 * GDD value causing leaf out Lout 200\/400 \np13 * Minimum daily temperature causing leaf fall Lfall 8\/15 \np14 * Fraction of leaf loss transferred to litter Fll 0.2\/0.7 \np15 * Turnover rate of labile carbon (per day) Tlab 1 x 10\n-4\/0.1 \np16 * Fraction of labile transfers respired Flr 0.01\/0.5 \np17 * Maximum Cf value (gC m\n-2) Cfmax 100\/500 \nTable 3. Model parameters requiring calibration.  NPP2 is NPP remaining after allocation to foliage.  874 \n* parameters p12-17 are used in DALEC-deciduous only. 875 \n 876 \n877 \nFox, Williams et al. \n36 \n 878 \nExperiment Data Drivers Sites Parameters States \n1 FLUXNET NEE and \nLAI data, 2000-1 \nObserved, \n2000-1 \nDE-EC, \nEV-EC \nGenerated by \nMDF, with 90% CI \nGenerated by MDF \nwith 90% CI \n2 Artificial \/synthetic Artificial  DE-SYN, \nEV-SYN \nGenerated by \nMDF, with 90% CI \nGenerated by MDF \nwith 90% CI \n3 None Observed, \n2002 \nDE-EC, \nEV-EC \nFrom Expt 1 Generated by MDF \nwith 90% CI \n4 None Artificial DE-SYN, \nEV-SYN \nFrom Expt 2 Generated by MDF \nwith 90% CI \n 879 \nTable 4. Experimental summary for Reflex. The table shows for each experiment the input data, the 880 \nsource of the meteorological drivers, and the site codes. The first two experiments generated parameter 881 \nestimates and estimates of model states (fluxes and pools of C), while the final two experiments were 882 \nforecasts of model states only. Acronyms: DE - deciduous vegetation, EV - evergreen vegetation, SYN \u2013 883 \nsynthetic data, EC- observed eddy covariance and LAI data. 884 \nFox, Williams et al. \n37 \n \nParticipant Name \u2013 type of \nmethodology \nCode Prior Cost\/objective function Initial pools Convergence \ntests \nNumber of \nparameter \nsets \nproduced \nNumber \nof model \niterations \nProgramming \nlanguage \nE1 (stage 1)  \n \nMCMC Metropolis, \nthen EnKF \n Uniform \nJ=\n1\n2\n\u2211\ni=1\nN\nf\nxi ,p \u2212 OBS i\n2\n\u03c3 obs,i\n2\n \nParameters to be \nestimated \nGelman and \nRubin (1992) \n~400000 ~1000000 Fortran  \n \nE1 (stage 2) Evensen \n(2003) \nPDFs \nfrom \nstage 1 \nKalman gain PDFs from stage 1 n\/a State only 8000 Fortran  \n \nE2 Ensemble Kalman \nfilter \nEvensen \n(2003) \nGaussian Kalman gain Cr=Cfmax, \nClit=0.5Cfmax, \nClab=0.5Cfmax +  \nEnKF 2 times  \nn\/a  \n \n~2000 800  \n \nFortran \nU1 Unscented Kalman \nfilter \nGove & \nHollinger \n(2006) \nGaussian Minimize posterior error covariance via the Kalman gain. As estimated by M3 n\/a State only n\/a R \nG1 Genetic algorithm Based on \nHaupt \nand \nHaupt \n(2004) \nuniform \nJ=\u2211\ni=1\nN f i \u2212 OBSi\n2\n\u03c3obs,i\n2\n+a\u00d7 [c 365 \u2212 c 0c 0 ]\n2\n[c 730 \u2212 c 0c 0 ]\n2\n \nTuned with \nparameters \n \nn\/a ~100000 \n \n \n \nFortran \nM1 MCMC \u2013 Metropolis   Gaussian likelihood Included in \ncalibration \nvisual  300000  Fortran \nM2 MCMC \u2013 Metropolis MCMC1 uniform \nJ=\n1\n2\n\u2211\ni=1\nN\nf\nxi ,p \u2212 OBS i\n2\n\u03c3 obs,i\n2\n \nParameters to be \nestimated \n \nVisual \ncomparison of \nparameter \nPDFs from 2 \nchains \n \n1000000 \n \n1000000 \n \nFortran  \n \nM3 Simulated \nannealing-\nMetropolis \nSAM uniform \nJ=2\nf x,p \u2212 OBS\n2\n\u03c3obs\n2\n\u22c5\n1\nN  \nParameters to be \nestimated \n \nn\/a 1000 \n \n~250000 Fortran \nM4 MCMC \u2013 Metropolis MCMC3 uniform \nJ=\n1\n2\n\u2211\ni=1\nN\nf\nxi ,p \u2212 OBS i\n2\n\u03c3 obs,i\n2  \nSpinup to equilibrium \nof total C \n \nHeidelberger \nand Welch \n(1983) \n \n80000 \n \n~300000 \n \nR \nM5 Multiple complex \nMCMC \u2013 Metropolis \nSCEM uniform \nJ=\nSSEOBS\n\u03c3OBS\n2  \nParameters to be \nestimated \n \nGelman and \nRubin (1992) \n \n~500000 \n \n150000 \n \nMatlab \nTable 5. A summary of the algorithms used in the experiment. Methods using Metropolis algorithm alone are labelled Mx. U1 and E1 used a Kalman filter after an initial \nMetropolis algorithm search for parameters. G1 and E2 are the only methods not using the Metropolis algorithm. \nFox, Williams et al. \n38 \nEvergreen: EV-SYN     Deciduous: DE-SYN    \nParam d1 d2 d3 D Rank  d1 d2  d3 D Rank \nTd 0.26 0.36 0.75 0.87 11  0.26 0.42 0.72 0.87 17  \nFg 0.30 0.41 0.02 0.51 6  0.11 0.42 0.09 0.45 8 \nFnf 0.07 0.49 0.00 0.50 5  0.26 0.53 0.37 0.70 16  \nFnrr 0.24 0.65 0.31 0.76 9  0.19 0.60 0.07 0.64 15  \nTf 0.06 0.20 0.03 0.21 1  0.05 0.16 0.01 0.17 3  \nTw 0.22 0.40 0.69 0.83 10  0.27 0.37 0.22 0.51 12  \nTr 0.27 0.52 0.03 0.59 8  0.04 0.28 0.02 0.28 5  \nTl 0.07 0.22 0.03 0.23 2  0.03 0.15 0.03 0.15 2  \nTs 0.05 0.16 0.21 0.27 4  0.04 0.08 0.01 0.09 1  \nEt 0.04 0.24 0.00 0.24 3  0.05 0.17 0.04 0.18 4  \nPr 0.21 0.47 0.15 0.54 7  0.14 0.46 0.06 0.49 10  \nLout       0.22 0.40 0.19 0.49 11  \nLfall       0.14 0.25 0.10 0.30 6  \nFll       0.13 0.52 0.24 0.59 14  \nTlab       0.19 0.54 0.01 0.57 13  \nFlr       0.18 0.33 0.00 0.38 7  \nCfmax       0.22 0.36 0.17 0.46 9 \n  \nMean 0.16 0.38 0.20 0.51   0.15 0.36 0.14 0.43 \n \nTable 6. Parameter estimation metrics using 9 different algorithms based on synthetic data for evergreen (left) \nand deciduous (right) forest. Metric d1 quantifies consistency among methods; d2 quantifies the data constraint \non the confidence intervals; and d3 quantifies the consistency with the truth. D is the sum of the d1-3. The rank \ncolumn identifies the rank of D for each parameter, with lower values of D, and lower ranks, indicating better \nestimation.  \nFox, Williams et al. \n39 \n \nEvergreen EV-EC     Deciduous DE-EC  \n    \n d1 d2 D Rank  d1 d2 D Rank \nTd 0.28 0.42 0.5 9  0.29 0.36 0.47 14  \nFg 0.11 0.36 0.37 6  0.08 0.3 0.31 7  \nFnf 0.16 0.31 0.35 5  0.2 0.55 0.58 17  \nFnrr 0.29 0.6 0.66 11  0.15 0.53 0.55 16   \nTf 0.08 0.19 0.2 3  0.12 0.25 0.28 6  \nTw 0.24 0.35 0.42 7  0.21 0.35 0.4 12  \nTr 0.29 0.35 0.45 8  0.32 0.2 0.38 9  \nTl 0.09 0.23 0.25 4  0.08 0.18 0.2 1  \nTs 0.08 0.1 0.13 1  0.05 0.2 0.21 2  \nEt 0.02 0.2 0.2 2  0.09 0.19 0.21 3  \nPr 0.14 0.52 0.53 10  0.17 0.35 0.39 11  \nLout      0.21 0.37 0.43 13  \nLfall      0.2 0.32 0.38 10  \nFll      0.16 0.32 0.36 8  \nTlab      0.1 0.49 0.5 15  \nFlr      0.12 0.23 0.25 5  \nCfmax      0.03 0.25 0.25 4 \n  \nMean 0.16 0.33 0.37   0.15 0.32 0.36 \n \nTable 7 Parameter estimation metrics using 9 different algorithms based on observed data for evergreen (left) \nand deciduous (right) forest. Metric d1 quantifies consistency among methods; d2 quantifies the data constraint \non the confidence intervals. D is the sum of the d1-2. The rank column identifies the rank of D for each parameter, \nwith lower values of D, and lower ranks, indicating better estimation.  \nFox, Williams et al. \n40 \n \n DE-Syn EV-Syn \n Year 1 Year 2 Year 3 Year 1 Year 2 Year 3 \nAlgorithm       \nM1 0.95 0.97 0.99 0.81 0.89 1.00 \nM2 0.73 0.65 0.81 0.95 0.61 0.51 \nM3 1.00 1.00 1.00 1.00 1.00 1.00 \nM4 0.95 0.97 0.96 0.80 0.86 0.85 \nM5 0.66 0.37 0.36 0.39 0.25 0.35 \nE1 0.90 0.83 0.95 0.93 0.77 0.69 \nE2 0.85 0.99 1.00 0.44 0.61 0.60 \nU1 0.99 0.99 1.00 0.99 0.98 1.00 \nG1 1.00 1.00 0.98 1.00 0.99 1.00 \n \nTable 8. Fraction of days in each year where 90% confidence interval encompassed the synthetic \u201ctrue\u201d value of \nNEE. Fractions are shown for each of the 3 individual years for DE-SYN and EV-SYN datasets. Values between \n0.85-0.95 are in bold and are consistent with the 90% CI. Values of 1.0 are indicated by italics. \nFox, Williams et al. \n41 \n \n Foliar C mass (Cf) Daily NEE  \n RSME   (gC m\n-2\n) CI frac RMSE (gC m\n-2\n d\n-1\n) CI frac \nAlgorithm DE-EC EV-EC DE-EC EV-EC DE-EC EV-EC DE-EC EV-EC \nM1 12.3 29.9 1 0.5 1.42 1.50 0.14 0.14 \nM2 7.6 16.6 0 0.83 1.21 1.34 0.11 0.06 \nM3 6.9 19.4 1 0.94 1.35 1.42 0.56 0.16 \nM4 16.9 18.9 1 1 1.57 1.73 0.39 0.19 \nM5 10.6 17.8 0 0.17 2.25 1.37 0.2 0.16 \nE1 6.1 20.3 1 0.33 1.10 1.49 0.14 0.08 \nE2 30.2 37.8 1 1 1.70 1.45 0.86 0.16 \nU1 4.1 15.5 1 1 1.34 1.37 0.84 0.61 \nG1 4.2 22.6 1 0.83 1.24 1.54 0.43 0.16 \nn 1 18 1 18 218 171 218 171 \n \nTable 9. Assessment of year 3 best-fit predictions and 90% confidence intervals (CI) for the EC datasets. \nComparisons with both foliar carbon mass (Cf) and daily net ecosystem exchange (NEE) are shown. Assessment \nof best fit predictions is through root mean square error (RMSE) on observations for year 3 for deciduous (DE) \nand evergreen (EV) forests. Assessment of confidence intervals is through quantifying the fraction of days in \nyear 3 where the 90% confidence interval encompassed the observed NEE. Values between 0.85-0.95 are in bold \nand are deemed consistent with the 90% CI. Algorithms are identified by codes. n is number of observations in \nyear 3, which were withheld from the experimental team. \nFox, Williams et al. \n42 \n \nDataset Year 1 Year 2 Year 3 \nDE-EC 181.0 96.6 186.2 \nEV-EC 119.3 92.6 169.4 \nDE-SYN 139.3 83.8 148.9 \nEV-SYN 95.4 58.1 117.9 \n \nTable 10. Mean size of 90% confidence interval on annual NEE for 3 years. Assessments were made with outputs \nfrom the nine algorithms, and compared for different years and datasets. The outputs for the first two years \nwere analyses, based on model-data fusion. The output for the final year was generated from model predictions \nusing estimated parameters and meteorological forcing, and no data.  Units are gC m\n-2\n yr\n-1\n.\nFox, Williams et al. \n43 \n \nFigures \n \n \n \nFigure 1 A schematic of the DALEC (black) and DALEC-deciduous (black and grey) models. The figures show \npools (boxes) and fluxes (arrows) of C. Feed back between DALEC and the photosynthesis model is indicated by \ndotted line. Allocation fluxes are A, litter-fall fluxes by L, and respiration by R, split between autotrophic (a) and \nheterotrophic (h). D is decomposition and GPP is gross primary productivity.    \n \nGPP Cr \nCw \nCf \nClit \nCSOM \n \n      \nRa \n \nAf \nAr \nAw \nLf \nLr \nLw \nRh1 \nD \nClab  \nAtolab \nAfromlab \nRh2 \n \nFox, Williams et al. \n44 \n \n \nFigure 2. Parameter estimation for deciduous synthetic (DE-SYN) data. The panels shows each of the algorithms\u201f best estimate of each parameter, and the magnitude of \neach 90% confidence intervals. The \u201etrue\u201f value of the parameter used in generating the synthetic data is indicated by the d vertical line. The upper and lower bounds of \neach parameter, as provided to the experimenters, is indicated by the range of each x-axis. X-axes are log scaled for turnover rates (all parameters beginning T). For an \nexplanation of parameter symbols see Table 5. \n \nFox, Williams et al. \n45 \n \nFigure 3. A comparison of two metrics of parameter calibration success against mean parameter 90% confidence intervals of each algorithm (d4, see text). Parameter \ncalibration success is judged in two ways: (1) by the fraction of 90% confidence intervals encompassing the true parameter values obtained by each algorithm, see left \npanels \u2013 high values are better; (2) by the mean normalized difference between best estimate and true parameter values obtained by each algorithm (d5, see text), see right \npanels \u2013 low values are better.  Individual algorithms are identified by alphanumerics (Table 5). The top two panels are generated from the deciduous synthetic data, the \nbottom two from evergreen synthetic data. Data for the synthetic experiments are shown, where true values of the parameters are known. \nFox, Williams et al. \n46 \n \nFigure 4. Estimated time series of net ecosystem exchange of CO2 (NEE) over 3 years from each algorithm using observations from the DE-EC dataset over the first 2 \nyears (top panel) and 90% confidence intervals on the estimates (lower panel). The eddy covariance data is shown as open symbols. \nFox, Williams et al. \n47 \n \n \nFigure 5. A comparison between the summary success rate of annual estimates of GPP (left), Re (centre) and \nNEE (right) for each algorithm plotted against the mean size of the 90% confidence interval used in the tests. \nThe tests were for DE-SYN and EV-SYN, the synthetic datasets. Success was judged on whether each \u201ctrue\u201d \nannual flux was within the 90% confidence interval of the estimate. There were 6 tests (3 years x 2 datasets) for \neach flux. On the right panel the results for E1 and M1 were very similar. All panels have the same scale. \n \nFox, Williams et al. \n48 \n \n \n \nFigure 6. Annual analyses of NEE, GPP and Re for 2000, 2001 and prognoses for 2002 generated with the DE-EC dataset from Hesse, France.  Results are shown for each \nalgorithm for NEE and for 8 algorithms for GPP and Re, with 90% confidence intervals indicated. The dashed lines show the best estimates from gap-filling routines using \nhourly NEE data, while the dotted lines show interquartile range among the estimates from the array of gap-filling routines for 2001 and 2002. (Desai et al. 2008).\nFox, Williams et al. \n49 \n \nFigure 7 Annual analyses of NEE, GPP and Re for 2000, 2001 and prognoses for 2002 generated with the EV-EC dataset from Loobos, Netherlands.  Results are shown for \neach algorithm for NEE and for 8 algorithms for GPP and Re, with 90% confidence intervals indicated. The dashed lines show the best estimates from gap-filling routines \nusing hourly NEE data (Desai et al. 2008). \nFox, Williams et al. \n50 \n \n \nFigure 8 Retrieved estimates of foliar C stocks over three years for the EV-EC deciduous site with \nobservations of NEE fluxes and LAI assimilated. The upper panel shows best fit or mean for Cf, with \nobservations marked, and the lower panel shows the width of the 90% confidence interval. \nFox, Williams et al. \n51 \n \nFigure 9. Retrieved estimates of soil organic matter\/coarse woody debris C stocks over three years for the \nDE-EC deciduous site with observations of NEE fluxes and LAI assimilated. The upper panel shows best \nfit or mean for Csom, and the lower panel shows the width of the 90% confidence interval. \nFox, Williams et al. \n52 \n \nFigure 10. Retrieved estimates of woody C stocks over three years for the DE-EC deciduous site with \nobservations of NEE fluxes and LAI assimilated. The upper panel shows best fit or mean for Cw, and the \nlower panel shows the width of the 90% confidence interval. \n"}
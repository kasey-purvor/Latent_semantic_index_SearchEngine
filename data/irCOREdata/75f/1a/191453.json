{"doi":"10.1007\/s10710-007-9024-z","coreId":"191453","oai":"oai:lra.le.ac.uk:2381\/1117","identifiers":["oai:lra.le.ac.uk:2381\/1117","10.1007\/s10710-007-9024-z"],"title":"A self-organizing random immigrants genetic algorithm for dynamic optimization problems","authors":["Tinos, Renato","Yang, Shengxiang"],"enrichments":{"references":[{"id":44628538,"title":"A genetic algorithm with variable range of local search for tracking changing environments.","authors":[],"date":"1996","doi":"10.1007\/3-540-61723-x_1002","raw":"F. Vavak, T. C. Fogarty, and K. Jukes. A genetic algorithm with variable range of local search for tracking changing environments. In H.-M. Voigt, editor, Parallel Problem Solving from Nature, number 1141 in LNCS. Springer Verlag Berlin, 1996.","cites":null},{"id":44628532,"title":"Adaptation to a changing environment by means of the feedback thermodynamical genetic algorithm.","authors":[],"date":"1998","doi":"10.1007\/bfb0056858","raw":"N. Mori, H. Kita, and Y. Nishikawa. Adaptation to a changing environment by means of the feedback thermodynamical genetic algorithm. In A. E. Eiben, T. Ba\u00a8ck, M. Schoenauer, and H.-P. Schwefel, editors, Parallel Problem Solving from Nature, number 1498 in LNCS, pages 149\u2013158. Springer, 1998.","cites":null},{"id":44628530,"title":"An Introduction to Genetic Algorithms.","authors":[],"date":"1996","doi":"10.1007\/978-3-662-03315-9_1","raw":"M. Mitchell. An Introduction to Genetic Algorithms. MIT Press, 1996.","cites":null},{"id":44628506,"title":"An investigation into the use of hypermutation as an adaptive operator in genetic algorithms having continuouis, time-dependent nonstationary environments.","authors":[],"date":"1990","doi":null,"raw":"H. G. Cobb. An investigation into the use of hypermutation as an adaptive operator in genetic algorithms having continuouis, time-dependent nonstationary environments. Technical Report AIC-90-001, Naval Research Laboratory, Washington, USA, 1990.","cites":null},{"id":44628510,"title":"Analyzing deception in trap functions.","authors":[],"date":"1993","doi":"10.1016\/b978-0-08-094832-4.50012-x","raw":"K. Deb and D. E. Goldberg. Analyzing deception in trap functions. In L. D. Whitley, editor, Foundation of Genetic Algorithms 2, pages 93\u2013108, 1993.","cites":null},{"id":44628534,"title":"Biological extinction in earth history.","authors":[],"date":"1986","doi":"10.1126\/science.11542058","raw":"D. M. Raup. Biological extinction in earth history. Science, 231:1528\u20131533, 1986.","cites":null},{"id":44628542,"title":"Constructing dynamic test environments for genetic algorithms based on problem difficulty.","authors":[],"date":"2004","doi":"10.1109\/cec.2004.1331042","raw":"S. Yang. Constructing dynamic test environments for genetic algorithms based on problem difficulty. In Proc. of the 2004 IEEE Congress on Evolutionary Computation, volume 2, pages 1262\u20131269, 2004.","cites":null},{"id":44628502,"title":"Evolutionary approaches to dynamic optimization problems - introduction and recent trends.","authors":[],"date":"2003","doi":"10.1007\/978-3-642-18965-4_9","raw":"J. Branke. Evolutionary approaches to dynamic optimization problems - introduction and recent trends. In J. Branke, editor, Proc. of the GECCO Workshop on Evolutionary Algorithms for Dynamic Optimization Problems, pages 2\u20134, 2003.","cites":null},{"id":44628500,"title":"Evolutionary Optimization in Dynamic Environments.","authors":[],"date":"2001","doi":"10.1007\/978-1-4615-0911-0","raw":"J. Branke. Evolutionary Optimization in Dynamic Environments. Kluwer, 2001.","cites":null},{"id":44628536,"title":"Evolutionary optimization in non-stationary environments.","authors":[],"date":"2000","doi":"10.1109\/cec.1999.785498","raw":"K. Trojanowski and Z. Michalewicz. Evolutionary optimization in non-stationary environments. Journal of Computer Science and Technology, 1(2):93\u2013124, 2000. 24 Renato Tino\u00b4s, Shengxiang Yang","cites":null},{"id":44628522,"title":"Evolutionary optimization in uncertain environments - a survey.","authors":[],"date":"2005","doi":"10.1109\/tevc.2005.846356","raw":"Y. Jin and J. Branke. Evolutionary optimization in uncertain environments - a survey. IEEE Trans. on Evolutionary Computation, 9(3):303\u2013317, 2005.","cites":null},{"id":44628544,"title":"Experimental study on population-based incremental learning algorithms for dynamic optimization problems.","authors":[],"date":"2005","doi":"10.1007\/s00500-004-0422-3","raw":"S. Yang and X. Yao. Experimental study on population-based incremental learning algorithms for dynamic optimization problems. Soft Computing, 9(11):815\u2013834, 2005. Genet Program Evolvable Mach 25","cites":null},{"id":44628528,"title":"Extending particle swarm optimisers with self-organized criticality.","authors":[],"date":"2002","doi":"10.1109\/cec.2002.1004479","raw":"M. L\u00f8vbjerg and T. Krink. Extending particle swarm optimisers with self-organized criticality. In Proc. of the 2002 IEEE Congress on Evolutionary Computation, volume 2, pages 1588\u20131593, 2002.","cites":null},{"id":44628518,"title":"Genetic algorithms for changing environments.","authors":[],"date":"1992","doi":"10.1007\/978-1-4615-2740-4","raw":"J. J. Grefenstette. Genetic algorithms for changing environments. In R. Maenner and B. Manderick, editors, Parallel Problem Solving from Nature 2, pages 137\u2013144. North Holland, 1992.","cites":null},{"id":44628508,"title":"Genetic algorithms for tracking changing environments.","authors":[],"date":"1993","doi":null,"raw":"H. G. Cobb and J. J. Grefenstette. Genetic algorithms for tracking changing environments. In S. Forrest, editor, Proc. of the 5th Int. Conf. on Genetic Algorithms, pages 523\u2013530, 1993.","cites":null},{"id":44628512,"title":"Genetic Algorithms in Search, Optimization, and Machine Learning.","authors":[],"date":"1989","doi":"10.5860\/choice.27-0936","raw":"D. A. Goldberg. Genetic Algorithms in Search, Optimization, and Machine Learning. Addison-Wesley Publishing Company, Inc., 1989.","cites":null},{"id":44628494,"title":"How Nature Works: the Science of Self-organized Criticality.","authors":[],"date":"1997","doi":"10.1063\/1.882032","raw":"P. Bak. How Nature Works: the Science of Self-organized Criticality. Oxford University Press, 1997.","cites":null},{"id":44628540,"title":"Non-stationary problem optimization using the primal-dual genetic algorithm. In","authors":[],"date":"2003","doi":"10.1109\/cec.2003.1299951","raw":"S. Yang. Non-stationary problem optimization using the primal-dual genetic algorithm. In R. Sarker, R. Reynolds, H. Abbass, K.-C. Tan, R. McKay, D. Essam, and T. Gedeon, editors, Proc. of the 2003 IEEE Congress on Evolutionary Computation, volume 3, pages 2246\u20132253, 2003.","cites":null},{"id":44628504,"title":"On the use of niching for dynamic landscapes.","authors":[],"date":"1997","doi":"10.1109\/icec.1997.592336","raw":"W. Cedeno and V. R. Vemuri. On the use of niching for dynamic landscapes. In Proc. of the 1997 IEEE Int. Conf. on Evolutionary Computation, pages 361\u2013366, 1997.","cites":null},{"id":44628498,"title":"Optimization with extremal dynamics.","authors":[],"date":"2003","doi":"10.1103\/physrevlett.86.5211","raw":"S. Boettcher and A. G. Percus. Optimization with extremal dynamics. Complexity, 8(2):57\u201362, 2003.","cites":null},{"id":44628526,"title":"Self-organized criticality and mass extinction in evolutionary algorithms.","authors":[],"date":"2001","doi":"10.1109\/cec.2001.934321","raw":"T. Krink and R. Thomsen. Self-organized criticality and mass extinction in evolutionary algorithms. In Proc. of the 2001 Congress on Evolutionary Computation, volume 2, pages 1155\u20131161, 2001.","cites":null},{"id":44628520,"title":"Self-organized Criticality: Emergent Complex Behavior in Physical and Biological Systems.","authors":[],"date":"1998","doi":"10.1017\/cbo9780511622717","raw":"H. J. Jensen. Self-organized Criticality: Emergent Complex Behavior in Physical and Biological Systems. Cambridge University Press, 1998.","cites":null},{"id":44628496,"title":"Self-organized criticality. an explanation of 1\/f noise.","authors":[],"date":"1987","doi":"10.1103\/physrevlett.59.381","raw":"P. Bak, C. Tang, and K. Wiesenfeld. Self-organized criticality. an explanation of 1\/f noise. Physical Review Letters, 59(4):381\u2013384, 1987.","cites":null},{"id":44628514,"title":"The Design of Innovation: Lessons from and for Competent Genetic Algorithms.","authors":[],"date":"2002","doi":"10.1007\/978-1-4757-3643-4_12","raw":"D. A. Goldberg. The Design of Innovation: Lessons from and for Competent Genetic Algorithms. Boston, MA: Kluwer Academic Publishers., 2002.","cites":null},{"id":44628524,"title":"The Origins of Order: Self-organization and Selection in Evolution.","authors":[],"date":"1993","doi":"10.1016\/s0006-3495(93)81321-3","raw":"S. A. Kauffman. The Origins of Order: Self-organization and Selection in Evolution. Oxford University Press, 1993.","cites":null},{"id":44628516,"title":"Wonderful Life: The Burgess Shale and the Nature of History.","authors":[],"date":"1989","doi":"10.1002\/ajpa.1330840314","raw":"S. J. Gould. Wonderful Life: The Burgess Shale and the Nature of History. W. W. Norton and Company, 1989.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-09","abstract":"This is the authors' final draft of the paper published as Genetic Programming and Evolvable Machines, 2007, 8(3), pp. 255-286.  The original publication is available at www.springerlink.com, DOI: 10.1007\/s10710-007-9024-zIn this paper a genetic algorithm is proposed where the worst individual and\\ud\nindividuals with indices close to its index are replaced in every generation by randomly\\ud\ngenerated individuals for dynamic optimization problems. In the proposed genetic algorithm, the replacement of an individual can affect other individuals in a chain reaction. The new individuals are preserved in a subpopulation which is defined by the number of individuals created in the current chain reaction. If the values of fitness are similar, as is the case with small diversity, one single replacement can affect a large number of individuals in the population. This simple approach can take the system to a self-organizing behavior, which can be useful to control the diversity level of the population and hence allows the genetic algorithm to escape from local optima once the problem changes due to\\ud\nthe dynamics","downloadUrl":"http:\/\/hdl.handle.net\/2381\/1117","fullTextIdentifier":"https:\/\/lra.le.ac.uk\/bitstream\/2381\/1117\/1\/GPEM07.pdf","pdfHashValue":"20e2b8f1e73529dec1e1bb86db1e44c38ff1a806","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:lra.le.ac.uk:2381\/1117<\/identifier><datestamp>\n                2012-05-25T15:52:10Z<\/datestamp><setSpec>\n                com_2381_316<\/setSpec><setSpec>\n                com_2381_9549<\/setSpec><setSpec>\n                col_2381_1116<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nA self-organizing random immigrants genetic algorithm for dynamic optimization problems<\/dc:title><dc:creator>\nTinos, Renato<\/dc:creator><dc:creator>\nYang, Shengxiang<\/dc:creator><dc:description>\nThis is the authors' final draft of the paper published as Genetic Programming and Evolvable Machines, 2007, 8(3), pp. 255-286.  The original publication is available at www.springerlink.com, DOI: 10.1007\/s10710-007-9024-z<\/dc:description><dc:description>\nIn this paper a genetic algorithm is proposed where the worst individual and\\ud\nindividuals with indices close to its index are replaced in every generation by randomly\\ud\ngenerated individuals for dynamic optimization problems. In the proposed genetic algorithm, the replacement of an individual can affect other individuals in a chain reaction. The new individuals are preserved in a subpopulation which is defined by the number of individuals created in the current chain reaction. If the values of fitness are similar, as is the case with small diversity, one single replacement can affect a large number of individuals in the population. This simple approach can take the system to a self-organizing behavior, which can be useful to control the diversity level of the population and hence allows the genetic algorithm to escape from local optima once the problem changes due to\\ud\nthe dynamics.<\/dc:description><dc:date>\n2007-10-10T12:45:51Z<\/dc:date><dc:date>\n2007-10-10T12:45:51Z<\/dc:date><dc:date>\n2007-09<\/dc:date><dc:type>\nArticle<\/dc:type><dc:identifier>\nGenetic Programming and Evolvable Machines, 2007, 8(3), pp.255-286<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2381\/1117<\/dc:identifier><dc:language>\nen<\/dc:language><dc:relation>\nRAE 2007<\/dc:relation><dc:publisher>\nSpringer<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["RAE 2007"],"year":2007,"topics":[],"subject":["Article"],"fullText":"Genetic Programming and Evolvable Machines, 8(3): 255-286, 2007.\n(DOI 10.1007\/s10710-007-9024-z)\nA Self-Organizing Random Immigrants Genetic\nAlgorithm for Dynamic Optimization Problems\nRenato Tino\u00b4s1, Shengxiang Yang2\n1 Departamento de F\u00b4\u0131sica e Matema\u00b4tica, FFCLRP, Universidade de Sa\u02dco Paulo (USP),\nRibeira\u02dco Preto, 14040-901, Brazil e-mail: rtinos@ffclrp.usp.br\n2 Department of Computer Science, University of Leicester, University Road, Leicester\nLE1 7RH, United Kingdom e-mail: s.yang@mcs.le.ac.uk\nSeptember 12, 2007\nAbstract In this paper a genetic algorithm is proposed where the worst individual and\nindividuals with indices close to its index are replaced in every generation by randomly\ngenerated individuals for dynamic optimization problems. In the proposed genetic algo-\nrithm, the replacement of an individual can affect other individuals in a chain reaction.\nThe new individuals are preserved in a subpopulation which is defined by the number of\nindividuals created in the current chain reaction. If the values of fitness are similar, as is\nthe case with small diversity, one single replacement can affect a large number of indi-\nviduals in the population. This simple approach can take the system to a self-organizing\nbehavior, which can be useful to control the diversity level of the population and hence\nallows the genetic algorithm to escape from local optima once the problem changes due to\nthe dynamics.\nKeywords genetic algorithms, self-organized criticality, dynamic optimization problems,\nrandom immigrants\n1 Introduction\nIn recent years evolutionary algorithms (EAs) have been successfully applied to a\nlarge number of optimization problems. EAs are a class of meta-heuristic algorithms\nwhich are inspired by the principles of natural evolution. While natural evolution\ndeals very well with environmental changes, caused, for example, by natural cata-\nclysms, geological modifications, and competition for natural resources, they rep-\nresent a serious challenge for traditional EAs. As a significant part of optimization\nproblems in the real world are dynamic optimization problems (DOPs), there is a\ngrowing interest in research of EAs for such problems [4].\nIn DOPs, the evaluation function, the decision variables, and the constraints of\nthe optimization problem are not fixed [22]. When changes occur in the problem,\nthe solution given by the optimization procedure may be no longer effective, and a\n2 Renato Tino\u00b4s, Shengxiang Yang\nnew solution should be found [5]. The optimization problem may change for several\nreasons, like faults, machine degradation, environmental or climatic modifications,\nor economic factors.\nThe simplest approach to deal with DOPs is to start a new optimization process\nwhenever a change in the problem is noticed. The optimization process, however,\ngenerally requires time and substantial computational effort. If the new solution\nafter the change in the problem is, in some sense, related to the previous solution,\nknowledge obtained during the search for the old solution can be used to find a new\nsolution [15]. In this case, the search for new solutions based on the old solutions\ncan save substantial processing time. EAs are particularly attractive for such prob-\nlems. Individuals representing solutions of the problem prior to the changes can be\ntransferred into the new optimization process.\nHowever, in EAs, the population of solutions generally converges in the fitness\nlandscape to points close to the best individual of a population. If the fitness land-\nscape abruptly changes, the actual population can be trapped in local optima close\nto the old solution. In fact, premature convergence of the solution to a local op-\ntimum is not a problem exclusive to DOPs. It can also be a serious problem in\nstationary optimization problems [19]. In order to avoid premature convergence,\nseveral approaches where diversity is re-introduced or maintained throughout the\nrun have been proposed in the literature over recent years (see surveys [5,15,22]).\nTypical examples of such approaches are the random immigrants approach [13],\nsharing or crowding mechanisms [6], variable local search [23], thermodynamic ge-\nnetic algorithm [20], and the use of hypermutation [7].\nThe random immigrants approach is very interesting and simple [13]. In a ge-\nnetic algorithm (GA) with random immigrants, a fraction of the current population\nis replaced by randomly generated individuals in each generation of the run. A re-\nplacement strategy, like replacing random or worst individuals of the population,\ndefines which individuals are replaced by the immigrants. The random immigrants\napproach tries to maintain the diversity level of the population, which can be very\nuseful to prepare the GA for possible changes in the fitness landscape [8].\nHowever, if the number of genes in an individual is high and the local optimum of\nthe population has fitness much higher than the mean fitness of all possible solutions\nof the search space, the survival probability of new random individuals is generally\nvery low. This happens because the selection methods employed in GAs preserve,\ndirectly or indirectly, the best individuals of a population, and the probability that\nthe fitness of new random individuals is higher than (or close to) the fitness of\ncurrent individuals is generally low.\nIn this paper, instead of substituting the worst or randomly selected individuals\nwith random immigrants in each generation, the worst individual and individuals\nwith indices close to its index are replaced. The newly introduced immigrants are\nplaced in a subpopulation and are not allowed to be replaced by individuals of the\nmain population. In this way, individuals start to interact among themselves and,\nif the fitness of the individuals is close, as in the case of low diversity levels, one\nsingle replacement of an individual can affect a great number of individuals of the\npopulation in a chain reaction. The number of individuals in the subpopulation is\nnot defined by the programmer, but is given by the number of individuals created\nGenet Program Evolvable Mach 3\nin the current chain reaction. It is important to observe that this simple approach\ncan take the system to a self-organized behavior useful in DOPs.\nThe experimental results of our work suggest that the proposed GA represents\na kind of self-organizing behavior known as self-organized criticality (SOC) [1],\ndescribed in Sect. 3 of this paper. Prior to that, we present in Sect. 2 the random\nimmigrants approach. The proposed GA is presented in Sect. 4, and experimental\nresults with DOPs are reported and analyzed in Sect. 5. Sect. 6 concludes our paper\nwith discussions on relevant future work.\n2 The Random Immigrants Genetic Algorithm\nThe Random Immigrants GA (RIGA) proposed by Grefenstette [13] is inspired by\nthe flux of immigrants in a biological population. In GAs, the flux of immigrants\ngenerally increases the genetic diversity level of a population, allowing to escape\nfrom local optima caused by occasional environmental changes. The RIGA can be\nsummarized by Algorithm 1, where i denotes the index of each individual of the\npopulation. Algorithm 1 differs from the generational Simple GA (SGA) only by\nthe inclusion of line 4.\nAlgorithm 1 Random Immigrants Genetic Algorithm\nRequire: pc: crossover rate; pm: mutation rate; rr: replacement rate\n1: initializePopulation(P)\n2: evaluatePopulation(P)\n3: while (stop criteria are not satisfied) do\n4: P \u2190 replaceFractionPopulation(P, rr)\n5: for i\u2190 1 to P.size do\n6: Pnew.individual(i) \u2190 selection(P,i)\n7: end for\n8: crossover(Pnew ,pc)\n9: mutation(Pnew,pm)\n10: evaluatePopulation(Pnew)\n11: P \u2190 Pnew\n12: end while\nIn the RIGA, some individuals of the current population P are replaced by\nrandomly generated individuals. A replacement rate rr specifies the number of in-\ndividuals replaced in each generation. In the standard RIGA, randomly chosen in-\ndividuals are replaced in each generation. In another replacement strategy, instead\nof replacing randomly chosen individuals, the individuals of the current population\nwith the lowest fitness are replaced by random immigrants.\n3 Self-Organized Criticality\nBak et al. suggested in Ref. [2] that systems with several interacting constituents\nmay exhibit a kind of self-organizing behavior, which was named SOC, with inter-\n4 Renato Tino\u00b4s, Shengxiang Yang\nesting properties. It was suggested that several phenomena exhibit SOC, e.g., sand\npiles, earthquakes, forest fires, electric breakdowns, or growing interfaces.\nSystems exhibiting SOC have an interesting characteristic: even without any\ncontrol action from outside, they self-organize into a critical state [14]. In a system\nexhibiting non-critical behavior, the distribution of responses to external perturba-\ntion is narrow and can be well described by an averaged value. In a system exhibiting\ncritical behavior, no single characteristic response exists, i.e., the system exhibits\nscale invariance, and a small perturbation in one location of the system may gen-\nerate a small effect on its neighbourhood or a chain reaction that affects all the\nconstituents of the system.\nThe statistical distributions describing the response of the system exhibiting\nSOC are given by power laws in the form\np(s) \u223c s\u2212\u03c4 (1)\nand\np(d) \u223c d\u2212\u03b1, (2)\nwhere s is the number of constituents of the system affected by the perturbation, d\nis the duration of the chain reaction (lifetime), and \u03c4 and \u03b1 are real constants. As\nan example, consider the sand pile model described in [2], where a single grain is\nadded at a random position in every interval of time \u2206t. In order to characterize the\nresponse of the system, one can measure the number of sand grains (s) involved in\neach avalanche induced by the addition of a single grain and the duration (d) of each\navalanche. In the critical state, the statistical distributions describing the response\nof the sand pile model to the addition of a single grain are given by Eqs. 1 and 2,\nand the addition of a single grain can affect from only a grain in its neighbourhood\nto the whole sand pile.\nResearchers have suggested that SOC occurs in natural evolution too [1]. Evi-\ndence of SOC in evolution would be the fact that it does not happen gradually at a\nslow and constant pace [12]. There are many more small extinction events than large\nevents, such as the Cretaceous extinction of dinosaurs and many other species, and\nextinction events occur on a large variety of length scales [21]. These facts suggest\nthat extinctions propagate through ecosystems, such as avalanches in a sand pile,\nand perturbations of the same size can unleash extinction events of a large variety\nof sizes. This would occur because species coevolve to a critical state [16].\nIn Ref. [1], a very simple simulation model, known as the Bak-Sneppen Model,\nwas proposed to explore the connection between evolution and SOC. In the one-\ndimensional version of this model, the individuals (or species in the authors\u2019 ter-\nminology) are placed in a circle, and a random value of fitness is assigned to each\nindividual. In each generation of the simulation, the individual with the lowest fit-\nness in the current population, one individual located to its right position, and one\nto its left position will have their fitness values replaced by random values. An anal-\nogy of the connection between neighbours in the model is the interaction between\nspecies in nature. If, as an example, a prey goes extinct, the fitness of its predators\nwill change. The Bak-Sneppen Model can be summarized by Algorithm 2.\nThis simple model can lead to interesting behavior. At the outset of the sim-\nulation, mean fitness of the population is low, but, as the number of generation\nGenet Program Evolvable Mach 5\nAlgorithm 2 Bak-Sneppen Model\n1: Find the index j of the individual with the lowest fitness\n2: Replace the fitness of individuals with indices j, j \u2212 1, and j + 1 by random values\ndrawn from uniform distribution\nincreases, mean fitness increases, too. Eventually, mean fitness ceases to increase,\nand the critical state is reached. In the Bak-Sneppen Model, a substitution of the\nfitness of the worst individual causes the substitution of its two next neighbours.\nIn the critical state, the values of fitness of the neighbours are very often replaced\nby random numbers with smaller values. The new worst individual can be then one\nof these two neighbours, which are replaced with its two next neighbours, originat-\ning a chain reaction, called replacement event in this work, that can affect all the\nindividuals of the population. The replacement events exhibit scale invariance and\ntheir statistical distributions are given by power laws in the form of Eqs. 1 and 2.\nLarge replacement events generally occur if almost all individuals of the population\nhave similar high values of fitness.\nIt is important to observe that SOC avoids the situation where a species gets\ntrapped in a local optimum in the fitness landscape. Because the idea is powerful and\nsimple, researchers proposed the use of SOC in optimization processes. Boettcher\nand Percus [3] proposed optimization with extremal dynamics, a local-search heuris-\ntic to find solutions in problems where constituents of the system are connected, e.g.\nspin glass optimization problem. L\u00f8vbjerg and Krink [18] extended particle swarm\noptimization with SOC in order to better control the optimization process and to\nmaintain the diversity level.\nIn GAs, Krink and Thomsen [17] proposed the use of the sand pile model pre-\nviously discussed to generate power laws to determine which individuals, placed\non a grid, should be replaced in each generation. If an individual goes extinct, a\nmutated version of the best individual of the population is created in its place. It\nis important to observe that, however, in the algorithm proposed in Ref. [17] SOC\nappears in the sand pile model used to control the size of the extinctions, and is\nnot the result of a self-organization of constituents of that system (individuals of\nthe GA).\n4 Self-Organizing Random Immigrants Genetic Algorithm\nIn this paper, we propose the replacement of the individual with the lowest fitness\nof the current population and other rr\u22121 individuals with new randomly generated\nindividuals. The indices of individuals in the population are used to determine which\nindividual will be replaced. In each generation of the algorithm, the individual with\nthe lowest fitness in the current population (index j), \u2308(rr \u2212 1)\/2\u2309 individuals with\nindices from j\u2212\u2308(rr \u2212 1)\/2\u2309 to j\u22121, and \u230a(rr \u2212 1)\/2\u230b individuals with indices from\nj + 1 to j + \u230a(rr \u2212 1)\/2\u230b are replaced by randomly generated individuals. It can be\nobserved that, as the proposed GA is not spatially distributed, the indices of the\nindividuals inside the population are random.\n6 Renato Tino\u00b4s, Shengxiang Yang\nIt must be said that this simple idea alone does not guarantee that the system\nexhibits SOC since new random immigrants added to the population generally have\nlow fitness and are very often substituted by individuals with high fitness present\nin the population during the selection phase. As a consequence, the statistical dis-\ntribution describing the response of the system to a single replacement will not be\na power law, but a narrow distribution characterized by a small averaged value.\nIn the newly proposed variant of RIGA, a second strategy is adopted, by which\nthe new immigrants created during the current chain reaction (called replacement\nevent in this paper), are preserved in a subpopulation. The current size of this\nsubpopulation is not defined by the programmer, but is the number of individuals\ncreated in the current replacement event. In other words, the individuals in the\ncurrent population not belonging to the subpopulation are not allowed to replace\nindividuals of the subpopulation. The subpopulation is allowed to evolve, i.e., is\nsubmitted to selection, mutation, and crossover among individuals that belong to\nthe subpopulation.\nThe hope is that the system can now exhibit SOC in order to increase the\ndiversity level of the population in a self-organized way and, therefore, to avoid a\nsituation where individuals get trapped in local optima of the fitness landscape if\nthe problem changes.\nIn the proposed GA, called Self-Organizing Random Immigrants GA (SORIGA),\nthere are two major modifications from the RIGA. In the first modification, the func-\ntion \u201creplaceFractionPopulation(P, rr)\u201d is modified as presented in Algorithm 3. In\nthis function, the individual with the lowest fitness and other rr \u2212 1 individuals are\nreplaced by randomly generated individuals. The current size (or duration) of each\nreplacement event, i.e., the number of times that the individual with the lowest\nfitness and other rr \u2212 1 individuals are replaced in the current replacement event,\nis recorded and denoted by d. Each individual of the population has an index. Each\nelement k of the binary vector P.replaced indicates whether the individual with\nindex k has been replaced for at least once in the current replacement event. For\nexample, P.replaced[k] = 1 means individual k has been replaced in the current\nreplacement event at least once and hence it belongs to the current subpopulation.\nThe number of individuals in the current subpopulation equals the number of el-\nements in P.replaced that are set to 1. When the chain reaction ceases, i.e., the\nindividual with the lowest fitness does not belong to the subpopulation, the duration\nof the replacement event d is reset to 1.\nThe second modification in SORIGA lies in the selection of each individual into\nthe new population, as shown in Algorithm 4. For each new individual, if its index\nwas not involved in the current replacement event, i.e., P.replaced[k] = 0, the new\nindividual is selected from the main population that consists of individuals with\nindex k satisfying P.replaced[k] = 0 using a standard selection scheme; otherwise, it\nis selected from the subpopulation that consists of individuals with index k satisfying\nP.replaced[k] = 1 using a standard selection scheme.\nAs an example, SORIGA is applied to a simple problem where the fitness func-\ntion is defined as\nf(x) =\nu(x)\nl\n, (3)\nGenet Program Evolvable Mach 7\nAlgorithm 3 replaceFractionPopulation(P, rr)\n1: Find the index j of the individual with the lowest fitness\n2: if (P.replaced[j] = 0) then\n3: d \u2190 1\n4: for k \u2190 1 to P.size do\n5: P.replaced(k)\u2190 0\n6: end for\n7: else\n8: d \u2190 d+ 1\n9: end if\n10: for k \u2190 1 to P.size do\n11: if (j \u2212 \u2308(rr \u2212 1)\/2\u2309 \u2264 k \u2264 j + \u230a(rr \u2212 1)\/2\u230b) then\n12: Replace P.individual[k] by a randomly generated individual\n13: P.replaced[k]\u2190 1\n14: end if\n15: end for\nAlgorithm 4 selection(P,i)\n1: if (P.replaced[i] = 0) then\n2: Select an individual from the main population with individuals with index k satis-\nfying P.replaced[k] = 0\n3: else\n4: Select an individual from the subpopulation with individuals with index k satisfying\nP.replaced[k] = 1\n5: end if\nwhere u(x) is the unitation function of a binary vector (individual) x of length\nl, returning the number of ones in vector x. In this example, randomly generated\nindividuals of the first generation are selected according to elitism and roulette\nwheel sampling. Mutation with pm = 0.01 and two-point crossover with pc = 0.6\nare employed. The number of individuals in the population is equal to 12 and l = 30.\nFig. 1 presents the first three steps of a replacement event in a run of SORIGA on\nthis example with replacement rate rr = 3. The figure shows the fitness of all\nindividuals in the current population in generations 27, 28, and 29 respectively.\nIn generation 27, the individual with index 6 (index j in Algorithm 3) has the\nlowest fitness in the population. In this way, this individual and the individuals\nwith indices 5 and 7 are replaced by random individuals. In the next generation,\nthe individual with index j = 5 has now the lowest fitness, and together with the\nindividuals with indices 4 and 6 is replaced. In generation 29, the individual with\nindex j = 4 has the lowest fitness. It can be observed that the chain reaction was\npropagated because the remaining individuals have fitness values higher than the\nindividuals in the subpopulation defined by the individuals with indices k, where\nP.replaced[k] = 1 (see Algorithms 3 and 4).\n8 Renato Tino\u00b4s, Shengxiang Yang\n1 2 3 4 5 6 7 8 9 10 11 12\n0\n0.5\n1\n1.5\nfit\nne\nss\n1 2 3 4 5 6 7 8 9 10 11 12\n0\n0.5\n1\n1.5\nfit\nne\nss\n1 2 3 4 5 6 7 8 9 10 11 12\n0\n0.5\n1\n1.5\nindividual\nfit\nne\nss\n 0         0          0         0          1         1          1          0         0          0         0         0\n 0         0          0          1         1          1         1          0         0          0         0          0\n 0         0          1         1         1          1         1          0         0          0         0          0\nt = 27\nd = 1 \nj = 6\nt = 28\nd = 2 \nj = 5\nt = 29\nd = 3 \nj = 4\nFig. 1 Fitness of the individuals of the current population at generations 27, 28, and 29\nin a run of the SORIGA on the example problem. The 0\u2019s and 1\u2019s indicates the values of\neach element of the vector P.replaced.\n5 Experimental Study\nIn order to evaluate the performance of SORIGA, five sets of experiments were car-\nried out. In the experiments presented in this work, the dynamic problem generator\nproposed in [24,26] is employed to construct DOPs based on five stationary test\nproblems. The dynamic problem generator is presented in Sect. 5.1 while the five\nstationary test problems used for this purpose are described in Sect. 5.2.\nIn all experiments presented here, SORIGA is compared to SGA, and two ver-\nsions of the GA with random immigrants. In the first version, denoted RIGA1, rr\nindividuals randomly chosen are replaced by new random individuals. In the sec-\nond version, denoted RIGA2, the rr worst individuals, i.e., the individuals with the\nlowest fitness, are replaced by new random individuals. The experimental design is\ndescribed in Sect. 5.3, and the results are presented and analyzed respectively in\nSects. 5.4 and 5.5. The results of including a neighboring scheme to SORIGA are\npresented in Sect. 5.6.\n5.1 Dynamic Problem Generator\nIn order to evaluate the performance of different GAs in DOPs, a dynamic problem\ngenerator that can generate DOPs from any binary encoded stationary problem was\nproposed in Refs. [24,26]. Given a stationary problem where the fitness function is\nGenet Program Evolvable Mach 9\nf(x) and x \u2208 {0, 1}l, the dynamics of an environment that is periodically changed\nevery \u03c4 generations is formulated as follows:\nf(x, t) = f\n(\nx\u2295M(k)\n)\n(4)\nwhere \u2295 is the bitwise exclusive-or (XOR) operator, t is the generation index,\nk = \u2308t\/\u03c4\u2309 is the period index, and M(k) is a binary mask for period k that is\nincrementally generated by:\nM(k) =M(k \u2212 1)\u2295T(k) (5)\nwhere T(k) is a binary template randomly created for period k containing \u230a\u03c1\u00d7 l\u230b\nones, and {\u03c1 \u2208 R | 0.0 \u2264 \u03c1 \u2264 1.0} controls the degree of change for the DOP. If\n\u03c1 = 0.0, the problem stays stationary, while if \u03c1 = 1.0, the extreme fitness landscape\nchange in the sense of Hamming distance occurs. For the first period,M(1) is equal\nto the zero vector. The dynamic problem generator proposed in Refs. [24,26] can\nbe used to investigate the performance of different GAs in well studied benchmark\noptimization problems, e.g., the royal road function (see next section).\n5.2 Stationary Test Problems\nFive stationary problems are selected as test suite for the algorithms SGA, RIGA1,\nRIGA2, and SORIGA. The DOPs are constructed from these stationary problems\nusing the dynamic problem generator described in Sect. 5.1.\n5.2.1 Royal Road Function: Mitchell, Forrest, and Holland proposed a class of\nfitness landscapes, called royal road functions, to investigate the schema processing\n[19]. One of these functions, called royal road R1, is defined as:\nf(x) =\nq\u2211\ns=1\ncs \u03b4s(x) (6)\nwhere q is the number of schemata that are juxtaposed and summed together,\ncs = c if the schema s is present in the solution x, and cs = 0 otherwise. In this\ncontribution, the royal road function is defined on a sixty-four bit string, and each\nschema is composed of 8 contiguous fixed bits. If all bits of x corresponding to the\nfixed bits of the schema s are equal to 1, c = 8 is added to the fitness function.\n5.2.2 Deceptive Functions: Trap functions can be used to create deceptive func-\ntions for GAs, i.e., function where there exist low-order schemata that, instead of\ncombining to form high-order schemata, forms schemata resulting in a deceptive\nsolution that is sub-optimal [10], [11]. A trap function is defined as follows:\nf(x) =\n{\na\nz\n(z \u2212 u(x)), if u(x) \u2264 z\nb\nl\u2212z\n(u(x)\u2212 z), otherwise,\n(7)\n10 Renato Tino\u00b4s, Shengxiang Yang\nwhere u(x) is the unitation function of a binary vector x of length l, a is the local\nand possibly deceptive optimum, b is the global optimum, and z is the slope-change\nlocation which separates the attraction basin sizes of the two optima.\nA trap function is deceptive on average if the ratio of the fitness of the local\noptimum to that of the global optimum is constrained by the following relation [9]:\na\nb\n\u2265\n2\u2212 1\/(l\u2212 z)\n2\u2212 1\/z\n(8)\nThe parameters a, b, and z determine the difficulty for GAs to find the global\noptimum b as opposed to the local optimum a [25]. Two deceptive functions based on\ntrap functions are considered in this work. In the first deceptive function (deceptive\nfunction 1), 10-bit trap functions are employed with a set to 0.82 and z set to 8.\nIn the second deceptive function (deceptive function 2), 50-bit trap functions are\nemployed with a set to 0.80 and z set to 48. In both functions, b is set to 1.0.\n5.2.3 Scaling Problems: Deception is not the only element that can generate dif-\nficulty to a GA. The problem difficulty can also be caused by scaling. The scaling\nproblem arises in functions that consist of several schemata with different worth to\nthe solution [11]. A scaling problem can be simulated using additively decomposable\nfunctions as follows:\nf(x) =\nq\u2211\ns=1\ncs fs(xIs) (9)\nwhere q is the number of schemata that are juxtaposed and summed together, Is is\nthe set of the fixed bit positions that form schema s, and cs is the scaling factor for\neach sub-function fs. The royal road function presented in this section is a scaling\nproblem with uniform scaling, i.e., cs = c.\nUsing Eqs. 7 and 9, it is possible to create different scaling problems based on\ntrap functions by adjusting the parameters cs. Two scaling problems based on trap\nfunctions and with exponential scaling (cs = 2\ns\u22121) are considered in this work. In\nthe first scaling problem (scaling problem 1), the fitness function is computed by\njuxtaposing and summing together four 5-bit trap functions. In the second scaling\nproblem (scaling problem 2), the fitness function is computed by juxtaposing and\nsumming together ten 5-bit trap functions. In both problems, b is set to 1.0, a is\nset to 0.7, and z is set to 3.\n5.3 Experimental Design\nIn the dynamic problem generator described in Sect. 5.1, the fitness function is\nperiodically changed every \u03c4 generations according to Eqs. 4 and 5. The algorithm\ncapability of adapting to dynamic environments under different degree of conver-\ngence can be investigated by setting \u03c4 to different values. Based on our preliminary\nexperiments on stationary problems, \u03c4 is set to three different values. The first two\nvalues, \u03c4 = 10 and \u03c4 = 200, imply a change in the fitness function in an early and\na medium stage of the optimization process respectively. The last value, \u03c4 = 1000\nGenet Program Evolvable Mach 11\nimplies a change in the fitness function at a late or converged stage of the optimiza-\ntion process. Each algorithm was executed for 10 periods of environmental changes.\nThe degree of change in the dynamic problem generator is controlled by setting\nparameter \u03c1. Three different values of \u03c1 were used here in the experiments. These\nvalues represent different change levels: very light shifting (\u03c1 = 0.05), medium vari-\nation (\u03c1 = 0.6), and very high change (\u03c1 = 0.95). In the experiments with deceptive\nproblem 1, as \u230a\u03c1\u00d7 l\u230b = 0 when l = 10 and \u03c1 = 0.05, the values of \u03c1 are set to 0.10,\n0.60, and 0.90.\nIn order to compare different GAs, each algorithm was executed 30 times (with\n30 random seeds) for each one of the test problems described in the last section\nand with each one of the nine combinations of the environmental dynamics pa-\nrameters \u03c4 and \u03c1. For each run of an algorithm for a DOP, the individuals of the\ninitial population were randomly chosen. In each generation, two individuals of the\npopulation were selected according to elitism and the remaining individuals were\nselected according to roulette wheel sampling (Sections 5.4.1 and 5.4.3) or tour-\nnament selection (Sect. 5.4.2). Traditional bit mutation with rate pm = 0.01 and\ntwo-point crossover with rate pc = 0.7 were employed. The population size was set\nto 120 individuals. Three replacement rates are considered for the algorithms with\nrandom immigrants in order to compare the performance of the algorithms when\nthe number of replaced individuals changes. The first value of rr, whose results are\ndiscussed in Sections 5.4.1 and 5.4.2, is set to 3, i.e., 3 individuals (2.5% of the\npopulation) are replaced by random immigrants in each generation. The second\nand third values of rr with results presented in Sect. 5.4.3 are set to 12 and 24\nrespectively, i.e., 12 individuals or 24 (10% or 20 % of the population) are replaced\nby random immigrants in each generation.\nThe comparison of results obtained by different algorithms on DOPs is more\ncomplex than the same comparison on stationary problems [22]. For DOPs, it is\nnecessary to evaluate not the final result, but rather the optimization process itself.\nThe mean best-of-generation fitness was used to evaluate the GAs.\n5.4 Experimental Results\nExperiments were carried out on the dynamic version of the test problems described\nin Sect. 5.2 in order to help analyze the performance of the algorithms on dynamic\nproblems. Results are presented in the following sections for different selection meth-\nods and different values of the replacement rates.\n5.4.1 Selection with Roulette Wheel Sampling: Selection with roulette wheel sam-\npling is a fitness-proportionate selection, where the expected number of times an\nindividual is selected to reproduce is equal to its fitness divided by the mean pop-\nulation fitness [19]. The experimental results on DOPs averaged over 30 runs with\nroulette wheel sampling and rr = 3 for the GAs with random immigrants are shown\nin Tables 1 and 2. Experimental results of mean best-of-generation fitness and some\nstatistical test results over this measure are presented in Table 1. Experimental re-\nsults of mean population fitness are presented in Table 2. In Table 1, the statistical\n12 Renato Tino\u00b4s, Shengxiang Yang\n10 20 30 40 50 60 70 80 90 100\n5\n10\n15\n20\n25\n30\n35\n40\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n10 20 30 40 50 60 70 80 90 100\n5\n10\n15\n20\n25\n30\n35\n40\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 2 Best-of-generation fitness of algorithms on dynamic royal road function where the\nenvironmental dynamics parameter \u03c4 is set to 10 and: (a) \u03c1 is set to 0.05, (b) \u03c1 is set to\n0.95.\ncomparison regarding SORIGA - SGA, SORIGA - RIGA1, and SORIGA - RIGA2\nis carried out by t-test with 58 degrees of freedom at a 0.05 level of significance\nregarding the mean best-of-generation fitness. The t-test results are shown in the\nparentheses as \u201c+\u201d, \u201c\u2212\u201d, or \u201c\u223c\u201d when SORIGA is significantly better than, signif-\nicantly worse than, or statistically equivalent to other GAs respectively. Figs. 2-11\nshow the results of mean best-of-generation fitness in experiments where \u03c4 is set\nto 10 or 1000 and \u03c1 is set to 0.05 or 0.95 (0.10 or 0.90 in the experiments with\ndeceptive function 1) respectively.\n5.4.2 Selection with Tournament: Tournament selection is a selection procedure\ncomputationally cheaper than fitness-proportionate selection. In the simplest ver-\nsion of tournament selection, two individuals of the current population are randomly\nchosen and the individual with higher fitness is selected to be reproduced if a random\nnumber generated with uniform distribution in [0, 1] is smaller than a parameter kts\n[19]. Otherwise, the individual with the lower fitness is selected. The parameter kts\nis chosen in [0, 1] and can be used to control the selection pressure. Higher values\nof kts imply higher levels of selection pressure. Experimental results on DOPs aver-\naged over 30 runs and with two values of kts are presented in this section in order to\ncompare the performance of the GAs when the selection pressure changes. Results\nof mean best-of-generation fitness when kts = 0.70 or kts = 0.90 and some statis-\ntical test results over this measure are presented in Tables 3 and 4. The statistic\ncomparison regarding SORIGA - SGA, SORIGA - RIGA1, and SORIGA - RIGA2\nis carried out by t-test with 58 degrees of freedom at a 0.05 level of significance and\nGenet Program Evolvable Mach 13\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0\n10\n20\n30\n40\n50\n60\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0\n10\n20\n30\n40\n50\n60\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 3 Best-of-generation fitness of algorithms on dynamic royal road function where the\nenvironmental dynamics parameter \u03c4 is set to 1000 and: (a) \u03c1 is set to 0.05, (b) \u03c1 is set to\n0.95.\n10 20 30 40 50 60 70 80 90 100\n0.6\n0.7\n0.8\n0.9\n1\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n10 20 30 40 50 60 70 80 90 100\n0.6\n0.7\n0.8\n0.9\n1\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 4 Best-of-generation fitness of algorithms on dynamic deceptive function 1 where the\nenvironmental dynamics parameter \u03c4 is set to 10 and: (a) \u03c1 is set to 0.10, (b) \u03c1 is set to\n0.90.\n14 Renato Tino\u00b4s, Shengxiang Yang\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 5 Best-of-generation fitness of algorithms on dynamic deceptive function 1 where the\nenvironmental dynamics parameter \u03c4 is set to 1000 and: (a) \u03c1 is set to 0.10, (b) \u03c1 is set to\n0.90.\n10 20 30 40 50 60 70 80 90 100\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n10 20 30 40 50 60 70 80 90 100\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 6 Best-of-generation fitness of algorithms on dynamic deceptive function 2 where the\nenvironmental dynamics parameter \u03c4 is set to 10 and: (a) \u03c1 is set to 0.05, (b) \u03c1 is set to\n0.95.\nGenet Program Evolvable Mach 15\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 7 Best-of-generation fitness of algorithms on dynamic deceptive function 2 where the\nenvironmental dynamics parameter \u03c4 is set to 1000 and: (a) \u03c1 is set to 0.05, (b) \u03c1 is set to\n0.95.\n10 20 30 40 50 60 70 80 90 100\n0.75\n0.8\n0.85\n0.9\n0.95\n1\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n10 20 30 40 50 60 70 80 90 100\n0.75\n0.8\n0.85\n0.9\n0.95\n1\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 8 Best-of-generation fitness of algorithms on dynamic Scaling Problem 1 where the\nenvironmental dynamics parameter \u03c4 is set to 10 and: (a) \u03c1 is set to 0.05, (b) \u03c1 is set to\n0.95.\n16 Renato Tino\u00b4s, Shengxiang Yang\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0.6\n0.7\n0.8\n0.9\n1\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0.6\n0.7\n0.8\n0.9\n1\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 9 Best-of-generation fitness of algorithms on dynamic Scaling Problem 1 where the\nenvironmental dynamics parameter \u03c4 is set to 1000 and: (a) \u03c1 is set to 0.05, (b) \u03c1 is set to\n0.95.\n10 20 30 40 50 60 70 80 90 100\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n10 20 30 40 50 60 70 80 90 100\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 10 Best-of-generation fitness of algorithms on dynamic Scaling Problem 2 where the\nenvironmental dynamics parameter \u03c4 is set to 10 and: (a) \u03c1 is set to 0.05, (b) \u03c1 is set to\n0.95.\nGenet Program Evolvable Mach 17\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\ngeneration\nfitn\nes\ns\n(a)\nSGA\nRIGA1\nRIGA2\nSORIGA\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\ngeneration\nfitn\nes\ns\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\nFig. 11 Best-of-generation fitness of algorithms on dynamic Scaling Problem 2 where the\nenvironmental dynamics parameter \u03c4 is set to 1000 and: (a) \u03c1 is set to 0.05, (b) \u03c1 is set to\n0.95.\nthe t-test results are shown in Tables 3 and 4 the same way as in Table 1. In all\nexperiments, rr is set to 3 for the GAs with random immigrants.\n5.4.3 Selection with Roulette Wheel Sampling and with rr = 12 or rr = 24 The\nresults on DOPs averaged over 30 runs for the experiments where roulette wheel\nsampling selection is employed and rr is set to 12 or 24 for the GAs with random\nimmigrants are presented in Tables 5 and 6 respectively. Similarly, the statistical\ncomparison is carried out between SORIGA and other GAs and the t-test results\nare shown in Tables 5 and 6 in the same way as in Table 1.\n5.5 Analysis of the Results\nSeveral results can be observed by analyzing the experimental results. The perfor-\nmance of SORIGA is generally significantly better than the performance of SGA\non the DOPs tested in this paper. The performance of SORIGA increases with the\nperiod of change \u03c4 and with the degree of change \u03c1 for the DOPs. It can be ob-\nserved that the performance of SORIGA is generally better for \u03c1 > 0.10 (medium\nand high degree of changes). These results can be explained by the fact that SGA\nhad difficulty in escaping from the local optima induced by medium or high changes\nof the global optima on the DOPs tested. However, random immigrants inserted in\nevery generation provide diversity to the last three GAs and prepare the population\nfor eventual change, which explains the better results of these GAs with random\n18 Renato Tino\u00b4s, Shengxiang Yang\nimmigrants when compared to SGA. For example, this behavior can be observed in\nFigs. 3, 5, 7, 9, and 11, where the best-of-generation fitness of all GAs on the five\nDOPs with \u03c4 = 1000 are plotted.\nExperimental results on the tested DOPs with \u03c1 > 0.10 agree with those pre-\nsented in Ref. [8], where the performance of RIGA, Hypermutation GA, and SGA\nwere compared in DOPs constructed from changing landscapes produced by hills\nthat are shaped using mathematical functions. Three types of environmental changes\nwere considered: linear translation of the hills, periodic changes in the location of\nthe maximum hill, and oscillating changes between two landscapes. In the exper-\niments [8], the performance of RIGA was better than the performance of Hyper-\nmutation GA and SGA in those DOPs with severe environmental changes. Such\nresults were explained by the fact that RIGA prepares the population well for pos-\nsible catastrophic changes through an increase in the genetic diversity. However,\nthe performance of RIGA was worse in DOPs with small environmental changes,\nexplained by an increase in the probability of losing information that may match\nsuch changes. Here, the worse performance of GAs with random immigrants occurs\nagain on DOPs with slight environmental changes (\u03c1 \u2264 0.1).\nLet us now analyze the results of the three GAs with random immigrants. First,\nlet us investigate how the proposed SORIGA works. In the beginning of the ex-\nperiments, the individuals of the initial populations and the immigrants generally\nhave low fitness. Since several individuals in the population have low fitness, the\nprobability that one of the replaced individuals becomes the new worst is low. As\na consequence, a single replacement of an individual generally does not generate\nlarge chain reactions of replacements. As the number of generations increases, the\nmean fitness increases too, and several individuals of the current population have\nfitness values higher than the average fitness of the new random individuals. Then,\nthe probability that one of the individuals with indices close to the index of the\nreplaced worst individual becomes the new worst individual increases, and a chain\nreaction can be developed with a large variety of sizes.\nWhile the performance of SORIGA was generally worse than the performance\nof other RIGAs on the deceptive function 2, it was generally significantly better on\nother DOPs for values of \u03c1 > 0.10. The better results of SORIGA over other GAs\nwith random immigrants in the experiments presented here can be mainly explained\nby the higher values of the diversity level of the population in SORIGA. In Fig. 12,\nthe mean Hamming Distance averaged over 30 runs in the initial 2000 generations\nof the dynamic Scaling Problem 2 where the environmental dynamics parameter \u03c4\nis set to 1000 and \u03c1 is set to 0.95 is presented. The mean Hamming Distance of the\npopulation at generation t is computed as\nh(t) =\n1\nN2\nN\u2211\ni=1\nN\u2211\nj=1\n(\nxi(t)\u2295 xj(t)\n)\n=\n2\nN2\nN\u22121\u2211\ni=1\nN\u2211\nj=i+1\n(\nxi(t)\u2295 xj(t)\n)\n(10)\nwhere xi(t) is the chromosome of the i-th individual of the population at generation\nt andN is the population size. The mean Hamming Distance can be used to estimate\nthe diversity level of the population. Higher values of the mean Hamming Distance\nimply in higher values of the diversity level of the population. One can observe in\nGenet Program Evolvable Mach 19\n500 1000 1500 2000\n0\n0.1\n0.2\n0.3\n0.4\n0.5\ngeneration\nM\nea\nn \nHa\nm\nm\ning\n D\nist\nan\nce\n(a)\n500 1000 1500 2000\n0\n0.1\n0.2\n0.3\n0.4\n0.5\ngeneration\nM\nea\nn \nHa\nm\nm\ning\n D\nist\nan\nce\n(b)\nSGA\nRIGA1\nRIGA2\nSORIGA\n500 1000 1500 2000\n0\n0.1\n0.2\n0.3\n0.4\n0.5\ngeneration\nM\nea\nn \nHa\nm\nm\ning\n D\nist\nan\nce\n(c)\n500 1000 1500 2000\n0\n0.1\n0.2\n0.3\n0.4\n0.5\ngeneration\nM\nea\nn \nHa\nm\nm\ning\n D\nist\nan\nce\n(d)\nFig. 12 Mean Hamming Distance averaged over 30 runs in the initial 2000 generations of\nthe dynamic Scaling Problem 2 with \u03c4 = 1000 and \u03c1 = 0.95: (a) Roulette wheel sampling\nselection with rr = 3; (b) Tournament selection with kts = 0.70; (c) Tournament selection\nwith kts = 0.90; (d) Roulette wheel sampling selection with rr = 12.\nFig. 12 that the mean Hamming Distance decreases after the initial generations\nand the changes in the problem toward a small mean value. One can still observe\nthat the mean Hamming Distances are higher for the SORIGA, indicating that the\ndiversity level is high for this algorithm when compared to the other GAs. This fact\ncan be observed by analyzing the results presented in Table 2. SORIGA generally\npresented the lower values of the mean fitness of the population, even though its\nfitness values of the best-of-generation individuals were higher.\nAnother factor that explains the better results of SORIGA is that the survival\nprobability of a new random individual, which can be evolved to become a solution\nof the problem, is generally lower in the standard GAs with random immigrants.\nThis happens because the fitness values for the current individuals, whose locations\nare generally located in (or close to) local maxima after several generations, are\ngenerally much higher than the mean fitness of the search space (i.e., the mean\nfitness of all possible individuals). SORIGA preserves a new potential solution in\na subpopulation and allows it to evolve while the current replacement event is in\nprogress. As it is necessary to develop the potential solution inside the subpopula-\ntion, the performance of SORIGA increases with the period of change \u03c4 . One can\nobserve in Tables 1 - 6 that the best results of SORIGA are those with \u03c4 = 1000.\nFig. 13 shows the results of the mean population and best-of-generation fitness,\nmean Hamming Distance, and duration of replacement events in the first 2000\ngenerations of the second trial of the experiments of SORIGA with the roulette\nwheel sampling selection on dynamic Scaling Problem 2 with \u03c4 = 1000 and \u03c1 = 0.95.\n20 Renato Tino\u00b4s, Shengxiang Yang\n0 200 400 600 800 1000 1200 1400 1600 1800 2000\n0.2\n0.4\n0.6\n0.8\n1\ngeneration\nFi\ntn\nes\ns\n(a)\n0 200 400 600 800 1000 1200 1400 1600 1800 2000\n0.1\n0.2\n0.3\n0.4\n0.5\ngeneration\nM\nea\nn \nHa\nm\nm\ning\n D\nist\nan\nce\n(b)\n0 200 400 600 800 1000 1200 1400 1600 1800 2000\n0\n5\n10\n15\n20\ngeneration\nd\n(c)\nFig. 13 Initial 2000 generations of SORIGA with roulette wheel sampling selection on\nthe second trial of the dynamic Scaling Problem 2 with \u03c4 = 1000 and \u03c1 = 0.95: (a) Mean\npopulation (solid line) and best-of-generation fitness (dotted line); (b) Mean Hamming\ndistance; (c) Duration of replacement events (in generations).\nOne can observe that larger replacement events generally occurred when the mean\npopulation fitness was high and the diversity level of the population was small. Such\ninteresting behavior was reached by self-organization, and not by a rule imposed by\nthe programmer. In the experimental results on the last five DOPs, the size of the\nsubpopulation self-organized according to the population diversity level. This result\ncan be observed in Tables 3 and 4, where the performance of SORIGA in comparison\nto other RIGAs increases when the selection pressure increases by changing kts from\n0.70 to 0.90 in the experiments with tournament selection. One can observe that the\nmean Hamming distances were lower for the experiment with kts = 0.90 (Fig. 12),\nindicating a low diversity in the population.\nIt is important to observe that the random immigrants mechanism incurs a cost\non the GA as a part of the individuals that could be used to explore the current\nbest solution are replaced by randomly generated individuals. This cost was depre-\nciated by the advantage of increasing the diversity level in problems where there are\ndifficulties in escaping from local optima induced by severe changes using only the\ntraditional GA mechanisms. The balance between the advantage of increasing the\ndiversity of the population by introducing randomly generated individuals and the\ncost of replacing part of the population that could be used to explore the current\nbest solution should be found by properly setting the parameter rr in the standard\nRIGA. In the experiments performed in this work, the performance of the RIGA1\nand RIGA2 was generally better when rr = 24 (Table 6), which corresponded to\n20% of the population. When rr is larger than this value, the performance gen-\nGenet Program Evolvable Mach 21\nerally depreciated. However, for SORIGA, the better results were generally found\nfor smaller values of rr. Those results are explained by the fact that, in SORIGA,\nthe size of the subpopulation is generally larger than rr , which implies that less\nindividuals of the population are employed to explore the current best solution. In\nthis way, SORIGA is interesting, when compared to other RIGAs, for values of rr\nsmaller than the value which represents the best value for the standard RIGA.\nIt can also be observed that the performance of SORIGA decreases when the\ndifficulty level introduced by deception increases from dynamic deceptive function\n1 to dynamic deceptive function 2 (Tables 1 - 6). This happens because on dynamic\ndeceptive function 2 the probability to generate a fair random immigrant close to\nthe global optimum and develop it in a subpopulation is very low. It can be seen in\nFigs. 5 and 7 that, while the best-of-generation individuals of the GAs with random\nimmigrants converge to the global optimum after the changes on deceptive function\n1, they converge to the local optimum on deceptive function 2.\nIn the experiments on DOPs presented here, just like that the fossil records\ndata for the extinction events in nature [21], there are more small replacement\nevents than large ones, and the replacement events occur on a large variety of\nlength scales. When the distribution of the number of replacement events against\neach size is plotted in a log-log scale, the results exhibit power laws (see Sect. 3)\neven without any apparent tuning, suggesting the presence of SOC.\n5.6 Including a Neighboring Scheme\nIn the SORIGA presented in Sect. 4, the relations among the replaced individuals in\neach generation are determined by the indices of the individuals, i.e., the relations\nare random. In each generation, the individuals with indices from j \u2212 \u2308(rr \u2212 1)\/2\u2309\nto j + \u230a(rr \u2212 1)\/2\u230b, where j is the index of the individual with the lowest fitness in\nthe current population, are replaced by randomly generated individuals.\nIn this subsection, another replacement scheme, called neighborhood reserving\nselection scheme, is investigated. In this scheme, the individuals in the population\nare ordered according to the index of their first parent after the reproduction step.\nAs an example, suppose a population with only 5 individuals cyclically indexed as\n[1\u22122\u22123\u22124\u22125\u22121]. After reproduction, suppose that the individuals with the follow-\ning first parents [3, 4, 2, 3, 1] are present in the new population. In the neighborhood\nreserving selection scheme, the new population is rearranged to [1, 2, 3, 3, 4]. In this\nway, a neighborhood is spatially reserved to the maximal degree.\nTable 7 presents the results of the SORIGA with this neighboring scheme when\nselection with roulette wheel sampling was employed and 3 individuals were re-\nplaced in each generation, denoted SORIGA2. Comparing the results presented in\nTable 7 to those presented in Table 1 for the SORIGA, it can be observed that the\nperformance of the two SORIGAs are similar for most problems while both show\ngood performance in comparison to other GAs.\n22 Renato Tino\u00b4s, Shengxiang Yang\n6 Conclusions and Future Work\nIn recent years, several approaches have been developed into EAs to deal with dy-\nnamic optimization problems. The random immigrants scheme is a simple yet inter-\nesting approach, which aims to improve the diversity of the population by replacing\nrandom indiivudals into the population. However, traditional random immigrants\nscheme has some shortcomings. The newly inserted random immigrants may not sur-\nvive the selection phase due to their low fitness. In this paper, a new self-organizing\nrandom immigrants scheme is proposed for GAs for DOPs, where the individual\nwith the lowest fitness and those with indices close to its index are replaced by ran-\ndom immigrants in every generation. In order to protect these random immigrants\nfrom being removed immediately by the selection phase, a subpopulation is used to\npreserve them. The subpopulation evolves in parallel with the main population and\nmay enlarge or shrink until going extinct, which is called a replacement event.\nThe individual replacement and subpopulation strategies in the proposed immi-\ngrants scheme are dependent: they only have positive effect when applied together.\nWithout the subpopulation strategy, the proposed replacement strategy makes no\nsense. On the other hand, the use of subpopulation without the proposed replace-\nment strategy implies the use of subpopulations whose sizes are not self-organized.\nFor example, if random individuals are replaced in every generation, as in traditional\nRIGAs, and a subpopulation is used to keep new individuals, the subpopulation\nshould have a fixed size.\nIn SORIGA where the proposed immigrants scheme is applied, individuals start\nto interact between themselves and, when the fitness of the individuals are close,\nas in the case of low diversity, one single replacement can affect a great number\nof individuals in a replacement event. It is important to observe that the proposed\nsimple approach can take the system to a self-organizing behavior, which can be\nuseful for DOPs to maintain diversity of solutions and to allow the GA to escape\nfrom local optima if the problem changes. The experimental results presented in this\npaper indicate that SORIGA produces a higher diversity level in the population than\nSGA and traditional RIGAs.\nImplementing self-organizing behavior, such as the self-organized criticality stud-\nied here, and including it in GAs has shown to be beneficial for their performance\nunder dynamic environments. Future work will compare the self-organizing prop-\nerty with other properties, such as speciation schemes, and investigate its effect\non constrained DOPs, e.g., the dynamic Knapsack problem. Further work has to\ninvestigate other kinds of interaction among individuals that might produce self-\norganization.\nAcknowledgments\nThe authors would like to thank Prof. Wolfgang Bazhaf and the anonymous re-\nviewers for their thoughtful suggestions and helpful comments, which greatly con-\ntributed to the improvement of the paper. This work was supported by FAPESP\n(Proc. 04\/04289-6).\nGenet Program Evolvable Mach 23\nReferences\n1. P. Bak. How Nature Works: the Science of Self-organized Criticality. Oxford University\nPress, 1997.\n2. P. Bak, C. Tang, and K. Wiesenfeld. Self-organized criticality. an explanation of 1\/f\nnoise. Physical Review Letters, 59(4):381\u2013384, 1987.\n3. S. Boettcher and A. G. Percus. Optimization with extremal dynamics. Complexity,\n8(2):57\u201362, 2003.\n4. J. Branke. Evolutionary Optimization in Dynamic Environments. Kluwer, 2001.\n5. J. Branke. Evolutionary approaches to dynamic optimization problems - introduction\nand recent trends. In J. Branke, editor, Proc. of the GECCO Workshop on Evolution-\nary Algorithms for Dynamic Optimization Problems, pages 2\u20134, 2003.\n6. W. Cedeno and V. R. Vemuri. On the use of niching for dynamic landscapes. In Proc.\nof the 1997 IEEE Int. Conf. on Evolutionary Computation, pages 361\u2013366, 1997.\n7. H. G. Cobb. An investigation into the use of hypermutation as an adaptive operator\nin genetic algorithms having continuouis, time-dependent nonstationary environments.\nTechnical Report AIC-90-001, Naval Research Laboratory, Washington, USA, 1990.\n8. H. G. Cobb and J. J. Grefenstette. Genetic algorithms for tracking changing environ-\nments. In S. Forrest, editor, Proc. of the 5th Int. Conf. on Genetic Algorithms, pages\n523\u2013530, 1993.\n9. K. Deb and D. E. Goldberg. Analyzing deception in trap functions. In L. D. Whitley,\neditor, Foundation of Genetic Algorithms 2, pages 93\u2013108, 1993.\n10. D. A. Goldberg. Genetic Algorithms in Search, Optimization, and Machine Learning.\nAddison-Wesley Publishing Company, Inc., 1989.\n11. D. A. Goldberg. The Design of Innovation: Lessons from and for Competent Genetic\nAlgorithms. Boston, MA: Kluwer Academic Publishers., 2002.\n12. S. J. Gould. Wonderful Life: The Burgess Shale and the Nature of History. W. W.\nNorton and Company, 1989.\n13. J. J. Grefenstette. Genetic algorithms for changing environments. In R. Maenner and\nB. Manderick, editors, Parallel Problem Solving from Nature 2, pages 137\u2013144. North\nHolland, 1992.\n14. H. J. Jensen. Self-organized Criticality: Emergent Complex Behavior in Physical and\nBiological Systems. Cambridge University Press, 1998.\n15. Y. Jin and J. Branke. Evolutionary optimization in uncertain environments - a survey.\nIEEE Trans. on Evolutionary Computation, 9(3):303\u2013317, 2005.\n16. S. A. Kauffman. The Origins of Order: Self-organization and Selection in Evolution.\nOxford University Press, 1993.\n17. T. Krink and R. Thomsen. Self-organized criticality and mass extinction in evolution-\nary algorithms. In Proc. of the 2001 Congress on Evolutionary Computation, volume 2,\npages 1155\u20131161, 2001.\n18. M. L\u00f8vbjerg and T. Krink. Extending particle swarm optimisers with self-organized\ncriticality. In Proc. of the 2002 IEEE Congress on Evolutionary Computation, vol-\nume 2, pages 1588\u20131593, 2002.\n19. M. Mitchell. An Introduction to Genetic Algorithms. MIT Press, 1996.\n20. N. Mori, H. Kita, and Y. Nishikawa. Adaptation to a changing environment by means\nof the feedback thermodynamical genetic algorithm. In A. E. Eiben, T. Ba\u00a8ck, M. Schoe-\nnauer, and H.-P. Schwefel, editors, Parallel Problem Solving from Nature, number 1498\nin LNCS, pages 149\u2013158. Springer, 1998.\n21. D. M. Raup. Biological extinction in earth history. Science, 231:1528\u20131533, 1986.\n22. K. Trojanowski and Z. Michalewicz. Evolutionary optimization in non-stationary\nenvironments. Journal of Computer Science and Technology, 1(2):93\u2013124, 2000.\n24 Renato Tino\u00b4s, Shengxiang Yang\n23. F. Vavak, T. C. Fogarty, and K. Jukes. A genetic algorithm with variable range of local\nsearch for tracking changing environments. In H.-M. Voigt, editor, Parallel Problem\nSolving from Nature, number 1141 in LNCS. Springer Verlag Berlin, 1996.\n24. S. Yang. Non-stationary problem optimization using the primal-dual genetic algo-\nrithm. In R. Sarker, R. Reynolds, H. Abbass, K.-C. Tan, R. McKay, D. Essam, and\nT. Gedeon, editors, Proc. of the 2003 IEEE Congress on Evolutionary Computation,\nvolume 3, pages 2246\u20132253, 2003.\n25. S. Yang. Constructing dynamic test environments for genetic algorithms based on\nproblem difficulty. In Proc. of the 2004 IEEE Congress on Evolutionary Computation,\nvolume 2, pages 1262\u20131269, 2004.\n26. S. Yang and X. Yao. Experimental study on population-based incremental learning\nalgorithms for dynamic optimization problems. Soft Computing, 9(11):815\u2013834, 2005.\nGenet Program Evolvable Mach 25\nTable 1 Experimental results of the mean best-of-generation fitness (selection with\nroulette wheel sampling) and relevant statistical comparisons (inside the parentheses).\nProblem Dynamics Algorithm\n\u03c4 \u03c1 SGA RIGA1 RIGA2 SORIGA\n10 0.05 30.60 (\u223c) 30.03 (\u223c) 30.80 (\u223c) 30.94\n10 0.60 6.62 (+) 8.47 (+) 10.94 (\u223c) 11.47\n10 0.95 12.92 (+) 14.44 (\u223c) 14.66 (\u223c) 15.08\nRoyal Road 200 0.05 59.97 (\u223c) 59.69 (\u223c) 59.91 (\u223c) 59.79\nFunction 200 0.60 29.38 (+) 37.72 (+) 38.94 (+) 41.10\n200 0.95 24.08 (+) 36.10 (+) 38.06 (+) 40.33\n1000 0.05 63.10 (\u223c) 63.10 (\u223c) 63.26 (\u2212) 63.10\n1000 0.60 53.24 (+) 57.07 (+) 57.43 (+) 57.78\n1000 0.95 49.70 (+) 57.09 (+) 57.16 (+) 57.75\n10 0.10 0.8276 (\u223c) 0.8328 (\u223c) 0.8292 (\u223c) 0.8322\n10 0.60 0.7601 (+) 0.7895 (\u223c) 0.7829 (+) 0.7966\n10 0.90 0.8418 (+) 0.8711 (\u223c) 0.8619 (\u223c) 0.8692\nDeceptive 200 0.10 0.8408 (+) 0.8959 (\u223c) 0.8912 (+) 0.9127\nFunction 1 200 0.60 0.8193 (+) 0.8681 (+) 0.8708 (+) 0.8841\n200 0.90 0.9092 (+) 0.9314 (\u223c) 0.9267 (+) 0.9339\n1000 0.10 0.8422 (+) 0.9685 (+) 0.9669 (+) 0.9838\n1000 0.60 0.8250 (+) 0.9448 (+) 0.9463 (+) 0.9550\n1000 0.90 0.9121 (+) 0.9697 (\u223c) 0.9703 (\u223c) 0.9743\n10 0.05 0.6947 (\u2212) 0.6938 (\u223c) 0.7000 (\u2212) 0.6894\n10 0.60 0.5565 (+) 0.5676 (\u223c) 0.5654 (+) 0.5682\n10 0.95 0.5401 (+) 0.5511 (\u223c) 0.5463 (+) 0.5521\nDeceptive 200 0.05 0.7931 (\u2212) 0.7928 (\u2212) 0.7931 (\u2212) 0.7914\nFunction 2 200 0.60 0.7496 (+) 0.7582 (\u2212) 0.7597 (\u2212) 0.7572\n200 0.95 0.7306 (+) 0.7580 (\u223c) 0.7597 (\u2212) 0.7572\n1000 0.05 0.7985 (\u2212) 0.7985 (\u2212) 0.7987 (\u2212) 0.7983\n1000 0.60 0.7900 (+) 0.7917 (\u2212) 0.7919 (\u2212) 0.7915\n1000 0.95 0.7867 (+) 0.7916 (\u223c) 0.7920 (\u2212) 0.7917\n10 0.05 0.9673 (\u223c) 0.9722 (\u2212) 0.9635 (\u223c) 0.9578\n10 0.60 0.7705 (+) 0.8084 (+) 0.8121 (+) 0.8204\n10 0.95 0.8268 (+) 0.8475 (\u223c) 0.8423 (+) 0.8511\nScaling 200 0.05 0.9958 (\u223c) 0.9985 (\u223c) 0.9973 (\u223c) 0.9983\nFunction 1 200 0.60 0.8760 (+) 0.9496 (+) 0.9509 (+) 0.9670\n200 0.95 0.8546 (+) 0.9251 (+) 0.9226 (+) 0.9496\n1000 0.05 0.9994 (\u223c) 0.9997 (\u223c) 0.9995 (\u223c) 0.9997\n1000 0.60 0.8917 (+) 0.9870 (+) 0.9857 (+) 0.9932\n1000 0.95 0.8706 (+) 0.9797 (+) 0.9766 (+) 0.9880\n10 0.05 0.9327 (\u2212) 0.9222 (\u223c) 0.9298 (\u2212) 0.9151\n10 0.60 0.7380 (+) 0.7633 (+) 0.7622 (+) 0.7723\n10 0.95 0.8217 (+) 0.8328 (\u223c) 0.8364 (\u223c) 0.8413\nScaling 200 0.05 0.9898 (\u223c) 0.9917 (\u223c) 0.9912 (\u223c) 0.9926\nFunction 2 200 0.60 0.8665 (+) 0.9365 (+) 0.9350 (+) 0.9480\n200 0.95 0.8517 (+) 0.9113 (+) 0.9068 (+) 0.9288\n1000 0.05 0.9963 (\u223c) 0.9980 (\u223c) 0.9978 (\u223c) 0.9979\n1000 0.60 0.8860 (+) 0.9747 (+) 0.9743 (+) 0.9828\n1000 0.95 0.8633 (+) 0.9616 (+) 0.9588 (+) 0.9770\n26 Renato Tino\u00b4s, Shengxiang Yang\nTable 2 Experimental results of the mean population fitness (selection with roulette wheel\nsampling).\nProblem Dynamics Algorithm\n\u03c4 \u03c1 SGA RIGA1 RIGA2 SORIGA\n10 0.05 18.41 18.06 18.82 17.87\n10 0.60 4.48 5.55 7.17 7.00\n10 0.95 8.10 9.06 9.12 8.92\nRoyal Road 200 0.05 38.91 38.82 39.40 35.88\nFunction 200 0.60 20.09 25.68 26.72 25.86\n200 0.95 16.74 24.72 26.15 25.46\n1000 0.05 40.95 40.99 41.60 37.72\n1000 0.60 34.97 37.45 38.14 34.92\n1000 0.95 32.68 37.46 37.99 34.92\n10 0.10 0.6606 0.6454 0.6577 0.6305\n10 0.60 0.4845 0.4935 0.4924 0.4947\n10 0.90 0.5709 0.5652 0.5754 0.5639\nDeceptive 200 0.10 0.7630 0.7296 0.7475 0.7228\nFunction 1 200 0.60 0.7342 0.7170 0.7293 0.6952\n200 0.90 0.8168 0.7763 0.7880 0.7391\n1000 0.10 0.7683 0.7600 0.7673 0.7903\n1000 0.60 0.7523 0.7075 0.7158 0.6939\n1000 0.90 0.8261 0.7587 0.7693 0.7308\n10 0.05 0.5663 0.5572 0.5710 0.5386\n10 0.60 0.4202 0.4223 0.4272 0.4235\n10 0.95 0.3985 0.4016 0.4032 0.4037\nDeceptive 200 0.05 0.6718 0.6554 0.6730 0.6303\nFunction 2 200 0.60 0.6262 0.6182 0.6351 0.5985\n200 0.95 0.6055 0.6165 0.6332 0.5974\n1000 0.05 0.6778 0.6607 0.6790 0.6366\n1000 0.60 0.6689 0.6534 0.6714 0.6300\n1000 0.95 0.6647 0.6532 0.6709 0.6301\n10 0.05 0.7329 0.7277 0.7361 0.7008\n10 0.60 0.4777 0.4829 0.4884 0.4831\n10 0.95 0.5880 0.5761 0.5862 0.5596\nScaling 200 0.05 0.8569 0.8467 0.8599 0.8167\nFunction 1 200 0.60 0.7436 0.7852 0.8006 0.7734\n200 0.95 0.7357 0.7670 0.7766 0.7596\n1000 0.05 0.8650 0.8523 0.8671 0.8225\n1000 0.60 0.7701 0.8376 0.8508 0.8136\n1000 0.95 0.7545 0.8313 0.8428 0.8091\n10 0.05 0.7210 0.7024 0.7185 0.6774\n10 0.60 0.4738 0.4766 0.4826 0.4763\n10 0.95 0.6086 0.5979 0.6017 0.5844\nScaling 200 0.05 0.8380 0.8294 0.8413 0.8032\nFunction 2 200 0.60 0.7275 0.7724 0.7816 0.7584\n200 0.95 0.7243 0.7575 0.7646 0.7467\n1000 0.05 0.8459 0.8373 0.8500 0.8099\n1000 0.60 0.7534 0.8173 0.8292 0.7973\n1000 0.95 0.7373 0.8084 0.8183 0.7938\nGenet Program Evolvable Mach 27\nTable 3 Experimental results of the mean best-of-generation fitness (tournament selection\nwith kts = 0.70) and relevant statistical comparisons (inside the parentheses).\nProblem Dynamics Algorithm\n\u03c4 \u03c1 SGA RIGA1 RIGA2 SORIGA\n10 0.05 24.14 (\u2212) 23.13 (\u223c) 25.37 (\u2212) 22.58\n10 0.60 10.57 (\u223c) 10.98 (\u223c) 11.22 (\u223c) 10.91\n10 0.95 12.77 (\u223c) 12.47 (\u223c) 12.70 (\u223c) 12.53\nRoyal Road 200 0.05 58.24 (\u2212) 55.93 (\u2212) 57.85 (\u2212) 52.83\nFunction 200 0.60 33.73 (+) 36.53 (\u223c) 37.34 (\u223c) 36.93\n200 0.95 28.50 (+) 34.49 (+) 35.38 (\u223c) 35.33\n1000 0.05 62.61 (\u2212) 62.08 (\u2212) 62.54 (\u2212) 60.70\n1000 0.60 54.57 (\u223c) 55.03 (\u2212) 56.01 (\u2212) 54.36\n1000 0.95 51.92 (+) 54.31 (\u2212) 55.46 (\u2212) 53.71\n10 0.10 0.8222 (\u223c) 0.8269 (\u223c) 0.8280 (\u223c) 0.8252\n10 0.60 0.7586 (+) 0.7851 (+) 0.7819 (+) 0.7959\n10 0.90 0.8501 (+) 0.8676 (+) 0.8712 (+) 0.8881\nDeceptive 200 0.10 0.8258 (+) 0.8761 (+) 0.8761 (+) 0.8931\nFunction 1 200 0.60 0.8186 (+) 0.8813 (+) 0.8701 (+) 0.8972\n200 0.90 0.9112 (+) 0.9484 (\u223c) 0.9529 (\u223c) 0.9546\n1000 0.10 0.8278 (+) 0.9545 (+) 0.9493 (+) 0.9703\n1000 0.60 0.8261 (+) 0.9510 (+) 0.9477 (+) 0.9649\n1000 0.90 0.9236 (+) 0.9802 (\u223c) 0.9748 (+) 0.9833\n10 0.05 0.7331 (\u2212) 0.7244 (\u223c) 0.7299 (\u2212) 0.7221\n10 0.60 0.5558 (+) 0.5667 (+) 0.5671 (+) 0.5703\n10 0.95 0.5288 (+) 0.5466 (+) 0.5434 (+) 0.5517\nDeceptive 200 0.05 0.7971 (\u2212) 0.7967 (\u2212) 0.7971 (\u2212) 0.7962\nFunction 2 200 0.60 0.7588 (+) 0.7690 (+) 0.7711 (\u2212) 0.7703\n200 0.95 0.7433 (+) 0.7658 (+) 0.7686 (\u223c) 0.7671\n1000 0.05 0.7994 (\u2212) 0.7993 (\u2212) 0.7994 (\u2212) 0.7992\n1000 0.60 0.7919 (+) 0.7938 (+) 0.7942 (\u2212) 0.7941\n1000 0.95 0.7894 (+) 0.7931(\u223c) 0.7948 (\u223c) 0.7942\n10 0.05 0.9495 (\u223c) 0.9593 (\u223c) 0.9579 (\u223c) 0.9558\n10 0.60 0.7794 (+) 0.8156 (\u223c) 0.8055 (+) 0.8158\n10 0.95 0.8333 (+) 0.8525 (\u223c) 0.8488 (\u223c) 0.8503\nScaling 200 0.05 0.9809 (+) 0.9964 (\u223c) 0.9963 (\u223c) 0.9977\nFunction 1 200 0.60 0.8604 (+) 0.9513 (+) 0.9424 (+) 0.9629\n200 0.95 0.8530 (+) 0.9222 (+) 0.9160 (+) 0.9453\n1000 0.05 0.9874 (+) 0.9993 (\u223c) 0.9992 (\u223c) 0.9995\n1000 0.60 0.8782 (+) 0.9855 (+) 0.9820 (+) 0.9923\n1000 0.95 0.8554 (+) 0.9759 (+) 0.9689 (+) 0.9873\n10 0.05 0.9229 (\u223c) 0.9256 (\u223c) 0.9283 (\u223c) 0.9291\n10 0.60 0.7317 (+) 0.7642 (+) 0.7515 (+) 0.7720\n10 0.95 0.8299 (\u223c) 0.8381 (\u223c) 0.8333 (\u223c) 0.8353\nScaling 200 0.05 0.9783 (+) 0.9904 (\u223c) 0.9940 (\u223c) 0.9930\nFunction 2 200 0.60 0.8593 (+) 0.9334 (+) 0.9275 (+) 0.9436\n200 0.95 0.8498 (+) 0.9065 (+) 0.9047 (+) 0.9249\n1000 0.05 0.9860 (+) 0.9982 (\u223c) 0.9987 (\u223c) 0.9987\n1000 0.60 0.8697 (+) 0.9715 (+) 0.9677 (+) 0.9819\n1000 0.95 0.8527 (+) 0.9601 (+) 0.9500 (+) 0.9712\n28 Renato Tino\u00b4s, Shengxiang Yang\nTable 4 Experimental results of the mean best-of-generation fitness (tournament selection\nwith kts = 0.9) and relevant statistical comparisons (inside the parentheses).\nProblem Dynamics Algorithm\n\u03c4 \u03c1 SGA RIGA1 RIGA2 SORIGA\n10 0.05 30.97 (\u223c) 28.93 (+) 31.39 (\u223c) 30.91\n10 0.60 10.91 (+) 11.96 (\u223c) 11.90 (\u223c) 12.05\n10 0.95 15.49 (\u223c) 15.26 (\u223c) 15.19 (\u223c) 15.44\nRoyal Road 200 0.05 60.90 (\u223c) 60.96 (\u223c) 61.54 (\u2212) 60.60\nFunction 200 0.60 35.89 (+) 40.69 (+) 41.04 (+) 42.72\n200 0.95 29.22 (+) 37.27 (+) 37.37 (+) 39.73\n1000 0.05 63.35 (\u223c) 63.39 (\u223c) 63.54 (\u2212) 63.34\n1000 0.60 56.81 (+) 58.41 (\u223c) 58.73 (\u223c) 58.62\n1000 0.95 54.10 (+) 57.47 (+) 57.69 (\u223c) 57.84\n10 0.10 0.8224 (\u223c) 0.8257 (\u223c) 0.8263 (\u223c) 0.8247\n10 0.60 0.7219 (+) 0.7621 (\u223c) 0.7508 (+) 0.7681\n10 0.90 0.8513 (+) 0.8665 (+) 0.8685 (+) 0.8857\nDeceptive 200 0.10 0.8252 (+) 0.8875 (\u223c) 0.8935 (\u223c) 0.9011\nFunction 1 200 0.60 0.8144 (+) 0.8703 (+) 0.8685 (+) 0.8808\n200 0.90 0.9083 (+) 0.9406 (\u223c) 0.9269 (+) 0.9471\n1000 0.10 0.8314 (+) 0.9745 (\u223c) 0.9660 (+) 0.9746\n1000 0.60 0.8234 (+) 0.9496 (+) 0.9436 (+) 0.9587\n1000 0.90 0.9128 (+) 0.9731 (+) 0.9656 (+) 0.9795\n10 0.05 0.7609 (\u2212) 0.7577 (\u223c) 0.7598 (\u2212) 0.7564\n10 0.60 0.5521 (+) 0.5720 (+) 0.5729 (+) 0.5758\n10 0.95 0.5058 (+) 0.5456 (+) 0.5462 (+) 0.5544\nDeceptive 200 0.05 0.7982 (\u2212) 0.7982 (\u223c) 0.7983 (\u2212) 0.7981\nFunction 2 200 0.60 0.7682 (+) 0.7786 (+) 0.7791 (+) 0.7798\n200 0.95 0.7482 (+) 0.7779 (\u223c) 0.7798 (\u223c) 0.7807\n1000 0.05 0.7996 (\u2212) 0.7996 (\u223c) 0.7997 (\u2212) 0.7996\n1000 0.60 0.7936 (+) 0.7957 (+) 0.7959 (+) 0.7960\n1000 0.95 0.7943 (\u223c) 0.7974 (\u223c) 0.7983 (\u223c) 0.7970\n10 0.05 0.9665 (\u223c) 0.9683 (\u223c) 0.9685 (\u223c) 0.9735\n10 0.60 0.7594 (+) 0.7996 (+) 0.7942 (+) 0.8117\n10 0.95 0.8318 (+) 0.8508 (+) 0.8521 (+) 0.8613\nScaling 200 0.05 0.9826 (+) 0.9900 (+) 0.9876 (+) 0.9969\nFunction 1 200 0.60 0.8538 (+) 0.9386 (+) 0.9334 (+) 0.9542\n200 0.95 0.8497 (+) 0.9042 (+) 0.9011 (+) 0.9323\n1000 0.05 0.9832 (+) 0.9982 (+) 0.9970 (+) 0.9994\n1000 0.60 0.8666 (+) 0.9680 (+) 0.9641 (+) 0.9838\n1000 0.95 0.8507 (+) 0.9487 (+) 0.9477 (+) 0.9702\n10 0.05 0.9402 (\u223c) 0.9480 (\u223c) 0.9432 (\u223c) 0.9515\n10 0.60 0.7240 (+) 0.7541 (+) 0.7520 (+) 0.7699\n10 0.95 0.8273 (+) 0.8351 (\u223c) 0.8340 (+) 0.8399\nScaling 200 0.05 0.9725 (+) 0.9818 (\u223c) 0.9789 (+) 0.9873\nFunction 2 200 0.60 0.8523 (+) 0.9230 (+) 0.9276 (+) 0.9383\n200 0.95 0.8485 (+) 0.8889 (+) 0.8833 (+) 0.9143\n1000 0.05 0.9750 (+) 0.9925 (+) 0.9896 (+) 0.9962\n1000 0.60 0.8652 (+) 0.9507 (+) 0.9476 (+) 0.9695\n1000 0.95 0.8508 (+) 0.9314 (+) 0.9248 (+) 0.9514\nGenet Program Evolvable Mach 29\nTable 5 Experimental results of the mean best-of-generation fitness (selection with\nroulette wheel sampling and rr = 12) and relevant statistical comparisons (inside the\nparentheses). The results of SGA are equal to those presented in Table 1.\nProblem Dynamics Algorithm\n\u03c4 \u03c1 SGA RIGA1 RIGA2 SORIGA\n10 0.05 30.60 (+) 32.73 (\u223c) 32.51 (\u223c) 32.95\n10 0.60 6.62 (+) 13.77 (+) 14.63 (+) 15.99\n10 0.95 12.92 (+) 16.39 (+) 16.83 (+) 18.29\nRoyal Road 200 0.05 59.97 (\u223c) 59.90 (\u223c) 60.83 (\u2212) 59.64\nFunction 200 0.60 29.38 (+) 41.38 (+) 42.37 (+) 47.46\n200 0.95 24.08 (+) 40.32 (+) 41.81 (+) 47.22\n1000 0.05 63.10 (\u223c) 63.09 (\u223c) 63.35 (\u2212) 63.07\n1000 0.60 53.24 (+) 57.48 (+) 58.65 (+) 59.95\n1000 0.95 49.70 (+) 57.81 (+) 58.81 (+) 59.98\n10 0.10 0.8276 (\u223c) 0.8425 (\u223c) 0.8421 (\u223c) 0.8394\n10 0.60 0.7601 (+) 0.8020 (+) 0.8034 (+) 0.8321\n10 0.90 0.8418 (+) 0.8880 (\u223c) 0.8922 (\u223c) 0.8945\nDeceptive 200 0.10 0.8408 (+) 0.9817 (\u223c) 0.9423 (+) 0.9863\nFunction 1 200 0.60 0.8193 (+) 0.9372 (+) 0.9334 (+) 0.9541\n200 0.90 0.9092 (+) 0.9562 (+) 0.9690 (\u2212) 0.9624\n1000 0.10 0.8422 (+) 0.9986 (\u223c) 0.9886 (+) 0.9992\n1000 0.60 0.8250 (+) 0.9862 (+) 0.9854 (+) 0.9902\n1000 0.90 0.9121 (+) 0.9874 (+) 0.9933 (\u2212) 0.9901\n10 0.05 0.6947 (\u2212) 0.6883 (\u2212) 0.7048 (\u2212) 0.6618\n10 0.60 0.5565 (+) 0.5760 (\u223c) 0.5761 (\u223c) 0.5736\n10 0.95 0.5401 (+) 0.5647 (\u223c) 0.5610 (+) 0.5670\nDeceptive 200 0.05 0.7931 (\u2212) 0.7913 (\u2212) 0.7943 (\u2212) 0.7868\nFunction 2 200 0.60 0.7496 (\u2212) 0.7582 (\u2212) 0.7675 (\u2212) 0.7454\n200 0.95 0.7306 (+) 0.7583 (\u2212) 0.7679 (\u2212) 0.7453\n1000 0.05 0.7985 (\u2212) 0.7981 (\u2212) 0.7988 (\u2212) 0.7975\n1000 0.60 0.7900 (\u2212) 0.7917 (\u2212) 0.7934 (\u2212) 0.7890\n1000 0.95 0.7867 (+) 0.7916 (\u2212) 0.7936 (\u2212) 0.7890\n10 0.05 0.9673 (\u223c) 0.9652 (\u223c) 0.9691 (\u2212) 0.9616\n10 0.60 0.7705 (+) 0.8395 (+) 0.8450 (+) 0.8510\n10 0.95 0.8268 (+) 0.8664 (+) 0.8680 (\u223c) 0.8731\nScaling 200 0.05 0.9958 (\u223c) 0.9986 (\u223c) 0.9988 (\u2212) 0.9983\nFunction 1 200 0.60 0.8760 (+) 0.9784 (+) 0.9772 (+) 0.9855\n200 0.95 0.8546 (+) 0.9676 (+) 0.9592 (+) 0.9834\n1000 0.05 0.9994 (\u223c) 0.9997 (\u223c) 0.9998 (\u2212) 0.9997\n1000 0.60 0.8917 (+) 0.9958 (+) 0.9952 (+) 0.9971\n1000 0.95 0.8706 (+) 0.9933 (+) 0.9913 (+) 0.9964\n10 0.05 0.9327(\u2212) 0.9359(\u2212) 0.9292 (\u223c) 0.9241\n10 0.60 0.7380 (+) 0.7992 (\u223c) 0.7897 (+) 0.8019\n10 0.95 0.8217 (+) 0.8421 (\u223c) 0.8435 (\u223c) 0.8402\nScaling 200 0.05 0.9898 (\u223c) 0.9929 (\u223c) 0.9918 (\u223c) 0.9922\nFunction 2 200 0.60 0.8665 (+) 0.9583 (+) 0.9582 (+) 0.9670\n200 0.95 0.8517 (+) 0.9449 (+) 0.9371 (+) 0.9587\n1000 0.05 0.9963 (\u223c) 0.9982(\u2212) 0.9982 (\u223c) 0.9978\n1000 0.60 0.8860 (+) 0.9872 (+) 0.9860 (+) 0.9907\n1000 0.95 0.8633 (+) 0.9825 (+) 0.9794 (+) 0.9887\n30 Renato Tino\u00b4s, Shengxiang Yang\nTable 6 Experimental results of the mean best-of-generation fitness (selection with\nroulette wheel sampling and rr = 24) and relevant statistical comparisons (inside the\nparentheses). The results of SGA are equal to those presented in Table 1.\nProblem Dynamics Algorithm\n\u03c4 \u03c1 SGA RIGA1 RIGA2 SORIGA\n10 0.05 30.60 (\u223c) 33.29 (\u223c) 33.98 (\u2212) 32.09\n10 0.60 6.62 (+) 16.73 (+) 17.55 (+) 15.99\n10 0.95 12.92 (+) 18.49 (\u223c) 18.76 (\u223c) 18.20\nRoyal Road 200 0.05 59.97 (\u2212) 59.82 (\u2212) 61.48 (\u2212) 55.11\nFunction 200 0.60 29.38 (+) 42.84 (+) 45.57 (+) 47.43\n200 0.95 24.08 (+) 42.53 (+) 45.24 (+) 47.97\n1000 0.05 63.10 (\u2212) 63.08 (\u2212) 63.51 (\u2212) 57.16\n1000 0.60 53.24 (+) 58.20 (\u2212) 59.59 (\u2212) 55.52\n1000 0.95 49.70 (+) 58.16 (\u2212) 59.81 (\u2212) 55.63\n10 0.10 0.8276 (+) 0.8645 (\u223c) 0.8468 (+) 0.8675\n10 0.60 0.7601 (+) 0.8408 (\u223c) 0.8251 (+) 0.8459\n10 0.90 0.8418 (+) 0.8999 (\u223c) 0.9138 (\u2212) 0.8950\nDeceptive 200 0.10 0.8408 (+) 0.9958 () 0.9682 (+) 0.9801\nFunction 1 200 0.60 0.8193 (+) 0.9619 (+) 0.9659 (+) 0.9768\n200 0.90 0.9092 (+) 0.9702 (+) 0.9824 (\u223c) 0.9833\n1000 0.10 0.8422 (+) 0.9986 (\u223c) 0.9886 (+) 0.9992\n1000 0.60 0.8250 (+) 0.9862 (+) 0.9854 (+) 0.9902\n1000 0.90 0.9121 (+) 0.9874 (+) 0.9933 (\u2212) 0.9901\n10 0.05 0.6947 (\u2212) 0.6736 (\u2212) 0.7094 (\u2212) 0.6330\n10 0.60 0.5565 (+) 0.5803 (\u2212) 0.5868 (\u2212) 0.5755\n10 0.95 0.5401 (+) 0.5744 (\u2212) 0.5747 (\u2212) 0.5710\nDeceptive 200 0.05 0.7931 (\u2212) 0.7890 (\u2212) 0.7946 (\u2212) 0.7765\nFunction 2 200 0.60 0.7496 (\u2212) 0.7535 (\u2212) 0.7710 (\u2212) 0.7151\n200 0.95 0.7306 (+) 0.7583 (\u2212) 0.7716 (\u2212) 0.7173\n1000 0.05 0.7985 (\u2212) 0.7979 (\u2212) 0.7989 (\u2212) 0.7922\n1000 0.60 0.7900 (\u2212) 0.7904 (\u2212) 0.7942 (\u2212) 0.7782\n1000 0.95 0.7867 (\u2212) 0.7906 (\u2212) 0.7944 (\u2212) 0.7786\n10 0.05 0.9673 (\u2212) 0.9637 (\u2212) 0.9694 (\u2212) 0.9366\n10 0.60 0.7705 (+) 0.8586 (\u223c) 0.8568 (\u223c) 0.8587\n10 0.95 0.8268 (+) 0.8739 (\u223c) 0.8765 (\u2212) 0.8693\nScaling 200 0.05 0.9958 (\u223c) 0.9986 (\u2212) 0.9986 (\u2212) 0.9959\nFunction 1 200 0.60 0.8760 (+) 0.9862 (\u223c) 0.9847 (\u223c) 0.9852\n200 0.95 0.8546 (+) 0.9809 (+) 0.9722 (+) 0.9859\n1000 0.05 0.9994 (\u2212) 0.9997 (\u2212) 0.9997 (\u2212) 0.9987\n1000 0.60 0.8917 (+) 0.9971 (\u2212) 0.9970 (\u2212) 0.9966\n1000 0.95 0.8706 (+) 0.9959 (+) 0.9941 (+) 0.9966\n10 0.05 0.9327(\u2212) 0.9315(\u2212) 0.9386 (\u2212) 0.9033\n10 0.60 0.7380 (+) 0.8123 (\u223c) 0.8114 (\u223c) 0.8116\n10 0.95 0.8217 (\u223c) 0.8507 (\u2212) 0.8501 (\u2212) 0.8271\nScaling 200 0.05 0.9898 (\u2212) 0.9936 (\u2212) 0.9956 (\u2212) 0.9855\nFunction 2 200 0.60 0.8665 (+) 0.9681 (\u2212) 0.9694 (\u2212) 0.9648\n200 0.95 0.8517 (+) 0.9571 (+) 0.9493 (+) 0.9645\n1000 0.05 0.9963 (\u2212) 0.9982(\u2212) 0.9999 (\u2212) 0.9936\n1000 0.60 0.8860 (+) 0.9912 (\u2212) 0.9910 (\u2212) 0.9877\n1000 0.95 0.8633 (+) 0.9883 (\u2212) 0.9855 (+) 0.9871\nGenet Program Evolvable Mach 31\nTable 7 Experimental results of the mean best-of-generation fitness when the neighbor-\nhood reserving selection scheme is employed (SORIGA2) and the statistical comparison\nregarding SORIGA2 - SORIGA (inside the parentheses). The results of SORIGA are pre-\nsented in Table 1.\nDynamics Royal Road Deceptive Deceptive Scaling Scaling\n\u03c4 \u03c1 Function Function 1 Function 2 Function 1 Function 2\n10 0.05 31.36(\u223c) 0.8291(\u223c) 0.6925(\u223c) 0.9627(\u223c) 0.9202(\u223c)\n10 0.60 11.63(\u223c) 0.7947(\u223c) 0.5701(\u223c) 0.8213(\u223c) 0.7765(\u223c)\n10 0.95 15.08(\u223c) 0.8766(\u223c) 0.5508(\u223c) 0.8509(\u223c) 0.8384(\u223c)\n200 0.05 58.48(\u2212) 0.8906(\u2212) 0.7910(\u223c) 0.9981(\u223c) 0.9925(\u223c)\n200 0.60 40.82(\u223c) 0.8781(\u223c) 0.7569(\u223c) 0.9670(\u223c) 0.9489(\u223c)\n200 0.95 40.12(\u223c) 0.9391(\u223c) 0.7569(\u223c) 0.9499(\u223c) 0.9322(+)\n1000 0.05 62.91(\u2212) 0.9588(\u2212) 0.7983(\u223c) 0.9996(\u223c) 0.9981(\u223c)\n1000 0.60 56.88(\u2212) 0.9594(\u223c) 0.7914(\u223c) 0.9930(\u223c) 0.9842(\u223c)\n1000 0.95 56.78(\u2212) 0.9758(\u223c) 0.7911(\u2212) 0.9881(\u223c) 0.9761(\u223c)\n"}
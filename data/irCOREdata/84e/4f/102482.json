{"doi":"10.1109\/SECPRI.1996.502680","coreId":"102482","oai":"oai:epubs.surrey.ac.uk:1945","identifiers":["oai:epubs.surrey.ac.uk:1945","10.1109\/SECPRI.1996.502680"],"title":"Security properties and CSP","authors":["Schneider, Steve A."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"1996-05-06","abstract":"<p>Security properties such as confidentiality and authenticity\\ud\nmay be considered in terms of the flow of\\ud\nmessages within a network. To the extent that this\\ud\ncharacterisation is justified, the use of a process algebra\\ud\nsuch as Communicating Sequential Processes (CSP)\\ud\nseems appropriate to describe and analyse them. This\\ud\npaper explores ways in which security properties may\\ud\nbe described as CSP specifications, how security mechanisms\\ud\nmay be captured, and how particular protocols\\ud\ndesigned to provide these properties may be analysed\\ud\nwithin the CSP framework. The paper is concerned\\ud\nwith the theoretical basis for such analysis. A sketch\\ud\nverification of a simple example is carried out as an\\ud\nillustration.<\/p","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:1945<\/identifier><datestamp>\n      2017-10-31T14:03:45Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:436F6D707574696E67<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/1945\/<\/dc:relation><dc:title>\n        Security properties and CSP<\/dc:title><dc:creator>\n        Schneider, Steve A.<\/dc:creator><dc:description>\n        <p>Security properties such as confidentiality and authenticity\\ud\nmay be considered in terms of the flow of\\ud\nmessages within a network. To the extent that this\\ud\ncharacterisation is justified, the use of a process algebra\\ud\nsuch as Communicating Sequential Processes (CSP)\\ud\nseems appropriate to describe and analyse them. This\\ud\npaper explores ways in which security properties may\\ud\nbe described as CSP specifications, how security mechanisms\\ud\nmay be captured, and how particular protocols\\ud\ndesigned to provide these properties may be analysed\\ud\nwithin the CSP framework. The paper is concerned\\ud\nwith the theoretical basis for such analysis. A sketch\\ud\nverification of a simple example is carried out as an\\ud\nillustration.<\/p><\/dc:description><dc:date>\n        1996-05-06<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/1945\/1\/fulltext.pdf<\/dc:identifier><dc:identifier>\n          Schneider, Steve A.  (1996) Security properties and CSP   Proceedings of the 1996 IEEE Symposium on Security and Privacy.  pp. 174-187.      <\/dc:identifier><dc:relation>\n        10.1109\/SECPRI.1996.502680<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/1945\/","10.1109\/SECPRI.1996.502680"],"year":1996,"topics":[],"subject":["Article","NonPeerReviewed"],"fullText":"Security properties and CSP \nSteve Schneider \nRoyal Holloway, University of London \nEgham, Surrey, TW20 OEX \nAbstract \nSecurity properties such as confidentiality and au- \nthenticity may  be considered in terms of the flow of \nmessages within a network. To the extent that this \ncharacterisation is justified, the use of a process algebra \nsuch as Communicating Sequential Processes (CSP) \nseems appropriate to describe and analyse them\u2019. This \npaper explores ways in which security properties may \nbe described as CSP specifications, how security mech- \nanisms may be captured, and how particular protocols \ndesigned to provide these properties may be analysed \nwithin the CSP framework. The paper is  concerned \nwith the theoretical basis for  such analysis. A sketch \nverification of a simple example i s  carried out as an \nillustration. \n1 Introduction \nSecurity protocols are designed to provide proper- \nties such as authentication, key exchanges, key distri- \nbution, non-repudiation, proof of origin, integrity, con- \nfidentiality and anonymity, for users who wish to ex- \nchange messages over a medium over which they have \nlittle control. These properties are often difficult to \ncharacterise formally (or even informally). The proto- \ncols themselves often contain a great deal of combinato- \nrial complexity, making their verification extremely dif- \nficult and prone to  error. This paper promotes the view \nthat process algebra can provide a single framework \nboth for modelling protocols and for capturing secu- \nrity properties, facilitating verification and debugging. \nIt is a discussion paper, proposing possible approaches \nrather than providing definitive answers. It considers \nonly confidentiality and authenticity here; other prop- \nerties have been considered in [7]. \nIt has been argued that security properties should \nbe considered as properties concerning the flow of mes- \nsages within a network. To the extent that this char- \nacterisation is justified, the use of a process algebra \nsuch as CSP [3] seems appropriate to describe and anal- \nyse them. This paper considers ways in which security \nproperties may be described using the notation of CSP, \nhow security mechanisms may be captured, and how \nparticular protocols designed to  provide these proper- \nties may be analysed within the CSP framework. \nThe approach presented is rather general, and it is \nclear that the modelling of particular properties and \nanalysis of particular protocols will require tailoring \nof the model presented here. But this paper aims at \nexploring a general approach rather than trying to  con- \nstruct a universal model suitable for handling all pos- \nsible security issues, which is probably an unrealistic \nSecurity properties are generally properties requir- \ning that something bad should not occur (though they \nare not exclusively of this form); these tend to be con- \nsidered as safety properties. Of course, particular com- \nmunication protocols will also aim to be live (some- \nthing good should occur), in that they will be designed \nto achieve goals such as delivery of messages. But there \nis a distinction to  be drawn between the security re- \nquirements implemented by such a protocol, and its \nliveness requirements which are important for commu- \nnication but which are generally independent of secu- \nrity. It is possible that there are some security proper- \nties which can be expressed only as liveness properties; \nthese are outside the scope of this paper. Hence the \ntraces model for CSP will be adequate for our present \nneeds: to analyse properties of the form \u2018something \nbad should not happen\u2019 it is sufficient to focus on what \nsystems may do, rather than what they must do. All \nequivalences and refinements expressed in this paper \nare therefore grounded in the traces model. \nThis paper is structured as follows: The relevant \nCSP notation is introduced in Section 2; Section 3 con- \ntains a discussion of how the properties of confidential- \nity and authentication may be captured within CSP \nindependently of security protocols; Section 4 discusses \nthe modelling of security protocols and of the networks \non which they are implemented, and contains an exam- \ngoal. \n174 \n0-8186-7417-2\/96 $5.00 0 1996 IEEE \nple verification of of a toy confidentiality property to \nillustrate the material; finally Section 5 discusses the \napproach and its potential. \n2 CSP notation \nCSP is an abstract language designed specifically for \nthe description of communication patterns of concur- \nrent system components that interact through message \npassing. It is underpinned by a theory which supports \nanalysis of systems described in CSP. It is therefore \nwell suited to the description and analysis of network \nprotocols: protocols can be described within CSP, as \ncan the relevant aspects of the network. Their interac- \ntions can be investigated, and certain aspects of their \nbehaviour can be verified through use of the theory. \nThis section introduces the notation and ideas used in \nthis paper. In particular, only the traces model for CSP \nis used here. For a fuller introduction to the language \nthe reader is referred to [3]. \nEvents \nSystems are modelled in terms of the events that they \ncan perform. The set of all possible events (fixed at \nthe beginning of the analysis) is denoted E. Events \nmay be atomic in structure or may consist of a number \nof distinct components. For example, an event put.5 \nconsists of two parts: a channel name put,  and a data \nvalue 5 .  An example of events used in this paper are \nthose of the form c.2.j.m consisting of a channel e ,  \na source i, a destination j and a message m. If M \nand N are sets of messages, then M . N  will be the set \nof messages {m.n  I m E M A n E N } .  If m is a \nsingle message then we elide the set brackets and define \nm.N to be {m} .N .  Thus for example the set of events \ni .N.m = (2.n.m I n E N } .  A channel c is said to be of \ntype M if any message c.m E C has that m E M .  \nProcesses \nProcesses are the components of systems. They are the \nentities that are described using CSP, and they are de- \nscribed in terms of the possible events that they may \nengage in. The process STOP is the process that can \nengage in no events at all; it is equivalent to deadlock. \nIf P is a process then the process a --+ P is only able \nto initially perform a,  following which it will behave \nin the way described by P.  The process P 0 Q (pro- \nnounced \u2018 P  choice &\u2019) can behave either as P or as Q: \nits possible communications are those of P and those \nof Q. An indexed form of choice UiEI P; is able to \nbehave as any of its arguments Pi. \nProcesses may also be composed in parallel. If A \nis a set of events then the process P I[ A ] \\  Q behaves \nas P and Q acting concurrently, with the requirement \nthat they have to synchronise on any event in the syn- \nchronisattioin set A; events not in A may be performed \nby either process independently of the other. A special \nform of parallel operator in which the two components \ndo not interact on any events is P I I I Q which is equiv- \nalent to P I [{} ]1 Q. \nProcesses may be recursively defined by means of \nequatioinal definitions. Process names must appear on \nthe left hand side of such definitions, and CSP expres- \nsions which may include those names appear on the \nright hamd side. For example, the definition \nLIGHT = on -+ off -+ LIGHT \ndefines a process LIGHT whose only possible be- \nhaviour is to perform on and off alternately. \nTraces \nThe semantics of a process P is defined to be the set \nof sequences of events (traces(P)) that it may pos- \nsibly perform. Examples of traces include () (the \nempty trace, which is possible for any process) and \n(on ,  off , on) which is a possible trace of LIGHT. \nA useful operator on traces is projection: If A is \na set of events then the trace tr  1 A is defined to be \nthe maximal subsequence of tr  all of whose events are \ndrawn from A .  If A is a singleton set ( a }  then we \noverload notation and write tr  1 a for tr  1 { a ) .  \nAnalysing processes \nSpecifications are given as predicates on traces, and a \nprocess P satisfies a specification S if all of its traces \nsatisfy S:  \nP sat S e V tr  E traces(P).S \nA process P is refined by a process Q (written \nP Q) if traces(Q) C traces(P). This means that \nif P meets a specification then Q will also meet it. \nModel-checking techniques allow the refinement rela- \ntion P 5 Q to be checked mechanically (for finite- \nstate processes) using the tool FDR [l]. Since two pro- \ncesses are equal if each refines the other, this means \nthat equality of processes can also be checked using \nFDR. \n3 Security properties \nA network provides a means for users, such as people \nor applkations programs, to communicate by sending \n175 \nand receiving messages. This situation may be mod- \nelled a t  a high level of abstraction in CSP as a process \nNET which provides to each user two ways of inter- \nacting with it: sending messages to other parties, and \nreceiving messages from other parties. \nWe will assume a universal set MESSAGE of all \nmessages that might be sent by any party, and we will \nconsider the users to be numbered up to n: \nUSER = ( 0 , 1 , .  . ., n> \nThe channel employed by user i to input messages to \nthe network will be the input channel in.2, of type \nUSER.MESSAGE. An input of the form in.i.j.m is \nconsidered an instruction from user i to transmit mes- \nsage m to user j .  \neventually become available. Generally these proper- \nties are expressed precisely and formally in terms of \nthe semantic models of CSP. \nAlthough it is necessary to know the internal struc- \nture of the network in order to demonstrate that it \nprovides particular services, the services or properties \nthemselves should be expressible simply in terms of the \ninteractions the network offers its users. This is the \ncase for common communications protocols, and in this \npaper we take the view that security properties can be \ncaptured in the same way. We therefore examine and \noffer definitions of these properties before considering \nthe network at any finer level of detail. \nThere are two views from which security properties \ncan be considered: \nNETWORK \nFigure 1. High level view of the network \nThe channel employed by user i to receive messages \noutput from the network will be the output channel \nout.2, of type USER.MESSAGE. An output of the \nform 0ut.i.j.m is considered to be receipt by user i of \nmessage m sent by user j .  \nUsers\u2019 requirements on the network are expressed \nin terms of the behaviour of the network as a whole, \nand CSP has been used successfully for some years in \nthe description and analysis of communications proto- \ncols. Common safety and liveness properties are read- \nily expressed in terms of the possible behaviour of the \nnetwork with respect to the users. For example, the \nproperty that no spurious messages are generated is \ncaptured as a safety property that requires any output \nmessage to have previously been input: if 0ut.i.j.m \nappears in a trace, then in.j.i.m must have already \noccurred. The liveness requirement that no message is \nlost can be formalised as follows: for any input mes- \nsage in.i.j.m the corresponding output 0ut.j.i.m must \n0 from the viewpoint of the users of the network, \nwho do not know which other parties are to be \ntrusted. Properties expressed from this viewpoint \nwill generally include assumptions (implicitly or \nexplicitly) that a user\u2019s communication partner \nwill not act contrary to the aims of the protocol. \nFor example, that any shared secrets should not \nbe disclosed to third parties. \n0 from a high-level \u2018God\u2019s eye view\u2019 which identi- \nfies those nodes which follow their protocols faith- \nfully, and also identifies those which are engaging \nin more general activity, perhaps in attempting to \nfind a flaw in a protocol. If this view is taken, then \ncare should be taken to ensure that this privileged \ninformation is not accidentally used in the protocol \ndescription: the responses of a node should not be \ndependent on information which is available only \nat the high-level view. In some circumstances, a \nnode may not have knowledge concerning its com- \nmunication partner; in other cases, a protocol may \nbe invoked only when communicating with partic- \nular known and trusted users (how this knowledge \nand trust is obtained is outside the scope of this \nreport). \nIn this report we will follow the high-level view. This \nmeans we can postulate the existence of an enemy \nwhose identity is known and can be used in the for- \nmulation of security properties. We will use 0 E USER \nas the name of this enemy process. Later we will jus- \ntify the decision to use only a single enemy, by arguing \nthat further enemies do not increase the vulnerability \nof protocols: the single enemy in a sense encapsulates \nthe behaviour of all enemies. \n176 \nConfidentiality \nConfidentiality for a particular set of messages M \nis achieved when users may communicate any mes- \nsage drawn from the set M without the possibility of \nany user other than the intended recipient receiving \nit. In other words, if an input 2n.i.j.m occurs, then \nany (subsequent) output 0ut.h.l.m must be for user j: \ni.e. h = j. Thus given user j and message m, if an \noutput 0ut.j.i.m occurs (for some i) then some user 1 \n(not necessarily i) must have sent that message to j: \nthere must be some previous input ofthe form in.l.j.m. \nThus j cannot obtain messages that were intended for \nsome other user. \nFor analysis purposes, we will consider the system \nfrom the God's-eye view: the only user which might \nobtain messages intended for some other user will be \nuser 0. Hence confidentiality will be captured as a spec- \nification requiring that any message output to user 0 \nmust have actually been sent to user 0. We restrict at- \ntention to the message set M as being those messages \nwhich are intended to remain confidential. We also as- \nsume they cannot be generated by user 0 (which would \nbe true for example for signed messages), though this \nis a simplifying assumption that is not justified in all \ncircumstances. This assumption is implicit in the def- \ninition, since otherwise 0 could simply guess any con- \nfidential message. Other messages (such as encrypted \nmessages or control messages) will in general be avail- \nable to eavesdroppers, but confidentiality is not con- \ncerned with protecting these. \nThese considerations may be captured as a trace \nspecification \nDefinition 3.1 N E T  provides confidentiality for the \nset of messages M if and only if \nNET sat 'dm : M o tr  I out.0.USER.m # () \n+ tr in. USER.0.m # () \n13 \nThis definition states that any message m which is out- \nput to user 0 (i.e. evidenced by a message out.O.i.m \nin the trace t r )  must have initially been sent to user 0 \n(i.e. there must be some j for which in.j.O.m appears \nin the trace). \nThis may also be expressed within the CSP process \nalgebra: \nTheorem 3.2 A process N E T  provides confidential- \nity in the sense of Definition 3.1 if and only if \n'dm : M N E T  I [  in.US'ER.O.mIl STOP = \nNET I [  out.0.USER.m ] I  STOP \nin. USER.V.m, \n0 \nThis stsites that if input of message m from any user \nto user 0 is blocked, then so is output of message m to \nuser 0. \nObserve that this is not equivalent to \nN E T  I[ in. USER.O.MIl STOP = \nN E T  I[ out.0. USER.M ] I  STOP \nin. USER.V.M \nFor exalmple, N E T  = in.1.0.ml -+ out.0,l.ml + \nin.1.2.nz2 -+ out.O.l.m2 + STOP meets the latter \nequivalence but not the former: a message m2 from \nuser 1 to  user 2 has been output by user 0, and this \nbreaches confidentiality (assuming ml ,  m2  E M ) .  \nThis property may also be captured in the traces \nmodel, as the property CONF \nCC)NF(tr) 2 messages(tr [ out.0. U5'ER.M) \nmessages( tr 1 in.  USER.0.M) \nThis states that the messages (from message set M )  \noutput from user 0 must be a subset of those that were \nsent to it. In other words, user 0 cannot obtain any \nmessages from M that are not sent to it. \nThe fact that this property is a sat specification \nmeans that it is preserved by refinement. \nA simlplification \nObserve that if no messages are ever sent to 0 (perhaps \nif users are communicating with users they know and \ntrust to be honest) then the characterisation of con- \nfidentiality may be simplified, since no messages will \never be sent to user 0. \nThe definition simplifies to \nN E T  sat 'd m : M tr out.O. USER.m = () \nwhich is equivalent to the simpler form \nN E T  sat tr 1 out.O. USER.M = () \nThis property may be expressed entirely within the \nprocess algebra in a number of different ways. The first \nway calptures the idea that if attention is focussed en- \ntirely upon events from out.O. USER.M, then nothing \nshould be (observed: \nN E T  \\ (C \\ out.0.USER.M) = STOP \nThe process STOP is a refinement of NET \\ (E \\ \nout.0.USER.M) (since in the traces model STOP is a \nrefinem.ent of every process), so achieving equality is \nequivalent to obtaining refinement in the other direc- \ntion: \nSTOP & N E T  \\ (E \\ out.O. USER.M) \n177 \nAn alternative characterisation is obtained by consider- \ning the effects of preventing N E T  from performing any \nevents in out.0.USER.M. A system providing confi- \ndentiality should not be affected by this restriction: \nN E T  = N E T  I[ out.O. USER.MIl STOP \nSince restricting the behaviour of N E T  can only reduce \nits behaviours, it follows automatically that the restric- \ntion is a refinement of N E T .  Hence the processes are \nequivalent precisely when there is a refinement in the \nother direction: \nN E T  I[ out.O. USER.M]I STOP E N E T  \nA final characterisation regards the system as accept- \nable if every event it can perform is in the set C \\ \nout.O. i7SER.M. In other words, everything it can per- \nform is also possible for a process which can always \nperform any of those events: \nAll of these characterisations are provably equivalent \nto the assertion N E T  sat tr 1 out.0. USER.M = () \nIt is straightforward using the process algebra to \nshow that if a system provides confidentiality for two \nsets M 1  and M 2  separately, then it provides confiden- \ntiality for both sets simultaneously: if \nN E T  I[ out.O. USER.M1]1 STOP = N E T  \nand \nN E T  I[ out.0. USER.M2]1 STOP = N E T  \nthen \nN E T  I [  out.O. USER.(Ml U M2)]1  STOP \nI [  out.O. USEB.M2]1 S T O P )  \n= ( ( N E T  I[ out.0. U S E R . M l ] (  S T O P )  \n= \n= N E T  \nN E T  I[ out.0. USER.M2]1 STOP \nMessage Authentication \nThis property requires that messages can be guar- \nanteed to be \u2018authentic\u2019, in the sense that a particu- \nlar message purporting to have come from a particular \nsource really did come from that source. Authentica- \ntion requires that messages cannot be forged. \nIn abstract terms, event b \u2018authenticates\u2019 event a \nif the observation of b is possible only if a occurred \npreviously: the observation of b provides \u2018evidence\u2019 of \na\u2019s previous occurrence. \nDefinition 3.3 Event b authenticates event a in pro- \ncess P if and only if P sat A UTH ( t r )  , where \nA U T H ( t r )  = tr  1 b # () =+ tr  1 U # (> \n0 \nObserve that this specification does not restrict the \nnumber of occurrences of event b to each occurrence \nof event a. \nThe expression of this property in terms of a s a t  \nspecification demonstrates that it is preserved by re- \nfinement. \nThis specification can also be captured as a process \nalgebraic equation. \nP I[ a ,  b ] l  STOP = P I [  a31 STOP \nAnd since it is always the case that \nP I[ a ] [  STOP 5 P I[ a ,  b]l STOP \nthe condition is equivalent to  \nP I [ %  bll  STOP !z p I [ . ]  \nFor example, the process \nP = a - + b  \ncl \nSTOP \n+ STOP \nb -+ c -+ STOP \nhas c authenticating b: \nP I[ b ,  C ] \\  STOP = a -+ STOP \n= P l [ b ] l S T O P  \nbut it does not have b authenticating a: \nP l [ a , b ] l S T O P  = STOP \n# \n= P l [ a ] l S T O P  \nb -+ c -+ STOP \nIn other words, a b event can occur even if a did not \noccur previously. \nIn the context of sending and receiving messages, we \nwould require a received message 0ut.j.i.m to authen- \nticate a sent message in.i.j .m. In other words, receipt \nof the message i.m (\u2018m from i\u2019) by node j is possible \nonly if that message was sent by node i. Thus on a sys- \ntem N E T  consisting of the medium, enemy and nodes, \nthe property to  check would be \nN E T  I[ in.i.j.m ] I  STOP = \nN E T  I[ zn.i.j.m]l STOP \n0ut.j.i.m \n178 \nFor example, a buffer process \nCOPY = in?x --+ out!x -+ COPY \nhas 0ut.x authenticating 2n.x for any x :  no message \ncan be output unless it has previously been input. \nThis characterisation of authentication can be pro- \nmoted to sets of events. The set B authenticates the \nset A in P if any message in B authenticates any of \nthe messages in A .  In other words, if any of the mes- \nsages in B is seen, then one of the messages in A must \npreviously have occurred. This is captured as follows \nDefinition 3.4 B authenticates A in P if and only if \nP I [ A U B ] ( S T O P  = P I [ A ] l S T O P  \n(3 \nThis form might be useful when we wish to check \nthat a message is genuine even when its origina- \ntor is unknown. This could be captured as the set \n0ut . j .  USER.m authenticating the set in.  l7SER.j.m. \nThe authenticating message indicates that some honest \nnode generated the original message. \nThe buffer process COPY has the weaker property \nof 0ut.M authenticating in .M:  no output can occur \nbefore input. This property is strictly weaker than the \nprevious property, in which every output authenticates \na corresponding input. For example, a random bit gen- \nerator which allows any bit to be output following any \ninput bit \nRAND = in?x + ( out!0 + RAND \n0 out!l  -+ RAND) \nalso has out.{O, 1) authenticating in.{O, 1)-no bit can \nbe output if there wasn\u2019t previously an input-but does \nnot have 0ut.x authenticating 2n.c for any particular \n.J, \nThe definition provides a straightforward proof of \ntransitivity of authentication: if C authenticates B ,  \nand B authenticates A ,  then C authenticates A: \nP I [ A U C ] I S T O P  \n= P I[ A ] \/  STOP I[ C ] l  STOP \n= P I [ A U B ] J S T O P J [ C ] I S T O P  \n= P I [ A U B U C ] I S T O P  \n= \n= \n= P I [ A U B ] I S T O P  \nP I[ B U C]l STOP I [  All STOP \nP I [  B]1 STOP I[ All STOP \n= P I [ A ] l S T O P  \n4 The network \nArchitecture \nA common architecture for which security protocols \nare designed consists of a network of nodes (typically \nworkstatioins) which are able to communicate asyn- \nchronously by sending messages to each other over a \nmedium, which acts as a postal service. The need for \nsecurity arises from the fact that the users of this ser- \nvice (such 8 s  people, and applications programs) do not \nhave control over the medium, and so it is possible for \nmalicious agents to intercept or interfere with network \ntraffic. The need for confidentiality in the face of an \ninsecure medium creates the need for some form of en- \ncryption, and the need for authenticity when message \nforgery is possible also raises the need for some form of \nsecurity mechanism. \nA common approach to modelling this situation is \nto consider a set of nodes as connected to the medium, \nwhich is modelled as a single process. Although the \nmedium will in general consist of a network of pro- \ncesses, this network may be considered at a higher level \nof abstraction as a single process. The only interactions \nthe nodes may have with other nodes must be through \nthis medium. As discussed earlier, we will find it con- \nvenient to model malicious interference by means of a \nseparate einemy process node 0 which manipulates the \nessentially passive medium. \nThus the service provided to the users is modelled \nas \nNODE;) I[ trans, recl1 MEDIUM ( I I\/ I i E rJSER\\O \nThe nodes are unable to interact directly, so their op- \neration is entirely interleaved. They all communicate \nwith the medium by means of channels trans and rec, \nused by tlhe nodes to transmit and receive messages \nrespectively. \nQuite often the distinction between a user and the \nnode by which the user communicates with the net- \nwork 1:s bllurred when addressing security properties. \nAn authentication check that a particular server re- \nmains up requires a response directly from that server \nrather than from the network operator responsible for \nit. Hence nn some cases it is appropriate to think of the \nuser and the node as being the same entity. However, \nfor the purposes of this paper we find it convenient to \ntreat them as distinct. \nAll forms of interference will be modelled by an in- \ntruder process ENEMY = NODE0 that is able to alter \nthe coindition of the medium via certain channels not \navailable to the nodes. The entire system will be de- \n179 \nscribed by \nNET (IIlitCrSER\\O NODEi) \nI [  trans, recl1 \nMEDIUM \nI [  leak, kill, a d d ] )  \nENEMY \nThe process NET will always refer to this configura- \ntion, though it will generally be parameterised by par- \nticular descriptions of the node processes NODE;, and \nof the processes MEDIUM and E N E M Y .  \nI f  \nFigure 2. Architecture of the network \nMessages \nThe kind of messages that are transmitted and re- \nceived will depend upon the particular protocol being \nmodelled, so it is probably best, at least initially, to \ndefer definition of the type of these channels until we \ncome to model a protocol. We can note that each node \nNODEi will use channels tran5.i and rec.i to interact \nwith the medium, so trans and rec may be thought \nof as denoting families of channels rather than single \nchannels. It is also likely that a destination field will \nbe required as part of the message, as well as the mes- \nsage itself and possibly an encryption. It is not clear \nat this stage how best to handle encrypted messages: \nin order to maintain the possibility that the number of \nencryption levels may be arbitrarily large, a recursive \ndata structure will be required, perhaps along the lines \nof \nMESSAGE ::= PLAINTEXT \nI K E Y  \n1 K E Y  (MESSAGE) \nI MESSAGE.MESSAGE \nand even plaintext messages might have some non- \ntrivial structure: \nPLAINTEXT ::= USER \nI T E X T  \nI PLAINTEXT.PLAINTEXT \nThis is not the only structure appropriate for mes- \nsages. For example, in a key-exchange protocol, keys \nthemselves take on a dual role, being used to en- \ncrypt messages, but also comprising the messages to \nbe encrypted. Thus for key-exchange mechanisms, \nthe set K E Y  should also be included as possible \nPLAINTEXT.  Other cryptographic mechanisms such \nas hash functions may be included as possible mes- \nsages, in which case the definition of MESSAGE \nmight be extended with two extra lines HASH and \nHASH(MESSAGE).  For the purposes of this paper, \nwe will use the definition of MESSAGE as given above, \nwhile remembering that this can be varied according to \nmodelling needs. \nIt will also prove useful, when considering what an \nenemy may deduce about messages it has received, to \nbe able to extract the information in messages. An \nextraction function kernel may be defined by struc- \ntural induction on MESSAGE; and kerneh defined for \nPLAINTEXT.  In the case we have given above, these \nfunctions will be defined as follows: \nIcernel(p) = ICerneh(p) \nkernel(lc) = ( I C }  \nkernel(k(m)) = kernel(m) \nkernel(m1.mz) = kernel(m1) U kernel(m2) \nkerneb(u) = { U }  \nkerneb(t)  = { t }  \nkerne&(pl.pz) = kerneh(p1) U kernek(p2) \nThis definition contains a clause for each clause of \nMESSAGE, reflecting the data structure in a natural \nway. \nThe function kernel lifts to sets in the obvious way. \nMessage properties \nAn intruder is able to manipulate the medium in \nThe approach taken here of using particular ways. \n180 \nevents to signal particular modes of interference (in \npreference to having them occur nondeterministically) \nwas originally taken in [6]. The advantage of this ap- \nproach is that it allows greater control over the level \nand type of interference that may occur. \nHowever, the enemy is not capable of producing all \nmessages: for example, it cannot generate a message \nencrypted with a key it does not have (though of course \nit could reproduce such a message if it had previously \nreceived it). \nIn fact, the messages the intruder is able to generate \nwill depend on the messages it has already seen pass \nas network traffic, the messages it is already able to \ngenerate, and the keys it has seen or which it owns. \nWe will use an information system [5 ]  to define which \nmessages can be generated by the enemy. It will have \na trivial consistency relation: any set of messages is \nconsistent. The definition of the relation t- of the in- \nformation system will be dependent on, and should en- \ncapsulate the encryption mechanism. An information \nsystem defines a relation t- between finite sets of to- \nkens and single tokens, indicating when the token can \nbe generated from the set. In this case, we will use the \nrelationship to indicate when the enemy, or indeed any \nother agent, can generate a particular message given \nthe messages it has already seen. \nConsider an example in which messages may be en- \ncrypted by means of either secret keys or public keys. \nThere will be the set PUBLIC of all the nodes\u2019 pub- \nlic keys-for simplicity we assume one for each node \nPUBLIC = { p i  1 i E USER) C_ K E Y  \nThere will also be the set S of all the nodes\u2019 secret \nkeys-one for each node \nSECRET = {s, 1 i E USER) 5 K E Y  \nThis set is distinct from the set of public keys: \nSECRET n PUBLIC = 0 \nFinally there will be a set of shared keys SHARED, \ndistinct both from public and secret keys: \nSECRET fl SHARED = 0 \nPUBLIC n SHARED = IZI \nThe entailment relation t-: Pfi,( MESSA G E )  \nMESSAGE will be a relation between a finite set \nX \nof \nmessages (that we think of as the enemy having seen) \nand messages that the enemy can generate. The re- \nlation is closed under the axioms for an information \nsystem: \nA l .  If m E B then B I- m \nA2. If B I-. m and B C B\u2019 then B\u2018 I- m \nA3. If B Ik mi for each mi E B\u2019 and B\u2019 F m then \nB t - m  \nWe will abuse notation and allow the relation between \npossibly infinite sets and messages: \nS t- me 3 T 5\u201d\u201d S e T I -  m \nWe encapsulate the way in which messages can be \ngenerated by considering the possible structures for a \nmessage: \nM l .  B t - m A B k k  3 B t k ( m )  \nM2. B t mp A B  I- m2 # B I- m1.m2 \nwhere m ,  ml and m2 are messages, and k is a key. \nCertain properties of particular encoding mecha- \nnisms mtiy also be captured by providing additional \ninference rules. For example, the relationship between \nsecret and. public keys may be captured by the follow- \ning pak of rules: \nKP. {ya(s,i(m,))> 1- m \nK2. {s , (p;(m))\u2019)  I- m \nwhere pi (5 P and si  E S. \nFor example, these rules allow us to deduce the obvi- \nous result that possession of a message encrypted with \na secret key (s i (m),  say), together with possession of \nthe public key, allows the original message to be re- \ntrieved: \nI. { p i , s i ( m ) }  t- s i (m)  A1 \n2. ( P i ,  s , ( m ) )  t- Pa A1 \n4. {Pi, s i ( m ) )  I- m 3, K1, A3 \nThe appropriate rule for shared keys is that possession \nof a shared key together with a message encrypted with \nthat key allows generation of the original message: \nK3. {k7 Ic(m)} I- m if k E SHARED \nIt is also possible to encode various other deductions \nwe might wish to include in the capability of t,he enemy, \nfor example deducing a key from observing both an \nencoded message and that message in plaintext: \nK4. { m, k ( m ) )  t- IC \nThe rules that we give model different encryption \nand dlecryption capabilities of the enemy. \nThe rules can also be used to encapsulate properties \nof encryption. For example, if encryption were com- \nmutative, then we could include the rule \nK5. {h, h(m)} t- h 2 ( h ( m ) )  \n3. {Pi, s i (m) )  t- . d s z ( m ) )  MI, 1, 2 \n18 1 \nMedium \nThe description of MEDIUM involves a number of \ndecisions about the best way to model the network \nmedium . \nWe must allow the possibility of an intruder, who \nis able to manipulate the medium in particular ways. \nThis could be done by building the intruder into the \nmedium (so the medium itself has the capability of in- \nterfering with message traffic in particular ways); but \nwe prefer to follow Roscoe\u2019s approach [6] of including \na separate model of the intruder. This second ap- \nproach gives greater separation between the medium \nitself, which would then be considered as essentially a \npassive service provided to the various nodes, and a ma- \nlicious agent who has particular capabilities to manip- \nulate the medium in particular ways. The capabilities \nof this agent will be made more explicit, and manipu- \nlation of the medium will be associated with particular \nevents, which will make attacks on protocols easier to  \nfollow and understand. \nThe medium (containing the set of messages B )  may \nbe described initially as MEDIUM(D),  where: \nMEDIUM(B)  = I N P U T ( B )  \nU \n0 UTP U T ( B )  \n0 \nI A ( B )  \nThe process I N P U T ( B )  permits input to the medium. \nWe must decide on the type of messages that the \nmedium will accept and offer. For the purposes of \nthis paper, we will separate out the destination and \nsource from the body of the message. Again there are \nother possibilities, for example, if the message is to be \nbroadcast to all users then no explicit destination field \nis required. \nI N P U T ( B )  = \nai trans.i?j?x -+ MEDIUM(B U { i . j . z } )  \nHere the channel trans is of type \nUSER. USER.MESSAGE. A message trans.i.j.m \nshould be thought of as node i sending an input 3.m \nto the medium, indicating the wish that message m \nbe delivered to node j. Thus i is the source, j the \ndestination, and m the message. \nWe have abstracted away refusals, in the sense that \ninput can never be refused, which amounts to making \nthe assumption that nothing can be deduced from how \nor when the messages are accepted. This is a reason- \nable assumption, since there are protocols currently in \nuse to perform tasks such as masking network traffic. \nHence at this level of abstraction we can assume that \nmessages are always accepted by the network. (If this \nis later felt to be unrealistic, the definition of INPUT \ncan be altered accordingly, so that messages may not \nBe input after the number of messages in the network \nreaches some capacity threshold) \nThe process OUTPUT allows output from the \nmedium: \nO U T P U T ( B )  = \nrec.Q!i!x -+ MEDIUM(B \\ {i . j .x})  \n\u2018i.j .x\u20acB \nHere the channel rec is of type \nUSER. USER.MESSAGE. A message rec.j.i.m \ncorresponds to the receipt of a message m by node Q \nwhich is labelled as coming from source node i. \nNote that an empty external choice is simply equiv- \nalent to STOP,  so when the set B is empty (Le. the \nmedium contains no messages) there is no possibility \nFinally, the process I A ( B )  describes the possible in- \nteractions with the medium due to Intruder Actions. \nA perfectly secure medium would treat this part of the \nprocess description as STOP. In cases we are consider- \ning, we model the ways in which the medium is suscep- \ntible to interference. Mere, the medium is vulnerable \nto having messages removed, added, or leaked. \nof output. \nI A ( B )  = \nkill -+ ObEB MEDIUM(B \\ ( 6 ) )  if B # 0 \n0 \nadd?i?j?x -+ MEDIUM(B U { i . j . x} )  \n0 \nU \nMEDIUM (0) X B = 0  \nleuk!i!j!z -+ MEDIUM(B)  \ni . j . x E B  \nEnemy action \nIA modelling the enemy we are concerned with mes- \nsages that the enemy is able to generate. These may \nbe used to disrupt a protocol, or may correspond to \ninformation about what the enemy has discovered con- \ncerning supposedly confidential messages. \nCertain assumptions may be made concerning the \nenemy, depending on the property that is under analy- \nsis. When checking confidentiality, it is often assumed \nthat the enemy is unable to generate those messages M \n(which can be generated by the users) that should be \nkept confidential. On the other hand, when checking \nauthentication it should be assumed that the enemy \n(as well as the honest users) is capable of generating \n182 \nthose messages whose authenticity is ensured by the \nprotocol, since if the enemy is unable to generate them \nthen there is no need for an authentication protocol. \nFor integrity, it is assumed that the enemy is capable \nof generating messages from M. \nThese assumptions may be incorporated into the de- \nscription of the enemy, which may then be parame- \nterised by a set of messages S that it has seen, and a \nset of messages INIT that it is initially able to gener- \nate. The assumptions can be expressed as conditions \non INIT and on the set of messages M which the par- \nticular security property is concerned with. \nThe question also arises as to whether it is suffi- \ncient to model enemy actions using a single ENEMY \nprocess. In principle it is possible that a number of \nmalicious agents acting together might effect an at- \ntack where a single agent would be unable to do so. \nWhether or not this is possible in the model being de- \nveloped here depends on the actual description of the \nprocess E N E M Y .  In fact, the description to be pre- \nsented enjoys the property that \nENEMY = ENEMY 1 1 1  ENEMY \nHence for all analysis done at the level of traces we \nsee that any number of enemies acting together are \nencapsulated within the description of a single enemy. \nIn addition to the messages that can be generated \nfrom those messages already seen, the enemy is able to \ngenerate particular plaintext messages. Furthermore, \nthe enemy should be considered to be in possession of \nall of the nodes' public keys, and all of the users' names. \nWe therefore use a set INIT to model all of the infor- \nmation initially in the possession of the enemy. Thus \nwe have PUBLIC 5 INIT and USER 5 INIT.  The \nrelation k gives the capability of the enemy to generate \nmessages from messages already in its possession. The \nCSP description of the enemy will use this relation. \nThe set S records those messages that have been read \nfrom the medium. This is initialised to 0, so ENEMY \nis defined to be E N E M Y ( m ) ,  where \nE N E M Y ( S )  = KILL(S) \n0 \nA D D ( S )  \nU \nL E A K (  S )  \nKNOWS(S)  \nThe first option allows the enemy to kill a message-to \nremove it from the medium. It is described simply as \nKILL( S) = kill + ENEMY ( S )  \nIn fact, when dealing with trace properties of commu- \nnication protocols, the ability of the enemy to kill mes- \nsages is entirely irrelevant. Although the possible re- \nmoval of messages from the medium can interfere with \nliveness properties of communications protocols, it can- \nnot compromise properties expressed only in terms of \ntraces. This is because the medium allows the reorder- \ning of inessages, so any particular message could al- \nways be ignored and remain in the medium without \nbeing killed. Any protocol that guarantees a security \nproperty if the enemy is unable to kill messages will \ntherefore guarantee it in any case. An equally useful \ndefinition of KILL(S) would be STOP (which would \nbe equivalent to omitting this option entirely). \nThe second course of action available to the enemy \nis to insert any message that it can generate onto the \nmedium. These are any messages that can be generated \nfrom it:; initial set INIT together with the messages S \nthat have since come into its possession. \nObserve that this description incorporates the ability of \nthe enemy to manipulate message address fields, thus \ngiving the impression that a message comes from a \nsource other than the genuine source. \nIf the enemy is considered to be simply an eaves- \ndr0ppe.r with no power to add messages to the medium, \nthen the ADD component would simply be modelled \nas STOP (or omitted entirely). \nThe third option allows it to observe any message \ncurrently on the medium: \nL E A K ( S )  = leak?i?j?a + E N E M Y ( S  U {z)) \nThe final option is included to model the enemy's \nknowledge of particular messages. This is accomplished \nby allowing the enemy to output any message that can \nin fact be generated. \nThe chainnel out.0 is used to indicate those messages \nthat the enemy can deduce from what has already been \nseen together with what was known initially. \nThe argument S represents the set of messages that \nthe enemy has already seen. Normally this will be the \nempty set at the beginning of a protocol run, but it is \npossible to model the effect that possession of a partic- \nular key might have on the vulnerability of a protocol, \nby including such a key, or some other message, in the \nset S. \nObserve that we have allowed the insertion of any \nmessage into the medium, so in particular false sources \ncan be attached to messages. Rerouting of a message \n183 \ncan also be modelled, by having the enemy read it via \nleak, kill it (this is cleaner though not essential, as al- \nready discussed), and then add the same message with \na different destination field back to the medium. \nNow the assumption that is made in the case of con- \nfidentiality can be formalised. We are assuming that \nnone of the messages that we wish to keep confiden- \ntial are in fact in the kernel of the messages that can \ninitially be generated by the enemy: \nM n kernel(INIT) = \nOn the other hand, for integrity and authenticity, we \nare (implicitly) assuming that \nM n INIT # \nin the sense that protocols designed to provide these \nservices are intended to deal with messages that can \nbe generated by an enemy. \nWhen checking a confidentiality protocol, strong use \nis made of this assumption, since if the enemy can out- \nput a message that is supposed to be confidential then \nthe protocol is considered to be insecure. However, \nthere are situations such as key-exchange where a pro- \ntocol is designed to provide both confidentiality and \nauthenticity, in which case it is reasonable to begin \nanalysis with M r! INIT # 0. In such situations, the \nabove modelling of what the enemy knows is not ade- \nquate, and it would be necessary to construct a more \nsophisticated, complex model of the enemy which keeps \ntrack of incoming and outgoing messages and outputs \non out.O only those messages it deduces have been gen- \nerated by the legitimate users, in particular ignoring \nthose messages in M that it puts onto the medium and \nthen reads back via leak. We will not pursue this fur- \nther in this paper, but will observe that it is a situation \nto  bear in mind. \nNodes \nWe must consider the nodes-which are the link \nbetween the user and the medium-to be under the \ncontrol of the user. It is the nodes that will provide \nthe security facilities required by the users, such as en- \ncrypting and deciphering messages. \nThe (finite) set of all nodes will be labelled using the \nset USER = (0, I, . . . , n}. \nThe nodes provide the means by which users send \nmessages over the network. A user communicating \nwith the network is in fact communicating with the \ncorresponding node. Nodes interact with users by \ninputting plaintext messages with intended destina- \ntions, and outputting such messages together with \ntheir source. The process NODE; thus communi- \ncates with its user via channels in.i and 0ut.i of \ntype USER.PLAINTEXT.  An input 2n.i.j.m to node \nNODE, is interpreted as a request from user i to send \ninessage m to user j .  Similarly, an output communi- \ncation 0ut.i.j.m is interpreted as delivery to user i of \nmessage m purporting to come from j. \nNodes (with the exception of node 0) interact with \nthe medium by transmitting (possibly enciphered) \nmessages together with other control messages, in- \ntended recipients, and any other messages employed \nby the protocol being used. The channels used are \ntrans.i for transmission, and rec.i for receipt of mes- \nsages. These channels are of type USER.MESSAGE, \nwhere the set MESSAGE contains both plain and en- \ncrypted messages (as discussed later). A communica- \ntion trans.i.j.m corresponds to NODEi placing mes- \nsage m with destination j onto the medium. A com- \nmunication rec.2. j . m  corresponds to NQDEi receiving \nmessage m from the medium, with source purporting \nto  be j .  \nThe description of a NODEi process will depend on \nthe security property we are aiming to verify of the \nnetwork. For confidentiality, authenticity, anonymity \nand integrity its description will consist of a CSP im- \nplementation of the particular protocol under analysis. \nFor example, an extremely simple protocol to provide \nconfidentiality of messages sent from user 1 to user 2 \nwill be implemented using NQDEz\u2019s public key p2 and \nsecret key s2 as follows: \nNODE1 = in.l.2?x -+ trans.l!2!pz(z) -+ NODE1 \nNODE2 = rec.2?j?y -+ \nSTOP if s ~ ( Y )  PLAINTEXT \nout.2!j!s2( y )  \n-+ NODE2 otherwise \nwhere s2(p2(z))  = 5 for any message I .  Observe that \nthis protocol does not ensure authenticity. \nThe situation is different in the case of non- \nrepudiation. In this case, verification is from the \njudge\u2019s viewpoint, and the judge does not have con- \ntrol over the nodes used in a non-repudiation protocol. \nIn fact, from the judge\u2019s viewpoint, the parties could \neach be dishonest. Indeed, it is this possibility that \ngenerates the need for a non-repudiation protocol in \nthe first place. \nThe judge has to allow for the possibility that \neach node has the capabilities of node 0. Thus non- \nrepudiation has to be established in the context of \nnodes which can kill ,  add, and leak messages as well \nas interact with the medium in the usual ways. The \nnodes for which non-repudiation should be established \n184 \nare therefore or alternatively as \nNODEi(M) = \nin. i?j?s  + NODEi(M U (8)) \nout.i!j!z -+ NODE,(M) INIT\u201d MI- 5 \n\u2018 J I N I T U M I - x  trans.i!j!z -+ NODEi(M)  \n0 rec.z?j?z + N O D E i ( M U { z } )  \nm I T u  II- \n0 leak?Z?j?z -+ NODEi(M U {z}) \n0 kill -+ NODEi(M) \nadd! i! j !z  + NODEi(M))  \nFrom a modelling point of view the interfaces of these \nprocesses with the network must be expanded to in- \nclude the channels add, leak and kill. \nSince the node is able to generate its own plaintext \nmessages, the in.i  channel is perhaps redundant, but \nis retained as a source of messages so that particular \nnon-repudiation protocols will refine this node. \nThe set of messages M corresponding to the initial \nstate of the node will contain all of the keys which the \nnode may use to encrypt and decrypt messages. \nMeadows\u2019 example \nIn order to illustrate the above material, we will \npresent a simple example used in [4] and [2]. It is \nnot even a protocol, but is instead a simple example \ndesigned purely for illustrative purposes. In fact, it is \nnot the kind of example that best illustrates the bene- \nfits of the process algebra approach, since process alge- \nbra would be of more use in exploring subtle patterns \nof interactions between different parties; here the in- \nteractions are fairly simple. However, it illustrates the \napproach. Although the proof of such an obvious prop- \nerty seems unduly long, it is also lengthier than might \nbe expected in [4] and [2]. This is because a significant \namount of formalisation needs to be done before the \nproof can actually proceed, \nThe example consists of a legitimate user who en- \ncrypts received messages with a particular key, and re- \nturns them to the medium. This could be described \nas a legitimate node (number 1 for definiteness) which \nreceives messages on rec.1, encrypts them, and returns \nthem on trans.1. The process algebra is as follows: \nNODE1 = rec.l?j?z -+ t rans . l ! j !k(z )  -+ NODE1 \nwhere k is a key possessed by NODE1. \nThe aim is to establish that the enemy cannot obtain \na particular message a that it does not already possess. \nThis is expressed as confidentiality with respect to a: \nNET = NET I[ out.O.O.a]l STOP \nNET sat ( t r  1 out.0.0.a = ()) \nWe make the standard assumption for confidentiality, \nthat the enemy is not in possession of any messages \ncontaining a: \nKERNEL( a )  sf kernel( INIT) \nWe ma,y take the description of NET to consist \nof the node NODE1, the initially empty medium \nMEDICrM(@), and the enemy who has initially learned \nnothing: ENEMY (0). \nIt wiU prove useful to extract certain sets of mes- \nsages from traces of the system: \nLEAK(tr) = {m I3 i , j  0 tr 1 Zealc.i.j.m # ()} \nA D D ( t r )  = { m  I3i , j  0 tr 1 add.2.j.m # ()} \n{m I 3 j  0 tr 1 trans.k.j .m # ()} \nRE:Ck(tr) = {m I3j 0 tr 1 rec.k.j.m # ()} \nOUTo(tr) = {m I tr 1 out.0.0.m # ()} \nTRANSk(tr) = \nME:SS(tT) = LEAK(tr )  U ADD@?) U \nTRANS1 ( t ~ )  U RECl ( t r )  U \n0 UTo( t ~ )  \nLemma 4.1 The kernel function is closed under the \ngenerates relation, i.e. \nB k- m j kernel(m) C kernel(B) \n0 \nProof By considering all of the clauses that define \nthe relation I-: A l l  A2, A3, M1, M2, K 1 ,  K 2 ,  K 3 ,  and \nK4. The result follows for each clause, so it is true for \nthe relation. 0 \nIn order to prove confidentiality of NET with re- \nspect tlo a we will use certain properties of its compo- \nnents. The required properties are described in the \nfollowing Ilemma. They combine information about \nthe state of the components (as maintained in S and \nB) and, events that have occurred (extracted from the \ntrace). A combination of information from both these \nsources is often required in establishing this kind of re- \nsult. State-based approaches commonly include a \u2018his- \ntory\u2019 variable as a component of the state in order to \nrecord trace information. The approach taken here is \ncloser )to event-based approaches which provide some \nway of extracting the state of the system from its trace. \n185 \nLemma 4.2 The component processes meet the fol- \nlowing specifications: \nENEMY ( s )  \nE N E M Y ( S )  \nMEDIUM(E)  \nMEDIUM ( E )  \nNODE1 \nwhere \nE l s ( t r )  = \nkernel(ADD(tr))  C \nsat E 1 ,y ( tr ) \nsat E 2 s ( t r )  \ns a t  M I S (  t r )  \ns a t  M 2 s (  t r )  \ns a t  N 1 s( tr)  \nkernel(S) U kernel(1NIT) U kerne l (LEAK(tr ) )  \nE 2 s ( t r )  = \nkernel( OUTo( tr ) )  C_ \nkernel(S) U kernel(IN1T) U kernel(LEAK( t r ) )  \nM l s ( t r )  = \nkerne l (LEAK(tr ) )  C \nkernel(E) U kernel( TRANSi(tr)  U kerneZ(ADD(tr)) \nM 2 s ( t r )  = \nkerne l (REC(tr ) )  C \nkerneZ(B) U kernel( T R A N S l ( t r )  U kernel(ADD(tr))  \nkernel( TRANS1 ( t r ) )  C_ kernel( REG1 ( t r ) )  \nN l s ( t r )  = \n0 \nProof This is a standard mutual recursion proof in \nCSP. The full proof has been omitted for reasons of \nspace. 0 \nSome further process algebra manipulation (details \nin the full paper) finally yields the required result. \nTheorem 4.3 The network is secure: \n(NODE1 \nMEDIUM \nE N E M Y )  s a t  tr out.O.0.a = () \nI[  trans.1, rec. l] \/  \nI [  leak,  a d d ,  kill11 \n0 \nProof The strategy of the proof is as follows: we will \nuse the properties established in Lemma 4.2 to prove \nthat the kernels of all messages passed around the sys- \ntem must be contained in the kernel of INIT .  Since it \nis given that a kerne l ( lNIT) ,  it follows that a can \nnever be passed along channel out.O. \nThe proof could easily be adapted to take other \nnodes into account. In fact, descriptions of the other \nnodes are not even necessary, all that is required of \nthem is that they meet some particular specification: \nfor example, that they do not transmit any messages \nwhose kernel intersects with that of a: \nNODE, sat \nkernel( TRANSj ( t r ) )  n kernel( a )  = \nOf course, more complex specifications might be more \nappropriate, for example that the messages added to \nthe network by the nodes do not intersect with a \n(though those that were passed to the node may be \npassed back): \nNODE, s a t  \nkernel( T R A N S j ( t r ) )  \nn ( k e r n e l ( a )  \\ kerne l (RECj( t r ) ) )  \n= 0  \nThis latter specification is in fact met by NODE1. \n5 Discussion \nModel-checking \nThis paper has been concerned with the expression \nof particular security properties and protocols within \nthe framework of CSP, in order to provide a founda- \ntion for analysis and verification. This approach is mo- \ntivated in part by the availability of model-checking \ntools such as FDR[l], and the work has always pro- \nceeded with an eye on applicability of these tools. How- \never, it is inevitable that there will be some practical \ndifficulties, and it may be necessary to adapt some of \nthe properties. When this becomes necessary, we will \nhave to establish that the properties we are checking do \nindeed correspond to the properties presented in this \npaper, or at least that results obtained by application \nof the tools allow us make the inferences we require. \nFor example, the sets PLAINTEXT and \nMESSAGES will generally be infinite, even when \nthe base sets are very small. This makes them unsuit- \nable for direct analysis by means of model-checking \nusing current (February 1996) state-of-the-art technoli- \nogy, though the situation will improve as value-passing \nis introduced. Techniques such as Skolemisation \n(deducing results concerning all messages from veri- \nfications on place-holders) might also be appropriate \nhere. In any case some simplifications will have to  be \nmade (perhaps concerning the maximum number of \nencryptions) in order to regain finitude of the message \n186 \nspace; and some additional justification of these \nassumptions will then be requhed to derive general \ncorrectness. This should not present any problems, \nsince the protocols themselves will only perform \nencryptions to a certain level (generally no more than \ntwo) and so any interference involving deeper levels \nwill be detected in any case. But nevertheless it will \nbe necessary to prove that the imposition of a bound \ndoes not rule out any attacks on a protocol, in order \nto have confidence in the results of the analysis. \nAdditional modelling issues \nThe modelling of the enemy as a separate process \nallows for the possibility of introducing tactics in the \nstate space exploration when model-checking, for ex- \nample by restricting the number of messages that the \nenemy will place on the medium. By accompanying \nenemy interference with the performance of events, \nwe may introduce tactics by introducing further con- \nstraints in parallel, refining the system. This may prove \nuseful when attempting to detect flaws, since a flaw in \na refinement will be a flaw in the original system, but \ncorrectness of refined protocols does not imply that the \noriginal one is correct unless it can be demonstrated \nthat the introduction of the tactic does not rule out \nany possible attacks. \nNon-repudiation seems to be a completely different \nkind of property. Each party in a non-repudiating ex- \nchange of messages is concerned that the other might \nnot be honest. Furthermore, it is not enough for each \nparty to be satisfied that the other party received the \nrequhed messages; each party aims to obtain evidence \nsufficient to convince an outside party that the ex- \nchange took place, \nDirections \nMeadows\u2019 example appears to be particularly \nstraightforward (which is what makes it a good ex- \nample for comparing different approaches) because the \nproof rests on the fact that at no stage is the infor- \nmation required to generate the message a ever intro- \nduced into the system; the invariant for the system is \ntherefore fairly simple, and does not rely particularly \non encryption and decryption properties, but simply \non the property that no generation of messages by the \nt- relation can introduce new information. It will be \nharder to find suitable invariants for scenarios where \ninformation is present in encrypted form (such as com- \nmunication between two users via a shared key), where \nit will be necessary to prove that at no stage could it \never be decrypted. More subtle properties Qf encryp- \ntion and decryption will be required. \nIt seems disappointing that such a simple example \nas Meadows\u2019 still requires a lengthy proof. However, \npart of the point of doing such a proof is to explore \nthe relationship between the language-theoretic ideas \nunderpinning it and the invariant of the CSP recursive \ndescription. It seems likely that this relationship will \nbe similar in many proof of this type, and we would \nhope to obtain theorems which allow results concern- \ning the language of messages that can be generated \nto be translated immediately to the CSP setting with- \nout the need for a laborious manual translation. A \nclose relationship between CSP protocol descriptions \nand rules for generating messages would allow more \nnatural proofs. Once this i s  achieved we would expect \nthe result that a particular set of rules cannot genes- \nate any message containing a to translate immediately \ninto the result that the corresponding CSP description \nhas the required confidentiality property. \nAcknowledgements \nThanks are due to Peter Ryan, Richard Moore, \nIrfun IZakiuddin, Paul Gardiner, Bill Roscoe, Gavin \nLowe, Michael Goldsmith and Abraham Sidiropoulos \nfor much lively discussion and perceptive comments on \nearlier versions of this work. Thanks also to the anony- \nmous referees for their careful reviewing of the paper, \nand for their useful and constructive suggestions. \nThanks also to DRA Malvern for providing funding \nfor this research. \nRefe,rences \nFor\u201d Systems (Europe) Ltd. Failures divergences re- \nfinement user manual and tutorial, 1994. \nJ. W. Gray and J. McLean. Using temporal logic to \nspecify and verify cryptographic protocols (progress re- \nport). In Proceedings of the eighth IEEE Computer Se- \ncurmity Foundations Workshop, 1995. \nC. A. R. Hoare. Communicating Sequential Processes. \nPrmtice-Hall, 1985. \nC. Meadows. Applying formal methods to the analysis \nof a key management protocol. Journal of Computer \nSecurity, 1(1), 1992. \nA. W. Roscoe. Lecture notes on domain theory, 1986. \nOxford University. \nA. W. Roscoe. Prospects for describing, specifying and \nverifying key-exchange protocols in csp and fdr, 1994. \nFoirmal Systems (Europe) Ltd. \nS. A. Schneider. Modelling security properties with csp, \n19!)6. Royal Holloway Technical Report CSD-TR-96-04. \n187 \n"}
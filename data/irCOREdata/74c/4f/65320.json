{"doi":"10.1007\/11547662_7","coreId":"65320","oai":"oai:dro.dur.ac.uk.OAI2:6226","identifiers":["oai:dro.dur.ac.uk.OAI2:6226","10.1007\/11547662_7"],"title":"Memory usage verification for OO programs.","authors":["Chin, W.-N.","Nguyen, H. H.","Qin, S.","Rinard, M. C."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":["Hankin, C.","Siveroni, I."],"datePublished":"2005-09-01","abstract":"We present a new type system for an object-oriented (OO) language that characterizes the sizes of data structures and the amount of heap memory required to successfully execute methods that operate on these data structures. Key components of this type system include type assertions that use symbolic Presburger arithmetic expressions to capture data structure sizes, the effect of methods on the data structures that they manipulate, and the amount of memory that methods allocate and deallocate. For each method, we conservatively capture the amount of memory required to execute the method as a function of the sizes of the method\u2019s inputs. The safety guarantee is that the method will never attempt to use more memory than its type expressions specify. We have implemented a type checker to verify memory usages of OO programs. Our experience is that the type system can precisely and effectively capture memory bounds for a wide range of programs","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65320.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/6226\/1\/6226.pdf","pdfHashValue":"21a9e29a17006b612b421ebf058fa4855b969d0f","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:6226<\/identifier><datestamp>\n      2015-03-31T11:54:36Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Memory usage verification for OO programs.<\/dc:title><dc:creator>\n        Chin, W.-N.<\/dc:creator><dc:creator>\n        Nguyen, H. H.<\/dc:creator><dc:creator>\n        Qin, S.<\/dc:creator><dc:creator>\n        Rinard, M. C.<\/dc:creator><dc:description>\n        We present a new type system for an object-oriented (OO) language that characterizes the sizes of data structures and the amount of heap memory required to successfully execute methods that operate on these data structures. Key components of this type system include type assertions that use symbolic Presburger arithmetic expressions to capture data structure sizes, the effect of methods on the data structures that they manipulate, and the amount of memory that methods allocate and deallocate. For each method, we conservatively capture the amount of memory required to execute the method as a function of the sizes of the method\u2019s inputs. The safety guarantee is that the method will never attempt to use more memory than its type expressions specify. We have implemented a type checker to verify memory usages of OO programs. Our experience is that the type system can precisely and effectively capture memory bounds for a wide range of programs.<\/dc:description><dc:publisher>\n        Springer<\/dc:publisher><dc:source>\n        Hankin, C. & Siveroni, I. (Eds.). (2005). Static analysis : 12th International Symposium, SAS 2005, 7-9 September 2005, London, UK ; proceedings. Berlin: Springer, pp. 70-86, Lecture notes in computer science(3672)<\/dc:source><dc:contributor>\n        Hankin, C.<\/dc:contributor><dc:contributor>\n        Siveroni, I.<\/dc:contributor><dc:date>\n        2005-09-01<\/dc:date><dc:type>\n        Book chapter<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:6226<\/dc:identifier><dc:identifier>\n        issn:0302-9743<\/dc:identifier><dc:identifier>\n        issn: 1611-3349<\/dc:identifier><dc:identifier>\n        doi:10.1007\/11547662_7<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6226\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1007\/11547662_7<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6226\/1\/6226.pdf<\/dc:identifier><dc:rights>\n        The final publication is available at Springer via http:\/\/dx.doi.org\/10.1007\/11547662_7<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["0302-9743"," 1611-3349","issn: 1611-3349","issn:0302-9743"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2005,"topics":[],"subject":["Book chapter","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n10 December 2009\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nChin, W.-N. and Nguyen, H. H. and Qin, S. and Rinard, M. C. (2005) \u2019Memory usage verification for OO\nprograms.\u2019, in Static analysis : 12th International Symposium, SAS 2005, 7-9 September 2005, London, UK ;\nproceedings. Berlin ; New York: Springer , pp. 70-86. Lecture notes in computer science. (3672).\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1007\/115476627\nPublisher\u2019s copyright statement:\nThe original publication is available at www.springerlink.com\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n  \nDurham Research Online \n \nDeposited in DRO: \n10 December 2009 \n \nPeer-review status: \nPeer-reviewed \n \nPublication status: \nAccepted for publication version \n \nCitation for published item: \nChin, W.-N. and Nguyen, H. H. and Qin, S. and Rinard, M. C. (2005) 'Memory usage \nverification for OO programs.', in Static analysis : 12th International Symposium, SAS 2005, \nSeptember 7-9, 2005, London, UK ; proceedings. Berlin ; New York: Springer , pp. 70-86. \nLecture notes in computer science. (3672). \n \nFurther information on publishers website: \nhttp:\/\/dx.doi.org\/10.1007\/11547662_7 \n \nPublishers copyright statement: \nThe original publication is available at www.springerlink.com \n \n \n \n \n \n \n \n \n \n \n \nUse policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior \npermission or charge, for personal research or study, educational, or not-for-profit purposes provided that : \n \n\uf0a7 a full bibliographic reference is made to the original source \n\uf0a7 a link is made to the metadata record in DRO \n\uf0a7 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders. \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nMemory Usage Verification for OO Programs\u22c6\nWei-Ngan Chin1,2, Huu Hai Nguyen1, Shengchao Qin3, and Martin Rinard4\n1 Computer Science Programme, Singapore-MIT Alliance\n2 Department of Computer Science, National University of Singapore\n3 Department of Computer Science, University of Durham\n4 Laboratory for Computer Science, Massachusetts Institute of Technology\n{chinwn,nguyenh2}@comp.nus.edu.sg\nshengchao.qin@durham.ac.uk, rinard@lcs.mit.edu\nAbstract. We present a new type system for an object-oriented (OO) language\nthat characterizes the sizes of data structures and the amount of heap memory\nrequired to successfully execute methods that operate on these data structures.\nKey components of this type system include type assertions that use symbolic\nPresburger arithmetic expressions to capture data structure sizes, the effect of\nmethods on the data structures that they manipulate, and the amount of memory\nthat methods allocate and deallocate. For each method, we conservatively capture\nthe amount of memory required to execute the method as a function of the sizes\nof the method\u2019s inputs. The safety guarantee is that the method will never attempt\nto use more memory than its type expressions specify. We have implemented a\ntype checker to verify memory usages of OO programs. Our experience is that\nthe type system can precisely and effectively capture memory bounds for a wide\nrange of programs.\n1 Introduction\nMemory management is a key concern for many applications. Over the years re-\nsearchers have developed a range of memory management approaches; examples in-\nclude explicit allocation and deallocation, copying garbage collection, and region-based\nmemory allocation. However, an important aspect that has been largely ignored in past\nwork is the safe estimation of memory space required for program execution. Overal-\nlocation of memory may cause inefficiency, while underallocation may cause software\nfailure. In this paper, we attempt to make memory usage more predictable by static\nverification on the memory usage of each program.\nWe present a new type system, based on dependent type[21], that characterizes the\namount of memory required to execute each program component. The key components\nof this type system include:\n\u2013 Data Structure Sizes and Size Constraints: The type of each data structure in-\ncludes index parameters to characterize its size properties, which are expressed in\nterms of the sizes of data structures that it contains. In many cases the sizes of these\ndata structures are correlated; our approach uses size constraints expressed using\nsymbolic Presburger arithmetic terms to precisely capture these correlations.\n\u2013 Heap Recovery: Our type system captures the distinction between shared and un-\naliased objects and supports explicit deallocation of unaliased objects.\n\u22c6 slightly revised from SAS\u201905 version\n\u2013 Preconditions and Postconditions: Each method comes with a precondition that\ncaptures both the expected sizes of the data structures on which it operates and any\ncorrelations between these sizes. The method\u2019s postcondition expresses the new\nsize and correlations of these data structures after the method executes as a function\nof the original sizes when the method was invoked.\n\u2013 Heap Usage Effects: Each method comes with two memory effects. These effects\nuse symbolic values (present in method precondition) to capture (i) memory re-\nquirement which specify the maximum heap space that the method may consume,\n(ii) memory release which specify the minimum heap space that the method will\nrecover. Heap effects are expressed at the granularity of classes and can capture\nthe net change in the number of instances of each class.\nOur paper makes several new technical contributions. Firstly, we design a formal\nverification system in the form of a type system, that can formally and statically capture\nmemory usage for the object-oriented (OO) paradigm. We believe that ours is the first\nsuch formal type system for OO paradigm. Secondly, we advocate for explicit heap re-\ncovery to provide more timely reclamation of dead objects in support of tighter bounds\non memory usage. We show how such recovery commands may be automatically in-\nserted. Thirdly, we have proven the soundness of our type checking rules. Each well-\ntyped program is guaranteed to meet its memory usage specification, and will never fail\ndue to insufficient memory whenever its memory precondition is met. Lastly, we have\nimplemented a type checker and have shown that it is fairly precise and can handle a\nreasonably large class of programs. Runtime stack space to hold methods\u2019 parame-\nters and local variables is another aspect of memory needed. For simplicity, we omit its\nconsideration in this paper.\n2 Overview\nMemory usage occurs primarily in the heap to hold dynamically created objects. In our\nmodel, heap space is consumed via the new operation for newly created objects, while\nunused objects may be recovered via an explicit deallocation primitive, called dispose.\nMemory usage (based on consumption and recovery) should be calculated over the\nentire computation of each program. This calculation is done in a safe manner to help\nidentify the high watermark on memory space needed. We achieve this through the use\nof a conservative upper bound on memory consumed, and a conservative lower bound\non memory recovered for each expression (and method).\nTo safely predict the memory usage of each program, we propose a size-polymorphic\ntype system for object-oriented programs with support for interprocedural size analysis.\nIn this type system, size properties of both user-defined types and primitive types are\ncaptured. In the case of primitive integer type int\u3008v\u3009, the size variable v captures its in-\nteger value, while for boolean type bool\u3008b\u3009, the size variable b is either 0 or 1 denoting\nfalse or true, respectively. (Note that size variables capture some integer-based prop-\nerties of the data structure. For simple types, the values are directly captured.) For user-\ndefined class types, we use c\u3008n1, . . . , np\u3009 where \u03c6 ; \u03c6I with size variables n1, . . . , np to\ndenote size properties that are defined in size relation \u03c6, and invariant constraint \u03c6I . As\nan example, consider a user-defined stack class, that is implemented with a linked list,\nand a binary tree class as shown below.\nclass List\u3008n\u3009 where n=m+1 ; n\u22650 { Object\u3008\u3009@S val; List\u3008m\u3009@U next; \u00b7 \u00b7 \u00b7 }\nclass Stack\u3008n\u3009 where n=m ; n\u22650 { List\u3008m\u3009@U head; \u00b7 \u00b7 \u00b7 }\nclass BTree\u3008s, d\u3009 where s=1+s1+s2\u2227d=1+max(d1, d2) ; s\u22650\u2227d\u22650 {\nObject\u3008\u3009@S val; BTree\u3008s1, d1\u3009@U left; BTree\u3008s2, d2\u3009@U right; \u00b7 \u00b7 \u00b7 }\nList\u3008n\u3009 denotes a linked-list data structure of size n, and similarly for Stack\u3008n\u3009. The\nsize relations n=m+1 and n=m define some size properties of the objects in terms of\nthe sizes of their components, while the constraint n\u22650 signifies an invariant associated\nwith the class type. Class BTree\u3008s, d\u3009 represents a binary tree with size variables s and\nd denoting the total number of nodes and the depth of the tree, respectively. Due to\nthe need to track the states of mutable objects, our type system requires the support of\nalias controls of the form A=U | S | R | L. We use U and S to mark each reference that\nis (definitely) unaliased and (possibly) shared, respectively. We use R to mark read-\nonly fields which must never be updated after object initialization. We use L to mark\nunique references that are temporarily borrowed by a parameter for the duration of\nits method\u2019s execution. Our alias annotation mechanism are adapted from [5, 8, 1] and\nreported in [9]. Briefly, they allow us to track unique objects from mutable fields, as\nwell as shareable objects from read-only fields.\nTo specify memory usage, we decorate each method with the following declaration:\nt mn (t1v1, . . . , tnvn) where \u03c6pr;\u03c6po; \u01ebc; \u01ebr {e}\nwhere \u03c6pr and \u03c6po denote the precondition and postcondition of the method, expressed\nin terms of constraints\/formulae on the size variables of the method\u2019s parameters and\nresult. Precondition \u03c6pr denotes an applicability condition of the method in terms of\nthe sizes of its parameters. Postcondition \u03c6po can provide a precise size relation for the\nparameters and result of the declared method. The memory effect is captured by \u01ebc and\n\u01ebr. Note that \u01ebc denotes memory requirement, i.e., the maximum memory space that\nmay be consumed, while \u01ebr denotes net release, i.e., the minimum memory space that\nwill be recovered at the end of method invocation. Memory effects (consumption and\nrecovery) are expressed using a bag notation of the form {(ci, \u03b1i)}mi=1, where ci denotes\na class type, while \u03b1i denotes its symbolic count.\nclass Stack\u3008n\u3009 where n=m ; n\u22650 { List\u3008m\u3009@U head;\nL | void\u3008\u3009@S push(Object\u3008\u3009@S o) where true;n\u2032=n+1; {(List, 1)}; {}\n{ List\u3008\u3009@U tmp=this.head; this.head=new List(o, tmp)}\nL | void\u3008\u3009@S pop() where n>0; n\u2032=n\u22121; {}; {(List, 1)}\n{ List\u3008\u3009@U t1 = this.head; List\u3008\u3009@U t2 = t1.next; t1.dispose(); this.head = t2}\nL | bool\u3008b\u3009@S isEmpty() where n\u22650; n\u2032=n \u2227 (n=0\u2227b=1 \u2228 n>0\u2227b=0); {}; {}\n{ List\u3008\u3009@U t = this.head; bool\u3008\u3009@S v = isNull(t); this.head = t; v}\nL | void\u3008\u3009@S emptyStack() where n\u22650\u2227d=n; n\u2032=0; {}; {(List, d)}\n{ bool\u3008\u3009@S v = this.isEmpty(); if v then () else {this.pop(); this.emptyStack()}}\nL | void\u3008\u3009@S push3pop2(Object\u3008\u3009@S o) where true;n\u2032=n+1; {(List, 2)}; {(List, 1)}\n{ this.push(o); this.push(o); this.pop(); this.push(o); this.pop()}}\nFig. 1. Methods for the Stack Class\nExamples of method declarations for the Stack class are given in Fig 1. The nota-\ntion (A | ) prior to each method captures the alias annotation of the current this para-\nmeter. Note our use of the primed notation, advocated in [13, 16], to capture imperative\nchanges on size properties. For the push method, n\u2032=n+1 captures the fact that the size\nof the stack object has increased by 1; similarly, the postcondition for the pop method,\nn\u2032=n\u22121, denotes that the size of the stack is decreased by 1 after the operation. The\nmemory requirement for the push method, \u01ebr={(List, 1)}, captures the fact that one\nList node will be consumed. For the pop method, \u01ebr={(List, 1)} indicates that one\nList node will be recovered.\n{\rM\re\rm\r.\rR\re\rq\r.\r N\re\rt\rR\re\rl\re\ra\rs\re\r}\r\np\ru\rs\rh\r p\ru\rs\rh\r p\ru\rs\rh\rp\ro\rp\r p\ro\rp\r\nt\ri\rm\re\r\nFig. 2. push3pop2: Heap Consumption and Recovery\nFor the isEmpty method,\nn\u2032=n captures the fact that\nthe size of the receiver ob-\nject (this) is not changed by\nthe method. Furthermore, its\noutput of type bool\u3008b\u3009@S is\nrelated to the object\u2019s size\nthrough a disjunctive con-\nstraint n=0\u2227b=1\u2228n>0\u2227b=0.\nPrimitive types are annotated with alias S because their values are immutable and can be\nfreely shared and yet remain trackable. The emptyStack method releases all List nodes\nof the Stack object. For push3pop2 method, the memory consumed (or required) from\nthe heap is {(List, 2)}, while the net release is {(List, 1)}, as illustrated in Fig. 2.\nSize variables and their constraints are specified at method boundary, and need not\nbe specified for local variables. Hence, we may use bool\u3008\u3009@S instead of bool\u3008v\u3009@S for\nthe type of a local variable.\n3 Language and Annotations\nWe focus on a core object-oriented language, called MEMJ, with size, alias, and mem-\nory annotations in Fig 3. MEMJ is designed to be an intermediate language for Java\nwith either supplied or inferred annotations. A suffix notation y\u2217 denotes a list of zero\nor more distinct syntactic terms that are suitably separated. For example, (t v)\u2217 denotes\n(t1 v1, . . . , tn vn) where n\u22650. Local variable declarations are supported by block struc-\nture of the form: (t v = e1; e2) with e2 denoting the result. We assume a call-by-value\nsemantics for MEMJ, where values (primitives or references) are passed as arguments\nto parameters of methods. For simplicity, we do not allow the parameters to be updated\n(or re-assigned) with different values. There is no loss of generality, as we can always\ncopy such parameters to local variables for updating.\nThe MEMJ language is deliberately kept simple to facilitate the formulation of static\nand dynamic semantics. Typical language constructs, such as multi-declaration block,\nsequence, calls with complex arguments, etc. can be automatically translated to con-\nstructs in MEMJ. Also, loops can be viewed as syntactic abbreviations for tail-recursive\nmethods, and are supported by our analysis. Several other language features, includ-\ning downcast and a field-binding construct are also supported in our implementation.\nFor simplicity, we omit them in this paper, as they play supporting roles and are not\nP ::= def\u2217 meth\u2217\ndef ::= class c1\u3008n1..p\u3009 [ extends c2\u3008n1..q\u3009 ] where \u03c6 ; \u03c6I { fd\u2217 (A | meth)\u2217 }\nmeth ::= t mn ((t v)\u2217) where \u03c6pr;\u03c6po; \u01ebc; \u01ebr {e}\nfd ::= t f t ::= \u03c4 \u3008n\u2217\u3009@A A ::= U | L | S | R\n\u03c4 ::= c | pr w ::= v | v.f pr ::= int | bool | void\ne ::=(c) null | k | w | w = e | t v = e1 ; e2 | new c(v\u2217)\n| v.mn (v\u2217) | mn (v\u2217) | if v then e1 else e2 | v.dispose()\n\u01eb = {(c, \u03b1)\u2217} (Memory Space Abstraction)\n\u03c6 \u2208 F (Presburger Size Constraint)\n::= b | \u03c61 \u2227 \u03c62 | \u03c61 \u2228 \u03c62 | \u00ac\u03c6 | \u2203n \u00b7 \u03c6 | \u2200n \u00b7 \u03c6\nb \u2208 BExp (Boolean Expression)\n::= true | false | \u03b11 =\u03b12 | \u03b11<\u03b12 | \u03b11\u2264\u03b12\n\u03b1 \u2208 AExp (Arithmetic Expression)\n::= kint | n | kint \u2217 \u03b1 | \u03b11+\u03b12 | \u2212\u03b1 | max(\u03b11,\u03b12) | min(\u03b11,\u03b12)\nwhere kint \u2208 Z is an integer constant; n \u2208 SV is a size variable\nf \u2208 Fd is a field name; v \u2208 Var is an object variable\nFig. 3. Syntax for the MEMJ Language\ncore to the main ideas proposed here. The interested reader may refer to our companion\ntechnical report[10] for more information.\nTo support sized typing, our programs are augmented with size variables and con-\nstraints. For size constraints, we restrict to Presburger form, as decidable (and practical)\nconstraint solvers exist, e.g. [19]. We are primarily interested in tracking size properties\nof objects. We therefore restrict the relation \u03c6 in each class declaration of c1\u3008n1, .., np\u3009\nwhich extends c2\u3008n1, .., nq\u3009 to the form\nVp\ni=q+1 ni=\u03b1i whereby V(\u03b1i) \u2229 {n1, .., np} = \u2205.\nNote that V(\u03b1i) returns the set of size variables that appeared in \u03b1i. This restricts size\nproperties to depend solely on the components of their objects.\nNote that each class declaration has a set of instance methods whose main purpose\nis to manipulate objects of the declared class. For convenience, we also provide a set\nof static methods with the same syntax as instance methods, except for its access to the\nthis object. One important feature of MEMJ is that memory recovery is done safely\n(without creating dangling references) through a v.dispose() primitive.\n4 Heap Usage Specification\nTo allow memory usage to be precisely specified, we propose a bag abstraction of\nthe form {(ci, \u03b1i)}ni=1 where ci denotes its classification, while \u03b1i is its cardinality. In\nthis paper, we shall use ci \u2208 CN where CN denotes all class types. For instance, \u03a51 =\n{(c1, 2), (c2, 4), (c3 , x + 3)} denotes a bag with c1 occurring twice, c2 four times and\nc3 x + 3 times. We provide the following two basic operations for bag abstraction to\ncapture both the domain and the count of its element, as follows:\ndom(\u03a5 ) =df {c | (c, n) \u2208 \u03a5} \u03a5 (c) =df\n\bn, if (c, n) \u2208 \u03a5\n0, otherwise\nWe define union, difference, exclusion over bags as:\n\u03a51 \u228e \u03a52 =df {(c, \u03a51(c)+\u03a52(c)) | c \u2208 dom(\u03a51) \u222a dom(\u03a52)}\n\u03a51 \u2212 \u03a52 =df {(c, \u03a51(c)\u2212\u03a52(c)) | c \u2208 dom(\u03a51) \u222a dom(\u03a52)}\n\u03a5 \\ X =df {(c, \u03a5 (c)) | c \u2208 dom(\u03a5 )\u2212 X}\nTo check for adequacy of memory, we provide a bag comparator operation under a\nsize constraint \u2206, as follows:\n\u2206 \u22a2 \u03a51 \u2292 \u03a52 =df (\u2206\u21d2 (\u2200c \u2208 Z \u00b7 \u03a51(c) \u2265 \u03a52(c))) where Z = dom(\u03a51) \u222a dom(\u03a52)\nThe bag abstraction notation for memory is quite general and can be made more pre-\ncise by refining its operations. For example, some class types are of the same size and\ncould replace each other to increase memory reuse. To achieve this we can use a bag\nabstraction that is grouped by size(ci) instead of class type ci.\n4.1 Heap Consumption\nHeap space is consumed when objects are created by the new primitive, and also by\nmethod calls, except that the latter is aggregated to include recovery prior to consump-\ntion. Our aggregation (of recovery prior to consumption) is designed to identify a high\nwatermark of maximum memory needed for safe program execution. For each expres-\nsion, we predict a conservative upper bound on the memory that the expression may\nconsume, and also a conservative lower bound on the memory that the expression will\nrelease. If the expression releases some memory before consumption, we will use the\nreleased memory to obtain a lower memory requirement. Such aggregated calculations\non both consumption and recovery can help capture both a net change in the level of\nmemory, as well as the high watermark of memory needed for safe execution.\nFor example, consider a recursive function which does p pops from one stack\nobject, followed by the same number of pushes on another stack.\nvoid\u3008\u3009@S moverec(Stack\u3008a\u3009@L s, Stack\u3008b\u3009@L t, int\u3008p\u3009@S i)\nwhere a\u2265p\u22650; a\u2032=a\u2212p\u2227b\u2032=b+p; {} ; {}\n{ if i<1 then ()\nelse {Object\u3008\u3009@S o = s.top(); s.pop(); moverec(s, t, i\u22121); t.push(o)} }\nDue to aggregation (involving recovery before consumption), the heap space that\nmay be consumed is zero. For each recursive call, the space for a List node is released\nby s.pop() before it is reused by t.push(o). Aggregated over the recursive calls, we will\nhave p number of List nodes that have been released before the same number of nodes\nare consumed. Hence, no new heap space is needed. Such aggregation is sensitive to\nthe order of the operations.\nConsider now a different function which performs p pushes on t, followed by the\nsame number of pops from s.\nvoid\u3008\u3009@S moverec2(Stack\u3008a\u3009@L s, Stack\u3008b\u3009@L t, int\u3008p\u3009@S i)\nwhere a\u2265p\u22650; a\u2032=a\u2212p\u2227b\u2032=b+p; {(List, p)}; {(List, p)}\n{ if i<1 then ()\nelse {Object\u3008\u3009@S o = s.top(); t.push(o); moverec2(s, t, i\u22121); s.pop()} }\nThough the net change in memory usage is also zero, the memory effect for this\nfunction is different as we require p number of List nodes to be consumed on entry,\nbefore the same number of List nodes are recovered. This new memory effect has the\npotential to push up the high watermark of memory needed by p List nodes.\n4.2 Heap Recovery\nExplicit heap space recovery via dispose has several advantages. It facilitates the\ntimely recovery of dead objects, which allows memory usage to be predicted more\naccurately (with tighter bounds). It also permits the use of more efficient custom allo-\ncators[4], where desired. Moreover, we shall provide an automatic technique to insert\ndispose primitives with the help of alias annotation. With such a technique, we only\nneed to ensure that objects that are being disposed are non-null. This non-nullness prop-\nerty can be captured by a non-nullness analyser, such as [12]. This property is required\nas we always recover memory space for each dispose primitive.\nMemory recovery via dispose should occur when unique references that are still\nalive (not in dead-set) are being discarded. This could occur at four places1 : (i) end\nof local block, (ii) end of method block, (iii) prior to assignment operation, and (iv)\nat conditional expression. We would like to recover the memory space for each non-\nnull reference that is about to become dead. For example, consider the pop method\u2019s\ndefinition:\nL | void\u3008\u3009@S pop() where \u00b7 \u00b7 \u00b7 { List\u3008\u3009@U t1 = this.head; head = t1.next}\nThe object pointed to by head is about to become dead prior to the operation,\nhead = t1.next. To recover this dead object, we insert a dispose command to obtain\nhead = (t1.next <; head.dispose()) where e1<;e2\u2261(t v = e1;e2;v). Consider the defin-\nition of the destroy method which calls emptyStack with an L-mode parameter.\nvoid\u3008\u3009@S destroy(Stack\u3008n\u3009@U s) where \u00b7 \u00b7 \u00b7 {emptyStack(s)}\nA unique s object is about to become dead at the end of the destroy method. To\nrecover this space, we can insert s.dispose() prior to the method\u2019s exit.\nLet us formalise an automatic technique for the explicit recovery of dead objects\nthat are known at compile-time. Given an expression e, we utilize the alias annotation\nto obtain a new expression e1 where suitable explicit heap dispose operations have been\nsafely inserted. This is achieved by a translation below with \u0393 to denote a type environ-\nment mapping program variables to their annotated types, and \u0398(\u03981) to denote the set\nof dead references (of the form v or v.f ) before (after) the evaluation of expression e.\n\u0393 ;\u0398 \u22a2 e \u2192\u0592H e1 :: t, \u03981\nMost rules are structure-preserving (or identity) rewritings, except for four rules given\nin Fig 4. A sequence of disposals can be effected through dispose(D), with D containing\na set of variable\/field references that are about to be dead at the end of expression e.\nFor the assignment rule [H:ASSIGN], we add w to the disposal set if it is unique and\nis not yet in dead-set using D = {w | ann(t)=U}\u2212\u03981. The function isParam(w) returns\ntrue if w is a parameter variable, otherwise it returns false (for fields and local vari-\nables). The function ann extracts the alias of an annotated type, ann(\u03c4 \u3008v\u2217\u3009@A) = A. A\n1 Note that unique reference cannot escape through e1 in e1; e2 as we require e1 to be of the\nvoid type.\n[H:ASSIGN]\n\u00ac isParam(w) \u0393 (w) = t\nD = {w | ann(t) = U} \u2212\u03981\n\u0393 ;\u0398 \u22a2 e \u2192\u0592H e1 :: t1, \u03981\n\u22a2 t1 <: t\ne2 = (e1 \u0001 D=\u2205\u0003 e1<; dispose(D))\n\u0393 ;\u0398 \u22a2 w = e \u2192\u0592H\nw = e2 :: void@S, \u03981\\w\n[H:IF]\n\u0393 (v) = bool\u3008b\u3009@S\n\u0393 ;\u0398 \u22a2 ei \u2192\u0592H e\u02c6i :: ti, \u0398i i = 1, 2\nt = msst(t1, t2) \u03983 = \u03981 \u222a \u03982\nDi = \u03983\u2212\u0398i i = 1, 2\nEi = (e\u02c6i \u0001 Di=\u2205\u0003 e\u02c6i<; dispose(D)) i = 1, 2\n\u0393 ;\u0398 \u22a2 if v then e1 else e2 \u2192\u0592H\nif v then E1 else E2 :: t,\u03983\n[H:METH]\n\u03931 = \u0393 + {v1 :: t1, .., vp :: tp}\n\u03931; \u2205 \u22a2 e \u2192\u0592H e1 :: t, \u0398\n\u22a2 t <: t0 ann(t0) 6= L\n\u2200i\u22081..p\u00b7(ann(ti) =L)\u21d2(\u2200f \u00b7vi.f 6\u2208\u0398)\nD = {w | (w :: t) \u2208 \u03931, ann(t)=U}\u2212\u0398\ne2 = (e1 \u0001 D=\u2205\u0003 e1<; dispose(D))\n\u0393 \u22a2meth t0 mn((ti vi)i:1..p){e}\n\u2192\u0592H t0 mn((ti vi)i:1..p) {e2}\n[H:LOCAL]\n\u0393 ;\u0398 \u22a2 e1 \u2192\u0592H e3 :: t1, \u03981\n\u22a2 t1 <: t\nann(t) 6\u2208 {L, R}\n\u0393+{v :: t};\u03981 \u22a2 e2 \u2192\u0592H e4 :: t2, \u03982\nD = {v | ann(t) = U} \u2212\u03982\ne5 = (e4 \u0001 D=\u2205\u0003 e4<; dispose(D))\n\u0393 ;\u0398 \u22a2 (t v = e1 ; e2) \u2192\u0592H\n(t v = e3 ; e5) :: t2, \u03982\\v\nFig. 4. Automatic Insertion of dispose operation\nconditional is expressed as \u03be1 \u0001 b\u0003 \u03be2 =df\n\b \u03be1, if b;\n\u03be2, otherwise.\nFurthermore, we have:\n\u0398\\v =df \u0398 \u2212 {v, v.f\n\u2217} \u0398\\v.f =df \u0398 \u2212 {v.f}\nFor the method declaration rule [H:METH], we add to the disposal set those parameters\nwhich are unique but not yet dead using {w | (w :: t) \u2208 \u03931, ann(t) = U} \u2212\u0398. For the local\ndeclaration rule [H:LOCAL], we add v to the disposal set if it is unique but not yet dead\nusing {v | ann(t) = U} \u2212\u03982. For the [H:IF] rule, the uniqueness that are consumed in one\nbranch may have their heap spaces recovered in the other branch. This is captured by\nDi = \u03983\u2212\u0398i , i = 1, 2. Notice that msst(t1, t2) returns the minimal supertype of both t1\nand t2, as follows:\n\u03c41 <: \u03c4 \u03c42 <: \u03c4 \u2200\u03c43 \u00b7 (\u03c41, \u03c42 <: \u03c43\u21d2\u03c4 <: \u03c43)\nA1\u2264aA A2\u2264aA \u2200A3 \u00b7 (A1,A2\u2264aA3\u21d2A\u2264aA3)\nmsst(\u03c41@A1, \u03c42@A2) =df \u03c4@A\nNote that \u03c41 <: \u03c42 denotes the subtype relation for underlying types (without anno-\ntations). Alias subtyping rules (shown below) allow unique references to be passed to\nshared and lent-once locations (in addition to other unique locations), but not vice-versa.\nA \u2264a A U \u2264a L U\u2264a S\nIn the rest of this paper, we shall present a new static type system for verifying\nmemory heap usage, followed by a set of safety theorems on the type rules.\n5 Rules for Memory Checking\nWe present type judgements for expressions, method declarations, class declarations\nand programs to check for adequacy of memory, using relations of the form:\n\u0393 ;\u2206;\u03a5 \u22a2 e :: t,\u22061, \u03a51 \u0393 \u22a2meth meth \u22a2class def \u22a2 P\nNote that \u0393 is the type environment as explained earlier; \u2206(\u22061) denotes the size\nconstraint, which holds for the size variables associated with \u0393 (\u0393 and t) for expression\ne before (after) its evaluation; t is an annotated type. Also, \u03a5 (\u03a51) is used to denote the\navailable memory space in terms of bag abstraction before (after) the evaluation.\nWe present a few key syntax-directed type rules in Fig 5, with the rest of the rules in\nthe technical report. Before that, let us describe some notations used by the type rules.\n[ASSIGN]\n\u0393 ;\u2206; \u03a5 \u22a2 e :: t1,\u22061, \u03a51 \u0393 \u22a2 w :: t, \u03c6, Y\n\u22a2 t1<:t, \u03c1 X=V(t1)\u222aV(t) \u22062=\u2203X\u00b7(\u22061\u25e6Y\u03c1\u03c6)\n\u0393 ;\u2206;\u03a5 \u22a2 w = e :: void\u3008\u3009@S,\u22062, \u03a51\n[DISPOSE]\n\u0393 (v) = c\u3008n\u2217\u3009@U \u03a51 = \u03a5 \u228e {(c, 1)}\n\u0393 ;\u2206;\u03a5 \u22a2 v.dispose() :: void\u3008\u3009@S,\u2206, \u03a51\n[NEW]\nfdList(c\u3008n\u2217\u3009) = ([(t\u02c6i fi)]pi=1, \u03c6\u2032)\nr\u2217 = fresh() ti = prime(\u0393 (vi))\n\u22a2 ti <: [R 7\u2192 S]t\u02c6i, \u03c1i i\u22081..p\n\u03c1 = [n\u2217 7\u2192 r\u2217]\u222a\nSp\ni=1\u03c1i\n\u2206 \u22a2 \u03a5 \u2292 {(c, 1)} X =\nSp\ni=1 V(t\u02c6i)\n\u22061 = \u2206\u2227(\u2203X\u00b7\u03c1\u03c6\n\u2032) \u03a51 = \u03a5\u2212{(c, 1)}\n\u0393 ;\u2206;\u03a5 \u22a2 new c(v1..p) :: c\u3008r\n\u2217\u3009@U,\u22061, \u03a51\n[IF]\n\u0393 (v) = bool\u3008b\u3009@S\n\u0393 ;\u2206 \u2227 b\u2032 = 1; \u03a5 \u22a2 e1 :: t1,\u22061, \u03a51\n\u0393 ;\u2206 \u2227 b\u2032 = 0; \u03a5 \u22a2 e2 :: t2,\u22062, \u03a52\n(t, \u03a53,\u22063) = unify(t1, t2, \u03a51, \u03a52,\u22061,\u22062)\n\u0393 ;\u2206;\u03a5 \u22a2 if v then e1 else e2 :: t,\u22063, \u03a53\n[OVERRIDE]\nmethk = t mn((ti vi)i:1..p) where\n\u03c6prk;\u03c6pok; \u01ebkm; \u01ebkn {\u00b7 \u00b7 \u00b7 }, k = 1, 2\n\u03c6pr1\u21d2\u03c6pr2 \u03c6po2\u21d2\u03c6po1\n\u03c6pr1 \u22a2 \u01eb1m\u2292\u01eb2m \u03c6pr1 \u22a2 \u01eb2n\u2292\u01eb1n\n\u22a2 OverridesOK(meth1,meth2)\n[IMI]\n\u22a2 (A | t\u02c6 mn((t\u02c6i v\u02c6i)i:1..p) where\u03c6pr;\u03c6po; \u01ebc; \u01ebr{e})\u2208c\u3008n\u2217\u3009\nt = fresh(t\u02c6) t0 = c\u3008n\u2217\u3009@A \u0393 (vi) = ti i\u22080..p \u22a2 ti <: t\u02c6i, \u03c1i i\u22081..p\n\u03c1p =\nSp\ni=1 \u03c1i \u22061 \u22a2 \u03a5\u2292\u01ebc \u03c1=rename(t\u02c6, t)\u222a\u03c1p\u222aprime(\u03c1p)\n\u2206\u2248>V(\u0393 ) \u2203V(\u01ebc)\u222aV(\u01ebr)\u00b7\u03c1 \u03c6pr \u22061 = \u2206 \u25e6L \u2203Y \u00b7 \u03c1(\u03c6pr\u2227\u03c6po)\n\u03a51 = \u03a5\u2212\u01ebc\u228e\u01ebr X =\nSp\ni=1 V(t\u02c6i) Y = X \u222a prime(X) L =\nSp\ni=0 V(ti)\n\u0393 ;\u2206;\u03a5 \u22a2 v0.mn(v1..p) :: t,\u22061, \u03a51\n[METH]\n\u03931 = \u0393 \u222a {v1 :: t\u02c61, .., vp :: t\u02c6p} \u2206 = noX (\u03931)\u2227\u03c6pr\u2227inv(\u03931) \u2206 \u22a2\u01ebc\u2292\u2205\n\u03931;\u2206; \u01ebc \u22a2 e :: t,\u22061, \u03a51 \u03c6pr\u2227\u22061 \u22a2\u03a51 \u2292 \u01ebr \u2206 \u22a2\u01ebr\u2292\u2205 \u22a2 t <: t\u02c6, \u03c1\n( , ,Ni) = Vfield(t\u02c6i), i\u22081..p Y =\nSp\ni=1 Ni (\u2203 prime(Y)\u00b7\u22061)\u21d2\u03c1(\u03c6po)\n\u0393 \u22a2meth t\u02c6 mn((t\u02c6i vi)i:1..p) where \u03c6pr;\u03c6po; \u01ebc; \u01ebr {e}\nFig. 5. Some Type Rules for Memory Checking\n5.1 Notations\nWe use function V to return size variables of a formula, e.g. V(x\u2032=z+1\u2227y=2)={x\u2032, y, z}.\nWe extend it to annotated type, type environment, and memory specification, e.g.,\nV(\u03c4 \u3008n\u2217\u3009@A)={n\u2217}, V({(c, 4\u00d7d+8)})={d}. The function prime takes a set of size vari-\nables and returns their primed version, e.g. prime({s1, . . . , sn})={s\u20321, . . . , s\u2032n}. Note that\nprime operation is idempotent, namely (v\u2032)\u2032=v\u2032. We extend this to (annotated) type, type\nenvironment, and even substitution. For example, prime(\u03c4 \u3008n1, . . . , nk\u3009) = \u03c4 \u3008n\u20321, . . . , n\u2032k\u3009,\nand prime([x 7\u2192a, y 7\u2192b]) = [x\u2032 7\u2192a\u2032, y\u2032 7\u2192b\u2032]. Often, we need to express a no-change con-\ndition on a set of size variables. We define a noX operation as follows which returns a\nformula for which the original and primed variables are made equal.\nnoX ({}) =df true noX ({x}\u222aX) =df (x\n\u2032=x)\u2227noX (X)\nWe extend this function to annotated types (and type environments), as follows: noX (t)\n=df noX (V(t)). Also, we use n\u2217 = fresh() to generate new size variables n\u2217. We extend it\nto annotated type, so that t\u02c6 = fresh(t) will return a new type t\u02c6 with the same underlying\ntype as t but with fresh size variables instead. Function rename(t1, t2) returns an\nequality substitution, e.g. rename(Int\u3008r\u3009, Int\u3008s\u2032\u3009)=[r 7\u2192s\u2032]. The operator\u222a combines two\ndomain disjoint substitutions into one.\nThe function fdList is used to retrieve a full list of fields for a given class, together\nwith its size relation. The function inv is used to retrieve the size invariant that is asso-\nciated with each type. This function shall also be extended to type environment and list\nof types. The function Vfield classifies size variables from each field into three groups :\n(i) immutable, (ii) mutable but unique, (iii) otherwise (non-trackable).\nTo effect a change \u03c6 to an existing poststate \u2206, we provide an operator, \u25e6Y , with\nY = {s\u2217} to denote the set of size variables that is to be updated, as follows:\n\u2206 \u25e6Y \u03c6 =df \u2203 r1 \u00b7 \u00b7 \u00b7 rn \u00b7 \u03c12(\u2206) \u2227 \u03c11(\u03c6)\nwhere Y = {s1, . . . , sn} ; {r1, . . . , rn} = fresh() ; \u03c11 = [si 7\u2192 ri]ni=1 ; \u03c12 = [s\u2032i 7\u2192 ri]ni=1\n5.2 Assignment\nThe [ASSIGN] rule captures imperative updates (to object fields and variables) by mod-\nifying the current size constraint to a new updated state with changes to the imperative\nsize variables from the LHS. From the rule, note that \u0393 \u22a2 w :: t, \u03c6, Y is to identify Y as a\nset of imperative size variables and also to gather a constraint \u03c6 for this set. The subtype\nrelation \u22a2 t1 <: t, \u03c1 will return a substitution that maps the size variables of supertype\nto that of the subtype. This mapping ignores all non-trackable size variables that may\nbe globally aliased, but immutable and unique mutable size variables are captured.\n5.3 Memory Operations\nThe heap space is directly changed by the new and dispose primitives. Their corre-\nsponding type rules, [NEW] and [DISPOSE], would ensure that sufficient memory is\navailable for consumption by new and will credit back space relinquished by dispose.\nThe memory effect is accumulated according to the flow of computation. Consider:\n\u2206\u22a2\u03a5\u2292{(List, 1)} \u22061=\u2206\u25e6{x}x\n\u2032=x+1\n\u0393 ;\u2206;\u03a5 \u22a2 x = new List(o, x) :: void\u3008\u3009@S, \u22061, \u03a5\u2212{(List, 1)}\n\u03a51=(\u03a5\u2212{(List, 1)})\u228e{(List, 1)}\n\u0393 ;\u22061;\u03a5\u2212{(List, 1)} \u22a2 y.dispose() :: void\u3008\u3009@S, \u22061, \u03a51\n\u0393 ;\u2206;\u03a5 \u22a2 x = new List(o, x); y.dispose() :: void\u3008\u3009@S, \u22061, \u03a5\nThe new operation consumes a List node, while the dispose operation releases\nback a List node. The net effect is that available memory \u03a5 is unchanged. However,\ndue to the order of the two operations, we require \u2206\u22a2\u03a5\u2292{(List, 1)} which affects the\nmaximum memory required.\nAnother rule which has a direct effect on memory is the method invocation rule\n[IMI]. Sufficient memory must be available for consumption prior to each call (as spec-\nified by \u22061 \u22a2 \u03a5\u2292\u01ebc), with the net memory release added back in the end (as specified\nby \u03a51 = \u03a5\u2212\u01ebc\u228e\u01ebr). Each method precondition must be met by the pre-state of its caller.\nThis is checked by \u2206\u2248>V(\u0393 ) \u2203V(\u01ebc)\u222aV(\u01ebr)\u00b7\u03c1 \u03c6pr which uses a relation \u2248>X , defined as:\n\u2206 \u2248>X \u03c6 =df (\u2206\u21d2 \u03c1\u03c6), where \u03c1 = [s1 7\u2192 s\u20321, .., sn 7\u2192 s\u2032n] \u2227 Vu(\u03c6) \u2229X = {s1, .., sn}.\nNote that Vu returns size variables in unprimed form, e.g. Vu(x\u2032=z+1\u2227y=2) = {x, y, z}.\n5.4 Conditional\nOur type rule for conditional [IF] is able to track both the size-constraints and memory\nusages in a path-sensitive manner. Path-sensitivity is encoded by adding b\u2032=1 and b\u2032=0\nto the pre-states of the two branches, respectively. We achieve path-sensitivity for mem-\nory usage specification by integrating it with relational size constraints derived. Take\nnote that the unify operation merges the post-state constraints and memory usages from\nthe two branches via a disjunction, a formal definition and an example can be found in\nour report [10]. Path-sensitivity makes our analysis more accurate and is critical for\nanalysing the memory requirement of recursive methods.\n5.5 Method Declaration\nEach method declaration is checked to see if its definition is consistent with the mem-\nory usage specification given in its declaration header by the [METH] rule. The initial\nmemory is \u01ebc. The final available memory of the method body e is \u03a51 which must not\nbe less than the declared net memory release (as specified by \u03c6pr\u2227\u22061 \u22a2 \u03a51 \u2292 \u01ebr).\nFunction subtyping for the OO paradigm is used to support method overriding. This\nis captured by the [OVERRIDE] rule in Fig 5. Each method which overrides another\nis expected to be contravariant on its precondition (and memory consumption) and\ncovariant on its postcondition (and memory releases)\n6 Soundness of Type System\nWe have proposed a small-step operational semantics (denoted by \u2192\u0592 transitions) instru-\nmented with alias and size notations[10], and have also formalised two safety theorems\nfor our type rules. The first theorem states that each well-typed expression preserves\nits type under reduction with a runtime environment\u03a0 and a store \u031f that are consistent\nwith the compile-time counterparts, \u0393 (type environment) and \u03a3 (store typing). Also,\nfinal size constraint is consistent with the value obtained on termination.\nTheorem 1 (Preservation).\n(a) (Expression) If \u0393 ;\u03a3;\u2206;\u0398; \u03a5 \u22a2 e :: t,\u22061, \u03981, \u03a51 \u0393 ;\u03a3;\u2206;\u0398; \u03a5 |= \u3008\u03a0,\u031f, \u03c3\u3009\n\u3008\u03a0,\u031f, \u03c3\u3009 [e] \u2192\u0592 \u3008\u03a01,\u031f1, \u03c31\u3009 [e1]\nthen there exist \u03a3\u03b1 \u2287 \u03a3, \u0393\u03b1, \u2206\u03b1, \u0398\u03b1, and \u03a5\u03b1, such that\n\u0393 \u2212 diff(e, e1) = \u0393\u03b1 \u2212 diff(e1, e) \u0393\u03b1;\u03a3\u03b1;\u2206\u03b1;\u0398\u03b1;\u03a5\u03b1 \u22a2 e1 :: t,\u22061, \u03981, \u03a51\n\u0393\u03b1;\u03a3\u03b1;\u2206\u03b1;\u0398\u03b1;\u03a5\u03b1 |= \u3008\u03a01,\u031f1, \u03c31\u3009 .\n(b) (Value) If \u0393 ;\u03a3;\u2206;\u0398;\u03a5 \u22a2 (A, \u03b4) :: t,\u22061, \u03981;\u03a51 \u0393 ;\u03a3;\u2206;\u0398;\u03a5 |= \u3008\u03a0,\u031f, \u03c3\u3009\nthen the following hold:\n\u0398 = \u03981 \u0393 + {x :: t};\u03a3;\u22062;\u03981;\u03a51 |= \u3008\u03a0 + {x 7\u2192 (A, \u03b4)},\u031f, \u03c3 \u3009\nwhere x = fresh() , \u22062 = [v 7\u2192 v\u2032]v\u2208V(t)\u22061.\nProof: By induction over the depth of type derivation for expression e. Details are given\nin the technical report [10]. 2\nThe second safety theorem on progress captures the fact that well-typed programs\ncannot go wrong. Specifically, this theorem guarantees that no memory adequacy errors\nare ever encountered for well-typed MEMJ programs, as follows:\nTheorem 2 (Progress). If \u0393 ;\u03a3;\u2206;\u0398; \u03a5\u22a2e :: t,\u22061, \u03981, \u03a51 and \u0393 ;\u03a3;\u2206;\u0398; \u03a5 |= \u3008\u03a0,\u031f, \u03c3\u3009,\nthen either e is a value, or \u3008\u03a0,\u031f, \u03c3\u3009 [e] \u2192\u0592 Err-Null, or there exist \u03a01,\u031f1, \u03c31, e1 such\nthat \u3008\u03a0,\u031f, \u03c3\u3009 [e] \u2192\u0592 \u3008\u03a01,\u031f1, \u03c31\u3009 [e1].\nProof: By induction over the depth of type derivation for expression e. Details are given\nin the technical report [10]. 2\n7 Implementation\nWe have constructed a type checker for MEMJ, and have also built a preprocessor to\nallow a more expressive language to be accepted. The entire prototype was built using\na Haskell compiler[18] where we have added a library (based on [19]) for Presburger\narithmetic constraint-solving.\nThe main objective of our initial experiments is to show that our memory usage\nspecification mechanism is expressive and that such an advanced form of type checking\nis viable. We converted to MEMJ a set of programs from the Java version of the Olden\nbenchmark suite [7] and another set of smaller programs from the RegJava bench-\nmark[11], before subjecting them to memory adequacy checking. Our initial experi-\nmental results are encouraging; however this is a proof-of-concept implementation and\nthere is scope for optimization and more exhaustive experimentation.\nPrograms Size (lines) Checking (in sec.) Verified\nSource Ann. Alias Memory Methods\nbisort 340 7 0.01 2.56 6\/6\nem3d 462 19 0.05 1.14 20\/20\nhealth 562 22 0.05 6.37 15\/15\nmst 473 31 0.02 1.26 22\/22\npower 765 24 0.06 4.28 19\/19\ntreeadd 195 6 0.02 0.32 4\/4\ntsp 545 10 0.02 3.54 9\/9\nperimeter 745 12 0.02 21.81 8\/8\nn-body 1128 31 0.60 1.25 22\/22\nVoronoi 1000 45 0.03 3.51 39\/40\nstack 122 12 0.01 0.08 10\/10\nsieve 88 7 0.01 0.09 6\/6\nm-sort 183 13 0.01 0.36 12\/12\nlife 164 9 0.02 2.95 7\/7\nMandelbrot 194 11 0.01 1.72 10\/10\nReynolds3 98 6 0.01 0.18 4\/4\nFig. 6. Type Checking Experimental Results\nFigure 6 summarises the sta-\ntistics obtained for each program\nthat we have verified via our type\nchecker. Column 3 illustrates the\nsize and memory annotation over-\nheads which must be made in\nthe header declarations of each\nclass and method. Columns 4 and\n5 highlight the CPU times used\n(in seconds) for alias and mem-\nory checking, respectively. Our ex-\nperiments were done under Red-\nhat Linux 9.0 platform on Pen-\ntium 2.4 GHz with 768MB main\nmemory. Except for the perimeter\nprogram (which has more condi-\ntionals from using a quadtree data\nstructure), all programs take under\n10 seconds to verify, despite them\nbeing medium-sized programs and\nthe high complexity of Presburger solving. We attribute this to the fact that memory dec-\nlarations are verified in a summary-based fashion for each method definition. The last\ncolumn highlights the number of methods that have been successfully verified as using\nmemory spaces that are bounded by symbolic Presburger formulae. All methods\u2019 heap\nusage could be statically bounded, except2 for a method in Voronoi that has an allocation\ninside a loop, with a complex termination condition. Apart from the memory check-\ning system described above, we have also conducted some preliminary investigation on\nmemory inference which is described in [17].\n8 Related Work\nPast research on memory models for object-oriented paradigm have focused largely on\nefficiency and safety. We are unaware of any prior type-based work on analysing heap\nmemory usage by OO programs for the purpose of checking for memory adequacy. The\nclosest related work on memory adequacy are based on first-order functional paradigm,\nwhere data structures are mostly immutable and thus easier to handle.\nHughes and Pareto [15] proposed a type and effect system on space usage estimation\nfor a first-order functional language, extended with region language constructs of Tofte\nand Talpin\u2019s[20]. The use of region model facilitates recovery of heap space. However,\nas each region is only deleted when all its objects become dead, more memory than\nnecessary may be used, as reported by [4].\nHofmann and Jost [14] proposed a solution to obtain linear bounds on the heap\nspace usage of first-order functional programs. A key feature of their solution is the use\n2 For Olden programs which built tree-like data structure, we make a minor change to take total\nnodes rather than heights as parameters. This avoids exponential formulae.\nof linear typing which allows the space of each last-use data constructor (or record) to\nbe directly recycled by a matching allocation. With this approach, memory recovery can\nbe supported within each function, but not across functions in general. Moreover, their\nmodel does not track the symbolic sizes of data structures. Nevertheless, one significant\nadvance of their work is an inference mechanism through linear programming (LP)\ntechnique. The main advantage of LP technique is that no fix-point analysis is required,\nbut it restricts the memory effects to a linear form without disjunction.\nApart from the above memory analysis work on high level languages, Aspinall and\nCompagnoni [3] presented a first-order linearly typed assembly language to allow safe\nreuse of heap space. Their system is a target for the compilation of a functional pro-\ngramming language with a similar type systems (e.g. Hofmann\u2019s LFPL) . More recently,\nCachera et. al. [6] proposed a constraint-based memory analysis for Java Bytecode-like\nlanguages. For a given program their loop-detecting algorithm can detect methods and\ninstructions that execute an unbounded number of times, thus can be used to check\nwhether the memory usage is bounded or not. However, their analysis cannot check\nwhether a given amount of memory is adequate or not, while our system does.\n9 Concluding Remarks\nWe have proposed a memory usage type system for a non-trivial object-oriented core\nlanguage. We have designed a flexible specification mechanism to allow memory needs\nof user programs to be declared abstractly, and then verifies if memory adequacy prop-\nerty holds for the given definitions. Our approach requires heap space to be explicitly\ndeallocated, which can be handled automatically. We have also built a prototype type\nchecker to confirm the viability and practicality of our approach. We envision our frame-\nwork to be useful for embedded system, where memory is considered to be a critical\nresource. We also envision the synergy of predicable memory bounds with region-based\nmemory management systems. In particular, bounded memory regions can result in bet-\nter performance. Synergistically, region-based system can provide timely recovery for\nshared objects that are dead, providing us with tighter memory bounds.\nAcknowledgement The authors would like to acknowledge the invaluable help of Florin\nCraciun with the evaluation of a set of the benchmark programs.\nReferences\n1. J. Aldrich, V. Kostadinov, and C. Chambers. Alias Annotation for Program Understanding.\nIn ACM OOPSLA, Seattle, Washington, November 2002.\n2. B. Alpern, D. Attanasio, J. J. Barton, A. Cocchi, S. F. Hummel, D. Lieber, M. Mergen,\nT. Ngo, J. Shepherd, and S. Smith. Implementing Jalapen\u02dco in Java. In ACM OOPSLA,\nDenver, Colorado, November 1999.\n3. D. Aspinall and A. Compagnoni. Heap bounded assembly language. Journal of Automated\nReasoning, 31:261\u2013302, 2003.\n4. E. D. Berger, B. G. Zorn, and K. S. Mckinley. Reconsidering Custom Memory Allocation.\nIn ACM OOPSLA, November 2002.\n5. J. Boyland, J. Noble, and W. Retert. Capabilities for Sharing: A Generalization of Unique-\nness and Read-Only. In ECOOP, Budapest, Hungary, June 2001.\n6. D. Cachera, T. Jensen, D. Pichardie, and G. Schneider. Certified Memory Usage Analysis.\nIn 13th International Symposium of Formal Methods Europe (FM\u201905), July 2005.\n7. M. C. Carlisle and A. Rogers. Software caching and computation migration in Olden. In 4th\nPrinciples and Practice of Parallel Programming, Santa Barbara, California, May 1993.\n8. E. C. Chan, J. Boyland, and W. L. Scherlis. Promises: Limited Specifications for Analysis\nand Manipulation. In Proceedings of the International Conference on Software Engineering,\npages 167\u2013176, Kyoto, Japan, April 1998.\n9. W.N. Chin, S.C. Khoo, S.C. Qin, C. Popeea, and H.H. Nguyen. Verifying Safety Policies\nwith Size Properties and Alias Controls. In 27th International Conference on Software En-\ngineering (ICSE05), St. Louis, Missouri, May 2005.\n10. W.N. Chin, H.H. Nguyen, S.C. Qin, and M. Rinard. Predictable Memory Usage for Object-\nOriented Programs. Technical report, SoC, Natl Univ. of Singapore, November 2004. avail.\nat http:\/\/www.dur.ac.uk\/shengchao.qin\/papers\/memj.ps.gz.\n11. M. V. Christiansen and P. Velschow. Region-Based Memory Management in Java. Master\u2019s\nThesis, Department of Computer Science (DIKU), University of Copenhagen, 1998.\n12. M. Fahndrich and R. Leino. Declaring and checking non-null types in an object-oriented\nlanguage. In ACM OOPSLA, Anaheim, CA, October 2003.\n13. C. A. R. Hoare and J. He. Unifying Theories of Programming. Prentice-Hall, 1998.\n14. M. Hofmann and S. Jost. Static prediction of heap space usage for first order functional\nprograms. In ACM POPL, New Orleans, Louisiana, January 2003.\n15. J. Hughes and L. Pareto. Recursion and Dynamic Data-Structures in Bounded Space: To-\nwards Embedded ML Programming. In Proceedings of the International Conference on\nFunctional Programming (ICFP \u201999), September 1999.\n16. L. Lamport. The temporal logic of actions. ACM Trans. on Programming Languages and\nSystems, 16(3):872\u2013923, May 1994.\n17. H. H. Nguyen. Memory Usage Inference for Object-Oriented Programs. Technical report,\nCS Programme, Singapore-MIT Alliance, July 2004. (Term Paper).\n18. S Peyton-Jones and et al. Glasgow Haskell Compiler. http:\/\/www.haskell.org\/ghc.\n19. W. Pugh. The Omega Test: A fast practical integer programming algorithm for dependence\nanalysis. Communications of the ACM, 8:102\u2013114, 1992.\n20. M. Tofte and J. Talpin. Region-based memory management. Information and Computation,\n132(2), 1997.\n21. H. Xi and F. Pfenning. Eliminating array bound checking through dependent types. In ACM\nPLDI. ACM Press, June 1998.\nA Alias Checking\nWe introduce four alias control mechanisms U | S | R | L adopted from [5, 8, 1]. These\nalias mechanisms shall be used to support precise size tracking in the presence of mu-\ntable objects, and also for the automatic recovery of dead unique objects. For size-\ntracking, we introduce R-mode fields to allow size-immutable properties to be accu-\nrately tracked for all objects. For example, an alternative class declaration for the list\ndata type is given below, where its next field is marked as read-only (or immutable).\nNote that the val field remains mutable.\nclass RList\u3008n\u3009 where n=m+1 ; n\u22650 { Object\u3008\u3009@S val; RList\u3008m\u3009@R next; \u00b7 \u00b7 \u00b7 }\nThe size property of such an RList type can be analysed at compile-time, while\nallowing its objects to be freely shared. However, this comes at the cost of losing both\nmutability and uniqueness.\nWe make use of L-mode parameters, with the limited unique (or lent-once) property\n[8], to capture unique references that are temporarily lent out to method calls. They\nallow the preservation of uniqueness together with precise size-tracking across methods.\nConsider the following method with two List parameters.\nvoid\u3008\u3009@S join(List\u3008m\u3009@L x, List\u3008n\u3009@U y) where n > 0;m\u2032=n+m; \u00b7 \u00b7 \u00b7\n{ if isNull(x.next) then x.next = y else join(x.next, y) }\nThe first parameter is annotated as lent-once and can thus be tracked for size proper-\nties without loss of uniqueness. However, the second parameter is marked unique as its\nreference escapes the method body (into the tail of the List from the first parameter). In\nother words, the parameter y can have its uniqueness consumed but not x, as reflected\nin the body of the above method declaration. Given two unique lists, a and b, the call\njoin(a, b) would consume the uniqueness of b but not that of a. Our lent-once policy is\nmore restrictive than normal lending [1] as we require each lent-once parameter to be\nunaliased within the scope of its method. For example, join(a, a) is allowed by the type\nrules of [1], but disallowed by our lent-once\u2019s policy.\nIn our alias type system, uniqueness may be transferred from one location (variable,\nfield or parameter) to another location. Consider a type environment {x::Object\u3008\u3009@U,\ny::Object\u3008\u3009@U, z::Object\u3008\u3009@S} where variables x and y are unique, while z is shared. In\nthe following code, {x = y; z = x}, the uniqueness of y is first transferred to location x,\nfollowed by the consumption of uniqueness of x that is lost to the shared variable z. In\nour type judgement, we track variables\/fields that have become dead using:\n\u0393 ;\u0398 \u22a2 e :: t, \u03981\nHere, each dead-set \u0398(\u03981) captures the set of references with consumed uniqueness\nbefore(after) the evaluation of expression e. \u0393 is a type enviroment which maps vari-\nables to their annotated types. Other type judgements for methods, classes and programs\nhave the following forms.\n\u0393 \u22a2meth meth \u22a2def def \u22a2P defi:1..p methi:1..q\nThe full set of alias checking rules are given in our technical report [10]).\n"}
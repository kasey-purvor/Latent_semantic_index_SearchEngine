{"doi":"10.1109\/IJCNN.2006.247176","coreId":"196329","oai":"oai:lra.le.ac.uk:2381\/8505","identifiers":["oai:lra.le.ac.uk:2381\/8505","10.1109\/IJCNN.2006.247176"],"title":"Job-Shop Scheduling with an Adaptive Neural Network and Local Search Hybrid Approach","authors":["Yang, Shengxiang"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2006-07","abstract":"Job-shop scheduling is one of the most difficult production scheduling problems in industry. This paper proposes an adaptive neural network and local search hybrid approach for the job-shop scheduling problem. The adaptive neural network is constructed based on constraint satisfactions of job-shop scheduling and can adapt its structure and neuron connections during the solving process. The neural network is used to solve feasible schedules for the job-shop scheduling problem while the local search scheme aims to improve the performance by searching the neighbourhood of a given feasible schedule. The experimental study validates the proposed hybrid approach for job-shop scheduling regarding the quality of solutions and the computing speed","downloadUrl":"http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?isnumber=36115&arnumber=1716466&count=787&index=404&tag=1.","fullTextIdentifier":"https:\/\/lra.le.ac.uk\/bitstream\/2381\/8505\/1\/IJCNN06.pdf","pdfHashValue":"6caa0444813bfcf85e13eecfa8d8c2c2a1ca93a6","publisher":"Institute of Electrical and Electronics Engineers (IEEE)","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:lra.le.ac.uk:2381\/8505<\/identifier><datestamp>\n                2016-04-06T08:43:34Z<\/datestamp><setSpec>\n                com_2381_316<\/setSpec><setSpec>\n                com_2381_9549<\/setSpec><setSpec>\n                col_2381_4072<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nJob-Shop Scheduling with an Adaptive Neural Network and Local Search Hybrid Approach<\/dc:title><dc:creator>\nYang, Shengxiang<\/dc:creator><dc:description>\nJob-shop scheduling is one of the most difficult production scheduling problems in industry. This paper proposes an adaptive neural network and local search hybrid approach for the job-shop scheduling problem. The adaptive neural network is constructed based on constraint satisfactions of job-shop scheduling and can adapt its structure and neuron connections during the solving process. The neural network is used to solve feasible schedules for the job-shop scheduling problem while the local search scheme aims to improve the performance by searching the neighbourhood of a given feasible schedule. The experimental study validates the proposed hybrid approach for job-shop scheduling regarding the quality of solutions and the computing speed.<\/dc:description><dc:date>\n2010-09-20T15:39:27Z<\/dc:date><dc:date>\n2010-09-20T15:39:27Z<\/dc:date><dc:date>\n2006-07<\/dc:date><dc:type>\nConference paper<\/dc:type><dc:identifier>\nIEEE International Joint Conference on Neural Networks 2006, Conference Proceedings, pp. 2720-2727.<\/dc:identifier><dc:identifier>\n0780394909<\/dc:identifier><dc:identifier>\nhttp:\/\/ieeexplore.ieee.org\/xpl\/articleDetails.jsp?arnumber=1716466<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2381\/8505<\/dc:identifier><dc:identifier>\n10.1109\/IJCNN.2006.247176<\/dc:identifier><dc:language>\nen<\/dc:language><dc:rights>\nThis is the author's final draft of the paper published as IEEE International Joint Conference on Neural Networks 2006, Conference Proceedings, pp. 2720-2727.  The final version is available from http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?isnumber=36115&arnumber=1716466&count=787&index=404&tag=1.  Copyright \u00a9 2006 IEEE.  Doi: 10.1109\/IJCNN.2006.247176  \\ud\n   \\ud\n\\ud\nThis material is posted here with permission of the IEEE. Such permission of the IEEE does not in any way imply IEEE endorsement of any of the University of Leicester\u2019s  products or services.  Internal or personal use of this material is permitted.  However, permission to reprint\/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution must be obtained from the IEEE by writing to pubs-permissions@ieee.org.\\ud\n\\ud\nBy choosing to view this document, you agree to all provisions of the copyright laws protecting it.<\/dc:rights><dc:publisher>\nInstitute of Electrical and Electronics Engineers (IEEE)<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2006,"topics":[],"subject":["Conference paper"],"fullText":"Job-Shop Scheduling with an Adaptive Neural Network and Local\nSearch Hybrid Approach\nShengxiang Yang, Member, IEEE\nAbstract\u2014 Job-shop scheduling is one of the most difficult\nproduction scheduling problems in industry. This paper pro-\nposes an adaptive neural network and local search hybrid\napproach for the job-shop scheduling problem. The adaptive\nneural network is constructed based on constraint satisfactions\nof job-shop scheduling and can adapt its structure and neuron\nconnections during the solving process. The neural network\nis used to solve feasible schedules for the job-shop scheduling\nproblem while the local search scheme aims to improve the\nperformance by searching the neighbourhood of a given feasible\nschedule. The experimental study validates the proposed hybrid\napproach for job-shop scheduling regarding the quality of\nsolutions and the computing speed.\nI. INTRODUCTION\nThe job-shop scheduling problem (JSP) is one of the most\ndifficult production scheduling problems. It aims to allocate\na number of machines over time to perform a set of jobs\nwith certain constraint conditions in order to optimize certain\ncriterion, e.g., minimizing the makespan. Traditionally, there\nare three kinds of approaches to solve the JSPs, priority rules,\ncombinatorial optimization and constraints analysis [5]. Due\nto the hardness of solving JSPs researchers also investigated\nintelligent methods for JSPs [8].\nFoo and Takefuji [6], [7] first used a neural network to\nsolve JSPs. Thereafter, several neural networks have been\ndevised by researchers for JSPs. Willems [12] first proposed\na constraint satisfaction neural network for traditional JSPs.\nYu [16] extended Willems\u2019s neural network by adding a\njob constraint block to deal with free operations. Yang and\nWang in [13] devised a constraint satisfaction adaptive neural\nnetwork (CSANN) for generalized JSPs where there may\nexist free sequence operation pairs or free operations of each\njob. CSANN is constructed from the constraints of a JSP and\nworks by resolving constraint violations during its running.\nCSANN can adapt the connection weights and biases of\nneurons according to the actual constraint violations during\nthe running of CSANN.\nRecently, Yang [15] further proposed an improved CSANN\nmodel, called CSANN-II. In CSANN-II, the resource con-\nstraint block is constructed adaptively from actual resource\nconstraint satisfactions during the running, which is achieved\nby quick sorting the jobs on each machine according to\ntheir starting time and then orderly pair two neighbouring\njobs into resource constraint units. CSANN-II has reduced\nnumber of resource constraint units in the resource constraint\nblock, which leads to reduced network complexity and hence\nShengxiang Yang is with the Department of Computer Science, University\nof Leicester, University Road, Leicester LE1 7RH, United Kingdom (Tel:\n0044-116-2515341; Fax: 0044-116-252 3915; Email: s.yang@mcs.le.ac.uk).\nreduced computational complexity. Several heuristics have\nbeen combined with CSANN-II to guarantee its convergence,\naccelerate its solving speed, and improve the quality of\nobtained solutions.\nIn this paper, a local search mechanism is further proposed\nto be combined into CSANN-II for JSPs. In the local search\nmechanism, given a feasible schedule obtained by CSANN-\nII, we first relax the starting time of the operations to\nobtain an relaxed schedule and then we perform local search\nfrom the relaxed schedule iteratively as follows. We first\nswap the starting times of the operation with the largest\ncompletion time and a randomly selected different opera-\ntion on each machine and then use CSANN-II to obtain\na feasible schedule from this resulting possibly infeasible\nschedule. In order to test the efficiency of the proposed hybrid\napproach, experiments are carried out to compare the hybrid\napproach with CSANN-II only and two classical heuristics\non three benchmark JSPs by Muth and Thompson [11]. The\nexperimental results show that CSANN-II with the local\nsearch scheme has good performance regarding the quality\nof solutions and the computing speed.\nThe remaining of this paper is organized as follows.\nSection II describes the mathematical formulation, the clas-\nsification of feasible solutions, and Giffler and Thompson\u2019s\nclassic heuristics [9] for JSPs. Section III presents in detail\nthe model of CSANN-II, including its neuron model and\nits adaptive connections and architecture. In Section IV,\nwe describe the proposed local search scheme that can be\ncombined with CSANN-II for better performance. Section V\npresents the experimental results of comparing the proposed\nhybrid approach with CSANN-II and two classical heuristics\nfor JSPs. Finally, Section VI concludes this paper with some\ndiscussions on the relevant future work.\nII. JOB-SHOP SCHEDULING PROBLEM\nA. Description of the Job-Shop Scheduling Problem\nTraditionally, the JSP can be stated as follows [1]: given\n\u0000 jobs to be processed on \u0001 machines in a prescribed\norder. The objective is to optimally arrange the processing\norder and the start times of operations to optimize certain\ncriteria. Usually, for JSPs there are two types of constraints:\nsequence constraint and resource constraint. The first type\nmeans that two operations of a job cannot be processed at\nthe same time. The second type states that no more than\none job can be handled on a machine at the same time.\nJSP can be viewed as an optimization problem, bounded\nby both sequence and resource constraints. In this paper we\nconsider traditional JSPs and assume each job pass through\nall machines in certain sequencing order. The processing\ntime of each operation on a machine is known and fixed.\nOperations can not be interrupted once started, i.e., non-\npreemptive. The JSP is formally described as follows.\nLet\n\u0000\u0002\u0001\u0004\u0003\u0005\u0000\u0007\u0006\t\b\u000b\n\f\n\u000b\n\r\b\u000e\u0000\u0010\u000f\u0012\u0011\nand \u0013\n\u0001\u0014\u0003\n\u0013\n\u0006\u0015\b\f\n\u000b\n\f\n\r\b\n\u0013\u0002\u0016\n\u0011\ndenote\nthe job and machine set respectively, where \u0000 and \u0001 are the\nnumber of jobs and machines. Each job has \u0001 operations.\n\u0017\u0019\u0018ff\u001a\u000efi\nrepresents operation fl of job ffi to be processed on\nmachine \u001f ,  \n\u0018ff\u001a\u000bfi\nand !\n\u0018ff\u001a\u000bfi\nrepresent the start time and pro-\ncessing time of\n\u0017\u0019\u0018\"\u001a\u000efi\nrespectively,  \n\u0018ff#%$&fi\nand !\n\u0018\"#%$'fi\nrepresent\nthe start time and process time of the last operation of job\nffi respectively. Denote (\n\u0018\nand )\n\u0018\nas the release date (earliest\nstarting time) and due date (latest ending time) of job ffi . Let\n * \n\u0018\nbe the sequence set of operation pairs [ \u0017+\u0018\"\u001a-, , \u0017.\u00180\/0fi ] of\njob ffi , where operation \u0017 \u0018ff\u001a-, must precede \u0017 \u00180\/0fi . Let 12 fi be\nthe set of operations\n\u0017 \u0018ff\u001a\u000efi\nto be processed on machine \u001f .\nTaking minimizing the makespan as the optimization cri-\nterion, the JSP considered can be formulated as follows:\n\u00133ffi\n\u0000\nffi \u00014ffi%576\u00048\n\u0001\n\u0001:9\u0010;\n\u0018=<7>\r?\n \n\u0018ff#%$@fi*A\n!\n\u0018\"#%$@fi\u000eB\nC\u000bD\rEGF\n6\u0015HJIKIGL\n \n\u00180\/0fiNM\n \n\u0018ff\u001aO,QP\n!\n\u0018\"\u001a-,\n\b\nR\n\u0017.\u0018\"\u001a-,\n\b\n\u0017\u0019\u00180\/0fiJSUT\n * \n\u0018\n\b\nfl\n\bOV\nT\n\u0003\u0010W\u0005\b\f\n\u000b\n\u000b\nX\b\n\u0001\n\u0011\u0010\b\nffi\nT\n\u0000 (1)\n ZY\n\/fffiNM\n \n\u0018ff\u001a\u000efi2P\n!\n\u0018ff\u001a\u000bfi\nL\u0015([ \n\u0018\"\u001a\u000efiNM\n ZY\n\/0fi\\P\n!\rY\n\/fffi\n\b\n\u0017\u0019\u0018\"\u001a\u000efi\n\b\n\u0017\nY\n\/fffi\\T\n1\\ \nfi\n\b\nffi\n\b\nF\nT\n\u0000]\b\n\u001f\nT\n\u0013 (2)\n(\n\u0018_^\n \n\u0018\nY\nfi\\^\n)\n\u0018\fM\n!\n\u0018\nY\nfi\n\b\nffi\nT\n\u0000]\b\nF\nT\n\u00037W\u0005\b\f\n\u000b\n\f\n\r\b\n\u0001\n\u00117\b\n\u001f\nT\n\u0013 (3)\nIn the above formulation, the cost function 8 is the\ncomplete time of the latest operation. Minimizing the cost\nfunction means minimizing the makespan. Eqn. (1) repre-\nsents the sequence constraint between two operations of a\njob. Eqn. (2) represents the resource constraints between two\njobs on a machine in a disjunctive format. Eqn. (3) represents\nthe release and due date constraints of jobs.\nB. Classification of Feasible Solutions for JSPs\nFor a given JSP, there are in fact infinite feasible sched-\nules since arbitrary excess idle times can be inserted into\na feasible schedule to create new feasible ones. Given a\nfeasible schedule for JSPs, if an operation can be left-shifted\n(started earlier) without altering the processing sequences,\nsuch a left-shift is called a local left-shift. If a left-shift of an\noperation alters the processing sequences but does not delay\nany other operations, it is called a global left-shift. Based on\nthe concept of local and global left-shift, feasible schedules\nfor JSPs can be classified into four types: inadmissible, semi-\nactive, active and non-delay.\nInadmissible schedules are those that contain excess idle\ntime and can be improved by local and\/or global left-shift(s).\nobviously, these kind of schedules are not of practical useful-\nness. Semi-active schedules are those that allow no local left-\nshift, but there may be allowable global left-shift(s). Active\nschedules are those that allow neither local left-shift(s) nor\nglobal left-shift(s). Non-delay schedules are active schedules\nin which no machine is kept idle while some operation can\nTABLE I\nA LIST OF JOB-SHOP DISPATCH RULES.\nRule Description\nSPT (Shortest Processing Time) Select an operation with the shortest\nprocessing time\nLPT (Longest Processing Time) Select an operation with the longest\nprocessing time\nMWR (Most Work Remaining) Select an operation for the job with the\nmost total remaining processing time\nLWR (Least Work Remaining) Select an operation for the job with the\nleast total remaining processing time\nMOR (Most Operations Remaining) Select an operation for the job with the\ngreatest number of operations remaining\nLOR (Least Operations Remaining) Select an operation for the job with the\ngreatest number of operations remaining\nbe processed. An optimal schedule is guaranteed to be an\nactive one but not necessarily a non-delay one [1].\nC. Giffler and Thompson Heuristics for JSPs\nGiffler and Thompson [9] first proposed a systematic\nmethod, denoted GT-Random in this paper, to generate any\nactive schedules for JSPs as described below. Let 8` \n?'\u00172B\nand\n8`a\n?&\u00172B\ndenote the earliest (possible) start time and earliest\n(possible) completion time of an operation \u0017 respectively.\nAn active schedule is generated by repeating the algorithm\nuntil all operations are scheduled as follows.\n1). Let b be a set of all unscheduled operations. Find\nan operation\n\u0017dc (with ties broken randomly) that has\nthe minimum earliest (possible) completion time in b .\nThat is,\n\u0017`cfe\n\u0001\narg min\n\u0003\n8`a\n?&\u00172B\u000bg \u0017hT\nb\n\u0011\n. Let \u0013\nc\ndenote the machine that processes\n\u0017\nc\n.\n2). Construct the conflict set a which contains unsched-\nuled operations in b that are processed on \u0013\nc\nand\nwhose processing will overlap with\n\u0017`c\n. That is, a\ne\n\u0001\n\u0003\n\u0017iT\nb\ngZ\u0017\non \u0013\nc\n\b\n8` \n?&\u00172BNj\n8ka\n?'\u0017dclB\n\u0011\n.\n3). Select an operation \u0017mT a randomly and schedule it\non \u0013\nc\nwith its completion time equal to 8`a\n?&\u00172B\n.\nIn Step 3 of the above GT-Random algorithm, if all\npossible choices are considered, all active (non-delay) sched-\nules will be generated respectively, but the total number of\nschedules will be very large. Researchers have developed\na large number of heuristic priority rules to be used in\nthe Giffler and Thompson algorithm to select an operation\nfrom the schedulable set to be dispatched next. An extensive\nsummary and discussion can be found in [3], [10]. Table I\nlists some priority rules commonly used in practice.\nIt is also quite common that the priority rules can be\ncombined into the Giffler and Thompson algorithm: when\ndispatching an operation, one priority rule is first randomly\nselected from a pre-defined set of priority rules and then\napplied to select an operation. This hybrid method is denoted\nGT-Rule in this paper.\nBoth the GT-Random and GT-Rule algorithms have be-\ncome the basis for many priority-rule based heuristics and\nhybrid scheduling systems for JSPs. They will be used as\n\u0000\u0002\u0001\n\u0003\u0005\u0004 \u0006\n\u0007\n\u0006\n\b\n\b\n\b\n\b\n\b\n\b\n\t\n\u000b\n\u000b\n\u000b\n\u000b\n\u000b\n\u000b\n\f\n\u0006\n\r\n\u0018 \u000e\u0019\u0018\n\u000f\nA\nW\n\u0010\n\u0018\n\u000e \u0006\n\u000e\nY\n\u000e\n\u000f\n\u0011\n\u0011\n\u0011\n\u0011\n\u0011\n\u0011\n\u0011\n\u0011\n\u0011\n\u0011\n\u0012\n\u0018 \u0006\n\u0012\n\u0018\nY\n\u0012\n\u0018 \u000f\n\u0013 ?\n\r\n\u0018'B\nFig. 1. General neural unit model.\npeer algorithms in this paper1 for comparing the performance\nof CSANNs, to be described next, for JSPs.\nIII. IMPROVED CONSTRAINT SATISFACTION ADAPTIVE\nNEURAL NETWORK \u2014 CSANN-II\nA. Neurons of CSANN-II\nUsually a neural unit ffi consists of a linear summator and\na nonlinear activation function\n\u0013 ?\n\n\nB\n, which are serialized as\nfollows:\n\u000e\u0019\u0018\n\u0001\n\u0013 ?\n\r\n\u0018@B\n\u0001\n\u0013 ?\n\u000f\n\u0014\nY\u0016\u0015\n\u0006\n?\n\u0012\n\u0018\nY\u0018\u0017\n\u000e\nY\nB A\n\u0010\n\u0018&B\n\b (4)\nwhere the summator sums a bias \u0010\n\u0018\nand received activations\n\u000e\nY\n?\nF\n\u0001 W7\b\u000b\n\f\n\u000b\n\r\b\n\u0000\nB\nfrom connected units with connection\nweight\n\u0012\n\u0018\nY from unit F to unit ffi . The output of summator\nis the net input\n\r\n\u0018\nto neuron ffi , which is then passed to the\nactivation function\n\u0013 ?\n\n\nB\nto obtain the activation\n\u000e\n\u0018\n. Fig. 1\nshows the model of a general neural unit.\nBased on the general neuron model, CSANN-II contains\nthree kinds of neurons: ST-units, SC-units and RC-units. ST-\nunits represent operations with the activation of each ST-\nunit representing the start time of an operation. SC-units\nand RC-units represent whether the sequence constraints and\nresource constraints are satisfied respectively. The net input\nand activation functions of an ST-unit,  \u001a\u0019\n\u0018\n, are defined as:\n\rfiffffifl\n$\u000b?\nI\nB\n\u0001\n\u0014\nY\n?\n\u0012\n\u0018\nY\n\u0017\n\u000e\nffffi\u001f! \n?\nI\nB-B A\n\u0014\n\u001a\n?\n\u0012\n\u0018ff\u001a\n\u0017\n\u000e#\"\n\u001f%$\n?\nI\nB B\nA&\u000e\nffffifl\n$\u000e?\nI\nM\nW\nB (5)\n\u000e\nffffifl\n$\u000e?\nI\nB\n\u0001('\n) *\n(\n\u0018\n\b \r\nffffifl\n$J?\nI\nBNj\n(\n\u0018\n\r\nffffifl\n$J?\nI\nB\n\b\n(\n\u0018_^\n\r\nffffifl\n$J?\nI\nBN^\n)\n\u0018\fM\n!\nffffifl\n$\n)\n\u0018\rM\n!\nff+fl\n$\n\b,\r\nffffifl\n$\u000e?\nI\nB.-\n)\n\u0018 M\n!\nffffifl\n$\n(6)\nwhere in Eqn. (5) the net input of  \u001a\u0019 \u0018 is summed from\nthree parts. The first and second parts come from the\nweighted activations of SC-units and RC-units related to  \/\u0019\n\u0018\n,\nwhich implement feedback adjustments due to sequence and\nresource violations respectively. The third part comes from\nprevious activation of unit  \/\u0019\n\u0018\nitself. The activation function\nin Eqn. (6) is a linear-segmented function, where ( \u0018 and ) \u0018\nare the release and due date of job ffi to which the operation,\ncorresponding to  \/\u0019\n\u0018\n, belongs. !\nffffifl\n$\nis the processing time of\n1The GT-Rule algorithm studied in this paper uses exactly the six rules\nin Table I as the set of priority rules\nthe operation. This activation function implements the release\nand due date constraints described by Eqn. (3).\nThe net input and activation functions of an SC-unit  *a\n\u0018\nor RC-unit 12a\n\u0018\nhave the same definition as shown below:\n\r\u0018\u001f\n$ ?\nI\nB\n\u00010\u0012 \u0006\n\u0017\n\u000e\nff+fl21\n?\nI\nB A\n\u001243\n\u0017\n\u000e\nff+fl65\n?\nI\nB A\n\u0010,\u001f\n$ (7)\n\u000e \u001f $J?\nI\nB\n\u000187:9\n\b \r \u001f\n$J?\nI\nB P\n9\nM\n\r \u001f\n$ ?\nI\nB\n\b;\r \u001f\n$J?\nI\nB j\n9\n(8)\nwhere a\n\u0018\nrepresents  *a\n\u0018\nor 12a\n\u0018\nand\n\u0010&\u001f\n$\nis the bias, which\nequals the processing time of a relative operation. The ST-\nunits,  \/\u0019\n\u0006\nand  \/\u0019\n3\n, represent two operations of the same job\nfor an SC-unit, or two operations sharing the same machine\nfor a RC-unit. The activation function is linear-segmented.\nWhen the activation of an SC- or RC-unit is greater than\n9 , it means the relevant sequence or resource constraint is\nviolated and there will be feedback adjustments from  *a \u0018\nor 1\\a\n\u0018\nto connected  \/\u0019\n\u0006\nand  \u001a\u0019\n3\nwith adaptive weights.\nB. Adaptive Connection Weights and Biases\nUsually for a neural network for constraint satisfac-\ntory problems, the connection weights between neurons are\nproblem-specific and set in advance before it is run. In\nCSANN-II, the connection weights and biases are adaptive\nin accordance with the actual activations of ST-units while\nCSANN is running, together with the sequence and resource\nconstraints of the specific JSP.\nAll neurons of CSANN-II are structured into two problem-\nspecific constraint blocks: sequence constraint block (SC-\nblock) and resource constraint block (RC-block). Each SC-\nblock unit consists of two ST-units that represent two op-\nerations of a job and one SC-unit that represents whether\nrelevant sequence constraint is satisfied, see Fig. 2. Similarly,\neach RC-block unit has two ST-units that represent two op-\nerations on a machine and one RC-unit representing whether\nrelevant resource constraint is satisfied, see Fig. 3.\n<>=\n?>@\n<>=\n?>@\n<A=\n?A@\nB\nB\nB\nB\nBDC\n\u0006 E\nE\nE\nE\nE\nF\nG\nGIH J\nJ K\nLM NO\nG\nGIH\nJ\nJ K\nE\nE\nE\nE\nE P\nB\nB\nB\nB\nB Q\nJ\nJ K\nG\nGIH\nR,S\nTVU TXW\nTXY\nTXZ\n[.\\2]\n$\n$_^\nR,SR,S `ba!cedgf `ba!cih j\nk\n\\ml\n$\n$on\nk\n\\ml\n$\n^qp\nrs\\ml\n$\n$Dn\nrs\\ml\n$\n^qp\n`ut\/cedvh\nFig. 2. A SC-block unit w!x\u001ay czdvh .\nFig. 2 shows an example SC-block unit  *a\n\u0010\n\u0018ff\u001a \/\n. ST-units\n \/\u0019\n\u0018\"\u001a-,\nand  \/\u0019\n\u00180\/0fi\nrepresent two operations\n\u0017\u0019\u0018\"\u001a-,\nand\n\u0017\u0019\u0018 \/0fi\nof job ffi . Their activations \u000e ffffifl\u0015$ $on and \u000e ffffifl\u0015$ ^qp represent the\nstart times  \n\u0018\"\u001a-,\nand  \n\u00180\/0fi\n. The SC-unit  Ka\n\u0018\"\u001a \/\nrepresents the\nsequence constraint of Eqn. (1) between \u0017\\\u0018ff\u001aO, and \u0017\u0019\u00180\/0fi , with\n\u0010\nffffi\u001fZ$\n$_^ being its bias. In Fig. 2, {\nffffifl\u0015$\n$Dn ( { ffffifl\u0015$ ^qp ) represents\n\u0000(\u0001\n\u0003(\u0004\n<>=\n?>@\n<>=\n?>@\nB\nB\nB\nB\nBDC\n\u0006 E\nE\nE\nE\nE\nF\nG\nGIH J\nJ K\nL\nM\nN\nO\nR,S\nT\u0001\u0000 T\u0003\u0002\nT\u0001\u0004\nT\u0003\u0005\n[\u0007\u0006!]\np $ $  ^\nR,SR,S `ba!ced\u0016j `ba\t\b_h j\nk\n\\2l\n$ $\u0016p\nk\n\\ml\n ^qp\nrs\\ml\n$ $_p\nrs\\ml\n ^qp\n\n\nt+jgczd\u000b\b\u0016h\nG\nGIH\nJ\nJ K\nE\nE\nE\nE\nE P\nB\nB\nB\nB\nB Q\nJ\nJ K\nG\nGIH\nFig. 3. A RC-block unit \fIx\u001ay\njgczd\r\b_h\n.\nthe initial value for  \n\u0018ff\u001aO, (  \u0018 \/0fi ) that is taken as the initial net\ninput to  \/\u0019\n\u0018ff\u001a-, (  \/\u0019 \u0018 \/0fi ). The weights and bias are valued as:\n\u0012 \u0006Z\u0001\nM\nW7\b#\u001243X\u0001 W7\b#\u0012\u000f\u000eX\u0001\nM\n\u0012 \b#\u0012\u000f\u0010X\u00010\u0012 \b#\u0010\/ff\u0016\u001f $ $_^\f\u0001\nM\n!\n\u0018\"\u001a-,\n(9)\nwhere\n\u0012\n, henceforth, is positive feedback adjustment factor.\nAt time I during the run of CSANN-II, if the sequence\nconstraint between\n\u0017\u0019\u0018\"\u001a-,\nand\n\u0017\u0019\u0018 \/0fi\nis satisfied, the activation\n\u000e ffffi\u001f\u0012$ $\u0016^\n?\nI\nB\nof  *a\n\u0018\"\u001a \/\nequals zero; otherwise, the activation of\n *a\n\u0018\"\u001a \/\nwill be greater than zero and can be calculated by\n\u000e\nffffi\u001f\u0012$\n$\u0016^\n?\nI\nB\n\u0001\nM\n\r\nffffi\u001fZ$\n$_^\n?\nI\nB\n\u0001\n\u000e\nff+fl\u0015$\n$Dn\n?\nI\nB A\n!\n\u0018\"\u001a-,dM \u000e\nffffifll$\n^qp\n?\nI\nB\n\u0001\n \n\u0018\"\u001a-,\n?\nI\nB A\n!\n\u0018ff\u001a-,\nM\n \n\u00180\/0fi\n?\nI\nB (10)\nThe feedback adjustments from  *a \u0018ff\u001a \/ to  \/\u0019 \u0018ff\u001aO, and  \/\u0019 \u00180\/0fi\nare shown as follows:\n\u000e\nff+fl\u0015$\n$Dn\n?\nI\nA\nW\nB\n\u0001\n \n\u0018\"\u001a-,Z?\nI\nA\nW\nB\n\u0001\n \n\u0018\"\u001a-, ?\nI\nB\fM\n\u0012\n\u0017\n\u000e\nffffi\u001fZ$\n$_^\n?\nI\nB (11)\n\u000e\nff+fl\u0015$\n^qp\n?\nI\nA\nW\nB\n\u0001\n \n\u0018 \/fffi\n?\nI\nA\nW\nB\n\u0001\n \n\u00180\/0fi\n?\nI\nB A\n\u0012\n\u0017\n\u000e\nffffi\u001fZ$\n$_^\n?\nI\nB (12)\nwhere the feedback adjustments put backward  \u0018\"\u001a-, of \u0017 \u0018ff\u001aO,\nand put forward  \n\u0018 \/0fi\nof\n\u0017\n\u00180\/0fi\n. Hence, the sequence constraint\nviolation between\n\u0017\n\u0018ff\u001a-,\nand\n\u0017\n\u00180\/0fi\nmay be solved.\nFig. 3 shows an example RC-block unit, 12a\n\u0010\nfi \u0018ff\u001a\nY\n\/\n, which\nrepresents the resource constraint of Eqn. (2) between \u0017 \u0018\"\u001a\u000efi\nand\n\u0017\nY\n\/0fi\non machine \u001f . At time I during the run of CSANN-\nII, the weights and bias are adaptively valued according to\nthe following two cases.\nCase 1: If\n\u000e\nffffifl\u0015$\n$\u0016p\n?\nI\nBN^ \u000e\nffffifl\n \n^qp\n?\nI\nB\n, i.e.,  \n\u0018ff\u001a\u000bfi\u0005?\nI\nBN^\n ZY\n\/0fi7?\nI\nB\n,\nEqn. (13) holds\n\u0012 \u0011\u0012\u0001\nM\nW7\b \u0012\u000f\u0013\u0012\u0001 W7\b \u0012\u000f\u0014X\u0001\nM\n\u0012 \b \u0012 \u0015Z\u00010\u0012 \b \u0010\n\"\n\u001f\np\n$\n$\n \n^\t\u0001\nM\n!\n\u0018\"\u001a\u000efi\n(13)\nIn this case 12a\n\u0010\nfiG\u0018\"\u001a\nY\n\/\nrepresents a sequence constraint\ndescribed by the first disjunctive equation of Eqn. (2). If\nviolation exists, the activation of 12a\nfiG\u0018\"\u001a\nY\n\/\nand feedback\nadjustments from 1\\a fiG\u0018\"\u001a Y \/ to  \/\u0019 \u0018ff\u001a\u000efi and  \u001a\u0019ZY \/0fi are calculated\nby\n\u000e,\"\n\u001fbp\n$\n$\n \n^\n?\nI\nB\n\u0001\n\u000e\nff+fl\n$\n$_p\n?\nI\nB A\n!\n\u0018\"\u001a\u000efi\nM \u000e\nffffifl\n \n^qp\n?\nI\nB\n\u0001\n \n\u0018ff\u001a\u000bfi\n?\nI\nB A\n!\n\u0018\"\u001a\u000efi\nM\n \nY\n\/0fi\n?\nI\nB (14)\n\u000e\nff+fl\u0015$\n$_p\n?\nI\nA\nW\nB\n\u0001\n \n\u0018ff\u001a\u000bfi=?\nI\nA\nW\nB\n\u0001\n\u000e\nff+fl\u0015$\n$_p\n?\nI\nB\fA\n\u0012 \u0014\n\u0017\n\u000e\n\"\n\u001f\np\n$\n$\n \n^\n?\nI\nB\n\u0001\n \n\u0018\"\u001a\u000efi7?\nI\nB M\n\u0012\n\u0017\n\u000e\n\"\n\u001f\np\n$\n$\n \n^\n?\nI\nB (15)\n\u000e ff+fl\n ^qp\n?\nI\nA\nW\nB\n\u0001\n ZY\n\/0fi\u0005?\nI\nA\nW\nB\n\u0001\n\u000e ffffifl\n ^qp\n?\nI\nB\fA\n\u0012 \u0015\n\u0017\n\u000e \"\n\u001f p $ $  ^\n?\nI\nB\n\u0001\n Y\n\/0fi ?\nI\nB A\n\u0012\n\u0017\n\u000e,\"\n\u001f p $ $  ^\n?\nI\nB (16)\nCase 2: If \u000e ff+fl\u0015$ $_p ? I\nB P \u000e ffffifl\n ^qp\n?\nI\nB\n, that is,  \n\u0018ff\u001a\u000efi\u0005?\nI\nB P\n ZY\n\/fffi\u0005?\nI\nB\n, Eqn. (17) holds\n\u0012 \u0011\u0012\u0001 W\u0005\b \u0012 \u0013\u0012\u0001\nM\nW\u0005\b.\u0012\u000f\u0014X\u0001 \u0012 \b \u0012\u000f\u0015X\u0001\nM\n\u0012\u0002\b \u0010\n\"\n\u001f p $ $  ^\u0015\u0001\nM\n!\u0012Y\n\/0fi\n(17)\nIn this case 12a\n\u0010\nfiG\u0018\"\u001a\nY\n\/\nrepresents a sequence constraint\ndescribed by the second disjunctive equation of Eqn. (2).\nIf there exists violation, the activation of 1\\a\nfiG\u0018\"\u001a\nY\n\/\nand the\nfeedback adjustments are calculated by\n\u000e,\"\n\u001f p $ $  ^\n?\nI\nB\n\u0001\n\u000e\nffffifl\n ^qp\n?\nI\nBUA\n! Y\n\/0fi M \u000e\nffffifl\u0015$ $\u0016p\n?\nI\nB\n\u0001\n Y\n\/0fi ?\nI\nB A\n! Y\n\/fffi M\n \n\u0018ff\u001a\u000efi ?\nI\nB (18)\n\u000e ffffifl\u0015$ $\u0016p\n?\nI\nA\nW\nB\n\u0001\n \n\u0018ff\u001a\u000efi'?\nI\nA\nW\nB\n\u0001\n\u000e ffffifl\u0015$ $\u0016p\n?\nI\nB\fA\n\u0012 \u0014\n\u0017\n\u000e \"\n\u001f p $ $  ^\n?\nI\nB\n\u0001\n \n\u0018\"\u001a\u000efi7?\nI\nB A\n\u0012\n\u0017\n\u000e \"\n\u001f p $ $  ^\n?\nI\nB (19)\n\u000e ffffifl\n ^qp\n?\nI\nA\nW\nB\n\u0001\n ZY\n\/fffi ?\nI\nA\nW\nB\n\u0001\n\u000e ffffifl\n ^qp\n?\nI\nBlA\n\u0012\u000f\u0015\n\u0017\n\u000e \"\n\u001f p $ $  ^\n?\nI\nB\n\u0001\n ZY\n\/fffi\u0005?\nI\nB M\n\u0012\n\u0017\n\u000e \"\n\u001f p $ $  ^\n?\nI\nB (20)\nThe architecture of CSANN-II consists of two layers. The\nbottom layer consists of only ST-units. The top layer consists\nof SC-units and RC-units that are connected to ST-units at\nthe bottom layer according to a specific JSP.\nC. Adaptive RC-Block Scheme\nCSANN-II uses an adaptive scheme to construct the RC-\nblock when it is running, as described below:\n1). Before each iteration of the RC-block, sort the ST-units\nrelated to each machine according to their activations,\ni.e., present start times of relevant operations to be\nprocessed on the machine, in a non-decreasing order;\n2). From the first to the last in the ordered ST-unit list,\nconstruct one RC-block unit for two adjacent ST-units.\nThis results in \u0000\nM\nW\nRC-block units for each machine.\nWith the above adaptive scheme, for a traditional JSP with\n\u0001 machines and \u0000 jobs where each job passes trough all\nmachines in certain order, the number of RC-block units is\nreduced to \u0000\nM\nW\nfor each machine instead of \u0000\n?\n\u0000\nM\nW\nB\u0017\u0016\u0019\u0018\nin the original CSANN. Totally, CSANN-II requires \u0001 \u0000 ST-\nunits, \u0000\n?\n\u0001\nM\nW\nB\nSC-units, and \u0001\n?\n\u0000\nM\nW\nB\nRC-units, which\ngives a total number of \u001a \u0001 \u0000\nM\n\u0001\nM\n\u0000 neurons in the order\nof\n\u0017 ?\n\u0001\n\u0000\nB\n, while CSANN consists of \u0000\n?\n9fiffffifl\n\u0001\n\u0000\nA\nW\nff fl\n\u0001\nM\nW\nB\nneurons in the order of\n\u0017 ?\n\u0001\n\u0000\n3\nB\n. Hence, CSANN-II achieves\na deduction of magnitude \u0000 with respect to the network\ncomplexity.\nGiven a problem-specific CSANN-II, it is run iteratively:\nfirst run SC-block units and then RC-block units in a fixed\norder until the activations of all SC-units and RC-units\nequal zero. The final activations of ST-units form a feasible\nschedule. For each iteration, CSANN-II needs to sort the\nST-units for each machine, which can be done in\n\u0017 ?\n\u0000 \u001f\"!\t# \u0000\nB\ntime by the quick sort algorithm. It also needs calculating\n\u0000\n?\n\u0001\nM\nW\nB\nSC-unit and \u0001\n?\n\u0000\nM\nW\nB\nRC-units, resulting in a\ncomputational complexity of\n\u0017 ?\n\u0001\n\u0000 \u001f$!\u0019# \u0000\nB\nfor each iteration.\nIn contrast, CSANN requires \u0000\n?\n\u0001\nM\nW\nB\nSC-unit and \u0001 \u0000\n?\n\u0000\nM\nW\nB \u0016 \u0018\nRC-unit calculations, totally in the order of\n\u0017 ?\n\u0001\n\u0000\n3\nB\n.\nHence, computationally CSANN-II achieves a deduction of\n\u0017 ?\n\u0000\n\u0016\n\u001f\"!\t# \u0000\nB\nover CSANN for each iteration.\nD. Combined Heuristic Algorithms for CSANN-II\nSeveral heuristics have been devised and combined into\nCSANN-II to guarantee its convergence, accelerate its solv-\ning speed, and improve the quality of solutions. They are\ndescribed as follows.\n1) Swapping the order of adjacent operations: This\nheuristics has two aspects: to accelerate the solving process\nand to guarantee obtaining feasible solution [13], [14]. The\nformer, called Heuristic Alg. 1(a), is for two adjacent op-\nerations of the same job, while the latter, called Heuristic\nAlg. 1(b), is for two adjacent operations on the same ma-\nchine.\nFor Heuristic Alg. 1(a), assuming R \u0017+\u0018\"\u001a-, \b \u0017\u0019\u0018 \/fffiJS T  * \u0018 , at\ntime I during the running of neural networks, if\n\u000e ffffifll$ $Dn\n?\nI\nB P\n\u000e ffffifl\u0015$ ^qp\n?\nI\nB (i. e.,  \u0018ff\u001aO,Z? I B4P  \u0018 \/0fi\u0005? I B ), exchange the order of\n\u0017 \u0018ff\u001a-,\nand\n\u0017 \u0018 \/0fi\nby exchanging their start times as follows:\n\u000e\nffffifl $ $on\n?\nI\nA\nW\nB\n\u0001\n \n\u0018ff\u001a-, ?\nI\nA\nW\nB\n\u0001\n \n\u00180\/0fi ?\nI\nB (21)\n\u000e\nffffifl\u0015$\n^qp\n?\nI\nA\nW\nB\n\u0001\n \n\u00180\/0fi7?\nI\nA\nW\nB\n\u0001\n \n\u0018\"\u001a-,Z?\nI\nB (22)\nIn fact, Eqns. (21) and (22) form a more direct method of\nremoving sequence constraint violations than the feedback\nadjustment scheme in CSANN-II. Thus, the adjustment time\nfor removing sequence constraint violations is shortened and\nthe solving process is speeded up.\nDuring the running of CSANNs, due to conflicts resulting\nfrom sequence constraint and resource constraint violation\nfeedback adjustments, the phenomenon of dead lock may\nhappen2. Dead lock will stop CSANNs from obtaining a\nfeasible solution. Heuristic Alg. 1(b) was proposed to break\ndead lock (and hence guarantee obtaining feasible schedules)\nby exchanging the order of two adjacent operations on the\nsame machine via exchanging their start times. Heuristic\nAlg. 1(b) works as follows.\nFor each RC-block unit 12a \u0010\nfiG\u0018\"\u001a\nY\n\/\n, a variable \u0019\nfi \u0018ff\u001a\nY\n\/O?\nI\nB\nis\ndefined to count the number of continuous and similar feed-\nback adjustments, accumulated over iterations, from 1\\a fiG\u0018\"\u001a Y \/\nto  \/\u0019\n\u0018\"\u001a\u000efi\nand  \/\u0019ZY\n\/0fi\ndue to the resource constraint viola-\ntion between\n\u0017+\u0018ff\u001a\u000efi\nand\n\u0017\nY\n\/0fi\non machine \u001f . Two feedback\nadjustments are called similar if they have the same effect\non  \/\u0019\n\u0018\"\u001a\u000efi\nand  \/\u0019ZY\n\/0fi\n, e.g., both pushing  \n\u0018\"\u001a\u000efi\nforward and\n ZY\n\/0fi\nbackward. Whenever the resource constraint between\n\u0017\n\u0018ff\u001a\u000efi\nand\n\u0017\nY\n\/0fi\nis satisfied or a different feedback adjustment\noccurs within 1\\a\n\u0010\nfiG\u0018\"\u001a\nY\n\/\n, \u0019\nfi \u0018ff\u001a\nY\n\/\n?\nI\nB\nwill be reset to zero.\nHowever, during the running of CSANNs, if dead lock\nhappens \u0019\nfiG\u0018\"\u001a\nY\n\/\n?\nI\nB\nwill keep increasing over iterations of\nCSANNs. And when \u0019\nfiG\u0018\"\u001a\nY\n\/\n?\nI\nB\nreaches a threshold parameter\n\u0019 , the equations below will swap the order of\n\u0017+\u0018\"\u001a\u000efi\nand\n\u0017\nY\n\/0fi\nby swapping their start times.\n\u000e\nffffifl\u0015$\n$\u0016p\n?\nI\nA\nW\nB\n\u0001\n \n\u0018\"\u001a\u000efi ?\nI\nA\nW\nB\n\u0001\n ZY\n\/0fi\u0005?\nI\nB (23)\n2See [13] for more detailed explanation on the reason to dead lock.\n\u000e ffffifl\n ^qp\n?\nI\nA\nW\nB\n\u0001\n ZY\n\/fffi\u0005?\nI\nA\nW\nB\n\u0001\n \n\u0018\"\u001a\u000efi\u0005?\nI\nB (24)\n2) Obtaining a proper expected makespan adaptively: For\na JSP without due date constraints, before running CSANN-\nII, an expected makespan is prescribed, which is what the\nscheduler wants to achieve and can be used as the common\ndue date of all jobs. The value of expected makespan affects\nthe performance of CSANN-II greatly: if set too loose, the\nquality of obtained schedules will be low, while set too\ntight, it will take CSANN-II too long to obtain a schedule.\nThis qualifies the importance of selecting a proper expected\nmakespan for CSANN-II to run.\nIn [15], an adaptive scheme was proposed to obtain a\nproper expected makespan by adding a preprocessing stage,\nwhich is denoted Heuristic Alg. 2 in this paper. Let\n\u000f\n!\ndenote the total processing time of all operations and\n\u000f\n\u0017\ntotal number of operations (e.g., \u000f \u0017 \u0001 \u0001 \u0000 ). Heuristic\nAlg. 2 is shown as follows:\n1) Set the initial expected makespan 8`\u0013 ? 9 B \u0001 9fiffffifl \u0017\n\u000f\n! ;\n2) Run CSANN-II for \u0001 times and compute the mean\niterations\n\u0002\n{\n\u0001\n\u000f\n{\n\u0016\n\u0001 that CSANN-II uses to obtain a\nschedule;\n3) If \u0002{ j\u0004\u0003 \u0017 \u000f \u0017 , 8k\u0013 ? fl A W B \u0001 8`\u0013 ? fl BZM 9fiff 9 W \u0017 \u000f !\nand go to step 2; Otherwise, stop the preprocess-\ning stage and return 8k\u0013\n?\nfl\nB\nas the final expected\nmakespan.\nwhere in step 3, \u0001 and\n\u0003\nare parameters for the preprocessing\nstage. The aim of Heuristic Alg. 2 is to obtain a proper ex-\npected makespan that makes the average iterations CSANNs\nrequire for a schedule to be linear with respect to\n\u000f\n\u0017\n.\n3) Improving the quality of schedules: The feasible sched-\nules obtained by CSANNs are usually inadmissible, which\ncan be improved by deleting machine idle times. In [15],\nan algorithm, henceforth called Heuristic Alg. 3, is used to\nobtain an active schedule from the one obtained by CSANNs\nas follows:\n1) Given a feasible schedule obtained by CSANN-II, sort\nall operations in the non-decreasing order of their start\ntimes.\n2) From the first to the last in the ordered operation\nlist, each operation is moved forward to its earliest\npossible start time by first carrying out global left-shift\n(if possible) and then local left-shift.\nIV. CSANN-II AND LOCAL SEARCH HYBRID APPROACH\nA. Local Search Mechanism\nLocal search mechanisms have proved helpful for improv-\ning the performance of many optimization algorithms. The\nbasic principle of local search mechanisms is as follows:\npick a (possibly bad) feasible solution, change it a little bit\n(usually according to a defined neighbourhood), and check\nwhether a better solution is obtained. If so, the algorithm\nmoves to this new solution; otherwise, just make another\nchange to the old solution. The procedure continues until\nsome termination condition becomes true, e.g., the maximum\nnumber of changes without improvement has reached.\nThe local search mechanism can be integrated into\nCSANNs for better performance. The idea is described as fol-\nlows. From a feasible schedule obtained by CSANN-II, find\nthe last job on each machine and swap it with one randomly\nselected different job on the machine by exchanging their\nstart times. Then, run CSANN-II from the resulting (possibly\ninfeasible) schedule to obtain a new feasible schedule. If the\nnew schedule is better, the local search moves to this new\nschedule; otherwise, the local search continues from the old\nsolution. This progress continues until a pre-set maximum\nnumber of local searches have been done.\nHere, one problem lies in that if we use the schedule\nobtained by CSANN-II directly as the base for local search,\nit may take a long time to run CSANN-II for a new\nschedule because the original schedule is quite tight. To solve\nthis problem, we propose a schedule relaxing technique to\nobtain a quite relaxed schedule from a schedule obtained\nby CSANN-II. Then, local search is carried out from the\nrelaxed schedule instead. The schedule relaxing technique is\ndescribed below.\nB. Schedule Relaxing Technique\nGiven a feasible schedule obtained by CSANN-II, a re-\nlaxed schedule can be obtained in the follow steps:\n1) Calculate the distance between the expected makespan\nand the makespan of the given schedule. Let \u0000 denote\nthe distance.\n2) Find a critical path in the schedule and let \u0000 denote\nthe number of critical operations in the critical path\nand ) \u0001 \u0000\n\u0016]?\n\u0000\nM\nW\nB\ndenote the relax distance.\n3) Sort all operations in the schedule in the non-\ndecreasing order of their start times.\n4) Transverse from the first to the last in the ordered\noperation list and postpone the start time of operations\nas follows: when we meet an operation with its start\ntime larger than the start time of the ffi th critical\noperation but smaller than the start time of the ffi\nA\nW\nth\ncritical operation in the critical path, its start time is\nright shifted by ffi\u0002\u0001 ) units of time.\nFig. 4 shows an example schedule relaxing on a JSP with\nthree machine and three jobs. The original schedule is a tight\nactive schedule with the unique critical path consisting of\nfour critical operations. In the relaxed schedule, the critical\npath is lengthened by \u0000 with a gap of ) inserted between\ntwo original critical operations Other non-critical operations\nare also postponed accordingly.\nC. Framework of the Hybrid Approach for JSPs\nThe hybrid approach consists of CSANN-II and the pro-\nposed local search mechanism, denoted CSANN-LS in this\npaper. In practice, the hybrid approach is executed a number\nof times to obtain schedules and the best schedule will be\nused as the final schedule. The running strategy is shown as\nfollows:\n1). Construct a CSANN-II for a specific JSP, set values for\n\u0012\n, \u0019 ,\n\u0001\n,\n\u0003\n, and the maximum number of schedules\n\u0013 9\u0010;X _H\u0004\u0003Z6l) to be calculated;\nMakespan\nM3\nM2\nM1\n0\nMakespan\nCritical Path with Four Critical Operations\nExpected\n(a)\nMakespan\nM3\nM2\nM1\n0 Expected\nMakespan\nRelax Distance, d\n(b)\nFig. 4. Illustrating a relaxing operation: (a) before and (b) after.\n2). Perform the pre-processing stage with Heuristic Alg. 2\nto obtain a proper expected makespan;\n3). Run CSANN-II for one schedule with the above ob-\ntained expected makespan;\n4). Create a relaxed schedule from the schedule obtained\nby CSANN-II;\n5). Perform a local search from the relaxed schedule;\n6). If the maximum number of schedules, \u0013 9\u0010;\u0012 *H\u0004\u0003 6\u0015) , is\nreached, stop; otherwise, go to step 4.\nThe procedure of running CSANN-II for one feasible\nschedule is shown as follows:\n1). Randomly initialize  \u0018ff\u001aO, ? 9 B or set  \u0018ff\u001a-, ? 9 B according\nto a given schedule for each operation\n\u0017\n\u0018ff\u001a-,\n, and take\nit as the initial input {\nffffifl\n$\n$on\nto ST-unit  \/\u0019\n\u0018\"\u001a-,\n;\n2). Run each SC-unit  *a \u0018\"\u001a \/ of the SC-block: calculate its\nactivation with Eqn. (10). If \u000e ffffi\u001f\u0012$ $\u0016^ ? I B\u0006\u0005\u0001 9 , it means\nthe violation of related sequence constraint, then adjust\nactivations of related ST-units with Eqns. (11) and\n(12) or Eqns. (21) and (22) if Heuristic Alg. 1(a) is\ntriggered;\n3). Construct the RC-block adaptively;\n4). Run each RC-unit 1\\a fi \u0018ff\u001a Y \/ of the RC-block, calculate\nits activation with Eqn. (14) or Eqn. (18). \u000e \" \u001f p $ $  ^ ? I B\u0007\u0005\u0001\n9 means the violation of resource constraint corre-\nsponding to Eqn. (2). Then adjust \u000e ffffifll$ $_p ? I A W B and\n\u000e\nffffifl\n \n^qp\n?\nI\nA\nW\nB\nwith Eqns. (15) and (16) or Eqns. (19) and\n(20), or with Eqns. (23) and (24) if Heuristic Alg. 1(b)\nis triggered;\n5). Repeat step 2 to 4 until all neurons become stable with-\nout changes, i.e., all sequence and resource constraints\nare satisfied and an feasible schedule is obtained;\n6). Use Heuristic Alg. 3 to obtain an active schedule from\nthe feasible schedule obtained by CSANN-II.\nV. EXPERIMENTAL STUDY\nA. Experimental Setting\nThe experimental study was finished on a 2.8GHz Intel\nPentium 4 PC under GNU C++ programming environment.\nThe benchmark problems, Muth and Thompson\u2019s FT06,\nFT10 and FT20 JSPs [11], were taken as the test problems\nto compare the performance of CSANN-LS, CSANN-II, GT-\nRandom and GT-Rule. The parameters for CSANNs are set\nas:\n\u0012h\u0001\n9 ff fl , \u0019\n\u0001\nfl ,\n\u0001\n\u0001 W\n9 and\n\u0003\n\u0001\n\u0018\n.\nFor each run of an algorithm on a test JSP,\nW\n9\n\u0011\nschedules3\nwere calculated with the intermediate best-so-far schedule\nrecorded every 100 schedule. And for each run the final best\nschedule and time used were also recorded. In order to avoid\nthe effect a random seed may have, 50 runs with different\nrandom seeds were carried out for each algorithm on each\ntest problem and the mean results over 50 runs are reported.\nB. Experimental Results and Analysis\nThe experimental results regarding makespan of final best\nschedule and time used in second are given in Table II,\nwhere Min\/Ave\/Std means minimum, average and standard\ndeviation over 50 runs of algorithms respectively. Statistical\ncomparison of algorithms by one-tailed I -test is also given in\nTable II, where the I -test values shown in bold font are signif-\nicant with 98 degrees of freedom at a 0.05 significance level.\nThe experimental results regarding best-so-far makespan of\nalgorithms against schedules are plotted in Fig. 5, where the\ndata was averaged over 50 runs.\nTABLE II\nEXPERIMENTAL RESULTS OF COMPARING METHODS.\nMeasure Algorithm FT06 FT10 FT20\nMakespan CSANN-LS 55\/55\/0.0 971\/999\/16.1 1221\/1269\/25.8\n(Min\/Ave\/Std) CSANN-II 55\/55\/0.0 982\/1009\/9.9 1292\/1334\/12.7\nGT-Random 55\/56.2\/0.8 1048\/1102\/17.9 1336\/1383\/16.7\nGT-Rule 55\/56.8\/0.8 1073\/1116\/15.7 1333\/1379\/17.4\nTime Used CSANN-LS 16\/78.3\/105.5 68\/675\/916.2 49\/100\/61.5\nin Seconds CSANN-II 31\/129\/166.5 222\/753\/607.1 820\/941\/168.6\n(Min\/Ave\/Std) GT-Random 4\/4.3\/0.46 16\/16.9\/0.56 33\/34.2\/1.0\nGT-Rule 4\/4.6\/0.49 17\/18.0\/0.45 35\/38.9\/3.9\nt-Test Results Regarding Markspan\nCSANN-LS \u2013 CSANN-II 0.0 -3.82 -15.89\nCSANN-LS \u2013 GT-Random -10.43 -30.35 -26.07\nCSANN-LS \u2013 GT-Rule -15.92 -36.78 -24.95\nt-Test Results Regarding Time Used\nCSANN-LS \u2013 CSANN-II -1.83 -0.5 -33.14\nCSANN-LS \u2013 GT-Random 4.96 5.08 7.59\nCSANN-LS \u2013 GT-Rule 4.94 5.07 7.03\nFrom Table II and Fig. 5, it can be seen that CSANN-\nLS significantly outperforms CSANN-II regarding both the\nquality of obtained schedules on FT10 and FT20 and the\nsolving speed on all test JSPs. CSANN-LS also significantly\noutperforms GT-Random and GT-Rule with respect to the\n3For CSANNs the schedules calculated during the preprocessing stage\nwere also counted into the total \u0000\u0002\u0001\n\u0000\nschedules.\n 54\n 56\n 58\n 60\n 62\n 64\n10008006004002000\nM\nea\nn \nBe\nst-\nSo\n-F\nar\n M\nak\nes\npa\nn\nNo. of Schedules ( x 100 )\nCSANN-LS\nCSANN-II\nGT-Random\nGT-Rule\n(a)\n 950\n 1000\n 1050\n 1100\n 1150\n 1200\n 1250\n10008006004002000\nM\nea\nn \nBe\nst-\nSo\n-F\nar\n M\nak\nes\npa\nn\nNo. of Schedules ( x 100 )\nCSANN-LS\nCSANN-II\nGT-Random\nGT-Rule\n(b)\n 1250\n 1300\n 1350\n 1400\n 1450\n 1500\n 1550\n10008006004002000\nM\nea\nn \nBe\nst-\nSo\n-F\nar\n M\nak\nes\npa\nn\nNo. of Schedules ( x 100 )\nCSANN-LS\nCSANN-II\nGT-Random\nGT-Rule\n(c)\nFig. 5. Test results on (a) FT06, (b) FT10 and (c) FT20.\nquality of obtained schedules on all test JSPs but spends\nsignificantly more computational time.\nFrom Fig. 5, it can be seen that on FT06 both CSANN-\nII and CSANN-LS reach the optimum makespan 55 very\nquickly while both GT-Random and GT-Rule fail to achieve\nthe optimum within\nW\n9\n\u0011\nschedules. On FT10, CSANN-LS\nperform better than CSANN-II and on FT20, CSANN-LS\nclears wins over CSANN-II. On all the three problems,\nCSANN-II and CSANN-LS outperform GT-Random and GT-\nRule clearly with respect to the best-so-far makespan against\nschedules tried.\nIn order to carry out a fairer comparison between the\nalgorithms in terms of the computational time, further ex-\nperiments were carried out to run the algorithms on the test\nJSPs for certain fixed time. For each run, the algorithms are\ngiven a maximum of 60, 300, and 600 seconds on FT06,\nFT10, and FT20 respectively. The results regarding the final\nTABLE III\nEXPERIMENTAL RESULTS OF COMPARING ALGORITHMS WITH THE\nMAXIMUM ALLOWABLE RUN TIME SET TO 60, 300, AND 600 SECONDS\nFOR FT06, FT10, AND FT20 RESPECTIVELY.\nMakespan (Min\/Ave\/Std)\nAlgorithm FT06 FT10 FT20\nCSANN-LS 55\/55.04\/0.3 971\/999\/12.8 1201\/1250\/19.6\nCSANN-II 55\/55\/0.0 982\/1012\/11.3 1292\/1337\/13.1\nGT-Random 55\/55.1\/0.3 1017\/1075\/13.5 1325\/1351\/11.8\nGT-Rule 55\/55.4\/0.6 1060\/1087\/11.2 1325\/1350\/12.8\nt-Test Result\nCSANN-LS \u2013 CSANN-II 1.0 -5.43 -26.26\nCSANN-LS \u2013 GT-Random -1.02 -29.06 -31.23\nCSANN-LS \u2013 GT-Rule -7.89 -36.87 -30.31\nmakespan, also averaged over 50 runs, are shown in Table III.\nFrom Table III it can been seen CSANN-LS still significantly\noutperforms CSANN-II, GT-Random and GT-Rule on nearly\nall test JSPs.\nVI. CONCLUSIONS AND FUTURE WORK\nThis paper proposes a local search scheme for the im-\nproved adaptive neural network, CSANN-II. In the hybrid\napproach CSANN-LS, CSANN-II together with some heuris-\ntics is used to obtain feasible schedules for JSPs while the\nlocal search scheme is used to iterate the obtained schedules\nfor better schedules. The schedule relaxing technique helps\nshorten the run time for CSANN-II to obtain a new sched-\nule from a possibly infeasible schedule that has just been\nchanged by the local search scheme.\nFor JSPs on the selected benchmark problems, experi-\nmental study shows that CSANN-LS yields higher quality\nsolutions than CSANN-II and the two classical Giffler and\nThompson\u2019s heuristic algorithms. CSANN-II is also much\nfaster in computing speed than CSANN-II, roughly by a\nfactor of 2 to 15, but CSANN-LS is 2 to 4 times slower\nthan the two classical approaches to find a fixed number of\nsolutions for the benchmark JSPs. When the solving time\nis fixed, both CSANN-II and CSANN-LS can find higher\nquality solutions than the two classical approaches.\nCSANN-II can act as a good base for constructing further\nhybrid systems for JSPs and other production scheduling\nproblems. It is noticeable that many other advanced intelli-\ngent methods for JSPs, e.g., hybrid genetic algorithms [4], are\nin fact based on the Giffler and Thompson\u2019s heuristics. We\nbelieve integrating CSANN-II into those advanced intelligent\nmethods to replace the Giffler and Thompson\u2019s heuristics will\nfurther improve the performance for JSPs. This work is now\nunder investigation.\nREFERENCES\n[1] K. R. Baker, Introduction to Sequence and Scheduling, New York: John\nWiley & Sons, 1974.\n[2] C. Bierwirth and D. Mattfeld, \u201cProduction scheduling and rescheduling\nwith genetic algorithms,\u201d Evolutionary Computation, Vol. 7, No. 1,\npp. 1\u201317, 1999.\n[3] J. Blackstone, D. Phillips, and G. Hogg, \u201cA state-of-the-art survey of\ndispatching rules for manufacturing job shop operations,\u201d International\nJournal of Production Researches, Vol. 20, pp. 27\u201345, 1982.\n[4] R. Cheng, M. Gen and Y. Tsujimura, \u201cA tutorial survey of job-shop\nscheduling problems using genetic algorithms, Part II: Hybrid genetic\nsearch strategies,\u201d Computers and Industrial Engineering, Vol. 36,\npp. 343\u2013364, 1999.\n[5] D. Dubois, H. Fargier and H. Prade, \u201cFuzzy constraints in job-shop\nscheduling,\u201d Journal of Intelligent Manufacturing, Vol. 6, pp. 215\u2013234,\n1995.\n[6] S. Y. Foo and Y. Takefuji, \u201cNeural networks for solving job-shop\nscheduling: Part 1. Problem representation,\u201d Proc. IEEE IJCNN, Vol. II,\npp. 275\u2013282, 1988.\n[7] S. Y. Foo and Y. Takefuji, \u201cStochastic neural networks for solving\njob-shop scheduling: Part 2. Architecture and simulations,\u201d Proc. IEEE\nIJCNN, Vol. II, pp. 283\u2013290, 1988.\n[8] M. S. Fox and M. Zweben, Knowledge-based Scheduling, San Manteo,\nCA: Morgan Kaufmann Publishers, 1993.\n[9] B. Giffler and G. Thompson, \u201cAlgorithms for solving production\nscheduling problems,\u201d Operations Research, Vol. 8, pp. 487\u2013503, 1960.\n[10] R. Haupt, \u201cA survey of priority-rule based scheduling problem,\u201d OR\nSpektrum, Vol. 11, pp. 3\u201316, 1989.\n[11] J. F. Muth and G. L. Thompson, Industrial Scheduling, Prentice Hall,\nEnglewood Cliffs, NJ, 1963.\n[12] T. M. Willems, \u201cNeural networks for job-shop scheduling,\u201d Control\nEngineering Practice, Vol. 2, No. 1, pp. 31\u201339, 1994.\n[13] S. Yang and D. Wang, \u201cConstraint satisfaction adaptive neural network\nand heuristics combined approaches for generalized job-shop schedul-\ning,\u201d IEEE Trans. on Neural Networks, Vol. 11, No. 2, pp. 474\u2013486,\n2000.\n[14] S. Yang and D. Wang, \u201cA new adaptive neural network and heuristics\nhybrid approach for job-shop scheduling,\u201d Compters & Operations\nResearch, Vol. 28, No. 11, pp. 955\u2013971, 2001.\n[15] S. Yang, \u201cAn improved adaptive neural network for job-shop schedul-\ning,\u201d Proc. of IEEE 2005 Int. Conf. on Systems, Man and Cybernetics,\nVol. 2, pp. 1200\u20131205, 2005.\n[16] H.-B. Yu, Research of intelligent production scheduling methods and\ntheir applications, PhD Thesis, Northeastern University, China, 1997.\n"}
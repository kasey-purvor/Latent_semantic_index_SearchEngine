{"doi":"10.1109\/PERCOM.2007.33","coreId":"91446","oai":"oai:eprints.lancs.ac.uk:12951","identifiers":["oai:eprints.lancs.ac.uk:12951","10.1109\/PERCOM.2007.33"],"title":"Structural Learning of Activities from Sparse Datasets","authors":["Albinali, Fahd","Davies, Nigel","Friday, Adrian"],"enrichments":{"references":[{"id":16520676,"title":"A living laboratory for the design and evaluation of ubiquitous computing technologies. In: CHI \u201905: CHI \u201905 extended abstracts on Human factors in computing systems,","authors":[],"date":"2005","doi":null,"raw":"Intille, S.S., Larson, K., Beaudin, J.S., Nawyn, J., Tapia, E.M., Kaushik, P.: A living laboratory for the design and evaluation of ubiquitous computing technologies. In: CHI \u201905: CHI \u201905 extended abstracts on Human factors in computing systems, New York, NY, USA, ACM Press (2005) 1941\u20131944","cites":null},{"id":16520662,"title":"A rule-based approach to the analysis of elders activity data: Detection of health and possible emergency conditions. AAAI Fall","authors":[],"date":"2005","doi":null,"raw":"Dalal, S., Alwan, M., Seifra\ufb01, R., Kell, S., Brown, D.: A rule-based approach to the analysis of elders activity data: Detection of health and possible emergency conditions. AAAI Fall 2005 Symposium (2005)","cites":null},{"id":16520663,"title":"A.: Objective remote assessment of activities of daily living: Analysis of meal preparaion patterns. Poster Presentation","authors":[],"date":"2002","doi":null,"raw":"Barger, T., Alwan, M., Kell, S., Turner, B., Wood, S., Naidu, A.: Objective remote assessment of activities of daily living: Analysis of meal preparaion patterns. Poster Presentation (2002) Medical Automation Research Center, University of Virginia Health System.","cites":null},{"id":16520658,"title":"Activity recognition in the home setting using simple and ubiquitous sensors.","authors":[],"date":"2004","doi":null,"raw":"Tapia, E., Intille, S., Larson, K.: Activity recognition in the home setting using simple and ubiquitous sensors. LNCS Springer-Verlag 3001 (2004)","cites":null},{"id":16520661,"title":"An intelligent fuzzy agent approach for realising ambient intelligence in intelligent inhabited environments.","authors":[],"date":"2005","doi":null,"raw":"Doctor, F., Hagras, H., Callaghan, V.: An intelligent fuzzy agent approach for realising ambient intelligence in intelligent inhabited environments. IEEE Trans. On Systems, Man and Cybernetics 35(1) (2005) 55\u201365","cites":null},{"id":16520675,"title":"E.: A bayesian method for the induction of probabilistic networks from data.","authors":[],"date":"1992","doi":null,"raw":"Cooper, G.F., Herskovits, E.: A bayesian method for the induction of probabilistic networks from data. Machine Learning 09(4) (1992) 309\u2013347","cites":null},{"id":16520671,"title":"Graphical models, causality and intervention","authors":[],"date":"1993","doi":null,"raw":"Pearl, J.: Graphical models, causality and intervention (1993)","cites":null},{"id":16520667,"title":"Human Action: A Treatise on Economics. Fox & Wilkes","authors":[],"date":"1966","doi":null,"raw":"Mises, L.: Human Action: A Treatise on Economics. Fox & Wilkes (1966)","cites":null},{"id":16520659,"title":"Inferring activities from interactions with objects.","authors":[],"date":"2004","doi":null,"raw":"Philipose, M., Fishkin, K.P., Perkowitz, M., Patterson, D.J., Fox, D., Kautz, H., Hahnel, D.: Inferring activities from interactions with objects. IEEE Pervasive Computing 3(4) (2004) 50\u201357","cites":null},{"id":16520660,"title":"Layered representations for recognizing o\ufb03ce activity.","authors":[],"date":"2002","doi":null,"raw":"Oliver, N., Horvitz, E., Garg, A.: Layered representations for recognizing o\ufb03ce activity. The Fourth IEEE International Conference on Multimodal Interaction (2002) 3\u201384. Mozer, M.C.: The neural network house: An environment that adapts to its inhabitants. AAAI Spring Symposium (1998) 110\u2013114","cites":null},{"id":16520673,"title":"Learning bayesian networks is np-complete","authors":[],"date":"1995","doi":null,"raw":"Chickering, D.: Learning bayesian networks is np-complete (1995)","cites":null},{"id":16520665,"title":"M.G.: Towards understanding daily life via auto-identi\ufb01cation and statistical analysis. UbiHealth Workshop. UbiComp","authors":[],"date":"2003","doi":null,"raw":"Philipose, M., Fishkin, K., Fox, D., Kautz, H., Patterson, D., Perkowitz, M.G.: Towards understanding daily life via auto-identi\ufb01cation and statistical analysis. UbiHealth Workshop. UbiComp (2003)","cites":null},{"id":16520669,"title":"Using a live-in laboratory for ubiquitous computing research.","authors":[],"date":"2006","doi":null,"raw":"Intille, S., Larson, K., Tapia, E., Beaudin, J., Kaushik, J.: Using a live-in laboratory for ubiquitous computing research. LNCS Springer-Verlag (2006)","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2007","abstract":"A major challenge in pervasive computing is to learn activity patterns, such as bathing and cleaning from sensor data. Typical sensor deployments generate sparse datasets with thousands of sensor readings and a few instances of activities. The imbalance between the number of features (i.e. sensors) and the classification targets (i.e. activities) complicates the learning process. In this paper, we propose a novel framework for discovering relationships between sensor signals and observed human activities from sparse datasets. The framework builds on the use of Bayesian networks for modeling activities by representing statistical dependencies between sensors. We optimize learning Bayesian networks of activities in 3 ways. Firstly, we perform multicollinearity analysis to focus on orthogonal sensor data with minimal redundancy. Secondly, we propose Efron's bootstrapping to generate large training sets that capture important features of an activity. Finally, we find the best Bayesian network that explains our data using a heuristic search that is insensitive to the exact ordering between variables. We evaluate our proposed approach using a publicly available data set gathered from MIT's PlaceLab. The inferred networks correctly identify activities for 85% of the time","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/91446.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/12951\/1\/albinali%2Dsparsedatasets%2Dpercom2007%2Dpreprint.pdf","pdfHashValue":"88edb8e3d197f3822ecf7d3a1a4c0162a3aa5b57","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:12951<\/identifier><datestamp>\n      2017-09-21T01:33:43Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Structural Learning of Activities from Sparse Datasets<\/dc:title><dc:creator>\n        Albinali, Fahd<\/dc:creator><dc:creator>\n        Davies, Nigel<\/dc:creator><dc:creator>\n        Friday, Adrian<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        A major challenge in pervasive computing is to learn activity patterns, such as bathing and cleaning from sensor data. Typical sensor deployments generate sparse datasets with thousands of sensor readings and a few instances of activities. The imbalance between the number of features (i.e. sensors) and the classification targets (i.e. activities) complicates the learning process. In this paper, we propose a novel framework for discovering relationships between sensor signals and observed human activities from sparse datasets. The framework builds on the use of Bayesian networks for modeling activities by representing statistical dependencies between sensors. We optimize learning Bayesian networks of activities in 3 ways. Firstly, we perform multicollinearity analysis to focus on orthogonal sensor data with minimal redundancy. Secondly, we propose Efron's bootstrapping to generate large training sets that capture important features of an activity. Finally, we find the best Bayesian network that explains our data using a heuristic search that is insensitive to the exact ordering between variables. We evaluate our proposed approach using a publicly available data set gathered from MIT's PlaceLab. The inferred networks correctly identify activities for 85% of the time.<\/dc:description><dc:date>\n        2007<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/12951\/1\/albinali%2Dsparsedatasets%2Dpercom2007%2Dpreprint.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/PERCOM.2007.33<\/dc:relation><dc:identifier>\n        Albinali, Fahd and Davies, Nigel and Friday, Adrian (2007) Structural Learning of Activities from Sparse Datasets. In: Pervasive Computing and Communications, 2007. PerCom '07. Fifth Annual IEEE International Conference on. , pp. 221-228.<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/12951\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/PERCOM.2007.33","http:\/\/eprints.lancs.ac.uk\/12951\/"],"year":2007,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"Structural Learning of Activities from Sparse\nDatasets\nFahd Albinali1, Nigel Davies1,2, and Adrian Friday1\n1 University of Arizona, Tucson AZ 85704, USA,\nalbinali@cs.arizona.edu\n2 Lancaster University, Lancaster LA1 1WB UK,\n{nigel,adrian}@comp.lancs.ac.uk\nAbstract. A major challenge in pervasive computing is to learn activ-\nity patterns, such as bathing and cleaning from sensor data. Typical\nsensor deployments generate sparse datasets with thousands of sensor\nreadings and a few instances of activities. The imbalance between the\nnumber of features (i.e. sensors) and the classification targets (i.e. ac-\ntivities) complicates the learning process. In this paper, we propose a\nnovel framework for discovering relationships between sensor signals and\nobserved human activities from sparse datasets. The framework builds\non the use of Bayesian networks for modeling activities by representing\nstatistical dependencies between sensors. We optimize learning Bayesian\nnetworks of activities in 3 ways. Firstly, we perform multicollinearity\nanalysis to focus on orthogonal sensor data with minimal redundancy.\nSecondly, we propose Efron\u2019s bootstrapping to generate large training\nsets that capture important features of an activity. Finally, we find the\nbest Bayesian network that explains our data using a heuristic search\nthat is insensitive to the exact ordering between variables. We evaluate\nour proposed approach using a publicly available data set gathered from\nMIT\u2019s PlaceLab. The inferred networks correctly identify activities for\n85% of the time.\n1 Introduction\nA central theme in pervasive computing is the need to build systems that use\nlow-level sensor data to identify the Activities of Daily Living (ADLs) (such\nas cleaning or bathing). Recently, there has been significant progress in this\narea including (a) deploying real systems that extract information from a va-\nriety of sensors [1], (b) developing and extending machine learning approaches\nthat model activities including Bayesian [2], Markov [3], Neural [4], and rule-\ninduction [5] classifiers and (c) studying specific domains to identify relevant\ncontext information which in turn can be used to support activity recognition\n[6].\nThe vision of developing systems that recognize ADLs has been driven by nu-\nmerous compelling applications. For example, in the medical field, professionals\nbelieve that changes in the activities of daily living such as eating, showering etc.\nare important in the detection of emerging medical conditions and that moni-\ntoring the daily activities of people can reduce the number of low risk cases that\ncome into hospitals \u2013 thereby reducing the financial burden on health systems\nand allowing more focus on patients at higher risk [6].\nA major challenge in learning ADL patterns is the lack of large training sets\nthat reflect accurate aspects of an activity. For instance, existing deployments\nsuch as the PlaceLab generate thousands of sensor readings along with only tens\nof instances of activities. Such sparse data cannot be used to learn a complete\nmodel of an activity. However, such sets contain important information that\nmay reflect sensor patterns during activities. The goal is therefore to separate\nimportant sensor signals from noisy ones and to identify true relationships from\nspurious ones.\nIn this paper, we propose a novel framework for discovering relationships\nbetween sensor signals and observed human activities from sparse datasets. The\nframework builds on the use of Bayesian networks for modeling activities by\nrepresenting statistical dependencies between sensors. We extend earlier efforts\nin three fundamental ways. Firstly, we perform multicollinearity analysis to fo-\ncus on orthogonal features of our data (i.e. features with minimal redundancy).\nThe goal here is to eliminate aspects of the data that do not contribute addi-\ntional information. Secondly, we propose Efron\u2019s bootstrapping to generate large\ntraining sets that capture important features of each activity. Bootstrapping is\na non-parametric technique that resamples with replacement from the original\ndata. The underlying intuition is that bootstrap runs will emphasize consistent\nfeatures in our original data thereby facilitating learning. Finally, we find the\nbest Bayesian network that explains our data using a heuristic search that is\ninsensitive to the exact ordering between variables. We specifically eliminate the\nbias due to the ordering between consecutive variables. We evaluate our proposed\napproach using a publicly available data set gathered from MIT\u2019s PlaceLab. The\ninferred networks correctly identify activities for 85% of our validation set.\n2 Background\nMost work on recognizing activities has centered on using statistical methods\nto build relationships between observed sensor data and ADLs. For example,\nthe MARC home project [7] used mixture models and hierarchical clustering\nto detect breakfast and dinner preparation activities in the kitchen. Both ac-\ntivities were detected with high accuracy. Na\u00a8\u0131ve Bayesian classifiers were used\nby researchers at MIT [1] to detect ADLs in home settings using environmen-\ntal state-change sensors. For 13 ADLs, the percentage of time that an activity\nwas correctly detected peaked at 31%. The Guide project [8] used unsupervised\nmethods (that do not require activity labeling) to detect activities using RFID\ntags placed on objects. This method relied on \"large quantities of reliable sensed\ndata about activities\"and achieved good recognition accuracy . More recently,\nProactive Activity Toolkit (PROACT) [2] used dynamic Bayesian networks and\nRFID tags to build ADL models. Subjects were given task sheets for 14 differ-\nent activities that were performed using a glove equipped with an RFID reader.\nWhen the reader failed to capture a particular touch, subjects were asked to\nretouch objects. PROACT successfully inferred that an activity occurred 88%\nof the time. Finally, Doctor et al. [5] used fuzzy rule induction and genetic pro-\ngramming to construct rule sets for activities from sensor data. This approach\nexamined 10 different activities and produced 306 rules to predict ADLs.\nMany factors contribute to the difficulty in recognizing ADLs including: first,\nADLs may vary in their frequency of occurrence from once a week to a number of\ntimes per day (e.g. washing clothes vs. going to the bathroom). The infrequency\nof many ADLs prevents the collection of sufficiently large data sets with balanced\nADL entries. This in turn complicates the task of learning ADL patterns.\nSecond, human action is not always purposeful [9] and therefore observable\naction (that is captured by sensors) may not correlate to particular activities.\nThis increases noise in ADL data sets and makes them difficult to analyze.\nThird, many ADLs consist of logical sequences of sub-activities (e.g. cooking\nincludes chopping, frying, serving etc.) and typically involve the firing of com-\nplex combinations of sensors. However, many ADL recognition methods do not\nexplore different structural dependencies between sensors that in turn reduces\nmodel accuracy.\nIn the remainder of this paper, we present three techniques to address the\nabove challenges. Section 3 discusses our approach to generating small feature\nvectors with minimal redundancy from raw sensor data. Section 4 describes\nbootstrapping as a method to generate large activity samples that emphasize\nimportant aspects of each activity. We then discuss how to learn Bayesian net-\nworks and present a heuristic search approach in section 5. Section 6 outlines our\nalgorithm. Section 7 evaluates our approach. Finally, we conclude and discuss\nfuture work in section 8.\n3 Feature Encoding and Selection\nProximity to objects has been the most critical aspect in modeling activities.\nActivations of proximity sensors are typically encoded to incorporate tempo-\nral information such as quantitative relationships (e.g. stove sensor fired during\ncooking) or qualitative relationships (e.g. the shower sensor fired after the bath-\nroom light sensor). Intille et al. shows that low-order temporal relationships be-\ntween sensor activations are sufficient for recognizing ADLs using na\u00a8\u0131ve Bayesian\nclassifiers [10].\nWe use a similar approach to encode our data. First, we discretized sen-\nsor readings based on fixed thresholds. A possible criticism of discretization is\nthat it penalizes sensors whose range of variation is small: because with a fixed\nthreshold, we would not capture small changes. This turned out to be not critical\nbecause most of our sensor readings can be interpreted in a discrete manner. For\ninstance, although current sensors measure continuous current flows, we easily\ndistinguished 2 levels of current flow that indicate that a device is either on or off.\nSecond, we encode consecutive sensor readings into a single feature vector where\nF (Si, Sj) = 1 implies that sensor Si fired before sensor Sj and F (Si, Sj) = 0\nimplies that sensor Si did not fire before sensor Sj .\nIn a setup of N sensors, we have NxN features that can be included in our\nmodel and therefore reducing the number of features is critical. We use 2 ap-\nproaches to reduce the number of features for an activity. First, we only consider\nthe features that fire in our training data during the activity. Second, we perform\na multicollinearity analysis on the remaining features to discard those that are\nlinearly correlated.\nMulticollinearity analysis describes a statistical method to determine if columns\nof a matrix behave in a correlated manner. Specifically, we apply eigen decompo-\nsition on the correlation matrix of our features to determine linearly dependent\nfeatures. This splits the data into orthogonal eigen vectors where associated eigen\nvalues reflect the magnitude of each vector. Ideally, all eigen values should be\nlarge reflecting that all orthogonal vectors are important and that there is mini-\nmal redundancy. The presence of small eigen values points to multicollinearities\nin the data (i.e redundancy).\nBased on the eigen values, we choose the set of features with minimal redun-\ndancy (i.e. the most linearly uncorrelated). The intuition is that features that\nchange together do not contribute any additional information to the learning\nprocess, instead they complicate the search for a solution and therefore such\nfeatures should be eliminated. By applying this concept, we reduced our feature\nset without losing critical information.\n4 Bootstrapping for Model Induction\nUnlike typical applications of learning from data, sensor data from pervasive en-\nvironments pose unique challenges. Firstly, pervasive environments are equipped\nwith hundreds of sensors that are sampled at high rates. This generates large\nfeature sets with many readings that can easily suppress the true signal of an\nactivity. Secondly, there is a clear imbalance between the frequencies of activities\nand the amount of sensor readings that pervasive setups generate. Such sparse\ndata cannot be used to learn a complete model of an activity and can easily\nskew model parameters to extreme values.\nTo overcome the above challenges, we propose the use of Efron\u2019s non-parametric\nbootstrapping for data generation and subsequently model induction. The idea\nbehind bootstrapping is that if an activity sample is a good approximation of\nthe true activity, a sampling distribution can be estimated by generating a large\nnumber of new samples (called pseudo samples) by randomly sampling with\nreplacement from the original data set. Therefore, if sensor S fires consistently\nwithin a particular activity A, then we should be able to detect that in our boot-\nstrap runs. If only a small fraction of our bootstrap samples reflect the presence\nof S in A then probably S is unrelated to A.\nWe bootstrap both training and validation samples of our features for all\nactivities. Using the generated data, we invoke the search algorithm to learn a\nStove\nSensor\nKitchen\nLight\nMotion\nSensor\nCooking\n{0, 1} {0, 1} {0, 1}\n{0, 1}\nP(Cooking| Stove, Light,\nMotion}\nFeatures\n),...,,(\n21 n\nXXX\nActivity\nPattern\nFig. 1. Mathematical Structure of a Bayesian Network\nBayesian network for each activity. We then validate our results with respect to\nthe bootstrap runs of our validation samples.\n5 Learning Bayesian Networks\nWe summarize learning of Bayesian networks from data. For a more detailed\nexposition, we refer the reader to [11].\nConsider a finite set of independent discrete random variablesX = X1, ..., Xn\nwhere each variable Xi may take on values from a finite set. A Bayesian network\nis a Directed Acyclic Graph (DAG) that describes relationships of probabilistic\ndependency between the above variables. More formally, a Bayesian network BN\nis a pair < G,\u0398 >. G is a DAG whose nodes represent the random variables\nin X and whose edges represent probabilistic dependencies between the vari-\nables. \u0398 represents the parameters of the Bayesian network including estimates\nof the prior distributions for root nodes and estimates of the conditional distri-\nbutions for each edge. Therefore, a learned Bayesian network defines a unique\njoint probability distribution over X given by:\nPBN (X1, ..., Xn) =\nn\u220f\ni=1\nPBN (Xi|parents(Xi))\nFigure 1 shows the mathematical structure of a node in a Bayesian Network.\nGiven some training data D = d1, ..., dm where di represent an assignment to\nthe discrete random variables in our model, the problem of learning a Bayesian\nnetwork involves two components: a scoring metric and a search procedure. The\nscoring metric measures the goodness-of-fit of the learned network to the training\ndata D. This metric has to possess 3 properties. First, structure equivalence that\nmeans that for any two networks with identical structures, the score must be\nthe same. Second, the score should be decomposable which means it can assess\nthe exact gain or loss due to adding, removing or changing the direction of an\nedge in a network. Finally, the score should have a closed form. The second\ncomponent of the learning algorithm is a search procedure for the network with\nthe highest score which is known to be NP-hard [12] . Instead, heuristic searches\nare typically used such as hill-climbing to find approximate solutions.\nIt is important to emphasize that the network structures that are discovered\nare sensitive to the search algorithm. For instance, hill-climbing techniques will\noften produce a set of networks that are very similar in structure as the algorithm\nconverges to a solution. This is a serious limitation since we run the risk of over-\nrestricting our search for dependencies among variables. Next, we describe a\nnovel technique that performs a polynomially bounded search of networks that\nhave fundamentally different structures.\n6 Efficient Structural Learning of Activities\nA basic method for learning a Bayesian network uses K2 hill-climbing [13] where\narcs from a fixed ordering of variables (i.e. nodes) are added to each node to\nmaximize the probability that the network is correct, given the data using Bayes\nformula:\nP (N |D) = P (N)P (D|N)P (D)\nThe probability of the data D, given our network, N, assumes a Dirichlet\nprior which is given by Cooper and Herskovits [13].\nA major limitation of the above approach is sensitivity to the order of intro-\nducing arcs into the model. For instance, the impact of an important dependency\nbetween two variables can be suppressed by less critical dependencies because\nthey were explored earlier in the list of variables. It should be noted that perform-\ning an exhaustive search for all possible networks is infeasible because searching\nfor an optimal network is NP-hard.\nInstead, we circumvent the limitation imposed by ordering by using a greedy\nsearch algorithm that is insensitive to ordering between consecutive nodes. Our\nalgorithm examines the networks that are generated by the dihedral groups of\nour features. A dihedral group of n features is a set of permutations that include\nn rotations and n reflections of the features. Figure 2, shows the dihedral groups\nfor 3 features. The intuition behind using these permutations is that rotations\nallow each sensor to be entered at least once as the first element in the learner\nthereby having the highest impact. Reflections switch the ordering of every 2\nconsecutive features thus eliminating the bias due to consecutive node ordering.\nMore importantly, for n features we have 2n dihedral permutations which sets a\npolynomial upper bound on the number of networks to explore.\nFor each permutation, we use K2 hill-climbing [13] to learn the best network\nstructure from independent bootstrap samples. We then choose the network with\nthe highest score as the best classifier for an activity. Details of the algorithm\nare given in figure 3.\n321\nFFF\n312\nFFF\n213\nFFF\n132\nFFF\n231\nFFF\n123\nFFF\nReflection\nReflection\nReflection\nRotation\nRotation\nFig. 2. Dihedral Permutations of 3 Features\nInput: \nA set of m activities \nFor each activity i, a set of in  sensor readings during the activity \nAn upper bound k on the number of parents for each node \nAlgorithm: \niFM  is a feature matrix for ia  where nullFM i =\ntF  is an  mm nn \u00d7  feature vector at time t, nullFt =\nFor each second t in activity ia : maa \u21921\nConstruct tF  for ia   such that 1),( =jiFt  if issensor  fired before jssensor at time t \niFM =append( iFM , tF ) \/\/ includes only sensors that fired \nFor each activity ia : maa \u21921\niC =CorrelationMatrix( iFM ) \nPerform Eigen Decomposition on iC\nEliminate Features that correlate with small eigen values from iFM\niT = Generatre training set for ia  by resampling k  instances with replacement \niV = Generatre validation set for ia  by resampling 'k  instances with replacement \nGenerate the dihedral permutations iP  of the features in iFM\nFor each permutation ijp  in iP\nUse K2 hill-climbing to learn network ijB  from iT\nCompute the priors and conditional probabilities for ijB\nEvaluate the network against the training set iT\nStore the network that scores best on the training set in iBN\nRandomly shuffle all validation sets \nRun all learned networks in parallel against the validation sets \nPick the class that has the highest probability \nOutput: \nThe classification accuracy for each activity in our validation set. \nFig. 3. Structural Learning Algorithm\n7 Evaluation\nWe wanted to evaluate our approach using data sets from realistic settings where\nusers perform everyday activities in environments that resemble their homes.\nUsers should be able to multi-task their activities, determine their sequence\nand pace, interact with other people and engage in complex behaviors without\ninterruptions. More importantly, we wanted to minimize the bias in our data sets\nthat may result from imposing specific activities on users or installing sensors in\nways that improve recognition of specific activities.\nWe found one publicly available dataset that fit our criteria from MIT\u2019s\nPlaceLab [14]: a live-in laboratory in Cambridge, MA. The PlaceLab data was\nrecorded on March 2005 for 4 consecutive hours where a researcher performed a\nset of common household activities. The researcher determined the type of ac-\ntivities, their sequence, their pace and whether they overlap. As the researcher\nconducted the activities, data was sampled from approximately 300 sensors such\nas current flow sensors and switch sensors. 9 infrared cameras and 9 color cam-\neras were used to record activities throughout the space. Subsequently, trained\nannotators used the video feeds to annotate the sensor data with appropriate\nactivity labels. This approach has at least two advantages: (1) users are not\nrequired to annotate their own activities and therefore have a more realistic\nexperience in the space. (2) With video records, annotators can easily label ac-\ntivities at different granularity (e.g. a user is chopping vegetables and cooking).\nMore information about the data set and its format can be found in [14].\n7.1 Methodology\nIn our analysis, we looked at 24 different activities. 21 activities had at least 2\nsamples and therefore we were able to run independent bootstraps for training\nand validation data. 3 activities had 1 sample that we used for bootstrapping\nboth our training and validation data.\nWe considered data from 286 sensors including: switch sensors that detect on\nand off events such as doors being opened or closed, light sensors that measure\nthe degree of illumination in different areas, gas sensors that measure amount\nof gas flow to the water heater and stove burners, current sensors that detect\ncurrent flows in 43 different circuits, water sensors that measure the amount of\nwater flow for different faucets and toilets and MITes sensors that measure the\nmovement of different objects.\nThe raw sensor data is initially preprocessed to obtain feature vectors of\nthe form described in section 3. These feature vectors reflect sensor activity\nduring every second of an activity. Multicollinearity analysis is then performed\non the discrete features to eliminate linearly dependent features. The number\nof features is selected such that at least 90% of the variability in the data is\nmaintained with an upper bound of 25 features per activity for computational\nreasons. This resulted in an average of 15 features per activity.\nUsing 2 sets of independent samples for each activity, we applied non-parametric\nbootstraps to generate 100 instances for training and 20 instances for validation\nper activity. The training samples are given to our search algorithm that finds\nthe best Bayesian network that explains our data. The search procedure uses K2\nhill-climbing with restarts that examine the dihedral groups of our features. For\n24 activities, the search algorithm generated 24 Bayesian networks.\nTable 1. Percentage of time activity detected\nActivity Examples Features BNT BNT-1FT BNT-5FT BNT-RS RG\nCleaning a surface 7 15 88% 85% 28% 88% 4%\nCleaning 3 13 88% 69% 31% 82% 4%\nDishwashing 3 12 85% 69% 15% 38% 4%\nDisposing Garbage 3 6 83% 52% 17% 67% 4%\nDrinking 7 22 92% 84% 56% 20% 4%\nDrying Dishes 3 19 88% 83% 38% 13% 4%\nEating a meal 3 23 94% 91% 43% 94% 4%\nHandwashing Dishes 13 24 94% 90% 52% 75% 4%\nLaundry 2 17 89% 78% 76% 97% 4%\nListening to music 1 22 92% 88% 58% 89% 4%\nMaking the bed 4 8 67% 57% 22% 78% 4%\nMeal preparation 6 16 91% 85% 45% 91% 4%\nMeasuring 3 11 90% 80% 10% 90% 4%\nMixing and Stirring 9 17 92% 92% 50% 29% 4%\nMopping 4 25 93% 85% 81% 19% 4%\nPreparing Food 2 9 75% 58% 8% 67% 4%\nPreparing Meal 3 18 67% 71% 38% 95% 4%\nPutting away laundry 1 14 87% 80% 27% 33% 4%\nRetrieving ingredients 10 11 83% 74% 18% 92% 4%\nSweeping 3 7 71% 57% 29% 71% 4%\nUsing a computer 10 21 96% 88% 46% 95% 4%\nUsing a phone 6 3 68% 67% 33% 67% 4%\nWashing Ingredients 1 18 90% 86% 50% 90% 4%\nWatching Movies 3 5 80% 60% 24% 80% 4%\nMean 4.5 15 85% 76% 37% 70% 4%\n7.2 Accuracy Analysis\nTo assess the accuracy of our approach, we randomly shuffled the activities in\nour validation set. Each activity had 20 instances for a total of 480 activities.\nWe gave the feature sequences of each activity (without segmenting between\nactivities) to our inference software that assessed the 24 Bayesian networks in\nparallel. A history of 10 seconds is used in setting the nodes of the Bayesian\nnetworks.\nThe inference software returns the most likely activity (for each second) based\non a stringent criteria where a valid classification should have a probability that\nis at least double the probabilities of other classifiers. Therefore a classification\nwith probability 0.9 and 0.6 from BN1 and BN2 is inadmissible.\nTable 1 shows the results for 24 ADLs in the column labeled BNT. Our\nnetworks correctly inferred that an activity occurred 85% of the time. This is\nsignificantly better than the random guess case (shown in table 1 in the RG\ncolumn) which would yield an average of 4% in terms of classification accuracy.\nOur best performance was 96% for 'using a computer' which simply involved\nfeatures of sensors located in the office area. This activity had a unique spatial\nlocality that did not overlap with other activities. The worst performance was\nfor 'preparing a meal' and 'making the bed'. The former activity significantly\noverlapped with 'preparing food' with respect to the underlying features. The\nlatter activity generated a small number of sensor activations and was detected\ntowards the end of the activity.\n7.3 Robustness Analysis\nWe performed a number of tests to analyze the robustness of our procedure.\nWe examined one particularly interesting hypothesis, namely whether accuracy\nincreases as the number of features in our model increases. In classification prob-\nlems, adding irrelevant features can degrade performance. We performed a re-\ngression fit between accuracy and the number of features followed by a hypothesis\ntest. We found strong evidence that an increase in the number of features leads to\nimproved accuracy (p < 0.0001). This result comes at no surprise, since we care-\nfully selected orthogonal features to include in our model using multicollinearity\nanalysis.\nWe also tested the robustness of our analysis to the addition of linearly de-\npendent features. For each activity, we randomly selected 1 and 5 features with\ncollinearity to the original feature set. We then added those features to our train-\ning and validation data and retrained our models. Table 1 shows the results of\nadding 1 and 5 features in the columns BNT-1FT and BNT-5FT respectively.\nAs expected, the average classification accuracy dropped from 85% to 76% with\n1 added feature and to 37% with 5 added features. 'Preparing Meal' was an ex-\nception where accuracy slightly increased by adding 1 feature. In this particular\ninstance, we randomly picked the second least correlated feature to add. This\nfeature still explained part of the variability in our data and therefore led to\na slight improvement. However, the results clearly validate our methodology in\nselecting important features to include in our learning procedure.\nFinally, we wanted to test our search procedure (that uses the dihedral per-\nmutations) against standard K2 hill-climbing with random restarts where the\norder by which arcs are added to a particular node from other nodes is random.\nThe results of the randomized algorithm are shown in table 1 in the column\nlabeled BNT-RS. Our approach outperformed the randomized algorithm by an\naverage of 15% across all activities. However, this result is not consistent for\nall activities. In several instances, the randomized algorithm arrived at a better\nsolution such as 'Preparing Meal' . This came at a cost where accuracy dropped\nfor another overlapping activity namely 'preparing food' . More interestingly, the\nrandomized algorithm gave identical results to our algorithm for many activities\nwhich may suggest that order between consecutive features is not critical for\nthose activities. However, we emphasize that both algorithms start with iden-\ntical and orthogonal features which demonstrates the importance of our initial\nselection criteria and may explain why both algorithms arrived at similar con-\nclusions.\n8 Conclusion\nThis paper proposes a novel methodology for modeling activities from sparse\ndatasets. Our work addresses a fundamental problem that arises in practical de-\nployments: the imbalance between the number of activities and the number of\nsensor readings. Whereas previous efforts attempt to learn directly from sparse\ndata, we focus on overcoming the sparsity of the available data. Initially, multi-\ncollinearity analysis eliminates redundant information in our data. Efron\u2019s boot-\nstrapping is then used to generate training and validation sets from independent\nsamples. Finally, we find the best Bayesian network that explains our data using\na heuristic search that is insensitive to the exact ordering between consecutive\nvariables. Our networks achieve an average accuracy of 85% and perform more\nconsistently than hill-climbing with random restarts across 24 different activities.\nIt is important to note that our approach does not necessarily learn a com-\nplete model of an activity. However, without our proposed optimizations it would\nbe difficult or perhaps impossible to learn patterns from sparse data. Moreover,\nmany statistical assumptions will fail because of the lack of sufficiently large\ndata sets. Instead, our approach emphasizes consistent aspects of the data and\ntries to search for a consistent feature profile of an activity.\nOur plans for future work include exploring the causality relationships be-\ntween the nodes in our Bayesian networks. A Bayesian network captures the\nprobabilistic dependencies between a set of variables. This may or may not re-\nflect causal relationships between the variables involved. We are interested in\nidentifying pairs of nodes that have a causal relationship between them to at-\ntach meaning to our networks and to engage users in more intimate interactions.\nFor example, users may be able to ask why the system incorrectly classified an\nactivity and then attempt to correct system behavior by inducing some bias.\nReferences\n1. Tapia, E., Intille, S., Larson, K.: Activity recognition in the home setting using\nsimple and ubiquitous sensors. LNCS Springer-Verlag 3001 (2004)\n2. Philipose, M., Fishkin, K.P., Perkowitz, M., Patterson, D.J., Fox, D., Kautz, H.,\nHahnel, D.: Inferring activities from interactions with objects. IEEE Pervasive\nComputing 3(4) (2004) 50\u201357\n3. Oliver, N., Horvitz, E., Garg, A.: Layered representations for recognizing office\nactivity. The Fourth IEEE International Conference on Multimodal Interaction\n(2002) 3\u20138\n4. Mozer, M.C.: The neural network house: An environment that adapts to its in-\nhabitants. AAAI Spring Symposium (1998) 110\u2013114\n5. Doctor, F., Hagras, H., Callaghan, V.: An intelligent fuzzy agent approach for\nrealising ambient intelligence in intelligent inhabited environments. IEEE Trans.\nOn Systems, Man and Cybernetics 35(1) (2005) 55\u201365\n6. Dalal, S., Alwan, M., Seifrafi, R., Kell, S., Brown, D.: A rule-based approach to\nthe analysis of elders activity data: Detection of health and possible emergency\nconditions. AAAI Fall 2005 Symposium (2005)\n7. Barger, T., Alwan, M., Kell, S., Turner, B., Wood, S., Naidu, A.: Objective remote\nassessment of activities of daily living: Analysis of meal preparaion patterns. Poster\nPresentation (2002) Medical Automation Research Center, University of Virginia\nHealth System.\n8. Philipose, M., Fishkin, K., Fox, D., Kautz, H., Patterson, D., Perkowitz, M.G.:\nTowards understanding daily life via auto-identification and statistical analysis.\nUbiHealth Workshop. UbiComp (2003)\n9. Mises, L.: Human Action: A Treatise on Economics. Fox & Wilkes (1966)\n10. Intille, S., Larson, K., Tapia, E., Beaudin, J., Kaushik, J.: Using a live-in laboratory\nfor ubiquitous computing research. LNCS Springer-Verlag (2006)\n11. Pearl, J.: Graphical models, causality and intervention (1993)\n12. Chickering, D.: Learning bayesian networks is np-complete (1995)\n13. Cooper, G.F., Herskovits, E.: A bayesian method for the induction of probabilistic\nnetworks from data. Machine Learning 09(4) (1992) 309\u2013347\n14. Intille, S.S., Larson, K., Beaudin, J.S., Nawyn, J., Tapia, E.M., Kaushik, P.: A liv-\ning laboratory for the design and evaluation of ubiquitous computing technologies.\nIn: CHI \u201905: CHI \u201905 extended abstracts on Human factors in computing systems,\nNew York, NY, USA, ACM Press (2005) 1941\u20131944\n"}
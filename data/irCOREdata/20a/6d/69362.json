{"doi":"10.1109\/FUZZY.2008.4630479","coreId":"69362","oai":"oai:eprints.lancs.ac.uk:27120","identifiers":["oai:eprints.lancs.ac.uk:27120","10.1109\/FUZZY.2008.4630479"],"title":"On line learning fuzzy rule-based system structure from data streams.","authors":["Angelov, Plamen","Zhou, Xiaowei"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-06","abstract":"A new approach to fuzzy rule-based systems structure identification in on-line (possibly real-time) mode is described in this paper. It expands the so called evolving Takagi-Sugeno (eTS) approach by introducing self-learning aspects not only to the number of fuzzy rules and system parameters but also to the number of antecedent part variables (inputs). The approach can be seen as on-line sensitivity analysis or on-line feature extraction (if in a classification application, e.g. in eClass which is the classification version of eTS). This adds to the flexibility and self-learning capabilities of the proposed system. In this paper the mechanism of formation of new fuzzy sets as well as of new fuzzy rules is analyzed from the point of view of on-line (recursive) data density estimation. Fuzzy system structure simplification is also analyzed in on-line context. Utility- and age-based mechanisms to address this problem are proposed. The rule-base structure evolves based on a gradual update driven by; i) information coming from the new data samples; ii) on-line monitoring and analysis of the existing rules in terms of their utility, age, and variables that form them. The theoretical theses are supported by experimental results from a range of real industrial data from chemical, petro-chemical and car industries. The proposed methodology is applicable to a wide range of fault detection, prediction, and control problems when the input or feature channels are too many","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"IEEE","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:27120<\/identifier><datestamp>\n      2018-01-24T02:04:21Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        On line learning fuzzy rule-based system structure from data streams.<\/dc:title><dc:creator>\n        Angelov, Plamen<\/dc:creator><dc:creator>\n        Zhou, Xiaowei<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        A new approach to fuzzy rule-based systems structure identification in on-line (possibly real-time) mode is described in this paper. It expands the so called evolving Takagi-Sugeno (eTS) approach by introducing self-learning aspects not only to the number of fuzzy rules and system parameters but also to the number of antecedent part variables (inputs). The approach can be seen as on-line sensitivity analysis or on-line feature extraction (if in a classification application, e.g. in eClass which is the classification version of eTS). This adds to the flexibility and self-learning capabilities of the proposed system. In this paper the mechanism of formation of new fuzzy sets as well as of new fuzzy rules is analyzed from the point of view of on-line (recursive) data density estimation. Fuzzy system structure simplification is also analyzed in on-line context. Utility- and age-based mechanisms to address this problem are proposed. The rule-base structure evolves based on a gradual update driven by; i) information coming from the new data samples; ii) on-line monitoring and analysis of the existing rules in terms of their utility, age, and variables that form them. The theoretical theses are supported by experimental results from a range of real industrial data from chemical, petro-chemical and car industries. The proposed methodology is applicable to a wide range of fault detection, prediction, and control problems when the input or feature channels are too many.<\/dc:description><dc:publisher>\n        IEEE<\/dc:publisher><dc:date>\n        2008-06<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/FUZZY.2008.4630479<\/dc:relation><dc:identifier>\n        Angelov, Plamen and Zhou, Xiaowei (2008) On line learning fuzzy rule-based system structure from data streams. In: IEEE International Conference on Fuzzy Systems, 2008. FUZZ-IEEE 2008. (IEEE World Congress on Computational Intelligence). IEEE, pp. 915-922. ISBN 978-1-4244-1818-3<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/27120\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":null,"relations":["http:\/\/dx.doi.org\/10.1109\/FUZZY.2008.4630479","http:\/\/eprints.lancs.ac.uk\/27120\/"],"year":2008,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"  \n \n  \nAbstract \u2014A new approach to fuzzy rule-based systems \nstructure identification in on-line (possibly real-time) mode is \ndescribed in this paper. It expands the so called evolving \nTakagi-Sugeno (eTS) approach by introducing self-learning \naspects not only to the number of fuzzy rules and system \nparameters but also to the number of antecedent part variables \n(inputs). The approach can be seen as on-line sensitivity \nanalysis or on-line feature extraction (if in a classification \napplication, e.g. in eClass which is the classification version of \neTS). This adds to the flexibility and self-learning capabilities \nof the proposed system. In this paper the mechanism of \nformation of new fuzzy sets as well as of new fuzzy rules is \nanalyzed from the point of view of on-line (recursive) data \ndensity estimation. Fuzzy system structure simplification is also \nanalyzed in on-line context. Utility- and age-based mechanisms \nto address this problem are proposed. The rule-base structure \nevolves based on a gradual update driven by; i) information \ncoming from the new data samples; ii) on-line monitoring and \nanalysis of the existing rules in terms of their utility, age, and \nvariables that form them. The theoretical theses are supported \nby experimental results from a range of real industrial data \nfrom chemical, petro-chemical and car industries. The \nproposed methodology is applicable to a wide range of fault \ndetection, prediction, and control problems when the input or \nfeature channels are too many. \nI. INTRODUCTION \nuzzy rule-based models, and in particular, \nTakagi-Sugeno type of fuzzy rule-based models have \nfound numerous applications during the last couple \ndecades [1,2]. During the first decade (late 1980s, early \n1990s) they were primarily designed using expert knowledge \nand considered a full coverage of the data space [3] (usually \nequally distributed between the fuzzy sets that represent \ndifferent linguistic terms). Since mid-1990s a different \napproach became popular as \u2018data-driven\u2019 fuzzy systems \ndesign [4]-[6]. The importance of this approach should not \nbe underestimated because it makes possible automation of \nthe process of fuzzy systems design (including on-line and in \nreal-time). This makes fuzzy systems much more attractive \nfor real applications including in areas such as robotics, \nadvanced industrial processes etc. [7]-[8]. Still, the problems \nof structure identification of the fuzzy rule based system; \nespecially in on-line mode is paid little or no attention [3,4]. \nUsually, it is assumed that the structure is selected and \npre-fixed. In some works it is a result of data space \n \nBoth authors are with the Intelligent Systems Research Laboratory, \nDepartment of Communication Systems, InfoLab21, Lancaster University, \nLancaster, LA1 4WA, UK; phone +44 (1524) 510391; fax: +44 (1524) \n510489, e-mail: p.angelov@lancaster.ac.uk \npartitioning by clustering [5], but in off-line mode and with a \npre-defined number of clusters and pre-defined number of \ninputs (features). In the present paper, we challenge this \nproblem by a proposal for a fully data-driven method that \nallows a truly flexible and evolving structure of the fuzzy \nsystems (in particular of Takagi-Sugeno type) to be designed \non-line. The basic principle is of a gradual evolution of the \nfuzzy rule-based model structure in terms of fuzzy rules and \ntheir components \u2013 fuzzy sets, including variables of the \nantecedent part. The structure of the fuzzy rules is \ndetermined by on-line incremental clustering of the \ninput-output data space. The inputs (features) are gradually \nselected from the initial pool of potential inputs (features) \nbased on their accumulated sensitivity. The proposed \napproach is verified on a number of real industrial examples. \nThe quality of the fuzzy rule base can be monitored on-line \nand simplified based on the removal of fuzzy rules that are \nold or marginally used. \nThe remainder of the paper is structured as follows. In \nSection II the approach to on-line learning the antecedent \npart of the fuzzy systems by recursively estimating data \ndensity distributions is presented. In Section III the newly \nproposed approach to select inputs (features) on-line is \nintroduced. In Section IV mechanisms for fuzzy rules \nreduction based on cluster\/rule age and utility are \nintroduced. Section V describes the application of the \nproposed techniques to various experimental data, and \nfinally, the Conclusions and Discussion Section closes the \npaper. \nII. ON-LINE LEARNING FUZZY SYSTEMS ANTECEDENTS \nBASED ON DATA DENSITY \nThe main driver of the proposed approach is the attempt to \nestimate the data density in a recursive (therefore \ncomputationally efficient and suitable for on-line and \nreal-time applications) manner from the data streams and to \nreact on the data density variations by modifying the \nunderlying structure of the model. It is well known that the \ndata density has been estimated off-line by kernels in image \nprocessing [9], by Parzen windows [10] in statistical \nlearning. It is also exploited in generalized regression \nmodels [11], so called Mountain function [12] and so called \npotential [13]. In all of these methods the data density is \nestimated based on Gaussian distribution. In [14] it was \nproposed to use Cauchy function over the sum of distances \nbetween data points, because the Cauchy function same as \nOn Line Learning Fuzzy Rule-based System Structure from Data \nStreams \nPlamen Angelov, Senior Member IEEE, Xiaowei Zhou, Student Member IEEE \nF\n915\n978-1-4244-1819-0\/08\/$25.00 c\u00a92008 IEEE\n  \n \nthe Gaussian: \na) is monotonic;  \nb) its maximum is unique and of value 1; \nc) asymptotically tends to zero when the argument tends to \ninfinity. \nThese properties, which are necessary for a density \nfunction, are satisfied by both functions, because the Cauchy \nfunction is, in fact, a first order approximation of the \nGaussian: \n\u00a6 +\u2212+\n\u2248=\n\u00a6\n\u2212\n=\n\u00a6 \u2212\n\u2212\n\u2212\n\u2212\n=\n\u2212\n=\n1\n1\n2\n2\n2\n)()(\n2\n)()(\n...\n2\n)()(\n1\n11\n1\n1 2\n2\n1\n1\n2\n2\nk\ni\nizkz\nizkz\nizkz\ne\ne\nk\ni\nk\ni\n\u03c3\n\u03c3\n\u03c3\n (5) \nwhere z denotes the input-output vector; k is the current \ntime instant; \u0131 denotes the spread or zone of influence of the \ncluster. \nThe data density (expressed by the value called potential, \nP) has been used as a criterion to form new clusters in the \nevolving fuzzy clustering approach, eClustering [14]:  \n\u00a6\u2212\n=\n\u2212\n\u2212\n+\n=\n1\n1\n2\n2\n2\n)()(\n1\n11\n1))((\nk\ni\nizkz\nk\nkzP\n\u03c3\n (6) \nThe rationale is that the points with high potential are \ngood candidates for becoming focal points of fuzzy rules. \nEstimation of the data density in on-line mode is not a trivial \ntask, because by definition density in the data space around \nthe current data point is based on the distance between this \npoint and all other data samples which in an on-line mode \nwill not be kept in the memory. This require a recursive \nprocedure to calculate (6), which was proposed in [14,15]:   \n)(2)()1)()(1(\n1))((\nkckbkak\nkkzP\n\u2212++\u2212\n\u2212\n=               (7) \nValues a(k) and c(k) can be calculated from the current frame \nonly: \n\u00a6+\n=\n=\nmn\nj\nj kzka\n1\n2 )()( ; \u00a6+\n=\n=\nmn\nj\njj kdkzkc\n1\n)()()(  (8) \nwhere n denotes the dimensionality of the inputs; m denotes \ndimensionality of the outputs; )(kd j is calculated \nrecursively as shown below. \nThe value )(kb is also accumulated during the processing \nof the frames one by one as given by the following recursive \nexpressions: \n     0)1();1()1()( =\u2212+\u2212= bkakbkb  (9) \n     0)();1()1()( =\u2212+\u2212= kdkzkdkd jjjj  (10) \nThe value of the spread (zone of influence of the clusters), \n\u03c3 is proposed to be updated on-line in a data-driven fashion \nby learning the data distribution and variance [16]: \n \n( ) ( )\u00a6\n=\n\u2212\u2212+\u2212=\n)(\n1\n222 )()()(\n11)1()(\nkN\nl\nll\ni\nijij\ni\nkzkz\nkN\nkk \u03b1\u03b1\u03c3\u03c3  (11) \nwhere \u012e denotes the learning step (recommended value \n0.5); )(kNi  denotes the number of data samples that are \nassociated with the ith cluster based on the closeness; the \ninitial value of the spread is usually 5.0)1( =j\u03c3 . \nNote that the focal points and their potentials are kept in \nthe memory while all other previous data samples are \ndiscarded from the memory. The potentials of the focal \npoints are, however, updated at each time step (with each \nnew data sample being read) because by definition the \npotential should represent the data density in respect to all \ndata samples (including the ones that will appear after the \nmoment when a sample is being used as a prototype to form a \ncluster). Therefore, an update of the potential of focal points \nis required, which can be done by the following formula \n[14-16]: \n2\n*\n*\n*\n1))1((\n1)2(1\n1))((\nijij\ni\ni\nxx\nkzP\nkk\nkkzP\n\u2212+\u00b8\u00b8\u00b9\n\u00b7\n\u00a8\u00a8\u00a9\n\u00a7\n\u2212\n\u2212\n\u2212+\u2212\n\u2212\n=  (12) \nOnce the data density is estimated by (7)-(10) with the \nspread adapted by (11) one can form a fuzzy rule-base \naccording to the following basic principles: \n1) a data sample that have high potential is eligible to be \na focal point of a fuzzy rule; \n2) a data sample that lies in an area of data space not \ncovered by other fuzzy rules is also eligible to form a \nfuzzy rule in order to ensure coverage of the data space; \n3) avoid overlap and information redundancy in \nforming new fuzzy rules. \nThe first principle, 1) is reflected by the following \nexpression [15,17]: \n( ))(max))(( *\n1\nkzPkzP\nR\ni=\n>  (13) \nwhere z* denotes the data sample that has already been \nchosen to be a focal point of a fuzzy rule; R denotes the \nnumber of fuzzy rules up to the moment k (before condition \n(13) is checked. \nA milder version of (13) can be formulated which makes \neasier to form new clusters if there are many data points that \nare not associated to any cluster called \u2018outer\u2019 data points: \n( ))(max))(( *\n1\nkzPkzP\nR\ni=\n>\u03b3  (14) \n916 2008 IEEE International Conference on Fuzzy Systems (FUZZ 2008)\n  \n \nWhere ( )\n\u00b0\u00af\n\u00b0\u00ae\n\u00ad \u2200\u2200<\n\u2212\n=\n\u2212\nelse\njiex\nN\nk\nk\ni\nj\n1\n,;\n3\nlog 2\u03bc\u03b3 is a factor \nthat takes into account the \u2018outer\u2019 data points; N is the \nnumber of the \u2018outer\u2019 data points.  \nThe second principle, 2) is reflected by the following \nexpression [18]:  \n( ))(min))(( *\n1\nkzPkzP\nR\ni=\n<  (15) \nBased on both principles, 1) and 2) we can formulate two \nalternative versions of the conditions, namely: \n\u2022 Condition A1: (13) OR (15); \n\u2022 Condition A2 (14). \nThe third principle, 3) and the possibility of the rule-base \nto gradually shrink is guaranteed by the following condition \nB [16]: \n( ) ],1[;;)(];,1[, 1 njjekxRii ij =\u2200>=\u2203 \u2212\u03bc  (16) \nwhere [ ]Tnxxxx ,...,, 21= denotes the input vector \n(features if classification problem); ij\u03bc denotes the \nmembership function (usually of Gaussian type) of the jth \nfuzzy set of the ith fuzzy rule ( )\n( )\n2\n2*\n2\n)(\nj\nijj xkx\nkij ex\n\u03c3\u03bc\n\u2212\u2212\n= . \nThis is particularly important for the focal points of rules \nthat might be formed based on the first principle, 1) \nfollowing expression (13) which might lie too close to each \nother. The third principle, 3), in fact, leads also to simpler \nfuzzy rule-base to be formed if compare to other clustering \nmethods such as ART [27], VQ [28] etc. which often require \nlater so called \u2018pruning\u2019 [29]. \nThe rationale of the expression (15) is related to the so \ncalled \u2018one-sigma\u2019 condition, jijj xkx \u03c3>\u2212 *)(  known \nfrom the machine learning literature [10]. That is, expression \n(15) is true when in the rule base there is a fuzzy rule, i such \nthat the input vector of the current data sample, kx is \ndescribed in all dimensions, j by at least 36.01 \u2248\u2212e . \nBased on these principles, the following algorithm for \non-line learning the antecedents of the fuzzy system based on \nthe data density can be formulated \n_______________________________________________ \nRead data sample z(k)=[x(k);y(k)] \n( ) THENkIF 1=  \n\/\/initialization stage\/\/ \n\/\/initialize the variables for recursive calculation\/\/ \ndj(k)=0;j=[1,n]; b(k)=0 \n\/\/ the input part of the first data sample is the focal point \nof the first cluster (rule)\/\/ \n)1()1(*1 xx \u2190 ; 1;1))(( *1 \u2190\u2190 RkzP   \n\/\/form the antecedent part of the first fuzzy rule\/\/ \n( ) ( )*11*11111 ... nn xisxANDANDxisxIFRule  \nELSE  \nRecursively calculate potential of the current data \nsample, ))(( kzP by (7)-(10); \nUpdate the spread of the clusters (membership \nfunctions of the respective fuzzy sets) by (11); \nRecursively update the potentials of the existing cluster \ncenters, by (12); \nCheck  \n Condition A (A1 or A2); \n    Condition B where \nA1) the point is with high potential and covers new \narea of data space \u2013 expressed by (13) or (15); \nA2) same as above but expressed by (14); \nB) the point overlap with the previously formed \nfuzzy rules (16); \n( ) ( )int)( pofocalnewiskxTHENAIF\n )()(* 1 kxkxR \u2190+ 1));(())(( * 1 +\u2190\u2190+ RRkzPkzP R   \n( ) ( ))(* kxnearestremoveTHENBANDAIF l\n)()(* kxkxl \u2190 1));(())(( * 1 +\u2190\u2190+ RRkzPkzP R   \nAssign the new point to the nearest cluster. \nRepeat until end of data stream \n______________________________________________ \nAlgorithm Recursive data space partitioning based on the data density \nAs a result of this data density-based on-line clustering \nprocedure the following fuzzy rule base formed of \nantecedent parts is generated from the data stream: \n( ) ( ) ( ) ],1[;... **22*11 RixisxxisxANDxisxIFR inniii =  (17) \nIt can then be either; i) stored and later analyzed by an \noperator; ii) used for prediction at each time step if combined \nwith consequent part identification as described in [15]; iii) \nused for classification if combined with consequent part \nidentification as described in [19]; iv) used for clustering the \ndata and various applications e.g. in robotics [7,21]. \nIII. ON-LINE INPUT SELECTION IN SELF-LEARNING \nTAKAGI-SUGENO FUZZY SYSTEMS \nIn the previous section, and, to the best of our knowledge, \nin all previous research in on-line fuzzy systems \nidentification indeed, it was assumed that the dimensionality \nof the input (features) vector, n is pre-defined for each \nproblem at hand. In this paper we propose an approach that \nbreaks this assumption for Takagi-Sugeno (TS) type fuzzy \nsystems and gradually removes inputs (features) that do not \n2008 IEEE International Conference on Fuzzy Systems (FUZZ 2008) 917\n  \n \ncontribute to the output. This is based on the on-line \nestimation of the sensitivity of the output. Because in TS \nfuzzy systems the output is locally linear, the sensitivity \nanalysis reduces to analysis of the consequent parameters: \n( ) ( ) ( )\n],1[;\n...\n1\n0\n**\n22\n*\n11\nRixyTHEN\nxisxxisxANDxisxIFR\nn\nj\nijijii\ninniii\n=\u00b8\u00b8\u00b9\n\u00b7\n\u00a8\u00a8\u00a9\n\u00a7\n+= \u00a6\n=\n\u03b8\u03b8\n (18) \nThe overall output of the TS fuzzy system is determined as \na weighted average of the outputs of the local linear models \n[22]: \n\u00a6\n=\n=\nR\ni\nii yy\n1\n\u03bb  (19) \nwhere \n\u00a6\u220f\n\u220f\n= =\n=\n= R\nl\nn\nj\nlj\nn\nj\nij\ni\nx\nx\n1 1\n1\n)(\n)(\n\u03bc\n\u03bc\n\u03bb  is the firing strength of the ith \nfuzzy rule. \nThe importance of each input (feature) can be evaluated \nby the ratio of the accumulated sum of the consequent \nparameters for the specific jth input (feature) in respect to all \nn inputs (features) [23]: \n],1[];,1[;\n)(\n)()(\n1\nnjRi\nkT\nkT\nk\nn\nr\nir\nij\nij === \u00a6\n=\n\u03c9  (20) \nwhere \u00a6\n=\n=\u03a4\nk\nl\nijij lk\n1\n)()( \u03b8  denotes the accumulated sum \nof parameter values of the ith rule.  \nSince the inputs, outputs, and the internal variables of the \neTS system can be normalized online as described in [7], \nthey are comparable between each other. The value of the \nweight can be used for a gradual removal of inputs (features) \nthat contribute little to the overall output (see equation (18)). \nThen the inputs (features), j* that do not contribute enough \nto the output and will be removed from the fuzzy system \nstructure at the next time instant can be determined by:  \n10];,1[];,1[)(max)(\n10];,1[];,1[)()(\n11*\n*\n1\n1*\n*\n>==<\u2203\n\u2264==<\u2203\n=\n=\n\u00a6\nnnjRikTkj\nnnjRikTkj\nir\nn\nr\nij\nn\nr\nirij\n\u03b5\u03c9\n\u03b5\u03c9\n (21) \nwhere \u01301 denotes the tolerable minimum weight of an \ninput (feature) \u2013 suggested value is 3 to 5%. \nThe condition is in terms of the proportion which the \nweight of a certain input (feature) is from the total (sum) or \nthe bigger (maximum) of the accumulated sum of \nparameters. If this proportion is insignificant (less than \u0130) \nthen this input (feature) is negligible and can be removed \nwithout significantly affecting the output. The two \nconditions differ, because when the number of inputs \n(features), n is big the total sum may become too large; at the \nsame time, for a small number of features, the sum gives a \nbetter representation than the maximum (an averaging \neffect). This technique for on-line input (feature) selection is \nillustrated in section V on real industrial data.    \nThe importance of this technique should not be \nunderestimated, because very often in a real environment \nthere are many measurable variables that influence our \noutput. Selecting most informative inputs (features) is a \ncritical task that is usually associated with the pre-processing \nstages [10] and is addressed by approaches such as PCA \n[10], GP [24], etc. These approaches, however, require a \nbatch set of data and a fixed model structure. Relaxing the \nrequirement in terms of the most informative inputs \n(features) significantly improves the flexibility of the model \nthat is being used and adds to the level of autonomy.  \nIV. ON-LINE FUZZY SYSTEM STRUCTURE SIMPLIFICATION \nIn section II the automatic design of the fuzzy system \nantecedents based on the on-line estimation of the data \ndensity was described. In section III, a methodology to \ngradually reduce the number of inputs (features) has been \ndescribed. Learning parameters of the consequents has been \ndescribed elsewhere [15,16]. In this section techniques that \nfurther contribute to the flexibility of the evolving fuzzy \nrule-based model will be introduced. They are based on \non-line monitoring and analysis of the quality of the rule base \nthrough the age and utility of the fuzzy rules. \nAge of the cluster and respectively of the fuzzy rule was \nfirst introduced in [25]. Here we introduce a simpler \nformula:   \n],1[;)()(\n)(\n1 Ri\nkN\nI\nkkAge\ni\nkN\nl\nl\ni\nl\n=\u2212=\n\u00a6\n=\n (22) \nwhere I denotes the time index of the moment when the \nrespective data sample was read; \n The Age indicates how old is the information that \nsupports certain fuzzy rule (data that are associated with \ncertain cluster). One can monitor on-line the Age of each \nfuzzy rule and compare this with the mean Age that is \ndetermined as \u00a6\n=\n=\nR\ni\ni kAgeR\nkAge\n1\n)(1)(  which can be \nupdated on-line. One can use the Age of the rule to remove \nolder rules [25] or to detect concept drift which corresponds \nto the inflexed point of the Age curve (the point when the \nderivative of Age in terms of time index, ( )\ndk\nAged changes \nits sign [26].  In Fig 1, the through monitoring the age of the \nfuzzy rules one can detect two major operating shifts in the \nprocess at sample 2250 and sample 2689. Around sample \n2250, the 6th rule is activated significantly more frequently \nthan other rules and its aging slower. Around sample 2689, \n918 2008 IEEE International Conference on Fuzzy Systems (FUZZ 2008)\n  \n \nthe system switches back to the previous status and the 2nd \nrule becomes \u201cyounger\u201d while the 6th rule gets \u201colder\u201d being \nactivated less. \nThe utility of a fuzzy rule is introduced in [23] to represent \nthe degree of support of a fuzzy rule. While the support of a \ncluster (respectively fuzzy rule) determined as the number of \ndata samples associated to a certain cluster\/rule based on the \nminimum distance criteria [25] determines a crisp (integer) \nnumber of data samples that support certain cluster \n(respectively fuzzy rule) the utility can be seen as a fuzzy \nmeasure of the support of a fuzzy rule. It is defined [23] as \nthe accumulated firing strength of the respective fuzzy rule \nfor the span of its life: \n],1[;)( 1 Ri\ntk\nk\ni\nk\nl\nl\ni =\n\u2212\n=\n\u00a6\n=\n\u03bb\n\u03b7  (23) \nwhere it  denotes the time instant when the i\nth\n fuzzy rule has \nbeen generated.   \nUtility, i\u03b7 accumulates the weight of the rule \ncontributions to the overall output during the life of the rule \n(from the current time instant back to the moment when this \nrule was generated). It is a measure of importance of the \nrespective fuzzy rule comparing to the other rules \n(comparison is hidden in the relative nature of \u021c (see \nequation (18)). In Fig. 2 one can observe that the usage \n(utility) of some fuzzy rules (e.g. rules 1 and 2) is gradually \ndiminished during the process after sample 500, while the \nutility of some other rules is increased (e.g. rules 5 and 7).  \nThe evolution of Age and Utility of specific fuzzy rules \nthroughout the process of on-line design and use of TS fuzzy \nsystems with industrial data is illustrated in Figure 1 and 2. \nMarginal rules (rules for which 2\u03b5\u03b7 <i ; where 2\u03b5 is the \nlevel of utility below which it is deemed to be marginal) are \nbeing removed (suggested value is 3 to 5%). \n \n    Figure 1 Age analysis for Propylene synthesis. \n \n    Figure 2 Utility evolution for Propylene synthesis. \nV. EXPERIMENTAL RESULTS \nA number of experiments were carried out on data streams \nfrom several real industrial processes. Each data stream was \ntested with four different settings of the eTS in order to \nanalyse the effects and the performance of the advanced \nfeatures introduced in this paper.  The first test is based on \nthe basic eTS without on-line input selection (OIS) and \nmarginal rules removal (MRR); the second test is of eTS \nwith OIS only; the third test is of eTS with by MRR only; and \nthe last test is of eTS enhanced by both OIS and MRR. The \noverall performance of the proposed approach was analyzed \nbased on a comparison of these experiments on different \nindustrial data sets. In order for a comparison to demonstrate \nthe general accuracy of the proposed approach, the data sets \nare also tested with the well established conventional offline \nfuzzy approaches such as ANFIS [31]. In the test with \nANFIS each data set is separated into training set and test \nset. The training set is used for the offline training and the \nbenchmark tests were carried on the test sets. The three data \nsets were also tested with a number of established and recent \napproaches, including a feed-forward - back-propagation \nneural network, and DENFIS [32]. Note that the proposed \nsystem can be implemented as a soft sensor [8] which may \nalso be realized as an embedded system (due to the efficient \nrecursive calculations it is possible to realize the algorithm \non chip [30]). \nA. Oil refinery case study  \nThis data set contains 447 data samples obtained from a \ncrude oil distillation plant in CEPSA oil refinery located in \nSanta Cruz, Tenerife, Spain (courtesy of Dr. J. J. Macias \nHernandez). The aim is to predict the inflammability point \nby so called Abel index in the process of production of \nkerosene. Since eTS can work in real-time in online mode, it \nis considered a promising tool to monitor the quality [8]. The \nAbel index can be used to guide the operations of process \ncontrol in a safe and productive way. Conventionally, this \nanalysis is carried out with the use of laboratory analysis \n2008 IEEE International Conference on Fuzzy Systems (FUZZ 2008) 919\n  \n \nperiodically, usually on hourly or daily basis. Predictions \nwere based on hourly average estimation. However, such \nperiodical estimation does not closely correspond to the \nchanges in the dynamic process. As common for the \nlaboratory-based benchmarks, the performance was \nmeasured based on the standard deviation over the absolute \nerrors between real outputs and the predictions: \n\u00a6\u2212\n=\n\u2212\n\u2212\n=\n1\n1\n2)()\n1\n1(\nvalN\ni\ni\nvalN\ne \u03b5\u03b5  (24) \nWhere e is the measurement; Nval is the number of samples \nduring the validation period; \u03b5 denotes the absolute error.  \nNormally, e lower than 5 is an acceptable accuracy range [8]. \nIt is demonstrated that the proposed technique can \nproduce acceptable precision in modeling (the numerical \nresults are tabulated in Table I) and can also generate a well \ninterpretable rule-base that can be very helpful to the process \noperators. \n \nFinal Rule base in the Abel inflammability test \nR1: IF (P is 5.4%) AND (Tco is 323.3 oC) AND \u2026 \nAND (Tne is 126.8 oC)   \nTHEN (A1=20.2 + 92.7P + \u2026 + 0.12 Tne)  \nR\n 2: IF (P is 11.7%) AND (Tco is 365.0 oC) AND \u2026  \nAND (Tne is 147.6 oC)   \nTHEN (A2=42.1 + 63.4P + \u2026 + 0.10 Tne)  \nR\n 3: IF (P is 5.4%) AND (Tco is 335.14 oC) AND \u2026   \nAND (Tne is 136.1 oC)    \nTHEN (A3=25.2 + 71.9P + \u2026 + 0.19 Tne)  \nB. Propylene case study  \nThe propylene data set is collected from a chemical \ndistillation process run at The Dow Chemical Co., USA \n(courtesy of Dr. A. Kordon, [26]). The data set consists of \n3000 readings from 23 sensors that are on the plant. They are \nused to predict the propylene content in the product output \nfrom the distillation. Some of the inputs may be irrelevant to \nthe model and thus bring noise. Therefore the input selection \nis very important task, which is usually done off-line as a part \nof the pre-processing. \nInstead, the procedure proposed in this paper is on-line \nand leads to an effective selection of the small subset of the \ninputs. One can see that there are two significant shifts in the \noperating condition which took place, which tests the online \nlearning ability of the system in a new condition. The results \n(tabulated in Table II) illustrate the online feature selection; \nthe two most informative inputs were selected after 130 \nsamples have been processed. From Table II it is seen that \nusing all the proposed advanced features of eTS a compact \nfuzzy model of 7 fuzzy rules and two inputs (fuzzy sets per \nrule) can be evolved on-line which also provides the best \nprecision. This demonstrates that highly compact, \ntransparent and interpretable fuzzy models can be designed \nfrom data streams on-line using eTS with the enhancement \nfeatures as described in this paper. \nFinal Rule-base for Propylene: \nR1: IF (x1 is 24.6) AND (x2 is 26.3)  \nTHEN ( 21 324.0039.0 xxy \u2212+\u2212= )  \nR2: IF (x1 is 39.0) AND (x2 is43.5)  \nTHEN ( 21 340.077.4615.0 xxy \u2212+\u2212= ) \nR3: IF (x1 is 46.2) AND (x2 is 49.5)  \nTHEN ( 21 450.0090.1679.0 xxy ++\u2212= )  \nR4: IF (x1 is 45.9) AND (x2 is 49.9)  \nTHEN ( 21 032.3570.5340.1 xxy \u2212+\u2212= ) \nR5: IF (x1 is 36.2) AND (x2 is 43.5)  \nTHEN ( 21 065.0320.0002.0 xxy \u2212+\u2212= ) \nR6 IF (x1 is 31.6) AND (x2 is 38.7)  \nTHEN ( 21 129.0366.0007.0 xxy \u2212+\u2212= )  \nR7 IF (x1 is 40.6) AND (x2 is  39.5)  \nTHEN ( 21 345.0406.0527.0 xxy \u2212+\u2212= )  \nAs shown in Figure 3 the more important inputs quickly \nbecome distinct indicated by their importance described by \n(20). \nTABLE I \nRESULTS FOR PREDICTING QUALITY OF THE CRUDE OIL DISTILLATION \nSetting Rules inputs rmse e \nNeural Network (off-line) - 7 2.87 3.43 \nANFIS (off-line) 29 7 2.15 2.25 \nDENFIS 29 7 2.46 - \neTS without OIS and MRR 5 7 2.29 2.37 \neTS with OIS only 9 5 2.30 2.38 \neTS with MRR 3 7 2.19 2.28 \neTS with OIS and MRR 3 6 2.18 2.27 \nTABLE II \nRESULTS FOR PREDICTING PROPYLENE CONTENT OF DISTILLATION \nMethod Rules inputs rmse Correl \nNN (off-line) - 23 0.11 0.963 \nANFIS (off-line) 29 23 0.11 0.972 \nDENFIS 235 23 0.11 0.979 \neTS without OIS & MRR 23 23 0.10 0.981 \neTS with OIS only 23 2 0.09 0.982 \neTS with MRR only 14 23 0.12 0.974 \neTS with OIS and MRR 7 2 0.09 0.983 \n \n920 2008 IEEE International Conference on Fuzzy Systems (FUZZ 2008)\n  \n \n \n \n \nFigure 3 Importance of inputs - at time instances k=20 and 120 \nC. NOx emission case study  \nThe last data set was collected from car engines (courtesy \nof Dr. E. Lughofer, University of Linz Austria) to estimate \nthe NOx\n \ncontent in the emissions that they produce based on \nthe variables that are easy to measure, such as pressure in the \ncylinders, engine torque, rotation speed, etc. [20]. In total as \nmuch as 180 input variables are considered as potential \ninputs (these also include the physical variables described in \nthe previous sentence taken at different time instants, i.e. \nwith different time delay).  In [20] we used off-line input \nvariable selection method and common knowledge to \ndetermine the best 5 inputs. Instead, in this paper we start \nprocessing all the data inputs available and select the best \nsubset automatically on-line. When we apply on-line inputs \nselection only the end result is a fuzzy model with 101 inputs \nand 36 fuzzy rules; when we combine this with the use of \nutility for removal of marginal fuzzy rules we automatically \nevolve a fuzzy Takagi-Sugeno model with 7 inputs and 13 \nfuzzy rules (see all the results in Table III). Moreover, the \nprediction error is lower with the model that has inputs \nselected automatically.  \nThe evolution of the utility for each fuzzy rule is \nillustrated in Figure 4. It was generated based on the test \nkeeping all the generated rules for the whole testing period. \nThe utility of certain rules become lower over the time.  \nIt is interesting to notice that in Table III, the rule removal \nhelps reducing the finally selected inputs. The reason is that \nthe criteria verifying each input based on the importance of \nthe inputs, \u03c9  as described in (21) is checked for each rule \none by one, rather than on all rules as a whole.  Dropping the \nmarginal rules also leads to a removal of some inputs, and \nconsequently causes the inputs to be dropped out.  \n \n \nFigure 4 Evolution of the utility of the fuzzy rules at time instances k=200 \nand k=500 \nVI. ACKNOWLEDGEMENTS \nThe authors are thankful to Dr. Arthur Kordon from The \nDow Chemical, Dr. Jose Macias Hernandez from CEPSA, \nTenerife, Spain, and Dr. Edwin Lughofer from Johannes \nKepler University of Linz, Austria for providing \nexperimental data. \nVII. CONCLUSION AND DISCUSSION \nA new approach to fuzzy systems structure learning form \ndata streams is proposed in the paper that takes the recently \nintroduced evolving fuzzy Takagi-Sugeno (eTS) models \nTABLE III \nRESULTS FOR NOX CAR EMISSION ANALYSIS  \nModel Rules inputs rmse Correl \nNN (off-line) - 180 0.15 0.934 \nDENFIS 113 180 0.17 0.917 \nANFIS 32 180 0.15 0.932 \neTS without OIS & MRR 22 180 0.17 0.914 \neTS with OIS only 36 101 0.13 0.947 \neTS with MRR only 14 180 0.17 0.908 \neTS with OIS and MRR 13 7 0.15 0.935 \n2008 IEEE International Conference on Fuzzy Systems (FUZZ 2008) 921\n  \n \nfurther. The novelty lies in the combination of techniques \nthat allow for a truly flexible and open (expandable and \nshrinking) structure of the fuzzy rule base and fuzzy sets to \nbe designed on-line. This includes a new approach for fuzzy \nrules (respectively clusters) utility and age \u2013 based structure \nsimplification, a new approach for automatic gradual \nselection of most influential inputs (features) based on \nconsequents parameter evaluation and sensitivity analysis, \nand an enhanced method for antecedents learning by data \npartitioning, including spreads update. All these new and \nimproved techniques were approbated on a range of \nindustrial-based data sets in Section V and demonstrated that \nvery compact and efficient flexible (with open and adaptive \nstructure) fuzzy systems (in particular of TS type) can be \ngenerated from data streams on line (possibly in real time). \nThe evolution of quality estimation parameters of the fuzzy \nsystem structure (such as age, utility, spread, number of \ninputs\/features) was illustrated on specific case studies and \nhas been analyzed.  \nREFERENCES \n[1] L. Kuncheva, Fuzzy Classifiers, Physica-Verlag, 2000, ISBN \n3-7908-1298-6. \n[2] D. Nauck, R. Kruse, A Neuro-fuzzy method to learn fuzzy \nclassification rules from data, Fuzzy Sets and Systems, Vol. 89, pp. \n277-288, 1997. \n[3] K. J. Cios, W. Pedricz, R.W. Swinarski (1998) Data Mining Methods \nfor Knowledge Discovery, Boston, MA, USA: Kluwer Academic \nPress. \n[4] J. A. Roubos, M. Setnes (2001). Compact and transparent fuzzy \nmodels and classifiers through iterative complexity reduction. IEEE \nTransactions on fuzzy systems, 9, 516-524. \n[5] R. Babuska, Fuzzy Modeling for Control, Kluwer Academic \nPublishers, Boston, USA, 1998. \n[6] P. Angelov, C. Xydeas, Fuzzy Systems Design: Direct and Indirect \nApproaches, Soft Computing, special issue on New Trends in the \nFuzzy Modelling part I: Novel Approaches, vol. 10 (9), July 2006, \npp.836-849. \n[7] X. Zhou, P. Angelov, \u201cAutonomous Visual Self-localization in \nCompletely Unknown Environment using Evolving Fuzzy \nRule-based Classifier\u201d, Proc. IEEE Intern. Conf. on Comput. \nIntelligence Applic. for Defense and Security, Honolulu, USA, 1-5 \nApril 2007, pp. 131-138. \n[8] J. J. Macias-Hernandez, P. Angelov, X. Zhou, Soft Sensor for \nPredicting Crude Oil Distillation Side Streams using Takagi-Sugeno \nEvolving Fuzzy Models, Proc. 2007 IEEE Intern. Conf. on Systems, \nMan, and Cybernetics, 7-10 Oct., 2007, Montreal, Canada, ISBN \n1-4244-0991-8\/07, pp.3305-3310.  \n[9] A. Elgammal, R. Suraiswami, D. Harwood, and L. Davis, \n\u201cBackground and Foreground modeling using non-parametric Kernel \nDensity Estimation for visual surveillance KDE\u201d, Proc. 2002 IEEE \nVol. 90 (7), pp. 1151 \u2013 1163.  \n[10] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical \nLearning: Data Mining, Inference and Prediction. Heidelberg, \nGermany: Springer Verlag, 2001. \n[11] D. Specht, \"A general regression neural network\", IEEE Transactions \non Neural Networks, vol. 2 , No 6, pp. 568-576, 1991. \n[12] R. R. Yager, D. P. Filev, \"Learning of fuzzy rules by mountain \nclustering, Proc. SPIE Conf. on Appl. of Fuzzy Logic Technology, \nBoston, MA, USA, pp. 246-254, 1993. \n[13] S. L. Chiu, \"Fuzzy model identification based on cluster estimation\", \nJ. of Intel. and Fuzzy Syst. vol. 2, pp. 267-278, 1994. \n[14] P. Angelov, \u201cAn Approach for Fuzzy Rule-base Adaptation using \nOn-line Clustering\u201d, International Journal of Approximate \nReasoning, Vol. 35 , No 3, March 2004, pp. 275-289. \n[15] P. Angelov, D. Filev, \u201cAn Approach to On-line Identification of \nTakagi-Sugeno Fuzzy Models\u201d, IEEE Transactions on System, Man, \nand Cybernetics, part B - Cybernetics, vol.34, No1, 2004, \npp.484-498. ISSN 1094-6977.  \n[16] P. Angelov, X. Zhou, \u201cEvolving fuzzy systems from data streams in \nReal time,\u201d In Proc. 2006 International Symposium on Evolving \nFuzzy Systems, Ambleside, Lake District, UK pp. 29-35, IEEE Press. \n[17] P. Angelov, \u201cEvolving Rule-based Models: A Tool for Design of \nFlexible Adaptive Systems\u201d. Heidelberg, Germany: Springer, 2002. \n[18] P. Angelov, J. Victor, A. Dourado, D. Filev, On-line evolution of \nTakagi-Sugeno Fuzzy Models, In Proc. 2nd IFAC Workshop on \nAdvanced Fuzzy\/Neural Control,16-17 September 2004, Oulu, \nFinland, pp.67-72. \n[19] P. Angelov, X. Zhou, F. Klawonn, \u201cEvolving Fuzzy Rule-based \nClassifiers\u201d, In Proc. 2007 IEEE Symposium on Computational \nIntelligence in Image and Signal Processing, CIISP 2007, Honolulu, \nHI, USA, 1-5 April 2007, pp.220-225. \n[20] P. Angelov, E. Lughofer. P. E. Klement, Two Approaches for \nData-Driven Design of Evolving Fuzzy Systems: eTS and FLEXFIS, \nThe 2005 North American Fuzzy Information Processing Society \nAnn. Conf., June 21-25 2005, Ann Arbor, Michigan, USA, pp.31-35. \n[21] P. Angelov, R. Ramezani, X. Zhou, Autonomous Novelty Detection \nand Object Tracking in Video Streams using Evolving Clustering and \nTakagi-Sugeno type Neuro-Fuzzy System, 2008 World Congress on \nComput. Intel., WCCI-2008, Hong Kong, June 2008, to appear. \n[22] R. Yager, D. Filev, R. R. Yager, D. P. Filev, Essentials of Fuzzy \nModeling and Control, NY: John Wiley, 1994. \n[23] P. Angelov, Machine Learning (Collaborative Systems) UK patent \napplication, GB-0621734.3, 1 November 2006. \n[24] G. Smits, A. Kordon, E. Jordaan . C. Vladislavleva, and M. \nKotanchek, Variable Selection in Industrial Data Sets Using Pareto \nGenetic Programming,  In: Yu T., R. Riolo, B. Worzel (Eds): Genetic \nProgramming Theory & Practice III. Springer, NY, pp. 79-92, 2006.  \n[25] P. Angelov, D. Filev, Simpl_eTS: A Simplified Method for Learning \nEvolving Takagi-Sugeno Fuzzy Models, The 2005 IEEE \nInternational Conference on Fuzzy Systems FUZZ-IEEE, Reno, Las \nVegas, USA, 22-25 May 2005, pp.1068-1073. \n[26] P. Angelov, A. Kordon, X. Zhou, Evolving Fuzzy Inferential Sensors \nfor Process Industry, 3rd Int. Workshop on Genetic & Evolving Fuzzy \nSyst., 4-7 March, 2008, Witten-Bomerholz, Germany, to appear. \n[27] G. A. Carpenter and S. Grossberg, \u201cAdaptive Resonance Theory \n(ART),\u201d in The Handbook of Brain Theory and Neural Networks, M. \nA. Arbib, Ed. Cambridge, MA: MIT Press, 1995, pp. 79\u201382. \n[28] R. Gray, \u201cVector quantization,\u201d IEEE ASSP Magazine, pp. 4\u201329, \n1984. \n[29] E. Lughofer, E. Huellermeier, and E. Klement, \u201cImproving the \ninterpretability of data-driven evolving fuzzy systems,\u201d in \nProceedings of EUSFLAT 2005, Barcelona, Spain, 2005, pp. 28\u201333. \n[30] M. Everett, P. Angelov, EvoMap: On-Chip Implementation of \nIntelligent Information Modelling using EVOlving MAPping, Tech. \nReport, 2005, Lancaster University, Lancaster, UK, pp.1-15. \n[31] J. S. R. Jang, ANFIS: Adaptive Network-based Fuzzy Inference \nSystems, IEEE Trans. on Systems, Man & Cybernetics, part B \u2013 \nCybernetics, vol. 23, No 3, 1993, pp. 665 - 685.  \n[32] N. Kasabov and Q. Song, DENFIS: Dynamic Evolving Neural-Fuzzy \nInference System and Its Application for Time-Series Prediction, \nIEEE Trans. on Fuzzy Systems, vol.10, No. 2, 2002, pp. 144 - 154.  \n \n \n \n922 2008 IEEE International Conference on Fuzzy Systems (FUZZ 2008)\n"}
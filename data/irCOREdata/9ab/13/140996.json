{"doi":"10.1016\/j.jprocont.2005.04.007","coreId":"140996","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/925","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/925","10.1016\/j.jprocont.2005.04.007"],"title":"A Formulation of nonlinear model predictive control using automatic\ndifferentiation","authors":["Cao, Yi"],"enrichments":{"references":[{"id":37923513,"title":"ADOL-C: A package for the automatic di\ufb00erentiation of algorithms written in C\/C++,","authors":[],"date":"1996","doi":"10.1145\/229473.229474","raw":"A. Griewank, D. Juedes, J. Utke, ADOL-C: A package for the automatic di\ufb00erentiation of algorithms written in C\/C++, ACM Transactions on Mathematical Software 22 (1996) 131\u2013167.","cites":null},{"id":37923525,"title":"Allg\u00a8 ower, A computationally attractive nonlinear predictive control scheme with guaranteed stability for stable systems,","authors":[],"date":"1998","doi":"10.1016\/s0959-1524(98)00021-3","raw":"H. Chen, F. Allg\u00a8 ower, A computationally attractive nonlinear predictive control scheme with guaranteed stability for stable systems, Journal of Process Control 8 (5\u20136) (1998) 475\u2013485.","cites":null},{"id":37923533,"title":"Applied Process Control \u2013 A Case Study,","authors":[],"date":"1989","doi":null,"raw":"R. Newell, P. Lee, Applied Process Control \u2013 A Case Study, Prentice Hall, Englewood Cli\ufb00s, NJ, 1989.","cites":null},{"id":37923508,"title":"Automatic Di\ufb00erentiation: Techniques and Applications,","authors":[],"date":"1981","doi":"10.1007\/3-540-10861-0","raw":"L. Rall, Automatic Di\ufb00erentiation: Techniques and Applications, Lecture Notes in Computer Science, Vol. 120, Springer Verlag, Berlin, 1981.","cites":null},{"id":37923532,"title":"Cheap newton steps for optimal control problems: automatic di\ufb00erentiation and Pantoja\u2019s algorithm,","authors":[],"date":"1999","doi":"10.1080\/10556789908805736","raw":"B. Christianson, Cheap newton steps for optimal control problems: automatic di\ufb00erentiation and Pantoja\u2019s algorithm, Optimization Methods and Software 10 (5) (1999) 729\u2013743.","cites":null},{"id":37923518,"title":"Computation of state and input trajectories for \ufb02at systems using automatic di\ufb00erentiation,","authors":[],"date":"2004","doi":"10.1016\/j.automatica.2003.10.018","raw":"K. R\u00a8 obenack, O. Vogel, Computation of state and input trajectories for \ufb02at systems using automatic di\ufb00erentiation, Automatica 40 (2004) 459\u2013464.","cites":null},{"id":37923493,"title":"Computational issues in nonlinear predictive control,","authors":[],"date":"1993","doi":"10.1016\/0098-1354(93)80027-k","raw":"P. B. Sistu, R. S. Gopinath, B. W. Bequette, Computational issues in nonlinear predictive control, Comput. Chem. Eng. 17 (1993) 361\u2013367.","cites":null},{"id":37923504,"title":"CVODES: An ODE solver with sensitivity analysis capabilities,","authors":[],"date":"2003","doi":"10.1115\/detc2005-85597","raw":"R. Serban, A. C. Hindmarch, CVODES: An ODE solver with sensitivity analysis capabilities, Tech. Rep. UCRL-JP-200039, Lawrence Livermore National Laboratory, U.S. Department of Energy (2003).","cites":null},{"id":37923510,"title":"Evaluating Derivatives,","authors":[],"date":"2000","doi":"10.1137\/1.9780898717761","raw":"A. Griewank, Evaluating Derivatives, SIAM, Philadelphia, PA, 2000.","cites":null},{"id":37923505,"title":"Evaluating gradients in optimal control: Continuous adjoint versus automatic di\ufb00erentiation,","authors":[],"date":"2004","doi":"10.1023\/b:jota.0000041731.71309.f1","raw":"R. Griesse, A. Walther, Evaluating gradients in optimal control: Continuous adjoint versus automatic di\ufb00erentiation, Journal of Optimization Theory and Applications 122 (1) (2004) 63\u201386.","cites":null},{"id":37923495,"title":"Introduction to model based optimization of chemical processes on moving horizons, in:","authors":[],"date":"2001","doi":"10.1007\/978-3-662-04331-8_18","raw":"T. Binder, L. Blank, H. Bock, R. Bulirsch, W. Dahmen, M. Diehl, T. Kronseder, W. Marquardt, J. Schloder, O. Stryk, Introduction to model based optimization of chemical processes on moving horizons, in: M. Gr\u00a8 otschel, S. Krumke, J. Rambau (Eds.), Online Optimization of Large Scale Systems: State of Art, Springer, 2001, pp. 295\u2013340.","cites":null},{"id":37923506,"title":"Nonlinear model predictive control using automatic di\ufb00erentiation, in:","authors":[],"date":"2003","doi":"10.1016\/j.jprocont.2007.10.012","raw":"Y. Cao, R. Al-Seyab, Nonlinear model predictive control using automatic di\ufb00erentiation, in: European Control Conference (ECC 2003), Cambridge, UK, 2003, p. in CDROM.","cites":null},{"id":37923500,"title":"Obtaining sensitivity information in dynamic optimization problems solved by the sequential approach,","authors":[],"date":"1999","doi":"10.1016\/s0098-1354(99)00010-1","raw":"S.Storen, T.Hertzberg, Obtaining sensitivity information in dynamic optimization problems solved by the sequential approach, Computers and Chemical Engineering 23 (1999) 807\u2013819.","cites":null},{"id":37923516,"title":"ODE solving via automatic di\ufb00erentiation and rational prediction, in:","authors":[],"date":"1995","doi":"10.1007\/3-540-62598-4_85","raw":"A. Griewank, ODE solving via automatic di\ufb00erentiation and rational prediction, in: D. Gri\ufb03ths, G. Watson (Eds.), Numerical Analysis 1995, Vol. 344 of Pitman Research Notes in Mathematics Series, Addison-Wesley., Reading, MA, 1995.","cites":null},{"id":37923527,"title":"Optimal Control: An Introduction to the Theory and Its Applications,","authors":[],"date":"1966","doi":null,"raw":"M. Athans, P. L. Falb, Optimal Control: An Introduction to the Theory and Its Applications, McGraw-Hill, New York, 1966.","cites":null},{"id":37923507,"title":"R.H.Luecke, Rapid computation of the jacobian matrix for optimization of nonlinear dynamic processes,","authors":[],"date":"1986","doi":"10.1016\/0098-1354(86)87007-7","raw":"A.M.Morshedi, H.Y.Lin, R.H.Luecke, Rapid computation of the jacobian matrix for optimization of nonlinear dynamic processes, Computers and Chemical Engineering 10 (4) (1986) 367\u2013376.","cites":null},{"id":37923509,"title":"Reverse accumulation and accurate rounding error estimates for taylor series.,","authors":[],"date":"1992","doi":"10.1080\/10556789208805508","raw":"B. Christianson, Reverse accumulation and accurate rounding error estimates for taylor series., Optimization Methods and Software 1 (1992) 81\u201394.","cites":null},{"id":37923501,"title":"Sensitivity analysis of linearlyimplicit di\ufb00erential-algebraic systems by one-step extrapolation,","authors":[],"date":"2004","doi":"10.1016\/j.apnum.2003.07.001","raw":"M. Schlegel, W. Marquardt, R. Ehrig, U. Nowak, Sensitivity analysis of linearlyimplicit di\ufb00erential-algebraic systems by one-step extrapolation, Applied 11Numerical Mathematics 48 (2004) 83\u2013102.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2005-12-01T00:00:00Z","abstract":"An efficient algorithm is developed to alleviate the computational burden\nassociated with nonlinear model predictive control (NMPC). The new algorithm\nextends an existing algorithm for solutions of dynamic sensitivity from\nautonomous to non-autonomous differential equations using the Taylor series and\nautomatic differentiation (AD). A formulation is then presented to recast the\nNMPC problem as a standard nonlinear programming problem by using the Taylor\nseries and AD. The efficiency of the new algorithm is compared with other\napproaches via an evaporation case study. The comparison shows that the new\nalgorithm can reduce computational time by two orders of magnitude","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/140996.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/10.1016\/j.jprocont.2005.04.007","pdfHashValue":"b4328085207fffbb45f555f419fec4b4010258d1","publisher":"Elsevier Science B.V., Amsterdam.","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/925<\/identifier><datestamp>2011-11-13T23:28:14Z<\/datestamp><setSpec>hdl_1826_19<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>A Formulation of nonlinear model predictive control using automatic\ndifferentiation<\/dc:title><dc:creator>Cao, Yi<\/dc:creator><dc:subject>Predictive control<\/dc:subject><dc:subject>Optimal control<\/dc:subject><dc:subject>Dynamic sensitivity<\/dc:subject><dc:description>An efficient algorithm is developed to alleviate the computational burden\nassociated with nonlinear model predictive control (NMPC). The new algorithm\nextends an existing algorithm for solutions of dynamic sensitivity from\nautonomous to non-autonomous differential equations using the Taylor series and\nautomatic differentiation (AD). A formulation is then presented to recast the\nNMPC problem as a standard nonlinear programming problem by using the Taylor\nseries and AD. The efficiency of the new algorithm is compared with other\napproaches via an evaporation case study. The comparison shows that the new\nalgorithm can reduce computational time by two orders of magnitude.<\/dc:description><dc:publisher>Elsevier Science B.V., Amsterdam.<\/dc:publisher><dc:date>2011-11-13T23:28:14Z<\/dc:date><dc:date>2011-11-13T23:28:14Z<\/dc:date><dc:date>2005-12-01T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>Yi Cao, A formulation of nonlinear model predictive control using automatic\ndifferentiation, Journal of Process Control, Volume 15, Issue 8, December 2005,\nPages 851-858.<\/dc:identifier><dc:identifier>0959-1524<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1016\/j.jprocont.2005.04.007<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/925<\/dc:identifier><dc:language>en_UK<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0959-1524","0959-1524"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2005,"topics":["Predictive control","Optimal control","Dynamic sensitivity"],"subject":["Article"],"fullText":"A Formulation of Nonlinear Model Predictive\nControl Using Automatic Differentiation\nYi Cao\nSchool of Engineering, Cranfield University, Bedford MK43 0AL, UK\nTel: (44)1234 750 111, Fax: (44)1234 750 728\nAbstract\nAn efficient algorithm is developed to alleviate the computational burden associ-\nated with Nonlinear Model Predictive Control (NMPC). The new algorithm ex-\ntends an existing algorithm for solutions of dynamic sensitivity from autonomous\nto non-autonomous differential equations using the Taylor series and automatic\ndifferentiation (AD). A formulation is then presented to recast the NMPC prob-\nlem as a standard nonlinear programming problem by using the Taylor series and\nAD. The efficiency of the new algorithm is compared with other approaches via an\nevaporation case study. The comparison shows that the new algorithm can reduce\ncomputational time by two orders of magnitude.\nKey words: Predictive Control, Optimal Control, Dynamic Sensitivity\n1 Introduction\nIn the last two decades, linear model predictive control has been well recog-\nnized by industry due to its intuitiveness and capability to handle multivari-\nable constraints. However, the extension to nonlinear model based predictive\ncontrol (NMPC) has not been so successful although a significant amount of\nresearch effort has been put into this area. One of the main obstacles, which\nblocks NMPC techniques to become widely applicable, is the computational\nburden associated with the requirement to solve a set of nonlinear differential\nequations and a nonlinear dynamic optimization problem in real-time.\nThe objective of NMPC is to determine a set of future control moves in order to\nminimize a cost function based on a desired output trajectory over a prediction\nEmail address: y.cao@cranfield.ac.uk (Yi Cao).\nPreprint submitted to Journal of Process Control 11 April 2005\nhorizon. The computation involved in solving the optimization problem at\nevery sampling time can become so intensive, particularly for high-dimensional\nsystems, that it could make on-line applications almost impossible [1]. There\nexist a number of strategies for tracking the optimal control problem through\nnonlinear programming (NLP) [2]: successive linearization, direct single and\nmultiple shooting methods, and others. To efficiently solve the NLP problem\nderived, all these approaches require intensive computation of derivatives. In\na typical situation, calculating dynamic sensitivity could take more than 70\npercent of the total computation time for NLP. Hence, dynamic sensitivity\ncalculation is the computational bottleneck of solving a dynamic optimization\nproblem. There are three ways to calculate sensitivity of a dynamic system [3]:\nperturbations, sensitivity equations and adjoint equations. In a perturbation\napproach finite differences are used to approximate derivatives. Hence it needs\nat least applying N perturbations to the dynamic system to get the solution\nof a N -parameter sensitivity problem [3]. Alternatively, sensitivity can also be\nobtained by simultaneously solving the original ordinary differential equations\n(ODE) together with nN sensitivity equations, where n is the number of\nstates [4]. Finally, sensitivity can be calculated by solving n adjoint equations\n(in reverse direction). A number of efficient solvers have been developed to\ntackle the dynamic sensitivity problem, for example, the CVODES package\n[5]. Recently, automatic differentiation (AD) techniques have been applied to\nsolve dynamic optimization problems [6]. In previous work [7], a first-order\napproximation is introduced to simply the dynamic sensitivity equation by\nusing AD so that the computation efficiency is improved. A similar approach\nhas been proposed in [8] without using AD. However, due to the first-order\napproximation, the sensitivity obtained may not be accurate enough in some\ncases, particularly for NMPC with process constraints. In most published work\nusing AD for dynamic optimization, AD has only been used to generate low\n(first and\/or second) order derivatives, therefore efficiency of these approaches\nis not satisfactory.\nIn this work, the advantages of AD techniques have been intensively utilized\nto improve the efficiency of NMPC. More specifically, an existing algorithm\nto solve ODE and sensitivity using high-order Taylor series and AD for au-\ntonomous systems is extended to non-autonomous systems. An approach to\nestimate and control the error due to truncation of the Taylor series is also\nprovided. Then, based on this algorithm, the NMPC problem has been re-\nformulated as a NLP problem so that it can be efficiently solved by any mod-\nern NLP solvers. The paper is organized as follows. After a brief overview\nof AD, its principles to solve autonomous ODE\u2019s and to calculate dynamic\nsensitivity are explained in section 2. Section 3 extends the techniques to non-\nautonomous systems. Then, a formulation of NMPC using AD is proposed in\nsection 4, where the issues of error analysis and control are also addressed. A\ncase study is presented in section 5 to show the usage and efficiency of the\nnew algorithm. Finally, the paper is concluded in section 6.\n2\n2 Automatic Differentiation\nAD is a class of computational techniques for evaluating derivatives of func-\ntions defined in computer programs [9]. It is superior to other two approaches:\nsymbolic differentiation and finite difference approximation. To compute deriva-\ntives symbolically using computer algebra software such as Mathematica or\nMaple, an enormous expression growth normally occurs due to a repeated eval-\nuation of common sub-expressions. On the other hand, with finite difference\napproximation, accuracy of derivatives is restricted because of cancellation\nand truncation errors, particularly, for high order derivatives. Automatic dif-\nferentiation techniques overcome these drawbacks by systematically applying\nthe chain rule to functions defined by arbitrary computer programs. A com-\nputer program is equivalent to a computational graph consisting of a sequence\nof elementary operations whose derivatives are well known. Hence, by numer-\nically applying the chain rule to these arithmetic sequences, not only can AD\ndeliver truncation-error free derivatives but it also avoids code growth.\n2.1 Taylor Series by AD\nConsider a d-time continuously differentiable function, f : Rn \u2192 Rm. Let\nx(t) \u2208 Rn be given by the truncated Taylor series: x(t) = x[0]+x[1]t+\u00b7 \u00b7 \u00b7+x[d]td,\nwith coefficients x[i] = (i!)\n\u22121(\u2202ix(t)\/\u2202ti)|t=0 \u2208 Rn. Then, z(t) = f(x(t)) \u2208 Rm\ncan be expressed by a Taylor expansion: z(t) = z[0]+z[1]t+\u00b7 \u00b7 \u00b7+z[d]td+O(td+1)\nwhere z[j] = (j!)\n\u22121(\u2202jz(t)\/\u2202tj)|t=0 \u2208 Rm. From the chain rule, z[j] is uniquely\ndetermined by the coefficient vectors, x[i] with i \u2264 j, i.e.\nz[j] \u2261 z[j](x[0],x[1], . . . ,x[j]) (1)\nNevertheless, inherently, functions z[j] are also d-time continuously differen-\ntiable and their derivatives satisfy the identity [10]:\n\u2202z[j]\n\u2202x[i]\n=\n\u2202z[j\u2212i]\n\u2202x[0]\n:= A[j\u2212i] \u2261 A[j\u2212i](x[0],x[1], . . . ,x[j\u2212i]) (2)\nwhere,A[j] \u2208 Rn\u00d7n, j = 0, . . . , d are also the Taylor coefficients of the Jacobian\npath, i.e. f \u2032(x(t)) = A0 +A1t+ \u00b7 \u00b7 \u00b7+Adtd +O(td+1).\nAD techniques provide an efficient way to calculate these coefficient vectors,\nz[j] and matrices, A[i] [11]. For example, with the software package, ADOL-\nC [12], by using the forward mode of AD, all Taylor coefficient vectors for\na given degree, d can be calculated simultaneously, whilst the matrices, A[i]\ncan be obtained by using the reverse mode of AD. The run time and memory\nrequirement associated with these calculations grow only in a order of d2.\n3\n2.2 Autonomous Differential Equation\nWhen the above approach is applied to an autonomous differential equation,\ni.e. x\u02d9 = f(x(t)), since x[k+1] = z[k]\/(k + 1), all Taylor coefficients of x(t) up\nto any order can be iteratively obtained from x[0] = x(0) by using (1) [13].\nMoreover, the sensitivity of Taylor coefficients against the initial value x[0] can\nalso be efficiently obtained by matrix accumulation from (2):\nB[k] :=\ndx[k]\ndx[0]\n=\n1\nk\ndz[k\u22121]\ndx[0]\n=\n1\nk\nk\u22121\u2211\nj=0\n\u2202z[k\u22121]\n\u2202x[j]\ndx[j]\ndx[0]\n=\n1\nk\nk\u22121\u2211\nj=0\nA[k\u2212j\u22121]B[j] (3)\nwhere B[k] \u2208 Rn\u00d7n, k = 0, . . . , d are the Taylor coefficients of the solution to\nthe sensitivity equations, B\u02d9 = f \u2032(x)B, B[0] = B(0) = I.\n3 Non-autonomous Systems\nAlthough the above algorithm is very efficient, to make it applicable for\nNMPC, the algorithm has to be extended to solving dynamic sensitivity of\nnon-autonomous state space systems:\nx\u02d9(t) = f(x(t),u(t)), x(0) = x[0] (4)\ny(t) = g(x(t),u(t)), 0 \u2264 t \u2264 h\nwhere, u(t) \u2208 Rm is the control input and y(t) \u2208 Rp the output. It is a normal\npractice, for example in [14], to convert the system (4) to autonomous by\naugmenting it with u\u02d9 = 0 so that the results described in the previous section\ncan be directly used. However, the augmented system has m extra differential\nequations, hence the algorithm is not efficient particularly when m is large. In\nthis work, an efficient approach is to be described as follows.\nUsing normalized time, \u03c4 = t\/h, the right-hand-side of the state equation\nbecomes z(x(\u03c4),u(\u03c4)) := hf(x(\u03c4),u(\u03c4)) and the solution interval is 0 \u2264 \u03c4 \u2264\n1. Assume u(\u03c4) = u[0] + u[1]\u03c4 + \u00b7 \u00b7 \u00b7 + u[r]\u03c4 r, r \u2264 d and all its coefficients,\nu[k], k = 1, . . . , r are known. Let v =\n[\nuT[0] \u00b7 \u00b7 \u00b7 uT[r]\n]T\n. Using AD, the Taylor\ncoefficients of x(\u03c4) and y(\u03c4) can be iteratively determined from x[0] and v.\nx[k+1] =\n1\nk + 1\nz[k](x[0], . . . ,x[k],v), k = 0, . . . , d\u2212 1 (5)\ny[k] = y[k](x[0], . . . ,x[k],v), k = 0, . . . , d (6)\nThen, by applying AD to (5) and (6), the partial derivatives are obtained and\n4\npartitioned as follows:\nA[k] =\n[\nA[k]\n\u2223\u2223\u2223 A[k]v] :=\n[\n\u2202z[k]\n\u2202x[0]\n\u2223\u2223\u2223\u2223\u2223 \u2202z[k]\u2202v\n]\n, k = 0, . . . , d\u2212 1 (7)\nC[k] =\n[\nC[k]x\n\u2223\u2223\u2223 C[k]v] :=\n[\n\u2202y[k]\n\u2202x[0]\n\u2223\u2223\u2223\u2223\u2223 \u2202y[k]\u2202v\n]\n, k = 0, . . . , d (8)\nThe total derivatives are accumulated from these partial derivatives as follows:\nB[k] =\n[\nB[k]x | B[k]v\n]\n:=\n[\ndx[k]\ndx[0]\n\u2223\u2223\u2223\u2223\u2223 dx[k]dv\n]\n=\n1\nk\n\uf8eb\uf8edA[k\u22121] + k\u22121\u2211\nj=1\nA[k\u2212j\u22121]xB[j]\n\uf8f6\uf8f8 , k = 1, . . . , d (9)\nD[k] =\n[\nD[k]x | D[k]v\n]\n:=\n[\ndy[k]\ndx[0]\n\u2223\u2223\u2223\u2223\u2223 dy[k]dv\n]\n= C[k] +\nk\u2211\nj=1\nC[k\u2212j]xB[j], k = 0, . . . , d (10)\nNote, B[0] =\n[\nI | 0\n]\n. In summary, the solutions of system (4) at t = h are\nx(h) =\nd\u2211\ni=0\nx[i], y(h) =\nd\u2211\ni=0\ny[i] (11)\nwhilst their sensitivities to initial value, x[0] and input coefficients, v are\nBx(h) :=\ndx(h)\ndx[0]\n=\nd\u2211\ni=0\nB[i]x = I+\nd\u2211\ni=1\nB[i]x (12)\nBv(h) :=\ndx(h)\ndv\n=\nd\u2211\ni=0\nB[i]v =\nd\u2211\ni=1\nB[i]v (13)\nDx(h) :=\ndy(h)\ndx[0]\n=\nd\u2211\ni=0\nD[i]x (14)\nDv(h) :=\ndy(h)\ndv\n=\nd\u2211\ni=0\nD[i]v (15)\n5\n4 Nonlinear Model Predictive Control\n4.1 Formulation\nFor nonlinear system (4), at current sampling time, t = t0, consider the general\noptimal control problem:\nmin\nu\nJ = \u03c8(x(tP ),u(tP )) +\n\u222b tP\nt0\n\u03d5(x(t),u(t))dt\ns.t. x\u02d9 = f(x(t),u(t)), x(t0) = x[0] (16)\n\u03be(x(t),u(t)) \u2264 0\n\u03b6(x(tP ),u(tP )) \u2264 0\nwhere \u03be \u2208 Rq and \u03b6 \u2208 Rs are trajectory and terminal constraints, respec-\ntively. The prediction horizon [t0, tP ] is divided into P intervals, t0, t1, . . . , tP\nwith ti+1 = ti + hi and\n\u2211P\u22121\ni=0 hi = tP \u2212 t0. Assume the optimal solution to\n(16) is u(t) =\n\u2211r\ni=0 u[i](tk)(t \u2212 tk)i for tk \u2264 t \u2264 tk+1, k = 0, . . . , P \u2212 1.\nThen, only the solution in the first interval is to be implemented and whole\nprocedure will be repeated at next sampling instance. Note, combination of\nthe terminal performance index \u03c8 and the terminal constraints \u03b6 is imposed\nso that the minimized performance index in the receding sequence decreases\nmonotonously. Hence, closed-loop stability under such moving horizon control\nis ensured [15].\nIt is well-known that the above Bolza form can be converted into the Mayer\nform [16]. For problem (16), augment system (4) by defining\n\u02d9\u00afx(t) = \u03d5(x(t),u(t)), x\u00af(t0) = 0\ny1(t) = \u03be(x(t),u(t))\ny2(t) = \u03b6(x(t),u(t))\ny\u00af(t) = \u03c8(x(t),u(t)) + x\u00af(t)\nx\u02dc(t) =\n\uf8ee\uf8ef\uf8f0x\nx\u00af\n\uf8f9\uf8fa\uf8fb , f\u02dc =\n\uf8ee\uf8ef\uf8f0f\n\u03d5\n\uf8f9\uf8fa\uf8fb , x\u02dc[0] =\n\uf8ee\uf8ef\uf8f0x[0]\n0\n\uf8f9\uf8fa\uf8fb\ny =\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\ny1\ny2\ny\u00af\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb , g =\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u03be\n\u03b6\n\u03c8 + x\u00af\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n6\nThen, the optimal control problem can be recast as\nmin\nu(t)\nJ = y\u00af(tP ) (17)\ns.t. \u02d9\u02dcx(t) = f\u02dc(x\u02dc(t),u(t)), x\u02dc(t0) = x\u02dc[0]\ny(t) = g(x\u02dc(t),u(t))\ny1(t) \u2264 0 y2(tP ) \u2264 0\nLet u[0](k), . . . ,u[r](k) be input coefficients at t = tk and v \u2208 Rm\u00d7(r+1)\u00d7P be\ndefined as:\nv :=\n[\nvT0 \u00b7 \u00b7 \u00b7 vTP\u22121\n]T\n(18)\nwhere vk :=\n[\nuT[0](k) \u00b7 \u00b7 \u00b7 uT[r](k)\n]T\n. For given vk, x\u02dc(k + 1) := x\u02dc(tk+1) and\ny(k) := y(tk) are iteratively determined from x\u02dc(k) using (11). Hence, (17) can\nbe represented in discrete form\nmin\nv\nJ = y\u00af(P ) (19)\ns.t. x\u02dc(k + 1) = fk(x\u02dc(k),vk), x\u02dc(0) = x\u02dc[0]\ny(k) = gk(x\u02dc(k),vk) 0 \u2264 k \u2264 P \u2212 1\ny1(k) \u2264 0, y2(P ) \u2264 0\nProblem (19) is a standard NLP problem with P \u00d7 m \u00d7 (r + 1) degrees of\nfreedom. The first order derivatives of J and constraints can be easily ob-\ntained by using (14) and (15) repeatedly. More specifically, define dy(k)\ndv\n=[\ndy(k)\ndv0\n\u00b7 \u00b7 \u00b7 dy(k)\ndvP\u22121\n]\nThen,\ndy(k)\ndvj\n=\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n0 k \u2264 j\nDv(j + 1) k = j + 1\nDx\u02dc(k)Bx\u02dc(k \u2212 1) \u00b7 \u00b7 \u00b7Bx\u02dc(j + 2)Bv(j + 1) k > j + 1\nHence, derivatives of J and constraints are obtained as\ndJ\ndv\n=\n[\ndy(P )\ndv\n]\nq+s+1\n,\ndy2(P )\ndv\n=\n[\ndy(P )\ndv\n]\nq+1:q+s\n,\ndy1(k)\ndvj\n=\n[\ndy(k)\ndv\n]\n1:q+1\nwhere [\u00b7]k stands for the k-th row of a matrix, and [\u00b7]a:b stands for rows of a\nmatrix from a-th to b-th.\nFor MPC with moving horizon, M < P , i.e. uk = uM\u22121, k = M, . . . , P \u2212 1,\nthe derivative against vM\u22121 is a summation of derivatives against vk, k =\nM \u2212 1, . . . , P \u2212 1, i.e. d\/dvM\u22121 = \u2211P\u22121k=M\u22121 d\/dvk.\nWith more advanced AD programming, the second order derivatives are also\n7\nreadily to be obtained [17]. Hence, using AD, the nonlinear model predictive\ncontrol problem can be efficiently solved by any modern NLP software.\n4.2 Error analysis and control\nBy using AD, the Taylor coefficients, x[i] and B[i] obtained using the above\nmethod are exact [11]. However, the ODE solution and sensitivity obtained at\nt = h are only approximations due to truncation of the Taylor series. Assume\nx(h) =\n\u2211d\nk=0 x[k]h\nk + \u03b5(h, d) and the radius of convergence is r. Then,\n\u03b5(h, d) \u2248 C(h\/r)d+1 (20)\nwhere C is constant. For a sufficiently large d,\nr \u2248 rd := \u2016x[d\u22121]\u2016\u221e\u2016x[d]\u2016\u221e (21)\nSince \u03b5(h, d\u2212 1) \u2248 \u03b5(h, d)(rd\/h) \u2248 \u03b5(h, d) + \u2016x[d]\u2016\u221e, it leads to an estimation\nof the truncation error:\n\u03b5(h, d) =\nh\u2016x[d]\u20162\u221e\n\u2016x[d\u22121]\u2016\u221e \u2212 h\u2016x[d]\u2016\u221e (22)\nFor a given error tolerance, \u03b4, if \u03b4 \u2264 \u03b5(h, d+1), either reducing h or increase d\ncan control the error to the required level. Using (22), the required adjustment\nin step (h1 = h\/c, c > 1) or in order (d1 = d + p, p > 0) to satisfy the error\nlevel can be derived:\nc =\nh\u2016x[d]\u2016\u221e(\u2016x[d]\u2016\u221e + \u03b4)\n\u2016x[d\u22121]\u2016\u221e (23)\np =\nln(\u03b4\/\u03b5(h, d))\nln(h\u2016x[d]\u2016\u221e\/\u2016x[d\u22121]\u2016\u221e) (24)\nThe judgement of which to be adjusted is based on the comparison of the\nnumber of operations to be increased. When reducing h by a factor of c, to\nreach the original step, h, the computation will increase of c times. On the\nother hand, if increasing d to d + p, computation will increase a factor of\n(1 + p\/d)2. Hence, after rounding to their nearest upper integers, if c >=\n(1+ p\/d)2, order will be increased by p. Otherwise, the step will be decreased\nby a factor of c.\nThe above error is the local error at each step. These errors will be propagated\ninto the final cost function. The propagation can be estimated by using the\n8\nsensitivity matrix, Bx(k) at each step, i.e. the global error at step k, \u03b5g(k) is\n\u03b5g(k) = \u03b5(hk, dk) + \u2016Bx(k)\u2016i\u221e\u03b5g(k \u2212 1) (25)\nwhere \u2016 \u00b7 \u2016i\u221e is the induced infinity norm of a matrix. For a given process,\nassume \u03b2 \u2265 \u2016Bx(k)\u2016i\u221e, k = 1, . . . , P . Then, at the end of prediction horizon,\nthe global error is estimated as\n\u03b5g(P ) \u2264 \u03b5(hP , dP ) + \u03b2\u03b5(hP\u22121, dP\u22121) + \u00b7 \u00b7 \u00b7+ \u03b2P\u22121\u03b5(h1, d1)\nAssume all local errors are controlled at the same level, \u03b4 and the desired\nglobal error level is \u03b4g. Then, the local error should be controlled at level\n\u03b4 =\n\u03b4g(\u03b2 \u2212 1)\n\u03b2P \u2212 1 (26)\n5 Case Study\n5.1 Evaporator\nThe NMPC formulation described so far is applied to the evaporation process\nof Newell and Lee [18], shown in Figure 1. The process variables are listed in\nTable 1 and model equations are given in Appendix.\n5.2 Nonlinear model predictive control\nThe control objective of the case study is to track setpoint changes of X2 from\n25% to 15% and P2 from 50.5 kPa to 70 kPa when disturbances, F1, X1, T1\nand T200 are varying within \u00b120% of their nominal values. The control system\nis configured with three manipulated variables, F2, P100 and F200 and three\nmeasurements, L2, X2 and P2. All manipulated variables are subject to a first-\norder lag with a time constant equal to 0.5 min and saturation constraints,\n0 \u2264 F2 \u2264 4, 0 \u2264 P100 \u2264 400 and 0 \u2264 F200 \u2264 400. All disturbances are\nunmeasured and simulated as random signals changing every 5 minutes and\npassing through a 0.2-min first-order lag.\nThe NMPC is designed with cost function: J =\n\u222b P\n0 (y \u2212 r)TW (y \u2212 r)dt,\nwhere y =\n[\nL2 X2 P2\n]T\nand r =\n[\n1 15 70\n]T\n. Design parameters are: sam-\npling period, h = 1 min, P = 10 min, input horizon M = 5 min and\nW = diag[100, 1, 1]. By using piecewise constant input, the result NLP prob-\nlem has 3\u00d7M = 15 degrees of freedom.\n9\nTo fully use the advantage of the above sensitivity algorithm, the NLP problem\nis solved as a nonlinear least square problem [7] using the solver lsqnonlin in\nMATLAB Optimization Toolbox. To solve the problem, total 30 \u00d7 15 = 450\nsensitivity variables have to calculated in addition to original 3 states. The\nsensitivity algorithm is implemented in C using ADOL-C and interfaced to\nMATLAB via a mex wrap. Simulation results with the above configuration are\nshown in Figure 2. It can be seen from Figure 2 that measured outputs follow\nthe setpoints quite well (a)\u2013(c) in spite of the existence of severe unmeasured\ndisturbances (g)\u2013(j). This is achieved without violating the input constraints\n(d)\u2013(f).\n5.3 Sensitivity algorithm comparison\nTo demonstrate the efficiency of the new algorithm to calculate sensitivity,\nthe algorithm is implemented in two AD approaches: operation overloading\nby using ADOL-C, and source transformation, by using a preliminary AD\nprogram (STTAD) developed by the author, both in C. These two programs,\nboth implemented with error control described in section 4.2, are compared\nwith one of the most advanced dynamic sensitivity solvers, CVODES [5]. The\ncomparison is based on the forward mode of CVODES, which simultaneously\nsolves the dynamic sensitivity with the original ODE. At each step, 3 states\nand 18 sensitivity variables (3 states against 3 initial values and 3 input values)\nare integrated, and then the sensitivity of the whole prediction horizon are\nobtained by accumulating these stepwise sensitivity variables. All tests are\ndone in a Windows XP PC with an Intel Pentium-4 processor running at 2.5\nGHz.\nFirstly, the computing times of these programs used in the above NMPC\nsimulation are compared and shown in the first part of Table 2. It is shown\nthat using the AD algorithm, the computation time is reduced by two orders of\nmagnitude (from 7.08 to 0.08), whilst the ratio of the sensitivity computation\ntime over total optimization time is reduced from over 40% to less than a\npercent. Hence, the original computation bottleneck does not exist when using\nthe algorithm proposed in the work. ADOL-C is a program for general AD\ncomputation. For a specific problem, operation overloading can introduce a\nsignificant amount of computation overheads, hence reducing the efficiency.\nThe comparison shows that for online application, source transformation is\nmore attractive than operation overloading.\nTo compare computation time associated with accuracy, a reference solution\nis produced by using CVODES program and setting the error tolerance to\nthe spacing of floating point number of double precision, i.e. \u03b4 = 2\u221252 =\n2.2204\u00d710\u221216. Then, with three tolerance settings, (1e-6, 1e-8 and 1e-11), com-\n10\nputation time and accuracy of three programs are compared in the second part\nof Table 2. The table shows that AD programs perform better than CVODES\nin both efficiency and accuracy. Particularly, STTAD consistently reduces\ncomputing time about two orders of magnitude comparing with CVODES.\nIt can be seen that the order of Taylor series plays an important role in er-\nror control. Increase the order by a few number, the error would be reduced\nby a number of orders of magnitude without increasing too much computa-\ntion time. However, using traditional approaches, like CVODES, significant\ncomputation time may have to be traded off for a reduction in computation\nerror.\n6 Conclusion\nA new algorithm to calculate non-autonomous dynamic sensitivity using AD\nbased Taylor coefficients has been proposed. Based on the new algorithm, a\nNMPC formulation has been presented. Approaches for computational error\nanalysis and control are also discussed. Due to the high-order Taylor series\nused, the new approach is very efficient and accurate. The feasibility of the\nnew algorithm is demonstrated via an evaporator case study, whilst its ef-\nficiency and accuracy are verified through the comparison with CVODES, a\nstate-of-the-art software package for solving dynamic sensitivity problems. The\ncase study shows that the typical computation bottleneck in solving dynamic\noptimization problems could be removed by using the proposed dynamic sen-\nsitivity algorithm. Hence, the approach described in this work is much suitable\nfor online application such as NMPC.\nReferences\n[1] P. B. Sistu, R. S. Gopinath, B. W. Bequette, Computational issues in nonlinear\npredictive control, Comput. Chem. Eng. 17 (1993) 361\u2013367.\n[2] T. Binder, L. Blank, H. Bock, R. Bulirsch, W. Dahmen, M. Diehl, T. Kronseder,\nW. Marquardt, J. Schloder, O. Stryk, Introduction to model based optimization\nof chemical processes on moving horizons, in: M. Gro\u00a8tschel, S. Krumke,\nJ. Rambau (Eds.), Online Optimization of Large Scale Systems: State of Art,\nSpringer, 2001, pp. 295\u2013340.\n[3] S.Storen, T.Hertzberg, Obtaining sensitivity information in dynamic\noptimization problems solved by the sequential approach, Computers and\nChemical Engineering 23 (1999) 807\u2013819.\n[4] M. Schlegel, W. Marquardt, R. Ehrig, U. Nowak, Sensitivity analysis of linearly-\nimplicit differential-algebraic systems by one-step extrapolation, Applied\n11\nNumerical Mathematics 48 (2004) 83\u2013102.\n[5] R. Serban, A. C. Hindmarch, CVODES: An ODE solver with sensitivity analysis\ncapabilities, Tech. Rep. UCRL-JP-200039, Lawrence Livermore National\nLaboratory, U.S. Department of Energy (2003).\n[6] R. Griesse, A. Walther, Evaluating gradients in optimal control: Continuous\nadjoint versus automatic differentiation, Journal of Optimization Theory and\nApplications 122 (1) (2004) 63\u201386.\n[7] Y. Cao, R. Al-Seyab, Nonlinear model predictive control using automatic\ndifferentiation, in: European Control Conference (ECC 2003), Cambridge, UK,\n2003, p. in CDROM.\n[8] A.M.Morshedi, H.Y.Lin, R.H.Luecke, Rapid computation of the jacobian matrix\nfor optimization of nonlinear dynamic processes, Computers and Chemical\nEngineering 10 (4) (1986) 367\u2013376.\n[9] L. Rall, Automatic Differentiation: Techniques and Applications, Lecture Notes\nin Computer Science, Vol. 120, Springer Verlag, Berlin, 1981.\n[10] B. Christianson, Reverse accumulation and accurate rounding error estimates\nfor taylor series., Optimization Methods and Software 1 (1992) 81\u201394.\n[11] A. Griewank, Evaluating Derivatives, SIAM, Philadelphia, PA, 2000.\n[12] A. Griewank, D. Juedes, J. Utke, ADOL-C: A package for the automatic\ndifferentiation of algorithms written in C\/C++, ACM Transactions on\nMathematical Software 22 (1996) 131\u2013167.\n[13] A. Griewank, ODE solving via automatic differentiation and rational prediction,\nin: D. Griffiths, G. Watson (Eds.), Numerical Analysis 1995, Vol. 344 of Pitman\nResearch Notes in Mathematics Series, Addison-Wesley., Reading, MA, 1995.\n[14] K. Ro\u00a8benack, O. Vogel, Computation of state and input trajectories for flat\nsystems using automatic differentiation, Automatica 40 (2004) 459\u2013464.\n[15] H. Chen, F. Allgo\u00a8wer, A computationally attractive nonlinear predictive control\nscheme with guaranteed stability for stable systems, Journal of Process Control\n8 (5\u20136) (1998) 475\u2013485.\n[16] M. Athans, P. L. Falb, Optimal Control: An Introduction to the Theory and\nIts Applications, McGraw-Hill, New York, 1966.\n[17] B. Christianson, Cheap newton steps for optimal control problems: automatic\ndifferentiation and Pantoja\u2019s algorithm, Optimization Methods and Software\n10 (5) (1999) 729\u2013743.\n[18] R. Newell, P. Lee, Applied Process Control \u2013 A Case Study, Prentice Hall,\nEnglewood Cliffs, NJ, 1989.\n12\nAppendix. Model equations\ndL2\ndt\n=\nF1 \u2212 F4 \u2212 F2\n20\n(27)\ndX2\ndt\n=\nF1X1 \u2212 F2X2\n20\n(28)\ndP2\ndt\n=\nF4 \u2212 F5\n4\n(29)\nT2=0.5616P2 + 0.3126X2 + 48.43 (30)\nT3=0.507P2 + 55.0 (31)\nF4=\nQ100 \u2212 0.07F1(T2 \u2212 T1)\n38.5\n(32)\nT100=0.1538P100 + 90.0 (33)\nQ100=0.16(F1 + F3)(T100 \u2212 T2) (34)\nF100=Q100\/36.6 (35)\nQ200=\n0.9576F200(T3 \u2212 T200)\n0.14F200 + 6.84\n(36)\nT201=T200 +\n13.68(T3 \u2212 T200)\n0.14F200 + 6.84\n(37)\nF5=\nQ200\n38.5\n(38)\n13\nsteam\nF100\nP100\nT100\nseparator\nP2, L2\nproduct\nF2, X2, T2\nfeed\nF1, X1, T1\ncondensate\nF5\ncooling\nwater\nF200, T200\nevaporator\ncondensate\nT201\ncondenser\nF4, T3\nF3\nFig. 1. Evaporator System\n14\n0.5\n1\n1.5\nL2\n, m\n(a)\n10\n20\n30\nX2\n, %\n(b)\n40\n60\n80\nP2\n, k\nPa\n(c)\n0\n2\n4\nF2\n, k\ng\/\nm\nin\n(d)\n0\n200\n400\nP1\n00\n, k\nPa\n(e)\n0\n100\n200\nF2\n00\n, k\ng\/\nm\nin\n(f)\n\u22122\n0\n2\nF1\n, k\ng\/\nm\nin\n(g)\n\u22121\n0\n1\nX1\n, %\n(h)\n0 20 40 60 80 100\n\u221210\n0\n10\ntime, min\nT1\n, o\nC\n(i)\n0 20 40 60 80 100\n\u22125\n0\n5\ntime, min\nT2\n00\n, o\nC\n(j)\nFig. 2. Simulation result. (a)\u2013(c) Measured outputs with setpoints. (d)\u2013(f) Manip-\nulated variables. (g)\u2013(j) Disturbances.\n15\nTable 1\nVariables and Optimal Values\nVar. Description Value Units\nF1 Feed flowrate 10 kg\/mim\nF2 Product flowrate 2 kg\/mim\nF3 Circulating flowrate 50 kg\/mim\nF4 Vapor flowrate 8 kg\/mim\nF5 Condensate flowrate 8 kg\/mim\nX1 Feed composition 5 %\nX2 Product composition 25 %\nT1 Feed temperature 40 oC\nT2 Product temperature 84.6 oC\nT3 Vapor temperature 80.6 oC\nL2 Separator level 1 meter\nP2 Operating pressure 50.5 kPa\nF100 Steam flowrate 9.3 kg\/mim\nT100 Steam temperature 119.9 oC\nP100 Steam pressure 194.7 kPa\nQ100 Heat duty 339 kW\nF200 Cooling water flowrate 208 kg\/mim\nT200 Inlet C.W. temperature 25 oC\nT201 Outlet C.W. temperature 46.1 oC\nQ200 Condenser duty 307.9 kW\n16\nTable 2\nComputational Time and Accuracy Comparison\nNMPC\nSTTAD ADOL-C CVODES\nTolerance Time, s T\/Total, % Time, s T\/Total, % Time, s T\/Total, %\n1e-6 0.08 0.83 2.062 17.36 7.079 42.35\nSimulation, P = 100 and M = 1\nactual STTAD ADOL-C CVODES\nTolerance order Time, ms Error Time, ms Error Time, ms Error\n1e-6 6 0.359 1.25e-7 7.344 1.25e-7 35.94 4.09e-5\n1e-8 7 0.391 3.57e-9 8.437 3.57e-9 51.65 7.65e-7\n1e-11 9 0.531 1.92e-12 11.72 1.92e-12 95.31 4.53e-9\nSimulation, P = 100 and M = 10\nactual STTAD ADOL-C CVODES\nTolerance order Time, ms Error Time, ms Error Time, ms Error\n1e-6 6 0.453 6.96e-8 8.125 6.96e-8 34.37 4.57e-5\n1e-8 8 0.531 1.74e-9 8.750 1.74e-9 53.12 9.09e-7\n1e-11 10 0.641 2.13e-13 11.72 2.13e-13 98.44 4.5326e-9\nSimulation, P = 100 and M = 100\nactual STTAD ADOL-C CVODES\nTolerance order Time, ms Error Time, ms Error Time, ms Error\n1e-6 6 3.281 6.96e-8 12.50 6.96e-8 42.19 4.09e-5\n1e-8 8 3.281 1.74e-9 12.50 1.74e-9 59.37 7.56e-7\n1e-11 10 3.437 1.85e-13 14.063 1.85e-13 107.8 4.53e-9\n17\n"}
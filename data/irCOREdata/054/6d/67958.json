{"doi":"10.1080\/09298215.2010.503898","coreId":"67958","oai":"oai:eprints.lancs.ac.uk:34349","identifiers":["oai:eprints.lancs.ac.uk:34349","10.1080\/09298215.2010.503898"],"title":"Schenkerian analysis by computer:a proof of concept","authors":["Marsden, Alan"],"enrichments":{"references":[{"id":840109,"title":"A computer aid for Schenkerian analysis.","authors":[],"date":"1980","doi":"10.2307\/3680082","raw":null,"cites":null},{"id":836155,"title":"A framework for automated Schenkerian analysis.","authors":[],"date":"2008","doi":null,"raw":null,"cites":null},{"id":840403,"title":"A generative grammar for jazz chord sequences.","authors":[],"date":"1984","doi":"10.2307\/40285282","raw":null,"cites":null},{"id":837215,"title":"A Generative Theory of Tonal Music.","authors":[],"date":"1983","doi":null,"raw":null,"cites":null},{"id":833004,"title":"A LISP-based system for the study of Schenkerian analysis.","authors":[],"date":"1978","doi":null,"raw":null,"cites":null},{"id":841007,"title":"A pregroup grammar for chord sequences.","authors":[],"date":"2005","doi":"10.1080\/09298210600578162","raw":null,"cites":null},{"id":833290,"title":"A probabilistic context-free grammar for melodic reduction.","authors":[],"date":"2007","doi":null,"raw":null,"cites":null},{"id":834806,"title":"A Trinity of Essays.","authors":[],"date":"1967","doi":null,"raw":null,"cites":null},{"id":832084,"title":"An expert system for harmonizing chorales in the style of J.S.","authors":[],"date":"1990","doi":null,"raw":null,"cites":null},{"id":831772,"title":"An expert system for harmonizing four-part chorales.Computer","authors":[],"date":"1988","doi":null,"raw":null,"cites":null},{"id":830976,"title":"Analysis of Tonal Music (2nd edition).","authors":[],"date":"2007","doi":null,"raw":null,"cites":null},{"id":835837,"title":"APL applied in music theory.","authors":[],"date":"1988","doi":null,"raw":null,"cites":null},{"id":838672,"title":"Beyond Schenkerism: the need for alternatives in music analysis. Chicago IL:","authors":[],"date":"1977","doi":null,"raw":null,"cites":null},{"id":839104,"title":"Computer analysis of jazz chord sequences: is Solar a blues?. In","authors":[],"date":"2000","doi":null,"raw":null,"cites":null},{"id":839855,"title":"Der frei Satz. Vienna: Universal Edition. Published in English as Free Composition, translated and edited by E.","authors":[],"date":"1935","doi":null,"raw":null,"cites":null},{"id":830660,"title":"Explaining Tonality: Schenkerian Theory and Beyond.","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":835600,"title":"Explication of the middleground of Schenker\u2018s theory of tonality.","authors":[],"date":"1977","doi":null,"raw":null,"cites":null},{"id":833961,"title":"FATTA: Full automatic time-span tree analyzer.","authors":[],"date":"2007","doi":null,"raw":null,"cites":null},{"id":838026,"title":"Generative Structural Representation of Tonal Music.","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":834217,"title":"Humdrum and Kern: selective feature encoding.","authors":[],"date":"1997","doi":null,"raw":null,"cites":null},{"id":838805,"title":"Identifying melodies from reduced pitch patterns.","authors":[],"date":"1991","doi":null,"raw":null,"cites":null},{"id":833711,"title":"Implementing \u2015A Generative Theory of Tonal Music\u2016.","authors":[],"date":"2006","doi":null,"raw":null,"cites":null},{"id":832600,"title":"Instructor\u2018s Manual for \u2017Introduction to Schenkerian Analysis\u2018.","authors":[],"date":"1982","doi":null,"raw":null,"cites":null},{"id":832325,"title":"Introduction to Schenkerian Analysis.","authors":[],"date":"1982","doi":null,"raw":null,"cites":null},{"id":836955,"title":"Measuring musical forces.","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":840902,"title":"Music and Probability.","authors":[],"date":"2007","doi":"10.1177\/102986490901300214","raw":null,"cites":null},{"id":833441,"title":"MusicXML for notation and analysis.","authors":[],"date":"2001","doi":null,"raw":null,"cites":null},{"id":838560,"title":"Parsing Context-Free Grammars for Music: A Computational Model of Schenkerian Analysis.","authors":[],"date":"2004","doi":null,"raw":null,"cites":null},{"id":835064,"title":"Proving Musical Theorems I: The Middleground of Hienrich Schenker\u2018s Theory of Tonality (Tech.","authors":[],"date":"1975","doi":null,"raw":null,"cites":null},{"id":831524,"title":"Report on the Choral Project: An Expert System for Harmonizing Fourpart Chorales.","authors":[],"date":"1987","doi":null,"raw":null,"cites":null},{"id":837773,"title":"Representing Melodic Patterns as Networks of Elaborations.","authors":[],"date":"2001","doi":null,"raw":null,"cites":null},{"id":832885,"title":"Schenker\u2018s theory of tonal music\u2014its explication through computational processes.","authors":[],"date":"1976","doi":null,"raw":null,"cites":null},{"id":838283,"title":"Schenkerian reduction as search.","authors":[],"date":"2008","doi":null,"raw":null,"cites":null},{"id":834474,"title":"Speech and Natural Language Processing, 2nd edition. Upper Saddle River,","authors":[],"date":"2009","doi":null,"raw":null,"cites":null},{"id":839600,"title":"Studies, Cambridge:","authors":[],"date":"1990","doi":null,"raw":null,"cites":null},{"id":840672,"title":"The blues and the abstract truth: music and mental models.","authors":[],"date":"1996","doi":null,"raw":null,"cites":null},{"id":829884,"title":"The concept of musical grammar (translated by S. Maguire with the assistance of W.","authors":[],"date":"1983","doi":null,"raw":null,"cites":null},{"id":835343,"title":"The decidability of languages that assert music.","authors":[],"date":"1976","doi":null,"raw":null,"cites":null},{"id":829627,"title":"The semantics of musical hierarchies.","authors":[],"date":"1993","doi":null,"raw":null,"cites":null},{"id":830427,"title":"The Unanswered Question: Six Talks at Harvard.","authors":[],"date":"1976","doi":null,"raw":null,"cites":null},{"id":830140,"title":"Theory and analysis of European melody.","authors":[],"date":"1992","doi":null,"raw":null,"cites":null},{"id":836666,"title":"Theory of Suspensions.","authors":[],"date":"1971","doi":null,"raw":null,"cites":null},{"id":837497,"title":"Tonal Pitch Space.","authors":[],"date":"2001","doi":null,"raw":null,"cites":null},{"id":839340,"title":"Towards a Methodology for Schenkerian Analysis (translated by William Drabkin).","authors":[],"date":"1988","doi":null,"raw":null,"cites":null},{"id":831254,"title":"Using attribute grammars to find solutions to musical equational programs.","authors":[],"date":"1994","doi":null,"raw":null,"cites":null},{"id":836405,"title":"Using harmonic and melodic analyses to automate the initial stages of Schenkerian analysis.","authors":[],"date":"2009","doi":null,"raw":null,"cites":null}],"documentType":{"type":0.6666666667}},"contributors":[],"datePublished":"2010-09","abstract":"A system for automatically deriving a Schenkerian reduction of an extract of tonal music is described. Schenkerian theory is formalised in a quasi-grammatical manner, expressing a reduction as a binary-tree structure. Computer software which operates in the manner of a chart parser using this grammar has been implemented, capable of deriving a matrix of reduction possibilities, in polynomial time, from a representation of the score. A full reduction of the extract can be discovered by selecting a tree from this matrix. The number of possible valid reductions for even short extracts is found to be extremely large, so criteria are required to distinguish good reductions from bad ones. To find such criteria, themes from five Mozart piano sonatas are analysed and samples of 'good' reductions (defined by reference to pre-existing analyses of these themes) are compared with randomly sampled reductions. Nine criteria are thereby derived, which can be applied in the process of parsing and selecting a reduction. The results are promising, but the process is still too computationally expensive--only extracts of a few bars in length can be reduced--and more extensive testing is required before the system can be properly claimed to perform automatic Schenkerian analysis","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/67958.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/34349\/1\/ProofOfConcept.pdf","pdfHashValue":"bcad0c1e3924d2c9d7952031211e81388c00a0b9","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:34349<\/identifier><datestamp>\n      2018-01-24T03:03:15Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D4D:4D31<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Schenkerian analysis by computer:a proof of concept<\/dc:title><dc:creator>\n        Marsden, Alan<\/dc:creator><dc:subject>\n        M Music<\/dc:subject><dc:description>\n        A system for automatically deriving a Schenkerian reduction of an extract of tonal music is described. Schenkerian theory is formalised in a quasi-grammatical manner, expressing a reduction as a binary-tree structure. Computer software which operates in the manner of a chart parser using this grammar has been implemented, capable of deriving a matrix of reduction possibilities, in polynomial time, from a representation of the score. A full reduction of the extract can be discovered by selecting a tree from this matrix. The number of possible valid reductions for even short extracts is found to be extremely large, so criteria are required to distinguish good reductions from bad ones. To find such criteria, themes from five Mozart piano sonatas are analysed and samples of 'good' reductions (defined by reference to pre-existing analyses of these themes) are compared with randomly sampled reductions. Nine criteria are thereby derived, which can be applied in the process of parsing and selecting a reduction. The results are promising, but the process is still too computationally expensive--only extracts of a few bars in length can be reduced--and more extensive testing is required before the system can be properly claimed to perform automatic Schenkerian analysis.<\/dc:description><dc:date>\n        2010-09<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/34349\/1\/ProofOfConcept.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1080\/09298215.2010.503898<\/dc:relation><dc:identifier>\n        Marsden, Alan (2010) Schenkerian analysis by computer:a proof of concept. Journal of New Music Research, 39 (3). pp. 269-289. ISSN 1744-5027<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/34349\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1080\/09298215.2010.503898","http:\/\/eprints.lancs.ac.uk\/34349\/"],"year":2010,"topics":["M Music"],"subject":["Journal Article","NonPeerReviewed"],"fullText":"Schenkerian Analysis by Computer: A Proof of Concept \nThis is a pre-print of an article to be published in Journal of New Music Research, vol.39, \nno.3. Details of the definitive version may be found at www.informaworld.com\/jnmr.  \nAlan Marsden,  \nLancaster Institute for the Contemporary Arts, Lancaster University, UK \nA.Marsden@lancaster.ac.uk \nAbstract \nA system for automatically deriving a Schenkerian reduction of an extract of tonal music is \ndescribed. Schenkerian theory is formalised in a quasi-grammatical manner, expressing a \nreduction as a binary-tree structure. Computer software which operates in the manner of a \nchart parser using this grammar has been implemented, capable of deriving a matrix of \nreduction possibilities, in polynomial time, from a representation of the score. A full \nreduction of the extract can be discovered by selecting a tree from this matrix. The number \nof possible valid reductions for even short extracts is found to be extremely large, so \ncriteria are required to distinguish good reductions from bad ones. To find such criteria, \nthemes from five Mozart piano sonatas are analysed and samples of \u2017good\u2018 reductions \n(defined by reference to pre-existing analyses of these themes) are compared with randomly \nsampled reductions. Nine criteria are thereby derived, which can be applied in the process of \nparsing and selecting a reduction. The results are promising, but the process is still too \ncomputationally expensive\u2014only extracts of a few bars in length can be reduced\u2014and more \nextensive testing is required before the system can be properly claimed to perform \nautomatic Schenkerian analysis.  \n1. Introduction \n1.1 Rationale \nSince the first flurry of interest in formal grammars and their potential application to music, \nbeginning in the 1960s and most famously manifested in Bernstein\u2018s Norton Lectures of \n1973 (Bernstein, 1976), some have looked to Schenkerian theory as providing a kind of \ngrammar of music and have sought to implement it in a computer program after the fashion \nof computational linguistics. A decade or so later, Lerdahl and Jackendoff presented a \nsimilarly reductional theory explicitly grounded in generative linguistics (Lerdahl & \nJackendoff, 1983), which has also attracted attempts at computational implementation, \nmost recently and most successfully in the work of Hamanaka, Hirata & Tojo (2006, 2007). \nThe potential benefits of a program to derive Schenkerian analyses or reduction trees in the \nstyle of Lerdahl and Jackendoff would be enormous. Such an analysis adumbrates much of \nthe information carried in other kinds of structural analyses. For example, though few \nharmonic functions are explicitly indicated in a Schenkerian analysis, it is a simple matter to \nread at least the main harmonies from a graph. Segmentations are also inherent in the \nstructure of a reduction, represented in Schenker\u2018s graphs principally by the use of different \nsizes of notes, beams and slurs, or in analyses in the style of Lerdahl & Jackendoff in the \nbranching of the tree structure. A system which derived Schenkerian analyses or reduction \ntrees would therefore also deliver a significant quantity of other useful information about a \npiece of music. (Further benefits of generative reductional representation of music are \ndescribed in (Marsden, 2005). The benefits for the representation of pattern in particular are \ndescribed in (Marsden, 2001).) \n1.2 Main contribution \nThis paper gives a proof of concept of a mechanism for deriving Schenkerian analyses, and \nthe kind of reductional representations described in (Marsden, 2005), from score data (more \nspecifically, quantised MIDI-like data). The system described is too inefficient to provide an \neffective music-analysis tool\u2014only short sections of simple music can be analysed. \nFurthermore, it is premature to claim that the analyses derived are \u2017correct\u2018 or useful. \nHowever, the work described here does provide grounds for optimism that further \ndevelopment might produce a tool which is both useful and reliable. \nThis work also provides a means for empirical investigation of the principles of Schenkerian \nanalysis. Schenkerian theory (in common with many other music theories) is expressed \nessentially in the form of rules by which music may be elaborated, rather than describing \neither a mechanism by which a piece may be reduced or criteria by which one may choose \nbetween the various possible reductions which conform to the rules. There has been some \ndiscussion of what such criteria might be (Plum, 1988; Schachter, 1990), and guidance is \ngiven to students in making Schenkerian analyses (e.g., Pankhurst, 2008). However, there is \nno general agreement among music theorists about how a reduction should be made, nor \nany clear idea about how one would find out. The computational implementation described \nhere allows the empirical investigation of both the adequacy of a set of rules and the criteria \nfor choosing one analysis over another, and therefore promises advances in the theory of \nmusic analysis with a stronger empirical basis than heretofore.  \n1.3 Outline \nSection 2 of this paper gives an essential summary of Schenkerian reduction and reviews \nrelated prior systematic work. Section 3 gives a formalisation of quasi-Schenkerian tonal \nreduction with sufficient precision for computational implementation. Section 4 discusses \nthe problem of the explosion of the solution space and describes a reduction algorithm to \ncope with this problem. Section 5 describes exploratory empirical work, using short extracts \nof Mozart piano sonatas and pre-existing analyses of those extracts, to discover a \n\u2017goodness\u2018 metric by which to select a preferred reduction from among the many \npossibilities. Section 6 discusses the results with respect to this small sample, which show \nmoderate success, and considers the prospects for further work.  \nAs stated above, this is a proof of concept rather than a claim to have solved the problem of \nSchenkerian analysis by computer. The mechanism described here will not simply scale up \nto cover more than a few bars of music. While there are many published Schenkerian \nanalyses which might be a source of test material, most cover entire pieces of music and \nsmall test examples are not readily available. Two substantial steps therefore remain to be \ntaken before the problem of Schenkerian analysis by computer can be claimed to have been \nproperly solved: thorough testing, and development of a mechanism which can be applied \nto realistic spans of music.  \n2. Systematic Reduction of Tonal Music \n2.1 Schenkerian analysis \nWhile reduction, in the broad sense of \u2017information reduction\u2018, is a part of any analysis, \nwhen applied to music the term generally has the quite specific meaning of deriving from a \npiece of music a structure of notes which contains the main structural outline of that music \nwithout its more \u2017ornamental\u2018 features. Thus the result of reducing a piece of music is itself \na piece of music (at least in the sense that it is a structure of notes) which contains fewer \nnotes than the original. The reduction process can then be applied recursively, producing \never simpler and simpler musical structures, until an irreducible basis is reached. Although \nthe fundamental idea of such reduction is found in many places in music theory, it takes its \nmost developed form in Schenkerian analysis, a technique of music analysis which has its \norigins in the publications and teaching of Heinrich Schenker (expressed most succinctly in \nDer Freie Satz (Schenker, 1935)). In the English-speaking world, Schenker\u2018s ideas were \nspread principally by his pupils who emigrated to the USA. By the 1970s Schenkerian theory \nhad become the orthodoxy of tonal music taught at American universities. (A recent \nmanifestation of this is (Cadwallader, 2007).) While powerful opposing theories have been \nproposed, there can be no denying the significant influence of Schenkerian analysis, and the \nvalue that a large body of music scholars has placed on it.  \nThere is much more to Schenkerian analysis than just the removal of non-essential notes. \nFurthermore, Schenker himself did not aim to present a scientifically systematic theory of \nmusical reduction (though he does make reference to musical \u2017laws\u2018). The work described \nhere is thus not a \u2017computerisation\u2018 of Schenkerian theory in toto, but rather an attempt to \nforge a systematic basis for the kind of reduction which is at the core of that theory. \n2.2 Lerdahl & Jackendoff \nAs mentioned above, Lerdahl and Jackendoff (1983) have proposed a theory which also \nmakes use of the same essential concept of reduction. There are important points of contact \nwith Schenkerian analysis, but also four significant differences. \n1. Lerdahl & Jackendoff express their theory in a much more explicitly systematic fashion, \npresenting it as a set of rules which generate well defined structures. In the case of \nreductions these structures are explicitly trees. \n2. Their reductions are based principally on melody-plus-chord rather than on the full \ncontrapuntal texture, as in Schenker\u2018s reductions. \n3. Derivation of their reductions depends on grouping and metrical structures which are \nreductional in a different sense. \n4. They identify two different kinds of reductional structure, \u2017time-span\u2018 and \n\u2017prolongational\u2018, which are, essentially, the result of bottom-up and top-down derivation \nrespectively. \nAs will be seen below, I use the concept of binary trees found in the theory of Lerdahl & \nJackendoff, but I regard the other three significant differences as disadvantages in \ncomparison with the conceptual simplicity of Schenkerian analysis which finds just one kind \nof structure based on one kind of information in a piece of music. Some of the more general \narguments and conclusions of this paper, however, apply just as much to analysis in the \nstyle of Lerdahl & Jackendoff as they do to Schenkerian analysis, and would apply to any \nsimilar reductional analysis. \n2.3 Recursive functions \nEarlier work on implementation of Schenkerian theory in computer software has drawn on \nsimilarities between Schenkerian theory and the concept of recursion in mathematics and \ncomputer science. As pointed out above, since the result of a reduction (or, inversely, an \nelaboration) is, like the original, a structure of notes, reduction (or elaboration) may be \napplied recursively. The earliest publication which relates Schenkerian theory to computing \nin this manner is (Kassler, 1967), which expresses the middle-to-background reductions of \nSchenkerian theory as a set of operations on matrix representations of pitch structures. \nSmoliar and others instead represented music in a list structure (the classic vehicle for \nrecursion) and implemented a set of Schenkerian elaboration functions in LISP (Frankel, \nRosenschein & Smoliar, 1976, 1978; Smoliar, 1980). The structure of a piece of music could \nthereby be expressed as a nested sequence of function calls which, when evaluated, would \ngenerate the list structure of notes corresponding to the score. \nOthers took as their starting point formal grammars rather than computing concepts, but \nthe results are not significantly different. One of the most Schenkerian among these projects \nwas by Baroni and colleagues (Baroni, 1982; Baroni, Dalmonte & Jacoboni, 1992), though it \napplied only to melodies. Once again, the software generated music rather than analysing it, \nbut one attraction of using formal grammars is the possibility of using a parsing mechanism \nproven to be effective for a class of grammars as a means of analysis. Interest in musical \ngrammars has therefore often focused on the application of different kinds of grammar to \nmusic (Steedman, 1984, 1996; Barbar, Desainte-Catherine & Miniussi, 1993; Desainte-\nCatherine & Barbar, 1994; Terrat, 2005). However, such parsing has not often been shown \nto be effective in analysis of pieces. One notable exception is (Pachet, 2000). Another is the \nSchenkerian component of Ebcio\u011flu\u2018s chorale-harmonisation system (1987, 1988, 1990) \nwhich contains a grammar and heuristics for deriving Schenker-like analyses of the melody \nand bass lines of a chorale.  \n2.4 Automatic reduction \nFrankel, Rosenschein and Smoliar were hopeful of extending their LISP-based work to make \na system capable of automatic analysis: \u2017we anticipate that on the basis of our results thus \nfar, we should be able to formulate an experimental grammar to be used for automated \nanalysis.\u2018 (1976, p.30) In a later publication, however, they are more cautious: \u2017it is \nquestionable whether a program which produces Schenkerian analyses may be designed \nwithout a peripheral \u2015world model\u2016 of musical perception\u2018. (1978, p.134) Two years later \nSmoliar presented his software explicitly as an aid to the human analyst (Smoliar, 1980) with \nno implication of future automation.  \nKassler has worked steadily on software to derive analyses according to his matrix-\nmanipulation model of Schenkerian theory, resulting in software which is able to derive an \nanalysis from a three-voice middleground, i.e., not directly from the score but from an \nalready partially reduced structure (1975, 1977, 1988). This is impressive work which \ndeserves to be better known, though unfortunately Kassler himself has not been able to \ndevelop it further (personal communication, 5 May 2005). \nMusical grammars have often been concerned with chords rather than notes, partly because \nchords form single sequences of symbols rather than the multiple parallel sequences of \nnotes which constitute most pieces of music. Grammars which deal with notes have tended, \nlike Baroni\u2018s, to represent only single lines. Ebcio\u011flu\u2018s grammar, for example, handled the \nbass and melody of a chorale harmonisation separately. Furthermore, its author made clear \nthat he did not attempt to faithfully implement Schenker\u2018s theory, but rather only aspects of \nit, principally linear progressions (Ebcio\u011flu 1987, p.88). The result was a system reported to \nbe capable of deriving \u2017good hierarchical voice-leading analyses\u2018 of chorale melodies, but \nnot of bass lines (Ebcio\u011flu 1987, p.79). \nMavromatis & Brown (2004) also took a grammar-based approach, but their grammar dealt \nwith multi-voice structures rather than one-dimensional sequences of either chord symbols \nor notes. They demonstrated the theoretical possibility of expressing Schenkerian theory in \na context-free grammar, a kind of grammar which has a particularly simple and effective \nparsing mechanism. While this suggested that the grammar could form the basis for \nautomatic derivation of Schenkerian analyses, this promise has not been fulfilled because \nthe number of re-write rules required is preventatively large (Mavromatis, personal \ncommunication, 6 March 2007). Possibly using a context-free grammar merely moves \ncomplexity from the parsing process into the grammar itself. \nAs will become clear below, complexity is the real stumbling-block to progress towards \nSchenkerian analysis by computer. A simple analysis system leads to many, many possible \nanalyses, of which many are either incorrect or not as good as others. Although it has not \nbeen reported, I suspect that it was this complexity which prevented Smoliar and Kassler \nfrom achieving their objectives in the 1980s. Ebcio\u011flu overcame the problem to some \ndegree through the use of explicit heuristics to select analysis steps which are more likely to \nproduce good analyses. Gilbert & Conklin (2007) took as their starting point a grammar of \nmelody with similarities to that of Baroni, but made it explicitly probabilistic so that analysis \nsteps were more likely to lead to good analyses. A Hidden Markov Model learned \nprobabilities based on a set of exemplars, resulting in software which was able to derive \nreductions from melodies with a moderate degree of success. \nThe software ATTA, by Hamanaka, Hirata & Tojo (2006), derived a reduction in the style of \nLerdahl & Jackendoff from a melody. The problem of multitudes of possible analyses was \nhere handled through the user adjusting parameters for each melody to arrive at an \nacceptable reduction (a process reported to take an expert about 10 minutes for each \nmelody, 2006, p.271). A development of the system which uses a feedback loop from higher \nlevels of reduction to adjust parameters automatically has been shown to be able to produce \nbetter results than no parameter adjustment, but the results are still quite distant from \n\u2017good\u2018 analyses (2007). \nThe most recent research explicitly directed as computational Schenkerian analysis has been \nby Kirlin & Utgoff. They describe a representation system and theoretical framework for the \nimplementation of Schenkerian analysis, conceived as search through a space of directed \nacyclic graphs (with some similarities to the work described here). Their response to the \nproblem of the size of the search space is essentially to work on \u2017pre-processing\u2018 to guide \nsearch. They report software which is able to pick out a candidate Ursatz (fundamental \nstructure) from a piece of piano music (Kirlin & Utgoff, 2008). Working from the other end of \nthe problem, Kirlin has recently implemented software which derives a foreground from a \nscore with a notable degree of success (Kirlin, 2009). \nIn summary, for more than three decades there have been attempts to implement \nSchenkerian reduction (or similar) in computer software. Kassler\u2018s work demonstrated that \nthis was possible for restricted kinds of music (middlegrounds), but, as demonstrated in the \nwork of Mavromatis & Brown, there are serious impediments to effective automatic \nreduction. The relative success of Ebcio\u011flu, Gilbert & Conklin and Hamanaka, Hirata & Tojo \nin dealing with melodies, however, suggests that techniques for overcoming these \nimpediments can be found for full musical textures. In the remainder of this paper, I give a \nproof of concept of such a technique. \n3. Formalisation of Reduction \n3.1 Musical primitives \nA Schenkerian analysis generally consists of a set of \u2017graphs\u2018 presented in a kind of music \nnotation, at several levels, often with an accompanying textual commentary and sometimes \nnotes and comments written on the actual graphs. Here I will ignore these textual comments \nand deal only with the music notation of the graphs. Each graph spans the entire length of \nthe piece, and each represents a level of reduction between the \u2017surface\u2018 of the piece (the \nnotes of the score) and the Ursatz, which, according to the analysis, is the particular model \nused in this piece of one of the three forms of fundamental structure which Schenker \nbelieved to underlie every piece of proper tonal music.  \nThe graphs most importantly consist of notes, slurs, barlines, clefs and key signatures. \nBarlines, if present at all, appear only in the lowest level graphs, but the use of bar numbers \nand the alignment of graphs with each other can imply where the time-points \ncorresponding to barlines occur in higher-level graphs also. Other symbols on the graphs \nwill not be considered here. While an analyst might make reference to factors such as \narticulation and dynamics in the course of making an analysis, these factors do not have any \nexplicit role in the theory. One factor which is clearly of considerable importance is which \ninstrument plays which note, but its importance seems to have been so self-evident for \nSchenker that even that factor deserves no explicit role in his theory. Here, I simply side-\nstep the issue by considering only keyboard music where this factor is irrelevant. Thus, for \nthe present purposes, the surface of a piece of music will be considered to be a collection of \nnotes defined by their pitch and rhythm, within a given framework of key and metre. \nIt might be thought that representing pitch in terms which differentiate different \u2017spellings\u2018 \n(i.e., which distinguish C\u266f from D\u266d) would be appropriate for an application such as this \ndealing with tonal music. However, it is only when a pitch has a role within a musical \nstructure that one can properly distinguish between two notes sounding the same but \nhaving different spellings, and these structures are to be derived from the surface \nrepresentation rather than to be expressed within it. Furthermore, I know of no tonal \nstructure in which two pitches which sound the same but are spelled differently are \nsimultaneously present. (Structures in which they are successively present are found in many \n18th- and 19th-century pieces.) Thus, since it is best to keep things simple until they need \nto be made more complex, I will assume that pitches can be represented within the twelve-\ntone scale, and in each derived tonal structure it will be possible to unequivocally determine \nhow a pitch should be spelled, should that be required. Thus pitches can be represented in a \ntwelve-tone scale and considered equivalent to integers, and it is simplest to use the \nexisting MIDI standard pitch codes for this purpose. The common concept of the pitch class, \nwhich ignores the octave in which a pitch occurs, will also be used. Pitch classes will be \nrepresented simply as integers modulo 12. The tonal structure of a piece depends on a key \nwhich, strictly speaking, should be derived in the course of analysis. To simplify early \ndevelopment, however, the key is taken to be explicitly stated in advance of analysis; at a \nfuture stage of development, the key should be inferred by the analysis process. \nSchenker gives no significance to absolute duration: whether a note lasts for a second or a \nminute has no explicit role in his theory. Schenker writes little about relative durations, \neither, but they clearly are important in the making of Schenkerian analyses. Thus durations \nare represented only in relative terms, for which rational numbers with no absolute \nsignificance can be used. Rhythm has an aspect of stress as well as duration, inherent in the \nstrong and weak beats of metre, an aspect of the structure which, like key, should properly \nbe derived in the course of analysis. However, as in the case of key, the metre is currently \ngiven in advance as an offset from the start of the piece to the first strong beat, and a \npattern giving the lengths of strong and weak beats in the same terms as the rational \nnumbers of the durations of notes. Again, at a future stage of development the metre \nshould be inferred by the analysis process. \nFollowing this reasoning, the surface of a piece of music could be represented as a \ncollection of notes, each represented by three numbers: an integer for the pitch, a rational \nnumber for the duration, and another rational number to represent the time at which the \nnote starts relative to the start of the piece. However, for reasons which will become clear \nlater, it is useful to be able to treat a piece as a succession of events each consisting of any \nnumber of sounding notes (i.e., a single note or a chord), or none (i.e., a rest), and at which \neach note might start (or start again) or might be a continuation of a note in the previous \nevent (a tied note). These events will be called \u2017segments\u2018 (corresponding to the \u2017time spans\u2018 \nof Lerdahl & Jackendoff). (In some music-theoretic texts such a construct is called a \n\u2017simultaneity\u2018, but sometimes the word is also used for instants which have no duration or \nan indeterminate duration, so the word \u2017segment\u2018 is used here to avoid any potential \nconfusion.) In this representation, individual notes do not need to have durations: the \nduration can be attached to the segment and all notes within the segment will have that \nduration. Furthermore, starting times do not need to be represented, because they are \ninherent in the sum of the durations of the preceding segments in the sequence. On the \nother hand, it is now necessary to add to each note a property to indicate whether it is tied \nto a preceding note or is a newly started note. Furthermore, a single note in a score might \nhave to be represented by several notes across several segments, with a tie on the second \nand subsequent notes.  \nThe surface of a piece is thus represented as a sequence of segments. A segment has a \nduration (represented by a rational number) and a set of notes (possibly empty). Each note \nhas a pitch (represented by an integer) and a state of being tied or not tied to a preceding \nnote. (An illustration is given in Figures 1 and 2.) Note that there is no explicit \nrepresentation of voices: the notes of one segment follow the notes of another with no \nimplication that any note in the first is in the same voice as any note in the second. While \nthe voices of a piece are generally evident to the listener and to someone reading the score, \nthey are not generally explicitly represented in the score in keyboard music. Furthermore, \nthere are many cases in Schenkerian analysis where elaborations involve notes from more \nthan one voice, or where one voice at the surface becomes more than one voice at some \nlevel of reduction. In general, the analysis system presented here employs no explicit \nconcept of voice, except to give a particular role in some situations to the lowest or highest \nnotes of segments. \nSince we are dealing with keyboard music, this representation can be thought of in terms \nalso of activity on the keyboard, rather like a piano roll. Each segment corresponds to a \nstate of the keyboard\u2014whether each note is depressed or not\u2014and lasts for a specific \nrelative duration. At the beginning of each state, each depressed note can have been held \ndown (corresponding to a tied note) or struck (corresponding to a non-tied note). This detail \nwould not be required in a strict representation of the changing state of the keyboard, since \nevery occurrence of a struck note must be preceded by a state of the keyboard in which the \nnote is not depressed. However, these states might have an extremely short duration and \nhave no independent structural role in the music. In the same way, the minute differences in \ntiming between the beginnings of notes which are played \u2017together\u2018 (but not actually \ntogether) are ignored. The representation thus does not correspond to a strict \nrepresentation of the changing physical state of the keyboard but rather to an idealised \nrepresentation which abstracts from this the musically significant changes of state. One \nconsequence of this correspondence is that the analysis procedure described below could, \nsubject to this idealisation (which is not trivial), be applied to MIDI representations of pieces \nof music. \n3.2 Binary trees \nLerdahl & Jackendoff explicitly represent their reductions in tree structures. Schenker, \nworking within a different and earlier intellectual tradition, did not, but the work of Kassler \nand Smoliar demonstrates that a conversion of his graphs to tree structures is possible \n(discussed in detail in Marsden, 2005). To simplify, a reductional structure will here be \nconsidered to be a binary tree. Two aspects of Schenkerian theory do not fit simply into this \nsimple structure: elaborations which produce sequences of notes and elaborations which \ndepend on context outside the time span being elaborated. These introduce some additional \ncomplications, discussed below, but it appears that the benefit of the simplicity of the \nbinary tree structure is worth the cost of accommodating these complications. \nEach node of a reductional tree is a segment (as defined above) (again following Lerdahl & \nJackendoff). The duration of a segment which is not a terminal (i.e., not a \u2017leaf\u2018 of the tree) is \nequal to the sum of the durations of the two segments below it in the tree. In this I follow \nKomar (1971) who adds treatment of rhythm to Schenkerian theory by regarding elaboration \nas introducing additional notes within a specific time span. Thus at each branching point a \nlonger (more background) span is divided into shorter (more foreground) spans. \nAs mentioned above, the highest level of a Schenkerian analysis is an Ursatz, one of a class \nof three prototype structures which Schenker believed to underlie every great piece of \nmusic. Each of these begins and ends with tonic harmony in root position, has root-position \ndominant harmony immediately preceding the final tonic, and has a top line (the Urlinie) \nwhich descends by step from the tonic, fifth or third of the scale to the tonic an octave, fifth \nor third below respectively. However, it makes for a simpler formal structure if reduction is \nconsidered to continue beyond the Ursatz until a single segment is reached, making a single \ntree. Indeed Schenker himself considered the three forms of the Ursatz to be derived from \nthe static tonic triad, the \u2017chord in nature\u2018. As formalised here, therefore, a legitimate \nanalysis will be a binary tree of segments, of which the highest (the \u2017root\u2018) has root-position \ntonic harmony, and which contains a sequence of segments forming an Ursatz. This \nsequence must span the entire tree, i.e., every other segment in the tree must be either an \nancestor or a descendent of a segment in the sequence. \n3.3 Atomic elaborations \nThe notes of segments which are not the highest-level segment (the \u2017root\u2018) can be derived \nby applying specific \u2017atomic elaborations\u2018 to the notes of the segment above in the tree. \nAtomic elaborations correspond to the simplest techniques of diminution described by \nSchenker in Der Freie Satz, some of which are familiar from the theory of ornamentation: \nappoggiaturas, suspensions, neighbour notes, and the like. Each elaboration refers to a \nsingle note in the segment above, which will be called the \u2017parent\u2018, and produces two notes \n(or a note and a rest), called the \u2017children\u2018, one in each of the segments below. The precise \nvocabulary of possible elaborations should be a topic of research, based on a close reading \nof theoretical texts such as Schenker\u2018s and empirical research on actual analyses, and it will \nvary according to the repertoire of music to be analysed. However, for this proof of concept \nthe simple set of elaborations defined in Table 1 will be used. Schenker\u2018s more complex \ntechniques of diminution can generally be formed by combinations of these atomic \nelaborations; that all of them can be so formed is yet to be proven. \n \nName parent  1st child  2nd child  pre-\ncontext \npost-\ncontext \nconsonant \npitches \ninheritance \ntype pitch tie pitch tie pitch tie pitch pitch set of pitch class inheritance \nconsonant skip 1 x t x t y  no \u2205 \u2205 x + y either \nconsonant skip 2 y no x t y  no \u2205 \u2205 x + y either \nappoggiatura y no x = y\u00b11 or y\u00b12 no y no \u2205 \u2205 y 2nd \nanticipation x t x t y  no \u2205 y x 1st \nneighbour note x t x t y = z\u00b11 or z\u00b12 no \u2205 z x 1st \nsuspension y no x = y\u00b11 or y\u00b12 yes y no x \u2205 y 2nd \nrepetition x t x t x no \u2205 \u2205 x either \nhold x t x t x yes \u2205 \u2205 x either \nshortening x t x t rest no \u2205 \u2205 x either \ndelay x no rest no x no \u2205 \u2205 x either \ninterruption* x t x t y no \u2205 \u2205 I IV \nTable 1. Definitions of \u2017atomic elaborations\u2018. *Additional conditions also apply to the \u2017interruption\u2018 elaboration: the harmony of the second \nsegment must be V or V7. \nThe definitions in Table 1 are probably too restrictive in some details. For example, the \ndefinition of \u2017repetition\u2018, \u2017hold\u2018, \u2017shortening\u2018 and \u2017delay\u2018 in Table 1 (elaborations which in \nmusic theory seem so obvious as not to warrant definition) require the notes to be \nconsonant. In actual music, however, it is not difficult to find dissonant notes which are \nrepeated or followed or preceded by a rest. However, allowing looser definitions \nconsiderably increases the complexity of the reduction process. Since, as will become clear \nbelow, the computational complexity is already severe, this proof of concept takes this \nrestrictive definition for these elaborations, which is adequate in most cases.  \nOther definitions are probably too loose. The \u2017consonant skip\u2018 elaboration generates a leap \nfrom one consonant note to another, and exists in two forms, one in which the parent note \nhas the pitch of the first note and one in which the parent note has the pitch of the second. \nThis elaboration is not one referred to by Schenker, but not every case in which he appears \nto use an elaboration generating a leap from one consonant note to another conforms to his \ndefinition of \u2017arpeggiation\u2018 (the term he uses more commonly). Forte & Gilbert make \nextensive use of the term \u2017consonant skip\u2018 but do not give a clear definition. Most \noccurrences of \u2017consonant skips\u2018 in the literature occur as a leap of a third or fourth from \none note to the next above or below in the prevailing harmony, but sometimes leaps of \nlarger intervals are labelled as consonant skips. Therefore a non-restrictive definition of \nconsonant skip has been used here which accommodates a leap to any note of the same \nharmony, regardless of the interval. Deriving acceptable analyses from the test pieces used \nhere was not possible when this definition was restricted to intervals of a third or fourth, but \nit remains worryingly loose to allow a skip to any note of the harmony with no constraint. \nEven looser is the elaboration I call \u2017interruption\u2018. This is a kind of elaboration Schenker \nexplicitly describes, but only in specific situations. It occurs when there is a move from the \ntonic to the dominant, with the Urlinie descending to the second degree of the scale, \nfollowed by a caesura, a resumption of the tonic and a return to the first note of the Urlinie. \nThe pattern thus only occurs for Schenker at the higher levels of reduction. However, \nsomething like it evidently occurs also at lower levels, where there is a move to the \ndominant which does not proceed smoothly to notes which follow. Again, an elaboration like \nthis appears necessary to allow derivation of acceptable analyses from pieces such as the \ntest pieces used here, but its use should probably be more constrained. \nSome common techniques of diminution can produce more than one new child note: \npassing notes and arpeggiations. The simplest passing note is a single note placed between \ntwo others a third apart, but passing notes can also exist as two notes placed between notes \na fourth apart, which implies the need for ternary branching in the tree. One possibility is to \nintroduce an additional kind of \u2017note\u2018 to represent an intermediate stage in a multiple-\npassing-note elaboration, and represent such passing-note elaborations in more than one \nbinary branching. A similar technique can be used to represent multiple-note arpeggiations. \nIntroducing this additional kind of \u2017note\u2018, however, considerably increases the \ncomputational complexity of the reduction process. As for the restrictive definition of \n\u2017repetition\u2018, \u2017hold\u2018, \u2017shortening\u2018 and \u2017delay\u2018 elaborations, this proof of concept will take the \nexpedient, but probably ultimately incorrect, approach of assuming that every passing-note \nelaboration can be represented as a set of one of more neighbour-note elaborations applied \nrecursively. Multiple-note arpeggiations will be represented by recursive consonant-skip \nelaborations. \nIn the formal definition given below, the term \u2017atomic elaboration\u2018 is used for elaborations \nsuch as those described here which have a single note as parent and a pair of notes (or a \nnote and a rest) as children. The term \u2017elaboration\u2018 is used to refer to a ternary relationship \nbetween segments whereby a parent segment is elaborated to become a pair of child \nsegments. Such an elaboration must be made up of a valid set of atomic elaborations. \nEvery segment is considered to contain a notional rest, even if no rest is notated in the \nscore. Thus there is always a rest available to be a child of a \u2017shortening\u2018 or \u2017delay\u2018 \nelaboration. This allows configurations such as \u2017unfoldings\u2018, where a single voice \nadumbrates more than one voice in \u2017pseudo-polyphony\u2018, to arise naturally by multiple \n\u2017shortening\u2018 and \u2017delay\u2018 elaborations. \n3.4 Context notes \nThe simplest atomic elaborations, such as \u2017repetition\u2018 and \u2017consonant skip\u2018, require no \nreference outside of the span of the note to be elaborated. Others, like anticipations and \nneighbour notes, can exist only in the presence of an appropriate following note. \nSuspensions require a particular preceding note. These will be referred to as \u2017post-context\u2018 \nand \u2017pre-context\u2018 notes respectively. The requirements, if any, for each atomic elaboration \nare specified in Table 1.  \nThis aspect of elaborations considerably complicates reduction in that one branch of a tree \ncannot be derived (or generated) without reference to another. It also complicates the \ncorrespondence between the tree structure representing the reduction of a piece and \nsegmentations of that piece. (Lerdahl recognises an equivalent difficulty and accommodates \nit within his theory by a modification of the grouping rules to allow \u2017polyphonic grouping\u2018, \ni.e. grouping in different parts which is \u2017out of phase\u2018 (Lerdahl, 2001, pp.32\u201334).) \nMost importantly, two segments can only legitimately be children of a parent segment if all \nof the elaborations along the \u2017trailing edge\u2018 of the tree below the first child (i.e. the \nelaborations of that child, and of its second child, and of the second child of that child, etc.) \nfind their required post-context pitches in the second child or the segments along the \n\u2017leading edge\u2018 of the tree below that second child, and vice versa for the pre-context pitches \nof the elaborations along the \u2017leading edge\u2018 of the tree below the second child. Furthermore, \nan elaboration cannot find its required post-context pitch in a segment which is at a higher \nlevel than an elaboration which finds its required pre-context pitch in a parent of that \nelaboration. These constraints can be equivalently expressed as follows: it must be possible \nto progressively elaborate from the root segment by applying one elaboration at a time to \nany currently non-elaborated segment in a sequence such that at every step the required \npre-context notes of every atomic elaboration making up the elaboration of that segment \nare present in the immediately preceding unelaborated segment and the required post-\ncontext notes of every atomic elaboration are present in the immediately following \nunelaborated segment. \nThe formal definition below, and the implemented reduction process, make use of the \nconcept of a \u2017valid sequence\u2018 of segments. This is a pair of segments which conforms to the \nconstraint on contexts described above. In the base case, every pair of consecutive surface \nsegments is a valid sequence (because surface segments are not elaborated). From this the \nvalidity of any other pair of consecutive segments can be induced: a pair is valid if either the \npair made of the second child of the first segment and the second segment is valid or the \npair made of the first segment and the first child of the second segment is valid. \n3.5 Harmonic constraints and combinations of elaborations \nElaborations generally require certain notes to be consonant. (The others need not be \ndissonant, but often are, or at least are dissonant with respect to the time span of the \nelaborated note.) When simultaneous elaborations occur, the consonances they imply must \nbe consistent. This is defined to mean that the pitch classes of the consonant notes must be \nmembers of an acceptable harmony. Properly, a complex definition referring to keys and \nprogressions is required for harmonies, but for the present purposes it is sufficient to define \nharmonies as sets of pitch classes. Every segment has associated with it a harmony, which is \na (possibly empty) set of pitch classes. This set indicates those pitch classes which are \nconsonant within that segment. Note that it is not necessary for all the pitch classes in the \nset of pitch classes to be actually present in the notes of that segment. All surface segments \nhave an empty harmony. \nEight kinds of acceptable harmony are defined: four triads\u2014minor, major, diminished and \naugmented\u2014and four sevenths\u2014dominant, minor, diminished, and half diminished. \n(Harmonies should be added to or removed from this list according to the repertoire under \nexamination; as stated previously, the objective at this stage is to keep definitions simple.) \nThe harmony of a segment is acceptable if it is equal to or a subset of one of these eight. In \nthe reduction process described below, a distinction is made between \u2017simple\u2018 harmonies\u2014\nminor, major and diminished triads, and the dominant seventh of the current key\u2014and \n\u2017complex\u2018 harmonies\u2014augmented triads, minor, diminished and half-diminished sevenths, \nand dominant sevenths in other keys. This is intended to encompass the concept that some \nharmonies are more consonant than others, and to reflect in part Schenker\u2018s theory \nconcerning seventh chords. While Schenker made clear that he did not regard seventh \nchords as consonant harmonies like triads (see Brown, 2005, p.58), he did also allow the \npossibility of a dominant seventh occurring even at the first level of elaboration of the \nUrsatz (see, for example, Figure 19 of Der freie Satz (Schenker, 1935, supplement)). I \ntherefore include the dominant seventh among the \u2017simple\u2018 harmonies (an approach \nrecommended in Pankhurst, 2008, pp.22\u201325). \nIn a reductional structure, the harmony of the parent segment must be equal to, or a \nsuperset of, the harmony of at least one of the child segments. Which child this must be is \ncharacterised as \u2017inheritance\u2018: \u20171st\u2018 indicates that the harmony of the first child is equal to \nor a subset of the harmony of the parent, \u20172nd\u2018 that the harmony of the second child is \nequal to or a subset of the harmony of the parent, while \u2017either\u2018 indicates that either or both \nmay be equal or a subset. A special inheritance of \u2017IV\u2018 is used in the case of \u2017interruption\u2018 \nelaborations to specify that the harmonies of the children must be equal to or subsets of I \nand V7 respectively. At later levels of reduction, an inheritance of \u2017both\u2018, requiring the \nharmonies of both children to be equal to or subsets of the parent harmony, is also \npossible. (Schenker does not state this requirement for inheritance of harmony in his theory, \nbut it is evident from his analyses. It is explicit in the theory of Lerdahl & Jackendoff (1983, \npp.152\u2013155).)  \nAgain, although not a recognised component of Schenkerian theory, it is useful to make a \ndistinction in the harmonic behaviour of children between progressions and non-\nprogressions. (This is similar to the \u2017progressions\u2018 and \u2017prolongations\u2018 of Lerdahl & \nJackendoff (1983, pp.181\u2013182).) A progression occurs when the harmonies of one of the \nchildren is not equal to or a subset of the harmony of the parent. In this case all the notes of \neach of the two child segments must be consonant with their respective harmonies. In the \ncase of a non-progression, when the parent harmony is equal to or a superset of the \nharmony of both child segments, it is possible for dissonant notes to occur. \nThere seems no reason to insist that a parent note cannot be elaborated by more than one \natomic elaboration. On the contrary, there appear to be instances in actual analyses where a \nsingle note is elaborated simultaneously in more than one way. Similarly, there seems no \nreason to insist that a single note cannot be the child of more than one atomic elaboration. \nOn the other hand, the logic of the tree structure of segments requires that every note in a \nsegment which is not a leaf must be a parent of at least one atomic elaboration. \nFurthermore, every note in every segment which is not the root must be a child of at least \none atomic elaboration.  \nSchenker does admit \u2017implied notes\u2018 which occur at higher levels but do not correspond to \nany note with the same pitch at the surface, and also the possibility that a note might occur \nat a higher level in a different octave from that at which it occurs at the surface, by \u2017register \ntransfer\u2018. However, these are subtleties which are not accommodated in this proof of \nconcept, and in the formalisation used here every atomic elaboration has a parent note \nwhich has the same pitch as one of its children. This means that the two children can be \ndesignated as a \u2017main note\u2018 and a \u2017subsidiary note\u2018. While, as indicated above, a single note \ncan be a child of more than one atomic elaboration, it cannot be a subsidiary note in one \nbut a main note in another. \n3.6 Summary \nTo summarise, the formal theory presented here uses the following concepts \npitch: integer \nduration: rational \npitch class: integer modulo 12 \ntie: boolean \nnote: pitch \u00d7 tie \nrest \nharmony: set of pitch class \ninheritance: \u20171st\u2018, \u20172nd\u2018, \u2017either\u2018, \u2017both\u2018 or \u2017IV\u2018. \nsegment: (set of note + rest) \u00d7 duration \u00d7 harmony \nsurface: sequence of segments \nanalysis: binary tree of segments \nand the following relations (\u2017_\u2018 stands for any unspecified argument, \u2205 for the empty set, I \nfor the tonic triad, and V7 for the dominant seventh): \nclass(p, pc): pitch \u00d7 pitch class \npc = p modulo 12; the operator class(p) can be defined to yield the pitch class pc such \nthat class(p, pc). \nconsonant(p, h): pitch \u00d7 harmony \nconsonant(class(p) \u222a h) \nconsonant(h): harmony \nThe harmony must be equal to or a subset of one of a certain set of harmonies, \ndefined by the tonal language. In the system described here this set is all major, \nminor, diminished and augmented triads, and all dominant, minor, diminished and \nhalf-diminished sevenths. \natomic_elaboration(n, n1, n2, p1, p2, h, i):  \nnote \u00d7 (note \u222a rest) \u00d7 (note \u222a rest) \u00d7 (pitch \u222a \u2205) \u00d7 (pitch \u222a \u2205) \u00d7 harmony \u00d7 inheritance \nThe arguments must conform to one of the elaboration patterns defined by the tonal \nlanguage, such as those defined in Table 1. The arguments are, respectively, the \nparent note, the first child note, the second child note, the pre-context pitch (if any) \nrequired to be present in some preceding segment, the post-context pitch (if any) \nrequired to be present in some following segment, the set of pitch classes which must \nbe consonant (the harmony), and the inheritance. \nelaboration(s, s1, s2, E): segment \u00d7 segment \u00d7 segment \u00d7 set of atomic_elaboration \nLet h, h1, h2 be the harmonies of s, s1, s2 respectively. \nAll the following must be true:  \nvalid_sequence(s1, s2). \nconsonant(h). \n{n: (n, _, _, _, _, _, _) \u2208 E} = notes of s. \n{n1: (_, n1, _, _, _, _, _) \u2208 E} - rest = notes of s1. \n{n2: (_, _, n2, _, _, _, _) \u2208 E} - rest = notes of s2. \nLet P1 = {p1: (_, _, _, p1, _, _, _) \u2208 E}.  \nIf P1 \u2260 {\u2205}, there must exist a segment s3 such that valid_sequence(s3, s) and \n\u2200p1 \u2208 P1 (\u2203n3 component of s3 (p1 = pitch of n3)). \nLet P2 = {p2: (_, _, _, _, p2, _, _) \u2208 E}.  \nIf P2 \u2260 {\u2205}, there must exist a segment s4 such that valid_sequence(s, s4) and \n\u2200p2 \u2208 P2 (\u2203n4 component of s4 (p2 = pitch of n4 and n4 is not tied)). \nLet h4 = \u22c3{h3: (_, _, _, _, _, h3, _) \u2208 E} and I = {i: (_, _, _, _, _, _, i) \u2208 E}.  \nEither (h1 \u222a h2 \u222a h4) \u2286 h  \nor let h1a = h1 \u222a {class(pitch of n1): n1 member of s1} and h2a = h2 \u222a \n{class(pitch of n2): n2 member of s2}.  \nconsonant(h1a) and consonant(h2a) and  \neither I \u2286 {1st, either} and (h1a \u222a h4) \u2286 h  \nor I \u2286 {2nd, either} and (h2a \u222a h4) \u2286 h \nor I = IV and h1a \u2286 I and h2a \u2286 V7 and h = I \nvalid_sequence(s1, s2): segment \u00d7 segment \nEither s2 follows s1 in the surface \nor let E1 be a set of atomic elaborations such that elaboration(s1, _, s12, E1), and \nvalid_sequence(s12, s2) and \nlet P2 = {p2: (_, _, _, _, p2, _, _) \u2208 E1}.  \nEither P2 = {\u2205} or \u2200p2 \u2208 P2 (\u2203n2 component of s2 (p2 = pitch of n2)). \nor let E2 be a set of atomic elaborations such that elaboration(s2, s21, _, E2), and \nvalid_sequence(s1, s21) and \nlet P1 = {p1: (_, _, _, p1, _, _, _) \u2208 E2}.  \nEither P1 = {\u2205} or \u2200p1 \u2208 P1 (\u2203n1 component of s1 (p1 = pitch of n1)). \nAs noted above, formally every segment contains a rest, even if no rest is notated in the \nscore at the corresponding point. (The only place where a rest must be notated is where a \nsegment contains no notes.) The piece to be analysed must be represented as a sequence of \nsegments whose harmonies are all \u2205 (the empty set). To derive a reduction, one needs to \nfind an analysis (a tree of segments) such that the sequence of leaves of the tree is equal to \nthe surface to be analysed, and for every segment s of the analysis and its children s1 and \ns2, a valid relation elaboration(s, s1, s2, _) holds.  \n3.7 Example of formal reduction \n \nFigure 1. Final bars of \u2017Au claire de la lune\u2018 \nSurface:  \n[1, {<67, no>}, \u2205], [1, {<71, no>, <55, no>}, \u2205], [1, {<69, no>, <50, no>}, \u2205],  \n[1, {<69, no>, <50, yes>}, \u2205], [4, {<67, no>, <55, no>}, \u2205] \nReduction:  \n[8, {<71, no>, <55, no>}, {2, 7, 11}] \n[4, {<71, no>, <55, no>}, {2, 7, 11}] \n[2, {<71, no>, <55, no>}, {7, 11}] \n[1, {<67, no>}, \u2205] \n[1, {<71, no>, <55, no>}, \u2205] \n{consonant skip 2, delay} \n[2, {<69, no>, <50, no>}, {2, 9}] \n[1, {<69, no>, <50, no>}, \u2205] \n[1, {<69, no>, <50, yes>}, \u2205] \n{repetition, hold} \n{neighbour note, consonant skip 1} \n[4, {<67, no>, <55, no>}, \u2205] \n{consonant skip 1, repetition} \nFigure 2. The surface and reduction of Figure 1 in numerical notation. Each segment is \nnotated as [duration, notes, harmony], and each note as <pitch, tied>. \nThe analysis of an example taken from the end of the French folk song \u2017Au claire de la lune\u2018 \nis illustrated in Figure 1. As described above, the piece must first be split into segments, as \nin the line labelled \u2017Surface\u2018, so the minim (half note) D3 is divided into two crotchets \n(quarter notes), the second tied to the first. Figure 2 gives the same information (but this \ntime containing information on harmonies) in a numerical form. \nThe first stage of reduction is to derive segment 1A from segments 1 & 2. These two \nsegments form a valid sequence, since both are surface segments. There is just one note in \nsegment 1, but every segment also includes a notional rest, so two atomic elaborations can \nform segment 1A from segments 1 & 2:  \nconsonant_skip_2(<71, no>, <67, no>, <71, no>, \u2205, \u2205, {7, 11}, either) \ndelay(<55, no>, rest, <55, no>, \u2205, \u2205, {7}, either) \nThe combined inheritance of these two atomic elaborations is \u2017either\u2018, so the harmony of \nsegment 1A must be a superset of the harmony of either segment 1 or segment 2, and of \nthe union of the required harmony of the atomic elaborations, i.e., {7, 11}. The harmony of \nsegment 1A is therefore {7, 11} (i.e., pitch classes G and B must be consonant), which is a \nvalid harmony. The duration of segment 1A is the sum of the durations of segments 1 & 2, \ni.e., 2. \nSegment 3A similarly derives from segments 3 & 4 by the following two atomic elaborations: \nrepetition(<69, no>, <69, no>, <69, no>, \u2205, \u2205, {9}, either) \nhold(<50, no>, <50, no>, <50, yes>, \u2205, \u2205, {2}, either) \nThe harmony of segment 3A is {2, 10} (i.e., pitch classes D and A must be consonant). \nSegments 1A & 3A make a valid sequence: the set of atomic elaborations which make \nsegment 1A has no required post-context pitches and the set which makes segment 3A has \nno required pre-context pitches; the second child of segment 1A, segment 2, is a surface \nsegment and so makes a valid sequence with segment 3, also a surface segment; therefore \nsegment 1A makes a valid sequence with segment 3, and since this is the first child of \nsegment 3A, segment 1A makes a valid sequence with segment 3A. Furthermore, they can \nbe reduced to segment 1B by the following set of atomic elaborations: \nneighbour_note(<71, no>, <71, no>, <69, no>, \u2205, 67, {11}, 1st) \nconsonant_skip_1(<55, no>, <55, no>, <50, no>, \u2205, \u2205, {2, 7}, either) \nThe harmony of segment 1B must therefore be the union of the required harmony of these \ntwo atomic elaborations, and of the harmony of segment 1A (by virtue of the \u20171st\u2018 \ninheritance of the first atomic elaboration). Its harmony is therefore {2, 7, 11} (i.e., pitch \nclasses G, B and D must be consonant). \nFinally, segment 1C is formed from segments 1B and 5. That these two segments make a \nvalid sequence is slightly more complicated, because one of the atomic elaborations \ninvolved in the derivation of segment 1B requires a post-context pitch: the pitch 67 (G4), to \nwhich the neighbour note resolves, must be found. This pitch is present in segment 5, and \nso the segments form a valid sequence. Segment 1C can then be derived by the following \ntwo atomic elaborations: \nconsonant_skip_1(<71, no>, <71, no>, <67, no>, \u2205, \u2205, {7, 11}, either) \nrepetition(<55, no>, <55, no>, <55, no>, \u2205, \u2205, {7}, either) \nThe segments at level A form an Ursatz: the three segments have top pitches in the \nsequence 71, 69, 67 (B4, A4, G4) forming a step-wise descent to the tonic. The first and last \nsegments have tonic harmony and the tonic pitch in the bass. (In fact the harmony of the \nlast segment is the empty set, which means that strictly any pitch can be consonant, but this \nadmits the possibility of tonic harmony, which is all that is required.) This reduction \ntherefore forms a valid analysis of this tiny piece. \nNote that other sets of atomic elaborations can produce the same reduction, and there are \nother possible valid reductions of this piece. Music theorists admit the possibility that there \ncan be more than one valid Schenkerian analysis of a piece of music. A great deal of the \nliterature discusses alternative analyses, with a strong implication that some analyses are \nbetter than other valid but weaker analyses. As will become clear below, a major difficulty in \nthe implementation of Schenkerian analysis is to choose between many alternative analyses. \n4. A Reduction Algorithm \n4.1 Deriving a reduction \nFrom inspection of Table 1, it is clear that, given any pair of notes n1 and n2, it is possible \nto determine the possible parent notes and elaborations which could generate this pair of \nnotes, i.e., to find all members of the relation atomic_elaboration(n, n1, n2, p1, p2, h, i) \nwhich have n1 and n2 as arguments. Using this information, for any pair of segments s1 and \ns2, it is therefore possible to determine all possible parent segments s such that \nelaboration(s, s1, s2, _). A procedure for this is as follows. First we must ensure that s1 and \ns2 form a valid sequence. We can determine whether or not this is the case from a record of \nthe intermediate segments and pre- and post-context requirements of elaborations by \nwhich s1 and s2 are derived from the surface. Then, taking each possible pair of notes and \nrests from s1 and s2, and each combination of the atomic elaborations which can apply to \nthese pairs, we can determine valid combinations of atomic elaborations by taking the union \nof their harmonies and their inheritances and ensuring that these are valid harmonies, and \nwe can form the resulting segments from the set of resultant parent notes and the resultant \nharmonies. \nThe only tricky part of this is the requirement for possible context notes p1 and p2 in \natomic elaborations, since these do not need to occur at the surface of the piece but might \ninstead arise in reductions from the surface. (In the piece illustrated in Figures 1 and 2, for \nexample, the G4, which is the required context for the \u2017neighbour note\u2018 elaboration by \nwhich segment 1B is derived, need not have occurred at the beginning of the second bar of \nthe surface. There might have been some elaboration of this note which places a different \nnote or a rest at the beginning of that bar. The required context note would then have \noccurred not at the surface but at level A, in a new segment 5A.) However, the only pre-\ncontext note required in the set of elaborations defined in Table 1 is for suspensions, and \nthis note (called a \u2017preparation\u2018 in music theory) must be tied to the first of the child notes, \nand therefore it must be present at the surface, since no note can intervene between the \nnote tied from and the note tied to. (In fact, this is an oversimplification, and in some \nrepertoires suspensions do occur with a \u2017remote\u2018 preparation which, on the surface, does \nnot occur immediately before the suspension and is not tied to it. However, such cases \ncould also be considered, when using the set of elaborations of Table 1, to be \nappoggiaturas, which require no pre-context.) Thus it is only post-contexts which need to \nbe sought in levels above the surface. If reduction proceeds \u2017backwards\u2018 through a piece, \nfrom the end to the beginning, any required post-context notes will, at each point, have \nalready been found in reductions of the following section of music. \nA naive reduction procedure, then, might select a pair of as-yet unreduced segments near \nthe end of the piece and determine a set of atomic elaborations and a parent segment which \ncould produce this pair as children. Then it would recursively select another pair of \nunreduced segments, possibly including the newly created parent segment, and determine \nits set of atomic elaborations and parent. If for any chosen pair a set of atomic elaborations \nand parent segment cannot be found, the procedure could try another pair instead. If all \npossible pairs have been tried, the procedure could backtrack, undoing the last reduction, \nand try a different reduction, either for the same pair of for a different pair. At each step, \nexcept one involving backtracking, the number of segments still to be reduced is one less. \nProvided the backtracking procedure tries every possibility and does not try a possibility \nwhich has been tried before, the procedure will eventually find a complete reduction if one \nexists, resulting in just a single segment at the highest level. \nThis is essentially the same argument as used by Kassler (1976) to demonstrate that \nautomatic Schenkerian reduction is a logical possibility. However, the naive procedure \nsuffers from two faults. Firstly, there is no guarantee that an analysis will be found in a \nreasonable time. It is entirely possible that the procedure will spend so long finding a valid \nanalysis of the piece as to be useless. Secondly, experiments have shown that the atomic \nelaborations defined here can produce analyses which are valid in the terms of this theory, \nbut which most analysts would regard as unacceptable. Furthermore, it is possible (indeed \nlikely) that different definitions of elaborations, unless the definition is vastly more complex, \nare likely to also produce unacceptable analyses. The \u2017rules\u2018 of Schenkerian analysis seem to \nbe too loose to determine acceptable analyses by themselves alone. (Temperley makes a \nsimilar point based on some initial experiments. (Temperley, 2007, pp.175\u2013176)) Other \nfactors must come into play to distinguish acceptable from unacceptable analyses or, better, \ngood from bad. A path towards solution of these two problems is the main contribution of \nthis paper. \n4.2 Explosion of the solution space \nFor all but the smallest pieces, the size of the possible solution space\u2014the number of \npossible analyses\u2014is extremely large, and grows extremely rapidly with larger pieces, for \ntwo reasons. Firstly, the number of binary trees with the same number of leaves but with \ndifferent branching increases very rapidly with increases in the number of leaves. If all \npossible branchings are allowed, the number of different binary trees for n leaves is given \nby the \u2017Catalan number\u2018 Cn: (2n)!\/(n+1)!n!. There are 14 trees with five leaves, but 4862 \nwith ten. As we will see below, for actual pieces of music, even taking into account \nrestrictions on branching, the number of possible trees is well over a trillion. \nSecondly, the notes from segments reduced together can be paired differently. It is not \nnecessarily the case that the top note of the first segment will be paired with the top note of \nthe second, etc. The top note of the first segment might be paired with a rest, for example, \nand its second highest note be paired with the top note of the second segment. To \ndetermine the total number of different possible analyses, the number of different pairings \nin the reduction of one pair needs to be multiplied by the number of reductions in the \npreceding pair, etc., with the result that the number of possible analyses rises exponentially \nas the length of the music to be analysed increases. \n4.3 Matrix of partial solutions \nA common technique to overcome such combinatorial explosion is to use dynamic \nprogramming. This is a procedure which constructs an array of local solutions together with \nsome scoring metric. It is necessary that each local solution and score be derivable from the \ninformation stored in the immediately neighbouring local solutions on which it is based. \nOnce the array is complete, the optimal global solution is constructed by tracing back the \npath through the best scoring local solutions to the origin. The technique typically \ntransforms a problem of exponential complexity to one of polynomial complexity. \nThe technique used here is of this kind, and essentially uses the CKY algorithm (Jurafsky & \nMartin, 2009, pp.470\u2013477) to act as a kind of chart parser (Jurafsky & Martin, 2009, pp.482\u2013\n484). This constructs a \u2017chart\u2018 of partial parses, like a dynamic-programming array, on the \nway to making a complete parse of a sentence. An empty triangular matrix of \u2017cells\u2018 is \nformed with the segments of the surface in the lowest row. The second row of cells will hold \nsegments which will each span two surface segments, the third row segments spanning \nthree surface segments, etc., until the highest cell contains segments which span the entire \npiece. Essentially using the bottom-up CKY algorithm, this array is filled from the bottom \nright with all the possible segments which result from reduction of each of the pairs of \nsegments which cover the span of each cell.  \nOnce the matrix is filled, complete analyses can be extracted from the matrix by selecting \none of the top-level segments, and then recursively selecting pairs of possible child \nsegments until the surface is reached. The selection process is rather complicated because \nis it necessary to ensure fulfilment of the context constraints on the elaborations by which \nparents are derived from children. Thus selecting a child in one branch of the analysis can \nhave the effect of invalidating certain selections in an adjacent branch. If records are kept of \nthe context constraints for each parent-child relationship, elaborations rendered invalid in \nanother branch can be removed, restricting the choice of children in that branch. However, \nthe constraints can have remote consequences also, and the currently implemented \nprocedure does occasionally reach a point where no valid children can be selected. In such \ncases selection must either backtrack or start again. The analysis selection procedure is \nthus, in the worst case, of factorial complexity, and so I cannot claim to have implemented a \nSchenkerian-analysis procedure of polynomial complexity. However, in practice the \nconstraints are rather loose, and so backtracking is not common and the worst case rarely \narises. \nAs the matrix is filled, three additional pieces of information are attached to derived \nsegments: \n1. \u2017Goodness\u2018 score. This allows later selection, in dynamic-programming fashion, of a \nbest-scoring analysis. Section 5 describes a first attempt to establish a suitable \nmetric for goodness.  \n2. Ursatz possibilities. This gives the parts of an Ursatz which a segment can supply \n(whether as single upper and bass notes or as a sequence of such notes in its \nchildren and other descendents). This allows selection of top-level segments and \nsubsequent children to be restricted to only those which yield an analysis containing \nan Ursatz.  \n3. The multiplicity of sub-trees. This is an upper bound on the number of different \npossible sub-trees there are below the segment concerned. This information is used \nin selecting a sample of analyses and is described in more detail in Section 5.2. \nOnce the matrix is filled, it is pruned in a top-down process which removes segments below \nthe top level which have no parent. At the same time, the record of Ursatz possibilities is \nalso pruned to remove records of possibilities which turn out to be impossible to realise \nbecause the necessary corresponding parts of an Ursatz can never arise from neighbouring \nsegments. \n4.4 Computational complexity \nThe time complexity of the CKY algorithm is generally described to be of order O(n3). The \nsize of the matrix, and so the number of cells to be filled, is clearly related to the square of \nthe number of surface segments. The number of pairs of lower-level cells to be considered \nwhen filling a cell increases linearly with the height of the row of the cell, related in turn to \nthe number of surface segments, yielding an order where the square of the number of \nsegments (for the number of cells) is multiplied by the number of surface segments once \nmore (for the number of pairs to be considered at each cell), and the quoted order of O(n3). \nA further factor to be considered, however, is the number of alternative segments stored in \neach cell. At the surface there is only one segment for each cell, but at higher levels there \ncan be many alternative reductions. In the absence of information on which to make a better \ninference, we might assume that the number of alternative segments stored in a cell \nincreases linearly with the height of the row of the cell. The maximum number of alternative \npairs of segments to be considered for reduction for each pair of cells is the product of the \nmaximum number of alternative segments in each cell. This maximum number of segments \nis related to the number of surface segments, so the maximum number of pairs is related to \nthe square of the number of surface segments, and the overall time complexity should be \ntaken to be O(n5) [O(n3 * n2)]. On the other hand, there is a ceiling on the number of \npossible alternative segments in a cell, because there is a finite limit to the number of \npossible combinations of notes which can be played simultaneously on a keyboard, so this \nfactor can strictly be considered as constant and the time complexity taken to be the \ntheoretical O(n3). In practice, the time complexity is likely to be between n3 and n5. Other \nfactors do not change this order of complexity: determining the presence or absence of a \nrequired context, and whether or not a pair of segments forms a valid sequence can both be \ndone in constant time with appropriate record-keeping; the time taken by top-down \npruning is related only to the size of the matrix. \nIn space, the base theoretical complexity is O(n2), determined by the size of the matrix to be \nfilled. However, once again, the number of alternative segments to be stored in each cell \nshould be considered, which would increase this complexity to O(n3). Furthermore, the \nrequirement to record the validity of each pair of possible segments increases this yet \nfurther to O(n4). As for time, because of constraints on the number of alternative segments, \na realistic estimate of space complexity is likely to be between n2 and n4. \nThese quantities are better than the factorial order outlined in section 4.2, but still too large \nto yield a useful algorithm. Section 6 briefly considers the development of different \nalgorithms of lower complexity. \n4.5 Limits \nInitial results showed that unrestricted filling of the matrix of cells was practical only for \nextracts of music just a handful of segments long. Thus certain limits have been imposed to \nrule out reductions believed to be almost always \u2017bad\u2018 and keep the processing \nrequirements of time and space within practical bounds, as follows.  \n1. Segments are limited to no more than four notes on the grounds that Schenkerian \ngraphs usually show no more than four simultaneous lines.  \n2. \u2017Complex\u2018 harmonies (i.e., seventh harmonies other than the dominant seventh) are \npermitted only in contexts where there is no possible reduction which results in a \nsimple harmony. \n3. Pairing of very short with very long segments is restricted, especially if the short \nsegment comes first. (It will be seen that empirical investigations confirmed that \nthese were indeed apparent factors in the goodness and badness of reductions.) If \nthe short segment comes first, it must have no less than a third of the duration of \nthe longer one. If the short segment comes second, it must have no less than an \neighth of the duration of the longer one. \n4. The complexity of division of a time span is limited. If the ratio between two \nsegments forming a sequence valid for reduction is expressed as a rational number \nin its simplest form, the sum of the numerator and denominator must not exceed \nnine.  \n5. There is a limit on the syncopation inherent in derived segments. Each time point at \nthe surface is associated with a given level of beat. The beginning of a bar is level 1, \nthe next strongest beat or beats (if the division is into threes) within the bar are at \nlevel 2, etc., with each time division introducing a weaker level of beat. (The \nmechanism is explained more fully in Section 5.5 below.) A segment is syncopated if \nthere exists a time point within its span which has a stronger level of beat than the \nlevel at the start of the segment. The limit on syncopation used here is that there can \nbe no time point which is more than one level stronger than the start of the \nsegment. (The empirical investigations reported below confirm that syncopation \nshould, on balance, be avoided.) \n6. Pairings of notes between segments which produce crossing voices are not \npermitted. I.e., if note n1 in the first segment is paired with note n2 in the second, \nthen no note below (above) n1 can be paired with a note above (below) n2. A similar \nrestriction prevents crossing over a note paired with a rest: if n1 is paired with a rest, \nthen no note below (above) n1 can be paired with a note in the other segment which \nis higher (lower) than n1. \n7. The number of voices which can join at or split from a single note is restricted. A \nnote n1 can be paired with no more than two notes in the other segment. If it is \npaired with a rest, it cannot be paired with any other note.  \n4.6 Example of automatic reduction \n \n \n \n \n \n     \n     \n     \n     \nG4 B4 \nG3 \nA4 \nD3 \nA4 \n_D3 \nG4 \nG3 \na. \n \n \n \n     \n     \n     \n  A4 \nD3 \n  \nG4 B4 \nG3 \nA4 \nD3 \nA4 \n_D3 \nG4 \nG3 \nb. \n \n     \n     \n  G4 \nG3 \nD3 \n  \n  A4 \nD3 \n  \nG4 B4 \nG3 \nA4 \nD3 \nA4 \n_D3 \nG4 \nG3 \nc. \n \n \n \n \n \n \n \n \n     \n     \n B4 \nA4 \nG3 \nD3 \nG4 \nG3 \nD3 \n  \n B4 \nG3 \nD3 \nA4 \nD3 \n  \nG4 B4 \nG3 \nA4 \nD3 \nA4 \n_D3 \nG4 \nG3 \nd. \n \nB4 \nG4 \nG3 \nD3 \n    \nB4 \nA4 \nG4 \nG3 \nD3 \n    \nB4 \nA4 \nG4 \nG3 \nB4 \nA4 \nG3 \nD3 \nG4 \nG3 \nD3 \n  \nB4 \nG4 \nG3 \nB4 \nG3 \nD3 \nA4 \nD3 \n  \nG4 B4 \nG3 \nA4 \nD3 \nA4 \n_D3 \nG4 \nG3 \ne. \n \n \n \nB4 \nG4 \nG3 \n    \nB4 \nA4 \nG4 \nG3 \nD3 \n    \n  G4 \nG3 \nD3 \n  \nB4 \nG4 \nG3 \n A4 \nD3 \n  \nG4 B4 \nG3 \nA4 \nD3 \nA4 \n_D3 \nG4 \nG3 \nf. \nFigure 3. Illustration of reduction procedure.  \nThe reduction procedure is illustrated in Figure 3. The music here is the same as in Figures \n1 and 2. The bottom row of the charts a-f represents the segments of the surface of the \npiece. Each cell in each second row from the bottom contains segments which span two \nsegments of the surface (the one below and the one below and to the right). Each cell in \neach third row contains segments which span three segments of the surface, etc. \nChart a represents the initial state, when only the surface segments exist. The first step is to \nreduce the last pair of segments to find segments to fill the last cell of the second row from \nthe bottom. However, the resulting segments would exceed the syncopation limit. (The time \npoint at their start is two levels weaker than the level at the start of the next bar, which \nwould be included in the span of the resulting segments.) Therefore no segments are \nderived. \nAt the next step, the possible segments resulting from reducing the third and fourth surface \nsegments (A4\/D3 with A4\/_D3) are placed in the second-to-last cell of the row second from \nthe bottom. Only one segment is possible: one consisting of the notes A4 and D3, as shown \nin chart b.  \nThen the segments for the cell above, which covers the last three segments of the surface, \nare derived. The segments in this cell could be derived from two pairs of cells: the third cell \nof the surface with the last cell of the second-from-bottom row, and the third cell of the \nsecond-from-bottom row with the last cell of the surface. However, the last cell of the \nsecond-from-bottom row contains no segments, so only the second possibility is \nconsidered, which means that only one pair of segments needs to be considered since the \nthird cell of the second-from-bottom row contains only one segment, like the last cell of the \nsurface. This pair of segments (A4\/D3 and G4\/G3) produce three possible reductions: \nG4\/G3\/D3, G4\/G3 and G4\/D3, represented in chart c only by their constituent pitches. \nIn a similar manner, two cells of the second column are filled with three and four segments \nrespectively, to produce the chart d. The top cell of this column remains empty because its \nsegments would once again exceed the syncopation limit. Furthermore, one of the possible \nsegments in the second-from-bottom cell (B4\/G3) of this column is subsequently deleted \nbecause it turns out not to have any parents in later reductions. (This segment lacks D3, \nwhich is necessary to make a reduction with the fourth segment of the surface, since the \nonly note which can form an atomic elaboration with the tied _D3 in that segment is another \nD3.) \nFinally the cells in the first column are filled from the bottom up with seven, fifteen, sixteen \nand fifteen segments respectively. Once again some of the segments in the third row, first \ncolumn are subsequently removed because they lack parents, leaving just nine segments in \nthis cell. The result is illustrated in chart e. \nChart f shows the result of pruning the resulting set of reductions to leave only those which \ncontain an Ursatz. Let it be stressed that the cells of the chart properly contain sets of \nsegments, not sets of pitches as Figure 3 might imply. The notation used there is intended \nto be illustrative only, but readable. For example, it should not be presumed that the cell in \nthe second row, first column of chart f contains segments made up of all combinations of \nthe five pitches listed there. There are 31 such combinations. Some are excluded because \nthey do not make valid harmonies or the seventh chords they imply would not be allowed. \nHowever, seventeen combinations of these pitches would imply simple harmonies, but the \ncell in the resulting chart contains just eight cells. (The example software referred to below \nshows more details, allowing a chart to be constructed, explored and manipulated.) \nFrom the resulting chart f, it is possible to select a number of valid analyses, including the \none shown in Figures 1 & 2. \n5. Empirical Results and a \u2017Goodness\u2018 Metric \n5.1 Software \nThe reduction procedure described above has been implemented in software, using the \nprogramming language Java, version 1.6. Example software is available for download at \nhttp:\/\/lancs.ac.uk\/staff\/marsdena\/schenker. A demonstration applet is also provided. At \npresent, musical input must be in a text file in a simple but specific format. It is intended to \nallow import from formats such as Humdrum kern (Huron, 1997) and MusicXML (Good, \n2001) in future. The software at this stage is intended to facilitate further theoretical \nresearch rather than to provide a tool for making Schenkerian analyses. \nThe results reported below arose from using this software on a computer with 4GB of RAM \nand an Intel Core2 Duo processor running at 2.66GHz with the Ubuntu operating system \n8.04.  \n5.2 Materials \nThe materials used in this investigation are four themes from movements in rondo form \nfrom piano sonatas by Mozart (the last movements of K.545, K.333, K.570, and the rondo \nK.494, which was published with the two movements K.533 to form a complete sonata)   \nand two themes from variation movements (the first movement of the sonata K.331 and the \nlast of K.284). All these themes form small but complete and self-contained musical units: \nin Schenkerian terms, they contain an Ursatz. The four rondo themes are ones I have used \nfor many years in teaching Schenkerian analysis to undergraduate students, for the same \nreason of combination of compactness and completeness. As a consequence, there are pre-\nexisting analyses for these themes in the model answers I have supplied to students. \nFurthermore, the theme from K.333 is used as an exercise in the textbook by Forte & Gilbert \n(1982a, p.140), who also provide a model answer (1982b, p.42). Forte & Gilbert and other \nauthors also present analyses of the variation theme from K.331, while my colleague Neil \nBoynton has kindly allowed me to use an analysis he himself has made of the theme from \nK.284. These analyses form a \u2017ground truth\u2018 sufficiently sound for this initial investigation. \nIdeally the ground truth would consist entirely of analyses by someone other than myself\u2014\nideally they would be by Schenker\u2014but it is difficult to find complete analyses of short but \ncomplete musical examples. At the outset of this investigation I had planned to use also the \nlast-movement themes from K.330 and K.576, which I use in teaching alongside the other \nfour, but the demands of computing time and space from these slightly longer themes were \nprohibitive. \nIndeed, short as they are, only parts of these six themes have been used. The extracts \nanalysed are taken from, or based on, just the second phrase of each of the themes. (All the \nthemes have a first phrase which ends on the dominant and a second which starts like the \nfirst phrase but ends on the tonic.) The resulting six phrases are given in Figure 4. The \nexample from K.570 is not exactly the second phrase of the Mozart theme; it omits the \nanacrusis and a grace note and replaces the penultimate note of the melody line. In the \noriginal this note is D5, a note which music theory would call an \u2017\u00e9chapp\u00e9e\u2018 because it is \ndissonant with the dominant harmony but does not resolve down to the consonant C5. \n(Other formulations would call this an \u2017incomplete neighbour note\u2018.) This kind of elaboration \ncould have been included in the set defined in Table 1, but, because it is only loosely \nconstrained, possible examples could then be found in many places, considerably increasing \nthe already severe complexity of the reduction process. As an expedient to allow some \nresults to be obtained, this note has been replaced by the Bb4 found in example 3, which is \ninstead an \u2017anticipation\u2018. Similarly, the example from K.284 omits the anacrusis of two \ncrotchet (quarter-note) A4s, and a middle-voice A3 is missed out in the last bar to ensure \nthat no segment contains more than four notes. \n  \n \n \n \n \n \nFigure 4. Six Mozart themes (some slightly modified). \nOutline reductions were derived from the \u2017ground-truth\u2018 analyses of each of the examples. \nIn a number of cases, the analyses could be interpreted in slightly different ways. There \nwere two sources of ambiguity. First, since the rhythm of higher levels is not specified, \noccasionally the notes of a higher level could align with the surface in more than one way. \nSecond, the analyses sometimes transposed bass notes by an octave to make a neater \nanalysis, and the reduction could contain a note in one of two possible octaves. For each \nambiguous case, a reduction was formed encompassing each possible interpretation \n(though the differences were very small). Thus there were often more possible \u2017ground-\ntruth\u2018 reductions for an example than there were original analyses. As an example, Figure 5 \nshows the \u2017ground truth\u2018 outline reduction derived from Forte & Gilbert\u2018s analysis of the \nK.333 theme (1982b, p.42). The reduction of this theme derived from my teaching materials \ndiffers from this in some lower-level details (the bass crotchets (quarter notes) D4-G4 in the \nfirst bar (measure) are omitted and a quaver (eighth note) D5 is included) and in taking C4 \nrather than F4 as the main bass note of the second bar. \n \nFigure 5. Outline reduction of the K.333 theme derived from Forte & Gilbert (1982b, p.42). \n5.3 Method \nThe research method, in outline, was as follows.  \n1. The reduction chart was derived for each example, following the procedure \ndescribed in Section 4. \n2. A sample of 1000 analyses was selected from the chart, without regard as to whether \nor not they contained an Ursatz. \n3. A second sample of 1000 analyses was selected, this time selecting only analyses \nwhich contain an Ursatz. \n4. A third sample of 1000 analyses was selected, this time selecting only analyses \nwhich both contain an Ursatz and conform to a \u2017ground-truth\u2018 reduction. A sample \nwas taken for each \u2017ground-truth\u2018 reduction. These analyses were taken to constitute \n\u2017good\u2018 analyses, since they conform to the ground truth. \n5. A \u2017preferred\u2018 analysis was selected, containing an Ursatz and conforming to a \n\u2017ground-truth\u2018 reduction, which yielded the apparent best analysis, according to my \nexperience of Schenkerian analysis and my musical judgement. Figure 6 shows the \npreferred analysis for the K.333 theme. \n6. The results of steps 2-5 were measured according to a set of candidate goodness \nmeasures, and the means and standard deviations computed for each set. \n7. A candidate \u2017goodness\u2018 metric was derived from those measures which distinguished \nthe ideal analyses (step 5) and the good analyses (step 4) from the sample analyses \nwith Ursatz (step 3). \n8. To test the \u2017goodness\u2018 metric, for each example the reduction chart was derived \nonce again using the new goodness metric, and the highest-scoring analysis was \nselected. (The segments derived in the reduction process were identical to those \nderived in step 1, but they now had meaningful scores attached.) If the procedure \nand goodness metric were correct, each selected analysis should both conform to a \n\u2017ground-truth\u2018 reduction and appear reasonable on the basis of musical judgement. \n9. As a further test of the \u2017goodness\u2018 metric, step 8 was repeated with pruning. At each \nstep, only the n best-scoring segments were kept, with n, the \u2017pruning limit\u2018, \nranging from 1 to 100. If the goodness metric were effective, a good analysis should \nresult from a low pruning index in each case. \n \nFigure 6. Preferred analysis of the K.333 theme. \nThe test procedures used here are not really adequate: tests should be made on material \ndifferent from that used to derive the goodness metric to avoid the error of over-fitting. \nIdeally, more extensive testing would be carried out on different materials, but to be \npractical this will have to await collection of a suite of suitable test materials and \ndevelopment of more efficient algorithms. The procedures outlined here have taken about \ntwo weeks of processing time to complete.  \n5.4 Sampling \nFor this procedure to be at all valid, the samples taken in steps 2\u20134 should fairly reflect the \ndistribution of their sets. Naively selecting child segments at random will not result in a fair \nsample, because the number of possible sub-trees below one child might be very different \nfrom those below another. Selecting children with equal probability will result in a higher \nlikelihood of selecting analyses which exist among fewer alternatives. Ensuring that each \ndifferent analysis has an equal likelihood of selection requires weighting the selection of \nchildren by the multiplicity of the sub-trees below them. This quantity is recorded as the \nreduction chart is filled as follows. The multiplicity at a surface segment is 1. The \nmultiplicity at segments above the surface is the sum of the products of the multiplicities of \neach pair of child segments. This is the total number of possible sub-trees below that \nsegment, ignoring any context constraints, and is therefore an upper bound on the number \nof valid sub-trees. As selection proceeds, the non-selected segments are removed. \nElaborations and segments which have become invalid because their required contexts have \nbeen removed are then also removed, and the procedure repeated recursively until all \nconsequential changes have been made. The multiplicity for segments is then recalculated \nto compute the new (lower) upper bound. Selection is thus not guaranteed to be completely \nfair, but the difference between the upper bound on multiplicity of sub-trees and the actual \nnumber of valid sub-trees is relatively small, and any unfairness which remains in the \nselection procedure must be the result of variation in this difference. I know of no reason \nwhy this variation should be systematic and so believe that the selection is likely to be \nsufficiently fair. \nA by-product of this selection procedure is a means of estimating the total number of valid \nanalyses in each set. The reduction in multiplicity after recalculation following the selection \nof a pair of child segments can be measured at each stage. Assuming that this reduction \ndoes not vary systematically from one part of the chart to another, the average reduction \ncan then be applied to the sum of the multiplicities of the top-level segments to arrive at an \nestimate of the total number of valid analyses. \nTable 2 gives these estimated sizes, the computation times and other data for each of the \nsix examples. The reduction chart for the K.545 theme contained no analysis which \nconformed to the ground truths, so the sets at steps 4 and 5 were empty. This theme is \nunusual in that it does not start with a root position tonic (and indeed it is the one students \nfind most difficult!); both my sample answer and that of Forte & Gilbert (1982b, p.44) take a \nbass C to be implied at the beginning, a step not unusual in Schenkerian analysis, but not \none accommodated in the theory as formalised here. Peculiarities in this theme probably \nalso underlie another anomaly: that the estimated number of possible reductions with an \nUrsatz is greater than the estimated total number of possible reductions, which is clearly \nwrong. Something about this theme caused a severe over-estimate of the factor by which \nthe raw multiplicity should be reduced when estimating the total number of possible \nreductions, a much greater reduction than in the case of the other themes. \nAs indicated in section 5.2 above, I had originally intended to use two other themes also. \nHowever, even when these were simplified by making a composite phrase which joined the \nopening few bars of the first phrase to the conclusion of the second phrase, the result was \ntoo large to deal with. A reduction chart could be derived successfully (though only after \nhours of processing), but the amount of memory taken was so great as to make any further \nprocessing with this chart impractical, especially since the selection procedure is of \nexponential order of complexity in time. Table 2 includes figures for the time and space \ntaken to derive the reduction chart for each theme. These do conform to the hypothesised \ncomputational complexities of between n3 and n5 for time and n2 and n4 for space, but of \ncourse there is insufficient data to confirm this. The number of notes in a piece appears to \nbe a better predictor of time and space complexity than the number of segments, and \nsuggests complexities of n4.5 and n3.2 for time and space respectively. \n \nTheme N\nu\nm\nb\ne\nr \no\nf \ns\ne\ng\nm\ne\nn\nts\n \nN\nu\nm\nb\ne\nr \no\nf \nn\no\nte\ns\n \nC\no\nm\np\nu\nta\nti\no\nn\n t\nim\ne\n \n(s\ne\nc\n) \nC\no\nm\np\nu\nta\nti\no\nn\n \ns\np\na\nc\ne\n (\nM\nB\n) \nT\no\nta\nl \nn\nu\nm\nb\ne\nr \no\nf \np\no\ns\ns\nib\nle\n a\nn\na\nly\ns\ne\ns\n \nN\nu\nm\nb\ne\nr \no\nf \np\no\ns\ns\nib\nle\n a\nn\na\nly\ns\ne\ns\n \nw\nit\nh\n U\nrs\na\ntz\n \nC\no\nn\nfo\nrm\na\nn\nc\ne\n t\no\n \n\u2017g\nro\nu\nn\nd\n t\nru\nth\n\u2018 \no\nf \nb\ne\ns\nt-\ns\nc\no\nri\nn\ng\n \na\nn\na\nly\ns\nis\n \nK.545 22 58 138 141 6.3e12 9.2e12 \u2013 \nK.333 19 40 125 88 7.5e11 1.0e11 79% \nK.570 31 65 543 277 4.5e22 5.8e20 83% \nK.494 34 82 2512 880 1.0e25 1.0e24 90% \nK.331 17 55 248 230 1.8e15 8.3e14 91% \nK.284 26 67 1524 510 1.3e21 1.2e20 98% \nTable 2. Computation results. \nThe striking thing about the figures in Table 2 is how many possible analyses there appear \nto be for even short and simple themes. (For comparison, the number of stars in the visible \nuniverse is generally estimated to be of the order of 1022.) As Temperley suggests (2007, \np.176), the rules of Schenkerian analysis seem to be much too loose to specify an analysis \nwith any degree of usefulness. Clearly other factors are at work in Schenkerian analysis, \nwhich are probed in the following sections. \n5.5 Candidate goodness measures \nSchenkerian analysts have long recognised that alternative analyses of the same piece are \npossible, and the literature does include some discussion of the factors used to decide \nwhich is best among alternative analyses. However, there is no accepted set of principles \nwhich distinguish a good analysis from a bad one. Candidate goodness measures could be \nfound in the \u2017indices\u2018 proposed by Plum (1988) and in a famous article by Schachter (1990). \nOther good sources for candidate goodness measures are the preference rules of Lerdahl & \nJackendoff (1983), Larson\u2018s \u2017musical forces\u2018 (Larson & Vanhandel, 2005), and Schenkerian \ninstructional literature (e.g., Forte & Gilbert, 1982a; Cadwallader & Gagn\u00e9 2007; Pankhurst, \n2009). However, for this initial proof of concept, measures have been designed on a more \nintuitive basis of what is simple to compute and is presumed to be potentially fruitful. In \nprinciple, the same procedures could be applied to test measures derived from these \nsources. \nThe fourteen measure used were as follows. \n1. duration ratio: the duration of the shorter child divided by the duration of the longer. \n2. short-long: 1 if the duration of the first child is less than the duration of the second; \n0 otherwise. \n3. syncopations:  if a beat stronger than the beat at the start of the segment occurs \nbefore the end of the segment, the difference in level of strength between the \nstrongest such beat and the beat at the start of the segment; otherwise 0. \n4. harmonic simplicity: 1 if the harmony is (consonant with) I or V7; otherwise 0. \n5. root-position: 1 if the lowest pitch of the segment can be the root of the harmony; \notherwise 0. \n6. second-inversion: 1 if the lowest pitch of the segment can only be the fifth of the \nharmony; otherwise 0. \n7. harmonic support: proportion of the surface in the span of a segment which is \nconsonant with the harmony of that segment (measured in time). \n8. pitch support: proportion of the surface in the span of a segment which contains the \npitches of that segment, averaged for each pitch of the segment. \n9. interval in semitones between the paired notes of the child segments (i.e., the pairs \nof notes which participate in atomic elaborations), averaged per pair. \n10. voice split\/join: the number of notes in child segments which are paired with more \nthan one note in the other segment. \n11. delay: the number of atomic elaborations which start with a rest. \n12. shortening: the number of atomic elaborations which finish with a rest. \n13. post-context from ancestor: the number of levels of reduction between the lowest \ncommon ancestor and the required context (if any). \n14. post-context from surface: the number of levels of reduction between the surface \nand the required context (if any). \nA value for each of these measures was computed for each segment. Since measurements \nwere only taken for complete analyses, derived by selecting children from the reduction \nmatrix, each segment which was not a surface segment had just one pair of children. \nHowever, there might have been more than one possible harmony for a segment arising \nfrom more than one possible set of atomic reductions. In such cases, the measure computed \nwas the presumed best among the possible harmonies and sets of atomic reductions. This \nwas the highest for measures 4, 5, 7, and 8, and the lowest for measures 6, 9, 10, 11, 12, \n13, and 14. For surface segments, those measures which depend on children (1, 2, 9, 11, \n10, 11, 12) took a value of 0. For other segments, the recorded value for each measure was \nthe sum of the recorded values for its children plus the value computed for the segment \nitself. The measure for an entire analysis was then the recorded measure for the top-level \nsegment divided by the number of segments in the analysis. \nThe syncopation measure was computed as follows. As mentioned above, a metre for each \nextract is specified in advance which assigns to each point in time a strength of beat, \nrepresented as an integer, with lower numbers representing strong beats. The strength of \nthe beat at the beginning of each bar (measure) is 1 and all beats within the bar are weaker. \nFor each metre, there is a specified pattern of beats, such as 1 3 2 3 for 4\/4. The strengths \nfor time points between these specified beats is computed according to the following \nprocedure. \nLet b1 and b2 be the beats preceding and following the time point t respectively. \nLet s be the strength of the weaker of beats b1 and b2. \nLet x be the interval between b1 and b2 and y be the interval between b1 and t, both \nexpressed as positive integers. \nUntil y is a multiple of x, \ndivide x by the smallest prime number less than x and set x to the result, \nadd 1 to s. \nThe strength of the beat at t is s. \n5.6 Sampling results \nTable 3 gives the mean value for each of these measures for the sets of results from each of \nthe themes. For each theme, the row \u2017All\u2018 gives the values for the sample of all possible \nreductions (step 2 of the procedure outlined above), the row \u2017With Ursatz\u2018 from the sample \nof reductions with an Ursatz (step 3), the row \u2017Conforming\u2018 from the samples of reductions \nconforming to a \u2017ground truth\u2018 (step 4), and the row \u2017Preferred\u2018 from the single most \npreferred reduction in each case (step 5). The row \u2017Std. dev.\u2018 gives the standard deviations \nof the sample of measure from all possible reductions (step 2). (The standard deviations \nfrom the Ursatz samples (step 3) were not significantly different.) \n  \n d\nu\nra\nti\no\nn\n r\na\nti\no\n \ns\nh\no\nrt\n-\nlo\nn\ng\n \ns\ny\nn\nc\no\np\na\nti\no\nn\n \nh\na\nrm\no\nn\nic\n s\nim\np\nli\nc\nit\ny\n \nro\no\nt-\np\no\ns\nit\nio\nn\n \ns\ne\nc\no\nn\nd\n-\nin\nv\ne\nrs\nio\nn\n \nh\na\nrm\no\nn\nic\n s\nu\np\np\no\nrt\n \np\nit\nc\nh\n s\nu\np\np\no\nrt\n \nv\no\nic\ne\n s\np\nli\nt\/\njo\nin\n \nin\nte\nrv\na\nl \nd\ne\nla\ny\n \ns\nh\no\nrt\ne\nn\nin\ng\n \np\no\ns\nt-\nc\no\nn\nte\nx\nt \nfr\no\nm\n p\na\nre\nn\nt \np\no\ns\nt-\nc\no\nn\nte\nx\nt \nfr\no\nm\n s\nu\nrf\na\nc\ne\n \nK.333 \n              Std. dev. 0.39 0.07 0.04 0.10 0.16 0.08 0.04 0.03 0.07 0.42 0.14 0.15 0.31 0.28 \nAll  2.17 0.17 0.07 0.76 0.63 0.07 0.69 0.47 0.15 2.05 0.42 0.36 0.31 0.46 \nWith Ursatz 2.23 0.17 0.06 0.82 0.75 0.01 0.70 0.46 0.16 1.99 0.42 0.38 0.30 0.54 \nConforming 1.70 0.13 0.03 0.88 0.81 0.00 0.74 0.51 0.14 1.76 0.36 0.38 0.19 0.60 \nPreferred 1.56 0.11 0.03 0.89 0.91 0.00 0.74 0.54 0.06 1.16 0.28 0.28 0.33 0.50 \nK.570 \n              Std. dev. 0.24 0.08 0.04 0.03 0.12 0.07 0.03 0.02 0.07 0.44 0.10 0.10 0.26 0.21 \nAll  2.12 0.28 0.14 0.85 0.68 0.08 0.67 0.50 0.21 2.58 0.36 0.43 0.36 0.25 \nWith Ursatz 2.21 0.26 0.14 0.85 0.74 0.04 0.67 0.48 0.17 2.40 0.33 0.40 0.30 0.27 \nConforming 1.95 0.27 0.11 0.87 0.66 0.06 0.70 0.48 0.14 2.05 0.32 0.41 0.16 0.24 \nPreferred 1.40 0.03 0.00 0.90 0.53 0.13 0.71 0.52 0.00 1.17 0.27 0.37 0.14 0.29 \nK.494 \n              Std. dev. 0.24 0.07 0.04 0.07 0.13 0.06 0.03 0.02 0.06 0.32 0.10 0.09 0.24 0.21 \nAll  2.04 0.25 0.11 0.87 0.57 0.05 0.72 0.51 0.19 1.82 0.46 0.39 0.29 0.36 \nWith Ursatz 1.99 0.24 0.10 0.89 0.65 0.02 0.73 0.52 0.19 1.77 0.47 0.40 0.22 0.47 \nConforming 1.92 0.25 0.08 0.95 0.63 0.00 0.78 0.53 0.15 1.45 0.45 0.41 0.08 0.57 \nPreferred 1.30 0.03 0.00 0.94 0.55 0.00 0.74 0.58 0.00 1.13 0.21 0.18 0.13 0.63 \nK.331 \n              Std. dev. 0.32 0.09 0.04 0.06 0.20 0.10 0.05 0.04 0.12 0.50 0.13 0.10 0.18 0.17 \nAll  2.83 0.29 0.10 0.92 0.54 0.08 0.66 0.53 0.45 2.86 0.42 0.22 0.21 0.09 \nWith Ursatz 2.83 0.28 0.10 0.92 0.66 0.02 0.67 0.53 0.44 2.85 0.42 0.24 0.19 0.08 \nConforming 2.11 0.16 0.06 0.95 0.70 0.02 0.70 0.62 0.29 1.98 0.28 0.20 0.42 0.18 \nPreferred 2.44 0.00 0.00 1.00 0.71 0.00 0.70 0.65 0.06 0.99 0.13 0.19 0.17 0.67 \nK.284 \n              Std. dev. 0.28 0.07 0.04 0.05 0.14 0.07 0.03 0.02 0.07 0.44 0.11 0.11 0.25 0.28 \nAll  2.10 0.24 0.12 0.79 0.71 0.06 0.68 0.46 0.20 2.56 0.45 0.39 0.25 0.36 \nWith Ursatz 2.19 0.25 0.12 0.78 0.74 0.04 0.68 0.46 0.20 2.39 0.43 0.36 0.25 0.38 \nConforming 1.90 0.19 0.09 0.80 0.84 0.02 0.73 0.49 0.18 2.16 0.41 0.37 0.33 0.34 \nPreferred 1.08 0.04 0.02 0.80 0.93 0.00 0.72 0.51 0.00 1.48 0.44 0.32 0.75 0.50 \nWeight -2.16 -1.93 -2.05 0.75   0.37 2.72 -2.39 -2.35  -0.54   \n \nTable 3. Sampling results. \n \nThe objective of the sampling and measuring exercise was to discover factors which \ndistinguish the \u2017good\u2018 analyses (those which conform to a ground truth, and the preferred \nanalysis) from other possible analyses with an Ursatz. Thus in table 3, every case of a \n\u2017Conforming\u2018 or \u2017Preferred\u2018 measure which differs from the \u2017With Ursatz\u2018 measure by more \nthan one standard deviation is underlined. Columns corresponding to measures for which \nthe difference is always positive or always negative (if it is not negligible) are shaded. These \nare measure which distinguish \u2017good\u2018 analyses from others in a consistent manner (if at all). \nIn four cases (duration ratio, pitch support, voice split\/join, and interval) every one of the \npreferred reductions is distinguished by a difference greater than one standard deviation, \nand in the case of duration ratio and pitch support the difference for the sample of \n\u2017conforming\u2018 reductions is also greater than one standard deviation for the majority of \nthemes. In the case of three other measures, (short-long, syncopation and delay) a majority \nof the preferred analyses differ by more than one standard deviation from the Ursatz \nsample, but in the case of the delay measure, one also differs (but by only a small amount) \nin the opposite direction. This measure is therefore not considered a good candidate. Three \nother measures (harmonic simplicity, harmonic support, and shortening) show consistent \ndifferences, but most are small. The bottom row of the table gives the harmonic mean of the \ndifferences between the measures for the preferred reduction and the Ursatz sample in \nthese nine cases, expressed in standard deviations. (The harmonic mean is used because it \nresults in lower values for distributions with greater variance but the same mean. Thus high \nvalues result from consistently large differences.) From this we can propose nine principles \nfor making good analyses, in order of decreasing strength. \n1. Select higher level pitches which are more often present in the surface. \n2. Avoid splitting and joining of voices. \n3. Select reductions with small intervals between notes reduced together. \n4. Reduce segments of approximately equal duration together. \n5. Avoid reductions which create syncopations at higher levels. \n6. Avoid reducing a shorter segment with a following longer segment. \n7. Prefer reductions with more tonic and dominant harmony. \n8. Avoid reductions where a note is followed by a rest. \n9. Prefer reductions where higher level harmonies are more often consonant with the \nsurface. \nFrom the product of the harmonic means and the standard deviations, a weight can be \ncomputed to be used in combining each measure into a composite \u2017goodness metric\u2018. For \nsimplicity, simple linear combination was used (i.e., each measure is multiplied by the \nappropriate weight and the results added together). Further research should determine \nwhether or not there is a more appropriate method of combination. \n5.7 Selection of best-scoring analysis \nThe scoring metric could now be used in a procedure which selected the best-scoring \nanalysis from a reduction chart in order to complete the process of automatically deriving an \nanalysis from the notes of the surface (step 8 of the process outlined in section 5.3 above). \nFirst, reduction charts were recomputed for each example using the goodness metric \nproposed above. Most segments above the surface of the chart were parents of a number of \npossible elaborations, sometimes with the same pair of children and sometimes with \ndifferent pairs. The score recorded for a segment was the best among the various \npossibilities. The best-scoring analysis could then be selected by selecting the highest-\nscoring top-level segment which had a complete Ursatz among its recorded Ursatz \npossibilities. Children were selected in a recursive procedure which, at each level, selected \nthe highest-scoring pair of children which yielded this Ursatz. (It was here that it was vital to \nhave recorded the Ursatz possibilities of each segment.) However, in many cases the \nrecorded best score for a segment arose from an elaboration or pair of children which was \nno longer valid, either because a required context had been removed as a result of selection \nof segments in another part of the matrix, or because they did not conform to the required \nUrsatz. Thus often no complete analysis existed for the selected top-level segment which \nyielded the score recorded for that segment, and similarly for segments at lower levels of \nanalysis.  \nTo ensure that the highest-scoring valid analysis with an Ursatz was found, a best-first \nsearch procedure was used which can be described as follows. The procedure depends on a \ndata structure which can be called a \u2017partial analysis\u2018 which has a score and keeps a record \nof the segments selected so far and of information for updating the score of that partial \nanalysis. An agenda of partial analyses is maintained which lists the partial analyses derived \nto date in order of decreasing score. Initially the agenda consists essentially of the partial \nanalyses based on each possible top-level segment. At each step the best-scoring partial \nanalysis is removed from the agenda and extended by selecting children for some non-\nsurface segment. This generally results in several new partial analyses which are inserted \ninto the agenda according to their score. The score is essentially an upper bound on the \nscore of any analysis selected from this partial analysis. When children are selected, this \nupper bound can often be reduced, so the score for the resulting partial analysis is reduced \naccordingly. (In fact, the procedure is more complex than this. Selection of children takes \nplace in several steps, first selecting the pair of cells in which to find children, and so on, \nupdating the score at each step. Furthermore, no more than two partial analyses result from \neach extension: the first selects the best-scoring children, the second records which choices \nremain. This results in a more efficient procedure, but the effect is the same.) The first \nanalysis found to be the best-scoring partial analysis in the agenda which cannot be further \nextended is an analysis with the highest possible score. Other analyses with equal scores \nmight exist, but none can have a higher score. (The same procedure can be continued to \nfind these other high-scoring analyses.) This procedure is unfortunately of factorial \ncomplexity in the worst case, but the search strategy reduces the likelihood of the worst \ncase arising. \nIn no case did a top-scoring analysis derived by this procedure exactly match a preferred \nanalysis. On the other hand, the results did generally conform quite well to the ground \ntruths derived from pre-existing analyses done by hand. In attempting to quantify the \naccuracy of his foreground-deriving software, Kirlin used a typical precision\/recall measure, \nbut acknowledged that this was problematic because the information given in the published \nanalyses used as ground truth and in his computed foregrounds was not equivalent (2009, \npp.426\u2013427). In particular, because he was concerned only with top and bass voices, the \npublished analyses generally contained more notes than his foregrounds. I had the opposite \nproblem: the computed analyses accounted for all voices and every intermediate reduction, \nwhereas the \u2017ground truths\u2018 typically concerned only the top and bass voices and left many \nintermediate reduction steps implied. Thus it was to be expected that the ground truths \nwould contain fewer notes than the computed analyses. An appropriate test would check the \ninclusion of notes from the ground truths in the results but not vice versa. Thus the \nmeasure used here was simply to count the proportion of notes in the ground truth \nreductions which occurred at the same time and with the same duration in the automatically \ncomputed analyses. As pointed out above, there was generally more than one ground truth \nfor each theme; the figure used was the best match, on the basis that each ground truth was \nequally valid and the system should be considered to be successful if its output matched \nany of the ground truths.  \nThis was nevertheless quite a severe test, since where there were deviations the \nautomatically derived analysis often showed some similarity with the ground truth (for \nexample by having the same pitches but in a different rhythm) but this similarity was not \ntaken into account in the test. The match with the ground truth was therefore generally \nbetter than suggested by the figures given in Table 2, but these figures are nevertheless \nencouraging. As an example, Figure 7 shows the best-scoring analysis for the K.333 theme, \nwhich was the worst match with the ground truth among the best-scoring analyses for the \nthemes tested. (The best-matching ground truth for this theme is shown in Figure 5. A \nbetter analysis of this theme, derived using pruning, is shown in Figure 8.) \n Figure 7. Automatically derived best-scoring analysis of the K.333 theme. \n5.8 Pruning \nAs indicated above, the reduction procedure is extremely expensive in terms of computing \ntime and space. Because the complexity arises from combination, reducing the number of \nsegments to be combined at an early stage has a disproportionate impact on the overall \ncomputing cost. It would thus be beneficial to discard low-scoring segments in the course \nof the reduction procedure if this can be done with confidence that a good analysis is not \nthereby jeopardised. To test this, the reduction procedure was rerun on the five examples \nwhich produced analyses conforming to the ground truth, with one simple modification. \nThis was to limit the number of segments retained in a cell after each reduction step, and \ndiscard lower-scoring segments beyond that limit. The limit ranged from 1 to 100, and the \nresulting best-scoring analyses were tested for conformity with the ground truths in the \nsame manner as described in section 5.7 above. The resulting best scores and \ncorresponding match with the ground truth reductions are shown in Table 4. Figures of 0% \nfor the score and match indicate that the system failed to derive an analysis at all with the \ngiven pruning limit. (These tables record only the results where there is a change in score or \nmatch as the pruning limit increased. Thus for the K.333 theme, no analyses were derived \nuntil the pruning limit reached 10. Then the best score and match remained unchanged \nuntil the pruning limit reached 78.) \nIn no case was an analysis derived by keeping only the best-scoring segment at each \nreduction step (i.e., with a pruning limit of 1). In every case, the best-scoring analysis \nderived without any pruning (as in section 5.7 above) was derived with a pruning limit of 79 \nor less. In four of the five cases, the best score was already reached at a pruning limit of 35. \nIt was only for K.333 that the much larger pruning limit was necessary to achieve the \nmaximum score, and in this case the match with the ground truth is seen to be markedly \nworse than with a much lower pruning limit of 10, even though the score is higher. A higher \nscore (as measured by the metric derived in section 5.6 above) does not therefore \nnecessarily mean a better analysis. For comparison with Figure 7, Figure 8 shows the best-\nscoring analysis derived with a pruning limit of 10. \n \nFigure 8. Automatically derived best-scoring analysis of the K.333 theme with a pruning \nlimit of 10. \nIn two other cases we also see a reduction in the match with the ground truth with the last \nincreases in the pruning limit. In fact, in the case of K.284, there is a perfect match between \none of the ground truths for this theme and the best-scoring derived analysis with a \npruning limit in the range 20 to 32. Although this decrease in the \u2017quality\u2018 of the analyses \nwith less pruning is unexpected, it is actually an encouraging result. It suggests that the \nfactors which determine a good analysis are, to some degree at least, local, since the \npruning decision is taken only on the basis of local information. It should be possible, \ntherefore, to find a better pruning mechanism which makes better use of this local \ninformation. This also suggests that a reduction procedure based on search (see below) has \nsome chance of success. For the present, it appears that a simple pruning limit of about 30 \nis likely to produce a good analysis, but cannot guarantee the best analysis. \n \n K.333 \nLimit Score Match \n1 0 0% \n10 856 93% \n78 879 79% \n79 886 79% \n \nK.570 \nLimit Score Match \n1 0 0% \n11 1233 66% \n13 1263 63% \n16 1659 83% \n27 1661 83% \n \nK.494 \nLimit Score Match \n1 0 0% \n5 1753 59% \n6 1781 64% \n7 0 0% \n8 1599 51% \n9 1629 54% \n10 0 0% \n12 1649 44% \n13 1639 44% \n15 1648 44% \n16 1658 44% \n20 1677 59% \n21 1693 59% \n23 1902 67% \n25 1961 90% \n28 1962 90% \n35 1973 90% \n \nK.331 \nLimit Score Match \n1 0 0% \n2 828 84% \n3 873 88% \n4 932 98% \n7 944 98% \n9 948 91% \n \nK.284 \nLimit Score Match \n1 0 0% \n6 1012 91% \n8 1024 91% \n9 1025 95% \n12 1032 93% \n17 1035 93% \n20 1169 100% \n22 1212 100% \n29 1211 100% \n33 1213 98% \n35 1214 98% \nTable 4. Score and match with a ground-truth outline reduction in relation to pruning limit. \n6. Discussion and Future Work \n6.1 Outcome \nThe essential outcome of the research described here is a computational procedure capable \nof deriving Schenkerian-like reductions from the pitch and time information in a score. The \nreductions do match, to some considerable degree, the analyses that expert analysts make. \nThere are two very significant caveats, however. Firstly, the procedure is extremely \nexpensive in terms of computation time and space, and only short phrases can be processed \nwith realistic resources. The pruning results suggest that savings can be made with further \nresearch, but even with a low pruning limit it has not been possible to derive complete \nanalyses from the two other themes which I had planned to use in this project. The \nreduction chart can be derived in reasonable time, but the procedure to select from it the \nbest-scoring analysis runs out of heap space. As stated above, while the chart-reduction \nprocess is of polynomial order, this step is of factorial order in the worst case. A practical \nanalysis system requires a different order of procedure. \nSecondly, the quality of analyses produced has not been adequately tested, so the claim that \nthe procedure produces Schenkerian-like reductions must be regarded as provisional. The \nsame sources were used both in the derivation of goodness measures and in testing of \nthose measures, which will tend to over-fitting. Tests on different material are required, but \nwill have to await collection of suitable ground truths. As indicated above, analyses of \nsufficiently short complete themes are not readily available. \n6.2 Greater computational efficiency \nPart of the difficulty in testing is the sheer quantity of computation time taken at present. A \nmore efficient procedure is urgently required. As stated above, the main difficulty in the \ncurrent procedure is the mechanism to select the best-scoring analysis from the reduction \nchart. I suspect that one problem here is that scores are not associated with Ursatz \npossibilities (i.e., the best score for a segment is recorded, regardless of whether or not the \nscore can arise with a set of children which conform to a particular segment of an Ursatz). \nThus a great deal of computation time is probably wasted pursuing high-scoring \npossibilities which will never fit with other parts of the analysis. On the other hand, \nassociating scores with Ursatz possibilities will considerably increase the quantity of data to \nbe recorded and so lead to greater inefficiency in another part of the process. This kind of \ntrade-off should be a topic of further research. \nThe scoring and pruning mechanisms used here have been extremely simple. It is entirely \npossible that the weights for the different measures should not apply equally in all parts of \nan analysis (some might weigh more heavily than others at higher levels, for example), and \nalso possible that something other than linear combination gives a better result. The \npruning mechanism currently applies only to segments within a single cell, and does not \ntake account of how alternative segments in different cells compete with each other. \nConsiderable efficiency savings are therefore likely in these areas, particularly in view of the \nhints that local information is more important than global. \nFundamentally, though, I suspect that an entirely different procedure is required, one which \nhas a lower order of complexity as a result of its essential process rather than as a result of \nincidental savings. Kirlin & Utgoff (2008) have advocated intelligent search as a solution to \nthis problem, and Geraint Wiggins and I have already had some small-scale success in \nimplementing a search procedure (Marsden & Wiggins, 2008). Such a procedure will almost \ncertainly not be guaranteed to produce the \u2017best\u2018 result, but to do so is probably unrealistic \nfor this particular problem. Even human experts produce a range of possible results, and \nthen spend ages and pages of print in discussing their relative merits, so a \u2017best\u2018 result is \nprobably a fantasy. \n6.3 Further empirical work \nGiven more suitable materials, further empirical work to test or refine the results given here \nwould be quite easy. As indicated above, the same procedures could also be used to make \nempirical tests of the work of some music theorists (Plum, Lerdahl & Jackendoff, Larson, \netc.), though to translate their work into empirically testable measures might not be simple. \nThe really significant empirical work, however, would not depend on published analyses or \nmusic theory but on musical behaviour. Schenkerian theory has been subject to powerful \ncriticism (e.g., Narmour (1977)) and many doubt that it says anything of use or value about \nmusic. Some have attempted to test whether reduction does play some part in listening to or \nremembering music (e.g., Oura & Hatano, 1991) but there is little work of this kind. Perhaps \nthis is because there has been little to test with, for the same reason that material for this \nstudy has been hard to come by: complete analyses of short complete segments are rare. \nPossibly a mechanism which produces reductions, such as described here, will facilitate such \nwork, allowing the reduction mechanism itself to be refined. \nThe real test of an automatic reduction procedure, I suspect, will be whether or not it proves \nto be useful when embedded in other music-processing systems. Will it, for example, allow \nbetter searches for music similar to an example? If automatic reduction allows better \nprocessing in systems which aim to handle musical data in a musically intelligent manner, \nthen it will have proven its value. \n \nReferences \nBarbar, K., Desainte-Catherine, M., & Miniussi, A. (1993). The semantics of musical \nhierarchies. Computer Music Journal, 17, 30\u201337. \nBaroni, M. (1983). The concept of musical grammar (translated by S. Maguire with the \nassistance of W. Drabkin). Music Analysis, 2, 175\u2013208. \nBaroni, M., Dalmonte, R., & Jacobini, C. (1992). Theory and analysis of European melody. In \nA.Marsden & A. Pople (eds.) Computer Representations and Models in Music, London: \nAcademic Press, 187\u2013206. \nBernstein, L. (1976). The Unanswered Question: Six Talks at Harvard. Cambridge, MA: \nHarvard University Press. \nBrown, M. (2005). Explaining Tonality: Schenkerian Theory and Beyond. Rochester NY: \nUniversity of Rochester Press. \nCadwallader, A., & Gagn\u00e9, D. (2007). Analysis of Tonal Music (2nd edition). Oxford: Oxford \nUniversity Press. \nDesainte-Catherine, M., & Barbar, K. (1994). Using attribute grammars to find solutions to \nmusical equational programs. ACM SIGPLAN Notices, 29, 56\u201363. \nEbcio\u011flu, K. (1987). Report on the Choral Project: An Expert System for Harmonizing Four-\npart Chorales. Technical report RC 12628, IBM, Thomas J. Watson Research Centre, \nYorktown Heights, New York. \nEbcio\u011flu, K. (1988). An expert system for harmonizing four-part chorales.Computer Music \nJournal, 12, 43\u201351. \nEbcio\u011flu, K. (1990). An expert system for harmonizing chorales in the style of J.S. Bach. \nJournal of Logic Programming, 8, 145-185. \nForte, A. & Gilbert, S.E. (1982a). Introduction to Schenkerian Analysis. New York: Norton. \nForte, A. & Gilbert, S.E. (1982b). Instructor\u2018s Manual for \u2017Introduction to Schenkerian \nAnalysis\u2018. New York: Norton. \nFrankel, R.E., Rosenschein, S.J. & Smoliar, S.W. (1976). Schenker\u2018s theory of tonal music\u2014its \nexplication through computational processes. International Journal of Man-Machine Studies, \n10, 121\u2013138. \nFrankel, R.E., Rosenschein, S.J. & Smoliar, S.W. (1978). A LISP-based system for the study of \nSchenkerian analysis. Computers and the Humanities, 10, 21\u201332. \nGilbert, E., & Conklin, D. (2007). A probabilistic context-free grammar for melodic \nreduction. Proceedings of the International Workshop on Artificial Intelligence and Music, \n20th International Joint Conference on Artificial Intelligence (IJCAI). Hyderabad, India, 83\u201394. \nGood, M. (2001). MusicXML for notation and analysis. In W.B. Hewlett & E. Selfridge-Field \n(eds.) The Virtual Score: Representation, Retrieval, Restoration (Computing in Musicology, \n12), Cambridge MA: MIT Press, 113\u2013124. \nHamanaka, M., Hirata, K., & Tojo, S. (2006). Implementing \u2015A Generative Theory of Tonal \nMusic\u2016. Journal of New Music Research, 35, 249\u2013277. \nHamanaka, M., Hirata, K., & Tojo, S. (2007). FATTA: Full automatic time-span tree analyzer. \nProceedings of the International Computer Music Conference (ICMC), Copenhagen, August \n2007, 153\u2013156. \nHuron, D. (1997). Humdrum and Kern: selective feature encoding. In E. Selfridge-Field (ed.) \nBeyond MIDI: The Handbook of Musical Codes, Cambridge MA: MIT Press, 1997, 375\u2013401.  \nJurafsky, D., & Martin, J.H. (2009). Speech and Natural Language Processing, 2nd edition. \nUpper Saddle River, NJ: Pearson.  \nKassler, M. (1967). A Trinity of Essays. PhD dissertation, Princeton University. \nKassler, M. (1975). Proving Musical Theorems I: The Middleground of Hienrich Schenker\u2018s \nTheory of Tonality (Tech. Rep. No. 103). Sydney, Australia: University of Sydney, School of \nPhysics, Basser Department of Computer Science. \nKassler, M. (1976). The decidability of languages that assert music. Perspectives of New \nMusic, 14\/2\u201315\/1, 249\u2013251. \nKassler, M. (1977). Explication of the middleground of Schenker\u2018s theory of tonality. \nMiscellanea Musicologica: Adelaide Studies in Musicology, 9, 72\u201381. \nKassler, M. (1988). APL applied in music theory. APL Quote Quad, 18, 209\u2013214. \nKirlin, P.B & Utgoff, P.E. (2008). A framework for automated Schenkerian analysis. \nProceedings of the International Conference on Music Information Retrieval (ISMIR), \nPhiladelphia, USA, 363\u2013368. \nKirlin, P.B. (2009). Using harmonic and melodic analyses to automate the initial stages of \nSchenkerian analysis. Proceedings of the International Conference on Music Information \nRetrieval (ISMIR), Kobe, Japan, 423\u2013428. \nKomar, A.J. (1971). Theory of Suspensions. Princeton, NJ: Princeton University Press. \nLarson, S. & Vanhandel, L. (2005). Measuring musical forces. Music Perception, 23, 119\u2013136. \nLerdahl, F., & Jackendoff, R. (1983). A Generative Theory of Tonal Music. Cambridge, MA: \nMIT Press. \nLerdahl, F. (2001). Tonal Pitch Space. Oxford: Oxford University Press. \nMarsden, A. (2001). Representing Melodic Patterns as Networks of Elaborations. Computers \nand the Humanities, 35, 37\u201354. \nMarsden, A. (2005). Generative Structural Representation of Tonal Music. Journal of New \nMusic Research, 34, 409\u2013428. \nMarsden, A. & Wiggins, G.A. (2008). Schenkerian reduction as search. Proceedings of the \nfourth Conference on Interdisciplinary Musicology (CIM08), Thessaloniki, Greece, \nhttp:\/\/cim08.web.auth.gr\/cim08_papers\/Marsden-Wiggins\/Marsden-Wiggins.pdf (last \naccessed 8\/12\/09). \nMavromatis, P., & Brown, M. (2004). Parsing Context-Free Grammars for Music: A \nComputational Model of Schenkerian Analysis. Proceedings of the 8th International \nConference on Music Perception and Cognition, Evanston, USA, 414\u2013415. \nNarmour, E. (1977). Beyond Schenkerism: the need for alternatives in music analysis. \nChicago IL: University of Chicago Press. \nOura, Y., & Hatano, G. (1991). Identifying melodies from reduced pitch patterns. \nPsychologica Belgica, 31, 217\u2013237. \nPachet, F. (2000). Computer analysis of jazz chord sequences: is Solar a blues?. In E. \nMiranda (ed.) Readings in Artificial Intelligence and Music, Amsterdam: Harwood Academic \nPublishers, 85\u2013113. \nPankhurst, T. (2008). SchenkerGUIDE. London: Routledge. \nPlum, K-O. (1988). Towards a Methodology for Schenkerian Analysis (translated by William \nDrabkin). Music Analysis, 7, 143\u2013164. \nSchachter, C. (1990). Either\/Or. In H. Siegel (ed.), Schenker Studies, Cambridge: Cambridge \nUniversity Press, 165\u201379. Reprinted in C. Schachter, Unfoldings, Oxford: Oxford University \nPress, 1999,  121\u201333. \nSchenker, H. (1935). Der frei Satz. Vienna: Universal Edition. Published in English as Free \nComposition, translated and edited by E. Oster, New York: Longman, 1979. \nSmoliar, S.W. (1980). A computer aid for Schenkerian analysis. Computer Music Journal, 4, \n41\u201359. \nSteedman, M.J. (1984). A generative grammar for jazz chord sequences. Music Perception, 2, \n52\u201377. \nSteedman, M.J. (1996). The blues and the abstract truth: music and mental models. In A. \nGarnham & J. Oakhill (eds.), Mental Models in Cognitive Science, Hove: Psychology Press, \n305\u2013318. \nTemperley, D. (2007). Music and Probability. Cambridge, MA: MIT Press. \nTerrat, R.G. (2005). A pregroup grammar for chord sequences. Journal of New Music \nResearch, 34, 355\u2013360. \n \n"}
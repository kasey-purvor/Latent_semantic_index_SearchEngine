{"doi":"10.1109\/ESDIS.2009.4938994","coreId":"69364","oai":"oai:eprints.lancs.ac.uk:27115","identifiers":["oai:eprints.lancs.ac.uk:27115","10.1109\/ESDIS.2009.4938994"],"title":"Modelling evolving user behaviours","authors":["Iglesias, Jose","Angelov, Plamen","Ledezma, Agapito","Sanchis, Araceli"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2009-04","abstract":"Knowledge about computer users is very beneficial for assisting them, predicting their future actions or detecting masqueraders. In this paper, a new approach for creating and recognizing automatically the behaviour profile of a computer user is presented. In this case, a computer user behaviour is represented as the sequence of the commands (s)he types during her\/his work. This sequence is transformed into a distribution of relevant subsequences of commands in order to find out a profile that defines its behaviour. Also, because of a user profile is not necessarily fixed but rather it evolves\/changes, we propose an evolving method to keep up to date the created profiles using an Evolving Systems approach. In this paper we combine the evolving classifier with a trie-based user profiling to obtain a powerful self-learning on-line scheme. We also develop further the recursive formula of the potential of a data point to become a cluster centre using cosine distance which is provided in the Appendix. The novel approach proposed in this paper can be applicable to any problem of dynamic\/evolving user behaviour modelling where it can be represented as a sequence of actions and events. It has been evaluated on several real data streams. (c) IEEE Press","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"IEEE","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:27115<\/identifier><datestamp>\n      2018-01-24T05:51:00Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Modelling evolving user behaviours<\/dc:title><dc:creator>\n        Iglesias, Jose<\/dc:creator><dc:creator>\n        Angelov, Plamen<\/dc:creator><dc:creator>\n        Ledezma, Agapito<\/dc:creator><dc:creator>\n        Sanchis, Araceli<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        Knowledge about computer users is very beneficial for assisting them, predicting their future actions or detecting masqueraders. In this paper, a new approach for creating and recognizing automatically the behaviour profile of a computer user is presented. In this case, a computer user behaviour is represented as the sequence of the commands (s)he types during her\/his work. This sequence is transformed into a distribution of relevant subsequences of commands in order to find out a profile that defines its behaviour. Also, because of a user profile is not necessarily fixed but rather it evolves\/changes, we propose an evolving method to keep up to date the created profiles using an Evolving Systems approach. In this paper we combine the evolving classifier with a trie-based user profiling to obtain a powerful self-learning on-line scheme. We also develop further the recursive formula of the potential of a data point to become a cluster centre using cosine distance which is provided in the Appendix. The novel approach proposed in this paper can be applicable to any problem of dynamic\/evolving user behaviour modelling where it can be represented as a sequence of actions and events. It has been evaluated on several real data streams. (c) IEEE Press.<\/dc:description><dc:publisher>\n        IEEE<\/dc:publisher><dc:date>\n        2009-04<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/ESDIS.2009.4938994<\/dc:relation><dc:identifier>\n        Iglesias, Jose and Angelov, Plamen and Ledezma, Agapito and Sanchis, Araceli (2009) Modelling evolving user behaviours. In: IEEE Workshop on Evolving and Self-Developing Intelligent Systems, 2009. ESDIS '09. IEEE, pp. 16-23. ISBN 978-1-4244-2754-3<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/27115\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":null,"relations":["http:\/\/dx.doi.org\/10.1109\/ESDIS.2009.4938994","http:\/\/eprints.lancs.ac.uk\/27115\/"],"year":2009,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"Modelling Evolving User Behaviours\nJose A. Iglesias, Plamen Angelov, Agapito Ledezma and Araceli Sanchis\nAbstract\u2014 Knowledge about computer users is very beneficial\nfor assisting them, predicting their future actions or detecting\nmasqueraders. In this paper, a new approach for creating and\nrecognizing automatically the behaviour profile of a computer\nuser is presented. In this case, a computer user behaviour is\nrepresented as the sequence of the commands (s)he types during\nher\/his work. This sequence is transformed into a distribution\nof relevant subsequences of commands in order to find out a\nprofile that defines its behaviour. Also, because of a user profile\nis not necessarily fixed but rather it evolves\/changes, we propose\nan evolving method to keep up to date the created profiles using\nan Evolving Systems approach. In this paper we combine the\nevolving classifier with a trie-based user profiling to obtain a\npowerful self-learning on-line scheme. We also develop further\nthe recursive formula of the potential of a data point to become\na cluster centre using cosine distance which is provided in the\nAppendix. The novel approach proposed in this paper can be\napplicable to any problem of dynamic\/evolving user behaviour\nmodelling where it can be represented as a sequence of actions\nand events. It has been evaluated on several real data streams.\nI. INTRODUCTION\nRECOGNIZING the behaviour of others in real-time isa significant aspect in many different environments.\nSpecifically, the recognition of computer users can be very\nbeneficial for assisting them, predicting their future actions or\ndetecting masqueraders. This recognition needs the creation\nof a user profile that contains information that characterizes\nthe usage behaviour of a computer user. The construction\nof effective user profiles is a difficult problem for different\naspects: human behaviour is usually erratic, and sometimes\nhumans behave differently because of a change in their goals.\nThis last problem makes necessary that the user profiles we\ncreate evolve.\nIn recent years, significant work has been carried out for\nprofiling users; however, most of the user profiles do not\nchange according to the environment and new goals of the\nuser. In this research, it is proposed an adaptive approach\nfor creating behaviour profiles and recognizing users. We\ncall this approach EvABCD (Evolving Agent Behaviour Clas-\nsification based on Distributions of relevant events). It is\nbased on representing the behaviour of an agent (user) as an\nadaptive distribution of her\/his relevant atomic behaviours in\nan evolving way.\nFor evaluating EvABCD, the UNIX operating system en-\nvironment is used. Some research on this environment [1],\nThis work is partially supported by the Spanish Government under project\nTRA2007-67374-C02-02\nPlamen Angelov is with the Department of Communication Systems,\nInfoLab21, Lancaster University, UK. E-mail:p.angelov@lancaster.ac.uk\nJose A. Iglesias, Agapito Ledezma and Araceli Sanchis are with\nthe CAOS Group, Carlos III University of Madrid, Spain. E-\nmails:{jiglesia,ledezma,masm}@inf.uc3m.es.\n[2] focus on detecting masquerades (individuals who im-\npersonate other users on computer networks and systems)\nfrom sequences of UNIX commands. However, EvABCD\ncreates evolving user profiles from a sequence of commands\nand classifies a new user into one of the previously created\nprofiles. Thus, the goal of EvABCD in the UNIX environment\ncan be divided into two phases: 1) creating and updating\nuser profiles from the commands the users typed in a UNIX\nshell. 2) classifying a new sequence of commands into the\npredefined profiles. Because of we use an evolving classifier,\nit is constantly learning and adapting the existing classifier\nstructure to accommodate the newly observed emerging\nbehaviours. Once a user is classified, relevant actions can\nbe done, however this task is not addressed in this paper.\nThe creation of UNIX user profiles from a sequence of\nUNIX commands should consider the sequentiality of the\ncommands typed by the user and the influence of his\/her\npast experiences. This aspect motivates the idea of automated\nsequence learning for computer user behaviour classification;\nif we do not know the features that influence the behaviour\nof a user, we can consider a sequence of past actions\nto incorporate some of the historical context of the user.\nHowever, it is difficult or in general impossible, to build\na classifier that will have a full description of all possible\nbehaviours of the user because the user behavior evolves with\ntime, they are not static and new patterns may emerge as well\nas an old habit may be forgotten or stopped to be used. The\ndescriptions of a particular behaviour itself may also evolve\n(we assume that each behaviour is described by one or more\nfuzzy rules). Therefore, we use an evolving (fuzzy) system\nthat allows for the user behaviours to be dynamic, to evolve.\nThis paper is organized as follows: Section 2 provides a\nbrief overview of the background and related work relevant\nto this research. Our approach (EvABCD) is explained in\ndetail in section 3. Section 4 describes the construction of\nthe user behaviour profile. The evolving Unix user classifier\nis detailed in Section 5. Section 6 describes the experimental\nsetting and the experimental results obtained. Finally, Section\n7 contains future work and concluding remarks.\nII. BACKGROUND AND RELATED WORK\nDifferent methods have been used to find out relevant\ninformation under the human behaviour in many different\nareas: Macedo et al. [3] propose a system (WebMemex) that\nprovides recommended information based on the captured\nhistory of navigation from a list of known users. Pepyne et\nal. [4] describe a method using queuing theory and logistic\nregression modeling methods for profiling computer users\nbased on simple temporal aspects of their behaviour. Gody\nand Amandi [5] present a technique to generate readable user\n978-1-4244-2754-3\/09\/$25.00 \u00a92009 IEEE 16\nprofiles that accurately capture interests by observing their\nbehaviour on the Web.\nIn the computer intrusion detection problem, Coull et\nal. [6] propose an effective algorithm that uses pair-wise\nsequence alignment to characterize similarity between se-\nquences of commands. Schonlau et al. [1] investigate a\nnumber of statistical approaches for detecting masqueraders.\nAngelov and Zhou propose in [7] to use evolving fuzzy\nclassifiers for computer intrusion detection.\nAlthough there is a lot of work focusing on user profiling\nin a specific environment, it is not clear that they can be\ntransferred to other environments. However, EvABCD can\nbe used in any domain in which a user behaviour can be\nrepresented as a sequence of actions or events. Because\nsequences are very relevant in human skill learning and\nreasoning [8], the problem of user profile classification is\nexamined as a problem of sequence classification. According\nto this aspect, Horman and Kaminka [9] present a learner\nwith unlabelled sequential data that discover meaningful pat-\nterns of sequential behaviour from example streams. Popular\napproaches to such learning include statistical analysis and\nfrequency based methods. Lane and Brodley [10] present an\napproach based on the basis of instance-based learning (IBL)\ntechniques, and several techniques for reducing data storage\nrequirements of the user profile.\nIt should be emphasized that all of the above approaches\nignore the fact that user behaviours can change or their\ndescription can change and evolve. To the best of our\nknowledge this is the first publication where user behaviour is\nconsidered, treated and modelled as a dynamic and evolving\nphenomenon. This is the most important contribution of this\npaper.\nIII. THE PROPOSED APPROACH EVABCD\nThis section introduces the proposed approach for auto-\nmatic clustering, classifier design and classification of the\nbehaviour profiles of users. Although the proposed approach\ncan be applied for any behaviour represented by a sequence\nof events, we detail it using the UNIX Commands envi-\nronment. Therefore, a behaviour profile is created from the\ncommands a UNIX user types during a period of time. In\naddition, a novel evolving user behaviour classifier based on\nEvolving Fuzzy Systems is presented which takes into account\nthe fact that the behaviour of any user is not fixed, but is\nrather changing, evolving.\nIn order to classify an observed behaviour, our approach,\nas many other agent modeling methods [11] creates a library\nwhich contains the different expected behaviours. However,\nin our approach this library is not a pre-fixed one, but is\nevolving, learning from the observations of the users real\nbehaviours and moreover it starts to be filled in \u2019from\nscratch\u2019 by assigning temporarily to the library the first\nobserved user as a prototype. That means that the library is\ncontinuously changing, evolving influenced by the changing\nuser behaviours observed in the environment. This evolving\nlibrary (called evolving-profile-library (EPLib)) is created\nand updated by the Evolving user classifier.\nThus, the proposed approach includes at each step the\nfollowing two main actions:\n1) Learning and Update of the Classifier: This action\ninvolves in itself two sub-actions:\na) Update User Behaviour Profiles. This sub-\naction analyzes the sequences of commands typed\nby different UNIX users (data stream) on-line and\ncreates and updates the corresponding profiles.\nThis process is detailed in Section 4.\nb) Evolving the Classifier. This sub-action includes\non-line learning and update of the classifier, in-\ncluding the potential of each behaviour to be\na prototype, and update of the evolving-profile-\nlibrary (EPLib). This whole process is explained\nin Section 5.\n2) User Classification: The user profiles created in the\nprevious action are associated to one of the prototypes\nfrom the EPLib and they are classified into one of the\nclasses formed by the prototypes. This action is also\ndetailed in Section 5.\nIV. CONSTRUCTION OF THE USER BEHAVIOUR PROFILE\nIn order to construct a user behaviour profile in on-line\nmode from a data stream we have to extract an ordered se-\nquence of recognized atomic behaviours. For this purpose we\nconsider that the atomic behaviours of a user are represented\nby the commands (s)he types in.\nThe commands typed by an agent are inherently sequen-\ntial, and this sequentiality is considered in the modeling\nprocess (when a user types a command, it usually depends\non the previous typed commands and it is related to the\nfollowing commands). According to this aspect, in order\nto get the most representative set of subsequences from a\nsequence, we propose the use of a trie data structure [12].\nThis trie data structure was also used in [13] and in [14]\nwhere a team behaviour was learned as well as in [15]\nto classify the behaviour patterns of a RoboCup soccer\nsimulation team.\nThe construction of a user profile from a single sequence\nof commands is done by a three steps process: 1. Seg-\nmentation of the sequence of commands, 2. Storage of the\nsubsequences in a trie, and 3. Creation of the user profile.\nThese steps are detailed in the following 3 subsections.\nIn order to clarify this process for creating, lets consider\nthe following sequence as an example: {ls \u2192 date \u2192 ls \u2192\ndate \u2192 cat}.\nA. Segmentation of the sequence of commands\nFirst, the sequence is segmented into subsequences of\nequal length from the first to the last element. Thus, the\nsequence A=A1A2...An (where n is the number of commands\nof the sequence) will be segmented in the subsequences de-\nscribed by Ai...Ai+length \u2200 i,i=[1,n-length+1], where length\nis the size of the subsequences created and this value deter-\nmines how many commands are considered as dependent. In\nthe remainder of the paper, we will use the term subsequence\nlength to denote the value of this length.\n17\nIn the proposed sample sequence ({ ls\u2192 date\u2192 ls\u2192 date\n\u2192 cat}), let 3 be the subsequence length, then we obtain:\n{ls \u2192 date \u2192 ls} and {date \u2192 ls \u2192 date} and {ls \u2192 date\n\u2192 cat}.\nB. Storage of the subsequences in a trie\nThe subsequences of commands are stored in a trie in a\nway that all possible subsequences are accessible and ex-\nplicitly represented. In a trie, a node represents a command,\nand its children represent the commands that follow it. Also,\neach node keeps track of the number of times a command has\nbeen inserted on to it. When a new subsequence is inserted\ninto the trie, existing nodes of the trie are modified and\/or\nnew nodes are created. Moreover, as the dependencies of the\ncommands are relevant in the user profile, the subsequence\nsuffixes (subsequences that extend to the end of the given\nsequence) are also inserted.\nConsidering the previous example, the first subsequence\n({ls \u2192 date \u2192 ls}) is added as the first branch of the empty\ntrie (Figure 1 a). Each node is labeled with the number 1\nwhich indicates that the command has been inserted in the\nnode once (in Figure 1, this number is enclosed in square\nbrackets). Then, the suffixes of the subsequence ({date \u2192\nls} and {ls}) are also inserted (Figure 1 b). Finally, after\ninserting the 3 subsequences and its corresponding suffixes,\nthe completed trie is obtained (Figure 1 c).\nFig. 1. Steps of creating an example trie.\nC. Creation of the user profile\nOnce the trie is created, the subsequences that characterize\nthe user profile and its relevance are obtained by traversing\nthe trie (where a subsequence is a path from the root node\nto any other node of the trie). For this purpose, frequency-\nbased methods can be used. In particular, in EvABCD, to\nevaluate the relevance of a subsequence, its relative frequency\nor support [16] is calculated. In this case, the support of a\nsubsequence is defined as the ratio of the number of times\nthe subsequence has been inserted into the trie to the total\nnumber of subsequences of equal size inserted. Because\nof the frequency of a command is always higher than the\nfrequency of two consecutive commands, it is important to\ncalculate the support according to the subsequences of equal\nsize.\nThus, in this step the trie can be transformed into a set\nof subsequences labeled with its support value. In EvABCD\nthis set of subsequences is represented as a distribution of\nrelevant subsequences.\nIn the previous example, the trie consists of 9 nodes;\ntherefore, the profile consists of 9 different subsequences\nwhich are labeled with its support. Figure 2 shows the\ndistribution of these subsequences.\nOnce a user behaviour profile has been created, it is\nclassified by the classifier as explained in the next section.\nV. EVOLVING UNIX USER CLASSIFIER\nA classifier is a mapping from the feature space to the\nclass label space. In the proposed classifier, the feature\nspace is defined by distributions of subsequences of events\n(a distribution represents a user behaviour and has been\ncalculated as explained in the previous subsection). On the\nother hand, the class label space is represented by the most\nrepresentative distributions. Thus, a distribution in the class\nlabel space represents a specific behaviour which is one of\nthe prototypes of the evolving-profile-library (EPLib). The\nprototypes are not fixed and evolve (dynamically change)\ntaking into account the new information collected on-line\nfrom the data stream - this is what makes the classifier\nEvolving. The number of these prototypes is not pre-fixed but\nit depends on the homogeneity of the observed behaviours.\nThe whole classifier is detailed in the following sub-sections.\nA. User behaviour representation\nEvABC receives observations in real-time from the en-\nvironment to analyze. In our case, these observations are\nthe commands typed by a user. These observations are con-\nverted into the corresponding distribution on-line. In order\nto classify UNIX user behaviours these distributions must be\nrepresented in a data space. For this reason, each distribution\nis considered as a data vector that defines a point that can\nbe represented in the data space.\nThe data space in which we can represent these points\nshould consist of n dimensions, where n is the number of\nthe different subsequences observed. It means that we should\nknow all the different subsequences of the environment a\npriori. However, these subsequences could be unknown and\nthe creation of this data space from the beginning is not\nefficient. For this reason, in EvABCD the dimensions of the\ndata space also evolves (is incrementally growing) according\nto the different subsequences that are represented in it.\nFigure 3 explains graphically this novel idea. In this\nexample, the distribution of the first user consists of 5\nsubsequences of commands (ls, date, ls-date, cat and vi),\ntherefore we need a 5 dimensional data space to represent\nthis distribution (each different subsequence is represented\nby one dimension). If we consider the second user, we can\nsee that 2 of the 5 previous subsequences have not been typed\nby this user (ls-date and cat). It is important to consider that\nthis value is not available so it can not be represented by the\nnumber 0. Also, there are 2 new subsequences (emacs and\nrm) so the representation of this value in the same data space\nneeds to increase the dimensionality of the data space from 5\nto 7. To sum up, the dimensions of the data space represent\nthe different subsequences typed by the users and they\n18\nFig. 2. Distribution of subsequences.\nwill increase according to the different new subsequences\nobtained.\nFig. 3. Distributions of subsequences of events in evolving systems -\nExample\nB. Calculating the potential of a data sample\nAs in [7], a prototype is a data sample (a behaviour\nrepresented by a distribution of subsequences of events) that\nrepresents several samples and has been selected from the\navailable data by an unsupervised learning. The classifier\nis initialized with the first data sample (which is stored in\nEPLib). After this, each data sample is classified to one\nof the prototypes (classes) defined in the classifier. Then,\nbased on the potential of the new data sample to become a\nprototype [17], it could form a new prototype or replace an\nexisting one.\nThe potential of a data sample (zk) is calculated by the\nequation (1) which represents a function of the accumulated\ndistance between a sample and all the other samples in the\ndata space per class. The result of this function represents\nthe density of the data that surrounds a certain data sample.\nP (zk) =\n1\n1 +\n\u2211k\u22121\ni=1 distance\n2(xk,xi)\nk\u22121\n(1)\nwhere zk denotes the kth data sample and distance repre-\nsents the distance between two samples in the data space.\nIn [18] the potential is calculated using the euclidean\ndistance and in [7] it is calculated using the cosine distance.\nCosine distance has the advantage that it tolerates different\nsamples to have different number of attributes (subsequences\nlabeled with its support value). Cosine distance also tolerates\nif the value of several subsequences in a sample can be null\n(null is different than zero). Therefore, EvABCD uses the\ncosine distance (cosDist) to measure the similarity between\ntwo behaviours.\ncosDist(zk, zp) = 1\u2212\n\u2211n\nj=1 zkjzpj\u221a\u2211n\nj=1 z\n2\nkj\n\u2211n\nj=1 z\n2\npj\n(2)\nwhere zk and zp represent the two samples to measure its\ndistance and n represents the number of different attributes\n(subsequences) in both samples.\nNote that the expression in the equation (1) requires all\nthe accumulated data which contradicts to the requirement\nfor real-time and on-line application needed in the proposed\napproach. For this reason, a recursive expression of the\npotential in which is not needed to store the history of all\nthe data was developed in [17] [18] using euclidean distance\nand in [7] using cosine distance.\nAs it is explained in the Appendix, to get recursively the\nvalue of the potential of a sample using the equation (1)\nis necessary to calculate nxn different accumulated values\nwhich store the result of multiply a value by all the other\ndifferent values (these values are represented as dijk ). As it\nis detailed in the Appendix, the result of this derivation is:\nPk(zk) =\n1\n2 + [ 1h(k\u22121) [[\u22122BK ] + [ 1hDk]]]\nk = 2, 3...;P1(z1) = 1\nwhere :\nBk =\nn\u2211\nj=1\nzkjb\nj\nk ; b\nj\nk = b\nj\n(k\u22121) +\n\u221a\n(zjk)2\u2211n\nl=1(z\nl\nk)2\nbj1 =\n\u221a\n(zj1)2\u2211n\nl=1(z\nl\n1)2\n; j = [1, n+ 1]\nDk =\nn\u2211\nj=1\nzjk\nn\u2211\np=1\nzpkd\njp\nk ; d\njp\nk = d\njp\n(k\u22121) +\nzjkz\np\nk\u2211n\nl=1(z\nl\nk)2\nd1j1 =\nzj1z\n1\n1\u2211n\nl=1(z\nl\n1)2\n; j = [1, n+ 1]\n(3)\nHowever, in our particular application of user behaviour\nmodelling the data represent support values and are thus\npositive. Thus, to simplify the expression (1) one can use\nsimply the distance instead of square of the distance. For\nthis reason, we use equation (4) instead of (1).\n19\nP (zk) =\n1\n1 +\n\u2211k\u22121\ni=1 cosDist(xk,xi)\nk\u22121\n(4)\nUsing the equation (4), we develop a recursive expression\nsimilar to the recursive expressions derived in [18] and [7].\nThis formula is as follows:\nPk(zk) =\n1\n2\u2212 1k\u22121 1\u221a\u2211n\nj=1(z\nj\nk)\n2\nBk\n; k = 2, 3, ...;P1(z1) = 1\nwhere Bk =\nn\u2211\nj=1\nzjkb\nj\nk ; b\nj\nk = b\nj\n(k\u22121) +\n\u221a\n(zjk)2\u2211n\nl=1(z\nl\nk)2\nand bj1 =\n\u221a\n(zj1)2\u2211n\nl=1(z\nl\n1)2\n; j = [1, n+ 1]\n(5)\nC. Creating new prototypes\nThe proposed evolving user behaviour classifier EvABCD\ncan start \u2019from scratch\u2019 (without prototypes in the library)\nin a similar manner as eClass evolving fuzzy rule-based\nclassifier proposed in [18], used in [19] for robotics and\nfurther developed in [7]. The potential of each new data\nsample (user behaviour represented by a distribution of\nsubsequences) is calculated recursively and the potential of\nthe other prototypes is updated. After that, the potential of\nthe new sample (zk) is compared with the potential of the\nexisting prototypes. A new prototype is created if its value\nis higher than any other existing prototype, as shown in\nequation (6).\n\u2203i, i = [1, NumPrototypes]; P (zk) > P (Proti) (6)\nThus, if the new data sample is not relevant, the overall\nstructure of the classifier is not changed. Otherwise, the\nclassifier evolves by adding new prototypes which represent\na part of the observed data samples.\nD. Removing existing prototypes\nAfter adding a new prototype, we check whether any of the\nalready existing prototypes are described well by the newly\nadded prototype [7]. By well we mean that the value of\nthe membership function that describes the closeness to the\nprototype is a Gaussian bell function due to its generalization\ncapabilities (equation (7)):\n\u2203i, i = [1, NumPrototypes]; \u00b5i(zk) > e\u22121 (7)\nFor this reason, we calculate the membership function\nbetween a data sample and a prototype which is defined\nas (8):\n\u00b5i(zk) = e\n\u2212 12 [\ncosDist(zk,Proti)\n\u03c3i\n] ; i = [1, NumPrototypes]\n(8)\nwhere cosDist(zk, P roti) represents the cosine distance\nbetween a data sample (zk) and the ith prototype (Proti);\n\u03c3i represents the spread of the membership function, which\nalso represents the radius of the zone of influence of the\nprototype. This spread is determined based on the scatter [20]\nof the data. The equation to get the spread of the kth data\nsample is defined in (9):\n\u03c3i(k) =\n\u221a\u221a\u221a\u221a1\nk\nk\u2211\nj=1\ncosDist(Proti, zk) ; \u03c3i(0) = 1 (9)\nwhere k is the number of data samples inserted in the same\nclass; cosDist(Proti, zk) is the cosine distance between the\nnew data sample (zk) and the ith prototype.\nHowever, to calculate the scatter without storing all the\nreceived samples, this value can be updated (as shown\nin [18]) recursively by equation (10):\n\u03c3i(k) =\n\u221a\n[\u03c3i(k)]2 +\n1\nk\n[cosDist2(Proti, zk)\u2212 [\u03c3i(k \u2212 1)]2]\n(10)\nE. Classification Method\nIn order to classify a new data sample, we compare it\nwith all the prototypes stored in the evolving-profile-library\n(EPLib). This comparison is done using cosine distance and\nthe smallest distance determines the closest similarity. This\naspect is considered in equation (11).\nClass(xz) = Class(Prot\u2217);\nProt\u2217 =MINNumProti=1 (cosDist(xPrototypei , xz))\n(11)\nThe time-consumed for classifying a new sample depends\non the number of prototypes and its number of attributes.\nHowever, we can consider (in general terms) that both\nthe time-consumed and the computational complexity are\nreduced and are acceptable for real-time applications (in\norder of milliseconds per data sample).\nF. Structure of the EvABCD\nOnce explained the different parts in which the proposed\nclassifier can be divided, we show the structure of this\nclassifier. The input of the proposed classifier is a behaviour\nstream, where each behaviour is represented as a distribution\nof subsequences of events. Therefore, once the distribution\nhas been created from the stream, it is processed by the\nclassifier. The structure of the proposed classifier is as\nfollows:\n1) Classify the new sample in a class (represented by a\nprototype) using (11).\n2) Calculate the potential of the new data sample to be\na prototype using the recursive formula (5).\n3) Update all the prototypes considering the new data\nsample (using (5)). It is done because the situation of\nthe data space changes with the insertion of each new\ndata sample.\n4) Insert the new data sample as a new prototype if\nneeded (if (6) holds).\n20\n5) Remove any prototype if needed (if (7) holds).\nTherefore, as we can see, the classifier does not need\nto be configured (the classifier can start \u2019from scratch\u2019)\naccording to the environment where it is used. Also, the\nrelevant information of the obtained samples is necessary\nto update the library, but it is not necessary to store all the\ninformation in it.\nG. Supervised and unsupervised learning\nThe proposed classifier can be used for both supervised\nand unsupervised learning.\n\u2022 Supervised learning: The data samples that are ob-\nserved can have a label assigned to them a priori. In this\ncase, a specific class (label) is represented by several\nprototypes (the number of prototypes depends on how\nheterogeneous are the samples of the same class). This\ntechniques is used for example in eClass1 [18] and [7];\n\u2022 Unsupervised learning: The observed data samples do\nnot have labels. In this case, the classes are created\nbased on the prototypes and, thus, any prototype repre-\nsents a different class (label). Such technique is used for\nexample in eClass0 [18] and [7] which is a clustering-\nbased classification.\nVI. EXPERIMENTAL SETUP AND RESULTS\nIn order to evaluate EvABCD in the UNIX environment,\nwe use a data set with the UNIX commands typed by 168\nreal users and labeled in 4 different groups. Therefore, in\nthese experiments we will use supervised learning.\nA. Data Set\nFor evaluating EvABCD in the UNIX environment, we\nhave used the command-line data collected by Green-\nberg [21] using UNIX csh command interpreter. In these data,\nfour target groups were identified, representing a total of 168\nmale and female users with a wide cross-section of computer\nexperience and needs. Salient features, the size of the data\nstream (the number of people observed) and command lines\nof each group are described below.\n\u2022 Novice Programmers: The users of this group had little\nor no previous exposure to programming, operating sys-\ntems, or Unix-like command-based interfaces. Sample:\n55 Users and 77423 command lines.\n\u2022 Experienced Programmers: In this group, the members\nwere senior computer science undergraduates, expected\nto have a fair knowledge of the Unix environment.\nSample: 36 Users and 74906 command lines.\n\u2022 Computer Scientist: This group had varying experience\nwith Unix, although all were experts with computers.\nSample: Sample: 52 Users and 125691 command lines.\n\u2022 Non-programmers: Document preparation was the dom-\ninant activity of the members of this group. Knowledge\nof Unix was the minimum necessary to get the job done.\nSample: 25 Users and 25608 command lines.\nB. Experimental Design\nIn order to measure the performance of the proposed\nclassifier using the above data, the well-established technique\nof cross-validation is used. For this research, 10-fold cross-\nvalidation is chosen. Thus, all the users (training set) are\ndivided into 10 disjoint subsets with equal size. Each of\nthe 10 subsets is left out in turn for evaluation. It should\nbe emphasized that the proposed EvABCD does not need\nnecessarily to work in this mode. This is done mainly in\norder to have comparable results with the established off-\nline techniques. In reality the proposed EvABCD classifier\ncan work on a per sample and per user basis.\nThe number of UNIX commands analyzed per user is very\nrelevant for the result of the classification. Using EvABCD\nin a real application, after a user has typed a particular\nnumber of commands, its behaviour can be classified and\nthe evolving behaviour library updated. However, in order to\nuse all the data we have, in this experiment all the commands\nthe user has typed during a long period of time are used. For\nthis resason, a distribution (which represent a behaviour) is\nrepresented by a very large number of subsequences. And\nif the number of users increases, the number of different\nsubsequences increases, too.\nIn the phase of behaviour model creation, the length of the\nsubsequences in which the original sequence is segmented\n(used for creating the trie) is a relevant parameter: using\nlonger subsequences, the time consumed for creating the\ntrie and the number of relevant subsequences in the corre-\nsponding distribution increase drastically. In the experiments\npresented in this paper, the subsequence length value was\nselected to be 3.\nC. Results\nAlthough the sequence length is small (3 commands),\nthe number of commands typed per user is large; thus,\nthe number of different subsequences of commands created\nper user is very large. The number of diffeerent subse-\nquences is shown per group as follows; Novice Programmers:\n25614, Experienced Programmers: 43049, Computer Scien-\ntists: 66490, Non-Programmers: 10572. Also, the number of\ndifferent subsequences of commands typed by the 168 users\nis 135317.\nAccording to this data, after applying EvABCD using the\nexplained experimental design, the percentage of users cor-\nrectly classified into its corresponding group is: 100% on\nvalidation data! Therefore, this result shows that the proposed\nclassifier works excellent in this kind of environments.\nThe number of prototypes created per group is important,\ntoo. As we have used 10-fold cross validation, the number\nof different prototypes created in each of the 10 runs is\nshown in table VI-C. This number varies depending on the\nheterogeneity of the data.\nThe result obtained in this experiment shows that the pro-\nposed classifier can be very useful to classify user behaviours\nin a dynamic environment for the example of the UNIX user\nprofiles with a great amount of data (in this case, commands\n21\nTABLE I\nEVABCD: NUMBER OF PROTOTYPES CREATED PER GROUP USING\n10-FOLD CROSS-VALIDATION\nPrototypes in each of the 10 runs\nGroup 1 2 3 4 5 6 7 8 9 10\nNovice Progr. 3 2 7 2 2 2 3 4 2 2\nExp. Progr. 2 3 3 2 2 2 2 2 2 2\nComp. Scientists 2 2 1 2 1 1 1 1 3 3\nNon-Progr. 2 2 1 2 2 2 2 2 2 2\nper user). In order to compare these results we consider\ntwo well established classifiers - the algorithm C4.5 used to\ngenerate a decision tree and the k-nearest neighbor algorithm\n(k-NN) used to classify objects based on closest training\nexamples in the feature space. However, this comparison\ncould not be done in this experiment because of the big\namount of attributes per sample to consider. This obstructed\nboth algorithm C4.5 and k-nearest neighbor algorithm (k-\nNN) could not run because of the memory overload. Note,\nthat our proposed approach does not need to store entire data\nstream in the memory and disregards any sample after being\nused. Thus, based on the experiment size and dimensions as\ndescribed so far, the proposed approach EvABCD was the\nonly working alternative.\nHowever, in order to make a comparison, we reduced the\nnumber of subsequences of commands per user using its\nsupport value. In this case, we consider that the subsequences\nwith a higher support are more relevant. The percentage of\nsubsequences reduced is very high and only around the 3%\nof the initial data were used. It means that the total number\nof different subsequences considered was in this reduced\ndimensionality second experiment equal to 3531. In this\nreduced dimension experiment, again the proposed EvABCD\nevolving classifier outperformed the well established off-line\nclassifiers and the results are tabulated in table VI-C.\nTABLE II\nCOMPARATIVE RESULTS\nClassifier Rate of unknown users correctly classified\nEvABCD 81,54 %\nC4.5 73,80 %\n3-Nearest Neighbor 44,64 %\nNote that this reduction in the dimensionality of the\nexperiment as well as the 10-fold cross-validation is needed\nonly for the sake of comparison. Inevitably, the reduction of\nthe raw data leads to a lower performance, but nevertheless,\nthe proposed evolving classifier EvABCD outperforms signif-\nicantly the well established off-line classifiers. Moreover, it\nis computationally more simple and efficient as it is recursive\nand one pass (works on a per sample basis).\nVII. CONCLUSIONS\nIn this paper we propose a generic approach to user\nbehaviours modelling and consider the specific example of\nusers of Unix computer command sequences. The proposed\nevolving classifier EvABCD is one pass, non-iterative, recur-\nsive and therefore, computationally very efficient and fast.\nThe test results with a data sequence of 168 real users\nof Unix demonstrates that it is also able to outperform\nsignificantly the well established off-line classifiers in terms\nof correct classification on validation data. Although it is not\naddressed in this paper, the proposed method can be also used\nto monitor, analyze and detect abnormalities based on a time\nvarying pattern of same users and to detect masqueraders. It\ncan also be applied to other type of users such as users of\ne-services, digital communications, etc.\nAPPENDIX\nIn this appendix the expression of the potential is trans-\nformed in a recursive expression in which the potential is\ncalculated using only the current data sample (zk). For this\nnovel derivation we combine the expression of the potential\nfor a sample data (equation (1)) represented by a vector of\nelements and the distance cosine expression (2).\nPk(zk) =\n1\n1 + [ 1k\u22121\n\u2211k\u22121\ni=1 [1\u2212\n\u2211n\nj=1 z\nj\nkz\nj\ni\u221a\u2211n\nj=1(z\nj\nk)\n2\n\u2211n\nj=1(z\nj\ni )\n2\n]2]\n(12)\nwhere zk denotes the kth sample inserted in the space data.\nEach sample is represented by a set of values represented by\na number: the ith attribute (element) of the kz sample is\nrepresented as: zik.\nIn order to explain the derivation of the expression step by\nstep; firstly, we consider the denominator of the equation (12)\nwhich is named as den.P (zk).\nden.Pk(zk) = 1 + [\n1\nk \u2212 1\nk\u22121\u2211\ni=1\n[1\u2212\n\u2211n\nj=1 z\nj\nkz\nj\ni\u221a\u2211n\nj=1(z\nj\nk)2\n\u2211n\nj=1(z\nj\ni )2\n]2]\nden.Pk(zk) = 1 + [\n1\nk \u2212 1\nk\u22121\u2211\ni=1\n[1\u2212 fi\nh gi\n]2] where :\nfi =\nn\u2211\nj=1\nzjkz\nj\ni , h =\n\u221a\u221a\u221a\u221a n\u2211\nj=1\n(zjk)2 and gi =\n\u221a\u221a\u221a\u221a n\u2211\nj=1\n(zji )2\n(13)\nWe can observe that the variables fi and gi depend on\nthe sum of all the data samples (all these data samples are\nrepresented by i); but the variable h represents the sum of\nthe attributes value of the sample. Therefore, deriving (13),\nwe obtain:\nden.Pk(zk) = 2 + [\n1\nh(k \u2212 1) [[\u22122\nk\u22121\u2211\ni=1\nfi\ngi\n] + [\n1\nh\nk\u22121\u2211\ni=1\n(\nfi\ngi\n)2]]]\n(14)\nIn order to obtain an expression for the potential from (14),\nwe rename as follows:\n22\nden.Pk(zk) = 2 + [\n1\nh(k \u2212 1) [[\u22122BK ] + [\n1\nh\nDk]]]\nwhere : Bk =\nk\u22121\u2211\ni=1\nfi\ngi\n; Dk =\nk\u22121\u2211\ni=1\n(\nfi\ngi\n)2\n(15)\nIf we analyze each variable (Bk and Dk) separately\n(considering the renaming done in (13)):\nFirstly, we consider Bk\nBk =\nk\u22121\u2211\ni=1\n\u2211n\nj=1 z\nj\nkz\nj\ni\u221a\u2211n\nj=1(z\nj\ni )2\n=\nn\u2211\nj=1\nzjk\nk\u22121\u2211\ni=1\n\u221a\n(zji )2\u2211n\nl=1(z\nl\ni)2\n(16)\nIf we define bik, each attribute of the sample b, we get:\nbjk =\nn\u2211\ni=1\n\u221a\n(zji )2\u2211n\nl=1(z\nl\ni)2\n(17)\nThus, the value of Bk can be calculated as a recursive\nexpression:\nBk =\nn\u2211\nj=1\nzkjb\nj\nk ; b\nj\nk = b\nj\n(k\u22121) +\n\u221a\n(zjk)2\u2211n\nl=1(z\nl\nk)2\nbj1 =\n\u221a\n(zj1)2\u2211n\nl=1(z\nl\n1)2\n(18)\nSecondly, considering Dk with the renaming done in (13),\nwe get:\nDk =\nk\u22121\u2211\ni=1\n(\n\u2211n\nj=1 z\nj\nkz\nj\ni\u221a\u2211n\nj=1(z\nj\ni )2\n)2\nDk =\nn\u2211\nj=1\nzjk\nn\u2211\np=1\nzpk\nk\u22121\u2211\ni=1\nzijk z\nip\nk\n1\u2211n\nl=1(z\nl\ni)2\n(19)\nIf we define dik, each attribute of the sample d, we get:\ndjpk =\nk\u22121\u2211\ni=1\nzijk z\nip\nk\n1\u2211n\nl=1(z\nl\ni)2\n(20)\nTherefore:\nDk =\nn\u2211\nj=1\nzjk\nn\u2211\np=1\nzpkd\njp\nk ; d\njp\nk = d\njp\n(k\u22121) +\nzjkz\np\nk\u2211n\nl=1(z\nl\nk)2\n;\nd1j1 =\nzj1z\n1\n1\u2211n\nl=1(z\nl\n1)2\n; j = [1, n+ 1]\n(21)\nFinally:\nPk(zk) =\n1\n2 + [ 1h(k\u22121) [[\u22122BK ] + [ 1hDk]]]\nk = 2, 3...;P1(z1) = 1\n(22)\nwhere Bk is obtained as in (18), and Dk is described\nin (21).\nNote that to get recursively the value of Bk, it is necessary\nto calculate n accumulated values (in this case, n is the\nnumber of the different subsequences obtained). However,\nto get recursively the value of Dk we need to calculate\nnxn different accumulated values which store the result of\nmultiply a value by all the other different values (these values\nare represented as dijk ).\nREFERENCES\n[1] M. Schonlau, W. Dumouchel, W. H. Ju, A. F. Karr, and Theus,\n\u201cComputer Intrusion: Detecting Masquerades,\u201d in Statistical Science,\nvol. 16, 2001, pp. 58\u201374.\n[2] R. A. Maxion and T. N. Townsend, \u201cMasquerade detection using trun-\ncated command lines,\u201d in DSN \u201902: Proceedings of the 2002 Interna-\ntional Conference on Dependable Systems and Networks. Washington,\nDC, USA: IEEE Computer Society, 2002, pp. 219\u2013228.\n[3] A. A. Macedo, K. N. Truong, J. A. Camacho-Guerrero, and\nM. da GraC\u00b8a Pimentel, \u201cAutomatically sharing web experiences\nthrough a hyperdocument recommender system,\u201d in HYPERTEXT\n2003. New York, NY, USA: ACM, 2003, pp. 48\u201356.\n[4] D. L. Pepyne, J. Hu, and W. Gong, \u201cUser profiling for computer\nsecurity,\u201d in Proc. American Control Conference, 2004, pp. 982\u2013987.\n[5] D. Godoy and A. Amandi, \u201cUser profiling for web page filtering,\u201d\nIEEE Internet Computing, vol. 9, no. 4, pp. 56\u201364, 2005.\n[6] S. E. Coull, J. W. Branch, B. K. Szymanski, and E. Breimer, \u201cIntrusion\ndetection: A bioinformatics approach.\u201d in ACSAC, 2003, pp. 24\u201333.\n[7] P. Angelov and X. Zhou, \u201cEvolving fuzzy rule-based classifiers from\ndata streams,\u201d IEEE Transactions on Fuzzy Systems: Special issue on\nEvolving Fuzzy Systems, vol. 16, no. 6, p. to appear, 2008.\n[8] J. Anderson, Learning and Memory: An Integrated Approach. New\nYork: John Wiley and Sons., 1995.\n[9] Y. Horman and G. A. Kaminka, \u201cRemoving biases in unsupervised\nlearning of sequential patterns,\u201d Intelligent Data Analysis, vol. 11,\nno. 5, pp. 457\u2013480, 2007.\n[10] T. Lane and C. E. Brodley, \u201cTemporal sequence learning and data\nreduction for anomaly detection,\u201d in CCS \u201998: Proceedings of the 5th\nACM conference on Computer and communications security. New\nYork, NY, USA: ACM, 1998, pp. 150\u2013158.\n[11] P. Riley and M. M. Veloso, \u201cOn behavior classification in adversarial\nenvironments,\u201d in DARS, pp. 371\u2013380.\n[12] E. Fredkin, \u201cTrie memory,\u201d Comm. A.C.M., vol. 3, no. 9, pp. 490\u2013499,\nSept. 1960.\n[13] J. A. Iglesias, A. Ledezma, and A. Sanchs, \u201cSequence classification\nusing statistical pattern recognition.\u201d in IDA, ser. LNCS, vol. 4723.\nSpringer, 2007, pp. 207\u2013218.\n[14] G. A. Kaminka, M. Fidanboylu, A. Chang, and M. M. Veloso, \u201cLearn-\ning the sequential coordinated behavior of teams from observations,\u201d\nin RoboCup, ser. Lecture Notes in Computer Science, vol. 2752.\nSpringer, 2002, pp. 111\u2013125.\n[15] J. A. Iglesias, A. Ledezma, and A. Sanchis, \u201cA comparing method of\ntwo team behaviours in the simulation coach competition,\u201d in MDAI,\nser. LNCS, vol. 3885. Springer, 2006, pp. 117\u2013128.\n[16] R. Agrawal and R. Srikant, \u201cMining sequential patterns,\u201d in Inter-\nnational Conference on Data Engineering, Taipei, Taiwan, 1995, pp.\n3\u201314.\n[17] P. Angelov and D. Filev, \u201cAn approach to online identification of\ntakagi-sugeno fuzzy models,\u201d Systems, Man, and Cybernetics, Part\nB, IEEE Transactions on, vol. 34, no. 1, pp. 484\u2013498, Feb. 2004.\n[18] P. Angelov, X. Zhou, and F. Klawonn, \u201cEvolving fuzzy rule-based clas-\nsifiers,\u201d Computational Intelligence in Image and Signal Processing,\n2007. CIISP 2007. IEEE Symposium on, pp. 220\u2013225, April 2007.\n[19] X. Zhou and P. Angelov, \u201cAutonomous visual self-localization in\ncompletely unknown environment using evolving fuzzy rule-based\nclassifier,\u201d Computational Intelligence in Security and Defense Ap-\nplications, 2007. CISDA 2007. IEEE Symp., pp. 131\u2013138, April 2007.\n[20] P. Angelov and D. Filev, \u201cSimpl ets: a simplified method for learning\nevolving takagi-sugeno fuzzy models,\u201d Fuzzy Systems, 2005. FUZZ\n\u201905. The 14th IEEE International Conference on, pp. 1068\u20131073, May\n2005.\n[21] S. Greenberg, \u201cUsing unix: Collected traces of 168 users,\u201d Master\u2019s\nthesis, Department of Computer Science, University of Calgary, Al-\nberta, Canada, 1988.\n23\n"}
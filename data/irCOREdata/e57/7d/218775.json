{"doi":"10.1007\/s10992-011-9176-4","coreId":"218775","oai":"oai:eprints.lse.ac.uk:35450","identifiers":["oai:eprints.lse.ac.uk:35450","10.1007\/s10992-011-9176-4"],"title":"Conditional probability in the light of qualitative belief change","authors":["Makinson, David C."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-04","abstract":"We explore ways in which purely qualitative belief change in the AGM tradition throws light on options in the treatment of conditional probability. First, by helping see why it can be useful to go beyond the ratio rule defining conditional from one-place probability. Second, by clarifying what is at stake in different ways of doing that. Third, by suggesting novel forms of conditional probability corresponding to familiar variants of qualitative belief change, and conversely. Likewise, we explain how recent work on the qualitative part of probabilistic inference leads to a very broad class of 'proto-probability' functions","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/218775.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/35450\/1\/Makinson_Conditional-probability-in-the-light-of-qualitative-belief-change_2011.pdf","pdfHashValue":"b55a2f637903af4a4a0c93f17111f18263074b21","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:35450<\/identifier><datestamp>\n      2014-05-22T11:53:12Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5048<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/35450\/<\/dc:relation><dc:title>\n        Conditional probability in the light of qualitative belief change<\/dc:title><dc:creator>\n        Makinson, David C.<\/dc:creator><dc:subject>\n        B Philosophy (General)<\/dc:subject><dc:description>\n        We explore ways in which purely qualitative belief change in the AGM tradition throws light on options in the treatment of conditional probability. First, by helping see why it can be useful to go beyond the ratio rule defining conditional from one-place probability. Second, by clarifying what is at stake in different ways of doing that. Third, by suggesting novel forms of conditional probability corresponding to familiar variants of qualitative belief change, and conversely. Likewise, we explain how recent work on the qualitative part of probabilistic inference leads to a very broad class of 'proto-probability' functions.<\/dc:description><dc:publisher>\n        Springer<\/dc:publisher><dc:date>\n        2011-04<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/35450\/1\/Makinson_Conditional-probability-in-the-light-of-qualitative-belief-change_2011.pdf<\/dc:identifier><dc:identifier>\n          Makinson, David C.  (2011) Conditional probability in the light of qualitative belief change.  Journal of Philosophical Logic, 40 (2).  pp. 121-153.  ISSN 0022-3611     <\/dc:identifier><dc:relation>\n        http:\/\/www.springer.com\/philosophy\/logic+and+philosophy+of+language\/journal\/10992<\/dc:relation><dc:relation>\n        10.1007\/s10992-011-9176-4<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":null,"relations":["http:\/\/eprints.lse.ac.uk\/35450\/","http:\/\/www.springer.com\/philosophy\/logic+and+philosophy+of+language\/journal\/10992","10.1007\/s10992-011-9176-4"],"year":2011,"topics":["B Philosophy (General)"],"subject":["Article","PeerReviewed"],"fullText":"  \nDavid C. Makinson \nConditional probability in the light of \nqualitative belief change \n \nArticle (Accepted version) \n(Refereed) \n \n \n \nOriginal citation: \nMakinson, David C. (2011) Conditional probability in the light of qualitative belief change. Journal \nof Philosophical Logic, 40 (2). pp. 121-153. ISSN 0022-3611 DOI: 10.1007\/s10992-011-9176-4 \n \n\u00a9 2011 Springer Science+Business Media B.V. \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/35450\/ \nAvailable in LSE Research Online: May 2014 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final accepted version of the journal article. There may be \ndifferences between this version and the published version.  You are advised to consult the \npublisher\u2019s version if you wish to cite from it. \n \n \n \n1 \nConditional Probability in the Light of Qualitative Belief Change \n \nDavid Makinson \n \n \nAbstract \n \nWe explore ways in which purely qualitative belief change in the AGM tradition \nthrows light on options in the treatment of conditional probability. First, by helping \nsee why it can be useful to go beyond the ratio rule defining conditional from one-\nplace probability. Second, by clarifying what is at stake in different ways of doing \nthat. Third, by suggesting novel forms of conditional probability corresponding to \nfamiliar variants of qualitative belief change, and conversely. Likewise, we explain \nhow recent work on the qualitative part of probabilistic inference leads to a very broad \nclass of \u2018proto-probability\u2019 functions.  \n \nKey words: conditional probability, belief revision, ratio rule, AGM, Hosiasson-\nLindenbaum, Kolmogorov, Popper, R\u00e9nyi, van Fraassen, cores, screened revision, \nhyper-revisionary probability, proto-probability, conditional plausibility measures. \n \n \n1. Why Go Beyond the Ratio Rule? \n \nKolmogorov\u2019s axioms for one-place probability functions are simple and easy to work \nwith, and the associated ratio definition of conditional probability is convenient to use \n(see appendix). They have become standard. So why go beyond them? \n \nThe reasons advanced in the literature are of two main kinds: a metaphysical \ncomplaint and a pragmatic appeal for greater expressiveness. We outline them in this \nsection, and suggest that while the metaphysical grounds are less than compelling, \nthere is indeed a need for greater expressive capacity. In the following section, we \nshow how a comparison with the situation in qualitative belief revision makes that \nneed all the more evident. \n \nTo keep the main text reader-friendly, most of the verifications and historical remarks \nare placed in an extended appendix, whose sections run parallel to the main text. \n \n1.1. Doctrinal vs Pragmatic Considerations \n \nIt is commonly felt (see appendix) that all probability is 'really' conditional anyway, \nand we should bring this out by integrating it into our formal treatment. From a \nsubjective perspective: a probability judgement is always made given a whole lot of \nbackground information, and so is in some sense conditional on that information. \nFrom a frequency standpoint: probability is some sort of limiting frequency of a type \nof item in a reference set, and if we enlarge or diminish the set, the frequency will in \ngeneral change.  \n \nHowever, this perspective has its limitations. Considered as an argument, it may \ninvolve an infinite regress, as is most easily seen in the field-of-sets mode. Suppose \nwe do take probability as a two-place function p: F\n2\uf0ae[0,1] where F is a field of \nsubsets of a set S. This still depends on the choice of the underlying set S. Turning p \n2 \ninto a three-place function p: F\n3\uf0ae[0,1] will not help, as F3 still depends on S, taking \nus one step further in an infinite regress. The only way to eliminate all such \ndependence is to fix the domain as the universal class. But practising probabilists \nnever do this and, if done, it might as well be done from the beginning, with one-place \nfunctions.  \n \nHistorically, the perspective is reminiscent of an early way of looking at classical \nfirst-order logic, according to which universal quantifications \uf022x\uf06a(x) are at bottom \nalways conditional, since their range depends on the choice of domain of discourse. \nOn this view, the dependency should be made explicit from the outset by always \nquantifying over the entire universe, rewriting \uf022x\uf06a(x) as \uf022x[Dx\uf0ae\uf06a(x)] where D is \nthe intended domain. Such a view had some philosophical currency for a while \ndespite the difficulties of talking about a universal set (so the universe was thought of \nas a class rather than a set). But we have become accustomed to working with the \nsimpler mode of representing universal quantification without running into difficulty, \nand the philosophical worries have simply withered away.  \n \nThe historical precedent carries a methodological lesson. Even if all quantification or \nprobability can be said to be in some sense conditional, this does not imply that the \nconditionality should always be brought into the formalism of the theory itself. It may \nsometimes be better treated as part of the business of applying the theory to specific \nproblems. \n \nThus, it would seem that the doctrinal or metaphysical reasons for always taking \nconditional probability as primitive are less than compelling. Nevertheless, an \nimportant consideration remains. When conditional probability is defined by the ratio \nrule, it has limited expressive capacity. Sometimes we would like to allow \npropositions that have been accorded zero probability to serve as conditions for the \nprobability of other propositions. This is impossible when p(x|a) is understood as \np(a\uf0d9x)\/p(a), for it is undefined when p(a) \uf03d 0.  \n \nThe most famous example of this expressive gap is due to Borel. Suppose a point is \nselected at random from the surface of the earth. What is the probability that it lies in \nthe western hemisphere, given that it lies on the equator? The condition of lying \n(exactly) on the equator has probability 0 under the random selection, but we would \nbe inclined to regard the question as meaningful and even as having 1\/2 for its answer. \nExamples have also arisen in the course of investigations in game theory in \nconnection with strategic reasoning and weak dominance; for references see Halpern \n(to appear).  \n \nThis complaint is more modest than the doctrinal claim, pointing to a gap rather than \nalleging a defect. It suggests that it could be helpful to have a more general \nconception of conditional probability that covers what we will call the critical zone \u2013 \nthe case where the condition a is consistent but of zero probability \u2013 and that we \nshould try to articulate it.  \n \nAs remarked by e.g. R\u00e9nyi, in mathematical practice one can sometimes 'work around' \nthe problem. The idea is that when a is in the critical zone, we could take p(x|a) to be \nthe limit of the values of p(x|a\uf0a2) for a suitable infinite sequence of non-critical \napproximations a\uf0a2 to a. This is natural for some examples, such as Borel's \n3 \nhemisphere\/equator one. However, it is possible only for suitable domains \u2013 notably \nfields based directly or indirectly on the real numbers \u2013 satisfying appropriate \nconditions. Moreover, the outcome will depend on our choice of the approximating \nsequence. In the hemisphere\/equator problem, we get the answer 0.5 only if each of \nthe approximating 'equators' has constant width around the globe. If each is thicker in \nthe west than in the east, then the figure will be higher. So the procedure provides \nneither a general solution nor, within its domain, a unique one.  \n \nThis is not to dismiss R\u00e9nyi\u2019s way around the problem out of hand. In practical \nsituations, it may often be the best thing to do. Suppose that in an empirical \ninvestigation we have been working extensively with a particular one-place \nprobability function, and we unexpectedly find ourselves needing to conditionalize on \na proposition to which it accorded value zero. Should we go back and reconstruct \neverything in terms of an intrinsically two-place function? To do so poses two \ndifficulties. In the first place, we need to specify, in a principled manner, the \nbehaviour of the two-place function over the critical zone. We may find that there is \nmore arbitrariness in the decisions required there than in choosing a particular \napproximating sequence \u2013 especially so if, as in the case of the equator example, there \nis a sequence that suggests itself quite naturally. Once the new two-place probability \nfunction has been specified there remains the job of rewriting, in terms of it, all the \nwork so far done in the empirical investigation, and checking that it continues to run. \nIn such circumstances, the simplest thing to do may often be to follow R\u00e9nyi\u2019s work-\naround.  \n \nLet us return, however, to the theoretical level. How should a two-place probability \nfunction behave over the critical zone? There are, of course, quite trivial ways of \nregulating it. One, due to Carnap 1950, is to declare that the zone is empty: whenever \np(x) \uf03d 0 then x is inconsistent. This is sometimes known as the regularity condition. It \nhas the immediate effect that the ratio definition of p(x|a) as p(a\uf0d9x)\/p(a) covers all \ninstances of the right argument a except when a is inconsistent. For inconsistent a, \none can then either leave p(x|a) undefined, or take it to have value 1 for all values of \nthe left argument x. However, as remarked e.g. by Spohn 1986, this is more like a way \nof avoiding than solving the problem. It abolishes by fiat the distinction between \nlogical impossibility and total improbability.  \n \nMoreover, as noted by Harper 1975 (page 229), Carnap's restriction creates an \ninternal inelegance: the set of functions is not closed under left projection of  \nconditionalization, i.e. in Bayesian terminology, under update. To see this, let p be a \nproper one-place Kolmogorov function satisfying Carnap's regularity condition, and \nconsider the two-place function p(\uf0d7|\uf0d7) determined by the ratio definition. Now take a \ncontingent proposition a with 1 \uf0b9 p(a) \uf0b9 0, and form the left projection pa(\uf0d7) alias \np(\uf0d7|a) of the two-place function. By the definition of left projections (see appendix) we \nhave pa(x) \uf03d p(x|a) so substituting \uf0d8a for x, we have pa(\uf0d8a) \uf03d p(\uf0d8a|a) \uf03d p(\uf0d8a\uf0d9a)\/p(a) \n\uf03d 0\/p(a) \uf03d 0 since p(a) > 0. Thus pa(\uf0d8a) \uf03d 0 even though \uf0d8a is consistent, violating \nthe regularity condition as applied to pa. Even when p satisfies the regularity \ncondition, the left projection of its conditionalization under the ratio definition \n(briefly, its update) need not do so. \n \nAnother trivial way of covering the critical zone is to put p(x|a) = 1 for every value of \nx when p(a) = 0. This might be called the ratio\/unit definition of conditional \n4 \nprobability. But while this renders the function always-defined, and is very \nconvenient in many contexts, it does not do much to increase expressive power since \nit makes p(x|a) = p(y|a) = 1 whenever the condition a is in the critical zone. Hopefully \nwe should be able to get something more discriminating; the two-place function \nshould in some sense be essentially conditional.  \n \n1.2. Some Notational Niceties \n \nIn the following sections, we compare various options for axiomatizing conditional \nprobability in the light of qualitative belief revision. When doing so, we follow certain \nnotational conventions for clarity. In particular, we distinguish p(x|a) from p(x,a), \nwriting: \n\uf0b7 p(x|a) with a bar when it is understood as a two-place operation defined from a \none-place one by the ratio rule, i.e. by putting p(x|a) \uf03d p(a\uf0d9x)\/p(a) when p(a) \n\uf03e 0, possibly with the extension that puts p(x|a) \uf03d 1 when p(a) \uf03d 0 (in which \ncase we call it the ratio\/unit rule).   \n\uf0b7 p(x,a) with a comma when taking p as an undefined (arbitrary or primitive) \ntwo-place operation defined over all or part of L\n2\n. \n \nCare will always be taken to specify the arity (number of places) of a function under \nconsideration, either by mentioning it explicitly, or by using place-markers as in p(\uf0d7), \np(\uf0d7|\uf0d7), p(\uf0d7,\uf0d7).  \n \nThroughout, Cn is the operation of classical consequence; we also write \uf0bb for the \nrelation of classical equivalence. \n \n \n2. Exploring the Critical Zone \n \nIn this section we weigh the significance of the critical zone. We begin by observing \nthat an analogous zone already arises on the qualitative level for AGM belief change, \nand explaining how this helps bring out the conceptual options underlying different \nsystems for two-place conditional probability. We then review those systems, \npresenting them in a modular way that makes manifest the intuitive rationales for \napparently technical choices.    \n \n2.1. A Leaf from the AGM Book  \n \nIt is instructive to compare the situation for probability change with that for \nqualitative belief change in the AGM tradition initiated in Alchourr\u00f3n, G\u00e4rdenfors \nand Makinson 1985.  \n \nThere, expansion is one thing, revision another. Let K be any belief set, i.e. a set of \npropositions closed under the operation Cn of classical consequence, i.e. K \uf03d Cn(K). \nThe expansion of K by a is defined simply by putting K\uf02ba \uf03d Cn(K\uf0c8{a}). However \nrevision is defined by putting K\uf02aa \uf03d Cn((K\uf02d\uf0d8a)\uf0c8{a}), where \uf02d is a suitable \ncontraction operation forming from K a subset that no longer implies the item \ncontracted (when it is not itself logically true), and satisfying certain regularity \nconditions.  \n5 \n \nWe thus have two different kinds of change side by side. Again, they differ in the \ncritical zone which, in this qualitative context, is the case where we modify the belief \nset K by a proposition a that is itself consistent but inconsistent with K. In this critical \nzone, expansion creates blow-out to the set of all propositions of the language, while \nrevision forces removal of items from the belief set. Outside the critical zone, the two \noperations coincide. This basic difference should not be obscured by talk of expansion \nbeing a special case of revision. That is just a sloppy way of saying that the values of \nthe two operations are the same outside the critical zone; neither operation is a special \ncase of the other.  \n \nThis basic conceptual difference reflects itself in the different formal properties of \nexpansion and revision. There are principles that hold for expansion but not for \nrevision, and conversely. In particular: \n \n\uf0b7 Expansion never loses anything from the initial belief set, i.e. K \uf0cd K\uf02ba. This is \nsometimes known as the principle of belief preservation. In contrast, revision \neliminates material from the belief set whenever the input a is in the critical \nzone. \n \n\uf0b7  When a is inconsistent with K, expansion gives us blow-out: both a,\uf0d8a \uf0ce \nK\uf02ba \uf03d Cn(K\uf0c8a) \uf03d L (the whole language). In contrast for revision, even when \na is inconsistent with K then, as long as a is itself consistent, so is K\uf02aa. This \nproperty of revision is known as the principle of (input) consistency \npreservation. \n \nThe pattern is replicated in the probabilistic context.  There too we are looking at two \ndifferent kinds of operation, which coincide outside but differ inside the critical zone \n\u2013 which in this context, we recall, is the case where a is consistent but p(a) \uf03d 0. One is \nexpansionary, the other is revisionary. \n \n\uf0b7 The expansionary operation is given by the ratio\/unit definition. It satisfies a \nprobabilistic analogue of qualitative belief preservation: p(x|a) \uf03d 1 whenever \np(x) \uf03d p(x|T) \uf03d 1. Expressed with left projections, pa(x) \uf03d 1 whenever pT(x) \uf03d 1. \nIn other words, conditionalizing never reduces the corresponding belief set: \nwriting B(p) for {x: p(x) \uf03d 1} we always have B(p) \uf0cd B(pa) \uf03d {x: pa(x) \uf03d 1} \uf03d \n{x: p(x|a) \uf03d 1}; see the appendix for detailed verification. No juice is lost. In \ncontrast, a revisionary operation would allow for loss of material from the \nassociated belief set.  \n \n\uf0b7 When p(a) \uf03d 0, the expansionary operation blows-out to the unit function \n(irrespective of a\u2019s own consistency): in that case pa(x) \uf03d p(x|a) \uf03d 1 for all x, \nso that B(pa) \uf03d L; see the appendix for a full verification. In contrast, a \nrevisionary conditional probability function would never give us the unit \nfunction when the condition a is itself consistent.   \n \nThese two kinds of conditionalization should not be thought of as competing for the \nposition of 'the correct one'. Like expansion and revision in the qualitative context, \nthey can work side by side, as different kinds of conditionalization. But how can the \nrevisionary conception best be expressed?  \n6 \n \nThere are two main approaches to the problem. One is to define a family of revision \noperations that take one-place probability functions to others. That is the path taken \nby G\u00e4rdenfors in a pioneering paper of 1986 (integrated into his book of 1988). The \nother approach is to define a family of two-place probability functions. That is the \ndirection followed in varying manners by Hosiasson-Lindenbaum 1940, R\u00e9nyi 1955, \n1970, 1970a, Popper 1959 and others in their wake.  \n \nAlthough different in appearance, the two approaches are intimately related \u2013 indeed \nat bottom the same \u2013 as hinted by G\u00e4rdenfors 1988 and observed explicitly by \nLindstr\u00f6m and Rabinowicz 1989. Here, we consider only the approach using two-\nplace probability functions. Our initial questions are: What are the essential \nconceptual differences between the differing axiom systems for two-place probability, \nand what are their advantages and disadvantages?  \n \n2.2. Bird\u2019s-Eye View of Available Systems \n \nThe usual presentations of axiom systems for two-place probability functions can be \nquite confusing. The systems are not always formulated in an intuitively evident \nmanner. They can also be difficult to compare due to differing choices of right \ndomain \u2013 sometimes the whole of L, sometimes the consistent propositions in L, \nsometimes an arbitrary subset of L lying between {x: p(x,T) \uf03e 0} and L itself. To \nfacilitate comparison and focus on essentials, we formulate all systems as functions \ndefined with unrestricted right domain and thus on the whole of L\n2\n. We also present \nthe systems in a modular way, that is, with a common basis and differing in what is \nadded to it.  \n \nThe leading idea is to exploit R\u00e9nyi's insight that for 'most' values of the right \nargument of the two-place function, the left projections should be proper one-place \nKolmogorov functions, adding that in the remaining cases they should be the unit \nfunction. We obtain modularity by making a different specification of what counts as \n'most' for each system.  \n \nWe begin with the basic van Fraassen system, which was formulated in the field-of-\nsets mode by van Fraassen 1976 and 1995. Expressed in the propositional mode for \ntwo-place functions p: L\n2\n \uf0ae [0,1], its axioms are the following three of right \nextensionality, left projection, and product:   \n(vF1)  p(x,a) \uf03d p(x,a\uf0a2)  whenever a \uf0bb a\uf0a2  \n(vF2)   pa is a one-place Kolmogorov probability function with pa(a) \uf03d 1 \n(vF3) p(x\uf0d9y,a) \uf03d p(x,a)\uf0d7p(y,a\uf0d9x) for all formulae a, x, y. \n \nIn (vF1), recall that we are using \uf0bb for classical equivalence. Note that (vF2), as \nformulated here, says that pa is a one-place Kolmogorov function, but it does not say \nwhether it is proper or improper (the unit function). Indeed, the axioms are consistent \nwith pa being the unit function for every a \uf0ce L.  \n \nDespite their modesty, the van Fraassen axioms have surprisingly many useful \nconsequences. The following were already noticed by van Fraassen 1976, 1995, Arl\u00f3 \n7 \nCosta 2001, Arl\u00f3 Costa and Parikh 2005. For the convenience of the reader, we recall \nbrief verifications in the appendix.   \n\uf0b7 Left extensionality: p(x,a) \uf03d p(x\uf0a2,a)  whenever x \uf0bb x\uf0a2.  \n\uf0b7 When y \uf0ce Cn(x) then p(x,a) \uf0a3 p(y,a).  \n\uf0b7 When p(\uf0d7) is defined as p(\uf0d7,T), then we have the ratio rule (though not its unit \nextension to the critical zone, i.e. the ratio\/unit rule).  \n\uf0b7 When a is a contradiction, then pa is the unit function.  \n\uf0b7 The set \uf044 of all a \uf0ce L such that pa is the unit function is an ideal. That is, it is \nclosed downwards (whenever a \uf0ce Cn(b) and a \uf0ce \uf044 then b \uf0ce \uf044) and also \nclosed under disjunction (whenever a,b \uf0ce \uf044 then a\uf0dab \uf0ce \uf044).  \n\uf0b7 pa is the unit function iff p(a,b) \uf03d 0 for all b such that pb is a proper \nKolmogorov function. \n \nVan Fraassen 1976, 1995 called the a \uf0ce L such that pa is a proper Kolmogorov \nfunction normal, and the remaining a \uf0ce L abnormal \u2013 of course, modulo the function \np(\uf0d7,\uf0d7). In that terminology, the set of all abnormal formulae form a non-empty ideal \ncontaining the contradictions, and a formula a is abnormal iff p(a,b) \uf03d 0 for all normal \nb. Apart from that, the van Fraassen axioms do not tell us much about which formulae \nare normal, which abnormal. \n \nPopper\u2019s system goes some way to filling the gap. It may be obtained by adding a \nsingle axiom, stating that pa is normal whenever p(a,T) \uf03e 0. \n \n(Positive): when p(a,T) \uf03e 0 then pa is a proper Kolmogorov function. \n \nThis still leaves unspecified the status of pa when a is in the critical zone, i.e. \nconsistent but with p(a,T) \uf03d 0. The other systems fill this gap in three different ways. \nCarnap\u2019s system does so trivially, by declaring that the zone is empty:  \n \n(Carnap) When a is consistent then p(a,T) \uf03e 0. \n \nThis is equivalent to what we would get by staying with one-place functions as \nprimitive, using the ratio\/unit definition to generate two-place functions, but declaring \nthat only contradictions can get the value 0. \n \nThe Unit system fills the gap almost as trivially, by adding instead an axiom saying \nthat any left projection from a point in the critical zone has constant value 1: \n \n(Unit)  When a is consistent but p(a,T) \uf03d 0, then pa is the unit function. \n \nThis is equivalent to what we would get by keeping one-place functions as primitive \nand using the ratio\/unit definition to generate two-place ones, without requiring that \nonly contradictions can get the value 0. \n \nHosiasson-Lindenbaum\u2019s system (briefly HL) regulates the critical zone by treating its \nelements just like consistent propositions outside the zone. It adds to the Popper \naxioms: \n8 \n \n(HL) When a is consistent but p(a,T) \uf03d 0, then pa is a proper Kolmogorov \nprobability function. \n \nThus, in terms of R\u00e9nyi's leading idea mentioned above, 'most values of the right \nargument' means, for an arbitrary p(\uf0d7,\uf0d7): \n \n\uf0b7 In the Hosiasson-Lindenbaum system: all propositions above or in the critical \nzone, \n \n\uf0b7 In the Unit system: all propositions above the critical zone but none of those in \nit, \n \n\uf0b7 In the Popper system: all propositions above the critical zone plus those in an \nunspecified subset (possibly empty) of it, \n \n\uf0b7 In Carnap\u2019s system: any of the first three, since the critical zone is declared \nempty. \n \nFor the van Fraassen system, the content of 'most values of the right argument' is a \nlittle more complex and we return to it in a moment. \n \nIt is easy to check that these axiom systems are equivalent to their usual presentations \n(see appendix), giving us the sets Carnap, Unit, HL, Popper, van Fraassen of \nfunctions. The modular arrangement makes it clear at a glance, from their very \nformulation, what the relations between the systems are. Specifically, we have \nCarnap \uf03d Unit\uf0c7HL \uf0cc Unit, HL \uf0cc Unit\uf0c8HL \uf0cc Popper \uf0cc Popper\uf0c8{1(\uf0d7,\uf0d7)} \uf03d van \nFraassen, where 1(\uf0d7,\uf0d7) is the unit two-place function putting p(x,a) \uf03d 1 for all a,x, and \n\uf0cc\uf020is proper inclusion. \n \nThe first four relations were established by Leblanc and Roeper (1989 theorems 4 and \n15, table 5, figure 15; also 1999 chapter 3 section 2), with however rather laborious \nverifications from the usual formulations of the systems, and without mentioning the \nhistorical role of Hosiasson-Lindenbaum as a key contributor. With the present \nmodular formulation, the inter-relations become trivial, except for the inclusion van \nFraassen \uf0cd Popper\uf0c8{1(\uf0d7,\uf0d7)} and the proper part of the inclusion Unit\uf0c8HL \uf0cc \nPopper. We comment on these in turn. \n \nThe inclusion van Fraassen \uf0cd Popper\uf0c8{1(\uf0d7,\uf0d7)} amounts to observing that Popper\u2019s \nsystem may be obtained from that of van Frassen by adding an axiom saying that p(\uf0d7,\uf0d7) \nis not the unit two-place function, i.e. that p(x,b) \uf0b9 1 for some x,b. This is known from \nthe work of van Fraassen 1976, 1995, but for convenience we give a brief verification \nin the appendix.  \n \nSince van Fraassen \uf03d Popper\uf0c8{1(\uf0d7,\uf0d7)}, the two classes differ by only a single \nfunction \u2013 the two-place unit function. The relation between the systems of Popper \nand van Fraassen is thus analogous to that between the original system of \nKolmogorov for proper one-place probability functions, and the extension obtained by \nadding the improper (unit) one-place function. Further, we can locate the van Fraassen \n9 \nsystem in the framework of R\u00e9nyi's intuitive idea of 'most values of the right \nargument' as follows:    \n \n\uf0b7 In the van Fraassen system, 'most' means: either none at all (in the case of the \ntwo-place unit function), or (for all other functions p(\uf0d7,\uf0d7)) all propositions \nabove the critical zone plus those in an unspecified subset of it (like Popper).   \n \nFor the proper part of the inclusion Unit\uf0c8HL \uf0cc Popper, we need a 'mixed' function, \nfailing axioms (Unit) and (HL) but satisfying the Popper axioms. Such a function was \nalready supplied by Leblanc and Roeper 1989 in the form of a rather enigmatic 64-\nelement table; in the appendix we equip the same example with an intuitive rule-based \nformulation. The relations between the classes are pictured in the diagram of Figure 1 \nbelow. \n \nThe reader may be surprised that we have not mentioned the axiomatic system of \nR\u00e9nyi 1955, also in his later books 1970, 1970a. This is not neglect: R\u00e9nyi's work is \nindeed capital, providing the leading idea on which most subsequent presentations \n(including the present one) are based. Rather, his system takes a form rather different \nfrom those above. He presents a scheme for a range of axiomatizations, with the right \ndomain of the function serving as a parameter. For a suitable choice of this parameter \n(and a little massage) we may obtain the axiomatization of Popper, and likewise of \nHosiasson-Lindenbaum. Thus, strictly speaking (and taking into account the \nchronology), Popper's axioms could be called the R\u00e9nyi\/Popper postulates. These \nhistorical matters are reviewed more fully in the appendix.   \n \nFigure 1. Hasse Diagram for Classes of Two-Place Probability Functions \n \n  \uf0b7   van Fraassen \uf03d Popper\uf0c8{1(\uf0d7,\uf0d7)} \n \n  \uf0b7   Popper \n \n  \uf0b7   Unit\uf0c8HL \n \n  Unit    \uf0b7           \uf0b7   HL (Hosiasson-Lindenbaum) \n \n  \uf0b7   Carnap \uf03d Unit\uf0c7HL \n \n \n \n3. Comparative Attractions \n \nAre there any reasons for preferring one of these systems to another? From our \ndiscussion so far, there are three serious contenders going beyond the ratio\/unit \naccount, namely the systems of Hosiasson-Lindenbaum, Popper, and van Fraassen. In \nthis section we discuss possible grounds for preferring one to the other, coming to the \nconclusion that the choice is not a matter of correctness but of policy, particularly \nregarding two questions. The first is conceptual: how revisionary do we want our \nconditional probability to be? This separates Hosiasson-Lindenbaum on the one hand \nfrom Popper and van Fraassen on the other. The second question is more technical: do \nwe want the class of functions to be closed under Bayesian update? Its answer groups \n10 \nHosiasson-Lindenbaum and Popper in contrast with van Fraassen. Despite these \ndifferences, there is an overall conceptual unity: we show that the two broader classes \nof functions may be transformed into the narrowest one by passing from the classical \nto suitably chosen supraclasical background consequence relations.   \n \n3.1. Hosiasson-Lindenbaum vs Popper vs van Fraassen \n \nThe Hosiasson-Lindenbaum system is not just revisionary \u2013 it is radically so, \nsatisfying without reserve the probabilistic counterpart of consistency preservation. \nThat is, for every proposition a, if it is consistent then pa is a proper Kolmogorov \nfunction. The only values of the right argument that project to the unit function are the \ninconsistent ones.  \n \nOn the other hand Popper\u2019s system is more compromising. Its spirit was expressed by \nLeblanc 1989, who asked: \u201cCan\u2019t there be some statement of L that is 'utterly \nunbelievable', so unbelievable indeed that \u2013 should you believe it \u2013 you\u2019d believe \nanything, and yet is not truth-functionally false?\u201d. It is \u2018variably revisionary\u2019, in that it \nleaves unspecified the extent to which a function satisfying the axioms is \nexpansionary, and how far it is revisionary. As one extremal case it covers functions \np(\uf0d7,\uf0d7) that are purely expansionary, i.e. pa blows out to the unit function for every a in \nthe critical zone as well as for inconsistent a. These are the functions satisfying the \nUnit axiom above. At the other extreme it covers the Hosiasson-Lindenbaum \nfunctions, where pa never blows out in the critical zone. In between, it covers many \n\u2018mixed\u2019 functions, where for certain a,b in the critical zone pb is the unit function \nwhile pa is a proper Kolmogorov function. Van Fraassen's system is also variably \nrevisionary, but covers just one more function than does Popper's: the two-place unit \nfunction p(\uf0d7,\uf0d7) \uf03d\uf0201(\uf0d7,\uf0d7), for which pa is the one-place unit function for any choice of a \nwhatsoever in the right domain.  \n \nThus, if we a looking for a notion of conditional probability that is as revisionary as \npossible, we will naturally turn to the  Hosiasson-Lindenbaum functions; if we wish to \nallow variation in the extent to which it is revisionary, we will favour the Popper or \nvan Fraassen functions. \n \nOn a more technical level, of the three classes of functions, that of van Fraassen is the \nonly one that is closed under Bayesian update. The point is very similar to that made \nby Harper 1975 regarding Carnap's regularity condition (see section 1.1 above), and \nmay be expressed as follows.  \n \nAs well as passing from an unconditional to a conditional function, we often need to \nstrengthen the condition of an already conditional one. It is useful to express this as an \noperation taking a two-place function p(\uf0d7,\uf0d7) to another two-place function p\uf0d9b(\uf0d7,\uf0d7) by \nthe rule p\uf0d9b(x,a) \uf03d p(x,a\uf0d9b). This is a familiar move in the Bayesian tradition, where it \nis called update. But the operation breaks the boundaries of the class of Hosiasson-\nLindenbaum functions. It may happen that while a is consistent, a\uf0d9b is not, in which \ncase for any function p(\uf0d7,\uf0d7) satisfying the Hosiasson-Lindenbaum axioms, (p\uf0d9b)a is the \nunit function despite the consistency of a, so that p\uf0d9b does not satisfy axiom (HL).  \n \nIndeed, the update operation also breaks the boundaries of the class of Popper \nfunctions. To see this, consider any Popper function p(\uf0d7,\uf0d7) , and let a be an inconsistent \n11 \nproposition. Then p\uf0d9a(a,T) \uf03d p(a,a) \uf03d 1 \uf03e 0, while for all values of x we have (p\uf0d9a)a(x) \n\uf03d p\uf0d9a(x,a) \uf03d p(x,a) \uf03d 1 since a is inconsistent, so that (p\uf0d9a)a is the unit function. These \ntwo facts together contradict the distinctive Popper axiom (Positive).  \n \nThe only way to keep our class of functions closed under Bayesian update is to \ngeneralize to the class of all van Fraassen functions. Thus, if we regard closure under \nupdate as important or convenient, we will thus naturally gravitate towards the van \nFraassen system. On the other hand, it may be suggested that from the point of view \nof a revisionary concept of conditional probability, Bayesian update as defined above \nis quite inappropriate, suitable only for an expansionary notion with conditional \nprobability given by the ratio or ratio\/unit definition. This is discussed further in the \nappendix. \n \nOn the other hand, the gap between the three classes of function may be less \nsignificant than appears at first sight, for every van Fraassen function may be \ntransformed into a Hosiasson-Lindenbaum one by suitably expanding the underlying \nconsequence relation.   \n \nTo see this, consider any two-place function p(\uf0d7,\uf0d7) satisfying the van Fraassen axioms. \nWe have already noted (section 2.2) that the set \uf044 of all a \uf0ce L such that pa is the unit \nfunction is a non-empty ideal. That is, it contains all contradictions, whenever a \uf0ce \nCn(b) and a \uf0ce \uf044 then b \uf0ce \uf044, and whenever a,b \uf0ce \uf044 then a\uf0dab \uf0ce \uf044. Hence the set \uf0d1 \uf03d \n{a: \uf0d8a \uf0ce \uf044} is a filter, i.e. whenever b \uf0ce Cn(a) and a \uf0ce \uf0d1 then b \uf0ce \uf0d1, and whenever \na,b \uf0ce \uf0d1 then a\uf0d9b \uf0ce \uf0d1). From this in turn it follows that if we define a supraclassical \nconsequence operation Cn\uf0a2 by putting Cn\uf0a2(A) \uf03d Cn(A\uf0c8\uf0d1) we have: \uf05e \uf0ce Cn\uf0a2(a) iff \uf05e \n\uf0ce Cn({a}\uf0c8\uf0d1) iff \uf0d8a \uf0ce Cn(\uf0d1) \uf03d \uf0d1 iff a \uf0ce \uf044 iff pa is the unit function. That is, pa is \nthe unit function iff a is inconsistent modulo Cn\uf0a2. Using this, it is not difficult to show \nthat if p(\uf0d7,\uf0d7) is a van Fraassen function modulo Cn then it is a Hosiasson-Lindenbaum \nfunction modulo Cn\uf0a2.  \n \nIn brief: any van Fraassen function (modulo classical Cn) is a Hosiasson-Lindenbaum \nfunction modulo a suitably defined supraclassical consequence operation Cn\uf0a2, with the \nabnormal elements becoming Cn\uf0a2-inconsistent. From this point of view, the \ndifferences between the three classes of functions may be seen as a matter of the \nbackground logic rather than one of probability. Of course, it should be remembered \nthat, unlike classical consequence, such supraclassical consequence relations are not \nclosed under substitution of arbitrary formulae for elementary letters (Makinson \n2005), so we are using a rather different kind of logic.   \n \n3.2. Does it Ever Make a Difference? \n \nCan the choice of kind of conditional probability ever make a substantive difference \nto an application? One example where it does is the theory of \u2018cores\u2019, set out by Arl\u00f3 \nCosta 2001 and Arl\u00f3 Costa & Parikh 2005 building on ideas of van Fraassen 1995. \n \nCores were introduced to give a probabilistic account of an intuitive distinction \nbetween a broader class of \u2018plain\u2019 beliefs and a narrower one of \u2018full\u2019 beliefs, with the \nformal desiderata that the classes are distinct, non-trival, and both closed under \nclassical consequence (and hence under conjunction).  \n \n12 \nTranslating from the field-of-sets mode used by the authors mentioned, a core for a \nPopper function p: L\n2\uf0ae [0,1] is defined to be a formula c such that (1) c is normal, \nthat is, the left projection pc of p from the right value c is a proper Kolmogorov \nfunction, and (2) for all formulae b inconsistent with c we have p(b, c\n\uf02b\uf0dab) \uf03d 0 for \nevery consistent c\n\uf02b\n logically implying c.  \n \nPlain beliefs modulo p are then identified with those formulae logically implied by at \nleast one core, while full beliefs are those implied by every core. The authors show \nthat in the finite case, for any Popper function p: L\n2\uf0ae [0,1] there is a unique strongest \ncore c0 and a unique weakest one c1; so that in that case plain beliefs are those \nformulae logically implied by c0, while full beliefs are those implied by c1. Indeed, in \nthe field-of-sets mode we have the same whenever the underlying set is countable and \nwe assume countable additivity. \n  \nHowever, for plain beliefs so defined, there is a difficulty. In the finite case they turn \nout to be just the formulae x with p(x,T) \uf03d 1. In the field-of-sets mode, and assuming \ncountable additivity, this also holds whenever the underlying set is countable. This is \ngiven as the 'coincidence lemma' of Arl\u00f3 Costa 2001 page 578, and is also an \nimmediate consequence of Lemma 3.1 of Arl\u00f3 Costa and Parikh 2005. Thus in these \ncontexts, the definition of plain belief in terms of cores gives us nothing new, no \nmatter how we choose our Popper function. Nevertheless, as Parikh has urged \n(personal communication), when we are working in the uncountable case, or in the \ncountable one but without countable additivity, we may not have the same collapse.   \n \nIt does not seem to have been noticed in the literature that for full beliefs as defined \nvia cores, the outcome depends critically on whether or not we are working with a \nHosiasson-Lindenbaum function. If we are, it turns out that the full beliefs become \njust the tautologies \u2013 which is hardly what was wanted. To show this, we need only \nverify that T is itself a core. Using the definition above, it suffices to check that p(\uf05e,T) \n\uf03d 0 (which is immediate) and that whenever b is inconsistent while a is consistent  \nthen p(b,a\uf0dab) \uf03d 0. But by the inconsistency of b we have p(b,a\uf0dab) \uf03d p(b,a); and since \np is a Hosiasson-Lindenbaum function, its left projection pa from consistent a is a \nproper Kolmogorov function, so by the inconsistency of b again, 0 \uf03d pa(b) \uf03d p(b,a). \nNote that this argument does not depend on any cardinality assumptions.  \n \nThus the use of cores for defining a formal notion of full belief is not robust between \nthe two notions of two-place probability, Hosiasson-Lindenbaum and Popper. The \nconstruction gives a non-trivial account of full belief only when there is at least one \nconsistent a such that pa is the unit function. Some might take this as a reason for \npreferring Popper to Hosiasson-Lindenbaum functions; others might take it as casting \ndoubt on the value of the above definition of a core. \n     \n4. Back and Forth between Belief Revision and Conditional Probability \n \n4.1. Correspondence between AGM and HL  \n \nWe have been using AGM belief revision to explain why we should take seriously a \nrevisionary reading of two-place probability functions and to help throw light on the \noptions available, notably those of Hosiasson-Lindenbaum, Popper, and van Fraassen.  \n \n13 \nWhich of these three accounts of conditional probability corresponds formally to \nAGM belief revision? From the discussion so far, one would guess that it is the HL \nsystem, and indeed that turns out to be the case. There is a natural map (due \nessentially to Lindstr\u00f6m and Rabinowicz 1989, building on G\u00e4rdenfors 1988 chapter \n5) from the family of all HL conditional probability functions into the family of all \nAGM revision operations on consistent belief sets. The definition is straightforward. \nGiven an HL function p(\uf0d7,\uf0d7) we define a belief set K \uf03d B(p) to be the 'top' of p, i.e. \nB(p) \uf03d {x: p(x,T) \uf03d 1} and the revision operation \uf02ap: {K}XL\uf0ae2\nL\n or more briefly\uf02ap: \nL\uf0ae2L by putting \uf02ap(a) \uf03d {x: p(x,a) \uf03d 1}. It is not difficult to show that this map has \nthe stated properties and that, moreover, it is surjective in the finite case \u2013 though of \ncourse far from injective). Details and verifications are given in the appendix.  \n \nThe qualitative AGM axioms may thus be seen as reflections of the quantitative ones \nof Hosiasson-Lindenbaum. To this extent, the 1985 AGM postulates may be said to \ngo back to 1940! \n \nThe existence of such a map prompts a number of further questions. To what kinds of \nqualitative belief revision do the systems of Popper and of van Fraassen correspond? \nConversely, what kinds of conditional probability correspond to variant procedures \nfor belief revision, such as the 'screened revision' of Makinson 1997? Are there any \nfurther interesting notions of conditional probability with a revisionary spirit that \nmight have qualitative counterparts?  \n \nTo get a qualitative analogue of Popper (while keeping classical consequence as our \nbackground consequence relation) we need to abandon or weaken the AGM postulate \n(K\uf02a5): K\uf02aa is consistent whenever a is consistent. For van Fraassen, we also need to \nadd the revision function that makes K\uf02aa inconsistent for every a, and, as a result,  \nqualify postulate (K\uf02a\uf033): K\uf02aa \uf0cd Cn(K\uf0c8{a}). For further discussion of these matters, \nsee Arl\u00f3-Costa 2001.   \n \n4.2. From Screened Revision to Screened Conditional Probability \n \nScreened revision is a variant form of AGM belief revision. Its basic idea is to see the \noperation as made up of two steps: a pre-processing step possibly followed by \napplication of an AGM revision. The pre-processor decides the question of whether to \nrevise, and this is done by checking whether the proposed input is consistent with a \ncentral part of the belief set under consideration, regarded as a protected subset. If \nthey are mutually inconsistent, the belief set remains unchanged; otherwise we apply \nan AGM revision in a manner that protects the privileged material. Clearly, such a \ncomposite process will not satisfy all the postulates of AGM revision: for example, \nthe postulate of success, a \uf0ce K\uf02aa, will fail in the first case. For more details, see \nMakinson 1997. \n \nWhat would a probabilistic analogue of this look like? Roughly speaking, using the \nlanguage of Leblanc cited in section 3.1, when a is too unbelievable to take seriously \nas a condition, we put the probability of x on condition a to be just the unconditioned \nprobability of x rather than 1. In other words, for such a we require that p(\uf0d7,a) \uf03d p(\uf0d7,T) \nrather than p(\uf0d7,a) \uf03d 1(\uf0d7,a). At the same time, we protect the negation of a, by requiring \nthat p(\uf0d8a,b) \uf03d 1 \uf03d p(\uf0d8a,T) for all b. Thus, on the semantic level the functions are like \nthose of Popper except that pT(\uf0d7) takes the place of 1(\uf0d7) as the left projection pa of \n14 \nabnormal a, and negations of 'unbelievable' elements continue to get the value 1 under \nall conditions. \n \nThis forces modification of the axioms. In particular, the axiom (vF2) of left \nprojection must be weakened: we no longer always have pa(a) \uf03d 1 since when a is \nunbelievable pa(a) \uf03d pT(a) \uf03d p(a,T) \uf03d 0. In another respect, however, (vF2) can be \nstrengthened: we can require that the left projection from any point is always a proper \nKolmogorov function, as we no longer have any use for the unit function. The product \naxiom (vF3) must also be weakened. To show this, consider any inconsistent a. \nUnrestricted use of the product axiom would give us that for all x: pT(x) \uf03d pa(x) \uf03d \np(x,a) \uf03d p(x\uf0d9x,a) \uf03d p(x,a)\uf0d7p(x,a\uf0d9x) \uf03d p(x,a)\uf0d7p(x,a) \uf03d pa(x)\uf0d7pa(x) \uf03d pT(x)\uf0d7pT(x); so that \nfor any x, pT(x) is either 0 or 1 \u2013 which is quite undesirable behaviour. The problem of \naxiomatizing the class of such 'screened two-place probability functions' appears to be \nopen.   \n \n4.3. From Hyper-revisionary Conditionalization to Hyper-revisionary Revision \n \nAs is well known, for any van Fraassen function p(\uf0d7,\uf0d7) and a \uf0ce L, if p(a,T) \uf03e 0 then \np(x,a) is determined by a natural relativization of the ratio rule: p(x,a) \uf03d \np(a\uf0d9x,T)\/p(a,T). Indeed, this equality is almost immediate: the product axiom gives us \np(a\uf0d9x,T) \uf03d p(a,T)\uf0d7p(x,a\uf0d9T) \uf03d p(a,T)\uf0d7p(x,a) by right extensionality, permitting division \nwhen p(a,T) \uf03e 0.  \n \nAs remarked by Jonny Blamey (personal communication), this might be seen as too \nconservative. For if a has a very low positive probability \u2013 say, to fix ideas, 0 \uf03c p(a,T) \n\uf03c 0.01 \u2013 then a surprise occurrence of a might sometimes lead us to question whether \nthe function p(\uf0d7,\uf0d7) was really right to give p(a,T) such a small value. We should \nperhaps move to a function q(\uf0d7,\uf0d7) which makes the truth of a less unexpected, i.e. puts \nq(a,T) well above p(a,T); and for such a q the value of q(x,a) will be q(a\uf0d9x,T)\/q(a,T), \nwhich may be quite different from p(a\uf0d9x,T)\/p(a,T).  \n \nPhilosophically, this 'hyper-revisionary' proposal drives an interesting wedge between \ntwo different ways of adopting a condition a. On the one hand, we may accept it \nbecause its truth has been revealed to us; on the other hand, we may entertain it to \nexplore its consequences. The argument above suggests grounds for sometimes \nabandoning p(\uf0d7,\uf0d7) when we are confronted with the truth of a proposition a for which p \ngave a very low value; but it does not suggest doing so when we merely entertain the \ntruth of a to determine what effect it has on our probabilities. The hyper-revisionary \nproposal thus has the merit of providing formal expression to a difference between \naccepting and supposing a condition of low probability, which tends to be neglected \nby the usual treatments of conditional probability.    \n \nOf course, the proposal has a practical inconvenience. In applications, there can be no \nuniversally fixed cut-off point, such as 0.01, at which we should revise the probability \nfunction before applying the relativized ratio rule. Where to draw the line would be a \nmatter of context, purposes and subject matter, balanced in an informal judgement. \nThis situation is reminiscent of that arising in the theory of error statistics as \ndeveloped by Fisher, Neyman and Pearson, where one considers the choice between \nrival statistical hypotheses under evidence that is logically consistent with each of \nthem, but highly improbable given one while not so improbable given the other. \n15 \nIndeed, there may be deep connections between hyper-revisionary conditional \nprobability and error statistics, but we do not attempt to explore them in the present \npaper.    \n \nWhat would a qualitative analogue of such hyper-revisionary conditionalization look \nlike? It would allow that even when input a is logically consistent with belief set K, \nwe should not always take K\uf02aa to be Cn(K\uf0c8{a}). As well as adding in a, we should \nperhaps be contracting K, for despite the logical consistency of the two, a may be so \nimplausible in the eyes of K that the revelation of the truth of the former may lead us \nto an 'agonizing reappraisal' of the latter.  \n \nThis, of course, is counter to one of the basic postulates of AGM belief revision, K\uf02a4, \nwhich puts K\uf02aa \uf03d Cn(K\uf0c8{a}) in every case that a is consistent with K, where we read \n'consistency' as consistency under Cn, which in turn is taken to be classical \nconsequence. Under this reading, AGM does not admit any conflict less than classical \nconsistency as forcing contraction, and so K\uf02a4 must be modified for hyper-\nrevisionary belief change. The exact adjustments required do not appear to have been \nstudied. \n \nThese examples \u2013 from screened revision to a counterpart for conditionalization, and \nfrom hyper-revisionary conditionalization to a corresponding kind of revision \u2013 \npresumably do not exhaust the possibilities for going back and forth. As a rule of \nthumb, given an interesting variant of AGM qualitative belief revision we should \nexpect a corresponding variant of Hosiasson-Lindenbaum conditional probability, and \nvice versa.   \n \n5. Proto-probability   \n \nIn 1996, Hawthorne investigated rules of uncertain inference which, while qualitative, \nmay be given a probabilistic justification, using them to form an axiom system that he \ncalled Q. All its axioms are in a natural sense probabilistically sound, although the \nconverse has not yet been settled. The question arises: do we need the full force of the \naxioms of probability in order to justify the rules of Q, or can it be done with weaker \naxioms? In this section we observe that considerable weakening is possible. We need \nonly certain modest order-theoretic conditions from among those available in the \nsystem of conditional probability of van Fraassen, already the weakest of those \npresented in section 2.2. \n \n5.1. Hawthorne's system Q of Uncertain Inference \n \nFirst, we recall Hawthorne\u2019s axioms. They concern consequence relations |~ (in \nwords: snake) between formulae of classical propositional logic. There are six Horn \nrules O1\u2013O6 defining a system O, and one 'almost Horn' rule of 'negation rationality' \n(NR) whose addition gives Q. As usual, Cn is classical consequence and \uf0bb is classical \nequivalence:  \n \nO1. a |~ a     (reflexivity ) \nO2. When a |~ x and y \uf0ce Cn(x), then a |~ y (RW: right weakening) \nO3. When a |~ x  and a \uf0bb b, then b |~ x (LCE: left classical equivalence) \n16 \nO4. When a |~ x\uf0d9y, then a\uf0d9x |~ y  (VCM: very cautious monotony) \nO5. When a |~ x, b |~ x and \uf0d8b \uf0ce Cn(a), then a\uf0dab |~ x  (XOR: exclusive \uf0da\uf02b) \nO6. When a |~ x and a\uf0d9\uf0d8y |~ y, then a |~ x\uf0d9y  (WAND: weak \uf0d9\uf02b). \nNR. When a\uf0dab |~ x and \uf0d8b \uf0ce Cn(a), then either a |~ x or b |~ x. \n \nAs Hawthorne showed, the system Q is probabilistically sound in the sense that for \nany probability function p(\uf0d7,\uf0d7) satisfying van Fraassen's postulates and 'threshold' t \uf0ce \n[0,1], if we define a relation by putting a |~pt x iff p(x,a) \uf0b3 t, then |~pt satisfies all the \nrules of Q. For further information on systems O and Q see Hawthorne 1996, \nHawthorne and Makinson 2007, Paris and Simmonds 2009, Simmonds 2010, \nMakinson (to appear). In particular, Paris and Simmonds have shown that O (i.e. the \nabove without NR) is not complete for the class of probabilistically sound Horn rules. \n \n5.2. Proto-probability Functions \n \nOur question is: how much probability is really needed for the job? If we simply drop \none of the van Fraassen axioms, then we admit functions that do not validate \nHawthorne's system Q. So, rather than delete, we abstract. It turns out that the \nvalidation can be effected by any function into an arbitrary complete preorder with \ngreatest and least elements, satisfying certain very modest conditions in which no \narithmetical operations appear.  \n \nLet D be any non-empty set equipped with a relation \uf0a3 that is transitive and complete \n(d \uf0a3 e or e \uf0a3 d, for all d,e \uf0ce D) with a greatest element 1D and a distinct least element \n0D. Note that we do not require that \uf0a3\uf020is anti-symmetric (and thus linear), although of \ncourse it may be so. A proto-probability function into D is any function p: L\n2\uf0aeD \nsatisfying the following six conditions:  \nP1. p(a,a) \uf03d 1D  \nP2. p(x,a) \uf0a3 p(y,a) whenever y \uf0ce Cn(x) \nP3. p(x,a) \uf03d p(x,b) whenever a \uf0bb b  \nP4. p(x\uf0d9y,a) \uf0a3 p(y,a\uf0d9x) \nP5. p(x,a) \uf0a3 p(x,a\uf0dab) \uf0a3 p(x,b) whenever p(x,a) \uf0a3 p(x,b) and \uf0d8b \uf0ce Cn(a)  \nP6. p(x,a) \uf03d p(x\uf0d9y,a) whenever p(y,a\uf0d9\uf0d8y) \uf0b9 0D.  \n \nWe call condition (P5) the principle of disjunctive interpolation. The part p(x,a\uf0dab) \uf0a3 \np(x,b) (under the stated conditions) is essentially the same as a principle of \n\u2018alternative presumption\u2019 of Koopman 1940, 1940a. The condition as a whole is \nessentially the finite case of a rule known as conglomerability, due to  Seidenfeld et al \n1998. It may also be seen as extracting the qualitative content of a principle for \nquantitative conditional probability that was articulated by G\u00e4rdenfors 1988. The \nappendix details all three connections.  \n \nIf we take any proto-probability function p(\uf0d7,\uf0d7) and t \uf0ce D, and define a relation by \nputting a |~pt x iff p(x,a) \uf0b3 t, then |~pt satisfies all the rules of Q. This fact may be seen \nas a soundness theorem for Q with respect to proto-probability functions. Indeed, each \ncondition (Oi) follows directly from its counterpart (Pi), with (NR) also following \n17 \nfrom (P5). The completeness of the relation \uf0a3 over D is needed to derive the two \npostulates of Q dealing with disjunction, i.e. NR and O5 (alias XOR). The \nverifications are trivial, but given the novelty of the notion of proto-probability, we \nprovide them in the appendix.  \n \nIt is also easy to check (see appendix) that when D is set at [0,1] and \uf0a3 as usual, then \nthe axioms for proto-probability functions follow from those of van Fraassen, a \nfortiori from the stronger systems discussed in section 2.2. In fact, they are \nconsiderably weaker. Informally, it is clear that the left projection and product axioms \nof van Fraassen do not hold for all proto-probability functions since our conditions for \nthe latter make no use of addition (which is implicit in the left projection axiom), nor \nof multiplication (explicit in the product axiom).  \n \nFor a specific example of a proto-probability function that is not a van Fraassen one, \ntake p: L\n2\uf0ae{0,1} to be the characteristic function of the classical consequence \nrelation, i.e. put p(x,a) \uf03d 1 when x \uf0ce Cn(a), otherwise p(x,a) \uf03d 0. Clearly, this satisfies \nconditions P1 through P6, but it fails (vF2) since p(x\uf0da\uf0d8x,T) \uf03d 1 while p(x,T) \uf03d 0 \uf03d \np(\uf0d8x,T) for contingent formulae x, so that pT is not a Kolmogorov function.  \n \nIn summary, the proto-probability functions are defined by purely order-theoretic \nconditions that are strictly weaker than the main systems for conditional probability as \ndescribed in section 2 above. Yet they are strong enough to support the rules defining \nHawthorne\u2019s system Q of probabilistic inference. In fact, we also have a \nrepresentation theorem for Q in terms of proto-probability functions: given any \nconsequence relation |~ satisfying the conditions of system Q, there is a proto-\nprobability function p: L\n2\uf0aeD with |~ \uf03d\uf020\uf07c\uf07ept. The proof is quite trivial. Choose D \n\uf03d\uf020{0,1} and \uf0a3 as usual over it, take p: L2\uf0aeD to be the characteristic function of  |~ \n(i.e. p(x,a) \uf03d\uf0201 when  a |~ x, else p(x,a) \uf03d\uf020\uf030), and finally put t \uf03d\uf0201. It is straightforward \nto check that p is a proto-probability function, and we have immediately that |~ \uf03d\uf020\uf07c\uf07ep1 \nby the equivalences a |~ x iff p(x,a) \uf03d\uf0201 iff a |~ p1 x. \n \nFrom the soundness and representation systems for the system Q we immediately \nhave a representation theorem for proto-probability functions themselves. For any \nproto-probability function q: L\n2\uf0aeE and any t \uf0ce E, there is a proto-probability \nfunction p: L\n2\uf0ae{0,1} with |~qt \uf03d\uf020\uf07c\uf07ep1. This may also be verified directly without \npassing through the logic Q: given q: L\n2\uf0aeE and t \uf0ce E, simply put p(x,a) \uf03d\uf0201 when \nq(x,a) \uf0b3 t and p(x,a) \uf03d\uf0200 otherwise. \n \nRepresentation theorems normally imply associated completeness theorems, though \nnot always conversely (see Makinson 2007 for a general discussion). This is no \nexception. Consider any rule \u2013 whether Horn or allowing negative premises and\/or \nconclusion \u2013 with premises \u00b1i(ai |~ xi) and conclusion \u00b1(b |~ y), where \u00b1 is affirmation \nor denial. Suppose that it fails for some consequence relation |~ satisfying all \npostulates of Q. Then there is a proto-probability function p (namely the one that \nrepresents |~) such that each p(xi,ai) is correspondingly 1 or 0 while p(y,b) is \ncontrariwise 0 or 1.  \n \nClosely related to the results above is a closure property of the class of all proto-\nprobability functions. Let D, E be any non-empty sets equipped respectively with \ntransitive complete relations \uf0a3\uf02c\uf020\uf0a3\uf0a2\uf020, with greatest and least elements 1D, 0D, 1E, 0E. \n18 \nConsider any proto-probability function p: L\n2\uf0aeD and order-preserving function h: \nD\uf0ae E with h(1D) \uf03d 1E and  h(0D) \uf03d 0E. Then the composition p\uf0a2: L\n2\uf0aeE defined by \nputting p\uf0a2(x,a) \uf03d\uf020h(p\uf028x,a\uf029) is also a proto-probability function. In particular, this is the \ncase when we choose E \uf03d\uf020\uf07b\uf030\uf02c\uf031\uf07d\uf02c\uf020t \uf0b9 0D in D, and h(d) \uf03d 1\uf020iff d \uf0b3 t else h(d) \uf03d 0. The \nverification is straightforward; the only condition that needs attention is P5, which we \ngive in the appendix.  \n \nIn contrast, however, the class of all proto-probability functions is not closed under \ndirect products, since the intersection of two complete relations over a set is not in \ngeneral complete.   \n \n5.3. Comparison with Plausibility Measures, and Further Examples  \n \nHow do proto-probability functions compare with the well-known 'conditional \nplausibility measures' studied by Halpern in a number of papers, e.g. Halpern 2001? A \nshort answer is that while their conditions on the relation \uf0a3 are incomparable,  as are \nthe domains of the functions, Halpern's conditions are, roughly speaking, considerably \nmore general; a more precise comparison is given in the appendix. This is not \nsurprising, for the motivations are not the same. We are asking how much probability \nis needed to validate the properties (as given by system Q) of probabilistically sound \nqualitative consequence relations; Halpern is looking for a 'most general' kind of \nconditional probability that includes all those known in the literature.      \n \nWe note three further kinds of function that are simultaneously conditional \nplausibility measures and proto-probability functions, namely the 'conditional ranking \nfunctions' of Spohn e.g. 1986, 2009, 'conditional possibility functions' of Dubois and \nPrade e.g. 1988, and 'conditional quasi-measures' of Weydert 1994. We simply state \nsome basic facts, omitting the verifications.  \n \n\uf0b7 Let \uf06b: L\uf0aeN\uf0c8{\uf0a5\uf07d be a 'negative ranking function' in the sense of Spohn \n(expressed in the propositional rather than his field of sets mode) on the \nlanguage L into the natural numbers together with \uf0a5. Consider Spohn's \nassociated 'conditional ranking function' defined by putting \uf06b(x|a) \uf03d \n\uf06b(a\uf0d9x)\uf02d\uf06b(a). Then if we convert the order of the ranking (so that 0 becomes \nthe greatest element and \uf0a5 the least), the function \uf06b(\uf0d7|\uf0d7) satisfies the conditions \n(P1) through (P6) for proto-probability functions (without needing the \nhypothesis that \uf0d8b \uf0ce Cn(a) for P5).  \n \n\uf0b7 Let \uf070: L\uf0ae[0,1] be a 'possibility measure' in the sense of  Dubois and Prade \n(again in the propositional rather than their field-of-sets mode),  i.e. \uf070(a) \n\uf03d\uf020\uf070(b) when a,b are classically equivalent, \uf070(a) \uf03d\uf020\uf030\uf020when a is a contradiction, \n\uf070(a) \uf03d\uf020\uf031\uf020when a is a tautology, and \uf070(a\uf0dab) \uf03d\uf020max{\uf070(a),\uf070(b)}.\uf020Consider the \nassociated 'conditional possibility function' defined by Dubois and Prade 1988 \npage 206, which sets \uf070(x|a) \uf03d \uf070(a\uf0d9x)\/\uf070(a), except when \uf070(a) \uf03d\uf020\uf030 as in the ratio \ndefinition from Kolmogorov probabilities. Then \uf070(\uf0d7|\uf0d7) (without conversion of \nthe order) satisfies conditions (P1)\u2013(P6).  \n \n\uf0b7 Weydert 1994 abstracted the common algebraic features of the above two \nexamples in his 'quasi-measure spaces', and the resulting 'conditional quasi-\n19 \nmeasures' are also both conditional plausibility measures and proto-probability \nfunctions.     \n \nAppendix \n \nThis appendix runs parallel to the main text. It contains most of the formal definitions \nand verifications, as well as references and historical remarks supporting the main \ntext. \n  \nFor Section 1: Why Go Beyond the Ratio Rule? \n \nThe Kolmogorov axioms \n \nThere are several modes for presenting the Kolmogorov axioms for one-place \nprobability functions, according to what we take as their domain. It may be a field of \nsets (most common in mathematics and applications), or equivalently a Boolean \nalgebra (the preferred way of algebraists), or the set of all formulae of a propositional \nlanguage (whose quotient structure under classical equivalence will be a free Boolean \nalgebra). In this paper we work in the propositional mode, with the following \nformulation (Makinson 2005) of the postulates.  \n \nA (one-place) proper Kolmogorov function p: L\uf0ae[0,1] is any function defined on the \nset L of formulae of a language closed under the Boolean connectives, into the real \nnumbers from 0 to 1, such that: \n(K1)  p(x) = 1 for some formula x  \n(K2) p(x) \uf0a3 p(y) whenever y \uf0ce Cn(x) \n(K3) p(x\uf0day) = p(x)\uf02bp(y) whenever \uf0d8y \uf0ce Cn(x). \n \nCn is classical consequence; we also write \uf0bb for classical equivalence. Thus postulate \n(K1) tells us that 1 is in that range of p; (K2) says that p(x) \uf0a3 p(y) whenever x \nclassically implies y; (K3), called the rule of finite additivity, tells us that p(x\uf0day) = \np(x)\uf02bp(y) whenever x is inconsistent with y. It is sometimes extended so as to \nconstrain the probability of countable unions (most easily expressed in the field of \nsets mode).  \n \nAs remarked in the text and observed by many authors, e.g. Harper 1975 and \nsubsequently G\u00e4rdenfors 1988, Leblanc and Roeper 1989, in comparative contexts it \nis convenient to regard the unit function (i.e. the function p that puts p(x) \uf03d 1 for every \nx \uf0ce L) as also being a Kolmogorov function, and we will follow this convention. It \ncan be formalized by the simple expedient of defining a Kolmogorov function as one \nthat is either a proper Kolmogorov function (i.e. satisfies the above postulates) or is \nthe unit function. Equivalently, one could weaken axiom (K3) by putting it under the \nproviso that p is not the unit function. We refer to the unit function as the improper \nKolmogorov probability function.  \n \nThe ratio rule \n \nThe ratio rule for conditional probability uses an arbitrary Kolmogorov function p: \nL\uf0ae[0,1] to define a two-place function, conventionally written as p(x|a) and read as \n20 \n'the probability of x given a', defined on Lx{a \uf0ce L: p(a) \uf03e 0} by the rule: p(x|a) \uf03d \np(a\uf0d9x)\/p(a) when p(a) \uf03e 0 and otherwise undefined.  \n \nLeft projections \n \nWe recall the standard concept of the left projection fa: X\uf0aeY of a two-place function \nf: XxA\uf0aeY from point a \uf0ce A, defined by putting fa(x) \uf03d f(x,a) for all x \uf0ce X. \n \n \nFor Section 1.1. Doctrinal vs Pragmatic Considerations \n \nThe view that all probability is 'really' conditional \n \nSuch views have been expressed by a number of probabilists, notably R\u00e9nyi 1955 and \n1970, de Finetti 1974 and by some philosophers, e.g. H\u00e1jek 2003.  \n \nR\u00e9nyi 1955 (page 286) puts it briefly: \u201cIn fact, the probability of an event depends \nessentially on the circumstances under which the event possibly occurs, and it is a \ncommonplace to say that in reality every probability is conditional\u201d. The same idea \nrecurs at greater length in his 1970 (page 35).   \n \nDe Finetti 1974 (page 134) similarly remarks: \u201cEvery evaluation of probability is \nconditional; not only on the mentality or psychology of the individual involved, at the \ntime in question, but also, and especially, on the state of information in which he finds \nhimself at that moment.\u201d  \n \nMore recently, H\u00e1jek 2003 writes: \u201c...given an unconditional probability, there is \nalways a corresponding conditional probability lurking in the background. Your \nassignment of 1\/2 to the coin landing heads superficially seems unconditional; but \nreally it is conditional on tacit assumptions about the coin, the toss, the immediate \nenvironment, and so on. In fact, it is conditional on your total evidence.\u201d  \n \nCarnap\u2019s regularity condition \n \nCarnap\u2019s formulation of the additional 'regularity' condition may be found in his book \nof 1950 section 53 axiom C53-3 and also the paper 1971 chapter 2.7 page 101, cf also  \nhis 1952. \n \nIt may be suggested that when constructing a specific one-place probability function \nin an empirical investigation, the wise researcher will assign extremal values (zero \nand one) as seldom as possible, so as to minimize the likelihood of conditionalization \nproblems further down the line. However, as has often been observed, such a policy \nwould have the inconvenience of impeding the free use of Bayesian \nconditionalization, under which pa(a) \uf03d 1 for all a, replacing it by the rather more \ncomplex Jeffrey conditionalization.  \n \nWe note in passing that the concept of a 'counterfactual probability function' \ndiscussed by Boutilier 1995 (building on Stalnaker 1970) also assumes that the critical \nzone is empty. That concept, defined in the finite case, is a curious mixture of \nquantitative and qualitative ingredients. It puts p(x,a), called the counterfactual \n21 \nprobability of x given a, to be the proportion of the 'best' a-states of the model that are \nx-states. The emptiness of the critical zone is assumed for the same reason as before: \nto ensure that the denominator is non-zero for consistent formulae a. \n \nFor Section 1.2. Some Notational Niceties \n \nTwo-place functions could alternatively be distinguished from one-place ones by \ndifferent type-faces, e.g. lower case for one and upper case for the other. However \nthat convention meshes poorly with the standard notation for left projection, which we \nalso need to use extensively. \n \nFor Section 2.1. A Leaf from the AGM Book  \n \nHow important is the critical zone? \n \nOur view of the importance of the critical zone contrasts with its minimization by \nsome authors. For example McGee 1994: \u201cThe problem we have been examining, \nhow to revise one\u2019s system of beliefs upon obtaining new evidence that had prior \nprobability 0, is not a problem that has any great practical significance.\u201d \n \nConditional probability in the light of counterfactual conditionals \n \nAn argument for going beyond the ratio definition of two-place probability may also \nbe made in terms of counterfactual conditionals rather than belief revision. Indeed, \nthat is the way in which it is usually developed in the philosophical literature, going \nback to Stalnaker 1970. However, in the author\u2019s view, the comparison with belief \nrevision affords a clearer view, and also lends itself to the construction of natural \nformal maps, as shown in section 4.  \n     \nVerifications of properties of B(p) \n \nWe verify the claims made in bullet points about belief sets for probability functions. \nGiven a one-place function p we define the corresponding belief set B(p) \uf03d {x: p(x) \uf03d \n1}. This is also sometimes called the top of the function. Write B\uf02ba for the qualitative \nexpansion of B by a, i.e. B\uf02ba \uf03d Cn(B\uf0c8{a}). With pa(\uf0d7) understood as the left \nprojection from a of the conditionalization p(\uf0d7|\uf0d7) obtained from p(\uf0d7) by the ratio\/unit \nrule, we want show: (1) in all cases, B(p) \uf0cd B(p)\uf02ba \uf0cd B(pa) and (2) in the limiting \ncase that p(a) \uf03d 0 we have belief explosion: B(p)\uf02ba \uf03d L \uf03d B(pa), where L is the set of \nall propositions of the language. \n \nFor (1), the first inclusion is immediate from the definition of expansion above. To \ncheck the second inclusion, note that since B(pa) is closed under consequence it \nsuffices to show that a \uf0ce B(pa) and B(p) \uf0cd B(pa). The former is immediate since when \np(a) \uf03e 0 then pa(a) \uf03d 1 by the ratio definition and the Kolmogorov postulates for one-\nplace probability, and pa(a) is also 1 when p(a) \uf03d 0, by the unit part of the ratio\/unit \ndefinition. For the latter, it suffices to show that whenever p(x) \uf03d 1 then pa(x) \uf03d 1. \nThis is immediate when p(a) \uf03d 0. When p(a) \uf03e 0 we have pa(x) \uf03d p(a\uf0d9x)\/p(a) \uf03d \np(a)\/p(a) \uf03d 1 since the hypothesis p(x) \uf03d 1 implies that p(a\uf0d9x) \uf03d p(a). For (2), it \nsuffices to show further that when p(a) \uf03d 0 we have B(p)\uf02ba \uf03d L. But when the \nhypothesis holds then p(\uf0d8a) \uf03d 1, so \uf0d8a \uf0ce B(p) and thus B(p)\uf02ba \uf0ca Cn(\uf0d8a,a) \uf03d L. \n22 \n \nFor Section 2.2. Bird\u2019s-eye View of Available Systems  \n \nVerification of consequences of the van Fraassen axioms \n \nLeft extensionality: p(x,a) \uf03d p(x\uf0a2,a)  whenever x \uf0bb x\uf0a2. Verification: By left projection, \npa is either a proper Kolmogorov function or the unit function. In the former case, \np(x,a) \uf03d pa(x) \uf03d pa(x\uf0a2) \uf03d p(x\uf0a2,a) using the hypothesis. In the latter case, p(x,a) \uf03d pa(x) \uf03d \n1 \uf03d pa(x\uf0a2) \uf03d p(x\uf0a2,a) irrespective of the hypothesis.  \n \nWhen y \uf0ce Cn(x) then p(x,a) \uf0a3 p(y,a). Verification: If y \uf0ce Cn(x) then x \uf0bb y\uf0d9x so by left \nextensionality and product, p(x,a) \uf03d p(y\uf0d9x,a) \uf03d p(y,a)\uf0d7p(x,a\uf0d9y) \uf0a3 p(y,a).  \n \nWhen p(\uf0d7) is defined as p(\uf0d7,T), then we have the ratio rule. Verification: Suitably \ninstantiating the product axiom, p(a\uf0d9x,T) \uf03d p(a,T)\uf0d7p(x,a\uf0d9T) \uf03d p(a,T)\uf0d7p(x,a) using right \nextensionality, so if p(a,T) \uf03e 0 we have p(x,a) \uf03d p(a\uf0d9x,T)\/p(a,T) \uf03d p(a\uf0d9x)\/p(a). \n \nWhen a is a contradiction, then pa is the unit function. Verification: 1 \uf03d pa(a) \uf03d p(a,a) \n\uf0a3 p(x,a) \uf03d pa(x), using left projection and an inequality already established.  \n \nThe set \uf044 of all a \uf0ce L such that pa is the unit function is an ideal. Verification: To \nshow that \uf044 is closed downwards, suppose a \uf0ce \uf044 and a \uf0ce Cn(b). Then 1 \uf03d  p(b\uf0d9x,a) \uf03d \np(b,a)\uf0d7p(x,a\uf0d9b) \uf03d 1\uf0d7p(x,a\uf0d9b) \uf03d p(x,b) \uf03d pb(x), using the first supposition, product, first \nsupposition again, second supposition respectively. To show that \uf044 is closed under \ndisjunction, suppose pa, pb are both the unit function. To show that pa\uf0dab is also the unit \nfunction it suffices, by the left projection axiom to show that it is not a proper \nKolmogorov function. Suppose it is; we get a contradiction. From the van Fraassen \naxioms we have p(\uf05e,a\uf0dab) \uf03d p(\uf05e\uf0d9a,a\uf0dab) \uf03d p(a,a\uf0dab)\uf0d7p(\uf05e,a\uf0d9(a\uf0dab)) \uf03d p(a,a\uf0dab)\uf0d7p(\uf05e,a) \n\uf03d p(a,a\uf0dab)\uf0d71 \uf03d p(a,a\uf0dab) using the supposition that pa is the unit function. Likewise \np(\uf05e,a\uf0dab) \uf03d p(b,a\uf0dab). By the supposition that pa\uf0dab is a proper Kolmogorov function \nwe have p(\uf05e,a\uf0dab) \uf03d 0 so p(a,a\uf0dab) \uf03d 0 \uf03d p(b,a\uf0dab). By the same supposition, \np(a\uf0dab,a\uf0dab) \uf0a3  p(a,a\uf0dab)\uf02bp(b,a\uf0dab) \uf03d 0\uf02b0 \uf03d 0, contradicting the second part of the left \nprojection axiom.   \nFinally, we check that a is abnormal iff p(a,b) \uf03d 0 for all normal b. Verification: From \nright to left, suppose p(a,b) \uf03d 0 for all normal b, but a is not abnormal. Then a is \nnormal, so p(a,a) \uf03d 0, contradicting the second part of the left projection axiom. From \nleft to right, suppose a is abnormal and b is normal. Then a\uf0d9b is abnormal as already \nestablished, so 0 \uf03d p(\uf05e,b) \uf03d p(\uf05e\uf0d9a,b) \uf03d p(a,b)\uf0d7p(\uf05e,a\uf0d9b) \uf03d p(a,b)\uf0d71 \uf03d p(a,b) as desired.   \n \nVerification of the alternative axiomatization of the Popper system \n \nFor the easy half, assume the van Fraassen axioms plus (Positive); we need to show \nthat p(x,b) \uf0b9 1 for some x,b. By left projection, p(T,T) \uf03d 1 \uf03e 0 so by (Positive) pT is \nproper and thus p(\uf05e,T) \uf03d 0 \uf0b9 1 as desired. For the tricky half, assume the van Fraassen \naxioms plus p(x,b) \uf0b9 1 for some x,b. Suppose p(a,T) \uf03e 0; we need to show that pa is \nproper, for which it suffices to show that it is not the unit function. First note that \np(\uf05e,T) \uf03d p(\uf05e\uf0d9b,T) \uf03d p(b,T)\uf0d7p(\uf05e,T\uf0d9b) \uf03d p(b,T)\uf0d7p(\uf05e,b); but since p(x,b) \uf0b9 1 it follows \nthat pb is proper so p(\uf05e,b) \uf03d 0 and thus p(\uf05e,T) \uf03d 0. But also p(\uf05e,T) \uf03d p(\uf05e\uf0d9a,T) \uf03d \n23 \np(a,T)\uf0d7p(\uf05e,a), so since p(a,T) \uf03e 0 we have p(\uf05e,a) \uf03d 0 so that pa is not the unit \nfunction, as desired. \n \nExample of a 'mixed' function \n \nLeblanc and Roeper 1989 gave an example of a two-place function satisfying the \nPopper postulates, whose treatment of formulae with probability zero is a mix of the \nexpansionary and revisionary policies. They presented it rather enigmatically as an \n8\uf0d78 table (their Table 5). We provide it with a more transparent rule-based \npresentation, which for convenience we express with a field of sets.  \n \nTake the field F of all subsets of the three-element set S \uf03d {\uf061,\uf062,\uf067}. For motivation, \nthink of \uf061,\uf062,\uf067 as being of increasing levels of importance beginning from \uf061, which \nhas no importance at all. For a,x \uf0cd S, put p(x,a) \uf03d 1 unless there is some item of \npositive importance in a and the item of greatest importance in a is not in x. More \nprecisely, we define p: S\n2\uf0ae[0,1], in fact into {0,1}, as follows: \n \n1. If \uf067 \uf0ce a then p(x,a) \uf03d 1 if \uf067 \uf0ce x, otherwise p(x,a) \uf03d 0 \n2. If \uf067 \uf0cf a but \uf062 \uf0ce a then p(x,a) \uf03d 1 if \uf062 \uf0ce x, otherwise p(x,a) \uf03d 0 \n3. If \uf067 \uf0cf a and \uf062 \uf0cf a then p(x,a) \uf03d 1. \n \nThis function is a mix of the two kinds of conditional probability: p({\uf062},S) \uf03d 0 \uf03d \np({\uf061},S) applying the first clause, but p(\uf0c6,{\uf062}) \uf03d 0 applying the second while \np(\uf0c6,{\uf061}) \uf03d 1 by the third. On the other hand, it is straightforward to check that it \nsatisfies the Popper axioms. \n \nHistorical development of conditional probability \n \nWe review the historical steps in the construction of axioms for two-place probability \nfunctions, working backwards from Popper 1959. For ease of comparison, we \nconsider them all in the propositional mode, and treat each as defined on the whole of \nL\n2\n, but comment on particularities of the original formulations each as we go.  \n \nPopper's original postulates for two-place probability functions, contained in an \nappendix of Popper 1959 (recalled e.g. in Leblanc and Roeper 1989 and more \naccessibly Koons 2009) were in the propositional mode. They reflected a desire for \nthe autonomy of probability theory from logic, abstract algebra and set theory and so \navoided any use of concepts from those areas. But if we are happy to use concepts of \nclassical logic in our presentation then, as shown by subsequent writers, Popper's \naxioms may be given more perspicuously. The following formulation of Hawthorne \n1996 requires that for p: L\n2\uf0ae[0,1]: \n \n(P0)  p(x,a) \uf0b9 1 for some formulae a, x  \n(P1) p(x,a) \uf03d p(x,b)  whenever a \uf0bb b \n(P2)  p(x,a) \uf03d 1 whenever x \uf0ce Cn(a) \n(P3) either p(x\uf0day,a) = p(x,a)\uf02bp(y,a) whenever \uf0d8(x\uf0d9y) \uf0ce Cn(a), or pa is the \nunit function \n(P4) p(x\uf0d9y,a) \uf03d p(y,a)\uf0d7p(x,y\uf0d9a) \n \n24 \nOf course, if we are working in the context of fields of sets, (P1) becomes vacuous. \nWarning: The term 'Popper function' is sometimes used rather loosely, to refer to \nalmost any primitive two-place probability function defined over the critical zone. For \nexample, Lindstr\u00f6m and Rabinowicz 1989 use the term to refer to the narrower class \nof Hosiasson-Lindenbaum functions, defined below. \n \nOur modular presentation takes from R\u00e9nyi 1955, 1970, 1970a his leading idea that \nfor 'most' values of a, the left projection from a will be a proper Kolmogorov function \ngiving a the value 1, and so is very similar in gestalt. But in its details, R\u00e9nyi's system \nis rather different from any of those we have considered. Formulated in the field-of-\nsets mode, it treats the right domain as a parameter, allowing it to be chosen as any \nsubset of the left domain that is consistent with the axioms. These axioms are just the \nproduct rule and the principle that pa is a proper one-place Kolmogorov function with \npa(a) \uf03d 1, both formulated under the restriction that the right argument takes a value in \nthe restricted right domain. For values of the right argument outside that subset, the \nprobability functions are left undefined. We are thus given a scheme for a family of \naxiom sets, one for each choice of right domain.  \n \nThis yields the Popper axioms if we constrain the right domain to include {a: p(a,S) \uf03e \n0}, where S is the set on which the field is based, and carry out the following editing: \n(a) put p(x,a) \uf03d 1 for all a outside the right domain, (b) ensure consistency by \nallowing in the left projection axiom that pa may be improper (as in the axiom (vF2) \nof section 2.2), (c) for the one-place Kolmogorov functions mentioned in the left \nprojection axiom, weaken R\u00e9nyi's assumption of countable to finite additivity, and \nfinally (d) translate from the field-of-sets mode to the propositional one.  \n \nThe system of Hosiasson-Lindenbaum 1940 concerned what she called 'confirmation' \nfunctions, writing them as c(x,a) rather than p(x,a) and working in the propositional \nmode. This ground-breaking work has been comparatively neglected, despite its \naccessible and respected place of publication. In particular, the paper is not mentioned \nin any of R\u00e9nyi 1955, 1970, 1970a, nor in the wide-ranging discussion of Harper 1975 \nor the comprehensive study of Roeper and Leblanc 1999. Popper 1959 does mention \nHosiasson-Lindenbaum in passing, but with respect to other questions and without \nciting her 1940 paper. This contrasts with his explicit acknowledgement (note 12 in \nnew appendix iv) of the influence of R\u00e9nyi 1955 on his thinking.  \n \nWe remark that the Hosiasson-Lindenbaum system reappears in field-of-sets form in \nDubins 1975, a paper that has been particularly influential among statisticians. \nHowever, Dubins' definition (of 'full conditional probability' in his section 3) appears \nto have been devised independently: he does not mention Hosiasson-Lindenbaum's \npaper, and the manner of presentation suggests the influence of R\u00e9nyi.   \n \nHosiasson-Lindenbaum excluded inconsistent propositions from the right domain \n(likewise Dubins excluded the empty set in his later version). Restoring the \ninconsistent propositions to make that domain full, we get the following axioms:  \n(HL1)  p(x,a) \uf03d 1 whenever x \uf0ce Cn(a) \n(HL2)  p(x\uf0day,a) = p(x,a)\uf02bp(y,a) whenever \uf0d8(x\uf0d9y) \uf0ce Cn(a), provided a is \nconsistent  \n(HL3) p(x\uf0d9y,a) \uf03d p(x,a)\uf0d7p(y,a\uf0d9x) for all formulae a, x, y \n25 \n (HL4) p(x,a) \uf03d p(x,b) whenever a \uf0bb b.  \n \nAxiom (HL2) thus broadens the conditions under which the left projection of a two-\nplace function satisfies additivity and is thus a proper Kolmogorov function, from the \nnarrower case p(a,T) \uf03e 0 to the wider one that a is consistent. The system may be \nobtained fron R\u00e9nyi's scheme by putting the right domain to be the set of all non-\nempty sets of S and editing by first putting p(x,\uf0c6) \uf03d 1 and then as for Popper\u2019s \nsystem. \n \nIn what respect can it be said that R\u00e9nyi's formulation was an advance on that of \nHosiasson-Lindenbaum? For working mathematicians and statisticians, its use of the \nfield-of-sets mode made application to practical problems more transparent. The \nvariability of the right domain may have made it more flexible. But at a deeper level, \nthe step forward from earlier formulations was conceptual \u2013 the realization that a \nrather arbitrary-looking axiom system becomes natural if we build it around the idea \nthat for 'most' values of the right argument, the left projection will be a proper one-\nplace probability function. As R\u00e9nyi put it: \u201ca conditional probability space is nothing \nelse than a set of ordinary probability spaces which are connected with each other by \n[the product axiom]\u201d (R\u00e9nyi 1955 pp 289-290).  \n \nMini-note: We reverse a correction made by Hailperin 1991 (page 75) to the effect \nthat since Hosiasson-Lindenbaum\u2019s formulation is in the propositional mode, it needs \na left companion to (HL4) stating that p(x,a) \uf03d p(y,a) whenever x \uf0bb y. In fact, this \nfollows from the postulates as given. In the limiting case that a is inconsistent we \nhave p(x,a) \uf03d 1 \uf03d p(y,a) by (HL1), so suppose a is consistent and x \uf0bb y. Then \uf0d8(x\uf0d9\uf0d8y) \n\uf0ce Cn(a), so by the additivity axiom (HL2) we have p(x\uf0da\uf0d8y,a) \uf03d p(x,a)\uf02bp(\uf0d8y,a). But \nthe supposition also gives us LHS \uf03d 1 by (HL1), so p(x,a)\uf02bp(\uf0d8y,a) \uf03d 1. Moreover, \n(HL1) and (HL2) imply that p(\uf0d8y,a) \uf03d 1 \uf02d p(y,a), and so by arithmetic p(x,a) \uf03d p(y,a). \nEssentially this point was already made by Tarski with regard to the earlier \naxiomatization of Mazurkiewicz 1932 (discussed below), and was acknowledged in \nfootnote 1 of that paper.  \n \nHosiasson-Lindenbaum 1940 states that her axioms for two-place probability are \n\u201canalogous\u201d to still earlier ones of Mazurkiewicz 1932. In fact, they considerably \nsimplify and clarify his quite complex system, which requires the left domain to \ncontain individual propositions, while the right one contains consistent sets of \npropositions closed under classical consequence \u2013 the two kinds of proposition drawn, \nmoreover, from intersecting and not very clearly defined languages. In his only \nexample, Mazurkiewicz considers a game: the left argument of p(x,A) can be filled by \na proposition describing a state of play, while the right one can be occupied by a \nclosed set of propositions containing the rules of the game, the current state of play, \nand any mathematical apparatus needed for deductions. \n \nIn turn, Mazurkiewicz states that he is taking as his starting point the axioms of \nBohlmann 1909. However, Bohlmann\u2019s postulates are for one-place probability in a \nmode of unanalysed items called events and occurrences, which he supplements with \nan 'axiom' defining conditional probability by the ratio rule.  \n \nFor some late nineteenth-century uses of conditional probability (without any attempt \nat axiomatization) see Hailperin 1988.  \n26 \n \nThus our trail into the history of axiomatizations of two-place probability that cover \nthe critical zone appears to end with Mazurkiewicz 1932 as first serious attempt, \nHosiasson-Lindenbaum 1940 as the first really successful one, and R\u00e9nyi 1955 for \nproviding a clear gestalt.   \n \nFor Section 3.1. Hosiasson-Lindenbaum vs Popper vs van Fraassen \n \nBayesian update of a conditional probability function \n \nAs mentioned in the text, it may be suggested that while Bayesian update as defined \nby the rule p\uf0d9b(x,a) \uf03d p(x,a\uf0d9b) is suitable for an expansionary notion of conditional \nprobability given by the ratio or ratio\/unit definition, it is quite inappropriate for a \nrevisionary one. The class of Hosiasson-Lindenbaum (or of Popper) functions should \nindeed be closed under conditionalization, but that operation should be understood \ndifferently. Once again, the point may be appreciated by comparing with the situation \nfor qualitative belief change. The counterpart of Bayesian update for qualitative \nexpansion is the equality (K\uf02ba)\uf02bb \uf03d K\uf02b(a\uf0d9b), which is trivially correct by classical \nlogic. But the counterpart for revision would be (K\uf02aa)\uf02ab \uf03d K\uf02a(a\uf0d9b), which is quite \ninappropriate, conflicting with the principle of conservation of consistency of input \n(i.e. that K\uf02ax is consistent whenever x is consistent). It is acceptable only in the \nspecial case that b is consistent with K\uf02aa, where the equality (K\uf02aa)\uf02ab \uf03d (K\uf02aa)\uf02bb is \ngiven by the AGM supplementary postulates (K\uf02a7) and (K\uf02a8).  \n \nSo how should we define conditionalization of a revisionary two-place probability \nfunction p(\uf0d7,\uf0d7) under an input proposition a? The short answer is that there is no such \ndefinition, because there is not a unique operation of this kind. Just as on the \nqualitative level there are many ways of revising a belief set and thus in particular of \nrevising its revision, so too on the quantitative level there are many ways of revising a \nconditional probability function p(\uf0d7,\uf0d7) given an input proposition a. In both contexts \nwe may articulate interesting regularity conditions, but there is no formally justified \nchoice of a unique and universally applicable operation taking conditional probability \nfunction p(\uf0d7,\uf0d7) and propositional input a to a conditional probability function p\uf02aa(\uf0d7,\uf0d7) \nthat is waiting to be expressed as a definition. Moreover, just as the task of settling on \nsuitable regularity conditions for iterated qualitative belief revision is notoriously \ndifficult (much more so than in the case of one-shot AGM revision) and is still under \ndebate, so too we may expect that the task of articulating consensual regularity \nconditions on the passage from p(\uf0d7,\uf0d7) and a to p\uf02aa(\uf0d7,\uf0d7), following input of proposition a, \nwill not be easy.      \n \nChanging the underlying consequence operation \n \nIf one is working in the mode of fields-of-sets, or of Boolean algebras as carriers for \nthe probability functions, then one can similarly express van Fraassen functions as \nHosiasson-Lindenbaum ones by passing to the quotient algebra determined by the \nsame filter as in the propositional mode. Essentially this construction was used for \ndifferent purposes by Harper 1976 (section 6).  \n \nFor Section 4.1. Correspondence between AGM and HL \n \n27 \nA map from HL into AGM \n \nLindstr\u00f6m and Rabinowicz 1989, building on work of G\u00e4rdenfors 1988 chapter 5, \nalready constructed a map from the class of all G\u00e4rdenfors probability-revision \noperations into the class of AGM belief revision operations. The construction below \nessentially translates it (with some simplifications and an explicit verification of \nsurjectivity in the finite case) into a map from the class of Hosiasson-Lindenbaum \nprobability functions to the AGM operations.  \n \n \nGiven any HL function p: L\n2\uf0ae[0,1] as defined in section 2.2 or equivalently in its \nappendix, we construct the associated belief set K \uf03d\uf020B(p), called the top of p, as \nfollows:  \n\uf0b7 B(p) \uf03d \uf02ap(T) \uf03d\uf020{x: p(x,T) \uf03d 1}.  \n \nWe define an AGM belief revision function with this set K fixed, i.e. as the two-place \noperation \uf02ap: {K}XL\uf0ae2\nL\n with singleton left domain, or more briefly the one-place \noperation \uf02ap: L\uf0ae2\nL\n, by putting: \n\uf0b7 \uf02ap(a) \uf03d {x: p(x,a) \uf03d 1}. \n \nWe need to show that for every HL function p: L\n2\uf0ae[0,1]: \n\uf0b7 B(p) is a consistent belief set. \n\uf0b7 The operation \uf02ap: L\uf0ae2\nL\n satisfies the full set of AGM postulates (K\uf02a1) through \n(K\uf02a8) with respect to K \uf03d B(p).  \n \nFirst, recall from section 2.2 that for HL functions p(\uf0d7,\uf0d7), the left projection pa from a \nis a proper Kolmogorov one-place probability function whenever a is consistent, so  \nwe can apply well-known properties of the one-place functions without detailed \njustification, as well as the HL axioms themselves. \n \nTo show that K \uf03d B(p) is a belief set, suppose y \uf0ce Cn(K); we need to check that y \uf0ce K. \nBy compactness, y \uf0ce Cn{\uf0d9xi: i \uf0a3 n} for some x1,.., xn \uf0ce B(p), so each p(xi,T) \uf03d 1, so \np(\uf0d9xi,T) \uf03d 1 and thus p(y,T) \uf03d 1 so that y \uf0ce B(p). To show that B(p) is consistent we \nneed then only note that p(\uf05e,T) \uf03d 0.  \n \nWe now check that the function \uf02ap\uf020: L\uf0ae2\nL\n satisfies each of the AGM postulates (K\uf02a1) \nthrough (K\uf02a8) with respect to K \uf03d B(p). Some general remarks before the details: \n\uf0b7 The AGM postulates for revision were first formulated in G\u00e4rdenfors 1984 \nand a convenient overview may be found in Peppas 2007, whose presentation \nwe follow. We note in passing that the classic account in Alchourr\u00f3n, \nG\u00e4rdenfors and Makinson 1985 focused on contraction, and its axiomatization \nof revision contains a confusion: it omits postulate (K\uf02a3) below, and treats the \ndefinition of contraction from revision via the Harper identity as a postulate.  \n\uf0b7 We are not verifying satisfaction with respect to an arbitrary belief set K, but \nwith respect to a specific belief set depending on the choice of p, namely  K \uf03d \nB(p) \uf03d {x: p(x,T) \uf03d 1}. This specification is needed for (K\uf02a3) and (K\uf02a4), \n28 \nthough not for the other postulates, where K does not appear in unrevised \nform.  \n\uf0b7 Our result corrects the claim made by Spohn 1986 and 2009 that the AGM \npostulates correspond to the Popper axioms for conditional probability. When \nCn is understood as classical consequence, the specific Hosiasson-\nLindenbaum axiom (HL) (see section 2.2) is needed to ensure that the function \n\uf02ap\uf020: L\uf0ae2\nL\n satisfies the AGM postulate (K\uf02a5), as noted in the verification \nbelow. \n \n(K\uf02a1): K\uf02aa \uf03d Cn(K\uf02aa). Verification: Same as the above for B(p) \uf03d Cn(B(p)), but \nreplacing T by a.  \n(K\uf02a2): a \uf0ce K\uf02aa. Verification: We need p(a,a) \uf03d 1, immediate from axiom (vF2). \n(K\uf02a3):  K\uf02aa \uf0cd Cn(K\uf0c8{a}). Verification: Suppose y \uf0ce LHS, so that p(y,a) \uf03d 1. We \nneed to show that y \uf0ce Cn(K\uf0c8{a}) \uf03d Cn(B(p)\uf0c8{a}) \uf03d Cn({x: p(x,T) \uf03d 1}\uf0c8{a}), so it \nsuffices to show that \uf0d8a\uf0day \uf0ce {x: p(x,T) \uf03d 1}, i.e. that p(\uf0d8a\uf0day,T) \uf03d 1. Now p(\uf0d8a\uf0day,T) \n\uf03d p(\uf0d8a\uf0da(a\uf0d9y),T) \uf03d p(\uf0d8a,T)\uf02bp(a\uf0d9y,T). But p(a\uf0d9y,T) \uf03d p(a,T)\uf0d7p(y,a) \uf03d p(a,T) since by \nsupposition p(y,a) \uf03d 1. Thus p(\uf0d8a\uf0day,T) \uf03d p(\uf0d8a,T)\uf02bp(a,T) \uf03d p(T,T) \uf03d 1 as desired.  \n(K\uf02a4):  Cn(K\uf0c8{a}) \uf0cd K\uf02aa whenever a is consistent with K. Verification: Suppose y \n\uf0ce Cn(K\uf0c8{a}) and a is consistent with K; we need to show p(y,a) \uf03d 1. By the first \nsupposition, \uf0d8a\uf0day \uf0ce Cn(\uf0d9xi: i \uf0a3 n} for some x1,.., xn \uf0ce K \uf03d B(p) with each p(xi,T) \uf03d 1, \nso that p(\uf0d9xi,T) \uf03d 1 and thus p(\uf0d8a\uf0day,T) \uf03d 1. Hence p(a,T) \uf03d p(a\uf0d9(\uf0d8a\uf0day),T) \uf03d \np(a\uf0d9y,T). But also we have p(a\uf0d9y,T) \uf03d p(a,T)\uf0d7p(y,a). Putting these together, p(a,T) \uf03d \np(a,T)\uf0d7p(y,a). But by supposition, \uf0d8a \uf0cf K \uf03d B(p) so p(\uf0d8a,T) \uf0b9 1 so p(a,T) \uf0b9 0, so by \narithmetic p(y,a) \uf03d 1 as desired. \n(K\uf02a5): K\uf02aa is consistent whenever a is consistent. Verification: Suppose a is \nconsistent; we need p(\uf05e,a) \uf03d 0, which is immediate given the distinctive axiom for  \nfor HL functions.  \n(K\uf02a6):  If a \uf0bb b then K\uf02aa \uf0bb K\uf02ab. Verification: Suppose a \uf0bb b; we need p(x,a) \uf03d 1 iff \np(x,b) \uf03d 1, again immediate. \n(K\uf02a7):  K\uf02a(a\uf0d9b) \uf0cd  Cn((K\uf02aa)\uf0c8{b}). Verification: Suppose x \uf0ce LHS, so that p(x,a\uf0d9b) \n\uf03d 1. It suffices to show that \uf0d8b\uf0dax \uf0ce K\uf02aa, i.e. that p(\uf0d8b\uf0dax,a) \uf03d 1. When a is abnormal, \nthis is immediate, so suppose that a is normal. From the supposition, p(\uf0d8b\uf0dax, a\uf0d9b) \uf03d \n1. Now  p(b\uf0d9x,a) \uf03d p(b\uf0d9(\uf0d8b\uf0dax),a) \uf03d p(b,a)\uf0d7p(\uf0d8b\uf0dax,a\uf0d9b) \uf03d p(b,a)\uf0d71 \uf03d p(b,a). Since a \nis normal, the left projection of p from a is a proper Kolmogorov function, so we may \nconclude that p(b\uf0d9\uf0d8x, a) \uf03d 0 and thus p(\uf0d8b\uf0dax, a) \uf03d 1 as desired.  \n(K\uf02a8):  Cn((K\uf02aa)\uf0c8{b}) \uf0cd K\uf02a(a\uf0d9b) whenever b is consistent with K\uf02aa. Verification: \nSuppose that y \uf0ce LHS and b is consistent with K\uf02aa; we need to show that p(y,a\uf0d9b) \uf03d \n1. By the second supposition, \uf0d8b \uf0cf K\uf02aa  so p(\uf0d8b,a) \uf0b9 1 and thus a is normal and \nmoreover p(b,a) \uf0b9 0. By the first supposition, \uf0d8b\uf0day \uf0ce K\uf02aa, i.e. p(\uf0d8b\uf0day,a) \uf03d 1. Hence \np(b,a) \uf03d p(b\uf0d9(\uf0d8b\uf0day),a) \uf03d p(b\uf0d9y,a). But also p(b\uf0d9y,a) \uf03d p(b,a)\uf0d7p(y,a\uf0d9b). Putting these \ntogether, p(b,a) \uf03d p(b,a)\uf0d7p(y,a\uf0d9b). Since as noted p(b,a) \uf0b9 0, arithmetic gives us \np(y,a\uf0d9b) \uf03d 1 as desired. \n \nFailure of injectivity \n \n29 \nFor the failure of injectivity it suffices to find two distinct HL functions p \uf0b9 p\uf0a2 with \uf02ap \n\uf03d \uf02ap\uf0a2, i.e. with \uf02ap(a) \uf03d {x: p(x,a) \uf03d 1} \uf03d {x: p\uf0a2(x,a) \uf03d 1} \uf03d \uf02ap\uf0a2(a) for all a \uf0ce L, i.e. with \np(x,a) \uf03d 1 iff p\uf0a2(x,a) \uf03d 1 for all a,x \uf0ce L. For simplicity we do this with Boolean \nalgebras rather than propositional languages. Take any finite Boolean algebra with n \uf0b3 \n2 atoms, and two distinct probability distributions f,f\uf0a2 to these atoms with each atom \ngetting a non-zero probability; extend them to one-place probability functions (for \nsimplicity using the same names) on the entire algebra. Noting that every non-zero \nelement of the algebra receives a non-zero probability under each of these functions, \nwe can define two-place functions p,p\uf0a2: L2\uf0ae[0,1] by the ratio rule for non-zero right \narguments and putting p(x,0) \uf03d p\uf0a2(x,0) \uf03d 1. These are HL probability functions, in fact \nthey are Carnap functions. Then for all a,x we have p(x,a) \uf03d 1 iff p(a\uf0d9x) \uf03d p(a)  iff a \uf0a3 \nx and likewise for p\uf0a2, and so p(x,a) \uf03d 1 iff p\uf0a2(x,a) \uf03d 1 as desired.  \n \nSurjectivity in the finite case \n \nWe now show that the map is surjective for consistent belief sets and under the \ncondition of finiteness (i.e. that the propositional language has only finitely many \nmutually non-equivalent formulae). That is, in such a language, for every belief set K \nand every revision operation \uf02a: L\uf0ae2L satisfying the AGM postulates with respect to \nK, there is a HL function p: L\n2\uf0ae[0,1] with \uf02a \uf03d \uf02ap and such that if K is consistent then \nK \uf03d B(p).  \n \nThe construction is quite straightforward. Given \uf02a and K, we define p: L2\uf0ae[0,1] as \nfollows: \n\uf0b7 In the limiting case that a is inconsistent, put p(x,a) \uf03d 1 for all x \uf0ce L  \n\uf0b7 In the principal case that a is consistent, put p(x,a) to be the proportion of \n(K\uf02aa)-worlds that are x-worlds.  \n \nHere, a world is a maximal consistent set of formulae, and an X-world, for X \uf0cd L, is a \nworld Y with X \uf0cd Y. We need to show that (1) p satisfies the HL axioms, (2) \uf02a \uf03d \uf02ap, \nand (3) if K is consistent then K \uf03d B(p). \n \nFor (1) it is convenient to check the HL axioms in the form given to them by \nHosiasson-Lindenbaum 1940 (see appendix to section 2.2), as follows.  \n \n(HL1) p(x,a) \uf03d 1 whenever x \uf0ce Cn(a). Verification: If a is inconsistent then we have \np(x,a) \uf03d 1 by the definition for that case, so we may suppose that a is consistent. By \nAGM, a \uf0ce K\uf02aa so if x \uf0ce Cn(a) we have x \uf0ce Cn(K\uf02aa) \uf03d K\uf02aa. Thus when x \uf0ce Cn(a), \nall (K\uf02aa)-worlds are x-worlds, i.e. the proportion of (K\uf02aa)-worlds that are x-worlds is \n1, so p(x,a) \uf03d 1 as required. \n \n(HL2)  p(x\uf0day,a) = p(x,a)\uf02bp(y,a) whenever a is consistent and \uf0d8(x\uf0d9y) \uf0ce Cn(a). \nVerification: Suppose a is consistent and \uf0d8(x\uf0d9y) \uf0ce Cn(a). By the first supposition, we \nneed to consider proportions, and by the second the proportion of (K\uf02aa)-worlds that \nare (x\uf0day)-worlds is the sum of the proportions of (K\uf02aa)-worlds that are, separately, x-\nworlds or y-worlds, and we are done. \n \n30 \n(HL3) p(x\uf0d9y,a) \uf03d p(x,a)\uf0d7p(y,a\uf0d9x). Verification: If a is inconsistent then so is a\uf0d9x and \nLHS \uf03d 1 \uf03d RHS. Suppose a is consistent. If a\uf0d9x is inconsistent then LHS \uf03d 0 while \nRHS \uf03d 0\uf0d71 \uf03d 0 and again we are done. If a\uf0d9x is consistent then LHS is the proportion \nof (K\uf02aa)-worlds that are (x\uf0d9y)-worlds, while RHS is the proportion of (K\uf02aa)-worlds \nthat are x-worlds multiplied by the proportion of (K\uf02aa\uf0d9x)-worlds that are y-worlds. If \nx is inconsistent with K\uf02aa then both LHS and RHS equal 0, so we may suppose that x \nis consistent with K\uf02aa. Then by AGM axioms (K\uf02a7) and (K\uf02a8) the (K\uf02aa\uf0d9x)-worlds \nare just the (K\uf02aa)-worlds that are x-worlds. Hence RHS is the proportion of (K\uf02aa)-\nworlds that are x-worlds multiplied by the proportion of those that are y-worlds, which \nequals the proportion of (K\uf02aa)-worlds that are (x\uf0d9y)-worlds, equalling the LHS and \nwe are done. \n  \n(HL4) p(x,a) \uf03d p(x,b) whenever a \uf0bb b. Verification: If a is inconsistent then so is b, so \nLHS \uf03d 1 \uf03d RHS. If a is consistent, then if a \uf0bb b the a-worlds are just the b-worlds, and \nthe proportion of a-worlds that are x-worlds is the same as the proportion of b-worlds \nthat are x-worlds. \n \nTo show that (2) \uf02a \uf03d \uf02ap, consider first the principal case that a is consistent, where we \nneed only note that by the definition of \uf02ap we have x \uf0ce \uf02ap(a) iff p(x,a) \uf03d 1 while, by \nthe definition of p, also p(x,a) \uf03d 1 iff every (K\uf02aa)-world is an x-world, i.e. iff x \uf0ce \nCn(K\uf02aa) \uf03d K\uf02aa. In the limiting case that a is inconsistent, p(x,a) \uf03d 1 for every x and \nby the AGM postulates, x \uf0ce K\uf02aa for every x, so again we are done.  \n \nFinally, we check (3) that if K is consistent then K \uf03d B(p). For this, we need only \nshow that x \uf0ce K iff p(x,T) \uf03d 1. But if K is consistent, the AGM postulates tell us that K \n\uf03d K\uf02aT, and the equivalence p(x,a) \uf03d 1 iff x \uf0ce K\uf02aa just established may be applied \nsubstituting T for a, completing our proof. \n \nWe conjecture that surjectivity fails in the infinite case. Evidently its present proof \nbreaks down there, since one cannot meaningfully speak of proportions of infinite \nsets, thus blocking the definition of p(\uf0d7,\uf0d7) above. Nor is it possible to repair the proof \nby replacing proportionality by some probability distribution that gives each world a \nnon-zero value. For if the set of formulae is countable, there are continuum many \nworlds and as is well known, there is no probability distribution on a non-countable \nset that gives a non-zero value to each element.  \n \nOne may wonder whether it is possible to get rid of the condition that K is consistent \nwhen verifying (3). It can be done \u2013 at the cost of fiddling with the definitions of both \nAGM revision and HL functions for this case. When K is inconsistent, we need to \ntake K\uf02aa \uf03d K, and consequently modify the AGM postulate K\uf02a5 to read, a little \nredundantly given (K\uf02a\uf032\uf029: K is consistent iff both K and a are consistent. At the same \ntime, we need to add the unit two-place function 1(\uf0d7,\uf0d7) to the class of HL functions, \nand consequently replace both the Popper and HL postulates by the following: pa is a \nproper Kolmogorov function iff p(\uf05e,T) \uf0b9\uf020\uf031\uf020and a is consistent. We omit verifications. \n \nFor Section 5.1. Hawthorne's system Q of Uncertain Inference \n \nIt is interesting that some of Hawthorne's postulates are echoed in the theory of data \nmining, in axioms for redundancy among association rules, despite the fact that these \n31 \ndeal with a context without any propositional connectives. See Balc\u00e1zar 2010 for \nmore information.  \n \nFor Section 5.2. Proto-probability Functions  \n \nDisjunctive interpolation \n \nAs remarked in the text, the principle of disjunctive interpolation is essentially a \nrestriction to the finite case of a rule known as conglomerability, due to  Seidenfeld et \nal 1998. That rule says that if r \uf0a3 p(y|ai) \uf0a3 s for every cell ai of a partition {ai: i \uf0ce I} of \nthe probability space, then r \uf0a3 p(y) \uf0a3 s. This principle is uncontroversial in the finite \ncase, following from the Kolmogorov axioms, but poses difficulties in the case that I \nis countable, where it can fail unless countable additivity is assumed. Our disjunctive \ninterpolation is the anodyne case that #(I) \uf03d 2, from which of course the other finite \ncases may be obtained by induction.   \n \nOne half of our rule was articulated and discussed by Koopman 1940, 1940a under \nname of \u2018alternative presumption\u2019. Recall that disjunctive interpolation states that \np(x,a) \uf0a3 p(x,a\uf0dab) \uf0a3 p(x,b) whenever p(x,a) \uf0a3 p(x,b) and \uf0d8b \uf0ce Cn(a). Koopman\u2019s rule \nof alternative presumption says that p(x,a) \uf0a3 p(y,c) whenever both p(x,a\uf0d9b), \np(x,a\uf0d9\uf0d8b) \uf0a3 p(y,c). If one assumes that the order \uf0a3 is complete (as we do, although \nKoopman does not), alternative presumption is in fact equivalent to the right half of \ndisjunctive interpolation (i.e the assertion that p(x,a\uf0dab) \uf0a3 p(x,b) under the same \nconditions).  \n \nTo obtain Koopman, suppose both p(x,a\uf0d9b) \uf0a3 p(y,c) and p(x,a\uf0d9\uf0d8b) \uf0a3 p(y,c).  By the \ncompleteness of \uf0a3, either p(x,a\uf0d9b) \uf0a3 p(x,a\uf0d9\uf0d8b) or conversely. In e.g. the former case \nwe have by the right part of disjunctive interpolation that p(x,(a\uf0d9b)\uf0da(a\uf0d9\uf0d8b)) \uf0a3 \np(x,a\uf0d9\uf0d8b), so by the second supposition with right extensionality and transitivity of \n\uf0a3, we are done. In the converse direction, suppose p(x,a) \uf0a3 p(x,b) and \uf0d8b \uf0ce Cn(a), we \nwant to show that p(x,a\uf0dab) \uf0a3 p(x,b). We need only note that p(x,(a\uf0dab)\uf0d9b) \uf03d p(x,b) \nand, since \uf0d8b \uf0ce Cn(a), also p(x,(a\uf0dab)\uf0d9\uf0d8b) \uf03d p(x,a) \uf0a3 p(x,b), so we can apply \nKoopman to get p(x,(a\uf0dab)) \uf0a3 p(x,b).   \n \nDisjunctive interpolation may also be seen as extracting the qualitative content of \nG\u00e4rdenfors' principle (P*M) in section 5.8 of his 1988. That principle may be \nformulated in the language of two-place conditional probability, as follows: p(x,a\uf0dab) \n\uf03d p(x,a)\uf0d7k \uf02b p(x,b)\uf0d7\uf028\uf031\uf02dk) where k = p(a,a\uf0dab), whenever \uf0d8b \uf0ce Cn(a). Disjunctive \ninterpolation follows immediately. For if  \uf0d8b \uf0ce Cn(a) and p(x,a) \uf0a3 p(x,b) then by \n(P*M) p(x,a\uf0dab) \uf0a3 p(x,b)\uf0d7k \uf02b p(x,b)\uf0d7\uf028\uf031\uf02dk) = p(x,b)\uf0d7\uf028k\uf02b\uf028\uf031\uf02dk)) = p(x,b) and likewise \np(x,a\uf0dab) \uf0b3 p(x,a)\uf0d7k \uf02b p(x,a)\uf0d7\uf028\uf031\uf02dk) = p(x,a)\uf0d7\uf028k\uf02b\uf028\uf031\uf02dk)) = p(x,a).  \n \nActually, G\u00e4rdenfors presented his principle (P*M) in terms of operations \uf02a\uf020that \nrevise one-place probability functions: p\uf02a(a\uf0dab) \uf03d (p\uf02aa)\uf0d7k \uf02b (p\uf02ab)\uf0d7\uf028\uf031\uf02dk) where k = \n(p\uf02a\uf028a\uf0dab))(a), whenever \uf0d8b \uf0ce Cn(a). The two versions translate directly.  \n \nVerification that Q is proto-probabilistically sound \n \n32 \nWe check that when we take any proto-probability function p(\uf0d7,\uf0d7) and t \uf0ce D, and \ndefine a relation by putting a |~pt x iff p(x,a) \uf0b3 t, then |~pt satisfies all the rules of Q. \nFor (O1) we need p(a,a) \uf0b3 t, which is immediate from (P1). For (O2), we need that \nwhen p(x,a) \uf0b3 t and y \uf0ce Cn(x) then p(y,a) \uf0b3 t, which is immediate from (P2) and \ntransitivity. For (O3), we need that when p(x,a) \uf0b3 t and a \uf0bb b then p(x,b) \uf0b3 t, which is \nimmediate from (P3). For (O4), we need that when p(x\uf0d9y,a) \uf0b3 t then p(y,a\uf0d9x) \uf0b3 t, \nwhich is immediate from (P4) and transitivity. For (O6) alias WAND, we need that \nwhen p(x,a) \uf0b3 t and p(y,a\uf0d9\uf0d8y) \uf0b3 t then p(x\uf0d9y,a) \uf0b3 t. If t \uf03d 0D then this is immediate, \nand if t \uf0b9 0D it is given by (P6). \n \nIt remains to obtain (O5) and the non-Horn rule NR of negation rationality, which we \ndo from the two parts of (P5), making use of the completeness of the relation \uf0a3. \nSuppose for both that \uf0d8b \uf0ce Cn(a). For (O5) we need that when p(x,a) \uf0b3 t, p(x,b) \uf0b3 t \nthen p(x,a\uf0dab) \uf0b3 t. Since the order on D is complete, either p(x,a) \uf0a3 p(x,b) or \nconversely; consider e.g. the former. Then by the left part of (P5), p(x,a) \uf0a3 p(x,a\uf0dab) \nand we are done by transitivity of \uf0a3. For NR we need to show that when p(x,a\uf0dab) \uf0b3 t \nthen either p(x,a) \uf0b3 t or p(x,b) \uf0b3 t. Since the order on D is complete, either p(x,a) \uf0a3 \np(x,b) or conversely, consider e.g. the former. Then by the right part of (P5), p(x,a\uf0dab) \n\uf0a3 p(x,b) so by transitivity p(x,b) \uf0b3 t as desired.  \n \nNote that the only conditions on \uf0a3\uf020that are used in this verification are those imposed: \ntransitivity, completeness, largest and least elements. In particular, we did not need \nanti-symmetry. \n \nThe modularity of this verification shows that it can also be run for subsystems. In \nparticular, if on the semantic side we omit the conditions (P4) and (P6) we can still \nobtain the postulates of system Q that do not refer explicitly to conjunction, i.e. Q less \n(O4: VCM) and (O6: WAND). Perhaps more interestingly, when we omit condition \n(P5) (and this time also, if desired, the requirement that \uf0a3 is complete) we can still \nobtain the postulates of Q that do not refer to disjunction, i.e. Q less (O5: XOR) and \n(NR). Representation theorems then follow by the same construction as used in the \ntext. Such systems may be worth exploring further, but we do not pursue the matter \nhere.  \n \nVerification that van Fraassen functions satisfy the proto-probability conditions \n \nThe verifications of (P1) through (P4) are trivial; we give those for (P5) and (P6). The \nlatter is the shorter. Suppose p(y,a\uf0d9\uf0d8y) \uf0b9 0; we want to show p(x,a) \uf03d p(x\uf0d9y,a). If pa \nis the unit function this is immediate, so suppose that it is a proper Kolmogorov \nfunction, so that p(y\uf0d9\uf0d8y,a) \uf03d 0. Now by (vF3), p(y\uf0d9\uf0d8y,a) \uf03d p(\uf0d8y,a)\u00b7p(y,a\uf0d9\uf0d8y) so one \nof the two factors is zero, so by the initial supposition the left one is, so in turn \np(x\uf0d9\uf0d8y,a) \uf03d 0. By (vF2) we have p(x,a) \uf03d p(x\uf0d9y,a) \uf02b p(x\uf0d9\uf0d8y,a) so p(x,a) \uf03d p(x\uf0d9y,a) \nas desired.  \n \nFor (P5), we have already observed that it follows immediately from G\u00e4rdenfors' \nprinciple (P*M), which is known to follow from the van Fraassen axioms. For a direct \nverification, however, we can argue as follows. Suppose \uf0d8b \uf0ce Cn(a) and p(x,a) \uf0a3 \np(x,b); we want to show that p(x,a) \uf0a3 p(x,a\uf0dab) \uf0a3 p(x,b). In the case that pa\uf0dab is the unit \nfunction we have the left inequality and moreover, since the set of abnormal elements \n33 \nof D is an ideal (see section 2.2 and its appendix), pb is also the unit function giving us \nalso the right one. So suppose that pa\uf0dab is not the unit function, and so is a proper \nKolmogorov function; we show first the right inequality. By (vF2), p(x,a\uf0dab) \uf03d \np(x\uf0d9a,a\uf0dab) \uf02b p(x\uf0d9\uf0d8a,a\uf0dab). By the product rule (vF3) the left summand equals \np(a,a\uf0dab)\u00b7p(x,a) \uf0a3 p(a,a\uf0dab)\u00b7p(x,b) since p(x,a) \uf0a3 p(x,b), while the right one equals \np(\uf0d8a,a\uf0dab)\u00b7p(x,\uf0d8a\uf0d9b) = p(\uf0d8a,a\uf0dab)\u00b7p(x,b) since \uf0d8b \uf0ce Cn(a). Putting these together, \np(x,a\uf0dab) \uf0a3 [p(a,a\uf0dab)\u00b7p(x,b)] \uf02b [p(\uf0d8a,a\uf0dab)\u00b7p(x,b)] = p(x,b) by arithmetic distribution \nand (vF2) again. A similar argument (interchanging a and b and converting \uf0a3) gives \nus p(x,a\uf0dab) \uf0b3 p(x,a), and we are done. \n \nNote that in this verification we have appealed to all three of the axioms of van \nFraassen (the first one implicitly, the other two explicitly). If we simply drop any one \nof these three axioms, we allow in non-proto-probability functions. However, there \nmight be interesting ways of weakening the second or third of the van Fraassen \naxioms that leave us within the class.  \n \nVerification of closure property of the class of all proto-probability functions \n \nConditions P1\u2013P4 and P6 are immediate; P5 is a little less so, as follows. Suppose \uf0d8b \n\uf0ce Cn(a) and hp(x,a) \uf0a3\uf0a2 hp(x,b); we need to show that hp(x,a) \uf0a3\uf0a2 hp(x,a\uf0dab) \uf0a3\uf0a2 hp(x,b). \nIf p(x,a) \uf0a3 p(x,b) we have p(x,a) \uf0a3 p(x,a\uf0dab) \uf0a3 p(x,b) since p is a proto-probability \nfunction, and we need only apply order-preservation. Otherwise, by completeness of \n\uf0a3\uf020we have\uf020p(x,b) \uf0a3 p(x,a) so, again since p is a proto-probability function, p(x,b) \uf0a3 \np(x,b\uf0daa) \uf03d\uf020p(x,a\uf0dab) \uf0a3 p(x,a) and so by order-preservation hp(x,b) \uf0a3\uf0a2 hp(x,a\uf0dab) \uf0a3\uf0a2 \nhp(x,a). So by the supposition hp(x,a) \uf0a3\uf0a2 hp(x,b), transitivity of \uf0a3\uf0a2\uf020gives us hp(x,a) \uf0a3\uf0a2 \nhp(x,a\uf0dab) \uf0a3\uf0a2 hp(x,b) as desired.      \n \nFor Section 5.3. Comparison with Plausibility Measures, and Further Examples  \n \nComparison of proto-probability functions with Halpern's conditional plausibility \nmeasures \n \nComparison is rendered tricky by the fact that there are inter-connected differences \nregarding the relation over the target set, the domain of the function, and the \nregularities imposed on the function itself. For the relation \uf0a3\uf020over the target set D, we \nhave required it to be transitive and connected (thus also reflexive) but not necessarily \nanti-symmetric, while Halpern constrains it to be a partial ordering (reflexive, \ntransitive and anti-symmetric) but not necessarily connected. Regarding the domain, a \ntrivial difference is that conditional plausibility measures are defined in the field-of-\nsets rather than propositional mode; this is essentially a matter of presentation which \nwe can ignore. However, Halpern also follows R\u00e9nyi in allowing that the right \nargument need not range over the whole of the field. To be sure, we can complete the \nright domain by giving the function value 1 for the omitted right argument values, but \nthat forces reconsideration of Halpern's first axiom which, in the propositional mode, \nsays that p(\uf05e,a) \uf03d\uf020\uf030\uf02e To maintain consistency, that axiom needs to be restricted to \n'normal'  values of a, i.e. those whose left projection is not the one-place unit function. \nThat done, if we confine attention to those relations \uf0a3\uf020on the target set that satisfy \nboth sets of conditions, i.e. to linear relations, then Halpern's conditions are \nconsiderably weaker than ours, in that neither P5 nor P6 is required, and only part of \nP4, giving him a broader class.     \n34 \n \nAcknowledgements \n \nThis is a considerably revised and extended version of a paper with the same title, \n'Conditional probability in the light of qualitative belief change', published in Hykel \nHosni & Franco Montagna (eds), Probability, Uncertainty and Rationality. CRM \nSeries Vol 10, Edizioni della Scuola Normale Superiore, Pisa 2010, ISBN 978-88-\n7642-347-5. The author is grateful to the editors and publishers for kind permission to \ntake the material further.  \n \nThanks to Horacio Arl\u00f3 Costa, Jonny Blamey, Richard Bradley, Franz Dietrich, Peter \nG\u00e4rdenfors, Jim Hawthorne, Hykel Hosni, Franco Montagna, Rohit Parikh, Wlodek \nRabinowicz, Miklos Redei, Emil Weydert and four anonymous referees for valuable \ncomments on drafts, as well as to the participants in the LSE Popper Seminar of 12 \nOctober 2010 who commented on a presentation there. The author is also grateful to \nto Hykel Hosni, Jacek Malinowski and Miklos Redei for assistance in obtaining \ncopies of rather inaccessible texts of Bohlmann, Mazurkiewicz and R\u00e9nyi.  \n \nReferences \n \nAlchourr\u00f3n, Carlos, Peter G\u00e4rdenfors and David Makinson 1985. 'On the logic of \ntheory change: partial meet contraction and revision functions' The Journal of \nSymbolic Logic 50: 510-530. \nArl\u00f3 Costa, Horacio 2001. 'Bayesian epistemology and epistemic conditionals: on the \nstatus of export-import laws' The Journal of Philosophy 98: 555-593.  \nArl\u00f3 Costa, Horacio and Rohit Parikh 2005. 'Conditional probability and defeasible \ninference' Journal of Philosophical Logic 34: 97-119. \nBalc\u00e1zar, Jos\u00e9 L. 2010. 'Redundancy, deduction schemes, and minimum-size bases \nfor association rules' Logical Methods in Computer Science 6: 1-33. \nBohlmann, G. 1909. 'Die Grundbegriffe der Wahrscheinlichkeitsrechnung in ihrer \nAnwendung auf die Lebensversicherung' pages 244-278 of Atti del IV Congresso \nInternazionale dei Matematici, Roma 6-11 Aprile 1908 (Roma: Accademia dei \nLincei), vol. III. \nBoutilier, Craig 1995. 'On the revision of probabilistic belief states' Notre Dame \nJournal of Formal Logic 36: 158-183. \nCarnap, Rudolf 1950. Logical Foundations of Probability (Chicago University Press). \nCarnap, Rudolf 1952. The Continuum of Inductive Methods (Chicago University \nPress). \nCarnap, Rudolf 1971. 'A basic system of inductive logic' pages 33-165 of Carnap and \nJeffries eds Studies in Inductive Logic and Probability (University of California \nPress).  \nde Finetti, Bruno 1974. Theory of Probability (New York: Wiley). \nDubins, Lester E. 1975. 'Finitely additive conditional probabilities, conglomerability \nand disintegrations' Annals of Probability 3: 89-99. \n35 \nDubois, Didier and Henri Prade 1998. 'Possibility theory: qualitative and quantitative \naspects' pages 169-226 of D.M. Gabbay and P.Smets eds Handbook of  Defeasible \nReasoning and Uncertainty Management Systems, Vol I' (Dordrecht: Kluwer).  \nG\u00e4rdenfors, Peter 1984. 'The dynamics of belief as a basis for logic' British Journal \nfor the Philosophy of Science 35: 1-10. \nG\u00e4rdenfors, Peter 1986. 'The dynamics of belief: contractions and revisions of \nprobability functions' Topoi 5: 29-37. \nG\u00e4rdenfors, Peter 1988. Knowledge in Flux: Modeling the Dynamics of Epistemic \nStates (Cambridge Mass: MIT Press). \nH\u00e1jek, Alan 2003. 'What conditional probability could not be' Synthese 137: 273-323.  \nHailperin, Theodore 1988. 'The development of probability logic from Leibniz to \nMacColl' History and Philosophy of Logic 9: 131-191. \nHailperin, Theodore 1991. 'Probability logic in the twentieth century' History and \nPhilosophy of Logic 12: 71-110. \nHalpern, Joseph 2001. 'Plausibility measures: a general approach for representing \nuncertainty' Proceedings of the 17\nth\n Joint Conference on AI (IJCAI 2001) (San \nFrancisco: Morgan Kaufmann). \nHalpern, Joseph (to appear). 'Lexicographic probability, conditional probability, and \nnonstandard probability' Games and Economic Behaviour. Meanwhile, see \nhttp:\/\/www.c.s.cornell.edu\/home\/halpern\/papers\/lex.pdf \nHarper, W.L. 1975. 'Rational belief change, Popper functions and counterfactuals' \nSynthese 30: 221-262. Reprinted with minor editorial changes in pages 73-115 of \nW.L. Harper and C.A. Hooker eds Foundations of Probability, Statistical Inference, \nand Statistical Theories of Science, Vol I (Dordrecht: Reidel).  \nHarper, W.L. 1976. 'Rational conceptual change' pages 462-494 of PSA: Proceedings \nof the Biennial Meeting of the Philosophy of Science Association 1976, Vol. II \n(University of Chicago Press). \nHawthorne, James 1996. 'On the logic of nonmonotonic conditionals and conditional \nprobabilities' Journal of Philosophical Logic 25: 185-218. \nHawthorne, James and David Makinson 2007. 'The quantitative\/qualitative watershed \nfor rules of uncertain inference' Studia Logica 86: 249-299.  \nHosiasson-Lindenbaum 1940. 'On confirmation' The Journal of Symbolic Logic 4: \n133-148. \nKoons, Robert 2009. 'Supplement to Defeasible Reasoning' Stanford Encyclopedia of \nPhilosophy http:\/\/plato.stanford.edu \nKoopman, Bernard O. 1940. 'The axioms and algebra of intuitive probability' The \nAnnals of Mathematics 41: 269-292. \nKoopman, Bernard O. 1940a. 'The bases of probability' Bulletin of the American \nMathematical Society 46: 763-774. Accessed 05 April 2009. \nLeblanc, Hugues 1989. 'Popper's formal contributions to probability theory' pages \n341-367 of M.A. Notturno ed. Perspectives on Psychologism (Leiden: E.J. Brill). \nLeblanc, Hugues and Peter Roeper 1989. 'On relativizing Kolmogorov\u2019s absolute \nprobability functions' Notre Dame Journal of Formal Logic 30: 485-512.  \n36 \nLindstr\u00f6m, Sten and Wlodzimierz Rabinowicz 1989. 'On probabilistic representation \nof non-probabilistic belief revision' Journal of Philosophical Logic 18: 69-101. \nMakinson, David 1997. 'Screened revision' Theoria 63: 14-23. \nMakinson, David 2005. Bridges from Classical to Nonmonotonic Logic (London: \nCollege Publications). \nMakinson, David 2007. 'Completeness theorems, representation theorems: what\u2019s the \ndifference?' In Hommage \u00e0 Wlodek: Philosophical Papers dedicated to Wlodek \nRabinowicz, ed. R\u00f8nnow-Rasmussen et al. www.fil.lu.se\/hommageawlodek \nMakinson, David (to appear). 'Logical questions behind the lottery and preface \nparadoxes: lossy rules for uncertain inference' Synthese, issue commemorating Henry \nKyburg. \nMazurkiewicz, S. 1932. 'Zur Axiomatik der Wahrscheinlichkeitsrechnung' Comptes \nrendus des s\u00e9ance de la Soci\u00e9t\u00e9 des Sciences et des Lettres de Varsovie \n(Sprawozdania z posiedze\u0144 Towarzystwa Naukowego Warszawskiego) 25: 1-4. \nMcGee, Vann 1994. 'Learning the impossible' pages 179-199 of E. Eells and Brian \nSkyrms eds Probability and Conditionals: Belief Revision and Rational Decision \n(Cambridge University Press). \nParis, Jeff & Richard Simmonds, R. (2009). 'O is not enough' Review of Symbolic \nLogic, 2: 298-309. \nPeppas, Pavlos 2007. 'Belief revision' chapter 8 of F. van Harmelen, V. Lifschitz, B. \nPorter eds Handbook of Knowledge Representation (Amsterdam: Elsevier).  \nPopper, Karl 1959. The Logic of Scientific Discovery second edition (New York: \nBasic Books). \nR\u00e9nyi, Alfr\u00e9d 1955. 'On a new axiomatic theory of probability' Acta Mathematica \nAcademiae Scientiae Hungaricae 6: 268-335. \nRenyi, Alfr\u00e9d 1970. Foundations of Probability Theory (San Francisco: Holden-Day). \nR\u00e9nyi, Alfr\u00e9d 1970a. Probability Theory (Amsterdam: North-Holland). \nRoeper, Peter and Hugues Leblanc 1999. Probability Theory and Probability Logic \n(Toronto: University of Toronto Press). \nSeidenfeld, T, M.J. Schervish and J.B. Kaldane 1998. 'Non-conglomerability for \nfinite-valued, finitely additive probability' Sankya Series A 60.3: 476-491. \nSimmonds, Richard 2010. 'On Horn closure conditions for probabilistic consequence \nrelations' (PhD thesis, University of Manchester).  \nSpohn, Wolfgang 1986. 'The representation of Popper measures' Topoi 5: 69-74. \nSpohn, Wolfgang 2009. 'A survey of ranking theory', pages 185-228 of Franz Huber \net al eds Degrees of Belief (New York: Springer).   \nStalnaker, R.C. 1970. 'Probability and conditionals' Philosophy of Science 37: 64-80, \nreprinted in pages 107-128 of W.L. Harper et al eds Ifs (Dordrecht: Reidel, 1981). \nvan Fraassen, Bas 1976. 'Representation of conditional probabilities' Journal of \nPhilosophical Logic 5: 417-430. \nvan Fraassen, Bas 1995. 'Fine-grained opinion, probability, and the logic of full belief' \nJournal of Philosophical Logic 24: 349-377. \n37 \nWeydert, Emil 1994. 'General belief measures' Uncertainty in Artificial Intelligence \n94: 575-582 (San Francisco: Morgan Kaufmann). \n \n \nDepartment. of Philosophy, Logic and Scientific Method  \nLondon School of Economics  \nHoughton Street, London WC2A 2AE, United Kingdom  \ndavid.makinson@gmail.com \n \nNote: This version contains some minor corrections and additions to the text as \npublished \n \n \n \n"}
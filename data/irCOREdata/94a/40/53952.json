{"doi":"10.1109\/GRC.2008.4664729","coreId":"53952","oai":"oai:eprints.lincoln.ac.uk:2803","identifiers":["oai:eprints.lincoln.ac.uk:2803","10.1109\/GRC.2008.4664729"],"title":"An immune algorithm based fuzzy predictive modeling mechanism using variable length coding and multi-objective optimization allied to engineering materials processing","authors":["Chen, Jun","Mahfouf, M."],"enrichments":{"references":[{"id":862048,"title":"A Computationally Efficient Evolutionary Algorithm for Real-Parameter Optimization\u201d,","authors":[],"date":"2002","doi":"10.1162\/106365602760972767","raw":null,"cites":null},{"id":18448413,"title":"A Computationally Efficient Evolutionary Algorithm for Real-Parameter Optimization\uff94\u201d,","authors":[],"date":"2002","doi":"10.1162\/106365602760972767","raw":"Deb, K., Anand, A., Joshi, D., \uff93\u201cA Computationally Efficient Evolutionary  Algorithm  for  Real-Parameter  Optimization\uff94\u201d, Evolutionary Computation, Vol. 10 (4), MIT Press, 2002, pp. 371-395.","cites":null},{"id":861476,"title":"A K-Means Clustering Algorithm\u201d,","authors":[],"date":"1979","doi":"10.2307\/2346830","raw":null,"cites":null},{"id":18448410,"title":"A K-Means Clustering Algorithm\uff94\u201d,","authors":[],"date":"1979","doi":"10.2307\/2346830","raw":"Hartigan,  J.  A.,  Wong,  M.  A.,  \uff93\u201cA  K-Means  Clustering Algorithm\uff94\u201d, Applied Statistics, Vol. 28 (1), 1979, pp. 100-108.","cites":null},{"id":862534,"title":"A Systematic Neuro-Fuzzy Modeling Framework With Application to Material Property Prediction\u201d,","authors":[],"date":"2001","doi":"10.1109\/3477.956039","raw":null,"cites":null},{"id":18448415,"title":"A Systematic Neuro-Fuzzy Modeling Framework With Application to Material Property Prediction\uff94\u201d,","authors":[],"date":"2001","doi":"10.1109\/3477.956039","raw":"Chen, M. Y., Linkens, D. A., \uff93\u201cA Systematic Neuro-Fuzzy Modeling  Framework  With  Application  to  Material  Property Prediction\uff94\u201d,  IEEE  Transactions  on  Systems,  Man,  and Cybernetics, Vol. 31 (5), 2001, pp.781-790","cites":null},{"id":861241,"title":"About the Use of Fuzzy Clustering Techniques for Fuzzy Model\u201d, Fuzzy Sets and Systems,","authors":[],"date":"1999","doi":"10.1016\/s0165-0114(97)00276-5","raw":null,"cites":null},{"id":18448409,"title":"About the Use of Fuzzy Clustering Techniques for Fuzzy Model\uff94\u201d, Fuzzy Sets and Systems,","authors":[],"date":"1999","doi":"10.1016\/s0165-0114(97)00276-5","raw":"Gomez-Skarmeta, A. F., Delgado, M., Vila, M. A., \uff93\u201cAbout the  Use  of  Fuzzy  Clustering  Techniques  for  Fuzzy  Model\uff94\u201d, Fuzzy Sets and Systems, Vol. 106, 1999, pp. 179-188.","cites":null},{"id":861009,"title":"ANFIS: Adaptive-Network-Based Fuzzy Inference System\u201d,","authors":[],"date":"1993","doi":"10.1109\/21.256541","raw":null,"cites":null},{"id":18448408,"title":"ANFIS: Adaptive-Network-Based Fuzzy Inference System\uff94\u201d,","authors":[],"date":"1993","doi":"10.1109\/21.256541","raw":"Jang,  J.-S.R.,  \uff93\u201cANFIS:  Adaptive-Network-Based  Fuzzy Inference  System\uff94\u201d,  IEEE  Transactions  on  Systems,  Man  and Cybernetics, Vol. 23(3), 1993, pp. 665-685.","cites":null},{"id":862276,"title":"Artificial Immune Systems as a Bioinspired Optimization Technique and Its Engineering Applications\u201d, Artificial Immune Systems and Natural Computing: Applying Complex Adaptive Technologies,","authors":[],"date":"2007","doi":"10.4018\/978-1-60566-310-4.ch002","raw":null,"cites":null},{"id":18448414,"title":"Artificial Immune Systems as a Bioinspired Optimization Technique and Its Engineering Applications\uff94\u201d, Artificial Immune Systems and Natural Computing: Applying Complex Adaptive Technologies,","authors":[],"date":"2007","doi":"10.4018\/978-1-60566-310-4.ch002","raw":"Chen, J., Mahfouf, M., \uff93\u201cArtificial Immune Systems as a Bioinspired  Optimization  Technique  and  Its  Engineering Applications\uff94\u201d,  Artificial  Immune  Systems  and  Natural Computing: Applying Complex Adaptive Technologies, 2007 (to be appear).","cites":null},{"id":861662,"title":"FCM: The Fuzzy Cmeans Clustering Algorithm\u201d,","authors":[],"date":"1984","doi":"10.1016\/0098-3004(84)90020-7","raw":null,"cites":null},{"id":18448411,"title":"FCM: The Fuzzy Cmeans Clustering Algorithm\uff94\u201d,","authors":[],"date":"1984","doi":"10.1016\/0098-3004(84)90020-7","raw":"Bezdek, J. C., Ehrlich, R., Full, W., \uff93\u201cFCM: The Fuzzy Cmeans Clustering Algorithm\uff94\u201d, COMP. GEOSCI., Vol. 10 (2-3), 1984, pp. 191-203.","cites":null},{"id":861939,"title":"Fuzzy Model Identification Based on Cluster Estimation\u201d,","authors":[],"date":"1994","doi":"10.1109\/fuzzy.1994.343644","raw":null,"cites":null},{"id":18448412,"title":"Fuzzy Model Identification Based on Cluster Estimation\uff94\u201d,","authors":[],"date":"1994","doi":"10.1109\/fuzzy.1994.343644","raw":"Chiu,  S.,  \uff93\u201cFuzzy  Model  Identification  Based  on  Cluster Estimation\uff94\u201d, J. of Intelligent & Fuzzy Systems, Vol. 2 (3), 1994","cites":null},{"id":860772,"title":"Genetic Fuzzy Systems: Evolutionary Tuning and Learning of Fuzzy Knowledge Bases, World Scientific,","authors":[],"date":"2001","doi":"10.1142\/4177","raw":"Cordon, O., Herrera, F., Hoffann, F., Magdalena, L., Genetic Fuzzy  Systems:  Evolutionary  Tuning  and  Learning  of  Fuzzy Knowledge Bases, World Scientific, Singapore, 2001.","cites":null},{"id":862759,"title":"Multi-objective Hierarchical Genetic Algorithm for Interpretable Fuzzy Rule-based Knowledge Extraction\u201d,","authors":[],"date":"2005","doi":"10.1016\/j.fss.2004.07.013","raw":null,"cites":null},{"id":18448416,"title":"Multi-objective Hierarchical Genetic Algorithm for Interpretable Fuzzy Rule-based Knowledge Extraction\uff94\u201d,","authors":[],"date":"2005","doi":"10.1016\/j.fss.2004.07.013","raw":"Wang, H. L., Kwong, S., Jin, Y. C., Wei, W., Man, K. F., \uff93\u201cMulti-objective  Hierarchical  Genetic  Algorithm  for Interpretable Fuzzy Rule-based Knowledge Extraction\uff94\u201d, Fuzzy Sets and Systems, Vol. 149 (1), 2005, pp. 149-186. (b) (c) (a)","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2008","abstract":"In this paper, a systematic multi-objective fuzzy\\ud\nmodeling approach is proposed, which can be regarded\\ud\nas a three-stage modeling procedure. In the first stage, an\\ud\nevolutionary based clustering algorithm is developed to\\ud\nextract an initial fuzzy rule base from the data. Based on\\ud\nthis model, a back-propagation algorithm with momentum\\ud\nterms is used to refine the initial fuzzy model. The refined\\ud\nmodel is then used to seed the initial population of an\\ud\nimmune inspired multi-objective optimization algorithm\\ud\nin the third stage to obtain a set of fuzzy models with\\ud\nimproved transparency. To tackle the problem of\\ud\nsimultaneously optimizing the structure and parameters, a\\ud\nvariable length coding scheme is adopted to improve the\\ud\nefficiency of the search. The proposed modeling approach\\ud\nis applied to a real data set from the steel industry.\\ud\nResults show that the proposed approach is capable of\\ud\neliciting not only accurate but also transparent fuzzy\\ud\nmodels","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/53952.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/2803\/1\/An_Immune_Algorithm.pdf","pdfHashValue":"ca9c883023f732b2dcef4ed3a706c9c30c3cc43a","publisher":"Institution of Electronic and Electrical Engineers","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:2803<\/identifier><datestamp>\n      2017-08-09T11:35:34Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F47:6A6163735F47373030<\/setSpec><setSpec>\n      74797065733D636F6E666572656E63655F6974656D<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/2803\/<\/dc:relation><dc:title>\n        An immune algorithm based fuzzy predictive modeling mechanism using variable length coding and multi-objective optimization allied to engineering materials processing<\/dc:title><dc:creator>\n        Chen, Jun<\/dc:creator><dc:creator>\n        Mahfouf, M.<\/dc:creator><dc:subject>\n        G700 Artificial Intelligence<\/dc:subject><dc:description>\n        In this paper, a systematic multi-objective fuzzy\\ud\nmodeling approach is proposed, which can be regarded\\ud\nas a three-stage modeling procedure. In the first stage, an\\ud\nevolutionary based clustering algorithm is developed to\\ud\nextract an initial fuzzy rule base from the data. Based on\\ud\nthis model, a back-propagation algorithm with momentum\\ud\nterms is used to refine the initial fuzzy model. The refined\\ud\nmodel is then used to seed the initial population of an\\ud\nimmune inspired multi-objective optimization algorithm\\ud\nin the third stage to obtain a set of fuzzy models with\\ud\nimproved transparency. To tackle the problem of\\ud\nsimultaneously optimizing the structure and parameters, a\\ud\nvariable length coding scheme is adopted to improve the\\ud\nefficiency of the search. The proposed modeling approach\\ud\nis applied to a real data set from the steel industry.\\ud\nResults show that the proposed approach is capable of\\ud\neliciting not only accurate but also transparent fuzzy\\ud\nmodels.<\/dc:description><dc:publisher>\n        Institution of Electronic and Electrical Engineers<\/dc:publisher><dc:date>\n        2008<\/dc:date><dc:type>\n        Conference or Workshop contribution<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/2803\/1\/An_Immune_Algorithm.pdf<\/dc:identifier><dc:identifier>\n          Chen, Jun and Mahfouf, M.  (2008) An immune algorithm based fuzzy predictive modeling mechanism using variable length coding and multi-objective optimization allied to engineering materials processing.  In: Granular Computing, 2008. GrC 2008. IEEE International Conference on, 26-28 August 2008, Hangzhou, China.  <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/GRC.2008.4664729<\/dc:relation><dc:relation>\n        10.1109\/GRC.2008.4664729<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/2803\/","http:\/\/dx.doi.org\/10.1109\/GRC.2008.4664729","10.1109\/GRC.2008.4664729"],"year":2008,"topics":["G700 Artificial Intelligence"],"subject":["Conference or Workshop contribution","PeerReviewed"],"fullText":"An Immune Algorithm Based Fuzzy Predictive Modeling Mechanism using \nVariable Length Coding and Multi-objective Optimization Allied to \nEngineering Materials Processing \n \nJun Chen and Mahdi Mahfouf \nThe University of Sheffield, UK, Department of Automatic Control and Systems Engineering \nInstitute for Microstructural and Mechanical Process Engineering: \n The University of Sheffield (IMMPETUS) \n{jun.chen, m.mahfouf}@sheffield.ac.uk \n \n \nAbstract \n \nIn this paper, a systematic multi-objective fuzzy \nmodeling approach is proposed, which can be regarded \nas a three-stage modeling procedure. In the first stage, an \nevolutionary based clustering algorithm is developed to \nextract an initial fuzzy rule base from the data. Based on \nthis model, a back-propagation algorithm with momentum \nterms is used to refine the initial fuzzy model. The refined \nmodel is then used to seed the initial population of an \nimmune inspired multi-objective optimization algorithm \nin the third stage to obtain a set of fuzzy models with \nimproved transparency. To tackle the problem of \nsimultaneously optimizing the structure and parameters, a \nvariable length coding scheme is adopted to improve the \nefficiency of the search. The proposed modeling approach \nis applied to a real data set from the steel industry. \nResults show that the proposed approach is capable of \neliciting not only accurate but also transparent fuzzy \nmodels.  \n \n \n1. Introduction \n \nFuzzy Rule-Based Systems (FRBS) have the additional \nability to integrate human expertise in the form of vague \nor imprecise statements rather than crisp mathematics, for \nmany real-world systems\u0092\u2019 knowledge can only be \ndescribed by experts with nature language. Depending on \nwhat degree to which such expertise is involved, fuzzy \nmodeling can belong to white box, black box or grey box \nmodeling. Previous researches on fuzzy modeling are \nmainly concerned with how to synthesis a rule-base with \ndomain-dependent knowledge from human experts, such \nas operators, and hence render the task of tuning the \nparameters associated with the antecedent and consequent \nparts as an optimization problem, e.g. recursive least-\nsquares or gradient-based method. Without the tuning \nprocess following the synthesis step, the above approach \nis indeed equivalent to white-box modeling and the built \nmodel can be regarded as descriptive FRBS [1], which \ngives rise to four limitations: 1) often, expert knowledge \nis not available or is limited ; 2) it is very hard to handle \nproblems with a significant amount of data to be \nprocessed and analysed;  3) it suffers from the curse of \ndimensionality; 4) the way to design such a fuzzy system \nis not domain-independent and thus no systematic design \nprocedure can be followed. In all these cases, pure \nknowledge extraction from experts fails to provide a \nsatisfactory solution. However, discovering knowledge \nfrom data can help in overcoming the aforementioned \nlimitations by augmenting FRBS with an additional \nlearning ability. \nIn the past two decades, many successes in the \nhybridization of FRBS and learning methods have been \nregistered. The most representative one must be the so-\ncalled neuro-fuzzy system, which incorporates learning \nmethods usually used in neural networks into FRBS [2].  \nAlmost at the same time, attempts of hybridizing \nclustering methods with fuzzy systems were carried out \nand led very promising results [3]. The aim of these types \nof hybridization is to automatically induce rules from \nlarge collections of learning data. Despite the great \nsuccess using the aforementioned paradigms, the \nfollowing limitations have been identified: 1) the designer \nstill needs to set the granulation level or the number of \nclusters; 2) the need to set start points for clustering and \nneural networks; 3) most importantly, the hence elicited \nFRBS can only be described as approximate FRBS [1] \nrather than the descriptive one. The main drawback \ncompared to the descriptive one is the degradation in \nterms of interpretability of the rule base due to the \nautomatic learning process, which yields overlapped \nfuzzy sets. Although such approximate FRBS retains \nsome interpretability, it may become more black-box \noriented although often its performance is very much \nimproved compared to the descriptive one.  \nThe shift between the descriptive and approximate \nFRBS represents two extremes of designing fuzzy models. \nThe last two decades have witnessed the popularity of the \nlatter by compromising the interpretability with accuracy, \nwhich deviates from the original intention of FRBS. In the \nlight of the above discussion, the main thrust of this paper \nis to present a systematic way of building FRBS, which \npreserves some degree of interpretability during the \nautomatic learning process, while at the same time \nretaining a high level of accuracy. To this aim, section 2 \ndescribes a global evolutionary based clustering method, \nwhich is developed to create an initial model with the \nmaximum allowable number of rules. Section 3 presents a \nconstrained back-propagation (BP) algorithm with \nmomentum terms, which serves to improve the accuracy \nof the initial FRBS. An immune inspired multi-objective \noptimization algorithm is incorporated in the last stage by \nrealizing that the increased interpretability is often a \ncontradictory goal against the objective of the accuracy, \nwhich can be found in section 4. To account for the need \nof simultaneously optimizing rule base structure and \nmembership parameters, a variable length coding scheme \nis devised and presented in section 4. Finally, the \nexperimental results for predicting the Tensile Strength \n(TS) of alloy steels are presented in section 5.   \n \n2. First stage: an evolutionary based \nclustering algorithm-G3Kmeans \n \nClustering is incorporated into fuzzy modeling \nespecially when the numerical data has a very high \ndimensionality. The purpose is to extract the relationship \nbetween independent system variables so that the initial \nfuzzy structure with only a few rules can be obtained. \nAmong many methods, attempts have been made to \nobtain clusters by minimizing the within-cluster-distance \nand maximizing the inter-cluster-distance, which results \nin points within the identified clusters being as close to \neach other as possible. K-means clustering [4] and fuzzy \nC-means [5] are two instances of this family. By \nunderstanding the nature of fuzzy modeling and fuzzy \npartition, it is reckoned that the method based on this idea \nis more close to the modeling requirement since one \nwishes to isolate data points into sub-regions so that each \none can be described by a localized fuzzy rule.  \nThree most often used clustering algorithms for fuzzy \npartition are K-means, fuzzy C-means and subtractive \nclustering [6]. The first two are found to be very sensitive \nto the initial points and often get stuck at some local \noptima. The third one is found to only produce near \noptimal partitions and is usually used as a method to \nestimate the number of clusters as a priori for other \nclustering algorithms. Hence, an evolutionary based \nclustering algorithm-G3Kmeans, representing the \nhybridization of G3PCX [7] and K-means, is put forward \nin this paper to overcome such drawbacks. The purpose of \nthe hybridization is to utilize the global search capability \nof GA to find a set of cluster centers so that a within-\ncluster-distance criterion is minimized. By doing so, the \nsensitivity to the initial settings is avoided in the first \nplace, and more importantly a good global fuzzy partition \nis extracted, which can ease the optimization in the \nsecond stage. Since G3PCX is a real coded GA, it is very \nefficient in terms of solving this real parameter \noptimization problem. The detailed steps included in \nG3Kmeans are as follows. \n(1) Initialization: The randomly generated k cluster \ncenters are encoded in each chromosome in a \nconcatenated form. P chromosomes are generated in \nthe initial population.  \n(2) Assigning data points: Each data point is assigned to \none cluster with the center of Cj using equation (1): \n{ )1(\n,,2,1,;,,2,1\n:\nilklitm\nCXCX\nifCX lmimim \u2260==\n\u2212<\u2212\n\u2208\n!!\n \nWhere, || is the Euclidean norm and t is the number of \ndata samples. After the assignment, cluster centers \nencoded in the chromosome are updated by \ncalculating the mean value of each cluster. \n(3) Fitness computation: the fitness value of each \nindividual is calculated using equation (2): \n)2(),...,,(\n1\n2\n21 \u00a6 \u00a6\n= \u2208\n\u2212=\nk\nl Cx\nlmk\nlm\nCXCCC\u03d6  \nWhere, \u03d6 is a within-cluster-distance metric to be \noptimized (minimized), and kCCC ,..., 21  are k \ncluster centers. \n(4) Parent-Centric Crossover (PCX): Generate \u03bb  \noffspring from the \u00b5 parents using the Parent-Centric \nCrossover [9]. \n(5) Fitness computation: the cluster centres and fitness \nvalues of the offspring are updated and calculated \nagain as what have been done in the step 2 and 3 \naccordingly. \n(6) Parents to be replaced: choose two parents at \nrandom from the population P. \n(7) Replacement: From the combined subpopulation of \ntwo chosen parents and \u03bb created offspring, choose \nthe best two solutions and replace the chosen two \nparents (in step 6) with these solutions. \n(8) Iteration: the aforementioned steps from step 2 are \nrepeated for a specified generations, and the final \nsolution is the one with the smallest objective value at \nthe end of the execution.  \nAs will be seen in Section 3, the Gaussian membership \nfunction is used. In such a case, the identified cluster \ncentres C correspond directly to the centers of Gaussian \nmembership functions. The spread of the Gaussian \nmembership function is obtained by first calculating the U \nmatrix as follows: \n)3(),(\n1\n1\n\u2212\n=\n\u00b8\u00b8\u00b9\n\u00b7\n\u00a8\u00a8\u00a9\n\u00a7\n\u2212\n\u2212\n= \u00a6\nk\nl lm\nim\nCX\nCX\nmiU  \nWhere, U specifies the degrees of data points belonging to \neach cluster center.  Spread ji\u03c3 is then calculated as \nfollows: \n( )\n( )( ) )4(,2,1,log2max\n2\ntm\nmiU\nCX ji\nj\nmj\ni\n!=\u00b8\n\u00b8\n\u00b9\n\u00b7\n\u00a8\n\u00a8\n\u00a9\n\u00a7\n\u22c5\n\u2212\u2212\n=\u03c3  \nWhere, j indicates the dimension of the spread for the ith \ncluster.  With centres and spreads obtained from the \nclustering algorithm, the Gaussian membership function \ncan be specified as follows: \n( ) )5(\n2\n1exp\n2\n\u00b8\n\u00b8\n\u00b9\n\u00b7\n\u00a8\n\u00a8\n\u00a9\n\u00a7\n\u00b8\u00b8\u00b9\n\u00b7\n\u00a8\u00a8\u00a9\n\u00a7\n\u2212\n\u22c5\u2212= j\ni\nj\ni\nj\nmj\nmA\ncxxj\ni \u03c3\n\u00b5  \n \n3. Second stage: refining the initial model \nwith a back-propagation algorithm  \n \nAfter the first stage, a FRBS with the pre-specified \nnumber of rules is extracted from the numerical data. This \ninitial fuzzy model is not optimal from two perspectives: \n1) the structure of FRBS is not optimal as far as the \ninterpretability is concerned; 2) the membership function \nparameters need to be tuned further. A constrained back-\npropagation (BP) algorithm is thus utilized to first \nimprove the accuracy of the initial FRBS so that a \n\u0091\u2018vaccine model\u0092\u2019 [8] can be obtained for the further \noperation in the multi-objective optimization stage.   \nThe well-known problem associated with BP lies in its \nlocal search limitation. However, this problem is \nsomehow relaxed by using a global clustering algorithm \nin the first stage, which enhances its ability of locating \ngood global FRBS in the sense that a within-cluster-\ndistance is globally minimized. If the centre of average \ndefuzzification, production inference rule, singleton \nfuzzification and Gaussian membership function are \nemployed, a fuzzy system can be represented as follows: \n)6()|(\n1\n1 \u03b8\n\u00b5\n\u00b5\nm\ncrisp\nqk\ni i\nk\ni i\nq\nicrisp\nq Xy\nb\ny\n\u2206\n=\n=\n=\n\u22c5\n=\n\u00a6\n\u00a6  \nWhere, q is the number of outputs and is set as 1 in this \nwork; k is the number of rules in the rule base; b is the \ncentre of the output membership functions; \ni\u00b5 is the \nmatching degree of the ith rule as described as follows: \n)7()()()()( 21 21 nmAmAmAmi xxxX niii \u00b5\u00b5\u00b5\u00b5 \u22c5\u22c5\u22c5= !  \n\u03b8 is the parameter vector subject to the minimization of  \nthe mean square error. Since the convergence properties \nof BP can sometimes be improved via the additions of \n\u0091\u2018momentum terms\u0092\u2019, the following parameter update laws \nare derived: \n)8()1()()()1( 1\n1 )(\n)(\n1 \u2212\u2206\u22c5+\u22c5\u22c5\u2212=+ \u00a6\n=\ntbttbtb ik\ni ti\nti\nmii \u03b2\u00b5\n\u00b5\n\u03b5\u03bb  \n)9()1(\n)(\n)()()1( 2\n1 )(\n)(\n2 \u2212\u2206\u22c5+\n\u22c5\n\u22c5\u22c5\u2212=+\n\u00a6\n=\ntc\ntq\nttctc jik\ni ti\nti\nm\nj\ni\nj\ni \u03b2\u00b5\n\u00b5\n\u03b5\u03bb\n)10()1(\n)(\n)()()1( 3\n1 )(\n)(\n3 \u2212\u2206\u22c5+\n\u22c5\n\u22c5\u22c5\u2212=+\n\u00a6\n=\nt\ntr\nttt jik\ni ti\nti\nm\nj\ni\nj\ni \u03c3\u03b2\u00b5\n\u00b5\n\u03b5\u03bb\u03c3\u03c3\nwhere,       ( )\n( ) ( )( )\n)11(\n)1()()1(\n)|(\n)(\n)|(\n)|(\n3\n2\n2\n\u2212\u2212=\u2212\u2206\n\u2212\n\u22c5\u2212=\n\u00b8\u00b8\u00b9\n\u00b7\n\u00a8\u00a8\u00a9\n\u00a7\n\u2212\n\u22c5\u2212=\n\u2212=\ntbtbtb\ncxXybr\ncxXybq\nyxy\niii\nj\ni\nj\ni\nj\nm\nm\ncrisp\ni\nj\ni\nj\ni\nj\nm\nm\ncrisp\ni\nmm\ncrisp\nm\n\u03c3\n\u03b8\n\u03c3\n\u03b8\n\u03b8\u03b5\n \n     As one can see from Equations 8 to 10, there are no \nconstraints for updating these parameters. Hence, during \nthe course of the optimization, centres are likely to be \nplaced outside the boundaries. Although this does not \naffect the ultimate accuracy of FRBS, it does cause \nconfusion for the users when assigning linguistic labels. \nHence, in this work, a constraint handling scheme is \nadded, which checks the boundary violation for centres \nduring each iteration and drive any violated centres back \nto the boundaries. The step size \u03bb  and the gain of \nmomentum term\u03b2 are all set to 0.035 in this work. \n \n4. Third stage: multi-objective fuzzy \nmodeling  \n \nAn optimal FRBS could be obtained by optimizing the \nrule-base structure and membership function parameters \neither simultaneously or separately. The previous two \nstages can be viewed as the instances of a separate \nstructure and parameter learning. The drawbacks of the \nseparate learning are as follows: 1) only a sub-optimal \nresult may be obtained since the structure and parameters \nneed to cooperate to provide a satisfactory FRBS; 2) the \nseparate structure learning relies strongly on the human \npreference. Hence, only problem 2, namely the need to set \nthe start points, as mentioned in the Section 1 would have \nbeen solved by using G3Kmeans. One still has to set the \ninitial granulation level and only an approximate FRBS \ncan be elicited.  \nTo improve the interpretability of such an approximate \nFRBS, authors in [9] performed model simplifications and \na fine-tuning operation is required. It is still a separate \nlearning process so that model simplifications rely heavily \non the pre-specified thresholds according to the designer\u0092\u2019s \npreference. In [10], authors proposed a hierarchical \nscheme to evolve both parts. However, a rule matrix is \nrequired, which would be vulnerable to high dimensional \nproblems due to the exponential increase in the matrix \ndimension.  \nThe proposed approach in this work utilizes a multi-\nobjective optimization framework and a variable length \ncoding scheme, which does not suffer from the curse of \ndimensionality. A set of FRBS representing the trade-offs \nof interpretability and accuracy are obtained through a \nsingle run, and only the maximum number of rules is \nrequired as a priori, which reduces any user intervention \nduring the whole design process to a minimum level.  \n \n4.1. A framework of the immune inspired multi-\nobjective fuzzy modeling \n \nFig. 1. shows the framework of the proposed modeling \napproach which is based on [8], in which the authors have \nproved that a multi-stage optimization procedure can \nreduce the computational load of the whole search process \ngreatly. G3Kmeans and BP in this paper function exactly \nthe same as the first step of that procedure to extract the \nso-called \u0091\u2018vaccine model\u0092\u2019.  \n \n \nFig. 1. The framework of the proposed immune based \nfuzzy predictive modeling methodology \n \nA Population Adaptive based Immune Algorithm \n(PAIA) [8] is utilized in the third stage to optimize both \nthe structure and parameters simultaneously. Activation \ncalculates the affinity (fitness) for each Antibody \n(solution) so that an adaptive number of clones can be \nproduced. Affinity maturation mutates the clones so that \nmore search space can be explored. Reselection selects \ngood candidate solutions from the combined parents and \nclones to provide a selection pressure to effectively drive \nthe candidate solutions towards the Pareto front over \nmany iteration steps; Network suppression is used to \nregulate the dynamics of the population so that it can \nadapt to the problem. Although immune algorithms \naccidentally resemble some characteristics of Genetic \nAlgorithms, a more efficient search could be induced \nsince the population is adaptive. Variable length coding \nand model simplifications are added to the original PAIA \nto account for the structure optimization as will be \nexplained in the next two sub-sections. Further details on \nPAIA can be found in [8]. \n \n4.2. Variable length coding scheme \n \nA variable length coding, which only encodes effective \nrules, is employed in this work to account for the \nefficiency of the search and the curse of dimensionality. \nSince only the parameters of effective rules are encoded, \nthe increase of the code length is only linear to the \ndimension, which is not the case for the hierarchical \ncoding. Some previous works [1] fixed the length of \ncoding according to the maximum allowable number of \nrules, and filled the empty places with random values if \nFRBS has fewer rules as shown in Fig. 2.  \n \n2\n3\n2\n3\n2\n2\n2\n2\n2\n1\n2\n1\n2 |;; bccc \u03c3\u03c3\u03c3\n3\n3\n3\n3\n3\n2\n3\n2\n3\n1\n3\n1\n3 |;; bccc \u03c3\u03c3\u03c3  \nFig. 2. Example of the variable length coding for a \ntwo-input system: (a) three-rule FRBS; (b) six-rule \nFRBS \n \nSince most heuristic search methods rely on a distance \ncalculation (interaction between individuals) in the \nphenotypic space, which is the major force to direct the \nsearch, an ineffective optimization may be induced \nbecause some parts of the long FRBS may interact with \nthe random part of the one with fewer rules. So a method \nis needed to address the problem of individuals with \ndifferent lengths. Unconstraint optimization causes \nanother problem as shown in Fig. 3, where FRBS1 and \nFRBS2 are exactly the same. However, because of the \nblind search mechanism, values encoded in the Rules 1 \nand 7 are different within the two FRBSs. In a different \ninstance, rules may be deleted, e.g. Rule7 in FRBS2. \nThus, a very large distance is produced as the affinity \nvalue if the conventional distance measure is used in such \na case. In PAIA this would lead to a very large mutation, \nhowever, only a small or non jump is needed.  \n \n \nFig. 3. The problems associated with FRBS having \ndifferent rule lengths and unconstrained optimization \nTo tackle the aforementioned problems, a new distance \nindex is proposed to calculate the affinity for PAIA in the \nactivation step. The basic idea is to find the distance of \nthe closest rules in different FRBSs rather than the \ndistance of corresponding rules. Hence, Rule1 in FRBS1 \nwill be paired with Rule7 in FRBS2. The mathematical \ndescription of the idea is as follows: \n( ) ( )\n)12(\n)21(\n)()()()(\n),(\n2\n12\n1\n22\n1\n11\n1\n11\nkkrl\nlRlRlRlR\nRRdist\nk\ni\nrl\nl\nCi\nj\ni\nk\nk\ni\nrl\nl\nCi\nk\ni\nj\nkj\n+\u22c5\n\u2212+\u2212\n=\n\u00a6\u00a6\u00a6\u00a6\n=\n=\n=\n=  \nWhere,\nkj RR , are two FRBS with k1 and k2 rules; rl is the \nlength of the rule; 1Ci\nkR )(\n2Ci\njR represent the closest rule in \nkR )( jR  with respect to the i1th (i2th) rule in jR )( kR . \nThe above distance index is used to replace the one in the \noriginal PAIA for calculating affinity (refer to [8] for \nmore details about affinity calculation). \n \n4.3. Model simplification  \n \nA model simplification step is added to PAIA. The aim \nis to remove the redundancy both in the rules and in the \nfuzzy sets so that one can pursue the FRBS structure \noptimization along with the accuracy at the same time.  \n \n(I) Rule pruning: three scenarios can be regarded as \nhaving redundant rules and thus need to be pruned. \ni.  Insignificant rules: inspired by the idea behind neural \nnetwork pruning, insignificant rules are the ones that \ncontribute the least to any prediction error increase when \nnot including this rule. This occurs because other rules \nmay have already covered the area under these rules. \nInsignificant rules are deleted when the following \ncondition is met: \n)13()max\/( inprndrcr >\u22c5  \nWhere, cr is the number of rules in the current FRBS; \nmaxr is the maximum allowable number of rules; rnd is a \nrandom number between [0, 1]. Pin is a design parameter \nwhich limits the fewest rules in FRBS and is 0.5 in this \nwork.  \nii. Redundant rules: rules that only cover a small amount \nof data are regarded as redundant rules since they may not \nbe fired in most cases. They are deleted subject to the \nfollowing condition: \n)14(_\/\n1\nrdrrndrdrthnn\nj\nj\ni \u22c5=<\n\u2206\n=\n\u00a6 \u03c3  \nWhere, n is the input dimension; th_rdr is a design \nparameter which randomly changes between [0, rdr] \nevery t generations and rdr is 0.01 in this work.  \niii. Merging similar rules: during the optimization rules \nmay have similar fuzzy sets in the antecedent. Those rules \nshould be merged together by taking the mean values of \nthose fuzzy sets to keep FRBS consistent and \nparsimonious. The following condition should be met:  \n)15()1(_\n;,,1,\n,,1\n),,(min mrmrrndmrth\nlikli\nnj\nAAS jl\nj\ni +\u2212\u22c5=>\u00bf\n\u00be\n\u00bd\n\u00af\n\u00ae\n\u00ad\n\u2260=\n= \u2206\n!\n!  \nWhere, ),( jlji AAS  are the similarity between two fuzzy sets \nand will be explained later; th_mr is the threshold which \nrandomly changes between [mr, 1] every t generations \nand mr is 0.9 in this work. \n \n(II) Redundant fuzzy sets: one can encounter two \nsituations. \ni. Universal fuzzy sets: fuzzy sets which meet the \nfollowing condition are regarded as universal fuzzy sets \nand thus are deleted: \n)16()1(_),( ufsufsrndufsthUAS ji +\u2212\u22c5=>\n\u2206\n \nWhere, U is the universal fuzzy set; th_ufs is the threshold \nwhich randomly changes between [ufs, 1] every t \ngenerations and ufs is 0.65 in this work. \nii. Merging similar fuzzy sets: two fuzzy sets are \nconsidered to be similar if following condition is met: \n)17(\n)()(1\n1),(\n)1(_),(\n22 j\nl\nj\ni\nj\nl\nj\ni\nj\nl\nj\ni\nj\nl\nj\ni\ncc\nAAS\nsfssfsrndsfsthAAS\n\u03c3\u03c3 \u2212+\u2212+\n=\n+\u2212\u22c5=>\n\u2206\n \nWhere, th_sfs is the threshold which randomly changes \nbetween [sfs, 1] every t generations and sfs is 0.9 in this \nwork. Means values of two similar fuzzy sets are \ncalculated to substitute the original two fuzzy sets.  \n It is worth noting here that all simplification \nprocesses, expect for the \u0091\u2018insignificant rules\u0092\u2019, only have \n\u03b1 chance to be evoked at each generation, where \u03b1 is \n20% in this work.  \n \n5. Experimental studies \n \nTo validate the proposed modeling framework, it is \napplied to the modeling of Tensile Strength (TS) of alloy \nsteels. In this work, 3760 TS data are used. 75% of the \ndata are used for training and the remaining data are used \nfor checking. Another 12 more recent samples are used as \nthe unseen data set to validate the generalisation \nproperties of the model. The TS data includes 15 inputs \nand one output. The inputs consists of the weight \npercentages for the chemical compositions, the test depth, \nthe size of the specimen and the site where it has been \nproduced, the cooling medium, the quenching and \ntempering temperatures. The output is the tensile strength \nitself. \nTwo objectives are formulated with the first focusing \non the prediction accuracy and the second on the structure \nsimplification as follows: \n( )\n)18(\n:2\n:1 1\n2\nRLNsetNruleObjectiv\nm\nyy\nRMSEObjective\nm\nk\nrealprediction\n++\n\u2212\n=\n\u00a6\n=\n \nwhere, yprediction and yreal are predicted and real outputs \nrespectively; Nrule is the number of fuzzy rules in FRBS; \nNset is the total number of fuzzy sets; RL is the \nsummation of the rule length of each rule. \nFig. 4 shows the Pareto fronts obtained through the \nthird stage. Table 1 includes the detailed parameters of a \n9-rule fuzzy model selected from a set of Pareto models \nand its validation performance upon 12 unseen data \npoints. \n150 200 250 300 350 400\n25\n30\n35\n40\n45\n50\n55\n60\n65\n70\nPareto front (Objective1 vs. Objective2)\nObjective2(Nrules+Nsets+RL)\nO\nbje\nct\niv\ne \n1(R\nM\nSE\n)\n25 30 35 40 45 50 55 60 65 70\n6\n7\n8\n9\n10\n11\n12\nPareto front (Objective1 vs. Nrule)\nObjective1 (RMSE)\nTh\ne\n \nn\num\nbe\nr \nof\n \nru\nle\ns\n \nFig. 4. The Pareto fronts obtained from the third stage \n \nTable 1. The parameters of a 9-rule fuzzy model \n9-rule fuzzy model Parameters \nThe number of fuzzy rules 9 \nThe number of fuzzy sets \nin each inputs \nInputs: [7; 6; 6; 6; 5; \n7;6; 8; 7; 6; 2; 6; 6; \n9; 9] \nRMSE for training 36.013 \nRMSE for checking 39.767 \nRMSE for validation 48.619 \n      \n600 800 1000 1200 1400 1600 1800\n600\n800\n1000\n1200\n1400\n1600\n1800\nActual outputs\nPr\ned\nic\nte\nd \nou\ntp\nut\ns\nChecking RMSE: 111.09\n \n400 600 800 1000 1200 1400 1600 1800 2000\n400\n600\n800\n1000\n1200\n1400\n1600\n1800\n2000\nChecking RMSE: 35.5121 \nPredicted outputs\nAc\ntu\nal\n \nou\ntp\nut\ns\n \n400 600 800 1000 1200 1400 1600 1800 2000\n400\n600\n800\n1000\n1200\n1400\n1600\n1800\n2000\nChecking RMSE: 39.767\nPredicted outputs\nAc\ntu\nal\n \nou\ntp\nut\ns\n \nFig. 5. The prediction performances of the three \nstages: (a) the initial FRBS; (b) the refined FRBS; (c) a \n9-rule FRBS \n     \nFig. 5 shows the results obtained from the three stages. \nThe first two stages give FRBS consisting of a maximum \nof 12 rules. The third stage produce a set of Pareto FRBS \nand only a 9-rule model is presented here.    The training \nRMSEs are 112.29, 30.12 and 36.01 for the three stages \nrespectively. The checking RMSE is 111.09, 35.51 and \n39.77. Fig. 6 shows the simplified fuzzy sets in input 11 \ncompared to the refined 12-rule model. \n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\n0\n0.2\n0.4\n0.6\n0.8\n1\nD\neg\nre\ne \nof\n \nm\nem\nbe\nrs\nhi\np\nInput 11\n12 rules \n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\n0\n0.2\n0.4\n0.6\n0.8\n1\nInput 11\nD\neg\nre\ne \nof\n \nm\nem\nbe\nrs\nhi\np\n9 rules\n \nFig. 6. The fuzzy sets of input 11: (right) the refined \n12-rule model; (left) the optimized 9-rule model  \n \n6. Conclusion \n \nThe proposed modeling approach is not sensitive to the \ninitial settings. The initial granulation level is not an \nimportant factor anymore since in the third stage a set of \nPareto FRBS with different structure are elicited. Only the \nmaximum allowable number of rules is required as a \nprior. This simple framework provides the user with more \noptions for a set of eliciting optimal models and leaves the \ndesigner\u0092\u2019s intervention to a minimum level.  \n \nReferences \n[1] Cordon, O., Herrera, F., Hoffann, F., Magdalena, L., Genetic \nFuzzy Systems: Evolutionary Tuning and Learning of Fuzzy \nKnowledge Bases, World Scientific, Singapore, 2001. \n[2] Jang, J.-S.R., \u0093\u201cANFIS: Adaptive-Network-Based Fuzzy \nInference System\u0094\u201d, IEEE Transactions on Systems, Man and \nCybernetics, Vol. 23(3), 1993, pp. 665-685. \n[3] Gomez-Skarmeta, A. F., Delgado, M., Vila, M. A., \u0093\u201cAbout \nthe Use of Fuzzy Clustering Techniques for Fuzzy Model\u0094\u201d, \nFuzzy Sets and Systems, Vol. 106, 1999, pp. 179-188. \n[4] Hartigan, J. A., Wong, M. A., \u0093\u201cA K-Means Clustering \nAlgorithm\u0094\u201d, Applied Statistics, Vol. 28 (1), 1979, pp. 100-108. \n[5] Bezdek, J. C., Ehrlich, R., Full, W., \u0093\u201cFCM: The Fuzzy C-\nmeans Clustering Algorithm\u0094\u201d, COMP. GEOSCI., Vol. 10 (2-3), \n1984, pp. 191-203. \n[6] Chiu, S., \u0093\u201cFuzzy Model Identification Based on Cluster \nEstimation\u0094\u201d, J. of Intelligent & Fuzzy Systems, Vol. 2 (3), 1994 \n[7] Deb, K., Anand, A., Joshi, D., \u0093\u201cA Computationally Efficient \nEvolutionary Algorithm for Real-Parameter Optimization\u0094\u201d, \nEvolutionary Computation, Vol. 10 (4), MIT Press, 2002, pp. \n371-395.  \n[8] Chen, J., Mahfouf, M., \u0093\u201cArtificial Immune Systems as a Bio-\ninspired Optimization Technique and Its Engineering \nApplications\u0094\u201d, Artificial Immune Systems and Natural \nComputing: Applying Complex Adaptive Technologies, 2007 (to \nbe appear). \n[9] Chen, M. Y., Linkens, D. A., \u0093\u201cA Systematic Neuro-Fuzzy \nModeling Framework With Application to Material Property \nPrediction\u0094\u201d, IEEE Transactions on Systems, Man, and \nCybernetics, Vol. 31 (5), 2001, pp.781-790 \n[10] Wang, H. L., Kwong, S., Jin, Y. C., Wei, W., Man, K. F., \n\u0093\u201cMulti-objective Hierarchical Genetic Algorithm for \nInterpretable Fuzzy Rule-based Knowledge Extraction\u0094\u201d, Fuzzy \nSets and Systems, Vol. 149 (1), 2005, pp. 149-186. \n(b) \n(c) \n(a) \n"}
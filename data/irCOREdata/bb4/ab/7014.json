{"doi":"10.1080\/0968776950030106","coreId":"7014","oai":"oai:generic.eprints.org:169\/core5","identifiers":["oai:generic.eprints.org:169\/core5","10.1080\/0968776950030106"],"title":"Computer\u2010simulated experiments and computer games: A method of design analysis","authors":["Leary, Jerome"],"enrichments":{"references":[{"id":443772,"title":"A Comparison of Student Achievement Across Three Methods of Presentation of a Computer Based Science Simulation,","authors":[],"date":"1984","doi":"10.1300\/j025v02n04_06","raw":"Sherwood, R.D. & Hasselbring, T. (1984), A Comparison of Student Achievement Across Three Methods of Presentation of a Computer Based Science Simulation, Technical Report Series, Report No. 84.1.5 (ERIC Document Reproduction Services No. ED 262 750).","cites":null},{"id":193493,"title":"A taxonomy of computer simulations',","authors":[],"date":"1986","doi":null,"raw":"Gredler, M.B. (1986), 'A taxonomy of computer simulations', Educational Technology, 26, 4, 7-12.","cites":null},{"id":193495,"title":"Computer simulated practicals', paper presented at","authors":[],"date":"1994","doi":null,"raw":"Leary, J.J. (1994), 'Computer simulated practicals', paper presented at the 29th International Conference of the Association for Educational and Training Technology (Napier University, Edinburgh, 11-13 April).","cites":null},{"id":443769,"title":"Computer simulation of laboratory experiments: an unrealised potential',","authors":[],"date":"1990","doi":"10.1016\/0360-1315(90)90009-v","raw":"Magin, D.J. & Reizes, J.A. (1990), 'Computer simulation of laboratory experiments: an unrealised potential', Computers and Education, 14, 3, 263-70.","cites":null},{"id":193491,"title":"Computer simulations of laboratory experiences',","authors":[],"date":"1989","doi":null,"raw":"Clariana, R.B. (1989), 'Computer simulations of laboratory experiences', Journal of Computers in Mathematics and Science Teaching, 8, 2, 14-19.","cites":null},{"id":443773,"title":"Computerised science simulations stimulus to generalised problem solving capabilities', paper presented at the","authors":[],"date":"1984","doi":null,"raw":"Vockell, E.L. & Rivers, R.H. (1984), 'Computerised science simulations stimulus to generalised problem solving capabilities', paper presented at the Annual Convention of the American Education Research Association (68th, New Orleans LA, April 24).","cites":null},{"id":193492,"title":"Leary Computer simulated experiments and computer","authors":[],"date":"1993","doi":null,"raw":"47Jerome J, Leary Computer simulated experiments and computer games Entwistle, N. (1993), Recent Research on Student Learning and the Learning Environment, Centre for Research on Learning and Instruction, University of Edinburgh.","cites":null},{"id":443771,"title":"Levels of questioning and forms of feedback: instructional factors in courseware design', paper presented at the Annual Meeting of the American Educational Research Association (Chicago IL,","authors":[],"date":"1985","doi":null,"raw":"Merrill, J. (1985), 'Levels of questioning and forms of feedback: instructional factors in courseware design', paper presented at the Annual Meeting of the American Educational Research Association (Chicago IL, March 4).","cites":null},{"id":443770,"title":"Motivation, Interest and Learning,","authors":[],"date":"1994","doi":null,"raw":"Mayhew, J. (1994), Motivation, Interest and Learning, School of Law, Social Work and Social Policy, Liverpool John Moores University (forthcoming).","cites":null},{"id":193494,"title":"Student reactions to the use of computerised experiments in introductory psychology',","authors":[],"date":"1986","doi":null,"raw":"Hedlund, D.E. & Casolara, W.S. (1986), 'Student reactions to the use of computerised experiments in introductory psychology', Educational Technology, 26, 3, 42-5.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"1995","abstract":"This paper describes a new research programme to design computer\u2010simulated experiments in the field of fuels and combustion, and describes a method of categorization based on a taxonomy proposed by Gredler. The key features which enhance science content and process skills are identified The simulations are designed to be as realistic as possible, and are built using three\u2010dimensional computer\u2010aided design, rendering and animation tools, with the intention of creating an interactive virtual laboratory on the computer screen. A number of computer games are also categorized against the computer simulations and the same taxonomy for comparison. The paper then describes how designers of computer simulations can add to their own learning by retrospectively analysing their own simulations","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/7014.pdf","fullTextIdentifier":"http:\/\/repository.alt.ac.uk\/169\/1\/ALT_J_Vol3_No1_1995_Computer_simulated_experiments.pdf","pdfHashValue":"6649bc59b919e250e7158834d9a648aadfc5c997","publisher":"Universit of Wales Press","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:generic.eprints.org:169<\/identifier><datestamp>\n      2011-04-04T09:26:11Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D4C:4C42<\/setSpec><setSpec>\n      7375626A656374733D4C:4C43:4C4331303232<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/repository.alt.ac.uk\/169\/<\/dc:relation><dc:title>\n        Computer\u2010simulated experiments and computer games: A method of design analysis<\/dc:title><dc:creator>\n        Leary, Jerome<\/dc:creator><dc:subject>\n        LB Theory and practice of education<\/dc:subject><dc:subject>\n        LC1022 - 1022.25 Computer-assisted Education<\/dc:subject><dc:description>\n        This paper describes a new research programme to design computer\u2010simulated experiments in the field of fuels and combustion, and describes a method of categorization based on a taxonomy proposed by Gredler. The key features which enhance science content and process skills are identified The simulations are designed to be as realistic as possible, and are built using three\u2010dimensional computer\u2010aided design, rendering and animation tools, with the intention of creating an interactive virtual laboratory on the computer screen. A number of computer games are also categorized against the computer simulations and the same taxonomy for comparison. The paper then describes how designers of computer simulations can add to their own learning by retrospectively analysing their own simulations.<\/dc:description><dc:publisher>\n        Universit of Wales Press<\/dc:publisher><dc:date>\n        1995<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:rights>\n        cc_by_nc_nd<\/dc:rights><dc:identifier>\n        http:\/\/repository.alt.ac.uk\/169\/1\/ALT_J_Vol3_No1_1995_Computer_simulated_experiments.pdf<\/dc:identifier><dc:identifier>\n          Leary, Jerome  (1995) Computer\u2010simulated experiments and computer games: A method of design analysis.  Association for Learning Technology Journal, 3 (1).  pp. 40-48.  ISSN 0968-7769     <\/dc:identifier><dc:relation>\n        10.1080\/0968776950030106<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/repository.alt.ac.uk\/169\/","10.1080\/0968776950030106"],"year":1995,"topics":["LB Theory and practice of education","LC1022 - 1022.25 Computer-assisted Education"],"subject":["Article","PeerReviewed"],"fullText":"Computer-simulated experiments\nand computer games: a method of design analysis\nJerome J. Leary\nDepartment of Mathematical Sciences, University of Brighton\nThis paper describes a new research programme to design computer-simulated experiments in the\nfield of fuels and combustion, and describes a method of categorization based on a taxonomy\nproposed by Gredler. The key features which enhance science content and process skills are\nidentified The simulations are designed to be as realistic as possible, and are built using three-\ndimensional computer-aided design, rendering and animation tools, with the intention of creating\nan interactive virtual laboratory on the computer screen. A number of computer games are also\ncategorized against the computer simulations and the same taxonomy for comparison. The paper\nthen describes how designers of computer simulations can add to their own learning by\nretrospectively analysing their own simulations.\nBackground\nThrough the new modularization of the undergraduate science degree at the University of\nBrighton, larger numbers of students are choosing to take some science modules which\ninclude an amount of laboratory practical work. Indeed, within energy studies, the fuels\nand combustion module, for which the computer simulations were written, has seen a\nfourfold increase in student numbers from twelve to around fifty. Fitting out additional\nlaboratories with new equipment to accommodate this increase presented problems: the\nlaboratory space did not exist; fitting out the laboratories with new equipment would\ninvolve a relatively large capital spend per student for equipment that would be used\ninfrequently; and, because some of the experiments use inflammable liquids and gases,\nadditional staff would be needed for laboratory supervision.\nHowever, the option of running a science-based module such as fuels and combustion\nwith students doing fewer practic\u00e1is was not desirable from an educational view, since\nexperimentation plays a key role in enabling students to develop science process skills\n(Gibbs & Jaques, 1990), and a reduction in the amount of experimentation would have a\nconsequential effect on students developing those process skills. The necessity of teaching\n40\nALT-] Volume 3 Number I\nthe maximum amount of science content and science process in a cost-effective manner\nleads to consideration of computer simulations as a supplemental means of instruction.\nIndeed, the opportunity was seen that the total number of experiments that an individual\nstudent performed could be increased with the use of computer simulations.\nMuch research has already confirmed that simulations are no less a viable means of\ninstruction than any other form of instructional approach (for example, Hedlund et al,\n1986; Sherwood et al, 1984), and in fact studies have shown that students achieved as well,\nif not better, on the post tests through computer simulations. Mag\u00edn and Reizes (1990)\nsuggest there is considerable unexploited potential for computer simulations in education\nin the field of laboratory experiments, but in reality there is little computer simulation\nsoftware available for undergraduate teaching in the field of science. In 1992, this dearth\nlead to the instigation of a research programme by the author of this paper in computer\nsimulations within the University (Leary, 1994). The latest three-dimensional computer-\naided design, rendering and animation tools would give the experiments a sense of realism.\nThe experiments\nIt was initially planned to develop eight computer-simulated experiments in the field of\nfuels and combustion. This phase is now complete and the simulations are currently being\ntested on second-year energy studies students. The students use the simulations to:\n\u2022 determine the gross and net calorific values of natural gas using a Boy's Calorimeter;\n\u2022 determine the upper and lower flash points of liquid hydrocarbon fuels using the\nPensky Martens apparatus;\n\u2022 measure the relative density of liquid hydrocarbon fuels by the balance method and\nwith hydrometers;\n\u2022 determine the viscosity of liquid hydrocarbon fuels by using a Redwood Viscometer;\n\u2022 determine the fractions of light hydrocarbons in gasoline using a distillation column;\n\u2022 measure the pollutant emissions from a Wankel engine;\n\u2022 determine the constituents of coal and efficiency of combustion by measuring the\nproducts of combustion in a fluidized bed boiler;\n\u2022 investigate diesel-engine efficiency and diesel knock by varying fuel injection profiles.\nClassification of simulations\nBefore undertaking any redesign or refining of the initial eight computer-simulated\nexperiments, or indeed developing any further simulations, it was felt necessary to\nperform an analysis to identify the factors involved in optimizing the success of the\nlearning outcome and, thereby, add to the designer's own learning. As a comparison,\nsome popular computer games would also be analysed on the same basis. The model\nchosen for the analysis was Gredler's taxonomy (Gredler, 1986) of computer simulations\nwhich identified four categories of simulation:\n41\n\u00a1er\u00f3me J, Leary Computer simulated experiments and computer games\n1. Structured questions with associated graphics. The learner views the simulation, then\nanswers specific questions. These can be either drill-and-practice or tutorial type exercises.\n2. Assignment of variables with results exercises. One or more independent variables are\nset by the learner and the results on the dependent variable or variables are observed\nthrough several trials. The nature of this simulation is cyclic, feedback being related to\nvariables affecting other variables.\n3. Diagnostic simulations. This type of simulation usually involves applied decision-\nmaking in a professional content area leading to the development of 'expert knowledge'.\nA decision variable is selected by the learner after several episodes, and there is usually\none large scenario.\n4. Group-interactive. This is applied decision-making in a real social context.\nDistinguishing the correct approach in context is the principal learning outcome. There is\nno right or wrong answer in this case, and the results of decisions are difficult to\ndetermine. None of the laboratory experiments falls into this category, so the category is\nnot considered further.\nComputer games\nThe following computer games were chosen arbitrarily on the basis of being commercially\nsuccessful and representing a cross-section:\n\u2022 Microsoft Flight Simulator\n\u2022 Pong\n\u2022 SimCity\n\u2022 Doom\nAnal\/sis of the taxonomy\nTable 1 identifies the fit between the eight computer-simulated experiments described\nabove, the four computer games, and the taxonomy proposed by Gredler (1986). The\ndescriptions of type, or categories, are listed on the left, and the shaded boxes identify\nthose items which match each of the four classifications. If there is a match between a\ncomputer simulation or a computer game and a category, a star is used to indicate this.\nThen, in looking at the data in each of the columns, it is a matter of identifying a match\nbetween each column and each of the columns with shaded boxes. If the'pattern is the\nsame, the category of simulation is clearly identified as being either of the four types. The\ntaxonomy splits the category-structured questions with associated graphics into two other\ncategories: drill and practice, and tutorial.\nThe conclusions that can be drawn from the analysis of the simulations in the table are\nthat:\n\u2022 there is a weak but marked correlation between both the tutorial and variable\nassignment categories and the majority of the simulations;\n42\nNature of situation presented\nI.I\n1 1\n1.3\n1.4\nSpecific problems each requiring a particular answer \u2022\nA continuing situation that includes two or more variables [\nComplex real-world problem that takes new directions in response to in\n|\nprt\"\nUse of visuals and data | |\nLess\u00ab\nII A1\nn.A2\nH.A3\n>n preparation\nVisual presentation of a real-world problem \u2022\nGraphic presentation of a set of data I -'V\nFeedback to students\nII.B1\nII.B2\nII.B3\nII.B4\nIdentifies right and wrong answers\nProvides clue's to errors in student's selected strategy\nIdentifies outcomes of student's assignment of values to variables 1\nDescribes new direction in a complex problem that follows student's inp\nNature of instructional process\nHI.1\nm.2\nin.3\nH1.4\nIU.5\nSolve a set of discrete, specific problems\nIdentify new examples of concepts or rules\nDisco ver the optimum strategy to solve a problem 1\nDiscover the set of values identified as optimum for several variables I\nImplement the knowledge acquired in a particular subject area\nVa\nr. \nA\nss\nig\nn. I\nu t |\n\u2022\nExperiment Number\n1\n*\nr4-\n\u00dc *\n**\n2\n*\n3\n*\n*\n4\n*\n*\n*\n5\n*\n*\n*\n6\n*\n7\n*\n*\n8\n*\n\u2022\u2014\u2022\n*\n*\n*\n*\n*\n*\n*\n\u2022\nH H Condition\ni l l Optional\nTable I: Classification of computer simulations and computer games\nJerome J, Leary Computer simulated experiments and computer games\n\u2022 there is strong use of visuals in both demonstration of items and presentation of the\nrunning experiments;\n\u2022 the simulations provide only weak feedback and do not identify errors in the student's\nselections;\n\u2022 simulation number 3 shows marked characteristics of the drill-and-practice class;\n\u2022 the nature of the instructional process of simulations 7 and 8 is akin to the diagnostic\nclass.\nThis analysis provides an extremely useful agenda for further design work on the\nsimulations with the issue of weak feedback heading the list. It also provides an insight\ninto the timing of the use of the simulations within the fuels and combustion module as a\nwhole, as it is apparent from the taxonomy that simulations 1, 7 and 8 are partly\ndiagnostic in nature and require some prior knowledge, that simulations 2, 4, 5, and 6 are\nmainly variable assignment and require minimal prior knowledge, while simulation 3, as a\ndrill-and-practice type, can be used without any prior knowledge of measuring relative\ndensity. Lastly, the analysis also provides a level of comfort as it confirms that about half\nof the simulations fall into the assignment of variables class, which Clariana (1989)\nindicates do result in improved learning of specific content and also of more generalized\ncognitive processes.\nThe games were also analysed using Gredler's taxonomy and the results are also shown in\nTable 1. It is quite interesting that there is a strong correlation in all cases with variable\nassignment and diagnostic categories. The emphasis in these games is providing an\nenvironment in which players can test their skill, be it landing an aircraft, playing ping\npong, managing a city or doing battle, and although the teaching of these skills is not a\nprimary aim of the software - commercial success is - the development of the skills does\noccur, and the players in all cases do improve their performance and increase their\nknowledge.\nHowever, although the analysis using the taxonomy provides much useful information, it\nleaves unanswered some questions concerning the effectiveness of the simulations. This is\nbecause these questions primarily concern learner understanding rather than typological\nissues of context and feedback, and are, therefore, outside the ambit of Gredler's\ntaxonomy. When addressing issues of learner understanding there is, unfortunately, no\nsingle reference point like Gredler's taxonomy, and a comprehensive view of the issues is\ngained only by studying relevant literature, some of which is discussed below. They\ninclude areas such as enhanced reality, learner guidance or learner control, level of\nquestioning, degree of fascination, and transfer.\nFurther issues\nEnhanced reality. The eight simulations developed for the fuels and combustion module\nare, thanks to the latest 3D graphics tools, quite realistic, and this is borne out by student\nfeedback. Realism is considered important as many of the undergraduates on the module\nhave no prior experience of what some fuel-testing apparatus looks like. Thus, important\nfeatures have been enhanced using animations and cut-away views. For example,\n44\nALT-J Volume 3 Number I\nFigure I: Boy's Calorimeter\nsimulation\nsimulation number 1, which uses a Boy's Calorimeter (Figure 1) to determine the gross\nand net calorific values of gaseous fuels, shows a cut-away view of the inner workings of\nthe calorimeter, allowing the student to view the direction and magnitude of water flows,\ngas flows and the combustion flame. This view conveys additional information which\nwould not be available in a conventional laboratpry. Furthermore, where possible, task-\nirrelevant cues have been eliminated or reduced. Again using simulation number 1 as an\nexample, the experiment would, in reality, involve a mass of wiring, connecting\nthermocouples and other components to temperature meters, whereas the simulation\nshows only simple digital thermometers. The simulations also highlight features that may\nnot be visible in reality, such as heat flows, and show magnified views, such as a single oil\ndroplet burning, and slow down time so that fast processes, such as combustion occurring\nin a diesel engine, can be studied in detail in slow motion (Figure 2). Successful\nimplementation of these features was a key design consideration, and the ability of the\neight simulations to aid the students' understanding more effectively than traditional\nlaboratory-based experiments is therefore deemed to be high.\nLearner guidance or learner control. It has been shown, for example by Vockell & Rivers\n(1984), that guided discovery computer simulations are generally better than the\nexploratory computer simulations, particularly in the development of general problem-\nsolving skills. This is contrary to the commonly held view that free exploratory discovery\nis best for learning science process, and that guided discovery is best for learning science\ncontent. In any case, simulations of a diagnostic nature require prerequisite knowledge\nand provide a test environment to try out that acquired know-how. In other types, it is\nmore difficult to determine in advance exactly how much learner-guidance to include in\neach of the simulations, so the method for deciding this is an interactive one based on\nstudent feedback. The amount of student questioning is monitored and used to include or\nremove additional information.\n45\nJerome J, Leaiy Computer simulated experiments and computer games\nFigure 2: Diesel engine\nsimulation\nLevel of questioning. This is aimed at stimulating reflection on what has occurred during\neach experiment. A correct level of questioning is important because reflection is needed\nto create a deeper understanding, and in order to develop cognitive processes in the\nlearner. In a study by Merrill (1985), the use of higher-level questions in computer\nsimulations was supported, but not lower-level questions where individual attributes of a\nconcept are treated in isolation. In the simulations described in this paper, students are\nasked a set of higher-level questions at the end of the experimentation phase to encourage\nreflection. In diagnostic simulations and computer games, students are already working at\na deeper level, testing and refining their mental model continuously, and so additional\nquestioning is less appropriate.\nFascination. The level of difficulty of a simulation is important. Ideally, there should be\nan exact match between the learner's ability and the difficulty of the simulation to\nstimulate interest. If a simulation is too easy it will result in boredom and poor skill\ndevelopment, whereas if a simulation is too difficult it will cause anxiety in the learner\nand a failure to understand or complete the task. However, if there is an exact match, the\nlearner is more likely to proceed with maximum concentration, or even become fascinated\nwith the task, at which point learning occurs with consummate ease (Mayhew 1994) as the\nstudent becomes addicted. With computer simulations, it is much easier to match the\ndifficulty of the task with the level of competence of the learner. Some computer games\ndo this particularly well with different skill levels. With real experiments, this process is\nlimited by physical constramts. Student feedback suggests that the level of difficulty for\none or two of the experiments is too low, in particular simulation number 3. Table 1\nconfirms that this simulation belongs to the drill-and-practice class, which are routine in\nnature, and therefore we can conclude that simulation number 3 needs to be redesigned to\nmake it more challenging.\nValidation. One desirable learning outcome from any experimentation is development of\nskill in validation of results. Rather than trusting implicitly the output of the experiment, as\nstudents are more likely to do with computer generated results, in these experiments\n46\nALT-} Volume 3 Number I\nstudents are made aware that they should treat the measurements from the computer\nsimulations with the same degree of caution as they would measurements from equivalent\nreal experiments. Several processes are incorporated into the simulation to ensure that good\nresults can be obtained only with careful procedure. For example, a mathematical model\nwhich is dynamic, with built-in time delays, thermal inertias and so on; a measurement\nvariation or 'noise' added to measurements; and, thirdly, variations introduced into the\nparameters of the model so that it changes gradually over time in a random manner. The\nlevel of these contingencies actually built in determine the development of experimentation\nskills and lead to a fuller appreciation of the nature of empirical investigation.\nTransfer. The above issues directly affect transfer, that is, the ability of a student to use\nknowledge in either a similar context (near transfer) or a different context (far transfer).\nThis is tied in with whether the student is gaining a surface knowledge or a deeper\nunderstanding (Entwistle, 1993). To perform far transfer, the student must acquire a\ndeeper understanding, and in general simulations of a diagnostic class are better at this\nthan drill and practice. However, other issues are also important, for example enhancing\nreality, providing an optimum level of learner guidance, generating higher level questions,\nand making the simulations fascinating all help the student achieve a deeper\nunderstanding and obtain skills in both near and far transfer.\nConclusions\nIt is natural for designers of simulations to want to undertake some form of analysis of\ntheir work to identify how their own learning can be improved. More effective designers\nlead to more effective simulations. Educational software also has a lot to learn from\ncomputer games in their potential to support that old adage that learning can be fun.\nGredler's taxonomy is a useful tool for assessing the context and feedback characteristics\nof simulations and comparing them to other types of software, such as computer games,\nand it can provide useful pointers for retrospective design work. An assessment of the\neffectiveness of characteristics beyond typological considerations is, however, much more\ndifficult as there is no single reference point as yet that provides a model for comparison.\nThe analysis of issues such as enhanced reality, learner control or program control, level\nof questioning, fascination, and transfer, is, therefore, judgmental and often subjective.\nAs designers' judgement about the effectiveness of their own simulations may be clouded\nby their close proximity to the development work, other judgements such as the students'\nfeedback should be taken into account. Despite the problems associated with the\nassessment of learner understanding, the exercise outlined in this paper encourages the\ndesigner to take a holistic view, and provides criteria which will tend to make his or her\nwork more effective.\nReferences\nClariana, R.B. (1989), 'Computer simulations of laboratory experiences', Journal of\nComputers in Mathematics and Science Teaching, 8, 2, 14-19.\n47\nJerome J, Leary Computer simulated experiments and computer games\nEntwistle, N. (1993), Recent Research on Student Learning and the Learning Environment,\nCentre for Research on Learning and Instruction, University of Edinburgh.\nGibbs, G. & Jaques, D. (1990), Labs and Practicals, Oxford, Educational Methods Unit,\nOxford Brookes University.\nGredler, M.B. (1986), 'A taxonomy of computer simulations', Educational Technology,\n26, 4, 7-12.\nHedlund, D.E. & Casolara, W.S. (1986), 'Student reactions to the use of computerised\nexperiments in introductory psychology', Educational Technology, 26, 3, 42-5.\nLeary, J.J. (1994), 'Computer simulated practicals', paper presented at the 29th\nInternational Conference of the Association for Educational and Training Technology\n(Napier University, Edinburgh, 11-13 April).\nMagin, D.J. & Reizes, J.A. (1990), 'Computer simulation of laboratory experiments: an\nunrealised potential', Computers and Education, 14, 3, 263-70.\nMayhew, J. (1994), Motivation, Interest and Learning, School of Law, Social Work and\nSocial Policy, Liverpool John Moores University (forthcoming).\nMerrill, J. (1985), 'Levels of questioning and forms of feedback: instructional factors in\ncourseware design', paper presented at the Annual Meeting of the American Educational\nResearch Association (Chicago IL, March 4).\nSherwood, R.D. & Hasselbring, T. (1984), A Comparison of Student Achievement Across\nThree Methods of Presentation of a Computer Based Science Simulation, Technical Report\nSeries, Report No. 84.1.5 (ERIC Document Reproduction Services No. ED 262 750).\nVockell, E.L. & Rivers, R.H. (1984), 'Computerised science simulations stimulus to\ngeneralised problem solving capabilities', paper presented at the Annual Convention of\nthe American Education Research Association (68th, New Orleans LA, April 24).\n48\n"}
{"doi":"10.1007\/3-540-36572-9_21","coreId":"70452","oai":"oai:eprints.lancs.ac.uk:12086","identifiers":["oai:eprints.lancs.ac.uk:12086","10.1007\/3-540-36572-9_21"],"title":"Ubiquitous interaction:using surfaces in everyday environments as pointing devices","authors":["Strohbach, Martin","Van Laerhoven, Kristof","Gellersen, Hans","Schmidt, Albrecht"],"enrichments":{"references":[{"id":16302745,"title":"A directory of sources for input technologies.","authors":[],"date":"2002","doi":"10.1145\/15698.15702","raw":"Buxton, B. A directory of sources for input technologies. 2002. http:\/\/www.billbuxton.com\/InputSources.html","cites":null},{"id":16302744,"title":"Interaction i n Smart Environments,","authors":[],"date":"1999","doi":"10.1007\/3-540-48157-5_31","raw":"Beigl, M.. Point & Click  - Interaction i n Smart Environments,  Proc. 1 st Intl Symposium on Handheld and Ubiquitous Computing (HUC99), Karlsruhe, Germany, October 1999, Lecture Notes in Computer Science No. 1707, SpringerVerlag, pp 311-314.","cites":null},{"id":16302747,"title":"Issues and Techniques","authors":[],"date":null,"doi":"10.1145\/325165.325239","raw":"Buxton, W., Hill, R. and Rowley, P., Issues and Techniques in Touch-Sensitive","cites":null},{"id":16302742,"title":"ORL Active Floor.","authors":[],"date":"1997","doi":"10.1109\/98.626980","raw":"Addlesee, M.D., Jones, A., Livesey, F., and Samaria, F. ORL Active Floor. IEEE Personal Communications, Vol.4, No 5, Oct 1997, pp. 35-41.","cites":null}],"documentType":{"type":1}},"contributors":["Carbonell, No\u00eblle","Stephanidis, Constantine"],"datePublished":"2002-01","abstract":"To augment everyday environments as interface to computing may lead to more accessible and inclusive user interfaces, exploiting affordances existing in the physical world for interaction with digital functionality. A major challenge for such interfaces is to preserve accustomed uses while providing unobtrusive access to new services. In this paper we discuss augmentation of common surfaces such as tables as generic pointing device. The basic concept is to sense the load, the load changes and the patterns of change observed on a surface using embedded load sensors. We describe the interaction model used to derive pointing actions from basic sensor observations, and detail the technical augmentation of two ordinary tables that we used for our experiments. The technology effectively emulates a serial mouse, and our implementation and use experience prove that it is unobtrusive, robust, and both intuitively and reliably usable","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/70452.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/12086\/1\/schmidt_ui4all_2002.pdf","pdfHashValue":"571486b83339f0573a0da845e652d1134d14f94d","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:12086<\/identifier><datestamp>\n      2017-11-29T00:06:43Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Ubiquitous interaction:using surfaces in everyday environments as pointing devices<\/dc:title><dc:creator>\n        Strohbach, Martin<\/dc:creator><dc:creator>\n        Van Laerhoven, Kristof<\/dc:creator><dc:creator>\n        Gellersen, Hans<\/dc:creator><dc:creator>\n        Schmidt, Albrecht<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        To augment everyday environments as interface to computing may lead to more accessible and inclusive user interfaces, exploiting affordances existing in the physical world for interaction with digital functionality. A major challenge for such interfaces is to preserve accustomed uses while providing unobtrusive access to new services. In this paper we discuss augmentation of common surfaces such as tables as generic pointing device. The basic concept is to sense the load, the load changes and the patterns of change observed on a surface using embedded load sensors. We describe the interaction model used to derive pointing actions from basic sensor observations, and detail the technical augmentation of two ordinary tables that we used for our experiments. The technology effectively emulates a serial mouse, and our implementation and use experience prove that it is unobtrusive, robust, and both intuitively and reliably usable.<\/dc:description><dc:publisher>\n        Springer<\/dc:publisher><dc:contributor>\n        Carbonell, No\u00eblle<\/dc:contributor><dc:contributor>\n        Stephanidis, Constantine<\/dc:contributor><dc:date>\n        2002-01<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/12086\/1\/schmidt_ui4all_2002.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/3-540-36572-9_21<\/dc:relation><dc:identifier>\n        Strohbach, Martin and Van Laerhoven, Kristof and Gellersen, Hans and Schmidt, Albrecht (2002) Ubiquitous interaction:using surfaces in everyday environments as pointing devices. In: Universal Access Theoretical Perspectives, Practice, and Experience. Lecture Notes in Computer Science . Springer, Berlin, pp. 263-279. ISBN 9783540008552<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/12086\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1007\/3-540-36572-9_21","http:\/\/eprints.lancs.ac.uk\/12086\/"],"year":2002,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"Ubiquitous Interaction - Using Surfaces in Everyday \nEnvironments as Pointing Devices \nAlbrecht Schmidt, Martin Strohbach, Kristof van Laerhoven,  \nand Hans-W. Gellersen \nComputing Department,  \nLancaster University \nLancaster, LA1 4YR, UK  \nE-mail: {albrecht, strohbach, kristof, hwg}@comp.lancs.ac.uk \nhttp:\/\/ubicomp.lancs.ac.uk   \nAbstract. To augment everyday environments as interface to computing may \nlead to more accessible and inclusive user interfaces, exploiting affordances \nexisting in the physical world for interaction with digital functionality. A major \nchallenge for such interfaces is to preserve accustomed uses while providing \nunobtrusive access to new services. In this paper we discuss augmentation of \ncommon surfaces such as tables as generic pointing device. The basic concept \nis to sense the load, the load changes and the patterns of change observed on a \nsurface using embedded load sensors. We describe the interaction model used \nto derive pointing actions from basic sensor observations, and detail the \ntechnical augmentation of two ordinary tables that we used for our experiments.  \nThe technology effectively emulates a serial mouse, and our implementation \nand use experience prove that it is unobtrusive, robust, and both intuitively and \nreliably usable.  \n1 Introduction \nTo use our everyday environments as interface to computer-based services is an \nintriguing vision toward more accessible and inclusive user interfaces. The principal \nidea is to augment common structures and everyday artifacts as interaction devices \nthat inherit design affordances from the physical world for interaction with the digital \nrealm. The key motivation is to yield interfaces that are experienced as familiar, \nnatural and fitting in our environments, to the extent that they become peripheral to \neveryday activity. The design challenge for such interfaces is therefore to preserve the \noriginal appearance, purpose and function of augmented structures and artifacts, and \nto exploit their affordances rather than break with accustomed use.  \nWeiser\u2019s vision of ubiquitous computing was an early suggestion of the world as \ninterface to computing, referred to by him and his colleagues as embedded virtuality \n[18]. This has since been followed by many inspirational research contributions, \nexploring notions of augmented environments [19], tangible user interfaces [16] and \nambient information display [17]. This research has yielded a wide range of \nillustrative examples demonstrating the combination of \u2018real world\u2019 affordances with \naccess to the digital world. However these examples tend to be highly application \nspecific, while there appears to be no notable work on more generic interfaces \nembedded in everyday environments. \nIn a recent publication we have discussed augmentation of common surfaces in \neveryday environments such as table-tops, shelves and floor space with load sensors \nto render them responsive to activity occurring on them. We have demonstrated that \nsurface-based load sensing is a very robust and versatile source of information that \ncan be used as context for ubiquitous computing applications [21]. More specifically, \nwe have shown that three basic types of context can be obtained from events on a \nload-sensitive surface. These are the measured overall force (corresponding to the \nweight of an object or to explicitly applied pressure), the position on the surface at \nwhich a change in force is observed (corresponding to where an object is placed or \nremoved), and the type of interaction expressed in the signal waveforms \n(corresponding to how an object is placed). We have further shown that more \nelaborate context can be obtained by combining observations over time (tracking \nactivity) or space (relating activity across multiple surfaces). The use of such context \nin computer applications effectively constitutes implicit human-computer interaction \n[22] as it is based on human activity but not created as explicit input to the \napplication. \nIn this paper we extend our work on load-sensitive surfaces to demonstrate their \nuse for explicit human-computer interaction. We do this by considering use of \nordinary surfaces as generic pointing device. The guiding scenario is that we might \nsimply use the surface of a coffee table in the living room as track pad to navigate the \nWeb on the TV screen. The challenges are interesting: obviously we do not wish a \ncoffee table to appear wired and instrumented, and more importantly we expect the \nplacement of cups and other items not to be prohibited by the new function of the \ntable.  \nOur contribution is organized as follows. In section 2 we analyze the challenges of \nimplementing of a pointing device on a common surface. This is followed by an \nintroduction of our technology concept in section 3, and of recorded sensor data in \nsection 4, illustrating how our approach works. In section 5 we provide further detail \non the implementation of two tables that we augmented as wireless trackpads, and in \nsection 6 we briefly relate use experience. The final sections 7 and 8 reflect on related \nresearch, future work and our main conclusions. \n2 Analysis of Everyday Surfaces as Interaction Device \nIn this section we first consider general challenges in augmenting common surfaces \nfor pointing, and then consider the specific problems arising with the use of load-\nsensing as basic interface technology. \n2.1 Challenges \nThe following four points are particularly critical for a successful implementation of a \nubiquitous pointing device.  \nPreserving the Original Functionality of the Surface. When adding functionality to \nobjects of everyday life it is important that the original functionality of the artefact is \nnot sacrified. In the case of a table \u2013 augmenting the coffee table with a pointing \nfunctionality should not enforce a different way of using the table while it is used in \nits usual way. Even when it is used for pointing it should still be usable for its original \npurpose. In other words pointing should be still feasible when the table is occupied \nwith objects. \nMany Surfaces \u2013 one Pointing Device. It is obvious that an interface that is ubiquitous \ncan not be bound to a specific place or artefact. In an ideal case, interaction is possible \nfrom everywhere without switching interfaces. In the case of surfaces the challenge is \nto realise a seamless transition from surface to surface when interacting. The \nanticipated implementation would allow the user to use any surface \u2013 that is \nconvenient at this moment in time \u2013 to be used as a pointing device. \nUnobtrusive Realisation. Building a ubiquitous interface should not make the table \nlook like a computer. The appearance of artefacts is often one of their main \nproperties. Especially in personal environments furniture and artefacts are an essential \npart of the interior of a home. Introducing the technology should no require a change \nin the appearance of a table or shelf. The interface should be a part of a invisible \ncomputer \u2013 because the interface is often what people perceive as their computer. \nRobust and Reliable Implementation. When including sensing capabilities into \nsurfaces it has to be done in a robust and reliable way. The different ways in which \nsurfaces are being used have to be taken into account, e.g. it has to be anticipated that \npeople may sit on a table. Especially when considering home environments reliability \nand zero maintenance becomes a crucial issue. When designing a solution one should \nbe aware that calibration and maintenance are hindering the deployment of such \ntechnologies. \n2.2 Load Sensing as Approach to Surface Augmentation  \nThe basic idea of the approach is to interpret the shift in load distribution on the \nsurface as pointing and clicking action. The change in the load distribution is induced \nby the user\u2019s interaction on the surface. Pressing a finger onto the surface and moving \nit will change the load distribution on the surface. The assumption is that this change \ncan be measured and converted into a pointing action. The hypothesis is that by these \nmeans pointing \u2013 tracking a finger \u2013 anywhere on the surface can be converted into a \nrelative change of a pointer. If during the pointing action there is an increase in \npressure followed by a release in pressure at the same position this can be interpreted \nas a clicking action. \nTo measure the load distribution the surface has to be placed onto load cells that \nallow a precise acquisition of the weight on the surface and also how it is distributed. \nHaving the load on each corner it becomes possible to calculate the centre of pressure \non the surface and also the absolute weight on the surface. The centre of pressure \nmoves when a users tracks the finger across, but it also moves when objects are \nplaced onto the surface. \nThe further assumption is that detecting the manual interaction and converting \nthese relative moves of the centre of pressure should allow the generation of relative \nmoves of a pointer. The overall weight represents all the items on the surface (in some \ncases the weight of the surface itself) and also the manually applied pressure. By \nanalysing the changes to the overall pressure in context of the interaction taking place \nit becomes possible to determine when there is a click operation performed. \nThese assumptions made here are tested with experiments gaining data sets as \ndescribed in section 4. \n2.3 Problems arising with Load Sensing \nTo realise the idea of using load sensing technologies to add pointing capabilities to a \nsurface further obstacles have to be overcome. \nChanging Load on the Surface. The load on the surface is changing also without it \nbeing used as a pointing device. E.g. what is on a table changes over time, objects are \nmoved, taken away, and put down. These events have to be discriminated from the \nuser interaction that is made to interact with the computer. The algorithms have to \ntake into account that the base load may change. \nRecognising Start and End of User Interaction. The user interacts with the surface in \ntwo different ways \u2013 using the original functionality and using it as a pointing device. \nE.g. it is essential to recognize whether someone puts a cup of tea on the table or \nsomeone is pointing. \nDistributed Sensing. Using more than one surface makes it necessary to have \ndistributed sensing. Each surface is a load sensing platform, but the resulting \ninteraction should be coherent as coming from one input device. Communication \nbetween the backend \u2013 e.g. the computer the pointer is attached to \u2013 and the various \nsensing devices is required. \nSampling Speed and High Resolution. To acquire the user interaction with high \nprecision it is necessary to sample the load cells output very quickly and also with a \nhigh resolution of the analog-digital conversion. Most commerciality available \nsolutions for scales and weighing technologies sample with high resolution but very \nslow just a few readings a second. \nNoise due to interaction. Surfaces are connected to other parts of the environment, e.g. \nfurniture is standing on the floor and shelves are mounted to the wall. Interacting in \nsuch an environment the user may introduce noise into the load sensing system by \nwalking around or leaning against a wall. Because the acquisition is done with high \nprecision walking up to the table may already change the load distribution on the table \nslightly. \n3 Load Sensing to detect Point and Click Interactions \nIn order to realise pointing and clicking on a surface based on load sensing \ntechnology it must be possible to calculate changes in position and other actions from \nthe forces measured.  \n3.1 Acquisition of the 2D Position \nThe anticipated setup consists out of a flat surface (e.g. the top of a table) that is \nsupported by four load cells, one in each corner. Load cells are sensors that measure \nthe force that is applied; they are typically used in scales to indicate the weight. Here \nthe obvious rule summing the forces from all 4 load cells are equal to the force \ncreated by the weight of the surface and the objects on to of the surface. Scales \ntypically offer a mechanism to subtract a base weight (tare) so that only the object \nplaced on the surface are considered. Applying manual pressure onto the surface, will \nincrease the forces on the corresponding load cells.  \nDepending on the position of the surface where an object is placed or where \npressure is applied the forces measured at the individual load cells are different. To \nfind the point where the object is placed or pressure is applied it is necessary to map \nthe load measured at each corner onto the 2d layout of the surface, see figure 1.  \nAssuming a static force Fx is applied at position x, y on a surface of the size xmax by \nymax forces in each corner F1, F2, F3, and F4 can be measured. Using the following \nequation the position can be calculated: \n \n \nForce Fx\nat (x,y)\nForce F1\nat (0,0)\nForce F3\nat (xmax,ymax)\nForce F4\nat (0,ymax)\nForce F2\nat (xmax,0)\n \n \nFigure 1: Determining the 2D position using 4 Load sensors. \n4321 FFFFFx +++=    (Equation 1) \nxF\nx\nFFx max32 )( +=       (Equation 2) \nxF\ny\nFFy max43 )( +=     (Equation 3) \nSumming up the forces of all load cells gives the total, see equation 1. Knowing \nthe forces and the overall size of the surface (or more precise the corners where the \nsurface touches the load cells), the centre of pressure can be calculated, see equations \n2 and 3. When more than one object is placed in the surface or when pressure is \napplied at more than one point, the calculation results in a point in between. \nAs mentioned earlier usually the surface itself has a weight, too. For calculating the \nposition of an object or a point of pressure this has to be taken into account, see \nequations4, 5 and 6. In an environment where objects are placed and removed from \nthe surface this tare-weight is changing. By keeping track of changes that became \nstable, e.g. typically objects that have been placed on the surface, or objects that have \nbeen removed; it is possible to dynamically adjust the tare-weight. Knowing the pre-\nload it is still possible to find the position of objects or interaction. These pre-loads to \nthe surface result in forces denoted as F01, F02, F03, and F04. The sum of the pre-load \nis F0x. To calculate the position where pressure is applied in a setting where already \nload is on the surface equation 4, 5, and 6 can be used.  \n \n4321 00000 FFFFF x +++=        (Equation 4) \n)0(\n))0()0(( max3322\nxx FF\nx\nFFFFx\n-\n-+-=   (Equation 5) \n)0(\n))0()0(( max4433\nxx FF\nyFFFFy\n-\n-+-=   (Equation 6) \n3.2 Interacting with Surfaces \nTo understand and model interaction with a surface we looked at the states that occur \nand events that can happen. The resulting state diagram, depicted in figure 2, becomes \nthe foundation for the software that translates changes recorded by the load cells into \nmouse movements and events. \nIn the following, we characterize the states and also some of the transitions. The \nvariable used to explain are the forces here as discrete values over time: F1(t), F2(t), \nF3(t), F4(t). Representing the load measured by each of the load cells on which the \nsurface is resting at time t. The coordinates of the position of the centre of pressure at \ntime t is denoted p(t) or as its components x(t) and y(t). \nWhen starting up there is no knowledge available in what state the surface is, this \nis denoted by state X. In our model we have decided that this state can only be left via \na transition to the state \u201cno interaction\u201d. The transition from X to A occurs when the \nsums of absolute changes of the forces over the last n discrete time steps is close to \nzero (e instead of 0 to overcome problems with noise), see Equation 7. This means \nthat the only transition takes place when the forces on the surface do not change. \n\u00e5 \u00e5\n= --=\n<-\n4..1 )1)..((\n))()((\ni tntj\nii jFtF e  (Equation 7) \n  \nThe system stays in state A as long as this condition is true. The value for e may be \nslightly greater than for entering the state so minimal change in the load distribution \non the surface are not overlooked. The state A is independent of the pre-load that is \napplied to the surface; as long as forces are static \u2013 e.g. from objects that have been \nplaced onto the surface previously \u2013 they have no influence. When the system is in \nstate A also the values for the pre-load F0i, and F0x. are set. The equation assumes \nnoise-free data. However, to deal with noise instead of the raw values for Fi(t) a \nfiltered value can be used, see the next section. From state A transitions to B, E, F, \nand X are possible.  \nThe state B is reached when the system recognizes that the user has put her finger \nonto the surface. The transition from A into B is characterized by a monotonous \nincrease in the sum of load over all load cells over the transition time. This leads to \nthe first derivative being greater or equal 0. Instead of calculating the first derivative \nthe simple condition Fx(t)<Fx(t+1) can be used to check whether or not this criteria is \nmet. Furthermore, the sum of the forces has to be in a certain interval (Dmin, Dmax), see \nequation 8. \n))(0)((\n))(0)((\nmax\nmin\nDtFtF\nDtFtF\nxx\nxx\n<-\n\u00d9>-\n   (Equation 8) \n \nA\n\"No Interaction\"\nB\n\"Surface\nTouched\"\nC\n\"Tracking\"\nD\n\"Clicking\"\nE\n\"Object placed\non the surface\"\nF\n\"Object\nremoved from\nthe surface\"\nX\n\"Unknown\"\n \n \nFigure 2: Modelling the interaction with a surface. \nThe transition from B to A, e.g. when lifting the finger off the surface is similar, \nonly the derivative is less or equal 0 in this case.  \nAs long as the position is not changing over the last n readings and the force is in \nthe interval used in equation 8, the system stays in this state. As there is manual \ninteraction on the surface the forces are not quite stable and therefore a further \ncondition can be stated: the square of sums of changes of the forces over the last n \ndiscrete time steps is greater than a threshold d, see equations 9.  \n \ne\nd\n<-\n>-\n\u00e5\n\u00e5\n--=\n--=\n)1)..((\n)1)..((\n))()((\n))()((\ntntj\ntntj\nxx\njptp\njFtF\n  (Equations 9) \n  \nFrom state B transitions to C, D, and A are possible. When in the state tracking (C) \nit is assumed that the user is moving a finger on the surface resulting in a change of \nthe measured centre of pressure ( pd ), see equation 10. Other features are similar to \nthe state B. When the user stops moving, a transition to B occurs. \n \n p\ntntj\njptp d>-\u00e5\n--= )1)..((\n))()((   (Equation 10) \n \nWhile the surface is touched an increased pressure at the same point is resulting in \na change to state D (clicking). This transition occur when the system is in state B or \nC. The state clicking is characterized by the fact that within a given time span (e.g. \nabout a second) the overall load is first increased and then decreased. The position of \nthe centre of gravity however stays roughly the same. The increase must be in a \npredefined interval stating a threshold which separates clicking from the changes that \noccur while tracking. It also should not exceed a maximum force.  \nThe states E and F are specific to surfaces that are used to put things on temporally. \nThe state \u201cobject placed on the surface\u201d (E) is similar to touching the surface. \nHowever, after the object has been placed, the weight distribution is stable again. \nWhen this is recognized, a transition is made back to the state A and the initial load is \nupdated with the new weight. Similarly when an object is removed from the surface \n(F), this will lead to a change in the weight distribution and possibly to a change of \nthe centre of pressure. However, after the object is taken away the system will be \nstable again. In this case, the initial weight distribution will be updated with the new \nvalues for each of the load cells, too. In this way also multiple objects can be placed \non the surface or taken away. \nWhen objects are placed on the surface or removed from the surface while a \ntracking action or a click action is performed (in state C or D) this becomes much \nharder to recognize. Initial data analyses shows, that it may be possible, but we \nexcluded these case in our first implementation. \n4 Analysis of Load Sensor Data \nWe build an experimental data acquisition setup, using 2 different types of load cells \nand two table tops (see the implementation section for details). Various data sets have \nbeen recorded and plotted to gain an understanding of the load data measured during \ntypical interaction. We were particularly interested in events such as putting down \n \n \nFigure 3. Load sensing data during various events: (1) placing a cup onto the coffee table, \n(2) placing a book next to it, (3) putting the index in the middle of the table, pressing \nslightly, and moving to the right, (4) \u2018clicking\u2019, (5) going back to the left, (6) \u2018clicking\u2019, (7) \ngoing more to the left, and (8) \u2018clicking\u2019 and releasing. The top plot shows the raw sensor \ndata, the middle and bottom plots the moving average and standard deviation over 10 \nsamples respectively. Notice how moving the index over the surface is clearly visible, for \nexample at (7), and the value of the standard deviation to pick out significant events. \nobjects, removing objects, moving the finger over the surface, and increasing pressure \nat a certain point while tracking. \nThe dataset presented here contains typical sensor data from the load cells that has \nbeen gathered to demonstrate the feasibility of the approach. Our particular interest \nwas in investigating tracking and clicking on a populated surface as well as putting \ndown different objects onto the surface. The dataset is from a small 80x80cm coffee \ntable, on which two objects were placed, after which it was used to track the \nmovement direction of the finger, plus the force that was used on it to identify a \n\u2018clicking\u2019 event.  \nFigure 3 shows the time series plot of the dataset, where the raw sensor data is \nplotted in time against its filtered moving average and standard deviation (See the \nfigure caption for a concise description of the events). The interval over which these \nstatistics were evaluated was experimentally verified at 10 samples. \nWe have also recorded data sets using considerably larger surfaces (such as a \ndining table, 135x75 cm approximately) and less sensitive load cells. Although there \nis a less distinguishable response for events in the standard deviation plot, peeks \nremain present, albeit with a significant difference between objects being placed onto \nthe surface, and the user directly touching it. \nThe basic statistics based on averaging and standard deviation can effortlessly be \nimplemented on small microprocessor. This approach proved to be sufficient in our \nfirst prototypes to let the user control a mouse cursor on a nearby computer screen. \nThis can also be deduced from Figure 3, where standard deviation of the raw sensor \nsignals gives distinct peaks whenever new pressure points are introduced, whether \nthey are from an object that has been placed on the surface, or from explicit user \ninteraction. \nAlthough the moving average filter over 10 samples produced satisfactory results \nfor our initial tracking purposes, we believe that using more elaborate tracking \nalgorithms (such as a Kalman filter, see [20] for an excellent introduction ) could \nenhance performance even more, with a negligible cost in implementation.  \nThe dataset presented here and other datasets are available for download at the \nproject website at [11]. \n5 System Implementation \nBased on the experience gained we implemented a distributed ubiquitous pointing \nsystem. It incorporates two tables that offer pointing capabilities and that are \nconnected over a wireless link to a device that is attached to a PC emulating a serial \nmouse. \n5.1 Tracking Tables \nWe converted two of the shelf tables into pointing devices by building load cells \nbetween the supporting structure and the table top. To explore the possibilities we \nused two different tables and different types of load cells. \nThe coffee table is equipped with load cells that measure a maximal load of 1kg \neach, so that the surface can reliably measure 4kg of load, see figure 5. A mechanical \noverload protecting is build into the table. If the table is in overload state (e.g. \nsomeone is sitting on the table) pointing is suspended.  \nFor the dining table we used 4 load cells each capable of measuring load up to \n50kg, resulting into an overall load of 200kg. Each load cell is robust against overload \nup to 100kg to ensure the system will not break under exceptionally high load. The \nload cells are mounted to the table top and on the legs of the table frame there are \nplanes where the load cells rest. See figure 4 and the accompanying video for details. \n5.2 Data Acquisition and Communication \nThe load cells used on the small table are essentially a wheat stone bridge providing a \nmaximal output signal of 20mV when the driving voltage is 5V. This output signal is \namplified by a factor of 220, resulting in a output signal of 0 to 4.4V (different values \napply for the larger table). The amplified output voltage of each of the load cells is \nthen converted into a digital value using the AD converter in the MCU, sampling each \nat 250Hz. The four input values correspond to F1(t), F2(t), F3(t), and F4(t). \nThe microcontroller (PIC16F876) is initialized with the size of the table and \ncalculates the position of the centre of pressure. If it is recognized that the table is in \nthe \u201cno interaction\u201d state (A) the values for F01, F02, F03, and F04 are updated with \n    \n \n \n \n \nFigure 4. Coffee table with build in load cells. \nthe average over the last 16 readings. Whenever the state \u201ctracking\u201d (C) is recognized \nthe relative change is calculated and is communicated. When the state \u201cclicking\u201d (D) \nis recognized by the software on the microcontroller this is also communicated as a \nbutton press event.  \nThe communication is done wireless using a RF transceiver module (Radiometrix \nBIM2) that offers up to 64kbit\/s. As the amount of data to communicate is very small \nand in order to get a better error performance, we run the protocol at 19200 bits\/s. \nEvents, either tracking or clicking, are communicated in one packet, which consists of \na preamble, followed by a start-byte, the identifier of the objects (coffee table or \ndinning table), an identifier stating that it is a mouse event, and then the offset in x, \nthe offset in y, and the click state. Finally two bytes of 16-bit CRC are attached to \nensure that the transmitted data is correct. The unit only transmits data, no \nacknowledgement for packets are performed, using a lower transmission speed proved \nvery reliable and also loosing a mouse movement or a button state is generally \nuncritical.  \nThe block diagram of the system is depicted in figure 6 and a labelled photo is \nshown in figure 7. The full schematic and further information on the components are \navailable from the project web page [11]. \n5.3 Mouse Emulation \nThe ubiquitous pointing device is attached to a PC via serial line. On the PC no extra \nsoftware is needed. The protocol used is the Microsoft mouse protocol, consisting of \nthree 7 bit words coding the button states and the relative movement since the last \npacket was sent. The same hardware as for data acquisition with different software is \nused as a base station receiving the pointing operations from the tables and converting \n \n \n                 Figure 5. resting point and load cell mounted under the table \ntop of a dinning table. \nthem into the serial Microsoft mouse format. When no packets are received the units \nsends from time data that indicates zero movements to the PC. When receiving the \npackets from the RF-transceiver and converting them into a mouse data stream it is \nnot differentiated from where the events have come from. For the PC it looks as a \nstream of mouse movements and events from a single mouse.  \n5.4 Access Control \nIn the implementation we omitted to enforce access control. When on two surfaces \ntracking and clicking actions are performed they are multiplexed into one stream of \nevents. In longer time intervals that is very reasonable, e.g. using the coffee table to \nswitch to another TV program and walking over to get some food and switching off \nthe TV from the dining table. However, in competitive situations where more people \nare pointing at the same time the outcome is not meaningful. As the envisioned use \ncases are in spaces where people communicate with each other we decided to leave \naccess control to be a social factor.  \nLoad\nCell\nLoad\nCell\nLoad\nCell\nLoad\nCell\namp amp amp amp\nAD conversion\nProcessing\nRF-Communication\nSerial\nCommunication\n \n \nFigure 6. The load sensing and communication unit. \nIn case where a strict access\/token control is required an implementation using \nlocking mechanism are straight forward. Whenever tracking or pointing action from \none device is received all other devices are locked out till the device communicates a \n\u201cno interaction\u201d state or a timeout has passed.  \n6 Use experience  \nThe described system has been fully implemented and installed in the Innovative \nInteractions Lab at Lancaster. This is an environment designed to flexibly recreate \ndomestic settings with everyday furniture, facilitating research into augmented \neveryday environment. Part of this lab has been fully augmented with load sensing as \ndescribed in an earlier publication [21].  \nFollowing the initial installation of the trackpad-enabled tables we first conducted \ntrials to establish reliability and robustness of the technology under simulated real-\nworld conditions. This involved use of the surfaces for controlling a web browser on \nan adjacent screen, in the presence of other interactions on the surface, such as \nplacement and removal of books, use of coffee cups, and so on. The technology \nproved to be perfectly reliable in detecting the correct interaction state, ie. not \nmistaking object placement as click for example. Some of these test sessions have \nbeen video taped for closer inspection of sensor-level observation and signal analysis \nin relation to carried out interactions. \nA second set of tests involved a larger number of users from other research groups \nat the Department. These users were all highly familiar with the use of the mouse as \npointing device. The test was aimed to establish whether a regular user of mouse or \ntrackpad devices would experience any difficulty in using our embedded technology. \n \n \n        Figure 7. microcontroller unit for load sensing, data acquisition, \nand wireless communication. \nAll of these users found our system intuitively usable, and were instantly able to \ncontrol a mouse on a screen, and to apply this in conjunction with our web browsing \nscenario. An interesting observation though was that the surface quality influenced \nuse experience. One of the tables had a nicely polished wood finish whereas the wood \ngrain on the other could still be felt. Tracking on the first surface was much more \npleasant than on the second. On the second surface we could also observe that people \ntried using objects that where on the table, such as a book or a lighter, instead of their \nfinger for pointing. In some instances, we covered the rough surface with a glass plate \nhalfway through the test, and feedback from users generally indicated that the \nsmoother surface greatly improved usability.  \nAs an installation in the Innovative Interactions Lab, the trackpad-enabled tables \ncontinue to be used spontaneously in particular with visitors. Spontaneous use without \nparticular maintenance or preparation further supports our claim that the technology is \nrobust, reliable, and intuitively usable.   \n7 Related Work \nInteraction in non-desktop environments is a central research question addressed in \nmany projects recently. In [9] a number of issues are addressed that arise from putting \ncomputing into everyday surroundings. Ethnographic research carried out in such \nenvironments, which differ significantly from work desktop environments, suggests \nthat tables often are the centre of interaction [5].  \nTables have been investigated as computing and CSCW platform in various \nprojects. In most projects the focus is to integrate input and output media into the \ntable and create a new interactive experience. An advanced system of this type of user \ninterface is described in [6]. In our work we deliberately concentrated on using tables \nas input devices only while preserving their original properties and expression. The \nInteracTable [15] is a table that offers both input and output. A touch screen \ntechnology is used for the input, however, which makes the table rather an additional \ncomputing device than a table with additional capabilities, as objects can not be \nplaced on the table surface. \nA different approach to realize ubiquitous pointing is to provide the user with an \nadditional device. An example of a generalized contextual remote control is presented \nin [2]. The FieldMouse is an approach to realizing ubiquitous interaction as well [14]. \nIts extension, using barcode tagging offers a general mechanism for interaction that is \nrelated to physical objects [12]. In contrast to our work the interface is a device that \nthe user carries along rather than a direct interaction opportunity within the \nenvironment.  \nIn [4], issues and techniques that are relevant in the process of designing touch \nsensitive input devices are presented. A comprehensive directory of input devices is \nalso maintained at [3] by the same author. \nLoad cells and force sensing has been used in a number of projects where ground \nreaction forces were used as additional or alternative input. A tiled floor that can \ndistinguish people was presented in [1], while a similar arrangement using a single \nfloor tile is describe in [13]. Experiments in these publications show that ground \nreaction forces are different between people and can therefore be used to discriminate \nthem. The tiled floor was also used as input device to a computing game [8]. For \nmeasuring the ground reaction force, especially in biometrics, commercial products \nsuch as the Kistler Plate [10] are available as well. Using load cells in our prototype \nwe exploit the same phenomenon, however the forces introduced are intended to be \nfrom explicit manual interaction rather than from walking or jumping. \n7 Discussion and Future Work \nThe implementation and use of the trackpad-enabled tables leads to some interesting \nobservations and considerations for future work.  \nThe implementation of the state transitions requires selection of threshold values. \nIn general a trade-off between two approaches, defensive or optimistic, exists. In the \ndefensive version actions and events are only performed when the recognition \nalgorithm is absolute sure that the event was performed. This usually introduces some \ndelay or the interaction is not performed at all. The optimistic approach performs \nactions and events even when the recognition algorithm is not quite sure if the event \nhas really occurred.  \nThe sensor pattern created when putting an object onto the surface, for instance, is \noften similar to the initial phase of the tracking. In a defensive approach the system \nwaits till it can reliably discriminate the two actions and only performs tracking when \nit is sure that the action is tracking, as opposed to it being an object that has been put \ndown. In an optimistic approach, the data is used from the very start to move the \npointer and when it is recognized that it was an object pointing is suspended. Our \nexperience showed that immediate reaction is a critical feature for novel users, and \ntherefore our implementation leans towards an optimistic pointing behavior, risking \ndisplacement of the pointer when the system gets it wrong. For the clicking we \nimplemented a defensive approach, as clicks tend to be unacceptable at the wrong \nlocation.  \nIn casual settings we also realized that people often put their elbows onto the edges \nof the table, while no pointing takes place. This can easily be detected using position \ninformation, also providing a means to adjust to the orientation of the user that is \nsitting in front of the surface. This could also offer a solution to the table top \norientation problem discussed in [7]. We assume as a rule that during pointing the \nelbows are not placed on the surface. The current implementation showed also that \nthe captured data is most critical for determining the user interaction. The second \nhardware generation will therefore contain increased precision amplifiers and 24bit \nA\/D converter to increase the quality of the sensor data. \nIn the wireless protocol from the surface to the base station, the additional \ninformation on which surface the interaction took place is communicated as well. This \ninformation is not being used at this point, as it has solely been connected as a serial \nmouse so far. However, it could prove interesting to use this as contextual information \non where the pointing action was performed. \n8 Conclusions \nThis paper proposes the use of load sensors on the corners of a surface as an \naffordable alternative to traditional pointing methods, using infrastructure that is \npresent in every home and office environment.  \nBoth experiments and prototype implementations indicate that it is feasible to add \npointing capabilities to traditional tables without scarifying or interfering with the \noriginal properties and intended use. Initial experiences while running the prototypes \nin our living lab environment show a potential and suggested also further \nimprovements. \nAcknowledgements \nThis research was made possible with funding from the UK Engineering and Physical \nSciences Research Council for the Equator IRC (EPSRC GR\/N15986\/01, \nhttp:\/\/www.equator.ac.uk\/), and from the Commission of the European Union for the \nSmart-Its project (IST-2000-25428, http:\/\/www.smart-its.org\/). \nReferences \n1. Addlesee, M.D., Jones, A., Livesey, F., and Samaria, F. ORL Active Floor. IEEE \nPersonal Communications, Vol.4, No 5, Oct 1997, pp. 35-41.  \n2.  Beigl, M.. Point & Click - Interaction in Smart Environments, Proc. 1st Intl \nSymposium on Handheld and Ubiquitous Computing (HUC99), Karlsruhe, \nGermany, October 1999, Lecture Notes in Computer Science No. 1707, Springer-\nVerlag, pp 311-314. \n3. Buxton, B. A directory of sources for input technologies. 2002.  \nhttp:\/\/www.billbuxton.com\/InputSources.html \n4. Buxton, W., Hill, R. and Rowley, P., Issues and Techniques in Touch-Sensitive \nTablet Input in Proceedings of Siggraph \u201985 (July 22-26, San Francisco), \nACM\/Siggraph, 1985, pp. 215-224 \n5. Crabtree, A., Hemmings, T. and Rodden, T.. Pattern-based Support for \nInteractive Design in Domestic Settings. Technical Report Equator-01-016, \nUniversity of Nottingham, The School of Computer Science and IT, December \n2001. http:\/\/www.equator.ac.uk\/papers\/Authors\/crabtree.html \n6. Deitz, P. and Leigh, D. (2001). DiamondTouch: A Multi-User Touch \nTechnology. Proc. of UIST\u201901, pp. 219-226. \n7. Hancock, M.S. Mandryk, R. L. Scott, S. D, Inkpen, K. M. Determining User-\nLocation at Interactive Tabletops. Submitted to CHI 2002 \nhttp:\/\/www.sfu.ca\/~mhancock\/portfolio\/tableaware.html \n8. Headon, R. and Curwen R. Ubiquitous Game Control. In UBICOMP Workshop \non Designing Ubiquitous Computing Games. Atlanta, 2001. \n9. Kidd, Cory D., Robert J. Orr, Gregory D. Abowd, Christopher G. Atkeson, Irfan \nA. Essa, Blair MacIntyre, Elizabeth Mynatt, Thad E. Starner and Wendy \nNewstetter. The Aware Home: A Living Laboratory for Ubiquitous Computing \nResearch. In the Proceedings of the Second International Workshop on \nCooperative Buildings - CoBuild'99. Position paper, October 1999. \n10. Kistler force plate. http:\/\/www.kistler.com\/ \n11. Lancaster University, Embedded load sensing project \nhttp:\/\/www.comp.lancs.ac.uk\/~albrecht\/load\/ \n12. Masui, T., Siio, I.. Real-World Graphical User Interfaces. In Proceedings of the \nInternational Symposium on Handheld and Ubiquitous Computing (HUC2000), \npp.72-84, , 2000.9.25-27. \n13. Orr, R. J. and Abowd G. D. The Smart Floor: A Mechanism for Natural User \nIdentification and Tracking.  In Proceedings of CHI 2000 Human Factors in \nComputing Systems (April 1\u20136, 2000, The Hague, Netherlands), ACM\/SIGCHI. \n14. Siio, I., Masui, T., Fukuchi, K. \"Real-world Interaction using the FieldMouse\" \nCHI Letters, Vol.1, Issue 1 (Proceedings of the UIST'99), pp.113-119, ACM \nPress, Nov. 7-10,1999 \n15. Streitz, N.A.,  Gei\u00dfler, J.,  Holmer, T.,  Konomi, S.,  M\u00fcller-Tomfelde, C.,  \nReischl, W.,  Rexroth, P.,  Seitz, P., and Steinmetz, R. i-LAND: An interactive \nLandscape for Creativitiy and Innovation. Proc. CHI '99, Pittsburgh, PA, U.S.A., \nMay 15-20, 1999. ACM Press, New York, pp. 120-127. \n16. Ishii, H. and Ullmer, B., \"Tangible Bits: Towards Seamless Interfaces between \nPeople, Bits and Atoms,\" Proceedings of Conference on Human Factors in \nComputing Systems (CHI '97), ACM, Atlanta, March 1997, pp. 234-241. \n17. Elin R\u00f8nby Pedersen, Tomas Sokoler: AROMA: Abstract Representation of \nPresence Supporting Mutual Awareness. CHI 1997: 51-58 \n18.  M. Weiser, \"The Computer for the 21st Century,\" Scientific American 265, No. 3, \n94-104 (September 1991). \n19. Wellner P, Mackay W, Gold R (1993). Computer-Augmented Environments: \nBack to the Real World. Communications of the ACM, 36(7), pp. 24-26. \n20. Welsch, G. and Bishop G. An introduction to the Kalman Filter. TR 95-041, \nDepartment of Computer Science, University of North Carolina at Chapel Hill. \nMarch, 2002. \n21.  A. Schmidt, M. Strohbach, K. Van Laerhoven, A. Friday and H.W. Gellersen. \nContext acquisition based on Load Sensing. Proc. Ubicomp 2002, Gothenburg, \nSweden, Sept. 2002.   \n22.   A. Schmidt. Implicit Human Computer Interaction Through Context. In Personal \nTechnologies Volume 4(2&3), June 2000. pp 191-199. \n \n \n"}
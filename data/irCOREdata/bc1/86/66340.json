{"doi":"10.1109\/TVCG.2006.114","coreId":"66340","oai":"oai:dro.dur.ac.uk.OAI2:1901","identifiers":["oai:dro.dur.ac.uk.OAI2:1901","10.1109\/TVCG.2006.114"],"title":"A trajectory-preserving synchronization method for collaborative visualization.","authors":["Li., L.","Li, F.","Lau, R."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2006-10","abstract":"In the past decade, a lot of research work has been conducted to support collaborative visualization among remote users over the networks, allowing them to visualize and manipulate shared data for problem solving. There are many applications of collaborative visualization, such as oceanography, meteorology and medical science. To facilitate user interaction, a critical system requirement for collaborative visualization is to ensure that remote users will perceive a synchronized view of the shared data. Failing this requirement, the user&#194;&#191;&#194;&#191;s ability in performing the desirable collaborative tasks will be affected. In this paper, we propose a synchronization method to support collaborative visualization. It considers how interaction with dynamic objects is perceived by application participants under the existence of network latency, and remedies the motion trajectory of the dynamic objects. It also handles the false positive and false negative collision detection problems. The new method is particularly well designed for handling content changes due to unpredictable user interventions or object collisions. We demonstrate the effectiveness of our method through a number of experiment","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/66340.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/1901\/1\/1901.pdf","pdfHashValue":"917fc7347af07dddc97963ee70001cb0a494b767","publisher":"IEEE","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:1901<\/identifier><datestamp>\n      2011-08-10T15:30:08Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        A trajectory-preserving synchronization method for collaborative visualization.<\/dc:title><dc:creator>\n        Li., L.<\/dc:creator><dc:creator>\n        Li, F.<\/dc:creator><dc:creator>\n        Lau, R.<\/dc:creator><dc:description>\n        In the past decade, a lot of research work has been conducted to support collaborative visualization among remote users over the networks, allowing them to visualize and manipulate shared data for problem solving. There are many applications of collaborative visualization, such as oceanography, meteorology and medical science. To facilitate user interaction, a critical system requirement for collaborative visualization is to ensure that remote users will perceive a synchronized view of the shared data. Failing this requirement, the user&#194;&#191;&#194;&#191;s ability in performing the desirable collaborative tasks will be affected. In this paper, we propose a synchronization method to support collaborative visualization. It considers how interaction with dynamic objects is perceived by application participants under the existence of network latency, and remedies the motion trajectory of the dynamic objects. It also handles the false positive and false negative collision detection problems. The new method is particularly well designed for handling content changes due to unpredictable user interventions or object collisions. We demonstrate the effectiveness of our method through a number of experiments<\/dc:description><dc:subject>\n        Collaborative visualization<\/dc:subject><dc:subject>\n         Network latency<\/dc:subject><dc:subject>\n         Motion synchronization<\/dc:subject><dc:subject>\n         Distributed synchronization.<\/dc:subject><dc:publisher>\n        IEEE<\/dc:publisher><dc:source>\n        IEEE transactions on visualization and computer graphics, 2006, Vol.12(5), pp.989-996 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2006-10<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:1901<\/dc:identifier><dc:identifier>\n        issn:1077-2626<\/dc:identifier><dc:identifier>\n        doi:10.1109\/TVCG.2006.114<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/1901\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1109\/TVCG.2006.114<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/1901\/1\/1901.pdf<\/dc:identifier><dc:rights>\n        \u00a92006 IEEE. Personal use of this material is permitted. However, permission to reprint\/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE.<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["1077-2626","issn:1077-2626"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2006,"topics":["Collaborative visualization","Network latency","Motion synchronization","Distributed synchronization."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n08 October 2008\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nLi., L. and Li, F. and Lau, R. (2006) \u2019A trajectory-preserving synchronization method for collaborative\nvisualization.\u2019, IEEE transactions on visualization and computer graphics., 12 (5). pp. 989-996.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1109\/TVCG.2006.114\nPublisher\u2019s copyright statement:\n2006 IEEE. Personal use of this material is permitted. However, permission to reprint\/republish this material for\nadvertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists,\nor to reuse any copyrighted component of this work in other works must be obtained from the IEEE.\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n Use policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without \nprior permission or charge, for personal research or study, educational, or not-for-profit purposes \nprovided that : \n \n\u0083 a full bibliographic reference is made to the original source \n\u0083 a link is made to the metadata record in DRO \n\u0083 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright \nholders.  \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nDurham Research Online \n Deposited in DRO:\n08 October 2008\nVersion of attached file:\nPublished\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nLi., L. and Li, F. and Lau, R. (2006) 'A trajectory-preserving synchronization method for collaborative visualization.',\nIEEE transactions on visualization and computer graphics., 12 (5), pp.\u0000989-996.\nFurther information on publishers website:\nhttp:\/\/dx.doi.org\/10.1109\/TVCG.2006.114\nPublishers copyright statement:\n\u00a92006 IEEE. Personal use of this material is permitted. However, permission to reprint\/republish this material\nfor advertising or promotional purposes or for creating new collective works for resale or redistribution to servers\nor lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE.\nIEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 12, NO. 5, SEPTEMBER\/OCTOBER 2006 \n \nA Trajectory-Preserving Synchronization Method for \nCollaborative Visualization\nLewis W.F. Li, Frederick W.B. Li, and Rynson W.H. Lau \nAbstract\u2014In the past decade, a lot of research work has been conducted to support collaborative visualization among remote \nusers over the networks, allowing them to visualize and manipulate shared data for problem solving. There are many applications \nof collaborative visualization, such as oceanography, meteorology and medical science. To facilitate user interaction, a critical \nsystem requirement for collaborative visualization is to ensure that remote users will perceive a synchronized view of the shared \ndata. Failing this requirement, the user\u2019s ability in performing the desirable collaborative tasks will be affected. In this paper, we \npropose a synchronization method to support collaborative visualization. It considers how interaction with dynamic objects is \nperceived by application participants under the existence of network latency, and remedies the motion trajectory of the dynamic \nobjects. It also handles the false positive and false negative collision detection problems. The new method is particularly well \ndesigned for handling content changes due to unpredictable user interventions or object collisions. We demonstrate the \neffectiveness of our method through a number of experiments. \nIndex Terms\u2014Collaborative visualization, network latency, motion synchronization, distributed synchronization.\n \n1 INTRODUCTION \nCollaborative visualization [10] allows geographically separated \nusers to access a shared virtual environment to visualize and \nmanipulate datasets for problem solving without physical travel. \nExample works include fluid dynamics visualization [27], volume \nvisualization [1] and medical data visualization [26]. In contrast to \nthose working individually with standalone visualization applications, \nresearch studies have found that users working in groups through \ncollaborative visualization applications can often work out a better \nsolution for a given problem [17]. To facilitate collaborative dataset \nmanipulation for visualization, CSpray [21] was designed to \ncomprise a \u201cspray-paint can metaphor\u201d for users to edit a dataset in a \ngraphical way. A control mechanism is provided for users to modify \nthe dataset in a mutually exclusive manner. If a user changes the \ndataset, updates of the dataset will be broadcasted to remote users. \nHowever, the system does not address the inconsistency problem of \ndynamic objects due to network latency. Hence, if we conduct \nvisualization on a time-dependent dataset [9], such as thunderstorms \nand tornados, synchronization of the dataset among remote users \nwould be difficult. First, as this type of dataset changes continuously \nover time, it is difficult to guarantee that each of these changes will \nbe reported timely to the remote users throughout the collaboration \nsession. Second, as different users may be connected to each other or \nto the server via different network routes, they may perceive \ndifferent amounts of network latency, and hence delay, in receiving \nthe update messages. Although it is possible to introduce a further \ndelay for the updated information to be presented to the users at a \nsynchronized moment [7], it will substantially affect the interactivity \nof the collaboration.  \nRecently, we have developed a method to support global-wise \nsynchronization for collaborative applications [14]. The method runs \na reference simulator for each dynamic object on the application \nserver. Each of the clients interested in the object, including those \nthat access the objects as well as the owner of the object, will \nexecute a gradual synchronization process on the local copy of the \nobject to align its motion to that of the reference simulator running at \nthe server. Our results show that the method effectively reduces the \nnetwork latency by half and quickly align the motion of the \nreplicated object to that of the original dynamic object. However, the \nmethod still suffers from a high error during the period when an \ninteraction has just occurred and before the interaction message has \nreached the client, causing the users to make inappropriate decisions. \nIt may also leads to the false positive and false negative collision \nproblems as discussed later. \nIn this paper, we present a trajectory-preserving synchronization \nmethod, which significantly extends our previous work [14] to \nsupport collaborative visualization. It considers how spatial changes \nand interactions of dynamic objects are affected by network latency. \nA set of procedures have been developed to correct the motion \ntrajectory of the dynamic objects. In addition, solutions have also \nbeen provided to handle the false positive and false negative \ncollision detection problems. To demonstrate the effectiveness of our \nmethod, we have conducted experiments on a prototype system for \nflow visualization [25]. With this prototype, users may manipulate \ndynamic objects with the CyberGloves, which are electronic gloves \nfor sensing hand and finger motions, to intervene the flow of a \ndataset for visualization. The dynamic and interactive nature of this \nprototype provides an efficacious testbed for verifying the \neffectiveness of the new method.  \nThe rest of the paper is organized as follows. Section 2 briefly \nsummarizes related work. Section 3 outlines the foundation of our \nmethod. Section 4 presents in detail our trajectory-preserving \nsynchronization method. Section 5 shows how the new method \nhandles object collisions. Section 6 studies the performance of the \nproposed method with a number of experiments. Finally, Section 7 \nbriefly concludes the work presented in this paper. \n2 RELATED WORK \n2.1 Collaborative Applications \nA unique characteristic of collaborative applications is the need to \ndistribute state updates to remote sites over the network to update the \nstates of the shared objects at these sites. Because of network latency, \ndifferent remote sites may receive the updates after different amounts \nof delay, causing the view discrepancy problem at these sites. \nNevertheless, traditional applications such as [2] and [12] may still \nwork well under the existence of network latency as long as the state \nupdates are received by the remote sites in a correct order. This is \n \nx Lewis W.F. Li is with Department of Computer Science at City University \nof Hong Kong, Hong Kong, E-Mail: kwfli@cs.cityu.edu.hk. \nx Frederick W.B. Li and Rynson W.H. Lau are with Department of Computer \nScience at University of Durham, United Kingdom., E-Mail:  \n{Frederick.Li | Rynson.Lau} @durham.ac.uk. \nManuscript received 31 March 2006; accepted 1 August 2006; posted online 6 \nNovember 2006. \nFor information on obtaining reprints of this article, please send e-mail to: \ntvcg@computer.org. \n989\n1077-2626\/06\/$20.00 \u00a9 2006 IEEE       Published by the IEEE Computer Society\nAuthorized licensed use limited to: IEEE Xplore. Downloaded on October 8, 2008 at 09:13 from IEEE Xplore.  Restrictions apply.\nIEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 12, NO. 5, SEPTEMBER\/OCTOBER 2006 \nbecause these applications typically have a large time gap between \nany two consecutive updates as compared with the network latency. \nAs such, the network latency becomes insignificant and the users can \nimplicitly perceive synchronized application content at all times. \nHowever, collaborative applications that involve time-dependent \ndata and continuous user interaction may be different from the above \napplications. The state update events in these applications are \ncontinuous [18] in nature. In order for users to interact with the \nsystem based on the same updated view of the data, the updates need \nto be presented to the remote users either without any delay or at \nleast within a very short period of time. However, this is not trivial to \nachieve. An early attempt to explore the discrepant views among \nremote users on shared data due to network latency was done in \nDEVA3 [22], which claimed that inconsistency may be tolerated if \nlatency is small enough. Some works have been conducted to study \nhow the delay in delivering state updates will affect the interactivity \nof collaborative applications [4, 21]. To cope with the latency \nproblem, adaptations could be performed at either the user or the \nsystem side. For user side adaptation, [24] proposes to explicitly \ndisclose delay information to the users and let the users adjust their \nbehavior by themselves to cope with the state discrepancy problem. \nUnfortunately, this arrangement is subjective to different users and \nwould heavily slow down the user interaction. \nFor system side adaptation, a popular approach is to use dead \nreckoning [16]. With this approach, the controlling client of a \ndynamic object runs a motion predictor for the object. Other clients \naccessing the object also run the same motion predictor to drive the \nmotion of the local copies of the object. The controlling client is \nrequired to keep track of the error between the actual and predicted \nmotions of the object, and sends the updated motion information to \nthe other clients when the error is higher than a given threshold. \nAlthough this approach is very simple, it does not guarantee that the \nstate of a shared object could be synchronized among all the remote \nclients.  \nIn [18], a local-lag mechanism is proposed to address this \nproblem. When the controlling client issues a state update of the \ndynamic object, the update will be sent to the remote clients \nimmediately but not to the sender itself until a local-lag period is \nexpired. This is to reduce the discrepancy between the sender and the \nreceivers. However, as different pairs of clients may suffer from \ndifferent amounts of latency, a single value of local-lag can only be \nused to synchronize two clients, the sender and the receiver, but not \namong a number of clients. In [3], users make use of the reference \nstate information from the server to correct the states of their local \ncopies of the dynamic objects. Again, there is no control mechanism \nto guarantee that the states generated at a client would be \nsynchronized with those at other clients. \n2.2 Clock Synchronization \nThe synchronization problem has also been studied by researchers \nworking on clock synchronization. In particular, Network Time \nProtocol (NTP) [19] has been adopted as a standard for computers \nconnected via the Internet to synchronize their clocks to within 10ms \nof error. It relies on selecting and filtering time information from a \nset of time servers. On the other hand, there are also different \nstrategies proposed in adjusting the local clock when the correct time \ninformation is received [10, 12, 20]. Backward correction [11] and \nforward correction [23] are two approaches, which make a backward \nor a forward adjustment on the clock value, respectively. \nUndesirably, they introduce a time discontinuity problem to the \nclock. [13] addresses this problem by speeding up or slowing down a \nclock to synchronize it against a reference clock. However, it incurs \na severe run-time overhead as it needs to adjust the time once at \nevery clock tick. Hence, it generally requires hardware support. To \nreduce the overhead, [15] proposes an adaptive method for clock \nsynchronization. It uses a time server to propagate time information \nto the clients via a re-synchronization process for the clients to \ndetermine their clock drift rates. The time between two consecutive \nre-synchronization processes will be shortened or lengthened based \non the drift rate of a client clock. It is set inversely proportion to \nclock drift rate. At the client, clock correction is performed by \nextrapolating the clock continuously with the newest clock drift rate \ndetermined in the latest re-synchronization process. \nAlthough methods used in clock synchronization appear to \naddress the synchronization problem in collaborative visualization, it \nis difficult to apply them directly to address the problem. First, the \ntime value in clock synchronization is only a parameter with a single \ndegree-of-freedom, while the motion parameters of the datasets for \nvisualization may have three or higher degrees-of-freedom. Second, \nthe clock information is periodic, i.e., the occurrence of a time event \nis predictable. This simplifies the synchronization problem. In \ncontrast, the motion of the datasets for visualization is likely \nunpredictable, especially when user interactions or object collisions \nare possible. Third, in clock synchronization, the time server is the \nprime reference for all clocks, which only need to synchronize to the \nchanges from the time server. In collaborative visualization, however, \nany user may initiate its own actions to manipulate a dataset and \nsuch actions need to be synchronized among all the users. \n3 FOUNDATION \n3.1 Consistency Control Model \nIn [14], we proposed a relaxed consistency control model to \nsynchronize the object states among remote clients in collaborative \napplications. We observed that application users would likely pay \nmore attention on the state trajectory of a dynamic object, i.e., the \ncontinuous sequence of state changes of the object, rather than on the \nindividual states of the object in order for them to determine their \nactions to respond. Hence, we proposed to relax the strict time-\ndependent consistency control requirement on individual states of a \nreplicated object among all relevant clients to allow the state \ntrajectories of the replicated object among the relevant sites to \ndeviate from that of the correct one by an acceptable amount. \nFormally speaking, given that the states of a replicated object at two \nremote sites at time t are si(t) and sj(t), the state discrepancy D of the \nobject between the two sites during any time period Ta and Tb should \nbe smaller than an application specific tolerance, [ . Therefore, \n\u00b3 \u001f\u0010 b\na\nT\nT ji\ndttstsD [|)()(|  (1)\nThis relaxed model could be reverted back to the original strict \ntime-dependent consistency control model if we shorten the time \nperiod so that Ta = Tb and set tolerance [ = 0. \n3.2 Gradual Synchronization \nTo implement the consistency control model, we have developed a \ngradual synchronization method [14] to trade accuracy of individual \nstates of a dynamic object for the preservation of the state trajectory \nof the object. We assume that a collaborative application has a client-\nserver architecture. The server runs a simulator, called a reference \nsimulator, for each dynamic object. This reference simulator serves \nas a standard reference for synchronizing the motion of all copies of \nthe object at different remote clients. Each client interested in an \nobject will also run a simulator as a local copy of the object. This \nmethod effectively reduces the latency of a client to obtain the \nupdated state of an object from a double round-trip time delay to a \nsingle one.  \nTo simulate object motions, we need to apply appropriate motion \nequations [8] to drive the motion of the objects. For example, we \nmay apply a first-order predictor (or a more advanced method [5]) to \ndrive an object when it is under the user\u2019s control: \nVtppnew u\u000e  (2)\nwhere p is the current position of the dynamic object, t is the time \ndifference between p and pnew, and V is the motion vector of the \n990\nAuthorized licensed use limited to: IEEE Xplore. Downloaded on October 8, 2008 at 09:13 from IEEE Xplore.  Restrictions apply.\nLI ET AL.:  A TRAJECTORY-PRESERVING SYNCHRONIZATION METHOD FOR COLLABORATIVE VISUALIZATION \n \nobject. When we need to simulate object interactions and responses, \nwe may apply a second-order predictor instead: \n  22AtVtppnew \u000e\u000e  \nAtVVnew \u000e  \n(3)\n(4)\nwhere A is the acceleration vector of the dynamic object, and t is the \ntime difference between V and Vnew. For the simulation of flows, \nsuch as water, smoke or fire, we may apply appropriate motion \nequations according to their behaviors [6].  \nDuring run-time, two motion timers Ts and Tc are maintained at \nthe server and the client, respectively. They are the virtual clocks \nindicating how long a dynamic object has been performing certain \nmovement as perceived by the server and by the client. Hence, they \nrepresent t in Eq. (2) to (4). When a dynamic object changes its \nmotion, each interested client will gradually align the motion of its \nlocal copy of the object to that of the reference simulator at the \nserver by adjusting the increment rate of Tc of the object. The \nsimulator of the object at the client and the reference simulator of the \nobject at the server are said to be synchronized when Tc = Ts.  \nIn general, this method successfully maintains the consistency of \ndynamic objects in collaborative applications, except between the \nperiod when an interaction has just occurred and before the update \nmessage reaches the remote client. During this period, the two sites \ncan have a very high discrepancy. Although this discrepancy will be \nsettled shortly after the update message is received at the remote \nclient, it still produces a high visual error during this period. This can \nbe serious if the interactions occur frequently. \n4 TRAJECTORY-PRESERVING SYNCHRONIZATION \nThe new synchronization method extends our earlier method [14] by \nconsidering how interactions are perceived by the remote users or the \nserver in the existence of network latency. It includes separate \nmechanisms for handling client-server and client-client \nsynchronizations. To simplify our discussion, Figures 1 to 3 help \nillustrate our method graphically. We assume that client A initiates a \nmotion change to a dynamic object, which can be a user controlled \nobject or a primitive object of a dataset in flow simulation. A motion \ncommand is then generated as a result of the motion change and sent \nto the server to update the motion of the corresponding reference \nsimulator S. Concurrently, client B is visualizing the change of the \nobject and needs to gather updates of the object from the reference \nsimulator running at the server. \n4.1 Client-Server Synchronization \nAs shown in Figure 1, before a new motion occurs at Pinit, the \nmotions of the dynamic object at client A and of its reference \nsimulator S are synchronized. When the object is driven to move in a \nnew direction Vnew by a script, by a user interaction or by an object \ncollision, a motion command is generated. However, as it will take \ntime for this motion command to reach the server, S will continue to \nmove in its current direction until Pstart, when the server receives the \nmotion command. This discrepant motion is represented as the \nexpected motion vector Vr, and its motion would last for the time \nduration of a half round-trip delay.  \nTo remedy the state discrepancy problem during motion change, \nwe propose to adjust the motion of the dynamic object at A gradually \nto align with that of S. This motion remediation method helps \nminimize the state discrepancy raised during a motion change while \npreserving the motion trajectory as much as possible. It is shown by \nthe blue arrows in Figure 2. First, instead of driving the dynamic \nobject at A solely with Vnew, we let it move in the direction of the \nvector sum of Vnew and Vr for the time duration estSAT \u0010 , where \nest\nSAT \u0010  is \nthe estimated latency between client A and the server collected from \nrecent statistics [14]. Note that estSAT \u0010  is used instead of the real \nlatency (half round-trip time) TA\u2013S, since the most updated TA\u2013S is not \ncurrently available at the client. After that, we set the motion of the \ndynamic object to move in the direction of Vnew. Once the server has \nreceived the new motion command from A, it will reply the client by \nsending it the values of Pstart and Ts. Upon the reception of such \ninformation, A will evaluate the residual state discrepancy Vdis as the \nvector difference between Pcurr of the object at the server and the \ncurrent position of the object at A, where Pcurr = Pstart + (TA\u2013S + Ts) \u00d7 \nVnew and TA\u2013S is the most updated latency. With the value of Vdis, we \nmay further remedy the motion of the dynamic object at A to move \nin the direction of the vector sum of Vnew and Vdis. Hence, such \nmotion could eventually be synchronized with that of S at Psync. \nFinally, we again resume the motion of the object at A to move in the \ndirection of Vnew. \n \nFig. 1. The state discrepancy problem during motion change. \nServer applies\nthe new motion\nClient starts\na new motion (Vnew)\nReception of \nPstart and Ts\nNew motion at server\nNew motion at client\nState discrepant vector \n(Vdis)\nSynchronized motion\nAmended client motion\nVector sum of \nVnew and Vr\nVdis\nPcurr\nPstart\nPsync\n \nFig. 2. Motion remediation in client-server synchronization. \n4.2 Client-Client Synchronization \nFigure 3 shows our motion remediation process to address the state \ndiscrepancy problem in client-client communications. Using the \nsame scenario and notation as in the client-server synchronization \nexample, we consider the situation that client B is interested in the \nmotion of the dynamic object driven by client A. Hence, the server \nneeds to propagate the motion information of the object to B. Before \nthe object is driven to move in a new direction, the motions of S at \nthe server and the local copy of the object at B are synchronized at \nPstart. Assuming that S is driven to move in a new direction Vnew \nwhen an interaction occurs, Vnew will then be propagated to B. Again, \nit will take time for this motion command to arrive at B. Thus, the \nlocal copy of the object at B is expected to continuous moving in its \ncurrent direction until client B receives Vnew. Then, B will estimate \nthe state discrepancy Vdis as the vector difference between Pcurr of the \nobject at the server and the current position of it at B, where \nnew\nest\nBSstartcurr VTPP u\u000e \u0010 . Note that \nest\nBST \u0010  is the estimated latency \nbetween client B and the server collected from recent statistics. With \nVdis, we may amend the motion of the object in B to move in the \ndirection of the vector sum of Vnew and Vdis such that it could \neventually be closely synchronized with that of S at Psync. At this \npoint, we resume the motion of the local copy of the object to move \nin the direction of Vnew. This adjusted client motion is shown as \nbrown arrows in Figure 3. Hereafter, when client B receives the most \nupdated latency TS\u2013B, it will adjust the increment rate of Tc using TS\u2013B, \nwhich is the gradual synchronization process for client B to remedy \nany residual state discrepancy [14]. \n \n991\nAuthorized licensed use limited to: IEEE Xplore. Downloaded on October 8, 2008 at 09:13 from IEEE Xplore.  Restrictions apply.\nIEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 12, NO. 5, SEPTEMBER\/OCTOBER 2006 \n \nFig. 3. Motion remediation in client-client synchronization. \n4.3 Synchronization at an Arbitrary Moment \nOne important advantage of the new method is that a prior \nsynchronized state between a dynamic object and its reference \nsimulator is not required before a new synchronization cycle could \nbe taken place. Hence, our method can synchronize new motion \ncommands generated at any arbitrary moment, including during \nmotion remediation. We explain this with the example shown in \nFigure 4. While client A is executing a motion remediation process, \nit sends out another motion command to indicate that the motion of \nthe dynamic object has been changed to Vnew. Although the previous \nobject motion command at A has still not been synchronized with the \nreference simulator at the server, we may start a new client-server \nsynchronization process for the new motion command by applying \nthe new motion on the object immediately.  \nInstead of moving in Vnew, the dynamic object at A moves in the \ndirection of the vector sum of Vnew and Vr for the time duration of \nest\nSAT \u0010 , followed by the direction of Vnew until the client has received \nPstart and Ts from the server. Upon receiving such information, the \nclient evaluates the residual state discrepancy Vdis as the vector \ndifference between Pcurr of the object at the server and the current \nposition of the object at A, in the same way as described in Section \n4.1. With Vdis, we may further amend the motion of the object at A to \nmove in the direction of the vector sum of Vnew and Vdis such that this \nmotion and that of S could eventually be synchronized at Psync. \nFinally, we resume the motion of the object at A to move in the \ndirection of Vnew. \n \nFig. 4. Motion remediation at an arbitrary moment. \n5 HANDLING OF OBJECT COLLISIONS \nAnother critical issue in collaborative visualization is to assert a \nconsistent view among remote users in object collisions. This issue \ntypically does not exist in a standalone visualization application, \nsince updated states of dynamic objects are maintained and presented \nwithin a single client, where delay can be neglected. However, \nbecause of network latency and since each user may suffer from a \ndifferent amount of network latency, object collision information \nmay be presented to different users at different time moments. This \nmay lead to inconsistent object collision results. This problem is still \nan open research topic.  \nTo our knowledge, [20] is the only work that attempts to address \nthis problem. It uses dead reckoning to guide the motions of dynamic \nobjects and addresses the inconsistency problem as follows. First, \nwhen a client needs to detect possible collisions between two remote \nobjects or between one remote object and one static object, it uses \nthe local state information of these objects to compute a temporary \ncollision result for visual presentation. The collision result may then \nbe overridden by an updated one from the remote client when it is \navailable. This may, however, introduce temporary inconsistency on \nthe collision results among remote users. Second, when a client \npredicts that a collision will likely occur between its own controlled \nobject and a remote object, the system would instruct the remote \nclient to propagate the state of the remote object more frequently to \nthis client. This helps decrease the error in evaluating the collision \ndetection result at the client. This unfortunately would increase the \nnetwork loading. In addition, the false positive and false negative \ncollision results, which will be discussed next, are not considered in \nthis method. \n5.1 The Collision Problem \nIn our method, when an object collision occurs, we evaluate and \ninterpret the collision response as motion commands according to the \nreactions of the colliding objects. The motion commands would then \nbe fed as input to the motion predictors of the objects to update the \nobject motions. In this way, our synchronization method could \nnatively support the global-wise consistency of object collisions \namong the participants, i.e., the participating clients and the server. \nHowever, because of network latency, the new motion commands \nwill still be received and interpreted by each participant at a different \ntime moment. This may lead to a false positive or a false negative \ncollision detection result, which corresponds to an invalid or a \nmissing collision instance of an object, respectively. \nWe have identified all possible false positive and false negative \ncollision detection results as shown in Table 1. We assume that the \nroles of the clients and of the server are the same as those mentioned \nin Section 4. From Table 1, there are mainly two reasons leading to \nthe collision problem. First, when an object in client A changes its \nmotion during motion remediation, i.e., same situation as Section 4.3, \nthe motion of this object at client A and that of the reference \nsimulator at the server will be different temporarily. Second, as it \ntakes time for the motion commands to be delivered to client B, the \nmotion of the object in B will also be different from that of the \nreference simulator at the server. In both cases, inconsistent collision \nresults may be produced. \n5.2 The Algorithm \nTo address the collision problem, we follow our reference simulator \nscheme, where the motion of a dynamic object maintained at a client \nonly needs to be synchronized with that of the reference simulator at \nthe server. Thus, if we could resolve the collision problem between \neach client (either client A or client B) with the server, we would \nthen have handled the problem globally among all participants. \nBased on this observation, we convert the collision problem shown \nin Table 1 into two simpler problems, involving only two parties: \nclient A \u2013 server (Table 2) and client B \u2013 server (Table 3). To \naddress the collision problem, we may just handle individual cases \nshown in Tables 2 and 3 as follows: \n \nx Cases (a), (d), (e) and (h): As the collision problem does not \nexist, no actions are required. \nx Cases (c) and (g): A false positive collision occurs at the server. \nWhen a dynamic object changes its motion, the server will send \nan update message to client B to update the state of the object at \nB. To trade transient discrepancy of client A for global \nconsistency, the collision event detected at the server will be sent \n992\nAuthorized licensed use limited to: IEEE Xplore. Downloaded on October 8, 2008 at 09:13 from IEEE Xplore.  Restrictions apply.\nLI ET AL.:  A TRAJECTORY-PRESERVING SYNCHRONIZATION METHOD FOR COLLABORATIVE VISUALIZATION \n \nto both clients A and B to override the object motion there so \nthat they will both have the same object state.  \nx Case (b): A false negative collision result occurs at the server. \nSince the server does not detect a collision, it will not send out a \ncollision event, causing an inconsistency with client A. This \nproblem only occurs when client A issues a new motion \ncommand during motion remediation, which leads to a collision. \nTo trade transient discrepancy of client A for global consistency, \nwe inhabit client A to perform collision detection until the \nmotion remediation process has finished, which typically takes a \nround-trip time. \nx Case (f): A false positive collision result occurs at client B. This \nhappens only while the server is sending a motion command to \nclient B but the original motion of the object at B has already led \nto a collision. This problem could not be avoided but could be \nquickly corrected by the new motion command from the server, \nand the inconsistent state could only last for a half round-trip \ntime. As in case (b), to maintain global consistency, we inhabit \nclient B to perform collision detection until the motion \nremediation process has finished. This situation would last for \nanother half round-trip time.  \n \n6 RESULTS AND DISCUSSIONS \nTo study the performance of our method, we have developed a \nprototype to support flow visualization and dynamic user interaction. \nWe have tested it on a set of PCs with a P4 2.0GHz CPU, 1GBytes \nRAM and a GeForce4 Ti4200 graphics card. Each client machine has \na CyberGlove with a 3D tracker connected to it to capture the user\u2019s \nhand gesture and position. The CyberGlove allows a user to \nmanipulate the objects in an intuitive way inside the prototype \nenvironment, where each unit of spatial distance is defined as 1m. \nThe user may apply force to an object and use the object to intervene \na flow simulation. In addition, we have connected the machines \nthrough TCP connections, which handle the packet lost problem \nautomatically, and use timestamps to ensure message ordering. \nFigure 5 shows a series of screenshots from one of our experiments \non flow visualization. \nBefore the experiments, we first collected the latency statistics of \ndifferent network connections as show in Table 4. (Connection \nOverseas 1 measures the latency between Hong Kong and US, while \nOverseas 2 is created to model a long latency connection.) \n \nTable 4. Latency information for different network connections \nLatency (ms) Category \nMean Max. Min \nLAN (within a department) 5  7  0  \nIntranet (within a university) 40  57  32  \nOverseas 1 (modeling two nearby countries) 160  186 132  \nOverseas 2 (modeling two distant countries) 325  537 294  \n \n6.1 Experiment 1 \nThis experiment compares the performance of the new method with \nour original synchronization method [14] and dead reckoning [16] in \nterms of accuracy. It measures the object position discrepancy \nexperienced by relevant machines when two users are connected via \nan overseas link with a network latency of roughly 160ms as shown \nin Figure 6. In the experiment, we use first-order and second-order \npolynomials to model the motion of the object when it is being \ngrasped to move and thrown out by a user, respectively. \nTo simplify the discrepancy measurement without loss of \ngenerality, we observe in this experiment the motion of a selected \nobject, which is spherical in shape. The users have a full control on \nthe motion of this object and use the object to intervene a flow \nsimulation. However, to simplify this experiment, we have confined \nthe motion of all the tiny particles of the flow so that they do not \naffect the motion of the selected object. During the experiment, a \nuser (client A) is asked to pick up the selected object and move it \naround arbitrarily with a velocity of 1 m\/s. After around 4 seconds, \nthe user throws the object out with a velocity of 3m\/s under 9.8m2\/s \ngravity, it hits the floor and bounces up and down several times. The \nelastic coefficient of the object is 0.7. Such interaction is observed by \na remote user (client B). We have measured the position discrepancy \nof the object between client A \u2013 server (Figure 6(a)), server \u2013 client \nB (Figure 6(b)), and client A \u2013 client B (Figure 6(c)) during a fixed \nperiod of time. The position discrepancies exhibited by our original \nmethod, and the new method, and dead reckoning are shown in each \nof the three diagrams. \nWe assume that the positions of the object in the three machines \nare synchronized at 1s. As the user sudden changes the motion of the \nobject, we can see that there is an increase in discrepancy in all three \ndiagrams of Figure 6. In Figure 6(a), as dead reckoning does not \nperform any correction until when the server receives the update \nTable 2. Client A and server \ncollision problems \nCase Client A Server \n(a) \u00d7 \u00d7 \n(b) O \u00d7 \n(c) \u00d7 O \n(d) O O  \nTable 3. Server and Client B \ncollision problems \nCase Server Client B \n(e) \u00d7 \u00d7 \n(f) \u00d7 O \n(g) O \u00d7 \n(h) O O  \nTable 1. Possible false positive and false negative collision problems (\u00d7 indicates no collision and O indicates a collision) \nClient A Server Client B Collision Problem and Its Causes \n\u00d7 \u00d7 \u00d7 No collisions occur. The collision problem does not exist. \n\u00d7 \u00d7 O Before the new motion command arrives at client B, the motion of the object at B leads to a collision. False positive collision occurs. \n\u00d7 O \u00d7 Client A issues a new motion command during motion remediation, which does not lead to a collision. However, such command causes a false positive collision when it reaches the server. \n\u00d7 O O Client A issues a new motion command during motion remediation, which does not lead to a collision, while client B inherits the same state from the server. False positive collision occurs. \nO \u00d7 \u00d7 \nClient A issues a new motion command during motion remediation, which leads to a collision. However, this \ncommand does not cause a collision when it reaches the server, while client B inherits the same state from the \nserver. False negative collision occurs. \nO \u00d7 O \nClient A issues a new motion command during motion remediation, which leads to a collision. However, the \nnew command does not cause a collision when it reaches the server. False negative collision occurs. \nOn the other hand, before the new command arrives at client B, the motion of the object at B leads to a \ncollision, which does not correspond to the one at client A. False positive collision occurs. \nO O \u00d7 Client B does not receive the state update in time. False negative collision occurs. \nO O O Collision is detected correctly at all parties. No collision problems arise. \n \n993\nAuthorized licensed use limited to: IEEE Xplore. Downloaded on October 8, 2008 at 09:13 from IEEE Xplore.  Restrictions apply.\nIEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 12, NO. 5, SEPTEMBER\/OCTOBER 2006 \nmessage from client A, the discrepancy rises much more rapidly. In \naddition, it also lasts for longer as dead reckoning does not send out \nan update message to the server until the error between the actual \nand the predicted motions is high enough. With our previous method, \nwhen the object at client A changes motion, A would send out an \nupdate message to the server immediately and move the object at a \nreduced speed to minimize its discrepancy with the server. Hence, its \ndiscrepancy rises much slower than dead reckoning. The method that \nwe propose here is even more aggressive. It modifies the motion of \nthe object at client A to anticipate for the latency existed between A \nand the server. Hence, its discrepancy is further reduced.  \nWhen the server has received and applied the update to the object, \nthe object discrepancy using dead reckoning drops immediately. This \nhappens at around 1.2s. For our original and the new methods, we \nreceive the update message at around 1.16s, after 160ms of latency. \nThe reason for our methods to receive the update message slightly \nearlier than dead reckoning is that we do not need a thresholding \nprocess. Our original method would also have a sudden drop as we \nupdate the object position at the server to the actual position where \nthe object started to change motion at client A. However, the \ndiscrepancy would not drop to zero as the object in client A has \nalready moved some distance. This discrepancy will be further \nreduced as the object in client A continues to move in a reduced \nspeed than that of the server until they are synchronized. With the \nnew method, the discrepancy gradually reduces to zero \n(approximately) as we continue to correct the object motion at client \nA until it is synchronized with that in the server. \nIn Figure 6(b), the discrepancy of dead reckoning suddenly \nincreases as the server suddenly correct the object location when it \nreceives the update message from client A. This discrepancy \ncontinues to increase as the object in client B continues to move in \nits current direction until B receives the update message from the \nserver. Then, the discrepancy suddenly drops to zero as B applies the \nupdate to the object. With our original method, the rise in \ndiscrepancy is similar to dead reckoning except that here it happens \nearlier at about 1.16s instead of 1.2s and drops earlier at about 1.32s. \nHowever, the discrepancy would not drop to zero as we move the \nobject at client B to the location where the object started to change \nmotion at the server. This discrepancy will be further reduced as the \nobject in client B speeds up until it catches up with the object at the \nserver. With the new method, the discrepancy gradually reduces to \nzero as we continue to correct the object motion at client B. \nAt about 4s, client A throws the object out, which hits the floor \nand bounces up and down several times. This leads to a series of \nobject collisions. We discuss the performance of our method when \nwe apply it to collision detection in the next experiment. \n \n \n0.000\n0.100\n0.200\n0.300\n0.400\n0.500\n0.600\n0.700\n0.800\nTime(sec) 1.00 2.00 3.00 4.00 5.00 6.00 \nPo\nsi\ntio\nn \nD\nis\ncr\nep\nan\ncy\n (m\n)\nNew  Method\nOriginal Method\nDead Reckoning\n(a)\n \n0.000\n0.100\n0.200\n0.300\n0.400\n0.500\n0.600\n0.700\n0.800\nTime(sec) 1.00 2.00 3.00 4.00 5.00 6.00 \nPo\nsi\ntio\nn \nD\nis\ncr\nep\nan\ncy\n (m\n) (b)\n \n0.000\n0.100\n0.200\n0.300\n0.400\n0.500\n0.600\n0.700\n0.800\nTime(sec) 1.00 2.00 3.00 4.00 5.00 6.00 \nPo\nsi\ntio\nn \nD\nis\ncr\nep\nan\ncy\n (m\n) (c)\nFig. 6. Position discrepancies of the three methods, observed between: \n(a) client A and the server, (b) the server and client B, and (c) client A \nand client B. \nIn general, we may observe from Figure 6 that although the dead \nreckoning method is very simple, it produces high discrepancy \nduring motion changes. Our original method is successful in \nreducing the discrepancy. However, through motion adjustment as \nFig. 5. Screen shots of our prototype for collaborative visualization. \n994\nAuthorized licensed use limited to: IEEE Xplore. Downloaded on October 8, 2008 at 09:13 from IEEE Xplore.  Restrictions apply.\nLI ET AL.:  A TRAJECTORY-PRESERVING SYNCHRONIZATION METHOD FOR COLLABORATIVE VISUALIZATION \n \nwell as using the server as a reference, the new method not only \nfurther reduces the discrepancy but also shorten the duration of \ndiscrepancy, as observed in Figure 6(c).  \n6.2 Experiment 2 \nIn this experiment, we follow similar settings as in Experiment 1 but \nfocus more on the accuracy of the new method in handling object \ncollisions under different types of network connection as shown in \nTable 4. The experiment is conducted by 4 users, clients A to D. \nEach of the users is connected to the server with a different network \nconnection and takes turn to act as the controller, who throws the \nselected object out to initiate collisions, and the other three users \nwould be the observers, who monitor the motion of the selected \nobject. When throwing the object, the controller simply throws the \nobject up to the sky and let it fall down on to the floor. Then, the \nobject will bounce up and down a few times before it rests on the \nfloor. During the experiment, we record the position discrepancy of \nthe object between each of the users and the server. The results are \nshown in Figure 7, with each user taking turn to be the controller. \n \n \n0.000\n0.100\n0.200\n0.300\n0.400\nTime(sec) 1.00 2.00 3.00 4.00 \nPo\nsi\ntio\nn \ndi\nsc\nre\npa\nnc\ny \n(m\n)\nA: Controller (LAN)\nB: Observer (Intranet)\nC: Observer (Overseas 1)\nD: Observer (Overseas 2)\n(a)\n \n0.000\n0.100\n0.200\n0.300\n0.400\nTime(sec) 1.00 2.00 3.00 4.00 \nPo\nsi\ntio\nn \ndi\nsc\nre\npa\nnc\ny \n(m\n) A: Observer (LAN)\nB: Controller (Intranet)\nC: Observer (Overseas 1)\nD: Observer (Overseas 2)\n(b)\n \n0.000\n0.100\n0.200\n0.300\n0.400\nTim e(sec) 1.00 2.00 3.00 4.00 \nPo\nsi\ntio\nn \ndi\nsc\nre\npa\nnc\ny \n(m\n)\nA: Observer (LAN)\nB: Observer (Intranet)\nC: Controller (Overseas1)\nD: Observer (Overseas2)\n(c)\n \n0.000\n0.100\n0.200\n0.300\n0.400\nTim e (s e c) 1.00 2.00 3.00 4.00 \nPo\nsi\ntio\nn \ndi\nsc\nre\npa\nnc\ny \n(m\n)\nA : Obs e rve r  (LAN)\nB: Obs e rve r  (Intrane t)\nC: Obs e rve r  (Ove rs e as  1)\nD: Controlle r  (Ove rs e as  2)\n(d)\nFig. 7. Position discrepancies, during object collisions, of the four \nclients relative to the server when (a) client A, (b) client B, (c) client C, \nor (d) client D, is acting as the controller. \nSince the controller throws out the selected object at around 0.3s, \nwe can see from the four diagrams of Figure 7 that the position \ndiscrepancy between the controller and the server suddenly increases \nat 0.3s in all four diagrams. In Figure 7(a), as client A (the controller) \nhas a rather low network latency with the server, it can quickly \nsynchronize with the server and the discrepancy begins to drop until \naround 0.6s when the object reaches its highest point in the sky. \nOther observers will gradually synchronize with the server \ndepending on their network latencies with the server. Once the server \nhas received the message that the object has been thrown out from \nthe controller\u2019s hand, the simulation program running in the server \nwill take over the motion of the object. At 0.6s, the simulation \nprogram determines that the object should begin to fall down and \naccelerates as it falls due to gravity. Due to the error in the measured \nnetwork latency as well as the fluctuation (or jittering) of the latency, \nwhich is further magnified by the acceleration of the object, the \ndiscrepancies between the four clients and the server gradually \nincrease again until about 1.2s when the object hits the floor and \nrebounds. \nFigures 7(b), 7(c) and 7(d) exhibit similar behavior, except that \ntheir observers\u2019 discrepancies with the server start at a later time \nafter the controller has thrown the object out. This is due to the \nincrease in network latency between the controller and the server. \n7 CONCLUSION AND FUTURE WORK \nIn this paper, we have proposed a synchronization method to support \ncollaborative visualization. It considers how interaction with \ndynamic objects is perceived by application participants under the \nexistence of network latency, and remedies the motion trajectory of \nthe dynamic objects. It also handles the false positive and false \nnegative collision detection problems. The new method is \nparticularly well designed for handling content changes due to \nunpredictable user interventions or object collisions. Experimental \nresults show that our method could effectively provide a good \nconsistency control to support collaborative visualization.  \nDespite the merits of our proposed method, it does have some \nlimitations. For example, it assumes using connection-oriented \nnetwork protocols and message loss is not considered. We would like \nto address this as our future work. In addition, as haptic interfaces \nare becoming popular and it may widen the application of \ncollaborative visualization by providing user with force feedback, we \nwould also like to extend our work to handle haptic rendering as well. \nACKNOWLEDGEMENTS \nWe would like to thank the reviewers for their valuable comments \nand suggestions. The work described in this paper was partially \nsupported by two CERG grants from the Research Grants Council of \nHong Kong (Ref. Nos.: PolyU 5188\/04E and CityU 1133\/04E). \nREFERENCES \n[1] V. Anupam, C. Baja, D. Schikore, and M. Schikore, \u201cDistributed and \nCollaborative Visualization,\u201d IEEE Computer, 27(7):37-43, Jul. 1994. \n[2] P. Bernstein and N. Goodman, \u201cConcurrency Control in Distributed \nDatabase Systems,\u201d ACM Computing Surveys, 13(2):185-221, 1981. \n[3] Y. Bernier, \u201cLatency Compensating Methods in Client\/Server In-game \nProtocol Design and Optimization,\u201d Proc. of the Game Developers \nConference, 2001. \n[4] S. Butner and M. Ghodoussi, \u201cTransforming a Surgical Robot for \nHuman Telesurgery,\u201d IEEE Trans. on Robotics and Automation, \n19(5):818-824, Oct. 2003. \n[5] A. Chan, R. Lau, and B. Ng, \u201cNotion Prediction for Caching and \nPrefetching in Mouse-Driven DVE Navigation,\u201d ACM Trans. on \nInternet Technology, 5(1):70-91, Feb. 2005. \n[6] O. Deusen et al., \u201cThe Elements of Nature: Interactive and Realistic \nTechniques,\u201d ACM SIGGRAPH 2004 Course Note #31, Aug. 2004. \n[7] C. Diot and L. Gautier, \u201cA Distributed Architecture for Multiplayer \nInteractive Applications on the Internet,\u201d IEEE Networks Magazine, \n13(4):6-15, Jul.-Aug. 1999. \n[8] DIS Steering Committee, \u201cIEEE Standard for Distributed Interactive \nSimulation - Application Protocols,\u201d IEEE Standard 1278, 1998. \n[9] V. Jaswal, \u201cCAVEvis: Distributed Real-Time Visualization of Time-\nVarying Scalar and Vector Fields Using the Cave Virtual Reality \nTheater,\u201d Proc. of IEEE Visualization, pp.301-308, Oct. 1997. \n[10] G. Johnson and T. Elvins, \u201cIntroduction to Collaborative Visualization,\u201d \nProc. of ACM SIGGRAPH, pp. 8-11, May 1998. \n995\nAuthorized licensed use limited to: IEEE Xplore. Downloaded on October 8, 2008 at 09:13 from IEEE Xplore.  Restrictions apply.\nIEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 12, NO. 5, SEPTEMBER\/OCTOBER 2006 \n[11] H. Kopetz and W. Ochsenreiter, \u201cClock Synchronization in Distributed \nReal-Time Systems,\u201d IEEE Trans. on Computers, 36(8):933-940, Aug. \n1987. \n[12] L. Lamport, \u201cTime, Clocks, and the Ordering of Events in a Distributed \nSystem,\u201d Communications of the ACM, 21(7):558-565, 1978. \n[13] L. Lamport and P. Melliar-Smith, \u201cSynchronizing Clocks in the \nPresence of Faults,\u201d Journal of ACM, 32(1):52-78, Jan. 1985. \n[14] F. Li, L. Li, and R. Lau, \u201cSupporting Continuous Consistency in \nMultiplayer Online Games,\u201d Proc. of ACM Multimedia, pp. 388-391, \nOct. 2004. \n[15] C. Liao, M. Martonosi, and D. Clark, \u201cExperience with an Adaptive \nGlobally-Synchronizing Clock Algorithm,\u201d Proc. of ACM SPAA, \npp.106-114, Jun. 1999. \n[16] M. Macedonia, M. Zyda, D. Pratt, P. Barham, and S. Zeswitz, \n\u201cNPSNET: A Network Software Architecture For Large Scale Virtual \nEnvironments\u201d, Presence: Teleoperators and Virtual Environments, \n3(4):265-287, 1994. \n[17] G. Mark, A. Kobsa, and V. Gonzalez, \u201cDo Four Eyes See Better Than \nTwo? Collaborative Versus Individual Discovery in Data Visualization \nSystems,\u201d Proc. of IEEE Information Visualization, pp. 249-255, Jul. \n2002. \n[18] M. Mauve, J. Vogel, V. Hilt, and W. Effelsberg, \u201cLocal-lag and \nTimewarp: Providing Consistency for Replicated Continuous \nApplications,\u201d IEEE Trans. on Multimedia, 6(1):47-57, 2004. \n[19] D. Mills, \u201cInternet Time Synchronization: the Network Time Protocol,\u201d \nIEEE Trans. on Communications, 39(10):1482-1493, 1991. \n[20] J. Ohlenburg, \u201cImproving Collision Detection in Distributed Virtual \nEnvironments by Adaptive Collision Prediction Tracking,\u201d Proc. of \nIEEE VR, pp. 83-90, Mar. 2004. \n[21] A. Pang and C. Wittenbrink, \u201cCollaborative Visualization with Cspray,\u201d \nIEEE Computer Graphics and Applications, 17(2):32-41, Mar.-Apr. \n1997. \n[22] S. Pettifer, J. Cook, J. Marsh, and A. West, \u201cDEVA3: Architecture for a \nLarge-Scale Distributed Virtual Reality System,\u201d Proc. of ACM VRST, \npp. 33-40, Oct. 2000. \n[23] T. Srikanth and S. Toueg, \u201cOptimal Clock Synchronization,\u201d Journal of \nACM, 34(3):626-645, Jul. 1987. \n[24] I. Vaghi, C. Greenhalgh, and S. Benford, \u201cCoping with Inconsistency \ndue to Network Delays in Collaborative Virtual Environments,\u201d Proc. \nof ACM VRST, pp.42-49, Dec. 1999. \n[25] J. Wijk, \u201cFlow Visualization with Surface Particles,\u201d IEEE Computer \nGraphics and Applications, 13(4):18-24, Jul. 1993. \n[26] J. Wood, H. Wright and K. Brodlie, \u201cCollaborative Visualization,\u201d Proc. \nof IEEE Visualization, pp. 253-259, Oct. 1997. \n[27] M. Gerald-Yamasaki, \u201cCooperative Visualization of Computational \nFluid Dynamics,\u201d Proc. of Eurographics, pp.497-508, Sept. 1993. \n996\nAuthorized licensed use limited to: IEEE Xplore. Downloaded on October 8, 2008 at 09:13 from IEEE Xplore.  Restrictions apply.\n"}
{"doi":"10.1145\/958432.958472","coreId":"70401","oai":"oai:eprints.lancs.ac.uk:12231","identifiers":["oai:eprints.lancs.ac.uk:12231","10.1145\/958432.958472"],"title":"Using an Autonomous Cube for Basic Navigation and Input","authors":["Van Laerhoven, Kristof","Villar, Nicolas","Kortuem, Gerd","Gellersen, Hans","Schmidt, Albrecht"],"enrichments":{"references":[{"id":16301026,"title":"ADXRS150 gyroscope: \u00b1150\u00b0\/s Single Chip Yaw Rate Gyro with Signal Conditioning Data Sheet (Rev.","authors":[],"date":null,"doi":null,"raw":"ADXRS150 gyroscope: \u00b1150\u00b0\/s Single Chip Yaw Rate Gyro with Signal Conditioning Data Sheet (Rev. A, 1\/03)","cites":null},{"id":16301030,"title":"An Inertial Measurement Framework for Gesture Recognition and Applications.","authors":[],"date":"2001","doi":"10.1007\/3-540-47873-6_2","raw":"Benbasat, A.Y. and Paradiso, J. A. An Inertial Measurement Framework for Gesture Recognition and Applications. In Ipke Wachsmuth, Timo Sowa (Eds.), Gesture and Sign Language in Human-Computer Interaction, International Gesture Workshop, GW 2001, London, UK, 2001 Proceedings, Springer-Verlag Berlin, 2002.","cites":null},{"id":16301053,"title":"Cognitive Cubes: A Tangible User Interface for Cognitive Assessment,","authors":[],"date":"2002","doi":"10.1145\/503376.503438","raw":"Sharlin, E., Itoh, Y., Watson, B., Kitamura, Y., Liu, L., Sutphen, S. Cognitive Cubes: A Tangible User Interface for Cognitive Assessment, ACM CHI 2002 Conference Proceedings, pp. 347-354, April 20-25, 2002, Minneapolis, Minnesota","cites":null},{"id":16301031,"title":"Exploring brick-based camera control.","authors":[],"date":"1999","doi":"10.1007\/3-540-48157-5_11","raw":"Fjeld, M., Voorhorst, F., Bichsel, M., & Krueger, H. Exploring brick-based camera control. In H.-J. Bullinger & J. Ziegler (eds): Proceedings of HCI International\u201999, (the 8 th International Conference on Human-Computer Interaction), pp. 1060-1064. 1999.","cites":null},{"id":16301041,"title":"iMAR Triaxial iTGAC-FK Sensor Cube with Fiber Optical Gyros and Accelerometers.","authors":[],"date":null,"doi":null,"raw":"iMAR Triaxial iTGAC-FK Sensor Cube with Fiber Optical Gyros and Accelerometers. http:\/\/www.imarnavigation.de\/englishside\/dat_engl\/tgac_fk.pdf","cites":null},{"id":16301038,"title":"Independent Component Analysis (ICA).","authors":[],"date":"2001","doi":"10.1002\/0471221317","raw":"Hyv\u00e4rinen, A., Karhunen, J., Oja, E. Independent Component Analysis (ICA). John Wiley & Sons, 2001.","cites":null},{"id":16301044,"title":"Machine Learning. McGraw-Hill c,","authors":[],"date":"1997","doi":"10.1002\/(sici)1099-1689(199909)9:3<191::aid-stvr184>3.0.co;2-e","raw":"Mitchell, T. Machine Learning. McGraw-Hill c, 1997.","cites":null},{"id":16301028,"title":"Rock \u2019n\u2019 scroll is here to stay.","authors":[],"date":"2000","doi":"10.1109\/38.844371","raw":"Bartlett, J.F. Rock \u2019n\u2019 scroll is here to stay. IEEE Computer Graphics and Applications, Vol. 20-3, May\/June 2000. pp. 40\u201345.","cites":null},{"id":16301055,"title":"The Cube. World of Mathematics. Online web resource.","authors":[],"date":null,"doi":null,"raw":"Weisstein, E. The Cube. World of Mathematics. Online web resource. http:\/\/mathworld.wolfram.com\/Cube.html","cites":null},{"id":16301033,"title":"The Cubic Mouse: A New Device for Three-Dimensional Input.","authors":[],"date":"2000","doi":"10.1145\/332040.332491","raw":"Froehlich, B. and Plate, J. The Cubic Mouse: A New Device for Three-Dimensional Input. Proceedings of CHI 2000, pp. 526-531. 2000.","cites":null},{"id":16301106,"title":"The Hexahedron (Cube). In Polyhedron Models.","authors":[],"date":"1989","doi":null,"raw":"Wenninger, M.J. The Hexahedron (Cube). In Polyhedron Models. Cambridge, England: Cambridge University Press, p.16, 1989.","cites":null},{"id":16301049,"title":"ToolStone: Effective use of the physical manipulation vocabularies of input devices.","authors":[],"date":"2000","doi":"10.1145\/354401.354421","raw":"Rekimoto, J. and Sciammarella, E. ToolStone: Effective use of the physical manipulation vocabularies of input devices. In Proc. of UIST 2000, 2000.","cites":null},{"id":16301035,"title":"Triangles: Design of a Physical\/Digital Construction Kit.","authors":[],"date":null,"doi":"10.1145\/263552.263592","raw":"Gorbet, M., Orth, M. and Ishii, H. Triangles: Design of a Physical\/Digital Construction Kit. Proceedings of Designing Interactive Systems: Processes, Practices, Methods, and Techniques (ACM DIS '97), Amsterdam, ACM, pp. 125-128.","cites":null},{"id":16301047,"title":"Unit\u2014A Modular Framework for Interaction Technique Design, Development and Implementation. Master\u2019s project at the KTH,","authors":[],"date":"2002","doi":null,"raw":"Olwal., A. Unit\u2014A Modular Framework for Interaction Technique Design, Development and Implementation. Master\u2019s project at the KTH, Stockholm, Sweden, executed in the Department of Computer Science at Columbia University, New York, USA. 2002.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2003-01","abstract":"This paper presents a low-cost and practical approach to achieve basic input using a tactile cube-shaped object, augmented with a set of sensors, processor, batteries and wireless communication. The algorithm we propose combines a finite state machine model incorporating prior knowledge about the symmetrical structure of the cube, with maximum likelihood estimation using multivariate Gaussians. The claim that the presented solution is cheap, fast and requires few resources, is demonstrated by implementation in a small-sized, microcontroller-driven hardware configuration with inexpensive sensors. We conclude with a few prototyped applications that aim at characterizing how the familiar and elementary shape of the cube allows it to be used as an interaction device","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/70401.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/12231\/1\/icmipui_2003.pdf","pdfHashValue":"1f07803eb1180c1bd8c3a07ed12a8edfc2e733e1","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:12231<\/identifier><datestamp>\n      2018-01-24T02:09:46Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Using an Autonomous Cube for Basic Navigation and Input<\/dc:title><dc:creator>\n        Van Laerhoven, Kristof<\/dc:creator><dc:creator>\n        Villar, Nicolas<\/dc:creator><dc:creator>\n        Kortuem, Gerd<\/dc:creator><dc:creator>\n        Gellersen, Hans<\/dc:creator><dc:creator>\n        Schmidt, Albrecht<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        This paper presents a low-cost and practical approach to achieve basic input using a tactile cube-shaped object, augmented with a set of sensors, processor, batteries and wireless communication. The algorithm we propose combines a finite state machine model incorporating prior knowledge about the symmetrical structure of the cube, with maximum likelihood estimation using multivariate Gaussians. The claim that the presented solution is cheap, fast and requires few resources, is demonstrated by implementation in a small-sized, microcontroller-driven hardware configuration with inexpensive sensors. We conclude with a few prototyped applications that aim at characterizing how the familiar and elementary shape of the cube allows it to be used as an interaction device.<\/dc:description><dc:date>\n        2003-01<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/12231\/1\/icmipui_2003.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1145\/958432.958472<\/dc:relation><dc:identifier>\n        Van Laerhoven, Kristof and Villar, Nicolas and Kortuem, Gerd and Gellersen, Hans and Schmidt, Albrecht (2003) Using an Autonomous Cube for Basic Navigation and Input. In: 5th international conference on Multimodal interfaces. , pp. 203-211.<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/12231\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1145\/958432.958472","http:\/\/eprints.lancs.ac.uk\/12231\/"],"year":2003,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"Using an Autonomous Cube for Basic Navigation and Input \nKristof Van Laerhoven, Nicolas Villar, Albrecht Schmidt, Gerd Kortuem, and Hans Gellersen \nDepartment of Computing \nLancaster University \nLA1 4YR Lancaster \n{kristof, villar, albrecht, kortuem, hwg}@comp.lancs.ac.uk \n \n \nABSTRACT \nThis paper presents a low-cost and practical approach to achieve \nbasic input using a tactile cube-shaped object, augmented with a \nset of sensors, processor, batteries and wireless communication. \nThe algorithm we propose combines a finite state machine model \nincorporating prior knowledge about the symmetrical structure of \nthe cube, with maximum likelihood estimation using multivariate \nGaussians. The claim that the presented solution is cheap, fast and \nrequires few resources, is demonstrated by implementation in a \nsmall-sized, microcontroller-driven hardware configuration with \ninexpensive sensors. We conclude with a few prototyped \napplications that aim at characterizing how the familiar and \nelementary shape of the cube allows it to be used as an interaction \ndevice.  \nCategories and Subject Descriptors \nH.5.2 [Information Interfaces and Presentation]: User \nInterfaces \u2013 Haptic I\/O, Input devices and strategies.  \nGeneral Terms \nAlgorithms, Reliability, Human Factors, Verification. \nKeywords \nSensor-based tactile interfaces, haptic interfaces, Markov chain, \nMaximum Likelihood estimation, Gaussian modeling. \n1. INTRODUCTION \nOne of the goals that researchers in ubiquitous computing strive \ntowards is the integration of computing technology into objects \nthat are different from traditional functional appliances: the \nobjects need to mix more fluently in everyday environments, and \ninteraction should be intuitive. Making these objects look, feel, \nand behave familiarly for the sake of the user often results in very \ntight constraints for the designers of its hardware and software. \nThe affordance and familiarity of an object are major factors for \ninteraction with it. Apart from its shape and feel, size is important \nas well: The additional electronic components should be \ncontained within the augmented object, without enlarging it. \nOther crucial constraints are battery power, as batteries need to be \nreplaced or recharged periodically, and robustness and reliability, \nsince people might treat these objects forcefully. \nThe focus of this paper is not so much on \u2018digitizing\u2019 an existing \nobject; it concentrates more on the creation of a novel object \nhaving the shape and form factor of an elementary three-\ndimensional structure: a cube or die. Certain properties, like its \nsymmetry and well-known shape, make it relatively easy to \nmodel, both in software and in the mind of the user. Using sensors \nthat track a notion of its state, this cube can be used as a basic \ninput device for selection and navigation, while blending in with \nthe environment and remaining easy to physically and mentally \ngrasp. Further assumptions are the cube\u2019s physically separation \nfrom any appliance (a cable might encumber interaction), and that \nit broadcasts its state as a service to the environment, rather than \none specific appliance.  \n \nFigure 1. Picture of our transparent version of the cube, with \nall of its electronic components fixed inside. \nWe present an augmented cube the size of a large die, which \nwirelessly transmits which of its sides is up, its orientation, and \nwhether it went through a predefined gesture. This paper will \nconcentrate on key choices in the design of the algorithms, since \nthey allow the cube to have low cost, small form factor, and fast \nresponse time:  \n\u2022 The cube\u2019s orientation is inferred, using the data from \naccelerometers only, rather than utilizing (bigger) \ngyroscopes or similar sensors.  \n\u2022 The software runs on a standard PIC microcontroller that \nhas limited memory. It is well suited for embedded devices.  \n \nPermission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are \nnot made or distributed for profit or commercial advantage and that \ncopies bear this notice and the full citation on the first page. To copy \notherwise, or republish, to post on servers or to redistribute to lists, \nrequires prior specific permission and\/or a fee. \nICMI\u201903, November 5\u20137, 2003, Vancouver, British Columbia, Canada. \nCopyright 2003 ACM 1-58113-621-8\/03\/0011\u2026$5.00. \n \nThe cube is intended to be used by applications in its \nsurroundings. The applications pick up its transmissions and \ntranslate them into actions for selection and navigation tasks.  \n2. HARDWARE \nDuring the prototyping phase, the choice of hardware is \nimportant, since it has direct consequences for the remainder of \nthe system design. The cube as an object has to remain small and \nrobust enough for the users to handle it, and its \u201cdigital self\u201d \nneeds to be accurate and autonomous so it can work properly for \nlong periods without requiring cabling for power and \ncommunication. \n2.1 Basic Processing: PIC Microcontroller  \nThe heart of the hardware is a Microchip PIC microprocessor \n(PIC18F252), which is small, fast (10 Mips), consumes little \nenergy (25 \u00b5A \/ 0.2 \u00b5A standby), and is easy to interface to the \nsensors and communication module. The downside is that the \nentire software for processing the sensor data and broadcasting it \nvia a wireless protocol has to fit in a tiny program memory \n(32Kbyte) and only has access to a small amount of data memory \n(1536 bytes).  \n \nFigure 2. The two stacked hardware boards with the major \ncomponents annotated. A battery (coin-sized or 2 AAA) and \nsecond accelerometer are not visible from this angle. \n2.2 Sensors \nThe microcontroller we used has fourteen inputs for binary \nsensors and a built-in analog-to-digital conversion unit that allows \nfive analog sensors to be attached. Our objective, however, to \nkeep the hardware as simple and low-cost as possible without \ngiving in too much on performance, means that we kept the \nnumber of sensors low: \n\u2022 Two dual-axis accelerometers (ADXL311) measure both \ndynamic acceleration (e.g., vibration) and static acceleration \n(e.g., gravity) in a plane. The sensors\u2019 ability to measure \ngravity gives us the opportunity to discriminate in contexts \nwhere acceleration may be zero (such as different positions of \nthe cube). We used two accelerometers to get acceleration in \nthree dimensions (X-Y and X-Z). \n\u2022 One capacitive sensor (QT110) measures proximity of the \nuser\u2019s hand (i.e., whether the user is holding the cube or not), \nmainly to wake up the microcontroller from standby. \nBoth types of sensors are particularly cheap in power \nconsumption (400\u00b5A \/ 20\u00b5A), and price (5 USD \/ 1.6 USD1) per \naccelerometer and proximity sensor respectively, due to their \nmanufacturing process and presence in a large number of \napplications.  \nOther sensors that would track the cube\u2019s movements are \nsignificantly larger and more expensive. Gyroscopes, for instance, \nare being used in similar hardware to get an additional three \ndegrees of freedom (by explicitly sensing rotation around the \nthree axes). They are known to drift, however, and it is common \nfor them to also include a temperature sensor and voltage \nreference to condition the signal. The manufacturing process is \nmore complicated, and therefore drives up the package size and \nprice (typically around 40 USD1 [2]); gyroscopes also require a \nsignificant amount of current (typically 6 mA [2]). In this paper, \nthe sensing is limited to inexpensive and small inertial \nacceleration sensing, with an additional algorithm included on the \nmicrocontroller to compensate for the lack of explicit rotation \nsensors.   \n2.3 Communications \nThe communications module is a Radiometrix BIM2 chip that \ntransmits and receives data wirelessly (via FM) over an \napproximate range up to fifty meters indoors. Its relatively low \npower consumption for an RF module (~8 mA) and considerable \ndata rate (64 kbps) make it an ideal interface between the cube \nand surrounding applications. Unlike many tracking appliances, \nthe cube will only output information about itself to its \nenvironment when its state has changed or when a certain gesture \nis performed, thus preserving the batteries as much as possible. \nWireless transmission is by far the most power-hungry component \nof the cube. \n2.4 Characteristics \nThe prototype hardware used in this paper consists of two boards \n(as shown in Figure 2) that stack on top of each other: One board \nmakes up the core section, containing the microcontroller, \ncommunications module, and a coin-size Lithium cell on the \nbottom. The second board has the acceleration and proximity \nsensors, plus a few empty slots for future sensors, should they be \nrequired. The total setup for one cube, including the printed \ncircuit board and all components, costs about 50 USD.  \nThe entire system runs on a three volt Lithium coin-cell battery, \nor two AAA batteries which give a lifetime of approximately four \nmonths with the current embedded software and normal usage \n(\u201cnormal\u201d usage defined by the first application in section 7).  \n3. MODEL OVERVIEW \nOur objective is to give the cube a digital representation, so that it \ncan offer its state as a service to applications in its environment. \nWhat states it can and should detect, and what behaviors can be \ndetected, are vital considerations for obtaining a model for the \ncube.  \nThe system that we implemented has three modules: the first \nestimates which is the top side of the cube, the second uses this \n                                                                \n1 Prices per unit for 100+ purchased, on 28\/04\/2003. \nQT110 proximity \nPIC Microcontroller BIM2 RF transceiver ADXL311 accelerometer\nTime (\u00b110 milliseconds) \nSe\nns\nor\nva\nlu\nes\n \ninformation with prior states to estimate the direction to which all \nother sides are pointing, and finally the third model overrules the \nothers if it is confident enough that a gesture was performed. \nFigure 3 gives an overview of the system with some examples. \n \nFigure 3. The three modules that produce the cube\u2019s output, \nabstracting from the raw acceleration data. \n3.1 Which Side Is Up? \nA first approximation of a model estimates which side of the cube \nis \u2018on top\u2019, which we will define as relative to the user but \nassume to be similar to pointing upwards if the cube would be \nlying on the ground. Note that this is just a rough approximation \nof the cube\u2019s state, especially as it doesn\u2019t include rotation in the \nX-Y plane parallel to the top side; we know the orientation of the \ntop and bottom sides, due to the symmetry of the cube, but not the \norientation of the four other sides. However, this basic model \nalone is already useable for making simple selections, similar to \nmaking a (random) selection by rolling a die.  \nAccelerometers that operate in three perpendicular dimensions are \na well-known tool to estimate the position of an object, relative to \nthe earth\u2019s gravitational field. We will model the top side by \nanalyzing the accelerometers\u2019 sensor data for each possible side, \nand using these six models for estimation of the side that is most \nlikely \u2018on top\u2019.  \n3.2 Orientation Of All Sides Relative To User \nInstead of just expressing the top and bottom sides, a more \nappropriate model would be to represent where each side is \npointing to, relative to the user. These orientations do not need to \nbe precise measurements in degrees: a more useful set would be \nthe already existing \u2018on top\u2019\/\u2019Up\u2019 and \u2018on bottom\u2019\/\u2019Down\u2019, \naccompanied by the other directions (defined as \u2018North\u2019, \u2018South\u2019, \n\u2018West\u2019, and \u2018East\u2019) again relative to the user. Rather than \nthrowing away the previous model and adding some sensors that \nsense orientation in all three dimensions, we use the previous \nmodel to estimate the orientation of all sides. This method will \nrequire an a priori known starting orientation, or at least the \norientation of two perpendicular sides.  \n3.3 Gestures  \nA third addition to the cube\u2019s model, still using the minimal set of \nsensors from the hardware discussed in section 2, is a distinct set \nof gestures that the user can perform with the cube in hand. The \nmodule that will recognize the gestures runs parallel to the other \nmodules, overriding it whenever the most likely gesture is \nrecognized with a sufficient probability. As the given sensor\u2019s \ncapabilities are limited, gestures will typically involve signals \nwith a high variance and a distinct pattern.  \n4. FINDING THE TOP SIDE \nThe three-dimensional arrangement of the accelerometers allows \na very easy and robust way to work out which side of the cube is \non top. We can assume that there is no drift in the sensor signals, \nand only a small amount of noise. Furthermore, as there are four \nsignals available (two per accelerometer), all four will be used to \ndistinguish the six possible sides facing upwards. Arguably, the \nfourth (redundant) acceleration signal will only give a small \ninformation gain, but is included nonetheless as it will not \nperceptibly affect the real-time performance of the software on \nthe microcontroller. \n4.1 Multivariate Gaussian Modeling of Sides  \nDue to the properties of the acceleration sensors, one can expect \nthat the combined signals they produce will indeed vary for each \norientation of the cube. An obvious method to model the data \nfrom each side being the one on top is to represent it as a four-\ndimensional Gaussian:  \n)(1)(\n2\n1\n2)2(\n1)( i\nxi\nT\nix\ni\ni exG\n\u00b5\u00b5\n\u03c0\n\u2212\u2212\u03a3\u2212\u2212\n\u03a3=\n \nwhere i ranges from 1 to 6 to identify the sides of the cube, x \nspecifies a four-dimensional vector with the sensor readings, and \nthe two parameters \u00b5 and \u03a3  indicate the mean (average) vector \nand covariance matrix, respectively. \nThe Gaussian for each side being the one on top can thus be \ncharacterized by obtaining the averages and the covariances from \nsample data. This can be done by recording a dataset for each side \nfacing upwards, and storing the averages and covariances from \nthese datasets as pre-calculated values in the hardware. It is \nhowever also possible, and feasible, to code the calculation of the \naverages and covariances into a routine that can reassess or re-\ncalibrate these parameters at run-time. Sample data from the cube \nbeing placed on all six sides successively is plotted as a time \nseries in Figure 4.  \nFigure 4. Samples from the cube\u2019s sensors, while placed on all \nsix sides successively (labeled in the plot). \nTo visualize the Gaussian models, a dimensionality reduction \nalgorithm (FastICA [14], based on Independent Component \nAnalysis [3]) was utilized to map the four-dimensional data space \nA\ncc\nel\ner\nat\nio\nn \nse\nns\nor\ns \nWhich side is  \n\u2018on top\u2019? \n \nWhat is direction \nof all sides? \nHas a gesture been performed? \nO\nut\npu\nt \n1 2  3 4 \n5 6 \n(which is hard to visualize) into a two-dimensional space. Figure \n5 shows the six two-dimensional Gaussians (notice how they are \nevenly distributed over the input space) with a sample trace of a \ncube being rotated around, cycling through all six states. \n \nFigure 5. Mapping to a two-dimensional space to visualize the \nGaussians for all six sides. The line trace is a trace plot of the \nreadings while the cube was turned around from side to side.  \n4.2 Maximum Likelihood Estimation  \nThe Gaussians will be used for each sample reported by the \nacceleration sensors to establish which side these readings belong \nto. Using the formula in the previous section, the side i for which \nthe Gaussian Gi(x) has the highest value for the current sensor \nreadings x, will be the most likely side that is on top of the cube.  \nTo fit this into a Maximum Likelihood (ML, see [11] for a brief \nintroduction) estimation procedure, we start with Bayes\u2019 rule: \n)(\n)()(\n)(\nxP\niTPiTxP\nxiTP\n====  \nwhere P( T=i | x ) is the posterior probability that the side i is on \ntop, given the sensor data x, and P( x | T=i ) is the prior \nprobability that sensor data x enters the system, while it is given \nthat side i is on top. The two other values, P(T=i) and P(x), \nsignify the probability that the cube has i as a top side and the \nprobability that the sensors read the vector x, respectively.  \nSince only the side i that is the top side is of interest, we search \nfor the maximum argument instead of just the probabilities: \n\uf8f7\uf8f7\uf8f8\n\uf8f6\n\uf8ec\uf8ec\uf8ed\n\uf8eb ==\n)(\n)()(\nmaxarg\nxP\niTPiTxP\ni\n= ( ))(maxarg xG\ni\ni  \nby replacing the prior probabilities with the Gaussians, and \nassuming that all sides of the cube are equally likely to be on top, \nP(T=i) = 1\/6.  \nThis can be simplified by including the natural log function to \neliminate the exponential function in the Gaussian: \n\uf8f7\uf8f8\n\uf8f6\uf8ec\uf8ed\n\uf8eb \u03a3\u2212\u2212\u2212\u03a3\u2212\u2212 \u2212 iiiTi xx\ni\nln\n2\n1)2ln(\n2\n1)()(\n2\n1maxarg 1 \u03c0\u00b5\u00b5\n \nFinally, eliminating the constants and reversing the sign produces \nan easier formula that gives the most likely top side of the cube: \n( )iiiTi xx\ni\n\u03a3+\u2212\u03a3\u2212 \u2212 ln)()(minarg 1 \u00b5\u00b5  \nBy filling in the four acceleration values x=(x1, x2, x3, x4) into this \nformula, and having computed the \u00b5i , ln|\u03a3|, and \u03a3-1 beforehand, \none gets the side i that is most likely the top side. This calculation \nfits easily into the microcontroller\u2019s program memory and does \nnot need an excessive amount of stored data: In the C source code \nfor the microcontroller, the computation per input, per side, \nrequires 20 multiplications, 4 subtractions, and 16 additions. The \namount of time that this takes is negligible, compared to the other \ncode segments for reading the sensor values and establishing \ncommunication. \n4.3 Re-estimating Parameters at Run-time \nNot only does the estimation procedure fit easily on a \nmicrocontroller, the generation of the covariance matrices and \nmeans was implemented on the microcontroller as well. This \ncould be used for re-calibration (although the sensors do not drift \nas such, sides may need to be re-mapped or the hardware might be \nrepositioned within the cube), or during an initial \u2018training phase\u2019. \nThe one restriction that affects the accuracy is the size of the \ndatasets per side, due to the limited amount of available memory.  \n5. MODELING THE CUBE \n5.1 Symmetrical Properties Of The Cube  \nThe cube is known in mathematics as a hexahedron, from the \ngroup of polyhedrons, or more precisely isohedrons, consisting of \nsix square sides, 8 vertices, 12 edges, and having numerous \ninteresting properties (see [15] and [16] for an introduction).  \nIn the case of a die, the cube has opposite faces, which are labeled \nby number to always sum to seven. This gives two possible mirror \nimage arrangements in which the numbers 1, 2, and 3 may be \narranged in a clockwise or counterclockwise order about a corner. \nThe illustration in Figure 6a shows the six sides, numbered with \ndie-like counterclockwise arrangements, when viewed from along \nthe three-fold rotation axis towards the center of the die.  \n \nFigure 6. a) The arrangement of the cube in this paper follows \nthat of a counterclockwise die. b) A 90 degree rotation along \nany axis through the center points of opposite faces leaves the \ncube invariant. \nThe most important symmetry of the die for this paper is that it \nremains invariant when applying certain sequences of rotational \ntransformations of 90 degrees along the axis through the centers \na) \n2 5 3 4 \n1 \n6 \nb) \nof opposing faces. Figure 6b shows these three axes. We will \nconsider for the remainder of this paper that the cube has, like the \ndie in Figure 6a, numbered faces, but do not assume that they are \nvisibly marked on the object. \n5.2 Defining A Basic Set Of States  \nA certain state of a cube will be defined as an arrangement of \nsides according to the following directions from the view of the \nperson holding it (see Figure 7a for an illustration):  \n\u2022 Top \/ Up: the side that faces upward \n\u2022 Bottom \/ Down: the side that faces downward \n\u2022 West: the side that faces to the left   \n\u2022 East: the side that faces to the right \n\u2022 North: the side that faces away from the user \n\u2022 South: the side that faces toward the user \n \nWith these definitions in place, two important remarks can be \nmade about the notation of a state: First, in general, for a person \nholding the cube without knowing or observing any labels of the \nsides, there are twenty-four possible states. Second, by exploiting \nthe cube\u2019s structural properties and labeling each face of the cube \nas mentioned in the previous section, a given cube\u2019s state can be \ndescribed by knowing only the direction of two adjacent faces.  \nIt is therefore sufficient to take two fixed directions (Top and \nSouth, for instance), rather than describing a state by all six \ndirections. \n \nFigure 7. a) A diagram of the six parameters for defining the \ncube\u2019s state from the user\u2019s view. b) The defined set of four \npossible transitions. The labels for the sides in both views are \nrelative to the user\u2019s perspective. \n5.3 Modeling The Transitions \nUsing the states defined in the previous section, one can define \nsix possible 90 degree rotations between those states (two per \naxis, for positive or negative rotation). For reasons that will be \nspecified later in this section, this set of possible transitions will \nbe limited in our model to four of those (See Figure 7b): \n\u2022 Forward: rotating the cube so that the Top side becomes the \nNorth side \n\u2022 Back: rotating the cube so that the Top side becomes the \nSouth side \n\u2022 Left: rotating the cube so that the Top side becomes the West \nside \n\u2022 Right: rotating the cube so that the Top side becomes the East \nside \nGiven this set of transitions, and denoting a state by X,Y where X \nis the top side and Y is the south side, a finite state machine can be \nbuilt (See state transition diagram in Figure 8). Notice that all 24 \npossible states can be reached with the four transitions defined \nabove. \n \nFigure 8. All possible state transitions in two interlinked \ngraphs: Links between a state (rectangles) to the left, right, \nup, and down another state indicate a transition after rotating \nthe cube to the left, right, forward, and backward \nrespectively. A cube\u2019s state X,Y is characterized by the Top \nside X, and the South side Y. The smaller states specify links \nbetween the two graphs. Open links should be linked to the \nstate on the other side of the graph: a left transition from 3,1 \n(in the upper-left of the second graph) links to 2,1 for example \n(upper-right of the same graph).  \n \nThe reason for restricting the set of transitions to the four \nmentioned above becomes clear when investigating the state \ntransition diagram in Figure 8 in detail: One can take any state in \nthe graph as an example, and examine all the possible transitions \n(up, down, left and right). All first components of the states are \ndifferent, regardless which one was taken. Knowing the starting \nstate and the first component of the destination state therefore \nidentifies the transition, with the first component being the top \nside. the conclusion is consequently:  \nFor any given state, both the previous transition and the current \nstate can be inferred by just knowing the previous state and the \ncurrent Top side.  \n5,3 \n3,2 \n4,5 \n2,4 \n1,3 \n1,4 \n2,3 \n3,5 \n4,2 \n5,4 \n6,3 \n6,4 \n4,1 \n6,5 6,2 \n3,1 \n6,2 6,5 \n3,6 \n3,6 \n1,5 \n3,1 \n4,6 \n1,2 \n4,6 4,1 \n1,5 \n1,2 \n5,6 \n6,2 \n1,5 \n2,1 \n3,6 \n3,1 \n2,6 \n6,5 \n1,2 \n5,1 \n4,6 \n4,1 \n1,3 \n4,5 4,2 \n6,3 \n4,2 4,5 \n6,4 \n6,4 \n3,5 \n6,3 \n1,4 \n3,2 \n1,4 1,3 \n3,5 \n3,2 \na) b) \nIf the previous top side was for example side 5, and the previous \nSouth side was 4, with the current Top side being side 1, then the \ngraphs in Figure 8 can be used as a lookup table where only one \noccurrence can be found: state 5,4 linked to state 1,4 via the Left \ntransition.  \n5.4  Summary \nThis section modeled the cube with a finite state machine, with \nstates being a description of the orientation of all sides and with \nrotations as the transitions between the states. Limiting the \ntransitions to left, right, forward and back rotations, gives not only \na lighter model, in which all twenty-four possible states can still \nbe reached, but also requires the knowledge of just the previous \nstate and the current top side.  \nThe consequences are significant: by knowing the starting state, \nthe model can keep track of its states by just estimating the top \nside of the cube. The algorithm in section 4 does just that, so by \ncombining it with the finite state machine from this section, the \nstate of the cube and the last transition can be tracked at any given \npoint in time. This finally means that the cube can be used for \nbasic navigation, using the four transitions Left, Right, Forward, \nand Back. \n6. GESTURES \nThe model that was characterized in the previous two sections \nallows basic interaction by changing the state of the cube. The \nsame sensors that measure its orientation, however, can also \nmeasure dynamic acceleration. A basic set of gestures (shaking \nthe cube, twisting it, and knocking on it) that give distinct signal \npatterns is used as additional means of input. Figure 9 shows \nexample timeseries plots for these discrete events. \nAn important requirement for the gestures is that they must be \nindependent of the orientation of the cube itself, i.e. the gestures \nmust be recognized regardless of the cube\u2019s states. The other \nrestrictions that applied in previous sections due to the \nmicrocontroller-based platform, such as limited memory, power, \nand processing resources, are valid for the gesture recognition \nalgorithms as well.  \nIdeally, the gestures should be straightforward and familiar \nenough to a person that is handed the cube for the first time and \nasked to perform gestures like shaking, twisting or knocking on \nthe cube.  \nThe patterns of these three gestures have certain characteristics \nthat are distinguishable enough from one another, and from a non-\ngesture (i.e. normal use of the cube without performing an actual \ngesture). The examples in Figure 9 show a high variation across \nthe signals whenever a gesture is carried out, which validates the \nuse of variance or standard deviation as a feature. A main \ndifference between the shaking gesture and the twisting gesture is \nthe number of sensors that give a strong variation, as shaking \ntends to be more unidirectional. The variance over a short time \nspan is also key to distinguishing the knocking on the cube.  \nBy calculating the variances for all sensor channels over a sliding \nwindow of 50 samples, and averaging them to get an orientation-\nindependent value, a sufficient feature is generated to make the \ndistinction. As the averaged variance is the sole influential \ndescriptive feature that distinguishes the three gestures, a simple \nEuclidean minimum-distance classifier determines which gesture \nis the most likely one. Again, this algorithm is small and fast \nenough to operate within the microcontroller\u2019s limited resources. \n0 10 20 30 40 50 60 70 80 90 100\n100\n200\n300\n400\n500\n600\n700\nTime (+\/- 10ms)\nS\nen\nso\nrv\nal\nue\ns\n \n0 10 20 30 40 50 60 70\n350\n400\n450\n500\n550\n600\n650\nTime (+\/-10ms)\nS\nen\nso\nrv\nal\nue\ns\n \n10 20 30 40 50 60 70 80 90 100\n200\n300\n400\n500\n600\n700\n800\n900\nTime (+\/- 10ms)\nS\nen\nso\nrv\nal\nue\ns\n \nFigure 9. Time series plots (from top to bottom) for the \ngestures \u201cshaking\u201d, \u201ctwisting\u201d, and \u201cknocking\u201d. The \nhorizontal axes mark the time, the vertical axes show the \nsensor signals for the four accelerometers.  \nOne of the short-term future work goals in this research is to \nimplement a re-training procedure similar to the one for finding \nthe top side. This would complete the cube\u2019s autonomy, and make \nit fully re-configurable at run-time.  \n7. APPLICATION EXAMPLES \nThe cube system discussed so far, broadcasts a message over a \nwireless link whenever it detects that it is being manipulated. This \ncan be triggered by either placing the cube on a different side \n(changing its state), or performing one of the cube\u2019s predefined \ngestures. \nThe cube\u2019s output, when picked up by a receiver, has the \nfollowing format: \n\u201c[C<top side> <south side> <last action> <gesture> ]\u201d \nwith each of the variables (in italics) represented by a number, \nfollowed by a value that indicates confidence in the prediction \n(mainly for debugging purposes). Two implementations are \ndiscussed in this section to illustrate how this information could \nbe utilized by an application for which the cube can be used as an \ninput device. \n7.1 Controlling Audio Mixer Profiles \nThe Innovative Interactions Lab at Lancaster University is a \n\u2018living lab\u2019 meeting area which is fitted with several large-screen \ndisplays, sensors, and a high-end 8-channel audio system. The \naudio system is controlled through a mixer that is hooked up to a \nnumber of devices, such as a TV, a net-meeting environment, \nMiniDisc player, CD player and several input sockets positioned \naround the lab space.  \nUtilizing the audio system for any of these appliances means \ngoing to the mixing panel, switching the appropriate channels and \nsetting the sliders to the required volume on the mixer. In \npractice, this requires expertise with not only the mixer settings, \nbut also the entire audio system.  \nBy using the cube as a simple, tangible interface, anybody in the \nlab can set the audio system to one of the six most popular \nsettings by placing the cube so that the side that relates to the \ndesired appliance faces upwards. The cube\u2019s output is sent to a \nbase station that converts the packets to a MIDI stream that \ncontrols the mixing panel (see Figure 10 for a picture of the lab \nsetup), as well as two large plasma screens.  \n \n \nFigure 10. The cube that selects audio profiles for the lab\u2019s \nmixer panel has labeled sides corresponding to the available \naudio sources. The side on top (TV in this case) is selected. \nThe small circuit board above the camera to the right of the \nplasma screen is the base station. The inset shows the \nequipment that drives the lab\u2019s audio system; sliders and \nchannels are automatically set to one of six common profiles \nby the cube.  \nThis first example uses merely the first module of the cube \n(\u201cwhich side is up?\u201d), but it has been deployed for half a year and \nhas become an accepted part of the lab, being used by a number \nof people on a daily basis.  \n7.2 On-Screen Navigation \nAnother example uses the outputs of the cube\u2019s second and third \nalgorithm modules as well, which provide applications with the \ndirection of all sides, the last state-transition (forward, back, left \nor right) and gestures.  \nFigure 11 shows a demonstration program that asks the user to \nnavigate an animated dot on the screen to a certain position and \nperform a certain action. Navigation is achieved by rotating the \ncube 90 degrees in the desired direction, while actions are \nrepresented by the gestures \u201cshaking\u201d, \u201ctwisting\u201d, and \n\u201cknocking\u201d.  \n \n \nFigure 11. The cube is used in a demonstration game to \nnavigate a dot on the screen by rotating the cube 90 degrees \nforward, backward, to the left or to the right. Actions like \nshaking the cube and knocking on it execute specific tasks. \nNotice that the cube has no labeled sides.  \nRotation of the cube along the Z-axis during the game results in \nthe model being distorted, as mentioned in section 5. Early tests, \nhowever, show that users are able to quickly correct this situation \nand rotate the cube back in the right position. Another restriction \nfor the application is that the cube needs to start with a known \nstarting state, which requires resetting it while holding the cube \nwith a marked side towards the user. Envisioned applications \nrange from simple user interfaces for children and disabled users, \nto games where four-way navigation and few actions are \nsufficient as interaction primitives (e.g. early text-based adventure \ngames, or board games).  \n8. RELATED WORK \nMany input devices exist that have embedded motion sensors, \nusually a combination of accelerometers and gyroscopes (see for \ninstance [1] or [3]). Most of them are considerably different from \nour approach as they track a relative two-dimensional or three-\ndimensional position in space, rather than states, and transmit \nthese data continuously to a dedicated application.  \nBenbasat and Paradiso [4] describe a device that is similar in form \nand sensing hardware. Their Inertial Measurement Unit (IMU) is \ncube-shaped and has four acceleration sensors, but also three \ngyroscopes. The algorithms on the IMU are specifically geared \ntowards gesture recognition, exploiting it as a generic sensor that \nis attached to another object. The framework around the IMU \nprovides \u2018atomic gestures\u2019 to an application\u2019s designer that can be \ncombined with AND and OR operators. The IMU cube is not \nenvisioned as a standalone device, and therefore does not have, \nnor require, the internal state model that allows the basic \nnavigation described in this paper.  \nThe fundamental shape of the cube has inspired others to create \ntangible interaction elements that are cube shaped, but require \nadditional external tracking equipment (such as reference beacons \nor tablet surfaces). Olwal [12] envisions cubes as core \ncomponents in an AR interface, Frohlich and Plate track position \nand orientation in three dimensional space of their Cubic Mouse \n[7], a cube with three orthogonal rods through the sides and \nbuttons, and Sharlin et al. use a collection of cubes to assess 3D \nconstructive abilities in the Cognitive Cubes project [14].  \nThe Toolstone [13] is a brick-like object on a tablet that senses \nmanipulation of itself by using internal coils. The Triangles \nsystem [8] uses a basic two-dimensional triangle to create a \nsystem for interaction with digital information. Brick-like objects \nhave been used for control in computer vision [6].  \n9. CONCLUSIONS \nA tangible cube that embodies basic gesture recognition with \ndirectional state and navigation information was introduced. In \nhardware, simple acceleration sensors are employed, leading to an \nefficient design in terms of energy consumption and size \nconstraints. In software, the lack of additional sensors is \ncompensated by an internal model of the cube\u2019s symmetrical \nproperties in a state diagram, a rigid maximum likelihood \nestimation procedure to guess the states, and crude gesture \nrecognition.  \nThe algorithms fit comfortably in a microcontroller environment \nwithout needing further calculation outside the cube; wireless \ncommunication is only activated when either a gesture is \nperformed or the cube\u2019s state has been changed. Initial \nexperiments in which the cube is deployed in real-world contexts \nsuggest that the cube is reliable and its batteries have an adequate \nlifespan.  \nFurther experimentation is scheduled to investigate the usability \nof the cube, the effects of its design (such as material, color, \nweight, or edges), and its limitations and fortes as an input device. \nMore in-depth hardware and algorithm descriptions, plus the \nMatlab scripts and datasets that were used to create the graphs in \nthis paper are available at: http:\/\/ubicomp.lancs.ac.uk \n10. ACKNOWLEDGMENTS \nThe prototypes in this work have been based upon earlier \nhardware and studies from the Smart-Its project (funded by the \nEU\u2019s IST framework), and the Equator project (funded by \nEPSRC, under grant GR\/N15986\/01 - \"Technological Innovation \nin Physical and Digital Life\").  \nWe would like to thank our partners in those projects, as well as \nall our colleagues at the department who were so kind to test the \ncube out and give us their feedback.  \n \n \n \n11. REFERENCES \n[1] 3D Mouse from Handview: http:\/\/www.handview.com\/  \n[2] ADXRS150 gyroscope: \u00b1150\u00b0\/s Single Chip Yaw Rate Gyro \nwith Signal Conditioning Data Sheet (Rev. A, 1\/03)   \n[3] Bartlett, J.F. Rock \u2019n\u2019 scroll is here to stay. IEEE Computer \nGraphics and Applications, Vol. 20-3, May\/June 2000. pp. \n40\u201345.  \n[4] Benbasat, A.Y. and Paradiso, J. A. An Inertial Measurement \nFramework for Gesture Recognition and Applications. In \nIpke Wachsmuth, Timo Sowa (Eds.), Gesture and Sign \nLanguage in Human-Computer Interaction, International \nGesture Workshop, GW 2001, London, UK, 2001 \nProceedings, Springer-Verlag Berlin, 2002. \n[5] FastICA Toolkit, Helsinki University of Technology. \nhttp:\/\/www.cis.hut.fi\/projects\/ica\/fastica\/ \n[6] Fjeld, M., Voorhorst, F., Bichsel, M., & Krueger, H. \nExploring brick-based camera control. In H.-J. Bullinger & J. \nZiegler (eds): Proceedings of HCI International\u201999, (the 8th \nInternational Conference on Human-Computer Interaction), \npp. 1060-1064. 1999.  \n[7] Froehlich, B. and Plate, J. The Cubic Mouse: A New Device \nfor Three-Dimensional Input. Proceedings of CHI 2000, pp. \n526-531. 2000. \n[8] Gorbet, M., Orth, M. and Ishii, H. Triangles: Design of a \nPhysical\/Digital Construction Kit. Proceedings of Designing \nInteractive Systems: Processes, Practices, Methods, and \nTechniques (ACM DIS '97), Amsterdam, ACM, pp. 125-128.  \n[9] Hyv\u00e4rinen, A., Karhunen, J., Oja, E. Independent \nComponent Analysis (ICA). John Wiley & Sons, 2001. \n[10] iMAR Triaxial iTGAC-FK Sensor Cube with Fiber Optical \nGyros and Accelerometers. http:\/\/www.imar-\nnavigation.de\/englishside\/dat_engl\/tgac_fk.pdf  \n[11] Mitchell, T. Machine Learning. McGraw-Hill c, 1997. \n[12] Olwal., A. Unit\u2014A Modular Framework for Interaction \nTechnique Design, Development and Implementation. \nMaster\u2019s project at the KTH, Stockholm, Sweden, executed \nin the Department of Computer Science at Columbia \nUniversity, New York, USA. 2002. \n[13] Rekimoto, J. and Sciammarella, E. ToolStone: Effective use \nof the physical manipulation vocabularies of input devices. \nIn Proc. of UIST 2000, 2000. \n[14] Sharlin, E., Itoh, Y., Watson, B., Kitamura, Y., Liu, L., \nSutphen, S. Cognitive Cubes: A Tangible User \nInterface for Cognitive Assessment, ACM CHI 2002 \nConference Proceedings, pp. 347-354, April 20-25, \n2002, Minneapolis, Minnesota \n[15] Weisstein, E. The Cube. World of Mathematics. Online web \nresource. http:\/\/mathworld.wolfram.com\/Cube.html  \n[16] Wenninger, M.J. The Hexahedron (Cube). In Polyhedron \nModels. Cambridge, England: Cambridge University Press, \np.16, 1989.  \n"}
{"doi":"10.1207\/S15326969ECO1403_3","coreId":"93169","oai":"oai:eprints.lse.ac.uk:2606","identifiers":["oai:eprints.lse.ac.uk:2606","10.1207\/S15326969ECO1403_3"],"title":"Gibson's affordances and Turing's theory of computation","authors":["Wells, Andrew J."],"enrichments":{"references":[],"documentType":{"type":0.6666666667}},"contributors":[],"datePublished":"2002","abstract":"The concept of affordance is a central component of the ecological psychology of J. J. Gibson (1966, 1977, 1979\/1986). Affordances are properties of the environment taken relative to an observer. Ecological theorists have developed formal models for the analysis of affordances. Models proposed by Shaw and Turvey (1981), Turvey (1992), and Greeno (1994) are described and evaluated, and another approach, using Turing's (1936-1937\/1965) theory of computation, is outlined. Affordances are characterized as the configurations of Turing machines. It is shown that Turing's work provides a natural vehicle for exploring Gibson's ideas","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/93169.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/2606\/1\/Affordances_and_Computation_APA_style_%28LSERO%29.pdf","pdfHashValue":"b0bf4922a95432c99f8ec39fa5c49fec42e1846a","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:2606<\/identifier><datestamp>\n      2016-06-20T11:19:03Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5053<\/setSpec><setSpec>\n      74797065733D4445505453:4C53452D504253<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/2606\/<\/dc:relation><dc:title>\n        Gibson's affordances and Turing's theory of computation<\/dc:title><dc:creator>\n        Wells, Andrew J.<\/dc:creator><dc:subject>\n        BF Psychology<\/dc:subject><dc:description>\n        The concept of affordance is a central component of the ecological psychology of J. J. Gibson (1966, 1977, 1979\/1986). Affordances are properties of the environment taken relative to an observer. Ecological theorists have developed formal models for the analysis of affordances. Models proposed by Shaw and Turvey (1981), Turvey (1992), and Greeno (1994) are described and evaluated, and another approach, using Turing's (1936-1937\/1965) theory of computation, is outlined. Affordances are characterized as the configurations of Turing machines. It is shown that Turing's work provides a natural vehicle for exploring Gibson's ideas.<\/dc:description><dc:date>\n        2002<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/2606\/1\/Affordances_and_Computation_APA_style_%28LSERO%29.pdf<\/dc:identifier><dc:identifier>\n          Wells, Andrew J.  (2002) Gibson's affordances and Turing's theory of computation.  Ecological Psychology, 14 (3).  pp. 140-180.  ISSN 1040-7413     <\/dc:identifier><dc:relation>\n        http:\/\/www.leaonline.com<\/dc:relation><dc:relation>\n        10.1207\/S15326969ECO1403_3<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/2606\/","http:\/\/www.leaonline.com","10.1207\/S15326969ECO1403_3"],"year":2002,"topics":["BF Psychology"],"subject":["Article","PeerReviewed"],"fullText":"  \nA.J. Wells\nGibson's affordances and Turing's theory \nof computation \n \nArticle (Accepted version) \n(Refereed) \nOriginal citation: \nWells, Andrew J. (2002) Gibson's affordances and Turing's theory of computation. Ecological \npsychology, 14 (3). pp. 140-180 \nDOI: 10.1207\/S15326969ECO1403_3\n \n\u00a9 2002 Lawrence Erlbaum Associates, Inc. \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/2606\/  \nAvailable in LSE Research Online: January 2010 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final manuscript accepted version of the journal article, \nincorporating any revisions agreed during the peer review process.  Some differences between \nthis version and the published version may remain.  You are advised to consult the publisher\u2019s \nGibson\u2019s affordances    1 \nAFFORDANCES AND COMPUTATION \n \n \n \nGibson\u2019s affordances and Turing\u2019s theory of computation \n \n \n \n \nA.J. Wells \nThe London School of Economics and Political Science \n \n \n \n \n \n \n \n  \nGibson\u2019s affordances    2 \nAbstract \nThe concept of affordance is a central component of the ecological psychology of J.J. \nGibson.  Affordances are properties of the environment taken relative to an observer.  \nEcological theorists have developed formal models for the analysis of affordances.  Models \nproposed by Shaw and Turvey (1981), Turvey (1992) and Greeno (1994) are described and \nevaluated and another approach, using Turing\u2019s theory of computation, is outlined.  \nAffordances are characterised as the configurations of Turing machines.  It is shown that \nTuring\u2019s work provides a natural vehicle for exploring Gibson\u2019s ideas.   \n  \nGibson\u2019s affordances    3 \nGibson\u2019s affordances and Turing\u2019s theory of computation. \nIntroduction. \nThe concept of affordance is a central component of  J.J. Gibson\u2019s ecological approach to \npsychology.  Early references to the concept are found in Gibson (1966) where he proposed \nthat perception should be understood in terms of perceptual systems rather than channels of \nsensation.  A theory of affordances was developed in Gibson (1977) and in his final book, \nGibson (1979).  Like many other profound ideas, the concept of affordance is intuitively \nsimple, but its richness makes it hard to pin down precisely.   Gibson eschewed formal \ndefinition and used examples to illustrate the wide-ranging nature of the idea.  Other \necological theorists have developed formal models to provide a basis for further theoretical \ndevelopment.  Shaw & McIntyre (1974) examined the nature of the invariance relations \nlinking physical and psychological laws, and formal schemas for affordances were developed \nby Turvey & Shaw (1979), Shaw & Turvey (1981) and Shaw, Turvey & Mace (1982).  A \nframework for ecological psychology, based on the concept of a \u201ccoalition\u201d, was set out by \nShaw & Turvey (1981).  Turvey (1992) offered an alternative formal definition of \naffordances and Greeno (1994) suggested an analysis based on situation theory.  This paper \nreviews these approaches and argues that an account of affordances based on Turing\u2019s theory \nof computation provides a stronger and simpler formal foundation for ecological psychology.   \nIt has been widely agreed both by its proponents and opponents that Gibson\u2019s ecological \ntheory stands in opposition to computational theories of perception, (cf. Gibson, 1979; \nUllman, 1980; Fodor & Pylyshyn, 1981; Turvey, Shaw, Reed & Mace, 1981; Carello, \nTurvey, Kugler & Shaw 1984; Pylyshyn, 1984; Shepard 1984; Reed 1991; Greeno 1994; \nThelen & Smith 1994; Kelso, 1995; Port & van Gelder, 1995; Clark, 1997).  However, \nTuring\u2019s original theory of computation contains striking formal parallels to the affordance \nconcept that have not previously been considered.  They are outlined in this paper.  The \n  \nGibson\u2019s affordances    4 \napproach is not Procrustean.  It does not attempt to bring affordances within the purview of a \ntraditional computational framework for perceptual theory in the way advocated, for \nexample, by Vera & Simon (1993).  Instead, it is based on the idea that the theory of \ncomputation, as presented in Turing (1936-7), is a natural vehicle for clarifying and exploring \nquestions that arise within ecological psychology.  Turing\u2019s theory lends itself to this purpose \nbecause it is an ecological theory.  It is concerned with entities that are defined at the \necological scale and it demonstrates the reciprocity or mutuality of the agent and its \nenvironment.  The abstract conception of a computing machine that Turing developed in \n1936 treats the fundamental relationship between the agent and the environment in a \ncompletely different fashion from later theories based on stored program computers (see \ndiscussion in Wells, 1998).  This crucial point has not been widely recognized.   \nThe new computational approach is intended to promote analysis of questions about \nthe internal states of perceivers in a way that is consistent with Gibson\u2019s ecological approach \nbut goes beyond his primary concern with the informational content of the environment.  \nMany theorists, who are otherwise sympathetic to Gibson\u2019s ideas, have found his apparent \nrejection of the perceptual significance of the internal states of the perceiver untenable.  \nShepard (1984), for example, argued that perceptual theorists need to consider constraints \nthat have been internalized as a result of selective pressures operating over evolutionary time.  \nHe suggested that the metaphor of resonance, which Gibson had derived from Lashley, could \nbe developed to this end.  This line of development has had only limited success.  Kelso \n(1995, p.188) suggests that it remains \u201cunderelaborated\u201d.   The approach taken in this paper \nshows how the internal states of the agent can be incorporated into ecological theory. \nAffordances were characterised by Gibson as properties of the environment taken \nrelative to an animal.  Gibson emphasised the mutuality or reciprocity of the relations \nbetween animals and their environments but his own work was concerned primarily with the \n  \nGibson\u2019s affordances    5 \nanalysis of environmental information.  Other ecological theorists have stressed the need to \nprovide a complementary account of those properties of animals that enable them to act on \naffordances.  The term \u201ceffectivity\u201d has been widely used for this purpose and much of the \nformal work that has been done has had as a goal the elucidation of the relation between \naffordances and effectivities.  Shaw, Turvey and their colleagues have argued that \naffordances and effectivities are \u201cduals\u201d of each other and the coalitional framework set out \nby Shaw & Turvey (1981) treats the concept of duality as fundamental.  It is argued here that \nTuring\u2019s computational model provides a clear account of effectivities and affordances and \ndemonstrates the mutuality between them better than does the concept of duality.  \nGibson on Affordances. \nGibson (1979, p.22) described psychology as \u201cthe study of the perception and \nbehavior of animals and men as a function of what the environment affords.\u201d  He regarded \nthe hypothesis that information in the ambient optic array specifies affordances to be \u201cthe \nculmination of ecological optics\u201d (Gibson 1979, p.143).  Affordances have many \ncharacteristics.  They can be subsumed within a framework that focuses on the following \nseven features; affordances are ecological, they are relational, they are facts of the \nenvironment and behavior, sets of them constitute niches, they are meanings, they are \ninvariant combinations of variables and they are perceived directly. \nAffordance is an ecological concept. \nThe world, as Gibson observed, can be described at many levels because reality has \nstructure at many levels.  He argued that the appropriate level at which to study human, and \nother animal, behavior was the ecological level.  The characterization of the ecological level \nhas been controversial (see discussion in Fodor & Pylyshyn 1981; Turvey, Shaw, Reed & \nMace 1981), but it can plausibly be regarded as a level of analysis whose ontology contains \nthe everyday objects and events with which human behavior is concerned.  Turvey (1992) \n  \nGibson\u2019s affordances    6 \nsuggested that ecological ontology is materialist and dynamicist but is not committed to the \nreductionism of classical physicalism.  Issues about the appropriate ontology for ecological \npsychology have also been discussed by Kadar & Effken (1994), in a review of Turvey\u2019s \npaper, and by Still & Good (1998) whose concerns include the importance of the social \naffordances of conspecifics.  The ecological level for a species is thus partly determined by \nthe kinds of objects and events that have constituted significant selection pressures for that \nspecies.  However, although ontology and evolution are both important, the key point about \nGibson\u2019s ecological approach to perception is that it is concerned with natural, unfettered \nvision.  One corollary of this approach is that one cannot be interested simply in the anatomy \nand physiology of the eye or in the activity of the brain.  \u201cWe are told that vision depends on \nthe eye, which is connected to the brain.  I shall suggest that natural vision depends on the \neyes in the head on a body supported by the ground, the brain being only the central organ of \na complete visual system.\u201d  Gibson (1979, p.1).  A further corollary of the approach is a \nfundamental concern with what the environment offers the unconstrained perceiver.  The \ntheory of affordances is central to the ecological approach because it examines the nature of \nthe relationship between the mobile perceiver and the environment.   \nAffordances are relational. \nThe ecological nature of affordances implies that they are also relational, i.e. that they are \npredicated of two or more things taken together.  Gibson described affordances as pointing \ntwo ways, to the environment and to the observer. He coined the term \u201caffordance\u201d in order \nto be able to refer to an organism and its environment in a new way. Lombardo (1987) has \nsuggested that affordances exemplify the principle of reciprocity which he takes to be the \ncentral insight in Gibson\u2019s ecological approach.  Lombardo suggests that reciprocity in this \nsense means distinguishable yet mutually supportive realities.  However, the relational or \nreciprocal nature of affordances creates a tension in Gibson\u2019s theorizing because he also \n  \nGibson\u2019s affordances    7 \nclaims that affordances are facts of the environment and not dependent on the needs of the \nobserver. Thus, while reciprocity is an important part of the ecological approach, Gibson\u2019s \nview of the nature of animal\/environment relations can best be described as asymmetric inter-\ndependence.  The relationship is one of inter-dependence because the terms \u201canimal\u201d and \n\u201cenvironment\u201d are complementary, but it is asymmetric because the environment is a more \nimportant source of perceptual structure than the animal.  The asymmetry in Gibson\u2019s \napproach has been a source of controversy particularly with regard to his unwillingness to \nconcede a substantial role for internal representations in perception.    \nAn early presentation of the concept of affordance, Gibson (1966, p.285), was made in \nthe context of the theory of information pickup.  The context makes it clear that affordances \nare part of the information available in the environment.  Affordances are defined as \u201cwhat \nthings furnish, for good or ill.\u201d  The notion that affordances are relational with both \nenvironmental and animal components is not prominent.  The emphasis is very much on their \nenvironmental character. \nGibson (1977) and Gibson (1979, Ch.8) provide an opportunity to examine the evolution \nof Gibson\u2019s thinking about the relational nature of affordances.  Gibson (1977) is a \npreliminary version of Chapter 8 of Gibson (1979).  The two versions of the chapter are \nstructurally very similar but there are revisions and additions which, presumably, reflect \nchanges in Gibson\u2019s thinking. One of the notable developments from 1977 to 1979 is an \nincreased emphasis on the relational nature of affordances.  \nIn Gibson (1977, p67) an affordance of an object is defined as \u201ca specific combination of \nthe properties of its substance and its surfaces taken with reference to an animal\u201d.  Although \naffordances are defined in this passage \u201cwith reference to an animal\u201d it is not clear how the \nreference is to be understood.  Gibson does not refer to the properties of animals even though \nan intuitive and natural way to understand the relational nature of affordances would be in \n  \nGibson\u2019s affordances    8 \nterms of matching properties of objects and individuals.  Presumably he wanted to avoid the \nsuggestion that affordances depend on the individual. \nThe corresponding passage in Gibson (1979, p.127) reads as follows; \u201cThe affordances of \nthe environment are what it offers the animal, what it provides or furnishes, either for good or \nill\u2026It implies the complementarity of the animal and the environment.\u201d  An interesting \ndifference between these two passages is the introduction of the term \u201ccomplementarity\u201d in \n1979 to describe the relation between environment and animal.  Complementarity is a \nconcept, originally developed in physics, that refers to the existence of superficially \ninconsistent views of an object or phenomenon such as the wave\/particle duality of light.  If \nGibson had this in mind, the use of the term to describe affordances suggests that he \nconsidered the relation between animals and environments to be stronger than simple \nreciprocity or interdependence.  One possibility is that environments and animals are, in a \nsense, co-defined.   Then \u201canimal\u201d would be one particular way of referring to the \nanimal\/environment duality and \u201cenvironment\u201d would be another.  As with waves and \nparticles, the choice of term would vary according to the particular aspect of the system under \ninvestigation.  Some support for this notion can be found in Gibson (1979, p.8) where he \nsays: \nThe fact is worth remembering because it is often neglected that the words animal and \nenvironment make an inseparable pair.  Each term implies the other.  No animal could \nexist without an environment surrounding it.  Equally, although not so obvious, an \nenvironment implies an animal (or at least an organism) to be surrounded.  This means \nthat the surface of the earth, millions of years ago before life developed on it, was not an \nenvironment, properly speaking. \nOne important final point is Gibson\u2019s absolute rejection of dualism.  His claim that \naffordances point to the environment and to the observer  \u201cis wholly inconsistent with \n  \nGibson\u2019s affordances    9 \ndualism in any form, either mind-matter dualism or mind-body dualism.  The awareness of \nthe world and of one\u2019s complementary relations to the world are not separable.\u201d  Gibson \n(1979, p.141). \nAffordances are facts of the environment and facts of behavior. \nGibson was a realist about the objects of perception.  The fact that affordances are \nrelational does not imply that the things that afford behavior depend on the observer.  \u201cThe \nobserver may or may not perceive or attend to the affordance, according to his needs, but the \naffordance, being invariant, is always there to be perceived.\u201d  Gibson (1979, p.139).  Thus \naffordances are facts of the environment.  At the same time, a core part of the ecological \napproach is the activity of the perceiver.  Gibson was frequently at pains to stress that \nperception is an achievement of the active observer.  \u201cThe eyes, ears, nose, mouth, and skin \ncan orient, explore, and investigate.  When thus active they are neither passive senses nor \nchannels of sensory quality, but ways of paying attention to whatever is constant in the \nchanging stimulation.\u201d Gibson (1966, p.4). The theory of affordances links what objects offer \nto the possibilities for behavior that exist for a given creature.  The theory \u201cimplies that to see \nthings is to see how to get about among them and what to do or not do with them.\u201d  Gibson \n(1979, p.223).  Moreover, affordances are not neutral.  Some are positive and some negative \nand it is this that \u201cmakes locomotion through the medium such a fundamental kind of \nbehavior for animals.\u201d Gibson (1979, p.232).  Thus affordances are also facts of behavior. \nSets of affordances constitute niches. \nGibson distinguished the niche an animal occupies from its habitat.  The habitat of an \nanimal, he suggested, refers to where it lives, whereas its niche refers to how it lives.  The \nrelational treatment of niches and animals suggests an analysis in terms of affordances and \nGibson made this explicit when he said that \u201ca niche is a set of affordances\u201d  Gibson (1979, \np.128).  This idea implies that \u201cthe environment from an ecological viewpoint\u2026is a complex \n  \nGibson\u2019s affordances    10 \nset of relationships among various affordances\u201d Shaw, Turvey & Mace (1982, p.196).  The \nnature of the links between affordances is tackled in Shaw and Turvey\u2019s analysis of \necosystems as coalitions and also has a natural explanation in Turing machine terms. \nAffordances are meanings. \nAn important aspect of the characterization of affordances as ecological is the \nhypothesis that affordances are meanings.  \u201cPerhaps the composition and layout of surfaces \nconstitute what they afford.  If so, to perceive them is to perceive what they afford.  This is a \nradical hypothesis, because it implies that the \u201cvalues\u201d and \u201cmeanings\u201d of things in the \nenvironment can be directly perceived.\u201d Gibson (1979, p.127).  Gibson also says quite clearly \nthat meanings qua affordances are independent of the observer.  \u201cAn affordance is not \nbestowed upon an object by a need of an observer and his act of perceiving it.  The object \noffers what it does because it is what it is.\u201d  Gibson (1979, p.139). His approach requires a \ndistinction between the physical conditions for meaningfulness and the perception of a \nmeaning at a specific place and time.  Consider, for example, that British rock climbers in a \nless secular age deployed the concept of a \u201cthank God\u201d hold.  In Gibsonian terms, a thank \nGod hold is an attached object on a cliff face that affords safe, secure, and relatively relaxed \ngrasping.  It is the kind of hold that a climber fervently desires at the end of a long, strenuous \npitch on exiguous holds when nerves and muscles are complaining.  The climber who grasps \nsuch a hold in trying circumstances experiences a release of physical and nervous tension, \nfeels exhilaration and a sense of ease, and may utter the words that give the hold its name.  \nHowever, despite the intimate connection between the hold and the thoughts and feelings of \nthe climber, the physical conditions for a thank God hold obtain whether there is anyone \nusing it or not and it is always there to be perceived and used.   \nAffordances are invariant combinations of variables. \n  \nGibson\u2019s affordances    11 \nThe notion of invariant structure that underlies the flux of stimulation is a central \naspect of Gibson\u2019s theorising. It provides the basis for his approach to the fundamental \nquestion of how constant perception is possible.  For Gibson, constant perception is possible \nbecause \u201ccertain higher-order variables \u2013 stimulus energy, ratios, and proportions, for \nexample \u2013 do not change. They remain invariant with movements of the observer and with \nchanges in the intensity of stimulation.\u201d Gibson (1966, p.3).  This view contrasts with the \nconstructivist proposal that the constants of perception are built by internal operations of the \nperceiver on the changing deliverances of the senses.   \nInvariant structure is also important in the Gibsonian framework because it explains \nthe conditions that supported the evolution of animal life and encourages an evolutionary \napproach to perceptual theory.  The link between evolutionary processes and affordances is \nquite explicit.  Gibson described how the medium allows breathing and locomotion, and can \nbe filled with illumination, vibrations and odours.  \u201cAll these offerings of nature, these \npossibilities or opportunities, these affordances as I will call them, are invariant.  They have \nbeen strikingly constant throughout the whole evolution of animal life.\u201d  Gibson (1979, \npp.18-19).  \nA further linkage between invariants and affordances in Gibson (1979) emphasizes \nthe significance of mobility. It occurs in Gibson\u2019s appraisal of his early theory of how \nambient light is structured.  One source of variation in the structuring of ambient light is the \ndiurnal rotation of the earth.  Another, highly significant, source of variation in optical \nstructure is found in the flow of stimulation that is available to a mobile creature. \u201cThe \nperceiver extracts the invariants of structure from the flux of stimulation while still noticing \nthe flux.  For the visual system in particular, he tunes in on the invariant structure of the \nambient optic array that underlies the changing perspective structure caused by his \nmovements.\u201d  Gibson (1979, p.247).   The linkage between the detection of invariants and the \n  \nGibson\u2019s affordances    12 \nmobility of the perceiver is a key aspect of the theory of affordances. \u201cThe theory of \naffordances implies that to see things is to see how to get about among them and what to do \nor not do with them.  If this is true, visual perception serves behavior, and behavior is \ncontrolled by perception.\u201d  Gibson (1979, p.223).   \n One other important aspect of the characterisation of affordances as invariant \ncombinations of variables is that it allows for different orders of affordances.  If primary \naffordances are always found in particular combinations then those combinations can \nthemselves constitute higher order affordances.  Gibson may have had this idea in mind when \ndiscussing the optical information for perceiving affordances where he says,  \u2018a unique \ncombination of invariants, a compound invariant, is just another invariant\u2026it could be argued \nthat when a number of stimuli are completely covariant, when they always go together, they \nconstitute a single \u201cstimulus\u201d.\u2019 Gibson (1979, p.141). \nAffordances are perceived directly. \nGibson recognised that, in general, complex affordances have to be learned.  \nHowever, he claimed that the basic affordances of the environment are perceived directly. \nGibson used the idea of direct perception to distinguish the theory of affordances from earlier \ntheories such as that of the Gestalt psychologist Kurt Koffka.  Koffka had suggested that the \ndirectness and immediacy of the perception of what he called \u201cphenomenal\u201d objects arose \nfrom a dynamic relation between the object and the ego.  Gibson reports that he found this \ntheory unintelligible and said, Gibson (1979, pp.139-140) that: \nThere is an easier way of explaining why the values of things seem to be perceived \nimmediately and directly.  It is because the affordances of things for an observer are \nspecified in stimulus information.  They seem to be perceived directly because they \nare perceived directly.  \nCoalitions as models for ecosystems. \n  \nGibson\u2019s affordances    13 \nThe formal treatment of coalitions forms part of a wide ranging paper by Shaw & \nTurvey (1981).  That paper is part of an extensive body of work developed by Shaw, Turvey \nand their co-workers over a period of more than twenty five years.  A summary of some of \nthe key aspects of this literature can be found in Turvey & Shaw (1995).  Turvey and Shaw \nreject dualism and argue for an understanding of the relation between an animal and its \nenvironment in terms of the concept of duality.  The link between perception and action is \ncharacterised by the claim that affordances and effectivities are duals.  This claim is worked \nout in detail in Shaw & Turvey (1981).  The focus of the coalitional style of inquiry is \u201cthe \nanimal-environment system described in full\u201d Shaw & Turvey (1981, p.344), but a coalition \nis only a partial model of an ecosystem, because \u201cit is not intended to be a dynamic model of \nnatural systems, for these must include\u2026both time-dependent and energy-dependent \nprocesses.\u201d Shaw & Turvey (1981, p.393).  Instead, a coalition \u201cprovides a formal description \nfor how many grains of analysis are minimally required and maximally allowed over which \nvariables must be selected (bases), related, ordered, and evaluated\u201d Shaw & Turvey (1981, \np.393).   \nA coalition is a mathematical model of an ecosystem.  The model pays particular \nattention to the issues of mutuality and nesting of contexts.  The \u201cfundamental building \nblock\u201d is the concept of a duality relation which is claimed to hold between affordances and \neffectivities.  This is intended to capture the core notion of animal-environment mutuality.  \nDualities exist in various branches of mathematics.  In plane projective geometry, for \nexample, \u201cto each theorem of the subject the statement obtained from it by interchanging the \nwords \u2018point\u2019 and \u2018line\u2019 is also a theorem.\u201d Kleene (1971, p.56).  Similar relationships can be \nfound in the algebra of sets, in propositional logic and in the predicate calculus.  Dualities are \ntypically expressed in terms of syntactic transformations, but they reflect a deeper underlying \nreality.  Care is needed, however, even in those systems where dualities are known to exist, \n  \nGibson\u2019s affordances    14 \nnot to overstate the generality of the principle.  Kleene (1971, p.123), for example, shows that \nduality holds only as a subsidiary deduction rule for the propositional calculus.   \nIt is important to note that the existence of a syntactic transform T which is such that \nT(\u03b1) = \u03b2 and T(\u03b2) = \u03b1 does not suffice to demonstrate the existence of a genuine duality \nbetween \u03b1 and \u03b2.  If that were so, we could demonstrate a duality between cats and dogs by \ndefining T as the relative complement (B \u2013 a) of the pair set B = {cat, dog} for each a in B.  \nUnder this definition T(cat) = {dog} and T(dog) = {cat}.  Clearly this tells us nothing about \ncats and dogs, but only something about the structure of the set B.  If a duality is known to \nexist then an appropriate syntactic transform can be used to obtain one member from the \nother, but it is fallacious to infer the converse.  It is necessary, therefore, to distinguish \nsyntactic duals from substantive duals.  Syntactic duals can be created by stipulative \ndefinition but substantive duals depend on the prior existence of deeper relationships \nalthough they will also have syntactic expressions.  Shaw and Turvey\u2019s analysis is based on \nsyntactic duals derived from stipulative definitions.  They say that a duality is specified by \n\u201cany symmetrical rule\u2026where T applies to map X onto Z and Z onto X\u201d Shaw & Turvey \n(1981, p.381).  This definition allows the dog\/cat example to count as a duality. \nThe failure to distinguish syntactic from substantive dualities leads Shaw and Turvey \ninto a circular argument in the discussion of schemas for affordances and effectivities that \nprecedes the exposition of the formal structure of a coalition.  Drawing on earlier work, Shaw \nand Turvey propose (X,Z,O | X = Z) = Y as an affordance schema.  This is read as \u201cX affords \nY for Z on occasion O if and only if there exists a duality relation between X and Z\u201d.  They \nthen suggest that if affordances are \u201ctruly dual\u201d concepts of effectivities there will be a \nsyntactic relation between the affordance schema and the effectivity schema.  This they then \ndefine.  The syntactic relation transforms (X,Z,O | X = Z) into (Z,X,O | Z = X).  Having \ndefined the rule they say \u201cBy inspection, we see then that the schema that defines an \n  \nGibson\u2019s affordances    15 \naffordance (X,Z,O|X = Z) is dual with the schema (Z,X,O|Z = X) under application of the rule \nalready stipulated.  This resulting schema should correspond to an effectivity.\u201d Shaw & \nTurvey (1981, p.388).  Finally, they claim that \u201cThe general form of this duality of perception \nand action, vis \u00e0 vis affordances and effectivities, is by no means trivial; for it provides the \nbasis for our original assumption that perception and action must be closely linked.\u201d Shaw & \nTurvey (1981, p.388, emphasis added).  The argument is clearly circular; if there is a \nsubstantive duality between affordances and effectivities there will be a syntactic duality.  \nThere is (by stipulation) a syntactic duality, therefore there is a substantive duality.   \n  A coalition relates four categories of entities, a set B of bases, a set R of relations, a \nset O of orders and a set Vof values.  Each category of entity, i.e. bases, relations, etc. is said \nto identify a \u201cgrain\u201d of analysis.  Thus there is a basis grain, a relation grain, an order grain \nand a value grain.  Grains are related to each other on a dimension of coarseness g(B) > g(R) \n> g(O) > g(V) where \u201c>\u201d indicates \u201ccoarser than\u201d.  One might think that a fine grain would \nstand to a coarse grain as a molecular analysis stands to a molar analysis.  But that is not what \nis intended.  In a footnote to the formal model (p.389), grains of analysis are explicitly \ndistinguished from scales of analysis which refer to the molecular\/molar type of dimension \nand from levels of analysis which refer to the degree of abstraction of a model.  Grains model \nwhat Shaw and Turvey call contexts of constraint.  The basis grain describes the set of \nvariables over which the model is defined.  The relation grain describes the ecological \nrelations that are possible given the basis variables.  It allows the theorist to describe \necological relations that are independent of specific animals.  The relation of edibility for \nexample, can be described at the relation grain independently of particular animals and \nparticular foods.  The order grain provides descriptors for the affordance structure of the \nenvironment and for the effectivity structure of an animal.  This grain is, therefore, animal \n  \nGibson\u2019s affordances    16 \nspecific.  Finally, the value grain specifies which affordances are noticed or which \neffectivities are activated on a given occasion.  \n Shaw and Turvey stipulate that grains must be characterised as \u201cthe disjoint union of \ndual subsets\u201d Shaw & Turvey (1981, p.389).  This allows them to specify syntactic dualities \nat each grain.  The term \u201cdisjoint union\u201d has different definitions in different branches of \nmathematics but Shaw and Turvey intend it to mean that each grain is structured as a set with \ntwo non-overlapping members which are themselves sets.  Thus the basis grain is a set B = \n{X,Z}, the relation grain is a set R = {\u03c6,\u03c8}, the order grain is a set O = {A,E} the value grain \nis a set V = {S,N}, and in each case, the members X and Z, for example, have no elements in \ncommon.  The disjoint subsets are related by a \u201cduality operation\u201d T which is such that for a \ngiven grain G = {\u03b1,\u03b2}, T(\u03b1) = \u03b2 and T(\u03b2) = \u03b1.  Thus, for the basis grain, T(X) = Z and T(Z) \n= X, for the relation grain T(\u03c6) = \u03c8 and T(\u03c8) = \u03c6 and so, mutatis mutandis, for the order and \nvalue grains.  T is defined in terms of set complementation and is clearly a syntactic duality.   \nTo understand coalitions it is necessary to consider the structure of each grain of \nanalysis in greater detail.  The basis grain B = {X,Z} is derived from a set U which is defined \nby Shaw and Turvey as a set of ordered pairs of descriptors for \u201cthe \u2018polar\u2019 concepts of all \ndimensions of significant variation in nature\u201d Shaw & Turvey (1981, p.390). U = {(b1,b1\u2019), \n(b2,b2\u2019), \u2026}, each bi  is a variable and bi\u2019 is its dual covariate variable.1  Shaw and Turvey \nsuggest that a bi might be a dimension of thermal variation and its dual, bi\u2019, a covariate \ndimension of radiant variation.  Thus bi would, presumably, be a number representing heat \nand bi\u2019 a number representing light.  B = {X,Z} is derived from U. X and Z are defined as \nordered tuples, but it is not clear whether X and Z are intended to be finite or infinite.  In one \nplace (p.390) the definitions are bounded by a number k such that  X = (b1, b2, \u2026, bk) and Z = \n(b1\u2019, b2\u2019, \u2026, bk\u2019) elsewhere (p.392) they are unbounded X = (b1, b2, \u2026) and Z = (b1\u2019, b2\u2019, \n\u2026).2   For present expository purposes this is not a crucial point.  The simplest coalition need \n  \nGibson\u2019s affordances    17 \nhave only two variables, one in X and one in Y and is clearly finite.  Consider the activity of \ngrasping a ball.  To a first approximation, a person can grasp a ball if their hand-span is \ncompatible with the diameter of the ball.  In the analysis of this case X contains just a single \nenvironmental variable, the diameter of the ball, and the corresponding single animal variable \nin Z is the hand-span of the agent.  It is assumed that the diameter of the ball and the hand-\nspan of the agent are measured in some appropriate set of units, but in the illustration of the \nformal model given here the variable names alone are used.  Because there is just one \nvariable in X and one in Z, X and Z are treated as singleton sets rather than ordered tuples.  \nThus X = {ball-diameter}, Z = {hand-span} and B = {ball-diameter, hand-span}.3  For the \nsake of brevity \u201cb\u201d stands for ball-diameter and \u201ch\u201d for hand-span.  Thus X = {b}, Z = {h} \nand B = {b,h}.   \n  The relation grain R is intended to model the ecological relations that are possible \ngiven the particular basis grain chosen. R is defined as the Cartesian product B x B.  Thus, in \nthe example, R is the set of ordered pairs {<b,b>, <b,h>, <h,b>, <h,h>}.  By stipulation, R is \nalso characterised as the set {\u03c6,\u03c8} such that \u03c6 = {<b,b>, <b,h>}and \u03c8 = {<h,b>, <h,h>}.  The \nset \u03c6 is said to correspond to the environment and the set \u03c8 to the animal but the nature of the \ncorrespondence is unspecified.  On inspection it is clear that each pair in \u03c6 has \u201cb\u201d as its first \nmember and always includes \u201cb\u201d whereas each pair in \u03c8 has \u201ch\u201d as its first member and \nalways includes \u201ch\u201d.  Thus there are more references to the environmental variable \u201cb\u201d in \u03c6 \nand more to the animal variable \u201ch\u201d in \u03c8.  Beyond that, the interpretation of the members of \nR is opaque because the ordering is not interpreted.  One can imagine that an ordered pair like \n<b,h> might be used to indicate, say, an information flow from environment to animal and a \npair like <h,b> for a flow in the other direction but Shaw and Turvey do not suggest these or \nany other interpretations. Without an interpretation of the elements of R it is impossible to tell \n  \nGibson\u2019s affordances    18 \nwhat ecological relations Shaw and Turvey intend to model with the relation grain.  In the \ncontext of the example one might hope to be able to specify ecological relations like \ngrasping, catching, throwing, rolling and bouncing, but the formal model provides no clues as \nto how this might be done.  Given this lack of specificity, the fact that a transform T can be \ndefined such that T(\u03c6) = \u03c8 and vice versa, provides nothing more than a syntactic duality, \neven though Shaw and Turvey suggest that it demonstrates a fundamental duality between \nenvironments and animals. \nFrom the point of view of the analysis of affordances, the order grain is the most \nimportant because it provides formal descriptors for affordance and effectivity structures.  \nThe order grain is based on a set O which is defined as the Cartesian product R x R.  Thus the \nmembers of O are ordered pairs of ordered pairs.  Continuing with the example of grasping, \nO = {<<b,b>,<b,b>>, <<b,b>,<b,h>>, <<b,b>,<h,b>>, <<b,b>,<h,h>>, <<b,h>,<b,b>>, \n<<b,h>,<b,h>>, <<b,h>,<h,b>>, <<b,h>,<h,h>>, <<h,b>,<b,b>>, <<h,b>,<b,h>>, \n<<h,b>,<h,b>>, <<h,b>,<h,h>>, <<h,h>,<b,b>>, <<h,h>,<b,h>>, <<h,h>,<h,b>>, \n<<h,h>,<h,h>>}.  Like B and R, O is divided into halves by stipulative definition such that O \n= {A,E}with A = {<<b,b>,<b,b>>,\u2026, <<b,h>,<h,h>>} and E = {<<h,b>,<b,b>>,\u2026, \n<<h,h>,<h,h>>}.  The sets A and E are intended to provide descriptors for affordances and \neffectivities respectively.  Inspection of A and E shows that the members of A all have a \nmember of \u03c6 as their first element (<b,b>, for example, is the first element of <<b,b>,<b,h>>) \nand the members of E all have a member of \u03c8 as their first element.  However, like the \nelements of R, the elements of O, including eight different affordance schemas, are \nuninterpreted.  This leaves important and difficult questions open.  Should one always expect \nto find eight types of affordance regardless of the domain over which the variables in the \necosystem ranged?  Could there, for example, be eight types of ball grasping affordance?  \nWhen one considers the different types of ball game and the different types of grip it seems \n  \nGibson\u2019s affordances    19 \nplausible, but it is not obvious that it would always be possible to populate the full range of \nschemas.  If it were not possible for an arbitrary domain, restrictions would have to be \nspecified indicating which types were compatible with the domain.  That would further \ncomplicate the analysis. \nShaw and Turvey define a transformation T such that T(A) = E and T(E) = A.  They \nargue that T demonstrates the duality of affordances and effectivities.  The definition of T is \nmore complex than the relative complement operation used to define the transforms for the \nsets B and R but like them it is open to the criticism that it is a purely syntactic duality.  T has \ntwo stages; in the first stage a structure <<a,b>, <c,d>> is mapped to <<c,d>, <a,b>> and in \nthe second stage <<c,d>, <a,b>> is mapped to <<c\u2019,d\u2019>, <a\u2019,b\u2019>>.  Thus the first stage takes \nan ordered pair of the form <A,E> and turns it into a pair of the form <E,A> and the second \nstage takes each lowest level element and transforms it according to the transformation \ndefined for the basis grain.  Using the current example and combining the two stages, \nT(<<b,b>,<b,h>>) = <<h,b>,<h,h>>.  If one catalogues all the transforms on O as Shaw and \nTurvey do in their Table 11.2, (Shaw & Turvey, 1981, p.395) they fall into three classes.  \nThere are mappings from affordances to effectivities and vice versa which Shaw and Turvey \ncall \u201cOther-Duals\u201d, mappings from affordances to affordances and effectivities to \neffectivities, which Shaw and Turvey call \u201cOrder-Reflexive Duals\u201d and identity mappings \nwhich Shaw and Turvey call \u201cSelf-Duals\u201d.  Other-Duals are said to reflect the fundamental \nlinkage between perception and action, Order-Reflexive Duals are said to specify \ncomplementary affordance or effectivity properties and Self-Reflexive Duals are said to \nspecify repetitive cycles of perceiving or acting, Shaw & Turvey (1981, p.394). \nThe three-fold classification of Other-Duals, Order-Reflexive Duals and Self-Duals \narises from the specific form of T and prompts two questions.  Why does T have two stages \nand why are the stages as they are?  There is no discussion of either of these questions but \n  \nGibson\u2019s affordances    20 \nthey are important because other transforms can easily be defined.  Suppose, for example, \nthat a transform T\u2019 is used which is just the first stage of Shaw and Turvey\u2019s transform T.  In \nthat case, the duality T\u2019: A -> E and E -> A still exists but its character is changed.  Under T\u2019 \nthere are no Order-Reflexive Duals or Self-Duals.  Every transformation yields an Other-\nDual.  This shows that the categories \u201cOther-Dual\u201d, \u201cOrder-Reflexive Dual\u201d and \u201cSelf-Dual\u201d \nare artefacts of the definition of T which is given no independent justification.  Without it, T \nhas no more claim to represent truths about the nature of affordances and effectivities than \ndoes any other syntactic duality that can be defined for the order grain.   \nThe finest grain of analysis in a coalition is V, the value grain.   This is not defined as \nO x O, which one might expect given the preceding definitions of O and R, but as O x {+,-}.4  \nThe value grain is intended to distinguish those affordances and effectivities that are selected \nand activated on a given occasion from those that are not.  The formal definition of V inherits \nthe lack of specificity of its predecessors and is similarly difficult to interpret. \nWithout interpretations of the orderings found at the different grains, coalitions do not \nprovide the precision that one looks for in a mathematical model.  Nor does they fulfil Shaw \nand Turvey\u2019s stated aim of demonstrating how the potential regress of explanatory levels can \nbe blocked.  They suggest that a regress to coarser grains than B is blocked because the \naddition of new dual variables to B simply increases the number of elements without adding a \nnew level.  At the value grain they argue that no new subsets of V are produced by the \naddition of variables to B.  These points do not make the case.  At the level of the basis grain, \nit is precisely the choice of variables that is important for explanatory closure.  The fact that \nthe basis grain is closed under duality is a consequence of the stipulation that each variable in \nX has a covariate in Z.  It does not ensure that the set of variables chosen for X and Z will \nsuffice to explain the phenomena under study.  Thus the definition of B and the exclusion of \ncoarser grains is irrelevant to explanatory closure.  At the value grain it is argued that any \n  \nGibson\u2019s affordances    21 \n\u201cattempt to fabricate arbitrary partitions under V, aside from those dual partitions specified \nby {+,-}, will fail to be closed under a duality operation.\u201d  Shaw & Turvey (1981, p.392).  It \ndoes not follow that V is the finest grain possible in the analysis of an ecosystem.  An \nindefinitely large number of further grains can be defined, starting with the Cartesian product \nV x V, because the hierarchy of Cartesian products is endless.  To block the regress it would \nbe necessary to show that neither V x V nor any finer grain could have any explanatory value.  \nShaw and Turvey\u2019s analysis does not achieve this.  Indeed, when one considers that the grain \nV x V would consist of relations between selected and unselected affordances and \neffectivities, it is apparent that it might provide structures relevant to the explanation of \nbehavioural sequences.   \nIn conclusion, the formal structure developed by Shaw & Turvey (1981) does not do \njustice to the issues raised by the philosophical analysis in the earlier part of the paper.  The \ncoalition does not prevent the possibility of an explanatory regress and it does not \ndemonstrate either that there are substantive dualities at the different grains described or that \nthe concept of a duality is the most appropriate way of modelling the reciprocity of relations \nbetween animals and their environments.   \nTurvey\u2019s analysis of affordances and prospective control. \nTurvey (1992) discussed the concept of affordance and its theoretical development in \nthe context of the prospective control of animal activity.  Prospective control is concerned \nwith future actions such as the attainment of goals.  Turvey suggested that affordances for \nactions are fundamental and that understanding them provides the foundation on which other \ntypes of affordances might be based.  It is not obvious how Turvey\u2019s work on prospective \ncontrol should be related to coalitions.  Both build on the analysis of mutual compatibility \nundertaken by Turvey & Shaw (1979) and Turvey retains the idea that the relationship \nbetween an animal and its environment can be described as a duality, but his formal analysis \n  \nGibson\u2019s affordances    22 \nis different from that of Shaw & Turvey (1981) and is treated here as a distinct line of \ntheoretical development. \nTurvey set out to establish that possibilities for action constitute an ontological rather \nthan an epistemological category.  His analysis supports the direct realism which is \ncharacteristic of ecological psychology. Turvey began his paper by offering a picture of \necological ontology as materialist and dynamicist but not reductionist, thus allowing for real \nthings to exist at a variety of physical scales.  He then characterised properties from the \necological standpoint.  He distinguished formal properties from substantive properties, the \nlatter being the main object of his exegesis.  Substantive properties, he says, are to be \ndistinguished from attributes.  Attributes are epistemological entities whereas properties are \nontological entities.  Properties may be intrinsic, that is inherent to individual things, or they \nmay be mutual, that is  properties of pairs or n-tuples of individuals.  Solubility is an example \nTurvey gave of a mutual substantive property.  Intrinsic and mutual substantive properties are \nequally real. \n Turvey characterised affordances as substantive properties rather than as attributes.  \nThis establishes their ecological reality and makes them independent of the epistemological \nor perceptual state of the agent in a way which makes the analysis consistent with Gibson\u2019s \nclaim that affordances exist independently of the observer. Turvey also discussed the status of \npossibility.  This was done in terms of a brief discussion of laws and how they are to be \nidentified at the ecological scale.  A much fuller discussion of ecological laws and the \nimportant question of whether laws must be exceptionless can be found in Turvey et al. \n(1981).  Turvey defined a law as \u201can invariant relation between or among substantial \nproperties of things.\u201d Turvey (1992, p.177).  He then argued that laws prescribe what can \nhappen but not what must necessarily happen at a particular time.  Actual occurrences depend \non circumstances as well as on laws.  Turvey then identified real possibility with lawfulness \n  \nGibson\u2019s affordances    23 \nrather than with lawfulness plus circumstances.  This allows for exceptions and shows, if his \narguments are sound, that although an affordance may or may not be actualised on a given \noccasion, it is nonetheless a real possibility that embodies an ecological law and not one that \nis dependent on the current conceptualisation of an agent.  Thus the fact that an agent eats an \napple rather than using it as a missile leaves open the real possibility that apples afford \nthrowing as well as nourishment.   \n Turvey argued that to understand how affordances embody laws it is necessary to \nconsider real possibility in dispositional terms.  He suggested that dispositional properties are \nfundamental to affordances and that they have three key characteristics; dispositions precede \nactivity, they come in pairs whose members complement each other, and they are always \nactualised in suitable circumstances.   \n In the light of his analysis of properties, laws, possibility and dispositions Turvey \noffered a tri-partite characterisation of affordances.  They are real possibilities, they are \ndispositions and they are complemented by effectivities.  Thus, \u201cAn affordance is a particular \nkind of disposition, one whose complement is a dispositional property of an organism.\u201d \nTurvey (1992, p.179).  Turvey provided a more formal characterisation of affordances that \nmakes his commitments precise. This was done in terms of what he called a \u201cjoining\u201d or \n\u201cjuxtaposition\u201d function.  The juxtaposition function is analogous to the formal dualities of \nShaw & Turvey (1981) but is quite different in detail.  Consider an entity X with dispositional \nproperty p and an entity Z with dispositional property q.  Wpq = j(Xp, Zq) is the unit formed by \nX and Z being conjoined in an appropriate way such that a third property r is made manifest.  \nr is a mutal or relational property of the second order unit Wpq.  Turvey gave the example of a \nprism that refracts light. Refractibility is a dispositional property of light, refraction is a \ndispositional property of a prism, and when a prism and light are brought together in \nappropriate circumstances, as in Newton\u2019s famous demonstration of the spectrum of visible \n  \nGibson\u2019s affordances    24 \nwavelengths for example, they yield \u201ca light-bending-in-prism system\u201d Turvey (1992, p.179).  \nWhat is not clear from Turvey\u2019s example is whether the manifest property r should in this \ncase be identified with the bending of the light or with the manifestation of the rainbow hues \nof the spectrum.  It might, in fact, be better to think of r as a member of a set R of properties, \nbecause there is no reason in principle why the juxtaposition of the entities X and Z should \nlead to only one manifest property.  Turvey applied the ideas of a system Wpq formed by \njuxtaposition and a new property r to define both affordances and effectivities.  If X is an \nentity with property p, Z is an entity with property q, and Wpq is the juxtaposition of X and Z, \nthen p is an affordance of X and q is an effectivity of Z, if and only if there is a third property \nr such that three conditions hold; \nC1. Wpq = j(Xp, Zq) possesses r \nC2. Wpq = j(Xp, Zq) possesses neither p nor q \nC3. Neither Z nor X possesses r \nThis definition ties affordances and effectivities together.  It stipulates that affordances and \neffectivities exist if and only if there is a transformation of the properties p and q of X and Z \nto the property r of Wpq.  This formal definition cannot be right because it is too restrictive.  \nC2 rules out many of Gibson\u2019s examples of affordances.  Turvey\u2019s paper gives only one \nexample of C2.  \u201cThe disposition p of salt to be soluble rests with the fact that it is a lattice of \nelectrically charged ions bound by an electrical attraction between opposite charges\u2026The \nsalt-dissolved-in-water system lacks the attraction between ions; it does not possess p.\u201d \nTurvey (1992, p.181).  C2 works in this instance but there are many others where it does not.  \nConsider the affordance of grasping again.  \u201cTo be graspable, an object must have opposite \nsurfaces separated by a distance less than the span of the hand.\u201d  Gibson (1979, p.133). Using \nTurvey\u2019s formalism, a person who perceives the affordance of grasping is X.  The property p \nof X is their hand-span, which is k units measured in some appropriate scale.  Z is the object \n  \nGibson\u2019s affordances    25 \nthat affords grasping, and q is the property that Z has opposite surfaces less than k units apart.  \nWpq is the hand-grasping-object system.  C2 requires that Z affords grasping and X effects \ngrasping if and only if Wpq, the actualised hand-grasping-object system, possesses neither p \nnor q.  This cannot be correct.  A hand-span is not changed by the act of grasping, nor, in \ngeneral, is the distance between opposite surfaces of an object changed when it is grasped.  A \nsimilar objection can be made with respect to many other affordances.  Cups do not lose the \nproperties that afford drinking when we use them for that purpose, nor do agents lose the \nproperties that afford social life when they interact with each other.  It is so obvious that C2 is \ntoo strong that one might wonder why it was included. C1 and C3 seem sufficient to bind \naffordances and effectivities together.   \nGreeno\u2019s analysis of affordances. \nGreeno (1994) discussed affordances in a paper which draws on situation theory, \n(Barwise & Perry, 1983; Barwise, 1989; Devlin, 1991).  Greeno makes the fundamental point \nthat \u201cIn any interaction involving an agent with some other system, conditions that enable \nthat interaction include some properties of the agent along with some properties of the other \nsystem.\u201d  Greeno (1994, p.338).  He characterises affordances as the relevant properties of \nthe environment in agent-environment interactions and uses the term \u201cability\u201d to describe the \ncontribution of the agent.  Greeno\u2019s emphasis on the study of conditions that enable \ninteractions between animals and their environments shows that his analysis tackles some of \nthe issues that Shaw & Turvey (1981) were engaging with when they described grains of \nanalysis as contexts of constraint. \n Greeno suggests, citing the work of Warren & Whang (1987), that the most \nproductive empirical work on affordances has treated them as graded properties.  A graded \nproperty, in Greeno\u2019s terms, is one that admits of degrees of presence.  Loudness is an \nexample.  A sound can vary continuously from a scarcely perceptible whisper to a painful \n  \nGibson\u2019s affordances    26 \nroar.  Greeno also suggests that the use of different formal systems can promote the \ndevelopment of theoretical perspectives and proposes that situation theory provides a natural \nway to treat affordances.  Linking ecological psychology and situation theory is a promising \nstrategy.  It seems particularly apposite in the context of Gibson\u2019s proposal that affordances \nprovide a new theory of meaning, because situation semantics is committed to a form of \nrealism that fits well with Gibson\u2019s thinking.  Barwise (1989, p.51) says that situation \nsemantics is committed to the claim that \u201cmeaning does not reside in the head or in some \nmysterious realm but in the interaction of real, living things and their actual environment.\u201d   \nGreeno\u2019s specific proposal is that affordances and abilities can be characterised as \nconditional constraints as these are understood in situation theory.  This proposal is less \nconvincing than the general case for thinking about ecological psychology in situation \ntheoretic terms as an analysis of the core terms shows.  A football match is a situation and so \nis a marriage.  We speak of facing threatening situations, such as becoming unemployed or \nfalling ill, or experiencing a change in our situation as a result of winning a lottery or \nreceiving an inheritance.   What counts as a situation for an individual depends on their \nscheme of individuation that is on how they understand the world.  Roughly speaking, a \nsituation is a structured part of the world that an agent treats as an entity and that has \nparticular relations to behavior.  Individual situations belong to one or another situation type.  \nTwo football matches belong to the same type even though the players may be different, the \nresults may be different and the locations and times of play are different.  Situations belong to \nthe same type by virtue of sharing aspects of structure such as a set of rules, a causal \nsequence or common perceptual elements.  A situation type is a class of situations with one \nor more specific relational properties.  Some types are systematically related to other types.  \nIn Association Football, the type of situation called a \u201cwin\u201d is systematically related to the \ntypes of situations describing the number of goals scored by each side.  Side A wins a match \n  \nGibson\u2019s affordances    27 \nagainst side B if and only if it scores more goals than side B.  The dependencies that exist \nbetween situation types are called constraints, and it is constraints that make situations \nmeaningful.  The constraints that determine what counts as winning a football match are \nconventional, but there can also be natural, causal constraints between situation types.  A \ncommon example is enshrined in the saying \u201cThere\u2019s no smoke without fire.\u201d  The saying \nimplies the existence of the constraint that all situations of the type where smoke is present \nare also situations of the type where fire is present.   \nMany, perhaps most, constraints do not hold absolutely but are conditional upon \nbackground circumstances.  Barwise (1989) gives an example involving his daughter Claire.  \nWhen she was very small Claire rubbed her eyes when she was sleepy but not otherwise.  As \na result Barwise and his wife came to believe that all the situations in which Claire rubbed \nher eyes meant that she was sleepy.  They believed that there was a systematic relation or \nconstraint between the type of situation described by \u201cClaire rubs her eyes\u201d and the type \ndescribed by \u201cClaire is sleepy\u201d such as to justify the inference \u201cIf Claire rubs her eyes, she is \nsleepy\u201d.  Thus they believed that Claire\u2019s rubbing her eyes meant that she was sleepy.  In due \ncourse, however, it became obvious that Claire was also rubbing her eyes at times when she \nwas not sleepy and the Barwises concluded that she was suffering from an allergy.  This \nmeant that \u201cIf Claire rubs her eyes, she is sleepy\u201d no longer held without exception but only \nin cases where the allergen was not present.  Thus the constraint was conditional on the \nabsence of the allergen.   \nA conditional constraint, therefore, is one that holds relative to certain background \nconditions, which may be positive or negative, and Greeno\u2019s analysis identifies affordances \nand abilities as those background conditions under which constraints do, in fact, hold.  The \nattraction of this idea is that it gives a clear sense of the relational nature of affordances and \nGreeno discusses a number of examples including using a doorway to enter a room and \n  \nGibson\u2019s affordances    28 \nchanging the direction of a car by moving the steering wheel.  One might also consider \nGibson\u2019s characterisation of a surface of support.  \u201cIf a terrestrial surface is nearly horizontal \n(instead of slanted), nearly flat (instead of convex or concave), and sufficiently extended \n(relative to the size of the animal) and if its substance is rigid (relative to the weight of the \nanimal), then the surface affords support.\u201d Gibson (1979, p.127).  In situation theoretic terms, \na constraint exists between situations involving horizontal, flat, extended, rigid surfaces and \nsituations involving the support of animals when appropriate background conditions link the \nextension and rigidity of the surface to the size and weight of the animal.   \nThe principal problem with Greeno\u2019s idea is that it runs counter to two of Gibson\u2019s \nideas, that affordances are meanings and that some of them are directly perceptible.  Consider \nagain the case of baby Claire Barwise.  It seems natural and in keeping with Gibson\u2019s \nintentions to suppose that it was Claire\u2019s rubbing her eyes that afforded the inference that she \nwas sleepy.  This identifies the affordance with the constraint rather than with the conditions \nunder which it holds and is compatible both with the affordance being a meaning and with it \nbeing directly perceptible.  That is not what Greeno\u2019s proposal suggests.  Greeno\u2019s proposal \nsuggests that the affordance should be thought of as the absence of the allergen since that was \nthe condition under which the constraint held.  But the absence of the allergen is neither \ndirectly perceptible nor a meaning.  It is certainly true that if conditions fail then affordances \nfail, but conditionality is probably better used as an explanation for the misperception of \naffordances than as a characterisation of them. \nIt seems, therefore, that it would be better to think of affordances as constraints \nlinking situation types rather than as the conditions under which constraints hold.  Even then, \nit is not clear that the analysis works quite as required because the concept of a constraint is \nbroader than the concept of an affordance.  Constraints are relations between situation types \nand these can be of many kinds whereas affordances are quite specifically relations between \n  \nGibson\u2019s affordances    29 \nan animal and its environment.  Thus affordances would have to be specified as particular \nclasses of constraints, namely those involving agents.  Greeno was right to draw attention to \nsituation theory as a source of ideas for the formal development of Gibson\u2019s principal \necological concepts but the specific analysis he proposes needs to be reconsidered. \nTuring machine theory. \nThe key feature of an affordance is that it is something \u201cthat refers to both the \nenvironment and the animal\u2026It implies the complementarity of the animal and the \nenvironment.\u201d  Gibson (1979, p.127). This feature must be captured in an adequate formal \ntreatment of affordances. Shaw, Turvey and Greeno treat the term \u201caffordance\u201d as having a \npurely environmental reference and use the terms \u201ceffectivity\u201d and \u201cability\u201d to refer to the \nanimal\u2019s contribution to action.  The environmental and animal components have then to be \nbound together in a way that demonstrates their complementarity.  Shaw and Turvey (1981) \nuse dualities for this purpose, Turvey (1992) uses the juxtaposition function and Greeno \n(1994) proposes that both affordances and abilities are conditional constraints on successful \nperformance of an action.   \nThe treatment of affordances in purely environmental terms rests on Gibson\u2019s emphasis \non the physical reality of affordances and their independence from the observer\u2019s perception. \nHowever, he also wrote passages in which the distinction between the environment and the \nanimal is much less clear.  In a classic example, Gibson (1979, p.129, he says: \nBut, actually, an affordance is neither an objective property nor a subjective property; or \nit is both if you like.  An affordance cuts across the dichotomy of subjective-objective and \nhelps us to understand its inadequacy.  It is equally a fact of the environment and a fact of \nbehavior.  It is both physical and psychical, yet neither.  An affordance points both ways, \nto the environment and to the observer.  \n  \nGibson\u2019s affordances    30 \nThis suggests that the term \u201caffordance\u201d was intended to make reference to the animal and to \nthe environment in a way which is not quite caught by either Greeno\u2019s or Turvey\u2019s analysis.  \nThe challenge, then, is to find a way to characterize affordances which can do justice to \nGibson\u2019s complex intuitions in a clear and productive fashion.  The proposal advanced here is \nthat a treatment of affordances and effectivities in terms of the theory of Turing machines \ncaptures the essence of these concepts in a profound and illuminating way.   \nTuring\u2019s analysis of computation. \nAlan Turing was a British mathematician who developed the concept of the abstract \ncomputing machine that now bears his name.  In a famous paper, Turing (1936-7), he \nanalysed the processes involved in the calculation of a number using pencil and paper.  His \ninvestigation was intended to include all numbers that could be calculated using a finitely \nspecified rule.  Thus it included mundane numbers like those that result from adding up the \nprices of items in an invoice and more exotic numbers like \u03c0, whose full representation \ninvolves an infinite number of digits.  Turing\u2019s analysis was an ecological one for at least the \nfollowing two reasons.  First, its fundamental objects, people who calculate and the numerals \nthey write on paper, are defined at the ecological scale, Gibson (1979, p.9).  Second, the \nanalysis formalized the operations of a relational system consisting of an agent who reads and \nwrites symbols using the structured environment of paper ruled into squares.   The system as \na whole carries out numerical computations.  The analysis was not concerned with purely \nmental arithmetic, although it makes reference to the internal states of the person calculating.  \nThe paper and pencil are essential parts of the system and cannot be dispensed with.   \nTuring\u2019s paper was concerned with foundational issues in mathematical logic which \ngo beyond the scope of the present paper.   However, his investigation explored the \nfundamental notion of a definite method in mathematics and this aspect of his work is \ndirectly relevant here.  It is clear that a definite method must be finitely specifiable.  To this \n  \nGibson\u2019s affordances    31 \nTuring added the insight that it was in the nature of a definite method that it could be applied \nmechanically.  Informally, this might mean no more than the fact that an over-learned method \ncan be applied without thought.  But Turing took the idea a step further and argued that if a \nmethod really was definite, then a machine could, at least in principle, be designed to carry it \nout.  He therefore considered what processes a human, working with pencil and paper, might \npossibly use in calculating a number according to a finitely specified rule with a view to \nbuilding a machine to perform such calculations.  The outcome of Turing\u2019s analysis was a \nclass of abstract machines, now called Turing machines.  Every Turing machine has \ncomponents modelling the agent and components modelling the external environment.  These \ncomponents can be used to model affordances and effectivities in the following way. \nAn affordance A is defined as an ordered pair (q,a) in which q is an animal referential \nterm and a is an environment referential term.  A represents a situation in which an animal in \nfunctional state q perceives an entity a.  In Turing machine theory pairs of this kind are called \n\u201cconfigurations\u201d.5  An effectivity E is defined as an ordered triple (b,p,k) in which b is an \nenvironment referential term, p is an animal referential term, and k refers to both because it \nrepresents a movement of the animal relative to the environment.  E represents a situation in \nwhich the animal carries out behavior b, changes its functional state to p and moves in \ndirection k.  In Turing machine theory, triples of this kind are called \u201cactions\u201d.  \nConfigurations and actions are combined in \u201cinstructions\u201d.  A Turing machine instruction has \nthe form (A,E) = ((q,a),(b,p,k)).  (A,E) represents a situation in which an animal perceives the \naffordance A and effects the behaviors in E.  It is helpful to think of instructions as the \narguments and values of a function \u03c6 that maps affordances onto effectivities.   A set of \ninstructions constitutes the \u201cmachine table\u201d for a Turing machine.  It specifies all the \nconfigurations and associated actions which define the machine.  When configurations and \nactions are used as models of affordances and effectivities the machine table specifies a set of \n  \nGibson\u2019s affordances    32 \naffordances and their associated effectivities.  Thus, in Gibson\u2019s terms, a machine table \nspecifies a niche. The complementarity between animal and environment is captured in the \nway that the set of instructions relating affordances to effectivities specifies the way that the \nanimal behaves.  Turing machines have both structure and dynamics and are thus capable of \nproviding models of the animal, the environment and behavior. \nIn the brief description above, there are animal referential and environment referential \nterms.  These need further explanation.  An affordance is defined as an ordered pair (q,a).  q \nis a member of a finite set Q which enumerates the functional states of an animal.  In \nTuring\u2019s original work, the members of Q were formal analogs of the \u201cstates of mind\u201d of a \nhuman computer but the restriction to states of mind is not an essential part of the definition.  \nQ is a finite set of functional states of an animal, which may include functional states other \nthan states of mind.  It was an important part of the definition of the Turing machine that the \nstate set was finite, and this is carried over into the current context.  However, Turing\u2019s work \nwas entirely non-committal about how the functional states might be instantiated in any \nparticular case.  The formal scheme simply specifies the relations among states and between \nstates and their inputs and outputs.  It was important in Turing\u2019s theory that a machine could, \nin principle, be built to realise the abstractly defined set of functional states but no constraints \nwere imposed on their realisation.  There is, in particular, no requirement that the functional \nstates are, or contain, symbolic representations of the external environment of the kind \nproposed by conventional computational theories of mind.  The other term a in (q, a) is a \nmember of a finite set S of types of entity in the environment.  In Turing\u2019s original work, S \nwas a set of symbol types, including letters, digits and punctuation marks.  This is because \nTuring was specifically concerned with the computation of numbers.  There is no reason why \nother types of entity cannot also be modelled by the formal scheme.  \n  \nGibson\u2019s affordances    33 \nThe core features of the formal specification of an affordance as a configuration (q, a) \nof a Turing machine are that the sets Q and S from which q and a are drawn are finite sets, \nthat Q is a set of functional states of an animal and that S is a set of entities in the \nenvironment of the animal.  The particular interpretations that the sets Q and S were given in \nTuring\u2019s original work reflect his specific focus on numerical computation rather than an \nintrinsic limitation of the model.  It is, however, an intrinsic part of the model that the sets Q \nand S are finite.  This means that the set of affordances, which is a binary relation on Q x S, is \nalso finite.6  Similar points can be made about effectivities.   \nThe formal scheme for an effectivity E = (b,p,k) contains three terms.  p \u03b5 Q and b \u03b5 S \nare members of the same sets as the components of affordances just discussed.  k represents a \nmovement of the animal in its environment.  In Turing\u2019s original work, the environment was \na one-dimensional paper tape divided into squares.  As a result, only three distinct types of \nmovement were possible, movements left, movements right and no movements.  The highly \nrestricted nature of the original Turing machine environment was a consequence of Turing\u2019s \nparticular interest in numerical computation and is not an intrinsic feature of the formalism.  \nIt is possible in principle to extend the set M of movements to include elements like \u201csit\u201d, \nstand\u201d, \u201cgrasp\u201d and so forth.  In practice, of course, as the history of attempts to build mobile \nrobots shows, it is difficult to realise a formal scheme containing such movements.  The key \nrestriction on M is like those on Q and S, namely that the set M has a finite number of \nelements.   \nAn example Turing machine. \nThis section fleshes out the introduction above with a detailed description of a \nmachine which Turing used to illustrate his theory.  Consider the activity of writing out the \nsequence of numbers 0,1,2,\u2026 Without the punctuation it is equivalent to a single number \nwith digits 012\u2026 We can therefore talk equivalently about a sequence of numbers or a \n  \nGibson\u2019s affordances    34 \nsequence of digits.  The base of the number sequence is also irrelevant to the formal nature of \nthe task.  Turing used a unary form of representation where 1 is represented by 1, 2 by 11, 3 \nby 111 etc.  The symbol 0 is used to represent the number zero and as punctuation.  Thus the \nsequence 0, 01, 011, \u2026 is equivalent in unary representation to the sequence 0, 1, 2, \u2026 \nAlthough the sequence is infinite the task of writing it out is real and Turing\u2019s abstract \nspecification was for a machine that might, in principle, be built.   \nTo make the situation concrete, imagine an unfortunate life prisoner who has been \nsentenced to the task of writing out on a paper tape (a portion of) the infinite sequence of \ndigits produced by Turing\u2019s machine.  The hapless prisoner is locked in a cell seated at a \ntable with the start of the tape in front of him and the unmarked tape heaped on the floor to \nthe right.  He writes 0 on the first square, 0 on the second, 1 on the third and so on.  As he \nworks, he moves the tape from right to left to bring fresh unmarked squares into place under \nhis pencil, and the portion of tape he has written on grows steadily on the floor to the left of \nthe table.  The pencil he uses is modelled in the Turing machine by the abstract process of \nprinting a symbol.  The requirement for an indefinite quantity of paper is met by requiring the \ntape to be unbounded in the sense that more can be added when needed.  The unboundedness \nof the tape is a general feature of Turing machines. \nThe internal states of the prisoner are modelled as a finite set of functional states.  The \nmodel does not include his unhappiness, boredom, resentment or any of the other things he \nmight well be feeling.  It is concerned solely with the functional states needed for him to \ncarry out the task at hand.  The issue of finiteness of memory is important.  At the start of the \ntask, the prisoner will be able to remember where he has got to, and will be able to count out \nthe digits of the current number from memory.  But as the numbers increase in size, there will \ncome a point at which he will no longer be able to do this because the numbers will be bigger \nthan his memory can cope with.  However, there is a way to manage the task which shifts the \n  \nGibson\u2019s affordances    35 \nburden of representation from the prisoner to the environment.  The representation of each \nnumber is one digit longer than its predecessor.  The next number in the sequence can, \ntherefore, be written out by copying the previous number and writing an additional 1 at the \nend.  If each digit is marked off as it is copied, the load on the memory of the prisoner is \nconstant.  He trades load on his memory for book keeping using the tape.   \n The task of writing out the sequence 0010110111\u2026 can be performed by a Turing \nmachine with four internal states.  The precise details given here are slightly different from \nthe way that Turing defined the machine but the way it works is essentially the same.  A \nmachine table for the machine HP, which simulates the hapless prisoner, is shown in Table 1. \nTABLE 1 ABOUT HERE \nHP is thought of as a black box equipped with perceptual and motor systems.  Its \nperceptual systems allow it to scan a single square of the tape at a given time and to recognize \nthat it is blank or that it contains one of the symbols indicated in Table 1.  This square is \ncalled the \u201cscanned\u201d square. HP\u2019s motor systems allow it to erase the symbol on the scanned \nsquare, to print a symbol and to move one square to the left or right so as to change the \nscanned square.  The environment external to HP consists of a one-dimensional tape divided \ninto squares as discussed above.  Time for HP is divided into a series of discrete moments, t0, \nt1, \u2026,  tn which are such that exactly one instruction is carried out in each moment.   The key \nnotion is succession rather than duration; tk follows tj if and only if k > j.  This does not rule \nout the possibility of incorporating a more realistic treatment of time into an extended formal \nmodel. \nHP is started in functional state q1 scanning the leftmost square of the blank tape.  \nThe time is t0.  At this point HP is simulating the hapless prisoner at the start of his sentence.  \nIn Table 2, the first twenty eight steps in the infinite sequence of HP\u2019s operations are shown.   \nTABLE 2 ABOUT HERE \n  \nGibson\u2019s affordances    36 \nEvery step of the machine\u2019s operations involves both its current functional state and \nits environment.  At each step the environment, i.e. the tape, is perceived to read the symbol \non the scanned square and is acted upon by printing and moving.7  There is no notion of \ninternal processing independently of the environment.  Second, information is stored by \nacting on the environment not by modifying the functional states of the machine. \nNevertheless there is a clear need for different functional states to manage the fact that a \ngiven input requires different actions at different times.  The # symbol, for example, is part of \nfour affordances each with a different effectivity.   \n The processing of the machine follows the outline suggested for the hapless prisoner.  \nThe sequence 001011011101111\u2026is treated as a sequence of overlapping segments.  Each \nsegment is bounded by zeroes which are separated by 0, 1, 2, \u2026 ones.  Thus the first three \nsegments are 00, 010, 0110.  All the zeroes except the first are printed by state q2.  The first \nis printed by state q1 in an action that is unique because the configuration (q1, #) that causes \nit happens once only at time t0.  The need for this unique action can be appreciated by \nconsidering what would happen if the machine were started in state q2 rather than state q1 at \ntime t0.  It would print a 0 on the first square and then try to move left which would not be \npossible because the machine at t0 is on the leftmost square of the tape.8  State q1 starts the \nmachine at time t0 with an action that simulates the writing of the first of an endless sequence \nof digits by the hapless prisoner.  At time t1 HP prints the second 0 on the tape.  This is both \nthe closing 0 of the first segment 00 and the opening 0 of the second segment 010.  Having \nprinted a 0 HP moves leftwards exploring the segment just completed to detect any 1s it \ncontains.  If a 1 is found a transition is made to functional state q3 which copies the 1 to the \nnext segment.  If a 1 is not found the transition is to q4 which adds an extra 1 to the new \nsegment. At time t2 there are no 1s on the tape because the first segment is 00 so a transition \nis made to functional state q4 whose effectivities move HP to the right until a blank square is \n  \nGibson\u2019s affordances    37 \nencountered at t4.  The affordance (q4, #) is associated with the effectivity (1, q2, R) which \ncauses a 1 to be printed on the blank square, moves HP one square right and makes a \ntransition to functional state q2 to begin a new segment.  The current segment is now 010 \nwhich contains a 1.  This is perceived by the affordance (q2, 1) at t6.  The effectivity (X, q3, \nR) replaces the 1 with an X to prevent its being counted an infinite number of times and \nmakes a transition to functional state q3.  The affordances involving q3 have the single \nfunction of copying 1s to the new segment.  This is achieved by moving HP rightwards until \na blank square is found on which a 1 can be printed.  This happens at t8 and a transition is \nmade to functional state q1.  The affordance (q1, 0) at t9 leads immediately to a transition to \nq2. It is not immediately obvious why the transition is made indirectly from q3 via q1 to q2 \nrather than directly from q3 to q2.  The reason for this does not become clear until t27.  At t26, \nHP has just copied a second 1 to the new segment.  If a transition were made to q2 at this \npoint it would misinterpret the 1 scanned at t27 and treat it as one to be copied rather than as \npart of the new segment.  So state q1 is used to reposition HP at the 0 separating the two \ncurrent segments.  This illustrates a fundamental point about Turing machines such as HP.  A \ngiven functional state can have only one set of actions defined for each symbol it can \nrecognize.  If this were not so, if for example two different sets of actions were defined for a \ngiven input symbol, a decision would have to be made about which of these was to be carried \nout.  This would not be a simple operation in Turing\u2019s terms and it is not clear how the \ndecision process would be mechanized.9  From t9 to t11 q2 continues to check the segment \n0X0 for further 1s.  No more are found so a transition is made to q4 to append the final 1 to \nthe segment under construction.  The effectivities associated with q4 also tidy up the tape as \nHP moves rightward by changing any Xs back to 1s.  The segment is completed at t15 and a \ntransition is made to q2 to begin a fresh cycle at t16. \n  \nGibson\u2019s affordances    38 \n One important aspect of the structure of HP that is not clearly visible either in the \nmachine table or in the trace of HP\u2019s processing in Table 2 is the way the functional states are \nrelated to each other by patterns of transition.  This information is contained in the machine \ntable but it is much more clearly visible in a state transition diagram.  A state transition \ndiagram for HP is shown in Figure 1. \nFIGURE 1 ABOUT HERE \nTo summarize, HP is a deterministic Turing machine with four functional states q1, \nq2, q3, q4 which prints the infinite sequence 0010110111\u2026 HP is a formal model of the \nhapless prisoner endlessly writing out numbers in his prison cell.  It is clear from the analysis \nthat even a simple system like HP with just four functional states and an alphabet of four \nsymbols can give rise to complex, structured behavior.   That behavior is determined by the \ninteractions between the machine and its environment as specified by its affordances and \neffectivities.   \nConfigurations and Affordances \n HP has fifteen affordances, i.e. its fifteen configurations.  The parallels between \naffordances and configurations are both striking and informative but they have not previously \nbeen widely discussed because ideas derived from Turing machines have typically been used \nin cognitive science exclusively to characterise functional organisation inside the head of the \nperceiver.   In such cases, the tape is treated as a model of memory and the finite state control \nas a model of executive processes.  In fact, however, the Turing machine was developed as a \nmodel of the relation between a person and the external environment and not as a model of \nthe mind divorced from the environment.  When used to support a relational approach, as it is \nin this paper, the Turing machine model serves as a critique of computational cognitive \nscience and supports the philosophical foundations of ecological psychology.  \nConfigurations model ecological concepts. \n  \nGibson\u2019s affordances    39 \nThe configurations of Turing machines are models of ecological entities because the \nconcepts of internal state and symbol formalize aspects of the ontology of everyday life that \nare found at the scale of human behavioral ecology.  The states and symbols of HP are \nmodels of the functional states of the hapless prisoner and his activities with paper and pencil.  \nConfigurations are also ecological models because they are concerned with the reciprocal \nnature of states and symbols and because they are concerned with the perceptions and actions \nof a control system which is unfettered with respect to its (admittedly limited) environment. \nConfigurations are relational. \nAffordances point two ways, to the agent and to the environment.  So do the \nconfigurations of Turing machines.  Each configuration of HP refers to one of its internal \nstates and to the contents of a square of its tape.  Moreover, the formalisation of affordances \nas configurations also respects the relation of asymmetric inter-dependence between agents \nand environments.  Interdependence is asymmetric because Gibson saw the environment as \nprior to animals and as the source of perceptual information for animals.  The tape is the \nsource of perceptual information for a Turing machine.  There is information of a kind in \ninternal states but a Turing machine depends on its tape for the information with which it \ncomputes.  That is true even for a machine like HP which is started on a blank tape.  Turing \nmachines are provably more powerful than other classes of abstract machines precisely \nbecause they are systematically connected to an unbounded environment that is accessed at \neach step of their operations.  Gibson\u2019s argument for the priority of the environment, which \nwas based on evolutionary considerations, does not have an exact counterpart in Turing \nmachine theory.  It is worth noting, however, that if the environment were changed, by \nspecifying a two-dimensional tape for example, the structure of internal states would also \nhave to change. \n  \nGibson\u2019s affordances    40 \n The relational nature of affordances also emphasizes the mutuality of animal and \nenvironment.  This point is strongly illustrated in the configurations of Turing machines.  HP \nhas the configurations that it has in order to be able to process a tape which is organised in \nthe way that it is, and the sequence of symbols on the tape has the characteristics that it does \nbecause the internal states of HP are organised as they are. \n One point where the analysis of affordances as configurations differs from Gibson is \nin making specific reference to properties of the agent.  Although Gibson made explicit \nreferences to properties of substances and surfaces in the definition of affordances he referred \nto these as being taken \u201cwith reference to an animal\u201d Gibson (1977, p.67) rather than with \nreferences to properties of an animal.  This was done in order to avoid making affordances \ndepend on the subjective experience of the agent.  Gibson was quite explicit about this; \n\u201c\u2026affordances are properties of things taken with reference to an observer but not properties \nof the experiences of the observer.  They are not subjective values; they are not feelings of \npleasure or pain added to neutral perceptions.\u201d  Gibson (1979, p.137).  The difficulty with \nthis is that it makes it hard to understand what reference to an animal can mean particularly \nwhen it is acknowledged that affordances are related \u201cto the motives and needs of an \nobserver\u201d Gibson (1979, p.143).  The analysis of affordances as configurations helps to \nclarify this difficult area.  Configurations include both properties of the environment and \nproperties of the agent, but the properties of the agent do not make configurations into \nsubjective phenomena, nor do they necessarily make reference to the experiences of the \nobserver.  Configurations preserve the objectivity of affordances because the set S from \nwhich the sj are drawn is a set of environmental entities.  Configurations are also independent \nof the subjective experiences of the observer because internal states are functionally defined.  \nIt might happen that the instantiation of an internal state was such as to generate a subjective \n  \nGibson\u2019s affordances    41 \nexperience but such experience is not constitutive of the internal state components of \nconfigurations.   \nConfigurations are facts of the environment and facts of behavior. \nThe treatment of affordances as configurations makes it very clear how they can \u201ccut \nacross the dichotomy of subjective-objective\u201d Gibson (1979, p.129).  Consider, for example, \nthe configuration (q2, #) of HP.  It is a fact of the environment because it occurs at particular \ntimes and places and with respect to particular squares on the tape.  Table 2 shows that it \noccurs at times t1, t5 and t16 and, like every other configuration except (q1, #), infinitely often \nthereafter.  It is also linked to behavior because it is associated with the effectivity (0, q2, L).  \nSimilar remarks can be made about each of the other configurations of HP.  It is also clear \nthat the internal state components of configurations function in a way that is consistent with \nwhat Gibson wrote about perceptual systems. Internal states, considered as parts of the \nfunctional apparatus of Turing machines, are active ways of paying attention to what is going \non in the environment.  This is particularly clear when we consider that different \nconfigurations become salient as a Turing machine moves around its tape in the course of a \ncomputation.  Locomotion through the medium is a fundamental activity for animals.  \nLocomotion across its tape is a fundamental activity for a Turing machine.  Configurations \nshow that systematic behavior depends on structure that exists both in the environment and in \nthe agent.  Behavior is derived from both of these sources of structure, but to say this is not to \nsay that there is anything like an explicit model of the environment inside the black box of \nthe Turing machine.  There isn\u2019t.  It isn\u2019t needed because the environment provides sufficient \ninformation.  The structure in the black box is there to ensure that the appropriate behavior is \ncarried out at the right places in the environment.  Indeed one can think about what \nattunement to the environment might mean in ecological theory by considering the ways in \nwhich configurations mesh structure in the environment with structure in the agent to produce \n  \nGibson\u2019s affordances    42 \nbehavior.   The Turing machine approach to configurations suggests, therefore, a slightly \ndifferent thesis than Gibson\u2019s.  It suggests not that affordances are facts of the environment \nand facts of behavior, but that they are facts of the environment and of the agent that are \ndeterminately linked to behavior via effectivities.  The configurations of Turing machines are \ncausally associated with their behavior but are conceptually distinct from the behavior that \nthey cause. \nA final issue concerns the nature of the links between affordances and behavior.  HP \nshows that the links can be complex.  A Turing machine configuration has two components, \nan action has three. Configurations are defined in terms of pairs of internal states and \nsymbols.  Since HP has four states and four symbols, sixteen configurations could be defined \nof which fifteen are actually used.  By the same logic there are thirty-two definable actions \nfor HP (4 states x 4 symbols x 2 movements).  No more than fifteen of these could actually be \nused because a configuration cannot have more than one action associated with it.  In fact, HP \nuses only ten distinct actions.  This means that different configurations share the same \nactions.  This theoretical fact leads to an empirical question.  Would the general expectation \nbe that animals have fewer effectivities than affordances?  It is plausible to think so.  Many \nthings, for instance, afford eating but eating is a single type of activity.  Similar \nconsiderations apply to other activities like throwing and grasping.   \nSets of configurations constitute niches. \nWhen affordances are treated as the configurations of Turing machines, Gibson\u2019s idea \nthat sets of affordances constitute niches comes into sharp focus.  There are three main \ncomponents to the niche concept; it specifies the way of life of an animal, i.e. how it lives \nrather than where it lives, it suggests that sets of affordances have a certain unity or \ncoherence and it suggests that different animals that share aspects of their ways of life have \naffordances in common.  The set of configurations of a Turing machine certainly specifies \n  \nGibson\u2019s affordances    43 \nhow it functions rather than where it functions.  The tape is where it functions and this is the \nformal equivalent of the habitat of an animal.  But it seems insufficient to call the set of \nconfigurations of a Turing machine a niche, because that leaves out of account the fact that \nthe course of a Turing machine computation depends not just on its configurations but also on \nhow the tape, i.e. the environment, is organised at the start of a computation.  HP starts on a \nblank tape but many other Turing machines, in particular all members of the important class \nof universal machines, depend on structure on the tape at the start of a computation.  The \ntreatment of affordances as configurations suggests that the concept of a niche is actually \nricher than Gibson proposes; it consists of sets of affordances plus a specification of the \nstructure of the environment.  A niche, in other words, is a habitat plus a set of affordances.   \nThe idea that sets of affordances have a certain unity or coherence is also true of sets \nof configurations.  HP has the set of configurations that it does and not another set, because \nthe set that it has is needed to perform the task.  The point is not that the task could not be \nhandled by another set of configurations but that the members of the particular set defined for \nHP go together.  They jointly define the control structure of the machine.  This suggests a \nstrong claim about the coherence of a set of affordances, namely that a set of affordances is \nconstitutive of the ecological specification of an animal.   \nThe idea that different animals may have sets of affordances in common is also one \nthat can be illuminated within the Turing machine framework.  HP does not demonstrate the \npoint because it is a very simple machine, but more complex Turing machines are often built \nusing identical sub-machines to carry out common tasks.  Turing designed his celebrated \nuniversal machine in just this way.  This idea can be used in two ways; it shows how Turing \nmachines may have replicated structure if they carry out the same sub-task at different times \nor with respect to different aspects of their environments and it shows how different Turing \nmachines may have structure in common if they have sub-tasks in common \n  \nGibson\u2019s affordances    44 \nConfigurations are meanings. \nThe treatment of affordances as the configurations of Turing machines leads to a re-\ninterpretation of Gibson\u2019s claim that affordances are meanings.  In the light of Gibson\u2019s \ncharacterisation of affordances as properties of the environment taken relative to the \nobserver, the thesis that affordances are meanings makes them external to and independent of \nthe observer.  The treatment of affordances as configurations brings the states of the observer \ninto the definition.  This implies that meanings are not entirely external to the observer.  \nHowever, bringing external states in, in this way, does not make meanings a property of the \nexperiences of the observer.  The environmental term in a configuration is both real and \nexternal to the observer.  It is not, therefore, a subjective experience.   \n Treating affordances as configurations also helps one to understand the subtle, layered \nnature of meaning.  Three ideas can be distinguished.  The meanings of configurations are \ncontextual, configurations are meaningful at more than one level and their meanings are \nintrinsically linked to the activities of a machine.  Consider HP again. The meanings of its \nconfigurations are contextual because they can only be understood properly in relation to \neach other and to the symbol structures on the tape.  The configuration (q4, #), for example, \nillustrates the importance of context.  (q4, #) means that HP has reached the end of the \nprinted portion of the tape and that a 1 has to be printed to complete the current number in the \nsequence.  This depends on (q4, #) occurring only after any 1s encountered by HP in state q2 \nhave been copied by the activities of HP in state q3.  It also depends on there being no gaps in \nthe printed sequence.   \nThe idea that configurations are meaningful at more than one level can also be \nillustrated using (q4, #).  Each time it occurs it means that another number in the sequence \nhas been completed.  Thus on its first occurrence it means that 1 has been completed, on its \nsecond occurrence that 2 has been completed and so forth.   \n  \nGibson\u2019s affordances    45 \nThe idea that meanings are intrinsically linked to the activities of the machine is \nillustrated by every configuration.  Even here there are some subtleties of interpretation.  \nDifferent configurations can be associated with the same action.  (q3, #) and (q1,1) both \ntrigger the action (1,q1,L).  In this case the meanings are different.  However, in other cases, \ndifferent actions arguably have the same larger scale meaning.  The configurations (q3, 0), \n(q3, 1) and (q3, X) have different actions associated with them.  But each of those actions \nmoves HP one square to the right as part of a sequence of behavior that seeks the first \navailable blank square in order to print a 1 on it.  Their meanings, at this higher level, are the \nsame even though their micro-meanings are different.  \nConfigurations are invariant combinations of variables. \nIn one simple sense, this point is obviously true.  Each configuration of a Turing \nmachine is an invariant combination of variables, one internal state and one symbol.  (q1, #), \nfor example, is the invariant combination of the internal state q1 and the symbol #.  However, \nthere are more important parallels than this between configurations and invariants.  First there \nis the notion that invariant structure in the environment is the source of information for the \nperceiver.  This idea is true for Turing machines.  Symbol tokens are the source of \ninformation for a Turing machine.  This is true even for machines like HP which start on a \nblank tape.  The first configuration (q1, #) registers the environmental information that the \ncurrently scanned square is blank.  The interaction of squares and symbols demonstrates a \nfundamental reliance on invariant structure.  The basic property required of the symbol \nalphabet of a Turing machine is the invariant property \u201ctype identity\u201d.  Type identity is the \nrequirement that a token of a given symbol, 0 for example, must be identifiable as a token of \nthat symbol and must be distinguishable from the tokens of any other symbol.  This does not \nmean that symbol tokens must share all their properties.  The Turing machine treatment of \n  \nGibson\u2019s affordances    46 \naffordances provides an opportunity to examine the use of invariant structure in the service of \nbehavior.   \n The formal structure of Turing machines may also serve to illuminate the link \nbetween evolutionary processes and affordances that Gibson discussed in various places.  His \npoint was that some environmental invariants had remained constant during millions of years \nof evolutionary history and had determined the life and behavior of animals.   The permanent \nstructure of the environment, in other words, had causal agency in the determination of the \nbasic behavioral repertoire of a species.  A natural question to ask once one recognizes this \npoint is how the permanent structure of the environment is related to the organic structures \nthat define animals and support their perception and behavior.  Gibson\u2019s own work was not \nfocused on this question although he recognized its importance.  The clarity and simplicity of \nTuring machines can help us to understand what issues are salient even though Turing \nmachines are designed artefacts rather than products of evolution.  This is not the place for a \nlengthy discussion, but a number of points may usefully be mentioned.  First, some internal \nstructuring in machines and organisms is a pre-requisite for successful action.  A Turing \nmachine without internal states cannot do anything and an animal without internal states \ncannot do anything either.  Second, there is a theoretical trade off between structure in the \norganism and structure in the environment.  Any Turing machine computation can be carried \nout by a machine with only two internal states provided that the symbol alphabet is made \nlarge enough.  This was proved by Claude Shannon and is discussed by Minsky (1967).  \nConversely, it can also be shown that any computation can be carried out using a two symbol \nalphabet provided the set of internal states is large enough.  These results show that one \ncannot decide, a priori, whether a particular behavior results from structure in the \nenvironment or structure in the organism.  Every behavior will depend on both types of \nstructure and the balance between them is a matter for empirical determination.  The fact that \n  \nGibson\u2019s affordances    47 \nthere may be sufficient structure in the environment for unambiguous normal perception does \nnot, therefore, preclude the need for and use of internal structure to support perception and \nproduce behavior.  The Turing machine model suggests that structure in the organism \ncomplements structure in the environment.  Behavior results from the co-ordination of \nperception and the possibilities for action that the environment affords at a given time and \nplace.   This is true for people as well as artificial machines. \nConfigurations are perceived directly. \n The activity of a Turing machine as it scans and moves around its tape provides a \npromising formal model of direct perception.   First it is noteworthy that Turing\u2019s \nterminology makes reference to visual perception.  The control of a Turing machine scans its \ntape and recognizes symbols printed on squares.  This recognition is \u201cdirect\u201d in Gibson\u2019s \nsense of the word even though the object of perception is a symbol.  There is no mediation \nvia a picture of any kind.  The current internal state does not construct a representation of the \nsymbol on the scanned square nor infer its existence, it simply recognizes it.  Second, the \nprocess of symbol recognition is part of a process of getting around the environment \nconstituted by the tape.  HP\u2019s movements back and forth are controlled jointly by its internal \nstates and by the symbols on its tape.  In this sense its activities can serve as a model of the \nprocess of information pickup.  The theory of direct perception does not preclude an active \nrole for the organism.  Indeed, it is essential.  \u201cGibson makes it clear in his current theory that \none can only have direct perception if the environmental and organismic components of \nperceptual theory are compatible.  Presumably they will be compatible only if one develops \neach component of the theory with an eye to the other.\u201d Mace (1977, pp.46-7). \nThe status of internal states in abstract machine theory. \nThe concept of an internal state stems from Turing\u2019s original analysis of computation \nbut the need for an internal state variable in abstract machine theory was challenged by \n  \nGibson\u2019s affordances    48 \nRobert Shaw and James Todd in their response to Ullman (1980).  Shaw and Todd questioned \nUllman\u2019s fundamental assumption that perception requires internal cognitive states.  They \nframed the issues in terms of two questions about machine theory.  First, is the state variable \na necessary term in all abstract machine descriptions or can it be replaced with some other \nterm filling the same formal role?  Second, if the state variable is used, need it be given the \nstandard cognitivist interpretation as an internal representation which causally mediates \nperceptual effects or can it be treated as something other than a reified internal state?  If it can \nbe shown that the abstract machine theoretic approach to perception need not involve internal \nstates, then, a fortiori, the computational approach need not involve them either.  If that is so, \nthen Gibson cannot be criticised by computationalists such as Ullman for leaving internal \nstates out of his theory of perception.  Shaw and Todd argue that the state variable can be \ndispensed with in abstract machine theory and claim, in consequence, that Ullman\u2019s critique \nof Gibson collapses.  If their argument is sound it also undermines the argument developed in \nthis paper. \n The foundation on which Shaw and Todd based their argument is the \u201cclasses of \nhistories\u201d approach to abstract machines, (cf. Minsky 1967, pp.14-16). The starting point is \nan animal or machine A with a history of interaction with an environment E. H(t) denotes this \nhistory up to time t and includes all the effects of A\u2019s relationship with E including inputs and \noutputs.  Assuming that the states of affairs in which A has participated up to time t constrain \nits response to the next input S, the response can be described in terms of a function F which \nis such that R(t+1) = F(H(t), S(t)).  Shaw and Todd note that this formulation makes no \nreference to internal states of the machine A but is based purely on the current input S(t) and \nthe history H(t) of A\u2019s interaction with E.  Why then do machine theorists typically make use \nof the notation Q(t) to describe a machine\u2019s internal state at time t?  Shaw and Todd argue \nthat it is purely a convenience which allows the theorist to avoid having to consider the \n  \nGibson\u2019s affordances    49 \nentire, cumbersome, history of transactions that may reach back to the remote past.  \u201cThe \nvariable Q(t) has no meaning of its own, except what is derived from the history term H(t).\u201d  \nShaw & Todd (1980, p.401).  They further argue that even if the theorist adopts Q(t) as a \nconvenience there is no need to reify it as an internal state.  Quoting Minsky (1967), they \nsuggest that Q(t) can equally well be described as an external state.  From this Shaw & Todd \n(1980, p.401) conclude: \nThe fundamental insight suggested by Minsky\u2019s observation is that the variables Q(t) \nand H(t) have at least two possible semantic interpretations.  Whereas the cognitive \ninterpretation describes them as \u201cinternal states\u201d the behavioral interpretation \ndescribes them as \u201cexternal states\u201d.  This implies that the two views are \ncomplementary and, therefore, there must exist commensurate formal \ncharacterizations under which the two views possess the same explanatory power. \n Since Q(t) stands for the internal states of a Turing machine such as HP, it is clear that Shaw \nand Todd\u2019s view represents a challenge to the construal of affordances in this paper.  In his \nresponse Ullman suggested that the classes of histories approach was descriptively correct but \nwas unsatisfactory as a psychological theory.   \nThere are stronger reasons than Ullman gave for rejecting the approach favoured by \nShaw and Todd.  While it is true that the term H(t) refers to the entire history of transactions \nof a machine with its environment, a particular history refers to what has happened inside the \nmachine whose history it is, as well as to the inputs the machine has received and the outputs \nit has produced.  Minsky makes this clear when he discusses what would happen if we were \nto \u201cdisconnect\u201d a machine from its environment and give it an input.  The machine would \nrespond with an output from the set that it can produce and the question is which one.  \u201cJust \nwhich signal rj occurs at t + 1 would depend, of course, both on which signal si is chosen at \ntime t and on the state of affairs inside M at time t.\u201d  Minsky (1967, p.15).  Minsky then goes \n  \nGibson\u2019s affordances    50 \non to say that if one assumes that the state of affairs inside M is determined by the history of \nM then the response produced at a given moment can indeed be understood as a function of \nthe history of the machine and the current input.  Thus Shaw and Todd are wrong to say that \nthe state variable Q has no independent meaning apart from the history H.  It refers \nindependently to the state of affairs inside M.  That state of affairs can be treated implicitly \nand wrapped up in a description of the machine\u2019s transactions with its environment but it \ndoes not disappear.   \n Shaw and Todd\u2019s argument misses the point of the classes of histories approach to the \ndefinition of internal states.  The point of abstract machine theory is to study machines that \ncan be made from a finite set of parts.  There are many good reasons for wanting to do this, \nnot least the fact that every constructible machine, natural or artificial, must in fact be made \nfrom a finite set of parts.  Turing\u2019s starting point was the idea that a mechanical model of a \nhuman computer could have only a finite number of machine configurations.  The classes of \nhistories approach to internal states uses this finitude to good advantage.  For any given \nmachine, one can imagine an infinite variety of possible histories.  Some of them will be \nindefinitely long and events from the far distant past may contribute to determining the \nresponse of the machine in the present.  If every separate event in an indefinitely lengthy \nhistory left an independent trace the machine would need an indefinitely large memory \ncapacity to remember them all.  A machine made from a given set of n parts could not, \ntherefore, possibly store a complete record of the events of an arbitrarily long history.  This \nmeans that the machine could not, in its behaviour distinguish between all possible histories.  \nMinsky discusses at some length the notion of an equivalence class of histories as a set whose \nmembers are indistinguishable from each other but distinct from the members of any other \nequivalence class.  The equivalence class concept, he says, \u201cbrings us to the key postulate of \nthe theory of finite automata.  We assume that the machine can distinguish, by its present and \n  \nGibson\u2019s affordances    51 \nfuture behavior, between only some finite number of classes of possible histories.  These \nclasses will be called the \u2018internal states\u2019 of the machine.\u201d Minsky (1967, p.16).   The \nconcept of an internal state inescapably refers to the finite set of parts out of which a machine \nis built, but is completely agnostic about the precise details of their implementation.  From \nthe standpoint of ecological psychology this is pivotal for two reasons.  First, the \ninescapability clause shows that behavior cannot properly be understood without reference to \ninternal states.  But equally importantly, the fundamental agnosticism about implementation \nshows that there is no a priori reason for supposing that internal states must be arranged as \ninternal representations in the fashion insisted on by computationalists like Ullman.  It is the \ncharacterisation of internal states that is important not the question of whether they are \nneeded or not and it is this point that Shaw and Todd could more profitably have made the \ncornerstone of their critique of Ullman.  Moreover, although in his later works Gibson says \nthings that look like an outright denial of the need for internal states, reading him this way \nmakes his position both within and between books inconsistent.  If he is read as denying only \nthe thesis that internal states must be arranged as structured representations that constitute the \nbasis for perception of the world, then the way is open for an account that builds, for \nexample, on the notion of resonance or some other notion, such as that developed in this \npaper, that is compatible with an account of perception as direct.  One might here notice, as \nMinsky observes (cf. Minsky 1967, p.17), that although the internal state of a machine at time \nt depends on the whole history of the machine, the dependencies with respect to the past and \nthe present can be separated.  Thus one can acknowledge with Gibson that the perceptual \nsystems of an organism depend on the remote past and were evolved with respect to it, \nwithout having to concede that perception now depends on memories.  The notion of an \ninternal state does not have to be understood in term of memory traces although it is \nacknowledged that the history of an organism\u2019s interaction with an environment has had an \n  \nGibson\u2019s affordances    52 \nimpact on its structure.  This understanding of internal states also helps with the analysis of \nhow affordances can both be learned and directly perceived.  The learning of an affordance \nincreases the set of distinguishable internal states of the learner in a way that enriches the \nlearner\u2019s behavioral repertoire.  This may, but need not, include a memory of the learning \nepisodes.      \nUniversal machines. \nThe discussion thus far has been focused on the example Turing machine HP.  HP is a \nmono-functional or special purpose Turing machine.  It carries out only one task, the \nproduction of the sequence 0010110111\u2026 A countable infinity of special purpose Turing \nmachines can be defined each of which carries out a specific computation.  Turing wanted to \nknow what, if any, limits there were to mechanical computation.  To this end he designed \nwhat he called a \u201cuniversal\u201d machine.  In one sense the universal machine was a Turing \nmachine like any other.  It was defined in terms of a finite set of internal states and a finite set \nof symbols and its control structure could be specified in a machine table.  In another sense \nthe universal machine was different from other Turing machines.  It was not started on a \nblank tape like HP but on a tape containing a string of symbols representing the machine \ntable of a Turing machine known as the target machine.  The universal machine was able to \ninterpret and act upon this string of symbols and thus to produce the output that the target \nmachine would have produced even though its own control structure was different.  The \nmachine was universal in the sense that it could interpret the machine table of any of the \ncountable infinity of definable Turing machines.  It was, therefore, the abstract ancestor of \nthe programmable computers that we have today.   \n The universal machine concept provides a way of extending the formal treatment of \naffordances begun in this paper.  It provides resources for thinking about Gibson\u2019s analysis of \ndepiction in Part Four of The Ecological Approach to Visual Perception and also for \n  \nGibson\u2019s affordances    53 \nunderstanding the significance of the other forms of display that humans have developed.  \nThe universal machine concept, properly understood, also provides further evidence for the \nbasic Gibsonian proposition that the information for perception is to be found primarily in the \nenvironment.  An adequate discussion of these issues would probably double the size of an \nalready lengthy paper and will have to be tackled elsewhere.  Readers who are interested in \nthe topic of universal machines can find an accessible introduction in Minsky (1967).  \nTuring\u2019s own universal machine, which can be found in his 1936 paper, is a wonderful \nconstruction and repays careful study but Turing makes no concessions to his readers and his \nnotation is not easy to grasp at first sight. \nConclusions. \nTuring\u2019s theory of computation provides a suitable formal model for studying \nGibson\u2019s theory of affordances.  There are striking and previously unrecognized parallels \nbetween the two theories and a grounding in each theory enriches one\u2019s understanding of the \nother.  Turing\u2019s theory also provides a clear formalisation of the concept of effectivity which \nmany theorists believe is needed to supplement Gibson\u2019s account of affordances.  At the start \nof The Ecological Approach Gibson suggested that what psychology needs \u201cis the kind of \nthinking that is beginning to be attempted in what is loosely called systems theory.\u201d Gibson \n(1979, p.2).  Systems theory had its origins in, among others, the work of Wiener on \ncybernetics and Shannon and Weaver on information theory.  Both cybernetics and \ninformation theory draw on ideas which were originally formalized by Turing.  At the end of \nThe Ecological Approach Gibson also said of the terminology and concepts of invariants, \n\u201cThese terms and concepts are subject to revision as the ecological approach to perception \nbecomes clear.  May they never shackle thought as the old terms and concepts have!\u201d  Gibson \n(1979, p.311).  Formal treatments of affordances and effectivities will be valuable only to the \nextent that they help to develop rather than shackle the ecological approach.  It is to be hoped \n  \nGibson\u2019s affordances    54 \nthat the community of ecological psychologists will come to see Turing\u2019s analysis of \ncomputation as a fruitful aid to the development of their theories. \n  \nGibson\u2019s affordances    55 \nReferences. \nBarwise, J.  (1989).  The Situation in Logic.  CSLI Lecture Notes; no.17.  Stanford, CA: \nCenter for the Study of Language and Information. \nBarwise, J. & Perry, J. (1983).  Situations and Attitudes.  Cambridge, MA: MIT Press. \nCarello, C., Turvey, M.T., Kugler, P.N., & Shaw, R.E. (1984).  Inadequacies of the Computer \nMetaphor.  In M. Gazzaniga (Ed.), Handbook of Cognitive Neuroscience.  New York: \nPlenum Press, 229-248. \nClark, A. (1997).  Being There.  Putting Brain, Body, and World Together Again.  \nCambridge, MA: MIT Press. \nDevlin, K. (1991).  Logic and Information.  Cambridge, UK: Cambridge University Press. \nEnderton, H.B. (1977).  Elements of Set Theory.  San Diego, CA: Academic Press. \nFodor, J.A. & Pylyshyn, Z.W. (1981).  How direct is visual perception?: Some reflections on \nGibson\u2019s \u201cEcological Approach\u201d.  Cognition, 9, 139-196. \nGibson, J.J. (1966).  The Senses Considered as Perceptual Systems.  Boston : Houghton \nMifflin. \nGibson, J.J. (1977).  The Theory of Affordances.  In R.Shaw and J. Bransford (Eds.)  \nPerceiving, Acting, and Knowing.  Toward an Ecological Psychology.  Hillsdale: NJ, \nLawrence Erlbaum Associates, 67-82. \nGibson, J.J. (1979).  The Ecological Approach to Visual Perception.  Boston: Houghton \nMifflin. \nGreeno, J.G.  (1994).  Gibson\u2019s Affordances.  Psychological Review, 101(2), 336-342. \nHarnad, S. (Ed.) (1987).  Categorical perception.  The groundwork of cognition.  Cambridge, \nUK: Cambridge University Press. \n  \nGibson\u2019s affordances    56 \nKadar, E. & Effken, J. (1994).  Heideggerian Meditations on an Alternative Ontology for \nEcological Psychology: A Response to Turvey\u2019s (1992) Proposal.  Ecological \nPsychology, 6(4), 297-341. \nKelso, J.A.S. (1995).  Dynamic Patterns.  The Self-Organization of Brain and Behavior.  \nCambridge, MA: MIT Press. \nKleene, S.C. (1971).  Introduction to Metamathematics.  Amsterdam: North Holland \nPublishing Company. \nLombardo, T. (1987).  The reciprocity of perceiver and environment: The evolution of James \nJ. Gibson\u2019s ecological psychology.  Hillsdale, NJ: Lawrence Erlbaum Associates. \nMace, W.M. (1977).  James J. Gibson\u2019s Strategy for Perceiving: Ask Not What\u2019s Inside Your \nHead, but What Your Head\u2019s Inside of.  In, R.Shaw and J. Bransford (Eds.)  \nPerceiving, Acting, and Knowing.  Toward an Ecological Psychology.  Hillsdale: NJ, \nLawrence Erlbaum Associates, 43-65. \nMinsky, M.L. (1967).  Computation: Finite and Infinite Machines.  Englewood Cliffs, NJ: \nPrentice-Hall Inc. \nPort, R.F. & van Gelder, T. (Eds), (1995).  Mind as Motion.  Explorations in the Dynamics of \nCognition.  Cambridge, MA: MIT Press. \nPylyshyn, Z.W. (1984).  Computation and Cognition.  Toward a Foundation for Cognitive \nScience.  Cambridge, MA: MIT Press. \nReed, E.S. (1991).  James Gibson\u2019s ecological approach to cognition.  In A. Still, & A. \nCostall (Eds.), Against Cognitivism.  Alternative Foundations for Cognitive \nPsychology.  London: Harvester Wheatsheaf. \nShaw, R. & McIntyre, M. (1974).  Algoristic foundations to cognitive psychology.  In W.B. \nWeimer & D.S. Palermo (eds.)  Cognition and The Symbolic Processes.  Hillsdale, \nNJ: Lawrence Erlbaum Associates, 305-362. \n  \nGibson\u2019s affordances    57 \nShaw, R. & Todd, J.  (1980).  Abstract machine theory and direct perception.  The Behavioral \nand Brain Sciences, 3, 400-401. \nShaw, R. & Turvey, M.T. (1981).  Coalitions as models for Ecosystems: A Realist \nPerspective on Perceptual Organization.  In M. Kubovy & J.R. Pomerantz (eds.)  \nPerceptual Organization.  Hillsdale, NJ: Lawrence Erlbaum Associates, 343-415. \nShaw, R., Turvey, M.T., & Mace, W. (1982).  Ecological Psychology: The Consequence of a \nCommitment to Realism.  In W.B Weimer & D.S. Palermo (eds.)  Cognition and the \nSymbolic Processes.  Volume 2.  Hillsdale, NJ: Lawrence Erlbaum Associates, 159-\n226. \nShepard, R.N. (1984).  Ecological Constraints on Internal Representation: Resonant \nKinematics of Perceiving, Imagining, Thinking, and Dreaming.  Psychological \nReview, 91(4), 417-447. \nStill, A. & Good, J. (1998).  The Ontology of Mutualism.  Ecological Psychology, 10(1), 39-\n63. \nThelen, E. & Smith, L.B. (1994).  A Dynamic Systems Approach to the Development of \nCognition and Action.  Cambridge, MA: MIT Press. \nTuring, A.M. (1936-7).  On Computable Numbers, with an Application to the \nEntscheidungsproblem.  Proceedings of the London Mathematical Society, ser.2, vol. \n42, 230-265.  Reprinted in M. Davis (ed.), (1965), The Undecidable. Basic Papers on \nUndecidable Propositions, Unsolvable problems and Computable Functions.  New \nYork: Raven Press Books Ltd., 116-154. \nTurvey, M.T. (1992).  Affordances and Prospective Control: An Outline of the Ontology.  \nEcological Psychology, 4(3), 173-187. \nTurvey, M.T. & Shaw, R. (1979).  The Primacy of Perceiving: An Ecological Reformulation \nof Perception for Understanding Memory.  In L-G. Nilsson (ed.) Perspectives on \n  \nGibson\u2019s affordances    58 \nMemory Research: Essays in Honor of Uppsala University\u2019s 500th Anniversary.  \nHillsdale, NJ: Lawrence Erlbaum Associates, 167-222. \nTurvey, M.T. & Shaw, R.E. (1995).  Toward and Ecological Physics and a Physical \nPsychology.  In R.L. Solso & D.W. Massaro (eds.)  The Science of the Mind: 2001 \nand Beyond.  New York: NY, Oxford University Press, 144-169. \nTurvey, M.T., Shaw, R.E., Reed, E.S., & Mace, W.M. (1981).  Ecological laws of perceiving \nand acting: In reply to Fodor and Pylyshyn (1981).  Cognition, 9, 237-304. \nUllman, S. (1980).  Against direct perception.  The Behavioral and Brain Sciences, 3, 373-\n415. \nVera, A.H. & Simon, H.A. (1993).  Situated Action: A Symbolic Interpretation.  Cognitive \nScience, 17(1), 7-48. \nWarren, W.H. Jnr, & Whang, S. (1987).  Visual guidance of walking through apertures: \nBody-scaled information for affordances.  Journal of Experimental Psychology: \nHuman Perception and Performance, 13, 371-383. \nWells, A.J. (1998).  Turing\u2019s Analysis of Computation and Theories of Cognitive \nArchitecture.  Cognitive Science, 22(3), 269 \u2013 294. \n \n  \nGibson\u2019s affordances    59 \nAuthor Note. \nA.J. Wells, Department of Social Psychology, The London School of Economics and \nPolitical Science.  \nCorrespondence concerning this article and requests for reprints should be addressed \nto the author at, The Department of Social Psychology, The London School of Economics \nand Political Science, Houghton Street, London WC2A 2AE, United Kingdom.  E-mail: \nA.J.Wells@lse.ac.uk   \n  \nGibson\u2019s affordances    60 \nFootnotes. \n1. Shaw and Turvey vary their choice of notation.  Sometimes they use (x,y) to denote \nan ordered pair, at other times they use <x,y>.   \n2. The definitions of X and Z are in conflict with the stipulation that X and Z are to be \nsubsets of B.  X and Z, as ordered tuples, are elements of B, not subsets.   \n3. Strictly speaking, given the definition B = {X, Z}, B should be defined as {{ball-\ndiameter}, {hand-span}}.  However, it is clearer and seems more in keeping with Shaw and \nTurvey\u2019s intentions to define B as the union of X and Z. \n4.  Shaw and Turvey say (p.391) that V = A x E x {+,-} but this cannot be correct \ngiven other things they say about V. \n5. The notation (a,b) for an ordered pair is more commonly used in the theory of \ncomputation than the notation <a,b>. \n6.  Strictly speaking, affordance types. \n7. When the machine reads and prints the same symbol, as in step t2 for example, \nthere is no formal distinction made between leaving the symbol unchanged and erasing and \nre-printing it. \n8. If a Turing machine encounters circumstances for which it does not have any \nactions defined, it stops. \n9. The control mechanism of HP is a deterministic finite automaton (DFA).  It is \npossible to define non-deterministic finite automata (NFA) in which state changes are only \npartially determined by the current state and input symbol.  Non-determinism of this kind \ndoes not increase the computational power of the automaton since for any NFA it is always \npossible to construct a DFA to compute the same function.   \n  \nGibson\u2019s affordances    61 \n \nTable 1.  The machine table for the four state, four symbol Turing machine HP. \n \n # 0 1 X \nq1 0,q2,R 0,q2,L 1,q1,L  \nq2 0,q2,L 0,q4,R X,q3,R X,q2,L \nq3 1,q1,L 0,q3,R 1,q3,R X,q3,R \nq4 1,q2,R 0,q4,R 1,q4,R 1,q4,R \n \nNote.  The first row of Table 1 shows the symbols that can appear on HP\u2019s tape.  These are the \nenvironmental components of the affordances of HP.  The # symbol is used to indicate a \nblank square.  Thus, HP can recognise when a square is blank or when it has a 0,1 or X on it.  \nThe symbol X is used for bookkeeping purposes.  It enables the machine to count the 1s it has \nto copy.  The first column of Table 1 shows the different functional states that HP can be in.  \nThese are the animal components of the affordances of HP.  They are labelled q1 to q4.  The \nuse of the letter q is a convention that stems from Turing\u2019s own work.  The entries in the \nbody of the table indicate the actions that HP carries out.  They are the effectivities of HP.  If, \nfor example, HP is in state q1 reading a blank square, then the affordance (q1,#) is actualised.  \nThe corresponding effectivity is (0,q2,R).  This means that HP prints a 0 on the blank square, \nmoves right one square and makes a transition to functional state q2.   The movement and the \nchange of functional state lead to the actualization of a new affordance (q2,#).  This leads to \nthe behaviour indicated by the effectivity (0,q2,L) and so forth. \n \n  \nGibson\u2019s affordances    62 \nTable 2.  A trace of the first twenty eight steps of the computation performed by HP. \nTime Tape Configuration Action \nt0 (#)# # # # # # # # # q1,# 0,q2,R \nt1  0(#)# # # # # # # # q2,# 0,q2,L \nt2 (0)0 # # # # # # # # q2,0 0,q4,R \nt3  0(0)# # # # # # # # q4,0 0,q4,R \nt4  0 0(#)# # # # # # # q4,# 1,q2,R \nt5  0 0 1(#)# # # # # #  q2,# 0,q2,L \nt6  0 0(1)0 # # # # # # q2,1 X,q3,R \nt7  0 0 X(0)# # # # # # q3,X X,q3,R \nt8  0 0 X 0(#)# # # # # q3,# 1,q1,L \nt9  0 0 X(0)1 # # # # # q1,0 0,q2,L \nt10  0 0(X)0 1 # # # # # q2,X X,q2,L \nt11  0(0)X 0 1 # # # # # q2,0 0,q4,R \nt12  0 0(X)0 1 # # # # # q4,X 1,q4,R \nt13  0 0 1(0)1 # # # # # q4,0 0,q4,R \nt14  0 0 1 0(1)# # # # # q4,1 1,q4,R \nt15  0 0 1 0 1(#)# # # # q4,# 1,q2,R \nt16  0 0 1 0 1 1(#)# # # q2,# 0,q2,L \nt17  0 0 1 0 1(1)0 # # # q2,1 X,q3,R \nt18  0 0 1 0 1 X(0)# # # q3,0 0,q3,R \nt19  0 0 1 0 1 X 0(#)# # q3,# 1,q1,L \nt20  0 0 1 0 1 X(0)1 # # q1,0 0,q2,L \nt21  0 0 1 0 1(X)0 1 # # q2,X X,q2,L \n  \nGibson\u2019s affordances    63 \nt22  0 0 1 0(1)X 0 1 # # q2,1 X,q3,R \nt23  0 0 1 0 X(X)0 1 # # q3,X X,q3,R \nt24  0 0 1 0 X X(0)1 # # q3,0 0,q3,R \nt25  0 0 1 0 X X 0(1)# # q3,1 1,q3,R \nt26  0 0 1 0 X X 0 1(#)# q3,# 1,q1,L \nt27  0 0 1 0 X X 0(1)1 # q1,1 1,q1,L \n \nNote. The first column of Table 2 shows the time, the second shows the state of the first ten \nsquares of the tape.  Each symbol represents the contents of a single square, and the \nparentheses round one of the symbols represent the square currently scanned by HP.  The \nthird column shows the successive configurations (affordances) of HP and the fourth the \nsuccessive actions (effectivities) that are taken.  The state of the tape at  time tn+1 shows the \nmodifications made at time tn.  Twenty eight steps are needed to demonstrate all of the \nmachine\u2019s instructions.   \n  \nGibson\u2019s affordances    64 \nFigure 1.  The state transition diagram for HP. \n \n#,0,L \nX,X,L  \n \n \n \n \n \n \n \n \nq2 q1 q4 \nq3 \n1,1,L #,0,R \n0,0,L \n0,0,R \n1,1,R \nX,1,R #,1,L \n1,X,R \n0,0,R \n1,1,R \nX,X,R \n#,1,R \n0,0,R \n \nFigure . The circles in the state diagram represent the distinct functional states of HP and the \narrows between circles represent the transitions between states.  A transition is made from the \nstate at the tail of an arrow to the state at its head.  An arrow that returns to the state from \nwhich it came indicates a transition from a state to itself or, equivalently, no change of state.  \nThe text boxes labelling the transition arrows have one, two or three rows of symbols in \nthem.  Each row represents a particular transition.  The first character is the input symbol, the \nsecond the output symbol and the third the direction in which HP moves relative to the tape.  \nThe state diagram shows the pattern of relations between functional states.  States q2 and q4, \nfor example, are immediately accessible from each other, whereas state q4 is only indirectly \naccessible from states q1 and q3. \n  \n"}
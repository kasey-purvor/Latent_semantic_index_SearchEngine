{"doi":"10.1016\/j.ssci.2003.12.002","coreId":"137265","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/775","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/775","10.1016\/j.ssci.2003.12.002"],"title":"Airborne Separation Assurance Systems: towards a work programme to prove safety","authors":["Brooker, Peter"],"enrichments":{"references":[{"id":38104174,"title":"A Method for Predicting the Number of Near Mid-Air Collisions in a Defined Airspace.","authors":[],"date":"1971","doi":"10.1017\/s0373463300018683","raw":"May, G. (1971). A Method for Predicting the Number of Near Mid-Air Collisions in a Defined Airspace. Journal of the Institute of Navigation, 24, 204-218.","cites":null},{"id":38104189,"title":"Comment on \u2018The meaning of probability in probabilistic safety analysis\u2019","authors":[],"date":"1995","doi":"10.1016\/0951-8320(95)00062-7","raw":"Yellman, T.W., and Murray, T. M., (1995). Comment on \u2018The meaning of probability in probabilistic safety analysis\u2019 Reliability Engineering and System Safety 49, 201-205.","cites":null},{"id":38104177,"title":"Comparison of Alerted and Visually Acquired Airborne Aircraft in a Complex Air Traffic Environment.","authors":[],"date":"1998","doi":"10.4271\/981205","raw":"Moore, S. M., (1998). Comparison of Alerted and Visually Acquired Airborne Aircraft in a Complex Air Traffic Environment. Proceedings of the 1998 advances in aviation safety conference, SAE\/P-321, 981205,held at Daytona Beach, Florida, April 6-8, 1998. SAE.","cites":null},{"id":38104171,"title":"Designing for safety: the \u2018free flight\u2019 air traffic management concept.","authors":[],"date":"2002","doi":"10.1016\/s0951-8320(01)00096-5","raw":"Hoekstra, J. M., Van gent, R. N. H. W., Ruigrok, R. C., J. (2002). Designing for safety: the \u2018free flight\u2019 air traffic management concept. Reliability Engineering and System Safety 75, 215-232.","cites":null},{"id":38104185,"title":"Development and application of a human error identification tool for air traffic control.","authors":[],"date":"2002","doi":"10.1016\/s0003-6870(02)00010-8","raw":"Shorrock, S. T. and Kirwan, B. (2002). Development and application of a human error identification tool for air traffic control. Applied Ergonomics 33 319\u2013336.","cites":null},{"id":38104178,"title":"Dougherty\u2019s Dilemma and the One-sidedness of Human Reliability Analysis Reliability Engineering and System Safety,","authors":[],"date":"1990","doi":"10.1016\/0951-8320(90)90017-h","raw":"Moray, N., (1990). Dougherty\u2019s Dilemma and the One-sidedness of Human Reliability Analysis Reliability Engineering and System Safety, 29, 337-344.","cites":null},{"id":38104165,"title":"Emerald (Emerging RTD Activities of relevance to ATM Concept Definition) \u2013 Final Summary Report. http:\/\/www.cordis.lu\/transport\/src\/emeraldrep.htm Eurocontrol","authors":[],"date":"1999","doi":null,"raw":"EC (European Commission) Transport RTD Programme, (1999). Emerald (Emerging RTD Activities of relevance to ATM Concept Definition) \u2013 Final Summary Report. http:\/\/www.cordis.lu\/transport\/src\/emeraldrep.htm Eurocontrol (1998). EATMS Validation Strategy Document. http:\/\/www.eurocontrol.int\/eatmp\/library\/documents\/EATMS_Validation_Strategy. pdf Eurocontrol (2002a). ACAS brochure. http:\/\/www.nbaa.org\/intl\/acas2_training_brochure.pdf Eurocontrol (2002b). Investigation of experience in modeling and determining separation minima. CARE-ASAS Activity 3. http:\/\/www.eurocontrol.int\/care\/asas\/documentation\/care-asas-a3-01-019.pdf Eurocontrol SRC [Safety Regulation Commission] (2000a). Risk Assessment and Mitigation in ATM. Eurocontrol Safety Regulatory Requirement ESARR 4. Edition 1.0. Eurocontrol, Brussels.","cites":null},{"id":38104176,"title":"European Studies to Investigate the Feasibility of using 1000 ft feet Vertical Separation Minima above FL 290: Part III \u2013 Further Results and Overall Conclusions.","authors":[],"date":"1993","doi":"10.1017\/s0373463300011589","raw":"Moek, G., ten Have, J. M., Harrison, D. and Cox, M. E. (1993). European Studies to Investigate the Feasibility of using 1000 ft feet Vertical Separation Minima above FL 290: Part III \u2013 Further Results and Overall Conclusions. Journal of the Institute of Navigation, 46, 245-261.","cites":null},{"id":38104150,"title":"Free-Flight and en route air safety: a first-order analysis,","authors":[],"date":"2000","doi":"10.1287\/opre.48.6.833.12394","raw":"Barnett, A., (2000). Free-Flight and en route air safety: a first-order analysis, Operations Research 48(6), 833-845.","cites":null},{"id":38104154,"title":"Future Air Traffic Management Systems and Financial Decision-Making Constraints.","authors":[],"date":"2002","doi":"10.1023\/b:port.0000007306.26907.22","raw":"Brooker, P. (2002c) Future Air Traffic Management Systems and Financial Decision-Making Constraints. Cranfield University Research Report PB\/3\/1\/02, ISBN 1 861940 85 8 \u2013 to appear in \u2018Transportation\u2019 in a shortened form].","cites":null},{"id":38104153,"title":"Future Air Traffic Management: Quantitative En Route Safety Assessment Part 2 \u2013 New Approaches.","authors":[],"date":"2002","doi":"10.1017\/s037346330200187x","raw":"Brooker, P. (2002b). Future Air Traffic Management: Quantitative En Route Safety Assessment Part 2 \u2013 New Approaches. Journal of the Institute of Navigation 55(3), 363-379.","cites":null},{"id":38104155,"title":"Future Air Traffic Management: Strategy and Control Philosophy.","authors":[],"date":"2003","doi":null,"raw":"Brooker, P. (2003). Future Air Traffic Management: Strategy and Control Philosophy. The Aeronautical Journal, 107(October), 589-598.","cites":null},{"id":38104164,"title":"Human reliability analysis \u2013 where shouldst thou turn? Reliability Engineering and System Safety,","authors":[],"date":"1990","doi":"10.1016\/0951-8320(90)90012-c","raw":"Dougherty, E. M. (1990). Human reliability analysis \u2013 where shouldst thou turn? Reliability Engineering and System Safety, 29, 283-299.","cites":null},{"id":38104172,"title":"Human Reliability Analysis: Context and Control,","authors":[],"date":"1993","doi":"10.1080\/00140139508928506","raw":"Hollnagel E., (1993). Human Reliability Analysis: Context and Control, Academic Press, London.","cites":null},{"id":38104151,"title":"Limitations of the See-and-Avoid Principle. Australian Department of Transport and Communications.","authors":[],"date":"1991","doi":null,"raw":"BASI, (1991). Limitations of the See-and-Avoid Principle. Australian Department of Transport and Communications.","cites":null},{"id":38104168,"title":"Logic of Statistical Inference,","authors":[],"date":"1976","doi":"10.2307\/2333679","raw":"Hacking, I. (1976). Logic of Statistical Inference, Cambridge University Press, Cambridge.","cites":null},{"id":38104190,"title":"Managing Criticality of ASAS Applications. 3 rd USA\/Europe Air Traffic Management R&D Seminar. http:\/\/www.caasd.org\/library\/presentations\/zeitlin.pdf","authors":[],"date":"2000","doi":null,"raw":"Zeitlin, A. D. and Bonnemaison, B., (2000). Managing Criticality of ASAS Applications. 3 rd USA\/Europe Air Traffic Management R&D Seminar. http:\/\/www.caasd.org\/library\/presentations\/zeitlin.pdf Zeitlin, A. D., (2001). Safety Assessments of ADS-B and ASAS, 4 th USA\/Europe Air Traffic Management R&D Seminar. http:\/\/www.mitre.org\/support\/papers\/tech_papers_01\/zeitlin_safetya\/zeitlin_safety .pdf","cites":null},{"id":38104161,"title":"Minimum Navigation Performance Specification and Other Separation Variables in the North Atlantic Area.","authors":[],"date":"1979","doi":null,"raw":"Brooker, P. and White, F. A. (1979). Minimum Navigation Performance Specification and Other Separation Variables in the North Atlantic Area. Journal of the Institute of Navigation, 32(3) 357-374.","cites":null},{"id":38104182,"title":"National Airspace\\Occupancy and Conflict Analysis Models for Evaluating Scenarios under the Free-Flight Paradigm.","authors":[],"date":"2000","doi":"10.1287\/trsc.34.4.321.12326","raw":"Sherali, H. D., Smith, J. C., Trani, A. A. and Sale, S. (2000). National Airspace\\Occupancy and Conflict Analysis Models for Evaluating Scenarios under the Free-Flight Paradigm. Transportation Science 34(40). 321-336.","cites":null},{"id":38104152,"title":"One safe sky for Europe \u2013 A revolution","authors":[],"date":"2003","doi":null,"raw":"Baumgartner, M. (2003). One safe sky for Europe \u2013 A revolution in European ATM.  The Controller, July, 8-12.","cites":null},{"id":38104180,"title":"Quiddities: an intermittently philosophical Dictionary,","authors":[],"date":"1987","doi":"10.2307\/1772611","raw":"Quine, W. V., (1987). Quiddities: an intermittently philosophical Dictionary, Bellknap Press of Harvard University Press, Cambridge, Mass., USA.","cites":null},{"id":38104156,"title":"Radar Inaccuracies and Mid-Air Collision Risk: Part 1 - a Dynamic Methodology \u2013","authors":[],"date":"2004","doi":"10.1017\/s0373463303002558","raw":"Brooker, P. (2004a) Radar Inaccuracies and Mid-Air Collision Risk: Part 1 - a Dynamic Methodology \u2013 to appear in the \u2018Journal of the Institute of Navigation\u2019.","cites":null},{"id":38104157,"title":"Radar Inaccuracies and Mid-Air Collision Risk: Part 2 - En Route Radar Separation Minima \u2013","authors":[],"date":"2004","doi":"10.1017\/s037346330300256x","raw":"Brooker, P. (2004b) Radar Inaccuracies and Mid-Air Collision Risk: Part 2 - En Route Radar Separation Minima \u2013 to appear in the \u2018Journal of the Institute of Navigation\u2019.","cites":null},{"id":38104170,"title":"Results of ACAS II Safety Analysis. ICAO Secondary Surveillance Radar Improvements and Collision Avoidance Systems Panel (SICASP\/5)","authors":[],"date":"1993","doi":null,"raw":"Harrison, D. (1993). Results of ACAS II Safety Analysis. ICAO Secondary Surveillance Radar Improvements and Collision Avoidance Systems Panel (SICASP\/5) Harrison D. and Moek G. (1992). European Studies to Investigate the Feasibility of using 1000 ft Vertical Separation Minima above FL 290: Part II \u2013 Precision Data Analysis and Collision Risk Assessment. Journal of the Institute of Navigation, 45, 91-106.","cites":null},{"id":38104181,"title":"Review of the General Concept of Separation Panel (RGCSP)","authors":[],"date":"1995","doi":null,"raw":"Review of the General Concept of Separation Panel (RGCSP) (1995). Working Group A Meeting: Summary of Discussions and Conclusions. (1995). ICAO.","cites":null},{"id":38104163,"title":"Review of the Target Level of Safety for NAT MNPS Airspace.","authors":[],"date":"1993","doi":null,"raw":"Davies, E. H. and Sharpe, A. G. (1993). Review of the Target Level of Safety for NAT MNPS Airspace. CS Report 9301. NATS, London.","cites":null},{"id":38104167,"title":"Safety Minima Study: Review of Existing Standards and Practices. SRC Doc 1, Eurocontrol, Brussels. http:\/\/www.eurocontrol.be\/src\/index.html FAA\/Eurocontrol","authors":[],"date":"1998","doi":null,"raw":"Eurocontrol SRC (2000b). Safety Minima Study: Review of Existing Standards and Practices. SRC Doc 1, Eurocontrol, Brussels. http:\/\/www.eurocontrol.be\/src\/index.html FAA\/Eurocontrol (1998). A Concept Paper for Separation Safety Modeling An FAA\/EUROCONTROL Cooperative Effort on Air Traffic Modeling for Separation Standards http:\/\/www.faa.gov\/asd\/ia-or\/pdf\/cpcomplete.pdf FAA\/Eurocontrol (2001). Cooperative R&D: Principles of Operation for the Use of Airborne Separation Assurance Systems (Version: 7.1) http:\/\/humanfactors.arc.nasa.gov\/ihi\/documents\/PO-ASAS.pdf Foot, P.B. (1994). A Review of the Results of a Trial Hazard Analysis of Airspace Sectors 24 and 26S. CS Report 9427, Civil Aviation Authority, London.","cites":null},{"id":38104169,"title":"Simultaneous Operation of Conflict Alert and ACAS II in UK En-Route Airspace.","authors":[],"date":"1989","doi":null,"raw":"Hale, S. and Law, M. (1989). Simultaneous Operation of Conflict Alert and ACAS II in UK En-Route Airspace. DORA Report 8914, CAA.","cites":null},{"id":38104188,"title":"Structuring Criteria for automated separation assurance, nd USA\/Europe Air Traffic Management R&D Seminar.","authors":[],"date":"1998","doi":null,"raw":"Simpson, R. W., (1998). Structuring Criteria for automated separation assurance, nd USA\/Europe Air Traffic Management R&D Seminar. http:\/\/atm-seminar98.eurocontrol.fr\/finalpapers\/track2\/simpson.pdf Swain, A. D., (1990). Human Reliability Analysis: Needs, Status, Trends and Limitations Reliability Engineering and System Safety, 29, 301-313. THEATRE website, (2002). http:\/\/www.theatre.isdefe.es\/home.sys.html?forum Watson, S. R., (19945). The meaning of probability in probabilistic safety analysis Reliability Engineering and System Safety 45, 261-269.","cites":null},{"id":38104159,"title":"Target Levels of Safety for Controlled Airspace. CAA Paper 77002.","authors":[],"date":"1977","doi":null,"raw":"Brooker, P. and Ingham, T. (1977). Target Levels of Safety for Controlled Airspace. CAA Paper 77002. CAA, London.","cites":null},{"id":38104162,"title":"The Chambers Dictionary,","authors":[],"date":"1998","doi":"10.5860\/choice.35-3035","raw":"The Chambers Dictionary, (1998). Chambers Harrap, Edinburgh.","cites":null},{"id":38104179,"title":"The Human Factor in System Reliability \u2013 Is Human Performance Predictable?","authors":[],"date":"2001","doi":null,"raw":"NATO RTO Meeting Proceedings 32 (2001). The Human Factor in System Reliability \u2013 Is Human Performance Predictable? RTO-MP-032.","cites":null},{"id":38104149,"title":"The paradoxes of almost totally safe transportation systems,","authors":[],"date":"2001","doi":"10.1016\/s0925-7535(00)00045-x","raw":"Amalberti, R., (2001). The paradoxes of almost totally safe transportation systems, Safety Science 37, 109-126.","cites":null},{"id":38104175,"title":"The Threat and the Glory,","authors":[],"date":"1991","doi":null,"raw":"Medawar, P., (1991). The Threat and the Glory, Oxford University Press.","cites":null}],"documentType":{"type":0.6666666667}},"contributors":[],"datePublished":"2004-10","abstract":"With Full Delegation Airborne Separation Assurance System (ASAS), separation control would be delegated to the (properly equipped) aircraft, i.e. aircraft pilots are responsible for aircraft separation.  The aim is to try to identify a tangible work programme \u2013 rational and evidence based, and within the compass of known techniques \u2013 that would prove safety.  The task here is to create a framework in which to integrate these existing building blocks with results from additional work developed from well-specified experiments.  \n\nReasons for retaining the existing separation minima in an ASAS system are put forward.  For the current system, comparatively large proportions of the Air Traffic Services risk budget should be allocated to \u2018Reasonable Intent\u2019 risk (effectively \u2018right place on wrong flight path\u2019).  The key argument here is that mid-air collision in an ASAS environment will predominantly arise from this type of risk.  The use of Probabilistic Risk Assessment, which requires the probabilities of safety-critical events to be estimated for \u2018human components\u2019 (Human Reliability Analysis), is reviewed.  The danger is the creation of \u2018over-elaborate\u2019 models \u2013 ones whose parameters cannot be reliably estimated from the data likely to be obtainable.  A simple model that can be soundly based on available data is proposed","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/137265.pdf","fullTextIdentifier":"http:\/\/hdl.handle.net\/1826\/775","pdfHashValue":"042daba0a7627a6566900ff014c893f44b7ab3e4","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/775<\/identifier><datestamp>2010-04-23T13:07:03Z<\/datestamp><setSpec>hdl_1826_19<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Airborne Separation Assurance Systems: towards a work programme to prove safety<\/dc:title><dc:creator>Brooker, Peter<\/dc:creator><dc:description>With Full Delegation Airborne Separation Assurance System (ASAS), separation control would be delegated to the (properly equipped) aircraft, i.e. aircraft pilots are responsible for aircraft separation.  The aim is to try to identify a tangible work programme \u2013 rational and evidence based, and within the compass of known techniques \u2013 that would prove safety.  The task here is to create a framework in which to integrate these existing building blocks with results from additional work developed from well-specified experiments.  \n\nReasons for retaining the existing separation minima in an ASAS system are put forward.  For the current system, comparatively large proportions of the Air Traffic Services risk budget should be allocated to \u2018Reasonable Intent\u2019 risk (effectively \u2018right place on wrong flight path\u2019).  The key argument here is that mid-air collision in an ASAS environment will predominantly arise from this type of risk.  The use of Probabilistic Risk Assessment, which requires the probabilities of safety-critical events to be estimated for \u2018human components\u2019 (Human Reliability Analysis), is reviewed.  The danger is the creation of \u2018over-elaborate\u2019 models \u2013 ones whose parameters cannot be reliably estimated from the data likely to be obtainable.  A simple model that can be soundly based on available data is proposed.<\/dc:description><dc:publisher>Elsevier<\/dc:publisher><dc:date>2005-11-22T13:33:18Z<\/dc:date><dc:date>2005-11-22T13:33:18Z<\/dc:date><dc:date>2004-10<\/dc:date><dc:type>Article<\/dc:type><dc:format>359980 bytes<\/dc:format><dc:format>1886 bytes<\/dc:format><dc:format>application\/pdf<\/dc:format><dc:format>text\/plain<\/dc:format><dc:identifier>Peter Brooker, Airborne Separation Assurance Systems: towards a work programme to prove safety, Safety Science, Volume 42, Issue 8, October 2004, Pages 723-754.<\/dc:identifier><dc:identifier>0925-7535<\/dc:identifier><dc:identifier>http:\/\/hdl.handle.net\/1826\/775<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1016\/j.ssci.2003.12.002<\/dc:identifier><dc:language>en<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0925-7535","0925-7535"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2004,"topics":[],"subject":["Article"],"fullText":"  1\n \nCranfield University \nBuilding 83 \nCranfield  \nBedfordshire MK43 0AL \nEngland \nTel +44 (0) 1234 750111 Extn.5086 \nFax +44 (0) 1234 750192 \ne-mail: p.brooker@cranfield.ac.uk \n \n \nAIRBORNE SEPARATION ASSURANCE SYSTEMS: \nTOWARDS A WORK PROGRAMME TO PROVE SAFETY \nPeter Brooker \n[Cranfield Research Report PB\/12\/1\/02] \n[Copyright \u00a9 Cranfield University, 2002] \n[ISBN 1 861940 91 2] \n \n \u201cContent is a glimpse of something, an encounter like a flash.  It is very tiny \u2013 \nvery tiny, content.\u201d  Attributed to Willem de Kooning. \nABSTRACT \nWith Full Delegation Airborne Separation Assurance System (ASAS), separation \ncontrol would be delegated to the (properly equipped) aircraft, i.e. aircraft pilots \nare responsible for aircraft separation.  The aim is to try to identify a tangible \nwork programme \u2013 rational and evidence based, and within the compass of \nknown techniques \u2013 that would prove safety.  The task here is to create a \nframework in which to integrate these existing building blocks with results from \nadditional work developed from well-specified experiments.   \n \nReasons for retaining the existing separation minima in an ASAS system are put \nforward.  For the current system, comparatively large proportions of the Air \nTraffic Services risk budget should be allocated to \u2018Reasonable Intent\u2019 risk \n(effectively \u2018right place on wrong flight path\u2019).  The key argument here is that mid-\nair collision in an ASAS environment will predominantly arise from this type of \nrisk.  The use of Probabilistic Risk Assessment, which requires the probabilities \nof safety-critical events to be estimated for \u2018human components\u2019 (Human \nReliability Analysis), is reviewed.  The danger is the creation of \u2018over-elaborate\u2019 \nmodels \u2013 ones whose parameters cannot be reliably estimated from the data \n  2\nlikely to be obtainable.  A simple model that can be soundly based on available \ndata is proposed.   \n1. INTRODUCTION \nThe present air traffic control (ATC) system has several distinct components.  Air \ntraffic controllers communicate through radiotelephony; they use flight plans \nagreed with pilots; they monitor highly processed radar data; and, in developed \nStates, they have short-term conflict alert (STCA) systems available to warn of \naircraft coming into close proximity.  These data flows are embedded in \u2018safety \nstructures\u2019, e.g. with well-defined controlled airspace and formal rules for control \nsuch as the minimum separation permitted between aircraft.  System procedures \nwere originally designed to be \u2018tolerant\u2019 of equipment failure, as decades ago the \nequipment was much less accurate or reliable.  The system safety structures \nhave also been designed to be relatively easy for human operators to \ncomprehend and use.   \n \nThe present concept has evolved: it is \u2018overlaid\u2019, in that new technology has \nlargely been added on to the previous concept.  Any new functionality generally \nhas to able to carry out both the tasks of the previous generation plus some new \nones.  Can the current system continue \u2018evolving\u2019 for many more years?  To \nquote Amalberti (2001): \n\u201cMost of today\u2019s man-machine systems were designed in the 1960s\u2026No \nsystem will last forever, and we are probably dealing today with ageing \nlogic which will someday be replaced by a different logic once the \ntechnology is finally mature\u2026\u201d \n[The phrase \u2018once the technology is finally mature\u2019 is a key one, and is the \nsubject of much of the following.]  There are already major problems with system \ncapacity, leading to significant flight delays, mainly because controller workload \nis nearing acceptable limits in busy airspace sectors.  The phrase \u2018Free Flight\u2019 \nhas resonated in the ATC community for much of the last decade, suggesting \nthat flights should use preferred \u2013 more cost effective \u2013 routeings and profiles, \nrather than follow fixed routeings.   \n \nAirborne Separation Assurance Systems \u2013 ASAS \u2013 are a possible way forward \nfor air traffic management.  Studies are in progress under the auspices of the \nFAA, Eurocontrol (FAA\/Eurocontrol, 2001) and the European Commission.  \nSome technical details of potential technologies to provide ASAS, and the wider \nsystem context, are given in EC (1998) \u2013 ASAS would generally be provided \nthrough some kind of ADS-B (\u2018Automatic Dependent Surveillance \u2013 Broadcast\u2019) \nequipment.  The main feature of ASAS is that separation control is delegated to \nthe (properly equipped) aircraft, i.e. aircraft pilots are responsible for their \naircraft\u2019s separation from other flights.  This is termed \u2018full delegation\u2019, defined as: \n  3\nFull delegation: Pilots are responsible for all the tasks related to \nseparation assurance: identification of problems and solutions, \nimplementation and monitoring. \nASAS as used here always refers to Full Delegation.  There are other ways in \nwhich airborne equipment providing information on nearby aircraft can be \nintegrated into the system, e.g. see Brooker (2003).  There might be critical \u2013 and \npotentially very difficult \u2013 transition processes between the present system and \nASAS.  Such transitions might raise new problems both over time \u2013 e.g. mixed \nequipage and partial delegation of ATC tasks \u2013 and in space \u2013 e.g. interfaces \nbetween ASAS and conventional ATC regions.  However, intermediate \noperational steps to the \u2018full ASAS\u2019 investigated here could provide useful \nevidence on ASAS safety performance.  No assumption about the availability of \nsuch information is made here, i.e. it would be a \u2018bonus\u2019.  Some of the ideas and \ntechniques explored here could also have wider applicability; for example, the \ndevelopment of automated aids for ground control would produce similar issues \nto those raised by ASAS.   \n \nASAS would be considerably different from the present Air Traffic Management \n(ATM) system (taken here to include ATC and all other functions that deliver air \ntraffic\u2019s safety, capacity, cost-effectiveness, etc).  This paper addresses the \nquestion: \u201cHow would one prove that an ASAS system is safe in practice?\u201d  The \nbiggest problem with safety arguments is the need to understand all the possible \nways that a failure could lead to an accident.  Demonstrating completeness is \nextremely difficult with complex systems such as ASAS in busy airspace \u2013 or \nanything else that relies heavily on software, displays and people.  There is \ninevitably some resort to probabilistic arguments and statistical evidence.  So, \nthe question addressed here might better be put in the form: \u201cWhat would be the \nleast complex and most robust calculations required to do the job?\u201d  It needs to \nbe stressed that broad-based real-time simulations are inadequate to \ndemonstrate safety of complex systems, but, as will be indicated in later sections, \nwell-focused simulations are indispensable components of effective risk \nanalyses. \n \nASAS has, of course, to be seen in the larger context of possible future ATM \nsystems \u2013 as is evident from the linkages from the European Commission\u2019s \nTHEATRE work.  [THEATRE is the \u2018Thematic Network on Air Transport for ATM \nValidation Activities\u2019: its objective is to achieve transparency and effectiveness \nbetween validation projects in the 5th Framework Programme of the European \nCommission; its Validation and Safety Working Group is particularly relevant \nhere.]   \nThe validation problem can be stated in even more demanding terms.  To quote \nthe recent FAA\/Eurocontrol document on ASAS (2001): \n\u201cASAS applications involving major reliance on aircraft systems and \nchanges to present responsibilities and procedures to ensure aircraft \nseparation will require rigorous safety analysis and validation before \n  4\nimplementation.  This analysis will need to demonstrate conclusively that \nthe ASAS application meets or exceeds the required Target Level of \nSafety, including consideration of equipment failure and human error.  \nMethodologies and guidelines for these analyses will need to be agreed at \nthe international level.\u201d \nWords such as \u2018rigorous\u2019 and \u2018conclusively\u2019 set a very uncompromising tone.  \nThe same kinds of phrases appear in many other ASAS-related documents \u2013 \n\u2018detailed and rigorous safety assessment\u2019 is a common variant.  But the \nvalidation processes then described often appear to be very abstract and \nunspecific: indeed, some appear to value metaphysics and elegance as having \nmore merit than practical applicability.  So, what would actually be practical and \ntheoretically sound methods for achieving the quantitative goal?  Precisely what \ncalculations have to be carried out?  What evidence and information from the \noperation of present systems needs to be used?  What new data has to be \ngathered \u2013 and does this require specific types of simulations?  How, in \nAmalberti\u2019s phrase, is the technology \u2013 or rather the technology & human system \n\u2013 demonstrated to be \u2018fully mature\u2019?   \n \nThis paper attempts to start to answer such questions.  The aim is to try to \nidentify a tangible work programme \u2013 rational and evidence based, and within the \ncompass of known techniques \u2013 that would prove safety in the terms set out in \nthe above quotation.  In fact, many of the building blocks already exist: the task \nhere is to create a framework in which to integrate these components with \nadditional work that can be developed from well-specified experiments. \n \nThe sections are as follows: \n2. The Concepts of Validation and Proof \n3. Safety Targets and Probability \n4. Separation Minima \n5. Probabilistic Risk Assessment \n6. \u2018Reasonable Intent\u2019 Risks \n7. ASAS Safety Issues \n8. A \u2018Minimal Framework\u2019 Collision Risk Model \n9. Conclusions \n2. THE CONCEPTS OF VALIDATION AND PROOF \nIt is necessary to try to understand the logical underpinnings of \u2018validation\u2019.  ATM \nhas a definition (Eurocontrol, 1998): \nValidation \u2013 \u2018The process through which a desired level of confidence in \nthe ability of a deliverable to operate in a real-life environment may be \n  5\ndemonstrated against a pre-defined level of functionality, operability and \nperformance.\u2019 \nThis is a complex definition.  It has moved on from the sort of definition that is \ngiven in dictionaries (Chambers, 1998) eg: \nvalidate -\u2026to check items to ensure that they conform to input rules and \ne.g. fall within an acceptable range \nValidation in ATM appears to be being used to mean \u2018proof\u2019; again from \nChambers: \nproof -\u2026demonstration; evidence that convinces the mind and goes \ntoward determining the decision\u2026;  \nThe key phrase above that supports this view is \u2018desired level of confidence\u2019, \nwhich equates to \u2018evidence that convinces the mind\u2019.  One reason that the word \nproof is not used may be that the same or similar word is found in several \nEuropean languages, where it tends to have a meaning of \u2018test\u2019.  To understand \nhow proof should be manifested in ATM, it is worth examining the concept in \nlogic and legal contexts, as these influence thinking about the concept. \n \nProof in logic tends to have a very restricted meaning.  It is a demonstration of \nthe validity of a proposition based on specific premises \u2013 a deductive argument.  \nThus, for any real number p, 1 + p2 \u2265 2p can be shown to be correct given the \nrules of algebra and the fact that the square of a real number is positive.  \nEngineering design problems such as ASAS do not fall into this class, because \nthey rely on an \u2018inductive\u2019 chain of reasoning, in which the truth of the premises \nmakes it probable \u2013 rather than necessary \u2013 that the conclusion is true.  Hence, \n\u2018proof\u2019 of ASAS safety cannot be logically guaranteed \u2013 an obvious point, but one \nat odds with calls for \u2018absolute safety\u2019.  In other words, it is impossible to assure \nany sort of formal \u2018completeness\u2019 of any risk analysis \u2013 there can never be a \nproof that all types of errors or risk modes have been identified.  However, in \ntraditional \u2018hard\u2019 engineering disciplines, with physical constructions, \nextrapolations based on measured data combined with physical laws can enable \nthe performance of a system to be proved satisfactory to a high degree of \nconfidence. \n \nWhen human beings enter into the analysis, either as part of the operational \nsystem or as analysts of its performance, the situation is much more complex.  \nIssues raised by the former are dealt with in latter sections.  An example of the \nlatter is expert witnesses giving scientific \u2013 generally medical \u2013 evidence in a \nlegal case.  They have two tasks: to provide basic scientific or technical data; and \nto present conclusions or inferences from the facts, given that the judge and\/or \njury, not having specialised knowledge, could not themselves draw.  In principle, \nsuch medical opinions can be empirically supported, although the required range \nof observations and experiments may not be available.   \n \n  6\nIn an adversarial legal system, such as the UK and USA, evidence from expert \nwitnesses can be challenged, and indeed both sides in a legal case can present \nexpert testimony.  The sort of question with which the expert witness has to \nassist is \u201cHas the prosecution proved beyond reasonable doubt that the accused \nkilled the victim?\u201d  These are obviously similar to the phrases \u2018desired level of \nconfidence\u2019, and \u2018evidence that convinces the mind\u2019.  Decision-makers cannot be \nexpected to accept the expert\u2019s judgements and opinions in an uncritical fashion.  \nThere is an onus on him or her to be able to demonstrate to these intelligent non-\nexperts the reasoning and processes by which the conclusions have been \nreached.  This demonstration should be \u2018robust\u2019, i.e. with the inferences not \neasily being demolished if particular assumptions do not fully hold or \nrelationships between variables are not exact.  The decision-makers \u2013 States, \nATC organisations, and individuals \u2013 are personified here as the \u2018Rational \nEvidence Scrutiniser\u2019 (RES).  The RES represents the \u2018directing minds\u2019 \nresponsible for aviation safety.   \n \nGiven the definition of validation set out earlier, the task of proof would need to \nbe a convincing description explaining how safety is assured through protective \nbarriers in the system and the nature of resilience against \u2018unsafe incidents\u2019.  \nThis narrative would have to make clear the nature and rationality of the \nquantifications involved.  Confidence is built by displaying with clarity the rational \nnature of the calculations and demonstrating that all the quantitative aspects \nhave some reasonable basis in observations and relevant measurements.  This \n\u2018hard\u2019 viewpoint stretches back to Descartes and Hume.  What else could be \nadopted in critical matters of aviation safety, because such processes must \nreflect the highest standards of public decision-making?  \n \nThe RES therefore wants to be convinced through a rigorous and explicit \napproach that risk estimates are well founded.  It is the actual \u2018process of \nexplication\u2019 that should convince the RES that there are firm foundations to risk \nestimates.  One would expect the RES to be sceptical if the core arguments were \nto be attempted through scientific complexity, with \u2018magic black box\u2019 \nmathematical and statistical calculations involving many acronyms and a host of \nGreek symbols.  \u2018Confidence\u2019 could surely only come about through the creation \nof a compelling \u2018narrative\u2019 explanation, soundly based in theoretical \nunderstanding and empirical evidence, and open to challenge, checking and \nverification at every stage.  In particular, this implies that commercial modelling \nproducts, i.e. which are not open to the possibility of scrutiny or peer review, \nwould not be adequate to convince the RES.   \n \nIt needs to be noted that validation is not the only critical element in ATM safety \nprocesses.  Certification and Verification are key elements: \nCertification \u2013 \u2018The process aiming at the satisfaction of an authority that \na deliverable complies with a set of regulations, in order to ensure its \nproper operation.\u2019 \n  7\nVerification \u2013 `The process of evaluating the products of a given system \ndevelopment activity to determine correctness and consistency with \nrespect to the products and standards provided as input to that activity.\u2019 \nThese will not be discussed directly in the following, although many similar issues \nare involved \u2013 in particular, safety certification increasingly relies on the outputs \nfrom validation and safety management.   \n \nMore generally, safety criticality of ASAS applications is being explored by a \nnumber of researchers, mainly with aim of guiding developers and designers to \nensure robustness where it is most needed.  The papers by Zeitlin (2001) and \nZeitlin and Bonnemaison (2000), and their references to RTCA work, are \nparticularly relevant to some of the issues discussed here. \n3. SAFETY TARGETS AND PROBABILITY \nThe key quantitative safety concept in ATC is that of a Target Level of Safety \u2013 \nTLS.  This is actually a design hurdle.  It is a quantified risk level (measured as \nan accident rate) that a system should \u2013 i.e. be designed to \u2013 deliver.  TLSs \ncover all aviation-related causes, but do not usually attempt to cover the \nconsequences of terrorism or criminal behaviour (although the literature has not \nalways been clear on this).  It is usually expressed as a proportion of fatal \naccidents per so many flying hours (or airport movements when that is more \nappropriate).  As will be examined later, most of the practical problems are not \nactually with the TLS but with the proper estimation of the safety level that is \u2013 or \nwould be \u2013 achieved.  There is an Actual Level of Safety \u2013 an \u2018ALS\u2019 - being \nachieved in the system under examination: how is this to be calculated with \nsufficient accuracy for the RES to be confident that the ALS < TLS? \n \nA TLS can be derived in several ways.  Brooker (2002) and the Safety \nRegulation Commission of Eurocontrol (SRCb, 2000) sketch the kinds of \ncalculations involved.  TLSs appropriate for accidents arising from mid-air \ncollisions have been developed since the 1970s.  They are usually derived by \ntaking historical accident rates, which show a progressive reduction over time, \nand extrapolating forward.  Thus, the TLS value gets tighter and tighter over time.  \nThe original focus was on commercial passenger jet flights in North Atlantic \nairspace, but the TLS has been used for en route controlled airspace generally.  \nIn particular, it is used in the calculation of the separation minima required \nbetween aircraft in oceanic and domestic airspace. \n \nThe TLS is measured in fatal aircraft accidents, i.e. accidents in which at least \none person in the aircraft was killed, per so many aircraft flying hours.  The \ncurrent ICAO (RGCSP, 1995) figure of 1.5 x 10-8 fatal aircraft accidents per flying \nhour is the total rate corresponding to mid-air collisions \u2013 for any reason and in \nany spatial dimension \u2013 in en route flight in controlled airspace.  Brooker and \nIngham (1977), and Davies and Sharpe (1993) show how the TLS is derived.  It \nis important to stress that the TLS includes the consequences of \u2018blunder\u2019 type \n  8\nerrors, such as errors in coordination between the aircraft crew and ATC (leading \nto an aircraft occupying a flight level or routeing other than that intended by \nATC), or errors in ATC instructions leading to a similar consequence.  For \nexample, Harrison and Moek (1992) explain how the vertical domain TLS, taken \nas third of the total TLS, is partitioned into \u2018loss of planned separation\u2019 errors and \n\u2018other\u2019 errors.  Thus, the TLS is not simply driven by technical operation \u2013 e.g. \naltimetry in the vertical case \u2013 but by total system performance.  This is a crucial \npoint, which underpins the discussion in Section 6, on \u2018Reasonable Intent\u2019 risks. \n \nTo put the ICAO TLS in context, for UK ATC, assume 1 million (106) en route \nflight hours a year indefinitely into the future.  If the TLS represents the actual risk \nrate, this would correspond to one mid-air collision \u2013 two fatal aircraft accidents \u2013 \nper 134 years.  Given current average passengers per aircraft, there would be \nabout 200 fatalities in such a collision.  On past decision-making trends, such a \nTLS for 20 and 30 years ahead with an ASAS-based ATC will be even tougher.  \nSuch a target will requires the acceptance of the aviation community, given that \nASAS as described here would in many ways be an \u2018end state\u2019 concept for ATC.   \n \nBut what does such a design target mean in practice?  To explore this, it is \nnecessary to examine the statistics of rare events. \nPoisson Distributions and Confidence Intervals \nThe Poisson distribution \u2013 found in any standard textbook on probability \u2013 is a \ngood statistical model for discrete and rare events, particularly when such events \nare generated from a large number of independent sources.  A typical Poisson \nrandom variable is a count of the number of events that occur in a certain time \ninterval or spatial area, e.g. the number of calls received by a switchboard during \na given time period. \n \nFor the Poisson distribution to be applicable, several conditions must apply: \nThe events of interest occur at random over a particular continuous period \nof time (or distance interval, region of area, etc).   \nEvents occur singly, i.e. not exactly simultaneously. \nEvents are statistically independent, i.e. the occurrence or non-occurrence \nof an event does not affect the chance of another event occurring.  Hence, \nthe occurrence of events is \u2018memoryless\u2019.   \nEvents occur at a constant average rate, usually denoted by the Greek \nletter \u03bb.   \nWith these conditions, it can be shown that: \nProbability (r events in time t) = (\u03bbt)r e-\u03bbt\/ r!   r = 0, 1, 2... \nThe Poisson distribution has expected value \u03bbt and an identical variance \u03bbt. \n \n  9\nThe statistical confidence intervals \u2013 again, found in standard textbooks \u2013 for a \nPoisson distribution are of key importance in assessing data on rare events.  A \nkey calculation is the one-sided upper confidence point at 95% \u2013 the value \"a\" of \n\u03bbt for which the observation of 0 events is 5% probable, ie: \nProbability (0 events in time t) = a0 e-a \/ 0! = e-a = 0.05, \nwhich gives a = 2.995\u2026 \u2013 say 3. \nSo, if during a period, zero events are observed, then with 95% confidence it can \nbe said that the mean value for observation is less than 3.  This is a powerful \nmessage: the absence of events provides \u2018weak\u2019 evidence about the underlying \nrate. \n \nIn the present context, suppose one wanted to confirm that the value of \u03bb \naccording to the TLS, 1.5 x 10-8, was being achieved in practice by counting the \nrate at which accidents occur.  Note that these are collisions (and flying hours) in \nall the en route airspace under consideration (see Davies and Sharpe (1993) for \ndefinitions), and that in this simple model it is assumed that about the same \ndegree of protection against collision risk is to be assured everywhere in this \nairspace.  Observing for 1.33 x 108 flying hours (a large number \u2013 1.33 times 100 \nmillion) would statistically be expected to produce two accidents, i.e. one mid-air \ncollision \u2013 noting that it is collisions which are Poisson events, not accidents.  \nHowever, an absence of collisions would be the most statistically likely scenario, \nwhich would imply an upper confidence level of 3 mid-air collisions in 1.33 x 108 \nhours, i.e. a collision rate of 2.25 x 10-8.  Thus, even observing for long periods \ncomparable with the expected interval between accidents does not produce \nstrong confidence in the value of the ALS.  Observations for much shorter \nperiods are far worse: no mid-airs in a period of the order of million hours \nproduces an upper confidence level two orders of magnitude above the TLS.   \n \nRare events pose an intrinsically difficult problem for the system designer.  Even \nif one or two accidents were to be observed, this does not produce large \nimprovements in the degree by which he or she  could be statistically confident \nabout the TLS being achieved.  The upper confidence levels for 1 and two \nobserved events are shown below. \n \nNumber of \nobserved events \nUpper Confidence \nlimit at 95% \n0 3.00 \n1 4.74 \n2 6.30 \n \nThese results, obvious to a statistician, show the impossibility of statistical proof \nthrough direct observations on a new system, under controlled experimental \nconditions, that ASAS meets the TLS.  The use of methods other than classical \nstatistical inference does not help.  Subjective probability techniques (Hacking, \n  10\n1976) depend on an individual\u2019s understanding of relative outcomes, and are \nhence inappropriate for rare events.  Bayesian probability techniques require \nsome kind of prior probability distribution to be constructed (the conjugate prior \ndistribution for a Poisson is a Gamma distribution) \u2013 but where does the prior \nknowledge (sic) of rare events come from? \n \nThere is even no way of proving the safety of the existing ATM system \nstatistically (indeed, the 2002 mid-air collision over the Swiss-German border \ncould be said to indicate that the TLS is not currently being met in European \nairspace).  There are obvious problems for \u2018verification\u2019, defined earlier.   \n \nTo solve this problem, system safety somehow has to be partitioned into \nelements, for each of which safety factors can be quantitatively demonstrated, \nwith the necessary statistical confidence, for the RES.  Ideally, each element in \nthis partition model would provide safety factors of 102 or 103, so that their \nproduct would deliver the required TLS.  Thus, the risk has somehow to be built \nup of separable components, i.e. be the product of statistically independent \nevents or characteristics.  Two modelling methods can be envisaged: either the \nmodel is built up from features of the present system plus reliably modelled \nbehaviour for new features or the model is constructed from the characteristics of \nthe future system using some kinds of general principles.  These may be termed \nCollision Risk Modelling (CRM) and Probabilistic Risk Assessment (PRA), \nalthough there are wide variations in the research literature.  To these must be \nadded real-time simulation of different components of new ATM systems.  \n[FAA\/Eurocontrol, 1998 is an excellent review article on these and other aspects \nof collision risk estimation.] \n \nThese kinds of issues are not specific to aviation.  The nuclear power plant \nindustry has had an ongoing debate over much of the last half century about \nprobabilistic risk analyses.  A quote from Yellman and Murray (1995 \u2013 see also \nWatson, 1994 and 1995) makes the point vigorously and succinctly: \n \u201cNow consider the statement \u2018I estimate the probability of a core-melt in \nthis (only partially designed and as yet unbuilt) nuclear power plant over \nten years of operation to be 0.0000346\u2019.  Not only does the plant not exist, \nit may never be built, or at least not built to the current design.  And if it is \nbuilt,\u2026we won\u2019t get a large and stable enough sample of its operation to \nvalidate the \u2019estimate\u2019 to any meaningful degree of confidence.  It sounds \nless abrasive to say that a probability \u2018estimate\u2019 is being made than that an \nassertion is being made.\u201d \nTherefore, the message is that ASAS \u2018risk estimates\u2019 are actually assertions \nabout the degree of risk.  There is no way of demonstrating by logical or \nstatistical means that the TLS \u2018standard\u2019 would be met \u2013 the best evidence that \ncan put before the RES is a well argued and robust assertion about the ALS. \n  11\n4. SEPARATION MINIMA \nOne of the key safety barriers used to protect against mid-air collision is the use \nof separation minima (sometimes referred to as separation standards).  Any \nsensible theory or framework for mid-air collision risk has to provide an \nunderstanding of the steps required to get from considerations of separation \nminima to estimates of that risk.  Background on separation minima is given in \nBrooker (2002) and FAA\/Eurocontrol (2001).  Their role in ATC is open to several \ninterpretations (to quote Simpson (1998): \u201cATC separation criteria is usually an \narea of confused and non-rigorous analysis\u201d).  From a system point of view, \nseparation minima are \u2018formal rules\u2019.  Originally, these standards were required \nbecause of inaccuracies in radar and altimetry data, but they are increasingly \nseen as \u2018buffers\u2019 to permit effective warnings and controller\/pilot actions.  For \npresent purposes, they are the minimum distances that controllers should permit \nbetween aircraft.   \n \nFor example, in airspace with secondary radar coverage, the controller operates \nwith 5 Nm plan (= horizontal) separation and 1000 feet vertical separation; at \nleast one of these minima must be being achieved at all times.  In the case of \nvertical separation, the minimum is interpreted as being at least one flight level \napart.  There are airspace regions that are not covered by ground-based ATC \u2013 \nthe North Atlantic (NAT) Region is an important example.  The NAT region \noperates using a structured track system with (eg) aircraft on adjacent tracks at \nthe same flight level are kept 1\u00b0 (roughly 60 Nm) apart.  This standard was \ndetermined by consideration of navigation performance rather than \u2018active\u2019 ATC - \nthe driving force to reduce separation minima is fuel penalties.  ASAS concepts \nused in the NAT region could help to reduce separation minima further, but this is \nnot discussed in the following. \n \nFor ASAS in en route airspace, to quote the FAA\/Eurocontrol (2001) document \n\u201c\u2026it is supposed that airborne separation will be provided and maintained \nby flight crews applying standardised separation minima.  Therefore, the \nmajor issue is the establishment of these \u2018airborne separation minima\u2019 so \nas to achieve safe flight operations.  Optimistic views are that airborne \nseparation minima could be much smaller than ATC radar separation \nminima and could thus allow for capacity increases.  Other views are \nmuch more reserved and warn that they might be larger than ATC radar \nseparation minima, while possibly smaller than procedural separation \nminima\u2026These separation minima will have to be established at the ICAO \nlevel...\u201d \nThere are two extremely good reasons for retaining the existing minima in an \nASAS system, certainly initially in the RES\u2019s work (aside from the complexities \ninvolved in trying to make changes, e.g. see the recent work on separation \nminima changes in an ASAS environment (Eurocontrol, 2002b)).  The first is \nelegantly set out by Quine (1987 \u2013 see also Simon, 1982), the second by Popper \n(Medawar, 1991).  Quine notes the virtue of constraints as a \u2018freedom from \n  12\ndecision\u2019: it limits the searches required.  At present, the controller does not have \nto carry out an assessment about the likelihood of a mid-air collision between \npairs of aircraft: all he or she need do is to ensure that the separation minima are \nnot breached.  Thus, a decision about what to do \u2013 and hence the possibility of \nsome kind of error \u2013 is replaced by an effective \u2018rule of thumb\u2019 that establishes \n\u2018protection criteria\u2019 between aircraft (Simpson, 1998).   \n \nPopper\u2019s point is that it is wise to retain as many features of the existing system \nin the new system as possible, and try to introduce change step by step, thereby \nminimising the problems and complexities introduced by new interactions in \nhuman-machine systems: \u2018piecemeal social engineering\u2019 is to be preferred to full \nscale re-engineering.  In particular, to change the arrangements for separation \nminima would risk burdening pilots with extra tasks beyond those that ASAS \nwould \u2018transfer from the controller\u2019. \n \nAnother viewpoint, focusing on en route capacity, is that the economic gains from \nASAS could be very substantial in terms of reductions in ground-based \noperational costs and the potential for increased capacity (see, for example, \nBrooker, 2002a and 2003).  These would far exceed any from improved \nflightpaths arising from presumably marginal changes to the separation minima.  \nSo why \u2018tinker\u2019 with the latter and hence put in jeopardy the early introduction of \nASAS?  Strategic financial decisions about ATM system-level investments are \ninherently difficult ones, because the operational adaptive skills of ATC and \nairlines tend to reduce or defer new technology benefits, while few major \nchanges produce immediate operational cost savings and revenues to airlines \nand airports (see Brooker, 2002c).   \n \nThese are different, perhaps somewhat abstract, ways of viewing the issue, but \nthe practical safety benefits of retaining separation minima can perhaps be \nsimply illustrated from a probabilistic viewpoint. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nProportion \nof time  \nat this \nseparation \ndistance \nSeparation distance \nMinimum \nNo separation \nminimum \nWith separation \nminimum \n# \n  13\n \n \nFigure 1. Effect of separation minimum of distance distributions \u2013 speculative \n \nFigure 1 speculates \u2013 note the word \u2013 on how the use of a separation minimum \nchanges the proportion of time potentially spent at close distances.  The dotted \nline is the case without a minimum, with ATC intervening only when controllers \njudge it is \u2018necessary\u2019 to prevent a potential serious conflict.  Controllers would \nprobably work with some minimum miss distance in mind.  The closest \nseparations would occur when they misjudged relative velocities or when there \nwas insufficient time to instruct pilots to manoeuvre.  There would be quite a few \nmoderately low separation values (at #) \u2013 circumstances where the aircraft were \nclose in position but in which the configuration, given relative velocities, would \nnot be judged hazardous.  These could not be allowed if a separation minimum \nwere in operation.  The dashed line shows the distribution of distances between \naircraft when using a minimum.  The effect of the minimum is to move the aircraft \npairs at \u2018near to zero\u2019 separation to \u2018greater than or near to the minimum\u2019.  Thus, \nthe key point is that risk calculations now focus on deviations from a safe value \nrather than the closeness to an unsafe one.  This offers an extra probabilistic \nlayer of safety.  Such a role for separation minima has probably been recognised \nin the past, but its importance has not received much attention.   \n5. PROBABILISTIC RISK ASSESSMENT \nThere is a huge literature on Probabilistic Risk Assessment \u2013 PRA (Probabilistic \nSafety Analysis \u2013 PSA \u2013 is also used).  PRAs try to estimate the risk of accidents \nby analysing the sequences of events that could produce an accident \u2013 the \n\u2018causal chains\u2019.  Failures arise from \u2018errors\u2019 \u2013 or indeed natural variations \u2013 from \n\u2018normal operations\u2019.  At each stage, the probability of an event\u2019s success or \nfailure in safety terms has to be quantified.  For events representing the function \nof mechanical or electronic components the failure probability can in theory, and \noften in practice, be determined by observations of the performance of that \nparticular sub-system.  An understanding of failure modes and engineering \ncharacteristics leads to a valid PRA estimate.  But complex systems generally \ncontain people who have make decisions and act on the information presented to \nthem, so some of the events require probabilities to be estimated for \u2018human \ncomponents\u2019 \u2013 the task of Human Reliability Analysis (HRA). \n \nWhile these kinds of probability might well be calculated to a good degree of \napproximation for an industrial process, it is much more difficult to produce \nestimates of these risk components for what are already rare events.  A \nnecessary ingredient is that the mechanisms and factors involved should be \ntraceable to what happens in the real world.  The models may well be \nappropriate but the difficulty is in \u2018populating\u2019 them with relevant data.  An \nexample is Foot (1994), a trial PSA of the present (sic) UK CAA en route air \ntraffic operations. This study illustrates how classical hazard analysis techniques \n  14\nmight be applied to subsystems of a complex, man-in-the-loop system to obtain \nthe collision risk.  It also demonstrates the combinatorial explosion in fault tree \ncomplexity and hence the requirement to estimate a raft of failure mode \nparameters.   \n \nThe traditional way of getting around the problem of the inherent uncertainty in \nprobabilistic risk assessment is to aim for a cautious assessment.  If it is possible \nto show that safety targets would be met, even when ignoring significant safety \nbarriers (such as TCAS \u2013 of which more later) and overestimating failure rates, \nthen the problem goes away.  Unfortunately, this seldom works even with current \nATM systems: a collection of \u2018cautious\u2019 assumptions generally tends to produce \nover-pessimistic risk estimates, and hence has little value for safety decision-\nmakers. \n \nThese difficulties with HRA methods, particularly in the nuclear power plant case, \nhave themselves generated a huge literature.  Much of the impetus for a very \ncritical approach to the subject came from a special edition of \u2018Reliability \nEngineering and System Safety\u2019 in 1990.  The editorial by Dougherty and the \npapers by Swain and Moray are good examples of the honest \u2013 and indeed wise \n\u2013 analysis of the issues.  Hollnagel\u2019s book (1993) and the more recent NATO \nconference (2001) are two instances of the continuing debate on the topic. \n \nDougherty set out the problems with HRA simply: \nInsufficient empirical data \nConcerns about use of expert judgements, particularly for rare events \nLack of confidence that simulator data matches real life \nDisconnects between modelling assumptions and psychological \nknowledge \nUse of \u2018Performance Shaping factors\u2019 to modify data \nIndeed, some behavioural scientists tend to believe that a much deeper \ntheoretical foundation is needed before quantification should be attempted.  This \nis a perfectly valid view, but not very helpful to system designers \u2013 how long do \nthey (and society) have to wait before the imprimatur of the researchers?  \nHollnagel (1993) does not discuss safety targets, but comments, re improved \ntechnology to improve ATC capacity: \n\u2026all these enabling technologies could have been developed and used to \nreduce the level of risk while keeping system utilisation constant.  In other \nwords, although flights would not have become more frequent, it would \nhave become safer to fly.\u201d \nAgain, this is a position that can be rationally held, given appropriate premises, \nbut is it fruitful for airlines and ATM system designers?  The public actually wants \nbetter safety and more flights\u2013 the TLS has been progressively reduced over the \nlast 30 years.   \n  15\nBut HRA\u2019s issues and lessons cannot be ignored.  Some quotes from Moray \n(1990) are very relevant to the ASAS case: \n\u201cThe use of \u2018expert judgement\u2019 is a polite name for \u2018expert guesses\u2019, and \nwe do not have data to validate the accuracy of the guesses. \nThe attempt to find a single number is an attempt to establish a context-\nfree universal fact about human performance.  No such thing exists.  It is \nsimply fantasy to think that the probability of human error is described by a \nsingle number\u2026 \n[Re flight crew error rates]  How do any of us survive?  The answer (and \nthe lesson) is that in the case of airliners they are quite forgiving \nsystems\u2026there is time enough, usually, to make errors, discover them, \nand recover from them. \nThe most serious design deficiency of the Chernobyl reactor was \nthat\u2026the instability was such that once it occurred there was no time to \nrecover from the error.\u201d \n \nA PSA incorporating a HRA is thus a complex \u2013 and ultimately probably correct \nmodel \u2013 that is likely only to produce usable answers at some indefinite point in \nthe future.  This cannot be the way forward in the present circumstances, and \n\u2018giving up\u2019 is surely not the conclusion that should be drawn.  There is obviously \na great deal of valuable information derived from Human Factor experiments.  \nHow can this best be used and developed?  Can a simpler model framework be \nconstructed that delivers testable results?   \n \nThe danger is therefore the creation of \u2018over-elaborate\u2019 models \u2013 ones whose \nparameters cannot be reliably estimated from the data likely to be obtainable.  \nThus, the focus has to be on the simplest model that can be soundly based on \navailable data.  Section 8 presents a possible model, but it is first necessary to \nexplore some human factors-related aspects of Airproxes and ASAS. \n6. \u2018REASONABLE INTENT\u2019 RISKS \nBrooker (2002) discusses the lessons that can be learned about potential \ncollisions by studying Airproxes; these lessons from Airproxes and other safety \nincidents are not sufficient to prevent all future types of accident \u2013 but they do \noffer some necessary tests.  The UK Airprox Board (UKAB) Report data for the \nyear 2000 revealed: \n(a) No incidents arose because of a radar accuracy or resolution problem, or \nfrom normal altimetry operation.  This is not to say that these do not exist, \nbut, on the statistical evidence here, they would be a causal factor in only \na small proportion of Airproxes.  Scans of earlier years\u2019 Airprox reports \nreveal a similar picture. \n(b) In no case did pilots or controllers express strong concerns about \ndisruption by warning systems. \n  16\n(c) Most of the Airproxes were judged by the UKAB to have been caused by \nfailures in procedures, rules, structures, or communication by both pilots \nand controllers, e.g. \u2018pilot misunderstood the ATC instruction\u2019; \u2018ATC and \npilot procedure errors\u2019; \u2018controller distraction when sector split\u2019; \u2018pilots\u2019 \npoor RT discipline\u2019; \u2018pilot procedure for altimetry in error\u2019; \u2018ATC memory \nslip\u2019. \n(d) Past UKAB Reports list as the top four causal factors: \u2018did not \nseparate\/poor judgement by controllers\u2019, level busts, \u2018did not pass\/late \npassing traffic information\u2019, poor coordination by controllers.  These \nimmediate causes in this UKAB categorisation would all seem to have \nbeen human errors of some kind. \n \nBrooker (2002) then introduces two concepts relevant to mid-air collision: \n\u2018Position Integrity\u2019 and \u2018Reasonable Intent\u2019: \nPosition Integrity:  The system has this when positional equipment for \nnavigation and surveillance is functioning \u2018normally\u2019 \u2013 when the errors on \nradar, GPS, altimetry, measurements are not extreme, when displays \nwork properly, when signals are not corrupted or lost, etc. \nReasonable Intent:  this is an inference that would usually be made \u2018after \nthe event\u2019: did the controller implement what a competent controller would \nhave considered a reasonable (albeit perhaps not perfect) course of \naction; did the pilot do something that other pilots would have judged \ndecent practice (albeit perhaps not the ideal decisions)?  It thus covers \nmisjudgements and blunders as normally understood.  It is primarily a \nhuman factors issue. \n \nIn risk budgeting terms (i.e. to compare with the TLS), if Airproxes are a good \nguide to potential mid-airs, risks from Position Integrity failure are the kinds of \nevent resulting from the loss of planned separation for which \u2018traditional\u2019 (See \nFAA\/Eurocontrol, 1998 for a historical review) collision risk models were \ndeveloped.  These models largely focused on equipment performance or failure, \nwhich would be \u2018attributable to the loss of correctly established separation\u2019.  In \npractice, these collision risk models had to be adapted to incorporate reasonable \nintent errors.  For example, even 20+ years ago, the NAT model North Atlantic \nhad to include waypoint insertion errors as well as navigation errors (Brooker and \nWhite, 1979). \n \nReasonable Intent failures are more typical of observed Airproxes, generated by \nhuman error in the widest sense.  In crude terms, the first is \u2018wrong place on right \nflight path\u2019 and the second is \u2018right place on wrong flight path\u2019.  [These types of \nevents are both \u2018first order\u2019, in that they reflect what are essentially single \nfailures, but there can also be multiple problems and specific emergencies \u2013 see \nBrooker (2002) - well covered by safety regulation \u2013 as evidenced in Profit \n(1995), and are therefore not discussed further here.] \n \n  17\nThe observed relative proportions of different types of Airprox suggest that, for \nthe current system, comparatively large proportions of the Air Traffic Services \nrisk budget should be allocated to Reasonable Intent risk.  The key argument \nhere is that mid-air collision in an ASAS environment will predominantly arise \nfrom the latter type of risk. \n \nThese types of risk cannot be calculated by a similar means to the Position \nIntegrity risks.  With these \u2018equipment\u2019 risks, it is possible to analyse relevant \ndata of what are essentially engineering observations.  By their very nature, \nReasonable Intent risks are deeply embedded in human functions and \nperformance \u2013 the subject of Human Reliability Analysis (HRA).  The problems of \nHRA\u2019s application to ATM therefore need to be solved.  This might well be a \nformidable undertaking: controllers\u2019 tasks appear to be much less structured \u2013 \ni.e. with more discretion to determine solutions \u2013 than are nuclear workers\u2019.   \n \nThe extent to which the risk in an ASAS environment would reflect the current \nsituation \u2013 where reasonable intent failures dominate \u2013 depends of course very \nmuch on how the ASAS system is designed and what is the precise role of the \nhuman.  At one extreme, in particular in an \u2018electronic Visual Flight Rules\u2019 \nenvironment, it is likely that human errors would be the dominant concern.  \nHowever, if the ASAS equipment offered solutions to conflicts, or even executed \nsome types of these solutions automatically, then the equipment performance \nwould obviously be a much more important factor.  The Airproxes examined \noccurred in a human centred operation, where equipment provides information \nfor decision-making but seldom offers solutions and never \u2018makes the decisions\u2019; \nhence it is hardly surprising that human errors were leading causal factors. \n7. ASAS SAFETY ISSUES \nWhy should one believe that an ASAS operational concept could be constructed \nthat would at least maintain and preferably increase safety?  The following \nderived from FAA\/Eurocontrol (2001) notes some key safety points: \nSituational Awareness: The flight crew is presented with flight information \nconcerning surrounding traffic, possibly in conjunction with a navigation \ndisplay or a surface map, which assists flight crews with: \n\u0083 see-and-avoid duties;  \n\u0083 avoiding blunders or errors; and  \n\u0083 information to facilitate correct decision-making.  \nAutomation: ASAS uses various sources of position and intent data.  \nASAS generates guidance to the crew for safe and timely resolution of \nconflicts or maintenance of safe separation. \nGuidance presented directly to flight crew: ASAS guidance does not \ndepend on ground-to-air communication, hence preventing the common \nhazard of missed or garbled radio communications. \n  18\n \nBut there are potential negative effects on safety.  The controller\u2019s tasks are \neither eliminated or transferred to the pilot.  Could significant features be lost?  \nCould there be new types of pilot-induced errors, or increased rates of existing \nerrors, perhaps due to increased workload? \nHuman Failure Modes \nA great deal of work has been undertaken in recent years by Eurocontrol and \nstates to develop tools and methodologies for the analysis of human error in ATM \nincidents focusing particularly on Human Factors in the resolution of incidents.  \nKey elements are the identification of the forms of human error that occur as part \nof an incident, and the decomposition of these errors to determine the \npsychological mechanisms behind the error, and hence the reasons why the \nerrors occur.  One recent technique is TRACEr (Shorrock and Kirwan, 2002): \nTRACEr provides some basic \u2018grammar\u2019 for understanding errors.   \n \nAt a high level, errors fall into a number of categories associated with the task \nthat is being performed (e.g. radar monitoring, strip handling, etc).  Each of these \nerrors can have a number of underlying causes (e.g. judgement, \nplanning\/decision-making failure, perception and vigilance failures).  The ultimate \ncause of an error is the psychological mechanism that results in the operator \nmaking an error.  Such mechanisms include perceptual tunnelling (when the \noperator focuses on one particular situation at the expense of all others) and \ninformation processing failure (where the operator\u2019s information processing \nsystem is unable to cope with the type or quantity of information presented).  For \nthe purposes of the analysis of human errors in ATM incidents, a taxonomy has \nbeen developed for task errors (Shorrock and Kirwan, 2002), shown in Figure 2 \nbelow.   \n  19\n \n \nPRESENT ATM SYSTEM \n \nController Task Errors \n \n \nSeparation \nController-pilot communications  \nRadar monitoring \nAircraft observation \/ recognition  \nCo-ordination \nControl room communications \nAircraft transfer \nFlight progress strip use  \nOperational materials checking  \nTraining, supervision, or examining \nHMI  \nOther task  \n \nPilot tasks \n \nPilot-controller communications \nAircraft handling \nVisual observation \nFlightdeck co-ordination\/communications \nOperational materials checking  \nTraining, supervision, or examining \nHMI  \nOther task  \n \n \n \n \n \n \n \nASAS SYSTEM \n \nPilot Task Errors? \n \n \nPilot-controller communications \nAircraft handling \nVisual observation \nFlightdeck co-ordination\/communications \nOperational materials checking  \nTraining, supervision, or examining \nHMI  \nSeparation \nRadar monitoring \nOperational materials checking \nOther task  \nNEW \u2013 ASAS-RELATED \n \n \n \n \n \nFigure 2. Task Error Taxonomy \n \n\u2018Separation Error\u2019 needs explanation.  These are errors associated with \ncontrollers climbing, descending or turning aircraft into conflict with other traffic \n(compare with \u2018Reasonable Intent\u2019 risks above).  \u2018Separation Error\u2019 does not \ntherefore refer to the outcome of the error, but rather an error in which the \nprescribed separation was not maintained and which was not detected in time to \nprevent the loss of separation. \n \nWhat extra types of error would be produced in an ASAS environment?  Would \nthere be increased rates for existing types?  Could pilot workload be a significant \nissue?  How loosely or tightly coupled should the system be?  Taking a key \nthought from Moray (1990): how \u2018forgiving\u2019 would the system be of errors and \nfailures?   \n  20\n8. A \u2018MINIMAL FRAMEWORK\u2019 COLLISION RISK MODEL \nDefinition of the Model \nTo try to understand how an ASAS safety proof might be developed, it is easiest \nto construct a \u2018Minimal Framework\u2019 Collision Risk model.  This probabilistic \nframework establishes logical connections and allows the several distinct \ncomponents of modelling to be examined.  It starts from aspects clearly related to \nbreaches of separation and then focuses down to collision risk.  The \ndevelopment of the framework makes apparent what are the key Human Factors \nexperiments that need to be performed, i.e. it powerfully links in these \nexperiments to risk estimation.  First, it is necessary to define some terms, which \nare then analysed.   \n \nA \u2018Significant Separation Breach\u2019 \u2013 SSB - is an event when two aircraft have lost \nseparation in all dimensions by a significant amount and action may be required \nto recover minimum separation.  \u2018Significant\u2019 means that small deviations from \nminimum separation, e.g. because of wind effects or FMS smoothing, are \ntolerated: for the moment.  However, \u2018significant\u2019 does imply that the breach is \nunacceptable \u2013 but not necessarily \u2018unsafe\u2019 or \u2018hazardous\u2019.  If the present system \nis any guide, SSBs will very probably occur through blunders and other kinds of \nReasonable Intent failure rather than Position Integrity problems (although it will \nstill be necessary to estimate the risks from the latter type of failure \u2013 e.g. \nBrooker (2004a\/b) discusses analytical calculations of collision risks arising \nsolely from radar inaccuracy).  These \u2018proximate\u2019 incidents are prima facie \ninstances of some degree of need for action to resolve possible problems \u2013 \npotential \u2018precursor\u2019 events.  Simpson (1998) offers some interesting examples of \npotential encounter criteria akin to an SSB.  As defined, an SSB would roughly \ncorrespond to Simpson\u2019s \u2018Monitoring Criteria\u2019.  An SSB might also be compared \nto an Airprox (see Brooker, 2002 for references and discussion).  The Significant \nSeparation Breach Rate \u2013 \u2018SSBR\u2019 \u2013 is the frequency of SSBs per number of \nsystem flying hours. \n \nThe next definition is the SSB\/Collision Scaling Factor \u2013 SF for short.  It is the \nratio of the long-term average of collisions to SSBs if no safety defensive barriers \nwere in place, i.e. \u2018blind flying\u2019.  It reflects the fact that an SSB has much larger \ndimensions than an aircraft, and so the SF is much less than unity. \n \nThe third definition tries to summarise detections and actions in the \u2018defensive \nbarrier\u2019 process: the \u2018Barrier Failure Probability\u2019 \u2013 BFP.  Two families of \nprobabilities need to be estimated: P(T), the probability of detection by time T \nbefore closest approach \u2013 through ASAS, TCAS and visual acquisition \u2013 and \nQ(T), the probability of effective conflict resolution given an alert at time T. \n \nWith these definitions of terms, the rate of collision CR is: \nCR = SSBR x SF x BFP, ie \n  21\nCR = SSBR x SF x { P(T) # ( 1 \u2013 Q(T) ) } \nHere the hash sign and curly brackets represent the convolution integral of the \nfunctions P(T) and ( 1 \u2013 Q(T) ), i.e. the probability densities are multiplied and the \nsummed.  The picture is a simple one \u2013 Figure 3.  \n \n \nFigure 3. \u2018Minimal Framework\u2019 collision risk model illustration \n \nThis model does need some refinement before it is a full description.  For \nexample, there is a possibility that an \u2018unnecessary\u2019 evasive manoeuvre \u2013 i.e. \nwhere the aircraft would not have collided if they had kept to their previous \nflightpaths, could result in a collision.  This is probably relatively unlikely, but \nwould need to be handled through a separate analysis.  Relevant research has \nbeen carried out by Geisinger in the context of the Analytic Blunder Model \n(referenced in FAA\/Eurocontrol, 1998).  Also relevant is the work done to \nestimate the rate of \u2018induced collisions\u2019 that occur through the use of TCAS \n(Harrison, 1993), which showed that in ideal circumstances these could be \nexpected at a rate of 4% of the existing (sic \u2013 i.e. before TCAS) risk of collision. \nEstimating the Minimal Framework Model parameters \nSignificant Separation Breach Rate \u2013 SSBR \nThe en route horizontal and vertical separation minima are taken as 5 Nm and \n1000 feet respectively.  These tend to the values used by ATC providers with \n(eg) monopulse secondary radars.  For an SSB to be defined, there needs to be \nsome judgement about what constitutes a \u2018significant\u2019 breach of these minima.  \nAs noted above, Simpson (1998) has examined this kind of issue with some \n \nSSB Rate \nScale down for \n\u2018dimensional probability\u2019 \nScale down for \u2018safety \ndefensive barriers\u2019 \nCollision Rate \n  22\nrigour.  For present purposes, the assumption is made that a horizontal breach of \n1 Nm and a vertical breach of 300 feet would count as \u2018significant\u2019.  These figures \nare \u2018not unreasonable\u2019 given the levels of navigational performance currently \nbeing achieved. \n \nHow would the SSBR be estimated?  As already noted, SSBs very probably will \nnot occur through Position Integrity problems but from failures of Reasonable \nIntent \u2013 from the consequences of human error modes of the types discussed \nabove in relation to TRACEr.  The Sherali et al (2000) and Barnett (2002) \nmodelling work are starting points.  They focus on the rate at which conflict \nprobes will be required to help resolve potential conflicts.  The next stage used to \nuse a technique such as TRACEr (Shorrock and Kirwan, 2002) to help to \ngenerate realistic and comprehensive SSBs at reasonable rates.  TRACEr \nprovides some basic \u2018grammar\u2019 for understanding errors but further modelling \nwork is required.  These are easy to write but the research tasks are probably \nvery much harder to do in practice \u2013 but it has to be done. \n \nUnfortunately, Airprox data is unlikely to be an adequate guide for SSBs.  The \npresent ATC processes generate Airproxes from what is largely a fixed route \nsystem plus tactical procedures, e.g. with pilot\/controller negotiated climbs and \ndescents.  ASAS airspace and procedures would be very different. \n \nThe range of airspaces used in this modelling would need to cover the full range \nof types of future airspace volumes and traffic densities\/patterns.  Given that \ntraffic is expected to increase considerably, ASAS would need to be able to \ndemonstrate it can cope with high frequencies of potential conflicts in highly \ndense airspace.  It would be essential to include factors that require significant \n\u2018non-direct\u2019 routeing.  An example is a military zone, either permanent or \ntemporary, which in some States these can occupy sizable airspace volumes).  \nWeather-related restrictions on particular routes and locations would also be \n\u2018natural features\u2019 in worldwide ASAS airspace.   \n \nThe TLS is derived for flights using a large volume of en route airspace.  The \nrisks in particular parts of that airspace can be different from this \u2018average figure\u2019 \n\u2013 see Brooker and Ingham (1977).  However, large deviations from the average \nTLS would not be tolerated.  In ASAS safety calculations, the risks in the different \ntypes of airspace \u2013 in the broadest sense \u2013 would therefore need to be properly \nweighted by their system flying hours.  It cannot be assumed that SSBs would \nalways occur \u2018randomly\u2019 throughout the airspace concerned.  For example, SSBs \nmight be more likely near a particular boundary point in ASAS airspace, perhaps \nwhere aircraft would be \u2018funnelled\u2019 into traditional airspace.  This could generate \nincidents where aircraft were cleared to already occupied flight levels, i.e. the \naircraft would level off at the worst possible location in risk terms (but this higher \nrisk would tend to occur for a comparatively small proportion of flying hours). \n \n  23\nSSB\/Collision Scaling Factor - SF \nSF is defined as the ratio of the long-term average of collisions to SSBs if no \nsafety defensive barriers were in place, i.e. \u2018blind flying\u2019.  It reflects the much \nlarger dimensions of an SSB compared to an aircraft.   \n \nSuppose aircraft SSB dimensions are modelled as discs (see Brooker (2002 for \nmore detail on this model and references to the earlier original work by May and \nothers).  Each SSB disc has height Hb and radius Rb as shown below.   \n \nFigure 4. SSB disc \n \nAircraft are taken as having an SSB if their discs touch.  Next, assume that discs \nare always orientated along the relative velocity vector Vr (magnitude Vr) of the \ntwo aircraft \u2013 given that aircraft generally do not change altitude at extremely \nhigh rates of climb.  [In many collision risk models, these discs are orientated in \nthe normal \u2018xyz\u2019 coordinates, but this is just a convention.  The discs are not \u2018real\u2019 \n\u2013 they just serve to \u2018envelop\u2019 the aircraft \u2013 so their orientation in the model is a \nmatter of choice.  The choice made here is convenient and has no physical or \nsafety significance, i.e. it does not influence the validity of the results.]  Now, \nmodel an SSB by an equivalent picture \u2013 taking aircraft 2 as a point and the \n\u2018protected zone\u2019 of aircraft 1 as a larger \u2018collision disc\u2019 of dimensions 2Hb and \n2Rb, in the frame of reference based on aircraft 2, i.e. in which it is at rest, as \nillustrated below   \n \n \n \n \n \n \n \n \n \n \nFigure 5. Equivalent collision disc \n \nThe \u2018cross section\u2019 of the larger collision disc viewed from Aircraft 1 is simply a \nrectangle of area proportional to Hb x Rb.  If the positions and velocities of aircraft \nin an SSB are statistically random, then the calculation of SF is one of \ngeometrical probability.  The dimensional dependence for collisions\/SSBs would \n2Rb\nHb \nVr \nAircraft 1 \nAircraft 2 \n  24\nbe in proportion to H x R, where H is the height of an aircraft and R the radius of \na collision disc just enclosing its fuselage and wingspan (Brooker, 2002 and May, \n1971). \n \nTaking the SSB dimensions as:  \nHb = 700 feet = 0.115 Nm \nRb = 4 Nm \nand the aircraft disc as: \nH = 0.010 Nm = about 60 feet \nR = 0.017 Nm = about 100 feet \ngives: \nSF = ( H x R ) \/ (Hb x Rb ) \n= 0.010 x 0.017 \/ 4 x 0.115 = 1 \/ 2,705 \nBut this very small number is not a realistic estimate, in particular because of the \nhigh accuracy of height keeping.   \n \nCurrently, thanks to improvements in altimetry, aircraft in cruise tend to fly very \nclose to their flight levels (see Brooker (2002) and Moek et al (1993) and use \nonly a few of them (see Brooker (2002), quoting Moek et al, 1993).  Most modern \njets are optimised to fly at around the tropopause, say 35,000 feet, so FL 350 \nand the immediate neighbouring flight levels are very popular.  The data from \nMoek et al (1993) on vertical errors is: for long\/medium range types, the standard \ndeviation was 85 feet; for medium\/short range types it was 155 feet.  Since 1993, \nthere have been continued strenuous efforts by airlines and ATC providers to \nimprove and monitor vertical performance, as part of the programme of work to \nreduce vertical separation above FL 290 to 1000 feet.   \n \nHowever, in a free flight ASAS scenario using existing separation minima (e.g. \nsee Hoekstra et al, 2002), acceptable flightpaths for aircraft on crossing routeings \nwould be separated by one or more flight levels.  This vertical concentration \nmeans that the likelihood of the aircraft being in \u2018vertical overlap\u2019 would be much \nthe same for both SSBs and collisions, i.e. there would be much less \n\u2018dimensional scaling down\u2019.  A simplified calculation of \u2018vertical overlap for aircraft \nflying at the same level shows the importance of the effect and the nature of the \nfunctional dependence.   \n \nDenote the aircraft height by H and the probability distribution of heights about \nthe flight level by f(v).  For a second aircraft at a distance Y from the flight level \nthe probability of the two aircraft being in vertical overlap is: \n\u222b +\u2212 HY HY dvvf )(  \n  25\nIf this is summed over all possible Y values, this gives the probability of vertical \noverlap as: \nPz(0) = \u222b \u221e\u221e\u2212 )(Yf \u222b +\u2212 HY HY dYdvvf )(  \nThe zero in the function is just a reminder that the aircraft are intended to be at \nthe same altitude z.  It can be assumed that f is a well-behaved function that can \nbe expanded out in a Taylor series, to give: \nPz(0) = dYtermscubicHYfYf }2).({)(\u222b \u221e\u221e\u2212 +  \nThe quadratic terms cancel out in the expansion.  If the cubic terms can be \nneglected this becomes: \nPz(0) \u2245  2H dYYf\u222b \u221e\u221e\u2212 2)]([  \nThe integrand\u2019s dependence on [ f(Y)] 2 is important.  As an illustration, taking \nf(Y) as double exponential (not too far from Moek et al\u2019s observed height keeping \ndata) gives: \n[ ] 1\/ 2.)( \u2212\u2212= \u03bb\u03bbYeYf              [NB: The standard deviation of f(Y) is \u221a2\u03bb .] \nThis gives: \nPz(0) = H \/ 2\u03bb  \nThus, an aircraft disc of height 60 feet and a \u03bb  value of 60 feet would give a \nPz(0) of 0.5.  In practice, f(Y) could be estimated in the same ways used in earlier \nstudies (eg, Moek et al, 1993), so the integrals could be computed numerically \u2013 \nand might well show that the cubic terms above should not be neglected.   \n \nIn the horizontal dimension, the ratio of Rb to R would be 4 to 0.017, i.e. 235.  \nMultiplying this by 2, i.e. assuming independence between vertical and horizontal \nprobability distributions, gives SF as about 1 in 470. \n \nNote the need for \u2018randomness\u2019 in this calculation.  It is possible to think of ways \nin which the relative velocity vector might not be uniformly distributed in the Rb \ndimension, e.g. with the funnelling effect noted earlier.   \n \nBarrier Failure Probability\u2019 \nThe previous elements in the calculation presented \u2013 \u2018blind flying\u2019 in the fullest \nsense \u2013 do not include the safety defensive barrier effects of automatic warning \nsystems and controller\/pilot action, including the effectiveness of See-and-Avoid.  \nBFP measures the effectiveness \u2013 or rather the possibility of failure \u2013 of these \nbarriers.  The present system has three main safety barriers: \n  26\n \nConflict Alert (STCA) \u2013 The ground computer processing system has the \nfacility for analysing SSR tracks to predict if aircraft might come into close \nproximity in the near future and, if they do, warn the controller by flashing \na message on his radar screen.  Subsequent controller instructions would \nbe \u2018normal\u2019, e.g. would generally tend to separate the aircraft by horizontal \nvectoring. \nTraffic alert and Collision Avoidance System TCAS (generically ACAS II) \n[The abbreviation TCAS will be used here, except in quoted text, to \nemphasize the difference between ASAS and TCAS] \u2013 An on board \ncollision avoidance system based on detection of other aircraft in the \nvicinity carrying SSR transponders.  These tell the pilot of nearby traffic \u2013 \nTA (Traffic Advisory) \u2013 and aircraft coming into conflict \u2013 RA (Resolution \nAdvisory).  RAs tell the pilot to climb or descend as appropriate to take it \nout of risk with immediate action. \n\u2018See-and Avoid\u2019 \u2013 The pilot visually searches for other aircraft, and then \nchanges course if this is necessary to avoid them.  Aircraft crew are \nexhorted to maintain vigilance so as to see and avoid potential mid-air \ncollisions. \nOther elements also contribute to safety of course, such as the `party line' effect \nin voice communications and the crew's experience about what generally \nhappens at particular locations and routeings.   \n \nWith Full Delegation, ASAS takes over the role of STCA.  ASAS is used to \nensure that the separation minima between aircraft is maintained; TCAS provides \na final independent backup system if the separation minima are breached and \nthere is risk of collision.  See-and-avoid would be the \u2018last resort\u2019 safety tool.  \nASAS conflict detection would operate 10 to 20 minutes before the closest point \nof approach (CPA), while TCAS provides traffic advisories 20 to 50 seconds \nbefore CPA and Resolution Alert (RA) gives warnings 35 seconds before CPA \n(Eurocontrol, 2002a).  ASAS would need to be integrated \u2013 both in terms of \nequipment and in operational usage \u2013 with an aircraft\u2019s TCAS (e.g. see Abeloos \net al (2000), Zeitlin and Bonnemaison (2000), and Zeitlin (2001), and later text in \nthis section regarding independence and common mode failures).   \n \nShould the effects of al these three be taken into in the risk calculations to \nestimate an ALS to be compared with the TLS?  These are examined in reverse \norder. \n \nA major study on See-and-Avoid (BASI, 1991) concluded that in visual \nconditions, in the absence of some form of traffic alert, the probability of a pilot \nvisually acquiring a threat aircraft is generally low until a short time before CPA.  \nFor commercial aircraft speeds, See-and-Avoid usually failed to alert potential \ncollisions.  Even under the best conditions, visual search can be like \u2018looking for \na needle in a haystack\u2019, and in poor visibility the chance of it succeeding would \n  27\nbe negligible.  Thus, the pilot cannot reliably visually acquire other traffic or \nconsistently.  Trials under test flight conditions suggest that visual acquisition \nalone (i.e. without any \u2018cues\u2019 from an alerting system), is less than 50% effective \n(Moore, 1998). \n \nHence, See-and-Avoid, whilst it plays a useful role, does not reduce risk by a \nquantitatively significant amount.  Moreover, for aircraft flying under IFR, it seems \nrather dubious to be reliant on non-instrument means for any part of the \nprotection against catastrophic system failures \u2013 which a mid-air collision would \ncertainly represent.  Thus, there is not a strong argument for risk reduction from \nSee-and-Avoid being estimated in the ALS. \n \nTCAS is rather different \u2013 but there are some differing views about its \u2018safety \nsystem function\u2019 (FAA\/Eurocontrol 2001).  TCAS was introduced in order to \nreduce the risk of mid-air collisions; and has been designed to operate in all \nairspace.  Thus \u2013 paragraph 2.2.6 \u2013 it presently \u2018serves as a last resort safety \nnet, irrespective of any separation standards\u2019 appropriate to airspace categories, \nand \u2019it has no other role in the ATM system\u2019.  FAA\/Eurocontrol (2001) notes that \nICAO documents indicate that:  \nThe provision of ATC services in a given airspace shall not be based on \nthe ACAS equipage of the aircraft; and  \nAir traffic control units shall provide the same services to ACAS and non-\nACAS aircraft.   \nOn this basis, ATC procedures have to be judged safe without considering the \neffect of the TCAS safety net \u2013 so TCAS in practice helps to prevent mid-air \ncollisions, but gets no \u2018credit\u2019 for this in system safety assessment. \n \nFAA\/Eurocontrol (2001) comments (paragraph 3.2): \n\u201cFollowing appropriate clearances and instructions results in separation \nminima being maintained and thus ensuring safety.  Separation minima \nare established such that the risk of collision is at an acceptable level.  \nThe other processes by which the flight crews avoid collisions also \ncontribute to reducing the risk of collision, but they do so in an \nunquantified way\u2026The use of ACAS does not amount to separation \nprovision because it provides no guarantee that the risk of collision is \nreduced to an acceptable level.\u201d \nSo, on this view: \n\u201cIn normal circumstances, when separation (ATC or flight deck) is \nprovided, airborne collision avoidance should not be necessary.  \nApplications implementing airborne separation should achieve the \napproved Target Level of Safety (TLS) independently from airborne \ncollision avoidance.\u201d \n \n  28\nAlthough these views can be comprehended, they do not seem very rational \nones in terms of the development of TLSs and collision risk modelling.  TLSs and \nALSs are by their very nature statistical statements rather than \u2018guarantees\u2019.  To \nreiterate an earlier point, collisions decades ago might have been more likely to \nbe caused by equipment and navigation hardware problems, but today\u2019s \nAirproxes and other incident data shows that the highest likelihood for collision \narises \u2013 in crude terms \u2013 from being in the \u2018right place but on the wrong flight \npath\u2019.  The view that separation minima somehow \u2018guarantee safety\u2019 by \nprotecting against \u2018technical errors\u2019 on the flight path is therefore wrong.  \nSeparation minima of themselves do not guarantee safety, any more than a road \nspeed limit prevents car crashes.  It is actually the control of the \u2018failure rate\u2019 \nwhen minima are breached that delivers the required safety.   \n \nAs already stressed, collisions are most likely to be caused by human error in the \nlargest sense \u2013 and these would be very infrequent probabilistic events.  \nSeparation minima and TCAS alerts are different ways of providing a safety \nbarrier against this possibility, and these barriers are, to different degrees, \nstatistical in nature rather than providing \u2018guarantees\u2019.  One of them reduces the \ncomplexity of decisions that controllers have to take; the other alerts pilots and \ncontrollers to the need to take a decision.  Both of them are now integral parts of \nthe ATM safety system \u2013 so why should only one of them be included in risk \ncalculations? \n \nA major problem is that a flawed definition of \u2018ATM system\u2019 appears to have been \nadopted by Eurocontrol (e.g. in Eurocontrol SRC (2000a) \u2013 \u2018ESARR 4\u2019) and \nICAO.  Surely, the most rational definition would be something on the lines of:  \nATM system: Everything that contributes to the safe movement of air \ntraffic \u2013 the \u2018Total System\u2019. \nThe prime goal of the ATM system on this definition is to control risks.  Safety in \nATM is \u2018the interaction between Procedures, People and Equipment\u2019 \n(Baumgartner, 2003).  The pilot is part of this ATM system.  In the current \nsystem, the controller generally has greater knowledge of the ATM environment \nand the risks posed by neighbouring aircraft than does the pilot.  But Total \nSystem safety depends on the pilot\u2019s actions, which include following instructions \nfrom the controller and that the pilot acts in accord with TCAS alerts. \n \n  29\nMoreover, and essentially continuing the discussion in Section 3, the TLS was \nnever intended to be a measure of \u2018acceptable air traffic control failure\u2019 but to be \na target that the ATM system should achieve.  The TLS was not developed on \nthe basis that certain types of system, technology or procedure would either be \npresent or absent.  The risk calculations for an ATM system\u2019s ALS were seen as \npotentially including all mitigating factors, from controller monitoring and \nintervention to automatic warning systems.  The TLS was not therefore produced \nin the context of the causal factors or mechanisms by which safety is either at \nrisk from or by which it is assured.  The ICAO teams that developed the TLS \nphilosophy did not a priori rule out the use of systems such as TCAS in delivering \nthe TLS (Brooker and Ingham (1977) sets out the key references).  In the modern \nday, the point is well illustrated by Baumgartner\u2019s (2003) definition: \u201cTLS: The \nlevel of safety which the total system is designed to meet\u201d.   \n \nThese comments can only scratch the surface of the issues involved in setting \nthe right future policy for the inclusion \u2013 or otherwise \u2013 of TCAS in hazard \nanalyses.  Further papers will endeavour to achieve a fuller analysis, with \ndetailed critiques of present ICAO and Eurocontrol policy, including ESARR 4 \n(Eurocontrol SRC, 2000a). \n \nReturning to the calculation of Barrier Failure Probability: the  two generic terms \nP(T) and 1 \u2013 Q(T) in BFP, the first is, leaving aside See-and-Avoid elements, \nequipment-based, while the second depends on human performance given an \nalert.  In both cases, these probabilities are averaged over the range of \nencounters.  It needs to be stressed that all the parameters in the Minimal \nFramework Model are long-term averages for the airspaces under consideration \n\u2013 remembering that the TLS is itself a long-term average rate for mid-air collision \naccidents. \n \nEstimates of P(T) can be made by simulating the operation of ASAS and TCAS \non representative aircraft encounters.  In the past, before these types of \nequipment were in common use, this could be done by using radar encounter \ndata.  A good example using UK data is the study by Hale and Law (1989).  This \nwas very important work because it showed inter alia that all genuinely \u2018serious\u2019 \nencounters, out of a sample of more than a thousand aircraft pairs, were \ndetected by both systems.  Its key conclusion was that \u2018the majority of conflicts \nlikely to result in a TCAS RA would have been already alerted to the controller in \ngood time to anticipate the RA\u2019. \n \nFor the full delegation scenario, ASAS would have to be demonstrated to deliver \nat least equal performance to STCA, because it has to provide equivalent \nfunctionality.  There are important issues here about the extent that ASAS and \nTCAS equipments use the same information sources and how they are \nintegrated in aircraft systems.  Abeloos et al (2000) suggest that surveillance \ndata fusion of ADS-B and TCAS could improve airborne surveillance \nperformance; and recommend that ASAS and TCAS data be presented on the \n  30\nsame display.  Zeitlin and Bonnemaison (2000) note the importance of \nTCAS\/ASAS independence, and in particular stress that any loss of ASAS \nfunctions must not be detrimental to the functioning of TCAS, given its \n\u2018independent last resort\u2019 requirement.  Hence, it is vital to understand the risks \nposed by \u2018common mode\u2019 failures and how they might be mitigated. \n \nEstimates of 1 \u2013 Q(T) require simulation by aircrew, across the whole range of \ncategories of encounter examined for P(T).  Simulations of probability of \ndetection for \u2018seeded errors\u2019 are necessary to test out the resilience of the \nsystem.  The aim is to build confidence in the adaptability of the system rather \nthan produce any kind of statistical proof.  Resilience in this context is the \nnumber of safety barriers that are operative, but also has to provide assurance \nthat system safety reaction times are sufficient.  These seeded errors in \nsimulation have to match the types of things that can happen, i.e. as generated \nby the error processes that lead to significant safety breaches.  A further check \nwould be to verify that all existing types of Airproxes are resolved.   \n \nHow can it be known that the results of such simulations are \u2018right\u2019, or rather that \nthey can deliver the kinds of statistical statements that are required?  As noted in \nan earlier Section, the contributors to the special edition of \u2018Reliability \nEngineering and System Safety\u2019 in 1990 raised several wise concerns about \nsimulation and the need for validation.   \n \nSome simple comments need making here.  To start with, it is a question of \nconfidence in results.  Simulation can be an effective tool, but the trials must take \nplace over comparatively long periods to eliminate unfamiliarity with new \nprocesses.  Fortunately, ASAS as envisaged here requires aircraft\/pilot \nsimulation rather than workstation\/controller simulations.  Aircraft simulators can \nnow be very realistic, as evidenced by the realistic behaviour of pilots in \nemergency scenarios.  But the estimation of the BFP must also guard against \naircrew being too aware that some kind of abnormal incident has been \nprogrammed.  Thus, it is vital to test seeded \u2018blunders\u2019 in the context of a \nreasonably long stretch of normal operations rather than just present the aircrew \nwith a high rate of blunders.  \n9. CONCLUSIONS \nWith Full Delegation Airborne Separation Assurance System (ASAS), separation \ncontrol would be delegated to the (properly equipped) aircraft, i.e. aircraft pilots \nare responsible for their aircraft\u2019s separation from other flights.  The aim is to try \nto identify a tangible work programme \u2013 rational and evidence based, and within \nthe compass of known techniques \u2013 a framework that would prove safety.   \n \nReasons for retaining the existing separation minima in an ASAS system have \nbeen put forward.  The observed relative proportions of different types of Airprox \nsuggest that, for the current system, comparatively large proportions of the Air \n  31\nTraffic Services risk budget should be allocated to \u2018Reasonable Intent\u2019 risk \n(effectively \u2018right place on wrong flight path\u2019).  The key argument here is that mid-\nair collision in an ASAS environment will predominantly arise from this type of \nrisk.  Problems with the use of Probabilistic Risk Assessment with safety-critical \nevents requiring probabilities to be estimated for \u2018human components\u2019 \u2013 Human \nReliability Analysis \u2013 are reviewed.   \n \nThe danger is the creation of \u2018over-elaborate\u2019 models \u2013 ones whose parameters \ncannot be reliably estimated from the data likely to be obtainable.  Thus, the \nfocus has to be on the simplest model that can be soundly based on available \ndata.  A simple \u2018Minimal Framework\u2019 Collision Risk Model is therefore \nconstructed \u2013 which potentially can deliver practical results.  It has three \ncomponents:  \nSignificant Separation Breaches (SSB) \u2013 events when two aircraft have \nlost separation in all dimensions by a significant amount and action may \nbe required to recover minimum separation;  \nSSB\/Collision Scaling Factor (SF) \u2013 the ratio of the long term average of \ncollisions to SSBs if no safety defensive barriers were in place; and the  \nBarrier Failure Probability (BFP) \u2013 the probability of failure of safety \ndefensive barriers such as automatic warning systems.  \nThe analysis here shows that these factors can be modelled by: \nSSBR \u2013 airspace geometry\/traffic pattern plus human error simulation \nSF \u2013 kinematics of encounters \nBFP \u2013 equipment and human performance knowledge\/simulations \nMany of the building blocks for these already exist.  This structure therefore \nenables these components to be integrated with specific additional work to be \ndeveloped from well-specified experiments.  But the challenge is to develop \nfocused simulation tools and structured experiments to deliver quantitative \noutputs \u2013 results that are sufficiently convincing for the Rational Evidence \nScrutiniser of Section 2.  To reiterate the key point in that section\u2019s debate, this \ndegree of \u2018confidence\u2019 can only come about through the creation of a compelling \n\u2018narrative\u2019 explanation, soundly based in theoretical understanding and empirical \nevidence, and open to challenge, checking and verification at every stage.   \n \nIf this approach does not work, then what could? \nACKNOWLEDGEMENTS \nThis work was supported by a research grant by the Civil Aviation Authority\u2019s \nSafety Regulation Group (SRG).  I would like to thank SRG staff and Ian Parker \nof National Air Traffic Services Ltd (NATS) for their comments on earlier drafts, \nand the referees for their cogent criticisms.  I would also like to thank Ian Parker \n  32\nand Barry Kirwan of Eurocontrol for bringing me up to date on some current work \non some strategic safety and human factors issues. \n  33\nREFERENCES \nAbeloos, A., Mulder, M., van Paasen, R. and Hoffman, E. (2000). Potential co-\noperations between the TCAS and the ASAS.  International Conference on \nHuman-Computer Interaction in Aeronautics (HCI-Aero 2000). Toulouse, 27-29 \nSeptember 2000.http:\/\/www.eurocontrol.fr\/projects\/freer\/archive\/hci_aero.pdf. \nAmalberti, R., (2001). The paradoxes of almost totally safe transportation \nsystems, Safety Science 37, 109-126. \nBarnett, A., (2000). Free-Flight and en route air safety: a first-order analysis, \nOperations Research 48(6), 833-845. \nBASI, (1991). Limitations of the See-and-Avoid Principle. Australian Department \nof Transport and Communications. \nBaumgartner, M. (2003). One safe sky for Europe \u2013 A revolution in European \nATM.  The Controller, July, 8-12. \nBrooker, P. (2002a) Future Air Traffic Management \u2013 Passing the Key Tests, The \nAeronautical Journal, 106(1058), 211-215. \nBrooker, P. (2002b). Future Air Traffic Management: Quantitative En Route \nSafety Assessment Part 2 \u2013 New Approaches. Journal of the Institute of \nNavigation 55(3), 363-379. \nBrooker, P. (2002c) Future Air Traffic Management Systems and Financial \nDecision-Making Constraints. Cranfield University Research Report PB\/3\/1\/02, \nISBN 1 861940 85 8 \u2013 to appear in \u2018Transportation\u2019 in a shortened form].  \nBrooker, P. (2003). Future Air Traffic Management: Strategy and Control \nPhilosophy. The Aeronautical Journal, 107(October), 589-598. \nBrooker, P. (2004a) Radar Inaccuracies and Mid-Air Collision Risk: Part 1 - a \nDynamic Methodology \u2013 to appear in the \u2018Journal of the Institute of Navigation\u2019. \nBrooker, P. (2004b) Radar Inaccuracies and Mid-Air Collision Risk: Part 2 - En \nRoute Radar Separation Minima \u2013 to appear in the \u2018Journal of the Institute of \nNavigation\u2019. \nBrooker, P. and Ingham, T. (1977). Target Levels of Safety for Controlled \nAirspace. CAA Paper 77002. CAA, London. \nBrooker, P. and White, F. A. (1979). Minimum Navigation Performance \nSpecification and Other Separation Variables in the North Atlantic Area. Journal \nof the Institute of Navigation, 32(3) 357-374. \nThe Chambers Dictionary, (1998). Chambers Harrap, Edinburgh. \nDavies, E. H. and Sharpe, A. G. (1993). Review of the Target Level of Safety for \nNAT MNPS Airspace. CS Report 9301. NATS, London. \nDougherty, E. M. (1990). Human reliability analysis \u2013 where shouldst thou turn? \nReliability Engineering and System Safety, 29, 283-299. \n  34\nEC (European Commission) Transport RTD Programme, (1999). Emerald \n(Emerging RTD Activities of relevance to ATM Concept Definition) \u2013 Final \nSummary Report. http:\/\/www.cordis.lu\/transport\/src\/emeraldrep.htm \nEurocontrol (1998). EATMS Validation Strategy Document.  \nhttp:\/\/www.eurocontrol.int\/eatmp\/library\/documents\/EATMS_Validation_Strategy.\npdf \nEurocontrol (2002a). ACAS brochure. \nhttp:\/\/www.nbaa.org\/intl\/acas2_training_brochure.pdf \nEurocontrol (2002b). Investigation of experience in modeling and determining \nseparation minima. CARE-ASAS Activity 3. \nhttp:\/\/www.eurocontrol.int\/care\/asas\/documentation\/care-asas-a3-01-019.pdf \nEurocontrol SRC [Safety Regulation Commission] (2000a). Risk Assessment and \nMitigation in ATM. Eurocontrol Safety Regulatory Requirement ESARR 4. Edition \n1.0. Eurocontrol, Brussels. \nEurocontrol SRC (2000b). Safety Minima Study: Review of Existing Standards \nand Practices. SRC Doc 1, Eurocontrol, Brussels. \nhttp:\/\/www.eurocontrol.be\/src\/index.html \nFAA\/Eurocontrol (1998). A Concept Paper for Separation Safety Modeling An \nFAA\/EUROCONTROL Cooperative Effort on Air Traffic Modeling for Separation \nStandards http:\/\/www.faa.gov\/asd\/ia-or\/pdf\/cpcomplete.pdf \nFAA\/Eurocontrol (2001). Cooperative R&D: Principles of Operation for the Use of \nAirborne Separation Assurance Systems (Version: 7.1) http:\/\/human-\nfactors.arc.nasa.gov\/ihi\/documents\/PO-ASAS.pdf \nFoot, P.B. (1994). A Review of the Results of a Trial Hazard Analysis of Airspace \nSectors 24 and 26S. CS Report 9427, Civil Aviation Authority, London. \nHacking, I. (1976). Logic of Statistical Inference, Cambridge University Press, \nCambridge. \nHale, S. and Law, M. (1989). Simultaneous Operation of Conflict Alert and ACAS \nII in UK En-Route Airspace. DORA Report 8914, CAA. \nHarrison, D. (1993). Results of ACAS II Safety Analysis. ICAO Secondary \nSurveillance Radar Improvements and Collision Avoidance Systems Panel \n(SICASP\/5) \nHarrison D. and Moek G. (1992). European Studies to Investigate the Feasibility \nof using 1000 ft Vertical Separation Minima above FL 290: Part II \u2013 Precision \nData Analysis and Collision Risk Assessment. Journal of the Institute of \nNavigation, 45, 91-106. \nHoekstra, J. M., Van gent, R. N. H. W., Ruigrok, R. C., J. (2002). Designing for \nsafety: the \u2018free flight\u2019 air traffic management concept. Reliability Engineering and \nSystem Safety 75, 215-232. \n  35\nHollnagel E., (1993). Human Reliability Analysis: Context and Control, Academic \nPress, London. \nMay, G. (1971). A Method for Predicting the Number of Near Mid-Air Collisions in \na Defined Airspace. Journal of the Institute of Navigation, 24, 204-218. \nMedawar, P., (1991). The Threat and the Glory, Oxford University Press. \nMoek, G., ten Have, J. M., Harrison, D. and Cox, M. E. (1993). European Studies \nto Investigate the Feasibility of using 1000 ft feet Vertical Separation Minima \nabove FL 290: Part III \u2013 Further Results and Overall Conclusions. Journal of the \nInstitute of Navigation, 46, 245-261. \nMoore, S. M., (1998). Comparison of Alerted and Visually Acquired Airborne \nAircraft in a Complex Air Traffic Environment. Proceedings of the 1998 advances \nin aviation safety conference, SAE\/P-321, 981205,held at Daytona Beach, \nFlorida, April 6-8, 1998. SAE. \nMoray, N., (1990). Dougherty\u2019s Dilemma and the One-sidedness of Human \nReliability Analysis Reliability Engineering and System Safety, 29, 337-344. \nNATO RTO Meeting Proceedings 32 (2001). The Human Factor in System \nReliability \u2013 Is Human Performance Predictable? RTO-MP-032. \nQuine, W. V., (1987). Quiddities: an intermittently philosophical Dictionary, \nBellknap Press of Harvard University Press, Cambridge, Mass., USA. \nReview of the General Concept of Separation Panel (RGCSP) (1995). Working \nGroup A Meeting: Summary of Discussions and Conclusions. (1995). ICAO. \nSherali, H. D., Smith, J. C., Trani, A. A. and Sale, S. (2000). National \nAirspace\\Occupancy and Conflict Analysis Models for Evaluating Scenarios \nunder the Free-Flight Paradigm. Transportation Science 34(40). 321-336. \nShorrock, S. T. and Kirwan, B. (2002). Development and application of a human \nerror identification tool for air traffic control. Applied Ergonomics 33 319\u2013336. \nSimon, H.A., (1982). Models of Bounded Rationality (Vols. 1 & 2). Cambridge, \nMA, MIT Press. \nSimpson, R. W., (1998). Structuring Criteria for automated separation assurance, \n2nd USA\/Europe Air Traffic Management R&D Seminar. http:\/\/atm-seminar-\n98.eurocontrol.fr\/finalpapers\/track2\/simpson.pdf \nSwain, A. D., (1990). Human Reliability Analysis: Needs, Status, Trends and \nLimitations Reliability Engineering and System Safety, 29, 301-313. \nTHEATRE website, (2002). http:\/\/www.theatre.isdefe.es\/home.sys.html?forum \nWatson, S. R., (19945). The meaning of probability in probabilistic safety analysis \nReliability Engineering and System Safety 45, 261-269. \nWatson, S. R., (1995). Response to Yellman, T.W., and Murray, T. M., (1995). \nComment on \u2018The meaning of probability in probabilistic safety analysis\u2019 \nReliability Engineering and System Safety 49, 207-209. \n  36\nYellman, T.W., and Murray, T. M., (1995). Comment on \u2018The meaning of \nprobability in probabilistic safety analysis\u2019 Reliability Engineering and System \nSafety 49, 201-205. \nZeitlin, A. D. and Bonnemaison, B., (2000). Managing Criticality of ASAS \nApplications. 3rd USA\/Europe Air Traffic Management R&D Seminar. \nhttp:\/\/www.caasd.org\/library\/presentations\/zeitlin.pdf \nZeitlin, A. D., (2001). Safety Assessments of ADS-B and ASAS, 4th USA\/Europe \nAir Traffic Management R&D Seminar. \nhttp:\/\/www.mitre.org\/support\/papers\/tech_papers_01\/zeitlin_safetya\/zeitlin_safety\n.pdf \n"}
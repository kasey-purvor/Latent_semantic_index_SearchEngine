{"doi":"10.1016\/j.apnum.2010.10.012","coreId":"196840","oai":"oai:lra.le.ac.uk:2381\/9044","identifiers":["oai:lra.le.ac.uk:2381\/9044","10.1016\/j.apnum.2010.10.012"],"title":"An Optimization Approach to Weak Approximation of Stochastic Differential Equations with Jumps","authors":["Kashima, Kenji","Kawai, Reiichiro"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-01-06","abstract":"We propose an optimization approach to weak approximation of stochastic differential equations with jumps. A mathematical programming technique is employed to obtain numerically upper and lower bound estimates of the expectation of interest, where the optimization procedure ends up with a polynomial programming. A major advantage of our approach is that we do not need to simulate sample paths of jump processes, for which few practical simulation techniques exist. We provide numerical results of moment estimations for Dol\u00e9ans\u2013Dade stochastic exponential, truncated stable L\u00e9vy processes and Ornstein\u2013Uhlenbeck-type processes to illustrate that our method is able to capture very well the distributional characteristics of stochastic differential equations with jumps","downloadUrl":"http:\/\/www.sciencedirect.com\/science\/journal\/01689274,","fullTextIdentifier":"https:\/\/lra.le.ac.uk\/bitstream\/2381\/9044\/1\/opt1.pdf","pdfHashValue":"4fa3dea81aff2c4f40a0e94460c4f29c8e4b6174","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:lra.le.ac.uk:2381\/9044<\/identifier><datestamp>\n                2015-12-10T16:04:00Z<\/datestamp><setSpec>\n                com_2381_445<\/setSpec><setSpec>\n                com_2381_9549<\/setSpec><setSpec>\n                col_2381_3823<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nAn Optimization Approach to Weak Approximation of Stochastic Differential Equations with Jumps<\/dc:title><dc:creator>\nKashima, Kenji<\/dc:creator><dc:creator>\nKawai, Reiichiro<\/dc:creator><dc:subject>\nDol\u00e9ans\u2013Dade stochastic exponential<\/dc:subject><dc:subject>\nL\u00e9vy processes<\/dc:subject><dc:subject>\nStochastic differential equations<\/dc:subject><dc:subject>\nTruncated stable process<\/dc:subject><dc:subject>\nOrnstein\u2013Uhlenbeck-type process<\/dc:subject><dc:subject>\nPolynomial programming<\/dc:subject><dc:subject>\nWeak approximation<\/dc:subject><dc:description>\nWe propose an optimization approach to weak approximation of stochastic differential equations with jumps. A mathematical programming technique is employed to obtain numerically upper and lower bound estimates of the expectation of interest, where the optimization procedure ends up with a polynomial programming. A major advantage of our approach is that we do not need to simulate sample paths of jump processes, for which few practical simulation techniques exist. We provide numerical results of moment estimations for Dol\u00e9ans\u2013Dade stochastic exponential, truncated stable L\u00e9vy processes and Ornstein\u2013Uhlenbeck-type processes to illustrate that our method is able to capture very well the distributional characteristics of stochastic differential equations with jumps.<\/dc:description><dc:date>\n2011-02-08T10:53:30Z<\/dc:date><dc:date>\n2011-02-08T10:53:30Z<\/dc:date><dc:date>\n2011-01-06<\/dc:date><dc:type>\nArticle<\/dc:type><dc:identifier>\nApplied Numerical Mathematics, 2011,  61 (5), pp. 641-650<\/dc:identifier><dc:identifier>\n0168-9274<\/dc:identifier><dc:identifier>\nhttp:\/\/www.sciencedirect.com\/science\/article\/pii\/S0168927411000110<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2381\/9044<\/dc:identifier><dc:identifier>\n10.1016\/j.apnum.2010.10.012<\/dc:identifier><dc:language>\nen<\/dc:language><dc:rights>\nThis is the author\u2019s final draft of the paper published as Applied Numerical Mathematics, 2011,  61 (5), pp. 641-650.  The final published version is available at http:\/\/www.sciencedirect.com\/science\/journal\/01689274, Doi: 10.1016\/j.apnum.2010.10.012.<\/dc:rights><dc:publisher>\nElsevier<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["0168-9274","issn:0168-9274"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2011,"topics":["Dol\u00e9ans\u2013Dade stochastic exponential","L\u00e9vy processes","Stochastic differential equations","Truncated stable process","Ornstein\u2013Uhlenbeck-type process","Polynomial programming","Weak approximation"],"subject":["Article"],"fullText":"An Optimization Approach to Weak Approximation of Stochastic\nDifferential Equations with Jumps\nKENJI KASHIMA\u0003 AND REIICHIRO KAWAI\u2020\nAbstract\nWe propose an optimization approach to weak approximation of stochastic differential equations with\njumps. A mathematical programming technique is employed to obtain numerically upper and lower\nbound estimates of the expectation of interest, where the optimization procedure ends up with a poly-\nnomial programming. A major advantage of our approach is that we do not need to simulate sample\npaths of jump processes, for which few practical simulation technique exist. We provide numerical re-\nsults of moment estimations for Dole\u00b4ans-Dade stochastic exponential, truncated stable Le\u00b4vy processes\nand Ornstein-Uhlenbeck-type processes to illustrate that our method is able to capture very well the\ndistributional characteristics of stochastic differential equations with jumps.\nMSC: 60H10, 65C30, 60G51, 90C22.\nKeywords: Dole\u00b4ans-Dade stochastic exponential, Le\u00b4vy processes, stochastic differential equations, trun-\ncated stable process, Ornstein-Uhlenbeck-type process, polynomial programming, weak approximation.\n1 Introduction\nStochastic differential equations have long been used to build realistic models in economics, finance, biol-\nogy, the social sciences, chemistry, physics and other fields. In most active fields of application, dynamics\nwith possible sudden shift have become more and more important. To model such shifts, one would like\nto employ stochastic differential equations where the underlying randomness contains jumps. Regardless\nof its practical importance, the theory and the computational techniques of the stochastic differential equa-\ntions with jumps have not been developed as thoroughly as in the diffusion case. As nice references on the\nsubject, we refer to Applebaum [1], Bass [2] and Situ [21].\nFrom a practical point of view, the sample paths approximation of stochastic differential equations has\nbeen a central issue for the purpose of numerical evaluation and simulation on the computer. There are two\nnotions of the approximation; strong and weak approximations. On one hand, strong approximation schemes\nprovide pathwise approximations E[kXT \u0000XDT k2]\u0014CDb , where D2 (0;1) is the maximum stepsize of a time\ndiscretization fXDt : t 2 [0;T ]g, where C is a positive constant and b is the order of the approximation. The\nstrong approximation is used for scenario analysis, filtering or hedge simulation. For applications such as\nderivative pricing, on the other hand, the computation of moments or expected utilities, we need to estimate\nthe expected value of a function of marginals, or a functional of sample paths. In those cases, the so-\ncalled weak approximations are sufficient, that is, jE[V (XT )]\u0000E[V (XDT )]j \u0014 CDb , where V is a suitable\nsmooth function satisfying some polynomial growth condition at infinity. Other applications of the weak\napproximation include the computation of functional integrals, invariant measures, and Lyapunov exponents.\nPublished in Applied Numerical Mathematics (2011) 61(5) 641-650.\n\u0003Email address: kashima@mei.titech.ac.jp. Postal address: Graduate School of Information Science and Engineering, Tokyo\nInstitute of Technology, Tokyo, 152-8552, Japan.\n\u2020Corresponding author. Email address: reiichiro.kawai@gmail.com. Postal address: Department of Mathematics, University of\nLeicester, Leicester LE1 7RH, UK.\n1\nTheoretical properties of time discretization schemes are mostly studied for the diffusion case. See Kloeden\nand Platen [9] for detailed investigations. For stochastic differential equations with jumps, the weak rate of\nconvergence of Euler-Maruyama schemes is studied, for example, in Liu and Li [12], Kubilius and Platen\n[10], Protter and Talay [17], and Jacod et al. [5]. Jump-adapted discretization is investigated, for example,\nin Bruti-Liberati and Platen [4], Higham and Kloeden [6] and Mikulevic\u02c7ius and Platen [13], while jump\nadaptation is only valid in the compound Poisson framework.\nThe main purpose of this paper is to propose a new approach to weak approximation of stochastic dif-\nferential equations with jumps. Unlike Monte Carlo simulations with time discretization approximation\nof sample paths, we employ a mathematical programming technique to obtain numerically upper and lower\nbounds of the expectation of interest, where the optimization procedure ends up with a polynomial program-\nming. To this end, we follow the idea of Primbs [16] that reduces computation of bounds to an optimization\nproblem.1 Note that the framework of [16] only deals with the pure diffusion setting, that is, without jump\ncomponent, for which standard Monte Carlo methods are often sufficient. In contrast, few efficient sim-\nulation techniques exist for jump processes. Due to the complexity of the Ito formula for general jump\nprocesses, we need to carefully examine whether resulting optimization problems are practically solvable.\nFortunately, as we will demonstrate in what follows, our approach covers various jump processes of practical\ninterest.\nThe rest of this paper is organized as follows. Section 2 discusses our motivation by demonstrating dif-\nficulties and limitations of time discretization approximation, which our approach may get around. Section\n3 introduces and studies our optimization approach to the weak approximation. Section 4 provides three\nnumerical examples to illustrate that our method is able to capture very well the marginal distributions of\nstochastic differential equations with jumps via moment estimation. Finally, Section 5 concludes.\n2 Motivation\nLet us begin this section with general notations which will be used throughout the paper. Let N be the\ncollection of natural numbers with N0 := N[f0g. We also use the notations R0 := R n f0g and R+ :=\n(0;+\u00a5). For k 2 N, \u00b6k indicates the partial derivative with respect to k-th argument. We denote by Ckt ;kx\nthe class of continuous functions with continuous differentiability of kt-time for the first argument and of\nkx-time for the second argument. We denote by\nL! the weak convergence of random processes in the space\nD([0;+\u00a5);R) of ca`dla`g functions from [0;+\u00a5) intoR equipped with the Skorohod topology. We henceforth\nfix (W;F ;P) as our underlying probability space.\nLet X0 be given in R and let T > 0. Consider a one-dimensional stochastic differential equation\ndXt = a0 (t;Xt)dt+a1 (t;Xt)dWt +\nZ\nR0\nb(t;Xt\u0000;z)(m\u0000n)(dz;dt) ; t 2 [0;T ]; (2.1)\nwhere fWt : t \u0015 0g is a standard Brownian motion and where m is a Poisson random measure on R0 whose\ncompensator is given by the Le\u00b4vy measure n , that is, a s -finite measure defined on R0 satisfying\nR\nR0(jzj2^\n1)n(dz) < +\u00a5: Here, we assume that for each t 2 [0;T ], the functions a0(t;x), a1(t;x) and b(t;x;z) in\n(2.1) satisfy the usual conditions such as at most linear growth and Lipschitz so that the solution of (2.1)\nis well defined. We henceforth equip our underlying probability space with the natural filtration (Ft)t2[0;T ]\ngenerated by fXt : t 2 [0;T ]g. Let X be the support of the stochastic process fXt : t 2 [0;T ]g defined by\n(2.1), that is,\nX := inffB 2B(R) : P(Xt 2 B; t 2 [0;T ]) = 1g :\nOur interest throughout this study is in computing the expectation\nE [V (t;Xt)] ;\n1See also Lasserre et al. [11] for the dual formulation called generalized moment problems.\n2\nfor V : [0;+\u00a5)\u0002R 7! R such that E[jV (t;Xt)j] < +\u00a5, where t is an (Ft)t2[0;T ]-stopping time taking\nits values in [0;T ]. To demonstrate some difficulties and limitations of time discretization approximation\nof stochastic differential equations with jumps, let us begin with a simple setting with X0 > 0, t = T ,\na0(t;x) = a1(t;x)\u0011 0, and b(t;x;z) = xz, that is, (2.1) reduces to a Dole\u00b4ans-Dade stochastic exponential\ndXt = Xt\u0000\nZ\nR0\nz(m\u0000n)(dz;dt); X0 > 0; (2.2)\nwhich is a martingale with respect to its natural filtration. Assume further that the Le\u00b4vy measure n is defined\nonly on (\u00001;+\u00a5). It holds by the Ito formula that\nd lnXt =\u0000\nZ\n(\u00001;+\u00a5)\nzn (dz)dt+\nZ\n(\u00001;+\u00a5)\nln(1+ z)m (dz;dt) ;\nor equivalently, in the canonical form,\nXt = X0 exp\n\u0014\n\u0000t\nZ\n(\u00001;+\u00a5)\nzn (dz)+\nZ t\n0\nZ\n(\u00001;+\u00a5)\nln(1+ z)m (dz;ds)\n\u0015\n: (2.3)\nIt follows from the expression (2.3) that Xt > 0, a:s: For the computation of E[V (T;XT )], a standard tech-\nnique is the Monte Carlo simulation with sample generations of the marginal XT . Let us discuss typical\ndifficulties in simulation of XT .\n(i) In most cases, the marginal XT is simulated via the time discretization of the sample paths of fXt : t 2\n[0;T ]g. It is however rare to know how to simulate the increments R t2t1 RR+ z(m\u0000n)(dz;dt), with few\nexceptions such as gamma processes and stable processes. Moreover, the use of Euler-Maruyama\nschemes may ruin intrinsic properties of fXt : t \u0015 0g, such as the non-negativity of sample paths.\n(ii) The simulation knowledge of increments\nR t2\nt1\nR\nR+ z(m\u0000n)(dz;dt) is in general not equivalent to that\nof the increments with an arbitrary stepsize. In contrast, this problem never appear in the diffusion\ncase due to the Gaussian scaling property.\n(iii) We may alternatively simulate the sample paths based upon (2.3) using a shot noise representation\nof Poisson random measure m(dz;ds). (See Rosin\u00b4ski [18] for details.) However, as in the case of\nincrements, it is difficult to find a shot noise series representation in a convenient form. In addition,\nit is not sensible to generate random sequences for each sample path, in particular when the series is\ninfinite.\nEven the issues (i) and (iii) may not arise in the pure diffusion case. For example, a simple linear form\ndXt = XtsdWt can be rewritten in the canonical form Xt = X0 exp[\u0000s2=2+sWt ], which is easy to simulate.\nWe will give concrete illustrations for those issues in Section 4.1.\n3 Optimization approach to estimation of upper and lower bounds\nIn this section, we formulate a mathematical programming problem, which yields upper and lower bounds\nof the expectation E[V (t;Xt)] of the model (2.2). Our framework is completely different from the afore-\nmentioned Monte Carlo simulations, in the sense that we generate no random variates.\nWe are now in a position to introduce our optimization approach to the weak approximation. It holds by\nthe Ito formula that for f 2C1;2([0;T ]\u0002X ;R),\nd f (t;Xt) =A f (t;Xt)dt+\u00b62 f (t;Xt)a1(t;Xt)dWt +\nZ\nR0\nBz f (t;Xt\u0000)(m\u0000n)(dz;dt); a:s:; (3.1)\n3\nwhere\nA f (t;x) := \u00b61 f (t;x)+\u00b62 f (t;x)a0(t;x)+\n1\n2\n\u00b6 22 f (t;x)a1(t;x)2\n+\nZ\nR0\n(Bz f (t;x)\u0000\u00b62 f (t;x)b(t;x;z))n(dz);\nand for z 2 R0,\nBz f (t;x) := f (t;x+b(t;x;z))\u0000 f (t;x) :\nIf\nE\n\u0014Z t\n0\n(\u00b62 f (t;Xt)a1(t;Xt))2 dt\n\u0015\n<+\u00a5;\nand if\nE\n\u0014Z t\n0\nZ\nR0\n(Bz f (t;Xt))\n2n(dz)dt\n\u0015\n<+\u00a5; (3.2)\nthen the stochastic process f f (t;Xt)\u0000 f (0;X0)\u0000\nR t\n0A f (s;Xs)ds : t 2 [0;T ]g is a square-integrable martin-\ngale with respect to the filtration (Ft)t2[0;T ]. We can then derive the associated Dynkin formula, for any\n(Ft)t2[0;T ]-stopping time t taking values in [0;T ],\nE [ f (t;Xt)]\u0000 f (0;X0) = E\n\u0014Z t\n0\nA f (s;Xs)ds\n\u0015\n:\nRemark 3.1. The formula (3.1) is not in a standard form given in the literature, while this can be obtained\nin a straightforward manner. (See, for example, Applebaum [1].) Note also that we have not imposed\nany conditions on the jump component for the validity of (3.1). In fact, we will shortly need to impose\nconditions for optimization problems of our interest to be well defined, which are, much stronger than,\nsufficient to guarantee that (3.1) is well defined.\nThroughout this paper, we freeze the stopping time t = T . As soon as one finds an f 2 C1;2([0;T ]\u0002\nX ;R) such that A f (t;x)\u0014 0 onX and f (T;x)\u0015V (T;x) onX , we get\nE [V (T;XT )]\u0014 E [ f (T;XT )]\u0014 f (0;X0):\nClearly, the deterministic value f (0;X0) serves as an upper bound of E[V (T;XT )]. To minimize this upper\nbound f (0;X0), we now turn to the optimization problem\nmin f (0;X0)\ns:t: f (T;x)\u0015V (T;x) onX ;\nA f (t;x)\u0014 0 on [0;T ]\u0002X ;\nf 2C1;2([0;T ]\u0002X ;R):\nThis optimization problem is very difficult to solve since the function class of f and V are too broad. To\nsimplify the above optimization problem, we restrict the function f to be polynomial in both t and x, that is,\nin the form\nf (t;x) = \u00e5\nB(0;0)\nckt ;kxt\nktxkx ; (3.3)\nwhere\nB(l;m) :=\n\b\n(kt ;kx) 2 N2 : l \u0014 kt \u0014 Kt ; m\u0014 kx \u0014 Kx\n\t\n;\nfor some fixed natural numbers Kt and Kx and for a sequence fckt ;kxgB(0;0) of constants. For convenience in\nnotation, we henceforth denote by Cp the class of polynomial functions of the form (3.3). (It is certainly\nmore precise to denote the class by CKt ;Kxp instead, while we suppress Kt and Kx in what follows. There is\n4\nno possibility of confusion since they are fixed throughout implementation of each optimization.) We also\nneed to set V to be a piecewise polynomial in both t and x, and both a0 and a1 are inCp([0;T ]\u0002X ;R):We\nhave now arrived at the following optimization problem\nmin f (0;X0)\ns:t: f (T;x)\u0015V (T;x) onX ;\nA f (t;x)\u0014 0 on [0;T ]\u0002X ;\nf 2Cp([0;T ]\u0002X ;R):\n(3.4)\nSuppose, for a moment, that there is no jump in the formulation (3.1), that is, b \u0011 0 as in the setting of\n[16]. Then, A f is trivially polynomial, and consequently the entire setting (3.4) reduces to a polynomial\noptimization problem. Let us return to our setting with jumps. It turns out that A f is not necessarily\npolynomial due to the jump component. We can circumvent this difficulty by decomposing the coefficient b\nas\nb(t;x;z) = b1(t;x)b2(z); (3.5)\nwhere b1 2Cp([0;T ]\u0002X ;R) and where b2 : R0 7! R such thatZ\nR0\njb2(z)jk n(dz)<+\u00a5; k = 2; : : : ;kx: (3.6)\nand then, a simple algebra yields\nA f (t;x) = \u00e5\nB(1;0)\nckt ;kxktt\nkt\u00001xkx + \u00e5\nB(0;1)\nckt ;kxt\nktkxxkx\u00001a0(t;x)\n+\n1\n2 \u00e5B(0;2)\nckt ;kxt\nktkx(kx\u00001)xkx\u00002a1(t;x)2\n+ \u00e5\nB(0;2)\nckt ;kxt\nkt\nkx\u00002\n\u00e5\nk=0\nkxCkx\nkb1(t;x)kx\u0000k\nZ\nR0\nb2(z)kx\u0000kn(dz):\nSince the integral\nR\nR0 b2(z)\nkx\u0000kn(dz) is independent of t and x, the optimization problem (3.4) falls in the\nframework of polynomial programming.\nIn general, polynomial optimization problems are still NP hard. However, if the degrees Kt and Kx are\nfixed, sum of squares relaxation techniques enable us to solve the problem efficiently. Let us here briefly\ndescribe this relaxation procedure in a setting with X = R+, the value function V being polynomial and\nckt ;kx = 0 for kt +kx > 2n, where n is a positive integer. Let q(t;x) be a vector consisting of (n+1)(n+2)=2\nmonomials of the form tkxl such that k \u0015 0; l \u0015 0 and k+ l \u0014 n. Instead of the original problem (3.4), we\nwill solve\nmin f (0;X0)\ns:t: f (T;x) =V (T;x)+q(t;x)TQ1q(t;x)+ xq(t;x)TQ2q(t;x);\nA f (t;x) =\u0000q(t;x)TQ3q(t;x)\u0000 xt(T \u0000 t)q(t;x)TQ4q(t;x);\nfQkgk=1;:::;4 are positive semidefinite matrices;\n(3.7)\nwhere decision variables are not only f but also Qk\u2019s. This formulation serves as a relaxation of the original\nproblem (3.4) since the equalities in (3.7) imply the inequalities in (3.4), due to the positive semidefinite-\nness of Qk\u2019s. The optimization problem (3.7) can be rewritten as an optimization problem under a set of\nlinear equalities and semidefiniteness constraints. This problem conversion is automatically executed by\nSOSTOOLS. The resulting problem can be solved with semidefinite programming, for which several well-\nestablished solvers exist.\n5\nRemark 3.2. The decomposition (3.5) and the integrability condition (3.6) are sufficient to guarantee that\nthe Ito formula (3.1) is well defined. If b2(z) = qz for some constant q , then (2.1) is called a Le\u00b4vy-driven\nstochastic differential equation, since then the jump component reduces toZ\nR0\nb(t;Xt\u0000;z)(m\u0000n)(dz;dt) = qb1(t;Xt\u0000)\nZ\nR0\nz(m\u0000n)(dz;dt);\nwhere the integral of the right hand side corresponds to a Le\u00b4vy process.\nTo obtain a lower bound of E[V (T;XT )], we wish to find a g 2 Cp([0;T ]\u0002X ;R) via the polynomial\nprogramming\nmax g(0;X0)\ns:t: g(T;x)\u0014V (T;x) onX ;\nA g(t;x)\u0015 0 on [0;T ]\u0002X ;\ng 2Cp([0;T ]\u0002X ;R);\n(3.8)\nin a similar manner to (3.4). Let us remind again that our optimization approach yields upper and lower\nbounds of E[V (T;XT )] without sample paths simulation.\nRemark 3.3. The conservativeness of sum of square relaxation has been intensively studied, for example,\nin Parrilo [14]. It is known that in most settings, the relaxation error can be made arbitrarily small by em-\nploying more sophisticated relaxation techniques than those applied in (3.7), in return for rapidly increasing\ncomputation burden. Let us also discuss the conservativeness caused by restricting bounding functions f\nand g to polynomialsCp([0;T ]\u0002X ;R). A similar issue has been discussed in the framework of generalized\nmoment problems, which is the dual formulation of ours, for example, in Lasserre et al. [11]. They show that\nthe gap between optimal upper and lower bounds converges to 0 as the degrees of moments tend to infinity,\nunder suitable conditions on underlying random elements. In fact, thanks to the duality of formulations, this\nissue can be addressed in a similar manner. Error analysis of this type is, however, not necessarily informa-\ntive in the framework of semidefinite programming, since it is impossible in practice to solve semidefinite\nprogramming problems of arbitrarily high dimension. For this reason, it seems more worthwhile to examine\neffectiveness of our approach through numerical experiments, which we will demonstrate in Section 4.\n4 Numerical illustrations\nIn this section, we test our method on a Dole\u00b4ans-Dade stochastic exponential, a truncated stable subordinator\nand a process of Ornstein-Uhlenbeck type, all with no diffusion component, that is, a1(t;x) \u0011 0. We here\nestimate moments of those processes, which are available in closed form for the sake of comparison. In\nthe numerical examples presented hereafter, we utilized MATLAB SOSTOOLS combined with SeDuMi\n[15, 22], using a computer with a Pentium 4 3.2GHz processor and 2 GB memory.\n4.1 Dole\u00b4ans-Dade stochastic exponential driven by gamma process\nSet X0 > 0, a0(t;x) = a1(t;x) = 0, b1(t;x) = x, b2(z) = z, and\nn(dz) = a\ne\u0000bz\nz\ndz; z> 0;\nfor a > 0 and b > 0, that is a gamma Le\u00b4vy measure. In this setting, (2.1) reduces to a Dole\u00b4ans-Dade\nstochastic exponential (2.2). It is clear that E[XT ] = X0. Moreover, we have E[X2t ] = X20 e\na\nb2\nt , since by the\nIto-Wiener isometry,\nE\n\u0002\nX2T\n\u0003\n= X20 +\nZ\nR+\nz2n(dz)E\n\u0014Z T\n0\nX2t dt\n\u0015\n= X20 +\na\nb2\nZ T\n0\nE\n\u0002\nX2t\n\u0003\ndt;\n6\nwhere the interchange of the integrals holds by the Fubini theorem with the almost sure non-negativity of\nX2t . (For more details, we refer to Applebaum [1].)\nOn one hand, Euler-Maruyama schemes do not guarantee the non-negativity of sample paths. To il-\nlustrate this, let N 2 N and D := T=N, and consider the equidistant time discretization approximation of\nfXt : t 2 [0;T ]g, that is,\nXkD\nX(k\u00001)D\n= 1+ gk(aD;b)\u0000aD=b; (4.1)\nwhere fgk(a;b)gk2N is a sequence of iid gamma random variables with the common distribution ba=G(a)ya\u00001e\u0000bydy\non R+. With a choice of (a;b;D) satisfying 1\u0000 aD=b < 0, discretized sample paths may drop below zero.\nSuch numerical experiments produce a misleading result E [XT ]\u001c X0.\nOn the other hand, based upon the canonical form (2.3) with a shot noise series representation due to\nBondesson [3], sample paths can be simulated as\nXt = X0 exp\n\"\n\u0000t a\nb\n+\n+\u00a5\n\u00e5\nk=1\nln\n\u0012\n1+ e\u0000\nGk\naT\nVk\nb\n\u0013\n1(Tk \u0014 t)\n#\n; t 2 [0;T ]; (4.2)\nwhere fGkgk2N are arrival times of a standard Poisson process, where fVkgk2N is a sequence of iid standard\nexponential random variables, and where fTkgk2N is a sequence of iid uniform random variables on [0;T ].\nIt is, however, not sensible to generate this infinite series for each sample path.\nBy noting thatX =R+ and\nR\nR+ z\nkn(dz) = a(k\u00001)!=bk for k= 2;3; : : :, it holds that for f 2Cp([0;T ]\u0002\nR+;R),\nA f (t;x) = \u00e5\nB(1;0)\nckt ;kxktt\nkt\u00001xkx + \u00e5\nB(0;2)\nckt ;kxt\nktxkx\nkx\u00002\n\u00e5\nk=0\nkxCk\na(kx\u0000 k\u00001)!\nbkx\u0000k\n:\nWe can check the condition (3.2) by\nE\n\u0014Z T\n0\nZ\nR+\nBz f (t;Xt)n(dz)dt\n\u0015\n= E\n24Z T\n0\nZ\nR+\n \n\u00e5\nB(0;1)\nckt ;kxt\nktXkxt\nkx\n\u00e5\nk=1\nkxCkz\nk\n!2\na\ne\u0000bz\nz\ndzdt\n35 :\nBy the Fubini theorem, it thus suffices to have E[X2Kxt ] < +\u00a5 for each t 2 [0;T ]. In view of (2.3), it holds\nthat for each kx 2 N,\nE\nh\nX2Kxt\ni\n\u0014 X2Kx0 E\n\u0014\nexp\n\u0012\n2Kx\nZ T\n0\nZ\nR+\nln(1+ z)m(dz;ds)\n\u0013\u0015\n= X2Kx0 exp\n\"\nT\nZ\nR+\n\u0000\ne2Kxz\u00001\u0001ae\u0000b(ez\u00001)\nez\u00001 dz\n#\n<+\u00a5:\nThis implies that Kx can be taken arbitrarily large.\nHere, we test our optimization approach on estimation of E[Xt ] = X0 and E[X2t ] = X20 e\na\nb2\nt . Numerical\nresults are presented in Table 1. The two numbers given in the row \u201cSDP\u201d indicate upper and lower bounds\nobtained through our optimization approach. Note that whenX is unbounded, we must choose Kx \u0015 p for\nthe estimation of the p-th moment because of the constraint f (T;x) \u0015 xp for x 2X . In view of this, we\nchoose the minimal degree Kx = p. We also set Kt = p. It took at most 1 second to solve each optimization\nproblem to obtain a bound. We can see from Table 1 that even such a low degree polynomial function\nachieves tight upper and lower bounds. For comparison purpose, we also provide 99%-confidence intervals\nof Monte Carlo simulations based upon 50000 iid samples. The \u201cMC (ES)\u201c rows present intervals obtained\nthrough the Euler-Maruyama Scheme (4.1) with equidistant stepsize of 1e-2, while the \u201cMC (SR)\u201c rows\ngive results through the Series Representation (4.2) with truncation of the infinite series to 100 per unit\n7\ntime. Recall that Euler-Maruyama schemes produce some amount of discretization error, while an infinite\nshot noise series representation provides an approximative simulation method as well due to truncation of\nthe infinite series. Any large sample size in Monte Carlo simulations can never be in competition with\nour results since the upper and lower bounds obtained through our method form nothing but the 100%-\nconfidence interval. By taking into account the computing time required for the Monte Carlo simulations,\nthe superiority of our optimization approach is evident.\nt = 1 t = 2 t = 3\nE [Xt ]\nTrue Value 1.0000 1.000 1.0000\nSDP 1.0000 \u2013 1.0000 1.0000 \u2013 1.0000 1.0000 \u2013 1.0000\nMC (ES) [0.9973, 1.0021] [0.9951, 1.0021] [0.9934, 1.0022]\nMC (SR) [0.9986, 1.0036] [0.9959, 1.0028] [0.9942, 1.0029]\nE\n\u0002\nX2t\n\u0003 True Value 1.04545 1.09296 1.14263SDP 1.04541 \u2013 1.04550 1.09294 \u2013 1.09300 1.14249 \u2013 1.14288\nMC (ES) [1.0347, 1.0531] [1.0727, 1.1099] [1.1073, 1.1703]\nMC (SR) [1.0388, 1.0565] [1.0744, 1.1029] [1.1178, 1.1593]\nTable 1: Numerical results for Dole\u00b4ans-Dade stochastic exponential with X0 = 1 and (a;b) = (0:1;1:5).\n4.2 Short- and long-range behaviors of truncated stable subordinator\nSet X0 = 0, a1(t;x) = 0, b1(t;x) = 1, b2(z) = z, and\nn(dz) =\n1\nz1+a\n1(z\u0014 h)dz; z 2 R+;\nfor some a 2 (0;1) and h > 0, and a0(t;x) =\nR\nR+ zn(dz). Then, the stochastic differential equation (2.1)\nreduces to\nXt =\nZ t\n0\nZ\nR0\nzm(dz;ds);\nthat is, a truncated stable subordinator.\nHere, in view of Houdre\u00b4 and Kawai [7] and Rosin\u00b4ski [19], we test our method on short- and long-range\nbehaviors of truncated stable processes, by looking into convergence in terms of moments. Due to the\ntruncation of Le\u00b4vy measure, its marginal has a finite moment of every polynomial order. (See Theorem 25.3\nof Sato [20], for example.) For every t > 0, its moments of up to fourth order are given by\nE [Xt ] =\nZ\nR+\nzn(dz) = t\nh1\u0000a\n1\u0000a ;\nE\nh\n(Xt \u0000E [Xt ])2\ni\n= t\nZ\nR+\nz2n(dz) = t\nh2\u0000a\n2\u0000a ;\nE\nh\n(Xt \u0000E [Xt ])3\ni\n= t\nZ\nR+\nz3n(dz) = t\nh3\u0000a\n3\u0000a ;\nE\nh\n(Xt \u0000E [Xt ])4\ni\n= t\nZ\nR+\nz4n(dz)+3\n\u0012\nt\nZ\nR+\nz2n(dz)\n\u00132\n= t\nh4\u0000a\n4\u0000a +3\n\u0012\nt\nh2\u0000a\n2\u0000a\n\u00132\n:\nFirst, for the short-range behavior, we can prove that as h # 0,n\nh\u00001=aXht : t \u0015 0\no\nL!\nn\nX (a)t : t \u0015 0\no\n;\n8\nwhere fX (a)t : t \u0015 0g is a stable subordinator with Le\u00b4vy measure z\u00001\u0000adz on R+. To apply our optimization\nmethod to the first and the second moments, it is sufficient to first compute moments of Xht , and to multiply\nnext a scaling related to h. Clearly,X = R+. We have for f 2Cp([0;T ]\u0002R;R),\nA f (ht;x) = \u00e5\nB(1;0)\nckt ;kxkt(ht)\nkt\u00001xkx + \u00e5\nB(0;1)\nckt ;kx(ht)\nkt\nkx\u00001\n\u00e5\nk=0\nkxCkx\nk hkx\u0000k\u0000a\nkx\u0000 k\u0000a :\nOn the other hand, in the long run, as h \"+\u00a5,n\nh\u00001=2 (Xht \u0000E [Xht ]) : t \u0015 0\no\nL!fWt : t \u0015 0g ;\nwhere fWt : t \u0015 0g is a (centered) Brownian motion with E[jW1j2] = h2\u0000a=(2\u0000a). In this case, X = R,\na0(t;x) = 0, and we take the form f (ht;Xht \u0000E[Xht ]). Hence, we have\nA f (ht;x) = \u00e5\nB(1;0)\nckt ;kxkt(ht)\nkt\u00001xkx + \u00e5\nB(0;2)\nckt ;kx(ht)\nkt\nkx\u00002\n\u00e5\nk=0\nkxCkx\nk hkx\u0000k\u0000a\nkx\u0000 k\u0000a :\nWe present numerical results in Table 2 and in Table 3. Similarly to the previous example, for the estimation\nof the p-th moment, we set Kt = Kx = p.\nUnlike in the last example, we do not provide numerical results of Monte Carlo simulations due to\nextremely large computing effort required. To the best of our knowledge, the only decent method for the\nsample paths generation is based on its infinite shot noise series representation\nfXt : t 2 [0;T ]g L=\n(\n+\u00a5\n\u00e5\nk=1\n\u0012\nh\u0000a +\naGk\nT\n\u0013\u00001=a\n1(Tk \u0014 t) : t 2 [0;T ]\n)\n; (4.3)\nwhere fGkgk2N are arrival times of a standard Poisson process and where fTkgk2N is a sequence of iid\nuniform random variables on [0;T ]. We have observed through our experiments that the infinite series\nconverges at an extremely slow rate. For instance, even in the shortest time case h = 0:01, at least 5000\njumps are required to obtain decent estimation results. This Monte Carlo simulation is too expensive to be\ncompetitive against our optimization approach.\nh= 1 h= 0:1 h= 0:01 h # 0\nE\nh\nh\u00001=aXht\ni True Value 5.000 8.8914 15.811 +\u00a5\nSDP 5.000 \u2013 5.000 8.8914 \u2013 8.8914 15.811 \u2013 15.811 n\/a\nE\nh\n(h\u00001=aXht)2\ni True Value 25.833 105.41 1083.3 +\u00a5\nSDP 25.833 \u2013 25.833 105.41 \u2013 105.41 1083.3 \u2013 1083.3 n\/a\nTable 2: Numerical results for short-range behavior with X0 = 0, a = 0:8, h = 1, and t = 1.\nh= 1 h= 5 h= 10 h \"+\u00a5\nE\n\u0014\u0010\n1p\nh\n(Xht \u0000E [Xht ])\n\u00112\u0015 True Value 0.8333 0.8333 0.8333 0.8333\nSDP 0.8333 \u2013 0.8333 0.8333 \u2013 0.8333 0.8333 \u2013 0.8333 n\/a\nE\n\u0014\u0010\n1p\nh\n(Xht \u0000E [Xht ])\n\u00113\u0015 True Value 0.4545 0.2033 0.1437 0\nSDP 0.4545 \u2013 0.4545 0.2032 \u2013 0.2033 0.1437 \u2013 0.1437 n\/a\nE\n\u0014\u0010\n1p\nh\n(Xht \u0000E [Xht ])\n\u00114\u0015 True Value 2.3958 2.1458 2.1146 2.0833\nSDP 2.3958 - 2.3958 2.1458 - 2.1458 2.1127 - 2.1150 n\/a\nTable 3: Numerical results for long-range behavior with X0 = 0, a = 0:8, h = 1, and t = 1.\n9\n4.3 Process of Ornstein-Uhlenbeck type with gamma stationary distribution\nLet n be a Le\u00b4vy measure on R+ such that\nR\nR+ zn(dz) < +\u00a5. Set a0(t;x) = \u0000lx+\nR\nR+ zn(dz) for some\nl > 0, a1(t;x) = 0, b1(t;x) = 1, b2(z) = z, and X0 is independent of m . Then, the stochastic differential\nequation (2.1) reduces to\ndXt =\u0000lXtdt+\nZ\nR+\nzm(dz;dt);\nwhich is called a process of Ornstein-Uhlenbeck type. Its strong solution is given in closed form\nXt = e\u0000l tX0+\nZ t\n0\nZ\nR+\ne\u0000l (t\u0000s)zm(dz;ds): (4.4)\nFor simplicity, we fix X0 = 0, l = 1 and n(dz) = bae\u0000bzdz, where a > 0 and b > 0. We can show that the\nstationary distribution of fXt : t \u0015 0g is gamma with probability density ba=G(a)xa\u00001e\u0000bx defined on R+.\n(See, for example, Sato [20] for more details.)\nBy noting thatX = R+ and\nR\nR+ z\nkn(dz) = ak!=bk for k 2 N, it holds that for f 2Cp([0;T ]\u0002R+;R),\nA f (t;x) = \u00e5\nB(1;0)\nckt ;kxktt\nkt\u00001xkx +\n\u0010\n\u0000x+ a\nb\n\u0011\n\u00e5\nB(0;1)\nckt ;kxt\nktkxxkx\u00001\n+ \u00e5\nB(0;2)\nckt ;kxt\nkt\nkx\u00002\n\u00e5\nk=0\nkxCkx\nk a(kx\u0000 k)!\nbkx\u0000k\n:\nThe condition (3.2) holds for each Kt and Kx, since for each t 2 [0;T ],Z t\n0\nZ\nR+\ne\u0000l (t\u0000s)zm(dz;ds)\u0014\nZ T\n0\nZ\nR+\nzm(dz;ds); a:s:;\nwhere the right hand side is an infinitely divisible random variable, whose Le\u00b4vy measure has an exponential\ndecay at infinity.\nWe test our method on the distribution transition via moment estimations of E[Xt ] = (1\u0000 e\u0000t)a=b,\nE[X2t ] = (1\u0000 e\u00002t)a=b2+(1\u0000 e\u0000t)2a2=b2, and limt\"+\u00a5E[X3t ] = G(a+ 3)=(b3G(a)). Numerical results are\npresented in Table 4. We set Kt in the same manner as in the previous example. It is well known that\ncomputing effort required for solving a polynomial optimization problem through sum of squares decompo-\nsition significantly increases as the polynomial has larger degrees. In our experiments, however, even with\na relatively large setting Kx = 10, computing time was at most 2 seconds.\nSince the Le\u00b4vy measure n here is finite, sample paths can be simulated in the exact sense through a\nstandard compound Poisson generation applied in the expression (4.4). To compare our methods with such\na typical Monte Carlo technique, we also provide 99%-confidence interval based on 1000000 iid samples.\nAs can be observed, even with the extraordinarily large number of samples, the 99%-confidence intervals\nare far from comparable with our results.\n5 Concluding remarks\nIn this paper, we have developed a new approach to the weak approximation of stochastic differential equa-\ntions with jumps, through an optimization problem yielding upper and lower bounds of the expectation of\ninterest. It is a major advantage that our approach provides bounds without sample path simulation of jump\nprocesses, for which few practical simulation technique exist. In most numerical experiments which we\nhave conducted, we have obtained fairly tight bounds without taking very large degrees of bounding poly-\nnomial functions. We conjecture that the tightness of upper and lower bounds may be ruined when the value\n10\nt = 1 t = 2 t = 3 t \"+\u00a5\nE [Xt ]\nTrue Value 0.042141 0.057644 0.063348 0.06667\nSDP 0.042141 \u2013 0.042141 0.057644 \u2013 0.057644 0.063347 \u2013 0.063348 n\/a\nMC [0.041733, 0.042747] [0.056985, 0.058058] [0.062879, 0.063967] n\/a\nE\n\u0002\nX2t\n\u0003 True Value 0.040205 0.046953 0.048347 0.04889\nSDP 0.040205 \u2013 0.040205 0.046952 \u2013 0.046955 0.048331 \u2013 0.048347 n\/a\nMC [0.039618, 0.041484] [0.045721, 0.047600] [0.047666, 0.049604] n\/a\nE\n\u0002\nX3t\n\u0003 True Value n\/a n\/a n\/a 0.06844\nSDP 0.061217 \u2013 0.061268 0.066812 \u2013 0.066886 0.068009 \u2013 0.068051 n\/a\nMC [0.059161, 0.064966] [0.063362, 0.068839] [0.066005, 0.071926] n\/a\nTable 4: Numerical results with X0 = 0 and (a;b) = (0:1;1:5). The intervals are 99%-confidence interval\nwith 1000000 iid samples.\nfunction has a highly complicated form, while this could be overcome by relaxing the bounding polynomial\nfunctions to piecewise polynomial functions.\nIn this paper, we have only dealt with stochastic differential equations whose marginal has finite mo-\nments of up to a sufficiently large polynomial order. There are, however, various interesting examples that\ndo not meet such moment conditions, such as stochastic differential equations driven by stable Le\u00b4vy pro-\ncesses and the Heston stochastic volatility model even in the pure diffusion case. In particular, the latter\nexample entails a multidimensional formulation, which will be a numerically challenging problem due to\nthe high dimensionality of semidefinite programming. Those issues will be addressed in our subsequent\npaper [8].\nBesides extensions and improvements of our present approach, it would certainly be worthwhile to\napply our method to practical problems, such as option pricing and calibration in finance, the probability\ntail estimation, and so on.\nAcknowledgements\nThe authors would like to thank Japan Society for the Promotion of Science for Grant-in-Aid for Scientific\nResearch 20740059 and 21686039. Part of this work was carried out while RK was based at Center for the\nStudy of Finance and Insurance, Osaka University, Japan.\nReferences\n[1] D. Applebaum, Le\u00b4vy Processes and Stochastic Calculus, Cambridge University Press, 2004.\n[2] R. Bass, Stochastic differential equations with jumps, Probability Surveys, 1 (2004) 1-19.\n[3] L. Bondesson, On simulation from infinitely divisible distributions, Advances in Applied Probability, 14(4) (1982) 855-869.\n[4] N. Bruti-Liberati, E. Platen, Strong approximations of stochastic differential equations with jumps, Journal of Computational\nand Applied Mathematics, 205(2) (2007) 982-1001.\n[5] J. Jacod, T.G. Kurtz, S. Me\u00b4le\u00b4ard, P. Protter, The approximate Euler method for Le\u00b4vy driven stochastic differential equations,\nAnnales de l\u2019Institut Henri Poincare\u00b4 (B) Probabilite\u00b4s et Statistiques, 41 (2005) 523-558.\n[6] D.J. Higham, P.E. Kloeden, Strong convergence rates for backward Euler on a class of nonlinear jump-diffusion problems,\nJournal of Computational and Applied Mathematics, 205(2) (2007) 949-956.\n[7] C. Houdre\u00b4, R. Kawai, On layered stable processes, Bernoulli, 13(1) (2007) 252-278.\n[8] K. Kashima, R. Kawai, A weak approximation of stochastic differential equations with jumps through tempered polynomial\noptimization, Stochastic Models, 27(1) (2010) 26-49.\n[9] P.E. Kloeden, E. Platen, Numerical Solution of Stochastic Differential Equations, Third Printing, Springer, Berlin, 1999.\n[10] K. Kubilius, E. Platen, Rate of weak convergence of the Euler approximation for diffusion processes with jumps, Monte\nCarlo Methods and Applications, 8(1) (2002) 83-96.\n11\n[11] J.B. Lasserre, T. Prieto-Rumeau, M. Zervos, Pricing a class of exotic via moments and SDP relaxations, Mathematical\nFinance, 16(3) (2006) 469-494.\n[12] X.Q. Liu, C.W. Li, Weak approximations and extrapolations of stochastic differential equations with jumps, SIAM Journal\non Numerical Analysis, 37(6) (2004) 1747-1767.\n[13] R. Mikulevic\u02c7ius, E. Platen, Time discrete Taylor approximations for Ito\u02c6 processes with jump component, Math Nachr., 138\n(1998) 93-104.\n[14] P.A. Parrilo, Semidefinite programming relaxations for semialgebraic problems, Mathematical Programming Series B, 96(2)\n(2003) 293-320.\n[15] S. Prajna, A. Papachristodoulou, P. Seiler, P.A. Parrilo, SOS-TOOLS: Sum of squares optimization toolbox for MATLAB,\n2004.\n[16] J.A. Primbs, Optimization based option pricing bounds via piecewise polynomial super- and sub-martingales, In: 2008\nAmerican Control Conference.\n[17] P. Protter, D. Talay, The Euler scheme for Le\u00b4vy driven stochastic differential equations, Annals of Probability, 25 (1997)\n393-423.\n[18] J. Rosin\u00b4ski, Series representations of Le\u00b4vy processes from the perspective of point processes, In: Le\u00b4vy Processes - Theory\nand Applications, Eds. Barndorff-Nielsen, O.-E., Mikosch, T., Resnick, S.I., Birkha\u00a8user, 401-415, 2001.\n[19] J. Rosin\u00b4ski, Tempering stable processes, Stochastic Processes and their Applications, 117(6) (2001) 677-707.\n[20] K. Sato, Le\u00b4vy processes and infinitely divisible distributions, Cambridge University Press, 1999.\n[21] R. Situ., Reflecting Stochastic Differential Equations with Jumps and Applications, Chapman & Hall, 1999.\n[22] J. Sturm, SeDuMi version 1.1. (2006)\n12\n"}
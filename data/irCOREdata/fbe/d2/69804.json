{"doi":"10.1109\/ISUVR.2008.23","coreId":"69804","oai":"oai:eprints.lancs.ac.uk:21188","identifiers":["oai:eprints.lancs.ac.uk:21188","10.1109\/ISUVR.2008.23"],"title":"3D Motion Control of Connected Augmented Virtuality on Mobile Phones.","authors":["Chehimi, Fadi","Coulton, Paul","Edwards, Reuben"],"enrichments":{"references":[{"id":1030014,"title":"A taxonomy of mixed reality visual displays&quot;,","authors":[],"date":"1994","doi":null,"raw":null,"cites":null},{"id":1029777,"title":"Sensing techniques for mobile interaction,","authors":[],"date":"2000","doi":"10.1145\/1057237.1057240","raw":null,"cites":null},{"id":1029993,"title":"Using a Mobile Phone as a Wii-like Controller for Playing Games on a Large Public Display&quot;,","authors":[],"date":"2008","doi":"10.1155\/2008\/539078","raw":null,"cites":null},{"id":1029572,"title":"Virtual Applications: Applications with Virtual Inhabitated 3-D Worlds.","authors":[],"date":"2004","doi":null,"raw":null,"cites":null}],"documentType":{"type":null}},"contributors":[],"datePublished":"2008-07-10","abstract":"Applications of 3 Dimensional (3-D) virtual reality are now possible on current mobile phones due to the advances in mobile 3-D graphics technologies. However, the user-interface to these applications is generally still limited to the basic phone keypad which detracts from the sophisticated experience 3-D worlds can provide. In this paper we present a solution to this problem which utilizes the accelerometers on mobile phones to provide 3-D motion-controlled navigation through networked 3-D environments. This mechanism not only eliminates the use of buttons on the phone for control but also bridges the physical world to the virtual one to maintain optimum user experience","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"IEEE Computer Society","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:21188<\/identifier><datestamp>\n      2018-01-24T01:57:31Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413736<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        3D Motion Control of Connected Augmented Virtuality on Mobile Phones.<\/dc:title><dc:creator>\n        Chehimi, Fadi<\/dc:creator><dc:creator>\n        Coulton, Paul<\/dc:creator><dc:creator>\n        Edwards, Reuben<\/dc:creator><dc:subject>\n        QA76 Computer software<\/dc:subject><dc:description>\n        Applications of 3 Dimensional (3-D) virtual reality are now possible on current mobile phones due to the advances in mobile 3-D graphics technologies. However, the user-interface to these applications is generally still limited to the basic phone keypad which detracts from the sophisticated experience 3-D worlds can provide. In this paper we present a solution to this problem which utilizes the accelerometers on mobile phones to provide 3-D motion-controlled navigation through networked 3-D environments. This mechanism not only eliminates the use of buttons on the phone for control but also bridges the physical world to the virtual one to maintain optimum user experience.<\/dc:description><dc:publisher>\n        IEEE Computer Society<\/dc:publisher><dc:date>\n        2008-07-10<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/ISUVR.2008.23<\/dc:relation><dc:identifier>\n        Chehimi, Fadi and Coulton, Paul and Edwards, Reuben (2008) 3D Motion Control of Connected Augmented Virtuality on Mobile Phones. In: Proceedings of the 2008 International Symposium on Ubiquitous Virtual Reality. IEEE Computer Society, Gwangju, pp. 67-70. ISBN 978-0-7695-3259-2<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/21188\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/ISUVR.2008.23","http:\/\/eprints.lancs.ac.uk\/21188\/"],"year":2008,"topics":["QA76 Computer software"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"3D Motion Control of Connected Augmented Virtuality on Mobile Phones\nFadi Chehimi, Paul Coulton, Reuben Edwards\nInfoLab21, Lancaster University, Lancaster, LA1 4WA, UK\nf.chehimi, p.coulton, r.edwards@lancaster.ac.uk\nAbstract\nApplications of 3 Dimensional (3-D) virtual reality\nare now possible on current mobile phones due to the\nadvances in mobile 3-D graphics technologies.\nHowever, the user-interface to these applications is\ngenerally still limited to the basic phone keypad which\ndetracts from the sophisticated experience 3-D worlds\ncan provide. In this paper we present a solution to this\nproblem which utilizes the accelerometers on mobile\nphones to provide 3-D motion-controlled navigation\nthrough networked 3-D environments. This mechanism\nnot only eliminates the use of buttons on the phone for\ncontrol but also bridges the physical world to the\nvirtual one to maintain optimum user experience.\n1. Introduction\nSince the first introduction of public 3-D graphics\nApplication Programming Interfaces (API) for mobile\nphones in 2003 and the commercialization of mobile\nGraphics Processing Units (GPU) in 2006, 3-D virtual\nreality environments have become feasible\napplications on mobile phones. Full 3-D navigation in\n3-D worlds with photo-realistic appearances and\nrelatively highly detailed 3-D models are now\nachievable on the small display screens of these\ndevices. However, the available interaction interface\nwith these environments on phones is still restricted to\nthe limited T9 keypad which is primarily designed and\noptimized for number and text entry rather than\nintensive interaction with on-board applications.\nUsing such 2-D interfaces to interact with 3-D\nimmersive environments, like those in virtual reality\napplications, on the small screens can often be tedious\nand may degrade the overall user experience. We have\ntackled this restriction by using the 3-axis\naccelerometers recently introduced on a number of\nmobile phones to create a 3-D motion-controlled\ninterface which introduces a totally different\nexperience than the available 2-D implementations.\nUsing accelerometers to provide a tilt interface to\nmobile phone applications has been proposed for a\nnumber of years [1,2]. Some researchers for instance\nhave implemented it to navigate through phone menus\nwithout the need to tap any button [3]. Sony Ericsson\nhas used it in its W580 and W910 phones to control\nmusic players and switch between tracks by shaking\nthe phone. Even more, some developers have gone\nbeyond that to create Wii-like controllers for games\nrunning on the phone or on large public screens [4].\nAlmost all proposed approaches for utilizing the\naccelerometer limited the interaction experience to the\n2-D visual plane of the screen (whether on the phone\nor public display): moving horizontally (left and right)\nor vertically (front and back). Whilst this is an\nacceptable approach for 2-D applications it is a serious\nlimitation for rich, 3-D ones which require free and\nfull 3-D navigation capabilities in their 3-D scenes.\nOur proposed solution to overcome this limitation\nis presented by the MIRAGE-X API which we have\ndeveloped for the leading mobile platform: Symbian\nOS. The API provides the functionality to detect the\nphone\u2019s physical movement and translate it into 3-D\ndirectional vectors which then dictate the virtual\nmovement in the 3-D virtual world. In more specific\nterms, our approach augments the 3-D virtual world\non the phone with 3-D motion data from the physical\nworld to create a mixture of the two worlds in the form\nof \u201cAugmented Virtuality\u201d, according to Paul\nMilgram\u2019s \u201cReality-Virtuality Continuum\u201d [5].\nWe have developed the prototype game\nMirageSpace, which is a multiplayer space war game\nconnected over Bluetooth, to demonstrate the usability\nof MIRAGE-X and to show its applicability in\nnetworked environments such as those in multiplayer\nvirtual reality games. The game and its initial user\ntrials are discussed in section 4 after the presentation\nof the design and implementation of the API in\nsections 2 and 3 respectively. Section 5 then concludes\nour overall discussion and highlights the future\nexpansion of the API.\nInternational Symposium on Ubiquitous Virtual Reality\n978-0-7695-3259-2\/08 $25.00 \u00a9 2008 IEEE\nDOI 10.1109\/ISUVR.2008.23\n67\nAuthorized licensed use limited to: Lancaster University Library. Downloaded on December 19, 2008 at 04:23 from IEEE Xplore.  Restrictions apply.\nFigure 1.  Flying orientation in MirageSpace according to phone movement\nb. Flying upwards c. Flying downwards\nd. Rotating clockwise e. Rotating counter clockwise\na. Initial view: flying forwards\n2. MIRAGE-X overview\nMIRAGE-X is designed to provide applications\nwith instinctive navigation capability through 3-D\nworlds with first-person view by simply moving the\nphone in the direction the user wishes to move to. This\ncontrol is achieved by pitching the phone up or down,\nFigures 1.b and 1.c, and rotating it clock or counter\nclock wise, Figures 1.d and 1.e, giving as a result a\nfull 3-D movement in any direction with free pivoting\nat any arbitrary point in the 3-D world, unlike existing\nsensor solutions that allow 2-D type of motion only.\nThe accelerometer detects the movement of the\nphone in the physical world and then sends its\norientation readings to OpenGL ES (Embedded\nSystems), which is a lightweight subset of desktop\nOpenGL specially optimized for resource-constrained\ndevices such as mobile phones. OpenGL ES\naccordingly updates the relative view directions in the\n3-D environment and renders it on screen.\nTo complement the user experience of integrating\nthe virtual and real worlds the API mandates that as\nan initial starting point for any application the phone\nshould be held by the user in the up-right position\nwhere the screen, either horizontal or vertical, is\nperpendicular to the ground. This positioning\nenhances the notion of moving into the 3-D world\nwhere the screen acts as a window to an imaginary\nworld behind the phone which the user is moving in.\n2.1. General API architecture\nThe architecture of MIRAGE-X API and how to\nimplement it in Symbian applications is illustrated in\nthe UML diagram shown in Figure 2. Class\nCRRSensorApi is the native Symbian API\nresponsible of manipulating the accelerometer sensor.\nMIRAGE-X instantiates that class and receives\nmotion notifications through the interface API\nMRRSensorDataListener. When the accelerometer\nsenses motion it issues a call to this interface\u2019s only\npure virtual function HandleDataEventL(\u0002)\npassing as a parameter the sensor\u2019s information (id,\ncategory and name), and the three axes readings. This\nfunction is implemented to smooth out the cluttered\noutputs by applying some digital filter, as described\nnext, before submitting them to the API\u2019s function\nCameraLookAt() which constructs the 3-D view.\nIn order to use MIRAGE-X the client application\nmust instantiate CMirageX, extend some of its\nmethods (optional), and construct the framework for\nOpenGL ES, which the API then supplies with the\nfinal filtered orientation data to render the 3-D scenes\nin their appropriate direction.\n3. MIRAGE-X implementation\nMIRAGE-X is implemented in C++ to be used in\nmobile applications developed for the Symbian OS. At\npresent the API is targeted at mobile phones which\nhave accelerometers onboard and based on Nokia S60\nCRRSensorApiMRRSensorDataListener\nOpenGL ES APIs\nFigure 2. MIRAGE-X architecture and use\nCMirageX\nCUserApp\n68\nAuthorized licensed use limited to: Lancaster University Library. Downloaded on December 19, 2008 at 04:23 from IEEE Xplore.  Restrictions apply.\n3rd Edition user interface platform. At the time of\nwriting Nokia N93i, N95, and N82 are the only S60\nphones available that have accelerometers open for\nthird-party developers to use (we have used the N95 in\nour experiments). Nonetheless, Nigel Clifford, CEO of\nSymbian Ltd, indicated in his keynote at the Symbian\nSmartphone show in October of 2007 that this is likely\nto change during 2008 to add more devices to the list.\n3.1. Using the sensor readings\nThe N95 utilizes a \u00b12g to \u00b16g accelerometer [6]\nwhich can detect acceleration forces with a magnitude\nof up to six times that of earth\u2019s gravity. It outputs\nthree 12-bit signed data values [4] at a frequency of 40\nto 2560 Hz depending on the decimation factor (DC)\nset by the handset manufacturer [6]. Empirical\nevidence verified in [4] has shown this to be 40 Hz.\nThese outputs correspond to the three phone axes X, Y\nand Z shown in Figure 3.a. MIRAGE-X reflects these\noutputs from the physical world into motion directions\nin the virtual one. This data is manipulated through\nLinear Algebra and Trigonometry to calculate the\nappropriate rotation matrixes on the three axes, and to\ndetermine the three directional movements: forwards\ninto the space, sideways rotation, and vertical pitching.\nAs mentioned earlier the phone should initially be\nheld in the up-right position when using applications\nthat implement MIRAGE-X. The initial filtered\nreadings from the sensor in this position, while the\nphone is horizontal, are -90 for the X axis and zero for\nboth Y and Z. Tilting the phone forwards or\nbackwards gives a Z reading that ranges between -90\nand +90. This value is used to calculate an arbitrary-\nrotation matrix around the normal vector on the plane\nof the camera\u2019s up and look-at vectors. The matrix\nthen updates the direction of these two vectors and the\nup and down flying orientations in the 3-D world. The\nforward movement into the world is always calculated\nas a displacement along the new look-at vector.\nRotating the phone clock or counter clock wise on\nthe other hand gives Y readings that range between\n+90 and -90 which determine the left and right 3-D\nrotation. Here we have two different rotations applied:\nthe tilting of the scene on screen clock or counter\nclock wise to give an impression that the spaceship\nhas tilted sideways, and the actual left and right\nrotation in the 3-D space. The first rotation is achieved\nby calculating another arbitrary-rotation matrix, this\ntime around the always-updated look-at vector. The\nsecond rotation occurs around the world\u2019s global Y\naxis and generates a third matrix.\n3.2. Filtering the sensor outputs\nThe readings generated from accelerometers are\nraw data which are subject to noise. Figure 3.b shows\nthe three accelerometer outputs of the N95 when\nstatically placed upon a desk (representing a\nhorizontal plane). It can be seen that the X and Y\noutputs are approximately zero but with some sensor\nevident noise, and that the Z output is showing a\nnegative 1g force, which is the effect of gravity on the\ndevice in the -Z direction, plus noise as well [4].\nThis noise has been reduced in MIRAGE-X by\napplying a low-pass digital filter, with a cut-off of\napproximately 10 Hz, on the sensor readings. The\nfilter smoothes out the calculated tilt angles and\norientation vectors before sending them to OpenGL\nES to render the scene. Not applying this filter would\nhave caused a constant shake in the scene which\nwould have severely degraded the user experience.\n4. Demo application: MirageSpace\nWe have developed the multiplayer game (up to 4\nplayer) MirageSpace to demonstrate the use of\nMIRAGE-X in a connected virtual environment. The\ngame simulates a space battle where each player is\nassigned a spaceship and controls it by moving the\nphone in the direction the player wishes to fly towards,\nFigure 1. According to that physical motion of the\nphone the spaceship maneuvers in the game and its 3-\nD position is exchanged between the multiple players\nover Bluetooth. One player\u2019s phone acts as a server in\nthe networked game session and is responsible of\nupdating others with all spaceships\u2019 locations,\norientations and weaponry. The participants receive\nthis data and constantly update their local databases\nwhich the game refers to during the session.\nThe game has several elements that compose its\nchallenging environment. There are three different\ntypes of weapons that can be acquired by players to\na. acceleration axes b. acceleration at rest\nFigure 3. Nokia N95 accelerometer details\n69\nAuthorized licensed use limited to: Lancaster University Library. Downloaded on December 19, 2008 at 04:23 from IEEE Xplore.  Restrictions apply.\nenhance their roles in the game. There are asteroids\nscattered in the space which must be avoided whilst\nflying or some endurance power would be lost. There\nare power-ups as well to recover this loss. More over,\nplayers can speed up or slow down by tapping the up\nor down arrows on the keypad. Having this feature\nalongside the control provided by the accelerometer\nhelps the players maneuver their spaceship rapidly and\naccurately to avoid, asteroids, shootings from other\nopponents and to shoot them down.\nWhen one player detects another\u2019s spaceship on\nscreen and shoots it, his phone sends a message to the\nserver which then deactivates the shot spaceship and\ninforms all other players of that event. The game\ncontinues until there is one last-spaceship-standing.\n4.1. User experience\nWe have conducted initial trials on the use of\nMirageSpace and another further detailed study on a\nprevious game, MirageMoney, which was also\ndeveloped using MIRAGE-X. The results from both\nstudies showed that users were so excited and\nentertained by the use of accelerometers for 3-D games\nand found it more engaging, more interactive, easier\nto use and more responsive than buttons. The concept\nof utilizing motion control and 3-D graphics via\nMIRAGE-X was appealing to all of them and they\nbelieved that this approach would shape the future of\nmobile gaming. This led to some user describe\nMirageMoney as \u201cthe very first real 3-D game with\nhigh quality motion control via the accelerometer\u201d.\nSome users initially believed that MirageMoney\nand MirageSpace would be a boring game experience\ncompared to console gaming. But, when they tried the\ngames they were amazed by how balanced the control\nin the games was, how fast and easy it was to learn it,\nand how by practically tilting the phone their direction\nin the 3-D world on screen got altered accordingly.\nThey admitted later that they loved the experience and\nthat these were the type of games they would like to\nsee more of on mobile phones.\nSome users had problems maneuvering the phone\nto make the right moves in the game. Whilst all\nparticipants in the trials could recognize the pitching\nmotion (moving up and down) in the 3-D world\nwithout any guidance, some had trouble realizing the\nsideway rotation which required the phone to pivot\naround its center point rather than around the vector\nparallel to the gravity direction. Therefore, we made\nsure the user instructions and the online demo video\nillustrate this motion clearly which helped user to\neasily and rapidly adapt to the required moves and\ngive good feedback of their overall experience.\n5. Conclusion and future work\nOur first trials with MirageMoney showed a great\ninterest from the public and a remarkable attention\nfrom the mobile development community for the use\nof MIRAGE-X as a novel 3-D controlling interface.\nMirageSpace extends that experience further to\ninclude the connectivity feature and introduce an\nengaging multiplayer environment. This extension has\ndemonstrated that users\u2019 experience with 3-D virtual\ngames on mobile phones was further enhanced by the\nchallenge created whilst applying physical moves from\nthe real world to hunt other players in the virtual one.\nThis mixed reality research of using MIRAGE-X\nwill continue to investigate other possibilities for the\nAPI such as utilizing it with the GPS receiver on the\nN95 and a digital compass to create augmented reality\nlocation-based applications. The use of GPS with this\nAPI has then obvious uses within the fields of tourism\nand information services*.\n7. References\n[1] Andersen, P. and Qvortrup, L. Virtual Applications:\nApplications with Virtual Inhabitated 3-D Worlds. Springer,\nLondon, 2004, pp.142, 160.\n[2] Coulton, P., Edwards, R., Bamford, W., Chehimi, F.,\nGilbertson, P., and Rashid, M., Mobile Games: Challenges\nand Opportunities, Advances in Computers No 69, Elsevier\nPress 2007.\n[3] Hinckley, K., Pierce, J., Sinclair, M., and Horvitz, E.,\nSensing techniques for mobile interaction, Proc. of the 13th\nACM Symposium on User Interface Software and\nTechnology, San Diego, California, USA, 2000, pp. 91-100.\n[4] Vajk, T. Bamford, W. Coulton, P. and Edwards, R.\n\u201cUsing a Mobile Phone as a Wii-like Controller for Playing\nGames on a Large Public Display\", International Journal of\nComputer Games Technology, vol. 2008, Article ID 539078.\n[5] P Milgram and F Kishino. \"A taxonomy of mixed reality\nvisual displays\", IEICE Transactions on Information and\nSystems, Special issue on Networked Reality, Dec. 1994.\n[6] http:\/\/www.st.com\/stonline\/products\/families\/sensors\/\naccelerometers.htm. Last accessed April. 2008.\n*\nThe authors wish to acknowledge the support of Nokia for the work\nof the Mobile Radicals Research Group in Infolab21 at Lancaster\nUniversity where this work was carried out.\n70\nAuthorized licensed use limited to: Lancaster University Library. Downloaded on December 19, 2008 at 04:23 from IEEE Xplore.  Restrictions apply.\n"}
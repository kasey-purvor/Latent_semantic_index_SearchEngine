{"doi":"10.1371\/journal.pone.0003781","coreId":"177274","oai":"oai:aura.abdn.ac.uk:2164\/2061","identifiers":["oai:aura.abdn.ac.uk:2164\/2061","10.1371\/journal.pone.0003781"],"title":"Coding of visual object features and feature conjunctions in the human brain","authors":["Martinovic, Jasna","Gruber, Thomas","Mueller, Matthias M"],"enrichments":{"references":[{"id":428376,"title":"A cross-lab study of event-related gamma activity in a standard object-recognition paradigm.","authors":[],"date":"2006","doi":"10.1016\/j.neuroimage.2006.07.034","raw":"Busch NA, Herrmann CS, Mu \u00a8ller MM, Lenz D, Gruber T (2006) A cross-lab study of event-related gamma activity in a standard object-recognition paradigm. Neuroimage 33: 1169\u20131177.","cites":null},{"id":7068,"title":"A standardized Set of 260 pictures: Norms for name agreement, image agreement, familiarity and visual complexity.","authors":[],"date":"1980","doi":"10.1037\/\/0278-7393.6.2.174","raw":"Snodgrass JG, Vanderwart M (1980) A standardized Set of 260 pictures: Norms for name agreement, image agreement, familiarity and visual complexity. Journal of Experimental Psychology: Human Learning and Memory 6: 174\u2013215.","cites":null},{"id":7074,"title":"Activation timecourse of ventral visual stream object-recognition areas: High density electrical mapping of perceptual closure processes.","authors":[],"date":"2000","doi":"10.1162\/089892900562372","raw":"Doniger GM, Foxe JJ, Murray MM, Higgins BA, Snodgrass JG, et al. (2000) Activation timecourse of ventral visual stream object-recognition areas: High density electrical mapping of perceptual closure processes. Journal of Cognitive Neuroscience 12: 615\u2013621.","cites":null},{"id":7046,"title":"Age of acquisition for naming and knowing: A new hypothesis.","authors":[],"date":"2006","doi":"10.1080\/02724980443000674","raw":"Funnell E, Hughes D, Woodcock J (2006) Age of acquisition for naming and knowing: A new hypothesis. Quarterly Journal of Experimental Psychology 59: 268\u2013295.","cites":null},{"id":428292,"title":"An event-related potential investigation of the relationship between semantic and perceptual levels of representation.","authors":[],"date":"2003","doi":"10.1016\/s0093-934x(02)00546-1","raw":"van Schie HT, Wijers AA, Kellenbach ML, Stowe LA (2003) An event-related potential investigation of the relationship between semantic and perceptual levels of representation. Brain and Language 86: 300\u2013325.","cites":null},{"id":7048,"title":"Color makes a difference: Two-dimensional object naming in literate and illiterate subjects.","authors":[],"date":"2006","doi":"10.1016\/j.bandc.2005.09.012","raw":"Reis A, Faisca L, Ingvar M, Petersson KM (2006) Color makes a difference: Two-dimensional object naming in literate and illiterate subjects. Brain and Cognition 60: 49\u201354.","cites":null},{"id":7042,"title":"Contribution of color to face recognition.","authors":[],"date":"2002","doi":"10.1068\/p3376","raw":"Yip AW, Sinha P (2002) Contribution of color to face recognition. Perception 31: 995\u20131003.","cites":null},{"id":428291,"title":"Dynamic shape synthesis in posterior inferotemporal cortex.","authors":[],"date":"2006","doi":"10.1016\/j.neuron.2005.11.026","raw":"Brincat SL, Connor CE (2006) Dynamic shape synthesis in posterior inferotemporal cortex. Neuron 49: 17\u201324.","cites":null},{"id":7057,"title":"Early gamma response is sensory in origin: a conclusion based on cross-comparison of results from multiple experimental paradigms.","authors":[],"date":"1998","doi":"10.1016\/S0167-8760(98)00030-0","raw":"Karakas S, Basar E (1998) Early gamma response is sensory in origin: a conclusion based on cross-comparison of results from multiple experimental paradigms. International Journal of Psychophysiology 31: 13\u201331.","cites":null},{"id":7059,"title":"EEG oscillations in the gamma and alpha range respond differently to spatial frequency.","authors":[],"date":"2007","doi":"10.1016\/j.visres.2007.03.022","raw":"Fru \u00a8nd I, Busch NA, Korner U, Schadow J, Herrmann CS (2007) EEG oscillations in the gamma and alpha range respond differently to spatial frequency. Vision Reasearch 47: 2086\u20132098.","cites":null},{"id":428354,"title":"EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis.","authors":[],"date":"2004","doi":"10.1016\/j.jneumeth.2003.10.009","raw":"Delorme A, Makeig S (2004) EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. Journal of Neuroscience Methods 134: 9\u201321.","cites":null},{"id":7069,"title":"Effects of picture repetition on induced gamma band responses, evoked potentials, and phase synchrony in the human EEG.","authors":[],"date":"2002","doi":"10.1016\/s0926-6410(01)00130-6","raw":"Gruber T, Mu \u00a8ller MM (2002) Effects of picture repetition on induced gamma band responses, evoked potentials, and phase synchrony in the human EEG. Cognitive Brain Research 13: 377\u2013392. Object Features PLoS ONE | www.plosone.org 9 November 2008 | Volume 3 | Issue 11 | e378129. Bates E, D\u2019Amico S, Jacobsen T, Szekely A, Andonova E, et al. (2003) Timed picture naming in seven languages. Psychonomic Bulletin & Review 10: 344\u2013380.","cites":null},{"id":7056,"title":"Feature linking via synchronization among distributed assemblies: simulations of results from cat visual cortex.","authors":[],"date":"1990","doi":"10.1162\/neco.1990.2.3.293","raw":"Eckhorn R, Reitboeck HJ, Arndt M, Dicke P (1990) Feature linking via synchronization among distributed assemblies: simulations of results from cat visual cortex. Neural Computation 2: 293\u2013307.","cites":null},{"id":428377,"title":"Gamma responses and ERPs in a visual classification task.","authors":[],"date":"1999","doi":"10.1016\/S1388-2457(99)00002-4","raw":"Herrmann CS, Mecklinger A, Pfeifer E (1999) Gamma responses and ERPs in a visual classification task. Clinical Neurophysiology 110: 636\u2013642.","cites":null},{"id":428352,"title":"High quality recording of bioelectric events: I: interference reduction, theory and practice.","authors":[],"date":"1990","doi":"10.1007\/bf02441961","raw":"Metting Van Rijn AC, Peper A, Grimbergen CA (1990) High quality recording of bioelectric events: I: interference reduction, theory and practice. Medical and Biological Engineering and Computing 28: 389\u2013397.","cites":null},{"id":428353,"title":"High quality recording of bioelectric events. II: a low noise low-power multichannel amplifier design.","authors":[],"date":"1991","doi":"10.1007\/bf02441666","raw":"Metting Van Rijn AC, Peper A, Grimbergen CA (1991) High quality recording of bioelectric events. II: a low noise low-power multichannel amplifier design. Medical and Biological Engineering and Computing 29: 433\u2013440.","cites":null},{"id":7055,"title":"Human brain electrophysiology.","authors":[],"date":"1989","doi":null,"raw":"Regan D (1989) Human brain electrophysiology. New York: Elsevier.","cites":null},{"id":7067,"title":"Induced gamma-band activity is related to the time point of object identification.","authors":[],"date":"2008","doi":"10.1016\/j.brainres.2007.12.050","raw":"Martinovic J, Gruber T, Hantsch A, Mu \u00a8ller MM (2008) Induced gamma-band activity is related to the time point of object identification. Brain Research 1198: 93\u2013106.","cites":null},{"id":428358,"title":"Induced gamma-band responses predict recognition delays during object identification.","authors":[],"date":"2007","doi":"10.1162\/jocn.2007.19.6.921","raw":"Martinovic J, Gruber T, Mu \u00a8ller MM (2007) Induced gamma-band responses predict recognition delays during object identification. Journal of Cognitive Neuroscience 19: 921\u2013934.","cites":null},{"id":7071,"title":"Is color an intrinsic property of object representation?","authors":[],"date":"2003","doi":"10.1068\/p5050","raw":"Naor-Raz G, Tarr MJ, Kersten D (2003) Is color an intrinsic property of object representation? Perception 32: 667\u2013680.","cites":null},{"id":428357,"title":"Keil A","authors":[],"date":"2004","doi":null,"raw":"Muller MM, Keil A (2004) Neuronal synchronization and selective color processing in the human brain. Journal of Cognitive Neuroscience 16: 503\u2013522.","cites":null},{"id":7054,"title":"Limits of eventrelated potential differences in tracking object processing speed.","authors":[],"date":"2007","doi":"10.1162\/jocn.2007.19.8.1241","raw":"Rousselet GA, Mace MJM, Thorpe SJ, Fabre-Thorpe M (2007) Limits of eventrelated potential differences in tracking object processing speed. Journal of Cognitive Neuroscience 19: 1241\u20131258.","cites":null},{"id":7060,"title":"Memory-matches evoke human gamma-responses.","authors":[],"date":"2004","doi":null,"raw":"Herrmann CS, Lenz D, Junge S, Busch NA, Maess B (2004) Memory-matches evoke human gamma-responses. BMC Neuroscience 5: 13.","cites":null},{"id":428296,"title":"Microsaccades: A microcosm for research on oculomotor control, attention and visual perception.","authors":[],"date":"2006","doi":"10.1016\/s0079-6123(06)54009-9","raw":"Engbert R (2006) Microsaccades: A microcosm for research on oculomotor control, attention and visual perception. In: Martinez-Conde S, Macknik S, Martinez L, Alonso J-M, Tse P, eds. Fundamentals of vision: Low and mid-level processes in perception. Amsterdam: Elsevier. pp 177\u2013192.","cites":null},{"id":428290,"title":"Modelling event-related responses in the brain.","authors":[],"date":"2005","doi":"10.1016\/j.neuroimage.2004.12.030","raw":"David O, Harrison L, Friston KJ (2005) Modelling event-related responses in the brain. Neuroimage 25: 756\u2013770.","cites":null},{"id":7062,"title":"Modulation of oscillatory brain activity and evoked potentials in a repetition priming task in the human EEG.","authors":[],"date":"2004","doi":"10.1111\/j.0953-816x.2004.03176.x","raw":"Gruber T, Malinowski P, Mu \u00a8ller MM (2004) Modulation of oscillatory brain activity and evoked potentials in a repetition priming task in the human EEG. European Journal of Neuroscience 19: 1073\u20131082.","cites":null},{"id":428294,"title":"Neuronal correlates of repetition priming of frequently presented objects: Insights from induced gamma band responses.","authors":[],"date":"2007","doi":"10.1016\/j.neulet.2007.09.065","raw":"Conrad N, Giabbiconi CM, Mu \u00a8ller MM, Gruber T (2007) Neuronal correlates of repetition priming of frequently presented objects: Insights from induced gamma band responses. Neuroscience Letters 429: 126\u2013130.","cites":null},{"id":428293,"title":"Neuronal mechanisms of repetition priming in occipitotemporal cortex: spatiotemporal evidence from functional magnetic resonance imaging and electroencephalography.","authors":[],"date":"2005","doi":"10.1523\/jneurosci.4107-04.2005","raw":"Fiebach CJ, Gruber T, Supp GG (2005) Neuronal mechanisms of repetition priming in occipitotemporal cortex: spatiotemporal evidence from functional magnetic resonance imaging and electroencephalography. Journal of Neuroscience 25: 3414\u20133422.","cites":null},{"id":7066,"title":"Neurophysiological evidence for the time course of activation of global shape, part, and local contour representations during visual object categorization and memory.","authors":[],"date":"2007","doi":"10.1162\/jocn.2007.19.5.734","raw":"Schendan HE, Kutas M (2007) Neurophysiological evidence for the time course of activation of global shape, part, and local contour representations during visual object categorization and memory. Journal of Cognitive Neuroscience 19: 734\u2013749.","cites":null},{"id":7073,"title":"Neuropsychological evidence for two processing times for visual object identification.","authors":[],"date":"2002","doi":"10.1016\/S0028-3932(01)00176-2","raw":"Schendan HE, Kutas M (2002) Neuropsychological evidence for two processing times for visual object identification. Neuropsychologia 40: 931\u2013945.","cites":null},{"id":428350,"title":"Object recognition and segmentation by a fragment-based hierarchy.","authors":[],"date":"2007","doi":"10.1016\/j.tics.2006.11.009","raw":"Ullman S (2007) Object recognition and segmentation by a fragment-based hierarchy. Trends in Cognitive Sciences 11: 58\u201364.","cites":null},{"id":7063,"title":"Oscillatory brain activity dissociates between associative stimulus content in a repetition priming task in the human EEG.","authors":[],"date":"2005","doi":"10.1093\/cercor\/bhh113","raw":"Gruber T, Mu \u00a8ller MM (2005) Oscillatory brain activity dissociates between associative stimulus content in a repetition priming task in the human EEG. Cerebral Cortex 15: 109\u2013116.","cites":null},{"id":7064,"title":"Oscillatory gamma activity in humans and its role in object representation.","authors":[],"date":"1999","doi":"10.1016\/S1364-6613(99)01299-1","raw":"Tallon-Baudry C, Bertrand O (1999) Oscillatory gamma activity in humans and its role in object representation. TICS 3: 151\u2013162.","cites":null},{"id":428375,"title":"Oscillatory gammaband (30\u201370 Hz) activity induced by a visual search task in human.","authors":[],"date":"1997","doi":null,"raw":"Tallon-Baudry C, Bertrand O, Delpuech C, Pernier J (1997) Oscillatory gammaband (30\u201370 Hz) activity induced by a visual search task in human. The Journal of Neuroscience 17: 722\u2013734.","cites":null},{"id":7052,"title":"Rapid categorization of foveal and extrafoveal natural images: Associated ERPs and effects of lateralization.","authors":[],"date":"2005","doi":"10.1016\/j.bandc.2005.06.002","raw":"Fize D, Fabre-Thorpe M, Richard G, Doyon B, Thorpe SJ (2005) Rapid categorization of foveal and extrafoveal natural images: Associated ERPs and effects of lateralization. Brain and Cognition 59: 145\u2013158.","cites":null},{"id":7038,"title":"Real age-of-acquisition effects in lexical retrieval.","authors":[],"date":"1998","doi":"10.1037\/\/0278-7393.24.2.515","raw":"Ellis AW, Morrison CM (1998) Real age-of-acquisition effects in lexical retrieval. Journal of Experimental Psychology: Learning, Memory and Cognition 24: 515\u2013523.","cites":null},{"id":7040,"title":"Recognition-by-components: A theory of human image understanding.","authors":[],"date":"1987","doi":"10.1037\/\/0033-295X.94.2.115","raw":"Biederman I (1987) Recognition-by-components: A theory of human image understanding. Psychological Review 94: 115\u2013147.","cites":null},{"id":7039,"title":"Representation and recognition of the spatial organization of three-dimensional shapes.","authors":[],"date":"1978","doi":"10.1098\/rspb.1978.0020","raw":"Marr D, Nishihara HK (1978) Representation and recognition of the spatial organization of three-dimensional shapes. Proceedings of the Royal Society of London, Series B 200: 269\u2013294.","cites":null},{"id":7037,"title":"Revisiting Snodgrass and Vanderwart\u2019s object pictorial set: The role of surface detail in basic-level object recognition.","authors":[],"date":"2004","doi":"10.1068\/p5117","raw":"Rossion B, Pourtois G (2004) Revisiting Snodgrass and Vanderwart\u2019s object pictorial set: The role of surface detail in basic-level object recognition. Perception 33: 217\u2013236.","cites":null},{"id":428356,"title":"Selective visual-spatial attention alters induced gamma band responses in the human EEG.","authors":[],"date":"1999","doi":"10.1016\/s1388-2457(99)00176-5","raw":"Gruber T, Mu \u00a8ller MM, Keil A, Elbert T (1999) Selective visual-spatial attention alters induced gamma band responses in the human EEG. Clinical Neurophysiology 110: 2074\u20132085.","cites":null},{"id":7044,"title":"Sensory and cognitive contributions of color to the recognition of natural scenes.","authors":[],"date":"2000","doi":"10.1016\/S0960-9822(00)00563-7","raw":"Gegenfurtner KR, Rieger J (2000) Sensory and cognitive contributions of color to the recognition of natural scenes. Current Biology 10: 805\u2013808.","cites":null},{"id":7058,"title":"Size matters: effects of stimulus size, duration and eccentricity on the visual gammaband response.","authors":[],"date":"2004","doi":"10.1016\/j.clinph.2004.03.015","raw":"Busch NA, Debener S, Kranczioch C, Engel AK, Herrmann CS (2004) Size matters: effects of stimulus size, duration and eccentricity on the visual gammaband response. Clinical Neurophysiology 115: 1810\u20131820.","cites":null},{"id":7050,"title":"Speed of processing in the human visual system.","authors":[],"date":"1996","doi":"10.1038\/381520a0","raw":"Thorpe S, Fize D, Marlot C (1996) Speed of processing in the human visual system. Nature 381: 520\u2013522.","cites":null},{"id":428378,"title":"Spherical splines for scalp potential and current source density mapping.","authors":[],"date":"1988","doi":"10.1016\/0013-4694(89)90180-6","raw":"Perrin F, Pernier J, Bertrand O, Echallier JF (1988) Spherical splines for scalp potential and current source density mapping. Electroencephalography and Clinical Neurophysiology 72: 184\u2013187. Object Features PLoS ONE | www.plosone.org 10 November 2008 | Volume 3 | Issue 11 | e3781","cites":null},{"id":428355,"title":"Statistical control of artifacts in dense array EEG\/MEG studies.","authors":[],"date":"2000","doi":"10.1111\/1469-8986.3740523","raw":"Junghoefer M, Elbert T, Tucker DM, Braun C (2000) Statistical control of artifacts in dense array EEG\/MEG studies. Psychophysiology 37: 523\u2013532.","cites":null},{"id":428373,"title":"Stimulus frequency dependence of the transient oscillatory auditory evoked response (40 Hz) studied by electric and magnetic recordings","authors":[],"date":"1994","doi":"10.1007\/978-1-4899-1307-4_17","raw":"Bertrand O, Pantev C (1994) Stimulus frequency dependence of the transient oscillatory auditory evoked response (40 Hz) studied by electric and magnetic recordings in human. In: Pantev C, Elbert T, Lu \u00a8tkenho \u00a8ner B, eds. Oscillatory Event-Related Brain Dynamics. New York: Plenum Press. pp 231\u2013242.","cites":null},{"id":428351,"title":"The 10\u201320 electrode system of the International Federation.","authors":[],"date":"1958","doi":null,"raw":"Jasper HH (1958) The 10\u201320 electrode system of the International Federation. Electroencephalography and Clinical Neurophysiology 10: 370\u2013375.","cites":null},{"id":7041,"title":"The role of color in high level vision. Trends","authors":[],"date":"2001","doi":"10.1016\/S1364-6613(00)01626-0","raw":"Tanaka JW, Weiskopf D, Williams P (2001) The role of color in high level vision. Trends in Cognitive Sciences 5: 211\u2013215.","cites":null},{"id":7053,"title":"The time course of visual processing: from early perception to decision-making.","authors":[],"date":"2001","doi":"10.1162\/08989290152001880","raw":"VanRullen R, Thorpe SJ (2001) The time course of visual processing: from early perception to decision-making. Journal of Cognitive Neuroscience 13: 454\u2013461.","cites":null},{"id":7065,"title":"Time course of processes and representations supporting visual object identification and memory.","authors":[],"date":"2003","doi":"10.1162\/089892903321107864","raw":"Schendan HE, Kutas M (2003) Time course of processes and representations supporting visual object identification and memory. Journal of Cognitive Neuroscience 15: 111\u2013135.","cites":null},{"id":7061,"title":"Time pressure modulates electrophysiological correlates of early visual processing.","authors":[],"date":"2008","doi":"10.1371\/journal.pone.0001675","raw":"Fru \u00a8nd I, Busch NA, Schadow J, Gruber T, Ko \u00a8rner U, et al. (2008) Time pressure modulates electrophysiological correlates of early visual processing. PLOS Biology 3: e1675.","cites":null},{"id":7072,"title":"Timecourse of neural signatures of object recognition.","authors":[],"date":"2003","doi":"10.1167\/3.7.4","raw":"Johnson JS, Olshausen BA (2003) Timecourse of neural signatures of object recognition. Journal of Vision 3: 499\u2013512.","cites":null},{"id":7070,"title":"Timed picture naming in seven languages.","authors":[],"date":"2003","doi":"10.3758\/BF03196494","raw":null,"cites":null},{"id":428349,"title":"Topdown facilitation of visual recognition.","authors":[],"date":"2006","doi":"10.1073\/pnas.0507062103","raw":"Bar M, Kassam KS, Ghuman AS, Boshyan J, Schmid AM, et al. (2006) Topdown facilitation of visual recognition. Proceedings of the National Academy of Sciences of USA 103: 449\u2013454.","cites":null},{"id":428295,"title":"Transient induced gamma-band response in EEG as a manifestation of miniature saccades.","authors":[],"date":"2008","doi":"10.1016\/j.neuron.2008.03.027","raw":"Yuval-Greenberg S, Tomer O, Keren AS, Nelken I, Deouell LY (2008) Transient induced gamma-band response in EEG as a manifestation of miniature saccades. Neuron 58: 429\u2013411.","cites":null}],"documentType":{"type":1}},"contributors":["University of Aberdeen, School of Psychology"],"datePublished":"2008-11-21","abstract":"Peer reviewedPublisher PD","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:aura.abdn.ac.uk:2164\/2061<\/identifier><datestamp>\n                2018-01-05T21:55:05Z<\/datestamp><setSpec>\n                com_2164_646<\/setSpec><setSpec>\n                com_2164_366<\/setSpec><setSpec>\n                com_2164_330<\/setSpec><setSpec>\n                com_2164_705<\/setSpec><setSpec>\n                col_2164_647<\/setSpec><setSpec>\n                col_2164_706<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nCoding of visual object features and feature conjunctions in the human brain<\/dc:title><dc:creator>\nMartinovic, Jasna<\/dc:creator><dc:creator>\nGruber, Thomas<\/dc:creator><dc:creator>\nMueller, Matthias M<\/dc:creator><dc:contributor>\nUniversity of Aberdeen, School of Psychology<\/dc:contributor><dc:subject>\ngamma-band-responses<\/dc:subject><dc:subject>\nrepetition priming task<\/dc:subject><dc:subject>\nhuman EEG<\/dc:subject><dc:subject>\ntime-course<\/dc:subject><dc:subject>\nneurophysiological evidence<\/dc:subject><dc:subject>\nbioelectric events<\/dc:subject><dc:subject>\nevoked-potentials<\/dc:subject><dc:subject>\nrecognition<\/dc:subject><dc:subject>\ncolor<\/dc:subject><dc:subject>\nidentification<\/dc:subject><dc:subject>\nRC0321 Neuroscience. Biological psychiatry. Neuropsychiatry<\/dc:subject><dc:subject>\nRC0321<\/dc:subject><dc:description>\nPeer reviewed<\/dc:description><dc:description>\nPublisher PDF<\/dc:description><dc:date>\n2011-05-19T16:15:02Z<\/dc:date><dc:date>\n2011-05-19T16:15:02Z<\/dc:date><dc:date>\n2008-11-21<\/dc:date><dc:type>\nJournal article<\/dc:type><dc:identifier>\nMartinovic , J , Gruber , T & Mueller , M M 2008 , ' Coding of visual object features and feature conjunctions in the human brain ' PLoS ONE , vol 3 , no. 11 , e3781 . DOI: 10.1371\/journal.pone.0003781<\/dc:identifier><dc:identifier>\n1932-6203<\/dc:identifier><dc:identifier>\nPURE: 1592401<\/dc:identifier><dc:identifier>\nPURE UUID: 881f4d4e-d7e2-4f44-8537-abad7447b0f7<\/dc:identifier><dc:identifier>\nWOS: 000265448800002<\/dc:identifier><dc:identifier>\nScopus: 57049126370<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2164\/2061<\/dc:identifier><dc:identifier>\nhttp:\/\/dx.doi.org\/10.1371\/journal.pone.0003781<\/dc:identifier><dc:language>\neng<\/dc:language><dc:relation>\nPLoS ONE<\/dc:relation><dc:format>\n10<\/dc:format>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["issn:1932-6203","1932-6203"]}],"language":{"code":"en","id":9,"name":"English"},"relations":["PLoS ONE"],"year":2008,"topics":["gamma-band-responses","repetition priming task","human EEG","time-course","neurophysiological evidence","bioelectric events","evoked-potentials","recognition","color","identification","RC0321 Neuroscience. Biological psychiatry. Neuropsychiatry","RC0321"],"subject":["Journal article"],"fullText":"Coding of Visual Object Features and Feature\nConjunctions in the Human Brain\nJasna Martinovic1, Thomas Gruber2, Matthias M. Mu\u00a8ller3*\n1 School of Psychology, University of Liverpool, Liverpool, United Kingdom, 2 Institut fu\u00a8r Psychologie, University of Osnabru\u00a8ck, Osnabru\u00a8ck, Germany, 3 Institut fu\u00a8r\nPsychologie I, Universita\u00a8t Leipzig, Leipzig, Germany\nAbstract\nObject recognition is achieved through neural mechanisms reliant on the activity of distributed coordinated neural\nassemblies. In the initial steps of this process, an object\u2019s features are thought to be coded very rapidly in distinct neural\nassemblies. These features play different functional roles in the recognition process - while colour facilitates recognition,\nadditional contours and edges delay it. Here, we selectively varied the amount and role of object features in an entry-level\ncategorization paradigm and related them to the electrical activity of the human brain. We found that early\nsynchronizations (approx. 100 ms) increased quantitatively when more image features had to be coded, without reflecting\ntheir qualitative contribution to the recognition process. Later activity (approx. 200\u2013400 ms) was modulated by the\nrepresentational role of object features. These findings demonstrate that although early synchronizations may be sufficient\nfor relatively crude discrimination of objects in visual scenes, they cannot support entry-level categorization. This was\nsubserved by later processes of object model selection, which utilized the representational value of object features such as\ncolour or edges to select the appropriate model and achieve identification.\nCitation: Martinovic J, Gruber T, Mu\u00a8ller MM (2008) Coding of Visual Object Features and Feature Conjunctions in the Human Brain. PLoS ONE 3(11): e3781.\ndoi:10.1371\/journal.pone.0003781\nEditor: Jan Lauwereyns, Victoria University of Wellington, New Zealand\nReceived August 26, 2008; Accepted September 28, 2008; Published November 21, 2008\nCopyright: \u0001 2008 Martinovic et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits\nunrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\nFunding: The Deutsche Forschungsgemeinschaft supported this research. J.M. was supported by the DAAD and the ESRC.\nCompeting Interests: The authors have declared that no competing interests exist.\n* E-mail: m.mueller@rz.uni-leipzig.de\nIntroduction\nIn the initial steps of the recognition process, an object\u2019s features\nare thought to be coded very rapidly in distinct but coordinated\nneural assemblies. The significance of the detail in the depiction of\nthese features depends on the level of specificity at which object\nrepresentation occurs: while superordinate classification (e.g., iden-\ntifying an image of a bird as \u2018an animal\u2019) can be performed based on\nvery few image qualities that roughly define shape, basic level (e.g.,\nidentifying it as \u2018a bird\u2019) or subordinate level (e.g., identifying it as \u2018a\npenguin\u2019) classification will rely on other features too. In everyday life,\nobjects are recognised at the entry-level of recognition, which\ncombines basic and subordinate levels. This means that while more\ntypical exemplars will be recognised at basic-level (e.g., sparrow\nclassed as a \u2018bird\u2019), exemplars with distinct attributes will be\nrecognised at a subordinate level (e.g., \u2018an ostrich\u2019 or \u2018a peacock\u2019).\nSurface detail (texture, shading and colour) and visual complexity\n(intricacy of lines and detail) represent the two most obvious forms of\nobject-image properties that can impact on entry-level recognition\nprocesses. Their functional roles differ - while colour facilitates\nrecognition [1], additional amount of contours and edges delays it [2].\nTheories of object recognition differ in the significance they\nattribute to various kinds of object\u2019s features. Some consider\nrepresentations to rely mainly on shape [3,4], while others also\nacknowledge the contribution of surface detail, such as colour [5].\nRecent evidence supports the latter \u2018shape and surface\u2019 models\nthat posit a genuine role of surface detail: colour, in particular,\nshowing an advantage in recognition of objects [1], faces [6] and\nnatural scenes [7]. Facilitative effects of colour on behavioural\nperformance were recently confirmed in children [8] and illiterate\nadults [9], although it is often necessary to use presentation at\nthreshold levels (i.e., masked brief images) in order to obtain\nbehavioural effects of colour in normal adults. Colour is\nconsidered to be an aid in picture decoding or discrimination\nthrough improving access to stored object knowledge. Similarly,\nvisual complexity is assumed to determine the ease of picture\ndecoding, or the ease of processing before or at the structural stage\nof object recognition. However, opposite to colour, it has a\ndetrimental effect on recognition performance [2].\nObject features such as shape, colour or texture are coded very\nrapidly. Therefore, many researchers agree that an early stream of\nfeature-coding neural processes must drive the speed of object\nrecognition. Indeed, in cases when observers are looking for the\npresence of a particular object in natural scenes recognition can be\nultra-rapid. For example, Thorpe, Fize and Marlot [10] have shown\nthat approximately 150 ms is needed to identify the presence of an\nanimal in a natural scene. The initial feedforward stream of up to\n100\u2013150 ms is thus sufficient for coarse object categorisation [11,12].\nIt has been argued that this is due to an early activation of high-level\nunits in the ventral visual stream \u2013 these units are assumed to select\nhigh-level feature conjunctions diagnostic for target-category stimuli\n[13]. In the aforementioned Thorpe et al.\u2019s studies, recognition\noccurred at the superordinate level of specificity. But can the\nprocessing of features and feature-conjunctions also lead to such\nearly identification-related activations when objects need to be\nclassified at a more specific entry-level?\nElectroencephalography (EEG) provides a measure of fast\ntemporal processes that lead to object recognition and is an ideal\nPLoS ONE | www.plosone.org 1 November 2008 | Volume 3 | Issue 11 | e3781\ntool for assessing the temporal locus of representational processing.\nIn EEG studies, first object-related effects are reported to occur at\napprox. 80 ms [12], which is in the time range of the first positive\ncomponent P1 of the event-related potential (ERP). It is\nconsidered that early object-related effects in the P1 range are\ntask-independent: a product of low-level perceptual processing of\nimage properties, highly sensitive to changes in luminance,\ncontrast or spatial frequencies [14]. While P1 reflects the earliest\nevoked component carried by the lower frequency bands of the\nEEG signal (usually ERPs are filtered at 25 Hz), it partially\ntemporally overlaps with the evoked gamma-band activity (GBA).\nEvoked GBA is time and phase-locked to stimulus onset; it is\nevident around 50\u2013150 ms in the lower gamma-band frequency\nranges (30\u201340 Hz). Modulations of its amplitude reflect differences\nin the perceptual processing of features [15,16] and it is highly\nsensitive to changes in low-level properties of images [17,18].\nUsing an object\/non-object discrimination task, a few studies have\nobtained object-related modulations of evoked GBA [19,20],\nparalleling the early evoked effects seen by the Thorpe group.\nInduced GBA is non time or phase-locked to stimulus onset. It\nusually occurs around 200\u2013400 ms and its frequency (30\u201390 Hz)\ntends to vary between participants. Significant levels of induced\nGBA are elicited in studies that require identification of foveally\npresented familiar objects [21,22] and it is thought to reflect\nsynchronisation in distributed neural assemblies which is a marker\nof cortical object representation [23]. A frontal ERP component\nwith a latency of around 200\u2013400 ms known as the N350 is a\nmarker of another late representational process \u2013 object model\nselection, which matches the visual percept to stored object\nknowledge and is affected by image attributes [24,25].\nTo determine the temporal locus of identification-specific\nmodulations in entry-level recognition, we selectively varied the\namount and representational role of object features and related them\nto the electrical activity in the human brain (P1, N350, evoked and\ninduced GBA). In a series of EEG experiments, participants had to\nsuccessfully identify images of objects that contained different types\nor different degrees of visual object features (see Figure 1). We\nexamined the representation of surface detail (i.e., shading-defined\ntexture and colour; Experiment 1), visual complexity (i.e., amount of\ncontours; Experiment 2) and colour typicality (i.e., typical or atypical\ncolour of colour diagnostic objects; Experiment 3).\nThese features play different representational roles: colour\nfacilitates identification (with a particular role for colour diagnostic\nobjects) while additional contours deter it. In the EEG, we focused\non modulations of two early markers: the P1 and the evoked GBA.\nWe also assessed the N350 and induced GBA, as markers of late\nrepresentational activity. Object identification was assessed\nthrough a grammatical gender decision task, which required the\nparticipants to make a syntactic judgment on the object\u2019s name\n(for trial outlook, see Figure 2). This task was experimentally\nvalidated in a previous study [26] and due to it being an implicit\nnaming task, it ensured that object identification was performed at\nthe entry-level of specificity.\nResults\nExperiment 1: Surface detail\nDesign. This experiment relied on the Rossion and Pourtois\n[1] stimulus set of objects presented at different levels of surface\ndetail, based on the well-known and widely used Snodgrass and\nVanderwart [27] set. The set is large, containing objects from\nmany different categories. For each object, three versions of the\nimage are represented: a line, a grey-shaded and a coloured\ndrawing. A line drawing is a specific form of a 2D object-image,\nbecause it contains pre-processed edges. Also, the image of a line\ndrawing solely consists of high spatial frequencies. Meanwhile, in\naddition to those same predefined edges, textured or coloured line\ndrawings also contain information about the surface of the object,\ngiven in low spatial frequencies. Therefore, the images in the\nstimulus set differ both in their low-level visual properties, and in\nthe sources of information that can be used to access the object\nrepresentation (shape, or shape and colour).\nStimuli consisted of 210 images of familiar objects for each of\nthe three levels of surface detail (line, texture and colour; thus, 630\ntotal images; see Figure 1a); out of these, 67 were colour diagnostic\nand 143 were non colour diagnostic objects. Each participant was\nshown a randomly pre-selected subset of stimuli for each of the\nFigure 1. Examples of stimuli. a) Experiment 1: line drawings, gray-\nshaded and coloured images of objects (taken from Rossion and\nPourtois, 2004); b) Experiment 2: low and high visual complexity images\nof objects (taken from Bates et al., 2003); c) Experiment 3: typically and\natypically coloured images of colour-diagnostic objects (taken from\nNaor-Raz et al., 2003).\ndoi:10.1371\/journal.pone.0003781.g001\nFigure 2. Trial outlook (same for all experiments).\ndoi:10.1371\/journal.pone.0003781.g002\nObject Features\nPLoS ONE | www.plosone.org 2 November 2008 | Volume 3 | Issue 11 | e3781\nthree conditions \u2013 a total of 210 stimuli. By not presenting images\nof the same object with different level of surface detail to the same\nparticipant, previously reported repetition suppression effects in\nthe induced GBA were avoided [21,28]. Stimulus presentation was\nbalanced across the sample to control for item-specific effects.\nThus, across the sample, each object was seen equally often at\neach level of surface detail (line, texture, colour).\nFindings. Repeated measures ANOVA revealed no effect on\nreaction times (F (2, 16) = 0.84, n.s.) or accuracies (F (2, 16) = 0.61,\nn.s.) in an across participant analysis (see Figure 3). When colour\ndiagnostic objects were analysed in isolation across items, a\nsignificant reduction in response times was found (F (2, 65) = 4.28;\np,0.05) for coloured images (means: line drawing 1096618 ms;\nshaded 1117620 ms; coloured 1062618 ms). This demonstrates\nthat colour was indeed processed as a unique attribute of the\nobject image and facilitated object recognition.\nIn the EEG, we found a highly significant increase of amplitude\nfor both P1 (F (2, 16) = 9.29, p,0.001) and evoked GBA (F (2,\n16) = 3.50, p,0.05) when the amount of object features was\nincreased by adding surface detail (see Figure 4). A shift in the\nlatency of N350 was also found (F (2, 16) = 6.06, p,0.05), driven\nby shorter latencies for coloured pictures as opposed to both line\ndrawings (t (17) = 3.59, p,0.01) and textured drawings (t\n(17) = 2.21, p,0.05). There was no modulation of N350\u2019s\namplitude (F (2, 16) = 0.66, n.s.). Induced GBA\u2019s amplitude was\nnot modulated (F (2, 16) = 1.63, n.s.).\nConclusion. Surface detail increased the amplitude of early\nevoked activity elicited in our object identification paradigm. A\nselective latency shift of the N350 for coloured objects was also\nfound, reflecting a facilitatory effect of colour on object recognition.\nIs the increase in the amplitude of early components also related to\nthis facilitation, or is it an outcome of an increase in the amount of\nFigure 3. Accuracies and response times for Experiment 1. Data is depicted by box plots, with midlines indicating medians, ends of boxes\nindicating 25th and 75th percentiles, ends of lines indicating 10th and 90th percentiles, and dots indicating observations falling in the outlying 10\npercentiles.\ndoi:10.1371\/journal.pone.0003781.g003\nFigure 4. EEG findings from Experiment 1 (surface detail): ERPs and evoked GBA. a) ERPs: Grand mean baseline corrected ERP time courses\nat regional mean sites with time windows of P1 and N350 components indicated by grey boxes (black: line drawings; dotted: textured; magenta:\ncoloured). To the right, scalp topographies of P1 and N350, averaged across all conditions. b) Evoked GBA: Grand mean baseline-corrected TF-plots\naveraged across 128 electrodes. Black box indicates the time-window of maximal activity. To the right, grand mean 3D spherical spline amplitude-\nmap representing an average across conditions, based on the 62.5 Hz frequency band centred on the 35 Hz wavelet during the time-window of\nmaximal activity. Black box indicates the electrode sites of interest. All plots represent the average across the sample. Electrode names are given for\nchannels taken into regional means. Bar plots of grand mean evoked GBA are also given, with a one standard error bar.\ndoi:10.1371\/journal.pone.0003781.g004\nObject Features\nPLoS ONE | www.plosone.org 3 November 2008 | Volume 3 | Issue 11 | e3781\nobject features to be processed? In the next experiment, we\nmanipulated the amount of visual complexity in the image. The\ntwo effects should now dissociate: as high visual complexity has a\ndetrimental effect on recognition, an early mnemonic input would\nimply that it should evoke less activity than low visual complexity.\nHowever, if there is no early mnemonic input so that evoked activity\nrather reflects low-level feature processing, it should increase with\nadditional contours in high complexity items.\nExperiment 2: Visual Complexity\nDesign. Visual complexity usually denotes the amount of\ndifferent object-features contained in an image. Here, we define it\nas the amount of contour-given detail, qualifying the content in the\nimage that needs to be processed in order to recognise the image\nas that of a familiar object (as per [2]). Visual complexity can be\nmeasured either through mean subjective ratings of images\u2019 detail,\nor objectively through jpeg file size. According to Bates et al. [29],\nit is more accurate to use objective measures of image complexity\nthat are based on digitised file size. This is due to the fact that,\nunlike subjective visual complexity ratings, objective measures are\nindependent of culture-specific expectations about the \u2018\u2018best\u2019\u2019 way\nto represent a given concept.\nObjects from the International Picture Naming Project (IPNP)\nstimulus set [29] were selected into groups of low and high visual\ncomplexity based on jpeg file size. Stimuli consisted of 172 images of\nobjects: one half was of low and the other half of high visual\ncomplexity (for examples, see Figure 1b). IPNP contains 520 pictures\nwith listed German language naming norms for many relevant\nnaming factors. Items were carefully selected into matched and\ncontrolled groups of low and high complexity stimuli based on their\nvisual complexity rank. Initially, images showing objects with natural\ngender (e.g., a rooster or a hen) were removed, as natural gender\ncould selectively facilitate grammatical gender decisions for these\nitems. Subsequently, all items with neutral gender were removed, in\norder to reduce the number of possible responses to two equally\nfrequent types of response (masculine and feminine). The remaining\nitems were then ranked based on their visual complexity, with 25%\nof the items at the lower and upper end of the distribution taken into\nthe final stimulus set. Thus, each condition contained 86 images,\nwith 43 objects being of masculine gender and the other 43 of\nfeminine gender. In order to ascertain the differences between\nconditions in factors relevant for naming, important variables from\nthe IPNP norms were assessed (see Table 1). Across item one-way\nANOVA revealed that the two groups did not differ significantly in\nnormative naming times (F (1,170) = 2.41; n.s.) or other important\nnaming-related factors, apart from visual complexity. However,\ndifferences were found between objects of low and high conceptual\ncomplexity (i.e., the amount of object-elements necessary to depict\nthe represented concept), with slower naming times for more\ncomplex items (F (1, 170) = 6.02, p,0.05).\nFindings. Across participants, we found no differences in\nresponse times (t (17) =21.52, n.s.) or accuracies (t (17) =20.27,\nn.s.) between low and high visual complexity stimuli (Figure 5).\nSignificantly higher response times for more complex objects were\nfound in an across item comparison of objects differing in conceptual\ncomplexity (F (1, 169) = 10.64, p,0.001), confirming that\ndecoding of such images was adversely affected by increased\ncomplexity. An across item analysis verified that our response\ntimes related to German-language normative naming times by\nrevealing a highly significant correlation (r = 0.74, p,0.001).\nIn the EEG it was observed that P1 amplitudes (t (17) =23.83,\np,0.001) and evoked GBA amplitudes (t (17) =24.19, p,0.001)\nwere increased for visually highly complex items (see Figure 6).\nAdditionally, there was a shift in the latency of the P1 (t\n(17) = 7.06, p,0.001), with earlier peaks for highly complex\nobjects. N350 amplitude was also more negative for highly\ncomplex items (t (17) = 3.88, p,0.001). Induced GBA remained\nunmodulated (t (17) =20.10, n.s.).\nConclusion. It seems that early evoked activity reflects low-\nlevel feature processing since it was again increased with additional\nobject features, despite their detrimental role for object\nidentification. But what would happen if the number of features\nremained the same and their role for object recognition differed,\nbeing either facilitatory or detrimental for the speed of processing?\nTable 1. Picture-naming norms and average naming RTs across conditions for Experiment 2 (Means6SEs) (** p,0.001).\nVisual Complexity\n(JPEG file size, kb)\nWord Length (in\nphonological\nsyllables)\nWord Complexity\n(complex or not)\nName agreement\n(H statistic)\nFrequency (Log natural\ntransformation of fre-\nquency counts, CELEX)\nAverage naming\nRT for German\n[ms]\nLow complexity (n = 86) 76586161** 2.1360.09 0.3460.05 0.6760.07 2.0560.13 1090631\nHigh complexity (n = 86) 27 9846867** 2.2760.10 0.3160.05 0.8260.08 1.9060.16 1155629\ndoi:10.1371\/journal.pone.0003781.t001\nFigure 5. Accuracies and response times for Experiment 2. Data is depicted by box plots, with midlines indicating medians, ends of boxes\nindicating 25th and 75th percentiles, ends of lines indicating 10th and 90th percentiles, and dots indicating observations falling in the outlying 10\npercentiles.\ndoi:10.1371\/journal.pone.0003781.g005\nObject Features\nPLoS ONE | www.plosone.org 4 November 2008 | Volume 3 | Issue 11 | e3781\nTo answer this question, we conducted our final experiment,\ncontrasting identification of colour diagnostic objects which were\npresented either in their typical colour or in an atypical colour.\nExperiment 3: The typicality of object\u2019s colour\nDesign. Colour-shape associations in object recognition are\nintrinsic: Naor-raz et al. [30] have demonstrated that colour\ndiagnostic objects are recognized faster if presented in their typical\ncolours, while their processing is slowed if the colours are changed to\nan atypical hue (see Figure 1c). Such a role of visual colour\nknowledge implies that a yellow banana gives rise to a qualitatively\ndifferent type of processing than a purple banana \u2013 even when the\nshape in the image is same. In this experiment, we utilized the Naor-\nraz et al. [30] stimulus set with images of colour diagnostic objects\neither in their typical colour or in an atypical colour. The stimulus set\ncontained 138 images: each object could be presented either in its\ntypical or in an atypical colour. Typically and atypically coloured\nobjects were counterbalanced across participants, so that each\nstimulus was shown in each condition an equal number of times\nacross the sample.\nFindings. An across participants analysis revealed that RTs\nwere faster for typically coloured objects (typical colour\n1150623 ms, atypical colour 1202631 ms, t (25)=22.94,\np,0.01). Participants were also more accurate in responses to\ntypically coloured objects (typical colour 84.661.2%, atypical colour\n80.761.0%, t (25) = 3.04, p,0.01; see Figure 7).\nERP and evoked GBA results are shown in Figure 8. There\nwere no changes in P1 amplitudes (t (25) = 1.28, n.s.) or evoked\nGBA amplitudes (t (25) = 0.75, n.s.). However, the modulation in\nN350 amplitude was significant (t (25) = 2.15, p,0.05), with more\nFigure 6. EEG findings from Experiment 2 (visual complexity): ERPs and evoked GBA. a) ERPs: Grand mean baseline corrected ERP time\ncourses at regional mean sites with time windows of P1 and N350 components indicated by grey boxes (black: low visual complexity; magenta: high\nvisual complexity). To the right, scalp topographies of P1 and N350, averaged across conditions. b) Evoked GBA: Grand mean baseline-corrected TF-\nplots averaged across 128 electrodes. Black box indicates the time-window of maximal activity. To the right, grand mean 3D spherical spline\namplitude-map representing an average across conditions, based on the 62.5 Hz frequency band centred on the 35 Hz wavelet during the time-\nwindow of maximal activity. Black box indicates the electrode sites of interest. All plots represent the average across the sample. Electrode names are\ngiven for channels taken into regional means. Bar plots of grand mean evoked GBA are also given, with a one standard error bar.\ndoi:10.1371\/journal.pone.0003781.g006\nFigure 7. Accuracies and response times for Experiment 3. Data is depicted by box plots, with midlines indicating medians, ends of boxes\nindicating 25th and 75th percentiles, ends of lines indicating 10th and 90th percentiles, and dots indicating observations falling in the outlying 10\npercentiles.\ndoi:10.1371\/journal.pone.0003781.g007\nObject Features\nPLoS ONE | www.plosone.org 5 November 2008 | Volume 3 | Issue 11 | e3781\nnegativity for atypically coloured objects. Induced GBA remained\nunmodulated (t (25) =20.74, n.s.; see Figure 9).\nConclusion. In this experiment, with the overall amount of\nfeatures constant across conditions, the early evoked components\nremained unmodulated. The shift in N350 again reflected the\nnegative impact of atypical colours on the representational\nprocess, in line with the observed behavioural effects. Therefore,\nwe conclude that early evoked components reflect low-level feature\nprocessing. Task-relevant mnemonically influenced processing of\nobject features has its earliest effects on the N350 component, a\nmarker of object model selection.\nDiscussion\nWe selectively varied the amount and representational role of\nobject features and related them to the electrical activity of the\nhuman brain. The novelty of our study is in the fact that the\ncontribution of object features to representation was ensured by a\ntask that demanded entry-level identification, which is used in\neveryday perception of real-life objects (trees, houses, dogs, cars,\netc.). Therefore, for the first time it was possible to assess if the\nfeature\u2019s representational relevance would have a differential\nimpact on the earliest measures of object processing.\nThe role of features for object representation was confirmed\nthrough RT costs or benefits. P1 component of the ERP and\nevoked GBA\u2019s amplitude increased when more image features had\nto be coded, without reflecting the specific feature\u2019s qualitative\ncontribution to the recognition process. The similarity of the\neffects of surface detail on both the P1 and the evoked GBA\nindicates that these two components may reflect complementary\nand co-occurring sensory processing of stimuli. On the contrary,\nmodulations at the level of the ERP component N350 reflected the\nFigure 8. EEG findings from Experiment 3 (colour typicality): ERPs and evoked GBA. a) ERPs: Grand mean baseline corrected ERP time\ncourses at regional mean sites with time windows of P1 and N350 components indicated by grey boxes (black: typical colour; magenta: atypical\ncolour). To the right, scalp topographies of P1 and N350, averaged across conditions. b) Evoked GBA: Grand mean baseline-corrected TF-plots\naveraged across 128 electrodes. Black box indicates the time-window of maximal activity. To the right, grand mean 3D spherical spline amplitude-\nmap representing an average across conditions, based on the 62.5 Hz frequency band centred on the 35 Hz wavelet during the time-window of\nmaximal activity. Black box indicates the electrode sites of interest. All plots represent the average across the sample. Electrode names are given for\nchannels taken into regional means. Bar plots of grand mean evoked GBA are also given, with a one standard error bar.\ndoi:10.1371\/journal.pone.0003781.g008\nFigure 9. Time-by-Frequency plots for induced GBA (all experiments). a) Experiment 1 - surface detail. b) Experiment 2 - visual complexity; c)\nExperiment 3 - colour typicality. All plots represent a baseline-corrected grand mean at the sites of maximal activity. Black boxes indicate the time-\nwindow of induced GBA response for each condition.\ndoi:10.1371\/journal.pone.0003781.g009\nObject Features\nPLoS ONE | www.plosone.org 6 November 2008 | Volume 3 | Issue 11 | e3781\nrepresentational significance of object features. N350 is a\ncomponent sensitive to image quality and reflects integrative\nactivity that follows the initial processing stream in the visual\nsystem. The temporal locus of the feature-specific mnemonic effect\nwas thus at the N350 component, around approx. 200\u2013350 ms.\nInduced GBA, which co-occurs with the N350, remained\nunmodulated in its amplitude. Thus, induced GBA reflects stages\nof processing that do not directly relate to picture decoding\nprocesses and may be more conceptual in nature.\nOur findings on early evoked effects due to changes in object\nfeatures extend the findings of the Thorpe group [12] who studied\nsuperordinate object identification. They found earliest object-\nrelated EEG effects at 80 ms. While these effects were task-\nindependent, there were also task-related but category-indepen-\ndent modulations at approximately 150 ms. Such findings are\nlikely to stem from top-down driven segmentation of the image\nwherein high-level feature conjunctions are selected on the basis of\ntheir diagnosticity for target-category stimuli (vehicles or animals\n[13]). In our task, participants had to implicitly name images of\nobjects from a large and varied set: there was no segmentation\nfrom background involved and specific identity of each object had\nto be accessed. In such conditions, identification-specific effects\ncannot emerge as early \u2013 they are divergent from both sensory\nfeature-related effects at 80 ms, as well as from category-\nindependent but task-related effects of feature-conjunctions at\n150 ms. In our study, identification-specific effects started at\napproximately 200 ms and were observable at the level of the\nN350 component of the ERP. Convergent are the findings of\nJohnson and Olshausen [31] who attributed object-related\nchanges in ERP waveforms prior to 137 ms to early processing\nof featural differences and late changes post 150 ms to the\nrecognition process itself.\nWe found that N350 modulations matched the effects obtained in\nthe behavioural data: benefits for coloured objects (earlier latency in\nExperiment 1), as well as costs for more contours (higher amplitude\nin Experiment 2) or atypical colour of colour-diagnostic items (higher\namplitude in Experiment 3). N350 is known to reflect object-\nmatching processes and responds with higher amplitudes to images\nthat are not as straightforwardly identifiable [24,25]. N350 and its\nposterior complement Ncl are thought to be generated in the\nposterior ventral cortex \u2013 in particular, the lateral-occipital complex,\na significant part of the ventral recognition stream [32,33]. Schendan\nand Kutas [25] propose that N350 reflects a reactivation of occipito-\ntemporal cortex in order to integrate information across a wide range\nof representational regions, from early visual areas to the\nventrolateral prefrontal cortex [34,35]. Unlike earlier evoked\ncomponents, it was modulated by the features representational role,\nindicating that it is the earliest evoked locus of feature-driven\nmnemonic effects in entry-level object recognition.\nAlthough induced GBA is generally considered to be the earliest\nmarker of cortical object representation, it remained unmodulated\nin our study. Induced GBA\u2019s amplitude has thus been shown to be\nless sensitive to image attributes that drive perceptual processing of\nobjects. It may be that induced GBA\u2019s amplitude is more\ndependent on the conceptual processing of the object\u2019s identity.\nSuch conceptual processing is necessarily intertwined with\nperceptual processes, as semantic and perceptual levels of\nrepresentation are known to be coupled [36]. The conceptual\nnature of induced GBA is supported by the fact that it can also be\nelicited in word\/pseudoword discrimination paradigms with\nhighly similar attributes to peaks elicited with object\/non-object\ntasks. Both with words and visual objects, induced GBA peaks\nspanned the 200\u2013350 ms period and exhibited repetition suppres-\nsion effects for familiar words and objects ([21,22,37]). The\nimportance of semantic associations for induced GBA elicited by\nfamiliar objects is also demonstrated in the fact that even after 10\nrepetitions, unfamiliar objects (i.e., nonsensical images created by\nscrambling of familiar objects) do not start exhibiting the\nsharpening effect associated with repetition suppression [38]. In\nour experiments, induced GBA was always associated with\nsuccessful recognition of familiar objects. Thus, no variability in\nconceptual processes between conditions would be expected and is\nlikely to be reflected in the steady amplitude of the induced GBA\nacross conditions.\nAn explanation of scalp-recorded induced GBA as a manifestation\nof miniature or microsaccadic eye movements has recently been put\nforward [39]. Microsaccades are rapid small-amplitude eye\nmovements spontaneously occurring about once per second with\nthe main purpose of countering perceptual fading, whose role for\nvisual perception and attention is only starting to be explored [40].\nYuval-Greenberg et al. [39] observed that miniature eye movement\u2019s\nsaccadic spike potentials and induced GBA are both modulated by\nobject coherence and object type in a highly correlated fashion. In\nour study, lack of modulation of induced GBA\u2019s amplitude by object\nfeatures in the presence of multiple modulations of other more\nfeature-sensitive components (evoked GBA, ERPs) would indicate\nthat the induced GBA we have observed is different in nature to the\n\u2018miniature saccade\u2019 related activity reported by Yuval-Greenberg et\nal. [39]. Indeed, an ongoing discussion supports the possibility of\naccurate scalp-recordings of induced GBA if proper study design\n(foveal presentation with instruction to suppress eye movements) and\nartifact removal procedures are used (see comments at Neuron\nonline: http:\/\/www.neuron.org\/content\/article\/comments?uid=\nPIIS0896627308003012#top). Thus, we conclude that the commu-\nnality of object-related conceptual processes between conditions was\nreflected in the steady amplitude of the induced GBA, irrespective of\nthe changes in lower-level features.\nIn summary, it is now generally accepted that visual object\nidentification is achieved through a functional cooperation of\ndistributed brain regions, integrating diverse information in a\nremarkably fast and efficient fashion. In spite of great variability of\nviewpoints, sizes or possible occlusions in everyday visual scenes,\nobjects are identified within approx. 300 ms of processing time.\nModels of visual object recognition attempt to explain the rapid\nand concurrent processes that lead to successful object identifica-\ntion, with an initial feed forward processing stream followed by a\nseries of feedback loops. While the earliest processing, lasting up to\n100\u2013150 ms, deals with the analysis of low-level object features\nand their conjunctions, later stream of processing lasting up to\n300 ms is thought to reflect the mnemonic continuation of\nrepresentational activity [12,41]. Neurophysiological measures can\ndirectly reflect the time course of cognitive processes, making EEG\nan essential tool in studying differential processing of objects in the\nhuman brain during the crucial period of representational\nprocessing (i.e., up to 300\u2013400 ms). Our series of EEG\nexperiments systematically explored stimulus space according to\nobject feature\u2019s relevance to representational processing at entry-\nlevel of specificity, at which object\u2019s identity is accessed in everyday\nlife. It demonstrated that in these circumstances, feature-driven\nmnemonic effects can only appear in a time window that allows\nrecurrent and feedback interactions between representational\nbrain areas [25]. Any earlier effects (i.e. prior to 200 ms) are\nrelated to the amount of features in the image and their\nconjunctions which can be highly diagnostic of object identity\nunder specific tasks and stimulus sets (explaining the findings of\n[13,19]). In everyday vision categorical representational processing\nof objects is not ultra-rapid and seems to require the full 300 ms of\nneural processing. This has significant implications on models of\nObject Features\nPLoS ONE | www.plosone.org 7 November 2008 | Volume 3 | Issue 11 | e3781\nvisual object representation. Recently, pictorial models of object\nrepresentation which emphasise the differential contribution of\nimage features at several hierarchically organised stages of\nclassification have emerged [42]. The body of EEG findings in\nobject recognition support such feature-based models. Thus,\ndepending on the level of specificity of classification, the\ncontribution of features can be either early -subserving ultra-rapid\nbut coarse categorisation as in the studies of Thorpe and\nHerrmann research groups- or late -subserving entry-level\ncategorisation that was examined in this study.\nMaterials and Methods\nParticipants\nHealthy university students received class credit or a small\nhonorarium for participating in the study (Experiment 1: 18\nparticipants aged 19\u201339 years, mean age= 23 years; Experiment\n2: 18 participants aged 18\u201326 years, mean age = 22 years;\nExperiment 3: 25 participants aged 19\u201333, mean age 33 years).\nParticipants had been removed from the sample when technical\nproblems had occurred during the recording or if they exhibited\nexcessive EEG artifacts (less than 60% artifact free trials)\n(Experiment 1: two participants; Experiment 2: three participants;\nExperiment 3: four participants). Participants reported normal or\ncorrected-to-normal vision and all were native speakers of\nGerman. None had participated in object recognition studies in\npreceding six months. Individual written informed consent was\nobtained and the study conformed to the Code of Ethics of the\nWorld Medical Association.\nStimulus presentation and task\nStimulus presentation occurred in a random order, which was\ndifferent for each of the participants. Participants performed an\nimplicit naming task requiring them to press a different button\ndepending on the grammatical gender of object\u2019s name (in\nExperiments 1 and 3 masculine, feminine or neutral; in\nExperiment 2 masculine or feminine). For a detailed description\nof the task, see Martinovic et al. [26]. Participants first performed a\npractice block (in Experiment 1, 32 trials; in Experiment 2, 40\ntrials; in Experiment 3, 30 trials) \u2013 the practice contained a subset\nof stimuli that were not used in the experiment itself. Experiment 1\nconsisted of two blocks, each one lasting approximately seven\nminutes and containing 105 trials. Experiment 2 had four blocks\nwith 43 stimuli, each lasting approx. three minutes. Experiment 3\nconsisted of two blocks with 69 trials, each lasting approx. four and\na half minutes. Each trial consisted of a variable 500\u2013800 ms\nbaseline period, during which a black fixation cross (0.6u60.6u)\nwas presented. The fixation cross was then removed and a\nstimulus picture was displayed for 650 ms. The picture was then\nreplaced by the fixation cross, which remained on the screen for\nanother period of 1650 ms. This was followed by the display of an\n\u2018X\u2019 for 900 ms, during which participants were allowed to blink.\nStimuli were presented centrally on a 19-inch computer screen,\nwith a 70 Hz refresh rate. The monitor was positioned outside of\nthe dimly lit soundproof testing chamber and the participants\nviewed it through a window from a 1 m distance. The objects\npresented on the images subtended a visual angle ranging from\naround 1.5u to around 4.6u. All stimuli were shown on a white\nbackground. Stimulus onset was synchronised to the vertical\nretrace of the monitor. The presentation and the timing of the\nexperiment were controlled using a Matlab Toolbox, allowing\nvisual presentation and response-recording with precise timing\n(Cogent, www.vislab.ucl.ac.uk\/Cogent\/; The Mathworks, Inc,\nNatick, Massachusetts). Halfway through the experiment partic-\nipants were asked to change the responding hand. Participants\nwere instructed to minimise eye movements and blinking during\nthe display of a stimulus or the fixation cross.\nEEG recording\nEEG was recorded continuously from 128 locations using active\nAg-AgCl electrodes (BioSemi Active-Two amplifier system; Biosemi,\nAmsterdam, The Netherlands) placed in an elastic cap. In this system\nthe typically-used \u2018\u2018ground\u2019\u2019 electrodes in other EEG amplifiers are\nreplaced through the use of two additional active electrodes,\npositioned in close proximity to the electrode Cz of the international\n10\u201320 system [43]: CommonMode Sense (CMS) acts as a recording\nreference and Driven Right Leg (DRL) serves as ground [44,45].\nHorizontal and vertical electrooculograms were recorded in order to\nexclude trials with blinks and significant eye movements. EEG signal\nwas sampled at a rate of 512 Hz and was segmented into epochs\nstarting 500 ms prior and lasting 1500 ms following picture onset.\nEEG data processing was performed using the EEGlab toolbox [46]\ncombined with in-house procedures running under the Matlab (The\nMathworks, Inc, Natick, Massachusetts) environment. Artefact\ncorrection was performed by means of \u2018\u2018statistical correction of\nartefacts in dense array studies\u2019\u2019 (SCADS; [47]). It is widely accepted\nin the field and has been applied and described in several\npublications [48,49]. All incorrectly answered trials were excluded\nprior to data analysis. In Experiment 1, the average rejection rate\nwas 29.3%, resulting in approx. 44 remaining trials per condition. In\nExperiment 2, the average rejection rate was 29.6%, resulting in\napprox. 53 remaining trials per condition. In Experiment 3, the\naverage rejection rate was 26.5%, resulting in approx. 42 remaining\ntrials per condition. Further analyses were performed using the\naverage reference.\nBehavioural data analysis\nRTs between 400 and 2300 ms, the maximum time allowed for\nresponses, for trials with correct responses were taken into further\nanalysis. Accuracy rates were analysed across participants while\nRTs on correctly answered trials were analysed both across\nparticipants and across items. Median RTs for correct items were\ncomputed for each participant. Means across participants were\nthen computed to obtain a measure of central tendency known as\na mean of median RT. This was done due to the skewness of RT\ndistributions and is a common procedure when working with RTs\n(e.g., see [26]). Across participant differences were analysed with\nrepeated measures ANOVAs or paired t-tests; across item\ndifferences were analysed with one-way ANOVAs.\nEvent related potentials (ERPs) analysis\nA 25 Hz low-pass filter was applied to the data before all ERP\nanalyses. Two ERP components were assessed: P1 and N350.\nFigures 3\u20135 (see Results) list the analysis windows and electrode\nsites taken into the regional mean for each component. Mean\namplitude within the respective time window was calculated for\neach component and mean amplitude during the period 100 ms\nprior to stimulus onset (baseline) was subtracted. Each component\nwas subject to repeated measures ANOVAs or paired t-tests. Post-\nhoc tests were performed using paired t-tests.\nAnalysis of evoked and induced spectral changes\nHigh frequency oscillatory activity was analysed according to\nthe standard procedure employed in many previous studies (e.g.,\n[21,22,26,50]). In brief, spectral changes in oscillatory activity\nwere analysed by means of Morlet wavelet analysis [51], which\noffers a good compromise between time and frequency resolution\nObject Features\nPLoS ONE | www.plosone.org 8 November 2008 | Volume 3 | Issue 11 | e3781\n[23]. This method provides a time-varying magnitude of the signal\nin each frequency band leading to a time-by-frequency (TF)\nrepresentation of the signal and, together with suggested\nparameter definitions that allow for a good time and frequency\nresolution in the gamma frequency range, is detailed in previous\nstudies (e.g. [22]). In order to achieve good time and frequency\nresolution in the gamma frequency range, the wavelet family in\nthis study was defined by a constant m= f0 \/sf = 7, with f0\nranging from 2.5 to 100 Hz in 0.5 Hz steps. This data was\nsubsequently reduced to form 2.5 Hz-wide wavelets. Time-varying\nenergy in a given frequency band was calculated for each epoch by\ntaking the absolute value of the convolution of the signal with the\nwavelet.\nPreliminary electrode sites used for time-by-frequency plots\nwere selected on the basis of previous findings of maximal local\ngamma power elicited by object identification paradigms; parietal\nfor induced GBA ([21,22,52]) and occipital for evoked GBA\n([52,53,54,55]). These sites were further readjusted in order to\nenvelop the area of maximal amplitude for data collapsed across\nconditions in case the observed grand mean topography happened\nto differ from previous findings.\nIn order to identify the time window and frequency range of the\nGBA peaks mean baseline-corrected spectral amplitude (baseline:\nbetween 200 and 100 ms prior to stimulus onset) was collapsed\ntogether for all conditions and represented in TF-plots in the 30\u2013\n90 Hz range. The length of the time window of maximal gamma\nband amplitude was defined based on the observed grand-mean\nGBA, a common approach in previous studies (e.g., [17,22]).\nMaps of oscillatory responses in the 65 Hz frequency band\ncentred upon the 35 Hz wavelet (for evoked GBA) or maximal\nactivity wavelet for each participant (for induced GBA) during the\ntime window of maximal activity were calculated by means of\nspherical spline interpolations [56]. Regional means of interest\nwere determined on the basis of grand mean topographies.\nEvoked oscillatory activity is by definition time-and phase-\nlocked to stimulus onset and was analysed through a transforma-\ntion of the unfiltered ERP into the frequency domain. Evoked\nGBA has low inter-individual variability and in object categorisa-\ntion studies that use line-drawings it is usually observed at\nfrequencies between 30 and 40 Hz, with maximal activity usually\noccurring in a narrow time interval around 50\u2013150 ms post\nstimulus-onset (e.g., [21,22,50]). Therefore a 65 Hz range was\ntaken around a central wavelet of 35 Hz within a time window of\n50\u2013150 ms. Due to inter-individual differences in the induced\ngamma peak in the frequency domain a specific wavelet for each\nparticipant was chosen based on the frequency of his\/her maximal\namplitude in an average across all three conditions. Centred upon\nthis wavelet a frequency band of 65 Hz was subsequently formed\nfor the purpose of statistical analyses.\nDifferences between conditions at the regional mean sites in the\namplitude after baseline subtraction were analysed by means of\nrepeated measurement ANOVAs or paired t-tests.\nAcknowledgments\nWe would like to thank Renate Zahn, Sophie Trauer and Tobias Forderer\nfor their help with data acquisition and S\u00f8ren Andersen for technical\nassistance. We would also like to thank Quoc Vuong for helpful comments\non the manuscript.\nAuthor Contributions\nConceived and designed the experiments: JM MMM. Performed the\nexperiments: JM. Analyzed the data: JM TG. Contributed reagents\/\nmaterials\/analysis tools: TG MMM. Wrote the paper: JM MMM.\nReferences\n1. Rossion B, Pourtois G (2004) Revisiting Snodgrass and Vanderwart\u2019s object\npictorial set: The role of surface detail in basic-level object recognition.\nPerception 33: 217\u2013236.\n2. Ellis AW, Morrison CM (1998) Real age-of-acquisition effects in lexical retrieval.\nJournal of Experimental Psychology: Learning, Memory and Cognition 24:\n515\u2013523.\n3. Marr D, Nishihara HK (1978) Representation and recognition of the spatial\norganization of three-dimensional shapes. Proceedings of the Royal Society of\nLondon, Series B 200: 269\u2013294.\n4. Biederman I (1987) Recognition-by-components: A theory of human image\nunderstanding. Psychological Review 94: 115\u2013147.\n5. Tanaka JW, Weiskopf D, Williams P (2001) The role of color in high level vision.\nTrends in Cognitive Sciences 5: 211\u2013215.\n6. Yip AW, Sinha P (2002) Contribution of color to face recognition. Perception\n31: 995\u20131003.\n7. Gegenfurtner KR, Rieger J (2000) Sensory and cognitive contributions of color\nto the recognition of natural scenes. Current Biology 10: 805\u2013808.\n8. Funnell E, Hughes D, Woodcock J (2006) Age of acquisition for naming and\nknowing: A new hypothesis. Quarterly Journal of Experimental Psychology 59:\n268\u2013295.\n9. Reis A, Faisca L, Ingvar M, Petersson KM (2006) Color makes a difference:\nTwo-dimensional object naming in literate and illiterate subjects. Brain and\nCognition 60: 49\u201354.\n10. Thorpe S, Fize D, Marlot C (1996) Speed of processing in the human visual\nsystem. Nature 381: 520\u2013522.\n11. Fize D, Fabre-Thorpe M, Richard G, Doyon B, Thorpe SJ (2005) Rapid\ncategorization of foveal and extrafoveal natural images: Associated ERPs and\neffects of lateralization. Brain and Cognition 59: 145\u2013158.\n12. VanRullen R, Thorpe SJ (2001) The time course of visual processing: from\nearly perception to decision-making. Journal of Cognitive Neuroscience 13:\n454\u2013461.\n13. Rousselet GA, Mace MJM, Thorpe SJ, Fabre-Thorpe M (2007) Limits of event-\nrelated potential differences in tracking object processing speed. Journal of\nCognitive Neuroscience 19: 1241\u20131258.\n14. Regan D (1989) Human brain electrophysiology. New York: Elsevier.\n15. Eckhorn R, Reitboeck HJ, Arndt M, Dicke P (1990) Feature linking via\nsynchronization among distributed assemblies: simulations of results from cat\nvisual cortex. Neural Computation 2: 293\u2013307.\n16. Karakas S, Basar E (1998) Early gamma response is sensory in origin: a\nconclusion based on cross-comparison of results from multiple experimental\nparadigms. International Journal of Psychophysiology 31: 13\u201331.\n17. Busch NA, Debener S, Kranczioch C, Engel AK, Herrmann CS (2004) Size\nmatters: effects of stimulus size, duration and eccentricity on the visual gamma-\nband response. Clinical Neurophysiology 115: 1810\u20131820.\n18. Fru\u00a8nd I, Busch NA, Korner U, Schadow J, Herrmann CS (2007) EEG\noscillations in the gamma and alpha range respond differently to spatial\nfrequency. Vision Reasearch 47: 2086\u20132098.\n19. Herrmann CS, Lenz D, Junge S, Busch NA, Maess B (2004) Memory-matches\nevoke human gamma-responses. BMC Neuroscience 5: 13.\n20. Fru\u00a8nd I, Busch NA, Schadow J, Gruber T, Ko\u00a8rner U, et al. (2008) Time\npressure modulates electrophysiological correlates of early visual processing.\nPLOS Biology 3: e1675.\n21. Gruber T, Malinowski P, Mu\u00a8ller MM (2004) Modulation of oscillatory brain\nactivity and evoked potentials in a repetition priming task in the human EEG.\nEuropean Journal of Neuroscience 19: 1073\u20131082.\n22. Gruber T, Mu\u00a8ller MM (2005) Oscillatory brain activity dissociates between\nassociative stimulus content in a repetition priming task in the human EEG.\nCerebral Cortex 15: 109\u2013116.\n23. Tallon-Baudry C, Bertrand O (1999) Oscillatory gamma activity in humans and\nits role in object representation. TICS 3: 151\u2013162.\n24. Schendan HE, Kutas M (2003) Time course of processes and representations\nsupporting visual object identification and memory. Journal of Cognitive\nNeuroscience 15: 111\u2013135.\n25. Schendan HE, Kutas M (2007) Neurophysiological evidence for the time course\nof activation of global shape, part, and local contour representations during\nvisual object categorization and memory. Journal of Cognitive Neuroscience 19:\n734\u2013749.\n26. Martinovic J, Gruber T, Hantsch A, Mu\u00a8ller MM (2008) Induced gamma-band\nactivity is related to the time point of object identification. Brain Research 1198:\n93\u2013106.\n27. Snodgrass JG, Vanderwart M (1980) A standardized Set of 260 pictures: Norms\nfor name agreement, image agreement, familiarity and visual complexity.\nJournal of Experimental Psychology: Human Learning and Memory 6:\n174\u2013215.\n28. Gruber T, Mu\u00a8ller MM (2002) Effects of picture repetition on induced gamma\nband responses, evoked potentials, and phase synchrony in the human EEG.\nCognitive Brain Research 13: 377\u2013392.\nObject Features\nPLoS ONE | www.plosone.org 9 November 2008 | Volume 3 | Issue 11 | e3781\n29. Bates E, D\u2019Amico S, Jacobsen T, Szekely A, Andonova E, et al. (2003) Timed\npicture naming in seven languages. Psychonomic Bulletin & Review 10:\n344\u2013380.\n30. Naor-Raz G, Tarr MJ, Kersten D (2003) Is color an intrinsic property of object\nrepresentation? Perception 32: 667\u2013680.\n31. Johnson JS, Olshausen BA (2003) Timecourse of neural signatures of object\nrecognition. Journal of Vision 3: 499\u2013512.\n32. Schendan HE, Kutas M (2002) Neuropsychological evidence for two processing\ntimes for visual object identification. Neuropsychologia 40: 931\u2013945.\n33. Doniger GM, Foxe JJ, Murray MM, Higgins BA, Snodgrass JG, et al. (2000)\nActivation timecourse of ventral visual stream object-recognition areas: High\ndensity electrical mapping of perceptual closure processes. Journal of Cognitive\nNeuroscience 12: 615\u2013621.\n34. David O, Harrison L, Friston KJ (2005) Modelling event-related responses in the\nbrain. Neuroimage 25: 756\u2013770.\n35. Brincat SL, Connor CE (2006) Dynamic shape synthesis in posterior\ninferotemporal cortex. Neuron 49: 17\u201324.\n36. van Schie HT, Wijers AA, Kellenbach ML, Stowe LA (2003) An event-related\npotential investigation of the relationship between semantic and perceptual levels\nof representation. Brain and Language 86: 300\u2013325.\n37. Fiebach CJ, Gruber T, Supp GG (2005) Neuronal mechanisms of repetition\npriming in occipitotemporal cortex: spatiotemporal evidence from functional\nmagnetic resonance imaging and electroencephalography. Journal of Neurosci-\nence 25: 3414\u20133422.\n38. Conrad N, Giabbiconi CM, Mu\u00a8ller MM, Gruber T (2007) Neuronal correlates\nof repetition priming of frequently presented objects: Insights from induced\ngamma band responses. Neuroscience Letters 429: 126\u2013130.\n39. Yuval-Greenberg S, Tomer O, Keren AS, Nelken I, Deouell LY (2008)\nTransient induced gamma-band response in EEG as a manifestation of\nminiature saccades. Neuron 58: 429\u2013411.\n40. Engbert R (2006) Microsaccades: A microcosm for research on oculomotor\ncontrol, attention and visual perception. In: Martinez-Conde S, Macknik S,\nMartinez L, Alonso J-M, Tse P, eds. Fundamentals of vision: Low and mid-level\nprocesses in perception. Amsterdam: Elsevier. pp 177\u2013192.\n41. Bar M, Kassam KS, Ghuman AS, Boshyan J, Schmid AM, et al. (2006) Top-\ndown facilitation of visual recognition. Proceedings of the National Academy of\nSciences of USA 103: 449\u2013454.\n42. Ullman S (2007) Object recognition and segmentation by a fragment-based\nhierarchy. Trends in Cognitive Sciences 11: 58\u201364.\n43. Jasper HH (1958) The 10\u201320 electrode system of the International Federation.\nElectroencephalography and Clinical Neurophysiology 10: 370\u2013375.\n44. Metting Van Rijn AC, Peper A, Grimbergen CA (1990) High quality recording\nof bioelectric events: I: interference reduction, theory and practice. Medical and\nBiological Engineering and Computing 28: 389\u2013397.\n45. Metting Van Rijn AC, Peper A, Grimbergen CA (1991) High quality recording\nof bioelectric events. II: a low noise low-power multichannel amplifier design.\nMedical and Biological Engineering and Computing 29: 433\u2013440.\n46. Delorme A, Makeig S (2004) EEGLAB: an open source toolbox for analysis of\nsingle-trial EEG dynamics including independent component analysis. Journal of\nNeuroscience Methods 134: 9\u201321.\n47. Junghoefer M, Elbert T, Tucker DM, Braun C (2000) Statistical control of\nartifacts in dense array EEG\/MEG studies. Psychophysiology 37: 523\u2013532.\n48. Gruber T, Mu\u00a8ller MM, Keil A, Elbert T (1999) Selective visual-spatial attention\nalters induced gamma band responses in the human EEG. Clinical\nNeurophysiology 110: 2074\u20132085.\n49. Muller MM, Keil A (2004) Neuronal synchronization and selective color\nprocessing in the human brain. Journal of Cognitive Neuroscience 16: 503\u2013522.\n50. Martinovic J, Gruber T, Mu\u00a8ller MM (2007) Induced gamma-band responses\npredict recognition delays during object identification. Journal of Cognitive\nNeuroscience 19: 921\u2013934.\n51. Bertrand O, Pantev C (1994) Stimulus frequency dependence of the transient\noscillatory auditory evoked response (40 Hz) studied by electric and magnetic\nrecordings in human. In: Pantev C, Elbert T, Lu\u00a8tkenho\u00a8ner B, eds. Oscillatory\nEvent-Related Brain Dynamics. New York: Plenum Press. pp 231\u2013242.\n52. Martinovic J, Gruber T, Mu\u00a8ller MM (2007) Induced gamma-band responses\npredict recognition delays during object identification. Journal of Cognitive\nNeuroscience 19: 1\u201314.\n53. Tallon-Baudry C, Bertrand O, Delpuech C, Pernier J (1997) Oscillatory gamma-\nband (30\u201370 Hz) activity induced by a visual search task in human. The Journal\nof Neuroscience 17: 722\u2013734.\n54. Busch NA, Herrmann CS, Mu\u00a8ller MM, Lenz D, Gruber T (2006) A cross-lab\nstudy of event-related gamma activity in a standard object-recognition\nparadigm. Neuroimage 33: 1169\u20131177.\n55. Herrmann CS, Mecklinger A, Pfeifer E (1999) Gamma responses and ERPs in a\nvisual classification task. Clinical Neurophysiology 110: 636\u2013642.\n56. Perrin F, Pernier J, Bertrand O, Echallier JF (1988) Spherical splines for scalp\npotential and current source density mapping. Electroencephalography and\nClinical Neurophysiology 72: 184\u2013187.\nObject Features\nPLoS ONE | www.plosone.org 10 November 2008 | Volume 3 | Issue 11 | e3781\n"}
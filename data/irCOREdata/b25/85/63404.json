{"doi":"10.1016\/S0098-3004(00)00048-0","coreId":"63404","oai":"oai:nora.nerc.ac.uk:2408","identifiers":["oai:nora.nerc.ac.uk:2408","10.1016\/S0098-3004(00)00048-0"],"title":"Geoscience after IT: Part M. Business requirements that drive the information system, and provide coherent frameworks","authors":["Loudon, T.V."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":["Loudon, T.V."],"datePublished":"2000-04","abstract":"The roles of participants in the information system are changing, and this is reflected in their business groupings and motivation. IT brings greater flexibility to the record, but without a coherent framework, cyberspace becomes a chaotic sludge of trivial ephemera. Cataloging and indexing, peer review by editorial boards and the disciplined approach of information communities can impose the necessary order and standards. Metadata and data models can help to maintain a clear structure for geoscience. Business aspects link the objectives of the investigator to the framework of the science, defining the logic of reorganization and providing incentives to drive the system","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/63404.pdf","fullTextIdentifier":"http:\/\/nora.nerc.ac.uk\/2408\/1\/Part_M.pdf","pdfHashValue":"1b8e424d3b0a5889c42f79639e236476e4f15e37","publisher":"Pergamon Elsevier-Science Ltd, Oxford","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:nora.nerc.ac.uk:2408<\/identifier><datestamp>\n      2012-11-22T11:48:22Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D5338<\/setSpec><setSpec>\n      7375626A656374733D5339<\/setSpec><setSpec>\n      7375626A656374733D533130<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/2408\/<\/dc:relation><dc:title>\n        Geoscience after IT: Part M. Business requirements that drive the information system, and provide coherent frameworks<\/dc:title><dc:creator>\n        Loudon, T.V.<\/dc:creator><dc:subject>\n        Computer Science<\/dc:subject><dc:subject>\n        Data and Information<\/dc:subject><dc:subject>\n        Earth Sciences<\/dc:subject><dc:description>\n        The roles of participants in the information system are changing, and this is reflected in their business groupings and motivation. IT brings greater flexibility to the record, but without a coherent framework, cyberspace becomes a chaotic sludge of trivial ephemera. Cataloging and indexing, peer review by editorial boards and the disciplined approach of information communities can impose the necessary order and standards. Metadata and data models can help to maintain a clear structure for geoscience. Business aspects link the objectives of the investigator to the framework of the science, defining the logic of reorganization and providing incentives to drive the system.<\/dc:description><dc:publisher>\n        Pergamon Elsevier-Science Ltd, Oxford<\/dc:publisher><dc:contributor>\n        Loudon, T.V.<\/dc:contributor><dc:date>\n        2000-04<\/dc:date><dc:type>\n        Publication - Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/2408\/1\/Part_M.pdf<\/dc:identifier><dc:identifier>\n         \n\n  Loudon, T.V..  2000  Geoscience after IT: Part M. Business requirements that drive the information system, and provide coherent frameworks.   Computers & Geosciences, 26 (3, Sup). A123-A132.  https:\/\/doi.org\/10.1016\/S0098-3004(00)00048-0 <https:\/\/doi.org\/10.1016\/S0098-3004(00)00048-0>     \n <\/dc:identifier><dc:relation>\n        http:\/\/www.elsevier.com\/wps\/find\/journaldescription.cws_home\/398\/description#description<\/dc:relation><dc:relation>\n        doi:10.1016\/S0098-3004(00)00048-0<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/nora.nerc.ac.uk\/id\/eprint\/2408\/","http:\/\/www.elsevier.com\/wps\/find\/journaldescription.cws_home\/398\/description#description","doi:10.1016\/S0098-3004(00)00048-0"],"year":2000,"topics":["Computer Science","Data and Information","Earth Sciences"],"subject":["Publication - Article","PeerReviewed"],"fullText":"<<<Back to Table of Contents      \nOn to Epilog (or prolog)>>> \n \n \nGeoscience after IT: Part M \n \nBusiness requirements drive the information system, and \nprovide coherent frameworks \n \nT. V. Loudon \nBritish Geological Survey, West Mains Road, Edinburgh EH9 3LA, U.K. \ne-mail: v.loudon@bgs.ac.uk \n \n \nPostprint of article in Computers & Geosciences, 26 (3A) April 2000, pp. A123-A132 \n \nAbstract - The roles of participants in the information system are changing, and this \nis reflected in their business groupings and motivation. IT brings greater flexibility to \nthe record, but without a coherent framework, cyberspace becomes a chaotic sludge of \ntrivial ephemera. Cataloging and indexing, peer review by editorial boards and the \ndisciplined approach of information communities can impose the necessary order and \nstandards. Metadata and data models can help to maintain a clear structure for \ngeoscience. Business aspects link the objectives of the investigator to the framework \nof the science, defining the logic of reorganization and providing incentives to drive \nthe system. \n \nKey Words - Catalogs, editorial boards, information communities, information system \nstrategy, business aspects. \n \n \n1. Activities, participants, roles and driving forces \n \nSubsystems are selected to minimize their interactions (part I, section 2.2). \nNevertheless, much of the interest lies at the interfaces. Scientific investigations are \nconducted at the interface between the real world and the information system, \ndrawing information from the repositories, testing or extending it by observations and \nmeasurements in the real world, and returning with conclusions that may be added to \nthe knowledge base. The scientists' activities (D 7) are usually described by verbs, \nsuch as investigate, integrate, explain, curate, communicate. During a project, there is \nat least one cycle of activities (applying processes to objects), such as plan, undertake \ndesk studies and field work, analyze, report, review, possibly return to additional \nstudy of the literature, more field work, and so on. Fig. 1 shows them within a circle, \nto avoid an arbitrary beginning or end. \n \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \n \n \nFig. 1. Some activities in a project. A cycle of activities that may be followed more than once during an \ninvestigation. \n \nThe investigators and the users of the information interact with many other \nparticipants (those playing a part in the operation of the information system). \nManagers may define the business setting, possibly standing in as proxies for other \nstakeholders such as customers or stockholders. In an educational environment, \nsupervisors may interpret the views of professors and other academics. Contact with \nthe recorded knowledge base is likely to be through intermediaries (who assist the \nuser or contributor to interact with some aspect of the system), such as librarians, \ninformation scientists, booksellers and curators. Collection of data may be assisted by \nlaboratory staff, instrumentation experts, field and laboratory assistants. Recording the \nresults may involve typists, data-entry specialists, reviewers, editors, referees, \ncurators, catalogers, database administrators, printers and publishers. The managers or \nsupervisors are likely at all stages to advise, monitor progress, and ensure that the \nresults conform to the intended objectives. The recommendations of standards \norganizations have a bearing at all stages. In addition, scientists interact informally \nwith others working in a similar area or topic, with customers, and with those who can \nsupply more detailed information or who are involved in broader studies.   \n \nTechnology reduces the dependence of authors and users on intermediaries, such as \nthose just mentioned (see also B 1, M 2.1). As the information industry changes in \nresponse to new technology, the new participants tend to be described in terms of \ntheir roles, and some of the old categories can be merged with the new. The roles \ninclude clients; users; information owners, keepers and suppliers; database and \nrepository managers; Internet service providers; network (communications and \ndelivery) operators; webmasters; application developers; standards setters and quality \nassessors. The client\/server mode of operation places responsibility for storing and \nserving the information with the originator, probably delegated to a proxy, and the \nform of presentation with the client who reads the information. The considerable \nsupport from the IT industry and the service suppliers, the \/ between client and server, \nis a vital, often neglected, component, but is not our subject here. \n \nThe participants work together in business groupings, such as oil companies or \nacademic faculties, sharing broad objectives and ways of working. The organization is \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nlikely to be staffed with a range of experts to meet the demands of the projects it \nundertakes. It probably provides financial support and shared facilities, such as access \nto records, libraries, laboratories and computing facilities. The participants are \nthemselves likely to be represented as objects in other databases, such as staff lists \nand personnel files. These may well contain information useful to the scientist, such \nas an e-mail address or the name of a student\u2019s supervisor. The need to communicate \ncrosses all boundaries and cannot be limited by system definitions.  \n \nInformation is driven through the system by powerful forces. Curiosity or commercial \ngain may be the initial incentive for investigation. A desire to share the results, \nperhaps to gain kudos, promotion or scientific standing, can carry the process \nforward. Without such forces, it is unlikely that the system would operate at all, and \ntheir identification (preferably without undue cynicism) is an important part of \nanalyzing the system. The motivating factors that drive the participants (Herzberg et \nal, 1993) include opportunities for achievement, recognition and advancement, and \nthe chance to exercise creativity and take on responsibility. In any change to the \nsystem, motivation must be kept in mind to ensure cooperation in the new \ndevelopment. Its form may determine, for example, whether information sharing or \ninformation hoarding seems more attractive (I 8.2, M 3.2). The motives of, say, the \nscientist and the publisher may conflict, creating tension within the information \nsystem that has to be managed by negotiation.  The information system is a social \ncreation involving many disparate contributors in a shared activity. It will succeed or \nfail (Peuquet and Bacastow, 1991) depending on the motivation of all concerned.  \n \n2. Frameworks for models \n \nRecorded information has in the past been formalized and fragmented into maps, \nreports, databases, archives and collections. We are now at an early stage in the global \ndevelopment of the hypermedia knowledge repository also known as cyberspace. \nContributors of information are not constrained by the form of final presentation. This \ncan be decided by users to meet their specific requirements. Users can bring together \ninformation from many sources, align differing ideas, employ visualization \ntechniques, and present the results as they see fit. However, although the system can \naccommodate individual contributions on their own terms, that merely transfers to \nusers the task of finding and integrating information from different sources. \nFlexibility is obtained at the cost of a clear structure. \n \nFrom the desktop we reach a vast pool of diverse knowledge. Unfortunately, it seems \nat times like a chaotic swirling sludge of trivial ephemera. Metadata and the \nassociated standards are essential to sharing knowledge, but do not in themselves \nprovide the framework for organized thought. We can understand words without \nrecognizing a coherent story. To bring order to this chaos we need a framework that \nreflects the structures of our conceptual models. \n \nProjects generally aim to gather new information or develop new ideas. Again, a clear \nstructure might make the process more efficient. In reporting the results, there should \nbe no need to repeat large amounts of what has already been recorded. Instead, \nlinkages should as far as possible give an indication of the dependency on earlier \nwork and earlier ideas. This can be done by the author in the course of preparing the \nnew document. Given a well-structured context, it should be possible to indicate \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nprecisely what has been assumed and where the ideas depart from those generally \naccepted. This would help to assess knock-on effects when ideas or definitions \nchange. It could also indicate to the reader, in a detailed and objective way, the level \nof knowledge needed to assimilate the new ideas contained in the document, and offer \nprecise guidance on where additional background can be found. It should not be \nnecessary to complete a project before making results available to others, as \nfragments can be linked in to the existing context, and new versions replace old ones \nas the work proceeds. Nevertheless, to some extent projects supersede previous \nstudies and therefore cannot be rigidly constrained within a pre-existing framework. \n \nThree parallel approaches to a more coherent framework come to mind.  \n1. One is cataloging.  For example, bibliographic information for project \ndocuments could be held in a library catalog; or new hydrocarbons data could \nbe recorded, placed in a repository and cataloged following POSC standards. \nThe catalog provides structure and a means of access. The reputation of the \ndata supplier or archive manager gives some assurance of quality.  \n2. A second approach, well suited to exploratory projects, is extension of the \ncurrent scientific literature (I 6), to embrace new mechanisms of delivery \nwhile retaining the structure and evaluation imposed by the editorial board, as \ndescribed in L 3. This implies that each document is largely self-contained and \nself-explanatory. As previously mentioned, archiving problems may arise with \nmultimedia documents (L 6.3).  \n3. A third approach is for an information community to define a general model \n(M 2.3) for structuring relevant knowledge within the scope of their activities, \ntreating individual investigations as subprojects within a unified framework \nthat evolves as ideas develop.  \n \nThe three approaches, considered in M 2.1 and 2.2, are not mutually exclusive. The \nsame object could be relevant in more than one framework, and can readily be shared \nby hypertext reference. For example, the description of a fossil might be archived \nonly once, but referenced from a geological survey model, an oil exploration \nrepository and a paleontological journal. In this fast evolving field, it is likely that \nthese and many other frameworks for shared knowledge will be explored. As \nmembers of the geoscience community, it is our task to drive this evolution - to \nunderstand and appraise, encourage or condemn. \n \n2.1 Realigning responsibilities \n \nArchiving has in the past been the responsibility of libraries. The copyright in the \ndocuments, however, is generally retained by their publishers, who could create an \nelectronic archive of them as a source of significant future income. In due course, \nsuch archives would almost certainly improve the service and reduce the cost. Much \nof that saving would come from the reduced archiving role of the libraries. Libraries, \nhowever, are at present the main channel of government funds in purchasing \nconventional publications. The publishers may be reluctant, for the time being, to \nupset their main customers. In a travesty of the market place, publishers may even \noffer electronic copies of science journals at a higher price than the paper version on \nthe grounds that even if they cost less to produce, they offer more to the purchaser. \n \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nIf some of the functions of libraries are at risk from electronic archives, the same \ncould be said for publishers (see Butler 1999). Authors may be tempted to publish \ntheir own papers. In the past, this would have condemned the paper to obscurity. In \nthe future, cataloging information is likely to be part of the document or digital object, \nand thus the responsibility of the object\u2019s owner. It is retrievable by search engines, \nsome of which, for efficiency, would copy the cataloging information into an index \nand possibly extend it. Readers could thus find and retrieve the paper independently. \nBut there are problems. The quality of an unrefereed document has not been assessed, \nand there is no indication, other than the author\u2019s reputation and affiliation, of its \nscientific standing. There is therefore little kudos for the author, and no guidance for \nthe reader about whether its findings are valid or significant. Furthermore, without \nsome assurance that the paper will be widely available within a long-term archive, it \ncannot be seen as part of the permanent scientific record.  \n \nSolutions to these problems are in the hands of editors rather than publishers. Editors \nand referees are more likely to be concerned, as at present, with whether contributions \ndeal with an appropriate topic at a suitable level, meet the house style and agreed \nstandards, evaluating their relevance and quality, and ensuring that they are original, \ninoffensive, and give credit where it is due. Readers then have the task of assessing \nthe \u2018brand names\u2019 of the editorial boards, just as they would expect today to have a \nview on the quality of a particular journal.  \n \nThe role of the publisher, on the other hand, may be subsumed into repository or \narchive management, concerned principally with organizing and maintaining an \ninformation system and making its contents available. Some scientific societies have \ntaken on the role of publisher, for example, the Institute of Physics (1999). In some \nfields, large commercial publishers may dominate, because of their financial \nresources, global reach, wide coverage of many disciplines, marketing skills, and \nabove all their copyright of existing content (ScienceDirect, 1999). In the long run, \ncosts must be recovered for access to an electronic repository, and the profit potential, \nparticularly if charges are visible to the reader, may prove controversial. \n \nFeatures which users might look for in such an information system (K 3) include: \n\u2022 stability - there should be a clear and credible commitment to long-term \npreservation, access and maintenance of all information \n\u2022 usability - provenance, ownership of intellectual property rights, and terms and \nconditions of use should be clear \n\u2022 fairness - charges and conditions of use should be seen as fair, reasonable, \ncompetitive and consistent  \n\u2022 reliability -  the user should be able to assess the accuracy and quality of all \ninformation \n\u2022 comprehensiveness - within the demarcated scope of the service, the user \nshould be confident that all likely sources are included or referenced, \nincluding the most recent work \n\u2022 convenience - the system should be easy to use through a consistent, familiar \ninterface, and provide a rapid and efficient response \n\u2022 clear structure - available and relevant material should be easy to find and \nhave pointers to related information \n \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nThe Digital Object Identifier (L 3) is a basis for such a system, building on the \nexisting scientific literature. The digital object is the scientific paper, supported by \nentries in indexes and catalogs. A consortium of publishers has taken an intitiative \n(ScienceDirect, 1999) to supplement, and potentially replace, paper copies with items \narchived electronically, for example in SGML. Versions for browsing and printing, \nfor example in HTML, XML and PDF, are generated from the archive and accessible \nthrough the publisher's gateway, which controls access and imposes charges if \nrequired. A wide range of refereed literature, with indexes, abstracts and catalogs, can \nthus be made available from the desktop. The flexibility and ease of use of the Web \nbrowser complement the authority, structure and permanence of the scientific \nliterature. The digital objects can of course be hyperlinked, and references reached by \na click. As they share the same desktop interface, the formal literature can link to \nephemera, detail, and work in progress recorded on the World Wide Web. Equally the \nliterature can have links to and from the spatial models described in the next section. \n \nThe scientific paper of around 5000 words is a convenient length for downloading to \nthe desktop, and appropriate for marshaling and presenting a coherent view of a \nspecific argument. More extended accounts, such as topic reviews and books, are \nnormally arranged in chapters dealing with separate aspects of the subject. The \nchapter, rather than the book, might be seen as suitable for cataloging as a retrievable \nunit, analogous to the scientific paper. Electronic archives should focus on the content \nnot the container. Older distinctions based on the format of presentation, such as \nbook, serial or reprint, are likely to blur. The general scientific literature, however, is \nlikely to be archived as sets of discrete objects or documents, and this may be \ninappropriate for some of the tightly structured work of information communities. \n \n2.2 The information communities \n \nThe OGIS Guide (L 4) points out that each scientist has a unique view of the world, \nand that this makes communication more difficult (Buehler and McKee, 1998). They \nidentify information communities \u2013 collections of people who, at least part of the \ntime, share a common world view, language, definitions and representations \u2013 and \nexplore possible means of communicating between such groups. An example might \nbe NOAA, the Department of Mines and the USGS, each with their own objectives, \nmethods, terminology and standards. Understanding the concepts of an information \ncommunity can be helped by a strong framework of data models with clearly defined \nterms and relationships. \n \nValid interpretation across community boundaries is likely to depend in large part on \nthe background knowledge of the human interpreter. This is not available, nor likely \nto become available, to the computer. As Kent (1978) pointed out, language is a \npowerful tool to reconcile different viewpoints, and a basis for communicating \nbackground knowledge both of large concepts and of the details of a single object. \nWritten explanations are therefore needed in  close association with spatial and data \nobjects at every level of detail.  \n \nWe can already see in the World Wide Web the emergence of a global knowledge \nnetwork, using hypermedia to express and relate ideas. There is a clear distinction \nbetween cross-references among objects, which call attention to some relationship or \nanalogy, and the tightly linked conclusions that emerge from a project based on a \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nsingle coherent set of background assumptions, objectives and working methods. \nWithin the loose global linkages of the hypermedia knowledge repository there are \nmore tightly organized structures of geoscience information managed by defined \ninformation communities. \n \nLarge information communities, such as geological surveys, already publish many of \ntheir own findings, and should find this easier in an IT environment. Their internal \nrefereeing and quality assessment procedures, their copyright ownership, their brand \nname and reputation among their customers are already established. They should \ntherefore be able to meet most of the users' criteria in 2.1. \n \nAs well as their own findings, a survey may hold data originally collected by external \norganizations for various purposes, such as site investigation or mineral assessment. \nThe accuracy of the data is variable and cannot appropriately be judged by the survey. \nProvided this is made clear, however, and the source and ownership of data sets are \nclearly identified in the metadata, the user can evaluate them against the quality-\nassessed survey view of the same area, and vice versa. The survey is adding value by \nmaking the information available in context. There are benefits to the contributor in \nplacing records within the structure of a repository where the costs of initial design, \ninstallation, marketing and maintenance are spread across many users. There are \nbenefits to the repository in achieving more comprehensive coverage by accepting \nexternal contributions. \n \nThe requirement for up-to-date information seems to conflict with the need for a \npermanent record of earlier views. This can be overcome by archiving date-stamped \nprevious versions, or by retaining the ability to reconstruct them from journalized \nchanges, as generally only a small part of a document or data set is superseded. The \ntask of maintaining versions should not be underestimated, for while it can be readily \nhandled in a prototype, it could be the dominant issue in a production system (Newell \net al, 1992). \n \nIn fast developing technology, the lead organization tends to keep moving ever further \nahead of the pack, because users prefer a single mainstream solution. The leader can \nset standards while others inevitably fall behind. A winner-take-all situation \ndevelops, to be broken only by user dissatisfaction, by competitors using technology \nmore effectively or catching a new wave of technological advance, by financial \nmuscle, by political interference or a combination of these. Even within a small niche, \nsuch as a country's geology, users may prefer a single source of survey information. \nAll users can then work on the same basis, and different areas can readily be \ncompared. \n \nOn those grounds, a survey or similar organization (indeed any group dominating its \nniche and working to shared, comprehensive standards) can be well placed to \nmaintain its market position. It just needs to stay in the forefront of technology, keep \nin line with changing standards, and satisfy customers and politicians. Because \ninformation technology bridges national and disciplinary boundaries, standards must \nbe international and standards within geoscience must be consistent with those in \nrelated fields. Close collaboration with a range of other organizations is therefore \nessential. Some organizations can share information system resources through \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \n\u201cextranet crossware\u201d (Netscape, 1999). Both sides gain from the links (win-win), as \nwell as customers benefiting from good service at reasonable cost. \n \nAn information community exists because its members share objectives and are \norganized to find an integrated solution. A geological survey (I 8.1) is an example of \nan information community, one of its roles being to assemble basic geological \ninformation about an area in a form which can be used in many other applications \n(rather than being collected separately for each project). The conventional means of \nachieving a coherent overview is to publish standard series of maps with \naccompanying memoirs and explanatory reports, all to consistent standards. As this is \nfirmly embedded in old technology, surveys have had to review their work from first \nprinciples. The British Geological Survey, an example of a medium-sized survey, \nconsidered the issue of their basic geoscientific model (Ovadia and Loudon, 1993) as \ndescribed in the next section. \n \n2.3 A basic regional geoscience framework \n \nThe earlier description of the geoscience information system (I 2.3) gave some \nimpression of its scope and form, but said little about its scientific content. The \ntriangular image of increasing abstraction in L, Fig. 3 hints that there is some shared, \ngeneral model \u2013 the paradigm that geoscientists have at the back of their minds. If so, \nthere should be a route from a single set of observations at the bottom of the triangle, \nsuch as a soil profile, linking upwards at higher levels of generality through the entire \nbody of existing knowledge. Indeed, the claim to be a science suggests that the body \nof knowledge should be coherent and internally consistent. A greatly simplified \noverview is required to provide an overall structure into which observations and ideas \ncan be fitted, and from which relevant information can be retrieved. \n \nThe framework of a general geoscience model can help to bring order to a multitude \nof investigations whose varied business aims lead to a diversity of approaches. A \nsingle, coherent, general model can specifically address the area of overlap and thus \nhelp to avoid unnecessary duplication. The task of developing that model and sharing \nthe results can appropriately be assigned to an identified information community, such \nas a geological survey. The need for cooperation with related information \ncommunities is illustrated by, for example, the links between topographic and \ngeological mapping. \n \nGeological, topographic and related surveys worldwide have developed such models \nof national aspects of geoscience. Examples can be found in Australia (Australian \nGeodynamics Cooperative Research Centre, 2000), France (BRGM, 2000), Canada \n(Lithoprobe, 2000) and the United Kingdom (Adlam et al, 1988). Their concern is to \nconvey knowledge of the consequence of geological and related processes, states and \nevents in geological time and space. Their findings, which have a strong spatial \nelement, have generally been expressed as maps and reports on specific areas. \nGeological maps may list the various rock units present in the area (classification and \nnomenclature), and by relating their location to a topographic base map, show their \nspatial distribution (disposition) at or near the earth's surface. Drift and soil maps \nmay show the disposition of sequences of units. Orientation measurements, \nintersections with the topography, and cross-sections give an impression of the three-\ndimensional form, sequence, shape and structure (configuration) of the units. \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nGeneralized sections and text comments give an indication of the lithological and \npetrographical composition of the material. Specialist maps might give information \nabout the geochemical composition of the material, the geophysical properties of the \nrock mass or the geotechnical properties of individual units. Paleogeographical maps \nand palinspastic reconstructions can be used to express a view on their formation and \nhistorical development. Symbols on the map may show wells, traverses, \nmeasurement stations, outcrops, and collection localities as points where evidence \nwas gathered to support the conclusions.   \n \nMany aspects, such as detailed descriptions and accounts of processes, can be \naddressed more satisfactorily in text than on a map. The paleontologist studying a \nsingle fossil, or the seismologist studying an earthquake, may indeed consider a \ngeneral geoscience model to be irrelevant. But their findings are ultimately related to \nsome framework of space and time, viewing the fossil as a component of the material \nof a rock unit, throwing light on its history; and the earthquake as an event resulting \nfrom the reaction of the material to its properties and stress history. \n \nReports and maps are often closely associated, but perhaps maps give clearer pointers \nto a general model, because their graphical symbolism, uniformity, and the need for \nworldwide coverage require a formalized and consistent approach. However, the \nconventional map is a product of a particular technology. We are looking for an \nunderlying model which refers to the scientific concepts, not the technical solutions, \nfor our interest is in how technology can evolve to fit scientific needs (see Laxton and \nBecken, 1995). The concepts must be as free as possible from their form of \npresentation. \n \nIn a general geoscience spatial model, the objects of interest are the earth and parts \nof the earth, such as rock units or their bounding surfaces. The aspects of interest just \nmentioned are their disposition, configuration, composition, properties, history and \nevidence.   \n \nThe underlying concepts are familiar. They address issues analogous to those that \nmight worry a three-year-old child on looking into a dark room.   \n \n\u2022 What is in there and what is it called? (Object classification and nomenclature)  \n\u2022 Where is it?  (Disposition)  \n\u2022 What does it look like?  (Configuration)  \n\u2022 What is it made of?  (Composition)  \n\u2022 What does it do?  (Properties)   \n\u2022 How did it get there?  (History and geological processes)  \n\u2022 How do I know? (Evidence and business aspects) \n \nWe try to develop and convey the knowledge (held in our brains) of states, processes \nand events, sequenced in time and patterned in space, which we believe may account \nfor our observations within our accepted world view. The types of model with which \ngeoscientists are concerned largely determine the unique characteristics of their \ninformation system. In particular, the spatial model (G 2) is the key, not only to the \ndisposition and configuration of objects, but also to understanding many of the \nrelationships of their composition, properties and processes. IT may offer radical \nimprovements in implementing the framework. \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \n \nWhere a strong framework and good retrieval techniques are in place, the survey \nmodel can tie into contributions from external projects, like a commentator adding \nfootnotes to an existing story. Ideally, it should support interwoven stories dealing \nwith any relevant topic, tied to geological space and time and the object-class \nhierarchies defined in the metadata. Data models define the scope and relationships of \nthe topics considered, and provide a structure for storage and retrieval of information. \nThe content may be complete for all the subject areas and topics, although level of \ndetail and date of last revision will inevitably vary. Here is a context where \ncontributions can be evaluated, stored and found when required, and a means of \nreconciling information obtained for differing business purposes. Conflicting and \nchanging views can be held side by side, for evaluation by users. \n \nModels such as this can provide firmly structured areas embedded in the more flexible \nhypermedia knowledge repository. Some information communities, such as oil \ncompanies, have more clearly defined business requirements, and precise ideas about \nthe geoscience information required to support them. Academic studies, in contrast, \nmay have fewer preconditions, and a need to follow ideas wherever they may lead. \nThey must choose different points on a trade-off. On the one hand, well-defined \nstructures and consistent standards bring reduced redundancy, increased relevance and \nefficient access. On the other hand, the scientific literature offers greater flexibility \nand ability to cope with change. The cost is greater repetition and greater effort to \ncomprehend the diversity of ideas and modes of expression. The scientific literature is \nalready evolving to offer hypermedia documents within distinct topic areas overseen \nby editorial boards.  \n \nWe thus see the development of a flexible hypermedia knowledge repository. Within \nit, structured areas are provided by information communities of all sizes and forms, \nfrom individual businesses to consortiums of business partners, geological surveys, \neditorial boards for geoscience literature, and the organizations that help to establish, \nformalize and encourage the use of standards. \n \n3. Business aspects \n \nAny geoscience project is embedded in some kind of business - mineral development, \ncivil engineering, survey, education, research, or whatever - which sets its objectives, \nresources and time scale. All the information systems that deliver information for the \nbusiness, including the geoscience information system, are changing because of IT. \nMost businesses follow a yearly cycle of reviewing progress, deciding priorities, \nallocating funds and so on, according to a business plan. Feeding information into \nthis, and therefore synchronized with it, there may be an information system \nstrategy which supports the business objectives (CCTA, 1989). It sets out a plan (for \nthe various parts of the business) for development of the information systems, \npolicies, programs of work and IT infrastructure. While the strategy may be the \nresponsibility of an IT department, geoscience needs must be taken into account and \nfed through to the business plan at the appropriate time. The geoscience manager who \nwishes to take full advantage of IT must therefore keep the business aspects in mind.  \n \nThe unpredictable course of technology will itself respond to business needs. Views \non mainstream developments in IT can be culled from the Web pages of the major \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nsoftware suppliers, such as Microsoft, Oracle and Sun (their Web addresses can be \nfound by inserting their names between www. and .com). Those with a more \nacademic approach may be more interested in open source software, such as Linux or \nGNU (place between www. and .org for their Web addresses). Such code can be \namended for specific applications and much of the software is free. Today\u2019s standard \nprocedures may be by-passed by tomorrow\u2019s technology, and planning should \ntherefore be flexible and kept under continual review. \n \n3.1 Organizational consequences \n \nIn areas such as word processing, computer-aided design and Web searching, \ncomputers can assist users to carry out tasks which otherwise would require, say, a \ntyping pool, publisher, drawing office, and library. Some changes to roles in the \norganization were considered in M 1. In general, intermediaries between the \noriginator and the user of information can either be eliminated (disintermediation), \nor given a changed role, for example in providing advice on design and layout or \ndevelopment of standards, or in providing information systems maintenance and \ntraining. \n \nComputer support can assist project planning and monitoring. Because computer-\nmediated information can be made available rapidly and widely within an \norganization, employees can respond to plans and requirements within a less complex \nmanagement hierarchy (delayering) and with greater independence of individuals and \ngroups.  \n \nRather than regarding collection and management of information as closely linked \nactivities, with data collectors responsible for looking after their own results, \nstandards provide flexibility to combine or separate the responsibilities as \nappropriate. Information can be maintained by the originator during the course of a \nproject and still be available to others over network links. Without necessarily altering \nthe standard format of the information, it can in due course be passed to the control of \na repository for long-term security.  \n \nLarge amounts of data can be analyzed by computer provided they meet uniform \nstandards. Where detailed standards are in place, many groups from many \norganizations can contribute shareable information. Data can be stored and managed \nin a shared repository. For example, POSC (L 5) has assembled standards that enable \ndata from many sources to be shared through local and international repositories, \nwhere the task of data management is handed over (outsourced) to specialists. The \nresult is huge savings to individual companies, and generally more reliable access to \ninformation.  \n \n3.2 Cost recovery \n \nWith most scholarly publication and government-funded survey, the main costs are \nincurred in prepublication research. Even the costs of publication relate mostly to \npreparatory work before the first copy is printed (B 1). The effect of electronic \ndelivery is to reduce the initial publication cost and almost eliminate the costs of \nsupplying subsequent copies, as printing costs fall on the user. The costs that might \neventually be recovered include digitizing and storing the information, a contribution \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nto the cost of its acquisition, and the overhead cost of maintaining the system \nstandards and metadata. As mentioned earlier (M 2.2), success is helped by \ndominating the chosen market. It is therefore important for charges to be kept as low \nas practicable with the aim of attracting the largest possible number of customers. \nCustomers require comprehensive information, and a viable system will need rapid \ngrowth both in terms of number of customers and amount of information. A \nprolonged period of free access while the service is being established, followed by \ngradual introduction of charges, is the pattern followed, for example, by most \nelectronic journals and newspapers. Their large capital investment has no short-term \nreturn. \n \nRegistration of users can enable a repository to identify customers, find out which \nareas are of most interest and keep customers informed of relevant developments. It \nalso ensures that the user is aware of the terms and conditions of supplying the \ninformation. The casual or one-off user can be allowed to bypass much of the \nregistration procedure. For organizations that are heavy users of the information, a \nmonthly or annual invoice could be convenient, covering all staff from that \norganization. This could either be a flat rate at levels related to usage, or based on the \ntotal of list prices for all objects accessed. For the large user, fixed amounts are \nsimpler, but the occasional user may prefer to pay per object, and ways of transferring \nsmall amounts of cash for such transactions are being developed. For sums of more \nthan a few dollars, charge cards are a possible alternative. The latest news of \ncharging procedures can be found on the Web (see, for example, Schutzer, 1996; \nHerzberg, 1998).  \n \nIncentives are the driving force of an information system. An obvious incentive is \nmoney - the metric of utility space. As a creature of market forces, money can help to \nbalance supply and demand. As an appendage to tradable objects, it can encourage \nsharing, not hoarding, of information. For example, a repository might charge a fee to \ndepositors of information in order to recover the cost of managing and storing the \ninformation. The user of the information might also have to pay, to recover costs of \ndissemination and to pass on a royalty to the depositor. Academic susceptibilities \nmight prefer a subsidized repository with payment in kudos not cash. Either way, \nthere are incentives for all concerned to behave in a socially desirable manner.  \n \nTo ensure that authors can benefit from their creativity, the law recognizes \nintellectual property rights (IPR), such as copyright. This covers the author\u2019s rights \nto acknowledgment (paternity), to avoid alteration by others (integrity) and to \nroyalties from sale of the work. The ease of copying electronic documents puts IPR at \nrisk, see Lejeune (1999) or section 5.1: legal issues in Bailey (1996). This is one \nimpediment to electronic communication. So-called trusted systems have been \ndeveloped, but not yet widely adopted, which enable the information supplier to \ncontrol information distribution as never before (The Economist, 1999). Another \nproblem is the difficulty of calculating value. Devising a simple but effective pricing \nmechanism involves compromise. For example, consider what some economists call \nnetwork externalities, that is, activities that support, benefit and extend the system as \na whole, rather than individual users.  \n \nYou may recall Mr Bell\u2019s problem. He invented and built a telephone, but had no-one \nto call. There is a snowball effect. The more people own phones, the more useful each \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \none is, provided of course that they all follow suitable standards to make \ncommunication possible, and their phone numbers are widely known. There might be \nprofit for Mr Bell in setting up a telephone company and selling services; but it is then \nto his advantage to encourage and subsidize the network of lines and exchanges, the \navailability of directories, and to reward the initial subscribers until the snowball \neffect takes over. These network externalities are a necessary development cost to \nhim, not a profit. Above all, he must remain locked into the dominant standards. \nSomeday his telephone might be linked to others throughout the world. I suppose he \ncould have made an alternative decision to give away telephones and profit from the \nsale of directories, but the customer\u2019s perception of value and the difficulties of \nprotecting market share must be taken into account. \n \nStandards and metainformation, which describe what information is available, what it \nis useful for, how to get it and what it means, can be regarded as network externalities \nin the information system. They enhance the value of the main body of information. \nThe more widely known and accepted they are, the more the overall value is \nenhanced. There is therefore a case for making metainformation readily and freely \navailable to all, or even paying for its dissemination (advertising). It follows that \nstandard setting bodies need external funding from members or governments. \n \nAnother quirk of the system reflects the difficulty of the first purchaser of a telephone. \nThe high cost and unreliability of the untried device are matched by the tedium of \nbeing able to chat only to Mr Bell. Initial involvement with a radically new \ninformation system, as contributor or user, has similar drawbacks. Being a pioneer is a \nmug\u2019s game - much better to wait until the systems are grooved in and most \ninformation transformed. For the rational individual, the clever strategy appears to be \nto wait until the last minute before leaping onto a new development curve. And so, for \na while, governments, not wishing to be bypassed by history, offer subsidies for new \ndevelopments. Rational organizations grab them, for an organization changes more \nslowly than an individual, with more to gain by being ahead of the field. They invent \nways to motivate staff and customers \u2013 and the attractions of the rational employee \nfade in comparison with the one with knowledge of IT. \n \n5. References \n \nAdlam, K.A.McL., Clayton, A.R., Kelk, B., 1988. A \u2018demonstrator\u2019 for the National \nGeosciences Data Index. International Journal of Geographical Information Systems, \n2(2), 161-170. \n \nButler, D., 1999. The writing is on the web for science journals in print. Nature, 397 \n(6716), 195-200. \n \nCCTA, 1989. The Information Systems Guides. John Wiley & Sons, Chichester. \n \nHerzberg, F., Mausner, B., Snyderman, B.B., 1993. The Motivation to Work. Wiley, \nNew York, 157pp. \n \nKent, W., 1978.  Data and Reality. North-Holland Publishing Company, Amsterdam, \n211pp. \n \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nLaxton, J.L., Becken, K., 1995. The design and implementation of a spatial database \nfor the production of geological maps. Computers & Geosciences, 22(7),  723-733. \n \nNewell, R.G., Theriault, D., Easterfield, M., 1992. Temporal GIS - modeling the \nevolution of spatial data in time. Computers & Geosciences, 18(4), 427-434. \n \nOvadia, D.C., Loudon, T.V., 1993. GIS in a geological survey\u2019s migration strategy. \nProceedings of the 5th National AGI Conference, Birmingham, UK. pp. 3.12.1-\n3.12.4. \n \nPeuquet, D.J., Bacastow, T., 1991. Organizational issues in the development of \nGeographical Information Systems: a case study of U.S. Army topographic \ninformation automation. International Journal of Geographical Information Systems, \n5(3), 303-319. \n \nThe Economist, 1999. Digital rights and wrongs. The Economist, 353(8128) (July 17 \n1999), 99-100. \n \n5.1 Internet references \n \nAustralian Geodynamics Cooperative Research Centre. 4D geodynamic model of \nAustralia. http:\/\/www.agcrc.csiro.au\/4dgm\/ \n \nBailey, C.W., Jr., 1996- . Scholarly electronic publishing bibliography. Houston: \nUniversity of Houston Libraries, 1996-99. http:\/\/info.lib.uh.edu\/sepb\/sepb.html \n \nBRGM. Le programme national de recherche scientifique pour l\u2019imagerie g\u00e9ologique \net g\u00e9ophysique de la France en 3D. \nhttp:\/\/www.brgm.fr\/geofrance3d\/geofrance3d.html \n \nBuehler, K., McKee, L. (editors), 1998. The OpenGIS guide: Introduction to \nInteroperable Geoprocessing. http:\/\/www.opengis.org\/techno\/guide.htm \n \nHerzberg, A., 1998. Safeguarding digital library contents: charging for online content. \nD-Lib Magazine, January 1998. \nhttp:\/\/www.dlib.org\/dlib\/january98\/ibm\/01herzberg.html \n \nInstitute of Physics, 1999. Sources, Journals. http:\/\/www.iop.org\/jo.html \n \nLejeune, L., 1999. Who owns what? The Journal of Electronic Processing, March \n1999, vol 4 (3). http:\/\/www.press.umich.edu\/jep\/04-03\/glos0403.html \n \nLithoprobe: Canada\u2019s National Geoscience Project \nhttp:\/\/www.geop.ubc.ca\/Lithoprobe\/public\/aboutlp.html \n \nNetscape, 1999. Building applications in the Net economy. \nhttp:\/\/developer.netscape.com\/docs\/wpapers\/index.html \n \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nLoudon, T.V., 2000. Geoscience after IT: Part M  (postprint, Computers & Geosciences, 26(3A)) \n \nSchutzer, D., 1996. A need for a common infrastructure: digital libraries and \nelectronic commerce. D-Lib Magazine, April 1996. \nhttp:\/\/www.dlib.org\/dlib\/april96\/04schutzer.html \n \nScienceDirect, 1999- . ScienceDirect: providing desktop access to the full text of \nmore than 1000 scientific, medical and technical journals published by the world\u2019s \nleading scientific publishers. http:\/\/www.sciencedirect.com\/ \n \n \n \n \n \nDisclaimer: The views expressed by the author are not necessarily those of the British \nGeological Survey or any other organization. I thank those providing examples, but should \npoint out that the mention of proprietary products does not imply a recommendation or \nendorsement of the product. \n \n<<<Back to Table of Contents       \nOn to Part M(4): Epilog (or Prolog)>>> \n \n \n \n"}
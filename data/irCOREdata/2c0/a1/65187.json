{"doi":"10.1016\/j.jcss.2007.02.001","coreId":"65187","oai":"oai:dro.dur.ac.uk.OAI2:6668","identifiers":["oai:dro.dur.ac.uk.OAI2:6668","10.1016\/j.jcss.2007.02.001"],"title":"Maximum H-colourable subdigraphs and constraint optimization with arbitrary weights.","authors":["Jonsson,  P.","Krokhin,  A."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-08-01","abstract":"In the maximum constraint satisfaction problem (Max CSP), one is given a finite collection of positive-weight constraints on overlapping sets of variables, and the goal is to assign values from a given domain to the variables so that the total weight of satisfied constraints is maximized. We consider this problem and its variant Max AW CSP where the weights are allowed to be both positive and negative, and study how the complexity of the problems depends on the allowed constraint types. We prove that Max AW CSP over an arbitrary finite domain exhibits a dichotomy: it is either polynomial-time solvable or NP-hard. Our proof builds on two results that may be of independent interest: one is that the problem of finding a maximum H-colourable subdigraph in a given digraph is either NP-hard or trivial depending on H, and the other a dichotomy result for Max CSP with a single allowed constraint type.\\ud\n\\u","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65187.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/6668\/1\/6668.pdf","pdfHashValue":"378f804a12d7f233548a58cf6003c8f214e61676","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:6668<\/identifier><datestamp>\n      2011-12-14T09:48:38Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Maximum H-colourable subdigraphs and constraint optimization with arbitrary weights.<\/dc:title><dc:creator>\n        Jonsson,  P.<\/dc:creator><dc:creator>\n        Krokhin,  A.<\/dc:creator><dc:description>\n        In the maximum constraint satisfaction problem (Max CSP), one is given a finite collection of positive-weight constraints on overlapping sets of variables, and the goal is to assign values from a given domain to the variables so that the total weight of satisfied constraints is maximized. We consider this problem and its variant Max AW CSP where the weights are allowed to be both positive and negative, and study how the complexity of the problems depends on the allowed constraint types. We prove that Max AW CSP over an arbitrary finite domain exhibits a dichotomy: it is either polynomial-time solvable or NP-hard. Our proof builds on two results that may be of independent interest: one is that the problem of finding a maximum H-colourable subdigraph in a given digraph is either NP-hard or trivial depending on H, and the other a dichotomy result for Max CSP with a single allowed constraint type.\\ud\n\\ud\n<\/dc:description><dc:subject>\n        Maximum constraint satisfaction problem<\/dc:subject><dc:subject>\n         Digraph H-colouring<\/dc:subject><dc:subject>\n         Complexity<\/dc:subject><dc:subject>\n         Dichotomy<\/dc:subject><dc:publisher>\n        Elsevier<\/dc:publisher><dc:source>\n        Journal of computer and system sciences, 2007, Vol.73(5), pp.691-702 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2007-08-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:6668<\/dc:identifier><dc:identifier>\n        issn:0022-0000<\/dc:identifier><dc:identifier>\n        doi:10.1016\/j.jcss.2007.02.001<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6668\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1016\/j.jcss.2007.02.001<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6668\/1\/6668.pdf<\/dc:identifier><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0022-0000","0022-0000"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2007,"topics":["Maximum constraint satisfaction problem","Digraph H-colouring","Complexity","Dichotomy"],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n06 April 2010\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nJonsson, P. and Krokhin, A. (2007) \u2019Maximum H-colourable subdigraphs and constraint optimization with\narbitrary weights.\u2019, Journal of computer and system sciences., 73 (5). pp. 691-702.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1016\/j.jcss.2007.02.001\nPublisher\u2019s copyright statement:\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n  \n \nDurham Research Online \n \nDeposited in DRO: \n06 April 2010 \n \nPeer-review status: \nPeer-reviewed \n \nPublication status: \nAccepted for publication version \n \nCitation for published item: \nJonsson, P. and Krokhin, A. (2007) 'Maximum H-colourable subdigraphs and constraint \noptimization with arbitrary weights.', Journal of computer and system sciences., 73 (5). pp. \n691-702. \n \nFurther information on publisher\u2019s website: \nhttp:\/\/dx.doi.org\/10.1016\/j.jcss.2007.02.001 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nUse policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior \npermission or charge, for personal research or study, educational, or not-for-profit purposes provided that : \n \n\uf0a7 a full bibliographic reference is made to the original source \n\uf0a7 a link is made to the metadata record in DRO \n\uf0a7 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders. \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nMaximum H-colourable subdigraphs and\nconstraint optimization with arbitrary weights\nPeter Jonsson a,\u2217,\naDepartment of Computer and Information Science, Linko\u00a8pings Universitet,\nSE-581 83 Linko\u00a8ping, Sweden, tel: +46 13 282415, fax: +46 13 282499\nAndrei Krokhin b\nbDepartment of Computer Science, University of Durham, Science Laboratories,\nSouth Road, Durham DH1 3LE, UK\n\u2217 Corresponding author.\nEmail addresses: Peter.Jonsson@ida.liu.se (Peter Jonsson),\nandrei.krokhin@durham.ac.uk (Andrei Krokhin).\nPreprint submitted to Elsevier Science 22 January 2007\nAbstract: In the maximum constraint satisfaction problem (Max CSP), one\nis given a finite collection of positive-weight constraints on overlapping sets of\nvariables, and the goal is to assign values from a given domain to the variables\nso that the total weight of satisfied constraints is maximized. We consider this\nproblem and its variant Max AW CSP where the weights are allowed to be\nboth positive and negative, and study how the complexity of the problems de-\npends on the allowed constraint types. We prove thatMax AW CSP over an\narbitrary finite domain exhibits a dichotomy: it is either polynomial-time solv-\nable or NP-hard. Our proof builds on two results that may be of independent\ninterest: one is that the problem of finding a maximum H-colourable subdi-\ngraph in a given digraph is either NP-hard or trivial depending on H, and\nthe other a dichotomy result for Max CSP with a single allowed constraint\ntype.\nKeywords: maximum constraint satisfaction problem, digraph H-colouring,\ncomplexity, dichotomy\n2\n1 Introduction and Related Work\nThe constraint satisfaction problem (CSP) is a powerful general framework in\nwhich a variety of combinatorial problems can be expressed [9]. The aim in a\nconstraint satisfaction problem is to find an assignment of values to the vari-\nables subject to specified constraints. This framework is used across a variety of\nresearch areas in artificial intelligence (see [14,31]), and in computer science,\nincluding algorithmic graph theory [22], combinatorial optimization [19,20],\ndatabase theory [17,26], learning theory [5,11] and complexity theory [9,10,15].\nAn instance of a constraint satisfaction problem is a set of constraints applied\nto certain specified subsets of variables, and the question is whether there is an\nassignment to the variables such that all constraint applications are satisfied.\nThe problem of determining how the complexity of CSP (or of one of its many\nvariants) depends on the set F of constraint types (i.e., predicates) allowed in\ninstances has been thoroughly studied in the last years. Such parameterized\nproblems are denoted CSP(F). The first result of this kind was obtained by\nSchaefer [29] 25 years ago, where he proved that, for all choices of F , CSP(F)\nis either in P or NP-complete. Furthermore, he gave six classes of Boolean\nconstraints (or rather Boolean relations, or predicates) such that the problem\nCSP(F) is in P if and only if all predicates in F fall entirely within any of\nthese classes. Similar complete classifications of the complexity of constraint\nproblems have been given by, for instance, Bulatov [4] (CSP(F) for domains\nof size 3), Hell and Nes\u02c7etr\u02c7il [21] (graph H-colouring) and Creignou et al. [9]\n(various versions of Boolean CSP).\nMany different optimization variants of the CSP problem have been suggested.\nArguably the most well-known of them is the Max CSP problem where each\nconstraint is assigned a weight and the objective is to find an assignment\nthat maximizes the total weight of the satisfied constraints. This problem is\nclearly NP-hard in general since the Max Cut problem can be viewed as a\nMax CSP problem (see Example 1). Previously presented complexity results\nfor optimization versions of constraint satisfaction problems, parameterized\nby the set of allowed constraint types, have mostly been proved under the\nassumption that only non-negative weights are allowed (cf. [6,7,9,24,27]). In\nthe sequel, we will study such problems as well as optimization problems where\nwe allow arbitrary weights. We begin by defining these problems.\nThroughout the article D will denote a finite set with |D| > 1. Let R(m)D denote\nthe set of all m-ary predicates over D, that is, functions from Dm to {0, 1},\nand let RD =\n\u22c3\u221e\nm=1R\n(m)\nD .\nDefinition 1.1 A constraint over a set of variables V = {x1, x2, . . . , xn} is\nan expression of the form f(x) where\n3\n\u2022 f \u2208 R(m)D is called the constraint function; and\n\u2022 x = (xi1 , . . . , xim) is called the constraint scope.\nThe constraint f is said to be satisfied on a tuple a = (ai1 , . . . , aim) \u2208 Dm if\nf(a) = 1.\nDefinition 1.2 Let F be a finite subset of RD. An instance of the problem\nCSP(F) is a pair (V,C) where\n\u2022 V = {x1, . . . , xn} is a set of variables taking their values from D;\n\u2022 C is a collection of constraints f1(x1), . . . , fq(xq) over V , where fi \u2208 F for\nall 1 \u2264 i \u2264 q.\nThe question is whether there is a function \u03d5 : V \u2192 D which satisfies all\nconstraints in C.\nDefinition 1.3 For a finite F \u2286 RD, an instance of weighted Max CSP(F)\nis a tuple (V,C, \u03c1) where V,C are the same as for CSP(F), and \u03c1 : C \u2192 Z+ is\na function that assigns a positive integral weight \u03c1i to each constraint fi(xi).\nThe goal is to maximize the total weight of satisfied constraints, that is, to\nmaximize the function f : Dn \u2192 Z+, defined by f(x1, . . . , xn) = \u2211qi=1 \u03c1i \u00b7fi(xi).\nThe optimal value of a solution to (V,C, \u03c1) is denoted by Opt(V,C, \u03c1).\nIn the Max AW CSP(F) problem, we allow the weights to be arbitrary (that\nis, not necessarily positive) integers.\nInformally speaking, each constraint specifies a property for the variables in\nits scope, and the weight of a constraint in an instance ofMax CSP expresses\nthe measure of desirability for this property to hold, and one needs to find a so-\nlution with maximum overall measure of desirability. The problem Max AW\nCSP can then be seen as follows: the positive weights express the measure\nof desirability for certain properties to hold for the scopes of the constraints,\nwhile the constraints with negative weights express how undesirable it is for\ncertain collections (scopes) of variables to have the properties described by\nthe corresponding constraints; the goal is, again, to maximize the overall de-\nsirability. This is useful in, for example, turning constrained optimization into\nunconstrained optimization which is a common task in mathematical program-\nming (cf. [28]). In brief, the constrained problem is modified so that solutions\noutside the feasible region are penalized by giving them large negative weights,\nand thereafter the modified problem is solved by using an algorithm for uncon-\nstrained optimization. Other ways of using constraints to express preferences,\nwith analysis of complexity, can be found in [3,6].\nWe will study the complexity of problems Max CSP(F) and Max AW\nCSP(F). Many problems that have received considerable attention in the\nliterature are subsumed by Max AW CSP(F), and prominent examples are\n4\nMax k-Cut, Max DiCut and Max k-Sat.\nExample 1 The Max k-Cut problem is the problem of partitioning the set\nof vertices of a given undirected graph with (positive-)weighted edges into k\nsubsets so as to maximize the total weight of edges with ends being in different\nsubsets. This problem is the same as Max CSP({neqk}), where neqk is the\nbinary disequality ( 6=) predicate on a k-element set, and it is known to be NP-\nhard (see Problem GT33 in [1]). To see the correspondence between the two\nproblems, view the vertices of the graph as variables and edges as constraint\nscopes. Max 2-Cut is known as simply Max Cut.\nLet fdicut be the binary predicate on {0, 1} with fdicut(x, y) = 1 \u21d4 x = 0, y =\n1. Then, Max CSP({fdicut}) is essentially the problem Max DiCut (see\nproblem ND16 in [1]), which is the problem of partitioning the vertices of a\ndigraph with weighted arcs into two subsets V0 and V1 so as to maximize the\ntotal weight of arcs going from V0 to V1. This problem is known to be NP-hard\nas well.\nIf we considerMax AW CSP({neq2}) andMax AW CSP({fdicut}) instead,\nwe see that they correspond to Max Cut and Max DiCut generalised to\narbitrary weights, and such problems have been considered by, for instance,\nBarahona et al. [2] (who point out several important applications) and Goe-\nmans & Williamson [16] (who devise an approximation algorithm).\nFor the Boolean domain, that is, for |D| = 2, the complexity of problems\nMax CSP(F) and Max AW CSP(F) has been completely classified by\nCreignou [8] and Jonsson [23], respectively. In both cases, the results ap-\npeared to be dichotomies in the sense every such problem is either NP-hard\nor polynomial-time solvable. In this article, we prove thatMax AW CSP(F)\nis either polynomial-time solvable or NP-hard for any finite domain D, and\nwe also obtain a similar result for Max CSP(F) when F contains a sin-\ngle predicate (the example above indicates that some of the most important\nMax CSP(F) problems are of this kind). The only two previously published\ncomplete classifications of complexity for versions of CSP are the results of\nDalmau and Jonsson [12] and Grohe [18] where the parameter is, informally,\nthe way in which variables constrain each other (that is, allowed combinations\nof constraint scopes) rather than the set of allowed constraint predicates.\nRecent research pointed out a strong connection between tractability in Max\nCSP and the algebraic combinatorial property of supermodularity with re-\nspect to a lattice ordering of the domain [7,24,27]. We show that our results\nhave the same dividing line: intractable problems identified in this paper do\nnot have this property, while the tractable cases (trivially) do.\nThe structure of the article is as follows: Section 2 describes our reduction\ntechniques. Section 3 contains the proof of the main result and it is divided\n5\ninto two parts. In the first part, we study the problem of finding maximum-\nsize H-colourable subdigraphs in digraphs (which is an interesting problem in\nitself) \u2013 we show that it is either NP-hard or trivial depending on H. We also\nshow thatMax CSP(F), where F consists of a single predicate, is eitherNP-\nhard or trivial. These results are used in the second part to give a complete\nclassification ofMax AW CSP. Section 4 exhibits some connections between\nthe results in Section 3 and (super)modularity.\n2 Reduction techniques\nWe present two reduction techniques in this section. From now on, given a\nsubset D\u2032 \u2282 D, we let uD\u2032 denote a unary predicate such that uD\u2032(d) = 1 if\nand only if d \u2208 D\u2032.\n2.1 Strict implementations\nThe first reduction technique in our NP-hardness proofs is based on strict\nimplementations, see [9,25] where this notion was defined and used only for\nthe Boolean case. We will give this definition in a different form from that\nof [9,25], but it can easily be checked to be equivalent to the original one (in\nthe case |D| = 2).\nDefinition 2.1 Let Y = {y1, . . . , ym} and Z = {z1, . . . , zn} be two disjoint\nsets of variables. The variables in Y are called primary and the variables in Z\nauxiliary. The set Z may be empty. Let g1(y1), . . . , gs(ys), s > 0, be constraints\nover Y \u222a Z. If g(y1, . . . , ym) is a predicate such that the equality\ng(y1, . . . , ym) = max\nZ\ns\u2211\ni=1\ngi(yi)\u2212 (\u03b1\u2212 1)\nis satisfied for all y1, . . . , ym, and some fixed \u03b1 \u2208 Z+, then this equality is said\nto be a strict \u03b1-implementation of g from g1, . . . , gs.\nWe use \u03b1 \u2212 1 rather than \u03b1 in the above equality to ensure that this notion\ncoincides with the original notion of a strict \u03b1-implementation for Boolean\nconstraints [9,25]. The idea behind strict implementations is that they allow\none to modify instances (by substituting predicates) while keeping control over\ncosts of solutions. For example, assume that we have a constraint g(u, v) in an\ninstance of Max CSP(F), and there is a strict 2-implementation g(y1, y2) +\n1 = maxz(g1(y1, z) + g2(z, y2)). Then the constraint g(u, v) can be replaced\nby two constraints g1(u, z), g2(z, v) (where z is a fresh variable), and we know\n6\nthat every solution of cost c to the old instance can be modified (by choosing\nan appropriate value for z) to a solution of cost c+ 1 to the new instance.\nWe say that a collection of predicates F strictly implements a predicate g if,\nfor some \u03b1 \u2208 Z+, there exists a strict \u03b1-implementation of g using predicates\nonly from F .\nLemma 2.2 If F strictly implements a predicate g, andMax CSP(F \u222a {g})\nis NP-hard, then Max CSP(F) is NP-hard as well.\nProof: We need to show that Max CSP(F \u222a {g}) is polynomial-time re-\nducible to Max CSP(F). Let\ng(y1, . . . , ym) = max\nZ\ns\u2211\ni=1\ngi(yi)\u2212 (\u03b1\u2212 1), (1)\nwhere gi \u2208 F for all i.\nLet I be an instance ofMax CSP(F \u222a {g}) corresponding to maximizing the\nfunction\nf(x1, . . . , xn) =\nq\u2211\ni=1\n\u03c1i \u00b7 fi(xi). (2)\nThe idea is to transform it to an instance I \u2032 of Max CSP(F) by replacing\nevery constraint in I whose constraint predicate is g by its strict implemen-\ntation, introducing new copies of variables from Z each time.\nAssume without loss of generality that f1 = . . . = fr = g and fi \u2208 F for\nr + 1 \u2264 i \u2264 q. The constraint g(x1) in (2) can be replaced by the right-hand\nside of equation (1), changing the variables accordingly. Say, if\ng(x1, x2, x3) = max\nz1,z2\n[g1(x1, z1, z2) + g2(x2, z2, x3)]\u2212 1\nand x1 = (x1, x2, x1), then g(x1) would be replaced by\nmax\nz11 ,z\n1\n2\n[g1(x1, z\n1\n1 , z\n1\n2) + g2(x2, z\n1\n2 , x1)]\u2212 1.\nIf we do the same with every constraint g(xi), 1 \u2264 i \u2264 r, replacing the\nprimary variables by the corresponding variables from xi and using a new set\nZi of auxiliary variables every time, then we obtain that the goal in I can be\nrestated as that of maximizing the function\nf(x1, . . . , xn) =\nr\u2211\ni=1\n\u03c1i \u00b7 (max\nZi\ns\u2211\nj=1\ngj(y\ni\nj)\u2212 (\u03b1\u2212 1)) +\nq\u2211\ni=r+1\n\u03c1i \u00b7 fi(xi) =\n= max\nZ1\u222a...\u222aZr\nr\u2211\ni=1\n\u03c1i \u00b7 (\ns\u2211\nj=1\ngj(y\ni\nj)) +\nq\u2211\ni=r+1\n\u03c1i \u00b7 fi(xi)\u2212 (\u03b1\u2212 1) \u00b7\nr\u2211\ni=1\n\u03c1i.\n7\nClearly, maximizing this function is the same as maximizing the function\nr\u2211\ni=1\ns\u2211\nj=1\n\u03c1i \u00b7 gj(yij) +\nq\u2211\ni=r+1\n\u03c1i \u00b7 fi(xi).\nNote that this function corresponds to an instance I \u2032 of Max CSP(F) over\nthe set of variables {x1, . . . , xn} \u222a \u22c3ri=1 Zi. Since this transformation can be\nperformed in polynomial time, the result follows. 2\nThe next lemma is a direct application of strict implementations.\nLemma 2.3 If F contains two unary predicates uS, uT such that S \u2229 T = \u2205,\nthen Max CSP(F) is polynomial-time equivalent to Max CSP(F \u222a{uS\u222aT}).\nProof: One direction is trivial. The other direction follows from Lemma 2.2,\nsince uS\u222aT (x) = uS(x) + uT (x) is a strict 1-implementation of uS\u222aT (x). 2\n2.2 Domain restriction\nFor a subset D\u2032 \u2286 D, we denote the restriction of a predicate f to D\u2032 by f |D\u2032 ,\nas usual. Let F|D\u2032 = {f |D\u2032 | f \u2208 F and f |D\u2032 is not identically 0}.\nLemma 2.4 Suppose that uD\u2032 \u2208 F for some D\u2032 \u2286 D. If Max CSP(F|D\u2032) is\nNP-hard, then so is Max CSP(F).\nProof: Let I = (V,C, \u03c1) be an instance of Max CSP(F|D\u2032) and let K =\n1 +\n\u2211\nc\u2208C \u03c1(c). We will transform I into an instance I \u2032 of Max CSP(F) in\npolynomial time, in the following way: the set V stays the same; change every\nconstraint fi|D\u2032(xi) in C to fi(xi), add the constraints ci = uD\u2032(xi), xi \u2208 V , to\nC, and extend \u03c1 so that \u03c1(ci) = K for all new constraints ci.\nClearly, in every optimal solution to I \u2032, all variables are assigned values from\nD\u2032. Hence, an optimal solution to I \u2032 has value Opt(I) +K \u00b7 |V | where Opt(I)\nis the value of an optimal solution to I. 2\n3 Main results\nThis section is divided into two subsections: in the first we classify the com-\nplexity of Max CSP({h}), and in the second one we deal with Max AW\n8\nCSP(F). We say that a predicate is trivial if it is identically 0.\n3.1 Complexity of Max CSP({h})\nLet F = {h}. Clearly,Max CSP({h}) can be solved in polynomial time if h is\nunary. Indeed, in any instance of the problem, there is no interaction between\ndifferent variables, and hence we only need to choose an optimal value for each\nindividual variable. Assume from now on that h is at least binary. We shall\nsay that h is irreflexive if h(d, . . . , d) = 0 for all d \u2208 D.\nIf h is binary, then it can be considered as a digraphH = (VH , AH) where VH =\nD and (a, b) \u2208 AH \u21d4 h(a, b) = 1. Recall that, given a digraph H = (VH , AH),\na digraph G = (VG, AG) is called H-colourable if there exist a homomorphism\nfrom G to H, that is, a mapping \u03d5 : VG \u2192 VH such that (\u03d5(x), \u03d5(y)) \u2208 AH\nwhenever (x, y) \u2208 AG. In this case, we write G \u2192 H. Note that when h is\nbinary then the problem Max CSP({h}) can be represented as follows:\nMax H-col\nInstance: Digraph G = (V,A) with weights wa \u2208 Z+, a \u2208 A.\nGoal: Find a maximum weightH-colourable subdigraph of G, that is, A\u2032 \u2286 A\nwith maximum total weight\n\u2211\na\u2208A\u2032 wa such that the digraph G\u2032 = (V,A\u2032) is\nH-colourable.\nIndeed, consider the vertices of G as variables, and introduce a constraint\nh(x, y), with weight wa, for every arc a = (x, y) \u2208 AG. This gives a precise\ncorrespondence between the two problems.\nRecall that a digraph H is called a core if every homomorphism from H\ninto itself is injective (that is, an automorphism). It is well known that every\ndigraphH has a unique (up to isomorphism) subdigraphH \u2032 such thatH \u2192 H \u2032\nand H \u2032 is a core. In this case, the problems Max H-col and Max H \u2032-col\nare equivalent, and hence we may without loss of generality assume that H is\na core.\nLet, for simplicity,D = {0, . . . , p\u22121} and let h be an arbitrary binary predicate\non D. If H is a digraph associated with h as described above then we say that\nh is a core if H is a core.\nFor any d \u2208 D, define subsets d+ and d\u2212 ofD by the rules a \u2208 d+ \u21d4 h(d, a) = 1\nand a \u2208 d\u2212 \u21d4 h(a, d) = 1. Let U = {ud+ , ud\u2212 | d \u2208 D}.\nLemma 3.1 Let h be a core. If Max CSP({h} \u222a U) is NP-hard, then so is\nMax CSP({h}).\n9\nProof: Consider the digraph H associated with h. Let I = (V,C, \u03c1) be an\ninstance of Max CSP({h} \u222a U) and let K = 1 +\u2211c\u2208C \u03c1(c). Modify I to get\nan instance I \u2032 of Max CSP({h}) as follows:\n(1) Introduce fresh variables x\u20320, . . . , x\n\u2032\np\u22121, construct the following set of con-\nstraints {h(x\u2032i, x\u2032j) | h(i, j) = 1}, and add these constraints to C with\nweight K each.\n(2) Replace each constraint of the form ud+(x) in I by the constraint h(x\u2032d, x)\nwithout changing the weights. Similarly, replace every constraint ud\u2212(x)\nby h(x, x\u2032d) without changing the weights.\nNote that the scopes of constraints introduced in step 1 form a digraph G\u2032\n(with VG\u2032 = {x\u20320, . . . , x\u2032p\u22121}) isomorphic to H. Take an optimal solution \u03d5 to\nI \u2032. All constraints introduced in step 1 must be satisfied by \u03d5. Hence, since\nH is a core, \u03d5|VG\u2032 is an isomorphism from G\u2032 onto H. Define pi : VH \u2192 VH as\nfollows: pi(i) = j whenever \u03d5(x\u2032j) = i. Clearly, pi is an automorphism (i.e., a\ninjective endomorphism) of H. Moreover, \u03d5\u2032 = pi\u03d5 is also an optimal solution\nto I \u2032 which, in addition, satisfies the condition \u03d5\u2032(x\u2032i) = i for all i \u2208 D.\nThe construction in step 2 ensures that every optimal solution \u03c8 (say, with\nvalue m) to I can be extended, by letting \u03c8(x\u2032i) = i for all i \u2208 D, to a\nsolution to I \u2032 with value m + K \u00b7 |AH |. Since \u03d5 is optimal for I \u2032, it fol-\nlows that the restriction of \u03d5\u2032 onto V is an optimal solution to I. Therefore,\nOpt(I \u2032) = Opt(I) +K \u00b7 |AH | where Opt(I) and Opt(I \u2032) are values of optimal\nsolutions to I and I \u2032, respectively. Thus, this is a polynomial-time reduction\nfrom Max CSP({h} \u222a U) to Max CSP({h}). 2\nWe will now prove the classification result for Max CSP({h}) where h is\nbinary; the basic idea is to use the predicate h to strictly implement certain\nunary predicates and then apply the previous lemma.\nLemma 3.2 Let h : D2 \u2192 {0, 1} be a non-trivial predicate. If h(d, d) = 1\nfor some d \u2208 D, then Max CSP({h}) is trivial. Otherwise (that is, if h is\nirreflexive), it is NP-hard.\nProof: If h(d, d) = 1 for some d \u2208 D, then the assignment mapping every\nvariable to d satisfies all constraints in any instance. Hence, Max CSP({h})\nis trivial. Assume now that h is irreflexive. As explained above in this subsec-\ntion, we may now assume that h is a core (obviously, the core of an irreflexive\ndigraph is also irreflexive). We will prove the result by induction on |D|. If\n|D| = 2, then h(x, y) is one of neq2(x, y), fdicut(x, y), fdicut(y, x) (see Exam-\nple 1), so we are done. Assume that |D| > 2 and, for all irreflexive non-trivial\npredicates on smaller domains, the result holds. We consider three cases:\n10\nCase 1: There exists a v \u2208 D such that |v+| > 1.\nIf h|v+ is nontrivial, then Max CSP({h|v+}) is NP-hard by the inductive\nassumption, so the problem Max CSP(h, v+) is NP-hard by Lemma 2.4, so\nMax CSP({h}) is NP-hard by Lemma 3.1. Hence, we assume that h|v+ is\ntrivial and note that D 6= v+ \u222a {v} since h is a core.\nArbitrarily choose a vertex w \u2208 v+ and note that v+ \u2229 w\u2212 = \u2205 since h|v+ is\ntrivial. If v+ \u222a w\u2212  D, then Max CSP({h}) is NP-hard by the inductive\nassumption (h|v+\u222aw\u2212(v, w) = 1) and Lemmas 3.1 and 2.4, arguing as above. If\nh|w\u2212 is nontrivial, then Max CSP({h}) is NP-hard by the same argument.\nOtherwise, h(x, y) = 1 only if x \u2208 w\u2212 and y \u2208 v+. Assume there exist w1 \u2208 w\u2212\nand v1 \u2208 v+ such that h(w1, v1) = 0. Then, |v\u22121 | < |w\u2212| and v+ \u222a v\u22121  D. We\nsee that h|v+\u222av\u22121 (v, v1) = 1 and v+ \u2229 v\n\u2212\n1 = \u2205. Then, Max CSP({h|v+\u222av\u22121 }) is\nNP-hard by the inductive assumption andMax CSP(h, v+ \u222a v\u22121 ) isNP-hard\nby Lemma 2.4. Consequently,Max CSP(h, v+, v\u22121 ) isNP-hard by Lemma 2.3\nand Max CSP({h}) is NP-hard by Lemma 3.1. Finally, if h(x, y) = 1 when-\never x \u2208 w\u2212 and y \u2208 v+, then H is bipartite. Since h is a core, we have |D| = 2\nwhich is a contradiction.\nCase 2: There exists v \u2208 D such that |v\u2212| > 1.\nThis case is analogous to the previous case.\nCase 3: Every v \u2208 D satisfies |v+| \u2264 1 and |v\u2212| \u2264 1.\nPick any v, w \u2208 D such that h(v, w) = 1 and note that, since {v} = w\u2212 and\n{w} = v+, predicates u{v} and u{w} are members of U . By the inductive as-\nsumption, Max CSP({h|{v,w}) is NP-hard. As above, we apply Lemmas 2.3,\n3.1, and 2.4 to obtain NP-hardness of Max CSP({h}). 2\nFinally, we extend the previous lemma to predicates of arbitrary arity via an\ninductive argument.\nTheorem 3.3 Let h \u2208 R(n)D , n \u2265 2. If h(d, . . . , d) = 1 for some d \u2208 D,\nthen Max CSP({h}) is trivial. If h is nontrivial and irreflexive, then Max\nCSP({h}) is NP-hard.\nProof: If h(d, . . . , d) = 1 for some d \u2208 D, then the assignment mapping\nevery variable to d satisfies all constraints in any instance. Assume that\nh is nontrivial and irreflexive and show that Max CSP({h}) is NP-hard.\nThe proof is by induction on n (the arity of h). The basis when n = 2\nwas proved in Lemma 3.2. Assume that the result holds for n = k, k \u2265\n2. We show that it holds for n = k + 1. Assume first that there exists\n(a1, . . . , ak+1) \u2208 Dk+1 such that h(a1, . . . , ak+1) = 1 and |{a1, . . . , ak+1}| \u2264 k.\nWe assume without loss of generality that ak = ak+1 and consider the predicate\nh\u2032(x1, . . . , xk) = h(x1, . . . , xk, xk). Note that this is a strict 1-implementation\n11\nof h\u2032, that h\u2032(d, . . . , d) = 0 for all d \u2208 D, and that h\u2032 is nontrivial since\nh\u2032(a1, . . . , ak) = 1. Consequently, Max CSP({h\u2032}) is NP-hard by the induc-\ntion hypothesis, and Max CSP({h}) is NP-hard by Lemma 2.2.\nAssume now that |{a1, . . . , ak+1}| = k+1 whenever h(a1, . . . , ak+1) = 1. Con-\nsider the predicate h\u2032(x1, . . . , xk) = maxy h(x1, . . . , xk, y), and note that this\nis a strict 1-implementation of h\u2032. We see that h\u2032(d, . . . , d) = 0 for all d \u2208 D\n(due to the condition above) and h\u2032 is non-trivial since h is non-trivial. We\ncan once again apply the induction hypothesis and draw the conclusion that\nMax CSP({h\u2032}) and Max CSP({h}) are NP-hard. 2\n3.2 Complexity of Max AW CSP(F)\nTheorem 3.6 contains the classification result forMax AW CSP(F); its proof\nis based on Lemmas 3.4 and 3.5.\nGiven a predicate f : Dk \u2192 {0, 1}, we say that a variable xi, 1 \u2264 i \u2264 k, is\nfictitious in f(x1, . . . , xk) if\nf(a1, . . . , ai\u22121, ai, ai+1, . . . , an) = f(a1, . . . , ai\u22121, a\u2032i, ai+1, . . . , an)\nfor all choices of a1, . . . , ai\u22121, ai, a\u2032i, ai+1, . . . , ak \u2208 D, and xi is called essential\notherwise. We call an n-ary predicate f essentially unary if there is a subset\nD\u2032 \u2286 D and an index 1 \u2264 i \u2264 n such that f(x1, . . . , xn) = uD\u2032(xi) for all\nx1, . . . , xn \u2208 D; in other words, f(x1, . . . , xn) = 1 if and only if xi \u2208 D\u2032. Note\nthat a predicate is essentially unary if and only if at most one of its variables\nis essential.\nFor a predicate f , let f = 1\u2212 f .\nLemma 3.4 Let f be a predicate that is not essentially unary. Then, Max\nCSP({f, f}) is NP-hard.\nProof: Note that an argument is fictitious in f if and only if it is such in f .\nWe may without loss of generality assume that the arity of f is even, say 2k.\nMoreover, we can assume that f contains at most one fictitious argument if\nk > 1 and no fictitious arguments if f is binary. To justify these assumptions,\nnote that we can repeatedly maximize f and f over any one of their fictitious\narguments to strictly 1-implement predicates g and g, respectively, with less\nfictitious arguments. We stop this process when there is at most one fictitious\nvariable left and the arity of the obtained predicate is even. Since, by the\nassumption of the theorem, f initially has at least 2 essential variables, the\nobtained predicate has the required properties. If initially f is of odd arity and\n12\nhas no fictitious variables, then we can add one by strict 1-implementation\ng(x1, . . . , x2k) = f(x1, . . . , x2k\u22121).\nConsider the following two functions fi : D\n2k \u2192 {0, 1, 2}:\nf1(x,y) = max\na\u2208Dk\n[f(x, a) + f(y, a)]\nf2(x,y) = max\na\u2208Dk\n[f(a,x) + f(a,y)]\nWe show that at least one of them is a strict 2-implementation of a predicate\nFi : D\n2k \u2192 {0, 1}, that is, Fi(x,y) = fi(x,y) \u2212 1 for some 1 \u2264 i \u2264 2.\nAssume to the contrary that this does not hold, that is, for i = 1, 2, there\nexist xi,yi \u2208 Dk such that fi(xi,yi) = 0. Then,\n(1) for all a \u2208 Dk, f(x1, a) = 0 and f(y1, a) = 0; and\n(2) for all a\u2032 \u2208 Dk, f(a\u2032,x2) = 0 and f(a\u2032,y2) = 0.\nWe see that for all a\u2032, f(a\u2032,x2) = 0 so f(a\u2032,x2) = 1. However, for all a,\nf(y1, a) = 0 so by setting a = x2 and a\n\u2032 = y1 we obtain a contradiction. We\ncan consequently assume that at least one of the implementations above is a\nstrict 2-implementation of a predicate Fi. Assume that F1 is strictly imple-\nmented; the other case is analogous.\nClaim 1: F1 is irreflexive\nAssume F1(d, . . . , d) = 1 for some d \u2208 D. This implies that there exists an\na \u2208 Dk such that f(d, . . . , d, a) = 1 and f(d, . . . , d, a) = 1 which is impossible.\nClaim 2: F1 is nontrivial\nAssume to the contrary that F1(x,y) = 0 for all x,y \u2208 Dk. Then, for all\nx,y, a \u2208 Dk, exactly one of f(x, a) and f(y, a) equals 1. If there exist s, t,u \u2208\nDk such that f(t, s) = 1 and f(u, s) = 0, then f(t, s) = f(u, s) = 1 which\nleads to a contradiction and F1 is nontrivial. Otherwise, for all s \u2208 Dk, it\nholds that either f(t, s) = 1 for all t \u2208 Dk, or f(t, s) = 0 for all t \u2208 Dk. In\nother words, the first k arguments in f are fictitious. By our assumptions on\nf , it has at most one fictitious variable, and none at all if it is binary. Thus,\nwe reach a contradiction.\nWe have thus obtained a nontrivial, irreflexive, and at least binary predicate\nF1 via strict implementations, so NP-hardness of Max CSP({f, f}) follows\nfrom Theorem 3.3 and Lemma 2.2. 2\nFor F \u2286 RD, let F\u02dc = {f, f | f \u2208 F}.\nLemma 3.5 The problems Max AW CSP(F) and Max CSP(F\u02dc) are poly-\nnomial-time equivalent for any F \u2286 RD,\n13\nProof: Let I be an instance of Max CSP(F\u02dc) corresponding to maximizing\nthe function\n\u2211q\ni=1 \u03c1i \u00b7 fi(xi). For 1 \u2264 i \u2264 q, define f \u2032i to be fi if fi \u2208 F , and\nf i otherwise. Furthermore, for 1 \u2264 i \u2264 q, let \u03c1\u2032i be \u03c1i if fi \u2208 F , and \u2212\u03c1i\notherwise. Finally, let K =\n\u2211\nfi 6\u2208F \u03c1i. Now it is not hard to see that\nq\u2211\ni=1\n\u03c1\u2032i \u00b7 f \u2032i(xi) =\n\u2211\nfi\u2208F\n\u03c1i \u00b7 fi(xi) +\n\u2211\nfi 6\u2208F\n(\u2212\u03c1i)(1\u2212 fi(xi)) =\nq\u2211\ni=1\n\u03c1i \u00b7 fi(xi)\u2212K.\nIt is clear that I is equivalent to the instance I \u2032 of Max AW CSP(F) corre-\nsponding to maximizing the function\n\u2211q\ni=1 \u03c1\n\u2032\ni \u00b7 f \u2032i(xi).\nThe other direction is very similar. Let I be an instance ofMax AW CSP(F)\ncorresponding to maximizing the function\n\u2211q\ni=1 \u03c1i \u00b7fi(xi). For 1 \u2264 i \u2264 q, define\nf \u2032i to be fi if \u03c1i > 0, and f i otherwise. For 1 \u2264 i \u2264 q, let \u03c1\u2032i = |\u03c1i|. Let\nK =\n\u2211\n\u03c1i<0 \u03c1\n\u2032\ni. Again, it is not hard to see that\nq\u2211\ni=1\n\u03c1i \u00b7 fi(xi) =\nq\u2211\ni=1\n\u03c1\u2032i \u00b7 f \u2032i(xi)\u2212K.\nIt is clear that I is equivalent to the instance I \u2032 ofMax CSP(F\u02dc) correspond-\ning to maximizing the function\n\u2211q\ni=1 \u03c1\n\u2032\ni \u00b7 f \u2032i(xi). 2\nTheorem 3.6 Let F \u2286 RD. If every predicate in F is essentially unary, then\nthe problem Max AW CSP(F) is tractable. Otherwise, Max AW CSP(F)\nis NP-hard.\nProof: If every predicate in F is essentially unary, then, in any instance,\nthere is no variable that constrains any other variable. So, it is possible to\ngreedily choose the value of each variable such that the weight of satisfied\nconstraints is maximized \u2013 this yields an optimal solution to the given in-\nstance. This process can obviously be carried out in polynomial time. If F\ncontains a predicate f which is not essentially unary, then Max CSP({f, f})\nis NP-hard by Lemma 3.4 and the result follows from Lemma 3.5. 2\n4 Connections with (super)modularity\nRecent studies of the complexity and approximability of Max CSP [7,24,27]\nhave employed the algebraic property of supermodularity on lattices [30]. In\nthis section we investigate how this property relates to the results given in\nprevious sections.\n14\nRecall that a partial order onD is called a lattice if every two elements a, b \u2208 D\nhave a greatest common lower bound a u b (meet) and a least common upper\nbound aunionsqb (join). Every lattice can be considered as an algebra L = (D,u,unionsq)\nwith operations meet and join. For more information about lattices, see [13].\nIf, for 1 \u2264 i \u2264 n, Li is a lattice on a setDi, then the product lattice L1\u00d7. . .\u00d7Ln\nis defined onD1\u00d7. . .\u00d7Dn by extending the operations component-wise, that is,\nby setting, for a = (a1, . . . , an) and b = (b1, . . . , bn), aub = (a1ub1, . . . , anubn)\nand a unionsq b = (a1 unionsq b1, . . . , an unionsq bn). A function f : D1 \u00d7 . . . \u00d7Dn \u2192 R is said\nto be supermodular on L1 \u00d7 . . .\u00d7 Ln if\nf(a) + f(b) \u2264 f(a u b) + f(a unionsq b)\nfor all a,b. A function f is called submodular if the reverse inequality holds,\nand modular if it is both super- and submodular (that is, the above inequality\nis an equality). Modular functions are also sometimes called valuations [30].\nGiven a lattice L on D, let Ln denote the n-th power of L, that is, the product\nof n copies of L. Since predicates on D are functions Dn \u2192 {0, 1}, it makes\nsense to speak about modular, super- and submodular predicates on L. We\nshall say that a set F \u2286 RD is modular, super- or submodular on L if all\npredicates in F have the corresponding property.\nRecall that a distributive lattice is a lattice that can be represented by subsets\nof a set, with operations being set-theoretic intersection and union. Further-\nmore, a diamond is a lattice with the following structure: one element is greater\nthan all other elements, one element is smaller than all others, and all other\nelements are pairwise incomparable. Diamonds with at least 5 elements are\nnot distributive [13].\nIt is known that if F only contains predicates that are supermodular on some\nlattice L, which is distributive or a diamond, then Max CSP(F) is tractable\n(see [7,27], respectively) and there is evidence that all polynomial-time solv-\nable cases of Max CSP can be uniformly described by using the concept of\nsupermodularity, at least when the domains are small [7,24]. Moreover, all\nknown tractable cases of Max CSP(F) enjoy this property, while all known\nhard cases do not.\nWe will now show that, in all hardness results for Max CSP(F) obtained in\nthis paper, the set F is not supermodular on any lattice.\nProposition 4.1 If f \u2208 R(n)D , n \u2265 2, is nontrivial and irreflexive, then it is\nnot supermodular on any lattice on D.\nProof: Let L = (D,u,unionsq) be any lattice on D. Let a = (a1, a2, a3, . . . , an),\nf(a) = 1, and assume that the number ta = |{a1, . . . , an}| of distinct entries\n15\nin a is minimal among all tuples satisfying f . Since f is irreflexive, not all\nai\u2019s are the same. Assume without loss of generality that a1 6= a2. Let b =\n(a2, a1, a3, . . . , an). Since the operations u and unionsq of any lattice are obviously\ncommutative, we have a1 u a2 = a2 u a1 and a1 unionsq a2 = a2 unionsq a1. Moreover, we\nhave ai u ai = ai unionsq ai = ai for all 3 \u2264 i \u2264 n. Hence, taub, taunionsqb < ta, and we\nhave f(a u b) = f(a unionsq b) = 0 by the assumption on a.\nThus, f(a) + f(b) 6\u2264 f(a u b) + f(a unionsq b). 2\nWe will now show that, for any F , the set F\u02dc = {f, f | f \u2208 F} is not supermod-\nular on any lattice on D unless every f in F (and hence in F\u02dc) is essentially\nunary. We remark that every (essentially) unary predicate is (trivially) su-\npermodular on any totally ordered lattice. Now, it is easy to check from the\ndefinitions that a predicate f is supermodular on a lattice if and only if f is\nsubmodular on it. It follows that if F\u02dc is supermodular on some lattice L, then\nit is modular on L. In the rest of this section we will show that any modular\npredicate on a lattice is essentially unary.\nWe will use the following result of Topkis (see Theorem 2.6.4 [30]): A chain is\na totally ordered lattice. Let Xi, 1 \u2264 i \u2264 n, be chains, and X = X1\u00d7 . . .\u00d7Xn.\nA function f : X \u2192 R is said to be separable if there exist unary functions\ngi : Xi \u2192 R such that f(x1, . . . , xn) = \u2211ni=1 gi(xi) for all xi\u2019s.\nTheorem 4.2 ([30]) A real-valued function f on X is modular on X if and\nonly if it is separable.\nCorollary 4.3 Let X be as above. If f is modular on X and the range of f\nis {0, 1}, then f is essentially unary.\nRecall that every finite lattice L has the greatest element 1L and the least\nelement 0L. We will denote the elements (0L, . . . , 0L) and (1L, . . . , 1L) of L\nn\nby 0L and 1L, respectively.\nTheorem 4.4 If L is a lattice on D, then every modular predicate on L is\nessentially unary.\nProof: Let f be a modular predicate on L. We may assume that f is n-ary,\nn \u2265 2, and takes both values 0 and 1, since otherwise there is nothing to\nprove.\nAn element a \u2208 L is said to cover another element a\u2032 \u2208 L, denoted a\u2032 \u227a a, if\na\u2032 < a and there is no a\u2032\u2032 \u2208 L with a\u2032 < a\u2032\u2032 < a.\nFirst we show that there exist two elements, a = (a1, . . . , an) and b =\n(b1, . . . , bn), in L\nn such that f(a) = 0, f(b) = 1, and ai = bi for all posi-\n16\ntions i except one, where one of ai, bi covers the other in L.\nAssume that f(0L) = 0. Then, in L\nn, there is an unrefinable chain, say 0L =\nu1 \u227a u2 \u227a . . . \u227a us, between 0L and some element us such that f(us) = 1.\nClearly, there is some 1 \u2264 j \u2264 s \u2212 1 such that f(uj) = 0 and f(uj+1) = 1.\nIt is easy to see that, since uj \u227a uj+1 in Ln, all coordinates of uj and uj+1,\nexcept one, coincide, and in this one component the coordinate of uj+1 covers\nthe coordinate of uj. So we get the required elements a and b. If f(0L) = 1,\nthen the argument is very similar.\nAssume without loss of generality that a and b differ in the first component,\nthat is, a = (a1, a2, . . . , an) and b = (a\n\u2032\n1, a2, . . . , an) where a1 \u227a a\u20321 (the case\na\u20321 \u227a a1 is very similar). We will show that f essentially depends only on its\nfirst coordinate.\nFor 2 \u2264 i \u2264 n, let Xi = {ai, 1L}, and let X1 = {a1, a\u20321}. It is easy to see\nthat every Xi is a chain. Furthermore, X = X1 \u00d7 . . . \u00d7 Xn is a sublattice\nof Ln. Clearly, the restriction of f to X is a modular function on X. By\nCorollary 4.3, the function f |X is essentially unary. Moreover, by the choice of\na and b, we have that f |X = g(x1) for some unary predicate g on X1 such that\ng(a1) = 0 and g(a\n\u2032\n1) = 1. In particular, it follows that f(a1, 1L, . . . , 1L) = 0\nand f(a\u20321, 1L, . . . , 1L) = 1.\nAssume first that f(1L) = 1. Let c2, . . . , cn be arbitrary elements from L.\nFor 2 \u2264 i \u2264 n, let X \u2032i = {ci, 1L}, and let X \u20321 = {a1, 1L}. Furthermore, let\nX \u2032 = X \u20321\u00d7 . . .\u00d7X \u2032n. As above, each X \u2032i is a chain, and X \u2032 is a sublattice of Ln.\nLet f \u2032 = f |X\u2032 . Clearly, f \u2032 is modular on X \u2032. Moreover, since f(1L) = 1 and\nf(a1, 1L, . . . , 1L) = 0, Corollary 4.3 implies that f\n\u2032 = g\u2032(x1) for some g\u2032 such\nthat g\u2032(1L) = 1. Hence, f \u2032(1L, c2, . . . , cn) = 1. We infer that f(1L, x2, . . . , xn) =\n1 for all x2, . . . , xn \u2208 D.\nPick any elements d1, d2, . . . , dn \u2208 D such that f(d1, d2, . . . , dn) = 0. For\n1 \u2264 i \u2264 n, let X \u2032\u2032i = {di, 1L}, and let X \u2032\u2032 = X \u2032\u20321 \u00d7 . . .\u00d7X \u2032\u2032n. By restricting f to\nX \u2032\u2032 and using Corollary 4.3 together with equalities f(d1, d2, . . . , dn) = 0 and\nf(1L, d2, . . . , dn) = 1, we infer, as above, that f(d1, 1L, . . . , 1L) = 0.\nWe now take arbitrary e2, . . . , en \u2208 D and show that f(d1, e2, . . . , en) = 0.\nFor 2 \u2264 i \u2264 n, let X \u2032\u2032\u2032i = {ei, 1L}, and let X \u2032\u2032\u20321 = {d1, 1L}. Furthermore, let\nX \u2032\u2032\u2032 = X \u2032\u2032\u20321 \u00d7 . . . \u00d7 X \u2032\u2032\u2032n . By restricting f to X \u2032\u2032\u2032, we can apply Corollary 4.3\nagain. From the equalities f(1L, e2, . . . , en) = 1, f(1L, 1L, . . . , 1L) = 1, and\nf(d1, 1L, . . . , 1L) = 0, we conclude that f(d1, e2, . . . , en) = 0.\nWe have shown that, for any d1 \u2208 D, if f(d1, d2, . . . , dn) = 0 for some\nd2, . . . , dn \u2208 D, then we have f(d1, x2, . . . , xn) = 0 for all x2, . . . , xn. Thus,\nf essentially depends only on its first coordinate.\n17\nIf f(1L) = 0, then the argument is similar, simply exchange 0 and 1 through-\nout, and use a\u20321 instead of a1. 2\n5 Conclusion\nWe have proved that Max AW CSP over an arbitrary finite domain is ei-\nther polynomial-time solvable or NP-hard, and that the same holds for Max\nCSP({f}) where f is an arbitrary predicate on some finite domain. In order\nto prove these results, we showed that finding a maximum H-colourable subdi-\ngraph in a given digraph is eitherNP-hard or trivial depending on H. We have\nalso pointed out some connections between our work and (super)modularity.\nAllowing negative weights appeared to have drastic effect on the complexity\nof Max CSP, since only essentially trivial cases remained tractable. On the\npositive side, the obtained results agree with ideas of supermodularity-based\ndirection of research in Max CSP [7,24,27]. We believe that further progress\nin classifying the complexity of Max CSP will be made along the road of\nintegrating methods from algebraic lattice theory and classical combinatorial\noptimization, with Max CSP being a point of a new connection between the\ntwo research areas.\nAcknowledgements\nPeter Jonsson is supported by the Swedish Research Council (VR) under\ngrants 621\u20132003\u20133421 and 2006\u20134532, and the Center for Industrial Infor-\nmation Technology (Ceniit) under grant 04.01. Andrei Krokhin is supported\nby the UK Epsrc grant EP\/C543831\/1.\nReferences\n[1] G. Ausiello, P. Creszenzi, G. Gambosi, V. Kann, A. Marchetti-Spaccamela, and\nM. Protasi. Complexity and Approximation. Springer, 1999.\n[2] F. Barahona, M. Gro\u00a8tschel, M. Ju\u00a8nger, and G. Reinelt. An application of\ncombinatorial optimization to statistical physics and circuit layout design.\nOperations Research, 36:493\u2013513, 1988.\n18\n[3] S. Bistarelli, U. Montanari, F. Rossi, T. Schiex, G. Verfaillie, and\nH. Fargier. Semiring-based CSPs and Valued CSPs: Frameworks, properties,\nand comparison. Constraints, 4(3):199-240, 1999.\n[4] A. Bulatov. A dichotomy theorem for constraint satisfaction problems on a\n3-element set. Journal of the ACM, 53(1):66\u2013120, 2006.\n[5] A. Bulatov, H. Chen, and V. Dalmau. Learnability of relatively quantified\ngeneralized formulas. In Proc. 15th International Conference on Algorithmic\nLearning Theory (ALT-2004), pp. 365\u2013379, volume 3244 of LNCS, 2004.\n[6] D. Cohen, M. Cooper, P. Jeavons, and A. Krokhin. The complexity of soft\nconstraint satisfaction. Artificial Intelligence, 170(11):983-1016, 2006.\n[7] D. Cohen, M. Cooper, P. Jeavons, and A. Krokhin. Supermodular functions\nand the complexity of Max CSP. Discrete Applied Mathematics, 149(1-3):53\u201372,\n2005.\n[8] N. Creignou. A dichotomy theorem for maximum generalized satisfiability\nproblems. Journal of Computer and System Sciences, 51:511\u2013522, 1995.\n[9] N. Creignou, S. Khanna, and M. Sudan. Complexity Classifications of Boolean\nConstraint Satisfaction Problems, volume 7 of SIAM Monographs on Discrete\nMathematics and Applications. 2001.\n[10] V. Dalmau. Constraint satisfaction problems in non-deterministic logarithmic\nspace. In Proc. 29th International Colloquium on Automata, Languages and\nProgramming (ICALP-2002), pp. 414\u2013425, volume 2380 of LNCS, 2002.\n[11] V. Dalmau and P. Jeavons. Learnability of quantified formulas. Theoretical\nComputer Science, 306(1-3): 485\u2013511, 2003.\n[12] V. Dalmau and P. Jonsson. The complexity of counting homomorphisms seen\nfrom the other side. Theoretical Computer Science, 329(1-3): 315\u2013323, 2004.\n[13] B.A. Davey and H.A. Priestley. Introduction to Lattices and Order. Cambridge\nUniversity Press, 2002.\n[14] R. Dechter. Constraint Processing. Morgan Kaufmann, 2003.\n[15] T. Feder and M.Y. Vardi. The computational structure of monotone monadic\nSNP and constraint satisfaction: A study through Datalog and group theory.\nSIAM Journal on Computing, 28:57\u2013104, 1998.\n[16] M. Goemans and D. Williamson. Improved approximation algorithms for\nmaximum cut and satisfiability problems using semidefinite programming.\nJournal of the ACM, 42:1115\u20131145, 1995.\n[17] G. Gottlob, L. Leone, and F. Scarcello. Hypertree decomposition and tractable\nqueries. Journal of Computer and System Sciences, 64(3):579\u2013627, 2002.\n[18] M. Grohe. The complexity of homomorphism and constraint satisfaction\nproblems seen from the other side. In Proc. 44th IEEE Symposium on\nFoundations of Computer Science (FOCS-2003), pp. 552\u2013561, 2003.\n19\n[19] J. H\u02daastad. On bounded occurence constraint satisfaction. Information\nProcessing Letters, 74:1\u20136, 2000.\n[20] J. H\u02daastad. Some optimal inapproximability results. Journal of the ACM,\n48:798\u2013859, 2001.\n[21] P. Hell and J. Nes\u02c7etr\u02c7il. On the complexity of H-coloring. Journal of\nCombinatorial Theory, Ser.B, 48:92\u2013110, 1990.\n[22] P. Hell and J. Nes\u02c7etr\u02c7il. Graphs and Homomorphisms. Oxford University Press,\n2004.\n[23] P. Jonsson. Boolean constraint satisfaction: Complexity results for optimization\nproblems with arbitrary weights. Theoretical Computer Science, 244(1-2):189\u2013\n203, 2000.\n[24] P. Jonsson, M. Klasson, and A. Krokhin. The approximability of three-valued\nMax CSP. SIAM Journal on Computing, 35(3):1329\u20131349, 2006.\n[25] S. Khanna, M. Sudan, L. Trevisan, and D. Williamson. The approximability\nof constraint satisfaction problems. SIAM Journal on Computing, 30(6):1863\u2013\n1920, 2001.\n[26] Ph.G. Kolaitis and M.Y. Vardi. Conjunctive-query containment and constraint\nsatisfaction. Journal of Computer and System Sciences, 61:302\u2013332, 2000.\n[27] A. Krokhin and B. Larose. Maximum constraint satisfaction on diamonds. In\nProc. 11th International Conference on Principles and Practice of Constraint\nProgramming (CP-2005), pp. 388\u2013402, volume 3709 of LNCS, 2005.\n[28] J. Nocedal and S. Wright. Numerical Optimization. Springer, 1999.\n[29] T.J. Schaefer. The complexity of satisfiability problems. In Proc. 10th ACM\nSymposium on Theory of Computing (STOC-1978), pp. 216\u2013226, 1978.\n[30] D. Topkis. Supermodularity and Complementarity. Princeton University Press,\n1998.\n[31] E. Tsang. Foundations of Constraint Satisfaction. Academic Press, London,\n1993.\n20\n"}
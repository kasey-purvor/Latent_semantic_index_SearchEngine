{"doi":"10.1080\/13669870601011191","coreId":"141143","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/2926","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/2926","10.1080\/13669870601011191"],"title":"Benchmarking risk management within the international water utility sector. Part\nII: A survey of eight water utilities.","authors":["MacGillivray, Brian H.","Sharp, J. V.","Strutt, J. E.","Hamilton, Paul D.","Pollard, Simon J. T."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-01-31T00:00:00Z","abstract":"Risk management in the water utility sector is fast becoming explicit. Here, we\ndescribe application of a capability model to benchmark the risk management\nmaturity of eight water utilities from the UK, Australia and the USA. Our\nanalysis codifies risk management practice and offers practical guidance as to\nhow utilities may more effectively employ their portfolio of risk analysis\ntechniques for optimal, credible, and defensible decision making. For risk\nanalysis, observed good practices include the use of initiation criteria for\napplying risk assessment techniques; the adoption of formalised procedures to\nguide their application; and auditing and peer reviews to ensure procedural\ncompliance and provide quality assurance. Additionally, we have identified\ncommon weaknesses likely to be representative of the sector as a whole, in\nparticular a need for improved risk knowledge management and education and\ntraining in the discipline","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/141143.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/10.1080\/13669870601011191","pdfHashValue":"e2aebe53e1115b576bb026eaf0372c16d72931cb","publisher":"Taylor & Francis","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/2926<\/identifier><datestamp>2012-01-16T12:26:21Z<\/datestamp><setSpec>hdl_1826_24<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Benchmarking risk management within the international water utility sector. Part\nII: A survey of eight water utilities.<\/dc:title><dc:creator>MacGillivray, Brian H.<\/dc:creator><dc:creator>Sharp, J. V.<\/dc:creator><dc:creator>Strutt, J. E.<\/dc:creator><dc:creator>Hamilton, Paul D.<\/dc:creator><dc:creator>Pollard, Simon J. T.<\/dc:creator><dc:subject>Maturity model<\/dc:subject><dc:subject>risk analysis<\/dc:subject><dc:subject>risk management<\/dc:subject><dc:subject>water sector<\/dc:subject><dc:description>Risk management in the water utility sector is fast becoming explicit. Here, we\ndescribe application of a capability model to benchmark the risk management\nmaturity of eight water utilities from the UK, Australia and the USA. Our\nanalysis codifies risk management practice and offers practical guidance as to\nhow utilities may more effectively employ their portfolio of risk analysis\ntechniques for optimal, credible, and defensible decision making. For risk\nanalysis, observed good practices include the use of initiation criteria for\napplying risk assessment techniques; the adoption of formalised procedures to\nguide their application; and auditing and peer reviews to ensure procedural\ncompliance and provide quality assurance. Additionally, we have identified\ncommon weaknesses likely to be representative of the sector as a whole, in\nparticular a need for improved risk knowledge management and education and\ntraining in the discipline.<\/dc:description><dc:publisher>Taylor & Francis<\/dc:publisher><dc:date>2012-01-10T23:02:42Z<\/dc:date><dc:date>2012-01-10T23:02:42Z<\/dc:date><dc:date>2007-01-31T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>B. H. MacGillivray; J. V. Sharp; J. E. Strutt; P. D. Hamilton; S. J. T. Pollard.\nBenchmarking Risk Management Within the International Water Utility Sector. Part\nII: A Survey of Eight Water Utilities. Journal of Risk Research, Volume 10,\nIssue 1, January 2007, pages 105-123<\/dc:identifier><dc:identifier>1366-9877<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1080\/13669870601011191<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/2926<\/dc:identifier><dc:language>en_UK<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["1366-9877","issn:1366-9877"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2007,"topics":["Maturity model","risk analysis","risk management","water sector"],"subject":["Article"],"fullText":" 1\nBenchmarking risk management within the international water 1 \nutility sector.  Part II: a survey of eight water utilities 2 \n 3 \nB.H. MacGillivray, J.V. Sharp, J.E. Strutt, P.D. Hamilton and S.J.T. Pollard* 4 \n 5 \nSchool of Water Sciences, Cranfield University, Cranfield, Bedfordshire, MK43 0AL, UK. 6 \n 7 \n* Corresponding author 8 \nEmail: s.pollard@cranfield.ac.uk 9 \nTelephone: +44 (0)1234 754101 10 \n 11 \n 12 \n 13 \n 14 \n 15 \n 16 \n 17 \n 2\nABSTRACT 1 \nRisk management in the water utility sector is fast becoming explicit.  Here, we describe 2 \napplication of a capability model to benchmark the risk management maturity of eight 3 \nwater utilities from the UK, Australia and the USA.  Our analysis codifies risk 4 \nmanagement practice and offers practical guidance as to how utilities may more effectively 5 \nemploy their portfolio of risk analysis techniques for optimal, credible, and defensible 6 \ndecision making.  For risk analysis, observed good practices include the use of initiation 7 \ncriteria for applying risk assessment techniques; the adoption of formalised procedures to 8 \nguide their application; and auditing and peer reviews to ensure procedural compliance and 9 \nprovide quality assurance.  Additionally, we have identified common weaknesses likely to 10 \nbe representative of the sector as a whole, in particular a need for improved risk knowledge 11 \nmanagement and education and training in the discipline. 12 \n 13 \nKEYWORDS: maturity model, risk analysis, risk management, water sector 14 \n 15 \n 16 \n 17 \n 18 \n 19 \n 20 \n 21 \n 3\n1. Introduction 1 \n1.1 RISK MANAGEMENT IN THE WATER UTILITY SECTOR 2 \nThe water sector is witnessing a significant shift in the approach to managing risk to 3 \none that is increasingly explicit and broad in scope.  Risk management strategies and 4 \ntechniques traditionally applied to occupational health and safety and public health 5 \nprotection are seeing application to corporate level decision making, asset management 6 \n(Booth and Rogers, 2001; Lifton and Smeaton, 2003), watershed protection (IMPRESS 7 \nManagement, 2002; Lloyd and Abell, 2005; WHO, 2003) and network reliability (Stevens 8 \nand Lloyd, 2004; Stahl and Elliott, 1999).  This is in large part a response to the corporate 9 \ngovernance, asset management, public health and environmental protection agendas, and 10 \nrepresents a growing recognition that the provision of safe drinking water deserves to be 11 \ntreated as a \u201chigh reliability\u201d societal service, subject to the sectoral and organisational 12 \nrigours and controls inherent to the nuclear, offshore and aerospace industries (Pollard et 13 \nal., 2005).  However, it is not the presence of risk management  per se that governs the 14 \nvalue derived, but its relative maturity of implementation within a utility.  We have 15 \ndeveloped a capability maturity model for benchmarking and improving the processes that 16 \ncomprise risk management (MacGillivray et al., 2006a).  Here, we report its application to 17 \nbenchmark within the international water utility sector, the purpose of which was to 18 \nidentify good risk management practices and explore how they may be defined and 19 \ncontrolled within organisational processes. 20 \n 21 \n1.2 RISK MANAGEMENT CAPABILITY MATURITY MODEL (RM-CMM) 22 \n 4\nOur companion paper (MacGillivray et al., 2006a) describes the development of a 1 \nRM-CMM for the water utility sector.  The model is a prescriptive codification of water 2 \nsector risk management practice, within a process-based maturity hierarchy.  The model 3 \nwas developed by abstracting the principles of capability maturity modelling observed in 4 \nother disciplines, including software and systems engineering (Paulk et al., 1993; Software 5 \nEngineering Institute, 2002a), workforce development and management (Software 6 \nEngineering Institute, 2002b), offshore design safety (Sharp et al., 2002), reliability 7 \nengineering (Strutt, 2003), and construction (Sarshar et al., 2000).  This was achieved 8 \nthrough literature reviews (MacGillivray et al., 2006b; Pollard et al., 2004; Hamilton et al., 9 \n2006), structured interviews with water utility managers, and prior knowledge of maturity 10 \nmodelling in similar utility sectors.  We identified eleven risk management processes (Fig. 11 \n1).  These processes are separated into five maturity levels, from learner to best practice.  12 \nThese maturity levels, characterised by reference to key attributes (Fig. 1), reflect the 13 \nextent to which each process is defined, institutionalised and controlled.  It is important to 14 \nunderstand what these levels represent in practice as this is crucial to assessing the maturity 15 \nof an organisation.  Whilst the precise definition of the maturity hierarchy is process 16 \nspecific, a generalised description is provided in Table 1. 17 \n 18 \n2.  Methodology 19 \nEight water utilities from the UK, Australia and the USA participated in this study.  20 \nThis was supplemented by the participation of an electricity utility regarded as best 21 \npractice in risk management.  However, an incomplete questionnaire return prevented its 22 \nmaturity assessment, and we restrict its discussion to key observations.  The sample is 23 \n 5\nintended to reflect good risk management practice, hence we do not suggest that our 1 \nanalysis is representative of the sector as a whole.  The scope of analysis varies by utility, 2 \nand includes organisational, business unit, and functional perspectives (Table 2).    Sample 3 \nselection drew upon existing industrial contacts and was further informed by prior reviews 4 \n(MacGillivray et al., 2006b; Pollard et al., 2004; Hamilton et al., 2006) of the academic, 5 \npractitioner and grey literature. 6 \nA survey-type research design was adopted, whilst the research methods included 7 \nquestionnaire, interview and textual analysis.  The questionnaire was comprised of a series 8 \nof statements characterising the undertaking of each risk management process at each 9 \nmaturity level.  These were responded to on a four point scale (fully agree; generally agree; 10 \npartially agree; and disagree), with space provided for supporting comments.  Process 11 \nmaturity was determined according to the highest \u201cdegree of fit\u201d; a measure of the average 12 \nlevel of agreement with the guideline statements at each maturity level for each process.  13 \nThe interview and textual analysis was concerned with identifying the specific risk 14 \nmanagement practices undertaken within the sample and correlating these with our model 15 \n(e.g. how, practically, is risk analysis defined and controlled as a process).  Semi-structured 16 \ninterviews were undertaken with each assessor following receipt of the questionnaire.  The 17 \ninterview methodology was developed, tested and refined within a separate industrial case 18 \nstudy.  Interviews were conducted by \u2019phone, recorded, and subsequently converted into 19 \ntranscripts.  These transcripts were returned to each interviewee, providing them an 20 \nopportunity to comment.  Finally, a range of pertinent supporting company documentation 21 \nwas requested from each participant.  Those made available included risk management 22 \npolicies and frameworks, risk analysis procedures and techniques, and water safety plans. 23 \n 6\nGiven the qualitative nature of the research, mechanisms to validate our findings 1 \nwere adopted.  This was achieved through sample anonymity and triangulation.  2 \nAnonymity removed the potential for conflicts with the fundamental goal of adding to the 3 \nbody of knowledge (as opposed, e.g., to the participants\u2019 desire that the findings reflected 4 \npositively upon their organisation).  Triangulation sought to balance the lead author\u2019s 5 \nprincipal analysis of the questionnaires, texts and interview transcripts with a blind scoping 6 \nanalysis conducted by a co-author.  Additionally, each respondent was offered the 7 \nopportunity to comment on all statements within the paper referring specifically to their 8 \nutility.  Diverging perspectives were resolved through consensus. 9 \n 10 \n3. Results and discussion 11 \nFigs. 2 and 3 illustrate the sample process maturity profiles.  Detailed discussion of 12 \nthese levels may be found in our companion paper.  Here, we do not dwell on the maturity 13 \nprofiles as our scoring methodology is arbitrarily rather than scientifically derived and the 14 \nsample is not intended to reflect the sector as a whole.  We restrict ourselves to the 15 \nfollowing observations.  The sample profiles are relatively mature for the core and 16 \nsupporting processes of risk management, in contrast to the long-term processes of 17 \neducation and training in risk management and risk knowledge management.  Two 18 \nexplanations are offered.  Firstly, the attention and resources dedicated to the design and 19 \nexecution of processes is correlated with their perceived criticality.  Secondly, the long-20 \nterm processes receive limited treatment within the academic and practitioner literature, 21 \nleaving utilities bereft of guidance.  The maturity of the supporting processes \u2013 supply 22 \nchain risk management and change risk management \u2013 is particularly high.  The strength in 23 \n 7\nthe former is likely a function of the increasing level of outsourcing within the sector.  1 \nSimilarly, we propose that mature change risk management is driven by evolving 2 \nregulatory and governance structures and the commonality of internal restructuring.   3 \nWe now discuss the observed risk management practices on a process-specific basis.   4 \n 5 \n3.1 STRATEGIC RISK PLANNING 6 \nHere, we observed an even spread of our sample between L3 and L4.  Strategic risk 7 \nplanning is primarily concerned with the development of a risk management framework.  8 \nIn essence, these frameworks were observed to set out the rationale, procedures and 9 \nresponsibilities for the discipline.  At L3 and L4, we observed that their development may 10 \nbe characterised as the evaluation and adaptation of external risk management standards.  11 \nFor example, one manager described how the forbearer of their corporate-wide risk 12 \nmanagement framework was an adaptation of an occupational health and safety 13 \nmanagement system, which has evolved drawing upon the AS\/NZS: 4360 (Council of 14 \nStandards of Australia, 1999) standard and broader experiences of the sector.  Another 15 \ndescribed how they were \u201ctrying to use the rationale, the basis of the COSO (COSO, 2004) 16 \nstandard, but the methodology is one that\u2019s been developed by us.\u201d  We may consider the 17 \nvetting of these frameworks (e.g. by the Board, internal audit, etc.) as a form of output 18 \nvalidation, however, it was unclear whether the process by which they are developed, or 19 \nmore precisely adapted, is subject to oversight.   20 \n 21 \n3.2 ESTABLISHING RISK ACCEPTANCE CRITERIA 22 \nThis process involves the development of criteria for evaluating the tolerability and 23 \nsignificance of risk.  Here, we observed five L3 organisations, and one each at L2, L4 and 24 \n 8\nL5.  At L2, risk acceptability is largely set with reference to regulations and standards.  1 \nExpanding on this, the L2 manager stated that \u201cthe corporate risk appetite is primarily 2 \nperceptual and based upon broad guidelines established by upper management, the Board, 3 \nexternal auditors, stakeholders and bond-holders.\u201d   4 \nAn observed L3 practice was the allocation of risk tolerability criteria in operational 5 \nand financial areas.  These included design standards informed by hazard and operability 6 \n(HAZOP) analyses; operating and maintenance practices informed by reliability 7 \nmodelling; as low as reasonably practicable (ALARP) criteria for evaluating dam safety 8 \nrisk; the use of risk-based criteria to determine raw water treatment requirements; and risk-9 \nadjusted discount rates applied within financial analysis models to balance investment 10 \nreturns with uncertainty.  However, it appeared that the processes through which these 11 \ncriteria are established reside within organisational functions (e.g. engineering, finance) 12 \nand thus lie outside the remit of the corporate risk manager.  As one manager noted, 13 \ntolerability criteria may exist \u201cwithin discrete areas of the business\u2026but they exist as 14 \nislands with no\u2026overlaying risk management policy or strategy.\u201d 15 \n    Further, we observed the development of risk ranking techniques which outline the 16 \ncriteria by which organisations assess the significance of risk both at the corporate level 17 \nand, in some cases, specific to organisational functions such as asset management.  18 \nTolerability criteria were often embedded within these techniques (e.g. low risk: manage 19 \nby routine procedures; high risk: management response required).  These techniques were 20 \ntypically derived from risk management standards.  Observed adaptations included the 21 \nalignment of consequence criteria with corporate objectives (e.g. environmental, financial, 22 \netc.); the tailoring of impact descriptors; and the assignment of costs to impact categories.   23 \n 24 \n 9\n3.3 RISK ANALYSIS 1 \nHere, five utilities were evaluated at L3, three at L4.  Risk analysis involves the 2 \nidentification and assessment of risk.  Our sample indicates two distinct categories of risk 3 \nanalysis: a generic strategic technique; and a series of discrete methods applied in 4 \noperational areas.  The former may be characterised as the application of qualitative risk 5 \nranking techniques to analyse the risks inherent to managing a water utility as a business.  6 \nThe latter included a raft of industry standard and best practice tools, both qualitative and 7 \nquantitative.  Those observed included HAZOP studies; hazard analysis and critical control 8 \npoints (HACCP) evaluations; failure mode, effect and criticality analyses (FMECA); and 9 \nmonte carlo simulation of financial variables.   10 \nA prerequisite for process definition (L3) is that the application of these techniques is 11 \nguided by formalised procedures \u2013 a practice intended to ensure the consistency and rigour 12 \nof analysis.  Regarding strategic risk analysis, best practice may be described with 13 \nreference to the electricity utility.  Here, a range of risk identification techniques are 14 \navailable, and their selection depends upon \u201cthe depth and breadth of activities under 15 \nreview and the extent to which the business context is new.\u201d  Listed techniques include 16 \nstrengths, weaknesses, opportunities and threats (SWOT) analysis; scenario analysis; value 17 \nchain analysis; benchmarking; control self assessments; audit reports; etc.  Risk categories 18 \nare used as a further prompt for identification (strategic, regulatory, financial and 19 \noperational).  It was common practice across our sample to assess strategic risks via a 20 \ncombination of expert judgement and, where available, historic data to determine a range 21 \nof parameters (e.g. probability, consequence, development time, triggers, control design 22 \nand usage, etc.).  The electricity utility\u2019s use of the Delphi technique (Dalkey and Helmer, 23 \n1963) in risk assessment is notable.  Here, facilitated discussions and iterative anonymous 24 \n 10\nvoting were applied to generate expert consensus.  The method\u2019s explicit recognition of 1 \nhuman judgment as a legitimate input is particularly valuable where data is limited.  2 \nFurthermore, characterised as it is by group participation, anonymity and feedback loops, it 3 \nminimises bias and dogmatism (i.e. reduces the reluctance of staff to abandon previously 4 \nstated views).  A caveat: it appears that in many cases strategic risk analysis tends to be as 5 \none manager stated \u201cshepherded by the corporate risk team\u201d rather than guided in a 6 \nmechanistic manner.  This contrasts with the more procedural approach adopted 7 \noperationally (e.g. in occupational health and safety), and perhaps reflects the perceived 8 \nvalue of creativity in strategic risk analysis. 9 \nA further observed L3 characteristic was the use of criteria for the selection and 10 \napplication of risk analysis techniques.  The strategic risk ranking tools were typically 11 \ninitiated within business and strategic planning as well as on an ad hoc basis as new risks 12 \narise, whilst various nodes (e.g. the concept design stage for application of HAZOP) served 13 \nas initiating criteria for the various operational methods.   Observed selection criteria 14 \nincluded the use of financial thresholds to delineate the application of Monte Carlo 15 \nsimulation from simple checklists to evaluate financial risk within programme 16 \nmanagement. Basic verification mechanisms are a further L3 characteristic.  This is 17 \nreflected in one utility\u2019s requirement for supervisors to review risk assessments of minor 18 \nconstruction and maintenance works prior to \u201csign off.\u201d  Similarly, one manager 19 \nhighlighted the role of their \u201csystems certification process\u201d in ensuring procedural 20 \ncompliance.  Here, a taskforce  \u201cconducts certification audits, checking the business 21 \npractices of each system, making sure that they\u2019re in concert with our way of doing 22 \nbusiness; one element of which is that they\u2019re doing risk assessments and that they\u2019re 23 \ndoing it properly.\u201d  Another interviewee described a tri-partite approach to auditing.  Here, 24 \n 11\nin addition to external auditing by their parent company, \u201cinternal audit come in every 1 \nyear, to check that we\u2019re process compliant by drilling down from risk reporting at the 2 \nhighest level, right down through identification, assessment\u2026also as a [risk management] 3 \nteam, we do our own local audits to make sure that people are up to speed\u2026and [we] 4 \ntackle non compliance.\u201d  The importance of such checks and balances was highlighted by 5 \none participant\u2019s contrasting of the inconsistencies surrounding their locally managed 6 \nsanitary surveys with the consistency of their centrally managed barrier surveys.  7 \nFurthermore, several managers related concerns that analyst bias may lead to distortions of 8 \nrisk analysis outputs.  Whilst underscoring was the most commonly noted threat, one 9 \nmanager revealed that their adoption of a risk-based capital investment programme has led 10 \nto a significant likelihood of asset managers \u201cover-egging\u201d their analyses to attract greater 11 \nfunding for their regions.  To address this, verification should extend to audit the quality of 12 \nanalysis undertaken. 13 \nThis enhanced role for verification was observed at L4, as reflected in one utility\u2019s 14 \n\u201cquality assurance consistency checks\u201d within asset management.  Here, risk analysis 15 \noutputs and their underpinning assumptions were systematically reviewed and challenged 16 \nby a multi-disciplinary team of experts.  The interviewee noted that the value of this 17 \nprocedure extends beyond quality assurance of analysis outputs to highlighting common 18 \nerrors in applying the methodology itself: \u201cwe\u2019ve had some problems with people using 19 \n[the methodology], some were misinterpreting it, we spotted this from the data and [the 20 \nconsistency checks].  Some asset managers score the probability of an asset failing, some 21 \nscore the probability of an asset failing and [leading to a defined] impact; the latter is what 22 \nwe want.\u201d  We now highlight the subtle distinction between verification, which seeks to 23 \nevaluate whether the process has been followed correctly, and validation, which is 24 \n 12\nconcerned with whether the process itself is correct (e.g. validating the risk analysis 1 \ntechniques).  Both of these aspects were enshrined in one utility\u2019s application of a 2 \n\u201ccommon sense screen\u201d at the end of their water quality risk analysis process.  Here, if 3 \nanalysis outputs appeared at odds with experienced operational knowledge, the reason 4 \nbehind the \u201cfalse\u201d score was investigated, and the process and score adapted where 5 \nappropriate.   6 \nAlthough engagement of a broad range of stakeholders is characteristic of L4 7 \nmaturity, broad internal stakeholder engagement was characteristic of each utility\u2019s 8 \napproach to strategic risk analysis, which was typically conducted within cross-functional 9 \nforums.  However, the engagement of external stakeholders appears to occur on a far more 10 \nselective basis.  One L3 manager commented that there were \u201cno formal procedures for 11 \nexternal risk reporting\u201d and that, beyond the outcomes of security-related risk assessments, 12 \nthe \u201cregulator has shown little interest\u201d.  Two of the L4 interviewees expressed a greater 13 \nrecognition of the need to engage external actors in risk analysis, both where risks have 14 \nhigh external stakeholder implications (e.g. political or environmental) and where expert 15 \nguidance is required.  In contrast, one manager explained their reticence to engage external 16 \nbodies by noting that \u201crisk assessments are a risk for ourselves, if we identify something as 17 \na business risk, particularly if its environmental, hazardous, or regulatory, that\u2019s out there, 18 \nif you don\u2019t address that, it\u2019s going to come back at you.\u201d    19 \nFinally, the sufficiency of resourcing within each L4 company was evidenced by 20 \ntheir active research and development in risk analysis.  One was researching the integration 21 \nof predictive GIS tools with continuous and event-based monitoring data for application in 22 \ncatchment risk analysis.  In contrast, one L3 interviewee highlighted resource constraints 23 \nas a limitation: \u201cone issue is the complexity of our analyses, we have ten water systems 24 \n 13\nand thirteen catchments [which are] diverse in [size and] nature\u2026for a small organisation 1 \nthat serves only about 15,000 customers, resourcing these sorts of studies is not easy.\u201d 2 \n 3 \n3.4 RISK BASED DECISION MAKING AND REVIEW 4 \nRisk based decision making involves the identification and evaluation of solutions to 5 \nmanage individual risks.  Here, six of our sample were evaluated at L3 maturity, with one 6 \neach at L2 and L4.  At L3 maturity, we observed procedures to ensure that risk analysis 7 \noutputs explicitly inform decision making.  These ranged from the integration of the risk 8 \nanalysis and decision making processes within strategic risk management workshops, to 9 \nthe risk analysts\u2019 role of briefing non-technical decision makers in operational areas.  We 10 \nfurther observed decision making frameworks.  This is reflected in one utility\u2019s adoption of 11 \na predefined hierarchy of occupational health and safety hazard control measures: 12 \nelimination (does the work have to be done); substitution (can it be done in a less 13 \nhazardous way); engineering controls (isolation, containment); administration (procedures, 14 \ntrained staff); personal protective equipment (respirators, helmets); and warning signs.  15 \nThis structures the identification of solutions.  In a more generic context, the electricity 16 \nutility categorizes risks by the extent to which their exposure can be managed: controllable 17 \n(e.g. financial or health and safety risks) and influenceable (e.g. competition, regulation).  18 \nSeven \u201crisk treatment\u201d options are then applied to structure the identification of solutions: 19 \nretain; retain but change mitigation; increase (risk exposure is increased, for example, 20 \nwhere the current controls are not cost-effective); avoid (e.g. withdrawal from a business 21 \narea); reduce likelihood; reduce consequences (e.g. through emergency preparedness); and 22 \ntransfer (e.g. through insurance or outsourcing).  However, inherent in many risk 23 \nassessment methodologies is a decision making structure.  Consider one utility\u2019s catchment 24 \n 14\nto tap methodology.  Here, the assessment links hazard type (e.g. physical \u2013 turbidity and 1 \ncolour) to their causes (erosion) and to events (landslip, storm).  Clearly, by identifying the 2 \nunderlying mechanisms through which hazards are realised, rather than simply evaluating 3 \ntheir probabilities and consequences of occurrence, the identification of preventative 4 \nmeasures (e.g. stabilise gullies, isolate draw-off) is facilitated. 5 \nA further L3 characteristic is the establishment of objectives for risk based decisions.  6 \nHowever as one manager stated \u201cwith the exception of large projects, the majority of the 7 \ngoal-orientation will focus on cost and physical output\u201d, rather than risk reduction.  In 8 \ncontrast, one L3 utility adopted a goal setting regime for risk reduction at both the asset 9 \nand strategic level.  In the former, asset planners attached cost estimates and risk reduction 10 \ntargets to a range of potential capital, operating or maintenance strategies to address risks 11 \nacross their sites, which were then prioritised on the basis of risk reduction per pound 12 \nspent. 13 \nQuality assurance of decisions, whilst characteristic of L4, was observed to an extent 14 \nwithin each utility, ranging from the peer review format of cross-functional strategic risk 15 \nmanagement workshops to more formalised challenge processes.  For example, one 16 \nmanager noted that a central role of their \u201cexecutive leadership team\u201d \u2013 comprised of the 17 \npresident, vice presidents and union leader \u2013 and \u201cbusiness owners\u2019 council\u201d \u2013 comprised 18 \nof business unit representatives \u2013 was to provide input to and at times critique risk 19 \nmanagement decisions taken at the corporate and business unit levels respectively.  20 \n 21 \n3.5 RISK RESPONSE 22 \nRisk response is the implementation of risk based decisions.  Here, six of our sample 23 \nwere evaluated at L3 maturity, with one each at L2 and L4.  An L3 characteristic is the 24 \n 15\nsystematic allocation of responsibility, tasks, timescales, guidelines and resources for the 1 \nimplementation of risk based decisions; this was observed, e.g. within the development of 2 \n\u201caction plans.\u201d  Within the electricity utility, these include a description of the: risks to be 3 \nmitigated; business objectives threatened; required actions; risk champion; target date of 4 \ncompletion; residual risk rating; cost estimate; ease of implementation; and what could go 5 \nwrong.  Returning to a more operational context, we observed emergency management 6 \nplans detailing the procedures required to minimise the impacts of, for example, plant 7 \nfailure (check component connections, check for blockages, review raw water for turbidity, 8 \ntaste, odour and algae, etc.).  In practice, we observed that implementation processes were 9 \noften not unique to risk based decisions, i.e. there existed models for implementing capital 10 \nor operational solutions, not models for implementing risk based decisions per se.  Indeed, 11 \nthe electricity utility manager emphasised that his role as a risk manager was not to act as a 12 \n\u201ccentral policeman,\u201d and that implementation was a matter for individual business units 13 \nand functions.   14 \n 15 \n3.6 RISK MONITORING  16 \nThe sample contains one L2, five L3, and two L4 companies in risk monitoring.  The 17 \nL2 interviewee characterised risk monitoring as \u201cthe weaker part of our scheme; we don\u2019t 18 \ndo much beyond the quarterly reviews, the exception being some particularly critical 19 \nrisks\u201d.   20 \nOur sample indicates that risk monitoring may be partitioned into two tiers: the first 21 \ninvolving the re-evaluation of risk analyses outputs, the second relating to the tracking of 22 \ndiscrete parameters which describe the evolution of risks.  The former was observed to 23 \noccur by procedure at L3 and L4, through both cyclical requirements and event-driven 24 \n 16\ninitiators (e.g. changes to technical processes). The importance of such procedures was 1 \nemphasised by one manager\u2019s revelation that prior to their introduction of a central asset 2 \nrisk register with clear requirements for cyclical reviews of analysis outputs, risk analyses 3 \nwere not regularly updated, instead being performed for a specific purpose at decision 4 \nmaking points.  Good practice was further illustrated in one utility\u2019s adoption of reporting 5 \nprotocols for communicating the results of strategic risk re-evaluations; here: co-ordinators 6 \nreported on the evolution of significant exposures at monthly management meetings; 7 \nsignificantly increased risks were escalated to  unit directors within thirty six hours; and 8 \nthe risk management function reported to the Board on a monthly basis.  We further 9 \nobserved verification of procedural compliance, most commonly achieved through risk 10 \nregister oversight.   11 \nOne might argue that this first tier of risk monitoring is indistinct as a process from 12 \nrisk analysis, as the revision of previous risk assessments is an element of the feedback 13 \nloop within the latter process.  The distinct second tier was observed to be most prevalent 14 \nwithin drinking water quality management and network planning and operation.  In the 15 \nformer context, risk monitoring includes both the standard regulatory-driven tracking of 16 \nprimarily lagging water quality parameters (i.e. verification of water quality, e.g. coliform 17 \ntesting at customer taps), and, where the water safety plan approach is adopted, extends to 18 \ninclude leading indicators devised in accordance with the HACCP (Havelaar, 1994; Deere 19 \net al., 2001) model (i.e. operational parameters describing the effectiveness of control 20 \nmeasures designed to mitigate water quality hazards, e.g. ph residuals at and post 21 \ndisinfection).  It should be noted that HACCP has the inherent characteristics of L4 22 \nmaturity.  To illustrate, within one adopter we observed:  weekly reviews supported by in-23 \ndepth periodic audits to ensure compliance with the established monitoring protocol (i.e. 24 \n 17\nverification: ranging from requirements to review online turbidity data to the calibration of 1 \nanalysis and measurement equipment); formal peer reviews of established operational 2 \nparameters and their target and action limits (i.e. validation: exploring, for example, the 3 \nrationale behind setting 2000 cells\/mL of cyanobacteria as an action limit for controlling 4 \ntaste and odour related hazards); and annual reviews of the protocol taking account of 5 \nmodifications to processes, industry standards, regulatory guidelines and operating licenses 6 \n(i.e. feedback mechanisms). 7 \n 8 \n3.7 INTEGRATING RISK MANAGEMENT 9 \nHere, seven of our sample were evaluated at L3, with one at L4 maturity.  Our 10 \ndiscussion is restricted to one facet of integration: institutionalisation.  Our model views 11 \ninstitutionalisation as dependant on risk management \u201cenablers\u201d and \u201cevaluators.\u201d  12 \nEnablers include the provision of guidelines, procedures, systems, tools and training for the 13 \ndiscipline (L3), whilst evaluators include verification, validation and feedback mechanisms 14 \n(L4).  We have explored these within the context of each individual process, here, we seek 15 \nto evaluate whether this is a sufficient explanation. 16 \nIndeed, the influence of culture on institutionalisation, an aspect not explicitly 17 \nrepresented within our model, was highlighted by several participants.  One noted how 18 \nstaff perceptions ranged from \u201cthose going through the motions, to those more cognisant of 19 \nhow [risk management] supports the broader organisational processes.\u201d  The participant 20 \nfurther noted the importance of engaging and empowering operational staff in creating a 21 \nrisk management culture.  Here, this took the form of expert practitioners supporting front-22 \nline staff to fulfil their risk management obligations (e.g. jointly conducted risk 23 \nassessments) and actively seeking and considering their feedback in revising existing 24 \n 18\nprocesses (e.g. adapting risk evaluation criteria to reflect operational expertise).  We 1 \nfurther observed that a prerequisite for cultural change is commitment from executive and 2 \nsenior management, which is often dependent on external events.  One manager noted that 3 \n\u201c[the risk management team] have finally got the attention of our organisation; early on we 4 \ncouldn\u2019t get much dignity\u2026then a series of events occurred in the [United States] which 5 \nmade risk assessment more important, which resulted notably in the Sarbanes Oxley 6 \nlegislation, we have several members of our board who are very much attuned to 7 \nthat\u2026once we got top level buy in, the rest followed.\u201d  Similarly, one participant reflected 8 \nthat \u201cEnron, Barings\u2026showed that companies can go under if their controls fail, [whilst] 9 \nRailtrack showed that companies could lose their [license to operate].  [Another] wake up 10 \ncall was the idea of corporate manslaughter; [this] made us focus our efforts on\u2026assets 11 \nwith low likelihood of failure but high consequence, for example critical reservoirs.\u201d   12 \n   13 \n3.8 SUPPLY CHAIN RISK MANAGEMENT 14 \nThis process addresses both the way utilities obtain the raw components required to 15 \ndevelop products and the management of services provided by organisations throughout 16 \nthe supply chain (e.g. outsourcing agreements).  Here, we observed two L2, two L3, and 17 \nfour L4 utilities.  One L2 manager revealed that supply chain risk management was 18 \nprimarily \u201cleft to procurement,\u201d with formalised approaches to risk management tending to 19 \napply only to larger, discrete projects.  Similarly, one L3 interviewee stated that risk 20 \nmanagement was only explicitly involved in supply chain management in relation to 21 \nproducts and services critical to their continued operation, further noting that \u201calthough 22 \n[we] evaluate, qualify and support [our] critical vendors and suppliers, this is not within the 23 \ncontext of a formal risk based process.\u201d  In contrast, within one L3 utility risk management 24 \n 19\nwas explicitly interwoven within procurement policies and procedures.  Inspection of their 1 \ncontracting and tendering policy revealed that in contrast to the traditional approach of 2 \nselecting lowest cost suppliers once basic standards are met, a broad range of pre-3 \nqualification standards are applied as appropriate, including those that address risk 4 \nexplicitly (e.g. occupational health and safety, commercial risk, delivery risk) and 5 \nimplicitly (e.g. quality management accreditation).  Furthermore, prior to binding 6 \nacceptance, the probability of failure of the chosen tender to satisfactorily adhere to the 7 \ncontract, and the potential effects of such a failure, were formally assessed and reported.   8 \nWe obtained limited data on the practices of those L4 utilities, however, we observed 9 \nthat one required all contractors to utilise a formal risk management framework, whilst 10 \nanother adopted criteria to ensure that the \u201crisk attitude\u201d of capital partners aligned with 11 \ntheir own.   12 \n 13 \n3.9 CHANGE RISK MANAGEMENT 14 \nThis process is concerned with identifying and managing the risk implications of 15 \norganisational (e.g. re-engineering) and technical change.  Here, we evaluated one utility at 16 \nL2, and three each at L3 and L4.  We observed the expected lack of process definition 17 \nwithin the L2 utility, whose respondent noted that where changes to e.g. operating or asset 18 \nstandards are considered, \u201crisk would be part of the decision making process, although the 19 \nlevel of formality would vary\u201d.  Regarding organisational change, the interviewee stated 20 \nthat \u201cwhilst the utility has a team dedicated to providing support and education for the 21 \nimplementation of business process improvements, it does not focus on the risk 22 \nimplications of change.\u201d  At L3 and L4, we observed the undertaking of risk analysis to 23 \nevaluate the expediency of planned technical changes; the use of SWOT analysis to 24 \n 20\nevaluate the \u201cbusiness environment\u201d for changes that may constrain utility operations and 1 \nmanagement; application of environmental impact assessments for projects that modify 2 \nexisting processes or introduce new processes, activities or equipment; and regular 3 \nanalyses and reviews of risks and interdependencies within organisational change 4 \nprogrammes.   5 \n 6 \n3.10 EDUCATION AND TRAINING IN RISK MANAGEMENT 7 \nHere, we observed one L1 organisation, two at L2, and five at L3.  An ad hoc 8 \napproach was observed within the L1 utility, with no formal process in place to develop or 9 \nmaintain risk management skills and knowledge, and limited cognisance of the required 10 \ncompetencies for effective undertaking of the discipline.  As the L1 manager noted \u201cwe 11 \nrecognise we have an issue here\u2026we took over one hundred people through risk training 12 \nin 2000\/01, [but we\u2019ve] done nothing since\u2026the next logical step was to cascade it across 13 \nbusiness\u2026which we haven\u2019t.\u201d  Emphasising the importance of this deficiency, he noted 14 \n\u201cwe recognise some people have no knowledge of the [risk management] process, yet are 15 \nexpected to prioritise capital investment on the back of it; [but the] only hint of training is 16 \nwhen they get shot down at [the consistency checks].\u201d   17 \n  The defining characteristic of the L2 organisations was their limited process scope, 18 \nwith limited internal training in risk management (e.g. addressing occupational health and 19 \nsafety), supported by attendance of externally delivered courses for key managerial and 20 \noperating staff (e.g. risk management conferences, HACCP training for operating staff).  21 \nFor example, one L2 utility\u2019s site induction procedures sought to ensure that staff 22 \nunderstood site-specific hazards and the precautions required to protect their safety and the 23 \nquality of service.  These covered basic issues such as the isolation and lock out procedures 24 \n 21\nrequired for machinery during maintenance works, site emergency procedures, confined 1 \nspace entry procedures, and the location of the first aid kit.  This was supplemented by 2 \nvideo-based training on: risk management planning for drinking water supplies; job safety 3 \nanalysis; and safety leadership.  Indeed, this emphasis on \u201con the job\u201d training was a 4 \ncommon theme at L2, the logic perhaps being that staff learn best through real life, hands 5 \non examples, rather than lectures and presentations.  As the electricity utility interviewee 6 \nnoted, \u201cmost of the education and indoctrination was [achieved] by running [risk 7 \nmanagement] workshops.  At one time my staff were running forty to fifty workshops a 8 \nyear, so all the executives and managers were constantly exposed to this whole 9 \nmethodology of identifying, prioritising and mitigating risk; [towards the end], they\u2019d 10 \ncome and borrow our anonymous voting equipment and run their own workshops.\u201d   11 \nValuable insights regarding the formalisation of education and training may be 12 \ngleaned from one L3 utility.  Here, two dedicated risk management training packages were 13 \nobserved: an introductory course provided to key strategic members of the business, and a 14 \nmore comprehensive programme delivered to \u201cteam leaders\u201d.  Of greatest interest is the 15 \nlatter, which was structured around a formal definition of the competencies required for 16 \neffective risk management, ranging from an understanding of corporate governance to a 17 \ngrasp of the technical aspects of the risk assessment techniques adopted.  Both packages 18 \nwere initiated by procedure, with oversight from local management and the risk 19 \nmanagement team to verify compliance.  Furthermore, effective delivery of the process 20 \nwas verified through cyclical evaluations of the ability of staff to act on the training 21 \nreceived.  These evaluations partly underpinned succession routes, providing a strong 22 \ncatalyst for learning.  Supplementing these programmes, ad hoc training workshops were 23 \nprovided by risk management staff on request. 24 \n 22\nIn a more operational context, one L3 manager described how in addition to 1 \nexternally delivered HACCP training for key staff, internal training on the fundamentals of 2 \ndrinking water quality management focussed specifically on embedding the risk-based 3 \napproach inherent in their operating and management principles.  Furthermore, their post-4 \nincident analyses included an explicit evaluation of the a priori risk management strategy, 5 \nwhich the interviewee emphasised breeds familiarity with the methodologies and processes 6 \nof risk management and, by focussing on real examples (or plausible scenarios), 7 \nhighlighted the practical implications of the discipline to front-line staff. 8 \n 9 \n3.11 RISK KNOWLEDGE MANAGEMENT 10 \nHere, we observed three utilities at L2, and five at L3.  Risk knowledge management 11 \nmay be considered as the collection, storage and access of the data underpinning and 12 \naccumulated from the broader risk management processes, i.e. the input and output data.  13 \nOne L2 manager stated that input data requirements for risk management were not well 14 \ndefined, and noted that they \u201cdo not maintain detailed risk information beyond that which 15 \nis accumulated during risk assessments or that inherent in the normal conduct of business\u201d.  16 \nThe interviewee assigned this to both a \u201cresource driven inadequacy\u201d and inadvertent 17 \nconstraints imposed by legislation: \u201cin the public sector\u2026we\u2019re subject to open records 18 \nrequest\u2026you don\u2019t want [your risk analyses appearing] in the newspaper the next day, 19 \nhow we store those documents and record our decisions is a strategy in itself, we try to 20 \nlimit circulation, which may be counter-productive to traditional risk management\u201d. 21 \nAt L3, we observed procedures governing the use of software packages which serve 22 \nas tools for the collection, storage and access of output data collected throughout the life-23 \ncycle of risk management.  However, pre-defined strategies of input data collection were 24 \n 23\nrestricted to select operational risks, particularly those whose management was 1 \nunderpinned by formal analytical methodologies (e.g. reliability modelling), or, as one 2 \nmanager noted, subject to regulatory drivers (e.g. asset management, drinking water 3 \nquality management).  The electricity utility interviewee suggested that this is dictated by 4 \npragmatism, as \u201craw data requirements are fluid and evolve with the perceptions of 5 \nmanagement.\u201d  However, we contend that in the absence of predefined requirements, risk 6 \ndata collection is likely to be ad hoc, and largely restricted to the requirements of \u201cbusiness 7 \nas usual.\u201d  Indeed, one manager described a reliance on \u201cexpert judgement; without senior 8 \nexperienced people, I\u2019m not sure we have the data to underpin [risk management]\u201d.  A 9 \nfurther observed L3 characteristic was the lack of expertise for validation (i.e. to ensure 10 \nthat the correct data is being collected); to the extent that it is applied, it is informal and ex-11 \npost.   12 \n 13 \n4. Conclusions 14 \n We have described the application of a capability maturity model to benchmark risk 15 \nmanagement within eight water utilities.  The findings provide utility managers, technical 16 \nstaff, chief finance officers and regulatory officials with a systematic understanding of how 17 \nto implement and improve risk management.  This is timely work for a sector grappling to 18 \nadapt to evolving regulatory and governance arrangements.  Furthermore, the research 19 \nprovides a basis for evolving the model from a prescriptive to a descriptive state, which 20 \nwill ultimately render it fit for industrial ownership.      21 \n   22 \n 24\nAcknowledgements 1 \nThis work has been funded by the American Water Works Association Research 2 \nFoundation (AwwaRF project RFP2939) and a consortium of international water utility 3 \ncompanies.  The comments and views herein are the authors\u2019 alone.  BM is co-funded on a 4 \nUK Engineering and Physical Sciences Research Council (EPSRC) Doctoral training 5 \naccount. 6 \n 7 \nReferences 8 \nBooth, R. and Rogers, J. (2001) Using GIS technology to manage infrastructure capital 9 \nassets, J. AWWA, 93(11), 62-68. 10 \nCOSO (2004) Enterprise risk management framework - Executive Summary.  Available at 11 \nwww.otpp.com. 12 \nCouncil of Standards of Australia (1999) Australian\/New Zealand risk management 13 \nstandard No.4360: 1999. 14 \nDalkey, M. and Helmer, O. (1963) An experimental application of the Delphi method to 15 \nthe use of experts, Management Science, 9(3), 458-467. 16 \nDeere, D., Stevens, M., Davison, A., Helm, G. and Dufour A. (2001) Management 17 \nstrategies, Water quality: guidelines, standards and health, Edited by Fewtrell, L. and 18 \nBartram, J., WHO, IWA Publishing, London, 257-288. 19 \nHamilton, P.D., Pollard, S.J.T., Hrudey, S.E. and MacGillivray, B.H (2006) Risk 20 \nmanagement frameworks for the water sector \u2013 a review, at review. 21 \n 25\nHavelaar, A.H. (1994) Application of HACCP to drinking water supply.  Food Control, 5 1 \n(3) 145-152. 2 \nIMPRESS Management (2002) Guidance for the analysis of pressures and impacts in 3 \naccordance with the water framework directive, Draft 5.2, European Commission, 4 \nBrussels. 5 \nLifton, G. and Smeaton, P. (2003) Asset risk management in Scottish Water, Proc. of the 6 \nICE\/CIWEM Conference: Risk and reward in asset management delivery \u2013 who is best 7 \nprepared for the challenges ahead?, 14th November, 2003, London, UK. 8 \nLloyd, R. and Abell, P. (2005) Capital maintenance in Yorkshire Water\u2019s water business 9 \nunit, Proc. of Risk analysis strategies for better and more credible decision making, 6-10 \n8th April, 2005, Banff, Canada. 11 \nMacGillivray, B.H., Strutt, J.E., Sharp, J.V., Hamilton, P.D. and Pollard, S.J.T. (2006a) 12 \nBenchmarking risk management within the water utility sector. Part I: Design of a 13 \ncapability maturity methodology, J. Risk Research, at review. 14 \nMacGillivray, B.H, Hamilton, P.D., Strutt, J.E., Pollard, S.J.T. (2006b) Risk analysis 15 \nstrategies in the water utility sector: an inventory of applications for better and more 16 \ncredible decision-making, Critical Reviews in Environmental Science and Technology, 17 \n36, 85-139. 18 \nPaulk, M.C., Curtis, B., Chrissis, M.B. and Weber, C.V. (1993) Capability maturity model, 19 \nversion 1.1, IEEE Software 10(4), 18-27. 20 \n 26\nPollard, S.J.T., Strutt, J.E., MacGillivray, B.H., Hamilton, P.D. and Hrudey, S.E. (2004) 1 \nRisk analysis and management in the water utility sector \u2013 a review of drivers, tools and 2 \ntechniques, Trans. IChemE, Part B: Proc. Safety Environ. 82(B6): 1-10. 3 \nPollard, S.J.T., Strutt, J.E., MacGillivray, B.H., Hamilton, P.D. and Hrudey, S.E. (2004) 4 \nRisk analysis and management in the water utility sector \u2013 a review of drivers, tools and 5 \ntechniques, Trans. IChemE, Part B: Proc. Safety Environ. 82(B6): 1-10. 6 \nSarshar, M., Haigh, R., Finnemore, M., Aouad, G., Barrett, P., Baldry, D. and Sexton, M. 7 \n(2000) SPICE: a business process diagnostics tool for construction projects, 8 \nEngineering, Construction and Architectural Management, 7(3), 241-250.  9 \nSharp, J.V., Strutt, J.E., Busby, J. and Terry, E. (2002) Measurement of organizational 10 \nmaturity in designing safe offshore installations, Proceedings of the International 11 \nConference on Offshore Mechanics and Arctic Engineering, 2: 383-390. 12 \nSoftware Engineering Institute (2002a) CMMI for systems engineering \/ software 13 \nengineering \/ integrated product development \/ supplier sourcing, version 1.1.  14 \nAvailable at http:\/\/www.sei.cmu.edu\/ 15 \nSoftware Engineering Institute (2002b) People capability maturity model, version 2.0. 16 \nAvailable at http:\/\/www.sei.cmu.edu\/ 17 \nStahl, G.R. and Elliott, J.C. (1999) \u2018New generation\u2019 computer models for risk-based 18 \nplanning and management, Water Supply (Australia), 17(3\/4), 289-295. 19 \nStevens, I.M. and Lloyd, R.I. (2004) Water resources: Sustainable optimisation and 20 \nsecurity of supply, a proven example, Paper presented to the 2004 Water Sources 21 \nConference and Exposition, Jan 11-14th, 2004, Austin, Texas. 22 \n 27\nStrutt, J.E. (2003) Reliability capability maturity briefing document, Report No. R-03\/2\/1, 1 \nCranfield University. 2 \nStrutt, J.E., MacGillivray, B.H., Sharp, J.V., Pollard, S.J.T. and Hamilton, P.D. (2005) 3 \nMeasuring risk management capabilities, Proc. of Risk analysis strategies for better and 4 \nmore credible decision making, 6-8th April, 2005, Banff, Canada. 5 \n 28 \nTable 1. Generalised representation of the process maturity hierarchy. 1 \n 2 \nMaturity level Process Characteristics \nLevel 5 \u2013 Optimising \n \nThe process is a continual, explicit component of organisational activities, forming part of the \u2018culture\u2019.  Feedback is actively used to \nimprove both the philosophy and execution of the process, and the adaptation of organisational structures and practices to optimise its \nability to undertake the process (double loop learning).  Management continually establishes measurable targets for process \nimprovement, with systems in place to verify their achievement and to validate the means through which they are pursued.  Active \ninnovation, development and piloting of new ideas and technologies to optimise the process.   \nLevel 4 \u2013 Controlled \n \n \nVerification mechanisms extend to provide quality assurance, and are supplemented by the capacity for process validation.  Feedback is \nactively used to improve process execution, albeit within the constraints of existing process strategies (single loop learning).  Broadly \nspread competencies enable the process to reside within affected disciplines, although stakeholders work together to achieve an \nintegrated approach, capitalising on synergies and collective knowledge.  Sufficient resources are available, with limited internal R&D. \nLevel 3 \u2013 Defined  \n \nProcess scope exceeds regulatory requirements, extending across core business areas.  Documentation details procedures, criteria, \nmethods and guidelines for process undertaking, whilst basic audit mechanisms verify compliance.  Feedback limitations restrict process \nevolution to learning from \u2018events\u2019 (open loop learning).  Processes reside within the responsible unit, with limited cross-functional or \nexternal consultation.  Adequate resources in place.  \nLevel2 \u2013  Repeatable \n \nBasic process in place, focused on meeting regulatory requirements and addressing \u2018mission-critical\u2019 risks.  Initiated reactively, often in \nresponse to an event or situation.  Limited capacity to evolve based on experience. \nLevel 1 \u2013 Initial \n \nNo formal process; ad-hoc approach.  Reliance on individual heroics.  Limited awareness of regulatory requirements or relevant \nstandards. \n 29\n 1 \nDescriptor Respondent* Unit of study Scope of analysis \nUtility A Corporate risk manager Corporate Water supply, sewerage services \nand electricity distribution \nUtility B  Water quality manager Corporate Water supply and sewerage \nservices \nUtility C  Water quality manager Corporate Water supply and sewerage \nservices \nUtility D  Corporate risk manager Corporate Water supply \nUtility E  Asset manager Corporate Water supply and sewerage \nservices \nUtility F  Corporate risk manager Corporate Water supply and sewerage \nservices \nUtility G  Asset manager Business unit Water supply \nUtility H  Water quality manager Function Drinking water quality \nmanagement \nUtility I** Corporate risk manager Corporate Electricity transmission and \ndistribution \n* Respondent denotes the interviewee; in most cases, the questionnaire was undertaken in consultation with 2 \nother staff.  ** Data limitations prevented the maturity evaluation of Utility I. 3 \nTable 2. Sample characteristics. 4 \n 5 \n 6 \n 7 \n 8 \n 9 \n 10 \n 11 \n 12 \n 13 \n 14 \n 15 \n 30\n1 \n 2 \n 3 \n 4 \n 5 \nFig. 1. Overview of the RM-CMM (after Strutt et al., 2005). 6 \n 7 \n Processes \nStrategic risk planning (SRP) \nEstablishing risk acceptance criteria (ERAC) \nRisk analysis (RA) \nRisk based decision making and review (RBDM) \nRisk response (RR) \nRisk monitoring (RM) \nCore \nIntegrating risk management (IRM) \nSupply chain risk management (SCRM) Supporting \nChange risk management (CRM) \nEducation and training in risk management (E&T) Long-term \nRisk knowledge management (RKM) \nAttributes \nScope \nIntegration \nVerification and validation \nFeedback and organisational learning \nStakeholder engagement \nCompetence \nResources \nDocumentation and reporting \n1\n2\n          3 \n4\n5\nAd hoc\nOptimising \nMaturity \n 31\n 1 \n 2 \n 3 \n 4 \n 5 \n 6 \n 7 \n 8 \nFig. 2. Boxplot of the sample risk management process maturity by self-assessment. 9 \n1\n2\n3\n4\n5\nSRP ERAC RA RBDM RR RM IRM SCRM CRM E&T RKM\nProcess\nP\nro\nce\nss\n M\nat\nur\nity\nq1\nmin\nmedian\nmax\nq3\n 32 \nUtility A\n1\n2\n3\n4\n5\nSRP\nERAC\nRA\nRBDM\nRR\nRMIRM\nSCRM\nCRM\nE&T\nRKM\nUtility B\n1\n2\n3\n4\n5\nSRP\nERAC\nRA\nRBDM\nRR\nRMIRM\nSCRM\nCRM\nE&T\nRKM\nUtility C\n1\n2\n3\n4\n5\nSRP\nERAC\nRA\nRBDM\nRR\nRMIRM\nSCRM\nCRM\nE&T\nRKM\nUtility D\n1\n2\n3\n4\n5\nSRP\nERAC\nRA\nRBDM\nRR\nRMIRM\nSCRM\nCRM\nE&T\nRKM\nUtility E\n1\n2\n3\n4\n5\nSRP\nERAC\nRA\nRBDM\nRR\nRMIRM\nSCRM\nCRM\nE&T\nRKM\nUtility F\n1\n2\n3\n4\n5\nSRP\nERAC\nRA\nRBDM\nRR\nRMIRM\nSCRM\nCRM\nE&T\nRKM\nUtility G\n1\n2\n3\n4\n5\nSRP\nERAC\nRA\nRBDM\nRR\nRMIRM\nSCRM\nCRM\nE&T\nRKM\nUtility H\n1\n2\n3\n4\n5\nSRP\nERAC\nRA\nRBDM\nRR\nRMIRM\nSCRM\nCRM\nE&T\nRKM\n 2 \n 4 \n 6 \n 8 \n 10 \n 12 \n 14 \n 16 \n 18 \n 20 \n* Red indicates uncertainty arising from incomplete questionnaire data. 22 \nFig. 3. Spider diagrams of organisational maturity by self-assessment.   23 \n"}
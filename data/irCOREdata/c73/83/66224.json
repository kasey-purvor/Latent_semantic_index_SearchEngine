{"doi":"10.1016\/j.cognition.2006.05.005","coreId":"66224","oai":"oai:dro.dur.ac.uk.OAI2:2422","identifiers":["oai:dro.dur.ac.uk.OAI2:2422","10.1016\/j.cognition.2006.05.005"],"title":"Evidence for distinct contributions of form and motion information to the recognition of emotions from body gestures.","authors":["Atkinson,  A. P.","Tunstall,  M. L.","Dittrich,  W. H."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-07-01","abstract":"The importance of kinematics in emotion perception from body movement has been widely demonstrated. Evidence also suggests that the perception of biological motion relies to some extent on information about spatial and spatiotemporal form, yet the contribution of such form-related cues to emotion perception remains unclear. This study reports, for the first time, the relative effects on emotion recognition of inverting and motion-reversing patch-light compared to fully illuminated displays of whole body emotion gestures. Inverting the gesture movies or playing them backwards significantly impaired emotion classification accuracy, but did so more for patch-light displays than for identical but fully illuminated movement sequences. This result suggests that inversion impairs the processing of form information related to the configuration of body parts, and reversal impairs the sequencing of form changes, more than these manipulations impair the processing of kinematic cues. This effect was strongest for inversion, suggesting an important role for configural information in emotion recognition. Nevertheless, even in combination these stimulus manipulations did not abolish above chance recognition of any of the emotions, suggesting that kinematics help distinguish emotions expressed by body gestures. Disproportionate impairments in recognition accuracy were observed for fear and disgust under inversion, and for fear under motion reversal, suggesting a greater role for form-related cues in the perception of these emotions","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/66224.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/2422\/1\/2422.pdf","pdfHashValue":"f1c031b12f3c519182a861645923b0a9bed28fc1","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:2422<\/identifier><datestamp>\n      2017-03-10T11:56:32Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Evidence for distinct contributions of form and motion information to the recognition of emotions from body gestures.<\/dc:title><dc:creator>\n        Atkinson,  A. P.<\/dc:creator><dc:creator>\n        Tunstall,  M. L.<\/dc:creator><dc:creator>\n        Dittrich,  W. H.<\/dc:creator><dc:description>\n        The importance of kinematics in emotion perception from body movement has been widely demonstrated. Evidence also suggests that the perception of biological motion relies to some extent on information about spatial and spatiotemporal form, yet the contribution of such form-related cues to emotion perception remains unclear. This study reports, for the first time, the relative effects on emotion recognition of inverting and motion-reversing patch-light compared to fully illuminated displays of whole body emotion gestures. Inverting the gesture movies or playing them backwards significantly impaired emotion classification accuracy, but did so more for patch-light displays than for identical but fully illuminated movement sequences. This result suggests that inversion impairs the processing of form information related to the configuration of body parts, and reversal impairs the sequencing of form changes, more than these manipulations impair the processing of kinematic cues. This effect was strongest for inversion, suggesting an important role for configural information in emotion recognition. Nevertheless, even in combination these stimulus manipulations did not abolish above chance recognition of any of the emotions, suggesting that kinematics help distinguish emotions expressed by body gestures. Disproportionate impairments in recognition accuracy were observed for fear and disgust under inversion, and for fear under motion reversal, suggesting a greater role for form-related cues in the perception of these emotions.<\/dc:description><dc:subject>\n        Emotion recognition<\/dc:subject><dc:subject>\n         Biological motion<\/dc:subject><dc:subject>\n         Body movement<\/dc:subject><dc:subject>\n         Body gestures<\/dc:subject><dc:subject>\n         Configural cues.<\/dc:subject><dc:publisher>\n        Elsevier<\/dc:publisher><dc:source>\n        Cognition, 2007, Vol.104(1), pp.59-72 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2007-07-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:2422<\/dc:identifier><dc:identifier>\n        issn:0010-0277<\/dc:identifier><dc:identifier>\n        doi:10.1016\/j.cognition.2006.05.005<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/2422\/<\/dc:identifier><dc:identifier>\n        https:\/\/doi.org\/10.1016\/j.cognition.2006.05.005<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/2422\/1\/2422.pdf<\/dc:identifier><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["0010-0277","issn:0010-0277"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2007,"topics":["Emotion recognition","Biological motion","Body movement","Body gestures","Configural cues."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n26 February 2009\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nAtkinson, A. P. and Tunstall, M. L. and Dittrich, W. H. (2007) \u2019Evidence for distinct contributions of form\nand motion information to the recognition of emotions from body gestures.\u2019, Cognition., 104 (1). pp. 59-72.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1016\/j.cognition.2006.05.005\nPublisher\u2019s copyright statement:\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n Use policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without \nprior permission or charge, for personal research or study, educational, or not-for-profit purposes \nprovided that : \n \n\u0083 a full bibliographic reference is made to the original source \n\u0083 a link is made to the metadata record in DRO \n\u0083 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright \nholders.  \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nDurham Research Online \n Deposited in DRO:\n26 February 2009\nVersion of attached file:\nAccepted\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nAtkinson, A. P. and Tunstall, M. L. and Dittrich, W. H. (2007) 'Evidence for distinct contributions of form and\nmotion information to the recognition of emotions from body gestures.', Cognition., 104 (1), pp.\u000059-72.\nFurther information on publishers website:\nhttp:\/\/dx.doi.org\/10.1016\/j.cognition.2006.05.005\nForm and motion in emotion recognition 1 \nRunning head: FORM AND MOTION IN EMOTION RECOGNITION \n \nEvidence for distinct contributions of form and motion information to the \nrecognition of emotions from body gestures \n \nAnthony P. Atkinson\u00b6 \nMary L. Tunstall\u00b6 \nWinand H. Dittrich\u2020 \n \n\u00b6 Department of Psychology, Durham University, UK \n\u2020 School of Psychology, University of Hertfordshire, UK \n \n \nAddress correspondence to: \nAnthony P. Atkinson \nDepartment of Psychology, Durham University \nScience Laboratories, South Road \nDurham, DH1 3LE, U.K. \nTel. +44 - (0)191 - 3343234 \nEmail: a.p.atkinson@durham.ac.uk \n \nWord count: 4,291 \n \nForm and motion in emotion recognition 2 \nAbstract \nThe importance of kinematics in emotion perception from body movement has been \nwidely demonstrated. Evidence also suggests that the perception of biological motion \nrelies to some extent on information about spatial and spatiotemporal form, yet the \ncontribution of such form-related cues to emotion perception remains unclear. This \nstudy reports, for the first time, the relative effects on emotion recognition of \ninverting and motion-reversing patch-light compared to fully illuminated displays of \nwhole body emotion gestures. Inverting the gesture movies or playing them \nbackwards significantly impaired emotion classification accuracy, but did so more for \npatch-light displays than for identical but fully illuminated movement sequences. This \nresult suggests that inversion impairs the processing of form information related to the \nconfiguration of body parts, and reversal impairs the sequencing of form changes, \nmore than these manipulations impair the processing of kinematic cues. This effect \nwas strongest for inversion, suggesting an important role for configural information in \nemotion recognition. Nevertheless, even in combination these stimulus manipulations \ndid not abolish above chance recognition of any of the emotions, suggesting that \nkinematics help distinguish emotions expressed by body gestures. Disproportionate \nimpairments in recognition accuracy were observed for fear and disgust under \ninversion, and for fear under motion reversal, suggesting a greater role for form-\nrelated cues in the perception of these emotions. \n \nKeywords: Emotion recognition, biological motion, body movement, body gestures, \nconfigural cues. \nForm and motion in emotion recognition 3 \nEvidence for distinct contributions of form and motion information to the \nrecognition of emotions from body gestures \n Recognition of another\u2019s emotional expression likely involves processes that \nlink the perceptual properties of the stimulus to various knowledge structures, such as \nthe specific emotion concept, the lexical label for that emotion, and the perception of \nthe emotional response (or a central representation thereof) that the stimulus triggers \nin the observer (see Atkinson & Adolphs, 2005). Research on emotion recognition has \nbeen dominated by studies using photographs of facial expressions, yet movement of \nthe body or its parts is also revealing of other people\u2019s emotions. Using standard \nrecognition tasks, such as those requiring forced choices from a list of emotion labels \nor judgments of emotional intensity, several studies have demonstrated that, even in \nthe absence of facial and vocal cues, humans are adept at identifying basic emotions1 \nsignaled by static body postures (e.g., Atkinson, Dittrich, Gemmell, & Young, 2004; \nCoulson, 2004), arm movement (Pollick, Paterson, Bruderlin, & Sanford, 2001), and \nwhole body movement (e.g., Atkinson et al., 2004; de Meijer, 1989; Dittrich, \nTroscianko, Lea, & Morgan, 1996). On what visual information is this ability based? \nThree main classes of information relevant to the perception of body gestures \nand actions are: structural or form information and its changes over time (including \nmotion-mediated structural information), kinematics (e.g., velocity, acceleration, \ndisplacement) and dynamics (motion specified in terms of mass and force). \nConsiderable attention has been given to the role of kinematics in specifying cues for \naction and person perception. Typically, these studies employ point-light or patch-\nlight displays of human or other biological motion, in which static form information is \nminimal or absent but motion information (kinematics and dynamics) and motion-\nmediated structural information are preserved (Johansson, 1973). Point-light displays \nForm and motion in emotion recognition 4 \nof body movements provide a sufficient basis for observers to discriminate biological \nmotion from other types of motion, and to make accurate judgments about the people \nmaking the movements, including sex from gait (e.g., Barclay, Cutting, & Kozlowski, \n1978), identity from gait (Richardson & Johnston, 2005) or actions (Loula, Prasad, \nHarber, & Shiffrar, 2005), the weight of boxes from the lifting movement (Runeson & \nFrykholm, 1981), and complex individual or social actions (Dittrich, 1993). Some of \nthis evidence shows equivalent or near equivalent performance with point-light \ncompared to full-light (or solid-body) displays, in which the whole body or face is \nvisible (e.g., Hill, Jinno, & Johnston, 2003; Runeson & Frykholm, 1981), which \nsuggests that static form cues are rather less important than motion cues and may \noften be unnecessary for successful judgments about people and their actions based \non their visible behavior. Evidence for the relative importance of kinematic cues \ncomes from studies that measure the effects on recognition of changes in certain \nkinematic or structural dimensions of point-light stimuli. For example, accuracy in \njudging the sex of point-light walkers was influenced more by \u201cbody sway\u201d than by \nthe ratio of shoulder to hip width, in Mather and Murdoch\u2019s (1994) study, and was \ngreater when point-light walkers were normalized with respect to their size (thus \nproviding only motion information) than when they were normalized with respect to \ntheir motion information (thus providing only size cues), in Troje\u2019s (2002) study. \nIt has been argued that the ability to discriminate at least simple biological \nmovements in point-light displays may be based on relatively low-level or mid-level \nvisual processing that does not involve the reconstruction of the form of body parts or \nof the whole body, either from static form or motion-mediated structural cues (e.g., \nCasile & Giese, 2005; Mather, Radford, & West, 1992). Nevertheless, \nneuropsychological and neurophysiological evidence demonstrates that form \nForm and motion in emotion recognition 5 \ninformation can indeed subserve biological motion perception from point-light \ndisplays (e.g., Hirai & Hiraki, 2006; McLeod, Dittrich, Driver, Perrett, & Zihl, 1996; \nPeelen, Wiggett, & Downing, 2006; Vaina, Cowey, LeMay, Bienfang, & Kikinis, \n2002). The processing of changes in the form of the body over time may be \nparticularly important (e.g., Beintema & Lappe, 2002), especially in the context of \nmore sophisticated tasks, such as recognizing emotional states or complex actions \n(Casile & Giese, 2005; Giese & Poggio, 2003). \nThere is compelling evidence that the kinematics of body and body-part \nmovements are at least sufficient, and may often be important, in furnishing cues for \nthe perception of emotional expressions. For example, using point-light knocking and \ndrinking arm movements as stimuli, Pollick et al. (2001) found that judgments of \nanger and happiness were more likely when the movements were fast and jerky, and \nthat judgments of sadness were more closely associated with slow and smooth \nmovements. And Sawada, Suda, and Ishii (2003) reported that arm movements made \nwith the intention of expressing joy, sadness, or anger varied in their velocity, \nacceleration, and displacement, and that differences in these factors predicted the \nability of observers to distinguish between the three types of emotional expression. \nNonetheless, there is also evidence that form-related cues in moving bodies and faces, \nin addition to kinematics, contribute to emotion perception. Bassili (1978) reported \ngreater emotion classification accuracy for full-light compared to point-light facial \nmovements, except for happy expressions. Dittrich (1991) found equivalent emotion \nrecognition performance for point-light face stimuli in which the dots demarcated key \nfacial structures (e.g., eyes, mouth) and those in which the dots were positioned \nrandomly on the face. This result contrasts with Hill et al.\u2019s (2003) finding that sex \njudgments from facial movements were more accurate with spatially normalized than \nForm and motion in emotion recognition 6 \npseudo-random dot placement, and thus highlights the relationship between form and \nmotion information in specifying cues for emotion perception. In previous work, we \nreported a reduction in emotion recognition performance with point-light (Dittrich et \nal., 1996) and patch-light (Atkinson et al., 2004) displays of body gestures compared \nto full-light gestures. An important methodological advance introduced in the latter \nstudy was that our full-light and patch-light displays were made from identical \nrecordings, in contrast to previous studies, in which these two conditions were filmed \nseparately (e.g., Dittrich et al., 1996). Therefore, an argument that differences in task \nperformance between the two conditions could be due to differences between emotion \nportrayals in each filming session, rather than to differences in the amount of static \nform information in each stimulus type, can be ruled out. In the present study, we \ncapitalize on this methodological improvement to assess the relative contribution of \nform-related cues to emotion recognition. To this end, we combined the full-light \nversus patch-light manipulation with two other stimulus transformations that would \nimpair the processing of form-related cues whilst preserving the processing of \nkinematic cues, viz., stimulus inversion and reversal of the direction of motion. \nThe disproportionate disruption to the perception of faces compared to other \nobjects engendered by stimulus inversion (reviewed in Peterson & Rhodes, 2003) is \nalso evident in the perception of body postures (Reed, Stone, Bozova, & Tanaka, \n2003; Reed, Stone, Grubb, & McGoldrick, 2006; Stekelenburg & de Gelder, 2004) \nand movement. The spontaneous identification of point-light motion displays as \nbiological motion is impaired when they are shown upside down (Bertenthal & Pinto, \n1994; Pavlova & Sokolov, 2000; Shipley, 2003; Troje, 2003), even given prior \nknowledge about display orientation (Pavlova & Sokolov, 2003). Moreover, neural \nactivation characteristic of upright biological motion displays is attenuated or absent \nForm and motion in emotion recognition 7 \nwhen such displays are inverted (Grossman & Blake, 2001; Pavlova, Lutzenberger, \nSokolov, & Birbaumer, 2004). Inversion of point-light displays also disrupts the \nability to distinguish the identity of the actors from their actions (Loula et al., 2005), \nand sex judgments based on gait tend to be reversed (Barclay et al., 1978). Most \nrelevantly, Dittrich et al. (1996) found a main effect of stimulus orientation on the \nidentification of basic emotions in whole-body dance movements in point-light and \nfull-light displays, although it was only a decrement in accuracy with full-light anger \nexpressions that was driving this effect. This result does not fit with the expectation \nthat inversion would more severely impair emotion recognition from point-light than \nfull-light stimuli, on the reasoning that if the kinematics and dynamics are identical \nacross these two types of display, then the differential effect of inversion must be a \nfunction of the form-related differences between them. Hence we sought to examine \nfurther the effects of display inversion on the identification of emotions in whole-\nbody gestures, using stimuli that, unlike those used by Dittrich et al. (1996), consist of \nmore stereotypical, less stylized movements, often with specific gestures or actions, \nand that contained identical movement sequences across the full-light and point-light \nconditions. \nReversing biological motion does not impede the ability of observers to \nperceive that motion as biological, but such stimulus transformations influence \nperception nevertheless. Verfaillie (2000) reported that observers were faster to \nidentify the direction of movement of point-light walkers when they were primed by a \npoint-light walker moving and facing in the same direction, as compared to a walker \nmoving and\/or facing in opposite direction. Pavlova, Krageloh-Mann, Birbaumer, and \nSokolov (2002) found that the identification of a point-light walking dog as biological \nmotion was unaffected by motion reversal, whereas judgments as to the particular \nForm and motion in emotion recognition 8 \ntype of animal depended on the perceived direction of locomotion. Similarly, Sumi \n(1984) found that human movement was still perceived even when a movie clip of a \npoint-light walker was reversed and inverted, although rather less often when the \nactor moved three-dimensionally as compared to two-dimensionally. Upside-down \nand reversed two-dimensional human motion tended to elicit interpretations of the \nstimulus as a person in an upright orientation moving forward but in a strange \nmanner. Following Giese and Poggio\u2019s  (2003) \u201csnapshot\u201d approach, we suggest that \nmotion reversal primarily disrupts the integration of static form information over \ntime, rather than the extraction of static form per se. \nOn the basis of the evidence reviewed here, and given that our patch-light and \nfull-light displays contain identical motion information, differing only in the amount \nof form information they provide, we made the following predictions. If inversion \nimpairs the processing of static form and form-from-motion cues (perhaps by \nchanging the hierarchy of the body parts \u2014 Reed et al., 2006) more than it does the \nprocessing of kinematic and dynamic cues, then we should find that stimulus \ninversion more severely impairs emotion recognition accuracy from patch-light \ngestures than from full-light gestures. Similarly, if motion reversal impairs the \nprocessing of changes in form over time more than it does the processing of kinematic \nand dynamic cues, then we should find that reversing the direction of play more \nseverely impairs emotion recognition accuracy from the patch-light than from the full-\nlight stimuli. \nThis study also had two auxiliary aims. One was to test the prediction that \nstimulus inversion and motion reversal would impair the identification of certain \nemotions more than others, given the following assumption. If evolutionary pressures \nselected for fast-acting mechanisms for the detection of threat-related stimuli (e.g., \nForm and motion in emotion recognition 9 \nLeDoux, 1998; Walk & Homan, 1984), then the visual system might be biased \ntowards the detection of threatening emotion signals in static images, given that \npresumably a longer time must elapse for signals in expressive movements to be made \nexplicit (Dittrich et al.\u2019s, 1996, \u201cmodified alarm hypothesis\u201d). Thus, insofar as \ninversion impairs processing of the spatial configuration of body parts, we expected \ninversion to have a greater effect on the recognition of threat-related emotions \u2014 \nputatively, fear, anger, and (more debatably) disgust \u2014 than on the other emotions. In \naddition, we expected fear recognition to be most impaired by motion reversal, given \nthat cowering or retreating in fear was one of the most consistent characteristic \nmovements for any of our emotion displays, which when reversed would appear as \nadvancements (to the neutral stance). Our second auxiliary aim was to assess the \nvalidity of a newly created set of emotionally neutral body movements, comprising \neveryday actions and exercises. In the context of our experiment, the emotional \nneutrality of these new stimuli would be confirmed to the extent that they would very \nrarely be classified as one of the basic emotions provided in the forced-choice \nemotion-labeling task. \n \nMethods \nParticipants \nThirty-two students from Durham University participated in this experiment \nfor a small monetary reward. One group of 16 (13 females) viewed the full-light \nstimuli (aged 18 \u2013 26 years; M = 21.2 years, SD = 3.3), and the other group of 16 (15 \nfemales) viewed the patch-light stimuli (aged 19 \u2013 46 years; M = 21.8 years, SD = \n6.7). All participants had normal or corrected-to-normal vision. \nForm and motion in emotion recognition 10 \nStimuli \nAll stimuli were grey-scale digital movie clips of people expressing emotions \nor performing simple actions with whole-body movement. Expressions of anger, \ndisgust, fear, happiness, and sadness were selected from a larger set developed by \nAtkinson et al. (2004), for which the actors were free to interpret and express the \nemotions as they saw fit, with only minimal guidance as to the sorts of situations in \nwhich people might experience those emotions. Ten versions of each of these \nexpressions were selected for the present study on the basis that they were well \nrecognized as the intended emotion. (The selection process was thus blind to the \nparticular movements made by the actors, and an informal inspection of the selected \nset revealed a range of movements representative of the larger set, as described in \nAtkinson et al., 2004.) In addition, 10 emotionally neutral, common human \nmovements (3 bending or crouching, 2 hopping, 2 digging, 1 knocking, 1 walking, 1 \nstar-jumping2) were selected from a newly developed set created using the same \ntechniques as described in Atkinson et al. (2004). A two-stage procedure was \nemployed to select these 10 neutral movements. First, the original 96 full-light and 96 \nmatching patch-light stimuli (4 actors X 8 movements X 3 versions in each lighting \ncondition) were whittled down to a set of 32 identical movements in each lighting \ncondition, based on the free-responses of 20 undergraduates when asked of each \nstimulus what the person was (a) doing and (b) feeling (the instructions allowed \n\u2018nothing in particular\u2019 as a valid answer for b). Four examples of each of the 8 actions \nwere selected on the condition that, across their full-light and patch-light versions, \neach stimulus received no more than 1 emotion-related descriptor. The resultant 32 \nfull-light and 32 patch-light clips were then utilized in a forced-choice experiment \nalong with all 300 body expressions of emotion from Atkinson et al. (2004) (30 \nForm and motion in emotion recognition 11 \nversions X 5 emotions X 2 lighting conditions). Prior to this second preliminary \nexperiment, all the clips were edited to exactly 3 seconds in length, such that the clip \nbegan when the actor began moving from a neutral stance and ended before the actor \nhad returned to that stance. Participants classified either the patch-light or full-light \nstimuli in a 6-alternative forced-choice emotion-labeling task (angry, disgusted, \nfearful, happy, sad, neutral). \nOn the basis of the results of this second preliminary experiment, 10 well \nrecognized versions of each of the neutral and 5 emotional movements (X 2 lighting \nconditions) were selected for the present experiment. The stimuli were presented in \nthe center of a 17-inch monitor screen, with a frame size of 200mm in height and \n250mm in width. The viewed height of the actors at their neutral starting points \nranged from 100mm to 120mm (mean = 110mm, with a visual angle of 4.50 from a \nviewing distance of 700mm). Examples of the stimuli can be viewed online at \nhttp:\/\/www.dur.ac.uk\/a.p.atkinson\/. \nDesign and procedure \n All participants were tested individually in a quiet room. Each group of \nparticipants viewed the same stimuli (either 60 patch-light or 60 full-light clips) \nrepeated in 4 modes of presentation (blocks), as determined by a 2 (upright, inverted) \nX 2 (forward, reversed) factorial design. The block order was counterbalanced across \nparticipants and within each block the stimuli were presented pseudo-randomly. Upon \ngiving their signed, informed consent, the participants classified the stimuli in a 6-\nalternative forced-choice emotion-labeling task (angry, disgusted, fearful, happy, sad, \nneutral), beginning with a practice block, which consisted of 24 body-movement \nstimuli (6 emotions X 4 modes of presentation) not used in the experimental blocks. \nInstructions appeared after each stimulus, reminding the participants of the 6 labels, \nForm and motion in emotion recognition 12 \nand remained on the screen until the participants responded by pressing one of 6 keys \non the keyboard labeled with the relevant emotions, after which the subsequent \nstimulus appeared. \n \nResults \n Participants were able to identify all emotions reliably at above chance levels \n(16.67%) under all conditions, as determined by one-sample t-tests (all ts > 5.0). A \nmixed design ANOVA on the percentage correct classification data revealed highly \nsignificant main effects of stimulus orientation [F (1, 30) = 78.87, p < .001, \u03b72 = \n.724], direction of motion [F (1, 30) = 108.62, p < .001, \u03b72 = .784], lighting [F (1, 30) \n= 19.08, p < .001], \u03b72 = .389], and emotion [F (3.64, 109.28) = 14.1, p < .001, \u03b72 = \n.32, Greenhouse-Geisser corrected]. These effects reflected reductions in emotion \nclassification accuracy for patch-light compared to full-light, inverted compared to \nupright, and reversed-motion compared to forward-motion displays, and differences \nin classification accuracy between emotions. However, these main effects were \nmodified by four two-way interactions. A significant interaction between orientation \nand lighting [F (1, 30) = 10.13, p < .005, \u03b72 = .252] indicated that stimulus inversion \nreduced emotion classification accuracy more for the patch-light stimuli than for the \nfull-light stimuli (Figure 1a). A marginally significant interaction between direction \nand lighting [F (1, 30) = 3.41, p < .08, \u03b72 = .102] indicated that playing the movie \nclips backwards reduced emotion classification accuracy slightly more for the patch-\nlight stimuli than for the full-light stimuli (Figure 1b). \n------ Insert Figure 1 about here. ------ \nThe interaction between orientation and emotion was significant [F (5, 150) = \n4.63, p < .005, \u03b72 = .134], as was the interaction between direction and emotion [F (5, \nForm and motion in emotion recognition 13 \n150) = 9.95, p < .001, \u03b72 = .249]. Post-hoc tests (\u03b1 = .05) revealed that display \ninversion and motion reversal each significantly reduced recognition accuracy in all 6 \nemotions (all Fs > 6.7), yet inversion impaired the classification of fear and disgust \nmore than it did the other emotions (Figure 2a), and reversal impaired the \nclassification of fearful and (to a lesser extent) neutral expressions more than it did \nthe other emotions (Figure 2b). All other interactions were not significant. The lack of \nan interaction between orientation and direction reflects a summative effect of \ninversion and reversal: participants were less accurate when these stimulus \nmanipulations were combined than when either was implemented singly. Although \nthe classification task of this experiment did not require a speeded judgment, an \nanalysis of response times nevertheless confirmed that the accuracy data did not \nreflect a speed-accuracy trade-off. \n------ Insert Figure 2 about here. ------ \nWe conducted a subsequent analysis to assess the possibility that the greater \neffects of stimulus inversion and motion reversal on emotion recognition from the \npatch-light compared to the full-light displays could be due simply to the patch-light \ndisplays being more difficult to classify in the upright, forward presentations and \nthereby more vulnerable to stimulus degradation. A subset of the stimuli was selected \nfor this analysis on the basis of data from a previous (unpublished) forced-choice \nexperiment with the upright, forward displays, according to two criteria. The overall \nemotion recognition accuracy for the selected patch-light movements (M = 81.7%, \nSEM = 2.1) was equated with that for the corresponding full-light movements (M = \n84.2%, SEM = 1.3) [t = -1.73, df = 29, p > .09], while maintaining an equal number of \nexamples (5) of each emotion. The original 4-way ANOVA was then rerun with the \ndata for these selected stimuli from the present experiment. All 4 main effects were \nForm and motion in emotion recognition 14 \nagain significant, and although overall, full-light expressions were identified more \naccurately than patch-light expressions, they were equally well recognized in the \nupright, forward presentations (patch-light: M = 80.8%, SEM = 2.4; full-light: M = \n83.5%, SEM = 2.4). Importantly, the Lighting X Orientation interaction was \nsignificant [F (1, 30) = 11.4, p < .005, \u03b72 = .275], suggesting that this effect cannot be \naccounted for by a simple difference in task difficulty. There was no significant \nLighting X Direction interaction, however [F (1, 30) = 0.007, n.s.], which does not \nallow us to rule out a task difficulty explanation for the observed marginal effect in \nthe original analysis. \nFinally, in order to reveal any changes in patterns of misclassifications across \nthe different display types, and to confirm the emotional neutrality of the body \nmovements in the neutral set, we carried out single-link cluster analyses of the \nresponse frequencies for every combination of displayed emotion and response label.  \nThe results revealed very similar patterns of misclassifications regardless of the \nstimulus manipulation for the full-light displays (Figure 3). However, for the patch-\nlight displays there were more changes in the confusability of emotions with inversion \nand reversal (especially between fear, anger, and happiness; see Figure 4). In all but \nthe inverted, reversed patch-light displays, neutral gestures were clustered separately \nfrom all the emotional gestures. Thus, not only were gestures intended as emotionally \nneutral the least likely of the 6 emotion categories to be misclassified, but also, on the \nrare occasions when they were misclassified, there was no single emotion or set of \nemotions with which they were consistently confused. \n------ Insert Figures 3 & 4 about here. ------ \n \n \nForm and motion in emotion recognition 15 \nDiscussion \nThis study has demonstrated robust effects of stimulus inversion and motion \nreversal on the classification of basic emotions from patch-light and full-light movie \nclips of body gestures. Inverting the movies significantly impaired emotion \nrecognition accuracy, but did so more in the patch-light than in the full-light displays, \nindicating that inversion disrupts the processing of form cues more than it does the \nprocessing of kinematic and dynamic cues. Playing the movies backwards also \nsignificantly impaired emotion recognition accuracy, but this effect was only \nmarginally greater for the patch-light than for the full-light displays, providing \nqualified support for the importance of the sequencing of changes in form to \njudgments of emotions from body gestures. While we cannot be certain that our \nstimulus manipulations completely eliminated all cues other than kinematics, even \nwhen in combination, the substantial reduction in emotion classification performance, \nespecially for the inverted, reversed patch-light displays, attests to the importance of \nform cues in emotion perception; conversely, the fact that emotion classification \nperformance was still substantially above chance, even in the inverted, reversed \npatch-light displays, attests to the importance of kinematics in providing cues for \nemotion perception. While it is likely that inversion of biological motion disrupts the \nprocessing of dynamic cues related to movement within the earth\u2019s gravitational field \n(Barclay et al., 1978; Bertenthal, Proffitt, & Kramer, 1987; Bertenthal & Pinto, 1994; \nPavlova & Sokolov, 2000; Shipley, 2003), if that were all that inversion impaired, \nthen we should not have seen a greater effect of orientation for the patch-light \ncompared to full-light stimuli. \nOur results provide partial support for Dittrich et al.\u2019s (1996) modified version \nof Walk and Homan\u2019s (1984) \u201calarm hypothesis\u201d, insofar as the identification of \nForm and motion in emotion recognition 16 \nfearful and disgusted gestures was disproportionately impaired by inversion, \nsuggesting a more important role for static form cues in the recognition of these \nemotions compared to the other emotions. On this reasoning, however, one would \nalso expect a similar effect for anger, the identification of which was not \ndisproportionately impaired by inversion. Consistent with the idea that an important \ndiagnostic feature of fearful body movements is that they often involve cowering or \nretreating, which when reversed would appear as advancements (to the neutral \nstance), fear recognition was also disproportionately impaired by motion reversal. \nWhat specific form-related cues are utilized in emotion perception from body \ngestures? One suggestion is that the overall shape of particular body postures, such as \ntheir angularity or roundedness, informs emotion judgments (Aronoff, Woike, & \nHyman, 1992). The inversion effects reported here highlight the importance of \n\u2018relational\u2019 or \u2018configural\u2019 cues, whereas the effects of motion reversal tentatively \nsuggest a possible role for spatiotemporal cues (changes in form over time). Inversion \nof faces is widely thought to disrupt the processing of configural information. \nEvidence suggests that face inversion affects the coding of second-order relational \ninformation, which specifies the metric distances amongst features, more than it does \nthe coding of isolated features or first-order configuration (the relative positions of \nfeatures) (e.g., Diamond & Carey, 1986; Rhodes, Brake, & Atkinson, 1993). The \nresults of a recent study (Reed et al., 2006) indicate that inverting static, non-\nemotional body postures particularly affects the processing of structural information, \nwhich is defined as first-order configuration plus information about the relative \nposition of features with respect to the whole body (i.e., the structural hierarchy of \nbody parts). There is some evidence to suggest that inversion of whole-body \nmovements impairs the processing of configural information per se (Lu, Yuille, & Liu, \nForm and motion in emotion recognition 17 \n2005; Pinto & Shiffrar, 1999), and our results add weight to previous claims that such \ninformation plays an important role in subserving emotion perception from body \nexpressions (Dittrich et al., 1996; Stekelenburg & de Gelder, 2004). \nIn conclusion, the kinematics of body gestures are sufficient for observers to \ndistinguish at least the basic emotions, yet we have demonstrated that form-related, \nespecially configural, information can also provide important cues for emotion \nrecognition. Given the conventional and sometimes symbolic (Buck, 1984) nature of \nour actors\u2019 movements (see Atkinson at al. 2004, for details), we speculate that \nconfigurations of static form and their changes over time are more closely associated \nwith representations of what people do with their bodies than with how they move \nthem, the latter being specified mostly by kinematics (see also Giese & Poggio, \n2003).\nForm and motion in emotion recognition 18 \nAcknowledgments \nThis research was supported by a grant to A.P.A. as part of the McDonnell Project in \nPhilosophy and the Neurosciences (http:\/\/www.sfu.edu\/neurophilosophy\/). We are \ngrateful to Thomas Schenk and two anonymous reviewers for helpful comments on \nearlier versions of the article, to Michael Burt for advice on analysis, and to Andy \nYoung for encouragement and suggestions. \nForm and motion in emotion recognition 19 \n \nFootnotes\n                                                \n1 For theoretical and practical reasons, research on emotion perception and \nrecognition has focussed predominantly on the ability of people to discriminate or \nidentify \u201cbasic\u201d emotions (e.g., Ekman, 1992), such as anger, fear, and disgust, which \nare distinguished from more complex social and moral emotions, such as jealousy, \nguilt, and embarrassment. One such reason is that basic emotions are in part defined \nby characteristic facial expressions. (In more recent writings, Ekman, e.g., 1999, \nconsiders that many of these \u2018higher\u2019 emotions may in fact be \u2018basic\u2019, even if they \nlack corresponding facial expressions.) Notwithstanding the focus on basic emotions \nof research with bodily expressions, it is less clear whether these basic emotions can \nbe defined by characteristic bodily as well as facial expressions; this issue is ripe for \nfurther investigation. \n2 Star-jumps are also known as jumping-jacks. \nForm and motion in emotion recognition 20 \nReferences \nAronoff, J., Woike, B. A., & Hyman, L. M. (1992). Which are the stimuli in \nfacial displays of anger and happiness? Configurational bases of emotion recognition. \nJournal of Personality and Social Psychology, 62, 1050-1066. \n  Atkinson, A. P. & Adolphs, A. (2005). Visual emotion perception: \nMechanisms and processes. In L. F. Barrett, P. M. Niedenthal, & P. Winkielman \n(Eds.), Emotion and consciousness (pp.150-182). New York: Guilford Press. \nAtkinson, A. P., Dittrich, W. H., Gemmell, A. J., & Young, A. W. (2004). \nEmotion perception from dynamic and static body expressions in point-light and full-\nlight displays. Perception, 33, 717-746. \nBarclay, C. D., Cutting, J. E., & Kozlowski, L. T. (1978). Temporal and \nspatial factors in gait perception that influence gender recognition. Perception and \nPsychophysics, 23, 145-152. \nBassili, J. N. (1978). Facial motion in the perception of faces and of emotional \nexpression. Journal of Experimental Psychology: Human Perception and \nPerformance, 4, 373-379. \nBeintema, J. A., & Lappe, M. (2002). Perception of biological motion without \nlocal image motion. Proceedings of the National Academy of Sciences, 99, 5661-\n5663. \nBertenthal, B. I., & Pinto, J. (1994). Global processing of biological motions. \nPsychological Science, 5, 221-225. \nBertenthal, B. I., Proffitt, D. R., & Kramer, S. J. (1987). Perception of \nbiomechanical motions by infants: implementation of various processing constraints. \nJournal of Experimental Psychology: Human Perception and Performance, 13, 577-\n585. \nForm and motion in emotion recognition 21 \nBuck, R. (1984). The communication of emotion. New York: Guilford Press. \nCasile, A., & Giese, M. A. (2005). Critical features for the recognition of \nbiological motion. Journal of Vision, 5, 348-360. \nCoulson, M. (2004). Attributing emotion to static body postures: Recognition \naccuracy, confusions, and viewpoint dependence. Journal of Nonverbal Behavior, 28, \n117-139. \nde Meijer, M. (1989). The contribution of general features of body movement \nto the attribution of emotions. Journal of Nonverbal Behavior, 13, 247-268. \nDiamond, R., & Carey, S. (1986). Why faces are and are not special: An effect \nof expertise. Journal of Experimental Psychology: General, 115, 107-117. \nDittrich, W. H. (1991). Facial motion and the recognition of emotions. \nPsychologische Beitrage, 33, 366-377. \nDittrich, W. H. (1993). Action categories and recognition of biological \nmotion. Perception, 22, 15-22. \nDittrich, W. H., Troscianko, T., Lea, S., & Morgan, D. (1996). Perception of \nemotion from dynamic point-light displays represented in dance. Perception, 25, 727-\n738. \nEkman, P. (1992). An argument for basic emotions. Cognition & Emotion, 6, \n169-200. \nEkman, P. (1999). Basic emotions. In T. Dalgleish & T. Power (Eds.), The \nhandbook of cognition and emotion (pp.45-60). New York: Wiley. \nGiese, M. A., & Poggio, T. (2003). Neural mechanisms for the recognition of \nbiological movements. Nature Reviews Neuroscience, 4, 179-192. \nGrossman, E. D., & Blake, R. (2001). Brain activity evoked by inverted and \nimagined biological motion. Vision Research, 41, 1475-1482. \nForm and motion in emotion recognition 22 \nHill, H., Jinno, Y., & Johnston, A. (2003). Comparing solid-body with point-\nlight animations. Perception, 32, 561-566. \nHirai, M., & Hiraki, K. (2006). The relative importance of spatial versus \ntemporal structure in the perception of biological motion: An event-related potential \nstudy. Cognition, 99, B15-B29.  \nJohansson, G. (1973). Visual perception of biological motion and a model for \nits analysis. Perception and Psychophysics, 14, 201-211. \nLeDoux, J. (1998). The emotional brain: The mysterious underpinnings of \nemotional life. New York: Simon & Schuster. \nLoula, F., Prasad, S., Harber, K., & Shiffrar, M. (2005). Recognizing people \nfrom their movement. Journal of Experimental Psychology: Human Perception and \nPerformance, 31, 210-220. \nLu, H., Yuille, A., & Liu, Z. (2005). Configural processing in biological \nmotion detection: Human versus ideal observers [Abstract.]. Journal of Vision, 5, 23-\n23. \nMather, G., & Murdoch, L. (1994). Gender discrimination in biological \nmotion displays based on dynamic cues. Proceedings of the Royal Society of London, \nSeries B: Biological Sciences, 259, 273-279. \nMather, G., Radford, K., & West, S. (1992). Low-level visual processing of \nbiological motion. Proceedings of the Royal Society of London, Series B: Biological \nSciences, 249, 149-155. \nMcLeod, P., Dittrich, W., Driver, J., Perrett, D., & Zihl, J. (1996). Preserved \nand impaired detection of structure from motion by a \"motion-blind\" patient. Visual \nCognition, 3, 363-391. \nForm and motion in emotion recognition 23 \nPavlova, M., Krageloh-Mann, I., Birbaumer, N., & Sokolov, A. (2002). \nBiological motion shown backwards: the apparent-facing effect. Perception, 31, 435-\n443. \nPavlova, M., Lutzenberger, W., Sokolov, A., & Birbaumer, N. (2004). \nDissociable cortical processing of recognizable and non-recognizable biological \nmovement: Analysing gamma MEG activity. Cerebral Cortex, 14, 181-188. \nPavlova, M., & Sokolov, A. (2000). Orientation specificity in biological \nmotion perception. Perception and Psychophysics, 62, 889-899. \nPavlova, M., & Sokolov, A. (2003). Prior knowledge about display inversion \nin biological motion perception. Perception, 32, 937-946. \nPeelen, M. V., Wiggett, A. J., & Downing, P. E. (2006). Patterns of fMRI \nactivity dissociate overlapping functional brain areas that respond to biological \nmotion. Neuron, 49, 815-822. \nPeterson, M. P., & Rhodes, G. (Eds.) (2003). Perception of faces, objects and \nscenes: Analytic and holistic processing. Cambridge, MA: Oxford University Press. \nPinto, J., & Shiffrar, M. (1999). Subconfigurations of the human form in the \nperception of biological motion displays. Acta Psychologica, 102, 293-318. \nPollick, F. E., Paterson, H. M., Bruderlin, A., & Sanford, A. J., (2001). \nPerceiving affect from arm movement. Cognition, 82, B51-B61. \nReed, C. L., Stone, V. E., Bozova, S., & Tanaka, J. (2003). The body-\ninversion effect. Psychological Science, 14, 302-308. \nReed, C. L., Stone, V. E., Grubb, J. D., & McGoldrick, J. E. (2006). Turning \nconfigural processing upside down: Part and whole body postures. Journal of \nExperimental Psychology: Human Perception and Performance, 32, 73-87. \nForm and motion in emotion recognition 24 \nRhodes, G., Brake, S., & Atkinson, A. P. (1993). What's lost in inverted faces? \nCognition, 47, 25-57. \nRichardson, M. J., & Johnston, L. (2005). Person recognition from dynamic \nevents: The kinematic specification of individual identity in walking style. Journal of \nNonverbal Behavior, 29, 25-44. \nRuneson, S., & Frykholm, G. (1983). Kinematic specification of dynamics as \nan informational basis for person-and-action perception: Expectation, gender \nrecognition, and deceptive intention. Journal of Experimental Psychology: General, \n112, 585-615. \nSawada, M., Suda, K., & Ishii, M. (2003). Expression of emotions in dance: \nrelation between arm movement characteristics and emotion. Perceptual and Motor \nSkills, 97, 697-708. \nShipley, T. F. (2003). The effect of object and event orientation on perception \nof biological motion. Psychological Science, 14, 377-380. \nStekelenburg, J. J., & de Gelder, B. (2004). The neural correlates of perceiving \nhuman bodies: an ERP study on the body-inversion effect. Neuroreport, 15, 777-780. \nSumi, S. (1984). Upside-down presentation of the Johansson moving light-\nspot pattern. Perception, 13, 283-286. \nTroje, N. F. (2002). Decomposing biological motion: a framework for analysis \nand synthesis of human gait patterns. Journal of Vision, 2, 371-387. \nTroje, N. F. (2003). Reference frames for orientation anisotropies in face \nrecognition and biological-motion perception. Perception, 32, 201-210. \nVaina, L. M., Cowey, A., LeMay, M., Bienfang, D. C., & Kikinis, R. (2002). \nVisual deficits in a patient with 'kaleidoscopic disintegration of the visual world'. \nEuropean Journal of Neurology, 9, 463-477. \nForm and motion in emotion recognition 25 \nVerfaillie, K. (2000). Perceiving human locomotion: Priming effects in \ndirection discrimination. Brain and Cognition, 44, 192-213. \nWalk, R. D., & Homan, C. P. (1984). Emotion and dance in dynamic light \ndisplays. Bulletin of the Psychonomic Society, 22, 437-440. \nForm and motion in emotion recognition 26 \nFigure Captions \nFigure 1. Mean percentage correct forced-choice emotion classification for full-light \nand patch-light body gesture movie clips (a) in upright and inverted displays, and (b) \nplayed forward and in reverse. Error bars indicate standard errors of the means \n(SEMs). \nFigure 2. Mean percentage correct forced-choice emotion classification for body \ngestures (full-light and patch-light combined), as a function of emotion and (a) \ndisplay orientation, and (b) motion direction. Error bars indicate SEMs. \nFigure 3. Dendrograms constructed from single-link cluster analyses on the basis of \nthe Euclidean distance between response frequencies for the full-light stimuli, for \neach emotion under each of the orientation and motion direction manipulations. \nFigure 4. Dendrograms constructed from single-link cluster analyses on the basis of \nthe Euclidean distance between response frequencies for the patch-light stimuli, for \neach emotion under each of the orientation and motion direction manipulations. \nForm and motion in emotion recognition 27 \nFigure 1. \n \nForm and motion in emotion recognition 28 \nFigure 2. \n \n \nForm and motion in emotion recognition 29 \nFigure 3. \n \nForm and motion in emotion recognition 30 \nFigure 4. \n \n \n \n \n \n \n \n"}
{"doi":"10.1109\/TSMCB.2009.2028315","coreId":"69366","oai":"oai:eprints.lancs.ac.uk:27110","identifiers":["oai:eprints.lancs.ac.uk:27110","10.1109\/TSMCB.2009.2028315"],"title":"Adaptive inferential sensors based on evolving fuzzy models","authors":["Angelov, Plamen","Kordon, Arthur"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-04","abstract":"A new technique to the design and use of inferential sensors in the process industry is proposed in this paper, which is based on the recently introduced concept of evolving fuzzy models (EFMs). They address the challenge that the modern process industry faces today, namely, to develop such adaptive and self-calibrating online inferential sensors that reduce the maintenance costs while keeping the high precision and interpretability\/transparency. The proposed new methodology makes possible inferential sensors to recalibrate automatically, which reduces significantly the life-cycle efforts for their maintenance. This is achieved by the adaptive and flexible open-structure EFM used. The novelty of this paper lies in the following: (1) the overall concept of inferential sensors with evolving and self-developing structure from the data streams; (2) the new methodology for online automatic selection of input variables that are most relevant for the prediction; (3) the technique to detect automatically a shift in the data pattern using the age of the clusters (and fuzzy rules); (4) the online standardization technique used by the learning procedure of the evolving model; and (5) the application of this innovative approach to several real-life industrial processes from the chemical industry (evolving inferential sensors, namely, eSensors, were used for predicting the chemical properties of different products in The Dow Chemical Company, Freeport, TX). It should be noted, however, that the methodology and conclusions of this paper are valid for the broader area of chemical and process industries in general. The results demonstrate that well-interpretable and with-simple-structure inferential sensors can automatically be designed from the data stream in real time, which predict various process variables of interest. The proposed approach can be used as a basis for the development of a new generation of adaptive and evolving inferential sensors that can a- ddress the challenges of the modern advanced process industry","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/69366.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/27110\/1\/tsmcb%2Dangelov%2D2028315%2Dproof.pdf","pdfHashValue":"93386375cd1c4f77340946f6e62d979ae7472d95","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:27110<\/identifier><datestamp>\n      2018-01-24T02:50:12Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Adaptive inferential sensors based on evolving fuzzy models<\/dc:title><dc:creator>\n        Angelov, Plamen<\/dc:creator><dc:creator>\n        Kordon, Arthur<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        A new technique to the design and use of inferential sensors in the process industry is proposed in this paper, which is based on the recently introduced concept of evolving fuzzy models (EFMs). They address the challenge that the modern process industry faces today, namely, to develop such adaptive and self-calibrating online inferential sensors that reduce the maintenance costs while keeping the high precision and interpretability\/transparency. The proposed new methodology makes possible inferential sensors to recalibrate automatically, which reduces significantly the life-cycle efforts for their maintenance. This is achieved by the adaptive and flexible open-structure EFM used. The novelty of this paper lies in the following: (1) the overall concept of inferential sensors with evolving and self-developing structure from the data streams; (2) the new methodology for online automatic selection of input variables that are most relevant for the prediction; (3) the technique to detect automatically a shift in the data pattern using the age of the clusters (and fuzzy rules); (4) the online standardization technique used by the learning procedure of the evolving model; and (5) the application of this innovative approach to several real-life industrial processes from the chemical industry (evolving inferential sensors, namely, eSensors, were used for predicting the chemical properties of different products in The Dow Chemical Company, Freeport, TX). It should be noted, however, that the methodology and conclusions of this paper are valid for the broader area of chemical and process industries in general. The results demonstrate that well-interpretable and with-simple-structure inferential sensors can automatically be designed from the data stream in real time, which predict various process variables of interest. The proposed approach can be used as a basis for the development of a new generation of adaptive and evolving inferential sensors that can a- ddress the challenges of the modern advanced process industry.<\/dc:description><dc:date>\n        2010-04<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/27110\/1\/tsmcb%2Dangelov%2D2028315%2Dproof.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/TSMCB.2009.2028315<\/dc:relation><dc:identifier>\n        Angelov, Plamen and Kordon, Arthur (2010) Adaptive inferential sensors based on evolving fuzzy models. IEEE Transactions on Systems, Man and Cybernetics, Part B: Cybernetics, 40 (2). pp. 529-539. ISSN 1083-4419<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/27110\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/TSMCB.2009.2028315","http:\/\/eprints.lancs.ac.uk\/27110\/"],"year":2010,"topics":["QA75 Electronic computers. Computer science"],"subject":["Journal Article","PeerReviewed"],"fullText":"IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS 1\nAdaptive Inferential Sensors Based on\nEvolving Fuzzy Models\n1\n2\nPlamen Angelov, Senior Member, IEEE, and Arthur Kordon, Member, IEEE3\nAbstract\u2014A new technique to the design and use of inferential4\nsensors in the process industry is proposed in this paper, which5\nis based on the recently introduced concept of evolving fuzzy6\nmodels (EFMs). They address the challenge that the modern7\nprocess industry faces today, namely, to develop such adaptive and8\nself-calibrating online inferential sensors that reduce the mainte-9\nnance costs while keeping the high precision and interpretability\/10\ntransparency. The proposed new methodology makes possible11\ninferential sensors to recalibrate automatically, which reduces12\nsignificantly the life-cycle efforts for their maintenance. This is13\nachieved by the adaptive and flexible open-structure EFM used.14\nThe novelty of this paper lies in the following: 1) the overall15\nconcept of inferential sensors with evolving and self-developing16\nstructure from the data streams); 2) the new methodology for17\nonline automatic selection of input variables that are most relevant18\nfor the prediction; 3) the technique to detect automatically a shift19\nin the data pattern using the age of the clusters (and fuzzy rules);20\n4) the online standardization technique used by the learning pro-21\ncedure of the evolving model; and 5) the application of this inno-22\nvative approach to several real-life industrial processes from the23\nchemical industry (evolving inferential sensors, namely, eSensors,24\nwere used for predicting the chemical properties of different25\nproducts in The Dow Chemical Company, Freeport, TX). It should26\nbe noted, however, that the methodology and conclusions of this27\npaper are valid for the broader area of chemical and process indus-28\ntries in general. The results demonstrate that well-interpretable29\nand with-simple-structure inferential sensors can automatically be30\ndesigned from the data stream in real time, which predict various31\nprocess variables of interest. The proposed approach can be used32\nas a basis for the development of a new generation of adaptive and33\nevolving inferential sensors that can address the challenges of the34\nmodern advanced process industry.35\nIndex Terms\u2014Concept shift in data streams, evolving fuzzy36\nsystems, fuzzy-rule aging, inferential sensors, learning and adap-37\ntation, Takagi\u2013Sugeno (TS) fuzzy models.38\nI. INTRODUCTION39\nINFERENTIAL sensors [1], [21], [23], [27], [28] are able to40 provide accurate real-time estimates of difficult-to-measure41\nparameters or expensive measurements (like emissions, bio-42\nmass, melt index, etc.) from the available cheap sensors43\n(like temperatures, pressures, and flows). Different empirical44\nManuscript received October 17, 2008; revised March 27, 2009 and June 26,\n2009. This paper was recommended by Associate Editor T. H. Lee.\nP. Angelov is with the Intelligent Systems Research Laboratory, Infolab21,\nLancaster University, LA1 4WA Lancaster, U.K. (e-mail: p.angelov@lancaster.\nac.uk).\nA. Kordon is with The Dow Chemical Company, Freeport, TX 77541 USA\n(e-mail: AKKordon@Dow.com).\nColor versions of one or more of the figures in this paper are available online\nat http:\/\/ieeexplore.ieee.org.\nDigital Object Identifier 10.1109\/TSMCB.2009.2028315\nmethods have been used to develop inferential sensors, such 45\nas statistical models [2], neural networks (NNs) [3], support- 46\nvector machines [4], [22], and genetic programming [5], [13]. 47\nModel-based techniques for process-quality monitoring [1] of- 48\nten provide a valuable advantage over conventional approaches 49\nthat rely on manual intervention and laboratory tests. Such 50\nmodels, however, are costly to build and maintain since the 51\nenvironment in which an industrial process takes place is dy- 52\nnamically changing, the equipment is getting older and conta- 53\nminated or being replaced, raw materials usually alter in quality, 54\nand the complexity of processes leads to a number of aspects of 55\nthe process being ignored by the models. A crucial weakness 56\nof model-based approaches is that they do not take into account 57\nthe shift and drift in the data pattern that is related to the fact that 58\nthese models are developed offline under certain conditions. 59\nEven minor process changes outside these conditions may lead 60\nto unacceptable performance deterioration that requires manual 61\nmaintenance and recalibration. 62\nThe challenge is to develop inferential sensors with flexible 63\nyet interpretable structure [6] and adaptive parameters. The 64\ngradual evolution of the model structure (fuzzy rules) will 65\nmean that a retraining of the sensor when required will only 66\nmodify (add, remove, or replace) one or few fuzzy rules [7]. 67\nContrast this to a possible option of iteratively retraining an NN, 68\nwhich, in effect, will lead to a completely new NN and a loss of 69\nprevious information [29]. Ideally, we would require inferential 70\nsensors that can automatically recalibrate and detect shifts and 71\ndrifts in the data stream [4], [8]. One such methodological 72\nframework is presented by the evolving Takagi\u2013Sugeno (ETS) 73\nfuzzy models [9], [10]. In this paper, we use this framework and 74\nbuild upon it a methodological concept for evolving inferential 75\nsensors, namely, eSensors, which is new and original. The 76\nmain contributions of this paper include the following: 1) the 77\noverall concept of eSensors; 2) the new methodology for online 78\nautomatic selection of input variables that are most relevant for 79\nthe prediction; 3) the technique to detect automatically a shift in 80\nthe data pattern using the age of the clusters (and fuzzy rules); 81\n4) the online standardization technique used by the learning 82\nprocedure of the evolving model; and 5) the application of this 83\ninnovative approach to four real-life industrial processes from 84\nthe chemical industries. 85\nII. ADAPTIVE INFERENTIAL SENSORS BASED ON EFM 86\nA. Principles of EFM 87\nEvolving fuzzy models (EFMs) were first introduced as a 88\ntechnique for online adaptation of fuzzy-rule-based systems\u2019 89\n1083-4419\/$26.00 \u00a9 2009 IEEE\n2 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nstructure (rule-based fuzzy sets), as well as their parameters90\n[7], [14]. In that respect, they make a step further by comparing91\nthe aforementioned technique to the well-established adaptive-92\nsystem theory [15], which is applicable to linear systems only93\nand to a small circle of nonlinear systems. EFM systems are94\nnonlinear, linguistically interpretable, yet adaptable online in a95\n(local) least squares (LS) sense. The approach was further re-96\nfined for the specific case of the so-called TS fuzzy models [16]97\nby introducing a fully recursive algorithm called ETS [9], [10].98\nETS fuzzy models are particularly suited as a framework for99\naddressing the challenges that the process industry faces nowa-100\ndays. They can provide the algorithmic backbone of systems101\nthat can be implemented as embedded autonomous intelligent102\nsensors with self-calibration and self-maintenance capabilities.103\nThe basic idea of ETS is to allow the TS fuzzy system struc-104\nture to grow, shrink, adapt, and self-develop in an automatic105\nfashion learned online from the data streams in a locally optimal106\nway. TS fuzzy systems [16] are very attractive due to their dual107\nnature\u2014they combine the fuzzy linguistic antecedent part with108\na linear functional consequent part, thus being locally linear109\nbut nonlinear overall and being proven universal approximators110\n[17]. The antecedent part is a linguistic representation of a111\npartition of the measurable-variable space into fuzzily overlap-112\nping regions (see Fig. 14). The linguistic antecedent parts of113\nTS fuzzy systems make them attractive for human operators114\n(compared to NN, SVM, or polynomial models, for example).115\nThe architecture of an ETS fuzzy system is based on fuzzily116\nweighted local linear models of the following form [9], [10]:117\nLM i : yi = xT\u0398 (1)\nwhere LM i denotes the ith local model, i = 1, 2, . . . , N ; x =118\n[1, x1, x2, . . . , xn]T represents the (n + 1)\u00d7 1 extended vector119\nof measurable variables; yi = [yi1, yi2, . . . , yim]T is the m\u00d7 1120\nvector of estimated variables; and \u0398i = [\u03b8i0 \u03b8i1 \u00b7 \u00b7 \u00b7 \u03b8in]T121\ndenotes the matrix of consequent parameters.122\nAll of the N local linear models describe the process in a123\nlocal area defined by fuzzy rules and are blended in a fuzzy124\nway to produce the overall output that is nonlinear in terms of125\nmeasurable variables x\u2019s but is linear in terms of parameters \u0398\u2019s126\ny = \u03c8T\u0398 (2)\nwhere \u03c8 = [\u03bb1xT , \u03bb2xT , . . . , \u03bbNxT ]T is a vector of127\nmeasurable variables that are weighted by the normalized128\nactivation levels of the rules, \u03bbi, i = 1, 2, . . . , N , with \u03bbi129\nbeing the normalized firing level of the ith fuzzy rule that is a130\nfunction of x, i.e., \u03bbi(x).131\nThe overall TS fuzzy model can then be described by a set of132\nfuzzy rules of the following form:133\nRi : IF (x1 is around xi\u22171 ) AND, . . .\nAND\n(\nxn is around xi\u2217n\n)\n, THEN (yi = LM i) (3)\nwhere Ri denotes the ith fuzzy rule, with i = [1, N ]; N is the134\nnumber of fuzzy rules; (xj is around xi\u2217j ) denotes the jth fuzzy135\nset of the ith fuzzy rule, with j = 1, 2, . . . , n; and xi\u2217 is the136\nfocal point of the ith-rule antecedent part.137\nThe degree of membership of a certain data point (x) to any 138\nof the fuzzy rules can be described by a Gaussian centered at its 139\nfocal point 140\n\u03bci = e\n\u2212\n\u2211n\nj=1(xj\u2212x\ni\u2217\nj )\n2\n2(\u03c3ij)\n2\n(4)\nhaving a spread that is learned based on the data variance [10] 141\n(\nvijk\n)2 = \u03c1(vij(k\u22121)\n)2\n+ (1\u2212 \u03c1) 1\nnik\nni\nk\u2211\nl=1\n\u2016zi\u2217 \u2212 zl\u20162j ,\nvij1 = 1, \u03c3\ni\njk \u2190 vijk (5)\nwhere vijk denotes the variance of the data in the ith cluster 142\nin the jth dimension (jth variable) calculated at the kth time 143\ninstant, \u03c3ijk represents the spread of the Gaussian of the jth 144\nfuzzy set of the ith fuzzy rule calculated at the kth time instant, 145\nz = [x, y]T depicts the overall data vector, and nik denotes the 146\nsupport of the ith cluster\/rule\u2014the number of samples that are 147\nassociated with it based on the distance to the focal point. 148\nThe firing strength of a fuzzy rule is determined by a t-norm, 149\nwhich can be represented as inner product [18] 150\n\u03c4 i =\nn\u220f\nj=1\n\u03bcij(xj) (6)\nand is normalized so that it sums to one 151\n\u03bbi =\n\u03c4 i\u2211N\nj=1 \u03c4j\n. (7)\nB. Monitoring the Quality of the Rule Base 152\nOne can monitor and analyze online the quality of the 153\nclusters that are formed and the fuzzy rules, respectively\u2014for 154\nexample, the number of points that support them or their age 155\n[19]. The support of the rules is determined by a simple count- 156\ning of the samples that are associated with the nearest focal 157\npoint 158\nnik+1=n\ni\nk+1, i=arg\nN\nmin\ni=1\n\u2016xk\u2212xi\u2217\u2016, k=2, 3, . . . . (8)\nThe support is initiated by one at the moment a rule is created 159\nnN+1k \u2190 1, k = 2, 3, . . . . (9)\nIn this paper, we introduce a recursive formula to calculate 160\nthe age of the ith cluster\/rule calculated at the kth moment in 161\ntime (data sample) 162\nAik = k \u2212\n1\nnik\n(\nk \u2212Aik\u22121 + knik\n)\n(10)\nwhere kl is the time index when the data sample was read. 163\nThis follows from 164\nAik = k \u2212\n1\nnik\nni\nk\u2211\nl=1\nkl A\ni\nk\u22121 = k \u2212\n1\nnik\u22121\nni\nk\u22121\u2211\nl=1\nkl.\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 3\nFig. 1. (a) Top plot\u2014output variable in case study 4\u2014polymerization;\n(b) Bottom plot\u2014age of the fuzzy rules describing the propylene-polymerization\nprocess. The two instants when a shift in the data pattern occurs are marked.\nThis corresponds to a change in the aging rate seen from the bottom plot.\nFrom there, we get165\nni\nk\u22121\u2211\nl=1\nkl =\n(\nk \u2212Aik\u22121\n)\nAik = k \u2212\n1\nnik\n\u239b\n\u239d\nni\nk\u22121\u2211\nl=1\nkl + kni\nk\n\u239e\n\u23a0 .\nCombining these two expressions, we arrive at (10).166\nEach time a new rule is created, its age is initiated by the167\nindex of the data sample that is used as a focal point of that rule.168\nEach time a new data sample is associated to an existing rule169\n(the distance from a sample to that focal point is smaller than170\nthat to any other focal points), the age of that rule gets smaller.171\nIf no sample is assigned to a rule, it gets older by one. Note that172\nthe age of a fuzzy rule can take values from the [0; k] range.173\nThis is shown in Fig. 1 in the case of propylene estimation.174\nFrom the top plot, one can see that there are three different175\nstages of that process. The aging of three of the six fuzzy rules176\n(rules ## 1, 3, and 4) are depicted in the bottom plot. One can177\nsee that precisely at the moment of a shift in the data pattern178\n(a new phase), the aging of the rules is affected. By monitoring179\nthe derivative of A (i.e., aging rate), one can automatically180\ndetect such changes and respond by adapting the learning181\nmechanism or rate.182\nNote that the age rate of rule #1 becomes negative before it183\nincreases again. This illustrates the so-called concept shift and184\nis an indication of a transition from one operating state (which185\naffects the data density in one local region, i.e., around the focal186\npoint of this rule) to another one (which affects the data density187\nin another local region).188\nFig. 2. Evolution of the age and shift in the data pattern, resulting in forming\nnew clusters\/rules for case study 2. The inflex points correspond to a shift of the\ndata from one cluster to another existing cluster or to a newly formed cluster\n(as marked in the figure for each inflex point).\nThe age of the fuzzy rules (and the derivative of their age in 189\nterms of the sampling period (k), which represents the aging 190\nrate) can be very useful for online analysis of the concept 191\nshift in the data stream [12]. An eSensor can detect a concept 192\nshift [20] online by the rate of aging and the instances when 193\nit changes [the inflex points on the age evolution diagram that 194\ncorresponds to the change of the sign of the aging rate indicate 195\na shift (see Fig. 2)]. The aging corresponds to the first derivative 196\nof the age and is graphically represented by the slope of the age 197\nevolution lines in terms of the horizontal axis [see Fig. 1(b)]. 198\nIn this paper, we use the following principle for the update 199\nof the rule base by removing the older rules (rules whose age 200\nexceeds the mean age for that rule by more than the standard- 201\ndeviation [2] value calculated recursively up to that moment\/ 202\nsample): 203\nIF\n(\nAi>Ai+std(Ai)\n)\n, THEN(remove Ri;N\u2190N\u22121) (11)\nwhere Ai denotes the mean age (it is also denoted in Fig. 1(b) 204\nby a dash-dotted line) and std(Ai) represents the standard 205\ndeviation of the age of the ith rule. 206\nC. Evolving the Structure of the Sensor From the Data Stream 207\nThe online design and learning of the eSensor are outlined 208\nhere. Learning is based on decomposition of the identification 209\nproblem into the following [7], [9], [10]: 1) fuzzy-rule-based 210\nstructure design and 2) parameter identification. Both of these 211\nsubproblems can be performed in online mode during one time 212\nstep (per sample). The first subproblem, i.e., structure identifi- 213\ncation, can be approached using evolving clustering in the data 214\nspace [9], [10], [12]. This partitioning leads to forming infor- 215\nmation granules, described linguistically by fuzzy sets. Thus, 216\nit serves the transformation of the data into primitive forms 217\nof knowledge. The basic notion of the partitioning algorithm 218\nis that of the data density [26], which is defined as a Cauchy 219\nfunction over the sum of distances d\u2019s between a certain data 220\nsample zi and all other data samples in the feature space [10] 221\nDk(zk) =\n1\n1 + v2k\n(12)\n4 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nwhere v2k = (1\/k \u2212 1)\n\u2211k\u22121\ni=1 d\n2(zk, zi) is the variance of the222\ndata [2].223\nData-space partitioning is based on the following principle:224\nThe point with the highest density in the data space is chosen225\nto be the focal point, and the antecedent of the first fuzzy226\nrule is formed around it. In this way, fuzzy rules with high227\ndescriptive power and generalization capabilities are generated.228\nThe density can be recursively calculated using the current data229\npoint (zjk) and (n + 1) memorized quantities only (\u03b2k and \u03c7jk,230\nj = [1, n]) [10]231\nDk(zk) = (k \u2212 1) (\u03b1k(k \u2212 1) + \u03b2k \u2212 2\u03b3k + (k \u2212 1))\u22121 ,\nk = 2, 3, . . . (13)\nwhere \u03b1k =\n\u2211n+1\nj=1 (z\nj\nk)\n2; \u03b2k = \u03b2k\u22121 + \u03b1k\u22121, with \u03b21 = 0;232\nand \u03b3k =\n\u2211n+1\nj=1 z\nj\nk\u03c7\nj\nk, with \u03c7\nj\nk = \u03c7\nj\nk\u22121 + z\nj\nk\u22121 and \u03c7\nj\n1 = 0.233\nEach time a new data sample is read, it affects the data234\ndensity of the existing focal points and can be updated by [10]235\nDk(zi\u2217) =\n(k \u2212 1)Dk\u22121(zi\u2217)\nk \u2212 2 + Dk\u22121(zi\u2217) + Dk\u22121(zi\u2217)d(zi\u2217, zk) ,\nk = 2, 3, . . . (14)\nwhere d(zi\u2217, zk) denotes the distance between the ith focal236\npoint and the current point.237\nOnce the densities of the new coming data sample and of238\neach of the previously existing focal points are recursively239\nupdated, they are compared. If the new coming data sample240\nhas a higher density than any of the previously existing focal241\npoints, then this means that it is a good candidate to become a242\nfocal point of a new rule (a new local linear model) because it243\nhas high descriptive power and generalization potential244\nDk(zk) > Dk(zi\u2217) \u2200 i\u2217 \u2208 N. (15a)\nIf the new coming data sample has a lower density than any245\nof the previously existing focal points, then this means that it246\nis also a good candidate to become a focal point of a new rule247\n(a new local linear model) because it improves the coverage of248\nthe whole data space [12]249\nDk(zk) < Dk(zi\u2217) \u2200 i\u2217 \u2208 N. (15b)\nForming a new fuzzy rule around a newly added prototype250\nleads to a gradual increase of the size of the rule base, which is251\nwhy this approach is called \u201cevolving\u201d252\nz(N+1)\u2217 \u2190 zk. (16)\nThe density of the newly generated rule is set to one [10]253\ntemporarily (it will be updated to take into account later the254\ninfluence of each new coming data sample on the generalization255\npotential of this particular focal point)256\nDk\n(\nz(N+1)\u2217\n)\n\u2190 1. (17)\nTo increase the interpretability and update of the rule base,257\none needs also to remove the previously existing rules that258\nbecome ambiguous after insertion of the new rule. Therefore, 259\neach time a new fuzzy rule is added, it is also checked whether 260\nany of the already existing prototypes in the rule base are 261\ndescribed by this rule to a degree that is higher than 50% 262\n\u2203i, i=[1, N ]; \u03bcji (zN+1) > 0.5 \u2200 j, j=[1, n]. (18)\nIf any of the previously existing focal points satisfy this con- 263\ndition, the rules that correspond to them are being removed 264\n(replaced by the newly formed rule) [9], [19]. The spreads of 265\nthe membership functions are also recursively updated by (5). 266\nD. Self-Learning the eSensor 267\nOnce the antecedent part of the TS fuzzy model is formed, 268\nthe consequent-parameter estimation (the second subproblem 269\nof the learning) is addressed as a fuzzily weighted recursive LS 270\n(RLS) estimation problem per rule [15] 271\n\u0398ik =\u0398\ni\nk\u22121 + C\ni\nk\u03bb\nixk\n(\nyk \u2212 xTk \u0398ik\u22121\n)\n, \u0398i1 = 0 (19)\nCik =C\ni\nk\u22121\u2212\n\u03bbiCik\u22121xkx\nT\nk C\ni\nk\u22121\n1 + \u03bbixTk C\ni\nk\u22121xk\n, Ci1 = \u03a9I, k = 2, 3, . . .\n(20)\nwhere C \u2208 RN(n+L)xN(n+L) denotes the covariance matrix, \u03a9 272\nis a large positive number, and I is the identity matrix. 273\nAs a result, the eSensor blends in a fuzzy way local linear 274\npredictors. Moreover, it is optimally (in an LS sense) [15] 275\ntuned in terms of consequent parameters \u0398\u2019s. In terms of its 276\nantecedents and rule-based structure, it is based on the robust 277\nonline partitioning approach. The procedure of the eSensor self- 278\ndevelopment and self-calibration is represented as a pseudo- 279\ncode in the Appendix. 280\nE. Online Normalization and Standardization of the 281\nData in the eSensor 282\nOne specific issue related to this online algorithm is the 283\nnormalization or standardization of the data. Both normaliza- 284\ntion and standardization are well-established techniques for the 285\noffline case when all the data are available [2]. An approach 286\nto update the normalization ranges of the data in a recursive 287\nmanner is presented in [25], but in this paper, we use the 288\nrecursive version of the standardization technique that can 289\neasily be inferred from the offline version [2] because it depends 290\non the mean and variance of the data only. Let us remember that 291\n(offline) standardization is given by [2] 292\nZjk =\nzjk \u2212 zjk\n\u03b6jk\n, j = [1, n], k = 2, 3, . . . (21)\nwhere Zjk denotes the standardized value of zjk; zjk = 293\n(1\/k)\n\u2211k\nl=1 zjl, j = [1, n], k = 2, 3, . . . , represents the mean 294\nvalue of zjk; and vjk is the standard deviation of the jth input 295\ncalculated based on k data samples. 296\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 5\nBoth the mean and standard deviation can be updated297\nrecursively298\nzjk =\nk \u2212 1\nk\nzj(k\u22121) +\n1\nk\nzj(k\u22121),\nzj1 =0, j = [1, n + m], k = 2, 3, . . . (22a)\nv2jk =\nk \u2212 1\nk\nv2j(k\u22121) +\n1\nk \u2212 1\n(\nzjk \u2212 zj(k\u22121)\n)\n,\nvj1 =0, j = [1, n + m], k = 2, 3, . . . . (22b)\nIn order to return to the original scale, one should apply299\ndestandardization by300\nzjk = Zjk\u03bdjk + zjk, j = [1, n + m], k = 2, 3, . . . . (23)\nIII. ONLINE INPUT-VARIABLE SELECTION IN THE ESENSOR301\nInferential sensors, as well as other online models, tradi-302\ntionally assume the number of input variables to be known303\nbeforehand or to be preselected. In what follows, we propose an304\noriginal1 method to online \u201con-fly\u201d ranking and selection of in-305\nput variables, which was successfully approbated on the indus-306\ntrial case studies reported in this paper, as well as on other real307\napplications [30]. The importance of this technique should not308\nbe underestimated because, very often in practice, there are309\nlarge sets of candidate variables that may influence the moni-310\ntored or measured output, but often, it is not clear how much.311\nThe idea is based on online ranking of the accumulated values312\nformed by the consequent parameters \u0398ijk, j=[1,N ],i=[1,R].313\nThe accumulated values \u03c0\u2019s indicate that the weight of a par-314\nticular consequent parameter is determined by simply adding315\nthe absolute values (because the consequent parameters are316\nunrestricted in sign and value, and their contribution is judged317\nby the modulus)318\n\u03c0ijk =\nk\u2211\nl=1\n\u2223\u2223\u0398ijl\u2223\u2223 , j = [1, n], i = [1, R]. (24)\nOne can also form a weight of a particular feature by the ratio319\nof \u03c0 values320\n\u03c9ijk =\n\u03c0ijk\u2211n\nr=1 \u03c0\ni\njk\n, i = [1, R], j = [1, n]. (25)\nIt is important to note that (24) and (25) represent sums only321\nand are thus easily performed online. The values of the weights322\n\u03c9\u2019s indicate the contribution of a particular input to the overall323\noutput and are thus a measure of the sensitivity of the outputs.324\nTherefore, an intuitive technique to simplify the inferential325\nsensor structure in terms of inputs can be proposed, which326\ngradually removes the input variables for which the weight \u03c9 is327\nnegligibly small across the rules (i.e., the inputs that contribute328\nlittle to the overall output)329\nIF\n(\n\u2203j\u2217\n\u2223\u2223\u2223\u03c9ij\u2217k < \u03b5 nmax\nj=1\n\u03c0ijk\n)\n, THEN (remove j\u2217) (26)\n1This technique is part of a pending patent: P. Angelov, Machine Learning\n(Collaborative Systems), WO2008053161, priority date: November 1, 2006;\nintern. filing date: October 23, 2007; http:\/\/v3.espacenet.com\/textdoc?DB=\nEPODOC&IDX=WO2008053161&F=0&QPN=WO2008053161\nFig. 3. Overall schematic representation of the eSensor.\nwhere \u03b5 denotes a coefficient (the suggested values are 330\n[0.03; 0.1], which means that this input variable contributes 331\n3%\u201310% to the overall output on average. 332\nThe rationale for the simplicity of this technique stems from 333\nthe fact that the consequents represent locally linear combina- 334\ntions and can thus be analyzed. It should be noted that, when 335\nan input is removed (which does not usually occur very often), 336\nhowever, the dimension is reduced by one, which is reflected 337\nin the covariance matrices (a line and a column are removed), 338\nand the dimensions of the focal points are also updated, as well 339\nas the recursive variables in (13), i.e., \u03b1, \u03b2, \u03b3, and \u03c7. 340\nThe main advantages of the proposed eSensor approach that 341\nmakes it suitable for implementation in the process industry are 342\nas follows. 343\n1) It self-develops, evolves, and thus reduces the develop- 344\nment and maintenance costs significantly. 345\n2) It can provide high prediction rates. 346\n3) It is one-pass and recursive and has low computational 347\nrequirements; thus, it is suitable for hardware \u201con-chip\u201d 348\nimplementations [24]. 349\n4) It is useful for online analysis and monitoring of the 350\nconcept shift using fuzzy-rule aging [see Figs. 1(b) and 2] 351\nand thus makes useful conclusions for possible faults and 352\nthe quality of the process. 353\n5) It can automatically select online a small subset of relevant 354\ninputs, thus fully automating the development process. 355\n6) It can have a multiple-input\u2013multiple-output structure and 356\nthus build a separate regression model for each output 357\nvariable. 358\nThe procedure for adaptive and evolving inferential self- 359\ncalibrating sensors, which we call eSensor, is presented by the 360\npseudocode provided in the Appendix (see also Fig. 3). 361\nIV. CASE STUDY: INFERENTIAL SENSORS FOR 362\nCHEMICAL-PROPERTY ESTIMATION 363\nThe capabilities of the proposed evolving inferential sensor 364\nare explored on four different industrial data sets for chemical- 365\nproperty estimation. All four cases include operating-regime 366\nchanges with different impacts on specific chemical properties 367\ndue to different levels of process change, various measurement 368\nmethods with different accuracies, and a different number of 369\npotential process variables, related to the inferred chemical 370\nproperties. However, all the changes create a challenge to 371\n6 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nFig. 4. Case study 1: Composition 1. Top plot\u2014output variable (composition 1).\nMiddle plot\u2014input variable (x1). Bottom plot\u2014input variable (x2).\nexisting inferential sensors with a fixed structure. As a basis372\nfor comparison, inferential sensors based on the most widely373\nused methods in commercial soft-sensor products, such as the374\nfeedforward NN of multilayer perceptron (MLP) type [3] and375\nPLS [1], were used, as well as a recently introduced algorithm376\nfor adaptive online NN, namely, DENFIS [31].377\nIn the chemical industry, inferential sensors are mostly used378\nto estimate chemical properties, measured by two techniques:379\n1) offline laboratory analysis of grab samples of the proper-380\nties and 2) pseudo real-time analysis with low frequencies by381\ngas chromatographs. The sampling period for the properties,382\nmeasured by laboratory analysis, is several hours, and accu-383\nracy depends on different measurement methods and varies384\nsubstantially. The sampling period of gas-chromatograph-based385\nproperties is much shorter (usually 15\u201330 min), and accuracy is,386\non average, an order of magnitude higher than that from offline387\nlaboratory measurements. Three of the selected cases are based388\non offline laboratory measurements, and one is based on gas389\nchromatographs. In the cases with laboratory measurements,390\ntwo different levels of accuracies have been selected. The level391\nof operating-condition change (which could be quantified by392\nthe percentage increase from the average level for 50 samples393\nbefore the process change to the average level for 50 samples394\nafter the change), as well as the number of process inputs, is395\nalso different.396\nThe first case, called Composition 1, is based on product-397\ncomposition estimation in a distillation tower. The measure-398\nments are based on laboratory analysis, taken every 8 h, and399\nthe method accuracy is low (2.2% measurement error), which,400\nby itself, introduced a measurement noise. Process data are401\nthe hourly averaged values around the time when the sample402\nfor the laboratory measurement has been taken. The output403\ncomposition and the two-input data (Fig. 4) include 309 records404\n(samples). As it is seen in the middle plot in Fig. 4, a signifi-405\ncant change in operating conditions has been introduced after406\nsample 127 by input 1. It is interesting to note that the two407\ninput variables that were selected online using the eSensor are408\nFig. 5. Input and output variables for case study 2. Top plot\u2014output variable\n(composition 2). Middle plot\u2014input variable (x1). Bottom plot\u2014input\nvariable (x2).\nFig. 6. Output variable for case study 3 (composition 3). There are seven\nselected inputs, and they are not shown for clarity purposes.\nthe most statistically significant process variables related to this 409\ncomposition. 410\nThe second case, called Composition 2, is based on product- 411\ncomposition estimation in the bottom of a distillation tower, 412\nwhich is different from the tower in Composition 1. The com- 413\nposition measurements are based on laboratory analysis, taken 414\nevery 8 h with a more accurate method of 1.3% measurement 415\nerror, and are less noisy. Process data are the hourly averaged 416\nvalues for the time when the sample for the laboratory measure- 417\nment has been taken. The output composition and the two-input 418\ndata (Fig. 5) include 308 records (samples), where a signifi- 419\ncant change in operating conditions has been introduced after 420\nsample 113 by input 2. Forty-seven different input variables 421\nwere measured using \u201chard\u201d (conventional) sensors. 422\nThe third case, called Composition 3, is based on product- 423\ncomposition estimation in the top of the same distillation tower 424\nas that in Composition 2. The output composition is shown in 425\nFig. 6, and it also includes 308 data samples with a significant 426\nchange in operating conditions (catalyzing agent replacement) 427\nintroduced after sample 113. The key differences of Case 3 428\nrelative to the other laboratory-measurement-based cases are as 429\nfollows: 1) higher level of operating-condition changes (275% 430\nincrease versus 220% increase for Case 1 and 232% increase 431\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 7\nFig. 7. Flowchart of the eSensor from the real-time software-realization point of view. Sleep mode means a default state expecting an external request. Note that\nall the stages of eSensor self-calibration are combined in one block on the right bottom part of the flowchart. This includes learning, the online input selection, as\nwell as cluster\/rule removal based on their age. The details of this procedure are provided in the Appendix.\nfor Case 2) and 2) larger number of process inputs (seven inputs432\nversus two inputs for both Cases 1 and 2).433\nThe fourth case is based on propylene estimation in the top434\nof a distillation tower, which is different from the distillation435\ntowers in the previous cases. In this case 2, process variables436\nthat are related to propylene are used as inputs in the model437\ndevelopment. The propylene measurements are based on gas-438\nchromatograph analysis, taken every 15 min. Process data are439\nthe snapshot minute values for the time when the measurement440\nhas been taken. The data [Fig. 1(a)] include 3000 records441\n(samples) with very broad range of operating conditions.442\nThese four test cases (provided and used by The Dow Chem-443\nical Company, Freeport, TX) cover most of the real issues in444\napplying inferential sensors in the advanced process industry,445\nsuch as noisy data, changing operating conditions, a large446\nnumber of correlated inputs, etc.447\nV. EXPERIMENTAL RESULTS AND ANALYSIS448\nThe main aim of the experimental study was to generate449\ninterpretable simple-to-understand models that are flexible and450\nadaptive (evolving with time and following the dynamics of the 451\ndata pattern) and are robust to noise and imprecise measurement 452\ndata using the proposed technique eSensor and to compare 453\nthese results with the available alternatives based on MLP-type 454\nNN, PLS, and a recently introduced evolving NN, i.e., DENFIS 455\n[31]. Precision was measured using root mean square errors 456\n(RMSE), as well as correlation [2]. The data in all experiments 457\nwere standardized. The eSensor starts with an empty fuzzy- 458\nrule base (no iniSensor) and generates its rule-base \u201con fly\u201d 459\nbased on the data that are provided sample by sample and 460\ndisregarded from the memory once processed. It also optimizes 461\nthe parameters during retraining periods (it self-calibrates). The 462\noutput prediction is calculated for every data sample and can be 463\nused at any time instant. Samples for recalibration are provided 464\nwhen they are available (see Fig. 7). DENFIS was also applied 465\nin an online mode. 466\nThe conventional inferential sensors (PLS and NN) that are 467\nnot adaptive were trained initially using the first quarter of the 468\navailable data samples, and afterward, they were retrained using 469\nsamples from the third quarter of the available data stream. The 470\nerror was only calculated on the second and fourth quarters of 471\n8 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nFig. 8. Evolution of the rule base of the eSensor (number of rules vary\nstarting from one\u2014the first sample\u2014finishing with six, and reaching at some\nstage 10).\nTABLE I\nVALIDATION RESULT USING ESENSOR AND REFERENCE APPROACHES\nthe data stream in all cases (PLS, NN, and eSensor) to allow472\ncompatibility of the results. Note that the eSensor can also473\nbe retrained anytime when a training sample is available, and474\nmoreover, its structure (rule based) will be preserved and only475\ngradually adapted\/evolved.476\nThe evolution of the fuzzy rule base is shown in Fig. 8, where477\nthe number of fuzzy rules generated is shown for the fourth case478\nstudy (propylene). In retraining the NN and PLS, the parameters479\n(weights) change completely and are not interpretable. Note480\nthat both PLS and NN require a separate training phase to build481\nthe model and, during this phase, use all training data, while482\nthe eSensor starts \u201cfrom scratch\u201d and uses each time the current483\ndata sample only plus the accumulated parameters \u03b2 and \u03c7j484\n[see (13)]. DENFIS also needs initialization and cannot start485\n\u201cfrom scratch\u201d [31]. In addition, it is also noniterative. The486\nfuzzy models that have automatically been extracted by the487\neSensor from the data streams are transparent and understand-488\nable by the operator of the process, yet they are robust and flex-489\nible. That means that the fuzzy-rule base that is extracted can be490\nstored or directly presented to the operators without post-491\nprocessing.492\nFig. 9. Case study 1. (a) Top plot\u2014prediction of composition 1 by the\neSensor compared to the real data taken by laboratory samples every hour.\n(b) Bottom plot\u2014selected input variables by the eSensor.\nAs seen from Table I, the eSensor significantly outperforms 493\nconventional inferential sensors, such as feedforward MLP and 494\nPLS-based approaches, as well as the adaptive DENFIS ones, 495\nin terms of precision. It also has significantly smaller number 496\nof rules as compared to DENFIS. The predicted versus the 497\nreal (laboratory or chromatography) data are shown for all case 498\nstudies in Figs. 9\u201312 in the top plots, together with input- 499\nvariable selection in the bottom plots in Figs. 9\u201312. 500\nOne can see in Fig. 14 the local regions generated in another 501\nexperiment (Composition 1), which are represented by dashed 502\nlines. 503\nAdditionally, the eSensor builds its entire structure, includ- 504\ning input-variable online ranking and selection, fuzzy-rule 505\ngeneration, and self-recalibration, and is easily interpretable 506\n(linguistic). One example of the fuzzy-rule base generated 507\nautomatically at the end of the training phase is given in the 508\nfollowing for Case 2: 509\nFinal Rule Base for Composition 2: 510\nR1: IF (x1 is around 183.85) AND (x2 is around 170.31), 511\nTHEN (y = 0.84\u2212 0.96x1 + 0.61x2). 512\nR2: IF (x1 is around 178.09) AND (x2 is around 166.84), 513\nTHEN (y = 0.87\u2212 0.98x1 + 0.54x2). 514\nR3: IF (x1 is around 172.70) AND (x2 is around 166.01), 515\nTHEN (y = 0.87\u2212 1.02x1 + 0.64x2). 516\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 9\nFig. 10. Case study 2. (a) Top plot\u2014prediction of composition 2 by the\neSensor compared to the real data taken by laboratory samples every 8 h.\n(b) Bottom plot\u2014selected input variables by the eSensor.\nThe interpretability of the fuzzy rules can be seen in Fig. 13,517\nwhere the membership functions of the fuzzy sets that describe518\npropylene polymerization are depicted. This illustrates for the519\ninput variable x1 for the constant second input x2 the rate with520\nwhich the particular input (feature) affects the output in each521\nof the local regions. Linear dependences are understandable for522\nthe human operators, and it is obvious from Fig. 13 that there523\nare several linear dependences that are active for the values of524\nx1 (for example) around 25 and 40.525\nDuring the evolution of the rule base, the age of the clusters\/526\nrules is being monitored. Fig. 1(b) shows the age evolution of527\nthree rules from the rule base for propylene. Rule 1 is used528\nextensively around sample 1400, and its age drops significantly529\naround the same sample. At the same time, the age rate (first530\nderivative of the age) for rule 4 is positive and increasing,531\nwhich means that this particular fuzzy rule is getting older532\n(aging). Such changes indicate that there is a drift in the data533\npattern, and age rate provides a mathematical tool to detect this534\nautomatically. A similar case occurs at around sample 2650,535\nwhen a second significant drift is observed. Rule 3 is rarely used536\nafter its generation since its age rate is close to one during the537\nwhole process. This rule has been later removed automatically538\nfrom the rule base.539\nVI. CONCLUSION540\nA new type of adaptive, self-calibrating, and self-developing541\ninferential sensor that is based on the EFM of Takagi\u2013Sugeno542\nFig. 11. Case study 3. (a) Top plot\u2014prediction of composition 3 by the\neSensor compared to the real data taken by laboratory samples every 8 h.\n(b) Bottom plot\u2014selected input variables by the eSensor.\ntype (ETS) has been introduced in this paper and investigated 543\non a range of case studies from the chemical and process in- 544\ndustries. The proposed eSensors can be trained \u201con fly\u201d starting 545\neither \u201cfrom scratch\u201d or being primed with an initial rule base. 546\nThe results with data from real chemical processes demonstrate 547\nthat the proposed adaptive and evolving inferential sensor is 548\nvery flexible (it develops its model structure and adapts to 549\nsudden changes automatically, such as the introduced change 550\nof operating condition after sample 127 for Composition 1 551\nand after sample 113 for Composition 2). It does not need 552\nany pretraining and specific maintenance and thus reduces the 553\nlife-cycle costs significantly. The structure of the proposed 554\neSensor is transparent because it is composed of linguistic 555\nfuzzy rules that can be understood by an operator. The proposed 556\nevolving inferential sensor is also very robust. An illustration of 557\nthis for the example of Composition 3 was provided. Finally, 558\ndue to the recursive calculations, the proposed technique is 559\ncomputationally very light (the computational complexity is 560\non the order of O(n\u00d7R), where n is the number of inputs 561\n(in studied cases 2 or 7) and R is the number of fuzzy rules 562\ngenerated (usually a small number due to the very conservative 563\nrequirement for generating new rules based on the data density 564\n(15); in the studied cases, the number of fuzzy rules generated 565\nwas between two and six). It is important to note that the 566\nproposed eSensor is suitable for a range of process indus- 567\ntries, including, but not limited to, chemical, biotechnology, 568\noil refining, etc. 569\n10 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nFig. 12. Case study 4. (a) Top plot\u2014prediction of propylene by the eSensor\ncompared to the real data taken by the gas-chromatography test every 15 min.\n(b) Bottom plot\u2014selected input variables by the eSensor.\nAPPENDIX570\nAlgorithm: eSensor571\nBegin eSensor572\nInitialize eSensor by the first data sample, z1 = [x1, y1];573\n(D1)1 \u2190 1574\n(or by iniSensor if it exists)575\nDO for each data sample WHILE data are acquired576\nRead the measurable (by hard sensors) variables, xk;577\nCalculate the membership to each of the fuzzy sets by (4);578\nCalculate the rule firing strength by (6) and (7);579\nEstimate the outputs, y\u02c6k by (1);580\nAt the next time step (k \u2190 k + 1)581\nIF (mode = \u2018self-calibration\u2019)582\nGet the real value of the estimated variables, yk;583\nCalculate the density of the data sample, Dk(zk) by (13);584\nUpdate the density of the existing focal points, Dk(zi\u2217),585\nby (14);586\nIF (15) holds THEN587\nAdd a new focal point based on the new data point, (16);588\nInitiate its density to one, (17);589\nUpdate spreads of membership functions by (5);590\nIF (18) holds THEN Remove the rules for which it holds;591\nELSE (IF (15) holds)592\nIgnore (do not change the cluster structure);593\nUpdate spreads of membership functions by (5);594\nUpdate the age of the clusters by (10);595\nFig. 13. (a) Membership functions of two of the fuzzy sets that form the\nantecedent part of the fuzzy rules of the eSensor at the end of the training for\ncase study 4 (propylene). (b) Local linear models that form the consequent part\nof the fuzzy rules of the eSensor at the end of the training.\nFig. 14. Clusters that form the antecedent part of the fuzzy rules and illustrate\nthe local areas of validity of the rules.\nUpdate the input weights by (25) 596\nRemove the old rules (rules for which (11) holds); 597\nRemove the inputs with low weight (26). 598\nEND (IF THEN ELSE) 599\nUpdate the consequent parameters by (19) and (20). 600\nEND (self-calibration) 601\nEND (DO . . . WHILE) 602\nEND (eSensor) 603\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 11\nACKNOWLEDGMENT604\nThe authors would like to thank Dr. X. Zhou for performing605\nthe numerical experiments and producing some of the figures.606\nREFERENCES607\n[1] L. Fortuna, S. Graziani, A. Rizzo, and M. G. Xibilia, Soft Sensors for608\nMonitoring and Control of Industrial Processes. London, U.K.:609\nSpringer-Verlag, 2007.610\n[2] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statis-611\ntical Learning: Data Mining, Inference and Prediction. Heidelberg,612\nGermany: Springer-Verlag, 2001.613\n[3] R. Rallo, J. Ferre-Gine, A. Arenas, and F. Giralt, \u201cNeural virtual sensor614\nfor the inferential prediction of product quality from process variables,\u201d615\nComput. Chem. Eng., vol. 26, no. 12, pp. 1735\u20131754, Dec. 2002.616\n[4] R. Klinkenberg and T. Joachims, \u201cDetection concept drift with support617\nvector machines,\u201d in Proc. 7th ICML, 2000, pp. 487\u2013494.618\n[5] A. Kordon and G. Smits, \u201cSoft sensor development using genetic pro-619\ngramming,\u201d in Proc. GECCO, San Francisco, CA, 2001, pp. 1346\u20131351.620\n[6] F. Hopner and F. Klawonn, \u201cObtaining interpretable fuzzy models from621\nfuzzy clustering and fuzzy regression,\u201d in Proc. 4th Int. Conf. Knowl.-622\nBased Intell. Eng. Syst., Brighton, U.K., 2000, pp. 162\u2013165.623\n[7] P. Angelov, Evolving Rule-Based Models: A Tool for Design of Flexible624\nAdaptive Systems. Berlin, Germany: Springer-Verlag, 2002.625\n[8] G. Widmer and M. Kubat, \u201cLearning in the presence of concept drift and626\nhidden contexts,\u201d Mach. Learn., vol. 23, no. 1, pp. 69\u2013101, Apr. 1996.627\n[9] P. Angelov and D. Filev, \u201cAn approach to on-line identification of evolving628\nTakagi\u2013Sugeno models,\u201d IEEE Trans. Syst., Man, Cybern. B, Cybern.,629\nvol. 34, no. 1, pp. 484\u2013498, Feb. 2004.630\n[10] P. Angelov and X. Zhou, \u201cEvolving fuzzy systems from data streams in631\nreal-time,\u201d in Proc. Int. Symp. Evolving Fuzzy Syst., Ambleside, U.K.,632\nSep. 7\u20139, 2006, pp. 29\u201335.633\n[11] J. Macias, P. Angelov, and X. Zhou, \u201cPredicting quality of the crude oil634\ndistillation using evolving Takagi\u2013Sugeno fuzzy models,\u201d in Proc. Int.635\nSymp.Evolving Fuzzy Syst., Ambleside,U.K.,Sep. 7\u20139, 2006, pp. 201\u2013207.636\n[12] P. Angelov and X. Zhou, \u201cOn line learning fuzzy rule-based system struc-637\nture from data streams,\u201d in Proc. IEEE Int. Conf. Fuzzy Syst. Within IEEE638\nWorld Congr. Comput. Intell., Hong Kong, Jun. 1\u20136, 2008, pp. 915\u2013922.639\n[13] A. Kordon, G. Smits, A. Kalos, and E. Jordaan, \u201cRobust soft sensor640\ndevelopment using GP,\u201d in Nature-Inspired Methods in Chemometrics,641\nR. Leardi, Ed. Amsterdam, The Netherlands: Elsevier, 2003, pp. 69\u2013108.642\n[14] P. Angelov and R. Buswell, \u201cIdentification of evolving rule-based mod-643\nels,\u201d IEEE Trans. Fuzzy Syst., vol. 10, no. 5, pp. 667\u2013677, Oct. 2002.644\n[15] K. J. Astroem and B. Wittenmark, Adaptive Control. Reading, MA:645\nAddison-Wesley, 1989.646\n[16] T. Takagi and M. Sugeno, \u201cFuzzy identification of systems and its ap-647\nplication to modeling and control,\u201d IEEE Trans. Syst., Man, Cybern.,648\nvol. SMC-15, no. 1, pp. 116\u2013132, Jan.\/Feb. 1985.649\n[17] L.-X. Wang, \u201cFuzzy systems are universal approximators,\u201d in Proc.650\nFUZZ-IEEE, San Diego, CA, 1992, pp. 1163\u20131170.651\n[18] R. Yager and D. Filev, Essentials of Fuzzy Modelling and Control.652\nNew York: Wiley, 1994.653\n[19] P. Angelov and D. Filev, \u201cSimpl_eTS: A simplified method for learning654\nevolving Takagi\u2013Sugeno fuzzy models,\u201d in Proc. IEEE Int. Conf. Fuzzy655\nSyst., Reno, NV, May 22\u201325, 2005, pp. 1068\u20131073.656\n[20] P. Domingos and G. Hulten, \u201cCatching up with the data: Research issues657\nin mining data streams,\u201d in Proc. Workshop Res. Issues Data Mining658\nKnowl. Discov., Santa Barbara, CA, 2001.659\n[21] E. Y. Nagai and L. V. R. Arruda, \u201cSoft sensor based on fuzzy model identi-660\nfication,\u201d inProc. 16th IFAC World Congr., Prague, Czech Republic, 2005.661\n[22] W. Yan, H. Shao, and X. Wang, \u201cSoft sensing modeling based on support662\nvector machine and Bayesian model selection,\u201d Comput. Chem. Eng.,663\nvol. 28, no. 8, pp. 1489\u20131498, Jul. 2004.664\n[23] J. Liu, \u201cOn-line soft sensor for polyethylene process with multiple produc-665\ntion grades,\u201d in Proc. 16th IFAC World Congr., Prague, Czech Republic,666\n2005.667\n[24] P. Angelov and M. Everett, \u201cEvoMap: Evolving mapping\u2014668\nImplementation of evolving clustering on FPGA,\u201d Lancaster Univ.,669\nLancaster, U.K., 2005.670\n[25] X. Zhou and P. Angelov, \u201cAn approach to autonomous self-localization of671\na mobile robot in completely unknown environment using evolving fuzzy672\nrule-based classifier,\u201d in Proc. 1st IEEE Int. Conf. Comput. Intell. Appl.673\nDefense Security, Honolulu, HI, Apr. 1\u20135, 2007, pp. 131\u2013138.674\n[26] A. Ferreyra and J. J. Rubio, \u201cA new on-line self-constructing neural fuzzy675\nnetwork,\u201d in Proc. 45th IEEE Conf. Decision Control, Dec. 13\u201315, 2006,676\npp. 3003\u20133009.677\n[27] P. S. Lee and A. L. Dexter, \u201cA fuzzy sensor for measuring the mixed air 678\ntemperature in air handling units,\u201d Measurement, vol. 37, no. 1, pp. 83\u201393, 679\nJan. 2005. 680\n[28] M. J. Arauzo-Bravo, J. M. Cano-Izquierdo, E. Gomez-Sanchez, 681\nM. J. Lopez-Nieto, Y. A. Dimitriadis, and J. Lopez-Coronado, \u201cAutomati- 682\nzation of a penicillin production process with soft sensors and an adaptive 683\ncontroller based on neuro-fuzzy systems,\u201d Control Eng. Pract., vol. 12, 684\nno. 9, pp. 1073\u20131090, Sep. 2004. 685\n[29] R. M. French, \u201cCatastrophic forgetting in connectionist networks,\u201d Trends 686\nCogn. Sci., vol. 3, no. 4, pp. 128\u2013135, Apr. 1999. 687\n[30] J. Kelly, P. Angelov, M. J. Walsh, H. M. Pollock, M. A. Pitt, 688\nP. L. Martin-Hirsch, and F. Martin, \u201cA self-learning fuzzy classifier with 689\nfeature selection for intelligent interrogation of mid-IR spectroscopy data 690\nderived from different categories of exfoliative cervical cytology,\u201d Int. 691\nJ. Comput. Intell. Res.\u2014Special Issue on the Future of Fuzzy Systems 692\nResearch, vol. 4, no. 4, pp. 392\u2013401, Dec. 2008, invited paper. 693\n[31] N. K. Kasabov and Q. Song, \u201cDENFIS: Dynamic evolving neural-fuzzy 694\ninference system and its application for time-series prediction,\u201d IEEE 695\nTrans. Fuzzy Syst., vol. 10, no. 2, pp. 144\u2013154, Apr. 2002. 696\nPlamen Angelov (M\u201999\u2013SM\u201904) received the 697\nM.Eng. degree in electronics and automation from 698\nSofia Technical University, Sofia, Bulgaria, in 1989 699\nand the Ph.D. degree in optimal control from the 700\nBulgarian Academy of Sciences, Sofia, in 1993. 701\nHe spent over ten years as a Research Fellow 702\nworking on computational intelligence and control. 703\nDuring 1995\u20131996, he was with Hans-Knoell In- 704\nstitute, Jena, Germany. In 1997, he was a Visiting 705\nResearcher with the Catholic University of Leuven, 706\nLeuven, Belgium. From 1998\u20132003, he was with 707\nLoughborough University, U.K. In 2003, he was appointed as a Lecturer with 708\nLancaster University, U.K. In 2007, he was a Visiting Professor with University 709\nof Applied Sciences Braunschweig\/Wolfenb\u00fcttel, Germany. He is currently a 710\nSenior Lecturer (Associate Professor) with Lancaster University, Lancaster, 711\nU.K., where he is with the Intelligent Systems Research Laboratory. He has 712\nauthored or coauthored over 100 peer-reviewed publications, including the 713\nbook entitled Evolving Rule Based Models: A Tool for Design of Flexible 714\nAdaptive Systems (Springer-Verlag, 2002), and over 30 journal papers, and he 715\nis a holder of a patent in machine learning (2006). He is co-Editor-in-Chief of 716\nthe Evolving Systems journal (Springer) and a Member of the editorial boards 717\nof three other international scientific journals. 718\nDr. Angelov is a member of the Autonomous Systems Working Group of 719\nthe Northwest Science Council of the U.K. and the Technical Committee (TC) 720\non Fuzzy Systems, the Vice Chair of the TC on Standards, Computational 721\nIntelligence Society, and the founding Chair of the Task Force on Adaptive 722\nFuzzy Systems. He serves regularly on the technical\/program committees 723\nof leading international conferences on different aspects of computational 724\nintelligence. 725\nArthur Kordon (M\u201991) received the M.Eng. degree 726\nfrom Varna Technical University, Varna, Bulgaria, 727\nin 1974 and the Ph.D. degree from Sofia Technical 728\nUniversity, Sofia, Bulgaria, in 1990, both in electrical 729\nengineering. 730\nHe spent more than 30 years in different posi- 731\ntions in the industry and academe, developing and 732\napplying different methods of advanced control and 733\ncomputational intelligence. He is currently a Data 734\nMining and Modeling Leader with the Data Mining 735\nand Modeling Group, The Dow Chemical Company, 736\nFreeport, TX. He is an internationally recognized expert in applying computa- 737\ntional intelligence technologies in the industry. He has successfully introduced 738\nseveral novel technologies for improved manufacturing and new product de- 739\nsign, such as robust inferential sensors, automated operating discipline, and 740\naccelerated fundamental model building. He has published more than 60 peer- 741\nreviewed papers, including the book Applying Computational Intelligence: 742\nHow to Create Value (Springer-Verlag, 2009) and nine book chapters in the 743\narea of applied computational intelligence and advanced control. His research 744\ninterests include application issues of computational intelligence, robust empir- 745\nical modeling, intelligent process monitoring and control, and data mining. 746\nDr. Kordon is a member of the Technical Committee on Evolutionary 747\nComputation. He regularly serves on the program committees of leading 748\ninternational conferences related to computational intelligence. 749\nIEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS 1\nAdaptive Inferential Sensors Based on\nEvolving Fuzzy Models\n1\n2\nPlamen Angelov, Senior Member, IEEE, and Arthur Kordon, Member, IEEE3\nAbstract\u2014A new technique to the design and use of inferential4\nsensors in the process industry is proposed in this paper, which5\nis based on the recently introduced concept of evolving fuzzy6\nmodels (EFMs). They address the challenge that the modern7\nprocess industry faces today, namely, to develop such adaptive and8\nself-calibrating online inferential sensors that reduce the mainte-9\nnance costs while keeping the high precision and interpretability\/10\ntransparency. The proposed new methodology makes possible11\ninferential sensors to recalibrate automatically, which reduces12\nsignificantly the life-cycle efforts for their maintenance. This is13\nachieved by the adaptive and flexible open-structure EFM used.14\nThe novelty of this paper lies in the following: 1) the overall15\nconcept of inferential sensors with evolving and self-developing16\nstructure from the data streams); 2) the new methodology for17\nonline automatic selection of input variables that are most relevant18\nfor the prediction; 3) the technique to detect automatically a shift19\nin the data pattern using the age of the clusters (and fuzzy rules);20\n4) the online standardization technique used by the learning pro-21\ncedure of the evolving model; and 5) the application of this inno-22\nvative approach to several real-life industrial processes from the23\nchemical industry (evolving inferential sensors, namely, eSensors,24\nwere used for predicting the chemical properties of different25\nproducts in The Dow Chemical Company, Freeport, TX). It should26\nbe noted, however, that the methodology and conclusions of this27\npaper are valid for the broader area of chemical and process indus-28\ntries in general. The results demonstrate that well-interpretable29\nand with-simple-structure inferential sensors can automatically be30\ndesigned from the data stream in real time, which predict various31\nprocess variables of interest. The proposed approach can be used32\nas a basis for the development of a new generation of adaptive and33\nevolving inferential sensors that can address the challenges of the34\nmodern advanced process industry.35\nIndex Terms\u2014Concept shift in data streams, evolving fuzzy36\nsystems, fuzzy-rule aging, inferential sensors, learning and adap-37\ntation, Takagi\u2013Sugeno (TS) fuzzy models.38\nI. INTRODUCTION39\nINFERENTIAL sensors [1], [21], [23], [27], [28] are able to40 provide accurate real-time estimates of difficult-to-measure41\nparameters or expensive measurements (like emissions, bio-42\nmass, melt index, etc.) from the available cheap sensors43\n(like temperatures, pressures, and flows). Different empirical44\nManuscript received October 17, 2008; revised March 27, 2009 and June 26,\n2009. This paper was recommended by Associate Editor T. H. Lee.\nP. Angelov is with the Intelligent Systems Research Laboratory, Infolab21,\nLancaster University, LA1 4WA Lancaster, U.K. (e-mail: p.angelov@lancaster.\nac.uk).\nA. Kordon is with The Dow Chemical Company, Freeport, TX 77541 USA\n(e-mail: AKKordon@Dow.com).\nColor versions of one or more of the figures in this paper are available online\nat http:\/\/ieeexplore.ieee.org.\nDigital Object Identifier 10.1109\/TSMCB.2009.2028315\nmethods have been used to develop inferential sensors, such 45\nas statistical models [2], neural networks (NNs) [3], support- 46\nvector machines [4], [22], and genetic programming [5], [13]. 47\nModel-based techniques for process-quality monitoring [1] of- 48\nten provide a valuable advantage over conventional approaches 49\nthat rely on manual intervention and laboratory tests. Such 50\nmodels, however, are costly to build and maintain since the 51\nenvironment in which an industrial process takes place is dy- 52\nnamically changing, the equipment is getting older and conta- 53\nminated or being replaced, raw materials usually alter in quality, 54\nand the complexity of processes leads to a number of aspects of 55\nthe process being ignored by the models. A crucial weakness 56\nof model-based approaches is that they do not take into account 57\nthe shift and drift in the data pattern that is related to the fact that 58\nthese models are developed offline under certain conditions. 59\nEven minor process changes outside these conditions may lead 60\nto unacceptable performance deterioration that requires manual 61\nmaintenance and recalibration. 62\nThe challenge is to develop inferential sensors with flexible 63\nyet interpretable structure [6] and adaptive parameters. The 64\ngradual evolution of the model structure (fuzzy rules) will 65\nmean that a retraining of the sensor when required will only 66\nmodify (add, remove, or replace) one or few fuzzy rules [7]. 67\nContrast this to a possible option of iteratively retraining an NN, 68\nwhich, in effect, will lead to a completely new NN and a loss of 69\nprevious information [29]. Ideally, we would require inferential 70\nsensors that can automatically recalibrate and detect shifts and 71\ndrifts in the data stream [4], [8]. One such methodological 72\nframework is presented by the evolving Takagi\u2013Sugeno (ETS) 73\nfuzzy models [9], [10]. In this paper, we use this framework and 74\nbuild upon it a methodological concept for evolving inferential 75\nsensors, namely, eSensors, which is new and original. The 76\nmain contributions of this paper include the following: 1) the 77\noverall concept of eSensors; 2) the new methodology for online 78\nautomatic selection of input variables that are most relevant for 79\nthe prediction; 3) the technique to detect automatically a shift in 80\nthe data pattern using the age of the clusters (and fuzzy rules); 81\n4) the online standardization technique used by the learning 82\nprocedure of the evolving model; and 5) the application of this 83\ninnovative approach to four real-life industrial processes from 84\nthe chemical industries. 85\nII. ADAPTIVE INFERENTIAL SENSORS BASED ON EFM 86\nA. Principles of EFM 87\nEvolving fuzzy models (EFMs) were first introduced as a 88\ntechnique for online adaptation of fuzzy-rule-based systems\u2019 89\n1083-4419\/$26.00 \u00a9 2009 IEEE\n2 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nstructure (rule-based fuzzy sets), as well as their parameters90\n[7], [14]. In that respect, they make a step further by comparing91\nthe aforementioned technique to the well-established adaptive-92\nsystem theory [15], which is applicable to linear systems only93\nand to a small circle of nonlinear systems. EFM systems are94\nnonlinear, linguistically interpretable, yet adaptable online in a95\n(local) least squares (LS) sense. The approach was further re-96\nfined for the specific case of the so-called TS fuzzy models [16]97\nby introducing a fully recursive algorithm called ETS [9], [10].98\nETS fuzzy models are particularly suited as a framework for99\naddressing the challenges that the process industry faces nowa-100\ndays. They can provide the algorithmic backbone of systems101\nthat can be implemented as embedded autonomous intelligent102\nsensors with self-calibration and self-maintenance capabilities.103\nThe basic idea of ETS is to allow the TS fuzzy system struc-104\nture to grow, shrink, adapt, and self-develop in an automatic105\nfashion learned online from the data streams in a locally optimal106\nway. TS fuzzy systems [16] are very attractive due to their dual107\nnature\u2014they combine the fuzzy linguistic antecedent part with108\na linear functional consequent part, thus being locally linear109\nbut nonlinear overall and being proven universal approximators110\n[17]. The antecedent part is a linguistic representation of a111\npartition of the measurable-variable space into fuzzily overlap-112\nping regions (see Fig. 14). The linguistic antecedent parts of113\nTS fuzzy systems make them attractive for human operators114\n(compared to NN, SVM, or polynomial models, for example).115\nThe architecture of an ETS fuzzy system is based on fuzzily116\nweighted local linear models of the following form [9], [10]:117\nLM i : yi = xT\u0398 (1)\nwhere LM i denotes the ith local model, i = 1, 2, . . . , N ; x =118\n[1, x1, x2, . . . , xn]T represents the (n + 1)\u00d7 1 extended vector119\nof measurable variables; yi = [yi1, yi2, . . . , yim]T is the m\u00d7 1120\nvector of estimated variables; and \u0398i = [\u03b8i0 \u03b8i1 \u00b7 \u00b7 \u00b7 \u03b8in]T121\ndenotes the matrix of consequent parameters.122\nAll of the N local linear models describe the process in a123\nlocal area defined by fuzzy rules and are blended in a fuzzy124\nway to produce the overall output that is nonlinear in terms of125\nmeasurable variables x\u2019s but is linear in terms of parameters \u0398\u2019s126\ny = \u03c8T\u0398 (2)\nwhere \u03c8 = [\u03bb1xT , \u03bb2xT , . . . , \u03bbNxT ]T is a vector of127\nmeasurable variables that are weighted by the normalized128\nactivation levels of the rules, \u03bbi, i = 1, 2, . . . , N , with \u03bbi129\nbeing the normalized firing level of the ith fuzzy rule that is a130\nfunction of x, i.e., \u03bbi(x).131\nThe overall TS fuzzy model can then be described by a set of132\nfuzzy rules of the following form:133\nRi : IF (x1 is around xi\u22171 ) AND, . . .\nAND\n(\nxn is around xi\u2217n\n)\n, THEN (yi = LM i) (3)\nwhere Ri denotes the ith fuzzy rule, with i = [1, N ]; N is the134\nnumber of fuzzy rules; (xj is around xi\u2217j ) denotes the jth fuzzy135\nset of the ith fuzzy rule, with j = 1, 2, . . . , n; and xi\u2217 is the136\nfocal point of the ith-rule antecedent part.137\nThe degree of membership of a certain data point (x) to any 138\nof the fuzzy rules can be described by a Gaussian centered at its 139\nfocal point 140\n\u03bci = e\n\u2212\n\u2211n\nj=1(xj\u2212x\ni\u2217\nj )\n2\n2(\u03c3ij)\n2\n(4)\nhaving a spread that is learned based on the data variance [10] 141\n(\nvijk\n)2 = \u03c1(vij(k\u22121)\n)2\n+ (1\u2212 \u03c1) 1\nnik\nni\nk\u2211\nl=1\n\u2016zi\u2217 \u2212 zl\u20162j ,\nvij1 = 1, \u03c3\ni\njk \u2190 vijk (5)\nwhere vijk denotes the variance of the data in the ith cluster 142\nin the jth dimension (jth variable) calculated at the kth time 143\ninstant, \u03c3ijk represents the spread of the Gaussian of the jth 144\nfuzzy set of the ith fuzzy rule calculated at the kth time instant, 145\nz = [x, y]T depicts the overall data vector, and nik denotes the 146\nsupport of the ith cluster\/rule\u2014the number of samples that are 147\nassociated with it based on the distance to the focal point. 148\nThe firing strength of a fuzzy rule is determined by a t-norm, 149\nwhich can be represented as inner product [18] 150\n\u03c4 i =\nn\u220f\nj=1\n\u03bcij(xj) (6)\nand is normalized so that it sums to one 151\n\u03bbi =\n\u03c4 i\u2211N\nj=1 \u03c4j\n. (7)\nB. Monitoring the Quality of the Rule Base 152\nOne can monitor and analyze online the quality of the 153\nclusters that are formed and the fuzzy rules, respectively\u2014for 154\nexample, the number of points that support them or their age 155\n[19]. The support of the rules is determined by a simple count- 156\ning of the samples that are associated with the nearest focal 157\npoint 158\nnik+1=n\ni\nk+1, i=arg\nN\nmin\ni=1\n\u2016xk\u2212xi\u2217\u2016, k=2, 3, . . . . (8)\nThe support is initiated by one at the moment a rule is created 159\nnN+1k \u2190 1, k = 2, 3, . . . . (9)\nIn this paper, we introduce a recursive formula to calculate 160\nthe age of the ith cluster\/rule calculated at the kth moment in 161\ntime (data sample) 162\nAik = k \u2212\n1\nnik\n(\nk \u2212Aik\u22121 + knik\n)\n(10)\nwhere kl is the time index when the data sample was read. 163\nThis follows from 164\nAik = k \u2212\n1\nnik\nni\nk\u2211\nl=1\nkl A\ni\nk\u22121 = k \u2212\n1\nnik\u22121\nni\nk\u22121\u2211\nl=1\nkl.\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 3\nFig. 1. (a) Top plot\u2014output variable in case study 4\u2014polymerization;\n(b) Bottom plot\u2014age of the fuzzy rules describing the propylene-polymerization\nprocess. The two instants when a shift in the data pattern occurs are marked.\nThis corresponds to a change in the aging rate seen from the bottom plot.\nFrom there, we get165\nni\nk\u22121\u2211\nl=1\nkl =\n(\nk \u2212Aik\u22121\n)\nAik = k \u2212\n1\nnik\n\u239b\n\u239d\nni\nk\u22121\u2211\nl=1\nkl + kni\nk\n\u239e\n\u23a0 .\nCombining these two expressions, we arrive at (10).166\nEach time a new rule is created, its age is initiated by the167\nindex of the data sample that is used as a focal point of that rule.168\nEach time a new data sample is associated to an existing rule169\n(the distance from a sample to that focal point is smaller than170\nthat to any other focal points), the age of that rule gets smaller.171\nIf no sample is assigned to a rule, it gets older by one. Note that172\nthe age of a fuzzy rule can take values from the [0; k] range.173\nThis is shown in Fig. 1 in the case of propylene estimation.174\nFrom the top plot, one can see that there are three different175\nstages of that process. The aging of three of the six fuzzy rules176\n(rules ## 1, 3, and 4) are depicted in the bottom plot. One can177\nsee that precisely at the moment of a shift in the data pattern178\n(a new phase), the aging of the rules is affected. By monitoring179\nthe derivative of A (i.e., aging rate), one can automatically180\ndetect such changes and respond by adapting the learning181\nmechanism or rate.182\nNote that the age rate of rule #1 becomes negative before it183\nincreases again. This illustrates the so-called concept shift and184\nis an indication of a transition from one operating state (which185\naffects the data density in one local region, i.e., around the focal186\npoint of this rule) to another one (which affects the data density187\nin another local region).188\nFig. 2. Evolution of the age and shift in the data pattern, resulting in forming\nnew clusters\/rules for case study 2. The inflex points correspond to a shift of the\ndata from one cluster to another existing cluster or to a newly formed cluster\n(as marked in the figure for each inflex point).\nThe age of the fuzzy rules (and the derivative of their age in 189\nterms of the sampling period (k), which represents the aging 190\nrate) can be very useful for online analysis of the concept 191\nshift in the data stream [12]. An eSensor can detect a concept 192\nshift [20] online by the rate of aging and the instances when 193\nit changes [the inflex points on the age evolution diagram that 194\ncorresponds to the change of the sign of the aging rate indicate 195\na shift (see Fig. 2)]. The aging corresponds to the first derivative 196\nof the age and is graphically represented by the slope of the age 197\nevolution lines in terms of the horizontal axis [see Fig. 1(b)]. 198\nIn this paper, we use the following principle for the update 199\nof the rule base by removing the older rules (rules whose age 200\nexceeds the mean age for that rule by more than the standard- 201\ndeviation [2] value calculated recursively up to that moment\/ 202\nsample): 203\nIF\n(\nAi>Ai+std(Ai)\n)\n, THEN(remove Ri;N\u2190N\u22121) (11)\nwhere Ai denotes the mean age (it is also denoted in Fig. 1(b) 204\nby a dash-dotted line) and std(Ai) represents the standard 205\ndeviation of the age of the ith rule. 206\nC. Evolving the Structure of the Sensor From the Data Stream 207\nThe online design and learning of the eSensor are outlined 208\nhere. Learning is based on decomposition of the identification 209\nproblem into the following [7], [9], [10]: 1) fuzzy-rule-based 210\nstructure design and 2) parameter identification. Both of these 211\nsubproblems can be performed in online mode during one time 212\nstep (per sample). The first subproblem, i.e., structure identifi- 213\ncation, can be approached using evolving clustering in the data 214\nspace [9], [10], [12]. This partitioning leads to forming infor- 215\nmation granules, described linguistically by fuzzy sets. Thus, 216\nit serves the transformation of the data into primitive forms 217\nof knowledge. The basic notion of the partitioning algorithm 218\nis that of the data density [26], which is defined as a Cauchy 219\nfunction over the sum of distances d\u2019s between a certain data 220\nsample zi and all other data samples in the feature space [10] 221\nDk(zk) =\n1\n1 + v2k\n(12)\n4 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nwhere v2k = (1\/k \u2212 1)\n\u2211k\u22121\ni=1 d\n2(zk, zi) is the variance of the222\ndata [2].223\nData-space partitioning is based on the following principle:224\nThe point with the highest density in the data space is chosen225\nto be the focal point, and the antecedent of the first fuzzy226\nrule is formed around it. In this way, fuzzy rules with high227\ndescriptive power and generalization capabilities are generated.228\nThe density can be recursively calculated using the current data229\npoint (zjk) and (n + 1) memorized quantities only (\u03b2k and \u03c7jk,230\nj = [1, n]) [10]231\nDk(zk) = (k \u2212 1) (\u03b1k(k \u2212 1) + \u03b2k \u2212 2\u03b3k + (k \u2212 1))\u22121 ,\nk = 2, 3, . . . (13)\nwhere \u03b1k =\n\u2211n+1\nj=1 (z\nj\nk)\n2; \u03b2k = \u03b2k\u22121 + \u03b1k\u22121, with \u03b21 = 0;232\nand \u03b3k =\n\u2211n+1\nj=1 z\nj\nk\u03c7\nj\nk, with \u03c7\nj\nk = \u03c7\nj\nk\u22121 + z\nj\nk\u22121 and \u03c7\nj\n1 = 0.233\nEach time a new data sample is read, it affects the data234\ndensity of the existing focal points and can be updated by [10]235\nDk(zi\u2217) =\n(k \u2212 1)Dk\u22121(zi\u2217)\nk \u2212 2 + Dk\u22121(zi\u2217) + Dk\u22121(zi\u2217)d(zi\u2217, zk) ,\nk = 2, 3, . . . (14)\nwhere d(zi\u2217, zk) denotes the distance between the ith focal236\npoint and the current point.237\nOnce the densities of the new coming data sample and of238\neach of the previously existing focal points are recursively239\nupdated, they are compared. If the new coming data sample240\nhas a higher density than any of the previously existing focal241\npoints, then this means that it is a good candidate to become a242\nfocal point of a new rule (a new local linear model) because it243\nhas high descriptive power and generalization potential244\nDk(zk) > Dk(zi\u2217) \u2200 i\u2217 \u2208 N. (15a)\nIf the new coming data sample has a lower density than any245\nof the previously existing focal points, then this means that it246\nis also a good candidate to become a focal point of a new rule247\n(a new local linear model) because it improves the coverage of248\nthe whole data space [12]249\nDk(zk) < Dk(zi\u2217) \u2200 i\u2217 \u2208 N. (15b)\nForming a new fuzzy rule around a newly added prototype250\nleads to a gradual increase of the size of the rule base, which is251\nwhy this approach is called \u201cevolving\u201d252\nz(N+1)\u2217 \u2190 zk. (16)\nThe density of the newly generated rule is set to one [10]253\ntemporarily (it will be updated to take into account later the254\ninfluence of each new coming data sample on the generalization255\npotential of this particular focal point)256\nDk\n(\nz(N+1)\u2217\n)\n\u2190 1. (17)\nTo increase the interpretability and update of the rule base,257\none needs also to remove the previously existing rules that258\nbecome ambiguous after insertion of the new rule. Therefore, 259\neach time a new fuzzy rule is added, it is also checked whether 260\nany of the already existing prototypes in the rule base are 261\ndescribed by this rule to a degree that is higher than 50% 262\n\u2203i, i=[1, N ]; \u03bcji (zN+1) > 0.5 \u2200 j, j=[1, n]. (18)\nIf any of the previously existing focal points satisfy this con- 263\ndition, the rules that correspond to them are being removed 264\n(replaced by the newly formed rule) [9], [19]. The spreads of 265\nthe membership functions are also recursively updated by (5). 266\nD. Self-Learning the eSensor 267\nOnce the antecedent part of the TS fuzzy model is formed, 268\nthe consequent-parameter estimation (the second subproblem 269\nof the learning) is addressed as a fuzzily weighted recursive LS 270\n(RLS) estimation problem per rule [15] 271\n\u0398ik =\u0398\ni\nk\u22121 + C\ni\nk\u03bb\nixk\n(\nyk \u2212 xTk \u0398ik\u22121\n)\n, \u0398i1 = 0 (19)\nCik =C\ni\nk\u22121\u2212\n\u03bbiCik\u22121xkx\nT\nk C\ni\nk\u22121\n1 + \u03bbixTk C\ni\nk\u22121xk\n, Ci1 = \u03a9I, k = 2, 3, . . .\n(20)\nwhere C \u2208 RN(n+L)xN(n+L) denotes the covariance matrix, \u03a9 272\nis a large positive number, and I is the identity matrix. 273\nAs a result, the eSensor blends in a fuzzy way local linear 274\npredictors. Moreover, it is optimally (in an LS sense) [15] 275\ntuned in terms of consequent parameters \u0398\u2019s. In terms of its 276\nantecedents and rule-based structure, it is based on the robust 277\nonline partitioning approach. The procedure of the eSensor self- 278\ndevelopment and self-calibration is represented as a pseudo- 279\ncode in the Appendix. 280\nE. Online Normalization and Standardization of the 281\nData in the eSensor 282\nOne specific issue related to this online algorithm is the 283\nnormalization or standardization of the data. Both normaliza- 284\ntion and standardization are well-established techniques for the 285\noffline case when all the data are available [2]. An approach 286\nto update the normalization ranges of the data in a recursive 287\nmanner is presented in [25], but in this paper, we use the 288\nrecursive version of the standardization technique that can 289\neasily be inferred from the offline version [2] because it depends 290\non the mean and variance of the data only. Let us remember that 291\n(offline) standardization is given by [2] 292\nZjk =\nzjk \u2212 zjk\n\u03b6jk\n, j = [1, n], k = 2, 3, . . . (21)\nwhere Zjk denotes the standardized value of zjk; zjk = 293\n(1\/k)\n\u2211k\nl=1 zjl, j = [1, n], k = 2, 3, . . . , represents the mean 294\nvalue of zjk; and vjk is the standard deviation of the jth input 295\ncalculated based on k data samples. 296\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 5\nBoth the mean and standard deviation can be updated297\nrecursively298\nzjk =\nk \u2212 1\nk\nzj(k\u22121) +\n1\nk\nzj(k\u22121),\nzj1 =0, j = [1, n + m], k = 2, 3, . . . (22a)\nv2jk =\nk \u2212 1\nk\nv2j(k\u22121) +\n1\nk \u2212 1\n(\nzjk \u2212 zj(k\u22121)\n)\n,\nvj1 =0, j = [1, n + m], k = 2, 3, . . . . (22b)\nIn order to return to the original scale, one should apply299\ndestandardization by300\nzjk = Zjk\u03bdjk + zjk, j = [1, n + m], k = 2, 3, . . . . (23)\nIII. ONLINE INPUT-VARIABLE SELECTION IN THE ESENSOR301\nInferential sensors, as well as other online models, tradi-302\ntionally assume the number of input variables to be known303\nbeforehand or to be preselected. In what follows, we propose an304\noriginal1 method to online \u201con-fly\u201d ranking and selection of in-305\nput variables, which was successfully approbated on the indus-306\ntrial case studies reported in this paper, as well as on other real307\napplications [30]. The importance of this technique should not308\nbe underestimated because, very often in practice, there are309\nlarge sets of candidate variables that may influence the moni-310\ntored or measured output, but often, it is not clear how much.311\nThe idea is based on online ranking of the accumulated values312\nformed by the consequent parameters \u0398ijk, j=[1,N ],i=[1,R].313\nThe accumulated values \u03c0\u2019s indicate that the weight of a par-314\nticular consequent parameter is determined by simply adding315\nthe absolute values (because the consequent parameters are316\nunrestricted in sign and value, and their contribution is judged317\nby the modulus)318\n\u03c0ijk =\nk\u2211\nl=1\n\u2223\u2223\u0398ijl\u2223\u2223 , j = [1, n], i = [1, R]. (24)\nOne can also form a weight of a particular feature by the ratio319\nof \u03c0 values320\n\u03c9ijk =\n\u03c0ijk\u2211n\nr=1 \u03c0\ni\njk\n, i = [1, R], j = [1, n]. (25)\nIt is important to note that (24) and (25) represent sums only321\nand are thus easily performed online. The values of the weights322\n\u03c9\u2019s indicate the contribution of a particular input to the overall323\noutput and are thus a measure of the sensitivity of the outputs.324\nTherefore, an intuitive technique to simplify the inferential325\nsensor structure in terms of inputs can be proposed, which326\ngradually removes the input variables for which the weight \u03c9 is327\nnegligibly small across the rules (i.e., the inputs that contribute328\nlittle to the overall output)329\nIF\n(\n\u2203j\u2217\n\u2223\u2223\u2223\u03c9ij\u2217k < \u03b5 nmax\nj=1\n\u03c0ijk\n)\n, THEN (remove j\u2217) (26)\n1This technique is part of a pending patent: P. Angelov, Machine Learning\n(Collaborative Systems), WO2008053161, priority date: November 1, 2006;\nintern. filing date: October 23, 2007; http:\/\/v3.espacenet.com\/textdoc?DB=\nEPODOC&IDX=WO2008053161&F=0&QPN=WO2008053161\nFig. 3. Overall schematic representation of the eSensor.\nwhere \u03b5 denotes a coefficient (the suggested values are 330\n[0.03; 0.1], which means that this input variable contributes 331\n3%\u201310% to the overall output on average. 332\nThe rationale for the simplicity of this technique stems from 333\nthe fact that the consequents represent locally linear combina- 334\ntions and can thus be analyzed. It should be noted that, when 335\nan input is removed (which does not usually occur very often), 336\nhowever, the dimension is reduced by one, which is reflected 337\nin the covariance matrices (a line and a column are removed), 338\nand the dimensions of the focal points are also updated, as well 339\nas the recursive variables in (13), i.e., \u03b1, \u03b2, \u03b3, and \u03c7. 340\nThe main advantages of the proposed eSensor approach that 341\nmakes it suitable for implementation in the process industry are 342\nas follows. 343\n1) It self-develops, evolves, and thus reduces the develop- 344\nment and maintenance costs significantly. 345\n2) It can provide high prediction rates. 346\n3) It is one-pass and recursive and has low computational 347\nrequirements; thus, it is suitable for hardware \u201con-chip\u201d 348\nimplementations [24]. 349\n4) It is useful for online analysis and monitoring of the 350\nconcept shift using fuzzy-rule aging [see Figs. 1(b) and 2] 351\nand thus makes useful conclusions for possible faults and 352\nthe quality of the process. 353\n5) It can automatically select online a small subset of relevant 354\ninputs, thus fully automating the development process. 355\n6) It can have a multiple-input\u2013multiple-output structure and 356\nthus build a separate regression model for each output 357\nvariable. 358\nThe procedure for adaptive and evolving inferential self- 359\ncalibrating sensors, which we call eSensor, is presented by the 360\npseudocode provided in the Appendix (see also Fig. 3). 361\nIV. CASE STUDY: INFERENTIAL SENSORS FOR 362\nCHEMICAL-PROPERTY ESTIMATION 363\nThe capabilities of the proposed evolving inferential sensor 364\nare explored on four different industrial data sets for chemical- 365\nproperty estimation. All four cases include operating-regime 366\nchanges with different impacts on specific chemical properties 367\ndue to different levels of process change, various measurement 368\nmethods with different accuracies, and a different number of 369\npotential process variables, related to the inferred chemical 370\nproperties. However, all the changes create a challenge to 371\n6 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nFig. 4. Case study 1: Composition 1. Top plot\u2014output variable (composition 1).\nMiddle plot\u2014input variable (x1). Bottom plot\u2014input variable (x2).\nexisting inferential sensors with a fixed structure. As a basis372\nfor comparison, inferential sensors based on the most widely373\nused methods in commercial soft-sensor products, such as the374\nfeedforward NN of multilayer perceptron (MLP) type [3] and375\nPLS [1], were used, as well as a recently introduced algorithm376\nfor adaptive online NN, namely, DENFIS [31].377\nIn the chemical industry, inferential sensors are mostly used378\nto estimate chemical properties, measured by two techniques:379\n1) offline laboratory analysis of grab samples of the proper-380\nties and 2) pseudo real-time analysis with low frequencies by381\ngas chromatographs. The sampling period for the properties,382\nmeasured by laboratory analysis, is several hours, and accu-383\nracy depends on different measurement methods and varies384\nsubstantially. The sampling period of gas-chromatograph-based385\nproperties is much shorter (usually 15\u201330 min), and accuracy is,386\non average, an order of magnitude higher than that from offline387\nlaboratory measurements. Three of the selected cases are based388\non offline laboratory measurements, and one is based on gas389\nchromatographs. In the cases with laboratory measurements,390\ntwo different levels of accuracies have been selected. The level391\nof operating-condition change (which could be quantified by392\nthe percentage increase from the average level for 50 samples393\nbefore the process change to the average level for 50 samples394\nafter the change), as well as the number of process inputs, is395\nalso different.396\nThe first case, called Composition 1, is based on product-397\ncomposition estimation in a distillation tower. The measure-398\nments are based on laboratory analysis, taken every 8 h, and399\nthe method accuracy is low (2.2% measurement error), which,400\nby itself, introduced a measurement noise. Process data are401\nthe hourly averaged values around the time when the sample402\nfor the laboratory measurement has been taken. The output403\ncomposition and the two-input data (Fig. 4) include 309 records404\n(samples). As it is seen in the middle plot in Fig. 4, a signifi-405\ncant change in operating conditions has been introduced after406\nsample 127 by input 1. It is interesting to note that the two407\ninput variables that were selected online using the eSensor are408\nFig. 5. Input and output variables for case study 2. Top plot\u2014output variable\n(composition 2). Middle plot\u2014input variable (x1). Bottom plot\u2014input\nvariable (x2).\nFig. 6. Output variable for case study 3 (composition 3). There are seven\nselected inputs, and they are not shown for clarity purposes.\nthe most statistically significant process variables related to this 409\ncomposition. 410\nThe second case, called Composition 2, is based on product- 411\ncomposition estimation in the bottom of a distillation tower, 412\nwhich is different from the tower in Composition 1. The com- 413\nposition measurements are based on laboratory analysis, taken 414\nevery 8 h with a more accurate method of 1.3% measurement 415\nerror, and are less noisy. Process data are the hourly averaged 416\nvalues for the time when the sample for the laboratory measure- 417\nment has been taken. The output composition and the two-input 418\ndata (Fig. 5) include 308 records (samples), where a signifi- 419\ncant change in operating conditions has been introduced after 420\nsample 113 by input 2. Forty-seven different input variables 421\nwere measured using \u201chard\u201d (conventional) sensors. 422\nThe third case, called Composition 3, is based on product- 423\ncomposition estimation in the top of the same distillation tower 424\nas that in Composition 2. The output composition is shown in 425\nFig. 6, and it also includes 308 data samples with a significant 426\nchange in operating conditions (catalyzing agent replacement) 427\nintroduced after sample 113. The key differences of Case 3 428\nrelative to the other laboratory-measurement-based cases are as 429\nfollows: 1) higher level of operating-condition changes (275% 430\nincrease versus 220% increase for Case 1 and 232% increase 431\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 7\nFig. 7. Flowchart of the eSensor from the real-time software-realization point of view. Sleep mode means a default state expecting an external request. Note that\nall the stages of eSensor self-calibration are combined in one block on the right bottom part of the flowchart. This includes learning, the online input selection, as\nwell as cluster\/rule removal based on their age. The details of this procedure are provided in the Appendix.\nfor Case 2) and 2) larger number of process inputs (seven inputs432\nversus two inputs for both Cases 1 and 2).433\nThe fourth case is based on propylene estimation in the top434\nof a distillation tower, which is different from the distillation435\ntowers in the previous cases. In this case 2, process variables436\nthat are related to propylene are used as inputs in the model437\ndevelopment. The propylene measurements are based on gas-438\nchromatograph analysis, taken every 15 min. Process data are439\nthe snapshot minute values for the time when the measurement440\nhas been taken. The data [Fig. 1(a)] include 3000 records441\n(samples) with very broad range of operating conditions.442\nThese four test cases (provided and used by The Dow Chem-443\nical Company, Freeport, TX) cover most of the real issues in444\napplying inferential sensors in the advanced process industry,445\nsuch as noisy data, changing operating conditions, a large446\nnumber of correlated inputs, etc.447\nV. EXPERIMENTAL RESULTS AND ANALYSIS448\nThe main aim of the experimental study was to generate449\ninterpretable simple-to-understand models that are flexible and450\nadaptive (evolving with time and following the dynamics of the 451\ndata pattern) and are robust to noise and imprecise measurement 452\ndata using the proposed technique eSensor and to compare 453\nthese results with the available alternatives based on MLP-type 454\nNN, PLS, and a recently introduced evolving NN, i.e., DENFIS 455\n[31]. Precision was measured using root mean square errors 456\n(RMSE), as well as correlation [2]. The data in all experiments 457\nwere standardized. The eSensor starts with an empty fuzzy- 458\nrule base (no iniSensor) and generates its rule-base \u201con fly\u201d 459\nbased on the data that are provided sample by sample and 460\ndisregarded from the memory once processed. It also optimizes 461\nthe parameters during retraining periods (it self-calibrates). The 462\noutput prediction is calculated for every data sample and can be 463\nused at any time instant. Samples for recalibration are provided 464\nwhen they are available (see Fig. 7). DENFIS was also applied 465\nin an online mode. 466\nThe conventional inferential sensors (PLS and NN) that are 467\nnot adaptive were trained initially using the first quarter of the 468\navailable data samples, and afterward, they were retrained using 469\nsamples from the third quarter of the available data stream. The 470\nerror was only calculated on the second and fourth quarters of 471\n8 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nFig. 8. Evolution of the rule base of the eSensor (number of rules vary\nstarting from one\u2014the first sample\u2014finishing with six, and reaching at some\nstage 10).\nTABLE I\nVALIDATION RESULT USING ESENSOR AND REFERENCE APPROACHES\nthe data stream in all cases (PLS, NN, and eSensor) to allow472\ncompatibility of the results. Note that the eSensor can also473\nbe retrained anytime when a training sample is available, and474\nmoreover, its structure (rule based) will be preserved and only475\ngradually adapted\/evolved.476\nThe evolution of the fuzzy rule base is shown in Fig. 8, where477\nthe number of fuzzy rules generated is shown for the fourth case478\nstudy (propylene). In retraining the NN and PLS, the parameters479\n(weights) change completely and are not interpretable. Note480\nthat both PLS and NN require a separate training phase to build481\nthe model and, during this phase, use all training data, while482\nthe eSensor starts \u201cfrom scratch\u201d and uses each time the current483\ndata sample only plus the accumulated parameters \u03b2 and \u03c7j484\n[see (13)]. DENFIS also needs initialization and cannot start485\n\u201cfrom scratch\u201d [31]. In addition, it is also noniterative. The486\nfuzzy models that have automatically been extracted by the487\neSensor from the data streams are transparent and understand-488\nable by the operator of the process, yet they are robust and flex-489\nible. That means that the fuzzy-rule base that is extracted can be490\nstored or directly presented to the operators without post-491\nprocessing.492\nFig. 9. Case study 1. (a) Top plot\u2014prediction of composition 1 by the\neSensor compared to the real data taken by laboratory samples every hour.\n(b) Bottom plot\u2014selected input variables by the eSensor.\nAs seen from Table I, the eSensor significantly outperforms 493\nconventional inferential sensors, such as feedforward MLP and 494\nPLS-based approaches, as well as the adaptive DENFIS ones, 495\nin terms of precision. It also has significantly smaller number 496\nof rules as compared to DENFIS. The predicted versus the 497\nreal (laboratory or chromatography) data are shown for all case 498\nstudies in Figs. 9\u201312 in the top plots, together with input- 499\nvariable selection in the bottom plots in Figs. 9\u201312. 500\nOne can see in Fig. 14 the local regions generated in another 501\nexperiment (Composition 1), which are represented by dashed 502\nlines. 503\nAdditionally, the eSensor builds its entire structure, includ- 504\ning input-variable online ranking and selection, fuzzy-rule 505\ngeneration, and self-recalibration, and is easily interpretable 506\n(linguistic). One example of the fuzzy-rule base generated 507\nautomatically at the end of the training phase is given in the 508\nfollowing for Case 2: 509\nFinal Rule Base for Composition 2: 510\nR1: IF (x1 is around 183.85) AND (x2 is around 170.31), 511\nTHEN (y = 0.84\u2212 0.96x1 + 0.61x2). 512\nR2: IF (x1 is around 178.09) AND (x2 is around 166.84), 513\nTHEN (y = 0.87\u2212 0.98x1 + 0.54x2). 514\nR3: IF (x1 is around 172.70) AND (x2 is around 166.01), 515\nTHEN (y = 0.87\u2212 1.02x1 + 0.64x2). 516\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 9\nFig. 10. Case study 2. (a) Top plot\u2014prediction of composition 2 by the\neSensor compared to the real data taken by laboratory samples every 8 h.\n(b) Bottom plot\u2014selected input variables by the eSensor.\nThe interpretability of the fuzzy rules can be seen in Fig. 13,517\nwhere the membership functions of the fuzzy sets that describe518\npropylene polymerization are depicted. This illustrates for the519\ninput variable x1 for the constant second input x2 the rate with520\nwhich the particular input (feature) affects the output in each521\nof the local regions. Linear dependences are understandable for522\nthe human operators, and it is obvious from Fig. 13 that there523\nare several linear dependences that are active for the values of524\nx1 (for example) around 25 and 40.525\nDuring the evolution of the rule base, the age of the clusters\/526\nrules is being monitored. Fig. 1(b) shows the age evolution of527\nthree rules from the rule base for propylene. Rule 1 is used528\nextensively around sample 1400, and its age drops significantly529\naround the same sample. At the same time, the age rate (first530\nderivative of the age) for rule 4 is positive and increasing,531\nwhich means that this particular fuzzy rule is getting older532\n(aging). Such changes indicate that there is a drift in the data533\npattern, and age rate provides a mathematical tool to detect this534\nautomatically. A similar case occurs at around sample 2650,535\nwhen a second significant drift is observed. Rule 3 is rarely used536\nafter its generation since its age rate is close to one during the537\nwhole process. This rule has been later removed automatically538\nfrom the rule base.539\nVI. CONCLUSION540\nA new type of adaptive, self-calibrating, and self-developing541\ninferential sensor that is based on the EFM of Takagi\u2013Sugeno542\nFig. 11. Case study 3. (a) Top plot\u2014prediction of composition 3 by the\neSensor compared to the real data taken by laboratory samples every 8 h.\n(b) Bottom plot\u2014selected input variables by the eSensor.\ntype (ETS) has been introduced in this paper and investigated 543\non a range of case studies from the chemical and process in- 544\ndustries. The proposed eSensors can be trained \u201con fly\u201d starting 545\neither \u201cfrom scratch\u201d or being primed with an initial rule base. 546\nThe results with data from real chemical processes demonstrate 547\nthat the proposed adaptive and evolving inferential sensor is 548\nvery flexible (it develops its model structure and adapts to 549\nsudden changes automatically, such as the introduced change 550\nof operating condition after sample 127 for Composition 1 551\nand after sample 113 for Composition 2). It does not need 552\nany pretraining and specific maintenance and thus reduces the 553\nlife-cycle costs significantly. The structure of the proposed 554\neSensor is transparent because it is composed of linguistic 555\nfuzzy rules that can be understood by an operator. The proposed 556\nevolving inferential sensor is also very robust. An illustration of 557\nthis for the example of Composition 3 was provided. Finally, 558\ndue to the recursive calculations, the proposed technique is 559\ncomputationally very light (the computational complexity is 560\non the order of O(n\u00d7R), where n is the number of inputs 561\n(in studied cases 2 or 7) and R is the number of fuzzy rules 562\ngenerated (usually a small number due to the very conservative 563\nrequirement for generating new rules based on the data density 564\n(15); in the studied cases, the number of fuzzy rules generated 565\nwas between two and six). It is important to note that the 566\nproposed eSensor is suitable for a range of process indus- 567\ntries, including, but not limited to, chemical, biotechnology, 568\noil refining, etc. 569\n10 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS\u2014PART B: CYBERNETICS\nFig. 12. Case study 4. (a) Top plot\u2014prediction of propylene by the eSensor\ncompared to the real data taken by the gas-chromatography test every 15 min.\n(b) Bottom plot\u2014selected input variables by the eSensor.\nAPPENDIX570\nAlgorithm: eSensor571\nBegin eSensor572\nInitialize eSensor by the first data sample, z1 = [x1, y1];573\n(D1)1 \u2190 1574\n(or by iniSensor if it exists)575\nDO for each data sample WHILE data are acquired576\nRead the measurable (by hard sensors) variables, xk;577\nCalculate the membership to each of the fuzzy sets by (4);578\nCalculate the rule firing strength by (6) and (7);579\nEstimate the outputs, y\u02c6k by (1);580\nAt the next time step (k \u2190 k + 1)581\nIF (mode = \u2018self-calibration\u2019)582\nGet the real value of the estimated variables, yk;583\nCalculate the density of the data sample, Dk(zk) by (13);584\nUpdate the density of the existing focal points, Dk(zi\u2217),585\nby (14);586\nIF (15) holds THEN587\nAdd a new focal point based on the new data point, (16);588\nInitiate its density to one, (17);589\nUpdate spreads of membership functions by (5);590\nIF (18) holds THEN Remove the rules for which it holds;591\nELSE (IF (15) holds)592\nIgnore (do not change the cluster structure);593\nUpdate spreads of membership functions by (5);594\nUpdate the age of the clusters by (10);595\nFig. 13. (a) Membership functions of two of the fuzzy sets that form the\nantecedent part of the fuzzy rules of the eSensor at the end of the training for\ncase study 4 (propylene). (b) Local linear models that form the consequent part\nof the fuzzy rules of the eSensor at the end of the training.\nFig. 14. Clusters that form the antecedent part of the fuzzy rules and illustrate\nthe local areas of validity of the rules.\nUpdate the input weights by (25) 596\nRemove the old rules (rules for which (11) holds); 597\nRemove the inputs with low weight (26). 598\nEND (IF THEN ELSE) 599\nUpdate the consequent parameters by (19) and (20). 600\nEND (self-calibration) 601\nEND (DO . . . WHILE) 602\nEND (eSensor) 603\nANGELOV AND KORDON: ADAPTIVE INFERENTIAL SENSORS BASED ON EVOLVING FUZZY MODELS 11\nACKNOWLEDGMENT604\nThe authors would like to thank Dr. X. Zhou for performing605\nthe numerical experiments and producing some of the figures.606\nREFERENCES607\n[1] L. Fortuna, S. Graziani, A. Rizzo, and M. G. Xibilia, Soft Sensors for608\nMonitoring and Control of Industrial Processes. London, U.K.:609\nSpringer-Verlag, 2007.610\n[2] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statis-611\ntical Learning: Data Mining, Inference and Prediction. Heidelberg,612\nGermany: Springer-Verlag, 2001.613\n[3] R. Rallo, J. Ferre-Gine, A. Arenas, and F. Giralt, \u201cNeural virtual sensor614\nfor the inferential prediction of product quality from process variables,\u201d615\nComput. Chem. Eng., vol. 26, no. 12, pp. 1735\u20131754, Dec. 2002.616\n[4] R. Klinkenberg and T. Joachims, \u201cDetection concept drift with support617\nvector machines,\u201d in Proc. 7th ICML, 2000, pp. 487\u2013494.618\n[5] A. Kordon and G. Smits, \u201cSoft sensor development using genetic pro-619\ngramming,\u201d in Proc. GECCO, San Francisco, CA, 2001, pp. 1346\u20131351.620\n[6] F. Hopner and F. Klawonn, \u201cObtaining interpretable fuzzy models from621\nfuzzy clustering and fuzzy regression,\u201d in Proc. 4th Int. Conf. Knowl.-622\nBased Intell. Eng. Syst., Brighton, U.K., 2000, pp. 162\u2013165.623\n[7] P. Angelov, Evolving Rule-Based Models: A Tool for Design of Flexible624\nAdaptive Systems. Berlin, Germany: Springer-Verlag, 2002.625\n[8] G. Widmer and M. Kubat, \u201cLearning in the presence of concept drift and626\nhidden contexts,\u201d Mach. Learn., vol. 23, no. 1, pp. 69\u2013101, Apr. 1996.627\n[9] P. Angelov and D. Filev, \u201cAn approach to on-line identification of evolving628\nTakagi\u2013Sugeno models,\u201d IEEE Trans. Syst., Man, Cybern. B, Cybern.,629\nvol. 34, no. 1, pp. 484\u2013498, Feb. 2004.630\n[10] P. Angelov and X. Zhou, \u201cEvolving fuzzy systems from data streams in631\nreal-time,\u201d in Proc. Int. Symp. Evolving Fuzzy Syst., Ambleside, U.K.,632\nSep. 7\u20139, 2006, pp. 29\u201335.633\n[11] J. Macias, P. Angelov, and X. Zhou, \u201cPredicting quality of the crude oil634\ndistillation using evolving Takagi\u2013Sugeno fuzzy models,\u201d in Proc. Int.635\nSymp.Evolving Fuzzy Syst., Ambleside,U.K.,Sep. 7\u20139, 2006, pp. 201\u2013207.636\n[12] P. Angelov and X. Zhou, \u201cOn line learning fuzzy rule-based system struc-637\nture from data streams,\u201d in Proc. IEEE Int. Conf. Fuzzy Syst. Within IEEE638\nWorld Congr. Comput. Intell., Hong Kong, Jun. 1\u20136, 2008, pp. 915\u2013922.639\n[13] A. Kordon, G. Smits, A. Kalos, and E. Jordaan, \u201cRobust soft sensor640\ndevelopment using GP,\u201d in Nature-Inspired Methods in Chemometrics,641\nR. Leardi, Ed. Amsterdam, The Netherlands: Elsevier, 2003, pp. 69\u2013108.642\n[14] P. Angelov and R. Buswell, \u201cIdentification of evolving rule-based mod-643\nels,\u201d IEEE Trans. Fuzzy Syst., vol. 10, no. 5, pp. 667\u2013677, Oct. 2002.644\n[15] K. J. Astroem and B. Wittenmark, Adaptive Control. Reading, MA:645\nAddison-Wesley, 1989.646\n[16] T. Takagi and M. Sugeno, \u201cFuzzy identification of systems and its ap-647\nplication to modeling and control,\u201d IEEE Trans. Syst., Man, Cybern.,648\nvol. SMC-15, no. 1, pp. 116\u2013132, Jan.\/Feb. 1985.649\n[17] L.-X. Wang, \u201cFuzzy systems are universal approximators,\u201d in Proc.650\nFUZZ-IEEE, San Diego, CA, 1992, pp. 1163\u20131170.651\n[18] R. Yager and D. Filev, Essentials of Fuzzy Modelling and Control.652\nNew York: Wiley, 1994.653\n[19] P. Angelov and D. Filev, \u201cSimpl_eTS: A simplified method for learning654\nevolving Takagi\u2013Sugeno fuzzy models,\u201d in Proc. IEEE Int. Conf. Fuzzy655\nSyst., Reno, NV, May 22\u201325, 2005, pp. 1068\u20131073.656\n[20] P. Domingos and G. Hulten, \u201cCatching up with the data: Research issues657\nin mining data streams,\u201d in Proc. Workshop Res. Issues Data Mining658\nKnowl. Discov., Santa Barbara, CA, 2001.659\n[21] E. Y. Nagai and L. V. R. Arruda, \u201cSoft sensor based on fuzzy model identi-660\nfication,\u201d inProc. 16th IFAC World Congr., Prague, Czech Republic, 2005.661\n[22] W. Yan, H. Shao, and X. Wang, \u201cSoft sensing modeling based on support662\nvector machine and Bayesian model selection,\u201d Comput. Chem. Eng.,663\nvol. 28, no. 8, pp. 1489\u20131498, Jul. 2004.664\n[23] J. Liu, \u201cOn-line soft sensor for polyethylene process with multiple produc-665\ntion grades,\u201d in Proc. 16th IFAC World Congr., Prague, Czech Republic,666\n2005.667\n[24] P. Angelov and M. Everett, \u201cEvoMap: Evolving mapping\u2014668\nImplementation of evolving clustering on FPGA,\u201d Lancaster Univ.,669\nLancaster, U.K., 2005.670\n[25] X. Zhou and P. Angelov, \u201cAn approach to autonomous self-localization of671\na mobile robot in completely unknown environment using evolving fuzzy672\nrule-based classifier,\u201d in Proc. 1st IEEE Int. Conf. Comput. Intell. Appl.673\nDefense Security, Honolulu, HI, Apr. 1\u20135, 2007, pp. 131\u2013138.674\n[26] A. Ferreyra and J. J. Rubio, \u201cA new on-line self-constructing neural fuzzy675\nnetwork,\u201d in Proc. 45th IEEE Conf. Decision Control, Dec. 13\u201315, 2006,676\npp. 3003\u20133009.677\n[27] P. S. Lee and A. L. Dexter, \u201cA fuzzy sensor for measuring the mixed air 678\ntemperature in air handling units,\u201d Measurement, vol. 37, no. 1, pp. 83\u201393, 679\nJan. 2005. 680\n[28] M. J. Arauzo-Bravo, J. M. Cano-Izquierdo, E. Gomez-Sanchez, 681\nM. J. Lopez-Nieto, Y. A. Dimitriadis, and J. Lopez-Coronado, \u201cAutomati- 682\nzation of a penicillin production process with soft sensors and an adaptive 683\ncontroller based on neuro-fuzzy systems,\u201d Control Eng. Pract., vol. 12, 684\nno. 9, pp. 1073\u20131090, Sep. 2004. 685\n[29] R. M. French, \u201cCatastrophic forgetting in connectionist networks,\u201d Trends 686\nCogn. Sci., vol. 3, no. 4, pp. 128\u2013135, Apr. 1999. 687\n[30] J. Kelly, P. Angelov, M. J. Walsh, H. M. Pollock, M. A. Pitt, 688\nP. L. Martin-Hirsch, and F. Martin, \u201cA self-learning fuzzy classifier with 689\nfeature selection for intelligent interrogation of mid-IR spectroscopy data 690\nderived from different categories of exfoliative cervical cytology,\u201d Int. 691\nJ. Comput. Intell. Res.\u2014Special Issue on the Future of Fuzzy Systems 692\nResearch, vol. 4, no. 4, pp. 392\u2013401, Dec. 2008, invited paper. 693\n[31] N. K. Kasabov and Q. Song, \u201cDENFIS: Dynamic evolving neural-fuzzy 694\ninference system and its application for time-series prediction,\u201d IEEE 695\nTrans. Fuzzy Syst., vol. 10, no. 2, pp. 144\u2013154, Apr. 2002. 696\nPlamen Angelov (M\u201999\u2013SM\u201904) received the 697\nM.Eng. degree in electronics and automation from 698\nSofia Technical University, Sofia, Bulgaria, in 1989 699\nand the Ph.D. degree in optimal control from the 700\nBulgarian Academy of Sciences, Sofia, in 1993. 701\nHe spent over ten years as a Research Fellow 702\nworking on computational intelligence and control. 703\nDuring 1995\u20131996, he was with Hans-Knoell In- 704\nstitute, Jena, Germany. In 1997, he was a Visiting 705\nResearcher with the Catholic University of Leuven, 706\nLeuven, Belgium. From 1998\u20132003, he was with 707\nLoughborough University, U.K. In 2003, he was appointed as a Lecturer with 708\nLancaster University, U.K. In 2007, he was a Visiting Professor with University 709\nof Applied Sciences Braunschweig\/Wolfenb\u00fcttel, Germany. He is currently a 710\nSenior Lecturer (Associate Professor) with Lancaster University, Lancaster, 711\nU.K., where he is with the Intelligent Systems Research Laboratory. He has 712\nauthored or coauthored over 100 peer-reviewed publications, including the 713\nbook entitled Evolving Rule Based Models: A Tool for Design of Flexible 714\nAdaptive Systems (Springer-Verlag, 2002), and over 30 journal papers, and he 715\nis a holder of a patent in machine learning (2006). He is co-Editor-in-Chief of 716\nthe Evolving Systems journal (Springer) and a Member of the editorial boards 717\nof three other international scientific journals. 718\nDr. Angelov is a member of the Autonomous Systems Working Group of 719\nthe Northwest Science Council of the U.K. and the Technical Committee (TC) 720\non Fuzzy Systems, the Vice Chair of the TC on Standards, Computational 721\nIntelligence Society, and the founding Chair of the Task Force on Adaptive 722\nFuzzy Systems. He serves regularly on the technical\/program committees 723\nof leading international conferences on different aspects of computational 724\nintelligence. 725\nArthur Kordon (M\u201991) received the M.Eng. degree 726\nfrom Varna Technical University, Varna, Bulgaria, 727\nin 1974 and the Ph.D. degree from Sofia Technical 728\nUniversity, Sofia, Bulgaria, in 1990, both in electrical 729\nengineering. 730\nHe spent more than 30 years in different posi- 731\ntions in the industry and academe, developing and 732\napplying different methods of advanced control and 733\ncomputational intelligence. He is currently a Data 734\nMining and Modeling Leader with the Data Mining 735\nand Modeling Group, The Dow Chemical Company, 736\nFreeport, TX. He is an internationally recognized expert in applying computa- 737\ntional intelligence technologies in the industry. He has successfully introduced 738\nseveral novel technologies for improved manufacturing and new product de- 739\nsign, such as robust inferential sensors, automated operating discipline, and 740\naccelerated fundamental model building. He has published more than 60 peer- 741\nreviewed papers, including the book Applying Computational Intelligence: 742\nHow to Create Value (Springer-Verlag, 2009) and nine book chapters in the 743\narea of applied computational intelligence and advanced control. His research 744\ninterests include application issues of computational intelligence, robust empir- 745\nical modeling, intelligent process monitoring and control, and data mining. 746\nDr. Kordon is a member of the Technical Committee on Evolutionary 747\nComputation. He regularly serves on the program committees of leading 748\ninternational conferences related to computational intelligence. 749\n"}
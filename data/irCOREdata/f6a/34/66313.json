{"doi":"10.1109\/SCAM.2006.30","coreId":"66313","oai":"oai:dro.dur.ac.uk.OAI2:2029","identifiers":["oai:dro.dur.ac.uk.OAI2:2029","10.1109\/SCAM.2006.30"],"title":"Stop-list slicing.","authors":["Gallagher, K.","Binkley, D.","Harman, M."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":["Di Penta, M.","Moonen, L."],"datePublished":"2006-09","abstract":"Traditional program slicing requires two parameters: a program location and a variable, or perhaps a set of variables, of interest. Stop-list slicing adds a third parameter to the slicing criterion: those variables that are not of interest. This third parameter is called the stoplist. When a variable in the stop-list is encountered, the data-flow dependence analysis of slicing is terminated for that variable. Stop-list slicing further focuses on the computation of interest, while ignoring computations known or determined to be uninteresting. This has the potential to reduce slice size when compared to traditional forms of slicing. In order to assess the size of the reduction obtained via stop-list slicing, the paper reports the results of three empirical evaluations: a large scale empirical study into the maximum slice size reduction that can be achieved when all program variables are on the stop-list; a study on a real program, to determine the reductions that could be obtained in a typical application; and qualitative case-based studies to illustrate stop-list slicing in the small. The large-scale study concerned a suite of 42 programs of approximately 800KLoc in total. Over 600K slices were computed. Using the maximal stoplist reduced the size of the computed slices by about one third on average. The typical program showed a slice size reduction of about one-quarter. The casebased studies indicate that the comprehension effects are worth further consideration","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/66313.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/2029\/1\/2029.pdf","pdfHashValue":"033db964eb391261a2868f5313316c47abbba125","publisher":"IEEE","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:2029<\/identifier><datestamp>\n      2011-08-11T13:56:43Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Stop-list slicing.<\/dc:title><dc:creator>\n         Gallagher, K.<\/dc:creator><dc:creator>\n        Binkley, D.<\/dc:creator><dc:creator>\n        Harman, M.<\/dc:creator><dc:description>\n        Traditional program slicing requires two parameters: a program location and a variable, or perhaps a set of variables, of interest. Stop-list slicing adds a third parameter to the slicing criterion: those variables that are not of interest. This third parameter is called the stoplist. When a variable in the stop-list is encountered, the data-flow dependence analysis of slicing is terminated for that variable. Stop-list slicing further focuses on the computation of interest, while ignoring computations known or determined to be uninteresting. This has the potential to reduce slice size when compared to traditional forms of slicing. In order to assess the size of the reduction obtained via stop-list slicing, the paper reports the results of three empirical evaluations: a large scale empirical study into the maximum slice size reduction that can be achieved when all program variables are on the stop-list; a study on a real program, to determine the reductions that could be obtained in a typical application; and qualitative case-based studies to illustrate stop-list slicing in the small. The large-scale study concerned a suite of 42 programs of approximately 800KLoc in total. Over 600K slices were computed. Using the maximal stoplist reduced the size of the computed slices by about one third on average. The typical program showed a slice size reduction of about one-quarter. The casebased studies indicate that the comprehension effects are worth further consideration. <\/dc:description><dc:publisher>\n        IEEE<\/dc:publisher><dc:source>\n        Di Penta, M. & Moonen, L. (Eds.).  6th IEEE International Workshop on Source Code Analysis and Manipulation, SCAM '06, 11-20 September 2006, Philadelphia USA ; proceedings. New York: IEEE, pp. 11-20<\/dc:source><dc:contributor>\n        Di Penta, M.<\/dc:contributor><dc:contributor>\n        Moonen, L.<\/dc:contributor><dc:date>\n        2006-09<\/dc:date><dc:type>\n        Book chapter<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:2029<\/dc:identifier><dc:identifier>\n        doi:10.1109\/SCAM.2006.30<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/2029\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1109\/SCAM.2006.30<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/2029\/1\/2029.pdf<\/dc:identifier><dc:rights>\n        \u00a92006 IEEE. Personal use of this material is permitted. However, permission to reprint\/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE.<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2006,"topics":[],"subject":["Book chapter","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n28 May 2008\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nGallagher, K. and Binkley, D. and Harman, M. (2006) \u2019Stop-list slicing.\u2019, in 6th IEEE International Workshop\non Source Code Analysis and Manipulation, SCAM \u201906, 11-20 September 2006, Philadelphia USA ;\nproceedings. New York: IEEE, pp. 11-20.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1109\/SCAM.2006.30\nPublisher\u2019s copyright statement:\n2006 IEEE. Personal use of this material is permitted. However, permission to reprint\/republish this material for\nadvertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists,\nor to reuse any copyrighted component of this work in other works must be obtained from the IEEE.\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n Use policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without \nprior permission or charge, for personal research or study, educational, or not-for-profit purposes \nprovided that : \n \n\u0083 a full bibliographic reference is made to the original source \n\u0083 a link is made to the metadata record in DRO \n\u0083 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright \nholders.  \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 3042 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nDurham Research Online \n \nDeposited in DRO: \n28 May 2008. \n \nVersion of attached file: \nPublished. \n \nPeer-review status of attached file: \nPeer-reviewed. \n \nCitation for published item: \nGallagher, K. and Binkley, D. and Harman, M. (2006) 'Stop-list Slicing.', 6th IEEE \nInternational Workshop on Source Code and Analysis and Manipulation, SCAM'06. . \nPhiladelphia, PA, USA, 27-29 September 2006. \n \nFurther information on publisher\u2019s website: \nhttp:\/\/dx.doi.org\/10.1109\/SCAM.2006.30\n \nStop-List Slicing\nKeith Gallagher\u2217\nComputer Science Department\nUniversity of Durham\nSouth Road\nDurham DH1 3LE, UK\nk.b.gallagher@durham.ac.uk\nDavid Binkley\nComputer Science Department\nLoyola College in Maryland\n4501 N. Charles St.\nBaltimore, MD. 21210 USA\nbinkley@cs.loyola.edu\nAbstract\nStop lists are used in information retrieval to re-\nduce the size of language processing tasks by eliminat-\ning non-content words. Stop lists are a collection of\nstop-words, words that do not contribute information\nto the language processing task. Stop-list program slic-\ning uses a stop list of variables to reduce the size of a\nprogram slice. In a fashion similar to selecting vari-\nables of interest for a program slice, the programmer\nselects variables that are not of interest. Stop-list slices\nare computed by removing certain data dependences for\nvariables in the non-interest set. In order to further\nunderstand and assess stop-list program slicing as a re-\nduction technique, we evaluated the size of reductions\nobtained by computing slices when dependences involv-\ning stop words are ignored during the computation of\nthe slices on a collection of C programs. In a suite\nof 42 programs of approximately 800,0000 source lines,\nover 600,000 slices were computed. Using a list of stop\nwords reduced the size of the computed slices by an av-\nerage of 34%.\n1 Introduction\nMark Weiser[12, 13] devised program slicing to aid\nprogram debugging. When debugging, the program-\nmer has a particular variable in mind. In slicing argot,\nthis particular variable is the variable that the pro-\ngrammer has determined to be \u201cof interest.\u201d The task\nof any program slicing technique is to then find the\nother variables (and statements) that could impact the\nvalue of this variable. Two significant problems occur\nin computing program slices. The first is finding the\nslicing criterion, i.e., finding the particular variable of\n\u2217On sabbatical leave from Loyola College in Maryland, USA\ninterest; the second is that the slices are often large\nand unwieldy.\nWhile a program slice elides irrelevant computa-\ntions, it may be that some of the (data flow) relevant\ncomputations included in the slice are not of interest to\nthe programmer. For instance, in any piece of software\nthere are variables that do the computation (e.g., out-\nputs), and variables that help to do the computation\n(e.g., counters, indices, and temporaries). But, are all\nvariables that are included in the program slice of equal\nimportance to the debugger or comprehender? Could\na programmer determine that a variable is not of in-\nterest and have computations that affect this variable\n\u201csliced\u201d away too? Is the removed information neces-\nsary to show the comprehender in the first place? As\npart of a comprehension task could it be that just to\n\u201cwrap one\u2019s head around\u201d what is going on that as-\nsignments to control variables, or some other subset\nof slice\u2019s variables, could be sliced out, too? We in-\nvestigate the reduction in the size of slices when these\n\u201chelper\u201d variables are omitted from the computation\nof a program slice.\nThe problem of finding variables of non-interest\nwould seem to be the same sort of problem as finding\nvariables of interest. Locating these interesting \/ un-\ninteresting variables is not the immediate focus of this\nwork; we presume that both the variables of interest\nand non-interest have been obtained in some fashion.\nIn this work, we are interested only in determining if\npursuing this idea has merit by determining the reduc-\ntions that could be obtained if uninteresting variables\nwere tagged for exclusion in the same way the inter-\nesting variables are tagged for inclusion in a program\nslice.\nThe motivation for this work is to attempt to re-\nduce the size and complexity of program slices. Previ-\nous work in this area has been concerned with devising\never more efficient data structures and algorithms to\n1\nobtain more precise slices. We consider an alternative\napproach which can be informally described as taking\nthe slices as emitted from a high quality program slicer\nand post process them to see if further reductions are\npossible. Conceptually, this is akin to the technique\nused [5], in which slices of differing criteria were com-\nbined by simple set equivalence.\nIn this paper we borrow a concept from information\nretrieval, that of stop words, and present evidence that\nusing a set of stop words whilst computing a program\nslice reduces the size of a slice enough that is indeed\nworth the effort. First, we present background, moti-\nvation and support for the application of stop words\nto program analysis. Then we present an operational\ndefinition and discussion of a stop-list slice via a collec-\ntion of examples. This discussion is followed by a de-\nscription the techniques used to compute the stop-list\nslices. The collected data is summarized and followed\nby a discussion of how this effort fits into the slicing\ncorpus.\nThe contributions of this paper are a definition of\na stop-list slice and an examination of 42 C programs\nthat shows that stop-list slicing is a viable technique for\nprogram analysis. Stop-list slicing is a way to \u201cslice the\nslice\u201d and thereby can aid comprehenders in the same\nway that slicing does: removal of unneeded, unwanted,\nor irrelevant information.\n2 Background\nThis section begins with a short discussion of stop-\nlists; discusses how they might be used in program\nanalysis; and introduces the data set used in the study.\n2.1 Stop Lists\nA stop list is used in information retrieval to reduce\nthe size of an index.\nA stop list is a list of words that are excluded\nfrom some language processing task, usually\nbecause they are viewed as non\u2013informative\nor potentially misleading. Usually they are\nnon\u2013content words like conjunctions, deter-\nminers, prepositions, etc. These are often\ncalled function words[10].\nFor instance, words such as \u201cthe\u201d, \u201cof,\u201d \u201cis,\u201d etc, need\nnot be included in an exhaustive index of a document\nand can thus be ignored when constructing the index.\nHere is the quotation of the previous paragraph after\nstop words have been removed:\nstop list list words excluded language process-\ning task viewed non\u2013informative misleading\nnon\u2013content words conjunctions determiners\nprepositions called function words\nWith the stop words removed the number of words\nin the quotation is reduced from 42 to 19, a reduction\nof almost 55%. If one knows that this quotation has\nhad the stop words removed, its sense remains, with a\nlittle work.\n2.2 Non\u203ainteresting Variables\nDo programs contain the functional equivalent of\nstop words? In other words, are there variables in pro-\ngrams that meet the generic criteria of stop words?\nWhile the quotation in Section 2.1 notes that stop\nwords may be misleading, we will ignore this possi-\nbility; if a variable is used in a program, we will as-\nsume that its use is not to mislead a program reader.\nTwo questions are studied. First, \u201cdo uninteresting\nvariables exist?\u201d and second (assuming so) \u201chow does\nelimination of assignments to these variables affect the\nslice size?\u201d\nThe study of stop-list slicing begins with an analy-\nsis to determine if there are variables in programs that\nqualify as stop words. Such variables would need to\nbe uninteresting to a software engineer. In addition,\ndiscounting such variables would have to have an effect\non slice size (i.e., the quantity of code a maintainer\nmust consider). To study these questions, the suite of\nprograms shown in Table 1 was analyzed. For each\nprogram, the table provides two measures of program\nsize, first, as reported by the Unix word count utility\nwc. While line counts as reported by word count are\nuseful when comparing with past studies, they provide\na rather crude measure. To provide an alternative es-\ntimate of program size, the third column reports the\nnumber of non-blank non-comment lines of code as re-\nported by sloc count [14].\n3 Stop List Slicing\nStop-list slicing is the application of a stop list to the\nslicing computation. The selection of variables to go on\nthe stop-list is akin to the selection of variables with\nrespect to which to slice. In some sense, their selection\ncan be considered \u201cthe dual\u201d of slice variable selection.\nWhen program slicing, an engineer selects variables \u201cof\ninterest;\u201d when stop-list slicing, the engineer also picks\na set of variables \u201cof non-interest.\u201d\nTo compute a stop-list slice, we first obtains a list\nof stop words (identifiers). Before computing a slice\n2\nSize (Loc)\nProgram wc sloc\na2ps 63,600 40,222\nacct 10,182 6,764\nbarcode 5,926 3,975\nbc 16,763 11,173\nbyacc 6,626 5,501\ncadp 12,930 10,620\ncompress 1,937 1,431\ncopia 1,170 1,110\ncsurf-pkgs 66,109 38,50\nctags 18,663 14,29\ncvs 101,306 67,828\ndiffutils 19,811 12,705\ned 13,579 9,046\nempire 58,539 48,800\nEPWIC-1 9,597 5,719\nespresso 22,050 21,780\nfindutils 18,558 11,843\nflex2.4.7 15,813 10,654\nflex2.5.4 21,543 15,283\nftpd 19,470 15,361\ngcc.cpp 6,399 5,731\ngnubg-0.0 10,316 6,988\ngnuchess 17,775 14,584\ngnugo 81,652 68,301\ngo 29,246 25,665\nijpeg 30,505 18,585\nindent 6,724 4,834\nli 7,597 4,888\nnamed 89,271 61,533\nntpd 47,936 30,773\noracolo2 14,864 8,333\nprepro 14,814 8,334\nreplace 563 512\nsendmail 46,873 31,491\nspace 9,564 6,200\nspice 179,623 136,182\ntermutils 7,006 4,908\ntile-forth 4,510 2,986\ntime 6,965 4,185\nuserv 8,009 6,132\nwdiff 6,256 4,112\nwhich 5,407 3,618\nwpst 20,499 13,438\nsum 1,156,546 824,935\naverage 26,896 19,185\nTable 1. The subject programs with simple\nline counting metrics.\nusing the standard graph reachability algorithm [8], all\ndata dependences that originate from simple assign-\nments to these identifiers are removed from system de-\npendence graph (the underlying representation used by\nthe slicer [4]). The kinds of assignment that qualify as\n\u201csimple\u201d are described in Table 2. In the next two sec-\ntions, we show first, by example, that stop-words, i.e.,\nvariables that are not relevant to the computation), ex-\nist in production code, and then we show, in Section 5,\nthe potential affect on slice size that their removal has.\nDeleted\nAssignments\nv = ... ( v = ...\nv++ v--\n++v --v\n*v++ *v--\nv <op>= ... v[...] = ...\nTable 2. Stop List Statement Types\n4 Examples\nThis section presents four examples that illustrate\nthe kind of variables we expect to be placed on a stop-\nlist. We start with a traditional example. Consider the\n\u201cusual suspect,\u201d Wordcount, shown on the left of Fig-\nure 1. The center of the figure is the program slice on\nvariable nw, the number of words, at the last statement,\nwhich includes definitions and references to the variable\ninword, the status variable that indicates whether or\nnot the scanner is advancing over white space, and to c,\nthe input variable. The slice omits 5 statements from\nthe original program.\nThe right of Figure 1 shows the corresponding\nstop-list slice computed using the stop list of c\nand inword. It thus ignores assignments to these\nvariables. Clearly we have lost execution seman-\ntics, for now the program is effectively equivalent\nto while (<constant>) { ...}; indeed, it will not\neven compile with the declarations removed. In a\ndisplay environment, the sliced statements might be\ndithered to indicate that they were elided via the stop\nlist. But note that by simple line counting, we have\nreduced the slice size by 31%, from 26 lines to 18.\nThe question arises: is the fragment on the right\nof Figure 1 comprehensible? We argue that it is in\nthe context of a comprehension exercise. Return to\nthe textual example of Section 2.1. If one is merely\nhanded the collection of words in the second quote,\nconfusion reigns. If one knows that this list of words\n3\n#include <stdio.h> #include <stdio.h> #include <stdio.h>\n#define YES 1 #define YES 1 #define YES 1\n#define NO 0 #define NO 0 #define NO 0\nmain() main() main()\n{ { {\nint c, nl, nw, nc, inword; int c, nw inword; int c, nw inword;\ninword = NO; inword = NO; inword = NO;\nnl = 0;\nnw = 0; nw = 0; nw = 0;\nnc = 0;\nc = getchar(); c = getchar();\nwhile ( c != EOF ) while ( c != EOF ) while ( c != EOF )\n{ { {\nnc = nc + 1;\nif ( c == \u2019\\n\u2019)\nnl = nl + 1;\nif ( c == \u2019 \u2019 || if ( c == \u2019 \u2019 || if ( c == \u2019 \u2019 ||\nc == \u2019\\n\u2019 || c == \u2019\\n\u2019 || c == \u2019\\n\u2019 ||\nc == \u2019\\t\u2019 ) c == \u2019\\t\u2019 ) c == \u2019\\t\u2019 )\ninword = NO; inword = NO;\nelse else else\nif ( inword == NO ) if ( inword == NO ) if ( inword == NO )\n{ { {\ninword = YES; inword = YES;\nnw = nw + 1; nw = nw + 1; nw = nw + 1;\n} } }\nc = getchar(); c = getchar();\n} } }\nprintf(\"%d \"%d \"%d \\n\", printf(\"%d \"%d \"%d \\n\", printf(\"%d \"%d \"%d \\n\",\nnl, nw, nc); nl, nw, nc); nl, nw, nc);\n} } }\nFigure 1. Wordcount program on the left. The program slice on variable nw at the last statement of\nWordcount program in the center. On the right a stop\u203alist slice of the program with assignments to\ninword and c, and their respective declarations, removed.\nhas had the stop words removed, a reasonable guess at\nits sense can be obtained. The same argument applies\nto a the fragment: we know it is a stop-list slice and in\nthis context we can make some reasonable assumptions\nabout the intent of missing variables, and the probable\nactions where the assignments are deleted.\nThus, when a comprehender knows that a stop-list\nslice is presented, we submit that eliminating assign-\nments to the input variable, c, does not adversely affect\ncomprehension of this slice. Nor does eliding references\nto the assignments to inword adversely affect compre-\nhension of this program slice. That the loop depends\non variable c is easily seen; likewise, the assignment to\nnw depends on inword. This is because control depen-\ndences are not removed from the stop list slice, just\nsimple assignments.\nBefore presenting the second example, we switch to\na more precise measure of slice size. To introduce the\nfundamental concepts of stop-list slicing and illustrate\nthe sizes of reductions obtained, the proceeding exam-\nple counted statements. This technique of text com-\nparison and line counting does not extend to the larger\nprograms analyzed. Thus, in subsequent examples of\nthis section and in the next section, we will use ver-\ntex counts in the System Dependence Graph [8] (SDG)\nfor measuring the percent reduction, rather than state-\nment counts. For ease or presentation, we will continue\nto present snippets of code (rather than dependence\ngraphs) to illustrate the stop-list slices.\nThe second example is shown on the left of Figure 2,\n4\nmain() main()\n{ {\nint i; int i;\nint number;\nint max = 0; int max = 0;\nscanf(\"%d\", &number);\nwhile (1 << max <= number)\n{\nmax++;\n}\nfor( i = max - 1; i >= 0; i--) for( i = max - 1; i >= 0; i--)\n{ {\nint current_digit = 1 << i; int current_digit = 1 << i;\nprintf(\"%c\", printf(\"%c\",\ncurrent_digit <= number ? \u20191\u2019 : \u20190\u2019); current_digit <= number ? \u20191\u2019 : \u20190\u2019);\nif (current_digit <= number) if (current_digit <= number)\nnumber = number - current_digit; number = number - current_digit;\n} }\nprintf(\"\\n\"); printf(\"\\n\");\n} }\nFigure 2. The fragment to the right shows the stop\u203alist slice of the fragment on the left using a stop\u203alist\nof {i, number}.\nwhich writes out the binary representation of the value\nreceived as input. The first loop serves only to compute\nthe number of iterations of the second loop. Placing\ni on the stop list causes the stop-list slice to exclude\nthe first loop; adding variable number to the stop-list\nremoves the scanf. The stop-list slice of this fragment\nis shown on the right of Figure 2. The reduction in this\ninstance is from 19 to 11, 42%.\nThe third example, shown in Figure 3, is from the\nutility slowcat [3]. It pauses while \u201ccat\u201ding a file af-\nter a certain number of bits have been output; thus,\n\u201ccat\u201ding the file slowly. Within the main loop pauses\nare inserted after a certain number of bits have been\noutput. The main input-output loop is preceded by\nstandard command line processing.\nThe main loop of slowcat is\nwhile ((c = getc(infile)) != EOF) { ... } .\nThe slice on this loop includes 18 vertices while the slice\non the counter increment \u201cbits read += 8\u201d includes\n21 vertices. The stop-list slice using c as the stop-list\ntaken with respect to \u201cbits read += 8\u201d includes only\n9 vertices (a 57% reduction). What is being excluded\nhere is opening the file, deciding the file name, etc. The\nint arg_ptr_index = 2;\n\/* first arg is required infile name *\/\nwhile (arg_ptr_index < argc)\n{\nif (!strcmp(argv[arg_ptr_index], \"-o\"))\n{\narg_ptr_index++;\nfilename = argv[arg_ptr_index];\n}\n[[ check other arguments ]]\n...\n}\nFigure 4. Argument Processor\nreduction occurs because c has a data dependence on\ninfile and data dependences on c are ignored.\nFinally, Figure 4 is shows a program fragment (ex-\ntracted from a large system) which does some com-\nmand line argument processing. The slice on the loop\nwhile (arg ptr index < argc) includes 50 vertices.\nThe slice on filename = argv[arg ptr index] from\n5\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#define DEFAULT_RATE 14400\n#define DELAY_POINT 256\nvoid main(int argc, char* argv[]){\nFILE *infile;\nlong rate = DEFAULT_RATE;\nint bits_read = 0;\nint c;\nunsigned long delay_time;\n\/************************************************\/\nif ((argc < 2) || (strcmp(argv[1],\"-h\") == 0)){\nprintf(\"usage:\\n %s file_name [bits\/sec]\\n\",argv[0]);\nprintf(\" The default time is 14400 bits\/sec.\\n\");\nexit(0);\n}\nif (argc >= 3){\nrate = atol(argv[2]);\nif (rate <= 200){\nfprintf(stderr,\"%s: illegal rate %s\\n\",argv[0],argv[2]);\nexit(-1);\n}\n}\ninfile = fopen(argv[1],\"r\");\nif (infile == NULL){\nfprintf(stderr,\"%s: unable to open %s for read\\n\",argv[0],argv[1]);\nexit(-1);\n}\n\/************************************************\/\ndelay_time = DELAY_POINT * 1000000 \/ rate;\nwhile ((c = getc(infile)) != EOF){\nputc(c,stdout);\nfflush(stdout);\nbits_read += 8;\nif (bits_read > DELAY_POINT){\nusleep(delay_time);\nbits_read = 0;\n}\n}\nfclose(infile);\n}\nFigure 3. Slowcat source. The stop\u203alist slice eliminates the argument processing. The elided source\nis noted between the starred lines\n6\nthe \u201c-o\u201d (output file name) option includes 52 vertices.\nPlacing arg ptr index on the stop list (thus ignoring\nthe dependence on arg ptr, also essentially making the\nloop while (<constant>) { ...}, this slice includes\n47 vertices. (The slice on the loop header contains only\n6 vertices.) Thus, we get a 10% reduction from 52 to\n47 vertices.\n5 Results and Discussion\nHaving illustrated in the proceeding section that\nstop-list slicing is advantageous in real code, the next\nquestion to ask is what is the maximum reduction pos-\nsible, which occurs when all variables are on the stop\nlist. This is not the same as removing all data depen-\ndences as only data dependences associated with \u2018sim-\nple\u2019 assignments are removed. Those data dependences\nfrom non-simple assignments (e.g., through pointers)\nand control dependences are not elided.\nThe maximal reductions for each program, when the\nsimple (as noted in Table 2) are shown in Table 3. The\ntable includes the number of slices taken and the av-\nerage slice size using an empty stop-list and a \u201cfull\u201d\nstop-list. The final column of the first presents the\npercent reduction for each program. Summary statis-\ntics over all program are presented in the last five rows\nof the table. Over all programs the reduction ranges\nfrom 8% to 77% with an average reduction of 34%.\nFinally, the program copia was used as a case study\nto examine the expected reduction for a realistic stop-\nlist (rather than all the variables in the program). Ta-\nble 4 shows the average slice size computed using an\nempty stop-list, then with all variables on the stop-\nlist, and finally with a representative stop-list as might\nbe chosen by a software engineer studying copia. The\nvariables on the representative stop list are shown in\nTable 5.\nFor copia, including all variables on the stop-list re-\nsults in a 41% reduction in average size size. While,\nas expected, the average reduction obtained using the\nrepresentative stop list was smaller, at 25% it still rep-\nresents a significant reduction in average slice size. This\nindicates that presenting a stop-list slice to a program-\nmer may be of interest.\n5.1 Interpretation Context\nThere are two external threats to these results: pro-\ngram selection and slice selection. Most of the pro-\ngrams come from the open-source community. There\nare no event-driven, real-time or embedded systems in\nthe sample. Thus, these results may not be extrapo-\nlated to these domains, without further analysis. The\nsample size assuages the concern that the sample does\nnot represent \u201ctypical\u201d programs. The slice selection\nthreat is assuaged by taking all slices; this eliminates\nconcerns that a bias may be introduced by a program-\nmer selected criterion. However, it does raise the con-\ncern that computing all slices is not representative of\nengineering activity. In this case we argue that, as our\nsample comprises all slices, it would include any slice\nchosen at random.\nThe only internal threat to these results is errors\nthat may be in in CodeSurfer itself, thereby compro-\nmising the data. To this we respond that CodeSurfer\nis a mature \u201cindustrial strength\u201d tool.\n6 Related Work\nThe program slicing tool CodeSurfer[4] has the abil-\nity to chase the data dependences of the system depen-\ndence graph. It does not have the ability, through the\ncurrent user interface, to ignore selected dependences\nin the systematic way that stop-list slicing does. The\nCodeSurfer internal representation of the system de-\npendence graph can be modified to ignore dependences\nby simply eliminating the selected dependences; this is\nhow the data presented in Table 3 was collected. The\nSeeSlice [2] system has the ability to limit the graph\nedge distance considered by a slicer. The distance lim-\nitation permits the comprehender to \u201cdrill down\u201d into\na specific area (distance) of interest. Our work would\nintegrate nicely into the CodeSurfer or SeeSlice envi-\nronments. The only enhancement required would be\nto tell the underlying slicing engines to ignore selected\ndata dependences.\nThe canto maintenance environment of Antoniol,\net al. [1] uses an incremental technique to integrate\nsoftware and architecture. canto can be used to con-\nstruct stop-list slices, although it was not designed to\ndo so. The construction of the slice is controlled by the\ncomprehender. We just provide the stop-list slice.\nOrso, et al., [11] use an incremental technique to ex-\npand slices in steps by using types to elide subtle data\nStop-list Average Slice Reduction\nSize Size in Percent\nEmpty 13,035\nAll variables 7,723 41%\n\u201cReasonable\u201d 9,810 25%\nTable 4. Average size of slices of program\ncopia with various stop\u203alists. The \u0093Reason\u203a\nable\u0094 stop\u203alist is given in Table 5\n7\nAverage Slice Size Average as Percent\nProgram Slices Empty Full Empty Full Reduction\nTaken Stop-List Stop-List Stop-List Stop-List\na2ps 58,280 26,937 21,747 46% 37% 19%\nacct 7,250 826 498 11% 7% 40%\nbarcode 3,908 1,700 1,080 44% 28% 37%\nbc 5,132 3,827 2,755 75% 54% 28%\nbyacc 10,150 2,407 1,346 24% 13% 44%\ncadp 15,672 1,906 1,337 12% 9% 30%\ncompress 1,084 315 140 29% 13% 56%\ncopia 4,686 2,113 1,449 45% 31% 31%\ncsurf-pkgs 43,044 11,122 8,773 26% 20% 21%\nctags 20,578 12,427 9,762 60% 47% 21%\ncvs 103,264 75,247 58,784 73% 57% 22%\ndiffutils 17,092 4,894 3,592 29% 21% 27%\ned 16,532 11,001 8,698 67% 53% 21%\nempire 120,246 56,279 44,582 47% 37% 21%\nEPWIC-1 12,492 1,817 419 15% 3% 77%\nespresso 29,362 12,917 8,950 44% 30% 31%\nfindutils 14,444 5,369 3,698 37% 26% 31%\nflex2-4-7 11,104 3,885 2,258 35% 20% 42%\nflex2-5-4 14,114 3,996 2,367 28% 17% 41%\nftpd 25,018 12,630 7,174 50% 29% 43%\ngcc.cpp 7,460 4,442 2,750 60% 37% 38%\ngnubg-0.0 9,556 3,372 2,491 35% 26% 26%\ngnuchess 15,068 8,084 4,759 54% 32% 41%\ngnugo 68,298 33,331 29,205 49% 43% 12%\ngo 35,862 28,803 18,917 80% 53% 34%\nijpeg 24,028 9,734 7,019 41% 29% 28%\nindent-1.10.0 6,748 3,496 2,129 52% 32% 39%\nli 13,690 8,292 5,514 61% 40% 33%\nnamed 106,828 58,939 44,675 55% 42% 24%\nntpd 40,198 16,026 12,234 40% 30% 24%\noracolo2 11,812 2,161 1,036 18% 9% 52%\nprepro 11,744 2,110 989 18% 8% 53%\nreplace 1,734 162 104 9% 6% 36%\nsendmail 47,344 22,792 16,406 48% 35% 28%\nspace 11,276 2,239 1,080 20% 10% 52%\nspice 212,620 67,515 41,932 32% 20% 38%\ntermutils 3,112 1,136 575 37% 18% 49%\ntile-forth-2.1 12,076 6,653 6,105 55% 51% 8%\ntime-1.7 1,044 165 113 16% 11% 31%\nuserv-0.95.0 12,516 3,515 2,441 28% 20% 31%\nwdiff.0.5 2,420 373 240 15% 10% 36%\nwhich 1,162 474 175 41% 15% 63%\nwpst 20,888 3,547 2,702 17% 13% 24%\nsum 626,646\naverage 29,759 13,925 10,124 40% 28% 34%\nmax 212,620 75,246 58,783 80% 57% 77%\nmin 1,044 162 104 9% 3% 8%\nstdev 40,339 19,530 14,545 19% 15% 13%\nTable 3. The Data\n8\nRAND SEED ALARM CLOCK\nFILE SYSTEM HEAP\nPROCESS UMASK adx\nady dot dot dot\nerrno fp\ni j\nm max\nmin n\np p1\nptr q\nq1 seed\ntemp FILE SYSTEM temp ALARM CLOCK\ntemp FILE SYSTEM temp HEAP\ntemp dot dot dot temp optind\ntemp star stderr temp star stdin\ntemp star stdout temp star stream\ntemp star strm vm\ny z\nTable 5. The \u0093Reasonable\u0094 Stop\u203aList for pro\u203a\ngram copia\ndependences and statements. The contribution of this\nwork is a more accurate slice that regards the semantic\ninformation contributed by the data types of the vari-\nables under consideration. Our distinction from it is\nthat we are not refining the slice to be more accurate;\nwe are eliminating information to assuage information\noverload.\nProgram dicing uses the information that some vari-\nables fail some tests, whilst other variables pass all\ntests, to automatically identify a set of statements\nlikely to contain the bug [9]. A program dice is ob-\ntained using set operations on backward program slices.\nDices relate to this work insofar as they eliminate state-\nments from program slices.\nDecomposition slice equivalence can be used to sig-\nnificantly reduce the number of slice a programmer\nneeds to comprehend, by forming equivalence classes\nof slices that were exactly the same, regardless of the\nslice criteria [5]. The slices computed by this technique\nare still large. The current work enhances the reduc-\ntion by further reducing the size of the slice that must\nbe comprehended.\n7 Future Work\nThe results presented here are promising and have\nled us to formulate a research plan.\n7.1 Control Stop\u203aList Slicing\nAs noted in Section 3 this paper focuses on data\nstop-list slicing. It is also possible to consider control\nstop list slicing. This subsection lays out a conceptual\nframework for control stop-list slicing.\nIn the SDG, for the code fragment \u201cif (p) a =\n1\u201d, the assignment \u201ca = 1\u201d is control dependent on\nif (p). Furthermore, a procedure is also control de-\npendent on each call-site to the procedure. Thus, if p\nwere a control stop word then the slice of\nif (p > 0)\na = 1;\nwould stop at \u201cif (p > 0)\u201d and not look for definition\nof p. Similarly, in the code fragment\na() { b(); }\nb() { c(); }\nc() { x = 1; }\nthe slice on the assignment \u201cx = 1\u201d includes the entry\npoints for c, b, and a because of control dependences.\nUsing a control stop-word list of b, the slice would stop\nat b.\n7.1.1 Output Statements\nIn the system dependence graph, \u201cprintf(\"%d\", a)\u201d\nis represented by a call vertex (to printf), parameter\nvertices for \u201c%d\u201d, a, and a vertex for the return value.\nThe call vertex is only involved in control dependence,\nso having it on a stop list would not change the (data)\nstop-list slice as defined in Section 3. Thus, an applica-\ntion of control stop-list slicing is the printf statement.\nThe variables referenced in a printf do not represent\ndata stop words because the call to printf is actually a\ncontrol point in the system dependence graph. Output\nstatements have always caused difficulties in computing\nprogram slices. Output statements do not contribute\nto the value of the variable in a slice, but they cer-\ntainly are of interest to a programmer considering a\nprogram slice. For output statements, we use the same\napproach as decomposition slicing [7], in which output\nstatements are not added to the slice computation, per\nse, but added in at the behest of the programmer.\n7.2 Locating Stop Words\nWe have deliberately avoided the question of finding\ncandidate stop-words. Now that we have some data\nthat shows that stop-list slicing is worth the effort,\n9\nwe will have to spend some time determining what\nvariables are likely candidates. One incipient idea is\nusing unchangeable variables from the decomposition\nslice on the variable of interest[6, 7]. The unchange-\nable variables are used in other computations and thus\ncannot be changed in the decomposition slicing soft-\nware evolution model. Unchangeable variables cer-\ntainly contribute to the computation in question, but\ntheir data and control flows are beyond the focus of\ninterest. Eliminating the data (and perhaps control)\ndependences on these variables is a reasonable place to\nstart.\nA second approach is to use techniques from infor-\nmation retrieval. A simple enumeration of variable uses\ncould be a starting place. For instance, in text process-\ning one could create a list words ordered the number\nof occurrences as a likely list of stop words. Applying\nthe same technique to program source may be fruitful.\n7.3 User Study\nWe will consider a user study. The goal of such a\nstudy would be to determine the \u201ccomprehension loss,\u201d\nif any, that might occur when a user is presented with\na program slice and with a stop-list slice on the same\ncriteria. An empirical evaluation would be difficult for\nthe usual reasons that threaten any user study: caliber\nof subjects; size of sample; size of program used; etc.\n8 Conclusion\nProgram slicing was devised to assist program com-\nprehenders and maintainers in their difficult task. The\ncentral premise of this work is that all variables are\nnot of equal importance to a software maintainer or\ncomprehender. There are certain idioms and patterns,\nthat are repeatedly used and can be considered as back-\nground noise in a comprehension environment. Exam-\nples of these are for-statements and their associated\ncounter and argument processing code. To further as-\nsist comprehenders and maintainers, we have shown\nhow the size of the slice itself can be reduced with-\nout significant loss of information. Moreover, this lost\ninformation can be easily retrieved by returning to a\ntypical program slice.\nReferences\n[1] G. Antoniol, R. Fiutem, G. Lutteri, P. Tonella, S. Zan-\nfei, and E. Merlo. Program understanding and main-\ntenance with the canto environment. In ICSM \u201997:\nProceedings of the International Conference on Soft-\nware Maintenance, page 72. IEEE Computer Society,\n1997.\n[2] T. Ball and S. Eick. Visualizing program slices. In\nProceedings of the Tenth International Symposium on\nVisual Languages, 1994.\n[3] R. W. Buccigrossi and E. P. Simoncelli. EP-\nWIC: Embedded Predictive Wavelet Image Coder.\nhttp:\/\/www.cns.nyu.edu\/ eero\/EPWIC\/.\n[4] CodeSurfer. GrammaTech, Inc.\nhttp:\/\/www.grammatech.com\/products\/codesurfer.\n[5] K. Gallagher and D. Binkley. An empirical study of\ncomputation equivalence as determined by decomposi-\ntion slice equivalence. In Proceedings of the 10th Work-\ning Conference on Reverse Engineering, WCRE\u201303,\n2003.\n[6] K. Gallagher, M. Harman, and S. Danicic. Guaran-\nteed inconsistency avoidance during software evolu-\ntion. Journal of Software Maintenance and Evolution:\nResearch and Practice, 2003. To appear Dec. 2003.\n[7] K. B. Gallagher and J. R. Lyle. Using program slic-\ning in software maintenance. IEEE Transactions on\nSoftware Engineering, 17(8):751\u2013761, August 1991.\n[8] S. Horwitz, T. Reps, and D. Binkley. Interprocedural\nslicing using dependence graphs. ACM Transactions\non Programming Languages and Systems, 12(1):35\u201346,\nJanuary 1990.\n[9] J. R. Lyle and M. D. Weiser. Automatic program bug\nlocation by program slicing. In Proceeding of the Sec-\nond International Conference on Computers and Ap-\nplications, pages 877\u2013882, Peking, China, June 1987.\n[10] T. Pedersen.\nwww.d.umn.edu\/\u02dc tpederse\/Group01\/wordnet.html.\n[11] A. Orso, S. Sinha, and M. J. Harrold. Incremental slic-\ning based on data-dependence types. In Proceedings of\nthe IEEE International Conference on Software Main-\ntenance (ICSM 2001), pages 158\u2013167, Firenze, Italy,\nnovember 2001.\n[12] M. Weiser. Programmers use slices when debugging.\nCACM, 25(7):446\u2013452, July 1982.\n[13] M. Weiser. Program slicing. IEEE Transactions on\nSoftware Engineering, 10:352\u2013357, July 1984.\n[14] D. A. Wheeler. SLOC count user\u2019s guide, 2005.\nhttp:\/\/www.dwheeler.com\/sloccount\/sloccount.html.\n10\n"}
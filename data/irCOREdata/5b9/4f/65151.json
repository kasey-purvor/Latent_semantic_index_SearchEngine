{"doi":"10.1016\/j.techfore.2009.10.008","coreId":"65151","oai":"oai:dro.dur.ac.uk.OAI2:6748","identifiers":["oai:dro.dur.ac.uk.OAI2:6748","10.1016\/j.techfore.2009.10.008"],"title":"The limits of forecasting methods in anticipating rare events.","authors":["Goodwin,  P.","Wright,  G."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-03-01","abstract":"In this paper we review methods that aim to aid the anticipation of rare, high-impact, events. We evaluate these methods according to their ability to yield well-calibrated probabilities or point forecasts for such events. We first identify six factors that can lead to poor calibration and then examine how successful the methods are in mitigating these factors. We demonstrate that all the extant forecasting methods \u2014 including the use of expert judgment, statistical forecasting, Delphi and prediction markets \u2014 contain fundamental weaknesses. We contrast these methods with a non-forecasting method that is intended to aid planning for the future \u2014 scenario planning. We conclude that all the methods are problematic for aiding the anticipation of rare events and that the only remedies are to either (i) to provide protection for the organization against the occurrence of negatively-valenced events whilst allowing the organization to benefit from the occurrence of positively-valenced events, or (ii) to provide conditions to challenge one's own thinking \u2014 and hence improve anticipation. We outline how components of devil's advocacy and dialectical inquiry can be combined with Delphi and scenario planning to enhance anticipation of rare events","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65151.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/6748\/1\/6748.pdf","pdfHashValue":"cb413361f71948b73a59a95e30af5e16e3fb84ca","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:6748<\/identifier><datestamp>\n      2010-05-07T10:11:49Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        The limits of forecasting methods in anticipating rare events.<\/dc:title><dc:creator>\n        Goodwin,  P.<\/dc:creator><dc:creator>\n        Wright,  G.<\/dc:creator><dc:description>\n        In this paper we review methods that aim to aid the anticipation of rare, high-impact, events. We evaluate these methods according to their ability to yield well-calibrated probabilities or point forecasts for such events. We first identify six factors that can lead to poor calibration and then examine how successful the methods are in mitigating these factors. We demonstrate that all the extant forecasting methods \u2014 including the use of expert judgment, statistical forecasting, Delphi and prediction markets \u2014 contain fundamental weaknesses. We contrast these methods with a non-forecasting method that is intended to aid planning for the future \u2014 scenario planning. We conclude that all the methods are problematic for aiding the anticipation of rare events and that the only remedies are to either (i) to provide protection for the organization against the occurrence of negatively-valenced events whilst allowing the organization to benefit from the occurrence of positively-valenced events, or (ii) to provide conditions to challenge one's own thinking \u2014 and hence improve anticipation. We outline how components of devil's advocacy and dialectical inquiry can be combined with Delphi and scenario planning to enhance anticipation of rare events.<\/dc:description><dc:subject>\n        Rare events<\/dc:subject><dc:subject>\n         Delph<\/dc:subject><dc:subject>\n         Scenario planning<\/dc:subject><dc:subject>\n         Expert judgment<\/dc:subject><dc:subject>\n         Statistical forecasting.<\/dc:subject><dc:publisher>\n        Elsevier<\/dc:publisher><dc:source>\n        Technological forecasting and social change, 2010, Vol.77(3), pp.355-368 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2010-03-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:6748<\/dc:identifier><dc:identifier>\n        issn:0040-1625<\/dc:identifier><dc:identifier>\n        doi:10.1016\/j.techfore.2009.10.008 <\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6748\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1016\/j.techfore.2009.10.008 <\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6748\/1\/6748.pdf<\/dc:identifier><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0040-1625","0040-1625"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2010,"topics":["Rare events","Delph","Scenario planning","Expert judgment","Statistical forecasting."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n07 May 2010\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nGoodwin, P. and Wright, G. (2010) \u2019The limits of forecasting methods in anticipating rare events.\u2019,\nTechnological forecasting and social change., 77 (3). pp. 355-368.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1016\/j.techfore.2009.10.008\nPublisher\u2019s copyright statement:\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n 1 \n \n1 \n \n \nThe limits of forecasting methods in anticipating rare events. \n \n \n \nPaul Goodwin* \nSchool of Management \nUniversity of Bath \nBath \nBA2 7AY \nUnited Kingdom \nTel: +44  (0) 1225 -383594 \nFax: +44 (0) 1225- 826473 \nEmail: mnspg@management.bath.ac.uk \n \n \nGeorge Wright \nDurham Business School \nUniversity of Durham \nMill Hill lane \nDurham City \nDH1 3lB \nUnited Kingdom \nTel: +44 (0) 191 33 45427 \nFax: +44 (0) 191 33 45201 \nEmail: george.wright@durham.ac.uk \n \n \n \n(* corresponding author) \n 2 \n \n2 \nThe limits of forecasting methods in anticipating rare events \n \nAbstract \n \nIn this paper we review methods that aim to aid the anticipation of rare, high-impact, events. We \nevaluate these methods according to their ability to yield well-calibrated probabilities or point \nforecasts for such events. We first identify six factors that can lead to poor calibration  and then \nexamine how successful the methods are in mitigating these factors. We demonstrate that all the \nextant forecasting methods - including the use of expert judgment, statistical forecasting, Delphi and \nprediction markets - contain fundamental weaknesses. We contrast these methods with a non-\nforecasting method that is intended to aid planning for the future \u2013 scenario planning. We conclude \nthat all the methods are problematic for aiding the anticipation of rare events and that the only \nremedies are to either (i) to provide protection for the organization against the occurrence of \nnegatively-valenced events whilst allowing the organization to benefit from the occurrence of \npositively-valenced events, or (ii) to provide conditions to challenge one\u201fs own thinking \u2013 and hence \nimprove anticipation. We outline how use of components of devil\u201fs advocacy and dialectical inquiry \ncan be combined with Delphi and scenario planning to enhance anticipation of rare events.\n 3 \n \n3 \nIntroduction: What do we mean by predictability? \nIt is not hard to identify events  that  have a large impact on the lives of many people, but which \nwere unexpected by most people. Some of these events are natural disasters and some have human \ncauses. Consider the global financial melt-down of 2008 . Once such an event occurs it often seems \nto have been inevitable, with hindsight. Makridakis, Hogarth, and Gaba [1] quote many examples of \npublicly-available forecasts made by key figures in finance and economics just before the global \nfinancial crisis of 2008. These before-event forecasts can now be seen to have been completely \nwrong.  Consider, also, newspaper coverage of terrorist attacks in the US homeland. Such coverage \nwas mute before the 9\/11 attacks but, post-event, analysis of the causes took many column-inches. \nHow good are (i) human judgment and (ii) statistical forecasting at anticipating the occurrence of \nsuch events? Can techniques that incorporate human judgment in a structured way improve \nanticipation over and above holistic judgement? This paper analyses these issues and seeks to \nidentify the limitations on our ability to accurately anticipate the occurrence of rare, high-impact, \nevents. We also consider what the implications of these limitations are for organisational planning.  \n \nThe nature of predictability \n \nAssume that all forecasts can ultimately be represented as an objective or subjective probability \ndistribution. We may, of course, only report the forecast in terms of the event we consider most \nprobable (e.g. \u201cI forecast that a Democrat will win in 2012\u201d) or as a measure of   central tendency of \nthe distribution, such as the mean (e.g. \u201cThe expected level of demand next year is 2500 units\u201d) .  \nAlso, we are excluding forecasts that may be expressed in fuzzy terms (e.g. \u201cI think that there\u201fs a \ngood chance that the economy will perform well\u201d). Based on this assumption, Wright and Goodwin \n[2] argue that the term, predictability, can be interpreted on two levels. First, predictability can relate \nto the capability of forecasters to  produce a well-calibrated probability distribution. Perfect \n 4 \n \n4 \ncalibration would be achieved, for example, if it rains on 10% of days when we have said that the \nprobability of rain is 10%.  If it rains on more, or less, than 10% of those days then our probability \nassessment is mis-calibrated \u2013 i.e., we may be over-confident or under-confident in our assessment  . \nSimilarly, if our forecast is simply reported as the mean of the distribution, we would expect the \nmean outcome in the future to be close to this value if our forecast is well-calibrated. Of course, \nwhen forecasts are made relatively infrequently we may not able to measure calibration.  \n \nAlternatively,  even if forecasts are made frequently, we are by definition unlikely to be able to \ncollect much data for occasions when rare events occur; so measuring our capability of  assigning \nappropriate probabilities to such event will be problematical. Nevertheless,  the concept is still useful \nas a criterion for explaining what we mean by poor quality, or high-quality, forecasts. Note than \nwhen we use the term predictability in this sense we are referring to the capability of carrying out the \nprediction task in a valid way. Such predictability can be high even when there are a large number of \npossible events that can occur, each with a low probability of occurrence, as long as our estimates of \nthese probabilities are well-calibrated. In  a draw in the UK national lottery  one of 13,983,816 \ndifferent sets of number can be selected. However, such events are predictable, in this first sense, \nbecause we can determine a perfectly calibrated probability  for each set. \n \nSecond, predictability can be interpreted as relating  to the dispersion of the probability distribution \u2013 \nthe more dispersed this is then the higher will be the expected error associated with a particular \nquantitative point forecast or, if the forecast is expressed as a statement that a particular event will \noccur, the lower will be the probability that the statement will be correct. For example, by this, \nsecond, definition of predictability, if the future demand for a product is approximately normally \ndistributed with a standard deviation of 250 units, then the outcome of future demand will be more \npredictable than if the standard deviation had been 500 units. Thus, in this second sense, the \n 5 \n \n5 \npredictability of sets of numbers in the UK national lottery is low. If you predict that a given set of \nnumbers will be drawn then you only have a 1\/13,983,816  probability of being correct. \n \nWright and Goodwin [2] argue that if well-calibrated probabilities can be obtained, decision theory \ncan be used to make rational decisions on the basis of them, even if the predictability (in the second \nsense) is low  [3].  If we have a reliable probability estimate for the occurrence of  an earthquake in a \nparticular county in the next ten years we can use a rational process to assign an appropriate level of \nresources in anticipation of that event, even if this probability is very low. If we do not have a \nreliable estimate then we may assign an inappropriate level of resources. It is therefore the first form \nof predictability \u2013 the ability to establish well calibrated forecasts - that is the topic of this paper \n(hereafter we will use the term in this sense only). While our prime interest is in events that have the \npotential to have a major impact it should be noted that the probability of these events is not \nnecessarily low \u2013 the probability of an important event may actually be quite high, we may simply \nhave not recognised this.   We will first examine the potential reasons why predictability in a given \nsituation may be low. Then we will compare the effectiveness of methods that are designed either to \nimprove predictability - or to allow for effective planning when predictability cannot be improved. \nWe then consider the implications for planning in organizations. \n \n \nSix causes of low predictability \nSparsity of  reference class \nPredictability will be greater when we have data on a large set of similar events (i.e., a large \nreference class) from which relative frequency information can be obtained. This will be the case \nwhen events are defined more generally - the greater the specificity of the definition, the smaller will \nbe its reference class. The number of terrorist attacks of any kind in the world in the course of a year \n 6 \n \n6 \nis therefore more predictable than the number of terrorist kidnappings occurring in the course of a \nweek.  Large reference classes are akin to larger samples of a population \u2013 they allow us to make \nmore reliable assessments of the underlying probability distribution. Large reference classes also \nlend themselves to statistical analysis, so that judgmental biases can be avoided in the estimation \ntask. Thus for some events,  like the number of earthquakes or hurricanes that might occur in the \nworld in the course of a year, it is possible to establish relative-frequency-based, objective, \nprobabilities and these probabilities are likely to be well-calibrated. In contrast, novel events, for \nwhich there are no past analogies, such as the \u201dthe Gulf stream will stop flowing  within twenty \nyears\u201d are likely to be highly unpredictable. \n \nReference class is outdated or does not contain extreme events \nReference classes are bound to be biased samples of potential events because they sample \u2013 and they \nsample only the past and not the future.  This will be a problem when systems that impact on the \noccurrence of those events are subject to fundamental changes. Reference classes are also likely to \nbe biased because very rare events with potentially massive impacts are, by definition, unlikely to be \nincluded in the sampling - so that their probabilities of occurrence (or even possibilities) are \ndiscounted due to sampling bias. The use of a reference class can, therefore lead to poorly-calibrated \nforecasts for the occurrence of rare, high impact, events. \n \nUse of inappropriate statistical models \nEven when a reference class is rich in data, there is a danger that poorly-calibrated forecasts may be \nobtained - because of erroneous assumptions and the use of an inappropriate probability distribution. \nThis may occur when people view mistakenly review the reference class as being a reliable sample \nof possible events and ignore the issues mentioned above. For example, Taleb [4] reports that \nfinancial models often assume that changes in stock prices follow a normal distribution yet, the stock \n 7 \n \n7 \nmarket crash of Black Monday represented a fall of  20 standard deviations from the mean and \nhence, if the normal distribution assumption is true,  should only have occurred once in  \u201eevery \nseveral billion lifetimes of the universe\u201f [4]. \n \nModels are also bound to be simplifications of real systems and may not fully account for complex \ninteractions between elements of these systems. This is likely to be true of models of the economy, \nweather systems or the human body  [5]. The effect of minor changes in one part of the system or in \ninitial conditions can be amplified through these interactions. Thus the range of uncertainty indicated \nby the  model may under estimate  the true range so that the generated probabilities are poorly \ncalibrated. Drawing analogies from systems biology, Orrel and McSharry [5] have suggested that \nusing a single model to capture the behaviour of these complex systems is inappropriate and that \nwhat is needed is the use of different approaches to model different aspects of systems. These \nmultiple approaches will require the collaboration of experts in different fields. However, these \nsuggestions have, as yet, been untested in areas such as climate, economic or political forecasting \nand the authors themselves appear to have some doubts about their likely success when they argue \nthat \u201cinstead of trying to predict the future, [perhaps] we should use models to better understand a \nsystem\u201fs behaviour.\u201d \n \n \nThe Danger of Misplaced Causality \nMost models will be based on the assumption about the causal relationships between variables. \nHowever, a coherent theory of causality, which provides a good fit to data in the reference class and \nwhich may have the support of a broad consensus of experts in the relevant field,  does not establish \nthat the causality exists. For example, there is a strong correlation between carbon dioxide emissions \nand global temperatures and a coherent theory to explain this linkage which has received widespread \n 8 \n \n8 \nscientific support. However, this has not prevented challenges to this theory of the cause of global \nwarming.  Correlations may be spurious (e.g. they may result from hidden third factors),  or they \nmay only apply in the conditions that are relevant to the reference class data . Moreover, when \nhuman judgment is involved (see below), correlations may be illusory [6] with preconceived \ncorrelations being confirmed in the judge\u201fs mind by the selective recall of instances that accord with \nthe belief in the correlation. The fallacy that a high correlation necessarily implies causation is \nwidely encountered and can be a powerful influence of people\u201fs reasoning. \n \nCognitive biases \nWhen the reference class contains insufficient cases for statistical estimation, human judgment is  \noften used to estimate the probabilities of  events occurring.   Much of the research on the quality of \nhuman judgment of probability has stemmed from the work of Tversky and Kahneman  [7] who \nargued that people use simple mental strategies or heuristics to cope with the complexities of \nestimating probabilities. While these heuristics can sometimes provide good estimates and reduce \nthe effort required by the decision maker, they can also lead to systematically biased judgments. The \nthree main heuristics identified are: \ni) Availability.  Here, events within the reference class which are vivid, recent, unusual or \nhighlighted by the media are readily recalled or envisaged and therefore assigned high probabilities. \nAvailability can be a reliable heuristic since frequently occurring events are usually easier to recall \nso the higher probabilities estimated for them should  be reliable. However, the ease with which an \nevent can be recalled or imagined sometimes has no relationship to the true probability of the event \noccurring.  For example, some events are easily recalled precisely because they are unusual and rare. \nBy contrast, events that have never occurred, or only occurred in the distant past, may be assigned a \nde-facto probability of zero, or near-zero. \nii)  Representativeness. This heuristic describes a tendency to ignore base rates frequencies and was \n 9 \n \n9 \ndemonstrated by Tversky and Kahneman in a series of experiments where participants were asked to \njudge the probability that an individual had a particular occupation. Participants were given both \nbase rate information and a low-quality, but stereotypical, description of the person. The finding was \nthat valid base-rate information was ignored. This and related studies indicate that even when useful \nreference class information is salient for utilisation in forecasting  it will be ignored in favour of \nephemeral, low-validity, individuating information. Indeed, Kahneman and Lovallo [8]\n \nhave argued \nthat people tend to see each individual forecasting problems as unique when it would best be thought \nof as example  of the  broader  reference class of events. Hence they  tend to pay particular attention \nto the distinguishing features of the problem in hand and reject analogies to other instances of the \nsame general type as superficial. For example, Cooper, Woo and Dunkelberger\n \n [9] found that \nentrepreneurs who were interviewed about their chances of business success produced assessments \nthat were unrelated to objective predictors such as college education, prior supervisory experience \nand initial capital. Moreover, more than 80% of them described their chances of success as 70% or \nbetter while the overall survival rate for new businesses is as low as 33%.  \n \nGigerenzer  [10] argues that we are simply not equipped to reason about uncertainty by assessing \nsubjective probabilities for unique events but that we can reason successfully about uncertainty with \nfrequencies. For example, the entrepreneurs might have been asked instead: \u201cWhat percentage of \nnew businesses are successful?\u201d. However,  obtaining relative-frequency-based assessments is not \nfeasible for rare events because a reference class of previous forecasts or historic frequencies is not \navailable. If human thinking is best expressed, and thought of, as that of frequency thinking rather \nthan probabilistic thinking this conceptualization clearly does not help in the anticipation of high-\nimpact rare events. \n \n 10 \n \n10 \niii)     Anchoring and insufficient adjustment.  Here, forecasts that are used in the decision process \nmay be biased by forecasters anchoring on the current value and making insufficient adjustment for \nthe effect of future conditions. Alternatively, there may be a tendency to anchor on the probability of \nsingle events when estimating the probability that a particular combination of events will occur. For \nexample,  if an individual component of a system has a 0.9 probability of functioning perfectly over \na given time scale this probability may unduly influence an estimate of the probability that all 100 \ncomponents of the system will function perfectly over the period in question.  \n \nFrame blindness  \nThe  frame refers to how one views and structures a prediction problem. It involves determining \nwhat must be predicted, the form the prediction will take (e.g. point estimate or prediction interval), \nwhat factors are likely to impinge on the event that is to be predicted, the consequences of inaccurate \nprediction, the likely reliability of the prediction and the effort and resources that it is appropriate to \ndevote to the prediction task. Since predictions are made to inform decisions the prediction frame \nwill be closely aligned with the way that the corresponding decision has been framed. Frames are \nbound to be simplifications of real problems and each of them will only give a partial view of a \nprediction problem. For example, different frames will emphasise different potential influences on \nthe event that is being predicted or they may attach different degrees of importance to the potential \nerrors associated with the prediction, Difficulties can arise when a single frame is used \nunquestionably by forecasters, perhaps because of habit or professional specialism. Managers\u201f \nmental models of the world, exemplified by the use of a single frame, are analogous to single visual \nperspectives on a scene. One viewpoint through a window frame may mean that only part of the \nexternal world is in view while another observer, looking through a different window frame, may see \nmore (or less) of the external environment. Additionally, the past experience of the observer shapes \nhis or her (mis)interpretation of events that occur.  \n 11 \n \n11 \n \nIn one study the variability between individual managers\u201f mental models of competitive structures in \nthe UK grocery retailing industry was examined [11]. Considerable variation was found in the nature \nand complexity of industry views from managers both within and between companies. This diversity \nwas associated with the functional roles that individual managers held. Barr et al. [12] addressed the \nissue of why some organizations are able to realign their strategy with a changing environment, \nwhilst others are not, offering a cognitive explanation for the lack of organizational renewal. They \nargued that \u201ehuman (cognitive) frailties mean that managers\u201f mental models of the competitive \nenvironment may be incomplete or inaccurate, and that these models \u201eoften fail to change in a timely \nmanner in response to a changing environment\u201f (p 17). At the same time, political pressures within \nthe organization act to quell dissonant or \u201edeviant\u201f opinion, which recognize the true, paradigm-\nthreatening nature of the information (see also [13]). \n \nAll of  this indicates that habitual frames of reference may come to dominate thinking and changes \nin the world that may herald the occurrence of rare, high impact events may not be recognized as \nsuch. Consider, for example, the dramatic sub-prime mortgage crisis that started in the US. The \ncausal factors behind the crisis now seem obvious, with hindsight. But these causes seem not to have \nbeen so obvious to the finance industry insiders, a-priori.  \n \nSolutions? \nWe next assess the extent to which these six causes of the low predictability of high-impact, rare \nevents can mitigated by approaches that have been proposed either to improve the calibration of \nforecasts or to enable effective planning to take place when it is assumed that unpredictability cannot \nbe reduced. Table 1 provides a summary of how well each of these methods is likely to impact on, or \nbe impacted by, the six causes of unpredictability that we have just outlined. Some of the strengths \n 12 \n \n12 \nTable 1: How the methods relate to the sources of unpredictability \nSource of unpredictability \nStatistical \nforecasting \nExpert \njudgment \nDecomposed \njudgment \nStructured \nanalogies \nJudgmental \nadjustment to \nstatistical  \nforecasts \nDelphi Prediction \nmarkets \nScenario planning \nSparsity of reference class Unreliable in \nthese \ncircumstances \nMay outperform \nstatistical methods in \nthese circumstances \nMay outperform \nstatistical methods \nin these \ncircumstances \nSupports best \nuse of available \ncases in \nreference class \nMay lead to \nimprovements \nover statistical \nforecasts in these \ncircumstances \nAddressed, in \nprinciple, by \nexchange of \nreasons \nMay outperform \nstatistical \nmethods in \nthese \ncircumstances \nAnalysis of causal  \ninteractions allows  \nparticipant to see beyond  \nexisting reference class \nInappropriate reference class Unreliable in \nthese \ncircumstances \nExpert  may focus on \nexplaining current \ncircumstances and \nlose the wider picture \nUnreliable if \nreference class is \nused \nUnreliable in \nthese \ncircumstances \nUnreliable if \nreference class is \nused \nAddressed, in \nprinciple, by \nexchange of \nreasons \nFast response to \nnew information  \nmay counter this \nproblem \nDanger of anchoring \n scenarios in current  \neconomic conditions and  \ncurrent media concerns \nInappropriate statistical \nmodel \nUnreliable in \nthese \ncircumstances \nNot applicable Not applicable Not applicable Mixed evidence \non whether \nadjustments can \ncompensate for  \nmodel  \nNot applicable Not applicable Not applicable \nMisplaced causality Model may \nembed false \nassumptions \nabout causality \nExpert may focus on \n\u201epet theory\u201f and \ndefend its use with \nvigour \nDecomposition \nstructure may \nemphasise false \ncausality \nassumptions \nSelection of \nanalogies may \nbe predicated \non false  causal \nassumptions \nAdjustments may \nreflect illusory \ncorrelations  \nReasons \nexchanged \nmay reflect \nparticular \ntheories about \ncausality \nwhich may be \nfalse  \nParticipants in \nthe market may \nbe influenced by \nthe paradigm \nwhich is \ncurrently \npopular.  \nScenarios depend on beliefs \n that particular causal \n chains apply \nCognitive biases Avoids \nproblem for a \ngiven data set, \nbut biases may \napply in \nselection of \ndata & method \nExperts are likely to \nsuffer from cognitive \nbiases \nBiases should be \nreduced by \ndecomposition  \nBiases in recall \nof similar cases \nshould be \nreduced \nUnreliable in \nthese \ncircumstances, \nbut structured \nmethods may \nimprove \nreliability \nAddressed, in \nprinciple, by \ndialectical \nnature of \nprocess and \naveraging of \nindividual \nestimates \nMitigated in \npart by \naggregation of \nindividual \nestimates \nSimulation heuristic may  \nlead to inappropriate  \nconfidence that a detailed \n scenario will unfold \nFrame blindness Not addressed Unlikely to be \naddressed by expert \nassociated with a \nparticular \u201eschool of \nthought\u201f \nNot addressed. \nStructure of \ndecomposition \nwill be predicated \non current frame  \nNot addressed Not addressed Addressed, in \npart, by \ndialectical \nnature of \nprocess \nNo mechanism \ninherent in the \nmethod for \nchallenging  this \nMay reinforce existing frame \n unless \u201eremarkable people\u201f \n are employed to challenge \nparticipants\u201f frames of \n reference \n 13 \n \n13 \nand limitations of these methods may also apply when the probabilties of frequently occurring \nmethods are being assessed. However, in these circumstances there is more chance of  rapid and \ndata-rich feedback on the accuracy of the forecasts so that errors and biases may be recognised and \ncorrected more quickly.  \n  \ni) Statistical forecasting \nWhen there is a large reference class of relevant data, statistical forecasting has the advantage that \nthis data can be handled completely and efficiently, thereby precluding the cognitive biases \nassociated with human judgment (although, in economic forecasting, data series used in model \nbuilding are often inaccurate and liable to be  revised, sometimes after significant delays). That said, \nthere is nothing inherent in statistical forecasting to warn that the forecasting problem may have \nbeen inappropriately framed and that attention is being paid to forecasting the wrong phenomena. \nFor example, we may focus our efforts on forecasting the behaviour of competitors in our industry or \nthe effects of our marketing mix, when the real impact on our company\u201fs well being will come from \nnew industries based on novel technologies.  Events sometimes have a high impact precisely because \nthey represent a change from events contained in the reference class that is thought to be relevant.  \n \nIn addition, judgmental and motivational biases may apply in the choice of  forecasting method  and \ndata. Changing conditions in an industry may mean that data on only the most recent members of the \nreference class are relevant. The longer the lead time of the forecast then the greater the danger that \nfew, if any members, of the reference class will be useful. Alternatively, in the short term, there may \nbe a tendency to fit models only to recent members because of over-reactions to events and \nperceptions of  changes that are really only noise [14].   \n \n 14 \n \n14 \nCausality can also be problematical for statistical methods. Correlations between variables do not \nprove causality so the selection of independent variables needs to be based on some external theory \nof what is likely to account for variations in the dependent variables. However, such theories are \nthemselves likely to have been informed or supported by the extent to which they fit past \nobservations and they may be inapplicable to conditions that will apply in the future. \n \nAssumptions that forecasting errors are normally distributed may be tempting because they simplify \nthe analysis and allow access to a well-established body of techniques. Such assumptions have been \nprevalent in portfolio analysis variance at risk (VaR) techniques [15]. However, these methods tend \nto underestimate the probability of extreme events when the \u201etrue\u201f distribution is \u201efat-tailed\u201f. This is \nbecause most of the data used in fitting the model  is close to the central tendency of the distribution \nand data on extremes is by definition, rare. Extreme value theory has attempted to avoid this bias by \nconcentrating analysis on the extremes and using distributions such as the generalised extreme value \ndistribution (GEV). This has a tail index parameter which determines the thickness of a \ndistribution\u201fs tail. However, extreme value theory still faces a number of challenges [15]. The small \namount of data that is available on extremes has to be used to determine if the \u201etrue\u201f distribution is \nindeed fat-tailed and to estimate the parameters of the distribution.  In addition, defining a threshold \nfor what is deemed to be an extreme event, and hence should be included in the estimation process, \ncan be problematical.  Lowering the threshold increases the number of observations available for \nestimating the tail index  so that the estimate is more  precise, but it is also likely to bring in \nobservations that are closer to the central tendency so that the bias in the estimate is increased. \n \nThe complete absence of extreme events, above a certain threshold, from the reference class means \nthat they can only be forecast by extrapolation. Extrapolation involves the strong assumption that the \nrelationship between dependent and independent variables remains the same beyond the observed \n 15 \n \n15 \ndata set. For example, assumptions of linear relationships may not apply far beyond the observed \ndata.  \n \n \nii) Expert judgment \nStatistical methods will be unreliable when membership of an appropriate class is sparse. In these \ncases recourse may be made to the use of experts\u201f judgmental forecasts. Research on the quality of \ncalibration performance of experts\u201f probability assessments \u2013 usually with respect to forecasting \nperformance - has been found, in several instances, to be very good; for example, [16] (financial \ninterest rates); [17] (horse racing); [18]  (the card game, Bridge); and, most strikingly, in weather \nforecasting  [19].  Conversely, in several instances poor calibration has been found  -for example \n[20] (clinical psychologists) and  [21] (maize judges).  More recently, Tetlock  [22] collected 82,361 \npolitical and economic forecasts from experts asking them to estimate probabilities for various \nevents. They performed worse than chance \n \nJudgmental probability forecasts are routinely generated in weather forecasting.  Indeed, the official \nforecasts issued by the National Weather Service in the United States are subjective probability \nforecasts.  Murphy & Brown  [19] evaluated these subjective forecasts and found that, for certain \ncategories of weather, they were more accurate than the available objective statistical techniques.  \nThe weather forecasters have a very large amount of information available, including the output \nfrom statistical techniques.  They also receive detailed feedback and have the opportunity to gain \nexperience of making forecasts under a wide range of meteorological conditions.  Furthermore, they \nhave considerable practice in quantifying their internal state of uncertainty.  These circumstances \nmay well be ideal for the relatively successful application of judgmental as compared to purely \nquantitative forecasting.   \n 16 \n \n16 \n \nMore widely, Bolger & Wright  [23] and Rowe & Wright [24] have argued that in many real world \ntasks, apparent expertise (as indicated by, for example, status) may have little relationship to any real \njudgment skill at the task in question.  In Bolger and Wright\u201fs review of studies of expert judgmental \nperformance they found that only six had showed \u201cgood\u201d performance by experts, while nine had \nshown poor performance.  Bolger and Wright analysed and then interpreted this pattern of \nperformance in terms of the \u201cecological validity\u201d and \u201clearnability\u201d of the tasks that were posed to \nthe experts.  By \u201cecological validity\u201d is meant the degree to which the experts were required to make \njudgments inside the domain of their professional experience and\/or express their judgments in \nfamiliar metrics.  By \u201clearnability\u201d is meant the degree to which it is possible for good judgment to \nbe learned in the task domain.  That is, if objective data and models and\/or reliable and usable \nfeedback are unavailable, then it may not be possible for a judge in that domain to improve his or her \nperformance significantly with experience.  In such cases, Bolger and Wright argued, the \nperformance of novices and \u201cexperts\u201d is likely to be equivalent and they concluded that expert \nperformance will be largely a function of the interaction between the dimensions of ecological \nvalidity and learnability \u2013 if both are high then good performance will be manifest, but if one or both \nare low then performance will be poor.   \n \nWright et al., [26] studied expert life-underwriters and attempted to ensure that the expert-task match \nwas as strong as possible (given experimental limitations), and that ecological validity was high, and \nyet still obtained expert performance that was not much better than lay person performance.  This \nresult suggests that the underwriting task is not truly \u201clearnable\u201d, i.e.,it is not one for which there is \nregular feedback on the correctness or otherwise of judgments.  Indeed, in the training of \nunderwriters, performance is assessed according to the similarity of junior underwriters\u201f judgments \nto those of their seniors  [27].  Once \u201ctrained,\u201d underwriters receive infrequent performance-related, \n 17 \n \n17 \nobjective feedback about the correctness of their judgments, and indeed it would be difficult to \nprovide such feedback, given that a \u201cpoor\u201d judgment might turn out to be insuring an applicant who \nsubsequently died of a condition after perhaps 20 years of a 25-year policy.  \n \nAs such, the tasks performed by other professional risk assessors may also be unlearnable.  For \nexample, in the case of major hazards in the nuclear industry there may be no risk\/judgment \nfeedback at all and the calibration of expert judgment cannot be assumed.  Similarly, recall  \nthe validity of expert predictive judgments about the likelihood magnitude of human infection by \n\u201cmad cow disease\u201d resulting from eating beef from herds infected with Bovine Spongiform \nEncephalopathy (BSE) in the early 1990\u201fs and the subsequent, poorly predicted, mortality rates [25]. \nHere the fact that the event was novel and unique precluded the availability of feedback. We \nconclude that the common sense assumption of the veracity of expert judgment of the likelihood of \nrare, high-impact events is ill-founded.  The lack of a reference class of prediction-outcome data for \nsuch rare events means that experts cannot learn from feedback, over time. It follows that bias in \nexpert judgment is, likely to be prevalent - since solely heuristic processes can be utilized by experts \nin the generation of forecasts. In addition, Tetlock  [22] found that the experts in his study were \nskilled at inventing excuses for the errors in their forecasts. (e.g. \u201cI was almost right\u201d, \u201cmy timing \nwas just off\u201d or \u201cI made the right mistake\u201d) This would further reduce any chance they had of \nlearning from the very limited outcome feedback that they received. \n \n \niii) Structured judgmental decomposition \nAs indicated earlier, judgmental forecasts may be subject to cognitive biases Decomposition of the \nforecasting task into smaller and hence easier judgmental tasks, it is argued, should improve the \nquality of any estimates elicited, including probabilities [28]. For example, the greater ease with \n 18 \n \n18 \nwhich the component tasks can be carried out may reduce reliance on over-simplifying heuristics \nand hence reduce the effect of their associated biases.  \n \nDecomposition, using event trees or fault trees [29] may be particularly helpful when probabilities of \nvery rare events have to be estimated. Availability bias, caused for example by the reporting of \nunusual events in the media,  may lead to the probabilities of very rare events being over estimated \nwhile people may also have difficulty in distinguishing  between probabilities like  0.00001 and  \n0.0000001  [3]. In these circumstances, an event tree could be formulated to depict the combinations \nof events which might foreshadow a rare event. The tree would then allow probability estimates to \nbe made for these precursor events, rather than the rare event itself.  Many of these events may be \nrelatively frequent and be associated with large reference classes so that statistical methods could be \nused to estimate their probabilities.  These probabilities can then be multiplied to establish the \nestimated probability of the rare event.  \n \nDecomposition has other potential advantages. In decision analysis, for example, the separation of \nthe probability estimation tasks from the consideration of the attractiveness of outcomes, may reduce \nthe effects of wishful thinking or optimism bias. In addition, the process of explicit quantification \n\u201eforces participants to express their assumptions and beliefs, thereby making them transparent and \nsubject to challenge and improvement\u201f [30].  It also can act as an antidote to groupthink  [31] where \nrisks are ignored or underplayed by groups of decision makers. By forcing explicit consideration of \nthe possibilities, decomposition may help to bring hitherto unrecognised opportunities or threats to \nthe surface so that appropriate and timely action can be taken. \n \nHowever, decomposition is not a panacea for the elicitation of judgmental forecasts. The events for \nto which the decomposition is being applied may depend on a restricted or inappropriate decision \n 19 \n \n19 \nframe.  As a result the wrong problem may be addressed and probability assessments may not be \ncarried out for events which represent fundamental changes from the status quo and which can have \nmajor impacts in the future. Moreover, the structure of the decomposition is likely to depend on \nparticular beliefs about what constitutes the casual chain of events.  In addition, there may be \nproblems in motivating forecasters to engage in decomposition because it involves an explicit \nexposure of one\u201fs assumptions, which may then be subject to challenge, while, if the decomposition \nis detailed it can involve considerable time and effort.  Motivation is likely to be particularly \nadversely affected where the decomposition method is unfamiliar to the person making the forecast \nor there is scepticism about the technique that is being used to implement it [28]. \n \niv) Structured analogies \nAnother approach to improving judgmental forecasts involves drawing the forecaster\u201fs attention to \nwhat is available in the reference class by highlighting the role of analogies. Without this support \npeople may rely informally on their ability to remember similar cases so availability bias may result \nfrom a propensity to recall recent or unusual cases. When the use of judgment is appropriate it is \nlikely that the membership of the reference class will be small. Because of this some researchers \nhave proposed approaches that allow access to the reference class to be structured so that improved \ninferences can be drawn from it despite its sparsity.  For example, Lee et al [32] investigated ways of \nimproving judgmental estimates of the effect of future sales promotions by providing a database of \npast promotions and deploying an algorithm which displayed the promotions that were most similar \nto the forthcoming promotion, together with their estimated effects on demand. Obtaining a useful \nnumber of analogies necessarily involved selecting  past promotions which differed to some extent \nfrom the target promotion (e.g. in their timing, type or sales region) so Lee et al.\u201fs forecasting \nsupport system also provided a simple facility that  allowed the user to explore the likely effect of \nthese differences. This helped them to estimate the size of adaptations they needed to make to the \n 20 \n \n20 \npromotion effects of the selected cases when making their forecasts. The structured use of analogies \nhas also been investigated in the context of conflict forecasting by Green and Armstrong [33]. Here, \nexperts were asked to recall conflicts that were similar to the target case, to state the outcome of \nthese conflicts and to rate their degree of similarity with the target. An administrator then combined \nthis information to produce a forecast. In both of these studies the structured approach to the use of \nreference class information led to significant improvements in forecast accuracy.  \n \nHowever, in the case of rare events, there is a danger that this emphasis on past analogies may \ndistract the forecaster\u201fs attention away from the possibility of events which are not within the \nexisting reference class, particularly rare and extreme events \u2013 a situation which is highly likely \nwhen membership of the reference class is sparse.  Also, the selection of similar events through \neither algorithms or expert judgment also may be predicated on a particular view of causality (e.g. \nthat the effects of sales promotions are dependent on the characteristics that have been selected for \nstorage in a database or that conflicts that are judged to be similar on a set of characteristics will  be \nresolved in the same way because of these characteristics). \n \nv) Statistical forecasting with judgmental intervention or adjustment \nSome systems manifest regular behaviour that is occasionally disturbed by the effects of foreseeable \nspecial events. For example, a time series of the demand for a product may exhibit regular seasonal \npatterns, which are disturbed when the product is promoted or subject to a change in taxation. In this \nsituation statistical methods are likely to provide well calibrated forecasts during normal periods. \nHowever, the effects  of the special events (these are sometimes referred to as \u201cbroken leg\u201d cues) \nmay be relatively unpredictable.  When these events are infrequent or unique, the absence of a large \nreference class of similar events will preclude the effective use of statistical methods. In these cases \nforecasters may apply their judgment to estimate the effects of the special event.  \n 21 \n \n21 \n \nIn companies, managers commonly adjust statistical baseline forecasts to take the effect of special \nevents into account, while economists often apply judgment to the components of econometric \nmodels [34, 35]. Laboratory and real world studies have demonstrated that such adjustments \ntypically improve the accuracy of the baseline forecasts [36, 37].  There is, however, mixed evidence \nthat they can compensate for situations when an inappropriate statistical model has been applied to \nthe data [38, 39].  Moreover, research also suggests that there is much scope for enhancing \npredictability in these situations. First, decisions on when to intervene are often poor with a tendency \ntowards over intervention as people falsely see special cases in random movements in the graph or \nare motivated to adjust forecasts to reinforce a sense of ownership of the forecasting process [36, \n40].  Second, estimates of the size of the required adjustment  are subject to cognitive biases. As a \nresult, they often poorly calibrated with the outcomes of the special events. Clearly, the \ndecomposition and structured analogies approaches outlined in the last section may be effective in \nimproving judgmental adjustments as well as forecasts that are wholly based on judgment. \n \nvi) Delphi \nJudgement, alone, is used in the Delphi procedure where multiple individuals are initially required to \ngive separate numerical judgements or forecasts \u2013 often years into the future and often for high-\nimpact events. These forecasts are, likely to be revised in the light of feedback provided  \nanonymously by other members of the Delphi panel, over a number of subsequent \u201erounds\u201f or \niterations.  Response stability found across panellists, is the signal to cease additional iterations and \ntake the average of the final round as the Delphi yield.  \n \nDelphi\u201fs effectiveness over comparative procedures, at least in terms of judgemental accuracy, has \ngenerally been demonstrated.   In a review of empirical studies of Delphi, Rowe and Wright \n 22 \n \n22 \n[41]found that Delphi groups outperformed \u201estatistical\u201f groups (which involve the aggregation of the \njudgements of non-interacting individuals) in twelve studies, underperformed these in two, and \u201etied\u201f \nin two others, while Delphi outperformed standard interacting groups in five studies, \nunderperformed in one, and \u201etied\u201f in two.  This trend is all the more impressive given that many \nlaboratory studies of Delphi effectiveness have used simplified versions of the technique (e.g. with \nlimited feedback) in simplified contexts (e.g. using non-expert, student subjects) that might be \nanticipated to undermine the virtues of the technique. \n \nAlthough research suggests that Delphi allows improved judgement compared to alternative \nmethods, as demonstrated in these \u201etechnique comparison\u201f studies, the reasons for this are still \nunclear, given relative dearth of \u201eprocess\u201f studies that have attempted to establish the precise \nmechanism for improvement in Delphi.  Generally, it is assumed that Delphi improves judgemental \naccuracy because of the feedback provided between rounds \u2013 in conjunction with the panellists\u201f \nanonymity.   Rowe and Wright [42] compared three feedback conditions: an \u201eIteration\u201f condition \nover rounds without feedback from the members of the Delphi panel), a \u201eStatistical\u201f feedback \ncondition (involving median values and range of estimates), and a \u201eReasons\u201f feedback condition \n(involving reasons from the Delphi panellists along with their numerical estimates).   They found \nthat, although subjects were less inclined to change their forecasts as a result of receiving Reasons \nfeedback than other types, when they did change forecasts, this change tended to be for the better, \nleading to a reduction in error.   Although subjects tended to make greater changes to their forecasts \nin the Iteration and Statistical conditions than in the Reasons condition, these changes did not, in \ngeneral, improve predictions.  \n \nAs such, there is indicative evidence that the receipt of reasons why a particular numerical forecast is \nbeing advocated by a panel member is a useful source of information that can be used to improve \n 23 \n \n23 \nother panelists\u201f predictions.   However, note that the focus of the Delphi procedure is on the \nprediction of single target variables such as the date of occurrence of a future event or a point \nestimate of an uncertain future quantity. Delphi is a well utilised procedure and most applications \nfocus on forecasts of a 20 \u2013 25 year horizon.   The exchange of reasons between panellists can, in \nprinciple, alert panellists to inappropriate framings, biases in the recall of similar cases, utilisation of \ninappropriate reference classes, cognitive bias, and inappropriate views of causality underpinning the \nunfolding of event chains. However, much depends on the degree of communication of the reasoning \nprocesses underpinning a particular panellists\u201f prediction. In most Delphi applications, many \npredictions are sought from expert panellists and so, in practice, exchange of elaborated reasons may \nbe attenuated. Also, exchange of reasons has not, to date, been a priority in practice \u2013 most \napplications of Delphi have involved the exchange of numerical estimates only. \n \nvii) Prediction markets \nPrediction markets offer an alternative method of obtaining estimates from groups. Participants  \ntrade contracts which typically stipulate that their owner will receive a sum of money (say $1) if a \nparticular event occurs and nothing otherwise. The current price of the contract is taken to be the \nparticipants\u201f  aggregate view of the probability that the event will occur. Certain theoretical \nconditions have to be met for this to be the case. (e.g that traders are risk averse and their beliefs are \nindependently normally distributed around the true value [43, 44])   However, the reliability of the \napproach may be robust to departures from these assumptions and empirical studies of the \nperformance of a diverse range of markets indicate that they do yield accurate results [45]. \nPrediction markets offer the advantage that they rapidly respond to the latest information so that \nwhich may reduced the danger of  heavy dependence on out-of-date members of the reference class \nAlso the aggregation of individual estimates may counter the cognitive biases of individual \nforecasters.  \n 24 \n \n24 \n \nNevertheless many of the reports of accurate  forecasts obtained from prediction  markets relate to \ncircumstances  where there was a  relatively small set of  possible outcomes (e.g. outcomes of \nresearch and development projects, winners of  Presidential elections, successes of new products \nwhich films will be box-office successes, Oscar winners and outcomes of sports events).  There is \nless evidence about their success in  producing well calibrated probabilities for rare events.  Indeed, \nthere would have to be some awareness of the possibility of such an event in the first place in order \nfor a contract relating to it to be formulated in the first place. Moreover,  the  high level of stock \nmarkets\u201f prices before  the credit crunch of 2008 suggests that  markets may not be good predictors \nof such events. The  majority of participants in a market may be influenced by predominant views \nabout causality presented by the mass media. In addition, when anonymous reasons underlying \njudgments are exchanged in a Delphi process, people have an opportunity to learn and hence \nimprove their estimates. In prediction markets no such information is shared so there are no \nopportunities to challenge the  potential frame blindness of individual participants. \n \nviii) Scenario planning \nThe practice of scenario planning implicitly accepts that managers are not able to make valid \nassessments of the likelihood of unique future events and that \u201ebest guesses\u201f of what the future may \nhold may be wrong. This view is in harmony with Gerd Gigerenzer\u201fs argument that probability \ntheory does not apply to single events. Advocates of scenario planning also argue that it can counter \ngroupthink by allowing minority opinions about the future to have \u201eairtime\u201f, relative to majority \nopinion. \n \nHow do scenarios achieve this? The first point to note is that a scenario is not a forecast of the \n 25 \n \n25 \nfuture. Multiple scenarios are pen-pictures of a range of plausible futures. Each individual scenario \nhas an infinitesimal probability of actual occurrence but the range of a set of individual scenarios \ncan be constructed in such a way as to bound the uncertainties that are seen to be inherent in the \nfuture \u2013 like the edges on the boundaries surrounding a multi-dimensional space. \n \nScenarios focus on key uncertainties and certainties about the future and use this information to \nconstruct pen-pictures in an information-rich way in order to provide vivid descriptions of future \nworlds. By contrast, subjective probabilities entered into a decision tree provide numerical values \nthat can be used in an expected utility calculation. The judgment process that produced such \nnumbers is often not verbalized or recorded. When individuals disagree about their subjective \nprobabilities for a critical event, then decision analysis practice is often to take an average, or \nweighted average, rather than to explore, in detail, the reasoning processes underlying individuals\u201f \nassessments. Inherent in such analysis is the assumption that it is useful and possible to attempt to \npredict the future, whereas scenario planning assumes that the best that can be done is to identify \ncritical future uncertainties and plan for the range of futures that could, plausibly, unfold. \nEssentially, scenarios highlight the causal reasoning underlying judgments about the future and give \nexplicit attention to sources of uncertainty without trying to turn an uncertainty into a probability. A \nmajor focus is how the future can evolve from today\u201fs point-in-time to the future that has unfolded \nin the horizon year of the scenario \u2013 say 10 years hence. The relationship between the critical \nuncertainties (as they resolve themselves \u2013 one way or the other), important predetermined trends \n(such as demographics, e.g. the proportion of the US population who are in various age bands in, \nsay, 10 years\u201f time) and the behavior of actors who have a stake in the particular future (and who \nwill tend to act to preserve and enhance their own interests within that future) are thought through in \nthe process of scenario planning such that the resultant pen-pictures are, in fact, seen as plausible to \nthose who have constructed the scenarios. \n 26 \n \n26 \n \nFigure 1 gives two examples of such causal analysis using data from a recent intervention, conducted \nby one of the authors, in a major EU bank involved in residential mortgage lending. The scenario \nmethod used was the \u201cintuitive logics\u201c approach \u2013 see [46, 47] for more detail. The two clusters \nwhich were viewed by workshop participants to be both (i) of the highest uncertainty and (ii) the \nhighest impact on the bank\u201fs operations are illustrated. \n \n \n \n \nAgeing Population\nNew \nProducts\/Criteria \nfor Older People\nNew Risk Profiles\nINTEREST ONLY TIMEBOMB?\nHas Underforming \nAssets \nNo Assets \neg Policies\nNew Products\nNew Mortgage\/\nProducts\nRemortgage\nHas Unpaid \nMortgages\nOption of \nLet to \nBuy\nSell\/Downsize?Will Continue to \nPay Interest or \nRent\nRent\n \n \n 27 \n \n27 \nRecovering \nMargins for Banks\nNew Products for all \nMarket Segments\nHEALTH OF BROKER CHANNEL\nTechnology + \nconfidence allows \ncustomer to buy \ndirect\nDifferent Direct \nChannels (Tesco)\nRegulation \nChanges\nLonger Term \nMortgage \nDeals\nLess \nChurn\nLess Broker \nDemand\n \n \n \nFigure 1: Two high impact, high uncertainty clusters \n \n \nNote that, in general, the two clusters that result from application of the intuitive logics approach to \nscenario construction will each contain a mix of pre-determined elements and critical uncertainties \nthat are causally linked together. The four scenarios that are constructed at the next step are derived \nfrom the resolution of events within each cluster into two major outcomes - with each of the two \noutcomes of the first cluster then being combined with each of the two outcomes of the second \ncluster (see [46], chapter 7, for more detail). Thus, resolution of the contents of the two high-impact, \nhigh-uncertainty, clusters drive the development of the storylines of the four resultant scenarios. The \ndevelopment of the four storylines will, in practice, also utilise other uncertainties and pre-\ndetermined elements that have been generated by scenario workshop participants but which are seen, \nby these participants, to have less impact on the focal issue of concern. of actual occurrence. \n \nNote that scenario planning is a practitioner-derived approach to dealing with uncertainty in decision \nmaking. It is not based on an axiom system \u2013 as is decision analysis \u2013 and so different practitioners \n 28 \n \n28 \ntend to promote different methodologies to construct scenarios. As we have seen, scenario thinking \nemphasizes the construction of causal \u201estorylines\u201f that describe how the future will unfold.  Such a \nway of anticipating the future seems to be quite natural. For example, Willem Wagenaar\n   \nin a study \nof how judges reach decisions in courtrooms has found, analogously, that judges and juries do not \nweigh probabilities that a defendant is guilty \u201ebeyond reasonable doubt\u201f. Instead, such decision \nmakers evaluate scenarios that describe why and how the accused committed the crime. One such \nscenario is, in principle, contained in the prosecution\u201fs indictment. The prosecution tells the story of \nwhat happened and the court decides whether that is a true story or not. \u201eGood\u201f stories provide a \ncontext that gives an easy and natural explanation of why the \u201eactors\u201f behaved in the way they did. \nSo, storytelling via scenario planning may be a natural way of making sense of the world. Because \nof its focus on causality, scenario planning is intuitively more attractive to managers and the take-up \nof scenario planning has been extensive compared to decision analysis \u2013 see [47]. Within a scenario \nplanning workshop, decision makers experience and acknowledge the continuing fluidity of an \nemerging decision context. Scenario planning does not evaluate options against uncertainties in a \nsingle process of analysis. Instead, once the range of plausible futures has been defined, these futures \ncan be utilized over an extended time period as and when new decision options are developed and \nsubsequently tested in the \u201ewindtunnel\u201f conditions. \n \nHowever, scenario planning is not without problems in aiding the anticipation of rare, high-impact \nevents. Availability bias can enter scenarios, such that recent and current media-emphasised \nconcerns (e.g. of financial downturns)  replicate themselves in to-be constructed scenarios. These \npractice-recognised issues have been labeled as as \u201cfuture myopia\u201d.  By contrast, as Wright et al [48] \nnote, one way, used in practice by scenario practitioners, is to provide challenge to the decision \nmakers\u201f mental models by the introduction of   \u201cremarkable people\u201d into the strategic conversation \u2013 \ni.e., by including, as participants, in a scenario exercise those individuals (often from outside the host \n 29 \n \n29 \norganization) who hold disparate and contradictory views on key uncertainties.   In the scenario \nintervention conducted by the authors with a EU bank\u201fs residential mortgage business, described \nearlier, the participant directors evidenced no recognition of factors that could lead to the \u2013 then just \nmonths away \u2013 sub-prime meltdown in the US and its subsequent impact on the UK housing market.  \nIn fact, at the time of our scenario intervention the bank was considering increasing its sub-prime \nexposure! Whether or not the inclusion of \u201cremarkable people \u201cin, what was, a purely internal \nscenario planning exercise would have placed the sub-prime meltdown on the scenario agenda is \nunknown. Scenario planning practitioners argue that between-workshop activity spent on \nresearching the nature of critical uncertainties identified in earlier workshops will also add to the \nquality of a strategic conversation about the nature of the future - but empirical evidence on the \nbenefit of such desk-based research has also not been conducted. \n \nInterestingly, only one extant study has provided an investigation of the impact of the use of scenario \nplanning on subsequent and contemporaneous corporate performance [49].   In that study, the \nauthors measured the degree of use of scenario planning in both water industry firms and IT \nconsulting firms.   However, the achieved questionnaire returns from the firms in these industries \nwas low (22 water and 25 IT) and so, in our view, even indicative conclusions cannot be drawn.  \nClearly, as yet, the benefits of scenario planning on an organizational performance have not been \nempirically demonstrated. \n \nCan the anticipation of rare events be improved? \nProtective strategies \nThe above discussion reveals that all of the extant methods contain weaknesses. Of particular \nconcern are those possible high-impact events that are implicitly assigned a probability of zero. As \n 30 \n \n30 \nsuch, decision makers using any or all of these methods will still be susceptible to surprises that may \nhave severely negative consequences or represent huge missed opportunities.  Makridakis and Taleb \n[50] argue that we should accept that accurate predictions of the occurrence of rare, high-impact \nevents are not possible and so should adopt protective strategies \u2013 such as hedging by use of \nfinancial \u201ccovered puts\u201d.  They argue that we should buy insurance to limit the downside of \nnegatively-valenced events (such as a huge loss of a major industrial plant) but allow the unlimited \nupside of  positively-valenced events (such as a possible huge gain by investing a small amount in a \nspeculative venture). Makridakis, Hogarth, and Gaba [1] argue that business strategies should be \nbuilt to the same analogous standard as buildings that are designed to withstand low-probability, but \nhigh-impact, earthquakes. Taleb [51] argues for redundancy in financial investment by retaining \n\u201cidle\u201d capital \u2013 so-called de-leveraging. He notes that human beings have some duplicate organs and \nalso some organs can take on new functions \u2013 so-called degeneracy. Thus, maximising redundancy, \nalthough increasing costs and restricting the possibility of leveraging resources, enables survival in \ndifficult times.   In a similar vein, Wright and Goodwin [2] argued that the decision maker should be \nalert to the degree to which any major strategic option is: (i) flexible \u2013 i.e., investment can be up-\nscaled or down-scaled at any point in the future; (ii) diversified \u2013 i.e., following the option that \ndiversifies the firm\u201fs current major offering(s)  by providing either a different technology base, a \ndifferent production base, or a different customer base;  (iii) insurable. This prescription can be \nimplemented as a necessary check-list that must be completed in any option evaluation or as part of \na more formalised, multi-attribute, evaluation of options against scenarios [52]. \n \nAttempting to  prepare  for all possible high-impact events \nAn alternative to having strategies to provide protection against unknown events which are assumed \nto be completely unpredictable is to try to identify all possible high impact events that might occur  \nand make contingency plans to deal with them For example, in the sphere of crisis management, \n 31 \n \n31 \nPearson et al [53] noted that many organizations prepare for the crisis that they believe most \nprobable or will have most impact if it occurs. These authors argue that , instead,  \u201c\u2026 the best-\nprepared organizations compile a crisis portfolio for an assortment of crises that would demand \ndifferent responses\u2026 this may seem a wasteful approach but\u2026 the most dangerous crises\u2026 cause \ngreater trouble, specifically because no-one  was thinking about or preparing for them\u201d (p 55).  \nHowever, the cost-benefit trade-off of preparing an organization for all possible crises is not \naddressed in the extant literature. Nor is a systematic approach offered to enable managers to rank-\norder crises for differential attention. \nWidening the range of possible scenarios \nIn the sphere of scenario planning, Wright and Goodwin [2] argued for an enhancement of the \nscenario planning process by creating a range of more extreme scenarios than those that result from \nuse of the intuitive logics scenario development methodology, described earlier.  Wright and \nGoodwin argued that scenarios should encompass a wider range of uncertainties in order to \nanticipate rare high-impact events. For example, a conventional range of scenarios for the UK \neconomy may contain GDP growth figures ranging from -2% to +5%. But how secure can decision \nmakers be that this represents the complete range of possibilities? Rather than moving forward \nthrough causal chains to arrive at scenarios, as in conventional, intuitive logics, scenario planning, \nWright and Goodwin\u201fs alternative is to work backwards from an organization\u201fs objectives. Here, the \nranges of possible achievement (worst possible and best possible case) for each of the main \nobjectives can be extended (i.e., made more extreme) and decision makers can be asked whether \nthere they can envisage particular interactions of pre-cursor events that make these, more extreme, \nbest- and worst-case levels of achievement plausible. Note the word \u201cplausible\u201d - plausibility implies \nthat the causal events underpinning a major scenario outcome can be articulated. As such, outcomes \nsuch as \u201cGDP growth of 3000%\u201d would not be deemed plausible and so would not be part of any set \nof such extreme scenarios. In a similar vein to Wright and Goodwin\u201fs backward logic scenario \n 32 \n \n32 \nmethod, Makridakis, Hogarth, and Gaba [1] argue that strategic thinkers should create a \u201cvirtual \ntime-machine\u201d and imagine that rare, high-impact, events have, in fact, happened. Next the \nstrategists should attempt to think-through their causation. In short, methods for widening the range \nof constructed scenarios are now under development but, of course, the resultant scenarios may still \nnot contain the particular rare events that actually occur. This is especially true if the causal \nunfolding of these events is, a-priori, opaque to scenario workshop participants.  \n \nPractical proposals for enhancing Delphi and scenario planning by incorporating devil\u2019s advocacy \nand dialectical inquiry  \nSchweiger, Sandberg and Ragan [54] observe that discussion and other interaction amongst top \nexecutives are the common ways in which information is shared and evaluated. But groups of \ndecision makers often smooth over conflict and the social pressure for social harmony amongst \nindividual group members is strong \u2013 such that group members become more concerned with \nretaining the approval of fellow members than coming up with good solutions to the task in hand.  \nAs Janis [55] noted, in discussing his concept of groupthink, these processes can lead to the \nsuppression of ideas that are critical of the decision on which the majority of a group is converging \nand, as such, there can be a failure to examine the risks of preferred decisions, a failure to re-appraise \ninitially\u2013rejected alternatives, a failure to work out contingency plans, and an increasing feeling of \ninvulnerability in the group\u201fs decision. As a remedy, Janis argued that  the leader should  (i) \nwithhold his own opinion - since in hierarchical organizations subordinates will also tend not to \ncriticise opinions proffered by those who are higher up the hierarchy, (ii) encourage new ideas and \ncriticisms, (iii) make sure that the group listens to minority views , and (iv) use processes designed \nto delay forming an early consensus.  \n \n 33 \n \n33 \nOf the methods that we have reviewed to aid the anticipation of rare, high-impact events, only \nDelphi and scenario planning provide some degree of argument-based challenge to thinking. As we \nhave seen, Delphi does this by the anonymous dialectical exchange of arguments for particular \npoints of view. By contrast, scenario planning does this by engaging a process whereby detailed \ncausal  stories for alternative plausible futures are constructed. But as we argued and demonstrated,  \nconventional scenario planning may,  in fact, replicate and  reinforce  existing frames of the future \nunless \u201cremarkable people\u201d are employed to challenge these framings. Groups tend to share \ninformation that the individuals have in common and the probability that a piece of information is \nshared in group discussion has been found to be proportional to the number of people aware of it \n[56].  \n \nIn the decision making literature, rather than the forecasting literature, alternative group-based \nmethods for improving decision making have been proposed and tested. We describe these \napproaches next and then re-formulate these approaches to aid the anticipation of rare events. \nSchweiger et al [57] discuss alternative approaches to engender debate and evaluation of decisions in \nmanagement teams. They differentiate (i) dialectical inquiry and (ii) devil\u201fs advocacy. Both methods \nsystematically introduce conflict and debate by using sub-groups who role-play. In dialectical \ninquiry, the subgroups develop opposing alternatives and then come together to debate their \nassumptions and recommendations. In devil\u201fs advocacy, one subgroup offers a proposal, while the \nother plays devil\u201fs advocate, critically probing all elements and recommendations in the proposal. \nBoth methods encourage groups to generate alternative courses of action and minimise tendencies \ntowards premature agreement or convergence on a single alternative. Both methods also lead to a \nmore critical evaluation of assumptions by providing mechanisms for encouraging dissent whilst at \nthe same time fostering a high-level of understanding of the final group decision. Nevertheless, these \nrole-played, conflict-enhancing, interventions for improving decision making need to be focussed on \n 34 \n \n34 \nfactual information because personalities can, inappropriately, become the focus of discussion. \nAdvocates of the techniques argue that they are most-suited to ill-structured non-routine decisions.  \nAn empirical study [57] compared both techniques to a non-adversarial approach where decisions \nwere simply discussed with the aim of achieving a consensus amongst group members.  \nQuestionnaire ratings by group participants found that the two conflict-based approaches were rated \nhigher in terms of producing better recommendations and better questioning of assumptions.  \nFormalizing and legitimizing conflict can thus enhance perceptions of the quality of the outcome of \ngroup decision making. However, whilst conflict can improve perceived decision quality, it may \nweaken the ability of the group to work together in the future if the role-playing is not sensitively \nmanaged.  Also, as Nemeth, Brown and Rogers [58] document, authentic minority dissent, when \ncorrectly managed, is superior to role-playing interventions in stimulating a greater search for \ninformation on all sides of an issue. But, generally the authentic dissenter is disliked even when \nshe\/he has been shown to stimulate better thought processes. However, other research has shown that \nthe persistent authentic dissenter, while not liked, can be admired and respected [59]. Also, of course \nimplementation of decisions rests on securing the subsequent cooperation of involved parties and so \naffective personal criticism invoked in the prior critical debate will be dysfunctional [60]. \n \nYaniv [61] demonstrated the power of role-playing in a laboratory-based study of  a framing \nproblem. Here, participants were divided into two groups whose members were psychologically \nprimed with either (i) one or the other of two perspectives  on the problem \u2013 the heterogeneous \ncondition , or (ii)  the same perspective on a decision  problem \u2013 the homogeneous condition. Each \nof the two groups then convened to discuss the decision problem and come to a group decision. The \nresults were compelling \u2013 the homogeneous grouping revealed a stronger framing effect than the \nheterogeneous grouping. This minimal manipulation produced a discernable impact on subsequent \ndecision quality. Yaniv concluded that Delphi applications could actively create such heterogeneity \n 35 \n \n35 \nby assigning roles to panellists as they make their individual forecasts \u2013 such as conservative, \npessimistic, or optimistic. Additionally, by our analysis, the roles assigned could include those of  an \nagent provocateur  - who provides distinctly different forecasts from  those of other panelists and \nincludes  a critique of other transmitted  rationales within his own  accompanying rationale for the \nforecast - before it is transmitted anonymously to other panelists. \n \nIn scenario planning, sometimes scenario development involves a scenario team composed of \nrepresentatives from multiple agencies. Cairns et al [62] have argued that the process of scenario \nplanning can provide a non-adversarial, common viewpoint to unite, what may be, fragmented \ngroupings. By contrast, in terms of our analysis, the fragmentation should instead be conserved \u2013 at \nleast until the point when any action response to the constructed set of scenarios is debated. In more \nusual scenario development conducted within a single organization, the conventional process results \nin the initial development of four skeleton scenarios that are then each fleshed-out by one of four \nsub-groups.  On our analysis, once a particular scenario is fully developed it should then be \nsubjected to adversarial critique by one or more of the other subgroups. Such a process could also be \nextended to provide adversarial critiques of the more extreme scenarios whose construction we \ndescribed earlier in this section. \n \nConclusions \nIn this paper we reviewed methodologies that aim to aid anticipation of rare, high-impact, events. \nWe examined predictability from the perspective of forecasters\u201f ability to obtain well-calibrated \nprobabilities or point forecasts for events and identified six factors that can lead to poor calibration \nand hence low predictability. We then examined how successful a range of existing methods are in \nmitigating these factors, including the use of expert judgment, statistical forecasting, Delphi, \n 36 \n \n36 \nprediction markets and scenario planning. We demonstrated that all the extant methods, including \ncombinations of methods, contain weaknesses and that anticipation of rare, high-impact, events can \nonly be achieved by judgmental heuristics that, likely, entail bias. We conclude that the only \nremedies are to either (i) provide protection for the organization against the occurrence of \nnegatively-valenced events whilst allowing the organization to benefit from the occurrence of \npositively-valenced events - such protection can involve the creation of redundancy, flexibility, and \ndiversity in an organization\u201fs operations and resources, or (ii) provide conditions to challenge one\u201fs \nown thinking \u2013 and hence improve anticipation. We outlined how use of components of devil\u201fs \nadvocacy and dialectical inquiry can be combined with Delphi and scenario planning to enhance \nanticipation of rare events. \n \n \n \n \nREFERENCES \n \n[1] Makridakis, S., Hogarth, R.M. & Gaba, A. (2009) Forecasting and uncertainty in the economic \nand business world. International Journal of Forecasting \n[2] Wright, G & Goodwin, P. (2009) Decision making and planning under low levels of \npredictability: enhancing the scenario method. International Journal of Forecasting \n[3] Goodwin, P. & Wright, G. (2004). Decision Analysis for Management Judgment, Chichester: \nWiley. \n[4] Taleb, N. N. (2008). The black swan: the impact of the highly improbable, London: Penguin.  \n[5] Orrel, D,. and McSharry, P. (2009) Systems economics: Overcoming the pitfalls of forecasting \nmodels via a multidisciplinary approach, International Journal of Forecasting \n[6] Hamilton, D.L and Rose, T\/L. (1980) Illusory correlation and the maintenance of stereotypical \nbeliefs, Journal of Personality and Social Psychology,  39, 832-845 \n 37 \n \n37 \n[7] Tversky A. & Kahneman D. (1974). Judgment under uncertainty: Heuristics and biases, Science, \n185, 1124-1131. \n[8] Kahneman, D. and Lovallo, D. (1993) Timid choices and bold forecasts: A cognitive perspective \non risk taking, Management Science, 39, 17-31. \n[9] Cooper, A, Woo, C. and Dunkelberger, W. (1988) Entrepreneurs\u201f perceived chances for success, \nJournal of Business Venturing, 3, 97-108. \n[10] Gigerenzer, G. (1994) Why the Distinction between Single Event Probabilities and Frequencies \nis Important for Psychology (and Vice Versa), in G. Wright and P. Ayton (eds) Subjective \nProbability, Wiley, Chichester.  \n[11] Johnson, G (1987) \u201cStrategic change and the management process.\u201d  Oxford: Blackwell.  \n[12] Barr, P. S., Stimpert, J. L., & Huff, A. S. (1992). Cognitive change action, and organizational \nrenewal,  Strategic Management Journal, 13, 15-36. \n[13] Miller, D., & Friesen. P. (1980). Momentum and revolution in organizational adaptation, \nAcademy of Management Journal, 23: 591-614. \n[14] Fildes, R. & Goodwin, P. (2007a). Good and bad judgment in forecasting: lessons from four \ncompanies, Foresight, 8, 5-10. \n[15] Bensalah, Y. (2000). Steps in applying extreme value theory to finance: a review, Bank of \nCanada Working Paper 2000-20. \n[16] Kabus, I. (1976) You can bank on uncertainty, Harvard Business Review, May-June, 95-105. \n[17] Hoerl, A. and Fallin, H. K. (1974) Reliability of subjective evaluation in a high incentive \nsituation, Journal of the Royal Statistical Society, 137, 227-230.  \n[18] Keren, G. (1987) Facing uncertainty in the game of bridge: a calibration study, Organisational \nBehaviour and Human Decision Processes, 39, 98-114. \n 38 \n \n38 \n[19] Murphy, A. H. and Brown, B. G. (1985) A comparative evaluation of objective and subjective \nweather forecasts in the United States. In G. Wright (Ed.) Behavioural Decision Making, Plenum, \nNew York.  \n[20] Oskamp, S. (1965) Overconfidence in case-study judgements, Journal of Consulting \nPsychology, 29, 261-265. \n[21]  Wallace, E, H. A. (1923) What is the Corn Judge\u201fs mind? Journal of the American Society of \nAgronomy, 15, 300-304. \n [22] Tetlock, P.E., (2005).  Expert Political Judgment, Princeton: Princeton University Press. \n[23] Bolger, F. & Wright, G. (1994). Assessing the quality of expert judgment: issues and analysis,  \nDecision Support Systems, 11, 1-24 \n[24] Rowe, G & Wright, G. (2001) Differences in expert and lay judgements of risk: myth or reality? \nRisk Analysis, 21, 341-356. \n[25] Maxwell , R. J. (1999) The British government\u201fs handling of risk: Some reflections on the \nBSE\/CJD crisis.  In P. Bennett & K. Calman (Eds.), Communications and public health (pp 94-107).  \nOxford: Oxford University Press. \n[26] Wright G., van der Heijden K., Bradfield R., Burt G. & Cairns G.,  (2004). The psychology of \nwhy organizations can be slow to adapt and change: And what can be done about it, Journal of \nGeneral Management, 29, 21-36  \n[27] Bolger, F., Wright, G., Rowe, G,. GammackJ.,  and Wood, R. J.  (1989) LUST for life: \nDeveloping expert systems for life assurance underwriting. In N. Shadbold (Ed.) Research and \nDevelopment in Expert Systems, VI, Cambridge University Press, Cambridge.  \n[28] Goodwin, P. & Wright, G. (1993). Improving judgmental time series forecasting: a review of the \nguidance provided by research, International Journal of Forecasting, 9, 147-161 \n[29] Pat\u00e9-Cornell, M.E. (1984).  Fault trees versus event trees in reliability analysis, Risk Analysis, 4, \n177-186. \n 39 \n \n39 \n[30] Bazerman M. H. & Watkins, M.D. (2008). Predictable Surprises, Boston: Harvard Business \nPress. \n[31] Janis, I.L. & Mann, L. (1972).  Victims of Groupthink, Boston: Houghton Mifflin  \n[32] Lee, W.Y., Goodwin, P., Fildes, R., Nikolopoulos, K. & Lawrence, M. (2007). Providing \nsupport for the use of analogies in demand forecasting   tasks, International Journal of Forecasting, \n23, 377-390. \n[33] Green, K.C. & Armstrong, J.S. (2007). Structured analogies for forecasting, International \nJournal of Forecasting, 23, 365-376. \n[34] Fildes, R. & Goodwin, P. (2007b). Against your better judgment?  How organizations can \nimprove their use of management judgment in forecasting, Interfaces,  37, 570-576. \n[35] Turner D.S. (1990). The role of judgment in macroeconomic forecasting, Journal of Forecasting, \n9, 315-345. \n[36] Fildes, R., Goodwin, P., Lawrence, M. & Nikolopoulos, K. (2008). Effective forecasting and \njudgmental adjustments: an empirical evaluation and strategies for improvement in supply-chain \nplanning, International Journal of Forecasting, forthcoming. \n[37] Donihue M.R. (1993). Evaluating the role judgment plays in forecast accuracy,  Journal of \nForecasting, 12, 81-92. \n[38] Willemain, T.R. (1991). The effect of graphical adjustment on forecast accuracy, International \nJournal of Forecasting, 7, 151-154. \n[39] Goodwin, P., Fildes, R.,  Lawrence, M. & Nikolopoulos, K.(2007). The process of using a \nforecasting support system, International Journal of Forecasting, 23, 391-404. \n[40] \u00d6nkal, D & G\u00f6n\u00fcl, M.S. (2005). Judgmental adjustment: a challenge to providers and users of \nforecasts, Foresight, 2, 13-17. \n 40 \n \n40 \n[41] Rowe, G. & Wright, G. (2001). Expert opinions in forecasting; the role of the Delphi technique. \nIn J.S. Armstrong (Ed.) Principles of Forecasting: A handbook for researchers and practitioners, \nBoston: Kluwer Academic Publishers, pp125-144. \n[42] Rowe, G. & Wright, G. (1996). The impact of task characteristics on the performance of \nstructure group forecasting techniques, International Journal of Forecasting, 12, 73-89 \n[43] Grossman, S.J. (1976) On the Efficiency of Competitive Stock Markets Where Traders Have \nDiverse Information, The Journal of Finance, 31, 573-585. \n[44] Wolfers , J. and Zitzewitz, E. (2008) Prediction Markets in Theory and Practice. In S.N. Durlauf \nand L.E. Blume (Eds.) The New Palgrave Dictionary of Economics 2nd Edition, London: Palgrave \nMacmillan. \n[45] Pennock D.M., Lawrence S, Giles C.L, and Nielsen, F.A. (2001) The Real Power of Artificial \nMarkets, Science  291   987-988. \n[46] van der Heijden, K., Bradfield, R., Burt, G., Cairns, G. & Wright, G., (2002). The Sixth Sense: \nAccelerating Organisational Learning with Scenarios, Chichester: Wiley. \n[47] Bradfield, R., Wright, G., Burt, G., Cairns. G. & van der Heijden, K. (2005). The origins and \nevolution of scenario techniques in long range business planning, Futures, 37, 395-812 \n[48] Wright, G., Cairns, G. & Goodwin, P. (2008). Teaching scenario planning: Lessons from \npractice in academic and business, European Journal of Operational Research, forthcoming. \n[49] Phelps, R., Chan, C. & Kapalis, S.C. (2001).Does scenario planning affect performance?  Two \nexploratory studies, Journal of Business Research, 51, 223-232 \n [50] Makridakis, S. & Taleb, N.N. (2009) Introduction to the special issue: decision making and \nplanning under low levels of predictability. International Journal of Forecasting \n[51] Taleb, N.N. (2009) The fourth quadrant: a map of the limits of forecasting. International \nJournal of Forecasting \n 41 \n \n41 \n[52] Goodwin  P and Wright G, (2001) Enhancing strategy evaluation in scenario planning : A role \nfor decision analysis. Journal of Management Studies,  38, 1-16. \n[53] Pearson, C. M. & Clair, J. A. (1998).  Reframing crisis management, Academy of Management \nReview, 23, 59-76. \n[54] Schweiger D. M, Sandberg, W.R., & Ragan, J.W. (1986) Group approaches for improving \nstrategic decision making: A comparative analysis of dialectical inquiry, devil\u201fs advocacy, and \nconsensus. Academy of Management Journal, 29, 51-71 \n[55] Janis, I.L. (1972). Victims of Groupthink. Boston: Houghton Miflin. \n[56] Stasser, G, & Stewart, D. (1992) Discovery of hidden profiles by decision making groups: \nsolving a problem versus making a judgment. Journal of Personality and Social Psychology, 63, \n426-434. \n[57] Schweiger D. M, Sandberg, W.R., & Rechner, P.A. (1989) Experiential effects of dialectical \ninquiry, devil\u201fs advocacy, and consensus approaches to strategic decision making. Academy of \nManagement Journal, 32, 745-772. \n[58] Nemeth, C, Brown, K, & Rogers, J. (2001) Devil\u201fs advocate versus authentic dissent: \nstimulating quantity and quality. European Journal of Social Psychology, 31, 707-720. \n[59] Nemeth,C, & Chiles, C. ( 1998) Modeling courage: the role of dissent in fostering \nindependence. European Journal of Social Psychology, 18, 275-280. \n[60] Amason, A.C. (1996) Distinguishing the effects of functional and dysfunctional conflict on \nstrategic decision making: resolving a paradox for top management teams. Academy of Management \nJournal, 39, 123-148. \n[61] Yaniv, I (in press). Group diversity and decision quality: amplification and attenuation of the \nframing effect, International Journal of Forecasting. \n[62] Cairns  G, Wright G, Bradfield R, van der Heijden K & Burt G. (2006) Enhancing foresight  \n \nbetween multiple agencies:  issues in the use of scenario thinking to overcome fragmentation.  \n \n 42 \n \n42 \nFutures, 38, 1011- 1025. \n \n \n \n \n \n \nPaul Goodwin is a Professor of Management Science at the University of  Bath, UK. He is an \nassociate editor of the International journal of Forecasting. \n \nGeorge Wright is a professor at Durham Business School, UK. He is editor of the Journal of \nBehavioral Decision Making and an associate editor of both  International Journal of Forecasting and \nJournal of Forecasting \n"}
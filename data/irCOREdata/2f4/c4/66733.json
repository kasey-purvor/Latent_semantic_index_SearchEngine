{"doi":"10.1017\/S089006040606001X","coreId":"66733","oai":"oai:dro.dur.ac.uk.OAI2:273","identifiers":["oai:dro.dur.ac.uk.OAI2:273","10.1017\/S089006040606001X"],"title":"Learning inexpensive parametric design models using an augmented genetic programming technique.","authors":["Matthews,  P. C.","Standingford,  D. W. F.","Holden,  C. M. E.","Wallace,  K. M."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2006-02","abstract":"Previous applications of Genetic Programming (GP) have been restricted to searching for algebraic approximations mapping the design parameters (e.g. geometrical parameters) to a single design objective (e.g. weight).  In addition, these algebraic expressions tend to be highly complex.  By adding a simple extension to the GP technique, a powerful design data analysis tool is developed.  This paper significantly extends the analysis capabilities of GP by searching for multiple simple models within a single population by splitting the population into multiple islands according to the design variables used by individual members.  Where members from different islands `cooperate', simple design models can be extracted from this cooperation.  This relatively simple extension to GP is shown to have powerful implications to extracting design models that can be readily interpreted and exploited by human designers.  The full analysis method, GP-HEM (Genetic Programming Heuristics Extraction Method), is described and illustrated by means of a design case study","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/66733.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/273\/1\/273.pdf","pdfHashValue":"2bad18281f4be4087d51c2b9f557ae7292642481","publisher":"Cambridge University Press","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:273<\/identifier><datestamp>\n      2011-05-24T15:51:00Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Learning inexpensive parametric design models using an augmented genetic programming technique.<\/dc:title><dc:creator>\n        Matthews,  P. C.<\/dc:creator><dc:creator>\n        Standingford,  D. W. F.<\/dc:creator><dc:creator>\n        Holden,  C. M. E.<\/dc:creator><dc:creator>\n        Wallace,  K. M.<\/dc:creator><dc:description>\n        Previous applications of Genetic Programming (GP) have been restricted to searching for algebraic approximations mapping the design parameters (e.g. geometrical parameters) to a single design objective (e.g. weight).  In addition, these algebraic expressions tend to be highly complex.  By adding a simple extension to the GP technique, a powerful design data analysis tool is developed.  This paper significantly extends the analysis capabilities of GP by searching for multiple simple models within a single population by splitting the population into multiple islands according to the design variables used by individual members.  Where members from different islands `cooperate', simple design models can be extracted from this cooperation.  This relatively simple extension to GP is shown to have powerful implications to extracting design models that can be readily interpreted and exploited by human designers.  The full analysis method, GP-HEM (Genetic Programming Heuristics Extraction Method), is described and illustrated by means of a design case study. <\/dc:description><dc:subject>\n        Genetic programming<\/dc:subject><dc:subject>\n         Knowledge elicitation<\/dc:subject><dc:subject>\n         Design model induction<\/dc:subject><dc:subject>\n         Meta-models<\/dc:subject><dc:subject>\n         Data mining.<\/dc:subject><dc:publisher>\n        Cambridge University Press<\/dc:publisher><dc:source>\n        Artificial intelligence for engineering design, analysis and manufacturing, 2006, Vol.20(1), pp.1-18 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2006-02<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:273<\/dc:identifier><dc:identifier>\n        issn:0890-0604<\/dc:identifier><dc:identifier>\n        issn: 1469-1760<\/dc:identifier><dc:identifier>\n        doi:10.1017\/S089006040606001X<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/273\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1017\/S089006040606001X<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/273\/1\/273.pdf<\/dc:identifier><dc:rights>\n        This paper has been published by Cambridge University Press in \" Artificial intelligence for engineering design, analysis and manufacturing\" (20: 1 (2006) 1-18) http:\/\/journals.cambridge.org\/action\/displayAbstract?fromPage=online&aid=398600<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn: 1469-1760","0890-0604"," 1469-1760","issn:0890-0604"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2006,"topics":["Genetic programming","Knowledge elicitation","Design model induction","Meta-models","Data mining."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n09 March 2010\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nMatthews, P. C. and Standingford, D. W. F. and Holden, C. M. E. and Wallace, K. M. (2006) \u2019Learning\ninexpensive parametric design models using an augmented genetic programming technique.\u2019, Artificial\nintelligence for engineering design, analysis and manufacturing., 20 (1). pp. 1-18.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1017\/S089006040606001X\nPublisher\u2019s copyright statement:\nThis paper has been published by Cambridge University Press in \u201d Artificial intelligence for engineering design,\nanalysis and manufacturing\u201d (20: 1 (2006) 1-18)\nhttp:\/\/journals.cambridge.org\/action\/displayAbstract?fromPage=onlineaid=398600\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\nLearning inexpensive parametric design models using an\naugmented genetic programming technique\nPETER C. MATTHEWS,1 DAVID W.F. STANDINGFORD,2 CARREN M.E. HOLDEN,3\nand KEN M. WALLACE4\n1School of Engineering, University of Durham, Durham, United Kingdom\n2BAE Systems, Advanced Technology Centre, Filton, Bristol, United Kingdom\n3Aerodynamic Methods and Tools, Airbus UK, Filton, Bristol, United Kingdom\n4Engineering Design Centre, University of Cambridge Engineering Department, Cambridge, United Kingdom\n(Received October 16, 2003; Accepted May 3, 2005!\nAbstract\nPrevious applications of genetic programming ~GP! have been restricted to searching for algebraic approximations\nmapping the design parameters ~e.g., geometrical parameters! to a single design objective ~e.g., weight!. In addition,\nthese algebraic expressions tend to be highly complex. By adding a simple extension to the GP technique, a powerful\ndesign data analysis tool is developed. This paper significantly extends the analysis capabilities of GP by searching for\nmultiple simple models within a single population by splitting the population into multiple islands according to the\ndesign variables used by individual members. Where members from different islands \u201ccooperate,\u201d simple design\nmodels can be extracted from this cooperation. This relatively simple extension to GP is shown to have powerful\nimplications to extracting design models that can be readily interpreted and exploited by human designers. The full\nanalysis method, GP heuristics extraction method, is described and illustrated by means of a design case study.\nKeywords: Data Mining; Design Model Induction; Genetic Programming; Knowledge Elicitation; Metamodels\n1. INTRODUCTION\nA designer\u2019s ability to rapidly identify and modify concep-\ntual designs is based on their tacit domain knowledge. This\nknowledge takes the form of relationships between the design\nparameters ~aspects of the design a designer has control\nover! and design objectives ~aspects of the design resulting\nfrom the designer\u2019s choices!. These relationships will be\ndependent on the particular design family, and can be con-\nsidered as a tacit model. Typically, this tacit knowledge is\nthe result of extensive experience of designing other prod-\nuct family members. Tacit knowledge has been defined as\n\u201cknowledge which cannot be articulated easily\u201d ~Shadbolt\n& Milton, 1999!. Obtaining such knowledge through expe-\nrience requires time. One method for accelerating this pro-\ncess is by providing the knowledge explicitly. However,\ntransforming a designer\u2019s tacit knowledge into explicit\nknowledge is known to be a costly and not always a totally\naccurate method ~Ahmed, 2001!.\nThis research aims to build computational methods for\nextracting design knowledge from previous design exem-\nplars, and for reporting this back to designers in an intuitive\nmanner. This knowledge will take the form of simple alge-\nbraic relationships between design parameters and objec-\ntives. The quality of these heuristic relationships can be\nfurther improved through expert interpretation. On the sur-\nface, the use of experts appears to counter the argument of\ndeveloping the computational analysis method in the first\nplace. However, the extracted relationships provide a basis\nfor the expert to document the domain, as opposed from\nproviding this documentation with no starting point. Fig-\nure 1 shows the overall procedure for generating this report\nusing the genetic programming heuristics extraction method\n~GP-HEM!.\nGiven a set of coarse relationships, it then becomes pos-\nsible to search more rapidly the design space. A designer\nReprint requests to: Peter C. Matthews, School of Engineering, Uni-\nversity of Durham, Durham DH1 3LE, UK. E-mail: p.c.matthews@\ndurham.ac.uk\nAIE06001 1018 12007005 12:54 am log no. AIE06001\nArtificial Intelligence for Engineering Design, Analysis and Manufacturing ~2006!, 20, 1\u201318. Printed in the USA.\nCopyright \u00a9 2006 Cambridge University Press 0890-0604006 $16.00\nDOI: 10.10170S089006040606001X\nFigure 1\n1\ncan specify a desired value for a given design variable1 and\nthe ~relevant! relationships then provide an estimate of what\nthe set of related design variables should be. Further, as\nthese relationships are explicit, they provide knowledge\nregarding the nature of the relationship between sets of vari-\nables, most frequently as a set of tradeoffs between subsets\nof design variables. This represents a significant improve-\nment over \u201cblack box\u201d methods, for example, neural net-\nworks, where the domain can be modeled; however, there is\nno explicit understanding of the model. Using such a black\nbox method requires a trial and error approach to searching\nthe design domain. For a similar reason the extracted rela-\ntionships must be kept simple: it is possible to learn a highly\naccurate model, and report the exact algebraic expression.\nHowever, these relationships are too complex to provide\nunderstanding, and hence can provide little direction to a\ndesigner.\nTo illustrate the aim of this method, consider a bicycle\ndesign. Most bicycles can be described by a common set of\ndesign variables ~wheel size, position of top bar, stiffness,\nweight, cost, etc.!. In addition to the \u201cengineering\u201d vari-\nables, subjective variables can also be added such as \u201cdesir-\nability,\u201d as perhaps measured by sales volume. When\ndesigning a new bicycle, a designer will have a target spec-\nification. This specification will determine targets for a sub-\nset of the design variables. The designer\u2019s task is then to\nprovide firm values for the remaining design variables, poten-\ntially modifying some of those provided in the original spec-\nification where they prove to be infeasible. The relationships\nare used to provide this information. Note that it is also\npossible to make estimates on the subjective elements of\nthe design, as these relationships are also extracted.\nThe total knowledge extraction method comprises a num-\nber of components, each of which will be described in detail.\nAt the core is the GP component. This alone searches for\nincreasingly complex and accurate models for the given\nproduct family. However, the aim is not to provide a single,\n\u201cgrand-unifying\u201d model of the domain but rather a collec-\ntion of loosely related simple micromodels. This is achieved\nthrough a component that ensures the GP is \u201cpressured\u201d\ninto generating these simple micromodels. Finally, there is\nthe reporting component, which is used at the end of the\nmethod to provide a meaningful report of the micromodels.\nFigure 2 illustrates the interaction between the components.\nThese micromodels will be described in greater detail later\nin the paper.\nThe remainder of the paper discusses the background to\nthis research ~Section 2!, followed by a more extensive\ndescription of the GP algorithm ~Section 3!. The applica-\ntions of the GP, including the supporting components, are\nthen be described ~Section 4!. The method is illustrated\nwith a case study, including an analysis of the results ~Sec-\ntion 5!. Finally, a general discussion of the method con-\ncludes the paper ~Section 6!.\n2. BACKGROUND: ENGINEERING\nKNOWLEDGE\nThere are a number of methods for eliciting domain knowl-\nedge. These can be split into two main subdivisions: deduc-\ntive and inductive. The deductive methods require domain\nexperts to provide a set of rules or cases that can be used to\ndeduce new examples of the domain. Inductive methods are\nthe reverse of this: from a set of examples they obtain rules\nthat describe the relationships between these. This work\nlooks at using the results of an inductive approach and inter-\npreting these to provide the rules that a deductive method\nrequires.\n2.1. Design representation\nIt is assumed that the designs are to be represented para-\nmetrically. This is a common encoding method where the\nrelevant design variables are the parameters of the design\nrepresentation model. A design instance is then described\n1A design variable is either a design parameter ~e.g., length, material,\netc.! or design objective ~e.g., weight, cost, esthetic properties!, and the\nfull set of variables defines the design problem space.\nFig. 1. The overall procedure for generating the design relationship report. This paper concentrates on the right-hand side of the\nfigure.\nFig. 2. The interaction between the components: the algorithm iterates\nbetween the GP and the micromodels components until termination, when\nthe report generation module is used.\nAIE06001 2018 12007005 12:54 am\nfn 1\nFigure 2\n2 P.C. Matthews et al.\nby the associated ~typically numerical! values taken by these\nparameters ~Eastman et al., 1991; Green, 1997; Malmqvist\n& Schachinger, 1997!. This does have the drawback of\nrestricting the domain into a single representation; how-\never, it is possible to allow sufficient flexibility by careful\nabstraction of the domain. For example, the bicycle exam-\nple could detail all the possible saddle configurations; how-\never, these are unlikely to have a major impact on the\nremainder of the domain, and hence, it is acceptable to\nassume that these can be represented simply by the saddle\nconnection point only. In addition to the design parameters\n~e.g., geometry, material, etc.!, this representation must also\ncontain all the objective design criteria ~e.g., weight, cost!\nand the subjective criteria that have been measured previ-\nously ~e.g., suitable for city riding!. The set of design param-\neters, objective, and subjective criteria2 all form the design\nvariable set. The analysis method will seek relationships\nbetween all these design variables.\n2.2. Engineering design knowledge needs\nThe knowledge needs of designers changes as they gain\nexperience. Popovic ~2004! classifies the designer exper-\ntise level in part according to how many design rules and\nconstraints a designer can mentally manage at any one time.\nHence, to improve the capacity of novice designers, it is\nbeneficial to present design rules and constraints in an intu-\nitive manner, that is, one that requires less mental effort to\nprocess. Although this will impact the complexity of design\nrules and constraints, the benefit is that designers are able\nto process more rapidly a larger scope of the total design\nmodel.\nIn addition to the cognitive aspects of the knowledge\npresentation, it is also necessary to consider the type of\nknowledge that designers require. Ahmed and Wallace ~2004!\nreport on empirical evidence quantifying the relative vol-\numes of novice queries for specific types of design infor-\nmation. Of these queries, the two largest categories were\nrelated to company and design process. Clearly, these are\nconsidered important by the novice designers but as they\nare process related, these will not contain significant prod-\nuct knowledge. The next most significant set of queries\nrelate more closely to product, and are classified under \u201chow\ndoes it work,\u201d \u201cwhat are the tradeoffs,\u201d \u201cwhat is a typical\nvalue,\u201d and \u201cwhat issues to consider.\u201d This product type\nknowledge can be represented by the relationships between\nproduct design parameters and objectives.\n2.3. Knowledge engineering management methods\nKnowledge engineering methods are concerned with elicit-\ning domain knowledge from experts for future use. This\nhas two aspects: the acquiring specific knowledge, and the\nstorage and structuring of this knowledge.\nEliciting specific knowledge is primarily concerned with\nthe rationale and rules that generate designs ~Blessing, 1994;\nArciszewski, 1997; Smith & Morrow, 1999!. Although these\nrules can provide more explicit guidance during design, a\nmajor challenge is to identify the appropriate rule at any\ngiven point in the design process. Examples of this are rule-\nbased design systems, for example, Siddall ~1986!, Arafat\net al. ~1993!, Thornton ~1996!, and Arciszewski ~1997!.\nCritically, a large investment is needed to elicit these rules.\nThis typically involves interviewing design experts, and\nthen encoding and structuring the rules so that they can be\nreadily accessed ~Modesitt, 1992!. This approach tends to\nbe expensive to implement ~Ahmed, 2001!.\nThe storage aspects extend beyond the physical nature\nand media that is used to record design knowledge. Assum-\ning that some archival media is being used, there is the\nissue of structuring and retrieving the information. This must\naddress the granularity of the design data to be stored and\nhow this is to be structured. These issues are researched by\nproduct and project data management groups. Such data-\nbases can be used to populate a case-based reasoning design\ntool ~Leake et al., 1999; Reich & Barai, 1999; Roseman,\n2000!. This approach allows designers to identify the most\nsimilar previous designs. These designs are then used as\nstarting points for new designs, provided the designer under-\nstands the effects of any modifications made. Such an\napproach provides no rationale about how such previous\ndesigns were reached, unless this is explicitly included.\nHence, there is a need to link the storage with rationale\nused to create the design in the first instance.\nThe method introduced in this paper aims to exploit design\ndatabases that lack rationale. Through the analysis of such\ndatabases, explicit design knowledge is to be extracted, pro-\nviding rationale for these designs. By providing explicit\nunderstanding of the relationships in the domain, it will\nalso be possible to create new designs more rapidly. Fur-\nther, there is the potential of discovering new domain rules\nthat were overlooked by domain experts.\n2.4. Induction methods\nInduction methods are data driven as opposed to expert\ndriven, which is the case with the knowledge engineering\napproaches. This provides an advantage in cases where expert\navailability is limited, but sufficient prior data is available\nto build a model of the product family. There are a number\nof induction methods, ranging widely in the transparency\nof the models they generate ~Andrews et al., 1995; Hecker-\nman, 1999; Maire, 1999; Hong et al., 2000; Hwang & Yang,\n2002!. A brief overview of a sample of these is provided,\nstarting with neural networks, one of the least transparent\napproaches.\nNeural networks have been shown to be able to learn\ncomplex mappings well ~Lawrence et al., 1996!. The ben-\n2The subjective criteria will be included, and hence referred to, as\ndesign objectives.\nAIE06001 3018 12007005 12:54 am\nfn 2\nLearning inexpensive parametric design models 3\nefits of using neural networks lies in the wide range of\ndomains they can be applied to, and the speed at which they\nperform at once trained. These benefits are underpinned by\na strong theoretical understanding of how they learn and\nthe performance and accuracy that can be expected of neu-\nral networks. However, the internal structure of the trained\nnetwork remains opaque. This is a problem, as it difficult to\nunderstand how the input and output variables are related.\nWithout this understanding, all that can be done is to use\nthe neural network in a trial and error mode, which is an\ninefficient search strategy. There has been work on extract-\ning simple and intelligible rules from these networks\n~Corbett-Clark, 1998; Huang & Xing, 2002; Matthews,\n2002!. This is a posttraining process, which provides explicit\nrules that can then be validated by an expert, and poten-\ntially edited if necessary. This provides a combined strategy\nto gain insights into the domain. However, this is a more\ncomplex process than acquiring the rules directly from the\ndata.\nData mining methods are a large collection of methods\nthat, in general, generate association rules from large data-\nbases. In contrast to neural networks, these are explicit rules.\nHowever, the rules are difficult to interpret, and are most\noften used as part of some other algorithm, for example,\ncredit card fraud detection ~Michalski & Kaufman, 1997!.\nData mining is primarily used to classify accurately and\nefficiently new cases into previously determined catego-\nries. As these methods are commonly used for computer\nidentification of, for example, fraud detection, importance\nis given to the statistical significance of data mining results.\nThe understanding of the limits of data mining methods\nrepresents one of the major benefits of this approach. How-\never, the rules generated by the data mining methods are\nrarely used to provide greater insight into the original prob-\nlem domain.\nAutomated science discovery methods provide insights\ninto a domain where only empirical evidence is available.\nThese methods iteratively build and test rules on a given set\nof observations, guided by a set of functional operators\nZ\u02d9 ytkow, 1999, 2000!. Several empirical applications are\ncited, including physics, chemistry, and astronomy. Lan-\ngley et al. ~1987! introduced an algorithm for building math-\nematical equations from a given set of observation variables.\nThis algorithm searches for equations that result in constant\nvalues for given subsets of observations, and use these to\nbuild further equations until some equation remains con-\nstant for all observations. This final equation represents a\nlaw for the given domain. The science discovery methods\nrepresent an implementation of the scientific method, and\ntherefore, inherit the rigor that this thorough approach pro-\nvides. Unfortunately, these discovery methods tend to be\nexhaustive, and hence, computationally expensive. In addi-\ntion, for the science discovery methods, it is assumed that\nall the necessary observations are included.\nFor further reference on machine learning techniques and\nmethods, Michalski and Tecuci ~1994! and Mitchell ~1997!\nprovide thorough overviews of the domain, and Arcisze-\nwski and Ziarko ~1992! discuss a selection of methods from\nan engineering perspective.\n2.5. Summary: Criteria for an HEM\nEngineering design knowledge presents an interesting set\nof requirements: a designer must have an understanding of\nhow the various design variables are interrelated, but at the\nsame time seeks new areas that are likely to challenge this\nunderstanding. Therefore, to support a designer, it will be\nnecessary to provide these relationships in a nonconstrain-\ning manner. A large single unifying model is likely to con-\nstrain. For this reason, this approach proposes to offer a set\nof small ~micro! models representing certain aspects of the\ndomain. These loosely related micromodels represent a set\nof heuristics to be used by a designer searching for a good\nconcept that can then be further analyzed by more expen-\nsive tools. The micromodels will be simple enough that the\nengineering principles can be seen without compromising\naccuracy, providing domain understanding, and hence, the\nability to search the design space intelligently.\n3. EVOLUTIONARY SEARCH ALGORITHMS\nEvolutionary search algorithms are in general generate and\ntest beam searches ~Mitchell, 1997!. These are searches\nwhere a large number of potential solutions are considered,\nand the search for better solutions is biased in the direction\nof the current best set of solutions. Hence, the current \u201cpop-\nulation\u201d of solutions is used to generate the next population\nof solutions for consideration. The heuristic used to gener-\nate the new population members from the old population\nwas inspired from Darwinian survival of the fittest theory.\nSolutions that are \u201cfitter\u201d are stochastically combined with\neach other to generate new solutions. The theory is that\nsome of the new solutions will have been combined from\n~or inherited! \u201cgood\u201d parts of their parents, and hence, will\nalso be fitter. This is a stochastic process, and the combina-\ntions are performed randomly biased by the measured fit-\nness of the parent solutions.\nGenetic algorithms ~GAs! are a successful and well-\nknown implementation of this technique for numerical opti-\nmization problems where the problem representation is fixed\n~Goldberg, 1989!. This approach has been shown to work\nwell in domains where traditional gradient search-based tools\nperform poorly due to the cost of computing gradients ~Jen-\nkins, 1996; Gen & Cheng, 2000!. After a number of gener-\nations, the solution population lies mainly in a region of\ngood solutions. Clearly, there are two criteria needed for a\ndomain to be suitable for this approach. First, solutions in\nthe domain must be expressible in a fixed format, for exam-\nple, a real-valued vector. Second, there must be a predeter-\nmined fitness function that can evaluate candidate solutions.\nIt appears that the GA approach is suitable for a family of\nAIE06001 4018 12007005 12:54 am\n4 P.C. Matthews et al.\nproducts, because they are all described using a fixed for-\nmat, provided a suitable fitness function exists.\n3.1. GP\nGP is an evolutionary search algorithm ~Koza, 1992; Koza\net al., 1999!. With GP, a more flexible solution represen-\ntation is adopted. Instead of a fixed vectorlike structure, a\ntree structure is used. This allows the representation of\nfunctional forms ~see Fig. 3!. Functions are built up from\nprimitive functional elements ~e.g., addition and multipli-\ncation in algebra, or LISP functions!. These functions form\nthe nodes of a tree. The arguments of these functions are\nthen subtrees, the terminal nodes being the function vari-\nables or constants. GP uses the same sexual recombination\napproach to generate the new solution space, but the oper-\nators are modified to apply to tree structures. This search\nresults in identifying tree structures that provide good solu-\ntions, as evaluated by the provided fitness function. An\nexample would be identifying an algebraic expression that\ncurve fits the given dataset well. Unless there is some\nevolutionary pressure to keep these tree structures small,\nthey are able to grow arbitrarily large if this improves\ntheir fitness score.\n3.2. Island approach\nAs there is no great need in evolutionary computing searches\nfor new candidate solutions to be generated synchro-\nnously, a number of evolutionary algorithms were devel-\noped for distributed computing environments. One of the\nearlier versions of this was applied to optimization of Walsh\npolynomials, distributing the solution populations to dif-\nferent independent GAs ~Tanese, 1989!. Two methods were\ncompared, one where the GAs were left running indepen-\ndently of each other, and one where a small portion of the\npopulation was allowed to \u201cmigrate\u201d between the other-\nwise independent GAs. Cohoon et al. ~1987! defined a set\nof basic migration policies. These determine how mem-\nbers of different \u201cislands\u201d can migrate between islands: a\nmesh structure restricts migration between neighbors, a\nstar allows migration through a central point, linear0\ncircular is a one-dimensional mesh, and random removes\nany restriction to the interisland migration. This island\napproach provided nearly linear acceleration when the pro-\ncessing was distributed between independent processors.\nFurther studies demonstrated that this could be improved\nto superlinear acceleration by controlling the migration\nmore carefully ~Belding, 1995; Andre & Koza, 1996!.\nMore practical applications of the island approach appear\nlater. Potter et al. ~1995! use the island approach to evolve\na robot controller that has two competing strategies. The\ntwo strategies are evolved independently ~one on each\nisland!; however, this application was sensitive to the ini-\ntial seeding. Further work developed the island approach to\nstring matching and neural networks ~Potter, 1997; Potter\n& De Jong, 2000!. This provided a better understanding of\nthe behaviors of niches in the overall population, and how\nthese niches can cooperate to provide some emergent\nbehavior.\nFig. 3. The creation of functional trees, using functional nodes for addition, squaring, and square root and terminal nodes a and b.\nAIE06001 5018 12007005 12:54 am\nFigure 3\n?1?\nLearning inexpensive parametric design models 5\nWiegand et al. ~2001! formalized the above approaches,\nand provided a general framework for cooperative coevo-\nlutionary algorithms. This work investigated more general\nquestions about evaluating the collaborative nature between\nthe islands and how many islands should be used.\n3.3. Combining the EC elements\nWe have just described the core computational ideas that\nare to be adopted in the search for simple useful design\nrelationships. As the aim is to search for arbitrary algebraic\nstructures, the GP approach is the most suitable for this\ntask. This will allow for the flexibility that can be achieved\nusing algebraic structures that would not naturally occur if\nadopting the GA encoding method. As noted, the algebraic\nrelationships can become arbitrarily large unless pressure is\napplied to keep them small. However, it is important to\nidentify potential complex relationships. This will be\nachieved by using the island approach: individual solutions\nwill be kept simple, and similar solutions will be developed\non their own island. The interaction of these islands will\nrepresent the more complex behavior. Hence, it will be pos-\nsible to report these complex behaviors by reporting the\nlinkage between a pair of these islands that each represent a\nsimple behavior. This linkage is identified through \u201ccollab-\norative\u201d behavior between islands. The next section expands\non these ideas.\n4. SEARCHING FOR DESIGN RELATIONSHIPS\nThe GP approach is adapted in a novel manner to search for\ndesign relationships. As noted in the previous section, the\nisland approach proved not only to accelerate the search,\nbut also provided a wider variety of solutions. This is a key\nfactor in developing and implementing the search method.\nThe search method is divided into three major processes:\nislands creation, fitness measurement, and final reporting,\nand these are linked as shown in Figure 4. Each of these is\nnow described, after first discussing the problem domain.\n4.1. Problem domain\nThe GP-HEM developed in this paper is based around real-\nvalued design variables. This, in turn, provides a restriction\non the type of design domain that can be analyzed fruit-\nfully. The approach identifies simple algebraic relation-\nships between subsets of design variables. Hence, it is\nnecessary for the problem domain to be described using\nsuch components. In addition, the nature of the relation-\nships being extracted is mostly continuous.3\nAs the design domain must be specified to this paramet-\nric granularity, this appears to be most applicable to the\nembodiment design phase. However, these algebraic rules\ncan be interpreted as design guidelines, which provide a\ngreater understanding of the design family. This understand-\ning can then be applied at the earlier conceptual design\nstage, leading to better quality design concepts.\nBecause of the constraints on design representation, this\napproach appears to be most suited to mechanically ori-\nented design domains. Similar approaches exist, for exam-\nple, Ishino and Jin ~2002! apply GP to understand designers\u2019\nintent in a mechanical gear design domain. Such domains\nare more likely to be continuous in the design parameters,\nand hence, more suitable to this approach. There is evi-\ndence that a similar approach has also provided interesting\nresults in chemical process engineering ~Lakshminaray-\nanan et al., 2000!. It should be possible to apply this approach\nto other design domains, provided a sufficiently continuous\nproblem area is being analyzed. Both these methods apply a\nGP to identify the mapping between the design parameters\nand a single design objective. Where designs have multiple\nobjectives, this process is repeated once for each objective.\nHighly discontinuous domains are not expected to be suc-\ncessfully modeled by this approach, for example, in soft-\nware design where very small design changes can result in\nlarge performance changes. In addition, the modeling of\nsoftware design in a conceptual manner is a nontrivial task.\n4.2. Assumptions\nA number of assumptions are made on the nature of the\ndesign domain, the available data, and type of models that\nare to be extracted. First, it is assumed that the design domain\nis continuous ~or no less than piecewise continuous! in the\n3Exceptions are of the form 10~x \u0001 y!, which is discontinuous along\nx\u0002 y.\nFig. 4. The overall process flow of the GP-HEM. Each iteration modifies the current population to provide the population of the next\niteration.\nAIE06001 6018 12007005 12:54 am\nFigure 4\nfn 3\n6 P.C. Matthews et al.\ndesign variables. This assumption permits the search for\nalgebraic models, rather than classification type models. It\nalso allows simpler approximation functions to be created.\nThis leads to the second assumption: the data is real valued\nand all present ~no missing values!. Thus, algebraic expres-\nsions constructed from the design variables can be directly\nevaluated as a real number. The third and final assumption\nis that micromodels provide a meaningful representation of\nthe design domain. It is assumed that by combining micro-\nmodels, and thus in particular enabling direct relationships\nbetween subsets of design objectives, meaningful and inter-\nesting domain relationships will be identified with the\nGP-HEM.\n4.3. Island creation\nThe islands GP approaches described in Section 3.2 simply\ndistributed the solution population between processors arbi-\ntrarily. For the GP-HEM, each island represents a meaning-\nful subset of design variables, and therefore there is a need\nfor more careful distribution of the population between the\nislands. However, it is not known beforehand which design\nvariables belong together. The approach adopted for the\nGP-HEM is to cluster the population of candidate solu-\ntions, and to treat each cluster independently as if it were a\nreal island. This requires a metric to determine how the\nobjects are to be clustered. This poses a challenge, because\nthere are no inexpensive metrics for the functional space\nbeing searched by the GP. The following sections describe\nhow this clustering can be achieved.\n4.3.1. Clustering method\nThe partitioning around medoids ~PAM! algorithm ~Kauf-\nman & Rousseeuw, 1990! was selected as the clustering\nalgorithm, because it is simple and identifies a member of\neach cluster as a representative for its cluster. This repre-\nsentative element is called the cluster\u2019s medoid. Other clus-\ntering algorithms typically compute a prototypical point that\nrepresents a \u201ctruer\u201d center; however, this is not possible to\ndo with the functional forms. Each island then represents a\nparticular \u201cmicromodel\u201d class, and it is desired that these\nare to be as diverse as possible with respect to the design\naspects they address. Therefore, the metric should be based\non the contents of the functional form ~i.e., the design vari-\nables that are being used in the function!. Kusiak ~2001!\nuses similar ideas with rough sets to allow for potentially\noverlapping rules.\n4.3.2. Function space pseudometric\nA pseudometric was developed to reflect these cluster-\ning requirements. This provides a means of measuring sim-\nilarity between different algebraic expressions so that they\ncan be clustered using PAM. It was also desired to be able\nto identify functionally identical expressions that occur\ncommonly using the GP process. For example, the two\ndistinct function trees representing x\u0003 y and x\u0003 y\u0003 y\u0003 x\nare seen as being identical, as they are equivalent by a\nmultiplicative factor. The function space is projected into\na fixed sized hash vector, to which the Euclidean distance\nmetric can be applied. The hash vector is given by the\nproportion of each design parameter\u2019s presence in the func-\ntion. In the example above, the two hash vectors would be\n~1, 1! and ~2, 2!, respectively. When these are normalized,\nthe two hash vectors become equal, and therefore have\nzero distance between them.\nThe function hashes exist in a metric space and hence\ncan be clustered by PAM, the clustering algorithm. PAM\nprovides a set of clusters and medoids that are used as rep-\nresentatives for their associated cluster. These clusters are\ntreated as the islands described previously. Further details\nof the PAM algorithms are given in Appendix A.\n4.3.3. Interisland migration policy\nIn addition to the generation of the islands it is necessary\nto define the policy on inter- and intracluster crossovers.\nThe aim is to have most crossovers produced from within\ntheir own island ~intraisland!. In addition, a few interisland\ncrossovers are performed to promote a small degree of\ngenetic variety within each island. These interisland cross-\novers are done by taking all the medoids, treating them as a\nsingle island, and applying the intraisland crossover proce-\ndure to this set. The remaining genetic operators ~mutation\nand injection! only involve single candidates, and so no\nspecial consideration is required. The final population is\nevaluated again for fitness, and the procedure repeated, gen-\nerating a new set of islands. With the new set of islands, it is\npossible that the island boundaries are shifted. This allows\nfor the nature of each island to evolve as well as the whole\npopulation.\n4.4. The fitness function\nThe fitness function provides the bias that directs the GP\nsearch. This function must reflect the desired properties of\nthe better solutions, and it is typically computed by a func-\ntion independent of the solution set. The aim is for the\nGP-HEM to discover pairs of functions that contain differ-\nent terminal nodes, but have a high covariance coefficient.\nThis is because the method is based on a cooperating coevo-\nlutionary approach, where \u201chalves\u201d of the micromodels are\ngenerated by the GP. Such pairs describe interesting phe-\nnomena that are being observed within the dataset. How-\never, this is based strictly on the current population as\nopposed to some external measurement. As a result, it is no\nlonger possible to compare fitness values across generations.\nThe candidate solutions are clustered into different islands\nbased on the symbols they contained, and within each island\nit is expected that candidates have a high covariance. The\nalgorithm therefore does not compare the covariance of a\ncandidate solution with that of other members of that\nsolution\u2019s island. In a further runtime optimization mea-\nAIE06001 7018 12007005 12:54 am\nLearning inexpensive parametric design models 7\nsure, the candidate is only measured against the medoids of\nthe other islands. This is because the medoid is the repre-\nsentative of the island, and it will have a high covariance\nbetween itself and its fellow island members.\nThe aim is to keep the functions simple. To achieve this,\na penalty is given to longer functions. Hence, the desired\nproperties of the fitness function for a given solution mem-\nber ~ f ! can be summarized as follows:\n1. the average covariance f has with the other islands\u2019\nmedoids must be high, because this suggests that f is a\nmeaningful design expression when compared to the\nother medoids; and\n2. the number of terms used in f should be kept low, but\nnot so low that trivial expressions are overly pro-\nmoted, because this suggests that f is likely to be\ncomprehensible.\nBased on this, the fitness function is expressed as follows:\nfitness ~ f ! \u0002\n(\ng\u0001M\nSfg2\n6M 6log~len~ f !\u00031! , ~1!\nwhere M is the set of medoids; Sfg is the covariance between\nfunctions f and g; and len~ f ! is the length of function f,\nwhich is counted by the number of terminal nodes.\n4.5. Termination and final report\nEvolutionary computing algorithms are typically termi-\nnated when the maximum fitness score achieves a preset\nlevel. This requires the fitness scores to be comparable\nbetween generations, which is not the case with the\nGP-HEM. Hence, the termination criteria in this case are\ncrudely set to terminate the GP search algorithm after a\npreset number of iterations.\nOn termination of the evolutionary search algorithm, the\nresults are compiled into a final report. This report is effec-\ntively the user interface of the method, and hence, it is\nimportant to ensure this report is meaningful to designers.\nThis is achieved by reporting the functions in the simplest\nversion possible. The report identifies pairs of functions\nthat are both highly correlated and quite different with respect\nto the terminal nodes they contain.\nThe first step of the reporting function is to take a final\nmeasurement of the fitness of all the candidate solutions.\nThis is performed in the same manner as previously and\nthus requires the population to be clustered into islands one\nlast time. The next step is to identify \u201chigh-quality\u201d pairs of\ncandidate solutions from the population. This quality is mea-\nsured by the pairs that have high covariance; are short; and\ncome from different islands. This is computed for the func-\ntion pair ~ f, g!, where f and g are from different islands, as\nfollows:\nQfg \u0002\n6Sfg 6\nlog~len~ f !\u0003 len~g!! . ~2!\nFunction pairs are then reported, starting with the asso-\nciated pair that scored the highest quality measure. The\nreport displays the two functional form, in standard alge-\nbraic format, and the quality score for that pair.\n5. CASE STUDY: FLAT SCREEN DISPLAY\nTo test and illustrate the functionality of the GP-HEM a\nsmall design case study was developed. A flat screen dis-\nplay domain was created by defining a small set of relation-\nships between the design parameters ~aspects of the design\ndetermined by the designer! and objectives ~aspects of the\ndesign determined by the parameters!. These relationships\nwere designed to be sufficiently complex that all the design\nobjectives could not only be expressed in terms of the design\nparameters.As the relationships were known before the analy-\nsis, it was possible to measure how well the analysis method\nperforms.\n5.1. Design space definition\nThe design space of the panel was represented by four design\nparameters and four objective criteria, forming an eight\ndimensional space. The design parameters were: width ~x!,\nheight ~ y!, depth ~d!, and material ~r!, all of which were\nrandomly sampled from a uniform distribution. The objec-\ntive criteria were weight, cost, life expectancy, and sales\nvolume. These were related as follows:\nweight \u0002 xydr\u0003 \u00abN , ~3!\nlife \u0002 r\u0003 \u00abN , ~4!\nunits \u0002 10\u00abU , ~5!\ncost \u0002\nlife\nunits\n\u0003 \u00abN , ~6!\nwhere \u00abN and \u00abU represent noise and are randomly sampled\nvalues from a normal and uniform distribution, respec-\ntively. Note that the number of units sold was modeled only\nby a random value. This represents the subjective nature of\nthe customer population. A key aim of this case study was\nto find out an explicit relationship for this objective based\non the remaining parameters. In addition, all objectives had\na small amount of Gaussian noise added. This was sup-\nposed to represent the noise occurring in real-world domains\ndue to other factors that this simple model did not include.\nFinally, a database of 200 examples was created from\nthis model. This represented the \u201cpast designs\u201d that would\nform the basis of the analysis. The size of this database was\nset similar to other product databases that would be analyzed.\nAIE06001 8018 12007005 12:54 am\n8 P.C. Matthews et al.\n5.2. Domain analysis\nIn addition to supplying a database of previous examples,\nthe GP-HEM has three running parameters that need to\nbe supplied. These determine how the analysis will be\nperformed:\n1. population size: how many relationships to hold for\nconsideration during each iteration;\n2. number of clusters: how many islands to create; and\n3. number of iterations: number of generations to allow\nthe search process to run.\nFor this case study, the parameters were as follows: the\npopulation size was set to 100, this population was to be\nsplit into 10 clusters, and the GP was allowed to run for 10\ngenerations. After the run, the top 10 relationships ~pair-\nings! were reported as follows:\n1. wt and d quality\u0002 1.39520\n2. rho and life quality\u0002 1.37310\n3. wt and wt\u0003 units quality\u0002 0.91024\n4. wt and rho\u0003 wt quality\u0002 0.91024\n5. life0cost and units quality\u0002 0.91011\n6. d0y and d quality\u0002 0.90143\n7. d and life * d quality\u0002 0.89774\n8. life and units * cost quality\u0002 0.89401\n9. d and wt0life quality\u0002 0.88777\n10. wt and life * d quality\u0002 0.88747\nAlthough most of these relationships do not fully extract\ncomponents of the original model, a number of useful design\nheuristics are reported. Further, this report illustrates how\nthe quality function @Eq. ~2!# scores the pairings.\nThe following paragraphs analyze the report with respect\nto each of the design objectives.\n5.2.1. Weight-related relationships\nThis was the only relationship not to be fully discovered.\nCoarse approximations for weight are given in relation-\nships 1, 9, and 10 ~note that relationships 9 and 10 are\neffectively the same!. The principal reason that the full rela-\ntionship for weight is difficult to recover is that a total of\nfive terms are required. The fitness and quality functions\nboth penalize heavily on total expression length, which in\nthis case is overly severe. Relationship 1 ~i.e., the strongest\naccording to the quality measure! does express that the thick-\nness of the design has the strongest effect on the design\nweight. A more accurate version can be inferred from rela-\ntionships 2 and 10, which is that weight is strongly depen-\ndent on the thickness times the material density ~r!.\nRelationships 3 and 4 are of little meaning, as weight is\nrepeated in both halves of the relationship. This has the\neffect of increasing the covariance, and hence the quality\nscore artificially.\n5.2.2. Life-related relationships\nLife was directly linked to the material choice ~r!. This\nwas introduced as a single trivial relationship to test if the\nmethod would be able to extract these. This was extracted\nin relationship 2. The fact that it was not rated as the top\nrelationship in terms of quality is a reflection of the effect\nof added noise.\n5.2.3. Units-related relationships\nThe units objective, designed to reflect the sales vol-\nume, was drawn from a uniformly random sample. This\nwas done to reflect the subjective nature of this objec-\ntive, at least to the degree that it could not be described\nby the design parameters alone. Relationships 5 and 8\naccurately report on the relationships between units and\nthe rest of the product description. Relationship 3 also\ninvolves units; however, this is only as part of a relation-\nship between the weight and itself and thus should be\ndiscounted.\n5.2.4. Cost-related relationships\nThe cost objective could only be derived from other design\nobjectives. This was to demonstrate one of the motivating\nfactors of this approach: the ability to identify design rela-\ntionships not only derivable from design parameters. Such\nrelationships are important in design, as they provide knowl-\nedge about the tradeoffs that are made regarding a product\u2019s\nobjectives. Although it is often feasible to infer such rela-\ntionships from the design parameters, these tend to be dif-\nficult to identify.\nIn this case study, this relationship is reported twice in\ndifferent, but equivalent, formats. This relationship was accu-\nrately reported in relationships 5 and 8. Again, the low\npositioning of these reflects how the quality function penal-\nizes long expressions ~they both have a total of three terms!\nand the effect of the added noise.\n5.3. Method parameter sensitivity\nThe GP-HEM has four principal parameters: number of clus-\nters to use, population size, crossover policy, and number of\ngenerations to run for before terminating. A series of inde-\npendent experiments were run to investigate the sensitivity\nof the GP-HEM to each of these parameters. A common\ndatum point is used throughout all the experiments as a\nreference point.\nAs discussed in Section 4.5, one drawback with the\nGP-HEM is the difficulty in measuring fitness indepen-\ndently of a given generation and cluster configuration. The\ndevelopment of the quality function @Eq. ~2!# provides some\nmeasure independent measure of the final report, allowing\ndifferent runs of the GP-HEM to be compared. In addition\nto this, an additional manual evaluation for the final report\nwas used. Function pairs were classified into one of five\ndifferent categories:\nAIE06001 9018 12007005 12:54 am\nLearning inexpensive parametric design models 9\nperfect: the function pair is a complete representation of\nthe a design relationship;\ngood: the function pair is sufficient to identify a trend in\nthe design relationship;\naverage: the function pair has a component of the design\nrelationship, but would require some further analysis\nto identify the design trend;\nmisleading: the function pair has a component of the\ndesign relationship, but expressed in a misleading man-\nner; and\nwrong: the function pair is completely wrong.\nIndependent GP-HEM runs can be compared by the cat-\negorization profile of each run. Although it might appear to\nbe ideal to extract perfect relationships, a designer is likely\nto prefer to identify trends in the design domain. As such, a\ndesirable profile is one with a high number of good and\naverage relationships and a low number of misleading and\nwrong relationships.\n5.3.1. Number of islands\nThe number of islands, or clusters, determines how many\ndifferent types of \u201chalf\u201d relationships can be classified.\nClearly, it is essential to set the number of clusters no lower\nthan the number of half relationships that exist in the design\ndomain. However, it is unlikely that this number is known a\npriori. Therefore, it is good practice to set the number of\nislands slightly higher than would be expected for the design\ndomain.\nThe GP-HEM was executed using the flat screen display\ndata set with a series of different clustering settings. The\nresults are presented in Table 1 using the profiles and qual-\nity measures. From here, it is can be seen that k \u0002 3 pro-\nduces the \u201cbest\u201d results, in terms of the total number of\ngood and average relationships. An alternative view would\nbe to consider that k\u000210, the datum setting, is best in terms\nof minimizing wasted effort due to wrong or misleading\nrelationships. It is worth noting that the quality range ~min0\nmax Q! is nearly constant for all k settings.\n5.3.2. GP policy\nAt the core of any GP algorithm lies the crossover policy.\nThis defines what proportion of the next generation arises\nfrom sexual reproduction ~crossover!, mutation, elite reten-\ntion, and random injection. The sum of these four must add\nup to 100% of the new population, and so there were 3\ndegrees of freedom for this set of experiments. The exper-\niments explicitly changed the crossover, mutation, and elit-\nism proportions allowing the random injection level to be\ndetermined by the remaining available population. Each\nparameter was tested at a low, medium, and high setting,\nthe datum being all three parameters set at medium. Due to\nthe time required to manually inspect each set of results, a\nsubset of the total possible 27 experiments was drawn up.\nThis experiment schedule is listed in Table 2, and the pro-\nfile results are listed Table 3.\nFor more detailed analysis, the raw result table is reor-\ndered for each policy parameter. For each parameter, the\ntable is presented in order of ascending value of that param-\neter. Trends for each policy parameter were identified in\nterm of how the profile changed as each individual param-\nTable 1. Classification profiles and quality ranges for cluster\nnumber experiments\nk P G A M W min Q max Q t ~s!\n2 0 0 4 5 13 0.65 0.91 588.2\n3 2 1 10 1 8 0.88 1.40 577.1\n5 2 5 2 3 10 0.87 1.40 639.4\nDatum 2 2 3 9 6 0.86 1.40 565.4\n15 1 0 2 10 9 0.90 1.40 660.7\n20 2 0 5 8 7 0.90 1.40 712.4\nDatum, k\u0002 10.\nTable 2. Experiment schedule for the GP\ncross-over policy\nId Elite Cross Mutate\n1 10 ~L! 40 ~L! 10 ~L!\n2 10 ~L! 40 ~L! 20 ~H!\n3 10 ~L! 70 ~H! 10 ~L!\n4 20 ~M! 40 ~L! 15 ~M!\n5 20 ~M! 40 ~L! 10 ~M!\n6 25 ~H! 55 ~M! 10 ~L!\n7 25 ~H! 70 ~L! 5 ~vL!\nDatum 20 ~M! 55 ~M! 15 ~M!\nAll values are percentages. Note that experiment 7\nrequired a very low mutate setting to ensure that the sum\u0001\n100%.\nTable 3. Profile results from the GP cross-over policy\nassessment\nId EXM P G A M W\n1 LLL 5 3 3 7 4\n2 LLH 2 4 3 8 5\n3 LHL 0 6 3 9 4\n4 MLM 2 5 3 6 6\n5 MHL 1 2 7 12 0\n6 HML 3 3 7 3 6\n7 HHL 1 4 8 2 7\nDatum MMM 2 2 3 9 6\nE, elite; X, cross-over; M, mutate; PGAMW, number of relationships\nper assessment category.\nAIE06001 10018 12007005 12:54 am\nTable 1\nTable 2\nTable 3\n10 P.C. Matthews et al.\neter was increased. From Table 4, we can note the follow-\ning: a high elitism policy is better; a high crossover policy\nis better; and a low mutate policy is worst. In respect to the\nmutate policy, the better policy depends on if the object is\nto maximize the good and average relationships ~in which\ncase use high mutate!, or minimize misleading and wrong\n~in which case use medium mutate!.\n5.3.3. Population\nThe population represents the number of relationships\nunder consideration in the GP-HEM algorithm. As the rela-\ntionships are algebraic, there are infinitely many distinct\nforms that can be created using the given design variables.\nHowever, as the aim is to identify simple relationships, this\nreduces the number of potential candidates. In the flat screen\ndesign domain, it would be feasible to enumerate and test\nall relationships consisting of up to five symbols. However,\nthis approach would not scale to more complex domains.\nThe population size was varied between 50 and 200, each\ntime evaluating the final relationships.\nTable 5 contains the results of these runs. From this table\nit can be seen that there is an optimal population at about\nn \u0002 50. This is interesting, as it clearly demonstrates that\nlarge populations are detrimental to the quality of the final\nresult. However, it is important to bear in mind that the\nnumber of clusters will also have an effect on the final\noutcome: for the smaller populations each cluster will hold\nfew members and for the large population each cluster will\nhold many members that potentially should not be in the\nsame cluster.\n5.3.4. Number of design variables\nThe GP-HEM uses the design variables as the building\nblocks for the algebraic relationships. Increasing the num-\nber of variables represents an increase in the domain com-\nplexity. For this experiment, redundant variables were added.\nThese variables took on random values that had no relation-\nship either to the rest of the design or to each other. There-\nfore, it was not expected that these variables should appear\nin meaningful design relationships. However, it must be\nnoted that although the number of variables was increased,\nthere was no similar increase in the number of islands. As a\nresult, each island \u201ccontained\u201d more variables on average.\nTable 6 contains the results of this these runs. The results\nshow that the GP-HEM is relatively robust to a small increase\nin the number of ~redundant! variables. When the increase\nbecomes large ~v\u000212 and 16!, numerous completely wrong\nTable 4. Profile trends for GP policy\nparameters\nElite\nId E P G A M W\n1 L 5 3 3 7 4\n2 L 2 4 3 8 5\n3 L 0 6 3 9 4\n4 M 2 5 3 6 6\n5 M 1 2 7 12 0\nD M 2 2 3 9 6\n6 H 3 3 7 3 6\n7 H 1 4 8 2 7\nCross-over\nId X P G A M W\n1 L 5 3 3 7 4\n2 L 2 4 3 8 5\n4 L 2 5 3 6 6\n6 M 3 3 7 3 6\nD M 2 2 3 9 6\n3 H 0 6 3 9 4\n5 H 1 2 7 12 0\n7 H 1 4 8 2 7\nMutate\nId M P G A M W\n1 L 5 3 3 7 4\n3 L 0 6 3 9 4\n5 L 1 2 7 12 0\n6 L 3 3 7 3 6\n7 L 1 4 8 2 7\n4 M 2 5 3 6 6\nD M 2 2 3 9 6\n2 H 2 4 3 8 5\nTable 5. Varying the population size used by GP-HEM\nn P G A M W min Q max Q t ~s!\n20 2 0 2 4 14 0.72 1.35 135.8\n50 2 4 4 8 4 0.71 1.40 271.6\nDatum 2 5 2 3 10 0.87 1.40 565.4\n150 2 2 0 3 15 0.89 1.40 1162.1\n200 2 2 0 0 18 0.91 1.40 2087.9\nDatum, n\u0002 100.\nTable 6. Applying the GP-HEM to the design domain with\nredundant design variables added\nv P G A M W min Q max Q t ~s!\nDatum 2 5 2 3 10 0.87 1.40 565.4\n10 2 2 1 8 9 0.72 1.40 643.4\n12 2 4 2 0 14 0.89 1.40 724.9\n16 1 1 1 4 15 0.71 1.40 680.1\nDatum: v\u0002 8, the basic screen design domain.\nAIE06001 11018 12007005 12:54 am\nTable 4\nTable 5\nTable 6\nLearning inexpensive parametric design models 11\nrelationships are being reported. However, this will be partly\nbiased due to the number of islands remaining fixed.\n5.3.5. Sensitivity to data sample size\nAn important aspect of any machine learning approach is\nthe volume of data required to obtain \u201cgood\u201d results. This\nset of runs illustrates how the GP-HEM performs with vary-\ning amounts of data from which to learn the relationships.\nThe data sample size was varied between 50 and 600 data\npoints.\nTable 7 contains the results for these runs. Overall, there\nis relatively little change in the profile of the results and the\nrange of quality scores. However, with fewer points, there\nwill be a more significant change in the confidence in the\nrelationships. In addition, this set of runs also illustrates\nhow the computational time increases with the increased\nsample size.\n5.3.6. Sensitivity to noise\nIn addition to the sensitivity to sample size, it is impor-\ntant to consider how well a machine learning algorithm\nhandles noisy data sets. In this set of runs, a controlled\namount of noise was added to the sample generated from\nthe domain model, ranging from s\u0002 0 to 1.0.\nTable 8 contains the results for these runs. Interestingly,\nthere is very little difference in the profile of the relation-\nships extracted. The main difference in the results between\nthe various noise levels is given by the reduced quality\nmeasurements. This is to be expected, as the quality score is\nbased on the covariance between the relationships that will\nbe reduced as a result of adding noise to the original data.\n5.3.7. Convergence and termination criteria\nThe GP-HEM adopted the simple termination criteria of\nhalting after a predetermined number of generations. A set\nof experiments was run to identify the trends in the perfor-\nmance of GP-HEM with varying the run length from 1 gen-\neration through to 20 generations.\nTable 9 contains the relationship profiles for all the runs\nof varying lengths. The primary interest is in the relation-\nships that are classified under good and average. The results\nshow that this stabilizes at nine relationships in total from\nfive generations onward. The poorest two relationship\nclasses, misleading and wrong, remain stable throughout.\nThe perfect relationships reduce rapidly from a relatively\nhigh count early in the run through to a stable count of two\nin later generations.\n5.3.8. Computational complexity and scalability issues\nThe code was written as a set of Matlab functions. This\nprovided a good code developing and testing environment\nat the cost of execution speed. The bottleneck within this\nenvironment lies in the evaluation of the population against\nthe design data. Each relationship is evaluated for each data\npoint, mapping it onto a real value using the Matlab eval\nprocedure. The amount of time required for this operation\nis primarily a function of the complexity of the relation-\nship. By the nature of the GP-HEM\u2019s aims, this function\ncomplexity is bounded stochastically through the fitness\nfunction, and hence, for the purposes of this complexity\nanalysis it shall be assumed to be constant. If there is a\npopulation of N expressions and a total of d data points, the\ntotal computational complexity in terms of function evalu-\nations is ~ONd ! per generation. In addition to this, the data\nresulting from the expression evaluations is used to com-\npute the covariance between each pair of expressions, which\nhas complexity O~N 2!. The run times on the all the exper-\niments with the flat screen display ~v\u0002 8 design variables,\nd \u0002 200 data points, and N \u0002 100 expressions! ranged\nbetween 120 and 2000 s, with the datum point taking about\n350 s. The greatest variance in run time arose through vary-\ning the relationship population size. This time variance is\ndue to the variance arising in the length of the individual\nTable 7. Varying the sample size used by the GP-HEM\nN P G A M W min Q max Q t ~s!\n50 3 2 0 8 9 0.90 1.40 389.2\n100 2 3 0 15 1 0.86 1.41 467.8\nDatum 2 5 2 3 10 0.87 1.40 565.4\n400 1 3 0 13 5 0.89 1.39 893.8\n600 2 2 2 10 6 0.91 1.40 1444.0\nDatum, N\u0002 200.\nTable 8. Varying the added noise level to the data\ns P G A M W min Q max Q t ~s!\n0.00 2 2 1 13 4 0.90 1.44 552.7\n0.05 2 2 1 12 5 0.90 1.40 560.9\nDatum 2 5 2 3 10 0.87 1.40 565.4\n0.50 1 2 1 14 4 0.88 1.37 614.5\n1.00 0 2 0 13 7 0.82 1.27 605.2\nDatum, s\u0002 0.1.\nTable 9. Relationship profiles after varying number of\ngenerations\nn P G A M W min Q max Q t ~s!\n1 4 2 4 12 0 0.90 1.40 131.9\n2 3 4 3 10 2 0.89 1.40 163.1\n5 2 6 3 10 1 0.89 1.40 344.6\nDatum 2 5 2 3 10 0.87 1.40 565.4\n15 0 8 1 19 3 0.88 1.40 907.4\n20 2 4 5 9 1 0.89 1.40 1363.2\nDatum, n\u0002 10.\nAIE06001 12018 12007005 12:54 am\nTable 7\nTable 8\nTable 9\n12 P.C. Matthews et al.\nexpressions, which is a stochastic variable. However, with\neach generation, the potential maximum complexity of the\nrelationships increases. These results were obtained run-\nning Matlab on a single 2.8-GHz Intel-based processor with\n1 GB of RAM available.\nThe second computational bottleneck lies in the cluster-\ning algorithm. The clustering algorithm is supplied with\npairwise distances between all the population members, and\nthen it greedily identifies the best clustering of these ~see\nAppendix A!. In addition, this is only weakly dependent on\nhow many design variables there are. The term weakly is\nused in this case as the Matlab evaluation function in this\ncase appears to be near constant with respect to the number\nof variables. The number of design variables only comes\ninto effect when computing the pairwise distance between\ntwo relationships using the hash function described in Sec-\ntion 4.3.2, and then only has a small effect on the total\ncomputation time for that function. The complexity of the\nPAM algorithm is O~N 2!, which dominates the O~Nv! com-\nplexity of the hashing functions ~where v is the number of\ndesign variables! as it is expected that v \u0004 N.\nThe computational complexity of the GP operations will\nbe O~N !, as there is one operation per new population mem-\nber. The complexity of the termination decision is constant\nunder this implementation: it is simply a check on how\nmany generations have been produced. Finally, the compu-\ntational complexity of the final report generation is similar\nto the fitness evaluation, namely O~N 2!\u0003 O~Nd!.\nIn addition to the computational complexity issues, the\ndata volume needed for trustworthy results also needs to be\nconsidered. Effectively, this asks the question: how small a\n~data! scale can be meaningfully processed with the\nGP-HEM? This is dependent on how noisy the data set is.\nThe majority of the experiments run for this paper had a\nrelatively small amount of noise added ~s\u0002 0.1!, and used\na total of 200 data points. This proved to be ample data, and\nsimilar results were obtained using both noisier data sets\nand smaller data sets. The GP-HEM scales well in terms of\nnumber of design variables, provided the number of islands\nused is also scaled. Trials with extra independent variables\nwere run, with little effect to the final outcome. The number\nof islands effectively controls the complexity: increasing\nthe number of islands decreases the complexity of the expres-\nsions in the population. However, with more islands to spread\nthe population ~and complexity! across will require the gen-\neration of a lengthier final report.\nThe only aspect that has not been considered when scal-\ning the problem domain is the interpretation of the results.\nWith a more complex domain, the extracted relationships\nwill also be more complex. In this paper, a simple case\nstudy is used to demonstrate and test the approach. The\nrelationships are easily evaluated by a \u201cdomain expert.\u201d\nThe next development phase for the GP-HEM requires test-\ning in more complex domains, and reviewing how this affects\nthe time required by the domain experts to review the interim\nresults.\n5.4. Discussion\nThe analysis of this design case study has illustrated the\nnature of the relationships that can be extracted, along with\nsome of the weaknesses of the implementation. A signifi-\ncant number of design heuristics were extracted that pro-\nvide an understanding of how the design variables are related\nthrough tradeoffs. These were not only based on design\nparameters, but they also could provide an understanding\nof how the design characteristics were related.\nThe principal weakness is evident in the scoring func-\ntions, both fitness @Eq. ~1!# and quality @Eq. ~2!# . It is not\npossible to compare fitness function score directly between\npopulation generations. This is important to enable measur-\ning of how well the population is improving overall between\ngenerations and to provide a more intelligent stop criteria.\nThe quality scoring function has two drawbacks: first, it\npenalizes important long expression too heavily, and sec-\nond it scores tautological relationships too highly ~e.g., rela-\ntionship 3!. The first issue should be able to be rectified by\nmodifying the nature of the length penalty. The second issue\nwill require an extra penalty component to the quality func-\ntion reflecting on the amount of overlap in design variables\nbetween the two halves of the relationship.\n6. CONCLUSIONS\nThe GP-HEM introduced in this paper is a novel means for\nextracting simple rules from a database of previous designs.\nThis provides a means for more rapidly documenting the\ndesign domain by providing relationships between the key\ndesign variables. Once this documentation exists, it can be\nused by a larger population of designers, in particular where\nthe design of the product is possibly being undertaken by\nnonexperts. It is important that their creativity is kept within\nfeasible design constraints and that the best estimates are\nprovided for the objective functions. This is to provide high-\nquality feedback rapidly to designers, potentially through\nan expert systemlike interface. As such, the quantitative\nrules are effectively transformed into qualitative design heu-\nristics. This allows designers to explore rapidly the concep-\ntual design space intelligently, with minimal restriction on\ncreativity.\n6.1. Comparison of GP-HEM with other data\nmining approaches\nData mining, and more specifically, methods for gaining\nrule-based understanding of data sets, has been of interest\nsince computational resources have become readily acces-\nsible. There are two independent drivers for this research:\never larger databases require digesting to present a manage-\nable overview of the data, and to provide computationally\nsimpler versions of complex models using data samples\ntaken from the complex models. This paper has been pri-\nmarily concerned with the second driver.\nAIE06001 13018 12007005 12:54 am\nLearning inexpensive parametric design models 13\nModel induction methods can be broadly divided into\ntwo categories: classifiers, and regression models. Classifi-\ners provide a true0false test that a given data point belongs\nto a specific class. These classifiers are analyzed and char-\nacterized according to their prediction strength. This pro-\nvides a good understanding of how well any classifier\nperforms. As described in Section 2.4, neural networks can\nbe trained to classify and these can then be examined to\nextract the classification rules ~Corbett-Clark, 1998; Huang\n& Xing, 2002!. Although these rules do provide transpar-\nency to the neural network, they do not provide comprehen-\nsibility. More recently, Johansson et al. ~2004! and Duch\net al. ~2004! identify with this need for comprehensibility.\nBoth papers report on methods for generating comprehen-\nsible classifier rules. Johansson et al. ~2004! use GP tech-\nniques for identifying comprehensible propositional logic\nstatements that encode classification rules. These are eval-\nuated based on their accuracy and comprehensibility, effec-\ntively trading accuracy for comprehensibility. Unfortunately,\nno details are provided on the nature of these metrics. Duch\net al. ~2004! also extracts propositional classification rules,\nbut optimizes the extracted rules using a specific set of rule\ntransformations that trade rule accuracy against simplicity.\nRegression rules provide mappings between continuous\ninput variables and output variables. The nature of the map-\nping will be determined in part by the regression model and\nits parameter settings. In general terms, the aim is to iden-\ntify suitable models such that the error in mapping of a\nknown dataset is minimized ~Wegkamp, 2003!. However,\neven when constraining the complexity, the space of all\nmodels is huge. Early \u201cscience discovery\u201d methods used\nexhaustive search algorithms to greedily search the model\nspace ~Langley et al., 1987!; however, this approach does\nnot take model comprehensibility into account. Support vec-\ntor machines ~SVMs! provide another type of regression\nmodel. The SVM has the ability to approximate more com-\nplex models using direct summation of a small number of\nbasis functions. The SVM approach has been applied in a\nwide range of engineering domains and compares well to\nother metamodeling techniques ~Nair et al., 2002; Clarke\net al., 2003!. However, although SVMs perform well in\nterms of error minimization, they do not provide compre-\nhensible models that can be readily understood by design-\ners. A review of a number of other metamodeling methods\nfor engineering design is provided by Simpson et al. ~2001!.\nThis review does stress the importance of comprehensibil-\nity, and highlights the challenges when multiple objectives\nare to be taken into account.\nThe GP-HEM identifies simple regression models with a\ncritical difference to the above methods: all the above\nreported methods treat design parameters and objectives\ndifferently. They aim to identify a set of independent regres-\nsion models oi\u0002 fi~x! for each design objective, oi . This is\na natural approach, as it provides explicit models for each\ndesign objective independently. However, designers also\nbenefit from understanding the tradeoffs made between\nobjectives. Identifying relationships between objectives thus\nprovides the designer with a clear holistic understanding of\nthe product\u2019s behavior. An example of this is given by rela-\ntionship 5 ~life0cost and units!, relating the three design\nobjectives ~Section 5.2.3!.\nThe GP-HEM identification method is based on a novel\nimplementation of the islands approach from the well-\nknown GP methodology. This simple addition to the GP\nmethodology greatly extends the nature of the rules that are\nreported. As noted previously, \u201ctraditional\u201d regression model\nidentification methods search for equations for each objec-\ntive function independently, using only the design param-\neters as terminal nodes for the function trees. The approach\nadopted in this paper removes that restriction. As demon-\nstrated in the case study ~Section 5!, there are relationships\nthat cannot be described using only design parameters. These\nfrequently represent some behavior external to the design,\nfor example, the customer population\u2019s subjectivity. How-\never, these are very important relationships to extract and\nuse when designing products.\nThe weakness of with the GP-HEM is that there is little\ndirect control over the accuracy of the micromodels. Partial\ncontrol is exerted through the fitness function, which pro-\nmotes accurate micromodels through measuring how well\nthe models correlate given the data sample taken from the\ndomain. The comprehensibility is similarly controlled by\npromoting smaller micromodels. However, as the evolution-\nary algorithm is stochastic, it is not possible to predict exactly\nhow the models progress. This is a significant difference to\nthe deterministic approaches used by most other methods\ndescribed in Section 2.4.\nThe empirical results demonstrate that simple relation-\nships are being successfully extracted. These relationships\ntend to require expert interpretation to provide understand-\ning of the domain, as they are not necessarily extracted in\nthe most meaningful form. However, these are still helpful\nin providing insight into the trends and tradeoffs between\nsets of parameters. Such relationships can be used to direct\ndesigners towards how to modify designs to match new\ndesign requirements.\n6.2. Future work\nThere are aspects of this approach that require further work.\nAs with all evolutionary approaches, the key element is\nthe fitness function. The empirical evidence presented in\nthe examples and the case study indicates that the parsi-\nmony bias is too strong, thus preventing the more complex\nsolutions from being reported. Further, a major difficulty\nin this implementation is the lack of population-independent\nfitness metrics. As the current fitness metric @Eq. ~1!# is\nbased on the current population, it is impossible to track\nthe overall performance of the search between genera-\ntions. One possible technique to be explored is replacing\nthe current single fitness function by a set of competing\nfitness functions and to use Pareto ranking to determine an\nAIE06001 14018 12007005 12:54 am\n14 P.C. Matthews et al.\nindividual\u2019s relative fitness compared to the rest of the\npopulation.\nIn addition, there are other GP techniques that could\nimprove the performance, for example, encapsulation ~Koza\net al., 1999!. This identifies useful subtrees that should be\ntreated as atomic nodes by introducing them as new termi-\nnal nodes during the evolutionary process. However, there\nis little research available to help identify these subtrees.\nFurther work relating to the use of GP should also consider\nseeding the initial population with likely first order esti-\nmates of candidate solutions that could be obtained from\ntechniques such as principal components analysis.\nThis work represents ongoing research to address these\nissues. The aim is to provide a toolkit for examining data-\nbases of prior products and provide concise and readily\ninterpretable relationships governing the product family.\nACKNOWLEDGMENTS\nThis work was undertaken while the corresponding author was\nfully funded by the University Technology Partnership, a collab-\norative research project between the Universities of Cambridge,\nSheffield, and Southampton; and with industrial partners BAE\nSystems and Rolls-Royce, PLC. The authors thank the anony-\nmous referees for their comments.\nREFERENCES\nAhmed, S. ~2001!. Understanding the use and reuse of experience in engi-\nneering design. PhD Thesis. University of Cambridge, Engineering\nDepartment.\nAhmed, S., & Wallace, K.M. ~2004!. Understanding the knowledge needs\nof novice designers in the aerospace industry. Design Studies 25(2),\n155\u2013173.\nAndre, D., & Koza, J. ~1996!. A parallel implementation of genetic pro-\ngramming that achieves super-linear performance. Proc. Int. Conf. Par-\nallel and Distributed Processing Techniques and Applications ~Hamid,\nR., Ed.!, Vol. 3, pp. 1163\u20131174, Athens, GA.\nAndrews, R., Diederich, J., & Tickle, A.B. ~1995!. Survey and critique of\ntechniques for extracting rules from trained artificial neural networks.\nKnowledge-Based Systems 8(6), 373\u2013389.\nArafat, G.H., Goodman, B., & Arciszewski, T. ~1993!. Ramzes: a\nknowledge-based system for structural concepts evaluation. Comput-\ning Systems in Engineering 4(2\u20133), 211\u2013221.\nArciszewski, T. ~1997!. Engineering semantic evaluation of decision rules.\nJournal of Intelligent and Fuzzy Systems 5, 285\u2013295.\nArciszewski, T., & Ziarko, W. ~1992!. Knowledge Acquisition in Civil\nEngineering, pp. 50\u2013 68. New York: American Society of Civil\nEngineers.\nBelding, T.C. ~1995!. The distributed genetic algorithm revisited. Proc.\nSixth Int. Conf. Genetic Algorithms ~Eshelman, L., Ed.!, pp. 114\u2013121.\nSan Francisco, CA: Morgan Kaufmann.\nBlessing, L.T.M. ~1994!. A process-based approach to computer-supported\nengineering design. PhD Thesis. University of Twente.\nClarke, S.M., Griebsch, J.H., & Simpson, T.W. ~2003!. Analysis of support\nvector regression for approximation of complex engineering analyses.\nProc. ASME 2003 Design Engineering Technical Conf., Paper No.\nDETC20030DEC48759, Chicago.\nCohoon, J.P., Hegde, S.U., Martin, W.N., & Richards, D. ~1987!. Punctu-\nated equilibria: a parallel genetic algorithm. Proc. Second Int. Conf.\nGenetic Algorithms and Their Application, pp. 148\u2013154. Hillsdale, NJ:\nErlbaum.\nCorbett-Clark, T.A. ~1998!. Explanation from neural networks. PhD The-\nsis. Oxford University, Department of Engineering Science.\nDuch, W., Setiono, R., & @.#Zurada, J.M. ~2004!. Computational intelli-\ngence methods for rule-based data understanding. Proceedings of the\nIEEE 92(5), 771\u2013805.\nEastman, C.M., Bond, A.H., & Chase, S.C. ~1991!. A formal approach for\nproduct model information. Research in Engineering Design 2(2),\n65\u201380.\nGen, M., & Cheng, R. ~2000!. Genetic Algorithms and Engineering Opti-\nmization. New York: Wiley.\nGoldberg, D.E. ~1989!. Genetic Algorithms in Search, Optimization and\nMachine Learning. Reading, MA: Addison\u2013Wesley.\nGreen, G. ~1997!. Modelling concept design evaluation. Artificial Intelli-\ngence for Engineering Design, Analysis and Manufacturing 11(3),\n211\u2013217.\nHeckerman, D. ~1999!. Learning in graphical models, adaptive computa-\ntion and machine learning. In A Tutorial on Learning with Bayesian\nNetworks, pp. 301\u2013354. Cambridge, MA: MIT Press.\nHong, T.P., Wang, T.T., Wang, S.L., & Chien, B.C. ~2000!. Learning a\ncoverage set of maximally general fuzzy rules by rough sets. Expert\nSystems with Applications 19(2), 97\u2013103.\nHuang, S.H., & Xing, H. ~2002!. Extract intelligible and concise fuzzy\nrules from neural networks. Fuzzy Sets and Systems 132(2), 233\u2013243.\nHwang, S.Y., & Yang, W.S. ~2002!. On the discovery of process models\nfrom their instances. Decision Support Systems 34, 41\u201357.\nIshino, Y., & Jin, Y. ~2002!. Estimate design intent: a multiple genetic\nprogramming and multivariate analysis approach. Advanced Engineer-\ning Informatics 16(2), 107\u2013125.\nJenkins, W.M. ~1996!. A genetic algorithm for structural design optimiza-\ntion. Proc. NATO Advanced Science Institutes. Series F: Computer\nand Systems Sciences. Emergent Computing Methods in Engineering\nDesign: Applications of Genetic Algorithms and Neural Networks, Vol.\n149, pp. 30\u201352. Berlin: Springer\u2013Verlag.\nJohansson, U., Niklasson, L., & K\u00f6onig, R. ~2004!. Accuracy vs. compre-\nhensibility in data mining models. Proc. Seventh Int. Conf. Informa-\ntion Fusion ~Svensson, P., & Schubert, J., Eds.!, Vol. 1, pp. 295\u2013300,\nMountain View, CA.\nKaufman, L., & Rousseeuw, P.J. ~1990!. Finding Groups in Data: An\nIntroduction to Cluster Analysis, Probability and Mathematical Statis-\ntics. New York: Wiley.\nKoza, J.R. ~1992!. Genetic Programing: On the Programming of Comput-\ners by Means of Natural Selection, Complex Adaptive Systems. Cam-\nbridge, MA: MIT Press.\nKoza, J.R., Bennet, F. H., III, Andre, D., & Keane, M.A. ~1999!. Genetic\nProgramming III: Darwinian Invention and Problem Solving. San Fran-\ncisco, CA: Morgan Kaufmann.\nKusiak, A. ~2001!. Rough set theory: a data mining tool for semiconductor\nmanufacturing. IEEE Transactions on Electronic Packaging Manufac-\nturing 24(1), 44\u201350.\nLakshminarayanan, S., Fujii, H., Grosman, B., Dassau, E., & Lewin, D.R.\n~2000!. New product design via analysis of historical databases. Com-\nputers and Chemical Engineering 24(2\u20137), 671\u2013 676.\nLangley, P., Simon, H.A., Bradshaw, G.L., & @.#Zytkow, J.M. ~1987!. Sci-\nentific Discovery: Computational Explorations of the Creative Pro-\ncesses. Cambridge, MA: MIT Press.\nLawrence, S., Tsoi, A.C., & Back, A.D. ~1996!. Function approximation\nwith neural networks and local methods: Bias, variance and smooth-\nness. Proc. Australian Conf. Neural Networks ~Bartlett, P., Burkitt, A.,\n& Williamson, R., Eds.!, pp. 16\u201321, Australian National University.\nLeake, D.B., Birnbaum, L., Hammond, K., Marlow, C., & Yang, H.\n~1999!. Case-Based Reasoning Research and Development 1999. Lec-\nture Notes in Artificial Intelligence, Vol. 1650, pp. 482\u2013 496. Berlin:\nSpringer\u2013Verlag.\nMaire, F. ~1999!. Ruleextraction by backpropogation of polyhedra. Neural\nNetworks 12(4\u20135), 717\u2013725.\nMalmqvist, J., & Schachinger, P. ~1997!. Towards an implementation of\nthe chromosome model\u2014Focusing the design specification. Proc. 11th\nInt. Conf. Engineering Design ~Riitahuhta, A., Ed.!, Vol. 3, pp. 203\u2013\n212, Tampere University of Technology.\nMatthews, P.C. ~2002!. The application of self organizing maps in concep-\ntual design. PhD Thesis. University of Cambridge, Engineering\nDepartment.\nMichalski, R.S., & Kaufman, K.A. ~1997!. Data mining and knowledge\ndiscovery: a review of issues and a multistrategy approach. In Machine\nLearning and Data Mining: Methods and Applications, pp. 71\u2013112.\nChichester: Wiley.\nAIE06001 15018 12007005 12:54 am\n?2?\n?3?\n?2?\n?3?\nLearning inexpensive parametric design models 15\nMichalski, R.S., & Tecuci, G., Eds. ~1994!. Machine Learning: A Multi-\nstrategy Approach, Vol. IV. San Francisco, CA: Morgan Kaufmann.\nMitchell, T.M. ~1997!. Machine Learning. New York: McGraw\u2013Hill.\nModesitt, K.L. ~1992!. Basic principles and techniques in knowledge acqui-\nsition. In Knowledge Acquisition in Civil Engineering, pp. 11\u2013 49. New\nYork: American Society of Civil Engineers.\nNair, P.B., Choudhury, A., & Keane, A.J. ~2002!. Some greedy learning\nalgorithms for sparse regression and classification with Mercer ker-\nnels. Journal of Machine Learning Research, 3, 781\u2013801.\nPopovic, V. ~2004!. Expertise development in a product design\u2014Strategic\nand domainspecific knowledge connections. Design Studies 25(5),\n527\u2013545.\nPotter, M.A. ~1997!. The design and analysis of a computational model of\ncooperative coevolution. PhD Thesis. George Mason University.\nPotter, M.A., & De Jong, K.A. ~2000!. Cooperative coevolution: an archi-\ntecture for evolving coadapted subcomponents. Evolutionary Compu-\ntation 8(1), 1\u201329.\nPotter, M.A., De Jong, K.A., & Grefenstette, J.J. ~1995!. A coevolutionary\napproach to learning sequential decision rules. In Proc. Sixth Int. Conf.\nGenetic Algorithms ~Eshelman, L., Ed.!, pp. 366\u2013372. San Francisco,\nCA: Morgan Kaufmann.\nReich, Y., & Barai, S.V. ~1999!. Evaluating machine learning models for\nengineering problems. Artificial Intelligence in Engineering 13(2),\n257\u2013272.\nRoseman, M. ~2000!. Case-based evolutionary design. Artificial Intelli-\ngence for Engineering Design, Analysis and Manufacturing 14(1),\n17\u201329.\nShadbolt, N.R., & Milton, N. ~1999!. From knowledge engineering to\nknowledge management. British Journal of Management 10, 309\u2013322.\nSiddall, J.N. ~1986!. Probabilistic modelling in design. ASME Journal of\nMechanisms, Transmissions, and Automation in Design 108(3),\n330\u2013335.\nSimpson, T.W., Peplinski, J.D., Koch, P.N., & Allen, J.K. ~2001!. Meta-\nmodels for computer-based engineering design: survey and recommen-\ndations. Engineering with Computers 17, 129\u2013150.\nSmith, R.P., & Morrow, J. ~1999!. Product development process modeling.\nDesign Studies 20(3), 237\u2013261.\nTanese, R. ~1989!. Distributed genetic algorithms for function optimiza-\ntion. PhD Thesis. University of Michigan.\nThornton, A.C. ~1996!. The use of constraint-based design knowledge to\nimprove the search for feasible designs. Engineering Applications of\nArtificial Intelligence 9(4), 393\u2013 402.\nWegkamp, M. ~2003!. Model selection in nonparametric regression. The\nAnnals of Statistics 31(1), 252\u2013273.\nWiegand, R.P., Liles, W.C., & De Jong, K.A. ~2001!. An empirical analy-\nsis of collaboration methods in cooperative coevolutionary algorithms.\nProc. Genetic and Evolutionary Computation Conf. (GECCO2001)\n~Spector, L., Goodman, E.D., Wu, A., Langdon, W.B., Voigt, H.-M.,\nGen, M., Sen, S., Dorigo, M., Pezeshk, S., Garzon, M.H., & Burke, E.,\nEds.!, pp. 1235\u20131242. San Francisco, CA: Morgan Kaufmann.\nZ\u02d9 ytkow, J.M. ~1999!. The melting pot of automated discovery: principles\nfor a new science. In Discovery Science: Second Int. Conf. Lecture\nNotes in Artificial Intelligence, Vol. 1721, pp. 1\u201312. Berlin:\nSpringer\u2013Verlag.\nZ\u02d9 ytkow, J.M. ~2000!. Automated discovery: a fusion of multidisciplinary\nprinciples. In Advances in Artificial Intelligence. Lecture Notes in Arti-\nficial Intelligence, Vol. 1822, pp. 443\u2013 448. Berlin: Springer\u2013Verlag.\nAPPENDIX A: PAM CLUSTERING\nALGORITHM\nThe GP-HEM method uses clustering to separate individual can-\ndidate solutions into sets of \u201csimilar\u201d solutions. As with all clus-\ntering algorithms, each cluster is given a representative description.\nFor most clustering algorithms, this representative is computed\nfrom the cluster members ~e.g., taking the average value of numer-\nical parameters representing the clustered objects!. In the GP-HEM\nalgorithm, this is not possible as the space is not continuous. Instead,\nit is necessary to identify a member from each cluster to represent\nthe cluster.\nThe PAM algorithm is based around searching for a predeter-\nmined set of representative objects ~medoids! from a given set\n~Kaufman and Rousseeuw, 1990!. Briefly, the algorithm operates\nas follows to identify k medoids from a data set:\n1. Initially, k distinct objects are chosen arbitrarily as medoids.\n2. For each object, the nearest medoid is identified and its dis-\ntance noted.\n3. The total distance between objects and their medoids is then\nsummed for this configuration. A greedy algorithm then\nsearches for the best set of medoids.\n4. Each medoid is individually swapped for each nonmedoid,\nand the total distance is measured each time ~similar to steps\n2 and 3!.\n5. The swap that results in the minimum total distance is kept.\nThis process is repeated from step 2 until no further swaps\nresult in a lower total distance.\nThe results of this algorithm are the k medoids. Cluster\nmembership is then determined according to which medoid is\nnearest.\nTable A.1. Raw data set for PAM illustration\nId x Coordinate y Coordinate\n1 1.0 4.0\n2 5.0 1.0\n3 5.0 2.0\n4 5.0 4.0\n5 10.0 4.0\n6 25.0 4.0\n7 25.0 6.0\n8 25.0 7.0\n9 25.0 8.0\n10 29.0 7.0\nFig. A.1. A two-dimensional data plot of 10 objects.\nAIE06001 16018 12007005 12:54 am\n?2?\n?2?\n16 P.C. Matthews et al.\nA.1. Illustration\nThis example is taken from Kaufman and Rousseeuw ~1990!.\nTable A.1 contains the coordinates of 10 objects, which have been\nplotted in Figure A.1. From this data, the euclidean distances are\ncomputed between all pairs of points. If K \u0002 2 clusters are to be\nidentified, then the algorithms starts be arbitrarily choosing two\nmedoid candidates, say points 1 and 5. A new table can be drawn\nup, for each point computing the distance to point 1 and point 5.\nTable A.2 contains this information and also identifies the clusters\nfor this case. Clearly, this is not a very good clustering. At the final\niteration, the medoids are points 4 and 8. Table A.3 is the distance\ntable for this case. Figure A.2 illustrates these two clustering\nconfigurations.\nPeter Matthews is a Lecturer in design informatics at the\nSchool of Engineering at the University of Durham. He\nobtained a BA in mathematics ~1994!, a MS in computer\nscience ~1995!, and a PhD in engineering design ~2002!\nfrom University of Cambridge. He then remained at Cam-\nbridge for another year as a Research Associate. Dr. Mat-\nthews\u2019 core research interests are in applying machine\nlearning techniques to design problems.\nDavid Standingford graduated with first class honors in\napplied mathematics from the University of Adelaide in\n1993. He completed his PhD in numerical methods for aero-\ndynamics at the University of Adelaide in 1997 and then\nworked at the University of Delaware for 2 years under a\nNASA contract for microgravity fluid dynamics research.\nSubsequently, he moved to BAE SYSTEMS in 2000, where\nhe is now the Group Leader for fluid dynamics in the Depart-\nment of Mathematical Modelling, BAE Systems Advanced\nTechnology Center ~Sowerby!. Dr. Standingford is also the\nIndustrial Coordinator for the Rolls-Royce0BAE Systems\nUniversity Technology Partnership for Design, in collabo-\nration with the Universities of Cambridge, Southampton,\nand Sheffield.\nCarren Holden has worked for 20 years in decision sup-\nport and process improvement research for commercial and\nmilitary aircraft for BAE SYSTEMS until recently at its\nAdvanced Technology Centre, Sowerby, in Bristol. She\nTable A.2. Distance and clusters for first iteration\nDistance to\nId Part 1 Part 5 Minimum Medoid\n1 0.00 9.00 0.00 1\n2 5.00 5.83 5.00 1\n3 4.47 5.39 4.47 1\n4 4.00 5.00 4.00 1\n5 9.00 0.00 0.00 5\n6 24.00 15.00 15.00 5\n7 24.08 15.13 15.13 5\n8 24.19 15.30 15.30 5\n9 24.33 15.52 15.52 5\n10 28.16 19.24 19.24 5\n93.70\nFig. A.2. The clustering of the first and last iteration.\nTable A.3. Distance and clusters for last iteration\nDistance to\nId Part 4 Part 8 Minimum Medoid\n1 4.00 24.19 4.00 4\n2 3.00 20.88 3.00 4\n3 2.00 20.62 2.00 4\n4 0.00 20.22 0.00 4\n5 5.00 15.30 5.00 4\n6 20.00 3.00 3.00 8\n7 20.10 1.00 1.00 8\n8 20.22 0.00 0.00 8\n9 20.40 1.00 1.00 8\n10 24.19 4.00 4.00 8\n23.00\nAIE06001 17018 12007005 12:54 am\nTable A1\nFigure A1 Table A2\nTable A3\nFigure A2\nLearning inexpensive parametric design models 17\nobtained her PhD in 2005 at the University of Southampton\nunder the supervision of Professor Andy Keane. Dr. Holden\nis currently working in the Flight Physics Department of\nAirbus, UK.\nKen Wallace is Professor of engineering design at the Uni-\nversity of Cambridge. He is Chairman of the Engineering\nDesign Centre and Codirector of the Rolls-Royce0BAE Sys-\ntems University Technology Partnership for Design. In 1968\nhe completed a university apprenticeship with Rolls-Royce\nAerospace, during which time he obtained his BS in mechan-\nical engineering from the University of Manchester Insti-\ntute of Science and Technology. He is a Fellow of the Royal\nAcademy of Engineering, the Institution of Mechanical Engi-\nneers, and the Institution of Engineering Designers.\nAIE06001 18018 12007005 12:54 am\n18 P.C. Matthews et al.\n"}
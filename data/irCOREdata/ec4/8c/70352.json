{"doi":"10.1109\/MCG.2004.1255810","coreId":"70352","oai":"oai:eprints.lancs.ac.uk:12390","identifiers":["oai:eprints.lancs.ac.uk:12390","10.1109\/MCG.2004.1255810"],"title":"Building intelligent environments with smart-its","authors":["Holmquist, Lars Erik","Gellersen, Hans","Kortuem, Gerd","Schmidt, Albrecht","Strohbach, Martin","Antifakos, Stavros","Michahelles, Florian","Schiele, Bernt","Beigl, Michael","Maze, Ramia"],"enrichments":{"references":[{"id":16316721,"title":"Applying Wearable Sensors to Avalanche Rescue: First Experiences with a","authors":[],"date":"2003","doi":"10.1016\/j.cag.2003.08.008","raw":"6. F.  Michahelles  et  al.,  \u201cApplying  Wearable  Sensors  to Avalanche  Rescue:  First  Experiences  with  a  Novel Avalanche Beacon,\u201d Computers & Graphics, vol. 27, no. 6, 2003, pp. 839-847.","cites":null},{"id":16316720,"title":"Context Acquisition Based on Load Sensing,\u201d","authors":[],"date":"2002","doi":"10.1007\/3-540-45809-3_26","raw":"5. A. Schmidt et al., \u201cContext Acquisition Based on Load Sensing,\u201d Proc. 4th Int\u2019l Conf. Ubiquitous Computing (Ubicomp), Springer Verlag, vol. 2498, 2002, pp. 333-351.","cites":null},{"id":16316722,"title":"Designing Tomorrow\u2019s Smart Products: Experience with the SmartIts Platform,\u201d","authors":[],"date":"2003","doi":"10.1145\/997078.997105","raw":"7. L.E. Holmquist, R. Maz\u00e9\u201a and S. Ljungblad, \u201cDesigning Tomorrow\u2019s Smart Products: Experience with the SmartIts Platform,\u201d Proc. Designing for User Experience(DUX 03), ACM Press, 2003.","cites":null},{"id":16316719,"title":"Michahelles et al., \u201cInstructions Immersed into the Real World: How Your Furniture Can Teach You,\u201d Adjunct Proc.","authors":[],"date":"2002","doi":null,"raw":"Ubiquitous Computing (Ubicomp), Springer Verlag, vol. 2498, 2002, pp. 351-359. 4. F. Michahelles et al., \u201cInstructions Immersed into the Real World: How Your Furniture Can Teach You,\u201d Adjunct Proc.","cites":null},{"id":16316718,"title":"Physical Prototyping with Smart-Its,\u201d to appear in","authors":[],"date":null,"doi":"10.1109\/mprv.2004.1321032","raw":"2.  H. Gellersen et al., \u201cPhysical Prototyping with Smart-Its,\u201d to appear in IEEE Pervasive Computing, Oct.-Dec. 2003. 3. S. Antifakos, F. Michahelles, and B. Schiele, \u201cProactive Instructions for Furniture Assembly,\u201d Proc. 4th Int\u2019l Conf.","cites":null},{"id":16316723,"title":"Smart-Its Friends: A Technique for Users to Easily Establish Connections between Smart Artifacts,\u201d","authors":[],"date":"2001","doi":"10.1007\/3-540-45427-6_10","raw":"8. L.E. Holmquist et al., \u201cSmart-Its Friends: A Technique for Users to Easily Establish Connections between Smart Artifacts,\u201d Proc. 3rd Int\u2019l Conf. Ubiquitous Computing (Ubicomp), Springer Verlag, vol. 2201, 2001, pp. 116-122. IEEE Computer Graphics and Applications 63 10 In the future, a multitude of everyday objects could be equipped with embedded sensing, computation, and communication capabilities.Lars Erik Holmquist is leader of the  Future  Applications  Lab,  a research group at the Viktoria Institute  in  Gothenburg,  Sweden.  His research interests include ubiquitous computing, mobile services, and information  visualization.  Holmquist received a PhD in informatics from Gothenburg University. Hans-Werner Gellersenis a professor of interactive systems in the department of computing at Lancaster University. His research interests include ubiquitous computing and human-computer systems that take the real world into account. Gellersen received a PhD in computer science from the University of Karlsruhe. Gerd  Kortuem is  a  lecturer  in computer science at Lancaster University. His research interests include user interface technologies, ubiquitous computing, wearable computing,  and  software  engineering. Kortuem received a PhD in computer science from the University of Oregon. He is a member of the IEEE Computer Society and the ACM. Albrecht Schmidtis a researcher with the media informatics group at the  University  of  Munich.  His research interests include novel user interfaces and new forms of interaction enabled by ubiquitous computing.  Schmidt  received  a  PhD  in computer science from Lancaster University. Martin Strohbach is a PhD student  at  Lancaster  University.  His research interests include development  support  for  smart  objects. Strohbach received an MSc in context aware systems from the University of Karlsruhe. Stavros Antifakos is a PhD student in the perceptual computing and computer vision group at ETH Zurich. His current research interests include perceptual computing with a diverse set of sensors, ambient displays, and applications for ubiquitous computing environments. Antifakos received the equivalent of a master\u2019s degree in computer science from ETH Zurich. Florian Michahellesis a PhD student in the perceptual computing and computer  vision  group  at  ETH Zurich. His research interests include participative design of wearable computing applications with end users and self-organizing sensors for perceptual computing. Michahelles received an MSc in computer  science  from  Ludwig-Maximilians  Universit\u00e4t M\u00fcnchen, Germany. Bernt Schiele is an assistant professor  at  the  computer  science department  at  ETH  Zurich.  His research interests include computer vision, perceptual computing, statistical  learning  methods,  wearable computers, and integration of multimodal sensor data. Schiele received a PhD in computer science from INP Grenoble, France. He is a member of the IEEE Computer Society and the ACM. Michael Beiglis a senior research assistant at the University of Karlsruhe. His research interests include people at the center of communication and information technology, with speci\ufb01c interest in novel information appliances, electronic artifacts, mobile and ubiquitous networks, human-computer interaction, and context awareness. Beigl received a PhD in computing from the University of Karlsruhe. Ramia Maz\u00e9 is the director of the PLAY studio of the Interactive Institute in Sweden, which focuses on new materials and methods in the design of ubiquitous computing applications. Her research interests include user-centered methods and strategies for prototyping new systems, products, and concepts. Maz\u00e9 received an MA in computer design from the Royal College of Art, London. Readers may contact Lars Holmquist at Viktoria Inst., Box 620, SE 405 30; Goteborg, Sweden; leh@viktoria.se. For further information on this or any other computing topic, please visit our Digital Library at http:\/\/computer. org\/publications\/dlib.","cites":null},{"id":16316717,"title":"The Computer for the 21st Century,\u201d","authors":[],"date":"1991","doi":"10.1038\/scientificamerican0991-94","raw":"1. M. Weiser, \u201cThe Computer for the 21st Century,\u201d Scientific Am., vol. 265, no. 9, 1991, pp. 66-75.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2004-01","abstract":"Smart-Its are self-contained, stick-on computers that attach to everyday objects. These augmented objects become soft media, enabling dynamic digital relationships with users and each other","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/70352.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/12390\/1\/smart%2Dits_cga.pdf","pdfHashValue":"3087f1dd30ddddd129ac65df369aa2b889a73c18","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:12390<\/identifier><datestamp>\n      2018-01-24T00:04:29Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Building intelligent environments with smart-its<\/dc:title><dc:creator>\n        Holmquist, Lars Erik<\/dc:creator><dc:creator>\n        Gellersen, Hans<\/dc:creator><dc:creator>\n        Kortuem, Gerd<\/dc:creator><dc:creator>\n        Schmidt, Albrecht<\/dc:creator><dc:creator>\n        Strohbach, Martin<\/dc:creator><dc:creator>\n        Antifakos, Stavros<\/dc:creator><dc:creator>\n        Michahelles, Florian<\/dc:creator><dc:creator>\n        Schiele, Bernt<\/dc:creator><dc:creator>\n        Beigl, Michael<\/dc:creator><dc:creator>\n        Maze, Ramia<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        Smart-Its are self-contained, stick-on computers that attach to everyday objects. These augmented objects become soft media, enabling dynamic digital relationships with users and each other.<\/dc:description><dc:date>\n        2004-01<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/MCG.2004.1255810<\/dc:relation><dc:identifier>\n        Holmquist, Lars Erik and Gellersen, Hans and Kortuem, Gerd and Schmidt, Albrecht and Strohbach, Martin and Antifakos, Stavros and Michahelles, Florian and Schiele, Bernt and Beigl, Michael and Maze, Ramia (2004) Building intelligent environments with smart-its. IEEE Computer Graphics and Applications, 24 (1). pp. 56-64. ISSN 0272-1716<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/12390\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/MCG.2004.1255810","http:\/\/eprints.lancs.ac.uk\/12390\/"],"year":2004,"topics":["QA75 Electronic computers. Computer science"],"subject":["Journal Article","PeerReviewed"],"fullText":"In the Smart-Its project, we are developingtechnology to realize a vision of computa-\ntion everywhere, where computer technology seam-\nlessly integrates into everyday life, supporting users in\ntheir daily tasks. By embedding sensors, computation,\nand communication into common artifacts, future com-\nputing applications can adapt to human users rather\nthan the other way around. Howev-\ner, it\u2019s currently difficult to develop\nthis type of ubiquitous computing1\nbecause of the lack of toolkits inte-\ngrating both the required hardware\nand software. Therefore, we are cre-\nating a class of small computers\u2014\ncalled Smart-Its (http:\/\/www.\nsmart-its.org)\u2014equipped with\nwireless communication and sen-\nsors to make it possible to create\nsmart artifacts with little overhead.\nThe Smart-Its project is a collabo-\nration among six partners in five\ncountries: ETH Zurich (Switzer-\nland), Interactive Institute (Swe-\nden), Lancaster University (UK), the\nUniversity of Karlsruhe (Germany),\nthe Viktoria Institute (Sweden), and VTT (Finland). The\nproject ran from 2001 to 2003 as part of the European\nresearch initiative called the Disappearing Computer\n(http:\/\/www.disappearing-computer.org). In this proac-\ntive research program, the European Union\u2019s funding\nagency for Future and Emerging Technologies supports\nthe exploration of how information technology can be\ndiffused into everyday objects and settings. There are 16\nprojects in the program, developing everything from\ncomputational fibers to computer-augmented office fur-\nniture. By supporting a critical mass of innovative and\nfar-reaching projects, the Disappearing Computer pro-\ngram hopes to create synergy effects that could not have\nbeen achieved by a smaller number of separate projects.\nThe Smart-Its vision fits well into the overall goal of\nthe Disappearing Computer initiative. We see a future\nin which mundane everyday artifacts become aug-\nmented as soft media, and thus become able to enter\ninto dynamic digital relationships with users and with\neach other. The long-term goal of the Smart-Its project\nis providing a platform that developers and researchers\ncan use to explore future applications but with much\nless overhead than currently required. As Smart-Its and\nother similar physical construction kits stabilize, they\nshould become as easy to use as today\u2019s GUI toolkits for\ndesktop computers. When we reach this stage, we\nbelieve there will be an explosion of new innovations;\njust as fast graphics and GUI toolkits have enabled a mul-\ntitude of new interactive applications for desktop com-\nputers. To this end, we are in the process of releasing all\nnecessary information about Smart-Its into the public\ndomain so that others can benefit from the work.\nSmart-Its platform\nYou can think of a Smart-Its as a small, self-contained,\nstick-on computer that users can attach to objects much\nlike a 3M Post-It note. To ensure flexibility, we used a\nmodular approach when designing the hardware. A\nSmart-Its consists of a core board with a wireless trans-\nceiver to let the device communicate with other Smart-\nIts, plus a sensor board that gives the Smart-Its data\nabout its surroundings. For more information about the\nSmart-Its architecture, see \u201cThe Smart-Its Hardware\u201d\nsidebar. The standard sensor board has five sensors:\nlight, sound, pressure, acceleration, and temperature.\nFor specific purposes, we could add other sensors\u2014such\nas a gas sensor, a load sensor, or a camera for receiving\nimages. We have also developed several APIs to aid\napplication development. For instance, there is a com-\nmunication API to facilitate communication between\nSmart-Its and other devices. Another example is the per-\nception API, which allows the abstraction of low-level\nsensor data to higher-level concepts, so-called percepts.\nFor more information about programming for the\nSmart-Its, see \u201cThe Smart-Its Perception API\u201d sidebar\non page 58.\nThe major advantage of the Smart-Its platform is that\nit allows designers and researchers to construct respon-\nsive or intelligent environments with comparably little\nEmerging Technologies\nSmart-Its are self-contained,\nstick-on computers that\nattach to everyday objects.\nThese augmented objects\nbecome soft media,\nenabling dynamic digital\nrelationships with users and\neach other.\nLars Erik Holmquist\nViktoria Institute\nHans-Werner Gellersen, Gerd Kortuem, \nAlbrecht Schmidt, and Martin Strohbach \nLancaster University\nStavros Antifakos, Florian Michahelles, and \nBernt Schiele\nETH Zurich \nMichael Beigl \nUniversity of Karlsruhe \nRamia Maz\u00e9\nInteractive Institute\nBuilding Intelligent\nEnvironments with\nSmart-Its\n56 January\/February 2004 Published by the IEEE Computer Society 0272-1716\/04\/$20.00 \u00a9 2004 IEEE\noverhead.2 Typically, research projects that develop\nsmart or context-aware objects require building a lot of\ncustom hardware and software from scratch. The\nSmart-Its project addresses this issue by presenting a\nstandardized hardware solution coupled with commu-\nnication and sensing APIs. Future interactive systems\nIEEE Computer Graphics and Applications 57\nThe Smart-Its Hardware\nWith the Smart-Its hardware (see Figure A), we provide\ngeneric devices for sensing, computing, and\ncommunication on a large scale. Currently, Smart-Its can be\nas small as 17 x 25 x 15 mm including sensors and battery,\nwith a weight of about 8 grams (or 20 grams including an\nAAA battery). Other Smart-Its types are larger and simpler,\naiming at ease of modification, customization, and\nreproduction for use as teaching material or as quick\ndemonstrator projects. Over the course of the project, the\nSmart-Its hardware has evolved into smaller, more compact\niterations, as shown in Figure B. A broad range of sensors\nand actuators can be integrated on the devices. The generic\nsensor boards can sense audio, light levels, acceleration,\nhumidity, temperature, and pressure. Outputs include a\nspeaker and LEDs. Additional sensors and actuators are\nattachable via standard I\/O interfaces, allowing us to\nextend the capabilities with off-the-shelf components. \nSmart-Its can be powered by a range of sources, from\nlithium coin cells, standard AAAs, or rechargeable batteries.\nThe choice depends on the target artifact\u2019s shape and size,\nuse, and projected lifetime. Smart-Its\u2019 onboard computing\nand storage allows it to process small programs without any\nassumption of computing infrastructure in the environment.\nFor example, each Smart-Its can interpret its own sensor\nvalues along with those gathered from other sensor devices.\nIt can then communicate the interpreted values to other\nsystems, such as a PC or other more high-powered\nprocessing unit. To minimize the requirements for regular\nuser-based maintenance, Smart-Its introduces a new power-\nmanagement concept based on sensed situations. The\ndevice controls power-safe modes of internal and attached\nexternal devices. Depending on the application\u2014sensors\nused, processing required, and communication needs\u2014a\nSmart-Its\u2019 lifetime ranges from several days to one year.\nThe Smart-Its also features efficient short-range\ncommunication through a wireless ad hoc network.\nHardware requirements and constraints for the radio link\ndesign were size, energy consumption, full control on the\nphysical layer, and midspeed transmission bandwidth (125\nkilobits per second). Up to 1,024 nodes can request to be\nsent at the same time. An arbitrary number of Smart-Its\nreceiving and 256 trying to send at the same time reduces\nthe available network bandwidth by about 10 percent. In\ntypical settings with a dozen Smart-Its, interference is\nbelow the noise on the channel and is therefore not\nmeasurable. To allow fast reaction on network changes,\nSmart-Its instantly communicates (average 12.6 ms) even\nfrom a switched-off state or when coming to a new\nenvironment without any need for configuration. High-\nprecision automatic clock synchronization makes possible\nreal-time reaction on events from other devices, or\ncooperative behavior of devices. This lets us compare high-\nspeed signals such as audio or acceleration.\nDevelopment on Smart-Its is done in C. A wireless\nprogram download tool, analysis tool, and database tool\nsupport programming. The download tool connects to the\neditor and compiler and transfers developed programs to\nthe Smart-Its. The analysis tool supervises the behavior of\nSmart-Its and helps debug applications. The database tool\nallows retrieval of information from all communication and\nexports the data to statistic tools for long-term evaluation.\nSensors\nActuators\nPr\noc\nes\nsi\nng\nC\nom\nm\nun\nic\nat\nio\nns\nA To ensure flexibility, the Smart-Its hardware consists of two\nseparate components: a core board and a sensor board.\nB During the course of the project, the Smart-Its hardware has\nmoved through several evolutionary steps from (1) larger\nhardware to (2) smaller hardware.\n(1)\n(2)\nwill require a multitude of sensors and distributed com-\nputation. With Smart-Its and other physical prototyp-\ning toolkits, we can explore such systems today but\nwithout building everything from scratch. Smart-Its is\nonly one of several similar physical prototyping tools\nthat researchers can use to get applications up and run-\nning quickly. See the sidebar \u201cOther Physical Prototyp-\ning Kits\u201d for more information about prototyping.\nA major part of the Smart-Its project has been to\ndevelop and integrate the hardware and software. We\nalso developed several sample applications to demon-\nstrate the vision of computation embedded in the world.\nThese applications vary from solving a mundane but\nintricate task such as furniture assembly, to lifesaving\napplications such as supporting avalanche rescue teams.\nHowever, none of these should be considered the killer\napp that will accelerate the presence of ubiquitous com-\nputing. Instead, they act as a vehicle to explore the pos-\nsibilities of Smart-Its and similar technology. These\napplication demonstrations have also served to validate\nthe technology itself during the development process.\nProactive furniture assembly\nPrinted handbooks, instructions, and reference man-\nuals for items such as a laptop, furniture, or VCR all have\na common fault: Users rarely read them. It\u2019s not simply\nthat people are lazy, overconfident, and believe they\nhave no time to spend bothering with instructions. The\nquality of the instructions themselves is often poor. Fur-\nthermore, there is a divide between the instructions on\nthe printed page and the real object. What if the instruc-\ntions could be better integrated with the actual task?\nWith one Smart-Its application, shown in Figure 1,\nwe propose a framework for proactive guidance that\naims to overcome limitations of today\u2019s printed instruc-\ntions.3 We chose as our example the task of assembling\na piece of flat-pack furniture\u2014a seemingly simple\nprocess but one that often goes wrong. By attaching\ncomputing devices and multiple sensors onto the parts\nof the unassembled furniture, the system can recognize\nthe actions of the user and determine the current state\nof the assembly process. It can then suggest the next\nmost appropriate action at any point in time. We used\nthe sensors in Smart-Its devices attached to the furni-\nture to gather information about the user\u2019s actions. A\nseparate laptop collected the information through wire-\nless communication with the Smart-Its.\nTo assist the user, we need to create a plan that repre-\nsents the different ways to assemble the piece. The plan\nconsists of states and interconnecting actions, similar to\nthose in a finite-state machine. We can divide the actions\nrequired to assemble the furniture hierarchically into par-\ntial actions. We can detect these partial actions with the\naccelerometers and force sensors of the Smart-Its\nattached to the boards. Furthermore, a gyroscope in the\nscrewdriver supplies additional information. Using a\nlarge enough number of sensors, we achieve high-quali-\nty perception and provide precise instructions to the user.\nOne important problem is how to present the infor-\nmation. Originally, we used a laptop screen to present\nthe user\u2019s progress. However, this still presents a divi-\nsion between the instructions and the actual object.\nInstead, to integrate the instructions into the objects\nperfectly, we mounted LEDs directly on the boards,\nshown in Figure 2. By using different colors and blink-\ning patterns, we can provide a limited but precise set of\ninstructions: The underlying principle is to enhance the\nphysical object\u2019s static affordances by additional dynam-\nics hints.4 User studies revealed that the integration of\nthe instructions into the objects provides a significant-\nly better understanding than presenting descriptions on\na separate screen.\nEmerging Technologies\n58 January\/February 2004\nThe Smart-Its Perception API\nThe Perception API (PAPI), which insulates application requests\nfrom internal sensor processing, provides uniform access to various\nkinds of sensors. PAPI addresses single perception among sensors\nlocated on the same Smart-Its board, collective perception among\ndistributed Smart-Its boards, and out-band processing for large data\nstreams. Unique universal identifiers distinguish the different\nboards, sensors, and features of sensor values. Each Smart-Its device\nis aware of its attached sensors and can share this information with\nother devices through wireless communication. PAPI offers a query\nmechanism for discovering available sensors. As a result, PAPI\nabstracts from internal sensor processing and provides a more\nconvenient access to sensor readings by various methods.\nDevices can access local sensor readings, referred to as single\nperception, via four methods. A single request enables a device to\nreceive only one single sensor value, or allows it to poll a series of\nvalues. The condition-triggered notification method offers atomic\nfeature value conditions (<, >, =) that specify when a particular\nsensor should send an interrupt to the calling device. All conditions\nare treated as one-time triggers. The continuous-subscription\nmethod offers a continuous feature value series on a timely basis.\nThe constant stream method constantly streams feature data by\nusing maximal bandwidth.\nCollective perception enables Smart-Its to have remote access to\nsensors attached to other Smart-Its boards. In such cases, a\ndistance measure can set the sensor discovery range. A value of 0\nrepresents all local sensors on a Smart-Its board, whereas 255\nmeans all accessible boards. The values in between represent\ncorresponding physical distance measures.\nFinally, an out-band functionality enables an application to\nreserve the entire radio band for streaming intensive data, such as\nvideo or high-quality audio, to external back-end resources.\nHowever, because out-band functionality blocks the entire Smart-Its\ncommunication function, its use should be limited to short periods.\n1 We attached\nSmart-Its to the\npieces of a flat-\npack furniture\nkit and to some\nof the assembly\ntools, letting\nthe system\nmonitor the\nuser\u2019s progress.\nAlthough this example concerns\nfurniture, we can generalize it to\nmany other assembly tasks, such as a\ncar or airplane factory assembly line.\nFor many safety-critical assembly\nand maintenance tasks, this type of\nrecognition and verification of pro-\ncedural actions might also prove use-\nful. We predict the initial adoption of\nthis technology happening in this\narea. Another possibility is quality\ncontrol. Whereas it currently does\nnot make economic sense to embed\nsensors in furniture that costs a few\nhundred dollars, it can pay off quick-\nly when assembling an expensive\nIEEE Computer Graphics and Applications 59\nOther Physical Prototyping Kits\nA main feature of intelligent environments is the ability to\nsense different contexts, and there are several frameworks\nfor creating context-aware applications. For instance, the\ncontext toolkit1 presents a software framework to support\nthe implementation of context-aware applications. This\nframework enables exploration of context-aware design\nspace, particularly in dealing with ambiguous or inaccurate\nsensor data. However, the level of abstraction is high, and\nthis toolkit doesn\u2019t present the integrated hardware-\nsoftware solution that Smart-Its represents. \nAs small computing devices that integrate physical\ninteraction and wireless networking, Smart-Its shares several\nfeatures with other wireless sensor platforms. The Berkeley\nMotes platform was originally developed for collection of\nsensor data in large-scale ad hoc networks but recently\nresearchers have considered it for ubiquitous computing\napplications.2 Motes places more emphasis on networking,\ncommunication, and data propagation. To support this,\nMotes provides the Tiny OS for very small networked\ndevices and a protocol stack that supports ad hoc routing in\nlarge networks\u2014features not available in Smart-Its. Smart-\nIts, on the other hand, provides distinct support for rapid\nassembly and design iterations over device concepts. \nOther small-computing platforms to which Smart-Its\nrelates include the i-Bean from Millennial Net and MIT\u2019s\nSensor Stack. The i-Bean is a self-contained, miniaturized\ncomputer with a digital I\/O interface, analog-to-digital and\ndigital-to-analog converters, and a radio frequency trans-\nceiver for bidirectional communication.3 The i-Bean func-\ntions as a data-acquisition and processing device and is\nprimarily used for healthcare applications. The Sensor Stack\nplatform for high-density wireless sensing stresses device\nmodularity and fast prototyping.4 The modules are fabri-\ncated in a 3D stackable manner, allowing for the develop-\nment and easy addition of extra panels.\nTwo European platforms to which the Smart-Its project\nrelates are the Eyes sensor node,5 which is under develop-\nment by a European project consortium for sensor network\nresearch, and the BTNode developed at ETH Zurich.6 The\nBTNode Bluetooth-based sensor node stresses interoper-\nability as the main design goal. To support Bluetooth\nnetworking, BTNode uses a more powerful processor and\nmore memory than most other sensor-node platforms.\nAmong these platforms, the Smart-Its technology is unique in\nits focus on rapid prototyping and development of hardware\nand software. \nSeveral toolkits exist for prototyping tangible input and\noutput systems not based on wireless communication.\nRecent examples include Phidgets7 and iStuff.8 Such toolkits\nhelp developers create customized input and output\ndevices for a variety of applications running on a dedicated\ncomputer. Examples of input devices include physical\nbuttons, sliders, and tag readers. Output devices include\nmotors, buzzers, and lights as well as a computer screen.\nSuch toolkits could potentially expand the vocabulary of\ninteractive applications beyond the mouse and keyboard.\nReferences\n1. A.K. Dey et al., \u201cConceptual Framework and a Toolkit for Sup-\nporting the Rapid Prototyping of Context-Aware Applications,\u201d\nHuman-Computer Interaction (HCI) J., vol.16, nos. 2-4, 2001, pp.\n97-166.\n2. J. Hill et al., \u201cSystem Architecture Directions for Networked Sen-\nsors,\u201d Architectural Support for Programming Languages and Oper-\nating Systems, 2000, pp. 93-104.\n3. S. Rhee and S. Liu, \u201cAn Ultra-Low Power, Self-Organizing Wireless\nNetwork and Its Applications to Noninvasive Biomedical Instru-\nmentation,\u201d Proc. IEEE\/Sarnoff Symp. Advances in Wired and Wire-\nless Comm., IEEE Press, 2002.\n4. J. Barton et al., \u201cMiniature Modular Wireless Sensor Networks,\u201d\nAdjunct Proc. 4th Int\u2019l Conf. Ubiquitous Computing (Ubicomp), Vik-\ntoria Inst., 2002, pp. 25-26.\n5. S. Dulman and P. Havinga, Operating System Fundamentals for the\nEYES Distributed Sensor Network, Utrecht, 2002.\n6. J. Beutel et al., Thiele: Bluetooth Smart Nodes for Ad-Hoc Networks,\nTIK Report No. 167, ETH Zurich, April 2003.\n7. S. Greenberg and C. Fitchett, \u201cPhidgets: Easy Development of\nPhysical Interfaces through Physical Widgets,\u201d Proc. 14th Ann.\nACM Symp. User Interface Software and Technology (UIST 01), ACM\nPress, 2001, pp. 209-218.\n8. R. Ballagas et al., \u201ciStuff: A Physical User Interface Toolkit for Ubiq-\nuitous Computing Environments,\u201d Proc. ACM Ann. Conf. Human\nFactors in Computing Systems (SIGCHI), 2003, pp. 537-544.\n2 LED lights on\nthe components\nguide the user\nin the assembly\nprocess: (a)\nrotation and \n(b) screwing.\n(a) (b)\nitem (such as a car) or when maintaining a safety-criti-\ncal part of a power plant. If even one mistake per item is\navoided, this could easily justify the whole investment.\nLoad-sensing furniture\nSo what happens when the pieces have been assem-\nbled? If we leave the Smart-Its and sensors in the furni-\nture, ordinary furniture can be made smart. One area\nin which we have found surprising potential is load sens-\ning, which effectively means turning ordinary pieces of\nfurniture into weight-measuring devices.5\nUsing Smart-Its, we embedded load-sensing tech-\nnology in several pieces of furniture: a coffee table, a\ndining table, shelves, and drawers. The tables in partic-\nular are augmented using industrial load cells, as shown\nin Figure 3. We can unobtrusively install the cells\nbetween the tabletop and frame so that the tabletop\nrests on a load cell at each corner. In our latest version,\nwe placed the boxes containing the load cells under the\ntable legs, making augmentation of the table much more\nflexible. For each surface, a Smart-Its with a load add-\non module interfaces with the load cells. The system\nsamples and reads the values from all four load-sensing\ncells at about 200 Hz. Because we build the technology\non top of the Smart-Its platform, each augmented object\nbecomes a wireless sensor in the Smart-Its network.\nBy measuring the load on each corner, we can easily\ncalculate the center of gravity\u2019s location on the surface.\nBy observing how the center of gravity moves, we can\ndetect interaction on the surface and recognize specific\npatterns. We can process this information into interac-\ntion primitives, such as tracking an object\u2019s position and\nweight or a finger\u2019s track as someone traces it over the\nsurface. In essence, the entire table surface becomes a\nsensor system because we can precisely pinpoint the loca-\ntion and weight of all objects placed on it. Together, sev-\neral load-sensing chairs and tables could collect detailed\ninformation about the activity in an environment.\nOn the basis of these interaction primitives, we devel-\noped several applications. For instance, one application\nlets the user use a surface, such as a tabletop, to manipu-\nlate a mouse pointer on a computer\nscreen. The movement of the finger\nor of an object on the surface\u2014cap-\ntured in the trace interaction primi-\ntive\u2014is then converted in increments\nfor the mouse movement in a con-\nventional system. In other words,\ninstead of manipulating a mouse on\nthe table, the user can regard the\nentire table as a pointing device. This\ncould be quite convenient when\nusers must control an electronic\ndevice, such as a television set, but\ndon\u2019t wish to use yet another remote\ncontrol or pointing device.\nSupporting avalanche\nrescue\nSmart-Its is a general platform\nsuitable for many types of applica-\ntions, including mobile and wear-\nable computing systems. For example, the prototype of\nthe avalanche lifeguard system, A-Life, incorporates\nSmart-Its technology.6 The goal of the A-Life project was\nto explore the applicability of wearable sensors for\nmountaineers, skiers, and snowboarders. We involved\ndomain experts such as emergency physicians, profes-\nsional rescuers, and avalanche researchers early in the\ndevelopment process.\nIn alpine areas, many landslides each year cause acci-\ndents and even deaths. The time it takes to find and\nextricate victims is extremely crucial: Once a person is\nburied, the survival chances drop dramatically after the\nfirst 15 minutes. Current technology, such as radio-\nbased tracking systems, can only offer the rescue team\ninformation on the location of a single victim at a time.\nHowever, statistics show that in many cases there are\nmultiple victims, and the order in which rescuers save\nthem can be crucial. Some victims might survive for\nhours, whereas others only have minutes. If rescuers\ncould find a means to address the most urgent cases first,\nthey might save many additional lives.\nThe A-Life system, shown in Figure 4, addresses this\nissue using wearable Smart-Its-based sensors. These\nsensors measure vital signs and environmental condi-\ntions of avalanche victims; the system then broadcasts\nthe information to rescuers. Visualizing this informa-\ntion will help rescuers in the field separate victims by\nurgency and coordinate the rescue process more effi-\nciently. The Smart-Its technology helped in construct-\ning a functional rapid prototype for a first evaluation\nwith experts: Off-the-shelf oximeters, oxygen sensor,\nand accelerometer connect to a Smart-Its communica-\ntion board that establishes a connection to a handheld\ncomputer (shown in Figure 5) and wireless connectivi-\nty among different prototype units. Different focus\ngroups have used this prototype for participatory eval-\nuations with practitioners in the field. In particular, we\ndemonstrated it to avalanche researchers of the Swiss\nFederal Institute for Snow and Avalanche Research, to\na practicing emergency physician, and to skiers at an\navalanche rescue-training course. \nEmerging Technologies\n60 January\/February 2004\n3 Load-sensing\nfurniture has\nload cells\ninstalled in each\ncorner, moni-\ntored by a cen-\ntral Smart-Its.\nGenerally, we received positive feedback for the idea\nof applying wearable sensors to avalanche rescue, as\nthis was a completely new idea for all participants. We\nhad an interesting discussion with emergency physi-\ncians about the appropriateness of the different sens-\ning technologies. The avalanche researchers suggested\nrecording sensor values over time for analyzing the\nprocess of an avalanche accident, much like black-box\ndevices do in airplanes. Ethical issues initiated a dis-\ncussion on whether a device should suggest to rescuers\nwhich victim to rescue first. The Smart-Its technology\nprototype enabled us to show the opportunities of sens-\ning technology for avalanche rescue before we actual-\nly develop the final product. We believe that Smart-Its\nalso could help in prototyping many other wearable\napplications.\nEnvisioning the smart restaurant\nWhat would it be like to have a complete environ-\nment augmented with smart technology? In a collabo-\nration between an interaction designer and a technical\nteam, we created a set of demonstrators that used\nSmart-Its in conjunction with various presentation\ntechniques to envision a complete future workplace.7\nWe presented the demonstrations as an interactive\nexhibit in which visitors could manipulate different\naugmented objects to trigger various responses. The\ndemonstration made use of actual sensor values\nderived from Smart-Its attached to the objects. To flesh\nout the environment, we provided more expansive\nparts of each scenario, presented as animations that\nvisitors\u2019 actions would trigger.\nWe chose restaurants as the domain. A restaurant is\na dynamic environment where people act in many dif-\nferent roles\u2014as guests, waiters, chefs, and so on\u2014per-\nforming different tasks, such as ordering from a menu,\nserving a dish, or preparing the food. These activities\nrely on a diverse set of artifacts, like kitchen utensils,\nfood items, and furniture. All this seemed to make\nrestaurants a perfect environment for Smart-Its aug-\nmentation (see Figures 6 and 7).\nIEEE Computer Graphics and Applications 61\nOxygen sensor\nOximeter\n4 The A-Life\nsystem uses an\noximeter and\nother sensors to\nprovide rescue\nteams with\nupdated infor-\nmation about\navalanche\nvictims.\n5 The rescue\nteam\u2019s interface\nis PDA based\nand gives\ninstant access to\nvital informa-\ntion to aid in\ntheir work.\n6 To create a smart restaurant environment, we aug-\nmented several everyday artifacts with Smart-Its.\n7 Together, the items in the smart restaurant installation created an inter-\nactive environment where visitors could interact with smart objects.\nIn the first scenario, as illustrated in Figure 8, we\nshowed how sensitive food items could keep track of\ntheir lifecycle status, and how they could communicate\nin internal and external networks. In the demonstra-\ntion, we augmented a box of oysters in a refrigerator\nwith a Smart-Its. When visitors opened the fridge door,\nan image of the oyster box would appear on a separate\nscreen. A dynamic best-before label on this animated\nbox would change according to how long the fridge door\nwas kept open and the time before the oysters expired.\nThis best-before value changed in real time but was sim-\nulated because we did not have access to a sufficiently\ncomplex set of sensors to correctly determine the oys-\nters\u2019 freshness.\nInstead, we simply determined if the fridge door was\nopen by using the light sensor in the Smart-Its. If the vis-\nitor kept the door open too long, an animated sequence\nwould run, showing how new oysters were arriving in a\ndelivery truck and a dock at the harbor. The idea was\nthat if all oyster boxes were augmented, they could start\nan internal negotiation of their value. For example, a\nbox that would soon expire might, if there were fresh\nboxes arriving at the local distributor, be prepared to\nlower its asking price quite significantly to restaurateurs\nshopping for oysters.\nThe second scenario, shown in Figure 9, illustrated\nhow the status of food items could be directly reflected\nin the cost for customers. Visitors were invited to manip-\nulate a bottle of wine, augmented with a Smart-Its. The\nsensors in the bottle would monitor temperature, light\nexposure, angle, and movement used to calculate a\ndecay curve reflecting if the wine had been correctly\nstored. When the bottle was shaken\u2014which would\nrelease sediment and thus degrade the quality\u2014an ani-\nmated menu would appear. The prices of the different\nwines on the menu would change dynamically so that\nthe price of a bottle that was mistreated might go down,\nwhereas the price of well-treated bottles would go up.\nIf the user put the bottle back in\nthe correct position for storage, its\nprice would eventually stabilize and\ngo up again, reflecting that the sed-\niment had settled. We did not mea-\nsure the actual sediment, but used\nthe Smart-Its\u2019 accelerometer to\ndetect movements and position. An\naccompanying video showed how\nthe bottles in the wine cellar would\nnegotiate a sort of stock market\nvalue and how the current menu\nwould be advertised on an external\nbillboard.\nThe final scenario showed how\nseveral objects could collaborate\nand share data to support a task. It\ntook the form of an interactive order\npreparation where Smart-Its-aug-\nmented items included a piece of\ncheese and a wine bottle. Visitors\nwould place the items on a tray, and\nby simply moving the tray to the\nserving counter, the items would\nbecome grouped together and open a communication\nchannel. The grouping was determined by comparing\nthe movement of the objects as read by the Smart-Its\u2019\naccelerometers. Only the objects on the tray would share\nthe same values. This is similar to the Smart-Its friends\ntechnique, where users would hold objects together and\nshake them to explicitly create a grouping.8\nWhen the objects had been grouped, the objects\nthemselves could start to determine the optimal serv-\ning conditions. The cheese requires a correct tempera-\nture, the wine must settle, and so forth. An animation\nshowed these values as they changed, but because tem-\nperature changes much too slowly for use in an exhibi-\ntion setting, we simulated some numbers. When all\nEmerging Technologies\n62 January\/February 2004\n8 Animations\nshow aspects of\nthe demonstra-\ntions that we\ndid not directly\nimplement in\nphysical arti-\nfacts.\n9 We used\nanimation to\nillustrate how\nthe status of\nfood items\ncould be direct-\nly reflected in\nthe cost for\ncustomers.\nitems were ready, the Smart-Its\ndevices would signal the waiter and\nan animation would show how the\nwaiter could now serve the com-\npleted order.\nTaken together, this suite of pre-\nsentations showed how sensors,\ncommunication, and computation\ncould augment and support several\nobjects and tasks. By mixing real\nsensor data and visual scenarios, we\ncreated a complete vision of an intel-\nligent environment of the future,\nwith which visitors could interact.\nFuture Smart-Its\ntechnology\nWith Smart-Its, we have taken the\nfirst steps toward a platform for cre-\nating intelligent environments like\nthe kind shown in Figure 10. As\nshown in the application examples, such environments\ncould potentially support users in many different tasks,\nfrom the mundane assembly of a piece of furniture to\nlife-and-death situations in the field. With the increased\nproliferation and availability of Smart-Its and other plat-\nforms for creating computationally augmented physi-\ncal environments, we will see a lot of experimentation\nthat could lead to products that enter the mainstream.\nIn fact, this is already happening. A multitude of smart\nconsumer products that use this type of sensor and com-\nmunication technology are in development at research\nlabs all over the world. It\u2019s only a question of time before\nwe can buy them in the shops. \nBut it is obvious that there still must be several key\nadvances before this type of technology can easily be\nembedded in everyday objects. In particular, the size\nmust shrink, as must the cost, to make possible the real-\nistic inclusion of this kind of technology in consumer\nproducts. Power consumption must become signifi-\ncantly lower, if only because users will not want to\nchange batteries in their sensing tables or recharge their\nsmart coffee cups very often. For prototyping and prod-\nuct development, standardized tools and APIs must\nmake application development easier. Finally, if we envi-\nsion a world with a multitude of smart objects that inter-\noperate and communicate, we must create common\ncommunication protocols and agree upon semantics for\ndata sharing. \nEnabling platforms such as Smart-Its allows us to\ninvestigate these important issues. By letting researchers\nquickly build and evaluate smart and context-aware\napplications, they can give us a glimpse of the intelli-\ngent environments of the future. \u0002\nAcknowledgments\nWe thank all members of the Smart-Its consortium for\ntheir role in the collaborative development of the Smart-\nIts applications. In particular, contributors to the imple-\nmentation of the platform and demonstrators include\nTimo Ahonen, Christian Decker, Lalya Gaye, Peter\nLjungstrand, Magnus Nilsson, Tobias Rydenhag, Daniel\nSpanagel, and Nicolas Villar. Hanna Landin created the\nvideo from which Figure 10 is taken. The Smart-Its pro-\nject is funded in part by the Commission of the Euro-\npean Union under key action \u201cFuture and Emerging\nTechnologies\u201d (contract IST-2000-25428), and by the\nSwiss Federal Office for Education and Science (con-\ntract BBW 00.0281). Lancaster\u2019s contribution was made\npossible with additional support from the UK Engi-\nneering and Physical Science Research Council as part\nof the Equator project (grant GR\/N15986\/01).\nReferences\n1. M. Weiser, \u201cThe Computer for the 21st Century,\u201d Scientif-\nic Am., vol. 265, no. 9, 1991, pp. 66-75.\n2. H. Gellersen et al., \u201cPhysical Prototyping with Smart-Its,\u201d to\nappear in IEEE Pervasive Computing, Oct.-Dec. 2003.\n3. S. Antifakos, F. Michahelles, and B. Schiele, \u201cProactive\nInstructions for Furniture Assembly,\u201d Proc. 4th Int\u2019l Conf.\nUbiquitous Computing (Ubicomp), Springer Verlag, vol.\n2498, 2002, pp. 351-359.\n4. F. Michahelles et al., \u201cInstructions Immersed into the Real\nWorld: How Your Furniture Can Teach You,\u201d Adjunct Proc.\n5th Int\u2019l Conf. Ubiquitous Computing (Ubicomp), Springer-\nVerlag, 2003, pp. 155-156.\n5. A. Schmidt et al., \u201cContext Acquisition Based on Load Sens-\ning,\u201d Proc. 4th Int\u2019l Conf. Ubiquitous Computing (Ubicomp),\nSpringer Verlag, vol. 2498, 2002, pp. 333-351.\n6. F. Michahelles et al., \u201cApplying Wearable Sensors to\nAvalanche Rescue: First Experiences with a Novel\nAvalanche Beacon,\u201d Computers & Graphics, vol. 27, no. 6,\n2003, pp. 839-847.\n7. L.E. Holmquist, R. Maz\u00e9\u201a and S. Ljungblad, \u201cDesigning\nTomorrow\u2019s Smart Products: Experience with the Smart-\nIts Platform,\u201d Proc. Designing for User Experience (DUX 03),\nACM Press, 2003.\n8. L.E. Holmquist et al., \u201cSmart-Its Friends: A Technique for\nUsers to Easily Establish Connections between Smart Arti-\nfacts,\u201d Proc. 3rd Int\u2019l Conf. Ubiquitous Computing (Ubi-\ncomp), Springer Verlag, vol. 2201, 2001, pp. 116-122.\nIEEE Computer Graphics and Applications 63\n10 In the\nfuture, a multi-\ntude of every-\nday objects\ncould be\nequipped with\nembedded\nsensing, compu-\ntation, and\ncommunication\ncapabilities.\nLars Erik Holmquist is leader of\nthe Future Applications Lab, a\nresearch group at the Viktoria Insti-\ntute in Gothenburg, Sweden. His\nresearch interests include ubiquitous\ncomputing, mobile services, and infor-\nmation visualization. Holmquist\nreceived a PhD in informatics from Gothenburg University.\nHans-Werner Gellersen is a pro-\nfessor of interactive systems in the\ndepartment of computing at Lan-\ncaster University. His research inter-\nests include ubiquitous computing\nand human-computer systems that\ntake the real world into account.\nGellersen received a PhD in computer science from the Uni-\nversity of Karlsruhe.\nGerd Kortuem is a lecturer in\ncomputer science at Lancaster Uni-\nversity. His research interests include\nuser interface technologies, ubiqui-\ntous computing, wearable comput-\ning, and software engineering.\nKortuem received a PhD in computer\nscience from the University of Oregon. He is a member of\nthe IEEE Computer Society and the ACM. \nAlbrecht Schmidt is a researcher\nwith the media informatics group at\nthe University of Munich. His\nresearch interests include novel user\ninterfaces and new forms of interac-\ntion enabled by ubiquitous comput-\ning. Schmidt received a PhD in\ncomputer science from Lancaster University.\nMartin Strohbach is a PhD stu-\ndent at Lancaster University. His\nresearch interests include develop-\nment support for smart objects.\nStrohbach received an MSc in context\naware systems from the University of\nKarlsruhe.\nStavros Antifakos is a PhD stu-\ndent in the perceptual computing\nand computer vision group at ETH\nZurich. His current research interests\ninclude perceptual computing with a\ndiverse set of sensors, ambient dis-\nplays, and applications for ubiqui-\ntous computing environments. Antifakos received the\nequivalent of a master\u2019s degree in computer science from\nETH Zurich.\nFlorian Michahelles is a PhD stu-\ndent in the perceptual computing and\ncomputer vision group at ETH\nZurich. His research interests include\nparticipative design of wearable com-\nputing applications with end users\nand self-organizing sensors for per-\nceptual computing. Michahelles received an MSc in com-\nputer science from Ludwig-Maximilians Universit\u00e4t\nM\u00fcnchen, Germany.\nBernt Schiele is an assistant pro-\nfessor at the computer science\ndepartment at ETH Zurich. His\nresearch interests include computer\nvision, perceptual computing, statis-\ntical learning methods, wearable\ncomputers, and integration of multi-\nmodal sensor data. Schiele received a PhD in computer sci-\nence from INP Grenoble, France. He is a member of the IEEE\nComputer Society and the ACM.\nMichael Beigl is a senior research\nassistant at the University of Karl-\nsruhe. His research interests include\npeople at the center of communica-\ntion and information technology,\nwith specific interest in novel infor-\nmation appliances, electronic arti-\nfacts, mobile and ubiquitous networks, human-computer\ninteraction, and context awareness. Beigl received a PhD\nin computing from the University of Karlsruhe.\nRamia Maz\u00e9 is the director of the\nPLAY studio of the Interactive Insti-\ntute in Sweden, which focuses on new\nmaterials and methods in the design\nof ubiquitous computing applica-\ntions. Her research interests include\nuser-centered methods and strategies\nfor prototyping new systems, products, and concepts. Maz\u00e9\nreceived an MA in computer design from the Royal College\nof Art, London.\nReaders may contact Lars Holmquist at Viktoria Inst.,\nBox 620, SE 405 30; Goteborg, Sweden; leh@viktoria.se.\nFor further information on this or any other computing\ntopic, please visit our Digital Library at http:\/\/computer.\norg\/publications\/dlib.\nEmerging Technologies\n64 January\/February 2004\n"}
{"doi":"10.1103\/PhysRevE.77.061105","coreId":"69763","oai":"oai:eprints.lancs.ac.uk:22886","identifiers":["oai:eprints.lancs.ac.uk:22886","10.1103\/PhysRevE.77.061105"],"title":"Inferential framework for nonstationary dynamics. I. Theory.","authors":["Luchinsky, Dmitri G.","Smelyanskiy, Vadim N.","Duggento, Andrea","McClintock, Peter V. E."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2008","abstract":"A general Bayesian framework is introduced for the inference of time-varying parameters in nonstationary, nonlinear, stochastic dynamical systems. Its convergence is discussed. The performance of the method is analyzed in the context of detecting signaling in a system of neurons modeled as FitzHugh-Nagumo FHN oscillators. It is assumed that only fast action potentials for each oscillator mixed by an unknown measurement matrix can be detected. It is shown that the proposed approach is able to reconstruct unmeasured hidden variables of the FHN oscillators, to determine the model parameters, to detect stepwise changes of control parameters for each oscillator, and to follow continuous evolution of the control parameters in the adiabatic limit","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/69763.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/22886\/1\/PRE2008InferentialFrameI.pdf","pdfHashValue":"99758b455646420f4abf1cf14c12331bb9749fe1","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:22886<\/identifier><datestamp>\n      2018-01-24T02:42:21Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5143<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Inferential framework for nonstationary dynamics. I. Theory.<\/dc:title><dc:creator>\n        Luchinsky, Dmitri G.<\/dc:creator><dc:creator>\n        Smelyanskiy, Vadim N.<\/dc:creator><dc:creator>\n        Duggento, Andrea<\/dc:creator><dc:creator>\n        McClintock, Peter V. E.<\/dc:creator><dc:subject>\n        QC Physics<\/dc:subject><dc:description>\n        A general Bayesian framework is introduced for the inference of time-varying parameters in nonstationary, nonlinear, stochastic dynamical systems. Its convergence is discussed. The performance of the method is analyzed in the context of detecting signaling in a system of neurons modeled as FitzHugh-Nagumo FHN oscillators. It is assumed that only fast action potentials for each oscillator mixed by an unknown measurement matrix can be detected. It is shown that the proposed approach is able to reconstruct unmeasured hidden variables of the FHN oscillators, to determine the model parameters, to detect stepwise changes of control parameters for each oscillator, and to follow continuous evolution of the control parameters in the adiabatic limit.<\/dc:description><dc:date>\n        2008<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/22886\/1\/PRE2008InferentialFrameI.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1103\/PhysRevE.77.061105<\/dc:relation><dc:identifier>\n        Luchinsky, Dmitri G. and Smelyanskiy, Vadim N. and Duggento, Andrea and McClintock, Peter V. E. (2008) Inferential framework for nonstationary dynamics. I. Theory. Physical Review E, 77 (6). pp. 1-8. ISSN 1539-3755<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/22886\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":null,"relations":["http:\/\/dx.doi.org\/10.1103\/PhysRevE.77.061105","http:\/\/eprints.lancs.ac.uk\/22886\/"],"year":2008,"topics":["QC Physics"],"subject":["Journal Article","PeerReviewed"],"fullText":"Inferential framework for nonstationary dynamics. I. Theory\nDmitri G. Luchinsky,1,2 Vadim N. Smelyanskiy,1 Andrea Duggento,2 and Peter V. E. McClintock2\n1NASA Ames Research Center, Mail Stop 269-2, Moffett Field, California 94035, USA\n2Department of Physics, Lancaster University, Lancaster LA1 4YB, United Kingdom\n\u0001Received 30 January 2008; published 4 June 2008\u0002\nA general Bayesian framework is introduced for the inference of time-varying parameters in nonstationary,\nnonlinear, stochastic dynamical systems. Its convergence is discussed. The performance of the method is\nanalyzed in the context of detecting signaling in a system of neurons modeled as FitzHugh-Nagumo \u0001FHN\u0002\noscillators. It is assumed that only fast action potentials for each oscillator mixed by an unknown measurement\nmatrix can be detected. It is shown that the proposed approach is able to reconstruct unmeasured \u0001hidden\u0002\nvariables of the FHN oscillators, to determine the model parameters, to detect stepwise changes of control\nparameters for each oscillator, and to follow continuous evolution of the control parameters in the adiabatic\nlimit.\nDOI: 10.1103\/PhysRevE.77.061105 PACS number\u0001s\u0002: 02.50.Tt, 05.45.Tp, 05.10.Gg, 05.45.Xt\nI. INTRODUCTION\nComplex phenomena in nature and technology can often\nbe modeled successfully by stochastic nonlinear dynamical\nsystems, thereby facilitating the diagnosis of faults, the prog-\nnosis of future conditions, and control. Examples range from\nmodels of reactors \u00031\u0004 and helioseismology \u00032\u0004 to models\nused in physiology \u00033\u0004 and neuroscience \u00034\u0004. The problem of\ninferring the parameters of such models from time-series\ndata has therefore attracted much attention over the past de-\ncade \u00033,5\u201313\u0004. In general, important control parameters of\nthe systems in question vary in time so that the system dy-\nnamics is nonstationary. It is highly desirable, therefore, to\nextend the inferential framework to encompass almost-real-\ntime tracking of time-varying parameters of nonstationary\nsystems.\nMost of the algorithms rely heavily on extensive numeri-\ncal simulation \u00039,10,13\u0004, or require a large amount of data\n\u00035,7\u0004 \u0001cf. econometric series analysis \u000314\u0004\u0002, and cannot easily\nbe adapted for parameter tracking in nonstationary stochastic\nnonlinear systems. More importantly, most earlier calcula-\ntions of flows produce biased estimates because they lack a\nterm related to the Jacobian of transformation from stochas-\ntic to deterministic variables. The term in question gives \u000315\u0004\na leading-order contribution to the inference results in the\npresence of strong dynamical noise.\nWe recently introduced an analytic solution of the dy-\nnamical inference problem \u000315,16\u0004 based on Bayesian statis-\ntics and a path-integral formulation of stochastic nonlinear\ndynamics. It allows for fast, unbiased estimation of the\nmodel parameters, provides optimal compensation for the\ndynamical noise, and paves the way to almost-real-time\ntracking of time-varying parameters. There are, however, two\nimportant features that have not hitherto been considered:\nmeasurement noise and nonstationarity of the dynamics.\nThey are often important in practice.\nIn this paper, we demonstrate how the Bayesian frame-\nwork can be extended to infer information encoded in time-\nvarying control parameters of a nonlinear nonstationary sys-\ntem, almost in real time. In paper II \u000317\u0004, immediately\nfollowing this paper, we consider an application of the\nscheme to a model of physiological signaling.\nSuch an inferential framework can have a wide range of\ninterdisciplinary applications ranging from aerospace \u000318,19\u0004\nto nanosensors. In particular, it can be especially advanta-\ngeous in the analysis of signals from neuronal systems. Their\ndynamical details are known only approximately. Internal\nand measurement noises exert strong influences, and the time\nvariation of the control parameters is directly related to in-\nformation coding. We focus on physiological applications,\ntherefore, and consider as an example the inference of time-\nvarying control parameters from the measurements of the\nspiking dynamics of neural systems. The neural system is\nmodeled by a set of FitzHugh-Nagumo \u0001FHN\u0002 equations\n\u000320\u201323\u0004, a system that has been found useful in modeling\nnerve fibers \u000324\u0004 and certain muscle cells, e.g., in the heart\ntissue \u000325\u201327\u0004. It has also been used intensively in studies of\npassive myelinated axons \u000328\u0004 and various forms of arrhyth-\nmia and cardiac activation evolution \u000329\u0004. The highly non-\nlinear and nonstationary nature of the system dynamics\nmakes it difficult to apply standard techniques for the reliable\ninference of control parameters.\nWe will show that our approach is able to decode the time\nevolution of the control parameters in a system of neurons\nmodeled as FHN oscillators, including detection of their\nlarge stepwise changes for each oscillator and continuous\nvariation in the adiabatic limit. Because the method is based\non nonlinear dynamical inference, the parameter-tracking al-\ngorithm is effectively embedded into the learning inferential\nframework, enabling us to reconstruct both the unmeasured\n\u0001hidden\u0002 variables of the FHN oscillators and the model pa-\nrameters. To illustrate this point, we will reconstruct the sys-\ntem parameters assuming that the original parameters of the\nmodel are unknown, that only one coordinate of each oscil-\nlator is available for recording, and that these measurements\nare mixed by a measurement matrix.\nThe paper is organized as follows. Section II presents the\ntheory of Bayesian dynamical inference in the presence of\ndynamical and measurement noises. An example of global\noptimization both in the parameter and path spaces is pro-\nPHYSICAL REVIEW E 77, 061105 \u00012008\u0002\n1539-3755\/2008\/77\u00016\u0002\/061105\u00018\u0002 \u00a92008 The American Physical Society061105-1\nvided in Sec. III. In Sec. IV, the theory of Bayesian inference\nfor a system of L FHN oscillators is presented, providing the\nbasis for physiological applications. In Sec. V, the results are\nsummarized and conclusions are drawn.\nII. BAYESIAN INFERENTIAL FRAMEWORK FOR\nNONSTATIONARY DYNAMICS\nA. A general approach\nLet us consider the following problem. Given\nM-dimensional time-series data Y= \u0005yn\u0006y\u0001tn\u0002\u0007 \u0001tn=nh\u0002, how\ncan one infer the time variation of the unknown model\nparameters and the unknown dynamical trajectory M\n={c\u0001t\u0002 ,b\u0001t\u0002 ,D\u02c6 ,M\u02c6 , \u0005xn\u0007}? It is assumed that the underlying\ndynamics can be described by a set of L-dimensional \u0001L\n\u0001M\u0002 stochastic differential equations of the form\nx\u02d9\u0001t\u0002 = f\u0001x\bc\u0002 + \tD\u02c6 \u0001\u0001t\u0002 , \u00011\u0002\nand the observations Y are related to the actual unknown\ndynamical variables X= \u0005xn\u0006x\u0001tn\u0002\u0007 via the following mea-\nsurement equation:\ny\u0001t\u0002 = g\u0001x\bb\u0002 + \tM\u02c6 \u0002\u0001t\u0002 . \u00012\u0002\nHere X\u02c6 is an M\u0002L measurement matrix, \u0001\u0001t\u0002 and \u0002\u0001t\u0002 are L-\nand M-dimensional Gaussian white noises, and D\u02c6 and M\u02c6 are\n\u0001L\u0002L\u0002- and \u0001M\u0002M\u0002-dimensional dynamical and measure-\nment diffusion matrices, respectively.\nThe problem is essentially stochastic and nonlinear and its\nsolution is given by the so-called posterior density\n\u0003post\u0001M \bY\u0002 of the unknown parameters M conditioned on\nobservations. The latter can be calculated in general form via\nBayes\u2019 theorem,\n\u0003post\u0001M\bY\u0002 =\n\u0001\u0001Y\bM\u0002\u0003prior\u0001M\u0002\n\n \u0001 \u0001Y\bM\u0002\u0003prior\u0001M\u0002dM\n. \u00013\u0002\nHere the prior density \u0003prior\u0001M\u0002 accumulates expert knowl-\nedge of the unknown parameters and the likelihood function\n\u0001\u0001Y \bM\u0002 is the probability density to observe \u0005yn\u0001t\u0002\u0007 given\nchoice M of the dynamical model. Thus within the Bayesian\nframework, the problem is reduced to the calculation of the\nlikelihood function and optimization of the posterior distri-\nbution with respect to M. If the sampling is dense enough,\nthe problem can be conveniently solved using Euler mid-\npoint discretization of Eqs. \u00011\u0002 and \u00012\u0002 in the form\nxn+1 = xn + hf\u0001xn\n*\bc\u0002 + h\tD\u02c6 \u0002n,\nyn = g\u0001xn\bb\u0002 + \tM\u02c6 \u0002n, \u00014\u0002\nwhere x\nn\n*\n= \u0001xn+1+xn\u0002 \/2. It was shown earlier \u0001see, e.g.,\n\u000315,30\u0004\u0002 that for independent sources of white Gaussian\nnoise in Eq. \u00014\u0002, the probability to observe yn+1 at each time\nstep can be factorized and written in the form\n\u0003\u0001yn+1\bxn,c\u0002 =\n 1\t\u00012\u0004\u0002M\bM\u02c6 \bexp\u000b\u2212\n1\n2\n\u0003yn+1 \u2212 g\u0001xn+1\bb\u0002\u0004T\n\u0002M\u02c6 \u22121\u0003yn+1 \u2212 g\u0001xn+1\bb\u0002\u0004\f\n\u0002\n1\n\t\u00012\u0004h\u0002L\bD\u02c6 \b\nexp\u000b\u2212 h2 \u0003x\u02d9n \u2212 f\u0001xn*\bc\u0002\u0004T\n\u0002D\u02c6 \u22121\u0003x\u02d9n \u2212 f\u0001xn\n*\bc\u0002\u0004 \u2212\nh\n2\n\u0001 \u00b7 \u0003f\u0001xn\u0002\bc\u0004\fdxn+1.\n\u00015\u0002\nSummation over all the discretization points n=0, . . . ,N\u22121\nyields the following result for the minus log-likelihood func-\ntion S=Sdyn+Smeas=\u2212ln\u0001 \u0001Y \bM\u0002:\nS =\nN\n2\nln\bD\u02c6 \b +\nh\n2 \rn=0\nN\u22121\n\u0005\u0001 \u00b7 \u0003f\u0001xn\u0002\bc\u0004\n+ \u0003x\u02d9n \u2212 f\u0001xn\n*\bc\u0002\u0004TD\u02c6 \u22121\u0003x\u02d9n \u2212 f\u0001xn\n*\bc\u0002\u0004\u0007 + N2 ln\bM\u02c6 \b\n+\n1\n2\rn=1\nN\n\u0003yn \u2212 g\u0001yn,xn\bb\u0002\u0004TM\u02c6 \u22121\u0003yn \u2212 g\u0001yn,xn\bb\u0002\u0004\n+ \u0001L + M\u0002N ln\u00012\u0004h\u0002 , \u00016\u0002\nwhere x\u02d9n=\nxn+1\u2212xn\nh . Here Sdyn and Smeas are the dynamical \u0001first\ntwo terms\u0002 and measurement \u0001next two terms\u0002 parts of the\nminus log-likelihood function. We note that Sdyn is the minus\nlog-probability density in the space of dynamical paths and,\nin the limit of N\u2192\u0005, h\u21920, T=Nh= const, it coincides with\nthe path-integral presentation obtained earlier in \u000331\u0004.\nEquations \u00011\u0002\u2013\u00013\u0002 and \u00016\u0002 provide a general Bayesian\nframework for learning the state and the model of the system\n\u00011\u0002 as well as for learning the parameters of the measurement\nmodel \u00012\u0002 and for tracking the variation of the parameters of\nthe system in time. It can readily be extended to encompass\ninertial measurement described by the following model:\ny\u02d9 = g\u0001y,x\bb\u0002 + \tM\u02c6 \u0002\u0001t\u0002 .\nIn the latter case, Smeas has a form that is similar to Sdyn, as\nwill be described in more detail elsewhere \u0001see also \u000332\u0004\u0002.\nTo find the general solution of the problem \u00011\u0002 and \u00012\u0002,\none can iterate optimization of S in the space of dynamical\npaths \u0005xn\u0007 and in the space of parameters \u0005c ,b ,D\u02c6 ,M\u02c6 \u0007 \u0001see\n\u000330\u0004\u0002.\nLet us assume that the optimal paths corresponding to the\nhidden dynamical variables \u0005xn\u0007 are found on the current step\nof iterations \u0001see, for example, Sec. III\u0002. At the next step of\niterations, the values of the model parameters \u0005c ,b ,D\u02c6 ,M\u02c6 \u0007\ncan be updated using the following equations \u0001cf. with \u000315\u0004\u0002:\nf\u0001x\bc\u0002 = F\u02c6 \u0001x\u0002c, g\u0001y,x\bb\u0002 = G\u02c6 \u0001y,x\u0002b , \u00017\u0002\nwhere matrices F\u02c6 and G\u02c6 have the form\nLUCHINSKY et al. PHYSICAL REVIEW E 77, 061105 \u00012008\u0002\n061105-2\nF\u02c6 = \u000e\u000f\u00061 . . . 0] \u0001 ]0 . . . \u00061\u0010 . . . \u000f\n\u0006F . . . 0\n] \u0001 ]\n0 . . . \u0006F\n\u0010\u0011 , \u00018\u0002\nG\u02c6 = \u000e\u000f\u00071 . . . 0] \u0001 ]0 . . . \u00071\u0010 . . . \u000f\n\u0007G . . . 0\n] \u0001 ]\n0 . . . \u0007G\n\u0010\u0011 , \u00019\u0002\nand \u0005\u0006i\u0007 and \u0005\u0007i\u0007 are the F- and G-dimensional sets of arbi-\ntrary base functions.\nChoosing prior PDFs for c and b in the form of Gaussian\ndistributions, and uniform prior PDFs for D\u02c6 and M\u02c6 , the fol-\nlowing equations can be obtained to update model param-\neters \u0001cf. with \u000315\u0004\u0002:\n\u0012D\u02c6 \u0013 =\nh\nN \rn=0\nN\u22121\n\u0001x\u02d9n \u2212 F\u02c6 nc\u0002\u0001x\u02d9n \u2212 F\u02c6 nc\u0002T, \u000110\u0002\n\u0012c\u0013 =\u0003\u02c6 X\n\u22121\u0001D\u02c6 \u0002wX\u0001D\u02c6 \u0002 , \u000111\u0002\nwX\u0001D\u02c6 \u0002 = h\r\nn=0\nN\u22121 \u000bF\u02c6 nTD\u22121x\u02d9n \u2212 v\u0001xn\u00022 \f , \u000112\u0002\n\u0003\u02c6 X\u0001D\u02c6 \u0002 = h\r\nn=0\nN\u22121\nF\u02c6 n\nTD\u02c6 \u22121F\u02c6 n, \u000113\u0002\nwhere F\u02c6 n\u0006F\u02c6 \u0001xn\u0002, and the components of the vector v\u0001x\u0002 are\nvm\u0001x\u0002 = \r\nl=1\nL\n\u0002Flm\u0001x\u0002\n\u0002xl\n, m = 1, . . . ,F . \u000114\u0002\nThe parameters of the measurement model can be estimated\nusing the conditions \u0002Smeas\u0002b =0 and\n\u0002Smeas\n\u0002Mnm\n=0, recovering the\nleast-square results in the form\n\u0012M\u02c6 \u0013 =\n1\nN\rn=1\nN\n\u0003yn \u2212 G\u02c6 nb\u0004\u0003yn \u2212 G\u02c6 nb\u0004T, \u000115\u0002\n\u0012b\u0013 =\u0004\u02c6 X,Y\n\u22121 \u0001M\u02c6 \u0002zX,Y\u0001M\u02c6 \u0002 , \u000116\u0002\nzX,Y\u0001M\u02c6 \u0002 = \r\nn=1\nN\n\u0003G\u02c6 nTM\u02c6 \u22121yn\u0004 , \u000117\u0002\n\u0004\u02c6 X,Y\n\u22121 \u0001M\u02c6 \u0002 = \r\nn=0\nN\u22121\nG\u02c6 nTM\u02c6 \u22121G\u02c6 n, \u000118\u0002\nwhere G\u02c6 n\u0006G\u02c6 \u0001yn ,xn\u0002.\nEquations \u000110\u0002\u2013\u000118\u0002, coupled with the optimization pro-\ncedure in the paths\u2019 space, represent the general Bayesian\nframework for learning a nonlinear stochastic dynamical sys-\ntem from measurements that are corrupted by noise. Using\nthis approach, we can develop a method of fast on-line track-\ning of the time-varying parameters of nonstationary systems,\nas described below.\nB. The main idea of the inferential framework\nfor nonstationary dynamics\nThe main idea of the method is to apply Eqs. \u000110\u0002\u2013\u000118\u0002\nwithin a window moving along the time trace of the experi-\nmental data, resulting in time-resolved inference of the\nmodel parameters. The time resolution of the method is lim-\nited by the convergence of the model parameters, but can be\nimproved substantially if we note that only a few parameters\nof the system have to be followed in time continuously,\nwhile the rest of the model parameters can be learned effi-\nciently from a block of stationary data from the time series.\nIndeed, in many practical applications, the majority of the\nsystem parameters remain constant and only a few control\nparameters vary in time. To achieve the best time resolution,\nwe introduce a two-step procedure, in which the tracking of\ntime-varying parameters is embedded into a Bayesian learn-\ning framework. As the first step, we select an interval of the\nexperimental time traces during which the system dynamics\nis stationary and learn model parameters. In the second step,\nwe assume that the majority of the parameters of the system\nremain constant and track only a few time-varying control\nparameters.\nTo clarify this idea, one has to take into account various\ncharacteristic time scales of the problem. The measured time\nseries are characterized by the sampling time step h and the\ntotal measurement time Tmeas=nh, where n is the number of\nmeasured points. The system dynamics has an intrinsic char-\nacteristic time scale \b0 and characteristic time scales of slow\n\bslow and fast \bfast variation of the model parameters. For the\nFitzHugh-Nagumo model, \b0 can be taken as equal to the\nwidth of the spike. The time resolution of the method is\ncharacterized by the convergence time of the inference\n\bres\u0001c\u0002. Note that \bres\u0001c\u0002 depends on the set of unknown\nmodel parameters.\nFor the method to be applicable, the characteristic time\nscale for slow variation of the model parameters has to be\nlarger than measurement time, \bslow\tTmeas. In this adiabatic\napproximation, slowly varying parameters can be assumed\nconstant. In the first step, it is further assumed that there\nexists a time trace of length T\t\bres\u0001c\u0002 where all the param-\neters of the system can be considered to remain constant.\nEquations \u000110\u0002\u2013\u000118\u0002 can then be used to learn the slowly\nvarying parameters of the model together with parameters of\nthe measurement model b. These parameters, once inferred,\nare considered to be constant and known. In the second step,\nthe set of model parameters is divided into known c\u0001k\u0002 and\nunknown c\u0001u\u0002 subsets. To infer fast-varying control param-\neters, one can use Eqs. \u000110\u0002\u2013\u000113\u0002 substituting x\u02d9 with \u0001x\u02d9\n\u2212F\u02c6 nc\u0001k\u0002\u0002 and F\u02c6 nc with F\u02c6 nc\u0001u\u0002. The possibility of fast on-line\ntracking of the control parameters arises in this approach due\nto the fact that \bres\u0001c\u0001u\u0002\u0002 can be made much shorter than\n\bres\u0001c\u0002.\nIn the context of the present research, we are interested\nmainly in the on-line tracking of the parameters of the physi-\nological signals that can be modeled as a system of a set of\nFitzHugh-Nagumo oscillators mixed by a measurement ma-\ntrix. In the following sections, we will introduce a specific\nexample of a system that can be used to model physiological\nmeasurements. Our primary goal will be to establish whether\nINFERENTIAL FRAMEWORK \u2026 . I. THEORY PHYSICAL REVIEW E 77, 061105 \u00012008\u0002\n061105-3\nthe convergence of the model parameters is sufficiently fast\nto allow for the on-line tracking \u0001decoding physiological in-\nformation in real time\u0002 of the control parameters of the\nmodel. This will be demonstrated in paper II \u000317\u0004.\nNext, we provide further arguments related to the conver-\ngence of the algorithm. We start by assuming that there is no\nmeasurement noise, so that we can avoid the need for opti-\nmization in the paths\u2019 space. We then provide a brief ex-\nample of the optimization procedure in the paths\u2019 space.\nC. Convergence of the model parameters\nSo let us neglect measurement noise, assuming that time\ntraces of the state variables can be measured directly, that we\nhave K blocks of data, and that we are interested only in the\ninference of the model parameters \u0005c\u0007. Even in this case, the\nconvergence of the model parameters depends essentially on\nthe specific system under consideration. However, a few gen-\neral remarks may be helpful in clarifying the issues to be\naddressed. Note that each block of data can be measured\nindependently and used at the step k+1 of inference \u0001k\n=1, . . . ,K\u0002 provided that the results at previous steps are\ntaken into account in the form of a prior distribution\npk\u0001\u0005c\u0007\u0002 \n exp\u0014\u2212 12 \u0001c \u2212 ck\u0002T\u0003\u02c6 k\u0001c \u2212 ck\u0002\u0015 . \u000119\u0002\nEquations \u000112\u0002 and \u000113\u0002 can be then written in the form \u0001see\n\u000315\u0004\u0002\nwk =\u0003\n\u02c6\nk\u22121\n\u22121 ck\u22121 + h \r\nn\u0001Nk\n\u000bF\u02c6 nTD\u02c6 \u22121x\u02d9n \u2212 vn2 \f , \u000120\u0002\n\u0003\u02c6 k =\u0003\n\u02c6\nk\u22121 + h \r\nn\u0001Nk\nF\u02c6 n\nTD\u02c6 \u22121F\u02c6 n. \u000121\u0002\nIt is clear that the covariance matrix of the posterior distri-\nbution is a sum over all the blocks and has the structure of a\nKronecker product,\n\u0003\u02c6 k =\u0005\n\u02c6 \u0001 Q\u02c6 , \u000122\u0002\nwhere\n\u0005\u02c6 = \r\nn\u0001N1,. . .,Nk \u000f\n\u00071,n\u00071,n . . . \u00071,n\u0007B,n\n] \u0001 ]\n\u0007B,n\u00071,n . . . \u0007B,n\u0007B,n\n\u0010 ,\n\u0007i,n\u0006\u0007i\u0001xn\u0002, and Q\u02c6 =D\u02c6 \u22121. Accordingly, all nonzero elements\nof this matrix grow in time as T=hN. On the other hand, the\nsecond term in Eq. \u000121\u0002 remains finite for a fixed number of\npoints in one block Nk. Therefore, \u0003\u02c6 k\u22121 approaches \u0003\u02c6 k for\nlarge T and ck becomes\nck \u0016 ck\u22121 + D\u02c6 \u0001 \u0005\u02c6 k\n\u22121 \r\nn\u0001Nk\n\u000bF\u02c6 nTD\u02c6 \u22121x\u02d9n \u2212 vn2 \f . \u000123\u0002\nThe convergence of ck is thus determined by the convergence\nof residuals in Eq. \u000123\u0002. Clearly, convergence of the residuals\nis proportional to the sum of eigenvalues of \u0005\u02c6 k\n\u22121: the pres-\nence of large eigenvalues slows down the convergence of all\ncoefficients \u0005ck\u0007.\nAt the same time, base functions related to the control\nparameters have a strong effect on the dynamics of the sys-\ntem and usually correspond to large eigenvalues of \u0005\u02c6 . There-\nfore, to achieve the best results in decoding nonstationary\ndynamics, one can use the general dynamical inference\nframework introduced above to learn most of the stationary\nmodel parameters in a preliminary analysis of the system.\nNext, by incorporating real-time inference into this inferen-\ntial learning framework and excluding all but the most im-\nportant nonstationary parameters from the tracking proce-\ndure, one can improve the time resolution of the method by\norders of magnitude.\nWe note that to exclude the learned model parameters\nfrom further analysis, one has to separate the vector field into\ntwo parts f\u0001x \bc\u0002= f\u0001\u0001x \bcknown\u0002+ f\u0002\u0001x \bcunknown\u0002 and to use \u0003x\u02d9\n\u2212 f\u0001\u0001x \bcknown\u0002\u0004 and f\u0002\u0001x \bcunknown\u0002 instead of x\u02d9 and f\u0001x \bc\u0002, re-\nspectively, in Eqs. \u000110\u0002 and \u000112\u0002. With this trivial modifica-\ntion, the method will allow for fast on-line tracking of the\nparameters of nonstationary nonlinear dynamical systems.\nIn the context of physiological applications, polynomial\nbase functions and relatively small noise intensities are of\nspecial interest. It is clear that in this case the smallest ele-\nments of \u0005\u02c6 correspond to the highest powers of polynomials.\nIn particular, in the case of a symmetric one-dimensional\n\u00011D\u0002 potential, the contribution of the polynomials of order\nm to the diagonal terms of \u0005\u02c6 will be proportional to \u0012xm\u0013\n\nDm. Accordingly, if the coefficients of the polynomials of\npower 3 can be learned before applying the on-line tracking\nprocedure, the time resolution of the method can ideally be\nimproved by three orders of magnitude for typical values of\nD\u00160.1. This effect will be demonstrated in paper II \u000317\u0004\nusing as an example a system of mixed FHN oscillators. In\nthe next section, we provide a brief example of the global\noptimization procedure, including optimization in the trajec-\ntory space, that can be used to learn model parameters in a\ngeneral case before applying time-resolved methods.\nIII. GLOBAL NONLINEAR OPTIMIZATION IN THE\nSPACE OF DYNAMICAL TRAJECTORIES\nA global optimization of the cost function in the space of\nthe model trajectories of nonlinear stochastic dynamical sys-\ntems is a long-standing problem in the theory of stochastic\nprocesses. A number of methods have been suggested earlier\nto solve this problem, including methods based on the Mar-\nkov chain Monte Carlo \u0001MCMC\u0002 \u000333\u0004, the extended Kalman\nfilter \u000310\u0004, and the Langevin method of sampling the poste-\nrior \u000332\u0004. In our earlier work, we generalized an extended\nKalman filter approach \u000330\u0004 and the MCMC \u000334\u0004 to sample\nthe paths of continuous nonlinear stochastic systems. Here\nwe will describe briefly a method based on global nonlinear\noptimization utilizing an explicit analytic form of the gradi-\nent and the Hessian of the cost function and the conjugate-\ngradient method \u0001see also \u000335\u0004\u0002.\nIndeed, let us consider the case in which g\u0001yn ,xn \bb\u0002\n=\u0006\u02c6 xn. In this case, the Hessian H\u02c6 of S takes the form\nLUCHINSKY et al. PHYSICAL REVIEW E 77, 061105 \u00012008\u0002\n061105-4\nH\u02c6 =\u000f\nB\u02c6 00 B\u02c6 01 0\u02c6 . . . 0\u02c6 0\u02c6\nB\u02c6 10 B\u02c6 11 B\u02c6 12 . . . 0\u02c6 0\u02c6\n\u00af \u00af \u00af \u00af \u00af \u00af\n0\u02c6 0\u02c6 0\u02c6 \u00af B\u02c6 n\u22121,n B\u02c6 nn\n\u0010 , \u000124\u0002\nwhere matrices B\u02c6 nm are given by the following expression:\nB\u02c6 nm =\n\u0002S\n\u0002xn \u0002 xm\n= \u0006\u02c6 TM\u02c6 \u22121\u0006\u02c6 \u000bnm +\nh\n2\n\u0002\n\u0002xn \u0002 xm\n\u0003tr\u0005\u02c6 \u0001xn\bc\u0002\u0004\u000bnm\n+\n1\nh\nD\u02c6 \u22121\u000bnm + h\u000bI\u02c6\/h + \u0002f\u0002xn\f\nT\nD\u02c6 \u22121\u000bI\u02c6\/h + \u0002f\n\u0002xn\n\f\u000bnm\n\u2212 h\u0003x\u02d9n \u2212 f\u0001xn\n*\bc\u0002\u0004TD\u02c6 \u22121\u0014 \u00022f\n\u0002xn\n2\u0015\u000bnm\n\u2212 h\u000bI\u02c6\/h + \u0002f\n\u0002xn\u22121\n\fTD\u02c6 \u22121\u000bm,n\u22121\n\u2212 hD\u02c6 \u22121\u000bI\u02c6\/h + \u0002f\n\u0002xn\n\f\u000bm,n+1 \u000125\u0002\nand the gradient \u0002S\u0002xn of S has the form\n\u0002S\n\u0002xn\n= \u2212 \u0001yn \u2212 \u0006\u02c6 xn\u0002TM\u02c6 \u22121\u0006\u02c6 \u0002 xn\n+\nh\n2\n\u0002\n\u0002xn\n\u0005\u0001 \u00b7 \u0003f\u0001xn\u0002\bc\u0004\u0007 + \u0003x\u02d9n\u22121 \u2212 f\u0001xn\u22121\n* \bc\u0002\u0004TD\u02c6 \u22121\n\u2212 \u0003x\u02d9n \u2212 f\u0001xn\n*\bc\u0002\u0004TD\u02c6 \u22121\u000bI\u02c6 + h\u0002f\u0001xn*\bc\u0002\n\u0002xn\n\f . \u000126\u0002\nGiven the form of the gradient \u0002S\u0002xn and of the Hessian H\n\u02c6\n,\nglobal optimization in the paths\u2019 space can be performed\nespecially efficiently.\nGiven a set of noisy observations Y, we first minimize S\nwith respect to X keeping the model parameters fixed. Ac-\ncording to the standard conjugate gradient procedure \u000336\u0004,\nwe do the following steps:\n\u0001i\u0002 Choose initial values for the state vector X0 and choose\ninitial directions d0=\u2212\u0001S\u0001X0\u0002.\n\u0001ii\u0002 Update values of the coordinates using X1=X0+\fd0,\nwhere\n\f = \u2212 \u0003d0\nT \u0001 S\u0001X0\u0002\u0004\/\u0003d0TH\u02c6 \u0001X0\u0002d0\u0004 .\n\u0001iii\u0002 Update direction, using\nd1 = \u2212 \u0001S\u0001X1\u0002 +\n\b\u0001S\u0001X1\u0002\b2\n\b\u0001S\u0001X0\u0002\b2\nd0.\nOnce the conjugate gradient algorithm has converged to\nsome global minimum X in the space of dynamical trajecto-\nries, we use this trajectory to infer model parameters by ap-\nplying Eqs. \u000110\u0002\u2013\u000113\u0002.\nConsider as an example a nonlinear system with a stable\nlimit cycle in the form\nx\u02d91 = x2 \u2212 x1\n2x2 + \r1\u0001t\u0002 ,\nx\u02d92 = \u2212 x1 + 0.1\u00011 \u2212 x1\n2\u0002x2 + \r2\u0001t\u0002 . \u000127\u0002\nThe state of the dynamical system is unknown. We assume\nfor simplicity that both coordinates were measured with\nmeasurement noise of amplitude 0.4 in both coordinates, i.e.,\nyi\u0001t\u0002 = xi\u0001t\u0002 + 0.4\u000ei\u0001t\u0002, i = 1,2.\nHere the measurement matrix has the form \u0006\u02c6 =I\u02c6 and the\nmeasurement noise matrix has the form M\u02c6 =0.16I\u02c6.\nWe further assume that the vector field of Eq. \u000127\u0002 is\nunknown and model it using the following set of eight\nknown base functions:\n\u000f = \u00051;x1;x2;x1\n2;x2\n2;x1x2;x1\n3;x1\n2x2\u0007 .\nIn explicit form, the model of the limit cycle system \u000127\u0002 is\nx\u02d91 = \r\ni=1\n8\nc2i\u22121\u0006i + \r1\u0001t\u0002, x\u02d92 = \r\ni=1\n8\nc2i\u0006i + \r2\u0001t\u0002 . \u000128\u0002\nWe now apply the algorithm described in the previous\nsection to infer both the unknown state and the vector field of\nthis system. An example of noise-corrupted measurements of\nthe system \u000127\u0002 is shown in Fig. 1\u0001a\u0002. Our technique allows\nrecovery of the stochastic dynamics of the system \u000127\u0002 as\nshown in Fig. 1\u0001b\u0002 and to estimate model parameters. The\nresults of the estimations are shown in Table I. It is evident\nthat the optimization in the paths\u2019 space can be performed\n-2\n0\n2\n-4 -2 0 2 4\ny\nx\n(a)\n-1\n0\n1\n-3 -2 -1 0 1 2 3\ny\nx\n(b)\nFIG. 1. \u0001a\u0002 Example of corrupted-by-noise measurements \u000127\u0002\nwith intensity of dynamical noise \u0012\rx\n2\u0001t\u0002\u0013=0.1 and \u0012\ry\n2\u0001t\u0002\u0013=0.2 and\nthe amplitude of measurement noise 0.4 in both coordinates. \u0001b\u0002\nRecovered stochastic dynamics of the system \u000127\u0002 \u0001dotted line\u0002 is\nshown in comparison with the actual dynamical trajectory \u0001solid\nline\u0002.\nINFERENTIAL FRAMEWORK \u2026 . I. THEORY PHYSICAL REVIEW E 77, 061105 \u00012008\u0002\n061105-5\nefficiently in the presence of measurement noise. In practice,\nhowever, the conjugate gradient algorithm requires about 20\nsteps for convergence. The complexity of such an algorithm\n\u0001calculated as a number of matrix operations\u0002 is much higher\nthat the complexity of the calculations of the model param-\neters using Eqs. \u000110\u0002\u2013\u000113\u0002. Accordingly, for the fast on-line\napplications of the algorithm one should avoid global opti-\nmization in the space of dynamical trajectories by, e.g., sup-\npressing measurement noise.\nThe main focus in the remaining part of the research will\nbe the development of the fast on-line tracking method for\nthe time-varying parameters. For the sake of simplicity of\nour further arguments, we therefore assume that measure-\nment noise can be neglected. In the next section, we will\nintroduce a specific example of a model that can be applied\nfor the interpretation of physiological time-series data using\nour Bayesian inferential framework.\nIV. SYSTEM OF FITZHUGH-NAGUMO OSCILLATORS\nIn the context of physiological applications, we consider\nthe following dynamical model \u0001see \u000317\u0004 for details of the\nnumerical analysis of this model\u0002:\nx\u02d9 = f\u0001x\bc\u0002 \u2212 q + \tD\u02c6 \u0001\u0001t\u0002, x = \u0001x1, . . . ,xL\u0002 , \u000129\u0002\nq\u02d9 = \u2212 \u0010q + \u0011x , \u000130\u0002\nrepresenting a set of independent FitzHugh-Nagumo sys-\ntems. The measurements are modeled by the following equa-\ntion:\ny = X\u02c6 x . \u000131\u0002\nNote that the q coordinates are \u201chidden\u201d or unobservable,\nwhile the x coordinates are accessible for measurement and\nare mixed by the measurement matrix X\u02c6 .\nThe main assumptions of the model \u000129\u0002\u2013\u000131\u0002 are that the\nmeasurement noise can be neglected together with the noise\nin Eq. \u000130\u0002. Under these assumptions, sampling in the paths\u2019\nspace can be avoided, thus paving the way to the fast on-line\ndecoding of physiological information. Indeed, in this case\nEq. \u000130\u0002 can be integrated,\nq\u0001t\u0002 = \u0011\n\n0\nt\nd\be\u2212\u0010\u0001t\u2212\b\u0002x\u0001\b\u0002 + e\u2212\u0010tq\u00010\u0002 . \u000132\u0002\nHere q\u00010\u0002 is a set of initial coordinates that needs to be\ninferred along with the rest of the parameters. Therefore, the\nunobservable variables can be excluded from further consid-\neration. According to the trapezoidal rule, the discrete ver-\nsion of Eq. \u000132\u0002 is\nq\u0001tk\u0002 = \u0011h\r\nr=0\nk\ne\u2212\u0010\u0001tk\u2212tr\u0002x\u0001tr\u0002 \u2212\nh\u0011\n2\n\u201ex\u0001tk\u0002 + e\u2212\u0010tkx\u0001t0\u0002\u2026\n+ e\u2212\u0010tkq\u00010\u0002 . \u000133\u0002\nThe resulting model and its discretization have the follow-\ning form:\nxk+1 = hf\u0001xk\n*\bc\u0002 \u2212 \u0011h2\r\nr=0\nk\ne\u2212\u0010\u0001tk\u2212tr\u0002x\u0001tr\u0002\n+\nh2\u0011\n2\n\u0003x\u0001tk\u0002 + e\u2212\u0010tkx\u0001t0\u0002\u0004\n\u2212 he\u2212\u0010tkq\u00010\u0002 + \u0007k + O\u0001h2\u0002 , \u000134\u0002\nwhere \u0007k=\u0017tk\ntk+1dt\u0001\u0001\u0001t\u0001\u0002 and xk\n*\u0006\nxk+1+xk\n2 .\nThe FHN oscillator is a special case of the dynamics in\nEqs. \u000129\u0002 and \u000130\u0002. It will be the subject of our numerical\nexperiments,\nv\u02d9 j = \u2212 v j\u0001v j \u2212 \f j\u0002\u0001v j \u2212 1\u0002 \u2212 qj + \u0012 j + dj\r j ,\nq\u02d9j = \u2212 \u0010qj + \u0011 jv j ,\n\u0012\r j\u0001t\u0002\ri\u0001t\u0001\u0002\u0013 = \u000bijdi\u000b\u0001t \u2212 t\u0001\u0002, j = 1:L . \u000135\u0002\nThe system described in Eq. \u000135\u0002 represents the simplified\ndynamic of L noninteracting neurons \u000321\u0004, each of them la-\nbeled with j; v j represents the membrane potential while qj\nare slow recovery variables.\nIn practice, signals that are collected from biological sys-\ntems are mixed with a measurement matrix; to tackle this\nproblem, we assume that the measurement variable is yi,\nwhich is a linear transformation of v j,\nyi = Xijv j . \u000136\u0002\nHere the mixing matrix X is an unknown quantity, therefore\nyi contains all the accessible information. In Fig. 2, there is\nan example of yi as in Eq. \u000136\u0002.\nTo write explicitly the system to be inferred, expressions\nof qi from Eq. \u000133\u0002 and of vi in Eq. \u000135\u0002 are plugged into Eq.\n\u000136\u0002. Within our inferential framework, this trajectory repre-\nsents the output of the following model:\ny\u02d9i = Aijyj + Bijlyjyl + Cijlmyjylym + \u0012\u02dci\n\u2212 h\r\nr=0\nk\ne\u2212\u0010\u0001tk\u2212tr\u0002\u0013ilyl\u0001tr\u0002 \u2212 \r\nr=0\nk\ne\u2212\u0010tkz\u02dci + Dij\r j + \u0001t\u0002 ,\n\u000137\u0002\nwhere z\u02dci are the components of the boundary condition q\u0001t\nTABLE I. Convergence of some coefficients of the system \u000128\u0002.\nWe have used one block of data with 40 000 points.\nCoefficients True values Inferred values Updated values\nc3 1 1.46 1.08\nc4 0 \u221242.64 0.02\nc10 \u22121 \u221210.93 \u22121.07\nc11 0.1 \u221235.68 0.258\nc15 0 1.82 0.005\nc16 \u22120.1 \u221227.96 \u22120.17\nD11 0.04 325 0.045\nD12 0 6 0.006\nD22 0.04 318 0.03\nLUCHINSKY et al. PHYSICAL REVIEW E 77, 061105 \u00012008\u0002\n061105-6\n=0\u0002, and use of the following definitions was made:\nAij = Xim\fm\u0001X\u22121\u0002mj ,\nBijl = Xim\u00011 + \fm\u0002\u0001X\u22121\u0002mj\u0001X\u22121\u0002ml,\nCjklm = Xji\u0001X\u22121\u0002ik\u0001X\u22121\u0002il\u0001X\u22121\u0002im,\n\u0013il = Xij\u0011 j\u0001X\u22121\u0002 jl. \u000138\u0002\nIn Eqs. \u000138\u0002, a sum over repeated indices is implied and all\nthe indices range from 1 to L. Also, the diffusion matrix Dij\nis expressed in terms of dj as\nDji = Xjidi. \u000139\u0002\nFinally, Eqs. \u000138\u0002 contain the crucial model parameters \u0012\u02dc j\nthat are the focus of our inference. They are related to the\noriginal model parameters \u0012 j by\n\u0012\u02dc j = Xji\u0012i. \u000140\u0002\nWe treat yj\u0001t\u0002 in Eqs. \u000138\u0002 as measured variables. As a result\nof the inference procedure, we will recover the matrix ele-\nments of A ,B ,C ,\u0013 ,D , \u0012\u02dc.\nThe parameters of the modified and original dynamical\nmodels can be learned effectively using stationary blocks of\nthe time-series data, as will be shown using numerical ex-\namples in paper II \u000317\u0004. Once the constant parameters of the\nmodel have been learned, the algorithm will allow for very\nfast on-line tracking of the time-varying control parameters.\nDetails of the convergence of the model parameters and of\nthe time resolution of the parameter tracking will be pro-\nvided in paper II, using as an example synthetic time-series\ndata generated by the model \u000129\u0002\u2013\u000131\u0002.\nV. CONCLUSION\nOur Bayesian framework for the time-resolved inference\nof a nonstationary stochastic dynamical system allows for\nlearning the parameters of the dynamical and measurement\nmodels from noise-corrupted time-series data with subse-\nquent fast tracking of time-varying control parameters. Con-\nvergence of the method in the parameter space, and global\noptimization in the space of dynamical trajectories, are dis-\ncussed. It is shown that to achieve the best time resolution,\none has to embed the time tracking of nonstationary dynam-\nics into an inferential learning framework that allows for\npreliminary inference of the model parameters in the station-\nary regime. Furthermore, one has to reduce the measurement\nnoise to a low level to avoid global optimization in the tra-\njectory space, which is necessarily time-consuming. In doing\nso, one can improve the time resolution of the method by\nseveral orders of magnitude. To apply this technique to the\nreal time decoding of information from nonstationary physi-\nological time-series data, we introduce a specific model of\nFHN oscillators mixed by an unknown measurement matrix.\nNext we show how this model can be reduced to allow for\nthe fast on-line tracking of nonstationary parameters in a\nBayesian inferential framework. A numerical investigation of\nthis system is presented and discussed in paper II \u000317\u0004.\nNote that for simplicity of the analysis, we have excluded\ndynamical noise from the equation for the recovery variable\nin Eq. \u000130\u0002 \u0001cf., e.g., \u000323\u0004\u0002. It is possible, however, to extend\nthe proposed method to encompass the case of a stochastic\nlinear differential equation for the hidden dynamical variable\nby adding a stochastic integral to the right-hand side of the\nreduced model \u000134\u0002. The corresponding extension of the\nmethod will be discussed in more detail elsewhere.\nFinally, we emphasize the broad interdisciplinary applica-\ntions of the method and we comment that it can readily be\nextended to take into account the effects of multiplicative\nand colored noise and of binary variables in the model.\nACKNOWLEDGMENTS\nWe are grateful to the Engineering and Physical Sciences\nResearch Council \u0001UK\u0002 and NASA for financial support, and\nto A. Stefanovska for valuable discussions.\n\u00031\u0004 H. Konno and K. Hayashi, Ann. Nucl. Energy 23, 35 \u00011996\u0002.\n\u00032\u0004 J. Christensen-Dalsgaard, Rev. Mod. Phys. 74, 1073 \u00012002\u0002.\n\u00033\u0004 V. N. Smelyanskiy, D. G. Luchinsky, A. Stefanovska, and P. V.\nE. McClintock, Phys. Rev. Lett. 94, 098101 \u00012005\u0002.\n\u00034\u0004 E. Izhikevich, Dynamical Systems in Neuroscience: The Ge-\nometry of Excitability and Bursting \u0001MIT Press, Cambridge,\nMA, 2006\u0002.\n\u00035\u0004 S. Siegert, R. Friedrich, and J. Peinke, Phys. Lett. A 243, 275\n\u00011998\u0002.\n\u00036\u0004 P. E. McSharry and L. A. Smith, Phys. Rev. Lett. 83, 4285\n\u00011999\u0002.\n\u00037\u0004 R. Friedrich et al., Phys. Lett. A 271, 217 \u00012000\u0002.\n\u00038\u0004 J. P. M. Heald and J. Stark, Phys. Rev. Lett. 84, 2366 \u00012000\u0002.\n\u00039\u0004 R. Meyer and N. Christensen, Phys. Rev. E 62, 3535 \u00012000\u0002.\n\u000310\u0004 R. Meyer and N. Christensen, Phys. Rev. E 65, 016206\n\u00012001\u0002.\n\u000311\u0004 J.-M. Fullana and M. Rossi, Phys. Rev. E 65, 031107 \u00012002\u0002.\n\u000312\u0004 M. Siefert, A. Kittel, R. Friedrich, and J. Peinke, Europhys.\n0\n1\n2\n3\n4\n0 4 8\nt (ms)\nV1\nFIG. 2. \u0001Color online\u0002 Example of a typical component y\u0001t\u0002\nfrom Eq. \u000136\u0002 with mixing matrix \u0001 12\n2\n1 \u0002. Values of the parameters are\n\f1=\f2=0.2, \u00121=\u00122=0.112, \u0010=0.005 105 1, \u00111=\u00112=0.0051, d1\n=0.001, and d2=0.002. Coefficients \u00121 and \u00122 change ranging from\n0.05 to 0.25.\nINFERENTIAL FRAMEWORK \u2026 . I. THEORY PHYSICAL REVIEW E 77, 061105 \u00012008\u0002\n061105-7\nLett. 61, 466 \u00012003\u0002.\n\u000313\u0004 F. Watanabe, H. Konno, and S. Kanemoto, Ann. Nucl. Energy\n31, 375 \u00012004\u0002.\n\u000314\u0004 W. Enders, Applied Econometric Time Series, 2nd ed. \u0001Wiley,\nHoboken, NJ, 2004\u0002.\n\u000315\u0004 V. N. Smelyanskiy, D. G. Luchinsky, D. A. Timucin, and A.\nBandrivskyy, Phys. Rev. E 72, 026202 \u00012005\u0002.\n\u000316\u0004 V. N. Smelyanskiy, D. G. Luchinsky, A. Stefanovska, and P. V.\nE. McClintock, Phys. Rev. Lett. 94, 098101 \u00012005\u0002.\n\u000317\u0004 A. Duggento et al., following paper, Phys. Rev. E 77, 061106\n\u00012008\u0002.\n\u000318\u0004 V. V. Osipov, D. G. Luchinsky, V. N. Smelyanskiy, and D. A.\nTimucin, Proceedings of the AIAA\/ASME\/SAE\/ASEE Joint\nPropulsion Conference and Exhibit, AIAA Conference Pro-\nceedings \u0001AIAA, Cincinnati, OH, 2007\u0002, p. 5823.\n\u000319\u0004 D. G. Luchinsky et al., Proceedings of the AIAA\nInfotech@Aerospace 2007 Conference and Exhibit, AIAA Con-\nference Proceedings \u0001AIAA, Robnert Park, CA, 2007\u0002,\np. 2829.\n\u000320\u0004 R. FitzHugh, Biophys. J. 1, 445 \u00011961\u0002.\n\u000321\u0004 J. Nagumo, S. Animoto, and S. Yoshizawa, Proc. IRE 50, 2061\n\u00011962\u0002.\n\u000322\u0004 A. T. Winfree, The Geometry of Biological Time \u0001Springer-\nVerlag, New York, 1980\u0002.\n\u000323\u0004 E. V. Pankratova, A. V. Polovinkin, and B. Spagnolo, Phys.\nLett. A 344, 45 \u00012005\u0002.\n\u000324\u0004 J. Keener and J. Sneyd, Mathematical Physiology \u0001Springer-\nVerlag, New York, 1998\u0002.\n\u000325\u0004 E. N. Best, Biophys. J. 27, 87 \u00011979\u0002.\n\u000326\u0004 J. Rogers and A. McCulloch, IEEE Trans. Biomed. Eng. 41,\n743 \u00011994\u0002.\n\u000327\u0004 R. R. Aliev and A. V. Panfilov, J. Theor. Biol. 181, 33 \u00011996\u0002.\n\u000328\u0004 P. Chen, SIAM J. Math. Anal. 23, 81 \u00011992\u0002.\n\u000329\u0004 O. Berenfeld and S. Abboud, Med. Eng. Phys. 18, 615 \u00011996\u0002.\n\u000330\u0004 D. G. Luchinsky, V. N. Smelyanskiy, and J. Smith, in Un-\nsolved Problems of Noise and Fluctuations, AIP Conf. Proc.\nNo. 800, edited by L. Reggiani et al. \u0001AIP, Melville, NY,\n2005\u0002, pp. 539\u2013545.\n\u000331\u0004 R. Graham, Z. Phys. B 26, 281 \u00011977\u0002.\n\u000332\u0004 A. Apte, M. Hairer, A. M. Stuart, and J. Voss, Physica D 230,\n50 \u00012007\u0002.\n\u000333\u0004 C. Calder, M. Lavine, P. M\u00fcller, and J. S. Clark, Ecology 84,\n1395 \u00012003\u0002.\n\u000334\u0004 V. N. Smelyanskiy, D. G. Luchinsky, and M. Millonas, e-print\narXiv:physics\/0601004v1.\n\u000335\u0004 D. G. Luchinsky, V. N. Smelyanskiy, M. Millonas, and P. V. E.\nMcClintock, in Noise in Complex Systems and Stochastic Dy-\nnamics III, Vol. 5845 of Proceedings of the Society of Photo-\nOptical Instrumentation Engineers (SPIE), edited by L. B.\nKish, K. Lindenberg, and Z. Gingl \u0001SPIE, Bellingham, WA,\n2005\u0002, pp. 173\u2013181.\n\u000336\u0004 W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vet-\nterling, Numerical Recipes in FORTRAN: The Art of Scientific\nComputing, 2nd ed. \u0001Cambridge University Press, Cambridge,\nUK, 1992\u0002.\nLUCHINSKY et al. PHYSICAL REVIEW E 77, 061105 \u00012008\u0002\n061105-8\n"}
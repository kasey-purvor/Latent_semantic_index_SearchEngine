{"doi":"10.1016\/j.ejor.2011.05.050","coreId":"177348","oai":"oai:aura.abdn.ac.uk:2164\/2151","identifiers":["oai:aura.abdn.ac.uk:2164\/2151","10.1016\/j.ejor.2011.05.050"],"title":"Information Security Trade-offs and Optimal Patching Policies","authors":["Ioannidis, Christos","Pym, David J.","Williams, Julian"],"enrichments":{"references":[{"id":5256,"title":"A decision support system for multi-attribute utility evaluation based on imprecise assignments. Decision Support Systems,","authors":[],"date":"2003","doi":"10.1016\/s0167-9236(02)00137-9","raw":"A. Jimen ez, S. Ros-Insua, and A. Mateos. A decision support system for multi-attribute utility evaluation based on imprecise assignments. Decision Support Systems, 36:65{79, 2003.","cites":null},{"id":5226,"title":"Analysing the performance of security solutions to reduce vulnerability exposure window.","authors":[],"date":"2008","doi":"10.1109\/ACSAC.2008.42","raw":"Y. Beres, J. Grin, S. Shiu, M. Heitman, D. Markle, and P. Ventura. Analysing the performance of security solutions to reduce vulnerability exposure window. In Proceedings of the 2008 Annual Computer Security Applications Conference, pages 33{42. IEEE Computer Society Conference Publishing Services (CPS), 2008.","cites":null},{"id":5228,"title":"Decision support for systems security investment.","authors":[],"date":"2010","doi":"10.1109\/NOMSW.2010.5486590","raw":"Y. Beres, D. Pym, and S. Shiu. Decision support for systems security investment. In Network Operations and Management Symposium Workshops (NOMS Wksps), 2010 IEEE\/IFIP, pages 118{125,","cites":null},{"id":5260,"title":"Decisions with Multiple Objectives: Preferences and Value Trade-offs.","authors":[],"date":"1976","doi":"10.1109\/TSMC.1979.4310245","raw":null,"cites":null},{"id":6018962,"title":"Decisions with Multiple Objectives: Preferences and Value Trade-os.","authors":[],"date":"1976","doi":"10.1109\/tsmc.1979.4310245","raw":"R.L. Keeney and H. Raia. Decisions with Multiple Objectives: Preferences and Value Trade-os. Wiley, 1976.","cites":null},{"id":6018951,"title":"Defending against multiple dierent attackers.","authors":[],"date":"2011","doi":"10.1016\/j.ejor.2010.12.013","raw":"Kjell Hausken and Vicki M. Bier. Defending against multiple dierent attackers. European Journal of Operational Research, 211(2):370 { 384, 2011.","cites":null},{"id":5248,"title":"Defending against multiple different attackers.","authors":[],"date":"2011","doi":"10.1016\/j.ejor.2010.12.013","raw":null,"cites":null},{"id":5235,"title":"Distributed Systems: Concepts and Design.","authors":[],"date":"2005","doi":null,"raw":"G. Coulouris, J. Dollimore, and T. Kindberg. Distributed Systems: Concepts and Design. Addison Wesley, 2005.","cites":null},{"id":5242,"title":"Information security expenditures and real options: A waitand-see approach.","authors":[],"date":"2003","doi":null,"raw":"L. Gordon, M. Loeb, and W. Lucyshyn. Information security expenditures and real options: A waitand-see approach. Computer Security Journal, 19(2):1{7, 2003.","cites":null},{"id":5252,"title":"Investments and trade-offs in the economics of information security.","authors":[],"date":"2009","doi":"10.1016\/j.ejor.2011.05.050","raw":null,"cites":null},{"id":5238,"title":"Large-scale vulnerability analysis.","authors":[],"date":"2006","doi":"10.1145\/1162666.1162671","raw":"S. Frei, M. May, U. Fiedler, and B. Plattner. Large-scale vulnerability analysis. In Proc. of SIGCOMM'06 Workshop. Association for Computing Machinery, 2006. Available at www.techzoom.net\/ papers\/sigcomm_lsad_large_scale_vulnerability_analysis_2006.pdf.","cites":null},{"id":6018963,"title":"Lottery equivalents: reduction of the certainty eect problem in utility assessment.","authors":[],"date":"1986","doi":"10.1287\/mnsc.32.1.56","raw":"M. McCord and R. de Neufville. Lottery equivalents: reduction of the certainty eect problem in utility assessment. Management Science, 32:56{61, 1986.","cites":null},{"id":5262,"title":"Lottery equivalents: reduction of the certainty effect problem in utility assessment.","authors":[],"date":"1986","doi":"10.1287\/mnsc.32.1.56","raw":null,"cites":null},{"id":5270,"title":"Managed security monitoring: Closing the window of exposure. Counterpane Internet Security. Manuscript available at: http:\/\/www.counterpane.com\/window.pdf,","authors":[],"date":"2000","doi":null,"raw":"B. Schneier. Managed security monitoring: Closing the window of exposure. Counterpane Internet Security. Manuscript available at: http:\/\/www.counterpane.com\/window.pdf, 2000.","cites":null},{"id":6018950,"title":"Managing Cybersecurity Resources: A Cost-Bene Analysis.","authors":[],"date":"2006","doi":"10.11610\/isij.1808","raw":"L.A. Gordon and M.P. Loeb. Managing Cybersecurity Resources: A Cost-Benet Analysis. McGraw Hill, 2006.","cites":null},{"id":5246,"title":"Managing Cybersecurity Resources: A Cost-Benefit Analysis.","authors":[],"date":"2006","doi":"10.11610\/isij.1808","raw":null,"cites":null},{"id":5266,"title":"Market entry, phased rollout or abandonment? a real option approach.","authors":[],"date":"2000","doi":"10.1016\/S0377-2217(99)00121-6","raw":"Enrico Pennings and Onno Lint. Market entry, phased rollout or abandonment? a real option approach. European Journal of Operational Research, 124(1):125 { 138, 2000.","cites":null},{"id":5221,"title":"Network Software Security and User Incentives.","authors":[],"date":"2006","doi":"10.1287\/mnsc.1060.0568","raw":"T. August and T. Tunca. Network Software Security and User Incentives. Management Science, 52(11):1703{1720, 2006.","cites":null},{"id":5264,"title":"Optimal Discretionary Monetary Policy in a Model of Asymmetric Bank Preferences.","authors":[],"date":"2003","doi":"10.1111\/1468-0297.t01-1-00149","raw":"R.A. Nobay and D.A. Peel. Optimal Discretionary Monetary Policy in a Model of Asymmetric Bank Preferences. Economic Journal, 113(489):657{665, 2003.","cites":null},{"id":5240,"title":"Optimal Interest-Rate Rules I: General Theory. Working Paper Series 9419,","authors":[],"date":"2002","doi":"10.3386\/w9419","raw":"M.P. Giannoni and M. Woodford. Optimal Interest-Rate Rules I: General Theory. Working Paper Series 9419, National Bureau of Economic Research, 2002. ISSU 9419, ISSN 0898-2937.","cites":null},{"id":5219,"title":"Optimal Policy for Software Vulnerability Disclosure.","authors":[],"date":"2008","doi":"10.1287\/mnsc.1070.0771","raw":"A. Arora, R. Telang, and H. Xu. Optimal Policy for Software Vulnerability Disclosure. Management Science, 54(4):642{656, 2008.","cites":null},{"id":5236,"title":"Point Processes. Monographs on Statistics and Applied Probability. Chapman and Hall,","authors":[],"date":"1980","doi":null,"raw":"D.R. Cox and V. Isham. Point Processes. Monographs on Statistics and Applied Probability. Chapman and Hall, 1980.","cites":null},{"id":5258,"title":"Quantitative model of the security intrusion process based on attacker behaviour.","authors":[],"date":"1997","doi":"10.1109\/32.588541","raw":"E. Jonsson and A. Olovsson. Quantitative model of the security intrusion process based on attacker behaviour. IEEE Transactions on Software Engineering, 23(4):235{245, 1997.","cites":null},{"id":5213,"title":"Security economics and the internal market. Report to the European Network and Information Security Agency (ENISA),","authors":[],"date":"2007","doi":null,"raw":"R. Anderson, R. B ohme, R. Clayton, and T. Moore. Security economics and the internal market. Report to the European Network and Information Security Agency (ENISA), 2007, http:\/\/www. enisa.europa.eu\/doc\/pdf\/report_sec_econ_&_int_mark_20080131.pdf.","cites":null},{"id":5233,"title":"Semantics for structured systems modelling and simulation.","authors":[],"date":"2010","doi":"10.4108\/icst.simutools2010.8631","raw":"M. Collinson, B. Monahan, and D. Pym. Semantics for structured systems modelling and simulation. In Proc. Simutools 2010. ICST: ACM Digital Library and EU Digital Library, 2010. ISBN: 78-963-9799-87-5.","cites":null},{"id":6018956,"title":"Some experimental  on decision-making under risk and their implications.","authors":[],"date":"1989","doi":null,"raw":"J.Y. Jarey. Some experimental ndings on decision-making under risk and their implications. European Journal of Operational Research, 38:301{306, 1989.","cites":null},{"id":5254,"title":"Some experimental findings on decision-making under risk and their implications.","authors":[],"date":"1989","doi":"10.1016\/0377-2217(89)90007-6","raw":null,"cites":null},{"id":5250,"title":"Sources of bias in assessment procedures for utility functions.","authors":[],"date":"2009","doi":"10.1287\/mnsc.28.8.936","raw":"J.C. Hersey, H.C. Kunreuther, and P.J. Shoemaker. Sources of bias in assessment procedures for utility functions. Management Science, 28:936{953, 1982.25. C. Ioannidis, D. Pym, and J. Williams. Investments and trade-os in the economics of information security. In Roger Dingledine and Philippe Golle, editors, Proceedings of Financial Cryptography and Data Security '09, volume 5628 of LNCS, pages 148{166. Springer, 2009. Preprint available at http:\/\/www.cs.bath.ac.uk\/~pym\/IoannidisPymWilliams-FC09.pdf.","cites":null},{"id":5230,"title":"Technology choice under several uncertainty sources.","authors":[],"date":"2010","doi":"10.1016\/j.ejor.2010.03.010","raw":"Catherine Bobtche and Stphane Villeneuve. Technology choice under several uncertainty sources. European Journal of Operational Research, 206(3):586{600, 2010.","cites":null},{"id":5244,"title":"The Economics of Information Security Investment.","authors":[],"date":"2002","doi":"10.1145\/581271.581274","raw":"L.A. Gordon and M.P. Loeb. The Economics of Information Security Investment. ACM Transactions on Information and Systems Security, 5(4):438{457, 2002.","cites":null},{"id":5215,"title":"The economics of information security.","authors":[],"date":"2006","doi":"10.1126\/science.1130992","raw":"R. Anderson and T. Moore. The economics of information security. Science, 314:610{613, 2006. Extended version available at http:\/\/www.cl.cam.ac.uk\/~rja14\/Papers\/toulouse-summary.pdf.","cites":null},{"id":6018966,"title":"The Euler Scheme for Levy Driven Stochastic Dierential Equations. The Annals of Probability,","authors":[],"date":"1997","doi":"10.1214\/aop\/1024404293","raw":"P. Protter and D. Talay. The Euler Scheme for Levy Driven Stochastic Dierential Equations. The Annals of Probability, 25(1):393{423, 1997.","cites":null},{"id":5268,"title":"The Euler Scheme for Levy Driven Stochastic Differential Equations. The Annals of Probability,","authors":[],"date":"1997","doi":"10.1214\/aop\/1024404293","raw":null,"cites":null},{"id":5224,"title":"Timing the application of security patches for optimal uptime.","authors":[],"date":"2002","doi":null,"raw":"S. Beattie, S. Arnold, C. Cowans, P. Wagle, C. Wright, and A. Shostack. Timing the application of security patches for optimal uptime. In LISA '02: 16th System Administration Conference, 2002.","cites":null},{"id":5211,"title":"Why information security is hard: An economic perspective.","authors":[],"date":"2001","doi":"10.1109\/acsac.2001.991552","raw":"R. Anderson. Why information security is hard: An economic perspective. In Proc. 17th Annual Computer Security Applications Conference, 2001.","cites":null},{"id":5217,"title":"Windows of vulnerability: A case study analysis.","authors":[],"date":"2000","doi":"10.1109\/2.889093","raw":"A. Arbaugh, W.L. Fithem, and J. McHugh. Windows of vulnerability: A case study analysis. IEEE Computer, 2000.","cites":null}],"documentType":{"type":1}},"contributors":["University of Aberdeen, Accountancy & Finance"],"datePublished":"2012-01-16","abstract":"Peer reviewedPostprin","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:aura.abdn.ac.uk:2164\/2151<\/identifier><datestamp>\n                2018-01-04T18:16:06Z<\/datestamp><setSpec>\n                com_2164_320<\/setSpec><setSpec>\n                com_2164_319<\/setSpec><setSpec>\n                com_2164_318<\/setSpec><setSpec>\n                com_2164_552<\/setSpec><setSpec>\n                com_2164_352<\/setSpec><setSpec>\n                com_2164_329<\/setSpec><setSpec>\n                com_2164_705<\/setSpec><setSpec>\n                col_2164_321<\/setSpec><setSpec>\n                col_2164_553<\/setSpec><setSpec>\n                col_2164_706<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nInformation Security Trade-offs and Optimal Patching Policies<\/dc:title><dc:creator>\nIoannidis, Christos<\/dc:creator><dc:creator>\nPym, David J.<\/dc:creator><dc:creator>\nWilliams, Julian<\/dc:creator><dc:contributor>\nUniversity of Aberdeen, Accountancy & Finance<\/dc:contributor><dc:subject>\nInformation security<\/dc:subject><dc:subject>\nOptimal policy<\/dc:subject><dc:subject>\nRisk reduction<\/dc:subject><dc:subject>\nStochastic processes<\/dc:subject><dc:subject>\nQA75 Electronic computers. Computer science<\/dc:subject><dc:subject>\nQA75<\/dc:subject><dc:description>\nPeer reviewed<\/dc:description><dc:description>\nPostprint<\/dc:description><dc:date>\n2011-10-25T11:06:02Z<\/dc:date><dc:date>\n2011-10-25T11:06:02Z<\/dc:date><dc:date>\n2012-01-16<\/dc:date><dc:type>\nJournal article<\/dc:type><dc:identifier>\nIoannidis , C , Pym , D J & Williams , J 2012 , ' Information Security Trade-offs and Optimal Patching Policies ' European Journal of Operational Research , vol 216 , no. 2 , pp. 434-444 . DOI: 10.1016\/j.ejor.2011.05.050<\/dc:identifier><dc:identifier>\n0377-2217<\/dc:identifier><dc:identifier>\nPURE: 4539048<\/dc:identifier><dc:identifier>\nPURE UUID: fdccfe06-f151-48b6-b82e-7cebc5a207f1<\/dc:identifier><dc:identifier>\nScopus: 84857187741<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2164\/2151<\/dc:identifier><dc:identifier>\nhttp:\/\/dx.doi.org\/10.1016\/j.ejor.2011.05.050<\/dc:identifier><dc:language>\neng<\/dc:language><dc:relation>\nEuropean Journal of Operational Research<\/dc:relation><dc:rights>\n\u201cNOTICE: this is the author\u2019s version of a work that was accepted for publication in European Journal of Operational Research. Changes resulting from the publishing process, such as peer review, editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may have been made to this work since it was submitted for publication. A definitive version was subsequently published in European Journal of Operational Research, [VOL 216, ISSUE 2, (16\/012012)] DOI 10.1016\/j.ejor.2011.05.050\u201d<\/dc:rights><dc:format>\n11<\/dc:format>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["0377-2217","issn:0377-2217"]}],"language":{"code":"en","id":9,"name":"English"},"relations":["European Journal of Operational Research"],"year":2012,"topics":["Information security","Optimal policy","Risk reduction","Stochastic processes","QA75 Electronic computers. Computer science","QA75"],"subject":["Journal article"],"fullText":"Information Security Trade-offs\nand Optimal Patching Policies\nChristos Ioannidis1, David Pym2?, and Julian Williams3\n1 University of Bath\nDepartment of Economics\nBath BA2 7AY\nEngland, U.K.\nc.ioannidis@bath.ac.uk\n2 University of Aberdeen\nSchool of Natural and Computing Sciences\nKing\u2019s College\nAberdeen AB24 3UE\nScotland, U.K.\nd.j.pym@abdn.ac.uk\n3 School of Business\nUniversity of Aberdeen\nKing\u2019s College\nAberdeen AB24 3QY\nScotland, U.K.\njulian.williams@abdn.ac.uk\nAbstract. We develop and simulate a basic mathematical model of the costly deployment\nof software patches in the presence of trade-offs between confidentiality and availability.\nThe model incorporates representations of the key aspects of the system architecture, the\nmanagers\u2019 preferences, and the stochastic nature of the threat environment. Using the model,\nwe compute the optimal frequencies for regular and irregular patching, for both networks\nand clients, for two example types of organizations, military and financial. Such examples are\ncharacterized by their constellations of parameters. Military organizations, being relatively\nless cost-sensitive, tend to apply network patches upon their arrival. The relatively high cost\nof applying irregular client patches leads both types of organization to avoid deployment\nupon arrival.\n1 Introduction\nSoftware for computer networks, systems, and applications is typically subject to information\nsecurity flaws, which, if exploited, may lead to substantial losses for the host organization. As\nvulnerabilities appear, software vendors periodically release patches in response. For large organi-\nzations, with tens or even hundreds of thousands of network devices, the deployment of patches is\na costly exercise, impacting significantly on system availability, with consequences for properties of\nbusiness processes, for credibility, and revenue. Failure to deploy a patch, however, risks exposing\nthe host organization to exploitations of vulnerabilities.\nThe host organization\u2019s information security management team must make a judgement re-\ngarding the appropriate timing of the deployment of patches, in the light of the organization\u2019s\npolicies. As in other areas of information security operations, decisions to deploy patches involve\ntrade-offs between protecting the confidentiality of the system and maintaining its availability.\nIn recent years, there has been a good deal of research in the economics of information security.\nFor example, Anderson et al. [1, 3, 2] have presented wide-ranging discussions of the issues, whilst\nGordon and Loeb [21, 22] have employed a microeconomic analysis of the costs and benefits of\ndefences against given vulnerabilities.\n? This work has also been supported by the Cloud and Security Lab, HP Labs, Bristol.\nRecent work by the present authors [25] has considered how to apply ideas and methods from\nutility theory and dynamic optimization to investment in information security. More specifically,\nby way of an illustration of the methodology, we have presented a dynamic model of trade-offs\nbetween confidentiality, availability, and investment in information security.4 Our analysis has been\nmotivated by those situations \u2014 including a detailed example in Beautement et al. [8], based on\nthe use of USB memory sticks, as well as the work of Beres et al. [9, 10] \u2014 in which the corruption\nof data (i.e., integrity) is a relatively minor issue. Here we intend confidentiality to refer to the\nsystem\u2019s state of protection against breaches of confidentiality, rather than the state of exposure\nof any particular data item. Similarly, we intend availability to refer to the system\u2019s readiness\nto supply its intended service. Our use of this example does not exclude the applicability of the\nmethods we employ to situations in which integrity plays a major role. Such situations will be\nconsidered elsewhere. Moreover, in specific practical applications, it will typically be necessary to\nbuild richer models that incorporate more domain-specific details, such as the criticality of various\ninformation system components to business processes.\nIn this paper, we develop a model that is based on the confidentiality\u2013availability trade-off\nmodel presented in [25], in which patch arrivals are interpreted as shocks to confidentiality and\navailability. We use this model to derive patching strategies in (large) organizations. We consider\nin detail the optimal timing of both client and network patching. As in [25], the purpose of this\npaper is to illustrate the application of modelling and reasoning methods from utility theory and\nmacroeconomics to questions in information security management that involve trade-offs between\nattributes of interest.\nThe remainder of the paper is organized as follows: in Section 2, we discuss related work; in\nSection 3, we develop our basic mathematical set-up, which draws upon methods from utility\ntheory and dynamic optimization as deployed in economic and financial modelling, explaining\nhow we model optimal responses in the presence of shocks to confidentiality and availability; in\nSection 4, we study an example of a model of the kind described in Section 3, to which to introduce\na cost structure for implementing patches, and in which shocks to confidentiality and availability\nare given by the arrival (according to a Poisson process) of patches whose severity (or intensity)\nis drawn from a log-normal distribution; in Section 5, we describe the appropriate instance of the\nspace of parameters employed in the model, and present and comment upon the results of our\nnumerical simulations; finally, in Section 6, we explain our findings and their consequences for\npatching policies.\n2 Related Work\nBeres et al. [9] provide a process model (written in the Demos 2K modelling language [16], now su-\nperseded for our purposes by the Gnosis modelling language [13, 19]) of vulnerability management\npolicies in a large organization, and explore the effectiveness of both standard (or regular) patch-\nmanagement and emergency (or irregular) escalation-based policies. In designing their model,\nwhich is concerned with patching clients, they examine the decision making process followed by\nthe security operations managers of several large organizations, together with the different mitiga-\ntion and patching measures that might be selected. They also identify external threat environment\nevents that influence the type of mitigations that are deployed and the time at which they are\ndeployed. They focus on examining the \u2018risk exposure window\u2019, defined as the time from public\nvulnerability disclosure to when an organization believes the risk is mitigated, as a measure of\nthe effectiveness of these processes. By designing a model of these processes and running stochas-\ntic simulations, they examine the effectiveness of security operations processes and protection\nmechanisms based on external environment events.\nIn [23], it is postulated that both attackers and defenders behave strategically, whilst Beres et\nal. [9] seeks, treating attackers exogenously, to enable the decision-makers in IT security to predict\nthe outcome of investment decisions or changes in policy in advance of putting them into effect.\n4 Modelling multiple trade-offs can be accommodated within the same methodology.\nTheir results show the impact of increasing the effectiveness of early mitigations and of speeding\nup patch deployment on reducing the risk exposure window.\nThe importance of timely patching in networks in the presence of externalities has been ad-\ndressed by August and Tunca [6], in which they develop a set of incentive structures for users to\nimplement effective patch management when their actions impact upon the welfare of other users.\nThey show that software vendors can offer rewards to encourage timely patching when vulnerabil-\nities occur in both proprietary software and freeware and, given the differential costs of patching\nto users, conclude ([6], p. 1718) that \u2018a \u201cone-size-fits-all\u201d approach is unlikely to be an immediate\nremedy\u2019.\nThe timing of vulnerability disclosures by vendors is modelled formally by Arora, Telang, and\nXu (2008) [5], where it is shown that, with no regulation, the vendor releases a patch less frequently\nthan is socially optimal.\nThe relationship between the release of patches by vendors and their implementation has been\nstudied recently by Cavusoglu, Cavusoglu, and Zhang [12]. They classify patching cycles into\ntime-driven and event-driven. They show that social loss is minimized when vendor releases are\nsynchronized with the time-driven cycles of the system operator. Their analysis is done in the\ncontext of single vendor and a single system operator. When such synchronization cannot be\nachieved because it is costly, the imposition of liability of the vendor for delayed release cannot\nachieve socially optimal disclosures.\nWhen system operators employ a variety of applications, patch arrivals to the system operator\nwill appear as random events, without apparent periodicity. In this paper, we capture patch\narrivals as a Poisson process, and we decompose patching implementation into time-driven and\nevent-driven incidents.\nThe \u2018Vulnerability Timeline\u2019, reproduced from Beres et al. [9]in Figure 1, is a reference point\nfor many studies of patching policies.\n6\nFigure 2. Vulnerability Timeline1.\nAt the time of disclosure the vulnerability becomes widely known. Usually, this happens when vulnerability \ninformation is published by CERT or security vendors such as ISS, Security Focus, Secunia among others, later \nresulting in additional security advisory by the vendor. From this point in time the risk increases considerably, as \nthe vulnerability is analysed by hackers with exploit code potentially appearing quickly afterwards. We assume \nthat soon after this point, e.g. a day or two, an organization would note the vulnerability as part of its ongoing \nthreat awareness programme. The organization would then usually conduct a preliminary risk assessment to \ndetermine if the vulnerability applies to its environment. \nWe distinguish between the time when exploit code is available and the time that malware might appear. Code \nexploiting some features of vulnerability is usually published earlier, often very close to disclosure time, \nsometimes as a proof that the vulnerability exists. It takes longer to develop exploit code with the potential to\ncause substantial damage. However, the sequence of the exploit, disclosure, and malware time is not fixed. Both, \nthe exploit and the malware time can be before, at, or after the disclosure time. Similar reasoning applies to the \ntime taken to develop patches; release of a patch could coincide with disclosure time or it may take as much as 30 \ndays or more to develop.\nThe time of patch availability is the earliest date that the vendor of the software releases a patch providing\nprotection against the exploitation of the vulnerability. We assume that the organization learns of the patch either \nthe same day or with a delay that is negligible. The availability of other security mitigations such as signatures for \nintrusion prevention systems or anti-virus tools we take as being a separate matter from patch release.  In our time \nline we assume that such mitigations are usually available earlier than patch. That being said, we also recognise \nthat these mitigations are necessarily temporary stopgap measures and might not necessarily cover all disclosed \nvulnerabilities.\nOnce the organization receives a patch, the internal patch management process starts and continues until the patch \nis adequately deployed across the production environment. The organizations often regard that the exposure \nwindow closes when the proportion of systems patched is somewhere around 95%, as there will always be some \nnumber of systems that are either offline or unmanaged. This does not mean that risk goes to zero, since even one \nunpatched machine could present substantial exploitation risk, depending how it is positioned in the environment. \nHowever, to simplify our assumptions in the model, we regard the time when a patch is adequately deployed is \nwhen the window of exposure is closed: T5-T0. If an organizations uses other mitigations such as signatures we \nalso regard the time that these are adequately deployed as the time that exposure is closed: T2-T0.  \n4.2. The rate parameters of external events  \nThe analysis of the vulnerability timeline also highlights the events in the external environment that directly affect\ndecisions the organizations takes on when to deploy security mitigations. The availability of an exploit poses a \nsecurity threat to the organizations; sometimes the organization has to decide on an appropriate action before the \npatch is available. When the patch is released, the organization can start its patch management process, finally \nreducing the threat risk when the patch is deployed. The resulting exposure risk depends strongly on the timing \nand dynamics of those two external events.\n  \n1 The sequencing of events in this timeline is not fixed; the aim is to illustrate the various stages in the vulnerability life cycle.   \nDiscovery Disclosure T0\nCannot be \nmeasured\nOnly some groups aware, no \ndata yet\nSome public \ndata\nA lot of \npublic data\nPatching \nprocesses\nMinus zero days exploit Public exploit code T1\nPatch Available T3\nPatch Deployed T5\nWindow of Exposure\nMalware T4\nSignature Available T2\nFigure 1. Vulnerability Timeline: the sequencing of events in th s timeline is not fixed; the aim is to illustrate the\nvarious stages in the vulnerability life cycle (Beres et al. (2008) [9])\n(i.e., time-driven) and irregular (i.e., event-driven) patching\nin the presence of stochastic patch arrivals (at T3) that differ\nin frequency and intensity and impact upon confidentiality\nand availability. We take account of the system manager\u2019s\npreferred trade-off between protecting confidentiality a d\navailability.\n3. In roduction t the Modelling Method\nOrganizations deploy systems t chnologies in order to\nachi ve their business objectiv . Typically, it will be neces-\nsary for an organization to invest in deploying information\nsecurity policies, processes, and technologies in order to\nprotect the confidentiality, C, integrity, I , and availability,\nA, of its business processes. Defences deployed against each\nof C, I , and A may compromise the others. For example,\nthe process of deploying a network patch, in order to\nprotect the confidentiality of the organization\u2019s system, may\ncompromise the availability of network resources, such as\nfilestores and databases to client devices. In the presence of\nlimited investment resources, choices must be made between\ndifferent possible defences. A basic modelling framework\nfor addressing trade-offs of this kind has been given by\nIoannidis, Pym, and Williams (2009) [18].\nFollowing Ioannidis, Pym, and Williams (2009) [18], we\nfocus on the trade-off between confidentiality and availabil-\nity. This simplification is justifiable: in many \u2014 though by\nno means all \u2014 situations, corruption of data is not a major\nissue, and we can be concerned just with the availability of\nuncorrupted d ta. In particular, this assumptio is r asonable\nin the context of the empirical study by Beautement et al.\n(2008) [8] of the use of USB memory sticks, which provided\na partial motivation for the model described by Ioannidis,\nPym, and Williams (2009) [18]. Of more direct relevance\nto the present paper in this respect is the work of Beres,\nGriffin, and Shiu (2008) [9] which takes a similar approach\nin a process model of client patching.\nGiven this trade-off, to achieve the optimal deployment\nof investments in information security, an organization must\nexplicitly determine its security preferences. That is, for each\nof its business processes, determine the extent to which it\nprefers to protect differentially each of C, I , and A. For one\nexample, in order to protect revenue, an online retailer will\nattach a relatively high weighting to losses of availability.\nFor another example, a government intelligence service will\nattach relatively high weighting to losses in confidentiality.\nIn the presence of trade-offs between the constituent com-\nponents of information security, we adopt a well-established\nanalytical methodology employed in economics to model\ninstrument setting by a decision-maker when faced with a\ntrad -off between the economic magnitudes to be controlled.\n3.1. A Dynamic Model of Trade-offs\nFollowing Ioannidis, Pym, and Williams (2009) [18], we\nassume that our storage and processing technologies do not\ncorrupt data and study the trade-off between confidentiality\nand availability. This situation is intuitively appealing: disks,\nDVDs, and memory sticks are rarely corrupted, at least in\ncontexts similar to that studied in Beautement et al. (2008)\n[8]. Client and network patches, as modelled by Beres et\nal. (2008) [9], only rarely corrupt users\u2019 data. It should be\nemphasized, however, that there ar many situations in which\nthe suppression of integrity is not valid: Our present model\ndoes not capture such situations.\nTechnically, within the framework described by Giannoni\nand Woodford (2002) [14],2 we consider a utility maximiz-\ning decision-maker with convex preferences, u (t) over a\nfixed time horizon, [t0, T ].\nThe general linear stabilization policy problem can be\nexpressed as a solution to the following control problem,\nin which the economic interaction structure of the state\nvariables is given in terms of a linear system of the form\n2. See \u00a7 3.1 for a discussion of this general framework.\nFig. 1. Vulnerability Timeline: th sequencing of events in this timeline is not fixed; the aim is to illustrate\nthe various stages in the vulnerability life cycle (Beres et al. [9])\nThe timeline provides a detailed description of the sequence of events from the di covery of a\nvul erability to the deployment of a patch. Similar accou t of such a ti eline have been given\nby other authors; for example, Arbaugh et al. [4] and Schneier [34]. Of particular interest is Frei\net al. [17], which illustrates the distributi ns and frequencies of vulnerabilities, using data from\nseveral large databases. The vulnerability arrival timeline given by Frei et al. is augmented in\nBeres et al. [9]. Arora, Telang, and Xu [5] calcul e the socially optimal time interval between\ndiscovery and disclosure, T0. August and Tunca [6] calculate, in the presence of externalities, the\nopt al p ri Patch A ailable to Patch D ployed, T3 to T5, when vendors offer incentive to the\nsystem operator. Cavusoglu, Cavusoglu, and Zhang [12], calculate the socially optimal window of\nexposure an decompose the pa ching process in o ime- and vent-driven incident .\nBeattie et al. [7] e lore the factors affecting the best time to apply patches so that organiza-\ntions minimize disruptions caused by def ctive patches. Their results indicate that patching during\nthe period of 10 to 30 days after first patch release date is the optimal time for minimizing the dis-\nruption caused by defective patches. The adoption of a real options methodology for determining\nchoices of the appropriate technology in the presence of multiple sources of uncertainty and market\nentry has been addressed by [11, 32]. In a similar vein, Gordon et al. [20] offer a framework around\nwhich decisions to delay the implementation of patches are integrated into a financial model that\nexploits deferment.\nFrom the arguments discussed above, it is apparent that the timing of patch deployment\nmatters because their deployment subjects organizations to serious costs and mis-timing may\nexacerbate the impact of costs.\nIn our economic model, developed in Sections 3.2 and 4, we are concerned with just one\nsegment of the timeline: Patch Available to Patch Deployed. We develop a model of regular (i.e.,\ntime-driven) and irregular (i.e., event-driven) patching in the presence of stochastic patch arrivals\n(at T3) that differ in frequency and intensity and impact upon confidentiality and availability. We\ntake account of the system manager\u2019s preferred trade-off between protecting confidentiality and\navailability.\n3 Introduction to the Modelling Method\nOrganizations deploy systems technologies in order to achieve their business objectives. Typically,\nit will be necessary for an organization to invest in deploying information security policies, pro-\ncesses, and technologies in order to protect the confidentiality, C, integrity, I, and availability, A,\nof its business processes.\nDefences deployed against each of C, I, and A may compromise the others. For example, the\nprocess of deploying a network patch, in order to protect the confidentiality of the organization\u2019s\nsystem, may compromise the availability of network resources, such as filestores and databases\nto client devices. Moreover, the deployment of such defences is costly. It follows that security\nmanagers with limited budgets must determine an allocation of investments, K, to defences for C,\nI, and A that is appropriate to their priorities. Different types of organization will have different\npriorities and examples exist of trade-offs between all of C, I, A, and K.\nThe purpose of this paper is to illustrate the methodology of modelling and reasoning about\nthe dynamics of the trade-offs between the quantities of interest to the managers using methods\nthat are commonly deployed in macroeconomics. To that end, the situation we study, though\ninformed by reflective interaction with operational security managers in several large organizations,\nis somewhat simplified for illustrative purposes and brevity. For example, for the purposes of this\npaper, we consider just trade-offs between investments to protect confidentiality and availability.\nThis simplification should in no way be taken as an indication that integrity is not a concern that\nour methodology is able to address. Moreover, practical applications of our approach will typically\nrequire richer models that incorporate a good detail of domain-specific detail.\nA basic modelling framework for addressing trade-offs of this kind has been given by Ioannidis,\nPym, and Williams [25].\n3.1 A Dynamic Model of Trade-offs\nFollowing Ioannidis, Pym, and Williams [25], we assume \u2014 for simplicity and illustrative purposes,\nimplying no restriction of the method \u2014 that our storage and processing technologies do not\ncorrupt data and study the trade-off between confidentiality and availability. This simple situation\nis intuitively appealing: disks, DVDs, and memory sticks are rarely corrupted, at least in contexts\nsimilar to that studied in Beautement et al. [8]. Client and network patches, as modelled by Beres\net al. [9], only rarely corrupt users\u2019 data. It should be emphasized, however, that there are many\nsituations in which the suppression of integrity is not valid. In such cases, models of the kind\ndescribed herein must be enriched with components handling integrity.\nTechnically, within the framework described by Giannoni and Woodford [18], we consider a\nutility maximizing decision-maker with convex preferences, U (t) over a fixed time horizon, [t0, T ].\nThe general linear stabilization policy problem can be expressed as a solution to the following\ncontrol problem, in which the economic interaction structure of the state variables is given in\nterms of a linear system of the form\n\u0393\n[\nZt+1\nEtzt+1\n]\n= \u03a81\n[\nZt\nzt\n]\n+ \u03a82rt + \u03a83ut (1)\nwhere zt denotes a vector of endogenous variables (e.g., inflation, unemployment, consumption)\nand the vector of pre-determined variables is given by Zt (lagged values of the dependent and\ncurrent and lagged values of the independent variables), \u0393 , \u03a81, \u03a82, and \u03a83 represent the structure\nof the system as determined by the behaviour of the agents in the economy and the resource\nconstraint, and Et denotes the conditional expectations operator. The instrument available to the\nauthorities is given by rt and the system is disturbed from its original equilibrium position due\nto the existence of shocks ut. The objective of the policy is to minimize the quadratic objective\nfunction in terms of squared deviations of the variables of interest \u0398 from some a-priori specified\ntarget values \u0398\u2217 by choosing the appropriate value of r given the structure of the system, the loss\nfunction,\n\u039b = Et\n{\nT\u2211\nt=0\n\u03b4\u2212t\n2\n(\u0398 \u2212\u0398\u2217)T\u2126 (\u0398 \u2212\u0398\u2217)\n}\n(2)\nwhere the vector of variables denoted by \u0398 includes values of both zt and rt. The matrix \u2126\ndenotes the variance covariance matrix of the system and \u03b4 is the authorities\u2019 discount factor. The\nconditional (on all available information) expectations operator is Et.\nThe equilibrium characterization of the system consists of a set of time invariant equations:\nzt = \u03b20 + \u03b21\n\u2212\nZt + \u03b22\n\u2212\nut (3)\nwhere .\u00af indicates that the structure of the relevant vectors can differ from the one denoted in\nEquation 1, and the parameters \u03b20, \u03b21, and \u03b22 represent the optimal responses from Equation 2\nand are derived as combinations of the structural parameters in Equation 1.\nThe imposition of rational expectations requires that the model\u2019s predictions of the endogenous\nvariables are equal to the agents\u2019 forecasts.\nNobay and Peel [31] accommodate the absence of symmetric loss in the presence of deviations\nby employing, in \u039b, the Linex function whose asymmetry depends upon the choice of the parameter\na:\ng(ut) = {exp(aut)\u2212 aut \u2212 1} \/a2. (4)\nIn our case, we restrict our analysis to quadratic loss functions but we allow for unequal weights\nto be applied to its different arguments.\nThe analysis given by Giannoni and Woodford [18], together with refinements of the kind\nsuggested by the work of Nobay and Peel [31], provides a very general framework for capturing the\ndynamics of investments and trade-offs in information security within which the choices of security\nand investment properties to be modelled, along with associated organizational preferences, can\nbe captured.\n3.2 A Specific Dynamic Model of Trade-offs\nIn our context, the decision-maker wishes to minimize the following loss function, defined in terms\nof the time t levels of confidentiality, C(t), availability A(t), and investment K(t), and their\nrespective targets (C\u00af, A\u00af, K\u00af) and a control vector x:\nH (C(t), A(t),K(t; x)) = \u03c91\n(\nC (t)\u2212 C\u00af)2 + \u03c92 (A (t)\u2212 A\u00af)2 + \u03c93 (K (t; x)\u2212 K\u00af)2 (5)\nThe system\u2019s solution will be of the form\n= (x\u2217) , min\nx\n\u222b T\nt\nexp(\u2212\u03b4t)H (C(t), A(t),K(t; x)) dt (6)\nwhere \u03b4 is a discount factor operating over the investment horizon t, T and x\u2217 is the optimal\npolicy response. The weights in the loss function (5) characterize the type, or preferences, of\nthe organization; for example, military and deep-state organizations might put a great deal of\nweight on C compared to A, whilst a retailer or welfare distributor might place greater value on A\ncompared to C. A bank, when considering the potential impact of network patching on its client\ndevices\u2019 access to network services must make a more delicate judgement: its customers expect\ntheir data to be adequately protected, but also expect to access their accounts via ATMs at all\ntimes.\nFinally, the weight on (K(t; x) \u2212 K\u00af)2 reflects the system\u2019s loss when managers are forced to\ncompromise \u2018budgets\u2019. In practice, we expect managers\u2019 preferences for investment to be asym-\nmetric; that is, that they will be more averse to overspending.\nThe effectiveness of the managers\u2019 investment responses is constrained by the time evolution\nof confidentiality and availability. There are described by a system of equations (7) which express\ntheir dynamics in terms of parameters that characterize the behaviour of the system.\nC(t) = \u2212\u03b1(P )\n\uf8eb\uf8ed\u222b t\nt0\nA\u02d9 dt\n(\n\u03b2\n\u222b t\u2032\nt0\nK\u02d9 dt\u2032\n)\u22121\uf8f6\uf8f8+ C0\nA(t\u2032) = \u03b3\n(\u222b t\u2032\nt0\nR\u02d9 dt\u2032\n)\n+ \u03b4\n(\u222b t\u2032\nt0\nK\u02d9 dt\u2032\n)\n\u2212 \u000f\n(\u222b t\u2032\nt0\nC\u02d9 dt\u2032\n)\n\u2212 \u03b6(Q) (7)\nwhere t\u2032 < t, denoting that current shocks, \u03b1(P ), to confidentiality subsequently affect availability.\nWe explain the set-up below.\nShocks (reductions) to availability are denoted by the stochastic processQ, and shocks (breaches)\nin confidentiality are denoted by a second the stochastic process P . In both cases, the shocks enter\nthe system linearly, and the process is defined as being non-decreasing. Their impact is measured\nby \u03b1 and \u03b6, respectively. The system\u2019s attack surface is modelled by the availability\u222b t\nt0\nA\u02d9 dt, (8)\nand amplifies the influence of breaches of confidentiality, whilst increases in the capital stock of\ninformation security5,\n1\u222b t\nt0\nK\u02d9 dt\n, (9)\nmitigates against the severity of such shocks. The effectiveness of this mitigation is measured by\nthe value of the positive parameter \u03b2.\nThe availability of the system depends positively of the system\u2019s inter-connectedness,6\n\u222b t\u2032\nt0\nR\u02d9 dt\nand the capital stock of information security. Increases in confidentiality are expected to exert a\n5 For simplicity of exposition of the initial properties of the model, we do not allow for depreciation in\nthe capital stock of information security.\n6 The system response to deviations in confidentiality is given by (where x is an element of the control\nvector x)\nR\u02d9 = x\n(\nC \u2212 C\u00af)\nwhere R is defined as\nR =\n1\n1\u2212 \u03be (10)\nfor \u03be \u2208 [0, 1). R is thus considered to be a (very crude) measure of the interconnectedness of the system.\nThis notion of interconnectedness should not be confused with interdependence. In the theory of\ndistributed systems (see, for example, [14]), system availability is promoted by reducing the interde-\npendence of the distributed components: system availability is increased by increasing the extent to\nwhich the distributed components are able to operate independently of one another. In contrast, this\nnegative influence on the system\u2019s availability. The positive parameters \u03b3, \u03b4, \u000f, and \u03b6 measure the\nimpact of these factors on the system\u2019s availability.\nCapital stock in information security is determined by \u2018unexpected\u2019 fluctuations in availability\nand by the arrival of software and system upgrades, such as security patches. The time dynamics\nof this is expressed in Equation 11 (K0 is an initial value):\nK = \u2212\u03b7A+ P(x(t)) +K0 (11)\nHere x(t) is a component of the vector x in Equation 5. In the presence of patches, with asso-\nciated deployment costs given by P(x), IT managers must decide on the optimal timing of such\ndeployment to minimize costs. Note that, as t\u2032 \u2192\u221e, the system stabilizes.\nAs formulated here, the model shocks both confidentiality and availability. The model consid-\nered by the present authors in [25] shocks only confidentiality. A richer model might also shock\ninvestment. Such a model would need to be formulated with an additional control instrument,\nso that there would be an instrument corresponding to each shocked dimension. The general\nframework within which models such as these are formulated is discussed briefly in Section 3.1.\nIT managers will respond to decreases in availability by increasing investment in information\nsecurity (11). The managers\u2019 response is measured by the parameter, \u03b7. In the presence of de-\nviations of confidentiality from its target, IT managers respond by manipulating the system\u2019s\ninter-connectedness. Such response is calculated optimally given the architecture of the system,\nas captured by the parameters, the managers\u2019 preferences, and behaviour as captured by w1, w2,\nw3, and \u03b7, given the choice of targets C\u00af, A\u00af, and K\u00af.\nKnowledge of the existence of patches creates an expectation of a loss of both C and A. This\nnegative expectation triggers the patching response. Managers act upon expectations of patch\narrivals, P(x(t)), and plan for their implementation.\n4 A Patching Model\nIn this section, following the methodology of Section 3.1, for the system given in Section 3.2, we\ndescribe the threat environment represented by the arrival of patches, in the presence of fixed and\nvariable costs, and compute the optimal responses to approximate Equation 6. In this context, the\nvector control variate is the number of regular and irregular patches.\nPatches are interpreted as shocks to the confidentiality and availability of the system. That is,\nthe arrival of a patch (which is intended to be applied to the system) signals the existence of a\nvulnerability in the system\u2019s confidentiality or availability, because it admits the possibility of a\nbreach.\nPatches are considered to be a non-decreasing Cox-type point process [15], yt, with Poisson-type\narrivals, \u03a6 (t) |\u03b8\u03a6, and bivariate log-normal intensities \u03a8 (t) |\u03b8\u03a8 .\nThe Poisson process is a standard way of modelling independent arrivals and the log-normal\nis a single-tailed distribution which captures a random variable that arises as a product positive\nindependent random increments. Our choices represent a simplification of reality, but we believe it\nis a reasonable one. The vulnerabilities signalled by each patch have a an impact on confidentiality\nor availability described by Equation 12.[\ny1,t+\u2206t \u2212 y1,t\ny2,t+\u2206t \u2212 y2,t\n]\n=\n[\npi1,1 pi1,2\npi2,1 pi2,2\n] [\n\u03c81,t\n\u03c82,t\n]\n\u03c6t (12)\nThe parameter vector associated with the system consists of \u00b51, \u00b52, \u03c3\n2\n1 , \u03c3\n2\n2 , and the correlation\ncoefficient \u03c112. The matrix \u03a0, with components, pii,j , linearly decomposes the signal of the patch\n(albeit crude) measure of interconnectedness simply captures the extent to which the components of\nthe system are able to communicate with one another, thereby permitting data\/information located at\none component available to other components, but also permitting the propagation of malware.\nFor \u03be = 0, R = 1, so that the system amounts to a single isolated device. As \u03be \u2192 1, R \u2192 \u221e, and\nthe system amounts to a highly interconnected structure. We include the definition of R here only for\ncompleteness of presentation of the underlying model: we make no further use of it in this paper.\narrival to consequences for the availability and confidentiality of the system. The time t states\nof confidentiality Ct and availability At \u2014 the discrete-time equivalents of the continuous-time\nmeasures C(t) and A(t) \u2014 are based on a fully patched system, [C0, A0]\nT\n. In the presence of\npatches, confidentiality and availability evolve according to Equation 13:\n[\nCt\nAt\n]\n=\n[\nC0\nA0\n]\n\u2212 f\n[\ny1,t\ny2,t\n]\n(13)\nThe function f is a rescaling function to ensure that the patch information, contained in the\nevaluation of the intensities (\u03c81, \u03c82) at t, matches the appropriate scale of confidentiality and\navailability.\nIf the mapping of the vulnerabilities to confidentiality and availability is fully determined, then\nsuch stochastic decomposition is not required, thus significantly reducing the number of parameters\nto be estimated.\n4.1 Co-optimization and Decision Making\nWe consider a patching optimization problem, whereby the decision-maker has two instruments,\na long instrument, x1(t |t0, E(yt) ), which is a regular patching cycle taken at evenly spaced points\nin the time interval [t0, T ], and set prior to t0, and a short instrument, x2 (t), the decision to patch\nearly, taken within the interval t \u2208 [t0, T ].\nAt time t, the non-decreasing sequence of confidentiality and availability is as follows (notation:\n|\u2212 denotes dependency and \u2016 is read as \u2018or\u2019):\nt\u2032 |E(yt) \u2208\n[\nt0, t0 +\nT\nx1\n, t0 +\n2T\nx1\n, . . . , T\n]\n(14)\nCt+\u2206t =\n\uf8f1\uf8f2\uf8f3Ct +\u2206Ct |yt iff (t 6= t\n\u2032) \u2016(x2 = 0)\nC\u00af if t = t\u2032\nC\u00af if x2 > 0\n(15)\nAt+\u2206t =\n\uf8f1\uf8f2\uf8f3At +\u2206At |yt iff (t 6= t\n\u2032) \u2016(x2 = 0)\nA\u00af if t = t\u2032\nA\u00af if x2 > 0\n(16)\nIn the first cases of Equations 15 and 16, the system is vulnerable because patches have been\ninstalled neither by the utilization of the long nor the short instruments. All other cases denote\nthat the system has been patched.\nThe long instrument, x1, is an non-negative integer defining the number of regular patch\nimplementations during the planning period [t0, T ]. This process is considered to be the regular\npatching cycle and the associated required increases in information security capital stock are given\nas\nP1(x1(t)) = \u03bd expx1 (17)\nwhere \u03bd is the cost of implementing each patch.7\nImplementation of the short instrument, x2 (t), has two expenditure components: a fixed com-\nponent and an additional variable reflecting the extra expenditure requirements for patching ei-\nther side of the regular cycle. If x2(t) = 0, then no additional expenditure is required; that is,\nP2(x2(t)) = 0; otherwise, a convenient representation is given by the following equation:\nP2(x2(t)) = \u03c5 + \u03b1\u2032 (t\u2032\u2032 \u2212 x2)2 + \u03b2\u2032 (x2 \u2212 t\u2032)2 (18)\nwhere t\u2032\u2032 is the time of the next regular patch, t\u2032 is the timing of the previous regular patch, and\n\u03b1\u2032 and \u03b2\u2032 are structural parameters. In the case \u03b1\u2032 = \u03b2\u2032 = 0, there is no additional penalty for\ntiming the patch outside of the regular cycle. Patching under the short instrument is considered\n7 For x1 = 0, we define P1(x1) = 0.\nto be patching outside the regular cycle, constituting the irregular cycle: practitioners often refer\nto it as \u2018out-of-cycle\u2019 patching.\nP1 and P2 are the components of P that enter Equation 11 and increasing their size might\nlead to deviations from the target K\u00af.\n4.2 Analysis of the Model\nOur model offers a simple representation of patch arrivals and jump intensities, as the decision\nprocess is a continuous path decision problem (akin to the exercise choice of an American option).\nWe assume that the jumps are drawn from a log-normal distribution, as described in Equation 12,\nand they are decomposed according to their impact on confidentiality and availability, as described\nin Equation 13.\nClients face frequent, and low impact threats, in contrast to networks that encounter high\nimpact, low frequency threats. In both environments, implementing patches for both clients and\nnetworks incurs fixed and variable costs. The fixed costs of irregular patching are described in\nEquation 18 and the variable costs of regular patching are described in Equation 17. The fixed\ncosts are higher for networks. Similar models, with costly patching cycles, have been developed in\nterms of real options analysis; see, for example, the discussion by Gordon, Loeb, and Lucyshyn\n[15]. Within their modelling framework the threat environment characteristics are maintained, re-\nducing the decision-making trade-off to a simple minimization of costs associated with regular and\nevent-driven patching cycles. An innovative feature of our model is that IT managers\u2019 preference\nweightings, as expressed in Equation 5, reflecting the natures of their organizations, are important\nin determining patching policy.\nWhen vulnerabilities are disclosed and patches arrive, IT managers, in deciding the implemen-\ntation of patching operations, are taking into account the operational status of the system, as\nexpressed in Equation 7, the differential costs of regular (fixed time interval or fixed frequency,\nEquations 17 and 18) and irregular (ad hoc time interval or irregular frequency) patching, and\nthe impact of the threats on the system\u2019s characteristics (Equation 13). The managers\u2019 responses\nare captured by Equation 11, that incorporates the state of the system, in the presence of threats,\nand the cost of mitigations.\nBy choosing appropriate parameter constellations, we present numerical simulations based on a\ntwo organizational types (military and financial) and two particular cases of the patching problem\n(client and network). These examples are intended to demonstrate how the model may be used to\nguide policy, and are based on observations and interactions with practitioners.\nWe proceed, in Section 5, by providing a detailed account of the vectors of parameters and the\ncalculation of optimal patching frequencies for the given cases.\nWe have chosen to solve the model by simulation for the following reasons: the managers\u2019\nreaction, as represented by Equation 11, is path-dependent (and so does not have closed-form\nsolutions) as managers react to the continuous arrival of shocks; also, Equations 17 and 18 admit\nnon-convex forms.\n5 Numerical Simulations\nFor any given patch arrival path, and parameter constellation, we begin by searching for the\noptimal number of regular patching cycles. Conditional upon such finding, we compute the number\nirregular cycles. We repeat this process B (e.g., 1000, 10 000,. . . ) times, indexed by i, for each\nbootstrap iteration there n patches, indexed by j, drawn from the process given in Equation 12\nover T time intervals, indexed by t. We select the combination of x1 and x2 that provides the\nminimum expected loss as follows:\nmin\nx\n1\nB\nB\u2211\nj=1\nn\u2211\ni=1\nT\u2211\nt=1\n1\n2\u03b4\n\u2212tHi,j,t (19)\nIn Ioannidis, Pym, and Williams [25], we explain how different constellations of the parameters\nin the loss function and state equations, (5), (7), and (7), identify generic types of organizations.\nIn this paper, we adopt the constellations corresponding to the financial firm and the military\nestablishment, presented by Ioannidis, Pym, and Williams [25].\nThe additional parameters required in this paper, along with the system properties and the\ndecision-maker\u2019s preferences, are given in Table 1. Our choices of parameters are informed by exten-\nsive, reflective discussions with experienced practitioners. Certain parameters are easily identified,\nsuch as the rate of patch arrival, however the impact of vulnerabilities is more difficult to iden-\ntify. Part of ongoing research is to infer the impact of vulnerabilities from observing practitioner\nreactions to certain types of vulnerability and patching events. We emphasize that the extensive\nempirical studies (with all their well-documented attendant difficulties [24, 26\u201330]) that would be\nnecessary to obtain a more rigorous elicitation of preferences are beyond the scope of the present\npaper. For now, we require a plausible way to proceed and test the feasibility and value of the\noverall framing and modelling methods in the decision process, deferring consideration of more\nrigorous reference-elicitation methodologies to another occasion.\nCategory Parameters Description\nThreat Environment\n\u03b8\u03a6\n\u03b8\u03a81 = \u00b51\n\u03b8\u03a82 = \u00b52\n\u03b8\u03a83 = \u03c3\n2\n1\n\u03b8\u03a84 = \u03c3\n2\n2\n\u03b8\u03a85 = \u03c11,2\nPoisson process hyper-parameter\nMean of log-normal factor process 1\nMean of log-normal factor process 2\nVariance of log-normal factor process 1\nVariance of log-normal factor process 2\nCorrelation of factor process 1 and 2\nSystem Properties\n\u03bd\n\u03c5\n\u03b1\u2032\n\u03b2\u2032\npi1,1, . . . , pi2,2\nCost per regular patching cycle node\nCost of implementing an out-of-cycle patch\nEarly patch penalty parameter\nEarly patch penalty parameter\nPatch intensity to confidentiality and availability vulnerabilities\nDecision-maker\u2019s\nPreferences\n\u03c91\n\u03c92\n\u03c93\nC\u00af\nA\u00af\nK\u00af\nLoss function parameter: confidentiality\nLoss function parameter: availability\nLoss function parameter: investment\nTarget level of confidentiality\nTarget level of availability\nTarget level of investment\nTable 1. Parameter Categorization with Definitions\nThe parameters in the various categories given in Table 1 are set out as follows:\n\u2013 Threat Environment: The parameters can be estimated form observing histories of patch\narrivals and intensities;\n\u2013 System Properties: These are intrinsic to the configuration of the system;\n\u2013 Decision-maker\u2019s Preferences: These are determined by the managers\u2019 of the system to be\naligned with the relevant business processes.\nIn Table 5, we give numerical values of the parameters for both the financial and military\norganizations. For each type of organization, we assign values for both network and client patching\nenvironments. For implementation, the model is discretized using an Euler scheme[33], similar to\nthat employed in [25]. We compute by simulation the optimal patching frequencies (both regular\nand irregular) for both the client and network patching cases. We characterize the differential\nthreat environment for client and network as suggested in Table 2.\nClient patching is characterized by a relatively high value of parameter \u03b8\u03a6 (i.e., high-frequency\narrivals) and relatively low values of \u03b8\u03a81 (i.e., low impact events). In addition, the differential of\nTable 2. Suggested Parameter Hierarchies\n\u03b8\u03a6(client)\u001d \u03b8\u03a6(network) \u03c32(network)\u001d \u03c32(client)\n\u00b51(network)\u001d \u00b51(client) \u03c11,2(client) = \u03c11,2(network) = 0\n\u00b52(network)\u001d \u00b52(client) (\u03bd \u2212 \u03c5)(network)\u001d (\u03bd \u2212 \u03c5)(client)\n\u03c31(network)\u001d \u03c31(client)\nthe fixed costs of regular and irregular patching is negligible. Networking patching, however, is\ncharacterized by substantial cost differentials, low frequency, and high impact.\nTo simplify the model, we adopt a simple decomposition of the patching signal into availability\nand confidentiality as follows: in both cases pi1,1 = pi2,2 = 1 and pi1,2 = pi2,1 = 0. Specifically, the\nimpact on a system of an unpatched vulnerability results in a cost directly proportional to the\njump sizes of C and A.\nThe model is simulated over a period of 365 days, with patches arriving daily. Figures 2, 3, and\n4 depict the sample paths for the doubly stochastic process for network and client patches, together\nwith their decompositions into the confidentiality and availability factors. Over the period of the\nsimulation, network patching arrivals have low periodicity, with the decomposition of the factors\nbeing essentially symmetric. In contrast, client patching arrivals are approximately 3 12 times as\nfrequent. The average intensity of client patches is less than 13 that of network patches.\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n0\n20\n40\n60\n80\n100\n120\n140\n160\n0\n50\n100\n150\n200\nTime, \u0394t =\nT \u2212 t\n100\nNetwork Patching Simulation Pathways (200 Replications from 1000)\nFactor 1: y1 , t Shock to Con\ufb01dentiality\nFactor 2: y1 , t Shock to Availability\nFig. 2. Patch Arrivals (Network)\n5.1 Simulation Results for Different Organizations\nFor chosen sets of parameter values, we examine the model\u2019s response to cost of the irregular\npatching using, as the appropriate metric, the \u03c5\/\u03bd ratio. The adoption of this metric captures the\nimportance of cost in determining the optimal frequency of patching for a given threat environment.\nThe subsequent analysis computes the change (here decreasing) in the expected numbers of\nout-of-cycle patches deployed against the changing cost ratio of in- and out-of-cycle patching,\nwhilst holding the absolute cost of patching in-cycle constant.\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n0\n10\n20\n30\n40\n50\n60\n70\n80\n0\n20\n40\n60\n80\n100\n120\n140\n160\nTime, \u0394t =\nT \u2212 t\n100\nClient Patching Simulation Pathways (200 Replications from 1000)\nFactor 1: y1 , t Shock to Con\ufb01dentiality\nFactor 2: y1 , t Shock to Availability\nFig. 3. Patch Arrivals (Client)\n0 50 100 150 200 250\n0\n1\n2\n3\n4\n5\n6\nTime Index\nInt\nen\nsit\ny\nNetwork Patching Arrivals\n0 50 100 150 200 250\n0\n2\n4\n6\n8\n10\n12\nTime Index\nInt\nen\nsit\ny\nClient Patching Arrivals\nFactor, \u03c81\nFactor, \u03c82\nFactor, \u03c81\nFactor, \u03c82\nFig. 4. Confidentiality (\u03c81)\u2013Availability (\u03c82) Decompositions for Network and Client\n1 2 3 4 5 6\n0\n20\n40\n60\n80\nTime Between Cycle Patches\nCost Ratio\nD\nay\ns\n1 2 3 4 5 6\n0\n5\n10\n15\n20\nExpected Number of Out of Cycle Patches\nCost Ratio\nE\n(#\nP\nat\nch\nes\n)\n1 2 3 4 5 6\n0\n1\n2\n3\n4\n5\nStandard Deviation of Out of Cycle Patches\nCost Ratio\nst\nd(\n#P\nat\nch\nes\n)\nFig. 5. Military Client Patching. Upper graph: Expected number of out-of-cycle patches. Lower graph:\nStandard deviation of out-of-cycle patches\nClient Patching: Military versus Financial For client software patching, patches arrive often\nand have a low mean, albeit with a standard deviation that reflects the high variation in criticality\nbetween different client software \u00b5\u03c3 > 1 for both C and A.\nFigure 5 depicts against the cost ratio the expected number and standard deviation of out-\nof-cycle patches for a military organization, with parameter attributes shown in Table 1. We\ncalibrate the cost of cycle patches such that the number of out-of-cycle patches is consistent with\nthose observed in similar organizations with monthly patch management policies. Figure 6 presents\nthe same information for the financial organization.\nSeveral features are immediately apparent in this comparison. The difference between the\npreferences of the military and financial organizations results in a distinct profiles for out-of-cycle\npatching with respect to the same cost configurations. Military organizations ceteris paribus tend\nto apply more out-of-cycle patches than financial organizations, reflecting strong preference for\nconfidentiality at the expense of availability.\nThe standard deviation of out-of-cycle patches for military organizations, albeit modest, sug-\ngests a tolerance for some low-level risks. The variation characterized by the standard deviation is\nindicative of the different applications of the system in, for example, battlefield and support func-\ntions. This is consistent with the profile of military organizations with a more flexible approach\nto taking systems off-line than financial firms with higher cost penalties (dominant C, weighting\n\u03c91).\nFigures 7 and 8 present, for military and financial organizations, the managers\u2019 total discounted\nloss, and average longest wait (in days, over a year) for a patch to be applied against cost ratio.\nWe assume a discount rate of 6% per annum. Military organizations suffer higher losses through\nthreats and tend to wait less time to patch over all cost ratios compared to financial firms. For\nexample, given the same decomposition of the threat, and a cost ratio of 3, the maximum exposure\ntime for client patching by financial firms is 10 days, whilst for the military organization it is less\n1 2 3 4 5 6\n0\n20\n40\n60\n80\nTime Between Cycle Patches\nCost Ratio\nD\nay\ns\n1 2 3 4 5 6\n0\n2\n4\n6\n8\nExpected Number of Out of Cycle Patches\nCost Ratio\nE\n(#\nP\nat\nch\nes\n)\n1 2 3 4 5 6\n0\n1\n2\n3\nStandard Deviation of Out of Cycle Patches\nCost Ratio\nst\nd(\n#P\nat\nch\nes\n)\nFig. 6. Financial Client Patching. Upper graph: Expected number of out-of-cycle patches. Lower graph:\nStandard deviation of out-of-cycle patches\n1 2 3 4 5 6\n0\n0.5\n1\n1.5\n2\n2.5\n3\nExpected Total Loss\nCost Ratio\nRe\nal \nLo\nss\n1 2 3 4 5 6\n0\n5\n10\n15\n20\n25\n30\n35\nLongest Wait Until Patch Deployment\nCost Ratio\nEx\npo\nsu\nre\n tim\ne D\nay\ns\nFig. 7. Military Client Patching: Loss and longest wait\n1 2 3 4 5 6\n0\n0.2\n0.4\n0.6\n0.8\n1\n1.2\n1.4\n1.6\nExpected Total Loss\nCost Ratio\nRe\nal \nLo\nss\n1 2 3 4 5 6\n0\n10\n20\n30\n40\n50\nLongest Wait Until Patch Deployment\nCost Ratio\nEx\npo\nsu\nre\n tim\ne D\nay\ns\nFig. 8. Financial Client Patching: Loss and longest wait\nthan 6 days. Their losses stand at 0.9 and 1.5, respectively, reflecting the higher and unbalanced\nsensitivity of the military organization with respect to confidentiality. This sensitivity provides\nhigher amplification to the factor of the threat that is attached to confidentiality in comparison\nwith the factor assigned to availability. This profile is consistent throughout the range of simulated\ncost ratios.\nNetwork Patching Military versus Financial Network patches are far less frequent than\nclient patches, although the associated vulnerabilities are assumed to be uniformly more serious;\nthat is, \u00b5\u03c3 < 1, with a high average jump size \u00b5 for impacts on both C and A, and a higher level\nof correlation \u03c1 between jump sizes. The arrival rate is calibrated to an average of 6 patches per\nyear.\nAs in the client example, the upper graphs of Figures 9 and 10 present the expected number of\nout-of-cycle patches and the lower graphs of Figures 9 and 10 their respective standard deviations\nfor military and financial organizations. Figures 11 and 12 present the total expected loss and the\nmaximum tolerated exposure time for the two organizations.\nThe increased jump intensity of network (compared to client) vulnerabilities results in both\norganizations applying most patches as soon as they become available. In both cases, the standard\ndeviation associated with the expected number of patches is very small, implying that there\nis no tolerance of the persistence of such vulnerabilities. Comparing the military and financial\norganizations, our simulations show that for the military organization the range of the economically\nmeaningful cost ratio is about 3.8 For this range, all patches are implemented upon arrival. Unlike\n8 For this parameter constellation, for a cost ratio beyond about 3, the loss rises so rapidly that the model\ngives only a corner solution. The simulation algorithm searches for a solution with the range of 1 to 7\ndays. Beyond a cost ratio of about 3, jumps to the \u2018extreme value\u2019 of about 7, and stays there. The\nchange in early patch deployment is marked by a sudden switch away from instant patching at high cost\n1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6\n0\n2\n4\n6\n8\n10\nExpected Number of Out of Cycle Patches\nCost Ratio\nE(#\nPa\ntch\nes\n)\n1 1.2 1.4 1.6 1.8 2 2.2 2.4 2.6 2.8 3\n0\n2\n4\n6\n8\n10\nStandard Deviation of Out of Cycle Patches\nCost Ratio\nst\nd(#\nPa\ntch\nes\n)\nFig. 9. Military Network Patching. Upper graph: Expected number of out-of-cycle patches. Lower graph:\nStandard deviation of out-of-cycle patches\nthe financial firm, this shows that patch implementation is sensitive to the cost ratio over a wider\nrange. For the military organization, the longest wait until patch deployment is less than a day\nover the relevant range of the cost ratio, whilst, for the financial firm, the longest wait until patch\ndeployment extends to 9 days over the full range of the cost ratio.\nComparing the patching policies for client and network in the financial organization that is\nsensitive to the cost ratio, the longest wait until patch deployment is 5 times higher for clients\nthan for networks (45+ and 9, respectively). Similarly, for military organizations that exhibit a\nreduced sensitivity to the cost ratio, the difference, within the meaningful range, is between 3 days\nand 1 day (for a cost ratio of about 3).\nTables 3 and 4 summarize the main results from our simulations for the two organizations, for\nboth client and network patching. The tables illustrate clearly the distinct patching profiles of the\nfour situations.\nIn Table 3, the standard deviations correspond to the sensitivities of the same organizations\nto the relative severity of network and client threats.\nClient Network\nMilitary 5 (2.8) 6 (0)\nFinancial 2.2 (1.8) 0.75 (0.005)\nTable 3. Number of irregular patches (standard deviation), for cost ratio 3\nratios, instead of the gradual decline observed in client patching. This is indicative of network patching\nbeing a far more acute policy problem, with very sharp discontinuities.\n1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6\n0\n2\n4\n6\n8\n10\nExpected Number of Out of Cycle Patches\nCost Ratio\nE(\n#P\natc\nhe\ns)\n1 1.2 1.4 1.6 1.8 2 2.2 2.4 2.6 2.8 3\n0\n2\n4\n6\n8\n10\nStandard Deviation of Out of Cycle Patches\nCost Ratio\nst\nd(#\nPa\ntch\nes\n)\nFig. 10. Financial Network Patching. Upper graph: Expected number of out-of-cycle patches. Lower graph:\nStandard deviation of out-of-cycle patches\n1 2 3 4 5 6\n16\n16.5\n17\n17.5\n18\n18.5\n19\n19.5\n20\nExpected Total Loss\nCost Ratio\nRe\nal \nLo\nss\n1 2 3 4 5 6\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\nLongest Wait Until Patch Deployment\nCost Ratio\nEx\npo\nsur\ne t\nime\n Da\nys\nFig. 11. Military Network Patching: Loss and longest wait\n1 2 3 4 5 6\n9\n10\n11\n12\n13\n14\n15\n16\nExpected Total Loss\nCost Ratio\nRe\nal \nLo\nss\n1 2 3 4 5 6\n1\n2\n3\n4\n5\n6\n7\n8\n9\nLongest Wait Until Patch Deployment\nCost Ratio\nEx\npo\nsur\ne t\nime\n Da\nys\nFig. 12. Financial Network Patching: Loss and longest wait\nSimilarly, Table 4 indicates that network patches are mostly deployed upon arrival despite the\nassociated cost.\nClient Network\nMilitary 6 0.5\nFinancial 10 3.5\nTable 4. Longest wait to patch deployment, for cost ratio 3\n6 Conclusions\nWe have introduced a model that develops a methodology for the determination of the optimal\nfrequency for implementing patches in both network and client environments. The model recognises\nthat patching is costly, but postponing deployment exposes the system to attacks by malware that\nmay impair its performance and may result in the exposure of data as well as financial losses.\nThe methodology in this paper is based on the dynamics of the trade-offs between the attributes\nof the system that are of interest to the system\u2019s information security managers, using methods of\noptimization that are commonly deployed in economics. Operationalizing our approach will require\nmore detailed models that more closely reflect the nature of specific organizations. Nevertheless,\nthe approach developed in this paper constitutes a solid methodological base for addressing these\nproblems.\nCategory Parameters\nFinancial\nNetwork\nFinancial\nClient\nMilitary\nNetwork\nMilitary\nClient\nThreat\nEnvironment\n\u03b8\u03a8\n\u03b8\u03a81\n\u03b8\u03a82\n\u03b8\u03a83\n\u03b8\u03a84\n\u03b8\u03a85\n0.001\n0.1\n0.1\n0.2\n0.2\n0.2\n0.1\n0.001\n0.001\n0.001\n0.001\n0\n0.001\n0.1\n0.1\n0.2\n0.2\n0.2\n0.1\n0.001\n0.001\n0.001\n0.001\n0\nSystem\nProperties\n\u03c5\n\u03bd\n\u03b1\u2032\n\u03b2\u2032\npi1,1, . . . , pi2,2\n\u2208 [1, 3]\n50%\n50%[\n1 0\n0 1\n]\n\u2208 [1, 3]\n20%\n20%[\n1 0\n0 1\n]\n\u2208 [1, 3]\n35%\n35%[\n1 0\n0 1\n]\n\u2208 [1, 3]\n20%\n20%[\n1 0\n0 1\n]\nDecision-\nmaker\u2019s\nPreferences\n\u03c91\n\u03c92\n\u03c93\nC\u00af\nA\u00af\nK\u00af\n0.5\n0.5\n0.1\n95%\n95%\nconstant\n0.5\n0.5\n0.1\n90%\n90%\nconstant\n0.9\n0.5\n0.1\n95%\n95%\nconstant\n0.7\n0.4\n0.1\n90%\n90%\nconstant\nTable 5. Example parameter constellations for patching management based on representative industry\ncalibrations\nFollowing the approach developed in this paper, the system\u2019s operational status is characterized\nby availability and confidentiality that are exposed to serious risk of degradation owing to the\npotential for exploitation of vulnerabilities, as signalled by the arrival of patches. The model\nis based on the recognition that both IT managers and users appreciate the trade-off between\nthe fundamental characteristics of information security considered here, namely confidentiality\nand availability. We have simplified our analysis by suppressing issues of integrity. The model\u2019s\nparameters can be clustered in a manner that allows us to categorize and compare the responses\nto shocks of various types of organizations.\nWe find that out-of-cycle patching is cost-sensitive and its deployment depends crucially on\nthe preferences of the organization. In the case of client patching, we see that patching on arrival\nis not optimal, although tolerances to exposure are limited for military-type organizations. In the\ncase of network patching, the military organization will patch on arrival for a wide range of cost\ndifferentials, whilst the financial organization exhibits a high degree of sensitivity to the same\nvariate.\nFinally, note that our approach does not rely for its predictions on the imputation of monetary\nlosses associated with information degradation, but rather on metrics that are familiar to the\ninformation security community. We expect, therefore, to be able to validate the predications of\nour model empirically.\nAcknowledgments\nWe are grateful to Yolanta Beres, Jonathan Griffin, and Simon Shiu (all at the Cloud and Security\nLab, HP Labs, Bristol) for their advice on the state of the art in (modelling) patching strategies\nfor both clients and networks. We are particularly grateful for their allowing us to reproduce their\ndiagram of the \u2018Vulnerability Timeline\u2019 from Beres et al. (2008) [9].\nReferences\n1. R. Anderson. Why information security is hard: An economic perspective. In Proc. 17th Annual\nComputer Security Applications Conference, 2001.\n2. R. Anderson, R. Bo\u00a8hme, R. Clayton, and T. Moore. Security economics and the internal market.\nReport to the European Network and Information Security Agency (ENISA), 2007, http:\/\/www.\nenisa.europa.eu\/doc\/pdf\/report_sec_econ_&_int_mark_20080131.pdf.\n3. R. Anderson and T. Moore. The economics of information security. Science, 314:610\u2013613, 2006.\nExtended version available at http:\/\/www.cl.cam.ac.uk\/~rja14\/Papers\/toulouse-summary.pdf.\n4. A. Arbaugh, W.L. Fithem, and J. McHugh. Windows of vulnerability: A case study analysis. IEEE\nComputer, 2000.\n5. A. Arora, R. Telang, and H. Xu. Optimal Policy for Software Vulnerability Disclosure. Management\nScience, 54(4):642\u2013656, 2008.\n6. T. August and T. Tunca. Network Software Security and User Incentives. Management Science,\n52(11):1703\u20131720, 2006.\n7. S. Beattie, S. Arnold, C. Cowans, P. Wagle, C. Wright, and A. Shostack. Timing the application of\nsecurity patches for optimal uptime. In LISA \u201902: 16th System Administration Conference, 2002.\n8. A. Beautement, R. Coles, J. Griffin, C. Ioannidis, B. Monahan, D. Pym, A. Sasse, and M. Wonham.\nModelling the Human and Technological Costs and Benefits of USB Memory Stick Security. In M. Eric\nJohnson, editor, Managing Information Risk and the Economics of Security, pages 141\u2013163. Springer,\n2008.\n9. Y. Beres, J. Griffin, S. Shiu, M. Heitman, D. Markle, and P. Ventura. Analysing the performance of\nsecurity solutions to reduce vulnerability exposure window. In Proceedings of the 2008 Annual Com-\nputer Security Applications Conference, pages 33\u201342. IEEE Computer Society Conference Publishing\nServices (CPS), 2008.\n10. Y. Beres, D. Pym, and S. Shiu. Decision support for systems security investment. In Network Op-\nerations and Management Symposium Workshops (NOMS Wksps), 2010 IEEE\/IFIP, pages 118\u2013125,\n2010. doi: 10.1109\/NOMSW.2010.5486590, ISBN: 978-1-4244-6037-3, INSPEC Accession Number:\n11502735.\n11. Catherine Bobtcheff and Stphane Villeneuve. Technology choice under several uncertainty sources.\nEuropean Journal of Operational Research, 206(3):586\u2013600, 2010.\n12. H. Cavusoglu, H. Cavusoglu, and J. Zhang. Security Patch Management: Share the Burden or Share\nthe Damage. Management Science, 54(4):657\u2013670, 2008.\n13. M. Collinson, B. Monahan, and D. Pym. Semantics for structured systems modelling and simulation.\nIn Proc. Simutools 2010. ICST: ACM Digital Library and EU Digital Library, 2010. ISBN: 78-963-\n9799-87-5.\n14. G. Coulouris, J. Dollimore, and T. Kindberg. Distributed Systems: Concepts and Design. Addison\nWesley, 2005.\n15. D.R. Cox and V. Isham. Point Processes. Monographs on Statistics and Applied Probability. Chapman\nand Hall, 1980.\n16. Demos2k. http:\/\/www.demos2k.org.\n17. S. Frei, M. May, U. Fiedler, and B. Plattner. Large-scale vulnerability analysis. In Proc. of SIG-\nCOMM\u201906 Workshop. Association for Computing Machinery, 2006. Available at www.techzoom.net\/\npapers\/sigcomm_lsad_large_scale_vulnerability_analysis_2006.pdf.\n18. M.P. Giannoni and M. Woodford. Optimal Interest-Rate Rules I: General Theory. Working Paper\nSeries 9419, National Bureau of Economic Research, 2002. ISSU 9419, ISSN 0898-2937.\n19. Gnosis. http:\/\/www.hpl.hp.com\/research\/systems_security\/gnosis.html.\n20. L. Gordon, M. Loeb, and W. Lucyshyn. Information security expenditures and real options: A wait-\nand-see approach. Computer Security Journal, 19(2):1\u20137, 2003.\n21. L.A. Gordon and M.P. Loeb. The Economics of Information Security Investment. ACM Transactions\non Information and Systems Security, 5(4):438\u2013457, 2002.\n22. L.A. Gordon and M.P. Loeb. Managing Cybersecurity Resources: A Cost-Benefit Analysis. McGraw\nHill, 2006.\n23. Kjell Hausken and Vicki M. Bier. Defending against multiple different attackers. European Journal\nof Operational Research, 211(2):370 \u2013 384, 2011.\n24. J.C. Hersey, H.C. Kunreuther, and P.J. Shoemaker. Sources of bias in assessment procedures for\nutility functions. Management Science, 28:936\u2013953, 1982.\n25. C. Ioannidis, D. Pym, and J. Williams. Investments and trade-offs in the economics of information\nsecurity. In Roger Dingledine and Philippe Golle, editors, Proceedings of Financial Cryptography\nand Data Security \u201909, volume 5628 of LNCS, pages 148\u2013166. Springer, 2009. Preprint available at\nhttp:\/\/www.cs.bath.ac.uk\/~pym\/IoannidisPymWilliams-FC09.pdf.\n26. J.Y. Jaffrey. Some experimental findings on decision-making under risk and their implications. Euro-\npean Journal of Operational Research, 38:301\u2013306, 1989.\n27. A. Jimene\u00b4z, S. Ros-Insua, and A. Mateos. A decision support system for multi-attribute utility\nevaluation based on imprecise assignments. Decision Support Systems, 36:65\u201379, 2003.\n28. E. Jonsson and A. Olovsson. Quantitative model of the security intrusion process based on attacker\nbehaviour. IEEE Transactions on Software Engineering, 23(4):235\u2013245, 1997.\n29. R.L. Keeney and H. Raiffa. Decisions with Multiple Objectives: Preferences and Value Trade-offs.\nWiley, 1976.\n30. M. McCord and R. de Neufville. Lottery equivalents: reduction of the certainty effect problem in\nutility assessment. Management Science, 32:56\u201361, 1986.\n31. R.A. Nobay and D.A. Peel. Optimal Discretionary Monetary Policy in a Model of Asymmetric Bank\nPreferences. Economic Journal, 113(489):657\u2013665, 2003.\n32. Enrico Pennings and Onno Lint. Market entry, phased rollout or abandonment? a real option approach.\nEuropean Journal of Operational Research, 124(1):125 \u2013 138, 2000.\n33. P. Protter and D. Talay. The Euler Scheme for Levy Driven Stochastic Differential Equations. The\nAnnals of Probability, 25(1):393\u2013423, 1997.\n34. B. Schneier. Managed security monitoring: Closing the window of exposure. Counterpane Internet\nSecurity. Manuscript available at: http:\/\/www.counterpane.com\/window.pdf, 2000.\n"}
{"doi":"10.1109\/TCST.2010.2084088","coreId":"140624","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/5490","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/5490","10.1109\/TCST.2010.2084088"],"title":"A Conjugate Gradient-Based BPTT-Like Optimal Control Algorithm With Vehicle Dynamics Control Application","authors":["Kasac, Josip","Deur, Josko","Novakovic, Branko","Kolmanovsky, Ilya V.","Assadian, Francis"],"enrichments":{"references":[{"id":37944200,"title":"A BPTT-like optimal control algorithm with vehicle dynamics control application,\u201d","authors":[],"date":"2008","doi":"10.1115\/imece2008-67319","raw":"J. Kasa\u0107, J. Deur, B. Novakovi\u0107, and I. Kolmanovsky, \u201cA BPTT-like optimal control algorithm with vehicle dynamics control application,\u201d ASME International Mechanical Engineering Congress & Exposition, October 31-November 6, 2008, Boston, Massachusetts, USA.","cites":null},{"id":37944206,"title":"A Conjugate Gradient-based BPTT-like Optimal Control Algorithm,\u201d","authors":[],"date":"2009","doi":"10.1109\/cca.2009.5281028","raw":"J. Kasa\u0107, J. Deur, B. Novakovi\u0107, and I. Kolmanovsky, \u201cA Conjugate Gradient-based  BPTT-like  Optimal  Control  Algorithm,\u201d  IEEE International  Conference  on  Control  Applications,  July  8-10,  2009, Saint Petersburg, Russia.","cites":null},{"id":37944204,"title":"Advanced supervised learning in multi-layer perceptrons - From backpropagation to adaptive learning algorithms,\u201d","authors":[],"date":"1994","doi":"10.1016\/0920-5489(94)90017-5","raw":"M.  Riedmiller,  \u201cAdvanced  supervised  learning  in  multi-layer perceptrons - From backpropagation to adaptive learning algorithms,\u201d Int. J. Comput. Standards Interfaces, vol. 16, pp. 265, 1994.","cites":null},{"id":37944180,"title":"Application of sparse nonlinear programming to trajectory optimization,\u201d","authors":[],"date":"1992","doi":"10.2514\/3.20819","raw":"J.  T.  Betts  and  W.  P.  Huffman,  \u201cApplication  of  sparse  nonlinear programming  to  trajectory  optimization,\u201d  J.  Guidance  Control Dynamics, vol. 15, no. 1, pp. 198-206, 1992.","cites":null},{"id":37944196,"title":"Applied Optimal Control, Hemisphere Publishing Corp,","authors":[],"date":"1975","doi":null,"raw":"A.  E.  Bryson  and  Y.  Ho,  Applied  Optimal  Control,  Hemisphere Publishing Corp, 1975.","cites":null},{"id":37944205,"title":"Back propagation family album,\u201d","authors":[],"date":"1996","doi":null,"raw":"C. G. H. Jondarr, \u201cBack propagation family album,\u201d Technical Report C\/TR96-05, Macquarie University, August 1996.","cites":null},{"id":37944197,"title":"Backpropagation through time: What it does how to do it,\u201d","authors":[],"date":"1990","doi":"10.1109\/5.58337","raw":"P. J. Werbos, \u201cBackpropagation through time: What it does how to do it,\u201d Proceedings of the IEEE, vol. 78, no. 10, pp. 1550-1560, 1990.","cites":null},{"id":37944186,"title":"Computational Methods in Optimization,","authors":[],"date":"1971","doi":"10.2307\/2005111","raw":"E.  Polak,  Computational  Methods  in  Optimization,  Academic  Press, New York, 1971.","cites":null},{"id":37944188,"title":"Direct and indirect methods for trajectory optimization,\u201d","authors":[],"date":"1992","doi":"10.1007\/bf02071065","raw":"O.  von  Stryk,  and  R.  Bulirsch,  \u201cDirect  and  indirect  methods  for trajectory optimization,\u201d Annals of Operations Research, vol. 37, pp. 357-373, 1992.","cites":null},{"id":37944185,"title":"Dynamic Optimization,","authors":[],"date":"1999","doi":"10.1016\/s0005-1098(02)00084-5","raw":"A. E., Bryson, Dynamic Optimization, Addison-Wesley, 1999.","cites":null},{"id":37944181,"title":"Impe, \u201cOptimal control theory - A generic tool for identification and control of (Bio-)","authors":[],"date":"2002","doi":"10.1016\/s1367-5788(02)80012-8","raw":"I. Y. M. Smets, K. J. E. Versyck and J. F. M. Van Impe, \u201cOptimal control theory - A generic tool for identification and control of (Bio-) Chemical  Reactors,\u201d  Annual  Reviews in Control,  vol.  26,  pp. 57-73, 2002.","cites":null},{"id":37944194,"title":"Neural network application to optimal control of nonlinear systems,\u201d","authors":[],"date":"2001","doi":"10.1115\/imece2008-67319","raw":"J.  Kasa\u0107  and  B.  Novakovi\u0107,  \u201cNeural  network  application  to  optimal control  of  nonlinear  systems,\u201d  Proceedings  of  7-th  International Conference on Computer Aided Optimum Design of Structures, May 28-30, 2001, Bologna,  Italy, pp. 359-368.","cites":null},{"id":37944201,"title":"Numerical Optimization,","authors":[],"date":"2006","doi":"10.1007\/b98874","raw":"J. Nocedal and  S. J. Wright, Numerical Optimization, Springer, New York, 2006.","cites":null},{"id":37944189,"title":"Numerical solution of optimal control problems by direct collocation,\u201d","authors":[],"date":"1993","doi":"10.1007\/978-3-0348-7539-4_10","raw":"O. von Stryk, \u201cNumerical solution of optimal control problems by direct collocation,\u201d  in:  Bulirsch  R.,  Miele  A.,  Stoer  J.,  Well  K.H.  (eds.), Optimal Control-Calculus of Variations, Optimal Control Theory and Numerical  Methods,  International  Series  of  Numerical  Mathematics, vol. 111, Basel, Birkhauser, pp. 129\u2013143, 1993.","cites":null},{"id":37944191,"title":"Optimal control of nonlinear systems using neural networks,\u201d","authors":[],"date":"1998","doi":null,"raw":"J. Kasa\u0107, \u201cOptimal control of nonlinear systems using neural networks,\u201d M. Sc. Thesis (in Croatian), University of Zagreb, 1998.","cites":null},{"id":37944182,"title":"Optimal control of the industrial robot Manutec,\u201d","authors":[],"date":"1994","doi":"10.1007\/978-3-0348-8497-6_30","raw":"O.  von  Stryk  and  M.  Schlemmer,  \u201cOptimal  control  of  the  industrial robot  Manutec,\u201d  in:  Bulirsch,  R.,  Kraft  D.  (eds.),  Computational Optimal Control, International Series of Numerical Mathematics 115, Basel, Birkhauser, pp. 367-382, 1994.","cites":null},{"id":37944184,"title":"Optimal control techniques for assessing feasibility and defining subsystem level requirements: An automotive case study,\u201d","authors":[],"date":"2001","doi":"10.1109\/87.918904","raw":"I.  V.  Kolmanovsky,  and  A.  G.  Stefanopoulou,  \u201cOptimal  control techniques  for  assessing  feasibility  and  defining  subsystem  level requirements:  An  automotive  case  study,\u201d  IEEE  Trans.  on  Control System Technology, vol. 9, no. 3, pp. 524-534, May 2001.","cites":null},{"id":37944202,"title":"Practical Mathematical Optimization,","authors":[],"date":"2005","doi":"10.1007\/b105200","raw":"J.  A.  Snyman,  Practical  Mathematical  Optimization,  Springer,  New York, 2005.","cites":null},{"id":37944187,"title":"Practical Methods for Optimal Control using Nonlinear Programming,","authors":[],"date":"2001","doi":"10.1137\/1.9780898718577","raw":"J.  T.  Betts,  Practical  Methods  for  Optimal  Control  using  Nonlinear Programming,  Society  of  Industrial  and  Applied  Mathematics, Philadelphia, PA, 2001.","cites":null},{"id":37944199,"title":"Solving Ordinary Differential Equations I - Nonstiff Problems,","authors":[],"date":"1993","doi":"10.1137\/1032091","raw":"E. Hairer, S. P. Norsett, and G. Wanner, Solving Ordinary Differential Equations I - Nonstiff Problems, 2nd ed., Springer, Berlin, 1993.","cites":null},{"id":37944207,"title":"Space Vehicle Dynamics and Control,","authors":[],"date":"1998","doi":"10.2514\/4.860119","raw":"B. Wie, Space Vehicle Dynamics and Control, AIAA Education Series, 1998.","cites":null},{"id":37944203,"title":"Supersab: Fast adaptive backpropagation with good scaling properties,\u201d","authors":[],"date":"1990","doi":"10.1016\/0893-6080(90)90006-7","raw":"T.  Tollenaere,  \u201cSupersab:  Fast  adaptive  backpropagation  with  good scaling properties,\u201d Neural Networks, no. 3, vol. 5, 1990.","cites":null},{"id":37944190,"title":"Theory and implementation of numerical methods based on Runge-Kutta integration for solving optimal control problems,\u201d","authors":[],"date":"1996","doi":null,"raw":"A.  L.  Schwartz,  \u201cTheory  and  implementation  of  numerical  methods based  on  Runge-Kutta  integration  for  solving  optimal  control problems,\u201d PhD Thesis, University Of California At Berkeley, 1996.","cites":null},{"id":37944198,"title":"Vehicle handling control using active differentials,\u201d Ph.D. Thesis,","authors":[],"date":"2006","doi":null,"raw":"M.  Hancock,  \u201cVehicle  handling  control  using  active  differentials,\u201d Ph.D. Thesis, University of Loughborough, UK, 2006.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-11-01T00:00:00Z","abstract":"The paper presents a gradient-based algorithm for optimal control of nonlinear multivariable systems with control and state vectors constraints. The algorithm has a backward-in-time recurrent structure similar to the backpropagation-through-time algorithm, which is mostly used as a learning algorithm for dynamic neural networks. Other main features of the algorithm include the use of higher order Adams time-discretization schemes, numerical calculation of Jacobians, and advanced conjugate gradient methods for favorable convergence properties. The algorithm performance is illustrated on an example of off-line vehicle dynamics control optimization based on a realistic high-order vehicle model. The optimized control variables are active rear differential torque transfer and active rear steering road wheel angle, while the optimization tasks are trajectory tracking and roll minimization for a double lane change maneuver","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/140624.pdf","fullTextIdentifier":"https:\/\/dspace.lib.cranfield.ac.uk\/bitstream\/1826\/5490\/1\/Optimal_Control_Algorithm-2010.pdf","pdfHashValue":"b9eef20d33026b2cf306ae5f9e542a413ff48cde","publisher":"Institute of Electrical and Electronics Engineers","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/5490<\/identifier><datestamp>2014-02-18T10:09:19Z<\/datestamp><setSpec>hdl_1826_19<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>A Conjugate Gradient-Based BPTT-Like Optimal Control Algorithm With Vehicle Dynamics Control Application<\/dc:title><dc:creator>Kasac, Josip<\/dc:creator><dc:creator>Deur, Josko<\/dc:creator><dc:creator>Novakovic, Branko<\/dc:creator><dc:creator>Kolmanovsky, Ilya V.<\/dc:creator><dc:creator>Assadian, Francis<\/dc:creator><dc:subject>Automotive applications , conjugate gradient methods , optimal control , road vehicle control , vehicle dynamics<\/dc:subject><dc:description>The paper presents a gradient-based algorithm for optimal control of nonlinear multivariable systems with control and state vectors constraints. The algorithm has a backward-in-time recurrent structure similar to the backpropagation-through-time algorithm, which is mostly used as a learning algorithm for dynamic neural networks. Other main features of the algorithm include the use of higher order Adams time-discretization schemes, numerical calculation of Jacobians, and advanced conjugate gradient methods for favorable convergence properties. The algorithm performance is illustrated on an example of off-line vehicle dynamics control optimization based on a realistic high-order vehicle model. The optimized control variables are active rear differential torque transfer and active rear steering road wheel angle, while the optimization tasks are trajectory tracking and roll minimization for a double lane change maneuver.<\/dc:description><dc:publisher>Institute of Electrical and Electronics Engineers<\/dc:publisher><dc:date>2014-02-15T05:01:09Z<\/dc:date><dc:date>2014-02-15T05:01:09Z<\/dc:date><dc:date>2010-11-01T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>Josip Kasac, Josko Deur, Branko Novakovic, \nIlya V. Kolmanovsky and Francis Assadian, A Conjugate Gradient-Based BPTT-Like Optimal Control Algorithm With Vehicle Dynamics Control Application, IEEE Transactions on Control Systems Technology, Volume 19, Issue 6, 2011, Pages 1587 - 1595.<\/dc:identifier><dc:identifier>1063-6536<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1109\/TCST.2010.2084088<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/5490<\/dc:identifier><dc:rights>\u00a9 2011 IEEE. Personal use of this material is permitted. However, permission to reprint\/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE.<\/dc:rights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:1063-6536","1063-6536"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2010,"topics":["Automotive applications , conjugate gradient methods , optimal control , road vehicle control , vehicle dynamics"],"subject":["Article"],"fullText":" 1 \n  \nAbstract\u2014The paper presents a gradient-based algorithm for \noptimal control of nonlinear multivariable systems with control \nand state vectors constraints. The algorithm has a backward-in-\ntime recurrent structure similar to the backpropagation-through-\ntime (BPTT) algorithm, which is mostly used as a learning \nalgorithm for dynamic neural networks. Other main features of \nthe algorithm include the use of higher order Adams time-\ndiscretization schemes, numerical calculation of Jacobians, and \nadvanced conjugate gradient methods for favorable convergence \nproperties. The algorithm performance is illustrated on an \nexample of off-line vehicle dynamics control optimization based \non a realistic high-order vehicle model. The optimized control \nvariables are active rear differential torque transfer and active \nrear steering road wheel angle, while the optimization tasks are \ntrajectory tracking and roll minimization for a double lane \nchange maneuver. \n \nIndex Terms\u2014Optimal control, conjugate gradient methods, \nautomotive applications, road vehicle control.  \n \nI. INTRODUCTION \nPTIMAL control has found its applications in many \ndifferent engineering fields, including aerospace [1], \nprocess control [2], robotics [3] , and automotive control [4,5]. \nAny control system that includes complex dynamics with \nconstraints is a good candidate for applying optimal control. \nThe main aim is to find control variable trajectories that \nminimize an optimization criterion in the presence of \ninequality and equality constraints on the control and state \nvariables. By doing this in an off-line manner [1-5], the \noptimal control results can be used to assess the performance \n \nManuscript received October 9, 2009. This work has been supported by \nFord Motor Company, and partly by Jaguar Cars Ltd. and the Ministry of \nScience, Education and Sports of the Republic of Croatia. \nJosip Kasa\u0107, Jo\u0161ko Deur, and Branko Novakovi\u0107 are with the Faculty of \nMechanical Engineering and Naval Architecture, University of Zagreb, I. \nLu\u010di\u0107a 5, HR-10002 Zagreb, Croatia (e-mail: josip.kasac@fsb.hr; \njosko.deur@fsb.hr; branko.novakovic@fsb.hr).  \nIlya Kolmanovsky was with the Ford Research and Advanced Engineering \nat the time of writing this paper; he is now with the Department of Aerospace \nEngineering, University of Michigan, 1320 Beal Avenue, Ann Arbor, MI \n48109-2140 (e-mail: ilya@umich.edu). \nFrancis Assadian was with Jaguar Cars Ltd, UK at the time of writing this \npaper. Currently, he is with the Cranfield University, Department of \nAutomotive Engineering, Bedfordshire MK43 0AL, UK, (e-mail: \nf.assadian@cranfield.ac.uk). \nof control systems with different hardware and actuator \nconfigurations, set realistic targets for achievable system \nperformance, cascade targets to subsystems and components, \nand guide control system design and calibration process. For \nexample, prior to deciding on the vehicle dynamics actuators \n(e.g. active front\/rear steering and active central\/rear \ndifferential) and developing related on-line controls, the \noptimization results can provide valuable information on \nquality of various actuator configurations and establish an \n\"idealized\" benchmark to compare different control solutions \nand calibration in terms of their closeness to the ideal \nperformance. \nThe numerical methods of solving optimal control \nproblems can be divided into two categories: direct and \nindirect methods. Indirect methods based on Pontrjagin's \nmaximum principle lead to numerical solution of the two-point \nboundary value problem using multiple shooting or quasi-\nlinearization [6], [7]. Direct methods transform the original \ncontinuous-time optimal control problem into a finite-\ndimensional nonlinear programming (NLP) problem, which \ncan be solved by various NLP numerical optimization \nalgorithms such as sequential quadratic programming (SQP) \n[8-11]. The continuous-time state and\/or control variables are \nrepresented by a finite number of parameters by time-\ndiscretization or by using suitable basis functions such as B-\nsplines or Lagrange polynomials. \nThe main disadvantage of indirect methods is their need for \na good initial guess of the initial conditions for the adjoint \nvariables in order to converge. Also, this approach requires \nsymbolic differentiation to obtain adjoint equations. On the \nother hand, the direct methods are characterized by a large and \nsparse structure of Jacobian and Hessian matrices, so that they \ncan be computationally expensive for large systems. Direct \nmethods are mainly applied in industrial optimization \nproblems requiring fast and numerically robust optimization, \nwhile allowing for less accurate solutions. \nIn the NLP approach, the plant equation constraints are \nadded into the cost function in extension to the penalty \nfunctions related to the state and control constraints. The \ncontrol and state variables are treated as independent \nvariables, so that the cost function gradient calculation is \nrelatively simple. However, the optimization problem \nformulated in such a way may be characterized by a slow \nA Conjugate Gradient-Based BPTT-like \nOptimal Control Algorithm with Vehicle \nDynamics Control Application  \nJosip Kasa\u0107, Jo\u0161ko Deur, Senior Member, IEEE, Branko Novakovi\u0107, Senior Member, IEEE,                                \nIlya V. Kolmanovsky, Fellow, IEEE and Francis Assadian \nO \n 2 \nconvergence due to the additional plant-equations equality \nconstraints. Also, the numerical stability may be affected by \nthe choice of various optimization parameters such as \ndiscretization period and weighting factors of penalty \nfunctions. \nAn alternative direct approach of solving the optimal control \nproblem is proposed by the authors in [12] and [13]. In \ncontrast to the NLP approach, the plant equations constraints \nare not included in the cost function. The control and state \nvariables are treated as dependent variables (coupled via plant \nequations), so that the final algorithm has a backward-in-time \nstructure similar to the backpropagation-through-time (BPTT) \nalgorithm [14], [15], which is mostly used as a learning \nalgorithm for recurrent neural networks. Such an exact \ngradient algorithm is more complex than the NLP-based \nalgorithm, but it may provide better and numerically more \nstable convergence properties. The algorithm has been applied \nfor solving optimal control problems in the fields of robotics \n[12] and vehicle dynamics control [5]. \nIn order to further enhance its optimization accuracy and \nconvergence properties, the original BPTT algorithm [12,13,5] \nis extended in this paper by: (i) higher-order Adams numerical \nintegration schemes instead of the basic Euler discretization \nmethod, (ii) a straightforward derivation of gradient \nexpressions based on introducing a terminal cost function, (iii) \nnumerical calculation of Jacobians, and (iv) implementation of \nmore advanced, conjugate gradient methods. Exact gradient \nderivation based on the BPTT approach and higher-order \nAdams methods represents a key feature of the proposed \napproach and a novel contribution. It is precisely this \ncombination that, through our numerical case studies, has been \nproven to be effective, numerically robust, and capable of \nhandling models with complexity realistic for industrial \napplications. In regard to the vehicle dynamics control case \nstudy, a full 10-DOF vehicle model comprising a full \"magic\" \nformula tire model is used instead of a simplified vehicle\/tire \nmodel considered in [5]. \nII. OPTIMAL CONTROL PROBLEM FORMULATION \nA. Continuous-Time Problem Formulation \nA continuous-time nonlinear optimal control problem is \nconsidered. The problem is to find a control vector input u(t), \n0 \u2264 t \u2264 tf, which minimizes the Bolza-type cost function \n ( ) ( )0 0 0\n0\n( ) ( ), ( )\nft\nfJ t F t t dt= \u03a6 + \u222bx x u\n) )\n,  (1) \nsubject to the nonlinear continuous-time plant equations \n ( ) ( ) 0( ) ( ), ( ) , 0 ,t t t= =x x u x x) ) ) )& \u03c6   (2) \nand subject to the final conditions on the state vector \n ( )( ) 0,ft =b x)   (3) \nand subject to the control and state vector inequality \nconstraints \n ( )( ), ( ) 0t t \u2265g x u) ,  (4) \nand equality constraints \n ( )( ), ( ) 0t t =h x u) ,  (5) \nwhere ( )tx)  is an n0-dimensional state vector, u(t) is an m-\ndimensional control vector, g( ( )tx) , u(t)) is a p-dimensional \nvector function of inequality constraints, h( ( )tx) , u(t)) is a q-\ndimensional vector function of equality constraints, b( ( )ftx\n) ) \nis a r-dimensional vector function of final boundary condition \nconstraints, and tf is the terminal time. We assume that 0 ( )F \u22c5 , \n0 ( )\u03a6 \u22c5 , ( )\u22c5\u03c6 , ( )\u22c5b , ( )\u22c5g , and ( )\u22c5h  are continuously \ndifferentiable functions. \nIn general, additional constraints which ensure robustness \nmay be augmented to the optimal control problem formulation \nto avoid regions with large model uncertainties (which the \noptimization may otherwise incorrectly exploit) or to reduce \nparametric sensitivity of optimized control input trajectories \n(see e.g. [26, Chap. 10]). \nB. Transformation of Continuous-Time Optimization \nProblem \nThe optimization problem (1)-(5) can be reduced to the \nproblem of finding the control vector u(t) that minimizes the \ncost function \n ( ) ( )\n0\n( ) ( ), ( )\nft\nfJ t F t t dt= \u03a6 + \u222bx x u\n) )\n,  (6) \nsubject to the plant equations \n ( ) 0( ) ( ), ( ) , (0) ,t t t= =x x u x x) ) ) )& \u03c6   (7) \nwhere \n( ) ( ) ( )\n( ) ( )( )\n2\n0 ,\n1\n2\n,\n1\n( ), ( ) ( ), ( ) ( ), ( )\n( ), ( ) ( ), ( ) ,\nq\nh k k\nk\np\ng k k k\nk\nF t t F t t K h t t\nK g t t H g t t\n=\n\u2212\n=\n= + +\n+\n\u2211\n\u2211\nx u x u x u\nx u x u\n) ) )\n) )\n  (8) \n ( ) ( ) ( )20 ,\n1\n( ) ( ) ( )\nr\nf f b k k f\nk\nt t K b t\n=\n\u03a6 = \u03a6 +\u2211x x x\n) ) )\n,  (9) \nand H\u2212(z) is Heaviside step function defined as  \n ( ) 0, if 0 ,\n1, if 0.\nz\nH z\nz\n\u2212\n\u2265\uf8f1\n= \uf8f2\n<\uf8f3\n (10) \nThe second and third terms on the right-hand side of \nexpression (8) are the penalty functions for the inequality and \nequality constraints (4) and (5), respectively. Similarly, the \nsecond term on the right-hand side of expression (9) is the \npenalty function for the final boundary condition (3). Note that \nalthough the Heaviside step function ( )H z\u2212  is not continuous, \nthe penalty terms of the form 2 ( )z H z\u2212  in equation (8) are \n 3 \ncontinuously differentiable functions. The penalty function \ncoefficients Kh,k, Kg,k and Kb,k should be sufficiently large to \nprovide accurate constraints satisfaction. \nIn order to simplify application of higher-order numerical \nintegration methods for the plant equations (7) and the integral \nterm in the cost function (6), the problem (6)-(9) is \nreformulated, so that an additional state variable ( )nx t  is \nintroduced such that \n ( )( ), ( ) , (0) 0n nx F t t x= =x u)& , (11) \nwhere 0 1n n= + . Hence, the final continuous-time \noptimization problem is to find the control vector u(t) that \nminimizes the terminal cost function \n ( ) ( ) ( )( )f f n fJ t t x t= \u03a6 +x) , (12) \nsubject to the differential equations \n ( ) 0( ) ( ), ( ) , (0) ,t t t= =x f x u x x&  (13) \nwhere ( )tx  is the new n-dimensional state vector \n \n01 2( )\nT\nn nt x x x x\uf8ee \uf8f9= \uf8f0 \uf8fbx\n) ) )\nK ,   \nand \n \n02\nT\nn F1\uf8ee \uf8f9= \u03c6 \u03c6 \u03c6\uf8f0 \uf8fbf K . \n \nC. Time Discretization Based on Adams Method \nThe Adams method [17] belongs to the class of multistep \nnumerical methods for an approximate solution of the system \nof ordinary differential equations \n ( ) 0 0( ) ( ), ( ) , ( )t t t t= =x f x u x x& . (14) \nThe k-th order Adams method has the following form: \n \n( )\n1\n( 1) ( ) ( 1)\nk\nk\nj\nj\ni i a i j\u03c4\n=\n+ = + \u2212 +\u2211x x f , (15) \nfor 1, , 1,...i k k k= \u2212 + , and the initial conditions 0(0) =x x , \n1(1) =x x , 2(2) =x x , \u2026, 1( 1) kk \u2212\u2212 =x x ; where \u03c4 is the time \nstep, ( )kja  are the coefficients of the Adams method [17], and \n ( )( ) ( ), ( )i i i\u2261f f x u . (16) \nThe Adams method of the k-th order, as a multistep method, \nrequires knowledge of k initial conditions. These initial \nconditions are determined from the basic initial condition \n0(0) =x x  by using the 4th-order (one-step) Runge-Kutta \nmethod. \nThe explicit Adams method (15) is a k-th order vector \ndifference equation, which can be conveniently transformed \ninto the following discrete-time state-space form \n \n( )\n1\n( )\n( 1)1\n( )\n( 1)\n( 1) ( ) ( ) ( ),\n( 1) ( ) ( ),\n( 1) ( ),\nk\nj j j n j\nk\nrn j j r n jr\nk\nk n j jk\nx i x i a f i x i\nx i a f i x i\nx i a f i\n\u03c4 \u03c4 +\n+ + ++\n\u2212 +\n+ = + +\n+ = +\n+ =\n (17) \nfor r = 1,2,...,k\u22122, 1, 2,...,j n= , 1, , 1,...i k k k= \u2212 + , and the \ninitial conditions \n( 1)\n( )\n1\n( 1) ,\n( 1) ( 1 ) ,\nj j k\nk\nk\nqn j jl\nl q\nx k x\nx k a f k q l\n\u2212\n+\n= +\n\u2212 =\n\u2212 = \u2212 + \u2212\u2211\n \nfor q = 1,2,...,k\u22121. Finally, using the vector notation (cf. (13)), \nthe state-space form of the k-th order Adams method reads \n ( ) 0( 1) ( ), ( ) , (0)i i i+ = =x f x u x x%% % % % , (18) \nwhere ( )tx%  is the extended n k\u22c5 -dimensional state vector \n 1 2 1( )\nT\nn k n kt x x x x\u22c5 \u2212 \u22c5= \uf8ee \uf8f9\uf8f0 \uf8fbx% K ,   \nand \n \n( ) ( )\n1 1 11( ) ( ) ( ) ( )\nTk k\nn nkx i a f i x i a f i\u03c4 \u03c4 +\uf8ee \uf8f9= + +\uf8f0 \uf8fbf% K .  \n \nIII. BPTT OPTIMAL CONTROL ALGORITHM \nA. Discrete\u2013Time Optimization Problem \nThe discrete-time optimization problem is to find the \ncontrol sequence ( )iu , 0,1,..., 1i N= \u2212 , which minimizes the \ndiscrete-time form of the cost function (12): \n ( ) ( )( ) nJ N x N= \u03a6 +x) , (19) \nsubject to the k-th order Adams approximation of the \ncontinuous-time state equations (13): \n ( ) 0( 1) ( ), ( ) , (0)i i i+ = =x f x u x x%% % % % , (20) \nfor 1, , 1,..., 1i k k k N= \u2212 + \u2212 .  \nThe cost function J depends explicitly only on the state \nvector at the terminal time, ( )Nx , but an implicit dependence \non x(i) follows from the discrete-time state equations (20). \nThis fact will be used in derivation of the gradient decent \nalgorithm below for exact calculation of the gradient of cost \nfunction J with respect to control vector ( )iu , 0,1,..., 1i N= \u2212 .  \nB. Gradient Calculation \nThe gradient descent algorithm with respect to control \nvector is as follows: \n \n( ) ( ) ( ) ( ) ( ) ( )\n1\n,\nl l\nl\nJi i\ni\n\u03b7+ \u2202= \u2212\n\u2202\nu u\nu\n  (21) \nwhere i = 0, 1, \u2026, N-1,  l= 1, 2, \u2026, M, \u03b7 is the learning-rate, \nN is the number of time instants, and M is the number of \ngradient algorithm iterations. \nThe gradient of the cost function (19) in the l-th iteration of \nthe gradient algorithm and i-th sampling interval is given by \n ( ) ( )\n( )\n( )1\nnk\nr\nrj r j\nx NJ J\nu i x N u i\n=\n\u2202\u2202 \u2202\n=\n\u2202 \u2202 \u2202\u2211\n%\n%\n,  (22) \n 4 \nwhere 1, 2,...,j m= . The partial derivatives )(\/)(~ iuNx jr \u2202\u2202  \ncan be calculated backward in time, starting from 1i N= \u2212 :\n \n( )\n( )\n( )\n( )\n1\n1 1\nr r\nj j\nx N f N\nu N u N\n\u2202 \u2202 \u2212\n=\n\u2202 \u2212 \u2202 \u2212\n%%\n,  \nwhere ( ) ( )( ), ( )r rf i f i i\u2261 x u% % % , and 1,2,...,r nk= . Further, for \n2i N= \u2212 : \n \n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n1\n1\n11\n2 1 2\n21\n1 2\nnk\nqr r\nqj q j\nnk\nqr\nq q j\nx Nx N f N\nu N x N u N\nf Nf N\nx N u N\n=\n=\n\u2202 \u2212\u2202 \u2202 \u2212\n= =\n\u2202 \u2212 \u2202 \u2212 \u2202 \u2212\n\u2202 \u2212\u2202 \u2212\n=\n\u2202 \u2212 \u2202 \u2212\n\u2211\n\u2211\n% %%\n%\n%%\n%\n \nand for 3i N= \u2212 : \n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n( )\n1\n1\n1 1\n1 1\n11\n3 1 3\n21\n1 3\n2 21\n1 2 3\n2 31\n.\n1 2 3\nnk\nqr r\nqj q j\nnk\nqr\nq q j\nnk nk\nq pr\nq pq p j\nnk nk\nq pr\nq pq p j\nx Nx N f N\nu N x N u N\nf Nf N\nx N u N\nf N x Nf N\nx N x N u N\nf N f Nf N\nx N x N u N\n=\n=\n= =\n= =\n\u2202 \u2212\u2202 \u2202 \u2212\n= =\n\u2202 \u2212 \u2202 \u2212 \u2202 \u2212\n\u2202 \u2212\u2202 \u2212\n= =\n\u2202 \u2212 \u2202 \u2212\n\u2202 \u2212 \u2202 \u2212\u2202 \u2212\n= =\n\u2202 \u2212 \u2202 \u2212 \u2202 \u2212\n\u2202 \u2212 \u2202 \u2212\u2202 \u2212\n=\n\u2202 \u2212 \u2202 \u2212 \u2202 \u2212\n\u2211\n\u2211\n\u2211 \u2211\n\u2211 \u2211\n% %%\n%\n%%\n%\n%% %\n% %\n% %%\n% %\n \nBy introducing matrices ( )iU% , ( )iX% , )(iY  with the elements \n  ( ) ( )( )\ni\ni\ni\n\u2202\n=\n\u2202\nf\nU\nu\n%\n%\n,  ( ) ( )( )\ni\ni\ni\n\u2202\n=\n\u2202\nf\nX\nx\n%\n%\n%\n,  ( ) ( )( )\nN\ni\ni\n\u2202\n=\n\u2202\nx\nY\nu\n%\n, \nthe above derivatives )(\/)(~ iuNx jr \u2202\u2202 , i = N\u22121, N\u22122, N-3, can \nbe expressed in a more compact matrix form as \n )1(~)1( \u2212=\u2212 NN UY , (23) \n ( 2) ( 1) ( 2)N N N\u2212 = \u2212 \u2212Y X U% % , (24) \n ( 3) ( 1) ( 2) ( 3)N N N N\u2212 = \u2212 \u2212 \u2212Y X X U% % % . (25) \nThis procedure can be further continued as follows \n( 4) ( 1) ( 2) ( 3) ( 4)N N N N N\u2212 = \u2212 \u2212 \u2212 \u2212Y X X X U% % % % , (26) \n M  \n( ) ( 1) ( 2) ( 1) ( )i N N i i= \u2212 \u2212 +Y X X X U% % % %K . (27) \nBy introducing matrices )(iuJ  and )(NxJ  such that \n  ( )( )u\nJi\ni\n\u2202\n=\n\u2202\nJ\nu\n,    ( )( )x\nJN\nN\n\u2202\n=\n\u2202\nJ\nx%\n, \nthe final gradient )(iuJ  in (21) can be computed by the \nfollowing backward-in-time recursive matrix relations: \n ( ) ( ) ( )Tu xi i N=J Y J ,  (28) \n ( ) ( ) ( )i i i=Y D U% , (29) \n ( ) ( 1) ( 1)i i i= + +D D X% ,  (30) \nfor 2, 3, ...,0i N N= \u2212 \u2212 , with the initial conditions \n ( 1) ( 1) ( )Tu xN N N\u2212 = \u2212J U J% , (31) \n ID =\u2212 )1(N . (32) \nC. Calculation of Extended Jacobians \nThe extended Jacobians ( )iX%  and ( )iU%  can be expressed as \nfunctions of the basic Jacobians  \n  \n( )( ) ( )\nii\ni\n\u2202\n=\n\u2202\nfX\nx\n, \n( )( ) ( )\nii\ni\n\u2202\n=\n\u2202\nfU\nu\n, \nas given by the following equations based on (18): \n \n( )\n1\n( )\n2\n( )\n3\n( )\n1\n( )\n( )\n( )\n( )( )\n( )\n( )\nk\nk\nk\nk\nk\nk\nk\na i\na i\na i\ni\na i\na i\n\u03c4 \u03c4\n\u2212\n\uf8ee \uf8f9+\n\uf8ef \uf8fa\n\uf8ef \uf8fa\n\uf8ef \uf8fa\n= \uf8ef \uf8fa\n\uf8ef \uf8fa\n\uf8ef \uf8fa\n\uf8ef \uf8fa\n\uf8ef \uf8fa\uf8f0 \uf8fb\nI X I 0 0 0\nX 0 I 0 0\nX 0 0 0 0\nX\nX 0 0 0 I\nX 0 0 0 0\nL\nL\nL\n%\nM M M O M M\nL\nL\n, (33) \n \n( )\n1\n( )\n2\n( )\n3\n( )\n1\n( )\n( )\n( )\n( )( )\n( )\n( )\nk\nk\nk\nk\nk\nk\nk\na i\na i\na i\ni\na i\na i\n\u03c4\n\u2212\n\uf8ee \uf8f9\n\uf8ef \uf8fa\n\uf8ef \uf8fa\n\uf8ef \uf8fa\n= \uf8ef \uf8fa\n\uf8ef \uf8fa\n\uf8ef \uf8fa\n\uf8ef \uf8fa\n\uf8ef \uf8fa\uf8f0 \uf8fb\nU\nU\nUU\nU\nU\n%\nM\n, (34) \nSimilarly, based on (19), the extended gradient \n( )( ) \/ nkx N J N= \u2202 \u2202 \u2208J x R%  is related to the basic gradient \n( ) ( ) 0( ) \/ nN N\u2202\u03a6 \u2202 \u2208x x R) )  as follows \n ( ) ( )( ) 1 0 0\nTT\nx\nJN\nN N\n\uf8ee \uf8f9\uf8eb \uf8f6\u2202 \u2202\u03a6\uf8ef \uf8fa= = \uf8ec \uf8f7\uf8ec \uf8f7\uf8ef \uf8fa\u2202 \u2202\uf8ed \uf8f8\uf8f0 \uf8fb\nJ\nx x\nL)\n%\n. (35) \nThe basic Jacobians X(i) and U(i) can be calculated \nanalytically [5,13] or numerically based on an appropriate \nfinite-difference formula for the first derivatives [18]. \nIV. ALGORITHM CONVERGENCE SPEED-UP \nThe main weaknesses of the standard gradient algorithm \n(21), with a constant learning rate \u03b7 , include a rather slow \nconvergence and difficulties in tuning the learning rate \nappropriately. A small learning rate will result in a slow \nalgorithm convergence, while a large learning rate can lead to \nnumerical instabilities. \nIn this work we apply the conjugate gradient (CG) \nalgorithm [19]-[21] which has the following form \n \n( 1) ( ) ( )l l l\nl\u03b7+ = +w w d , (36) \n \n( 1) ( 1) ( )l l l\nl\u03b2+ += \u2212 +d g d , (37) \nwhere l\u03b7  and l\u03b2  are positive scalars, and  \n1 1(0) (1) ( 2) ( 1)\nT mN\nm mu u u N u N\u2261 \u2212 \u2212 \u2208\uf8ee \uf8f9\uf8f0 \uf8fbw RK , \n1 1(0) (1) ( 2) ( 1)\nT\nm m\nJ J J J\nu u u N u N\n\uf8ee \uf8f9\u2202 \u2202 \u2202 \u2202\n\u2261 \uf8ef \uf8fa\u2202 \u2202 \u2202 \u2212 \u2202 \u2212\uf8f0 \uf8fb\ng K .  \n 5 \nThe standard method for computing l\u03b7  is steepest descent \nor line search algorithm which requires one-dimensional \nminimization of the cost function. This is a computationally \nexpensive method which may require many evaluations of the \ncost function during one iteration of the gradient algorithm. \nAlso, if the cost function is not appropriately scaled, the \nsteepest-descent algorithm may exhibit poor convergence \nproperties. In order to avoid these issues, we use the \nSuperSAB approach [21], [22] which requires only the \ninformation on gradient directions in two consecutive \niterations of the gradient algorithm. The algorithm is modified \nin terms of using a scalar learning rate \u03b7l as oppose to a matrix \nformulation \u03b7l(i,j), i = 0,...,N-1, j = 1,...,m, in order to avoid \ndiscontinuities in the optimized control vector u. The modified \nSuperSAB algorithm is given by \n( ) ( ) ( )( )\n( ) ( ) ( )( )\n( ) ( )\n( ) ( 1) ( ) ( 1)\n1\n( ) ( 1) ( ) ( 1)\n1 1\n( ) ( 1)\n2 1\nif 0 &\nif 0 &\nif\nl T l l l\nl\nl T l l l\nl l\nl l\nl\nd J J\nd J J\nd J J\n\u03b7\n\u03b7 \u03b7\n\u03b7\n+ \u2212 \u2212\n\u2212\n\u2212 \u2212 \u2212\n\u2212\n\u2212 \u2212\n\u2212\n\uf8f1 \u2265 <\n\uf8f4\n\uf8f4\uf8f4\n= < <\uf8f2\n\uf8f4\n\uf8f4 >\n\uf8f4\uf8f3\ng g w w\ng g w w\nw w\n (38) \nwhere 2 10 1d d d\n\u2212 \u2212 +< < < < , and 0\u03b7  is the initial learning rate. \nIf the angle between two consecutive gradients is smaller than \n90\u00b0, ( ) ( 1) 0l T l\u2212 \u2265g g , the learning rate l\u03b7  is increased starting \nfrom some initial value. On the other hand, negative sign of the \nscalar product of the gradients, ( ) ( 1) 0l T l\u2212 <g g , indicates that \nthe iterative procedure has overshot the minimum of the cost \nfunction, and the learning rate l\u03b7  is decreased by multiplying \nit with the decreasing factor 1d\n\u2212\n smaller than unity. Also, the \nalgorithm (38) decreases the learning rate by a decreasing \nfactor 2 1d d\n\u2212 \u2212<  if the condition ( ) ( 1)( ) ( )l lJ J \u2212>w w  is \nsatisfied, in order to avoid occasional cost function spikes that \nmay affect the optimization accuracy [25]. \nThe scalar value l\u03b2  in (37) can be determined by using \ndifferent methods [21]. A comparison of these methods on the \nvehicle dynamics control example [25] have pointed out that \nthe following Dai-Yuan approach gives the fastest \nconvergence: \n ( )\n( 1) ( 1)\nmax( ) ( 1) ( )min ,\nl T l\nl l T l l\n\u03b2 \u03b2\n+ +\n+\n\uf8f1 \uf8fc\n\uf8f4 \uf8f4\n= \uf8f2 \uf8fd\n\u2212\uf8f4 \uf8f4\uf8f3 \uf8fe\ng g\nd g g\n.  (39) \nThe parameter l\u03b2  is limited to max\u03b2 , because the algorithm \n(38) for learning-rate tuning can induce ( ) ( 1)l l\u2212\u2265g g  in \nsituations when ( ) ( 1) 0l T l\u2212 <g g , thus leading to a possible \nalgorithm instability if l\u03b2  is not saturated. The limit value of \nl\u03b2  which guaranties numerical stability is max 1\u03b2 = . But, \ndepending on particular optimization problem this limit can be \nincreased (e.g. max 1.2\u03b2 = ), in order to provide a faster \nconvergence of the algorithm. If the parameter l\u03b2  has a \nconstant value, 0 1\u03b2< < , then the CG algorithm becomes \nequivalent to a standard gradient algorithm with momentum \n[23,24]. \nV. VEHICLE DYNAMICS CONTROL APPLICATION \nThe proposed optimal control algorithm has been verified in \n[18] on a chemical reaction model example with a known \nanalytical solution. In this section, the algorithm is used for \nmore realistic and complex off-line optimization of vehicle \ndynamics control variables. \nA. Vehicle Dynamics Model \nA 10 degree of freedom (DOF) vehicle dynamics model \n[16], provided by the Jaguar Cars, has been used in the bellow \noptimization study. The main 10 state variables are \nlongitudinal and lateral velocities U and V; roll, pitch, yaw, \nand heave rates p, q, r, and W; and four wheel angular speeds. \nThe auxiliary state variables are roll, pitch and yaw angles, as \nwell as the heave, which are used to determine the vehicle \nposition (X, Y) in the inertial coordinate frame and determine \nthe suspension deflections. The tire forces are obtained from \nthe 1994 \u201cMagic formula\u201d tire model (see [16] and references \ntherein).  \nThe rear steering and rear differential actuator dynamics are \napproximately described by first order lag terms with the time \nconstant of 25 ms. Two types of active differentials are \nconsidered [16]: Active Limited Slip Differential (ALSD) and \nTorque Vectoring Differential (TVD). The ALSD always \ntransfer the torque to the slower wheel. The TVD can also \ntransfer the torque to the faster wheel, provided that the \nfaster\/slower wheel speed ratio is not larger than a design \nfactor kAWSD that has a typical value of 1.25. The torque \ntransfer constraints have been implemented in the vehicle \nmodel, as explained in [5]. The overall nonlinear dynamics \nmodel has 18 state variables and two control variables. \n \nB. Optimization Problem Formulation \nSeveral optimization problems and control\/state vector \nconstraints are considered. \n1) Cost Functions Definition \nTrajectory tracking. The optimal control objective for the \ntrajectory tracking task is to find the active rear differential \nand active rear steering control variables \nr\nT\u2206  and \nr\n\u03b4 , \nrespectively, which ensure that the vehicle follows the \nreference trajectory in the X-Y inertial coordinate system with \na minimum tracking error. In other words, the problem is to \nfind the inputs \u2206Tr and \u03b4r that minimize the cost function: \n \n2 2\n11 12\n0\n( ) ( )\nft\nR RJ K X X K Y Y dt\uf8ee \uf8f9= \u2212 + \u2212\uf8f0 \uf8fb\u222b  (40) \nwhere XR and YR are coordinates of the reference trajectory, \nand K11 and K12 are the cost function weighting factors. The \ndouble lane change reference trajectory of Gaussian type is \nconsidered \n 0( )RX t U t=  (41) \n \n22\n0 \/)(\nmax)( \u03c3XXRR ReYXY \u2212\u2212=  .  (42) \n 6 \nwhere U0 is the initial longitudinal velocity, Ymax, X0, and \u03c3 are \nmaximum, center, and bandwidth of the Gaussian curve. \nRoll minimization. The optimal control objective for the roll \nminimization task is to find the control variables that ensure \nminimum chassis roll during the double lane change maneuver: \n \u222b=\nft\ndtJ\n0\n2\u03c6 , (43) \nwhere \u03c6  is the roll angle. \n2) Control and State Vector Constraints Formulation \nThe following inequality and equality constraints of the state \nvariables are considered and realized through the cost function \npenalty terms. \nTrajectory constraints (applies to roll minimization only). The \nroad trajectory is constrained as given by (cf. Fig. 6): \n ( ( )) ( ) ( ( ))offset R R offset R RY Y X t Y t Y Y X t\u2212 + \u2264 \u2264 +  , (44) \nwhere the reference trajectory function YR(.) is given by (42). \nBoundary conditions. The following boundary constraints on \nthe exit vehicle trajectory are considered (cf. Fig. 1): \n \n( ) (0)\n( )\n0\nf\nf\nY t Y\ndY t\ndt\n=\n=\n (45) \n \nC. Optimization Results \nThe C code optimization program for the vehicle control \nsystem has been executed on a personal computer with Intel \nCore Duo CPU (2.00GHz). The terminal time is tf = 6s and the \nsampling interval is \u03c4 = 0.003s, so that the number of \noptimization time intervals is N=2000. The number of \niterations of the Dai-Yuan conjugate gradient algorithm is \nM=400, while the standard gradient algorithm (with \u03b7 = \nconst.) required M = 4000 iterations for the same level of \naccuracy [25]. The Jacobians are calculated numerically. The \nsimple first-order Adams method is used, because the higher-\norder Adams methods have not given notable improvements \nfor the particular example (see [18] for another benchmark \nexample that demonstrates performance gains reached by using \nthe higher-order Adams methods). The algorithm execution \ntime is about 13 min, and it can be reduced by four times if the \nsimplified 7 DOF vehicle dynamics model [5] is used. \n1) Double Lane Change Example \nFigure 1 shows the results of optimization of the front road \nwheel angle input \u03b4f for the trajectory tracking problem (40) \nand a dry asphalt road (\u00b5 = 1). That is, the optimization task is \nto find an \"ideal\" driver steering input referred to the road \nwheel angle. The results in Fig. 1 indicate that the \"ideal\" \ndriver can provide accurate tracking of the sharp reference \ntrajectory, where the absolute value of lateral acceleration \nsaturates to its maximum value aym\u22481g = 9.81 m\/s2. \n \n \n \n \n \nFigures 2-5 show the optimization results for reduced tire-road \nfriction coefficient \u00b5 = 0.6 (e.g. wet asphalt surface) and \ndifferent vehicle dynamics actuators: active rear steering \n \nFig. 2.  Optimization results for ARS+TVD control (\u00b5 = 0.6). \n \nFig. 1.  Front wheel steering optimization results for asphalt road (\u00b5 = 1). \n 7 \n(ARS), active torque vectoring differential (TVD, kAWSD=1.25), \ncombined ARS and TVD, and active limited slip differential \n(ALSD). The top plot of each figure includes three \ntrajectories: (i) reference trajectory that corresponds to the \noptimized (reached) trajectory for \u00b5 = 1 (solid line in Fig. 1), \n(ii) trajectory when no control action is used (\u03b4r = 0, \u2206Tr = 0), \nand (iii) trajectory reached by using the optimal control action. \nThe front steering input \u03b4f is taken from Fig. 1 (no driver \nmodel is used). \nThe ARS intervention provides quite accurate trajectory \ntracking despite the worsen road condition (Fig. 3), thus \npreserving the driver's feeling of (safe) driving on high-\u00b5 road. \nThe tracking accuracy is somewhat worse for TVD control \n(Fig. 4), and the peak of side slip angle \u03b2 = atan(V\/U) is \nincreased by about 20%. The combined ARS and TVD control \n(Fig. 2) gives comparable tracking accuracy as in the case of \nindividual ARS control. However, the control effort is reduced \nwhen compared to the individual ARD or TVD control. The \nALSD cannot compensate for the understeer behavior in the \nfirst part of maneuver, and the corresponding tracking error is \nsimilar as in the case of passive vehicle (Fig. 5). Namely, since \nthe ALSD can transfer the torque to slower (inner) wheel only, \nit can only generate understeer (i.e. compensate for oversteer) \n[16]. Owing to the oversteer compensation, the ALSD \neffectively stabilizes the vehicle in the second part of \nmaneuver (Fig. 5). \n \n \n \n \n \nQualitatively similar results to those in Figs. 2-5 have been \nobtained for lower \u00b5 values, as well (cf. [5]). Also, many other \noptimization tests have been carried out, e.g. those related to \nlimited side slip angle or limited control input. \n \nFig. 5.  Optimization results for ALSD control (\u00b5 = 0.6). \n \n \nFig. 4.  Optimization results for TVD control (\u00b5 = 0.6). \n \n \nFig. 3.  Optimization results for ARS control (\u00b5 = 0.6). \n \n 8 \n \n2) Roll Minimization Example \nFigure 6 shows the \"ideal\" driver optimization results for the \nsame operating conditions as in Fig. 1, but the trajectory \ntracking cost function (40) is replaced with the roll \nminimization criterion (43), and the trajectory constraint (44) \nis taken into account. Figure 7 shows the TVD-based \noptimization results for the same roll minimization problem, \nwhere the steering input \u03b4f is taken from Fig. 1. The \ncomparative results from Figs. 6 and 7, including the passive \nvehicle response, are shown in Fig. 8. \nIn order to minimize the roll angle \u03c6 , the TVD generates \nundersteer around the instant of maximum lateral acceleration \n(t \u2248 2 s; Fig. 7) and forces the vehicle to touch the inner \ntrajectory bound. This results in reduction of the yaw rate r, \nthe lateral acceleration ay, and finally the roll angle \u03c6  when \ncompared to the passive vehicle (Fig. 8). The roll angle \nreduction is paid by lower trajectory tracking accuracy. \nThe \"ideal\" driver \"cuts\" the road even more, so that the \nvehicle touches the trajectory bounds in three points (Fig. 6). \nThis results in a substantial reduction of lateral acceleration \nand roll angle (Fig. 8). However, the trajectory tracking \nperformance is further deteriorated (Fig. 6). \n \n \n \n \nVI. CONCLUSION \nA BPTT-like gradient-based optimal control algorithm has \nbeen proposed in the paper. The optimization accuracy can \ngenerally be improved by using higher-order Adams numerical \nintegration schemes instead of the basic Euler method. \nIncorporation of numerical Jacobians enables the algorithm \napplication for complex problems, where analytical Jacobians \nare difficult to derive. Finally, implementation of advanced \nconjugate gradient methods, such as Dai-Yuan method, results \nin substantial improvement of convergence properties and \nreduction of execution time. The algorithm can be extended \nfor solving minimum-time optimal control problems [12]. \nThe proposed optimal control algorithm has been tested on \na relatively complex vehicle dynamics control problem with 18 \nstate variables and two control variables. The optimization \nresults have illustrated favorable features of the algorithm in \nterms of accuracy (e.g. a few thousands of time grid points can \nbe used), consistent numerical stability, and relatively fast \nexecution. Also, it has been demonstrated that the algorithm \ncan be effectively used to gain insights into the ultimate \nvehicle dynamics control performance for various actuator \nconfigurations. \nThe future work will be directed towards extending the \nalgorithm for combined parameter and control variable \noptimization problems, as well as feedback controller \nparameter optimization for either optimal control formulation \nor robust control formulation. Also, comparison of the \nalgorithm with other existing methods is a subject of ongoing \nwork and future publications. \nACKNOWLEDGMENT \nThe authors would like to thank Dr. Davor Hrovat from \nFord Research and Advanced Engineering and Dr. Matt \n \nFig. 8.  Additional comparative plots for roll optimizations from Figs. 6 \nand 7.   \n \nFig. 7.  TVD optimization results for roll minimization case (\u00b5 = 1). \n \n \n \nFig. 6.  Front wheel steering optimization results for roll minimization \ncase (\u00b5 = 1). \n \n 9 \nHancock from Jaguar Research for their helpful suggestions \nand\/or technical support. \nREFERENCES \n[1] J. T. Betts and W. P. Huffman, \u201cApplication of sparse nonlinear \nprogramming to trajectory optimization,\u201d J. Guidance Control \nDynamics, vol. 15, no. 1, pp. 198-206, 1992. \n[2] I. Y. M. Smets, K. J. E. Versyck and J. F. M. Van Impe, \u201cOptimal \ncontrol theory - A generic tool for identification and control of (Bio-) \nChemical Reactors,\u201d Annual Reviews in Control, vol. 26, pp. 57-73, \n2002. \n[3] O. von Stryk and M. Schlemmer, \u201cOptimal control of the industrial \nrobot Manutec,\u201d in: Bulirsch, R., Kraft D. (eds.), Computational \nOptimal Control, International Series of Numerical Mathematics 115, \nBasel, Birkhauser, pp. 367-382, 1994. \n[4] I. V. Kolmanovsky, and A. G. Stefanopoulou, \u201cOptimal control \ntechniques for assessing feasibility and defining subsystem level \nrequirements: An automotive case study,\u201d IEEE Trans. on Control \nSystem Technology, vol. 9, no. 3, pp. 524-534, May 2001. \n[5] J. Kasa\u0107, J. Deur, B. Novakovi\u0107, M. Hancock, and F. Assadian, \n\u201cOptimization of global chassis control variables,\u201d 17th IFAC World \nCongress, July 6-11, 2008, Seoul, Korea. \n[6] A. E., Bryson, Dynamic Optimization, Addison-Wesley, 1999. \n[7] E. Polak, Computational Methods in Optimization, Academic Press, \nNew York, 1971. \n[8] J. T. Betts, Practical Methods for Optimal Control using Nonlinear \nProgramming, Society of Industrial and Applied Mathematics, \nPhiladelphia, PA, 2001. \n[9] O. von Stryk, and R. Bulirsch, \u201cDirect and indirect methods for \ntrajectory optimization,\u201d Annals of Operations Research, vol. 37, pp. \n357-373, 1992. \n[10] O. von Stryk, \u201cNumerical solution of optimal control problems by direct \ncollocation,\u201d in: Bulirsch R., Miele A., Stoer J., Well K.H. (eds.), \nOptimal Control-Calculus of Variations, Optimal Control Theory and \nNumerical Methods, International Series of Numerical Mathematics, \nvol. 111, Basel, Birkhauser, pp. 129\u2013143, 1993. \n[11] A. L. Schwartz, \u201cTheory and implementation of numerical methods \nbased on Runge-Kutta integration for solving optimal control \nproblems,\u201d PhD Thesis, University Of California At Berkeley, 1996. \n[12] J. Kasa\u0107, \u201cOptimal control of nonlinear systems using neural networks,\u201d \nM. Sc. Thesis (in Croatian), University of Zagreb, 1998. \n[13] J. Kasa\u0107 and B. Novakovi\u0107, \u201cNeural network application to optimal \ncontrol of nonlinear systems,\u201d Proceedings of 7-th International \nConference on Computer Aided Optimum Design of Structures, May 28-\n30, 2001, Bologna,  Italy, pp. 359-368. \n[14] A. E. Bryson and Y. Ho, Applied Optimal Control, Hemisphere \nPublishing Corp, 1975. \n[15] P. J. Werbos, \u201cBackpropagation through time: What it does how to do \nit,\u201d Proceedings of the IEEE, vol. 78, no. 10, pp. 1550-1560, 1990. \n[16] M. Hancock, \u201cVehicle handling control using active differentials,\u201d \nPh.D. Thesis, University of Loughborough, UK, 2006. \n[17] E. Hairer, S. P. Norsett, and G. Wanner, Solving Ordinary Differential \nEquations I - Nonstiff Problems, 2nd ed., Springer, Berlin, 1993.  \n[18] J. Kasa\u0107, J. Deur, B. Novakovi\u0107, and I. Kolmanovsky, \u201cA BPTT-like \noptimal control algorithm with vehicle dynamics control application,\u201d \nASME International Mechanical Engineering Congress & Exposition, \nOctober 31-November 6, 2008, Boston, Massachusetts, USA. \n[19] J. Nocedal and S. J. Wright, Numerical Optimization, Springer, New \nYork, 2006. \n[20] J. A. Snyman, Practical Mathematical Optimization, Springer, New \nYork, 2005. \n[21] C. A. Floudas and P. M. Pardalos, (edit.), Encyclopedia of Optimization, \nSpringer, New York, 2008. \n[22] T. Tollenaere, \u201cSupersab: Fast adaptive backpropagation with good \nscaling properties,\u201d Neural Networks, no. 3, vol. 5, 1990. \n[23] M. Riedmiller, \u201cAdvanced supervised learning in multi-layer \nperceptrons - From backpropagation to adaptive learning algorithms,\u201d \nInt. J. Comput. Standards Interfaces, vol. 16, pp. 265, 1994. \n[24] C. G. H. Jondarr, \u201cBack propagation family album,\u201d Technical Report \nC\/TR96-05, Macquarie University, August 1996. \n[25] J. Kasa\u0107, J. Deur, B. Novakovi\u0107, and I. Kolmanovsky, \u201cA Conjugate \nGradient-based BPTT-like Optimal Control Algorithm,\u201d IEEE \nInternational Conference on Control Applications, July 8-10, 2009, \nSaint Petersburg, Russia. \n[26] B. Wie, Space Vehicle Dynamics and Control, AIAA Education Series, \n1998. \n \n \n \n \n \n \n"}
{"doi":"10.1016\/j.envint.2008.04.004","coreId":"140609","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/3336","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/3336","10.1016\/j.envint.2008.04.004"],"title":"What can water utilities do to improve risk management within their business\nfunctions? An improved tool and application of process benchmarking.","authors":["MacGillivray, Brian H.","Pollard, Simon J. T."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-11-01T00:00:00Z","abstract":"We present a model for benchmarking risk analysis and risk based decision making\npractice within organisations. It draws on behavioural and normative risk\nresearch, the principles of capability maturity modelling and our empirical\nobservations. It codifies the processes of risk analysis and risk based decision\nmaking within a framework that distinguishes between different levels of\nmaturity. Application of the model is detailed within the selected business\nfunctions of a water and wastewater utility. Observed risk analysis and risk\nbased decision making practices are discussed, together with their maturity of\nimplementation. The findings provide academics, utility professionals, and\nregulators a deeper understanding of the practical and theoretical underpinnings\nof risk management, and how distinctions can be made between organisational\ncapabilities in this essential business process","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/140609.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/10.1016\/j.envint.2008.04.004","pdfHashValue":"131df28c249b07db45da6c99cc0716a8f587724c","publisher":"Elsevier Science B.V., Amsterdam.","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/3336<\/identifier><datestamp>2011-09-30T15:23:10Z<\/datestamp><setSpec>hdl_1826_24<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>What can water utilities do to improve risk management within their business\nfunctions? An improved tool and application of process benchmarking.<\/dc:title><dc:creator>MacGillivray, Brian H.<\/dc:creator><dc:creator>Pollard, Simon J. T.<\/dc:creator><dc:subject>Risk analysis<\/dc:subject><dc:subject>Management<\/dc:subject><dc:subject>Decision theory<\/dc:subject><dc:subject>Benchmarking<\/dc:subject><dc:subject>Water utility<\/dc:subject><dc:description>We present a model for benchmarking risk analysis and risk based decision making\npractice within organisations. It draws on behavioural and normative risk\nresearch, the principles of capability maturity modelling and our empirical\nobservations. It codifies the processes of risk analysis and risk based decision\nmaking within a framework that distinguishes between different levels of\nmaturity. Application of the model is detailed within the selected business\nfunctions of a water and wastewater utility. Observed risk analysis and risk\nbased decision making practices are discussed, together with their maturity of\nimplementation. The findings provide academics, utility professionals, and\nregulators a deeper understanding of the practical and theoretical underpinnings\nof risk management, and how distinctions can be made between organisational\ncapabilities in this essential business process.<\/dc:description><dc:publisher>Elsevier Science B.V., Amsterdam.<\/dc:publisher><dc:date>2011-09-29T17:43:35Z<\/dc:date><dc:date>2011-09-29T17:43:35Z<\/dc:date><dc:date>2008-11-01T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>Brian H. MacGillivray, Simon J.T. Pollard, What can water utilities do to improve risk management within their business functions? An improved tool and application of process benchmarking, Environment International, Volume 34, Issue 8, November 2008, Pages 1120-1131<\/dc:identifier><dc:identifier>0160-4120<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1016\/j.envint.2008.04.004<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/3336<\/dc:identifier><dc:language>en_UK<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["0160-4120","issn:0160-4120"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2008,"topics":["Risk analysis","Management","Decision theory","Benchmarking","Water utility"],"subject":["Article"],"fullText":"Environment International, Volume 34, Issue 8, November 2008, Pages 1120-11311\nWhat can water utilities do to improve risk management2\nwithin their business functions? An improved tool and3\napplication of process benchmarking.4\n5\nBrian H. MacGillivray and Simon J.T. Pollard\uf02a6\n7\nCentre for Water Science, Sustainable Systems Department,8\nSchool of Applied Sciences, Cranfield University, Cranfield, Bedfordshire, MK43 0AL,9\nUnited Kingdom10\n11\nAbstract12\nWe present a model for benchmarking risk analysis and risk based decision13\nmaking practice within organisations. It draws on behavioural and normative risk14\nresearch, the principles of capability maturity modelling and our empirical15\nobservations. It codifies the processes of risk analysis and risk based decision making16\nwithin a framework that distinguishes between different levels of maturity. Application17\nof the model is detailed within the selected business functions of a water and18\nwastewater utility. Observed risk analysis and risk based decision making practices are19\ndiscussed, together with their maturity of implementation. The findings provide20\nacademics, utility professionals, and regulators a deeper understanding of the practical21\n\uf02a Corresponding author\/ Tel: +44 1234 754101; fax +44 1234 751671\nE-mail address: s.pollard@cranfield.ac.uk (Prof. S.J.T. Pollard)\nand theoretical underpinnings of risk management, and how distinctions can be made22\nbetween organisational capabilities in this essential business process.23\n24\nKeywords: risk analysis, management, decision theory, benchmarking, water utility.25\n1. Introduction26\nThe provision of safe, reliable drinking water, the overarching goal of the water27\nutility sector (AWWA et al. 2001), is within the bounds of the developed world\u2019s28\nscience, technology, and financial resources. Nevertheless, a nagging prevalence of29\nwater quality-related outbreaks remains in the developed world, with \u201ccauses\u201d ranging30\nfrom technical failures to institutional lapses and, in the extreme, negligence on the part31\nof operating and managerial staff (Hrudey and Hrudey, 2004). Regardless of the32\nmanifestation of these incidents, one might argue that excepting \u201cacts of God,\u201d they all33\nderive, fundamentally, from a limited organisational capacity in learning how to34\nprevent failures; in failures to proactively manage risk.35\nConventionally, utilities manage risk through codifying standard design and36\noperating procedures. Procedures develop with the introduction of improved methods37\nand technologies (e.g. novel treatment processes) and by reflecting on past mishaps.38\nFrom a risk management perspective, we are particularly concerned with the latter. A39\ndevelopmental cycle begins with a contamination event or near miss, following which40\nincident analysis is undertaken to determine its root cause, concluding with a technical,41\noperational or administrative solution (e.g. adapting design standards or operating42\nprocedures) designed to prevent its recurrence. This cycle exists at the individual43\nutility and sector level, the latter reflected in changes to national or sector-wide codes,44\nstandards or regulations where learning is generalised; for example, regarding the45\npathogenic hazards associated with backwashing treatment filters. Whilst this46\nretrospective approach to managing risk is necessary, it is a mistake to consider it47\nsufficient for risk management. Procedures can proliferate to the point where resources48\nare diverted towards preventing incidents that have happened, rather than those most49\nlikely to happen in the future (Lee, 1998). Further, a reliance on learning by trial and50\nerror, in isolation of more proactive strategies, is unsound where public health is at51\nstake because it is not protective. Although illustrated in a water quality context, this52\nargument extends to all aspects of the design, operation and management of utility53\nsystems (e.g. from process engineering to occupational health and safety management)54\nand across many industrial (water, waste, energy, transport) sectors.55\nRecognition of the limitations of post-hoc analysis is shifting the water sector56\ntowards proactive risk management, wherein utilities identify potential weaknesses and57\neliminate root causes of problems before failure occurs (MacGillivray et al., 2006;58\nHamilton et al., 2006; Pollard et al., 2004). Our research (Pollard et al., 2004; 2006;59\nHrudey et al., 2006; Pollard et al., 2007; MacGillivray et al., 2007a\/b) has been60\nconcerned with how we can improve organisational competencies in risk management61\nwithin the utility and related sectors. We have focussed on implementation rather than62\nthe technical aspects of the risk and decision analysis techniques employed and here,63\nwe introduce a model for benchmarking and improving the processes of risk analysis64\nand risk based decision making within utilities. We describe its application within a65\nwater and wastewater utility, and end by reflecting on our theoretical and empirical66\ncontributions.67\n.68\n69\n2. Benchmarking risk analysis and risk based decision making70\nCapability maturity models (Paulk, 1993) are simplified representations of71\norganisational disciplines (e.g. software design and engineering) that codify industry72\npractice within a maturity framework. They allow distinctions to be made between73\norganisational capabilities (e.g. the ability to manage risk) by reference to the maturity74\nof the processes applied. We have published the design (MacGillivray et al., 2007a)75\nand application (MacGillivray et al., 2007b) of a capability maturity model for76\nbenchmarking risk management practice within the utility sectors. This model77\ncontained eleven risk management processes at five maturity levels. The premise of the78\nmaturity levels was that once each process was enshrined in procedure, with staff79\ntrained in their application, roles and responsibilities assigned, necessary resources80\nsecured, and mechanisms in place to prevent deviations from requirements and to learn81\nfrom the feedback obtained, then implementation of risk management should be of82\nconsistently high quality. The demonstrable maturity of risk management then83\nbecomes the benchmark of an organisation\u2019s capability to manage risk, rather than84\nsimply the presence of risk policies, techniques or champions.85\nWe have since revised the model, responding to theoretical and empirical86\nchallenges derived from its application (see MacGillivray, 2007c). Our revision87\nfollows the spirit of the grounded theory approach (Glaser and Strauss, 1967; Straus88\nand Corbin, 1994), drawing primarily upon:89\n(i) the capability maturity modelling and quality management literatures;90\n(ii) normative risk analysis and management frameworks, both specific to the91\nwater and wastewater sectors and beyond;92\n(iii) behavioural research on decision making under uncertainty; and93\n(iv) our recent empirical observations.94\nA revised model, described here, incorporates risk analysis and risk based95\ndecision making, which are comprised of distinct practices. Risk analysis (Fig. 1;96\nTable 1) comprises the practices of system characterisation, hazard identification,97\nexposure assessment, control evaluation, consequence evaluation, likelihood98\nevaluation, and risk evaluation. Risk analysis looks to the future to determine what can99\ngo wrong and how, the potential consequences and the relative likelihood of this, and100\nfinally the overall level of risk. Risk analysis is always part of a decision context (Aven101\nand K\u00f8rte, 2003). Risk based decision making (Fig. 1; Table 2) is concerned with the102\nidentification and evaluation of risk management options and a managerial review prior103\nto selecting the optimal option(s). It is informed by criteria that establish the104\nacceptability of risk and that set out stakeholder values and concerns, which are used to105\nassess the relative merit of alternative options.106\nBoth processes are presented in five maturity levels, from ad hoc to adaptive,107\ncharacterised by the completeness of the process (i.e. whether all practices are108\nundertaken) and attributes that reflect the maturity of implementation. Maturity levels109\ncodify the extent to which each process is repeatable (level 2; L2), defined (L3),110\ncontrolled (L4) and adaptive (L5). Whilst the maturity attributes (Table 3) and levels111\n(Table 4) are specific to risk analysis, the same principles apply to risk based decision112\nmaking. Note, that to achieve a given maturity level, all positive requirements of that113\nlevel and the preceding levels must first be satisfied.114\n115\n3. Research methods116\nWhat can individual utilities learn about their organisational risk management117\nmaturity and how should they respond? How far should they go to improve risk118\nmanagement and what actions should they take? One water and wastewater utility119\nparticipated in this case study. The provision of safe, reliable drinking water depends120\non a range of business functions spanning the design, operation and management of121\nwater supply, wastewater treatment systems. We view the integration of risk122\nmanagement across the breadth of these business functions as crucial to delivering a123\nhigh level of competency in public health protection. Though the focus of our research124\nis water quality, by the nature of the utility\u2019s organisation, it extended to aspects of their125\nwastewater services. We critically assessed seven business functions: engineering;126\nproject management; drinking water quality management; network planning; asset127\nmanagement; emergency management; and occupational health and safety. The128\nresearch methods included interview and document analysis, as described below.129\nSemi-structured interview templates were developed and applied by business130\nfunction (e.g. asset management) and, where judged relevant, by functional discipline131\n(e.g. dam safety management). Questions explored the practical form of risk132\nmanagement in each business function (e.g. \u201cwhat is the process for identifying health133\nand safety hazards within workplaces?\u201d) and its maturity of implementation (e.g. \u201care134\nthere mechanisms for quality control of risk analyses?\u201d). Interviews (mean approx. 45135\nmin.) were conducted face to face (n = 32) and by \u2019phone (n = 1), recorded, and136\ntranscribed verbatim (with two exceptions, where notes were taken). Transcripts were137\nreturned to each interviewee, for comment. Finally, relevant company documentation138\nwas obtained from interviewees, the corporate intranet and the public domain (e.g.139\ninternet, conference articles). This included risk management policies and frameworks,140\nrisk analysis procedures and methods, accident and incident statistics and reports, water141\nsafety plans and risk analysis outputs.142\nEach business function\u2019s process maturity was assessed according to the lead143\nauthor\u2019s judgement based on the data obtained, by reference to our model. We consider144\nthe subjectivity of this to be unimportant, because the principal research objective was145\nto refine the model and illustrate its application, not necessarily to derive a maturity146\nassessment of auditable rigour. Mechanisms to validate our findings were adopted,147\nincluding sample anonymity and triangulation. Anonymity removed the potential for148\nconflicts with the goal of adding to the body of knowledge on risk management149\ncapability (as opposed to the participant\u2019s potential desire that findings reflected150\npositively on their organisation). Triangulation was secured through interviewing a151\nrange of representatives from each business function and cross-checking for152\ninconsistencies in accounts, cross-checking interviewee accounts with documented153\nsources, and providing the interviewees an opportunity to comment on drafts of the154\nresearch outlined in this paper. Of the seven functions evaluated, \u201cemergency155\nmanagement\u201d was excluded from the analysis due to contradictions in the data and the156\nlimited sample of interviewees (two, compared to a minimum of three elsewhere),157\nwhilst \u201cnetwork planning\u201d was excluded because of limited documentation obtained.158\n159\n4. Results160\nWe begin by summarising and discussing the observed risk analysis practices,161\nbefore evaluating their relative maturity of implementation. We then turn to risk based162\ndecision making.163\n4.1. Risk analysis: observed practices164\nTable 5 summarises risk analysis practice within the sub-sample of business165\nfunctions examined. Below, we provide a critical evaluation of the strengths and166\nlimitations of a selection of these practices.167\n4.1.1. Hazard identification168\nThe business functions within this utility adopted a range of hazard identification169\nmethods, each with their own strengths, limitations and application contexts. In170\noccupational health and safety management for example, hazard identification was171\nconcerned with identifying physical, chemical and biological threats. These were172\nprimarily identified using checklists linking known hazards with processes, equipment,173\nworkplaces, or operations, and supplemented with \u201cjudgement formed from experience174\nand knowledge of the work, past incident records, brainstorming, and system175\nengineering techniques.\u201d The approach acknowledges the value of checklists in176\ncontexts where there is a significant body of knowledge or experience on the range and177\nnature of potential hazards, and the notion that it is inappropriate to base hazard178\nidentification solely on lessons learned from the past, because hazards and the contexts179\nin which they arise are fundamentally dynamic.180\nSystem engineering techniques were applied within the engineering function.181\nHere, hazard identification was concerned with determining the root causes by which182\nengineered systems may fail to operate within their design specifications. This was183\nreflected in the utility\u2019s use of hazard and operability studies (HAZOP). In brief,184\nanalysts examined a process (e.g. disinfection) subdivided into nodes. At each node,185\nthe analysts applied guidewords (e.g. low, high) to process parameters (e.g.186\ntemperature, pressure, flow) to identify ways in which the process may deviate from its187\ndesign intention.188\nIn contrast, neither prescription nor a definitive methodological structure was189\nevident in project management\u2019s approach to hazard identification, which was190\nconcerned with threats to the delivery of projects to time, to budget, and within the191\nrequired quality parameters. Reflecting the unique nature of projects and their related192\nhazards, this function adopted facilitated group brainstorming, informed by generic risk193\ncategories (e.g. \u201ceconomic \/ business risk: the risk of exceeding project budget due to,194\nfor example, the impact of unfavourable exchange rates on the cost of minerals\u201d) to195\nstimulate dialogue and encourage a systematic and creative approach to hazard196\nidentification.197\n4.1.2. Exposure assessment198\nThe existence of a hazard does not constitute a risk because each hazard199\nrequires a pathway (a sequence of events, actions, or processes) that, if available, leads200\nto its realisation at a receptor. Whilst hazard identification is concerned with what can201\ngo wrong (e.g. introduction of hydrocarbons within a water supply system), exposure202\nassessment examines the how and why (e.g. off-take water contaminated via oil203\nemissions from inadequately maintained pumps or pipes, due to an absence of204\nprocedures or inadequate supervision and training of maintenance staff). It involves205\nidentifying possible routes to and causes of failure.206\nConsider the drinking water quality management function within our case study207\nutility, where risk analysis was based on an adaptation of the hazard analysis and208\ncritical control points (HACCP) methodology. The method seeks to provide a basis for209\nunderstanding and prioritising human health and aesthetic hazards within the water210\nsupply chain from catchment to tap. Within the function, knowledge of the211\nenvironmental behaviour of hazards (e.g. the environmental fate and transport of212\npathogens) and the system under examination, technical judgement, incident reports,213\nsurvey maps, and monitoring records was synthesised to link hazards within each214\nsubsystem (e.g. catchment: chlorine resistant pathogens) to their sources (e.g. dairy215\nfarming or grazing) and to the chain of events that may lead to their realisation (e.g.216\nrunoff or percolation from land based activities).217\nWhilst variable in rigour and method, a common theme was that each function\u2019s218\napproach to exposure assessment \u2013 where evident \u2013 tended to focus on how failure219\nevents may arise, rather than addressing the in-depth root causes. They neglected to220\nexplore the reasons why human or technical systems fail. This is an important oversight221\nin that easily predictable causes of failure are often manifestations of deeper,222\nunderlying weaknesses (Reason, 1997). An inability to understand causal paths to223\nfailure constrains the development of risk management options targeted at the root224\ncauses of risks. Indeed, this should be the guiding basis of HACCP \u2013 in that risk (rather225\nthan hazard) management should focus at the critical points of management control;226\nthat is on those processes whose failure is likely to drive the risk (Hrudey et al., 2006).227\n4.1.3. Consequence evaluation228\nThis practice involves identifying the nature of the consequences that follow a229\nhazardous event (e.g. financial, environmental) and assessing the severity of impact. A230\nrange of techniques, from quantitative modelling to qualitative ranking were applied231\nwithin our sub-sample of business functions. Applications of the former were restricted232\nto asset management (e.g. event tree analysis, dam break modelling, inundation233\nmapping, and economic impact evaluations in major dam risk analysis), with the234\nmajority of evaluations of the impact being single point estimates framed by risk235\nranking techniques. These techniques presented consequences according to the nature236\nof their impact (e.g. financial, environmental), and a graded scale of severity expressed237\nby descriptive benchmarks. Their application within the sub-sample of business238\nfunctions was not typically underpinned by an analytical method, relying instead on the239\ninterpretation of limited data sets (e.g. in occupational health and safety: cost of claims,240\nlost time due to incidents) to derive a credible consequence evaluation. Whilst this is241\noften a practical necessity, the indeterminacy intrinsic to this approach provides scope242\nfor individuals to bias (inadvertently or not) consequence evaluations, often in subtle243\nand difficult to detect ways such that risk analysis outcomes may reflect the desires of244\nvested interests (e.g. to secure funds, or to divert attention from flaws) rather than the245\ncorporate good. Such concerns are not unique to consequence evaluation, and provide246\na powerful rationale for quality control of the risk analysis process, which we discuss in247\nsection 4.2.4 below.248\n4.1.4. Likelihood evaluation249\nThis involves evaluating the probability that a hazardous event will occur and250\nlead to a defined severity of consequence. In drinking water quality management,251\nanalysts sought to characterise the likelihood of hazardous events occurring and leading252\nto a derogation of water quality standards or guidelines. Such judgements were253\ninformed by historic frequencies of exceedence (e.g. from turbidity monitoring data, E.254\ncoli concentrations). In some cases, these were supplemented by analysing critical255\nvariables. For example, evaluations of the likelihood of climatic and seasonal256\nvariations leading to excess levels of suspended solids in source waters were informed257\nby analysis correlating the historic loadings of suspended solids with flow and rainfall258\ndata. However, whilst comprehensive monitoring of water quality parameters within259\ncatchments and at customer taps was routine, the absence of an overarching monitoring260\nphilosophy rooted in preventative risk management, at the treatment and disinfection261\nplant level meant that the datasets characterising hazards within water supply systems262\nwere incomplete. As one interviewee noted, \u201cwe do have online monitoring\u2026but263\ntraditionally it\u2019s been a fairly ad hoc process\u2026no-one has really taken a holistic264\nview\u2026and said \u2013 I think we should have online [pH] monitors here, chlorine residual265\nanalysers [here and]\u2026for these reasons.\u201d266\nA similar theme emerged in occupational health and safety, whose risk analysis267\nprocedure stated that likelihood evaluations \u201cmay be determined using statistical268\nanalysis and calculations,\u201d but \u201cwhere no past data exists or is available, subjective269\nestimates will be required to reflect an individual\u2019s or groups degree of belief\u201d that a270\nparticular severity of consequence will occur. It further specified that experiments and271\nprototypes and economic, engineering or other models may be used to minimise272\nsubjective bias. Our observations revealed that modelling (e.g. event tree analysis) was273\nrestricted to isolated applications, whilst the availability of historic data (e.g. frequency274\nrates by injury type, mechanism of injury, etc.) was paradoxically constrained by the275\norganisation\u2019s good health and safety record. As one interviewee offered: \u201cthe amount276\nof information that we generate doesn\u2019t produce sufficient data for us to analyse\u2026and277\nthat\u2019s not necessarily because of a lack of reporting, it\u2019s just that\u2026we actually don\u2019t278\nproduce that many incidents.\u201d This was offset, in part, by reference to external data279\nsources (e.g. national health and safety databases). However, these fail to reflect the280\nunique nature of the utility\u2019s design, construction, operation, and maintenance practices281\nand, more broadly, their working culture.282\n4.2. Risk analysis: maturity of implementation283\nHaving summarised (Table 5) and discussed the business functions\u2019 risk analysis284\npractices, we now consider their maturity of implementation. Within each business285\nfunction, the requirements of Level 2 maturity in risk analysis (Table 4) were satisfied286\n(Fig. 2). A repeatable process was in place, characterised by explicit critical risk287\nanalysis practices. Level 2 is limited in two fundamental ways. One is that the key288\npractices of exposure assessment and control evaluation may be absent or undertaken289\nimplicitly. With the exceptions of engineering and drinking water quality management,290\nthis was true across our sub-sample (see Table 5). This is significant because a291\nknowledge of the pathways by which hazards are realised and of the weaknesses in the292\ndesign, operation and management of existing controls, is a prerequisite to developing293\nrisk management options targeted at common and root causes of failures that are yet to294\narise. A further defining L2 characteristic is that the rigour and quality with which295\ncritical practices are performed depends in large part on individuals that execute and296\nmanage the work, and may therefore vary considerably. Additionally, the techniques297\nadopted may be retrospective and historical, regardless of their applicability or298\ncurrency. This is because they do not fully satisfy the requirements of a defined (L3),299\ncontrolled (L4) or adaptive (L5) process. However, fully is the key word here, as we300\nobserved each function exhibiting some of the higher level maturity attributes and so301\nour characterisation may be somewhat harsh. We now discuss specific attributes of302\ntheir maturity in risk analysis.303\n4.2.1. Initiation criteria304\nWithin many sectors, there are accepted standards of performance and codes of305\npractice that, if adhered to, provide high degrees of control (UKOOA, 1999; Pollard et306\nal., 2004). These standards are applied in familiar and well-characterised situations307\nwhere uncertainties and system vulnerabilities are well understood. Adhering to the308\nhistoric basis for safe operations can be considered as discharging the risk management309\nduty (Health and Safety Laboratory, 2003; UKOOA, 1999). Returning to our sample of310\nbusiness functions, this concept was reflected in an electrical engineer\u2019s comments:311\n\u201celectricity is a dangerous thing, it\u2019s a source of high energy that can be released312\ninstantaneously. Obviously you need to be in control and protected satisfactorily to313\nmake sure that there\u2019s no risk to personnel or the property\u2026because the technology is314\nvery mature\u2026we have our own design guidelines [for electrical engineering] that315\nactually emphasise\u2026issues like lifecycle cost, security of operation, reliability,316\nsafety\u2026[and so on] I don\u2019t think it is necessary to have a formalised [risk analysis]317\nprocess [in electrical engineering], because it\u2019s part and parcel of the detailed design318\nanyway.\u201d319\nHowever, complex, uncertain and novel systems, with the potential to deviate320\nfrom routine operation, may require risk analysis, so as to better understand what drives321\nthe risk from or to the plant, process or operation (UKOOA, 1999; Pollard et al., 2004).322\nThis principle extends beyond technical systems to embrace all aspects of managing a323\nwater utility. As such, a L3 attribute is the existence of initiation criteria: criteria that324\ninitiate the application and revision of risk analysis. Criteria observed within our sub-325\nsample included: undertaking project risk analyses prior to full financial approval326\ndepending on the cost, complexity and novelty of the project; undertaking manual327\nhandling risk analyses in occupational health and safety management for novel, altered328\nor relocated processes or in response to high frequency injury records or employee329\nrequests; undertaking HAZOP studies within engineering for complex or costly330\nprocesses at set stages of design completeness. Timescales for revising risk analyses of331\nvarious asset classes were observed in asset management. These criteria acknowledge332\nthat risk analysis is not a one-off activity, but requires regular revision to reflect system333\nchanges and the improved understanding of risks, that inevitably develops over time334\n(e.g. from monitoring data, increased operator experience). In a world becoming335\nobsessed with \u201cthe risk management of everything\u201d (Power, 2004), an absence of these336\ninitiation criteria may drain resources, as staff are tempted to conduct risk analysis337\nwithout first considering whether adherence to good practice would serve for sound risk338\nmanagement. At the other extreme, analysis may be applied reactively, perhaps even to339\nprovide ex post justifications of investment decisions (e.g. Health and Safety340\nLaboratory, 2003).341\n4.2.2. Stakeholder engagement342\nA further positive characteristic of the utility\u2019s approach to risk analysis was the343\nreflection of a broad spectrum of knowledge, skills, experience and perspectives within344\neach function\u2019s approach to risk analysis. One benefit of their primarily qualitative345\napproach was that it ensured that non-specialists, or what one interviewee referred to as346\n\u201cthe people that use the systems, use the equipment and undertake the processes,\u201d347\ncould actively participate in and critically scrutinise the process. This is key, as348\nengaging operational staff who have practical knowledge of the hazards under349\nexamination ensures a sense of ownership and engagement in the process, as opposed350\nto accountabilities residing within a core set of head-office experts isolated from351\noperational reality.352\n4.2.3. Competence353\nAs Rosness (1998) notes, the accuracy of risk analyses depends to a large extent354\non the competency of analysts to critically evaluate information and integrate it with355\ntheir own knowledge and assumptions. A need for education and training in risk356\nanalysis remains irrespective of the technical complexity of the methods adopted.357\nAside from the ubiquitous \u201con the job\u201d training, two elementary programmes were358\nobserved within our sub-sample: (i) internally delivered training modules within359\noccupational health and safety, comprising an overview of the relevant legislation, the360\nrisk analysis process, and some practical exercises; and (ii) voluntary external modules361\nfor HAZOP facilitators and project managers. However, formal definitions of the362\ncompetencies required of risk analysts and metrics for assessing whether they had been363\nimparted were absent, leading one to question on what basis education and training in364\nrisk analysis was targeted, assessed and improved. This critique is not restricted to our365\nsub-sample; there is a broader need for research on (i) the attributes and characteristics366\nof competent risk analysts; (ii) how they can be developed within staff; and (iii) how367\nthe vigilance secured can then be measured and retained.368\n4.2.4. Verification: quality control369\nThe quality control of risk analyses is intended to enhance their credibility370\nthrough addressing inherent uncertainties, both epistemic, due to lack of knowledge,371\nand operational, derived from the use of knowledge (e.g. analyst bias, judgements,372\nhuman error; see Faber and Stewart, 2003; Amendola, 2001). This aspect was perhaps373\na core weakness of the sub-sample. For example, peer reviews of risk analysis were374\nexecuted in a largely informal and unsystematic manner, whilst the use of facilitators375\nwas restricted to project risk analysis and HAZOP studies. That said, the role of the376\nlatter should not be underplayed, as our interviews emphasised that they did not drive377\nparticular outcomes or provide specific technical input, but sought to guide analysts in378\nthe application of methods and focus on the quality of process execution (e.g.379\nchallenging outliers during consequence evaluation, ensuring all relevant risk380\ncategories were considered during hazard identification).381\nWith formalised quality control mechanisms being the exception rather than the382\nnorm, there was an implicit reliance on analyst competencies, a presumed absence of383\nbias, and an assumed validity of the methods adopted. In practice, all risk analyses384\nhave inherent limitations and are based on assumptions rarely made explicit, and385\narguably, their applications are not scientific in a classical sense, but rather draw on the386\naccumulated experiences, knowledge and bias of analysts (Aven et al., 2006). As such,387\nignorance, assumptions, value judgements, and local perspectives distort analysis388\noutcomes from true objectivist ideals. Given this, the utility\u2019s rescinding of the Delphi389\ntechnique within their project risk analysis was disappointing. Historically, facilitated390\ndiscussions and iterative anonymous voting had been used to generate consensus in risk391\nevaluation. Characterised by group participation, anonymity and feedback loops, it392\nminimised bias and dogma (e.g. reduced the reluctance of staff to abandon previously393\nstated views). One interviewee suggested that since the approach had been abandoned,394\nevaluations tended to reflect the subjective judgement of lone experts, which \u201ctypically395\nwent unchallenged.\u201d This may be viewed as a pyrrhic victory for those who railed396\nagainst this symbol of \u201cbureaucracy,\u201d and a timely warning that the much maligned397\nconcepts of due process, of checks and balances, can suppress greater evils.398\n4.3. Risk based decision making: observed practices399\nTable 6 summarises risk based decision making practice within the sub-sample.400\nBelow, we evaluate the strengths and limitations of a selection of these practices.401\n4.3.1. Establish criteria for evaluating alternative risk management options402\nA range of risk management measures may be considered for a particular403\ndecision. Consider drinking water quality management. Options for reducing risks to404\npublic health posed by waterborne pathogens include: enhancing the monitoring of405\nindicator organisms in source waters (e.g. E. coli), catchment protection (e.g. fencing,406\nor exclusion zones for livestock), infrastructure upgrades (e.g. filtration flow control),407\nchlorine residual monitoring and operator training. The objective of each option is to408\nreduce the risk to a level considered acceptable. The decision as to which option(s) is409\nconsidered the best is influenced by many factors. Notwithstanding that all risk410\nmanagement decisions are value-laden, in best practice organisations these factors are411\nreflected in explicit criteria used to evaluate the relative merit of alternative options.412\nAs cost benefit analysis is linked to determining of whether risk management413\noptions satisfy the \u201cas low as reasonably practicable\u201d (ALARP) criteria adopted within414\nthe sub-sample, it is tempting to consider the balancing of costs and benefits as an415\nevaluation criterion. However, we propose cost benefit analysis is best viewed as a416\nmethodology for evaluating the relative utility of a risk management option. It does not417\nprescribe whether one should simply balance the financial expense of implementing an418\noption with the benefits of the risk reduction, or whether one should incorporate less419\ntangible aspects such as technical feasibility, social values such as equity and420\ndistribution, or political concerns. In other words, it leaves the evaluation criteria421\nunspecified. Whilst our research revealed that a broad range of criteria guided the422\nevaluation of risk management options within our sub-sample, they were only made423\nexplicit within asset management\u2019s risk-based approach to prioritising mains424\nreplacement and dam safety upgrades (Table 6). As such, one can expect what Arvai et425\nal. (2001) termed \u201calternative focussed\u201d decision making to predominate. This is426\ncharacterised by an analysis of available alternatives followed by selection of the427\n\u201coptimal\u201d option from a set of implied or poorly defined criteria. It is not desirable for428\na decision process to dictate or prescribe decisions, as an overly mechanical approach429\nfails to recognise the human aspects of performing difficult value judgements under430\nuncertainty (Aven et al., 2006). However, expressing the criteria against which those431\njudgements should be taken ensures that the rationale for decisions is constructed a432\npriori in a deliberative manner, rather than rationalised post hoc. Aside from433\nimproving risk management, explicit criteria serve to better equip utilities to manage434\nrisk issues, as they (i) provide a mechanism for reflecting legitimate stakeholder435\nconcerns in utility decision making (e.g. by incorporating public values and436\npreferences); and (ii) provide a documented, defensible rationale for decision on risk.437\n4.3.2. Identify risk management options438\nThis practice is concerned with generating alternative solutions for managing439\nrisk. Within the business functions, it was typically undertaken within creative440\nworkshops involving a diverse range of stakeholders. The value of brainstorming,441\nwhich seeks to stimulate innovation through open interaction and feedback, was cited442\nby various interviewees, one noting that it \u201cempowers people to think; the worst [thing]443\nthat you can do is take away people\u2019s creativity.\u201d Furthermore, engaging stakeholders444\nwith diverse skills and backgrounds helps identify and address those assumptions,445\nconstraints and biases that can have a significant influence on the generation of446\nalternatives (Aven and K\u00f8rte, 2003). Whilst primarily creative, within some functions447\nthis practice was informed by checklists of risk reduction alternatives. One example448\nwas occupational health and safety management\u2019s hierarchy of risk controls (control449\nbanding), which classified: engineering controls for hazard removal (e.g. substitution,450\nisolation, modification to design, guarding and mechanical ventilation); administrative451\ncontrols for preventing the occurrence of hazardous events (e.g. safe work practices, or452\nprocedures, training, supervision, nominating maximum exposure times); and personal453\nprotective equipment for minimising their severity of consequences.454\nPerhaps the most important factor was the depth and rigour of the risk analyses.455\nConsider risk analysis within drinking water quality management. Recall that hazards456\nidentified within each subsystem (e.g. catchment: pathogens) were linked to their457\nsources (e.g. dairy farming or grazing) and the events that may lead to their realisation458\n(e.g. runoff or percolation from land based activities). Detailed surveys were459\nundertaken exploring the adequacy of design, management and operation of those460\nactions, activities and processes applied to mitigate the introduction or transport of said461\nhazards from catchment to customer tap (e.g. catchment protection, pre-treatment,462\nozonation, etc.). We propose that systematically identifying the underlying463\nmechanisms through which hazardous events may occur, before evaluating the latent464\nand active weaknesses in their control mechanisms, is the normative approach to465\nidentifying risk management options. The overarching purpose of risk analysis should466\nbe to develop a better understanding of the factors governing system reliability, rather467\nthan a \u201cnumbers game\u201d (e.g. to simply satisfy quantitative risk acceptance criteria;468\nFaber and Stewart, 2003). When used diagnostically, risk analysis represents an469\nefficient tool for improving system safety and performance.470\n4.3.3. Evaluate options471\nWe now turn to the evaluation of risk management options. There are three472\nelements to this practice: (i) forecasting the impact of options against each evaluation473\ncriteria (e.g. technical feasibility); (ii) determining the relative merit of each option; and474\n(iii) determining the acceptability of the residual risk, post-implementation.475\nMethods for achieving the former within our sub-sample of business functions476\nincluded applying professional judgement, stakeholder consultations, cost-estimations,477\nand engineering studies (e.g. feasibility studies in major dam safety management). This478\nsaid, recall that in most business functions evaluation criteria were not defined, and so479\nthis element often tended towards the informal or implicit. For the second element, the480\ncost-benefit approach was widely adopted for assessing the relative merit of alternative481\nrisk management options. Formal mathematical analyses were restricted to risk482\nmanagement options that took the form of major capital projects (e.g. in major dam483\nsafety management). More commonly, managerial judgement was used to balance484\ncosts and benefits, at times informed by cost-effectiveness evaluations of risk reduction485\nper unit (Euro) spent. Thus, the determination of whether risks satisfied the ALARP486\ncriteria was judgement-based, rather than informed by an explicit evaluation of the487\ncosts and benefits of reducing vs. maintaining risk levels.488\nWe present two justifications for the variable rigour and formality that489\ncharacterised this practice: (i) that the resources expended in decision analysis must be490\njustified by the benefit of better decisions, and so detailed analysis is neither desirable491\nnor justifiable for every decision; and (ii) that evaluation criteria incorporating492\nintangible dimensions are difficult to incorporate within the analytic framework of cost493\nbenefit analysis.494\n4.4. Risk based decision making: maturity of implementation495\nThe sub-sample\u2019s risk based decision making profile mirrors that of risk analysis496\n(Fig. 2). However, the decision making processes were less mature, and characterised497\nby a lesser degree of definition. One implication is that we may expect a lesser degree498\nof rigour and formality in risk based decision making. Perhaps this reflects an499\norganisational culture that values judgement, intuition, and creativity of decision above500\nprescription. However, our model is intended to guide, not prescribe, decision making501\nwith the objective of encouraging a high degree of consistency, credibility, and502\nconfidence in the outcomes. In the absence of a clear framework, people struggle to503\nidentify their full range of values and concerns in a given decision context, and are ill-504\nequipped to perform the complex trade-offs common to risk based decision making505\n(Arvai et al., 2001; Slovic et al., 1977; Payne et al., 1992; Slovic, 1995; Matheson and506\nMatheson, 1998). It does not require a strong grasp of decision theory to conclude that507\nan aversion to decision frameworks, however motivated, is not conducive to sound risk508\nmanagement.509\n510\n5. Discussion511\nWe now critically evaluate our contribution, which is three-fold. We have (a)512\nsynthesised empirical observations with prior behavioral and normative risk research to513\ncodify the processes of risk analysis and risk based decision making; (b) placed these514\nprocesses within a maturity framework that distinguishes between levels of515\nimplementation, from ad hoc to adaptive; and (c) provided a comparative analysis of516\nrisk analysis and risk based decision making across a range of utility business517\nfunctions.518\n519\n5.1. Coding of risk analysis520\nConsider the codification of risk analysis (Fig. 1; Table 1), best described by521\nreference to the prominent risk frameworks that adopt an organisation-wide focus (e.g.522\nCOSO, 2004; AS\/NZS, 1999, 2004; FERMA, 2003) and those for drinking water523\nquality management (NZMOH, 2001; NHMRC, 2001, 2004; WHO, 2002, 2004). Our524\ninclusion of exposure assessment is distinctive because strategic risk management525\nframeworks tend to focus on finding sources of potential harm, to the neglect of the526\nunderlying pathways that lead to their realisation (i.e. how and why hazardous events527\nmay occur). This focus on root causes is mirrored in our treatment of control528\nevaluation, which involves identifying and assessing existing technical, physical and529\nadministrative controls. These are important advances, because the neglect of causal530\npathways to failure and latent weaknesses in system defences impedes the development531\nof risk management measures targeted at the root causes, and therefore, promotes a532\nfocus on hazard, rather than risk, management.533\nWe have placed consequence evaluation prior to likelihood evaluation. The534\nmajority of frameworks consider the order in which they are performed to be535\ninterchangeable, or at least make no explicit reference to the matter (e.g. COSO, 2004;536\nAS\/NZS, 1999, 2004; FERMA, 2003). Our reasoning is that the outcome(s) should be537\ndefined prior to any evaluation of the likelihood of occurrence. If these steps are538\nperformed in reverse, likelihood evaluation tends to be concerned only with the539\nlikelihood of a hazardous event occurring (e.g. the probability of asset failure), rather540\nthan with the likelihood of an event occurring and leading to a defined outcome (e.g.541\nthe probability of an asset failing and leading to a given environmental impact). The542\nformer approach overestimates risk. This is not a purely theoretical danger; our543\nresearch has revealed instances of its occurrence (MacGillivray et al., 2007b).544\n545\n5.2. Coding of risk based decision making546\nStrategic risk management frameworks (e.g. COSO, 2004; AS\/NZS, 1999, 2004;547\nFERMA, 2003) conventionally treat risk based decision making, namely the548\nidentification, evaluation and selection of options to manage risks, in a somewhat549\ncursory manner. And so the novelty of our coding (Fig. 1; Table 2) is best illustrated550\nwith reference to the decision theory literature. Notably, we have separated \u201cevaluate551\noptions\u201d into three elements: (i) forecasting the impact of options against each552\nevaluation criteria (e.g. technical feasibility); (ii) determining the relative merit of each553\noption; and (iii) determining the acceptability of the residual risk associated with each554\noption. We believe this provides an important advance to option evaluation, moving555\nbeyond the notion that the acceptability of a risk can be determined without considering556\nthe costs and benefits of maintaining vs. reducing risk levels (e.g. in using measures of557\nrisk as proxies for risk acceptability).558\nWe also highlight our inclusion of managerial review and option selection prior to559\nthe final risk management decision. Whilst not novel (e.g. Aven et al., 2006), it is560\ncrucial because it highlights our view that decision analysis should compliment, but not561\nreplace, the knowledge, intuitions and judgement of decision makers (Mintzberg,562\n1994). Further, risk based decisions should not reflect theoretically or analytically563\nderived perspectives that run counter to sound professional judgement (Hrudey and564\nHrudey, 2003). More specifically, it emphasises that because risk is at heart, an565\nexpression of uncertainty (Amendola, 2001), the outputs of a decision analysis must be566\ntreated diagnostically rather than deterministically, i.e., they should provide decision567\nsupport, not carte blanche decisions.568\n569\n5.3. Coding of maturity570\nOur research applies capability maturity modelling principles to the processes of571\nrisk analysis and risk based decision making (Tables 3 and 4). It allows users to572\ndistinguish the relative maturity of implementation of risk analysis and risk based573\ndecision making, presumed to correlate this with performance in managing risk. The574\norigins and logic of the hierarchy of maturity levels, particularly regarding the selection575\nand definition of attributes used to define process maturity, are summarised in Table 3576\n(for more detail, see MacGillivray, 2007c). This hierarchy is the heart of our model,577\nand the most valuable contribution by virtue of its usefulness as discussed below.578\n579\n5.4. Utility of the model for benchmarking580\nThroughout our work we have been concerned with improving risk management581\npractice and we are interested in vigilance on the ground. Hence we ask, who may use582\nthe model we have developed, and what will it enable them to do that they were583\npreviously unable to? The most obvious function of the model is as a tool for research584\non the form and, crucially, implementation of risk management within industry. At a585\nbasic level, this is valuable, because published investigations of the latter tend towards586\nthe anecdotal rather than methodologically rigorous (e.g. Dalgleish and Cooper, 2005;587\nAabo et al., 2005). From an organisational perspective, its principal function is588\nbenchmarking, which enables organisations to compare themselves against others in589\ntheir sector and beyond, and to identify and incorporate best practices. This is crucial590\nbecause risk management remains ethereal to many in terms of practice on the ground,591\ncreating a need for the systematic evaluation of strengths and weaknesses and the592\nsharing of best practice. It may also be used to drive improvements in the capabilities593\nof key suppliers and partners (e.g. through using maturity evaluations to inform594\nsupplier selection). Finally, we consider its potential within regulation, envisaging that595\nit may facilitate a step-change in the approach to regulating risk within utility sectors596\nfrom its current focus on reactive, outcome based approaches (e.g. water quality597\nstandards) and prescriptions (e.g. codes and regulations), towards a proactive,598\ncapability based approach.599\n600\n5.5. Empirical findings601\nFinally, we consider the contribution of our case study observations in their own602\nright. Three observations bear emphasising: descriptive risk research; a focus on the603\nimplementation of risk management; and a cross-functional perspective. We highlight604\nthe first due to the lack of theoretically informed descriptive risk research within the605\nwater utility sector. The importance of the second is borne out by casting our eyes606\nbeyond this sector, where one observes that academic treatments of risk management607\ntend to focus on technical and normative aspects, rather than institutional, behavioural,608\nor descriptive facets, which our findings stress. Finally, our function-specific approach609\ncounters the concept of \u201centerprise wide risk management,\u201d which appears to have610\ncreated a majority opinion amongst its practitioners that risk management is an over-611\narching strategic discipline rather than a devolved process with variations and nuances612\nof application within individual business functions.613\n614\n6. Conclusions615\nWe present a capability maturity model for benchmarking and improving risk616\nanalysis and risk based decision making, and illustrate its application to a cross-section617\nof water and wastewater utility functions within a single utility. The insight offered is618\nthree-fold:619\n\uf0b7 a synthesis of empirical observations with behavioral and normative risk620\nresearch to codify the processes of risk analysis and risk based decision making;621\n\uf0b7 an arrangement of these processes within a maturity framework that622\ndistinguishes their relative maturity of implementation from ad hoc to adaptive;623\n\uf0b7 a critical evaluation of the methods, techniques and maturity of risk analysis and624\nrisk based decision making across a range of utility functions.625\nThese findings provide researchers, utility managers, engineers, asset managers,626\noccupational health and safety representatives, public health officials, project managers,627\nchief finance officers and regulators a deeper understanding of the practical form and628\ntheoretical underpinnings of risk management, and how distinctions can be made629\nbetween organisational capabilities. This addresses an important gap in the literature630\nbecause, although the premise that institutional capacities rather than technical aspects631\nare the fundamental limiting factor in implementing risk management has earlier632\norigins (e.g. Garrick, 1988; Luehrman, 1997; Strutt, 2006), there remains a dearth of633\ndescriptive research on the practical form of risk management within the utility sectors634\nand, particularly, how it may be embedded. The latter is the subject of our ongoing635\nresearch.636\n637\nAcknowledgements638\nThis work has been part funded by the AWWA Research Foundation (AWWARF639\nproject RFP2939) and a consortium of international water utilities. The authors are640\nparticularly grateful to the case study utility and the lead individuals for their641\ncontributions, peer review and permission to publish. The comments and views herein,642\nhowever, are the authors\u2019 alone. BHM is co-funded by a UK Engineering and Physical643\nSciences Research Council (EPSRC) Doctoral training account.644\n645\nReferences646\nAabo, T.; Fraser, J.; Simkins, B. The rise and evolution of the chief risk officer:647\nenterprise risk management at Hydro One. Journal of Applied Corporate Finance.648\n17(3):62-75; 2005.649\nAmendola, A. Recent paradigms for risk informed decision making. Safety Sci. 40:17-650\n30; 2001.651\nArvai, J.L.; Gregory, R.; McDaniels, T.L. Testing a structured decision approach:652\nvalue-focused thinking for deliberative risk communication. Risk Anal. 21(6):1065-653\n1076; 2001.654\nAS\/NZS (Australian\/New Zealand Standard). AS\/NZS 4360:1999 Risk management.655\nStrathfield: Standards Association of Australia; 1999.656\nAS\/NZS (Australian\/New Zealand Standard). AS\/NZS 4360:2004 Risk management.657\nStrathfield: Standards Association of Australia; 2004.658\nAven, T.; Vinnem, J.E.; Wiencke, H.S. A decision framework for risk management,659\nwith application to the offshore oil and gas industry. Reliab Eng Syst Safe. In660\npress; 2006; available at: http:\/\/www.sciencedirect.com\/science\/article\/B6V4T-661\n4J9MSSC-2\/2\/5ad5d7aeb729a6d0d3cd0c93373fde01662\nAven, T.; K\u00f8rte, J. On the use of risk and decision analysis to support decision-663\nmaking. Reliab Eng Syst Safe. 79:289-299; 2003.664\nAWWA; EUREAU; WSAA; DVGW. Bonn Workshop 2001 \u2013 Key principles in665\nestablishing a framework for assuring the quality of drinking water: a summary.666\nAWWA, Denver, CO.; 2001.667\nCOSO (Committee of Sponsoring Organizations of the Treadway Commission).668\nEnterprise risk management \u2013 integrated framework. COSO; 2004.669\nCSA (Canadian Standards Association). Risk management: guidelines for decision670\nmakers. CAN\/CSA-Q850-97; 1997.671\nDalgleish, F.; Cooper, B.J. Risk management: developing a framework for a water672\nauthority. Int J Manage Environ Qual. 16(3): 235-249; 2005.673\nFaber, M.H.; Stewart, M.G. Risk assessment for civil engineering facilities: critical674\noverview and discussion. Reliab Eng Syst Safe. 80:173-184; 2003.675\nFERMA (Federation of European risk management associations). A risk management676\nstandard. FERMA; 2003; available at: http:\/\/www.ferma-677\nasso.org\/tabid\/195\/Default.aspx.678\nFischoff, B.; Lichtenstein, S.; Slovic, P.; Derby, S.; Keeneym R. Acceptable risk. New679\nYork: Cambridge University Press; 1981.680\nGarrick, B.J. The approach to risk analysis in three industries: nuclear power, space681\nsystems, and chemical process. Reliab Eng Syst Safe. 23:195-205; 1988.682\nGlaser, B.G; Strauss, A.L. The discovery of grounded theory. New York; Aldine; 1967.683\nHamilton, P.D.; Gale, P.; Pollard, S.J.T. A commentary on recent water safety684\ninitiatives in the context of water utility risk management. Environ Int. 32:958-966;685\n2006.686\nHealth and Safety Laboratory. Good practice and pitfalls in risk assessment. Health and687\nSafety Executive; research report 151; 2003; available at:688\nhttp:\/\/www.hse.gov.uk\/research\/rrhtm\/rr151.htm689\nHoyle, D. ISO 9000 Quality systems handbook, 4th edition. Butterworth-Heinemann;690\n2001.691\nHrudey S.E.; Hrudey E.J. Comments on the paper \u201cSociotechnical systems, risk692\nmanagement, and public health: comparing the North Battleford and Walkerton693\noutbreaks\u201d by Woo and Vicente. Reliab Eng Syst Safe. 82:343-345; 2003.694\nHrudey S.E.; Hrudey EJ. Safe drinking water\u2014lessons from recent outbreaks in695\naffluent nations. London: IWA Publishing; 2004.696\nHrudey, S.E., Hrudey, E. and Pollard, S.J.T. Risk management for assuring safe697\ndrinking water. Environ. Intl. 32: 948-957; 2006.698\nISO (International Organization for Standardization). ISO 9001 Quality management699\nsystems \u2013 requirements. Geneva: ISO; 2000.700\nJoy, J.; Griffiths, D. National minerals industry safety and health risk assessment701\nguideline. Minerals Council of Australia; Version 4; January 2005. available at:702\nhttp:\/\/www.mishc.uq.edu.au\/rag\/index.asp703\nLee, T. Assessment of safety culture at a nuclear reprocessing plant. Work Stress.704\n12(3):217-237; 1998.705\nLuehrman, T.A. What\u2019s it worth? A general manager\u2019s guide to valuation. Harvard706\nBusiness Review. 75(3):132-142; 1997.707\nMacGillivray, B.H.; Hamilton, P.D.; Strutt, J.E.; Pollard, S.J.T. Risk analysis strategies708\nin the water utility sector: an inventory of applications for better and more credible709\ndecision-making. Crit Rev Env Sci Tec. 36: 85-139; 2006.710\nMacGillivray, B.H.; Strutt, J.E.; Sharp, J.V.; Hamilton, P.D.; Pollard, S.J.T.711\nBenchmarking risk management within the water utility sector. Part I: Design of a712\ncapability maturity methodology. J Risk Res. 10(1):85-104; 2007a.713\nMacGillivray, B.H.; Strutt, J.E.; Sharp, J.V.; Hamilton, P.D.; Pollard, S.J.T.714\nBenchmarking risk management within the international water utility sector. Part II:715\nA survey of eight water utilities. J Risk Res. 10(1):105-123; 2007b.716\nMacGillivray, B.H. Benchmarking risk management practice within the water utility717\nsector. PhD thesis; Cranfield University; 2007c.718\nMatheson, D.; Matheson, J. The \u201csmart\u201d organization: Creating value through strategic719\nR&D. Cambridge, MA; Harvard Business School Press; 1998.720\nMHU (Major Hazards Unit). Hazard identification, risk assessment and risk control.721\nNew South Wales Department of Urban and Transport Planning. Advisory paper722\nno. 3; consultation draft; version A; 2003. available at:723\nhttp:\/\/www.planning.nsw.gov.au\/plansforaction\/mihaps-docs\/mihaps-docs.html724\nMintzberg, H. The rise and fall of strategic planning. Prentice Hall; New York; 1994.725\nNEA\/CSNI (Nuclear Energy Agency\/Committee on the Safety of Nuclear726\nOrganisations). Identification and assessment of organisational factors related to the727\nsafety of NPPs: state-of-the-art-report. OECD; Report 21(2); 1999; available at:728\nhttp:\/\/www.nea.fr\/html\/nsd\/docs\/1998\/csni-r98-17-vol1.pdf.729\nNZMOH (New Zealand Ministry of Health). How to prepare and develop public health730\nrisk management plans for drinking-water supplies. Wellington: Ministry of Health;731\n2001; available at: www.moh.govt.nz\/moh.nsf.732\nNHMRC. Australian drinking water guidelines. Canberra: NHMRC; 2004; available at:733\nwww.health.gov.au\/nhmrc\/publications\/synopses\/eh19syn.htm.734\nPaulk, M.C.; Curtis, B.; Chrissis, M.B.; Weber, C.V. Capability maturity model,735\nversion 1.1, IEEE Software. 10(4):18; 1993.736\nPayne, J.W.; Bettman, J.R.; Johnson, E.J. Behavioural decision research: A737\nconstructive processing perspective. Annu Rev Psychol. 43:87-132; 1992.738\nPollard, S.J.T.; Strutt, J.E.; MacGillivray, B.H.; Hamilton, P.D.; Hrudey, S.E. Risk739\nanalysis and management in the water utility sector \u2013 a review of drivers, tools and740\ntechniques. Trans. IChemE, Part B: Proc. Safety Environ. 82(B6): 1-10; 2004.741\nPollard, S.J.T., Strutt, J.E., MacGillivray, B.H., Sharp, J.V., Hrudey, S.E. and Hamilton,742\nP.D. Risk management capabilities \u2013 towards mindfulness for the international743\nwater utility sector. In: Water Contamination Emergencies: Enhancing our744\nResponse, Thompson, K.C. and Gray, J. (eds.), Royal Society of Chemistry745\nPublishing, Cambridge, 2006; pp.70-80.746\nPollard, S., Hrudey, S.E. and Hamilton, P.D. Risk analysis for more credible and747\ndefensible utility decisions, Awwa Research Foundation Project 2939, Awwa748\nResearch Foundation, Denver, CO; 2007749\nPower, M. The risk management of everything \u2014 rethinking the politics of uncertainty.750\nLondon: Demos; 2004.751\nReason, J. Managing the risks of organizational accidents. Ashgate, Aldershot, UK;752\n1997.753\nRosness, R. Risk influence analysis: a methodology for identification and assessment of754\nrisk reduction strategies. Reliab Eng Syst Safe. 60:153-164; 1998.755\nSlovic, P.; Fischoff, B.; Lichtenstein, S. Behavioural decision theory. Annu Rev756\nPsychol. 28:1-39; 1977.757\nSlovic, P. The construction of preference. American Psychologist. 50:364-371; 1995.758\nSEI (Software Engineering Institute). CMMI for systems engineering \/ software759\nengineering \/ integrated product development \/ supplier sourcing, version 1.1; 2002.760\navailable at http:\/\/www.sei.cmu.edu\/761\nStrauss, A.L.; Corbin, J. Grounded theory methodology: an overview, in N.K. Denzin762\nand Y.S. Lincoln (Eds.), Handbook of qualitative research. Thousand Oaks;763\nCA:Sage; 1994.764\nStrutt, J.E.; Sharp, J.V.; Terry, E.; Miles, R. Capability maturity models for offshore765\norganisational management. Environ Int. 32:1094-1105; 2006.766\nUKOOA (UK Offshore Oil Operators Association). Industry guidelines on a767\nframework for risk related decision support. London: UKOOA; 1999.768\nWHO (World Health Organisation). Water safety plans (revised draft). Report769\npublication WHO\/SDE\/WSH\/02.09; WHO; 2002.770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\nFig. 1. Risk analysis (left) and risk based decision making practices (right). Those encased784\nare considered key rather than critical, an important distinction in evaluating process785\nmaturity.786\nSystem characterisation\nHazard identification\nExposure assessment\nConsequence evaluation\nLikelihood evaluation\nRisk evaluation\nControl evaluation\nEstablish criteria for evaluating alternative risk\nreduction options\nIdentify risk management options\nEvaluate options\nManagerial review and option(s) selection\nEstablish risk acceptance criteria\n787\n788\n789\n790\n791\n792\n793\n794\n795\nKey: DWQM: drinking water quality management; AM: asset management; OH&S: occupational health and safety796\nmanagement; ENG: engineering; PM: project management.797\n798\nFig. 2. Spider diagram illustrating the maturity of implementation of risk analysis (left)799\nand risk based decision making (right) within the sub-sample (insufficient data was800\nobtained to evaluate the latter within engineering).801\nTable 1 Descriptions of the risk analysis practices and of the rationale for their inclusion in our802\nmodel803\nRisk analysis\npractice\nDescription Rationale\nSystem\ncharacterisation\nTo establish and describe the system\nwith which risk analysis is\nconcerned (e.g. workplace,\nengineering process, project).\nA comprehensive system understanding is a\nsine qua non for generating risk analysis\noutcomes that are valid and accepted by\nstakeholders.\nHazard\nidentification\nIdentifying situations, events, or\nsubstances with the potential for\ncausing adverse consequences, i.e.\nsources of harm or threats to the\nsystem.\nA hazard left unidentified is excluded from\nsubsequent analysis.\nExposure\nassessment\nWhilst hazard identification is\nconcerned with what can go wrong,\nThe potential existence of a hazard does not\nin itself constitute a risk, as each hazard\n1\n2\n3\n4\n5\nPM\nENG\nOH&SAM\nDWQM\n1\n2\n3\n4\n5\nPM\nENG\nOH&SAM\nDWQM\nprecursor identification focuses on\nhow and why things can go wrong,\nin other words identifying possible\nroutes to and causes of failure.\nrequires a process or pathway (precursor) to\nlead to its realisation. Thus, the value of this\npractice lies in both confirming the existence\nof pathways to failure (and therefore that a\nrisk exists) and informing the development\nof risk management options focussed at root\ncauses.\nControl\nevaluation\nThe identification and assessment of\nexisting technical, physical and\nadministrative controls which may\neither reduce the likelihood of a\nhazardous event occurring, or serve\nto mitigate its severity of\nconsequences. Assessment should\naddress both the criticality of the\ncontrols (e.g. based on their inherent\ncapacity to reduce risk, whether they\nare proactive or reactive, etc.) and\ntheir adequacy of design,\nmanagement and operation.\nAn evaluation of existing controls: informs\nthe evaluation of associated risk levels;\nserves to inform the development of risk\nmanagement options through identifying\nlatent and active control weaknesses (i.e.\nthrough serving as a gap analysis of existing\nrisk management measures); and captures\nthe historic basis for safe, reliable system\noperation.\nConsequence\nevaluation\nIdentifying the nature of the\nconsequences of a hazardous event\noccurring (e.g. financial,\nenvironmental) and assessing their\nseverity of impact.\nLikelihood\nevaluation\nThe evaluation of the likelihood (i.e.\nfrequency or probability) that a\nhazardous event will occur and lead\nto a defined severity of\nconsequence.\nRisk evaluation Combining measures of likelihood\nand consequence severity to derive\nan overall measure of risk, either\nqualitative (e.g. high, low) or\nquantitative (e.g. expected loss of\nlife, value at risk).\nDeriving and combining measures of\nconsequence and likelihood are required to\nestablish the overall level of risk associated\nwith a given hazard, so that management\nresources may be allocated accordingly and\nto assess the desirability of potential risk\nmanagement measures (e.g. to see if they\nsatisfy the ALARP criteria).\nTable 2 Descriptions of the risk based decision making practices and of the rationale for their804\ninclusion in our model805\nRisk based\ndecision\nmaking\npractice\nDescription Rationale\nEstablish\nrisk\nacceptance\ncriteria\nEstablishing criteria for\nevaluating the acceptability of\nrisk.\nIn the absence of such criteria, on what basis are\ndecisions taken on whether to mitigate or accept\nrisk?\nEstablish\ncriteria for\nevaluating\nalternative\nrisk\nmanagement\noptions\nEstablishing criteria used to\nevaluate the relative merit of\nalternative risk management\noptions (e.g. forecast risk\nreduction, technical\nfeasibility, cost of\nimplementation, latency of\neffects, environmental\nimpacts, etc.) and, where\ndeemed appropriate (e.g.\nwhere multi-attribute analysis\nis subsequently undertaken),\nweightings to establish their\nrelative importance.\nA range of risk management options may be\nconsidered for a particular decision context; the\ndecision as to which is considered the best option is\ninfluenced by many factors. Different concerns and\nvalues often need to be considered simultaneously,\nand their relative importance may be valued\ndifferently by various stakeholders (Faber and\nStewart, 2003). Making this explicit in the form of\ncriteria can improve the credibility and defensibility\nof decision making, minimise the possibility that\ndecisions will be second guessed or that their\nrationale be forgotten, remove barriers to\nstakeholder buy-in, and ensure the existence of an\naudit trail (SEI, 2002). More broadly, it enables\nvalue rather than \u201calternative focussed\u201d decision\nmaking, the latter being characterised by the\nselection of an \u201coptimal\u201d option from a set of\nimplied or poorly defined criteria (Arvai et al.,\n2001).\nIdentify risk\nmanagement\noptions\nGenerating alternative\nsolutions for the decision\nproblem.\nOptions not generated are excluded from subsequent\nevaluation and, ultimately, implementation.\nEvaluate\noptions\nThere are three elements to\nthis: forecasting the impact of\neach option against the\nindividual evaluation criteria;\ndetermining the relative merit\nof each option (e.g. via cost-\nbenefit analysis, multi-\nattribute analysis); and\ndetermining risk\nacceptability.\nSystematically evaluating the individual and\ncumulative merits of alternative options should\nprovide for more credible, defensible and rational\nrisk based decision making. Determining risk\nacceptability follows as it is risk management\noptions, not risks, which are unacceptable or\nacceptable (Fischoff et al., 1981), i.e. the\nacceptability of risk cannot be determined without\nconsidering the costs and benefits of maintaining vs.\nreducing current risk levels.\nManagerial\nreview and\noption(s)\nselection\nThe application of managerial\njudgement in reviewing the\npremises, assumptions, and\nlimitations of analyses, prior\nto the final decision (after\nAven et al., 2006).\nIn line with Mintzberg (1994), we consider that\ndecision analysis should compliment, but not\nreplace, the knowledge, intuitions and judgement of\ndecision makers, and further, that risk based\ndecisions should not reflect theoretically or\nanalytically derived perspectives that run counter to\nsound professional judgement (Hrudey and Hrudey,\n2003). More specifically, given that risk is, at a\nfundamental level, an expression of uncertainty, and\nthat the analysis of risk and decision alternatives is\nfurther subject to aleatory, epistemic and operational\nuncertainty (Amendola, 2001), the outputs must be\ntreated diagnostically rather than deterministically,\ni.e., they should provide decision support, not\ndecisions.\n806\nTable 3 Descriptions of the risk analysis process maturity attributes and their rationale for inclusion within our model\nAttribute Description Rationale Key aspects\nProcedures The rules guiding the\nexecution of risk analysis.\nProcedures serve to capture and disseminate\nknowledge of the optimal conduct of risk analysis\nso that it is maintained within the organisational\nmemory rather than as hidden expert knowledge\n(NEA\/CSNI, 1999), and so ensure its consistent,\nefficient conduct.\nAppropriate standardisation and formalisation of procedures taking\ninto account personnel experience and knowledge; participation of\nend users (e.g. risk analysts) in their development; matching detail\nwith complexity of work; making explicit the rationale for\nconducting risk analyses; being based on an analysis of the tasks\nrequired (NEA\/CSNI, 1999; Health and Safety Laboratory, 2003).\nRoles and\nresponsibilities\nAssignment of personnel to\nrisk analysis roles and\nresponsibilities.\nTo avoid the \u201cnot my job\u201d phenomenon (Joy and\nGriffiths, 2005), and ensure risk analysis receives\nappropriate focus and resource allocations.\nMatching role descriptions and assignment of responsibilities with\npersonnel competencies and authorities (NEA\/CSNI, 1999).\nSupporting well meaning statements that \u201crisk management is\neveryone\u2019s job\u201d with specific requirements.\nInitiation\ncriteria\nStages or conditions which\ninitiate risk analysis.\nTo ensure risk analyses is undertaken as required,\nrather than being initiated on an ad hoc, over\nzealous, or reactive basis, or marginalised as\n\u201cmake work.\u201d\nIdentifying where risk analysis is necessary vs. where adherence to\ncodes and standards can be said to discharge the duty (Health and\nSafety Laboratory, 2003; UKOOA, 1999), and making this explicit\nin cyclical and event-based criteria.\nResource\nmanagement\nThe planning, acquisition,\nand deployment of funds,\ntechniques and staff in\nsupport of risk analysis.\nResourcing of risk analysis is particularly critical\nduring periods of reduced budgets and downsizing,\nwhich may bring an emphasis on economic rather\nthan safe operation (NEA\/CSNI, 1999).\nSufficiency and availability of financial resources; access to\nsufficiently competent human resources; and a range of risk analysis\ntechniques which reflect the complexity of the organisation\u2019s\nactivities and working environment (Health and Safety Laboratory,\n2003).\nInput data\nmanagement\nThe identification,\ncollection, and storage of\nrisk analysis data inputs.\nThe systematic identification and capture of data\nrequirements serves to ensure analyses are\nunderpinned by objective data evaluation, rather\nthan reflecting best guesses in the guise of \u201cexpert\njudgement.\u201d\nThe definition of data requirements \/ data sources for risk analysis,\neither at the process level or, where not practical, on a case by case\nbasis, and mapping these to data collection and storage systems.\nOutput data\nmanagement\nThe collection, storage and\ndissemination of risk\nanalysis outputs.\nRisk analysis outputs must be systematically\nrecorded to inform decision makers, for audit and\ntraining purposes, and to facilitate future reviews\n(COSO, 2004; CSA, 2004). Further, this ensures\nstaff have current knowledge of the human,\ntechnical, organisational and environmental factors\nthat govern system safety (Reason, 1997).\nDocumenting in-depth the risk analysis outcomes, not simply the\noverall level of risk (e.g. sources of data, assumptions used, methods\nfollowed, etc.). Although in theory the storage media is unimportant\nas long as the outputs are easily retrievable (Health and Safety\nLaboratory, 2003), IT-based data systems (risk registers) have\nsignificant advantages, particularly in facilitating information flow\nbetween and across layers and boundaries of the organisation\n(COSO, 2004).\nVerification Ensuring compliance with\nrisk analysis procedures,\nand providing quality\ncontrol of the execution of\nrisk analysis.\nThe mere existence of procedures is not in itself\nenough to ensure that staff actions will be\nconsistent with them (Hoyle, 2001; ISO, 2000).\nErrors of omission or commission (e.g. due to\nmisunderstanding instructions, carelessness,\nfatigue or management override), may cause\ndeviations. Similarly, procedural compliance does\nnot ensure the quality of execution of risk analysis.\nImplementation of mechanisms to ensure adherence to procedures\n(e.g. auditing, \u201csign offs\u201d) and to sanction non-compliance. Quality\ncontrol mechanisms (e.g. peer reviews, Delphi panels) should be\nimplemented with explicit methods for controlling (e.g. establishing\ngroup consensus iteratively) or evaluating (e.g. quality criteria) the\nquality of analyses. An appropriate balance between the resources\nrequired, the constraints of bureaucracy, and the benefits of process\ncontrol should be struck.\nValidation Assessing the fundamental\ncorrectness of the risk\nanalysis process design\n(e.g. that the correct\ntechniques are being\napplied, that the correct\ninitiation criteria are in\nplace).\nThe willingness and means to question the validity\nof current risk analysis practices is required to\nshow due diligence and ensure that current\npractices are legitimate, and is further a\nprerequisite to the continual improvement of risk\nanalysis.\nFormalised approaches to validation include: statistical or\nmathematical approaches to validating technical methodologies,\nindependent peer reviews, and benchmarking surveys; and\ninformally may draw upon: professional networks, trade and\nscientific literature, etc.\nOrganisational\nlearning\nThe manner in which the\norganisation identifies,\nevaluates and implements\nimprovements to the design\nand execution of risk\nanalysis.\nMechanisms for verification and validation are\nmere panaceas if their findings are not acted upon,\ni.e., if they are not used to rectify deficiencies in\nthe design and execution of risk analysis.\nReviews should: be undertaken at specified intervals and on an event\ndriven-basis; consider a broad range of internal and external\nfeedback; focus on improving the validity of the risk analysis\nprocess and the effectiveness of its execution, not on ensuring it\ncomplies with a given standard; treat errors of omission or\ncommission in the execution of risk analysis not as isolated lapses\nrequiring sanction to prevent their re-occurrence, but as\nopportunities to identify and resolve root and common causes of\nerror; and be supported by a learning culture, wherein current\nmethods and approaches to risk analysis, and their underlying\nassumptions, are open to question and critical evaluation.\nStakeholder\nengagement\nThe engagement of\nstakeholders, both internal\nand external to the utility,\nfor the purpose of\nharnessing a broad range of\nperspectives, knowledge,\nskills and experience.\nThe legitimacy of risk analysis outputs depends\nupon appropriately broad stakeholder engagement,\nas risk is an intrinsically multi-faceted construct,\nwhose comprehensive understanding is often\nbeyond the capabilities of individuals or small\ngroups.\nA team approach to risk analysis which pools the knowledge, skills,\nexpertise and experience of a range of perspectives is preferable\n(Health and Safety Laboratory, 2003; MHU, 2003; Joy and Griffiths,\n2005). External stakeholders may be engaged to: capture expertise\n(e.g. consultants); confer additional legitimacy on the analyses;\ncommunicate due diligence (e.g. regulators); and capture community\nvalues and ensure they are incorporated within the analysis.\nCompetence The ability to demonstrate\nknowledge, skills, and\nexperience in risk analysis\nto the level required\n(Health and Safety\nLaboratory, 2003).\nThe legitimacy of risk analyses outcomes depends\nto a large extent on the capacity of staff to\ncritically evaluate available information and to\nsupplement it with their own knowledge and\nplausible assumptions (Rosness, 1998) , i.e. on\nstaff competencies.\nDefinition of required staff competencies in risk analysis; evaluation\nand implementation of appropriate education and training vehicles to\ndevelop \/ maintain those competencies (e.g. class room learning,\nexternal workshops); providing \u201con the job\u201d training under adequate\nsupervision; designing and implementing methods for evaluating the\nefficacy of educating and training (e.g. for measuring that the\nrequired competencies have been imparted).\n40\nTable 4 Descriptions of the risk analysis process maturity hierarchy, from ad hoc to adaptive1\nValidation\nA broad range of mechanisms are in place to capture feedback potentially\nchallenging the validity of the risk analysis process (e.g. benchmarking\nsurveys, professional networks, external peer reviews, mathematical\nvalidation of technical methodologies).\nLEVEL 5:\nAdaptive\nOrganisational\nlearning\nNorms and assumptions underpinning the design of the risk analysis process\nare openly questioned, critically evaluated and, where appropriate, revised in\nlight of validation findings (i.e. double loop learning).\nVerification\nVerification extends beyond rigorous mechanisms to ensure procedural\ncompliance (e.g. sign offs supplemented by in-depth audits) to provide formal\nquality control of risk analyses (e.g. peer reviews, challenge procedures,\nexternal facilitation, Delphi technique, etc.).LEVEL 4:\nControlled\nOrganisational\nlearning\nRoot and common causes of errors in the execution of risk analysis (e.g.\ndeficient communication, overly complex procedures, lack of education and\ntraining) are identified and resolved. Modifications to the design of the\nprocess are identified, evaluated and implemented within periodic and event-\ndriven reviews, but remain largely reactive and externally driven (i.e.\nmirroring changes to codes, standards, guidelines, etc.).\nThe critical and key risk analysis practices are explicitly undertaken.\nProcedures Procedures exist to guide the execution of risk analysis, with an appropriatedegree of standardisation, detail, and complexity.\nRoles and\nresponsibilities\nRisk analysis roles and responsibilities are allocated with sufficient regard for\nstaff competencies and authorities.\nInitiation\nCriteria\nCyclical and event-based criteria are in place to guide the initiation of risk\nanalyses.\nResource\nmanagement\nThe requisite monetary, human and technical resources are identified,\nacquired and deployed in support of risk analysis.\nInput data\nmanagement\nThe requisite data inputs are identified, acquired and deployed in support of\nrisk analysis.\nOutput data\nmanagement\nRisk analysis outputs are collected, stored and disseminated in a manner that\nsupports decision-making, satisfies audit requirements, and facilitates\norganisational learning.\nVerification\nBasic mechanisms are in place to ensure compliance with risk analysis\nprocedures, focussing on outputs rather than tasks performed (e.g. sign offs\non receipt of completed risk analyses).\nValidation The validity of the risk analysis process is questioned in light of changes toregulations, codes and standards.\nOrganisational\nlearning\nNon-compliances with risk analysis procedures are resolved on a case by case\nbasis (i.e. treated as isolated errors requiring sanction to prevent their\nrecurrence). Improvements to the design of the risk analysis process are\nimplemented in a reactive, ad hoc manner (e.g. in response to changes in\ncodes or regulations).\nStakeholder\nengagement\nA broad cross section of internal and external knowledge, experience, skills\nand perspectives is reflected within risk analysis, based on explicit guidelines\nor criteria for stakeholder engagement.\nLEVEL 3:\nDefined\nCompetence\nStaff exhibit adequate knowledge, skills and experience in risk analysis.\nEducation and training in risk analysis is planned and executed based on\nestablished competency requirements.\nLEVEL 2:\nRepeatable The critical risk analysis practices are explicitly undertaken.\nLEVEL 1:\nAd hoc\nRisk analysis is absent; or the critical practices are implicitly or incompletely\nperformed.\n41\nTable 5 Summary of the undertaking of each risk analysis practice within the sub-sample1\nAsset managementDrinking water quality management Occupational health and safety\nmanagement Treatment plants Major dams*\nProject management Engineering\nSystem\ncharacterisation\nSchematics of water supply systems\nwere produced. Data was obtained\nto characterise the following system\nelements: catchment (e.g.\ngeomorphology, climate, land uses);\nsource water (e.g. surface or ground\nwater, flow and reliability, seasonal\nchanges); storage tanks, reservoirs\nand intakes (e.g. detention times,\ndesign); treatment and distribution\nsystems (e.g. processes,\nconfiguration, monitoring); current\noperational procedures; point\nsources of pollution; and consumers\n(e.g. population, demand patterns).\nChecklists were used to\ninterrogate characteristics of\nthe work spaces and the type\nand methods of work to be\nundertaken (e.g. existence \/\nlocation of pits, shafts, ducts,\npressure vessels, access and\negress routes, ventilation,\nisolation and lockout\nprocedures, substances used,\netc.).\nPlant\ncomponents\nwere identified,\ntheir condition\nand performance\nevaluated\nthrough asset\ninspections, and\ncurrent operating\nand maintenance\nregimes detailed.\nEngineering\nassessments of dams\nwere undertaken,\ndrawing on technical\nreports, site visits,\nflood and earthquake\nloadings, dam safety\nstandards, etc.\nProject options were\ncharacterised through\nscope development and\nvalue management\nworkshops. These\ndetailed the project\nneed and relevant\nassumptions and\nconstraints, before\ncharacterising each\noption in terms\nincluding their:\nfunctional\nspecifications,\ncapacities, required\ninputs and outputs, and\nrelative costs and\nbenefits.\nPrior to the application\nof HAZOP studies,\nprocess and\ninstrumentation\ndiagrams \u2013 which show\nthe interconnection of\nprocess equipment and\nthe instrumentation\nused for process control\n\u2013 were created.\nHazard\nidentification\nChemical, microbiological, physical\nand radiological water quality\nhazards (e.g. chlorine sensitive\npathogens) were identified on a\nHazards were identified via\nthe use of task, substance and\nworkplace specific checklists.\nWhere deemed relevant, this\nA FMECA-type\napproach linked\npotential hazards\n(e.g. supernatant\nSignificant failure\nmodes (flood,\nearthquake, and static\nloading) were\nHazards threatening the\ndelivery of the project\noption(s) on time, to\nbudget, and within the\nHAZOP studies\nidentified potential\ndeviations from process\ndesign intent (i.e.\n42\nsystem and sub-system (e.g.\ncatchment, treatment) specific basis\nthrough a checklist-based approach.\nwas supplemented by systems\nengineering techniques,\nincident and near miss\nrecords, and brainstorming.\nidentified. required quality\nparameters, were\nidentified through\nfacilitated\nbrainstorming,\nstructured with\nreference to generic\nhazard categories.\nhazards) through the\napplication of guide\nwords (e.g. low, high,\nnone) to process\nparameters (e.g. ozone\nflow).\nExposure\nassessment\nKnowledge of the environmental\nbehaviour of hazards and the system\nunder examination, technical\njudgement, incident reports, survey\nmaps, and monitoring records were\nsynthesised to link hazards (e.g.\nchlorine sensitive pathogens) to their\nsources (e.g. dairy farming or\ngrazing) and to the events which\nmay lead to their realisation (e.g.\nrunoff or percolation from land\nbased activities).\nThere was an absence of\nexplicit provisions for\nidentifying the precursors to\nidentified hazards, one\nexception being for hazards\narising from manual handling\nactivities, where checklists\nexamined which aspects of the\nactions and movements,\nworkplace layout, and\nworking posture generated\nsaid hazards.\noverflows to\nsurroundings or\ntemporary\npipework\npumps) to their\ndirect causes\n(e.g. not enough\ncapacity to hold\nor evaporate\nsludge received)\nfor each\ncomponent and\nfor the plant as a\nwhole. Informed\nby site visits,\nincident records,\nand feedback\nfrom operating\nand maintenance\nstaff.\nNo inference\npossible.\nHazards (e.g. aqueduct\nerosion) were linked to\ntheir direct causes (e.g.\nmajor storm runoff;\nwater release from\nfailed stormwater\ndams).\nEngineering judgement\nwas applied to identify\npotential causes of\ndeviations from design\nintent (e.g. human\nerror: acts of omission\nor commission;\nequipment failure; and\nexternal events).\nControl\nevaluation\nActions, activities and processes\napplied to mitigate the introduction\nor transport of hazards from\ncatchment to customer tap (e.g.\ncatchment protection, pre-treatment,\nHealth and safety risk controls\nwere identified with reference\nto a control hierarchy which\nestablished their relative\ncriticality: engineering (e.g.\nNot observed to\nhave been\nexplicitly\nundertaken.\nThe influence of\nstructural and non-\nstructural (e.g. early\nwarning systems)\ncontrols was\nNot observed to have\nbeen explicitly\nundertaken.\nSystems or procedures\ndesigned to prevent,\ndetect, provide early\nwarning, or mitigate the\nconsequences of a\n43\nozonation) were identified via a\nchecklist-type approach applied to\nsystem schematics. Critical controls\nwere identified via set criteria.\nTechnical data, consultations with\noperators, and site visits informed\nsurvey-based evaluations of their\nadequacy of design, management\nand operation with reference to key\nattributes (e.g. infrastructure;\nplanning, procedures and legislation;\nmonitoring; and auditing).\nsubstitution, isolation, design\nmodification, guarding),\nadministrative (e.g. training,\nsupervision, procedures), and\npersonal protective equipment.\nNo explicit provision for\nevaluating their adequacy of\ndesign, management or\noperation.\nincorporated within\nthe modelling of\nfailure scenarios (i.e.\nwithin event trees,\ndam break modelling,\netc.).\ndeviation (i.e.\nsafeguards) were\nidentified. No explicit\nprovision for evaluating\ntheir adequacy of\ndesign, management or\noperation.\nConsequence\nevaluation\nThis may be generalised as the judgement-based interpretation of limited data sets describing the nature and severity of consequences of past hazardous events (e.g. in\noccupational health and safety: cost of claims, lost time due to incidents) to derive a credible evaluation of the potential consequence(s) of uncertain future events.\nEvaluations were near uniformly characterised with reference to descriptors of the nature (e.g. environmental, financial) and severity of consequences of events\nenshrined within the utility\u2019s portfolio of risk ranking techniques. However, isolated applications of mathematical modelling (e.g. event tree analysis, dam break\nmodelling, inundation mapping, and economic impact evaluations in major dam risk analysis; event tree analysis in one occupational health and safety risk analysis\napplication) were observed.\nLikelihood\nevaluation\nMay be generalised as the judgement-based interpretation of data pertaining to the frequency of past hazardous events (e.g. water quality exceedence frequencies) in light\nof analyst(s) knowledge, experience, and assumptions. Evaluations were near uniformly characterised with reference to likelihood benchmarks within risk ranking\ntechniques. However, isolated applications of mathematical modelling were observed (e.g. in major dam risk analysis, network reliability analysis, etc.).\nRisk evaluation Outside of isolated risk analyses driven by consultants (e.g. notional costs of risk and statistical lives lost were derived in major dam risk analysis), risk was expressed in\nqualitative terms (extreme, high, medium or low) derived by combining estimates of consequence severity and likelihood on a risk matrix.\n44\nTable 6 Summary of the undertaking of each risk based decision making practice within the sub-sample1\n2\nDrinking water quality\nmanagement\nOccupational health and\nsafety management\nAsset management Project management\nEstablish risk acceptance\ncriteria\nCorporate policy was to reduce risks to a level \u201cas low as reasonably practicable (ALARP).\u201d The ALARP principle recognises that it would be\npossible to spend infinite time, effort and money attempting to reduce a risk to zero, and reflects the idea that the benefits of risk reduction should\nbe balanced with the practicality of implementation. However, ALARP was not referred to within individual functions\u2019 risk management\nprocedures, with the exception of OH&S and in major dam safety management. In the latter, risk acceptability considered three criteria: life\nsafety criteria; ALARP, and the de minimis risk concept, in order of stringency.\nEstablish criteria for\nevaluating alternative risk\nmanagement options\nNot explicitly defined.\nInterviewees referred to cost,\ntime and effort required for\nimplementation; forecast risk\nreduction; regulatory\ncompliance; risks introduced\n(e.g. disinfection by-products);\ngeographical and technical\nfeasibility (e.g. site\nconstraints); operability;\nmanpower required; and social\nand political concerns.\nNot explicitly defined.\nForecast risk reduction,\ncost of implementation,\nand technical feasibility\nwere referred to by one\ninterviewee.\nDefined for below ground major water\nmains: qualitative risk reduction, cost\nof implementation, and latency of\neffects; for major dams: cost of\nimplementation, and forecast reduction\nin statistical lives lost and economic\nlosses from dam failure events\n(weighted to ensure preference for\nreducing lives lost).\nNot explicitly defined. Although project\nmanagers were explicitly required to take\na cost-benefit approach in evaluating risk\nmanagement options, the scope of these\nconsiderations, i.e. the criteria with which\ncosts and benefits were determined with\nreference to, was not defined.\nIdentify risk management\noptions\nOptions (e.g. infrastructure\nupgrades, fencing off sensitive\ncatchments, educating and\ntraining operators) were\nOptions (e.g.\nintroducing standard\nwork practices) were\ntypically generated in\nOptions (e.g. for wastewater treatment\nplants: capital projects, alterations to\noperating or maintenance regimes,\ncontingency plans; for dams: structural\nOptions were typically generated by the\nproject manager in consultation with\nrelevant stakeholders (e.g. engineering\nstaff, environmental representatives), or\n45\ngenerated by groups\nresponsible for the risk analysis\nof each sub-system (e.g.\ncatchment) in consultation with\nrelevant specialists (e.g.\nengineering, operations).\nbrainstorming sessions\ninvolving a broad cross-\nsection of regional \/\ndepartmental staff, and,\nwhere relevant, OH&S\nstaff.\nand non structural measures, such as\ninstalling external back up seals on\nconcrete faced rockfill dams, or early\nwarning systems, respectively) were\ngenerated by those groups responsible\nfor the risk analysis of each asset class\nin consultation with operating and\nmaintenance staff.\nwithin the risk analysis workshops\nthrough group brainstorming. This was\ninformed by predefined measures for:\nreducing likelihood of occurrence (e.g.\naudit and compliance programs, training,\npreventative maintenance); reducing\nimpact of occurrence (e.g. contingency\nplanning, engineering and structural\nbarriers, early warning devices); and risk\ntransfer (e.g. contracts; insurance\narrangements).\nThe impact of\noptions against\nindividual\nevaluation\ncriteria\nMethods ranged from the application of professional judgement, to the revision of risk analyses (i.e. to derive the forecast risk reduction), to\nstakeholder consultations, cost-estimations, and engineering studies (e.g. feasibility studies in major dam safety management). However, given\nthat in most cases the evaluation criteria were not explicitly defined, the undertaking of this tended towards the informal or implicit.\nDetermining\nrelative merit\nof options\nLargely informal and judgement-based, although the use of formal cost-benefit analysis was observed within asset management\u2019s approach to\nprioritising major dam safety upgrades, whilst cost effectiveness evaluations informed prioritisations of the replacement of below ground major\nwater mains. Furthermore, risk management options that took the form of capital projects valued in excess of approx. $150,000 (US) underwent\nformal cost-benefit analysis as part of the capital approval process.\nEvaluate\noptions\nThe\nacceptability\nof risk\nThe limited application of cost-benefit analysis in the context of evaluating risk management options meant that the determination of risk\nacceptability was typically judgement-based.\nManagerial review and\noption(s) selection\nWhilst our interviewees referred to peer reviews of varying formality as helping to shape the final option(s) selection across our sub-sample, the\ndata does not allow for a meaningful analysis of the roles of judgement, experience, bias, power structures, etc. in shaping decision outcomes.\n1\n"}
{"doi":"10.1214\/EJP.v13-484","coreId":"95156","oai":"oai:eprints.lse.ac.uk:23919","identifiers":["oai:eprints.lse.ac.uk:23919","10.1214\/EJP.v13-484"],"title":"The McKean stochastic game driven by a spectrally negative L\u00e9vy process","authors":["Baurdoux, Erik J.","Kyprianou, Andreas E."],"enrichments":{"references":[{"id":17270598,"title":"A potential-theoretical review of some exit problems of spectrally negative L\u00b4 evy processes.","authors":[],"date":"2005","doi":null,"raw":"Pistorius, M.R. (2005) A potential-theoretical review of some exit problems of spectrally negative L\u00b4 evy processes. S\u00b4 eminaire de Probabilit\u00b4 es XXXVIII, 30\u201341.","cites":null},{"id":17270602,"title":"An approach for solving perpetual optimal stopping problems driven by L\u00b4 evy processes.","authors":[],"date":"2007","doi":"10.1080\/17442500601108508","raw":"Surya, B.A. (2007) An approach for solving perpetual optimal stopping problems driven by L\u00b4 evy processes. Stochastics. 79 337\u2013361.","cites":null},{"id":17270599,"title":"An excursion theoretical approach to some boundary crossing problems and the Skorokhod embedding for re\ufb02ected L\u00b4 evy processes.","authors":[],"date":"2006","doi":"10.1007\/978-3-540-71189-6_15","raw":"Pistorius, M.R. (2006) An excursion theoretical approach to some boundary crossing problems and the Skorokhod embedding for re\ufb02ected L\u00b4 evy processes. S\u00b4 eminaire de Probabilit\u00b4 es XL, 287\u2013308.","cites":null},{"id":17270601,"title":"Optimal stopping rules.","authors":[],"date":"1977","doi":"10.1007\/springerreference_205515","raw":"Shiryaev, A.N. (1977) Optimal stopping rules. Springer.","cites":null},{"id":17270600,"title":"Stochastic Integration and Di\ufb00erential Equations. 2nd Edition.","authors":[],"date":"2004","doi":"10.1007\/978-3-662-02619-9","raw":"Protter, P. (2004) Stochastic Integration and Di\ufb00erential Equations. 2nd Edition. Springer.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-02-14","abstract":"We consider the stochastic-game-analogue of McKean's optimal stopping problem when the underlying source of randomness is a spectrally negative L\u00e9vy process. Compared to the solution for linear Brownian motion given in Kyprianou (2004) one finds two new phenomena. Firstly the breakdown of smooth fit and secondly the stopping domain for one of the players `thickens' from a singleton to an interval, at least in the case that there is no Gaussian component","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/95156.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/23919\/1\/McKean_stochastic_game_driven_by_a_spectrally_negative_L%C3%A9vy_process_%28lsero%29.pdf","pdfHashValue":"15876423edc8bfe34af4e6f02d61d048fdd3d45f","publisher":"Institute of Mathematical Statistics","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:23919<\/identifier><datestamp>\n      2014-03-13T17:15:49Z<\/datestamp><setSpec>\n      74797065733D43454E54524553:4C53455F52435F3633<\/setSpec><setSpec>\n      74797065733D4445505453:4C53452D5354<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/23919\/<\/dc:relation><dc:title>\n        The McKean stochastic game driven by a spectrally negative L\u00e9vy process<\/dc:title><dc:creator>\n        Baurdoux, Erik J.<\/dc:creator><dc:creator>\n        Kyprianou, Andreas E.<\/dc:creator><dc:subject>\n        QA Mathematics<\/dc:subject><dc:description>\n        We consider the stochastic-game-analogue of McKean's optimal stopping problem when the underlying source of randomness is a spectrally negative L\u00e9vy process. Compared to the solution for linear Brownian motion given in Kyprianou (2004) one finds two new phenomena. Firstly the breakdown of smooth fit and secondly the stopping domain for one of the players `thickens' from a singleton to an interval, at least in the case that there is no Gaussian component.<\/dc:description><dc:publisher>\n        Institute of Mathematical Statistics<\/dc:publisher><dc:date>\n        2008-02-14<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/23919\/1\/McKean_stochastic_game_driven_by_a_spectrally_negative_L%C3%A9vy_process_%28lsero%29.pdf<\/dc:identifier><dc:identifier>\n          Baurdoux, Erik J. and Kyprianou, Andreas E.  (2008) The McKean stochastic game driven by a spectrally negative L\u00e9vy process.  Electronic Journal of Probability, 13.  pp. 173-197.  ISSN 1083-6489     <\/dc:identifier><dc:relation>\n        http:\/\/www.math.washington.edu\/~ejpecp\/index.php<\/dc:relation><dc:relation>\n        10.1214\/EJP.v13-484<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/23919\/","http:\/\/www.math.washington.edu\/~ejpecp\/index.php","10.1214\/EJP.v13-484"],"year":2008,"topics":["QA Mathematics"],"subject":["Article","NonPeerReviewed"],"fullText":"  \nErik Baurdoux\nThe McKean stochastic game driven by a \nspectrally negative L\u00e9vy process \nArticle (Accepted version) \n(Refereed) \n \nOriginal citation: \nBaurdoux, Erik J. and Kyprianou, Andreas E. (2008) The McKean stochastic game driven by a \nspectrally negative L\u00e9vy process. Electronic journal of probability , 13 . pp. 173-197. ISSN 1083-\n6489 \n \n\u00a9 2008 The Authors  \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/23919\/\n \nAvailable in LSE Research Online: March 2011 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final manuscript accepted version of the journal article, \nincorporating any revisions agreed during the peer review process.  Some differences between \nthis version and the published version may remain.  You are advised to consult the publisher\u2019s \nversion if you wish to cite from it. \n \nSubmitted April 2007, Resubmitted December 2007\nTHE MCKEAN STOCHASTIC GAME DRIVEN BY A\nSPECTRALLY NEGATIVE LE\u00b4VY PROCESS\nERIK BAURDOUX\nDepartment of Statistics, London School of Economics, Houghton Street, London, WC2A 2AE,\nUK\nEmail: e.j.baurdoux@lse.ac.uk\nANDREAS E. KYPRIANOU\nDepartment of Mathematical Sciences, University of Bath, Bath BA2 7AY, UK.\nEmail: a.kyprianou@bath.ac.uk\nAMS 2000 Subject classification: Primary 60J99; secondary 60G40, 91B70.\nKeywords: Stochastic games, optimal stopping, pasting principles, fluctuation theory, Le\u00b4vy\nprocesses.\nAbstract\nWe consider the stochastic-game-analogue of McKean\u2019s optimal stopping problem when the\nunderlying source of randomness is a spectrally negative Le\u00b4vy process. Compared to the so-\nlution for linear Brownian motion given in Kyprianou (2004) one finds two new phenomena.\nFirstly the breakdown of smooth fit and secondly the stopping domain for one of the play-\ners \u2018thickens\u2019 from a singleton to an interval, at least in the case that there is no Gaussian\ncomponent.\n1 Introduction.\nLet X = {Xt : t \u2265 0} be a Le\u00b4vy process defined on a filtered probability space (\u2126,F ,F,P),\nwhere F := {Ft : t \u2265 0} is the filtration generated by X which is naturally enlarged (cf.\nDefinition 1.3.38 of Bichteler (2002)). Write T0,\u221e for the family of stopping times with respect\nto F. For x \u2208 R denote by Px the law of X when it is started at x and write simply P0 = P.\nAccordingly we shall write Ex and E for the associated expectation operators. In this paper\nwe shall assume throughout that X is spectrally negative meaning here that it has no positive\njumps and that it is not the negative of a subordinator. It is well known that the latter allows\nus to talk about the Laplace exponent \u03c8(\u03b8) := logE[e\u03b8X1 ] for \u03b8 \u2265 0. In general one may write\n\u03c8(\u03b8) = a\u03b8 +\n\u03c32\n2\n\u03b82 +\n\u222b\n(\u2212\u221e,0)\n(e\u03b8x \u2212 1\u2212 \u03b8x1{x>\u22121})\u03a0(dx), for \u03b8 \u2265 0 (1)\nwhere a \u2208 R, \u03c32 \u2265 0 and where the jump measure \u03a0 of X has zero mass on [0,\u221e) and satisfies\u222b\n(\u2212\u221e,0)\n(1 \u2227 x2)\u03a0(dx) <\u221e. (2)\n1\n2 1 Introduction.\nThis paper is concerned with stochastic games in the sense of, for example, Dynkin (1969),\nCvitanic\u00b4 and Karatzas (1996) and Kifer (2000). We are principally interested in showing,\nunder certain assumptions, the existence of a pair of stopping times \u03c4\u2217 and \u03c3\u2217 in T0,\u221e such\nthat for all x \u2208 R and all stopping times \u03c4, \u03c3 \u2208 T0,\u221e,\nMx(\u03c4, \u03c3\u2217) \u2264Mx(\u03c4\u2217, \u03c3\u2217) \u2264Mx(\u03c4\u2217, \u03c3), (3)\nwhere\nMx(\u03c4, \u03c3) = Ex[e\u2212r\u03c4 (K \u2212 eX\u03c4 )+1{\u03c4\u2264\u03c3} + e\u2212r\u03c3((K \u2212 eX\u03c3 )+ + \u03b4))1{\u03c3<\u03c4}]\nand K, \u03b4 > 0. When this happens we shall refer the pair (\u03c4\u2217, \u03c3\u2217) as a stochastic saddle\npoint (also known as Nash equilibrium cf. Ekstro\u00a8m and Peskir (2006)) and we shall refer\nto V (x) = Mx(\u03c4\u2217, \u03c3\u2217) as the value of the game (3). Moreover we shall refer to the triple\n(\u03c4\u2217, \u03c3\u2217, V ) as a solution to the stochastic game (3). Another objective is to be able to say\nsomething constructive about the nature of the stopping times \u03c4\u2217 and \u03c3\u2217 as well as the function\nV . The assumptions we shall make are that the parameter r satisfies\n0 \u2264 \u03c8(1) \u2264 r and r > 0. (4)\nNote that the assumption that r > 0 conveniently means that the gain in the expectations in\n(3) is well defined and equal to zero on the event {\u03c3 = \u03c4 = \u221e}. In Section 10 at the end of\nthis paper we shall make some remarks on the case that r = 0 and \u03c8(1) > 0.\nWhen \u03c8(1) = r > 0 the stochastic game (3) can be understood to characterise the risk neutral\nprice of a so-called game option in a simple market consisting of a risky asset whose value\nis given by {eXt : t \u2265 0} and a riskless asset which grows at rate r (cf. Kifer (2000)). The\nlatter game option is an American-type contract with infinite horizon which offers the holder\nthe right but not the obligation to claim (K \u2212 eX\u03c3 )+ at any stopping time \u03c3 \u2208 T0,\u221e, but in\naddition, the contract also gives the writer the right but not the obligation to force a payment\nof (K \u2212 eX\u03c4 )+ + \u03b4 at any stopping time \u03c4 \u2208 T0,\u221e. This paper does not per se discuss the\nfinancial consequences of the mathematical object (3) however.\nThe stochastic game (3) is closely related to the McKean optimal stopping problem\nU(x) = sup\n\u03c4\u2208T0,\u221e\nEx[e\u2212r\u03c4 (K \u2212 eX\u03c4 )+] (5)\nwhich, when r = \u03c8(1), characterises the value of a perpetual American put option (cf. McKean\n(1965)). Indeed, should it be the case that the stochastic saddle point in (3) is achieved when\n\u03c3 = \u221e, then U = V . Thanks to a plethora of research papers on the latter topic it is known\nthat an optimal stopping strategy for (5) is then\n\u03c4\u2217 = inf{t > 0 : Xt < log(KE[eXer ])}\nwhere Xt = infs\u2264tXs and er is an exponentially distributed random variable with parameter\nr which is independent of X. We refer to Chan (2004) and Mordecki (2002) who handled\nspecifically the case that X is spectrally negative and the case that X is a general Le\u00b4vy process\nrespectively. The stochastic game (3) may therefore be thought of as a natural extension of\nthe McKean optimal stopping problem and we henceforth refer to it as the McKean stochastic\ngame.\nDespite the fact that a solution to the stochastic game (3) has been explicitly characterised for\nthe case that X is a linear Brownian motion in Kyprianou (2004), it turns out that working\nThe McKean stochastic game\nwith spectrally negative Le\u00b4vy processes, as we do here, is a much more difficult problem.\nNaturally, this is the consequence of the introduction of jumps which necessitates the use\nof more complicated potential and stochastic analysis as well as being the cause of a more\ncomplicated optimal strategy for particular types of spectrally negative Le\u00b4vy processes thanks\nto the possibility of passing barriers by jumping over them. Indeed the analysis performed\nin this paper leaves open a number of finer issues concerning the exact characterisation of\nthe solution, in particular when a Gaussian component is present. In that case, it appears\nthat a considerably more subtle analysis is necessary to take account of how the strategies of\nthe sup-player and inf-player (who are looking for a maximising \u03c4\u2217 and minimising \u03c3\u2217 in (3),\nrespectively) will depend on the \u2018size\u2019 of the jumps compared to the Gaussian coefficient. This\nis left for further study and in this respect, the current work may be seen as a first treatment\non the topic. The case of two-sided jumps is also an open issue and we refer to Remark 8 later\nin the text for some discussion on the additional difficulties that arise. Finally we refer the\nreader to Ku\u00a8hn and Gapeev (2005) and Baurdoux and Kyprianou (2008) for other examples\nof stochastic games driven by Le\u00b4vy processes.\n2 Solutions to the McKean stochastic game.\nThe conclusions of Ekstro\u00a8m and Peskir (2006) guarantee that a solution to the McKean stochas-\ntic game exists, but tells us nothing of the nature of the value function. Below in Theorems\n2, 3 and 4 we give a qualitative and quantitative exposition of the solution to (3) under the\nassumption (4). Before doing so we need to give a brief reminder of a class of special functions\nwhich appear commonly in connection with the study of spectrally negative Le\u00b4vy processes\nand indeed in connection with the description below of the McKean stochastic game. For each\nq \u2265 0 we introduce the functions W (q) : R \u2192 [0,\u221e) which are known to satisfy for all x \u2208 R\nand a \u2265 0\nEx[e\u2212q\u03c4\n+\na 1{\u03c4+a <\u03c4\u22120 }] =\nW (q)(x \u2227 a)\nW (q)(a)\n, (6)\nwhere\n\u03c4+a := inf{t > 0 : Xt > a} and \u03c4\u22120 = inf{t > 0 : Xt < 0}\n(cf. Chapter 8 of Kyprianou (2006)). In particular it is evident that W (q)(x) = 0 for all x < 0\nand further, it is known that on (0,\u221e) W (q) is almost everywhere differentiable, there is right\ncontinuity at zero and \u222b \u221e\n0\ne\u2212\u03b2xW (q)(x)dx =\n1\n\u03c8(\u03b2)\u2212 q\nfor all \u03b2 > \u03a6(q), where \u03a6(q) is the largest root of the equation \u03c8(\u03b8) = q (of which there are\nat most two). For convenience we shall write W in place of W (0). Associated to the functions\nW (q) are the functions Z(q) : R\u2192 [1,\u221e) defined by\nZ(q)(x) = 1 + q\n\u222b x\n0\nW (q)(y)dy\nfor q \u2265 0. Together the functions W (q) and Z(q) are collectively known as scale functions\nand predominantly appear in almost all fluctuation identities for spectrally negative Le\u00b4vy\nprocesses. For example it is also known that for all x \u2208 R and a, q \u2265 0,\nEx[e\u2212q\u03c4\n\u2212\n0 1{\u03c4+a >\u03c4\u22120 }] = Z\n(q)(x \u2227 a)\u2212 Z\n(q)(a)\nW (q)(a)\nW (q)(x \u2227 a) (7)\n4 2 Solutions to the McKean stochastic game.\nand\nEx[e\u2212q\u03c4\n\u2212\n0 1{\u03c4\u22120 <\u221e}] = Z\n(q)(x)\u2212 q\n\u03a6(q)\nW (q)(x), (8)\nwhere q\/\u03a6(q) is to be understood in the limiting sense \u03c8\u2032(0) \u2228 0 when q = 0.\nIf we assume that\nthe jump measure X has no atoms when X has bounded variation\nthen it is known from existing literature (cf. Chan and Kyprianou (2005) and Doney (2005))\nthat W (q) \u2208 C1(0,\u221e) and hence Z(q) \u2208 C2(0,\u221e) and further, if X has a Gaussian component\nthey both belong to C2(0,\u221e). For computational convenience we shall proceed with the\nabove assumption on X. It is also known that if X has bounded variation with drift d, then\nW (q)(0) = 1\/d and otherwise W (q)(0) = 0. (Here and in the sequel we take the canonical\nrepresentation of a bounded variation spectrally negative Le\u00b4vy process Xt = dt\u2212 St for t \u2265 0\nwhere {St : t \u2265 0} is a driftless subordinator and d is a strictly positive constant which is\nreferred to as the drift). Further,\nW (q)\u2032(0+) =\n\uf8f1\uf8f2\uf8f3 2\/\u03c3\n2 when \u03c3 > 0,\n(\u03a0(\u2212\u221e, 0) + q)\/d2 when X is of bounded variation with \u03a0(\u2212\u221e, 0) <\u221e,\n\u221e otherwise.\n(9)\nConsider the exponential change of measure\ndP1\ndP\n\u2223\u2223\u2223\u2223\nFt\n= eXt\u2212\u03c8(1)t. (10)\nUnder P1, the process X is still a spectrally negative Le\u00b4vy process and we mark its Laplace\nexponent and scale functions with the subscript 1. It holds that\n\u03c81(\u03bb) = \u03c8(1 + \u03bb)\u2212 \u03c8(1) (11)\nfor \u03bb \u2265 0 and, by taking Laplace transforms, we find\nW\n(q)\n1 (x) = e\n\u2212xW (q+\u03c8(1))(x) (12)\nfor q \u2265 0. The reader is otherwise referred to Chapter VII of Bertoin (1996) or Chapter\n8 of Kyprianou (2006) for a general overview of scale functions of spectrally negative Le\u00b4vy\nprocesses.\nFor comparison with the main results in Theorems 2, 3 and 4 below we give the solution to the\nMcKean optimal stopping problem as it appears in Chan (2004) (see also Mordecki (2002)).\nTheorem 1 For the McKean optimal stopping problem under (4) we have\nU(x) = KZ(r)(x\u2212 k\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 k\u2217),\nwhere\nek\n\u2217\n= K\nr\n\u03a6(r)\n\u03a6(r)\u2212 1\nr \u2212 \u03c8(1) ,\nwhich is to be understood in the limiting sense when r = \u03c8(1), in other words, ek\n\u2217\n=\nK\u03c8(1)\/\u03c8\u2032(1). An optimal stopping time is given by \u03c4\u2217 = inf{t > 0 : Xt < k\u2217}.\nThe McKean stochastic game\nWe return now to the solution of the McKean stochastic game and present our main results\nin terms of scale functions.\nTheorem 2 Consider the McKean stochastic game under the assumption (4).\n(i) If \u03b4 \u2265 U(logK), then a stochastic saddle point is given by \u03c4\u2217 in Theorem 1 and \u03c3\u2217 =\u221e,\nin which case V = U.\n(ii) If \u03b4 < U(logK), a stochastic saddle point is given by the pair\n\u03c4\u2217 = inf{t > 0 : Xt < x\u2217} and \u03c3\u2217 = inf{t > 0 : Xt \u2208 [logK, y\u2217]},\nwhere x\u2217 uniquely solves\nZ(r)(logK \u2212 x)\u2212 Z(r\u2212\u03c8(1))1 (logK \u2212 x) =\n\u03b4\nK\n, (13)\nx\u2217 > k\u2217 (the optimal level of the corresponding McKean optimal stopping problem in\nTheorem 1) and y\u2217 \u2208 [logK, z\u2217], where z\u2217 is the unique solution to\nZ(r)(z \u2212 logK)\u2212 r\n\u03a6(r)\nW (r)(z \u2212 logK) = \u03b4\nK\n. (14)\nThe next theorem gives partial information on the value of y\u2217. Unfortunately, we are unable\nto give a complete characterisation of y\u2217.\nTheorem 3 Suppose in Theorem 2 that \u03b4 < U(logK). If X has no Gaussian component,\nthen y\u2217 > logK and necessarily \u03a0(\u2212\u221e, logK \u2212 y\u2217) > 0.\nThe question whether y\u2217 = logK is more difficult to answer when the Gaussian component of\nX is strictly positive and we refer to Section 8 for a discussion on this case.\nFor practical purposes, one would also like to be able to characterise y\u2217 as the unique solution\nto some functional equation. Recall that the value function V is said to have smooth pasting\nat a boundary point of the stopping region whenever it is differentiable there. Similarly,\ncontinuous pasting at a boundary point of the stopping region is said to occur whenever there\nis continuity there. Experience in the theory of optimal stopping shows that the position of an\noptimal threshold often follows as a consequence of a continuous or smooth pasting condition.\nSee for example Boyarchenko and Levendorskii (2002) Chan (2004), Peskir and Shiryaev (2000,\n2002), Gapeev (2002), Kyprianou (2005) and Surya (2007). In this case, despite the fact that\nwe are able to make decisive statements about pasting of the value function onto the upper\nand lower gain functions (see Theorem 4 below), the desired characterisation of y\u2217 has not\nbeen achieved (note however the discussion following Theorem 4).\nOur last main result gives information concerning the analytical shape of the value function\nV . In particular we address the issue of smooth and continuous pasting at x\u2217 and y\u2217. Define\nthe function j : R\u2192 R by\nj(x) = KZ(r)(x\u2212 x\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 x\u2217) + \u03b1e\u03a6(r)(logK\u2212x\n\u2217)W (r)(x\u2212 logK), (15)\nwhere\n\u03b1 = ex\n\u2217 r \u2212 \u03c8(1)\n\u03a6(r)\u2212 1 \u2212\nrK\n\u03a6(r)\n, (16)\nwhich is to be understood in the limiting sense, i.e. \u03b1 = ex\n\u2217\n\u03c8\u2032(1)\u2212K\u03c8(1) when r = \u03c8(1).\n6 2 Solutions to the McKean stochastic game.\nTheorem 4 For the McKean stochastic game under the assumption (4), when \u03b4 < U(logK),\nV is continuous everywhere. In particular\nV (x) = KZ(r)(x\u2212 x\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 x\u2217) (17)\nfor x \u2208 (\u2212\u221e, logK] and V (x) = \u03b4 for x \u2208 [logK, y\u2217]. Further, if y\u2217 = logK, then for any\nx \u2208 R\nV (x) = j(x).\nMoreover\n(i) If X has unbounded variation, then there is smooth pasting at x\u2217. Further, there is\nsmooth pasting at y\u2217 if and only if y\u2217 > logK.\n(ii) If X has bounded variation, then there is no smooth pasting at x\u2217 and no smooth pasting\nat y\u2217.\nNote that it is in fact possible to show that V is everywhere differentiable except possibly at\nx\u2217, y\u2217 and logK. This is clear from the expression for V (x) on x \u2208 (\u2212\u221e, y\u2217). However, when\ny\u2217 > logK, for the region x \u2208 (y\u2217,\u221e) things are less clear without an expression for V . None\nthe less, it is possible with the help of potential densities, which themselves can be written\nin terms of the scale functions, to write down a formula for V on the aforementioned region.\nThis formula is rather convoluted involving several terms and simply for the sake of brevity we\nrefrain from including it here. It may be possible to use this formula and the pasting conditions\nto find y\u2217, though it seems difficult to show that a solution to the resulting functional equation\nis unique.\nThere are a number of remarks which are worth making about the above three theorems.\nTheorem 2 (i) follows as a consequence of the same reasoning that one sees for the case that X\nis a linear Brownian motion in Kyprianou (2004). That is to say, when \u03b4 \u2265 U(logK) it follows\nthat U(x) \u2264 (K \u2212 ex)+ + \u03b4 showing that the inf-player would not be behaving optimally by\nstopping in a finite time. The proof of this fact is virtually identical to the proof given in\nKyprianou (2004) with the help of the Verification Lemma given in the next section and so we\nleave this part of the proof of Theorem 2 (i) as an exercise.\nWe shall henceforth assume that U(logK) > \u03b4.\nFor the McKean stochastic game when X is a linear Brownian motion and r = \u03c8(1) > 0 it was\nshown in Kyprianou (2004) that, with the above assumption on \u03b4, is small enough, a saddle\npoint is given by\n\u03c4\u2217 = inf{t > 0 : Xt < x\u2217} and \u03c3\u2217 = inf{t > 0 : Xt = logK},\nfor the sup-player and inf-player respectively, where x\u2217 is some value strictly less than logK.\nAlso it was shown there that the solution is convex and that there is smooth pasting at x\u2217. For\nspectrally negative Le\u00b4vy processes in general, Theorems 2-4 show that considerably different\nbehaviour occurs.\nFirstly, as was already found in numerous papers concerning optimal stopping problems driven\nby spectrally one sided Le\u00b4vy processes (cf. Alili and Kyprianou (2005), Chan (2004) and Avram\net al. (2004)), smooth pasting breaks down when the Le\u00b4vy process is of bounded variation.\nThe McKean stochastic game\nSecondly and more interestingly, the different form of the stopping region for the inf-player\ncan be understood intuitively by the following reasoning. In the linear Brownian motion case\nthere is no possibility for the process started at x > logK to enter (\u2212\u221e, logK] without hitting\n{logK}. The positive discount rate r and the constant pay-off on [logK,\u221e) imply that in this\ncase it does not make sense for the inf-player to stop anywhere on (logK,\u221e). However, when\nX has negative jumps there is a positive probability to jump below points. When X starts\nat a value which is slightly greater than logK, there is the danger (for the inf-player) that X\njumps to a large negative value, which could in principle lead to a relatively large pay-off to\nthe sup-player. The trade-off between this fact and the positive discount rate r when there\nis no Gaussian component results in the interval hitting strategy for the inf-player indicated\nby Theorem 3. Note also in that case that the fact that \u03a0(\u2212\u221e, logK \u2212 y\u2217) > 0 implies that\nwhen X0 > y\u2217 the Le\u00b4vy process may still jump over the stopping interval of the inf-player\nand possibly stop the game (either immediately or with further movement of X) by entering\n(\u2212\u221e, x\u2217). This is also a new feature of the optimal strategies compared to the linear Brownian\nmotion case as in the latter context, when X0 > y\u2217, the sup-player will never exercise before\nthe inf-player.\nThe paper continues with the following structure. In the next section we present a set of\nsufficient conditions to check for a solution to the McKean stochastic game. Following that,\nin Sections 4 and 5 we present a description of the candidate solution in the regions x \u2264 logK\nand x > logK. To some extent, the solution may be de-coupled into these two regions thanks\nto the spectral negativity of the underlying process. In Section 6 we show that the previously\ndescribed candidate solution fulfils the sufficient conditions outlined in Section 3 thus proving\nTheorem 2. Finally in Sections 7 and 9 we give the proofs of Theorems 3 and 4 respectively.\n3 Verification technique.\nTo keep calculations brief and to avoid repetition of ideas, it is worth stating up front the\nfundamental technique which leads to establishing the existence and hence characterisation of\na solution. This comes in the form of the following verification Lemma.\nLemma 5 (Verification Lemma) Consider the stochastic game (3) with r > 0. Suppose\nthat \u03c4\u2217 and \u03c3\u2217 are both in T0,\u221e and let\nV \u2217(x) = Ex[e\u2212r\u03c4\n\u2217\n(K \u2212 eX\u03c4\u2217 )+1{\u03c4\u2217\u2264\u03c3\u2217} + e\u2212r\u03c3\n\u2217\n((K \u2212 eX\u03c3\u2217 )+ + \u03b4))1{\u03c3\u2217<\u03c4\u2217}].\nThen the triple (V \u2217, \u03c4\u2217, \u03c3\u2217) is a solution to (3) if\n(i) V \u2217(x) \u2265 (K \u2212 ex)+,\n(ii) V \u2217(x) \u2264 (K \u2212 ex)+ + \u03b4\n(iii) V \u2217(X\u03c4\u2217) = (K \u2212 eX\u03c4\u2217 )+ almost surely on {\u03c4\u2217 <\u221e},\n(iv) V \u2217(X\u03c3\u2217) = (K \u2212 eX\u03c3\u2217 )+ + \u03b4 almost surely on {\u03c3\u2217 <\u221e},\n(v) the process {e\u2212r(t\u2227\u03c4\u2217)V \u2217(Xt\u2227\u03c4\u2217) : t \u2265 0} is a right continuous submartingale and\n(vi) the process {e\u2212r(t\u2227\u03c3\u2217)V \u2217(Xt\u2227\u03c3\u2217) : t \u2265 0} is a right continuous supermartingale.\n8 4 Candidature on x \u2264 log K.\nProof. For convenience, write G(x) = (K \u2212 ex)+, H(x) = (K \u2212 ex)+ + \u03b4 and\n\u0398r\u03c4,\u03c3 = e\n\u2212r\u03c4G(X\u03c4 )1{\u03c4\u2264\u03c3} + e\u2212r\u03c3H(X\u03c3)1{\u03c3<\u03c4}.\nNote that the assumption r > 0 implies that \u0398r\u221e,\u221e = 0. From the supermartingale property\n(vi), Doob\u2019s Optional Stopping Theorem, (iv) and (i) we know that for any \u03c4 \u2208 T0,\u221e and\nt \u2265 0,\nV \u2217(x) \u2265 Ex[e\u2212r(t\u2227\u03c4\u2227\u03c3\u2217)V \u2217(Xt\u2227\u03c4\u2227\u03c3\u2217)]\n\u2265 Ex[e\u2212r(t\u2227\u03c4)G(Xt\u2227\u03c4 )1{\u03c3\u2217\u2265t\u2227\u03c4} + e\u2212r\u03c3\n\u2217\nH(X\u03c3\u2217)1{\u03c3\u2217<t\u2227\u03c4}].\nIt follows from Fatou\u2019s Lemma by taking t \u2191 \u221e that\nV \u2217(x) \u2265 Ex[\u0398r\u03c4,\u03c3\u2217 ].\nNow using (v), Doob\u2019s Optimal Stopping Theorem, (iii) and (ii), we have for any \u03c3 \u2208 T0,\u221e\nand t \u2265 0 ,\nV \u2217(x) \u2264 Ex[e\u2212r\u03c4\u2217G(X\u03c4\u2217)1{\u03c4\u2217\u2264t\u2227\u03c3} + e\u2212r(t\u2227\u03c3)H(Xt\u2227\u03c3)1{\u03c4\u2217>t\u2227\u03c3}].\nTaking limits as t \u2191 \u221e and applying the Dominated Convergence Theorem, taking note of the\nnon-negativity of G, we have\nV \u2217(x) \u2264 Ex[\u0398r\u03c4\u2217,\u03c3] (18)\nand hence (\u03c4\u2217, \u03c3\u2217) is a saddle point to (3).\n4 Candidature on x \u2264 log K.\nHere we describe analytically a proposed solution when X0 \u2208 (\u2212\u221e, logK].\nLemma 6 For x \u2208 (\u2212\u221e, logK] define\nw(x) = KZ(r)(x\u2212 x\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 x\u2217), (19)\nwhere x\u2217 > k\u2217 uniquely solves (13). Then w has the following properties on (\u2212\u221e, logK],\n(i) w(x) = Ex[e\u2212r\u03c4\n+\nlogK \u03b41{\u03c4+logK<\u03c4\u2212x\u2217} + e\n\u2212r\u03c4\u2212\nx\u2217 (K \u2212 eX\u03c4\u2212x\u2217 )1{\u03c4\u2212\nx\u2217<\u03c4\n+\nlogK}],\n(ii) w(x) \u2265 (K \u2212 ex)+,\n(iii) w(x) \u2264 (K \u2212 ex)+ + \u03b4,\n(iv) the right derivative at x\u2217 is computed as follows\nw\u2032(x\u2217+) =\n{ \u2212ex\u2217 if X has unbounded variation,\n\u2212ex\u2217 + (Kr \u2212 (r \u2212 \u03c8(1))ex\u2217)\/d if X has bounded variation,\nwhere in the latter case d is the drift term,\n(v) w is decreasing,\n(vi) w(X\u03c4+logK ) = \u03b4 on {\u03c4\n+\nlogK <\u221e, X0 \u2264 logK},\nThe McKean stochastic game\n(vii) w(X\u03c4\u2212\nx\u2217\n) = (K \u2212 eX\u03c4\u2212x\u2217 ) on {\u03c4\u2212x\u2217 <\u221e},\n(viii) {e\u2212r(t\u2227\u03c4\u2212x\u2217\u2227\u03c4+logK)w(Xt\u2227\u03c4\u2212\nx\u2217\u2227\u03c4+logK ) : t \u2265 0} is a Px-martingale for x \u2264 logK and\n(ix) {e\u2212r(t\u2227\u03c4\u2212x\u2217\u2227\u03c4+logK)w(Xt\u2227\u03c4+logK ) : t \u2265 0} is a Px-supermartingale for x \u2264 logK.\nProof. First note that the left hand side of (13) is equal to\nh(x) :=\n\u222b logK\u2212x\n0\n(\u03c8(1)e\u2212y \u2212 r(e\u2212y \u2212 1))W (r)(y)dy\nwhich is a decreasing continuous function in x. Further, h(logK) = 0 and so we need to show\nthat h(\u2212\u221e) > \u03b4\/K in order to deduce that x\u2217 is uniquely defined. From Theorem 1 we have\nthat U(logK) = Kh(k\u2217) where k\u2217 < logK is defined in Theorem 1. Hence by monotonicity\nand the assumption on the size of \u03b4, h(\u2212\u221e) \u2265 h(k\u2217) = U(logK)\/K > \u03b4\/K. It also follows\nimmediately from this observation that x\u2217 > k\u2217.\nNext, denote by w(x) the right hand side of (19). The remainder of the proof consists of\nverifying that w fulfils conditions (i) to (ix) of Lemma 6 for x \u2208 (\u2212\u221e, logK]. We label the\nproof in parts accordingly.\n(i) Using (6) and (7) and the exponential change of measure (10), we find that for x \u2264 logK\nEx[e\u2212r\u03c4\n+\nlogK \u03b41{\u03c4+logK<\u03c4\u2212x\u2217} + e\n\u2212r\u03c4\u2212\nx\u2217 (K \u2212 eX\u03c4\u2212x\u2217 )1{\u03c4\u2212\nx\u2217<\u03c4\n+\nlogK}]\n= \u03b4\nW (r)(x\u2212 x\u2217)\nW (r)(logK \u2212 x\u2217) +K\n(\nZ(r)(x\u2212 x\u2217)\u2212 W\n(r)(x\u2212 x\u2217)Z(r)(logK \u2212 x\u2217)\nW (r)(logK \u2212 x\u2217)\n)\n\u2212exE1x[e\u2212(r\u2212\u03c8(1))\u03c4\n\u2212\nx\u22171{\u03c4\u2212\nx\u2217<\u03c4logK,y\u2217}]\n= \u03b4\nW (r)(x\u2212 x\u2217)\nW (r)(logK \u2212 x\u2217) +K\n(\nZ(r)(x\u2212 x\u2217)\u2212 W\n(r)(x\u2212 x\u2217)Z(r)(logK \u2212 x\u2217)\nW (r)(logK \u2212 x\u2217)\n)\n\u2212ex\n(\nZ\n(r\u2212\u03c8(1))\n1 (x\u2212 x\u2217)\u2212\nW\n(r\u2212\u03c8(1))\n1 (x\u2212 x\u2217)Z(r\u2212\u03c8(1))1 (logK \u2212 x\u2217)\nW\n(r\u2212\u03c8(1))\n1 (logK \u2212 x\u2217)\n)\n=\nW (r)(x\u2212 x\u2217)\nW (r)(logK \u2212 x\u2217)\n(\n\u03b4 \u2212KZ(r)(logK \u2212 x\u2217) +KZ(r\u2212\u03c8(1))1 (logK \u2212 x\u2217)\n)\n+KZ(r)(x\u2212 x\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 x\u2217)\n= w(x),\nwhere the last equality follows from the definition of x\u2217 in (13).\n(ii) By definition\nw(x) = K \u2212 ex +\n\u222b x\u2212x\u2217\n0\nr(K \u2212 ex\u2212y)W (r)(y) + \u03c8(1)ex\u2212yW (r)(y)dy.\nFor any x \u2264 logK, the integrand on the right hand side above is positive and hence w(x) \u2265\nK \u2212 ex for x \u2264 logK.\n10 4 Candidature on x \u2264 log K.\n(iii) We also see that\nw(x)\u2212 (K \u2212 ex) =\n\u222b x\u2212x\u2217\n0\n(rK + ex\u2212y(\u03c8(1)\u2212 r))W (r)(y)dy\n=\n\u222b x\nx\u2217\n(r(K \u2212 ez) + \u03c8(1)ez)W (r)(x\u2212 z)dz\nis increasing in x on [x\u2217, logK], which implies that for any x \u2264 logK\nw(x) \u2264 K \u2212 ex +\n\u222b logK\u2212x\u2217\n0\nKrW (r)(y)\u2212 cKW (r\u2212\u03c8(1))1 (y)dy = K \u2212 ex + \u03b4,\nwhere c = r \u2212 \u03c8(1) \u2265 0.\n(iv) The derivative of w at x \u2208 (\u2212\u221e, logK]\\{x\u2217} is given by\nw\u2032(x) = \u2212ex +KrW (r)(x\u2212 x\u2217)\u2212 cex\u2217W (r)(x\u2212 x\u2217)\u2212 cex\n\u222b x\u2212x\u2217\n0\ne\u2212yW (r)(y)dy.\nTaking limits as x \u2193 x\u2217 gives the stated result. In taking the latter limit, one needs to take\naccount of the fact for all q \u2265 0, W (q)(0) = 0 if X has unbounded variation and otherwise it\nis equal to 1\/d where d is the underlying drift.\n(v) Taking the expression for the value function, U , of the McKean optimal stopping problem\n(5) recall that x\u2217 > k\u2217 where k\u2217 is optimal level for (5). It is also known that U is convex and\ndecreasing in x. Hence for any x > k\u2217\nU \u2032(x) = KrW (r)(x\u2212 k\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 k\u2217)\u2212 cexW (r\u2212\u03c8(1))1 (x\u2212 k\u2217) < 0.\nSince we have that x\u2217 > k\u2217 we deduce that for x > x\u2217\nw\u2032(x) = KrW (r)(x\u2212 x\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 x\u2217)\u2212 cexW (r\u2212\u03c8(1))1 (x\u2212 x\u2217)\n< KrW (r)(x\u2212 x\u2217)\u2212 ex+k\u2217\u2212x\u2217Z(r\u2212\u03c8(1))1 (x\u2212 x\u2217)\u2212 cex+k\n\u2217\u2212x\u2217W (r\u2212\u03c8(1))1 (x\u2212 x\u2217)\n= U \u2032(x+ k\u2217 \u2212 x\u2217) < 0.\n(vi) and (vii). These two conditions follow by inspection using (13) in the case of (vi) and the\nfact that Z(q)(x) = 1 for all x \u2264 0 in the case of (vii).\n(viii) From (i), (vi) and (vii) we deduce from the strong Markov property that for X0 = x \u2264\nlogK we have that\nEx[e\u2212r\u03c4\n+\nlogK \u03b41{\u03c4+logK<\u03c4\u2212x\u2217} + e\n\u2212r\u03c4\u2212\nx\u2217 (K \u2212 eX\u03c4\u2212x\u2217 )1{\u03c4\u2212\nx\u2217<\u03c4\n+\nlogK}|Ft\u2227\u03c4\u2212x\u2217\u2227\u03c4+logK ]\n= e\u2212r(t\u2227\u03c4\n\u2212\nx\u2217\u2227\u03c4+logK)w(Xt\u2227\u03c4\u2212\nx\u2217\u2227\u03c4+logK )\nand now by the tower property of conditional expectation we observe the required martingale\nproperty.\n(ix). Noting that w is a C2(x\u2217, logK) function, a standard computation involving Ito\u02c6\u2019s formula\nshows that (\u0393 \u2212 r)w = 0 on (x\u2217, logK) thanks to the just established martingale property.\nFor x < x\u2217 we have that\n(\u0393\u2212 r)w(x) = (\u0393\u2212 r)(K \u2212 ex) = (\u2212r \u2212 \u03c8(1))ex < 0,\nThe McKean stochastic game\nwhere \u0393 is the infinitesimal generator of X. Despite the conclusion of part (iv) for the case\nof bounded variation, the function w is smooth enough to allow one to use the change of\nvariable formula in the case of bounded variation, and the classical Ito\u02c6\u2019s formula in the case\nof unbounded variation (cf. Kyprianou and Surya (2006) and Protter (2004)) to show that,\nin light of the above inequality, {e\u2212r(t\u2227\u03c4+logK)w(Xt\u2227\u03c4+logK ) : t \u2265 0} is a Px-supermartingale for\nx \u2264 logK.\n5 Candidature on x >log K.\nIn this section we give an analytical and probabilistic description of a proposed solution when\nX0 > logK.\nLemma 7 Define the function v : R\u2192 [0,K] by\nv(x) = inf\n\u03c3\u2208T0,\u221e\nEx[e\u2212r(\u03c3\u2227\u03c4\n\u2212\nlogK)w\u03b4(X\u03c4\u2212logK\u2227\u03c3)],\nwhere w\u03b4(x) = w(x) given in (19) for x \u2264 logK and w\u03b4(x) = \u03b4 for x > logK. Then v has\nthe following properties,\n(i) v(x) = w(x) for x < logK,\n(ii) v(x) \u2265 (K \u2212 ex)+ for x \u2208 R,\n(iii) v(x) \u2264 (K \u2212 ex)+ + \u03b4 for x \u2208 R,\n(iv) v(x) is non-increasing,\n(v) there exists a y\u2217 \u2265 logK such that\nv(x) = Ex[e\u2212r\u03c4\n\u2212\ny\u2217w\u03b4(X\u03c4\u2212\ny\u2217\n)],\n(vi) if y\u2217 = logK then necessarily X has a Gaussian component and for x \u2208 R\nv(x) = j(x) (20)\nwhere the function j was defined in (15).\n(vii) y\u2217 \u2264 z\u2217, where z\u2217 was defined as the unique solution of (14),\n(viii) v(X\u03c4\u2212\nx\u2217\n) = (K \u2212 eX\u03c4\u2212x\u2217 ) on {\u03c4\u2212x\u2217 = \u03c4\u2212y\u2217 <\u221e, X0 \u2264 logK},\n(ix) v(X\u03c4\u2212\ny\u2217\n) = \u03b4 on {\u03c4[logK,y\u2217] = \u03c4\u2212y\u2217 <\u221e} where\n\u03c4[logK,y\u2217] = inf{t > 0 : Xt \u2208 [logK, y\u2217]},\n(x) {e\u2212r(t\u2227\u03c4\u2212y\u2217 )v(Xt\u2227\u03c4\u2212\ny\u2217\n) : t \u2265 0} is a Px-martingale for x > logK,\n(xi) {e\u2212r(t\u2227\u03c4\u2212logK)v(Xt\u2227\u03c4\u2212logK ) : t \u2265 0} is a Px-submartingale for x > logK.\n12 5 Candidature on x >log K.\nProof.\n(i) Note that when x < logK we have Px(\u03c4\u2212logK = 0) = 1 so that v(x) = w(x).\n(ii) and (iii) These are trivial to verify in light of (i).\n(iv) Denote X\u2217t = Xt\u2227\u03c4\u2212logK for all t \u2265 0. Since w\u03b4 is a continous function and since X\n\u2217 is quasi-\nleft continuous we can deduce that v is upper semicontinuous. Furthermore, w\u03b4 is bounded and\ncontinuous, so we can apply a variant1 of Corollary 2.9 on p46 of Peskir and Shiryaev (2006),\nsee Theorem 3 on p127 of Shiryaev (1977), to conclude that there exists an optimal stopping\ntime, say, \u03c3\u2217, which without loss of generality we assume to be not greater than \u03c4\u2212logK . By\nconsidering the stopping time \u03c3 = \u221e we see by its definition that v(x) < KEx[e\u2212r\u03c4\n\u2212\nlogK ] and\nhence limx\u2191\u221e v(x) = 0. From the latter we deduce that the set defined by\nC := {x > logK : v(x) < \u03b4}\nis non-empty. The upper semicontinuity of v implies that this set is open. Corollary 2.9 of\nPeskir and Shiryaev (2006) also implies that it is optimal to take \u03c3\u2217 as the time of first entry\ninto the set R\\C.\nIn what follows, if \u03b6 is a stopping time for X we shall write \u03b6(x) to show the dependence of the\nstopping time on the value of X0 = x. For x > y > logK we have that \u03c4\u2212logK(x) \u2265 \u03c4\u2212logK(y)\nand thus, also appealing to the definition of v as an infimum,\nv(x)\u2212 v(y) \u2264 E\n[\ne\u2212r(\u03c4\n\u2212\nlogK(x)\u2227\u03c3\u2217(y))w\u03b4(X\u03c4\u2212logK(x)\u2227\u03c3\u2217(y) + x)\n\u2212e\u2212r(\u03c4\u2212logK(y)\u2227\u03c3\u2217(y))w\u03b4(X\u03c4\u2212logK(y)\u2227\u03c3\u2217(y) + y)\n]\n\u2264 E\n[\ne\u2212r(\u03c4\n\u2212\nlogK(y)\u2227\u03c3\u2217(y)(w\u03b4(X\u03c3\u2217(y) + x)\u2212 w\u03b4(X\u03c3\u2217(y) + y))\n]\n(21)\n\u2264 0,\nwhere in the second inequality we have used that \u03c3\u2217(y) \u2264 \u03c4\u2212logK(y) \u2264 \u03c4\u2212logK(x) and from\nLemma 6 (v), w\u03b4 is a decreasing function.\n(v) The fact that v is non-increasing and that C, defined above, is open implies that there\nexists a y\u2217 \u2265 logK such that C = (y\u2217,\u221e). In that case \u03c3\u2217 = \u03c4\u2212y\u2217 .\n(vi) By the dynamic programming principle, taking into account the fact that w\u03b4 = w for\nx \u2264 logK, it follows that\nv(x) = Ex[e\u2212r\u03c4\n\u2212\nx\u2217 (K \u2212 eX\u03c4\u2212x\u2217 )1{\u03c4\u2212\nx\u2217<TK} + e\n\u2212rTK \u03b41{TK<\u03c4\u2212x\u2217}].\nIt is shown in the Appendix that the right hand side above is equal to the right hand side of\n(20).\nNow assume thatX has no Gaussian component and suppose for contradiction that y\u2217 = logK.\nIf X has bounded variation with drift d, it is known that W (r)(0) = 1\/d and hence this would\nentail that\nv(logK+) = KZ(r)(logK \u2212 x\u2217)\u2212KZ(r\u2212\u03c8(1))1 (logK \u2212 x\u2217) + e\u03a6(r)(logK\u2212x\n\u2217)\u03b1\nd\n= \u03b4 + e\u03a6(r)(logK\u2212x\n\u2217)\u03b1\nd\n> \u03b4\n1See also their remarks at the end of Section 1.1.1 on p2, Section 2.1.1 on p27 and 2.2.2 on p35.\nThe McKean stochastic game\nwhere \u03b1 was given in (16). Note that we have used the fact that since k\u2217 < x\u2217 < logK where\nk\u2217 is the optimal crossing boundary in the McKean optimal stopping problem (cf. Theorem 1),\nwe have that \u03b1 > 0. Taking account of part (iii) of this Lemma we thus have a contradiction.\nWhen X has unbounded variation with no Gaussian component, we deduce from (9) that\nv\u2032(logK+) =\u221e, which again leads to a violation of the upper bound in (iii).\n(vii) First we need to prove that z\u2217 in (14) is well-defined and that y\u2217 \u2264 z\u2217. Denote by k(z)\nthe left hand side of (14). We start by showing that k(logK+) > \u03b4\/K. As we have remarked\nin the proof of (iv)\nv(z) < KEz[e\u2212r\u03c4\n\u2212\nlogK ] = Kk(z),\nwhere the equality follows from (8). We use (vi) to show that v(logK+) = \u03b4. When X has no\nGaussian component this follows from the fact that y\u2217 > logK and when X has a Gaussian\ncomponent this follows from continuity of the function j. It thus holds that k(logK+) > \u03b4\/K.\nNote that k is a continuous function on (logK,\u221e) From (8) it follows that k decreases on\n(logK,\u221e) and that limz\u2192\u221e k(z) = 0. Hence there exists a unique z\u2217 \u2208 (logK,\u221e) such that\nk(z\u2217) = \u03b4\/K. Now for z > z\u2217\nv(z) < Kk(z) < Kk(z\u2217) = \u03b4,\nwhich implies y\u2217 \u2264 z\u2217.\n(viii) and (ix) These are trivial statements.\n(x) and (xi) These are standard results from the theory of optimal stopping. See for example\nTheorem 2.2 on p29 of Peskir and Shiryaev (2006).\n6 Existence of a solution: proof of Theorem 2.\nRecall from earlier remarks that the first part of the theorem can be proved in the same way as\nwas dealt with for the case of Brownian motion in Kyprianou (2004). We therefore concentrate\non the second part of the theorem.\nWe piece together the conclusions of Lemmas 6 and 7 in order to check the conditions of the\nVerification Lemma.\nIn particular we consider the candidate triple (V \u2217, \u03c4\u2217, \u03c3\u2217) which is generated by the choices\n\u03c4\u2217 = inf{t > 0 : Xt < x\u2217} and \u03c3\u2217 = inf{t > 0 : Xt \u2208 [logK, y\u2217]} where the constants x\u2217 and\ny\u2217 are given in Lemmas 6 and 7 respectively. Note also, thanks to the fact that X is spectrally\nnegative, we have that\nV \u2217(x) = v(x)\nfor x \u2208 R.\nNote now that conditions (i) \u2013 (iv) of Lemma 5 are automatically satisfied and it remains to\nestablish the supermartingale and submartingale conditions in (v) and (vi). For the former we\nnote that if the initial value x \u2208 [x\u2217, logK) then spectral negativity and Lemma 6 (ix) gives\nthe required supermartinagle property. If on the other hand x > y\u2217 then since, by Lemma 7\n(ix), e\u2212rtv(Xt) is a martingale up to the stopping time \u03c4\u2212y\u2217 and since, by Lemma 6 (ix), given\nF\u03c4\u2212y\u2217 \u2229 {X\u03c4\u2212y\u2217 < logK} the process {e\n\u2212r(t+\u03c4\u2212\ny\u2217 )v(Xt+\u03c4\u2212\ny\u2217\n)} is a supermartingale, the required\nsupermartingale property follows. For the submartingale property, it is more convenient to\nbreak the proof into the cases that y\u2217 = logK and y\u2217 > logK.\n14 7 y\u2217 > log K when X has no Gaussian component: proof of Theorem 3.\nFor the case that y\u2217 > logK pick two arbitrary points logK < a < b < y\u2217. Now note\nfrom the proof of Lemma 6 (ix) that (\u0393 \u2212 r)v(x) = 0 on x \u2208 (x\u2217, logK). Further, it is\neasy to verify that, thanks to the fact that {e\u2212rtv(Xt) : t \u2264 \u03c4+a \u2227 \u03c4\u2212logK} is a submartingale,\n(\u0393 \u2212 r)v(x) > 0 for x \u2208 (logK, a). The submartingale property follows by piece-wise consid-\neration of the path of X and the following two facts. Firstly, thanks to the above remarks\non the value of (\u0393\u2212 r)v(x) and an application of the Ito\u02c6\u2013Meyer\u2013Tanaka formula (cf. Protter\n(2004), {e\u2212rtv(Xt) : t \u2265 0} is a submartingale when X0 \u2264 a and t < \u03c3+b \u2227 \u03c4\u2212x\u2217 . Secondly, from\nLemma 7 (xi) {e\u2212rtv(Xt) : t \u2265 0} is a submartingale when X0 \u2265 b and t < \u03c3\u2212a \u2227 \u03c4\u2212x\u2217 .\nTo deal with the case that y\u2217 = logK recall from Lemma 7 (vi) that necessarily X has a\nGaussian component. As mentioned in Section 2, this is a sufficient condition to guarantee\nthat both scale functions are twice continuously differentiable on (0,\u221e). An application of\nIto\u02c6\u2019s formula together with the martingale properties mentioned in Lemmas 6 (viii) and 7 (ix)\nshow that (\u0393\u2212r)v = 0 on (x\u2217, logK)\u222a(logK,\u221e). Using this fact together with the Ito\u02c6\u2013Meyer\u2013\nTanaka formula (cf. Protter (2004)) the submartingale property of {e\u2212r(t\u2227\u03c4\u2212x\u2217 )v(Xt\u2227\u03c4\u2212\nx\u2217\n) : t \u2265\n0} follows thanks to its semi-martingale decomposition which now takes the form\ne\u2212rtv(Xt) = v(X0) +Mt +\n\u222b t\n0\ne\u2212rs (v\u2032(logK+)\u2212 v\u2032(logK\u2212)) dLlogKs\non {t < \u03c4\u2212x\u2217} where LlogK is semi-martingale local time of X at logK and M is a martingale.\nSpecifically, the integral is non-negative as one may check from (9) the expression given for v\nin Lemma 7 (vi) that\nv\u2032(logK+)\u2212 v\u2032(logK\u2212) = 2\n\u03c32\n\u03b1e\u03a6(r)(logK\u2212x\n\u2217) > 0. (22)\nNote that we have used the fact that \u03b1, defined in (16), is strictly positive. The latter fact\nwas established in the proof of Lemma 7 (vi).\nRemark 8 It is clear from the above proof that we have made heavy use of the fact that X\nhas jumps only in one direction. In particular, this has enabled us to split the problem into\ntwo auxiliary problems and we have solved the problem independently on (\u2212\u221e, logK] and\nthen use this solution to construct the solution on (logK,\u221e). In the case that X has jumps\nin both directions, the analysis breaks down at a number of points. Fundamentally however,\nsince X may pass a fixed level from below by jumping over it, one is no longer able to solve the\nstochastic game on (\u2212\u221e, logK] without knowing the solution on (logK,\u221e). None the less,\nEkstro\u00a8m and Peskir (2006) still provide us with the existence of a stochastic saddle point.\n7 y\u2217 > log K when X has no Gaussian component: proof\nof Theorem 3.\n(i) It follows immediately from Lemma 7 that when y\u2217 = logK we necessarily have that X\nhas a Gaussian component.\nNext we show that \u03a0(\u2212\u221e, logK \u2212 y\u2217) > 0. Suppose that X0 \u2208 (logK, y\u2217), then we know\nthat {e\u2212rtV (Xt) : t \u2264 \u03c4\u2212logK} is a submartingale and that V (x) = \u03b4 on [logK, y\u2217]. We deduce\nfrom Ito\u02c6\u2019s formula (see for example Theorem 36 of Protter (2004)) that in the semi-martingale\nThe McKean stochastic game\ndecomposition of the aforementioned submartingale, the drift term must be non-negative and\nhence for any x \u2208 (logK, y\u2217)\n0 \u2264 (L \u2212 r)V (x)\n= \u2212r\u03b4 +\n\u222b 0\n\u2212\u221e\n(V (x+ y)\u2212 \u03b4)\u03a0(dy)\n= \u2212r\u03b4 +\n\u222b logK\u2212x\n\u2212\u221e\n(V (x+ y)\u2212 \u03b4)\u03a0(dy).\nTherefore, since V is decreasing on (\u2212\u221e, logK), we find that \u03a0(\u2212\u221e, logK \u2212 y\u2217) > 0 as\nrequired.\n8 Remarks on y\u2217 for the case that X has no Gaussian\ncomponent.\nIn the previous section we showed that y\u2217 > logK whenever X has no Gaussian component.\nIn this section we show that when X has a Gaussian component the distinction between\ny\u2217 = logK and y\u2217 > logK is a more subtle issue. This distinction is important, since in\nthe next section we will show that when X is of unbounded variation, the value function is\ndifferentiable at y\u2217 if and only if y\u2217 > logK. Lemma 7 (vi) implies that y\u2217 = logK exactly\nwhen the value function is equal to j(x). Reviewing the calculations in the previous sections\none sees that it is the upper bound condition (ii) of Lemma 5 which may not hold for j and\notherwise all other conditions are verifiable in the same way as before. A sufficient condition\nthat Lemma 5 (ii) holds is that j is a decreasing function in which case of course y\u2217 = logK.\nWhenever X has no Gaussian component, the function j violates this upper bound condition,\nas was shown in the proof of Lemma 7 (vi). This is caused by the behaviour of the scale\nfunction W at zero: when the Gaussian component of X is zero, either W is discontinuous\nor it has infinite right derivative at zero. Assume now that X has a Gaussian component.\nThen the behaviour of the scale function at zero implies that j(logK+) = \u03b4 and that j\nhas finite derivative on (logK,\u221e). From these properties alone we are not able to deduce\nanything about the value of y\u2217. In fact, as we will show next, whether the upper bound\ncondition is satisfied by j depends on the sign of j\u2032(logK+). Whenever j\u2032(logK+) > 0, it\nmust hold that y\u2217 > logK, since otherwise Lemma 7 (iii) and (vi) lead to a contradiction.\nWe show that a sufficient condition for j to be decreasing, and hence for y\u2217 to be equal to\nlogK, is given by j\u2032(logK+) < 0. Recall that j(x) = w(x) on (\u2212\u221e, logK]. From Lemma\n19 (v) and j\u2032(logK+) < 0 we deduce the existence some \u03b3 > 0 such that j is decreasing on\n(\u2212\u221e, logK + \u03b3]. Next let logK + \u03b3 \u2264 x < y \u2264 x+ \u03b3. By the strong Markov property\nj(y)\u2212 j(x) = E[e\u2212r\u03c4\u2212logK\u2212x(j(X\u03c4\u2212logK\u2212x + y)\u2212 j(X\u03c4\u2212logK\u2212x + x))].\nFrom\nX\u03c4\u2212logK\u2212x\n+ x < X\u03c4\u2212logK\u2212x + y \u2264 logK \u2212 x+ y \u2264 logK + \u03b3\nwe deduce that j(y)\u2212 j(x) < 0, which implies that j is a decreasing function on R.\nRemark 9 Note that when X is a Brownian motion and r = \u03c8(1) = \u03c32\/2 then the discussion\nabove agrees with Theorem 2 in Kyprianou (2004). Indeed, in this case the scale functions are\n16 9 Pasting properties at y\u2217: proof of Theorem 4.\ngiven by\nW (\u03c8(1))(x) =\n2\n\u03c32\nsinh(x) and Z(\u03c8(1))(x) = cosh(x)\nfor x \u2265 0. It follows that\nj\u2032(logK+) = \u03c8(1)KW (\u03c8(1))(logK \u2212 x\u2217)\u2212K + 2\u03b1K\n\u03c32\ne\u2212x\n\u2217\n= K sinh(logK \u2212 x\u2217)\u2212K + 2K \u2212K2e\u2212x\u2217\n= \u2212K\n2\n2\ne\u2212x\n\u2217 \u2212 1\n2\nex\n\u2217\n+K.\nSince x\u2217 solves KZ(\u03c8(1))(logK \u2212 x)\u2212K = \u03b4 we deduce that\nKe\u2212x\n\u2217\n+\n1\nK\nex\n\u2217\n= 2(\u03b4 +K)\nand thus\nj\u2032(logK+) = \u2212\u03b4 < 0.\nWe conclude that a stochastic saddle point is indeed given by\n\u03c4\u2217 = \u03c4\u2212x\u2217 and \u03c3\n\u2217 = TK .\nAlso, for the other cases r 6= \u03c32\/2, similar calculations lead to the results found in Kyprianou\n(2004).\nUnfortunately, there are rather few spectrally negative Le\u00b4vy processes for which the scale\nfunction are known in terms of elementary or special functions. Hence, in general, numerical\nanalysis is needed to check whether the condition j\u2032(logK) < 0 holds.\n9 Pasting properties at y\u2217: proof of Theorem 4.\nUsing notation as in the proof of Lemmas 5 and 7, it follows from monotonicity of V and the\ndefinition of (\u03c4\u2217, \u03c3\u2217) as a saddle point that for \u2212\u221e < x \u2264 y <\u221e\n0 \u2264 V (x)\u2212 V (y) \u2264 E[e\u2212r\u03c4\u2217(x)(G(X\u03c4\u2217(x) + x)\u2212G(X\u03c4\u2217(x) + y))1{\u03c4\u2217(x)\u2264\u03c3\u2217(y)}]\n+E[e\u2212r\u03c3\n\u2217(y)(G(X\u03c3\u2217(y) + x)\u2212G(X\u03c3\u2217(y) + y))1{\u03c3\u2217(y)<\u03c4\u2217(x)}]\nand continuity of V follows from continuity of G and dominated convergence.\nIt has already been shown in Section 4 whilst proving Theorem 2 that there is smooth pasting\nat x\u2217 if and only if X has unbounded variation. It remains then to establish the smoothness\nof V at y\u2217.\n(i) Suppose first that X is of unbounded variation. When X has a Gaussian component, recall\nfrom (22) that\nV \u2032(logK+)\u2212 V \u2032(logK\u2212) = 2\n\u03c32\n\u03b1e\u03a6(r)(logK\u2212x\n\u2217) > 0\nshowing that there can be no smooth fit at y\u2217 when y\u2217 = logK.\nNext suppose that y\u2217 > logK. Our aim is to show that V \u2032(y\u2217+) = 0. In order to do this we\nshall need two auxiliary results.\nThe McKean stochastic game\nLemma 10 Suppose X is of unbounded variation and let c < 0. Then\nlim\n\u03b5\u21930\nP(\u03c4\u2212c = \u03c4\n\u2212\n\u2212\u03b5, \u03c4\n\u2212\nc < \u03c4\n+\n\u03b5 )\n\u03b5\n= 0. (23)\nProof. Let c < 0. Define for \u03b5 > 0\nA\u03b5 := {\u03c4\u2212c = \u03c4\u2212\u2212\u03b5, \u03c4\u2212c < \u03c4+\u03b5 } = {X\u03c4\u2212\u2212\u03b5 < c, \u03c4\n\u2212\nc < \u03c4\n+\n\u03b5 }.\nand let Xt = sups\u2264tXs. Let L = {Lt : t \u2265 0} be the local time at zero of {Xt \u2212Xt : t \u2265 0}.\nDenote by {(t, \u000ft) : t \u2265 0} the process of excursions from zero of {Xt\u2212Xt : t \u2265 0} on the local\ntime scale. Note that excursions are of the form \u000ft = {\u000ft(s) : s \u2264 \u03b6t}, where \u03b6t is the duration\nof excursion \u000ft. For the generic excursion \u000f let\n\u03c1x := inf{s > 0 : \u000f(s) > x}.\nNote that A\u03b5 happens if and only if there exists a left endpoint g of an excursion such that\n(i) Lg < \u03b5 (at time g the process must not have exceeded \u03b5),\n(ii) \u000fLh < Xh+ \u03b5 \u2200h < g in the support of dL (during excursions before time g the process\nmust stay above \u2212\u03b5),\n(iii) \u000fLg (\u03c1Xg+\u03b5) > Xg \u2212 c (the first exit time below \u2212\u03b5 must be the first exit time below c).\nHence we can use the compensation formula (with g and h denoting left end points of excursion\nintervals) to deduce that\nP(A\u03b5) = E\n\uf8ee\uf8f0 \u2211\ng<L\u22121\u03b5\n1{\u000fLh<Xh+\u03b5 \u2200h<g}1{\u000fLg (\u03c1Xg+\u03b5)>Xg\u2212c}\n\uf8f9\uf8fb\n= E\n[\u222b L\u22121\u03b5 \u2212\n0\ndLs \u00b7 1{\u000fLu<Xu+\u03b5 \u2200u<s}\u03d5(Xs)\n]\n,\nwhere \u03d5(x) = n(\u000f(\u03c1x+\u03b5) > x\u2212 c).\nUsing the fact that XL\u22121t = t we find for \u03b5 small enough\n0 \u2264 1\n\u03b5\nP(A\u03b5)\n=\n1\n\u03b5\nE\n[\u222b \u03b5\u2227L\u221e\n0\ndt \u00b7 1{\u000f\u03b8<\u03b8+\u03b5 \u2200\u03b8<t}\u03d5(t)\n]\n(24)\n\u2264 1\n\u03b5\n\u222b \u03b5\n0\ndt \u00b7 n(\u000f(\u03c1t+\u03b5) > \u2212c)\n\u2264 1\n\u03b5\n\u222b 2\u03b5\n0\ndt \u00b7 n(\u000f(\u03c1t) > \u2212c).\nIt is known however (cf. Millar (1977)) that since X has unbounded variation limt\u21930 \u000f(\u03c1t) = 0\nwhich in turn implies that\nlim\n\u03b5\u21930\nP(A\u03b5)\n\u03b5\n= 0\nas required.\n18 9 Pasting properties at y\u2217: proof of Theorem 4.\nLemma 11 For any spectrally negative Le\u00b4vy process\nlim sup\n\u03b5\u21930\nW (2\u03b5)\nW (\u03b5)\n\u2264 2.\nProof. First suppose that X does not drift to \u2212\u221e, i.e. \u03a6(0) = 0. In that case, it is known\nthat W is proportional to the renewal function of the descending ladder height process. The\nresult is then immediate from the known sub-additivity of renewal functions (cf. Chapter\nIII of Bertoin (1996)). In the case that \u03a6(0) > 0 (i.e. X drifts to \u2212\u221e), it is known that\nW (x) = e\u03a6(0)xW \u2217(x) where W \u2217 plays the role of the scale function for X conditioned to drift\nto +\u221e (which is again a spectrally negative Le\u00b4vy process) and the result follows.\nWe are now ready to conclude the proof of part (i) of Theorem 4. To this end suppose y > logK\nand X is of unbounded variation. Since V = \u03b4 on [logK, y\u2217] it suffices to show that the right\nderivative of V exists at y\u2217 and that V \u2032(y\u2217+) = 0. Since V (y\u2217) = \u03b4 and since V (x) \u2264 \u03b4 for\nany x > logK we have for any x > y\u2217\nV (x)\u2212 V (y\u2217)\nx\u2212 y\u2217 \u2264 0,\nwhich implies that\nlim sup\nx\u2193y\u2217\nV (x)\u2212 V (y\u2217)\nx\u2212 y\u2217 \u2264 0.\nTo show that V \u2032(y\u2217) = 0 we must thus show that\nlim inf\nx\u2193y\u2217\nV (x)\u2212 V (y\u2217)\nx\u2212 y\u2217 \u2265 0.\nIn order to achieve this define for \u03b5 < logK \u2212 y\u2217\n\u03c4\u2217\u03b5 = inf{t \u2265 0 : Xt \/\u2208 [y\u2217 \u2212 \u03b5, y\u2217 + \u03b5]}\nFurthermore\n\u03c4+ := inf{t \u2265 0 : Xt > y\u2217 + \u03b5}\nand\n\u03c4\u2212 := inf{t \u2265 0 : Xt < y\u2217 \u2212 \u03b5}.\nWe have that for small enough \u03b5, {e\u2212r(t\u2227\u03c4\u03b5)V (Xt\u2227\u03c4\u03b5)}t\u22650 is a Py\u2217 -submartingale, hence by the\noptional sampling theorem\nE\u2217y[e\u2212r\u03c4\u03b5V (X\u03c4\u03b5)]\n\u2265 V (y\u2217)\n= V (y\u2217)E\u2217y[e\u2212r\u03c4\n+\n1{\u03c4+<\u03c4\u2212}] + \u03b4(1\u2212 E\u2217y[e\u2212r\u03c4\n+\n1{\u03c4+<\u03c4\u2212}]). (25)\nThe McKean stochastic game\nFurthermore we use Lemma 10 and the fact that V is bounded by K to deduce\nE\u2217y[e\u2212r\u03c4\u03b5V (X\u03c4\u03b5)]\n= V (y\u2217 + \u03b5)E\u2217y[e\u2212r\u03c4\n+\n1{\u03c4+<\u03c4\u2212}] + E\u2217y[e\u2212r\u03c4\n\u2212\nV (X\u03c4\u2212)1{\u03c4\u2212<\u03c4+}]\n= V (y\u2217 + \u03b5)E\u2217y[e\u2212r\u03c4\n+\n1{\u03c4+<\u03c4\u2212}] + \u03b4E\u2217y[e\u2212r\u03c4\n\u2212\n1{\u03c4\u2212logK<\u03c4\u2212<\u03c4+}]\n+E\u2217y[e\u2212r\u03c4\n\u2212\nV (X\u03c4\u2212)1{\u03c4\u2212logK=\u03c4\u2212<\u03c4+}]\n\u2264 V (y\u2217 + \u03b5)E\u2217y[e\u2212r\u03c4\n+\n1{\u03c4+<\u03c4\u2212}] + \u03b4E\u2217y[e\u2212r\u03c4\n\u2212\n1{\u03c4logK\u2212<\u03c4\u2212<\u03c4+}]\n+KP(\u03c4\u2212logK = \u03c4\n\u2212 < \u03c4+)\n\u2264 V (y\u2217 + \u03b5)E\u2217y[e\u2212r\u03c4\n+\n1{\u03c4+<\u03c4\u2212}] + \u03b4E\u2217y[e\u2212r\u03c4\n\u2212\n1{\u03c4\u2212<\u03c4+}] + o(\u03b5) as \u03b5 \u2193 0. (26)\nThe two expectations on the right hand side of (26) can be evaluated in terms of scale functions\nwith the help of (6) and (7). Also, because X is of unbounded variation, it is known that\nW (q)(0) = 0. Combining these facts, (25), (26) and using Lemma 11 we find\nlim inf\n\u03b5\u21930\nV (y\u2217 + \u03b5)\u2212 V (y\u2217)\n\u03b5\n\u2265 \u03b4 lim inf\n\u03b5\u21930\n1\u2212 E\u2217y[e\u2212r\u03c4\u03b5 ]\n\u03b5E\u2217y[e\u2212r\u03c4\n+1{\u03c4+<\u03c4\u2212}]\n= r\u03b4 lim inf\n\u03b5\u21930\n1\n\u03b5\n(\u222b 2\u03b5\n0\nW (r)(y)dy \u2212 W\n(r)(2\u03b5)\nW (r)(\u03b5)\n\u222b \u03b5\n0\nW (r)(y)dy\n)\n= 0.\nThis concludes the proof of part (i) of Theorem 4.\n(ii) Suppose now that X has bounded variation. We know that necessarily X has no Gaussian\ncomponent and hence by Theorem 3 that y\u2217 > logK. We see from (21) and continuity of V\nthat for \u03b5 > 0\nV (y\u2217 + \u03b5)\u2212 \u03b4\n\u03b5\n\u2264 E\n[\ne\u2212r\u03c4\n\u2212\ny\u2217 (y\n\u2217)\nw\u03b4(X\u03c4\u2212\ny\u2217 (y\n\u2217) + y\n\u2217 + \u03b5)\u2212 w\u03b4(X\u03c4\u2212\ny\u2217 (y\n\u2217) + y\n\u2217)\n\u03b5\n]\nwhere as before we are working under the measure P and indicated the dependency of stopping\ntimes on an initial position of X. Now recalling that w\u03b4 is a non-increasing function and is\nequal to V on (\u2212\u221e, logK), we have further with the help of Theorem 3, dominated convergence\nand the fact that V is decreasing on (\u2212\u221e, logK) that\nlim sup\n\u03b5\u21930\nV (y\u2217 + \u03b5)\u2212 \u03b4\n\u03b5\n\u2264 E[e\u2212r\u03c4\u2212y\u2217 (y\u2217)V \u2032(X\u03c4\u2212\ny\u2217 (y\n\u2217) + y\n\u2217)1{X\n\u03c4\n\u2212\ny\u2217 (y\n\u2217)+y\n\u2217<logK}] < 0.\nHence there is continuous fit but no smooth fit at y\u2217 in this case.\n10 Remarks on the case r = 0 and \u03c8(1) > 0.\nDealing with the case that r = 0 and \u03c8(1) > 0 first requires the problem to be formulated in\na slightly different way as a careful inspection of the proof of the Verification Lemma reveals\n20 10 Remarks on the case r = 0 and \u03c8(1) > 0.\nthat there is a problem with the inequality in (18) on account of the value of the gain on the\nevent that {\u03c4 = \u03c3 =\u221e}. The way round this is to reformulate the problem by defining\n\u03980\u03c4,\u03c3 = G(X\u03c4 )1{\u03c4\u2264\u03c3,\u03c4<\u221e} +H(X\u03c3)1{\u03c3<\u03c4,\u03c3<\u221e} + L(lim sup\nt\u2191\u221e\nXt, lim inf\nt\u2191\u221e\nXt)1{\u03c4=\u03c3=\u221e}\nwhere L(\u221e,\u221e) = \u03b4 and L(\u2212\u221e,\u2212\u221e) = K and L(\u221e,\u2212\u221e) = K.\nSuppose again that U(x) is the solution to (5) but now under the regime r = 0 and \u03c8(1) > 0.\nIt is not difficult to see that U(x) = K when X does not drift to \u221e and otherwise is given\nby the expression in Theorem 1 with r = 0. When \u03b4 is smaller than U(logK), we claim the\nsaddle point is given by\n\u03c4\u2217 = \u03c4\u2212x\u2217 and \u03c3\n\u2217 = inf{t : Xt \u2265 logK},\nwhere x\u2217 is the unique solution to\nK\u03c8(1)\n\u222b logK\u2212x\n0\ne\u2212yW (y)dy = \u03b4.\n(Note that here we use the assumption \u03c8(1) > 0). For x \u2264 logK the value function is given\nby\nV (x) = K \u2212 ex + \u03c8(1)ex\n\u222b x\u2212x\u2217\n0\ne\u2212yW (y)dy.\nIndeed it is possible to mildly adapt the statement and proof of the Verification Lemma to\nshow that these choices of \u03c4\u2217 and \u03c3\u2217 constitute a saddle point. The reader is referred to\nSection 10 of Chapter 5 of Baurdoux (2007) for a more detailed study of the r = 0 case.\nAppendix.\nOur objective here is to show that\nEx[e\u2212r\u03c4\n\u2212\nx\u2217 (K \u2212 eX\u03c4\u2212x\u2217 )1{\u03c4\u2212\nx\u2217<TK} + e\n\u2212rTK \u03b41{TK<\u03c4\u2212x\u2217}]\n= KZ(r)(x\u2212 x\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 x\u2217)\n+\u03b1e\u03a6(r)(logK\u2212x\n\u2217)W (r)(x\u2212 logK). (27)\nWe need first a preliminary Lemma. Recall that TK = inf{t > 0 : Xt = logK}.\nLemma 12 For all x \u2208 R the following two identities hold\nEx[e\u2212rTK1{TK<\u03c4\u2212x\u2217}] =\nW (r)(x\u2212 x\u2217)\nW (r)(logK \u2212 x\u2217) \u2212 e\n\u03a6(r)(logK\u2212x\u2217) W\n(r)(x\u2212 logK)\nW (r)(logK \u2212 x\u2217) .\nand\nEx[e\u2212r\u03c4\n\u2212\nx\u22171{\u03c4\u2212\nx\u2217<TK}] =\n(\nZ(r)(logK \u2212 x\u2217)\nW (r)(logK \u2212 x\u2217) \u2212\nr\n\u03a6(r)\n)\ne\u2212\u03a6(r)(logK\u2212x\n\u2217)W (r)(x\u2212 logK)\n+Z(r)(x\u2212 x\u2217)\u2212 Z\n(r)(logK \u2212 x\u2217)\nW (r)(logK \u2212 x\u2217)W\n(r)(x\u2212 x\u2217).\nThe McKean stochastic game\nProof. Denote by u+q the q-potential density of the process killed at exiting the positive\nhalfline. We know that for x, a \u2265 0\nu+q (x, a) = e\n\u2212\u03a6(q)aW (q)(x)\u2212W (q)(x\u2212 a).\nProposition 1 in Pistorius (2005) allows us to deduce with some algebra that\nEx[e\u2212rTK1{TK<\u03c4\u2212x\u2217}] =\nu+r (x\u2212 x\u2217, logK \u2212 x\u2217)\nu+r ((logK \u2212 x\u2217)\u2212, logK \u2212 x\u2217)\n=\nW (r)(x\u2212 x\u2217)\nW (r)(logK \u2212 x\u2217) \u2212 e\n\u03a6(r)(logK\u2212x\u2217) W\n(r)(x\u2212 logK)\nW (r)(logK \u2212 x\u2217) .\nFrom the Markov property it follows that Ex[e\u2212r\u03c4x\u22171{\u03c4\u2212\nx\u2217<TK}] is equal to\nEx[e\u2212r\u03c4\n\u2212\nx\u2217 ]\u2212 Ex[e\u2212r\u03c4\n\u2212\nx\u22171{TK<\u03c4\u2212x\u2217}]\n= Z(r)(x\u2212 x\u2217)\u2212 r\n\u03a6(r)\nW (r)(x\u2212 x\u2217)\u2212 ElogK [e\u2212r\u03c4\n\u2212\nx\u2217 ]Ex[e\u2212rTK1{TK<\u03c4\u2212x\u2217}]\n=\n(\nZ(r)(logK \u2212 x\u2217)\nW (r)(logK \u2212 x\u2217) \u2212\nr\n\u03a6(r)\n)\ne\u03a6(r)(logK\u2212x\n\u2217)W (r)(x\u2212 logK)\n+Z(r)(x\u2212 x\u2217)\u2212 Z\n(r)(logK \u2212 x\u2217)\nW (r)(logK \u2212 x\u2217)W\n(r)(x\u2212 x\u2217)\nthus concluding the proof.\nProof of (27). From Lemma 12\nEx[e\u2212r\u03c4\n\u2212\nx\u2217 (K \u2212 eX\u03c4\u2212x\u2217 )1{\u03c4\u2212\nx\u2217<TK} + e\n\u2212rTK \u03b41{TK<\u03c4\u2212x\u2217}]\n= KEx[e\u2212r\u03c4\n\u2212\nx\u22171{\u03c4\u2212\nx\u2217<TK}]\u2212 e\nxE1x[e\u2212c\u03c4x\n\u2217\u2212\n1{\u03c4\u2212\nx\u2217<TK}]\n+\u03b4\nW (r)(x\u2212 x\u2217)\nW (r)(logK \u2212 x\u2217) \u2212 \u03b4e\n\u03a6(r)(logK\u2212x\u2217) W\n(r)(x\u2212 logK)\nW (r)(logK \u2212 x\u2217)\n= K\n(\nZ(r)(logK \u2212 x\u2217)\nW (r)(logK \u2212 x\u2217) \u2212\nr\n\u03a6(r)\n)\ne\u03a6(r)(logK\u2212x\n\u2217)W (r)(x\u2212 logK)\n+KZ(r)(x\u2212 x\u2217)\u2212K Z\n(r)(logK \u2212 x\u2217)\nW (r)(logK \u2212 x\u2217)W\n(r)(x\u2212 x\u2217)\n\u2212ex\n(\nZ\n(r\u2212\u03c8(1))\n1 (logK \u2212 x\u2217)\nW\n(r\u2212\u03c8(1))\n1 (logK \u2212 x\u2217)\n\u2212 r \u2212 \u03c8(1)\n\u03a61(r \u2212 \u03c8(1))\n)\n\u00d7e\u03a61(r\u2212\u03c8(1))(logK\u2212x\u2217)W (r\u2212\u03c8(1))1 (x\u2212 logK)\n\u2212exZ(r\u2212\u03c8(1))1 (x\u2212 x\u2217) + ex\nZ\n(r\u2212\u03c8(1))\n1 (logK \u2212 x\u2217)\nW\n(r\u2212\u03c8(1))\n1 (logK \u2212 x\u2217)\nW\n(r\u2212\u03c8(1))\n1 (x\u2212 x\u2217)\n+\u03b4\nW (r)(x\u2212 x\u2217)\nW (r)(logK \u2212 x\u2217) \u2212 \u03b4e\n\u03a6(r)(logK\u2212x\u2217) W\n(r)(x\u2212 logK)\nW (r)(logK \u2212 x\u2217) ,\nwhere \u03a61 plays the role of \u03a6 under P1. Using (11) we have \u03c81(\u03a6(r)\u2212 1) = \u03c8(\u03a6(r))\u2212 \u03c8(1) =\nr \u2212 \u03c8(1) and thus \u03a61(r \u2212 \u03c8(1)) = \u03a6(r) \u2212 1. By definition of x\u2217 we have Z(r)(logK \u2212 x\u2217) \u2212\n22 REFERENCES\nZ\n(r\u2212\u03c8(1))\n1 (logK \u2212 x\u2217) = \u03b4\/K and we use (12) to conclude\nEx[e\u2212r\u03c4\n\u2212\nx\u2217 (K \u2212 eX\u03c4\u2212x\u2217 )1{\u03c4\u2212\nx\u2217<TK} + e\n\u2212rTK \u03b41{TK<\u03c4\u2212x\u2217}]\n= KZ(r)(x\u2212 x\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 x\u2217)\n+e\u03a6(r)(logK\u2212x\n\u2217) W\n(r)(x\u2212 logK)\nW (r)(logK \u2212 x\u2217)\n\u00d7\n(\nKZ(r)(logK \u2212 x\u2217)\u2212 \u03b4 \u2212KZ(r\u2212\u03c8(1))1 (logK \u2212 x\u2217)\n)\n+\nW (r)(x\u2212 x\u2217)\nW (r)(logK \u2212 x\u2217)\n(\n\u03b4 \u2212KZ(r)(logK \u2212 x\u2217) +KZ(r\u2212\u03c8(1))1 (logK \u2212 x\u2217)\n)\n+Ke\u03a6(r)(logK\u2212x\n\u2217)W (r)(x\u2212 logK)\n(\n\u2212 r\n\u03a6(r)\n+Kex\n\u2217 r \u2212 \u03c8(1)\n\u03a6(r)\u2212 1\n)\n= KZ(r)(x\u2212 x\u2217)\u2212 exZ(r\u2212\u03c8(1))1 (x\u2212 x\u2217) + \u03b1Ke\u03a6(r)(logK\u2212x\n\u2217)W (r)(x\u2212 logK)\nas required.\nAcknowledgements.\nWe are grateful to Christoph Ku\u00a8hn who suggested looking for an \u2018interval-hitting strategy\u2019 for\nthe inf-player. We are also grateful to Goran Peskir for several illuminating discussions. Part\nof this work was carried out whilst the first author was visiting the Department of Actuarial\nMathematics and Statistics at Heriot-Watt University. He is grateful for their hospitality.\nReferences\n[1] Alili, L. and Kyprianou, A.E. (2005) Some remarks on first passage of Le\u00b4vy processes,\nthe American put and smooth pasting. Ann. Appl. Probab. 15, 2062\u20132080.\n[2] Avram, F., Kyprianou, A.E. and Pistorius, M.R. (2004) Exit problems for spectrally\nnegative Le\u00b4vy processes and applications to (Canadized) Russian options. Ann. Appl.\nProbab. 14, 215\u2013238.\n[3] Baurdoux, E.J. (2007) Fluctuation Theory and Stochastic Games for Spectrally Negative\nLe\u00b4vy Processes. Ph.D. thesis, Utrecht University.\n[4] Baurdoux, E.J. and Kyprianou, A.E. (2008) The Shepp\u2013Shiryaev stochastic game driven\nby a spectrally negative Le\u00b4vy process. To appear in Theory of Probability and its Appli-\ncations.\n[5] Bertoin, J. (1996) Le\u00b4vy Processes. Cambridge University Press.\n[6] Bichteler, K. (2002) Stochastic Integration with Jumps. Cambridge University Press.\n[7] Boyarchenko, S.I. and Levendorskii, S.Z. (2002) Perpetual American options under Le\u00b4vy\nprocesses. SIAM J. Control Optim. 40, 1663\u20131696.\n[8] Chan, T. (2004) Some applications of Le\u00b4vy processes in insurance and finance. Finance.\n25, 71\u201394.\nThe McKean stochastic game REFERENCES\n[9] Chan, T. and Kyprianou, A.E. (2005) Smoothness of scale functions for spectrally negative\nLe\u00b4vy processes. Preprint.\n[10] Cvitanic\u00b4, J. and Karatzas, I. (1996) Backward stochastic differential equations with re-\nflection and Dynkin games. Ann. Probab. 24, no. 4, 2024\u20132056.\n[11] Doney, R.A. (2005) Some excursion calculations for spectrally one-sided Le\u00b4vy processes.\nSe\u00b4minaire de Probabilite\u00b4s, XXXVIII. 5\u201315. Springer.\n[12] Dynkin, E.B. (1969) A game-theoretic version of an optimal stopping problem Soviet\nMath, Dokl. 10, 270\u2013274.\n[13] Ekstro\u00a8m, E. and Peskir G. (2006) Optimal stopping games for Markov processes SIAM\nJ. Control Optim. To appear.\n[14] Gapeev, P.V. (2002) Problems of the sequential discrimination of hypotheses for a com-\npound Poisson process with exponential jumps. (Russian) Uspekhi Mat. Nauk. 57, 171\u2013\n172.\n[15] Kifer, Yu. (2000) Game options. Finance Stoch. 4, 443\u2013463.\n[16] Ku\u00a8hn, C. and Gapeev, P. V. (2005) Perpetual convertible bonds in jump-diffusion models.\nStatist. Decisions. 23, 15\u201331.\n[17] Kyprianou, A.E. (2004) Some calculations for Israeli options. Finance Stoch. 8, 73\u201386.\n[18] Kyprianou, A.E. (2006) Introductory Lectures on Fluctuations of Le\u00b4vy Processes with\nApplications. Springer.\n[19] Kyprianou, A.E. and Surya, B.A. (2005) A note on a change of variable formula with\nlocal time-space for Le\u00b4vy processes of bounded variation Se\u00b4minaire de Probabilite\u00b4s XL.\n97\u2013105.\n[20] Kyprianou, A.E., Rivero, V. and Song, R. (2008) Smoothness and convexity of scale\nfunctions with applications to de Finettis control problem. Preprint.\n[21] McKean, H. (1965) Appendix: A free boundary problem for the heat equation arising\nfrom a problem of mathematical economics. Ind. Manag. Rev. 6, 32\u201339.\n[22] Millar, P.W. (1977) Zero-one laws and the minimum of a Markov process. Trans. Amer.\nMath. Soc. 226, 365\u2013391.\n[23] Mordecki, E. (2002) Optimal stopping and perpetual options for Le\u00b4vy processes. Finance\nStoch. 6, 473\u2013493.\n[24] Peskir, G., Shiryaev, A.N. (2000), Sequential testing problems for Poisson processes. Ann.\nStatist. 28 , 837\u2013859.\n[25] Peskir, G., Shiryaev, A.N. (2002) Solving the Poisson disorder problem. Advances in\nfinance and stochastics, 295\u2013312, Springer, Berlin.\n[26] Peskir, G. and Shiryaev, A.N. (2006) Optimal Stopping and Free Boundary Value Prob-\nlems. Birkha\u00a8user.\n24 REFERENCES\n[27] Pistorius, M.R. (2005) A potential-theoretical review of some exit problems of spectrally\nnegative Le\u00b4vy processes. Se\u00b4minaire de Probabilite\u00b4s XXXVIII, 30\u201341.\n[28] Pistorius, M.R. (2006) An excursion theoretical approach to some boundary crossing prob-\nlems and the Skorokhod embedding for reflected Le\u00b4vy processes. Se\u00b4minaire de Probabilite\u00b4s\nXL, 287\u2013308.\n[29] Protter, P. (2004) Stochastic Integration and Differential Equations. 2nd Edition.\nSpringer.\n[30] Shiryaev, A.N. (1977) Optimal stopping rules. Springer.\n[31] Surya, B.A. (2007) An approach for solving perpetual optimal stopping problems driven\nby Le\u00b4vy processes. Stochastics. 79 337\u2013361.\n"}
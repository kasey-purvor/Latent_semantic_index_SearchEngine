{"doi":"10.1097\/EDE.0b013e3182003276","coreId":"216913","oai":"oai:eprints.lse.ac.uk:31520","identifiers":["oai:eprints.lse.ac.uk:31520","10.1097\/EDE.0b013e3182003276"],"title":"Adjusting for selection effects in epidemiologic studies: why sensitivity analysis is the only \u201csolution\u201d","authors":["Geneletti, Sara","Mason, Alexina","Best, Nicky"],"enrichments":{"references":[{"id":17324923,"title":"A joint modeling of neighborhood effects on participation in the RECORD Cohort Study and neighborhood effects on type 2 diabetes: bias assessment and correction.","authors":[],"date":null,"doi":"10.1097\/ede.0b013e3181fd2961","raw":"Chaix B, Billaudeau N, Thomas F, et al.  A joint modeling of neighborhood effects on participation in the RECORD Cohort Study and neighborhood effects on type 2 diabetes: bias assessment and correction.  Epidemiology.","cites":null},{"id":17324928,"title":"Adjusting for selection bias in retrospective, case\u2013control studies. Biostatistics.","authors":[],"date":"2009","doi":"10.1093\/biostatistics\/kxn010","raw":"Geneletti S, Richardson S, Best N. Adjusting for selection bias in retrospective, case\u2013control studies. Biostatistics. 2009; 10(1): 17-31.","cites":null},{"id":17324929,"title":"Bias modelling in evidence synthesis.","authors":[],"date":"2009","doi":null,"raw":"Turner RM, Spiegelhalter DJ, Smith GCS and Thompson SG.  Bias modelling in evidence synthesis. JRSSA. 2009; 172(1):21-47","cites":null},{"id":17324925,"title":"Causal Diagrams for Epidemiologic Research. Epidemiology.","authors":[],"date":"1999","doi":"10.1097\/00001648-199901000-00008","raw":"Greenland S, Pearl J, Robins JM.  Causal Diagrams for Epidemiologic Research. Epidemiology. 1999; 10(1):37-48.4. Hern\u00e1n MA, Hern\u00e1ndez-D\u00edaz S, Robins JM.  A structural approach to selection bias. Epidemiology. 2004; 15(5):615-25.","cites":null},{"id":17324927,"title":"Correcting for non-compliance and dependent censoring in an AIDS clinical trial with inverse probability of censoring weighted (IPCW) log-rank tests. Biometrics.","authors":[],"date":"2000","doi":"10.1111\/j.0006-341x.2000.00779.x","raw":"Robins JM, Finkelstein D.  Correcting for non-compliance and dependent censoring in an AIDS clinical trial with inverse probability of censoring weighted (IPCW) log-rank tests. Biometrics. 2000; 56(3):779-88.","cites":null},{"id":17324924,"title":"Correcting HIV prevalence estimates for survey non-participation: an application of Heckman-type selection models to the Zambian Demographic and Health Survey.","authors":[],"date":null,"doi":"10.1097\/ede.0b013e3181ffa201","raw":"Barnighausen T, Bor J, Wandira-Kazibwe S, Canning D. Correcting HIV prevalence estimates for survey non-participation: an application of Heckman-type selection models to the Zambian Demographic and Health Survey.  Epidemiology.","cites":null},{"id":17324931,"title":"Exposing our ignorance: the only \u201csolution\u201d to selection bias.","authors":[],"date":"1989","doi":"10.2307\/1164603","raw":"Allen NL and Holland PW. Exposing our ignorance: the only \u201csolution\u201d to selection bias. Journal of Educational Statistics. 1989; 14(2):141-45","cites":null},{"id":17324930,"title":"Missing Data In Longitudinal Studies Strategies for Bayesian Modeling and Sensitivity Analysis.","authors":[],"date":"2008","doi":"10.1201\/9781420011180","raw":"Daniels MJ, Hogan JW. Missing Data In Longitudinal Studies Strategies for Bayesian Modeling and Sensitivity Analysis. Chapman & Hall; 2008: 167-181.","cites":null},{"id":17324926,"title":"Multiple imputation: current perspectives, Statistical Methods in Medical Research.","authors":[],"date":"2007","doi":"10.1177\/0962280206075304","raw":"Kenward MG and Carpenter J, Multiple imputation: current perspectives, Statistical Methods in Medical Research. 2007; 16(3):199-218","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-01","abstract":null,"downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/216913.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/31520\/1\/Adjusting%20for%20selection%20effects%20%28LSERO%29.pdf","pdfHashValue":"0560b3c8702d94ca1989c8bd525a4a4d2b72aae6","publisher":"Lippincott Williams & Wilkins","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:31520<\/identifier><datestamp>\n      2012-04-24T09:55:24Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5354<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/31520\/<\/dc:relation><dc:title>\n        Adjusting for selection effects in epidemiologic studies: why sensitivity analysis is the only \u201csolution\u201d<\/dc:title><dc:creator>\n        Geneletti, Sara<\/dc:creator><dc:creator>\n        Mason, Alexina<\/dc:creator><dc:creator>\n        Best, Nicky<\/dc:creator><dc:subject>\n        HA Statistics<\/dc:subject><dc:publisher>\n        Lippincott Williams & Wilkins<\/dc:publisher><dc:date>\n        2011-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/31520\/1\/Adjusting%20for%20selection%20effects%20%28LSERO%29.pdf<\/dc:identifier><dc:identifier>\n          Geneletti, Sara and Mason, Alexina and Best, Nicky  (2011) Adjusting for selection effects in epidemiologic studies: why sensitivity analysis is the only \u201csolution\u201d.  Epidemiology, 22 (1).  pp. 36-39.  ISSN 1044-3983     <\/dc:identifier><dc:relation>\n        http:\/\/journals.lww.com\/epidem\/pages\/default.aspx<\/dc:relation><dc:relation>\n        10.1097\/EDE.0b013e3182003276<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/31520\/","http:\/\/journals.lww.com\/epidem\/pages\/default.aspx","10.1097\/EDE.0b013e3182003276"],"year":2011,"topics":["HA Statistics"],"subject":["Article","PeerReviewed"],"fullText":"  \nSara Geneletti, Alexina Mason and Nicky Best \nAdjusting for selection effects in \nepidemiologic studies: why sensitivity \nanalysis is the only \u201csolution\u201d \nArticle (Accepted version) \n(Refereed) \n \n \n Original citation: Geneletti, Sara and Mason, Alexina and Best, Nicky (2011) Adjusting for selection effects in \nepidemiologic studies: why sensitivity analysis is the only \u201csolution\u201d. Epidemiology, 22 (1). pp. \n36-39. ISSN 1044-3983  \nDOI: 10.1097\/EDE.0b013e3182003276  \n \n\u00a9 2011 Lippincott Williams & Wilkins  \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/31520\/ \nAvailable in LSE Research Online: April 2012 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final manuscript accepted version of the journal article, \nincorporating any revisions agreed during the peer review process.  Some differences between \nthis version and the published version may remain.  You are advised to consult the publisher\u2019s \nversion if you wish to cite from it. \n \n \nIntroduction\nChaix et al1 and Barnighausen et al2 provide thoughtful case studies in which the implications of \nsurvey non-participation are carefully considered and statistical models chosen to provide \nadjustment for likely bias.  But will papers such as these help to persuade epidemiologists to pay \nmore than lip service to the issues of selection on a routine basis?  The impact of selection bias \nmay often be quite weak and the adjustment methods may be technically difficult. However we \nargue that it is essential for researchers to formally think about the possible sources of bias in the \ndata they plan to analyse and to assess sensitivity of their conclusions to these potential biases.  \nThe two papers illustrate the use of different variants of selection models, which is just one of a \nnumber of approaches open to epidemiologists for adjusting for possible bias.  But, practically \nspeaking, does the adjustment method used matter?  Is some sort of adjustment better than none? \nCertainly, as non-participation increases, so do the risks that an analysis based only on complete \ncases will result in biased inference and invalid conclusions, and so some form of adjustment \nshould be considered.  The choice of adjustment method depends on the assumptions that are \nconsidered plausible regarding the nature of the non-participation and the type of additional \nsources of data that are available.   However, any chosen model will generally be based on \nuntestable assumptions, because by definition we do not observe the characteristics of primary \ninterest of the non-participants. Thus any method that attempts to correct for non-participation \nbias is essentially a sensitivity analysis. It is perfectly possible that a different set of assumptions \nabout the selection process will lead to different adjustments of the parameters of interest, and \nthe implications of this should always be explored and reported.\nIdentifying potential sources of bias resulting from non-participation\nIn both papers1,2 the researchers thought first about the structural assumptions they had to make \nabout the non-participation, and second about what data they could use to inform a participation \nmodel before developing a procedure to adjust for non-participation bias.  The structural \nassumptions refer to the mechanism that introduces bias, i.e. we must seek to answer the \nquestions: Are the participants systematically different from the non-participants on the variables \nof substantive interest?  If so, how does this difference manifest itself?  We have found that \ngraphical models, such as directed acyclic graphs (DAGs), are a useful tool for exploring these \nissues, and indeed Chaix et al use them to identify \"collider bias\". We discuss the use of such \nDAGs later below.\nTypes of additional data\nInformation about non-participation can be thought of as coming in two types which are \nexemplified in the two papers:1,2 internal and external.  Internal information comprises data \nwhich is available on all the individuals who are eligible to participate in a study, regardless of \nwhether they provide any information relating to the substantive question.  Typically this \nsituation occurs when the study is conducted within a cohort (e.g. a nested case-control study) or \na census, or when individuals in previous sweeps of a longitudinal study drop out.  In this case \nwe have some individual-level information about the non-participants which might be relevant to \ntheir non-participation.  In the HIV paper2, additional available data included numbers living in a \nhousehold and interviewer identity, both of which were used to inform the selection model.\nThere are also situations, for example, cross-sectional health surveys, cohort studies or case-\ncontrol studies that are set outside of cohorts, where no individual level information on the non-\nparticipants is available.  Fortunately, due to the large amount of data that are routinely collected \nin public health, it is often possible to find data that covers the same population as that of the \nstudy under investigation. This is external information, which comes from a different data source \nand does not include information on the individuals themselves, but may be of use for modelling \nnon-participation.  In fact it is often worth thinking about this aspect during the study design, and \nto collect information with a particular auxiliary data source in mind, in such a way that linking \nthe study to these data sources is easy in the analysis phase. This set-up is described in the paper \non neighbourhood effects by Chaix et al1 where individuals are recruited without a definite \nsampling frame, and a census provides external information based on neighbourhood of \nresidence of eligible participants. \nGraphical models can help identify mechanisms leading to bias \nDAGs are becoming increasingly popular in the epidemiologic literature.  They are very useful \nfor visualizing complex relationships between variables and for understanding potential sources \nof bias. There now exists a number of papers that can be used as recipes to identify what \nvariables are likely to cause bias in a data-set. 3,4  Recent work by Hernan et al4 describes very \nclearly how to determine whether a study is likely to be suffering from non-participation bias. \nWhen this is the case, the variable that indicates participation is a \"collider\". In both Chaix et al \nand Barnighausen et al, the DAG that describes the relationships between the variables of \ninterest has participation as a collider, indicating that selection bias is a potential problem, as we \nillustrate below.\nFigure 1: DAG representing the situation in Barnighausen et al. X are the observed characteristics of the \nrespondents and U is the unobserved correlation. U can also be viewed as unobserved characteristics. S is the \nselection indicator and Y is the HIV status. Z are the selection variables, interviewer identify or identify of an \ninterviewer of a member of the household.\nFigures 1 and 2 represent the relationships between the variables involved in the problems in the \npapers by Barnighausen et al and Chaix et al respectively. Figures 1a, 1b and 2a, 2b mirror one \nanother and show how participation bias manifests itelf in the same way in both papers.  In \nparticular in both cases, X and U are the observed and unobserved variables respectively, S is the \nselection indicator and Y the outcome of interest (HIV or diabetes status).  In Barnighausen et al, \nunder the Heckman model, U can be understood as the unknown correlation between the \nselection and observed variables, whereas in Chaix et al, U are the unobserved neighbourhood \neffects. \nFigures 1a and 2a show both observed and unobserved variables. Figures 1b and 2b however \nshow only the observed variables and the implied dependence due to not conditioning on \nunobserved variables.  The latter DAGs demonstrate the potential for selection bias, as S is a \ncollider between the outcome Y and the observed covariates X. \nFigures 1c and 2c differ because they represent the two approaches used to tackle participation \nbias. By introducing selection variables Z in Figure 1c such that the Heckman assumption of \nindependence of Z and Y holds, Barnighausen et al are able to identify and estimate the \nunobserved correlation and adjust for selection bias.  Chaix et al choose a different approach to \nadjusting for the bias in Figure 2c by finding a proxy for the unobserved neigbourhood effects in \nthe form of the random effects R.\nFigure 2: DAG representing the situation in Chaix et al. X are the observed neigbourhood effects and U are  the \nunobserved neighbourhood effects. S is the selection indicator and Y is diabetes status. R are the random effects.\nSelection of appropriate modelling method\nOnly when the reasons for, and implications of, the non-participation have been thought through \nthoroughly, is the analyst in a position to select an appropriate modelling method.  The choice \ndepends on whether the resulting missingness can plausibly be assumed to be missing at random, \nMAR5 (i.e. the probability of being missing is not dependent on unobserved data, given the \nobserved data).  For example, in Barnighausen et al, MAR means that the unobserved correlation \nis 0 and U disappears from the DAG in Figure 1a.  In this case there is often no need to model \nthe participation process, and options include multiple imputation6, re-weighting procedures such \nas inverse probability weighting7 or post-stratification8 and bias modelling techniques9.  \nBarnighausen et al considered that the missing HIV data from the non-responders was likely to \nbe missing not at random, MNAR5 (i.e. the probability of being missing is dependent on \nunobserved data, given the observed data), so a method which allowed the joint modelling of the \nparticipation process and the substantive question was required. Chaix et al also favoured this \njoint model approach, as the neighbourhood random effects were thought to influence both their \nstudy participation model and their diabetes model.  As we have discussed, both use a selection \nmodel, but the form differs, illustrating how the modelling choice is problem specific and \ndependent on assumptions made and the type of additional data available.  A third option for \nmodelling MNAR non-response is to explicitly model the link between Y and S in Figures 1b \nand 2b, by including Y as a predictor in the selection equation10.\nSelection models can be implemented within traditional (Barnighausen et al) or Bayesian (Chaix \net al) estimation frameworks. A Bayesian approach provides the option of incorporating \ninformation through expert priors, which can be formed through elicitation or literature search. \nFor instance, in the HIV paper, data from the Malawi study on the probability of refusing an HIV \ntest given HIV status could be incorporated into an informative prior on the covariance matrix of \nthe Heckman model.\nSensitivity analysis\nAs we have stressed, model choice and hence results are dependent on the assumptions made. \nUnfortunately, it is not possible to test whether missing data is MAR or MNAR (despite the \nslightly misleading impression given by the tests carried out by Barnighausen et al, since \nidentification of the correlation between HIV status and participation is completely dependent on \nthe choice of Z variable (exclusion restriction) and the distributional assumptions of the \nsubstantive and selection models). Consequently, it is essential that the robustness of results is \ntested by fitting a range of models which incorporate varying assumptions.  This can be as simple \nas the initial analyses of the HIV data2, where estimates were calculated assuming either that the \nmissing individuals were all HIV positive or all HIV negative, or can be sophisticated and, for \nexample, involve varying the form of the different parts of a joint model.  We have found that a \nBayesian approach is very conducive to these types of complex analysis, as the modular setup \nallows different assumptions about the non-participation model or the analysis model to be \nexplored relatively easily.  Our experience suggests that varying the functional form of either the \nanalysis or participation model can substantially alter results (A Mason, S Richardson, I Plewis \nand N Best, Strategy for modelling non-random missing data mechanisms in observational \nstudies using Bayesian methods, working paper, 2010).  In Barnighausen et al, which uses the \nfrequentist framework, it would be interesting to explore the implications of using different \nexclusion variables.\nConclusions \nWith increasing rates of non-participation in surveys and studies, it becomes more important that \nepidemiologists recognise the inherent uncertainty and potential for bias that accompanies non-\nresponse.  A mindset that bases conclusions on a single \u2018best\u2019 model needs to change to one that \npresents a range of models encompassing different plausible assumptions, or equivalently a \u2018base \nmodel\u2019 accompanied by a series of sensitivity analyses.  It may turn out that all the results are \nrobust to different assumptions, but unfortunately there is no way of knowing this without \ncarrying out the extended analysis.  The challenge for the researcher is to choose the most \nappropriate statistical tool\/approach for their particular problem, given their subject knowledge, \nutilising as much available additional information as possible.  Epidemiologists are more likely \nto go down this route if more practical advice and real examples which show its value are \navailable, and the two papers discussed here will contribute to this process. Equally important is \naccess to, and understanding of, software that allows the plausibility of different assumptions \nabout non-participation to be explored.\nChaix et al and Barnighausen et al each conclude that their method should be routinely used.  We \ncontend that the specific method is not so important, although it should be appropriate, but that \nroutine practice should follow the key principles of thinking about the selection process and \nassessing sensitivity to different assumptions. To quote the advice of Allen and Holland11 given \nto educational researchers over 20 years ago: \u201cYou must be prepared to think as hard about your \nnon-respondents as you do about your substantive research and to incorporate this into a \nsensitivity analysis. Otherwise, you have not handled selection bias but have only ignored it.\u201d\nReferences\n1. Chaix B, Billaudeau N, Thomas F, et al.  A joint modeling of neighborhood effects on \nparticipation in the RECORD Cohort Study and neighborhood effects on type 2 diabetes: \nbias assessment and correction.  Epidemiology.\n2. Barnighausen T, Bor J, Wandira-Kazibwe S, Canning D. Correcting HIV prevalence \nestimates for survey non-participation: an application of Heckman-type selection models to \nthe Zambian Demographic and Health Survey.  Epidemiology.\n3. Greenland S, Pearl J, Robins JM.  Causal Diagrams for Epidemiologic Research. \nEpidemiology. 1999; 10(1):37-48.\n4. Hern\u00e1n MA, Hern\u00e1ndez-D\u00edaz S, Robins JM.  A structural approach to selection bias. \nEpidemiology. 2004; 15(5):615-25.\n5. Rubin DB.  Inference and Missing Data.  Biometrika. 1976; 63(3): 581-92. \n6. Kenward MG and Carpenter J, Multiple imputation: current perspectives, Statistical Methods \nin Medical Research. 2007; 16(3):199-218\n7. Robins JM, Finkelstein D.  Correcting for non-compliance and dependent censoring in an \nAIDS clinical trial with inverse probability of censoring weighted (IPCW) log-rank tests. \nBiometrics. 2000; 56(3):779-88.\n8. Geneletti S, Richardson S, Best N. Adjusting for selection bias in retrospective, case\u2013control \nstudies. Biostatistics. 2009; 10(1): 17-31.\n9. Turner RM, Spiegelhalter DJ, Smith GCS and Thompson SG.  Bias modelling in evidence \nsynthesis. JRSSA. 2009; 172(1):21-47\n10. Daniels MJ, Hogan JW. Missing Data In Longitudinal Studies Strategies for Bayesian \nModeling and Sensitivity Analysis. Chapman & Hall; 2008: 167-181.\n11. Allen NL and Holland PW. Exposing our ignorance: the only \u201csolution\u201d to selection bias. \nJournal of Educational Statistics. 1989; 14(2):141-45\n"}
{"doi":"10.1108\/17410380510594480","coreId":"140225","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/3036","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/3036","10.1108\/17410380510594480"],"title":"Managing through measures: a study of impact on performance","authors":["Bourne, Mike","Kennerley, Mike","Franco-Santos, Monica"],"enrichments":{"references":[{"id":37969580,"title":"A Framework of the Factors Affecting the Evolution of Performance Measurement Systems',","authors":[],"date":"2002","doi":"10.1108\/01443570210450293","raw":"Kennerley, M.P. and Neely, A.D. (2002), 'A Framework of the Factors Affecting the Evolution of Performance Measurement Systems', International Journal of Operations & Production Management, Vol. 22, No. 11, pp. 1222-1245.","cites":null},{"id":37969560,"title":"Accounting, Budgeting and Control-Systems in Their Organisational Context - Theoretical and Empirical-Perspectives',","authors":[],"date":"1983","doi":"10.1016\/0361-3682(83)90023-5","raw":"Flamholtz, E.G. (1983), 'Accounting, Budgeting and Control-Systems in Their Organisational Context - Theoretical and Empirical-Perspectives', Accounting, Organisations and Society, Vol. 8, No. 2-3, pp. 153-169.","cites":null},{"id":37969563,"title":"Aligning Strategic Performance Measures and Results, The Conference Board,","authors":[],"date":"1999","doi":null,"raw":"Gates, S. (1999), Aligning Strategic Performance Measures and Results, The Conference Board, New York, USA.","cites":null},{"id":37969633,"title":"Ambiguity in the Using of Performance Measurement Information in Organizations: the Application of the Theoretical Framework of Measurement Risks in a Finnish Organizational Context\u201d,","authors":[],"date":"2001","doi":null,"raw":"Vakkuri, J. and Meklin, P. (2001), \u201cAmbiguity in the Using of Performance Measurement Information in Organizations: the Application of the Theoretical Framework of Measurement Risks in a Finnish Organizational Context\u201d, in Workshop on Performance Measurement and Management Control, Nice, France.","cites":null},{"id":37969539,"title":"An Empirical Investigation of an Incentive Plan That Includes Nonfinancial Performance Measures',","authors":[],"date":"2000","doi":"10.2308\/accr.2000.75.1.65","raw":"Banker, R.D., Potter, G. & Srinivasan, D., (2000), 'An Empirical Investigation of an Incentive Plan That Includes Nonfinancial Performance Measures', Accounting Review, Vol. 75, No. 1, pp. 65-92.","cites":null},{"id":37969591,"title":"An Empirical Study of Division and Plant Performance Measurement Systems in Selected World-Class Manufacturing Firms - Linkages for Competitive Advantage',","authors":[],"date":"1995","doi":"10.1080\/00207549508930145","raw":"Lockamy, A. and Cox, J.F. (1995), 'An Empirical Study of Division and Plant Performance Measurement Systems in Selected World-Class Manufacturing Firms - Linkages for Competitive Advantage', International Journal of Production Research, Vol. 33, No. 1, Jan, pp. 221-236 Lynch, R. L. & Cross, K. F., (1991), Measure Up - The Essential Guide to Measuring Business Performance, Mandarin, London.","cites":null},{"id":37969558,"title":"An Exploratory Study of Performance Measurement Systems and Relationship With Performance Results',","authors":[],"date":"2001","doi":"10.1016\/j.jom.2004.01.002","raw":"Evans, J.R. (2001), 'An Exploratory Study of Performance Measurement Systems and Relationship With Performance Results', in Presented at the Decisions Science Institute 32nd Annual Conference. Digitizing Decisions & Markets San Francisco, CA, pp. 1-27.","cites":null},{"id":37969551,"title":"An instrument for investigating the match between manufacturing strategy and performance measures, Working Paper,","authors":[],"date":"1991","doi":null,"raw":"Dixon, J. R., Nanni, A. J. & Vollmann, T. E., (1991). An instrument for investigating the match between manufacturing strategy and performance measures, Working Paper, Boston University.","cites":null},{"id":37969579,"title":"Are your performance measures obsolete?&quot;,","authors":[],"date":"1989","doi":null,"raw":"Keegan, D. P., Eiler, R. G. & Jones, C. R., (1989), &quot;Are your performance measures obsolete?&quot;, Management Accounting, June, pp. 45 - 50.","cites":null},{"id":37969562,"title":"Assessing Some Distinctive Dimensions of Performance Feedback Information in High Performing Plants',","authors":[],"date":"2000","doi":"10.1108\/01443570010308112","raw":"Forza, C. and Salvador, F. (2000), 'Assessing Some Distinctive Dimensions of Performance Feedback Information in High Performing Plants', International Journal of Operations & Production Management, Vol. 20, No. 3, pp. 359-385 Franco, M. & Bourne, M. C. S. (2004), \u201cAre strategic performance measurement systems really effective: a closer look at the evidence\u201d, Proceedings of the EurOMA Conference, June, INSEAD, France, Vol. 2, pp. 163 \u2013 174.","cites":null},{"id":37969594,"title":"Balanced Scorecards in Finnish Companies:","authors":[],"date":"2001","doi":"10.1006\/mare.2000.0154","raw":"Malmi, T. (2001), \u201cBalanced Scorecards in Finnish Companies: A Research Note\u201d, Management Accounting Research, Vol. 12, pp. 207-220.","cites":null},{"id":37969565,"title":"Changing Performance Measures at Caterpillar',","authors":[],"date":"1996","doi":null,"raw":"Hendricks, J.A.et al. (1996), 'Changing Performance Measures at Caterpillar', Management Accounting, Dec, pp. 18-24.","cites":null},{"id":37969571,"title":"Coming Up Short on Nonfinancial Performance Measurement',","authors":[],"date":"2003","doi":null,"raw":"Ittner, C.D. and Larcker, D.F. (2003), 'Coming Up Short on Nonfinancial Performance Measurement', Harvard Business Review, Vol. 81, No. 11, pp. 88-+.","cites":null},{"id":37969593,"title":"Communicating and Controlling Strategy: an Empirical Study of the Effectiveness of the Balanced Scorecard\u201d, available at: http:\/\/www.bettermanagement.com\/library\/ Library.aspx?LibraryID=539","authors":[],"date":"2002","doi":"10.2139\/ssrn.278939","raw":"Malina, M.A. & Selto, F.H. (2002), \u201cCommunicating and Controlling Strategy: an Empirical Study of the Effectiveness of the Balanced Scorecard\u201d, available at: http:\/\/www.bettermanagement.com\/library\/ Library.aspx?LibraryID=539 (accessed 2002).","cites":null},{"id":37969627,"title":"Competitiveness and the management of strategic change processes&quot;, in The competitiveness of European Industry: country policies and company","authors":[],"date":"1989","doi":null,"raw":"Pettigrew, A., Whipp, R. and Rosenfield, R., (1989), &quot;Competitiveness and the management of strategic change processes&quot;, in The competitiveness of European Industry: country policies and company strategies, Francis, A., Tharakan, P. K. M. (Eds.)., Routledge.","cites":null},{"id":37969555,"title":"Creating a Comprehensive System to Measure Performance',","authors":[],"date":"1992","doi":null,"raw":"Eccles, R.G. and Pyburn, P.J. (1992), 'Creating a Comprehensive System to Measure Performance', Management Accounting, No. October , pp. 323.","cites":null},{"id":37969626,"title":"Customer-Focused Manufacturing Strategy and the Use of Operations-Based Non-Financial Performance Measures: a Research Note',","authors":[],"date":"1997","doi":"10.1016\/s0361-3682(96)00048-7","raw":"Perera, S., Harrison, G. and Poole, M. (1997), 'Customer-Focused Manufacturing Strategy and the Use of Operations-Based Non-Financial Performance Measures: a Research Note', Accounting Organizations and Society, Vol. 22, No. 6, pp. 557-572.","cites":null},{"id":37969615,"title":"Designing performance measures: a structured approach\u201d,","authors":[],"date":"1997","doi":"10.1108\/01443579710177888","raw":"Neely, A. D., Richards, A. H., Mills, J. F., Platts, K. W. & Bourne, M. C. S., (1997), \u201cDesigning performance measures: a structured approach\u201d, International Journal of Production and Operations Management., Vol. 17, No. 11, pp. 1131 - 1152.","cites":null},{"id":37969548,"title":"Designing, implementing and updating performance measurement systems&quot;,","authors":[],"date":"2000","doi":"10.1108\/01443570010330739","raw":"Bourne, M. C. S., Mills, J. F., Wilcox, M. & Neely, A. D. & Platts, K, W., (2000), &quot;Designing, implementing and updating performance measurement systems&quot;, International Journal of Production and Operations Management, Vol. 20, No. 7, pp. 754-771.","cites":null},{"id":37969587,"title":"Determinants of Judgement Performance in Accounting Settings: Ability, Knowledge, Motivation, and Environment.","authors":[],"date":"1993","doi":"10.1016\/0361-3682(93)90040-d","raw":"Libby, R. & Luft, J. (1993), 'Determinants of Judgement Performance in Accounting Settings: Ability, Knowledge, Motivation, and Environment. ', Accounting Organizations and Society, Vol. 18, No. 5, pp. 425-450.","cites":null},{"id":37969575,"title":"Devising a balanced scorecard matched to business strategy&quot;,","authors":[],"date":"1994","doi":"10.1108\/eb054476","raw":"Kaplan, R. S., (1994), &quot;Devising a balanced scorecard matched to business strategy&quot;, Planning Review, Sept.\/Oct. pp. 15 - 19 & 48.","cites":null},{"id":37969624,"title":"Does the Balanced Scorecard work; an empirical investigation\u201d,","authors":[],"date":"2004","doi":null,"raw":"Neely, A. D., Kennerley, M. J. & Martinez, V., (2004), \u201cDoes the Balanced Scorecard work; an empirical investigation\u201d, Proceedings of the EurOMA conference, July, INSEAD, France Vol. 2, pp. 229 \u2013 238.","cites":null},{"id":37969583,"title":"Ethical Dilemmas in Performance Measurement\u201d,","authors":[],"date":"2003","doi":null,"raw":"Kerssens-Van Drongelen, I.C. & Fisscher, O.A.M. (2003), \u201cEthical Dilemmas in Performance Measurement\u201d, Journal of Business Ethics, Vol. 45, No. 1-2, pp. 51-63.","cites":null},{"id":37969589,"title":"From Balanced Scorecard to Strategy Gauge: Is Measurement Worth It?&quot;, Management Review,","authors":[],"date":"1996","doi":null,"raw":"Lingle, J. H. & Schiemann, W. A., (1996), &quot;From Balanced Scorecard to Strategy Gauge: Is Measurement Worth It?&quot;, Management Review, March , pp. 56 - 62.","cites":null},{"id":37969613,"title":"Getting the measure of your business,","authors":[],"date":"1996","doi":"10.1017\/cbo9780511754685","raw":"Neely, A. D., Mills, J. F., Gregory, M. J., Richards, A. H., Platts, K. W., & Bourne, M.C.S., (1996), Getting the measure of your business, Findlay, London.","cites":null},{"id":37969572,"title":"Good Enough Performance Measurement: a Trade-Off Between Activity and Action\u201d,","authors":[],"date":"2002","doi":"10.1057\/palgrave\/jors\/2601217","raw":"Johnston, R., Brignall, S. and Fitzgerald, L. (2002), ''Good Enough Performance Measurement: a Trade-Off Between Activity and Action\u201d, Journal of the Operational Research Society, Vol. 53, No. 3, Mar, pp. 256-262.","cites":null},{"id":37969550,"title":"Implementing performance measurement systems: a literature review\u201d,","authors":[],"date":"2003","doi":"10.1504\/ijbpm.2003.002097","raw":"Bourne, M. C. S., Neely, A. D., Mills, J. F. & Platts, K. W, (2003), \u201cImplementing performance measurement systems: a literature review\u201d, International Journal of Business Performance Management, Vol. 5, No. 1, pp. 1-24.17 Coates, J., Davis, T., Emmanuel, C., Longden, S.G. & Stacey, R. (1992), 'Multinational Companies Performance Measurement Systems: International Perspectives', Management Accounting Research, Vol. 3, pp. 133-150.","cites":null},{"id":37969567,"title":"Improving Control Through Effective Performance Measurement in SMEs',","authors":[],"date":"2001","doi":"10.1080\/09537280110061557","raw":"Hudson, M., Lean, J. and Smart, P.A. (2001a), 'Improving Control Through Effective Performance Measurement in SMEs', Production Planning and Control, Vol. 12, No. 8, pp. 804-813.","cites":null},{"id":37969628,"title":"Informativeness of Performance Measures in the Presence of Reporting Discretion\u201d,","authors":[],"date":"2004","doi":null,"raw":"Ramachandran, N., (2004), \u201cInformativeness of Performance Measures in the Presence of Reporting Discretion\u201d, Journal of Accounting, Auditing & Finance, Vol. 19 Issue 1, p61, 23p.22 Schneiderman, A., (1999), \u201cWhy balanced scorecards fail\u201d, Journal of Strategic Performance Measurement, Special edition, pp. 6 \u2013 11.","cites":null},{"id":37969543,"title":"Integrated Performance Measurement Systems: a development guide&quot;,","authors":[],"date":"1997","doi":"10.1108\/01443579710167230","raw":"Bititci, U. S., Carrie, A. S. & McDevitt, L, (1997), &quot;Integrated Performance Measurement Systems: a development guide&quot;, International Journal of Operations and Production Management, Vol. 17, No. 5, pp. 522-534.","cites":null},{"id":37969566,"title":"Linking Balanced Scorecard Measures to Size and Market Factors: Impact on Organizational Performance',","authors":[],"date":"2000","doi":"10.2308\/jmar.2000.12.1.1","raw":"Hoque, Z. & James, W. (2000), 'Linking Balanced Scorecard Measures to Size and Market Factors: Impact on Organizational Performance', Journal of Management Accounting Research, Vol. 12, pp. 1-17.","cites":null},{"id":37969629,"title":"Making Management Decisions: the Role of Intuition and Emotion',","authors":[],"date":"1987","doi":"10.5465\/ame.1987.4275905","raw":"Simon, H.A. (1987), 'Making Management Decisions: the Role of Intuition and Emotion', Academy of Management Executive, Feb, pp. 57-64.# Simons, R. (1991), 'Strategic Orientation and Top Management Attention to Control Systems', Strategic Management Journal, Vol. 12, pp. 49-62.","cites":null},{"id":37969574,"title":"Market Competition, Management Accounting Systems and Business Unit Performance ',","authors":[],"date":"1999","doi":"10.1006\/mare.1998.0097","raw":"Lokman, M. and Clarke, B. (1999), 'Market Competition, Management Accounting Systems and Business Unit Performance ', Management Accounting Research, Vol. 10, No. 2, pp. 137-158.","cites":null},{"id":37969542,"title":"Measures that Matter&quot;,","authors":[],"date":"1997","doi":null,"raw":"Bierbusse, P. & Siesfeld, T. (1997) &quot;Measures that Matter&quot;, Journal of Strategic Performance Measurement, Vol. 1, No. 2, pp. 6-11.","cites":null},{"id":37969618,"title":"Measuring Business Performance: Why, What and How,","authors":[],"date":"1998","doi":null,"raw":"Neely, A.D. (1998), Measuring Business Performance: Why, What and How, The Economist and Profile Books Ltd., London, UK.","cites":null},{"id":37969581,"title":"Measuring Performance in a Changing Business Environment',","authors":[],"date":"2003","doi":"10.1108\/13683040310509304","raw":"Kennerley, M. and Neely, A. (2003), 'Measuring Performance in a Changing Business Environment', International Journal of Operations & Production Management, Vol. 23, No. 2, pp. 213-229.","cites":null},{"id":37969556,"title":"Measuring the Payoffs of Corporate Actions: the Use of Financial and Non-Financial Indicators\u201d,","authors":[],"date":"2002","doi":null,"raw":"Epstein, M.J. (2002), \u201cMeasuring the Payoffs of Corporate Actions: the Use of Financial and Non-Financial Indicators\u201d, in Epstein, M.J. and Manzoni, J.F. (Ed.), Performance Measurement and Management Control: A Compendium of Research , Elsevier Science , Kidlington, Oxford, UK, pp. 3-13.","cites":null},{"id":37969546,"title":"M\u00e9thode de conception et d'implantation de syst\u00e8mes de measure de performances pour organisations industrielles&quot;, Th\u00e8se d' automatique, Universit\u00e9 de Bordeaux I,","authors":[],"date":"1990","doi":null,"raw":"Bitton, M., (1990), &quot;M\u00e9thode de conception et d'implantation de syst\u00e8mes de measure de performances pour organisations industrielles&quot;, Th\u00e8se d' automatique, Universit\u00e9 de Bordeaux I, France.","cites":null},{"id":37969582,"title":"On the Folly of Rewarding A, While Hoping for B',","authors":[],"date":"1995","doi":"10.5465\/ame.1995.9503133466","raw":"Kerr, S. (1995), 'On the Folly of Rewarding A, While Hoping for B', The Academy of Management Executive, Vol. 9, No. 1, pp. 7+.","cites":null},{"id":37969596,"title":"Overcoming Obstacles to Developing Effective Performance Measures ',","authors":[],"date":"1999","doi":"10.1108\/00438029910291192","raw":"Manoochehri, G. (1999), 'Overcoming Obstacles to Developing Effective Performance Measures ', Work Study, Vol. 48, No. 6, pp. 223-229.","cites":null},{"id":37969631,"title":"Performance Management and Operational Research: a Marriage Made in Heaven?',","authors":[],"date":"2002","doi":"10.1057\/palgrave\/jors\/2601279","raw":"Smith, P.C. and Goddard, M. (2002), 'Performance Management and Operational Research: a Marriage Made in Heaven?', Journal of the Operational Research Society, Vol. 53, No. 3, pp. 247-255.","cites":null},{"id":37969625,"title":"Performance Management: a Framework for Management Control Systems Research',","authors":[],"date":"1999","doi":"10.1006\/mare.1999.0115","raw":"Otley, D.T. (1999), 'Performance Management: a Framework for Management Control Systems Research', Management Accounting Research, Vol. 10, No. 4, Dec, pp. 363-382.","cites":null},{"id":37969584,"title":"Performance management&quot;, in Global Production Management,","authors":[],"date":"1999","doi":"10.1007\/978-0-387-35569-6_30","raw":"Krause, O. & Mertins, K., (1999), &quot;Performance management&quot;, in Global Production Management, Proceedings of the IFIP WG5.7 international conference on Advances in Production Management Systems, edited by Mertins, K., Krause, O. & Schallock, September.","cites":null},{"id":37969605,"title":"Performance Measurement and Management Control: a Compendium of Research, Elsevier Science Ltd.,","authors":[],"date":"2004","doi":null,"raw":"Performance Measurement and Management Control: a Compendium of Research, Elsevier Science Ltd., Oxford, UK, pp. 131-158 Michele, P., Franco, M., Marr, B. & Bourne, M., (2004), \u201cBusiness performance measurement: an organisational theory perspective\u201d, Performance Measurement and Management; Public & Private, Proceedings of the 4 th International PMA conference, 28 th \u2013 30 th July, Edinburgh, UK.","cites":null},{"id":37969585,"title":"Performance Measurement and Performance Management',","authors":[],"date":"1995","doi":"10.1016\/0925-5273(95)00081-x","raw":"Lebas, M.J. (1995), 'Performance Measurement and Performance Management', International Journal of Production Economics, Vol. 41, No. 1-3, pp. 23-35.","cites":null},{"id":37969559,"title":"Performance Measurement in Service Businesses, The Chartered Institute of Management Accountants,","authors":[],"date":"1991","doi":null,"raw":"Fitzgerald, L., Johnston, R., Brignall T. J. Silvestro, R. & Voss, C., (1991), Performance Measurement in Service Businesses, The Chartered Institute of Management Accountants, London.","cites":null},{"id":37969592,"title":"Performance Measurement Practices Survey Results,","authors":[],"date":"2001","doi":null,"raw":"Maisel, L.S. (2001), Performance Measurement Practices Survey Results, AICPA, US.","cites":null},{"id":37969621,"title":"Performance Measurement System Design: Developing and Testing a Process-Based Approach',","authors":[],"date":"2000","doi":"10.1108\/01443570010343708","raw":"Neely, A.D., Mills, J.F., Platts, K., Richards, H., Gregory M.J., Bourne, M. & Kennerley, M.P. (2000), 'Performance Measurement System Design: Developing and Testing a Process-Based Approach', International Journal of Operations & Production Management, Vol. 20, No. 10, pp. 1119-1145.","cites":null},{"id":37969547,"title":"Performance Measurement System Design: Testing a Process Approach in Manufacturing Companies&quot;,","authors":[],"date":"1999","doi":"10.1504\/ijbpm.1999.004435","raw":"Bourne, M. C. S., Mills, J. F., Bicheno J., Hamblin, D. J., Wilcox M. & Neely A. D. & Platts, K, W., (1999), &quot;Performance Measurement System Design: Testing a Process Approach in Manufacturing Companies&quot;, International Journal of Business Performance Measurement, Vol. 1, No. 2, pp. 154 - 170.","cites":null},{"id":37969552,"title":"Performance Measurement Systems - Models, Characteristics and Measures',","authors":[],"date":"2001","doi":"10.1108\/01443570110358459","raw":"De Toni, A. and Tonchia, S. (2001), 'Performance Measurement Systems - Models, Characteristics and Measures', International Journal of Operations & Production Management, Vol. 21, No. 1-2, pp. 46-70.","cites":null},{"id":37969607,"title":"Qualitative data analysis,","authors":[],"date":"1994","doi":"10.4324\/9780203413081_chapter_5","raw":"Miles. M. B. & Huberman A. M., (1994), Qualitative data analysis, Sage, Thousand Oaks. CA, USA.","cites":null},{"id":37969590,"title":"Quality-Focused Performance Measurement Systems: a Normative Model',","authors":[],"date":"1998","doi":"10.1108\/01443579810217440","raw":"Lockamy, A. (1998), 'Quality-Focused Performance Measurement Systems: a Normative Model', International Journal of Operations & Production Management, Vol. 18, No. 7-8,20 pp. 740-+.","cites":null},{"id":37969541,"title":"Some Evidence on the Use of Performance Management Systems\u201d,","authors":[],"date":"2001","doi":null,"raw":"Barsky, N. and Marchant, G. (2001), \u201cSome Evidence on the Use of Performance Management Systems\u201d, in Workshop on Performance Measurement and Management Control, Nice, France, pp. 25.","cites":null},{"id":37969603,"title":"Strategic Management and Management Control: Designing a New Theoretical Framework',","authors":[],"date":"2002","doi":null,"raw":"Mendoza, C. and Saulpic, O. (2002), 'Strategic Management and Management Control: Designing a New Theoretical Framework', in Epstein, M.J. and Manzoni, J.-F.ed.","cites":null},{"id":37969538,"title":"Strategic Performance Measurement and Incentive Compensation',","authors":[],"date":"1998","doi":"10.1016\/s0263-2373(98)00032-2","raw":"Atkinson, A.A. (1998), 'Strategic Performance Measurement and Incentive Compensation', European Management Journal, Vol. 16, No. 5, Oct, pp. 552-561.","cites":null},{"id":37969623,"title":"Strategy and performance: getting the measure of your business,","authors":[],"date":"2002","doi":"10.1017\/cbo9780511754685","raw":"Neely, A. D., Bourne, M. C. S., Mills, J. F., Richards, A. H.& Platts, K. W., (2002a), Strategy and performance: getting the measure of your business, Cambridge University Press, Cambridge.","cites":null},{"id":37969569,"title":"Succeeding in Managerial Accounting. Part 2: a Structural Equations Analysis',","authors":[],"date":"2000","doi":"10.1016\/s0361-3682(99)00064-1","raw":"Hunton, J.E. , Wier, B. & Stone, D.N. (2000), 'Succeeding in Managerial Accounting. Part 2: a Structural Equations Analysis', Accounting Organizations and Society, Vol. 25, No. 8, pp. 751-762.","cites":null},{"id":37969576,"title":"The balanced scorecard - measures that drive performance &quot;,","authors":[],"date":"1992","doi":null,"raw":"Kaplan, R. S. & Norton, D. P., (1992), &quot;The balanced scorecard - measures that drive performance &quot;, Harvard Business Review, Jan.\/Feb., pp. 71 - 79.19 Kaplan, R. S. & Norton, D. P., (1993), &quot;Putting the balanced scorecard to work&quot;, Harvard Business Review, Sept.\/Oct., pp. 134 - 147.","cites":null},{"id":37969611,"title":"The Balanced Scorecard: A Necessary Good or an Unnecessary Evil?',","authors":[],"date":"1999","doi":"10.1016\/s0263-2373(99)00034-1","raw":"Mooraj, S., Oyon, D. and Hostettler, D. (1999), 'The Balanced Scorecard: A Necessary Good or an Unnecessary Evil?', European Management Journal, Vol. 17, No. 5, pp. 481-491.","cites":null},{"id":37969588,"title":"The Balanced Scorecard: Judgmental Effects of Common and Unique Performance Measures',","authors":[],"date":"2000","doi":"10.2308\/accr.2000.75.3.283","raw":"Lipe, M.G. and Salterio, S.E. (2000), 'The Balanced Scorecard: Judgmental Effects of Common and Unique Performance Measures', Accounting Review, Vol. 75, No. 3, pp. 283-298.","cites":null},{"id":37969635,"title":"The Forces That Shape Organisational Performance Measurement Systems: an Interdisciplinary Review',","authors":[],"date":"1999","doi":"10.1016\/s0925-5273(98)00201-1","raw":"Waggoner, D.B., Neely, A.D. and Kennerley, M.P. (1999), 'The Forces That Shape Organisational Performance Measurement Systems: an Interdisciplinary Review', International Journal of Production Economics, Vol. 60, No. 1, Apr, pp. 53-60.","cites":null},{"id":37969545,"title":"The interplay between performance measurement, organizational culture and management styles\u201d,","authors":[],"date":"2004","doi":"10.1108\/13683040410555591","raw":"Bititci, U. S., Mendibil, K., Nudurupati, S., Turner, T. & Garengo, P., (2004), \u201cThe interplay between performance measurement, organizational culture and management styles\u201d, Measuring Business Excellence, Vol. 8, No. 3, pp. 28 \u2013 41.","cites":null},{"id":37969609,"title":"The Myths of MIS',","authors":[],"date":"1972","doi":"10.2307\/41164405","raw":"Mintzberg, H. (1972), 'The Myths of MIS', California Management Review, Vol. 15, No. 1, pp. 92-97.21 Moon, P. and Fitzgerald, L. (1996), 'Delivering the Goods at TNT: The Role of the Performance Measurement System', Management Accounting Research, Vol. 7, No. 4, pp. 431-457.","cites":null},{"id":37969554,"title":"The Performance Measurement Manifiesto',","authors":[],"date":"1991","doi":null,"raw":"Eccles, R.G. (1991), 'The Performance Measurement Manifiesto', Harvard Business Review, Jan-Feb, pp. 131-137.","cites":null},{"id":37969622,"title":"The Performance Prism: the Scorecard for Measuring and Managing Business Success,","authors":[],"date":"2002","doi":"10.1108\/13683040010377818","raw":"Neely, A.D., Adams, C. and Kennerley, M. (2002), The Performance Prism: the Scorecard for Measuring and Managing Business Success, Pearson Education Ltd., London, UK.","cites":null},{"id":37969553,"title":"The Role of Behavioral Factors in the Successful Implementation and Use of Performance Management Systems\u201d,","authors":[],"date":"2002","doi":"10.1108\/00251740310496206","raw":"De Waal, A.A. (2002), \u201cThe Role of Behavioral Factors in the Successful Implementation and Use of Performance Management Systems\u201d, in Neely, A.D., Walters, A. and Austin, R. (Ed.), Performance Measurement and Management: Research and Action, Centre for Business Performance, Cranfield School of Management, Cranfield, UK, pp. 157-164.","cites":null},{"id":37969578,"title":"The strategy focused organization: how balanced scorecard companies thrive in the new business environment,","authors":[],"date":"2001","doi":"10.5465\/amle.2005.19086796","raw":"Kaplan, R. S. & Norton, D. P., (2001), The strategy focused organization: how balanced scorecard companies thrive in the new business environment, Harvard Business School Press, Boston, MA, USA.","cites":null},{"id":37969549,"title":"The success and failure of performance measurement initiatives: the perceptions of participating managers\u201d,","authors":[],"date":"2002","doi":"10.1108\/01443570210450329","raw":"Bourne, M. C. S., Neely, A. D., Platts, K. W. & Mills, J. F., (2002), \u201cThe success and failure of performance measurement initiatives: the perceptions of participating managers\u201d, International Journal of Operations and Production Management, Vol. 22, No 11, pp. 1288 \u2013 1310.","cites":null},{"id":37969586,"title":"The ten commandments of balanced scorecard implementation&quot;,","authors":[],"date":"1998","doi":null,"raw":"Lewy & Du Mee, (1998), &quot;The ten commandments of balanced scorecard implementation&quot;, Management Control and Accounting, April.","cites":null},{"id":37969573,"title":"The Use of Nonfinancial Performance Measurement (NFM) by Managers and Their Perceived","authors":[],"date":"2001","doi":null,"raw":"Kalagnanam, S. (2001), \u201cThe Use of Nonfinancial Performance Measurement (NFM) by Managers and Their Perceived Influence on NFM on Future Performance\u201d, in Workshop on Performance Measurement and Management Control, Nice, France.","cites":null},{"id":37969597,"title":"The Use of Performance Measurement Information As a Driver in Designing a Performance Measurement System', in Performance Measurement and Management: Research and Action","authors":[],"date":"2002","doi":"10.1007\/978-3-540-73212-9_5","raw":"Martins, R.A. (2002), 'The Use of Performance Measurement Information As a Driver in Designing a Performance Measurement System', in Performance Measurement and Management: Research and Action Boston, USA, Centre for Business Performance, UK, McAdam, R. and Bailie, B. (2002), 'Business Performance Measures and Alignment Impact on Strategy - the Role of Business Improvement Models', International Journal of Operations & Production Management, Vol. 22, No. 9-10, pp. 972-996.","cites":null},{"id":37969568,"title":"Theory and Practice in SME Performance Measurement Systems',","authors":[],"date":"2001","doi":"10.1108\/eum0000000005587","raw":"Hudson, M., Smart, A. and Bourne, M. (2001b), 'Theory and Practice in SME Performance Measurement Systems', International Journal of Operations & Production Management, Vol. 21, No. 8, pp. 1096-1115.","cites":null},{"id":37969619,"title":"Three Modes of Measurement: Theory and Practice',","authors":[],"date":"1998","doi":"10.1504\/ijbpm.1998.004544","raw":"Neely, A.D. (1998a), 'Three Modes of Measurement: Theory and Practice', International Journal of Business Performance Management, Vol. 1, No. 1, pp. 47-64.","cites":null},{"id":37969561,"title":"Toward an Integrative Framework of Organisational Control',","authors":[],"date":"1985","doi":"10.1016\/0361-3682(85)90030-3","raw":"Flamholtz, E.G., Das, T.K. and Tsui, A.S. (1985), 'Toward an Integrative Framework of Organisational Control', Accounting, Organisations and Society, Vol. 10, No. 1, pp. 35-50.","cites":null},{"id":37969570,"title":"Understanding Non-Financial Performance Measurement Practices in Japanese Banks',","authors":[],"date":"2002","doi":"10.1108\/09513570210425583","raw":"Hussain, M. and Hoque, Z. (2002), 'Understanding Non-Financial Performance Measurement Practices in Japanese Banks', Accounting, Auditing & Accountability Journal, Vol. 15, No. 2, pp. 162-183 Ittner, C.D., & Larcker, D.F. (1998), 'Are Nonfinancial Measures Leading Indicators of Financial Performance? An Analysis of Customer Satisfaction', Journal of Accounting Research, Vol. 36, pp. 1-35.","cites":null},{"id":37969601,"title":"Unlocking the potential of performance measurement: a guide to practical implementation&quot;,","authors":[],"date":"1995","doi":"10.1080\/09540969509387888","raw":"Meekings, A., (1995), &quot;Unlocking the potential of performance measurement: a guide to practical implementation&quot;, Public Money & Management, Oct. - Dec., pp. 1 - 8.","cites":null},{"id":37969577,"title":"Using the balanced scorecard as a strategic management system&quot;,","authors":[],"date":"1996","doi":"10.1057\/9781137294678.0037","raw":"Kaplan, R. S. & Norton, D. P., (1996), &quot;Using the balanced scorecard as a strategic management system&quot;, Harvard Business Review, Jan,\/Feb., pp. 75 - 85.","cites":null},{"id":37969544,"title":"Web Enabled Performance Measurement Systems - Management Implications',","authors":[],"date":"2002","doi":"10.1108\/01443570210450310","raw":"Bititci, U.S., Nudurupati, S.S., Turner, T.J. and Creighton, S. (2002), 'Web Enabled Performance Measurement Systems - Management Implications', International Journal of Operations & Production Management, Vol. 22, No. 11, pp. 1273-1287.","cites":null},{"id":37969599,"title":"What Is Strategic Performance Measurement?\u201d, Ernst &","authors":[],"date":"1992","doi":null,"raw":"McGee, J.V., (1992), \u201cWhat Is Strategic Performance Measurement?\u201d, Ernst & Young Center for Business Innovation, US.","cites":null},{"id":37969620,"title":"Why measurement initiatives fail\u201d,","authors":[],"date":"2000","doi":"10.1108\/13683040010362283","raw":"Neely, A. & Bourne, M. (2000), \u201cWhy measurement initiatives fail\u201d, Measuring Business Excellence, Vol. 4, No. 4, pp. 3 \u2013 6.","cites":null},{"id":37969564,"title":"Working paper, Vrije University,","authors":[],"date":"1998","doi":null,"raw":"Gelderman, M., (1998), Working paper, Vrije University, Netherlands.18 Ghalayini, A.M. & Noble, J.S. (1996), 'The Changing Basis of Performance Measurement', International Journal of Operations & Production Management, Vol. 16, No. 8, pp. 63-80 Goold, M. & Quinn, J. J., (1991), \u201cThe paradox of strategic control\u201d, Strategic Management Journal, Vol. 11, pp. 43 \u2013 57.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2005-01-01T00:00:00Z","abstract":"Performance measurement has developed rapidly over the last two decades. The\ndissatisfaction with financial measures, which came to the fore in the 1980s,\nhas given way to a plethora of balanced performance measurement frameworks. Over\nthe period, the focus has moved from designing balanced performance measurement\nsystems, through implementation to the use of measures to manage performance.\nThere is now a debate in the literature over whether performance has a positive\nimpact on business performance, but despite the research, until recently, few\nstudies have examined the use of performance measures and how performance\nmeasurement impacts performance. This paper reports on a study of the use of\nperformance measures in multiple business units of the same organisation. The\nfindings suggest that current research into the impact of performance\nmeasurement on performance may be too simplistic in its approach as much of the\nresearch relies on studying the physical and formal systems used, ignoring the\ntypes of factors found to be important in this study. These factors include\nSimons\u2019 (1991) concept of interactive control and the paper suggests that this\nconcept deserves further stu","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/140225.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/10.1108\/17410380510594480","pdfHashValue":"a780f6a178ddd72914d3df0bf4dc33f12bb23980","publisher":"MCB University Press","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/3036<\/identifier><datestamp>2014-02-10T10:52:28Z<\/datestamp><setSpec>hdl_1826_28<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Managing through measures: a study of impact on performance<\/dc:title><dc:creator>Bourne, Mike<\/dc:creator><dc:creator>Kennerley, Mike<\/dc:creator><dc:creator>Franco-Santos, Monica<\/dc:creator><dc:subject>Business performance<\/dc:subject><dc:subject>Performance management<\/dc:subject><dc:subject>Performance measurement (quality)<\/dc:subject><dc:description>Performance measurement has developed rapidly over the last two decades. The\ndissatisfaction with financial measures, which came to the fore in the 1980s,\nhas given way to a plethora of balanced performance measurement frameworks. Over\nthe period, the focus has moved from designing balanced performance measurement\nsystems, through implementation to the use of measures to manage performance.\nThere is now a debate in the literature over whether performance has a positive\nimpact on business performance, but despite the research, until recently, few\nstudies have examined the use of performance measures and how performance\nmeasurement impacts performance. This paper reports on a study of the use of\nperformance measures in multiple business units of the same organisation. The\nfindings suggest that current research into the impact of performance\nmeasurement on performance may be too simplistic in its approach as much of the\nresearch relies on studying the physical and formal systems used, ignoring the\ntypes of factors found to be important in this study. These factors include\nSimons\u2019 (1991) concept of interactive control and the paper suggests that this\nconcept deserves further stud<\/dc:description><dc:publisher>MCB University Press<\/dc:publisher><dc:date>2012-08-09T23:02:25Z<\/dc:date><dc:date>2012-08-09T23:02:25Z<\/dc:date><dc:date>2005-01-01T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>Mike Bourne, Mike Kennerley, Monica Franco-Santos, Managing through measures: a\nstudy of impact on performance, 2005, Volume:16, Issue:4, Page:373 - 395<\/dc:identifier><dc:identifier>1741-038X<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1108\/17410380510594480<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/3036<\/dc:identifier><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["1741-038x","issn:1741-038X"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2005,"topics":["Business performance","Performance management","Performance measurement (quality)"],"subject":["Article"],"fullText":"1Bourne, M., Kennerley, M. and Franco-Santos, M. (2005), 'Managing Through Measures:\na Study of Impact on Performance', Journal of Manufacturing Technology Management,\nVol. 16, No. 4, pp. 373-395.\nMANAGING THROUGH MEASURES: A STUDY OF IMPACT ON\nPERFORMANCE\nMike Bourne1, Mike Kennerley & Monica Franco-Santos\n1. Contact author at: Centre for Business Performance, Cranfield School of\nManagement, Cranfield, MK43 0AL, England. Telephone + 44 (0) 1234 754919,\nemail m.bourne@cranfield.ac.uk\nDr Mike Bourne is Director of the Centre for Business Performance at Cranfield School of\nManagement where his research focuses on the design, implementation and use of\nperformance measurement systems.\nDr Mike Kennerley is Research Fellow at the Centre for Business Performance at\nCranfield School of Management.\nMonica Franco-Santos is Research Officer at the Centre for Business Performance at\nCranfield School of Management.\n2MANAGING THROUGH MEASURES: A STUDY OF IMPACT ON\nPERFORMANCE\nABSTRACT\nPerformance measurement has developed rapidly over the last two decades. The\ndissatisfaction with financial measures, which came to the fore in the 1980s, has given way\nto a plethora of balanced performance measurement frameworks. Over the period, the\nfocus has moved from designing balanced performance measurement systems, through\nimplementation to the use of measures to manage performance. There is now a debate in\nthe literature over whether performance has a positive impact on business performance, but\ndespite the research, until recently, few studies have examined the use of performance\nmeasures and how performance measurement impacts performance. This paper reports on\na study of the use of performance measures in multiple business units of the same\norganisation. The findings suggest that current research into the impact of performance\nmeasurement on performance may be too simplistic in its approach as much of the research\nrelies on studying the physical and formal systems used, ignoring the types of factors\nfound to be important in this study. These factors include Simons\u2019 (1991) concept of\ninteractive control and the paper suggests that this concept deserves further study.\nKey words: Performance Measurement, Performance Management, Business Performance\nINTRODUCTION\nWith the Balanced Scorecard (Kaplan & Norton, 1992) being cited by Harvard Business\nReview in 1997 as one of the most important management tools of the last 75 years,\nperformance measurement has been attracting a great deal of interest (Neely, 1998a). There\nare now numerous balanced performance measurement frameworks (Keegan et al 1989;\nLynch & Cross, 1991; Fitzgerald et al, 1991, Kaplan & Norton, 1992; Neely et al, 2002)\nand multiple processes for the design of performance measurement systems (Bitton, 1990;\nDixon et al, 1991; Kaplan & Norton, 1993, 1996; Neely et al, 1996, 2002a; Krause &\nMertins, 1999). The problems of implementation have also been studied (Meekings 1995;\nBierbusse & Siesfeld 1997; Lewy & Du Mee, 1998; Schneiderman, 1999; Bourne et al,\n1999, 2000, 2002, 2003), but the whole area of how performance measures are used has\nattracted less attention until recently. This now appears the focus of current research (e.g.\nLipe and Salterio, 2000, 2002; Kalagnanam, 2001; Vakkuri and Meklin, 2001; Barsky and\nMarchant, 2001; Malmi, 2001; Malina and Selto, 2002; Epstein, 2002) and the use of\nperformance measures is the subject of this paper.\nThe research described in this paper was designed to address the question \u201chow the\ndifferences in use of performance measurement have different impact on business\nperformance?\u201d Our working proposition was that the manner in which the data is acquired,\nanalysed, interpreted, communicated and acted upon has an impact on business unit\nperformance. But in undertaking this research, many other factors have to be taken into\naccount.\n3Currently, there is a continuing debate in the performance measurement literature as to\nwhether performance measurement has a positive impact on business performance or not.\nAs the literature review will show, the evidence is mixed. As a consequence, a better\nquestion may be \u201cunder what circumstances does performance measurement positively\nimpact on organisational performance?\u201d In practice, the organisational context,\nperformance measurement content and process will all impact on the outcome. Our\nobservation from reviewing the literature was that there was little field research focusing\non the process1 of using performance measures and therefore we designed this research\nspecifically to investigate the use of measurement and impact on performance. In this\nstudy, by examining different business units in the same organisation, many of the\ncontextual, process and content factors were common allowing us to focus on the use of\nthe measures. The case studies examined how performance measures were used in high\nand average performing business units. High and average performing business units were\nselected, as we wanted to know what differentiated the performance between the best and\nthe average, rather than between the best and the worst. Our research analysed the\ndifference in practices and relates these to differences in performance.\nThe format of this paper is as follows. Firstly, we review the literature, summarising the\nfactors believed to influence performance measurement effectiveness using Pettigrew et\nal\u2019s (1989) framework. Secondly, we outline the research itself and the methodology used\nto gather case study data and to \u201ccontrol\u201d for common organisational factors. Thirdly, we\ndescribe the organisation in which our cases studies were conducted and, in particular, the\nmanagement structure and performance measurement systems in use. Fourthly, we report\nour findings including the differentiators between high and average performing business\nunits. These are then discussed and contrasted with Simons\u2019 concept of interactive control.\nFinally we conclude and suggest this is an area for further research.\nTHE LITERATURE\nMany practitioners embarking upon a redevelopment of their performance measurement\nsystem assume that their efforts will have a positive impact on the organisation\u2019s overall\nperformance (Bourne et al, 1999). This is often their basic reason for beginning such a\nproject, but published research suggests that success is not certain.\nA recent study has analysed 99 published papers on the impact of performance\nmeasurement on organisational performance (Franco & Bourne, 2004). Although the study\nrevealed that the majority of papers found that performance measurement had a positive\nimpact on organisational performance, further analysis suggested that the more rigorous\nthe research method used, the less likely performance measurement would be found to\nhave a positive impact. The conclusion has to be that the research findings are\ncontradictory. Whilst some studies have found that the use of non-financial performance\n1 Despite significant research into the impact of performance measurement, little of this research focuses on\nthe process of using the measures to manage performance.\n4measures has a positive impact on business performance (Ittner & Larcker, 1998, 2003;\nBanker et al, 2000) others found no relationship (Perera et al, 1997, Neely et al, 2004).\nWhether performance measurement per se is a \u201cgood thing\u201d is certainly of academic\ninterest, but for those engaged in directing and managing organisations, the more\nimmediate question is \u201cunder what circumstances does performance measurement\npositively impact on organisational performance?\u201d To answer this question we will briefly\nreview the literature. As stated previously, the organisational context, performance\nmeasurement content and process will all impact on the outcome, so we have adopted\nPettigrew et al\u2019s (1989) framework of context, content and process in our presentation of\nthe literature.\nContext\nPettigrew et al (1989) defined context as both the organisation\u2019s external environment\n(such as the competitiveness of the industry, the economic and political situation) and\ninternal context (such as structure, culture, management style and resources). We address\nthese in turn.\nOur review of the literature found studies of the impact of external context on\norganisational performance. Smith & Goddard (2002) and Waggoner et al. (1999) have\nsuggested market uncertainty, supplier characteristic and the economic situation all impact\nperformance measurement effectiveness, whilst Goold & Quinn (1991) argued that\nperformance measurement effectiveness is contingent on the speed of change and the\nmeasureability of performance. Lokman and Clarke (1999) studied the influence of market\ncompetitiveness on the use of information, performance measurement and business unit\nperformance and Husain and Hoque (2002) found that economic constraints and regulatory\nregimes influenced the use of measurement systems. Publish research suggests that\nexternal environmental factors do have an impact on performance measurement\neffectiveness, but so far there is no overarching framework to describe this relationship.\nThe impact of internal context has been more widely researched and there are many\naspects cited, from organisation size and structure, culture and management style,\nmanagement resources and capabilities, the interface between the measurement system and\nother processes and the maturity of the system itself. We have summarised these in table 1.\nInternal Context Authors\nSystem maturity\n\uf0b7 More mature systems are more effective\nEvans, 2001; Martins, 2002\nOrganisational structure\n\uf0b7 Importance of aligning structure and\nmeasurement\nHendricks, 1996; Bourne et al, 2002\nOrganisational size\n\uf0b7 Measurement is easier in larger organisations\nand more problematic in smaller ones\nHoque and James, 2000; Hudson et al. 2001a,\n2001b\nOrganisational culture\n\uf0b7 Alignment between the cultural elements\nembedded in the measurement system and the\nusers\u2019 cultural preference is beneficial\nDe Waal, 2002; Gates, 1999; Johnston et al.,\n2002; Lingle and Schiemann, 1996; Lockamy and\nCox, 1995; Maisel, 2001; Malina and Selto, 2002;\nBititci et al, 2004\nManagement style Gelderman, 1998; Libby & Luft, 1993; Hunton et\n5\uf0b7 Appropriate style important, appropriate style\nmay be different in different settings and\nphases of implementation and use\nal, 2000; Simon 1987; Bititci et al, 2004\nCompetitive strategy\n\uf0b7 Measures should be aligned to strategy\nKaplan and Norton, 1996, 2001; Lockamy, 1998;\nMendoza and Saulpic, 2002; McAdam and Bailie,\n2002; Neely, 1998\nResources and capability\n\uf0b7 Companies need resources and capabilities to\nimplement and refresh their measurement\nsystems\nBourne, 2004, Kennerley and Neely, 2002\nInformation Systems infrastructure\n\uf0b7 High data integrity and a low burden of data\ncapture are important\nBititci et al., 2002; Eccles, 1991; Lingle and\nSchiemann, 1996; Manoochehri, 1999\nOther management practices and systems\n\uf0b7 There should be alignment between\nmeasurement and other systems (e.g.\nbudgeting, compensation)\nDe Toni and Tonchia, 2001; Eccles, 1991; Eccles\nand Pyburn, 1992; Kaplan and Norton, 1966,\n2001; Moon and Fitzgerald, 1996; Otley, 1999\nTable 1: Internal contextual factors impacting performance measurement effectiveness\nContent\nThe content of the measurement system is concerned with what is being measured and how\nthe measures are structured. For example, authors have identified that: -\n\uf0b7 The specific definition of the measures themselves is important (to both the\ndesigner of the measures to clarify strategy and to the user of the measures to\ninfluence behaviour and direct action, Neely et al, 1997)\n\uf0b7 The different dimensions of the measures used are important to the users of\nmeasurement systems as they direct management focus (Kaplan, 1984; Johnson &\nKaplan, 1987), be they internal and external or financial and non-financial (Keegan\net al, 1989); leading and lagging (Kaplan & Norton, 1996) or balanced (Kaplan &\nNorton, 1992).\n\uf0b7 The structure (the way the individual measures interrelate) too has been found to be\nimportant to the users of measurement systems (Lipe & Salterio 2000, 2002), be\nthat a pyramid (Lynch & Cross, 1991), matrix of results and determinants\n(Fitzgerald et al, 1991), strategy map (Kaplan & Norton, 1996) or a success map\n(Neely et al, 2002).\nEmpirical content studies suggest that performance measurement is more effective when\nthe measures are appropriately designed (Neely et al, 1997), include multiple dimensions\n(Lingle & Schiemann, 1996) and are structured in a way that helps managers understand\nthe interrelationship and reflects strategy (Lipe & Salterio, 2000, 2002).\nProcess\nFour main processes have been identified in performance measurement (Neely et al, 2000;\nBourne et al, 2000); these being design, implementation, use and refreshing.\nAs we stated in the introduction, the processes of design and implementation have been\nstudied and both have an impact on the outcome (Bourne et al, 2003) and effectiveness of\n6the measurement system (Neely & Bourne, 2000). Similarly the refreshing, or redesigning,\nof measures and the measurement system is important. Authors emphasise the need for\ncontinuous reviews of the measures themselves, their results, and their impact on goals and\nstrategy with a clear focus on improvement and learning (Ghalayini and Noble, 1996;\nJohnston et al., 2002; Kaplan and Norton, 2001b; Kennerley and Neely, 2002, 2003; Lingle\nand Schiemann, 1996; Neely et al., 2000) to keep the measures and measurement system\nrelevant for the organisation and its users (Manoochehri, 1999). The argument made is that\nthe measurement system will loose its effectiveness over time if it is not updated in line\nwith the environmental and organisational needs. However, three of Neely et al\u2019s (2000)\nprocesses (the design, implementation and refreshing processes) concern changing the state\nof the measurement system. From our review of the literature, the status quo (the situation\nwhere the performance measures are stable and used in managing performance) is less\nresearched.\nEmpirical studies of the use of measurement systems in the field at the level of detail of the\nprocess stages are rare, with Simons\u2019 (1991) work on interactive control being a notable\nexception. In his research he investigated the \u201clevers of control\u201d used in organisations to\nmeasure and manage performance. He concluded by differentiating between simple\nfeedback control, and \u201cinteractive control\u201d in which managers interact much more closely\nwith the data and management system. He found the interactive control to be more\neffective in certain situations. But given the relative lack of field studies, a framework was\nneeded to inform our research.\nOne of the simplest approaches to investigating the use of measures is through the stages in\nunderlying process, being data capture, data analysis, interpretation, communication and\ndecision making (Neely, 1998). Our literature review identified that writers focusing on the\nkey processes associated with the use of performance measures have identified seven\nfactors; (1) the linking to strategic objectives (Atkinson 1998; Otley 1999); (2) the method\nof data capture (Lynch & Cross, 1991; Simons, 1991; McGee, 1992; Neely, 1998); (3) data\nanalysis (Lynch & Cross 1991; Neely, 1998) (4) interpretation (Simons, 1991; Neely,\n1998) and evaluation (Ittner et al, 2003; Kerssens-van Drongelen & Fisscher,2003); (5) the\nprovision of information and communication (Bititci et al 1997; Forza & Salvador 2000;\nKerssens-van & Fisscher 2003; Lebas 1995; Lynch & Cross 1991; Simons, 1991; McGee,\n1992; Neely, 1998; Otley, 1999 (6) decision making (Ittner et al, 2003; Neely, 1998) and\n(7) taking action (Flamholtz, 1983, 1985; Simons, 1991). Synthesising these five stages\nand seven factors we have arrived at the process stages presented in table 2.\nProcess stages Authors\nAlignment with strategic\nobjectives\n(Atkinson 1998; Otley 1999)\nData capture Lynch & Cross (1991); McGee (1992); Simons (1991); Neely (1998)\nData analysis Lynch & Cross (1991); Neely (1998)\nInterpretation & evaluation Simons (1991); Neely (1998); Ittner et al (2003); Kerssens-van Drongelen\n& Fisscher (2003)\nCommunication and information\nprovision\nBititci et al (1997); Forza & Salvador (2000); Kerssens-van & Fisscher\n(2003); Lebas (1995); Lynch & Cross (1991); Simons (1991); McGee\n(1992); Neely (1998); Otley (1999)\nDecision making Ittner et al (2003); Neely (1998)\n7Taking action Flamholtz (1983, 1985); Simons (1991)\nTable 2 Process stages identified in performance measurement\nDuring this research, we adopted the framework from table 2 to guide our data collection,\ncase and cross case analysis. However, we did make one adjustment. It was decided that as\n\u201cdecision making\u201d is often difficult to observe (Ramachandran, 2004), it would be\nsubsumed in this study under the more observable outcome of the decisions - \u201ctaking\naction\u201d.\nSummarising the literature\nOur review identifies the contextual, process and content factors found in the literature that\nare believed to impact the effectiveness of performance measurement. Given the\nsignificant number of the contextual, process and content variables identified, studying of\nthe impact of performance measurement on performance is difficult. Therefore an\napproach that simplified the issues was needed. Hence the approach adopted here, that of\nresearching high and average performing operations in the same organisation, where many\nof the contextual, process and content variables are the same. This enabled us to focus on\n\u201chow the differences in use of performance measurement have different impact on business\nperformance?\u201d within a \u201ccontrolled\u201d environment.\nTHE RESEARCH METHODOLOGY\nIn order to progress the research, we needed access to an organisation that had multiple\nbusiness units operating in a similar manner in the same marketplace. Ideally, the system\nshould have been in place for more than two years, so that it was embedded and not a new\nsystem (Bourne et al, 2000; Evans, 2001; Martins, 2002). Further, the system needed to\ninclude a range of financial and non-financial measures, ideally that represented the\nperspectives of a Balanced Scorecard or similar recognised framework. The existence of a\ncommon data collection and processing system would be beneficial as it would increase\nthe probability of having reliable and comparable performance information. Having the\ndata management and reporting controlled by an IT department independent from those\nbeing measured would also reduce the chance of the data and information being distorted\nby the users.\nThe case study organisation was selected as it provided a network of comparable business\nunits with similar characteristics in which we could study how performance measures were\nused to manage performance. These practices could then be evaluated against direct\ninformation from both financial and non-financial measures, linking practices with\ncomparative levels of performance. The methodology was therefore designed to minimise\nboth internal and external contextual differences (Pettigrew et al, 1989, Bourne et al, 1999)\nallowing the research to focus on process, content and outputs. Table 3 illustrates how the\napproach was used and the factors, which were believed to be common (or controlled for)\nacross the cases and those identified as the focus for this research.\n8Ten individual case studies were conducted in total, five in high performing business units\nand five in average performing business units. To ensure consistency of data collection\nacross cases and researchers, a case study protocol was established to guide data collection\n(Yin, 1994) using table 3 as the basis for the data collection and being informed by the\nliterature identified above. As many factors were common across the cases being studied,\nour working proposition was that \u201cthe manner in which the data is acquired, analysed,\ninterpreted, communicated and acted upon has an impact on business unit performance\u201d.\nInsert Table 3 about here\nThe study was then conducted over a four month period in three phases. This first phase\ncomprised interviews with senior management and support staff in head office and\nobservation of the systems and procedures in use (seven days on site in total). During this\nperiod, five regions were arbitrarily selected to be studied and financial and non-financial\nperformance data was extracted from the balanced scorecard and profit and loss accounts\nto identify the performance of the business units in theses regions. The second phase\ninvolved interviewing the five managers responsible for these regions, discussing\nindividual business unit performance and selecting the business units to investigate. The\nthird phase comprised the site visits to the business units across the UK. The data\ncollection itself was conducted through a series of semi-structured interviews with Branch\nManagers, branch office personnel and operators. This was supported by direct observation\nand inspection of data and documentation to increase confidence in the findings by the\ntriangulation of different sources. Between half a day and a day was spent in each of the\nbusiness units over a two month period during phase three of the research and between\nfour and six individuals were interviewed per branch.\nThe cases were selected on the basis of two business units per region, with each Regional\nManager proposing a high and average performing business unit for study. The intention in\ndoing this was to minimise the differences between regions and in the management style of\nRegional Manager. However, the Regional Managers\u2019 recommendations were not accepted\nwithout verification. Access to the scorecard performance data and business unit profit and\nloss accounts enabled the researchers to form an independent view of comparative business\nunit performance. As mentioned, during phase one, interviews were conducted with central\nstaff. This included IT staff responsible for performance measurement reporting,\nrepresentatives from training, senior operations managers, accounting personnel and\ndirectors. As a result of the researchers\u2019 own analysis of the performance information,\nwhich was confirmed by the additional interviews, two of the original case studies were\nrejected. Two further cases were then conducted to replace the lost cases.\nFollowing Yin\u2019s (1994) prescriptions, individual cases were compiled before cross case\ncomparisons were made. Cross case comparisons were undertaken in two stages. Initially,\npairs of cases in the same region were compared. This was then followed by full cross\ncase comparison. Drawing conclusions from case study research is a difficult process, so\nthe approach adopted was based on Miles & Huberman's (1994) view of qualitative\nanalysis. This focuses on three phases \u2013 i) data reduction, ii) data display and iii)\nconclusion drawing and verification. The next section describes the case study organisation\nin more detail.\n9THE CASE STUDY ORGANISATION\nThe case study organisation is a UK based company providing repair services. These\nservices are sold directly to the consumer but also provided as a service to insurance\ncompanies. Service is delivered through an extensive network of branches (local business\nunits of the organisation) across the country. Each business unit has a Branch Manager and\nis managed as a profit centre within the service network. Regional Managers oversee some\n10 to 15 business units and the Regional Managers report directly to the Operations\nDirector.\nThe organisation as a whole has been using a \u201cBalanced Scorecard\u201d for over five years. At\nthe business level, that includes measures of financial performance, customer and\nemployee satisfaction and operational performance. However, the manner in which the\nscorecard has been cascaded to the business unit level has resulted in a much greater focus\non financial and operational measures. The customer perspective at the business unit level\nis measured through customer service measures, and the innovation and learning\nperspective through measures of operator productivity and rework.\nThe Branch Manager therefore receives weekly reports on operational performance\nincluding service levels and operator performance. These are generated automatically by\nthe IT system from data capture during transactions and presented in the form of traffic\nlights (green for on target, amber for near target and red for off target). The system\npresents the twelve scorecard measures in summary form, with the last week, month to\ndate and year to date figures appearing on a single screen. The software allows further\ninterrogation and drill down to transaction level. Branch Managers also have access to the\nscorecards of other business units within their own region so that they can compare their\nown business unit\u2019s performance with that of their colleagues. The Branch Managers also\nreceive an operators\u2019 scorecard (showing data on attendance, productivity and rework) on a\nweekly basis and the business unit profit and loss account each month.\nThere was also an incentive scheme in operation. Branch Managers\u2019 annual bonus was\npaid on the basis of achieving the budgeted profit target for the business unit. However,\ntheir performance was assessed on the basis of their scorecard performance, which was\nused as the basis for their annual salary increase. The operators within the business unit\nwere paid through a productivity bonus system that rewarded high levels of output in a\nweek and penalised non-attendance and poor quality. From our observations, the\ncombination of bonus paid on achieving budgeted profit and base pay on scorecard results,\nbalanced the focus between financial and non-financial measures. However, the operator\nbonus scheme drove different behaviour. This was believed by management to have\nincreased overall productivity across the company, but also caused the kinds of\ndysfunctional behaviours one would expect in specific situations (Kerr, 1995, \u201cOn the\nFolly of Rewarding A, While Hoping for B\u201d), presenting Branch Managers with some\ndilemmas over allocation of jobs.\nTHE FINDINGS\n10\nDrawing together the threads from the different cases was a difficult task as much of what\nwas happening in the different business units was similar. Repeating the similarities is of\nless value, so table 4 summarises the results of our final full cross case analysis\nemphasising the differences in each of the phases of the use of performance measurement.\nIn this section, we present our findings and observations by phase of the process, again\nfocusing on the differences rather than similarities. We begin with alignment to strategic\norganisational goals and end with taking action.\nInsert Table 4 about here\nAlignment to strategic organisational goals\nThe assumption underpinning the use of the balanced scorecard measures at business unit\nlevel was that getting a \u201cGreen Scorecard\u201d drove better performance (both financially and\nnon-financially). However when this proposition was challenged, there was wide spread\nacceptance by the Regional and Branch Managers that the link between financial\nperformance and the scorecard results had never been fully investigated and ready\nacceptance that the connection was not perfect. We interpreted this a strong indication that\nthe scorecard was being used as a means of controlling standards and not for maximising\nperformance.\nHigh performing business units were differentiated from the others by their business unit\nmanagers\u2019 use of simple mental models, which they used to manage the business unit on a\nday-to-day basis. They described how they used their own indicators (not the formal\nweekly scorecard measures) to manage, often using unofficial data sources (see below).\nThese had been developed from experience or insight into what the true drivers of business\nunit performance were. Many revolved around managing volume effectively and\nefficiently, but others focused on the development of individual skills and team working \u2013\naspects absent from the business unit level scorecard.\nGathering data\nThe formal Balanced Scorecard presented data gathered automatically from the service\nprocesses. Manual data input purely for measurement purpose was minimal.\nThe practice that differentiated high performing business units from the average was that\nmanagers in these business units collected additional data throughout the week from their\nplanning boards, conversations with team members and observations of activity. They did\nnot wait until the end of the week to take appropriate action as they adjusted their activities\nas the week progressed. As a result, the weekly scorecard results rarely came as a surprise\nto these managers. This proactive approach to data collection was visibly less apparent in\naverage performing business units and not mentioned in discussion with Branch Managers\nor staff\nAnalysing data\nBasic data analysis and display was performed by the IT system providing traffic light\nfeedback against target and month to date and year to date figures automatically. However\n11\nthe system did provide opportunities for extensive and time consuming analysis of the\nresults through data enquiry tools and data drill down to transaction level. Further, these\napplications and reports allowed comparisons between business units in the same regions,\nso managers could make direct comparison of their performance measures against their\nregional colleagues.\nThe information on average performing Branch Managers\u2019 use of data analysis tools was\ninconsistent, with some managers spending considerable time on analysis and others\nspending very little time. However, in high performing business units the use of data\nanalysis tools was consistent. In high performing business units, scorecard data analysis\nusing the standard data enquiry tools was very light. We have concluded from this that the\nmanagers in these business units were simply using the scorecard data to check their own\nassumptions and not as a fundamental tool for managing the business. However, in two\nbusiness units, additional tools had been developed to overcome specific problems. An\nexample was a detailed spreadsheet designed to calculate precisely consumable usage,\nsomething that had been a problem for the business unit in the past and that the tool helped\novercome. There was also evidence that managers were managing using their own systems\nrather than relying on the common company performance measurement systems. Evidence\nfor this included the continued use of old planning boards and additional focus on lost jobs.\nInterpretation and Evaluation\nInterpretation is concerned with extracting meaning from the performance measurement\nsystem. This was achieved by providing direct comparisons in the display of the weekly\nscorecard against targets. Additional comparisons were also available so that a Branch\nManger could compare their performance against other business units or the regional\naverage.\nAll business units were well aware of their performance in comparison to other business\nunits within the region and the better business units could express their performance in\nterms of company wide league tables. The factor that differentiated high performing\nbusiness units was the way they ignored inappropriate targets. Many targets were set on a\ncompany wide basis, and so were more or less achievable at business unit level depending\non local circumstances. High performing Branch Managers simply expressed the opinion\nthat they ignored inappropriate targets and managed their business unit with reference to\ntheir own targets (which on occasions were higher that those set nationally). We have\nconcluded that high performing business units are therefore not putting scarce resource into\naddressing specific inappropriate goals enabling them to maintain a high level of\nperformance overall.\nCommunicating Insight\nAt a company level, performance was communicated through the weekly scorecards,\noperator scorecards and monthly profit and loss account. These activities was reinforced by\nregular management meetings, one on one discussions and the monthly \u201cstate of the\nnation\u201d email from the operations director.\nHowever at the business unit level, communication was the biggest differentiator between\nhigh and average performing business units. The intensity of communication in high\n12\nperforming business units was so much greater, the frequency, the approach, the level of\ndetail in the content as well as the time spent. To provide one illustrative example, some\nBranch Managers had difficulty in interpreting their own profit and loss account, but in one\nbusiness unit the who team spent two hours on a Monday morning once a month analysing\nitem line by item line the whole of the business unit profit and loss statement and\ndiscussing what actions they could take to improve. In high performing business units,\nregular intense whole team meetings were not uncommon and reinforced the perpetual\nperformance dialogue in the business unit.\nTaking action\nAction taking was hard to observe but appeared to differ greatly across the organisation\ndepending on management style.\nAt the business unit level we observed a real dichotomy. In some instances action was\ntaken immediately on the discovery of a specific problem whilst in other circumstances,\naction was delayed. We have concluded that when the source of the problem is apparent\nand could be easily rectified, high performing managers acted quickly. On the other hand,\nwhen either the cause wasn\u2019t apparent or could not be simply fixed, action was delayed.\nThis meant that some natural variation in performance wasn\u2019t acted upon inappropriately.\nIt also meant that considerable latitude was given to individuals whose performance\ndeteriorated if the underlying cause was known (such as a personal problem). In fact this\nability to focus on both task and people issues simultaneously was a factor often present in\nhigh performing Branch Mangers and less apparent elsewhere.\nDISCUSSION\nThe studies undertaken did reveal that at a basic level, measurement and management of\nperformance was done in a similar manner across the business units. All used their reports,\ndisplayed them in line with company policy, communicated weekly to the staff and\nfulfilled the requirements of the appraisal system. Some, despite having been trained, were\nstill not fully conversant with the profit and loss (P&L) accounts, but at the basic level, this\nwas the only difference observed and was not common across all average performing\nbusiness units.\nThe differences observed between the high and average performing cases was in the way\nthey managed with the measures. Average performing business units were using the\nperformance measurement system as a simple control system, gathering the data, analysing\nit, interpreting and communicating the outcome and then taking action. On the other hand,\nhigh performing business units were using the measurement system much more\ninteractively. The performance measures were simply keeping the score at the end of the\nweek and informal data gathering and tracking systems were used to follow progress and\nguide quicker corrective action. This was reinforced by frequent formal and informal\ncommunication and informed action. Items less easily tracked (mainly cost items booked\nto the ledger) were reviewed in a more simplistic manner, but the level and involvement in\nthe detailed analysis was significantly higher in specific cases.\n13\nThis raises the question, \u201cis what we are observing in high performing business units just\nan example of Simons\u2019 (1991) interactive control?\u201d Simons stated\n\u201cA management control system is categorised as interactive when top managers\nuse it to personally and regularly involve themselves in the decisions of\nsubordinates. When systems are used for this purpose, four conditions are\ntypically present: Information generated by the management control system is an\nimportant and recurring agenda addressed by the highest levels of management;\nthe process demands frequent and regular attention from operating managers at all\nlevels of the organisation; data is interpreted and discussed in face-to-face\nmeetings of superiors, subordinates, and peers; the process relies on the continual\nchallenge and debate of underlying data, assumptions and action plans\u201d .\nThere are similarities. Managers were personally and regularly involving themselves with\ntheir subordinates\u2019 performance, performance information was regularly used in face-to-\nface discussions and meetings and performance was continually debated. However, there\nare also differences:\n1. This study was not of senior management of large organisations.\n2. The information used in this study was not confined to the formal performance\nmeasurement system. The findings suggest that higher performing business unit\nmanagers were responding to informal indicators during the week, using the formal\nmeasurement system to keep the score at the end of the week.\n3. The taking of action was influenced by local knowledge of personal and business\ncircumstances and did not always coincide with meeting specific organisational\ntargets (which locally were thought to be inappropriate).\n4. The interactive nature of the use of the measurement system was across the whole\nbusiness unit\u2019s performance; Simons (1991) suggested that interactive control\nshould be confined to one system, as it is unsustainable across all systems for\nprolonged periods.\n5. The concept of mental models (Eccles & Pyburn, 1992) does not explicitly appear\nin Simons\u2019 (1991) study.\nIt can be argued that some of the differences (1, 2 & 4 above) can be explained by the\nsmaller size of the business units in this study compared to Simons\u2019. However, it might\nsuggest that \u201cinteractive control\u201d may be different at different levels of the organisation,\nmay be used differently or may require refinement:\n1. Interactive control at a corporate level guides the development of formal responsive\nand timely reporting on key lead indicators; at the business unit level less formal\nindicators play this role.\n2. At business unit level it is possible to take account of knowledge of personal\ncircumstances and local differences in deciding on when and how to act. This is\nalso known to be the case at the corporate level (Mintzberg, 1972) but not explicit\nin Simons\u2019 (1991) concept of interactive control.\n3. If the pervasive interactive control we observed in this study is sustainable at the\nbusiness unit level, but (according to Simons, 1991) not at the corporate level, can\nwe design strategies to link the two and maximise the benefit from both?\n14\n4. Should we revisit Simons\u2019 (1991) \u201cinteractive control\u201d in the light of subsequent\ndevelopments in explicit mental models of cause and effect relationships such as\nstrategy maps (Kaplan & Norton, 1996) and success maps (Neely et al, 2002)?\nThere is evidence that such frameworks are useful for decision making (Lipe &\nSalterio, 2000, 2002) and challenging assumptions is explicitly mentioned in\nSimons\u2019 (1991) paper, but their role in \u201cinteractive control\u201d has not been studied.\nAs with Simons (1991) we identified models and assumptions as being important,\nbut the company had not reached the stage of formally developing a success map.\nCONCLUSIONS\nThe impact of performance measurement on business performance has been studied and\nreported in the literature, forming part of the continuing debate as to whether performance\nmeasurement has a positive impact on performance or not.\nThe majority of performance measurement researchers are not explicit about the theoretical\nunderpinning of their research (Michele et al, 2004). Here we have taken the proposition\nthat the manner in which the data is acquired, analysed, interpreted, communicated and\nacted upon has an impact on business unit performance. Our findings suggest that this is\nover simplistic. The intensity of engagement and interaction with the performance\nmeasurement processes has a greater impact than would be suggested from most of the\nmeasurement literature (Simons, 1991 excepted). As stated in the discussions, our findings\nhave similarities to Simons\u2019 concept of \u201cinteractive control\u201d, but there are differences.\nGiven the research is based on a single organisation, we cannot claim that Simons\u2019 (1991)\nconcept is incomplete, but this study should suggest that \u201cinteractive control\u201d would\nbenefit from further study in organisations using more recently developed performance\nmeasurement concepts and at multiple levels of the organisation.\nThis study has tried to contribute to this debate through multiple case studies of the use of\nperformance measurement in a single organisation. This approach has the advantage of\ncontrolling many of the contextual, process and content factors identified in the literature\nas having on impact on performance measurement. In particular, the physical aspects of the\nperformance measurement system used in each of the business units was based on the same\nmeasures, using the same data collection and processing systems and producing the same\ndata output and reports. It also has the advantage of allowing comparisons to be made\nbetween the performance of the business units being studied as, firstly, performance could\nbe compared using the same performance data and, secondly, the business units studied are\nin the same industry, in similar locations, with similar customers and all subjected to the\nsame business constraints.\nBut such an approach does have disadvantages. Being conducted in a single organisation\nhas implications for wider validity. Are the findings identified here relevant in a wider\ncontext? Similarly, as the research was based on a common performance measurement\nsystem, the uniqueness of this system has to be considered. Although the system was\nloosely based on the balanced scorecard (all four perspectives were measured), it could not\nbe necessarily considered representative of performance measurement systems generally in\nuse. The IT tool in use supporting the measurement system is one of some 27 currently on\n15\nthe market (Marr et al, 2003). The industry itself is a further factor. Multiple branch repair\nservices companies are not uncommon, but are far from widespread. The results need to be\ninterpreted in that light.\nFurther, the business unit comparisons relied on us being able to control for all the\ncontextual, process and content factors as identified in table 3. By taking and comparing\npairs of business units in the same region, we believe that we eliminated most of these\ninfluences. However, one factor, which is much more localised than the customer demand,\nis the local job market. In London this was highlighted as an issue and, as we did have a\nhigh and average performing pair of business units in London, this emerged during our\ninitial cross case analysis. Although this was not a factor identified during other cross case\ncomparisons, we cannot fully rule out the possibility that the quality of staff was a factor\nand this limitation should be more closely controlled in any future research.\nBeing based on a single organisation, the wider applicability of our specific findings from\nthis study should be questioned. However, what is important is the issue that this study\nraises, that studies that are confined to the physical and formal performance measurement\nroutines are likely not to observe many of the key factors that that differentiate between\nhigh and average performance. If, as we suggest, the interactive nature of the use of the\nmeasurement system is important, future research will need to find ways of observing,\nmeasuring and quantifying this interactivity to allow a richer picture of the impact of\nperformance measurement on performance to be developed.\nThis exploratory study has raised issues for future research. Firstly, we would recommend\nthat further cross business unit research is conducted in multiple organisations to test\nwhether the findings are replicable and applicable to a wider cross section of industry.\nSecondly, we would recommend longitudinal studies that tracked changes in practice and\nchanges in performance. This would be useful to understand whether the practices found\nhere are sustainable and produce sustainable higher levels of performance. It also would\nprovide insights when managers and practices changed in the same business unit. Thirdly,\nonce the factors have been refined, it would be appropriate to test the findings using survey\ninstruments developed from the case study insights. Ideally these surveys would be\nconducted across multiple organisations, but with multiple respondents from each of the\norganisations, rather than single organisational responses which currently dominate the\nliterature (e.g. Lingle & Schiemann, 1996, Gates, 1999). Fourthly, quasi-experimental\napproaches (similar to those by Lipe & Salterio, 2000, 2002) could be used to validate the\nimportance of the individual elements identified in the case and survey research. This\nwould tease apart factors that may naturally occur together. Finally, it must be remembered\nthat the impact on performance measurement effectiveness of many of the contextual,\nprocess and content issues in the literature has still have not been fully researched and\nthere is still much work to be done in this arena.\n16\nACKNOWLEDGEMENTS\nThis paper was produced during the research project \u201cManaging through measures\u201d, which\nwas sponsored by the EPSRC under grant number GR\/R56136\/01\nREFERENCES\nAtkinson, A.A. (1998), 'Strategic Performance Measurement and Incentive Compensation',\nEuropean Management Journal, Vol. 16, No. 5, Oct, pp. 552-561.\nBanker, R.D., Potter, G. & Srinivasan, D., (2000), 'An Empirical Investigation of an\nIncentive Plan That Includes Nonfinancial Performance Measures', Accounting Review,\nVol. 75, No. 1, pp. 65-92.\nBarsky, N. and Marchant, G. (2001), \u201cSome Evidence on the Use of Performance\nManagement Systems\u201d, in Workshop on Performance Measurement and Management\nControl, Nice, France, pp. 25.\nBierbusse, P. & Siesfeld, T. (1997) \"Measures that Matter\", Journal of Strategic\nPerformance Measurement, Vol. 1, No. 2, pp. 6-11.\nBititci, U. S., Carrie, A. S. & McDevitt, L, (1997), \"Integrated Performance Measurement\nSystems: a development guide\", International Journal of Operations and Production\nManagement, Vol. 17, No. 5, pp. 522-534.\nBititci, U.S., Nudurupati, S.S., Turner, T.J. and Creighton, S. (2002), 'Web Enabled\nPerformance Measurement Systems - Management Implications', International Journal of\nOperations & Production Management, Vol. 22, No. 11, pp. 1273-1287.\nBititci, U. S., Mendibil, K., Nudurupati, S., Turner, T. & Garengo, P., (2004), \u201cThe\ninterplay between performance measurement, organizational culture and management\nstyles\u201d, Measuring Business Excellence, Vol. 8, No. 3, pp. 28 \u2013 41.\nBitton, M., (1990), \"M\u00e9thode de conception et d'implantation de syst\u00e8mes de measure de\nperformances pour organisations industrielles\", Th\u00e8se d' automatique, Universit\u00e9 de\nBordeaux I, France.\nBourne, M. C. S., Mills, J. F., Bicheno J., Hamblin, D. J., Wilcox M. & Neely A. D. &\nPlatts, K, W., (1999), \"Performance Measurement System Design: Testing a Process\nApproach in Manufacturing Companies\", International Journal of Business Performance\nMeasurement, Vol. 1, No. 2, pp. 154 - 170.\nBourne, M. C. S., Mills, J. F., Wilcox, M. & Neely, A. D. & Platts, K, W., (2000),\n\"Designing, implementing and updating performance measurement systems\", International\nJournal of Production and Operations Management, Vol. 20, No. 7, pp. 754-771.\nBourne, M. C. S., Neely, A. D., Platts, K. W. & Mills, J. F., (2002), \u201cThe success and\nfailure of performance measurement initiatives: the perceptions of participating managers\u201d,\nInternational Journal of Operations and Production Management, Vol. 22, No 11, pp.\n1288 \u2013 1310.\nBourne, M. C. S., Neely, A. D., Mills, J. F. & Platts, K. W, (2003), \u201cImplementing\nperformance measurement systems: a literature review\u201d, International Journal of Business\nPerformance Management, Vol. 5, No. 1, pp. 1-24.\n17\nCoates, J., Davis, T., Emmanuel, C., Longden, S.G. & Stacey, R. (1992), 'Multinational\nCompanies Performance Measurement Systems: International Perspectives', Management\nAccounting Research, Vol. 3, pp. 133-150.\nDixon, J. R., Nanni, A. J. & Vollmann, T. E., (1991). An instrument for investigating the\nmatch between manufacturing strategy and performance measures, Working Paper, Boston\nUniversity.\nDe Toni, A. and Tonchia, S. (2001), 'Performance Measurement Systems - Models,\nCharacteristics and Measures', International Journal of Operations & Production\nManagement, Vol. 21, No. 1-2, pp. 46-70.\nDe Waal, A.A. (2002), \u201cThe Role of Behavioral Factors in the Successful Implementation\nand Use of Performance Management Systems\u201d, in Neely, A.D., Walters, A. and Austin,\nR. (Ed.), Performance Measurement and Management: Research and Action, Centre for\nBusiness Performance, Cranfield School of Management, Cranfield, UK, pp. 157-164.\nEccles, R.G. (1991), 'The Performance Measurement Manifiesto', Harvard Business\nReview, Jan-Feb, pp. 131-137.\nEccles, R.G. and Pyburn, P.J. (1992), 'Creating a Comprehensive System to Measure\nPerformance', Management Accounting, No. October , pp. 323.\nEpstein, M.J. (2002), \u201cMeasuring the Payoffs of Corporate Actions: the Use of Financial\nand Non-Financial Indicators\u201d, in Epstein, M.J. and Manzoni, J.F. (Ed.), Performance\nMeasurement and Management Control: A Compendium of Research , Elsevier Science ,\nKidlington, Oxford, UK, pp. 3-13.\nEvans, J.R. (2001), 'An Exploratory Study of Performance Measurement Systems and\nRelationship With Performance Results', in Presented at the Decisions Science Institute\n32nd Annual Conference. Digitizing Decisions & Markets San Francisco, CA, pp. 1-27.\nFitzgerald, L., Johnston, R., Brignall T. J. Silvestro, R. & Voss, C., (1991), Performance\nMeasurement in Service Businesses, The Chartered Institute of Management Accountants,\nLondon.\nFlamholtz, E.G. (1983), 'Accounting, Budgeting and Control-Systems in Their\nOrganisational Context - Theoretical and Empirical-Perspectives', Accounting,\nOrganisations and Society, Vol. 8, No. 2-3, pp. 153-169.\nFlamholtz, E.G., Das, T.K. and Tsui, A.S. (1985), 'Toward an Integrative Framework of\nOrganisational Control', Accounting, Organisations and Society, Vol. 10, No. 1, pp. 35-50.\nForza, C. and Salvador, F. (2000), 'Assessing Some Distinctive Dimensions of\nPerformance Feedback Information in High Performing Plants', International Journal of\nOperations & Production Management, Vol. 20, No. 3, pp. 359-385\nFranco, M. & Bourne, M. C. S. (2004), \u201cAre strategic performance measurement systems\nreally effective: a closer look at the evidence\u201d, Proceedings of the EurOMA Conference,\nJune, INSEAD, France, Vol. 2, pp. 163 \u2013 174.\nGates, S. (1999), Aligning Strategic Performance Measures and Results, The Conference\nBoard, New York, USA.\nGelderman, M., (1998), Working paper, Vrije University, Netherlands.\n18\nGhalayini, A.M. & Noble, J.S. (1996), 'The Changing Basis of Performance Measurement',\nInternational Journal of Operations & Production Management, Vol. 16, No. 8, pp. 63-80\nGoold, M. & Quinn, J. J., (1991), \u201cThe paradox of strategic control\u201d, Strategic\nManagement Journal, Vol. 11, pp. 43 \u2013 57.\nHendricks, J.A.et al. (1996), 'Changing Performance Measures at Caterpillar', Management\nAccounting, Dec, pp. 18-24.\nHoque, Z. & James, W. (2000), 'Linking Balanced Scorecard Measures to Size and Market\nFactors: Impact on Organizational Performance', Journal of Management Accounting\nResearch, Vol. 12, pp. 1-17.\nHudson, M., Lean, J. and Smart, P.A. (2001a), 'Improving Control Through Effective\nPerformance Measurement in SMEs', Production Planning and Control, Vol. 12, No. 8,\npp. 804-813.\nHudson, M., Smart, A. and Bourne, M. (2001b), 'Theory and Practice in SME Performance\nMeasurement Systems', International Journal of Operations & Production Management,\nVol. 21, No. 8, pp. 1096-1115.\nHunton, J.E. , Wier, B. & Stone, D.N. (2000), 'Succeeding in Managerial Accounting. Part\n2: a Structural Equations Analysis', Accounting Organizations and Society, Vol. 25, No. 8,\npp. 751-762.\nHussain, M. and Hoque, Z. (2002), 'Understanding Non-Financial Performance\nMeasurement Practices in Japanese Banks', Accounting, Auditing & Accountability\nJournal, Vol. 15, No. 2, pp. 162-183\nIttner, C.D., & Larcker, D.F. (1998), 'Are Nonfinancial Measures Leading Indicators of\nFinancial Performance? An Analysis of Customer Satisfaction', Journal of Accounting\nResearch, Vol. 36, pp. 1-35.\nIttner, C.D. and Larcker, D.F. (2003), 'Coming Up Short on Nonfinancial Performance\nMeasurement', Harvard Business Review, Vol. 81, No. 11, pp. 88-+.\nJohnston, R., Brignall, S. and Fitzgerald, L. (2002), ''Good Enough Performance\nMeasurement: a Trade-Off Between Activity and Action\u201d, Journal of the Operational\nResearch Society, Vol. 53, No. 3, Mar, pp. 256-262.\nKalagnanam, S. (2001), \u201cThe Use of Nonfinancial Performance Measurement (NFM) by\nManagers and Their Perceived Influence on NFM on Future Performance\u201d, in Workshop\non Performance Measurement and Management Control, Nice, France.\nLokman, M. and Clarke, B. (1999), 'Market Competition, Management Accounting\nSystems and Business Unit Performance ', Management Accounting Research, Vol. 10,\nNo. 2, pp. 137-158.\nKaplan, R. S., (1994), \"Devising a balanced scorecard matched to business strategy\",\nPlanning Review, Sept.\/Oct. pp. 15 - 19 & 48.\nKaplan, R. S. & Norton, D. P., (1992), \"The balanced scorecard - measures that drive\nperformance \", Harvard Business Review, Jan.\/Feb., pp. 71 - 79.\n19\nKaplan, R. S. & Norton, D. P., (1993), \"Putting the balanced scorecard to work\", Harvard\nBusiness Review, Sept.\/Oct., pp. 134 - 147.\nKaplan, R. S. & Norton, D. P., (1996), \"Using the balanced scorecard as a strategic\nmanagement system\", Harvard Business Review, Jan,\/Feb., pp. 75 - 85.\nKaplan, R. S. & Norton, D. P., (2001), The strategy focused organization: how balanced\nscorecard companies thrive in the new business environment, Harvard Business School\nPress, Boston, MA, USA.\nKeegan, D. P., Eiler, R. G. & Jones, C. R., (1989), \"Are your performance measures\nobsolete?\", Management Accounting, June, pp. 45 - 50.\nKennerley, M.P. and Neely, A.D. (2002), 'A Framework of the Factors Affecting the\nEvolution of Performance Measurement Systems', International Journal of Operations &\nProduction Management, Vol. 22, No. 11, pp. 1222-1245.\nKennerley, M. and Neely, A. (2003), 'Measuring Performance in a Changing Business\nEnvironment', International Journal of Operations & Production Management, Vol. 23,\nNo. 2, pp. 213-229.\nKerr, S. (1995), 'On the Folly of Rewarding A, While Hoping for B', The Academy of\nManagement Executive, Vol. 9, No. 1, pp. 7+.\nKerssens-Van Drongelen, I.C. & Fisscher, O.A.M. (2003), \u201cEthical Dilemmas in\nPerformance Measurement\u201d, Journal of Business Ethics, Vol. 45, No. 1-2, pp. 51-63.\nKrause, O. & Mertins, K., (1999), \"Performance management\", in Global Production\nManagement, Proceedings of the IFIP WG5.7 international conference on Advances in\nProduction Management Systems, edited by Mertins, K., Krause, O. & Schallock,\nSeptember.\nLebas, M.J. (1995), 'Performance Measurement and Performance Management',\nInternational Journal of Production Economics, Vol. 41, No. 1-3, pp. 23-35.\nLewy & Du Mee, (1998), \"The ten commandments of balanced scorecard\nimplementation\", Management Control and Accounting, April.\nLibby, R. & Luft, J. (1993), 'Determinants of Judgement Performance in Accounting\nSettings: Ability, Knowledge, Motivation, and Environment. ', Accounting Organizations\nand Society, Vol. 18, No. 5, pp. 425-450.\nLipe, M.G. and Salterio, S.E. (2000), 'The Balanced Scorecard: Judgmental Effects of\nCommon and Unique Performance Measures', Accounting Review, Vol. 75, No. 3, pp. 283-\n298.\nLipe, M.G. & Salterio, S.E. (2002), \u201cA Note on the Judgmental Effects of the Balanced\nScorecard's Information Organization\u201d, Accounting Organizations and Society, Vol. 27,\nNo. 6, Aug, pp. 531-540.\nLingle, J. H. & Schiemann, W. A., (1996), \"From Balanced Scorecard to Strategy Gauge:\nIs Measurement Worth It?\", Management Review, March , pp. 56 - 62.\nLockamy, A. (1998), 'Quality-Focused Performance Measurement Systems: a Normative\nModel', International Journal of Operations & Production Management, Vol. 18, No. 7-8,\n20\npp. 740-+.\nLockamy, A. and Cox, J.F. (1995), 'An Empirical Study of Division and Plant Performance\nMeasurement Systems in Selected World-Class Manufacturing Firms - Linkages for\nCompetitive Advantage', International Journal of Production Research, Vol. 33, No. 1,\nJan, pp. 221-236\nLynch, R. L. & Cross, K. F., (1991), Measure Up - The Essential Guide to Measuring\nBusiness Performance, Mandarin, London.\nMaisel, L.S. (2001), Performance Measurement Practices Survey Results, AICPA, US.\nMalina, M.A. & Selto, F.H. (2002), \u201cCommunicating and Controlling Strategy: an\nEmpirical Study of the Effectiveness of the Balanced Scorecard\u201d, available at:\nhttp:\/\/www.bettermanagement.com\/library\/ Library.aspx?LibraryID=539 (accessed 2002).\nMalmi, T. (2001), \u201cBalanced Scorecards in Finnish Companies: A Research Note\u201d,\nManagement Accounting Research, Vol. 12, pp. 207-220.\nMarr, B. and Neely, A.D. (2003) \u201cBalanced Scorecard Software Report\u201d, Gartner,\nStamford, CT. USA.\nManoochehri, G. (1999), 'Overcoming Obstacles to Developing Effective Performance\nMeasures ', Work Study, Vol. 48, No. 6, pp. 223-229.\nMartins, R.A. (2002), 'The Use of Performance Measurement Information As a Driver in\nDesigning a Performance Measurement System', in Performance Measurement and\nManagement: Research and Action Boston, USA, Centre for Business Performance, UK,\nMcAdam, R. and Bailie, B. (2002), 'Business Performance Measures and Alignment\nImpact on Strategy - the Role of Business Improvement Models', International Journal of\nOperations & Production Management, Vol. 22, No. 9-10, pp. 972-996.\nMcGee, J.V., (1992), \u201cWhat Is Strategic Performance Measurement?\u201d, Ernst & Young\nCenter for Business Innovation, US.\nMeekings, A., (1995), \"Unlocking the potential of performance measurement: a guide to\npractical implementation\", Public Money & Management, Oct. - Dec., pp. 1 - 8.\nMendoza, C. and Saulpic, O. (2002), 'Strategic Management and Management Control:\nDesigning a New Theoretical Framework', in Epstein, M.J. and Manzoni, J.-F.ed.\nPerformance Measurement and Management Control: a Compendium of Research,\nElsevier Science Ltd., Oxford, UK, pp. 131-158\nMichele, P., Franco, M., Marr, B. & Bourne, M., (2004), \u201cBusiness performance\nmeasurement: an organisational theory perspective\u201d, Performance Measurement and\nManagement; Public & Private, Proceedings of the 4th International PMA conference, 28th\n\u2013 30th July, Edinburgh, UK.\nMiles. M. B. & Huberman A. M., (1994), Qualitative data analysis, Sage, Thousand Oaks.\nCA, USA.\nMintzberg, H. (1972), 'The Myths of MIS', California Management Review, Vol. 15, No.\n1, pp. 92-97.\n21\nMoon, P. and Fitzgerald, L. (1996), 'Delivering the Goods at TNT: The Role of the\nPerformance Measurement System', Management Accounting Research, Vol. 7, No. 4, pp.\n431-457.\nMooraj, S., Oyon, D. and Hostettler, D. (1999), 'The Balanced Scorecard: A Necessary\nGood or an Unnecessary Evil?', European Management Journal, Vol. 17, No. 5, pp. 481-\n491.\nNeely, A. D., Mills, J. F., Gregory, M. J., Richards, A. H., Platts, K. W., & Bourne,\nM.C.S., (1996), Getting the measure of your business, Findlay, London.\nNeely, A. D., Richards, A. H., Mills, J. F., Platts, K. W. & Bourne, M. C. S., (1997),\n\u201cDesigning performance measures: a structured approach\u201d, International Journal of\nProduction and Operations Management., Vol. 17, No. 11, pp. 1131 - 1152.\nNeely, A.D. (1998), Measuring Business Performance: Why, What and How, The\nEconomist and Profile Books Ltd., London, UK.\nNeely, A.D. (1998a), 'Three Modes of Measurement: Theory and Practice', International\nJournal of Business Performance Management, Vol. 1, No. 1, pp. 47-64.\nNeely, A. & Bourne, M. (2000), \u201cWhy measurement initiatives fail\u201d, Measuring Business\nExcellence, Vol. 4, No. 4, pp. 3 \u2013 6.\nNeely, A.D., Mills, J.F., Platts, K., Richards, H., Gregory M.J., Bourne, M. & Kennerley,\nM.P. (2000), 'Performance Measurement System Design: Developing and Testing a\nProcess-Based Approach', International Journal of Operations & Production\nManagement, Vol. 20, No. 10, pp. 1119-1145.\nNeely, A.D., Adams, C. and Kennerley, M. (2002), The Performance Prism: the Scorecard\nfor Measuring and Managing Business Success, Pearson Education Ltd., London, UK.\nNeely, A. D., Bourne, M. C. S., Mills, J. F., Richards, A. H.& Platts, K. W., (2002a),\nStrategy and performance: getting the measure of your business, Cambridge University\nPress, Cambridge.\nNeely, A. D., Kennerley, M. J. & Martinez, V., (2004), \u201cDoes the Balanced Scorecard\nwork; an empirical investigation\u201d, Proceedings of the EurOMA conference, July, INSEAD,\nFrance Vol. 2, pp. 229 \u2013 238.\nOtley, D.T. (1999), 'Performance Management: a Framework for Management Control\nSystems Research', Management Accounting Research, Vol. 10, No. 4, Dec, pp. 363-382.\nPerera, S., Harrison, G. and Poole, M. (1997), 'Customer-Focused Manufacturing Strategy\nand the Use of Operations-Based Non-Financial Performance Measures: a Research Note',\nAccounting Organizations and Society, Vol. 22, No. 6, pp. 557-572.\nPettigrew, A., Whipp, R. and Rosenfield, R., (1989), \"Competitiveness and the\nmanagement of strategic change processes\", in The competitiveness of European Industry:\ncountry policies and company strategies, Francis, A., Tharakan, P. K. M. (Eds.).,\nRoutledge.\nRamachandran, N., (2004), \u201cInformativeness of Performance Measures in the Presence of\nReporting Discretion\u201d, Journal of Accounting, Auditing & Finance, Vol. 19 Issue 1, p61,\n23p.\n22\nSchneiderman, A., (1999), \u201cWhy balanced scorecards fail\u201d, Journal of Strategic\nPerformance Measurement, Special edition, pp. 6 \u2013 11.\nSimon, H.A. (1987), 'Making Management Decisions: the Role of Intuition and Emotion',\nAcademy of Management Executive, Feb, pp. 57-64.#\nSimons, R. (1991), 'Strategic Orientation and Top Management Attention to Control\nSystems', Strategic Management Journal, Vol. 12, pp. 49-62.\nSmith, P.C. and Goddard, M. (2002), 'Performance Management and Operational\nResearch: a Marriage Made in Heaven?', Journal of the Operational Research Society, Vol.\n53, No. 3, pp. 247-255.\nVakkuri, J. and Meklin, P. (2001), \u201cAmbiguity in the Using of Performance Measurement\nInformation in Organizations: the Application of the Theoretical Framework of\nMeasurement Risks in a Finnish Organizational Context\u201d, in Workshop on Performance\nMeasurement and Management Control, Nice, France.\nWaggoner, D.B., Neely, A.D. and Kennerley, M.P. (1999), 'The Forces That Shape\nOrganisational Performance Measurement Systems: an Interdisciplinary Review',\nInternational Journal of Production Economics, Vol. 60, No. 1, Apr, pp. 53-60.\nYin R. K., (1994), Case Study Research, Design and Methods, 2nd Edition, Sage\nPublications, Thousand Oaks.\n23\nFactors \u201cControl mechanism\u201d and Research Focus\nExternal Context\nIndustry competitiveness All BUs2 in the same business. Local differences minimised by comparing BUs in the same region\nEconomy All BUs in the same business. Local differences minimised by comparing BUs in the same region\nPolitical environment Common\nInternal Context\nSystem maturity In place across the business for 5 years\nOrganisational structure All BUs of a similar size, structure and reporting to similar regional structures\nOrganisational size All BUs of a similar size inside a medium sized enterprise\nOrganisational culture The same organisation, but local variances to be observed in the BUs studied\nManagement style The same organisation, but local variances to be observed in the BUs studied\nCompetitive strategy The same organisation, but local variances to be observed in the BUs studied\nResources and capability The same organisation, and staffing levels but local variances to be observed in the BUs studied\nInformation systems infrastructure Common throughout\nOther practices and systems Common throughout\nProcesses\nAlignment with objectives Common measures but local useage to be investigated and observed in the BUs studied\nData capture Formal data capture through a common IT system but to be investigated and observed in the BUs\nData analysis Reports common but additional analysis to be investigated and observed in the BUs studied\nInterpretation & evaluation To be investigated and observed\nDecision making To be investigated and observed\nCommunication and information\nprovision\nReports common but additional analysis to be investigated and observed\nDecision making and taking action To be investigated and observed\nContent\nDefinition of performance measures Common definition and central data processing enabling reliable comparisons on BUs\nDimensions measured Common balanced scorecard dimensions\nStructure and presentation Common structure with no strategy \/ success map but comparative data displayed\nTable 3, Factors to be researched\n2 BUs = Business Units\n24\nAlignment to\norganisational objectives\nGather data Analyse data Interpret \/\nEvaluate\nCommunicate\ninsight\nTake Action\nHigh\nPerforming\nBusiness Units\n(Business units\nnumbers 1,3,5,7,9)\n\uf0b7 Green scorecards lead to better\nperformance (1,3,5,7,9)\n\uf0b7 Personal mental model of\nassumptions of what drives\nperformance (1,5,7,9,)\n\uf0b7 Well trained people drive\nperformance (3,7)\n\uf0b7 Motivated people deliver\nperformance (1,3,5,7,9)\n\uf0b7 Motivation driven by\ncommunication (1,3,5,9)\n\uf0b7 Some measures interact\ntogether (3,7,9)\n\uf0b7 costs drive P&L (3,5,9)\n\uf0b7 Volume, lost jobs and rework\nare key to P&L (1,3,5,9)\n\uf0b7 Rework reflects training,\nmotivation or personal issues\n(1,3,5)\n\uf0b7 Recruitment key to long term\nperformance (1,3,7)\n\uf0b7 Own data collection\n(1,3,5,9)\n\uf0b7 Daily tracking of\njob progress and\nresults (3,5,7,9)\n\uf0b7 Occasional drill\ndown to interrogate\ndata (1,3,5,7,9)\n\uf0b7 Listening to office\nconversation and\nincoming calls (1,7)\n\uf0b7 Challenge cost\nallocation (3, 5, 9)\n\uf0b7 Root cause analysis\non lost jobs (3, 5, 7)\n\uf0b7 Specialised job\ncosting software\ndeveloped and used\nmonthly (9)\n\uf0b7 Specialised local\nconsumer usage\ntracking (7)\n\uf0b7 P&L variance\nanalysis with whole\nBU team to item\nline level (5)\n\uf0b7 P&L analysis with\noffice staff (7)\n\uf0b7 Old manual\nworkload display\nboard still used to\ntrack jobs in hand\n(1,9)\n\uf0b7 Against company\ntargets (1,3,5,7,9)\n(if appropriate,\n1,3,5)\n\uf0b7 Against own local\ntargets and\nstandards (3,5)\n\uf0b7 Estimate week\u2019s\nresults and use\nsystem to confirm\nevaluation (3,5,7,9)\n\uf0b7 Predict month end\nP&L - but difficult\n(3)\n\uf0b7 Against regional\nBU (1,3,5,7,9) and\nagainst whole\ncompany (3,5,7,9)\n\uf0b7 Display weekly\nresults and league\ntables (1,3,5,7,9)\n\uf0b7 Monthly 2 hour\nwhole team P&L\nreview meetings (5)\n\uf0b7 P&L review\nmonthly with office\nstaff (7)\n\uf0b7 Bi-monthly off site\nevening meeting\nwith pizza (3)\n\uf0b7 Regular one to one\n(5,7,9) and at every\nopportunity with\noperators (1, 3)\n\uf0b7 On P&L item lines\n(5,7,9)\n\uf0b7 On trend and not\nsingle result (3,5)\n\uf0b7 On morale and \/ or\nattitude (1,3,5)\n\uf0b7 On people issues, in\nand out of work\n(5,7)\n\uf0b7 After taking\nconditions into\naccount (1,3,5,7,9)\n\uf0b7 On local BU issues\n(1,7,9)\n\uf0b7 On own data\n(1,3,5,9)\n\uf0b7 Early, when\nappropriate\n(1,3,5,9)\nAverage\nPerforming\nBusiness Units\n(Business units\nnumbers\n2,4,6,8,10)\n\uf0b7 Green scorecards lead to better\nperformance (2,4,6,8,10)\n\uf0b7 Costs need to be contained\n(2,8)\n\uf0b7 People are important (2,4,6,10)\n\uf0b7 Rely on automatic\ndata acquisition\n(2,4,6,8,10,)\n\uf0b7 Weekly drill down\nto interrogate data\n(2,4,6,8,10)\n\uf0b7 Operators\u2019 time\nsheet reviewed\nweekly (2,4,6,8,10)\n\uf0b7 10 minute look\nthrough results at\nweekend (4,6,8)\n\uf0b7 Detailed weekly\ndrill down to\nevaluate\nperformance data\n(2,10)\n\uf0b7 Against company\ntargets (2,4,6,8,10)\n\uf0b7 Against region\n(2,4,6,8,10)\n\uf0b7 Traffic light colour\n(2,4,6,8,10)\n\uf0b7 Against budget\n(2,8,10)\n\uf0b7 Display weekly\nresults and league\ntables on wall\n(2,4,6,8,10)\n\uf0b7 Short performance\nreporting meetings\n(2,4,6,8,10)\n\uf0b7 Regular One to\nones (2, 6,10)\n\uf0b7 On variance from\nbudget (2,8,10)\n\uf0b7 On red traffic lights\n(2,4,6,8,10)\n\uf0b7 On operations\ndirector\u2019s monthly\nfocus email\n(2,4,6,8,10)\nTable 4: The results from the cross case analysis\n"}
{"doi":"10.1007\/978-3-642-17746-0_43","coreId":"177232","oai":"oai:aura.abdn.ac.uk:2164\/1132","identifiers":["oai:aura.abdn.ac.uk:2164\/1132","10.1007\/978-3-642-17746-0_43"],"title":"OWL-POLAR : semantic policies for agent reasoning","authors":["Sensoy, Murat","Norman, Timothy J","Vasconcelos, Wamberto Weber","Sycara, Katia P"],"enrichments":{"references":[{"id":188075,"title":"A functional taxonomy of normative conflict.","authors":[],"date":null,"doi":null,"raw":null,"cites":null},{"id":188074,"title":"A mapping system for the integration of owl-dl ontologies.","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":188076,"title":"A policy language for a pervasive computing environment.","authors":[],"date":"2003","doi":null,"raw":null,"cites":null},{"id":427028,"title":"Agent-based virtual organisations for the grid.","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":427026,"title":"Conflicts in policy-based distributed systems management.","authors":[],"date":"1999","doi":null,"raw":null,"cites":null},{"id":188072,"title":"Constraint rulebased programming of norms for electronic institutions. Autonomous Agents and MultiAgent Systems,","authors":[],"date":"2009","doi":null,"raw":null,"cites":null},{"id":188070,"title":"Modelling social action for AI agents.","authors":[],"date":null,"doi":null,"raw":null,"cites":null},{"id":427025,"title":"Norm adoption and consistency in the NoA agent architecture.","authors":[],"date":"2004","doi":null,"raw":null,"cites":null},{"id":427058,"title":"Normative conflicts in legal reasoning.","authors":[],"date":"1992","doi":"10.1007\/BF00114921","raw":null,"cites":null},{"id":188071,"title":"On the formal analysis of normative conflicts.","authors":[],"date":"2000","doi":null,"raw":null,"cites":null},{"id":188073,"title":"OWL 2 web ontology language: Document overview,","authors":[],"date":"2009","doi":null,"raw":null,"cites":null},{"id":427059,"title":"Pellet: A practical OWL-DL reasoner.","authors":[],"date":"2007","doi":"10.1016\/j.websem.2007.03.004","raw":null,"cites":null},{"id":188069,"title":"Reasoning about constitutive norms, counts-as conditionals, institutions, deadlines and violations.","authors":[],"date":"2008","doi":null,"raw":null,"cites":null},{"id":427027,"title":"Reasoning in Description Logics using Resolution and Deductive Databases.","authors":[],"date":"2006","doi":null,"raw":null,"cites":null},{"id":427029,"title":"SPARQL Query Language for RDF.","authors":[],"date":"2006","doi":null,"raw":null,"cites":null},{"id":188068,"title":"Structured systems economics for security management.","authors":[],"date":"2010","doi":null,"raw":null,"cites":null},{"id":188067,"title":"The Description Logic Handbook: Theory, Implementation and Applications.","authors":[],"date":"2003","doi":null,"raw":null,"cites":null}],"documentType":{"type":1}},"contributors":["Patel-Schneider, Peter F","Pan, Yue","Hitzler, Pascal","Mika, Peter","Zhang, Lei","Pan, Jeff Z","Horrocks, Ian","Glimm, Birte","University of Aberdeen, Natural & Computing Sciences, Computing Science","University of Aberdeen, dot.rural Digital Economy Hub"],"datePublished":"2011-01-04","abstract":"The original publication is available at www.springerlink.comPostprin","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"Springer Berlin \/ Heidelberg","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:aura.abdn.ac.uk:2164\/1132<\/identifier><datestamp>\n                2018-01-02T00:54:51Z<\/datestamp><setSpec>\n                com_2164_320<\/setSpec><setSpec>\n                com_2164_319<\/setSpec><setSpec>\n                com_2164_318<\/setSpec><setSpec>\n                com_2164_673<\/setSpec><setSpec>\n                com_2164_370<\/setSpec><setSpec>\n                com_2164_331<\/setSpec><setSpec>\n                com_2164_705<\/setSpec><setSpec>\n                col_2164_321<\/setSpec><setSpec>\n                col_2164_674<\/setSpec><setSpec>\n                col_2164_706<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nOWL-POLAR : semantic policies for agent reasoning<\/dc:title><dc:creator>\nSensoy, Murat<\/dc:creator><dc:creator>\nNorman, Timothy J<\/dc:creator><dc:creator>\nVasconcelos, Wamberto Weber<\/dc:creator><dc:creator>\nSycara, Katia P<\/dc:creator><dc:contributor>\nPatel-Schneider, Peter F<\/dc:contributor><dc:contributor>\nPan, Yue<\/dc:contributor><dc:contributor>\nHitzler, Pascal<\/dc:contributor><dc:contributor>\nMika, Peter<\/dc:contributor><dc:contributor>\nZhang, Lei<\/dc:contributor><dc:contributor>\nPan, Jeff Z<\/dc:contributor><dc:contributor>\nHorrocks, Ian<\/dc:contributor><dc:contributor>\nGlimm, Birte<\/dc:contributor><dc:contributor>\nUniversity of Aberdeen, Natural & Computing Sciences, Computing Science<\/dc:contributor><dc:contributor>\nUniversity of Aberdeen, dot.rural Digital Economy Hub<\/dc:contributor><dc:subject>\nsemantic web<\/dc:subject><dc:subject>\nQA75 Electronic computers. Computer science<\/dc:subject><dc:subject>\nQA75<\/dc:subject><dc:description>\nThe original publication is available at www.springerlink.com<\/dc:description><dc:description>\nPostprint<\/dc:description><dc:date>\n2011-02-14T17:10:32Z<\/dc:date><dc:date>\n2011-02-14T17:10:32Z<\/dc:date><dc:date>\n2011-01-04<\/dc:date><dc:type>\nConference item<\/dc:type><dc:identifier>\nSensoy , M , Norman , T J , Vasconcelos , W W & Sycara , K P 2011 , OWL-POLAR : semantic policies for agent reasoning . in P F Patel-Schneider , Y Pan , P Hitzler , P Mika , L Zhang , J Z Pan , I Horrocks & B Glimm (eds) , The Semantic Web : 9th International Semantic Web Conference, ISWC 2010, Shanghai, China, November 7-11, 2010, Revised Selected Papers, Part I . Lecture notes in computer science , vol. 6496 , Springer Berlin \/ Heidelberg , Berlin , pp. 679-695 . DOI: 10.1007\/978-3-642-17746-0_43<\/dc:identifier><dc:identifier>\n978-3-642-17745-3<\/dc:identifier><dc:identifier>\n978-3-642-17746-0<\/dc:identifier><dc:identifier>\n0302-9743<\/dc:identifier><dc:identifier>\nPURE: 3657151<\/dc:identifier><dc:identifier>\nPURE UUID: 5d9607dd-d48d-4a6d-bdcc-89340940050e<\/dc:identifier><dc:identifier>\nBibtex: urn:9c159a4bb28bf4d67e529b9831ed40cf<\/dc:identifier><dc:identifier>\nBibtex: urn:9c159a4bb28bf4d67e529b9831ed40cf<\/dc:identifier><dc:identifier>\nScopus: 78650884335<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2164\/1132<\/dc:identifier><dc:identifier>\nhttp:\/\/dx.doi.org\/10.1007\/978-3-642-17746-0_43<\/dc:identifier><dc:language>\neng<\/dc:language><dc:relation>\nThe Semantic Web<\/dc:relation><dc:relation>\nLecture notes in computer science<\/dc:relation><dc:format>\n17<\/dc:format><dc:publisher>\nSpringer Berlin \/ Heidelberg<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["0302-9743","issn:0302-9743"]}],"language":{"code":"en","id":9,"name":"English"},"relations":["The Semantic Web","Lecture notes in computer science"],"year":2011,"topics":["semantic web","QA75 Electronic computers. Computer science","QA75"],"subject":["Conference item"],"fullText":"OWL-POLAR: Semantic Policies for Agent Reasoning \u0002\nMurat S\u00b8ensoy1, Timothy J. Norman1, Wamberto W. Vasconcelos1, and Katia Sycara1,2\n1 Department of Computing Science, University of Aberdeen, AB24 3UE, Aberdeen, UK\n{m.sensoy,t.j.norman,w.w.vasconcelos}@abdn.ac.uk\n2 Carnegie Mellon University, Robotics Institute, Pittsburgh, PA 15213, USA\nkatia@cs.cmu.edu\nAbstract. Policies are declarations of constraints on the behaviour of compo-\nnents within distributed systems, and are often used to capture norms within\nagent-based systems. A few machine-processable representations for policies have\nbeen proposed, but they tend to be either limited in the types of policies that can\nbe expressed or limited by the complexity of associated reasoning mechanisms. In\nthis paper, we argue for a language that sufficiently expresses the types of policies\nessential in practical systems, and which enables both policy-governed decision-\nmaking and policy analysis within the bounds of decidability. We then propose an\nOWL-based representation of policies that meets these criteria using and a rea-\nsoning mechanism that uses a novel combination of ontology consistency check-\ning and query answering. In this way, agent-based systems can be developed that\noperate flexibly and effectively in policy-constrainted environments.\n1 Introduction\nIn this paper, we present a novel and powerful OWL 2.0 [7] knowledge representa-\ntion and reasoning mechanism for policies: OWL-POLAR (an acronym for OWL-based\nPOlicy Language for Agent Reasoning). Policies (aka. norms) are system-level princi-\nples of ideal activity that are binding upon the components of that system. Depending on\nthe nature of the system itself, policies may serve to control, regulate or simply guide\nthe activities of components. In systems security, for instance, the aim is typically to\ncontrol behaviour such that the system complies with the policies [18]. In real socio-\ntechnical systems, however, there are important limits to this and the aim is to develop\neffective sets of policies along with incentives to regulate behaviour [2]. In systems of\nautonomous agents, the term norm is most prevalent, but the concept and issues remain\nthe same [4]; for example, norms are used to regulate the behaviour of agents repre-\nsenting disparate interests in electronic institutions [6]. The objective of this research is\nto capture the essential requirements of policy representation and reasoning. In meeting\nthis objective three key requirements must be met:\n\u0002 This research was sponsored by the U.S. Army Research Laboratory and the U.K. Ministry of Defence and was accom-\nplished under Agreement Number W911NF-06-3-0001. The views and conclusions contained in this document are those\nof the author(s) and should not be interpreted as representing the official policies, either expressed or implied, of the\nU.S. Army Research Laboratory, the U.S. Government, the U.K. Ministry of Defence or the U.K. Government. The U.S.\nand U.K. Governments are authorized to reproduce and distribute reprints for Government purposes notwithstanding any\ncopyright notation hereon.\n1. System\/institutional policies must be machine understandable and underpinned by\na clear interpretation.\n2. The representation must be sufficiently expressive to capture the notion of a policy\nacross domains.\n3. Policies must be able to be effectively shared\/interpreted at run-time.\nThe choice of OWL 2.0 as an underlying language addresses the first requirement,\nbut in meeting the second two, we must clearly outline what is required of a policy\nlanguage and what reasoning should be supported by it. The desiderata of a model of\npolicies that motivates the language OWL-POLAR are as follows:\n\u2013 Representational adequacy. Policies (or norms) must capture the distinction be-\ntween activities that are required (obliged), restricted (prohibited) and, in some\nway, authorised but not necessarily expected (permitted) by some representational\nentity within the environment. It is essential to capture the authority from which\nthe policy\/norm comes, the subject (agent) to whom it applies, the object (activity)\nto which the policy\/norm refers, and the circumstances within which it applies.\n\u2013 Supporting decisions. Any reasoning mechanism that is driven\/guided by policies\nmust support both the determination of what policies\/norms apply in a given situa-\ntion, and what activities are warranted by the normative state of the agent if it were\nto comply with these policies.\n\u2013 Supporting analysis. Any reasoning mechanism that is driven\/guided by norma-\ntive\/policy constraints must support the assessment of policies in terms of: (i) whether\na policy\/norm is meaningful and (ii) whether norms conflict, and in what circum-\nstances they do conflict.\nWith the introduction of data ranges within the OWL 2.0 specification [7], we be-\nlieve that this desiderata of a model of policies can be met within the confines of OWL-\nDL. If this claim can be shown to be valid (as we aim to do within this paper), we believe\nthat OWL-POLAR provides, for the first time, a sufficiently expressive policy language\nfor which the key reasoning mechanisms required of such a language are decidable.\nThe paper is organised as follows: in Section 2 we formally specify the OWL-\nPOLAR language within OWL-DL; in Section 3 we describe how a set of active policies\nmay be computed, and how decisions about what activities are warranted by some set\nof policies may be made; then in Section 4 we present in detail the reasoning mecha-\nnisms that support the analysis of policies. OWL-POLAR is then compared to existing\nlanguages for policies in Section 5, and we present our conclusions in Section 6.\n2 Semantic Representation of Policies\nThe proposed language for semantic representation of policies is based on OWL-DL [7].\nAn OWL-DL ontology o = (TBoxo, ABoxo) consists of a set of axioms defining the\nclasses and relations (TBoxo) as well as a set of assertional axioms about the individu-\nals in the domain (ABoxo). Concept axioms have the form C \u0002 D where C and D are\nconcept descriptions, and relation axioms are expressions of the form R \u0002 S, where\nR and S are relation descriptions. The ABox contains concept assertions of the form\nC(a) where C is a concept and a is an individual name, and relation assertions of the\nform R(a, b), where R is a relation and a and b are individual names.\nConjunctive semantic formulas are used to express policies. A conjunctive semantic\nformula F o\u0002v =\n\u2227n\ni=0 \u03c6i over an ontology o is a conjunction of atomic assertions \u03c6 i,\nwhere \u0003v = \u3008?x0, . . . , ?xn\u3009 represents a vector of variables used in these assertions.\nFor the sake of convenience, we assume\n\u2227n\ni=0 \u03c6i \u2261 {\u03c61, . . . \u03c6n} in order to consider a\nconjunctive formula as a set of atomic assertions. Based on this, F o\u0002v can be considered\nas T o\u0002v \u222a Ro\u0002v \u222a Co\u0002v , where T o\u0002v is a set of type assertions using the concepts from o, e.g.,\n{student(?xi), nurse(?xj)}; Ro\u0002v is set of of relation assertions using the relations from\no, e.g., {marriedTo(?xi, ?xj)}; Co\u0002v is a set of constraint assertions on variables. Each\nconstraint assertion is of the form ?xi \u0004 \u03b2, where \u03b2 is a constant and \u0004 is any of the\nsymbols {>,<,=, \u0007=,\u2265,\u2264}. A constant is either a data literal (e.g, a numerical value)\nor an individual defined in o.\nVariables are divided into two categories; data-type and object variables. A data-\ntype variable refers to data values (e.g., integers) and can be used only once in R o\u0002v . On\nthe other hand, an object variable refers to individuals (e.g., University of Aberdeen)\nand can be used freely many times in Ro\u0002v. Equivalence and distinction between the val-\nues of object variables can be defined using OWL properties sameAs and differentFrom\nrespectively, e.g., owl:sameAs(?x,?y). In the rest of the paper, we use the symbols \u03b1, \u03c1,\n\u03d5, and e as a short hand for semantic formulas.\nGiven an ontology o, a conditional policy is defined as \u03b1 \u2212\u2192 N\u03c7:\u03c1 (a : \u03d5) \/e, where\n1. \u03b1, a conjunctive semantic formula, is the activation condition of the policy.\n2. N \u2208 {O,P, F} indicates if the policy is an obligation, permission or prohibition.\n3. \u03c7 is the policy addressee and \u03c1 describes \u03c7 using only the role concepts from the\nontology (e.g., ?x : student(?x)\u2227female(?x), where student and female are defined\nas sub-concepts of the role concept in the ontology). That is, \u03c1 is of the form\u2227n\ni=0 ri(\u03c7), where ri \u0002 role. Note that \u03c7 may directly refer to a specific individual\n(e.g., John) in the ontology or a variable.\n4. a : \u03d5 describes what is prohibited, permitted or obliged by the policy. Specifically,\na is a variable referring to the action to be regulated by the policy and \u03d5 describes a\nas an action instance using the concepts and properties from the ontology (e.g., ?a :\nSendF ileAction(?a) \u2227 hasReceiver(?a,John) \u2227 hasF ile(?a, T echReport218.pdf),\nwhere SendFileAction is an action concept). Each action concept has only a number\nof functional relations (aka. functional properties) [7] and these relations are used\nwhile describing an instance of that action.\n5. e defines the expiration condition.\nTable 1 illustrates how a conditional policy can be represented using the proposed\napproach. The policy in the table states that a person is obliged to leave a location when\nthere is a fire risk.\nTable 1. A person has to leave a location when there is a fire risk.\n\u03b1 P lace(?b) \u2227 hasF ireRisk(?b, true) \u2227 in(?x, ?b)\nN O\n\u03c7 : \u03c1 ?x : Person(?x)\na : \u03d5 ?a : LeavingAction(?a) \u2227 about(?a, ?b) \u2227 hasActor(?a, ?x)\ne hasF ireRisk(?b, false)\nGiven a semantic representation for the state of the world, policies are used to reason\nabout actions that are permitted, obliged or prohibited. Let \u0394 o be a semantic represen-\ntation for a state of the world based on an ontology o. Each state of the world is partially\nobservable; hence \u0394o is a partial representation of the world. \u0394o itself is represented as\nan ontology composed of (TBoxo, ABox\u0394) whereABox\u0394 is an extension of ABoxo.\n3 Reasoning with Policies\nWhen its activation conditions are satisfied, a conditional policy leads to an activated\npolicy. Definition 1 summarizes how a conditional policy is activated using ontological\nreasoning over a state of the world. Here we use query answering to determine acti-\nvated policies and reason about actions. The query answering mechanism we use in this\nwork is DL-safe; i.e. variables are bound only to the named individuals, to guarantee\ndecidability [8]. In this section, we address some of the key issues in supporting deci-\nsions governed by policies: activation and expiration, and reasoning about interactions\nbetween policies and actions.\nDefinition 1 Let \u0394o be a state of the world represented based on a domain ontology o.\nIf there is a substitution \u03c3 such that \u0394o \f (\u03b1 \u2227 \u03c1) \u00b7 \u03c3, but there is no substitution \u03c3 \u2032\nsuch that \u0394o \f (e \u00b7 \u03c3) \u00b7 \u03c3\u2032, then the policy (N\u03c7 (a : \u03d5)) \u00b7 \u03c3 becomes active. This policy\nexpires when there exists a substitution \u03c3 \u2032 such that \u0394o \f (e \u00b7 \u03c3) \u00b7 \u03c3\u2032.\nPerson\nPatient Doctor\nBuildingRoom\nJohnJane CentralHospital\nRoom245\ntype type type\ntype\nin\nin\ninChargeOf\nhasFireRisk\nin\nTBOX\nABOX\nHospital\nisA\nisA isA\nisA\nPlace\nisA\nin\nin\nHospitalRoom\nisA\nin\nAction\nisA\nhasActor\nLeavingAction\ntrue\nhasPatient\nhasFireRisk\nxsd:boolean\nCurrentTime\nt\ntype\nhasValue\n13:00:00\nhasValue\nxsd:time\nxsd:boolean\nhasAge\nxsd:int\ninChargeOf\nmarriedTo\nFig. 1. A partial state of the world represented based on a domain ontology.\n3.1 Policy Activation\nA policy is activated for a specific agent when the world state is such that the activation\ncondition holds for that agent and the expiration condition does not hold, and expires\nwhen this latter condition holds. The above definition is rather standard [11], but we\nnow describe how this is implemented efficiently through query answering. A conjunc-\ntive semantic formula can be trivially converted to a SPARQL query [15] and can be\nevaluated by OWL-DL reasoners with SPARQL-DL [17] support such as Pellet [17] to\nfind a substitution for its variables satisfying a specific state of the world. Therefore,\nwe can test \u0394o \f (\u03b1 \u2227 \u03c1) \u00b7 \u03c3 by writing a query for (\u03b1 \u2227 \u03c1) and testing whether it is\nentailed by \u0394o or not. Consider the conditional policy in Table 1 and assume that we\nhave the partially represented state of the world in Figure 1. We can write the semantic\nquery in Figure 2 to find \u03c3 for the conditional policy. When we query the state of the\nworld using SPARQL, each result in the result set provides a substitution \u03c3; in our case,\nwe have two \u03c3 values: {?x\/John, ?b\/Room245} and {?x\/Jane, ?b\/Room245}, representing\nthat there is a fire risk in the room 245 of the Central Hospital and that John and Jane\nare in that room.\nQuery:\nq(?x, ?b):-\nPlace(?b) \u2227\nhasFireRisk(?b, true) \u2227\nPerson(?x) \u2227\nin(?x,?b).\nSPARQL SYNTAX:\nPREFIX example: <http:\/\/www.example.com\/ns#>\nPREFIX rdf: <http:\/\/www.w3.org\/...rdf-syntax-ns#>\nPREFIX xsd: <http:\/\/www.w3.org\/2001\/XMLSchema#>\nSELECT ?x ?b\nWHERE {\n?b rdf:type example:Place.\n?b example:hasFireRisk \"true\"\u02c6\u02c6xsd:boolean.\n?x rdf:type example:Person.\n?x example:in ?b.\n}\nFig. 2. Query for the activation of a policy.\nNow, using the computed \u03c3 values, we should try to find a \u03c3 \u2032 such that \u0394o \f\n(e \u00b7 \u03c3) \u00b7 \u03c3\u2032. In our case, for this purpose, we can use the semantic query \u201cq():- has-\nFireRisk(Room245, false)\u201d. When the SPARQL representation of this query is executed\nover the state of the world shown in Figure 1, it returns false; that is the RDF graph\npattern represented by the query could not be found in the ontology. This means that\nthe policy in Table 1 should be activated using the variable bindings in \u03c3. The result is\nactivations of OJohn(?a : LeavingAction(?a) \u2227 about(?a,Room245)) and OJane(?a : Leav-\ningAction(?a) \u2227 about(?a,Room245)). These policies mean that John and Jane are obliged\nto leave the room 245; the obligation expires when the fire risk is removed.\n3.2 Reasoning about Actions\nLet us assume that a specific action a\u2032 : \u03d5\u2032 will be performed by x, where a \u2032 is a URI\nreferring to the action instance and \u03d5 \u2032 is a conjunctive semantic formula describing a \u2032\nwithout using any variables. Let \u0394o be the current state of the world. We can test if the\naction a\u2032 is permitted, forbidden or prohibited in \u0394o. For this purpose, based on \u0394o,\nwe create a \u201csandbox\u201d (hypothetical) state of the world \u0394 \u2032o to make what-if reason-\ning [21], i.e., \u0394\u2032o shows what happens if the action is performed. This is achieved by\nsimply adding the described action instance to \u0394o, i.e., \u0394\u2032o = \u0394o\u222a\u03d5\u2032. For example, the\nstate of the world in Figure 1 is extended using action instance LeaveAct 1: LeavingAc-\ntion(LeaveAct 1) \u2227 hasActor(LeaveAct 1,John) \u2227 about(LeaveAct 1,room245). The resulting\nstate of the world is shown in Figure 3.\nFor each active policy Nx(y : \u03d5y), we test the expiration conditions on \u0394 \u2032o as\nexplained before. If the policy\u2019s expiration conditions are satisfied, we can conclude\nthat the action a\u2032 : \u03d5\u2032 leads to the expiration of the policy. Otherwise, a semantic query\nQ of the form q(\u0003v\u03d5y ):- \u03d5y is created, where \u0003v\u03d5y is the vector of variables in \u03d5y . Then,\n\u0394\u2032o is queried with Q. Let the query return a result set rs; each result r \u2208 rs is a\nPerson\nPatient Doctor\nBuildingRoom\nJohn\nJane\nCentralHospital\nRoom245\ntype type\ntype\ntype\nin\nin\ninChargeOf\nhasFireRisk\nin\nTBOX\nABOX\nHospital\nisA\nisA isA\nisA\nPlace\nisA\nin\nin\nHospitalRoom\nisA\nin\nAction\nisA\nhasActor\nLeavingAction\ntrue\nhasPatient\nhasFireRisk\nxsd:boolean\nLeaveAct_1\ntype\nhasActor\nabout\nCurrentTime\nt\ntype\nhasValue\n13:00:00\nhasValue\nxsd:time\nxsd:boolean\nhasAge\nxsd:int\ninChargeOf\nmarriedTo\nFig. 3. The \u201csandbox\u201d (hypothetical) state of the world.\nsubstitution such that \u0394\u2032o \f \u03d5y \u00b7 r. If y \u00b7 r = a\u2032 for any such r, then a\u2032 is regulated by\nthe policy. In this case, we can interpret the policy based on its modality as follows:\n1. Nx = O: In this case, the policy represents an obligation; that is, x is obliged to\nperform a\u2032. Performing a\u2032 will remove this obligation.\n2. Nx = P : Performing a\u2032 is explicitly permitted.\n3. Nx = F : Performing a\u2032 is prohibited.\nAfter examining the active policies as described above, we can identify a number\nof possible normative positions with respect to the action instance a \u2032: (i) doing a\u2032 may\nbe explicitly permitted if there is a policy permitting it; (ii) doing a \u2032 may be obligatory\nif there exists a policy obliging it; (iii) doing a \u2032 may be prohibited if there is a policy\nprohibiting it; and (iv) there may be a conflict in the normative position with respect to\na\u2032 if it is either both prohibited and explicitly permitted, or both prohibited and obliged.\n4 Reasoning about Policies\nIn this section, we demonstrate reasoning techniques to support the analysis of policies\nin terms of their meaningfulness (Section 4.2) and possibility of conflict (Section 4.3),\nand hence address our third desideratum. Prior to this, however, we propose methods\nfor reasoning about semantic formulas to underpin our mechanisms for policy analysis.\n4.1 Reasoning about Semantic Formulas\nHere, we introduce methods for reasoning about semantic conjunctive formulas using\nquery freezing and constraint transformation.\nConjunctive Queries There is a relation between conjunctive formulas and conjunc-\ntive queries. A conjunctive semantic formula can trivially be converted into a conjunc-\ntive semantic query. For example, Ao\u0002v1 can be converted into the query qA():- A\no\n\u0002v1\n.\nTherefore, we can use query reasoning techniques to reason about semantic formulas.\nFor instance, in order to reason about the subsumption between semantic formulas, we\ncan use query subsumption (containment).\nIn conjunctive query literature, in order to test whether qA subsumes qB , the stan-\ndard technique of query freezing is used to reduce query containment problem to query\nanswering in Description Logics [13, 20]. For this purpose, we build a canonical ABox\n\u03a6qB from the query qB():- Bo\u0002v2 in three steps. First, for each variable in \u0003v2, we put a\nfresh individual into \u03a6qB using the type assertions about the variable. Note that this\nindividual should not exist in o. Second, we add each individual appearing in qB into\n\u03a6qB . This is done using the information about the individual from theABox o (e.g., type\nassertions). Third, relationships between individuals and constants defined in qB are in-\nserted into \u03a6qB . As a result of this process, \u03a6qB contains a pattern that exists only in\nontologies that satisfy qB . We combine \u03a6qB and our TBoxo to create a new canonical\nontology, o\u2032 = (TBoxo, \u03a6qB ). Example 1 demonstrates a simple case. Based on [20,\n13], we conclude that o \f qB \u0002 qA if and only if o\u2032 entails qA. In order to test whether\no\u2032 entails qA or not, we query o\u2032. That is, o\u2032 entails qA if there exists at least one match\nfor qA in o\u2032. This can easily be achieved by converting qA to SPARQL syntax and use\nPellet\u2019s SPARQL-DL query engine to answer qA on o\u2032 [17].\nExample 1 Let query qA be q():- Person(?p) \u2227 marriedTo(?p,?x) \u2227 Patient(?x) and query qB\nbe q():- Doctor(?x) \u2227 marriedTo(?x,Jane) \u2227 hasChild(?x,?c). Then, \u03a6qB contains an individual\nx, which is created for the variable ?x. The individual x is defined as of type Doctor. In \u03a6qB ,\nwe also have another individual Jane, which is defined in the original ABoxo as an instance of\nthe Patient class; we get all of its type assertions from the ABoxo. Then, we insert the object\nproperty marriedTo between the individuals x and Jane. Lastly, we create another individual c\nfor the variable ?c in \u03a6qB and insert the hasChild object property between x and c. The resulting\nontology is shown in Figure 4.\nPerson\nPatient Doctor\nJane\ntype\nmarriedTo\nTBOX\nABOX\nisA\nisA\nAction\nisA\nhasActor\nLeavingAction\nhasAge\nxsd:int\nX\ntype\nmarriedTo\nC\ntype\nhasChild\nhasChild\nFig. 4. The ontology created for qB in Example 1.\nThe query freezing method described above enables us to create a canonical ABox\nfor a semantic conjunctive formula; this ABox represents a pattern which only exists in\nontologies satisfying the semantic formula. On the other hand, this method assumes that\nvariables in queries can be assigned fresh individuals in a canonical ABox. However,\nin OWL-DL, individuals can refer to objects, but not data values [19]. Therefore, the\nproposed query freezing method can be used to test for subsumption between q A and\nqB only if the variables in qA and qB refer to objects. A variable can refer to an object\nif it is used as the domain of an object or datatype property (e.g., hasAge(?x,10)) or if\nit is used as the range of an object property (e.g., marriedTo(Jack,?x)). Unfortunately, in\nmany real-life settings, queries may have variables referring to data values with various\nconstraints, which we refer to here as datatype variables. In these settings, the query\nfreezing described above cannot be used to test subsumption. Example 2 illustrates a\nsimple scenario.\n<owl:Class rdf:about=\"#AgeConst1\">\n<rdfs:subClassOf>\n<owl:Restriction>\n<owl:onProperty rdf:resource=\"#hasAge\"\/>\n<owl:allValuesFrom>\n<rdfs:Datatype>\n<owl:onDataRange rdf:resource=\"&xsd;nonNegativeInteger\"\/>\n<xsd:minInclusive rdf:datatype=\"&xsd;int\">10<\/xsd:minInclusive>\n<xsd:maxExclusive rdf:datatype=\"&xsd;int\">20<\/xsd:maxExclusive>\n<\/rdfs:Datatype>\n<\/owl:allValuesFrom>\n<\/owl:Restriction>\n<\/rdfs:subClassOf>\n<\/owl:Class>\nFig. 5. A concept named AgeConst1 is created for hasAge(?c, ?a) \u2227 ?a \u2265 10 \u2227 ?a \u2264 20.\nExample 2 Let query qA be q():- Person(?p) \u2227 hasChild(?p,?c) \u2227 hasAge(?c,?y) \u2227 ?y \u2265 12 \u2227 ?y\n\u2264 16 and query qB be q():- Doctor(?x) \u2227marriedTo(?x,Jane) \u2227 hasChild(?x,?c) \u2227 hasAge(?c,?a)\n\u2227 ?a \u2265 10 \u2227 ?a \u2264 20. In this example, the query freezing method cannot be used directly to test\nsubsumption between qA and qB , because the variables ?y and ?a refer to data values, which\ncannot be represented by individuals in an OWL-DL ontology.\nConstraint Transformation Here, we propose constraint transformation. It is a pre-\nprocessing step which enables us to create a canonical ABox for semantic formulas\nwith datatype variables. Note that a datatype variable is used in a semantic formula to\nconstrain one datatype property, e.g., ?y is used to constrain the hasAge datatype prop-\nerty in qA of Example 2. Constraint transformation in contrast uses data-ranges intro-\nduced in OWL 2.0 [7] to transform each constrained datatype property to a named OWL\nclass. As a result, datatype variables and related datatype properties and constraints are\nreplaced with type assertions. This procedure is detailed in Algorithm 1.\nThe algorithm takes a conjunctive semantic formulaF o\u0002v and the ontology o as inputs\n(line 1). F o\u0002v is of the form T o\u0002v \u222aRo\u0002v\u222aCo\u0002v , where T o\u0002v , Ro\u0002v , and Co\u0002v are sets of type, relation\nand constraint assertions respectively. The outputs of the algorithm are the transformed\nsemantic formula F \u03c6\u0002u (containing no datatype variables) and the updated ontology \u03c6\n(line 2). Initially, F \u03c6\u0002u is set as equal to T o\u0002v and \u03c6 is the same as o (line 3). For each\nrelation assertion r(a, b) in Ro\u0002v , we do the following (line 4). First, we check if b is a\ndatatype variable (line 5). If so, this means that r is a datatype property with a variable\nin its range. In this case, we extract the set of constraints related to b from C o\u0002v , which is\nreferred by \u03b3d (line 6). Based on r and \u03b3d, we create a concept c in TBox\u03c6 using the\ncreateConcept function (line 7). This function works as follows:\n1. If \u03b3d \u0007= \u2205, then b implies some restrictions on the range of r. In this case, c should\nrefer to objects that have the property r with the restrictions defined in \u03b3 d on\nits range. While creating c in TBox\u03c6, we use data-ranges3 introduced in OWL\n2.0 to restrict the range of r accordingly. For example, if r(a, b) corresponds to\nhasAge(?c, ?a) and \u03b3d = {?a \u2265 10, ?a \u2264 20}, then a concept named AgeConst1\n3 http:\/\/www.w3.org\/TR\/2008\/WD-owl2-syntax-20081008\/#Data Ranges\nAlgorithm 1 Constraint transformation.\n1: Inputs: Formula F o\u0003v \u2261 T o\u0003v \u222aRo\u0003v \u222a Co\u0003v ,\nOntology o \u2261 (ABoxo, TBoxo)\n2: Outputs: Formula F \u03c6\u0003u ,\nOntology \u03c6 \u2261 (ABoxo, TBox\u03c6)\n3: Initialization: F \u03c6\u0003u = T\no\n\u0003v , TBox\u03c6 = TBoxo\n4: for all (r(a, b) \u2208 Ro\u0003v) do\n5: if (isDatatypeV ariable(b)) then\n6: \u03b3d = getConstraints(b,Co\u0003v)\n7: c = createConcept(r, \u03b3d, TBox\u03c6)\n8: \u03c4 = createTypeAssertion(a,c)\n9: F\u03c6\u0003u = F\n\u03c6\n\u0003u \u222a \u03c4\n10: else\n11: F\u03c6\u0003u = F\n\u03c6\n\u0003u \u222a r(a, b)\n12: \u03b3b = getConstraints(b,Co\u0003v)\n13: if (\u03b3b \b= \u2205 & \u00ac(\u03b3b \u2282 F\u03c6\u0003u )) then\n14: F\u03c6\u0003u = F\n\u03c6\n\u0003u \u222a \u03b3b\n15: end if\n16: end if\n17: end for\ncan be described as shown in Figure 5. For more sophisticated constraints, we\ncreate more complex class expressions using the OWL constructors owl:unionOf,\nowl:intersectionOf, and owl:complementOf.\n2. If \u03b3d = \u2205, then b has no constraints, which means that the data-range of b is\nequivalent to the range of its data-type (i.e., for xsd:int, the range is min inclusive\n\u22122147483648 and max inclusive 2147483647).\nAfter creating the concept c in TBox\u03c6, we create a type assertion \u03c4 to declare a as an\ninstance of c (e.g., AgeConst1(?c)) (line 8). This type assertion is added to F \u03c6\u0002u in order to\nsubstitute r(a, b) and \u03b3d in F o\u0002v (line 9). On the other hand, if b is not a datatype variable\n(line 10), there are two possibilities: (1) r is a datatype property but b is not a variable,\nor (2) r is an object property. In both cases, we directly add r(a, b) to F \u03c6\u0002u (line 11). If b\nhas constraints defined in Co\u0002v , we extract these constraints and add them to F\n\u03c6\n\u0002u if they\nare not already added (lines 12-15).\nIn order to test subsumption between qA and qB in Example 2, we should transform\nthe bodies of these queries and update the ontology they are based on. For this purpose,\nwe use constraint transformation twice. That is, we first update the ontology by adding\nthe concept AgeConst1 to handle hasAge(?c,?y) \u2227 ?y \u2265 10 \u2227 ?y \u2264 20 and transform qB\nto q():- Doctor(?x) \u2227 marriedTo(?x,Jane) \u2227 hasChild(?x,?c) \u2227 AgeConst1(?c). Then, we add\nconcept AgeConst2 to the ontology to handle hasAge(?c,?y) \u2227 ?y \u2265 12 \u2227 ?y \u2264 16 and\ntransform qA to q():- Person(?p) \u2227 hasChild(?p,?c) \u2227 AgeConst2(?c). After this preprocess-\ning step, we use query freezing to test qB \u0002 qA; the ontology with a canonical ABox\ncreated during query freezing is shown in Figure 6.\nWith these techniques in place, we are now in a position to address the issue of\npolicy analysis supported by OWL-POLAR. It is descried in the following sections.\nPerson\nPatient Doctor\nJane\ntype\nmarriedTo\nTBOX\nABOX\nisA isA\nAction\nisA\nhasActor\nLeavingAction\nhasAge\nxsd:int\nX\ntype\nmarriedTo\nC\ntype\nhasChild\nAgeConst1\nhasChild\ntype\nAgeConst2\nFig. 6. The Ontology created for qB in Example 2.\n4.2 Idle Policies\nA policy is idle if it is never activated or the policy\u2019s expiration condition is satisfied\nwhenever the policy is activated. This condition is formally described in Definition 2. If\na policy is idle, it cannot be used to regulate any action, because either it never activates\nor whenever it activates an obligation, permission, or prohibition about an action, the\nactivated policy expires. While designing policies, we may take domain knowledge into\naccount to avoid idle policies.\nDefinition 2 A policy \u03b1 \u2212\u2192 N\u03c7:\u03c1 (a : \u03d5) \/e is an idle policy if it does not activate\nfor any state of the world \u0394o or there is a substitution \u03c3\u2032 such that \u0394o \f (e \u00b7 \u03c3) \u00b7 \u03c3\u2032,\nwhenever there is a substitution \u03c3 such that \u0394o \f (\u03b1 \u2227 \u03c1) \u00b7 \u03c3.\nLet us demonstrate idle policies with a simple example. Assume that object prop-\nerty hasParent is an inverse property of hasChild. Also, let us assume in the domain\nontology, we have a SWRL rule such as hasSponsor(?c, true) \u2190 hasParent(?c, ?p) \u2227\nhasAge(?c, ?age) \u2227 ?age < 18, which means that children under 18 have a sponsor if\nthey have a parent. Now, consider the policy in Table 2. This policy is activated when a\nperson ?p has a child ?c, which is a student under 18. The activated policy expires when\n?c has a sponsor. Interestingly, whenever the policy is activated, the domain knowledge\nimplies that ?c has a sponsor. That is, whenever the policy is activated, it expires.\nTable 2. A simple idle policy example.\n\u03b1 hasChild(?p, ?c) \u2227 Student(?c)\u2227 hasAge(?c, ?age)\u2227?age < 18\nN O\n\u03c7 : \u03c1 ?p : Person(?p)\na : \u03d5 ?a : PayTuitionsOfStudent(?a) \u2227 about(?a, ?c) \u2227 hasActor(?a, ?p)\ne hasSponsor(?c, true)\nIn order to detect idle policies, we reason about the activation and expiration condi-\ntions of policies. Specifically, a policy \u03b1 \u2212\u2192 N\u03c7:\u03c1 (a : \u03d5) \/e is an idle policy if (\u03b1 \u2227 \u03c1)\nis unrealistic or implies e using the knowledge in the domain ontology. More formally,\nwe can show that the policy is idle if we show (\u03b1 \u2227 \u03c1) never holds or (\u03b1 \u2227 \u03c1) \u2192 e. This\ncan be achieved as follows. First, we freeze (\u03b1 \u2227 \u03c1) and create a canonical ontology o \u2032.\nIf the resulting o\u2032 is not a consistent ontology, then we can conclude that the policy is\nan idle policy, because (\u03b1 \u2227 \u03c1) never holds. Let o \u2032 be consistent and \u03c3 be a substitution\ndenoting the mapping of variables in (\u03b1 \u2227 \u03c1) to the fresh individuals in o \u2032. If there exists\na substitution \u03c3\u2032 such that o\u2032 \f (e \u00b7 \u03c3) \u00b7 \u03c3\u2032, we conclude that (\u03b1 \u2227 \u03c1) \u2192 e. We can test\no\u2032 \f (e \u00b7 \u03c3) \u00b7 \u03c3\u2032 by querying o\u2032 with q() : \u2212 (e \u00b7 \u03c3).\n4.3 Anticipating Conflicts between Policies\nIn many settings, policies may conflict. In the simplest case, one policy may prohibit\nan action while another requires it. There are, however, many less obvious interactions\nbetween policies that may lead to logical conflicts [9, 16, 12, 5]. Further developing our\nearlier example, consider the policy presented in Table 3 that states that a doctor cannot\nleave a room with patients if he is in charge of the room. This policy conflicts with the\npolicy in Table 1 under some specific conditions. For example, in the scenario described\nFigure 1, room 245 of Central Hospital has a fire risk and Dr. John is in charge of the\nroom, in which there are some patients. In this setting, the policy in Table 1 obligates\nDr. John to leave the room while the policy in Table 3 prohibits this action until the\nroom has no patient.\nTable 3. A doctor cannot leave a room containing patients if he is in charge of the room.\n\u03b1 Room(?r) \u2227 hasPatient(?r, true) \u2227 inChargeOf(?d, ?r)\nN F\n\u03c7 : \u03c1 ?d : Doctor(?d)\na : \u03d5 ?x : LeavingAction(?x) \u2227 about(?x, ?r) \u2227 hasActor(?x, ?d)\ne hasPatient(?r, false)\nIf we can determine possible logical conflicts while designing policies, we can cre-\nate better policies that are less likely to raise conflicts at run time. Furthermore, we can\nuse various conflict resolution strategies such as setting a priority ordering between the\npolicies to solve conflicts [11, 21, 22], once we determine that two policies may conflict.\nIn this section, we propose techniques to anticipate possible conflicts between poli-\ncies at design time. Suppose we have two non-idle policiesP i = \u03b1i \u2212\u2192 A\u03c7i:\u03c1i\n(\nai : \u03d5i\n)\n\/ei\nand Pj = \u03b1j \u2212\u2192 B\u03c7j :\u03c1j\n(\naj : \u03d5j\n)\n\/ej . These policies are active for the same policy\naddressee in the same state of the world \u0394 if the following requirements are satisfied:\n(i) \u0394 \f (\u03b1i \u2227 \u03c1i) \u00b7 \u03c3i, but no \u03c3\u2032i such that \u0394 \f\n(\nei \u00b7 \u03c3i\n) \u00b7 \u03c3\u2032i\n(ii) \u0394 \f (\u03b1j \u2227 \u03c1j) \u00b7 \u03c3j , but no \u03c3\u2032j such that \u0394 \f\n(\nej \u00b7 \u03c3j\n) \u00b7 \u03c3\u2032j\n(iii) \u03c7i \u00b7 \u03c3i = \u03c7j \u00b7 \u03c3j\nThe policies Pi and Pj conflict if the following requirements are also satisfied:\n(iv) (\u03d5i \u00b7 \u03c3i) \u0002 (\u03d5j \u00b7 \u03c3j) or (\u03d5j \u00b7 \u03c3j) \u0002 (\u03d5i \u00b7 \u03c3i)\n(v) A conflicts with B. That is, A \u2208 {P,O} while B \u2208 {F} or vice versa.\nWe can use Algorithm 2 to test if it is possible to have such a state of the world\nwhere Pi conflicts with Pj . The first step of the algorithm is to test if A conflicts with\nB (line 2). If they are conflicting, we continue with testing the other requirements. We\ncreate a canonical state of the world \u0394 in which Pi is active by freezing\n(\n\u03b1i \u2227 \u03c1i)\nwith a substitution \u03c3i mapping the variables in\n(\n\u03b1i \u2227 \u03c1i) to the fresh individuals in \u0394.\nGiven that (\u03d5j \u00b7 \u03c3) \u0002 \u03d5j for any substitution \u03c3 mapping variables into individuals, the\nrequirement (iv) implies that (\u03d5i \u00b7 \u03c3i) \u0002 \u03d5j . We test this as follows. First, we create\na canonical ontology o\u2032 by freezing (\u03d5i \u00b7 \u03c3i) (line 4) and then query o\u2032 with \u03d5j (line\n5). Each answer to this query defines a substitution \u03c3k mapping variables in \u03d5j into the\nterms in (\u03d5i \u00b7 \u03c3i), so that (\u03d5i \u00b7 \u03c3i) \u0002 (\u03d5j \u00b7 \u03c3k). If \u03d5j does not have any variable but\nit repeats in o\u2032 as a pattern, the result set contains only one empty substitution. If the\nquery fails, the result set is an empty set (\u2205), which means that it is not possible to have\na \u03c3k such that (\u03d5i \u00b7\u03c3i) \u0002 (\u03d5j \u00b7\u03c3k). For each \u03c3k satisfying (\u03d5i \u00b7\u03c3i) \u0002 (\u03d5j \u00b7\u03c3k), we test\nAlgorithm 2 An algorithm to anticipate if Pi may conflict with Pj .\n1: Inputs: Policy Pi = \u03b1i \u2212\u2192 A\u03c7i:\u03c1i\n(\nai : \u03d5i\n)\n\/ei,\nPolicy Pj = \u03b1j \u2212\u2192 B\u03c7j :\u03c1j\n(\naj : \u03d5j\n)\n\/ej\n2: if ( (A \u2208 {O, P} and B \u2208 {F}) or (A \u2208 {F} and B \u2208 {O, P}) ) then\n3: \u3008\u0394,\u03c3i\u3009 = freeze(\u03b1i \u2227 \u03c1i)\n4: \u3008o\u2032, \u3009 = freeze(\u03d5i \u00b7 \u03c3i)\n5: rs = query(o\u2032, \u03d5j)\n6: for all (\u03c3k \u2208 rs) do\n7: \u3008\u0394,\u03c3j\u3009 = update(\u0394,\n(\n\u03b1j \u2227 \u03c1j\n)\n\u00b7 \u03c3k)\n8: if (isConsistent(\u0394)) then\n9: if (query(\u0394, ei \u00b7 \u03c3i) = \u2205 and query(\u0394,\n(\nej \u00b7 \u03c3k\n)\n\u00b7 \u03c3j) = \u2205) then\n10: return true\n11: end if\n12: end if\n13: end for\n14: end if\n15: return false\nthe other requirements as follows. First, we update\u0394 by freezing\n(\n\u03b1j \u2227 \u03c1j) \u00b7\u03c3k without\nremoving any individual from its existing ABox (line 7). Note that as a result of this\nprocess, \u03c3j is the substitution mapping the variables in\n(\n\u03b1j \u2227 \u03c1j) \u00b7 \u03c3k to the new fresh\nindividuals in the updated \u0394, so that \u03c7i \u00b7\u03c3i =\n(\n\u03c7j \u00b7 \u03c3k\n) \u00b7\u03c3j . We test the consistency of\nthe resulting state of the world \u0394 (line 8). If this is not consistent, we can conclude that\nit is not possible to have a state of the world satisfying the requirements. If the resulting\n\u0394 is consistent, we check the expiration conditions of the policies. If both are active in\nthe resulting state of the world (line 9), the algorithm returns true (line 10). If any of\nthese requirements do not hold, the algorithm returns false (line 15).\nAs described above, the algorithm transforms the problem of anticipating conflict\nbetween two policies into an ontology consistency checking problem. To check the con-\nsistency of the constructed canonical state of the world \u0394, we have used the Pellet [17]\nreasoner. This reasoner adopts the open world assumption and does not have Unique\nName Assumption (UNA). Hence, it searches for a model4 of \u0394, also considering the\npossible overlapping between the individuals (i.e., individuals referring the same ob-\nject). If there is no model of \u0394, it is not possible to have a state of the world satisfying\nthe requirements stated above. We should also note that, while anticipating the conflict,\nAlgorithm 2 tests only the case (\u03d5i \u00b7 \u03c3i) \u0002 (\u03d5j \u00b7 \u03c3j). However, we also need to test\n(\u03d5j \u00b7 \u03c3j) \u0002 (\u03d5i \u00b7 \u03c3i) to capture the possibility of conflict. Therefore, if the algorithm\nreturns false, we should swap the policies and run the algorithm again. If it returns true\n4 A model of an ontology o is an interpretation of o satisfying all of its axioms [1].\nwith the swapped policies, we can conclude that there is a state of the world where these\npolicies may conflict.\nTo demonstrate the algorithm, let us use the policies presented in Tables 1 and 3\nand refer to them as Pi and Pj respectively. In this example, Pj is a prohibition while\nPi is an obligation, so the algorithm proceeds as follows (line 2). We create a canonical\nstate of the world \u0394 by freezing Person(?x) \u2227 Place(?b) \u2227 hasF ireRisk(?b, true)\n\u2227 in(?x, ?b) with a substitution \u03c3i = {?x\/x, ?b\/b} (line 3). Now we create a canon-\nical ontology a\u2032 by freezing \u03d5i \u00b7 \u03c3i with substitution {?a\/a} (line 4). This ontology\nhas the following ABox assertions: LeavingAction(a), about(a, b), hasActor(a, x).\nWe query o\u2032 with LeavingAction(?x) \u2227 about(?x, ?r) \u2227 hasActor(?x, ?d) (line 5).\nThe result set is composed of only one substitution: \u03c3k = {?x\/a, ?r\/b, ?d\/x}. The\nnext step is to update \u0394 by freezing Doctor(x ) \u2227 Room(b) \u2227 hasPatient(b, true)\n\u2227 inChargeOf (x , b) without removing the current ABox of \u0394 (line 7). The result-\ning canonical state of the world is shown in Figure 7. Lastly, we check whether both\npolicies remain in effect by checking their expiration conditions (line 9). In this ex-\nample, we query \u0394 with hasF ireRisk(b, false) and hasPatient(b, false). Both of\nthese queries return \u2205, hence we conclude that there is a state of the world where these\npolicies conflict (line 10).\nPerson\nPatient Doctor\nBuildingRoom\nTBOX\nABOX\nHospital\nisA\nisA isA\nisA\nPlace\nisA\nin\nin\nHospitalRoom\nisA\nin\nAction\nisA\nhasActor\nLeavingAction\nhasPatient\nhasFireRisk\nxsd:boolean\nCurrentTime\nhasValue\nxsd:time\nxsd:boolean\nhasAge\nxsd:int\nx\ntype\nb\ntype\nin hasFireRisk\ntrue\nhasPatient\ninChargeOf\ninChargeOf\ntrue\nmarriedTo\nFig. 7. The canonical state of the world where the policies of Table 1 and Table 3 conflict.\n5 Related Work and Discussion\nThere have been several policy languages proposed that are built upon Semantic Web\ntechnologies. Rei [10] is a policy language based on OWL-Lite and Prolog. It allows\nlogic-like variables to be used while describing policies. This gives it the flexibility to\nspecify relations like role value maps that are not directly possible in OWL. The use\nof these variables, however, makes DL reasoning services (e.g., static conflict detection\nbetween policies) unavailable for Rei policies. KAoS [21] is, probably, the most devel-\noped language for describing policies that are built upon OWL. KAoS was originally\ndesigned to use OWL-DL to define actions and policies. This, however, restricts the ex-\npressive power to DL and prevents KAoS from defining policies in which one element\nof an action\u2019s context depends on the value of another part of the current context. For\nexample, KAoS cannot be used to represent a policy like two soldiers are allowed to\ncommunicate only if they are in the same team. To handle such situations, KAoS has\nbeen enhanced with role-value maps using Stanford JTP, a general purpose theorem\nprover [21]. Unfortunately, subsumption reasoning is undecidable in the presence of\narbitrary role-value-maps [1].\nKAoS distinguishes between (positive and negative) obligation policies and (pos-\nitive and negative) authorization policies. Authorization policies permit (positive) or\nforbid (negative) actions, whereas obligation policies require (positive) or do not re-\nquire (negative) action. Thus the general types of policies that can be described are\nsimilar to those that we have discussed in this paper. Actions are also the object of a\nKAoS policy, and conditions on the application of policies can be described (context),\nalthough the subject (individual\/role) of the policy is not explicit (it is, however, in Rei).\nIn common with OWL-POLAR in its present form, KAoS does not capture the notion\nof the authority from which\/whom a policy comes, but there is a notion of the priority\nof a policy which partially (although far from adequately) addresses this issue. Un-\nlike OWL-POLAR, Rei and KAoS do not provide means to explicitly define expiration\nconditions of the policies.\nPolicy analysis within both KAoS and Rei is restricted to subsumption. A policy in\nKAoS is expressed as an OWL-DL class regulating an action, which is expressed as an\nOWL-DL class expression (e.g., using restrictions on properties such as performedBy\nand hasDestination). Two policies are regarded in conflict if their actions overlap (one\nsubsumes another) while the modality of these policies conflict (e.g., negative vs. pos-\nitive authorization). Similarly, if there exist two policies within Rei that overlap with\nrespect to the agent and action concerned and they are obligued and prohibited, then\na conflict is recognised. In such a situation, meta-policies are used to resolve the con-\nflict. Policy conflicts can also be detected within the Ponder2 framework [18, 23], where\nanalysis is far more sophisticated than that developed for either KAoS or Rei, but anal-\nysis is restricted to design time. In general, different methods can be used to resolve\nconflicts between policies. This issue has been explored in detail elsewhere [11].\nThe expressiveness of OWL-POLAR is not restricted to DL. Using semantic con-\njunctive formulas, it allows variables to be used while defining policies. However, in\nsemantic formulas, OWL-POLAR allows only object-type variables to be compared\nusing owl:sameAs and owl:differentFrom properties. On the other hand, data-type vari-\nables can be used to define constraints on the datatype properties. In other words, se-\nmantic formulas are restricted to describe states of the world, each of which can be\nrepresented as an OWL-DL ontology. Therefore, when a semantic formula is frozen,\nthe result is a canonical OWL-DL ontology. OWL-POLAR converts problems of rea-\nsoning with and about policies into query answering and ontology consistency checking\nproblems. Then, it uses an off-the-shelf reasoner (Pellet) to solve these problems. It is\nknown that consistency checking in OWL-DL is decidable [17], and query answering\nin OWL-DL has also been shown to be decidable under DL-safety restrictions [8].\nOntology languages like KAoS are built on OWL 1.0, which does not support data-\nranges. Therefore, while defining policies, they either do not allow complex constraints\nto be defined on datatype properties or use non-standard representations for these con-\nstraints, which prevents them from using the off-the-shelf reasoning technologies. The\nclear distinctions between OWL-POLAR and KAoS, however, are manifest in the fact\nthat data ranges are exploited in OWL-POLAR to enable the expression of more com-\nplex constraints on policies, and the sophistication of the reasoning mechansims de-\nscribed in this paper.\nTo the best of our knowledge, OWL-POLAR is the first policy framework that for-\nmally defines and detects idle policies. Existing approaches like KAoS and Rei analyse\npolicies only to detect some type of conflict, considering only subsumption between\npolicies. On the other hand, OWL-POLAR provides advanced policy analysis support\nthat is not limited to subsumption checking. Consider the following policies: (i) Dogs\nare prohibited from entering to a restaurant, and (ii) A member of CSI team is permit-\nted to enter a crime scene. There is no subsumption relationship between these policies,\nand so KAoS and Rei could not detect a conflict. However, OWL-POLAR anticipates a\nconflict by composing a state of the world where these policies are in conflict, e.g., the\ncrime scene is a restaurant and there is a dog in the CSI team.\nBuilding upon this research, we plan to explore various extensions to OWL-POLAR.\nWe will explore extending the representation of policies to include deadlines and penal-\nties associated with their violation, along the lines of [3]. Another issue we would like\nto investigate concerns how policing mechanisms [14] could make use of our repre-\nsentation and associated mechanisms to foster welfare in societies of self-interested\ncomponents\/agents. We plan to enhance our representation so as to allow constraints\nover arbitrary terms (and not just ?x \u0004 \u03b2, \u03b2 being a constant), possibly using constraint\nsatisfaction mechanisms to deal with these. Two further extensions should address poli-\ncies over many actions (as in, for instance, \u201c\u03be is obliged to perform \u03d5 1 and \u03d52\u201d) and\ndisjunctions (as in, for instance, \u201c\u03be is obliged to perform \u03d51 or \u03d52\u201d). Finally, we are ex-\nploring the use of OWL-POLAR in support of human decision-making, including joint\nplanning activities in hybrid human-software agent teams.\n6 Conclusions\nPolicies provide useful abstractions to constrain and control the behaviour of compo-\nnents in loosely coupled distributed systems. Policies, also called norms, help designers\nof large-scale, open, and heterogenous distributed systems (including multi-agent sys-\ntems) to specify, in a concise fashion, acceptable (or policy-compliant) global and indi-\nvidual computational behaviours, thus providing guarantees for the system as a whole.\nIn this paper, we have presented a semantically-rich representation for policies as\nwell as efficient mechanisms to reason with\/about them. OWL-POLAR meets all the\nessential requirements of policies, as well as achieving an effective balance between ex-\npressiveness (realistic policies can be adequately represented) and computational com-\nplexity of associated reasoning for decision-making and analysis (reasoning with and\nabout policies operate in feasible time).\nReferences\n1. F. Baader, D. Calvanese, D. L. McGuinness, D. Nardi, and P. F. Patel-Schneider, editors.\nThe Description Logic Handbook: Theory, Implementation and Applications. Cambridge\nUniversity Press, 2003.\n2. A. Beautement and D. Pym. Structured systems economics for security management. In Pro-\nceedings of the Ninth Workshop on the Economics of Information Security, Harvard, USA,\nJune 2010.\n3. G. Boella, J. Broersen, and L. Torre. Reasoning about constitutive norms, counts-as condi-\ntionals, institutions, deadlines and violations. In PRIMA \u201908: Proceedings of the 11th Pa-\ncific Rim International Conference on Multi-Agents, pages 86\u201397, Berlin, Heidelberg, 2008.\nSpringer-Verlag.\n4. C. Castelfranchi. Modelling social action for AI agents. Artificial Intelligence, 103:157\u2013182,\n1998.\n5. A. Elhag, J. Breuker, and P. Brouwer. On the formal analysis of normative conflicts. Infor-\nmation & Communications Technology Law, 9(3):207\u2013217, 2000.\n6. A. Garc\u0131\u00b4a-Camino, J. A. Rodr\u0131\u00b4guez-Aguilar, C. Sierra, and W. Vasconcelos. Constraint rule-\nbased programming of norms for electronic institutions. Autonomous Agents and Multi-\nAgent Systems, 18(1):186\u2013217, 2009.\n7. W. O. W. Group. OWL 2 web ontology language: Document overview, October 2009.\nhttp:\/\/www.w3.org\/TR\/owl2-overview.\n8. P. Haase and B. Motik. A mapping system for the integration of owl-dl ontologies. In IHIS\n\u201905: Proceedings of the first international workshop on Interoperability of heterogeneous\ninformation systems, pages 9\u201316, New York, NY, USA, 2005. ACM.\n9. H. Hill. A functional taxonomy of normative conflict. Law and Philosophy, 6(2):227\u2013247,\n1987.\n10. L. Kagal, T. Finin, and A. Joshi. A policy language for a pervasive computing environ-\nment. In POLICY \u201903: Proceedings of the 4th IEEE International Workshop on Policies for\nDistributed Systems and Networks, pages 63\u201374, 2003.\n11. M. J. Kollingbaum and T. J. Norman. Norm adoption and consistency in the NoA agent\narchitecture. Lecture Notes in Artificial Intelligence, 3067:169\u2013186, 2004.\n12. E. Lupu and M. Sloman. Conflicts in policy-based distributed systems management. IEEE\nTransactions on software engineering, 25(6):852\u2013869, 1999.\n13. B. Motik. Reasoning in Description Logics using Resolution and Deductive Databases. PhD\nthesis, Universitt Karlsruhe (TH), Karlsruhe, Germany, January 2006.\n14. J. Patel et. al. Agent-based virtual organisations for the grid. Int. Journal of Multi-Agent and\nGrid Systems, 1(4):237\u2013249, 2005.\n15. E. Prud\u2019hommeaux and A. Seaborne. SPARQL Query Language for RDF. Technical report,\nW3C, 2006. http:\/\/www.w3.org\/TR\/rdf-sparql-query\/.\n16. G. Sartor. Normative conflicts in legal reasoning. Artificial Intelligence and Law, 1(2):209\u2013\n235, 1992.\n17. E. Sirin, B. Parsia, B. C. Grau, A. Kalyanpur, and Y. Katz. Pellet: A practical OWL-DL\nreasoner. Web Semant., 5(2):51\u201353, 2007.\n18. M. Sloman and E. Lupu. Policy specification for programmable networks. In IWAN \u201999:\nProceedings of the First International Working Conference on Active Networks, pages 73\u2013\n84, London, UK, 1999. Springer-Verlag.\n19. M. K. Smith, C. Welty, and D. L. McGuinness. OWL: Web ontology language guide, Febru-\nary 2004. http:\/\/www.w3.org\/TR\/owl-guide.\n20. J. D. Ullman. Information integration using logical views. Theoretical Computer Science,\n239(2):189\u2013210, 2000.\n21. A. Uszok, J. M. Bradshaw, J. Lott, M. Breedy, L. Bunch, P. Feltovich, M. Johnson, and\nH. Jung. New developments in ontology-based policy management: Increasing the practi-\ncality and comprehensiveness of KAoS. In POLICY \u201908: Proceedings of the 2008 IEEE\nWorkshop on Policies for Distributed Systems and Networks, pages 145\u2013152, 2008.\n22. W. W. Vasconcelos, M. J. Kollingbaum, and T. J. Norman. Normative conflict resolution in\nmulti-agent systems. Autonomous Agents and Multi-Agent Systems, 19(2):124\u2013152, 2009.\n23. H. Zhao, J. Lobo, and S. M. Bellovin. An algebra for integration and analysis of ponder2\npolicies. In POLICY \u201908: Proceedings of the 2008 IEEE Workshop on Policies for Distributed\nSystems and Networks, pages 74\u201377, Washington, DC, USA, 2008. IEEE Computer Society.\n"}
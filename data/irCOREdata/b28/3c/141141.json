{"doi":"10.1080\/13669870601011183","coreId":"141141","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/2925","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/2925","10.1080\/13669870601011183"],"title":"Benchmarking risk management within the international water utility sector. Part\nI: Design of a capability maturity methodology.","authors":["Macgillivray, Brian H.","Sharp, J. V.","Strutt, J. E.","Hamilton, Paul D.","Pollard, Simon J. T."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-01-31T00:00:00Z","abstract":"Risk management in the water utility sector is becoming increasingly explicit.\nHowever, due to the novelty and complexity of the discipline, utilities are\nencountering difficulties in defining and institutionalising their risk\nmanagement processes. In response, the authors have developed a sector specific\ncapability maturity methodology for benchmarking and improving risk management.\nThe research, conducted in consultation with water utility practitioners, has\ndistilled risk management into a coherent, process-based framework. We\nidentified eleven risk management processes, and eight key attributes with\ncharacterise the extent to which these processes are defined, controlled and\ninstitutionalised. Implementation of the model should enable utilities to more\neffectively employ their portfolio of risk analysis techniques for optimal,\ncredible and defensible decision making","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/141141.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/10.1080\/13669870601011183","pdfHashValue":"42e6be4da637e8933dc1ff3bb35761584a8cee16","publisher":"Taylor & Francis","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/2925<\/identifier><datestamp>2012-01-16T14:47:27Z<\/datestamp><setSpec>hdl_1826_24<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Benchmarking risk management within the international water utility sector. Part\nI: Design of a capability maturity methodology.<\/dc:title><dc:creator>Macgillivray, Brian H.<\/dc:creator><dc:creator>Sharp, J. V.<\/dc:creator><dc:creator>Strutt, J. E.<\/dc:creator><dc:creator>Hamilton, Paul D.<\/dc:creator><dc:creator>Pollard, Simon J. T.<\/dc:creator><dc:subject>Maturity model<\/dc:subject><dc:subject>risk<\/dc:subject><dc:subject>analysis<\/dc:subject><dc:subject>management<\/dc:subject><dc:subject>water<\/dc:subject><dc:subject>sector<\/dc:subject><dc:description>Risk management in the water utility sector is becoming increasingly explicit.\nHowever, due to the novelty and complexity of the discipline, utilities are\nencountering difficulties in defining and institutionalising their risk\nmanagement processes. In response, the authors have developed a sector specific\ncapability maturity methodology for benchmarking and improving risk management.\nThe research, conducted in consultation with water utility practitioners, has\ndistilled risk management into a coherent, process-based framework. We\nidentified eleven risk management processes, and eight key attributes with\ncharacterise the extent to which these processes are defined, controlled and\ninstitutionalised. Implementation of the model should enable utilities to more\neffectively employ their portfolio of risk analysis techniques for optimal,\ncredible and defensible decision making.<\/dc:description><dc:publisher>Taylor & Francis<\/dc:publisher><dc:date>2012-01-10T23:00:48Z<\/dc:date><dc:date>2012-01-10T23:00:48Z<\/dc:date><dc:date>2007-01-31T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>B. H. MacGillivray; J. V. Sharp; J. E. Strutt; P. D. Hamilton; S. J. T. Pollard,\nBenchmarking Risk Management Within the International Water Utility Sector. Part\nI: Design of a Capability Maturity Methodology. Journal of Risk Research, Volume\n10, Issue 1, January 2007, pages 85-104<\/dc:identifier><dc:identifier>1366-9877<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1080\/13669870601011183<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/2925<\/dc:identifier><dc:language>en_UK<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["1366-9877","issn:1366-9877"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2007,"topics":["Maturity model","risk","analysis","management","water","sector"],"subject":["Article"],"fullText":" 1\nBenchmarking risk management within the international water 1 \nutility sector.  Part I: design of a capability maturity 2 \nmethodology  3 \n 4 \nB.H. MacGillivray, J.V. Sharp, J.E. Strutt, P.D. Hamilton and S.J.T. Pollard* 5 \n 6 \nSchool of Water Sciences, Cranfield University, Cranfield, Bedfordshire, MK43 0AL, UK. 7 \n 8 \n* Corresponding author 9 \nEmail: s.pollard@cranfield.ac.uk 10 \nTelephone: +44 (0)1234 754101 11 \n 12 \n 13 \n 14 \n 15 \n 16 \n 17 \n 18 \n 19 \n 20 \n 2\nABSTRACT 1 \nRisk management in the water utility sector is becoming increasingly explicit.  However, 2 \ndue to the novelty and complexity of the discipline, utilities are encountering difficulties in 3 \ndefining and institutionalising their risk management processes.  In response, the authors 4 \nhave developed a sector specific capability maturity methodology for benchmarking and 5 \nimproving risk management.  The research, conducted in consultation with water utility 6 \npractitioners, has distilled risk management into a coherent, process-based framework.  We 7 \nidentified eleven risk management processes, and eight key attributes with characterise the 8 \nextent to which these processes are defined, controlled and institutionalised.  9 \nImplementation of the model should enable utilities to more effectively employ their 10 \nportfolio of risk analysis techniques for optimal, credible and defensible decision making. 11 \n 12 \nKEYWORDS: maturity model, risk, analysis, management, water, sector 13 \n 14 \n 15 \n 16 \n 17 \n 18 \n 19 \n 20 \n 21 \n 3\n1. Introduction 1 \nFinancial restrictions, regulatory pressures and sectoral restructuring are encouraging 2 \nwater utilities to move from technically inclined, risk-averse management approaches 3 \ntowards more commercial, business-oriented practices (MacGillivray et al., 2006a).  Many 4 \nwithin the industry, spurred on by developments in international regulation and guidance, 5 \nare promoting a business-wide approach to risk management as a means to ease and exploit 6 \nthis transition (e.g. Lifton and Smeaton, 2003; Miller, 2005; Lloyd and Abell, 2005).  7 \nWhilst the sector has made good progress towards setting its stated goal (AWWA et al., 8 \n2001) of providing wholesome, safe drinking water that has the trust of customers within a 9 \nrisk-based context (Pollard et al., 2004), there remain barriers to the implementation of risk 10 \nmanagement.  These can be categorised as business-related, the challenge of embedding 11 \nrisk management within organisational cultures and decision-making processes (e.g. 12 \nPollard et al., 2004; Howard and Lourens, 2005); and technical, relating to the selection and 13 \napplication of risk analysis tools (e.g. MacGillivray et al., 2006a).  Our research addresses 14 \nthe former; the premise being that the tools and techniques for risk analysis are sufficiently 15 \ndeveloped, yet lacking is the organisational capacity to employ these methodologies for 16 \nmore optimal, credible, and defensible decision-making. 17 \nThe authors propose that the dominant cause of this capacity deficiency is the 18 \ndifficulty inherent in establishing, defining and controlling risk management processes.  19 \nThis is perhaps because the sector\u2019s approach to implementation has centred on adherence 20 \nto risk management frameworks.  These are essentially standards describing the 21 \nfundamentals of the prior art and the interrelationships between its core elements (e.g. 22 \nHamilton et al., 2006).  Here, we are not concerned with frameworks for drinking water 23 \n 4\nquality management (e.g. NHMRC, 2001; WHO, 2002), widely accepted and applied 1 \nwithin the sector as a means of placing public health protection within a risk-based context, 2 \nbut with those corporate-level frameworks intended to foster an integrated approach to risk 3 \nmanagement (e.g. COSO, 2004; Canadian Standards Association, 1997; Council of 4 \nStandards of Australia, 1999).  These latter frameworks have been instrumental in 5 \ntransforming the discipline from the preserve of engineering and finance functions towards 6 \na business-wide paradigm.  However, a number of criticisms may be offered.  Critically, 7 \nalthough they typically embrace the concept that risk management is comprised of 8 \nprocesses, their treatment of the discipline focuses on organisational structures and 9 \nprocedures.  They often fail to address how the core tasks and activities of risk management 10 \nmay be defined and controlled as processes.  Furthermore, although they have evolved 11 \nbeyond prescribing static requirements towards embracing the concept of continuous 12 \nimprovement, too often this is addressed as an afterthought rather than as an explicit 13 \ncomponent of these frameworks.  As such, the water sector has lacked methodologies on 14 \nwhich to base risk management improvement initiatives, suggesting that enhancements may 15 \noften be isolated and that their associated benefits can neither be replicated nor extended 16 \nthroughout organisations.  Finally, whilst typically generic in nature, these frameworks are 17 \noften representative of the large, financially-oriented firms where their application 18 \npredominates. 19 \nTo address these shortcomings, the authors have developed a sector-specific risk 20 \nmanagement capability maturity model (RM-CMM), a vehicle for benchmarking, 21 \nimplementing and improving the processes that comprise risk management.  In this paper 22 \nwe review the field of capability maturity modelling.  We then describe the research 23 \n 5\nmethodology adopted in the design of our model, before discussing its development, 1 \nstructure and practical definition.  A companion manuscript (MacGillivray et al., 2006b) 2 \ndescribes the model\u2019s application in a benchmarking of eight utilities within the 3 \ninternational water sector. 4 \n 5 \n2. Risk management in the water sector 6 \nThe water industry is undergoing a significant shift in its approach to risk 7 \nmanagement to one that is increasingly explicit and better integrated with other business 8 \nprocesses.  Risk management strategies and techniques traditionally applied to occupational 9 \nhealth and safety and public health protection are now seeing broader application for asset 10 \nmanagement (Booth and Rogers, 2001; Lifton and Smeaton, 2003), watershed protection 11 \n(IMPRESS Management, 2002; NHMRC, 2001; WHO, 2003) and network operation (Stahl 12 \nand Elliott, 1999; Stevens and Lloyd, 2004).  Beyond this operational context, utility 13 \nmanagers are increasingly concerned with managing the risks inherent to corporate level 14 \ndecision making.  Critical issues include decisions on outsourcing asset maintenance; 15 \nbilling and monitoring; the management of change; staff retention; the long-term viability 16 \nof investment decisions; and the management of external interfaces with regulators and 17 \n\u201ccompeting\u201d utilities (MacGillivray et al., 2006a).  Pollard et al. (2004) report that the 18 \norganisational hierarchy that exists even within \u201cflat\u201d utilities requires that these risks are 19 \nactively managed at strategic, programme and operational levels (Fig. 1).  Typically, there 20 \nare split accountabilities for these risks such that the chief financial officer \/ financial 21 \ndirector and Board have overall responsibility, supported by an internal audit or control 22 \nfunction for the management of strategic risks; executive and senior management address 23 \n 6\nprogramme level risks (e.g. asset management, maintenance planning); and operational 1 \n(e.g. site) managers bear responsibility for operational risks (e.g. treatment plant 2 \nperformance).   3 \nWater utilities must employ a range of techniques to evaluate and consider these 4 \naspects alongside one another, devising business and operating strategies that prioritise 5 \nresources on the basis of risk.  Here tensions may arise from the explicit risk trade-offs 6 \ninherent to running a commercial water utility, such that the industry\u2019s overarching goal of 7 \npublic health protection is placed in conflict with narrower financial interests.  Critically in 8 \nthis regard, the transition to an explicit risk management philosophy within the sector is 9 \nreflected in recent revisions to the World Health Organisation\u2019s (WHO, 2003) Guidelines 10 \nfor Drinking Water Quality.  It is this overall context that drives the need for an increased 11 \ncapability to manage risk. 12 \n 13 \n3. Overview of capability maturity modelling 14 \nA capability maturity model (CMM) is a simplified representation of an 15 \norganisational discipline (e.g. software engineering, risk management) that distils industry 16 \npractices into a coherent, process-based framework.  These models are constructed 17 \naccording to maturity levels, from learner to best practice, which are characterised by the 18 \nextent to which the processes are defined, controlled and institutionalised.  The field\u2019s 19 \norigins can be traced to the \u201cquality revolution\u201d of the 1970s (e.g. Crosby, 1979) and to the 20 \nfield of management performance measurement.  The CMM methodology was first 21 \narticulated by the Software Engineering Institute (SEI), whose seminal model (Paulk et al., 22 \n1993) explored the design capability of software development organisations.  The 23 \n 7\ncapability maturity modelling concept is finding increasing acceptance in academia and 1 \nindustry.  Notable applications include software and systems engineering (Paulk et al., 2 \n1993; Software Engineering Institute, 2002a), workforce development and management 3 \n(Software Engineering Institute, 2002b), offshore design safety (Sharp et al., 2002), 4 \nreliability engineering (Strutt, 2003), and construction (Sarshar et al., 2000).    Capability 5 \nmodels enable organisations to establish their current level of process maturity and identify 6 \nthe steps necessary to progress to a higher level, building on their strengths and improving 7 \non their weaknesses.  They may be used for benchmarking purposes, enabling organisations 8 \nto compare themselves against other companies in their sector and beyond.  This may be 9 \ndone at the corporate, functional or business unit level.  Similarly, they may be used to 10 \nassess the capabilities of key suppliers and partners. 11 \nRecently, a selection of risk management capability maturity models (e.g. IACCM, 12 \n2003; RMRDP, 2002) have been developed.  We believe that these models insufficiently 13 \nreflect the basic principles of capability maturity modelling.  The most critical point is that 14 \nthey are not explicitly process-centred.  Furthermore, they do not closely reflect the clear 15 \ndistinctions between maturity levels as set out by the SEI and developed further by 16 \nsubsequent researchers, instead characterising risk management maturity on a graded scale 17 \nof good-to-bad practice.  Of course, the CMM approach is not the sole means for improving 18 \nrisk management, and these critiqued models have found support within industry.  Thus, we 19 \ndo not imply that the IACCM and RMRDP models are without value, indeed their 20 \nsimplicity and modest time demands may prove attractive to many organisations.  21 \nHowever, our development of the RM-CMM is not an extension of these models, but rather 22 \na novel application of capability maturity modelling to risk management in the water utility 23 \nsector.   24 \n 8\n 1 \n4. Rationale of research methodology 2 \nThe tailoring of existing maturity models to a new discipline and sector is not a 3 \nsimple mapping exercise (Sarshar et al., 2000).  Here, the core principles of maturity 4 \nmodelling were abstracted and recreated in a form specific to risk management within the 5 \nwater utility sector.  Design of the research methodology (Fig. 2) was informed by the 6 \nauthors\u2019 previous experience in maturity modelling within similar utility sectors and drew 7 \nupon the CMM literature, particularly Sarshar et al. (2000).  The methodology is designated 8 \n\u201ctesting-out research\u201d (Starke, 1995).  Here, the aim is to explore the limits of previously 9 \nproposed generalisations and to specify, modify or clarify their content (Starke, 1995).  10 \nThis form of research must be conducted under real world conditions, where the kind of 11 \ncontrol present in laboratory conditions is neither feasible nor justifiable.  The lead author, 12 \nin concert with a steering group of four expert practitioners, designed the model in 13 \ncollaboration with partner water utilities.  Key development inputs included literature 14 \nreviews of risk management and capability maturity modelling, structured scoping 15 \ninterviews with eleven water utility professionals from five countries, prior knowledge of 16 \nmaturity modelling in similar utility sectors, and past experience within the water sector. 17 \nGiven the qualitative nature of the research, verification and validation mechanisms 18 \nwere adopted.  The purpose of the expert steering group was to verify that the model 19 \naccurately codified risk management in line with the principles of maturity modelling.  20 \nFurthermore, feedback was sought from three water utilities to ensure that the model 21 \nreflected the practical realities of managing risk in the sector.  This took the form of one 22 \nworkshop and two interviews conducted after sharing the pilot model.  This piloting sought 23 \n 9\nto validate the model\u2019s architecture (e.g. are the right processes included, are they 1 \nadequately characterised, are the key attributes relevant, etc.) and to clarify its terminology.  2 \nThe model remains under research.  The authors have recently tested the model through a 3 \nbenchmarking exercise and two industrial case studies.  These applications will provide 4 \ndata of intrinsic value to both the industrial and academic communities, and will serve as a 5 \nmeans for evolving the model towards a state compatible with industrial ownership.   6 \n 7 \n5. Risk management capability maturity model 8 \n5.1 MODEL OVERVIEW 9 \nThe RM-CMM is designed to measure and improve risk management processes.  10 \nHence it is process-based rather than focussing on specific outcomes or deliverables.  It is 11 \nincreasingly accepted that continuous process improvement is based on a series of small, 12 \nevolutionary steps, rather than revolutionary measures (Paulk et al., 1993).  The RM-CMM 13 \norganises these steps within evolutionary plateaus, or maturity levels, which lay successive 14 \nfoundations for continual process improvement.  Fig. 3 illustrates the model architecture.   15 \n 16 \n5.2 RISK MANAGEMENT MATURITY LEVELS 17 \nSetting sensible goals for process improvement requires an understanding of the 18 \ndifference between mature and immature organisations (Paulk et al., 1993).  We have 19 \ndeveloped descriptions of five maturity levels that characterise organisational behaviours in 20 \nboth risk management overall and for each constituent process.  These levels were derived 21 \nby abstraction from existing CMMs describing different disciplines (Paulk et al., 1993, 22 \nSoftware Engineering Institute, 2002a \/ 2002b; Sharp et al., 2002; Strutt, 2003; Sarshar et 23 \n 10\nal., 2000), contextualisation of which was supported by reviews (MacGillivray et al., 1 \n2006a, Pollard et al., 2004; Hamilton et al., 2006) and scoping interviews.  It is important to 2 \nunderstand what these levels represent in practice, as they are central to assessing the 3 \nmaturity of an organisation.  Below we describe the overarching maturity hierarchy.  Note 4 \nthat at a given level of maturity, the positive characteristics from preceding levels remain. 5 \n 6 \nLevel 1 \u2013 Initial 7 \nL1 organisations practice a largely ad hoc approach to risk management, possessing 8 \nno formal risk management processes and often exhibiting limited knowledge of relevant 9 \nstandards or regulatory guidelines.  Thus, they are largely reliant upon individual heroics 10 \nfor the active management of risk.  L1 organisations are likely to be small water providers 11 \nbased in isolated rural areas where resource constraints prevent the staffing of utilities with 12 \ndedicated water professionals. 13 \n 14 \nLevel 2 \u2013 The repeatable organisation 15 \nL2 organisations understand that they have risks that require formal management, and 16 \nhave established basic risk management processes for this purpose.  However, these 17 \nprocesses are ill-defined and poorly institutionalised, limiting their capacity to influence 18 \norganisational actions.  Furthermore, the scope of risk management is narrow, generally 19 \nrestricted to addressing mission-critical risks and areas required by regulation (e.g. 20 \noccupational health and safety, water quality).  Hence, at L2 the active management of risk 21 \ntends to be influenced less by explicit risk management processes than by the repetition of 22 \nactivities and practices that have worked for the organisation before.  In a technical context, 23 \n 11\nthis places a premium on accepted standards of performance and codes of practice (e.g. 1 \nengineering standards; accepted best practice) which, if adhered to, provide high degrees of 2 \ncontrol.  This is a pragmatic approach in familiar and well-characterised situations where 3 \nuncertainties and system vulnerabilities are well understood.   4 \nHowever, this mind set is vulnerable; when mistakes are made they do not learn \u2013 5 \nfailures are repeated as well as success.  Whilst L2 organisations often have a reputation for 6 \nachieving reliable, cost-effective water supply, they are very vulnerable to change, whether 7 \norganisational, technical or commercial.  This, allied with deficient organisational learning, 8 \nis a common theme across many recent water quality related outbreaks in affluent nations 9 \n(Hrudey and Hrudey, 2004).   10 \n 11 \nLevel 3 \u2013 The defined organisation 12 \nThe key characteristic of the L3 organisation is the definition and implementation of 13 \nrisk management processes across core business areas.  This is achieved through 14 \nestablishing process \u201cenablers\u201d.  Enablers include the policies, procedures and frameworks 15 \nthat guide risk management activities (i.e. who does what and when), and the provision of 16 \nadequate training, funding and tools in support of these activities.  Several scoping 17 \ninterviewees described their recent definition of risk management processes.  Drivers for 18 \nthis included: a desire to balance the role of \u201cbrainstorming\u201d and \u201cjudgement\u201d in risk 19 \nmanagement with more methodological, standardised and objective approaches; the need to 20 \n\u201cinstitutionalise\u201d risk management; and obligations to exhibit good corporate governance to 21 \nshareholders and regulators.  In essence, definition seeks to formalise existing implicit 22 \napproaches to risk management.  This is most notably illustrated in the sector\u2019s increasing 23 \n 12\nadoption of the \u201cwater safety plan\u201d approach, which codifies good practice in the 1 \nidentification, assessment and control of hazards to water quality.   2 \nDefinition creates an environment in which risks are methodically identified, 3 \nanalysed, responded to and monitored.  In a technical context, L3 maturity is required 4 \nwhere systems are characterised by greater levels of uncertainty and the potential to deviate 5 \nfrom routine operation.  This is increasingly common, as the trend towards utility self-6 \nsufficiency means that management can no longer seek to \u201cover-engineer\u201d facilities with 7 \nthe presumption of screening out technical risk (MacGillivray et al., 2006a).  Here, 8 \noptimisation of plant, network and process design and operation requires a capacity to 9 \nassess, understand and respond to what is driving the risk from or to the plant, process or 10 \nnetwork.  However, at L3 the efficiency and quality of risk management processes are 11 \nvariable, stemming from limitations in their verification, validation and feedback 12 \nmechanisms (the \u201cevaluators\u201d).  These limitations restrict organisations\u2019 ability to track and 13 \ntherefore control their risk management processes, which are thus characterised as \u201copen 14 \nloop.\u201d   15 \n 16 \nLevel 4 \u2013 The controlled organisation 17 \nThe key characteristic of the L4 organisation is a structure which not only enables 18 \ntheir risk management processes but also evaluates and ensures their effective execution 19 \n(closing the open loop of L3).  The scope of these processes reach throughout the 20 \norganisational hierarchy and across all functional boundaries.  Evaluating refers to the 21 \nimplementation of verification and validation mechanisms to provide feedback on the 22 \nstatus, quality, efficiency and expediency of risk management (e.g. ensuring procedural 23 \ncompliance, quality assurance, benchmarking etc.).  The value of systematic verification 24 \n 13\nwas emphasised by one scoping interviewee, who noted that previously, free access to the 1 \ncorporate risk register was combined with an absence of peer review of risk assessments.  2 \nThis had allowed staff to \u201cover-estimate their own pet concerns\u201d and to assign risk 3 \nreduction actions via the register to other staff \u201cunbeknownst to them.\u201d  These deficiencies 4 \nwere remedied through the introduction of formal procedures governing access and use of 5 \nthe register and the establishment of challenge procedures to provide quality assurance of 6 \nrisk assessments.  7 \nHowever, the L4 organisation tends to be hardwired and lacking in internal 8 \nflexibility.  This is reflected in that although a learning ethos exists, the manner in which L4 9 \norganisations learn is defined as single-loop (Argyris and Sch\u00f6n, 1978).  This refers to 10 \nlearning where the emphasis is on improving techniques for executing processes, within the 11 \nconstraints of established process strategies.  In other words, learning is directed towards 12 \nmaking existing process strategies more effective.  Single-loop learning tends to be present 13 \nin organisations where goals, values, frameworks and strategies are taken for granted.  This 14 \nlack of capacity for deeper learning hampers their ability to make informed risk 15 \nmanagement decisions in rapidly changing and uncertain contexts.  Additionally, L4 16 \norganisations are often unable to grasp the soft issues associated with human and 17 \norganisational behaviour.  This is a core weakness.  18 \n 19 \nLevel 5 \u2013 The optimised organisation 20 \nThe key characteristics of the L5 organisation are its adaptability, flexibility and 21 \nattention to human and organisational behaviour.  The L5 mindset is one of deeper 22 \nunderstanding, of an adaptive, learning organisation aiming to be best in class and always 23 \nimproving in the long term.  Central to this is their capacity for both double (Argyris and 24 \n 14\nSch\u00f6n, 1978) and triple-loop learning.  Double-loop learning involves questioning the 1 \nnorms, values and assumptions underlying the design of risk management processes, and is 2 \ntypically found in organisations where risk information is continually developed through a 3 \nbroad range of channels (e.g. experience, R+D, benchmarking, analysis, simulation, etc.).  4 \nThis information is openly shared, communicated and used to publicly test assumptions and 5 \nbeliefs.  We define triple-loop learning as questioning and revising broader organisational 6 \nstructures and practices to optimise the capability of risk management processes (e.g. 7 \nchanging incentive structures to encourage knowledge sharing and collaboration between 8 \ntraditionally competing departments, etc.).  The core enablers of triple-loop learning are an 9 \nunderstanding of how human and organisational behaviour influence process capability, 10 \nand organisational flexibility.  L5 organisations are also actively engaged in the innovation, 11 \ndevelopment and piloting of new ideas and technologies to optimise risk management 12 \nthroughout the organisation.  From these efforts, best practices are identified and 13 \ntransferred throughout the organisation.  L5 processes are extremely efficient and there is a 14 \nstrong risk management culture, because of the long term investments made in developing 15 \nprocesses and in training staff to participate in them.   16 \n 17 \n5.3 RISK MANAGEMENT PROCESSES 18 \nOur research identified 11 risk management processes (Fig. 3).  Strategic risk 19 \nplanning centres on developing the corporate framework for risk management.  Hamilton et 20 \nal. (2006) describe how these frameworks can introduce greater rigour, consistency and 21 \nstandardisation to the discipline.  The researchers further note their potential for adaptation 22 \nto suit \u201cuser needs.\u201d  This final point is crucial, as our scoping interviews suggested that 23 \nrisk management frameworks were not simply shoehorned within utilities.  Establishing 24 \n 15\nrisk acceptance criteria is perhaps the least understood aspect of risk management.  Whilst 1 \nour scoping interviews implied that internally developed criteria for evaluating the 2 \nsignificance of risks were commonplace (risk ranking techniques), prior experience in 3 \nsimilar sectors suggests that tolerability criteria are less prevalent and often externally 4 \nimposed (e.g. ALARP criteria for dam safety).  We address both of these aspects in the 5 \ncontext of an internal process, as we propose that both are required to develop responses to 6 \nrisks in a consistent, objective and defensible manner.  Risk analysis involves the 7 \nidentification and assessment of risk.  We have previously reviewed (MacGillivray et al., 8 \n2006a) its application in the sector at operational, programme and strategic levels.  Here, 9 \nour focus is not on the methodologies per se, but on their application.  Supported by 10 \ninitiation criteria and formal procedures, using personnel with appropriate skills, 11 \nexperience, and resources, risk analysis techniques can provide utilities with benefits 12 \nranging from an improved understanding of treatment reliability to an explicit appreciation 13 \nof project financial risks.  Applied inappropriately, whether due to ill-defined procedures or 14 \ndeficient institutional capacities, risk analysis is not a subset of risk management but its 15 \npanacea.  Our inclusion of risk based decision making examines how organisations identify 16 \nand evaluate solutions to manage individual risks.  Clearly, risk analysis is of little use if 17 \nthe outputs are intended to placate regulators rather than inform decision making.  18 \nFurthermore, one interviewee noted that an absence of criteria to evaluate decisions 19 \nrestricts objectivity (i.e. opinions dominate in decision making), and we further propose 20 \nthat it prevents the ex ante validation of decisions taken.  Risk response is the 21 \nimplementation of risk based decisions.  Although an argument may be forwarded that this 22 \nlies outside the scope of our model as implementation processes are unlikely to be unique 23 \nto risk based decisions (i.e. there will exist models for implementing capital or operational 24 \n 16\nsolutions, not models for implementing risk based decisions per se), it is included as 1 \ndecisions left unimplemented are hollow gestures.  The model\u2019s treatment of these latter 2 \ntwo processes is particularly relevant as risk management frameworks have historically 3 \nfocussed on the identification and assessment of risk, effectively marginalising guidance on 4 \ntheir practical management.  Risk monitoring involves tracking the evolution of identified 5 \nrisks, and is included in recognition of their dynamic nature.  Integration is the current 6 \nfocus of the risk management community.  From the literature and our scoping interviews, 7 \ntwo aspects were identified: embedding risk management within organisations; and 8 \nenterprise risk management, where risks are managed with reference to the organisation as 9 \na whole, rather than in isolation or in functional silos.  Illustrating the latter aspect, Lam 10 \n(2003) contends that the traditional, fragmented approach, where companies manage risk in 11 \norganisational \u201csilos,\u201d is ineffective because risks are highly interdependent and cannot be 12 \nsegmented and managed by entirely independent units. As one  scoping interviewee stated, 13 \n\u201cone of the challenges is\u2026when [staff] are all using discrete [risk] tools which may have 14 \ndifferent terminologies, scoring systems and ways of presenting the outputs, my role is [to 15 \nensure] is a shared understanding and an ability to interpret the results of tools in a 16 \nbusiness-wide context.\u201d  We introduce a third element of integration by abstraction from 17 \nthe systems engineering CMM (Software Engineering Institute, 2002a): integration of the 18 \nrisk management process interfaces (e.g. between risk analysis and risk based decision 19 \nmaking).   20 \nSupply chain risk management addresses two components: the sourcing of 21 \ncomponents required to develop a product (e.g. chemicals) and the management of services 22 \nprovided by organisations throughout the supply chain.  The latter element is of particular 23 \nsignificance to the sector owing to the increasing utilisation of outsourcing.  However, one 24 \n 17\npilot interviewee challenged the inclusion of product risk, arguing it is effectively managed 1 \nthrough adhering to quality accredited suppliers.  However, it was maintained as the 2 \nauthors\u2019 prior research in the oil and gas industry indicates that many organisational 3 \nfailures can be traced back to minor and apparently insignificant services and components 4 \nsourced from suppliers.  Change risk management is abstracted from the reliability 5 \nengineering CMM (Strutt, 2003), and involves identifying and managing the risk 6 \nimplications of organisational (e.g. business process re-engineering) and technical change.  7 \nWe justify its inclusion as a range of factors (e.g. globalisation, regulatory and market 8 \nrestructuring, novel technologies) are serving to fundamentally alter the context in which 9 \nwater utilities operate.  Education and training \u2013 the development and maintenance of the 10 \ncompetencies required to manage risk \u2013 is included as our scoping interviews suggested 11 \nthat risk management simply does not fit well into traditional company skill sets.  Risk 12 \nknowledge management may be considered as the collection, storage and access of the data 13 \nunderpinning and accumulated from the broader risk management processes, i.e. the input 14 \nand output data.  The latter aspect is drawn from our scoping interviews, which discussed 15 \nvarious risk communication and reporting protocols and the use of databases for storing 16 \nrisk assessment outputs.  We include the former aspect on the premise that in the absence of 17 \npre-defined data requirements, risk data collection is likely to be ad hoc and largely 18 \nrestricted to the needs of business as usual.   19 \nThere was some discussion amongst the authors as to whether research and 20 \ndevelopment in risk management merited inclusion as a process.  However, the pilot 21 \ninterviewees were resistant to this, with one considering it \u2018\u2018not directly relevant,\u2019\u2019 another 22 \nstating that the tools and techniques of the discipline are sufficiently developed, rendering it 23 \na secondary issue.  Although their experience within the sector confers validity to their 24 \n 18\narguments, they may nonetheless be considered somewhat short-sighted.  A compromise 1 \nwas found through considering research and development not as a distinct process but as a 2 \ndefining characteristic of mature risk analysis, risk monitoring and risk knowledge 3 \nmanagement.  4 \n 5 \n5.4 KEY ATTRIBUTES 6 \nWe have identified eight key attributes (Fig. 3) which characterise process maturity.  7 \nScope is included as we propose maturity to be correlated with the scope of implementation 8 \n(i.e. a well defined process restricted to engineering does not constitute high organisational 9 \nmaturity).  Here, integration refers to the existence of initiation criteria and procedures for 10 \nprocess execution.  Although its treatment as both process and attribute constitutes double-11 \ncoverage, this was felt appropriate given its prominence in the practitioner and academic 12 \nliterature.  Verification mechanisms address procedural compliance and quality assurance 13 \nof process execution, whilst validation determines whether the process itself is correct.  14 \nTogether, these mechanisms create process control, and provide the primary feedback 15 \ninputs for organisational learning.  The inclusion of organisational learning builds on prior 16 \nresearch conducted by the authors in offshore design and safety (Sharp et al., 2002) and 17 \nreliability engineering (Strutt, 2003), although the underlying principle is drawn from ideas 18 \nfrom the theory of action and the concept of single and double loop learning (Argyris and 19 \nSch\u00f6n, 1978).  It is best illustrated by paraphrasing Dalrymple (2006), who notes that 20 \nexperience rarely provides lessons directly, but instead requires interpretation through the 21 \nfilter of preconceived theories, values and prejudices.  Where these are impregnable, facts 22 \nare weak things.  The capacity to use experience to question and revise these preconceived 23 \nnotions constitutes double loop learning.   24 \n 19\nWe include stakeholder engagement in deference to its prominent representation 1 \nwithin risk management frameworks.  However, our scoping interviews revealed a 2 \ndisconnect between academic and industrial perceptions of the appropriate role of external 3 \nstakeholders within risk management, with the latter generally more resistant to their 4 \ninvolvement.  Explanations to support this stance included the need to preserve commercial 5 \nconfidentiality, concerns over possible conflicting objectives between stakeholders and 6 \norganisations, and fears that stakeholder representatives may lack specialist knowledge and 7 \nhence \u201cslow down\u201d risk management.  One interviewee described that whilst they 8 \ndeveloped emergency response plans for water quality incidents in conjunction with the 9 \npublic health regulator, they were resistant to brining concerns about drinking water safety 10 \nto the public domain owing to fears of press sensationalism.  Another noted that they \u201cdon\u2019t 11 \nso much consult stakeholders as expose the [risk] governance process to them [e.g. 12 \nregulators or shareholder representatives] \u2013 they form an opinion of [its] adequacy or 13 \notherwise.\u201d That said, there was agreement on the importance of engaging internal 14 \nstakeholders, on the premise that through engaging other departments, functions, and 15 \nbusiness units, organisations may avoid the silo mentality which has historically pervaded 16 \nrisk management, thus creating synergies through shared knowledge and expertise, the co-17 \nordination of related work, etc.  For example, one interviewee described the value of using 18 \n\u201cnetworks of participants\u201d to provide input to capital investment decisions.  Here, 19 \nstakeholders have the opportunity to critique proposed options (e.g. for constructing a new 20 \ntreatment plant, staff involved in the design, operation and maintenance, costing, etc.).  The 21 \ninclusion of competency as an attribute recognises that risk management processes will 22 \nprove ineffective if their execution lies outwith technical or managerial skill sets.  Indeed, 23 \nmany of our interviewees discussed their desire to maintain in-house competencies to 24 \n 20\nmanage risk in preference to relying on consultants.  Resourcing encompasses the use of 1 \nmonetary, human and technical (e.g. analysis methodologies) resources.  As one 2 \ninterviewee noted, \u201cfunding, manpower, and specialists\u201d are particular constraints to 3 \neffective risk management in smaller utilities.  Process documentation and reporting is the 4 \nfinal attribute.  Notably, Deloach (2000) reflects that there is often a lack of organisational 5 \nconsistency in reporting formats for risk management, which he perceives as a barrier to 6 \n\u201centerprise wide\u201d risk management.  More practically, one interviewee argued that in what 7 \nremains a conservative industry, if risk information is not properly documented and 8 \naccessible then staff will use this \u2018\u2018as an excuse to ignore risk management.\u2019\u2019   9 \nConsideration was afforded to the inclusion of culture as an attribute, given its 10 \nextensive discussion in the literature and our scoping interviews.  However, this was 11 \nrejected for two reasons.  Firstly, culture is a notoriously difficult concept to define, let 12 \nalone measure.  Secondly, overt attempts to change culture, which in this context may be 13 \nthought of as the values and beliefs held by employees that guide their actions in managing 14 \nrisk, are not only Orwellian, but likely to be ineffectual.  Ineffectual, as the authors consider 15 \nthat employee values and beliefs are not intrinsic properties, but rather are conditioned by 16 \nthe environment within which they manage risk (i.e. the risk management processes).  17 \nThus, culture change is a consequence of process improvement, not a prerequisite.   18 \n 19 \n5.5 INTERNAL STRUCTURE OF PROCESS ASSESSMENT FRAMEWORK 20 \nAt the framework\u2019s core are a series of guideline statements which describe how each 21 \nprocess is conducted at each level of maturity with reference to the key attributes.   In 22 \nsupport of this are process descriptions which also outline the key practices required to 23 \nsatisfy the process goals.  As the guideline statements are largely devolved from the 24 \n 21\nprinciples contained in the overarching maturity hierarchy, we do not dwell on their detail.  1 \nHowever, by way of illustration, Table 1 depicts the assessment framework at levels 3 and 2 \n4 for risk analysis.   3 \n 4 \n5.6 INTERNAL STRUCTURE OF PROCESS IMPROVEMENT FRAMEWORK 5 \nThis framework outlines the operational steps that utilities may take in order to 6 \nimplement their process improvement priorities as identified from application of the 7 \nassessment framework.  It was developed after receiving feedback that the assessment 8 \nframework was at a layer of abstraction which restricted its ability to inform the 9 \ndevelopment of improvement plans.  The steps are grouped by process and maturity level, 10 \nand are categorised according to actions to: perform base and advanced practices that 11 \nsatisfy the process goals (i.e. do the process); establish and define the process (i.e. structure 12 \nthe process); and enable and evaluate the process (i.e. institutionalise the process).  Table 2 13 \ndepicts the process improvement framework relating to progression from L3 to L4 in risk 14 \nanalysis.   15 \n 16 \n6. Illustrating the RM-CMM 17 \nWe have discussed the overarching maturity hierarchy, and introduced the risk 18 \nmanagement processes and those attributes which define their maturity.  Here, we build on 19 \nthese foundations by illustrating what the model practically means within various 20 \norganisational functions.  Consider first risk analysis.  The distinction between the ad hoc 21 \nand the repeatable level is that in the latter, the application of basic techniques by 22 \nexperienced staff creates a degree of stability.  In process engineering, this may entail the 23 \n 22\nexecution of hazard and operability studies (HAZOP) to identify and assess the potential 1 \nfor designs to deviate from specifications, whilst at L1 this potential would be addressed 2 \nimplicitly if at all.  At L3, initiation points for analyses are defined (e.g. at the concept 3 \ndesign stage), and formalised procedures detail the tasks, activities, roles and 4 \nresponsibilities for execution, creating a basic infrastructure that maintains the process 5 \nbeyond the tenure of experienced staff (who are depended upon at L2).  At L4, verification 6 \nextends beyond ensuring procedural compliance (L3) to address quality assurance of 7 \nanalyses, for example through technical peer reviews.  Questions addressed may include: 8 \ndid the analysts work their way through the HAZOP study systematically, or did they 9 \noverlook important scenarios, components and process flows; were all stages and operating 10 \nmodes of the process considered (e.g. startup, shutdown and transitioning to partial 11 \noperation); and was adequate time spent on the analysis. 12 \nWe now consider risk based decision making in the context of occupational health 13 \nand safety.  Here, the initiating point is the receipt of risk analysis outputs (e.g. job safety 14 \nrisk analyses, plant hazard evaluations, etc.).  These outputs, together perhaps with a 15 \npredefined hierarchy of health and safety risk controls (e.g. engineering; administrative; 16 \nand protective personal equipment) serve as the framework for identifying solutions to 17 \nmanage individual risks.  Once identified, these solutions may be evaluated with reference 18 \nto criteria including: cost, feasibility and risk reduction achieved.  In contrast, at L2 19 \nmaturity, decisions to manage risks are taken in isolation of a clearly defined framework 20 \nand perhaps even in the absence of risk analysis outputs, and are hence focus upon 21 \nreplicating historic good practice.  Thus, health and safety is under pressure when 22 \ncircumstances change, whether through the introduction of new technical processes or 23 \nmodifications to work practices.   24 \n 23\nFinally, consider education and training in risk management.  Here, a repeatable 1 \nprocess may focus on workshops, where the concepts of risk management are introduced to 2 \nstaff on an as required basis, supported by on the job training.  Further, there is an absence 3 \nof clear criteria dictating when and to whom training should be delivered.  An additional 4 \nweakness is the inability to define the required competencies for effective risk 5 \nmanagement.  Without these, on what basis are training programmes designed, how are the 6 \nappropriate means of delivery selected (e.g. classroom training, workshop, on the job, etc.), 7 \nand how can the efficacy of training be evaluated?  These weaknesses are remedied at the 8 \ndefined state. 9 \n 10 \n7. Model application  11 \nThe RM-CMM has a range of potential applications, including:  12 \n\u2022 Self-assessment or external evaluation (voluntary or audit) of risk management 13 \nmaturity at the corporate, business unit, functional and project level; 14 \n\u2022 Use by management and technical staff as a reference model for designing and 15 \nimplementing a risk management improvement initiative; 16 \n\u2022 Evaluation of potential suppliers\u2019 \/ contractors\u2019 \/ partners\u2019 risk management maturity 17 \nprior to selection. 18 \nThe model can be implemented either as a self-assessment procedure or by external 19 \naudit using independent verification authorities. It is felt that the latter, in most cases, gives 20 \ngreater credence to the results of an assessment. However, internal assessments are often 21 \nmore useful when using the model as an improvement tool rather than as a measurement 22 \n 24\ntool.  The companion paper (MacGillivray et al., 2006b) describes in detail the self-1 \nassessment methodology. 2 \n  3 \n8. Conclusions 4 \nWe have described a risk management capability maturity model, a vehicle for 5 \nbenchmarking and improving risk management within the water sector.  We have addressed 6 \nthe model\u2019s theoretical and empirical foundations, overviewed its architecture, and 7 \nillustrated its practical definition.  Implementation of the model should assist utilities to 8 \nmore effectively employ their portfolio of risk analysis techniques for optimal, credible, 9 \ndefensible decision making.  A companion paper describes its application to benchmark 10 \neight utilities within the international water sector. 11 \n 12 \nAcknowledgements 13 \nThis work has been funded by the American Water Works Association Research 14 \nFoundation (AwwaRF project RFP2939) and a consortium of international water utility 15 \ncompanies.  The comments and views herein are the authors\u2019 alone.  BM is co-funded on a 16 \nUK Engineering and Physical Sciences Research Council (EPSRC) Doctoral training 17 \naccount. 18 \n 19 \nReferences 20 \nArgyris, C. and Sch\u00f6n, D. (1978) Organizational learning: A theory of action perspective, 21 \nReading, Mass: Addison Wesley. 22 \n 25\nAWWA, EUREAU, WSAA and DVGW (2001) Bonn Workshop 2001 \u2013 Key principles in 1 \nestablishing a framework for assuring the quality of drinking water: a summary, 2 \nAWWA, Denver, CO., 2001. 3 \nBooth, R. and Rogers, J. (2001) Using GIS technology to manage infrastructure capital 4 \nassets, J. AWWA, 93(11), 62-68. 5 \nCanadian Standards Association (1997) Risk management: guidelines for decision makers.  6 \nCAN\/CSA-Q850-97. 7 \nCOSO (2004) Enterprise risk management framework - Executive Summary.  Available at 8 \nwww.otpp.com. 9 \nCouncil of Standards of Australia (1999) Australian\/New Zealand risk management 10 \nstandard No.4360: 1999. 11 \nCrosby, P. B. (1979) Quality is Free, New York, McGraw-Hill. 12 \nDalrymple, T. (2006) Less libert\u00e9 means less egalit\u00e9, City Journal, Winter 2006. 13 \nDeloach, J.W. (2000) Enterprise-wide risk management - strategies for linking risk and 14 \nopportunity, Pearson Education Limited, London, 284pp. 15 \nHamilton, P.D., Pollard, S.J.T., Hrudey, S.E. and MacGillivray, B.H (2006) Risk 16 \nmanagement frameworks for the water sector \u2013 a review, at review. 17 \nHoward, J. and Lourens, A. (2005) Engaging operational staff in risk management, Proc. of 18 \nRisk analysis strategies for better and more credible decision making, 6-8th April, 2005, 19 \nBanff, Canada. 20 \n 26\nHrudey, S.E. and Hrudey E.J. (2004) Safe drinking water: Lessons from recent outbreaks in 1 \naffluent nations, IWA Publishing. 2 \nIACCM (2003) Organisational maturity in risk management: The IACCM business risk 3 \nmanagement maturity model (BRM3).  Available at http:\/\/www.risk-doctor.com\/pdf-4 \nfiles\/brm1202.pdf. 5 \nIMPRESS Management (2002) Guidance for the analysis of pressures and impacts in 6 \naccordance with the water framework directive, Draft 5.2, European Commission, 7 \nBrussels. 8 \nLam, J. (2003) Enterprise risk management: from incentives to controls, John Wiley & 9 \nSons, Hoboken, New Jersey. 10 \nLifton, G. and Smeaton, P. (2003) Asset risk management in Scottish Water, Proc. of the 11 \nICE\/CIWEM Conference: Risk and reward in asset management delivery \u2013 who is best 12 \nprepared for the challenges ahead?, 14th November, 2003, London, UK. 13 \nLloyd, R. and Abell, P. (2005) Capital maintenance in Yorkshire Water\u2019s water business 14 \nunit, Proc. of Risk analysis strategies for better and more credible decision making, 6-8th 15 \nApril, 2005, Banff, Canada. 16 \nMacGillivray, B.H, Hamilton, P.D., Strutt, J.E., Pollard, S.J.T. (2006a) Risk analysis 17 \nstrategies in the water utility sector: an inventory of applications for better and more 18 \ncredible decision-making, Critical Reviews in Environmental Science and Technology, 19 \n36, 85-139. 20 \n 27\nMacGillivray, B.H., Pollard, S.J.T., Hamilton, P.D. and Bradshaw, R.A. (2006b) 1 \nBenchmarking risk management within the international water utility sector.  Part II: A 2 \nsurvey of eight water utilities, J. Risk Research, at review. 3 \nMiller, G.A. (2005) Risk governance in a water utility, Proc. of Risk analysis strategies for 4 \nbetter and more credible decision making, 6-8th April, 2005, Banff, Canada. 5 \nNHMRC (2001) Framework for management of drinking water quality, NHMRC, New 6 \nZealand. 7 \nPaulk, M.C., Curtis, B., Chrissis, M.B. and Weber, C.V. (1993) Capability maturity model, 8 \nversion 1.1, IEEE Software 10(4), 18-27. 9 \nPollard, S.J.T., Strutt, J.E., MacGillivray, B.H., Hamilton, P.D. and Hrudey, S.E. (2004) 10 \nRisk analysis and management in the water utility sector \u2013 a review of drivers, tools and 11 \ntechniques, Trans. IChemE, Part B: Proc. Safety Environ. 82(B6): 1-10. 12 \nPrime Minister\u2019s Strategy Unit (2002), Risk: improving Government\u2019s capability to handle 13 \nrisk and uncertainty, The Strategy Unit, London.  Available at:  http:\/\/www.number-14 \n10.gov.uk\/SU\/RISK\/risk\/home.html. 15 \nRMRDP (2002) Risk management maturity level development.  Available at 16 \nhttp:\/\/www.risksig.com\/Articles\/rm%20report%20final%20version%2012.doc. 17 \n Sarshar, M., Haigh, R., Finnemore, M., Aouad, G., Barrett, P., Baldry, D. and Sexton, M. 18 \n(2000) SPICE: a business process diagnostics tool for construction projects, 19 \nEngineering, Construction and Architectural Management, 7(3), 241-250.  20 \n 28\nSharp, J.V., Strutt, J.E., Busby, J. and Terry, E. (2002) Measurement of organizational 1 \nmaturity in designing safe offshore installations, Proceedings of the International 2 \nConference on Offshore Mechanics and Arctic Engineering, 2: 383-390. 3 \nSoftware Engineering Institute (2002a) CMMI for systems engineering \/ software 4 \nengineering \/ integrated product development \/ supplier sourcing, version 1.1.  5 \nAvailable at http:\/\/www.sei.cmu.edu\/. 6 \nSoftware Engineering Institute (2002b) People capability maturity model, version 2.0.  7 \nAvailable at http:\/\/www.sei.cmu.edu\/. 8 \nStahl, G.R. and Elliott, J.C. (1999) \u2018New generation\u2019 computer models for risk-based 9 \nplanning and management, Water Supply (Australia), 17(3\/4), 289-295. 10 \nStarke, R.E. (1995) The art of case study research, Sage, Thousand Oaks, CA and London. 11 \nStevens, I.M. and Lloyd, R.I. (2004) Water resources: Sustainable optimisation and 12 \nsecurity of supply, a proven example, A paper presented to the 2004 Water sources 13 \nconference and exposition, Jan 11-14th, 2004, Austin, Texas. 14 \nStrutt, J.E. (2003) Reliability capability maturity briefing document, Report No. R-03\/2\/1, 15 \nCranfield University. 16 \nWHO (2003), Guidelines for drinking water quality, 3rd Edition (draft), WHO.  Available 17 \nat: http:\/\/www.who.int\/water_sanitation_health\/dwq\/guidelines3rd\/en\/. 18 \nWHO (2002) Water safety plans (revised draft), Report publication 19 \nWHO\/SDE\/WSH\/02.09, World Health Organisation. 20 \n 29\n 1 \n 2 \n 3 \nFig. 1.  The risk hierarchy (adapted from Prime Minister\u2019s Strategy Unit, 2002) 4 \n 5 \n 6 \n 7 \n 8 \n 9 \n 10 \n 11 \n 12 \n 13 \n 14 \n 15 \n 16 \n 17 \n 18 \nOperational \nProgramme \nStrategic decisions \nDecisions transferring \nstrategy into action \nDecisions required \nfor implementation \n\u2022 Asset management\n\u2022 Water resource planning\n\u2022 Microbial risk assessment programme \n\u2022 Catchment protection programme \n\u2022 Security risks\/emergency planning \nStrategic \n\u2022 Individual compliance\/consent risks \n\u2022 Project risk assessment \n\u2022 Site health and safety \n\u2022 Maintenance planning \n\u2022 Process design reliability \n\u2022 Strategic investments\n\u2022 Merger and acquisition activity\n\u2022 Workforce retention\n\u2022 Technology risks\n\u2022 Political\/regulatory risks\n 30\n 1 \n 2 \nFig. 2. Research methodology for design of RM-CMM. 3 \n 4 \n 5 \n 6 \n 7 \n 8 \n 9 \n 10 \n 11 \n 12 \n 13 \n 14 \n 15 \nReview of water sector risk \nmanagement practice \nReview of CMM methodology \nScoping interviews with water \nsector practitioners \nPilot RM-CMM RM-CMM Pilot interviews and \nworkshop \nExpert panel \n 31\n 1 \n2 \n 3 \n 4 \n 5 \n 6 \n 7 \n 8 \n 9 \nFig. 3. Overview of the RM-CMM (after Strutt et al., 2005).10 \n Processes \nStrategic risk planning (SRP) \nEstablishing risk acceptance criteria (ERAC) \nRisk analysis (RA) \nRisk based decision making and review (RBDM) \nRisk response (RR) \nRisk monitoring (RM) \nCore \nIntegrating risk management (IRM) \nSupply chain risk management (SCRM) Supporting \nChange risk management (CRM) \nEducation and training in risk management (E&T) Long-term \nRisk knowledge management (RKM) \nAttributes \nScope \nIntegration \nVerification and validation \nFeedback and organisational learning \nStakeholder engagement \nCompetence \nResources \nDocumentation and reporting \n1\n2\n          3 \n4\n5\nAd hoc\nOptimising \nMaturity \n 32 \nAttribute Attribute at level 3: Risk analysis Attribute at level 4: Risk analysis \nScope A defined, documented process is in place containing criteria, methods \nand guidelines for the identification, assessment and evaluation (with \nrespect to acceptance criteria) of a broad range of risks across core \nbusiness areas, guided by a risk register.  The organisation is conversant \nwith and goes beyond the regulatory requirements for risk analysis. \nA controlled process is in place containing detailed criteria, methods and \nguidelines to manage the identification, assessment, evaluation (with respect to \nacceptance criteria), establishment of causality and linking (common cause and \ndependent) of risks at all levels of the company and across all functional \nboundaries of the business, guided by a company-specific risk register. \nIntegration Procedures are in place to initiate risk analysis processes. Risk analysis is initiated automatically as part of core business processes (e.g. \nperiodic business risk assessments). \nVerification and \nValidation \nBasic mechanisms are in place to verify that risk analysis is performed as \nrequired, largely reliant on lagging indicators.  The expertise for \nvalidation is generally lacking. \nVerification and validation systems are in place to verify the efficiency of risk \nanalysis activities and to validate their expediency (e.g. the organisation tracks \nthat tools and techniques are being used correctly and that the correct tools and \ntechniques are being used). \nFeedback and \nOrganisational \nLearning \nThe risk analysis tool suite is reviewed and modified on an event-driven \nbasis. \nFeedback is actively used to improve the execution of risk analysis (e.g. gaps \nidentified and risk analysis tools and techniques improved in response). \nStakeholder \nEngagement \nRisk analysis processes generally reside within the responsible unit, with \nlimited cross-functional or external consultation. \nRisk analysis processes generally reside within affected disciplines, and \nstakeholders work together to define and implement an integrated approach to \nrisk analysis, capitalising on synergies and collective knowledge. \nCompetence Detailed knowledge of risk analysis resides only within the responsible \nunit. \nMost involved staff exhibit a good level of competence in the selection and \napplication of risk analysis tools and techniques, and have access to support \nfrom internal or external expert risk practitioners. \nResources Adequate resources are provided in support of risk analysis, with both \nqualitative and quantitative tools and techniques available. \nSufficient resources are provided in support of risk analysis, a portion of which \nis made available for R + D for risk assessment.  A broad range of qualitative \nand quantitative tools and techniques are available and applied, including \nmethodologies for aggregating and comparing risks. \nDocumentation and \nReporting \nRisk analysis outputs are compiled and disseminated in a format that \nsupports decision making. \nRisk analysis outputs are compiled and disseminated in a clear, concise and \nactionable format that supports real-time decision making, and their reporting is \nco-ordinated with other risk reporting mechanisms (e.g. risk status updates). \n 1 \nTable 1. L3 and L4 process maturity in risk analysis.2 \n 33\n 1 \nDomain Improvement step \n \nProcess \nenablement \n\u2022 Identify and allocate sufficient resources in support of risk analysis, updating them as necessary \nto reflect changing needs. \n\u2022 Identify key internal and external stakeholders (e.g. representatives of different functions or \ndivisions of the business) and define their potential contributions (e.g. synergies from collective \nknowledge and advice, etc.) and requirements (e.g. involvement in assessing cross business \nimpacts). \n\u2022 Establish mechanisms to involve identified stakeholders (e.g. cross-functional working groups). \nProcess \nevaluation \n\u2022 Establish formal mechanisms (e.g. periodic reviews, audits, status reports, milestones, etc.) to \nverify that risk analysis adheres to its formal description, policies, and procedures, and is being \nperformed efficiently.  \n\u2022 Designate \u2018ownership\u2019 of verification to a responsible individual(s). The individual(s) is \nresponsible for ensuring verification is performed, reviewing the findings, and recommending \ncorrective action where necessary.  Stakeholders should be involved as appropriate (e.g. staff not \nconforming to established procedures). \n\u2022 Define and collect measures to support verification of adherence and efficiency (e.g. task and \nactivity checklists, cost of analyses, timeliness of analyses, etc.). \n\u2022 Establish formal mechanisms (e.g. periodic reviews, external advice, status reports, etc.) to \nvalidate the process of risk analysis.  Candidates for validation include the methods and \nprocedures for risk analysis (e.g. the tools and techniques applied) and the risk analysis outputs \n(e.g. do the analysis outputs inform decision making). \n\u2022 Designate \u2018ownership\u2019 of validation to a responsible individual(s). The individual(s) is \nresponsible for ensuring validation is performed, reviewing the findings, and recommending \ncorrective action where necessary.  Stakeholders should be involved as appropriate (e.g. where \nchanges to the tool suite or procedures are recommended, the process \u2018owners\u2019 would be \ninvolved). \n\u2022 Define and collect measures to support validation of risk analysis (e.g. internal assessments by \ndecision makers of the value of risk analysis outputs, formal validation of risk analysis \nmethodologies, etc.). \n\u2022 Establish mechanisms to compare in-house risk analysis with industry practice, making changes \nwhere appropriate (e.g. benchmarking initiatives, strategic information exchange, etc.). \n 2 \nTable 2. Steps for progressing between levels 3 and 4 in risk analysis. 3 \n"}
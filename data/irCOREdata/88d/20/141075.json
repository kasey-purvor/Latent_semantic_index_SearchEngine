{"doi":"10.1007\/978-3-642-02617-1_26","coreId":"141075","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/4249","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/4249","10.1007\/978-3-642-02617-1_26"],"title":"A deployment value model for intrusion detection sensors","authors":["Shaikh, S. A.","Chivers, H.","Nobles, P.","Clark, J. A.","Chen, H."],"enrichments":{"references":[{"id":37924933,"title":"A cost-sensitive model for preemptive intrusion response systems. In:","authors":[],"date":"2007","doi":"10.1109\/aina.2007.9","raw":"Stakhanova, N., Basu, S., Wong, J.: A cost-sensitive model for preemptive intrusion response systems. In: 21st International Conference on Advanced Information Networking and Applications (AINA 2007). (May 2007) 428\u2013435","cites":null},{"id":37924936,"title":"A formal approach to sensor placement and con\ufb01guration in a network intrusion detection system. In:","authors":[],"date":"2006","doi":"10.1145\/1137627.1137638","raw":"Rolando, M., Rossi, M., Sanarico, N., Mandrioli, D.: A formal approach to sensor placement and con\ufb01guration in a network intrusion detection system. In: Proceedings of the 2006 International Workshop on Software Engineering for Secure Systems, ACM Press (May 2006) 65\u201371","cites":null},{"id":37924937,"title":"Automated generation and analysis of attack graphs. In:","authors":[],"date":"2002","doi":"10.1109\/secpri.2002.1004377","raw":"Sheyner, O., Haines, J., Jha, S., Lippmann, R., Wing, J.M.: Automated generation and analysis of attack graphs. In: Proceedings of the 2002 IEEE Symposium on Security and Privacy. (May 2002) 273\u2013284","cites":null},{"id":37924929,"title":"Characterising intrusion detection sensors, part 2.","authors":[],"date":"2008","doi":"10.1016\/s1353-4858(08)70118-1","raw":"Shaikh, S.A., Chivers, H., Nobles, P., Clark, J.A., Chen, H.: Characterising intrusion detection sensors, part 2. Network Security 2008(10) (October 2008) 8\u201311","cites":null},{"id":37924927,"title":"Characterising intrusion detection sensors.","authors":[],"date":"2008","doi":"10.1016\/s1353-4858(08)70107-7","raw":"Shaikh, S.A., Chivers, H., Nobles, P., Clark, J.A., Chen, H.: Characterising intrusion detection sensors. Network Security 2008(9) (September 2008) 10\u201312","cites":null},{"id":37924932,"title":"E.: Toward cost-sensitive modeling for intrusion detection and response.","authors":[],"date":"1993","doi":"10.1007\/1-84628-253-5_8","raw":"Lee, W., Fan, W., Miller, M., Stolfo, S.J., Zadok, E.: Toward cost-sensitive modeling for intrusion detection and response. Journal of Comp. Sec. 10(1-2) (1993) 5\u201322","cites":null},{"id":37924934,"title":"Optimal ids sensor placement and alert prioritization using attack graphs.","authors":[],"date":"2008","doi":"10.1007\/s10922-008-9109-x","raw":"Noel, S., Jajodia, S.: Optimal ids sensor placement and alert prioritization using attack graphs. Journal of Network and Systems Management 16(3) (September 2008) 259\u2013275","cites":null},{"id":37924931,"title":"S.: The value of intrusion detection systems in information technology security architecture.","authors":[],"date":"2005","doi":"10.1287\/isre.1050.0041","raw":"Cavusoglu, H., Mishra, B., Raghunathan, S.: The value of intrusion detection systems in information technology security architecture. Information Systems Research 16(1) (March 2005) 28\u201346","cites":null},{"id":37924930,"title":"Security Design Analysis. York Computer Science","authors":[],"date":"2006","doi":"10.1007\/11909033_21","raw":"Chivers, H.: Security Design Analysis. York Computer Science Technical Report YCS 2006\/06, University of York, UK (2006)","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-02-18T00:00:00Z","abstract":"The value of an intrusion detection sensor is often associated with its data\ncollection and analysis features. Experience tells us such sensors fall under a\nrange of different types and are diverse in their operational characteristics.\nThere is a need to examine some of these characteristics to appreciate the value\nthey add to intrusion detection deployments. This paper presents a model to\ndetermine the value derived from deploying sensors, which serves to be useful to\nanalyse and compare intrusion detection deployments","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/141075.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/10.1007\/978-3-642-02617-1_26","pdfHashValue":"77837d7c4856e56d6d554f67291e2adb879ecf54","publisher":"Springer-verlag","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/4249<\/identifier><datestamp>2011-12-13T11:27:27Z<\/datestamp><setSpec>hdl_1826_13<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>A deployment value model for intrusion detection sensors<\/dc:title><dc:creator>Shaikh, S. A.<\/dc:creator><dc:creator>Chivers, H.<\/dc:creator><dc:creator>Nobles, P.<\/dc:creator><dc:creator>Clark, J. A.<\/dc:creator><dc:creator>Chen, H.<\/dc:creator><dc:description>The value of an intrusion detection sensor is often associated with its data\ncollection and analysis features. Experience tells us such sensors fall under a\nrange of different types and are diverse in their operational characteristics.\nThere is a need to examine some of these characteristics to appreciate the value\nthey add to intrusion detection deployments. This paper presents a model to\ndetermine the value derived from deploying sensors, which serves to be useful to\nanalyse and compare intrusion detection deployments.<\/dc:description><dc:publisher>Springer-verlag<\/dc:publisher><dc:date>2011-12-04T23:02:13Z<\/dc:date><dc:date>2011-12-04T23:02:13Z<\/dc:date><dc:date>2010-02-18T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>Siraj A. Shaikh, Howard Chivers, Philip Nobles, John A. Clark and Hao Chen; A\ndeployment value model for intrusion detection sensors, Lecture Notes in\nComputer Science, Volume 5576, 2009, Pages 250-259<\/dc:identifier><dc:identifier>0302-9743<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1007\/978-3-642-02617-1_26<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/4249<\/dc:identifier><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["0302-9743","issn:0302-9743"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2010,"topics":[],"subject":["Article"],"fullText":"A Deployment Value Model for Intrusion\nDetection Sensors\nSiraj A. Shaikh1, Howard Chivers1, Philip Nobles1, John A. Clark2, and Hao\nChen2\n1 Department of Informatics and Sensors, Cranfield University, Shrivenham, UK\n{s.shaikh, h.chivers, p.nobles}@cranfield.ac.uk,\n2 Department of Computer Science, York University, York, UK\n{jac, chenhao}@cs.york.ac.uk\nAbstract. The value of an intrusion detection sensor is often associated\nwith its data collection and analysis features. Experience tells us such\nsensors fall under a range of different types and are diverse in their\noperational characteristics. There is a need to examine some of these\ncharacteristics to appreciate the value they add to intrusion detection\ndeployments. This paper presents a model to determine the value derived\nfrom deploying sensors, which serves to be useful to analyse and compare\nintrusion detection deployments.\n1 Introduction\nThe value of an intrusion detection sensor is often associated with its data col-\nlection and analysis features. This is inevitable since so many of the sensors are\ndesigned with such characteristics in mind. Experience tells us such sensors fall\nunder a range of different types and are diverse in their operational character-\nistics, some of which have been little studied. They offer a range of analytical\nabilities, with varying levels of efficiency, and incur a variety of costs. Hence,\nthere is a need to examine these characteristics to appreciate the real value they\nadd to sensor deployments.\nWe present a model to help determine the benefit derived from deploying\nintrusion detection sensors at various locations in a network. The aim is to de-\nploy sensors at locations in a systematic fashion such that maximum cumulative\nbenefit is derived at a minimum cost. This builds on a broad characterisation of\nsensors identified in earlier work [1, 2] which looks at sensor interaction abilities,\nlocations in a network where such sensors could be placed, and costs involved\nin deploying and monitoring. Network locations are also characterised in terms\nof monitoring load incurred due to the amount of activity processed and cost of\ndisruption due to extra installation required.\nThe paper is organised as follows. Section 2 presents a characterisation of\nnetworks. Section 3 presents a characterisation of sensors. Section 4 presents the\nmain contribution of this paper: a deployment value model to determine the\nbenefit derived from placing a sensor at a location and a strategy to optimise\nthe deployment of multiple sensors. Section 5 illustrates this using a case study.\nSection 6 discusses some related work and section 7 concludes the paper.\n2 Characterising the network\nWe present network characteristics that help us to characterise the various de-\nployment locations available in a network. Such locations are distinguished ac-\ncording to a variety of factors which affect sensor deployment.\n2.1 Location type\nWe specify three types of locations for sensor deployment: hosts (H), segments\n(S) and backbone (B) links. Each type provides different opportunities for plac-\ning a sensor and collecting some unique data:\n- Backbone links are the most commonly used location for this purpose where\nnetwork traffic between hosts and parts of the network is monitored.\n- Segments allow such traffic to be monitored but are more useful for moni-\ntoring traffic within the same segment and link layer activity.\n- Hosts refer to clients or servers where process and application data is mon-\nitored. This is useful for detecting malicious code, including worms and\nviruses, system files, memory and processor utilisation, and logs.\nWe use the three types of locations to classify sensors accordingly. LT and AT\ndenote type for location L and sensor A respectively, and range over a given set\nof locations, LT , AT : {H, S, B}. Sensor A can be deployed over location L only\nif AT = LT . This ensures that sensors are deployed on compatible locations.\n2.2 Load factor\nWe specify load factor to denote the amount of processing due to monitoring\ninvolved at a location. For network links this corresponds to capacity and usage.\nHosts are characterised by processing load in terms of processor and memory\nusage. Network locations where a high load factor is typical include\n- backbone links due to the amount of traffic that passes through,\n- network and application servers given the amount of processing involved\nboth in offering services to a number of clients, and processing of data,\n- segments attached to busy servers or a large number of clients, and\n- gateways that serve to link the network to the outside world.\nWe express load factor LF for a location L as LF (L) and restrict it to a range\nof values [1,10] to express relative load for different locations in a network.\n2.3 Risk profile\nChivers [3] introduces risk profiles for system components to characterise the\nrisks to which a system is exposed to if the component is compromised. The\nnotion could be applied to network nodes to denote the level of risk exposure\nfor the network if particular nodes are compromised. This takes into account\nthe value of a node as an asset, its location and the type of access it provides\nto penetrate further in a network, and the likelihood of intrusions targeting it.\nRisk profiles serve to highlight, for example, that web servers, critical to the\noperation of an organisation engaged in electronic commerce and likely to have\nmore access to critical information, are at a higher risk than ordinary clients.\nWe extend the notion to apply to segment and backbone links. A link provides\nan opportunity to detect compromise and a risk profile for a link is essentially\na representation of the significance of such an opportunity. Calculation of risk\nprofile also takes into account any preventative measures deployed to reduce risk\nexposure in parts of the network; the calculation includes\n- the aggregate risk profile of nodes attached,\n- the aggregate risk profile of other links attached, and\n- the risk reductive effect of any preventative measures deployed on the link.\nA risk profile for a location L is denoted as R(L) and expressed as a ratio\nrelative to other locations within a network; the higher the R(L) the better the\nvalue of deploying a sensor at L. We restrict R(L) to a specific range [0,10].\n2.4 Disruption cost\nWe identify disruption cost for locations to estimate the cost of deploying sen-\nsors. There are two factors to consider here. First, the cost of disruption at the\nlocation due to installation. This includes changes to configuration that may be\nnecessary as a result of additional software or hardware deployed. Secondly, the\ncritical importance of the location to the overall operation of the network. This\nrepresents the cost of disruption to the normal operation during installation.\nSuch a cost is likely to manifest itself in terms of downtime, and a loss of ser-\nvices as a result. We denote disruption cost as D(L) for a location L and restrict\nit to a specific range [1,10], with a minimum such cost of 1.\n3 Sensor characteristics\nWe specify interaction abilities and efficiency, both of which are crucial to the\ncapability of a sensor. Costs are also critical to assess the efficiency of a sensor.\n3.1 Interaction abilities\nIndividual sensors are represented in terms of their interaction abilities. This is\nthe ability to understand and interact with protocol characteristics at various\nlayers of the network. It may be limited to a single layer or span multiple service\nlayers where at each layer a sensor may interact\n- to perform analysis using a range of data analysis techniques,\n- if need be, generate response to detect suspicious events, and\n- if possible, provide defense against such events.\nWe use a range of values [1,10] to denote interaction AI for a sensor A. For each\nof the four service layers (Physical, Network, Transport and Application) it is\nassigned out of 2.50; AI is the cumulative total of values for each layer.\n3.2 Efficiency\nWhereas interaction abilities are important to detecting various types of attacks,\nequally important is the performance of sensors to accurately detect events of\ninterest. This could be expressed in terms of the likelihood of false positives and\nnegatives. So, for example, a higher rate of false positives lowers the efficiency.\nWe denote sensor efficiency AE for a sensor A as a fraction and restrict it to\na particular range [0.1,1]. Since it serves to influence the interaction ability of a\nsensor, we use it to introduce a capability metric. Such a metric represents the\neffective monitoring capability of a sensor denoted as Cap(A) = AI \u00d7AE .\n3.3 Costs\nWe take into account two different costs, deployment costs and monitoring costs.\nDeployment cost is a sum of both the cost CDep(A) of installing, configuring\nand maintaining a sensor A, and the cost D(L) of disruption at a location L.\nNetwork based sensors generally require minimal changes to network configura-\ntion; sensors placed inline require some rearrangements and may therefore be\ncostlier. Host-based sensors are likely to be most costly to deploy given the dis-\nruption. Cost of deploying A over L is denoted CostD(A,L) = CDep(A) + D(L),\nwhere CDep(A) is restricted to a specific range [1,10].\nMonitoring costs are to do with the use of a sensor to detect potentially sus-\npicious events. For a given sensor A such costs include the human cost CMon(A)\nof manual engagement required for monitoring, and the load factor LF (L) for\na location L monitored. Manual judgements required differs from sensor to sen-\nsor. Such effort is dependent on the load factor: the busier the location, the\nhigher the levels of activity monitored, and therefore bigger the effort. The cost\nof monitoring using A at L is denoted CostM (A,L) = CMon(A) \u00d7 LF (L), where\nCMon(A) is restricted to a specific range [1,10].\n4 Deployment value model\nWe present a deployment value model for deploying a sensor in a network and\npresent a strategy to optimally deploy a number of such sensors.\n4.1 Deployment value\nOur characterisation of sensors and networks allows us to determine the value of\nsensors operating at particular locations in a network. The higher the capability\ndeployed to mitigate the maximum risk, the higher the value of a deployment.\nFor a sensor A and location L, assuming AT = LT , we denote deployment value\nV (A,L) for placing A over L as V (A, L) = (Cap(A)\u00d7R(L))\/CostT (A, L) where\nCostT (A,L) denotes the total cost as a sum of deployment costs and monitoring\ncosts for such a deployment CostT (A, L) = CostD(A, L) + CostM (A, L). Such\na deployment is considered effective if V (A,L) \u2265 1, else it is deemed not to\njustify the costs involved. Note that the maximal value (120) for the total cost\nCostT (A,L) outweighs the maximal possible (100) for Cap(A) \u00d7 R(L). This is\nacceptable since either the capability or the risk profile for a deployment should\njustify deployment costs at a minimum.\n4.2 Deployment strategy\nWe propose a deployment strategy to maximise deployment value of a set of\nsensors. We define a set of n sensors as SENSORS = {ai | 0 \u2264 i \u2264 n} and a set\nof m locations as LOCATIONS = {lj | 0 \u2264 j \u2264 m}. For some a \u2208 SENSORS\nand l \u2208 LOCATIONS we represent each placement, where a is placed at l, as\na couple < a, l >. Given n sensors and m locations, a deployment is a set DEP\nof all such placements where the total number is equal to the lower of n and m.\nThe challenge here is to determine the deployment value of a composition\nof sensors such that they are placed optimally, which, assuming all sensors are\ncompatible with the location deployed at, ensures that placement is prioritised\nin terms of the maximum deployment value possible, while avoiding duplication\nof sensor capabilities at a location. Formally,\nDEP = {< ai, lj > | \u2200 i, j \u2022\naiT = ljT \u2227ai \/\u2208 {a1, ..., ai\u22121}\u2227lj \/\u2208 {l1, ..., lj\u22121}\u2227V (ai, lj) \u2264 V (ai\u22121, lj\u22121)}\nThe construction of DEP ensures that for every placement\n- location types of ai and lj are compatible aiT = ljT ,\n- sensor ai has not been deployed in a prior placement ai \/\u2208 {a1, ..., ai\u22121},\n- location lj does not appear in a prior placement, lj \/\u2208 {l1, ..., lj\u22121}, and\n- deployment value of placing ai over lj is less than the deployment value of\nthe previous placement V (ai, lj) \u2264 V (ai\u22121, lj\u22121)}.\nThe set DEP results in a list of compatible sensor-location pairings, all of which\nare unique and in descending order of deployment value. We check whether each\nindividual deployment is of value 1 or more. A deployment value less than 1\nrepresents an ineffective deployment where costs exceed the benefit. To factor it\nin we calculate the loss of benefit for each such deployment and offset it from the\ntotal deployment value. The deployment value operator is overloaded to extend\nover sets as V (DEP ) and represents the cumulative total value of all individual\nsensor placements such that if V (a, l) \u2265 1 then V (DEP ) = V (DEP ) + V (a, l),\nor if V (a, l) < 1, then V (DEP ) = V (DEP )\u2212 (1\u2212 (V (a, l)).\n5 Case study\nWe present an example network to demonstrate our model. Three different sensor\ndeployment scenarios are chosen to reflect various host and network based sensors\navailable. A list of sensors in Table 1 serves as a good variety some of which we\nuse. It draws upon a characterisation of sensors from our earlier work [1, 2],\nassigning capability and costs based upon use and experience.\nTable 1. A list of intrusion detection sensors\nSensor (A) Type (AT ) Cap(A) CDep(A) CMon(A)\nCisco IOS Port Security S 1.92 5 5\nHP Virus Throttling H 6.39 8 2\nTripwire H 1.2 7 5\nAuditd H 3.36 9 8\nSnort S,B 6.72 8 3\nHoneyd S,B 3.5 8 5\nNepenthes S,B 1.54 8 5\nOSSEC H 4.32 10 3\nIPFirewall (IPFW) S,B 2.8 6 4\nArpwatch S 0.48 2 5\nWireshark(Ethereal) S,B 2.75 2 9\nFig. 1. An example network\n5.1 Example network\nThe network shown in Figure 1 comprises of two servers, on segment S1, and\ntwo clients, on segment S2. The backbone link B2 connects the two segments\nand the link B1 serves as the connection to the outside world. The two servers\nare labelled FTP and WWW to reflect the services they offer. They are the\nmost significant asset to the network operator providing profitable services and\nincurring an expensive downtime, and are more likely to be targeted by intruders.\nAs shown in Table 2, we assign a risk profile of 5 to both servers and a 1 to both\nclients. The servers incur a disruption cost of 8 compared to the 1 for clients.\nThe relative load factor for servers is also high, assigned a 7 to a 1 for clients. We\nassign a risk profile of 9 to B1 relatively higher to a 7 for B2 considering that B1\nis exposed to externally sourced traffic which can potentially target servers or\nclients. Risk profiles 4 and 2 assigned to the two segments S1 and S2 respectively\nare due to the value of the hosts residing on them. The disruption costs 9 and\n7 for B1 and B2 respectively reflect the level of disruption likely, while the load\nfactor for the two locations has a similar ratio of 9 and 6 respectively.\nTable 2. Risk, load and disruption cost assignments\nLocation L LT R(L) LF (L) D(L)\nC1 H 1 1 1\nC2 H 1 1 1\nFTP H 5 7 8\nWWW H 5 7 8\nS1 S 4 7 6\nS2 S 2 4 3\nB1 B 9 9 9\nB2 B 7 6 7\n5.2 Deployment scenarios\nWe consider three possible deployment scenarios. Scenario 1 focuses on host-\nbased IDS solutions. Open Source Host-based Intrusion Detection System (OS-\nSEC) is an open source solution that provides host-based intrusion detection\nand prevention. A total of four OSSEC clients are chosen to deploy at the four\nlocations as shown in Table 3. Total deployment value adds up to -2.28. Sensors\nplaced on the two servers add almost double the deployment value than the\nsensors placed on clients; such value is justified given that the servers are at a\nhigher risk than clients despite higher costs. Deployment value indicates high\ncosts of deploying an entirely host-based solution.\nTable 3. Deployment for Scenario 1\nL A R(L) Cap(A) CostT V (A, L)\nFTP OSSEC 5 4.32 39 0.55 [-0.45]\nWWW OSSEC 5 4.32 39 0.55 [-0.45]\nC1 OSSEC 1 4.32 14 0.31 [-0.69]\nC2 OSSEC 1 4.32 14 0.31 [-0.69]\nTable 4. Deployment for Scenario 2\nL A R(L) Cap(A) CostT V (A, L)\nB2 Snort 7 6.72 33 1.43\nB1 Snort 9 6.72 44 1.37\nS1 Cisco IOS Port Security 4 1.92 46 0.17 [-0.83]\nTable 5. Deployment for Scenario 3\nL A R(L) Cap(A) CostT V (A, L)\nB2 Snort 7 6.72 33 1.43\nFTP HP VT 5 6.39 30 1.07\nWWW HP VT 5 6.39 30 1.07\nScenario 2 focuses on network-based solutions. As shown in Table 4, two\nSnort sensors are deployed on the two most significant locations along with a\nswitch port security mechanism on one of the segments. The total deployment\nvalue adds up to 1.97. The two Snort sensors are deployed on backbone links B1\nand B2, and the port security mechanism is deployed at S1 given the higher risk\nprofile. The deployment value is significantly better than the first scenario. The\nsecond scenario benefits from a high capability sensor such as Snort deployed on\nthe two most critical locations providing both near maximum visibility of the\nnetwork at B2, and monitoring traffic to and from the external gateway at B1.\nScenario 3 combines both types of sensors. As shown in Table 5 the two\nhost-based sensors are deployed on the two servers and a single Snort sensor is\nplaced on the most significant link serving all externally sourced (and bound)\ntraffic. The total deployment value is 3.56. Both backbone links are critical for\nmonitoring both all traffic headed to and from the servers, and traffic passing in\nand out through the external gateway. While B1 provides visibility of all external\ntraffic to and from the servers, it does not suffice as it fails to cover traffic between\nthe internal segments. B2 provides good coverage but fails to offer any view of\nexternal traffic in and out of the clients on S2. The Snort sensor is deployed on\nB2 given the better value compared to B1; this is primarily due to the higher\ncost incurred for deploying on B1 even though the risk profile for such a location\nis higher. The deployment value for the third scenario is almost double the value\nfor second scenario. The deployment is designed such that the efficient host-\nbased sensors are chosen for the two most valuable assets (servers), along with\na single network-based sensor. The choice of deploying Snort on B2 over B1 is\nindicative of the costs involved with respect to the risk profile.\n6 Related work\nRelated work can be broadly divided in two categories: cost-benefit analysis of\nsensors taking into account efficiency and costs with disregard for the network\ndeployed on [4\u20136], and placement of sensors in a given network characterised\nusing system vulnerabilities but ignoring characteristics of sensors [7\u20139].\nLee et al [5] present a cost-benefit model deployments to evaluate data min-\ning approaches to classifying and responding to intrusions in network traffic\nstreams. They use various costs including intrusion damage, the type of re-\nsponse launched, and time and computational resources required for processing,\nto present a decision model for executing response to intrusions, where the lower\nthe total cost the better the value. Factors such as detection efficiency and sever-\nity of configuration are not explicitly modelled; they are likely to impact response\ncosts which determine consequential costs.\nNoel and Jajodia [7] present an approach for optimal sensor placement. They\nuse attack graphs to represent possible paths taken by potential intruders to at-\ntack a given asset. Such graphs are constructed in a topological fashion taking\ninto account both vulnerable services and applications that allow intruders to\nexploit nodes and use them as launch pads for further penetration, and protec-\ntive measures such as firewalls deployed to restrict connectivity between nodes.\nDeployments are devised to monitor all paths using least number of sensors. This\nis dealt with as a set cover problem and a greedy algorithm is used: each router\nnode allows for monitoring of certain graph edges and the challenge is to find a\nminimum set of routers that cover all edges. A vulnerability-driven approach [7]\nto deploying sensors overlooks factors such as traffic load on nodes. As a result\nthe deployment is optimised such that the more paths that go through a node\nthe more likely it is chosen for placement. The focus is limited on network-based\nsensors and sensor efficiency or costs are not modelled.\nSheyner et al [9] present another approach based on attack graphs. They\nmodel networks as finite state machines and construct attack graphs using a\nsymbolic model checker representing attacks as simple state transitions. Attack\ngraphs produced in this way allow a network model to be automatically checked\nfor a particular safety property given a set of permissible attacks. Minimisation\ntechniques are used to deduce what attacks go undetected, what attacks should\nbe prevented for the safety property to be satisfied, and using probabilistic in-\nformation what is the likelihood of detecting particular attacks. The model [9]\ndoes not characterise the network or sensors; deployment value then becomes\nmerely a measure of the likelihood of events being detected and prevented.\nRolando et al [8] introduce a formal logic-based approach to describe net-\nworks, and automatically analyse them to generate signatures for attack traffic\nand determine placement of sensors to detect such signatures. Their notation to\nmodel networks is simple yet expressive to specify network nodes and intercon-\nnecting links in relevant detail. While there are advantages to using a formal\nmodel, such an approach may not be scalable. The formal notation allows for a\nmore coarse-grained specification but it is not clear whether the resulting sensor\nconfigurations are even likely to be feasible for real environments. Moreover, the\nnotation does not allow for modelling any system-level location or sensor char-\nacteristics. The approach is demonstrated for a limited class of attacks for which\nthe logical predicates are simple to express. More complicated attacks will not\nbe as simple to express and likely to incur considerable computational resources.\n7 Discussion\nThe deployment value model and strategy presented in this paper have been\nimplemented using simple exhaustive search. Early results are promising for\nlarge scale deployments.\nMeans to reason and compare intrusion detection sensor deployments are\nimportant to judge the ability of such sensors to make a difference individually\nor in combination. Our aim is to represent the complex relationship between the\nsensor and network characteristics in as simple a model as possible. The approach\npresented here has characterised a variety of features of sensors, and along with\nrisk profiling and load characterisation for networks, such characteristics provide\na system-smart view of sensor deployments. Work is underway to analyse large\nreal deployments that serve to reflect on these aspects of the model. The current\ndeployment strategy, adopted in Section 4.2, is designed to place sensors with a\ngoal to maximise deployment value. Alternative strategies could be designed to\nemphasise risk reduction by improving the design of the network.\nAcknowledgment\nThis work is a joint effort by Cranfield and York universities, and funded by\nEngineering and Physical Sciences Research Council (EPSRC) (EP\/E028268\/1).\nReferences\n1. Shaikh, S.A., Chivers, H., Nobles, P., Clark, J.A., Chen, H.: Characterising intrusion\ndetection sensors. Network Security 2008(9) (September 2008) 10\u201312\n2. Shaikh, S.A., Chivers, H., Nobles, P., Clark, J.A., Chen, H.: Characterising intrusion\ndetection sensors, part 2. Network Security 2008(10) (October 2008) 8\u201311\n3. Chivers, H.: Security Design Analysis. York Computer Science Technical Report\nYCS 2006\/06, University of York, UK (2006)\n4. Cavusoglu, H., Mishra, B., Raghunathan, S.: The value of intrusion detection sys-\ntems in information technology security architecture. Information Systems Research\n16(1) (March 2005) 28\u201346\n5. Lee, W., Fan, W., Miller, M., Stolfo, S.J., Zadok, E.: Toward cost-sensitive modeling\nfor intrusion detection and response. Journal of Comp. Sec. 10(1-2) (1993) 5\u201322\n6. Stakhanova, N., Basu, S., Wong, J.: A cost-sensitive model for preemptive intru-\nsion response systems. In: 21st International Conference on Advanced Information\nNetworking and Applications (AINA 2007). (May 2007) 428\u2013435\n7. Noel, S., Jajodia, S.: Optimal ids sensor placement and alert prioritization using\nattack graphs. Journal of Network and Systems Management 16(3) (September\n2008) 259\u2013275\n8. Rolando, M., Rossi, M., Sanarico, N., Mandrioli, D.: A formal approach to sensor\nplacement and configuration in a network intrusion detection system. In: Pro-\nceedings of the 2006 International Workshop on Software Engineering for Secure\nSystems, ACM Press (May 2006) 65\u201371\n9. Sheyner, O., Haines, J., Jha, S., Lippmann, R., Wing, J.M.: Automated generation\nand analysis of attack graphs. In: Proceedings of the 2002 IEEE Symposium on\nSecurity and Privacy. (May 2002) 273\u2013284\n"}
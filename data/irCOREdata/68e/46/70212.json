{"doi":"10.1016\/j.cag.2006.07.002","coreId":"70212","oai":"oai:eprints.lancs.ac.uk:12939","identifiers":["oai:eprints.lancs.ac.uk:12939","10.1016\/j.cag.2006.07.002"],"title":"Supporting content scheduling on situated public displays.","authors":["Storz, Oliver","Friday, Adrian","Davies, Nigel"],"enrichments":{"references":[{"id":16312505,"title":"Brignull et al.: Dynamo: a public interactive surface supporting the cooperative sharing and exchange of media.","authors":[],"date":"2003","doi":"10.1145\/964696.964714","raw":"S. Izadi, H. Brignull et al.: Dynamo: a public interactive surface supporting the cooperative sharing and exchange of media. UIST \u201903: Proceedings of the 16th annual ACM symposium on User interface software and technology, pp. 159\u2013168. ACM Press, New York, NY, USA, 2003. ISBN 1-58113-636-6.","cites":null},{"id":16312484,"title":"Coping with temporal constraints in multimedia presentation planning.","authors":[],"date":"1996","doi":null,"raw":"E. Andr\u00b4 e and T. Rist: Coping with temporal constraints in multimedia presentation planning. Thirteenth National Conference on Arti\ufb01cialIntelligence, pp. 142\u2013147. 1996.","cites":null},{"id":16312487,"title":"Edwards et al.: Public and Situated Displays, chap. Supporting Extensible Public Display Systems with Speakeasy.","authors":[],"date":"2003","doi":"10.1007\/978-94-017-2813-3_15","raw":"J. Black, W. Edwards et al.: Public and Situated Displays, chap. Supporting Extensible Public Display Systems with Speakeasy. Kluwer Academic Publishers, 2003.","cites":null},{"id":16312516,"title":"Elvin has left the building: A publish\/-subscribe noti\ufb01cation service with quenching.","authors":[],"date":"1997","doi":null,"raw":"B. Segall and D. Arnold: Elvin has left the building: A publish\/-subscribe noti\ufb01cation service with quenching. AUUG97. Brisbane, Australia, 1997.","cites":null},{"id":16312490,"title":"Exploring Bluetooth based Mobile Phone Interaction with the Hermes Photo Display.","authors":[],"date":"2005","doi":"10.1145\/1085777.1085786","raw":"K. Cheverst, A. Dix et al.: Exploring Bluetooth based Mobile Phone Interaction with the Hermes Photo Display. Proceedings of the seventh ACM International Symposium on Human Computer Interaction with Mobile Devices and Services (MobileHCI \u201905) 2005, pp. 47\u201354. Salzburg, Austria, 2005.","cites":null},{"id":16312518,"title":"Gunawan et al.: Vista: interactive co\ufb00ee-corner display. CHI \u201905: CHI \u201905 extended abstracts on Human factors in computing systems,","authors":[],"date":"2005","doi":"10.1145\/1056808.1056818","raw":"M. Wichary, L. Gunawan et al.: Vista: interactive co\ufb00ee-corner display. CHI \u201905: CHI \u201905 extended abstracts on Human factors in computing systems, pp. 1062\u20131077. ACM Press, New York, NY, USA, 2005. ISBN 1-59593-002-7.","cites":null},{"id":16312510,"title":"Liongosari: UniCast, OutCast & GroupCast: Three Steps Toward Ubiquitous, Peripheral Displays.","authors":[],"date":"2001","doi":"10.1007\/3-540-45427-6_28","raw":"J. F. McCarthy, T. J. Costa and E. S. Liongosari: UniCast, OutCast & GroupCast: Three Steps Toward Ubiquitous, Peripheral Displays. UbiComp \u201901: Proceedings of the 3rd international conference on Ubiquitous Computing, pp. 332\u2013345. Springer-Verlag, London, UK, 2001. ISBN 3-540-42614-0.","cites":null},{"id":16312497,"title":"Public and Situated Displays, chap. Supporting communities of practice with large screen displays,","authors":[],"date":"2003","doi":"10.1007\/978-94-017-2813-3_11","raw":"A. Grasso, M. Muehlenbrock, F. Roulland and D. Snowdon: Public and Situated Displays, chap. Supporting communities of practice with large screen displays, pp. 261\u2013282. Kluwer Academic Publishers, 2003.","cites":null},{"id":16312513,"title":"Social coordination around a situated display appliance. CHI \u201903: Proceedings of the SIGCHI conference on Human factors in computing systems,","authors":[],"date":"2003","doi":"10.1145\/642611.642624","raw":"K. O\u2019Hara, M. Perry and S. Lewis: Social coordination around a situated display appliance. CHI \u201903: Proceedings of the SIGCHI conference on Human factors in computing systems, pp. 65\u201372. ACM Press, New York, NY, USA, 2003. ISBN 1-58113-630-7.[11] D. M. Russell and R. Gossweiler: On the Design of Personal & Communal Large Information Scale Appliances. UbiComp \u201901: Proceedings of the 3rd international conference on Ubiquitous Computing, pp. 354\u2013361. Springer-Verlag, London, UK, 2001. ISBN 3-540-42614-0.","cites":null},{"id":16312508,"title":"The Interactive Workspaces Project: Experiences with Ubiquitous Computing Rooms.","authors":[],"date":"2002","doi":"10.1109\/mprv.2002.1012339","raw":"B. Johanson, A. Fox and T. Winograd: The Interactive Workspaces Project: Experiences with Ubiquitous Computing Rooms. IEEE Pervasive Computing Magazine, vol. 1(2), Apr. 2002.","cites":null},{"id":16312502,"title":"The noti\ufb01cation collage: posting information to public and personal displays.","authors":[],"date":"2001","doi":"10.1145\/365024.365339","raw":"S. Greenberg and M. Rounding: The noti\ufb01cation collage: posting information to public and personal displays. CHI \u201901: Proceedings of the SIGCHI conference on Human factors in computing systems, pp. 514\u2013521. ACM Press, New York, NY, USA, 2001. ISBN 1-58113-327-8.","cites":null},{"id":16312494,"title":"The Plasma Poster Network: Posting Multimedia Content in Public Places.","authors":[],"date":"2003","doi":"10.1007\/978-94-017-2813-3_10","raw":"E. Churchill, L. Nelson, L. Denoue and A. Girgensohn: The Plasma Poster Network: Posting Multimedia Content in Public Places. Human-Computer Interaction INTERACT \u201903, pp. 599\u2013606. IOS Press, 2003.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2006","abstract":"There is increasing interest in creating networks of situated public displays that offer novel forms of interaction and rich media content - often as work towards a vision of ubiquitous computing or ambient multimedia. In this paper we present an infrastructure developed as part of the e-Campus project that is designed to support the coordinated scheduling of rich media content on networks of situated public displays. The design of the system was informed by an iterative process of developing, deploying and evaluating a set of three technology probes. The resulting system provides flexible support for the construction of domain-specific scheduling approaches on top of a common, domain-independent API. Using this approach we are able to support a combination of both statically scheduled content and interactive content across multiple displays. The API provides support for transactional semantics, allowing developers of schedulers to reliably schedule content across displays in the presence of conflicts and failures without negative impact on running applications","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/70212.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/12939\/1\/storz%2Dscheduling%2Decampus%2Dcag2006%2Dpreprint.pdf","pdfHashValue":"bc3120dc74dbe05b95783eca452009c21ad6553f","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:12939<\/identifier><datestamp>\n      2018-01-24T00:04:32Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Supporting content scheduling on situated public displays.<\/dc:title><dc:creator>\n        Storz, Oliver<\/dc:creator><dc:creator>\n        Friday, Adrian<\/dc:creator><dc:creator>\n        Davies, Nigel<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        There is increasing interest in creating networks of situated public displays that offer novel forms of interaction and rich media content - often as work towards a vision of ubiquitous computing or ambient multimedia. In this paper we present an infrastructure developed as part of the e-Campus project that is designed to support the coordinated scheduling of rich media content on networks of situated public displays. The design of the system was informed by an iterative process of developing, deploying and evaluating a set of three technology probes. The resulting system provides flexible support for the construction of domain-specific scheduling approaches on top of a common, domain-independent API. Using this approach we are able to support a combination of both statically scheduled content and interactive content across multiple displays. The API provides support for transactional semantics, allowing developers of schedulers to reliably schedule content across displays in the presence of conflicts and failures without negative impact on running applications.<\/dc:description><dc:date>\n        2006<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:relation>\n        http:\/\/dx.doi.org\/10.1016\/j.cag.2006.07.002<\/dc:relation><dc:identifier>\n        Storz, Oliver and Friday, Adrian and Davies, Nigel (2006) Supporting content scheduling on situated public displays. Computers and Graphics, 30 (5). pp. 681-691. ISSN 0097-8493<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/12939\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1016\/j.cag.2006.07.002","http:\/\/eprints.lancs.ac.uk\/12939\/"],"year":2006,"topics":["QA75 Electronic computers. Computer science"],"subject":["Journal Article","PeerReviewed"],"fullText":"Supporting Content Scheduling on Situated Public\nDisplays\nOliver Storz, Adrian Friday, Nigel Davies\nComputing Department, Infolab 21, Lancaster University, Lancaster, UK\n{oliver,adrian,nigel}@comp.lancs.ac.uk\nOctober 9, 2006\nAbstract\nThere is increasing interest in creating networks of situated public\ndisplays that offer novel forms of interaction and rich media content\n\u2013 often as work towards a vision of ubiquitous computing or ambi-\nent multimedia. In this paper we present an infrastructure developed\nas part of the e-Campus project that is designed to support the co-\nordinated scheduling of rich media content on networks of situated\npublic displays. The design of the system was informed by an iter-\native process of developing, deploying and evaluating a set of three\ntechnology probes. The resulting system provides flexible support for\nthe construction of domain-specific scheduling approaches on top of a\ncommon, domain-independent API. Using this approach we are able to\nsupport a combination of both statically scheduled content and inter-\nactive content across multiple displays. The API provides support for\ntransactional semantics, allowing developers of schedulers to reliably\nschedule content across displays in the presence of conflicts and failures\nwithout negative impact on running applications.\n1 Introduction\nIncreasingly we are witnessing the penetration of display technologies into\nurban environments and public spaces. In the UK, the BBC have deployed\nseveral large situated displays (the \u2018big screens\u2019) in urban centres1. In airport\nterminals, train stations and even on public transport itself, physical posters\nhave been replaced with LCD or Plasma displays. Projectors and steerable\nprojections turn conventional surfaces such as floors and walls into displays.\nThese displays present us with a combination of digital signage, information,\ntraditional broadcast media and advertising. This trend will only continue\nas novel low-cost display technologies such as printable displays and e-paper\nmove toward production.\n1http:\/\/www.bbc.co.uk\/bigscreens\n1\nFigure 1: Opening of the Metamorphosis installation using the public dis-\nplays in the underpass. Inset: members of .:thePooch:. arts collective keep-\ning a close eye on the system console.\nIn the future we believe the situated and dynamic nature of these dis-\nplays will mean that new interactive and context-aware applications become\npossible \u2013 extending such systems well beyond the current state-of-the-art\nin digital signage. For example, the displays could:\n\u2022 select content or adapt the the presentation of content, e.g. to target\nthe interests of passers by.\n\u2022 enable more complex forms of interaction (e.g. using mobile devices\n[3] or providing steerable content2).\n\u2022 form a network of multiple displays that can be exploited simultane-\nously or in sequence over time to present information in novel ways,\ne.g. supporting navigation, games, visualisations, art and community\ninteraction.\nWe are seeking to prototype such an environment in the e-Campus\nproject. In e-Campus we are deploying a series of display installations in\npublic spaces around our campus. One of the principle challenges in sup-\nporting these deployments is to create a software infrastructure that allows\n2http:\/\/www.blendomedia.com\nmultiple concurrent applications to schedule content across the shared dis-\nplay network. This is crucial to enable scheduling requests to be generated\nfrom a wide variety of sources including interactive applications and domain\nspecific schedulers. For example, scheduling requests might be generated\nfrom multimedia presentation software or multimedia document viewers. In\nthis paper we discuss the design and implementation of such a software in-\nfrastructure \u2013 focusing specifically on the computational model and API\nthat we provide to programmers wishing to develop schedulers for the net-\nwork of displays. To understand the requirements and refine our design to\nbetter support this domain we\u2019ve iterated our software through three public\ndisplay deployments. The resulting design offers a simple API for support-\ning the creation of heterogeneous content schedulers and provides fine-grain\ncontrol over the mapping of content to one or more displays. Importantly,\nthe API supports a transaction like concept that ensures content only be-\ncomes visible if all needed display and content resources are available. We\nhave built a working implementation of this API and it is currently being\nused to support an ongoing deployment on our University campus.\nThe paper is structured as follows: in section 2 we describe the iterative\nprocess and technology probes we\u2019ve used to refine the design of our soft-\nware and reflect on the design impact on our API at each stage. In section\n3 we describe the computational model, API and associated system sup-\nport that we provide to programmers for scheduling content on a network\nof situated displays. Section 4 describes and evaluates our current imple-\nmentation, reflecting on our use of the API in supporting the most recent of\nour deployments. We discuss related work in section 5 and finish with our\nconcluding remarks in section 6.\n2 Initial Technology Probes\nTo date we have deployed three situated display prototypes: a digital signage\nsystem at a conference, an installation at a local gallery, and a larger, more\npermanent installation in an underground bus station on campus. These\nprototypes have served as technology probes, generating requirements for,\nand allowing us to experiment with and refine the design of our software. In\nthis section we review each of the installations and discuss the impact and\nrefinements to our design.\n2.1 Installation 1: WMCSA 2004 conference signage\nOverview\nOur first technology probe deployed a digital signage solution at the 6th\nIEEE Workshop on Mobile Computing Systems and Applications, WMCSA\n2004. The WMCSA system consisted of four public displays stationed out-\nside each of the entrances to the main auditorium and demo room. The\ndisplays provided a rolling display of information for delegates tailored to\nthe display\u2019s location (proximity to ongoing conference activities) and the\ntime of day. Each display was able to show information relevant to the talks\nbeing presented in the adjacent rooms, about activities in the wider locale,\nand navigation symbols directing delegates to refreshments at appropriate\ntimes of the day. The displays were interconnected via a local network, al-\nlowing us to synchronise content across the displays on a per content item\nbasis.\nOne of the key issues we sought to explore with WMCSA was how to\nsimplify the process of injecting content into the system and of mapping that\ncontent to displays. We did this by exploiting a separation of concerns: au-\nthors could create content items (images, web pages, RSS feeds and videos)\nand request these to be mapped dynamically to the network of displays using\na constraint based scheduler. The author could specify a range of constraints\nfor each piece of content in a scheduling request, including:\n\u2022 temporal (\u201cdo not start before time t1\u201d, \u201cdo not finish after time t2\u201d)\n\u2022 duration (and whether the content item should repeat)\n\u2022 the set of displays to target\n\u2022 the required coordination between the displays\n\u2022 the priority of the content\nThe content of the WMCSA system was therefore reduced to a set of\nscheduling requests: some content had a requirement for synchronisation\nand temporal coherence (e.g. \u2018arrows directing delegates to lunch\u2019), whereas\nother content ran for the duration of the paper sessions but only on single\n(uncoordinated) displays (see figure 2). A scheduler associated with each\ndisplay observed these requests and attempted to construct a timeline for the\ndisplay that best matched the requested set of constraints. Where content\nwas required to be synchronised across displays, a distributed agreement\nprotocol was used to converge on a mutually agreeable time. The priority\nsystem allowed us to easily introduce \u2018background content\u2019 of a low priority.\nOnce content had been programmed into a timeslot only higher priority\ncontent could displace it (reducing the overall search complexity for schedul-\ning each job). Consequently, the order in which the scheduling requests were\nsubmitted could affect the resulting schedules in cases where more than one\npiece of content\u2019s constraints were satisfied. The timeline based system al-\nlowed us to introduce content items in advance of the point at which they\nwere due to be displayed (we anticipated being able to use the timeline in\nlater iterations to generate electronic programme guides and feed deadlines\ninto content caching and distribution mechanisms).\nFigure 2: A WMCSA situated public displays.\nDesign Reflections\nFollowing our live deployment, we reflected on the efficacy of our design. It\nemerged that while the system was adequate for scheduling situated content\nfor a small number of displays in the environment it was intended to operate\nin, i.e. as a digital signage solution at a workshop, there were already a\nnumber of concerns especially relating to the suitability and flexibility of\nthe constraint-based scheduling approach for future deployments:\nScalability. The complexity of creating schedules using a constraint-based\napproach is tractable with small numbers of displays, content items\nand relatively short timelines However, the search time increases in\npolynomial time as these factors grow. As a result we had to conclude\nthat this approach wouldn\u2019t scale for larger planned future deploy-\nments.\nTypes of constraints. We found that the types of constraints we were\nable to support in this first prototype quite often did not allow us to\ntune the presentation in exactly the way we intended. For example,\nwe found ourselves unable to schedule content \u201dright after\u201d another\ncontent item had finished without tying both content items down to\nexact start and end times.\nInteractivity. As we planned to introduce interactive content into the\nschedule in the future (e.g. user steerable or contributed content),\nwe found that too great a degree of sophistication was required in\nengineering the constraints to adequately allow us to interrupt the\nschedule to insert the interactive content elements: the fact that we\nhad to specify a duration for each piece of content, determining exactly\nfor how long a piece of content would be displayed, made it impossi-\nble to deal with spontaneous, interactive applications that users would\nwant to interact with for an unspecified amount of time.\nSpatial and geometric reasoning. Much of the WMCSA content was lo-\ncation (and in the case of the \u2018navigation arrows\u2019 orientation) sensitive.\nFor this deployment we were able to \u2018hand craft\u2019 the constraints and\ncontent to ensure that the correct information was presented on the\nappropriate display given its position and orientation (e.g. the navi-\ngation arrow pointed in the correct direction!).\n2.2 Installation 2: Brewery Arts Centre VE Day 60th An-\nniversary Exhibition\nOverview\nThe second installation took place at a local arts centre (The Brewery Arts\nCentre in Kendal, Cumbria) as part of their 60th Anniversary VE Day cel-\nebrations. The installation was one element of an interactive exhibition of\nlocal wartime memorabilia and consisted of four main components: a set of\nthree large projected public displays (see figure 3), a video diary booth, a web\nbased diary, and \u2018the Kirlian Table\u2019 (an interactive art exhibit created by a\nlocal arts collective). The public displays showed a series of news footage\nand radio broadcasts evocative of the era, interspersed with images captured\nfrom the interactive table surface and video diary entries contributed by vis-\nitors to the exhibition. The video diary entries were also made available via\na local web based content management system.\nThe Brewery deployment represented a significant evolution of the under-\nlying software architecture: instead of entirely pre-scripted and orchestrated\ncontent, the system now needed to support the dynamic introduction of new\ncontent into the live system. In this new domain, we also found that we had\na glut of content (hours of video and audio, large numbers of still images\nand an increasing body of visitor contributed content) to choose from, re-\nquiring the introduction of random content selection (e.g. \u2018schedule an item\nof content from this pool\u2019).\nFigure 3: Photograph of the Brewery exhibition space with the projected\ndisplays visible in the background.\nDesign Reflections\nThe Brewery deployment was particularly illuminating: we found we had\ntwo unexpected requirements. Firstly, as part of an exhibition there was a\nneed to use the public displays in an aesthetically pleasing way, this meant\ncreation of schedules that had nice temporal and spatial characteristics. The\nrequirement for precise orchestration of when and where content would ap-\npear, or as importantly, when there would be gaps (nothing showing on\nthe displays) required that we increased the determinism of the scheduling\nprocess. We achieved this by modifying the schedulers to work in terms of\nabsolute time. However, we still found it difficult to create pleasing sched-\nules given the underlying constraint satisfaction engine. We simply had\nnot anticipated the need to schedule an absence of content; classically, the\nschedulers would aim to pack the timeline to achieve high display utilisation.\nSecondly, we found the need to handle randomly chosen content had a\nfurther impact on the system: the media content (audio, video etc.) was not\nnecessarily of the same duration. This meant that the timeline agreed by the\nschedulers needed to adapt on the fly as individual content items were chosen\n(to avoid \u2018dead air\u2019 or truncation of playback), this was further complicated\nby the need to synchronise presentation across the displays. This was not\neasily supported using the absolute time based scheduler. Furthermore,\nthere did not appear to be an obvious algorithm for handling this correctly\nin the general case.\nThe need for meta-data and workflow support (e.g. for approval), and\nmanagement of content versioning and delivery are open issues more typ-\nically addressed in content management systems (e.g. in the broadcasting\ndomain). We are taking these requirements forward in future developments\nof the architecture.\n2.3 Installation 3: The Underpass\nOverview\nThe last in our series of technology probes was deployed in an underground\nbus station on campus (called \u2018the underpass\u2019). The aim of the installation\nwas to to enrich this \u2018interstitial non-space\u2019 by providing a mixture of infor-\nmation and interactive content to people waiting for buses. In contrast to\nour other technology probes, the installation in the underpass was intended\nto be a long term deployment, i.e. lasting at least for several months, pos-\nsibly up to a few years. To fit the physical dimensions of the space, it was\ndecided to deploy three large-scale projected displays that would be aligned\nside-by-side. We also wanted to be able to either use each of the projection\nsurfaces independently or in combination as wide-screen displays of 2 or 3\ndisplays.\nThe initial focus was to employ a mixture of content, including artis-\ntic material, textual information and videos. Consequently the installation\nopened up with a piece of interactive art (called \u2018Metamorphosis\u2019, see figure\n1) that consisted of a set of 3 videos that were to be shown side-by-side and\nwere controlled by a Max\/MSP3 script. Metamorphosis also interfaced with\na small number of sensors that, when triggered by passing traffic, would\ninfluence the behaviour of the artistic installation.\nBeing based on Max\/MSP, commercial software currently only supported\non either Windows or Mac operating systems, the commissioned piece of\ncontent was incompatible with parts of the scheduling system we had been\nusing for the previous technology probes, as those parts were heavily tied into\nthe X Window System 4. We were therefore forced to run Metamorphosis\non a set of four dedicated Mac Mini machines that were independent from\nthe rest of the installation.\nTo support additional content besides the artistic installation, we de-\nployed a PC with a mutliheaded graphics card that allowed us to either ren-\nder different pieces of content on each head or render content that spanned\nacross two or more heads. An AV matrix switch5 and an embedded AMX\ncontroller6 were put in place to allow us to switch between content rendered\non the PC and content rendered on the dedicated Mini Macs.\nDesign Reflections\nThe need to support an interactive piece of art that would not integrate\nwith other parts of the eCampus system and that could only be hosted on\nseparate machines made us aware of the requirement to be able to support\n3http:\/\/www.cycling74.com\/products\/maxmsp\n4http:\/\/www.opengroup.org\/\n5http:\/\/www.sierravideo.com\/\n6http:\/\/www.amx.com\nnon-standard hardware setups that, for example, require video inputs on\ndisplays to be switched to different sources during runtime.\nAs the AV matrix switch made it possible to switch any video source\nto none or one or more projectors, our previous model addressing displays\nin which each video output device, i.e. a monitor or a projector, was at-\ntached to exactly one video source, was clearly no longer valid. Moreover,\nscheduling a piece of content now not only involved handling contention be-\ntween different pieces of content on single displays, but included the need\nto arbitrate between different machines (PC or Mac Mini) competing for a\nprojector.\nFinally, and possibly most importantly, although Metamorphosis was\nphysically distributed onto a number of machines, the videos were designed\nto be shown simultaneously and side-by-side on all three projectors. It\ntherefore did not make any sense to schedule Metamorphosis in any form\nother than as an atomic unit that would be made visible if and only if all\nthree projectors were available.\n3 Design\n3.1 Requirements\nAs outlined in section 2, our initial studies put forward strong requirements\nfor being able to support not only a single scheduling model, but rather a\nwhole range of diverse and domain-specific scheduling approaches that en-\nable us to support a combination of statically scheduled content, interactive\ncontent, as well as content of dynamic or unknown length. During our initial\ndeployments it also became clear that an architecture for e-Campus would\nhave to support the scheduling of content that spanned multiple displays\nand operate on a multitude of hardware platforms, some of which would be\ncustom-crafted and would therefore not necessarily fit the classic view of a\npublic display, i.e. a PC and an attached plasma screen monitor. We identi-\nfied the following key design requirements for our scheduling infrastructure:\n\u2022 Support for scheduling content with a wide range of absolute and rel-\native timing constraints (e.g. show this content at 10am, every day at\n10am, just after the news or always no more than an hour before the\nweather bulletin).\n\u2022 Support for scheduling content across multiple displays in an atomic\nfashion (e.g. display this video on all the displays or none of them).\n\u2022 Support for the rapid introduction of interactive content (e.g. triggered\nby user presence or interaction).\n\u2022 Support for numerous independently developed domain specific sched-\nulers that can share the display network.\nscheduler scheduler scheduler\ndisplay\ninvoke operations on\napplications applications\ncontent\ndisplay\nhandler\nhandlerhandler\nhandler\nhandlerhandler\nFigure 4: Illustration of computational model of the e-Campus system.\n\u2018Schedulers\u2019 create \u2018applications\u2019 that render content on \u2018displays\u2019. \u2018Han-\ndlers\u2019 are policy modules that arbitrate conflicts for displays.\n\u2022 Provide an abstraction layer to free the scheduler developer from con-\ncerning themselves with the various video and audio sources\/ sinks\nand switching operations these necessitate.\n3.2 Computational Model\nIn order to support the creation of multiple domain specific schedulers that\nassist us in meeting the above requirements, we have attempted to factor out\nthe core functionality of the system into an abstract, installation indepen-\ndent computational model and an associated scheduling API. We describe\nthese in the following sections.\n3.2.1 Overview\nThe computational model is a simplified virtualised form of a hardware\ndeployment. It consists of a small number of entities, i.e. displays, ap-\nplications, schedulers and handlers (see figure 4). Schedulers are written\nwhenever a new requirement is introduced whose needs are not met by the\nexisting cadre of schedulers. A scheduler uses our scheduling API to cre-\nate and control applications that render content on displays. Handlers are\nneeded to catch cross-display conflicts for physical resources in installations\nthat permit such configurations.\nAt the core of the abstractions we provide is the concept of a display. A\ndisplay represents a possible outlet for content and there may be an n : m\nmapping between the actual computers & graphics hardware and physical\ndisplay devices in any given installation. In the Underpass for example,\nthere are seven conceptual displays: one for each mini-mac, one for each\naddressable head of the PC workstations\u2019 video card and one \u2018widescreen\ndisplay\u2019 which is comprised of the first three heads of the PC workstation.\nEach display is assigned a unique identifier which is needed in the scheduling\nAPI operations, as we will see later. By directing content to a particular\ndisplay the actual mapping of where the content needs to be distributed to,\nwhich video outputs need to be selected etc. is hidden from the developer.\nHandlers represent optional policy components that are principally used\nto detect conflicts between conceptual displays when they\u2019re mapped to the\nsame physical output devices. Handlers are normally written or configured\nat deployment time when the possible displays are registered and is nom-\ninally the only entity that embodies topology specific knowledge about an\ninstallation. Once a handler is in place for a given hardware setup, this\nwould not normally be changed when new content or schedulers are intro-\nduced. Schedulers do not interact directly with handlers, and so although\nthey exist in our computational model, they are normally not visible to the\ntypical developer.\nFinally, applications represent software on a display end-system that\nis responsible for rendering content types. When the scheduler starts an\napplication, the system ensures that the content is available and that a\nsuitable renderer exists that can be mapped to the target output device (see\nsection 3.3).\n3.2.2 Scheduling API\nWe have defined an API for the schedulers to interact with the various\ncomputational components. The API consists of just four core operations:\nCreateApplication, ChangeState, Transition, and, TerminateAppli-\ncation. The operations are all blocking and return a status code on comple-\ntion, so the caller can determine whether each of the operations succeeded.\nWe also support a group abstraction (most operations can refer to one or\nmore displays or applications in a single API call). Crucially, operations\ncan be embedded in a transactional block which causes them to be executed\natomically (we describe this further towards the end of this section). We\nnow examine these operations in further detail:\n\u2022 CreateApplication causes an application to be instantiated on one or\nmore (potentially all) displays. Applications encapsulate media spe-\ncific renderers for content. CreateApplication passes a content iden-\ntifier to the application, but the content is not accessed immediately\nand this does not affect the visible state of the display. The operation\nonly succeeds if the application can be started on all specified displays.\nA system-wide unique process id is returned for use in further calls.\n\u2022 ChangeState allows the scheduler to control its applications. Applica-\ntions are initially created \u201dinvisible\u201d (i.e. the output does not appear\non the video output) and in an idle state. ChangeState is used to\ninform applications to access and prefetch their content using the con-\ntent id (currently a URL) passed when it was created. At this stage\nthe scheduler can determine that the content is available and can be\nrenderered, however, the application is still not visible on the display.\n\u2022 Transition instructs the displays to make a specified set of applica-\ntions visible (or invisible). Transition causes two actions to be ini-\ntiated: firstly, the display issues a ChangeState request to involved\napplications. If successful the involved displays also directly change\nthe visibility of those applications on the physical display, i.e. make\nthem visible or not visible. This operation corresponds roughly to the\nconcept of uniconifying\/mapping and iconifying\/unmapping windows\nin a typical windowing system. There is scope in the future to em-\nbelish these transitions with effects such as alpha blending to improve\nthe aesthetics of this transition.\n\u2022 TerminateApplication can be used by developers of schedules to ter-\nminate applications.\nThe scheduling API provides support for transactional semantics. A\ntransaction in our system can group one or more of the above operations.\nThe visibility of content on the displays is not affected until the transaction\nis committed. The transaction succeeds (and the content is made visible) iff\nall the operations in the transaction complete within the specified timeout\ninterval. Our transactions provide atomicity : if any single operation fails,\nthen the transaction aborts and the operations roll back. This allows devel-\nopers to reliably schedule content across multiple displays in the presence\nof potential conflicts and failures. We are also able to provide guarantees\nwith respect to isolation in two distinct domains \u2013 system state and content\nvisibility. In terms of state, changes to an application or a display\u2019s state are\nvisible only within a transaction (though the creation of new applications is\nvisible system wide in our current implementation). Crucially, we are also\nable to support isolation as it applies to the actual physical visibility of op-\nerations on displays; we call this form of isolation visual isolation. Visual\nisolation guarantees that an independent human observer looking at displays\ninvolved in a transaction will not be able to witness any intermediate states\nbefore the transaction is committed.\nFigure 5: Current e-Campus Architecture.\n3.3 Engineering Model\nOur deployments are constructed from commodity hardware running con-\nventional desktop operating systems. In mapping the above computational\nmodel onto a given deployment infrastructure we are thus required to deal\nwith the practical issues of creating and terminating processes that ren-\nder content on a heterogeneous set of machines, controlling the placement\nand size of application windows when processes are created and routing the\nresulting audio and video to the selected displays and output channels as\nnecessary. The engineering model for a typical deployment is shown in figure\n5.\nTo the right of the figure we represent the various machines that make up\nthe configuration of the installation. This part of the figure is colour coded to\nrepresent the software components illustrated to the left. We describe the\nengineering of each of the colour coded components (displays, schedulers\n(clients) and handlers) in more detail below. All of these component pro-\ncesses communicate with each other using events via a publisher-subscriber\nevent channel.\nDisplays. Each machine in an installation typically offers one or more con-\nceptual displays (as discussed in section 3). Each conceptual display is\nmanaged by a display process running on the end-system. The display\nprocess is required to address two issues: firstly, the creation and termi-\nnation of application processes that render the content, and secondly,\nthe management of the application windows containing the rendered\ncontent. For legacy reasons in our current engineering model the dis-\nplay processes interact with a local window manager sub-component\nthat oversees the position, sizing and visibility of application windows.\nEach operating system we support requires its own native window\nmanager to interface with its default windowing system.\nDisplay processes handle the requests issued by schedulers as a result of\ncalls to the scheduling API. Specifically, displays handle all operations\nthat require the management and visibility of renderer processes, i.e.\nCreateApplication, Transition and TerminateApplication. Dis-\nplay processes also provide a management interface supporting the\nregistration of handler processes (described below). Displays are re-\nsponsible for resolving cases of contention between applications on a\nsingle conceptual display (i.e. attempting to show content on a dis-\nplay where content is already visible). The default contention resolu-\ntion policy causes visible content to be replaced by the newly created\ncontent.\nApplications. Each conceptual application represents a piece of content\nbeing rendered. In engineering terms, a conceptual application maps\nonto an application process responsible for the execution of native ren-\nderer processes that can actually render and display the content. For\nperformance reasons, renderers must execute on the physical hardware\nconnected to the output device necessary for producing output on the\ncorrect physical device. Each application process is associated with a\nsingle display in the system. The application process contains a state\nmachine governing the condition of its underlying renderer: render-\ners may be IDLE, PREPARED, VISIBLE, NOT VISIBLE and\nTERMINATED (where PREPARED means the content is ready to\nbe displayed). Schedulers and display processes issue ChangeState\nrequests to cause application processes to transition between these\nstates.\nHandlers. Handlers can be introduced to provide support for additional\nuser specified conflict detection and resolution strategies (e.g. to de-\ntect conflicts for displays across machines). Each handler process can\nbe registered with one or more display processes. A handler can be\nconfigured to intercept requests going to or responses returning from\ndisplays. Handlers are passed the original request or response (as ap-\npropriate), which they are able to act upon, optionally modify and\npass back to the display; in this manner handlers can observe what is\nscheduled on the display and control whether it appears.\nProtocol\nAll processes described above communicate using a request\/response-based\nprotocol engineered on top of an asynchronous, publish\/subscribe-based\nevent channel. The event channel supports one to many communication.\nComponents subscribe to events based on their content (sets of (name,value)\npairs). Events are delivered to all components whose subscription matches\nthe content. All events in our model contains a combination of fields, includ-\ning event type, display identifiers, group identifiers and process identifiers,\nenabling any process in the system to determine whether they are responsi-\nble for handling an event or not. Requests and responses all carry a globally\nunique request identifier enabling processes to correlate responses and re-\nquests.\nAll processes generate periodic status messages that are used to imple-\nment fault detection. Status messages are used by the scheduler processes\nto detect and react to unknown events and faults during the execution of its\nschedule.\nTransactions\nTransactions are supported by all components in the system. All protocol\nmessages that are part of a transaction carry a unique transaction identifier\n(or id 0 if they are not part of a transaction). To ensure visual isolation\n(described in section 3.2.2), API operations are handled differently if they are\npart of a transaction: all operations that have a visual impact are batched\n(written into a log) until the component receives a commit or an abort\nmessage for that particular transaction. Resources are locked to ensure that\nonly one transaction can be committed at once. If a commit is received then\nthe sequence of visible actions is executed and the lock is released. Similarly,\nif an abort is received the actions from the transactional block are undone by\nrewinding the log of operations (e.g. a corresponding application or renderer\nmay be terminated) and the lock is again released.\nAll transactions, once started, are required to be completed within a\nspecified time window. Transactions that are not committed within this\nwindow are automatically aborted. An abort event can be generated ei-\nther by the process that initiated the transaction, or by any other process\nparticipating in the transaction.\n4 Evaluation\n4.1 Implementation Status\nThe implementation of the e-Campus infrastructure started in September\n2005. As we were aiming to be able to deploy the e-Campus infrastruc-\nture on a diverse set of hardware platforms, we naturally tried to ensure\nthat as much of our code as possible would be reusable across those dif-\nferent platforms. The prototypes at WMCSA and the Brewery Arts Cen-\ntre were therefore mostly implemented in Java. However, problems with\nthe performance and memory footprint of Java-based code led us to imple-\nment the e-Campus infrastructure described in this paper almost completely\nin Python7, an interpreted scripting language that is both lightweight and\navailable for a large range of platforms. Inter-process communication uses a\npublish\/subscribe-based eventing platform called Elvin [12]. All communi-\ncation between components is expressed using Elvin events that are delivered\nthrough a centralised Elvin server.\nThe current version of the e-Campus infrastructure can be executed on a\nrange of platforms including PPC and Intel based Macs running Mac OS X\nand PCs running GNU\/Linux. As discussed in section 3.3, our implementa-\ntion of the \u201cdisplay\u201d component is currently split into two sub-components:\na generic display, implemented in Python, and a window management com-\nponent. The latter handles platform-specific aspects of process creation,\nprocess termination and window management, such as the management of\nsize and position of content on displays, and mapping and unmapping of con-\ntent on displays, as well as transitional effects between as content is made\nvisible or not visible. As a legacy of the previous deployments, this window\nmanagement component is currently implemented in C.\nAs the configuration for the deployment in the University\u2019s underpass in-\ncludes an audio\/video matrix switch that makes it possible for two or more\ndisplays in our architecture to use the same audio or video output, we had\nto put mechanisms in place that were able to handle resulting conflicts. As\na result, we have implemented a class of handler component that is able\nto detect and arbitrate conflicts between displays. These handlers process\nTransition requests to \u201cvisible\u201d. If conflicting displays are already display-\ning content that is physically visible, the handlers will attempt to instruct\nthese conflicting displays to make their content \u201cnot visible\u201d. The imple-\nmented handlers preserve transactional semantics as described in section\n3.\nIn principle our current implementation is able to display any type of\ncontent as long as there are \u201cappropriate\u201d renders available for the chosen\nformat for either the Mac OS X or the GNU\/Linux operating system. In\nthis context the qualifier \u201cappropriate\u201d refers to the ability of the renderer\nto be controlled externally. In case of static media elements, such as web\npages, renderers are required to at least expose an interface (either an API\nor a command-line interface) that enables the infrastructure to instruct the\nrenderer which piece of content to load and render. Additionally, for dy-\nnamic media types, such as video or audio, a renderer is required to expose\ninterfaces to playback-related functionalities, i.e. \u201cplay\u201d and \u201cpause\u201d. Our\ncurrent version of the e-Campus infrastructure provides support for videos,\nweb pages and pictures on the PC platform, and Max\/MSP performances\nand RSS-backed news feeds on the Macintosh platform. However, we expect\nthe list of supported media types to be easily extendable in the near future.\n7http:\/\/www.python.org\/\n4.2 Qualitative Evaluation\nThe e-Campus API provides us with a starting point for the creation of new\nschedulers to meet the specific constraints of emerging applications. This\nis important as it allows us to be flexible in how we associate the display\nresources with new content (the types of content and presentation of that\ncontent evolves all the time as we gain experience of working with 3rd party\ncontributors). Thus far we have successfully used the API to create simple\nspecialised schedulers for the following applications:\n\u2022 A simple time based scheduler that displays an RSS feed of train\ntimetable information at peak travel times, and triggers the display\nof a video supplied by a local artist at assigned points throughout the\nday,\n\u2022 A further time based scheduler that cycles through different combina-\ntions of the underpass displays every 10 minutes showing a poster for\nthe then forthcoming student elections, and\n\u2022 A scheduler that monitors the motion sensors and triggers a switch\nto the Metamorphosis installation (note that Max\/MSP acts as its\nown self contained scheduler, so once the display resources have been\nobtained using the platform API, the installation is self contained until\nits execution is terminated). This also meant that the installation\ncould be developed with a high degree of autonomy by the artist, and\nneeded a minimum of additional code to integrate it with our system\n(the artist did not have to learn any new tools).\nAll of these content types require multiple and in most cases disjoint\nsets of display resources to be available. The arbitration between these\napplications and the underlying AV switching is hidden from the developer\nof the scheduler, as can be seen from the following Python extract:\ntry:\ngid = api.MakeGroupId ()\nt = transaction( api , None )\n# Create renderers\n( worked , pid ) = t.CreateApplication( \u2019display -1\u2019,\n\"http :\/\/e-content \/~demo\/cycling1.mpg\", gid )\n( worked , pid ) = t.CreateApplication( \u2019display -2\u2019,\n\"http :\/\/e-content \/~demo\/cycling2.mpg\", gid )\n# Cause renderers to prefetch content\n# (note use of group id)\nt.ChangeState( gid , APPLICATION_STATE_PREPARED )\n# Make content visible\nt.Transition( DISPLAY_ID_ALL , gid ,\nAPPLICATION_STATE_VISIBLE )\nt.commit ()\nexcept transaction_aborted , msg:\nprint \"Can \u2019t display cycling video\", msg\nWe found the API operations and transactional support intuitive and\nsimple to use. The schedulers for these applications were all written, tested\nand installed the same day. We have yet to port the constraint based sched-\nuler to use the new API (we anticipate that this may become necessary as\nthe volume of contributed content and number of displays increase) \u2014 cer-\ntainly, higher level abstractions are required for many of our end-user groups\n(this is a subject of future work).\nOne of the unexpected benefits of our current approach is that we can\nvery easily remove content from the system by stopping the scheduler re-\nsponsible for introducing this content. We are also able to more easily control\neach scheduler and to create custom test harnesses by copying and modi-\nfying existing schedulers. This has helped us in debugging our system (for\ninstance, we can create a modified scheduler that runs in \u2018fast forward\u2019 to\nreduce debugging time).\nThe transactional semantics of the platform have enabled us to reliably\ndeal with contention between schedulers without negatively impacting run-\nning applications. In the case where content fails to start, or one of the\nresources is not available (e.g. used by higher priority content), the trans-\naction fails and the new content does not get introduced. The content on\ndisplays is only changed if all the necessary display resources can be suc-\ncessfully preempted, the content renderers can be executed and the content\ncan be prefetched ready for display). This removes a lot of the complexity\nfrom handling the failure cases in the schedulers themselves and means that\nin the common case we do not switch to broken or unavailable content.\n5 Related Work\nSituated display research systems can mainly be divided into two groups\nof systems: displays designed to enhance collaborative work and to enable\nusers to share information, and largely non-interactive displays designed to\npresent informational content. While most systems only provide support for\none of those two modes, hybrid systems exist, e.g. IBM\u2019s BlueBoard [11].\nContent for collaborative displays, such as the Dynamo [7] system or\nBlueBoard, is mainly displayed in an interactive fashion, i.e. users directly\ndetermine when to display individual pieces of content. Scheduling of con-\ntent and contention for display space are therefore typically resolved using\nsocial protocols rather than systems support.\nInformational display systems, including UniCast and OutCast [9], the\nPlasma Poster Network [4], the Community Wall [5] and BlueBoard (when\nacting as ambient information display), typically source their display content\nfrom a continuously looping playlist of either automatically harvested or\nuser-contributed content. Content for the GroupCast [9] system is scheduled\non-the-fly according to the interests of users within the direct vicinity of the\ndisplay. The CommunityWall provides the possibility to prioritise individual\npieces of content, thereby determining the frequency with which these items\nare presented on the displays. In the Notification Collage system [6], the\nvisibility of content is generally determined by the order notifications are\nposted to the system. The system places new notifications in a random\nlocation on the display, possibly obstructing older pieces of content. In\nVista [13] content is randomly selected from a pool of available items. Other\ndisplay systems only present a limited set of application-specific content,\nfor example free\/occupied information of a meeting room in case of the\nRoomWizard [10]. All these systems also allow users to directly interact\nwith content, e.g. to learn more about an item of interest. The focus of our\nwork is somewhat different to these systems in that fine grained control over\nthe aesthetics and presentation of content is often important and multiple\napplications need to be supported simultaneously.\nBased on our investigations so far, only Dynamo, the Notification Col-\nlage and the GroupCast system are able to support dynamically scheduled\ncontent. However, unlike the system we have presented in this article, these\nsystems employ customised scheduling algorithms: based on the presence\nof users in the case of GroupCast, random in the case of Dynamo, and im-\nmediate scheduling for the the Notification Collage. None of these systems\nis able to support alternative scheduling approaches. Moreover, none of\nthe systems mentioned above provides support for coordinating interrelated\nitems of content across a set of displays.\nWhile the systems referred to so far were mainly aimed at understand-\ning issues related to user interaction and user acceptance arising in the con-\ntext of deploying and using public and situated displays, a small number\nof initiatives, such as the Interactive Workspaces project [8] and SpeakEasy\n[2], approach this field from a systems-oriented perspective, i.e. by pro-\nviding middleware platforms and tools to facilitate application development\nfor situated displays. However, neither of these projects explores the syn-\nchronisation of content across displays, nor the handling of failure in such\nsituations, equivalent to our transaction support.\nRecent years have also seen growing numbers of commercial deployments\nof public displays, for example in airports and shopping centres. These\ndisplays typically display a fixed cycle of pre-authored content. Examples\ninclude Sony\u2019s Ziris system 8 and InfoScreen 9. These often mature products\n8http:\/\/www.sonybiz.net\/retail\/displays\n9http:\/\/www.infoscreen.de\ncan provide a useful backbone for providing a dependable public display\nsurface on which to create a further platform for experimentation.\nFinally, multimedia presentation planning systems, such as the work\nput forward by Andre\u00b4 and Rist [1], provide solutions for domain-specific\nscheduling problems. Using the architecture presented in this paper, it is\npossible to employ presentation planning approaches as one of the many\npossible types of scheduler for e-Campus.\n6 Conclusion and Future Work\nAs display technologies continue to reduce in cost we will witness a world\nin which public displays permeate our environment. How we will use this\nenormous potential resource is very much open to question, but our initial\ndeployments show that such display networks have enormous potential for\nengaging with people beyond the typical domains of broadcast media and\nadvertising. Our underpass deployment in particular features a combination\nof rich interactive media that has been very well received and has helped\ninvigorate an otherwise dull physical environment.\nIn this paper we\u2019ve focused on the design and development of a software\narchitecture to support scheduling of content in such installations. The API\nallows for complex multi-display content to be conveniently created and\nscheduled in an intuitive way. Our platform abstracts away from the details\nof the hardware, and provides a form of transaction that makes conflicts\nand failures easy to handle. In addition, our transactions provide atomicity\nand a form of isolation called \u2018visible isolation\u2019 to ensure that content is only\ndisplayed when all of the scheduling requirements can be met. This is partic-\nularly valuable in multi-screen configurations. We have shown how this API\nhas been used in the first of a number of situated public display deployments\nto successfully coordinate the placement of content across displays.\nAcknowledgements\nThis work would not have been possible without the support of EPSRC\n(GR\/N15986: The Equator project). Our sincere thanks also to Lancaster\nUniversity for supporting the e-Campus initiative and to the Brewery Arts\nCentre, Welfare State, .:the Pooch:., Andrew Scott and Joe Finney and the\ne-Campus team for all their hard work on the technology probes. Metamor-\nphosis was funded in part by a grant from the Lancaster Friends Programme.\nReferences\n[1] E. Andre\u00b4 and T. Rist: Coping with temporal constraints in multime-\ndia presentation planning . Thirteenth National Conference on Artificial\nIntelligence, pp. 142\u2013147. 1996.\n[2] J. Black, W. Edwards et al.: Public and Situated Displays, chap.\nSupporting Extensible Public Display Systems with Speakeasy. Kluwer\nAcademic Publishers, 2003.\n[3] K. Cheverst, A. Dix et al.: Exploring Bluetooth based Mobile\nPhone Interaction with the Hermes Photo Display . Proceedings of the\nseventh ACM International Symposium on Human Computer Interac-\ntion with Mobile Devices and Services (MobileHCI \u201905) 2005, pp. 47\u201354.\nSalzburg, Austria, 2005.\n[4] E. Churchill, L. Nelson, L. Denoue and A. Girgensohn: The\nPlasma Poster Network: Posting Multimedia Content in Public Places.\nHuman-Computer Interaction INTERACT \u201903, pp. 599\u2013606. IOS Press,\n2003.\n[5] A. Grasso, M. Muehlenbrock, F. Roulland and D. Snowdon:\nPublic and Situated Displays, chap. Supporting communities of practice\nwith large screen displays, pp. 261\u2013282. Kluwer Academic Publishers,\n2003.\n[6] S. Greenberg and M. Rounding: The notification collage: posting\ninformation to public and personal displays. CHI \u201901: Proceedings of\nthe SIGCHI conference on Human factors in computing systems, pp.\n514\u2013521. ACM Press, New York, NY, USA, 2001. ISBN 1-58113-327-8.\n[7] S. Izadi, H. Brignull et al.: Dynamo: a public interactive surface\nsupporting the cooperative sharing and exchange of media. UIST \u201903:\nProceedings of the 16th annual ACM symposium on User interface soft-\nware and technology, pp. 159\u2013168. ACM Press, New York, NY, USA,\n2003. ISBN 1-58113-636-6.\n[8] B. Johanson, A. Fox and T. Winograd: The Interactive\nWorkspaces Project: Experiences with Ubiquitous Computing Rooms.\nIEEE Pervasive Computing Magazine, vol. 1(2), Apr. 2002.\n[9] J. F. McCarthy, T. J. Costa and E. S. Liongosari: UniCast,\nOutCast & GroupCast: Three Steps Toward Ubiquitous, Peripheral Dis-\nplays. UbiComp \u201901: Proceedings of the 3rd international conference\non Ubiquitous Computing, pp. 332\u2013345. Springer-Verlag, London, UK,\n2001. ISBN 3-540-42614-0.\n[10] K. O\u2019Hara, M. Perry and S. Lewis: Social coordination around a\nsituated display appliance. CHI \u201903: Proceedings of the SIGCHI confer-\nence on Human factors in computing systems, pp. 65\u201372. ACM Press,\nNew York, NY, USA, 2003. ISBN 1-58113-630-7.\n[11] D. M. Russell and R. Gossweiler: On the Design of Personal &\nCommunal Large Information Scale Appliances. UbiComp \u201901: Pro-\nceedings of the 3rd international conference on Ubiquitous Computing,\npp. 354\u2013361. Springer-Verlag, London, UK, 2001. ISBN 3-540-42614-0.\n[12] B. Segall and D. Arnold: Elvin has left the building: A publish\/-\nsubscribe notification service with quenching . AUUG97. Brisbane, Aus-\ntralia, 1997.\n[13] M. Wichary, L. Gunawan et al.: Vista: interactive coffee-corner\ndisplay . CHI \u201905: CHI \u201905 extended abstracts on Human factors in\ncomputing systems, pp. 1062\u20131077. ACM Press, New York, NY, USA,\n2005. ISBN 1-59593-002-7.\n"}
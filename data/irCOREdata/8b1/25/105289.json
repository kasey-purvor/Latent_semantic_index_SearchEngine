{"doi":"10.1081\/ETC-200040782","coreId":"105289","oai":"oai:wrap.warwick.ac.uk:126","identifiers":["oai:wrap.warwick.ac.uk:126","10.1081\/ETC-200040782"],"title":"The sensitivity of chi-squared goodness-of-fit tests to the partitioning of data","authors":["Smith, Jeremy (Jeremy P.)"],"enrichments":{"references":[{"id":8639247,"title":"A method for simulating stable random variables\u201d.","authors":[],"date":"1976","doi":"10.1016\/0167-7152(95)00113-1","raw":"Chambers, J. M., Mallows, C. L. and Stuck, B. W. (1976). \u201cA method for simulating stable random variables\u201d. Journal of the American Statistical Association, 71, 340-344.","cites":null},{"id":8639268,"title":"A probability distribution and its uses in fitting data\u201d.","authors":[],"date":"1979","doi":"10.2307\/1268517","raw":"Ramberg, J.S., Dudewicz, E.J., Tadikamalla, P.R. and Mykytka, E. (1979). \u201cA probability distribution and its uses in fitting data\u201d.  Technometrics, 21, 201-214.","cites":null},{"id":8639266,"title":"An evaluation of tests of distributional forecasts\u201d,","authors":[],"date":"2003","doi":"10.1002\/for.876","raw":"Noceti, P, Smith, J. and Hodges, S. (2003). \u201cAn evaluation of tests of distributional forecasts\u201d, Journal of Forecasting, 22, 447-455.","cites":null},{"id":8639274,"title":"Asymmetric density forecasts of inflation and the Bank of England\u2019s fan chart\u201d.","authors":[],"date":"1999","doi":"10.1177\/002795019916700111","raw":"Wallis, K.F. (1999).  \u201cAsymmetric density forecasts of inflation and the Bank of England\u2019s fan chart\u201d.  National Institute Economic Review, No. 167, 106-112.","cites":null},{"id":8639272,"title":"Chance and stability, stable distributions and their applications. VSP Utrecht, The Netherlands.","authors":[],"date":"1999","doi":"10.1515\/9783110935974","raw":"Uchaikin, V. V. and Zolotarev, V. M. (1999). Chance and stability, stable distributions and their applications. VSP Utrecht, The Netherlands.","cites":null},{"id":8639259,"title":"Chi-squared goodness-of-fit tests: cell selection and power\u201d.","authors":[],"date":"1990","doi":"10.1080\/03610919008812915","raw":"Koelher, K. J. and Gan, F. F.  (1990). \u201cChi-squared goodness-of-fit tests: cell selection and power\u201d. Communications in Statistics, B, 19, 1265.","cites":null},{"id":8639281,"title":"Chi-squared tests of interval and density forecasts, and the Bank of England\u2019s fan charts\u201d.","authors":[],"date":"2003","doi":"10.1016\/s0169-2070(02)00009-2","raw":"Wallis, K.F. (2003). \u201cChi-squared tests of interval and density forecasts, and the Bank of England\u2019s fan charts\u201d.  International Journal of Forecasting, 19, 165-175.","cites":null},{"id":8639265,"title":"Financial applications of stable distributions.","authors":[],"date":"1994","doi":"10.1016\/s0169-7161(96)14015-3","raw":"McCulloch, J. H. (1994). Financial applications of stable distributions. In Statistical methods in finance (Maddala, G.S., and Rao, C.R., Eds.) Elsevier, pp.393-425.","cites":null},{"id":8639251,"title":"How many classes in the Pearson chi-square test?\u201d,","authors":[],"date":"1973","doi":"10.2307\/2284803","raw":"Dahiya, R. C. and Gurland  J. (1973). \u201cHow many classes in the Pearson chi-square test?\u201d, Journal of the American Statistical Association, 68, 678-89.","cites":null},{"id":8639270,"title":"Kendall\u2019s advanced theory of statistics,","authors":[],"date":"1999","doi":"10.2307\/2533293","raw":"Stuart, A., Ord, J.K. and Arnold, S. (1999).  Kendall\u2019s advanced theory of statistics, th ed., vol. 2A.  London: Edward Arnold.","cites":null},{"id":8639263,"title":"New methods in statistical economics\u201d.","authors":[],"date":"1963","doi":"10.1086\/258792","raw":"Mandelbrot, B. (1963). \u201cNew methods in statistical economics\u201d. Journal of Political Economy, 71, 421-440.","cites":null},{"id":8639243,"title":"Nonparametric tests of stochastic dominance in income distributions\u201d.","authors":[],"date":"1996","doi":"10.2307\/2171961","raw":"Anderson, G. (1996).  \u201cNonparametric tests of stochastic dominance in income distributions\u201d.  Econometrica, 64, 1183-1193.","cites":null},{"id":8639283,"title":"On the choice of the number and width of classes for the chi-square test of goodness-of-fit\u201d,","authors":[],"date":"1950","doi":"10.2307\/2280429","raw":"Williams, C.A., Jr. (1950). \u201cOn the choice of the number and width of classes for the chi-square test of goodness-of-fit\u201d, Journal of the American Statistical Association, 45, 77-86.","cites":null},{"id":8639264,"title":"On the choice of the number of class intervals in the application of the chi-square test\u201d.","authors":[],"date":"1942","doi":"10.1214\/aoms\/1177731569","raw":"Mann, H. B. and Wald, A. (1942). \u201cOn the choice of the number of class intervals in the application of the chi-square test\u201d. Annals of Mathematical Statistics, 13, 306-317.","cites":null},{"id":8639255,"title":"On the reliability of the classical chi-square test\u201d.","authors":[],"date":"1943","doi":"10.1214\/aoms\/1177731419","raw":"Gumbel, E. J. (1943). \u201cOn the reliability of the classical chi-square test\u201d. Annals of Mathematical Statistics, 14, 253-63.","cites":null},{"id":8639233,"title":"Simple tests of distributional form\u201d,","authors":[],"date":"1994","doi":"10.1016\/0304-4076(94)90024-8","raw":"Anderson, G. (1994). \u201cSimple tests of distributional form\u201d, Journal of Econometrics, 62, 265-276.","cites":null},{"id":8639267,"title":"Stable Paretian models in finance.","authors":[],"date":"2000","doi":"10.1080\/03610929808832156","raw":"Rachev, Svetlozar T. and Mittnik, S. (2000). Stable Paretian models in finance. Wiley.","cites":null},{"id":8639253,"title":"The behaviour of stock market prices\u201d.","authors":[],"date":"1965","doi":"10.1086\/294743","raw":"Fama, E. F. (1965). \u201cThe behaviour of stock market prices\u201d. Journal of Business, 38, 34-105.","cites":null},{"id":8639257,"title":"The number and width of classes in chi-square test\u201d.","authors":[],"date":"1963","doi":"10.2307\/2282716","raw":"Hamdan, M.A. (1963). \u201cThe number and width of classes in chi-square test\u201d. Journal of the American Statistical Association, 58, 678-89.","cites":null},{"id":8639258,"title":"The number of classes in chi-squared goodness-of-fit tests\u201d.","authors":[],"date":"1985","doi":"10.2307\/2288561","raw":"Kallenberg, W. C. M., Oosterhoff, J. and Schriever, B. F. (1985). \u201cThe number of classes in chi-squared goodness-of-fit tests\u201d. Journal of the American Statistical Association, 80, 959-968.","cites":null},{"id":8639245,"title":"The performance of SETAR models by regime: a conditional evaluation of interval and density forecasts\u201d,","authors":[],"date":"2003","doi":"10.1016\/j.ijforecast.2003.09.011","raw":"Boero, G. and Marrocu E. (2003). \u201cThe performance of SETAR models by regime: a conditional evaluation of interval and density forecasts\u201d, International Journal of Forecasting, forthcoming.","cites":null},{"id":8639249,"title":"Unbiasedness of the chi-square, likelihood ratio, and other goodness of fit tests for the equal cell case\u201d,","authors":[],"date":"1975","doi":"10.1214\/aos\/1176343197","raw":"Cohen, A. and Sackrowitz H. B. (1975). \u201cUnbiasedness of the chi-square, likelihood ratio, and other goodness of fit tests for the equal cell case\u201d, Annals of Statistics, 3, 959-964.","cites":null}],"documentType":{"type":0.8888888889}},"contributors":[],"datePublished":null,"abstract":"In this paper we conduct a Monte Carlo study to determine the power of\\ud\nPearson\u2019s overall goodness-of-fit test as well as the \u201cPearson analog\u201d tests (see\\ud\nAnderson (1994)) to detect rejections due to shifts in variance, skewness and kurtosis,\\ud\nas we vary the number and location of the partition points. Simulations are conducted\\ud\nfor small and moderate sample sizes. While it is generally recommended that to\\ud\nimprove the power of the goodness-of-fit test the partition points are equiprobable, we\\ud\nfind that power can be improved by the use of non-equiprobable partitions","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"University of Warwick, Department of Economics","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:wrap.warwick.ac.uk:126<\/identifier><datestamp>\n      2017-03-01T22:11:43Z<\/datestamp><setSpec>\n      7375626A656374733D48:4842<\/setSpec><setSpec>\n      74797065733D6D6F6E6F6772617068<\/setSpec><setSpec>\n      636F6C6C656374696F6E3D77726170<\/setSpec><\/header><metadata><rioxx xmlns=\"http:\/\/www.rioxx.net\/schema\/v2.0\/rioxx\/\" xmlns:ali=\"http:\/\/ali.niso.org\/2014\/ali\/1.0\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:dcterms=\"http:\/\/purl.org\/dc\/terms\/\" xmlns:rioxxterms=\"http:\/\/docs.rioxx.net\/schema\/v2.0\/rioxxterms\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.rioxx.net\/schema\/v2.0\/rioxx\/ http:\/\/www.rioxx.net\/schema\/v2.0\/rioxx\/rioxx.xsd\" ><ali:free_to_read>\n    \n      <\/ali:free_to_read><dc:description>In this paper we conduct a Monte Carlo study to determine the power of\\ud\nPearson\u2019s overall goodness-of-fit test as well as the \u201cPearson analog\u201d tests (see\\ud\nAnderson (1994)) to detect rejections due to shifts in variance, skewness and kurtosis,\\ud\nas we vary the number and location of the partition points. Simulations are conducted\\ud\nfor small and moderate sample sizes. While it is generally recommended that to\\ud\nimprove the power of the goodness-of-fit test the partition points are equiprobable, we\\ud\nfind that power can be improved by the use of non-equiprobable partitions.<\/dc:description><dc:format>application\/pdf<\/dc:format><dc:identifier>http:\/\/wrap.warwick.ac.uk\/126\/1\/WRAP_Smith_Jeremy_twerp694.pdf<\/dc:identifier><dc:language>en<\/dc:language><dc:publisher>University of Warwick, Department of Economics<\/dc:publisher><dc:relation>http:\/\/dx.doi.org\/10.1081\/ETC-200040782<\/dc:relation><dc:subject>HB<\/dc:subject><dc:title>The sensitivity of chi-squared goodness-of-fit tests to the partitioning of data<\/dc:title><rioxxterms:author>Smith, Jeremy (Jeremy P.)<\/rioxxterms:author><rioxxterms:type>Monograph<\/rioxxterms:type><rioxxterms:version>NA<\/rioxxterms:version><\/rioxx><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1081\/ETC-200040782"],"year":null,"topics":["HB"],"subject":["HB"],"fullText":"University of Warwick institutional repository: http:\/\/go.warwick.ac.uk\/wrap\n \nThis paper is made available online in accordance with publisher policies. \nPlease scroll down to view the document itself. Please refer to the repository \nrecord for this item and our policy information available from the repository \nhome page for further information.  \n \nTo see the final version of this paper please visit the publisher\u2019s website. \nAccess to the published version may require a subscription. \n \nAuthor(s): Jeremy Smith, Gianna.Boero & kenneth F Wallis \nArticle Title: The sensitivity of chi-squared goodness-of-fit tests to the \npartitioning of data \nYear of publication: 2004 \nLink to published version: http:\/\/dx.doi.org\/10.1081\/ETC-200040782 \n \n \n \n \n \n \nSensitivity of the Chi-Squared Goodness-of-Fit Test  \nto the Partitioning of Data \n \nGianna Boero \n \nJeremy Smith \n \nAnd \n \nKenneth F. Wallis \n \n \nNo 694 \n \n \n \n \n \n \n \n \n \nWARWICK  ECONOMIC  RESEARCH  PAPERS \n \n \n \n \nDEPARTMENT OF ECONOMICS \n 1\n \nSensitivity of the chi-squared goodness-of-fit test  \nto the partitioning of data  \n \n \n \nGianna Boero, Jeremy Smith and Kenneth F. Wallis \n \n \nDepartment of Economics \nUniversity of Warwick \nCoventry CV4 7AL, UK \n \n \nJanuary 2004 \n \n \n \nAbstract  In this paper we conduct a Monte Carlo study to determine the power of \nPearson\u2019s overall goodness-of-fit test as well as the \u201cPearson analog\u201d tests (see \nAnderson (1994)) to detect rejections due to shifts in variance, skewness and kurtosis, \nas we vary the number and location of the partition points. Simulations are conducted \nfor small and moderate sample sizes. While it is generally recommended that to \nimprove the power of the goodness-of-fit test the partition points are equiprobable, we \nfind that power can be improved by the use of non-equiprobable partitions. \n \n \n \nKeywords: Pearson\u2019s Goodness-of-fit test; Distributional assumptions; Monte Carlo; \nNormality; partitions. \n \nJEL classification:  C12, C14 \n \n \n \n \n \n \n \n \n \n \n \n \nAcknowledgements: The authors would like to thank Gordon Anderson and Peter \nBurridge as well as seminar participants at the ESEM conference 2003 for helpful \ncomments and suggestions. \n 2\n1. Introduction \nGoodness of fit or the degree of correspondence between observed outcomes \nand expected outcomes based upon a postulated distribution is a cornerstone of \nclassical statistics. The two classical nonparametric approaches to testing goodness of \nfit (as surveyed by Stuart, Ord and Arnold (1999, Ch. 25)) are (i) Pearson\u2019s goodness-\nof-fit (X2) test, which involves grouping data into classes and comparing observed \noutcomes to those hypothesised under some null distribution; and (ii) Kolmogorov-\nSmirnov (K-S) test, which involves comparing the empirical cumulative distribution \nfunction (cdf) with a cdf obtained under some null hypothesis. \nAnderson (1994) has devised a method to decompose the X2 test into a series \nof individual component tests (see Boero, Smith and Wallis, 2004), in which each \ncomponent test focuses on a different moment of the distribution, in an attempt to \nprovide more information on the nature of any rejection of the null hypothesis by the \nX2 test. \nIn spite of the wide use of the X2 test it is still not clear how many partition \npoints (class intervals) should be used in the construction of this test, and how these \nclass intervals should be formed. However, it is generally recommended that \nresearchers use equiprobable partitions, see Stuart, Ord and Arnold (1999). \nIn this paper we conduct a systematic analysis of the power of the X2 test in \nrelation to the number of partitions points. We also investigate the sensitivity of the \npower of the X2 test, as well as its component tests, to the location of the partition \npoints, that is, to the choice between equiprobable or non-equiprobable splits. The \npower of the X2 test is examined with respect to departures in variance, skewness and \nkurtosis from a null distribution of a N(0,1). The power of the X2 and its component \ntests is compared to that of the K-S statistic, additionally, we compare these tests to \n 3\nthe chi-squared test (for the population variation), when looking at variance \ndepartures and to the Jarque and Bera (1980) (J-B) test when looking at departures in \nskewness or kurtosis. \nThe paper proceeds as follows. Section 2 gives a brief description of the X2 \ntest and the literature on the choice of the number and location of the partition points. \nWe also discuss Anderson\u2019s (1994) method of decomposing the X2 test into its \ncomponent tests, as well as the K-S test. Section 3 outlines the alternative \ndistributions used to generate artificial data under the alternative hypotheses against \nwhich we test the null hypothesis of N(0,1). Section 4 reports the results of the X2 and \nits component tests to detect departures from the null hypothesis using both \nequiprobable and non-equiprobable partitions. Finally, in Section 5 we summarise the \nmain results and offer some concluding remarks. \n \n2. Goodness-of-fit tests \n2.1. The chi-squared goodness-of-fit (X2) test   \nPearson\u2019s classical goodness-of-fit (X2) test proceeds by dividing the range of \nthe variable into k mutually exclusive classes and comparing the probabilities of \noutcomes falling in these classes given by the hypothesised distribution with the \nobserved relative frequencies. With class probabilities 0, 1, ,ip i k\u0001 \u0002 \u0001 , \n1\n1\nk\ni\ni\np\n\u0001\n\u0001\u0001  \nand observed class frequencies 0, 1, ,in i k\u0001 \u0002 \u0001 , \n1\nk\ni\ni\nn N\n\u0001\n\u0001\u0001 , the test statistic is  \n\u0001 \u0002\n2\n2\n1\nk\ni i\ni i\nn Np\nX\nNp\n\u0001\n\u0001\n\u0002\u0001 . \nThis has a limiting 2\u0001 distribution with 1k \u0001  degrees of freedom if the hypothesised \ndistribution is correct. \n 4\nThe existing literature on the power of X2 test with different numbers of \npartitions (k) ranges from early studies by Mann and Wald (1942) and Gumbel (1943) \nto more recent work by Kallenberg et al. (1985) and Koehler and Gan (1990). Most of \nthese studies, have focused on asymptotic results and have assumed equiprobable \nclasses (such that, 1\/ , 1, ,ip k i k\u0001 \u0001 \u0001 ). Mann and Wald (1942) have suggested \nequiprobable class intervals and develop a formula for the optimal choice of the \nnumber of classes, which depends on the sample size, N, and the level of significance. \nFor equiprobable splits the formula for the choice of cells is k = 3.765(N-1)0.4, at the \n5% significance level. Table 1 reports values of k for selected values of N based upon \nthis formula. Although Mann and Wald\u2019s recommendation (p.307) is based on \nasymptotic theory, they suggest that the results hold approximately for sample sizes as \nlow as 200 and may be true for considerably smaller samples. \nTable 1 \nN k \n25 13 \n50 18 \n75 21 \n100 24 \n150 28 \n250 34 \n350 39 \n \nThe advantages of the Mann and Wald technique are that the application of the \nformula removes the subjective element from the choice of the number and width of \nthe classes and equiprobable classes are easy to use and lead to unbiased tests (see \nalso Gumbel, 1943, and Cohen and Sackrowitz, 1975). However, various numerical \nstudies have presented empirical evidence to show that the value of k proposed by \nMann and Wald is too large, resulting in loss of power in many situations. Williams \n(1950) indicates that the value of k as given by the Mann and Wald formula may be \n 5\nhalved for practical purposes, without relevant loss of power. See also Dahiya and \nGurland (1973), who suggest values of k between 3 and 12 for several different \nalternatives in testing for normality, for sample sizes of N=50 and 100. \nOther studies have suggested that the best choice of k depends on the nature of \nthe alternative hypothesis under consideration as well as the sample size, N. In a \ncomparison of the power of the X2 test and the likelihood ratio (LR) goodness-of-fit \ntests, Kallenberg et al. (1985) suggest that, particularly for heavy tailed alternatives, \nthe X2 test with equiprobable classes has the best power when k is relatively large \n(k=15 and 20 when N=50 and 100, respectively).  These values of k are quite similar \nto those given by the Mann and Wald formula, and are also suggested by Koehler and \nGan (1990) as a good overall choice.  \nOn the other hand, Kallenberg et al. (1985) argue that as the variance of X2 test \nincreases with k, and this has a negative effect on the power, non-equiprobable \npartitions with moderate k are better than equiprobable partitions with large k. For \nexample, partitions with some smaller classes in the tails and larger classes in the \nmiddle may lead to an important gain of power for alternatives with heavy tails, while \nfor thin-tailed alternatives, unbalanced partitions often cause a loss of power (p. 959).  \nMost of the results summarised above are based on asymptotic theory. Only a \nlimited number of cases have been examined to validate the asymptotic theory, \nKallenberg et al. (1985) present some results for N=50 and N=100, while Koehler and \nGan (1990) report results for N=20, 50 and 100. In contrast little is known for cases \nwith non-equiprobable partitions. In general, therefore the evidence that has been \nproduced is often contradictory, leaving the problems of how many partitions to use \nand how to choose them largely unresolved. \n 6\n2.2. X2 component tests or \u2018Pearson analog\u2019 tests \nAnderson (1994) presented a method for decomposing the X2 test into (k-1) \nindependent 2 (1)\u0001  component tests as: \n2 2 2\/ 1, , 1j j jX n j k\u0001 \u0002\u0001 \u0001 \u0002\u0001  \nwhere ( )j jv i x \u0001\n\u0001\n\u0002 \u0003 , x is a vector (kx1) of observed frequencies with mean \u0001, and ji  \nis a set of k dimensioned vectors (the decompositions are only really possible for k=4, \n8, 16 and 32). For example, for 8k \u0001 , we can write the first four vectors of ji  as: \n\u0001 \u00021 1 1 1 1 1 1 1mi \u0001 \u0002 \u0002 \u0002 \u0002  \n\u0001 \u00021 1 1 1 1 1 1 1sci \u0001 \u0002 \u0002 \u0002 \u0002  \n\u0001 \u00021 1 1 1 1 1 1 1ski \u0001 \u0002 \u0002 \u0002 \u0002  \n\u0001 \u00021 1 1 1 1 1 1 1ki \u0001 \u0002 \u0002 \u0002 \u0002  \nDefining 1 8( , , )p p p\u0001 \u0001 , where pj are the class probabilities, the variance is \nwritten: \n 2 21 ( ) , , ,j ji p j m sc sk k\u0001 \u0001\u0002 \u0003 \u0002  \nFrom the form of the ji  vectors, the first component test (PCM), using mi , \nfocuses on location shifts relative to the median. The second component test (PCSc), \nusing sci , focuses on scale shifts to the inter-quartile range. The third component test \n(PCSk), using ski , detects asymmetries, with shifts between the first and third quarters \nand the second and fourth quarters of the distribution. The fourth component test \n(PCK), using ki , detects kurtosis, with shifts towards the extremes and the centre of \nthe distribution. There are three remaining component tests, but these have no obvious \ninterpretation. Boero, Smith and Wallis (2004) present a more theoretical derivation \n 7\nof the component tests and show that the independence of the component tests does \nnot hold when using non-equiprobable splits, although each component test still has a \n2 (1)\u0001  distribution. An application of this \u201cPearson analog\u201d test to the comparison of \nincome distributions is given by Anderson (1996).  It has also been used in density \nforecast evaluation by Wallis (2003) and Boero and Marrocu (2003). \nWhile for the X2 test the choice of k is important, the individual component \ntests do not depend on k, once k is large enough to define them. When k=4 only three \ncomponents are defined and these three component tests are unchanged for k=8, \nassuming that the eight partitions are obtained by dividing each of the original four \npartitions into two, without moving the partition points.  \nWe define partition points implicitly, as the appropriate percentage points of \nthe relevant cdf, F, the partition points being the corresponding x-coordinates. Denote \nthe value of the cdf at the upper boundary of the jth partition as Fj.  The first and last \npartitions are open-ended, thus with F0 =0 and Fk =1 the partition probabilities satisfy, \npj = Fj\u0001Fj\u00011, j=1,\u2026,k, and a partition configuration is reported as the set {F1,\u2026,Fk\u00011}.  \nThe power of the individual component tests (and hence of X2) depends on the \nlocation of Fj. For example, for unimodal distributions, if two distributions differ only \nin their median then with k=8 classes, the power of the median component test is \nsensitive to F4, which corresponds to the sign change in the vector im. If the \ndistributions differ in the scale parameter (inter-quartile range), the power of the scale \ncomponent test depends upon F2 and F6, which correspond to the two sign changes in \nthe vector isc. If the distributions differ in skewness, the power of the skewness \ncomponent test is reliant on F2, F4 and F6, which correspond to the three sign changes \nin the vector isk. Finally, if the distributions differ in kurtosis, the power of the kurtosis \ncomponent test is reliant on F1, F3, F5 and F7, which correspond to the four sign \n 8\nchanges in the vector ik. See Anderson (1994) for further discussion of these partition \npoints. \n2.3. Kolmogorov-Smirnov test \nThe other nonparametric test used in the study is the K-S statistic  \nmax , 1 ,i iD A Z i N\u0001 \u0002 \u0003 \u0003  \nwhere Z is the theoretical cdf under the null hypothesis, and A is the empirical cdf. \n \n3. Experiments used in the Monte Carlo study \nThe Monte Carlo experiments in this paper are designed to determine the \npower of the X2 and its component tests to detect departures from the null distribution, \nN(0,1), with respect to variance, skewness or kurtosis. In this section we outline the \nnature of these alternative distributions. \nExperiment A: Non-unit variance \n2(0, )N \u0001 , with \u0002 varying from 0.1 to 2.0 through steps of 0.1.  \nExperiment B: Skewed distributions \nB1: Ramberg distribution (see Ramberg et al., 1979), is a flexible form expressed in \nterms of its cumulative probabilities. The Ramberg quantile and density functions \nhave the form: \n3 4\n1 2( ) (1 ) \/R p p p\n\u0001 \u0001\n\u0001 \u0001\u0001 \u0002\u0003 \u0004 \u0005 \u0005\u0006 \u0007  \n3 41 1\n2 3 4( ) [ ( )] (1 )f x f R p p p\n\u0001 \u0001\n\u0001 \u0001 \u0001\n\u0001 \u0001\u0001 \u0002\u0003 \u0003 \u0004 \u0005\u0006 \u0007  \nwith 0 1p\u0001 \u0001  being the cumulative probability, ( )R p  the corresponding quantile, \nand [ ( )]f R p  the density corresponding to ( )R p . Of the four parameters, 1\u0001  is the \nlocation parameter, 2\u0001  the scale parameter, and 3\u0001  and 4\u0001  are shape parameters. For \nthe present purpose we choose their values such that ( ) 0, ( ) 1E X V X\u0001 \u0001 , skewness \n 9\n={0.00, 0.05, 0.10, \u0003, 0.90} and kurtosis =3. The median is then non-zero and it is an \nincreasing function of the skewness. In order to concentrate on the effect of skewness \nalone we shift the distribution by the empirically calculated median. This distribution \nhas been used in a recent study by Noceti, Hodges and Smith (2003) who summarise \nthe results from a Monte Carlo study of the relative power of some distributional tests. \nB2: Two-piece normal distribution (see Wallis, 1999), is used by the Bank of England \nand the Sveriges Riksbank in presenting their density forecasts of inflation. The \nprobability density function is  \n\u0001 \u0002\n\u0001 \u0002\n1 2 2\n1 2 1\n1 2 2\n1 2 2\n2 ( ) \/ 2) exp \/ 2\n( )\n2 ( ) \/ 2) exp \/ 2\nx x\nf x\nx x\n\u0001 \u0002 \u0002 \u0003 \u0002 \u0003\n\u0001 \u0002 \u0002 \u0003 \u0002 \u0003\n\u0001\n\u0001\n\u0001 \u0002 \u0003\u0002 \u0003\u0004 \u0005 \u0005 \u0006\u0007 \b \u0007 \b\t\n\t\n\n \u000b\n\t\n\u0002 \u0003\u0002 \u0003\u0004 \u0005 \u0005 \f\t\u0007 \b \u0007 \b\r\n. \nThe distribution is positively skewed if 2 22 1\u0001 \u0001\u0001 , and is leptokurtic if 1 2\u0002 \u0002\u0001 .  \nAs in the Ramberg distribution, the median is an increasing function of skewness and \nwe again shift the distribution, to ensure a theoretical median of zero. In our \nsimulations we consider combinations of 1 2( , )\u0001 \u0001  that yield ( ) 1V X \u0001  and skewness \nof {0.00, 0.05, 0.10, \u0003, 0.90}. \nB3: Anderson\u2019s skewed distribution (see Anderson, 1994) \n( \/(1 )) 0\n(1 ) otherwise\nz d z\nx\nz d\n\u0001 \u0002\u0003\n\u0004 \u0005\n\u0001\u0006\n \nwhere ~ (0,1)z N . Since skewness\u00042\u0005d we set d={0.00, 0.025, \u0003, 0.45}. The mean, \nvariance and kurtosis of this distribution are all increasing functions of d, although the \nmedian is zero. The transformation is discontinuous at zero, hence the probability \ndensity function has a central singularity, unlike the two-piece normal distribution. \n 10\nC: Distributions with heavy tails.  \nC1: Stable distribution (see Chambers et al. (1976) for the code). General stable \ndistributions allow for varying degrees of tail heaviness and varying degrees of \nskewness. They can be represented with the general notation S(\u0001,\u0002,\u0003,\u0004), with four \nparameters: an index of stability (or characteristic exponent) 0<\u0001\u22642, which measures \nthe height of (or total probability in) the extreme tail areas of the distribution, a \nskewness parameter -1\u2264\u0002\u22641, a scale parameter \u0006\u00070 and a location parameter\u0001 \u0001\u0002 . \nWhen \u0001=2 and \u0002=0 the distribution is Gaussian with variance 2; when \u0001=1 and \u0002=0 \nthe distribution is Cauchy; when \u0001=0.5 and \u0002=1, the distribution is Levy. When \n0<\u0001<2 the extreme tails of the stable distribution are higher than those of a normal \ndistribution, and the total probability in the extreme tails is larger the smaller the \nvalue of \u0001.  In our simulations we use standardised symmetric stable distributions, by \nsetting \u0003=1, \u0004=0 and \u0002=0. One consequence of stable distributions is that, if \u0001<2, \nmoments of order \u0001 or higher do not exist. For \u0001=2 we scale the distribution to have a \nunit variance. \nStable distributions have been proposed as a model for many types of \nvariables, especially in physics, finance and economics (see, for example, Uchaikin \nand Zolotarev, 1999).  In finance, for example, stock prices are often modelled as \nnon-Gaussian stable distributions (see Mandelbrot, 1963, Fama, 1965, McCulloch, \n1994, and Rachev and Mittnik, 2000).  \nC2: Anderson\u2019s kurtotic distribution (see Anderson, 1994) \n\u0001 \u0002| | (1 )qx z z t\u0001 \u0002  \nwhere (0,1)z N\u0001  and t is a variance-shifting nuisance parameter. We take \ncombinations of q and t that give ( ) 1V X \u0001 and kurtosis in the range 2.0 to 7.0. \n 11\nThe results of the Monte Carlo experiments reported in this paper are based on \n5000 replications for sample sizes N=25, 50, 75, 100, 150, 250, 350. All tests are \nundertaken at the 5% significance level. For equiprobable partitions we take \nk=2,4,\u0003,40. For non-equiprobable partitions we take k = 4,8,16,32 and consider \npartitions which are symmetric around 0.5, such that for k=8, {F1, F2, F3, 0.5, 1-F3, 1-\nF2, 1-F1}. \n \n4. The power of the tests \n4.1. Departure from unit variance \nWe now analyse the power of the various tests for departures from the null \nhypothesis of N(0,1) due to a non-unit variance (experiment A).  \n4.1.1. Equiprobable classes \nWe first illustrate the relation between power and number of classes, in the \nequiprobable case for the X2 test. The results are reported in Figure 1a for a wide \nrange of alternatives with excess variance (thicker tails), and in Figure 1b for \nalternatives with variance smaller than one (thinner tails), for N=150 and k ranging \nfrom 2 to 40. More extensive results for different sample sizes are summarised in \nTable 2 (first three columns).  \nFrom Figures 1a and 1b it is evident that, for most alternatives, power is \nmaximised for a value k in the interval four to ten. Values of k greater than 10 do not \nlead to further increases in power, rather, the performance of the test is more or less \nunchanged for thick-tailed alternatives, while there seems to be considerable loss in \npower for thinner-tailed alternatives for values of k greater than 10.  \nTable 2 reports results for different sample sizes and indicates that the power \nis maximised for all sample sizes at k around 4 and 8 for alternatives with \u0004<1, and at \n 12\nk around 8 and 10 for alternatives with \u0004>1. Moreover, the power of the X2 test to \ndetect departures from a unit variance is slightly asymmetric around 1\u0001 \u0001 , showing \nmore power to reject the null distribution for 1\u0001 \u0001  compared with 1\u0001 \u0002 . In sum, for \nall alternatives and sample sizes considered in this section, the optimal value of k in \nthe case of equiprobable classes appears to be much smaller than the values suggested \nby the Mann and Wald formula in Table 1.  \nThe last two columns of Table 2 report the power of the K-S test and the \b\u0001 \ntest for the variance of a population, (N-1)s2\/\u03c32,\u0002with N-1 degrees of freedom. \nComparing the power of the X2 test with the K-S test shows a clear superiority of the \nX2 test in all cases; however, both tests have power inferior to that of the \b\u0001 test. \n4.1.2. Non-equiprobable classes \nAs discussed earlier the power of the scale component test (PCSc) (and hence \nthe X2 test) depends upon F2 and F6. In experiment A we set the partitions such that \n{F1, F2, \u2026,F7}= {F2\/2, F2, (0.5+F2)\/2, 0.5, 1-(0.5+F2)\/2, 1- F2, 1- F2\/2}, and take \nvalues of F2 in the range 0.15 to 0.3 through steps of 0.025. For k=8, Figures 2a and \n2b plot the power of the X2 and PCSc tests, respectively, against values of F2 for \nN=150 and k=8 for 1\u0001 \u0002 . \nFigure 2b shows that the power of the PCSc test unambiguously falls as F2 \nincreases for all \u0004. By comparison, Figure 2a shows that the power of the X2 test falls \nas F2 increases only for \u0004\u00051, and is largely insensitive to F2 for \u0004\u00061. For example, for \nthe X2 test when \u0004=1.2, power increases to 55% for F2=0.15, compared with 39% for \nF2=0.25, whereas when \u0004=0.8 power is roughly 60% irrespective of the value of F2. \nThe explanation for the insensitivity of the X2 test to F2 for \u0004\u00061 arises from looking at \nthe performance of the other component tests for 1\u0001 \u0001 . We have found that both the \nmedian (PCM) and skewness (PCSk) component tests have power around nominal \n 13\nsize for all N and for all values of \u0004, irrespective of F2 (these results are omitted from \nthe figures). However, the kurtosis (PCK) component test has some power to detect \n\u0004\t1, and for \u0004<1 this power increases as F2 increases, thereby offsetting the falling \npower of the PCSc test in the X2 test. For \u0004>1 there is some increase in power for the \nPCK test as F2 increases, but this increase is small compared to that observed for \u0004<1. \nAs anticipated above, Figure 2b shows that for both \u0004>1 and \u0004<1 there are \nclear gains in power for the PCSc test when the test is computed using non-\nequiprobable intervals. For example, for \u0004=1.2, power increases to 67% for F2=0.15, \ncompared with 46% for F2=0.25, and to 86% from 73% when \u0004=0.8. \nUsing F2=0.15, Table 2 (columns 4-6) reports the power of the X2 test for \ndifferent sample sizes. We note that, for all sample sizes, the power of the X2 test \nusing non-equiprobable partitions is significantly higher than for equiprobable \npartitions for \u0004\u00051, while there is little difference for \u0004\u00061. Also the results indicate that \nwith non-equiprobable partitions the power of the X2 test is not very sensitive to \nincreasing k from 4 to 8 or 16, providing there are sufficient observations to avoid \nsparsity in some partitions.  \nFinally, in Figure 3 we summarise the power results of the X2 test obtained for \n1\u0001 \u0002  and N=150, using k=10 equiprobable intervals, and k=8 non-equiprobable \nintervals (with F2=0.15). We also report the power of the PCSc component test with \nnon-equiprobable partitions (F2=0.15), the K-S test and the simple test for the \npopulation variance ( )1(2 \u0001N\u0001 ). As we can see, the best performance is given by the \nlatter (chi-sq in the figure). The power of the X2 with non-equiprobable partitions is \nvery similar to that of the PCSc test and both tests have higher power than the K-S \ntest. \n 14\nThe results discussed above, complement various suggestions from previous \nfindings, summarised in Koehler and Gan (1990), that the best choice of k may \ndepend on the alternative under consideration, as well as the sample size N, and \nprovide a further contrast to the results of Mann and Wald (1942). Moreover, our \nresults clearly show that unbalanced partitions with some small partitions in the tails \nlead to important gains in power when the alternative has heavy tails (\u0004>1). These \nfindings are consistent with the suggestion in Kallenberg et al. (1985). \n4.2. Departures due to Skewness \n4.2.1. Equiprobable classes \nWe now look at departures from the null hypothesis of normality due to  \nskewness. The relation between power and number of classes in the equiprobable case \nis illustrated in Figures 4 to 6. Figure 4 reports the results for the Ramberg distribution \n(B1), with skewness ranging between 0.2 to 0.8, for N=150 and k ranging from 2 to \n40. \nFirst of all, as expected, we observe noticeable gains in the power of the X2 \ntest for increasing degrees of skewness. Moreover, the power of the test is remarkably \nsensitive to the choice of k. In particular, there are significant gains in power when the \nnumber of classes increases from k=4 to k = 8, 10 and 12, with power increasing at a \nfaster rate the higher the degree of skewness. For example, from Figure 4 we observe \nthat, for N=150, power increases from approximately 14% (k=4) to 58% (k=10) when \nskewness is 0.4, and from 28% (k=4) to 91% (k=6) and to 100% (k=8) when skewness \nis 0.8.  \nResults for different sample sizes, reported in Table 3, are qualitatively similar \nto those discussed above. The results show that power of the X2 test is not very \nsensitive to changes in k in the range between 24-40. Again the optimal values of k \n 15\nsuggested by our experiments under skewed alternatives are significantly smaller than \nthe values suggested by Mann and Wald. \nQualitatively similar results are obtained for the two-piece normal distribution \n(B2), see Figure 5, which reports the power of the X2 test for skewness=0.5 and \ndifferent sample sizes. Figure 6 reports the power of the X2 test for Anderson\u2019s \nskewed distribution (B3), for N=150 and different degrees of skewness, we observe a \nless prominent impact on power by increasing k from 4 to 8 or 10.  \n4.2.2. Non-equiprobable classes \nAs discussed earlier for k=8, the power of the skewness component test \n(PCSk) depends upon the three points, F2, F4 and F6. Given our symmetry assumption \non the partitions, we have {F1, F2,\u2026,F7}= {F2\/2, F2, (0.5+F2)\/2, 0.5, 1-(0.5+F2)\/2, 1- \nF2, 1-F2\/2}, and conduct experiments for values of F2 in the range 0.15 to 0.3 in steps \nof 0.025. In Figures 7a and 7b we plot the power of the X2 and PCSk tests, \nrespectively, against values of F2 for N=150 and k=8, for B1 (Ramberg) with \nskewness ranging from 0.2 to 0.8.  \nFrom Figures 7a and 7b it can be seen that the power of both the X2 and the \nPCSk increases as F2 becomes smaller. At F2=0.15 (N=150 and skewness=0.6) the \npower for PCSk (X2) is 56% (67%) compared to 25% (51%) when using F2=0.25. In \ngeneral, the use of F2=0.15 (instead of F2=0.25) nearly doubles the power of the PCSk \ntest. \nThe results for B2 (two-piece normal) and B3 (Anderson\u2019s skewed distribution) \nare qualitatively similar to those reported in Figures 7a and 7b, although for B3 the \ngains to using non-equiprobable partitions are smaller than observed for B1 and B2. \nFor all experiments we find that the PCM, PCSc and PCK component tests exhibit \n 16\npower approximately equal to nominal size for all values of skewness, N and F2 \nconsidered. \nFigures 8a and 8b plots the power of the X2 test for B1 and B3 with N=150, for \nk=8 equiprobable partitions, k=8 non-equiprobable partitions (F2=0.15), and the PCSk \ntest using non-equiprobable partitions (F2=0.15). In the same figures we also report \nthe results from the K-S and J-B tests. Results for different sample sizes are \nsummarised in Table 3 for B1 and B2.  \nFirst of all, from Figures 8a and 8b and Table 3, we observe for all tests a \nsignificant increase in power for increasing degrees of skewness. Figure 8a and Table \n3 show that, overall, the performance of the X2 test is maximised with the use of k=8 \nnon-equiprobable partitions. These results apply to all sample sizes, as shown in Table \n3, and both alternatives B1 and B2. Figure 8a and Table 3 also report the performance \nof the K-S and J-B tests. The results indicate that the best performance for B1 and B2 \nis achieved by the J-B test and the worse performance by the K-S test. For example, \nfor alternative B1, and skewness 0.6 (N=150), the power of the J-B test is about 80%, \nwhile it is only 25% for the K-S test.  It is also clear that, with k=8 non-equiprobable \npartitions, the power of the X2 test is only marginally below that exhibited by the J-B \ntest (the largest differential between the power of the two tests is 13% for skewness of \n0.6).   \nA different ranking of the tests is obtained from the experiments conducted \nunder B3. Figure 8b shows that, in this case, the X2 test clearly dominates the J-B test. \nFinally, we notice that, differently from the results discussed above, with non-\nequiprobable partitions doubling k from 4 to 8 has no effect on power. \n 17\n4.3. Departures due to kurtosis \n4.3.1. Equiprobable classes \nThe relation between power and number of classes in the presence of kurtosis \nwhen the test is computed using equiprobable partitions is illustrated in Figures 9 and \n10 for C1 (Stable distribution) and C2 (Anderson\u2019s kurtotic distribution), respectively, \nfor k varying from 2 to 40 and N=150. As we can see from Figure 9, the power of the \nX2 test to detect departures from N(0,1) is very high, approaching 100% when the \nstability parameter \n\u000bdescribing the alternative distribution is less than 2. Similar \nfindings are obtained in the simulations with the Anderson\u2019s distribution, reported in \nFigure 10 where we can see that the power of the X2 test approaches 100% for \nkurtosis of about 6. Moreover, for both alternatives, we notice an improvement in the \npower of the test moving from 4 to 8 (or 10) partitions, after which the test does not \nseem to be sensitive to further increases in k. \n4.3.2. Non-equiprobable classes \nAs discussed earlier, for k=8 the power of the kurtosis component test (PCK) \ndepends upon the four points, F1, F3, F5 and F7. Given our symmetry assumption the \npartitions are {F1, F2, \u2026,F7}= {F1, (F1+F3)\/2, F3, 0.5, 1-F3, 1-(F1+F3)\/2, 1- F1}, and \nwe set values of F1, and F3 in the range 0.05 to 0.2 and 0.25 to 0.45, respectively. In \nFigures 11a and 11b we plot the power of the X2 and PCK tests, respectively, against \nvalues of F1 and F3 for N=150 and k=8 classes, for C1 with 95.1\u0001\u0001 .  \nFigure 11a shows that the power of the X2 test is maximised at F1=0.05 and \nF3=0.45, whereas the power for the PCK component test (Figure 11b) is maximised at \nF1=0.1 and F3=0.45. The difference between the two tests are accounted for by the \nfact that the PCSc component test has considerable power (as the variance is infinite) \nand this is maximised at F1=0.025 and F3=0.3. Both the PCM and PCSk component \n 18\ntests have power equal to nominal size for almost all values of kurtosis (results \nomitted from the figures). \nIn the simulations with C2 (Anderson\u2019s kurtotic distribution) we have found \nthat the power of both the X2 test and the PCK component test was maximised at \nF1=0.05 and F3=0.45. In this case while the PCSc test has shown some power (the \nsample variance for this experiment was approximately unity), it was markedly \nsmaller than the power of the PCK component test. \nFigures 12 and 13 explore further the performance of the X2 test under \nalternatives C1 and C2, respectively, when the test is computed using non-\nequiprobable partitions. The figures also report the performance of the J-B and K-S \nstatistics. Figure 12 shows that the X2 and PCK tests dominate the other tests in terms \nof power. In particular, we can see that the maximum power exhibited by the K-S test \nis 60%, while the power of the J-B test ranges between 20% and 50% for the stability \nparameter \n between 2 and 1.85, and becomes comparable to that of the X2 test for \nsmaller values of \u0001. Also Figure 12 illustrates some gains in power for the X2 and \nPCK tests by using non-equiprobable partitions. The power of the X2 test is, in fact, \nbetween 80% and 90% with 8 and 16 equiprobable partitions, and between 90% and \n100% with non-equiprobable partitions. The partitions were formed by setting \nF1=0.05 and F3=0.45, with k=8.  \nIn Figure 13 we report the results for C2, for X2 computed with k=10 \nequiprobable partitions and k=8 non-equiprobable partitions (F1=0.05 and F3=0.45), \nand for the PCK test (F1=0.05 and F3=0.45). It is clear that greater gains are achieved \nby the X2 test for this distribution (compared to C1) with the use of non-equiprobable \npartitions relative to equiprobable partitions. For example, for kurtosis of 4.4, k=10 \nequiprobable partitions deliver power of just above 50%, while power can reach \n 19\nvalues above 90% with the use of k=8 non-equiprobable partitions. Table 4 presents \nresults for different sample sizes. Comparing the performance of the X2 test with that \nof the K-S and J-B tests, we can see that the X2 test is superior to the K-S statistic for \nall values of k, and it is also superior to the J-B test for kurtosis higher than 3.6. \n4. Conclusions  \nIn this paper we have summarised the results of a Monte Carlo study of the \npower of the X2 test, considering small and moderate sample sizes, various values of \nk, and both equiprobable and non-equiprobable partitions. We have made suggestions \nfor values of k to use in testing for normality against special alternatives of interest, in \nthe case of equiprobable intervals, and show that there can be significant gains in \npower from the use of non-equiprobable intervals.   \nThe simulations have been designed to detect departures from a standard \nnormal distribution, in the presence of changes in variance, skewness and kurtosis. \nThe relative performance of the X2 test has been compared against that of the K-S \nstatistic, a simple test about the variance of a population, and the J-B test.  \nIn synthesis, two main results seem to apply in general to small and moderate \nsample sizes, and stand against common practical recommendations. First, our \nsimulations indicate that the \u2018optimal\u2019 number of cells is smaller than that \nrecommended in previous studies, most of which are based on asymptotic results.  \nSecond, the use of non-equiprobable partitions can increase the power of the \nX2 test significantly, for departures from the N(0,1) null due to shifts in variance, \nskewness and kurtosis. Specific choices of non-equiprobable partitions have shown to \nimprove the performance of the X2 test over the K-S test, and to reduce substantially \nits disadvantage with respect to the moment-based tests considered in this paper. \n 20\nReferences \nAnderson, G. (1994). \u201cSimple tests of distributional form\u201d, Journal of Econometrics, \n62, 265-276. \n \nAnderson, G. (1996).  \u201cNonparametric tests of stochastic dominance in income \ndistributions\u201d.  Econometrica, 64, 1183-1193. \n \nBoero, G., Smith, J. P. and Wallis, K. F. (2004). \u201cDecompositions of Pearson\u2019s Chi-\nSquared Test\u201d. Journal of Econometrics, forthcoming. \n \nBoero, G. and Marrocu E. (2003). \u201cThe performance of SETAR models by regime: a \nconditional evaluation of interval and density forecasts\u201d, International Journal \nof Forecasting, forthcoming.  \n \nChambers, J. M., Mallows, C. L. and Stuck, B. W. (1976). \u201cA method for simulating \nstable random variables\u201d. Journal of the American Statistical Association, 71, \n340-344. \n \nCohen, A. and Sackrowitz H. B. (1975). \u201cUnbiasedness of the chi-square, likelihood \nratio, and other goodness of fit tests for the equal cell case\u201d, Annals of \nStatistics, 3, 959-964. \n \nDahiya, R. C. and Gurland  J. (1973). \u201cHow many classes in the Pearson chi-square \ntest?\u201d, Journal of the American Statistical Association, 68, 678-89. \n \nFama, E. F. (1965). \u201cThe behaviour of stock market prices\u201d. Journal of Business, 38, \n34-105. \n \nGumbel, E. J. (1943). \u201cOn the reliability of the classical chi-square test\u201d. Annals of \nMathematical Statistics, 14, 253-63. \n \nHamdan, M.A. (1963). \u201cThe number and width of classes in chi-square test\u201d. Journal \nof the American Statistical Association, 58, 678-89. \n \nKallenberg, W. C. M., Oosterhoff, J. and Schriever, B. F. (1985). \u201cThe number of \nclasses in chi-squared goodness-of-fit tests\u201d. Journal of the American \nStatistical Association, 80, 959-968. \n \nKoelher, K. J. and Gan, F. F.  (1990). \u201cChi-squared goodness-of-fit tests: cell \nselection and power\u201d. Communications in Statistics, B, 19, 1265.  \n \nMandelbrot, B. (1963). \u201cNew methods in statistical economics\u201d. Journal of Political \nEconomy, 71, 421-440. \n \nMann, H. B. and Wald, A. (1942). \u201cOn the choice of the number of class intervals in \nthe application of the chi-square test\u201d. Annals of Mathematical Statistics, 13, \n306-317. \n \n 21\nMcCulloch, J. H. (1994). Financial applications of stable distributions. In Statistical \nmethods in finance (Maddala, G.S., and Rao, C.R., Eds.) Elsevier, pp.393-425. \n \nNoceti, P, Smith, J. and Hodges, S. (2003). \u201cAn evaluation of tests of distributional \nforecasts\u201d, Journal of Forecasting, 22, 447-455. \n \nRachev, Svetlozar T. and Mittnik, S. (2000). Stable Paretian models in finance. \nWiley. \n \nRamberg, J.S., Dudewicz, E.J., Tadikamalla, P.R. and Mykytka, E. (1979). \u201cA \nprobability distribution and its uses in fitting data\u201d.  Technometrics, 21, 201-\n214. \n \nStuart, A., Ord, J.K. and Arnold, S. (1999).  Kendall\u2019s advanced theory of statistics, \n6th ed., vol. 2A.  London: Edward Arnold. \n \nUchaikin, V. V. and Zolotarev, V. M. (1999). Chance and stability, stable \ndistributions and their applications. VSP Utrecht, The Netherlands. \n \nWallis, K.F. (1999).  \u201cAsymmetric density forecasts of inflation and the Bank of \nEngland\u2019s fan chart\u201d.  National Institute Economic Review, No. 167, 106-112. \n \nWallis, K.F. (2003). \u201cChi-squared tests of interval and density forecasts, and the Bank \nof England\u2019s fan charts\u201d.  International Journal of Forecasting, 19, 165-175.  \n \nWilliams, C.A., Jr. (1950). \u201cOn the choice of the number and width of classes for the \nchi-square test of goodness-of-fit\u201d, Journal of the American Statistical \nAssociation, 45, 77-86. \n \n 22\nTable 2: Power of the X2 test of N(0,1) vs N(0,d) \nAlternative A \n              Equiprobable splits        Non-equiprobable splits     \n\u0001\u0002 k=4 k=8 k=16 k=4 k=8 k=16 ch-sq. K-S \nN=25             \n0.6 47.8 40.8 27.7 44.6 26.7 13.2 96.9 12.0 \n0.7 23.2 22.4 15.5 20.3 13.0 8.1 75.1 9.3 \n0.8 9.1 9.6 8.9 9.0 6.7 4.8 39.9 5.5 \n0.9 5.3 6.7 7.0 4.8 6.1 4.3 15.5 6.3 \n1.1 4.6 5.9 6.0 7.8 9.8 9.2 18.2 6.0 \n1.2 8.2 10.7 8.5 13.8 14.6 14.8 39.0 8.1 \n1.3 9.5 13.1 13.1 20.7 24.2 24.2 60.6 10.8 \n1.4 15.4 21.0 21.9 32.1 36.9 36.2 77.4 15.4 \n1.5 18.8 31.4 33.5 43.4 47.6 50.0 88.1 20.7 \nN=50              \n0.6 85.6 85.3 67.1 91.0 79.6 53.2 100.0 42.9 \n0.7 50.6 48.6 31.4 55.9 39.1 21.4 97.0 16.4 \n0.8 19.5 19.3 13.8 21.1 15.4 8.4 67.8 8.2 \n0.9 7.3 8.0 6.3 8.5 6.8 5.0 24.6 4.4 \n1.1 7.5 6.7 6.0 11.2 10.6 10.8 26.3 5.5 \n1.2 13.6 14.9 13.5 19.8 21.9 21.0 59.3 11.8 \n1.3 19.2 24.1 24.0 34.5 38.0 37.2 83.9 16.0 \n1.4 31.0 41.7 45.2 51.6 59.6 59.1 95.1 24.6 \n1.5 39.2 59.4 64.1 69.5 78.6 79.7 98.8 36.0 \nN=100              \n0.6 99.6 99.7 98.9 100.0 99.8 98.6 100.0 90.2 \n0.7 82.0 87.1 76.2 91.3 87.4 66.9 100.0 46.5 \n0.8 38.0 40.4 30.5 47.4 37.5 23.6 92.9 14.9 \n0.9 10.6 10.0 10.3 11.3 10.1 7.2 40.8 6.7 \n1.1 9.3 11.8 9.1 15.4 13.6 15.5 40.2 9.3 \n1.2 21.6 29.0 27.6 37.3 38.9 36.4 83.0 15.5 \n1.3 39.2 51.7 53.2 61.8 67.6 66.2 97.7 29.1 \n1.4 58.2 74.8 80.8 81.6 88.6 88.6 99.8 48.2 \n1.5 74.8 90.4 93.8 95.3 97.9 98.2 100.0 70.3 \nN=150              \n0.6 100.0 100.0 100.0 100.0 100.0 100.0 100.0 99.5 \n0.7 94.5 97.8 96.3 99.0 98.6 94.3 100.0 74.3 \n0.8 54.5 58.9 48.2 66.9 62.3 41.5 98.7 22.4 \n0.9 12.2 12.0 9.0 16.5 11.3 9.1 54.6 7.3 \n1.1 11.8 15.0 11.1 20.3 18.8 16.9 51.9 9.2 \n1.2 27.7 38.7 40.5 49.2 54.5 52.5 93.4 19.9 \n1.3 56.2 72.3 75.7 80.4 85.7 85.4 99.7 42.0 \n1.4 75.5 91.9 94.1 94.4 97.0 97.6 100.0 70.1 \n1.5 91.4 98.2 99.6 99.0 100.0 100.0 100.0 89.4 \nN=250              \n0.6 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 \n0.7 99.3 100.0 100.0 100.0 100.0 100.0 100.0 97.2 \n0.8 77.8 85.5 79.0 90.8 89.7 76.8 100.0 47.8 \n0.9 20.0 21.5 17.5 27.1 22.5 15.5 74.8 9.6 \n1.1 18.6 18.9 17.7 24.9 27.0 24.5 69.7 11.8 \n1.2 46.3 61.6 63.1 71.1 75.1 73.9 99.1 33.9 \n1.3 79.6 94.1 95.6 95.6 97.7 97.7 100.0 67.8 \n1.4 94.1 99.1 99.5 99.5 99.7 99.9 100.0 94.1 \n1.5 99.8 99.9 100.0 99.9 100.0 100.0 100.0 99.6 \n \n 23\nTable 3: Power of the X2 test against skewness \nAlternative B1:  Ramberg distribution \n          Equiprobable splits     Non-equiprobable splits     \nskew k=4 k=8 k=16 k=4 k=8 k=16 K-S J-B \nN=50           \n0.5 6.1 11.1 11.9 12.5 14.6 13.4 9.8 10.9 \n0.6 7.1 14.5 15.6 16.6 20.4 16.6 11.9 15.9 \n0.7 11.1 26.0 23.2 27.5 29.8 26.8 15.8 28.0 \n0.8 11.9 64.1 50.1 52.4 55.1 49.6 20.8 33.9 \nN=100            \n0.5 8.9 21.0 21.6 23.0 27.6 25.0 14.7 30.8 \n0.6 10.1 33.2 33.4 32.9 45.1 38.1 18.8 48.2 \n0.7 16.9 59.8 58.4 57.9 72.7 62.4 25.7 75.1 \n0.8 19.8 97.9 90.6 89.7 94.4 91.3 35.1 91.8 \nN=150            \n0.5 11.5 30.4 33.8 34.2 45.4 37.5 19.6 55.3 \n0.6 13.8 51.1 53.0 49.5 66.7 59.3 24.7 80.6 \n0.7 22.1 82.6 83.9 79.5 94.6 86.8 35.0 96.8 \n0.8 28.2 100.0 99.6 97.4 99.9 99.9 48.3 99.8 \nN=250            \n0.5 18.0 50.2 58.6 54.9 72.9 63.1 27.5 86.3 \n0.6 24.3 80.2 85.3 76.2 92.9 88.4 41.0 98.9 \n0.7 35.2 98.0 99.2 96.3 100.0 99.8 54.1 100.0 \n0.8 45.6 100.0 100.0 100.0 100.0 100.0 78.0 100.0 \n \n \nAlternative B2:  Two-piece normal \n          Equiprobable splits      Non-equiprobable splits     \nskew k=4 k=8 k=16 k=4 k=8 k=16 K-S J-B \nN=50            \n0.5 7.2 8.0 9.0 9.0 8.3 9.8 7.6 14.1 \n0.6 9.3 14.3 14.0 15.1 17.7 15.4 12.3 20.5 \n0.7 7.1 18.2 16.0 18.6 20.4 17.1 11.2 25.1 \n0.8 9.5 25.6 22.4 26.4 31.1 26.4 13.8 34.8 \nN=100             \n0.5 8.7 14.7 16.5 18.2 19.4 17.9 13.3 32.8 \n0.6 9.1 24.5 25.2 24.9 29.6 25.6 14.8 44.4 \n0.7 10.7 37.1 34.7 39.1 45.6 38.5 19.4 65.8 \n0.8 13.5 57.5 54.6 54.4 66.3 56.5 22.5 77.9 \nN=150             \n0.5 10.6 22.1 24.6 25.6 29.2 26.0 18.1 53.1 \n0.6 12.5 40.3 38.9 38.9 48.1 39.6 19.6 68.3 \n0.7 13.2 54.8 55.1 54.8 70.5 60.5 26.1 89.8 \n0.8 18.7 79.5 78.4 74.4 89.2 81.4 34.6 95.8 \nN=250             \n0.5 14.8 38.0 42.3 42.0 54.6 46.6 24.2 80.6 \n0.6 19.5 62.3 67.0 61.4 79.7 70.2 32.1 94.0 \n0.7 22.1 82.6 85.8 80.7 94.7 90.6 38.9 99.3 \n0.8 27.4 97.7 98.9 95.2 99.8 99.0 51.6 100.0 \n \n 24\nTable 4: Power of the X2 test against kurtosis \nAlternative C2: Anderson's kurtotic distribution \n       Equiprobable splits   Non-equiprobable splits     \nkurtosis k=8 k=16 k=32 k=8 k=16 k=32 K-S J-B \nN=25            \n2.0 12.4 11.2 12.5 3.3 3.7 1.6 13.8 0.1 \n2.8 4.8 5.5 5.9 4.7 4.6 6.8 6.0 1.1 \n3.2 5.4 4.5 6.8 8.6 12.3 14.8 4.3 4.1 \n4.0 8.2 7.4 8.3 25.4 29.0 37.4 8.0 11.3 \n4.8 15.5 14.1 13.2 47.8 52.1 60.7 10.6 18.7 \n5.6 20.1 20.8 19.6 64.3 71.9 78.5 11.5 26.3 \n6.4 29.0 30.4 29.0 72.5 77.6 84.9 14.2 33.8 \n7.2 30.1 32.9 33.2 80.3 85.4 91.2 16.6 38.7 \nN=50             \n2.0 23.8 21.2 14.7 9.4 9.7 3.1 19.9 0.0 \n2.8 6.7 5.8 4.3 4.1 4.0 4.4 6.8 1.9 \n3.2 5.5 4.8 3.6 8.3 10.2 13.8 4.8 5.8 \n4.0 11.4 11.0 10.0 35.3 40.9 45.0 9.1 21.8 \n4.8 24.1 23.8 20.0 66.7 72.7 78.7 14.5 37.0 \n5.6 38.4 39.5 34.5 84.8 90.0 92.4 21.2 49.2 \n6.4 52.6 55.5 49.7 92.6 95.0 96.5 30.8 62.5 \n7.2 60.1 63.5 59.4 96.1 98.1 98.8 35.1 67.1 \nN=100             \n2.0 47.2 46.7 37.9 39.3 37.7 15.9 28.9 14.6 \n2.8 6.2 5.4 5.8 4.1 4.2 3.2 6.3 1.8 \n3.2 5.4 5.2 5.0 7.8 9.5 13.1 4.7 8.4 \n4.0 20.9 20.5 18.7 55.1 60.9 64.6 13.7 33.8 \n4.8 48.9 47.0 44.3 90.0 93.5 93.9 26.2 61.8 \n5.6 70.9 72.2 69.1 98.9 98.8 99.2 44.4 78.8 \n6.4 86.3 86.4 83.9 99.7 100.0 99.9 61.7 88.9 \n7.2 92.6 95.0 93.2 100.0 100.0 100.0 71.8 93.1 \nN=150             \n2.0 69.7 71.9 60.4 74.9 70.9 42.3 40.7 59.3 \n2.8 6.2 7.0 6.3 3.7 4.6 3.7 5.0 2.2 \n3.2 5.6 4.9 5.4 9.7 11.0 13.3 5.5 8.8 \n4.0 30.9 29.9 26.9 68.4 73.9 75.5 16.7 45.0 \n4.8 67.8 70.5 62.9 97.9 98.9 98.7 40.5 79.0 \n5.6 88.3 91.4 88.3 99.7 99.9 100.0 67.3 89.5 \n6.4 97.1 98.1 96.8 100.0 100.0 100.0 82.6 97.3 \n7.2 98.7 98.8 99.3 100.0 100.0 100.0 91.5 98.8 \n \nAlternative C1: Stable distribution \n       Equiprobable splits   Non-equiprobable splits     \nN k=8 k=16 k=32 k=8 k=16 k=32 K-S J-B \n\u0003=1.975\u0002            \n25 21.6 25.7 25.7 41.3 45.2 47.0 14.9 5.4 \n50 43.9 48.4 46.0 70.2 69.9 68.3 25.8 9.2 \n75 63.5 70.4 68.9 86.4 86.9 85.0 37.0 12.9 \n100 79.0 84.5 82.1 93.9 93.5 93.2 50.9 16.5 \n150 93.1 95.7 94.8 99.4 99.3 99.2 74.8 19.7 \n250 99.9 99.7 100.0 100.0 100.0 100.0 96.5 29.6 \n350 100.0 100.0 100.0 100.0 100.0 100.0 99.1 34.3 \n \n 25\n \n \nFigure 1a: Power of X2 test against variance departure, N =150, \u0001>1 (equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40\nk\n%\nd=1.1\nd=1.2\nd=1.3\nd=1.4\nd=1.5\nFigure 1b: Power of X 2 test against variance departure, N =150, \u0001<1 (equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40\nk\n%\nd=0.9\nd=0.8\nd=0.7\nd=0.6\n 26\n \n \nFigure 2a: Power of X 2 test against variance departure, N =150 (non-equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n0.15 0.175 0.2 0.225 0.25 0.275 0.3\nF 2\n%\nd=0.7\nd=0.8\nd=0.9\nd=1.1\nd=1.2\nd=1.3\nFigure 2b: Power of the PCSc test against variance departure, N =150 (non-equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n0.15 0.175 0.2 0.225 0.25 0.275 0.3\nF 2\n%\nd=0.7\nd=0.8\nd=0.9\nd=1.1\nd=1.2\nd=1.3\n 27\n \nFigure 4:  Power of the X 2 test against skewness (B 1: Ramberg distribution) N =150 (equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40\nskewness\n%\nskew=0.2\nskew=0.4\nskew=0.6\nskew=0.8\nFigure 3: Power of the X 2 test against variance departure, N =150\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 1.7\n\u0001\n%\nk=10\nk=8(ne)\nPcSc\nchi-sq\nK-S\n 28\n \n \n \n \nFigure 5: Power of the X 2 test against skewness (B2: two-piece). Skew=0.5, (equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40\nk\nPo\nw\ner\nN=25\nN=50\nN=75\nN=100\nN=150\nN=250\nN=350\nFigure 6:  Power of the X 2 test against skewness (B 3: Anderson) N =150 (equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40\nk\n%\nskew=0.2\nskew=0.4\nskew=0.6\nskew=0.8\n 29\n \n \nFigure 7a: Power of the X 2 test against skewness (B1: Ramberg), N=150 (non-equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n0.15 0.175 0.2 0.225 0.25 0.275 0.3\nF 2\n%\nskew=0.2\nskew=0.4\nskew=0.6\nskew=0.8\nFigure 7b: Power of the PCSk test against skewness (B 1: Ramberg), N =150 (non-equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n0.15 0.175 0.2 0.225 0.25 0.275 0.3\nF 2\n%\nskew=0.2\nskew=0.4\nskew=0.6\nskew=0.8\n 30\n \n \n \n \n \n \nFigure 8a: Power against skewness (B 1: Ramberg), N=150\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85\nskewness\n%\nk=8\nk=8(NE)\nPCSk\nK-S\nJ-B\nFigure 8b: Power against skewness (B 3: Anderson), N=150\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85\nskewness\n%\nk=8\nk=8(ne)\nPCSk\nK-S\nJ-B\n 31\n \n \n \n \nFigure 9: Power of the X 2 test agasinst kurtosis (C 1: Stable distribution), N=150\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40\nk\n%\nalpha=1.975\nalpha=1.95\nalpha=1.8\nFigure 10: Power of the X 2 test against kurtosis (C 2: Anderson), N=150 (equiprobable)\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40\nk\n%\nkurt=2.0\nkurt=3.6\nkurt=4.4\nkurt=5.2\nkurt=6.0\n 32\n \n \n0.25\n0.3\n0.35\n0.4\n0.45\n0.025 0.05 0.075 0.1 0.125 0.15 0.175 0.2\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n%\nF 3\nF 1\nFigure 11a: Power of the X 2 test against kurtosis (C 1: Stable, \u0002\u00031.975), N=100\n0.25\n0.3\n0.35\n0.4\n0.45\n0.025 0.05 0.075 0.1 0.125 0.15 0.175 0.2\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n%\nF 3\nF 1\nFigure 11b: Power of the PCK component test against kurtosis (C 1: Stable, \u0002=1.975), N=100\n 33\n \n \n \n \n \nFigure 12: Power against kurtosis (C 1: Stable), N=100\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n1.5 1.55 1.6 1.65 1.7 1.75 1.8 1.85 1.9 1.95 2\n\u0002\n%\nk=16\nk=8(ne)\nPCK\nK-S\nJ-B\nFigure 13: Power against kurtosis (C 2: Anderson) N=150\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n2 2.4 2.8 3.2 3.6 4 4.4 4.8 5.2 5.6 6 6.4 6.8 7.2\nkurtosis\n%\nk=10\nk=8(ne)\nPCK\nK-S\nJ-B\n"}
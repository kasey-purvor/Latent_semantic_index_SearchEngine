{"doi":"10.1111\/j.1467-9868.2011.00773.x","coreId":"220297","oai":"oai:eprints.lse.ac.uk:37663","identifiers":["oai:eprints.lse.ac.uk:37663","10.1111\/j.1467-9868.2011.00773.x"],"title":"Thick pen transformation for time series","authors":["Fryzlewicz, Piotr","Oh, H. S."],"enrichments":{"references":[{"id":17292309,"title":"A wavelet-based test for stationarity.","authors":[],"date":"2000","doi":"10.1111\/1467-9892.00200","raw":"M. Neumann and R. von Sachs. A wavelet-based test for stationarity. J. Time Ser. Anal., 21:597\u2013613, 2000.","cites":null},{"id":17292285,"title":"Break detection for a class of nonlinear time series models.","authors":[],"date":"2008","doi":"10.1111\/j.1467-9892.2008.00585.x","raw":"R. Davis, T. Lee, and G. Rodriguez-Yam. Break detection for a class of nonlinear time series models. Journal of Time Series Analysis, 29:834\u2013867, 2008.","cites":null},{"id":17292271,"title":"Convergence of Probability Measures.","authors":[],"date":"1968","doi":"10.1002\/9780470316962","raw":"P. Billingsley. Convergence of Probability Measures. Wiley, New York, 1968.","cites":null},{"id":17292270,"title":"Detecting multiple breaks in \ufb01nancial market volatility dynamics.","authors":[],"date":"2002","doi":"10.2139\/ssrn.313639","raw":"E. Andreou and E. Ghysels. Detecting multiple breaks in \ufb01nancial market volatility dynamics. Journal of Applied Econometrics, 17:579\u2013600, 2002.","cites":null},{"id":17292300,"title":"Discrimination and clustering for multivariate time series.","authors":[],"date":"1998","doi":"10.2307\/2669629","raw":"Y. Kakizawa, R. Shumway, and M. Taniguchi. Discrimination and clustering for multivariate time series. Journal of the American Statistical Association, 93:328\u2013340, 1998.","cites":null},{"id":17292325,"title":"Evolutionary spectra and non-stationary processes.","authors":[],"date":"1965","doi":null,"raw":"M. Priestley. Evolutionary spectra and non-stationary processes. Journal of the Royal Statistical Society. Series B, 27:204\u2013237, 1965.","cites":null},{"id":17292302,"title":"Exact indexing of dynamic time warping.","authors":[],"date":"2005","doi":"10.1007\/s10115-004-0154-9","raw":"E. Keogh and C.A. Ratanamahatana. Exact indexing of dynamic time warping. Knowledge and Information Systems, 7:358\u2013386, 2005.","cites":null},{"id":17292281,"title":"Fitting time series models to nonstationary processes.","authors":[],"date":"1997","doi":"10.1214\/aos\/1034276620","raw":"R. Dahlhaus. Fitting time series models to nonstationary processes. Ann. of Stat., 25:1\u201337, 1997.","cites":null},{"id":17292299,"title":"Hotelling\u2019s theorem of the volume of tubes: some illustrations in simultaneous inference and data analysis.","authors":[],"date":"1990","doi":"10.1214\/aos\/1176347620","raw":"S. Johansen and I.M. Johnstone. Hotelling\u2019s theorem of the volume of tubes: some illustrations in simultaneous inference and data analysis. Annals of Statistics, 18:652\u2013684, 1990.","cites":null},{"id":17292319,"title":"Improved SiZer for time series.","authors":[],"date":"2009","doi":"10.1016\/j.jspi.2009.05.003","raw":"C. Park, J. Hannig, and K.-H. Kang. Improved SiZer for time series. Statistica Sinica, 19: 1511\u20131530, 2009.","cites":null},{"id":17292287,"title":"Least angle regression.","authors":[],"date":"2004","doi":"10.1214\/009053604000000067","raw":"33B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani. Least angle regression. Annals of Statistics, 32:407\u2013499, 2004.","cites":null},{"id":17292338,"title":"Locally adaptive estimation of evolutionary wavelet spectra.","authors":[],"date":"2008","doi":"10.1214\/07-aos524","raw":"S. Van Bellegem and R. von Sachs. Locally adaptive estimation of evolutionary wavelet spectra. Annals of Statistics, 36:1879\u20131924, 2008.","cites":null},{"id":17292298,"title":"Long term storage capacity of reservoirs.","authors":[],"date":"1951","doi":"10.1680\/iicep.1956.11503","raw":"H.E. Hurst. Long term storage capacity of reservoirs. Trans. Am. Soc. Civil Engineers, 116: 770\u2013799, 1951.","cites":null},{"id":17292344,"title":"Min max operators in texture analysis.","authors":[],"date":"1985","doi":"10.1109\/tpami.1985.4767732","raw":"M. Werman and S. Peleg. Min max operators in texture analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, 7:730\u2013733, 1985.","cites":null},{"id":17292304,"title":"Morphologic edge detection.","authors":[],"date":"1987","doi":"10.1109\/jra.1987.1087088","raw":"S. Lee, R.M. Haralick, and L.G. Shapiro. Morphologic edge detection. IEEE Transactions on Robotics and Automation, 3:142\u2013156, 1987.","cites":null},{"id":17292330,"title":"Non-stationarities in stock returns.","authors":[],"date":"2005","doi":"10.1162\/0034653054638274","raw":"C. Starica and C. Granger. Non-stationarities in stock returns. Review of Economics and Statistics, 87:503\u2013522, 2005.","cites":null},{"id":17292288,"title":"Nonlinear Time Series.","authors":[],"date":"2003","doi":"10.1007\/b97702","raw":"J. Fan and Q. Yao. Nonlinear Time Series. Springer-Verlag, New York, 2003.","cites":null},{"id":17292290,"title":"Normalised least-squares estimation in time-varying ARCH models.","authors":[],"date":"2008","doi":"10.1214\/07-aos510","raw":"P. Fryzlewicz, T. Sapatinas, and S. Subba Rao. Normalised least-squares estimation in time-varying ARCH models. Annals of Statistics, 36:742\u2013786, 2008.","cites":null},{"id":17292303,"title":"On Hotelling\u2019s geometric approach to testing for a nonlinear parameter in regression.","authors":[],"date":"1988","doi":"10.2307\/1403794","raw":"M. Knowles and D. Siegmund. On Hotelling\u2019s geometric approach to testing for a nonlinear parameter in regression. International Statistical Review, 57:205\u2013220, 1988.","cites":null},{"id":17292292,"title":"On the performance of box-counting estimators of fractal dimension.","authors":[],"date":"1993","doi":"10.2307\/2336774","raw":"P. Hall and A. Wood. On the performance of box-counting estimators of fractal dimension. Biometrika, 80:246\u2013252, 1993.","cites":null},{"id":17292345,"title":"On the volume of tubes.","authors":[],"date":"1939","doi":"10.2307\/2371513","raw":"H. Weyl. On the volume of tubes. American Journal of Mathematics, 61:461\u2013472, 1939.","cites":null},{"id":17292337,"title":"Regression shrinkage and selection via the lasso.","authors":[],"date":"1996","doi":"10.1111\/j.1467-9868.2011.00771.x","raw":"R. Tibshirani. Regression shrinkage and selection via the lasso. J. Royal. Statist. Soc. B, 58:267\u2013288, 1996.","cites":null},{"id":17292286,"title":"Running max\/min calculation using a pruned ordered list.","authors":[],"date":"1996","doi":"10.1109\/78.542446","raw":"S. Douglas. Running max\/min calculation using a pruned ordered list. IEEE Transactions on Signal Processing, 44:2872\u20132877, 1996.","cites":null},{"id":17292305,"title":"Scale-Space Theory in Computer Vision.","authors":[],"date":"1994","doi":"10.1007\/978-1-4757-6465-9","raw":"T. Lindeberg. Scale-Space Theory in Computer Vision. Kluwer, Boston, 1994.","cites":null},{"id":17292275,"title":"SiZer for exploration of structures in curves.","authors":[],"date":"1999","doi":"10.2307\/2669996","raw":"P. Chaudhuri and J.S. Marron. SiZer for exploration of structures in curves. Journal of the American Statistical Association, 94:807\u2013823, 1999. J. Cho and J. Bae. Edge-adaptive local min\/max nonlinear \ufb01lter-based shoot suppression.","cites":null},{"id":17292327,"title":"SiZer for time series: A new approach to the analysis of trends.","authors":[],"date":"2007","doi":"10.1214\/07-ejs006","raw":"V. Rondonotti, J.S. Marron, and C. Park. SiZer for time series: A new approach to the analysis of trends. Electronic Journal of Statistics, 1:268\u2013289, 2007.","cites":null},{"id":17292326,"title":"Spectral Analysis and Time Series.","authors":[],"date":"1981","doi":null,"raw":"34M. B. Priestley. Spectral Analysis and Time Series. Academic Press, 1981.","cites":null},{"id":17292343,"title":"Statistical Modeling by Wavelets.","authors":[],"date":"1999","doi":"10.1002\/9780470317020","raw":"B. Vidakovic. Statistical Modeling by Wavelets. Wiley, New York, 1999.","cites":null},{"id":17292283,"title":"Stochastic Limit Theory.","authors":[],"date":"1994","doi":"10.1093\/0198774036.001.0001","raw":"J. Davidson. Stochastic Limit Theory. Oxford University Press, 1994.","cites":null},{"id":17292360,"title":"Stroke-model-based character extraction from gray-level document images.","authors":[],"date":"2001","doi":"10.1109\/83.935031","raw":"X. Ye, M. Cheriet, and C.Y. Suen. Stroke-model-based character extraction from gray-level document images. IEEE Transactions on Image Processing, 8:1152\u20131161, 2001.","cites":null},{"id":17292336,"title":"Tail probabilities of the maxima of Gaussian random \ufb01elds.","authors":[],"date":"1993","doi":"10.1214\/aop\/1176989393","raw":"J. Sun. Tail probabilities of the maxima of Gaussian random \ufb01elds. Annals of Probability, 21:34\u201371, 1993.","cites":null},{"id":17292312,"title":"Testing temporal constancy of the spectral structure of a time series.","authors":[],"date":"2009","doi":"10.3150\/08-bej179","raw":"E. Paparoditis. Testing temporal constancy of the spectral structure of a time series. Bernoulli, 15:1190\u20131221, 2009.","cites":null},{"id":17292301,"title":"The distribution of the maximum Brownian excursion.","authors":[],"date":"1976","doi":"10.2307\/3212843","raw":"D. Kennedy. The distribution of the maximum Brownian excursion. J. Appl. Prob., 13: 371\u2013376, 1976.","cites":null},{"id":17292340,"title":"The use of Boolean functions and logical operations for edge detection in images.","authors":[],"date":"1995","doi":"10.1016\/0165-1684(95)00048-i","raw":"M. Vemis, G. Economou, S. Fotopoulos, and A. Khodyrev. The use of Boolean functions and logical operations for edge detection in images. Signal Processing, 45:161\u2013172, 1995.","cites":null},{"id":17292329,"title":"Time Series Analysis and Its Applications: With R Examples, 2nd Edition.","authors":[],"date":"2006","doi":"10.1007\/s10182-008-0064-3","raw":"R. H. Shumway and D. S. Sto\ufb00er. Time Series Analysis and Its Applications: With R Examples, 2nd Edition. Springer, New York, 2006.","cites":null},{"id":17292273,"title":"Time Series: Data Analysis and Theory.","authors":[],"date":"1975","doi":"10.2307\/2530198","raw":"D. R. Brillinger. Time Series: Data Analysis and Theory. Holt, Rinehart & Winston, Inc., New York, 1975.","cites":null},{"id":17292274,"title":"Time Series: Theory and Methods.","authors":[],"date":"1987","doi":"10.1007\/978-1-4899-0004-3","raw":"P. J. Brockwell and R. A. Davis. Time Series: Theory and Methods. Springer, 1987.","cites":null},{"id":17292297,"title":"Tubes and spheres in n-spaces, and a class of statistical problems.","authors":[],"date":"1939","doi":"10.2307\/2371512","raw":"H. Hotelling. Tubes and spheres in n-spaces, and a class of statistical problems. American Journal of Mathematics, 61:440\u2013460, 1939.","cites":null},{"id":17292308,"title":"Wavelet Methods","authors":[],"date":"2008","doi":"10.1007\/978-0-387-75961-6","raw":"G. P. Nason. Wavelet Methods in Statistics with R. Springer, New York, 2008.","cites":null},{"id":17292321,"title":"Wavelet Methods for Time Series Analysis.","authors":[],"date":"2000","doi":"10.1017\/cbo9780511841040.012","raw":"D. B. Percival and A. T. Walden. Wavelet Methods for Time Series Analysis. Cambridge University Press, 2000.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-09","abstract":"Traditional visualization of time series data often consists of plotting the time series values against time and 'connecting the dots'. We propose an alternative, multiscale visualization technique, motivated by the scale-space approach in computer vision. In brief, our method also 'connects the dots' but uses a range of pens of varying thicknesses for this. The resulting multiscale map, which is termed the thick pen transform, corresponds to viewing the time series from a range of distances. We formally prove that the thick pen transform is a discriminatory statistic for two Gaussian time series with distinct correlation structures. Further, we show interesting possible applications of the thick pen transform to measuring cross-dependence in multivariate time series, classifying time series and testing for stationarity. In particular, we derive the asymptotic distribution of our test statistic and argue that the test is applicable to both linear and non-linear processes under low moment assumptions. Various other aspects of the methodology, including other possible applications, are also discussed","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/220297.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/37663\/1\/Thick_pen_transformation_for_time_series%28lsero%29.pdf","pdfHashValue":"fc1b479c5f2b4901b8e9a34a0d6f71c1c6b59e76","publisher":"Wiley on behalf of the Royal Statistical Society","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:37663<\/identifier><datestamp>\n      2017-10-16T09:16:31Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5354<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/37663\/<\/dc:relation><dc:title>\n        Thick pen transformation for time series<\/dc:title><dc:creator>\n        Fryzlewicz, Piotr<\/dc:creator><dc:creator>\n        Oh, H. S.<\/dc:creator><dc:subject>\n        HA Statistics<\/dc:subject><dc:description>\n        Traditional visualization of time series data often consists of plotting the time series values against time and 'connecting the dots'. We propose an alternative, multiscale visualization technique, motivated by the scale-space approach in computer vision. In brief, our method also 'connects the dots' but uses a range of pens of varying thicknesses for this. The resulting multiscale map, which is termed the thick pen transform, corresponds to viewing the time series from a range of distances. We formally prove that the thick pen transform is a discriminatory statistic for two Gaussian time series with distinct correlation structures. Further, we show interesting possible applications of the thick pen transform to measuring cross-dependence in multivariate time series, classifying time series and testing for stationarity. In particular, we derive the asymptotic distribution of our test statistic and argue that the test is applicable to both linear and non-linear processes under low moment assumptions. Various other aspects of the methodology, including other possible applications, are also discussed.<\/dc:description><dc:publisher>\n        Wiley on behalf of the Royal Statistical Society<\/dc:publisher><dc:date>\n        2011-09<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/37663\/1\/Thick_pen_transformation_for_time_series%28lsero%29.pdf<\/dc:identifier><dc:identifier>\n          Fryzlewicz, Piotr and Oh, H. S.  (2011) Thick pen transformation for time series.  Journal of the Royal Statistical Society. Series B: Statistical Methodology, 73 (4).  pp. 499-529.  ISSN 1369-7412     <\/dc:identifier><dc:relation>\n        http:\/\/www.wiley.com\/bw\/journal.asp?ref=1369-7412<\/dc:relation><dc:relation>\n        10.1111\/j.1467-9868.2011.00773.x<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/37663\/","http:\/\/www.wiley.com\/bw\/journal.asp?ref=1369-7412","10.1111\/j.1467-9868.2011.00773.x"],"year":2011,"topics":["HA Statistics"],"subject":["Article","PeerReviewed"],"fullText":"  \nPiotr Fryzlewicz, and H. S. Oh \nThick pen transformation for time series \n \nArticle (Accepted version) \n(Unrefereed) \n \n \n Original citation: Fryzlewicz, Piotr and Oh, H. S. (2011) Thick pen transformation for time series. Journal of the \nRoyal Statistical Society, series B, 73 (4). pp. 499-529. ISSN 1369-7412 \nDOI: 10.1111\/j.1467-9868.2011.00773.x \n \n\u00a9 2011 Royal Statistical Society \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/37663\/ \nAvailable in LSE Research Online: November 2011 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final accepted version of the journal article. There may be \ndifferences between this version and the published version.  You are advised to consult the \npublisher\u2019s version if you wish to cite from it. \n \n \n \nThick-pen transformation for time series\nP. Fryzlewicz H.-S. Oh\nJanuary 1, 2011\nAbstract\nTraditional visualisation of time series data often consists of plotting the time series\nvalues against time and \u201cconnecting the dots\u201d. We propose an alternative, multiscale\nvisualisation technique, motivated by the scale-space approach in computer vision. In\nbrief, our method also \u201cconnects the dots\u201d, but uses a range of pens of varying thick-\nnesses for this purpose. The resulting multiscale map, termed the Thick-Pen Transform\n(TPT) corresponds to viewing the time series from a range of distances. We formally\nprove that the TPT is a discriminatory statistic for two Gaussian time series with dis-\ntinct correlation structures. Further, we show interesting possible applications of the\nTPT to measuring cross-dependence in multivariate time series, classifying time series,\nand testing for stationarity. In particular, we derive the asymptotic distribution of our\ntest statistic, and argue that the test is applicable to both linear and nonlinear processes\nunder low moment assumptions. Various other aspects of the methodology, including\nother possible applications, are also discussed.\n1 Introduction\nTraditional objectives of time series analysis are at least twofold: to obtain an understanding\nof certain aspects of the data, and to forecast future values, although other objectives, such\nas for example process control, have also been extensively studied. Naturally enough, not\nall of these aims are relevant to or present in every case study: for example, in time series\nclassification problems, the focus will typically be on understanding and summarising the\ndata rather than forecasting.\nStatistical time series analysis typically tackles these aims by firstly assuming a statistical\nmodel, which can be either parametric or nonparametric, and then using suitable tools\nto estimate its parameters. Classical modelling, estimation and forecasting techniques for\nprocesses which are linear in their innovations and either stationary or easily transformed\ninto such, have been extensively covered in many excellent monographs, including Brillinger\n(1975), Priestley (1981), Brockwell and Davis (1987) and Shumway and Stoffer (2006), while\nstationary but nonlinear processes, including some of the models widely used in finance, are\ndescribed, for example, in Fan and Yao (2003).\nComparatively less literature exists on statistically rigorous modelling and estimation ideas\nfor nonstationary time series, where, necessarily, some modelling effort is needed to control\n1\nthe degree of nonstationarity in the process before consistent statistical inference is possible.\nNot attempting to be exhaustive, we mention the seminal work of Priestley (1965), who in-\ntroduced models based on a time-dependent transfer function in the spectral representation\nof nonstationary processes, and Dahlhaus (1997), who set up a framework for asymptotic\nconsiderations in nonstationary models by employing the rescaled-time principle.\nIn the following discussion, let Xt denote a generic univariate real-valued time series, or a\nreal-valued univariate component of a multivariate time series (we note that the method-\nology proposed in this work is applicable in both univariate and multivariate time series\nanalysis). Regardless of the nature of the problem to be solved, of the time series model\nto be used, and of the statistical techniques employed in the chosen model, the first step\nin the exploratory analysis of Xt is often the plotting and visual inspection of its values.\nWhile subsequent steps of the analysis, starting with the model choice, have understand-\nably received enormous attention in the statistical literature over the years, it appears to us\nthat the initial visualisation has been overwhelmingly skewed towards plotting the values of\n(t,Xt) and \u201cconnecting the dots\u201d. Useful as it undoubtedly is, the relative lack of variation\nin this initial step across time series literature prompts us to ask whether more can be\nachieved at this stage, perhaps by employing a more informative visualisation technique.\nAt the core of our alternative proposal for visualising time series data, which we later\nterm the \u201cthick-pen transform\u201d for time series, lies the idea of looking at time series data\nat multiple scales, or equivalently from multiple distances. To clarify and motivate our\nproposal, we consider the following visual experiment. The left-hand plot of Figure 1\nshows conventional \u201cconnect-the-dots\u201d visualisation of a piecewise-stationary time series,\nconsisting of white noise followed by a low-frequency sine wave. Moving away from the\nimage, or alternatively looking at the image with eyes half-closed, we are likely to observe\nthe illusory \u201cdisappearance\u201d of the sine wave. If we believe that visibility of the time series\nfrom a distance is linked to the \u201cvolume\u201d created by the line used to connect the dots, we\ncan prevent this phenomenon simply by using a thicker pen to plot the second half of the\ndata, which is done in the right-hand plot of Figure 1.\nOne possible lesson from this experiment is that the degree of visibility of time series data\nfrom a distance can be a helpful indicator of local structural properties of the data, as it\nis clearly able to discriminate between fast- and slowly-oscillating signals. Since, as argued\nabove, it is possible to associate \u201cvisibility\u201d from a certain distance with the \u201cvolume\u201d\ncreated by a pen of a certain thickness used to connect the points (t,Xt), we propose to\nvisualise a time series by plotting it using pens of various thicknesses, hoping that the\nresulting set of plots will provide interesting and useful information about the structure of\nthe time series, not only in a heuristic, but also in a formal probabilistic sense.\nThe above discussion leads us to the first preliminary definition of our \u201cthick-pen transform\u201d\nfor time series, which, without making it precise at this stage, we mean to denote a set\nof plots of the time series values, each performed using a pen of a different thickness.\nThe transform is clearly multiscale, with larger thickness values bringing out coarser-scale\nfeatures of the data. As a taster, we show in Figure 2 the same time series plotted with\npens of thickness 5 and 30 (units are arbitrary but their ratio correctly reflects relative\nthickness). As the rest of this article will argue, the thick-pen transform can be useful in\ntasks such as nonstationarity detection, time series classification, or measuring dependence\nbetween time series, amongst others.\nTime series literature is no stranger to the concept of \u201clooking at data at multiple scales\u201d,\n2\n0 200 400 600 800\n\u2212\n3\n\u2212\n2\n\u2212\n1\n0\n1\n2\n0 200 400 600 800\n\u2212\n3\n\u2212\n2\n\u2212\n1\n0\n1\n2\nFigure 1: White noise followed by slow wave, plotted with pen of thickness 1 (left plot) and\n1 followed by 20 (right plot).\nand references are diverse and rather loosely connected. Wavelets, which provide linear,\nmultiscale and local decomposition of data, have been used extensively in time series anal-\nysis; the reader is referred to the monographs of Vidakovic (1999), Percival and Walden\n(2000) and Nason (2008) and the references therein. Self-similarity and (multi-)fractality\nare often-recurring concepts in time series analysis, aiming to study parametric relation-\nships between distributions of the process at different scales, particularly in the context of\nlong-range dependent processes, see e.g. Doukhan et al. (2003). Other uses of multiscale\nmethods in time series are rarer, but include, for example, Van Bellegem and von Sachs\n(2008), who use a multiscale technique based on iterative testing for intervals of homogene-\nity for the purpose of second-order structure estimation in locally stationary time series.\nBesides using different methodology, our approach differs from the above in that in its\nphilosophy, it is primarily a visualisation technique (although its ultimate aim is to aid in\nsolving some well-established time series tasks such as those listed above). Unlike wavelets,\nit is not linear, and is not concerned with estimation: in particular, we do not define or\nattempt to estimate parameters such as the long-memory parameter, fractal dimensionality\nor the Hurst exponent. Indeed, the thick-pen transform can also be meaningfully applied\nto nonparametric time series models.\nAlthough different in terms of its aims and methodology, our approach shares some of\nits spirit with SiZer (Chaudhuri and Marron (1999)), a data visualisation technique for\ndisplaying features of kernel-smoothed data as a function of location and bandwidth, si-\nmultaneously over a range of bandwidths. The similarity with thick-pen is that the latter\ndisplays the time series simultaneously over a range of pen thickness values, without at-\ntempting to choose a \u201cbest\u201d thickness. Secondly, like SiZer, the thick-pen transform is also\nmotivated by the \u201cscale-space\u201d theory in computer vision (Lindeberg (1994)) in that as ar-\ngued above, large thickness values (or: larger bandwidths in SiZer) bring out features of the\ndata best seen from a large distance. Similarly, small thickness values (smaller bandwidths\n3\n0 200 400 600 800\n\u2212\n3\n\u2212\n1\n0\n1\n2\n3\n0 200 400 600 800\n\u2212\n3\n\u2212\n1\n0\n1\n2\n3\nFigure 2: White noise followed by slow wave, plotted with pen of thickness 5 (left plot) and\n30 (right plot).\nin SiZer) permit visualisation of features observable when zooming in closer. The funda-\nmental difference with SiZer is that the thick-pen transform (a) is designed for exploring\nthe dependence structure of time series rather than the shape of curves, and (b) is based on\nnonlinear operations (as described in Section 2), as opposed to the linear smoothing used in\nSiZer. We note that SiZer for time series, also based on kernel smoothing, has been studied\nin Rondonotti et al. (2007) and Park et al. (2009).\nThe paper is organised as follows. Section 2 outlines the basic methodology of the thick-\npen transform, and demonstrates its variation-diminishing and discrimination properties.\nSection 3 focuses on three possible applications of the thick-pen transform: testing for\nstationarity (where we propose the test, derive its asymptotic distribution under the null\nhypothesis and illustrate with simulated and real-data examples), classifying time series\n(where we propose the algorithm and apply it to a well-known geophysical dataset) and\nmeasuring dependence between time series (where we propose the measure and investigate\nvia simulated and real-data examples). Finally, Section 4 lists possible avenues for further\nresearch.\n2 Basic methodology and theory of the thick-pen transform\nFor the purpose of this and subsequent sections, we qualitatively define the thick-pen trans-\nform of a real-valued univariate process (Xt)\nn\nt=1 as follows. Let T denote the set of thickness\nparameters. For each \u03c4i \u2208 T , i = 1, . . . , |T |, let U \u03c4it denote the upper boundary of the area\ncovered by a pen of thickness \u03c4i while connecting the points (t,Xt)\nn\nt=1. Similarly, let L\n\u03c4i\nt\ndenote its lower boundary. The thick-pen transform TPT (Xt) is the sequence of all pairs\nof boundaries, i.e.\nTPT (Xt) = {(L\u03c4it , U \u03c4it )nt=1}i=1,...,|T |.\n4\nThe precise mathematical form of TPT (Xt) depends on the shape of the pen used. The\nexamples below describe two possibly the most natural pen shapes, as well as briefly dis-\ncussing other possible shapes. In all of the examples below, we let the set T of thickness\nparameters be the set of positive integers, i.e. T = {1, 2, . . .}.\nSquare pen. In this example, the pen is a closed square of side length \u03c4 \u2208 T , positioned\nso that two of its sides are parallel to the time axis. For each point along the straight\nline connecting (t,Xt) with (t+ 1,Xt+1), we place the pen so that the given point is\nat the centre of the right-hand side of the pen. In this set-up, we have\nU \u03c4t = max(Xt, . . . ,Xt+\u03c4 ) +\n\u03c4\n2\n(1)\nL\u03c4t = min(Xt, . . . ,Xt+\u03c4 )\u2212\n\u03c4\n2\n. (2)\nImportantly, we note the following recursive formula for computing U \u03c4t thickness-by-\nthickness: U \u03c4t = max(U\n\u03c4\u22121\nt , U\n\u03c4\u22121\nt+1 ) +\n1\n2 . Obviously, an analogous formula holds for\nL\u03c4t . For extra flexibility, we admit the possibility of replacing the constants \u00b1 \u03c42 with\n\u00b1\u03b3 \u03c42 , where the constant \u03b3 is termed the \u201cscaling factor\u201d and is to be chosen by the\nanalyst. We do not dwell on the choice of \u03b3 in this work, and set it by default to one\nin the examples below, unless mentioned otherwise.\nRound pen. Let the pen be a closed circle with diameter \u03c4 \u2208 T , positioned so that for\neach point along the straight line connecting (t,Xt) with (t + 1,Xt+1), the pen is\ncentred at the given point. Denoting by Z the set of integers, we have\nU \u03c4t = max\nk\u2208[\u2212|\u03c4 |\/2,|\u03c4 |\/2]\u2229Z\n{Xt+k +\n\u221a\n\u03c42\/4\u2212 k2} (3)\nL\u03c4t = min\nk\u2208[\u2212|\u03c4 |\/2,|\u03c4 |\/2]\u2229Z\n{Xt+k \u2212\n\u221a\n\u03c42\/4\u2212 k2}. (4)\nAs with the square pen, for extra flexibility, the additive terms \u00b1\n\u221a\n\u03c42\/4\u2212 k2 could\nbe replaced by \u00b1\u03b3\n\u221a\n\u03c42\/4\u2212 k2. In what follows, the scaling factor \u03b3 is always set to\none unless mentioned otherwise.\nOther possible pen shapes. We note the following interesting connection between the\nabove formulae (1) \u2013 (4) and kernel smoothing. Replacing the addition and subtraction\nby multiplication, and the \u201cmax\u201d and \u201cmin\u201d operators by the summation operator,\nwe obtain, up to a multiplicative factor proportional to \u03c42, kernel-smoothed versions\nof Xt using the one-sided uniform kernel (in the square-pen case) and the two-sided\ncircular kernel (in the round-pen case). Obvious generalisations of the square and\nround pens could be obtained by employing other kernel shapes.\nMore on the duality between kernel smoothing and the thick pen. Despite the du-\nality between kernel smoothing and the thick pen (as described above), these two are\nentirely different operations and they serve different purposes. Computed using a\nsingle bandwidth\/thickness, kernel smoothing of Xt produces one linear output se-\nquence (weighted local means of Xt), whereas the thick-pen transform produces two\nnonlinear output sequences L\u03c4t and U\n\u03c4\nt . Unlike the kernel-smoothed version of Xt\n(which can serve to estimate the trend but not the local dependence structure of Xt),\nthe thick-pen transform of Xt provides useful information on both the trend and the\n5\nlocal dependence structure, which we explain later in this section, and in particular\nin Theorem 2.1. By contrast, in order to use kernel smoothing to estimate or make\ninference on the local dependence structure of Xt, one would have to kernel-smooth\nnot Xt, but other local statistics of Xt (e.g. the sequence XtXt+1 to estimate the local\ncovariance at lag one; or local periodograms to estimate the local spectral density).\nWe note that for a fixed value of \u03c4 (i.e. focusing on a \u201csingle scale\u201d of our thick-pen\ntransform), and disregarding the additive constant \u03c4\/2, formulae (1), (2) are reminiscent of\nthe running maximum and minimum filters, used in signal and image processing for tasks\nsuch as edge detection (Lee et al. (1987), Douglas (1996), Vemis et al. (1995)), texture\ndescription (Werman and Peleg (1985)), character extraction (Ye et al. (2001)), indexing\nof dynamic time warping (Keogh and Ratanamahatana (2005)), or the suppression of over-\nand under-shoot (Cho and Bae (2006)). However, the fundamental difference with our\napproach is that the thick-pen transform puts these filters in a multiscale context (which,\nincidentally, is precisely what SiZer does to kernel smoothing) by considering a range of\nthickness parameters \u03c4 simultaneously. This is done with the initial aim of visualising time\nseries data, and the eventual aim of solving some classical problems in statistical time series\nanalysis mentioned earlier. Also, in contrast to the above heuristic approaches, ours is\nmore rigorous in that we formally prove, later in this section, that the thick-pen transform\ndiscriminates between two time series with different correlation structures (see Theorem\n2.1). One essential ingredient of this result is the multiscale context in which the thick-pen\ntransform operates.\nWe now consider a toy example which shows one possible way of visualising the thick-pen\ntransform. The top plot in Figure 3 shows the conventional visualisation of a time series\nconsisting of Gaussian white noise in the first half, and the Gaussian AR(1) process with\nparameter 0.9 in the second half. Both processes have the same variance. The middle\nplot shows the thick-pen transform using the round pen, with pen thicknesses ranging from\n10 to 100 in multiples of 10, where each trajectory is superimposed on the next thicker\none. The bottom plot shows the same object plotted with a different colour pattern. The\nreader is invited to think of this object as the \u201cthick-pen map\u201d of the given process. While\nvisual inspection of the top plot reveals obvious visual difference between the structure of\nthe process in the first and second half, a look at the thick-pen map reveals the multiscale\nnature of this difference. For instance, considering the bottom plot at the \u201cthinnest\u201d scale,\nwe observe the frequent brief but deep incursions of non-white colours into the white area in\nthe second, more structured half. On the other hand, at the \u201cthickest\u201d scales, by looking at\nthe darkest colours, the incursions in the second half are still present but are much longer-\nlasting and more shallow: consider, for example, the incursions around time t = 350 (lower\nboundary) or time t = 400 (upper boundary). We note that none of these features are\nobvious from the visual inspection of the top plot, but could serve as potentially interesting\n\u201cmarkers\u201d for discriminating between the two halves or detecting the change-point.\nHowever, it is important to bear in mind that the analyst does need to rely on her or\nhis vision to take advantage of the thick-pen transform of the data. In what follows, we\ndescribe certain summary statistics, involving the sequences U \u03c4t and L\n\u03c4\nt , which can be viewed\nas automatic \u201cscanners\u201d for reading off certain properties of the thick-pen map.\nWe first note that in the thick-pen transform as described above, one thickness value \u03c4\ngenerates two sequences: U \u03c4t and L\n\u03c4\nt . In some time series problems, for example nonsta-\ntionarity detection (as described later), it might be more convenient to use a single summary\n6\n0 100 200 300 400 500 600\n\u2212\n2\n\u2212\n1\n0\n1\n2\n0 100 200 300 400 500 600\n\u2212\n2\n\u2212\n1\n0\n1\n2\n0 100 200 300 400 500 600\n\u2212\n2\n\u2212\n1\n0\n1\n2\nFigure 3: White noise followed by AR(1) process with parameter 0.9, top: conventional\nvisualisation; middle and bottom plots: thick-pen visualisation.\n7\nsequence, instead of a pair. (By way of analogy, we mention that, for instance, a single scale\nin a wavelet transform is typically also represented by a single sequence: that of the wavelet\ncoefficient values at a given scale.) Below, we identify and describe some particular sum-\nmary statistics involving the sequences U \u03c4t and L\n\u03c4\nt which will be used later in the paper for\nthe purposes of nonstationarity detection as well as measuring dependence between time\nseries. We divide them into two classes: \u201cbasic\u201d and \u201cderivative\u201d summary statistics.\nBasic summary statistics. We define the following basic summary statistics involving\nU \u03c4t and L\n\u03c4\nt .\n\u0088 Volume of the pen, defined as V \u03c4t = U\n\u03c4\nt \u2212 L\u03c4t .\n\u0088 Mean of the pen, defined as M \u03c4t =\n1\n2{U \u03c4t + L\u03c4t }.\nDerivative summary statistics. We define the following derivative summary statistics\ninvolving U \u03c4t and L\n\u03c4\nt .\n\u0088 Rate of change of volume with respect to time t, defined as\n\u2206V \u03c4\nt\n\u2206t = V\n\u03c4\nt \u2212 V \u03c4t\u22121.\n\u0088 Rate of change of volume with respect to thickness \u03c4 , defined as\n\u2206V \u03c4\nt\n\u2206\u03c4 = V\n\u03c4\nt \u2212\nV \u03c4\u22121t .\n\u0088 Rate of change of mean with respect to time t, defined as\n\u2206M\u03c4\nt\n\u2206t =M\n\u03c4\nt \u2212M \u03c4t\u22121.\n\u0088 Rate of change of mean with respect to thickness \u03c4 , defined as\n\u2206M\u03c4\nt\n\u2206\u03c4 = M\n\u03c4\nt \u2212\nM \u03c4\u22121t .\nV \u03c4t measures the local width of the area created by the pen of thickness \u03c4 , andM\n\u03c4\nt measures\nits local mean level. The derivative summary statistics measure how those two quantities\nchange with respect to t or \u03c4 . Depending on the nature of the time series and problem at\nhand, more complex summary statistics are also possible. One such example is described\nin Section 4. A few remarks are in order.\nComplementarity of V \u03c4t and M\n\u03c4\nt . We note that V\n\u03c4\nt andM\n\u03c4\nt are constructed by applying\nthe complementary operations of subtraction and addition (respectively) to U \u03c4t and\nL\u03c4t , and thus can be viewed as \u201csymmetric\u201d quantities. To recover U\n\u03c4\nt and L\n\u03c4\nt from\nV \u03c4t and M\n\u03c4\nt we use the very similar operations\nU \u03c4t = M\n\u03c4\nt +\n1\n2\nV \u03c4t\nL\u03c4t = M\n\u03c4\nt \u2212\n1\n2\nV \u03c4t .\nLink between V \u03c4t and tube formula. Out of the basic and derivative summary statis-\ntics described above, V \u03c4t deserves special attention because of the fact that statistical\nliterature has previously explored the concept of \u201cthe volume of a covering of data\u201d,\nalbeit in other contexts. Weyl (1939) derived the famous \u201ctube formula\u201d for calculat-\ning the volume of a tube surrounding a smooth manifold embedded in a k-dimensional\nunit sphere, for a finite k, extending a previous result by Hotelling (1939). These re-\nsults were more recently discussed, extended and applied in various statistical contexts\ninvolving smooth (but not always deterministic) curves or surfaces by, amongst oth-\ners, Knowles and Siegmund (1988), Johansen and Johnstone (1990) and Sun (1993).\nWe are unaware of any applications of tube formulae in classical time series, where\nsample paths are often intrinsically non-smooth.\n8\nLink between V \u03c4t and estimation of fractal properties. On the other hand, in esti-\nmating the Hurst exponent or the fractal dimension of stochastic processes, two tech-\nniques involving statistics related to our V \u03c4t are the Rescaled Range Analysis (Hurst\n(1951)) and the \u201cbox-counting\u201d method, whose statistical properties in estimating the\nfractal dimension of a stationary continuous-time Gaussian process were studied in\nHall and Wood (1993). In contrast to the above methodologies, we emphasise here\nagain that our statistic V \u03c4t is not an estimator of any quantity; it is merely one pos-\nsible summary statistic for the multiscale thick-pen transform of any, not necessarily\nstationary time series, at location t and thickness (\u201cscale\u201d) \u03c4 . If taking the thick-pen\ntransform corresponds to viewing the time series from a range of distances, V \u03c4t (or\nany other summary statistic derived from the thick-pen transform) can be thought\nof as a particular form of \u201ceye\u201d or \u201cscanner\u201d used to record certain properties of the\ngiven time series, at time t, viewed from the given range of distances. We also em-\nphasise that the above-mentioned methodologies, Rescaled Range and box counting,\nhave traditionally been used for stationary, possibly long-memory processes. In con-\nstract, our statistic V \u03c4t is being put to work mainly in the context of nonstationary\nprocesses. For example, the following Section 3.1 demonstrates its usefulness in de-\ntecting nonstationarities in time series. Finally, we mention that while estimators of\nfractal properties of time series are typically considered in the limit as their \u201cscale\u201d\nparameter approaches either zero or infinity, our statistic V \u03c4t is also meaningful and\ninformative (both theoretically and empirically) for a finite number of thicknesses \u03c4 ,\nfor example when the task at hand is to detect nonstationarities in time series.\nV \u03c4t as a measure of self-overlap. We also mention an interesting interpretation of V\n\u03c4\nt as\nmeasure of the extent to which the pen \u201coverlaps with itself\u201d whilst plotting a given\ntime series. For each fixed time t, the quantity\n\u2211t\ni=1 V\n\u03c4\ni is a total measure of the\narea created by the pen at thickness \u03c4 up to time t. Thus, V \u03c4t =\n\u2211t\ni=1 V\n\u03c4\ni \u2212\n\u2211t\u22121\ni=1 V\n\u03c4\ni\nmeasures how much new area appeared at time t. Subtracting V \u03c4t from the area of\nthe \u201ctip\u201d of the pen (for example, \u03c42 for the square pen), we obtain a measure of how\nmuch the pen overlaps with itself whilst plotting the data.\nSmoothness of U \u03c4t , L\n\u03c4\nt . Recalling the analogy between pens and kernels described earlier,\nwe mention that pens corresponding to differentiable kernels (e.g. the round pen) will\nlead to smoother sequences U \u03c4t , L\n\u03c4\nt than pens corresponding to non-differentiable\nkernels, such as the square pen.\nWe are now ready to prove two theoretical properties of the thick-pen transform, both\nof which focus on the square pen (which we have found the least challenging to analyse\ntheoretically). The first one, in analogy to SiZer, establishes a \u201cvariation diminishing prop-\nerty\u201d of the thick-pen transform. The second one establishes the fundamental property that\nthe thick-pen transform is discriminative for Gaussian time series, i.e. that the thick-pen\ntransforms of two different Gaussian time series are distributed differently.\nProposition 2.1 Variation diminishing property. Let (Xt)\nn\nt=1 be a time series, let T =\n{1, 2, . . .} and let TPT (Xt) be the thick-pen transform of Xt. For any sequence (ft)mt=1, we\ndefine its total variation functional by\n\u2016f\u2016TV =\nm\u2211\nt=2\n|ft \u2212 ft\u22121|.\n9\nBoth \u2016U \u03c4\u2016TV and \u2016L\u03c4\u2016TV are non-increasing functions of \u03c4 .\nAt this point, we mention an interesting link between the thick-pen transform and SiZer.\nLindeberg (1994), Section 3.5.1 describes the variation dimishing property of kernels in\nlinear smoothing (as used in SiZer), in the sense that, roughly speaking, the number of sign\nchanges in the estimated function decreases as a function of the bandwidth if and only if\nthe kernel used is either Gaussian or one-sided exponential. In the case of the thick-pen\ntransform, note first that if Xt were a sequence of \u22121\u2019s and 1\u2019s, then \u2016U \u03c4\u2016TV and \u2016L\u03c4\u2016TV\nwould simply count, up to a multiplicative factor, the number of sign changes in U \u03c4t and\nL\u03c4t . The above proposition implies that in this special case, the thick-pen transform enjoys\na similar variation diminishing property, or, in other words, it demonstrates a \u201csmoothing\u201d\nproperty of the (nonlinear) max\/min filter.\nThe discrimination property follows. Before we formulate the result, we introduce the\nfollowing mild technical assumption, and explain it underneath.\nAssumption 2.1 For a given fixed lag \u03c4 > 0, a process Xt satisfies\n\u2203\u03bb0, \u03b4 \u2208 [0, 1) \u2200\u03bb > \u03bb0 \u2200 t\nP\n\uf8eb\n\uf8ed \u22c3\nt\u2264i,j\u2264t+\u03c4 ;{i,j}6={t,t+\u03c4}\n|Xi \u2212Xj| > |Xt \u2212Xt+\u03c4 |\n\u2223\u2223\u2223 |Xt \u2212Xt+\u03c4 | > \u03bb\n\uf8f6\n\uf8f8 \u2264 \u03b4.\nMore descriptively, the above assumption means that uniformly over all time locations t,\nconditioning on the fact that the absolute difference |Xt\u2212Xt+\u03c4 | is \u201clarge\u201d, it is not entirely\nunlikely that it achieves the maximum absolute difference amongst all |Xi\u2212Xj | for i, j lying\nbetween t, t+ \u03c4 . Since there is no requirement on \u03b4 other than that it should be less than\none, the above assumption should be viewed as a mild one. An extra discussion of this\nassumption appears underneath the proof of Theorem 2.1 in the Appendix.\nWe are now ready to state the discrimination result.\nTheorem 2.1 Let Xt, Yt be two zero-mean Gaussian time series such that for some s < t,\nthe distribution of Xs \u2212Xt is not the same as the distribution of Ys \u2212 Yt, and let both Xt\nand Yt satisfy Assumption 2.1 with \u03c4 = t \u2212 s. Let TPT (Xt), TPT (Yt) be the thick-pen\ntransforms of Xt, Yt respectively, both with the square pen where the set T of thickness\nparameters is T = {1, 2, . . .}, and let V \u03c4t (X), V \u03c4t (Y ) be the corresponding volumes. Then,\nTPT (Xt) and TPT (Yt) follow different probability distributions in the sense that the tri-\nvariate random vectors (V \u03c4\u22121s (X), V\n\u03c4\u22121\ns+1 (X), V\n\u03c4\ns (X)) and (V\n\u03c4\u22121\ns (Y ), V\n\u03c4\u22121\ns+1 (Y ), V\n\u03c4\ns (Y )) are\ndistributed differently.\nTheorem 2.1, although of a purely \u201cexistential\u201d nature, gives us hope that the thick-pen\ntransform can act as a successful discriminator for time series, as it uniquely determines\ntheir distribution (clearly, identically distributed time series yield identically distributed\nthick-pen transforms, and by the above theorem, differently distributed time series lead to\ndifferently distributed thick-pen transforms). Furthermore, the above theorem also gives\nus a hint as to the range of thickness parameters in which to look for the distributional\ndifferences: roughly and approximately speaking, if the autocorrelation structures of the two\ntime series differ at lag \u03c4 , differences in the distributions of the thick-pen transforms can\nalso be expected \u201caround\u201d thickness \u03c4 . To the best of our knowledge, the proof technique\n10\nfor Theorem 2.1 is new. With some effort, it can be extended to certain non-Gaussian\ndistributions; we leave this for future work. Note that since V 0t = 0, in the case \u03c4 = 1, the\nstatement of the theorem reduces to \u201cV 1s (X) and V\n1\ns (Y ) are distributed differently\u201d.\n3 Possible uses of the thick-pen transform\n3.1 Testing for nonstationarity via the thick-pen transform\nIn this section, we demonstrate, via both theoretical and empirical arguments, that the\nthick-pen transform can serve as an efficient tool for detecting nonstationarities in time\nseries. The logic we use for this purpose is as follows. Let K\u03c4t denote any generic basic,\nderivative or other summary statistic involving the sequences U \u03c4t and L\n\u03c4\nt which the analyst\nbelieves is likely to capture the nature of possible nonstationarity in the underlying process\nXt, if there is any. As a general guidance, taking K\n\u03c4\nt = V\n\u03c4\nt (volume) appears to be a good\nchoice when analysing possible changes in the dependence structure of the process, whereas\ntaking K\u03c4t =M\n\u03c4\nt is a good idea when analysing changes in the trend. Our simulation study\nin the latter part of this section offers more specific practical advice on the choice of K\u03c4t .\nLet the values of \u03c4 be positive integers. If Xt is stationary, then the vector-valued time\nseries (K\u03c41t , . . . ,K\n\u03c42\nt )t, where the choice of \u03c41, \u03c42 will be discussed later, is also stationary.\nFor the time being, fix \u03c4 \u2208 {\u03c41, \u03c41 + 1, . . . , \u03c42}. The following result will form the basis of\nour test for stationarity.\nTheorem 3.1 Let {Xt}nt=1 be a stationary process satisfying E|Xt|r < \u221e for some r > 2.\nIn addition let Xt be \u03b1-mixing with the mixing coefficients \u03b1m satisfying \u03b1m = O(m\n\u2212s) for\nsome s > rr\u22122 . Let TPT (Xt) be the thick-pen transform of Xt using an arbitrary pen but such\nthat both U \u03c4t and L\n\u03c4\nt are functions of Xt\u2212C\u03c4 , . . . ,Xt+C\u03c4 only, for some C > 0. Further let the\nsummary sequence K\u03c4t be such that for each fixed \u03c4 , we have n\n\u22121Var(\n\u2211n\nt=1K\n\u03c4\nt )\u2192 \u03c32\u03c4 <\u221e,\nand |K\u03c4t | \u2264 A+B|max(Xt\u2212C\u03c4 , . . . ,Xt+C\u03c4 )| for some constants A,B > 0, possibly depending\non \u03c4 . Under these conditions, the following functional central limit results hold for each fixed\n\u03c4 .\n(i) Let u \u2208 [0, 1]. We have\nY \u03c4n (u) :=\n1\n\u03c3\u03c4\n\u221a\nn\n\u2308nu\u2309\u2211\nt=1\nK\u03c4t \u2212 E(K\u03c4t ) d\u2192 Bu, (5)\nwhere Bu is the standard Wiener process on [0, 1].\n(ii) Further, we have\nZ\u03c4n(u) := Y\n\u03c4\nn (u)\u2212\n\u2308nu\u2309\nn\nY \u03c4n (1)\nd\u2192 B0u,\nwhere B0u is the standard Brownian bridge process on [0, 1].\nThe cumulative distribution function of the range of a Brownian bridge is well-known\n(Kennedy (1976)) and is given by\nFB0(x) = 1 + 2\n\u221e\u2211\nk=1\n(1\u2212 4k2x2) exp(\u22122k2x2).\n11\nThe above result naturally suggests the following procedure for testing stationarity:\n1. Fix the thinnest scale \u03c41 and the thickest scale \u03c42. The simulation study in the latter\npart of this section offers some insight into suitable choices of these parameters.\n2. Set the desired significance level \u03b1. With the Bonferroni correction, this becomes\n\u03b1B = \u03b1\/(\u03c42 \u2212 \u03c41 + 1).\n3. For each \u03c4 \u2208 {\u03c41, \u03c41+1, . . . , \u03c42}, estimate E(K\u03c4t ) (which is independent of t under the\nnull hypothesis of stationarity) by 1n\n\u2211n\nt=1K\n\u03c4\nt .\n4. Estimate \u03c32\u03c4 as s\u02c6\n\u03c4\n0 +2\n\u2211M\nk=1 s\u02c6\n\u03c4\nk, where {s\u02c6\u03c4k}k is the sample autocovariance sequence of\nK\u03c4t . The simulation study below discusses the choice of M .\n5. Using the estimated versions of E(K\u03c4t ) and \u03c3\u03c4 , form the Brownian bridge processes\nZ\u03c4n(u), and calculate their ranges R\n\u03c4 = maxu Z\n\u03c4\nn(u)\u2212minu Z\u03c4n(u).\n6. If FB0(max\u03c4 R\n\u03c4 ) > 1\u2212\u03b1B , then reject the hypothesis of stationarity; otherwise accept.\nA few remarks are in order.\nLow moment requirements. We note the low moment requirements of the proposed\ntest. Indeed, we only require that E|Xt|r < \u221e for some r > 2. This is because,\nobviously but interestingly, moments of maxima of random variables exist if an only if\nthe corresponding moments of the variables themselves exist. By contrast, a variety of\nnonstationarity tests proposed in literature, see e.g. Neumann and von Sachs (2000)\nand the references therein, are based on local second-order statistics of the process,\ne.g. local periodograms. If K\u03c4t were to be such a local quadratic form of Xt, we would\nautomatically need to require the existence of E|Xt|2r for some r > 2.\nDifference with Rescaled Range Analysis. In the earlier part of the paper, we men-\ntion differences between our methodology in the case where our summary statistic of\ninterest is V \u03c4t , and the Rescaled Range Analysis. Another difference emerges now.\nTaking K\u03c4t = V\n\u03c4\nt , the operations taken in (5) correspond to taking the local volume\n(where the \u2018locality\u2019 is determined by the thickness parameter \u03c4) and rescaling by\nthe global quantity \u03c3\u03c4 . This is in contrast to the Rescaled Range Analysis, which,\nin its local version, would take the local range and rescale it by the local standard\ndeviation. However, this would not be of use in detecting nonstationarities: we invite\nthe reader to think of a stationary process mutliplied by a time-varying standard de-\nviation function, for which such a local Rescaled Range Analysis would annihilate the\neffect of the time-varying standard deviation (due to the fact that for such a process,\nthe local range is roughly proportional to the local standard deviation) and thus make\nit impossible to detect the nonstationarity of the process.\nSuitability for both linear and nonlinear time series. A unique feature of our test\nis that it is equally valid for linear and nonlinear processes, provided they satisfy\nthe requirements of Theorem 3.1. This is in contrast to, for example, the variety of\ntests based on local second-order statistics of the process, which, by construction, are\nnot applicable to certain well-known nonlinear time series models such as (G)ARCH,\nwhich are simply \u201cwhite noise\u201d as far as their second-order properties are concerned.\n12\nExact p-value available when \u03c41 = \u03c42. When \u03c41 = \u03c42, the test is performed using a\nsingle thickness \u03c4 only, and there is no need to perform the Bonferroni correction. In\nthis case, it is possible to specify the exact p-value, which equals 1\u2212 FB0(R\u03c4 ).\nIn the simulation study that follows, we test using a single thickness \u03c4 only. This is done\nto \u201cseparate out\u201d the performance of the test from the effect of the Bonferroni correction,\nwhich has a chance of spoiling things when the dependence across \u03c4 amongst K\u03c41t , . . . ,K\n\u03c42\nt\nis too high. However, later in this section, we propose a way of alleviating this issue by\nconstructing K\u03c4t in such a way that this dependence hopefully remains low. Also, by using\na single thickness only, we are able to report the exact p-value.\nOur simulation study is in five parts. In part one, our test process is white noise with\nstandard deviation changing abruptly halfway through. In parts two and three, respec-\ntively, the test processes are AR(1) and ARCH(1), for which the autoregressive parameters\nchange halfway through, but the variance remains constant. In part four, we evaluate the\nperformance of our test for some challenging nonlinear processes from Davis et al. (2008).\nIn part five, we use an interesting example of an \u201con-off\u201d process to exhibit the multiscale\naspect of our test and explain why its performance naturally depends on the thickness used\nin the test. Since we test for structure rather than trend, our summary statistic of choice\nis K\u03c4t = V\n\u03c4\nt . We use the square pen, and the maximum autocovariance lag M from step 4\nof the testing procedure above is set equal to max(\u03c4, log n) (the \u03c4 in this expression \u201ctakes\ncare\u201d of the dependence arising from the construction of K\u03c4t , whereas the log n is respon-\nsible for picking up the most significant autocovariances arising from the autocovariance\nstructure of the original process Xt). We use thickness \u03c4 = 1 in parts one to four (the\nreason for this is given in part five). In part five, we also test using a single thickness at a\ntime, but we investigate how the performance of the test varies with the thickness used. For\ntesting using multiple thicknesses, our recommendations for the choice of \u03c41, \u03c42 are given\nlater in this section.\n(a) The model is Xt = \u03c3t\u03b5t, where {\u03b5t}500t=1 are i.i.d. N(0, 1), and \u03c3t changes from 1 for\nt = 1, . . . , 250 to \u03c3 for t = 251, . . . , 500. Average p-values based on 100 simulations\nare shown in Table 1. We note that even in the case \u03c3 = 1.35, for which the p-value is\nbelow 10%, it is still extremely difficult to detect the nonstationarity by simple visual\ninspection, so our test genuinely appears to help in this case.\n(b) The model is Xt = {1\u2212a2t}1\/2Yt, where Yt = at Yt\u22121+\u03b5t with {\u03b5t}500t=1 as above, and at\nchanges at t = 251 from a(1) to a(2). Note that Xt has a constant variance throughout,\nso the only change is in the autoregressive parameter. We report the results in Table\n2. It is remarkable that for a pair of parameters (a(1), a(2)) = (a, a + \u03b4) for a fixed \u03b4,\nit is becoming easier for our test to detect the nonstationarity as a increases. This,\nwe believe, has an appealing physical interpretation: indeed, the quantity V \u03c4t can be\nregarded as an \u201ceye\u201d or \u201cscanner\u201d used to view the time series from a distance. Thus,\nit should not suprise us that the test is more sensitive for higher values of a: after all,\nthe human eye also tends to be better at detecting the change for larger values of a,\nsince lower values of a imply noisier appearance of the data.\n(c) The model is Xt = {1 \u2212 at}1\/2Yt, where Yt = \u03c3t\u03b5t with {\u03b5t}1000t=1 as above, and \u03c32t =\n1 + atY\n2\nt\u22121. (The sample paths now have length 1000 in preparation for the next\nexample.) The parameter at changes at t = 501 from a\n(1) to a(2). Again, Xt has a\n13\nconstant variance throughout, and the only change is in the autoregressive parameter.\nObviously, the p-values are now not as impressive as in model (b), which is not\nsurprising, as nonstationarity detection for ARCH is known to be a harder problem\nthan for Gaussian AR processes. However, the next simulation example reassures us\nthat this is still not a bad result and in fact outperforms what we have been able to\nestablish is the state of the art, which is all the more interesting given the fact that\nour method is in no way specifically designed for ARCH or even nonlinear processes.\nThe example follows.\n(d) Davis et al. (2008) consider, amongst others, three challenging examples (from the\npoint of view of breakpoint detection) of the GARCH(1,1) model Xt = \u03c3t\u03b5t, with\n{\u03b5t}1000t=1 as above, and \u03c32t = a(0)t + a(1)t X2t\u22121 + b(1)t \u03c32t\u22121, where the triple of parameters\n(a\n(0)\nt , a\n(1)\nt , b\n(1)\nt ) changes, at time t = 501, as follows:\n(i) (0.4, 0.1, 0.5) \u2192 (0.4, 0.1, 0.6)\n(ii) (0.1, 0.1, 0.8) \u2192 (0.1, 0.1, 0.7)\n(iii) (0.4, 0.1, 0.5) \u2192 (0.5, 0.1, 0.5)\nWe ran our nonstationarity test on these three models, and Table 4 shows the percent-\nage of times (over 1000 simulations) that our test failed to detect their nonstationarity\nat 5% significance level. Comparing this to the percentage of times Davis et al. (2008)\n[Auto-Seg] and the competing method from Andreou and Ghysels (2002) [AG] failed\nto detect any breakpoints (i.e. classified the series as stationary), we can see that\nour method (which has not been particularly fine-tuned for GARCH or even nonlin-\near processes) outperforms these two state of the art techniques on these challenging\nexamples. To check calibration, we also ran our test on the stationary examples\nconsidered in Davis et al. (2008), in which the triples of parameters were\n(iv) (0.4, 0.1, 0.5)\n(v) (0.1, 0.1, 0.8)\nThe results are in Table 5. The empirical results for our test are not far off the\ntheoretical value of 5%.\n(e) In this example, we demonstrate that results of the thick-pen test for stationarity\ncan, understandably and interpretably, depend on the thickness at which the given\nprocess is being considered. This should not be viewed as a weakness of the thick-pen\nmethodology, but rather as a natural implication of the fact that certain processes do\nnot \u201cappear\u201d stationary when inspected at certain scales (= thicknesses) but do so at\nothers.\nFor example, we saw in parts (a)\u2013(d) that the thinnest pen (with \u03c4 = 1) was \u201csuf-\nficient\u201d in testing for stationarity of classical time series models such as AR(1),\nARCH(1) and GARCH(1,1). This is because when the values of their parameters\nchange, it follows that the stochastic relationship between two consecutive variables\ncomprising the series also changes, which is why it suffices to consider these processes\nat the smallest thickness value to detect the parameter change.\nHowever, in this example, we consider an altogether different stochastic process, which\nswitches, in a Markovian way, between being constant and equal to zero, and being\n14\nGaussian white noise with mean zero, variance one. (This could serve e.g. as a very\nrudimentary \u201ccartoon\u201d of a speech signal.) Consider the following cases:\nCase A. The switching probability, at any particular time t, is 120 .\nCase B. The switching probability, at any particular time t, is 150 .\nCase C. The switching probability, at any particular time t, is 120 , but overall the\ntime series is non-stationary in the sense that is it always equal to zero for the\nlast 30% of the time (so it is as in Case A times zero for the last 30% of the\ntime).\nSimulated sample paths for each of the cases: A, B and C, are in Figure 4.\nWe perform exactly the same test on cases A, B, C as in parts (a)\u2013(d), the only\ndifference being that we now vary thickness values from 1 to 14. Figure 5 shows the\naverage p-value of the test as a function of thickness, averaged over 100 simulated\nsample paths from models A (red), B (blue), C (green), each for a sample path of\nlength 1000.\nAs expected, the p-value increases with thickness, for models A and B. This is to be\ninterpreted as saying that the series begins to \u201clook\u201d stationary for higher thickness\nvalues, as it is for those values that we are beginning to \u201cbridge the gaps\u201d between\nthe white noise parts and therefore obtain a more complete, broad scale picture of\nthe process. For lower thickness values, the scale at which we view the process is \u201ctoo\nfine\u201d given the nature of the process: at those thicknesses, the transitions between\nthe white noise and zero parts are mistakenly interpreted as breakpoints.\nIn particular, we note that p-values for model A begin to exceed 10% for thicknesses\n3 and above. A similar threshold thickness for model B is 8. It is unsurprising that\nthe blue curve lies underneath the red curve: model B displays fewer changes, which\nare in addition further apart, and therefore are more likely to be misinterpreted as\nbreakpoints (or in other words in takes a higher thickness value, or a further zoom-out,\nto appreciate the stationarity of the process). On the other hand, process C is, on\naverage, correctly interpreted as non-stationary for all thicknesses in the considered\nrange.\nFinally, we run our stationarity test (with exactly the same parameters as above and with\n\u03c4 = 1) on the time series of logged and differenced daily closing values of the S&P 500\nindex, for the 500 trading days (approximately 2 years) ending 25 November 2009. Thus,\nthe considered period overlaps with the recent financial crisis. The data are plotted in\nFigure 6. Our choice of the thickness parameter is motivated by the good performance of\nour test with \u03c4 = 1 for (G)ARCH models, as illustrated above. Since our test is equally\nsuitable for linear and nonlinear processes, the test hypothesis is \u201cwhether any stationary\nmodel, possibly nonlinear, which satisfies the assumptions of Theorem 3.1, can explain the\nchanging volatility of the S&P 500 index over this period\u201d. However, the p-value of our test\nis less than 4\u00d7 10\u22124. This provides extremely strong evidence against the null hypothesis\nof stationarity, and in particular against nonlinear stationary models such as GARCH or\nits many variants. To place this result in a broader context, we mention that recently\nsome authors have advocated the use of nonstationary models for the evolution of financial\nlog-returns, see e.g. Starica and Granger (2005) and Fryzlewicz et al. (2008).\nWe conclude the section on testing for nonstationarity with a few important remarks.\n15\nTime\n0 200 400 600 800 1000\n\u2212\n3\n\u2212\n2\n\u2212\n1\n0\n1\n2\n3\nTime\n0 200 400 600 800 1000\n\u2212\n3\n\u2212\n2\n\u2212\n1\n0\n1\n2\n3\nTime\n0 200 400 600 800 1000\n\u2212\n3\n\u2212\n2\n\u2212\n1\n0\n1\n2\n3\nFigure 4: Simulated sample paths for cases A (top), B (middle), C (bottom) in simulation\nstudy (e), Section 3.1.\n16\nthickness\n2 4 6 8 10 12 14\n0.\n1\n0.\n2\n0.\n3\n0.\n4\n0.\n5\nFigure 5: p-value as a function of thickness, averaged over 100 simulated sample paths from\nmodels A (red), B (blue), C (green), each for a sample path of length 1000, in simulation\nstudy (e), Section 3.1. Horizontal lines at 0.05 and 0.1 for reference.\nTable 1: Average p-values for simulation model (a).\n\u03c3 1 1.1 1.2 1.3 1.35 1.4\np-value 0.59 0.47 0.29 0.1 0.07 0.04\nChoice of \u03c41 and \u03c42. Our recommendations for the choice of \u03c41 and \u03c42 are as follows. Since\nthe majority of commonly encountered nonstationary processes, such as piecewise\nARMA and (G)ARCH processes, exhibit changes in their dependence structure at\nsmall lags, we suggest setting \u03c41 = 1 when dealing with data which could be modelled\nin such frameworks. In light of Theorem 2.1, it may be helpful to perform some\npreliminary data analysis before selecting \u03c42 as, for example, the largest significant\nlag for which the autocovariance of the process is likely to change over time. It is much\nmore challenging to advise on a suitable choice of \u03c41, \u03c42 for processes resembling that\nof our simulation study (e) above, and we leave this interesting question for future\nwork.\nChoice of K\u03c4t for \u03c4 > \u03c41. When testing using multiple thicknesses \u03c4 , it must be borne in\nmind that for the most common choices of the summary statistic K\u03c4t (e.g. volume,\nmean), the degree of dependence between K\u03c4t for different consecutive values of \u03c4 will\n17\nTime\n0 100 200 300 400 500\n\u2212\n0.\n10\n\u2212\n0.\n05\n0.\n00\n0.\n05\n0.\n10\nFigure 6: Logged and differenced daily closing values of the S&P 500 index, for the 500\ntrading days ending 25 November 2009.\ntypically be non-negligible, and therefore the Bonferroni correction may not be very\neffective. In order to \u201cbreak\u201d this dependence, instead of taking, say, K\u03c41t = V\n\u03c41\nt ,\nK\u03c41+1t = V\n\u03c41+1\nt , K\n\u03c41+2\nt = V\n\u03c41+2\nt (etc.), we suggest taking K\n\u03c41\nt = V\n\u03c41\nt , K\n\u03c41+1\nt =\nV \u03c41+1t \u2212 V \u03c41t (= \u2206V\n\u03c41+1\nt\n\u2206\u03c4 ), K\n\u03c41+2\nt = V\n\u03c41+2\nt \u2212 V \u03c41+1t (= \u2206V\n\u03c41+2\nt\n\u2206\u03c4 ), etc. Empirically, we\nhave observed that this adjustment reduces the degree of dependence and thus makes\nthe Bonferroni correction more effective.\nWe illustrate the above choice of K\u03c4t with a challenging example of a non-stationary\nprocess Xt, which is Gaussian throughout, with variance one and lag-one autocorrela-\ntion equal to 1\/2; however, it is AR(1) in the first half and MA(1) in the second half\n(we refer to this model as AR(1)-MA(1) below). Since the change in the autocorrela-\ntion structure only occurs at lag two, it is clear that in this case it will be insufficient\nto test using K1t = V\n1\nt as V\n1\nt only uses lag-one information. Thus, we also test using\nK2t = V\n2\nt \u2212 V 1t . Average p-values for our thick-pen test for stationarity as a function\nof the sample size, based on 100 simulated sample paths, for both K1t and K\n2\nt , are\nshown in Figure 7.\nIt is unsurprising but interesting to observe that K1t performs extremely poorly and\nthat K2t performs well at detecting the non-stationarity in this model, since the largest\nlags examined by K1t and K\n2\nt are, respectively, 1 and 2. To assess how well K\n2\nt\nperforms, we compared the performance of our test to an analogous test based directly\non the local autocorrelation at lag two; in other words, we built the Brownian bridge\nstatistic exactly like in our test but based on the sequence XtXt+2 instead of K\n\u03c4\nt .\nSince Xt is Gaussian and its autocorrelation varies the most prominently at lag 2, we\nwould expect this autocorrelation-based test to be close to optimal; with some abuse\nof terminology, we henceforth refer to it as the \u201coracle\u201d test. It is unsurprising to note\nthat the oracle test does better than our thick-pen-based test since the former was\nfine-tuned to this particular Gaussian example; however, it is also interesting to note\n18\nTable 2: Average p-values for simulation model (b).\na(1) \\ a(2) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n0 0.59 0.51 0.39 0.29 0.1 0.03 0.01 0 0 0\n0.1 0.53 0.47 0.36 0.19 0.05 0.01 0 0 0\n0.2 0.58 0.5 0.28 0.15 0.02 0 0 0\n0.3 0.59 0.50 0.22 0.04 0 0 0\n0.4 0.57 0.39 0.15 0.01 0 0\n0.5 0.58 0.45 0.09 0 0\n0.6 0.52 0.35 0.01 0\n0.7 0.56 0.14 0\n0.8 0.61 0.01\n0.9 0.57\nTable 3: Average p-values for simulation model (c).\na(1) \\ a(2) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n0 0.57 0.53 0.51 0.51 0.49 0.39 0.3 0.17 0.13 0.06\n0.1 0.56 0.54 0.53 0.5 0.4 0.33 0.2 0.15 0.02\n0.2 0.59 0.57 0.5 0.46 0.38 0.21 0.1 0.05\n0.3 0.55 0.6 0.48 0.39 0.33 0.17 0.05\n0.4 0.54 0.55 0.48 0.30 0.22 0.05\n0.5 0.55 0.54 0.45 0.29 0.08\n0.6 0.53 0.54 0.34 0.12\n0.7 0.59 0.46 0.2\n0.8 0.6 0.33\n0.9 0.61\nthat it does not do dramatically better. On the other hand, it is worth emphasising\nthat a similar test based on local autocorrelations would by definition be of no use\nwhen investigating changes in the dependence structure beyond the second moment.\nIn particular, it would have to fail in the (G)ARCH framework (a set-up where our\nthick-pen test does well, as demonstrated earlier in this section) as (G)ARCH processes\nare simply white noise as far as their second-order structure is concerned.\nTesting using multiple summary statistics. If there are good reasons to believe that\nmultiple characteristics of the time series under consideration (e.g. mean level and\ndependence structure) change over time, it may make sense to test using multiple\nsummary statistics simultaneously (e.g. M \u03c4t and V\n\u03c4\nt ) instead of, or in addition to,\nlooking at multiple thicknesses \u03c4 simultaneously. The same procedure applies, includ-\ning obviously the Bonferroni correction.\nThick-pen as the last stage in a cascade of tests. Since, as demonstrated above, the\nthick-pen-based test is also applicable to situations where changes in the dependence\nstructure occur beyond the second moment, it is an option to use it as the last stage\nin a cascade of tests, where a test for changes in the mean is performed in the first\nstage, a test for changes in the second-order dependence structure in the second stage\n(for example that proposed in Paparoditis (2009)) and the thick-pen-based test in the\nfinal, third stage.\n19\nTable 4: Percentage of times the (nonstationary) models (i)\u2013(iii) were considered stationary\nin the Auto-Seg, AG and thick-pen (TP) procedures, in simulation (d).\n(i) (ii) (iii)\nAuto-Seg 80.4 37 87.8\nAG 72 21 85\nTP 71.5 8.9 81.8\nTable 5: Percentage of times the (stationary) models (iv)\u2013(v) were considered nonstationary\nin the Auto-Seg, AG and thick-pen (TP) procedures, in simulation (d).\n(iv) (v)\nAuto-Seg 4 4\nAG 4 12\nTP 3 6\n3.2 Measuring time series dependence via the thick-pen transform\nThe purpose of this section is to argue the potential usefulness of the thick-pen transform\nas a measure of association\/dependence between time series, especially in cases where tra-\nditional measures (e.g. cross-covariance, cross-spectrum, coherence) fail due to insufficient\nmoment conditions, or where a more \u201cvisual\u201d measure is required. We illustrate and expand\non this below. We aim at conveying the main idea, rather than at a detailed analysis.\nLet Xt and Yt be two univariate zero-mean (or zero-median if mean does not exist) time\nseries, roughly on the same scale (by which we mean variance if it exists or another robust\nmeasure of scale if it does not). Our main basic idea is to measure the overlap between\nthe areas created by the thick-pen transforms of X and Y . Denoting by L\u03c4t (Z) (U\n\u03c4\nt (Z))\nthe lower (upper) thick-pen boundary for a generic process Z at time t, thickness \u03c4 , we\ndefine the localised Thick-Pen Measure of Association (TPMA) between X and Y at time\nt, thickness \u03c4 as\n\u03c1\u03c4t (X,Y ) =\nmin{U \u03c4t (X), U \u03c4t (Y )} \u2212max{L\u03c4t (X), L\u03c4t (Y )}\nmax{U \u03c4t (X), U \u03c4t (Y )} \u2212min{L\u03c4t (X), L\u03c4t (Y )}\n.\nNote that if the intersection between [L\u03c4t (X), U\n\u03c4\nt (X)] and [L\n\u03c4\nt (Y ), U\n\u03c4\nt (Y )] is non-empty, then\n\u03c1\u03c4t (X,Y ) simply measures the length of this intersection as a proportion of the length of the\nunion of these two intervals. Indeed, if X = Y , then \u03c1\u03c4t (X,Y ) \u2261 1. If [L\u03c4t (X), U \u03c4t (X)] and\n[L\u03c4t (Y ), U\n\u03c4\nt (Y )] do not intersect, then \u03c1\n\u03c4\nt (X,Y ) measures the length of the \u201cgap\u201d between\nthem as a proportion of the length of the shortest interval containing their union, times\nminus one. If X and Y are stationary between times t1 and t2, a natural averaged version\nof \u03c1\u03c4t (X,Y ) is\n\u03c1\u00af\u03c4t1,t2(X,Y ) =\n1\nt2 \u2212 t1 + 1\nt2\u2211\nt=t1\n\u03c1\u03c4t (X,Y )\nNote that the range of \u03c1\u03c4t (X,Y ) is (\u22121, 1] and so it is a bounded random variable, which\nin particular possesses all finite moments, irrespective of the degree of heavy-tailedness of\nX or Y . This, in particular, implies that under appropriate mixing conditions (see e.g.\n20\n2000 4000 6000 8000 10000\n0.\n0\n0.\n1\n0.\n2\n0.\n3\n0.\n4\n0.\n5\nFigure 7: Average p-values (over 100 simulated sample paths) in detecting the non-\nstationarity of the AR(1)-MA(1) model, as a function of the sample size. Solid black:\nthick-pen test based on K1t . Green: thick-pen test based on K\n2\nt . Dotted black: \u201coracle\u201d\ntest. Dashed horizontal line at 0.1 for reference.\nDavidson (1994), Chapter 19, for a review), we have\nlim\nt2\u2212t1\u2192\u221e\n\u03c1\u00af\u03c4t1,t2(X,Y ) = E(\u03c1\n\u03c4\nt (X,Y ))\nin the almost-sure sense, if X and Y are stationary (but not necessarily light-tailed). How-\never, a similar convergence result does not hold for the sample correlation between X and\nY if their second moments do not exist.\nAlthough the range of \u03c1\u03c4t (X,Y ) is (\u22121, 1], the reader should not fall into the trap of iden-\ntifying values of \u03c1\u03c4t (X,Y ) close to \u22121 (0, 1) with \u201cperfect negative\u201d (\u201clack of\u201d, \u201cperfect\npositive\u201d) correlation between X and Y . The TPMA \u03c1\u03c4t (X,Y ) describes how the two time\nseries appear to co-vary when seen from the distance corresponding to thickness \u03c4 . For ex-\nample, if {Xt}100t=1 and {Yt}100t=1 are two independent Gaussian white noise sequences, they\nwill invariably appear very similar when viewed from a sufficiently large distance. The\nnumerical analysis of the quantity \u03c1\u00af991,100(X,Y ) (note the extremely high value of the thick-\nness parameter) applied to this example confirms this observation: indeed, in 100 simulated\nrealisations, the value of this quantity, in this particular example, never fell below 0.97.\nHowever, when computed at a range of (lower) thickness values, TPMA is well able to\ndiscriminate between different degrees and types of dependence in time series, also in cases\nwhere covariance fails. This is demonstrated next. (As an aside, we mention that TPMA\nis a \u201cvisual\u201d measure in the sense that it is often possible to deduce an approximate value\n21\nof \u03c1\u03c4t (X,Y ) simply by the visual inspection of the graphs of X and Y . However, the same\ncannot be said of covariance as it involves multiplication, which is not an obvious operation\nto perform graphically.)\nWe demonstrate the advantages of the TPMA using three examples. The first one involves\nTPMA analysis of the DJIA and FTSE 100 stock indices, with an interesting possible in-\nterpretation of the results. The second one involves variable selection where the covariates\n(and the response) are extremely heavy-tailed. The final example demonstrates the sensi-\ntivity of TPMA to the phase between the two input time series. We use the square pen\nthroughout.\nExample 1. In this example, we perform the Thick-Pen Measure of Association (TMPA)\nanalysis for a pair of time series: daily log-returns on the Dow Jones Industrial Average\n(Xt) and FTSE 100 (Yt) indices, on 2048 trading days ending 10 March 2010; both series are\nscaled so that their variance is 1. We note that the initial part of both series corresponds\nto the final part of the burst of the \u201cdotcom bubble\u201d in the early 2000s, while the final\npart of both series covers the period of the recent financial crisis. Both of those periods are\ncharacterised by a dramatic increase in volatility. The series are displayed in Figure 8.\nTo analyse the series, we use the TPMA with the square pen, the thickness parameter\n\u03c4 ranging from 1 to 199, and the scaling factor \u03b3 equal to zero: this is done to ensure\nthat the TPMA is invariant to changes in the marginal volatility of each series (indeed,\nwith the scaling factor equal to zero, the value of the TPMA remains the same if each\nseries is multiplied by the same constant \u03c3). For each thickness parameter \u03c4 , for ease of\nvisual interpretation, we additionally smooth the TPMA sequence \u03c1\u03c4t (X,Y ) by means of a\nGaussian kernel smoother with bandwidth 200. For comparative purposes, we also compute\nthe localised cross-correlation sequence \u03b3t(X,Y ) between X and Y , where the localisation is\nalso achieved by means of the Gaussian kernel with bandwidth 200. For ease of comparison,\nwe further normalise each sequence \u03c1\u03c4t (X,Y ) so that its overall (global) sample mean and\nvariance match those of \u03b3t(X,Y ).\nResults are visualised in Figure 9. The top plot shows \u03b3t(X,Y ) as well as \u03c1\n\u03c4\nt (X,Y ) for\n\u03c4 = 1, 4, 19. The peak present in all the sequences around time t = 300 indicates increased\nco-dependence between the two time series during the dotcom crisis. Similarly, the peak\naround time t = 1800 indicates increased co-dependence during the recent financial crisis.\nIt is interesting to see that the two peaks are apparent in all four indicators.\nHowever, it is fascinating to observe that the relationship between the levels of the two\npeaks differs depending on the value of the thickness parameter. For \u03c4 = 1, which roughly\ncorresponds to the \u2018daily\u2019 scale of the data, the value of \u03c1\u03c4t (X,Y ) at the later peak is higher\nthan that at the earlier peak. However, the opposite is true for \u03c4 = 4 (\u2018weekly\u2019 scale) and\n\u03c4 = 19 (\u2018monthly\u2019 scale). This is illustrated further in the middle plot, which shows the\ntime-thickness \u201cmap\u201d of \u03c1\u03c4t (X,Y ) (the darker the colour, the larger the value) and in the\nbottom plot, which shows (in red colour) the time-thickness regions where \u03c1\u03c4t (X,Y ) exceeds\nthe threshold of 0.566.\nAlthough this finding appears challenging to interpret, we note that the dotcom crisis was\na single-sector crisis, affecting mainly companies from the highly-globalised IT sector. On\nthe other hand, the recent financial crisis was a more complex phenomenon, involving both\nglobal-scale events (e.g. spectacular shocks in the global banking sector) and country-\nspecific events (e.g. bailout packages, announcements of macroeconomic indicators). We\n22\nTime\n0 500 1000 1500 2000\n\u2212\n6\n\u2212\n4\n\u2212\n2\n0\n2\n4\n6\nTime\n0 500 1000 1500 2000\n\u2212\n5\n0\n5\nFigure 8: Left: FTSE 100 index; right: DJIA index, both on 2048 trading days (roughly 8\nyears) ending 10 March 2010.\ncan only hypothesise that it might have been the presence of those country-specific effects\nthat led to the decreased dependence between DJIA and FTSE 100 as measured by the\nTPMA for larger thickness values. In other words, during the recent financial crisis, DJIA\nand FTSE 100 might have been responding in unison to abrupt global shocks (hence the\nextremely high co-dependence of the two series for smaller thickness values) but might have\nbeen less co-ordinated over longer time-scales (corresponding to higher thickness values) due\nto the possibly longer-term effects of country-specific factors affecting the value of these two\nstock indices.\nFinally, we mention that a similar analysis would not have been possible only based on the\nlocal cross-correlation sequence \u03b3t(X,Y ), as the latter quantity does not reflect the concept\nof \u201cviewing\u201d the data at multiple time-scales.\nExample 2. Unlike the other two examples, this one exceptionally departs from the domain\nof time series and considers a possible application of the TPMA to the problem of variable\nselection for heavy-tailed data. Such data arise naturally in finance (returns on financial\ninstruments) and biostatistics (gene expressions), amongst others. The Cauchy distribution\ndisplays an extreme degree of heavy-tailedness in the sense that even its first moment does\nnot exist. In the first part of the example, we attempt to measure the degree of linear\nassociation between X and Z = aX + Y , where X and Y are independent Cauchy vari-\nates. Having observed {Xt}nt=1 and {Zt}nt=1, we apply (a) the sample (Pearson) correlation\nbetween X and Z, (b) Kendall\u2019s tau rank correlation, (c) Spearman\u2019s rho rank correlation,\nand (d) the TPMA \u03c1\u00af11,n(X,Z), in an attempt to quantify the degree of dependence between\nX and Z, for a range of values of a. While we should not hope for either of these estimators\nto return a value close to a itself, it would be desirable for the sample distributions of the\nestimators to concentrate around values whose magnitude increases with a, to reflect the\nincreasing degree of dependence of X and Z as a increases.\n23\nTime\n0 500 1000 1500 2000\n0.\n30\n0.\n35\n0.\n40\n0.\n45\n0.\n50\n0.\n55\n0.\n60\n500 1000 1500 2000\n5\n10\n15\ntime\nth\nic\nkn\nes\ns\n500 1000 1500 2000\n5\n10\n15\ntime\nth\nic\nkn\nes\ns\nFigure 9: Top: \u03b3t(X,Y ) (black), \u03c1\n\u03c4\nt (X,Y ) for \u03c4 = 1, 4, 19 (red, blue, green, respectively).\nMiddle: time-thickness plot of \u03c1\u03c4t (X,Y ) (darker colour means larger value). Bottom: regions\nwhere \u03c1\u03c4t (X,Y ) exceeds 0.566 (red).\n24\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\n20\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n20\n40\n60\n80\n10\n0\n12\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\n20\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\n20\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n20\n40\n60\n80\n10\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\n20\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\nFr\neq\nue\nnc\ny\n0.0 0.2 0.4 0.6\n0\n50\n10\n0\n15\n0\nFigure 10: Left column: histograms, over 1000 simulations, of Kendall\u2019s tau correlations be-\ntween {Xt}1000t=1 and {Zt}1000t=1 , Zt = aXt+Yt; X,Y independent Cauchy, for a = 0, 0.4, 0.7, 1\n(from top to bottom). Middle column: Spearman\u2019s rho; right column: \u03c1\u00af11,1000(X,Z), for\nthe same values of a.\n25\nFigure 10 shows the sample distributions of Kendall\u2019s tau correlations between {Xt}nt=1 and\n{Zt}nt=1, for n = 1000, for a range of values of a, as well as the sample distributions of\nSpearman\u2019s rho and \u03c1\u00af11,n(X,Z). It is clear that all three statistics provide concentrated and\npeaked distributions, and that their average values appear to increase with a, as required.\nHowever, the advantage of \u03c1\u00af11,n(X,Z) is that it is computationally fast (unlike Kendall\u2019s tau\nand Spearman\u2019s rho, it does not involve a full sorting of the observations), a property which\nwould be of particular significance in tasks such as high-dimensional variable selection.\nWe note that the computational complexity of \u03c1\u00af\u03c41,n(X,Z) is O(n). The sample (Pearson)\ncorrelation is also rapid to compute, but it exhibits extremely poor performance in this\nexample, which is not surprising as the Cauchy distribution does not possess a finite variance\nor mean.\nTo investigate this issue further, the second part of Example 1 continues this theme but in\nthe context of variable selection. Sample correlation is the basic ingredient of most modern\nvariable selection techniques, including, amongst others, LARS (Efron et al. (2004)) and\nits various special cases such as Lasso (Tibshirani (1996)) or forward stagewise selection.\nIt could be replaced by Kendall\u2019s tau or Spearman\u2019s rho if the data were extremely heavy-\ntailed. We consider a simple linear regression model\nY = \u03b21X\n1 + \u03b22X\n2 + \u03b5,\nwhere X1, X2 and \u03b5 are independent Cauchy-distributed variables, and suppose that we\ncollect n = 1000 independent observations. We fix \u03b21 = 1, and vary \u03b22 from 0.7 to just\nshort of 1. Since \u03b21 > \u03b22, and thus the degree of dependence between Y and X\n1 is greater\nthan that between Y and X2, it would be desirable for any measure of vector dependence\nto return a larger value for the pair (Y,X1) than for (Y,X2), i.e. to rank X1 ahead of X2 in\nimportance. Table 6 shows the percentage of times (over 1000 simulations) that this correct\nranking was achieved by simple sample correlation (Marginal Correlation Ranking; MCR),\nKendall\u2019s tau, Spearman\u2019s rho and the TPMA. The latter three are extremely competitive,\nwith the TPMA being marginally superior in all cases. We also emphasise again its lower\ncomputational complexity. This provides evidence of its potential usefulness in variable\nselection contexts where the number of covariates is large. We emphasise that TPMA\nperformed well in this setting even though no rescaling of Y was performed, i.e. Y and Xi\nwere not exactly on the same \u201cscale\u201d. Also, we note that, unlike the three other measures,\nTPMA is not invariant with respect to permutations of the data (as it is designed as a \u201ctime\nseries\u201d measure). Thus, further performance improvement could be expected if we were to\naverage over some permutations of the data, at the expense of computational efficiency.\nTable 6: Percentage of cases the covariates were correctly ordered (over 1000 simulations)\nby Marginal Correlation Ranking (MCR), Kendall\u2019s tau (tau), Spearman\u2019s rho (rho) and\nthe Thick-Pen Measure of Association with thickness \u03c4 = 1 (TPMA), as a function of \u03b22.\n\u03b22 0.7 0.8 0.9 0.95 0.99\nMCR 62 59 55 52 51\ntau 99 96 83 65 51\nrho 99 95 81 66 53\nTPMA 100 97 83 66 53\nExample 3. The final example illustrating the potential applicability of the TPMA in\nmultivariate time series analysis concerns the detection of phase between time series. In\n26\nthickness\n2 4 6 8\n0.\n4\n0.\n5\n0.\n6\n0.\n7\n0.\n8\n0.\n9\n1.\n0\nthickness\n2 4 6 8\n0.\n00\n0.\n05\n0.\n10\n0.\n15\n0.\n20\nFigure 11: Thick-pen cross-spectra from Example 2. Top: cross-spectrum for q = 1 (red),\nq = 2 (green), q = 3 (blue), q = 4 (magenta), q = 5 (grey) and the independent case (black).\nBottom: differences between the coloured curves and the black curve; colours correspond.\nthis example, both {Xt}200t=1 and {Yt}200t=1 are i.i.d. Gaussian sequences (the reader is invited\nto think of them as, for example, representing residuals from two univariate model fits),\nwhich are however dependent on each other in the sense that Y is a shifted version of X:\nYt = B\nqXt,\nwhere B is the shift operator, and q ranges from 1 to 5. We also test the case where X\nis independent of Y . Figure 11 shows what we term the Thick-Pen Cross-Spectrum of\nX and Y , i.e. the sequence {\u03c1\u00af\u03c41,200(X,Y )}\u03c4 , here for \u03c4 ranging from 1 to 9, plotted for\nvarious values of q as well as for the case of X and Y being independent, averaged over\n1000 simulated sample paths.\nIf Yt = B\nqXt, then Xt, . . . ,Xt+q\u22121 is independent of Yt, . . . , Yt+q\u22121 and thus, for \u03c4 =\n1, . . . , q \u2212 1, we have that E(\u03c1\u00af\u03c41,200(X,Y )) = E(\u03c1\u00af\u03c41,200(X,Z)), where Z is independent of X.\nThis is illustrated in Figure 11, which shows that the averaged Thick-Pen Cross-Spectrum\nonly diverges from the spectrum for independent series for thickness values starting from\n\u03c4 = q, thus providing a natural way of estimating the phase q between X and Y . Exactly\nthe same phenomenon was observed in a similar example using the Cauchy distribution.\nTo conclude this section, we note that unlike covariance and related measures which only\nmake sense for a pair of time series, the TPMA naturally generalises to more than two time\nseries. For a collection of time series X1, . . . ,XM , we define\n\u03c1\u03c4t (X\n1, . . . ,XM ) =\nmini{U \u03c4t (Xi)} \u2212maxi{L\u03c4t (Xi)}\nmaxi{U \u03c4t (Xi)} \u2212mini{L\u03c4t (Xi)}\n.\n27\nIt is our belief that this extension can potentially pave the way for the application of the\nTPMA in tasks such as time series clustering.\n3.3 Non-stationary time series classification via the thick-pen transform\nIn this section, we show how the TPT can be used to classify not-necessarily-stationary\ntime series. The setting is as follows: we have C \u2265 2 groups of time series, where time\nseries within each group follow the same distribution, but the distributions differ across\nthe groups. Within each group c, we have already observed Nc time series. Given a \u201cnew\narrival\u201d Xt, we wish to classify it as belonging to one of the C groups. The generic TPT-\nbased classification algorithm proceeds as follows:\n1. Decide on a suitable summary sequence K\u03c4t .\n2. Compute K\u03c4t for each series in each group, and average this summary sequence con-\ntemporaneously over the series within each group, to produce K\u00af\u03c4,ct for each of the\ngroups c = 1, . . . , C.\n3. Compute K\u03c4t (X) for the new arrival Xt.\n4. Using a pre-selected distance function d(\u00b7, \u00b7) : Rn \u00d7 Rn \u2192 R, compute the distances\nbetween K\u03c4t (X) and K\u00af\n\u03c4,c\nt for c = 1, . . . , C.\n5. Classify Xt to the group which corresponds to the smallest distance.\nBy comparing K\u03c4t (X) and K\u00af\n\u03c4,c\nt , we essentially compare the (suitably understood) \u201cshape\u201d\nof the new arrival against the average \u201cshapes\u201d of the time series within each group, and\nclassify the new arrival to the group where the average shape of the time series (viewed at\nthickness \u03c4) resembles the most closely that of the new arrival.\nWe illustrate the use of the above algorithm on a well-known geophysics dataset. In the\nmonitoring of a comprehensive test ban treaty, it is critical to develop methods for discrimi-\nnating between nuclear explosions and earthquakes. We applied the proposed methodology\nfor classifying a time series as either an explosion or an earthquake. The proliferation of\nnuclear explosions is monitored in regional distances of 100 \u2013 2000 km and the record-\nings of mining explosions can serve as a reasonable proxy. A data set of regional (100\n\u2013 2000 km) recordings of several typical Scandinavian earthquakes and mining explosions\nmeasured by stations in Scandinavia are used in this study. The data set, consisting of\n8 earthquakes and 8 explosions, is given in Kakizawa et al. (1998). The problem is dis-\ncussed in detail in Shumway and Stoffer (2006), and the data are available online from\nhttp:\/\/lib.stat.cmu.edu\/general\/tsa2.\nPrior to the analysis, we center and scale each time series so that its sample mean is zero\nand its sample variance is one. We use the following selection of parameters: the square\npen, K\u03c4t = V\n\u03c4\nt (volume), d\n2(f, g) = 1n\n\u2211n\nt=1(ft \u2212 gt)2. We remove each of the 2 \u00d7 8 = 16\nseries one by one, and classify it using the above algorithm. As a result, each time series\nis classified either to the group consisting of the 7 remaining series from the same category\n(successful classification) or to the group consisting of the 8 series from the other category\n(failed classification).\n28\nthickness\nn\no\n o\nf s\nuc\nce\nss\nes\n0 100 200 300 400 500\n13\n.0\n13\n.5\n14\n.0\n14\n.5\n15\n.0\nthickness\nsu\ncc\ne\nss\n fo\nr \nse\nrie\ns \nno\n 1\n1\n0 100 200 300 400 500\n0.\n0\n0.\n2\n0.\n4\n0.\n6\n0.\n8\n1.\n0\nFigure 12: Top: number of successful classifications (out of 16) as a function of thickness\nin the data analysis of Section 3.3. Bottom: classification success for time series no. 11 as\na function of thickness.\n29\nThe top plot in Figure 12 shows the number of successful classifications (out of 16) as a\nfunction of thickness. The number of successes peaks at 15 for a certain range of thicknesses,\ndemonstrating the effectiveness of the methodology. The \u201cdouble bump\u201d in the plot is\ncaused by the series number 11, for which the classification success as a function of thickness\nis plotted in the bottom plot of Figure 12 and also exhibits the double bump. Albeit an\nunusual feature, it is very much in line with the multiscale philosophy of \u201cviewing the data\nat multiple thicknesses \/ scales\u201d. The result can be interpreted as saying that series number\n11 resembles other series from the same group when \u201cviewed\u201d at thickness 100 and around,\nas well as 300-400 and around, but not at thickness 200 and around.\nThe leave-one-out cross-validation as described above is a practical way of choosing the\n\u201cright\u201d thickness value(s) in classification problems.\n4 Discussion\nIn this section, we mention a few further aspects of the thick-pen methodology, which in\nour view would merit further study.\nLocal extrema of U \u03c4t , L\n\u03c4\nt as a marker. Depending on the nature of the time series and\nproblem at hand, more complex \u201cmarkers\u201d involving U \u03c4t and L\n\u03c4\nt are possible. Keeping track\nof local maxima of U \u03c4t and local minima of L\n\u03c4\nt is one such example. As illustrated in Figure\n3, for certain thicknesses, U \u03c4t appears to attain local maxima more often for time series with\nless dependence structure. If this were indeed the case, the same would obviously hold for\nlocal minima of L\u03c4t , for symmetrically distributed time series. Thus the following binary\nmarkers might be of use in nonstationarity detection and classification:\nU\n\u03c4\nt = I(U\n\u03c4\nt > U\n\u03c4\nt\u22121 \u2227 U \u03c4t > U \u03c4t+1)\nL\u03c4t = I(L\n\u03c4\nt < L\n\u03c4\nt\u22121 \u2227 L\u03c4t < L\u03c4t+1),\nwhere I(\u00b7) is the indicator function.\nAdaptive-thickness pens. The analogy between pens and kernels, mentioned in Section\n2, raises the question of whether it would be meaningful and valuable to consider pens\nwhose shape or thickness varies over time t according to local properties of the time series\nXt, e.g. its visibility from a distance.\nUnequispaced time series. The thick-pen transform, unlike many linear transforms such\nas the Fourier or wavelet transforms, extends naturally and easily to non-equispaced time\nseries.\nAcknowledgements\nPF would like to thank HSO for his hospitality during a visit to Seoul National University,\nKorea, where this work was initiated. We wish to thank Haeran Cho, Guy Nason, Hernando\nOmbao, Rainer von Sachs, Johan Segers, David Stoffer and Qiwei Yao for interesting and\nfruitful discussions.\n30\nA Proofs\nProof of Proposition 2.1. Consider the total variation of \u03a5\u03c4t := U\n\u03c4\nt \u2212 \u03c42 (clearly the\nadditive constant \u03c42 has no impact on the total variation). For any sequence f , define the\nshift operator B by (Bf)t = ft+1. Note the recursive relationship\n\u03a5\u03c4t = max(\u03a5\n\u03c4\u22121\nt , B\u03a5\n\u03c4\u22121\nt ).\nIt now suffices to observe that since B\u03a5\u03c4\u22121t is the shift of \u03a5\n\u03c4\u22121\nt in the horizontal direction,\ntaking this shift and taking the maximum of the two resulting functions cannot possibly\nincrease their total variation. Thus we have \u2016\u03a5\u03c4\u22121t \u2016TV = \u2016B\u03a5\u03c4\u22121t \u2016TV \u2265 \u2016\u03a5\u03c4t \u2016TV , and the\nproof is complete. \u0003\nProof of Theorem 2.1. We first define T s,s+\u03c4X = V\n\u03c4\ns (X)\u2212 \u03c4 and note that\nT s,s+\u03c4X = maxs\u2264i,j\u2264s+\u03c4\n(Xi \u2212Xj).\nWithout loss of generality, we consider s = 1; note that t = \u03c4 +1. In the new notation, our\ntask is to show that the joint distributions of {T 1,t\u22121X , T 2,tX , T 1,tX } and {T 1,t\u22121Y , T 2,tY , T 1,tY } are\ndifferent. Proceeding by contradiction, let us suppose that they are the same. If this were\ntrue, then in particular, we would have the equality\nP (T 1,tX \u2212 T 1,t\u22121X > 0 \u2227 T 1,tX \u2212 T 2,tX > 0 \u2227 T 1,tX > \u03bb) =\nP (T 1,tY \u2212 T 1,t\u22121Y > 0 \u2227 T 1,tY \u2212 T 2,tY > 0 \u2227 T 1,tY > \u03bb) =: a\nWe now note that if T 1,tX \u2212T 1,t\u22121X > 0, this implies that T 1,tX necessarily achieves its maximum\nat |Xt \u2212 Xq| for some q. Also (symmetrically), if T 1,tX \u2212 T 2,tX > 0, then T 1,tX achieves its\nmaximum at |X1 \u2212Xq| for some q. Therefore,\nT 1,tX \u2212 T 1,t\u22121X > 0 \u2227 T 1,tX \u2212 T 2,tX > 0\nmeans that T 1,tX achieves its maximum at |Xt \u2212X1|. Thus we have the event equality\nT 1,tX \u2212 T 1,t\u22121X > 0 \u2227 T 1,tX \u2212 T 2,tX > 0 \u2227 T 1,tX > \u03bb =\nT 1,tX \u2212 T 1,t\u22121X > 0 \u2227 T 1,tX \u2212 T 2,tX > 0 \u2227 |Xt \u2212X1| > \u03bb,\nand similarly for Y .\nWe now introduce \u03c31, \u03c32, such that Xt \u2212X1 \u223c N(0, \u03c321) and Yt \u2212 Y1 \u223c N(0, \u03c322). By the\nassumptions of the Theorem they are different, and without loss of generality, we assume\n\u03c31 > \u03c32.\nDenoting AX,t = {T 1,tX \u2212 T 1,t\u22121X > 0 \u2227 T 1,tX \u2212 T 2,tX > 0}, we decompose\nP (|Xt \u2212X1| > \u03bb) = P (|Xt \u2212X1| > \u03bb \u2227 AX,t) + P (|Xt \u2212X1| > \u03bb \u2227 AcX,t)\n= a+ P (|Xt \u2212X1| > \u03bb \u2227 AcX,t).\nSimilarly,\nP (|Yt \u2212 Y1| > \u03bb) = a+ P (|Yt \u2212 Y1| > \u03bb \u2227 AcY,t).\n31\nObserve now that Assumption 2.1 simply means that if \u03bb is large enough, we have\nP (AcX,t\n\u2223\u2223 |Xt \u2212X1| > \u03bb) \u2264 \u03b4 < 1,\nand similarly for Y . This implies that\n(1\u2212 \u03b4)P (|Xt \u2212X1| > \u03bb) \u2264 P (|Xt \u2212X1| > \u03bb)\u2212 P (|Xt \u2212X1| > \u03bb \u2227AcX,t)\n= a \u2264 P (|Xt \u2212X1| > \u03bb).\nSimilarly,\n(1\u2212 \u03b4)P (|Yt \u2212 Y1| > \u03bb) \u2264 a \u2264 P (|Yt \u2212 Y1| > \u03bb).\nIn particular, the above inequalities hold in the region \u03bb \u2265 \u03c32\n\u221a\n2 log n where n \u2192 \u221e.\nHowever, setting \u03bb = \u03c32\n\u221a\n2 log n and using simple properties of the tails of univariate\nnormal distributions, we then have that a = an (ignoring irrelevant logarithmic terms) is\nsimultaneously of the order n\u22121 (based on the inequality for Y ) and of the order n\u2212\u03c3\n2\n2\n\/\u03c32\n1\n(based on the inequality for X), which is a contradiction. This completes the proof of the\ntheorem. \u0003\nFurther clarification of Assumption 2.1. In the following, we identify an easy-to-\nverify, mixing-type assumpion which implies Assumption 2.1. We have, using the Bonferroni\ninequality on the way\nP (AcX,t\n\u2223\u2223 |Xt \u2212X1| > \u03bb) \u2264\nP (T 1,tX \u2212 T 1,t\u22121X = 0 \u2228 T 1,tX \u2212 T 2,tX = 0\n\u2223\u2223 |Xt \u2212X1| > \u03bb) \u2264\nP ( max\n(i,j)6=(1,t)\n|Xi \u2212Xj | \u2265 |Xt \u2212X1|\n\u2223\u2223 |Xt \u2212X1| > \u03bb) \u2264\nP ( max\n(i,j)6=(1,t)\n|Xi \u2212Xj | \u2265 \u03bb\n\u2223\u2223 |Xt \u2212X1| > \u03bb) =\nP\n(\u22c3\n(i,j)6=(1,t){|Xi \u2212Xj| \u2265 \u03bb \u2227 |Xt \u2212X1| > \u03bb}\n)\nP (|Xt \u2212X1| > \u03bb) \u2264\u2211\n(i,j)6=(1,t) P (|Xi \u2212Xj | \u2265 \u03bb \u2229 |Xt \u2212X1| > \u03bb)\nP (|Xt \u2212X1| > \u03bb)\nAt this point, we assume that for all (i, j) 6= (1, t),\nP (|Xi \u2212Xj | \u2265 \u03bb \u2229 |Xt \u2212X1| > \u03bb) \u2264 \u03b1\u03bbP (|Xi \u2212Xj| \u2265 \u03bb)P (|Xt \u2212X1| > \u03bb),\nwhere the sequence of constants \u03b1\u03bb is uniform over all i, j, t, and its permitted rate of\nincrease with \u03bb is specified below. Note that this assumption involves no maxima or minima\nand can be verified via simple Gaussian integration for a particular process. Applying this\nassumption and continuing the above chain of inequalities, we get\n. . . \u2264 \u03b1\u03bb\n\u2211\n(i,j)6=(1,t)\nP (|Xi \u2212Xj | \u2265 \u03bb).\nDenote \u03c3i,j = Var\n1\/2(Xi \u2212Xj). Continuing,\n. . . \u2264 \u03b1\u03bbt2 exp(\u2212\u03bb2\/{2max\ni,j\n(\u03c32i,j)}),\n32\nwhich, provided that \u03b1\u03bb does not go to infinity too fast with \u03bb, can be made arbitrarily\nsmall if \u03bb is large enough.\nProof of Theorem 3.1. We first note that since the existence of moments of a sequence\nof random variables implies the existence of the corresponding moments of local maxima\nof these variables, we have that E|K\u03c4t \u2212 E(K\u03c4t )|r < \u221e. Further, by Theorem 14.1 in\nDavidson (1994), the sequence K\u03c4t \u2212 E(K\u03c4t ), for any fixed \u03c4 , inherits the mixing properties\nof Xt, that is, is also \u03b1-mixing with the mixing coefficients \u03b1m satisfying \u03b1m = O(m\n\u2212s)\nfor some s > rr\u22122 . Thus, for any fixed \u03c4 , the sequence K\n\u03c4\nt \u2212 E(K\u03c4t ) satisfies the conditions\nof Corollary 29.7 in Davidson (1994), and the proof of (i) is complete. For (ii), since the\nsequence of functions hn that map Y\n\u03c4\nn (u) to Z\n\u03c4\nn(u), with the limiting mapping h taking\nY \u03c4n (u) to Y\n\u03c4\nn (u) \u2212 uY \u03c4n (1), satisfies the Extended Continuous Mapping Theorem (see e.g.\nBillingsley (1968)), we have that\nZ\u03c4n(u) = hn(Y\n\u03c4\nn (u))\nd\u2192 h(Bu) = B0u,\nwhich completes the proof. \u0003\nReferences\nE. Andreou and E. Ghysels. Detecting multiple breaks in financial market volatility dy-\nnamics. Journal of Applied Econometrics, 17:579\u2013600, 2002.\nP. Billingsley. Convergence of Probability Measures. Wiley, New York, 1968.\nD. R. Brillinger. Time Series: Data Analysis and Theory. Holt, Rinehart & Winston, Inc.,\nNew York, 1975.\nP. J. Brockwell and R. A. Davis. Time Series: Theory and Methods. Springer, 1987.\nP. Chaudhuri and J.S. Marron. SiZer for exploration of structures in curves. Journal of the\nAmerican Statistical Association, 94:807\u2013823, 1999.\nJ. Cho and J. Bae. Edge-adaptive local min\/max nonlinear filter-based shoot suppression.\nIEEE Transactions on Consumer Electronics, 52:1107\u20131111, 2006.\nR. Dahlhaus. Fitting time series models to nonstationary processes. Ann. of Stat., 25:1\u201337,\n1997.\nJ. Davidson. Stochastic Limit Theory. Oxford University Press, 1994.\nR. Davis, T. Lee, and G. Rodriguez-Yam. Break detection for a class of nonlinear time\nseries models. Journal of Time Series Analysis, 29:834\u2013867, 2008.\nS. Douglas. Running max\/min calculation using a pruned ordered list. IEEE Transactions\non Signal Processing, 44:2872\u20132877, 1996.\nP. Doukhan, G. Oppenheim, and M. S. Taqqu, editors. Theory and Applications of Long-\nRange Dependence. Birkha\u00a8user, 2003.\n33\nB. Efron, T. Hastie, I. Johnstone, and R. Tibshirani. Least angle regression. Annals of\nStatistics, 32:407\u2013499, 2004.\nJ. Fan and Q. Yao. Nonlinear Time Series. Springer-Verlag, New York, 2003.\nP. Fryzlewicz, T. Sapatinas, and S. Subba Rao. Normalised least-squares estimation in\ntime-varying ARCH models. Annals of Statistics, 36:742\u2013786, 2008.\nP. Hall and A. Wood. On the performance of box-counting estimators of fractal dimension.\nBiometrika, 80:246\u2013252, 1993.\nH. Hotelling. Tubes and spheres in n-spaces, and a class of statistical problems. American\nJournal of Mathematics, 61:440\u2013460, 1939.\nH.E. Hurst. Long term storage capacity of reservoirs. Trans. Am. Soc. Civil Engineers, 116:\n770\u2013799, 1951.\nS. Johansen and I.M. Johnstone. Hotelling\u2019s theorem of the volume of tubes: some illus-\ntrations in simultaneous inference and data analysis. Annals of Statistics, 18:652\u2013684,\n1990.\nY. Kakizawa, R. Shumway, and M. Taniguchi. Discrimination and clustering for multivariate\ntime series. Journal of the American Statistical Association, 93:328\u2013340, 1998.\nD. Kennedy. The distribution of the maximum Brownian excursion. J. Appl. Prob., 13:\n371\u2013376, 1976.\nE. Keogh and C.A. Ratanamahatana. Exact indexing of dynamic time warping. Knowledge\nand Information Systems, 7:358\u2013386, 2005.\nM. Knowles and D. Siegmund. On Hotelling\u2019s geometric approach to testing for a nonlinear\nparameter in regression. International Statistical Review, 57:205\u2013220, 1988.\nS. Lee, R.M. Haralick, and L.G. Shapiro. Morphologic edge detection. IEEE Transactions\non Robotics and Automation, 3:142\u2013156, 1987.\nT. Lindeberg. Scale-Space Theory in Computer Vision. Kluwer, Boston, 1994.\nG. P. Nason. Wavelet Methods in Statistics with R. Springer, New York, 2008.\nM. Neumann and R. von Sachs. A wavelet-based test for stationarity. J. Time Ser. Anal.,\n21:597\u2013613, 2000.\nE. Paparoditis. Testing temporal constancy of the spectral structure of a time series.\nBernoulli, 15:1190\u20131221, 2009.\nC. Park, J. Hannig, and K.-H. Kang. Improved SiZer for time series. Statistica Sinica, 19:\n1511\u20131530, 2009.\nD. B. Percival and A. T. Walden. Wavelet Methods for Time Series Analysis. Cambridge\nUniversity Press, 2000.\nM. Priestley. Evolutionary spectra and non-stationary processes. Journal of the Royal\nStatistical Society. Series B, 27:204\u2013237, 1965.\n34\nM. B. Priestley. Spectral Analysis and Time Series. Academic Press, 1981.\nV. Rondonotti, J.S. Marron, and C. Park. SiZer for time series: A new approach to the\nanalysis of trends. Electronic Journal of Statistics, 1:268\u2013289, 2007.\nR. H. Shumway and D. S. Stoffer. Time Series Analysis and Its Applications: With R\nExamples, 2nd Edition. Springer, New York, 2006.\nC. Starica and C. Granger. Non-stationarities in stock returns. Review of Economics and\nStatistics, 87:503\u2013522, 2005.\nJ. Sun. Tail probabilities of the maxima of Gaussian random fields. Annals of Probability,\n21:34\u201371, 1993.\nR. Tibshirani. Regression shrinkage and selection via the lasso. J. Royal. Statist. Soc. B,\n58:267\u2013288, 1996.\nS. Van Bellegem and R. von Sachs. Locally adaptive estimation of evolutionary wavelet\nspectra. Annals of Statistics, 36:1879\u20131924, 2008.\nM. Vemis, G. Economou, S. Fotopoulos, and A. Khodyrev. The use of Boolean functions\nand logical operations for edge detection in images. Signal Processing, 45:161\u2013172, 1995.\nB. Vidakovic. Statistical Modeling by Wavelets. Wiley, New York, 1999.\nM. Werman and S. Peleg. Min max operators in texture analysis. IEEE Transactions on\nPattern Analysis and Machine Intelligence, 7:730\u2013733, 1985.\nH. Weyl. On the volume of tubes. American Journal of Mathematics, 61:461\u2013472, 1939.\nX. Ye, M. Cheriet, and C.Y. Suen. Stroke-model-based character extraction from gray-level\ndocument images. IEEE Transactions on Image Processing, 8:1152\u20131161, 2001.\n35\n"}
{"doi":"10.1109\/ICASSP.2004.1326534","coreId":"102566","oai":"oai:epubs.surrey.ac.uk:2051","identifiers":["oai:epubs.surrey.ac.uk:2051","10.1109\/ICASSP.2004.1326534"],"title":"A scalable vertex-based shape intra-coding scheme for video objects","authors":["Hu, A","Worrall, S","Sadka, AH","Kondoz, AM"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":null,"abstract":"Scalable shape encoding is one of the important steps to achieving highly scalable object-based video coding. In this paper, a new scalable vertex-based shape intra-coding scheme has been described. To improve the encoding performance, we propose a new vertex selection scheme, which can reduce the number of approximation vertices. We also propose a new vertex encoding method, in which the information on the coarser layers and statistical entropy coding are exploited for high encoding efficiency. Experimental results show that the proposed scheme can provide 25-60% gain over the scalable encoding method in Buhan Jordan et al. (1998). For some sequences, it can achieve 5-10% gain over the conventional non-scalable vertex-based coding method (O\u2019Connell (1997)) in bit rate, at the price of additional complexity","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:2051<\/identifier><datestamp>\n      2017-10-31T14:04:05Z<\/datestamp><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/2051\/<\/dc:relation><dc:title>\n        A scalable vertex-based shape intra-coding scheme for video objects<\/dc:title><dc:creator>\n        Hu, A<\/dc:creator><dc:creator>\n        Worrall, S<\/dc:creator><dc:creator>\n        Sadka, AH<\/dc:creator><dc:creator>\n        Kondoz, AM<\/dc:creator><dc:description>\n        Scalable shape encoding is one of the important steps to achieving highly scalable object-based video coding. In this paper, a new scalable vertex-based shape intra-coding scheme has been described. To improve the encoding performance, we propose a new vertex selection scheme, which can reduce the number of approximation vertices. We also propose a new vertex encoding method, in which the information on the coarser layers and statistical entropy coding are exploited for high encoding efficiency. Experimental results show that the proposed scheme can provide 25-60% gain over the scalable encoding method in Buhan Jordan et al. (1998). For some sequences, it can achieve 5-10% gain over the conventional non-scalable vertex-based coding method (O\u2019Connell (1997)) in bit rate, at the price of additional complexity.<\/dc:description><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/2051\/1\/SRF002117.pdf<\/dc:identifier><dc:identifier>\n          Hu, A, Worrall, S, Sadka, AH and Kondoz, AM   A scalable vertex-based shape intra-coding scheme for video objects   Acoustics, Speech, and Signal Processing, 2004. Proceedings. (ICASSP \u201904). IEEE International Conference on, 3.  iii - 273-6 vol.3 - iii - 273-6 vol.3.      <\/dc:identifier><dc:relation>\n        http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1326534<\/dc:relation><dc:relation>\n        10.1109\/ICASSP.2004.1326534<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/2051\/","http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1326534","10.1109\/ICASSP.2004.1326534"],"year":null,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"A SCALABLE VERTEX-BASED SHAPE INTRA-CODING SCHEME FOR\nVIDEO OBJECTS\nM. Hu, S. Worrall, A. H. Sadka, A. M. Kondoz\nCentre for Communication Systems Research, University of Surrey,\nGuildford, Surrey, GU2 7XH, U.K.\nABSTRACT\nScalable shape encoding is one of the important steps to\nachieving highly scalable object-based video coding. In\nthis paper, a new scalable vertex-based shape intra-coding\nscheme has been described. To improve the encoding\nperformance, we propose a new vertex selection scheme,\nwhich can reduce the number of approximation vertices.\nWe also propose a new vertex encoding method, in which\nthe information on the coarser layers and statistical\nentropy coding are exploited for high encoding efficiency.\nExperimental results show that the proposed scheme can\nprovide 25-60% gain over the scalable encoding method\nin [7]. For some sequences, it can achieve 5-10% gain\nover conventional non-scalable vertex-based coding\nmethod [4] in bit rate, at the price of additional\ncomplexity.\n1. INTRODUCTION\nThe emergency of new multimedia applications, such as\nsearching, indexing and manipulation of visual\ninformation at the semantic object level, require further\nresearch on video representation and coding. In MPEG-4,\nvideo frame is composed of objects and each object is\nrepresented by three sets of parameters (shape, texture and\nmotion) so that the object can be encoded, accessed and\nmanipulated in arbitrary shape. Among these three sets of\nparameters, shape information is crucial for object\nrepresentation and object-based coding. In order to\ntransmit the shape of an object efficiently, a larger\nnumber of techniques have been proposed [1-5]. These\ncoding techniques are typically classified as block-based\ntechniques [1] and contour-based techniques [2-5]. These\ncoding algorithms can achieve lossy and\/or lossless\ncoding.\nIn multimedia networks, as devices with different\nbandwidths and available decoding powers are\ninterconnected, bitstream scalability is also desirable. In\nrecent years, much research has focused on this topic and\nsome methods have been proposed [7]. However,\nexperimental results show that these methods cannot\nachieve higher compression efficiency for (near-) lossless\nshape coding.\nIn this paper, we propose a new scalable vertex-based\nshape intra-coding scheme for high coding efficiency. To\nimprove coding efficiency, our efforts are concentrated on\nthe progressive approximation and scalable intra-coding.\nFirst, an optimal vertex selection scheme is proposed,\nwhich can achieve less approximation vertex number.\nSecond, an efficient vertex-encoding scheme is proposed.\nThe information of the transmitted layers is exploited to\nimprove coding efficiency. This paper is organized as\nfollows. The proposed shape-coding scheme is described\nin details in section 2. Section 3 presents some\nexperimental results and concludes the whole paper.\n2. SCHEME DESCRIPTION\nOur proposed scalable vertex-based shape intra-coding\nscheme consists of two parts: progressive approximation,\nand scalable vertex coding, which will be discussed in\ndetails in the following sections.\n2.1. Progressive vertex selection\nIn recent years, many vertex selection algorithms have\nbeen proposed [5-9]. The iterative refinement method\n(IRM) [5] has been widely used as it can be easily\nimplemented and make control feasible. However, this\nmethod cannot give optimal vertices. Recently, optimised\nvertex selection method [6] has been proposed, which has\nhigh computational complexity.\nA new vertex selection scheme is proposed to\napproximate object contour progressively. Before vertex\nselection, majority filtering [3] and contour refinement are\nfirst applied to impose some constraints on the contour.\nThis can reduce the number of vertices during\napproximation. During approximation, the vertices are\nclassified into several layers according to the selected\nerror bands. In our work, 4 layers are used for QCIF\nsequences. Layers 0, 1, 2, and 3 have the corresponding\nerror band 4max =d , 2max =d , 1max =d , 0max =d\nrespectively. These selections are based on the research\nresults in [7]: it does not seem useful to encode more than\n4 layers and lossy shape coding should be limited to small\ndistortions for video coding.\nFor the vertex selection of layer 0, curvature scale space\nimage [9] has been exploited. The vertices of layer 0\nshould include the salient point of object contour, which\ncan feature contour efficiently, so that they can be\ndecoded first. This is very important for the applications,\nsuch as shape retrieving and matching. However, for the\ncontour with small curvature, the method, which is just\nbased on curvature, cannot achieve smaller mismatch\nerror during coding. Therefore, IRM method is used after\nthe curvature-based selection is made.\nFor other refinement layers, IRM, together with a novel\nmerging scheme, has been exploited. Each approximating\npolygon edge of the coarser layers is recursively split by\nintroducing a new vertex at the contour point with the\nlargest distance, until the desired accuracy maxdd < is\nreached. For the layer with 0max =d , the intrinsic image\ngrid quantisation is taken into account.\n,,,\u0003\u0010\u0003\u0015\u001a\u0016\u0013\u0010\u001a\u001b\u0013\u0016\u0010\u001b\u0017\u001b\u0017\u0010\u001c\u0012\u0013\u0017\u0012\u0007\u0015\u0013\u0011\u0013\u0013\u0003\u008b\u0015\u0013\u0013\u0017\u0003,((( ,&$663\u0003\u0015\u0013\u0013\u0017\nAuthorized licensed use limited to: University of Surrey. Downloaded on May 11,2010 at 15:40:06 UTC from IEEE Xplore.  Restrictions apply. \nIn order to reduce the approximation vertices and\nencoding bitrate, a new merging algorithm is proposed\nand summarized as follows:\n1. Suppose, at layer { }3,2,1\u2208i , the contour has been\ndivided into \u2211\n\u2212\n=\n1\n0\ni\nk\nkN segments. Along every segment,\nif the vertex number of layer i is 2 or more, these\nvertices will be evaluated. If the vertex is removed\nand the polygon approximation still satisfies the error\ncondition, remove it. Otherwise, keep it.\n2. If 0max =d , and, for every segment 21 pp , the vertex\nnumber of layer i is 2\u2265jn , arrange these vertices\nalong the contour in array []pt , including two\nterminals. Then:\nFor (k=0; k< 1\u2212jn ; k++){\nFor (kk= ][kpt ; kk< ]1[ +kpt ; kk++) {\nIf (kk== ][kpt )\nIf we can find knm jj \u2212< points to approximate segment\n2, pkk , recode the points and number;\nElse\nIf we can find 1\u2212\u2212< knm jj points to approximate\nsegment 2pkk , recode the point positions and number; }\n}\nIf (no such point sets are found) { No merge is needed; }\nElse { Replace the vertices of layer i with the point set with the\nsmallest number. }\nFig. 1 illustrates an example for the lossless\napproximation, where (a) is achieved by the published\nmethods in [5] and [7] and (b) is achieved by the proposed\nmethod. For the approximation of the contour segment\nbetween 1X and 2X , four points are required by using\nthe method in [5] and [7]. While using our proposed\nmethod, only one point is chosen. More experimental\nresults in section 3 show that our proposed method can\nachieve less number of vertices to approximate the object\ncontour, especially for (near-) lossless approximation.\n2.2. Scalable vertex encoding\nFor scalable vertex-based shape coding, there are two\nkinds of information to be encoded: contour configuration\nand contour location. Contour configuration is represented\nby an ordered set of vertices that can be used by decoder\nto correctly produce the ordered list of vertices. The\ncontour location is represented by the coordinates ( )yx,\nof the vertices. In our proposed method, the scalable\nvertex encoding consists of the encoding of the vertices in\nlayer 0, vertex connectivity and position encoding of\nrefinement layers.\n2.2.1. Encoding of layer 0\nAs there is no parent approximation for layer 0, the\ncorresponding vertices have to be encoded directly. The\nencoding of layer 0 consists of two parts: initial vertex\nencoding and the encoding of other vertices.\nIn our proposed method, a vertex-reordering step is\nconducted before initial vertex encoding. As we know, the\nrelative distance between the initial vertex 0v and the last\nvertex 10 \u2212Nv does not need to be coded. In Object-\nadaptive vertex-based shape encoding (OAVE) scheme in\n[4], as the bit assignment during encoding is dynamically\ndetermined by the maximum relative distance, the\nreordering of vertices can reduce the number of encoded\nbits. After initial vertex is decided, two prediction models\nhave been proposed to encode its position: (a) relative to\nthe origin of the Video object plane (VOP) boundary box;\n(b) relative to the origins of other contours. During\nexperiments, we found that, if the number of contour of\nVOP is high, (b) is more efficient than (a).\nIn the proposed scheme, two encoding models have been\nused to encode the non-initial vertices: (a) OAVE\nencoding scheme in [4]. (b) Absolute addressing.\nExperimental results in [10] show that OAVE combined\nwith adaptive arithmetic coding for encoding a composite\nrelative address shows the best performance. However, at\nhigh distortion levels ( 0max >>d ), the redundancy of\nsuccessive octant numbers may be small so that the\ncoding of differential chain code is less efficient.\nFurthermore, at high distortion levels, the distribution of\nvertices along the object contour is more irregular. When\nrelative distance of at least one vertex is large, the bit\nassignments to all other vertices are also large. So, in our\nscheme, if above circumstance is encountered, absolute\naddressing is preferable. We choose one of above\nmethods that can produce fewer bits.\n2.2.2. Vertex-connectivity encoding of refinement layer\nFor scalable shape coding, the connectivity, the number of\nchild vertices along the coarser polygon edges, between\nthe vertices should be encoded and transmitted to the\ndecoder. In our research, 2-D symbol ( )BA, is defined to\nindicate the positions, where new vertices will be added.\nA is to define the number of edges (or vertices) before a\nX1 Y1\nY2 Y3\nY4X2\n(A)\nX1 Y1\nX2\n(B)\nFig.1 Comparison of different lossless approximation methods Fig.2 Illustration on vertex-connectivity coding\n\u2295\n\u2295\n\u2295\n\u2295\n\u2295\n\u2295\n\u2295\n\u2295\n\u2295\n\u2295\nS\n\u2295 Level 0\nLevel 1\nLevel 2\n,,,\u0003\u0010\u0003\u0015\u001a\u0017\nAuthorized licensed use limited to: University of Surrey. Downloaded on May 11,2010 at 15:40:06 UTC from IEEE Xplore.  Restrictions apply. \nvertex should be added. B is defined as the number of\nvertices to be added along this approximation edge. For\neach approximation layer (except layer 0), 2-D symbols\nare formed and variable-length coded to produce the bit\nstreams.\nThe following example illustrates the symbol\nconstruction. Assume that we plan to encode the vertices\nalong the object contour in Fig.2. First, 10 vertices in\nlayer 0 are encoded and the vertex S is chosen as the\nstarting point. For layer 1 and layer 2, the 2-D reference\nsymbols are formed as follows:\n(4,1), (1,1), (2,1), (2,2) (Layer 1)\n(1,1), (3,1), (3,4), (2,1), (1,1), (1,2), (2,1), (2,2) (Layer 2)\nDuring encoding of these symbols, variable length coder\n(VLC) has been used. As the number of vertices for every\nlayer has been included in the layer header, the end-of-\nlayer (EOL) information is not needed.\n50 video objects from QCIF sequences have been used to\nstudy the statistics of symbols, which is shown in Fig. 3.\nIt is found that layer2 1 and 2 have almost the same\nstatistics, which is different from that of layer 3.\nTherefore, two VLC tables are designed. From Fig. 3, it\nis also found that, for layer 1 and layer 2, almost 75% of\n(A, B) symbols with B=1; and for layer 3, almost 75% of\n(A, B) symbols with A=1. During vertex position\nencoding, this has been used to improve the encoding\nefficiency.\n2.2.3. Vertex-position encoding of refinement layers\nFor the vertex position encoding of refinement layers, the\nimproved OAVE encoding scheme in [4] has been used,\nin which the information from already transmitted coarser\nlayers and approximation error band is exploited for high\nencoding efficiency. The encoding process includes:\nDetermine and encode two indicators; encode the octant\nnumber; and encode the major and minor components.\nDetermine and encode two indicators: In the proposed\nmethod, only the segments containing the newly inserted\nvertices are used for determining maxx and maxy , which\nare used to select two indicators: xindicator and\nyindicator as described in details in [4]. The selected\nindicators are then encoded using a 3-bit FLC.\nEncode the octant numbers: In the proposed method, the\ndeterminant of octants is different from that in [4].\nAccording to the vertex number jn along the\napproximation edge, two octant determination methods\nare proposed. If 1=jn , we decide its octant from Fig.4\n(a). Otherwise, their octants are decided by Fig.4 (b).\nIn Fig.4 (a), 1X and 2X belong to the coarser layers.\nNow, if one point 1Y belongs to current layer, it must\nsatisfy 1max2 ddd <\u2264 and be located in the regions\nbetween 10\u0001 and 11\u0001 or between 20\u0001 and 21\u0001 . If 2\u2265jn ,\nthey are located in the region between 11\u0001 and 21\u0001 in Fig.\n4 (b). The regions corresponding to octant from 0 to 7 are\nseparated by 1\u0001 and 2\u0001 as indicated in Fig. 4 (a) and (b)\nfrom 0R to 7R respectively.\nAfter deciding the octants, they are encoded by using\nconditional differential chain coding (CDCC). The\ndifferential octant of 1Y is obtained by the difference\nbetween neighbouring octant value. In our research, three\npatterns of previous differential direction are used for\nclassifications and designing the VLC tables.\nEncode the major and minor component:\nThe vertex number along the approximation edges, as\nshown in Fig.4, also decides the encoding methods.\nSituation 1: If 1=jn and the octant of this vertex is 0, 3,\n4, or 7, its x is encoded by using xindicator of current\nlayer. Its y is decided by value d in Fig.4 (a) and is\nencoded by VLC. If its octant is 1, 2, 5, or 6, such as 1Z\nin Fig. 3 (a), its y is decided by d and encoded by VLC.\nIts x is encoded by using ( )\u23a1 \u23a4{ }1log,min 12 +xindicatorx ,\nwhere 1x can be deduced from value d and line 1\u0001\nSituation 2: If 2\u2265jn , as shown in Fig. 4 (b), the first\nFig. 3 statistical distribution of (A, B) pairs for Layers\n1, 2, and 3\nd2\nd1\nd\nX1\nX2\nY1\nx\ny\n\u00011\n\u00012\n.\n\u0002\n\u0003\nY0\nR0\nR1\nR2\nR4\nR3\n\u000111\n\u000110\n\u000120\n\u000121\nR5\nR6\nR7\nZ1\nd\nx1\nZ0\nd1\nd\nX1\nX2\nx\ny\n\u00011\n\u00012\n\u0002\n\u0003\nR0\nR1R2\nR5\nR3\nR6\nR7\n\u000111\n\u000101\n\u000121\nd\nR4\nY1\nY2\nFig. 4. Encoding vertex position for refinement layers\n(a)\n(b)\n,,,\u0003\u0010\u0003\u0015\u001a\u0018\nAuthorized licensed use limited to: University of Surrey. Downloaded on May 11,2010 at 15:40:06 UTC from IEEE Xplore.  Restrictions apply. \nvertex is encoded by using the same method as above\ndescribed, except that different VLC Table is used. For\nother vertices, the method in [4] is used except that the\nerror band is also used to decide the number of bits.\nFor every refinement layer, two VLC tables are designed\nfor above two situations. For situation 1, the discrete set\nof d is { }6,5,4,3,2 , { }3,2,1 , { }1,0 for layers 1, 2, 3,\nrespectively. For situation 2, the discrete set of d is\n{ }6,5,4,3,2,1,0 , { }3,2,1,0 , { }1,0 for layers 1, 2, 3,\nrespectively. For layer 1 and 2, about 75% of total\nvertices satisfy situation 1, the value d can be encoded\nby 1-2 bits. For layer 3, the value d can also be encoded\nusing a single bit as the discrete set of d is { }1,0 .\nTherefore, much improvement can be achieved especially\nfor (near-) lossless shape coding as also shown in the\nexperimental results of section 3.\n3. EXPERIMENTAL RESULTS AND\nCONCLUSION\nSeveral video objects are selected to study the\nperformance of vertex selection scheme. Fig 5 lists the\nrequired average number vertices under different error\ncriteria for different video objects. Compared with the\nmethod in [5] and [7], in which majority filtering is also\nexploited during performance comparison, our proposed\nmethod can achieve up to 30-80% and 20-30% of the total\nnumber of vertices for lossless reconstruction of test video\nobjects. Simulation results show that our vertex selection\nscheme can get less number of vertices for contour\nprogressive approximation.\nWe test the performance of the proposed encoding\nscheme by encoding several widely used QCIF shape\nsequences: Weather, Children-Kids, and News. The\nperformance is compared to that of the existing shape\nencoding schemes in [4], and [7]. Corresponding results\nare plotted in Fig. 6. Our proposed scheme can provide\n25-60% gain in bit rate over the scalable encoding method\nin [7]. For some sequences, it can achieve 5-10% gain\nover conventional non-scalable vertex-based coding [3] in\nbit rate.\nIn conclusion, our proposed scalable shape coding method\ncan achieve great improvement of compression\nperformance by exploiting the geometrical knowledge of\ncoarser levels and statistical entropy coding, although\nmore computation is needed.\n4. REFERENCES\n1. N. Brady, F. Bossen, and N. Murphy, \u201cContext-based\narithmetic encoding of 2D shape sequences\u201d, in Special\nsession on shape coding, ICIP\u201997, 1997\n2. G. Melnikov and A. K. Katsaggelos, \"A rate-distortion\noptimal scalable vertex based shape coding algorithm,''\nProc. ICASSP-2000, Turkey, June 5-9, 2000\n3. C. Gu and M. Kunt, \u201cContour simplification and\nmotion compensated coding\u201d, signal processing: Image\ncommunications, Vol.7, pp.279-296, Nov. 1995\n4. K. J. O\u2019Connell, \u201cObject-adaptive vertex-based shape\ncoding method\u201d, IEEE Trans. on CSVT, Vol.7, No.1,\npp.251-255, Feb. 1997\n5. P. Gerkin, \u201cObject-based analysis-synthesis coding of\nimage sequences at very low bit rates\u201d, IEEE Trans. on\nCSVT, Vol. 7, pp.251-255, Feb. 1997\n6. G. Melnikov and A.K. Katsaggelos, \"Shape\napproximation through recursive scalable layer\ngeneration,\" Proc. of ICIP, Canada, Sept 10-13, 2000\n7. C.L. Buhan Jordan, T. Ebrahimi, and M. Kunt\n\u201cProgressive content based shape compression for\nretrieval of binary images \u201d, Computer Vision and Image\nUnderstanding, Vol.71, No.2, pp.1126-1154, Aug. 1998\n8. N. Ansari, E.J. Delp, \u201cOn detecting dominant points\u201d,\nPattern Recognition, Vol. 24,No.5, pp.441-451, May 1991\n9. F. Mokhtarian and Alan K. Mackworth, \u201cA theory of\nmultiscale, curvature-based shape representation for\nplanar curves\u201d, IEEE Trans. on PAMI, Vol.14, No.8, pp.\n789-805, Aug. 1992\n10. Jae-won Chung, et.al., \u201cA new vertex-based binary\nshape coder for high coding efficiency\u201d, Signal\nProcessing: Image Commun., Vo..15, pp.665-684, 2000\nFig.6. Comparison of various encoding methods for three sequences: (a) Weather, (b) Children-Kids,\n(c) News\nFig. 5 Comparison of different vertex-selection methods\n,,,\u0003\u0010\u0003\u0015\u001a\u0019\nAuthorized licensed use limited to: University of Surrey. Downloaded on May 11,2010 at 15:40:06 UTC from IEEE Xplore.  Restrictions apply. \n"}
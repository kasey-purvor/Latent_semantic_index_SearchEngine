{"doi":"10.1243\/095440504322886532","coreId":"66738","oai":"oai:dro.dur.ac.uk.OAI2:248","identifiers":["oai:dro.dur.ac.uk.OAI2:248","10.1243\/095440504322886532"],"title":"Developing cost models by advanced modelling technology.","authors":["Stockton,  D. J.","Wang,  Q."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2004-02","abstract":"The aim of this paper is to examine the use of artificial neural network (ANNs) in the development of cost models. Although such advanced modelling techniques have been highly successful in many engineering areas, this success has been strongly dependent on the ability to choose the correct ANN structure. In this respect, choosing the most suitable structure for the individual processing elements that make up the ANN is essential. The research reported in this paper, therefore, makes use of the Taguchi methodology to identify best and worst structural elements for ANN processing elements. In order clearly to determine the accuracy of the models developed, cost information has been generated using a published cost model of a turning process. The cost information generated from this model has been used to train ANNs and test the resulting model for estimating accuracy. In order to measure accuracy, the 'percentage average absolute error' value has been adopted. Using this measure, the accuracy of models developed using the best and worst ANN structural elements have been compared with the use of regression analysis. The results indicate that the use of ANN to develop cost models is superior to regression analysis, although both methods fail to develop models that provide useful accuracies when large numbers of variables are involved. \\u","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/66738.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/248\/1\/248.pdf","pdfHashValue":"abaa02cc3b43963e8aff2747badd32a7f592b59e","publisher":"Professional Engineering Publishing","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:248<\/identifier><datestamp>\n      2011-05-24T15:16:02Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Developing cost models by advanced modelling technology.<\/dc:title><dc:creator>\n        Stockton,  D. J.<\/dc:creator><dc:creator>\n        Wang,  Q.<\/dc:creator><dc:description>\n        The aim of this paper is to examine the use of artificial neural network (ANNs) in the development of cost models. Although such advanced modelling techniques have been highly successful in many engineering areas, this success has been strongly dependent on the ability to choose the correct ANN structure. In this respect, choosing the most suitable structure for the individual processing elements that make up the ANN is essential. The research reported in this paper, therefore, makes use of the Taguchi methodology to identify best and worst structural elements for ANN processing elements. In order clearly to determine the accuracy of the models developed, cost information has been generated using a published cost model of a turning process. The cost information generated from this model has been used to train ANNs and test the resulting model for estimating accuracy. In order to measure accuracy, the 'percentage average absolute error' value has been adopted. Using this measure, the accuracy of models developed using the best and worst ANN structural elements have been compared with the use of regression analysis. The results indicate that the use of ANN to develop cost models is superior to regression analysis, although both methods fail to develop models that provide useful accuracies when large numbers of variables are involved. \\ud\n<\/dc:description><dc:subject>\n        Cost modelling<\/dc:subject><dc:subject>\n         Artifical neural networks<\/dc:subject><dc:subject>\n         Taguchi methodology.<\/dc:subject><dc:publisher>\n        Professional Engineering Publishing<\/dc:publisher><dc:source>\n        Proceedings of the I MECH E part B : journal of engineering manufacture, 2004, Vol.218(2), pp.213-224 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2004-02<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:248<\/dc:identifier><dc:identifier>\n        issn:0954-4054<\/dc:identifier><dc:identifier>\n        doi:10.1243\/095440504322886532<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/248\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1243\/095440504322886532<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/248\/1\/248.pdf<\/dc:identifier><dc:rights>\n        \u00a9 Stockton, D. J. and Wang, Q., 2004. The definitive, peer reviewed and edited version of\\ud\nthis article is published in Proceedings of the I MECH E part B : journal of engineering\\ud\nmanufacture, 218, 2, pp. 213-224, 10.1243\/095440504322886532<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["0954-4054","issn:0954-4054"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2004,"topics":["Cost modelling","Artifical neural networks","Taguchi methodology."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n15 February 2010\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nStockton, D. J. and Wang, Q. (2004) \u2019Developing cost models by advanced modelling technology.\u2019,\nProceedings of the I MECH E part B : journal of engineering manufacture., 218 (2). pp. 213-224.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1243\/095440504322886532\nPublisher\u2019s copyright statement:\nStockton, D. J. and Wang, Q., 2004. The definitive, peer reviewed and edited version of this article is published in\nProceedings of the I MECH E part B : journal of engineering manufacture, 218, 2, pp. 213-224,\n10.1243\/095440504322886532\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\nDeveloping cost models by advanced modelling\ntechnology\nD Stockton1 and Q Wang2*\n1Faculty of Computing Sciences and Engineering, De Montfort University, Leicester, UK\n2School of Engineering, University of Durham, UK\nAbstract: The aim of this paper is to examine the use of arti\u00aecial neural network (ANNs) in the\ndevelopment of cost models. Although such advanced modelling techniques have been highly\nsuccessful in many engineering areas, this success has been strongly dependent on the ability to choose\nthe correct ANN structure. In this respect, choosing the most suitable structure for the individual\nprocessing elements that make up the ANN is essential. The research reported in this paper, therefore,\nmakes use of the Taguchi methodology to identify best and worst structural elements for ANN\nprocessing elements. In order clearly to determine the accuracy of the models developed, cost\ninformation has been generated using a published cost model of a turning process. The cost\ninformation generated from this model has been used to train ANNs and test the resulting model for\nestimating accuracy. In order to measure accuracy, the `percentage average absolute error\u2019 value has\nbeen adopted. Using this measure, the accuracy of models developed using the best and worst ANN\nstructural elements have been compared with the use of regression analysis. The results indicate that\nthe use of ANN to develop cost models is superior to regression analysis, although both methods fail\nto develop models that provide useful accuracies when large numbers of variables are involved.\nKeywords: cost modelling, arti\u00aecial neural networks, Taguchi methodology\n1 INTRODUCTION\nIn order to support the product and process development\nneeded to meet market expectations such as greater\nchoice of products, greater choice of manufacturing\nprocess and greater emphasis on minimizing overall life\ncycle costs of products, it is expected that the quantity,\ntype, accuracy and complexity of cost information will\nneed to be greatly increased. These changes will have a\ndramatic e\u0080 ect on the cost estimating process. This\ne\u0080 ect will arise owing to the nature of the cost estimating\nprocess, which involves both costly and time consuming\ntasks that require high levels of process and product\nexpertise to arrive at valid cost estimates. Cost models\nare an essential part of the overall cost estimating process\nin that they are important methods of deriving cost and\nprocess time information. The changes a\u0080 ecting the\nmarket environment will have similar e\u0080 ects on both\nthe cost estimating and cost modelling processes, as\nshown in Table 1.\n2 COST ESTIMATING\nCost estimating [1] is the process of calculating the\nexpected cost resources, i.e. labour, material and over-\nhead costs, that are required to accomplish a manufac-\nturing task or to manufacture or purchase a speci\u00aec\nproduct. The type of estimate, normally characterized\nby the type of resource costed, and the level of detail in\nthe cost data output and its accuracy depend primarily\non the type of decision requiring cost data and the avail-\nability of data from which to derive the estimate. For\nexample, cost data are used within a variety of decision\ntypes including when designing products, manufacturing\nproducts and making process improvements. In general,\nhigher levels of estimating accuracy are normally asso-\nciated with greater levels of data detail. In terms of pro-\nduct design, for example, the amount of data available\nfor use in cost estimating is normally dependent upon\nwhere in the development process the product design\nis, i.e. at the concept stage few data are available while\nat the detailed engineering drawing stage much greater\namounts are available.\nThe basic guidelines for cost estimation in manufac-\nturing businesses are provided by Ostwald [1], Cunning-\nham and Dixon [2] and Chang [3]. In general, the process\n213\nB09403 # IMechE 2004 Proc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture\nThe MS was received on 30 May 2003 and was accepted after revision\nfor publication on 14 October 2003.\n*Corresponding author: School of Engineering, University of Durham,\nSouth Road, Durham DH1 3LE, UK.\nof developing a cost estimate can be divided into the\nbasic steps shown in Fig. 1. This basic process can vary\ndepending on the characteristics of the cost estimate\nrequired or limitations, such as data availability, that\nmay restrict the characteristics of the resulting cost\nestimate. In this respect the primary characteristics of\ncost estimates a\u0080 ecting the estimating process are their\naccuracy, precision, the personnel involved and the\ntype and level of detail of the cost data provided. An\nexample of the relationships between estimating process\nand model characteristics arises when a high level of\naccuracy is required which prevents the use of subjective\njudgement by experienced cost estimators being\nemployed, whereas when only low levels of data are\navailable the use of experienced estimators is essential.\nThe initial tasks involved in cost estimation are depen-\ndent on the products made, the manufacturing processes\nused and the speci\u00aec accounting methods employed by\nindividual business organizations. Within manufacturing\nindustry there is a wide variety of manufacturing pro-\ncesses and accounting models in use. Personnel under-\ntaking a cost estimating exercise must ensure they have\nexpertise in the particular processes and accounting\nmethods used by the speci\u00aec company for which the\nexercise is being undertaken.\nThe functional areas, such as engineering, manufac-\nturing and procurement, that are required to perform\nthe work must then be identi\u00aeed, a schedule of the\nwork must be prepared and the level of e\u0080 ort must be\nde\u00aened and identi\u00aeed. This stage also involves selecting\nan appropriate cost\/process time estimating methodol-\nogy, the main categories of which are shown in Fig. 2\n[4], and using this method to estimate the man hours,\nmaterial costs and other cost generating variables. In\naddition, the elapsed time required to perform each\ndetail of the work must be determined. Cost rates are\nthen identi\u00aeed and used to establish the relevant costs\nof work elements.\nIn terms of manufacturing, each of these methods\nrequires an analysis of the work task to be performed,\nand each can vary in the level of detail required in the\nde\u00aenition of the work to be performed. To determine\nthe costs of manufacturing a product or the costs\ninvolved in operating a speci\u00aec production process, it is\nnecessary to identify cost elements and choose an\nappropriate method for estimating each type of cost. In\nthis respect the majority of cost estimates are normally\ncompiled by utilizing a combination of past similar\nTable 1 Example of e\u0080 ects on cost estimating\/modelling processes\nLimitations of cost estimating\/modelling processes\nChanges occurring in the market environment\nGreater number\nof cost models\nrequired\nLess historical\ncost data\navailable\nLess time\navailable to\ndevelop model\nGreater product\nand process\ncomplexity\nLess process\nexpertise\navailable\nGreater choice of products\nGreater amounts of product customization\nGreater choice of materials\nGreater choice of manufacturing processes\nReduced product development cycles\nGreater emphasis placed on life cycle costs\nFig. 1 Basic cost estimating process\n214 D STOCKTON AND Q WANG\nProc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture B09403 # IMechE 2004\nproduct costs, established in-house cost knowledge\nand\/or published cost information. Published cost\ninformation can reduce the cost and time of establishing\ncosts. Such information includes cost indexes, which\nallow estimates to be adjusted to present industrial\nenvironments. For example, Marshall and Swift equip-\nment cost indexes [5] are compiled for over 40 di\u0080 erent\nindustries. However, existing cost information is of\nrestricted use when attempting to estimate the cost of\nnew manufacturing technology. Recently, arti\u00aecial\nneural networks have generated much research interest\nin the manufacturing area, although many of the applica-\ntions reported in the literature are either laboratory\nexperiments or preliminary applications.\n3 TURNING PROCESS\nThe objective of the current research was to examine the\nability of arti\u00aecial neural networks (ANNs) to develop\ncost models; i.e. this ability was measured in terms of\nthe resulting accuracy of the cost models developed. In\norder to ensure that the level of estimating accuracy of\nthe ANN model could be clearly determined, a spread-\nsheet version of a known cost model, i.e. that published\nby Boothroyd and Reynolds [6], was developed and\nused to generate the cost data information used to train\nand test the ANN models. Smith and Mason [7] adopted\nthis method of generating costing examples since it\nprovided the advantage of knowing, for certain, what\nthe true underlying relationships are between predictor\nvariables and costs. Hence, the performance of an\nANN in predicting these relationships could be measured\nwith a high level of certainty. In addition, this model was\nchosen as suitable for use within the experimentation\nsince it contained a relatively large number of predictor\nvariables, i.e. 16, and both linear and non-linear relation-\nships between these variables and process costs.\nThe model developed by Boothroyd and Reynolds [6]\ncan be broken down into the following major elements:\n1. The machining time for roughing operations, tmp (s),\nassuming that maximum power is used, is given by\ntmp \u02c6\n60rvpsW\ndmaW\nb\n\u02c6 60rvps\ndma\nW 1 \u00a2 b \u20261\u2020\nwhere\nrv \u02c6 proportion of the initial volume\nPs \u02c6 speci\u00aec cutting energy or unit power for the\nwork material (hpmin\/in3)\nW \u02c6 weight of the workpiece (lb)\ndm \u02c6 density of the work material (lb\/in3)\na \u02c6 constants\nb \u02c6 constants\n2. The non-productive time, tnp (s), is given by\ntnp \u02c6\ntsa \u2021 nttsb\nBS \u2021 tln \u2021 notpt\n\u20262\u2020\nwhere\ntsa \u02c6 basic set-up time for the machine\nnt \u02c6 number of tools\ntsb \u02c6 set-up time per tool\nBS \u02c6 batch size\ntln \u02c6 loading and unloading time\nno \u02c6 number of operations\ntpt \u02c6 tool positioning time per operation\n3. The \u00aenish machining time, tmc (s), will then be given\nby\ntmc \u02c6\n60A\nRsg\n\u20263\u2020\nwhere\nA \u02c6 effective area to be machined\nRsg \u02c6 machinability factor\n4. The e\u0080 ective area to be machined, A, assuming that\nall surfaces on the workpiece are to be \u00aenished,\nFig. 2 Cost estimating methods [4]\nDEVELOPING COST MODELS BY ADVANCED MODELLING TECHNOLOGY 215\nB09403 # IMechE 2004 Proc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture\nincluding a through bore, is given approximately by\nA \u02c6 3:7\n\u00b3\n1 \u00a2 ri\n2LDR\n\u2021 1 \u2021 r0:5i \u00a2\nre\n1:5\n\u00b4\nLDR0:33\nW0:67\nd0:67m\n\u20264\u2020\nwhere\nri \u02c6 proportion of material removed by internal\nmachining\nre \u02c6 proportion of material removed by external\nmachining\nLDR \u02c6 length\/diameter ratio of the workpiece\n5. Worn tool replacement costs can be signi\u00aecant when\noperating under optimum (minimum cost) condi-\ntions. It has been shown that these costs can be\nallowed for by modifying equation (3) as follows:\nt0mc \u02c6\n60A\nRsg\n1\n1 \u00a2 n \u20265\u2020\nwhere\nn \u02c6 Taylor tool life index\n6. When machining is carried out at maximum power,\nthe corrected value of tmp (s) to allow for tool replace-\nment costs is\nt0mp \u02c6 tmp\n\u00b5\n1 \u2021 1\n1 \u00a2 n\n\u00b3\ntmc\ntmp\n1\u00b4=n \u00b6\n\u20266\u2020\nWhen tmc=tmp < 1, this correction, however, will be\nsmall unless the maximum power conditions are\nclose to the recommended conditions, which will not\nusually be the case for \u00aenishing operations.\nThe variables used in the above turning cost model, and\nused as variables within the experimentation, are de\u00aened\nas follows:\nn \u02c6 Taylor tool life index\nrv \u02c6 proportion of the initial volume (m3)\nPS \u02c6 speci\u00aec cutting energy or unit power for the\nwork material (hp min\/in3)\nW \u02c6 weight of the workpiece (lb)\ndm \u02c6 density of the work material (lb\/in3)\nRsg \u02c6 machinability factor\nri \u02c6 proportion of material removed by internal\nmachining\nre \u02c6 proportion of material removed by external\nmachining\nLRD \u02c6 length\/diameter ratio of the workpiece\ntsa \u02c6 basic set-up time for the machine (s)\nnt \u02c6 number of tools\ntsb \u02c6 set-up time per tool (s)\nBS \u02c6 batch size\ntln \u02c6 loading and unloading time (s)\nno \u02c6 number of operations\ntpt \u02c6 tool positioning time per operation (s)\nAn analysis of the relationships between each of the\nabove variables and process costs is shown in Table 2\nin terms of whether they represent linear and\/or non-\nlinear types.\n4 ARTIFICIAL NEURAL NETWORKS\nFrom its initial development in the early 1940s [8], ANN\ntechnology has advanced tremendously in terms of\nits ability to identify complex relationships. An ANN\n[9\u00b112] consists of a number of computer processing\nelements. The processing element forms the heart of the\nANN, and it is the functions associated with these ele-\nments that provide the ANN with the ability to model a\nwide variety of relationships between input and output\nvariables. An ANN, therefore, consists of many proces-\nsing elements joined together in the above manner.\nProcessing elements are usually organized into groups\ncalled layers, with full or random connections between\nsuccessive layers. There are typically two layers that\npossess connections to the outside world, i.e. an input\nlayer where data are presented to the network, and an\noutput layer which holds the response of the network to\na given input. Layers distinct from the input and output\nbu\u0080 ers are called hidden layers.\nThe ANN structure shown in Fig. 3 [13] illustrates how\nthe ANN is made up of these three basic types of layer:\n1. The input layer accepts information from external\nsources and assigns weighted values to these depend-\ning on their relative importance as cost drivers.\n2. The hidden layer processes this input information and\nconverts it to the required output data.\n3. The output layer outputs cost data from the ANN.\nThe number of processing elements contained in a layer\ncan be varied, as can the number of hidden layers within\nany individual network. Processing elements within\nlayers are normally `fully connected\u2019; i.e. an individual\nTable 2 Relationships between variables and cost\nVariables\nLinear\nrelationship\nNon-linear\nrelationship\nBoth types of\nrelationship\nn\nrv\nPS\nW\ndm\nRsg\nri\nre\nLDR\ntsa\nnt\ntsb\nBS\ntln\nno\ntpt\n216 D STOCKTON AND Q WANG\nProc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture B09403 # IMechE 2004\nprocessing element within a layer is connected to all\nprocessing elements in both the preceding and succeed-\ning layers. Processing elements within the same layer\nare, however, not connected.\nAs values for process variables are input into the\nANN, the processing elements within the input, hidden\nand output layers are modi\u00aeed such that the di\u0080 erence\nbetween the output cost values and actual cost values,\ni.e. the error, is gradually minimized. This process,\ntermed `training the network\u2019, is performed within the\ncurrent research work using `back-propagation\u2019; i.e.\nthis technique calculates an error between actual\nvalues and output values and propagates the error\ninformation back through the network to each node\n(i.e. processing element) in each layer. This back-\npropagated error then drives the learning at each node.\nLearning is therefore the process of adapting or modify-\ning the connection weights in response to stimuli being\npresented at the input bu\u0080 er and optionally at the\noutput bu\u0080 er.\nProcessing elements (PEs) [14, 15] contain a number of\nmathematical functions, as shown in Fig. 4. These\nfunctions act in a sequential manner to transform input\nvalues into output values. Input values can either be\nexternally derived input values of predictor variables or\noutputs from processing elements in a preceding layer.\nThe functional steps within this sequence are as follows:\nStep 1: weighted summation function. Weightings are\napplied to each of the variable values input into a\nPE, and the summation function then sums these\nweighted variable values. Two methods of summing\nthe weighted inputs have been examined in the current\nresearch:\n1. The sum is the traditional sum of the e\u0080 ective\ninputs.\n2. The majority counts the number of e\u0080 ective inputs\ngreater than zero and subtracts the number of e\u0080 ec-\ntive inputs less than or equal to zero.\nStep 2: transfer function. The result of the weighted sum\nis transformed into a working output or `transfer\u2019\noutput by the transfer function. Four types of transfer\nfunction have been examined in the current research:\n1. In the linear function the transfer value is simply the\ninput value.\n2. The sigmoid function maps inputs into values\nbetween 0 and 1.\n3. The sine function transfers the trigonometric sine of\nthe input value.\nFig. 3 Arti\u00aecial neural network structure\nDEVELOPING COST MODELS BY ADVANCED MODELLING TECHNOLOGY 217\nB09403 # IMechE 2004 Proc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture\n4. Tanh (hyperbolic tangent) is similar to the sigmoid\nfunction but maps input values into the range \u00a2 1 to\n\u20211.\nPrior to applying the transfer function, uniformly dis-\ntributed random noise may be added. Three types of\nnoise function have been examined in the current\nresearch:\n1. In the case of uniform noise, a random value is\napplied to each PE in a layer.\n2. In the case of Gaussian noise, again a random value\nis applied to PEs, but these random values are\nnormally distributed.\n3. In the case of no noise, no noise function is applied.\nStep 3: scaling and limiting. Scaling is used to perform a\nlinear transformation on the result of the transfer\nfunction. After scaling is applied, the transfer function\nis clipped to the upper and lower limits.\nStep 4: output function. This provides a method of allow-\ning PEs within a layer to compete with each other.\nCompetition can occur to determine which PEs pro-\nvide outputs to PEs in succeeding layers and\/or to\ndetermine which PEs will participate in the learning\nor adaptation process. Three methods of determining\nthe participation of PEs have been examined in the\ncurrent research:\n1. In the direct method there is no competition\nbetween PEs.\n2. In the select method, if a PE has `learned\u2019, then the\noutput value for a single PE is set equal to the\ncurrent transfer value for a single PE. If a PE has\nnever `learned\u2019, the output value for a single PE is\nset equal to zero.\n3. In the one highest method, when processing ele-\nments compete for output, only the \u00aerst winner\nwill learn or adapt and no other PEs in the layer\nwill adapt its weight.\nStep 5: error function. Three methods have been exam-\nined in the current research for transforming the raw\nerror, i.e. the di\u0080 erence between the current output\nand the desired output:\n1. In the standard function no transformation takes\nplace.\n2. In the quadratic function the error is squared but\nretains its sign.\n3. The cubic function cubes the error.\nThe latter two functions increase the importance of\nlarge errors. A scale is then applied to the resulting\nerror function in order either to increase or to decrease\nthe error associated with a particular PE. The resulting\nvalue is termed the `current error\u2019.\nFig. 4 Function of a processing element\n218 D STOCKTON AND Q WANG\nProc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture B09403 # IMechE 2004\nStep 6: back-propagation. The process of back-propaga-\ntion consists of multiplying connection weights by a\nspeci\u00aec value and then adding the resulting value to\nthe error \u00aeeld in the source PE. Depending on the\nnetwork type, the back-propagated value is either the\ncurrent error, the current error scaled by the derivative\nof the transfer function or the desired output.\nStep 7: learning rules. Variable connection weights are\nmodi\u00aeed according to a learning rule, of which four\nhave been compared in the current research:\n1. According to the Hebb rule, if both the desired\noutput and the input are above a threshold value,\nthen the connecting weight is incremented by a\nset learning rate.\n2. The perceptron rule uses a derived amount to change\nthe connection weights between PEs. Individual\nweight changes depend on actual and desired\noutput values of PEs. A simple rule is used to deter-\nmine if weight changes should be applied: if the\noutput from an individual PE is active and is\nintended to be active, then do not apply the weight\nchanges, otherwise apply the weight changes.\n3. According to the delta rule, the error between the\ndesired output and the actual output transformed\nby the derivative of the transfer function is `back-\npropagated\u2019 to prior layers until the \u00aerst layer is\nreached.\n4. According to the Ext DBD rule, if the error is less\nthan the previous minimum error, the weights are\nsaved in memory as the current best. However, if\nthe current error exceeds the minimum previous\nerror, all connection weight values revert stochasti-\ncally to the stored best set of weights in memory\nand, in addition, the learning rate and momentum\nrate are decreased to begin recovery.\nIf some form of competition for learning is in e\u0080 ect,\nonly the weights belonging to the `winning\u2019 processing\nelement will be updated. Learning rules will use one or\nmore of the learning coe\u0081 cients from the learning and\nrecall schedule. These coe\u0081 cients will have di\u0080 erent\nmeanings depending on the particular learning rule.\n5 TAGUCHI METHODOLOGY\nTaguchi\u2019s methodology, often termed the `robust design\nmethod\u2019, provides the designer with a systematic and\ne\u0081 cient approach for conducting experimentation to\ndetermine near-optimum settings of design parameters\nfor performance and cost [16\u00b120]. The mathematical\ntools that form the methodology are primarily based\non the statistical theory underpinning the concepts of\n`design of experiments\u2019 [20\u00b122]. The primary advantage\nof using the Taguchi methodology is its ability to mini-\nmize the number of experiments required to identify\nthe e\u0080 ect, on estimating accuracy, of each of the alterna-\ntive mathematical functions that make up the structure\nof the individual ANN processing elements. The use of\nthe Taguchi methodology is justi\u00aeed since there is only\none output variable, i.e. cost. The technique is not\nbeing used to determine the e\u0080 ect of continuous vari-\nables; i.e. alternative mathematical techniques are being\ncompared, and the decisions required from the method\nare merely to identify the best and worst of these alterna-\ntives. Essentially, the Taguchi methodology enables a\nseries of experiments to be designed that will enable\nidenti\u00aecation of the optimal quality characteristics for\na speci\u00aec objective. In terms of product and process\ndesign, therefore, the methodology provides a systematic\napproach for determining the optimum con\u00aeguration of\ndesign parameters for performance, quality and cost.\nThe basis of the Taguchi methodology is the use of\northogonal arrays (OAs) which are employed to select\na range of experiments capable of e\u0081 ciently studying\nparameter spaces that contain a large number of decision\nvariables. The choice of an OA [23] depends on the\nnumber of degrees of freedom required for studying the\nmain and interaction e\u0080 ects.\n6 APPLICATION OF TAGUCHI\nMETHODOLOGY\nThe main function of an ANN-based cost modelling tool\nis to generate cost estimates that are accurate and inex-\npensive to generate in terms of the type and amount of\ninput data needed to train the network. The quality\ncharacteristic to be observed is `estimating accuracy\u2019,\nand maximizing accuracy is the objective. The objective\nfunction to be minimized is the `percentage average\nabsolute error\u2019. Also of importance within the cost\nestimating area is the range of error. This is measured,\nin the current research, using `standard deviation of the\npercentage average absolute error\u2019 values.\nThe controllable design factors (i.e. parameters) to be\nconsidered, along with their alternative levels, are listed\nin Table 3. In the case of designing ANN structures,\nthe alternative `level\u2019 of the design factors will be repre-\nsented by alternative types of mathematical function\nTable 3 ANN design factors and factor levels\nProcessing\nelement function Level 1 Level 2 Level 3\nSummation\nfunction\nSum Majority\nNoise function Uniform noise Gaussian noise None\nTransfer function Linear tanh Sine\nOutput function Direct Select One highest\nError function Standard Quadratic Cubic\nLearning rules Ext DBD Perceptron Delta rule\nDEVELOPING COST MODELS BY ADVANCED MODELLING TECHNOLOGY 219\nB09403 # IMechE 2004 Proc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture\nused within processing elements. These factor levels\nde\u00aene the experimental region to be studied.\nTo select the appropriate orthogonal array to \u00aet a\nspeci\u00aec case study, it is necessary to count the total\ndegrees of freedom to \u00aend the minimum number of\nexperiments that must be performed to reach a near-\noptimum parameter set [20, 22, 24]. One degree of free-\ndom is associated with the overall mean regardless of\nthe number of control factors. This is added to the\ndegrees of freedom associated with each control factor,\nwhich is equal to one less than the number of levels.\nThe number of degrees of freedom has been calculated\nin Table 4 as an example for the turning experimentation.\nTherefore, it is necessary to conduct at least 12 experi-\nments to reach a near-optimum case. This \u00aets into\nTaguchi\u2019s standard L18 array, shown in Table 5. In\norder for an array to be a viable choice, the number of\nrows must at least be equal to the degrees of freedom\nrequired [20]. The L18 array has 17 degrees of freedom\nand hence can manage eight factors at three levels.\nSince there are only six control factors, two of the\ncolumns of the array will remain empty. Orthogonality\nis not lost by keeping one or more columns of an array\nempty [20, 24].\nThe experiments listed in Tables 6 and 7 were carried\nout to determine the e\u0080 ects, on the accuracy of ANN-\nbased cost estimating models, of the following:\n(a) the number of variables used to construct models\nand\n(b) the number of data samples used to develop the cost\nmodels.\nTable 4 Total number of degrees of freedom\nProcessing\nelement function\nNumber of\nlevels\nDegrees of\nfreedom\nMean 1\nSummation function 2 1\nNoise function 3 2\nTransfer function 3 2\nOutput function 3 2\nError function 3 2\nLearning rules 3 2\nTotal number of degrees of freedom\u02c6 12\nTable 5 L18 orthogonal array turning cost models\nExperiment\nnumbers\nSummation\nfunctions Noise function\nTransfer\nfunction\nOutput\nfunctions\nError\nfunction\nLearning\nrules\n1 Sum Uniform noise Linear Direct Standard Ext DBD\n2 Sum Uniform noise tanh Select Quadratic Perceptron\n3 Sum Uniform noise Sine One highest Cubic Delta rule\n4 Sum Gaussian noise Linear Direct Quadratic Delta rule\n5 Sum Gaussian noise tanh Select Cubic Ext DBD\n6 Sum Gaussian noise Sine One highest Standard Perceptron\n7 Sum None Linear Select Standard Delta rule\n8 Sum None tanh One highest Quadratic Ext DBD\n9 Sum None Sine Direct Cubic Perceptron\n10 Majority Uniform noise Linear One highest Cubic Ext DBD\n11 Majority Uniform noise tanh Direct Standard Perceptron\n12 Majority Uniform noise Sine Select Quadratic Delta rule\n13 Majority Gaussian noise Linear Select Cubic Perceptron\n14 Majority Gaussian noise tanh One highest Standard Delta rule\n15 Majority Gaussian noise Sine Direct Quadratic Ext DBD\n16 Majority None Linear One highest Quadratic Perceptron\n17 Majority None tanh Direct Cubic Delta rule\n18 Majority None Sine Select Standard Ext DBD\nTable 6 Number of variables experimentation\nExperiment\nnumbers\nNumber of\nvariables\nNumber of\ndata points Model types tested\n1 to 15 1 150, 300, 450,\n600, 750\nBest ANN, worst\nANN, regression\n16 to 30 2 150, 300, 450,\n600, 750\nBest ANN, worst\nANN, regression\n31 to 45 4 150, 300, 450,\n600, 750\nBest ANN, worst\nANN, regression\n46 to 60 6 150, 300, 450,\n600, 750\nBest ANN, worst\nANN, regression\n61 to 75 9 150, 300, 450,\n600, 750\nBest ANN, worst\nANN, regression\n76 to 90 16 150, 300, 450,\n600, 750\nBest ANN, worst\nANN, regression\nTable 7 Number of data points experimentation\nExperiment\nnumbers\nNumber of\ndata points\nNumber of\nvariables Model types tested\n1 to 18 150 1, 2, 4, 6, 9, 16 Best ANN, worst\nANN, regression\n19 to 36 300 1, 2, 4, 6, 9, 16 Best ANN, worst\nANN, regression\n37 to 54 450 1, 2, 4, 6, 9, 16 Best ANN, worst\nANN, regression\n55 to 72 600 1, 2, 4, 6, 9, 16 Best ANN, worst\nANN, regression\n73 to 90 750 1, 2, 4, 6, 9, 16 Best ANN, worst\nANN, regression\n220 D STOCKTON AND Q WANG\nProc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture B09403 # IMechE 2004\nAs a comparison, models were also developed using the\nLINEST regression analysis function within a Microsoft\nExcel spreadsheet [25].\n7 RESULTS AND DISCUSSION\nIn order to identify the relative e\u0080 ect on cost modelling\nestimating accuracy of the number of variables and\nnumber of data points, the experiments listed in Tables\n6 and 7 were carried out, and the results are shown in\nFigs 5 to 10. From these \u00aegures the following e\u0080 ects\ncan be observed. Increasing the number of variables\nincreases the estimating accuracy of the resulting\nmodels both in terms of the percentage average absolute\nerror and the standard deviation of percentage average\nabsolute error:\n1. This e\u0080 ect becomes more pronounced as the number\nof data points used to construct the model decreases.\nHowever, both increasing numbers of variables and\nincreasing numbers of data points lead to improve-\nments in estimating accuracy.\n2. The estimating accuracy of the regression-based\nmodels, in general, increases with increasing numbers\nof variables, but there appears to be no marked\nincrease when the number of data points used to con-\nstruct models increases.\n3. In all cases the estimating accuracy obtained when\nusing the `worst\u2019 network structure is poor when\ncompared with that of the `best\u2019 structure and in\nmany cases the regression models have similar results.\nIn addition, the ability of such models to estimate\nFig. 5 Total of 150 data points with percentage average absolute error\nFig. 6 Total of 450 data points with percentage average absolute error\nDEVELOPING COST MODELS BY ADVANCED MODELLING TECHNOLOGY 221\nB09403 # IMechE 2004 Proc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture\nFig. 7 Total of 750 data points with percentage average absolute error\nFig. 8 Total of 150 data points with standard deviation of percentage average absolute error\nFig. 9 Total of 450 data points with standard deviation of percentage average absolute error\n222 D STOCKTON AND Q WANG\nProc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture B09403 # IMechE 2004\naccurate costs is erratic; i.e. in many cases there is no\nrelationship between estimating accuracy, number of\nvariables and number of data points.\n4. The greater the number of variables used, the less will\nbe the e\u0080 ect on estimating accuracy of increasing the\nnumber of data points.\n8 CONCLUSIONS\nExperiments have been undertaken to identify the in\u00afu-\nence, on the estimating accuracy of the resulting models,\nof varying the amount of data used to develop the model\nand varying the number of variables within the model.\nAs would be expected, increasing the amount of data\nused to develop the model and increasing the number\nof variables within the model in all cases leads to an over-\nall increase in the estimating accuracy of the resulting\nmodels. These experiments did, however, reveal that\nfewer variables and lower amounts of cost data are\nrequired to achieve a speci\u00aec level of estimating accuracy\nthan when using regression analysis. The results present\nin this paper also show that the consequences of choosing\nan appropriate network structure can be identi\u00aeed. Little\nevidence is available to suggest that speci\u00aec ANN struc-\ntures could be used over a range of applications. Hence,\nthe Taguchi approach adopted in this research represents\nan e\u0081 cient method for determining appropriate ANN\nstructures since it allows the number of experiments\nrequired for identi\u00aecation to be minimized together\nwith the costs of developing the resulting models.\nACKNOWLEDGEMENT\nThe authors wish to acknowledge the funding received\nfrom the Engineering and Physical Sciences Research\nCouncil (EPSRC) through the COSTMOD project\n(Ref. GR\/M 58818).\nREFERENCES\n1 Ostwald, P. Cost Estimating, 4th edition, 1988 (Prentice-\nHall, Englewood Cli\u0080 s, New Jersey).\n2 Cunningham,J. J. andDixon, J. R.Designingwith features:\nthe origin of features. Trans. ASME, Computers in Engng,\n1988, 237\u00b1243.\n3 Chang, T.-C. Expert Process Planning for Manufacturing,\n1990 (Addison-Wesley, Reading, Massachusetts).\n4 Wild, R. Essentials of Production and Operations Manage-\nment, 2nd edition, 1985 (Holt, Rinehart and Winston,\nLondon).\n5 Venkatachalam, A. R. A knowledge-based approach to\ndesign for manufacturability. PhD dissertation, Alabama\nUniversity, Alabama, 1990.\n6 Boothroyd,G. and Reynolds, C. Approximate cost estimates\nfor typical turned parts. J.Mfg Systems, 1989,8(3), 185\u00b1193.\n7 Smith, A. E. and Mason, A. K. Cost estimation predictive\nmodelling: regression versus neural network. J. Engng\nEcon., 1997, 42(2), 137\u00b1161.\n8 McCulloch, W. S. and Pitts, W. A. A logical calculus of the\nideas imminent in nervous activity. Bull. Math. Biophys.,\n1943, 5, 115\u00b1133.\n9 Bode, J. Neural networks for cost estimation. Cost Engng,\n1998, 40(1), 25\u00b131.\n10 De la Garza, J. M. and Rouhana, K. G. Neural networks\nversus parameter-based applications in cost engineering.\nJ. Cost Engng, February 1995, 37(2), 14\u00b118.\n11 Shtub, A. and Zimerman, Y. Neural-network-based\napproach for estimating the cost of assembly systems. Int.\nJ. Prod. Econ., September 1993, 32(2), 189\u00b1207.\n12 Bode, J., Ren, S. J. and Shi, Z. Z. Application of 3-layer\nperceptrons to cost estimation. In Proceedings of the\nIEEE International Conference on Neural Networks,\n1995, 4(4), 1749\u00b11754.\nFig. 10 Total of 750 data points with standard deviation of percentage average absolute error\nDEVELOPING COST MODELS BY ADVANCED MODELLING TECHNOLOGY 223\nB09403 # IMechE 2004 Proc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture\n13 Wang, Q. and Stockton,D. J. Process time estimating using\nneural networks. In Proceedings of the 15th International\nConference on Computer-Aided Production Engineering,\nDurham University, April 1999, pp. 201\u00b1206.\n14 Advanced Reference Guide for Professional II\/PLUS, 1996\n(The NeuralWare Inc., Pittsburgh, Pennsylvania).\n15 Wang, Q., Stockton, D. J. and Baguley, P. Using neural\nnetworks in cost model development process. In Proceed-\ningsof the SixteenthNationalConferenceonManufacturing\nResearch, University of East London, September 2000, pp.\n59\u00b163.\n16 Bendell, A. Introduction to Taguchi methodology. In Pro-\nceedings of the European Conference on Taguchi Methods,\n1988, pp. 1\u00b114.\n17 Kackar, R. N. Taguchi\u2019s quality philosophy: analysis and\ncommentary.Qual. Prog., December 1986, 21\u00b129.\n18 Logothetis, N. and Salmon, J. P. Tolerance design and\nanalysis of audio-circuits. In Proceedings of the European\nConference on Taguchi Methods, 1988, pp. 161\u00b1175.\n19 Meisl, C. J. Parametric cost analysis in the TQM environ-\nment. In 12th Annual Conference of International Society\nof Parametric Analysts, San Diego, California, 1990.\n20 Phadke, S. M. Quality Engineering Using Robust Design,\n1989 (Prentice-Hall, Englewood Cli\u0080 s, New Jersey).\n21 Gunter, B. A perspective on the Taguchi methods. Qual.\nProg., June 1987, 44\u00b151.\n22 Wille, R. Landing gear weight optimisation using Taguchi\nanalysis. In the 49th Annual International Conference of\nSociety of Allied Weight Engineers, Chandler, Arkansas,\n1990.\n23 Ross, P. J. Taguchi Techniques for Quality Engineering:\nLoss Function, Orthogonal Experiments, Parameter and\nTolerance Design, 1988 (McGraw-Hill, New York).\n24 TaguchiMethods: ImplementationManual, 1989 (American\nSupplier Institute, Dearborn, Michigan).\n25 Halberg, B., Kinkoph, S. and Ray, B. Special Edition\nUsing Microsoft Excel97, 1997 (Que Corporation,\nCarmel, Indiana).\n224 D STOCKTON AND Q WANG\nProc. Instn Mech. Engrs Vol. 218 Part B: J. Engineering Manufacture B09403 # IMechE 2004\n"}
{"doi":"10.1016\/j.physa.2011.07.028","coreId":"197717","oai":"oai:lra.le.ac.uk:2381\/9978","identifiers":["oai:lra.le.ac.uk:2381\/9978","10.1016\/j.physa.2011.07.028"],"title":"On finite truncation of infinite shot noise series representation of tempered stable laws","authors":["Imai, Junichi","Kawai, Reiichiro"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-07-31","abstract":"This is the author\u2019s version of a work that was accepted for publication in Physica A: Statistical Mechanics and its Applications. Changes resulting from the publishing process, such as editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may have been made to this work since it was submitted for publication. A definitive version was subsequently published in Physica A, 390 (23-24), 2011, pp. 4411-4425. DOI: 10.1016\/j.physa.2011.07.028Tempered stable processes are widely used in various fields of application as alternatives with finite\\ud\nsecond moment and long-range Gaussian behaviors to stable processes. Infinite shot noise series representation\\ud\nis the only exact simulation method for the tempered stable process and has recently attracted\\ud\nattention for simulation use with ever improved computational speed. In this paper, we derive series\\ud\nrepresentations for the tempered stable laws of increasing practical interest through the thinning, rejection,\\ud\nand inverse L\u00e9vy measure methods. We make a rigorous comparison among those representations,\\ud\nincluding the existing one due to [18, 34], in terms of the tail mass of L\u00e9vy measures which can be\\ud\nsimulated under a common finite truncation scheme. The tail mass are derived in closed form for some\\ud\nrepresentations thanks to various structural properties of the tempered stable laws. We prove that the\\ud\nrepresentation via the inverse L\u00e9vy measure method achieves a much faster convergence in truncation\\ud\nto the infinite sum than all the other representations. Numerical results are presented to support our\\ud\ntheoretical analysis.Peer-reviewedPost-prin","downloadUrl":"http:\/\/hdl.handle.net\/2381\/9978","fullTextIdentifier":"https:\/\/lra.le.ac.uk\/bitstream\/2381\/9978\/4\/qmc3.pdf","pdfHashValue":"72579030e48743fc05e5fe62149cd1e90aa0ffdc","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:lra.le.ac.uk:2381\/9978<\/identifier><datestamp>\n                2012-03-09T10:10:37Z<\/datestamp><setSpec>\n                com_2381_445<\/setSpec><setSpec>\n                com_2381_9549<\/setSpec><setSpec>\n                col_2381_3823<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nOn finite truncation of infinite shot noise series representation of tempered stable laws<\/dc:title><dc:creator>\nImai, Junichi<\/dc:creator><dc:creator>\nKawai, Reiichiro<\/dc:creator><dc:subject>\nInfinitely divisible random vector<\/dc:subject><dc:subject>\nInverse Levy measure method<\/dc:subject><dc:subject>\nRejection method<\/dc:subject><dc:subject>\nSample path simulation<\/dc:subject><dc:subject>\nShot noise method<\/dc:subject><dc:subject>\nTempered stable process<\/dc:subject><dc:subject>\nThinning method<\/dc:subject><dc:description>\nThis is the author\u2019s version of a work that was accepted for publication in Physica A: Statistical Mechanics and its Applications. Changes resulting from the publishing process, such as editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may have been made to this work since it was submitted for publication. A definitive version was subsequently published in Physica A, 390 (23-24), 2011, pp. 4411-4425. DOI: 10.1016\/j.physa.2011.07.028<\/dc:description><dc:description>\nTempered stable processes are widely used in various fields of application as alternatives with finite\\ud\nsecond moment and long-range Gaussian behaviors to stable processes. Infinite shot noise series representation\\ud\nis the only exact simulation method for the tempered stable process and has recently attracted\\ud\nattention for simulation use with ever improved computational speed. In this paper, we derive series\\ud\nrepresentations for the tempered stable laws of increasing practical interest through the thinning, rejection,\\ud\nand inverse L\u00e9vy measure methods. We make a rigorous comparison among those representations,\\ud\nincluding the existing one due to [18, 34], in terms of the tail mass of L\u00e9vy measures which can be\\ud\nsimulated under a common finite truncation scheme. The tail mass are derived in closed form for some\\ud\nrepresentations thanks to various structural properties of the tempered stable laws. We prove that the\\ud\nrepresentation via the inverse L\u00e9vy measure method achieves a much faster convergence in truncation\\ud\nto the infinite sum than all the other representations. Numerical results are presented to support our\\ud\ntheoretical analysis.<\/dc:description><dc:description>\nPeer-reviewed<\/dc:description><dc:description>\nPost-print<\/dc:description><dc:date>\n2011-12-21T09:56:03Z<\/dc:date><dc:date>\n2011-12-21T09:56:03Z<\/dc:date><dc:date>\n2011-07-31<\/dc:date><dc:type>\nJournal Article<\/dc:type><dc:type>\nArticle<\/dc:type><dc:identifier>\nPhysica A: Statistical Mechanics and its Applications, 2011, 390 (23-24), pp. 4411-4425.<\/dc:identifier><dc:identifier>\n0378-4371<\/dc:identifier><dc:identifier>\nhttp:\/\/www.journals.elsevier.com\/physica-a-statistical-mechanics-and-its-applications\/<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2381\/9978<\/dc:identifier><dc:identifier>\n10.1016\/j.physa.2011.07.028<\/dc:identifier><dc:language>\nen<\/dc:language><dc:rights>\nCopyright \u00a9 Elsevier B.V. All rights reserved.<\/dc:rights><dc:publisher>\nElsevier<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["0378-4371","issn:0378-4371"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2011,"topics":["Infinitely divisible random vector","Inverse Levy measure method","Rejection method","Sample path simulation","Shot noise method","Tempered stable process","Thinning method"],"subject":["Journal Article","Article"],"fullText":"On Finite Truncation of Infinite Shot Noise Series Representation\nof Tempered Stable Laws\nJUNICHI IMAI\u0003 AND REIICHIRO KAWAI\u2020\nAbstract\nTempered stable processes are widely used in various fields of application as alternatives with finite\nsecond moment and long-range Gaussian behaviors to stable processes. Infinite shot noise series repre-\nsentation is the only exact simulation method for the tempered stable process and has recently attracted\nattention for simulation use with ever improved computational speed. In this paper, we derive series\nrepresentations for the tempered stable laws of increasing practical interest through the thinning, rejec-\ntion, and inverse Le\u00b4vy measure methods. We make a rigorous comparison among those representations,\nincluding the existing one due to [18, 34], in terms of the tail mass of Le\u00b4vy measures which can be\nsimulated under a common finite truncation scheme. The tail mass are derived in closed form for some\nrepresentations thanks to various structural properties of the tempered stable laws. We prove that the\nrepresentation via the inverse Le\u00b4vy measure method achieves a much faster convergence in truncation\nto the infinite sum than all the other representations. Numerical results are presented to support our\ntheoretical analysis.\nKeywords: infinitely divisible random vector, inverse Le\u00b4vy measure method, rejection method, sample\npaths simulation, shot noise method, tempered stable process, thinning method.\n2010 Mathematics Subject Classification: 60E07, 65B10, 60B10, 65C10.\n1 Introduction\nThe class of tempered stable law was first proposed by Tweedie [36]. Its associated Le\u00b4vy and Ornstein-\nUhlenbeck processes were studied in Barndorff-Nielsen and Shephard [4] and Rosin\u00b4ski [34]. In particular,\nRosin\u00b4ski [34] reveals their featuring properties, such as a stable-like behavior over short intervals, the ab-\nsolute continuity with respect to its short-range limiting stable subordinator, aggregational Gaussianity and\na series representation in closed form. Such processes have been introduced in a variety of applications.\nIn mathematical finance, they were introduced to model asset price dynamics in Carr et al. [7] under the\nname CGMY model and stochastic volatility in Benth et al. [5] and Carr et al. [8]. They were also used in\nfinancial econometrics in [4] and in mathematical biology in Palmer et al. [31], to mention just a few. In sta-\ntistical physics, stochastic processes with heavy marginal probability tails and still with finite variance have\nbeen developed through various different direct truncations of the marginal density function of the stable\nlaw. The pioneering work of Mantegan and Stanley [28] is the constitution for the so-called truncated Le\u00b4vy\nflights in econophysics. In Koponen [26], the analytic expression for characteristic function of truncated\nLe\u00b4vy flights was derived. Multi-scaling properties of truncated Le\u00b4vy flights was investigated by Nakao [30]\nfor the first time. Arbitrary truncation of Le\u00b4vy flights was considered in Vinogradov [37]. In Figueiredo\nPublished in Physica A (2011) 390(23-24) 4411-4425.\n\u0003Email Address: jimai@ae.keio.ac.jp. Postal Address: Faculty of Science and Technology, Keio University, Yokohama, 223-\n8522, Japan.\n\u2020Corresponding Author. Email Address: reiichiro.kawai@le.ac.uk. Postal Address: Department of Mathematics, University of\nLeicester, Leicester LE1 7RH, UK. Tel: +44-116-223-1310. Fax: +44-116-252-3915.\n1\net al. [14], truncated Le\u00b4vy flights are extended to possess autocorrelation, which is often observed in the\nreal-world financial data. Various other related models were studied in, for instance, Gupta and Campanha\n[15], Matsushita, Rathie and Da Silva [29], and Podobnik et al. [32]. Those truncated Le\u00b4vy flight models are\nadequately capable of describing a variety of stylized properties seen in time series of complex systems and\nhave been appealing due to their intuitive approach, while they are no longer Le\u00b4vy processes and are thus\nnot robust to the observation time scale. This fact ensure practical importance and sample path generation\nof tempered stable processes.\nSeveral methods for simulation of sample paths of tempered stable Le\u00b4vy processes have been investi-\ngated in the literature. It is well known (Devroye [12] and Baeumer andMeerschaert [3]) that their univariate\nincrements with stability index smaller than one can be simulated in the exact sense through acceptance-\nrejection sampling using its non-tempered stable random variables as proposal distribution. The case of\nstability index greater than one is also discussed in [3] and Kawai and Masuda [25] in an approximative\nsense. With the help of those acceptance-rejection, simulations of tempered stable Ornstein-Uhlenbeck pro-\ncesses are investigated in Kawai and Masuda [23, 24] under a discrete observation setting. The other route\nof sample paths simulation is based on infinite shot noise series representations (Bondesson [6] and Rosin\u00b4ski\n[33]). Strictly speaking, the infinite shot noise series is the only exact simulation method for tempered stable\nprocesses to realize all the information of sample paths, that is, size, direction and timing of every single\njump. A closed form of such a series representation was derived in Rosin\u00b4ski [34] (first introduced in his\ndiscussion section of the article [4]). Its structure is sufficiently simple and enables one to simulate sample\npaths solely with elementary random variables, such as exponential and uniform. From a computational\npoint of view, the form of infinite sum raises issues of heavy computing load and of finite truncation [10]\nand suggests variance reduction for Monte Carlo simulation purposes [19, 20].\nThe main purpose of this paper is to investigate a finite truncation of infinite shot noise series represen-\ntation of the tempered stable law from a numerical standpoint in order to facilitate the simulation use of such\ninfinite series representations. By applying several methods for deriving a kernel of shot noise series (see\nRosin\u00b4ski [33]), we derive and present in Section 3 five different representations of the tempered stable law.\nOur main results are presented in Theorem 3.1 on the finite truncation of those five representations. In short,\nthe inverse Le\u00b4vy measure method [13, 27] simulates more mass of Le\u00b4vy measure tails under a common finite\ntruncation scheme, compared to representations based on the rejection and thinning methods [33] and the\nrepresentation of Rosin\u00b4ski [34]. In connection with recent results of the authors [17, 18], the inverse Le\u00b4vy\nmeasure method is most attractive from a simulation point of view. In the representation through the inverse\nLe\u00b4vy measure method, we only need to generate Poisson arrival times for the jump size and a few others for\njump timing and direction. In the case of the tempered stable law, however, the tail inverse of Le\u00b4vy measure\nis not available in closed form. This issue was addressed in [18] through a numerical approach, which we\nwill review in Appendix A to keep this paper self-contained. Numerical results on moment estimation of\nunilateral tempered stable random variable are presented in Section 4 to provide the support for our theo-\nretical analysis. To avoid overloading the paper with rather lengthy proofs of somewhat routine nature, we\nomit non-essential details in some instances.\n2 Preliminaries\nLet us begin this section with the notations which will be used throughout the paper. We denote by Rd the\nd-dimensional Euclidean space with the norm k \u0001 k, Rd0 := Rd nf0g, R+ := (0;+\u00a5) andB(Rd0) is the Borel\ns -field of Rd0 . We let N be the collection of positive integers, with N0 := N[f0g. We denote by L= and L!,\nrespectively, identity and convergence in law. Finally, we define the following.\n(i) fEkgk2N is a sequence of iid exponential random variables with unit mean,\n2\n(ii) fGkgk2N is a sequence of standard Poisson arrival times, generated iteratively as a successive sum-\nmation of iid exponential random variables;\nfG1;G2;G3; : : :g \nn\n\u00e51k=1Ek;\u00e5\n2\nk=1Ek;\u00e5\n3\nk=1Ek; : : :\no\n: (2.1)\nThe exponential random variables fEkgk2N serve as Poisson interarrival times.\n2.1 Tempered Stable Law\nWe here review the tempered stable law defined by Rosin\u00b4ski [34]. An infinitely divisible probability measure\nm on Rd , without Gaussian component, is called tempered stable if its Le\u00b4vy measure has the form\nn(B) =\nZ\nRd0\nZ\nR+\n1B(rv)\ne\u0000r\nra+1\ndrr(dv); B 2B(Rd0); (2.2)\nwhere a 2 (0;2) and where the measure r on Rd0 satisfiesZ\nRd0\nkvkar(dv)<+\u00a5: (2.3)\nThe two parameters a and r uniquely identify Le\u00b4vy measure of the tempered stable law. Under the addi-\ntional condition (R\nRd0\nkvkr(dv)<+\u00a5; if a 2 (0;1);R\nRd0\nkvk(1+ ln+ kvk)r(dv)<+\u00a5; if a = 1; (2.4)\nthe characteristic function of m has a closed form expression given by\nbm(y) = exp\u0014ihy;bi+Z\nRd0\nfa(hy;vi)r(dv)\n\u0015\n; (2.5)\nfor some b 2 Rd and where, for s 2 R;\nfa(s) =\n(\nG(\u0000a)((1\u0000 is)a \u00001+ ias); if a 2 (0;1)[ (1;2);\n(1\u0000 is) ln(1\u0000 is)+ is; if a = 1: (2.6)\nFor further details about its distributional properties, we refer the reader to [34]. Let us briefly survey\nknown simulation methods for the tempered stable law, except for the one based on infinite shot noise series\nrepresentation.\n(i) The most primitive and direct method for the tempered stable law is based on the use of its probability\ndistribution function computed from the characteristic function (2.5) by the Gil-Pelaez formula.\nHowever, we need to deal with numerical integrations for the formula, and also need to invert the\ndistribution for each uniform random variable.\n(ii) Gaussian approximation of small jump component was justified by [2, 10], while the remaining com-\nponent is compound Poisson. Let us clarify that simulation of the compound Poisson component is\nnot as easy as often claimed in the literature, as its standardized distribution function is not available\nin closed form and the intensity may be extremely large depending on the choice of the small jump\ncomponent. Great care should thus be taken when addressing this trade-off issue.\n3\n(iii) The one-dimensional unilateral tempered stable distribution admits a density function, which is an\nexponential tilting of the density of its corresponding non-tempered stable distribution. Together\nwith the well known exact, yet simple, simulation method of Chambers et al. [9], we can apply\nacceptance-rejection sampling. If its stability index is less than one, then the support of the distribu-\ntion is half real line and thus the acceptance-rejection sampling method is exact. (See, for example,\n[3, 12, 23].) Otherwise, the support is the entire real line, while acceptance-rejection sampling can\nstill be applied in an approximative sense due to Baeumer and Meerschaert [3]. (See also [24] for\nfurther analysis.)\n(iv) Related to (iii), the one-dimensional unilateral distribution can be evaluated for computation of the\nexpectation based on Theorem 33.3 of Sato [35]. In this case, the standardized exponential tilting\nacts as the Radon-Nykodym derivative for change of measure. This method is exact, regardless of\nstability index, while is only valid for computation of the expectation, not for sample paths simula-\ntion. (See, for example, [22] for practical use of this method.)\nTo the best of our knowledge, as just described, an exact simulation is possible in the path-wise sense only\nfor the one-dimensional unilateral case with stability index less than one. This observation justifies our\ninvestigation of infinite shot noise series representation from a numerical point of view.\n2.2 A Shot Noise Series Representation of Tempered Stable Laws\nLet us first review generalities on the series representation of general infinitely divisible law. Our startup\ndiscussion is essentially parallel to the inverse Le\u00b4vy measure method of [13, 27]. Notice first that the random\nvariable \u00e5+\u00a5k=1Gk1[0;T ](Gk) is infinitely divisible with Le\u00b4vy measure n(dz) = dz defined on (0;T ]. Recall\nalso that the epochs of an inhomogeneous Poisson process on [0;T ] with intensity h(t) can be generated by\nH(G1), H(G2), : : :, where H(t) = inffu 2 [0;T ] :\nR u\n0 h(s)ds< tg, provided that\nR T\n0 h(s)ds<+\u00a5. Therefore,\nby regarding the intensity h(t) as a Le\u00b4vy measure (\u201con state space\u201d rather than \u201con time\u201d), we deduce that\n\u00e5+\u00a5k=1H(Gk)1[0;T ](Gk) is an infinitely divisible random variable with Le\u00b4vy measure n(dz) = h(z)dz defined\non (0;T ]. Notice here that the definition of H(t) implicitly assumes that that the Le\u00b4vy measure n has a\ncompact support. Moreover, the condition\nR T\n0 h(s)ds<+\u00a5 indicates a finite Le\u00b4vy measure. We can extend\nthis formulation to an infinite Le\u00b4vy measure on R+, simply by redefining the kernel H as running down\nfrom the infinity rather than up the other way, that is, H(r) = inffu 2 R+ :\nR +\u00a5\nu h(s)ds < rg, and compute\n\u00e5+\u00a5k=1H(Gk), where fGkgk2N is no longer restricted on a finite interval [0;T ]. (See Asmussen and Glynn [1].)\nThe most general form of series representations is given by the so-called generalized shot noise method\nintroduced by Bondesson [6] and Rosin\u00b4ski [33]. Assume that Le\u00b4vy measure n defined on Rd0 can be decom-\nposed as\nn(B) =\nZ\nR+\nP(H(r;U) 2 B)dr; B 2B(Rd0); (2.7)\nwhereU is a random variate taking values in a suitable space U , and where H : R+\u0002U 7! Rd0 is such that\nfor each u 2 U , r 7! kH(r;u)k is non-increasing. Let fUkgk2N be a sequence of iid copies of the random\nvariateU , independent of fGkgk2N. Then, the random vector\n+\u00a5\n\u00e5\nk=1\n(H (Gk;Uk)\u0000E [H (Gk;Uk)1(kH (Gk;Uk)k \u0014 1)]) (2.8)\nhas an infinitely divisible law with characteristic function\ny 7! exp\n\u0014Z\nRd0\n\u0010\neihy;zi\u00001\u0000 ihy;zi1(0;1](kzk)\n\u0011\nn(dz)\n\u0015\n:\n4\nA series representation of the tempered stable law is derived in Rosin\u00b4ski [34] through the generalized shot\nnoise method. Let fWkgk2N be a sequence of iid standard exponential random variables, let fUkgk2N be a\nsequence of iid uniform random variables on [0;1], let fVkgk2N be a sequence of iid random vectors in Rd0\nwith common distribution kvkar(dv)\nma;r\n;\nwith\nma;r :=\nZ\nRd0\nkvkar(dv):\nAlso, let k0 =\nR\nRd0\nvkvka\u00001r(dv)=ma;r , and let\nz0 :=\n(\n(a=ma;r)\u00001=az (1=a)k0+ jG(1\u0000a)j\nR\nRd0\nvr(dv); if a 6= 1;\n(a\u00001 ln(ma;r)+2g)\nR\nRd0\nvr(dv)\u0000 RRd0 v lnkvkr(dv); if a = 1;\nwhere z denotes the Riemann zeta function and g(= 0:5772:::) is the Euler constant. Then, by Theorem 5.4\nof [34], it is known that the random vector\n+\u00a5\n\u00e5\nk=1\n\" \u0012\naGk\nma;r\n\u0013\u00001=a\n^WkU1=ak kVkk\n!\nVk\nkVkk \u0000\n\u0012\nak\nma ;r\n\u0013\u00001=a\nk0\n#\n+ z0 (2.9)\nhas the tempered stable law with characteristic function (2.5) with b= 0.\n3 Main Results\nIn this section, we derive three infinite shot noise series representations of tempered stable law and compare\nthem, including two known representations of [18, 34]. Let us first prepare some notations, which will be\nused in what follows. Fix l 2 (0;1], l1 2 R+ and l2 2 (0;1]. Define\nH1(r;w;u;v) :=\n\"\u0012\nar\nma;r\n\u0013\u00001=a\n^wu1=akvk\n#\nv\nkvk ;\nH2(r;w;v) := w1\n \nr \u0014 ma ;r kvkl\ne\u0000\n1\u0000l\nkvk w\nwa+1\n!\nv\nkvk ;\nH3(r;w;v) := w1\n0@r \u0014 ma;rG(l1)\u0012kvkl2\n\u0013l1 e\u0000 1\u0000l2kvk w\nwa+l1\n1A v\nkvk ;\nH4(r;u;v) := H(s)(r)1\n\u0010\ne\u0000H(s)(r)=kvk > u\n\u0011 v\nkvk ;\nH5(r;v) := inf\n(\nu 2 R+ :\nZ +\u00a5\nu\nma;r\ne\u0000s=kvk\nsa+1\nds> r\n)\nv\nkvk :\nWe will also use the notation\nH(s)(r) :=\n\u0012\nar\nma;r\n\u0013\u00001=a\n:\nEach of the above serve as a kernel of infinite shot noise series representation. Set the following random\nsequences.\n5\n(i) fGkgk2N is a sequence of standard Poisson arrival times,\n(ii) fVkgk2N is a sequence of iid random vectors with common distribution kvkar(dv)=ma;r on Rd0 ,\n(iii) fUkgk2N is a sequence of iid uniform random variables on [0;1],\n(iv) fW (1)k gk2N is a sequence of iid standard exponential random variables,\n(v) fW (2)k gk2N is a sequence of independent exponential random variables withW (2)k having rate l=kVkk\nconditionally on kVkk,\n(vi) fW (3)k gk2N is a sequence of independent gamma random variables with W (3)k having shape l1 and\nscale kVkk=l2 conditionally on kVkk.\nAs described in Section 2.2, any shot noise series representation of the tempered stable law has the form\nof infinite sum, since the associated Le\u00b4vy measure is infinite. To deal with infinite sums in simulation, we\nneed to truncate them up to a certain finite point. A straightforward approach is the truncation to a finite\nnumber of terms of the series, that is, \u00e5nk=1 for some n 2 N. In this paper, however, we adopt another\napproach based on the truncation to a finite time span of the underlying standard Poisson process, that is,\n\u00e5fk2N:Gk\u0014ng. Clearly, truncation level is left random and is thus different for different replications, while\nit is almost surely finite. This truncation scheme enables us to trace the part of Le\u00b4vy measure, which shot\nnoise series can simulate. With this truncation scheme, define for each n 2 N,\nX1;n := \u00e5\nfk2N:Gk\u0014ng\nh\nH1(Gk;W\n(1)\nk ;Uk;Vk)\u0000 c1;k\ni\n; (3.1)\nX2;n := \u00e5\nfk2N:Gk\u0014ng\nh\nH2(Gk;W\n(2)\nk ;Vk)\u0000 c2;k\ni\n; (3.2)\nX3;n := \u00e5\nfk2N:Gk\u0014ng\nh\nH3(Gk;W\n(3)\nk ;Vk)\u0000 c3;k\ni\n; (3.3)\nX4;n := \u00e5\nfk2N:Gk\u0014ng\n[H4(Gk;Uk;Vk)\u0000 c4;k] ; (3.4)\nX5;n := \u00e5\nfk2N:Gk\u0014ng\n[H5(Gk;Vk)\u0000 c5;k] ; (3.5)\nwhere\nc1;k := E[H1(Gk;W\n(1)\nk ;Uk;Vk)1(0;1](kH1(Gk;W (1)k ;Uk;Vk)k)];\nc2;k := E[H2(Gk;W\n(2)\nk ;Vk)1(0;1](kH2(Gk;W (2)k ;Vk)k)];\nc3;k := E[H3(Gk;W\n(3)\nk ;Vk)1(0;1](kH3(Gk;W (3)k ;Vk)k)];\nc4;k := E[H4(Gk;Uk;Vk)1(0;1](kH4(Gk;Uk;Vk)k)];\nc5;k := E[H5(Gk;Vk)1(0;1](kH5(Gk;Vk)k)]:\nThe representation (3.1) was derived by Rosin\u00b4ski [34] (first introduced in his discussion part of [4]). The\nrepresentations (3.2) and (3.3) are due to the thinning method of Rosin\u00b4ski [33]. The representation (3.4) is\ndue to the rejection method of Rosin\u00b4ski [33]. The representation (3.5) is based on the inverse Le\u00b4vy measure\nmethod.\nTheorem 3.1. (i) For each k= 1;2;3;4;5, the lawL (Xk;n) is infinitely divisible with Le\u00b4vy measure nn;k and\nconverges to the infinitely divisible law with triplet (0;0;n) as n \"+\u00a5.\n(ii) It holds that for each n 2 N,\nnk;n(Rd0) = n; k = 1;2;3;4;5:\n6\n(iii) It holds that for each n 2 N, x 2 R+ and C 2B(Sd\u00001),\nn1;n((x;+\u00a5)C) =\n\u0012\nn\na\nma;r\nxa ^1\n\u0013\nn((x;+\u00a5)C); (3.6)\nn4;n((x;+\u00a5)C) = n\n\u0010\u0010\u0000\nan=ma;r\n\u0001\u00001=a\n;+\u00a5\n\u0011\nC\n\u0011\n^n ((x;+\u00a5)C) ; (3.7)\nnk;n((x;+\u00a5)C)\u0014 n5;n((x;+\u00a5)C); k = 1;2;3;4: (3.8)\n(iv) It holds that for each n 2 N and q\u0015 0 such that Rkzk>1 kzkqn(dz)<+\u00a5,Z\nRd0\nkzkqnk;n(dz)<\nZ\nRd0\nkzkqn5;n(dz)\u0014\nZ\nRd0\nkzkqn(dz); k = 1;2;3;4: (3.9)\nFirst, the result (ii) asserts that all the five representations account for the mass n out of the infinite Le\u00b4vy\nmeasure n when truncating infinite series by fk 2 N : Gk \u0014 ng. The results (iii) provide useful information\nabout the way the representations simulate tails of Le\u00b4vy measure. In particular, the tail masses (3.6) and\n(3.7) are available in closed form thanks to various structural properties of the tempered stable laws and\nshow the effect of the almost sure finite truncation scheme fk 2 N : Gk \u0014 ng for the representations of\nRosin\u00b4ski (3.1) and of the rejection method (3.4) in the exact sense. Moreover, the inequality (3.8) indicates\nthat whenever the truncation is performed, the three representations (via the rejection and thinning methods)\ncannot simulate the tail of the Le\u00b4vy measure as much as the inverse Le\u00b4vy measure method. In conjunction\nwith the result (ii), we conclude that the three representations instead simulate some part of the Le\u00b4vy measure\ncloser to the origin. The inequality (iv) is a direct consequence of this observation. Since this fact holds for\nany truncation level n, the inverse Le\u00b4vy measure method dominates over the other three representations. It\nhowever seems difficult to find clear dominance relations between the representation (3.1) and the others.\nWe will compare those shortly through numerical experiments.\nProof. Throughout the proof, we will use the notations\nf (x;a;b) :=\nba\nG(a)\nxa\u00001e\u0000bx; x 2 R+ (3.10)\nfor the gamma probability density function with a> 0 and b> 0, and\ner(dv) := kvka\nma;r\nr(dv); v 2 Rd0 : (3.11)\nNote first that the truncation fk 2 N : Gk \u0014 ng of infinite series corresponds to the truncation of the integral\nwith respect to the Lebesgue measure dr to the interval (0;n) in the decomposition (2.7).\n(i) First of all, a change of variables yields the polar decomposition\nn(B) =\nZ\nRd0\nZ\nR+\n1B\n\u0012\nr\nv\nkvk\n\u0013\nma;r\ne\u0000r=kvk\nra+1\ndrer(dv); B 2B(Rd0):\nThe variable v in this representation corresponds to the random sequence fVkgk2N.\nWe begin with the representation of fX1;ngn2N. To this end, let us first decompose n((x;+\u00a5)C). Observe\n7\nthat for each x 2 R+ andC 2B(Sd\u00001),\nn((x;+\u00a5)C)\n=\nZ\nRd0\nZ\nR+\n1(x;+\u00a5)(wkvk)\ne\u0000w\nwa+1\ndw1C\n\u0012\nv\nkvk\n\u0013\nr(dv)\n=\nZ\nRd0\nZ +\u00a5\nx=kvk\ne\u0000w\nwa+1\ndw1C\n\u0012\nv\nkvk\n\u0013\nr(dv)\n=\nZ\nRd0\n1\na\n \u0012\nx\nkvk\n\u0013\u0000a\ne\u0000x=kvk\u0000\nZ\nR+\n1(x;+\u00a5)(wkvk)\ne\u0000w\nwa\ndw\n!\n1C\n\u0012\nv\nkvk\n\u0013\nr(dv)\n=\nZ\nRd0\nZ\nR+\n1(x;+\u00a5)(wkvk)\nx\u0000a \u0000 (wkvk)\u0000a\na\ne\u0000wdw1C\n\u0012\nv\nkvk\n\u0013\nkvkar(dv)\n=\nZ\nRd0\nZ\nR+\nZ 1\n0\n1(x;+\u00a5)\n\u0010\nwu1=akvk\n\u0011 ma;r\na\nx\u0000adue\u0000wdw1C\n\u0012\nv\nkvk\n\u0013er(dv) (3.12)\n=\nZ\nRd0\nZ\nR+\nZ 1\n0\nZ\nR+\n1(x;+\u00a5)\n \u0012\nar\nma;r\n\u0013\u00001=a\n^wu1=akvk\n!\ndrdue\u0000wdw1C\n\u0012\nv\nkvk\n\u0013er(dv);\nwhere the fifth equality holds by\n1(x;+\u00a5) (wkvk)\n\"\n1\u0000\n\u0012\nwkvk\nx\n\u0013\u0000a#\n= Leb\n\"\n(0;1)\\\n \u0012\nwkvk\nx\n\u0013\u0000a\n;+\u00a5\n!#\n=\nZ 1\n0\n1\n\u0012\nu1=a >\nx\nwkvk\n\u0013\ndu;\nwhile the sixth equality holds by\n1(x;+\u00a5)\n\u0010\nwu1=akvk\n\u0011 ma;r\na\nx\u0000a = 1(x;+\u00a5)\n\u0010\nwu1=akvk\n\u0011Z\nR+\n1(x;+\u00a5)\n\"\u0012\nar\nma;r\n\u0013\u00001=a#\ndr\n=\nZ\nR+\n1(x;+\u00a5)\n\"\u0012\nar\nma;r\n\u0013\u00001=a\n^wu1=akvk\n#\ndr:\nBy applying the generalized shot noise method [6, 33], we get the desired series representation.\nTo prove the claim for fX2;ngn2N, consider the probability measure on Rd0 ,\nF1(B) =\nZ\nRd0\nZ\nR+\n1B\n\u0012\nr\nv\nkvk\n\u0013\nf (r;1;l=kvk)dr er(dv); B 2B(Rd0):\nThe Le\u00b4vy measure n is absolutely continuous with respect to F1 with Radon-Nykodym derivative\ndv\ndF1\n(r;v) = ma;r\nkvk\nl\ne\u0000(1\u0000l )r=kvk\nra+1\n; (r;v) 2 R+\u0002Rd0 :\nBy applying the thinning method [33], we get the desired representation. The proof for fX3;ngn2N is similar.\nConsider the probability measure\nF2(B) =\nZ\nRd0\nZ\nR+\n1B\n\u0012\nr\nv\nkvk\n\u0013\nf (r;l1;l2=kvk)dr er(dv); B 2B(Rd0):\n8\nThe Le\u00b4vy measure n is absolutely continuous with respect to F2 with Radon-Nykodym derivative\ndv\ndF2\n(r;v) = ma;rG(l1)\n\u0012kvk\nl2\n\u0013l1 e\u0000(1\u0000l2)r=kvk\nra+l1\n; (r;v) 2 R+\u0002Rd0:\nTo prove the claim for fX4;ngn2N, consider the Le\u00b4vy measure\nn(s)(B) =\nZ\nRd0\nZ\nR+\n1B(rv)\n1\nra+1\ndrr(dv); B 2B(Rd0);\nwhich is a non-tempered counterpart of the tempered stable Le\u00b4vy measure n . By a simple change of vari-\nables, we have for each B 2B(Rd0),\nn(B) =\nZ\nRd0\nZ\nR+\n1B\n\u0012\nr\nv\nkvk\n\u0013\ne\u0000r=kvk\nra+1\ndrma;r er(dv);\nn(s)(B) =\nZ\nRd0\nZ\nR+\n1B\n\u0012\nr\nv\nkvk\n\u0013\n1\nra+1\ndrma;r er(dv);\nwhich implies that the Le\u00b4vy measure n(s) is of a stable law. It is well known that through the inverse Le\u00b4vy\nmeasure method [13, 27], a stable law induced by the Le\u00b4vy measure n(s) admits a series representation with\nthe kernel H(s)(r)v=kvk. Clearly, the Le\u00b4vy measure n is absolutely continuous with respect to n(s) with\nRadon-Nykodym derivative\ndv\ndv(s)\n(r;v) = e\u0000r=kvk; (r;v) 2 R+\u0002Rd0 :\nBy applying the rejection method of Rosin\u00b4ski [33], we get the desired series representation.\nFor fX5;ngn2N, it is clear that the kernel H5(r;v) corresponds to the inverse Le\u00b4vy measure method.\nFinally, we prove the infinite divisibility of L (Xk;n). The truncation scheme fk 2 N : Gk \u0014 ng corre-\nsponds to the truncation to (0;n) of the integral with respect to the variable r in each decomposition of Le\u00b4vy\nmeasure. It is then clear that for k= 1;2;3;4;5, n 2N and B 2B(Rd0), nk;n(B)\u0014 n(B). Hence, the measure\nnk;n is well defined as a Le\u00b4vy measure.\n(ii) All the representations nk;n are based on the generalized shot noise method due to (2.7). Therefore, by\nsetting B=Rd0 and truncating the integral with respect to the Lebesgue measure dr to the interval (0;n), we\nget the result.\n(iii) Due to the truncation by fk 2 N : Gk \u0014 ng, it holds that for each k = 1;2;3;4;5, and n 2 N, the random\nvector Xk;n has the infinitely divisible law with triplet (0;0;nk;n), such that for each B 2B(Rd0),\nn1;n(B) =\nZ\nRd0\nZ n\n0\nZ\nR+\nZ 1\n0\n1B\n \"\u0012\nar\nma;r\n\u0013\u00001=a\n^wu1=akvk\n#\nv\nkvk\n!\ndue\u0000wdwdr er(dv);\nn2;n(B) =\nZ\nRd0\nZ n\n0\nZ\nR+\n1B\n \nw1\n \nma;r\nkvk\nl\ne\u0000\n1\u0000l\nkvk w\nwa+1\n> r\n!\nv\nkvk\n!\nf (w;1;l=kvk)dwdr er(dv);\nn3;n(B) =\nZ\nRd0\nZ n\n0\nZ\nR+\n1B\n0@w1\n0@ma;rG(l1)\u0012kvkl2\n\u0013l1 e\u0000 1\u0000l2kvk w\nwa+l1\n> r\n1A v\nkvk\n1A\n\u0002 f (w;l1;l2=kvk)dwdr er(dv);\nn4;n(B) =\nZ\nRd0\nZ n\n0\nZ 1\n0\n1B\n \u0012\nar\nma;r\n\u0013\u00001=a\n1\n \ne\u0000\n1\nkvk\n\u0010\nar\nma;r\n\u0011\u00001=a\n> u\n!\nv\nkvk\n!\ndudr er(dv);\nn5;n(B) =\nZ\nRd0\nZ n\n0\n1B\n\u0012\nH5(r;v)\nv\nkvk\n\u0013\ndr er(dv):\n9\nTo prove (3.6), it suffices to observe that\nZ n\n0\n1(x;+\u00a5)\n \u0012\nar\nma;r\n\u0013\u00001=a\n^wu1=akvk\n!\ndr\n= 1(x;+\u00a5)\n\u0010\nwu1=akvk\n\u0011\nLeb\n (\nr 2 (0;n) :\n\u0012\nar\nma ;r\n\u0013\u00001=a\n> x\n)!\n= 1(x;+\u00a5)\n\u0010\nwu1=akvk\n\u0011\u0010\nn^ ma;r\na\nx\u0000a\n\u0011\n;\nwhich yields the first result with the help of (3.12). Second, to prove (3.7), observe that\nn4;n((x;+\u00a5)C)\n=\nZ\nRd0\nZ n\n0\nZ 1\n0\n1\n \ne\u0000\n1\nkvk\n\u0010\nar\nma;r\n\u0011\u00001=a\n> u\n!\n1(x;+\u00a5)\n \u0012\nar\nma;r\n\u0013\u00001=a!\ndudr1C\n\u0012\nv\nkvk\n\u0013er(dv)\n=\nZ\nRd0\nZ n^ma;ra x\u0000a\n0\ne\u0000\n1\nkvk\n\u0010\nar\nma;r\n\u0011\u00001=a\ndr1C\n\u0012\nv\nkvk\n\u0013er(dv)\n=\nZ\nRd0\nZ +\u00a5\nx_\n\u0010\nan\nma;r\n\u0011\u00001=a ma;r e\u0000r=kvkra+1 dr1C\n\u0012\nv\nkvk\n\u0013er(dv) (3.13)\n=\nZ\nRd0\n\"\u0012Z n\n0\ne\u0000H(s)(r)=kvkdr\n\u0013\n^\nZ +\u00a5\nx\nma;r\ne\u0000r=kvk\nra+1\ndr\n#\n1C\n\u0012\nv\nkvk\n\u0013er(dv)\n\u0014\nZ\nRd0\n\"\nn^\nZ +\u00a5\nx\nma;r\ne\u0000r=kvk\nra+1\ndr\n#\n1C\n\u0012\nv\nkvk\n\u0013er(dv): (3.14)\nThe claim (3.7) follows from (3.13). Moreover, the inequality (3.8) holds for n4;n by (3.14) since by the\ndefinition of the kernel H5(r;v), we have\nn5;n((x;+\u00a5)C) =\nZ\nRd0\n\"\nn^\nZ +\u00a5\nx\nma;r\ne\u0000r=kvk\nra+1\ndr\n#\n1C\n\u0012\nv\nkvk\n\u0013er(dv): (3.15)\nFor n1;n, it holds by (3.6) and (3.12) that\nn1;n ((x;+\u00a5)C) =\nZ\nRd0\n \nnaxa\nZ +\u00a5\nx\ne\u0000r=kvk\nra+1\ndr^\nZ +\u00a5\nx\nma;r\ne\u0000r=kvk\nra+1\ndr\n!\n1C\n\u0012\nv\nkvk\n\u0013er(dv)\n\u0014\nZ\nRd0\n \nnaxa\nZ +\u00a5\nx\n1\nra+1\ndr^\nZ +\u00a5\nx\nma ;r\ne\u0000r=kvk\nra+1\ndr\n!\n1C\n\u0012\nv\nkvk\n\u0013er(dv)\n= n5;n ((x;+\u00a5)C) :\nFinally, we prove the claim (3.8) for n2;n and n3;n. Those decompositions are due to the thinning method. Let\nfF(\u0001;v)gv2Rd0 be a measurable family of probability measures on R+ such that for each v 2 R\nd\n0 , the support\nof F(\u0001;v) is R+. Since for v 2 Rd0 , the measure ma;re\u0000w=kvk=wa+1dw on R+ is absolutely continuous\nwith respect to F(dw;v), the Radon-Nykodym derivative is well defined, for which we will write G(w;v),\n10\n(w;v) 2 R+\u0002Rd0 . Then, it holds that for each x 2 R+ andC 2B(Sd\u00001),Z\nRd0\nZ\nR+\nZ n\n0\n1(G(w;v)> r)dr1(x;+\u00a5)(w)F(dw;v)1C\n\u0012\nv\nkvk\n\u0013er(dv)\n=\nZ\nRd0\nZ +\u00a5\nx\n[n^G(w;v)]F(dw;v)1C\n\u0012\nv\nkvk\n\u0013er(dv)\n\u0014\nZ\nRd0\n\"\nn^\nZ +\u00a5\nx\nma;r\ne\u0000r=kvk\nra+1\ndr\n#\n1C\n\u0012\nv\nkvk\n\u0013er(dv) = n5;n((x;+\u00a5)C);\nwhere the inequality holds by the Jensen inequality for the concave function [n^ \u0001] and by for each x 2 R+\nand v 2 Rd0 , F((x;+\u00a5);v)\u0014 1.\n(iv) Observe that\n(n5;n\u0000nk;n)((x;+\u00a5)C)\u0015 (nk;n\u0000n5;n)((0;x)C);\nwhich follows from (ii) and (iii). It holds by this inequality that for each x 2 R+,Z\n(x;+\u00a5)C\nkzkq (n5;n\u0000nk;n)(dz)> xq (n5;n\u0000nk;n)((x;+\u00a5)C) (3.16)\n\u0015 xq (nk;n\u0000n5;n)((0;x)C)\n=\nZ\n(0;x)C\nxq (nk;n\u0000n5;n)(dz)>\nZ\n(0;x)C\nkzkq (nk;n\u0000n5;n)(dz):\nNote that the strict inequalities hold since we have assumed the Le\u00b4vy measure has no atoms. (In particular,\nthe both hand sides in (3.16) tend to get far apart for a higher q.) Hence, it holds that for each x 2 R+,Z\nRd0\nkzkqnk;n(dz) =\nZ\n(0;x)C\nkzkqnk;n(dz)\u0000\nZ\n(x;+\u00a5)C\nkzkq (n5;n\u0000nk;n)(dz)+\nZ\n(x;+\u00a5)C\nkzkqn5;n(dz)\n\u0014\nZ\n(0;x)C\nkzkqnk;n(dz)\u0000\nZ\n(0;x)C\nkzkq (nk;n\u0000n5;n)(dz)+\nZ\n(x;+\u00a5)C\nkzkqn5;n(dz)\n=\nZ\nRd0\nkzkqn5;n(dz):\nThe proof is complete.\nThe following corollary provides further useful insight into the way the rejection and the inverse Le\u00b4vy\nmeasure methods simulate tails of Le\u00b4vy measure. The simplification imposed in (i) is not very restrictive\nand indeed covers most settings of practical interest.\nCorollary 3.2. Consider the same setting of Theorem 3.1.\n(i) If there exists c 2R+ such that r(fv 2Rd0 : kvk= cg) = 1, then it holds that for each n 2N and x 2R+,\nn5;n\n\u0010\n(x;+\u00a5)Sd\u00001\n\u0011\n= n^n\n\u0010\n(x;+\u00a5)Sd\u00001\n\u0011\n:\n(ii) It holds that for x 2 R+,\nn4;n\n\u0010\n(x;+\u00a5)Sd\u00001\n\u0011\n\u0018 n^n\n\u0010\n(x;+\u00a5)Sd\u00001\n\u0011\n; n \"+\u00a5:\nProof. (i) This claim is trivial from the representation (3.15).\n11\n(ii) Observe that for each v 2 Rd0 , as n \"+\u00a5,Z +\u00a5\u0010\nan\nma;r\n\u0011\u00001=a ma;r e\u0000r=kvkra+1 dr =\nma;r\nkvka G\n \n\u0000a; 1kvk\n\u0012\nan\nma;r\n\u0013\u00001=a!\n\u0018 n;\nwhere we have used the well known asymptotics limx#0G(s;x)=xs = \u00001=s, with s < 0. This proves the\nclaim.\nTo close this section, let us present the tail probability asymptotics of the series. Interestingly, the\nfirst jumps of all the five different representations have the same tail probability asymptotics, although the\ncaptured tail mass differs for different representations under the same truncation scheme. For q 2 R+ and\nk 2 N, define\np1(q ; k) := P\n\u0010\nkH1\n\u0010\nGk;W\n(1)\nk ;Uk;Vk\n\u0011\nk> q\n\u0011\n;\np2(q ; k) := P\n\u0010\r\r\rH2\u0010Gk;W (2)k ;Vk\u0011\r\r\r> q\u0011 ;\np3(q ; k) := P\n\u0010\r\r\rH3\u0010Gk;W (3)k ;Vk\u0011\r\r\r> q\u0011 ;\np4(q ; k) := P(kH4(Gk;Uk;Vk)k> q) ;\np5(q ; k) := P(kH5 (Gk;Vk)k> q) :\nProposition 3.3. It holds that as q \"+\u00a5,\npn(q ; k)\u0018\nmk\u00001a;r\nG(k+1)ak\nZ\nRd0\nkvka e\n\u0000q=kvk\nq ka\nr(dv); n= 1;4; (3.17)\np2(q ; k)\u0018\nmk\u00001a;r\nG(k+1)l k\u00001(k+ ka\u00001)\nZ\nRd0\nkvka\u00001+k e\n\u0000(k\u0000(k\u00001)l )q=kvk\nq ka\u00001+k\nr(dv); (3.18)\np3(q ; k)\u0018 (ma;rG(l1))\nk\u00001\nG(k+1)l (k\u00001)l12\n1\nka+(k\u00001)l1\nZ\nRd0\nkvka+(k\u00001)l1 e\n\u0000(k\u0000(k\u00001)l2)q=kvk\nq ka+(k\u00001)l1\nr(dv); (3.19)\np5(q ; k)\u0018\nmk\u00001a;r\nG(k+1)ak\nZ\nRd0\nkvka e\n\u0000q=kvk\nq ka\nr(dv): (3.20)\nIn particular, it holds that for each k = 1; : : : ;5, as q \"+\u00a5,\npk(q ; 1)\u0018\nZ\nRd0\nkvka e\n\u0000q=kvk\naqa\nr(dv):\nProof. Throughout, we will use the notations (3.10) and (3.11) and the asymptotics; for b > 0 and k 2 N,Z +\u00a5\nx\ne\u0000r\nrb+1\ndr \u0018 e\n\u0000x\nbxb\n; as x \"+\u00a5; (3.21)\n1\nG(k)\nZ x\n0\nrk\u00001e\u0000rdr \u0018 x\nk\nG(k+1)\n; as x # 0: (3.22)\n12\nFirst, it holds by the independence of Gk,Wk andUk that\np1(q ;k) = P\n \u0012\naGk\nma;r\n\u0013\u00001=a\n> q\n!\nP\n\u0010\nW1U\n1=a\n1 kV1k> q\n\u0011\n=\nZ ma;r\naqa\n0\nf (y;k;1)dy\nZ\nRd0\nZ 1\n0\ne\u0000qu\n\u00001=a=kvkduer(dv)\n=\nZ ma;r\naqa\n0\nf (y;k;1)dy\naqa\nma;r\nZ\nRd0\nZ +\u00a5\nq=kvk\ne\u0000s\nsa+1\ndsr(dv)\n\u0018 m\nk\u00001\na;r\nG(k+1)ak\nZ\nRd0\nkvka e\n\u0000q=kvk\nq ka\nr(dv);\nas q \"+\u00a5, which yields the result (3.17) for n= 1. Next,\np2(q ;k) = P\n0@nW (2)1 > qo\\\n8<:Gk \u0014 ma;r kV1kl e\n\u0000 1\u0000lkvk W\n(2)\n1\n(W (2)1 )a+1\n9=;\n1A\n=\nZ\nRd0\nZ +\u00a5\nq\nZ ma;r kvkl e\u0000(1\u0000l )w=kvkwa+1\n0\nf (y;k;1)dy\nl\nkvke\n\u0000 lkvkwdwer(dv)\n\u0018 m\nk\u00001\na;r\nG(k+1)l k\u00001\nZ\nRd0\nZ +\u00a5\nq\ne\u0000k\n1\u0000l\nkvk w\nwk(a+1)\ne\u0000\nl\nkvkwdwkvkk+a\u00001r(dv)\n\u0018 m\nk\u00001\na;r\nG(k+1)l k\u00001(k+ ka\u00001)\nZ\nRd0\nkvka\u00001+k e\n\u0000(k\u0000(k\u00001)l )q=kvk\nq ka\u00001+k\nr(dv);\nwhich yields the result (3.18). Then,\np3(q ;k)\n= P\n0@nW (3)1 > qo\\\n8<:Gk \u0014 ma;rG(l1)\n\u0012kvk\nl2\n\u0013l1 e\u0000 1\u0000l2kV1kW (3)1\n(W (3)1 )a+l1\n9=;\n1A\n=\nZ\nRd0\nZ +\u00a5\nq\nZ ma;rG(l1)\u0010 kV1kl2 \u0011l1 e\u0000(1\u0000l2)w=kvkwa+l1\n0\nf (y;k;1)dy f (w;l1;l2=kvk)dw er(dv)\n\u0018 (ma ;rG(l1))\nk\u00001\nG(k+1)l (k\u00001)l12\n(k\u0000 (k\u00001)l2)ka+(k\u00001)l1\nZ\nRd0\nkvk(1\u0000k)a\nZ +\u00a5\nk\u0000(k\u00001)l2\nkvk q\ne\u0000s\nska+(k\u00001)l1+1\ndsr(dv)\n\u0018 (ma ;rG(l1))\nk\u00001\nG(k+1)l (k\u00001)l12\n1\nka+(k\u00001)l1\nZ\nRd0\nkvka+(k\u00001)l1 e\n\u0000(k\u0000(k\u00001)l2)q=kvk\nq ka+(k\u00001)l1\nr(dv);\n13\nas q \"+\u00a5, which yields the result (3.19). Next,\np4(q ;k) = P\n\u0010\b\nH(s)(Gk)> q\n\t\\ne\u0000H(s)(Gk)=kV1k >U1o\u0011\n=\nZ\nRd0\nZ ma;r\naqa\n0\ne\u0000H(s)(r)=kvk f (r;k;1)dr er(dv)\n=\nmk\u00001a;r\nG(k)ak\u00001\nZ\nRd0\nZ +\u00a5\nq=kvk\ns\u0000ak\u00001e\u0000s\u0000\n1\nkvka\nma;r\nasa dskvka(1\u0000k)r(dv)\n\u0018 m\nk\u00001\na;r\nG(k)ak\u00001\nZ\nRd0\nZ +\u00a5\nq=kvk\ns\u0000ak\u00001e\u0000sdskvka(1\u0000k)r(dv)\n\u0018 m\nk\u00001\na;r\nG(k+1)ak\nZ\nRd0\nkvka e\n\u0000q=kvk\nq ka\nr(dv);\nas q \"+\u00a5, which yields the result (3.17) for n4;n. Finally,\np5(q ;k) = P\n \nGk \u0014\nZ +\u00a5\nq\nma;r\ne\u0000s=kV1k\nsa+1\nds\n!\n=\nZ\nRd0\nZ R+\u00a5\nq ma;r s\n\u0000a\u00001e\u0000s=kvkds\n0\nf (y;k;1)dy er(dv)\n\u0018 1\nG(k+1)\nZ\nRd0\n\u0012Z +\u00a5\nq\nma;rs\u0000a\u00001e\u0000s=kvkds\n\u0013k er(dv)\n\u0018 m\nk\u00001\na;r\nG(k+1)ak\nZ\nRd0\nkvka e\n\u0000kq=kvk\nq ka\nr(dv);\nas q \"+\u00a5, which yields the result (3.20).\n4 Numerical Illustration\nConsider the spectrally positive tempered stable Le\u00b4vy measure\nn(dz) =\na2kk\nG(1\u0000k)\ne\u0000\n1\n2b\n1=k z\nzk+1\ndz; z 2 R+; (4.1)\nwhere a > 0, b \u0015 0 and k 2 (0;1). The associated Le\u00b4vy process fL(ts)t : t \u0015 0g (without drift) is called the\ntempered stable subordinator, with characteristic function\nE\nh\neiyL\n(ts)\nt\ni\n= exp\n\u0014\nt\nZ\nR+\n\u0000\neiyz\u00001\u0001n(dz)\u0015= exphta\u0010b\u0000\u0010b1=k \u00002iy\u0011k\u0011i : (4.2)\nIts moments can be derived in closed form. In particular, the first two are given by\nE\nh\nL(ts)T\ni\n= 2akb\nk\u00001\nk T; Var\n\u0010\nL(ts)T\n\u0011\n= 4ak(1\u0000k)b k\u00002k T: (4.3)\nThe formulation (4.1) is realized by setting a = k and r such that\nr(Rd0) = r\n\u0010n\n2b\u00001=k\no\u0011\n=\nabk\nG(1\u0000k) ;\n14\nin the definition (2.2). Note thatma;r = 2kak=G(1\u0000k). First, its marginal density function is known only in\nan infinite series representation except for the cases k = 1=2 and k = 1=3. The tempered stable subordinator\nwith k = 1=2 is called an inverse Gaussian process. The density function when k = 1=3 is very intricate\ndue to the presence of a Bessel function. (See [31].)\nHere, we compare the following four shot noise series representations;n\nL(ts)t : t 2 [0;T ]\no\nL\n=\n(\n+\u00a5\n\u00e5\nk=1\n\"\u0012\nG(1\u0000k)\na2k\nGk\nT\n\u0013\u00001=k\n^W\n(1)\nk U\n1=k\nk\nb1=k=2\n#\n1[0;t] (Tk) : t 2 [0;T ]\n)\n(4.4)\nL\n=\n(\n+\u00a5\n\u00e5\nk=1\nW (2)k 1\n \nGk\nT\n\u0014 ak2\nk+1b\u00001=k\nG(1\u0000k)(W (2)k )k+1\n!\n1[0;t] (Tk) : t 2 [0;T ]\n)\n(4.5)\nL\n=\n(\n+\u00a5\n\u00e5\nk=1\n\u0012\nG(1\u0000k)\na2k\nGk\nT\n\u0013\u00001=k\n1\n \ne\u0000\n1\n2 b\n1=k\n\u0010\nG(1\u0000k)\na2k\nGk\nT\n\u0011\u00001=k\n>Uk\n!\n1[0;t] (Tk) : t 2 [0;T ]\n)\n(4.6)\nL\n=\n(\n+\u00a5\n\u00e5\nk=1\nH5\n\u0012\nGk\nT\n;2b\u00001=k\n\u0013\n1[0;t] (Tk) : t 2 [0;T ]\n)\n: (4.7)\nRecall that fW (1)k gk2N is a sequence of iid standard exponential random variables, fUkgk2N is a sequence\nof iid uniform random variables on [0;1], fW (2)k gk2N is a sequence of iid exponential random variables\nwith rate b1=k=2, and fTkgk2N is a sequence of iid uniform random variables on [0;T ]. The kernel H5(r;v)\nis not available in closed form due to the incomplete gamma function. We employ a numerical approach\ndeveloped in [18] to obtain this kernel. (For the reader\u2019s convenience, we provide its brief description in\nAppendix A.) Note that the representation (4.5) can be recovered either from (3.2) with l = 1, or from (3.3)\nwith l1 = l2 = 1.\nFirst, we compare convergence of the representations (4.4)-(4.7) through estimation of E[L(ts)T ] and\nVar(L(ts)T ). Note that the random sequence fTkgk2N is not required for this experiment. (Let us remind\nthat series representations can be used for pathwise simulation purpose, not only for computation of expec-\ntations.) To avoid overloading the paper with exhaustive numerical results, we only provide results with the\nparameter setting (a; b; k; T ) = (10; 1:6; 0:2; 1:0).\nTo obtain a (nearly) complete estimator convergence, we generate a sufficiently large number N = 219(=\n524288) of iid (truncated) infinite sums on the right hand side of (4.4)-(4.7). We report relative error j(emn\u0000\nm)=mj in percentage where emn is a Monte Carlo estimate based on N iid replications and the finite truncation\nfk 2 N : Gk \u0014 ng for mn := E[emn] such that limn\"+\u00a5 mn = m . (Recall that the true value m is given by (4.3).)\nFirst of all, it is obvious from the results that the representation (4.7) provides an incomparably faster\nconvergence to the true value in the finite truncation fk 2 N : Gk \u0014 ng, than any other representations (4.4)-\n(4.6). Those results fairly support our theoretical results (3.8) and (3.9). It is particularly remarkable that the\nrepresentation (4.7) achieves a relative error of less than 1:00% with much smaller truncation. As indicated,\nthe difference becomes more evident for higher moments. (This is indeed obvious from the inequality\n(3.16).) On the one hand, the representation (4.5) converge at a fast rate when the truncation level n stays\nsmall, while slows down as n increases. The representation (4.6), on the other hand, does not behave well\nuntil a very large truncation. In particular, most indicators in (4.6) keep being rejected for small k\u2019s. It\nseems that the representations (4.4) and (4.6) exhibit a similar performance in terms of the number of terms\nrequired to reach a relative error of 1%.\nLet us close this section with discussing a further possible improvement through the applicability of\nlow-discrepancy sequences to the representations (4.4)-(4.7). As investigated in [17, 18], on the one hand, it\nis often effective to apply a suitable low-discrepancy sequence to the interarrival exponential times fEkgk2N\n15\nE[L(ts)T ] Var(L\n(ts)\nT )\nMinimum Thinning Rejection Inversion Minimum Thinning Rejection Inversion\nTruncation (4.4) (4.5) (4.6) (4.7) (4.4) (4.5) (4.6) (4.7)\n1 94.78% 72.29% 100.00% 60.29% 92.85% 41.07% 100.00% 20.55%\n2 89.61% 56.57% 100.00% 43.79% 85.88% 21.85% 100.00% 9.53%\n3 84.37% 47.22% 100.00% 33.48% 78.56% 13.74% 100.00% 5.30%\n4 79.17% 41.05% 100.00% 26.39% 71.54% 10.32% 100.00% 3.25%\n5 73.95% 36.50% 100.00% 21.22% 64.32% 7.45% 100.00% 2.21%\n10 47.84% 24.73% 99.56% 8.62% 28.43% 3.22% 96.75% 0.82%\n15 24.42% 19.38% 57.93% 4.22% 5.36% 1.88% 18.73% 0.66%\n20 11.45% 16.27% 22.35% 2.33% 0.82% 1.49% 1.46% 0.63%\n25 5.68% 14.09% 9.61% 1.40% 0.17% 0.68% 0.17% 0.62%\n30 3.04% 12.66% 4.72% 0.89% 0.38% 1.30% 0.37% 0.62%\n50 0.44% 9.12% 0.61% 0.23% 0.09% 0.46% 0.28% 0.45%\n100 0.12% 5.71% 0.04% 0.00% 0.11% 0.06% 0.36% 0.05%\n150 0.02% 4.49% 0.15% 0.01% 0.02% 0.40% 0.36% 0.05%\n200 0.11% 3.64% 0.04% 0.02% 0.10% 0.28% 0.03% 0.05%\nTable 1: Relative errors in estimation of the mean E[L(ts)T ]' 6:104E-1 and the variance Var(L(ts)T )' 9:313E-\n2. The numbers \u201cTruncation\u201d indicate \u201cn\u201d in fk 2 N : Gk \u0014 ng.\nin (2.1) since a systematic generation of the lower dimension of the interarrival times tends to contribute\nto improvements in both precision and convergence when computing expectations from the nature of the\nshot noise series representation. On the other hand, it has also been found that the presence of additional\nrandom elements water down the effectiveness of a low-discrepancy sequence. We have observed from\nnumerical experiments that the representations (4.4)-(4.6) require so many additional random sequences that\nthe application of low-discrepancy sequences increases computing effort without improving the estimator\nefficiency at all. In addition, the uniformity of low-discrepancy sequences seems to be ruined even further\nby the indicator functions in the representations (4.5) and (4.6).\n5 Concluding Remarks\nTempered stable processes combine both the stable and Gaussian trends, which are two stylized features\noften seen together in time series of complex systems. They are widely used in various fields of application\nsuch as, mathematical finance, econometrics and mathematical biology. In particular, such stochastic pro-\ncesses correspond to the so-called truncated Levy flights in physics and econophysics. Infinite shot noise\nseries representation is the only exact simulation method for the tempered stable process with stability index\ngreater than or equal to one and has recently attracted attention for simulation use.\nIn this paper, we have derived series representations for the tempered stable laws through the thinning,\nrejection, and inverse Le\u00b4vy measure methods. Based upon our rigorous comparison among those represen-\ntations in terms of the tail mass of Le\u00b4vy measures which can be simulated under a common finite truncation\nscheme, the representation via the inverse Le\u00b4vy measure method achieves a much faster convergence in\ntruncation to the infinite sum than all the other representations. Our results are expected to assist simulation\nstudy of, for example, the financial time series.\nThe results of this paper may be applicable to related stochastic processes. In particular, tempered stable\nprocesses of rich flexibility can further be extented through fractionalization and their sample paths can also\nbe simulated through the infinite series representation, as investigated in Houdre\u00b4 and Kawai [21]. Due to\nadditional model flexibility, it is natural to expect a better fit of the model to the observed data, though\nfractionalization might cause a confusion related to multifractability as pointed out in Heyde and Sly [16].\n16\nWe conjecture that our theoretical analysis is at least implicative, though not necessarily directly applicable,\nto the series representation of such fractional processes.\nA Numerical Inverse Le\u00b4vy Measure Method\nAs observed in Section 3, the kernel H5(r;v) is not available in closed form, precluded by the incomplete gamma func-\ntion. To materialize the inverse Le\u00b4vy measure method for the numerical experiment of Section 4, we have employed\nan efficient numerical inversion method of [18]. In principle, it is a generalization of a numerical inversion method\nproposed in [11], for inversion of probability distribution functions. To employ the method of [11] in our framework,\nwe transform a Le\u00b4vy measure into a probability distribution function. To be more precise, consider the Le\u00b4vy measure\n(4.1) which was investigated in Section 4. This Le\u00b4vy measure is infinite, that is,\nZ +\u00a5\n0\na2kk\nG(1\u0000k)\ne\u0000\n1\n2 b\n1=k z\nzk+1\ndz=:\nZ +\u00a5\n0\nw(x)dx=+\u00a5:\nTo apply quadrature and interpolation techniques, we need to truncate the support R+ to a compact, yet sufficiently\nlarge, domain [xmin; xmax]\u001a R+. LetW (x) denote the cumulative Le\u00b4vy measure, that is,\nW (x) :=\nZ +\u00a5\nx\nw(z)dz;\nwhere the cumulation here runs down from the infinity rather than up the other way, to avoid explosion at the origin.\nFor convenience, we write wmin and wmax forW (xmin) andW (xmax), respectively, that is,\nwmax :=W (xmax) =\nZ +\u00a5\nxmax\nw(z)dz; wmin :=W (xmin) =\nZ +\u00a5\nxmin\nw(z)dz:\nNote that wmax < wmin. To this end, we define functions F : R+ ! [0;1] and f : R+ ! R+[f0g by\nF(x) :=\n8><>:\n0; if x 2 (0; xmin);\nwmin\u0000W (x)\nwmin\u0000wmax ; if x 2 [xmin; xmax];\n1; if x 2 (xmax;+\u00a5);\nf (x) :=\n8><>:\n0; if x 2 (0; xmin);\nw(x)\nwmin\u0000wmax ; if x 2 [xmin; xmax];\n0; if x 2 (xmax;+\u00a5):\n(A.1)\nwhich act, respectively, as a cumulative distribution function and a probability density function in the method of [11].\nIn principle, the method of [11] can then be applied to the standardized cumulative Le\u00b4vy measure F(x) in (A.1).\nNow, the method of [11] consists of two components; the initial setup phase and the actual execution phase. In\nthe initial setup phase, the compact domain [xmin; xmax] is adaptively divided into disjoint subintervals on the basis\nof approximation error in F(x) produced by the Newton interpolation. This division should be conducted with great\ncare, as in the actual execution phase, we only obtain an approximation of F\u00001(u) for each sample u 2 (0;1) by\nthe Newton interpolation based on the information f(xk;F(xk))gk2N of nodes stored during the initial setup phase, in\norder to reduce a large amount of computational burden. In our framework, a further extra attention should be paid to\ncomputation of F(x) near the origin because it necessarily has a steep peak there. For this reason, the lower truncation\nxmin has to be chosen very carefully and some safety devices should be employed in algorithms to avoid undesired\nfailures caused by this. The actual execution is enhanced by employing an indexed search algorithm, rather than\nvery inefficient ordinary sequential or binary search, when searching an appropriate subinterval in which the sample\nvalue sits. It is claimed in [18] based on numerical experiments that computational effort for this numerical inversion\nmethod is relatively small compared to overall simulation. For example, in numerical experiments of Section 4, we\nset xmin =1.0E-7 and xmax = 10:0, and then wmin ' 34:2662 and wmax ' 0:0000. The initial setup phase divided the\ncompact domain [xmin; xmax] into 1753 subintervals and only required 0.344 second.\nThis numerical method requires a certain amount of initial work for its implementation, while it has the potential\nto provide significant improvements in simulation accuracy and estimator efficiency, as observed in Section 4. Equally\nimportant is that this numerical method is model-free and thus requires no adjustment to different Le\u00b4vy measures for\ndifferent problems.\n17\nReferences\n[1] Asmussen, S., Glynn, P.W. (2007) Stochastic Simulation: Algorithms and Analysis, Springer, New York.\n[2] Asmussen, S., Rosin\u00b4ski, J. (2001) Approximations of small jumps of Le\u00b4vy processes with a view towards simulation, Journal\nof Applied Probability, 38(2) 482-493.\n[3] Baeumer, B., Meerschaert, M.M. (2009) Tempered stable Le\u00b4vy motion and transit super-diffusion, Journal of Computational\nand Applied Mathematics, 223(10) 2438-2448.\n[4] Barndorff-Nielsen, O.E., Shephard, N. (2001) Non-Gaussian Ornstein-Uhlenbeck-based models and some of their uses in\nfinancial economics (with discussion), J. R. Statist. Soc. B, 63(2) 167-241.\n[5] Benth, F.E., Gorth, M., Kufakunesu, R. (2007) Valuing volatility and variance swaps for a non-Gaussian Ornstein-Uhlenbeck\nstochastic volatility model, Applied Mathematical Finance, 14(4) 347-363.\n[6] Bondesson, L. (1982) On simulation from infinitely divisible distributions, Advances in Applied Probability, 14(4) 855-869.\n[7] Carr, P., Geman, H., Madan, D.B., Yor, M. (2002) The fine structure of asset returns: An empirical investigation, Journal of\nBusiness, 75, 303-325.\n[8] Carr, P., Geman, H., Madan, D.B., Yor, M. (2003) Stochastic volatility for Le\u00b4vy processes, Mathematical Finance, 13,\n345-382.\n[9] Chambers, J.M., Mallows, C.L., Stuck, B.W. (1976) A method for simulating stable random variables, Journal of the Amer-\nican Statistical Association, 71(354) 340-344.\n[10] Cohen, S., Rosin\u00b4ski, J. (2007) Gaussian approximation of multivariate Le\u00b4vy processes with applications to simulation of\ntempered stable processes, Bernoulli, 13(1) 195-210.\n[11] Derflinger, G., Ho\u00a8rmann, W., Leydold, J. (2009) Random variate generation by numerical inversion when only the density\nis known, ACM Transactions on Modeling and Computer Simulation, 20(4) Article 18.\n[12] Devroye, L. (2009) Random variate generation for exponentially and polynomially tilted stable distributions, ACM Transac-\ntions on Modeling and Computer Simulation, 19(4) Article 18.\n[13] Ferguson, T.S., Klass, M.J. (1972) A representation of independent increment processes with Gaussian components, Annals\nof Mathematical Statistics, 43(5) 1634-1643.\n[14] Figueiredo, A., Gleria, I., Matsushita, R., Da Silva, S. (2003) On the origins of truncated Le\u00b4vy flights, Physics Letters A,\n315(1-2) 51-60.\n[15] Gupta, H.M., Campanha, J.R. (1999) The gradually truncated Le\u00b4vy flight for systems with power-law distributions, Physica\nA, 268, 231-239.\n[16] Heyde, C.C., Sly, A. (2008) A cautionary note on modeling with fractional Le\u00b4vy flights, Physica A, 387(21) 5024-5032.\n[17] Imai, J., Kawai, R. (2010) Quasi-Monte Carlo methods for infinitely divisible random vectors via series representations,\nSIAM Journal on Scientific Computing, 32(4) 1879-1897.\n[18] Imai, J., Kawai, R., Numerical inverse Le\u00b4vy measure method for infinite shot noise series representation, preprint.\n[19] Imai, J., Kawai, R., On Monte Carlo and quasi-Monte Carlo methods for series representation of infinitely divisible laws,\nMonte Carlo and Quasi-Monte Carlo Methods 2010, H. Wozniakowski, L. Plaskota (Eds.) Springer-Verlag, forthcoming.\n[20] Kawai, R. (2006) An importance sampling method based on the density transformation of Le\u00b4vy processes, Monte Carlo\nMethods and Applications, 12(2) 171-186.\n[21] Houdre\u00b4, C., Kawai, R. (2006) On fractional tempered stable motion, Stochastic Processes and their Applications, 116(8)\n1161-1184.\n[22] Kawai, R., Takeuchi, A., Computation of Greeks for asset price dynamics driven by stable and tempered stable processes,\nQuantitative Finance, doi:10.1080\/14697688.2011.589403.\n[23] Kawai, R., Masuda, H. (2011) Exact discrete sampling of finite variation tempered stable Ornstein-Uhlenbeck processes,\nMonte Carlo Methods and Applications, 17(3) 279-300.\n[24] Kawai, R., Masuda, H. (2012) Infinite variation tempered stable Ornstein-Uhlenbeck processes with discrete observations,\nCommunications in Statistics - Simulation and Computation, 41(1) 125-139.\n[25] Kawai, R., Masuda, H. (2011) On simulation of tempered stable random variates, Journal of Computational and Applied\nMathematics, 235(8) 2873-2887.\n[26] Koponen, I. (1995) Analytic approach to the problem of convergence of truncated Le\u00b4vy flights towards the Gaussian stochas-\ntic process, Physical Review E, 52, 1197-1199.\n18\n[27] LePage, R. (1980) Multidimensional infinitely divisible variables and processes II, In: Lecture Notes in Mathematics 860,\nSpringer-Verlag, Berlin, New York, Heidelberg, 279-284.\n[28] Mantegna, R.N., Stanley, H.E. (1994) Stochastic process with ultraslow convergence to a Gaussian: The truncated Le\u00b4vy\nflights, Physical Review Letters, 73, 2946-2949.\n[29] Matsushita, R., Rathie, P., Da Silva, S. (2003) Exponentially damped Le\u00b4vy flights, Physica A, 326, 544-555.\n[30] Nakao, H. (2000) Multi-scaling properties of truncated Le\u00b4vy flights, Phys. Lett. A, 266, 282-289.\n[31] Palmer, K.J., Ridout, M.S., Morgan, B.J.T. (2008) Modelling cell generation times by using the tempered stable distribution,\nJournal of the Royal Statistical Society: Series C (Applied Statistics), 57(4) 379-397.\n[32] Podobnik, B., Ivanov, P.Ch., Lee, Y., Stanley, H.E. (2000) Scale-invariant truncated Le\u00b4vy process, Europhysics Letters, 52(5)\n491.\n[33] Rosin\u00b4ski, J. (2001) Series representations of Le\u00b4vy processes from the perspective of point processes, In: Le\u00b4vy Processes -\nTheory and Applications, Eds. Barndorff-Nielsen, O.-E., Mikosch, T., Resnick, S.I., Birkha\u00a8user, 401-415.\n[34] Rosin\u00b4ski, J. (2007) Tempering stable processes, Stochastic Processes and their Applications, 117(6) 677-707.\n[35] Sato, K. (1999) Le\u00b4vy processes and infinitely divisible distributions, Cambridge University Press.\n[36] Tweedie, M.C.K. (1984) An index which distinguishes between some important exponential families, In: Statistics: Appli-\ncations and New Directions: Proc. Indian Statistical Institute Golden Jubilee International Conference (eds. J. Ghosh and J.\nRoy) 579-604.\n[37] Vinogradov, D.V. (2010) Cumulant approach of arbitrary truncated Levy flight, Physica A, 389(24) 5794-5800.\n19\n"}
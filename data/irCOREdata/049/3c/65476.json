{"doi":"10.1016\/S0004-3702(03)00014-6","coreId":"65476","oai":"oai:dro.dur.ac.uk.OAI2:5736","identifiers":["oai:dro.dur.ac.uk.OAI2:5736","10.1016\/S0004-3702(03)00014-6"],"title":"The complexity of achievement and maintenance problems in agent-based systems.","authors":["Stewart,  I. A."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2003-06-01","abstract":"We completely classify the computational complexity of the basic achievement and maintenance agent design problems in bounded environments when these problems are parameterized by the number of environment states and the number of agent actions. The different problems are P-complete, NP-complete, co-NP-complete or PSPACE-complete (when they are not trivial). We also consider alternative achievement and maintenance agent design problems by allowing longer runs in environments (that is, our environments are bounded but the bounds are more liberal than was the case previously). Again, we obtain a complete classification but so that the different problems are DEXPTIME-complete, NEXPTIME-complete, co-NEXPTIME-complete or NEXPSPACE-complete (when they are not trivial)","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65476.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/5736\/1\/5736.pdf","pdfHashValue":"11a3183c15cb4e635f80a7c2848583bb2981b9d6","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:5736<\/identifier><datestamp>\n      2011-11-10T11:02:21Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        The complexity of achievement and maintenance problems in agent-based systems.<\/dc:title><dc:creator>\n        Stewart,  I. A.<\/dc:creator><dc:description>\n        We completely classify the computational complexity of the basic achievement and maintenance agent design problems in bounded environments when these problems are parameterized by the number of environment states and the number of agent actions. The different problems are P-complete, NP-complete, co-NP-complete or PSPACE-complete (when they are not trivial). We also consider alternative achievement and maintenance agent design problems by allowing longer runs in environments (that is, our environments are bounded but the bounds are more liberal than was the case previously). Again, we obtain a complete classification but so that the different problems are DEXPTIME-complete, NEXPTIME-complete, co-NEXPTIME-complete or NEXPSPACE-complete (when they are not trivial).<\/dc:description><dc:subject>\n        Computational complexity<\/dc:subject><dc:subject>\n         Agent computing.<\/dc:subject><dc:publisher>\n        Elsevier<\/dc:publisher><dc:source>\n        Artificial intelligence, 2003, Vol.146(2), pp.175-191 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2003-06-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:5736<\/dc:identifier><dc:identifier>\n        issn:0004-3702<\/dc:identifier><dc:identifier>\n        doi:10.1016\/S0004-3702(03)00014-6<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/5736\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1016\/S0004-3702(03)00014-6<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/5736\/1\/5736.pdf<\/dc:identifier><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0004-3702","0004-3702"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2003,"topics":["Computational complexity","Agent computing."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n25 August 2009\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nStewart, I. A. (2003) \u2019The complexity of achievement and maintenance problems in agent-based systems.\u2019,\nArtificial intelligence., 146 (2). pp. 175-191.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1016\/S0004-3702(03)00014-6\nPublisher\u2019s copyright statement:\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n,  \n \nDurham Research Online \n \nDeposited in DRO: \n24 August 2009 \n \nPeer-review status: \nPeer-reviewed \n \nPublication status of attached file: \nAccepted for publication \n \nCitation for published item: \nStewart, I. A. (2003) 'The complexity of achievement and maintenance problems in agent-\nbased systems.', Artificial intelligence., 146 (2). pp. 175-191. \n \nFurther information on publisher\u2019s website: \nhttp:\/\/dx.doi.org\/10.1016\/S0004-3702(03)00014-6 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nUse policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior \npermission or charge, for personal research or study, educational, or not-for-profit purposes provided that : \n \n\uf0a7 a full bibliographic reference is made to the original source \n\uf0a7 a link is made to the metadata record in DRO \n\uf0a7 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders. \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nThe complexity of achievement and maintenance\nproblems in agent-based systems\nIain A. Stewart\u2217,\nDepartment of Computer Science,\nUniversity of Durham, Durham DH1 3LE, U.K.\nAbstract\nWe completely classify the computational complexity of the basic achievement and main-\ntenance agent design problems in bounded environments when these problems are parame-\nterized by the number of environment states and the number of agent actions. The differ-\nent problems are P-complete, NP-complete, co-NP-complete or PSPACE-complete (when\nthey are not trivial). We also consider alternative achievement and maintenance agent design\nproblems by allowing longer runs in environments (that is, our environments are bounded\nbut the bounds are more liberal than was the case previously). Again, we obtain a complete\nclassification but so that the different problems areDEXPTIME-complete, NEXPTIME-\ncomplete, co-NEXPTIME-complete or NEXPSPACE-complete (when they are not triv-\nial).\n1 Introduction\nAgent-based systems have been the subject of much research in artificial intelligence\nand computer science (see, for example, [21]). However, the computational complexity\nof basic agent-environment problems has not been seriously considered; although, it\nhas to be said, a number of similar and related problems in areas such as planning,\nmodel checking and Petri nets have been extensively studied. Examples from planning\ninclude: the basic planning problem, that is, the problem of deciding whether a\ngiven instance of the propositional STRIPS planning problem has a solution, i.e.,\na plan, which was proven to be PSPACE-complete [4]; a whole range of planning\nproblems in probabilistic planning domains [15]; planning problems in the presence\nof incompleteness [2]; and planning problems with temporal goals [3] (the reader\nis also referred to the survey paper [5]). Examples from model checking and Petri\nnets include: the problem of model checking with respect to Kripke structures and\nlinear temporal logic, LTL, which was proven to be PSPACE-complete [17]; and\nthe problems of model checking with respect to 1-safe Petri nets and both LTL and\ncomputation tree logic, CTL, which was proven to be PSPACE-complete [13] (the\nreader is referred to the survey papers [9] and [10]).\n\u2217Most of this work was completed whilst the author was at the University of Leicester.\n1\nThe only complexity-theoretic considerations of agent-environment problems so far\nare those due to Dunne and Wooldridge who study: the basic achievement and main-\ntenance agent design problems [18]; more sophisticated achievement and maintenance\nagent design problems [20, 8]; and the basic agent verification problem [7]. As might\nbe expected (given complexity results from planning, model checking and Petri nets),\nthese basic agent-environment problems turn out to be PSPACE-complete. The es-\nsential differences between agent-environment problems and many similar problems\nin, for example, planning, model checking and Petri nets are that the evolution of an\nagent-environment interaction is history-dependent (and not just state-dependent)\nand the environment can behave non-deterministically. Agent-environment interac-\ntions can be interpreted as games between two players where one player, the agent, is\nusually attempting to achieve or maintain some property whilst the other player, the\nenvironment, is attempting to make life as difficult as possible for the agent. Basic\nagent-environment problems amount to asking the question of whether the agent has\na winning strategy for the particular game.\nIn this paper, we refine the analysis in [18] so as to completely classify the achieve-\nment and maintenance agent design problems when these problems are parameterized\nby the number of environment states and the number of agent actions (the con-\nstructions in [18] are not sophisticated enough for us to be able to ascertain these\nresults). In order to exhibit our classification, we work with alternating Turing ma-\nchines (ATMs) and derive complexity-theoretic completeness results from first princi-\nples (that is, instead of working with known complete problems for some complexity\nclass, we encode \u2018raw\u2019 machine computations as instances of our problems). Focussing\non ATMs allows us to apply control to our parameters and is entirely natural. By this\nlatter remark, we mean that the fact that states of an ATM can alternate between\n\u2018existential\u2019 states and \u2018universal\u2019 states enables us to encode ATM computations as\nagent-environment interactions (or games). It is generally the case that \u2018first princi-\nples\u2019 proofs are rare in the related literature in planning, model checking and Petri\nnets but given our wish to focus on additional parameters, they appear to be necessary\nin our circumstances.\nOur basic achievement agent design problem is formulated using the notion of a\nbounded environment. Intuitively, such bounded environments correspond to an agent\nhaving to achieve some state of affairs \u2018quickly\u2019. One can also consider maintenance\nagent design in such bounded environments but a more relevant formulation of the\nmaintenance agent design problem is in a bounded environment where the bound\nis interpreted more liberally, so that agents must sustain some state of affairs for\na \u2018longer\u2019 period (having an agent sustain some state of affairs indefinitely leads to\nundecidable problems). Our reasoning here is that maintenance problems tend to be\nconcerned with ensuring \u2018something doesn\u2019t happen\u2019 over a significantly long period.\nWe prove that restricting the number of states and actions in agent-based systems\nleads: to achievement agent design problems that are P-complete, NP-complete, co-\nNP-complete and PSPACE-complete; and to maintenance agent design problems\n(where the bound on the length of runs within an environment is exponentially longer\nthan in the achievement agent design problem) that are DEXPTIME-complete,\nNEXPTIME-complete, co-NEXPTIME-complete and NEXPSPACE-complete.\nOur results should be of some interest to practitioners as they show that even if\nwe drastically reduce the numbers of states and actions in agent-based systems, most\n2\nof the basic achievement and maintenance design problems remain (very) intractable.\nAs regards complexity-theoretic bounds such as those mentioned above, it should be\nnoted that the fact that a problem is NP-complete essentially means that general\ninstances of the problem cannot be solved in practice, even when the size of the\ninstance is not particularly large. Nevertheless, there do exist heuristic methods for\ncertain NP-complete problems (such as SAT solvers) which cope pretty well with\nquite sizeable instances arising in practice. However, a problem that is PSPACE-\ncomplete, NEXPTIME-complete or NEXPSPACE-complete can be interpreted\nas being \u2018exponentially harder\u2019 than NP-complete problems and, as such, out of the\nreach of such heuristic methods.\n2 Agents and Environments\nIn this section, we detail a formal model for the analysis of environments and agents\n(the reader is referred to [19] for additional details). Essentially, we deal with finite-\nstate systems consisting of an environment and an agent, whereby the agent interacts\nwith the environment by performing actions, and the resulting actions change the\nstate of the environment.\nAn environment ENV is given by:\n\u2022 a finite set E of states and an initial state e0 \u2208 E;\n\u2022 a finite set A of actions; and\n\u2022 a state transformer function \u03c4 presented in the form of a polynomial-time de-\nterministic Turing machine.\n(In practice, we might think of both E and A as finite initial segments of natural\nnumbers, with e0 as 0.) The size of an environment ENV = (e0, E,A, \u03c4) is |E| +\n|A|+ |\u03c4 |, where |\u03c4 | is the length of a reasonable encoding of the given Turing machine\n\u03c4 (we often use \u03c4 to denote the state transformer function and a polynomial-time\ndeterministic Turing machine computing this function). It will always be the case\nthat any environment is in a specific state (from E), and depending upon which action\nis chosen by an agent and also the history of the interaction between the environment\nand the agent, the Turing machine \u03c4 will compute the set of possible next states of\nthe environment. Hence, \u03c4 can be viewed as (the description of) a polynomial-time\ncomputable function which takes an interaction history (that is, a sequence of states\nand actions, starting with the state e0, alternating between a state and an action,\nand ending with a state) and an action as input and yields a set of states as output.\nAssociated with an environment is the set of potential runs P defined as (the regular\nset) {e0}(AE)\u2217 (where A and E are the sets of actions and states), i.e., the set of\nfinite tuples whose first component is e0 and thereafter components alternate between\nactions and states so that the final component is a state. The length of any potential\nrun is the number of actions therein, i.e., if the tuple has 2n + 1 components then\nthe length of the tuple is n. However, not every potential run will be a legitimate\nrun: the legitimate runs will only be those permitted according to the interaction of\nan agent with the environment.\n3\nAn agent AG acts within an environment according to a given agent strategy\nfunction \u03c3 : P \u2192 A \u222a {\u0004}, where \u0004 is a new symbol hitherto unused. The set R of\nlegitimate runs of the agent-based system \u3008ENV ,AG\u3009 is defined inductively as follows:\n\u2022 (e0) is a legitimate run; and\n\u2022 if \u03c1 is a legitimate run, \u03c3(\u03c1) = a \u2208 A and e \u2208 \u03c4(\u03c1, a) then (\u03c1, a, e) is a legitimate\nrun\n(where (\u03c1, a, e) denotes the concatenation of a and e onto the tuple \u03c1). Note how\n\u03c4 is used as a function which, given a legitimate run and an action, computes the\nset of possible next states into which the environment can evolve (and so the state-\ntransformer function is history-dependent). Note also that whilst the agent behaves\ndeterministically, the environment can behave non-deterministically. We call a le-\ngitimate run r for which either \u03c3(\u03c1) = \u0004 or (\u03c3(\u03c1) = a and \u03c4(\u03c1, a) = \u2205) a complete\nlegitimate run (that is, a legitimate run which can not be further extended in the\ngiven system). We shall only ever be interested in the legitimate runs within any\nsystem \u3008ENV,AG\u3009.\nAgent-based systems are intended to model real systems. Hence, it is often the\ncase that we are not just looking for some particular circumstance in our system\nbut whether this circumstance has come about within some given time. For exam-\nple, amongst the sort of problems that have hitherto been considered of agent-based\nsystems are \u2018achievement\u2019 problems, where it is required that an agent achieves some\nspecific state of affairs, and \u2018maintenance\u2019 problems, where it is required that an agent\nmaintains a specific state of affairs. With achievement problems it is usually the case\nthat the state of affairs in hand should be achieved within some reasonable time, e.g.,\na search for data over the Internet should quickly register whether the data has been\nfound or not. However, with maintenance problems it is usually the case that the\nstate of affairs should be maintained in perpetuity, e.g., a web-crawler should never\nbe given access to data to which it does not have security clearance. Consequently,\nwe also consider bounded environments which are environments where, as well as the\nset of states E (and the initial state e0 \u2208 E), the set of actions A and the state\ntransformer function \u03c4 , a natural number b, the bound , is also supplied; with the\nresult that the size of a bounded environment is |E|+ |A|+ |\u03c4 |+ b. In an agent-based\nsystem where the environment is bounded, the set of legitimate runs is defined as\nabove except that now no legitimate run is allowed to contain more than b actions;\nthat is, the new set of legitimate runs is obtained from the old set by retaining all\nlegitimate runs of length at most b and truncating every run of length greater than b\nso that only the first b actions occur.\nAn example of an achievement problem, as was studied in [18], is the problem\nACHIEVEMENT AGENT DESIGN for which: an instance is a pair (ENV, G), where\nENV = (e0, E,A, \u03c4, b) is a bounded environment and G \u2286 E is a set of goal states;\nand a yes-instance is an instance for which there exists an agent AG such that ev-\nery legitimate run contains a goal state. An example of a maintenance problem,\nagain as studied in [18], is the problem MAINTENANCE AGENT DESIGN for which:\nan instance is a pair (ENV, B), where ENV = (e0, E,A, \u03c4, b) is a bounded environ-\nment and B \u2286 E is a set of bad states; and a yes-instance is an instance for which\nthere exists an agent AG such that no legitimate run contains a bad state. Both\n4\nproblems, ACHIEVEMENT AGENT DESIGN and MAINTENANCE AGENT DESIGN,\nwere proven in [18] to be PSPACE-complete1.\nNote that even though the problem MAINTENANCE AGENT DESIGN is a main-\ntenance problem, and so it makes sense to consider environments rather than bounded\nenvironments, the particular formulation in [18] was essentially for bounded environ-\nments. Indeed, if we were to relax the stipulation that an environment should be\nbounded then we would be faced with undecidable problems. Later on in this pa-\nper, we shall define an amended, more practically relevant version of the problem\nMAINTENANCE AGENT DESIGN where environments are still bounded but where\nruns in the environment can be exponentially longer.\nBefore we proceed, we have one remark to make. Consider the decision problem\nACHIEVEMENT AGENT DESIGN. When instances are encoded for input to, say,\na (deterministic) Turing machine, we should be able to easily ascertain whether an\ninput string is the encoding of an instance. In particular, we should be able to\ncheck whether the Turing machine (within the encoding) is a polynomial-time Turing\nmachine. Unfortunately, by Rice\u2019s Theorem (see, for example, [16]), it is undecidable\nto check whether a given Turing machine is a polynomial-time Turing machine. Hence,\nwe encode our polynomial time Turing machine as a pair, the first component of which\nis the encoding of a Turing machine M , and the second component of which is an\ninteger k; and we insist that any computation of M of length greater than nk + k (on\nan input of length n) halts as a rejecting computation. That is, (M,k) is essentially\na \u2018clocked\u2019 Turing machine. Any polynomial-time Turing machine can be realised as\na clocked Turing machine, and vice versa.\n3 Alternating Turing machines\nAlternating Turing machines were introduced in [6] and [14] as a model of parallel\nmachines. However, they have proven to be very useful with regard to sequential\ncomplexity too. The reader is referred to [1] and [12] for an extensive discussion of\nalternating Turing machines and for any details omitted below.\nAn alternating Turing machine (ATM ) M = \u3008Q,R,F,\u0393, \u03b4\u3009 is a non-deterministic\nTuring machine with a read-only input-tape, a read-write index-tape and one read-\nwrite work-tape (though there can be more work-tapes if needs be). All tapes are\ntwo-way infinite and on each tape, cells are indexed by the integers. The index-tape\nand the work-tape have associated tape-heads. The input string \u03c9, over {0, 1} and\nof length n, is presented on the input-tape in cells 1, 2, . . ., n, with all other cells of\nthe input-tape and every cell of the index- and work-tapes initially holding a special\nblank symbol \b. The finite work-tape alphabet \u0393 contains 0, 1 and \b and may also\ncontain other symbols. The symbols from {0, 1, \b} will be the only symbols appearing\non the index-tape, and whenever a bit of the input string \u03c9 is to be read, the longest\ncontiguous string of 0s and 1s on the index-tape (starting at cell 1), known as the\nindex , is taken as the binary representation of the name of the cell on the input-tape\nto be read (if cell 1 holds the blank symbol then the index is 0).\n1In [18], an attempt was made to only consider environments within which all (legitimate) runs\nare complete and have length \u2018polynomial in the size of |A|\u00d7|E|\u2019. This notion does not actually make\nsense and our definition, of a bounded environment, is the appropriate formalism. Nevertheless, the\nproofs in [18] of PSPACE-completeness essentially still hold for our formalism of the problems.\n5\nThe set Q is the finite set of states of M and contains the initial state q0 and the\naccept state qa (to obviate the need to consider trivial cases, we insist that q0 \t= qa).\nThe set of states R \u2286 Q is the set of read states of M ; and the set of states F is the set\nof universal states of M , with the states of Q\\F being the existential states (whether\na state is universal or existential impacts on whether an input string is accepted by\nan ATM, as we shall see below). The relation\n\u03b4 \u2286 (Q \\ {qa} \u00d7 {0, 1, \b}2 \u00d7 \u0393)\u00d7 (Q\u00d7 {0, 1, \b} \u00d7 \u0393\u00d7 {\u22121, 0, 1}2)\ndescribes the transitions of M as follows.\n\u2022 If ((q, s1, s2, s3), (q\u2032, s\u20322, s\u20323, h2, h3)) \u2208 \u03b4 and q \u2208 R then:\n\u2013 if M is in state q and the index has the value i with the ith cell of the\ninput-tape holding the symbol s1\n\u2013 then M can move into state q\u2032 and no other tape and head alterations are\nmade.\nSo, s2, s3, s\u20322, s\n\u2032\n3, h2 and h3 are redundant in such tuples of \u03b4.\n\u2022 If ((q, s1, s2, s3), (q\u2032, s\u20322, s\u20323, h2, h3)) \u2208 \u03b4 and q \t\u2208 R then:\n\u2013 if M is in state q; the index-head is scanning the symbol s2; and the work-\nhead is scanning the symbol s3\n\u2013 then M can move into state q\u2032; write the symbol s\u20322 on the index-tape and\nmove the index-head h2 cells to the right; and write the symbol s\u20323 on the\nwork-tape and move the work-head h3 cells to the right (with \u2018-1\u2019 meaning\na move of one cell to the left).\nSo, s1 is redundant in such tuples of \u03b4.\nAn ATM M computes in the usual way, to accept a set of strings over {0, 1}, except\nthat its notion of acceptance differs considerably from that of a non-deterministic\nTuring machine.\nSuppose that M halts on every input (this will always be the case for us). An\ninput string \u03c9 gives rise (in the usual way) to a finite computation tree T where the\nnodes are instantaneous descriptions (IDs) of M and where the edges (all directed\naway from the root) describe single transitions of M on input \u03c9. Every node is\neither existential or universal , depending upon the state in the ID. For any node u\nof T , denote by childT (u) the number of children of u. By imposing an order on the\ntransitions described by \u03b4, we can clearly talk about the first child of a node u, the\nsecond child of u, and so on. A valuation \u03bc on T is a function taking an existential\nnode u of T as an input and yielding an integer in {0, 1, 2, . . . , childT (u)} as output.\nWe apply a valuation \u03bc to T at every existential node, working away from the root\nin a breadth-first fashion, until there are no more existential nodes to consider, as\nfollows.\n\u2022 If p is a path in T from the root to an existential node u then:\n\u2013 if \u03bc(u) = i\n6\n\u2013 then erase all sub-trees of T , pendant from u with roots the jth child of u,\nfor every j \u2208 {1, 2, . . . , childT (u)} \\ {i}.\nApplying a valuation \u03bc to T yields a sub-tree \u03bc(T ) of T . If the sub-tree \u03bc(T ) is such\nthat every leaf is an accepting ID, i.e., the state of the ID is qa, then the valuation \u03bc\nis a true valuation. The input string \u03c9 is accepted by M if, and only if, there is a true\nvaluation on the corresponding computation tree T . The time taken by M to accept\n\u03c9 is the minimal height of any sub-tree \u03bc(T ), where \u03bc ranges over all true valuations.\nThe space used by M to accept \u03c9 is the minimum over any sub-tree \u03bc(T ), where \u03bc\nranges over all true valuations, of the maximal size of an ID in \u03bc(T ).\nCrucial to our analysis is the relationship between time-bounded ATMs and time-\nand space-bounded (deterministic and non-deterministic) Turing machines (note that\na non-deterministic Turing machine is just an ATM where all states are existential).\nWe denote the classes of languages accepted by deterministic and non-deterministic\nTuring machines in O(s(n)) space (resp. O(t(n)) time) by DSPACE(s(n)) and\nNSPACE(s(n)) (resp. DTIME(t(n)) and NTIME(t(n))). We denote the class of\nlanguages accepted by ATMs in simultaneous O(t(n)) time and O(s(n)) space by\nATISP(t(n), s(n)).\nTheorem 1 (see [12]) For every space constructible functions s(n) and t(n), for\nwhich s(n) = \u03a9(log(n)), we have that :\n\u2022 NSPACE (s(n)) \u2286 ATISP(s(n)2, s(n));\n\u2022 ATISP(t(n), s(n)) \u2286 NSPACE (t(n)2).\nWe remind the reader also of Savitch\u2019s Theorem.\nTheorem 2 (see [1]) For every space constructible function s(n) for which s(n) =\n\u03a9(log(n)), we have that NSPACE (s(n)) \u2286 DSPACE(s(n)2).\nFinally, we mention that all of the completeness results in this paper are with\nrespect to logspace reductions; that is, when we prove that every problem in some\ncomplexity class can be reduced to our complete problem, the actual reduction can\nnot only be computed using polynomial-time but also using logspace.\n4 Achievement problems\nWe beginning by reconsidering the problem ACHIEVEMENT AGENT DESIGN, first\ninvestigated in [18]. Whilst we re-prove the fact that this problem is PSPACE-\ncomplete, our proof is such that we obtain much more information about this problem\nand some of its close relations; in that our proof enables us to focus directly upon, and\nso restrict, the number of states and actions in our constructed bounded environments.\nTheorem 3 The problem ACHIEVEMENT AGENT DESIGN is PSPACE-complete.\nProof We begin by proving the PSPACE-hardness of our problem in hand. By\nTheorem 1, any problem in PSPACE can be accepted by a polynomial-time ATM.\nLet M be an ATM which runs in time t(n), for some polynomial t(n). By introducing\nextra \u2018dummy\u2019 states if necessary, we can assume that:\n7\n\u2022 every node in any computation tree of M has at most 2 children;\n\u2022 in traversing any path in any computation tree of M , starting from the root,\nwe alternate between existential and universal nodes, with the root being an\nexistential node;\n\u2022 all leaves in any computation tree of M are existential nodes.\nThe amended ATM (if indeed we need to amend our original Turing machine), which\nwe also denote by M , runs in time ct(n), for some constant c.\nConsider some computation tree T of M , resulting from the input string \u03c9 of\nlength n. We define a bounded environment ENV = (e0, E,A, \u03c4, b) and a set of\ngoal states G \u2286 E corresponding to T . The state set E is the set {ql, qr, qa}, with\nthe initial state, e0, being ql. The set of actions A is {l, r}. Given some path p\nin T , starting from the root and leading to an existential node, we obtain a tuple\n(e0, a1, e1, a2, . . . , am, em), where each ei \u2208 E and each ai \u2208 A, as follows. Starting\nfrom the root, traverse p and at the ith existential node on p, where 1 \u2264 i \u2264 m, the\nnode ui say (the root is the 0th), define: ei to be the state qa, if ui is an accepting\nnode, otherwise the state ql (resp. qr) if ui is the left-child (resp. right-child) of its\nparent; and, if i \t= m, ai+1 to be l (resp. r) if the next node on p is the left-child (resp.\nright-child) of ui. We say that the tuple (e0, a1, e1, a2, . . . , am, em) is the existential\ntrace of p.\nOn input a potential run \u03c1 = (e0, a1, e1, a2, . . . , am, em) and an action a, the\noutput from the function \u03c4 is defined as follows. We begin by checking that \u03c1 is an\nexistential trace in T . If it isn\u2019t then \u03c4 yields no output: otherwise, \u03c1 is the existential\ntrace of some path p in T (note that \u03c1 can be the existential trace of at most one\npath in T ) and we ascertain whether there is an edge in T from the final node, u\nsay, of p to a left-most child, if a = l, and to a right-most child, if a = r. If no such\nchild exists then \u03c4 yields no output: otherwise, such a child, v say, exists and the\noutput from \u03c4 is defined to be the set of states associated with the children of the\nnode v (there are at most 2 and there may be none). The function \u03c4 can clearly be\ncomputed in polynomial time (polynomial in m, to be precise): in fact, in O(m) time,\ni.e., linear-time. Our set of goal states G \u2286 E is the set {qa}; and our bound b is set\nat ct(n).\nHaving constructed an instance (ENV = (e0, E,A, \u03c4, b), G) of ACHIEVEMENT\nAGENT DESIGN, we need to ensure that the process of construction can be under-\ntaken using logspace. That this is the case is trivial except for the description of the\nfunction \u03c4 (remember, \u03c4 is not given explicitly but is presented as a polynomial-time\ndeterministic Turing machine which computes the function in hand2). Let M0 be\na deterministic Turing machine which takes as input the description of an ATM M\n(as described in the opening paragraph of this proof), an input string \u03c9 to M and a\nsequence (e0, a1, e1, a2, . . . , am, em) \u2208 E(AE)\u2217. The Turing machine M0 simulates a\ncomputation of M on \u03c9, where M is treated as a non-deterministic Turing machine\nand the sequence (e0, a1, e1, a2, . . . , am, em) dictates the choices made at any point\nof the computation. If such a simulation does not exist then M0 rejects the input,\notherwise M0 computes the function \u03c4 . Note that M0 is a fixed Turing machine.\nIt is straightforward to devise a logspace algorithm which takes M and \u03c9 as input\n2This point was completely overlooked in [18].\n8\nand outputs (using M0) a polynomial-time (in fact, linear-time) deterministic Turing\nmachine which computes \u03c4 .\nLet AG be any agent, with agent strategy function \u03c3, acting within the bounded\nenvironment ENV. This agent yields a valuation on the tree T in the natural way.\n\u2022 If p is a path in T from the root to an existential node u for which the existential\ntrace is \u03c1, then:\n\u2013 if \u03c3(\u03c1) = l (resp. r) and u has a left-child (resp. right-child)\n\u2013 then erase the right (resp. left) branch of T descending from u (if there is\none).\nAlternatively, any valuation on T clearly yields an agent acting within the bounded\nenvironment ENV. Moreover, there is an agent such that every legitimate run con-\ntains a goal state if, and only if, there is a true valuation on the tree T . Hence, the\nproblem ACHIEVEMENT AGENT DESIGN is PSPACE-hard.\nNow we show that our problem is in PSPACE. Let (ENV = (e0, E,A, \u03c4, b), G)\nbe an instance of our problem of size n. Consider the tree T , of depth at most 2b,\nconstructed as follows. Nodes are categorized as to their distance from the root, with\nthe distance equating to the level of the node. The level of the root is 0. Every node\non an even level is labelled as a universal node; and every node on an odd level as an\nexistential node. Also, every node on an even level will be labelled with a state of E;\nand every node on an odd level with a symbol from A. The root is labelled e0. Let\nu be a node on the (even) level 2m, for some m \u2208 {0, 1, . . . , b\u2212 1}, where u\u2019s label is\ne \u2208 E. Suppose that the path p from the root to the node u induces a (2k + 1)-tuple\n(e0, a0, e1, a1, . . . , am, em) of labels (alternating between states of E and symbols of A\nand starting with e0). The node u has |A| children (on level 2k+1) with these children\nlabelled with the symbols from A. The child on level 2k + 1 labelled with a \u2208 A has\n|\u03c4((e0, a0, e1, a1, . . . , am, em), a)| children (on level 2k+2) with these children labelled\nwith the elements of \u03c4((e0, a0, e1, a1, . . . , am, em), a). Finally, the tree is pruned by:\nfirst, removing any sub-trees pendant from a node (on an even level) whose associated\nlabel is in G; and, second, removing any leaves on an odd level (and so all leaves are\nexistential nodes and labelled with states of E).\nJust as we have a valuation on the computation tree of an ATM, so we have the\nnotion of a valuation on our tree T as constructed above. Essentially, a valuation \u03bc\nis such that we retain exactly one pendant sub-tree (if there is one) from every exis-\ntential node. Clearly, (ENV = (e0, E,A, \u03c4, b), G) is a yes-instance of ACHIEVEMENT\nAGENT DESIGN if, and only if, there is a true valuation \u03bc on T , i.e., one such that\nevery leaf of \u03bc(T ) is labelled with a state of G.\nIn order to ascertain whether there is a true valuation on T , we perform a \u2018non-\ndeterministic\u2019 depth-first search on T . Our depth-first search is such that whenever\nan existential node is encountered, we non-deterministically guess a child to move to\nnext; and when we back-track in our depth-first search, having guessed a child of an\nexistential node, we never guess another child but keep on moving back up the tree to\nthe (universal) parent node (from which we continue the depth-first search as normal).\nIf our search returns to the root having ascertained that every leaf encountered was\nlabelled with a state from G then we accept otherwise we reject. This clearly results in\na polynomial-space non-deterministic algorithm, and so, by Theorem 2, a PSPACE\nalgorithm, for the problem ACHIEVEMENT AGENT DESIGN. The result follows.\n9\nThe proof of Theorem 3 actually yields a much stronger result than that stated.\nCorollary 4 The problem ACHIEVEMENT AGENT DESIGN restricted to bounded\nenvironments with 3 states and 2 actions is PSPACE-complete.\nOur proof of Theorem 3 is superior to that in [18] because: first, as we have just\nseen in Corollary 4, it yields additional information (note that Corollary 4 is not deriv-\nable from the proof in [18]); second, as we shall see later, it enables us to prove com-\nplexity results about problems related to ACHIEVEMENT AGENT DESIGN; third,\nit exhibits a strong relationship between agent-based systems and alternation in the\ntheory of computation; and, fourth, it clarifies key issues which were ignored in [18].\nCorollary 4 gives us a significant insight into how we might impose restrictive con-\nditions so as to make the problem ACHIEVEMENT AGENT DESIGN feasibly solvable.\nFor brevity, we denote the problem ACHIEVEMENT AGENT DESIGN restricted to\nbounded environments where the set of states has size at most j and the set of actions\nhas size at most k by AAD(j, k).\nTheorem 5 The problem AAD(2, 2) is NP-complete.\nProof We begin by proving that AAD(2, 2) is inNP. Let (ENV = (e0, E,A, \u03c4, b), G)\nbe an instance of size n. W.l.o.g., we may assume that E = {q, qa}, A = {l, r},\nG = {qa} and e0 = q. Consider the following polynomial-time non-deterministic\nalgorithm.\nGuess a1 \u2208 A.\nIf \u03c4((q), a1) = \u2205 then reject.\nIf \u03c4((q), a1) = {qa} then accept.\nIf \u03c4((q), a1) = {q, qa} or {q} then\nguess a2 \u2208 A.\nIf \u03c4((q, a1, q), a2) = \u2205 then reject.\nIf \u03c4((q, a1, q), a2) = {qa} then accept.\nIf \u03c4((q, a1, q), a2) = {q, qa} or {q} then\nguess a3 \u2208 A.\nIf \u03c4((q, a1, q, a2, q), a3) = \u2205 then reject.\nIf \u03c4((q, a1, q, a2, q), a3) = {qa} then accept.\nIf \u03c4((q, a1, q, a2, q), a3) = {q, qa} or {q} then\n. . .\nguess ab \u2208 A.\nIf \u03c4((q, a1, q, . . . , ab\u22121, q), ab) = \u2205 then reject.\nIf \u03c4((q, a1, q, . . . , ab\u22121, q), ab) = {qa} then accept.\nIf \u03c4((q, a1, q, . . . , ab\u22121, q), ab) = {q, qa} or {q} then reject.\nThis algorithm clearly witnesses that our problem is in NP.\nLet M be a non-deterministic Turing machine running in time t(n), for some\npolynomial t(n). By introducing extra \u2018dummy\u2019 states if necessary, we can assume\nthat every node in any computation tree of M has at most 2 children. The amended\nTuring machine (if indeed we need to amend our original Turing machine), which we\nalso denote by M , runs in time ct(n), for some constant c.\n10\nConsider some computation tree T of M , resulting from the input string \u03c9 of\nlength n. We define a bounded environment ENV = (e0, E,A, \u03c4, b) and a set of goal\nstates G \u2286 E corresponding to T . The state set E = {q, qa}, with the initial state,\ne0, being q. The set of actions A is {l, r}. We associate a state with every node of T\nas follows: if the node is accepting then its associated state is qa; otherwise it is q.\nGiven a potential run \u03c1 = (e0, a1, e1, a2, . . . , am, em) and an action a, the output\nfrom the function \u03c4 is defined as follows. We begin by checking that there is a path p in\nT , starting from the root and obtained from the tuple (a1, a2, . . . , am) by interpreting\nthe symbol l (resp. r) as meaning \u2018go to the left-child (resp. right-child)\u2019, such that\nthe states of the nodes obtained by traversing p yield the tuple (e0, e1, . . . , em). If this\npath p does not exist then \u03c4 yields no output. Otherwise, p exists, and if a = l (resp.\na = r) then the output of \u03c4 is the state of the left-child (resp. right-child) of the final\nnode of p, if it exists: if it does not exist then \u03c4 yields no output. The function \u03c4 can\nclearly be computed in polynomial time: in fact, in linear-time. Our set of goal states\nG \u2286 E is the set {qa}; and our bound b is set at ct(n). As in the proof of Theorem 3,\nthe instance (ENV = (e0, E,A, \u03c4, b), G) can be constructed using logspace (including\nproviding a polynomial-time deterministic Turing machine computing \u03c4).\nLet AG be any agent, with agent strategy function \u03c3, acting within the bounded\nenvironment ENV. This agent yields a path in T in the natural way; and by con-\nstruction of (ENV, G), there is an agent such that every legitimate run contains a\ngoal state if, and only if, M accepts the input \u03c9. The result follows.\nNote that the algorithm in the proof of Theorem 5 is actually a polynomial-time\nnon-deterministic algorithm to solve the problem AAD(2, k), for any k \u2265 2. Hence,\nwe immediately obtain the following corollary.\nCorollary 6 For every k \u2265 2, the problem AAD(2, k) is NP-complete.\nWe now restrict the set of actions so that there is (essentially) only one possible\nagent strategy function.\nTheorem 7 The problem AAD(3, 1) is co-NP-complete.\nProof We first remark that it is straightforward to see that a problem is in co-NP\nif, and only if, there exists a polynomial-time non-deterministic Turing machine M\nsuch that:\n\u2022 the computation tree of M corresponding to some yes-instance of the problem\nis such that every leaf is accepting; and\n\u2022 the computation tree of M corresponding to some no-instance of the problem\nis such there exists a leaf which is not accepting.\nWe say that the language accepted by M according to the above criteria is the lan-\nguage co-accepted by M . Hence, co-NP consists of those languages co-accepted by\npolynomial-time non-deterministic Turing machines.\nWe begin by proving that the problem AAD(3, 1) is co-NP-hard. Let M be a\nnon-deterministic Turing machine which runs in time t(n), for some polynomial t(n).\nBy introducing extra \u2018dummy\u2019 states if necessary, we can assume that every node in\n11\nany computation tree of M has at most 2 children. The amended ATM (if indeed\nwe need to amend our original Turing machine), which we also denote by M , runs in\ntime ct(n), for some constant c.\nConsider some computation tree T of M , resulting from the input string \u03c9 of\nlength n. We define a bounded environment ENV = (e0, E,A, \u03c4, b) and a set of goal\nstates G \u2286 E corresponding to T . The state set E is the set {ql, qr, qa}, with the\ninitial state, e0, being ql. The set of actions A is {a}. Given some path p in T , starting\nfrom the root, we obtain a tuple (e0, a, e1, a, . . . , a, em), where each ei \u2208 E, as follows.\nStarting from the root, traverse p and at the ith node on p, where 1 \u2264 i \u2264 m, the\nnode ui say (the root is the 0th), define: ei to be the state qa, if ui is an accepting\nnode, otherwise the state ql (resp. qr) if ui is the left-child (resp. right-child) of its\nparent. We say that the tuple (e0, a1, e1, a2, . . . , am, em) is the trace of p.\nOn input a potential run \u03c1 = (e0, a, e1, a, . . . , a, em) and the action a, the output\nfrom the function \u03c4 is defined as follows. We begin by checking that \u03c1 is a trace in T .\nIf it isn\u2019t then \u03c4 yields no output: otherwise, \u03c1 is the trace of some path p in T (note\nthat \u03c1 can be the trace of at most one path in T ). If \u03c1 is the trace of some path p\nand the final node on p has no children then \u03c4 yields no output: otherwise, \u03c4 yields\nthe set of states associated with the children of this final node (there are at most 2\nand there may be none). The function \u03c4 can clearly be computed in polynomial time\n(polynomial in m, to be precise): in fact, in linear-time. Our set of goal states G \u2286 E\nis the set {qa}; and our bound b is set at ct(n). As in the proof of Theorem 3, this\nconstruction can be completed in logspace (including providing a polynomial-time\ndeterministic Turing machine computing \u03c4).\nLet AG be the agent whose agent strategy function \u03c3 yields the action a for every\nlegitimate run. Note that if AG does not witness that (ENV, G) is a yes-instance\nof AAD(3, 1) then no agent does. By construction, our reduction is such that M\nco-accepts a string \u03c9 if, and only if, every legitimate run in the agent-based system\n\u3008ENV ,AG\u3009 contains a goal state. That is, AAD(3, 1) is co-NP-hard.\nThat AAD(3, 1) is in co-NP is straightforward as verifying that an instance\n(ENV = (e0, E,A, \u03c4, b), G) of AAD(3, 1) is a yes-instance amounts to building a tree\n(of depth at most b for which every node has at most 3 sons) described by \u03c4 , whose\nnodes are labelled with states of E, and checking that every leaf is labelled by a node\nof G.\nThe fact that AAD(j, 1) is in co-NP, for any j \u2265 3, is trivial, given the above\nproof; and so we obtain the following corollary.\nCorollary 8 For j \u2265 3, the problem AAD(j, 1) is co-NP-complete.\nAll that remains is to consider the problem AAD(2, 1) (as the problem AAD(1, k)\nis trivial, for any k \u2265 1). However, the proof of Theorem 7 obviates the need for much\nmore analysis.\nCorollary 9 The problem AAD(2, 1) is P-complete.\nProof Let the Turing machine M in the proof of Theorem 7 be deterministic. Then\nproceeding in that proof but with a state set E = {ql, qa} yields that the problem\nAAD(2, 1) is P-hard. The fact that AAD(2, 1) is in P is straightforward.\n12\n5 Maintenance problems\nWe begin my analysing the MAINTENANCE AGENT DESIGN problem, henceforth\nabbreviated to MAD, as we did the ACHIEVEMENT AGENT DESIGN. We adopt an\nanalogous notation when referring to the various restrictions of the problem MAD. As\nit turns out, our \u2018first principles\u2019 approach from the previous section has accounted\nfor most of the hard work.\nCorollary 10 (a) If j \u2265 3 and k \u2265 2 then MAD(j, k) is PSPACE-complete.\n(b) If j = 2 and k \u2265 2 then MAD(j, k) is NP-complete.\n(c) If j \u2265 3 and k = 1 then MAD(j, k) is co-NP-complete.\n(d) If j = 2 and k = 1 then MAD(j, k) is P-complete.\n(e) If j = 1 and k \u2265 1 then MAD(j, k) is trivial.\nProof (a) With respect to the proof of Theorem 3, w.l.o.g. we may further assume\nthat every path in any computation tree of M ends in either an accepting node or\na rejecting node, where we have designated a particular state of M to be the reject\nstate. In the proof of Theorem 3, label the nodes of T so that: a node is labelled\nqa if it is a rejecting node (formerly, this was the case if it was an accepting node);\notherwise, it is labelled ql or qr (depending upon the child-parent relationship). The\namended proof then yields that the problem MAD(3, 2) is PSPACE-hard. Our\nPSPACE algorithm to solve MAD(3, 2) is as was the PSPACE algorithm in the\nproof of Theorem 3 except that the depth-first search checks that no node is labelled\nby a bad state (as opposed to, formerly, that every leaf is labelled with a state of\nG). Hence, MAD(3, 2) is PSPACE-complete; and therefore so is MAD(j, 2), for all\nj \u2265 3.\n(b) With respect to the proof of Theorem 5, we can devise a similar algorithm,\nto the algorithm in that proof, to solve MAD(2, 2) where, at each stage: we reject\nif \u03c4((q), ai) = {qa} or {q, qa}; we accept if \u03c4((q), ai) = \u2205; and we proceed (as in the\nalgorithm in the proof) otherwise (note that we are assuming that the state qa is the\nsolitary bad state). As regards the proof of NP-hardness, we may further assume\nthat every path in any computation tree of M ends in either an accepting node or\na rejecting node, where we have designated a particular state of M to be the reject\nstate. The proof then goes through with the only difference being that we associate:\nthe state qa with a node of T if the node is a rejecting node; and the state q if the\nnode is not a rejecting node (of course, we define B = {qa}).\n(c) and (d) With respect to the proof of Theorem 7, we proceed similarly to as\nin (a) and (b) above by flipping the association of states to nodes from accepting to\nrejecting. This suffices to yield the result.\n(e) Trivial.\nLet us now return to a remark we made when defining the problem MAD. We\ncommented that bounded environments are perhaps not appropriate for maintenance\nproblems in that the problems involve states of affairs which should persist in per-\npetuity rather than over a \u2018short\u2019 time-span. Of course, if we consider maintenance\n13\nproblems in unbounded environments then it is not difficult to see that such prob-\nlems are (generally) undecidable (hint: reduce from the Halting Problem for Turing\nmachines). However, a more sensible approach might be to consider maintenance\nproblems in bounded environments but where the bound is \u2018longer\u2019.\nDefine the problem MAD\u2032 as follows: an instance ENV = (e0, E,A, \u03c4, b) is a\nbounded environment and B \u2286 E is a set of bad states; and a yes-instance is an\ninstance for which there exists an agent AG such that no legitimate run contains a\nbad state but where the notion of legitimate is with respect to the length of run 2b\n(rather than b). Our reasoning is that the exponential bound 2b, whilst not being \u2018in\nperpetuity\u2019, might prove to be \u2018long enough in practice\u2019. The state\/action restrictions\nof the problem MAD\u2032 are defined as expected. Of course, we can also define the\nproblem AAD\u2032 (and its restrictions) in an analogous fashion (but these problems are\nnot so practically motivated).\nDefine\nNEXPSPACE = \u222a{NSPACE(2s(n)) : s(n) is some polynomial};\nNEXPTIME = \u222a{NTIME(2t(n)) : t(n) is some polynomial}; and\nDEXPTIME = \u222a{DTIME(2t(n)) : t(n) is some polynomial}.\nConsider the proofs of the theorems in the previous section and the relevance of\nthe polynomial t(n). This function plays no essential role in the proofs. Indeed,\nallowing this function to be 2q(n), where q(n) is some polynomial, in these proofs,\nallied with Theorems 1 and 2, immediately yields the following corollary.\nCorollary 11 (a) If j \u2265 3 and k \u2265 2 then MAD\u2032(j, k) and AAD\u2032(j, k) are\nNEXPSPACE-complete.\n(b) If j = 2 and k \u2265 2 then MAD\u2032(j, k) and AAD\u2032(j, k) areNEXPTIME-complete.\n(c) If j \u2265 3 and k = 1 then MAD\u2032(j, k) and AAD\u2032(j, k) are co-NEXPTIME-\ncomplete.\n(d) If j = 2 and k = 1 then MAD\u2032(j, k) and AAD\u2032(j, k) areDEXPTIME-complete.\n(e) If j = 1 and k \u2265 1 then MAD\u2032(j, k) and AAD\u2032(j, k) are trivial.\nWe could interpret a bound b as giving rise to runs of length up to 22\nb\nor 22\n2b\n,\nand so on. Of course, there are analogous results to Corollary 11 in these situations.\n6 Conclusion\nIn this paper we have essentially considered whether imposing numeric criteria on the\nnumbers of states and actions in an agent-based system might make basic achieve-\nment and maintenance agent design problems more tractable. We have discovered\nthat even under very severe numeric restrictions these problems remain computation-\nally intractable. Consequently, if we are to stand a chance of making these problems\ntractable then it must be through restrictions of other sorts. The most obvious re-\nstriction to make is on the state transformer function in an environment. In this\n14\npaper, we insisted that any state transformer function is always (a description of)\na polynomial-time computable function. We could go further and ask if our results\nstill hold when the state transformer function must be logspace computable, or even\nsomething yet more restrictive such as first-order definable. Note that, as remarked\nin our proofs, our results still hold if we insist that any state transformer function\nmust be linear-time computable.\nConsider generalizations of our problems where we might consider acceptance\ncriteria more complicated than any run always containing a goal state or no run ever\ncontaining a bad state. Essentially, our problems deal with the simplest achievement\nand maintenance agent design problems we might formulate. Consequently, our lower-\nbound (completeness) results should apply (in a similar if not an exact fashion) to\nmost other sensible criteria, e.g., such as the criterion considered in [20] where the\nagent had to aim for a goal state but at the same time avoid every bad state. On the\nother hand, the PSPACE and NEXPSPACE upper-bound results (where we do\nnot restrict the numbers of states and actions) will apply to any property definable in\nany sensible temporal logic, such as CTL, LTL or even quantified CTL (since model\nchecking for these temporal logics can be undertaken in PSPACE). We refrain from\nstating and proving any specific results in this vein as the proofs of any such results\nwould simply be minor extensions of our earlier constructions.\nFinally, we remark upon the complexity of optimistic agent-design problems as\nstudied in [20]. In [20], the authors studied a particular achievement agent-design\nproblem where instances are pairs (ENV , G) (as in the problem AAD) but an agent\nneed only ensure that there is at least one run containing a goal state, as opposed\nto ensuring that every run should contain a goal state. This problem is known as\nOPTIMISTIC ACHIEVEMENT AGENT DESIGN (OAD), and it was shown to beNP-\ncomplete in [20]3 Of course, there are analogously defined problems parameterized by\nthe number of states and the number of actions in an environment. Our proof of\nTheorem 5 essentially shows that any problem OAD(j, k), for j \u2265 2 and k \u2265 2, is\nNP-complete: the environment constructed in that proof is deterministic and so for\nany agent, the agent ensures that there is at least legitimate run containing a goal\nstate if, and only if, the agent ensures that every legitimate run contains a goal state.\nOur proof of Theorem 7 essentially shows that any problem OAD(j, 1), for j \u2265 3, is\nNP-complete: we apply the same construction as in that proof but we work with the\nusual notion of acceptance for a non-deterministic polynomial-time Turing machine.\nIf we assume (as we did in the proof of Corollary 9) that we work with a deterministic\npolynomial-time Turing machine in the amended proof of Theorem 7 then we get that\nthe problem OAD(2, 1) is P-complete. There are corresponding results for the pa-\nrameterized versions of the problem OPTIMISTIC MAINTENANCE AGENT DESIGN\n(OMD).\nThe situation as regards the problems OAD\u2032 and OMD\u2032 are similar. The proofs of\nthe above results yield: that OAD\u2032(j, k) and OMD\u2032(j, k) are NEXPTIME-complete\nif j \u2265 2 and k \u2265 2 or if j \u2265 3 and k = 1; and that OAD\u2032(2, 1) and OMD\u2032(2, 1) are\nDEXPTIME-complete. Consequently, the results in this paper completely subsume\nthose of [18, 20].\n3Again, we have an analogous remark to make as we did for the problem AAD earlier regarding\nbounded environments and runs of length \u2018polynomial in the size of |A| \u00d7 |E|\u2019.\n15\nReferences\n[1] J.L. Balca\u00b4zar, J. D\u0131\u00b4az and J. Gabarro\u00b4, Structural Complexity II , Springer-Verlag\n(1990).\n[2] C. Baral, V. Kreinovich and R. Trejo, Computational complexity of planning\nand approximate planning in presence of incompleteness, Artificial Intelligence\n122 (2000) 241\u2013267.\n[3] C. Baral, V. Kreinovich and R. Trejo, Computational complexity of planning\nwith temporal goals, Proceedings of the 17th International Joint Conference on\nArtificial Intelligence (ed. B. Nebel) (2001) 509\u2013514.\n[4] T. Bylander, The computational complexity of propositional STRIPS planning,\nArtificial Intelligence 69 (1994) 161\u2013204.\n[5] M. Cadoli, A survey of complexity results for planning, Proceedings of the Italian\nPlanning Workshop 1993 (IPW\u201993) (eds. A. Cesta and S. Gaglio), CNR - Na-\ntional Research Council of Italy - Special Project on Automatic Planning (1993)\n131\u2013145.\n[6] A.K. Chandra and L.J. Stockmeyer, Alternation, Proceedings of the 17th IEEE\nSymposium on Foundations of Computer Science (1976) 98\u2013108.\n[7] P.E. Dunne and M. Wooldridge, The computational complexity of agent verifica-\ntion, Proceedings of Intelligent Agents VIII : Agent Theories, Architectures and\nLanguages (ed. J.-J. Meyer and M. Tambe), Lecture Notes in Artificial Intelli-\ngence Volume 2333, Springer-Verlag, Berlin (2002) 115\u2013127.\n[8] P.E. Dunne, M.J. Wooldridge and M.R. Laurence, The computational complexity\nof boolean and stochastic agent design problems, Proceedings of the 1st Interna-\ntional Joint Conference on Autonomous Agents and Multiagent Systems , ACM\nPress (2002) 976\u2013983.\n[9] E.A. Emerson, Temporal and modal Logic, Handbook of Theoretical Computer\nScience Volume B (ed. J. van Leeuwen), Elsevier (1990) 995\u20131027.\n[10] J. Esparza, Decidability and complexity of Petri net problems - an introduc-\ntion, Lectures on Petri Nets I: Basic Models. Advances in Petri Nets (eds. G.\nRozenberg and W. Reisig), Lecture Notes in Computer Science Volume 1491,\nSpringer-Verlag, Berlin (1998) 374\u2013428.\n[11] M.R. Garey and D.S. Johnson, Computers and Intractability : A Guide to the\nTheory of NP-Completeness, Freeman (1979).\n[12] R. Greenlaw, H.J. Hoover, S. Miyano, W.L. Ruzzo, S. Shiraishi and T. Shoudai,\nThe Parallel Computation Project : Volumes I-III, http:\/\/www.cs.armstrong.\nedu\/greenlaw\/parallel.html (2000).\n[13] K. Heljanko, Model checking with finite complete prefixes is PSPACE-complete,\nProceedings of the 11th International Conference on Concurrency Theory (ed. C.\nPalamidessi), Lecture Notes in Computer Science Volume 1877, Springer-Verlag,\nBerlin (2000) 108\u2013122.\n16\n[14] D. Kozen, On parallelism in Turing machines, Proceedings of the 17th IEEE\nSymposium on Foundations of Computer Science (1976) 89\u201397.\n[15] M.L. Littman, J. Goldsmith and M. Mundhenk, The computational complexity\nof probabilistic planning, Journal of Artificial Intelligence Research 9 (1998)\n1\u201336.\n[16] P Odifreddi, Classical Recursion Theory , North-Holland, Amsterdam (1989).\n[17] A.P. Sistla and E.M. Clarke, The complexity of propositional linear temporal\nlogic, Journal of the Association for Computing Machinery 32 (1985) 733\u2013749.\n[18] M. Wooldridge, The computational complexity of agent design problems, Pro-\nceedings of the Fourth International Conference on Multi-Agent Systems (ed. E.\nDurfee), IEEE Press (2000).\n[19] M. Wooldridge, On the sources of complexity in agent design, Applied Artificial\nIntelligence 14 (2000) 623\u2013644.\n[20] M. Wooldridge and P.E. Dunne, Optimistic and disjunctive agent design prob-\nlems, Proceedings of Intelligent Agents VII : Agent Theories, Architectures and\nLanguages (ed. Y. Lesperance and C. Castelfranchi), Lecture Notes in Computer\nScience Volume 1986, Springer-Verlag, Berlin (2001) 1\u201314.\n[21] M. Wooldridge and N.R. Jennings, Intelligent agents: theory and practice, The\nKnowledge Engineering Review 10 (1995) 115\u2013152.\n17\n"}
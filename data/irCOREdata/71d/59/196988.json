{"doi":"10.1136\/qshc.2007.022756","coreId":"196988","oai":"oai:lra.le.ac.uk:2381\/9209","identifiers":["oai:lra.le.ac.uk:2381\/9209","10.1136\/qshc.2007.022756"],"title":"Never mind the scientific quality, feel the ethics?: an analysis of decision letters by Research Ethics Committees and a reflection","authors":["Angell, Emma L.","Bryman, Alan","Ashcroft, Richard E.","Dixon-Woods, Mary"],"enrichments":{"references":[{"id":43679336,"title":"A tale of two studies: research governance issues arising from two ethnographic investigations into the organisation of health and social care.","authors":[],"date":null,"doi":"10.1016\/s0020-7489(02)00111-6","raw":"Hannigan B, Allen D. A tale of two studies: research governance issues arising from two ethnographic investigations into the organisation of health and social care. Int J Nurs Stud","cites":null},{"id":43679334,"title":"An exercise in fatuity: research governance and the emasculation of HSR.","authors":[],"date":"2006","doi":"10.1258\/135581906778476580","raw":"Dingwall R. An exercise in fatuity: research governance and the emasculation of HSR. J Health Serv Res Policy 2006; 11: 193-4","cites":null},{"id":43679347,"title":"Boundary work and the demarcation of science from non-science: strains and interests in professional ideologies of scientists. Am Sociol Rev","authors":[],"date":"1983","doi":"10.2307\/2095325","raw":"Gieryn T. Boundary work and the demarcation of science from non-science: strains and interests in professional ideologies of scientists. Am Sociol Rev 1983; 48: 781-795","cites":null},{"id":43679341,"title":"Central Office for Research Ethics Committees,","authors":[],"date":"2001","doi":"10.7748\/mhp.7.5.28.s30","raw":"Central Office for Research Ethics Committees, 2001. Governance Arrangements for Research Ethics Committees (GAfREC). London: Department of Health","cites":null},{"id":43679342,"title":"Contesting the science\/ethics distinction in the review of clinical research. J Med Ethics.","authors":[],"date":"2007","doi":"10.1136\/jme.2006.016071","raw":"Dawson AJ, Yentis SM. Contesting the science\/ethics distinction in the review of clinical research. J Med Ethics. 2007; 33: 165-7","cites":null},{"id":43679339,"title":"Ethics Creep: governing social science research in the name of ethics. Qual Sociol","authors":[],"date":"2004","doi":"10.1023\/b:quas.0000049239.15922.a3","raw":"Haggerty KD. Ethics Creep: governing social science research in the name of ethics. Qual Sociol 2004; 27:391-414","cites":null},{"id":43679340,"title":"Ethics in Social and Behavioral Research.","authors":[],"date":"1978","doi":"10.1093\/sf\/58.3.962","raw":"Diener E, Crandall R. Ethics in Social and Behavioral Research. Chicago: University of Chicago Press; 1978","cites":null},{"id":43679343,"title":"Ethnographic content analysis. In: Lewis","authors":[],"date":null,"doi":"10.4135\/9781412950589.n292","raw":"Altheide DL. Ethnographic content analysis. In: Lewis Beck MS, Bryman A, Liao TF, editors. The Sage Enclycopaedia of Social Science Research Methods Thousand Oaks, Ca.: Sage;","cites":null},{"id":43679345,"title":"Is \u201cinconsistency\u201d in Research Ethics Committee decision-making really a problem? An empirical investigation and reflection. Clin Ethics","authors":[],"date":null,"doi":"10.1258\/147775007781029500","raw":"Angell EL, Jackson CJ, Ashcroft RE, Bryman A, Windridge K, Dixon-Woods M. Is \u201cinconsistency\u201d in Research Ethics Committee decision-making really a problem? An empirical investigation and reflection. Clin Ethics (in press)","cites":null},{"id":43679344,"title":"Qualitative Media Analysis. Thousand Oaks,","authors":[],"date":"1996","doi":"10.4135\/9781412985536","raw":"Altheide DL. Qualitative Media Analysis. Thousand Oaks, Ca.: Sage; 1996.","cites":null},{"id":43679338,"title":"Research Ethics Committees: Differences and moral judgement. Bioethics","authors":[],"date":"2004","doi":"10.1111\/j.1467-8519.2004.00407.x","raw":"Edwards SJL, Ashcroft RE, Kirchin S. 2004. Research Ethics Committees: Differences and moral judgement. Bioethics 2004; 18:408-427","cites":null},{"id":43679337,"title":"Responses of local research ethics committees to a study with approval from a multicentre research ethics committee. BMJ","authors":[],"date":"2000","doi":"10.1136\/bmj.320.7243.1182","raw":"Lux AL, Edwards SW, Osborne JP. Responses of local research ethics committees to a study with approval from a multicentre research ethics committee. BMJ 2000; 320: 1182-1183","cites":null},{"id":43679346,"title":"Testing treatments: better research for better healthcare. London: British Library,","authors":[],"date":"2006","doi":"10.1136\/ebm.12.3.91","raw":"Evans I, Thornton H, Chalmers I. Testing treatments: better research for better healthcare. London: British Library, 2006","cites":null},{"id":43679335,"title":"The Academy of Medical Sciences. Personal data for public good: using health information in medical research. London: Academy of Medical Sciences,","authors":[],"date":"2006","doi":null,"raw":"The Academy of Medical Sciences. Personal data for public good: using health information in medical research. London: Academy of Medical Sciences, 2006. Available from: http:\/\/www.acmedsci.ac.uk\/images\/publication\/Personal.pdf","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-04","abstract":"Objectives: The performance of NHS research ethics committees (RECs) is of growing interest. It has been proposed that they confine themselves to \u2018\u2018ethical\u2019\u2019 issues only and not concern themselves with the quality of the science. This study aimed to identify current practices of RECs in relation to scientific issues in research ethics applications.\\ud\nMethods: Letters written by UK RECs expressing provisional or unfavourable opinions in response to submitted research applications were sampled from the research ethics database held by the Central Office for Research Ethics Committees. Ethnographic content analysis (ECA) was used to develop a coding framework. QSR N6 software was used to facilitate coding.\\ud\nResults: \u2018\u2018Scientific issues\u2019\u2019 were raised in 104 (74%) of the 141 letters in our sample. The present data suggest that RECs frequently considered scientific issues and that judgments of these often informed their decisions about approval of applications. Current processes of peer review seemed insufficient to reassure RECs about the scientific quality of applications they were asked to review.\\ud\nConclusions: This study provides evidence that scientific issues are frequently raised in letters to researchers and are often considered a quality problem by RECs. In the discussion, the authors reflect on how far issues of science can and should be distinguished from those of ethics and the policy implications","downloadUrl":"http:\/\/qualitysafety.bmj.com\/content\/17\/2.toc","fullTextIdentifier":"https:\/\/lra.le.ac.uk\/bitstream\/2381\/9209\/3\/ethics%20and%20science%20qshc%20revised%20250507.pdf","pdfHashValue":"c380a38f6c77ed570d03f3097f657061bb79bce8","publisher":"BMJ Publishing Group","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:lra.le.ac.uk:2381\/9209<\/identifier><datestamp>\n                2016-04-13T15:23:01Z<\/datestamp><setSpec>\n                com_2381_57<\/setSpec><setSpec>\n                com_2381_9550<\/setSpec><setSpec>\n                col_2381_58<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nAn analysis of decision letters by research ethics committees: the ethics\/scientific quality boundary examined<\/dc:title><dc:title>\nNever mind the scientific quality, feel the ethics?: an analysis of decision letters by Research Ethics Committees and a reflection<\/dc:title><dc:creator>\nAngell, Emma L.<\/dc:creator><dc:creator>\nBryman, Alan<\/dc:creator><dc:creator>\nAshcroft, Richard E.<\/dc:creator><dc:creator>\nDixon-Woods, Mary<\/dc:creator><dc:description>\nObjectives: The performance of NHS research ethics committees (RECs) is of growing interest. It has been proposed that they confine themselves to \u2018\u2018ethical\u2019\u2019 issues only and not concern themselves with the quality of the science. This study aimed to identify current practices of RECs in relation to scientific issues in research ethics applications.\\ud\nMethods: Letters written by UK RECs expressing provisional or unfavourable opinions in response to submitted research applications were sampled from the research ethics database held by the Central Office for Research Ethics Committees. Ethnographic content analysis (ECA) was used to develop a coding framework. QSR N6 software was used to facilitate coding.\\ud\nResults: \u2018\u2018Scientific issues\u2019\u2019 were raised in 104 (74%) of the 141 letters in our sample. The present data suggest that RECs frequently considered scientific issues and that judgments of these often informed their decisions about approval of applications. Current processes of peer review seemed insufficient to reassure RECs about the scientific quality of applications they were asked to review.\\ud\nConclusions: This study provides evidence that scientific issues are frequently raised in letters to researchers and are often considered a quality problem by RECs. In the discussion, the authors reflect on how far issues of science can and should be distinguished from those of ethics and the policy implications.<\/dc:description><dc:date>\n2011-03-25T15:12:10Z<\/dc:date><dc:date>\n2011-03-25T15:12:10Z<\/dc:date><dc:date>\n2008-04<\/dc:date><dc:type>\nArticle<\/dc:type><dc:identifier>\nQuality and Safety in Health Care, 2008, 17 (2), pp. 131-136<\/dc:identifier><dc:identifier>\n1475-3898<\/dc:identifier><dc:identifier>\nhttp:\/\/qualitysafety.bmj.com\/content\/17\/2\/131<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2381\/9209<\/dc:identifier><dc:identifier>\n10.1136\/qshc.2007.022756<\/dc:identifier><dc:language>\nen<\/dc:language><dc:rights>\nThis is the author\u2019s final draft of the paper published as Quality and Safety in Health Care, 2008, 17 (2), pp. 131-136.  The final published version is available at http:\/\/qualitysafety.bmj.com\/content\/17\/2.toc\\ud\n, doi: 10.1136\/qshc.2007.022756.<\/dc:rights><dc:publisher>\nBMJ Publishing Group<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["1475-3898","issn:1475-3898"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2008,"topics":[],"subject":["Article"],"fullText":" 1 \nNever mind the scientific quality, feel the ethics?: an \nanalysis of decision letters by Research Ethics \nCommittees and a reflection \n \nEmma Angell, Alan Bryman, Richard Ashcroft, Mary Dixon-Woods \n \nEmma Angell \nResearch Associate \nSocial Science Research Group \nDepartment of Health Sciences \n2nd Floor, Adrian Building \nUniversity of Leicester \nLeicester LE1 7RH \nEmail: elj1@le.ac.uk \n \nAlan Bryman \nProfessor of Organisation and Social Research \nSchool of Management \nKen Edwards Building \nUniversity of Leicester \nLeicester LE1 7RH \nEmail: ab302@le.ac.uk \n \nRichard Ashcroft \nProfessor of Biomedical Ethics \nQueen Mary, University of London  \nBarts and the London Medical School  \nInstitute of Health Sciences Education  \n38-40 New Road  \nLondon E1 2AX \nEmail: r.ashcroft@qmul.ac.uk \n \nMary Dixon-Woods CORRESPONDING AUTHOR \nProfessor of Medical Sociology \nSocial Science Research Group \nDepartment of Health Sciences \n2nd Floor, Adrian Building \nUniversity of Leicester \nLeicester LE1 7RH \nEmail: md11@le.ac.uk \n \n 2 \n \nAbstract \n \nObjectives: The performance of NHS Research Ethics Committees (RECs) is of growing \ninterest. It has been proposed that they confine themselves to \u201cethical\u201d issues only, and not \nconcern themselves with the quality of the science. We aimed to identify current practices of \nRECs in relation to scientific issues in research ethics applications. \n \nMethods: Letters written by UK RECs expressing provisional or unfavourable opinions in \nresponse to submitted research applications were sampled from the Research Ethics \nDatabase held by the Central Office for Research Ethics Committees.  Ethnographic content \nanalysis (ECA) was used to develop a coding framework. QSR N6 software was used to \nfacilitate coding. \n \nResults: \u201cScientific issues\u201d were raised in 104 (74%) of the 141 letters in our sample. Our \ndata suggest that RECs frequently considered scientific issues and that judgements of these \noften informed their decisions about approval of applications. Current processes of peer \nreview seemed insufficient to reassure RECs about the scientific quality of applications they \nwere asked to review.  \n \nConclusions: Our study provides evidence that these issues are frequently raised in letters \nto researchers, and are often considered a quality problem by RECs. We reflect on how far \nissues of science can and should be distinguished from those of ethics, and on the policy \nimplications. \n \n \n \n \n \n \n \n \n 3 \nIntroduction \n \nThe practice of ethical review in health-related research has become increasingly contentious, \nwith recent interventions in the debate arguing that ethical review of most health services \nresearch is fatuous.1 In the UK, the performance of Research Ethics Committees has been \nwidely criticised. Excessive demands and inappropriate conservatism on the part of research \nethics committees (RECs) have been blamed for obstructing or impeding important research \nthat would be of benefit to patients.2 These charges have joined more long-standing \ncomplaints about the apparent capriciousness and inconsistency of RECs. 3 4 5 The perceived \ngrowth in the influence and scope of ethical review has been a source of much comment.6 A \nparticular and growing focus of criticism now concerns the perceived inclination of ethical \nreview to stray onto the territory of science, rather than confining itself to more traditional \nethical concerns such as not harming participants; informed consent; privacy; and avoiding \ndeception of participants.7\n \n   \nAt present, under the UK Research Governance Framework, 8\nIt is not the task of an REC to undertake additional scientific review, nor is it \nconstituted to do so, but it should satisfy itself that the review already undertaken is \nadequate for the nature of the proposal under consideration. \n responsibility for ensuring the \nquality of science technically rests with the so-called \u201csponsor\u201d of any study. Protocols \nsubmitted for ethical review should, under the research governance arrangements, have \nalready been peer-reviewed and had prior critique by methodological experts. The \nGovernance Arrangements for Research Ethics Committees (GAfREC) state that: \n9\nHowever, GAfREC also commends that RECs be \u201cadequately reassured\u201d about particular \naspects of the scientific design and conduct of the study, thus offering discretion to RECs \nabout how far they accept prior assessments of the quality of the science.   \n \n \nThe question of whether RECs should concern themselves with scientific matters has been \nraised in a number of countries worldwide. In a North American context, the term \u2018ethics \ncreep\u2019 has been devised to denote: \na dual process whereby the regulatory structure of the ethics bureaucracy is \nexpanding outward, colonizing new groups, practices, and institutions, while at the \nsame time intensifying the regulation of practices deemed to fall within its official \nambit.7 \nIn the UK, the issue has been given renewed emphasis in the UK by the recent Ad Hoc \nAdvisory Group on the Operation of NHS Research Ethics Committees,10 which reported that \nit did \u2018not believe that RECs should function as a secondary form of scientific review\u2019 and that \n\u2018RECs should deal with ethical rather than scientific review\u2019. These recommendations raise \nimportant questions about how far RECs should assume that the quality of research ethics \n 4 \napplications is assured through the processes of peer review that are supposed to have \noccurred before their deliberations. In addition, some have argued that the science\/ethics \ndistinction incoherent, and that RECs should not only be permitted to consider the science, \nbut are under an obligation to do so.11\n \n \nHowever, there is little systematic evidence about how far RECs currently do concern \nthemselves with scientific issues, which issues are especially likely to engage their attention, \nand what might be the consequences if they were suspend judgement on the science. In this \npaper we report an analysis of letters composed by NHS RECs in response to applications by \nresearchers, aiming to identify which types of scientific issue, if any, RECs identify as \ntroubling them in their ethical review of applications. \n  \nMethods \nStandard Operating Procedures issued by the Central Office for Research Ethics Committees \n(COREC) require that each REC in the UK register the applications it reviews onto the \nnational Research Ethics Database (RED).  Access to the RED was granted by COREC for \npurposes of our project. \n \nOur project was concerned with letters written by RECs to applicants following the first \nmeeting at which an application was considered (i.e. we did not include letters arising from \nconsideration of researchers\u2019 responses to amendments previously requested by the REC.. \nThree possible decisions can be made by RECs when they first consider applications: \nfavourable, provisional, and unfavourable (Box 1). We were interested in applications that \nreceived an unfavourable or provisional decision at first review, as such decisions indicated \nthat there was an issue in the application that troubled the REC. For applications in our study \nthat received a provisional opinion, the final decision was recorded where available (a small \nnumber of decisions were unavailable on the database). \n \n \n \n \n \n \n \n \n \n \n \n \n 5 \nBox 1: Decisions RECs may make  \n \n \n\u2022 A \u2018favourable\u2019 opinion means that an application is approved without further \namendments; these constitute ~15% of decisions made by RECs at first \nconsideration of an application.* \n\u2022  \u2018Provisional\u2019 opinions constitute ~64% of decisions at first review, and require \napplicants to make a response to the REC addressing issues raised in the letter \nbefore a final opinion can be issued. The final opinion may be either favourable or \nunfavourable. \n\u2022 An \u2018unfavourable\u2019 opinion (~8% of all submissions) at first review amounts to a \nrejection. Researchers have the option to either resubmit a new application (taking \ninto account the issues raised) or to appeal (in which case no changes can be made \nto the documentation). \nSome applications are withdrawn (~10% before review by a REC (for example because \nthe researchers have decided not to proceed), 3% after a provisional opinion has been \nissued).  RECs may also decide that applications are \u2018outside remit\u2019 or that advice should \nbe sought from an external expert (such as a methodologist or specialist clinician) before \ngiving a formal opinion. \n \n*Data based on the period October 2005-March 2006 \n \nCriteria for inclusion of a letter in our sample were as follows: \n \n\u2022 The letter conveyed a \u201cprovisional\u201d or \u201cunfavourable\u201d opinion. \n\u2022 The letter concerned an application considered by a REC for the first time during our \n\u201celigible periods\u201d: July 2005, October 2005, January 2006 and April 2006. These \nperiods were chosen to minimise seasonal effects in application submission. \n \nThe 55 RECs that not upload letters to the RED during our eligible periods were excluded, \nleaving 115 RECs from which letters could be sampled. The first letter that met our eligibility \ncriteria for each of the 115 RECs was chosen for inclusion in the study. Unfavourable \nopinions were purposefully over-represented to yield sufficient letters for analysis, so that they \nformed 20% of the initial sample. The remaining 80% of letters were those applications with \nprovisional opinions. In addition, because applications that initially received a provisional \ndecision but were subsequently issued with an unfavourable opinion were of particular \ninterest, this type of application was also purposefully over-sampled by including all such \napplications between March 2004 and July 2006 for which a letter was available. More than \none \u201cprovisional\u201d letter from some RECs was therefore included in the study. \n \n 6 \nDescriptive information about each application \u2013 e.g. clinical drug trial, qualitative study, \nstudent project etc \u2013 was recorded. We also recorded whether the proposal had been peer-\nreviewed prior to submission to the REC. There are several different classes of peer review \n(ranging from review within project team to external independent review) and the tick-box \ncategories for these have changed over time on the REC form. We report the categories \nticked by applicants when they submitted.  \n \nIn order to analyse the letters, ethnographic content analysis (ECA) 12 13 was employed. ECA \nrequires the development of a coding scheme or framework grounded in the data.  The \nframework was generated initially through close inspection and comparison across the texts \nof letters used a previous study,14\n \n  but was modified extensively in response to the new data \nin this project.  Explicit specifications were devised to aid data assignment, which was \nfacilitated by the use of QSR N6 software.  \nOur study was deemed by COREC not to require research ethics committee review. Care has \nbeen taken to anonymise quotations from the letters and where appropriate identifying details \nhave been modified or removed. \nResults \n \nTable 1 shows the outcomes of the 141 letters that were selected for inclusion in our study.  \nTwenty-three applications were given an unfavourable opinion at first review and 118 were \nissued with a provisional opinion.  Of these provisional opinions, 85 were later issued with a \nfavourable opinion and 26 with an unfavourable opinion.  Five were withdrawn by the \nresearcher, one was withdrawn by the REC, and one was still awaiting a response from the \nresearcher at the time we sampled (deemed \"final decision unknown\").  A mix of application \nand applicant types was achieved in our sample.  Of applications where the final decision was \nknown, 19\/40 (48%) of applications to undertake intervention projects were approved, 36\/56 \n(64%) of non-intervention projects were approved, and 30\/38 (79%) qualitative studies were \ngiven a favourable final opinion. \n \nScientific issues were raised in a large proportion (104, 74%) of the 141 letters. Though any \nquantitative analysis of these data will necessarily be tentative given our sampling strategy, \nthere is some evidence that RECs\u2019 judgement of scientific issues were decisive in influencing \nthe outcome of applications. \u201cTroubles\u201d concerning scientific quality were raised in 51 (60%) \nof the 85 applications that were initially provisional and later favourable. However, issues \nconcerning scientific quality were raised in 24 (92%) of the 26 applications given a final \nunfavourable opinion having been deemed \u201cprovisional\u201d at first review.  Scientific issues were \nalso raised as troubles in all 23 applications that were unfavourable at first review, suggesting \n 7 \nthat issues of scientific quality were strongly associated with applications that were initially or \neventually deemed unfavourable. \n \nWithin the overall category of \u201cscientific issues\u201d, we generated nine sub-categories to \ncharacterise the types of issues raised by RECs (Table 2): the sample;  choice of methods;  \nthe research question; the measuring instrument; analysis; bias; feasibility; equipoise, and \n\u201cother\u201d design issues. It is on the 104 letters where scientific issues were raised that our \nanalysis will focus. \n \nSampling \nIssues relating to sampling were raised in 68 (65%) of the 104 letters where \u201cscientific issues\u201d \nwere raised by RECs. The most common trouble relating to the sample concerned inclusion \nand exclusion criteria (19 letters).  RECs frequently requested further information, asked \nresearchers to exclude certain groups of people, sought justification for the inclusion of \nparticular vulnerable groups, or queried how potential participants would be identified. A \nconcern for sampling criteria to be transparent and for a full justification of inclusion and \nexclusion criteria was prominent. \n \nThe committee felt that the exclusion criteria for the study although sensible were not \nfelt to robustly exclude subjects at risk of a severe reaction based upon experience to \ndate.  The committee could not identify alternative criteria that would fulfil this \nrequirement. (Letter 67, provisional opinion, review within institution) \n \nEleven letters expressed concern about the size of the sample. They requested clarity, \njustification of the sample size or for calculations to be re-done, or suggested that the sample \nsize might be too small, especially when derived without the help of a statistical expert. \n \nThe power calculation of 45% was too low and would not identify any real difference. \nThe purpose of conducting the study is, therefore, under question.  (Letter 137, \nprovisional opinion, independent external review, review within company, internal \nreview) \n \nChoice of methods \nIssues relating to choice of methods were raised in 52 (50%) of the 104 letters where \nscientific issues were raised.  Most commonly, RECs expressed concern that the rationale for \nthe methods was unclear (27 letters).   \n \nThere was significant confusion over the title and the design throughout the \napplication [\u2026].  (Letter 24, unfavourable opinion, independent external review, \nreview within institution) \n 8 \n \nRECs often made suggestions for alternative ways of designing studies (17 letters), including \nthe usefulness of control groups, the sources of tissue samples or data, or randomisation. \n \nFollowing discussions with you we thought that the control group would not be helpful \ngiven the large number of variables and that to treat one disease state using the \nresearch subjects as their own controls would help you achieve at least some of the \nanswers you were trying to obtain.  (Letter 10, provisional opinion, independent \nexternal review, internal review) \n \nResearch question \nIssues relating to the research question were in 29 letters.  The most common concern was \nlack of clarity (15 letters). \n \nThere appears to be some confusion about the status of this study. Although it is \npresented as a pilot study, statistical advice given for a similar study will be used in \nthis present study (A45-2), which indicates that this is not actually a pilot study.  \nFurthermore the research questions do not appear to be those of a pilot study.  \n(Letter 90, unfavourable opinion) \n \nOther concerns relating to the research question included queries about why the study was \nbeing undertaken (4 letters), suggestions for alternative research questions (4 letters), \nquestions about whether the study would produce meaningful results (3 letters), and concern \nthat the research question might be too ambitious or complex (2 letters). \n \nMembers suggested that it was preferable to do the research using routinely collected \nblood samples and simplifying the research question.  (Letter 42, unfavourable \nopinion) \n \nMeasuring instruments \nQueries or concerns about measuring instruments \u2013 for example questionnaires and interview \nschedules \u2013 were raised in 28 (27%) of the 104 letters.   \n \nQuestion 15 provides only negative responses.  The committee suggested taking \nadvice from the Clinical Psychologist in order to suggest some neutral\/positive \nresponses.  (Letter 22, provisional opinion, review within institution) \n \nThe usefulness of the measures to be used (10 letters), rationale (8 letters), and the ability of \nthe study design to answer the research question (8 letters) were also questioned. \n \n 9 \nThe Committee considered that the study will not achieve the research question.  The \nstudy design will only test the cream.  This would leave the placebo patients denied a \nproven treatment for an investigation with no clear purpose.  (Letter 33, unfavourable \nopinion, no peer review) \n \nMembers suggested that it was preferable to do the research using routinely collected \nblood samples and simplifying the research question.  (Letter 42, unfavourable \nopinion, review within institution) \n \nData analysis \nRECs were concerned about issues relating to the analysis of data in 23 (22%) of the 104 \nletters, and in 10 letters they expressed specific concerns about statistical analysis. \n \nThe Committee noted that the application provided no information whatever on the \nstatistical analysis that would be undertaken, and I should be grateful if you could \nprovide clarification and confirmation from a Statistician independent of the study of \nthe validity of the proposed calculations.  (Letter 74, provisional opinion, review within \ninstitution) \n \nBias \nRECs queried aspects of the study design that might bias the findings in 16 (15%) of the 104 \nletters.  The most common concern related to the relationship between the researcher and \nparticipants (8 letters), but other issues relating to the potential for bias resulting from the \ndesign of the study were also raised.  \n \nYou indicated that financial limitations prevented you from undertaking transcription \nverbatim.  The question came up whether being selective might lead to errors arising.  \n(Letter 94, provisional opinion, internal review) \n \nFeasibility \nThe question of how likely it was that the work proposed by the researchers would be feasible \nwas raised by RECs in 12 (12%) of the 104 letters.  In six letters, RECs were concerned that \nrecruitment might be slower or more difficult than anticipated. Other issues included burdens \non staff, methods for extracting data, or the suitability of the research site and competence of \nthe researchers. \n \nMembers thought that the methodology used to recruit participants was unrealistic \nand as such recruitment could be a problem, as GPs may not find the time to \ndistribute the information sheets, especially if the study was unlikely to produce \n 10 \nsignificant results. Members strongly recommended that an alternate methodology \nshould be used.  (Letter 42, unfavourable opinion, review within institution) \n \nEquipoise \nConcerns about lack of equipoise were raised in 10 (10%) of the 104 letters. Other design \nissues were raised by RECs in 27 (26%) of the 104 letters.  These mainly related to scientific \npeer review (16 letters) \u2013 that it had not been submitted, that it was inadequate, or that the \nresearcher should address the concerns therein. \n \nAn independent external scientific critique specific to this area of expertise is \nrequired, the review that was submitted was considered inadequate by the \nCommittee (Letter 126, provisional opinion, independent external review, internal \nreview) \n \nOther issues \nOther design issues were raised by RECs in 27 letters.  These mainly related to scientific \npeer review (16 letters) \u2013 that it had not been submitted, that it was inadequate, or that the \nresearcher should address the concerns therein. \n \nAn independent external scientific critique specific to this area of expertise is \nrequired, the review that was submitted was considered inadequate by the \nCommittee  (Letter 126, provisional opinion) \n \nOther \u2018unspecified\u2019 issues relating to study design included concerns of a general nature (4 \nletters), missing or incorrect information (4 letters), issue relating to research governance \napproval (3 letters), and data monitoring (3 letters). \n \nThe Committee expressed unhappiness about the scientific presentation of this study \nand feels that it needs significant revision.  (Letter 6, unfavourable opinion) \n \nQuestions A12 and A13 have been left blank and there is insufficient information in \nthe remainder of the application about the tests being performed.  (Letter 90, \nunfavourable opinion) \n \nDiscussion \nOur analysis suggests that Research Ethics Committee letters frequently raised issues of \n\u201cscience\u201d, and sought clarification or amendment of methodological issues. Sampling \nappeared to be an area that was especially likely to be a focus of concern in REC letters, but \nmany other categories of scientific \u201ctrouble\u201d appeared to be important to RECs and may \n 11 \ninfluence the decisions they make. These findings suggest that RECs do not seem to find \nsufficient reassurance about the quality of science from peer review conducted before \napplications are seen by RECs.  \n \nOur study does have a number of important limitations. In particular, we did not analyse the \napplications themselves, only the letters written in response. Our sample aimed to represent \ndifferent types of decision, and is not fully representative of all types of application. \nNonetheless, our analysis does suggest that clarification of the case for regarding matters of \nresearch quality as ethical issues is needed, as is consideration of the limits and extent of the \nrole of RECs in this area.    \n \nClearly, one way of explaining our finding that RECs often concern themselves with matters of \nscience is to treat it as evidence of \u201cethics creep\u201d 6 and territorial expansion. Other \nexplanations should, however, be considered. One problem for RECs, for example, concerns \nhow it is that they can be assured that the scientific review carried out before they see an \napplication is adequate. At present, it is not at all clear how RECs should satisfy themselves \nthat the application has undergone appropriate review, since the current application form \nrequires applicants to state what kind of scientific review has been undertaken, but not \nnecessarily to include the reports with their application.  \n \nThe problem of being assured of the quality of prior review is of particular importance to \nRECs, because our data suggest that RECs tend to see research as a context in which the \nquality of research, considered broadly, has ethical implications.11 RECs, faced with what they \nconsider to be a scientifically poor or dubious project, are confronted with the dilemma that \nsuch studies may pose risks. Poor quality health research, may, for instance, be harmful to \nfuture patients, whose treatment could be based on inadequate or misleading evidence,15\n \n and \nunfair to present research participants, in that they are subject to the risks and \ninconveniences of participation in unworthy research. RECs may therefore feel that they are \nentitled to concern themselves with issues of science, on the grounds that bad science is bad \nethics. \nIn this respect, RECs may have a particular concern with ensuring that patients taking part in \nstudies are not harmed.  In the detail of what the REC letters in our sample were raising were \nmany issues that were concerned with the direct impacts of poor study design on the well-\nbeing of people \u2013 for example, the possibility that people in the placebo arm of a trial would \nbe denied a known effective treatment (the cream mentioned in letter 33, for example) for no \nclear benefit. Such examples legitimate the interest of RECs in scientific issues, and \nstrengthen the argument that RECs should adjudicate on these matters.  \n \n 12 \nClear examples such as this should not, however, obscure the fact that there were many \nexamples in our dataset where there was unlikely to be scientific consensus about the issue \nat hand \u2013 for example in relation to construction of questionnaires or sample size. The \nparlaying of such issues into matters of \u201charm\u201d is arguably more problematic. As all those in \nthe research community are aware, referees of research proposals often vary in their \nunderstanding of what is \u201cgood science\u201d, and scientific review conducted within the context of \na REC system is unlikely to be any different: there is no external infallible scientific authority \nto which appeals might be made. There is thus the potential that RECs might reject \napplications on scientific grounds that within the scientific community of practice in which they \noriginated are regarded as having satisfactory study designs.  \n \nA related process is that RECs may parlay scientific issues into harm-related form in order to \ndeem them \u201cethical\u201d issues, and this may be because RECs are concerned with issues of \nfairness. Fairness is problematic in ethical review for two reasons.  First, issues of fairness \nare often debatable and obscure, whereas issues of harm are more clear-cut.  Second, \nalthough researchers are under clear obligations not to harm their subjects, it is not clear that \nthey are obliged to treat participants and non-participants fairly. Our analysis revealed a \nwidespread concern among RECs about issues of sampling, and inclusion\/exclusion criteria. \nThus a scientific issue (exclusion\/inclusion criteria) can be redefined as an ethical one \n(protecting individuals from unfair and harmful discrimination).  \n \nAny account of the distinction between science and ethics must also recognise the more \ngeneral problem of distinguishing between science and non-science. To require RECs to \ndeny themselves consideration of scientific issues, one has to accept an unambiguous \ndistinction between ethics and science.  The evidence we present here suggests that it is \ndifficult to sustain such a distinction in practice, even if it is available in theory. Our data \nsuggest that the science\/ethics distinction can be seen as the outcome of a social process, \nrather than an a priori conceptual distinction. As Gieryn\u2019s16\n \n analysis of boundary work has \nshown, philosophers and sociologists of science have long struggled with the problem of \n\u201cdemarcation\u201d: how to identify the unique and essential characteristics of science. Gieryn \nidentifies boundary work as a rhetorical effort that involves the attribution, by scientists, of \nselected characteristics to the institution of science, for purposes of constructing a social \nboundary that distinguishes \u201cscience\u201d from \u201cnon-science\u201d. On this account, attempts to protect \nthe \u201cscience\u201d from the criticism of RECs involve boundary work rather than resting on an \nunchallengeable and uncontested distinction between \u201cscience\u201d and \u201cethics\u201d. \nOur findings raise questions about the appropriate policy response. Better assurance of the \nquality of the science might reduce the potential for conflict between RECs and researchers. \nOne response might be to focus on improving the quality of peer review before applications \nreach the committee stage, and to ensure that all scientific review reports are made available \n 13 \nto committees, the better to discourage RECs from considering scientific issues. One \npossibility might be that some types of peer review are considered more authoritative than \nothers \u2013 in the UK, for example, research proposals that have been through certain funders \nwill already have been subjected to rigorous peer review. It should be recognised, however, \nthat prior scientific review by funders may not guarantee that all of the issues that our data \nsuggest are of concern to RECs have been reviewed in detail; some funders require only brief \ndetails of such issues, and project specifications may change between approval by the funder \nand submission to the REC. Any system that relies on improved peer review before \nsubmission to the REC would also require caution to avoid creating an overly bureaucratic \nprocess to oversee the referee reports. \n \n A second response might be to accept that RECs may find it difficult to stop themselves from \nconsiderations of the science, for the reasons we outline above. If RECs are to consider such \nmatters, then their membership needs to include the appropriate expertise to provide the \nknowledge and credibility necessary to the (legitimate) exercise of power. To avoid the \noutcome of an application being (overly) dependent on the particular compositions of \nindividual committees, committees would also need to be constituted so that their expertise \nwas commensurate with the applications being submitted. Indeed the present situation, where \nRECs are encouraged to include a statistician among their membership, goes some way \ntowards acknowledging this implicitly. An argument might more strongly be made that \ncommittees should be constituted explicitly with methodological expertise in particular \ndomains \u2013 clinical trials, qualitative research, and so on \u2013 and only review applications within \nthose areas. However, given the increase in multi-disciplinary, multi-method studies, some \nflexibility in this approach would be needed. \n \nNone of these remedies is likely to completely resolve the problems (at least from the point of \nview of researchers) of RECs functioning both as scientific authorities as well as moral \nauthorities in having a role in assessing both the scientific and the moral credentials of \nresearchers and research proposals. For the present, researchers intending to conduct \ninvestigations in the health care field should recognise the degree to which their proposed \nresearch is likely to attract scientific scrutiny from RECs, and debates in the area should \nrecognise that there may be more to this scrutiny than simply \u201cethics creep\u201d. \n \n \n \n \n \n \n 14 \n 15 \n \n \nTable 1  REC letters and outcomes of the ethical review process \nFull decision Total letters \nIntervention \nstudies \nNon- \nintervention\nstudies \nQualitative \nstudies \nProvisional then favourable 85 19 (22%) 36 (42%) 30 (35%) \nUnfavourable at first review 23 8 (35%) 11 (48%) 4 (17%) \nProvisional then \nunfavourable 26 13 (50%) 9 (35%) 4 (16%) \nProvisional, final outcome \nunknown 7 3 (43%) 4 (57%) 0 (0%) \nTotal letters 141 43 (30%) 60 (43%) 38 (27%) \n \n \n \n \n \n \n \n \n \n 16 \n \nTable 2  Types of issues raised by RECs in the 104 letters where scientific quality was raised as a \"trouble\" \nFinal decision \nTotal \nletters Sampling \nChoice \nof \nmethods \nResearch \nquestion \nMeasuring \ninstrument \nData \nanalysis Bias Feasibility Equipoise \nOther \/ \nunspecified \ndesign \nissues \nProvisional then \nfavourable 51 30 15 9 15 9 7 2 5 8 \nUnfavourable at first \nreview 23 16 19 10 6 8 4 6 2 7 \nProvisional then \nunfavourable 24 18 16 7 5 5 3 3 3 10 \nProvisional, final \ndecision unknown 6 4 2 3 2 1 2 1 0 2 \nTotal letters 104 68 52 29 28 23 16 12 10 27 \n 17 \nAcknowledgements \n \nWe gratefully acknowledge funding from the National Research Ethics Service for \nthis work, though the views expressed are the authors' own. This paper was written \nup while Mary Dixon-Woods was a Distinguished Visiting Fellow at Queen Mary, \nUniversity of London. \n \n \n \nReferences \n                                                     \n1 Dingwall R. An exercise in fatuity: research governance and the emasculation of HSR. J \nHealth Serv Res Policy 2006; 11: 193-4 \n2 The Academy of Medical Sciences.  Personal data for public good: using health information \nin medical research. London: Academy of Medical Sciences, 2006. Available from: \nhttp:\/\/www.acmedsci.ac.uk\/images\/publication\/Personal.pdf \n3 Hannigan B, Allen D. A tale of two studies: research governance issues arising from two \nethnographic investigations into the organisation of health and social care. Int J Nurs Stud \n2003; 40: 685-695 \n4 Lux AL, Edwards SW, Osborne JP. Responses of local research ethics committees to a \nstudy with approval from a multicentre research ethics committee. BMJ 2000; 320: 1182-1183 \n5 Edwards SJL, Ashcroft RE, Kirchin S. 2004.  Research Ethics Committees: Differences and \nmoral judgement. Bioethics 2004; 18:408-427 \n6 Haggerty KD. Ethics Creep: governing social science research in the name of ethics. Qual \nSociol 2004; 27:391-414 \n7 Diener E, Crandall R. Ethics in Social and Behavioral Research. Chicago: University of \nChicago Press; 1978 \n8 Department of Health. Research Governance Framework for Health and Social Care. \nDepartment of Health Publications. March 2001 London. \nhttp:\/\/www.dh.gov.uk\/assetRoot\/04\/01\/47\/57\/04014757.pdf \n9 Central Office for Research Ethics Committees, 2001. Governance Arrangements for \nResearch Ethics Committees (GAfREC). London: Department of Health \n10 Department of Health. Report of the Ad Hoc Advisory Group on the Operation of NHS \nResearch Ethics Committees. London: DoH, 2005. \nhttp:\/\/www.dh.gov.uk\/assetRoot\/04\/11\/24\/17\/04112417.pdf \n11 Dawson AJ, Yentis SM. Contesting the science\/ethics distinction in the review of clinical \nresearch. J Med Ethics. 2007; 33: 165-7 \n 18 \n                                                                                                                                                        \n12 Altheide DL. Ethnographic content analysis. In: Lewis Beck MS, Bryman A, Liao TF, editors. \nThe Sage Enclycopaedia of Social Science Research Methods Thousand Oaks, Ca.: Sage; \n2004. \n13 Altheide DL. Qualitative Media Analysis. Thousand Oaks, Ca.: Sage; 1996. \n14 Angell EL, Jackson CJ, Ashcroft RE, Bryman A, Windridge K, Dixon-Woods M. Is \n\u201cinconsistency\u201d in Research Ethics Committee decision-making really a problem?  An \nempirical investigation and reflection. Clin Ethics (in press) \n15 Evans I, Thornton H, Chalmers I. Testing treatments: better research for better healthcare. \nLondon: British Library, 2006 \n16 Gieryn T. Boundary work and the demarcation of science from non-science: strains and \ninterests in professional ideologies of scientists. Am Sociol Rev 1983; 48: 781-795 \n"}
{"doi":"10.1016\/j.compbiomed.2005.09.006","coreId":"69368","oai":"oai:eprints.lancs.ac.uk:27080","identifiers":["oai:eprints.lancs.ac.uk:27080","10.1016\/j.compbiomed.2005.09.006"],"title":"Advances in classification of EEG signals via evolving fuzzy classifiers and dependant multiple HMMs.","authors":["Xydeas, Costas","Angelov, Plamen","Chiao, Shih-Yang","Reoullas, Michalis"],"enrichments":{"references":[{"id":994363,"title":"Multichannel EEG-based brain-computer communication,","authors":[],"date":"1994","doi":null,"raw":"J.R. Wolpaw, D.J McFarland, Multichannel EEG-based brain-computer communication, Electroencephalography and Clinical Neurophysiology 90, 444-449 (1994).","cites":null},{"id":994636,"title":"Cerebral responses to a continual tonic pain stimulus measured using positron emmision tomography\u201d,","authors":[],"date":"1998","doi":null,"raw":"S.W.G. Derbyshire, Jones A.K.P., \u201cCerebral responses to a continual tonic pain stimulus measured using positron emmision tomography\u201d, Pain 76 (1998) 127 \u2013 135.","cites":null},{"id":994889,"title":"Petsche H: \u201cProbability Mapping: Power and Coherence Analyses of Cognitive Processes\u201d,","authors":[],"date":"1988","doi":null,"raw":"P. Rappelsberger, Petsche H:  \u201cProbability Mapping: Power and Coherence Analyses of Cognitive Processes\u201d, Brain Topography, 1988, 1: 46-54.","cites":null},{"id":995167,"title":"Topographic and Coherence Mapping\u201d,","authors":[],"date":"1994","doi":null,"raw":"Chen A.-C.N., Rappelsberger P: \u201cBrain and Human Pain: Topographic and Coherence Mapping\u201d, Brain Topography, 1994, 7, No 2: 129-140.","cites":null},{"id":995400,"title":"Coherence Pattern Classification Using LVQs For Pain Detection\u201d, Analysis of Biomedical Signals and Images,","authors":[],"date":null,"doi":null,"raw":"L.K.Stergioulas, Reoullas M., Xydeas C.S., Baltas E., Bentley D., Youell P., Jones A.: \u201cCoherence Pattern Classification Using LVQs For Pain Detection\u201d, Analysis of Biomedical Signals and Images, 16th Biennial International EURASIP Conference BIOSIGNAL 2002 Proceedings, Vutium Press 2002: 56 \u2013 58. Published by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume 36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam.","cites":null},{"id":995442,"title":"Anatomical localization and intra-subject reproducibility of laser evoked potential source in cingulated cortex, using a realistic head model\u201d,","authors":[],"date":"2002","doi":null,"raw":"D.E. Bentley., P.D. Youell., A.K.P. Jones.: \u201cAnatomical localization and intra-subject reproducibility of laser evoked potential source in cingulated cortex, using a realistic head model\u201d, Clinical Neurophysiology 113 (2002) 1351 \u2013 1356.","cites":null},{"id":995631,"title":"A Gentle Tutorial of the EM Algorithm and its Application to Parameter Estimation for Gaussian Mixture and Hidden Markov Models,","authors":[],"date":"1997","doi":null,"raw":"J. Bilmes, A Gentle Tutorial of the EM Algorithm and its Application to Parameter Estimation for Gaussian Mixture and Hidden Markov Models, Tech. Report, International Computer Science Institute, Berkeley, 1997.","cites":null},{"id":995850,"title":"A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition,","authors":[],"date":"1989","doi":null,"raw":"L. R. Rabiner, A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition, Proc. of the IEEE, 77 (2), 257-286 (1989).","cites":null},{"id":996112,"title":"An Introduction to Hidden Markov Models and Bayesian Networks,","authors":[],"date":"2001","doi":null,"raw":"Z. Ghahramani, An Introduction to Hidden Markov Models and Bayesian Networks, International Journal of Pattern Recognition and AI, 15 (1), 9-42 (2001).","cites":null},{"id":996352,"title":"Markovian Models for Sequential Data, Neural Computer Surveys,","authors":[],"date":"1999","doi":null,"raw":"Y. Bengio, Markovian Models for Sequential Data, Neural Computer Surveys, Dept. of Information and Research Operation, 2, 129-162 (1999).","cites":null},{"id":996611,"title":"Generalized Hidden Markov Models-Part I: Theoretical Frameworks,","authors":[],"date":"2000","doi":null,"raw":"M. A. Mohamed, P. Gader, Generalized Hidden Markov Models-Part I: Theoretical Frameworks, IEEE Transaction on Fuzzy Systems, 8 (1), (February 2000).","cites":null},{"id":996807,"title":"Generalized Hidden Markov Models-Part II: Application to Handwritten Word Recognition,","authors":[],"date":"2000","doi":null,"raw":"M. A. Mohamed, P. Gader, Generalized Hidden Markov Models-Part II: Application to Handwritten Word Recognition, IEEE Transaction of Fuzzy Systems, 8 (1), (February 2000).","cites":null},{"id":997054,"title":"Automatic Speech Recognition: the development of the SPHINX system, Kluwer Academic Publish,","authors":[],"date":"1989","doi":null,"raw":"K. F. Lee, Automatic Speech Recognition: the development of the SPHINX system, Kluwer Academic Publish, (1989).","cites":null},{"id":997402,"title":"An approach to on-line identification of evolving Takagi-Sugeno models,","authors":[],"date":"2004","doi":null,"raw":"P. Angelov, D. Filev, An approach to on-line identification of evolving Takagi-Sugeno models, IEEE Trans. on Systems, Man and Cybernetics, part B, 34 (1), 484-498 (2004).","cites":null},{"id":997734,"title":"DENFIS: Dynamic Evolving Neural-Fuzzy Inference System and Its Application for Time-Series Prediction,","authors":[],"date":"2002","doi":null,"raw":"N. Kasabov, Q. Song, DENFIS: Dynamic Evolving Neural-Fuzzy Inference System and Its Application for Time-Series Prediction, IEEE Trans. on Fuzzy Systems 10(2), 144-154 (2002). Published by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume 36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam.","cites":null},{"id":997970,"title":"Using Hierarchical HMMs in Dynamic Behaviour Modelling,","authors":[],"date":"2004","doi":null,"raw":"S.-Y. Chiao, C. S. Xydeas, Using Hierarchical HMMs in Dynamic Behaviour Modelling, Proceedings of Seventh International Conference on Information Fusion,  Fusion 2004, Stockholm Sweden, 576-582 (2004).","cites":null},{"id":998021,"title":"Behaviour Modelling Using a Hierarchical HMM Approach,","authors":[],"date":"2005","doi":null,"raw":"S.-Y. Chiao, C. S. Xydeas, Behaviour Modelling Using a Hierarchical HMM Approach, IEEE Computer Society Press Proceedings, (May 2005 to appear).","cites":null},{"id":998320,"title":"Essentials of Fuzzy Modeling and Control,","authors":[],"date":"1994","doi":null,"raw":"R. R. Yager, D. P. Filev, Essentials of Fuzzy Modeling and Control, NY: John Wiley (1994).","cites":null},{"id":998607,"title":"Evolving Rule-based Models: A Tool for Design of Flexible Adaptive Systems,","authors":[],"date":"2002","doi":null,"raw":"P.P. Angelov, Evolving Rule-based Models: A Tool for Design of Flexible Adaptive Systems, Springer, Physica-Verlag, Heidelberg, Germany (2002).","cites":null},{"id":998675,"title":"Pattern Classification and Scene Analysis: Pattern Classification, 2nd edition,","authors":[],"date":"2001","doi":null,"raw":null,"cites":null},{"id":998925,"title":"Cluster Validity with Fuzzy Sets,","authors":[],"date":"1974","doi":"10.1080\/01969727308546047","raw":"J. Bezdek, Cluster Validity with Fuzzy Sets, Journal of Cybernetics, 3 (3), 58-71 (1974).","cites":null},{"id":999096,"title":"Unsupervised optimal fuzzy clustering,","authors":[],"date":"1989","doi":"10.1109\/34.192473","raw":"I. Gath, A.B. Geva, Unsupervised optimal fuzzy clustering, IEEE Trans, Pattern Analysis and Machine Intelligence, 7, 773-781 (1989).","cites":null},{"id":999357,"title":"Fuzzy Model Identification based on Cluster Estimation,","authors":[],"date":"1994","doi":null,"raw":"S.L. Chiu, Fuzzy Model Identification based on Cluster Estimation, Journal of Intelligent and Fuzzy Systems, 2, 267-278 (1994).","cites":null},{"id":999697,"title":"Evolving fuzzy neural networks for on-line supervised\/unsupervised knowledgebased learning,","authors":[],"date":"2001","doi":"10.1109\/3477.969494","raw":"N. Kasabov, Evolving fuzzy neural networks for on-line supervised\/unsupervised knowledgebased learning, IEEE Trans. SMC - part B, Cybernetics 31, 902-918 (2001).","cites":null},{"id":1000033,"title":"Agile Collaborative agents for classification of underwater targets, Undersea Defence Technology,","authors":[],"date":"2005","doi":null,"raw":"D. Carline , P. Angelov, R. Clifford, Agile Collaborative agents for classification of underwater targets, Undersea Defence Technology, 21-23 June 2005, Amsterdam, The Netherlands.","cites":null},{"id":1000063,"title":"An Approach for Fuzzy Rule-base Adaptation using On-line Clustering,","authors":[],"date":"2004","doi":"10.1016\/j.ijar.2003.08.006","raw":"P. Angelov, An Approach for Fuzzy Rule-base Adaptation using On-line Clustering, International Journal of Approximate Reasoning, Vol. 35 (3), March 2004, Pages 275-289.","cites":null},{"id":1000351,"title":"How Good are Fuzzy If-Then Classifiers,","authors":[],"date":null,"doi":"10.1109\/3477.865167","raw":"L. Kuncheva, How Good are Fuzzy If-Then Classifiers, IEEE Transactions on Systems, Man and Cybernetics-part B, Vol 30 (4) 501-509. Published by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume 36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam.","cites":null},{"id":16655908,"title":"Pattern Classification and Scene Analysis: Pattern Classification, 2 nd edition,","authors":[],"date":"2001","doi":null,"raw":"R. O. Duda, D. G. Stork, P. E. Hart, Pattern Classification and Scene Analysis: Pattern Classification, 2 nd edition, John Wiley, NY (2001).","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2006-10","abstract":"Two novel approaches to the problem of brain signals (electroencephalogram (EEG)) classification are introduced in the paper. The first method is based on a modular probabilistic network architecture that employs multiple dependant hidden Markov models (DM-HMM-D) on the input features (channels). The second method, eClass, is based on an on-line evolvable fuzzy rule base of EEG signal prototypes that represent each class and take into consideration the spatial proximity between input signals. Both approaches use supervised learning but differ in their mode of operation. eClass is designed recursively, on-line, and has an evolvable structure, while DM-HMM-D is trained off-line, in a block-based mode, and has a fixed architecture. Both methods have been extensively tested on real EEG data that is recorded during several experimental sessions involving a single female subject who is exposed to mild pain induced by a laser beam. Experimental results illustrate the viability of the proposed approaches and their potential in solving similar classification problems. (c) Elsevie","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/69368.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/27080\/1\/CiBM_EEGpaper2006.pdf","pdfHashValue":"be8f2f4bcc959cd4dd60e6104d2bd50521033846","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:27080<\/identifier><datestamp>\n      2018-01-24T02:50:08Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Advances in classification of EEG signals via evolving fuzzy classifiers and dependant multiple HMMs.<\/dc:title><dc:creator>\n        Xydeas, Costas<\/dc:creator><dc:creator>\n        Angelov, Plamen<\/dc:creator><dc:creator>\n        Chiao, Shih-Yang<\/dc:creator><dc:creator>\n        Reoullas, Michalis<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        Two novel approaches to the problem of brain signals (electroencephalogram (EEG)) classification are introduced in the paper. The first method is based on a modular probabilistic network architecture that employs multiple dependant hidden Markov models (DM-HMM-D) on the input features (channels). The second method, eClass, is based on an on-line evolvable fuzzy rule base of EEG signal prototypes that represent each class and take into consideration the spatial proximity between input signals. Both approaches use supervised learning but differ in their mode of operation. eClass is designed recursively, on-line, and has an evolvable structure, while DM-HMM-D is trained off-line, in a block-based mode, and has a fixed architecture. Both methods have been extensively tested on real EEG data that is recorded during several experimental sessions involving a single female subject who is exposed to mild pain induced by a laser beam. Experimental results illustrate the viability of the proposed approaches and their potential in solving similar classification problems. (c) Elsevier<\/dc:description><dc:date>\n        2006-10<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/27080\/1\/CiBM_EEGpaper2006.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1016\/j.compbiomed.2005.09.006<\/dc:relation><dc:identifier>\n        Xydeas, Costas and Angelov, Plamen and Chiao, Shih-Yang and Reoullas, Michalis (2006) Advances in classification of EEG signals via evolving fuzzy classifiers and dependant multiple HMMs. Computers in Biology and Medicine, 36 (10). pp. 1064-1083. ISSN 0010-4825<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/27080\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1016\/j.compbiomed.2005.09.006","http:\/\/eprints.lancs.ac.uk\/27080\/"],"year":2006,"topics":["QA75 Electronic computers. Computer science"],"subject":["Journal Article","PeerReviewed"],"fullText":"Published by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 1\nAdvances in Classification of EEG Signals via \nEvolving Fuzzy Classifiers and Dependant Multiple \nHMMs \n \n \nC. Xydeas, P. Angelov, C. Shih-Yang, M. Reoullas \n \nDigital Signal Processing Group \nDepartment of Communication Systems \nInfolab21, Lancaster University \nLancaster, LA1 4WA, UK \nPhone: +44-1524-510310 \nFax: +44-1524-592713 \n   \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 2\nAbstract: Two novel approaches to the problem of brain signals (EEG) classification \nare introduced in the paper. The first method is based on a modular probabilistic network \narchitecture that employs Multiple Dependant Hidden Markov Models (DM-HMM-D) on the   \ninput features (channels). The second method, eClass, is based on an on-line evolvable fuzzy \nrule base of EEG signal prototypes that represent each class and take into consideration the \nspatial proximity between input signals. Both approaches use supervised learning but differ \nin their mode of operation. eClass is designed recursively, on-line, and has an evolvable \nstructure, while DM-HMM-D is trained off-line, in a block-based mode, and has a fixed \narchitecture. Both methods have been extensively tested on real EEG data that is recorded \nduring several experimental sessions involving a single female subject who is exposed to mild \npain induced by a laser beam. Experimental results illustrate the viability of the proposed \napproaches and their potential in solving similar classification problems. \u00a9 Elsevier 2006 \n \nKeywords: EEG, HMM networks, on-line evolving clustering, evolving fuzzy rule-based \nclassification.  \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 3\n1. INTRODUCTION \n1.1 EEG in the context of brain-computer interaction \nThe human brain is the most complex information processing system known to science. It is this \ncomplexity that has attracted the interest of many scientists over the past years in studying the \nphysiological activity of the brain. Human brain activity can be recorded in the form of \nelectroencephalogram (EEG) signals. These provide an important source of information which can be \nuseful in the study of underlying brain processes as well as in a variety of medical applications i.e. the \nuse of EEG signals for psychiatric\/physiological diagnosis as well as for evaluation of sensory \nexperiences [1]. A particularly interesting aspect of EEG signal analysis is that related to pain \nexperiences. From a medical point of view, the pain sensation is important either because of its mere, \nunpleasant presence or because it inhibits physiological functions or because it can be related to \ncertain pathological conditions. These are a major source of disability, poor health status and \nmortality. The ability to analyze EEG signals and to interpret accurately different aspects of the pain \nsensation can be a major advance in pain research and clinical pain management. Previous work has \nshown that analysis of pain can be possible with the help of powerful techniques based on coherence \nanalysis and topographic mapping. Thus EEG coherence analysis provides a measure of functional \ncorrelations between EEG signals [1\u20135] whereas functional imaging techniques have identified the \nmatrix of brain structures that are responsible for the elaboration of pain experience. The precise \ndivision of function within this matrix is unclear. \nThe general thrust of the work presented in this paper is to develop practically feasible \n\u201cintelligent\u201d computer based systems for processing EEG brain activity information. Furthermore, the \nspecific EEG signal analysis issue addressed here is that of pain detection, a capability that can find \nextensive use in the medical area, for example in real-time pain monitoring of patients under \nanesthesia, or in the safety\/defense field, for example in real\u2013time pain detection monitoring of \nhuman operators performing critical tasks. The following two subsections provide an introduction to \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 4\ntwo and substantially different EEG signal classification methodologies (i.e. DM-HHM-D and e-\nClass) which have been developed and employed within the context of real-time pain detection. These \nclassification techniques employ supervised learning in their classification system design, with the \nDM-HHM-D technique relying on the a priori (off-line) provision of representative training data and \nhas a fixed system architecture whereas the e-Class method is capable of formulating the \nclassification system architecture and associated fuzzy rules\/parameters on-line and \u201cfrom scratch\u201d \nwhile processing and classifying given input EEG signals. Furthermore, given the fuzzy rules \ndesigned from previous data, e-Class is capable of updating and generalizing its set of rules by further \nrecursive on-line training using new data. \n1.2 HMM and DM-HMM-D \nThe theory of Hidden Markov Models (HMMs) [7]-[9] is a rigorous probabilistic classification \nframework that has been successfully applied to several applications domains  [10]-[12]. Furthermore, \ntheir natural capability of dealing with time varying patterns of arbitrary lengths is attractive due to \nthe expected variability in the time lengths of dynamic signal patterns. In most real-time classification \napplications (i.e. pain\/no pain EEG signals classification) several different signals or features are \nobserved (i.e. 64 EEG channels from the brain cap) in order to increase recognition\/classification \nperformance. \nWhen dealing with multiple features having discrete observation densities, two HMM system \ndesign approaches can be used [8,10]: The first, HMM-VQ, employs Vector Quantization (VQ) to \naccount for any dependencies that may exist between the input features whereas the second approach, \nIM-HMM-D, is based on the \u201cseparation\u201d of input features and the assumption of no significant \ndependency between input features. The main drawback of the VQ based approach is that \nclassification system performance can be reduced significantly if an inappropriate VQ method (in \nterms of quantization accuracy) is chosen [11]. Furthermore, due to system complexity limitations, \ncodebooks are of relatively small size and are constructed by considering as few input features as \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 5\npossible, which in turn leads to a feature selection search process. In addition when a new feature is \nadded or an old feature is removed, codebooks must be re-designed and HMM networks \nretrained\/redefined. \nThe second method [10][13] is based on a \u201cmulti-HMM-D\u201d system formulation (hereafter \nreferred to as IM-HMM-D)  that employs in parallel separate HMM networks per input feature and \ncombines their outputs in order to formulate an overall classification result. Furthermore a novel \nmultiple HMM-D  system architecture is presented in this paper that computes dynamically with time \n\u201cweights\u201d associated to the observed values of different features and employs them in the formulation \nof the overall classification result, according to the varying-with-time importance of the input \nfeatures. This proposed classification structure, named as DM-HMM-D, aims to fully and efficiently \nexploit any inter-dependencies that may exist between input features. \n1.3 Evolving Classifier (e-Class) \nAn important aspect in the analysis of EEG signals is the relevance of the classification system results \nand the system\u2019s generalization capability. Very often [6] EEG data are extracted from a small \nnumber of subjects or even a single subject, as in the case of the present study. Experimental \nconfiguration may vary, including the mental and physical condition of the subject (expectation, \nanxiety etc.). As a result, classifiers which are trained in a \u201cbatch\u201d mode with a fixed set of training \ndata may become irrelevant or imprecise when applied to scenarios characterized by new operating \nconditions. One possible solution to this problem is to design classifiers that can be recursively \nupdated, or self-organizing classifiers. \nRecently proposed schemes concerning evolving un-supervised clustering [26] and evolving Self \nOrganizing Maps (SOM) [15] can be extended to the case of supervised learning (labeled outputs). \nThese self-organizing classifiers are also called evolving, because they develop their structure of \nprototypical samples starting \u201cfrom scratch\u201c, using the input EEG signals and their accumulated \nproximity measure. In this paper, a novel fuzzy classifier is build. The proposed design approach is \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 6\ngeneric and can be applied to other classification problems, such as on-line classification of difficult \ntargets [25]. \n Paper Organization \nThe remaining of this paper is organized as follows. Section 2 gives an insight on the procedure used \nfor EEG data collection and includes some technical information on data acquisition and data \npreprocessing techniques. Section 3 discusses HMM systems in general and the novel DM-HMM-D \nscheme in particular, emphasizing its main characteristics and resulting advantages as compared to \nconventional HMM-D. Section 4 introduces a novel on-line recursive approach to the classification of \nEEG signals, called eClass, where the structure of the classifier evolves to take into account the \nchanging characteristics of the processed EEG signals. This classification method is generic and is \nideally suited for use in on-line type of applications where the architecture of the classification system \nis not predetermined [25]. Section 5 gives an account and analysis of the experimental results \nobtained from both methods operating on the same real data. Finally, section 6 concludes this paper \nwith a summary of the comparative investigations presented in previous sections and identifies future \nwork aimed at achieving further improvements in EEG pain classification results. \n2. EXPERIMENTAL CONFIGURATION \nRepeated heat stimuli in the form of laser pulses were delivered in a controlled manner by laser \ncannon (CO2 laser)  to the right forearm of the subject. The duration of each pulse is set to 150ms, and \neach such stimulus is repeated at regular intervals of 10s (epochs). Each EEG continuous recording \nincluded 61 stimuli. Note that EEG (channel) signal responses to the first stimulus were routinely \ndiscarded, as they were considerably higher in amplitude, due to an element of \u201csurprise\u201d that is often \nexhibited by the subject and associated artefacts in the EEGs. Thus, 60 stimuli were taken into \naccount for each recording and nine continuous EEG data files were produced from a  healthy female \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 7\nsubject. These data files were recorded on three different days (i.e. 08.06.00, 15.06.00 and 02.08.00) \nwith three EEG recording sessions taken on each of the above three days. \nMore specifically, this EEG data collection experimental procedure can be described as follows: \n \n1) The subject was seated comfortably in a chair, placed his\/her arm on a table and the laser \ncannon was positioned at a fixed distance from the subject\u2019s hand. \n2) Electrodes were placed around the scalp, the eyes (to test whether the subject blinks) and on \neach ear (which are used as \u201cground\u201d for EEG), see Figure 2.1. \n  Figure 2.1 here \n3) A computer is placed in front of the subject, showing a table with the pain intensity scale. The \nsubject was asked to rate the pain intensity of each stimulus using a scale from 0 to 10, where 0 \nrepresents no sensation and 10 represents unbearable pain. In these experiments the rating of 4 \n(\u201cjust painful\u201d) was used as a pain threshold (i.e. 1\u20133: non\u2013painful and 4\u201310: painful). Subjective \npain ratings were also recorded so that they could be used as \u201ctarget\u201d classification data during the \ntraining and testing procedures of the proposed classification algorithms. \n4) EEG readings taken from the electrodes were then stored automatically in a file using a control \nprogram that also operated the laser cannon. \nThus recordings were made using a 64\u2013electrode cap (see Figure 2.1) with 62 head electrodes while \ntwo face electrodes (vEOG and hEOG) were used to monitor artifacts from eye movement. It must be \nmentioned here that EEG artifacts associated with signal activity in electrodes vEOG and hEOG were \nappropriately removed prior to the pain classification experiments. \n Figure 2.2 here \nEEG signals were band\u2013pass filtered at 0.15\u201330Hz and sampled at a frequency of 500Hz, with a gain \nof 500 (150 for the EOG channels). Following the above described acquisition process of Pain\/No \nPain EEG signal files, signal segments of 1s duration were extracted from the original EEG files, \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 8\ncorresponding to (a) \u201cPain\u201d signal states, represented by 1s intervals starting from the time of the pain \nstimulus, and (b) \u201cNo Pain\u201d signal states represented by 1s intervals centred at 1s before the \napplication of each pain stimulus. \n3. DM-HMM-D \nThe general structure of a one-feature discrete observation HMM network is shown diagrammatically \nin Figure 3.1. \n  Figure 3.1 here \nThere are N hidden states (nodes) {S1,S2,\u2026,SN} in the model and M possible observations can be \ngenerated by the model. At every time step one of the states, say Sj, is entered based on the state \ntransition probability {aij} that depends on the previous state Si. After each transition is made, an \nobservation, say the m-th observation om, is produced from Sj with corresponding observation \nprobabilities {bj(om)}, note that the initial state probabilities are defined as {\u03c0i}. A compact notation \n\u03bb={{aij},{bj(om)},{\u03c0i}} is set to indicate the complete model parameters. Therefore, the probability of \nan given observation sequence O={o1,o2,\u2026,oT} in the period of time T can be calculated by tracing the \npaths Q={q1,q2,\u2026,qT} (Viterbi paths) which offer the maximum likelihood probability P(O|\u03bb). \nEquation 3.1 shows the result of multiplying all the probabilities that the Viterbi path passes through. \nNote that f(\u03c0,a) is a function of initial probabilities and state transition probabilities. \n\u220f\u220f\n1)(\n)(\n2)(\n)(1\n21\n)(),()()(\n)()()()|(\n)()()(1-)(11\n12111\nT\nk\nkq\nT\nk\nkqqqqq\nTqqqqqqq\nobafobaob\nobaobaobOP\nkkkk\nTTT\n==\n==\n== \u2212\n\u03c0\u03c0\n\u03c0\u03bb L\n (3.1) \nA novel multiple HMMs system architecture (named DM-HMM-D, Figure 3.2) is introduced that \ncomputes the weights attached to different sequences of observations prior to the operation of HMM \nmodels. Figure 3.2 (a) shows the conventional IM-HMM-D model framework and the final \nprobability likelihood in the IM-HMM-D is computed as shown in Equation 3.2 which assumes that \nthe i-th observation sequence O(i) and the remaining observation sequences {O(1),O(2),\u2026,O(c),\u2026,O(C)}, \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 9\nc\u2260i are independent.  \nFigure 3.2 here  \nIn this case C features {o(k)(1),o(k)(2),\u2026o(k)(C)} are available, at a given time k, the system employs C \nHMM parameter sets {\u03bb1,\u03bb2,\u2026, \u03bbC} and the total likelihood probability P(O|\u03bb) is given as: \n\u220f\n1\n)|)(()|(\nC\ni i\niOPOP\n=\n= \u03bb\u03bb  (3.2) \nThis conditional independence is stated as \n)|(=),|( )()( i\ni\ni\ni \u03bbOPY\u03bbOP  (3.3(a)) \nwhere O(i)={o1(i),\u2026,oT(i)} is the observation sequence of the i-th feature and \nY={O(1),O(2),\u2026,O(c),\u2026,O(C)}, c\u2260i are the observation sequences of the remaining features. \nIn Figure 3.2 (b), different sequences of observations are considered to be \u201clinked\u201d in a vertical \nmanner by assuming that a weighting function is introduced to each model. The output probability of \nthe i-th model is rewritten as )()\u02c6|( )( OwOP iii \u03bb , where i\u03bb\u02c6  is the new HMM parameter set for the i-th feature. \nEquation (3.2) can be rewritten as: \n\u220f\n1\n)( ))()\u02c6|(()\u02c6|(\nC\ni\nii\ni OwOPOP\n=\n=\u2032 \u03bb\u03bb  (3.3(b)) \nwhere wi(O) is designed to be the conditional probability of O(i) given Y, i.e. the probability of the \nobservation sequence of the i-th feature given the observation sequences of the remaining features. \n)|(=)( )( YOpOw ii  (3.3(c)) \nThe system shown in Figure 3.2(b) now takes the form shown in Figure 3.2(c) that can be also \ndepicted as in Figure 3.2 (d). This new Multi HMM model structure is named as DM-HMM-D, to \ndistinguish it from the conventional IM-HMM-D scheme. Since the weight function wi(O) and the \nconventional HMM structure are now effectively combined, the HMM training and testing procedures \nmust be adjusted appropriately. \nConsidering Equations (3.3(b)), (3.3(c)) and (3.2), the conditional probability )\u2032\u02c6|( )( ii \u03bbOp  can be rewritten \nas: \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 10\n\u220f\n\u220f \u220f\n1=)(\n)(\n)(\n)(\n)(\n)(\n)()()(\n1=)( 1=)(\n)(\n)(\n)(\n)(\n)(\n)()()(\n)()()(\n)|()(),(=\n)|()(),(=\n)|()\u02c6|(=) \u2032\u02c6|(\n)(\n)(\nT\nk\nk\ni\nk\ni\nk\ni\nq\nii\nT\nk\nT\nk\nk\ni\nk\ni\nk\ni\nq\nii\ni\ni\ni\ni\ni\nyopoba\u03c0f\nyopoba\u03c0f\nYOP\u03bbOP\u03bbOP\nk\nk\n \n(3.4) \nwhere the product terms represent the transitional probabilities of the new model, i.e. \n)|()(=)\u2032( )()( )()( )()()( )()( kikikijikij yopobob  (3.5) \nIt can be seen that the conditional independent probability P(O(i)|Y) will only affect observation \ntransition probability {bj(i)(o(k)(i))}. Therefore DM-HMM-D can be implemented by replacing \n{bj(i)(o(k)(i))} with the probability {bj(i)(o(k)(i))\u2019} at each time step (k). \n{bj(i)(o(k)(i))\u2019} is calculated using Equation (3.5) with the help of a pre-defined (during the training \nprocedure) \u201cdependency\u201d codebook that contains p(o(k)(i)|y(k)) estimates. In particular, p(o(k)(i)|y(k)) \nestimates are obtained using: \niz\niViUh\nOOh\nTiViUh\nTOOh\nyp\nyop\nooooopyop\nK\nk\nT\nk\nkkk\nK\nk\nT\nk\nkkk\nK\nk\nk\nK\nk\nT\nk\nkkk\nK\nk\nK\nk\nk\nT\nk\nkkk\nk\nk\ni\nkC\nk\nc\nkkk\ni\nkk\ni\nk\nk\nk\nk\nk\n\u2260,\n))(),((\n),(\n\/))(),((\n\/),(\n)(\n),(\n})),,,,,({|()(\n\u2211 \u2211\n\u2211 \u2211\n\u2211\u2211 \u2211\n\u2211 \u2211\u2211\n1 1)'(\n)()'(,\n1 1)'(\n)()'(,\n11 1)'(\n)()'(,\n1 11)'(\n)()'(,\n)(\n)(\n)(\n)()(\n)(\n)(\n)(\n)2(\n)(\n)1(\n)(\n)(\n)()(\n)(\n)(\n= =\n= =\n== =\n= == ==\n== LL\n \n(3.6) \nwhere Uk,(k)\u2019(i)={ok,(k)\u2019(1),ok,(k)\u2019(2),\u2026,ok,(k)\u2019(c),\u2026,ok,(k)\u2019(C)} and V(k)(i)={o(k)(1),o(k)(2),\u2026,o(k)(c) ,\u2026,o(k)(C)} with    \nc\u2260 i are calculated as the expected number of times in observing V(k)(i) for all Uk,(k)\u2019(i) in K training \ndata sets, k={1,2,\u2026,K}. The counting function h(a,b) is equal to one if and only if {a=b}, otherwise its \nvalue is zero. \nThe model evaluation and estimation procedures used in DM-HMM-D are effectively those \ndeveloped for conventional HMM-D structures with the simple replacement of {bj(i)(o(k)(i))} with \n{bj(i)(o(k)(i))p(o(k)(i)|y(k))}. \n3.1 Model Evaluation \nThis involves an efficient forward-backward procedure, which takes only O(TN2) operations with \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 11\nsequence length T and state number N.  \nThe forward algorithm incorporates the following steps: \n\u2022 Initialization: \nNiyopobi ii \u2264\u22641),|()()( 1111 \u03c0\u03b1 =  (3.7) \n\u2022 Induction: \nNjTkyopobaij kkkj\nN\ni\nijkk \u2264\u22641,\u2264)(\u22641),|()(])([)( 1)(1)(1)(\n1\n)(1)( \u2211 +++\n=\n+ = \u03b1\u03b1  (3.8) \n\u2022 Termination: \n\u2211\n1=\n)(=),|(\nN\ni\nT i\u03b1\u03bbYOP  (3.9) \nwhere the forward variable \u03b1(k)(i) is defined as \u03b1(k)(i)=P(o1 o2\u2026 o(k) , q(k)=Si\/,\u03bb)p(o(i)\/y(k)). This \nformulation of the forward probability calculation is based on a lattice structure and is efficient since \nthe calculation of the forward variable \u03b1(k)(i) involves only N previous values of \u03b1(k)-1(i) [4]. \nThe backward part of the process is similar to the Forward procedure with, \n\u2022 Initialization: \nNiiT \u2264\u22641,1)( =\u03b2  (3.10) \n\u2022 Induction: \n1,...,2,1=)(;\u2264\u22641),(])|()([=)( 1+)(\n1=\n1+)(1+)(1+)()( \u2211 TTkNij\u03b2yopobai\u03b2 kN\nj\nkkkjijk  (3.11) \n\u2022 Termination: \n\u2211\u2211\n1= 1=\n1+)(1+)(1+)(1+)()( )()|()()(=),|(\nN\ni\nN\nj\nkkkkjijk j\u03b2yopobai\u03b1\u03bbYOP  (3.12) \nwhere the backward variable \u03b2(k)(i) is defined as \u03b2(k)(i)=P(o(k)+1.. oT+2\u2026 oT| q(k)=Si,, \u03bb) p(o(i)\/y(k)). \n3.2 Model Estimation \nThe probability of P(O|Y, \u03bb)  is maximized via an iterative estimation process. Thus HMM parameter \nsets (models) are calculated using the EM algorithm [7] with E and M steps operating over an initial \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 12\nmodel, noted as },,{= \u03c0BA\u03bb  and a re-estimated model },,{= \u03c0BA\u03bb . The expectation step E \ninvolves the calculation of Baum\u2019s auxiliary function ),( \u03bb\u03bbQ ) whereas the M (modification) step is \nthe maximization over \u03bb . Re-estimation of a parameter set using K training data streams involves: \n\u2211\n1=\n)()(\n)(\n1\n)(\n1\n),|(\n)()(\n=\nK\nk\nkk\nkk\ni \u03bbYOP\ni\u03b2i\u03b1\n\u03c0  (3.13) \n\u2211 \u2211\n\u2211 \u2211\n1\n1-\n1\n)()(\n1\n1-\n1\n)(\n1\n)(\n1\n)(\n1\n)(\n1\n)()(\n)()(1\n)()|()()(1\nK\nk\nT\nt\nk\nt\nk\nt\nk\nK\nk\nT\nt\nk\nt\nk\nt\nk\nt\nk\nt\nk\njij\nk\nt\nk\nij k\nk\nii\nP\njyopobai\nP\na\n= =\n= =\n++++\n=\n\u03b2\u03b1\n\u03b2\u03b1\n (3.14) \n\u2211 \u2211\n\u2211 \u2211\n1\n1-\n1\n)()(\n1\n1-\n..\n1\n)()(\n)()(1\n)()(1\n)(\n)(\nK\nk\nT\nt\nk\nt\nk\nt\nk\nK\nk\nT\nots\nt\nk\nt\nk\nt\nk\nj k\nk\nk\nt\nii\nP\nii\nP\nb\n= =\n=\n=\n=\n=\n\u03b2\u03b1\n\u03b2\u03b1\nll  (3.15) \nIn DM-HMM-D parameter sets i\u03bb\u02c6={\u03c0(i),a(i),b(i)}, i=1,\u2026,C, are determined during training while using \n{bj(i)(ot(i))p(ot(i)|yt)} instead of {bj(i)(ot(i))} [14,15]. Following training, and during testing (i.e. when \nusing the derived system to perform classification of input signals) the required probability P(O(i)|Y) \nfor each input testing data stream is obtained from a pre-designed dependency codebook. \n4. E-CLASS \nAs mentioned earlier, the relevance of the results produced by an off-line classification technique will \nbe limited to the degree of representativeness of the training data. The applicability of such an off-line \ntrained classifier to new data sets is limited and therefore, the design of incrementally evolvable \nclassifiers is an attractive alternative. Evolvable fuzzy-rule-bases have been recently developed and \nsuccessfully applied to clustering [26], time-series prediction [14,15], and neuro-fuzzy systems [24]. \nIn this paper this concept [19] is extended to the on-line signal classification. The resulting novel \napproach called eClass is based on an evolvable rule base, which is composed of fuzzy rules of the \nfollowing form: \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 13\nRulej: IF (EEG 1 is EEG\n*\n1\nj ) AND \u2026AND (EEG n  is EEG\n*j\nn ) THEN (Class is Pain\/No Pain)     (4.1) \nwhere EEG i  denotes the electroencephalogram signal produced by the i\nth channel, i=1,2,\u2026,n; in this \nparticular application n=2, i.e. only the two most informative channels are employed (see \ndiagram representing the importance of all 64 channels in Figure 5.2). These channels have \nbeen identified according to the wi(O) weight values of input features (indicating the relative \nimportance of corresponding channels) as estimated by the system described in section 3; \nEEG *ji denotes the j\nth prototypical EEG signal of the ith input (channel), i=1,2,\u2026n; j=1,2,\u2026, \nRk rules, k=1,2,\u2026 ,m \nR is the number of fuzzy rules; \nm is the number of classes (in this particular application m=2, namely: \u201cPain\u201d and \u201cNo Pain\u201d) \nClass is the output of the classifier (in this particular application it is a binary variable with \nvalues Pain\/No Pain. \nThis overall rule base comprises of m sets of fuzzy rules \u2013 one per class, see Figure 4.1 where two sets \nof prototypical EEG signals are depicted \u2013 one for the class \u201cPain\u201d (Figure 4.1 (a)) and another for the \nclass \u201cNo Pain\u201d (Figure 4.2 (b)).  \nFigure 4.1 (a) and (b) here. \nThe fuzzy rule base is designed in on-line mode via supervised learning starting \u201cfrom scratch\u201d. It \nselects the first measured EEG signal as a prototype. Then, starting from the next measured EEG \nsignal, an accumulated proximity measure (called potential, [14, 19]) is calculated recursively and the \nrule-base is incrementally updated. The potential, P is inversely proportional to the sum of Euclidean \ndistances between a particular EEG signal and all other EEG signals. The value of the potential will \nbe higher for these EEG signals that are similar to a large number of other EEG signals. It should be \nnoted that in contrast to evolving clustering [26], evolving time series prediction [14], and evolving \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 14\nmodeling [15,22] techniques, in eClass the potential is calculated with respect to the inputs (discrete \nEEG signals) only. Class labels (classifier outputs) are not included in the calculation of P. \nThe overall classification is performed based on the so called \u2018winners take all\u2019 principle [27], \nwhich corresponds to the MAX t-norm used to produce a defuzzification (note that the same is also \nused in Mamdani type fuzzy models) [18].  \n( )jRjk kyy \u03bb1maxarg; ===         (4.2a) \n\u2211\n=\n=\nR\nj\njj yy\n1\n\u03bb          (4.2b) \nwhere yk represents the kth class, k=1,2,\u2026m \n\u2211\n=\n= R\ni\ni\nj\nj\n1\n\u03c4\n\u03c4\u03bb  is the normalized firing level of the jth rule, j=1,2,\u2026R. \n( )\u2211 \u2211= = = \u2212\u2212\nn\ni\nL\nl\nl\nj\nl\ni xx\nj e 1 1\n2*\u03b1\u03c4 is the firing rule of the jth fuzzy rule; j=1,2,\u2026,R; \nl\njx is the jth sampled EEG signal; \n*\njx is the jth prototypical EEG signal based on which the jth fuzzy rule antecedent is formed; \n\u03b1=4\/r 2 is a positive constant which defines the spread of the membership function of the \nfuzzy sets which are of Gaussian type; \nr is the radius that defines the zone of influence of the fuzzy rules; \nL denotes the length of the discrete EEG signal. \nIn Figure 4.2 a snap-shot, at given time instant k, of a 2-feature space is presented and two classes \n(Pain and No Pain) are shown with different types of lines. It is important to mention that the \nclassification of EEG signals is performed based on similarity using the whole length of the EEG \nsignal (l=1,2,\u2026,L), whereas this Figure represents information related to a certain time instant.  \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 15\nFigure 4.2 here \nThe input data space in eClass is clustered on a per class basis. For each class the algorithm \nforms a partial rule-base, which consists of Rk rules (k=1,2,\u2026 ,m). These class-related partial rule-\nbases are then combined to form the overall rule-base R of the eClass process. In this way, the total \nnumber of fuzzy rules that form the evolvable classifier R is equal to the sum of fuzzy rules that form \nthe partial rule-sets associated with each class, see Figure 4.3: \nR= R1+R2+\u2026+Rm         (4.3) \nFigure 4.3 here \nIt should be mentioned that the system learning and the testing procedures are performed in on-line \nmode. EEG signals are first presented to eClass for classification and then (given the ground \ntruth\/label) the same EEG signals are used to update or upgrade the partial rule-base, Rk of the (kth) \nclass. \nIn eClass training, EEG signals are collected continuously. Some signals reinforce and confirm \nthe information contained in the classifier. Other input signals provide new information, which may \nbe important enough to form a new fuzzy rule or to modify an existing one. The value of the \ninformation they contain can be measured by their potential, P. Two main potentials are calculated \nrecursively: \na) the potential of a EEG signal that is to be used as a new prototype; \nb) the potential of the existing prototype EEG signals. \nThus the potential of a new EEG signal to be a prototype of class j can be calculated recursively by \n[26]: \n[ ]\n)()(2))(1)(1(\n1)(\nkgkhkbk\nkkxPk +\u2212+\u2212\n\u2212=  ; k=2,3,\u2026    (4.4) \nwhere ))(( kxPk denotes the potential of the EEG signal x(k) calculated at the moment k;  \n \u2211\u2211+\n= =\n=\n1\n1 1\n2))(()(\nn\nj\nL\nl\nl\nj kxkb ;   ( )\u2211 \u2211\u2211\u2212\n=\n+\n= =\n=\n1\n1\n1\n1\n2\n1\n)()(\nk\ni\nn\nj\nL\nl\nl\nj ixkg      \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 16\n\u2211\u2211+\n= =\n=\n1\n1 1\n)()()(\nn\nj\nL\nl\nl\nj\nl\nj kpkxkh ;  \u2211\u2211\u2212\n= =\n=\n1\n1 1\n)()(\nk\ni\nL\nl\nl\nj\nl\nj ixkp  \nParameters b(k) and h(k) are calculated from the current EEG signal x(k), while ljp (k) and \ng(k) are recursively updated by \n\u2211\u2211+\n= =\n\u2212+\u2212=\n1\n1 1\n2))1(()1()(\nn\nj\nL\nl\nl\nj kxkgkg ; )1()1()( \u2212+\u2212= kxkpkp ljljlj  \nA new input EEG signal is influencing the potentials of the established prototypes ( *jx , \nj=1,2,\u2026,R), because by definition potentials depend on the distance to all of the input signals, \nincluding the new one. The potential of a prototype ( *jx ) at the moment k can be calculated as \n[26]: \n( )\n\u2211\u2211\u2211\u2212\n=\n+\n= =\u2212+\n= 1\n1\n1\n1 1\n2\n*\n)),((\n1\n11\n1)( k\np\nn\ni\nL\nl\ni\nl\nj\npjd\nk\nkxP ; k=2,3,\u2026     (4.5) \nwhere ( ))(* kxP j  is the potential of the at the moment k of the cluster, which is a prototype of \nthe jth rule; \n),( pjd il .is the distance calculated at the l\nth sample between the pth EEG signal and the \njth prototype (cluster centre) for the ith channel. \nSimilarly, for the time instant k-1 we have: \n( )\n\u2211\u2211\u2211\u2212\n=\n+\n= =\u2212+\n=\u2212 2\n1\n1\n1 1\n2\n*\n)),((\n2\n11\n1)1( k\np\nn\ni\np\nl\ni\nl\nj\npjd\nk\nkxP ; k=3,4,\u2026     (4.6) \nThus the potential of an existing prototype EEG signal can be expressed recursively from its   \npotential value at the previous time instant (i.e. before the new data sample is available) as: \n( ) ( ) ( ) ( )\u2211\u2211+\n= =\n\u2212\u2212++\u2212\n\u2212\u2212= 1\n1 1\n2**\n*\n*\n)1,()1()(2\n))1(()1(\n)( n\ni\nL\nl\ni\nljj\nj\nj\nkkdkxPkxPk\nkxPk\nkxP     (4.7) \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 17\nThe on-line classification procedure can be summarised as follows: \n1. Accept the first EEG signal as the first prototype. This is used to form the antecedent part \nof the fuzzy rule and its potential is set to 1. \n2. Starting from the next EEG signal for all subsequent EEG signals the potential of each \nnew signal is calculated recursively using equation (4.4).  \n3. The potentials of existing prototypes are recursively updated using equation (4.7). \n4. The potential of the new EEG input signal is compared to the updated potentials of the \nexisting prototypes. Then \n(a)  If the potential of the new EEG signal is higher than the potential of the existing \nprototypes then the new EEG signal is added as a new prototype and a new rule is \nformed ( )(* kxx R = and the number of rules in the rule-base gradually increases \n(R:= R+1). The condition used in this case i.e. of having a \u201chigher\u201d potential, limits \nthe generation of excessively large rule base; \n(b) If in addition to the previous condition the new EEG signal is close to an old \nprototype then the new EEG signal, x(k) replaces this prototype ( )(:* kxx j = ). \nThis on-line clustering approach results in an evolving rule-base, by recursively upgrading and \nmodifying the rule-base at every instant of time while inheriting the bulk of the rules from the \nprevious time instant (R- of the rules are preserved even when a modification or an upgrade take \nplace). \n5. EXPERIMENTAL RESULTS AND DISCUSSION \nAs mentioned in section 2, EEG data were recorded on three different occasions from a healthy \nfemale subject and on each of these days; three EEG recordings were taken by directing a laser beam \non the right arm of the subject. In total, nine EEG data files were obtained. The first eight files were \nused to obtain the required \u201ctraining\u201d data whereas the last file provided data for \u201ctesting\u201d the \nclassification performance of the proposed systems.. \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 18\n The overall HMM based experimental procedure is shown in Figure 5.1 and involves the \nnetwork training\/design and system classification performance evaluation processes for the \nconventional IM-HMM-D structure and the new DM-HMM-D system. A useful by-product of the \nsecond technique is the instantaneous \u201cweight\u201d information that is attached by DM-HMM-D to each \ninput signal. This information reflects the importance of each EEG channel\/signal for achieving \nmaximum classification performance. Note that the number of hidden states of each HMM network in \nboth the IM-HMM-D and DM-HMM-D systems is N. This was experimentally fixed to N=10 whereas \nthe resolution of the input scalar quantization process used assumed values M=100, 50, 20 and 10 \npossible values. Notice that M is also equal to the number of different discrete observation values that \ncan be produced from a network state. \nTable 5.1 provides a comparative list of the classification performance results obtained from \nthe IM-HMM-D and DM-HMM-D schemes. When performance is calculated as an average value \nusing both classes, the IM-HMM-D system delivers 69.11765% with M=20; and a maximum \n72.0588% with M=10. The relatively low performance of IM-HMM-D in classifying pain can be \nexplained in terms of the substantial inter-dependencies which exist between certain channels and \nwhich this system fails to take into consideration. Considerably higher classification accuracy rates \nare obtained by applying the DM-HMM-D system, see Table 5.1. This improved performance is \nobtained for all values of M and the system operates best (with a performance in excess of 95%) with \nM values in the region of 20 to 50. Note that when several different models provide similar \nclassification performance, structure with lower values of M and N are  preferred due to lower system \ncomplexity. Thus the model with M=20 and N=10 is used below to obtain the \u201cusage rate\u201d for each \nEEG channel and hence an indication of the significance of each channel. \n Note that, some sequences can be completely blocked out, if necessary, from the resulting \nlikelihood probability P by setting a minimum threshold Wthreshold that operates during classification on \nP(O(i)|Y) values stored in the predefined \u201cdependency\u201d codebook. In the reported experiments, \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 19\nWthreshold =10-5. Figure 5.2 shows the usage rate of each input channel (feature) as calculated from a \nclassification experiment with DM-HMM-D. In this figure certain channels (for example, Channels 4, \n6, 15, 16, 39, 48, 49, 51, and 58) are heavily involved in the classification of both Pain and No Pain \nconditions. In general, this input channel categorization methodology can be particularly useful to \nresearchers interested in the reduction of the number of input channels (features) presented at the \ninput of a classifier with a carefully controlled effect on classification performance.  \nExperimentation with the novel eClass system involved a data-set of 355 Pain and 355 No-Pain \nepochs, in order to produce the fuzzy rule-base of the classifier. As before, these epochs came from \nthe first 8 out of the available 9 EEG data-sets (experiments). Thus 710 signal epochs were introduced \nto the system together with their respective Pain\/No Pain labels, (ground-truth). It should be noted that \nthe eClass approach does not need to be pre-trained, but in order to compare the performance of the \ntwo methods; the same experimental conditions were used here. In this way the system produced a \n\u201crule-set\u201d for each of the Pain and No-Pain conditions, by comparing spatial proximities between \nsignals of the same class. Following the merging of these two individual \u201crule-sets\u201d, the system was \nready to classify unknown signals based on the \u201cglobal rule-set\u201d that contained a total of 168 \nprototypical EEG signals (rules). \nIn order to test the classification efficiency of the resulting system, 34 epochs from each class \ntaken from the 9th data-set that was used for testing the system, were presented to eClass. \nClassification was thus performed by comparing the distances formed between the input test EEG \nsignals and the prototypes stored in the \u201crule-set\u201d. \nTwo different approaches were then used in order to arrive at the required classification decision: \n1. A \u201cwinner takes all\u201d classification approach (see equation 4.2a). \n2. A weighted average approach (see equation 4.2b). \nUsing the first approach, eClass yielded a respectable 79.45% average classification accuracy rate.  \nOverall classification accuracy is significantly lower (64%) when using the second approach. Thus \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 20\nexperimental results illustrated that employing the \u201caggressive\u201d winner-takes-all type of decision \noutperforms the version that is based on the weighted type of classification. It should be noted that a \nclassification accuracy of 88.24% is achieved for the No-Pain class whereas the corresponding result \nfor the Pain condition is 69.21%. This can be associated to the observation that the number of rules \nformed by the system when modelling No-Pain EEG signals is significantly larger than that of the \nPain case. Note that the eClass approach does not require the number of prototypes to be pre-\nspecified; instead prototypes are formed according to the characteristics of the input signals and as a \nresult of an evolving design procedure. The reason why more clusters and hence prototypes are \nobtained in the No-Pain case can be traced to the higher variance of the EEG signals recorded under \nthe Pain condition, as compared to those recorded under No-Pain. Higher variance (Figure 4.1b) leads \nto lower potentials (equation (4.4)) which in turn restricts the process of generating new prototypes.  \n6. CONCLUSIONS \nTwo novel and substantially different approaches to the problem of automatically deciding on the \nPain\/No Pain condition of a subject using EEG signals are introduced in the paper. The first approach, \nDM-HMM-D, is based on a new formulation of a bank of HMM with discrete density classifiers \nwhere each HMM operates on a different channel. Furthermore DM-HMM-D exploits any inter-\ndependencies that may exist between the EEG signals of different channels via the introduction per \nHHM model of a varying with time weighting function that represents the instantaneous importance \nof each channel. This system performs substantially better than the conventional IM-HMM-D \napproach and with a Pain\/No Pain classification accuracy of 94% and 97% respectively. Whereas this \nHMM based approach to EEG Pain\/No Pain condition classification requires off-line supervised \ntraining of the system, in order to specify the model parameters whose architecture is fixed (and \nshould be therefore determined via experimentation), the second classification approach, i.e. eClass, is \nfar more flexible and defines its fuzzy rule-based structure on line and in response to the input EEG \nsignals presented to the system during its training process. This evolving rule based characteristic  is a \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 21\nmajor asset of eClass and an important differentiator, with respect to other off-line, fixed structure \nclassification systems, since it opens up significantly the way that the classifier can be used in \npractical real-time applications. Furthermore experimental results clearly demonstrated the potential \nof the eClass system whose underlining methodology bears the promise of further significant research \ndevelopments on supervised on line classification systems. \n7. ACKNOWLEDGEMENTS \nThe authors acknowledge the use of the EEG data courtesy of Hope Hospital, Manchester. The second \nauthor acknowledges the partial support by the Lancaster University of grant \u2018EvoMAP\u2019 SBA 7662 \n REFERENCES  \n[1] J.R. Wolpaw, D.J McFarland, Multichannel EEG-based brain-computer communication, \nElectroencephalography and Clinical Neurophysiology 90, 444-449 (1994).  \n[2] S.W.G. Derbyshire, Jones A.K.P., \u201cCerebral responses to a continual tonic pain stimulus \nmeasured using positron emmision tomography\u201d, Pain 76 (1998) 127 \u2013 135. \n[3] P. Rappelsberger, Petsche H:  \u201cProbability Mapping: Power and Coherence Analyses of \nCognitive Processes\u201d, Brain Topography, 1988, 1: 46-54. \n[4] Chen A.-C.N., Rappelsberger P: \u201cBrain and Human Pain: Topographic and Coherence \nMapping\u201d, Brain Topography, 1994, 7, No 2: 129-140. \n[5] L.K.Stergioulas, Reoullas M., Xydeas C.S., Baltas E., Bentley D., Youell P., Jones A.: \n\u201cCoherence Pattern Classification Using LVQs For Pain Detection\u201d, Analysis of Biomedical \nSignals and Images, 16th Biennial International EURASIP Conference BIOSIGNAL 2002 \nProceedings, Vutium Press 2002: 56 \u2013 58. \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 22\n[6] D.E. Bentley., P.D. Youell., A.K.P. Jones.: \u201cAnatomical localization and intra-subject \nreproducibility of laser evoked potential source in cingulated cortex, using a realistic head \nmodel\u201d, Clinical Neurophysiology 113 (2002) 1351 \u2013 1356.  \n[7] J. Bilmes, A Gentle Tutorial of the EM Algorithm and its Application to Parameter Estimation \nfor Gaussian Mixture and Hidden Markov Models, Tech. Report, International Computer \nScience Institute, Berkeley, 1997. \n[8] L. R. Rabiner, A Tutorial on Hidden Markov Models and Selected Applications in Speech \nRecognition, Proc. of the IEEE, 77 (2), 257-286 (1989). \n[9] Z. Ghahramani, An Introduction to Hidden Markov Models and Bayesian Networks, \nInternational Journal of Pattern Recognition and AI, 15 (1), 9-42 (2001). \n[10] Y. Bengio, Markovian Models for Sequential Data, Neural Computer Surveys, Dept. of \nInformation and Research Operation, 2, 129-162 (1999). \n[11] M. A. Mohamed, P. Gader, Generalized Hidden Markov Models-Part I: Theoretical \nFrameworks, IEEE Transaction on Fuzzy Systems, 8 (1), (February 2000). \n[12] M. A. Mohamed, P. Gader, Generalized Hidden Markov Models-Part II: Application to \nHandwritten Word Recognition, IEEE Transaction of Fuzzy Systems, 8 (1), (February 2000). \n[13] K. F. Lee, Automatic Speech Recognition: the development of the SPHINX system, Kluwer \nAcademic Publish, (1989). \n[14] P. Angelov, D. Filev, An approach to on-line identification of evolving Takagi-Sugeno \nmodels, IEEE Trans. on Systems, Man and Cybernetics, part B, 34 (1), 484-498 (2004). \n[15] N. Kasabov, Q. Song, DENFIS: Dynamic Evolving Neural-Fuzzy Inference System and Its \nApplication for Time-Series Prediction, IEEE Trans. on Fuzzy Systems 10(2), 144-154 (2002). \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 23\n[16] S.-Y. Chiao, C. S. Xydeas, Using Hierarchical HMMs in Dynamic Behaviour Modelling, \nProceedings of Seventh International Conference on Information Fusion, Fusion 2004, \nStockholm Sweden, 576-582 (2004). \n[17] S.-Y. Chiao, C. S. Xydeas, Behaviour Modelling Using a Hierarchical HMM Approach, IEEE \nComputer Society Press Proceedings, (May 2005 to appear). \n[18] R. R. Yager, D. P. Filev, Essentials of Fuzzy Modeling and Control, NY: John Wiley (1994). \n[19] P.P. Angelov, Evolving Rule-based Models: A Tool for Design of Flexible Adaptive Systems, \nSpringer, Physica-Verlag, Heidelberg, Germany (2002). \n[20] R. O. Duda, D. G. Stork, P. E. Hart, Pattern Classification and Scene Analysis: Pattern \nClassification, 2nd edition, John Wiley, NY (2001). \n[21] J. Bezdek, Cluster Validity with Fuzzy Sets, Journal of Cybernetics, 3 (3), 58-71 (1974). \n[22] I. Gath, A.B. Geva, Unsupervised optimal fuzzy clustering, IEEE Trans, Pattern Analysis and \nMachine Intelligence, 7, 773-781 (1989). \n[23] S.L. Chiu, Fuzzy Model Identification based on Cluster Estimation, Journal of Intelligent and \nFuzzy Systems, 2, 267-278 (1994). \n[24] N. Kasabov, Evolving fuzzy neural networks for on-line supervised\/unsupervised knowledge-\nbased learning, IEEE Trans. SMC - part B, Cybernetics 31, 902-918 (2001). \n[25] D. Carline , P. Angelov, R. Clifford, Agile Collaborative agents for classification of under-\nwater targets, Undersea Defence Technology, 21-23 June 2005, Amsterdam, The Netherlands. \n[26] P. Angelov, An Approach for Fuzzy Rule-base Adaptation using On-line Clustering, \nInternational Journal of Approximate Reasoning, Vol. 35 (3), March 2004, Pages 275-289. \n[27] L. Kuncheva, How Good are Fuzzy If-Then Classifiers, IEEE Transactions on Systems, Man \nand Cybernetics-part B, Vol 30 (4) 501-509. \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 24\n \n \nFigure 2.1: EEG cap in its physical form mounted on the scalp of a subject  \n \n \n \n \nFigure 2.2: The 64-electrode cap and its relevant positions together with the channel names \n \n \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 25\n \nFigure 3.1: A general HMM structure with N hidden states and M possible observations per \nstate. \nS 1 S 2 S 3 SN\u2026\nO1 \nO2 \nOM \n:\nO 1 \nO 2 \nOM \n:\nO 1 \nO 2 \nOM\n:\nO1\nO2\nOM\n:\n\u2026\nStates\nObservations\nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 26\noT(1)\u2026o2(1)o1(1)\noT(2)\u2026o2(2)o1(2)\noT(C)\u2026q2(C)o1(C)\nHMM#1\nHMM#2\nHMM#C\nP(O(2)|\u03bb2)\n(a)\n\u2026\nP(O(C)|\u03bbC)\nP(O(1)|\u03bb1)\n \n \noT(1)\u2026o2(1)o1(1)\noT(2)\u2026o2(2)o1(2)\noT(C)\u2026q2(C)o1(C)\nHMM#1\nHMM#2\nHMM#C\n(b)\n\u2026\nP(O(1)|      )\n1\u02c6\u03bb\nP(O(2)|      )\nP(O(C)|      )\n2\u02c6\u03bb\nC\u03bb\u02c6  \n \noT(1)\u2026o2(1)o1(1)\noT(2)\u2026o2(2)o1(2)\noT(C)\u2026q2(C)o1(C)\nHMM#1\nHMM#2\nHMM#C\n(c)\nP(O(1)|O)\nP(O(2)|O)\nP(O(C)|O)\n\u2026\nP(O(1)|      )\n1\u02c6\u03bb\nP(O(2)|      )\nP(O(C)|      )\n2\u02c6\u03bb\nC\u03bb\u02c6  \n \noT(1)\u2026o2(1)o1(1)\noT(2)\u2026o2(2)o1(2)\noT(C)\u2026q2(C)o1(C)\nDM-HMM-D-2#1\n(d)\nDM-HMM-D-2#2\nDM-HMM-D-2#C\n\u2026\nP(O(1)|      )\n1\u02c6\u03bb\nP(O(2)|      )\nP(O(C)|      )\n2\u02c6\u03bb\nC\u03bb\u02c6  \nFigure 3.2: (a) a conventional IM-HMM-D, (b) (c) and (d) DM-HMM-D equivalent \nstructures. \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 27\n0 50 100 150 200 250 300 350 400 450 500\n-10\n-8\n-6\n-4\n-2\n0\n2\n4\n6\n8\n10\nPrototype of Class NoPain\nSampling Instances of the EEG signals\nA\nm\npl\nitu\nde\n in\n m\nic\nro\nvo\nlts\nEEG1\n1\nEEG2\n1\nSample  l\nEEG3\n1\nEEG4\n1\n \nFigure 4.1 (a)  Prototype EEG signals for the class No Pain for one of the channels \n0 50 100 150 200 250 300 350 400 450 500\n-15\n-10\n-5\n0\n5\n10\n15\nPrototype of Class Pain\nSampling Instances of the EEG signals\nA\nm\npl\nitu\nde\n in\n m\nic\nro\nvo\nlts\nEEG1\n1\nEEG4\n1\nEEG3\n1\nEEG2\n1\nSample  l\nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 28\nFigure 4.1 (b)  Prototype EEG signals for the class Pain for the same channel \n \nFigure 4.2 A snap-shot of the clustering for certain moment of time l after discretization \nof EEG signals for the two channels \n \nFigure 4.3: General Model of the  eClass scheme.  \n \n  \n \nEEG1 \nEEG2\n* \n* \n* \n* \n* \n* \nLegend: \n \n   Class \u2018Pain\u2019  \n \n    Class \u2018No-Pain\u2019 \n.\n   value of the EEG signal for time instant l \n*   value of the prototype for time instant l \n. . . \n. \n. \n. \n. . \n. \n. ..\n.\n.\n.. . \n..\n.\n   Class1    Classm \nEEG signal \nselected as a \nprototype for \nClass1 \nEEG signal \nselected as a \nprototype \nfor Classm \n    Classification result \n........ \nOverall Rule-\nbase \n1\n1R  \n1\n1R\nR  \nmR1  \nm\nRm\nR  \nEEG vector \nx\u2208RnxL \nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 29\n \n \n \nFigure 5.1: Design and evaluation procedures in EEG classification experiments using \nHMMs \n \n \n \n \n \n \nTable 5.1: Classification results for the IM-HMM-D and DM-HMM-D systems. \nClassification performance is expressed as the percentage of correctly classified EEG \nsegments \n \n \nTraining Data Set \nScale Quantization \n(M=100,50,20,10) \nTraining\nIM-HMM-D \nTraining\nDM-HMM-D \nIM - HMM - D \nParameter sets \nDM- HMM -D \nParameter sets\nTesting Data Set\nScale Quantization \n(M=100,50,20,10)\nIM-HMM-D\nRecognition Results\nIM-HMM-D \nParameter sets\nDM-HMM-D \nParameter sets\nDM-HMM-D\nRecognition Results\nSelected Channels \nInformation\n91.1765%52.9412% 91.1765% 47.0588%97.0588%40.5882%97.0588% 41.1765% IM - HMM - D \n94.1176%97.0588%\n50\nPain       No Pain\n97.0588% 91.1765% \n100 \nPain          No Pain \n92.9412%55.8824% 94.1176% 97.0588%DM - HMM - D\n10 \nPain         No Pain\n20\nPain \nScale \nModel        No Pain Formatted: Font:\n(Default) Arial, 11\npt\nPublished by Journal: Computers in Biology and Medicine  (ISSN: 0010-4825)  Volume \n36, Issue 10, Pages 1064-1083 Publisher: Elsevier Science B.V., Amsterdam. \n \n 30\n0 10 20 30 40 50 60\n0\n20\n40\n60\n80\n100\nIndex of Channel\nU\nsa\nge\n R\nat\ne \n(%\n)\n0 10 20 30 40 50 60\n0\n20\n40\n60\n80\n100\nIndex of Channel\nU\nsa\nge\n R\nat\ne \n(%\n)\nPain Signal\nNo-Pain Signal\n \nFigure 5.2: Channel usage rates in DM-HMM-D Pain\/No-Pain classification \n \n \n"}
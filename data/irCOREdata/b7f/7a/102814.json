{"doi":"10.1109\/ICME.2008.4607477","coreId":"102814","oai":"oai:epubs.surrey.ac.uk:2356","identifiers":["oai:epubs.surrey.ac.uk:2356","10.1109\/ICME.2008.4607477"],"title":"Frame concealment algorithm for stereoscopic video using motion vector sharing","authors":["Hewage, CTER","Worrall, S","Dogan, S","Kondoz, AM"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-06","abstract":"Stereoscopic video is one of the simplest forms of multi view video, which can be easily adapted for communication applications. Much current research is based on colour and depth map stereoscopic video, due to its reduced bandwidth requirements and backward compatibility. Existing immersive media research is more focused on application processing than aspects related to transfer of immersive content over communication channels. As video over packet networks is affected by missing frames, caused by packet loss, this paper proposes a frame concealment method for colour and depth map based stereoscopic video. The proposed method exploits the motion correlation of colour and depth map image sequences. The colour motion information is reused for prediction during depth map coding. The redundant motion information is then used to conceal transmission errors at the decoder. The experimental results show that the proposed frame concealment scheme performs better than applying error concealment for colour and depth map video separately in a range of packet error conditions","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:2356<\/identifier><datestamp>\n      2017-10-31T14:05:16Z<\/datestamp><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/2356\/<\/dc:relation><dc:title>\n        Frame concealment algorithm for stereoscopic video using motion vector sharing<\/dc:title><dc:creator>\n        Hewage, CTER<\/dc:creator><dc:creator>\n        Worrall, S<\/dc:creator><dc:creator>\n        Dogan, S<\/dc:creator><dc:creator>\n        Kondoz, AM<\/dc:creator><dc:description>\n        Stereoscopic video is one of the simplest forms of multi view video, which can be easily adapted for communication applications. Much current research is based on colour and depth map stereoscopic video, due to its reduced bandwidth requirements and backward compatibility. Existing immersive media research is more focused on application processing than aspects related to transfer of immersive content over communication channels. As video over packet networks is affected by missing frames, caused by packet loss, this paper proposes a frame concealment method for colour and depth map based stereoscopic video. The proposed method exploits the motion correlation of colour and depth map image sequences. The colour motion information is reused for prediction during depth map coding. The redundant motion information is then used to conceal transmission errors at the decoder. The experimental results show that the proposed frame concealment scheme performs better than applying error concealment for colour and depth map video separately in a range of packet error conditions.<\/dc:description><dc:date>\n        2008-06<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/2356\/1\/SRF002480.pdf<\/dc:identifier><dc:identifier>\n          Hewage, CTER, Worrall, S, Dogan, S and Kondoz, AM  (2008) Frame concealment algorithm for stereoscopic video using motion vector sharing   Multimedia and Expo, 2008 IEEE International Conference on.  485 -488 - 485 -488.      <\/dc:identifier><dc:relation>\n        http:\/\/ieeexplore.ieee.org\/search\/srchabstract.jsp?tp=&arnumber=4607477&queryText%3DFRAME+CONCEALMENT+ALGORITHM+FOR+STEREOSCOPIC+VIDEO+USING+MOTION+VECTOR+SHARING%26openedRefinements%3D*%26searchField%3DSearch+All<\/dc:relation><dc:relation>\n        10.1109\/ICME.2008.4607477<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/2356\/","http:\/\/ieeexplore.ieee.org\/search\/srchabstract.jsp?tp=&arnumber=4607477&queryText%3DFRAME+CONCEALMENT+ALGORITHM+FOR+STEREOSCOPIC+VIDEO+USING+MOTION+VECTOR+SHARING%26openedRefinements%3D*%26searchField%3DSearch+All","10.1109\/ICME.2008.4607477"],"year":2008,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"FRAME CONCEALMENT ALGORITHM FOR STEREOSCOPIC VIDEO USING \nMOTION VECTOR SHARING \n \nC.T.E.R. Hewage, S. Worrall, S. Dogan, and A.M. Kondoz \n \n I-LAB, CCSR, University of Surrey, Guildford, Surrey, GU2 7XH, UK. \n \nABSTRACT \n \nStereoscopic video is one of the simplest forms of multi \nview video, which can be easily adapted for communication \napplications. Much current research is based on colour and \ndepth map stereoscopic video, due to its reduced bandwidth \nrequirements and backward compatibility. Existing \nimmersive media research is more focused on application \nprocessing than aspects related to transfer of immersive \ncontent over communication channels. As video over packet \nnetworks is affected by missing frames, caused by packet \nloss, this paper proposes a frame concealment method for \ncolour and depth map based stereoscopic video. The \nproposed method exploits the motion correlation of colour \nand depth map image sequences. The colour motion \ninformation is reused for prediction during depth map \ncoding. The redundant motion information is then used to \nconceal transmission errors at the decoder. The experimental \nresults show that the proposed frame concealment scheme \nperforms better than applying error concealment for colour \nand depth map video separately in a range of packet error \nconditions.  \n \nIndex Terms\u2014Depth-image-based rendering, Frame \nconcealment, Motion vector sharing, Stereoscopic video \n \n1. INTRODUCTION \n \nStereoscopic video (SSV) renders two slightly different \nviews of a scene, one for each eye, to enable the perception \nof depth. Recently, colour and depth map based SSV has \nbeen widely used in research and standardization activities \n[1,2]. Monoscopic video together with its associated per-\npixel depth map can be used to scale existing video \ncommunication applications into SSV with low overheads \n[3]. This format is more flexible and adaptable compared to \nstorage and transmission of the left and right views at low \nbitrates [4]. \n Depth map sequences typically have the same spatial \nresolution as colour video, and only contain a single plane of \nluminance data (see Fig. 1). The per-pixel depth value \ndetermines the position of the associated colour texture in \nthe 3-D space. A specialized image warping technique \nknown as the Depth-Image-Based Rendering (DIBR) is used \nto synthesize the desired binocular viewpoint image [5]. As \nthe motion of colour images and corresponding depth \ninformation is highly correlated, the colour motion \ninformation can thus be used as candidate motion \ninformation for the depth video. Hence, the bandwidth for \nlow bitrate SSV applications can be reduced as motion \nvectors (MVs) are transmitted only once. Furthermore, this \nreduces the encoding time and complexity of the SSV \nencoder. The analysis of motion correlation of \u2018colour and \ndepth\u2019 sequences and a MV sharing scheme based on \nMPEG-2 and H.264\/AVC is described in [6] and [7], \nrespectively. These developments are mainly focused on \nreducing the bandwidth, complexity and encoding time of \nthe SSV encoder. This paper exploits the correlation of \nmotion to conceal the frame losses that occur during \ntransmission of the SSV. \n \n \nFig. 1. \u2018Interview\u2019 sequence: (a) Colour image, (b) Per-pixel \ndepth image. The depth-images are normalized to a near \nclipping plane Znear and a far clipping plane Zfar \n \nThe transmission of high resolution 3-dimensional (3-D) \nvideo is studied for broadcast (DVB) and Internet Protocol \n(IP) based streaming video applications in [8]. Streaming 3D \nvideo over IP networks may lead to degraded quality due to \nframe losses. The effect of frame losses on the perceived \nquality of reconstructed 3-D video may be worse compared \nto that of conventional video (i.e., 2-D video) applications. \nHence, efficient error concealment algorithms are required \nto improve the reconstructed quality of streamed 3-D video. \nError concealment has been performed for left and right \nview based SSV using the additional data from the \ncorresponding image sequence [9,10]. This paper uses the \nshared MVs of the corresponding view (Colour or depth \nmap video) to conceal the lost frames. The proposed scheme \n485978-1-4244-2571-6\/08\/$25.00 \u00a92008 IEEE ICME 2008\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 16,2010 at 10:56:08 UTC from IEEE Xplore.  Restrictions apply. \nreuses the colour MVs during depth map encoding, and this \ninformation is transmitted in both colour and depth bit-\nstreams as redundant data in order to conceal transmission \nerrors. Lost frames are then concealed using the correctly \nreceived MVs of the corresponding colour or depth map \nframes accordingly.  \nThe paper is organized as follows. Section 2 elaborates \non the proposed frame concealment method based on \nscalable video coding (SVC) architecture. The experimental \nsetup, results obtained and discussion of those results are \ngiven in Section 3. Section 4 concludes the paper. \n \n2. FRAME CONCEALMENT USING SHARED \nMOTION VECTORS \n \nThe proposed MV sharing scheme for frame concealment is \nimplemented using the SVC layered encoding architecture, \nas shown in Fig. 2. The colour and depth information is \nencoded at the base and enhancement layers, respectively. \nThe scalable extension of H.264\/AVC is modified to \nimplement the MV sharing scheme [11]. This SVC \narchitecture is backward compatible to colour video as \nH.264\/AVC compatible base layer can be decoded using a \nstandard H.264\/AVC decoder. A performance analysis of a \nbackward compatible SVC encoding configuration for SSV \nis discussed in [12].  \n \n \n \n \n \n \n \n \n \n \n \n \n \nFig. 2. The MV sharing architecture based on SVC \n \nFor the colour image sequence, one MV is generated for \neach macroblock (MB) using the motion estimation process. \nTwo encoding modes are used to perform rate-distortion (R-\nD) optimization during depth map coding, namely \u2018MB skip\u2019 \nand \u2018Motion compensation\u2019. As large numbers of MBs in the \ndepth image sequence have a uniform texture without high \nfrequency components, the \u2018MB skip\u2019 mode is used to \nincrease the compression efficiency. The \u2018Motion \ncompensation\u2019 mode does not perform motion estimation. \nInstead, it reuses the MVs of the corresponding colour \nimage MBs to predict the current depth image at the \nenhancement layer. Then, the difference between the \npredicted and original frames is transform coded. The \n\u2018Motion compensation\u2019 mode is performed faster than \nconventional motion compensation modes as motion \nestimation does not take place during depth map coding. \nFinally, an R-D optimized encoding mode is selected to \nencode the MBs of the depth image. Hence, the global SVC \nbit-stream consists of both base and enhancement layer \nunits, which include headers, shared MVs and coded \nresidual texture data. \nThe overhead added due to the depth information needs \nto be kept at a smaller percentage of its corresponding \ncolour video. Due to the areas where the motion of colour \nand depth map is not highly correlated, the proposed MV \nsharing method imposes a bit budget penalty during depth \nmap coding. However, high quality depth maps can be \nobtained by adjusting the depth information percentage \nwithin an acceptable percentage of colour bitrate. Thus, the \naverage depth bitrate is kept below 25% of its corresponding \ncolour video bitrate. \n \n \n \n \n \n \n \nFig. 3. Frame concealment using shared MVs \n \nThe proposed frame concealment scheme using shared \nMVs is shown in Fig. 3. If a colour video frame is missing \ndue to packet losses, the MVs of the lost frame can be \nrecovered using the correctly received corresponding depth \nvideo frame. Similarly, when a depth frame is lost, then the \nMVs can be recovered from the uncorrupted corresponding \ncolour video frame. The recovered MVs from the \ncorresponding view are used to predict the current frame. \nThe quality of the reconstructed images are lower compared \nto that of error free decoding as residual information is not \nused during reconstruction. However, the motion of the \nreconstructed sequences will be intact and error propagation \nwill be minimized by this proposed method. If both \ncorresponding video frames are lost, then a conventional \nframe concealment algorithm needs to be used to recover the \nlost frames. The proposed scheme improves the image \nquality of both colour and depth map video, and thus \nultimately improves the perception of depth in SSV. \n \n3. EXPERIMENTS AND RESULTS \n \nTwo colour and depth map sequences are used for the \nexperiments, namely \u2018Orbi\u2019 and \u2018Interview\u2019. \u2018Orbi\u2019 is a very \ncomplex sequence with camera motion and multiple objects, \nwhereas \u2018Interview\u2019 is a sequence captured with a static \ncamera and featuring a stationary background. The tests are \ncarried out using standard definition (SD) TV resolution \n(720x576 pixels) videos. The test sequences are encoded \nusing the modified JSVM codec version 9.4. The basic \nSVC Encoder \n \n \n \n Colour  \n   MVs                 \nBase layer \nEncoder \nEnhancement \nlayer encoder \nColour \nDepth \n. . . \n. . . \nMVs \nMVs \n#1 Depth frame #2 Depth frame \n#1 Colour frame #2 Colour frame \n486\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 16,2010 at 10:56:08 UTC from IEEE Xplore.  Restrictions apply. \nencoding parameters are: 100 frames, IPPP\u2026 sequence \nformat, 25 frames\/s original frame rate, a single reference \nframe and Content Adaptive Binary Arithmetic Coding \n(CABAC). In order to accommodate SD resolution colour \nand depth map video, the average SVC encoder bitrate is set \nto 2Mbps. The quantization parameter (QP) of both layers is \nindependently varied to obtain the target bitrate. The depth \nbitrate is kept below 25% of its corresponding colour video \nbitrate. For each test sequence two SVC bit-streams are \ngenerated using separate MV estimation at both layers and \nthe proposed MV sharing method. The image qualities of the \ngenerated SVC bit-streams using separate MVs and the \nproposed MV sharing scheme are shown in Table 1. Due to \nthe areas of uncorrelated motion, the image quality with the \nproposed MV sharing is comparably lower compared to the \nimage quality with separate MVs at the given bitrate.  \n \nTable 1: Image quality of \u2018Orbi\u2019 and \u2018Interview\u2019 at 2Mbps \nOrbi Interview \n Colour \nPSNR\/dB \nDepth \nPSNR\/dB \nColour \nPSNR\/dB \nDepth \nPSNR\/dB \nSeparate MVs 40.13 38.10 41.05 42.34 \nProposed MV \nsharing scheme \n39.69 37.25 41.05 40.27 \n \nThe IP error patterns generated for the Internet video \nexperiments are used to corrupt the generated SVC bit-\nstreams at different packet loss rates [13]. Each coded video \nframe is encapsulated in a single network abstraction layer \n(NAL) unit and fragmented into packets of 1400 bytes, \nwhich is below the Internet's Maximum Transfer Unit \n(MTU) size of 1520 bytes. The first fragment contains the \nimportant header data of the frame NAL unit. Hence, if the \nfirst fragment of a frame is lost, it is assumed that the whole \nframe is lost, as the header data is unrecoverable without \nadding redundant information. Furthermore, it is assumed \nthat the sequence headers and the first I frame of both colour \nand depth image sequences are received uncorrupted. The \ncorrupted bit-streams are later decoded using a JSVM \ndecoder. The bit-streams generated using the separate \nmotion estimation processes are concealed using frame \ncopying. In frame copying, if the current frame is corrupted, \nthe previously decoded frame is copied to the current frame \nposition. Initially, for the bit-streams generated using the \nMV sharing scheme, the corrupted frames are concealed \nusing frame copying. Then, the lost frames are concealed \nusing the proposed frame concealment technique. The \nproposed technique uses the duplicated MVs from the \ncorresponding depth or colour frame. If the corresponding \nMVs are also corrupted, then frame copying is used to \nconceal the current frame. In order to average the results, the \nsimulations are run ten times starting from different \npositions in the error traces. \nFigures 4 and 5 show the reconstructed image qualities \nof the 'Orbi' and \u2018Interview\u2019 sequences using different frame \nconcealment methods. According to Figures 4 and 5, the \nproposed frame concealment method using shared MVs \noutperforms both of the frame copying methods, based on \nseparate motion estimation and shared MVs. This is more \nvisible in the case of colour image quality as depth frames \nare more likely to survive compared to corresponding colour \nvideo frames which are larger in size. The gain is significant \nin highly dynamic \u2018Orbi\u2019 sequence as motion of the \u2018Orbi\u2019 \nsequence is correctly restored using the duplicated MVs \nfrom the corresponding view. Due to low motion of the \n\u2018Interview\u2019 sequence, even frame copying method achieves \ncomparable results compared to the proposed frame \nconcealment method. The frame copying method with or \nwithout shared MVs performs similarly apart from the error \nfree condition. Although the error free quality of the \nproposed scheme is comparably lower, it improves the \nquality of reconstructed SSV over packet networks. \n   \n \n(a) \n \n(b) \nFig. 4. Image quality of the 'Orbi' sequence (a) Colour image \nsequence (b) Depth image sequence \n487\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 16,2010 at 10:56:08 UTC from IEEE Xplore.  Restrictions apply. \n \n(a) \n \n(b) \nFig. 5. Image quality of the 'Interview' sequence (a) Colour \nimage sequence (b) Depth image sequence \n \n4. CONCLUSION \n \nVideo streaming over packet networks is affected by packet \nlosses. Hence, efficient error concealment algorithms are \nrequired to improve the perceptual quality. This paper \nproposes a novel frame concealment algorithm for colour \nand depth map based SSV. The motion of colour and depth \nmap components is highly correlated. Hence, the proposed \nmethod reuses the MVs of colour information during depth \nmap encoding. The SVC based encoding architecture is used \nto encode the source video with backward compatibility and \nthe rate of the coded depth information was kept below 25% \nof the colour bitrate. Due to the areas of uncorrelated \nmotion, the coded image quality using shared MVs is \nslightly lower compared to separate MV estimation method. \nThe duplicated colour MVs are used to conceal the lost \nframes at the decoder. The experimental results show that \nthe quality of reconstructed colour and depth map video \nover packet networks can be vastly improved by the \nproposed method.  \n \n5. ACKNOWLEDGEMENTS \n  \nThe work presented was developed within VISNET II, a \nEuropean Network of Excellence-NoE (http:\/\/www.visnet-\nnoe.org), funded under the European Commission IST FP6 \nprogramme. \n \n6. REFERENCES \n \n[1] A. Bourge and C. Fehn, \u201cWhite paper on ISO\/IEC 23002-3 \nAuxiliary Video Data Representation\u201d, ISO\/IEC \nJTC1\/SC29\/WG11 N8039, 2006. \n[2] C. Fehn, R. De La Barre and S. Pastoor, \u201cInteractive 3-D TV: \nConcepts and Key Technologies, Proceedings of the IEEE, \nvol. 94, pp. 524-538, 2006. \n[3] C.T.E.R. Hewage, S. Worrall, S. Dogan, H. Kodikara \nArachchi and A.M. Kondoz, \"Stereoscopic TV over IP\", In \nProc. of the 4th IET European Conf. on Visual Media \nProduction, 2007. \n[4] C. Fehn, \u201cDepth-Image-Based Rendering (DIBR), \nCompression and Trans-mission for a New Approach on 3D-\nTV\u201d, Proceedings of SPIE Stereoscopic Displays and Virtual \nReality Systems XI, pp. 93-104, January 2004. \n[5] C. Fehn, \u201cA 3D-TV Approach using Depth-Image-Based \nRendering (DIBR)\u201d, In Proc. of Visualization, Imaging, and \nImage Processing (VIIP\u201903), pp. 482-487, 2003. \n[6] S. Grewatsch and E. Muller, \u201cSharing of motion vectors in 3D \nvideo coding\u201d, International conference on Image processing \n(ICIP), pp. 3271-3274, 2004. \n[7] Han Oh and Yo-Sung Ho, H.264-Based Depth Map Sequence \nCoding Using Motion Information of Corresponding Texture \nVideo, Springer Berlin\/Heidelberg, Advances in Image and \nVideo Technology, vol. 4319, 2006. \n[8] G.B. Akar, A. M. Tekalp, C. Fehn and M.R. Civanlar, \n\u201cTransport methods in 3DTV-A survey\u201d, IEEE Transactions \non Circuits and Systems for Video Technology, vol.17, pp. \n1622-1630, November 2007. \n[9] S. Knorr, C. Clemens, M. Kunter and T. Sikora, \u201cRobust \nconcealment for erroneous block bursts in stereoscopic \nimages\u201d, In Proc. 2nd Int. Symp. 3-D Dta Process., Visual., \nTransmiss. (3DPVT), pp. 820-827, 2004. \n[10] C. Clemens, M. Kunter, S. Knorr and T. Sikora, \u201cA hybrid \napproach for error concealment in stereoscopic images\u201d, \npresented at the 5th International workshop Image Anal. \nMultimedia Interactive Services (WIAMIS), 2004. \n[11] T. Wiegand, G. Sullivan, J. Reichel, H. Schwarz and M. Wien. \n\u201cJoint draft 8 of SVC amendment\u201d, ISO\/IEC \nJTC1\/SC29\/WG11 and ITU-T SG16 Q.69 (JVT-U201), 2006. \n[12] C.T.E.R. Hewage, H.A. Karim, S. Worrall, S.Dogan and A.M. \nKondoz. \u201cComparison of Stereo Video Coding Support in \nMPEG-4 MAC, H.264\/AVC and H.264\/SVC\u201d, In Proc. of \nIET Visual Information Engineering-VIE07, 2007. \n[13] W. Stephan. \u201cError patterns for Internet video experiments\u201d, \nITU-T SG16 Document Q15-I-16-R1, 1999.  \n488\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 16,2010 at 10:56:08 UTC from IEEE Xplore.  Restrictions apply. \n"}
{"doi":"10.1214\/105051604000000981","coreId":"199619","oai":"oai:eprints.lse.ac.uk:3219","identifiers":["oai:eprints.lse.ac.uk:3219","10.1214\/105051604000000981"],"title":"The disorder problem for compound Poisson processes with exponential jumps","authors":["Gapeev, Pavel V."],"enrichments":{"references":[{"id":17326512,"title":"a n dF RISTEDT, B.","authors":[],"date":"1985","doi":null,"raw":"BERRY,D .A .a n dF RISTEDT, B. (1985). Bandit Problems: Sequential Allocation of Experiments. Chapman and Hall, London.","cites":null},{"id":17326514,"title":"A note on the Poisson disorder problem.","authors":[],"date":"1976","doi":null,"raw":"DAVIS, M. H. A. (1976). A note on the Poisson disorder problem. Banach Center Publ. 1 65\u201372.","cites":null},{"id":17326513,"title":"Change-Point Problems.","authors":[],"date":"1994","doi":"10.1214\/aos\/1176325497","raw":"CARLSTEIN,E . ,M \u00dcLLER,H . - G .a n dS IEGMUND, D., eds. (1994). Change-Point Problems. IMS, Hayward, CA.","cites":null},{"id":17326531,"title":"Essentials of Stochastic Finance. World Scienti\ufb01c, Singapore.","authors":[],"date":"1999","doi":"10.1142\/9789812385192","raw":"SHIRYAEV, A. N. (1999). Essentials of Stochastic Finance. World Scienti\ufb01c, Singapore. RUSSIANACADEMY OF SCIENCES INSTITUTE OF CONTROL SCIENCES PROFSOYUZNAYASTREET 65 117997 MOSCOW RUSSIA E-MAIL: gapeev@cniica.ru","cites":null},{"id":17326522,"title":"L\u00e9vy Processes and In\ufb01nitely Divisible Distributions.","authors":[],"date":"1999","doi":"10.2307\/3621820","raw":"SATO, K. I. (1999). L\u00e9vy Processes and In\ufb01nitely Divisible Distributions. Cambridge Univ. Press.","cites":null},{"id":17326517,"title":"Limit Theorems for Stochastic Processes.","authors":[],"date":"1987","doi":"10.1007\/978-3-662-02514-7","raw":"JACOD,J .a n dS HIRYAEV, A. N. (1987). Limit Theorems for Stochastic Processes. Springer, Berlin.","cites":null},{"id":17326511,"title":"Normal inverse Gaussian processes and the modelling of stock returns.","authors":[],"date":"1995","doi":null,"raw":"BARNDORFF-NIELSEN, O. E. (1995). Normal inverse Gaussian processes and the modelling of stock returns. Research Report 300, Dept. Theoretical Statistics, Aarhus Univ.","cites":null},{"id":17326526,"title":"Onoptimum methods inquickest detectionproblems. Theory Probab.","authors":[],"date":null,"doi":null,"raw":"SHIRYAEV,A.N.(1963). Onoptimum methods inquickest detectionproblems. Theory Probab. Appl. 8 22\u201346.","cites":null},{"id":17326520,"title":"Optimal stopping for a diffusion with jumps.","authors":[],"date":"1999","doi":"10.1007\/s007800050060","raw":"MORDECKI, E. (1999). Optimal stopping for a diffusion with jumps. Finance Stochastics 3 227\u2013236.","cites":null},{"id":17326530,"title":"Optimal Stopping Rules.","authors":[],"date":"1978","doi":"10.1007\/978-3-540-74011-7_2","raw":"SHIRYAEV, A. N. (1978). Optimal Stopping Rules. Springer, Berlin.","cites":null},{"id":17326519,"title":"P ROKHOROV,Y U.V .a n dS","authors":[],"date":"1990","doi":null,"raw":"KOLMOGOROV,A .N . ,P ROKHOROV,Y U.V .a n dS HIRYAEV, A. N. (1990). Methods of detecting spontaneously occurring effects. Proc. Steklov Inst. Math. 1 1\u201321.ON THE DISORDER PROBLEM 499","cites":null},{"id":17326521,"title":"Solving the Poisson disorder problem.","authors":[],"date":"2002","doi":"10.1007\/978-3-662-04790-3_16","raw":"PESKIR,G .a n dS HIRYAEV, A. N. (2002). Solving the Poisson disorder problem. In Advances in Finance and Stochastics. Essays in Honour of Dieter Sondermann (K. Sandmann and P. Sch\u00f6nbucher, eds.) 295\u2013312. Springer, Berlin.","cites":null},{"id":17326527,"title":"Some exact formulas in a \u201cdisorder\u201d problem. Theory Probab.","authors":[],"date":"1965","doi":"10.1137\/1110043","raw":"SHIRYAEV, A. N. (1965). Some exact formulas in a \u201cdisorder\u201d problem. Theory Probab. Appl. 10 348\u2013354.","cites":null},{"id":17326516,"title":"The \u201cdisorder\u201d problem for a Poisson process. Theory Probab.","authors":[],"date":"1971","doi":"10.1137\/1116081","raw":"GAL\u2019CHUK,L.I.andR OZOVSKII, B. L. (1971). The \u201cdisorder\u201d problem for a Poisson process. Theory Probab. Appl. 16 712\u2013716.","cites":null},{"id":17326524,"title":"The detection of spontaneous effects.","authors":[],"date":"1961","doi":null,"raw":"SHIRYAEV, A. N. (1961). The detection of spontaneous effects. Soviet Math. Dokl. 2 740\u2013743.","cites":null},{"id":17326515,"title":"The optimum choice of the instant for stopping a Markov process.","authors":[],"date":"1963","doi":null,"raw":"DYNKIN, E. B. (1963). The optimum choice of the instant for stopping a Markov process. Soviet Math. Dokl. 4 627\u2013629.","cites":null},{"id":17326525,"title":"The problem of the most rapid detection of a disturbance in a stationary process.","authors":[],"date":"1961","doi":null,"raw":"SHIRYAEV, A. N. (1961). The problem of the most rapid detection of a disturbance in a stationary process. Soviet Math. Dokl. 2 795\u2013799.","cites":null},{"id":17326529,"title":"Two problems of sequential analysis.","authors":[],"date":"1967","doi":"10.1007\/bf01078755","raw":"SHIRYAEV, A. N. (1967). Two problems of sequential analysis. Cybernetics 3 63\u201369.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2005","abstract":"The problem of disorder seeks to determine a stopping time which is as close as possible to the unknown time of \u201cdisorder\u201d when the observed process changes its probability characteristics. We give a partial answer to this question for some special cases of L\u00e9vy processes and present a complete solution of the Bayesian and variational problem for a compound Poisson process with exponential jumps. The method of proof is based on reducing the Bayesian problem to an integro-differential free-boundary problem where, in some cases, the smooth-fit principle breaks down and is replaced by the principle of continuous fit","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/199619.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/3219\/1\/The_disorder_problem_for_compound_Poisson_processes_with_exponential_jumps%28lsero%29.pdf","pdfHashValue":"c0212ac5733606c66264e5dd57d8d33a71213b95","publisher":"Institute of Mathematical Statistics","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:3219<\/identifier><datestamp>\n      2014-02-27T11:22:37Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D4D41<\/setSpec><setSpec>\n      74797065733D43454E54524553:4C53455F52435F3130<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/3219\/<\/dc:relation><dc:title>\n        The disorder problem for compound Poisson processes with exponential jumps<\/dc:title><dc:creator>\n        Gapeev, Pavel V.<\/dc:creator><dc:subject>\n        HA Statistics<\/dc:subject><dc:description>\n        The problem of disorder seeks to determine a stopping time which is as close as possible to the unknown time of \u201cdisorder\u201d when the observed process changes its probability characteristics. We give a partial answer to this question for some special cases of L\u00e9vy processes and present a complete solution of the Bayesian and variational problem for a compound Poisson process with exponential jumps. The method of proof is based on reducing the Bayesian problem to an integro-differential free-boundary problem where, in some cases, the smooth-fit principle breaks down and is replaced by the principle of continuous fit.<\/dc:description><dc:publisher>\n        Institute of Mathematical Statistics<\/dc:publisher><dc:date>\n        2005<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/3219\/1\/The_disorder_problem_for_compound_Poisson_processes_with_exponential_jumps%28lsero%29.pdf<\/dc:identifier><dc:identifier>\n          Gapeev, Pavel V.  (2005) The disorder problem for compound Poisson processes with exponential jumps.  Annals of Applied Probability, 15 (1A).  pp. 487-499.  ISSN 1050-5164     <\/dc:identifier><dc:relation>\n        http:\/\/www.imstat.org\/aap\/<\/dc:relation><dc:relation>\n        10.1214\/105051604000000981<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/3219\/","http:\/\/www.imstat.org\/aap\/","10.1214\/105051604000000981"],"year":2005,"topics":["HA Statistics"],"subject":["Article","PeerReviewed"],"fullText":"  \nPavel V. Gapeev \nThe disorder problem for compound \nPoisson processes with exponential jumps \nArticle (Published version) \n(Refereed) \n \n \nOriginal citation: \nGapeev, Pavel V. (2005) The disorder problem for compound Poisson processes with \nexponential jumps. Annals of applied probability, 15 (1A). pp. 487-499. ISSN 1050-5164 \nDOI: 10.1214\/105051604000000981 \n \n\u00a9 2005 Institute of Mathematical Statistics \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/3219\/ \nAvailable in LSE Research Online: December 2011 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \nThe Annals of Applied Probability\n2005, Vol. 15, No. 1A, 487\u2013499\nDOI 10.1214\/105051604000000981\n\u00a9 Institute of Mathematical Statistics, 2005\nTHE DISORDER PROBLEM FOR COMPOUND POISSON\nPROCESSES WITH EXPONENTIAL JUMPS\nBY PAVEL V. GAPEEV\nRussian Academy of Sciences\nThe problem of disorder seeks to determine a stopping time which is\nas close as possible to the unknown time of \u201cdisorder\u201d when the observed\nprocess changes its probability characteristics. We give a partial answer to\nthis question for some special cases of L\u00e9vy processes and present a complete\nsolution of the Bayesian and variational problem for a compound Poisson\nprocess with exponential jumps. The method of proof is based on reducing the\nBayesian problem to an integro-differential free-boundary problem where,\nin some cases, the smooth-fit principle breaks down and is replaced by the\nprinciple of continuous fit.\n1. Introduction. Assume that at time t = 0 we begin to observe a continu-\nously updated process X = (Xt )t\u22650 whose probability characteristics change at\nsome unknown time \u03b8 , called the time of disorder, which cannot be observed di-\nrectly. Throughout this paper the random time \u03b8 can take the value 0 with probabil-\nity \u03c0 ; under the condition that \u03b8 > 0, it is exponentially distributed with parameter\n\u03bb > 0. The disorder problem or the problem of quickest disorder detection is to\ndecide by observing the process X the time instant at which we should give an\nalarm to indicate the occurrence of disorder. This time instant should be as close\nas possible to the time \u03b8 in the sense that both the probability of false alarm and the\nexpectation of the time interval between the occurrence of disorder and the alarm\n(when the latter is given correctly) should be minimal.\nThe problem of detecting a change in drift of a Wiener process was formulated\nand solved by Shiryaev [12\u201315] (see also [16] and [17], Chapter IV and page 208,\nfor historical notes and references). Some particular cases of the problem of\ndetecting a change in the intensity of a Poisson process were considered by\nGal\u2019chuk and Rozovskii [6] and by Davis [4]. Peskir and Shiryaev [10] presented\na complete solution of the disorder problem for a Poisson process in the Bayesian\nformulation. The main aim of this paper is to find an explicit expression of the\noptimal stopping boundary for the a posteriori probability process in some special\nReceived December 2001; revised June 2003.\nAMS 2000 subject classifications. Primary 60G40, 62M20, 34K10; secondary 62C10, 62L15,\n60J75.\nKey words and phrases. Disorder (quickest detection) problem, L\u00e9vy process, compound Poisson\nprocess, optimal stopping, integro-differential free-boundary problem, principles of smooth and\ncontinuous fit, measure of jumps and its compensator, Girsanov\u2019s theorem for semimartingales, It\u00f4\u2019s\nformula.\n487\n488 P. V. GAPEEV\ncases of the problem for L\u00e9vy processes and to present a complete solution to the\nproblem for a compound Poisson process that has exponentially distributed jumps.\nActually, we give the next example of process for which the quickest disorder\ndetection problem can be solved in an explicit form. Such processes are used, for\nexample, in several models of stochastic finance and insurance (see, e.g., [18]). For\nsome other optimal stopping problems for such processes see, for example, [9].\nThe paper is organized as follows. In Section 2 we give a formulation of\nthe Bayesian and variational problem of quickest disorder detection for L\u00e9vy\nprocesses. In Section 3 by the examination of the sample-path behavior of\nthe a posteriori probability process, we find an optimal stopping boundary in\nsome particular cases of the Bayesian problem. In Section 4 by means of\nsolving the corresponding integro-differential free-boundary problem, we derive\na complete solution of the Bayesian problem for a compound Poisson process\nwith exponential jumps, where we can observe the breakdown of the smooth-\nfit principle and its replacement by the principle of continuous fit. These effects\ncan be explained both by the examination of the sample-path properties of the a\nposteriori probability process and by the existence of a singularity point of the\nintegro-differential equation. Note that in models based on jump processes the\nsituations when the continuous fit replaces the smooth fit were earlier observed,\nfor example, in bandit problems (see, e.g., [2] for references). In Section 5, passing\nfrom the derived solution of the Bayesian problem, we find an explicit expression\nfor the optimal stopping boundary in the corresponding variational problem.\nWe note here that the problem of quickest detection admits different formula-\ntions and appears in on-line quality control, radar location, seismology and so forth\n(see, e.g., [3, 8]).\n2. Formulation of the Bayesian and variational problem. For a precise\nprobabilistic formulation of the quickest disorder detection problem for L\u00e9vy\nprocesses (see [17], Chapter IV, for the Wiener process case), let us suppose that\non some measurable space (\u0004,F ) equipped with a family of probability measures\n(P s)s\u22650 there exists a nonnegative random variable \u03b8 such that P s[\u03b8 = s] = 1\nfor all s \u2265 0. It is assumed that we observe a continuously updated process\nX = (Xt )t\u22650 with X0 = 0 and having, under the measure P s , the triplet(\n(t \u2227 s)b0 + ((t \u2212 s) \u2228 0)b1,0, dt [I{t<s}\u03bd0(dx)+ I{t\u2265s}\u03bd1(dx)])(2.1)\nwith respect to the function h(x) = x, x \u2208 R, for all t, s \u2265 0, where \u03bdi(dx) is a\nL\u00e9vy measure on R such that \u03bdi({0}) = 0 and \u222b (x2 \u2227 1)\u03bdi(dx) < \u221e for i = 0,1\n(see, e.g., [7], Chapter II.4, or [11], Chapter II.8). Here \u03b8 and X are assumed to be\nstochastically independent under P s for all s \u2265 0. Let us fix \u03bb > 0 and define the\nmeasures P\u03c0 = \u03c0P 0 + (1 \u2212 \u03c0) \u222b\u221e0 \u03bbe\u2212\u03bbsP s ds for all \u03c0 \u2208 [0,1], so that we have\nP\u03c0 [\u03b8 = 0] = \u03c0 and P\u03c0 [\u03b8 > t|\u03b8 > 0] = e\u2212\u03bbt for all t \u2265 0.\nLet \u03c4 be a stopping time with respect to the filtration FX = (F Xt )t\u22650, where\nF Xt = \u03c3 {Xs |0 \u2264 s \u2264 t}. We interpret \u03c4 as the time at which the alarm is sounded to\nON THE DISORDER PROBLEM 489\nsignal the change in distribution of the observed process X. The Bayesian disorder\nproblem is to minimize the risk function\nV (\u03c0) = inf\n\u03c4\n{P\u03c0 [\u03c4 < \u03b8] + cE\u03c0 [\u03c4 \u2212 \u03b8]+},(2.2)\nwhere the infimum is taken over all FX stopping times \u03c4 , and to find an optimal\nstopping time \u03c4\u2217 at which the infimum in (2.2) is attained. Here P\u03c0 [\u03c4 < \u03b8] is the\nprobability of false alarm, E\u03c0 [\u03c4 \u2212 \u03b8]+ is the average delay in detecting disorder\ncorrectly and c > 0 is some constant.\nIt is easily shown (see [17], pages 195\u2013197) that the value function V (\u03c0)\ncan be expressed in terms of the a posteriori probability process (\u03c0t), where\n\u03c0t = P\u03c0 [\u03b8 \u2264 t|F Xt ] for all t \u2265 0 and P\u03c0 [\u03c00 = \u03c0 ] = 1. Namely, we have\nV (\u03c0) = inf\n\u03c4\nE\u03c0\n[\n1 \u2212 \u03c0\u03c4 + c\n\u222b \u03c4\n0\n\u03c0t dt\n]\n.(2.3)\nMoreover, it is easily verified (see [17], page 204) that the infimum in (2.3) is\nactually taken over the class M(\u03c0) of stopping times \u03c4 such that E\u03c0 [\u03c4 ] < \u221e.\nTo give the corresponding variational or fixed false-alarm probability formula-\ntion, let the number \u03c0 \u2208 [0,1) be fixed and let M(\u03c0,\u03b1) denote the class of stopping\ntimes \u03c4 that satisfy\nP\u03c0 [\u03c4 < \u03b8] \u2264 \u03b1,(2.4)\nwhere \u03b1 is a given constant from the interval [0,1). The variational disorder\nproblem is to find in the class M(\u03c0,\u03b1) a stopping time \u03c4\u02c6 such that\nE\u03c0 [\u03c4\u02c6 \u2212 \u03b8]+ \u2264 E\u03c0 [\u03c4 \u2212 \u03b8]+(2.5)\nfor any other stopping time \u03c4 from M(\u03c0,\u03b1).\n3. Preliminary results and examples. Suppose that the filtration FX is right-\ncontinuous and the conditions\u222b\n|x|\u03bdi(dx) < \u221e (i = 0,1),(3.1)\nb1 = b0 +\n\u222b\nx\u03bd1(dx) \u2212\n\u222b\nx\u03bd0(dx),(3.2) \u222b (\u221a\nY (x) \u2212 1)2\u03bd0(dx) < \u221e(3.3)\nare satisfied, where Y (x) = \u03bd1(dx)\/\u03bd0(dx) for all x \u2208 R. Then by means of\nGirsanov\u2019s theorem for semimartingales ([7], Theorem III.5.34) and It\u00f4\u2019s formula\n([7], Theorem I.4.57), using the schema of arguments in [17], page 202, it can be\nverified that the process (\u03c0t ) solves the stochastic differential equation\nd\u03c0t = \u03bb(1 \u2212 \u03c0t ) dt +\n\u222b\n\u03c0t\u2212(1 \u2212 \u03c0t\u2212)(Y (x) \u2212 1)\n1 + \u03c0t\u2212(Y (x) \u2212 1) (\u00b5\nX \u2212 \u03bdX)(dt, dx),(3.4)\n490 P. V. GAPEEV\nwhere \u00b5X is the measure of jumps of the process X and its FX compensator \u03bdX is\ngiven by \u03bdX(dt, dx) = (\u03c0t\u2212\u03bd1(dx) + (1 \u2212 \u03c0t\u2212)\u03bd0(dx)) dt . From (3.4) it is easily\nseen that (\u03c0t ) is a time-homogeneous (strong) Markov process under P\u03c0 with\nrespect to the natural filtration which clearly coincides with FX . The latter implies\nthat the infimum in (2.3) can be taken over all stopping times of (\u03c0t ) playing the\nrole of a sufficient statistic (see, e.g., [17], Chapter II.15).\nIt can be also verified (see [17], pages 197 and 198, and [10]) that the value\nfunction V (\u03c0) is decreasing and concave on [0,1], and the optimal stopping time\nin (2.3) is given by\n\u03c4\u2217 = inf{t \u2265 0|\u03c0t \u2265 B\u2217},(3.5)\nwhere B\u2217 is the smallest number \u03c0 from [0,1] such that V (\u03c0) = 1 \u2212 \u03c0 .\nUsing the arguments from [10] we now find an explicit expression for the\noptimal stopping boundary B\u2217 in some particular cases of the problem.\nLEMMA 3.1. Assume in addition to (2.1) and (3.1)\u2013(3.3) that we have\n\u03bd1(dx) \u2265 \u03bd0(dx) (x \u2208 R),(3.6)\n0 <\n\u222b\nx\u03bd1(dx)\u2212\n\u222b\nx\u03bd0(dx) \u2264 c + \u03bb.(3.7)\nThen in the Bayesian problem of quickest disorder detection (2.2) + (2.3) the\nstopping time \u03c4\u2217 from (3.5) is optimal with B\u2217 = \bB , where we set\n\bB = \u03bb\n\u03bb + c .(3.8)\nPROOF. The assumption (3.7) ensures that \bB \u2264 B\u0302 , where we set\nB\u0302 = \u03bb\n\/(\u222b\nx\u03bd1(dx)\u2212\n\u222b\nx\u03bd0(dx)\n)\n.(3.9)\nFrom (3.4) it is seen that if B\u0302 \u2265 1, then the process (\u03c0t) is strictly increasing, and\nif B\u0302 < 1, then the drift rate of the continuous part of (\u03c0t) is positive on [0, B\u0302),\nnegative on (B\u0302,1) and equal to zero at B\u0302 . Thus, if (\u03c0t ) starts in [0, B\u0302) or in (B\u0302,1),\nthen under the absence of jumps, (\u03c0t) never reaches B\u0302 , because its drift tends to\nzero the same time with linear order. Therefore, by virtue of the fact that under the\ncondition (3.6) the process (\u03c0t ) can have only positive jumps, it can leave [0, B\u0302)\nonly by jumping and, fluctuating in (B\u0302,1), it cannot enter [0, B\u0302). If (\u03c0t) starts or\nends up at B\u0302 , then it is trapped there (P\u03c0 -a.s.) until the next jump of X occurs.\nFrom (3.4) it follows that the process (\u03c0t ) admits the representation\n\u03c0t = \u03c0 + \u03bb\n\u222b t\n0\n(1 \u2212 \u03c0s\u2212) ds + Mt,(3.10)\nON THE DISORDER PROBLEM 491\nwhere (Mt) is a martingale under P\u03c0 with respect to FX. Hence, by means of the\noptional sampling theorem (see, e.g., [7], Theorem I.1.39), from (3.10) together\nwith (3.4) and according to (3.1) we obtain that E\u03c0 [M\u03c4 ] = 0 and hence\nE\u03c0\n[\n1 \u2212 \u03c0\u03c4 + c\n\u222b \u03c4\n0\n\u03c0t dt\n]\n= 1 \u2212 \u03c0 + (\u03bb+ c)E\u03c0\n\u222b \u03c4\n0\n(\n\u03c0t \u2212 \u03bb\n\u03bb + c\n)\ndt(3.11)\nfor all stopping times \u03c4 from M(\u03c0). Recalling that the process (\u03c0t ) is monotone\nincreasing in [ \bB, B\u0302) and that after entering [B\u0302,1] cannot leave it, from (3.11) we\nmay therefore conclude that it is never optimal to stop (\u03c0t ) in [0, \bB ) and that (\u03c0t )\nmust be stopped instantly after passing through \bB . \u0001\nEXAMPLE 3.2. Assume that in (2.1) we have bi = 1\/\u03bbi and \u03bdi(dx) =\nI{x>0} exp(\u2212\u03bbix) dx\/x with \u03bbi > 0. Thus X is a gamma process with parameter\nchanging from \u03bb0 to \u03bb1 (see, e.g., [18], Chapter III.1). In this case the integrals\nin (3.1) and (3.3) are equal to 1\/\u03bbi and log[(\u03bb0 + \u03bb1)2\/(4\u03bb0\u03bb1)], respectively.\nTherefore, by Lemma 3.1 we get that if \u03bb0 > \u03bb1 > 0 and log(\u03bb0\/\u03bb1) \u2264 c + \u03bb, then\nthe stopping time \u03c4\u2217 from (3.5) is optimal with B\u2217 = \u03bb\/(\u03bb + c).\nEXAMPLE 3.3. Suppose that in (2.1) we have bi = 1\/\u03b3i and \u03bdi(dx) =\nI{x>0} exp(\u2212\u03b3 2i x\/2) dx\/(2\u03c0x3)1\/2 with \u03b3i > 0. Thus X is an inverse Gaussian\nprocess with parameter changing from \u03b30 to \u03b31 (see, e.g., [1]). In this case the\nintegrals in (3.1) and (3.3) are equal to 1\/\u03b3i and [2(\u03b3 20 + \u03b3 21 )]1\/2 \u2212 \u03b30 \u2212 \u03b31,\nrespectively. Therefore, by Lemma 3.1 we conclude that if \u03b30 > \u03b31 > 0 and\n\u03b30 \u2212 \u03b31 \u2264 c + \u03bb, then \u03c4\u2217 from (3.5) is optimal with B\u2217 = \u03bb\/(\u03bb + c).\nREMARK 3.4. From (3.11) it is seen that one should not stop (\u03c0t ) when it is\nin [0, \bB ], so for B\u2217 from (3.5) we have \bB \u2264 B\u2217 \u2264 1.\n4. Solution of the Bayesian problem for a compound Poisson process with\nexponential jumps. In the rest of the paper, we assume that the process X is\ndefined by\nXt =\n\u222b t\n0\n\u03b8s\u2212 dX1s +\n\u222b t\n0\n(1 \u2212 \u03b8s\u2212) dX0s ,(4.1)\nwhere Xis =\n\u2211Nis\nj=1 \u03be ij and \u03b8s = I{s\u2265\u03b8} for all t, s \u2265 0, Ni = (Nit ) is a Poisson\nprocess with intensity 1\/\u03bbi and (\u03be ij )j\u2208N is a sequence of independent random\nvariables exponentially distributed with parameter \u03bbi [Ni , (\u03be ij )j\u2208N and \u03b8 are\nsupposed to be independent] for i = 0,1. Then in (2.1) we have bi = 1\/\u03bb2i and\n\u03bdi(dx) = I{x>0} exp(\u2212\u03bbix) dx, and thus X is a compound Poisson process that\nhas exponentially distributed jumps with parameter changing from \u03bb0 to \u03bb1. In this\n492 P. V. GAPEEV\ncase the integrals in (3.1) and (3.3) are equal to 1\/\u03bb2i and (\u03bb0 \u2212 \u03bb1)2\/[\u03bb0\u03bb1(\u03bb0 +\n\u03bb1)], respectively, and (3.4) takes the form\nd\u03c0t = \u03bb(1 \u2212 \u03c0t ) dt\n+\n\u222b \u221e\n0\n\u03c0t\u2212(1 \u2212 \u03c0t\u2212)(exp(\u2212\u03bb1x) \u2212 exp(\u2212\u03bb0x))\n\u03c0t\u2212 exp(\u2212\u03bb1x) + (1 \u2212 \u03c0t\u2212) exp(\u2212\u03bb0x)(4.2) \u00d7 (\u00b5X(dt, dx)\u2212 (\u03c0t\u2212 exp(\u2212\u03bb1x)\n+ (1 \u2212 \u03c0t\u2212) exp(\u2212\u03bb0x))dt dx).\nStandard arguments imply that in this case the infinitesimal operator L of the\nprocess (\u03c0t) acts on a function f \u2208 C1([0,1]) according to the rule\n(Lf )(\u03c0) =\n(\n\u03bb \u2212\n(\n\u03bb0 \u2212 \u03bb1\n\u03bb0\u03bb1\n)\n\u03c0\n)\n(1 \u2212 \u03c0)f \u2032(\u03c0)\n+\n\u222b \u221e\n0\n[\nf\n(\n\u03c0 exp(\u2212\u03bb1x)\n\u03c0 exp(\u2212\u03bb1x) + (1 \u2212 \u03c0) exp(\u2212\u03bb0x)\n)\n\u2212 f (\u03c0)\n]\n(4.3)\n\u00d7 (\u03c0 exp(\u2212\u03bb1x) + (1 \u2212 \u03c0) exp(\u2212\u03bb0x))dx\nfor all \u03c0 \u2208 [0,1]. Using standard arguments based on the strong Markov property,\nit follows that V (\u03c0) is C1 on (0,B\u2217). Therefore, using the results from [17],\nChapter III.8, we can formulate the integro-differential free-boundary problem for\nthe unknown function V (\u03c0) from (2.3) and the unknown boundary B\u2217 from (3.5)\nas\n(LV )(\u03c0) = \u2212c\u03c0 (0 < \u03c0 < B\u2217),(4.4)\nV (\u03c0) = 1 \u2212 \u03c0 (B\u2217 \u2264 \u03c0 \u2264 1),(4.5)\nV (B\u2217\u2212) = 1 \u2212 B\u2217 (continuous fit),(4.6)\nwhere the condition (4.6) is satisfied by virtue of the concavity argument above.\nNote that the superharmonic characterization of the value function (see [5] and\n[17]) implies that V (\u03c0) is the largest function that satisfies (4.4)\u2013(4.6). Moreover,\nunder some relationships on the parameters of the model which are specified\nbelow, the condition\nV \u2032(B\u2217) = \u22121 (smooth fit)(4.7)\nmay be satisfied or break down. We also observe that, in this case, B\u0302 from (3.9)\ntakes the form\nB\u0302 = \u03bb\u03bb0\u03bb1\n\u03bb0 \u2212 \u03bb1(4.8)\nand turns out to be a singularity point of (4.4) when \u03bb0 > \u03bb1.\nUsing the schema of arguments in [10], we further show that the system (4.4)\u2013\n(4.6) admits an explicit solution which turns out to be a solution of the initial\nON THE DISORDER PROBLEM 493\noptimal stopping problem (2.3). For this, let us consider a continuous function\nf (\u03c0) that satisfies (4.4) on (0,B) and (4.5) on [B,1] for some 0 < B < 1 given\nand fixed.\nLet us first assume that \u03bb0 > \u03bb1. Then it follows that the function f\u02dc (y) = f (\u03c0)\nwith \u03c0 = ey\/(1 + ey) solves the system(\n\u03bb\u2032(1 + ey)\ney\n\u2212 1\n\u03b3 (\u03b3 \u2212 1)\n)\nf\u02dc \u2032(y) \u2212 f\u02dc (y)[\u03b3 (1 + e\ny) \u2212 1]\n\u03b3 (\u03b3 \u2212 1)(1 + ey)\n+ e\n\u03b3y\n1 + ey\n[\u222b B\u02dc\ny\nf\u02dc (z)(1 + ez)\ne\u03b3 z\ndz + e\n\u2212\u03b3 B\u02dc\n\u03b3\n]\n(4.9)\n= \u2212c(\u03bb0 \u2212 \u03bb1)e\ny\n1 + ey (y < B\u02dc),\nf\u02dc (y) = 1\n1 + ey (y \u2265 B\u02dc),(4.10)\nwhere we set \u03b3 = \u03bb0\/(\u03bb0 \u2212\u03bb1) > 1, \u03bb\u2032 = \u03bb(\u03bb0 \u2212 \u03bb1) > 0 and B\u02dc = log[B\/(1\u2212B)].\nIt can be easily shown that the system (4.9) + (4.10) has a unique solution which\nis given by\nf\u02dc (y; B\u02dc) = 1\n1 + eB\u02dc \u2212\n\u222b B\u02dc\ny\n\u03b3 (\u03b3 \u2212 1)F\u02dc (z, B\u02dc)e\u03b3 z\n\u03b3 (1 + ez)\u2212 1 dz,(4.11)\nF\u02dc (y, B\u02dc) = 1\nA\u02dc(y)\n(\nC\u02dc(y, B\u02dc)\u2212\n\u222b B\u02dc\ny\nC\u02dc(z, B\u02dc)\nA\u02dc(z)\nG\u02dc(z)\nG\u02dc(y)\ndz\n)\n,(4.12)\nA\u02dc(y) = 1 + e\ny\ney\n(\n\u03bb\u2032\u03b3 (\u03b3 \u2212 1)(1 + ey)\u2212 ey\n\u03b3 (1 + ey) \u2212 1\n)\n,(4.13)\nC\u02dc(y, B\u02dc) = e\n\u2212(\u03b3\u22121)B\u02dc\n\u03b3 (\u03b3 \u2212 1)(1 + eB\u02dc) \u2212\nc\u03bb0e\u2212(\u03b3\u22121)y\n\u03b3\n,(4.14)\nG\u02dc(y) =\n\uf8f1\uf8f4\uf8f2\n\uf8f4\uf8f3\n\u2223\u2223\u2223\u2223ey \u2212 B\u03021 \u2212 B\u0302\n\u2223\u2223\u2223\u2223a(1 + ey), if B\u0302 \n= 1,\nexp[\u2212\u03b3 ey](1 + ey), if B\u0302 = 1,\n(4.15)\nfor y \u2264 B\u02dc , and a = (B\u0302 + \u03b3 \u2212 1)\/(1 \u2212 B\u0302 ) if B\u0302 \n= 1. Using (4.11)\u2013(4.15) we may\nthus conclude that the function f (\u03c0;B) = f\u02dc (y; B\u02dc) given by\nf (\u03c0;B) = 1 \u2212 B \u2212\n\u222b B\n\u03c0\n\u03b3 \u03bb1F(x,B\u2217)(1 \u2212 x)[x\/(1 \u2212 x)]\u03b3\n\u03bb1 + (\u03bb0 \u2212 \u03bb1)x dx,(4.16)\nF(\u03c0,B) = 1\nA(\u03c0)\u03c0(1 \u2212 \u03c0)\n(\nC(\u03c0,B) \u2212\n\u222b B\n\u03c0\nC(x,B)G(x) dx\nA(x)G(\u03c0)x(1 \u2212 x)\n)\n,(4.17)\nA(\u03c0) = \u03bb\u03bb0\u03bb1 \u2212 (\u03bb0 \u2212 \u03bb1)\u03c0\n\u03c0 [\u03bb1 + (\u03bb0 \u2212 \u03bb1)\u03c0 ] ,(4.18)\n494 P. V. GAPEEV\nC(\u03c0,B) = 1 \u2212 B\n\u03b3 (\u03b3 \u2212 1)\n(1 \u2212 B\nB\n)\u03b3\u22121\n\u2212 c(\u03bb0 \u2212 \u03bb1)\n(1 \u2212 \u03c0\n\u03c0\n)\u03b3\u22121\n,(4.19)\nG(\u03c0) =\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f3\n\u2223\u2223\u2223\u2223 \u03bb\u03bb0\u03bb1 \u2212 (\u03bb0 \u2212 \u03bb1)\u03c0(\u03bb0 \u2212 \u03bb1 \u2212 \u03bb\u03bb0\u03bb1)(1 \u2212 \u03c0)\n\u2223\u2223\u2223\u2223a 11 \u2212 \u03c0 , if \u03bb\u03bb0\u03bb1\u03bb0 \u2212 \u03bb1 \n= 1,\nexp\n(\n\u03bb0\u03c0\n(\u03bb1 \u2212 \u03bb0)(1 \u2212 \u03c0)\n) 1\n1 \u2212 \u03c0 , if\n\u03bb\u03bb0\u03bb1\n\u03bb0 \u2212 \u03bb1 = 1,\n(4.20)\na = \u03bb1(1 + \u03bb\u03bb0)\n\u03bb0 \u2212 \u03bb1 \u2212 \u03bb\u03bb0\u03bb1 if\n\u03bb\u03bb0\u03bb1\n\u03bb0 \u2212 \u03bb1 \n= 1,(4.21)\nfor \u03c0 \u2208 (0,B] is a unique solution of the system (4.4) + (4.5).\nLet us now assume that \u03bb0 < \u03bb1. In this case it follows that the function\nf\u02dc (y) = f (\u03c0) with \u03c0 = ey\/(1 + ey) solves the equation(\n\u03bb\u2032(1 + ey)\ney\n\u2212 1\n\u03b3 (\u03b3 \u2212 1)\n)\nf\u02dc \u2032(y) \u2212 f\u02dc (y)[\u03b3 (1 + e\ny) \u2212 1]\n\u03b3 (\u03b3 \u2212 1)(1 + ey)\n(4.22)\n\u2212 e\n\u03b3y\n1 + ey\n\u222b y\n\u2212\u221e\nf\u02dc (z)(1 + ez)\ne\u03b3 z\ndz = \u2212c(\u03bb0 \u2212 \u03bb1)e\ny\n1 + ey (y < B\u02dc)\nand satisfies (4.10), where \u03b3 = \u03bb0\/(\u03bb0 \u2212 \u03bb1) < 0, \u03bb\u2032 = \u03bb(\u03bb0 \u2212 \u03bb1) < 0 and\nB\u02dc = log[B\/(1 \u2212B)]. It can be easily verified that the system (4.22) + (4.10) has a\nunique solution which is given by\nf\u02dc (y) = 1\n1 + eB\u02dc +\n\u222b y\n\u2212\u221e\n\u03b3 (\u03b3 \u2212 1)F\u02dc (z)e\u03b3 z\n\u03b3 (1 + ez) \u2212 1 dz,(4.23)\nF\u02dc (y) = \u2212c(\u03bb0 \u2212 \u03bb1)\nA\u02dc(y)\n(\ne\u2212(\u03b3\u22121)y +\n\u222b y\n\u2212\u221e\ne\u2212(\u03b3\u22121)z\nA\u02dc(z)\nG\u02dc(z)\nG\u02dc(y)\ndz\n)\n(4.24)\nfor y \u2264 B\u02dc , where A\u02dc(y) and G\u02dc(y) are defined in (4.13) and (4.15), respectively.\nUsing (4.23) + (4.24) and (4.13) + (4.15) we may therefore conclude that the\nfunction f (\u03c0;B) = f\u02dc (y) given by (4.16) with\nF(\u03c0) = \u2212 c(\u03bb0 \u2212 \u03bb1)\nA(\u03c0)\u03c0(1 \u2212 \u03c0)\n((1 \u2212 \u03c0\n\u03c0\n)\u03b3\u22121\n+\n\u222b \u03c0\n0\nG(x)(1 \u2212 x)\u03b3\u22122\nA(x)G(\u03c0)x\u03b3\ndx\n)\n(4.25)\nfor \u03c0 \u2208 (0,B] is a unique solution of the system (4.4) + (4.5).\nTaking into account the facts proved above, we are now ready to formulate the\nmain assertion of the section.\nTHEOREM 4.1. Suppose that the observed process X is given by (4.1). Then\nin the Bayesian problem of quickest disorder detection (2.2) + (2.3) the value\nfunction V (\u03c0) coincides with the function\nV\u2217(\u03c0) =\n{\nf (\u03c0;B\u2217), \u03c0 \u2208 (0,B\u2217),\n1 \u2212 \u03c0, \u03c0 \u2208 [B\u2217,1],(4.26)\nON THE DISORDER PROBLEM 495\n[with V\u2217(0) = f (0+;B\u2217)] and the optimal stopping time \u03c4\u2217 is explicitly given\nby (3.5), where f (\u03c0;B) and the boundary B\u2217 are specified as follows:\n(i) If \u03bb0 > \u03bb1 and c > 1\/\u03bb1 \u2212 1\/\u03bb0 \u2212 \u03bb, then f (\u03c0;B) is given by (4.16) +\n(4.17) and B\u2217 = \bB \u2261 \u03bb\/(\u03bb + c).\n(ii) If \u03bb0 > \u03bb1 and c = 1\/\u03bb1 \u2212 1\/\u03bb0 \u2212 \u03bb, then f (\u03c0;B) is given by (4.16) +\n(4.17) and B\u2217 = \bB = B\u0302 \u2261 \u03bb\u03bb0\u03bb1\/(\u03bb0 \u2212 \u03bb1).\n(iii) If \u03bb0 > \u03bb1 and c < 1\/\u03bb1 \u2212 1\/\u03bb0 \u2212 \u03bb, then f (\u03c0;B) is given by (4.16) +\n(4.17) and B\u2217 > \bB is a unique root of H(B\u2217) = 0, where we set\nH(B) =\n\u222b B\nB\u0302\nC(x,B)G(x)\nA(x)x(1 \u2212 x) dx.(4.27)\n(iv) If \u03bb0 < \u03bb1, then f (\u03c0;B) = f (\u03c0) is given by (4.16) + (4.25) and B\u2217 is\nuniquely determined from the equation\nf \u2032(B\u2217) = \u22121.(4.28)\nPROOF. (i) and (ii) In these cases the conditions (3.6) + (3.7) are satisfied and\nthus \bB \u2264 B\u0302 . Hence, by Lemma 3.1 we get that B\u2217 coincides with \bB and, by means\nof the uniqueness arguments for solutions of the first-order ordinary differential\nequations, we may conclude that V\u2217(\u03c0) = V (\u03c0) for all \u03c0 \u2208 [0,1].\n(iii) In this case we have B\u0302 < \bB , and thus, according to Remark 3.4, we see\nthat the optimal boundary B\u2217 is located to the right of B\u0302 . Taking an arbitrary B\nfrom (B\u0302,1), by means of the arguments above we obtain that the function f (\u03c0;B)\nfrom (4.16) + (4.17) is a unique solution of the system (4.4)\u2013(4.6) for \u03c0 \u2208 (B\u0302,B].\nObserve that in the given case there exists a unique point B \u2032 \u2208 (B\u0302,1) such that\nlim\u03c0\u2193B\u0302 f (\u03c0;B) = \u00b1\u221e for B \u2208 (B\u0302,B \u2032) \u222a (B \u2032,1) and lim\u03c0\u2193B\u0302 f (\u03c0;B \u2032) is finite.\nHence f (\u03c0;B) together with F(\u03c0,B) from (4.17) can be uniquely extended to\nthe interval (0, B\u0302], where by l\u2019H\u00f4pital\u2019s rule, we may let F(B\u0302,B \u2032) = F(B\u0302\u00b1,B \u2032)\nand thus f \u2032(B\u0302;B \u2032) = f \u2032(B\u0302\u00b1;B \u2032) \u2261 \u2212c\u03bb21\/(\u03bb0 \u2212\u03bb1 \u2212\u03bb\u03bb0\u03bb1). Then from (4.16)+\n(4.17) it follows that B \u2032 can be characterized by means of H(B \u2032) = 0, where\nH(B) is defined in (4.27). Since H(B\u0302+) = +0 and the derivative H \u2032(B) > 0 for\nB \u2208 (B\u0302, \bB ) and H \u2032(B) < 0 for B \u2208 ( \bB,1), the function H(B) increases on (B\u0302, \bB )\nand decreases on ( \bB,1). Thus, by virtue of the property limB\u2191\u221e H(B) = \u2212\u221e, we\nget that B \u2032 belongs to the interval (\bB,1) and H(B \u2032) = 0 has a unique solution.\nSummarizing the facts proved above, we see that the value function V (\u03c0) and\nthe optimal boundary B\u2217 should necessarily solve the system (4.4)\u2013(4.6) and there\nis only one point B \u2032 such that the solution f (\u03c0;B \u2032) taken at \u03c0 = B\u0302 is finite. We\nmay therefore conclude that B\u2217 coincides with B \u2032 and the uniqueness argument\nfor solutions of first-order differential equations implies that V\u2217(\u03c0) = V (\u03c0) for all\n\u03c0 \u2208 [0,1], thus proving the claim.\n(iv) Taking into account the fact that in this case the process (\u03c0t ) can increase\nonly continuously, following the arguments in [17], Chapter IV.4, and [10] we may\n496 P. V. GAPEEV\nguess that the smooth-fit condition (4.7) is satisfied and thus (4.28) holds. Using\nstraightforward calculations it is shown that f \u2032\u2032(\u03c0) < 0 for \u03c0 \u2208 (0,1); hence, the\nfunction f (\u03c0) from (4.16) + (4.25) is concave on [0,1] and its derivative f \u2032(\u03c0)\nis decreasing on (0,1). Therefore, by virtue of the facts that f \u2032(0+) = 0 and\nf \u2032(1\u2212) = \u2212\u221e, we may conclude that (4.28) admits a unique solution.\nLet us now show that the function V\u2217(\u03c0) defined in (4.26) + (4.16) + (4.25)\ncoincides with the value function V (\u03c0) and that B\u2217 being a unique root of (4.28)\nis an optimal stopping boundary. For this, applying It\u00f4\u2019s formula, we get\nV\u2217(\u03c0t ) = V\u2217(\u03c0) +\n\u222b t\n0\n(LV\u2217)(\u03c0s\u2212) ds + M\u2217t ,(4.29)\nwhere the process (M\u2217t ) defined by\nM\u2217t =\n\u222b t\n0\n\u222b \u221e\n0\n[\nV\u2217\n(\n\u03c0s\u2212 exp(\u2212\u03bb1x)\n\u03c0s\u2212 exp(\u2212\u03bb1x) + (1 \u2212 \u03c0s\u2212) exp(\u2212\u03bb0x)\n)\n\u2212 V\u2217(\u03c0s\u2212)\n]\n(4.30) \u00d7 (\u00b5X(ds, dx)\u2212 (\u03c0s\u2212 exp(\u2212\u03bb1x) + (1 \u2212 \u03c0s\u2212) exp(\u2212\u03bb0x))ds dx)\nis a martingale under P\u03c0 with respect to FX .\nSince V\u2217(\u03c0) is a bounded function, from (4.30) by means of the optional\nsampling theorem we get that E\u03c0 [M\u2217\u03c4 ] = 0 for all \u03c4 from M(\u03c0). Thus, taking\nthe expectation on both sides in (4.29) with \u03c4 instead of t and using the fact that a\ndirect verification yields (LV\u2217)(\u03c0) \u2265 \u2212c\u03c0 and V\u2217(\u03c0) \u2264 1 \u2212 \u03c0 , we obtain\nV\u2217(\u03c0) \u2264 E\u03c0\n[\n1 \u2212 \u03c0\u03c4 + c\n\u222b \u03c4\n0\n\u03c0t dt\n]\n(4.31)\nfor all \u03c4 from the class M(\u03c0), and hence V\u2217(\u03c0) \u2264 V (\u03c0) for all \u03c0 \u2208 [0,1].\nObserve that straightforward calculations above imply that the function V\u2217(\u03c0)\nand the boundary B\u2217 solve the system (4.4)\u2013(4.6); hence we have V\u2217(\u03c0\u03c4\u2217) =\n1\u2212 \u03c0\u03c4\u2217 and (LV\u2217)(\u03c0t ) = \u2212c\u03c0t for all 0 \u2264 t \u2264 \u03c4\u2217. Therefore, taking the expectation\non both sides in (4.29) with t replaced by \u03c4\u2217 and using the obvious fact that \u03c4\u2217\nbelongs to M(\u03c0), we see that the equality in (4.31) is attained at \u03c4 = \u03c4\u2217. This\nimplies that V\u2217(\u03c0) = V (\u03c0) for all \u03c0 \u2208 [0,1] and that B\u2217 is an optimal stopping\nboundary. Thus the proof is complete. \u0001\nREMARK 4.2. We observe that in case (i) of Theorem 4.1 we can verify\nthat f \u2032(B\u2217\u2212;B\u2217) = \u22121 and in the case (iv) we have proved that (4.28) holds,\nso that the smooth-fit condition (4.7) is satisfied. This can be explained by the\nfacts that the process (\u03c0t ) may pass through B\u2217 continuously and that (4.4) has no\nsingularity point. On the other hand, in case (ii) it is shown that f \u2032(B\u2217\u2212;B\u2217) =\n\u2212c\u03bb21\/(\u03bb0 \u2212 \u03bb1 \u2212 \u03bb\u03bb0\u03bb1) > \u22121 and in case (iii) it can be also proved that the\nsmooth-fit condition (4.7) breaks down. This can be explained by means of the\nfacts that the process (\u03c0t ) may pass through B\u2217 for the first time only by jumping\nand that (4.4) has a singularity point B\u0302 .\nON THE DISORDER PROBLEM 497\nREMARK 4.3. We note that the function f (\u03c0;B) for different B \u2208 (0,1) and\nthe function V\u2217(\u03c0) in cases (i)\u2013(iv) look the same as in [10], Figures 2\u20135.\n5. Solution of the variational problem for a compound Poisson process with\nexponential jumps. Let us first note that if \u03b1 \u2265 1 \u2212 \u03c0 , then letting \u03c4\u02c6 = 0 we get\nP\u03c0 [\u03c4\u02c6 < \u03b8] = P\u03c0 [\u03b8 > 0] = 1 \u2212 \u03c0 \u2264 \u03b1 and E\u03c0 [\u03c4\u02c6 \u2212 \u03b8]+ = 0, whence it is seen that\n\u03c4\u02c6 = 0 is optimal in the formulation (2.4) + (2.5).\nAssuming that 0 < \u03b1 < 1 \u2212 \u03c0 and following the arguments from [17],\npages 198\u2013200, we further show that the solution of the variational problem\n(2.4) + (2.5) can be obtained using the solution of the Bayesian problem. For this,\nlet us introduce the function\nu(\u03c0;B\u2217) = P\u03c0 [\u03c4\u2217 < \u03b8] (= E\u03c0 [1 \u2212 \u03c0\u03c4\u2217]).(5.1)\nTo find an explicit expression for the function u(\u03c0;B) in the case when \u03bb0 > \u03bb1,\nwe observe that, by virtue of the strong Markov property, it should solve the system\n(Lu)(\u03c0;B) = 0 (0 < \u03c0 < B),(5.2)\nu(\u03c0;B) = 1 \u2212 \u03c0 (B \u2264 \u03c0 \u2264 1).(5.3)\nBy means of the same arguments as in the text that accompanies the formulas\n(4.9)\u2013(4.21), it is shown that the system (5.2) + (5.3) admits the unique solution\nu(\u03c0;B) = 1 \u2212 B \u2212\n\u222b B\n\u03c0\n\u03b3 \u03bb1D(x,B)(1 \u2212 x)\n\u03bb1 + (\u03bb0 \u2212 \u03bb1)x\n(\nx\n1 \u2212 x\n)\u03b3\ndx,(5.4)\nD(\u03c0,B) = 1 \u2212 B\n\u03b3 (\u03b3 \u2212 1)A(\u03c0)\u03c0(1 \u2212 \u03c0)\nG(B)\nG(\u03c0)\n(1 \u2212 B\nB\n)\u03b3\n(5.5)\nfor \u03c0 \u2208 (0,B), \u03c0 \n= B\u0302 , where \u03b3 = \u03bb0\/(\u03bb0 \u2212 \u03bb1) > 1, the functions A(\u03c0) and\nG(\u03c0) are given by (4.18) and (4.20), respectively, and by l\u2019H\u00f4pital\u2019s rule, we can\nlet D(B\u0302,B) = D(B\u0302\u00b1,B) \u2261 0 as well as u(0;B) = u(0+;B).\nIt is not difficult to verify that \u2202u(\u03c0;B)\/(\u2202B) < 0 for B \u2208 (\u03c0,1), so that\nthe function u(\u03c0;B) is strictly decreasing on (\u03c0,1) for 0 < \u03c0 < 1 \u2212 \u03b1 fixed.\nTherefore, by virtue of the obvious facts that u(\u03c0;0) = 1 \u2212 \u03c0 and u(\u03c0;1) = 0,\nwe may conclude that there exists a point B(\u03b1) \u2264 1 \u2212 \u03b1 that is a unique solution\nof the equation\nu\n(\n\u03c0;B(\u03b1))= \u03b1.(5.6)\nLet us now formulate the main result of the section.\nTHEOREM 5.1. Suppose that the observed process X is given by (4.1). Then\nin the variational problem of quickest disorder detection (2.4) + (2.5), the optimal\nstopping time \u03c4\u02c6 is explicitly given by\n\u03c4\u02c6 = inf{t \u2265 0|\u03c0t \u2265 B(\u03b1)},(5.7)\nwhere the boundary B(\u03b1) \u2264 1 \u2212 \u03b1 is specified as follows:\n498 P. V. GAPEEV\n(i) If 0 < \u03b1 < 1 \u2212 \u03c0 and \u03bb0 > \u03bb1, then B(\u03b1) is a unique root of (5.6).\n(ii) If \u03b1 \u2265 1 \u2212 \u03c0 or \u03bb0 < \u03bb1, then B(\u03b1) = 1 \u2212 \u03b1.\nPROOF. (i) Let us consider the function B\u2217 = B\u2217(c) as an optimal boundary\nin the corresponding Bayesian problem which is uniquely determined from parts\n(i)\u2013(iii) of Theorem 4.1. It can be easily shown that B\u2217(c) is continuous and strictly\ndecreasing on (0,\u221e), and it satisfies limc\u21930 B\u2217(c) = 1 and limc\u2191\u221e B\u2217(c) = 0.\nThen there exists a constant c(\u03b1) such that B(\u03b1) = B\u2217(c(\u03b1)) and by the\ndefinition (2.2), we have\nP\u03c0 [\u03c4\u02c6 < \u03b8] + c(\u03b1)E\u03c0 [\u03c4\u02c6 \u2212 \u03b8]+ \u2264 P\u03c0 [\u03c4 < \u03b8] + c(\u03b1)E\u03c0 [\u03c4 \u2212 \u03b8]+(5.8)\nfor all stopping times \u03c4 . Since from (5.6) together with (5.1) and (3.5) it is seen\nthat P\u03c0 [\u03c4\u02c6 < \u03b8] = \u03b1, we may thus conclude that (5.8) directly yields\nc(\u03b1)E\u03c0 [\u03c4\u02c6 \u2212 \u03b8]+ \u2264 c(\u03b1)E\u03c0 [\u03c4 \u2212 \u03b8]+(5.9)\nfor all \u03c4 from M(\u03c0,\u03b1). Therefore, by virtue of the obvious fact that c(\u03b1) > 0 for\n0 < \u03b1 < 1 \u2212 \u03c0 , we obtain that \u03c4\u02c6 from (5.7) is optimal in (2.5).\n(ii) Since whenever \u03bb0 < \u03bb1, the process (\u03c0t ) can increase only continuously,\nwe get that {\u03c0\u03c4\u02c6 \u2265 B(\u03b1)} = {\u03c0\u03c4\u02c6 = B(\u03b1)}, and from (5.1) it thus follows that in this\ncase we have u(\u03c0;B) = 1 \u2212 B . Hence, from (5.6) it is seen that B(\u03b1) = 1 \u2212 \u03b1,\nand the arguments from the previous part (i) complete the proof. \u0001\nAcknowledgments. I am grateful to A. N. Shiryaev and G. Peskir for the\nstatement of the problem and for many helpful discussions. I am thankful to the\nEditor for the encouragement to prepare the revised version, and am obliged to an\nAssociate Editor and a referee for many useful suggestions which are incorporated\ninto the final version of the paper.\nREFERENCES\n[1] BARNDORFF-NIELSEN, O. E. (1995). Normal inverse Gaussian processes and the modelling\nof stock returns. Research Report 300, Dept. Theoretical Statistics, Aarhus Univ.\n[2] BERRY, D. A. and FRISTEDT, B. (1985). Bandit Problems: Sequential Allocation of Experi-\nments. Chapman and Hall, London.\n[3] CARLSTEIN, E., M\u00dcLLER, H.-G. and SIEGMUND, D., eds. (1994). Change-Point Problems.\nIMS, Hayward, CA.\n[4] DAVIS, M. H. A. (1976). A note on the Poisson disorder problem. Banach Center Publ. 1\n65\u201372.\n[5] DYNKIN, E. B. (1963). The optimum choice of the instant for stopping a Markov process.\nSoviet Math. Dokl. 4 627\u2013629.\n[6] GAL\u2019CHUK, L. I. and ROZOVSKII, B. L. (1971). The \u201cdisorder\u201d problem for a Poisson process.\nTheory Probab. Appl. 16 712\u2013716.\n[7] JACOD, J. and SHIRYAEV, A. N. (1987). Limit Theorems for Stochastic Processes. Springer,\nBerlin.\n[8] KOLMOGOROV, A. N., PROKHOROV, YU. V. and SHIRYAEV, A. N. (1990). Methods of\ndetecting spontaneously occurring effects. Proc. Steklov Inst. Math. 1 1\u201321.\nON THE DISORDER PROBLEM 499\n[9] MORDECKI, E. (1999). Optimal stopping for a diffusion with jumps. Finance Stochastics 3\n227\u2013236.\n[10] PESKIR, G. and SHIRYAEV, A. N. (2002). Solving the Poisson disorder problem. In Advances\nin Finance and Stochastics. Essays in Honour of Dieter Sondermann (K. Sandmann and\nP. Sch\u00f6nbucher, eds.) 295\u2013312. Springer, Berlin.\n[11] SATO, K. I. (1999). L\u00e9vy Processes and Infinitely Divisible Distributions. Cambridge Univ.\nPress.\n[12] SHIRYAEV, A. N. (1961). The detection of spontaneous effects. Soviet Math. Dokl. 2 740\u2013743.\n[13] SHIRYAEV, A. N. (1961). The problem of the most rapid detection of a disturbance in a\nstationary process. Soviet Math. Dokl. 2 795\u2013799.\n[14] SHIRYAEV, A. N. (1963). On optimum methods in quickest detection problems. Theory Probab.\nAppl. 8 22\u201346.\n[15] SHIRYAEV, A. N. (1965). Some exact formulas in a \u201cdisorder\u201d problem. Theory Probab. Appl.\n10 348\u2013354.\n[16] SHIRYAEV, A. N. (1967). Two problems of sequential analysis. Cybernetics 3 63\u201369.\n[17] SHIRYAEV, A. N. (1978). Optimal Stopping Rules. Springer, Berlin.\n[18] SHIRYAEV, A. N. (1999). Essentials of Stochastic Finance. World Scientific, Singapore.\nRUSSIAN ACADEMY OF SCIENCES\nINSTITUTE OF CONTROL SCIENCES\nPROFSOYUZNAYA STREET 65\n117997 MOSCOW\nRUSSIA\nE-MAIL: gapeev@cniica.ru\n"}
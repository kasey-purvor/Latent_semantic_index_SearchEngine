{"doi":"10.1111\/j.1467-9892.2008.00586.x","coreId":"212653","oai":"oai:eprints.lse.ac.uk:25186","identifiers":["oai:eprints.lse.ac.uk:25186","10.1111\/j.1467-9892.2008.00586.x"],"title":"A wavelet-Fisz approach to spectrum estimation","authors":["Fryzlewicz, Piotr","Nason, Guy P.","von Sachs, Rainer"],"enrichments":{"references":[{"id":17217744,"title":"A Haar-Fisz algorithm for Poisson intensity estimation.","authors":[],"date":"2004","doi":"10.1198\/106186004x2697","raw":"P. Fryzlewicz and G.P. Nason. A Haar-Fisz algorithm for Poisson intensity estimation. Journal of Computational and Graphical Statistics, 13:621{638, 2004.","cites":null},{"id":17217750,"title":"A Haar-Fisz technique for locally stationary volatility estimation. Biometrika, to appear,","authors":[],"date":"2006","doi":"10.1093\/biomet\/93.3.687","raw":"P. Fryzlewicz, T. Sapatinas, and S. Subba Rao. A Haar-Fisz technique for locally stationary volatility estimation. Biometrika, to appear, 2006.","cites":null},{"id":17217756,"title":"A theory for multiresolution signal decomposition: the wavelet representation.","authors":[],"date":"1989","doi":"10.1109\/34.192463","raw":"S. Mallat. A theory for multiresolution signal decomposition: the wavelet representation. IEEE Trans. Pattn Anal. Mach. Intell., 11:674{693, 1989.","cites":null},{"id":17217737,"title":"Adaptive estimation of the spectrum of a stationary Gaussian sequence.","authors":[],"date":"2001","doi":"10.2307\/3318739","raw":"F. Comte. Adaptive estimation of the spectrum of a stationary Gaussian sequence. Bernoulli, 7:267{298, 2001.","cites":null},{"id":17217760,"title":"Bayesian decision theoretic scale-adaptive estimation of a logspectral density.","authors":[],"date":"2003","doi":null,"raw":"M. Pensky and B. Vidakovic. Bayesian decision theoretic scale-adaptive estimation of a logspectral density. Preprint, 2003.","cites":null},{"id":17217752,"title":"Choice of thresholds for wavelet shrinkage estimate of the spectrum.","authors":[],"date":"1997","doi":"10.1111\/1467-9892.00048","raw":"H-Y. Gao. Choice of thresholds for wavelet shrinkage estimate of the spectrum. J. Time Ser. Anal., 18, 1997.","cites":null},{"id":17217741,"title":"Densities, spectral densities and modality.","authors":[],"date":"2004","doi":"10.1214\/009053604000000364","raw":"P.L. Davies and A. Kovac. Densities, spectral densities and modality. Ann. Stat., 32:1093{1136, 2004.","cites":null},{"id":17217754,"title":"Distributions in statistics: Continuous univariate distributions.","authors":[],"date":"1975","doi":"10.2307\/1266973","raw":"N. Johnson and S. Kotz. Distributions in statistics: Continuous univariate distributions. Wiley, 1975.","cites":null},{"id":17217749,"title":"Haar-Fisz estimation of evolutionary wavelet spectra.","authors":[],"date":"2005","doi":"10.1111\/j.1467-9868.2006.00558.x","raw":"P. Fryzlewicz and G.P. Nason. Haar-Fisz estimation of evolutionary wavelet spectra. Preprint, 2005.","cites":null},{"id":17217742,"title":"Ideal spatial adaptation by wavelet shrinkage.","authors":[],"date":"1994","doi":"10.2307\/2337118","raw":"D. L. Donoho and I. M. Johnstone. Ideal spatial adaptation by wavelet shrinkage. Biometrika, 81:425{455, 1994.","cites":null},{"id":17217738,"title":"Multitaper power spectrum estimation and thresholding: Wavelet packets versus wavelets.","authors":[],"date":"2002","doi":"10.1109\/tsp.2002.805503","raw":"A. C. Cristan and A. T. Walden. Multitaper power spectrum estimation and thresholding: Wavelet packets versus wavelets. IEEE Trans. Sig. Proc., 50:2976{2986, 2002.","cites":null},{"id":17217733,"title":"Posterior probability intervals for wavelet thresholding.","authors":[],"date":"2002","doi":"10.1111\/1467-9868.00332","raw":"S. Barber, G.P. Nason, and B.W. Silverman. Posterior probability intervals for wavelet thresholding. Journal of the Royal Statistical Society Series B, 64:189{205, 2002.","cites":null},{"id":17217761,"title":"Spectral Analysis and Time Series.","authors":[],"date":"1981","doi":"10.2307\/1268567","raw":"M. B. Priestley. Spectral Analysis and Time Series. Academic Press, 1981.","cites":null},{"id":17217739,"title":"Spectral analysis with tapered data.","authors":[],"date":"1983","doi":"10.1111\/j.1467-9892.1983.tb00366.x","raw":"R. Dahlhaus. Spectral analysis with tapered data. Journal of Time Series Analysis, 4:163{175, 1983.","cites":null},{"id":17217759,"title":"Spectral density estimation via nonlinear wavelet methods for stationary non-Gaussian time series.","authors":[],"date":"1996","doi":"10.1111\/j.1467-9892.1996.tb00295.x","raw":"M. H. Neumann. Spectral density estimation via nonlinear wavelet methods for stationary non-Gaussian time series. Journal of Time Series Analysis, 17:601{633, 1996.","cites":null},{"id":17217763,"title":"Statistical Modeling by Wavelets.","authors":[],"date":"1999","doi":"10.1002\/9780470317020","raw":"B. Vidakovic. Statistical Modeling by Wavelets. Wiley, New York, 1999.","cites":null},{"id":17217740,"title":"Ten Lectures on Wavelets.","authors":[],"date":"1992","doi":"10.1137\/1.9781611970104","raw":"I. Daubechies. Ten Lectures on Wavelets. SIAM, Philadelphia, Pa., 1992.","cites":null},{"id":17217755,"title":"The Spectral Analysis of Time Series.","authors":[],"date":"1995","doi":"10.1016\/b978-012419251-5\/50003-x","raw":"L.H. Koopmans. The Spectral Analysis of Time Series. Academic Press, San Diego, 2 edition, 1995.","cites":null},{"id":17217762,"title":"Time Series Analysis and Its Applications.","authors":[],"date":"2000","doi":"10.1007\/978-1-4757-3261-0","raw":"R.H. Shumway and D.S. Stoer. Time Series Analysis and Its Applications. Springer-Verlag, New York, 2000.","cites":null},{"id":17217734,"title":"Time Series: Data Analysis and Theory.","authors":[],"date":"1981","doi":"10.2307\/2530198","raw":"D.R. Brillinger. Time Series: Data Analysis and Theory. McGraw-Hill Inc., New York, 1981.","cites":null},{"id":17217735,"title":"Time Series: Theory and Methods.","authors":[],"date":"1987","doi":"10.1007\/978-1-4899-0004-3","raw":"P. J. Brockwell and R. A. Davis. Time Series: Theory and Methods. Springer, 1987.","cites":null},{"id":17217736,"title":"Translation-invariant de-noising.","authors":[],"date":"1995","doi":"10.1007\/978-1-4612-2544-7_9","raw":"19R.R. Coifman and D.L. Donoho. Translation-invariant de-noising. In Anestis Antoniadis and Georges Oppenheim, editors, Wavelets and Statistics, volume 103 of Lecture Notes in Statistics, pages 125{150. Springer-Verlag, New York, 1995.","cites":null},{"id":17217751,"title":"Wavelet estimation of spectral densities in time series analysis.","authors":[],"date":"1993","doi":null,"raw":"H-Y. Gao. Wavelet estimation of spectral densities in time series analysis. PhD thesis, University of California Berkeley, 1993.","cites":null},{"id":17217753,"title":"Wavelet Methods for Curve Estimation.","authors":[],"date":"2000","doi":null,"raw":"D. Herrick. Wavelet Methods for Curve Estimation. PhD thesis, University of Bristol, Bristol, U.K., 2000.","cites":null},{"id":17217758,"title":"Wavelet processes and adaptive estimation of the evolutionary wavelet spectrum.","authors":[],"date":"2000","doi":"10.1111\/1467-9868.00231","raw":"20G. P. Nason, R. von Sachs, and G. Kroisandt. Wavelet processes and adaptive estimation of the evolutionary wavelet spectrum. Journal of the Royal Statistical Society. Series B, 62:271{292, 2000.","cites":null},{"id":17217743,"title":"Wavelet shrinkage: asymptopia? (with discussion).","authors":[],"date":"1995","doi":"10.1007\/978-1-4612-1880-7_12","raw":"D. L. Donoho, I. M. Johnstone, G. Kerkyacharian, and D. Picard. Wavelet shrinkage: asymptopia? (with discussion). Journal of the Royal Statistical Society Series B, 57:301{369, 1995.","cites":null},{"id":17217757,"title":"Wavelet thresholding techniques for power spectrum estimation.","authors":[],"date":"1994","doi":"10.1109\/78.330372","raw":"P. Moulin. Wavelet thresholding techniques for power spectrum estimation. IEEE Trans. Sig. Proc., 42:3126{3136, 1994.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-09","abstract":"We suggest a new approach to wavelet threshold estimation of spectral densities of stationary\\ud\ntime series. It is well known that choosing appropriate thresholds to smooth the periodogram is\\ud\ndifficult because non-parametric spectral estimation suffers from problems similar to curve estimation\\ud\nwith a highly heteroscedastic and non-Gaussian error structure. Possible solutions that\\ud\nhave been proposed are plug-in estimation of the variance of the empirical wavelet coefficients\\ud\nor the log-transformation of the periodogram.\\ud\nIn this paper we propose an alternative method to address the problem of heteroscedasticity\\ud\nand non-normality. We estimate thresholds for the empirical wavelet coefficients of the (tapered)\\ud\nperiodogram as appropriate linear combinations of the periodogram values similar to empirical\\ud\nscaling coefficients. Our solution permits the design of \\asymptotically noise-free thresholds\",\\ud\nparalleling classical wavelet theory for nonparametric regression with Gaussian white noise errors.\\ud\nOur simulation studies show promising results that clearly improve the classical approaches\\ud\nmentioned above. In addition, we derive theoretical results on the near-optimal rate of convergence\\ud\nof the minimax mean-square risk for a class of spectral densities, including those of very\\ud\nlow regularity","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/212653.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/25186\/1\/A_wavelet-Fisz_approach_to_spectrum_estimation%28lsero%29.pdf","pdfHashValue":"c8052b6ac623c1693fc7dae24bae9ce31f7d6bcb","publisher":"Blackwell Publishing","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:25186<\/identifier><datestamp>\n      2011-11-25T11:15:41Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5354<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/25186\/<\/dc:relation><dc:title>\n        A wavelet-Fisz approach to spectrum estimation<\/dc:title><dc:creator>\n        Fryzlewicz, Piotr<\/dc:creator><dc:creator>\n        Nason, Guy P.<\/dc:creator><dc:creator>\n        von Sachs, Rainer<\/dc:creator><dc:subject>\n        HA Statistics<\/dc:subject><dc:description>\n        We suggest a new approach to wavelet threshold estimation of spectral densities of stationary\\ud\ntime series. It is well known that choosing appropriate thresholds to smooth the periodogram is\\ud\ndifficult because non-parametric spectral estimation suffers from problems similar to curve estimation\\ud\nwith a highly heteroscedastic and non-Gaussian error structure. Possible solutions that\\ud\nhave been proposed are plug-in estimation of the variance of the empirical wavelet coefficients\\ud\nor the log-transformation of the periodogram.\\ud\nIn this paper we propose an alternative method to address the problem of heteroscedasticity\\ud\nand non-normality. We estimate thresholds for the empirical wavelet coefficients of the (tapered)\\ud\nperiodogram as appropriate linear combinations of the periodogram values similar to empirical\\ud\nscaling coefficients. Our solution permits the design of \\asymptotically noise-free thresholds\",\\ud\nparalleling classical wavelet theory for nonparametric regression with Gaussian white noise errors.\\ud\nOur simulation studies show promising results that clearly improve the classical approaches\\ud\nmentioned above. In addition, we derive theoretical results on the near-optimal rate of convergence\\ud\nof the minimax mean-square risk for a class of spectral densities, including those of very\\ud\nlow regularity.<\/dc:description><dc:publisher>\n        Blackwell Publishing<\/dc:publisher><dc:date>\n        2008-09<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/25186\/1\/A_wavelet-Fisz_approach_to_spectrum_estimation%28lsero%29.pdf<\/dc:identifier><dc:identifier>\n          Fryzlewicz, Piotr and Nason, Guy P. and von Sachs, Rainer  (2008) A wavelet-Fisz approach to spectrum estimation.  Journal of Time Series Analysis, 29 (5).  pp. 868-880.  ISSN 0143-9782     <\/dc:identifier><dc:relation>\n        http:\/\/www.wiley.com\/bw\/journal.asp?ref=0143-9782&site=1<\/dc:relation><dc:relation>\n        10.1111\/j.1467-9892.2008.00586.x<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/25186\/","http:\/\/www.wiley.com\/bw\/journal.asp?ref=0143-9782&site=1","10.1111\/j.1467-9892.2008.00586.x"],"year":2008,"topics":["HA Statistics"],"subject":["Article","PeerReviewed"],"fullText":" \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nPiotr Fryzlewicz, Guy P. Nason and Rainer von Sachs \nA wavelet-Fisz approach to spectrum \nestimation \n \n \n \nArticle (Accepted version) \n(Unrefereed) \n \n \n \n \nOriginal citation: \nFryzlewicz, Piotr and Nason, Guy P. and von Sachs, Rainer (2008) A wavelet-Fisz approach to \nspectrum estimation. Journal of time series analysis, 29 (5). pp. 868-880. ISSN 0143-9782 \nDOI:  10.1111\/j.1467-9892.2008.00586.x \n \n\u00a9 2008 Wiley-Blackwell Publishing \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/25186\/ \nAvailable in LSE Research Online: November 2011 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website. \n \nThis document is the author\u2019s final accepted version of the journal article. There may be \ndifferences between this version and the published version.  You are advised to consult the \npublisher\u2019s version if you wish to cite from it. \nA wavelet-Fisz approach to spectrum estimation\nPiotr Fryzlewicz\u2217, Guy P. Nason\nDepartment of Mathematics,\nUniversity of Bristol,\nUniversity Walk,\nBristol BS8 1TW,\nUK.\n{p.z.fryzlewicz,g.p.nason}@bris.ac.uk\nand\nRainer von Sachs\nInstitut de statistique,\nUniversite\u00b4 Catholique de Louvain,\nVoie du Roman Pays, 20\nB-1348 Louvain-la-Neuve,\nBelgium.\nrvs@stat.ucl.ac.be\nMarch 21, 2006\n\u2217Author for correspondence.\n1\nAbstract\nWe suggest a new approach to wavelet threshold estimation of spectral densities of stationary\ntime series. It is well known that choosing appropriate thresholds to smooth the periodogram is\ndifficult because non-parametric spectral estimation suffers from problems similar to curve esti-\nmation with a highly heteroscedastic and non-Gaussian error structure. Possible solutions that\nhave been proposed are plug-in estimation of the variance of the empirical wavelet coefficients\nor the log-transformation of the periodogram.\nIn this paper we propose an alternative method to address the problem of heteroscedasticity\nand non-normality. We estimate thresholds for the empirical wavelet coefficients of the (tapered)\nperiodogram as appropriate linear combinations of the periodogram values similar to empirical\nscaling coefficients. Our solution permits the design of \u201casymptotically noise-free thresholds\u201d,\nparalleling classical wavelet theory for nonparametric regression with Gaussian white noise er-\nrors. Our simulation studies show promising results that clearly improve the classical approaches\nmentioned above. In addition, we derive theoretical results on the near-optimal rate of conver-\ngence of the minimax mean-square risk for a class of spectral densities, including those of very\nlow regularity.\nKey words: spectral density estimation, wavelet thresholding, wavelet-Fisz, periodogram,\nBesov spaces, smoothing.\n1 Introduction\nThe estimation of spectral densities is a fundamental problem in both theoretical and applied\ntime series analysis. Priestley (1981) provides a comprehensive introduction to the spectral\nanalysis of time series. Typically, inference in the spectral domain is based on the periodogram\nof the data xt. Often, a data taper is applied prior to computing the periodogram, in order\nto reduce leakage (Dahlhaus (1983)). It is well known that the (tapered) periodogram is an\ninconsistent estimator of the spectral density and needs to be smoothed to achieve consistency.\nDepending on the theoretical properties of the underlying stationary stochastic process Xt\nand the associated spectral density f(\u03c9), various periodogram smoothing techniques have been\nproposed. For spectral densities with a high degree of regularity, linear smoothing techniques\n(e.g. kernel smoothing) are appropriate. They are covered extensively in the literature: we\nrefer the reader, for example, to the monographs of Brillinger (1981), Koopmans (1995) and\nShumway and Stoffer (2000). The application of multiple tapers leads to, both leakage-reduced\nand smoothed, multitaper spectrum estimators, see e.g. Cristan and Walden (2002) and the\nreferences therein.\nHowever, it is well known that linear smoothing methods are incapable of achieving the\noptimal mean-square rate of convergence in cases where the underlying regression function\npossesses a low degree of regularity. Thus, in the case of discontinuous (or otherwise irregular)\nspectral densities, smoothing the periodogram using a nonlinear method might be more suitable.\nTwo such methods were recently proposed by Comte (2001) and Davies and Kovac (2004).\nIn the \u201cfunction + iid Gaussian noise\u201d regression model, wavelet thresholding, first proposed\nby Donoho and Johnstone (1994), has become the nonlinear smoothing method of choice for\nmany theoreticians and practitioners if the regression function is of low regularity. Thus, the\nidea of smoothing the periodogram using a nonlinear wavelet method might seem appealing.\nHowever, the periodogram approximately follows a multiplicative regression set-up where the\nvariance of the \u201cnoise\u201d is not constant over frequencies but is proportional to the level of the\nunderlying spectral density. This represents a hurdle for nonlinear wavelet thresholding, where\n2\nthe variance of the noise needs to be either known or easily estimable. To tackle this problem,\ntwo main approaches have been proposed in the literature.\nThe first approach consists in taking the logarithmic transform of the periodogram to stabilize\nthe variance and transform the model from multiplicative to additive, and only then proceeding\nwith the wavelet smoothing. This idea was first proposed by Gao (1993, 1997). Moulin (1994)\nderived wavelet thresholds for the logged periodogram using saddle point estimation techniques.\nPensky and Vidakovic (2003) derived thresholds for the log-periodogram using the Bayesian\nparadigm but also demonstrated their frequentist mean-square properties. The \u201cprice\u201d for\nusing the log transform is that it flattens out the data, often obscuring interesting features, such\nas peaks or troughs. Also, the resulting exponentiated estimators of the spectrum are biased,\nand even after the bias correction, their mean-square properties are not easy to establish.\nThe second approach (Neumann, 1996) consists in pre-estimating the variance of the peri-\nodogram via kernel smoothing, so that it can be supplied to the wavelet estimation procedure.\nAs with other plug-in estimators, the question of the choice of the pre-estimation procedure and\nits parameters arises. Also, kernel pre-estimation may not be appropriate in cases where the\nunderlying spectral density is, for example, discontinuous.\nTo overcome the drawbacks of the above log-based and plug-in estimators, we propose a new\nnonlinear wavelet smoothing technique for the periodogram, where thresholds for the empirical\nwavelet coefficients are constructed as appropriate local weighted l1 norms of the periodogram,\nas opposed to the l2 norm used in Neumann (1996). As explained in Section 2, the use of the\nl1 norm is motivated by the fact that, asymptotically, the mean of the periodogram is equal to\nits standard deviation. Also, unlike Neumann (1996), we avoid the kernel pre-estimation of the\nspectral density. Our approach yields a rapidly computable, mean-square consistent estimator\nwhich performs well in practice. Also, it permits the construction of noise-free reconstruction\nthresholds which produce visually appealing estimates and offer particularly impressive empirical\nperformance.\nThe paper is organised as follows. In the next section we recall the set-up of nonparamet-\nric estimation of spectral densities and give a non-technical motivation for our new approach.\nSection 3 contains our main theoretical achievements where we show near-optimal rates of con-\nvergence of the mean-square risk of our new spectral estimator over a class of spectral densities\nwhich also includes those of low regularity. The following section addresses the construction of\nso-called \u201cnoise-free thresholds\u201d which are designed to work better in non-asymptotic settings.\nIn a simulation section we compare our new approach with some of the established estimation\nmethods mentioned above. Proofs, and additional theoretical results that complete them, are\nin the Appendix.\n2 Set-up and motivation\nIn this introductory section, we both establish the technical assumptions for our set-up and give,\nby a simplified presentation of the spectral estimation problem, the essential motivation for our\nnew approach. It is only in Section 3 that we turn to a more formal asymptotic treatment of\nwavelet estimation of spectral densities.\n3\n2.1 Problem set-up\nAssume that we observe a sample path {Xt}Nt=1 of a real-valued, zero-mean, second-order sta-\ntionary process {Xt}\u221et=1. Our aim is to estimate the spectral density\nf(\u03c9) =\n1\n2pi\n\u221e\u2211\ns=\u2212\u221e\ncov(Xt, Xt+s) exp(\u2212i\u03c9s), \u03c9 \u2208 [\u2212pi, pi].\nThroughout the paper, we restrict our interest to processes whose spectral densities satisfy the\nfollowing assumption.\nAssumption 2.1 The spectral density f(\u03c9) satisfies\n(i) f(\u03c9) \u2265 \u00b5 > 0,\n(ii) f is of finite total variation over [\u2212pi, pi].\nNote that Assumption 2.1(i) would be natural in the context of log-spectrum estimation as\nit would guarantee that the log-spectrum was bounded from below. Since our wavelet-Fisz\nestimation method can also be viewed as based on the principle of variance stabilization (albeit\ncarried out in the wavelet domain), it is perhaps not surprising that we also require Assumption\n2.1(i) to hold. Assumption 2.1(ii) is a mild smoothness assumption on f .\nWe also place the following technical assumption on the process itself.\nAssumption 2.2 Assume\nsup\n1\u2264t1<\u221e\n(\n\u221e\u2211\nt2,...,tk=1\n| cum(Xt1 , . . . , Xtk)|\n)\n\u2264 Ck(k!)1+\u03b3 ,\nfor all k = 2, 3, . . ., where C is a generic positive constant and \u03b3 \u2265 0.\nAs in Neumann (1996), Assumption 2.2 implies asymptotic normality of the (appropriately\nscaled) local cumulative sums of Xt. The supremum on the left-hand side guarantees that the\nasymptotic normality is, in a sense, uniform over time t. By Remark 3.1 in Neumann (1996),\nif Xt is \u03b1-mixing an an appropriate rate and its marginal distribution is Gaussian, exponential,\ngamma, or inverse Gaussian, then \u03b3 can be set equal to zero. For heavier-tailed distributions, a\npositive value of \u03b3 might be required.\nOur nonparametric estimator will be based on the periodogram of the (possibly tapered)\nobservations\nIN (\u03c9) = (2piH\n(N)\n2 )\n\u22121\n\u2223\u2223\u2223\u2223\u2223\nN\u2211\ns=1\nh\n( s\nN\n)\nXs exp(\u2212i\u03c9s)\n\u2223\u2223\u2223\u2223\u2223\n2\n,\nwhere H\n(N)\nk =\n\u2211N\ns=1 h\nk(s\/N) and the taper function h(x) : [0, 1] \u2192 R satisfies the following\nassumption.\nAssumption 2.3 The taper function h is of bounded variation and satisfies H :=\n\u222b 1\n0 h\n2(x)dx >\n0.\nWith this assumption, we obtain, in particular, that H\n(N)\n2 \u223c NH . Note that h(x) \u2261 1 yields the\nnon-tapered periodogram. We refer the reader to Dahlhaus (1983) for a discussion of some in-\nteresting properties of tapered periodograms. A classical example of a non-trivial taper function\nis the so-called Hanning window (see e.g. Priestley, 1981, Section 7.4.1), defined by\nh(u) =\n{\n1\n2 (1\u2212 (cos 2piu)), if u \u2208 [0, 12 ]\nh(1\u2212 u), if u \u2208 [ 12 , 1]\n.\n4\nThe Hanning window is well known to reduce leakage effects which occur in spectra with a high\ndynamic range.\nIt is well known that the (tapered) periodogram is an inconsistent estimator of the spectral\ndensity and thus needs to be smoothed to achieve consistency. The next section describes our\nwavelet-Fisz method for smoothing IN (\u03c9).\n2.2 Motivation for the wavelet-Fisz approach\nAs mentioned in Section 2.1, our estimation methodology allows spectral densities which are\ndiscontinuous, since we only impose a total variation constraint. Ignoring for a moment these\ndiscontinuities, we base our motivation on the following well known facts of spectral estimation\ntheory (see e.g. Brockwell and Davis, 1987, Section 10.3). Periodogram ordinates IN (\u03c9k),\ncomputed at the Fourier frequencies \u03c9k = 2pik\/N \u2212 pi, k = N\/2, . . . , N , are asymptotically\nindependent and exponentially distributed with means f(\u03c9k) (except, in most cases, the \u201cedge\u201d\nfrequencies 0 and pi, but we shall ignore this fact for the time being).\nMotivated by this observation, we choose to demonstrate the basic mechanics of our estima-\ntion procedure on the following simplified model:\nJn(\u03c9k) = f(\u03c9k) ek, (1)\nwhere {ek}nk=1 is a sequence of iid variables distributed as Exp(1). In the model (1) we are now\nfaced with the problem of estimating the means f(\u03c9k) of Jn(\u03c9k). The model (1) is considered\nmerely for pedagogical purposes: our rigorous results in Section 3 concern estimation in the full\nmodel specified in Section 2.1. The quantity modelled in (1) is labelled as Jn to avoid confusion\nwith IN .\nAs mentioned in the Introduction, we base our estimation theory on wavelets. Since the sem-\ninal work of Donoho and Johnstone (1994), nonlinear estimation techniques based on wavelets\nhave become a popular and extensively studied tool for non-parametric regression. Many of them\ncombine excellent finite-sample performance, linear computational complexity, and optimal (or\nnear-optimal) asymptotic mean-square error behaviour over a variety of function smoothness\nclasses. A general overview of wavelet methods in statistics can be found, for example, in\nVidakovic (1999).\nA convenient starting point for wavelet estimation is the formulation of the regression prob-\nlem at hand in a \u201cfunction + noise\u201d setting, where the noise has mean zero and its variance is\neither known or can easily be estimated. Note that the logarithmic transformation transforms\nthe model (1) from multiplicative to additive:\nlog Jn(\u03c9k) = log f(\u03c9k) + E log ek + \u03b5k, (2)\nwhere \u03b5k = log ek\u2212E log ek has mean zero and a variance independent of k. Thus, many authors\n(some references are given in the Introduction) considered wavelet estimation of the log-spectral\ndensity in the logged model (2). However, one drawback of using the log transformation is\nthat it flattens out the data, often obscuring interesting features, e.g. spectral peaks which\nindicate hidden periodicities of the process. Also, the mean-square properties of the resulting\nexponentiated estimator of the spectral density f are not easy to establish.\nTo avoid these problems, it might be beneficial to work with the model (1) directly, without\nthe prior logarithmic transform. The model (1) can be rewritten as\nJn(\u03c9k) = f(\u03c9k) + \u03b5\u02dck,\n5\nwhere \u03b5\u02dck = f(\u03c9k)(ek \u2212 1). Applying the Discrete Wavelet Transform (DWT), a multiscale\northonormal linear transform, gives\n\u03d1\u02dcj,k = \u03d1j,k + \u03b5\u02dcj,k, j = 0, . . . , log2 n\u2212 1, k = 1, . . . , 2j ,\nand k = 1 for j = \u22121, where j and k are (respectively) scale and location parameters, and \u03d1\u02dcj,k,\n\u03d1j,k and \u03b5\u02dcj,k are the wavelet coefficients of Jn(\u03c9k), f(\u03c9k) and \u03b5\u02dck, respectively. For a large class\nof functions f , the sequence \u03d1j,k is sparse, with most \u03d1j,k\u2019s being equal, or close, to zero, which\nmotivates the use of simple thresholding estimators \u03d1\u02c6j,k which estimate \u03d1j,k by zero if and only\nif the corresponding empirical wavelet coefficient \u03d1\u02dcj,k falls below certain threshold in absolute\nvalue. This ensures that a large proportion of the noise \u03b5\u02dcj,k gets removed. The inverse DWT of\nthe thresholded coefficients \u03d1\u02c6j,k then yields an estimate f\u02c6 of the original function f .\nDrawing inspiration from the \u201cuniversal\u201d threshold theory first developed by Donoho and\nJohnstone (1994) in the Gaussian regression case, Neumann (1996) estimates \u03d1j,k by \u03d1\u02c6j,k =\n\u03d1\u02dcj,kI(|\u03d1\u02dcj,k | > tj,k), where the thresholds tj,k are set equal to\ntj,k = \u03c3\u02dcj,k\n\u221a\n2 log n (3)\nwith \u03c3\u02dcj,k = {var(\u03b5\u02dcj,k)}1\/2. In the simplified model (1), each \u03c3\u02dcj,k is of the form\n\u03c3\u02dcj,k =\n\uf8f1\uf8f2\uf8f3\nLj\u2211\nl=1\n\u03c82j,lf\n2(\u03c9l+\u03c4 )\n\uf8fc\uf8fd\uf8fe\n1\/2\n, (4)\nwhere \u03c4 is a shift parameter dependent on j and k, \u03c8j are discrete wavelet vectors (as described,\nfor example, in Nason et al. (2000)), and Lj are their support lengths. Obviously, f\n2 is unknown,\nand Neumann (1996) overcomes this by pre-estimating f(\u03c9k) via kernel smoothing, and using\nthe pre-estimate to obtain estimates of \u03c3\u02dcj,k which are then used in (3). Although simple and\nintutive, this approach generates a number of questions.\nFirstly, as mentioned in Section 2.1, the spectral density f may not be smooth as we only\nimpose the total variation constraint of f . In this case, pre-estimating f via kernel smoothing\nmight not be suitable in practice as discontinuities and\/or other irregularities in f will be\nsmoothed out. This is then likely to affect the performance of the final estimator f\u02c6 . Also, as\nwith any other non-parametric plug-in estimator, the kernel estimator would demand a choice\nof smoothing parameter, which might not be easy to select optimally.\nTo circumvent this, it may be advantageous to pre-estimate f(\u03c9k) in (4) by the inherently\nlocal estimate Jn(\u03c9k), for most scales j coarser than the observation scale. To the best of\nour knowledge, this approach has not been considered in literature. With this approach, the\nestimated \u03c3\u02dcj,k is simply a local weighted l2 norm of {Jn(\u03c9k)}k.\nOur wavelet-Fisz methodology is inspired by this observation, but instead of the local\nweighted l2 norm, it estimates thresholds using a local weighted l1 norm of {Jn(\u03c9k)}k. The\nheuristic reason for this is as follows. As the wavelet vectors \u03c8j are compactly supported and\nwell localised, and the function f(\u03c9) is likely to be \u201cmostly smooth\u201d (possibly with occasional\nirregularities), the hope is that for most values of j and k, the function f(\u03c9) can be well ap-\nproximated by a constant over the support of \u03c8j . Denoting the approximating constant by fj,k,\nand using the fact that \u2016\u03c82j\u20162 = 1, formula (4) implies that \u03c3\u02dcj,k is approximately equal to fj,k.\nThus, estimating \u03c3\u02dcj,k is approximately equivalent to estimating the constant fj,k, which is sim-\nply the local mean of an iid exponential sample. Because the maximum likelihood estimator of\nthe mean (= standard deviation) of an iid exponential sample is the sample mean, rather than\nthe sample standard deviation, we propose to estimate thresholds as a local weighted l1 norm of\n6\n{Jn(\u03c9k)}k, rather than the local l2 norm. The hope is that this provides a better estimator as it\nis known that the sample mean is a more regular statistic than the sample standard deviation.\nThe added benefit of using the local l1 norm, as opposed to l2, is that it permits the con-\nstruction of noise-free reconstruction thresholds, as detailed in Section 4.\nThe idea of using a local weighted l1 norm also underlies the Haar-Fisz estimation theory,\nintroduced by Fryzlewicz and Nason (2005) and Fryzlewicz et al. (2006) for other multiplicative\nmodels, namely for wavelet spectrum and locally stationary volatlity estimation, respectively.\nThe fundamental novelty of our approach is that we use general wavelets, as opposed to the\nHaar wavelets used in the latter work. This generalisation is essential as it permits us to include\nsome commonly encountered spectral densities (such as those corresponding to AR processes)\nin our estimation theory, which would not have been possible had we just used Haar wavelets.\nOn the other hand, more general wavelets require the use of different proof techniques. We also\nnote that Haar-Fisz estimation was first proposed by Fryzlewicz and Nason (2004), albeit in the\nnon-multiplicative context of Poisson intensity estimation.\n3 Wavelet-Fisz spectral density estimation\n3.1 Preparing the asymptotic set-up\nIn order to demonstrate asymptotic mean-square consistency of our proposed estimator, we\nembed our approach into the appropriate framework for theory, i.e. using orthonormal wavelets\ndefined as continuous square-integrable functions over a unit interval. For the remainder, we\nmean our wavelet bases to be 2pi\u2212periodic and defined on the [\u2212pi, pi] in the (periodised) fre-\nquency domain, as both our target function to estimate and our estimators themselves are\n2pi\u2212periodic. In order to keep our presentation sufficiently simple, we will use a notation with a\n\u201cclassical\u201d wavelet basis; details of how to periodise it can be found in, e.g., Daubechies (1992).\nAssumption 3.1 {\u03c60,k}k \u222a {\u03c8j,k}j\u22650;k are chosen to form an orthonormal basis of L2[\u2212pi, pi],\nwhere the functions \u03c6 and \u03c8 satisfy, for any r > m (with m \u2265 1 given by Theorem 3.1 below),\n(i) \u03c6 and \u03c8 are in Cr, which implies, in particular, that they have finite total variation over\n[\u2212pi, pi],\n(ii)\n\u222b\n\u03c6(x) dx = 1,\n(iii)\n\u222b\n\u03c8(x)xl dx = 0 for 0 \u2264 l \u2264 r.\nAs usual in multiscale wavelet theory, we use the notation gj,k(x) := 2\nj\/2 g(2j x \u2212 k), where\ng = \u03c8, \u03c6, so that the scaled and shifted functions \u03c8j,k and \u03c60,k are all normalised to square-\nintegrate to one. The indices j and k are \u201cscale\u201d and \u201clocation\u201d parameters, respectively.\nTo set up the notation for our wavelet threshold spectral estimator, let\nf\u0302(\u03c9) =\n\u2211\nk\n\u03b1\u02dck \u03c60,k(\u03c9) +\n\u2211\n(j,k)\u2208JN\n\u03c1(.)(\u03b1\u02dcj,k , \u03bbj,k) \u03c8j,k(\u03c9) , (5)\nwhere \u03c1(.)(\u03b1, \u03bb) denotes either the hard or the soft threshold rule applied to the coefficient \u03b1 us-\ning the threshold \u03bb, and the empirical wavelet coefficients are defined as \u03b1\u02dcj,k =\n\u222b\n\u03c8j,k(\u03c9)IN (\u03c9)d\u03c9\nand \u03b1\u02dck =\n\u222b\n\u03c60,kIN (\u03c9)d\u03c9. The corresponding true coefficients are defined by \u03b1j,k =\n\u222b\n\u03c8j,k(\u03c9)f(\u03c9)d\u03c9\nand \u03b1k =\n\u222b\n\u03c60,kf(\u03c9)d\u03c9.\nAs in Neumann (1996), we define JN = {(j, k) | 2j \u2264 C N1\u2212\u03b4} for some \u03b4 > 0 ; thus, the\nestimator f\u0302(\u03c9) includes a growing number of coarsest scales j, and excludes a growing number\nof finest scales. This is done to ensure that a certain asymptotic normality effect holds, see\n7\nformula (23) in the Appendix. The parameter \u03b4 is chosen so that\n\u2211\n(j,k)\/\u2208JN\n\u03b12j,k = O(N\n\u22121).\nAs will be seen from equation (11) below, the choice of 0 < \u03b4 \u2264 1\/3 and an arbitrary C <\u221e is\nsufficient.\n3.2 Construction of the wavelet-Fisz thresholds\nAs thoroughly motivated in Section 2.2, we require \u201ctheoretical\u201d thresholds \u03bbj,k in (5) which\ncould be estimated as local weighted l1 norms of the periodogram. For this to be possible, we\ndefine our \u03bbj,k as\n\u03bbj,k = \u03b8j,k\n\u221a\n2 log(#JN ), (6)\nwith\n\u03b8j,k = cN\n\u222b pi\n\u2212pi\n\u03baj,k(\u03c9)f(\u03c9)d\u03c9, (7)\nwhere, for reasons outlined in Section A.1, we take cN =\n\u221a\n2pi\/N H4\/H22 =: cN\n\u22121\/2. The \u03baj,k\nare nonnegative functions on L2[\u2212pi, pi] which are normalised to integrate to one. Although our\napproach allows for a relatively general choice of these weight functions, we focus our attention\non \u201cmod-wavelets\u201d, defined by \u03baj,k(\u00b7) := 2j \u03ba(2j \u00b7 \u2212k), where \u03ba(\u03c9) := |\u03c8(\u03c9)|\/\n\u222b |\u03c8(\u03c9)|d\u03c9. Our\nparticular choice of \u03baj,k is motivated by the derivation of the \u201cnoise-free reconstruction thresh-\nolds\u201d, see Section 4. Note that since\n\u222b\n\u03baj,k(\u03c9)d\u03c9 = 1, the parameters \u03b8j,k can be interpreted as\nlocal weighted l1 norms of f at scale j and location k.\nSince, obviously, thresholds \u03bbj,k are impracticable as they involve the unknown function f ,\nwe need to define our estimated thresholds \u03bb\u0302j,k. We propose the choice\n\u03bb\u0302j,k = \u03b8\u0302j,k\n\u221a\n2 log(#JN ) , (8)\nwhere\n\u03b8\u0302j,k = cN\n\u222b pi\n\u2212pi\n\u03baj,k(\u03c9) IN (\u03c9)d\u03c9. (9)\nWith this choice, our final estimator becomes\nf\u02dc(\u03c9) =\n\u2211\nk\n\u03b1\u02dck \u03c60,k(\u03c9) +\n\u2211\n(j,k)\u2208JN\n\u03c1(.)(\u03b1\u02dcj,k , \u03bb\u0302j,k) \u03c8j,k(\u03c9) . (10)\n3.3 Near-optimal rate of mean-square convergence\nThe near-optimal mean-square convergence rate of our coordinatewise thresholded wavelet spec-\ntral estimator f\u02dc is formulated in Theorem 3.1 below. As the rate of convergence will be faster\nthe higher the regularity of the target function to estimate, we assume that the spectral density\nf lies in a ball F of a quite general function space: a Besov space Bmp,q (with m, p \u2265 1). This\nmeans a slightly more general set-up than a Sobolev regularity for f , in that f is assumed to\nhave m generalised derivatives in Lp, with the parameter q allowing for additional spatial inho-\nmogeneity. For these function balls, the optimal rate of mean-square convergence, the so-called\n\u201cminimax rate\u201d, is N\u2212\n2m\n2m+1 . More details on Besov spaces in the context of wavelet thresholding\ncan be found, e.g., in Donoho et al. (1995). In this context, it is known that for the wavelet\ncoefficients \u03b1j,k of f in any ball F of B\nm\np,q ,\nsup\nf\u2208F\n\u2211\nj>J\n2j\u22121\u2211\nk=0\n\u03b12j,k = O (2\n\u22122J(m+1\/2\u22121\/(min(p,2))) , (11)\n8\nwhich is of order O(N\u2212\n2m\n2m+1 ) if 2\u2212J = O(N\u2212\n2\n3 ) (see Theorem 8 in, again, Donoho et al. (1995)).\nThis suggests choosing 0 < \u03b4 \u2264 1\/3 in the definition of JN = {(j, k) | 2j \u2264 C N1\u2212\u03b4}.\nThe proof of Theorem 3.1 works via showing the analogous result for our \u2018bona fide\u2019 estimator\nf\u0302 defined in (5), based on thresholds \u03bbj,k which can be as defined in formula (6), but, more\ngenerally, are required to satisfy the following assumption.\nAssumption 3.2 Let \u03c32j,k = var(\u03b1\u02dcj,k) (see Lemma A.1 for the exact formula for \u03c3\n2\nj,k), and let\nm be as in the statement of Theorem 3.1. Thresholds \u03bbj,k are such that\u2211\n(j,k)\u2208JN\n(\n\u03bbj,k\n\u03c3j,k\n+ 1\n)\n\u03c6(\u03bbj,k\/\u03c3j,k) = O(N\n1\/(2m+1)) (12)\nsup\n(j,k)\u2208JN\n\u03bbj,k = O(N\n\u22121\/2\n\u221a\nlog N), (13)\nwhere \u03c6 is the standard normal density.\nNote that by Lemma A.2 (with \u03b1N = 1), our thresholds \u03bbj,k , defined in formula (6), satisfy\nAssumption 3.2. As the result on the near-optimal convergence rate of the estimator f\u0302 is of\npurely theoretical interest, its statement appears in the Appendix, as Theorem A.1.\nHeuristically speaking, Assumption 3.2 controls the distance between the thresholds \u03bbj,k and\nthe benchmark \u201cuniversal\u201d thresholds \u03bbNj,k = \u03c3j,k\n\u221a\n2 log(#JN ), used, for example, by Neumann\n(1996). This is needed as the latter are motivated by the universal threshold theory in the\nGaussian regression case, and our thresholds \u03bbj,k also rely on asymptotic Gaussianity arguments.\nTheorem 3.1 works for our thresholds \u03bb\u0302j,k defined in formula (8), and, in more generality,\nfor any thresholds \u03bb\u0302j,k satisfying the following assumption.\nAssumption 3.3 Let \u03bbj,k be any thresholds satisfying Assumption 3.2, and let m be as in the\nstatement of Theorem 3.1. Thresholds \u03bb\u0302j,k are such that\n(i) There exists a \u03bd < 1\/(2m + 1) and a positive sequence \u03b1N approaching 1 from below as\nN \u2192\u221e such that \u2211\n(j,k)\u2208JN\nP(\u03bb\u02c6j,k < \u03b1N \u03bbj,k) = O(N\n\u03bd);\n(ii) There exists a constant C\u02dc <\u221e such that\u2211\n(j,k)\u2208JN\nP(\u03bb\u02c6j,k > C\u02dc N\n\u22121\/2\n\u221a\nlog N) = O(N\u2212\n2m\n2m+1 ).\nIn the final part of the Appendix, we demonstrate that if \u03bbj,k are as defined in (6), then our\nrandom thresholds \u03bb\u0302j,k, defined in formula (8), satisfy Assumption 3.3.\nEssentially, Assumption 3.3 requires that the random thresholds \u03bb\u0302j,k are not \u201ctoo far off\u201d,\nin an appropriate sense, from the theoretical thresholds \u03bbj,k.\nWe are now in a position to state our main theorem.\nTheorem 3.1 Suppose that Assumptions 2.1, 2.2, 2.3 and 3.1 hold. Let \u03bb\u0302j,k be any thresholds\nsatisfying Assumption 3.3; for example, those defined in formula (8). Let Bmp,q(C) be a Besov\nball of radius C <\u221e with m, p \u2265 1. We have\nsup\nf\u2208Bmp,q(C)\n{IE \u2016f\u02dc \u2212 f\u20162L2([\u2212pi,pi])} = O\n(\n(log N\/N)2m\/(2m+1)\n)\n. (14)\n9\nTheorem 3.1 shows that our data-driven wavelet threshold estimator f\u02dc achieves near-minimaxity\nin the mean-square sense over a large class of function spaces, and hence enjoys the same opti-\nmality properties as the analogous estimators in the \u201cfunction + i.i.d. Gaussian noise\u201d setting.\n4 Noise-free thresholds\nAlthough our wavelet-Fisz estimator f\u02dc enjoys good theoretical properties as stated in Theorem\n3.1, in practice it often oversmooths. This is not surprising as the thresholds \u03bb\u0302j,k contain the\nsame logarithmic term as the universal thresholds in Gaussian regression, and the latter tend\nto oversmooth. The aim of this section is to propose an alternative wavelet-Fisz thresholding\nestimator of f which performs better in practice.\nThe new estimator is constructed to possess the following noise-free reconstruction property:\nif the true function f(\u03c9) is a constant function of \u03c9, then, with high probability, our estimate of\nf is also constant and equal to the empirical mean of {IN (\u03c9k)}Nk=1. The noise-free reconstruction\nproperty guarantees that asymptotically, no noise survives the estimation procedure and thus\nthe resulting estimate is visually appealing and does not display spurious spikes.\nTo set the scene, we recall that our estimation procedure described in Section 3 essentially\nconsists in \u201ctesting\u201d whether each empirical wavelet coefficient\n\u222b\n\u03c8j,k(\u03c9)IN (\u03c9) exceeds, in abso-\nlute value, the quantity tj,N\n\u222b |\u03c8j,k(\u03c9)|IN (\u03c9), for a particular choice of tj,N . Our new noise-free\nestimator follows the same principle, but uses a different set of tj,N \u2019s, which we construct as\nfollows.\nFor the noise-free reconstruction property to hold, we require that for a constant spectral\ndensity f , all empirical wavelet coefficients fall below their corresponding thresholds, with a\nhigh probability. In other words, we require that\nP\n\uf8eb\uf8ed\u22c3\nj,k\n{\u222b\n\u03c8j,k(\u03c9)IN (\u03c9) > t\u02dcj,N\n\u222b\n|\u03c8j,k(\u03c9)|IN (\u03c9)\n}\uf8f6\uf8f8\u2192 0 as N \u2192\u221e. (15)\nDeriving t\u02dcj,N from (15) in an exact manner is possible, although computationally inefficient.\nBelow, we describe a set of approximations to (15), which facilitate the computation, although\nobviously yield a slightly different set of t\u02dcj,N . Simulations described in Section 5.2 demonstrate\ngood practical performance of the approximate noise-free thresholding estimator.\nWe first note that in practice, the integrals in (15) are replaced by sums, which gives the\ncondition\nP\n\uf8eb\uf8ed\u22c3\nj,k\n[ \u2211Lj\nl=1 \u03c8j,l IN{2pi(l\/N + k\/2j)\u2212 pi}\u2211Lj\nl=1 |\u03c8j,l| IN{2pi(l\/N + k\/2j)\u2212 pi}\n> t\u02dcj,N\n]\uf8f6\uf8f8\u2192 0 as N \u2192\u221e, (16)\nwhere, as in Section 2.2, \u03c8j are discrete wavelet vectors and Lj are their support lengths. By\nthe Bonferroni inequality, (16) is implied by\n\u2211\nj,k\nP\n( \u2211Lj\nl=1 \u03c8j,l IN{2pi(l\/N + k\/2j)\u2212 pi}\u2211Lj\nl=1 |\u03c8j,l| IN{2pi(l\/N + k\/2j)\u2212 pi}\n> t\u02dcj,N\n)\n\u2192 0 as N \u2192\u221e. (17)\nDenote Y +j,k :=\n\u2211\nl:\u03c8j,l>0\n\u03c8j,l IN (2pi(l\/N + k\/2\nj)\u2212 pi) and Y \u2212j,k := \u2212\n\u2211\nl:\u03c8j,l<0\n\u03c8j,l IN (2pi(l\/N +\nk\/2j) \u2212 pi). Note that the distribution of each Y +j,k (similarly, each Y \u2212j,k) is asymptotically the\n10\nsame, since IN (\u03c9k) is asymptotically a sequence of independent exponential variables centred\nat f . We rewrite (17) as\n\u2211\nj,k\nP\n(\nY +j,k\nY \u2212j,k\n>\n1 + t\u02dcj,N\n1\u2212 t\u02dcj,N\n)\n\u2192 0 as N \u2192\u221e. (18)\nNote that by Satterthwaite approximation (see e.g. Johnson and Kotz (1975)), Y +j,k and Y\n\u2212\nj,k are\napproximately independently distributed as \u03b21j\u03c7\n2\n\u03bd1j and \u03b22j\u03c7\n2\n\u03bd2j , for appropriate values of the\nconstants \u03b2\u00b7j and \u03bd\u00b7j . Thus (18) can be approximated as\u2211\nj\n2j\n(\n1\u2212 F\u03bd1j ,\u03bd2j\n(\n\u03b22j(1 + t\u02dcj,N )\n\u03b21j(1\u2212 t\u02dcj,N )\n))\n\u2192 0 as N \u2192\u221e, (19)\nwhere Fa,b(\u00b7) is the cdf of the F distribution with a, b degrees of freedom. To derive t\u02dcj,N , we\nnow mimick standard Gaussian universal thresholding, where the speed of convergence of the\nquantity analogous to (19) is 12{pi log2(N\/2)}\u22121\/2, and the analogues of the probabilities\n\u03b1j(N) := F\u03bd1j ,\u03bd2j\n(\n\u03b22j(1 + t\u02dcj,N )\n\u03b21j(1\u2212 t\u02dcj,N )\n)\n(20)\nare constant across scales; that is \u03b1j(N) = \u03b1(N). To find t\u02dcj,N , we first solve\u2211\nj\n2j(1\u2212 \u03b1(N)) = 1\n2\n{pi log2(N\/2)}\u22121\/2\nfor \u03b1(N), and then obtain each t\u02dcj,N numerically from (20).\n5 Implementation and simulations\n5.1 Implementation\nWe now outline some implementational details of our wavelet-Fisz spectral density estimator.\nThe algorithm for computing the estimator proceeds as follows.\n1. Given the data {Xt}Nt=1, compute the (tapered) periodogram IN (\u03c9k) at the Fourier fre-\nquencies \u03c9k = 2pik\/N \u2212 pi, k = N\/2, . . . , N . Note that we do not need to compute IN (\u03c9k)\nat the negative Fourier frequencies as IN (\u03c9) = IN (\u2212\u03c9).\n2. Given a wavelet basis \u03c8, compute the standard discrete decimated (or non-decimated)\nwavelet transform of IN (\u03c9k) using a fast algorithm described by Mallat (1989) (or Coifman\nand Donoho (1995)).\n3. Compute the thresholds \u03bb\u0302j,k from Section 3 or t\u02dcj,N from Section 4. To construct \u03bb\u0302j,k , we\nneed to choose the set JN . We have empirically found that the choice C = 1, \u03b4 = 0.01\n(as a default \u201csmall\u201d value) yields good practical performance of the estimator. Both \u03bb\u0302j,k\nand t\u02dcj,k require the computation of the equivalent of the discrete wavelet transform but\ncomputed using the mod-wavelets \u03baj,k instead of the wavelets \u03c8j,k. The latter part of this\nSection explains how it is done.\n4. Threshold the empirical wavelet coefficients of IN (\u03c9k) via hard or soft thresholding, for\n(j, k) \u2208 JN if \u03bb\u0302j,k are used, or for all j, k if t\u02dcj,N are used.\n11\n5. Invert the wavelet transform to get an estimate of f at the Fourier frequencies.\nComputing the mod-wavelet transform. An easy way to implement (9) would be to compute the\ndiscrete mod-wavelets, \u03baj , one for each scale j by computing \u03c8j using existing software and then\ntaking absolute values. One can then filter IN (\u03c9) one scale at a time. For the decimated algo-\nrithm, the computational complexity would be O(N log2 N); for the non-decimated algorithm,\nit would be O(N2 log2 N).\nOne of the key advantages of wavelet methods is their efficiency. For decimated transforms\nwe usually \u2018expect\u2019 O(N) algorithms and for non-decimated we would like O(N log2 N). Our\nmod-wavelet transform can achieve these complexities if we adopt an approximation approach\nsimilar to the one proposed by Herrick (2000) and subsequently used in Barber et al. (2002)\nalthough here it is based on adapting the forward wavelet transform not the inverse. The idea\nis to represent \u03baj,k in terms of scaling functions at a finer scale as follows:\n\u03baj,0(\u03c9) \u2248\n\u2211\n`\nej+m0,`\u03c6j+m0,`(\u03c9) (21)\nwhere j+m0 is some fixed number of scales finer than j which controls the level of approximation\n(m0 = 3 is typically very good but higher values are even better). The ej+m0,` sequence is a\nfinite support filter of length 2m0(b\u03c8 \u2212 a\u03c8) + (b\u03c6 \u2212 a\u03c6) where (a\u03c8, b\u03c8) is the finite support\ninterval for the wavelet \u03c8 and similarly for \u03c6. The ej,` sequence can easily be precomputed by\nthe appropriate inner product of \u03ba and \u03c6.\nThen the mod-wavelet transform of some function f(\u03c9) can, after some algebra, be approx-\nimated by \u222b\nf(\u03c9)\u03baj,k(\u03c9) d\u03c9 \u2248\n\u2211\n`\nej+m0,`\u22122m0kcj+m0,` (22)\nwhere cj,k are the standard discrete father wavelet coefficients produced by the (non-)decimated\nwavelet transform. Hence the mod-(non-)decimated wavelet coefficients can be produced by\nfirst performing the standard (non-)decimated wavelet transform and then computing the finite\nsum (22) for each coefficient.\n5.2 Simulations and comparison with existing estimators\nIn this section, we compare the empirical performance of our wavelet-Fisz estimator to the\nmethod of Gao (1993), as well as to the kernel smoothing of IN (\u03c9) with optimally chosen global,\nand locally varying, bandwidth. For the latter two methods, we have used the routines glkerns\nand lokerns (respectively) from the R package lokern. This simulation study also provides an\nindirect comparison with the method of Neumann (1996) who compares the performance of this\nestimator to a kernel smoother with an optimal global bandwidth.\nOur \u201ctest process\u201d is the same as in Neumann (1996) and is defined by Xt = Yt+\n1\n2Zt, where\nYt +\n1\n5\nYt\u22121 +\n9\n10\nYt\u22122 = \u03b5t + \u03b5t\u22122,\nand {\u03b5t}, {Zt} are independent Gaussian white noise processes with mean zero and variance\none. All our simulations are based on sample paths of size N = 1024.\nNote that Gao (1993) estimates the log-spectral density. In this simulation study, we correct\nthe bias of his estimator using the Euler-gamma constant, and then exponentiate it to obtain\nan estimate of the spectral density. Both Gao\u2019s and our wavelet-Fisz estimator use translation-\ninvariant hard thresholding with all resolution levels thresholded (results for soft thresholding are\n12\nglkerns lokerns Gao\nHaar 26% 17% 14%\nDaubExPhase 7 13% 3% 28%\nDaubLeAsymm 5 20% 11% 19%\nTable 1: Percentage by which the ISE of wavelet-Fisz (averaged over 100 sample paths) is lower\nthan that of the three competitors: glkerns, lokerns and Gao\u2019s method, for a selection of wavelet\nbases: Haar, Daubechies\u2019 Extremal Phase 7 and Daubechies\u2019 Least Asymmetric 5.\nworse and we do not report them). We use the \u201cnoise-free\u201d version of our estimator, described\nin Section 4.\nTapering often introduces substantial correlation in the periodogram ordinates. Empirically,\nwe have found that the performance of the wavelet-Fisz and Gao\u2019s estimators is not much\naffected by tapering. However, the performance of glkerns and lokerns deteriorates notably\nwhen tapering is introduced. This is due to the fact that the optimal bandwidth selection in\nboth these methods is based on cross-validation which often does not perform well if the data\nare correlated. Thus, we only report simulation results for the untapered periodogram.\nFigure 1 shows the true spectral density and sample reconstructions using all four methods\ntested. Gao\u2019s method and wavelet-Fisz use Daubechies\u2019 \u201cLeast Asymmetric 5\u201d wavelet. The\nglkerns method oversmooths the peak, which is not surprising given that it is a linear method\nwhich is not capable of estimating both smooth and inhomogeneous regions of the spectral\ndensity well. The method of Gao also oversmooths the peak, which is due to the magnification\nof the slight oversmooth of the peak of the log-spectral density after exponentiating the estimate.\nThe lokerns and wavelet-Fisz methods perform the best. Wavelet-Fisz reconstructs the\npeak better than lokerns and it also flatter in the tails. On the other hand, lokerns does\na better job at reconstructing the region immediately to the right of the peak. The ISE of\nwavelet-Fisz is around 12% lower than that of lokerns for this sample. It is also 39% lower\nthan the ISE of Gao\u2019s method and 41% lower than that of glkerns.\nWe have also computed the ISE averaged over 100 sampled paths for all 4 methods (and\na selection of wavelet bases for Gao\u2019s method and wavelet-Fisz). Table 1 shows percentage\nimprovements in ISE of the wavelet-Fisz method over its competitors. Clearly, wavelet-Fisz is\nthe best option for this inhomogeneous spectral density. We also mention that indirectly, it\nappears to perform better than the estimator of Neumann (1996) which outperformed a kernel\nsmoother with a global bandwidth by 5% on this example. In our case, the improvement over\nglkerns ranges from 13 to 26%.\nFinally, it is interesting to note that (perhaps slightly surprisingly) the use of Haar wavelets\ngives the two wavelet-based methods, wavelet-Fisz and Gao, the biggest advantage over the\nkernel-based methods. A possible explanation for this is that the derivation of the noise-free\nthreshold is exact in the case of Haar wavelets, but only approximate for other wavelets. The ap-\nproximation is described in Section 4. We remind the reader that in this case Haar wavelets pro-\nduce smooth (as opposed to piecewise constant) reconstructions as we use translation-invariant\nversions of the wavelet estimators.\n13\nIndex of Fourier frequency\n0 100 200 300 400 500\n0.\n2\n0.\n4\n0.\n6\n0.\n8\n1.\n0\nIndex of Fourier frequency\n0 100 200 300 400 500\n0.\n2\n0.\n4\n0.\n6\n0.\n8\n1.\n0\nFigure 1: Top: true spectral density (solid); reconstructions using glkerns (dotted) and lokerns\n(dashed). Bottom: true spectral density (solid); reconstructions using Gao\u2019s method (dotted) and\nwavelet-Fisz (dashed). See text for details.\n14\nA Proofs\nA.1 Auxiliary results\nBias, variance and cumulants of \u03b1\u02dcj,k. We first establish the bias, variance and higher cumulants\nof \u03b1\u02dcj,k. We recall that Hp :=\n\u222b 1\n0\nhp(x) dx .\nLemma A.1 Suppose that Assumptions 2.1, 2.2, 2.3 and 3.1 hold. The following hold uni-\nformly over (j, k) \u2208 JN .\n(a) IE \u03b1\u02dcj,k = \u03b1j,k + O(2\nj\/2 log N\/N)\n(b) \u03c32j,k := var(\u03b1\u02dcj,k) = 2pi\/N H4\/H\n2\n2\n\u222b pi\npi\n{f(\u03c9)}2 \u03c8j,k(\u03c9) [\u03c8j,k(\u03c9)+\u03c8j,k(\u2212\u03c9)] d\u03c9+ o(N\u22121) +\nO(2\u2212jN\u22121)\n(c) |cump(\u03b1\u02dcj,k\/\u03c3j,k)| \u2264 Cp (p!)2+2\u03b3 N\u22121 (2j\/2 log N\/N)\u2212(p\u22122) for p \u2265 3.\nFor the proof we refer the reader to Neumann (1996), Proposition 3.1.\nStrong asymptotic normality of \u03b1\u02dcj,k. The technique for proving the near-optimal rate of mean-\nsquare convergence of f\u0302 and f\u02dc is based on the following strong form of asymptotic normality of\nthe empirical wavelet coefficients \u03b1\u02dcj,k:\nP (\u00b1(\u03b1\u02dcj,k \u2212 \u03b1j,k)\/\u03c3j,k \u2265 x)\n1\u2212 \u03a6(x) \u2192 1, (23)\nuniformly over (j, k) \u2208 JN , x \u2264 \u2206\u03b3 , with \u2206\u03b3 = o(\u22061\/(3+4\u03b3)) and \u2206 = O(N \u03b4\/2\/ log N), where \u03b4\nis as described in the last paragraph of Section 3.1. Note that \u03a6(x) is the cdf of the standard\nnormal. The proof of (23) relies, amongst others, on the asymptotic behaviour of the cumulants\nof \u03b1\u02dcj,k of order two and higher, as specified in Lemma A.1. For details, we refer again to\nNeumann (1996).\nMean-square convergence of f\u0302 . We now state a theorem on the mean-square convergence of our\n\u2018bona fide\u2019 estimator f\u0302 defined in (5).\nTheorem A.1 Suppose that Assumptions 2.1, 2.2, 2.3 and 3.1 hold. Let \u03bbj,k be any thresholds\nsatisfying Assumption 3.2; for example, those defined in formula (6). Let Bmp,q(C) be a Besov\nball of radius C <\u221e with m, p \u2265 1. We have\nsup\nf\u2208Bmp,q(C)\n{IE \u2016f\u02dc \u2212 f\u20162L2([\u2212pi,pi])} = O\n(\n(log N\/N)2m\/(2m+1)\n)\n. (24)\nFor the proof of this theorem we refer to Neumann (1996), as it is parallel to the proof of\nTheorem 5.1 therein.\nChoice of cN . Finally, we motivate the choice cN =\n\u221a\n2pi\/N H4\/H22 in formula (7). A desired\nproperty of \u03b8j,k, required so that (12) may hold, is that \u03b8j,k should be \u201calmost equal\u201d to \u03c3j,k\nfor fine-scale coefficients. From Lemma A.1(b), we observe that\n\u03c3j,k \u2264\n\u221a\n2piH4\nN H22\nfj,k\n\u221a\n1 +\n\u222b pi\n\u2212pi\n|\u03c8j,k(\u03c9)\u03c8j,k(\u2212\u03c9)|d\u03c9 + o(N\u22121) +O(2\u2212jN\u22121) , (25)\nwhere f j,k = sup{f(\u03c9) : \u03c9 \u2208 supp(\u03c8j,k)} (for later purposes, we also denote f j,k = inf{f(\u03c9) :\n\u03c9 \u2208 supp(\u03c8j,k)}). Further we note that\n\u222b pi\n\u2212pi |\u03c8j,k(\u03c9)\u03c8j,k(\u2212\u03c9)| d\u03c9 = 0 except for a finite (and\nthe same) number of k at each scale j for which 0 \u2208 supp{\u03c8j,k}. This motivates setting cN to\nbe equal to cN =\n\u221a\n2pi\/N H4\/H22 =: cN\n\u22121\/2.\n15\nA.2 Proof of Theorem 3.1\nTo show that our data-driven wavelet-Fisz thresholds (8) fulfil Assumption 3.3, we specify what\nwe call, respectively, \u201clow\u201d and \u201chigh\u201d deterministic thresholds. We propose\n\u03bb\n(l)\nj,k = \u03b1N\u03b8j,k\n\u221a\n2 log(#JN )\n\u03bb\n(u)\nj,k = C\u02dc N\n\u22121\/2\n\u221a\nlog N,\nwith an \u03b1N \u2192 1\u2212, and with an appropriate constant C\u02dc specified below. Both \u03bb(l)j,k and \u03bb(u)j,k\nneed to satisfy Assumption 3.2.\nLemma A.2 Suppose that Assumptions 2.1 and 2.3 hold. If C\u02dc \u2265 c\u221a2 sup\u03c9 f(\u03c9), then \u2200 j, k \u03bb(u)j,k \u2265\nsupj,k \u03bb\n(l)\nj,k, and both \u03bb\n(l)\nj,k and \u03bb\n(u)\nj,k satisfy Assumption 3.2.\nProof. It is easy to check that if C\u02dc \u2265 c\u221a2 sup\u03c9 f(\u03c9), then \u2200 j, k \u03bb(u)j,k \u2265 supj,k \u03bb(l)j,k. We now\ncheck (12) for \u03bb\n(l)\nj,k. The factor \u03bb\n(l)\nj,k\/\u03c3j,k + 1 only contributes a logarithmic term so we skip it.\nDenote ZN = JN \u2229 {(j, k) : 0 \u2208 supp(\u03c8j,k)}. We have\uf8eb\uf8ed\u2211\nZN\n+\n\u2211\nJN\\ZN\n\uf8f6\uf8f8\u03c6(\u03bb(l)j,k\/\u03c3j,k) = O(M log N) + \u2211\nJN\\ZN\n\u03c6(\u03bb\n(l)\nj,k\/\u03c3j,k),\nwhere M is a constant. It remains to investigate the sum on the RHS. Recalling that H\n(N)\np :=\u2211N\nt=1 h\np(t\/N) and using (25), we bound \u03bb\n(l)\nj,k\/\u03c3j,k from below as follows:\n\u03bb\n(l)\nj,k\n\u03c3j,k\n\u2265\n\u03b1NcN\n\u22121\/2f\nj,k\n\u221a\n2 log(#JN )\u221a\n2piH\n(N)\n4\n(H\n(N)\n2 )\n2\nf j,k + o(N\n\u22121) +O(2\u2212jN\u22121)\n.\nWe introduce \u03b2N = cN\n\u22121\/2\/\n\u221a\n2piH\n(N)\n4 \/(H\n(N)\n2 )\n2, noting that \u03b2N \u2192 1. The above bound can be\nrewritten as\n\u03b1N\u03b2Nfj,k\n\u221a\n2 log(#JN )\nfj,k + o(N\n\u22121\/2) +O(2\u2212jN\u22121\/2)\n\u2265\n\u03b1N\u03b2Nfj,k\n\u221a\n2 log(#JN )\nf j,k\n+ o(N\u22121\/2) +O(2\u2212jN\u22121\/2) =\n\u03b1N\u03b2Nfj,k\n\u221a\n2 log(#JN )\nf j,k\n(\n1 + o((N log N)\u22121\/2) +O(2\u2212j(N log N)\u22121\/2)\n)\n=:\n\u03b1N \u03b2\u02dcNfj,k\n\u221a\n2 log(#JN )\nf j,k\n,\nwhere the first inequality holds by the convexity of u(x) = 1\/(a2 + x) for small x; note that\n\u03b2\u02dcN \u2192 1. Denoting \u00b5 = inf f(\u03c9), we have\nf\nj,k\nf j,k\n\u2265\nf\nj,k\nf\nj,k\n+ TV(f)|supp(\u03c8j,k)\n\u2265 \u00b5\n\u00b5+ TV(f)|supp(\u03c8j,k)\n,\n16\nwhere the last inequality follows from the fact that v(x) = x\/(x+a2) is increasing on [0,\u221e). As\nin Neumann (1996), the proof of Lemma 6.1 (ii), we have\n\u2211\nk TV(f)|supp(\u03c8j,k) \u2264 O(1)TV(f)\nand thus for a sequence dN \u2192 0, at each scale j we have\n#{k : TV(f)|supp(\u03c8j,k) > dN} = O(d\u22121N ). (26)\nDenote DN = JN \u2229 ZcN \u2229 {(j, k) : TV(f)|supp(\u03c8j,k) > dN}. Note that by (26), at each scale j\nat most O(d\u22121N ) coefficients are in DN . Denote further EN = JN \u2229 ZcN \u2229DcN . Let J\u2217 \u2212 1 be the\nfinest scale in JN . We have\n\u2211\nJN\\ZN\n\u03c6(\u03bb\n(l)\nj,k\/\u03c3j,k) =\n(\u2211\nDN\n+\n\u2211\nEN\n)\n\u03c6(\u03bb\n(l)\nj,k\/\u03c3j,k) = O(d\n\u22121\nN log N)+\nJ\u2217\u22121\u2211\nj=0\n2j\u2211\nk=1\n\u03c6\n(\n\u03b1N \u03b2\u02dcN\u00b5\n\u221a\n2 log(#JN )\n\u00b5+ dN\n)\n\u2264 O(d\u22121N log N) + (2pi)\u22121\/2\nJ\u2217\u22121\u2211\nj=0\n2\nj\u2212J\u2217\u03b12N \u03b2\u02dc\n2\nN\n\u0000\n\u00b5\n\u00b5+dN \u0001\n2\n= O(d\u22121N log N) +O((#JN )\n1\u2212\u03b12N \u03b2\u02dc\n2\nN\n\u0000\n\u00b5\n\u00b5+dN \u0001\n2\n) = O(d\u22121N log N) + o(N\n1\/(2m+1)),\nfor any m > 0. The last equality follows from the fact that 1\u2212 \u03b12N \u03b2\u02dc2N\n(\n\u00b5\n\u00b5+dN\n)2\n\u2192 0. Choosing\ndN = log\n\u22121 N (say), we have that (12) is satisfied irrespective of the smoothness parameter m.\nBecause the thresholds \u03bb\n(u)\nj,k are higher than \u03bb\n(l)\nj,k, (12) also holds for \u03bb\n(u)\nj,k . Obviously, (13) holds\nfor \u03bb\n(u)\nj,k , which implies that it also holds for \u03bb\n(l)\nj,k, since \u03bb\n(l)\nj,k are lower than \u03bb\n(u)\nj,k . \u0003\nTo continue the proof of Theorem 3.1, we show that our random thresholds (8) satisfy\nAssumption 3.3. In order to do so, we show that our \u201cestimators\u201d \u03b8\u0302j,k fulfil a strong form of\nasymptotic normality, paralleling the one in (23) for \u03b1\u02dcj,k.\nProposition A.1 Suppose that Assumptions 2.1, 2.2, 2.3 and 3.1 hold. Denote s2j,k = var(\u03b8\u02c6j,k).\nWe have\nP (\u00b1(\u03b8\u0302j,k \u2212 \u03b8j,k)\/sj,k \u2265 x)\n1\u2212 \u03a6(x) \u2192 1,\nuniformly over (j, k) \u2208 JN , x \u2264 \u2206\u03b3 , where \u2206\u03b3 = o(\u22061\/(3+4\u03b3)) and \u2206 = O(N \u03b4\/2\/ log N).\nProof. We start with some clarifying remarks as to the orders of magnitude of \u03b8\u02c6j,k, \u03b8j,k and\nsj,k. As each \u03baj,k integrates to one in L1, we have \u03b8j,k = O(N\n\u22121\/2) uniformly over j, k.\nThe bias in estimating \u03b8j,k by \u03b8\u02c6j,k is of order O(2\nj log N\/N3\/2). Its derivation completely\nparallels the proof of Lemma A.1(a), which is Proposition 3.1(i) in Neumann (1996): IE\u03b8\u02c6j,k =\n\u03b8j,k +O(cN2\nj log N\/N).\nThe variance s2j,k can be derived using Lemma 6 in Dahlhaus (1983), which is analogous to\nthe proof of Lemma A.1(b):\ns2j,k = c\n2\nN [c\n2\nN\n\u222b pi\n\u2212pi\nf2(\u03c9)\u03baj,k(\u03c9)(\u03baj,k(\u03c9) + \u03baj,k(\u2212\u03c9))d\u03c9 + o(2j N\u22121) +O(N\u22121)] .\nWith the normalisation\n\u222b\n\u03baj,k(\u03c9) d\u03c9 = 1 , we remark that the first term in brackets is of order\nO(2j\/N), which is easy to see since \u03baj,k(\u03c9) = 2\nj \u03ba(2j\u03c9 \u2212 k) .\nWith this observation, one gets the following auxiliary results, useful for the remainder:\u222b\n\u03ba2j,k(\u03c9) d\u03c9 = 2\nj and supk sup\u03c9 \u03baj,k(\u03c9) = O(2\nj). Thus, we note that the overall order of the\n17\nleading term of sj,k is 2\nj\/2N\u22121. By Assumption 2.1(i), we have a uniform lower bound on sj,k,\nwhich ensures that c\u22121N sj,k \u2265 c\u02dc (2j\/N)1\/2.\nHowever, as we are going to study the ratios of \u03b8\u02c6j,k\/sj,k and of the bias divided by sj,k, the\nnormalisation of each of the quantities \u03b8\u02c6j,k, \u03b8j,k and sj,k by the factor cN (which is of order\nN\u22121\/2) will cancel out. For example, for the bias treatment considered in Theorem A.1, we get\nIE{(\u03b8\u02c6j,k \u2212 \u03b8j,k)\/sj,k} = O\n(\n2j log N\/N\n(2j\/N)1\/2\n)\n= O((2j\/N)1\/2 log N) . (27)\nNote that since 2j \u2264 C N1\u2212\u03b4 , the rescaled bias converges to zero.\nThe key property to make the strong asymptotic normality work is the treatment of all\nhigher-order cumulants of \u03b8\u02c6j,k\/sj,k. We first parallel Lemma A.1(c):\ncump(\u03b8\u02c6j,k) = O(c\np\nN (p!)\n2+2\u03b3 2j\/N (2j\/N log N)p\u22122) , (28)\nfor all p \u2265 3. This immediately entails the result for the cumulants rescaled by the standard\ndeviation sj,k:\ncump(\u03b8\u02c6j,k\/sj,k) \u2264 C(p, \u03b3) (N\u2212\u03b4\/2 log N)p\u22122 ,\nuniformly over (j, k) \u2208 JN for all p \u2265 3, with a bounded constant C(p, \u03b3). The proof of this\nlast result is straightforward if we observe that the normalisation by the inverse of sj,k leads\nto the division of the order of equation (28) by the factor of cpN (2\nj\/N)p\/2. (Compare also\nthe order of the leading term of sj,k shown to be 2\nj\/2N\u22121). Elementary calculations give the\norder for the normalised cumulant as ((2j\/N)1\/2 log N)p\u22122, which, however, is clearly of order\n(N\u2212\u03b4\/2 log N)p\u22122.\nWe close by noting that one can choose \u2206 = N \u03b4\/2\/ log N to control the bias in formula (27)\nabove. This completes the proof of Proposition A.1, which is similar to the proof of Neumann\n(1996), Theorem 4.1. \u0003\nWith this strong form of asymptotic normality, we now verify that our random thresholds\n(8) satisfy Assumption 3.3.\nVerifying Assumption 3.3(i):\nDefine \u2206\u03b4 = (N\n\u03b4\/2\/ log N)1\/(3+4\u03b3)\/ log N (note that it satisfies the requirement for \u2206\u03b3 of\nProposition A.1) and let Z be standard normal. All Ci\u2019s are positive constants. Assump-\ntion 3.3(i) writes as follows:\u2211\n(j,k)\u2208JN\nP (\u03bb\u02c6j,k < \u03bb\n(l)\nj,k) =\n\u2211\n(j,k)\u2208JN\nP ((\u03b8j,k \u2212 \u03b8\u02c6j,k)\/sj,k > \u03b8j,k(1\u2212 \u03b1N )\/sj,k) \u2264\n\u2211\n(j,k)\u2208JN\nP ((\u03b8j,k \u2212 \u03b8\u02c6j,k)\/sj,k > min(\u03b8j,k(1\u2212 \u03b1N )\/sj,k,\u2206\u03b4)) \u2264\nC1\n\u2211\n(j,k)\u2208JN\nP (Z > min(\u03b8j,k(1\u2212 \u03b1N )\/sj,k,\u2206\u03b4)) \u2264\nC1\n\u2211\n(j,k)\u2208JN\nP (Z > \u03b8j,k(1\u2212 \u03b1N )\/sj,k) + C1\n\u2211\n(j,k)\u2208JN\nP (Z > \u2206\u03b4) =: I + II.\nRecalling the orders of \u03b8j,k and sj,k, and denoting b = exp(C\n2\n2\/2), we bound I as follows:\nC1\n\u2211\n(j,k)\u2208JN\nP (Z > C22\n(J\u2212j)\/2(1\u2212 \u03b1N ) \u2264 C3\n\u2211\n(j,k)\u2208JN\nexp(\u2212C222J\u2212j(1\u2212 \u03b1N )2\/2) =\n18\nC3\nJ\u2217\u2211\nj=0\n2jb\u2212(1\u2212\u03b1N)\n22J\u2212j \u2264 C3b\u2212(1\u2212\u03b1N )22J\u2212J\n\u2217\nJ\u2217\u2211\nj=0\n2j \u2264 C42J\n\u2217\nb\u2212(1\u2212\u03b1N )\n22J\u2212J\n\u2217\n.\nRecalling that 2J\n\u2217\n= N1\u2212\u03b4, and logging the above bound we obtain (1\u2212\u03b4) logbN\u2212(1\u2212\u03b1N)2N \u03b4 .\nTo ensure that it is bounded in N (say \u2264 C5), we need to take\n\u03b1N \u2264 1\u2212\n\u221a\n(1\u2212 \u03b4) logbN \u2212 C5\nN \u03b4\n.\nTurning now to II , we have 2J\n\u2217\nP (Z > \u2206\u03b4) \u2264 N1\u2212\u03b4 exp(\u2212\u22062\u03b4\/2). Logging this, we get (1 \u2212\n\u03b4) log N \u2212N \u03b4\/(3+4\u03b3)\/(2 log2+2\/(3+4\u03b3)N), which tends to \u2212\u221e, which means that II \u2192 0.\nVerifying Assumption 3.3(ii):\u2211\n(j,k)\u2208JN\nP (\u03bb\u02c6j,k > \u03bb\n(u)\nj,k ) \u2264\n\u2211\n(j,k)\u2208JN\nP (\u03b8\u02c6j,k > C6) =\n\u2211\n(j,k)\u2208JN\nP ((\u03b8\u02c6j,k \u2212 \u03b8j,k)\/sj,k > (C6 \u2212 \u03b8j,k)\/sj,k) \u2264\n\u2211\n(j,k)\u2208JN\nP ((\u03b8\u02c6j,k \u2212 \u03b8j,k)\/sj,k > C7N1\/22(J\u2212j)\/2) \u2264\n\u2211\n(j,k)\u2208JN\nP ((\u03b8\u02c6j,k \u2212 \u03b8j,k)\/sj,k > \u2206\u03b4) \u2264 C8\n\u2211\n(j,k)\u2208JN\nP (Z > \u2206\u03b4) \u2264 C8N1\u2212\u03b4 exp(\u2212\u22062\u03b4\/2).\nThis implies that we need to show N 1\u2212\u03b4 exp(\u2212N \u03b4\/(3+4\u03b3)\/(2 log2+2\/(3+4\u03b3)N)) \u2264 N\u22122m\/(2m+1).\nBut this is asymptotically true, which becomes obvious once both sides are logged.\nThe remainder of the proof of Theorem 3.1 proceeds exactly like the proof of Theorem 6.1\nof Neumann (1996).\nAcknowledgement\nThis work was supported by EPSRC Small Grant GR\/T22278\/01 which funded a visit by RvS\nto Bristol in Autumn 2004. PF thanks RvS for financial support and hospitality during visits\nto Louvain-la-Neuve and Kaiserslautern. He is also grateful to the Department of Mathemat-\nics, Imperial College London, where a large part of this work was done, for an excellent re-\nsearch environment. GPN was also supported by EPSRC Advanced Research Fellowship Grant\nGR\/A01664\/01 and by Responsive Mode Grant EP\/D005221\/1. The research of RvS was also\nsupported by IAP research network grant P 5\/24 of the Belgian government (Belgian Science\nPolicy).\nReferences\nS. Barber, G.P. Nason, and B.W. Silverman. Posterior probability intervals for wavelet thresh-\nolding. Journal of the Royal Statistical Society Series B, 64:189\u2013205, 2002.\nD.R. Brillinger. Time Series: Data Analysis and Theory. McGraw-Hill Inc., New York, 1981.\nP. J. Brockwell and R. A. Davis. Time Series: Theory and Methods. Springer, 1987.\n19\nR.R. Coifman and D.L. Donoho. Translation-invariant de-noising. In Anestis Antoniadis and\nGeorges Oppenheim, editors, Wavelets and Statistics, volume 103 of Lecture Notes in Statis-\ntics, pages 125\u2013150. Springer-Verlag, New York, 1995.\nF. Comte. Adaptive estimation of the spectrum of a stationary Gaussian sequence. Bernoulli,\n7:267\u2013298, 2001.\nA. C. Cristan and A. T. Walden. Multitaper power spectrum estimation and thresholding:\nWavelet packets versus wavelets. IEEE Trans. Sig. Proc., 50:2976\u20132986, 2002.\nR. Dahlhaus. Spectral analysis with tapered data. Journal of Time Series Analysis, 4:163\u2013175,\n1983.\nI. Daubechies. Ten Lectures on Wavelets. SIAM, Philadelphia, Pa., 1992.\nP.L. Davies and A. Kovac. Densities, spectral densities and modality. Ann. Stat., 32:1093\u20131136,\n2004.\nD. L. Donoho and I. M. Johnstone. Ideal spatial adaptation by wavelet shrinkage. Biometrika,\n81:425\u2013455, 1994.\nD. L. Donoho, I. M. Johnstone, G. Kerkyacharian, and D. Picard. Wavelet shrinkage: asymp-\ntopia? (with discussion). Journal of the Royal Statistical Society Series B, 57:301\u2013369, 1995.\nP. Fryzlewicz and G.P. Nason. A Haar-Fisz algorithm for Poisson intensity estimation. Journal\nof Computational and Graphical Statistics, 13:621\u2013638, 2004.\nP. Fryzlewicz and G.P. Nason. Haar-Fisz estimation of evolutionary wavelet spectra. Preprint,\n2005.\nP. Fryzlewicz, T. Sapatinas, and S. Subba Rao. A Haar-Fisz technique for locally stationary\nvolatility estimation. Biometrika, to appear, 2006.\nH-Y. Gao. Wavelet estimation of spectral densities in time series analysis. PhD thesis, University\nof California Berkeley, 1993.\nH-Y. Gao. Choice of thresholds for wavelet shrinkage estimate of the spectrum. J. Time Ser.\nAnal., 18, 1997.\nD. Herrick. Wavelet Methods for Curve Estimation. PhD thesis, University of Bristol, Bristol,\nU.K., 2000.\nN. Johnson and S. Kotz. Distributions in statistics: Continuous univariate distributions. Wiley,\n1975.\nL.H. Koopmans. The Spectral Analysis of Time Series. Academic Press, San Diego, 2 edition,\n1995.\nS. Mallat. A theory for multiresolution signal decomposition: the wavelet representation. IEEE\nTrans. Pattn Anal. Mach. Intell., 11:674\u2013693, 1989.\nP. Moulin. Wavelet thresholding techniques for power spectrum estimation. IEEE Trans. Sig.\nProc., 42:3126\u20133136, 1994.\n20\nG. P. Nason, R. von Sachs, and G. Kroisandt. Wavelet processes and adaptive estimation of the\nevolutionary wavelet spectrum. Journal of the Royal Statistical Society. Series B, 62:271\u2013292,\n2000.\nM. H. Neumann. Spectral density estimation via nonlinear wavelet methods for stationary\nnon-Gaussian time series. Journal of Time Series Analysis, 17:601\u2013633, 1996.\nM. Pensky and B. Vidakovic. Bayesian decision theoretic scale-adaptive estimation of a log-\nspectral density. Preprint, 2003.\nM. B. Priestley. Spectral Analysis and Time Series. Academic Press, 1981.\nR.H. Shumway and D.S. Stoffer. Time Series Analysis and Its Applications. Springer-Verlag,\nNew York, 2000.\nB. Vidakovic. Statistical Modeling by Wavelets. Wiley, New York, 1999.\n21\n"}
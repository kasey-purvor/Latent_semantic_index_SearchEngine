{"doi":"10.1109\/MLSP.2005.1532883","coreId":"71412","oai":"oai:eprints.lancs.ac.uk:1014","identifiers":["oai:eprints.lancs.ac.uk:1014","10.1109\/MLSP.2005.1532883"],"title":"Improved proposal distribution with gradient measures for tracking","authors":["Brasnett, P.","Mihaylova, L.","Bull, D.","Canagarajah, N."],"enrichments":{"references":[{"id":16366848,"title":"A novel approach to nonlinear \/ non-Gaussian Bayesian state estimation,\u201d","authors":[],"date":null,"doi":"10.1049\/ip-f-2.1993.0015","raw":"N. Gordon, D. Salmond, and A. Smith, \u201cA novel approach to nonlinear \/ non-Gaussian Bayesian state estimation,\u201d IEE (a) PF (frame 6) (b) PF (frame 54) (c) PF with Gradient (frame 6) (d) PF with Gradient (frame 54)","cites":null},{"id":16366845,"title":"A tutorial on particle \ufb01lters for online nonlinear\/non-Gaussian Bayesian tracking,\u201d","authors":[],"date":"2002","doi":"10.1109\/78.978374","raw":"M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp, \u201cA tutorial on particle \ufb01lters for online nonlinear\/non-Gaussian Bayesian tracking,\u201d IEEE Trans. on Signal Proc., vol. 50, no. 2, pp. 174\u2013188, 2002.","cites":null},{"id":16366846,"title":"Sequential Monte Carlo methods for dynamic systems,\u201d","authors":[],"date":"1998","doi":"10.2307\/2669847","raw":"J. Liu and R. Chen, \u201cSequential Monte Carlo methods for dynamic systems,\u201d Journal of the American Statistical Association, vol. 93, no. 443, pp. 1032\u20131044, 1998.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2005","abstract":"Particle filters have become a useful tool for the task of object tracking due to their applicability to a wide range of situations. To be able to obtain an accurate estimate from a particle filter a large number of particles is usually necessary. A crucial step in the design of a particle filter is the choice of the proposal distribution. A common choice for the proposal distribution is to use the transition distribution which models the dynamics of the system but takes no account of the current measurements. We present a particle filter for tracking rigid objects in video sequences that makes use of image gradients in the current frame to improve the proposal distribution. The gradient information is efficiently incorporated in the filter to minimise the computational cost. Results from synthetic and natural sequences show that the gradient information improves the accuracy and reduces the number of particles required","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/71412.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/1014\/1\/ML_2005.pdf","pdfHashValue":"d1d768bf20417d58f61f3df86f7a86e6f1f8080d","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:1014<\/identifier><datestamp>\n      2018-01-24T02:11:19Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Improved proposal distribution with gradient measures for tracking<\/dc:title><dc:creator>\n        Brasnett, P.<\/dc:creator><dc:creator>\n        Mihaylova, L.<\/dc:creator><dc:creator>\n        Bull, D.<\/dc:creator><dc:creator>\n        Canagarajah, N.<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        Particle filters have become a useful tool for the task of object tracking due to their applicability to a wide range of situations. To be able to obtain an accurate estimate from a particle filter a large number of particles is usually necessary. A crucial step in the design of a particle filter is the choice of the proposal distribution. A common choice for the proposal distribution is to use the transition distribution which models the dynamics of the system but takes no account of the current measurements. We present a particle filter for tracking rigid objects in video sequences that makes use of image gradients in the current frame to improve the proposal distribution. The gradient information is efficiently incorporated in the filter to minimise the computational cost. Results from synthetic and natural sequences show that the gradient information improves the accuracy and reduces the number of particles required.<\/dc:description><dc:date>\n        2005<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/1014\/1\/ML_2005.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/MLSP.2005.1532883<\/dc:relation><dc:identifier>\n        Brasnett, P. and Mihaylova, L. and Bull, D. and Canagarajah, N. (2005) Improved proposal distribution with gradient measures for tracking. In: Machine Learning for Signal Processing, 2005 IEEE Workshop on. , 105 - 110. ISBN 0-7803-9517-4<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/1014\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/MLSP.2005.1532883","http:\/\/eprints.lancs.ac.uk\/1014\/"],"year":2005,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"IMPROVED PROPOSAL DISTRIBUTION\nWITH GRADIENT MEASURES FOR TRACKING\nPaul Brasnett, Lyudmila Mihaylova\u2217, David Bull\u2217 and Nishan Canagarajah\u2217\nDept. of Electrical and Electronic Engineering\nUniversity of Bristol\npaul.brasnett@bristol.ac.uk, mila.mihaylova@bristol.ac.uk\nABSTRACT\nParticle filters have become a useful tool for the task of object\ntracking due to their applicability to a wide range of situations. To\nbe able to obtain an accurate estimate from a particle filter a large\nnumber of particles is usually necessary. A crucial step in the de-\nsign of a particle filter is the choice of the proposal distribution. A\ncommon choice for the proposal distribution is to use the transition\ndistribution which models the dynamics of the system but takes no\naccount of the current measurements. We present a particle fil-\nter for tracking rigid objects in video sequences that makes use of\nimage gradients in the current frame to improve the proposal distri-\nbution. The gradient information is efficiently incorporated in the\nfilter to minimise the computational cost. Results from synthetic\nand natural sequences show that the gradient information improves\nthe accuracy and reduces the number of particles required.\n1. INTRODUCTION\nTracking objects in video is an important task due to its ap-\nplications in diverse areas such as augmented reality, medi-\ncal applications and surveillance. The general aim of track-\ning is to keep track of the pose and location of one or more\nobjects through a sequence of frames.\nParticle filtering [1, 2, 3, 4] is a powerful approach for\ntracking because it makes no assumptions of Gaussian noises\nand it is able to cope with highly non-linear models de-\nscribing the image features and system dynamics. Chal-\nlenges arise when accurate state representations are required\nin (near) real-time. To obtain results that are accurate a very\ngood model for the proposal distribution is needed. Often\nthe transition distribution is used to model the proposal dis-\ntribution, this choice does not usually model the proposal\ndistribution accurately so a large number of particles are\nrequired. As one would expect increasing the number of\nparticles increases the complexity of the algorithm. This is\nparticularly true for tracking in video sequences because the\ncost of evaluating the likelihood tends to be high.\n\u2217This work has been conducted with support from the UK MOD Data\nand Information Fusion Defence Technology Centre under project DIF\nDTC 2.2.\nThere are a number of variants of the particle filter that\nattempt to address the problem of the proposal distribution.\nSome of them rely on additional strategies for the proposal\ndistribution such as Monte Carlo Markov chains or the use\nof gradient information in order to move particles toward\nmore likely regions. The idea of using gradient informa-\ntion in the proposal distribution has previously been applied\nto the area of wireless communications [5]. An additional\nMOVE step is introduced before the sampling step. The gra-\ndient information to guide the move to regions of higher\nlikelihood is calculated from the likelihood model.\nIn [6] the generation of particles is controlled by a mo-\nmentum term. Particles with a momentum below a thresh-\nold are propagated through a deterministic, gradient-descent\nsearch the remaining particles are propagated by sampling\nfrom the transition density function. An alternative method\nthat moves particles toward regions of higher likelihood is\nthe Kernel Particle Filter [7]. In this approach the mean shift\ntracker [8] is embedded in a particle filter. Following resam-\npling the mean shift iteratively estimates the local likelihood\ndensity gradient and moves the particles toward stationary\npoints, which include the modes. The result is that parti-\ncles are focused around stationary points in the likelihood\ndensity.\nThe aim of the work here is in a similar vein to the\nworks mentioned above, in that gradient information is used\nto shift the particles. In the present paper an error func-\ntion is defined and optimised in an efficient gradient-descent\nmethod based on the image gradient information available\nin the frame. In [5] a Levenburg-Marquardt optimisation\napproach is used whilst here a Newton-Raphson approach\nto gradient descent allows the development of an efficient\nimplementation. This approach works for a range of linear\nand non-linear motions, including common motions such as\nthe translation and affine models. The benefit of embedding\nthis in a particle filter framework is the ability to maintain\nmultiple hypothesis, something not possible in a purely de-\nterministic framework.\nAn introduction to particle filtering is provided in Sec-\ntion 2. Details of the colour histogram based likelihood\n1050-7803-9518-2\/05\/$20.00 \u00a92005 IEEE\nmodel are included in Section 3. A general description of\nthe gradient descent is given in Section 4, from this an ef-\nficient gradient measurement for video sequences is devel-\noped. The gradient information is incorporated into the par-\nticle filtering framework along with implementation details\nin Section 5. Results are presented in Section 6 and conclu-\nsions are given in Section 7.\n2. PARTICLE FILTERING\nGiven a system transition function ft : Rn \u00d7 Rm \u2192 Rn\nxt+1 = ft(xt,wt), (1)\nthe system state vector xt \u2208 Rn is estimated at time t where\nwt \u2208 Rm is a zero mean, white noise sequence independent\nof past and current states with a known probability density\nfunction (PDF).\nTable 1: Generic Particle Filter\n1. Initialisation\nFor n = 1, . . . , N set wn0 = 1N .\n2. Importance Sampling\nFor n = 1, . . . , N\n\u2022 Sample xnt+1 \u223c q(xt+1|xnt ,yt+1)\n\u2022 Evaluate the weights\nwnt+1 = w\nn\nt\np(yt+1|x\nn\nt+1)p(x\nn\nt+1|x\nn\nt )\nq(xnt+1|x\nn\nt ,yt+1)\n(2)\n\u2022 Normalise the weights, w\u02dcnt+1 =\nwn\nt+1\u2211\nN\nm=1\nwm\nt+1\nEvaluate N\u02c6eff = 1\u2211N\nn=1\n(w\u02dcn\nt+1\n)2\n3. Output\nEstimate the current state\nx\u02c6t+1 =\nN\u2211\nn=1\nw\u02dcnt+1x\nn\nt+1. (3)\n4. Resampling\nIf N\u02c6eff \u2264 Nthres\n\u2022 For n = 1, . . . , N , resample with replacement\nN particles xit+1 according to their weights,\nwhere Nthres is a given threshold value.\nMeasurements yt \u2208 Rp are related to the state vector\nvia the observation equation\nyt = ht(xt,vt), (4)\nwhere ht : Rn \u00d7 Rr \u2192 Rp is the measurement func-\ntion and vt \u2208 Rr is a different zero mean, white noise se-\nquence with known PDF, independent of past and present\nstates of the system noise. The Bayesian interpretation of\nthe tracking problem is to recursively calculate a degree\nof belief in the state xt at time t given the measurements\ny1:t = {y1, . . . ,yt}. This is represented by the posterior\nPDF p(xt|y1:t).\nThe posterior PDF p(xt|y1:t) of the state xt is approxi-\nmated by the particle filter given a measurement y1:t and a\nset of particles xnt each with a corresponding weight wnt\np(xt|y1:t) \u2248\nN\u2211\nn=1\nwnt \u03b4(xt \u2212 x\nn\nt ), (5)\nwhere \u03b4(.) is the Kronecker delta function. Each one of\nthe particles xnt+1 is drawn from the proposal distribution\nq(xnt+1|x\nn\n0:t,y1:t+1) and assigned a weight wnt+1 calculated\nrecursively at each time step by evaluating the transition\ndensity p(xt+1|xt) the likelihood p(yt+1|xt+1) and the ev-\nidence q(xnt+1|xnt ,yt+1). The generic particle filter is given\nin Table 1.\nNote that the resampling stage of Table 1 is necessary\nto limit the effects of degeneracy [4, 9], the case when only\none particle has significant weight.\nIn the design of a particle filter it is critical to choose a\nsuitable importance density q(xt+1|xn0:t,y0:t+1). A com-\nmon choice for the importance density q(xt+1|xnt ,yt+1) is\nto use the transition density\nq(xt+1|x\nn\nt ,yt+1) = p(xt+1|x\nn\nt ). (6)\nThis choice only takes into account the system dynam-\nics, no account is taken of the measurements. The transition\nprior is chosen because it leads to a straightforward imple-\nmentation.\n3. LIKELIHOOD MODEL\nWeighted colour histogram cues extracted from the frame\nare used as the result of the measurement function. The\nweighted histogram Hi,x for bin i and state x is given by\nHi,x = CH\n\u2211\nr\u2208Sx\nkN\n(\u2225\u2225\u2225\u2225 r\u00af \u2212 ra\n\u2225\u2225\u2225\u2225\n2\n)\n\u03b4i(br), i = 1 . . . B,\n(7)\nwhere r\u00af = (x\u00af, y\u00af) is the location of the center pixel, CH is\na normalisation constant such that\n\u2211B\ni=1 Hi,x = 1, a is the\nsize of the kernel, br \u2208 {1, . . . , B} denotes the histogram\nbins, \u03b4i(.) is the Kronecker delta function at i and Sx is the\nset of pixel locations {r1, . . . , rR} defined by the state x\nand the model g (see Section 4.2). The Gaussian kernel,\n106\nkN , is used to weight pixels in the center of the region more\nhighly than pixels at the edge of the region\nkN (r) = (2\u03c0)\n\u22121\/2e\u2212\n1\n2\nr. (8)\nThe Bhattacharyya coefficient \u03c1 determines the distance\nbetween two histograms\n\u03c1(Href,Htar) =\nB\u2211\ni=1\n\u221a\nHi,refHi,tar. (9)\nwhere two normalised histograms H\u02c6tar and H\u02c6ref represent\na target region defined in the current frame and a reference\nregion in the frame at t0. The Bhattacharyya distance [8]\nd(Htar,Href) =\n\u221a\n1\u2212 \u03c1(Htar,Href), (10)\nis a measure of the similarity between these two distribu-\ntions. The larger the measure \u03c1(Href,Htar) is, the more\nsimilar the distributions are. Conversely, for the distance\nd, the smaller the value the more similar the distributions\n(histograms) are. For two identical normalised histograms\nwe obtain d = 0 (\u03c1 = 1) indicating a perfect match.\nBased on this distance the likelihood function over red,\ngreen, blue (R, G, B) colour space can be defined by [10]\np(yt|x\nn\nt ) \u221d exp\n\uf8eb\n\uf8ed\u2212 \u2211\nc\u2208{R,G,B}\nd2(Hctar,H\nc\nref)\n2\u03c32c\n\uf8f6\n\uf8f8 , (11)\nfor the n-th particle xnt . The standard deviation \u03c3 specifies\nthe Gaussian noise in the measurements. Note that small\nBhattacharyya distances correspond to large weights in the\nparticle filter.\n4. GRADIENT INFORMATION\nThe aim of the gradient descent is to minimise an objective\nfunction, O, with respect to the state vector x,\nx\u02c6 = arg min\nx\nO(x). (12)\nIf It(xt) = [I(r1, t), . . . , I(rR, t)]\u2032 is the vector of R\npixel intensities from an image region Sxt , corresponding\nto state xt at time t. Furthermore the locations r = [x, y]\u2032\nin Sxt are determined by the model g. It is assumed that g\nis differentiable with respect to both r and x.\nThe objective function can specifically be defined as the\nfollowing least squares function [11]\nO(x) =\n\u2211\ni\u2208I\n(It(xt)\u2212 It0(x0))\n2, (13)\nwhere x0 is the initial state at time t0. Alternatively the\nobjective function can be expressed as\nO(xt) = \u2016It(xt)\u2212 It0(x0)\u2016\n2\n. (14)\nReposing the problem in terms of iteratively determin-\ning the offset \u03b4x such that x\u02c6t = xt + \u03b4x then (14) becomes\nO(\u03b4x) = \u2016It(xt + \u03b4x)\u2212 It0(x0)\u2016\n2\n. (15)\nIf we assume that \u03b4x is small then we can apply contin-\nuous optimisation procedures to a linearised version of the\nproblem. The problem can be linearised by performing a\nTaylor series expansion of It(xt + \u03b4x) about xt\nIt(xt + \u03b4x) \u2248 It(xt) + \u03b4xMt(xt) + H.O.T., (16)\nwhere H.O.T. refers to higher order terms of the Taylor se-\nries expansion and Mt is the Jacobian matrix of It with re-\nspect to xt. Making the substitution of (16) into (15) gives\nO(\u03b4x) \u2248 \u2016It(xt) + \u03b4xMt(xt)\u2212 It0(x0)\u2016\n2\n. (17)\nSolving for \u2202O\u2202(\u03b4x) = 0 and rearranging gives\n\u03b4x = \u2212(M \u2032tMt)\n\u22121M \u2032t [It(xt)\u2212 It0(x0)], (18)\nand from this x\u02c6t can be defined as\nx\u02c6t = xt \u2212 (M\n\u2032\ntMt)\n\u22121M \u2032tet, (19)\nwhere\net = It(xt)\u2212 It0(x0). (20)\n4.1. Efficient Algorithm\nEvaluating (19) requires the estimation of the gradient of\neach target region in every frame. To allow efficient on-\nline implementation it can be shown that Mt can be de-\ncomposed into a time-varying component \u03a3t and a con-\nstant M0, which can be determined off-line. The efficiency\ncomes from removing the need to recalculate the Jacobian\nMt at every iteration. The decomposition of Mt is\nMt(xt) =\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8f0\n\u2207rI(r1, t0)\n\u2032\n\u0393(r1)\n\u2207rI(r2, t0)\u2032\u0393(r2)\n.\n.\n.\n\u2207rI(rR, t0)\n\u2032\n\u0393(rR)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fb\u03a3t(x) = M0\u03a3t(x),\n(21)\nwhere \u2207rI(r\u2113, t0)\u2032, \u2113 = 1, . . . , R denotes the gradient,\nwith respect to the components of r, of pixel r\u2113 at time t0,\n\u03a3t(xt) is dependent upon the motion model used and \u0393(r)\ndepends on both the motion model g used and the pixel loca-\ntion r = [x, y]\u2032. Examples of g are given for the translation\nmodel (Section 4.2) and the affine model (Section 4.3).\nIf \u03a3t is invertible then the state can be moved toward\nthe minimum of the error vector et by\nx\u02c6t = xt \u2212 (\u03a3\n\u22121\nt )\n\u2032\n\u039bet (22)\nwhere \u039b = (M \u20320M0)\u22121M0 and is computed during an ini-\ntialisation stage based on the model used. Hence, equation\n(19) is replaced by the more computationally efficient (22).\n107\n4.2. Translation Motion Model\nThe motion model described here and in section 4.3 defines\nhow the pixel locations are related to the state. This first\nmodel is for the case when the object performs a translation\nmotion\nf(r,xt) = r + xt, xt = [ut, vt]\n\u2032 (23)\nand for this model M0 = [Ix(t0)|Iy(t0)] and \u03a3 is the 2\u00d72\nidentity matrix. Remembering that \u039b = (MT0 M0)\u22121M0\nthe updated state, x\u02c6t, at time t is given by\nx\u02c6t = xt \u2212\u039bet. (24)\n4.3. Affine Motion Model\nIf the object to be tracked is a planar object a more suit-\nable model to capture the transformation is given by the six\ncomponent affine transform. The motion model and current\nstate of the object xt at time t can be described by\nf(r,xt) =\n[\na c\nb d\n]\nr +\n[\nu\nv\n]\n= Ar + u. (25)\nThe state vector is xt = [ut, vt, at, bt, ct, dt]\u2032. Using the\naffine motion model gives\n\u0393(p) =\n[\n1 0 x 0 y 0\n0 1 0 x 0 y\n]\n, (26)\nand\n\u03a3t(x) =\n\uf8ee\n\uf8f0A\u22121 0 00 A\u22121 0\n0 0 A\u22121\n\uf8f9\n\uf8fb . (27)\nThe updated state, x\u02c6t, at time t is given by\nx\u02c6t = xt \u2212\u03a3\n\u2032\nt\u039bet. (28)\nIt is possible to use other models including some non-\nlinear models. Not all of them are suitable because of the\nseparability property needed to factorise M .\n5. IMPLEMENTATION\nTable 2 presents a particle filter that takes into account the\ngradient information in the way described in Section 4.\nTable 2: Particle Filter with Gradient Step\n1. Initialisation\nFor n = 1, . . . , N set wn0 = 1N .\nCalculate M0 = [Ix(t0)|Iy(t0)] for the target region\nand then evaluate\n\u039b = (MT0 M0)\n\u22121M0 (29)\n2. Importance Sampling\nFor n = 1, . . . , N ,\n\u2022 Sample xnt+1|t \u223c q(xt+1|xnt|t)\n\u2022 For j = 1, . . . , J (with J iterations)\n\u2013 Gradient step\nxnt+1|t = x\nn\nt+1|t \u2212\u2126\u03a3\n\u2032\nt\u039be\nn\nt+1\n\u2022 Evaluate the weights\nwnt+1 = w\nn\nt p(yt+1|x\nn\nt+1)\np(xit+1|x\ni\nt|t)\np(xit+1|x\ni\nt+1|t)\n(30)\n\u2022 Normalise the weights, w\u02dcnt+1 =\nwn\nt+1\u2211\nN\nm=1\nwm\nt+1\nEvaluate N\u02c6eff = 1\u2211N\nn=1\n(w\u02dcn\nt+1\n)2\n3. Output\nEstimate the current state\nx\u00aft+1 =\nN\u2211\nn=1\nw\u02dcnt+1x\nn\nt+1. (31)\n4. Resampling\nIf N\u02c6eff \u2264 Nthres\n\u2022 For n = 1, . . . , N , resample with replacement\nN particles xnt+1 according to their weights\nFor the purpose of tracking an object in video we ini-\ntially choose a region which defines the object. The shape\nof this region is fixed a priori and in our case it is a rectan-\ngular box characterised by the state vector x = (x, x\u02d9, y, y\u02d9)\u2032,\nwith x and y denoting the pixel location of the top-left cor-\nner of the rectangle, with velocities x\u02d9 and y\u02d9. Note that the\ndimensions of the rectangle are fixed through the sequence.\nThe transition distribution p(xt+1|xt) used for this work\nis a constant velocity dynamic model [12]\nxk+1 = Fxk + wk, wk \u223d N (0,Q) (32)\n108\nF =\n(\nF\u02dc 0\n0 F\u02dc\n)\n, F\u02dc =\n(\n1 T\n0 1\n)\n,\nQ =\n(\nQx 0\n0 Qy\n)\n, \u0393 =\n(\n1\n2T\n2\nT\n)\n,\nwith the state vector x = (x, x\u02d9, y, y\u02d9)\u2032, the system noise w =\n(w\u2032x,w\n\u2032\ny)\n\u2032 = (\u0393\u2032vx,k,\u0393\n\u2032vy,k)\n\u2032\n, vx,k \u223d N (0, \u03c3x), vy,k \u223d\nN (0, \u03c3y) being scalar valued zero mean white sequences\nwith standard deviations \u03c3x and \u03c3y respectively and T is\nthe sampling interval.\nThe covariance matrices of the noise respectively in x\nand y coordinates multiplied by the gain, are\nQx = \u0393\u03c3\n2\nx\u0393 =\n(\n1\n4T\n4 1\n2T\n3\n1\n2T\n3 T 2\n)\n\u03c32x.\nThe covariance Qy can be calculated in a similar way. Suit-\nable values for \u03c3x and \u03c3y are ([12], p. 273) in the range\n[ 12am, am], with am being the maximum acceleration.\nAn implementation issue in combining the constant ve-\nlocity model with the gradient descent is that the gradient\ndescent only updates the x and y coordinates of the state\nand appropriate account needs to be taken to update the ve-\nlocities. This is done through the use of the following matrix\n\u2126 =\n[\n1 1T 0 0\n0 0 1 1T\n]\u2032\n, (33)\nwhere T is the sampling period and in our implementation\nT = 1.\n6. RESULTS\nThe results presented here are from experiments carried out\non rigid objects in a natural sequences (Fig. 1) and a syn-\nthetic sequence (Fig. 2). The object in the synthetic se-\nquence is quite textured, in the artificial sequence it con-\ntains more homogeneous regions. The target regions are\ninitialised by providing the coordinates of the target region\nin the first frame. The state xt = (x\u02c6, y\u02c6) represents an esti-\nmate of the true coordinates (x, y), therefore the root mean\nsquare RMSE is\nRMSE =\n\u221a\n(xt \u2212 x\u02c6t)2 + (yt \u2212 y\u02c6t)2. (34)\nand for a sequence of F frames it is\nRMSEseq =\n\u221a\u221a\u221a\u221a 1\nF\nF\u2211\nt=1\n(xt \u2212 x\u02c6t)2 + (yt \u2212 y\u02c6t)2. (35)\nA comparison of the relative performance of the two al-\ngorithms over the natural sequence is given in Fig. 1. It can\nbe seen that for any number of particles more accurate re-\nsults are obtained by the particle filter with a gradient step.\n0 1 2 3 4 5\n90\n70\n50\n30\n10\nRMSE\nseq\nPa\nrti\ncl\nes\n \n \n \n \n \n \n \n \n \n \nGradient\nNo Gradient\n4.63\n3.28\n1.51\n0.79\n1.00\n0.48\n0.69\n0.39\n0.58\n0.33\n(a) Relative Performance\n0 0.5 1 1.5 2\n90\n70\n50\n30\n10\nTime\nPa\nrti\ncl\nes\n \n \n \n \n \n \n \n \n \n \nGradient\nNo Gradient\n1.76\n1.53\n1.51\n1.25\n1.20\n1.00\n0.86\n0.69\n0.42\n0.34\n(b) Relative Complexity\nFig. 1. Comparison of the generic particle filter and particle\nfilter with gradient step. All of the results are presented\nas relative to the generic particle filter with 50 particles (a)\nRelative RMSE of the state estimated by the algorithm. (b)\nRelative processing time for the generic particle filter and\nthe particle filter with gradient step. The results are for a\nsequence of 60 frames and are averaged over 100 runs.\nIt can also be seen that for comparable complexity the gra-\ndient particle filter outperforms the generic particle filter.\nTracking results of the two algorithms on the natural se-\nquence are shown in Fig. 3.\nResults from a synthetic sequence are shown in Fig. 2.\nThe estimated path from the particle filter is clearly smoother\nand more accurate when the gradient information is used.\nThis can be clearly seen in Fig. 2a by the jittering in the\nparticle filter path that is not present in when the gradient\nstep is used. The RMSE can be clearly seen to be lower\nwhen the gradient information is used in Fig. 2b.\n7. CONCLUSIONS\nWe have presented a method of improving the proposal dis-\ntribution in the particle filter by taking into account the gra-\ndient information available in a frame. The inclusion of\ninformation from the current frame in the proposal distri-\n109\n95 100 105 110 115 120 125\n120\n130\n140\n150\n160\n170\n180\n190\n200\n210\nx\ny\nTrue\nPF\nPF+Gradient\n(a) Tracking Results\n0 10 20 30 40 50 60\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\n4.5\nFrames\nR\nM\nSE\nPF\nPF + Gradient\n(b) RMSE\nFig. 2. Comparison of the generic particle filter and particle\nfilter with gradient step applied to an synthetic sequence.\n(a) A section of the true path of the object compared to the\nestimates from one run of the particle filter and the particle\nfilter with the gradient step. (b) The RMSE of the particle\nfilter and the particle filter with the gradient step, the results\nare the mean of 100 run.\nbution moves the particles to the high-likelihood regions\nwhich results in improved performance. An efficient imple-\nmentation of the gradient step particle filter is given. Re-\nsults show that there are two main improvements over a\ngeneric particle filter i) a significant increase in the accuracy\n(lower RMSE) and ii) since fewer particles are needed to\nrepresent the posterior there is a reduction in computational\ncomplexity. Future work will extend the method to include\nchanges to the object appearance.\n8. REFERENCES\n[1] M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp, \u201cA\ntutorial on particle filters for online nonlinear\/non-Gaussian\nBayesian tracking,\u201d IEEE Trans. on Signal Proc., vol. 50,\nno. 2, pp. 174\u2013188, 2002.\n[2] J. Liu and R. Chen, \u201cSequential Monte Carlo methods for\ndynamic systems,\u201d Journal of the American Statistical As-\nsociation, vol. 93, no. 443, pp. 1032\u20131044, 1998.\n[3] N. Gordon, D. Salmond, and A. Smith, \u201cA novel approach\nto nonlinear \/ non-Gaussian Bayesian state estimation,\u201d IEE\n(a) PF (frame 6) (b) PF (frame 54)\n(c) PF with Gradient (frame 6) (d) PF with Gradient (frame 54)\nFig. 3. Frames (6 and 54) from a sequence tracking the\nscoreboard with the two filters. It can be seen that the parti-\ncle filter with a gradient step results in more accurate track-\ning than the generic particle filter.\nProc. on Radar and Signal Processing, vol. 40, pp. 107\u2013113,\n1993.\n[4] A. Doucet, S. Godsill, and C. Andrieu, \u201cOn sequen-\ntial Monte Carlo sampling methods for Bayesian filtering,\u201d\nStatistics and Computing, vol. 10, no. 3, pp. 197\u2013208, 2000.\n[5] S. Haykin, K. Huber, and Z. Chen, \u201cBayesian sequential\nstate estimation for MIMO wireless communications,\u201d Pro-\nceedings of the IEEE, vol. 92, no. 3, pp. 439\u2013454, March\n2004.\n[6] J. Sullivan and J. Rittscher, \u201cGuiding random particles by\ndeterministic search,\u201d in IEEE Int. Conf. on Computer Vi-\nsion, July 2001, vol. 1, pp. 323\u2013330.\n[7] C. Chang and R. Ansari, \u201cKernel particle filter for visual\ntracking,\u201d IEEE Signal Processing Letters, vol. 12, no. 3,\npp. 242\u2013245, March 2005.\n[8] D. Comaneciu, V. Ramesh, and P. Meer, \u201cKernel-based ob-\nject tracking,\u201d IEEE Trans. on Pattern Analysis and Machine\nIntelligence, vol. 25, no. 5, pp. 564\u2013577, 2003.\n[9] A. Kong, J. Liu, and W. Wong, \u201cSequential imputations and\nBayesian missing data problems,\u201d Journal of the American\nStatistical Association, vol. 89, pp. 278\u2013288, 1994.\n[10] P. Pe\u00b4rez, J. Vermaak, and A. Blake, \u201cData fusion for tracking\nwith particles,\u201d Proceedings of the IEEE, vol. 92, no. 3, pp.\n495\u2013513, March 2004.\n[11] G. D. Hager and P. N. Belhumeur, \u201cEfficient region track-\ning with parametric models of geometry and illumination,\u201d\nIEEE Trans. on PAMI, vol. 20, no. 10, pp. 1025\u20131039, 1998.\n[12] Y. Bar-Shalom and X.R. Li, Estimation and Tracking: Prin-\nciples, Techniques and Software, Artech House, 1993.\n110\n"}
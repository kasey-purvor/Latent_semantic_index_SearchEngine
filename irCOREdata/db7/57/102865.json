{"doi":"10.1109\/WCNC.2005.1424738","coreId":"102865","oai":"oai:epubs.surrey.ac.uk:2422","identifiers":["oai:epubs.surrey.ac.uk:2422","10.1109\/WCNC.2005.1424738"],"title":"Modeling Split-TCP Latency and Buffering Requirements in GEO Satellite Networks","authors":["Karaliopoulos, M","Tafazolli, R","Evans, B"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2005-03","abstract":"The paper addresses the TCP performance enhancing\\ud\nproxy techniques broadly deployed in wireless networks. Drawing on available models for TCP latency, we describe an analytical model for the latency and the buffer requirements related to the split-TCP mechanism. Although the model applicability is broad, we present and evaluate the model in the context of geostationary satellite networks, where buffering requirements may become more\\ud\ndramatic. Simulation results are compared with the analytical\\ud\nmodel estimates and show that the model captures the impact of\\ud\nvarious parameters affecting the dynamics of the component\\ud\nconnections traversing the terrestrial and the satellite network","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"Institute of Electrical and Electronics Engineers","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:2422<\/identifier><datestamp>\n      2017-10-31T14:05:30Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/2422\/<\/dc:relation><dc:title>\n        Modeling Split-TCP Latency and Buffering Requirements in GEO Satellite Networks<\/dc:title><dc:creator>\n        Karaliopoulos, M<\/dc:creator><dc:creator>\n        Tafazolli, R<\/dc:creator><dc:creator>\n        Evans, B<\/dc:creator><dc:description>\n        The paper addresses the TCP performance enhancing\\ud\nproxy techniques broadly deployed in wireless networks. Drawing on available models for TCP latency, we describe an analytical model for the latency and the buffer requirements related to the split-TCP mechanism. Although the model applicability is broad, we present and evaluate the model in the context of geostationary satellite networks, where buffering requirements may become more\\ud\ndramatic. Simulation results are compared with the analytical\\ud\nmodel estimates and show that the model captures the impact of\\ud\nvarious parameters affecting the dynamics of the component\\ud\nconnections traversing the terrestrial and the satellite network.<\/dc:description><dc:publisher>\n        Institute of Electrical and Electronics Engineers<\/dc:publisher><dc:date>\n        2005-03<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/2422\/1\/SRF002644.pdf<\/dc:identifier><dc:identifier>\n          Karaliopoulos, M, Tafazolli, R and Evans, B  (2005) Modeling Split-TCP Latency and Buffering Requirements in GEO Satellite Networks   IEEE Wireless Communications and Networking Conference, 3.  pp. 1509-1514.      <\/dc:identifier><dc:relation>\n        http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1424738<\/dc:relation><dc:relation>\n        10.1109\/WCNC.2005.1424738<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/2422\/","http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1424738","10.1109\/WCNC.2005.1424738"],"year":2005,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"Modeling split-TCP latency and buffering \nrequirements in GEO satellite networks \n \nM. Karaliopoulos, R. Tafazolli and B. Evans \nCentre for Communication Systems Research \nUniversity of Surrey \nGuildford, GU2 7XH, United Kingdom \n \n \nAbstract\u2015The paper addresses the TCP performance enhancing \nproxy techniques broadly deployed in wireless networks. Drawing \non available models for TCP latency, we describe an analytical \nmodel for the latency and the buffer requirements related to the \nsplit-TCP mechanism. Although the model applicability is broad, \nwe present and evaluate the model in the context of geostationary \nsatellite networks, where buffering requirements may become more \ndramatic. Simulation results are compared with the analytical \nmodel estimates and show that the model captures the impact of \nvarious parameters affecting the dynamics of the component \nconnections traversing the terrestrial and the satellite network.  \nKeywords\u2015split connections; GEO satellite links; TCP \nI. INTRODUCTION \nTCP Performance Enhancing Proxies (TCPPEPs) are \namongst the favorite methods of enhancing TCP performance \nover wireless links, although they are viewed with skepticism \nwithin the IETF community. The main concerns are related to \nthe reliability and the security of data communications that use \nthe proxy services [1]: TCPPEPs conflict with the use of IPsec, \nwhich is mandatory for IPv6 and is regarded by many members \nof the Internet community as the unique way to enforce security \nin the Internet. The implementation of numerous features for \nTCP performance enhancement over wireless networks via use \nof intermediate agents, presupposes the capability to retrieve \ninformation carried in transport and application layer headers; \nthis is not possible with standard IPsec. Nevertheless, the \nperformance gain achieved with TCPPEPs appears to be too \nsignificant to be sacrificed. The proposal of Multi-Layer IPsec \n[2] reflects the will of the wireless communications community \nto preserve the performance enhancing features of TCPPEPs \nwithout sacrificing the advantages of IPsec. \nSplit connections are only one of the potential features of \nTCPPEPs. A proxy agent at the border between the wired and the \nwireless network intercepts the connection set-up (SYN) and \ntermination (FIN) packets and initiates another connection over \nthe wireless link. The proxy prematurely acknowledges the \narriving TCP segments, before they reach the receiver at the \nother end of the wireless link, thus allowing the TCP sender \nendpoint to open its window quickly and accelerate the transfer \nrate. In the same time, it caches TCP segments so that they are \nforwarded to the destination under the command of the protocol \ndeployed over the wireless link. Integrated PEP implementations \nfeature a single PEP component residing on a single node, \nwhereas distributed PEP implementations consist of multiple \nPEP components that may be hosted at multiple network nodes \nsurrounding the wireless links over which performance \nenhancement is targeted [1]. \nSplit connections have been studied extensively as a solution \nfor terrestrial wireless networks\u2212 see, for example [3] and \nreferences therein. The additional problem in the case of GEO \nsatellite networks is the high link latency that introduces higher \nbuffering requirements at the border node (gateway) between the \nwired and the satellite network. The required buffer space is \nhighly dependent on the transport protocol deployed over the \nsatellite link. This may be either a TCP variant enriched with \noptimizations related to satellite environments or an independent \nprotocol. In [4], TCP SACK is combined with three options, \nnamely window scaling, timestamps and larger initial window \n[5], to make up an enhanced TCP version that is deployed over \nthe satellite link. The advantage of this approach is that the \nsatellite component of the connection inherits the \nflow\/congestion control mechanisms of TCP that are necessary \nin shared satellite environments. On the other hand, the departure \nfrom TCP features allows higher flexibility in the protocol \noptimization. In [6], the authors propose the Satellite Transport \nProtocol (STP) as the satellite component of the end-to-end \nconnection. STP replaces the per-TCP segment(s) ACKs with \nperiodic exchange of reports between sender and receiver, which \nresults in significant savings in the reverse path (i.e., the path \nfollowed by ACK packets) [7]. \nIn this paper, we focus on integrated PEP split connection \nimplementations that deploy TCP over the satellite link (split-\nTCP). In section II, we present our model for the split-TCP \nlatency, namely the overall time spent on a finite transfer carried \nout by a split-TCP implementation, and the buffer requirements \nat the intermediate host hosting the TCPPEP agent. In doing so, \nwe \u2212inevitably\u2212 reproduce part of the analysis in [8], since it is \nrequired for the model formulation. We evaluate our model and \ndiscuss the simulation results in section III, before concluding \nour paper in section IV. \nII. THE MODEL \nA. Split-TCP latency model \nOur starting point is the TCP latency model described by \nCardwell, Savage and Anderson in [8]. The model can be \nIEEE Communications Society \/ WCNC 2005 1509 0-7803-8966-2\/05\/$20.00 \u00a9 2005 Crown Copyright\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 15:37:48 UTC from IEEE Xplore.  Restrictions apply. \nconsidered an improvement over earlier models addressing only \nthe congestion avoidance phase of TCP [9], [10], the \napplicability of which was limited to persistent TCP connections. \nIt addresses connections that transfer a finite amount of bytes D, \ncatering for the slow-start phase and the first loss recovery, and \ncaptures the impact of several protocol parameters such as the \ninitial window inW , the TCP delayed acknowledgment option \nand the maximum TCP receive window limitations maxW . On \nthe other hand, it invokes the model in [9] for the estimation of \nthe steady-state throughput, hence inheriting its weaknesses: no \nmodeling of the TCP fast recovery algorithm, sensitivity on \nprecise knowledge of the connection round-trip time (RTT) and \nTCP retransmission timeout variable [11, chapter 3]. \n1) Terrestrial component of the split-TCP connection: Let \nTp  be the TCP segment loss rate in the terrestrial component of \nthe connection. This loss rate may be due either to congestion at \nthe network buffers or link errors1. Following [8], the transfer \nevolves generally in three phases. The duration, or even \nrelevance, of each phase to the transfer progress depends mainly \non the encountered loss rate. \nWithout loss of generality, let us assume that the data transfer \nbegins at time t=0. The expected number of TCP segments \ndelivered from the terrestrial connection till the first packet loss \nis given in [8]: \n( )( ) ( )\n\uf8f4\uf8f4\uf8f3\n\uf8f4\uf8f4\uf8f2\n\uf8f1\n>\uf8f7\uf8f7\uf8f8\n\uf8f6\n\uf8ec\uf8ec\uf8ed\n\uf8eb\n+\n\u2212\u22c5\u2212\u2212\n=\n=\n01\n111\n0\n][\nT\nT\nT\nD\nT\nT\nsgm\nT\nss\nT pif\np\npp\npifD\nDE sgmT  (1) \nwhere \uf8fa\uf8fa\n\uf8f9\uf8ef\uf8ef\n\uf8ee\n=\nT\nsgm\nT MSS\nDD  is the transfer size in segments \nrespectively and TMSS  is the TCP segment size used by the \nterrestrial TCP sender. Unless otherwise noted, all window \nvalues mentioned subsequently imply TCP segments. \nLet inTW  be the initial window of the terrestrial connection \nand T\u03b3  be the rate of the congestion window (cwnd) exponential \ngrowth during slow start, which is 2 if delayed acknowledgments \nare not activated and 1.5 otherwise. Had no constraint maxTW  \nbeen imposed due to the maximum TCP buffer size or the \nreceive window, the mean cwnd size at the time of first packet \nloss would be \n[ ] [ ] ( )\nT\nin\nT\nT\nT\nss\nTss\nT\nWDE\nWE\n\u03b3\u03b3\n\u03b3\n+\n\u2212\u22c5\n=\n1\n. (2) \nDepending on the relation between [ ]ssTWE  and maxTW , two \nscenarios are possible. When [ ] maxTssT WWE \u2264 , the slow-start \nphase is terminated at time \n( )][log1 ssTT WERTTt TT \u03b3\u22c5=  (3) \n                                                           \n1 The link error probability is independent of the congestion loss. The opposite \ndoes not hold in general. \nduring which the connection transfers [ ]ssTDE  segments. \nOtherwise, slow-start evolves in two sub-phases. The first one is \nterminated when the window reaches ssTW  at time \n\uf8f7\uf8f7\uf8f8\n\uf8f6\n\uf8ec\uf8ec\uf8ed\n\uf8eb\n+\uf8f7\uf8f7\uf8f8\n\uf8f6\n\uf8ec\uf8ec\uf8ed\n\uf8eb\n\u22c5= 1log\nmax\n1\nT\nT\nTa\nW\nRTTt\nT\nT\n\u03b3\u03b3\n (4) \nduring which the connection transfers \n1\nmax\n1\n\u2212\n\u2212\u22c5\n=\nT\nin\nTTTa\nT\nWW\nD\n\u03b3\n\u03b3\n \nsegments. The second involves the transmission of maxTW  \nsegments per round and completes the transmission of [ ]ssTDE  \nsegments at time [ ]( )\nmax\n1\n11\nT\na\nT\nss\nT\nT\nT\na W\nDDE\nRTTtt\nT \u2212\n\u22c5+=  (5) \nThe slow-start phase will be terminated upon a segment loss \nwith probability \n( ) sgmTDTssT pl \u2212\u2212= 11  (6) \nleading to a retransmission timeout with probability [9] \n( ) ( ) [ ]( )\n( ) [ ]( ) ( )( ) \uf8f7\uf8f7\uf8f8\n\uf8f6\n\uf8ec\uf8ec\uf8ed\n\uf8eb\n\u2212\u2212\u2212\u2212\n\u2212\u2212\u22c5\u2212+\n=\n\u2212\n3\n33\n1111\n1111\n,1min\nT\nWE\nT\nWE\nTT\nRTO\npp\npp\np ss\nT\nss\nT\n. (7) \nWhen slow-start ends with a timeout, the suffered delay will \nbe equal to  ( )\nT\nTTTTTTo\nTRTO p\npppppp\nTT\n\u2212\n\u22c5+\u22c5+\u22c5+\u22c5+\u22c5++\n\u22c5=\n1\n32168421 65432\n \nwhere oTT  is the base TCP retransmission timer timeout value. \nWith probability 1- RTOp  the connection will enter Fast \nRecovery, whose duration is taken to be one round-trip time. \nOverall the connection will recover from the first segment loss in \ntime \n( )( )TRTORTORTOssTTT RTTpTpltt \u22c5\u2212+\u22c5\u22c5+= 112 . (8) \nThe connection then proceeds in congestion avoidance mode, \nwith a segment send rate RT  derived in the steady-state \nthroughput analysis in [9] and referred to in [8, Eq. 22]. The \nconnection finally completes the transfer of D bytes in time: [ ]( )\nT\nss\nT\nsgm\nTTT\nR\nDED\ntt\n\u2212\n+= 23  (9)\nTherefore, the progress of the data transfer in bytes with time \nat the terrestrial component of the connection, ( )tDT , is \nsummarized by (10). \n2) Satellite component of the split-TCP connection: \nAssuming that the initial connection set-up messages are let pass \nthrough the network end-to-end, the data transfer over the \nsatellite link begins with a hysteresis equal to 2\/TRTT . \nForgetting for a moment the dependence on the terrestrial \nTCP connection, the satellite component tends to evolve in a \nsimilar manner. Therefore we can estimate [ ]ssSDE , [ ]ssSWE  as in \nequations (1) and (2) on the basis of inSW , S\u03b3 , maxSW ,  \nIEEE Communications Society \/ WCNC 2005 1510 0-7803-8966-2\/05\/$20.00 \u00a9 2005 Crown Copyright\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 15:37:48 UTC from IEEE Xplore.  Restrictions apply. \n( )\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\uf8f4\uf8f4\n\uf8f4\uf8f4\n\uf8f4\uf8f4\n\uf8f4\n\uf8f3\n\uf8f4\uf8f4\n\uf8f4\uf8f4\n\uf8f4\uf8f4\n\uf8f4\n\uf8f2\n\uf8f1\n\u2264\u2264\u2212\u22c5\u22c5+\n\u2264\u2264\u22c5\n\u2264\u2264\u2264\n\u2212\n\u2212\n\u22c5\u22c5\n>\u2264\u2264\uf8f7\uf8f7\uf8f8\n\uf8f6\n\uf8ec\uf8ec\uf8ed\n\uf8eb\n\uf8fa\uf8fa\uf8fa\n\uf8f9\n\uf8ef\uf8ef\uf8ef\n\uf8ee\n\u2212\n\u22c5\u22c5+\n>\u2264\u2264\n\u2212\n\u2212\n\u22c5\u22c5\n= \uf8fa\uf8fa\n\uf8f9\uf8ef\uf8ef\n\uf8ee\n\uf8fa\uf8fa\n\uf8f9\uf8ef\uf8ef\n\uf8ee\nTTT\nTT\nss\nT\nTTss\nTT\nT\nss\nT\nT\nT\nRTT\nt\nTin\nTT\nT\nss\nT\nTT\na\nT\nT\na\nTT\na\nT\nT\nss\nT\nT\na\nT\nRTT\nt\nTin\nTT\nT\ntttttRMSSDE\ntttDEMSS\nWWEifttWMSS\nWWEiftttD\nRTT\ntt\nWMSSD\nWWEifttWMSS\ntD\nT\nT\n322\n21\nmax\n1\nmax\n11\n1max1\nmax\n1\n)(\n,0\n1\n1\n,,min\n,0\n1\n1\n\u03b3\n\u03b3\n\u03b3\n\u03b3\n (10) \n( )\n[ ]\n[ ]\n[ ]\n[ ]\n[ ]\uf8f4\uf8f4\n\uf8f4\uf8f4\n\uf8f4\uf8f4\n\uf8f4\n\uf8f3\n\uf8f4\uf8f4\n\uf8f4\uf8f4\n\uf8f4\uf8f4\n\uf8f4\n\uf8f2\n\uf8f1\n\u2264\u2264\u2212\u22c5\u22c5+\n\u2264\u2264\u22c5\n\u2264\u2264\u2264\n\u2212\n\u2212\n\u22c5\u22c5\n>\u2264\u2264\uf8f7\uf8f7\uf8f8\n\uf8f6\n\uf8ec\uf8ec\uf8ed\n\uf8eb\n\uf8fa\uf8fa\n\uf8f9\uf8ef\uf8ef\n\uf8ee\n\u2212\n\u22c5\u22c5+\n>\u2264\u2264\n\u2212\n\u2212\n\u22c5\u22c5\n=\n\uf8fa\uf8fa\uf8fa\n\uf8f9\n\uf8ef\uf8ef\uf8ef\n\uf8ee\n\u2212\n\uf8fa\uf8fa\uf8fa\n\uf8f9\n\uf8ef\uf8ef\uf8ef\n\uf8ee\n\u2212\nSSS\nSS\nss\nS\nSSss\nSS\nS\nss\nS\nSS\nS\nRTT\nRTTt\nSin\nSS\nS\nss\nS\nSS\na\nS\nS\na\nSS\na\nS\nS\nss\nS\nS\na\nT\nS\nRTT\nRTTt\nSin\nSS\nS\ntttttRMSSDE\ntttDEMSS\nWWEifttRTTWMSS\nWWEiftttD\nRTT\nttWMSSD\nWWEifttRTTWMSS\ntD\nS\nT\nS\nT\n322\n21\nmax\n1\n2\nmax\n11\n1max1\nmax\n1\n2\n\u02c6\u02c6)\u02c6(\n\u02c6\u02c6\n,\u02c6\n21\n1\n,\u02c6\u02c6,\n\u02c6\nmin\n,,\u02c6\n21\n1\n\u03b3\n\u03b3\n\u03b3\n\u03b3\n (11) \n \n \nSMSS , SRTT , and if we add a constant time shift to the \nrespective time instants  \n \n2\n\u02c6 TS\nx\nS\nx\nRTT\ntt += , { }3211 ax\u2208 , (12) \nthe cumulative number of bytes sent by the satellite component \nof the end-to-end connection is given by (11). \nB. Latency \nDepending on the relation between ( ) ( )tDtD ST ,  we can then \nidentify two cases: \na) ( ) ( ) \uf8fa\uf8fb\n\uf8f9\uf8ef\uf8f0\n\uf8ee\n\u2208\u2200\u2265 TTST t\nRTT\nttDtD 3,2\n (13) \nIn this case there are always TCP segments in the gateway \nbuffers and the satellite component of the connection never \nstarves. The overall transfer latency is dictated by the satellite \ncomponent of the connection that evolves more slowly than its \nterrestrial counterpart \nS\nsplit tTE 3\u02c6][ =  (14) \nb) ( ) ( ) \uf8fe\uf8fd\n\uf8fc\n\uf8f3\uf8f2\n\uf8f1 \u2264\u2032\u2264\u2032<\u2032\u2032\u2203 TTST ttRTTtDtDt 32:   (15) \nIn this case there is at least one interval during the transfer \ncompletion, where the gateway buffers empty. Therefore the \nTCP performance over the satellite link is actually constrained \nby the terrestrial portion of the connection. The overall transfer \nlatency is now: \nS\nT\nsplit RTTtTE += 3][  (16) \nC. Buffer requirements \nApparently, the buffered data ( )tB at the gateway are given \nby \n( ) ( ) ( )\uf8ee \uf8f9+\u2212= tDtDtB ST  (17) \nwhere \uf8ee \uf8f9+x  denotes the minimum non-negative integer \nnumber that is equal to or larger than x. \nIII. MODEL EVALUATION \nWe evaluate the model accuracy against ns2 [12] simulations. \nThe simulation scenario is depicted in Figure 1: a single TCPPEP  \nIEEE Communications Society \/ WCNC 2005 1511 0-7803-8966-2\/05\/$20.00 \u00a9 2005 Crown Copyright\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 15:37:48 UTC from IEEE Xplore.  Restrictions apply. \nTCPPEP\n{RTTT, pT}\n \nFigure 1. Simulation scenario for the validation of the split-TCP model \nagent, located at the satellite gateway node, splits a TCP \nconnection between a server node at the terrestrial network and \nan end node behind a satellite terminal. \nWe perform file transfers ranging from 20kB to 2MB varying the \nquality of the satellite link, the TCP round-trip time and the \npacket loss faced by the terrestrial component of the connection. \nThe default satellite link capacity (data rate) is 512kb\/s. We used \nthe TCP NewReno variant [13] with the timestamps option \nactivated. maxW  is set to 32kB, which is an intermediate value \nbetween the default settings for Windows 2000 (16kB) and the \nWindows XP (64kB), unless otherwise stated. The TCP MSS is \n526 bytes allowing for the timestamps option (10 bytes) and 40 \nbytes TCP\/IP headers. The granularity of the TCP timer is 100ms \nand the initial window is one TCP segment. \nFor all simulation results shown in the rest of the paper, we \nplot mean values, estimated as the average of 50 simulation runs, \nalong with their 95% confidence intervals. \nA. TCP latency \n1) No packet loss at the wired network: In this case, the split-\nTCP latency is dictated by the dynamics of the satellite \ncomponent of the end-to-end connection. Figure 2. suggests that \nas far as no packet loss is met at the terrestrial networks, the \nTRTT  does not affect the overall latency, since the terrestrial \ncomponent of the connection is much faster than its satellite \ncounterpart The terrestrial component features a smaller, error-\nfree loop and its throughput is only constrained by the receive \nwindow maxTW  (32kB). The link errors start having an impact on \nthe overall latency after some transfer size-dependent value, \nranging from BER = 10-6 for 20kB transfers to 10-7 for 2MB \ntransfers. \nThe model predictions follow closely the simulation outcome. \nThe precision of the model increases with larger transfer sizes \nand higher error rates, whereas it is slightly optimistic at lower \nerror rates. This is attributed to the non-negligible transmission \n(serialization) delay and the consequent queuing delay at the \nsatellite link buffers. For a 512kb\/s satellite link, this delay is not \nnegligible2. \n2) Packet loss at the terrestrial leg of the connection: We \nperform two sets of simulation experiments. In both sets we vary \nthe packet loss rate Tp  at the terrestrial network, whereas we \nmaintain fixed BER over the satellite link. In Figure 2a, the BER \nis set to the rather pessimistic value of 10-5. Although the \nthroughput of the terrestrial connection is reduced, the overall \n                                                           \n2 Note that the authors in [8] validate their TCP latency model simulating \ntransfers over a 1Gbps link, circumventing this way the impact of transmission \nand queuing delays. \nsplit-TCP latency is still determined by the latency of the satellite \ncomponent of the connection, since the high BER prevents TCP \nfrom reaching full speed over the satellite link. Only for Tp  as \nhigh as 0.2 is there notable performance deterioration suggesting \nthat we enter the { }ST pp ,  regime, where (15) holds. On the \ncontrary, Figure 2b plots the split-TCP latency when the BER is \nset to 10-8. Now, the terrestrial component of the connection \nappears to be the slower one and it is its own speed that defines \nthe overall latency, according to (16). \nBoth figures basically confirm the robustness of the model to \nthe dynamics of the terrestrial portion of the connection but also \nreveal the original TCP latency model inaccuracy with respect to \nthe timeout value parameter To. This becomes obvious in the \nBER = 10-8 case, where the overall latency is determined by the \ndynamics of the terrestrial connection. The probability of a \ntimeout increases with Tp  along with the weight of the \nrespective delay on the overall latency. The small TRTT  makes \nthe model predictions more sensitive to the To setting, which is \nstatic in the latency model of [8] as it is static in the PFTK \nformula [9] that is incorporated in the former model. On the \ncontrary, in the real protocol operation, To is adjusted \ncontinuously according to the experienced RTT. The default \nvalue of 1s, chosen for these runs according to the suggestions in \n[8] and [9], appears to be reasonably good for high packet loss \nrates but too high for moderate error rates, as intuitively \nexpected. Note that this inefficiency is hidden in Figure 3a, since \nthe split-TCP latency is determined by the slower satellite \ncomponent of the connection, which has a higher RTT. \nB. Buffer requirements \nIn Figure 4a-b we plot percentiles of the buffer requirements \nat the satellite gateway node hosting the TCPPEP. The buffered \ndata were logged during simulation with a time step equal to \n10ms, whereas the respective model values were obtained via \nsampling of (17) with the same frequency. The median(50th), the \n90th and the 99th percentiles of the two data sets were obtained \nsubsequently via off-line statistical processing of the derived \ntime series. As it can also be seen in Table I, the agreement of \nthe model with the simulation outcome improves with greater \npercentiles, which notably are the ones that matter in the \nestimation of buffer requirements. In particular, their 99th \npercentile is a good estimate of the maximum buffer space that is \nrequired if data loss is to be avoided. \nA closer look at the way the satellite gateway node buffer \noccupation evolves with time is given in Figure 5a and Figure \n5b, which plot ( )tDT , ( )tDS  and ( )tB  according to (10), (11) \nand (17), respectively. The increase of error rate over the satellite \nlink drives the satellite component of the connection earlier into \nthe congestion avoidance phase and lengthens the data transfer \nover the satellite link. As a result, higher amounts of data have to \nstay longer at the buffers. Since no packet loss is encountered at \nthe terrestrial network, the higher percentiles approximate the \nsize of the transfer. \nIEEE Communications Society \/ WCNC 2005 1512 0-7803-8966-2\/05\/$20.00 \u00a9 2005 Crown Copyright\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 15:37:48 UTC from IEEE Xplore.  Restrictions apply. \na) RTTT = 40ms, pT = 0 b) RTTT = 200ms, pT = 0 \n10\u22128 10\u22127 10\u22126 10\u22125\n100\n101\n102\nBER\nSp\nlit\u2212\nTC\nP \nla\nte\nnc\ny \n(s)\nD=20kB\nD=100kB\nD=500kB\nD=2MB\n \n10\u22128 10\u22127 10\u22126 10\u22125\n100\n101\n102\nBER\nSp\nlit\u2212\nTC\nP \nla\nte\nnc\ny \n(s)\nD=20kB\nD=100kB\nD=500kB\nD=2MB\n \nFigure 2. Split-TCP latency vs BER over the satellite link for various transfer sizes (dashed lines correspond to simulations) \na) RTTT = 40ms, BER = 10-5 b) RTTT = 40ms, BER = 10-8 \n0.01 0.02 0.05 0.1 0.2\n101\n102\n103\nLoss probability pT\nSp\nlit\u2212\nTC\nP \nla\nte\nnc\ny \n(s)\nD=20kB\nD=100kB\nD=500kB\nD=2MB\n \n0.01 0.02 0.05 0.1 0.210\n0\n101\n102\n103\nLoss probability pT\nSp\nlit\u2212\nTC\nP \nla\nte\nnc\ny \n(s)\nD=100kB\nD=200kB\nD=1MB\nD=2MB\n \nFigure 3. Split-TCP latency vs. packet loss at the terrestrial network (dashed lines correspond to simulations) \nD=20kB D=100kB D=500kB D=2MB  \n10\u22128 10\u22127 10\u22126 10\u22125\n103\n104\n105\n106\nBER\nM\ned\nia\nn \nof\n b\nuf\nfe\nr o\ncc\nup\nan\ncy\n (b\nyte\ns)\n \n10\u22128 10\u22127 10\u22126 10\u22125\n104\n105\n106\n107\nBER\n90\nth\n p\ner\nce\nnt\nile\n o\nf b\nuf\nfe\nr o\ncc\nup\nan\ncy\n (b\nyte\ns)\na) Median b) 90th percentile \nFigure 4. Statistics of buffer requirements vs BER over the satellite link for RTTT = 200ms and pT = 0 (dashed lines correspond to simulations) \nIEEE Communications Society \/ WCNC 2005 1513 0-7803-8966-2\/05\/$20.00 \u00a9 2005 Crown Copyright\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 15:37:48 UTC from IEEE Xplore.  Restrictions apply. \nTABLE I.  DIFFERENCE BETWEEN SIMULATION AND ANALYTICAL ESTIMATES FOR THE 90TH\/99TH PERCENTILE SOF THE BUFFER REQUIREMENTS AT THE SATELLITE \nGATEWAY NODE AS A PERCENTAGE OF THE SIMULATION ESTIMATES (RTTT = 200MS, PT = 0) \nBER over the satellite link  \n10-8 2x10-8 5x10-8 10-7 2x10-7 5x10-7 10-6 2x10-6 5x10-6 10-5 \n20kB 11.3\/2.9 11.3\/2.9 11.3\/2.9 11.3\/2.9 11.3\/2.9 11.3\/2.9 11.1\/2.9 10.7\/2.9 10\/2.5 7.9\/2.5 Transfer \nsize 2MB 8.2\/2.6 8.3\/2.8 9.8\/4.3 11.4\/6.1 8.2\/6.4 1.2\/2.8 4.6\/4.5 4.7\/4.2 3.6\/3.6 3.1\/2.9 \n \na) RTTT = 40ms, BER = 10-6  b) RTTT = 40ms, BER = 10-5 \n0 1 2 3 40\n1\n2\n3\n4\n5\nx 104\nTime (s)\nBu\nffe\nre\nd \nda\nta\n (b\nyte\ns)\nDT(t) DS(t) \nB(t) \n \n0 2 4 6 8 100\n1\n2\n3\n4\n5\nx 104\nTime (s)\nBu\nffe\nre\nd \nda\nta\n (b\nyte\ns)\nDT(t) \nDS(t) \nB(t) \n \nFigure 5. Cumulative transferred data from the terrestrial, ( )tDT , and the satellite, ( )tDS , components of the split connection and buffer \noccupation, ( )tB , at the intermediate node hosting the proxy \n \nIV. CONCLUSIONS \nWe have presented a model for the latency of the split-TCP \nconnection and the buffer requirements at the intermediate node, \nwhere splitting is deployed. The model draws on an existing \nmodel for TCP latency and inherits its advantages and \ndrawbacks. Therefore, the model can capture the impact of slow-\nstart and various TCP options deployed in the two components of \nthe end-to-end connection. On the other hand, its estimates \nexhibit sensitivity to the (static) value chosen for the \nretransmission timeout. The comparisons of the model estimates \nwith simulation results show good match between the two. \nNotably the model provides a generic systematic approach \nfor the estimation of the latency and buffer requirements related \nto the split connection mechanism. It can be adapted to \naccommodate split connection implementations that deploy \ndifferent transport protocols over the satellite link, as long as \nanalytical models for these protocols are available. Our current \nresearch evolves around this task. \nREFERENCES \n[1] J. Border et al., \u201cPerformance enhancing proxies intended to mitigate link-\nrelated degradations,\u201d Internet RFC 3135, June 2001 \n[2] Y. Zhang, \u201cA Multi-Layer IP Security Protocol for TCP Performance \nEnhancement in Wireless Networks,\u201d IEEE Journal on Selected Areas in \nCommunications, vol. 22, no. 4, pp. 767-776, May 2004 \n[3] H. Balakrishnan, V.N. Padmanabhan, S. Seshan and R.H. Katz, \u201cA \ncomparison of mechanisms for improving TCP performance over wireless \nlink,\u201d IEEE\/ACM Transactions on Networking, December 1997 \n[4] V.G. Bharadwaj, J.S. Baras and N.P. Butts, \u201cAn architecture for Internet \nservice via broadband satellite networks,\u201d International Journal of Satellite \nCommunications, vol. 19, no. 1, pp. 29-50, 2001 \n[5] M. Allman et al., \u201cOngoing TCP research related to satellites,\u201d Internet RFC \n2760, February 2000 \n[6] T. Henderson and R.H. Katz, \u201cSatellite Transport Protocol (STP): An \nSSCOP-based transport protocol for datagram satellite networks,\u201d in Proc. \n2nd International Workshop on Satellite-based Information Services \n(WOSBIS `97), Budapest, Hungary, Oct. 1997 \n[7] T. Henderson, \u201cTransport protocols for Internet-compatible satellite \nnetworks,\u201d IEEE Journal of Selected Areas in Communications, vol. 17, no. \n2, pp. 326-344, Feb. 1999 \n[8] N. Cardwell, S. Savage and T. Anderson, \u201cModelling TCP latency,\u201d in Proc. \nIEEE INFOCOM, Tel-Aviv, Israel, March 2000 \n[9] J. Padhye, V. Firoiu, D. Towsley and J. Kurose, \u201cModelling TCP Reno \nperformance: a simple model and its empirical validation,\u201d ACM Computer \nCommunications Review, vol. 28, no. 4, pp. 303-314, 1998 \n[10] M. Mathis, J. Semke, J. Mahdavi and T. Ott, \u201cThe macroscopic behaviour of \nthe TCP congestion avoidance algorithm,\u201d Computer Communications \nReview, vol. 3, July 1999 \n[11] M. Karaliopoulos, \u201cSupport of elastic TCP traffic over GEO broadband \nsatellite networks\u201d, PhD Thesis, University of Surrey, April 2004 \n[12] K. Fall and K. Varadhan, \u201cSatellite networking in ns,\u201d the ns manual-chapter \n17, February 2002 \n[13] S. Floyd and T. Henderson, \u201cThe NewReno modification to TCP's Fast \nRecovery algorithm,\u201d Internet RFC 2582, April 1999 \n \nIEEE Communications Society \/ WCNC 2005 1514 0-7803-8966-2\/05\/$20.00 \u00a9 2005 Crown Copyright\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 15:37:48 UTC from IEEE Xplore.  Restrictions apply. \n"}
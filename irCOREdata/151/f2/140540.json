{"doi":"10.1016\/j.ejor.2011.03.009","coreId":"140540","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/5780","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/5780","10.1016\/j.ejor.2011.03.009"],"title":"Support vector regression for warranty claim forecasting","authors":["Wu, Shaomin","Akbarov, Artur"],"enrichments":{"references":[{"id":37940841,"title":"A comparison of three strategies for forecasting warranty claims,","authors":[],"date":"1996","doi":null,"raw":"G. S. Wasserman, A. Sudjianto, A comparison of three strategies for forecasting warranty claims, IIE Transactions (Institute of Industrial Engineers) 28 (12) (1996) 967{977.","cites":null},{"id":37940817,"title":"A non-homogeneous Poisson process predictive model for automobile warranty claims,","authors":[],"date":"2007","doi":"10.1016\/j.ress.2005.12.004","raw":"K. Majeske, A non-homogeneous Poisson process predictive model for automobile warranty claims, Reliability Engineering and System Safety 92 (2) (2007) 243{251.","cites":null},{"id":37940854,"title":"A tutorial on support vector regression,","authors":[],"date":"2004","doi":"10.1023\/b:stco.0000035301.49549.88","raw":"A. Smola, B. Scholkopf, A tutorial on support vector regression, Statistics and Computing 14 (3) (2004) 199{222.","cites":null},{"id":37940850,"title":"A useful generalization of renewal theory: Counting process govemed by non-negative markovian increments,","authors":[],"date":"1986","doi":"10.2307\/3214117","raw":"M. Kijima, N. Sumita, A useful generalization of renewal theory: Counting process govemed by non-negative markovian increments, Journal of Applied Probability 23 (1986) 71{88.","cites":null},{"id":37940808,"title":"A warranty forecasting model based on piecewise statistical distributions and stochastic simulation,","authors":[],"date":"2005","doi":"10.1016\/j.ress.2004.07.016","raw":"A. Kleyner, P. Sandborn, A warranty forecasting model based on piecewise statistical distributions and stochastic simulation, Reliability Engineering and System Safety 88 (3) (2005) 207{214.","cites":null},{"id":37940810,"title":"An application of dynamic linear models for predicting warranty claims,","authors":[],"date":"1992","doi":"10.1016\/0360-8352(92)90031-e","raw":"G. S. Wasserman, An application of dynamic linear models for predicting warranty claims, Computers and Industrial Engineering 22 (1) (1992) 37{47.","cites":null},{"id":37940856,"title":"An empirical compartison of machine learning models for time series forecasting,","authors":[],"date":"2010","doi":"10.1080\/07474938.2010.481556","raw":"N. K. Ahmed, A. F. Atiya, N. E. Gayar, H. El-Shishiny, An empirical compartison of machine learning models for time series forecasting, Econometric Reviews 29 (5-6) (2010) 594{621.","cites":null},{"id":37940860,"title":"Application of machine learning techniques for supply chain demand forecasting,","authors":[],"date":"2008","doi":"10.1016\/j.ejor.2006.12.004","raw":"R. Carbonneau, K. Laframboise, R. Vahidov, Application of machine learning techniques for supply chain demand forecasting, European Journal of Operational Research 184 (3) (2008) 1140{1154.","cites":null},{"id":37940815,"title":"Bayesian analysis of discrete time warranty data,","authors":[],"date":"2004","doi":"10.1111\/j.1467-9876.2004.00435.x","raw":"D. Stephens, M. Crowder, Bayesian analysis of discrete time warranty data, Journal of the Royal Statistical Society Series C 53 (1) (2004) 195{217.","cites":null},{"id":37940819,"title":"Finite-horizon prediction of recurrent events, with application to forecasts of warranty claims,","authors":[],"date":"2007","doi":"10.1198\/004017006000000390","raw":"M. Fredette, J. F. Lawless, Finite-horizon prediction of recurrent events, with application to forecasts of warranty claims, Technometrics 49 (1) (2007) 66{80.","cites":null},{"id":37940843,"title":"Forecasting warranty claims, chapter 31, Product Warranty Handbook,","authors":[],"date":"1996","doi":null,"raw":"J. Chen, N. J. Lynn, N. D. Singpurwalla, Forecasting warranty claims, chapter 31, Product Warranty Handbook, Marcel Dekker, 1996, pp. 803{816.","cites":null},{"id":37940811,"title":"Forecasting warranty performance in the presence of the 'maturing data' phenomenon,","authors":[],"date":"2005","doi":"10.1080\/00207720500139930","raw":"B. Rai, N. Singh, Forecasting warranty performance in the presence of the 'maturing data' phenomenon, International Journal of Systems Science 36 (7) (2005) 381{394. 19[11] T. Hrycej, M. Grabert, Warranty cost forecast based on car failure data, in: Proceedings of the International Joint Conference on Neural Networks, IJCNN 2007, Celebrating 20 years of neural networks, Orlando, Florida, USA, August 12-17, 2007, 2007, pp. 108{113.","cites":null},{"id":37940813,"title":"G-renewal process as a model for statistical warranty claim prediction,","authors":[],"date":"2000","doi":"10.1109\/rams.2000.816321","raw":"M. P. Kaminskiy, V. V. Krivtsov, G-renewal process as a model for statistical warranty claim prediction, Proceedings of the Annual Reliability and Maintainability Symposium (2000) 276{280.","cites":null},{"id":37940807,"title":"Methods for the analysis and prediction of warranty claims,","authors":[],"date":"1991","doi":"10.2307\/1268780","raw":"J. D. Kalb eisch, J. F. Lawless, J. A. Robinson, Methods for the analysis and prediction of warranty claims, Technometrics 33 (3) (1991) 273{285.","cites":null},{"id":37940806,"title":"New product warranty: A literature review,","authors":[],"date":"2002","doi":"10.1016\/s0925-5273(02)00153-6","raw":"D. N. P. Murthy, I. Djamaludin, New product warranty: A literature review, International Journal of Production Economics 79 (3) (2002) 231{260.","cites":null},{"id":37940803,"title":"Repairable systems reliability. Modeling, inference, misconceptions and their causes,","authors":[],"date":"1984","doi":"10.2307\/2347868","raw":"H. Ascher, H. Feingold, Repairable systems reliability. Modeling, inference, misconceptions and their causes, Marcel Dekker, New York, 1984.","cites":null},{"id":37940861,"title":"Robust classi and regression using support vector machines,","authors":[],"date":"2006","doi":"10.1016\/j.ejor.2005.07.024","raw":"T. Trafalis, R. Gilbert, Robust classication and regression using support vector machines, European Journal of Operational Research 173 (3) (2006) 893{909.","cites":null},{"id":37940859,"title":"Rough support vector regression,","authors":[],"date":"2010","doi":"10.1016\/j.ejor.2009.10.023","raw":"P. Lingras, C. Butz, Rough support vector regression, European Journal of Operational Research 206 (2) (2010) 445{455.","cites":null},{"id":37940878,"title":"Support vector machine with adaptive parameters in  time series forecasting,","authors":[],"date":"2003","doi":"10.1109\/tnn.2003.820556","raw":"L. Cao, F. Tay, Support vector machine with adaptive parameters in nancial time series forecasting, IEEE Transactions on Neural Networks 14 (6) (2003) 1506{1518.","cites":null},{"id":37940802,"title":"Support vector networks,","authors":[],"date":"1995","doi":"10.1007\/bf00994018","raw":"C. Cortes, V. Vapnik, Support vector networks, Machine Learning, 20 (1995) 273-297.","cites":null},{"id":37940852,"title":"The nature of statistical learning theory,","authors":[],"date":"1995","doi":"10.1007\/978-1-4757-2440-0","raw":"V. Vapnik, The nature of statistical learning theory, Springer, New York, 1995.","cites":null},{"id":37940804,"title":"The rate of failure is the density, not the failure rate,","authors":[],"date":"1988","doi":"10.1007\/springerreference_14178","raw":"W. A. Jr. Thompson, The rate of failure is the density, not the failure rate, The American Statistician, 42 (4) (1988) 288","cites":null},{"id":37940879,"title":"The Simple Genetic Algorithm: Foundations and Theory,","authors":[],"date":"1999","doi":"10.1016\/b978-0-08-094832-4.50010-6","raw":"M. Vose, The Simple Genetic Algorithm: Foundations and Theory, MIT, 1999.","cites":null},{"id":37940847,"title":"Warranty claim analysis considering human factors,","authors":[],"date":"2011","doi":"10.1016\/j.ress.2010.07.010","raw":"S. Wu, Warranty claim analysis considering human factors, Reliability Engineering and System Safety 96 (2011) 131{138.","cites":null},{"id":37940805,"title":"Warranty cost analysis for products with a dormant state,","authors":[],"date":"2007","doi":"10.1016\/j.ejor.2006.09.056","raw":"S. Wu, H. Li, Warranty cost analysis for products with a dormant state, European Journal of Operational Research 182 (3) (2007) 1285{1293.","cites":null},{"id":37940845,"title":"Warranty cost analysis,","authors":[],"date":"1992","doi":"10.1002\/9780470061572.eqr128","raw":"W. Blischke, D. Murphy, Warranty cost analysis, Marcel Dekker, New York, 1992.","cites":null},{"id":37940812,"title":"Warranty problem: its statistical and game theoretic aspects,","authors":[],"date":"1993","doi":"10.1137\/1035002","raw":"N. D. Singpurwalla, S. Wilson, Warranty problem: its statistical and game theoretic aspects, SIAM Review 35 (1) (1993) 17{42.","cites":null},{"id":37940809,"title":"Warranty spend forecasting for subsystem failures in uenced by calendar month seasonality,","authors":[],"date":"2009","doi":"10.1109\/tr.2009.2019673","raw":"B. Rai, Warranty spend forecasting for subsystem failures in uenced by calendar month seasonality, IEEE Transactions on Reliability 48 (4) (2009) 649{657.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-08-16T00:00:00Z","abstract":"Forecasting the number of warranty claims is vitally important for\nmanufacturers\/warranty providers in preparing fiscal plans. In existing\nliterature, a number of techniques such as log-linear Poisson models, Kalman\nfilter, time series models, and artificial neural network models have been\ndeveloped. Nevertheless, one might find two weaknesses existing in these\napproaches: (1) they do not consider the fact that warranty claims reported in\nthe recent months might be more important in forecasting future warranty claims\nthan those reported in the earlier months, and (2) they are developed based on\nrepair rates (i.e, the total number of claims divided by the total number of\nproducts in service), which can cause information loss through such an\narithmetic-mean operation. To overcome the above two weaknesses, this paper\nintroduces two different approaches to forecasting warranty claims: the first is\na weighted support vector regression (SVR) model and the second is a weighted\nSVR-based time series model. These two approaches can be applied to two\nscenarios: when only claim rate data are available and when original claim data\nare available. Two case studies are conducted to validate the two modelling\napproaches. On the basis of model evaluation over six months ahead forecasting,\nthe results show that the proposed models exhibit superior performance compared\nto that of multilayer perceptrons, radial basis function networks and ordinary\nsupport vector regression models","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/140540.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/doi:10.1016\/j.ejor.2011.03.009","pdfHashValue":"13829274b07ece6b0160d3521d4d7cb4ec866731","publisher":"Elsevier Science B.V., Amsterdam.","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/5780<\/identifier><datestamp>2012-01-31T15:01:43Z<\/datestamp><setSpec>hdl_1826_24<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Support vector regression for warranty claim forecasting<\/dc:title><dc:creator>Wu, Shaomin<\/dc:creator><dc:creator>Akbarov, Artur<\/dc:creator><dc:subject>support vector regression, warranty claims, foecasting<\/dc:subject><dc:description>Forecasting the number of warranty claims is vitally important for\nmanufacturers\/warranty providers in preparing fiscal plans. In existing\nliterature, a number of techniques such as log-linear Poisson models, Kalman\nfilter, time series models, and artificial neural network models have been\ndeveloped. Nevertheless, one might find two weaknesses existing in these\napproaches: (1) they do not consider the fact that warranty claims reported in\nthe recent months might be more important in forecasting future warranty claims\nthan those reported in the earlier months, and (2) they are developed based on\nrepair rates (i.e, the total number of claims divided by the total number of\nproducts in service), which can cause information loss through such an\narithmetic-mean operation. To overcome the above two weaknesses, this paper\nintroduces two different approaches to forecasting warranty claims: the first is\na weighted support vector regression (SVR) model and the second is a weighted\nSVR-based time series model. These two approaches can be applied to two\nscenarios: when only claim rate data are available and when original claim data\nare available. Two case studies are conducted to validate the two modelling\napproaches. On the basis of model evaluation over six months ahead forecasting,\nthe results show that the proposed models exhibit superior performance compared\nto that of multilayer perceptrons, radial basis function networks and ordinary\nsupport vector regression models.<\/dc:description><dc:publisher>Elsevier Science B.V., Amsterdam.<\/dc:publisher><dc:date>2011-09-29T16:55:15Z<\/dc:date><dc:date>2011-09-29T16:55:15Z<\/dc:date><dc:date>2011-08-16T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>Shaomin Wu, and Artur Akbarov. Support vector regression for warranty claim forecasting. European Journal of Operational Research. Vol. 213, Issue 1, 16 August 2011, Pages 196-204<\/dc:identifier><dc:identifier>0377-2217<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/doi:10.1016\/j.ejor.2011.03.009<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/5780<\/dc:identifier><dc:language>en_UK<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["0377-2217","issn:0377-2217"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2011,"topics":["support vector regression, warranty claims, foecasting"],"subject":["Article"],"fullText":"Support vector regression for warranty claim\nforecasting\nShaomin Wu 1 , Artur Akbarov\nCranfield University, School of Applied Sciences, Cranfield, Bedfordshire MK43\n0AL, United Kingdom\nAbstract\nForecasting the number of warranty claims is vitally important for manufactur-\ners\/warranty providers in preparing fiscal plans. In existing literature, a number of\ntechniques such as log-linear Poisson models, Kalman filter, time series models, and\nartificial neural network models have been developed. Nevertheless, one might find\ntwo weaknesses existing in these approaches: (1) they do not consider the fact that\nwarranty claims reported in the recent months might be more important in fore-\ncasting future warranty claims than those reported in the earlier months, and (2)\nthey are developed based on repair rates (i.e, the total number of claims divided by\nthe total number of products in service), which can cause information loss through\nsuch an arithmetic-mean operation.\nTo overcome the above two weaknesses, this paper introduces two different ap-\nproaches to forecasting warranty claims: the first is a weighted support vector re-\ngression (SVR) model and the second is a weighted SVR-based time series model.\nThese two approaches can be applied to two scenarios: when only claim rate data\nare available and when original claim data are available. Two case studies are con-\nducted to validate the two modelling approaches. On the basis of model evaluation\nover six months ahead forecasting, the results show that the proposed models ex-\nhibit superior performance compared to that of multilayer perceptrons, radial basis\nfunction networks and ordinary support vector regression models.\nKeywords: support vector regression, radial basis function network, warranty claims,\nneural networks, multilayer perceptron.\n1 Introduction\nA warranty is a contractual obligation incurred by a manufacturer (vendor or seller) in\nconnection with the sale of a product. Nowadays, product warranty becomes increasingly\nmore important in consumer and commercial transactions, and is widely used and serves\n1 Corresponding author: shaomin.wu@cranfield.ac.uk\nmany purposes [4]. The US Congress has enacted several acts (UCC, Magnusson Moss\nAct, Tread Act, etc.) over the last 100 years. The European Union passed legislation\nrequiring a two-year warranty for all products sold in Europe [5].\nForecasting the number of warranty claims is vital for manufacturers\/warranty suppliers\nin preparing fiscal plans. Starting with Kalbfleisch et al. [6], considerable research on\nforecasting warranty claims has been conducted (see [6\u201318], for example).\nIn existing literature, researchers have developed a number of forecasting techniques,\nincluding log-linear Poisson models, Kalman filter, time series models, and artificial neural\nnetwork models such as multilayer perceptron (MLP) and radial basis function network\n(RBFN). Nevertheless, one might find two weaknesses in these approaches: (1) these\nmodelling techniques do not consider the fact that the warranty claims reported in the\nrecent months might be more important in forecasting future warranty claims than those\nreported in the earlier months, and (2) they are developed based on repair rates (i.e,\nthe number of claims divided by the number of products in service), which can cause\ninformation loss through such an arithmetic-mean operation.\nThis paper develops two approaches to overcome the above two weaknesses by using\nweighted support vector regression models to forecast the number of warranty claims.\nThe approaches developed can be used for the following two scenarios: when only claim\nrate data are available and when the original claim data are available. The performance\nof different modelling approaches has been compared on two industrial datasets.\nIn this paper, we will use the terms product and item interchangeably. The paper is struc-\ntured as follows. Section 2 reviews prior work on warranty claim forecasting, and details\nthe problems in warranty claim forecasting. Section 3 describes weighted support vector\nregression models. Section 4 applies the proposed models on two datasets: one is from an\nopen publication [17] and the other is warranty claims data collected from an electronics\nmanufacturer. This section also compares the performance of the modelling techniques\ndiscussed in this paper. Section 5 draws conclusions and suggests further research work.\n2 Problem description and prior work\nThis section first discusses the problem of warranty claim prediction and reviews existing\napproaches to tackle this problem.\n2.1 Acronyms and notation\nTable 1 and Table 2 show the acronyms and the notation used in this paper.\n2\nTable 1\nAcronyms\nANN artificial neural network\nFBNR failed but not reported\nMIS month in service\nMLP multilayer Perceptron\nNHPP non-homogeneous Poisson process\nORP ordinary renewal process\nRBFN radial basis function networks\nRBNF reported but not failed\nSVR support vector regression\ntSVR weighted SVR-based time series model\nwSSE weighted sum squared error\nwSVR weighted support vector regression\n2.2 Warranty claim data\nWe assume that claim data are aggregated on a monthly basis. These data can be ex-\npressed as shown in Table 3, where i (i = 1, 2, ...,m) in the 1st column represents month\nof sale.\nThe question of interest is how to forecast warranty claims xi,n0+1, ..., xi,n0+k for (n0 + 1)-\nth, (n0 + 2)-th, ...,(n0 + k)-th months given that claims data, xi,1, ..., xi,n0 , until the n0-th\nmonth is available.\n2.3 Estimating the number of warranty claims\nForecasting warranty claims, in general terms, is to forecast the expected number of\nclaims within the warranty coverage. The choice of the appropriate model for forecasting\nthe expected number of claims depends on a variety of factors such as: the nature of the\nproduct (repairable vs. non-repairable), warranty coverage scope (full vs. limited), the\nreplacement policy (pro rata vs. free), and warranty dimension (one vs. two dimensional)\n[19].\nAccording to [20], warranty claims might have the following two characteristics:\n\u2022 failed items might not be reported warranty, and\n\u2022 warranty claims might not be due to product failures.\nThe above two factors are especially common in warranty claims of electronics products.\nThese two factors are called FBNR (failed but not reported) and RBNF (reported but not\n3\nTable 2\nNotation\nF (t), R(t) F (t) = 1\u2212R(t), where F (t) is the cumulative distribution function and R(t) is\nthe reliability function of the products of interest\nf(t) = dF (t)dt\nm total number of sales months\nmj mj = m if j \u2264 n\u2212m+ 1, and mj = n+ 1\u2212 j if n\u2212m+ 1 < j \u2264 n, that is, mj is the\nnumber of observations in month j\nNi number of products sold in the ith month\nMij Mi1 = Ni, and Mij = Ni \u2212\n\u2211j\u22121\ni=1 xij for j > 1, that is, Mi,j is the remaining number of\nproducts in the market from sales batch Ni in month j\n\u00b5(t) = F (t) +\n\u222b t\n0 \u00b5(t\u2212 s)f(s)ds, which is the renewal function\nn largest months of products in service\nn0 number of months used for training forecasting models\nN\u02dc =\n\u2211m\ni=1Ni, which is the total number of products sold\nN\u02dcj =\n\u2211mj\ni=1Ni, which is the total number of products aged j\nNri(t1, t2) expected number of warranty claims for the repairable products sold in the i-th month\nwithin time period (t1, t2), for t2 > t1 and t = 1, 2, ...\nNnri(t1, t2) expected number of warranty claims for the non-repairable products sold in the i-th month\nwithin time period (t1, t2), for t2 > t1 and t = 1, 2, ...\np1, p2 positive integers\np(t) probability that a claim is not executed on an item, given that the item fails at time t.\nq(t) probability that a claim is made on an item, given that the item does not fail at time t.\nrj =\n\u2211mj\ni=1 xi,j , which is the total number of claims for products aged j\nhj =\nrj\nN\u02dcj\n, which is the claim rate of the products aged j\nxij number of warranty claims for products aged j and sold in the i-th month,\nwhere i = 1, 2, ...,m, j = 1, ..., n\nyj = (hj\u22121, ..., hj\u2212p1)\nzi,j = (j,Mi,j ,Mi,j\u22121, ...,Mi,j\u2212p2+1)\nfailed) in [20], respectively. Both, the number of warranty claims due to FBNR and RBNF,\naccount for quite a large proportion in the total number of claims [20]. The existence of\nthese two factors makes it difficult to use the reliability function, R(t), in forecasting\nwarranty claims. The following demonstrates the estimation of the number of warranty\nclaims for both repairable and non-repairable items.\n4\nTable 3\nWarranty claims (n \u2265 m)\nSold Sold Months in service (MIS)\nmonth amount 1 2 ... n\u2212m+ 1 n\u2212m+ 2 ... n\u2212 1 n\n1 N1 x11 x12 ... x1,n\u2212m+1 x1,n\u2212m+2 ... x1,n\u22121 x1,n\n2 N2 x21 x22 ... x2,n\u2212m+1 x2,n\u2212m+2 ... x2,n\u22121\n...\n...\n...\n...\n...\n...\n...\n...\nm\u2212 1 Nm\u22121 xm\u22121,1 xm\u22121,2 ... xm\u22121,n\u2212m+1 xm\u22121,n\u2212m+2\nm Nm xm,1 xm,2 ... xm,n\u2212m+1\n2.3.1 Repairable items\nWe assume that a failed item will be returned to the manufacturer and the item can be\nrestored to the same failure rate as it had when it failed (ie., minimal repair). Then within\na given time interval (t1, t2), the expected number of warranty claims for the products\nsold in the i-th month is given by\nNri(t1, t2) = Ni\n\u222b t2\nt1\n(1\u2212 p(v))f(v)\nR(v)\ndv +Ni\n\u222b t2\nt1\nq(v)dv (1)\nIn Eq. (1), the first term represents the number of claims made on a certain proportion of\nfailed products dictated by the probability of raising a claim on a failed product 1\u2212 p(t).\nThis term takes into account only the number of failed products that were reported as\nwarranty claims. Some product failures are not reported as warranty claims due to reasons\nsuch as obsolescence of the product, or new purchase. The second term represents the\nnumber of claims made on products that have not failed. That is, some warranty claims\nare raised due to other reasons than product failure, such as fraudulent claims, claims\nthat can be resolved by giving appropriate instructions on how to operate the products.\nThe repairable items with minimal repair are often modelled using non-homogeneous Pois-\nson process (NHPP). In this case the counting process of the NHPP model is governed\nby its intensity function \u03bb(t). In many applications the parametric form of \u03bb(t) is chosen\nto be the hazard function of a certain probability distribution. The intensity function,\nhowever, is only numerically equivalent to the hazard function, and is conceptually dif-\nferent, see Ascher and Feingold [2] and Thompson [3]. Thus, for the case of NHPP, the\nterm f(v)\/R(v) in Eq. (1) would be replaced by \u03bb(t).\n2.3.2 Non-repairable items\nWe assume that a failed item will be returned to the manufacturer and a new identical item\nwill be returned to the customer. Then within a given time interval (t1, t2), the expected\nnumber of warranty claims for the non-repairable products sold in the i-th month is given\nby\n5\nNnri(t1, t2) =Ni\n(\u222b t2\n0\n(1 + \u00b5(t2 \u2212 v))f(v)(1\u2212 p(v))dv\n\u2212\n\u222b t1\n0\n(1 + \u00b5(t1 \u2212 v))f(v)(1\u2212 p(v))dv\n)\n+Ni\n\u222b t2\nt1\nq(v)dv (2)\nIn Eq. (2), as in the case of Eq.(1), the first term represents the number of claims made on\nsome failed products depending on 1\u2212 p(t), and the second term represents the number\nof claims made on the products that have not failed.\n2.3.3 Comments\nA manufacturer might be able to estimate f(t) based on historical data or expert opinion.\nHowever, estimating customer behaviour functions p(t) and q(t) might be difficult. This\nis especially true for electronics products such as computers, mobile phone, and so on.\nThe users of these products might not be bothered to claim warranty, especially when\nthe failed items have served for quite a long time and\/or they are not expensive. In such\nscenarios, forecasting warranty claims based on f(t) might not be appropriate.\n2.4 Prior work on warranty claims forecasting\n2.4.1 Existing approaches\nThere are a number of approaches developed to forecasting warranty claims. These ap-\nproaches are briefly discussed below.\nLifetime distributions. Kleyner and Sandborn [7] present a warranty claim forecasting\nmodel based on a piecewise application of Weibull and exponential distributions. This\nmodel tries to capture the dynamic characteristic features of failure rates in both early\nfailure period and the intrinsic failure period of the bathtub curve. Rai [8] presents a\nforecasting model incorporating calendar month seasonality, business days per month\nfor authorised service centres, and sales ramp-up.\nStochastic processes. Kalbfleisch and Lawless [6] used a log-linear Poisson model to\nanalyse and forecast warranty claims. In their work, they modelled warranty claims\nbased on the date of warranty claim rather than the failure date, and therefore the\nreporting lag between occurrence of a claim and its entry to a database was taken\ninto consideration. Dynamic linear models with leading indicators are also used in\n[12]. Kaminskiy and Krivtsov [13] develop warranty claim forecasting models with the\nG-renewal process\u2013 generalised renewal processes introduced by Kijima and Sumita\n[21], the ordinary renewal process (ORP) and the non-homogeneous Poisson process\n(NHPP). They found that GRP provides a higher accuracy compared to the ORP or the\nNHPP. Majeske [15] present a NHPP-based technique that forecasts the total number\nof claims and the timing of claims during the vehicle lifetime. Fredette and Lawless\n[16] present forecasting methods for warranty claims using flexible non-homogeneous\nPoisson processes, where possible heterogeneity among the products is modelled using\nrandom effects.\n6\nArtificial neural networks. Wasserman [9] and Wasserman and Sudjianto [17] use neu-\nral network model\u2013MLP (multi-layer perceptron) to build warranty forecasting models.\nRai and Singh [10] use a neural network model\u2013 RBFN (radial basis function network)\u2013\nto forecast warranty claims. Hrycej and Grabert [11] use a neural network model\u2013MLP\n(multi-layer perceptron)\u2013to forecast warranty cost based on individual vehicle variables\n(i.e. age, monthly mileage rate, and road condition index) and the overall manufacturing\nquality fluctuation risk (i.e. different technical groups).\nThe Kalman filter and time series models. Singpurwalla and Wilson [12] consider\nusing the Kalman filter to build forecasting models. Wasserman [9] develop linear re-\ngression models, first-order auto-regression time series models, and also the Kalman\nfilter models to forecast warranty claims. In the linear regression models, the number of\nmonths in service is used to forecast the number of repairs per 1000 items. Wasserman\nand Sudjianto further compare linear regression models, time series models, the Kalman\nfilter, the orthogonal series, and artificial neural networks in modelling and forecasting\nwarranty claims [17]. He concludes that the Kalman filter model offers a significant im-\nprovement over simple linear regression approach, but both the orthogonal series and\nthe neural network models outperform the Kalman filter. In the same year, Chen et al.\n[18] propose to model and forecast the number of warranty claims using the Kalman\nfilter.\n2.4.2 Comments on the approaches reviewed above\nThe existing approaches reviewed in the previous section have the following weaknesses.\n\u2022 When fitting a lifetime probability distribution, one might assume that the warranty\ndata represents the exact number of failed products (see [8], for example). However, such\nan assumption might not hold due to FBNR and\/or RBNF phenomenons, as discussed\nin Section 2.3.\n\u2022 Stochastic process approaches might require rigid assumptions such as the claim rates\nfollowing a specific form (for example the assumption of a power law process for NHPP,\n[12,13,15,16]). Such an assumption might not hold in reality partly due to the reasons\ndiscussed in Section 2.3.\n\u2022 The approaches developed on the basis of repair rates (or claims rates) [7,9,17,18] may\ncause information loss, as they are obtained as a ratio of warranty claims to the number\nof products in service (ie. they integrate two observations into one).\n\u2022 None of the above-reviewed modelling techniques has considered the fact that the war-\nranty claims reported in the recent months might be more important for forecasting\nfuture claims than those reported in the earlier months.\nTo overcome the above weaknesses, we should develop a new approach that (1) employs\noriginal claim data (instead of claim rates\/repair rates), which allows us to use all of the\navailable information; (2) gives more weights to the recent warranty claims as the most\nrecent data can be more useful for predicting future claims; and (3) considers a more\nflexible model structure (to use a nonparametric approach rather than a parametric one).\nTo include all of these three requirements, we propose new warranty claims forecasting\napproaches:\n7\na weighted support vector regression model with original claim data as model input and\noutput variables, and an SVR-based time series model for the case where only claim rate\ndata are available.\n3 Weighted support vector regression\nSupport vector regression (SVR), developed in the context of statistical learning theory,\nis a novel nonparametric methodology for creating regression functions [22]. The aim of\nthe SVR is to optimise generalisation performance. Artificial neural networks (ANN) have\nbeen criticised for their vulnerability to the over-fitting problem\u2013which might result in a\ngood fit when we train a model, but poor prediction ability when we test the model on a\ndifferent test dataset. The SVR, in contrast, has an excellent generalisation performance,\nor prediction ability in the test dataset. Below we present a brief introduction to \u000f support\nvector regression, for a detailed overview of the SVR the reader is referred to [22\u201324] and\nfor the applications of the SVR the reader is referred to [25\u201327].\n3.1 Overview of \u000f-support vector regression\nFor a linear function f :\nf(x) = \u3008w,x\u3009+ b, w \u2208 Rd, b \u2208 R, (3)\nwhere \u3008\u00b7, \u00b7\u3009 represents a dot product, the \u000f-SVR aims to find a function f(x) which has at\nmost \u000f deviation from the actually observed values of y, and at the same time is as flat as\npossible. The latter can be achieved by minimising the norm ||w||2. Such an optimisation\nproblem implicitly assumes the existence of a solution for f . However, this is not always\nthe case, and it is often desired to allow for some errors higher than \u000f. This problem is\nresolved by introducing slack variables, \u03b6j and \u03b6\n\u2217\nj , see Cortes and Vapnik [1] and Smola\n[23]. Thus, the optimisation problem for finding suitable f can be stated as:\nminimise\n1\n2\n||w||2 + C\nl\u2211\nj=1\n(\u03b6j + \u03b6\n\u2217\nj )\nsubject to\n\uf8f1\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f3\nyj \u2212 \u3008w,xj\u3009 \u2212 b \u2264 \u000f+ \u03b6j\n\u3008w,xj\u3009+ b\u2212 yj \u2264 \u000f+ \u03b6\u2217j\n\u03bet, \u03be\n\u2217\nt \u2265 0\n(4)\nwhere l is the number of observations, b is the intercept, yj is the j\nth observation of\nthe dependent variable, xj is the j\nth observation vector of independent variables, \u03b6j and\n\u03b6\u2217j are error terms, and w is the weights vector that needs to be optimised to give the\nminimum of the objective function. The first term of the objective function, is the norm\n||w||2 = \u3008w,w\u3009, the minimum of which insures that the function f is as flat as possible.\nThe second term, C\n\u2211n\nt=1(\u03bet+\u03be\n\u2217\nt ), is known as the regularisation term and insures that the\n8\noptimisation problem posed by Eq. (4) is feasible. The parameter C determines the trade-\noff between the complexity of the model and errors. It is often determined by minimising\nsome error function on a validation dataset or by the means of cross-validation.\nEq. (4) can be restated in terms of the Lagrangian multipliers, which allows the extension\nof the linear f to nonlinear functions and makes it is easier to construct algorithms\nfor solving the optimisation problem. After constructing the Lagrangian and taking the\nderivatives it is possible to arrive at the following reformulation of Eq. (4):\nmaximise\n\uf8f1\uf8f2\uf8f3\u2212\n1\n2\n\u2211n\ni,j=1(\u03b1i \u2212 \u03b1\u2217i )(\u03b1j \u2212 \u03b1\u2217j )\u3008xi, xj\u3009\n\u2212\u000f\u2211nt=1(\u03b1t + \u03b1\u2217t ) +\u2211nt=1 yt(\u03b1t \u2212 \u03b1\u2217t )\nsubject to\nn\u2211\nt=1\n(\u03b1t \u2212 \u03b1\u2217t ) = 0 and \u03b1t, \u03b1\u2217t \u2208 [0, C]\n(5)\nwhere \u03b1 and \u03b1\u2217 are the Lagrangian multipliers of the first two constraints in (4) respec-\ntively. For all data points that lie inside the \u000f-tube, where |f(xt) \u2212 yt| < \u000f the \u03b1i, \u03b1\u2217i\nvanish. That is, we do not need all xi to describe w. The data points whose \u03b1i, \u03b1\n\u2217\ni do not\nvanish are called support vectors. As a result of the Lagrangian expansion, we also have:\nf(x) =\nn\u2211\nt=1\n(\u03b1t \u2212 \u03b1\u2217t )\u3008xt,x\u3009+ b. (6)\nThis is known as the support vector expansion. This expansion shows that the complexity\nof a function\u2019s representation by support vectors is independent of the dimensionality of\nthe input space, and depends only on the number of support vectors. Only for |f(xt\u2212yt| \u2265\n\u000f the Lagrange multipliers maybe nonzero.\nThe complexity of the SVR model depends on the number of support vectors and the\nregularisation constant C. High values of C increase the cost of errors in the training set\nand force a more accurate model for f . Such a model may not generalise well and lead to\noverfitting. Conversely, smaller values of C can lead to much simpler models allowing for\nmore errors and result in underfitting.\nFor nonlinear functions, SVR can be applied in the so-called feature space, where f be-\ncomes linear. This can be done by mapping: \u03a6 : Rd \u2192 zd, where zd is some d dimensional\nfeature space. As can be noted from Eq. (6) the SVR algorithm needs only dot products,\nhence it is sufficient to determine k(xt,x) = \u3008\u03a6(xt),\u03a6(x)\u3009. Thus, we have:\nf(x) =\nn\u2211\nt=1\n(\u03b1t \u2212 \u03b1\u2217t )k(xt,x) + b, (7)\nwhere k(xt,x) is known as the Kernel function.\nPlatt (1998) has proposed an efficient way to solve the optimisation problem posed by Eq.\n(5), known as Sequential Minimal Optimisation (SMO). SMO is a simple algorithm that\nsolves support vector machines (SVM) problems without any matrix storage and without\nusing numerical quadratic programming (QP) optimisation steps. SMO decomposes the\noverall QP problem into QP sub-problems and chooses to solve the smallest possible op-\ntimisation problem at every step. For standard SVM QP problem, the smallest possible\n9\noptimisation problem involves two Lagrangian multipliers. At every step, SMO chooses\ntwo Lagrangian multipliers to jointly optimise, finds the optimal values for these multipli-\ners and updates the SVM to reflect the new optimal values. The advantage of this method\nlies in the fact that solving for two Lagrangian multipliers can be done analytically; thus,\nnumerical QP is avoided altogether.\nBelow we consider two different approaches to building forecasting models: the first one\nis a weighted support vector regression (SVR) model, and the second one is a weighted\nSVR-based time series model.\n3.2 Time series model\nThe time series models are built based on warranty claim rate, h. The model can be\nexpressed as follows:\nhj = g1(hj\u22121, hj\u22122, ..., hj\u2212p1) + ej. (8)\nwhere p1 is the order and ej is the error. Eq. (8) can also be re-written as\nhj = g1(yj) + ej.\nA similar model has been considered by [17] for data from automotive industry, where\nin addition to hj\u22121 the claim rate for the previous year car model was also used as an\nindependent variable.\nWe can use support vector regression modified by Cao and Tay [28], which is called tSVR\n(or weighted SVR-based time series model) hereafter, to build the above time series model.\nThe tSVR aims to find a function g1(\u00b7) which has at most \u000f1 deviation from the actually\nobserved values of h:\ng1(y) = w1\nT\u03c61(y) + b (9)\nwhere b is the intercept, w1 is the weights vector and \u03c61 is a mapping to some feature\nspace. During the estimation process, the explicit mapping to \u03c61 is generally dealt away\nwith by making use of kernels k(yi,yj) = \u03c61(yi)\u03c61(yj), see Smola [23] for more details.\nThe resulting optimisation problem can be stated as follows:\nminimise\n1\n2\n||w1||2 +\nn0\u2211\nj=1\nc1,j(\u03b6j + \u03b6\n\u2217\nj )\nsubject to\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\nhj \u2212w1T\u03c61(yj)\u2212 b \u2264 \u000f1 + \u03b6j\nw1\nT\u03c61(yj) + b\u2212 hj \u2264 \u000f1 + \u03b6\u2217j\n\u03b6j, \u03b6\n\u2217\nj \u2265 0\n(10)\nwhere n0 is the number of observations, hj is the actual warranty claim rate at time j\nand yj = hj\u22121, hj\u22122, ..., hj\u2212p1 . The second term in the optimisation function represents the\nregularisation term. Here, the values of c1,j control the trade off between the complexity\nof the model and the errors \u03b6j and \u03b6\n\u2217\nj . The variable values of c1,j as opposed to constant\n10\nC allow to give different importance for errors depending on their temporal distance. For\nexample, the errors on most recent observations can be given more importance than the\nerrors on earlier observations. The specification of c1,j for all values of j depends on the\nspecific data set and can be determined through cross-validation.\nAlthough model (8) and model (10) have considered the fact that recent claims should have\nmore weights than the older ones, they still use claim rates as dependent and independent\nvariables. Below we introduce a new modelling approach that employs original warranty\nclaims as model\u2019s dependent variable.\nModel (10) can deal with the situation when only claim rates are available, but original\nclaims cannot be obtained.\n3.3 Regression models\nThe regression models are built as following.\nxi,j = g2(j,Mi,j,Mi,j\u22121, ...,Mi,j\u2212p2+1) + ei,j, (11)\nwhere i = 1, 2, ...n, and j = 1, 2, ...,m. Eq. (11) can also be rewritten as\nxi,j = g2(zi,j).\nA weighted SVR (wSVR) can be expressed as follows.\ng2(z) = w2\nT\u03c62(z) + b (12)\nwhere as previously, b is the intercept, w2 is the weights vector and \u03c62 is a mapping to\nsome feature space.\nThe wSVR aims to find a function g2(.) which has at most \u000f2 deviation from the actually\nobserved values of xi,j, and at the same time is as flat as possible. Allowing for some\nerrors higher than \u000f2, \u03bei,j and \u03be\n\u2217\ni,j, the optimisation problem for finding suitable g2(.) can\nbe stated as:\nminimise\n1\n2\n||w2||2 +\nn0\u2211\nj=1\n(\nc2,j\nmj\u2211\ni=1\n(\u03beij + \u03be\n\u2217\nij)\n)\nsubject to\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\nxij \u2212w2T\u03c62(zi,j)\u2212 b \u2264 \u000f2 + \u03beij\nw2\nT\u03c62(zi,j) + b\u2212 xij \u2264 \u000f2 + \u03be\u2217ij\n\u03beij, \u03be\n\u2217\nij \u2265 0\n(13)\nAs in the previous model, the values of c2,j control the trade-off between the complexity\nof the model and errors. Here, however, the errors, \u03bej and \u03be\n\u2217\nj , on the even-aged products\nreceived in different months are assigned the same importance; for example, for a given\nMIS (month in service), the weights are the same, but the weights are different over\ndifferent MIS.\n11\nModel (13) can deal with the situation when the original claims are available.\n3.4 Selection of c1,j and c2,j\nWe borrow the approach introduced by Cao and Tay [28] to search for the optimal values\nof c1,j and c2,j:\ncj = a0\n2\n1 + exp(a1 \u2212 2a1 jn0 )\n(14)\nwhere cj = c1,j for the tSVR, cj = c2,j for the wSVR, a0 and a1 are unknown parameters\nthat need to be estimated empirically. cj is an increasing function with respect to j.\nAscending values of cj allow more errors for distant data points.\n4 Case studies\nThis section aims to compare the performance of several forecasting methods commonly\nused in practice. The comparison is made based on two different datasets, one from the\nprevious study by [17], Table 4, and the other from an electronics manufacturer, Table 5.\n4.1 The datasets\nThe first dataset is shown in Table 4, we refer to this dataset as WS dataset. The time\nin service column in the table is given in terms of months. The prior and current year\nmodel columns represent repair rate per 1000 cars. Wasserman and Sudjianto [17] use\nthis dataset to test a number of algorithms: time series model, Kalman filter and MLP.\nThese models are defined for current year model in terms of time in service and prior year\nmodel.\nThe second dataset is supplied by an electronics manufacturer, whose name will not be\ndisclosed here for the confidentiality reason. The products are a type of internet networking\nequipment. The original dataset has the same format as shown in Table 3 and includes\nthree variables: monthly sales amounts, monthly warranty claims, and months in service\n(MIS). In order to keep the original data confidential, here we present a table of the claim\nrate per MIS of the original data. The claim rate data is presented in Table 5, where\nthe MIS columns show the number of MIS and the h columns show claim rate per 10000\nproducts. The warranty claims data of this dataset has the following properties:\n\u2022 The warranty claims are aggregated on a monthly basis.\n\u2022 The warranty policy of the product is a long-term warranty policy, and it expires when\nthe technological obsolescence has been announced.\n\u2022 The products are repairable. Once a claim is received, the manufacturer will immedi-\nately send out an identical product to the customer as a replacement. The received (or\nclaimed) product will be tested and\/or repaired. The sent-out product can be at any\n12\nTable 4\nWarranty claims data (adopted from [17]). Time in service is given in terms of months, and prior\nand current year data are given in terms of repair rate per 1000 cars.\nTime in Prior Current Time in Prior Current Time in Prior Current\nservice model year model year service model year model year service model year model year\n1 0.55 1.27 13 78.2 53.3 25 167 172\n2 4.68 1.58 14 84.0 61.8 26 173 186\n3 9.88 1.58 15 84.7 75.9 27 179 199\n4 12.8 7.71 16 89.0 90.8 28 185 211\n5 15.5 11.4 17 97.8 102 29 187 228\n6 20.0 18.7 18 110 105 30 189 249\n7 25.9 26.3 19 125 113 31 196 271\n8 33.1 35.4 20 139 125 32 205 290\n9 37.5 42.0 20 139 125 33 211 300\n10 45.4 46.4 22 158 139 34 213 328\n11 56.4 48.2 23 163 159 35 215 375\n12 68.9 48.8 24 166 165 36 221 430\nage: it can be new, or can be old. Due to this age uncertainty, it is difficult to estimate\nthe number of claims\/failures within a specific time period with conventionally used\nstatistical methods such as the renewal process or NHPP.\nTable 5\nWarranty claims data from an electronics manufacturer. MIS is given in terms of months, and\nh is given in terms of warranty claim rate per 10000 items.\nMIS h MIS h MIS h MIS h MIS h\n1 3.89 8 21.08 15 20.20 22 17.84 29 14.43\n2 9.42 9 22.69 16 19.98 23 17.46 30 19.12\n3 14.23 10 20.23 17 20.05 24 14.70 31 17.92\n4 17.41 11 23.07 18 16.68 25 14.68 32 23.39\n5 20.71 12 21.94 19 17.36 26 18.29 33 17.28\n6 21.87 13 19.79 20 16.56 27 18.51 34 41.91\n7 22.61 14 18.25 21 18.58 28 19.71\n4.2 Alternative modelling methods and performance measure\nWe apply the following five modelling methods: MLP, RBFN, SVR, tSVR, and wSVR on\nthe above two datasets. We code our computational programs with Java and borrow some\nfunctions from two data mining packages, Weka 2 and LIBSVM 3 . Each modelling method\n2 http:\/\/www.cs.waikato.ac.nz\/ml\/weka\/, accessed on 01 October 2010\n3 http:\/\/www.csie.ntu.edu.tw\/ cjlin\/libsvm\/, accessed on 01 October 2010\n13\nhas its own set of hyper-parameters that need to be specified by users. Below we briefly\ndescribe what hyper-parameters have been used for each of the forecasting methods.\n4.2.1 Modelling methods used for comparison\nRadial basis function network (RBFN). The RBFN used here has the following three\nhyper-parameters: (1) the number of Gaussian radial basis functions (GRBF) for the\nK-means algorithm to generate, (2) the minimum of standard deviation (MSD) for the\nGRBFs, and (3) the ridge value (R) for linear regression that is used for combining the\noutputs of GRBFs.\nMultilayer perceptron (MLP). The MLP used in this experiment is a network with a single\nhidden layer that uses the backpropogation algorithm to find its optimal parameters.\nThe hyper-parameters of this network are: (1) the number of hidden nodes in the hidden\nlayer (NHN), which controls the complexity of the network, (2) the learning rate (LR),\nfor determining the step size for the optimisation problem, and (3) the momentum (M),\nwhich is used to control convergence.\nSupport vector regression(SVR). The SVR has the following three main hyper-parameters:\n(1) the constant C which determines the trade-off between the complexity of the model\nand tolerance of errors, (2) \u000f\u2013which specifies the margins for negligible errors, and (3)\n\u03b3\u2013the parameter of the RBF kernel for the case of SVR with RBF kernel.\nWeighted SVR-based time series model (tSVR). In the case of tSVR, instead of C, as used\nin the above SVR, we use an adaptive C(\u00b7) (as shown in Eq. (14)). Thus, in addition\nto optimising the values of a0 and a1 in Eq. (14), we also need to optimise the values\nof \u000f and \u03b3.\nWeighted support vector regression. In the case of wSVR, it has the same hyper-parameters\nas those of tSVR.\nTo search for the optimal hyper-parameters of the above models, we use genetic algo-\nrithms (GA), which are adaptive search and optimisation algorithms that are based on\nthe principles of natural evolution theory. The reader is referred to [29] for an introduction\nto GA.\nThe following GA parameter settings are used for estimating the hype-parameters of\nthe forecasting methods. The crossover is implemented using a single point crossover,\nwhere for a pair of chromosomes a gene is selected randomly and swapped including all\nof the subsequent genes between the two chromosomes. The crossover rate is set to 35%\nof the population size. The mutation rate is set to 8.3%. The population size is kept\nfixed throughout the consecutive evolutions. 90% of the original population is selected\nfor the next generation with the addition of duplicate chromosomes. A typical population\nsize used for the experiments below is 75 with 50 population evolutions. The GA is\nimplemented based on Java open source component JGAP - Java Genetic Algorithms\nPackage 4 .\n4 http:\/\/jgap.sourceforge.net\/, accessed on 01 October 2010\n14\n4.2.2 Performance measure\nTo evaluate model performance, we conduct six months ahead forecasting in this paper.\nIn order to compare the performance of different forecasting methods on the data, we use\nthe following metrics to measure the performance of a model:\nMSE: For the time series model for WS dataset, we use the following mean squared error\n(MSE) as a performance metric.\nMSE =\n1\n6\nn0+6\u2211\nj=n0+1\n(hj \u2212 h\u02c6j)2 (15)\nwhere h\u02c6j is a claim rate estimated by a model. For example, if p1 = 1 in Eq. (8), then\nh\u02c6j, for j = n0 + k and k = 1, 2...6, can be obtained with the following rule:\nh\u02c6n0+k =\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3 g1(hn0) for k = 1g1(h\u02c6n0+k\u22121) for 2 \u2264 k \u2264 6 (16)\nwSSE: For the regression models, we use the following weighted sum squared error\n(wSSE) to measure model performance:\nwSSE =\nn0+6\u2211\nj=n0+1\nmj\u2211\ni=1\n(xi,j \u2212 x\u02c6i,j)2\nMi,j\n(17)\nwhere x\u02c6i,j is the number of claims estimated by a model. For example, if p2 = 1 in Eq.\n(11), then x\u02c6i,j, for j = n0 + k and k = 1, 2...6, can be obtained with the following rule:\nx\u02c6i,n0+k =\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3 g2(j,Mi,n0+k) for k = 1g2(j, M\u02c6i,n0+k) for 2 \u2264 k \u2264 6, (18)\nwhere M\u02c6i,n0+k = M\u02c6i,n0+k\u22121 \u2212 x\u02c6i,n0+k\u22121 and M\u02c6i,n0+1 = Mi,n0 \u2212 xi,n0 .\nFor the dataset shown in Table 4, following [17], we use the data of the first 30 months\nas the training dataset and the data from 31st to 36th months as the validation dataset.\nThe hyperparameters of a given forecasting method are selected from the model with the\nsmallest MSE over the validation dataset based on six months ahead forecasting using\nEq. (15). The results of estimated MSEs are presented in Table 6.\nFor the dataset shown in Table 5, we divide the dataset into three sets: the training\ndataset, the validation dataset, and the test dataset. The training dataset contains the\ndata including the first 22 MIS, the validation dataset includes claims with MIS between 23\nand 28, and test dataset contain claims with MIS between 29 and 34. The hyperparameters\nof the forecasting methods are optimised to yield the smallest MSE for the models with\nclaim rates as dependent variables (or the time series models) and the smallest wSSE for\nthe models with original claims as dependent variables (or the regression models) over\nthe validation dataset. After the optimal hyperparameters have been selected, we merge\n15\nthe training dataset and the validation dataset to create a new training dataset. We then\ntrain a new model with the optimal hyperparameters on the new training dataset. The\npredictions are made based on Eq. (16) and Eq. (18) accordingly. In order to compare the\ntime series models against the regression models, we convert the predicted rate values, h\u02c6j,\ninto the original data format, x\u02c6i,j, and evaluate the prediction performance on the test\ndataset based on Eq. (17). This is due to fact that in practise, we are mainly interested\nin predicting the actual warranty claims data rather than the rates. Therefore, evaluation\nof the prediction performance based on wSSE for both time series and regression models\nseems to be appropriate. This is not possible to implement on the WS dataset as the\noriginal warranty claims data is not publicly available.\nSince the GA might reach a local minimum, we repeat the evaluation experiment for each\nmodel 30 times. The results of these experiments are then compared using the t-test. The\nprediction performance (i.e. the values of MSE and wSSE) of different forecasting models\n(i.e. MLP, RBFN, SVR, tSVR and wSVR) are shown in Table 7, and Table 9.\n4.3 Results on the WS dataset\nTable 6 shows the values of MSE for each forecasting model. It is clear from this table that\nSVR and tSVR methods improve significantly on the results obtained by [17], where the\nbest result was obtained by using a two-node neural network with error on the validation\nset being MSE = 78.18. For SVR and tSVR, both MSEs for the training dataset and the\nvalidation set are lower than those obtained by [17]. It can been seen that between SVR\nand tSVR, tSVR performs slightly better than SVR.\nTable 6\nMean squared error over training and validation dataset for WS dataset.\nForecasting method Hyper-parameters MSE on training dataset MSE on validation set\nRBFN GRBF=6, MSD=2.3768, R=0.0111 20.82 85.68\nMLP NHN=10, LR=0.7351, M=0.6972 223.25 77.17\nSVR C=904.109, \u000f=6.2478, \u03b3=0.03838 16.61 74.11\ntSVR a0=752.818, a1=9.3178, \u000f=5.9305, \u03b3=0.0215 14.74 71.62\n4.4 Results on the industrial dataset\nThe experiments for the claim data shown in Table 5 were conducted using the following\nsearch bounds for the hyperparameters of the forecasting methods. For MLP, we have,\nNHN = {1,2,3,4}, LR \u2208 [0.2, 0.8], and M is set to a fixed value as the number of iterations\nis sufficiently large, 500, M = 0.2. For RBFN, we have, GRBF = {1,2,3,4}, R \u2208 [0, 1] and\nMSD = 0.1. For SVR, we have C \u2208 [1, 1000], \u000f \u2208 [0, 1], and \u03b3 is set to a fixed value of one\nover the number of attributes. For the wSVR method, we have b \u2208 [1, 1000], a \u2208 [0, 10]\nand \u000f and \u03b3 are set to the same values as in the case of SVR. Here, we present the results\nfor models with p1 = 1 and p2 = 1.\n16\n4.4.1 Time series models\nTable 7 shows the means of wSSE values (and their standard deviations in the brackets)\non validation datasets and test datasets. T-test for sample means with unequal variances\nare also carried out for comparing the performance of different models, as shown in Table\n8. We can find that, on validation datasets, MLP outperforms both RBF and SVR, and\ntSVR outperforms all of the other three approaches. tSVR also outperforms all of the\nother three approaches on test datasets.\nTable 7\nMeans (standard deviations) of the performance of the four time series models on the industrial\ndataset.\nDataset MLP RBF SVR tSVR\nvalidation dataset 0.9264(8.23E-08) 0.9532(2.04E-31) 0.9286(4.34E-07) 0.9178(8.28E-07)\ntest dataset 0.9871(6.4E-05) 0.9508(0.00) 0.9545(6.9E-06) 0.9487(1.75E-07)\nTable 8\nComparison of the four time series models on the industrial dataset: t-values.\nDataset MLP vs. MLP vs. MLP vs. RBF vs. RBF vs. SVR vs.\nRBF SVR tSVR SVR tSVR tSVR\nvalidation dataset -511.61 -16.48 49.46 204.73 213.13 52.54\ntest dataset 24.87 21.18 26.22 -7.84 26.58 12.14\n4.4.2 Regression models\nTable 9 shows the means of wSSE values (and their standard deviations in the brackets)\non validation datasets and test datasets and Table 10 shows the results of T-tests carried\nout for comparing the performance of the four regression models. We can see that wSVR\noutperforms all of the other methods on both validation and test datasets.\nTable 9\nMeans (standard deviations) of the outcomes of the four regression models on the industrial\ndataset.\nDataset MLP RBF SVR wSVR\nvalidation dataset 0.5874(2.37E-05) 0.5898(2.37E-05) 0.5726(1.18E-6) 0.5678(7.57E-07)\ntest dataset 0.7858(0.004) 0.5417(2.22E-12) 0.5215(1.21E-05) 0.5186(3.02E-06)\nTable 10\nComparison of the four regression models on the industrial dataset: t-values.\nDataset MLP vs. MLP vs. MLP vs. RBF vs. RBF vs. SVR vs.\nRBF SVR wSVR SVR wSVR wSVR\nvalidation dataset -2.69 16.30 21.78 86.89 138.83 18.96\ntest dataset 21.01 22.72 22.30 31.79 72.86 4.09\n17\n4.4.3 Comparison of the prediction performance between the forecasting models\nIt is interesting and important to compare the performance of the time series models and\nthe regression models, based on which we can select the optimally performed model. We\nplot box-plots of the distributions of the wSSE from both the time series models and\nthe regression models on the industrial dataset in Figure 1. Then, on both validation\ndatasets (see Figure 1(a)) and test datasets (see Figure 1(b)), we can see the prediction\nperformance of the regression models outperform that of the times series models. This\nimplies that the prediction performance of the models with original warranty claims as\nmodel\u2019s dependent variables outperform that of those models with claim rates\/repair rates\nas model\u2019s dependent variables.\nFrom these figures, we can also see that the MLP regression models perform similarly\nto the other models on the validation datasets, but have poor prediction ability on test\ndatasets.\n(a) Comparison on validation dataset (b) Comparison on test dataset\nFig. 1. Comparison between forecasting models 1 and 2. (The labels ended with (1) are time\nseries models, and those labels ended with (2) are regression models.)\n5 Conclusions\nThis paper has introduced two new approaches to forecasting warranty claims. We have\nalso compared the performance of five modelling techniques, namely, multilayer percep-\ntrons (MLP), radial basis function networks (RBFN), support vector regressions (SVR),\nweighted SVR-based time series models (tSVR), and weighted SVR regression models\n(wSVR), on two warranty claim datasets. The main findings of this paper, based on the\ntwo warranty claim data collected from two different industries, are\n\u2022 the prediction performance of the weighted SVR-based time series models outperform\nthat of MLP, RBFN and SVR;\n\u2022 the prediction performance of the weighted SVR regression models outperform that of\nMLP, RBFN and SVR;\n18\n\u2022 the prediction performance of the models with original warranty claims as model\u2019s\ndependent variables outperforms that of the models with claim rates\/repair rates as\nmodel\u2019s dependent variables.\n\u2022 the main reason why the weighted methods have better prediction accuracy is that the\nmost recent data is given more weights than earlier data.\nThis paper has only considered the problem of six-month ahead forecasting for warranty\nclaims. From a perspective of warranty suppliers\/manufacturers, long-term forecasting\n(such as 24 months, 36 months, even longer) of warranty claims is vitally important in\ntheir fiscal plans. Our future research will focus on long-term forecasting for warranty\nclaims.\nAcknowledgement\nThis research is supported by Engineering and Physical Sciences Research Council (EP-\nSRC) of the United Kingdom.\nReferences\n[1] C. Cortes, V. Vapnik, Support vector networks, Machine Learning, 20 (1995) 273-297.\n[2] H. Ascher, H. Feingold, Repairable systems reliability. Modeling, inference, misconceptions\nand their causes, Marcel Dekker, New York, 1984.\n[3] W. A. Jr. Thompson, The rate of failure is the density, not the failure rate, The American\nStatistician, 42 (4) (1988) 288\n[4] S. Wu, H. Li, Warranty cost analysis for products with a dormant state, European Journal\nof Operational Research 182 (3) (2007) 1285\u20131293.\n[5] D. N. P. Murthy, I. Djamaludin, New product warranty: A literature review, International\nJournal of Production Economics 79 (3) (2002) 231\u2013260.\n[6] J. D. Kalbfleisch, J. F. Lawless, J. A. Robinson, Methods for the analysis and prediction of\nwarranty claims, Technometrics 33 (3) (1991) 273\u2013285.\n[7] A. Kleyner, P. Sandborn, A warranty forecasting model based on piecewise statistical\ndistributions and stochastic simulation, Reliability Engineering and System Safety 88 (3)\n(2005) 207\u2013214.\n[8] B. Rai, Warranty spend forecasting for subsystem failures influenced by calendar month\nseasonality, IEEE Transactions on Reliability 48 (4) (2009) 649\u2013657.\n[9] G. S. Wasserman, An application of dynamic linear models for predicting warranty claims,\nComputers and Industrial Engineering 22 (1) (1992) 37\u201347.\n[10] B. Rai, N. Singh, Forecasting warranty performance in the presence of the \u2019maturing data\u2019\nphenomenon, International Journal of Systems Science 36 (7) (2005) 381\u2013394.\n19\n[11] T. Hrycej, M. Grabert, Warranty cost forecast based on car failure data, in: Proceedings of\nthe International Joint Conference on Neural Networks, IJCNN 2007, Celebrating 20 years\nof neural networks, Orlando, Florida, USA, August 12-17, 2007, 2007, pp. 108\u2013113.\n[12] N. D. Singpurwalla, S. Wilson, Warranty problem: its statistical and game theoretic aspects,\nSIAM Review 35 (1) (1993) 17\u201342.\n[13] M. P. Kaminskiy, V. V. Krivtsov, G-renewal process as a model for statistical warranty\nclaim prediction, Proceedings of the Annual Reliability and Maintainability Symposium\n(2000) 276\u2013280.\n[14] D. Stephens, M. Crowder, Bayesian analysis of discrete time warranty data, Journal of the\nRoyal Statistical Society Series C 53 (1) (2004) 195\u2013217.\n[15] K. Majeske, A non-homogeneous Poisson process predictive model for automobile warranty\nclaims, Reliability Engineering and System Safety 92 (2) (2007) 243\u2013251.\n[16] M. Fredette, J. F. Lawless, Finite-horizon prediction of recurrent events, with application\nto forecasts of warranty claims, Technometrics 49 (1) (2007) 66\u201380.\n[17] G. S. Wasserman, A. Sudjianto, A comparison of three strategies for forecasting warranty\nclaims, IIE Transactions (Institute of Industrial Engineers) 28 (12) (1996) 967\u2013977.\n[18] J. Chen, N. J. Lynn, N. D. Singpurwalla, Forecasting warranty claims, chapter 31, Product\nWarranty Handbook, Marcel Dekker, 1996, pp. 803\u2013816.\n[19] W. Blischke, D. Murphy, Warranty cost analysis, Marcel Dekker, New York, 1992.\n[20] S. Wu, Warranty claim analysis considering human factors, Reliability Engineering and\nSystem Safety 96 (2011) 131\u2013138.\n[21] M. Kijima, N. Sumita, A useful generalization of renewal theory: Counting process govemed\nby non-negative markovian increments, Journal of Applied Probability 23 (1986) 71\u201388.\n[22] V. Vapnik, The nature of statistical learning theory, Springer, New York, 1995.\n[23] A. Smola, B. Scholkopf, A tutorial on support vector regression, Statistics and Computing\n14 (3) (2004) 199\u2013222.\n[24] N. K. Ahmed, A. F. Atiya, N. E. Gayar, H. El-Shishiny, An empirical compartison of machine\nlearning models for time series forecasting, Econometric Reviews 29 (5-6) (2010) 594\u2013621.\n[25] P. Lingras, C. Butz, Rough support vector regression, European Journal of Operational\nResearch 206 (2) (2010) 445\u2013455.\n[26] R. Carbonneau, K. Laframboise, R. Vahidov, Application of machine learning techniques for\nsupply chain demand forecasting, European Journal of Operational Research 184 (3) (2008)\n1140\u20131154.\n[27] T. Trafalis, R. Gilbert, Robust classification and regression using support vector machines,\nEuropean Journal of Operational Research 173 (3) (2006) 893\u2013909.\n[28] L. Cao, F. Tay, Support vector machine with adaptive parameters in financial time series\nforecasting, IEEE Transactions on Neural Networks 14 (6) (2003) 1506\u20131518.\n[29] M. Vose, The Simple Genetic Algorithm: Foundations and Theory, MIT, 1999.\n20\n"}
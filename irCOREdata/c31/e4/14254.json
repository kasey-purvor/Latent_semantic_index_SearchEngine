{"doi":"10.1080\/0968776000080304","coreId":"14254","oai":"oai:generic.eprints.org:339\/core5","identifiers":["oai:generic.eprints.org:339\/core5","10.1080\/0968776000080304"],"title":"The evaluation of the national learning network","authors":["Caven\u2010Atack, Andrew S."],"enrichments":{"references":[{"id":1043043,"title":"1999a), Networking Lifelong Learning: Making IT Happen,","authors":[],"date":null,"doi":null,"raw":"FEFC (October 1999a), Networking Lifelong Learning: Making IT Happen, Coventry: FEFC.","cites":null},{"id":1043044,"title":"1999b), Benchmarking Data 1995-96 to 1997-98: Retention and Achievement Rates","authors":[],"date":null,"doi":null,"raw":"FEFC (September 1999b), Benchmarking Data 1995-96 to 1997-98: Retention and Achievement Rates in Further Education Colleges in England, Coventry: FEFC.","cites":null},{"id":1043045,"title":"1999c), Networking Lifelong Learning: An ILT Development Strategy for FE,","authors":[],"date":null,"doi":null,"raw":"FEFC (April 1999c), Networking Lifelong Learning: An ILT Development Strategy for FE, Coventry: FEFC.","cites":null},{"id":1043046,"title":"1999d), Networking Lifelong Learning: High-level Action Plan (HLAP),","authors":[],"date":null,"doi":null,"raw":"FEFC (June 1999d), Networking Lifelong Learning: High-level Action Plan (HLAP), Coventry: FEFC.","cites":null},{"id":1043041,"title":"Making IT Happen:","authors":[],"date":"2000","doi":"10.1201\/9781420025668","raw":"FEDA (January 2000), Making IT Happen: The First Report on the Efficiency and Effectiveness of ILT Investment in Further Education, London: FEDA.","cites":null},{"id":1043047,"title":"Networking Lifelong Learning: Making IT Happen: Evaluation Strategy, London:","authors":[],"date":"1999","doi":null,"raw":"FE ILT Committee (December 1999), Networking Lifelong Learning: Making IT Happen: Evaluation Strategy, London: FE ILT Committee.","cites":null},{"id":1043048,"title":"The Evaluation Cookbook,","authors":[],"date":"1998","doi":"10.1093\/fampra\/15.1.76","raw":"Harvey, J. (ed.) (1998), The Evaluation Cookbook, Edinburgh: LTDI.","cites":null},{"id":198755,"title":"Towards a new cost-aware evaluation framework',","authors":[],"date":"2000","doi":null,"raw":"Ash, C. (2000), 'Towards a new cost-aware evaluation framework', Educational Technology and Society, 3 (4), http:\/\/ifets.ieee.org\/periodical\/vol_4_2000\/v_4_2000.html.","cites":null},{"id":1043049,"title":"Utilization Focused Evaluation - New Century Text,","authors":[],"date":"1997","doi":"10.1016\/s1098-2140(99)80122-2","raw":"Patton, M. Q. (1997), Utilization Focused Evaluation - New Century Text, California: Sage Publications.","cites":null},{"id":1043042,"title":"Widening Participation in Further Education: Statistical Evidence 1996-97,","authors":[],"date":null,"doi":null,"raw":"FEFC (undated), Widening Participation in Further Education: Statistical Evidence 1996-97, Coventry: FEFC, http:\/\/www.fefcac.uk\/documents\/othercouncilpublications\/ other_pdf\/wp_se.pdf.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2000","abstract":"In December 1998, the Department for Education and Employment announced that \u00a374 million would be made available, over a three\u2010year period, to fund improvements in information and learning technology within English further education: this initiative is known as the National Learning Network. An evaluation team has been appointed to report on whether the investment is being used nationally and locally in an efficient and effective manner. This paper outlines the process by which this task is being fulfilled and how the impact of the investment is being evaluated through the close monitoring of forty\u2010one representative English FE colleges. It also presents a range of free\u2010standing evaluation tools which have been developed by the evaluation team for use within these colleges by internal practitioner\u2010evaluators. These tools will enable colleges to assess the effectiveness of the investment and enable the evaluation team to monitor the impact of the national investment on a small, representative cohort of students and staff over a two\u2010year period The paper concludes with a brief look at the role this development is playing in designing a universally applicable model for assessing cost\u2010effectiveness across all educational sectors","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/14254.pdf","fullTextIdentifier":"http:\/\/repository.alt.ac.uk\/339\/1\/ALT_J_Vol8_No3_2000_The%20evaluation%20of%20the%20national.pdf","pdfHashValue":"e6a2933ff627494fb80f785aaf02dd614b43046c","publisher":"University of Wales Press","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:generic.eprints.org:339<\/identifier><datestamp>\n      2011-04-04T09:14:41Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D4C:4C42<\/setSpec><setSpec>\n      7375626A656374733D4C:4C43:4C4331303232<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/repository.alt.ac.uk\/339\/<\/dc:relation><dc:title>\n        The evaluation of the national learning network<\/dc:title><dc:creator>\n        Caven\u2010Atack, Andrew S.<\/dc:creator><dc:subject>\n        LB Theory and practice of education<\/dc:subject><dc:subject>\n        LC1022 - 1022.25 Computer-assisted Education<\/dc:subject><dc:description>\n        In December 1998, the Department for Education and Employment announced that \u00a374 million would be made available, over a three\u2010year period, to fund improvements in information and learning technology within English further education: this initiative is known as the National Learning Network. An evaluation team has been appointed to report on whether the investment is being used nationally and locally in an efficient and effective manner. This paper outlines the process by which this task is being fulfilled and how the impact of the investment is being evaluated through the close monitoring of forty\u2010one representative English FE colleges. It also presents a range of free\u2010standing evaluation tools which have been developed by the evaluation team for use within these colleges by internal practitioner\u2010evaluators. These tools will enable colleges to assess the effectiveness of the investment and enable the evaluation team to monitor the impact of the national investment on a small, representative cohort of students and staff over a two\u2010year period The paper concludes with a brief look at the role this development is playing in designing a universally applicable model for assessing cost\u2010effectiveness across all educational sectors.<\/dc:description><dc:publisher>\n        University of Wales Press<\/dc:publisher><dc:date>\n        2000<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:rights>\n        cc_by_nc_nd<\/dc:rights><dc:identifier>\n        http:\/\/repository.alt.ac.uk\/339\/1\/ALT_J_Vol8_No3_2000_The%20evaluation%20of%20the%20national.pdf<\/dc:identifier><dc:identifier>\n          Caven\u2010Atack, Andrew S.  (2000) The evaluation of the national learning network.  Association for Learning Technology Journal, 8 (3).  pp. 21-30.  ISSN 0968-7769     <\/dc:identifier><dc:relation>\n        10.1080\/0968776000080304<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/repository.alt.ac.uk\/339\/","10.1080\/0968776000080304"],"year":2000,"topics":["LB Theory and practice of education","LC1022 - 1022.25 Computer-assisted Education"],"subject":["Article","PeerReviewed"],"fullText":"The evaluation of the\nNational Learning Network\nAndrew S.Thomas Caven-Atack\nSchool of Computing and Management Sciences, Sheffield Hallam University\nemail: a.caven-atack@shu.ac.uk\nIn December 1998, the Department for Education and Employment announced that \u00a374\nmillion would be made available, over a three-year period, to fund improvements in\ninformation and learning technology within English further education: this initiative is\nknown as the National Learning Network. An evaluation team has been appointed to\nreport on whether the investment is being used nationally and locally in an efficient and\neffective manner. This paper outlines the process by which this task is being fulfilled and\nhow the impact of the investment is being evaluated through the close monitoring of\nforty-one representative English FE colleges. It also presents a range of free-standing\nevaluation tools which have been developed by the evaluation team for use within these\ncolleges by internal practitioner-evaluators. These tools will enable colleges to assess the\neffectiveness of the investment and enable the evaluation team to monitor the impact of\nthe national investment on a small, representative cohort of students and staff over a two-\nyear period The paper concludes with a brief look at the role this development is playing\nin designing a universally applicable model for assessing cost-effectiveness across all\neducational sectors.\nIntroduction\nThe National Learning Network (NLN) is part of a response to the expectation that the\nfurther education (FE) sector within England will grow steadily over the next three years to\nfulfil the Department for Employment and Education's requirement to widen participation\nin this area of education. The NLN is just one of the initiatives aimed at (though not\nexclusive to) new students from non-traditional, disadvantaged and previously excluded\ngroups, and is expected to bring the student population in FE to over four million. The\nFurther Education Funding Council (FEFC) has noted that traditional FE learning\nparadigms are not suitable for this level of participation and that increased levels of\n21\nAndrew S.Thomas Caven-Atack The evaluation of the National Learning Network\ninformation and learning technology (ILT) will need to be implemented to cope with these\nincreased student numbers.\nBecause ILT is characterized by higher initial, fixed costs than traditional teaching and\nlearning methods but has the advantage of lower variable running costs (Vries and\nHertogenbosch, 1999), the majority of any ILT investment will be spent on initial fixed\ncosts. Once these initial costs have been met, ILT should have a lower cost per student\nlearning hour than traditional teaching and learning - providing the proper infrastructure\nhas been put in place. This emphasis on initial fixed costs leads to a greater need for careful\nplanning and implementation of the initial investment in ILT.\nThe National Learning Network\nIn December 1998, the Department for Education and Employment (DfEE) announced\nthat \u00a374 million would be made available, over a three-year period, to fund information\ntechnology (IT) infrastructure changes within English FE (FEFC, 1999a). This investment\nis expected to stimulate change mostly in the three main FEFC focus areas of widening\nparticipation, retention and achievement (FEFC, 1999b; FEFC, undated). On a smaller\nscale, this investment is expected to improve the quality of both the learning experience\nand the teaching experience, for both students and staff. The funding is expected to ensure\nthat all colleges are suitably equipped to cater for both the expected increases in the student\npopulation and the changing demands of educating these students for the information\nsociety: 'If all staff and students engage IT as a normal everyday tool for teaching and\nlearning activities, information literacy will be a natural by-product' (FEFC, 1999c).\nAccording to the FEFC, the English FE sector currently spends around \u00a3100 million per\nannum on ILT (FEFC, 1999d). The High Level Action Plan (HLAP) assumes that ILT\nexpenditure by colleges will continue at this level and that the extra funding from the NLN\nwill provide 'additionality' (ibid.).\nAlthough the FE sector already invests heavily in IT, the most recent British Educational\nCommunications and Technology agency (Becta) survey indicates that a considerable\namount of this provision is out of date and incapable of meeting the current demand from\nstudents in terms of both hardware and software (Becta, 1999). Prior to the NLN, there\nhas not been a national programme in FE to parallel higher education's Teaching and\nLearning Technology Programme (TLTP), which has invested some \u00a350 million in learning\ncontent creation and related support activities since 1992 (FEFC, 1999c). However, a\nnumber of initiatives for the promotion of ILT in FE have been funded and, on the whole,\nhave proved very successful. For example, the FEFC allocated \u00a31.9 million over five years,\nstarting in 1996, to fund Quality in Information and Learning Technology (QUILT), a\nprogramme of staff development for ILT use (see: http:\/\/www.feda.ac.uk\/quilt\/). In\naddition, \u00a30.575 million was provided over a period of two years to Further Education\nResources for Learning (FERL) for supporting colleges in their growing use of ILT (see:\nhttp:llferl.becta.org.uk).\nThe QUILT and FERL college-based projects have achieved levels of success beyond their\nrelatively modest investment (FEDA, 2000). However, because they were often developed\nin isolation, the specific models they provide cannot easily be copied by colleges in different\ncircumstances - that is, they lack 'transferability'. What is required is a quality-assured\n22\nALT-J Volume 8 Number 3\nevaluation process that produces examples of best practice that can be transferred to\nimprove other situations. Such examples must be easy to understand and to implement,\nand for this to occur, the evaluation methodology must be transparent and easy to use. If\nthese aims are achieved, identifying which activities to replicate, then constructing a new\nmodel by copying other models of best practice will not be a time-consuming process.\nEvaluating the National Learning Network\nAn NLN evaluation (NLN-e) team has been appointed on behalf of the Further\nEducation Development Agency (FEDA) to report on what ILT is being used in colleges\nand how this use is affecting the work of the sector. The specific aims of the NLN-e are\nthreefold:\n\u2022 to measure and identify changes in sector investment in and use of ILT over three\nyears;\n\u2022 to report changes in various sector performance indicators over the same period and\nlink these to the application of ILT; and\n\u2022 to assess changes in teaching and learning styles and methods involving the use of ILT.\nThe first NLN-e report to the Further Education Information and Learning Technology (FE\nILT) committee (FEILTC) provides a comprehensive picture of ILT investment and\neffectiveness prior to the introduction of the NLN (FEDA, 2000). The report provides the\nbasis from which sectoral change during the period of investment can be measured, assessed\nand compared. It includes a summary of the 1999 Becta survey, excerpts from selected FERL\nand QUILT case studies, a number of evaluation frameworks, and a discussion of extrinsic\nand intrinsic performance indicators. (Extrinsic performance indicators are directly\nmeasurable in line with the three government objectives of widening participation, increasing\nretention and improving achievement; intrinsic performance indicators are directly connected\nto ILT, such as student and staff computer ratios.) A series of performance indicators are\nbeing used as benchmarks against which future figures will be compared.\nOn a national level, the NLN-e involves formative (ongoing) and summative (end-of-\nproject) evaluation. The NLN-e team is keeping abreast of national-level NLN activities in\norder to assess if any of these activities have a direct impact within the case study colleges,\nand the NLN-e will conclude with a summative evaluation of these national-level activities.\nThe National Learning Network Evaluation\nTo assess the impact of the NLN investment at a local level, fifty carefully selected English\nFE colleges were offered the opportunity to participate in the NLN-e case studies; of\nwhich forty-one are now involved. Colleges were selected primarily by type - specialist,\nsixth form and general FE - with numbers for each type kept proportionate to the total in\nthe sector. Colleges were grouped by size to ensure an even mix of small, medium and large\ninstitutions; they are representative by FEFC regions; and colleges on the Council's\nexceptional support list (colleges at risk) were excluded. In addition, it was ensured that the\nproportion of non-respondents to the 1999 Becta survey was similar to that for all colleges.\nWithin these constraints, as far as possible, a balance between regions and between colleges\nwith high and low widening participation factors was maintained.\n23\nAndrew S.Thomas Caven-Atack The evaluation of the National Learning Network\nEach selected college was asked to choose a cohort of staff or students to study. At an\ninduction seminar attended by representatives from participating colleges and the NLN-e\nteam, a group of FEFC statisticians ensured that these cohorts covered a range of\nprogramme areas, age groups and modes of attendance (full-time or part-time).\nProgramme area\n1 Science\n2 Agriculture\n3 Construction\n4 Engineering\n5 Business\n6 Hotel & Catering\n7 Health & Community Care\n8 Ar t & Design\n9, Humanities\n10 Basic Education\nFull-time\nstudents\naged\n16-19\n4\n2\n1\n2\n3\n2\n3\n1\n6\n1\nFull-time\nstudents\naged\n19+\n2\n1\n1\nPart-time\nstudents\naged\n16-19\n1\n1\nPart-time\nstudents\naged\n19+\n1\n1\n1\n1\n5\nTable I: Cohorts being studied within each FEFC programme area, across age ranges and modes of\nattendance. (One cohort is across college and age.)\nThe NLN-e draws upon the successes of QUILT initiatives and FERL research and\ndevelopment projects. These individual pieces of work have been used as examples of ideas\nto be copied and as mistakes to avoid (however, it must be remembered that they are used\nwith caution because they relate to specific studies using models that are not readily\ntransferable to other situations). For example, the case studies highlighted the close\nrelationship between positive attitudes towards ILT and high levels of performance using\nILT. Armed with this knowledge, the NLN-e team is focusing upon this relationship by\nincluding questions about attitudes and abilities in the NLN-e questionnaire analysis pack,\nand by requesting information about this relationship in the six-monthly NLN-e case study\nreports completed by participating colleges. Furthermore, questions about this relationship\nin the Becta survey allow the evaluation team to compare local data obtained through\nNLN-e case study reports compiled by colleges, with national data obtained from the\nBecta survey.\nThe National Learning Network Evaluation tool pack\nThe college cohorts have each been given a range of free-standing evaluation tools,\ncollected together into an NLN-e tool pack. These tools will enable colleges to assess the\neffectiveness of their investment, and enable the NLN-e team to monitor the impact of the\nnational investment on a small, representative cohort of students and staff over a two-year\nperiod. Results from these grass-roots evaluations will be combined and compared with\ndata on national activities, taken from annual Becta surveys and from the formative\nevaluation reports of national activities also included under the umbrella of the NLN.\n24\nALT-J Volume 8 Number 3\nIn the tool pack, participating colleges have been provided with a number of evaluation tools\nto enable the collection and dissemination of a wealth of data. Colleges have been asked to\ncollect data using 'narratives' and questionnaires, then convert collected raw data into a case\nstudy report to the NLN-e team. The NLN-e team analyses all the case study reports, then\nprovides suitable feedback to each college and applies suggested modifications to the\nevaluation tools. Figure 1 provides a visual representation of this procedure.\nEvaluation Team\nCase Study Report\nNarrative Questionnaires\nFeedback\nLoop\nChosen Cohort\nCollege\nFigure I: The evaluation process.\nThe first draft of the NLN-e tool pack was used to provide a snapshot of ILT spending\nwithin the selected English FE colleges. It contained three sections: narrative suggestions;\nquestionnaires; and the reporting structure (case study format and guidelines). Each\nsection contained guidelines for use, an evaluation tool, plus guidelines for analysis (where\napplicable). As it is hoped that these evaluation tools will be developed to enable colleges to\nperform their own evaluations in future, each tool was chosen for its ease of use and\ninterpretation, and for its usability by non-specialists. The tool pack is aimed at FE\npractitioners - predominantly teachers - as it is these practitioners (not research evaluation\nexperts) who are involved in the evaluation process as both evaluators and the subjects of\nthe evaluation.\nTo appeal to all practitioners, the tool pack must cater for a wide range of individuals -\nincluding ILT enthusiasts and reluctant participants, IT experts and IT novices, and IT\nenthusiasts and technophobes. Although targeting one group - namely, IT experts - would\nconsiderably simplify the evaluation process, targeting a wider audience will aid the holistic\nnature of the NLN-e and any tools that arise from the NLN-e. The NLN-e team has also\nbenefited from having a large, representative group in terms of feedback on the NLN-e\ntools: thus the tool pack is modified by a representative group from colleges across the\ncountry. The lengthy duration of the evaluation is another benefit and has allowed the\n25\nAndrew S.Thomas Caven-Atack The evaluation of the National Learning Network\nNLN-e team gradually to introduce the colleges to evaluation tools, enabling close\nmonitoring of problems with individual aspects of each tool. This also extends the\nduration during which feedback is received, so the NLN-e team is not restricted to a\nsnapshot of opinions but is treated to ongoing commentary.\nThe NLN-etool pack is being developed into a framework for evaluating effectiveness that\nwill be applicable to a variety of educational settings. At the close of the NLN-e, these\ndevelopments will be disseminated to inform the debate on the cost-effectiveness of\neducational technologies; resulting in a set of tools for evaluating ILT developments that\nare applicable at an everyday level, and are available to the whole FE sector. On a larger\nscale, it is hoped that these tools will aid the development of an evaluation framework to\nassess the cost-effectiveness of learning in other sectors and on an international level.\nNarrative\nThe flexible nature of the NLN-e tool pack means it does not impose a rigid methodology\nthat might prove impractical in the everyday college situations for which it is intended. For\nexample, the narrative section within the first draft suggests a number of methods that\ncould be used to collect anecdotal information for inclusion in each case study report but\nnone of these methods are compulsory. Individuals are encouraged to decide which\nmethod (or methods) to use, providing they let the evaluation team know how data was\ncollected and include details of any problems and successes encountered. This should\nenable the NLN-e team to decide which methods are most appropriate to which situations\nand offer more detailed guidance in subsequent drafts of the NLN-e tool pack.\nThis active-reactive-adaptive approach (Patton, 1997) follows the advice proffered by a\nFEDA report on a questionnaire-based study, which concluded that evaluators, 'may . . .\nwish to consider adopting other methods of data collection as well as the questionnaire\ntemplates provided' (Attewell, Barnard and Thompson, 2000). The FEDA study also\nnoted that, 'using questionnaires only might result in too much concentration on the\nproduct rather than the process of learning with ICT' (Attewell et al.) and went on to\nsuggest that this problem could be overcome by combining several methods of data\ncollection - what the NLN-e refers to as the narrative methods.\nThe NLN narrative methods currently being trialled in the NLN-e are listed below.\n\u2022 Retrospective thinking - remembering as much as possible whilst filling in the case study\nreport. This is the simplest and least time-consuming method, which is also highly\nunreliable.\n\u2022 Keeping a journal - this can be time-consuming depending on how much detail is kept\nbut it often gives a very accurate picture of what has happened and of the general\nresponse to what happened.\n\u2022 Using a tape recorder - recording personal thoughts or the comments of the staff and\nstudents participating in the study onto audio cassette. This method involves a\nconsiderable amount of time and effort.\n\u2022 Creating video clips or photographs - recording the cohort in action creates very rich\ndata that can be used to provide illustrative examples. Providing a note is kept of what\nis being recorded, this is an innovative way of keeping track of events.\n26\nALT-J Volume 8 Number 3\n\u2022 Group discussion - discussion between staff and students involved in the cohort can\nemphasize key areas to be highlighted in the case study report.\n\u2022 Observation - a very rich data collection method that can be very time-consuming if\ndetailed.\nQuestionnaires\nThe first draft of the evaluation questionnaires was adapted from work recently completed\nby the Open University (OU) for the FEDA (Attewell, Barnard and Thompson, 2000).\nDrawing upon previous research and practical experience, a set of three customizable\nquestionnaire templates were developed and trialled. These were designed for the local\nevaluation of individual projects, strategies or specific uses of IT in teaching and learning.\nThe NLN-e team refined these questionnaires for use by the NLN-e case study colleges. In\ndoing so, the recommendations for improvements provided by FEDA were incorporated\ninto the questionnaire design. For example, supplementing questionnaires with other data\ncollection methods addresses the lack of triangulation in the original questionnaires.\nHowever, as with the FEDA study, questionnaires are retained by the NLN-e team as the\nmain data collection method.\nThe NLN-e team sought to widen the scope of the original questionnaires to survey\nattitudes, to include resource evaluation and to examine costs and cost-effectiveness -\nsomething beyond the remit of the original study. As the previous FEDA case study college\nrepresentatives were all fairly competent and enthusiastic ILT users, it was felt that the\noriginal questionnaires might prove inappropriate for the wide range of individuals being\nstudied by the NLN-e, especially as even these ILT enthusiasts experienced problems and\nmisunderstandings! The NLN-e team therefore sought to simplify the FEDA\nquestionnaire by removing the complex customization stage. Eliminating customization\nhas the added advantages of heightening the transferability of any results obtained and\nalso shortening the length of time needed to evaluate them. Using electronic rather than\npaper-based tools has also shortened the evaluation time, and this will decrease further\nonce these tools are placed online.\nTo aid the analysis of these questionnaires, they were inserted into a questionnaire analysis\npack, containing the three questionnaires plus guidelines for extracting meaningful data\nfrom each questionnaire. The original intention was simply to include an analysis template\n(as used in the FEDA precursor) along with the questionnaires, but comments from the\nNLN case study colleges indicated that a more structured approach would be welcomed.\nThe main focus of the questionnaire analysis pack is on attitudes towards and competence\nin using ILT. Questions address the relationship between members of the chosen cohort\nand ILT: focusing on the availability and use of IT hardware and software; on IT skills; on\nattitudes towards IT; and on considerations of cost and time. The results from these\nquestionnaires are included as an appendix to the case study reports submitted by the\ncolleges and they provide a rich source of information to feed into each case study report.\nCase study report\nThe case study report provides the interface between the college and the evaluation team.\nEach college is required to submit a report to the NLN evaluation team every six months.\nOnce submitted, these reports are analysed and appropriate feedback is given to each\ncollege. Modification and additions to the format of the case study report are expected at\n27\nAndrew S.Thomas Caven-Atnck The evaluation of the National Learning Network\neach feedback stage. It is hoped that changes based on the reports will improve the\nevaluation tools and the reporting structure.\nPrevious FEDA case studies revealed the usefulness of having clearly defined aims at the\nbeginning of the study (Attewell et al, 2000). For this reason, the NLN case study report\nformat begins by asking colleges to state their aims, their progress towards meeting these\naims, anything preventing their aims being achieved, and how they might overcome these\nbarriers. In accordance with suggestions made by the FEDA, the NLN-e is an ongoing\nprocess of evaluation with colleges asked to submit regular reports. The first case study\nreport detailed the current state of ILT within the college; subsequent reports will show\nchanges in the use of ILT, and the NLN-e team will assess the extent to which the NLN is\nresponsible for these changes. At the macro level of evaluation, a standard format means\nthat colleges and their use of ILT can be easily compared with one another through the\ncase study reports. It also provides examples of best practice, which enables practitioners at\nother colleges to construct their own project models by picking and choosing initiatives\noutlined in different reports that might be applicable to their own institution, and to assess\nhow effective these different methods might be.\nThe case study report is divided into the following sections.\n\u2022 General information - colleges are asked to list specific aims of using ILT with the\ncohort, rate how well these aims have been achieved, give reasons for these ratings and\nindicate what improvements might correct unsatisfactory ratings.\n\u2022 About your college and cohort - colleges are asked to provide background information\nabout the college, focusing upon ILT initiatives; colleges are also asked to provide\nbackground information about the chosen cohort as it was before the introduction of\nthe NLN.\n\u2022 Your activities to date - colleges are asked to describe current ILT initiatives,\nachievements and evaluations.\n\u2022 What effect has the activity had? - colleges are asked to describe the impact of the\nactivity on staff and student skills and attitudes.\n\u2022 The success of the activity - colleges are asked to provide information about successes\nand failures.\n\u2022 Comments on the evaluation tools - colleges are asked for feedback on the evaluation\nprocess.\nTo ensure that the format in which the evaluation data is returned to the NLN-e team\nremains consistent throughout all colleges, guidelines for each section of the case study\nreport were also included in the NLN-e tool pack.\nThere is a subtle but fundamental difference in approach between the FEDA case studies\nand the NLN-e: the FEDA team favoured customization whereas the NLN-e team favours\ntargeting the questionnaires. Individual customization does inhibit comparisons between\nprojects and therefore reduces transferability; however, Patton (1997) does warn us to\n'beware the evaluator who offers essentially the same design for every evaluation' because a\nuniversal approach would provide meaningless results with little or no practical\n28\nALT-J Volume 8 Number 3\napplication. The Learning Technology Dissemination Initiative (LTDI) Evaluation\nCookbook (Harvey, 1998) provides numerous approaches to evaluation and warns that\ndiffering situations or problems demand different approaches. In response to this\nconundrum, Ash (2000) has called for 'a rigorous, quality assured framework that\nencompasses a number of different evaluative approaches', and suggests that these\napproaches should be selected for their suitability to the task and situation, and that they\nshould be able to operate on a number of different levels.\nConclusion\nThe NLN-e continues until March 2002, when the final NLN-e report on the college case\nstudies will be published. A collection of case study reports completed by colleges will also\nbe made public at this time. The finalized NLN-e tool pack will be published and, it is\nhoped, adopted by the English FE sector for which it is being developed. The NLN-e team\nalso intends to develop this tool pack to be applicable to a wider group of users, including\nusers within the higher education sector.\nNLN funding has enabled FE to participate in Joint Information Systems Committee\n(JISC) initiatives, and JISC are consequently now offering the same services to FE that\nhave previously only been available to HE. For example, HE practitioners take high-speed\nInternet connections for granted but very few FE colleges are currently connected to the\nJoint Academic Network (JANET). By the close of the NLN, all English FE colleges will\nhave a JANET connection. All the initiatives within the NLN are self-evaluating and are\nbeing assessed separately for their impact upon the FE sector. The self-evaluation of the\nJANET initiative within FE will deem the project successful if all connections work\nproperly and are installed according to schedule; but this is not a measure of their\neffectiveness. The NLN-e team will assess the impact of JANET and similar initiatives,\nfocusing upon changes within the case study colleges.\nThe merging of HE and FE sectors is also taking place within other initiatives, such as the\nUniversity for Industry, where FE and HE are working together towards common goals.\nThis holistic approach is also being applied to evaluation, with JISC recognizing the\nimportance of costing alongside evaluation - for example, through the funding of the\nCosts of Networked Learning (CNL) project (Bacsich, Ash, Boniwell, Kaplan, Mardell\nand Caven-Atack, 1999). A recent FEDA report (FEDA, 2000) has already noted that\ncosting and effectiveness are interconnected. By combining insights into the evaluation of\nFE gained by the NLN with knowledge about costing HE gained by the CNL project, it\nseems likely that a comprehensive methodology for assessing cost-effectiveness for both\nHE and FE could soon be a reality. Further information about the NLN-e is available\nonline at: http:\/\/www.shu.acuk\/nlnl.\nAcknowledgements\nThe views expressed in this paper are those of the author, who would like to acknowledge\nthe support of Charlotte Ash at Sheffield Hallam University and Kevin Donovan at the\nFurther Education Development Agency.\n29\nAndrew S.Thomas Caven-Atack The evaluation of the National Learning Network\nReferences\nAsh, C. (2000), 'Towards a new cost-aware evaluation framework', Educational Technology\nand Society, 3 (4), http:\/\/ifets.ieee.org\/periodical\/vol_4_2000\/v_4_2000.html.\nAttewell, J., Barnard, J. and Thompson, J. (2000), Evaluating ICT Projects and Strategies in\nTeaching and Learning, London: FEDA.\nBacsich, P., Ash, C, Boniwell, K., Kaplan, L., Mardell, J. and Caven-Atack, A. (1999), The\nCosts of Networked Learning, Sheffield: Sheffield Hallam University.\nBecta (April 1999), Survey into Information and Learning Technology Provision, Access and\nPolicy in FE Colleges in England: Report to the Further Education ILT Committee,\nCoventry: FEFC.\nFEDA (January 2000), Making IT Happen: The First Report on the Efficiency and\nEffectiveness of ILT Investment in Further Education, London: FEDA.\nFEFC (undated), Widening Participation in Further Education: Statistical Evidence\n1996-97, Coventry: FEFC, http:\/\/www.fefcac.uk\/documents\/othercouncilpublications\/\nother_pdf\/wp_se.pdf.\nFEFC (October 1999a), Networking Lifelong Learning: Making IT Happen, Coventry:\nFEFC.\nFEFC (September 1999b), Benchmarking Data 1995-96 to 1997-98: Retention and\nAchievement Rates in Further Education Colleges in England, Coventry: FEFC.\nFEFC (April 1999c), Networking Lifelong Learning: An ILT Development Strategy for FE,\nCoventry: FEFC.\nFEFC (June 1999d), Networking Lifelong Learning: High-level Action Plan (HLAP),\nCoventry: FEFC.\nFE ILT Committee (December 1999), Networking Lifelong Learning: Making IT Happen:\nEvaluation Strategy, London: FE ILT Committee.\nHarvey, J. (ed.) (1998), The Evaluation Cookbook, Edinburgh: LTDI.\nPatton, M. Q. (1997), Utilization Focused Evaluation - New Century Text, California: Sage\nPublications.\nVries, P. and Hertogenbosch, S. (1999), Telelearn Project Report, Netherlands: CINOP.\n30\n"}
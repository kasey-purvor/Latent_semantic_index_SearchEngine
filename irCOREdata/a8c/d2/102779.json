{"doi":"10.1109\/IEMBS.2005.1615973","coreId":"102779","oai":"oai:epubs.surrey.ac.uk:2317","identifiers":["oai:epubs.surrey.ac.uk:2317","10.1109\/IEMBS.2005.1615973"],"title":"Clinical content detection for medical image retrieval","authors":["Chen, L","Tang, HL","Wells, I"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2005-01-01","abstract":null,"downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:2317<\/identifier><datestamp>\n      2017-10-31T14:05:02Z<\/datestamp><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/2317\/<\/dc:relation><dc:title>\n        Clinical content detection for medical image retrieval<\/dc:title><dc:creator>\n        Chen, L<\/dc:creator><dc:creator>\n        Tang, HL<\/dc:creator><dc:creator>\n        Wells, I<\/dc:creator><dc:date>\n        2005-01-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/2317\/1\/SRF002283.pdf<\/dc:identifier><dc:identifier>\n          Chen, L, Tang, HL and Wells, I  (2005) Clinical content detection for medical image retrieval   2005 27th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Vols 1-7.  pp. 6441-6444.      <\/dc:identifier><dc:relation>\n        http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1615973&tag=1<\/dc:relation><dc:relation>\n        10.1109\/IEMBS.2005.1615973<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/2317\/","http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1615973&tag=1","10.1109\/IEMBS.2005.1615973"],"year":2005,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"Clinical Content Detection for Medical Image Retrieval \nL. Chen1, H. L. Tang1 and I. Wells 2\n1Department of Computing, University of Surrey, Guildford, Surrey, GU2 7XH, UK  \n2 Department of Medical Physics, Royal Surrey County Hospital, Guildford, Surrey, GU2 7XX, UK \nAbstract - Content-based image retrieval (CBIR) is the most \nwidely used method for searching large-scale medical image \ncollections; however this approach is not suitable for high-level \napplications as human experts are accustomed to manage medical \nimages based on their clinical features rather than primitive \nfeatures. Automatic detection of clinical features in a large-scale \nimage database and realization of image retrieval by clinical \ncontent are still open issues. This paper presents a Markov random \nfield (MRF) based model for clinical content detection. Multiple \nclassifiers are applied to recognize a wide range of clinical features \nin a large-scale histological image database, and they are further \ncombined to generate more reliable and robust estimation. Spatial \ncontexts will cooperate with local estimations in the MRF based \nmodel to make a decision based on global consistency. The \ndetected clinical features will provide a basis for image retrieval. \nExperiments have been carried out in a large-scale histological \nimage database with promising results.  \nI. INTRODUCTION \nVolumes of medical images are rapidly generated and \nhow to effectively manage them has become a great \nchallenge [1]. Traditional indexing and retrieval of images \nare based on patient names, identifiers, keywords and \nmanual annotations, and these indexing methods vary with \ndifferent data types, formats and approaches. Clinical \nexperts find such database less useful when there is a need \nto retrieve clinical meaningful images. This applies equally \nto image resources available on the Internet and to image \ndatabases held by different departments in the same hospital. \nA promising solution is to index and retrieve images based \non their individual content including both primitive and \nsemantic properties.  \nCBIR has been widely used to retrieve medical images \nby matching visual features. This method is capable of \nmanaging large-scale image databases because of \ncomparatively generic attributes of low-level feature \ndescriptors; however semantic\/clinical features are desirable \nrather than low-level features in high-level applications [2]. \nThis has prompted much research in the field of image \nretrieval by semantic content, although automatic semantic \ncontent recognition has not yet been achieved in practice. \nThe broader the domain of the image data, the more difficult \nthe semantics are to detect automatically [3]. The reason is \nthat images in broad domains potentially have an \nunpredictable and complicated variability in their \nappearance even when they embody identical semantics. \nThis great difficulty in deriving clinical features from \nprimitive features has constrained many applications to \nexamine a limited number of clinical features along a single \norgan or a narrow area of body.  \nThe research presented in this paper will continue to \ninvestigate to examine a large-scale histological image \ndatabase, which is obtained from the whole gastrointestinal \ntract including six organs (oesophagus, stomach, small \nintestine, large intestine, anus and appendix) [2]. This type \nof image is visually similar and usually differs only in small \ndetails, but such subtle differences may be of pathological \nsignificance [4]. This provides a great challenge for \ndeveloping an automatic clinical content recognition \nmechanism, which can help retrieve images by clinical \ncontent. This paper proposes to apply multiple classifiers to \ncover complicated visual varieties associated with a wide \nrange of clinical features in the large-scale histological \nimage archive. These classifiers are combined with \ncomplementary information from each other, and provide \nreliable and robust local estimations. This cooperates with \nspatial contextual information in a MRF based model to \njointly detect clinical features in a global view. Images are \nthen retrieved based on these detected clinical features.  \nII. CLINICAL CONTENT DETECTION BASED \nON A MRF BASED MODEL \nProceedings of the 2005 IEEE\nEngineering in Medicine and Biology 27th Annual Conference\nShanghai, China, September 1-4, 2005\n0-7803-8740-6\/05\/$20.00 \u00a92005 IEEE. 6441\nAuthorized licensed use limited to: University of Surrey. Downloaded on May 12,2010 at 16:07:20 UTC from IEEE Xplore.  Restrictions apply. \nAutomatic detection of clinical features on an image \ndepends on measurements of local regions and spatial \ncontexts among these regions. An image is first segmented \ninto small regions, which are assumed to represent clinical \nfeatures from interest of histopathologists. Assume that N \nsegmented regions, },...,,{ 21 NRRRR  , need to be \nrecognized, and M potential clinical features, \n},...,,{ 21 Mwww : , are examined in a large-scale image \narchive. A set of random variables, },...,,{ 21 NLLLL  , is \ndefined on these regions. The lowercase letter, \n},...,,{ 21 Nllll  denotes a realization\/configuration of L,\nwhere Nili ,..,2,1,  :\u008f . },...,,{ 21 NLLLL   is a set of \nMarkov random variables if and only if P(l)>0 and \n)}({),(),( ')()( ' iiRnRniji RnillwherellPijllP ii \u008f  z . n(Ri) is \na set of neighbours of region Ri.\nWith respect to Bayesian theorem, the task of detection \nof clinical features on an image becomes finding an optimal \nconfiguration l with the maximum joint probability, given \nobservation d and domain knowledge pk. That is,  \nwhere \u020c is the set of all possible configurations on L.\nAccording to Markov-Gibbs equivalence,  \n),(\n1\n1),(\npkdlU\nTeZpkdlP\n\u0010\u0010 u (2)\nwhere \u00a6\n\u0010\n \nl\npkdlU\nTeZ\n),(\n1\n is a normalizing constant called \nthe partition function, T is a constant called the temperature \nwhich shall be assumed to be 1 unless specifically stated, \nand ),( pkdlU  is the energy function.  \nConsidering a four-neighbour system, the energy \nfunction is thus written as:  \n\u00a6 \u00a6\u00a6\n\u008f \u008f\u008f\n\u000e \nRi inj\nji\nRi\ni pkdllVpkdlVpkdlU\n)(\n21 ),,(),(),( (3)\nwhere (.)iV is called a clique function. The first part in (3) \nis called single-region clique function, and the second part is \npair-region function. The energy function includes not only \nthe information of single regions but also spatial contextual \ninformation among regions. A general principle for design \nof a clique function is that if the interpretation of regions (or \na single region) tends to be consistent with the \nmeasurements and spatial contexts, the clique function \ndecreases, resulting in a decrease in the energy function, and \nvice versa [5].  \nA. Single-Region Clique Function by Combining Multiple \nClassifiers\nThe previous methods for designing single-region \nclique functions normally use heuristics or single detector. \nThese methods however failed to deal with a large-scale \ndata, which have more complicated visual appearances \nassociated with a wide range of clinical features. This \nresearch proposes to apply multiple classifiers to handle \nthese complicated visual and semantic varieties in a \nlarge-scale data, and generate a reliable and robust \nestimation on local regions by combining complementary \ninformation from individual classifiers.  \nAssume K statistically independent classifiers, denoted \nas Keee ,...,, 21 , to deal with a local region Ri. For an \narbitrary classifier: }{,,...,2,1,)( 1\u000e\u0089:\u008f  Mk wjKkjxe ,\n1\u000eMw  represents rejected or unknown labels by a classifier, \nits confusion matrix records its detailed performance as \nbelow:  \n\u00b8\n\u00b8\n\u00b8\n\u00b8\n\u00b8\n\u00b9\n\u00b7\n\u00a8\n\u00a8\n\u00a8\n\u00a8\n\u00a8\n\u00a9\n\u00a7\n \n\u000e\n\u000e\n\u000e\nk\nMM\nk\nMM\nk\nM\nk\nM\nk\nM\nk\nM\nkk\nk\nM\nk\nM\nkk\nk\nnnnn\nnnnn\nnnnn\nCM\n)1(21\n)1(222221\n)1(111211\n...\n...............\n...\n...\nEach row i corresponds to class wi, and each column j\ncorresponds to ek(x)=wj. The element kijn  means that \nk\nijn\nsamples of category wi are assigned to category wj by )(xke .\nThe belief of the kth classifier is calculated as [6]:  \n\u00a6\u00a6\n  \n  \n \u008f  \u008f\nM\nt\nk\nit\nk\ntj\nk\nij\nM\nt\nk\nt\nk\ntj\nk\ni\nk\nij\njkijkik\nn\nn\nnn\nnn\nENwxewxPENwxewxb\n11\n.\n.\n)()\/(\n\/\n),)((),)((\n[\n(4)\nwhere 1,...,2,1,...,2,1,\n.\n. \u000e   MjandMi\nn\nn\nk\nt\nk\nik\nit[ . EN\ndenote a normal classification environment.  \nBy applying the averaging rule on multiple classifiers, \nthe belief with a realization li on Ri is calculated as: \n),(maxarg '\n'\npkdlPlifLlassign\nl <\u008f\n o (1)\n6442\nAuthorized licensed use limited to: University of Surrey. Downloaded on May 12,2010 at 16:07:20 UTC from IEEE Xplore.  Restrictions apply. \n\u00a6\n \n  \n  \n  \nK\nk\nkiik\nKii\nKiii\npkielLb\nK\npkieieielLP\npkieieielLblb\n1\n21\n21\n)),((1\n)),(),...,(),((\n)),(),...,(),(()(\nO\n(5)\nwhere \u00a6 \u00a6\n:\u008f  \n \nil\nK\nk\nik lbK 1\n)(11\nO\n to make sure that \u00a6\n:\u008f\n \nil\nilb 1)( .\nWhen the realization li is consistent with the domain \nknowledge and the statistical attributes on a local region Ri,\nthe clique function should be as low as possible. The \nsingle-region clique function is thus defined as: \n))(1()),(),...,(),(( 211 iiiiKiii lbpkReReRelV EG \u0010 (6)\nwhere 01 !t iG  and 01 !t iE  are the weights \nassociated with the corresponding clique functions and they \ncontrol the contributions of each clique function.  \nThe belief calculation method is applicable to arbitrary \nclassifiers, so the design of single-region functions has the \ngeneric capability of managing a large-scale image database. \nMeanwhile, complementary information from different \nclassifiers makes parameter estimations on single regions \nmore reliable and robust.  \nB. Pair-Region Clique Functions by a Knowledge \nElicitation Subsystem \nA knowledge elicitation subsystem [4] is used to learn \nspatial contextual information from the training data. The \nlearning mechanism, through an intuitive interface, allows \nhistopathologists provide sample knowledge which then is \nautomatically modelled.  \nGiven an arbitrary pair of regions {Ri, Rj}, its function \nis defined as:  \nijijjiji TpkRRDllV G )),,(,(\n)2(\n2 (7)\nwhere Tij=1 if the realization li and lj are possibly next to \neach other; otherwise Tij=0. \u012fij is weights for contributions \nfrom the clique function. D(2)(Ri, Rj) is the measurement of a \npair of regions. Since the measurement between the regions \nRi and Rj has no explicit statistical cues like boundary length \nand texture (or colour) contrast in the case of this research, \nFormula (7) is actually only based on spatial contextual \nknowledge acquired from the knowledge elicitation \nsubsystem. If there are more complex constraints (for \nexample, a measurement of a combination of two regions) \navailable for a pair of regions, their clique functions will \nbecome more and more complicated.  \nC. Optimization \nA MRF based model has been constructed for the \ndetection of clinical features in a large-scale histological \nimage archive in terms of multiple processors and domain \nknowledge. Its optimal interpretation is a realization of a set \nof Markov random variables with the maximum probability. \nThe simulated annealing (SA) algorithm is a popular \nmethod used for solving combinatorial optimization \nproblems [5]. The SA algorithm is a stochastic iterative \noptimization procedure, however the SA needs a slow \nenough schedule to reach a global solution. In this research, \na multi-population steepest descent algorithm [4] has been \ndeveloped to search a global optimization in a quick way.  \nIII. USING DETECTED CLINICAL FEATURES \nFOR IMAGE RETRIEVAL \nTwo similarity measurements [2] are designed to \ncompare local neighbour pattern of semantic labels and \nclinical feature frequency distribution. Neighbourhood \nSimilarity (NS) uses a matrix to record the co-occurrence \nfrequencies of all clinical features on a four-node neighbour \nsystem. Each element n(i, j) of the co-occurrence matrix \nrecords how many times label i is next to label j in an image. \nThe similarity between a query image and an image in the \ndatabase is calculated as follows [2]: \n\u00a6\u00a6\n  \n\u0010 \nN\nj\nN\ni\nrrqq sjinsjinsimilarity\n1 1\n),(),(                       \n)exp(\nNW\nsimilarityNS \u0010                    \nwhere N is the number of the clinical features and WN is the \nnumber of pair-regions in an image. sq and sr are the scaling \nfactors to eliminate the influence of the trivial \u2018lumen\u2019 \nfeature in the query and retrieved images, respectively.  \nLt\nt\nrq ww\nw\nss\n\u0010\n ,     \nwhere wt and wL are the total number of regions and the \nnumber of regions labelled with the \u2018lumen\u2019 feature \nrespectively. Fig.1 illustrates an example of image retrieval \nby the NS similarity measurement. The first position on the \n6443\nAuthorized licensed use limited to: University of Surrey. Downloaded on May 12,2010 at 16:07:20 UTC from IEEE Xplore.  Restrictions apply. \nretrieved ranking list is reasonably the query image itself.  \nClinical feature frequency distribution similarity \n(CFFDS) [2] counts the frequencies of the histological \nlabels detected in an image. The CFFDS measurement is \ndefined as:  \n\u00a6\n \n\u0010 \nN\ni\nrrqq siFsiFsimilarity\n1\n)()(\n)exp(\nNF\nsimilarityNS \u0010 \nwhere N is the number of the clinical categories, Fq(i) and \nFr(i) are the frequencies of clinical feature i occurring in the \nquery image and target image in the database, and FN is the \ntotal number of regions in an image. sq and sr are defined \nsame as above. Fig. 2 shows a retrieval example by applying \nthe CFFDS measurement. \nFig.1. Examples of NS similarity measurement \nFig. 2. Examples of CFFDS similarity measurement \nThe performance of the image retrieval is evaluated \nusing the following method. The first N (=6) images on the \nranking list are taken into the calculation as:  \n\u00a6\n \n \nN\ni\niCN\ngoodnessofmeasure\n1\n1__\nwhere \n\u00af\n\u00ae\n\u00ad \u0010\u000e\n \notherwise\nanswercorrecttheisCifiN\nC ii 0\n1\nIt should be noted that the original query image always \nappears at the first position and it is ignored from the \nranking list during the calculation of measure_of_goodness.\nN should be 5 in this case. Points are awarded if the correct \nimage appears in the first N positions. In an ideal situation, \nthe first N positions are positive retrieved images and the \nmeasure_of_goodness equals to 3. In a worst situation \nwhere the first N positions are negative samples, the \nmeasure_of_goodness should be 0. Experiments have been \ncarried out to evaluate the measure_of_goodness in the \nlarge-scale histological image database. The average \nmeasure_of_goodness of the NS measurement is 2.36, and \nthe average measure_of_goodness of the CFFDS \nmeasurement is 2.44. They are close to the ideal situation. \nThe retrieval performance, to some extent, depends on the \nperformance of automatic detection of clinical features. \nIV. CONCLUSION \nThis paper presented a MRF based model for clinical \ncontent detection in a large-scale histological image \ndatabase, with parameters estimated by combining multiple \nclassifiers and spatial contexts acquired by a knowledge \nelicitation subsystem. Images are then retrieved based on the \ndetected clinical content. Although the system has been \nevaluated in the gastrointestinal tract images, the proposed \nmethod has been designed in a generic way to suit for other \ntypes of image. We are currently planning to extend the \napproach to manage more medical image databases \nincluding mammography and prostate data.  \nREFERENCES\n[1] H. M\u00fcller, N. Michoux, et al., \u201cA review of content-based image \nretrieval systems in medical applications \u2013 clinical benefits and future \ndirections\u201d, International Journal of Medical Informatics, Vol. 73, pp. 1-23, \n2004. \n[2] H. L. Tang, R. Hanka, et al., \u201cHistological image retrieval based on \nsemantic content analysis\u201d, IEEE Transaction on Information Technology \nin BioMedicine, 7(1), pp. 26-36, 2003. \n[3] A. Smeulders, M. Worring, et al., \u201cContent-based image retrieval at the \nend of the early years\u201d, IEEE Transactions on Pattern Analysis and \nMachine Intelligence, 22(12), pp. 1349-1380, 2000.  \n[4] L. Chen, Semantic content recognition for a large-scale medical image \narchives, PhD thesis, University of Surrey, UK. 2005. \n[5]J. W. Modestino and J. Zhang, \u201cA Markov random field model-based \napproach to image interpretation\u201d, IEEE Transactions on Pattern Analysis \nand Machine Intelligence, 14(6), pp. 606-615, 1992. \n[6] L. Chen and H. L. Tang, \u201cImproved computation of beliefs based on \nconfusion matrix for combining multiple classifiers\u201d, IEE Electronics \nLetters, 40(4), pp. 238-239. 2004. \n6444\nAuthorized licensed use limited to: University of Surrey. Downloaded on May 12,2010 at 16:07:20 UTC from IEEE Xplore.  Restrictions apply. \n"}
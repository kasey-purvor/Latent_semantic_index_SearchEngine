{"doi":"10.1007\/978-3-642-03891-4_81","coreId":"55332","oai":"oai:eprints.lincoln.ac.uk:2131","identifiers":["oai:eprints.lincoln.ac.uk:2131","10.1007\/978-3-642-03891-4_81"],"title":"A robust lesion boundary segmentation algorithm using level set methods","authors":["Massey, Elizabeth","Hunter, Andrew","Lowell, James","Steel, David"],"enrichments":{"references":[{"id":18434521,"title":"An effective approach to detect lesions in color retinal images.","authors":[],"date":"2000","doi":"10.1109\/cvpr.2000.854775","raw":"Wang, H., Hsu, W., Goh, K., and Lee, M. (2000). An effective approach to detect lesions in color retinal images. In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, volume 2, pages 181\u2013186.","cites":null},{"id":18434520,"title":"Automated detection of diabetic retinopathy on digital fundus images. Diabetic Medicine,","authors":[],"date":"2002","doi":"10.1046\/j.1464-5491.2002.00613.x","raw":"Sinthanayothin, C., Boyce, J., Williamson, T., Cook, H., Mensah, E., and Lal, S. andUsher, D. (2002). Automated detection of diabetic retinopathy on digital fundus images. Diabetic Medicine, 19:105\u2013112.","cites":null},{"id":18434514,"title":"Automated Retinal Analysis.","authors":[],"date":"2005","doi":null,"raw":"Lowell, J. (2005). Automated Retinal Analysis. PhD thesis, University of Durham.","cites":null},{"id":18434516,"title":"Automatic recognition of exudative maculopathy using fuzzy c-means clustering and neural networks.","authors":[],"date":"2001","doi":null,"raw":"Osareh, A., Mirmehdi, M., Thomas, B., and Markham, R. (2001). Automatic recognition of exudative maculopathy using fuzzy c-means clustering and neural networks. In Claridge, E. and Bamber, J., editors, Medical Image Understanding and Analysis, pages 49\u201352. BMVA Press.","cites":null},{"id":18434519,"title":"Diabetic retinopathy a clinical update.","authors":[],"date":"2002","doi":"10.1007\/s00125-002-0990-7","raw":"Porta, M. and Bandello, F. (2002). Diabetic retinopathy a clinical update. Diabetologia, 45(12):1617\u20131634.","cites":null},{"id":18434508,"title":"Edges as outliers: Anisotropic smoothing using local image statistics. Scale-Space Theories in Computer Vision,","authors":[],"date":"1999","doi":"10.1007\/3-540-48236-9_23","raw":"Black, M. and Sapiro, G. (1999). Edges as outliers: Anisotropic smoothing using local image statistics. Scale-Space Theories in Computer Vision, pages 259\u2013270.","cites":null},{"id":18434517,"title":"Fronts propagating with curvaturedependent speed: Algorithms based on Hamilton-Jacobi formulations.","authors":[],"date":"1988","doi":"10.1016\/0021-9991(88)90002-2","raw":"Osher, S. and Sethian, J. A. (1988). Fronts propagating with curvaturedependent speed: Algorithms based on Hamilton-Jacobi formulations. Journal of Computational Physics, 79:12\u201349.","cites":null},{"id":18434524,"title":"Image analysis of fundus photographs: the detection and measurement of exudates associated with diabetic retinopathy.","authors":[],"date":"1989","doi":null,"raw":"Ward, N., Tomlinson, S., and Taylor, C. J. (1989). Image analysis of fundus photographs: the detection and measurement of exudates associated with diabetic retinopathy. Ophthalmology, 96(1):80\u201386","cites":null},{"id":18434513,"title":"On the color image segmentation algorithm based on the thresholding and the fuzzy c-means technique. Pattern Recognition,","authors":[],"date":"1990","doi":"10.1016\/0031-3203(90)90103-r","raw":"Lim, Y. W. and Lee, S. U. (1990). On the color image segmentation algorithm based on the thresholding and the fuzzy c-means technique. Pattern Recognition, 23:935\u2013952.","cites":null},{"id":18434515,"title":"Optic nerve head segmentation.","authors":[],"date":"2004","doi":"10.1109\/tmi.2003.823261","raw":"Lowell, J., Hunter, A., Steel, D., Basu, A., Ryder, R., Fletcher, E., and Kennedy, L. (2004). Optic nerve head segmentation. IEEE Transactions on Medical Imaging, 23(2):256\u2013264.","cites":null},{"id":18434523,"title":"Robust modelling of local image structures and its application to medical imagery.","authors":[],"date":"2004","doi":"10.1109\/icpr.2004.1334584","raw":"Wang, L., Bhalerao, A., and Wilson, R. (2004). Robust modelling of local image structures and its application to medical imagery. In ICPR04, pages III: 534\u2013537.","cites":null},{"id":18434518,"title":"Scale-space and edge detection using anisotropic diffusion.","authors":[],"date":"1990","doi":"10.1109\/34.56205","raw":"Perona, P. and Malik, J. (1990). Scale-space and edge detection using anisotropic diffusion. IEEE Transactions on Pattern Analysis and Machine Intelligence, 12(7):629\u2013639.","cites":null},{"id":18434511,"title":"The discrimination of similarly colored objects in computer images of the ocular fundus.","authors":[],"date":"1990","doi":null,"raw":"Goldbaum, M., Katz, N., Nelson, M., and Haff, L. (1990). The discrimination of similarly colored objects in computer images of the ocular fundus. Investigative Ophthalmology & Visual Science, 31:617\u2013623.","cites":null},{"id":18434509,"title":"Vascular Complications of Diabetes; current issues in pathogenesis and treatment, chapter 10,","authors":[],"date":"2002","doi":null,"raw":"Chen, H.-C. (2002). Vascular Complications of Diabetes; current issues in pathogenesis and treatment, chapter 10, pages 97\u2013108. Blackwell Publishing.","cites":null},{"id":18434510,"title":"Vessel segmentation and blood flow simulation using level-sets and embedded boundary methods. Computer Assisted Radiology and Surgery.","authors":[],"date":"2004","doi":"10.1016\/j.ics.2004.03.344","raw":"Deschamps, T., Schwartz, P., Trebotich, D., Colella, P., Saloner, D., and Malladi, R. (2004). Vessel segmentation and blood flow simulation using level-sets and embedded boundary methods. Computer Assisted Radiology and Surgery. Proceedings of the 18th International Congress and Exhibition, 1268:75\u201380.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2009-09-07","abstract":"This paper addresses the issue of accurate lesion segmentation in retinal imagery, using level set methods and\\ud\na novel stopping mechanism - an elementary features scheme. Specifically, the curve propagation is guided\\ud\nby a gradient map built using a combination of histogram equalization and robust statistics. The stopping\\ud\nmechanism uses elementary features gathered as the curve deforms over time, and then using a lesionness\\ud\nmeasure, defined herein, \u2019looks back in time\u2019 to find the point at which the curve best fits the real object.\\ud\nWe compare the proposed method against five other\\ud\nsegmentation algorithms performed on 50 randomly selected images of exudates with a database of clinician\\ud\ndemarcated boundaries as ground truth","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/55332.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/2131\/2\/LS_WC2009.pdf","pdfHashValue":"2c83367e0438b72516e4fc498baf159567ad96cd","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:2131<\/identifier><datestamp>\n      2013-03-13T08:34:21Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F47:6A6163735F47343030<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F47:6A6163735F47373430<\/setSpec><setSpec>\n      74797065733D636F6E666572656E63655F6974656D<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/2131\/<\/dc:relation><dc:title>\n        A robust lesion boundary segmentation algorithm using level set methods<\/dc:title><dc:creator>\n        Massey, Elizabeth<\/dc:creator><dc:creator>\n        Hunter, Andrew<\/dc:creator><dc:creator>\n        Lowell, James<\/dc:creator><dc:creator>\n        Steel, David<\/dc:creator><dc:subject>\n        G400 Computer Science<\/dc:subject><dc:subject>\n        G740 Computer Vision<\/dc:subject><dc:description>\n        This paper addresses the issue of accurate lesion segmentation in retinal imagery, using level set methods and\\ud\na novel stopping mechanism - an elementary features scheme. Specifically, the curve propagation is guided\\ud\nby a gradient map built using a combination of histogram equalization and robust statistics. The stopping\\ud\nmechanism uses elementary features gathered as the curve deforms over time, and then using a lesionness\\ud\nmeasure, defined herein, \u2019looks back in time\u2019 to find the point at which the curve best fits the real object.\\ud\nWe compare the proposed method against five other\\ud\nsegmentation algorithms performed on 50 randomly selected images of exudates with a database of clinician\\ud\ndemarcated boundaries as ground truth.<\/dc:description><dc:date>\n        2009-09-07<\/dc:date><dc:type>\n        Conference or Workshop contribution<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/2131\/2\/LS_WC2009.pdf<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/2131\/3\/WC2009-1569197186.pdf<\/dc:identifier><dc:identifier>\n          Massey, Elizabeth and Hunter, Andrew and Lowell, James and Steel, David  (2009) A robust lesion boundary segmentation algorithm using level set methods.  In: World Congress on Medical Physics and Biomedical Engineering, September 7 - 12, 2009, Munich, Germany.  <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/978-3-642-03891-4_81<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/2131\/","http:\/\/dx.doi.org\/10.1007\/978-3-642-03891-4_81"],"year":2009,"topics":["G400 Computer Science","G740 Computer Vision"],"subject":["Conference or Workshop contribution","PeerReviewed"],"fullText":" 1 \nWC2009-1569197186.doc \nA Robust Lesion Boundary Segmentation Algorithm using Level Set Methods \nE.M. Massey1, A. Hunter1, J. Lowell2, and D.H. Steel3 \n1\n University of Lincoln, Brayford Pool, Lincoln, LN6 7TS UK  \n2\n Foster Findlay Associates Limited, Newcastle Technopole Kings Manor, Newcastle Upon Tyne NE1 6PA UK\n3\n Consultant Ophthalmologist, Sunderland Eye Infirmary, Queen Alexandra Road, Sunderland SR2 9HP UK \nAbstract\u2014 This paper addresses the issue of accurate lesion \nsegmentation in retinal imagery, using level set methods and a \nnovel stopping mechanism - an elementary features scheme. \nSpecifically, the curve propagation is guided by a gradient \nmap built using a combination of histogram equalization and \nrobust statistics. The stopping mechanism uses elementary \nfeatures gathered as the curve deforms over time, and then \nusing a \u2018lesionness\u2019 measure, defined herein, \u2019looks back in \ntime\u2019 to find the point at which the curve best fits the real \nobject. We compare the proposed method against five other \nsegmentation algorithms performed on 50 randomly selected \nimages of exudates with a database of clinician demarcated \nboundaries as ground truth. \n \nKeywords\u2014 Retinal Image Analysis, Segmentation, Level Sets \nI. INTRODUCTION  \nThe diagnosis of diabetic retinopathy is based upon visually \nrecognizing various clinical features. Retinal lesions are \namong the first visual indicators suggestive of diabetic reti-\nnopathy. The threat to visual loss increases with the fre-\nquency of retinal lesions combined with their encroachment \ninto the macula (one optic disc diameter around the fovea). \nTo enable early diagnosis, it is therefore necessary to identi-\nfy both frequency and position of retinal lesions in relation \nto the fovea. This paper focuses on the segmentation of \nretinal lesions and presents a novel elementary features \nscheme as a level set stopping mechanism for ensuring an \naccurate boundary detection solution. While most applica-\ntions of level set methods have yielded excellent results, \nmany assume a fairly noise free surface. We propose to \napply level set methods to retinal images, which are noisy \nand have a slight surface curve especially near the edges. \nWe present a novel stopping mechanism which uses ele-\nmentary features gathered over time as the curve deforms \nand then a calculated lesionness measure to find the point in \ntime at which the curve best fits the lesion candidate. Sec-\ntions II and III provide background and discuss the current \nliterature, respectively, on region growing schemes as a \nbasis for comparison. Section IV describes the level set \nmethod and technique used. Section V discusses the evalua-\ntion results and provides comparison and observations about \nthe proposed method. Section VI gives conclusions. \nII. BACKGROUND \nRetinal exudates are an interesting challenge for segmenta-\ntion algorithms as they vary in appearance, conforming to \none of three structures: dot exudates, fluffy exudates and \ncircumscribed plaques of exudate. Dot exudates consist of \nround yellow spots lying superficially or deep in the sensory \nretina (Porta and Bandello, 2002). Fluffy exudates are paler \nthan dot exudates and tend to lie more superficially in the \nsensory retina. Plaque exudates vary in size more than the \nother two groups and represent a more diffuse accumulation \nof lipoprotein. In addition to their various appearances, \nexudates may have various arrangement patterns. Exudates \nmay surround leaking capillaries and microaneurysms in a \ncircinate pattern or be randomly scattered. Exudates are \nusually reflective and may appear to have a rigid, multifa-\nceted contour, ranging in color from white to yellow (Chen, \n2002). With varying shapes, sizes, patterns and contrast, \nexudate segmentation is a demanding problem, complicated \nby lighting variation over the image, natural pigmentation, \nthe intrinsic color of the lesion, and decreasing color satura-\ntion at lesion boundaries (Goldbaum et al., 1990). \nIII. SEGMENTATION ALGORITHMS \nLesion segmentation algorithms vary widely along with \ntheir results. The five chosen for comparison are discussed \nhere for context. Ward et al., (1989) introduced a semi-\nautomated exudate detection and measurement method, in \nwhich an operator selects a threshold value to segment ex-\nudates from a shade-corrected retinal background. Sintha-\nnayothin et al., (2002) presented a recursive region growing \nalgorithm applied to a Gaussian smoothed, contrast en-\nhanced image, where all but the faintest, or regions of simi-\nlar color were correctly distinguished. Wang et al., (2000) \ndefines a feature space to include color and exposure infor-\nmation and represents the red, green and blue (R,G,B) \nchannels as spherical coordinates. Features, including pixel \ncolor and illumination, were used to perform regional seg-\nmentation. Osareh et al., (2001) introduced a fuzzy C-\n2 \nMassey,E.M. et al. 2009 \nMeans clustering algorithm based on the work of (Lim and \nLee, 1990) to segment a color retinal image into homogene-\nous regions. The images are converted (RGB to HIS), nor-\nmalized and locally contrast enhanced. The algorithm finds \nall but the faintest exudate regions; however, it has a high \nfalse positive rate caused by cluster overlapping, noise, and \nuneven color distribution. Contrast Gradient Region Grow-\ning (CG), introduced in (Lowell, 2005), uses a traditional \nregion growing method employing a pixel intensity aggre-\ngation scheme for region growth, while using a Gaussian \nsmoothed gradient image to iteratively calculate a gradient \ncontrast between a grown (core) inner boundary and a di-\nlated outer boundary. A seed point is determined using a \nsmall 5 \u00d7 5 sub-window morphologically run over the fun-\ndus image, applying a maximum filter within each sub-\nwindow, producing peak points of the highest intensity \npixel. The core region is then grown by appending (select-\ning) the brightest boundary pixels on each iteration. Once \nthe growing process halts the final boundary is then located \nby using a combination of diameter and contrast to deter-\nmine the point of growth at which the object\u2019s contrast \ngradient is most significant. \nSince the pioneering work of Osher and Sethian \n(Osher and Sethian, 1988) Geometric Deformable Models, \nor Level Sets, have had a significant impact on the imaging \ncommunity due to their capability to preserve the topologi-\ncal information in an image. However, the literature on \nretinal image object segmentation using level sets focuses \nmainly on segmenting structures rather than pathologies. \nExcellent work by Wang et al., (2004) shows the power of \nevolving a curve to map prominent structures in an image. \nDeschampes et al., (2004) used level sets combined with \nembedded boundary methods to simulate blood flow and \nsegment major vessels. Lowell et al., (2004) used active \ncontours to find the optic nerve head. The work described \nherein is based on the seminal paper from (Osher and Se-\nthian, 1988) and the numerical implementation takes in-\nsights from Sapiro, chap. 2, (Sapiro, 2001). \nIV. LEVEL SET METHOD \nBeginning with the definition of level sets from (Osher and \nSethian, 1988): \n( ) \u03c6\u03b5\u03c6\u03c6\u03c6 \u2207=\u2207+\u2207+ KtyxUFt ,,0    (9) \nwhere: t\u03c6 is the propagating function at time t, \u03c6\u22070F  is the \nmotion of the curve in the direction normal to the front, \n( ) \u03c6\u2207tyxU ,, is the term that moves the curve across the \nsurface, and \u03c6\u03b5 \u2207K  is the speed term depending upon cur-\nvature.  For our purposes, ( ) \u03c6\u2207tyxU ,,  is the gradient map, \ndescribed in the next section and \u03c6\u03b5 \u2207K  is approximated \nusing a central differencing scheme.  \n The boundary of a lesion can be characterized by the \npoint of strongest intensity contrast between itself and the \nbackground retina. By determining the gradient of image \nIorig this maximum rate of change can be exploited. \nOptimally, what we want is to propagate a curve to an \nobject edge and then stop when the curve has correctly \nformed to the (correct) perimeter pixels. To do this we must \nprovide an edge stopping function. Since the retinal images \nare inherently noisy, and the edge pixels of retinal lesions \ncan look very much like background pixels, we want a \nmechanism that smoothes out the noise but preserves the \nedges. Isotropic filters (such as Gaussians) smooth the \nimage, but also lose important detail. Anisotropic filters, \nhowever, address the issue of edge preservation. \nFoundational work in anisotropic diffusion (Perona and \nMalik, 1990) gives the following classical description:  \n \n( )( )IIgdiv\nt\ntyxI \u2207\u2207=\n\u2202\n\u2202\n\u03c3,\n),,(\n   (10) \nwhere: I\u2207  is the gradient magnitude, and ( )Ig \u2207  is an \nedge-stopping function and \u03c3 is a scale parameter. The g \nfunction is chosen to satisfy g(x,\u03c3) \u2192 0 when x\u2192\u221e, so that \ndiffusion is \u2018stopped\u2019 across the edges; see also (Black and \nSapiro, 1999).  We apply the following function from (Pe-\nrona and Malik, 1990) to create our gradient map:  \n))(2(\n)(*2),( 2\nn\nn\nI I\nI\nyxg\n\u2212\n=\n     (11) \nwhere: In is a histogram equalized, normalized grayscale \n(green channel) image I(x,y) and \u03c3=1. \nV. PROCESS AND ALGORITHM \nA single channel, 59x59 pixel image Iorig is used to gener-\nate a gradient map and the starting point of the curve is \ndetermined using the simple peak detection algorithm de-\nscribed in Contrast Gradient Region Growing (above). The \ncurve is then allowed to propagate past the optimal point \n(boundary) of the object. The purpose of this is to avoid the \nunderestimation problem inherent in traditional region \ngrowing methods, and take advantage of forward\/backward \nlooking measures. A traditional use of level sets is to track a \ncurve to an object\u2019s boundary.  In our case, it is more inter-\nesting to \u2018peek ahead\u2019 by allowing the curve to move past \nthe optimal boundary and then \u2018look back\u2019 and measure \nhow well-formed the accumulated region is as a lesion. We \ndefine the term lesionness as a combination of compactness \n 3 \nMassey,E.M. et al. 2009 \n(c = p2\/a), where p is the perimeter and a is the area (Gon-\nzalez and Woods, 2001) and perimeter size constancy shp \nand use it as our \u2018stopping\u2019 mechanism. We are looking for \nmeasurements that can give indicators of how well-formed a \nregion is as a candidate lesion.  The elementary features \ngathered, then, include 1) the number of iterations the curve \nheld its perimeter size: shp; 2) the minimum compactness \nvalue: c; 3) the number of iterations the curve held that \ncompactness value: chp; 4) the maximum gradient contrast: \ngc. At each change in the curve shape two morphological \noperators (dilation and erosion) are used to calculate \u2018rings\u2019 \nabout the curve.  The contrast (difference) between these \ntwo rings is taken: \nCECD \u2295= 0      (12) \nCECE \u2295= 0      (13) \n\u2211 \u2211\n\u2208 \u2208\n\u2212=\nDp Ep\nII pgpggc )()(     (14) \nWhere: C0 is the infilled curve, CE is a 3x3 structuring \nelement, gI is the gradient map. \nOf the elements tracked during propagation, shp \nand chp are indicators of curve stabilization (slowing \ndown).  Let q be the iteration number and let h(q) be the \ncount of the number of iterations for which the values of \nboth chp and shp have held up to and including iteration q. \nLet qM, qN be the iterations with the two largest values of \nh(q), M < N. Let qc be the iteration with the smallest value \nof compactness c, and qgc be the iteration with the largest \ncontrast. Let Z be the set of critical iterations including qM \nand qN, and qc if   M < qc < N, and qgc if M < qgc < N. Thus, \nthe set Z includes the strongest stabilizing points and any \nother critical iteration(s) between them. Sometimes there \nmay be outlying critical iterations. For this reason we de-\ntermine the largest gap between successive critical iterations \nand discarding those after the largest gap form the set Z*, \nwhere Z*\u2282 Z. We define the best fit point, SV, as the aver-\nage of these critical iterations. Figure X shows an example \nof the plotted elemental feature points and the final curve. \n*#\n*\nZ\nq\nSV Zq\n\u2211\n\u2208\n=      (15) \nwhere: #Z* is the number of elements used.\n   \n  (a)   (b) \nFigure X. (a) Plots of elemental features; (b) final curve. \nVI. EVALUATION \nA comparison is made between the presented ELS algo-\nrithm and five other segmentation approaches.  Table 1 \nshows the results of our evaluation. \nTable 1 Algorithm Performance Metrics \nModel Sens. Spec. Accuracy Error Timing (secs) \nELS 96.94 98.97 98.87 29.35 561.26 \nCG 96.24 98.71 98.59 36.59 196.64 \nAR 91.13 92.53 92.45 196.15 69.70 \nFuzzy 88.29 94.18 93.89 158.95 98.39 \nRRG 47.72 90.99 88.85 290.1 82.30 \nDC 64.67 75.77 75.21 644.75 483.28 \n      \nELS \u2013 Elementary Features Scheme;  Fuzzy \u2013 Fuzzy C-means; \nCG \u2013 Contrast Gradient;               RRG \u2013 Recursive Region Grow; \nAR \u2013 Adaptive Recursive;               DC \u2013 Color Discriminant. \nAll algorithms were implemented and evaluated against a \nreference standard dataset of 50 randomly selected lesion \nimages. Images were taken with a Canon EOS 20D attached \nto a Canon fundus camera and demarcated with boundary \nmarkups by an expert ophthalmologist. The images are \nprovided courtesy of the Sunderland Eye Infirmary with \npermission to be used in this research. The benchmark com-\nparison was achieved by measuring the number of common \npixels shared between the reference standard and the algo-\nrithm\u2019s segmented output. For each reference standard re-\ngion R, true positive (pixels matched to reference standard) \nTP, false negative (pixels missed in reference standard) FN, \nfalse positive (pixels added over the reference standard) FP \nand true negative (background pixels in reference standard) \nTN. Statistics were calculated for each segmentation ap-\nproach. The values in Table 1 were measured using pixel-\nwise sensitivity, specificity, accuracy and error-rate: \nFNTP\nTPSens\n+\n=\n     (16) \nFPTN\nTNSpec\n+\n=\n     (17) \nFNTNFPTP\nTNTPAccuracy\n+++\n+\n=\n    (18) \nFPFNError +=      (19) \n \nThe following observations are made on the performance of \nthe ELS algorithm:  \nAccuracy: As shown in table 1 the ELS method outper-\nforms the CG algorithm in all areas and especially in show-\ning a reduction in error. Experiments show that the CG \nalgorithm tends to underestimate the lesions in general, as \ndenoted by the sensitivity measure. This underestimation is \n4 \nMassey,E.M. et al. 2009 \ndue to the smoothed gradient image used to determine the \nboundary contrast. As such, low contrast pixels get merged \ninto the retinal pigmentation.  \nRobustness: The ELS algorithm does not depend on a sin-\ngle criterion, such as compactness to find a solution; rather, \nseveral measurements are taken as the curve propagates. \nSince the measurements are not dependent on specific thre-\nsholds, the true measures of the data can be taken into ac-\ncount during the initial value calculation and reassessment \nphases.  \nGeometric: The ELS algorithm also is not dependent on a \nsingle pixel value at a specific point in time, rather the curve \nmoves in relation to curvature and direction of the normal. \nThus, global as well as local information is used during \ncurve propagation. Tracking the zero level set, as we do \nhere, overcomes topological problems (such as discontinui-\nties) that would hamper, even halt, traditional curve propa-\ngation algorithms.  \nVII. CONCLUSIONS  \nA novel algorithm for the automated segmentation and \nclassification of candidate lesions has been presented and \ncompared against other well-known algorithms. Due to \nmarginal color and intensity differences between lesion and \nbackground pixels, algorithms which depend on color and \nillumination are severely limited. The results shown in Ta-\nble 1 demonstrate the advantage of allowing a curve to \npropagate past an optimal boundary point to \u2018peek ahead\u2019 to \nadjacent areas.  Then use gathered features to \u2018look back in \ntime\u2019 to determine the best fitting curve and thus accurate \nsegmentation. \nACKNOWLEDGMENT \nThe authors would like to thank Dr. Bashir Al-Diri for \nhis contribution to this work. \nREFERENCES  \nBlack, M. and Sapiro, G. (1999). Edges as outliers: Anisotropic smoothing \nusing local image statistics. Scale-Space Theories in Computer Vision, \npages 259\u2013270. \n \nChen, H.-C. (2002). Vascular Complications of Diabetes; current issues in \npathogenesis and treatment, chapter 10, pages 97\u2013108. Blackwell Publish-\ning. \n \nDeschamps, T., Schwartz, P., Trebotich, D., Colella, P., Saloner, D., and \nMalladi, R. (2004). Vessel segmentation and blood flow simulation using \nlevel-sets and embedded boundary methods. Computer Assisted Radiology \nand Surgery. Proceedings of the 18th International Congress and Exhibi-\ntion, 1268:75\u201380. \n \nGoldbaum, M., Katz, N., Nelson, M., and Haff, L. (1990). The discrimina-\ntion of similarly colored objects in computer images of the ocular fundus. \nInvestigative Ophthalmology & Visual Science, 31:617\u2013623. \n \nGonzalez, R. C. and Woods, R. E. (2001). Digital Image Processing. \nPrentice Hall, Upper Saddle River, NJ. \n \nLim, Y. W. and Lee, S. U. (1990). On the color image segmentation algo-\nrithm based on the thresholding and the fuzzy c-means technique. Pattern \nRecognition, 23:935\u2013952. \n \nLowell, J. (2005). Automated Retinal Analysis. PhD thesis, University of \nDurham. \n \nLowell, J., Hunter, A., Steel, D., Basu, A., Ryder, R., Fletcher, E., and \nKennedy, L. (2004). Optic nerve head segmentation. IEEE Transactions on \nMedical Imaging, 23(2):256\u2013264. \n \nOsareh, A., Mirmehdi, M., Thomas, B., and Markham, R. (2001). Auto-\nmatic recognition of exudative maculopathy using fuzzy c-means cluster-\ning and neural networks. In Claridge, E. and Bamber, J., editors, Medical \nImage Understanding and Analysis, pages 49\u201352. BMVA Press. \n \nOsher, S. and Sethian, J. A. (1988). Fronts propagating with curvature-\ndependent speed: Algorithms based on Hamilton-Jacobi formulations. \nJournal of Computational Physics, 79:12\u201349. \n \nPerona, P. and Malik, J. (1990). Scale-space and edge detection using \nanisotropic diffusion. IEEE Transactions on Pattern Analysis and Machine \nIntelligence, 12(7):629\u2013639. \n \nPorta, M. and Bandello, F. (2002). Diabetic retinopathy a clinical update. \nDiabetologia, 45(12):1617\u20131634. \n \nSinthanayothin, C., Boyce, J., Williamson, T., Cook, H., Mensah, E., and \nLal, S. andUsher, D. (2002). Automated detection of diabetic retinopathy \non digital fundus images. Diabetic Medicine, 19:105\u2013112. \n \nWang, H., Hsu, W., Goh, K., and Lee, M. (2000). An effective approach to \ndetect lesions in color retinal images. In Proceedings IEEE Conference on \nComputer Vision and Pattern Recognition, volume 2, pages 181\u2013186. \n \nWang, L., Bhalerao, A., and Wilson, R. (2004). Robust modelling of local \nimage structures and its application to medical imagery. In ICPR04, pages \nIII: 534\u2013537. \n \nWard, N., Tomlinson, S., and Taylor, C. J. (1989). Image analysis of \nfundus photographs: the detection and measurement of exudates associated \nwith diabetic retinopathy. Ophthalmology, 96(1):80\u201386\n \n"}
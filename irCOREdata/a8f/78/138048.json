{"doi":"10.1108\/13673270610650111","coreId":"138048","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/1155","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/1155","10.1108\/13673270610650111"],"title":"KM your way to CMMI","authors":["Dayan, Rony","Evans, Stephen"],"enrichments":{"references":[{"id":38113687,"title":"Capability Maturity Model Integration (CMMI SM): A View From the Sponsors',","authors":[],"date":"2002","doi":"10.1002\/sys.10011","raw":"\/2, pp. 271-275. Rassa, R.C., Garber, V. and Etter, D.  (2002), 'Capability Maturity Model Integration (CMMI SM): A View From the Sponsors', Systems Engineering, Vol. 5, No. 1, pp. 3. Vernick, J.A., Jackson Purvis M. and Thomas, W.R.  (2002), 'The SEI Transition Partner Program for CMMI', Systems Engineering, Vol. 5, No. 1, pp. 27. Zubrow, Dave (2003), 'Current trends in the adoption of the CMMI(R) product suite', Proceedings of the 27th annual international computer software and applications conference.","cites":null},{"id":38113684,"title":"CMMI Distilled - A Practical Introduction to Integrated Process Improvement,","authors":[],"date":"2001","doi":"10.1145\/1039174.1039208","raw":"Ahern, D.M., Clouse, A., and Turner, R.  (2001), CMMI Distilled - A Practical Introduction to Integrated Process Improvement, Addison-Wesley, Ahmed, P.K., Lim, K.K. and Zairi, M. (1999), 'Measurement Practice for Knowledge Management', The Journal of Workplace Learning, Vol. 11, No. 8, pp. 304-311. Ahn, J.-H. and Chang, S.-G. (2004), 'Assessing the contribution of knowledge to business performance: The KP","cites":null},{"id":38113689,"title":"CMMI is a service mark of","authors":[],"date":null,"doi":null,"raw":"CMMI is a service mark of Carnegie Mellon University.","cites":null},{"id":38113693,"title":"Compare to the KM measurement as detailed in the KM paragraph.","authors":[],"date":null,"doi":null,"raw":"Compare to the KM measurement as detailed in the KM paragraph.","cites":null},{"id":38113695,"title":"In the KM program we call them Good Practices that evolve eventually to become Best Practices.","authors":[],"date":null,"doi":null,"raw":"In the KM program we call them Good Practices that evolve eventually to become Best Practices.","cites":null},{"id":38113691,"title":"KM procedure considered as part of the capturing chapter,","authors":[],"date":null,"doi":null,"raw":"KM procedure considered as part of the capturing chapter, as listed in the KM paragraph.","cites":null},{"id":38113694,"title":"KM procedure considered as part of the creating chapter,","authors":[],"date":null,"doi":null,"raw":"KM procedure considered as part of the creating chapter, as listed in the KM paragraph.","cites":null},{"id":38113692,"title":"KM procedure considered as part of the retrieving chapter,","authors":[],"date":null,"doi":null,"raw":"KM procedure considered as part of the retrieving chapter, as listed in the KM paragraph.","cites":null},{"id":38113690,"title":"KM procedure considered as part of the sharing chapter,","authors":[],"date":null,"doi":null,"raw":"KM procedure considered as part of the sharing chapter, as listed in the KM paragraph.","cites":null},{"id":38113685,"title":"Knowledge Management and Process Performance',","authors":[],"date":"1999","doi":"10.5772\/39455","raw":"methodology', Decision Support System, Vol. 36, pp. 403-416. Armistead, C. (1999), 'Knowledge Management and Process Performance', Journal of Knowledge Management, Vol. 3, No. 2, pp. 143-154. Boehm, B. (2000), 'Unifying Software Engineering and Systems Engineering', Computer, pp.","cites":null},{"id":38113688,"title":"Maturity Model, and Capability Maturity Modeling are registered in the U.S. Patent and Trademark Office.","authors":[],"date":null,"doi":"10.1036\/1097-8542.801890","raw":"CMM, Capability Maturity Model, and Capability Maturity Modeling are registered in the U.S. Patent and Trademark Office.","cites":null},{"id":38113686,"title":"Software Engineering Institute. The Capability Maturity Model: Guidelines for Improving the Software Process,","authors":[],"date":"1994","doi":"10.1145\/217030.565652","raw":"-116. Carnegie Mellon University, Software Engineering Institute. Upgrading From SW-CMM to CMMI\u00ae. Carnegie Mellon University (1994), Software Engineering Institute. The Capability Maturity Model: Guidelines for Improving the Software Process, Addison Wesley Longman, Inc., Reading, MA. CMMI Product Team, (2002), CMMI for System Engineering, Software Engineering, Integrated Product and Process Development, and Supplier Sourcing (Staged Representation), Report no. CMU\/SEI-2002-TR-012; ESC-TR-2002-012, Pittsburg, PA. Curtis, P., Phillips, D.M. and Weszka, J.  (2002), 'CMMI - The Evolution Continues!', Systems Engineering, Vol. 5, No. 1, pp. 7. Davenport, T.H., Harris, J.G., de Long, D.W. and Jacobson, A.L.  (2001), 'Data to Knowledge to Results: Building an Analytic Capability', California Management Review, Vol. 43, No. 2. Day, G. S. (1994), 'The capabilities of market-driven organizations', Journal of Marketing, Vol.58. No. 4, pp.37-52. Dayan, R.  (2003),  'KM and Culture Change at Israel Aircraft Industries',  The Knowledge Management Review, Vol. 6, No. 2, pp. 12-15. Heisig, P.  (2002), European Guide to Good Practice in Knowledge Management - Frameworks on Knowledge Management. Fraunhofer IPK. Jacobs, J.C. and Trienekens, J.J.M. (2002), 'Towards a Metric Based Verification and Validation Maturity Model', Proceedings of the 10 th International Workshop on Software Technology and Engineering Practice (STEP'02), Kristensen, K. and Westlund, A.H.  (2004), 'Accountable Business Performance Measurement for Sustainable Business Excellence', Performance Measurement and Business Results, Vol. 15, No. 5\/6, pp. 719-734. Lepasaar, M. and Makinen, T. 'Integrating Software Process Assessment Models Using a Process Meta-Model', IEEE, Liebowitz, J. and Wright, K.  (1999), 'Does Measuring Knowledge Makes &quot;Cents&quot;?',  Expert Systems With Applications, Vol. 17, pp. 99-103. Lim, K.K. and Ahmed, P.K.  (2000), 'Enabling Knowledge Management: A Measurement Perspective', ICMIT, pp. 690-695. Martin, W.J.  (2000),  'Approaches to the Measurement of the Impact of Knowledge Management Programmes',  Journal of Information Science, Vol. 26, No. 1, pp. 21-27. Miller, M.J., Pulgar-Vidal, F., and Ferrin, D.M. (2002), 'Achieving Higher Levels of CMMI Maturity Using Simulation', Proceedings of the 2002 Winter Simulation Conference. Paulk, M., Weber, C., Curtis, B., Chrissis, M. B. (1995), 'The Capability Maturity Model', Addison Wesley. Ramanujan, S. and Someswar, K.  (2004), 'Comparison of Knowledge Management and CMM\/CMMI Implementation', Journal of American Academy of Business, Vol. 4, No.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2006","abstract":"The purpose of this paper is to describe two related fields \u2013 knowledge management (KM) and capability maturity model integrated (CMMISM) \u2013 and highlight their similarities","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/138048.pdf","fullTextIdentifier":"http:\/\/hdl.handle.net\/1826\/1155","pdfHashValue":"fd80b65d5c89abca77a5ecb5dfaa5ae84f66e6c5","publisher":"Emerald","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/1155<\/identifier><datestamp>2008-03-12T11:04:57Z<\/datestamp><setSpec>hdl_1826_24<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>KM your way to CMMI<\/dc:title><dc:creator>Dayan, Rony<\/dc:creator><dc:creator>Evans, Stephen<\/dc:creator><dc:description>The purpose of this paper is to describe two related fields \u2013 knowledge management (KM) and capability maturity model integrated (CMMISM) \u2013 and highlight their similarities.<\/dc:description><dc:publisher>Emerald<\/dc:publisher><dc:date>2006-08-18T13:55:05Z<\/dc:date><dc:date>2006-08-18T13:55:05Z<\/dc:date><dc:date>2006<\/dc:date><dc:type>Postprint<\/dc:type><dc:format>73737 bytes<\/dc:format><dc:format>application\/pdf<\/dc:format><dc:identifier>Rony Dayan, Stephen Evans; KM your way to CMMI. Journal of Knowledge Management 2006 Vol 10 Iss 1 pp 69-80<\/dc:identifier><dc:identifier>1367-3270<\/dc:identifier><dc:identifier>http:\/\/hdl.handle.net\/1826\/1155<\/dc:identifier><dc:identifier>http:\/\/dx\/doi\/org\/10.1108\/13673270610650111<\/dc:identifier><dc:language>en<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["1367-3270","issn:1367-3270"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2006,"topics":[],"subject":["Postprint"],"fullText":"KM YOUR WAY TO CMMI \n \nRony Dayan \u2013 Director of Knowledge and Intellectual Property \nIsrael Aircraft Industries (rdayan@iai.co.il) \nStephen Evans - Head, International Ecotechnology Research Centre \nCranfield University, Department of Enterprise Integration (steve.evans@cranfield.ac.uk) \n \n \nAbstract \n \nThis paper was written to familiarize people involved with either field \u2013 Knowledge Management \n(KM) or Capability Maturity Model Integrated (CMMISM) with the other one in surfacing their \nsimilarities. \nThe KM framework used for this comparison is the one established and used at Israel Aircraft \nIndustries, while the CMMISM source of information is none but the original document produced \nby the CMMISM Product Team at the Carnegie Mellon University, as well as papers published on \nthe subject. \nKnowledge Management is a rather young discipline promising to maximize innovation and \ncompetitive advantage to organizations that practice knowledge capture, documentation, \nretrieval and reuse, creation, transfer and share to its knowledge assets in a measurable way, \nintegrated in its operational and business processes. \nThe Capability Maturity Model Integrated deals with the ways an organization has to follow, in \norder to maintain well mapped processes, having well defined stages, because of the \nassumption that in mature organizations, it is possible to measure and relate between the \nquality of the process and the quality of the product. \nThough KM and CMMISM take different approaches to the achievement of competitive \nadvantage, they seem to be supporting as well as dependent of each other as this article will \nattempt to show. \nPractitioners as well as researchers in the field of Knowledge Management and in the \nimplementation of the CMMISM standard will find comfort in realizing how mutually supportive \nare these two fields. \n \nIntroduction \n \nIn the hypercompetitive environment we are bound to perform, we find the knowledge we have \nand the usage we make of it to be the main source of our competitive advantage. A major part \nof this knowledge refers to defined and documented processes in the various competence \ncentres of the company (some of them technological while others are procedural). The rest \nremains in the generalized term of tacit knowledge which refers to the experience of the \ncompany's people, in their head and memory or at the tip of their fingers. \nKnowledge management (KM) is a rather young discipline promising to maximize innovation \nand competitive advantage to organizations that practice knowledge capture, documentation, \nretrieval and reuse, creation, transfer and share of its knowledge assets in a measurable way, \nintegrated in its operational and business processes. \nThe Capability Maturity Model Integrated (CMMISM) deals with the ways an organization has to \nfollow, in order to maintain well mapped processes, having well defined stages, because of the \nassumption that in mature organizations, it is possible to measure and relate between the \nquality of the product and the quality of the process. \nThough KM and CMMISM take different approaches to the achievement of competitive \nadvantage (Ramanujan & Someswar, 2004), they seem to be supporting as well as dependent \nof each other and this is the basis of this article. \n   \n Knowledge Management \n \nKnowledge Management is the systematic effort to capture, store, retrieve, reuse, create, \ntransfer and share knowledge assets within an organization, in a measurable way completely \nintegrated in its operational and business goals, in order to maximize innovation and \ncompetitive advantage. Knowledge can be classified as explicit or tacit. Explicit knowledge \nwould include such things as documented processes, directives, standards, or patents. Tacit \nknowledge is the knowledge that people carry around in their mind; it is their experience and \ntheir expertise and transforming it into an organizational asset is not straightforward. A \ncompany's greatest assets may not lie in the products they make but the knowledge of the \npeople who produce those products.  \nTherein lies the importance of having a method of collecting, managing, and maintaining that \nknowledge. Knowledge management is implemented in various organizations using different \nframeworks (Heisig, 2002). One that has been designed and run by the writer of this article who \nis the Director of Knowledge and Intellectual Capital of Israel Aircraft Industries, is built as a \ncomprehensive program around a full life cycle of the knowledge \u2013 starting from the creation of \nknowledge, the capture and documentation of it, its retrieval for reuse and its sharing (Dayan, \n2003). Specific processes have been defined to perform those activities and to measure their \ninfluence and possibly, their concrete effect on business results. These are: \n\u2022 New knowledge creation \no Knowledge extracted from the innovation process \no Knowledge from the new product initiative (NPI) process  \n \n\u2022 Knowledge capture and documentation \no Disciplinary knowledge capture \no Lessons learned from debriefings \no Organizing for content management \n \n\u2022 Knowledge retrieval for reuse \no Fostering the knowledge of core competence centres \no Using past knowledge in the generation of technical and price proposals \no Establishing business and technological knowledge bases \n \n\u2022 Knowledge sharing \no Communities of practice \no Generating good practices \no Using portals to share knowledge \n \nThis comprehensive KM program is measured at three levels \u2013 the performance level which \nshows how much of what needs to be performed out of the KM procedures, is actually \nachieved; the throughput level, to monitor that the KM activity was indeed efficient; and finally, \nthe operational or business result which is the aim of the KM program if indeed it is to support \nthe organization's goals. This measurement process enables the management of the program \nand its constant connection to the operational activity as the worst that can happen to such a \nprogram is its detachment from everyday life (Kristensen & Westlund, 2004).  \nThe concept of taming knowledge and putting it to work is not new; phrases containing the word \nknowledge, such as knowledge bases and knowledge engineering, existed before KM became \npopularized. KM is unique because it focuses on the individual as an expert and as the bearer \nof important knowledge that he or she can systematically share with an organization. KM \nsupports not only the know-how of a company, but also the know-where, know-who, know-what, \nknow-when, and know-why. In that, it is the mechanism that centralises the documentation \nabout the various processes involved with the operation of the company (Davenport, Harris, et \nal., 2001 ). \nAs we describe the more formal processes companies have to follow in order to be considered \nconsistent with the more recent quality standards, it will be evident that many of these \nrequirements are actually answered by complying with KM procedures.  \n \nFrom CMM1 to CMMISM 2 \n \nA model is a simplified representation of the world. Capability Maturity Models (CMMs) contain \nthe essential elements of effective processes for various applications. Since 1991, Capability \nMaturity Models have been developed for a myriad of disciplines. The SW-CMM was developed \nby the Software Engineering Institute of the Carnegie Mellon University, in collaboration with the \nsoftware community, and since its publication in 1991 has become a de facto standard for \nassessing and improving software processes. Models for software acquisition, workforce \nmanagement and development, and Integrated Product and Process Development came later. \nAlthough these models have proven useful to many organizations, the use of multiple models \nhas been problematic. \nThe CMM Integration project was formed to sort out the problem of using multiple CMMs by \ncombining their models into a single improvement framework for use by organizations pursuing \nenterprise-wide process improvement (Carnegie Mellon University). The CMMISM -SE\/SW \nintegrates the SW-CMM with the Systems Engineering Capability Model and concepts from \nIntegrated Product and Process Development (IPPD) to provide a framework for improving and \nevaluating capability maturity across both software and systems engineering aspects of an \norganization. Like other CMMs, Capability Maturity Model Integration (CMMISM) models provide \nguidance to use when developing processes. CMMISM models are not processes or process \ndescription; the actual processes used in an organization depend on many factors, including \napplication domain(s) and organization structure and size. \nA process is a set of practices performed to achieve a given purpose; it may include tools, \nmethods, material and\/or people. A process is therefore a leverage point for an organization's \nsustained improvement. Your workforce, in general is as good as it is trained to be. Getting \nbetter performance, higher yield, or improved throughput cannot only be the result of harder \nwork. It has to come out of smarter work \u2013 such, for which the process has been analyzed, \nimproved and hopefully optimized (Armistead, 1999). \nThe purpose of CMMISM is then, to provide guidance for improving the organization's processes \nand its ability to manage the development, acquisition, and maintenance of products and \nservices. CMMISM places proven approaches into a structure that helps the organization \nappraise its organizational maturity or process area capability, establish priorities for \nimprovement, and implement these improvements. \nThe Capability Maturity Model Integrated (CMMISM) offers you the means to improve your \norganization's ability to manage the development, acquisition and maintenance of products and \nservices. As such it has the potential to significantly improve your organization's efficiency and \nprofitability. CMMISM enables you to assess your organizational maturity and process area \ncapability. It identifies priorities for improvement, and provides guidance on the implementation \nof these improvements. \nThe US Department of Defence requirement, as stated in DoD 5000.2-R as follows, doesn't \nleave much of a choice to industries interested to do business with the largest and most \nimportant world customer: \n\"At a minimum, full compliance with SEI Capability Maturity Model Level 3, or its equivalent in \nan approved evaluation tool, is the Department's goal\".   \n \nCMMISM Reference models \n \nCMMISM models are designed to describe discrete levels of process improvement (CMMI \nProduct Team 2002). There are 4 disciplines for which CMMI models are developed: \n\u2022 Systems engineering \n\u2022 Software engineering \n\u2022 Integrated Product and Process Development \n\u2022 Supplier sourcing \n \nAs stated, the CMMISM is an integrated model having its sources in all these disciplines. The \nresult is not necessarily inclusive of them all, so that the alternative reference models \ncomprising of the CMMI could be either of the following: \n\u2022 Systems Engineering + Software Engineering \n\u2022 Systems Engineering + Software Engineering + Integrated Product and Process \nDevelopment (IPPD) \n\u2022 Systems Engineering + Software Engineering + Integrated Product and Process \nDevelopment (IPPD) + Supplier Sourcing (SS) \n \nThe five maturity levels \n \nCMMISM in its staged configuration is being measured at five different levels. A maturity level is \na well-defined plateau of process growth. Each maturity level stabilizes an important part of the \norganization's processes. Maturity levels consist of a predefined set of process areas. The \nmaturity levels are measured by the achievements of the goals that apply to each predefined \nset of process areas. The model consists of five maturity levels, each layer being the basis for \nongoing process improvement: \n\u2022 Initial \u2013 Process unpredictable, poorly controlled, and reactive. \n\u2022 Managed \u2013 Process characterized for projects and is often reactive. \n\u2022 Defined \u2013 Process characterized for the organization and is proactive \n\u2022 Quantitatively managed \u2013 Process measured and controlled. \n\u2022 Optimized \u2013 Focus on process improvement. \n \nThe very building of capability measurement in superseding levels has a value in itself. Indeed, \nreaching a higher capability without the mastering the confidence of the basic ones is like \nmaking a pyramid stand on its head and hopping it to remain stable and to reflect the situation \nacross the organization and not merely at chosen locations. The organization can achieve \nprogressive improvements in its maturity by first achieving stability at the project level and \ncontinuing to the most advanced-level, organization-wide continuous process improvement \nusing both quantitative and qualitative data to make decisions. \n \nProcess areas for CMMISM \n \nA process area consists of a set of related practices in an area that, when performed \ncollectively, satisfy a set of process goals considered important for making significant \nimprovement in that area. \nProcess goals are statements about process areas describing what a process area should \nachieve, to make significant process improvements. \n \nProcess areas can be grouped into 4 categories: \n\u2022 Engineering \n\u2022 Project management \n\u2022 Process management \n\u2022 Support \n \nIn its staged representation, CMMISM is addressing process areas according to the maturity \nlevel: \n \nLevel Focus Process areas \n1 Initial   \n2 Managed Basic project \nmanagement \nRequirements Management  \nProject Planning \nProject Monitoring and Control \nSupplier Agreement Management \nMeasurement and Analysis \nProcess and Product Quality Assurance \nConfiguration Management \n3 Defined Process \nstandardization \nRequirements development \nTechnical solution \nProduct integration \nVerification \nValidation \nOrganizational Process Focus \nOrganizational Process Definition \nOrganizational Training  \nIntegrated Project Management for IPPD \nRisk Management \nIntegrated Teaming \nIntegrated Supplier Management \nDecision Analysis and Resolution \nOrganizational Environment for Integration \n4 Quantitatively \nmanaged \nQuantitative \nmanagement \nOrganizational process performance \nQuantitative project management \n5 Optimizing Continuous \nprocess \nimprovement \nOrganizational innovation and deployment \nCausal analysis and resolution \n \nAhn & Chang (2004) refer to process knowledge as the knowledge associated with the activities \nperformed in each stage of a value chain from inbound logistics to customer care. Compared to \nproduct knowledge, which is directly related to the provision of products or services, process \nknowledge is a kind of glue that brings the organization assets together and enables the \nachievement of better financial and organizational and market performance (Day, 1994).  \n \nThe KM aspect of CMMISM \n \nCMMISM model components \n \nCMMISM models are designed to describe discrete levels of process improvement. In the staged \nrepresentation, maturity levels provide a recommended order for approaching process \nimprovement in stages. \nAs illustrated in Figure 1, maturity levels organize the process areas. Within the process areas \nare generic and specific goals as well as generic and specific practices. Common features \norganize generic practices. \n \n \n \n \nFigure 1: CMMISM Model Components \n \nThis representation focuses on good practices3 your organization can use to improve \nprocesses in the process areas that are within the maturity level it chooses to achieve. Before \nyou begin using a CMMISM model for improving processes, you must map your processes to \nCMMISM process areas. This mapping enables you to control process improvement in your \norganization by helping you track your organization\u2019s level of conformance to the CMMISM model \nyou are using. We shall examine now the various process areas relevant to the different \nCMMISM levels and look for the appropriate KM procedures that could support them. \n \nCMMISM Level 2 \n \nRequirement Management is the first process area addressed at this level. The purpose of this \nprocess area is to manage the requirements of the project's products and product components \nand to identify inconsistencies between those requirements and the project's plans and work \nproducts. Part of the management of requirements is to document requirements changes and \nrationale and maintain bidirectional traceability between source requirements and all product \nand product-component requirements. The use of the principles of content management4 or \neven the services of a document management system will facilitate very much this activity. \nMaturity Levels \nProcess Area 1 Process Area 2 Process Area n\nSpecific Goals Generic Goals\nCommitment\nto perform \nAbility \nto perform \nDirecting \nimplementation\nVerifying \nimplementation\nCommon Features \nSpecific Practices\nGeneric Practices\n \nProject planning is another process areas addressed at this level. It includes developing \nestimates (cost, schedule and risk estimates). If KM had been used, previous experience with \nsimilar projects could be tapped into in order to develop a more realistic estimate. The KM \nprogram we are dealing with is doing just that, and the additional purpose there is to use prior \ninformation to generate technical and price proposals5 in a controlled way. \nKM could be enhanced by CMMISM at this level due to the documentation that is required by \nCMMISM. That knowledge should be collected anyway, but using KM techniques, it would then \nbe organized for later use. KM should be applied to the lowest maturity areas since it is at this \nlevel that you would be looking for repeatability. With good documentation and wise use of \nresources, KM can enhance the CMMISM effort. \nThe specific goal of developing a project plan (Specific Goal #2, required at this level of \nCMMISM), is supported by seven specific practices: \n\u2022 Establish the budget and schedule \n\u2022 Identify project risks \n\u2022 Plan for project resources \n\u2022 Plan for needed knowledge and skills \n\u2022 Plan stakeholder involvement \n\u2022 Establish the project plan \n\u2022 Plan for data management (for Integrated Product and Process Development) \n \nPlanning for data management fits very well with the KM activity of content management which \naims at organizing the project data in an ontologically built hierarchical information tree. \nWhen integrated teams are formed, project data includes data developed and used solely within \na particular team as well as data applicable across integrated team boundaries if there are \nmultiple integrated teams. Data are the various forms of documentation required to support a \nprogram in all of its areas (e.g., administration, engineering, configuration management, \nfinancial, logistics, quality, safety, manufacturing, and procurement). The data may take any \nform (e.g., reports, manuals, notebooks, charts, drawings, specifications, files, or \ncorrespondence). The data may exist in any medium (e.g., printed or drawn on various \nmaterials, photographs, electronic, or multimedia). Data may be deliverable (e.g., items \nidentified by a program\u2019s contract data requirements) or non-deliverable (e.g., informal data, \ntrade studies and analyses, internal meeting minutes, internal design review documentation, \nlessons learned, and action items). Distribution may take many forms, including electronic \ntransmission. Nevertheless they all support the program in all of its areas.  \nThe data requirements for the project should be established for both the data items to be \ncreated and their content and form, based on a common or standard set of data requirements. \nUniform content and format requirements for data items facilitate understanding of data content \nand help with consistent management of the data resources. \nThe reason for collecting each document should be clear. This task includes the analysis and \nverification of project deliverables and non-deliverables, contract and non-contract data \nrequirements, and customer-supplied data. Often, data is unnecessarily collected with no clear \nunderstanding of how it will be used. This is wrong as knowledge capturing6 is costly and \nshould be performed only when needed. \n \nAnother process area at this level is Measurement and Analysis. This process area supports all \nthe others by providing specific practices that guide projects and organizations in aligning \nmeasurement needs and objectives with a measurement approach that will provide objective \nresults. These results can be used in making informed decisions and taking appropriate \ncorrective actions. The purpose of this process area is therefore to \"develop and sustain a \nmeasurement capability7 that is used to support management informational needs\". This \nprocess area in itself supports the need for knowledge management. It shows the need for a \nmeasurement procedure to be developed and recorded for future use. Something has to be \nestablished in order for it to be measured against in the future. \n \nConfiguration management is a process area that applies not only to projects, but also to \norganization work products such as standards, procedures, and reuse libraries. The KM activity \nrelated to new product initiative (NPI)8 process deals with the organized documentation of \ninformation developed all along the project life cycle, for the purpose of the project itself at \nfuture stages, or for the benefit of other projects who can reuse it. \n \nCMMISM Level 3 \n \nAt CMMISM level 3, organizational process definition involves development and maintenance of \nthe organisation's standard processes, along with related process assets (Carnegie Mellon \nUniversity, 1994). This is considered as the \"defined\" level of CMMISM and activities would be \nusing the organization's historical data if this information was available due to KM activity. The \ngeneric goal of institutionalizing a defined process (Generic Goal #3, required at this level of \nCMMISM), is backed up by two generic practices: \n\u2022 Generic Process #3.1 Establish a Defined Process \n\u2022 Generic Process #3.2 Collect Improvement Information \nThe collection of work products, measures, measurement results, and improvement information \nderived from planning and performing the requirements management process to support the \nfuture use and improvement of the organization\u2019s processes and process assets, fits very well \nwith the KM procedure of knowledge capture. \n \nThe CMMISM category of Process Management starts to come into effect at the 3rd level. \nProcess Management process areas contain the cross-project activities related to defining, \nplanning, resourcing, deploying, implementing, monitoring, controlling, appraising, measuring, \nand improving processes. The basic Process Management process areas provide the \norganization with a basic capability to document and share best practices9, organizational \nprocess assets, and learning across the organization. \nThe Organizational Process Focus process area helps the organization to plan and implement \norganizational process improvement based on an understanding of the current strengths and \nweaknesses of the organization\u2019s processes and process assets. Candidate improvements to \nthe organization\u2019s processes are obtained through various means. These include process-\nimprovement proposals, measurement of the processes, lessons learned10 in implementing the \nprocesses, and results of process appraisal and product evaluation activities. \nKM standardized processes for sharing knowledge11 (as listed above to be the communities of \npractice, the derivation of good practices and the usage of portals), and for knowledge capture \nand documentation12, could enhance and support the CMMISM implementation. \nAnother process area relevant to this level is the one of Technical Solution within which falls the \nspecific practice of performing Make, Buy, or Reuse Analyses (Specific Process #2.4). This \npractice will rely very much on the existence of a well documented set of competence centres. \nKM would normally include among its procedures the management of those competence \ncentres13, using attributes quite similar to those listed in the CMMISM practice. \n  \nCMMISM Level 4 \n \nOrganisations establish quantitative goals for product and process quality at CMMISM level 4. \nOrganisational process performance means an organisation creates well-defined and consistent \nmeasures for its processes and products. This serves as a foundation for quantitatively \nmanaging performance. This is the level of quantitative management and at this level, the \norganization is managed and you should be able to \"expect\" results. Defined organizational \nprocesses are present and used in new projects. The information gained and organized through \nKM will help the process run more smoothly, and with less effort due to the information being \naccessed through an organized manner. \nOne of the process areas relevant to this level is the one of Organizational Process \nPerformance. The purpose of Organizational Process Performance is to establish and maintain \na quantitative understanding of the performance of the organization\u2019s set of standard processes \nin support of quality and process-performance objectives, and to provide the process \nperformance data, baselines, and models to quantitatively manage the organization\u2019s projects. \nProcess performance is a measure of the actual results achieved by following a process. The \nexpected process performance can be used in establishing the project\u2019s quality and process-\nperformance objectives and can be used as a baseline against which actual project \nperformance can be compared. \nThe associated process performance models are used to represent past and current process \nperformance and to predict future results of the process.  \nWhen the organization has measures, data, and analytic techniques for critical process \ncharacteristics, it is able to do the following: \n\u2022 Determine whether processes are behaving consistently or have stable trends (i.e., are \npredictable) \n\u2022 Identify processes where the performance is within natural bounds that are consistent \nacross process implementation teams \n\u2022 Identify processes that show unusual (e.g., sporadic or unpredictable) behaviour \n\u2022 Identify any aspects of the processes that can be improved in the organization's set of \nstandard processes \n\u2022 Identify the implementation of a process which performs best \n \nSimilar activities are being performed in the implementation of the related KM program where \nthe performance of processes, their throughput and relation to operational and business results \nare being measured in order to continuously improve them. Some of the criteria for the selection \nof measures for KM procedures14 as well as for organizational performance are: \n\u2022 Relationship of the measures to the organization\u2019s business objectives \n\u2022 Visibility that the measures provide into the process performance \n\u2022 Availability of the measures \n\u2022 Extent to which the measures are objective \n\u2022 Frequency at which the observations of the measure can be collected \n\u2022 Extent to which the measures are controllable by changes to the process \n\u2022 Extent to which the measures represent the users\u2019 view of effective process \nperformance \n \nCMMISM Level 5 \n \nAt CMMISM level 5, the entire organisation focuses on continuous process and technology \nimprovement, which occurs through incremental or transformational advancement. Process and \ntechnology improvements are planned and managed as ordinary business activities and their \npurpose is to optimize the organisation's overall activity. One of the two process areas relevant \nto this level is the one of Organizational Innovation and Deployment. The purpose of \nOrganizational Innovation and Deployment is to select and deploy incremental and innovative \nimprovements that measurably improve the organization's processes and technologies. The \nimprovements support the organization's quality and process performance objectives as derived \nfrom the organization's business objectives. \nQuality and process-performance objectives that this process area might address include the \nfollowing: \n\u2022  Improved product quality (e.g., functionality, performance) \n\u2022  Increased productivity \n\u2022  Decreased cycle time \n\u2022  Greater customer and end-user satisfaction \n\u2022  Shorter development or production time to change functionality, add features, or \nadapt to new technologies \nAchievement of these objectives depends on the successful establishment of an infrastructure \nthat enables and encourages all people in the organization to propose potential improvements \nto the organization's processes and technologies. Higher levels of KM implementation also aim \nat involving the actual people of the organization and not only via their management. \n \nThe potential barriers contemplated for the CMMISM implementation at level 5 deploying process \nand technology improvements are similar to those faced by the implementers of KM and they \ninclude: \n\u2022 Turf guarding and parochial perspectives \n\u2022 Unclear or weak business rationale \n\u2022 Lack of short-term benefits and visible successes \n\u2022 Unclear picture of what is expected from everyone \n\u2022 Too many changes at the same time \n\u2022 Lack of involvement and support of relevant stakeholders \n \nThis is why KM implementation is often regarded as a cultural change. An organization \nimplementing KM would therefore have an easier job achieving the top CMMISM level (and vice-\nversa).  \n \nConclusions \n \nAs observed by Boehm (2000), CMM used to separate the software engineer from the concern \nfor system architecture and software requirements \u2013 \"Analysis and allocation of the system \nrequirements is not the responsibility of the software engineering group but is a prerequisite for \ntheir work\" (Paulk, Weber, et al., 1995). While the hardware and systems engineer sat around \nthe table discussing their previous system architecture, the software engineers sat on the side, \nwaiting for someone to give them a precise specification they could turn into code. CMMISM has \nprovided software engineers with a seat at the centre table, making them into concurrent \nstakeholders for the Customer and Product Requirements, Technical Solution, Project Planning, \nSupplier Agreement Management, Risk Management, and Decision Analysis and Resolution. \nExpanding from usage of a single-discipline model to a CMMISM model with multiple disciplines \nprovides an opportunity for significant reuse of existing process assets (Curtis, Phillips, et al., \n2002). This is where KM comes into the picture, defined by (Harigopal & Satyadas, 2001) as a \ndiscipline that provides the strategy, process, and technology to share and leverage information \nand expertise that will increase our level of understanding, to more effectively solve problems, \nand make decisions. It does it with procedures as \"knowledge capture\" - documenting existing \nprocesses, or \"good practices\" \u2013 disseminating and leveraging experienced procedures. \nCMMISM enables you to assess your organizational maturity and process area capability. It \nidentifies priorities for improvement, and provides guidance on the implementation of these \nimprovements. On the other hand, applying KM can bring enormous tangible and intangible \nbenefits. \nThese two area studies have different scope but similar methodologies such as maturity models \nand the evolvement through the processes. Interestingly, in the recent studies, one has taken \neffects on the other. We can see CMMISM levels and models applied to some KM models, and \nKM techniques applied to CMMISM activities. No matter how they affect each other, it is believed \nthat the debates and learning from each other should improve them both. Further, to learn from \nboth of the two studies can obtain the knowledge and clear concept of the operation of the \norganization as well as problem solving capability. When Knowledge Management is used with \nthe Capability Maturity Model Integrated, the organization becomes more efficient and effective \nin the development of the projects they are used on.  \nReferences \n \n Ahern, D.M., Clouse, A., and Turner, R.  (2001), CMMI Distilled - A Practical Introduction to \nIntegrated Process Improvement, Addison-Wesley,  \nAhmed, P.K., Lim, K.K. and Zairi, M. (1999), 'Measurement Practice for Knowledge \nManagement', The Journal of Workplace Learning, Vol. 11, No. 8, pp. 304-311. \nAhn, J.-H. and Chang, S.-G. (2004), 'Assessing the contribution of knowledge to business \nperformance: The KP3 methodology', Decision Support System, Vol. 36, pp. 403-416. \nArmistead, C. (1999), 'Knowledge Management and Process Performance', Journal of \nKnowledge Management, Vol. 3, No. 2, pp. 143-154. \nBoehm, B. (2000), 'Unifying Software Engineering and Systems Engineering', Computer, pp. \n114-116. \nCarnegie Mellon University, Software Engineering Institute. Upgrading From SW-CMM to \nCMMI\u00ae. \nCarnegie Mellon University (1994), Software Engineering Institute. The Capability Maturity \nModel: Guidelines for Improving the Software Process, Addison Wesley Longman, Inc., \nReading, MA.   \nCMMI Product Team, (2002), CMMI for System Engineering, Software Engineering, Integrated \nProduct and Process Development, and Supplier Sourcing (Staged Representation), \nReport no. CMU\/SEI-2002-TR-012; ESC-TR-2002-012, Pittsburg, PA. \nCurtis, P., Phillips, D.M. and Weszka, J.  (2002), 'CMMI - The Evolution Continues!', Systems \nEngineering, Vol. 5, No. 1, pp. 7. \nDavenport, T.H., Harris, J.G., de Long, D.W. and Jacobson, A.L.  (2001), 'Data to Knowledge to \nResults: Building an Analytic Capability', California Management Review, Vol. 43, No. 2. \nDay, G. S. (1994), 'The capabilities of market-driven organizations', Journal of Marketing, \nVol.58. No. 4, pp.37-52. \nDayan, R.  (2003),  'KM and Culture Change at Israel Aircraft Industries',  The Knowledge \nManagement Review, Vol. 6, No. 2, pp. 12-15. \nHeisig, P.  (2002), European Guide to Good Practice in Knowledge Management - Frameworks \non Knowledge Management. Fraunhofer IPK. \nJacobs, J.C. and Trienekens, J.J.M. (2002), 'Towards a Metric Based Verification and Validation \nMaturity Model', Proceedings of the 10th International Workshop on Software \nTechnology and Engineering Practice (STEP'02),  \nKristensen, K. and Westlund, A.H.  (2004), 'Accountable Business Performance Measurement \nfor Sustainable Business Excellence', Performance Measurement and Business \nResults, Vol. 15, No. 5\/6, pp. 719-734. \nLepasaar, M. and Makinen, T. 'Integrating Software Process Assessment Models Using a \nProcess Meta-Model', IEEE,  \nLiebowitz, J. and Wright, K.  (1999), 'Does Measuring Knowledge Makes \"Cents\"?',  Expert \nSystems With Applications, Vol. 17, pp. 99-103. \nLim, K.K. and Ahmed, P.K.  (2000), 'Enabling Knowledge Management: A Measurement \nPerspective', ICMIT, pp. 690-695. \nMartin, W.J.  (2000),  'Approaches to the Measurement of the Impact of Knowledge \nManagement Programmes',  Journal of Information Science, Vol. 26, No. 1, pp. 21-27. \nMiller, M.J., Pulgar-Vidal, F., and Ferrin, D.M. (2002), 'Achieving Higher Levels of CMMI \nMaturity Using Simulation', Proceedings of the 2002 Winter Simulation Conference. \nPaulk, M., Weber, C., Curtis, B., Chrissis, M. B. (1995), 'The Capability Maturity Model', Addison \nWesley. \nRamanujan, S. and Someswar, K.  (2004), 'Comparison of Knowledge Management and \nCMM\/CMMI Implementation', Journal of American Academy of Business, Vol. 4, No. \n1\/2, pp. 271-275. \nRassa, R.C., Garber, V. and Etter, D.  (2002), 'Capability Maturity Model Integration (CMMISM): \nA View From the Sponsors', Systems Engineering, Vol. 5, No. 1, pp. 3. \nVernick, J.A., Jackson Purvis M. and Thomas, W.R.  (2002), 'The SEI Transition Partner \nProgram for CMMI', Systems Engineering, Vol. 5, No. 1, pp. 27. \n \nZubrow, Dave (2003), 'Current trends in the adoption of the CMMI(R) product suite', \nProceedings of the 27th annual international computer software and applications conference. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                                 \n1 CMM, Capability Maturity Model, and Capability Maturity Modeling are registered in the U.S. \nPatent and Trademark Office. \n2 CMMI is a service mark of Carnegie Mellon University. \n3 KM procedure considered as part of the sharing chapter, as listed in the KM paragraph. \n4 KM procedure considered as part of the capturing chapter, as listed in the KM paragraph. \n5 KM procedure considered as part of the retrieving chapter, as listed in the KM paragraph. \n6 KM procedure considered as part of the capturing chapter, as listed in the KM paragraph. \n7 Compare to the KM measurement as detailed in the KM paragraph. \n8 KM procedure considered as part of the creating chapter, as listed in the KM paragraph. \n9 In the KM program we call them Good Practices that evolve eventually to become Best \nPractices. \n10 KM procedure considered as part of the capturing chapter, as listed in the KM paragraph.  \n11 As mentioned in the KM paragraph. \n12 As mentioned in the KM paragraph. \n13 KM procedure considered as part of the retrieving chapter, as listed in the KM paragraph. \n14 As mentioned in the KM paragraph. \n"}
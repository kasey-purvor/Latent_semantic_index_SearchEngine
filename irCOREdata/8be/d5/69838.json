{"doi":"10.3150\/08-BEJ176","coreId":"69838","oai":"oai:eprints.lancs.ac.uk:20931","identifiers":["oai:eprints.lancs.ac.uk:20931","10.3150\/08-BEJ176"],"title":"Optimal scaling of the random walk Metropolis on unimodal elliptically symmetric targets.","authors":["Sherlock, Chris","Roberts, Gareth"],"enrichments":{"references":[{"id":16338438,"title":"Ef\ufb01cient Metropolis jumping rules.","authors":[],"date":"1996","doi":null,"raw":"Gelman, A., Roberts, G.O. and Gilks, W.R. (1996). Ef\ufb01cient Metropolis jumping rules. In Bayesian Statistics, 5 (Alicante, 1994) 599\u2013607. New York: Oxford Univ. Press. MR1425429","cites":null},{"id":16338448,"title":"Equations of state calculations by fast computing machine.","authors":[],"date":"1953","doi":"10.1007\/978-1-4612-0667-5_6","raw":"Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H. and Teller, E. (1953). Equations of state calculations by fast computing machine. J. Chem. Phys. 21 1087\u20131091.","cites":null},{"id":16338430,"title":"From Metropolis to diffusions: Gibbs states and optimal scaling. Stochastic Process.","authors":[],"date":"2000","doi":"10.1016\/s0304-4149(00)00041-7","raw":"Breyer, L.A. and Roberts, G.O. (2000). From Metropolis to diffusions: Gibbs states and optimal scaling. Stochastic Process. Appl. 90 181\u2013206. MR1794535","cites":null},{"id":16338418,"title":"Mathematical Analysis.","authors":[],"date":"1974","doi":"10.2307\/2319053","raw":"Apostol, T.M. (1974). Mathematical Analysis. Reading, MA: Addison-Wesley. MR0344384","cites":null},{"id":16338461,"title":"Methodology for inference on the Markov modulated Poisson process and theory for optimal scaling of the random walk Metropolis.","authors":[],"date":"2006","doi":null,"raw":"Sherlock, C. (2006). Methodology for inference on the Markov modulated Poisson process and theory for optimal scaling of the random walk Metropolis. Ph.D. thesis, Lancaster University. Available at http:\/\/eprints.lancs.ac.uk\/850\/. Received February 2007 and revised October 2008","cites":null},{"id":16338453,"title":"Optimal metropolis algorithms for product measures on the vertices of a hypercube.","authors":[],"date":"1998","doi":"10.1080\/17442509808834136","raw":"Roberts, G.O. (1998). Optimal metropolis algorithms for product measures on the vertices of a hypercube. Stochastics Stochastic Rep. 62 275\u2013283. MR1613256","cites":null},{"id":16338458,"title":"Optimal scaling for various Metropolis\u2013Hastings algorithms.","authors":[],"date":"2001","doi":"10.1214\/ss\/1015346320","raw":"Roberts, G.O. and Rosenthal, J.S. (2001). Optimal scaling for various Metropolis\u2013Hastings algorithms. Statist. Sci. 16 351\u2013367. MR1888450","cites":null},{"id":16338442,"title":"Principles of Multivariate Analysis: A User\u2019s Perspective, 2nd ed.","authors":[],"date":"2000","doi":"10.2307\/2531791","raw":"Krzanowski, W.J. (2000). Principles of Multivariate Analysis: A User\u2019s Perspective, 2nd ed. Oxford Statistical Science Series 22. New York: The Clarendon Press Oxford Univ. Press. MR1133626","cites":null},{"id":16338434,"title":"Symmetric Multivariate and Related Distributions.","authors":[],"date":"1990","doi":"10.1007\/978-1-4899-2937-2","raw":"Fang, K.T., Kotz, S. and Ng, K.W. (1990). Symmetric Multivariate and Related Distributions. Monographs on Statistics and Applied Probability 36. London: Chapman and Hall. MR1071174","cites":null},{"id":16338456,"title":"Weak convergence and optimal scaling of random walk Metropolis algorithms.","authors":[],"date":"1997","doi":"10.1214\/aoap\/1034625254","raw":"Roberts, G.O., Gelman, A. and Gilks, W.R. (1997). Weak convergence and optimal scaling of random walk Metropolis algorithms. Ann. Appl. Probab. 7 110\u2013120. MR1428751","cites":null},{"id":16338423,"title":"Weak convergence of Metropolis algorithms for non-iid target distributions.","authors":[],"date":"2007","doi":"10.1214\/105051607000000096","raw":"Bedard, M. (2007). Weak convergence of Metropolis algorithms for non-iid target distributions. Ann. Appl. Probab. 17 1222\u20131244. MR2344305","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2009","abstract":"Scaling of proposals for Metropolis algorithms is an important practical problem in MCMC implementation. Criteria for scaling based on empirical acceptance rates of algorithms have been found to work consistently well across a broad range of problems. Essentially, proposal jump sizes are increased when acceptance rates are high and decreased when rates are low. In recent years, considerable theoretical support has been given for rules of this type which work on the basis that acceptance rates around 0.234 should be preferred. This has been based on asymptotic results which approximate high dimensional algorithm trajectories by diffusions. In this paper we develop a novel approach to understanding 0.234 which avoids the need for diffusion limits. We derive explicit formulae for algorithm efficiency and acceptance rates as functions of the scaling parameter. We apply these to the family of elliptically symmetric target densities, where further illuminating explicit results are possible. Under suitable conditions, we verify the 0.234 rule for a new class of target densities. Moreover, we can characterise cases where 0.234 fails to hold, either because the target density is too diffuse in a sense we make precise, or because the eccentricity of the target density is too severe, again in a sense we make precise. We provide numerical verifications of our results","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/69838.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/20931\/1\/http___projecteuclid.org_DPubS_Repository_1.0_Disseminate_view=body%26id=pdfview_1%26handle=euclid.pdf","pdfHashValue":"0b12279916cdff63d95f19abc920a58b5d6689a4","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:20931<\/identifier><datestamp>\n      2018-01-24T02:35:24Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Optimal scaling of the random walk Metropolis on unimodal elliptically symmetric targets.<\/dc:title><dc:creator>\n        Sherlock, Chris<\/dc:creator><dc:creator>\n        Roberts, Gareth<\/dc:creator><dc:subject>\n        QA Mathematics<\/dc:subject><dc:description>\n        Scaling of proposals for Metropolis algorithms is an important practical problem in MCMC implementation. Criteria for scaling based on empirical acceptance rates of algorithms have been found to work consistently well across a broad range of problems. Essentially, proposal jump sizes are increased when acceptance rates are high and decreased when rates are low. In recent years, considerable theoretical support has been given for rules of this type which work on the basis that acceptance rates around 0.234 should be preferred. This has been based on asymptotic results which approximate high dimensional algorithm trajectories by diffusions. In this paper we develop a novel approach to understanding 0.234 which avoids the need for diffusion limits. We derive explicit formulae for algorithm efficiency and acceptance rates as functions of the scaling parameter. We apply these to the family of elliptically symmetric target densities, where further illuminating explicit results are possible. Under suitable conditions, we verify the 0.234 rule for a new class of target densities. Moreover, we can characterise cases where 0.234 fails to hold, either because the target density is too diffuse in a sense we make precise, or because the eccentricity of the target density is too severe, again in a sense we make precise. We provide numerical verifications of our results.<\/dc:description><dc:date>\n        2009<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/20931\/1\/http___projecteuclid.org_DPubS_Repository_1.0_Disseminate_view=body%26id=pdfview_1%26handle=euclid.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.3150\/08-BEJ176<\/dc:relation><dc:identifier>\n        Sherlock, Chris and Roberts, Gareth (2009) Optimal scaling of the random walk Metropolis on unimodal elliptically symmetric targets. Bernoulli, 15 (3). pp. 774-798. ISSN 1350-7265<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/20931\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.3150\/08-BEJ176","http:\/\/eprints.lancs.ac.uk\/20931\/"],"year":2009,"topics":["QA Mathematics"],"subject":["Journal Article","PeerReviewed"],"fullText":"Bernoulli 15(3), 2009, 774\u2013798\nDOI: 10.3150\/08-BEJ176\nOptimal scaling of the random walk\nMetropolis on elliptically symmetric\nunimodal targets\nCHRIS SHERLOCK1 and GARETH ROBERTS2\n1Department of Mathematics and Statistics, Lancaster University, Lancaster, LA1 4YF, UK.\nE-mail: c.sherlock@lancaster.ac.uk\n2Department of Statistics, University of Warwick, Coventry, CV4 7AL, UK.\nE-mail: gareth.o.roberts@warwick.ac.uk\nScaling of proposals for Metropolis algorithms is an important practical problem in MCMC implementation.\nCriteria for scaling based on empirical acceptance rates of algorithms have been found to work consistently\nwell across a broad range of problems. Essentially, proposal jump sizes are increased when acceptance\nrates are high and decreased when rates are low. In recent years, considerable theoretical support has been\ngiven for rules of this type which work on the basis that acceptance rates around 0.234 should be preferred.\nThis has been based on asymptotic results that approximate high dimensional algorithm trajectories by\ndiffusions. In this paper, we develop a novel approach to understanding 0.234 which avoids the need for\ndiffusion limits. We derive explicit formulae for algorithm efficiency and acceptance rates as functions of\nthe scaling parameter. We apply these to the family of elliptically symmetric target densities, where further\nilluminating explicit results are possible. Under suitable conditions, we verify the 0.234 rule for a new class\nof target densities. Moreover, we can characterise cases where 0.234 fails to hold, either because the target\ndensity is too diffuse in a sense we make precise, or because the eccentricity of the target density is too\nsevere, again in a sense we make precise. We provide numerical verifications of our results.\nKeywords: optimal acceptance rate; optimal scaling; random walk Metropolis\n1. Introduction\nThe Metropolis\u2013Hastings updating scheme provides a very general class of algorithms for obtain-\ning a dependent sample from a target distribution, \u03c0(\u00b7). Given the current value X, a new value X\u2217\nis proposed from a pre-specified Lebesgue density q(x\u2217|x) and is then accepted with probability\n\u03b1(x,x\u2217) = min (1, (\u03c0(x\u2217)q(x|x\u2217))\/(\u03c0(x)q(x\u2217|x))). If the proposed value is accepted it becomes\nthe next current value (X\u2032 \u2190 X\u2217), otherwise the current value is left unchanged (X\u2032 \u2190 X).\nConsider the d-dimensional random walk Metropolis (RWM) [7]:\nq(x\u2217|x) = 1\n\u03bbd\nr\n(\nx\u2217 \u2212 x\n\u03bb\n)\n= 1\n\u03bbd\nr\n(\ny\u2217\n\u03bb\n)\n, (1)\n1350-7265 \u00a9 2009 ISI\/BS\nOptimal scaling of the random walk Metropolis 775\nwhere y\u2217 := x\u2217 \u2212 x is the proposed jump, and r(y) = r(\u2212y) for all y. In this case the acceptance\nprobability simplifies to\n\u03b1(x,x\u2217) = min\n(\n1,\n\u03c0(x\u2217)\n\u03c0(x)\n)\n. (2)\nNow consider the behaviour of the RWM as a function of the scale of proposed jumps, \u03bb, and\nsome measure of the scale of variability of the target distribution, \u03b7. If \u03bb \u0005 \u03b7 then, although\nproposed jumps are often accepted, the chain moves slowly and exploration of the target distri-\nbution is relatively inefficient. If \u03bb \u0006 \u03b7 then many proposed jumps are not accepted, the chain\nrarely moves and exploration is again inefficient. This suggests that given a particular target and\nform for the jump proposal distribution, there may exist a finite scale parameter for the proposal\nwith which the algorithm will explore the target as efficiently as possible. We are concerned with\nthe definition and existence of an optimal scaling, its asymptotic properties and the process of\nfinding it. We start with a brief review of current literature on the topic.\n1.1. Existing results for optimal scaling of the RWM\nExisting literature on this problem has concentrated on obtaining a limiting diffusion process\nfrom a sequence of Metropolis algorithms with increasing dimension. The speed of this limiting\ndiffusion is then maximised with respect to a transformation of the scale parameter to find the\noptimally scaled algorithm. Roberts et al. [9] first follow this program for densities of the form\n\u03c0(x) =\nd\u220f\ni=1\nf (xi) (3)\nusing Gaussian jump proposals, Y(d) \u223c N(0, \u03c3 2d Id). Here and throughout this article Id denotes\nthe d-dimensional identity matrix. For high dimensional targets which satisfy certain moment\nconditions it is shown that the optimal value of the scale parameter satisfies d1\/2\u03bb\u02c6d = l, for some\nfixed l which is dependent on the roughness of the target. Particularly appealing, however, from\na practical perspective, is the following distribution-free interpretation of the optimal scaling\nfor the class of distributions given by (3). It is the scaling that leads to the proportion 0.234 of\nproposed moves being accepted.\nEmpirically this \u201c0.234\u201d rule has been observed to be approximately right much more gener-\nally. Extensions and generalisations of this result can be found in Roberts and Rosenthal [10],\nwhich also provides an accessible review of the area, and Bedard [2], Breyer and Roberts [3],\nRoberts [8]. The focus of much of this work is in trying to characterise when the \u201c0.234\u201d rule\nholds and to explain how and why it breaks down in other situations.\nOne major disadvantage of the diffusion limit work is its reliance on asymptotics in the dimen-\nsionality of the problem. Although it is often empirically observed that the limiting behaviour can\nbe seen in rather small dimensional problems (see, e.g., Gelman et al. [5]) it is difficult to quantify\nthis in any general way.\nIn this paper we adopt a finite dimensional approach, deriving and working with explicit solu-\ntions for algorithm efficiency and overall acceptance rates.\n776 C. Sherlock and G. Roberts\n1.2. Efficiency and expected acceptance rate\nIn order to consider the problem of optimising the algorithm, an optimisation criterion needs\nto be chosen. Unfortunately this is far from unique. In practical MCMC, interest may lie in\nthe estimation of a collection of expected functionals. For any one of these functionals, f say,\na plausible criterion to minimise is the stationary integrated autocorrelation time for f given by\n\u03c4f = 1 + 2\n\u221e\u2211\ni=1\nCor(f (X0), f (Xi)).\nUnder appropriate conditions, the MCMC central limit theorem for {f (Xi)} gives a Monte Carlo\nvariance proportional to \u03c4f . This approach has two major disadvantages. First, estimation of \u03c4f\nis notoriously difficult, and second, this optimisation criterion gives a different solution for the\n\u201coptimal\u201d chain for different functionals f .\nIn the diffusion limit, the problem of non-uniqueness of the optimal chain is avoided since\nin all cases \u03c4f is proportional to the inverse of the diffusion speed. This suggests that plausible\ncriteria might be based on optimising properties of single increments of the chain.\nThe most general target distributions that we shall examine here possess elliptical symmetry. If\na d-dimensional target distribution has elliptical contours then there is a simple invertible linear\ntransformation T :\td \u2192 \td which produces a spherically symmetric target. To fix it (up to an\narbitrary rotation) we define T to be the transformation that produces a spherically symmetric\ntarget with unit scale parameter. Here the exact meaning of \u201cunit scale parameter\u201d may be decided\narbitrarily or by convention. The scale parameter \u03b2i along the ith principal axis of the ellipse is\nthe ith eigenvalue of T\u22121.\nLet X and X\u2032 be consecutive elements of a stationary chain exploring a d-dimensional tar-\nget distribution. A natural efficiency measure for elliptical targets is Mahalanobis distance, for\nexample, Krzanowski [6]:\nS2d := E\n[\u2016X\u2032 \u2212 X\u20162\u03b2] := E\n[\nd\u2211\ni=1\n1\n\u03b22i\n(X\u2032i \u2212Xi)2\n]\n= E\n[\nd\u2211\ni=1\n1\n\u03b22i\nY 2i\n]\n, (4)\nwhere X\u2032i and Xi are the components of X\u2032 and X along the ith principal axis and Yi are com-\nponents of the realised jump Y = X\u2032 \u2212 X. We refer to this as the expected square jump dis-\ntance, or ESJD. We will relate ESJD to expected acceptance rate (EAR) which we define as\n\u03b1d := E[\u03b1(X,X\u2217)], where the expectation is with respect to the joint law for the current value\nX and the proposed value X\u2217. Note that we are not interested in the value of the ESJD itself but\nonly in the scaling and EAR at which the maximum ESJD is attained.\n1.3. Outline of this paper\nThe body of this paper investigates the RWM algorithm on spherically and then elliptically sym-\nmetric unimodal targets. Section 2 considers finite dimensional algorithms on spherically sym-\nmetric unimodal targets and derives explicit formulae for ESJD and EAR in terms of the scale\nOptimal scaling of the random walk Metropolis 777\nparameter associated with the proposed jumps (Theorem 1). Several example algorithms are\nthen introduced and the forms of \u03b1d(\u03bb) and S2d(\u03bb) are derived for specific values of d either ana-\nlytically or by numerical integration. Numerical results for the relationship between the optimal\nacceptance rate and dimension are then described; in most of these examples the limiting optimal\nacceptance rate appears to be less than 0.234.\nThe explicit formulae in Theorem 1 involve the target\u2019s marginal one-dimensional distribu-\ntion function. Theorem 2 of Section 3 provides a limiting form for the marginal one-dimensional\ndistribution function of a spherically symmetric random variable as d \u2192 \u221e and Theorem 3\ncombines this with a result from measure theory to provide limiting forms for EAR and ESJD\nas d \u2192 \u221e. A natural next step would be to use the limiting ESJD to estimate a limiting optimal\nscale parameter rather than directly examining the limit of the optimal scale parameters of the\nfinite dimensional ESJDs. It is shown that this process is sometimes invalid when the target con-\ntains a mixture of scales that produce local maxima in ESJD and whose ratio increases without\nbound. Exact criteria are provided in Lemma 2 and are related to the numerical examples.\nMany \u201cstandard\u201d sequences of distributions satisfy the condition that as d \u2192 \u221e the proba-\nbility mass becomes concentrated in a spherical shell which itself becomes infinitesimally thin\nrelative to its radius. Thus the random walk on a rescaling of the target is, in the limit, effec-\ntively confined to the surface of this shell. Theorem 4 considers RWM algorithms on sequences\nof spherically symmetric unimodal targets where the sequence of proposal distributions satisfies\nthis \u201cshell condition\u201d. It is shown that if the target sequence also satisfies the \u201cshell condition\u201d\nthen the limiting optimal EAR is 0.234; however, if the target mass does not converge to an\ninfinitesimally thin shell then the limiting optimal EAR (if it exists) is strictly less than 0.234.\nRescalings of both the target and proposal are usually required in order to stabilise the radius of\nthe shell, whether or not it becomes infinitesimally thin. These influence the form of the optimal\nscale parameter so that in general it is not proportional to d\u22121\/2. Corollary 4 provides an explicit\nformula that is consistent with the numerical examples.\nSection 4 extends the results for finite dimensional random walks to all elliptically symmetric\ntargets. Limit results are extended through Theorem 5 to sequences of elliptically symmetric\ntargets for which the ellipses do not become too eccentric. The article concludes in Section 5\nwith a discussion.\n2. Exact results for finite dimension\nIn this section we derive Theorem 1, which provides exact formulae for ESJD and EAR for a ran-\ndom walk Metropolis algorithm acting on a unimodal spherically symmetric target. The formulae\nin Theorem 1 refer to the target\u2019s marginal one-dimensional distribution function; these are then\nconverted to use the more intuitive marginal radial distribution function. Several example targets\nare introduced and results from exact calculations of ESJD and EAR are presented.\nWe adopt the notation outlined in Section 1.2. All distributions (target and proposal) are as-\nsumed to have densities with respect to Lebesgue measure, and we consider the chain to be\nstationary so that the marginal densities of both X and X\u2032 are \u03c0(\u00b7). We also assume that the space\nof possible values for element x of a d-dimensional chain is \td .\nWe consider only target densities with a single mode; however, the density need not decrease\nwith strict monotonicity and may have a series of plateaux. We refer to random variables with\n778 C. Sherlock and G. Roberts\nsuch densities as unimodal. In this section and the section that follows we further restrict our\nchoice of target to include only random variables where the density has spherical contour lines.\nSuch random variables are termed isotropic or spherically symmetric. ESJD is as defined in (4)\nwhere the expectation is taken with respect to the joint law for the current position and the re-\nalised jump. For a spherical target \u03b2i = \u03b2\u2200i, the ESJD is proportional to the expected squared\nEuclidean distance, and both are maximised by the same scaling \u03bb\u02c6. Since the constant of propor-\ntionality, \u03b2 , derives from an arbitrary definition of \u201cunit scale parameter\u201d, we simply set it to 1\nfor spherically symmetric random variables.\nDenote the one-dimensional marginal distribution function of a general d-dimensional target\nX(d) along unit vector y\u02c6 as F1|d(x). When X(d) is spherically symmetric, this is independent\nof y\u02c6, and we simply refer to it as the one-dimensional marginal distribution function of X(d).\nThe following is proved in Appendix A.1.\nTheorem 1. Consider a stationary random walk Metropolis algorithm on a spherically symmet-\nric unimodal target which has marginal one-dimensional distribution function F1|d(x). Let jumps\nbe proposed from a symmetric density as defined in (1). In this case the expected acceptance rate\nand the expected square jump distance are\n\u03b1d(\u03bb) = 2E\n[\nF1|d\n(\u2212 12\u03bb|Y|)] and (5)\nS2d(\u03bb) = 2\u03bb2E\n[|Y|2F1|d(\u2212 12\u03bb|Y|)], (6)\nwhere the expectation is taken with respect to measure r(\u00b7).\nThe marginal distribution function F1|d(\u2212\u03bb|Y|\/2) is bounded and decreasing in \u03bb. Also\nlimx\u2192\u221e F1|d(\u2212x) = 0 and by symmetry, provided F1|d(\u00b7) is continuous at the origin,\nlimx\u21920 F1|d(\u2212x) = 0.5. Applying the bounded convergence theorem to (5) we therefore ob-\ntain the following intuitive result:\nCorollary 1. Let \u03bb be the scaling parameter for any RWM algorithm on a unimodal isotropic\ntarget Lebesgue density. In this situation the EAR at stationarity \u03b1d(\u03bb) decreases with increas-\ning \u03bb, with lim\u03bb\u21920 \u03b1d(\u03bb) = 1 and lim\u03bb\u2192\u221e \u03b1d(\u03bb) = 0.\nIn our search for an optimal scaling there is an implicit assumption that such a scaling exists.\nThis was justified intuitively in Section 1 but the existence of an optimal scaling has previously\nonly been proven for the limiting diffusion process as d \u2192 \u221e; see Roberts et al. [9]. Starting\nfrom Theorem 1 the following is relatively straightforward to prove (see Sherlock [11]) and starts\nto justify a search for an optimal scaling for a finite dimensional random walk algorithm rather\nthan a limit process.\nCorollary 2. Consider a spherically symmetric unimodal d-dimensional target Lebesgue density\n\u03c0(x). Let \u03c0(\u00b7) be explored via an RWM algorithm with proposal Lebesgue density 1\n\u03bbd\nr(y\/\u03bb). If\nOptimal scaling of the random walk Metropolis 779\nE\u03c0 [|X|2] < \u221e and Er [|Y|2] < \u221e then the ESJD of the Markov chain at stationarity attains its\nmaximum at a finite non-zero value (or values) of \u03bb.\nFor the remainder of this section we examine the behaviour of real, finite dimensional exam-\nples of random walk algorithms. As well as being of interest in its own right, this will motivate\nSection 3 where Theorem 1 will provide the basis from which properties of EAR and ESJD are\nobtained as dimension d \u2192 \u221e. To render Theorem 1 of more use for practical calculation, we\nfirst convert it to involve the more intuitive marginal radial distribution rather than the marginal\none-dimensional distribution function.\nWe introduce some further notation; write Fd(\u00b7) and f d(\u00b7) for the marginal radial distrib-\nution and density functions of d-dimensional spherically symmetric target X(d); these are the\ndistribution and density functions of |X(d)|. The density of |Y| (when \u03bb = 1) is denoted rd(\u00b7).\nWe start with a form for the one-dimensional marginal distribution function of a spherically\nsymmetric random variable in terms of its marginal radial distribution function. Derivation of\nthis result from first principles is straightforward; see Sherlock [11].\nLemma 1. For any d-dimensional spherically symmetric random variable with continuous mar-\nginal radial distribution function Fd(r) with Fd(0) = 0, the one-dimensional marginal distribu-\ntion function along any axis is\nF1|d(x1) = 12\n(\n1 + sign(x1)EX(d)\n[\nGd\n( |x1|2\n|X(d)|2\n)])\n(d \u2265 1), (7)\nwhere sign(x) = 1 for x \u2265 0 and sign(x) = \u22121 for x < 0, and Gd(\u00b7) is the distribution function\nof Ud , with U1 = 1 and\nUd \u223c Beta\n(\n1\n2\n,\nd \u2212 1\n2\n)\n(d > 1).\nFor the RWM we are concerned only with targets with Lebesgue densities. In this case both\nthe marginal one-dimensional and radial distribution functions are continuous, and Fd(0) = 0 as\nthere can be no point mass at the origin (or anywhere else). Substituting (7) into (5) and (6) gives\n\u03b1d(\u03bb) = EY,X(d)\n[\nKd\n(\n\u03bb|Y|\n2|X(d)|\n)]\nand S2d(\u03bb) = \u03bb2EY,X(d)\n[\n|Y|2Kd\n(\n\u03bb|Y|\n2|X(d)|\n)]\n,\nwhere Y is a random variable with density r(\u00b7) and Kd(x) := 1 \u2212 Gd(x2). The expectations\ndepend on X and Y only through their moduli, thus allowing expressions for EAR and ESJD\nin terms of simple double integrals involving the marginal radial densities of |X| and |Y|. For\nunimodal spherically symmetric targets we therefore obtain:\n\u03b1d(\u03bb) =\n\u222b \u221e\n0\ndy\n\u222b \u221e\n\u03bby\/2\ndx rd(y)f d(x)Kd\n(\n\u03bby\n2x\n)\n, (8)\nS2d(\u03bb) = \u03bb2\n\u222b \u221e\n0\ndy\n\u222b \u221e\n\u03bby\/2\ndx rd(y)f d(x)y\n2Kd\n(\n\u03bby\n2x\n)\n. (9)\n780 C. Sherlock and G. Roberts\nSince X(d) is spherically symmetric f d(|x|) = ad |x|d\u22121\u03c0(x), where ad := 2\u03c0d\/2\/\t(d\/2);\nsee [1], Chapter 15. In the examples below we also consider only spherically symmetric proposals\nso that rd(|y|) = ad |y|d\u22121rd(y).\n2.1. Explicit and computational results\nUsing (8) and (9) we first examine the dependency of EAR and ESJD on \u03bb for any given di-\nmension. We then examine the behaviour of the optimal scaling and optimal acceptance rate as\ndimension d increases.\nNow K1(u) = 1 for u < 1 and K1(u) = 0 otherwise, and so for one-dimensional RWM al-\ngorithms the integrals in (8) and (9) may sometimes be evaluated exactly. For example, with a\nGaussian target and Gaussian proposal, (8) and (9) give\n\u03b11(\u03bb) = 2\n\u03c0\ntan\u22121\n(\n2\n\u03bb\n)\nand\nS21(\u03bb) =\n2\u03bb2\n\u03c0\n(\ntan\u22121\n(\n2\n\u03bb\n)\n\u2212 2\u03bb\n\u03bb2 + 4\n)\n. (10)\nMaximising (10) numerically gives an optimal scaling of \u03bb\u02c6 \u2248 2.43 which corresponds to an\noptimal EAR of 0.439.\nWith both target and proposal following a double exponential distribution, (8) and (9) produce\n\u03b11(\u03bb) = 2\n\u03bb+ 2 and S\n2\n1(\u03bb) =\n16\u03bb2\n(\u03bb+ 2)3 .\nS21 and \u03b11 are thus related by the simple analytical expression S\n2\n1 = 8\u03b11(1 \u2212 \u03b11)2, and the ESJD\nattains a maximum at an EAR of 1\/3, for which \u03bb\u02c6 = 4.\nWe now consider two example targets with d = 10: first, a simple Gaussian (\u03c0d(x) \u221d e\u2212|x|2\/2),\nand second, a mixture of Gaussians:\n\u03c0d(x) \u221d (1 \u2212 pd)e\u2212|x|2\/2 + pd 1\ndd\ne\u2212|x|2\/(2d2) (d \u2265 2), (11)\nwith pd = 1\/d2. Both targets are explored using spherically symmetric Gaussian proposals; re-\nsults are shown in Figure 1. As with the previous two examples, increasing \u03bb from 0 to \u221e\ndecreases the EAR from 1 to 0, as deduced in Corollary 1. Further, in all four examples, as noted\nin Corollary 2, ESJD achieves a global maximum at finite, strictly positive values of \u03bb. In the\nfirst three examples ESJD as a function of the scaling shows a single maximum; however, in\nthe mixture example similar high ESJDs are achieved with two very different scale parameters\n(approximately 0.8 and 7.6). The acceptance rates at these maxima are 0.26 and 0.0026, respec-\ntively. The values \u03bb\u02c6 = 0.8 and \u03b1\u02c6 = 0.26 are almost identical to the optimal values for exploring\na standard ten-dimensional Gaussian and so are ideal for exploring the first component of the\nmixture. Optimal exploration of the second component is clearly to be achieved by increasing\nOptimal scaling of the random walk Metropolis 781\nFigure 1. Plots for a Gaussian target (left) and the Gaussian mixture target of (11) with pd = 1\/d2 (right),\nboth at d = 10 and with a Gaussian jump proposal. Panels from top to bottom are (i) ESJD against scaling,\n(ii) EAR against scaling and (iii) ESJD against EAR.\nthe scale parameter by a factor of 10; however, the second component has a mixture weight of\n0.01 and so the acceptance rate for such proposals is reduced accordingly. The mixture weighting\nof the second component, 1\/d2, is just sufficient to balance the increase in optimal jump size for\nthat component, with the result that the two peaks in ESJD are of equal heights.\nWe next examine the behaviour of the optimal scaling and the corresponding EAR as d in-\ncreases. Calculations are performed for eight different targets:\n1. Gaussian density: \u03c0d(x) \u221d e\u2212|x|2\/2;\n2. exponential density: \u03c0d(x) \u221d e\u2212|x|;\n3. target with a Gaussian marginal radial density: \u03c0d(x) \u221d |x|\u2212d+1e\u2212|x|2\/2;\n4. target with an exponential marginal radial density: \u03c0d(x) \u221d |x|\u2212d+1e\u2212|x|;\n5. lognormal density altered so as to be unimodal:\n\u03c0d(x) \u221d 1{|x|\u2264e\u2212(d\u22121)} + e\u2212(log |x|+(d\u22121))\n2\/21{|x|>e\u2212(d\u22121)};\n6. the mixture of Gaussians given by (11) with pd = 0.2;\n7. the mixture of Gaussians given by (11) with pd = 1\/d ;\n8. the mixture of Gaussians given by (11) with pd = 1\/d3.\n782 C. Sherlock and G. Roberts\nFigure 2. Plots of the optimal EAR \u03b1\u02c6 against dimension for example targets 1\u20134 using a Gaussian jump\nproposal. The horizontal dotted line approximates the apparent asymptotically optimal acceptance rate of\n0.234 in the first two plots and 0.10 and 0.06 in the third and fourth plots, respectively.\nProposals are generated from a Gaussian density. For each combination of target and proposal\nsimple numerical routines are employed to find the scaling \u03bb\u02c6 that produces the largest ESJD.\nSubstitution into (8) gives the corresponding optimal EAR \u03b1\u02c6.\nFigure 2 shows plots of optimal EAR against dimension for example targets 1\u20134. The first of\nthese is entirely consistent with Figure 4 in Roberts and Rosenthal [10], which shows optimal\nacceptance rates obtained through repeated runs of the RWM algorithm. The first two are consis-\ntent with a conjecture that the optimal EAR approaches 0.234 as d \u2192 \u221e; however, for examples\ntargets 3 and 4, the optimal EAR appears to approach limits of approximately 0.10 and 0.06,\nrespectively.\nFor target 5 with d = 1,2 or 3, plots of ESJD against scale parameter, EAR against scale pa-\nrameter and ESJD against EAR (not shown) are heuristically similar to those for the standard\nGaussian target in Figure 1. However, for d = 1, 2 and 3 the optimal EARs are approximately\n0.111, 0.010 and 0.00057, respectively, and appear to be approaching a limiting optimal accep-\ntance rate of 0.\nFigure 3 shows plots of EAR against dimension for the three mixture targets (6\u20138). Here the\nasymptotically optimal EAR appears to be approximately 0.234\/5, 0 and 0.234, respectively.\nThe limiting behaviour of each of these examples is explained in the next section.\nOptimal scaling of the random walk Metropolis 783\nFigure 3. Plots of the optimal EAR \u03b1\u02c6 against dimension for example targets 6\u20138 using a Gaussian jump\nproposal. The horizontal dotted line in each plot represents the apparent asymptotically optimal acceptance\nrate of 0.234\/5, 0 and 0.234, respectively.\n3. Limit results for spherically symmetric distributions\nTheorem 1 provides exact analytical forms for the EAR and ESJD of an RWM algorithm on\na unimodal spherically symmetric target in terms of the target\u2019s marginal one-dimensional dis-\ntribution function. In this section we investigate the behaviour of EAR and ESJD in the limit\nas dimension d \u2192 \u221e. As groundwork for this investigation we must first examine the possible\nlimiting forms of the marginal one-dimensional distribution function of a spherically symmetric\nrandom variable. We adopt the following notation: Convergence in distribution is denoted by\nD\u2212\u2192; convergence in probability is denoted by p\u2212\u2192 and convergence in mean square by m.s.\u2212\u2192.\nConvergence of the sequence of characteristic functions of a sequence of d-dimensional\nisotropic random variables (indexed by d) to that of a mixture of normals is proved as Theo-\nrem 2.21 of Fang et al. [4]. Thus the limiting marginal distribution along any given axis may be\nwritten as X1 = RZ with Z a standard Gaussian and R the mixing distribution. Sherlock [11]\nproves from first principles the following extension.\nTheorem 2. Let X(d) be a sequence of d-dimensional spherically symmetric random variables.\nIf there is a kd such that |X(d)|\/kd D\u2212\u2192 R then the sequence of marginal one-dimensional distri-\n784 C. Sherlock and G. Roberts\nbutions of X(d) satisfies\nF1|d\n(\nkd\nd1\/2\nx1\n)\n\u2192 \n(x1) := ER\n[\n\u000b\n(\nx1\nR\n)]\n,\nwhere \u000b(\u00b7) is the standard Gaussian distribution function.\n|X(d)| possesses a Lebesgue density and therefore no point mass at the origin; however, the\nrescaled limit R may possess such a point mass. Provided R has no point mass at 0, the limit-\ning marginal one-dimensional distribution function \n(x1) as defined in Theorem 2 is therefore\ncontinuous for all x \u2208 \t. This continuity implies that the limit in Theorem 2 is approached uni-\nformly in x1, and for this reason the lack of a radial point mass at 0 is an essential requirement\nin Theorem 3.\nThe condition of convergence of the rescaled modulus to 1 or to random variable R will turn\nout to be the key factor in determining the behaviour of the optimal EAR as d \u2192 \u221e; we now\nexamine this limiting convergence behaviour in more detail.\nFor many standard sequences of density functions there is a kd such that |X(d)|\/kd p\u2212\u2192 1.\nThis includes example targets 1 and 2 from Section 2.1, and more generally any density of the\nform \u03c0d(x) \u221d |x|ae\u2212|x|c . An intuitive understanding of target sequences satisfying this condition\nis that, as d \u2192 \u221e the probability mass becomes concentrated in a spherical shell which itself\nbecomes infinitesimally thin relative to its radius. The random walk on a rescaling of the target\nis, in the limit, effectively confined to the surface of this shell.\nExample targets 3 and 4 have marginal radial distributions which are always respectively a\npositive unit Gaussian and a unit exponential. The first term in the density of example target 5\nsimply ensures unimodality and becomes increasingly unimportant as d increases. Trivial alge-\nbraic rearrangement of the second component shows that its marginal radial distribution has the\nsame log-normal form whatever the dimension. Example targets 6\u20138 are examined in detail in\nSection 3.2.\n3.1. A limit theorem for EAR and ESJD\nWe now return to the RWM and derive limiting forms for ESJD and EAR on unimodal spherically\nsymmetric targets as d \u2192 \u221e. Henceforth it is assumed that the radial distribution of the target,\nrescaled by a suitable quantity k(d)x , converges weakly to some continuous limiting distribution,\nthat of a random variable R. From Theorem 2, the limiting marginal distribution function \n(\u00b7)\nis in general a scaled mixture of Gaussian distribution functions but in the special case that R\nis a point mass at 1 the scaled mixture of Gaussians clearly reduces to the standard Gaussian\ncumulative distribution function \u000b(\u00b7); F1|d( kdd1\/2 x1) \u2192 \u000b(x1).\nConsider a sequence of jump proposal random variables {Y(d)} with unit scale parameter. If\nthere exist k(d)y such that |Y(d)|\/k(d)y converges (in a sense to be defined) then simple limit results\nare possible. Implicit in the derivation of these limit results is a transformation of our target and\nOptimal scaling of the random walk Metropolis 785\nproposal: X\u02dc(d) \u2190 X(d)\/k(d)x and Y\u02dc(d) \u2190 Y(d)\/k(d)y . We define a transformed scale parameter\n\u03bcd := 12\nd1\/2k(d)y\nk\n(d)\nx\n\u03bbd . (12)\nA random walk on target density (k(d)x )d\u03c0d(k(d)x x) using proposal density (k(d)y )drd(k(d)y y) and\nscale parameter 2\u03bcd is therefore equivalent to a random walk on \u03c0d(x) using proposal rd(y) and\na scale parameter l = d1\/2\u03bbd , a quantity which is familiar from the diffusion-based approach\nto optimal scaling (see Section 1.1). The following theorem characterises the limiting behav-\niour for EAR and ESJD for fixed values, \u03bc, of the transformed scale parameter; it is proved in\nAppendix A.2.\nTheorem 3. Let {X(d)} be a sequence of d-dimensional unimodal spherically symmetric target\nrandom variables and let {Y(d)} be the corresponding sequence of jump proposals. If there exist\n{k(d)x } such that |X(d)|\/k(d)x D\u2212\u2192 R where R has no point mass at 0 then for fixed \u03bc:\n(i) If there exist {k(d)y } such that |Y(d)|\/k(d)y D\u2212\u2192 Y then\n\u03b1d(\u03bc) \u2192 2E\n[\n\u000b\n(\n\u2212\u03bcY\nR\n)]\n. (13)\n(ii) If in fact |Y(d)|\/k(d)y m.s.\u2212\u2192 Y with E[Y 2] < \u221e then\nd\n4k(d)x\n2 S\n2\nd(\u03bc) \u2192 2\u03bc2E\n[\nY 2\u000b\n(\n\u2212\u03bcY\nR\n)]\n. (14)\nThe remainder of this paper focusses on an important corollary to Theorem 3, which is ob-\ntained by setting Y = 1.\nCorollary 3. Let {X(d)}, {Y(d)}, {k(d)x } and {k(d)y } be as defined in Theorem 3 and let R be any\nnon-negative random variable with no point mass at 0.\n(i) If |X(d)|\/k(d)x D\u2212\u2192 R and |Y(d)|\/k(d)y m.s.\u2212\u2192 1\n\u03b1d(\u03bc) \u2192 2E\n[\n\u000b\n(\n\u2212\u03bc\nR\n)]\n, (15)\nd\n4k(d)x\n2 S\n2\nd(\u03bc) \u2192 2\u03bc2E\n[\n\u000b\n(\n\u2212\u03bc\nR\n)]\n. (16)\n(ii) If |X(d)|\/k(d)x p\u2212\u2192 1 and |Y(d)|\/k(d)y m.s.\u2212\u2192 1\n\u03b1d(\u03bc) \u2192 2\u000b(\u2212\u03bc), (17)\nd\n4k(d)x\n2 S\n2\nd(\u03bc) \u2192 2\u03bc2\u000b(\u2212\u03bc). (18)\n786 C. Sherlock and G. Roberts\nWith these asymptotic forms for EAR and ESJD we are finally equipped to examine the issue\nof optimal scaling in the limit as d \u2192 \u221e.\n3.2. The validity and existence of an asymptotically optimal scaling\nIt was shown in Section 2 that there is at least one finite optimal scaling for any spherically\nsymmetric unimodal finite dimensional target with finite second moment provided the second\nmoment of the proposal is also finite. We now investigate the validity and existence of a finite\nasymptotically optimal (transformed) scaling for spherically symmetric targets as d \u2192 \u221e.\n1. Validity: We shall obtain an asymptotically optimal scaling by maximising the limiting ef-\nficiency function. Ideally we would instead find the limit of the sequence of scalings which\nmaximise each finite dimensional efficiency function. We investigate the circumstances un-\nder which these are equivalent.\n2. Existence: It is not always the case that the limiting efficiency function possesses a finite\nmaximum; examples are provided.\nAn even stronger validity assumption is implicit in works such as Roberts et al. [9], Roberts\nand Rosenthal [10] and Bedard [2]. In each of these papers a limiting process is found and the\nefficiency of this limiting process is maximised to give an asymptotically optimal scaling.\nFor a given sequence of targets and proposals with optimal scalings \u03bb\u02c6d , we seek the limiting\ntransformed optimal scaling \u03bc\u02c6 := limd\u2192\u221e \u03bc\u02c6d , where \u03bc\u02c6d is given in terms of \u03bb\u02c6d by (12). The op-\ntimal scaling as d \u2192 \u221e would therefore be \u03bb\u02c6d \u223c (2k(d)x \u03bc\u02c6)\/(d1\/2k(d)y ). However the value \u03bc\u02c6 will\nbe obtained by maximising 2\u03bc2\n(\u2212\u03bc) \u221d limd\u2192\u221e S2d(\u03bc), where \n is defined as in Theorem 2.\nThe following result indicates when the scaling that optimises the limit is equivalent to the limit\nof the optimal scalings. A proof is provided in Appendix A.3.\nLemma 2. Let {S2d(\u03bc)} be a sequence of functions defined on [0,\u221e) with continuous pointwise\nlimit S2(\u03bc). Define\nM :=\n{\narg max\n\u03bc\nS2(\u03bc)\n}\nand Md :=\n{\narg max\n\u03bc\nS2d(\u03bc)\n}\n.\nFor each d \u2208 N select any \u03bc\u02c6d \u2208 Md .\n(i) If M = {\u03bc\u02c6} and \u03bc\u02c6d < a < \u221e \u2200d then \u03bc\u02c6d \u2192 \u03bc\u02c6.\n(ii) If M = {\u03bc\u02c6} \u2203 a sequence \u03bc\u2217d \u2192 \u03bc\u02c6 where each \u03bc\u2217d is a local maximum of S2d(\u00b7).\n(iii) If M = \u03c6 (S2 has no finite maximum) then \u03bc\u02c6d \u2192 \u221e, that is, limd\u2192\u221e(minMd) = \u221e.\n(iv) If M \u0013= \u03c6 and \u03bc\u02c6d < a < \u221e \u2200d then S2d(\u03bc\u02c6d) \u2192 S2(\u03bc\u02c6) for any \u03bc\u02c6 \u2208 M .\nWe now highlight certain aspects of Lemma 2 through reference to the mixture target (11), and\nspecifically to target examples 6\u20138 from Section 2.1. Later in this section Lemma 2 is also applied\nto target examples 1\u20135. In all that follows consider the sequence of graphs of S2d(\u03bcd) against \u03bcd ,\nwhere \u03bcd is given by (12); consider also the graph of the pointwise limit, S2(\u03bc), against \u03bc.\nFor all targets of the form (11) with sufficiently large d (so that the components are sufficiently\nOptimal scaling of the random walk Metropolis 787\nseparated in scale) each graph of S2d(\u03bcd) against \u03bcd has two peaks, and a different rescaling\nk\n(d)\nx applies to each component of the mixture. Choosing to rescale by the higher k(d)x would\nstabilise the right-hand peak while the left would approach \u03bcd = 0. However (unless pd \u2192 1)\nthis choice of scaling would create a point mass at the origin in the limiting radial distribution\nfunction \n(\u00b7), which is forbidden in the statement of Theorem 3. In order to apply the theorem\nwe must therefore rescale by the lower k(d)x which stabilises the left-hand peak while the right-\nhand peak drifts off to \u03bcd = \u221e and is therefore not present in the pointwise limit. The existence\nand consistency of a limiting optimal scaling then depend on the relative heights of the peaks\nwhich in turn depend on the limiting behaviour of pd .\nFirst consider any target with pd > 1\/d2 such as target examples 6 and 7. For a given dimen-\nsion this would produce plots similar to the right-hand panels of Figure 1 but with the right-hand\npeak higher than the left-hand peak and therefore providing the optimal scaling, \u03bc\u02c6d . The limit of\nthe scalings which maximise each finite dimensional ESJD is therefore not the same as the scal-\ning which optimises the limiting ESJD. In Lemma 2 Parts (i) and (iv) this situation is prevented\nthrough the condition \u03bc\u02c6d < a < \u221e.\nSuppose in fact that pd \u2192 p > 0, so that rescaling via the lower k(d)x produces a point mass\nat \u221e in the limiting rescaled radial distribution. Consider first the optimal scaling obtained from\nthe limiting form of the ESJD. By Theorem 2, \n(\u2212x1) \u2192 p\/2 as x1 \u2192 \u221e. Hence the limiting\nESJD given in Corollary 3 increases without bound as \u03bc \u2192 \u221e; this is an example of case (iii) in\nLemma 2. The optimal scaling for exploring a real d-dimensional target follows the portion of\nthe target with the larger scale parameter, and so in the limit accepted jumps only arise from this\nportion of the target. The limit of the optimal EAR is therefore the limiting optimal EAR for the\nlarger component multiplied by a factor p, as suggested by the results for target example 6.\nIf pd \u2192 p = 0 then only the left-hand peak affects the forms in Corollary 3; the optimal\nscaling and acceptance rate calculated from this corollary are therefore identical to those for\ntarget example 1. However the true optimal scaling follows the right-hand peak and so the true\nlimiting optimal acceptance rate is 0, as suggested by the results for target example 7.\nAlternatively if pd < 1\/d2 then for large enough d the stabilised left-hand peak dominates, \u03bc\u02c6d\nis bounded and the limit of the maxima is the maximum of the limit function. The true limiting\noptimal acceptance rate is exactly that of the lower component as suggested for target example 8,\nand this is given correctly by Corollary 3.\nProvided pd \u2192 0 the limiting forms for EAR and ESJD are unaffected by the speed at which\nthis limit is approached. The limiting forms are therefore uninformative about whether or not the\nsecond peak is important. This is a fundamental issue with the identifiability of a limiting optimal\nscaling from the limiting ESJD.\nThe above clearly generalises from the specific form (11) so that failure of the boundedness\ncondition on \u03bc\u02c6d in Lemma 2 intuitively corresponds to a target sequence that contains a mix-\nture of scales that produce local maxima in ESJD and whose ratio increases without bound. In\ngeneral, targets that vary on at least two very different scales are not amenable to the current\napproach. Indeed the very existence of a single \u201coptimal\u201d scaling is highly debatable. We wish\nto work with the limit S2(\u03bc), accepting its potential limitation. Therefore define \u03bc\u02c6 := minM\n(or \u03bc\u02c6 := \u221e if M = \u03c6), to be the asymptotically optimal transformed scaling (AOTS), and\n\u03bb\u02c6d = (2k(d)x \u03bc\u02c6)\/(d1\/2k(d)y ) to be the asymptotically optimal scaling (AOS). These are equiva-\nlent to the limit of the optimal (transformed) scalings provided \u03bc\u02c6d < a < \u221e,\u2200d . Similarly the\n788 C. Sherlock and G. Roberts\nasymptotically optimal expected acceptance rate (AOA) is the limiting EAR that results from\nusing the AOTS.\nWe now turn to the existence of an asymptotically optimal scaling. The practising statistician\nis free to choose the proposal distribution and we therefore assume throughout the remainder\nof our discussion of spherically symmetric targets that there is a sequence k(d)y such that the\ntransformed proposal satisfies |Y(d)|\/k(d)y m.s.\u2212\u2192 1.\nFirst consider the special case where there is a sequence k(d)x such that the transformed tar-\nget satisfies |X(d)|\/k(d)x p\u2212\u2192 1. Differentiating (18) we see that the optimal scaling must satisfy\n2\u000b(\u2212\u03bc\u02c6p) = \u03bc\u02c6p\u03c6(\u2212\u03bc\u02c6p), which gives \u03bc\u02c6p :\u2248 1.19. Substituting into (17) provides the EAR at\nthis optimal scaling: \u03b1\u02c6p :\u2248 0.234, as suggested by the finite dimensional results for target ex-\namples 1 and 2. More generally |X(d)|\/k(d)x D\u2212\u2192 R. Following our discussions on validity we\nnow assume that R contains no point mass at 0 or \u221e. In general we seek a finite scaling \u03bc\u02c6 that\nmaximises the pointwise limit of S2d as given in (16); we then compute the EAR using (15). We\nillustrate this process with reference to three of our non-standard examples from Section 2.1.\nFor target examples 3 and 4 the marginal radial distribution is positive Gaussian (\u03b8d(r) \u221d\ne\u2212r2\/2) and exponential (\u03b8d(r) = e\u2212r ), respectively. S2(\u03bc) is maximised at \u03bc\u02c6 = 1.67 and\n\u03bc\u02c6 = 2.86, respectively, which correspond to EARs of 0.091 and 0.055, consistent with the find-\nings in Section 2.1. In target examples 1\u20134, the ESJD of each element in the sequence has a single\nmaximum, so by Lemma 2(ii) the limit of these maxima is the maximum of the limit function,\nsubject to the scaling k(d)x .\nFor target example 5 the limiting transformed marginal radial density is \u03b8(r) \u221d e\u2212(log r)2 and\nnumerical evaluation shows S2(\u03bc) to be bounded above but to increase monotonically with \u03bc;\nthis corresponds to case (iii) of Lemma 2. As with target example 6 this provides a situation\nwhere S2(\u03bc) is increasing as \u03bc \u2192 \u221e. However unlike target example 6, here there is no radial\npoint mass at \u221e, S2(\u03bc) is bounded and the limiting optimal EAR is 0.\n3.3. Asymptotically optimal scaling and EAR\nIf |Y(d)|\/k(d)y m.s.\u2212\u2192 1 then for \u03bc to be optimal we require\n2\n(\u2212\u03bc) = \u03bc\n\u2032(\u2212\u03bc). (19)\nThere may not always be a solution for \u03bc (see Section 3.2) but when there is, denote this value\nas \u03bc\u02c6. Asymptotically optimal scaling is therefore achieved by setting \u03bc = \u03bc\u02c6, so that rearranging\n(12) we obtain the following corollary to Theorem 3:\nCorollary 4. Let {X(d)} be a sequence of d-dimensional spherically symmetric unimodal tar-\nget distributions and let {Y(d)} be a sequence of jump proposal distributions. If there exist se-\nquences {k(d)x } and {k(d)y } such that the marginal radial distribution function of X(d) satisfies\n|X(d)|\/kd D\u2212\u2192 R where R has no point mass at 0, |Y(d)|\/k(d)y m.s.\u2212\u2192 1, and provided there is a\nOptimal scaling of the random walk Metropolis 789\nFigure 4. Plots of log \u03bb\u02c6 against logd for target examples 1\u20134. Optimal values predicted using Corollary 4\nappear as dotted lines.\nsolution \u03bc\u02c6 to (19) then the asymptotically optimal scaling (AOS) satisfies\n\u03bb\u02c6d = 2\u03bc\u02c6 k\n(d)\nx\nd1\/2k(d)y\n.\nTarget examples 1 and 2 satisfy |X(d)|\/k(d)x p\u2212\u2192 1, with k(d)x = d1\/2 and k(d)x = d respectively;\nwe therefore expect an AOTS of \u03bc\u02c6p \u2248 1.19. For target examples 3 and 4, k(d)x = 1, and the AOTSs\nare, respectively, \u03bc\u02c6 \u2248 1.67 and \u03bc\u02c6 \u2248 2.86. Figure 4 shows plot of the true optimal scale parame-\nter against dimension evaluated numerically using (9). The asymptotic approximation given in\nCorollary 4 appears as a dotted line. Both axes are log-transformed and in all cases the finite\ndimensional optimal scalings are seen to approach their asymptotic values as d increases. For\nthe Gaussian target very close agreement is attained even in one dimension since the asymptotic\nGaussian approximation to the marginal radial distribution function is exact for all finite d .\nLet us now explore the AOA, if it exists, and define \u03b1\u221e(\u03bc) := limd\u2192\u221e \u03b1d(\u03bc). From Theo-\nrem 2 and Corollary 3(i)\n\u03b1\u221e(\u03bc) = 2\n(\u2212\u03bc) = 2ER\n[\n\u000b\n(\u2212\u03bc\nR\n)]\n,\n790 C. Sherlock and G. Roberts\nwhere R is the marginal radius of the limit of the sequence of scaled targets. We build upon\nTheorem 3, which explicitly requires that the rescaled marginal radial distribution should have\nno point mass at 0. Following the discussion in Section 3.2 the condition that there be an optimal\n\u03bc implies that the limiting marginal radius has no point mass at infinity. The following is proved\nin Appendix A.4.\nTheorem 4. Let X(d) be a sequence of d-dimensional spherically symmetric unimodal target\ndistributions and let Y(d) be a sequence of jump proposal distributions. Let there exist k(d)x and\nk\n(d)\ny such that |Y(d)|\/k(d)y m.s.\u2212\u2192 1 and |X(d)|\/k(d)x D\u2212\u2192 R for some R with no point mass at 0. If\nthere is a limiting (non-zero) AOA it is\n\u03b1\u221e(\u03bc) \u2264 \u03b1\u02c6p \u2248 0.234.\nEquality is achieved if and only if there exist k(d)x such that |X(d)|\/k(d)x p\u2212\u2192 1.\nFor \u201cstandard\u201d proposals, the often used optimal EAR of 0.234 therefore provides an upper\nbound on the possible optimal EARs for spherically symmetric targets, and it is achieved if and\nonly if the mass of the target converges (after rescaling) to an infinitesimally thin shell.\n4. Elliptically symmetric distributions\nAs discussed in Section 1.2 a unimodal elliptically symmetric target X may be defined in terms of\nan associated orthogonal linear map T such that X\u2217 := T(X) is spherically symmetric with unit\nscale parameter. Since T is linear, the jump proposal in the transformed space is Y\u2217 := T (Y).\nThe ESJD (4) is preserved under the transformation, since Y 2i \/\u03b22i = Y 2i\u2217, and thus we sim-\nply apply Theorem 1 in the transformed space. Write F \u22171|d(\u00b7) for the one-dimensional marginal\ndensity of spherically symmetric X\u2217, We wish to optimise the ESJD\nS2d(\u03bb) := 2\u03bb2E\n[|Y\u2217|2F \u22171|d(\u2212 12\u03bb|Y\u2217|)]. (20)\nHere expectation is with respect to Lebesgue measure r\u2217(\u00b7) of Y\u2217. Acceptance in the original\nspace is equivalent to acceptance in the transformed space and the EAR is therefore given by\n\u03b1d(\u03bb) = 2E\n[\nF \u22171|d\n(\u2212 12\u03bb|Y\u2217|)]. (21)\nCorollaries 1 and 2 are now seen to hold for all unimodal elliptically symmetric targets. For\nCorollary 3(i) to be applicable in the transformed space we require there to exist k\u2217(d)x and k\u2217(d)y\nsuch that\n|T(d)(X(d))|\nk\n\u2217(d)\nx\nD\u2212\u2192 R and |T\n(d)(Y(d))|\nk\n\u2217(d)\ny\nm.s.\u2212\u2192 1. (22)\nSince X(d)\u2217 is spherically symmetric, it is natural to request convergence of X(d)\u2217 \/k\u2217(d)x explicitly\nin the statement of the theorem. Bedard [2] considers a situation analogous to this, but with\nOptimal scaling of the random walk Metropolis 791\nR = 1. The working statistician is free to choose a jump proposal such that |Y(d)|\/k(d)y m.s.\u2212\u2192 1. If\nY(d) is in fact spherically symmetric this convergence carries through to the transformed space\nprovided the eccentricity of the original target is not \u201ctoo severe\u201d. A proof of the following\nappears in Appendix A.5.\nTheorem 5. Let {X(d)} be a sequence of elliptically symmetric unimodal targets and {T(d)} be\na sequence of linear maps such that X(d)\u2217 := T(d)(X(d)) is spherically symmetric with unit scale\nparameter. Let {Y(d)} be a sequence of spherically symmetric proposals and let there exist {k\u2217(d)x }\nand {k(d)y } such that\nX(d)\u2217\nk\n\u2217(d)\nx\nD\u2212\u2192 R and Y\n(d)\nk\n(d)\ny\nm.s.\u2212\u2192 1.\nDenote by \u03bdi the eigenvalues of T(d), and define k\u2217(d)y = (\u03bd2)1\/2k(d)y , where \u03bd2 := d\u22121\u2211di=1 \u03bd2i .\nIf\n\u03bdmax(d)\n2\u2211d\ni=1 \u03bdi(d)2\n\u2192 0 (23)\nthen for fixed\n\u03bc := 1\n2\nd1\/2k\u2217(d)y\nk\n\u2217(d)\nx\n\u03bbd (24)\nthe EAR and the ESJD satisfy\n\u03b1d(\u03bc) \u2192 2E\n[\n\u000b\n(\n\u2212\u03bc\nR\n)]\n, (25)\nd\n4k\u2217(d)x\n2 S\n2\nd(\u03bc) \u2192 2\u03bc2E\n[\n\u000b\n(\n\u2212\u03bc\nR\n)]\n, (26)\nwhere \u000b(x) is the cumulative distribution function of a standard Gaussian. If in fact R = 1 then\n\u03b1d(\u03bc) \u2192 2\u000b(\u2212\u03bc), (27)\nd\n4k\u2217(d)x\n2 S\n2\nd(\u03bc) \u2192 2\u03bc2\u000b(\u2212\u03bc). (28)\nNaturally (28) leads to the same optimal \u03bc\u02c6p as for a spherically symmetric target, so the AOA\nis still approximately 0.234 and the AOS satisfies\n\u03bb\u02c6d = 2\u03bc\u02c6p k\n\u2217(d)\nx\nd1\/2k(d)y\n\u00d7 1\n(\u03bd2)1\/2\n.\nSimilarly (25) and (26) lead again to \u03b1(\u03bc\u02c6) \u2264 \u03b1(\u03bc\u02c6p) \u2248 0.234.\n792 C. Sherlock and G. Roberts\n5. Discussion\nWe have investigated optimal scaling of the random walk Metropolis algorithm on unimodal\nelliptically symmetric targets. An approach through finite dimensions using expected square\njumping distance (ESJD) as a measure of efficiency both agrees with and extends the existing\nliterature, which is based upon diffusion limits.\nWe obtained exact analytical expressions for the expected acceptance rate (EAR) and the ESJD\nin finite dimension d . For any RWM algorithm on a spherically symmetric unimodal target it was\nshown that EAR decreases monotonically from 1 to 0 as the proposal scaling parameter increases\nfrom 0 to \u221e. This bijective mapping justifies to an extent the use of acceptance rate as a proxy\nfor the scale parameter. The theory for finite dimensional targets was then shown to extend to\nelliptically symmetric targets.\nAn asymptotic theory was developed for the behaviour of the RWM algorithm as dimension\nd \u2192 \u221e. It was shown that the asymptotically optimal EAR of 0.234 extends to the class of spher-\nically symmetric unimodal targets if and only if the mass of the targets converges to a spherical\nshell that becomes infinitely thin relative to its radius, with a similar but slightly stronger con-\ndition on the proposal. The optimal acceptance rate was then explored for target sequences for\nwhich the \u201cshell\u201d condition fails. In such cases the asymptotically optimal EAR (if it exists) was\nshown to be strictly less than 0.234. An asymptotic form for the optimal scale parameter showed\nthat the dimension dependent rescalings which stabilise the radial mass for both the proposal and\ntarget must be taken into account. Much of the existing literature (see Roberts et al. [9]) uses\nindependent and identically distributed (i.i.d.) target components and i.i.d. proposal components\nso that these two extra effects cancel and \u03bb\u02c6d \u221d d\u22121\/2.\nThe class for which the limit results are valid was then extended to include all algorithms\non elliptically symmetric targets such that the same \u201cshell\u201d conditions are satisfied once the\ntarget has been transformed to spherical symmetry by an orthogonal linear map. If the original\ntarget is explored by a spherically symmetric proposal then an additional constraint applies to\nthe eigenvalues of the linear map, which forbids the scale parameter of the smallest principle\ncomponent from being \u201ctoo much smaller\u201d than all the other scale parameters and is equivalent\nto the condition of Bedard [2], derived for targets with independent components that are identical\nup to a scaling.\nThe optimality limit results are not always valid for targets with at least two very different\n(but important) scales of variation; however, the suitability of the RWM to such targets is itself\nquestionable.\nExplicit forms for EAR and ESJD in terms of marginal radial densities were also used to ex-\nplore specific combinations of target and proposal in finite dimensions. Numerical and analytical\nresults agreed with our limit theory and with a simulation study in Roberts and Rosenthal [10].\nAppendix\nA.1. Proof of Theorem 1\nThe proof of Theorem 1 relies on a partitioning of the space of possible values for x\u2217 (and so\nfor x\u2032) given x into four disjoint regions:\nOptimal scaling of the random walk Metropolis 793\n\u2022 the identity region: Rid(x) := {x},\n\u2022 the equality region: Req(x) := {x\u2032 \u2208 \td : x\u2032 \/\u2208 Rid(x), \u03c0(x\u2032)q(x|x\u2032)\u03c0(x)q(x\u2032|x) = 1},\n\u2022 the acceptance region: Ra(x) := {x\u2032 \u2208 \td :\u03b1(x,x\u2032) = 1,x\u2032 \/\u2208 Req(x)\u222aRid(x)},\n\u2022 the rejection region: Rr(x) := {x\u2032 \u2208 \td :\u03b1(x,x\u2032) < 1}.\nHere \u03c0(\u00b7) is the target (Lebesgue) density. For vectors (x,x\u2032) in \td \u00d7 \td we employ the short-\nhand RID := {(x,x\u2032) : x \u2208 \td ,x\u2032 \u2208 Rid(x)}, with regions REQ,RA and RR defined analogously.\nThe following lemma holds for almost any Metropolis\u2013Hastings algorithm and allows us to\nsimplify the calculations of ESJD and EAR. It is convenient to be able to refer to the proposed\njump, Y\u2217 := X\u2217 \u2212 X.\nLemma 3. Consider any Metropoplis\u2013Hastings Markov chain with stationary Lebesgue density\n\u03c0(\u00b7). At stationarity let X denote the current element, X\u2217 the proposed next element and X\u2032 the\nrealised next element. Let proposals be drawn from Lebesgue density q(x\u2217|x) and assume that\u222b\nReq(x)\ndx\u2032q(x\u2032|x) = 0 \u2200x. (29)\nAlso denote the probability of accepting proposal x\u2217 by \u03b1(x,x\u2217) and the joint laws of (X,X\u2217)\nand (X,X\u2032), respectively, by\nA\u2217(dx,dx\u2217) := \u03c0(x)dxq(x\u2217|x)dx\u2217 (30)\nand\nA(dx,dx\u2032) := A\u2217(dx,dx\u2032)\u03b1(x,x\u2032)1{x\u2032 \u0013=x}\n+ \u03c0(x)dx\n\u222b\ndx\u2217q(x\u2217|x)(1 \u2212 \u03b1(x,x\u2217))1{x\u2032=x}. (31)\nFinally let h(x,x\u2032) be any function satisfying the following two conditions:\nh(x,x\u2032) = c \u00d7 h(x\u2032,x) \u2200x,x\u2032 (with c = \u00b11), (32)\nh(x,x) = 0 \u2200x. (33)\nSubject to the above conditions:\n1. E[h(X,X\u2032)] = (1 + c)\u00d7 \u222b\n(x,x\u2032)\u2208RA dx dx\n\u2032 \u03c0(x)q(x\u2032|x)h(x,x\u2032).\n2. E[\u03b1(X,X\u2217)] = 2 \u222b\n(x,x\u2217)\u2208RA dx dx\n\u2217 \u03c0(x)q(x\u2217|x).\nProof. First note that an exchangeability between the regions Ra(\u00b7) and Rr(\u00b7) follows directly\nfrom their definitions\nx\u2032 \u2208 Ra(x) \u21d0\u21d2 x \u2208 Rr(x\u2032).\n794 C. Sherlock and G. Roberts\nConsecutively applying this exchangeability, reversibility and the symmetry of h(\u00b7, \u00b7), we find:\u222b\n(x,x\u2032)\u2208RA\nA(dx,dx\u2032)h(x,x\u2032) =\n\u222b\n(x\u2032,x)\u2208RR\nA(dx,dx\u2032)h(x,x\u2032)\n=\n\u222b\n(x\u2032,x)\u2208RR\nA(dx\u2032,dx)h(x,x\u2032)\n= c \u00d7\n\u222b\n(x\u2032,x)\u2208RR\nA(dx\u2032,dx)h(x\u2032,x).\nThe set RID corresponds to the second term in A(dx,dx\u2032); this is in general not null with\nrespect to A(\u00b7, \u00b7); however, (33) implies that h(x,x\u2032) = 0 in RID. Further, \u03b1(x,x\u2217) = 1 \u2200(x,x\u2217) \u2208\nREQ(x,x\u2217), and (29) holds. Therefore\u222b\n(x,x\u2032)\u2208RID\u222aREQ\nA(dx,dx\u2032)h(x,x\u2032) = 0.\nThus RID and REQ contribute nothing to the overall expectation of h(X,X\u2032). Since \u03b1(x,x\u2217) =\n1 \u2200(x,x\u2217) \u2208 RA(x,x\u2217) the first result then follows.\nThe proof of the second result is similar to that of the first and is omitted. \u0002\nSherlock [11] shows that for a symmetric proposal (such as the RWM) Lemma 3 may be\nextended to deal with cases where the density contains a series of plateaux and hence REQ is not\nnull. REQ is then partitioned into a null set and pseudo-acceptance and rejection regions that are\nexactly as would be found if each plateau in fact had a small downward slope away from the\norigin.\nIn the region RA, where acceptance is guaranteed, we have x\u2032 = x\u2217 and y = y\u2217 so that for\nintegrals over RA we need not distinguish between proposed and accepted values. Applying\nLemma 3 with h(x,x\u2032) = \u2016x\u2032 \u2212 x\u20162\u03b2 = |y|2, we have\n\u03b1d(\u03bb) = 2\n\u03bbd\n\u222b\nRA\ndx dy\u03c0(x)r(y\/\u03bb), (34)\nS2d(\u03bb) =\n2\n\u03bbd\n\u222b\nRA\ndx dy |y|2\u03c0(x)r(y\/\u03bb). (35)\nFirst consider target densities that decrease with strict monotonicity from the mode. In this case\nRA corresponds to the region where\n\u03c0(x + y) > \u03c0(x) \u21d0\u21d2 |x + y|2 < |x|2 \u21d0\u21d2 x \u00b7 y\u02c6 < \u2212 12 |y|, (36)\nwhere y\u02c6 is the unit vector in the direction of y. So\n(x,x + y) \u2208 RA \u21d0\u21d2 y \u2208 \td and x \u00b7 y\u02c6 < \u2212 12 |y|.\nOptimal scaling of the random walk Metropolis 795\nThus (34) and (35) become\n\u03b1d(\u03bb) = 2\n\u03bbd\n\u222b\n\td\ndy r(y\/\u03bb)F1|d\n(\n\u22121\n2\n|y|\n)\n,\nS2d(\u03bb) =\n2\n\u03bbd\n\u222b\n\td\ndy |y|2r(y\/\u03bb)F1|d\n(\n\u22121\n2\n|y|\n)\n,\nand the required results follow directly.\nWithout strict monotonicity RA must simply be extended to include the \u201cpseudo-acceptance\nregions\u201d defined in Sherlock [11].\nA.2. Proof of Theorem 3\nTheorem 3 follows almost directly from the following simple lemma, the proof of which follows\nfrom a standard measure theory argument that we omit.\nLemma 4. Let Ud be a sequence of random variables and let Gd(\u00b7) \u2192 G(\u00b7) be a sequence of\nmonotonic functions with 0 \u2264 Gd(u) \u2264 1 and G(\u00b7) continuous. Then\nUd\np\u2212\u2192 U \u0017\u21d2 E[Gd(Ud)] \u2192 E[G(U)], and\nUd\nm.s.\u2212\u2192 U \u0017\u21d2 E[U2dGd(Ud)] \u2192 E[U2G(U)].\nNow note that \u2212 12\u03bbd |Y(d)| = \u2212\u03bc|Y(d)|\/k(d)y \u00d7 k(d)x \/d1\/2 whence (5) and (6) become\n\u03b1d(\u03bc) = 2E\n[\nF1|d\n(\n\u2212\u03bc |Y\n(d)|\nk\n(d)\ny\nk\n(d)\nx\nd1\/2\n)]\nand\nS2d(\u03bc) =\n8\u03bc2k(d)x\n2\nd\nE\n[( |Y(d)|\nk\n(d)\ny\n)2\nF1|d\n(\n\u2212\u03bc |Y\n(d)|\nk\n(d)\ny\nk\n(d)\nx\nd1\/2\n)]\n.\nAgain denote the limiting one-dimensional distribution function corresponding to R by \n(x). In\nLemma 4 substitute Ud = |Y(d)|\/k(d)y , U = Y , Gd(u) = F1|d(\u2212\u03bc k\n(d)\nx\nd1\/2\nu) and G(u) = \n(\u2212\u03bcu).\nNote also that since G(\u00b7) and Gd(\u00b7) are bounded the convergence in the first part of the lemma\nholds if Ud\nD\u2212\u2192 U . The theorem then follows directly.\nA.3. Proof of Lemma 2\n(i) Pick an arbitrarily small \u03b4 > 0 and set a\u2217 = max(a, \u03bc\u02c6+ \u03b4).\nDefine R := (\u03bc\u02c6\u2212 \u03b4, \u03bc\u02c6+ \u03b4) and T := [0, a\u2217]\\R.\nLet m := max\u03bc\u2208T S2(\u03bc). Since \u03bc\u02c6 \u2208 R uniquely maximises S2(\u00b7) in [0, a\u2217], and since\nT is compact, a strict inequality holds: m < S2(\u03bc\u02c6).\n796 C. Sherlock and G. Roberts\nAlso S2d(\u03bc) \u2192 S2(\u03bc) uniformly on compact [0, a\u2217] and hence \u2203d1 such that\n|S2(\u03bc)\u2212 S2d(\u03bc)| < 12\n(\nS2(\u03bc\u02c6)\u2212m) \u2200\u03bc \u2208 [0, a\u2217] and d > d1.\nHence for any \u03bcb \u2208 T and d > d1\nS2d(\u03bcb) < S\n2(\u03bcb)+ 12\n(\nS2(\u03bc\u02c6)\u2212m)\u2264 12(S2(\u03bc\u02c6)+m)\n= S2(\u03bc\u02c6)\u2212 12\n(\nS2(\u03bc\u02c6)\u2212m)< S2d(\u03bc\u02c6).\nSince \u03bc\u02c6d is confined to [0, a\u2217] it must therefore reside in R.\n(ii) Pick an arbitrarily small \u03b4 > 0 and set a\u2217 = \u03bc\u02c6+ 2\u03b4. Proceed exactly as in the proof to (i).\nThe interval (\u03bc\u02c6 \u2212 \u03b4, \u03bc\u02c6 + \u03b4) contains a local maximum of S2d since S2d(\u03bcb) < S2d(\u03bc\u02c6) for\nd > d1 and \u03bcb \u2208 [0, a\u2217]\\(\u03bc\u02c6\u2212 \u03b4, \u03bc\u02c6+ \u03b4).\n(iii) Pick a large k > 0 and let m := max\u03bc\u2208[0,k] S2(\u03bc). Now m < \u221e since S2(\u03bc) is continuous\non compact [0, k]. As there is no finite arg max, \u2203\u03bcb > k such that S2(\u03bcb) = m + \u03b4 for\nsome \u03b4 > 0.\nConvergence of S2d(\u03bc) to S2(\u03bc) is uniform on [0,\u03bcb] and therefore \u2203d1 such that\n|S2(\u03bc)\u2212 S2d(\u03bc)| <\n\u03b4\n2\n\u2200\u03bc \u2208 [0,\u03bcb] and d > d1.\nHence for \u03bca \u2208 [0, k]\nS2d(\u03bca) < S\n2(\u03bca)+ \u03b42 = S\n2(\u03bcb)\u2212 \u03b42 < S\n2\nd(\u03bcb).\nThus for any k and any \u03bca \u2208 [0, k], for all large enough d there is always an \u03bcb > k\nsuch that S2d(\u03bcb) > S\n2\nd(\u03bca) and hence the maximum is achieved at \u03bcd > k. Therefore\n\u03bcd \u2192 \u221e.\n(iv) Define a\u2217 = max(a, \u03bc\u02c6) and choose an \u03b5 > 0. Since S2d(\u03bc) \u2192 S2(\u03bc) uniformly on com-\npact [0, a\u2217], \u2203d1 such that \u2200d > d1 and \u03bc \u2208 [0, a\u2217], |S2(\u03bc)\u2212 S2d(\u03bc)| < \u03b5. By definition\nS2d(\u03bc\u02c6d) \u2265 S2d(\u03bc\u02c6), therefore\nS2(\u03bc\u02c6)\u2212 \u03b5 < S2d(\u03bc\u02c6) \u2264 S2d(\u03bc\u02c6d) < S2(\u03bc\u02c6d)+ \u03b5 < S2(\u03bc\u02c6)+ \u03b5.\nA.4. Proof of Theorem 4\nObserve that\n\n\u2032(\u2212\u03bc) = E\n[\n1\nR\n\u03c6\n(\n\u2212\u03bc\nR\n)]\n,\nso (19) becomes\n2E\n[\n\u000b\n(\n\u2212\u03bc\nR\n)]\n= E\n[\n\u03bc\nR\n\u03c6\n(\n\u2212\u03bc\nR\n)]\n. (37)\nOptimal scaling of the random walk Metropolis 797\nFor a given distribution of R, this has solution \u03bc\u02c6, from which the AOA is\n\u03b1\u02c6 := \u03b1\u221e(\u03bc\u02c6) = 2E\n[\n\u000b\n(\n\u2212 \u03bc\u02c6\nR\n)]\n.\nSubstitute V := \u000b(\u2212 \u03bc\u02c6\nR\n) so that for \u03bc \u2265 0 and R \u2265 0 we have v \u2208 [0,0.5]. Also define\nh(v) := \u2212\u000b\u22121(v)\u03c6(\u000b\u22121(v)).\nThe AOA is therefore\n\u03b1\u02c6 = 2E[V ]\nand (37) is satisfied, becoming\n2E[V ] = E[h(V )]. (38)\nBut\nd2h\ndv2\n= 2 \u000b\n\u22121(v)\n\u03c6(\u000b\u22121(v))\n\u2264 0 forv \u2208 [0,0.5],\nwith strict inequality for v \u2208 (0,0.5) (i.e., r \u2208 (0,\u221e)). Therefore by Jensen\u2019s inequality\nE[h(V )] \u2264 h(E[V ]). (39)\nSince h\u2032\u2032(\u00b7) is strictly negative except at the (finite) end points, equality is achieved if and only\nif all the mass in V is concentrated in one place, v0; this corresponds to all the mass in R being\nconcentrated at \u2212\u03bc\u02c6\/\u000b\u22121(v0) and is exactly the situation |X(d)|\/k(d)x p\u2212\u2192 1.\nSubstitute m := \u000b\u22121(E[V ]), so that (38) and (39) combine to give\n2\u000b(\u2212m) \u2264 m\u03c6(m).\nWhen there is equality the single solution to this equation is m\u02c6 = \u03bc\u02c6p \u2248 1.19. The inequality is\nstrict if and only if m > \u03bc\u02c6p , and hence 2\u000b(\u2212m) \u2264 2\u000b(\u2212\u03bc\u02c6p).\nTherefore the AOA is\n\u03b1\u02c6 = E[V ] = 2\u000b(\u2212m) \u2264 2\u03c6(\u2212\u03bc\u02c6p) \u2248 0.234,\nwith equality achieved if and only if |X(d)|\/k(d)x p\u2212\u2192 1.\nA.5. Proof of Theorem 5\nDenote the arithmetic mean of the squares of the d-dependent scalar values \u03b11(d), . . . , \u03b1d(d) by\n\u03b12(d), and the maximum by \u03b1max(d). The following is proved in Sherlock [11].\n798 C. Sherlock and G. Roberts\nLemma 5. Let S(d) be a sequence of orthogonal linear maps on \td with eigenvalues\n\u03b11(d), . . . , \u03b1d(d) and let U(d) be a sequence of isotropic random variables in \td . Then\n\u2223\u2223U(d)\u2223\u2223 m.s.\u2212\u2192 1 \u21d0\u21d2 |S(d)(U(d))|\n(\u03b12(d))1\/2\nm.s.\u2212\u2192 1\nprovided the eigenvalues of S(d) satisfy\n\u03b1max(d)\n2\u2211d\ni=1 \u03b1i(d)2\n\u2192 0. (40)\nIt should be emphasised that condition (40) applies to the map that transforms a spherically\nsymmetric random variable to an elliptically symmetric random variable.\nNow apply Lemma 5 with U(d) = Y(d)\/k(d)y and S(d) = T(d) to see that the second half of (22)\nholds with the new rescaling factor k\u2217(d)y . We may therefore apply Corollary 3 in the transformed\nspace with \u03bc as defined in (24). Since EAR and ESJD are invariant to the transformation this\nleads directly to (25)\u2013(28).\nReferences\n[1] Apostol, T.M. (1974). Mathematical Analysis. Reading, MA: Addison-Wesley. MR0344384\n[2] Bedard, M. (2007). Weak convergence of Metropolis algorithms for non-iid target distributions. Ann.\nAppl. Probab. 17 1222\u20131244. MR2344305\n[3] Breyer, L.A. and Roberts, G.O. (2000). From Metropolis to diffusions: Gibbs states and optimal scal-\ning. Stochastic Process. Appl. 90 181\u2013206. MR1794535\n[4] Fang, K.T., Kotz, S. and Ng, K.W. (1990). Symmetric Multivariate and Related Distributions. Mono-\ngraphs on Statistics and Applied Probability 36. London: Chapman and Hall. MR1071174\n[5] Gelman, A., Roberts, G.O. and Gilks, W.R. (1996). Efficient Metropolis jumping rules. In Bayesian\nStatistics, 5 (Alicante, 1994) 599\u2013607. New York: Oxford Univ. Press. MR1425429\n[6] Krzanowski, W.J. (2000). Principles of Multivariate Analysis: A User\u2019s Perspective, 2nd ed. Oxford\nStatistical Science Series 22. New York: The Clarendon Press Oxford Univ. Press. MR1133626\n[7] Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H. and Teller, E. (1953). Equations of\nstate calculations by fast computing machine. J. Chem. Phys. 21 1087\u20131091.\n[8] Roberts, G.O. (1998). Optimal metropolis algorithms for product measures on the vertices of a hyper-\ncube. Stochastics Stochastic Rep. 62 275\u2013283. MR1613256\n[9] Roberts, G.O., Gelman, A. and Gilks, W.R. (1997). Weak convergence and optimal scaling of random\nwalk Metropolis algorithms. Ann. Appl. Probab. 7 110\u2013120. MR1428751\n[10] Roberts, G.O. and Rosenthal, J.S. (2001). Optimal scaling for various Metropolis\u2013Hastings algo-\nrithms. Statist. Sci. 16 351\u2013367. MR1888450\n[11] Sherlock, C. (2006). Methodology for inference on the Markov modulated Poisson process and theory\nfor optimal scaling of the random walk Metropolis. Ph.D. thesis, Lancaster University. Available at\nhttp:\/\/eprints.lancs.ac.uk\/850\/.\nReceived February 2007 and revised October 2008\n"}
{"doi":"10.1080\/15326349.2011.542721","coreId":"196841","oai":"oai:lra.le.ac.uk:2381\/9045","identifiers":["oai:lra.le.ac.uk:2381\/9045","10.1080\/15326349.2011.542721"],"title":"A Weak Approximation of Stochastic Differential Equations with Jumps through Tempered Polynomial Optimization","authors":["Kashima, Kenji","Kawai, Reiichiro"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-01","abstract":"We present an optimization approach to the weak approximation of a general class of stochastic differential equations with jumps, in particular, when value functions with compact support are considered. Our approach employs a mathematical programming technique yielding upper and lower bounds of the expectation, without Monte Carlo sample paths simulations, based upon the exponential tempering of bounding polynomial functions to avoid their explosion at infinity. The resulting tempered polynomial optimization problems can be transformed into a solvable polynomial programming after a minor approximation. The exponential tempering widens the class of stochastic differential equations for which our methodology is well defined. The analysis is supported by numerical results on the tail probability of a stable subordinator and the survival probability of Ornstein-Uhlenbeck processes driven by a stable subordinator, both of which can be formulated with value functions with compact support and are not applicable in our framework without exponential tempering.Peer-reviewedPost-prin","downloadUrl":"http:\/\/hdl.handle.net\/2381\/9045","fullTextIdentifier":"https:\/\/lra.le.ac.uk\/bitstream\/2381\/9045\/3\/opt2.pdf","pdfHashValue":"2a4956e8ab733a5f9af86a3e638891c85228aa42","publisher":"Taylor & Francis","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:lra.le.ac.uk:2381\/9045<\/identifier><datestamp>\n                2013-10-24T01:01:28Z<\/datestamp><setSpec>\n                com_2381_445<\/setSpec><setSpec>\n                com_2381_9549<\/setSpec><setSpec>\n                col_2381_3823<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nA Weak Approximation of Stochastic Differential Equations with Jumps through Tempered Polynomial Optimization<\/dc:title><dc:creator>\nKashima, Kenji<\/dc:creator><dc:creator>\nKawai, Reiichiro<\/dc:creator><dc:subject>\nExponential tempering<\/dc:subject><dc:subject>\nL\u00e9vy process<\/dc:subject><dc:subject>\nOrnstein-Uhlenbeck process<\/dc:subject><dc:subject>\nSemidefinite programming<\/dc:subject><dc:subject>\nStable subordinator<\/dc:subject><dc:subject>\nSurvival probability estimation<\/dc:subject><dc:subject>\nTail probability estimation<\/dc:subject><dc:description>\nWe present an optimization approach to the weak approximation of a general class of stochastic differential equations with jumps, in particular, when value functions with compact support are considered. Our approach employs a mathematical programming technique yielding upper and lower bounds of the expectation, without Monte Carlo sample paths simulations, based upon the exponential tempering of bounding polynomial functions to avoid their explosion at infinity. The resulting tempered polynomial optimization problems can be transformed into a solvable polynomial programming after a minor approximation. The exponential tempering widens the class of stochastic differential equations for which our methodology is well defined. The analysis is supported by numerical results on the tail probability of a stable subordinator and the survival probability of Ornstein-Uhlenbeck processes driven by a stable subordinator, both of which can be formulated with value functions with compact support and are not applicable in our framework without exponential tempering.<\/dc:description><dc:description>\nPeer-reviewed<\/dc:description><dc:description>\nPost-print<\/dc:description><dc:date>\n2011-02-08T11:08:09Z<\/dc:date><dc:date>\n2011-02-08T11:08:09Z<\/dc:date><dc:date>\n2011-01<\/dc:date><dc:type>\nArticle<\/dc:type><dc:identifier>\nStochastic Models, 2011, 27 (1), pp. 26-49<\/dc:identifier><dc:identifier>\n1532-6349<\/dc:identifier><dc:identifier>\nhttp:\/\/www.informaworld.com\/smpp\/title~db=all~content=g932744425<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2381\/9045<\/dc:identifier><dc:identifier>\n10.1080\/15326349.2011.542721<\/dc:identifier><dc:language>\nen<\/dc:language><dc:rights>\nCopyright \u00a9 Taylor & Francis Group 2011.  Deposited with reference to the publisher\u2019s open access archiving policy.<\/dc:rights><dc:publisher>\nTaylor & Francis<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["issn:1532-6349","1532-6349"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2011,"topics":["Exponential tempering","L\u00e9vy process","Ornstein-Uhlenbeck process","Semidefinite programming","Stable subordinator","Survival probability estimation","Tail probability estimation"],"subject":["Article"],"fullText":"A Weak Approximation of Stochastic Differential Equations with\nJumps through Tempered Polynomial Optimization\nKENJI KASHIMA\u0003 AND REIICHIRO KAWAI\u2020\nAbstract\nWe present an optimization approach to the weak approximation of a general class of stochastic differ-\nential equations with jumps, in particular, when value functions with compact support are considered.\nOur approach employs a mathematical programming technique yielding upper and lower bounds of the\nexpectation, without Monte Carlo sample paths simulations, based upon the exponential tempering of\nbounding polynomial functions to avoid their explosion at infinity. The resulting tempered polynomial\noptimization problems can be transformed into a solvable polynomial programming after a minor ap-\nproximation. The exponential tempering widens the class of stochastic differential equations for which\nour methodology is well defined. The analysis is supported by numerical results on the tail probability\nof a stable subordinator and the survival probability of Ornstein-Uhlenbeck processes driven by a stable\nsubordinator, both of which can be formulated with value functions with compact support and are not\napplicable in our framework without exponential tempering.\nKeywords: exponential tempering, Le\u00b4vy process, stable subordinator, Ornstein-Uhlenbeck process, semidef-\ninite programming, tail probability estimation, survival probability estimation.\n2010 Mathematics Subject Classification: 60H10, 65C30, 60G51, 90C22.\n1 Introduction\nStochastic differential equations have long been used to build realistic models in economics, finance, bi-\nology, the social sciences, chemistry, physics and other fields. For practical applications such as moment\nand tail probability estimations, or expected utilities, we need to estimate the expected value of the solu-\ntion of stochastic differential equations. The so-called weak approximations via the time discretization of\nEuler-Maruyama type has been the most standard approach, that is, jE[V (XT )]\u0000E[V (XDT )]j \u0014CDb , where\nfXt : t 2 [0;T ]g is a solution of a suitable stochastic differential equation, V is a smooth function and XDT\nindicates the time discretization approximation of XT with time step D> 0. The theoretical investigation of\ntime discretization schemes in diffusion settings has been thoroughly presented in Kloeden and Platen [7],\nwhile stochastic differential equations with jumps have also been studied, for example, in Protter and Talay\n[15].\nIn contrast to Monte Carlo simulations of discretized sample paths, methodologies leading to the compu-\ntation of bounds for the expectation have been proposed and investigated in various fields of application by\nseveral authors, for example, Bertsimas, Popescu and Sethuraman [2], Eriksson and Pistorius [3], Helmes,\nRo\u00a8hl and Stockbridge [4], Lasserre and Prieto-Rumeau [8], Lasserre, Prieto-Rumeau and Zervos [9], Suzuki,\nMiyoshi and Kojima [18], to mention just a few. It is known that there exist two types of formulation of this\nframework, both of which arrive at a semi-definite programming in the end. One is the so-called generalized\nPublished in Stochastic Models (2011) 27(1) 26-49.\n\u0003Email address: kashima@mei.titech.ac.jp. Postal address: Graduate School of Information Science and Engineering, Tokyo\nInstitute of Technology, Tokyo, 152-8552, Japan.\n\u2020Email address: reiichiro.kawai@gmail.com. Postal address: Department of Mathematics, University of Leicester, Leicester\nLE1 7RH, UK.\n1\nmoment problem that makes use of the semi-definiteness of (localizing) moment matrices1. The other is a\npolynomial optimization approach for which sum-of-squares relaxation efficiently works. In this paper, our\ndiscussion is based on the latter formulation, mainly because it provides a more intuitive way to discuss how\nthe proposed method works. Note also that from an optimization point of view, those two formulations are\ndual to one another. (See, for example, Nishihara, Yagiura and Ibaraki [10] for a related discussion.)\nOur methodology can be described roughly as follows. First, one employs a function with arguments\nboth in time and in state, which bounds from above (or from below) at time T the value function uniformly\nover the support of XT . One further restricts the infinitesimal generator of the bounding function to be non-\npositive (or non-negative) over the whole space. Under all those constraints, the well-known Dynkin formula\nguarantees that the bounding function concentrated at the deterministic initial point (0;X0) serves as an upper\n(or lower) bound of the expectation. The final step is to minimize the upper bound (or maximize the lower\nbound). For this approach to make practical sense, one has to restrict the class of bounding functions to an\nextent where the optimization is solvable. In this respect, the most general class of differentiable functions\nfor the Ito formula is too abstract to be tractable. To address this issue, the existing literature focuses\non diffusion process with polynomial coefficients. Also, a more general class of stochastic differential\nequations including jumps is considered by the authors [5], for which standard Monte Carlo simulations\nare no longer implementable in terms of computational time, or often impossible due to nonavailability of\nsimulation methods. The extension from the diffusion setting is not trivial due to the difference operator of\nthe jump component in the infinitesimal generator.\nThe approach that we develop in this paper is a remarkable improvement of the methodology of [5],\nin particular when considering value functions with compact support. In [5], bounding functions must be\nin polynomial form to arrive at a polynomial programming, while in principle, any polynomial function\nnecessarily explodes at infinity whenever it is constrained to be either non-positive or non-negative. Due to\nthis explosion at infinity, bounds are likely to be very far from the true value in particular when considering\nstochastic differential equations with very heavy tails and a value function with compact support. Such sit-\nuations are often of practical interest, for example, the tail probability estimation of a stochastic differential\nequation with jumps. To address this issue, we introduce the exponential tempering of bounding polyno-\nmial functions so that the explosion never occurs at infinity. It is the theoretical basis that the optimization\nproblem with the exponential tempering employed can still be transformed into a solvable polynomial pro-\ngramming after a minor approximation. Moreover, it turns out that exponential tempering widens the class\nof stochastic differential equations, for which every step of our method is well defined.\nThe rest of this paper is organized as follows. Section 2 provides some basic exposition of the optimiza-\ntion approach of the authors [5] and illustrates why the optimization approach fails to yield tight bounds for\nfunctions with a compact support, for example, in the tail probability estimation. Section 3 introduces our\napproach based upon exponential tempering of bounding functions and investigates how to transform the\ntempered polynomial optimization problem to a solvable polynomial programming after a minor approx-\nimation. Section 4 presents two numerical examples to illustrate that our approach yields tight bounds in\nestimation of tail probabilities and survival probabilities. Section 5 indicates the direction of future research,\nincluding an investigation of estimation quality with respect to exponential tempering, an empirical study\nof its range of applicability, and the challenge of extending this work to multivariate stochastic differential\nequations. In the appendix, we provide a brief sketch of the method-of-moments approach, that is dual to\npolynomial optimization.\n1Another approach to the generalized moment problem is the linear programming relaxation based on the Hausdorff moment\nconditions. See Lasserre and Prieto-Rumeau [8] for a comparison of the performances of SDP and LP approaches.\n2\n2 Motivation\nLet us begin this section with general notations which will be used throughout the text. We define R0 :=\nRnf0g, R+ := (0;+\u00a5), and denote by N the set of positive integers. We writeB(A) for the Borel s -field\nof a set A \u0012 R. For k 2 N, \u00b6k indicates the partial derivative with respect to k-th argument. We denote by\nCkt ;kx the class of continuous functions which are kt-times continuously differentiable with respect to the\nfirst variable and kx-times continuously differentiable with respect to the second variable. We denote by Cp\nthe class of polynomial functions in the form of\nfp(t;x) = \u00e5\nB(0;0)\nckt ;kxt\nktxkx ; (2.1)\nwhere\nB(l;m) :=\n\b\n(kt ;kx) 2 N2 : kt \u0015 l; kx \u0015 m; kt + kx \u0014 K\n\t\n;\nfor a fixed even natural number K, while fckt ;kxgB(0;0) is a sequence of constants. Throughout the paper,\nwe fix the even natural number K. (Note that the class Cp depends on this K.) We fix (W;F ;P) as our\nunderlying probability space.\nLet T > 0. Consider a one-dimensional stochastic differential equation\ndXt = a0 (t;Xt)dt+a1 (t;Xt)dWt +\nZ\njzj\u00141\nb(t;Xt\u0000;z)(m\u0000n)(dz;dt)\n+\nZ\njzj>1\nb(t;Xt\u0000;z)m(dz;dt); t 2 [0;T ]; (2.2)\nwhere the initial state X0 is fixed at a constant in R, fWt : t \u0015 0g is a standard Brownian motion and m is\na Poisson random measure on R0 whose compensator is given by the Le\u00b4vy measure n , that is, a s -finite\nmeasure defined on R0 satisfying Z\nR0\n\u0000jzj2^1\u0001n(dz)<+\u00a5: (2.3)\nHere, we assume that for each t 2 [0;T ], the functions a0(t;x), a1(t;x) and b(t;x;z) in (2.2) satisfy the usual\nconditions such as at most linear growth and Lipschitz so that the solution of (2.2) is well defined. (For\nexample, see Theorem 1.19 of \u00d8ksendal and Sulem [11] and Section 6.2 of Applebaum [1].) We henceforth\nequip our underlying probability space with the natural filtration (Ft)t2[0;T ] generated by fXt : t 2 [0;T ]g.\nMoreover, throughout this study, we assume that b(t;x;z) 6= 0 and n 6= 0 to avoid triviality. Moreover, we\nuse the notation\nX := inffB\u0012 R : P(Xt 2 B; t 2 [0;T ]) = 1; B connectedg ;\nwhere fXt : t 2 [0;T ]g is defined in (2.2). Note that by imposing that the set X is connected, it may be\nsignificantly larger than the state space of the sample paths. (For example, if fXt : t 2 [0;T ]g is a standard\nPoisson process, then its state space is N[f0g, while the above definition yieldsX = [0;+\u00a5).) This larger\nspace will be required for optimization problems.\nOur interest throughout this study is in approximating the expectation\nE [V (t;Xt)] :\nHere,V is a function mapping from [0;T ]\u0002R toR, piecewise polynomial in t and x and such that its support\nis a bounded subset of [0;T ]\u0002KV where KV is a bounded set and E[jV (t ;Xt)j] < +\u00a5. Note that the\nfunction V may have discontinuities. Moreover, t is an (Ft)t2[0;T ]-stopping time taking its values in [0;T ].\nFor the computation of E[V (t ;Xt)], standard techniques include the Monte Carlo simulation of sample paths\nthrough the time discretization of stochastic differential equations, or even some exact knowledge of sample\npaths such as series representation of the Poisson jump component. Let us illustrate difficulties arising in\n3\nthe approximation of stochastic differential equations with jumps in a simple setting, fix X0 > 0, t = T ,\na0(t;x) = a1(t;x)\u0011 0, and b(t;x;z) = xz, that is, (2.2) reduces to a Dole\u00b4ans-Dade stochastic exponential\ndXt = Xt\u0000\nZ\nR0\nz(m\u0000n)(dz;dt); X0 > 0; (2.4)\nwhich is a martingale with respect to its natural filtration. Assume further that the Le\u00b4vy measure n is\nsupported on (\u00001;+\u00a5). It is elementary that the Ito formula yields\nd lnXt =\u0000\nZ\n(\u00001;+\u00a5)\nzn (dz)dt+\nZ\n(\u00001;+\u00a5)\nln(1+ z)m (dz;dt) ;\nor equivalently,\nXt = X0 exp\n\u0014\n\u0000t\nZ\n(\u00001;+\u00a5)\nzn (dz)+\nZ t\n0\nZ\n(\u00001;+\u00a5)\nln(1+ z)m (dz;ds)\n\u0015\n: (2.5)\nIt follows from (2.5) that Xt > 0, a:s: For the computation of E[V (T;XT )], a standard technique is the Monte\nCarlo simulation with the sample generation of the marginal XT . Let us discuss some typical drawbacks in\nsimulation of XT defined by (2.4).\n(i) In the explicit solution (2.5), we are required to keep track of the Poisson random measure m for\nsimulation of the term\nR T\n0\nR\n(\u00001;+\u00a5) ln(1+ z)m(dz;ds), which can be done by using its shot noise\nseries representation. (See Rosin\u00b4ski [16] for details.) It is however usually difficult to find a shot\nnoise representation in a convenient form. In addition, it is often extremely expensive to use shot\nnoise series representation for computational purposes, since shot noise series for an infinite Le\u00b4vy\nmeasure is infinite as well.\n(ii) We may instead rely on the time discretization of sample paths through (2.4), while the resulting\nmarginal law may not be reasonably accurate. (In this example, it may take negative values, while\ninitially XT > 0, a.s. For details about the discretization error, see, for instance, Kloeden and Platen\n[7].) Estimation results for E[V (T;XT )] could then be completely misleading.\n(iii) It is rare to know how to simulate increments\nR t2\nt1\nR\nR0 z(m\u0000n)(dz;dt), with some exceptions such as\ngamma processes and stable processes. Moreover, Le\u00b4vy processes have no scaling property, except\nfor stable processes (including Brownian motion). Hence, it is often not as simple as in the diffusion\nsetting to examine different stepsizes of the Euler-Maruyama scheme.\nIn the diffusion setting, the above issues often do not arise. Namely, increments of Brownian motion can\neasily be generated and have scaling property; stochastic differential equations are often explicitly solvable\n(see Chapter 4.4 of Kloeden and Platen [7] for various such examples). Those comparisons illustrate the\ndifficulty of sample paths simulation for stochastic differential equations with jumps.\nMeanwhile, completely different approaches have recently been investigated in Kashima and Kawai [5]\nfor a general setting with jumps, based upon semi-definite mathematical programming providing us with\nupper and lower bounds of the expectation without generating random numbers. Let us first review their\nmathematical programming based approaches in brief. For f 2C1;2([0;T ]\u0002X ;R), the Ito formula yields\nd f (t;Xt) =A f (t;Xt)dt+\u00b62 f (t;Xt)a1(t;Xt)dWt +\nZ\nR0\nBz f (t;Xt\u0000)(m\u0000n)(dz;dt); a:s:;\nwhere\nA f (t;x) := \u00b61 f (t;x)+\u00b62 f (t;x)a0(t;x)+\n1\n2\n\u00b6 22 f (t;x)a1(t;x)2\n+\nZ\nR0\n\u0000\nBz f (t;x)\u0000\u00b62 f (t;x)b(t;x;z)1(0;1](jzj)\n\u0001\nn(dz); (2.6)\n4\nand for z 2 R0,\nBz f (t;x) := f (t;x+b(t;x;z))\u0000 f (t;x) ; (2.7)\nprovided that for each (t;x) 2 [0;T ]\u0002X ,Z\njzj>1\njBz f (t;x)jn(dz)<+\u00a5:\nOne of the important building blocks of our approach is the Dynkin formula;\nE [ f (t;Xt)]\u0000 f (0;X0) = E\n\u0014Z t\n0\nA f (s;Xs)ds\n\u0015\n; (2.8)\nwhere t is an (Ft)t2[0;T ]-stopping time taking its values in [0;T ]. We briefly summarize the conditions under\nwhich the formula makes sense. Throughout this paper, we write (with some abuse of notation)\nE0 := inffB\u0012 [0;T ]\u0002R : P((t; Xt) 2 B) = 1; B connectedg ;\nE1 := inffB\u0012 [0;T ]\u0002R : P((t; Xt) 2 B; t 2 [0;t)) = 1; B connectedg ;\nE2 := E0[E1:\nLemma 2.1. Let f 2C1;2(E2;R) and assume that for each (t;x) 2 E1, the function A f (t;x) in (2.6) is well\ndefined. Then, the Dynkin formula (2.8) holds if at least one of the following conditions is satisfied;\n(i) E[j f (t;Xt)j]<+\u00a5, and for almost surely all t 2 [0;t), E[jA f (t;Xt)j]<+\u00a5,\n(ii) E[\nR t\n0 (\u00b62 f (s;Xs)a1(s;Xs))2ds]<+\u00a5 and E[\nR t\n0\nR\nR0(Bz f (s;Xs))\n2n(dz)ds]<+\u00a5.\nProof. It is trivial that the formula holds when (i) is satisfied. Next, if (ii) is satisfied, then the stochastic\nprocess f f (t;Xt)\u0000 f (0;X0)\u0000\nR t\n0A f (s;Xs)ds : t 2 [0;t ]g is a square-integrable local martingale with respect\nto the filtration (Ft)t2[0;T ].\nRemark 2.2. In case of no jump component, there exist other trivial conditions for the Dynkin formula to\nhold, such as the function f has compact support, the stopping time t is the first exit time for a bounded\nsubset of X , and so on. Those conditions are no longer readily valid when the Poisson jump is involved,\ndue to the local difference operator Bz of (2.7).\nTo proceed with our discussion, assume that both a0(t;x) and a1(t;x) are polynomial in t and x and the\ncoefficient b is decomposed as b(t;x;z) = b1(t;x)b2(z), where b1(t;x) is polynomial both in t and x, and\nwhere b2 :R0 7!R such that\nR\nR0 jb2(z)j\nk n(dz)<+\u00a5, for k= 2; : : : ;K. Consider the following optimization\nformulation\nminfckt ;kxgB(0;0) fp(0;X0)\ns:t: fp(t;x)\u0015V (t;x) on E0;\nA fp(t;x)\u0014 0 on E1;\nfp 2Cp(E2;R):\n(2.9)\nLet us emphasize that decision variables of this optimization problem (and all in what follows) are the\ncoefficients fckt ;kxgB(0;0) in the definition of the polynomial (2.1). By further assuming E[jXt jK ] < +\u00a5 for\nt 2 [0;T ], we have\nA fp(t;x) = \u00e5\nB(1;0)\nckt ;kxktt\nkt\u00001xkx + \u00e5\nB(0;1)\nckt ;kxt\nktkxxkx\u00001a0(t;x)\n+\n1\n2 \u00e5B(0;2)\nckt ;kxt\nktkx(kx\u00001)xkx\u00002a1(t;x)2\n+ \u00e5\nB(0;2)\nckt ;kxt\nkt\nkx\u00002\n\u00e5\nk=0\nkxCkx\nkb1(t;x)kx\u0000k\nZ\nR0\nb2(z)kx\u0000kn(dz):\n5\nThis implies that the optimization (2.9) is a polynomial programming problem. If the problem (2.9) is feasi-\nble, it provides us with an upper bound fp(0;X0) of the expectation E[V (t ;Xt)], in view of the inequalities\nE [V (t ;Xt)]\u0014 E [ fp(t ;Xt)]\u0014 fp(0;X0);\ndue to (2.8).\nIn general, polynomial optimization problems are NP hard. However, if the degrees of fp, that is, K is\nfixed, sums-of-squares relaxation enables us to solve the problem efficiently. (For details, we refer to Parrilo\n[12].) To obtain lower bounds of E[V (t;Xt)], we are only to find gp 2 Cp(E2;R) through the polynomial\nprogramming\nmax gp(0;X0)\ns:t: gp(t;x)\u0014V (t;x) on E0;\nA gp(t;x)\u0015 0 on E1;\ngp 2Cp(E2;R):\n(2.10)\nAs previously mentioned, this optimization approach does not require the sample paths simulation at all\ntowards the approximation of the expectation.\nLet us close this section by pointing out some possible drawbacks of the above methods, which leads to\nthe motivation of our study.\n(i) In principle, the weak approximation problem is supposed to be well-posed, wheneverE[jV (t;Xt)j]<\n+\u00a5. On the contrary, most of the existing approaches listed above require that the marginals t and\nXt have finite moments of higher order. However, this requirement may rule out some interesting\nproblem settings, such as stochastic differential equations driven by a stable Le\u00b4vy process, that we\nwill deal with in Section 4. In addition, it is sometimes difficult to check whether the requirement is\nactually satisfied, in particular when stochastic differential equations are involved.\n(ii) Suppose that we are interested in a probability estimation of a non-negative marginal XT , that is, the\nstopping time t is frozen at T and E[V (T;XT )] = E[1(XT 2 [0;q ])] for some q > 0. We will observe\nthat limx\"+\u00a5 fp(T;x) = +\u00a5, since fp(T;x) is polynomial in x and must be no less than V (T;x) over\nX . When the marginal XT has very heavy tail, bounds are likely to be very far from the true value,\nthat is,\ngp(0;X0)\u0014 E [gp(T;XT )]\u001c E [V (T;XT )]\u001c E [ fp(T;XT )]\u0014 fp(0;X0):\nBy a similar reasoning, ifX = R, for example, then limjxj\"+\u00a5A fp(t;x) =\u0000\u00a5 due to the constraint\nA fp(t;x)\u0014 0 over [0;T ]\u0002X . If this is the case, then we will observe\ngp(0;X0)\u001c E [gp(T;XT )]\u001c E [V (T;XT )]\u001c E [ fp(T;XT )]\u001c fp(0;X0):\nLet us emphasize again that the explosion at infinity necessarily occurs, whenever the bounding\nfunctions are of a polynomial form. As an exception, the use of smooth piecewise polynomial may\navoid the explosion at infinity. However, this method easily increases the computing burden and is\nnot applicable to stochastic differential equations with jumps as discussed in Kashima and Kawai\n[6].\nTo address those issues, we introduce the exponential tempering of bounding functions in the next section.\n3 Exponential Tempering of Bounding Functions\nAs before, we assume that both a0 and a1 are in Cp(E1;R) and the coefficient b can be decomposed as\nb(t;x;z) = b1(t;x)b2(z). In principle, our approach is based on the replacement of the polynomial fp(t;x)\n6\nwith its tempered f (t;x) = e\u0000bx fp(t;x), and the optimization problem\nmin f (0;X0)\ns:t: f (t;x)\u0015V (t;x) on E0;\nA f (t;x)\u0014 0 on E1;\nf (t;x) = e\u0000bx fp(t;x) on E2;\nfp 2Cp(E2;R);\n(3.1)\nwhere the decision variable is again the set of coefficients fckt ;kxgB(0;0) given in (2.1). With this optimization\nproblem, in couple with a counterpart for lower bounds, we aim at finding bounds for E[V (t ;Xt)] based\nupon a set of inequalities\ng(0;X0)\u0014 E [g(t ;Xt)]\u0014 E [V (t;Xt)]\u0014 E [ f (t ;Xt)]\u0014 f (0;X0); (3.2)\nwhere g(t;x) = e\u0000bxgp(t;x) for some gp 2Cp(E2;R).\nPrior to the development of our method, let us discuss conditions for the function A f (t;x) to be well\ndefined. Rather than trying to cover a general class, we focus our attention on the class of Le\u00b4vy-driven\nstochastic differential equations, which is sufficiently large for practical use in most situations. Throughout\nthis paper, we will write\nAb fp(t;x) := \u00b61 fp(t;x)+(\u0000b fp(t;x)+\u00b62 fp(t;x))a0(t;x)\n+\n1\n2\n\u0000\nb 2 fp(t;x)\u00002b\u00b62 fp(t;x)+\u00b6 22 fp(t;x)\n\u0001\na1(t;x)2\n+\nZ\nR0\n\u0010\ne\u0000bb1(t;x)b2(z) fp (t;x+b1(t;x)b2(z))\u0000 fp(t;x)\n\u0000(\u0000b fp(t;x)+\u00b62 fp(t;x))b1(t;x)b2(z)1(0;1](jzj)\n\u0001\nn(dz): (3.3)\nProposition 3.1. Consider the optimization problem (3.1). Fix (t;x) 2 E1. Let b2(z) = z and let n be\nsupported on R+. If\n(i) bb1(t;x)> 0, or\n(ii)\nR\nz>1 e\n\u0000bb1(t;x)zz(K_1)n(dz)<+\u00a5,\nthen the function A f (t;x) is well defined and its sign is identical to that of Ab fp(t;x).\nProof. Observe that\nA f (t;x) = e\u0000bxAb fp(t;x):\nHence, we investigateAb fp(t;x). The drift and the diffusion components are clearly well defined. The jump\ncomponent can be rewritten asZ\nR0\n\u0010\ne\u0000bb1(t;x)b2(z)\u00001+bb1(t;x)b2(z)1(0;1](jzj)\n\u0011\nn(dz) \u00e5\nB(0;0)\nckt ;kxt\nktxkx\n+b1(t;x)\nZ\nR0\nb2(z)\n\u0010\ne\u0000bb1(t;x)b2(z)\u00001(0;1](jzj)\n\u0011\nn(dz) \u00e5\nB(0;1)\nkxckt ;kxt\nktxkx\u00001 (3.4)\n+ \u00e5\nB(0;2)\nckt ;kxt\nkt\nkx\u00002\n\u00e5\nk=0\nkxCkx\nkb1(t;x)kx\u0000k\nZ\nR\ne\u0000bb1(t;x)b2(z)b2(z)kx\u0000kn(dz):\nHence, Ab fp(t;x) is well defined, if all the integrals with respect to n are well defined. Note that the third\nintegral appears only when K \u0015 2. With this in mind, we suppose so during this proof.\n7\nFirst, as z # 0, the integrands of (3.4) behave like z2, z2 and zk, k = 2; : : : ;K, respectively. Hence, by\n(2.3), they integrate near the origin. (Note that the conditions (i) and (ii) are irrelevant to the integrability\nnear the origin.)\nNext, as z \" +\u00a5, the integrands of (3.4) are O(1), o(1) and o(1), respectively, if bb1(t;x) > 0. Hence,\nagain due to (2.3), the claim holds when (i) is satisfied. If (i) is not satisfied, then the integrands behave\nrespectively like e\u0000bb1(t;x)z, ze\u0000bb1(t;x)z and zke\u0000bb1(t;x)z, k = 2; : : : ;K, at infinity.\nThe last claim holds by A f (t;x) = e\u0000bxAb fp(t;x) and e\u0000bx > 0.\nLet us return to the optimization problem (3.1). The minimization of f (0;X0)with respect to fckt ;kxgB(0;0)\nis obviously an operation identical to the minimization of fp(0;X0), multiplied by e\u0000bX0 afterward, since\ne\u0000bX0 is independent of fckt ;kxgB(0;0). Next, we deal with the constraintA f (t;x)\u0014 0 over E1. The following\nresult provides a verifiable condition under which we can safely replace the constraint with Ab fp(t;x)\u0014 0.\nProposition 3.2. If b > 0 and if b1(t;x) is constant over E1, then Ab fp(t;x) is polynomial in t and x.\nProof. All the components, but the jump component, of Ab fp(t;x) are clearly polynomial in t and x. Con-\ncerning the jump component, the integrals in (3.4) are independent of (t;x) when the conditions are im-\nposed.\nRemark 3.3. It seems almost necessary to have that b1(t;x) is constant over E1. As an illustrative example,\nwe take the Le\u00b4vy measure n(dz) = e\u0000z=zdz, z 2 R+, of the gamma process. We then haveZ +\u00a5\n0\n\u0010\ne\u0000bb1(t;x)z\u00001+bb1(t;x)z\n\u0011\nn(dz) =\u0000 ln(1+bb1(t;x))\u0000bb1(t;x);\nthat cannot be polynomial in x no matter what polynomial b1 is chosen.\nWe have so far fixed most ingredients of the problem setting. Let us finalize the validity of the optimiza-\ntion problem (3.1).\nProposition 3.4. Let b > 0, let b1(t;x) be constant over E1, letX \u0012R+[f0g, and let f (t;x) = e\u0000bx fp(t;x)\nwhere fp 2 Cp(E2;R). Assume that for each (t;x) 2 E1, the function A f (t;x) is well defined. Then, the\nDynkin formula (2.8) holds.\nProof. Thanks to the polynomial form of Ab fp(t;x), it suffices to check if E[e\u0000bXtXkt ] < +\u00a5 for a suit-\nable k 2 N. For any well-defined non-negative random variable X and for each k 2 N, E[e\u0000bXXk] < +\u00a5,\nsince e\u0000bxxk \u0014 e\u0000k(k=b )k < +\u00a5 for x 2 R+ [ f0g. From this fact and X \u0012 R+ [ f0g, it follows that\nE[j f (t;Xt)j] < +\u00a5, and for each t 2 [0;t), E[jA f (t;Xt)j] < +\u00a5. Hence, by Lemma 2.1 (i), the claim\nholds.\nThis claims that when a non-negative process is considered, our methodology is well defined as soon as\nb > 0, with no additional condition on the law of the solution of stochastic differential equations. Therefore,\nthe exponential tempering widens the class of stochastic differential equations for which our methodology\nis well defined. For example, the integrals in (3.4) with respect to the stable Le\u00b4vy measure are well defined\nwhen b > 0, while not as soon as b \u0014 0. Also, when b < 0, one would need to check the conditions\npresented in Lemma 2.1, that are often not verifiable in particular when a stochastic differential equation\nis involved. We will henceforth assume that the Dynkin formula (2.8) holds and the optimization problem\n(3.1) is well defined.\nNow, coming back to the optimization problem (3.1), we have shown in Proposition 3.1 and 3.2 that the\nconstraintAb fp(t;x)\u0014 0 is equivalent toA f (t;x)\u0014 0. The optimization problem (3.1) is now transformed\ninto an equivalent form\ne\u0000bX0\u0002\nmin fp(0;X0)\ns:t: fp(t;x)\u0015 ebxV (t;x) on E0;\nAb fp(t;x)\u0014 0 on E1;\nfp 2Cp(E2;R):\n8\nFinally, the constraint fp(t;x) \u0015 ebxV (t;x) over E0 remains non-polynomial. There seem to be no exact\nmethods to transform ebxV (t;x) into a (piecewise) polynomial form. (Recall that V (t;x) may have disconti-\nnuities.) We instead try to replace this with a (piecewise) polynomial constraint, which is a little more con-\nservative than the original one. It suffices to approximate the exponential ebx by polynomial on a bounded\nsetKV thanks to the support of the functionV . It is not very difficult to find a (piecewise) polynomial u(t;x)\nsuch that u(t;x) \u0015 ebxV (t;x) over E0. For example, for a small tolerance e > 0, one first finds a (piece-\nwise) polynomial p(t;x) such that sup(t;x)2E0 jebxV (t;x)\u0000 p(t;x)j \u0014 e , and then set u(t;x) = p(t;x)+ e and\nl(t;x) = p(t;x)\u0000 e .\nSuppose that we have found polynomials u(t;x) and l(t;x) such that l(t;x) \u0014 ebxV (t;x) \u0014 u(t;x) over\nE0. Then, for each b > 0, we arrive at a polynomial programming problem\nHU(b ) := e\u0000bX0\u0002\nmin fp(0;X0)\ns:t: fp(t;x)\u0015 u(t;x) on E0;\nAb fp(t;x)\u0014 0 on E1;\nfp 2Cp(E2;R);\n(3.5)\nthat is a fairly close approximation of the original problem (3.1). For lower bounds, we compute\nHL(b ) := e\u0000bX0\u0002\nmin gp(0;X0)\ns:t: gp(t;x)\u0014 l(t;x) on E0;\nAbgp(t;x)\u0015 0 on E1;\ngp 2Cp(E2;R):\n(3.6)\nThe parameter b above can be chosen arbitrarily. We will look at its choice later in numerical examples.\nRemark 3.5. Notice that the exponential term e\u0000bx serves as an exponential tilting when applied to the\nwhole real line. It is the exponential tempering only when the state space of the stochastic differential\nequation is bounded on at least one side. It seems tempting to apply the exponential tempering e\u0000bx2 of\nsecond order (or of a higher even order) since it tempers any polynomial function on both sides and its\nderivative is still as simple as a product of a polynomial and the tempering term itself. We have however\nobserved that the application of a higher order tempering is not of practical use for the reason that ebx\n2\n(in\nthe constraint fp(t;x) \u0014 ebx2V (t;x)) grows so fast that the polynomial approximation is very difficult even\nover a bounded set.\nUnder mild conditions such as the moment determinate property, it is straightforward to theoretically\nguarantee the convergence of the gap to zero, when considering the dual problem summarized in the Ap-\npendix. (See, for example, Theorem 7 of [9].) In practice, however, it is truly impossible to take the degrees\nof polynomial arbitrarily large due to the well known curse of dimensionality of the semi-definite program-\nming.\nBefore proceeding to numerical examples, let us present a result on a transform of the value function V ,\nof practical interest.\nProposition 3.6. Let v be in C1([0;T ];R). For f in C1;2(E2;R) such that\nf (t;x)\u0015V (t;x)\u0000 v(t) on E0;\nA f (t;x)\u0014\u0000 d\ndt\nv(t) on E1;\nit holds that\nE [V (t;Xt)]\u0014 f (0;X0)+ v(0):\n9\nProof. The result holds by\nE [V (t ;Xt)\u0000 v(t)]\u0014 E [ f (t ;Xt)] = f (0;X0)+E\n\u0014Z t\n0\nA f (t;Xt)dt\n\u0015\n\u0014 f (0;X0)\u0000E\n\u0014Z t\n0\nd\ndt\nv(t)dt\n\u0015\n;\nwhere we have used the assumptions imposed on f .\nThis result is primarily meant for the case V does not have bounded support, while V (t;x)\u0000 v(t) does.\nIn order for this to be actually valid in our framework, we need to look closely at the above assumptions on\nf . Since f is of the form e\u0000bx fp(t;x) and A f (t;x) = e\u0000bxAb fp(t;x), we get\nfp(t;x)\u0015 ebx (V (t;x)\u0000 v(t)) on E0;\nAb fp(t;x)\u0014\u0000ebx\nd\ndt\nv(t) on E1:\nThis implies that the result is valid if the following two conditions are satisfied;\n(i) V (t;x)\u0000 v(t) has compact support in terms of x almost surely, or the set E0 is bounded,\n(ii) the set f(t;x) 2 E1 : (d=dt)v(t) 6= 0g is bounded.\nExamples in the following section are related to Proposition 3.6.\n4 Numerical Illustrations\nIn this section, we test numerically our method on a probability estimation of a stable subordinator and on\na survival probability of an Ornstein-Uhlenbeck process driven by a stable process, both without diffusion\ncomponent, that is, a1(t;x)\u0011 0. Throughout this section, we set ckt ;kx \u0011 0 for kt +kx >K where K is an even\nnatural number, and approximate ebx by the standard Taylor expansion \u00e5Kk=0(bx)k=k! around the origin of\norder K. The resulting approximation gap e :=max(t;x)2E0 jebxV (t;x)\u0000u(t;x)j is satisfactorily small in each\nexample, where u(t;x) =V (t;x)\u00e5Kk=0(bx)k=k! is then (piecewise) polynomial.\n4.1 Tail Probability of Stable Subordinator\nFor illustrative purpose, we first test our method on a toy example; the tail probability estimation for a stable\nsubordinator at time T . Set X0 = 0, a1(t;x) = 0, b1(t;x) = 1, b2(z) = z, and\nn(dz) =\n1\nz1+a\ndz; z 2 R+; (4.1)\nfor some a 2 (0;1), and a0(t;x) =\nR\nz2(0;1] zn(dz). Then, the stochastic differential equation reduces to a\nstable subordinator\nXt =\nZ t\n0\nZ\nR+\nzm(dz;ds): (4.2)\nIn this setting, we have\nAb fp(t;x) =\u00b61 fp(t;x)+ fp(t;x)\nZ\nR+\n\u0010\ne\u0000b z\u00001\n\u0011\nn(dz)\n+ \u00e5\nB(0;1)\nckt ;kxt\nkt\nkx\u00001\n\u00e5\nk=0\nkxCkx\nk\nZ\nR+\ne\u0000b zzkx\u0000kn(dz); (4.3)\n10\nwhere the integrals are explicit asZ +\u00a5\n0\n\u0010\ne\u0000b z\u00001\n\u0011\nn(dz) =\u0000b\na\na\nG(1\u0000a);\nand Z +\u00a5\n0\ne\u0000b zzkx\u0000kn(dz) =\nG(kx\u0000 k\u0000a)\nb kx\u0000k\u0000a\n;\nthat are well defined if and only if b > 0. Hence, fix b > 0. By X0 = 0, it holds thatX = R+. Moreover,\nE0 = fTg\u0002X and E1 = [0;T )\u0002X . By Proposition 3.4, the Dynkin formula holds and our methodology\nis well defined.\nNow, consider the asymptotic tail probability, as l \"+\u00a5,\nP(X1 > l )\u0018 1ala :\nTo this end, the value function should be set in the form ofV (t;x) = 1(x> l ), while this value function does\nnot have compact support. To apply Proposition 3.6, we set v(t)\u0011 1 so that 1(x > l ) = v(t)\u0000V (t;x). (To\ncomply with the formulation of Proposition 3.6, the transform should instead be\u00001(x> l ) =V (t;x)\u0000v(t),\nwhile the sign is certainly not fundamental.) Obviously, this transform is valid in our exponential tempering\napproach since V (t;x)\u0000 v(t) has compact support in terms of x and (d=dt)v(t)\u0011 0.\nUsing the selfsimilarity of stable processes fh\u00001=aXht : t \u0015 0g L= fXt : t \u0015 0g, we set V (t;x) = 1(x >\nt1=al ) with fXt : t 2 [0;T ]g for some small T > 0, rather than V (t;x) = 1(x> l ) with fXt : t 2 [0;1]g. We\nthen compute the probability through the equation\nP(X1 \u0014 l ) = 1\u0000P(X1 > l ) = E [v(T )\u0000V (T;XT )] ;\nwith l = T\u00001=a . We will rather report numerical results for the probability P(X1 \u0014 l ) since this is what\nour optimization procedure actually deals with.\nNumerical results with fixed polynomial degrees are presented in Table 1 and 2. For example, concerning\nthe case a = 0:3 and T = 0:001 in Table 2, we can choose the smallest upper bound and the largest lower\nbound, that is,\n0:996189\u0014 P\n\u0010\nX1 \u0014 T\u00001=a\n\u0011\n\u0014 0:997045;\nboth of which happen to be from b = 3:0. Since T\u00001=a is sufficiently large, we have\nP\n\u0010\nX1 \u0014 T\u00001=a\n\u0011\n\u0019 1\u0000 T\na\n= 0:996667 2 [0:996189; 0:997045]:\nThis also implies that the estimation of this tail probability requires one to deal with a highly rare event\nsimulation. To compare this result with the Monte Carlo framework, observe that\nVar\n\u0010\n1\n\u0010\nX1 \u0014 T\u00001=a\n\u0011\u0011\n= E\n\u0014\n1\n\u0010\nX1 \u0014 T\u00001=a\n\u00112\u0015\u0000Eh1\u0010X1 \u0014 T\u00001=a\u0011i2\n\u0019 1\u0000 T\na\n\u0000\n\u0012\n1\u0000 T\na\n\u00132\n= 0:057632:\nDenoting by bFn a Monte Carlo estimator for the random variable 1(X1 \u0014 T\u00001=a) based on n iid replications,\nits 99:9999%-confidence interval is approximately given by\u0014bFn\u00004:890:05763pn ; bFn+4:890:05763pn\n\u0015\n:\n11\nTo narrow the length of this approximate confidence interval to that of [0:996189; 0:997045], we need at\nleast n= 433539 of iid samples. This number does not support the use of Monte Carlo methods in full.\nLet us discuss further on a superiority of our method over Monte Carlo methods. On one hand, although\nthe strong law of large number guarantees the almost sure convergence of a well-defined Monte Carlo\nestimator to the true value in theory, it is rather usual that a limiting value is very far from the true value\nand is extremely sensitive to the seed selected for a random number generator on computer. On the other\nhand, our approach is based on a purely deterministic optimization method, free of random elements. Unlike\nconfidence intervals in the Monte Carlo framework, it is guaranteed that the true value sits somewhere within\nthe obtained optimality gap. Therefore, the optimality gap [0:996189; 0:997045] above can be considered\nas a 100%-confidence interval, which certainly predominates the Monte Carlo simulation with any large\nsample size. In fact, the 100%-confidence interval is simply impossible in the Monte Carlo framework\nunless the estimator is simply degenerate.\na = 0:3 a = 0:6\nK\n6 8 10 6 8 10\nT\n0.97247 0.97154 0.97132 0.98829 0.98765 0.98761\n0.01 (0.96667) (0.96667) (0.96667) (0.98333) (0.98333) (0.98333)\n0.95981 0.96147 0.96172 0.97568 0.97693 0.97699\n0.997220 0.997124 0.997104 0.998831 0.998772 0.998771\n0.001 (0.996667) (0.996667) (0.996667) (0.998333) (0.998333) (0.998333)\n0.995924 0.996097 0.996119 0.997594 0.997706 0.997707\nTable 1: Numerical Results for the estimation of P(X1\u0014 T\u00001=a)with b = 2 for different polynomial degrees\nK. Each consists of an upper bound, the theoretical asymptotic value (in the parentheses), and a lower bound.\na = 0:3 a = 0:6\nb\n1.0 2.0 3.0 1.0 2.0 3.0\nT\n0.97110 0.97132 0.97076 0.98846 0.98761 0.98696\n0.01 (0.96667) (0.96667) (0.96667) (0.98333) (0.98333) (0.98333)\n0.96045 0.96172 0.96265 0.97501 0.97699 0.97823\n0.997221 0.997104 0.997045 0.998874 0.998771 0.998701\n0.001 (0.996667) (0.996667) (0.996667) (0.998333) (0.998333) (0.998333)\n0.995922 0.996119 0.996189 0.997463 0.997707 0.997840\nTable 2: Numerical Results for the estimation of P(X1 \u0014 T\u00001=a) with K = 10 for different exponential tem-\npering parameters b . Each consists of an upper bound, the theoretical asymptotic value (in the parentheses),\nand a lower bound.\nRemark 4.1. We have observed through the numerical results in Table 2 that the choice of b may not largely\naffect the quality of the estimation. Note, however, that different b \u2019s lead to different polynomial optimiza-\ntion problems. In view of intrinsic nature of the numerical optimization, the semi-definite relaxation of\npolynomial optimization and so on, it is difficult to raise theoretical reasons why this family of optimiza-\ntion problems gave similar bounds for different b \u2019s. Our method may however tighten the optimality gap\nthrough the choice of b , without increasing the size of mathematical programming with larger polynomial\ndegree K. It seems that numerical results tend to be more sensitive to the choice of b as the marginal XT has\nlighter tails. This would be an interesting topic as a future work.\n12\n4.2 Survival Probability of Ornstein-Uhlenbeck Processes\nHere, we test our method on the survival probability estimation of an Ornstein-Uhlenbeck process driven by\na stable subordinator. (See Suzuki, Miyoshi and Kojima [18] for a similar problem in the diffusion setting.)\nCompared with the example of Section 4.1, this example entails a stopping time t , rather than the frozen\nterminal time T .\nSet n(dz) = z\u00001\u0000adz, z 2R+ as given by (4.1), and set a0(t;x) =\u0000lx+\nR\nz2(0;1] zn(dz) for some l > 0,\na1(t;x) = 0, b1(t;x) = 1, b2(z) = z, and X0 > 0. Then, the stochastic differential equation reduces to\ndXt =\u0000lXtdt+\nZ\nR+\nzm(dz;dt); (4.4)\nwhich is called an Ornstein-Uhlenbeck process. Its solution is given by\nXt = e\u0000l tX0+\nZ t\n0\nZ\nR+\ne\u0000l (t\u0000s)zm(dz;ds):\nIts sample paths can be simulated in the exact sense over a finite horizon [0;T ], T > 0, by using the series\nrepresentation of stable subordinators as\nfXt : t 2 [0;T ]g L=\n(\ne\u0000l tX0+\n+\u00a5\n\u00e5\nk=1\ne\u0000l (t\u0000Tk)\n\u0012\naGk\nT\n\u0013\u00001=a\n1(Tk 2 [0; t]) : t 2 [0;T ]\n)\n; (4.5)\nwhere fGkgk2N is a sequence of arrival times of a standard Poisson process and fTkgk2N is a sequence of\niid uniform random variables on [0;T ]. However, this simulation method is extremely expensive and not of\npractical use due to the infinite sum for each sample path. In addition, the Euler-Maruyama discretization\nof the stochastic differential equation is an expensive yet only approximative method, which in general\nproduces an estimation error due to the discrete monitoring.\nIn this setting, we have\nAb fp(t;x) =\u00b61 fp(t;x)\u0000lx(\u0000b fp(t;x)+\u00b62 fp(t;x))+ fp(t;x)\nZ\nR+\n\u0010\ne\u0000b z\u00001\n\u0011\nn(dz)\n+ \u00e5\nB(0;1)\nckt ;kxt\nkt\nkx\u00001\n\u00e5\nk=0\nkxCkx\nk\nZ\nR+\ne\u0000b zzkx\u0000kn(dz);\nwhere the integrals are well defined if b > 0 and are explicit as presented in Section 4.1. Henceforth, we fix\nb > 0. By X0 > 0, it holds thatX = R+. By Proposition 3.4, the Dynkin formula (2.8) holds and thus our\noptimization approach is well defined. Note that the Dynkin formula fails to hold as soon as b \u0014 0, since\nfor each t > 0,\nE[Xt ]\u0015 e\u0000l tX0+ e\u0000l tE\n\u0014Z t\n0\nZ\nR+\nzm(dz;ds)\n\u0015\n=+\u00a5:\nWe consider the survival probability of fXt : t 2 [0;T ]g with finite time horizon out of the bounded set\nE1 = [0;T )\u0002 [0;U ];\nwhereU > X0. Then, t is the (Ft)t2[0;T ]-stopping time defined by\nt := infft \u0015 0 : Xt =2 E1g^T;\nthat is, the first exit time out of E1. The random vector (t ;Xt) indicates the exit location, where E0 can split\ninto two disjoint sets\nEu := [0;T ]\u0002 (U;+\u00a5);\nEr := fTg\u0002 [0;U ]:\n13\nIt is enough to have Eu[Er for the exit location, since fXt : t 2 [0;T ]g is almost surely non-negative. The\nunboundedness of the set Eu corresponds to the unbounded jump size of the stable subordinator.\nTo estimate the survival probability P((t;Xt) 2 Er), we set V (t;x) := 1((t;x) 2 Er). Since V (t;x) has\ncompact support, we do not have to apply Proposition 3.6. Tempered polynomial optimization problems are\nformulated as\nmin e\u0000bX0 fp(0;X0)\ns:t: fp(T;x)\u0015 u(x) on [0;U ];\nfp(t;x)\u0015 0 on Eu;\nAb fp(t;x)\u0014 0 on E1;\nfp 2Cp(E2;R);\nand\nmax e\u0000bX0gp(0;X0)\ns:t: gp(T;x)\u0014 l(x) on [0;U ];\ngp(t;x)\u0014 0 on Eu;\nAbgp(t;x)\u0015 0 on E1;\ngp 2Cp(E2;R);\n(4.6)\nwhere u(x) and l(x) are polynomial functions bounding ebx respectively from above and below uniformly\nover Er.\n? ??? ? ??? ? ??? ? ??? ?????\n????\n?\n???\n???\n???\n???\n?\n???\nx ? ????\n???? ????\n???? ???\n?\n?\n?\n?\n?\n?\n????\n?\n???\n???\n???\n???\n?\n???\nx\nt\ng\u0003(T;x)\u0014 1(x 2 [0;U ])\u0014 f \u0003(T;x) f \u0003(t;x)\u0015 0, (t;x) 2 Eu\nFigure 1: Optimal Tempered Polynomial Functions of the Optimization Problems (4.6) with l = 1, T = 0:1,\nU = 1, and b = 3.\nIn Figure 1, we draw optimal bounding functions f \u0003 and g\u0003 to illustrate the advantage of our exponential\ntempering approach. First, the left figure indicates that at terminal time T , the bounding functions bound\nthe step function 1(x 2 [0;U ]) from above and below. In contrast to the polynomial case with explosion at\ninfinity, it also indicates that they satisfy the ideal property that for each t 2 [0;T ],\nlim\nx\"+\u00a5\nf \u0003(t;x) = lim\nx\"+\u00a5\ng\u0003(t;x) = 0:\nThis avoids bounding functions to be far from one another and helps to achieve a tight optimality gap.\nNext, the right figure draws f \u0003 on the set Eu. Here, we are required to deal with two somewhat conflicting\nrequirements on the positive function f \u0003; it is desired to be as close to zero as possible uniformly over Eu,\nwhile the inequality f \u0003(T;U)\u0015 1 must hold at the boundary point (T;U). As can be observed, however, our\napproach works effectively under such a complex circumstance in such a way that the tempered bounding\nfunction f \u0003 tends rapidly to vanish at infinity. Let us emphasize again that this never comes true with\nbounding functions of polynomial form, that explode at infinity.\nRemark 4.2. In this problem setting, other quantities can also be estimated by our approach. One exam-\nple is the moment of the exit time, investigated in [4]. First, consider the value function V (t;x) = tk for\n14\nE[V (t ;Xt)] = E[tk]. The tempered optimization problem for this setting,\nmin e\u0000bX0 fp(0;X0)\ns:t: fp(t;x)\u0015 tkebx on E0;\nAb fp(t;x)\u0014 0 on E1;\nand\nmax e\u0000bX0gp(0;X0)\ns:t: gp(t;x)\u0014 tkebx on E0;\nAbgp(t;x)\u0015 0 on E1;\nis not solvable due to the exponential tempering because the set E0 is unbounded and the value function\nV (t;x) does not have bounded support. Instead, by applying Proposition 3.6 with v(t) = tk, we arrive at the\ntempered optimization problems are now formulated as\nmin e\u0000bX0 fp(0;X0)\ns:t: fp(t;x)\u0015 0 on E0;\nAb fp(t;x)\u0014\u0000ebxktk\u00001 on E1;\nand\nmax e\u0000bX0gp(0;X0)\ns:t: gp(t;x)\u0014 0 on E0;\nAbgp(t;x)\u0015\u0000ebxktk\u00001 on E1:\nThose are valid formulations since then V (t;x)\u0000 v(t)\u0011 0 and the set E1 is bounded.\nRemark 4.3. We have so far considered exponential tempering with b > 0, while a negative b may also\nbe chosen as soon as all required conditions are satisfied. For instance, consider the Ornstein-Uhlenbeck\nprocess (4.4) with m being a Poisson random measure whose compensator is given by the truncated stable\nLe\u00b4vy measure n(dz) = z\u00001\u0000adz supported on (0;h ], for some h > 0. Due to its bounded size of jumps, the\novershoot out of the set E1 in is certainly bounded, that is, the set Eu is bounded; Eu = [0;T ]\u0002 (U;U +h).\nContrary to our initial motivation, the optimization problems (4.6) can then be formulated with every b 2\nR. In connection with Remark 4.1, however, this provides us with some possibility of obtaining a tighter\noptimality gap.\n5 Concluding Remarks\nIn this paper, we have proposed an improvement of the optimization methodology of [5] through exponential\ntempering of bounding functions when value functions have compact support. Our approach yields lower\nand upper bounds of the expectation for stochastic differential equations with jumps without Monte Carlo\nsample paths simulation, which often requires extremely expensive computing effort. We have shown that\nthe tempered polynomial optimization can be transformed into a polynomial optimization problem after the\npolynomial approximation of the exponential function on a compact set. Moreover, exponential tempering\nwidens the class of stochastic differential equations to which our methodology is actually applicable.\nAs discussed in Remark 4.1 and 4.3, the estimation quality may be improved by choosing the parameter\nb wisely, without increasing the size of mathematical programming. We did not present an exhaustive\nstudy of its range of applicability relative to different value functions or underlying stochastic differential\nequations, which is significantly large. In fact, encouraged by the quality of numerical results and by the\nwide applicability, our methodology is expected to be a standard tool for the weak approximation of a general\nclass of stochastic differential equations with jumps. We should also remark that this framework may not be\nas robust as Monte Carlo methods when underlying stochastic differential equations are multivariate. These\nissues will be addressed in subsequent papers.\nAcknowledgements\nThe authors would like to thank Prof. Masakazu Kojima of Tokyo Institute of Technology for valuable\ncomments on polynomial optimization and semi-definite programming, and Kenya Nakamura and Damian\nHobson-Garcia for assistance with the computations reported in this paper. The authors gratefully acknowl-\nedge Grant-in-Aid for Scientific Research 20740059 and 21686039 from Japan Society for the Promotion\nof Science. Part of this work was carried out while RK was based at Center for the Study of Finance and\nInsurance, Osaka University.\n15\nAppendix: Generalized Problem of Moments\nIn principle, this approach is aimed at maximizing and minimizing the expectation, rather than its bounds\nas in our approach, where the underlying probability measure implicitly serves as the decision variable,\nunder the so-called moment conditions that reflect necessary conditions for a set of scalars to be identified\nwith moments of the probability measure. Due to the nature of methods, they are often called a method-of-\nmoments approach altogether in the literature.\nTo be more mathematically precise, we illustrate this approach under the setting of Section 4.2. Define\nthe distribution of the exit location by\nn0(B) := P((t;Xt) 2 B); B 2B(E0);\nand the expected occupation measure on the set E1 until the exit by\nn1(B) := E\n\u0014Z t\n0\n1((t;Xt) 2 B)dt\n\u0015\n; B 2B(E1):\nWith the measures n0 and n1, the Dynkin formula (2.8) readsZ\nEr\nf (t;x)n0(dt;dx) = f (0;X0)\u0000\nZ\nEu\nf (t;x)n0(dt;dx)+\nZ\nE1\nA f (t;x)n1(dt;dx);\nwhich is the so-called basic adjoint equation, named by Helmes, Ro\u00a8hl and Stockbridge [4]. We have shown\nthat for each non-negative integer k and l,\nb(top)k;l :=\nZ\nEu\ne\u0000bxtkxln0(dt;dx);\nb(rig)l :=\nZ\nEr\ne\u0000bxxln0(dt;dx);\nmk;l :=\nZ\nE0\ne\u0000bxtkxln1(dt;dx):\nare well defined. In the method-of-moments, the quantities above serve as decision variables in the resulting\nsemi-definite programming. First, by plugging a tempered monomial of the form\nf (t;x) = e\u0000bxtkxl;\ninto the basic adjoint equation, we obtain a family of equality constraints that moment sequence should\nmeet. Second, we constrain that the adequately defined moment and localizing moment matrices are positive\nsemi-definite. It is a necessary condition for decision variables to be moment sequence with respect to some\nmeasure on Eu; Er; and E0. Under these two constraints, the maximal and minimal values of \u00e5k ckb\n(rig)\nk are\nrespectively upper and lower bounds for the desired survival probability, where the sequence fckgk of real\nnumbers must satisfy, respectively, \u00e5k ckxk \u0015 ebx and \u00e5k ckxk \u0014 ebx uniformly over [0;U ].\nReferences\n[1] Applebaum, D. (2004) Le\u00b4vy Processes and Stochastic Calculus, Cambridge University Press.\n[2] Bertsimas, D., Popescu, I., Sethuraman, J. (2000) Moment problems and semidefinite programming, In: Handbook on\nsemidefinite programming: Theory, Algorithms, and Applications, H. Wolkovitz, ed., 469-509.\n[3] Eriksson, B., Pistorius, M. (2008) A method of moments approach to pricing double barrier contracts driven by a general\nclass of jump diffusions, available at arXiv:0812.4548v1.\n[4] Helmes, K., Ro\u00a8hl, S., Stockbridge, R.H. (2001) Computing moments of the exit time distribution for Markov processes by\nlinear programming, Operations Research, 49(4) 516-530.\n16\n[5] Kashima, K., Kawai, R. (2011) An optimization approach to weak approximation of stochastic differential equations with\njumps, Applied Numerical Mathematics, 61(5) 641-650.\n[6] Kashima, K., Kawai, R. (2010) An optimization approach to weak approximation of Levy-driven stochastic differential\nequations, Perspectives in Mathematical System Theory, Control, and Signal Processing: A Festschrift in Honor of Yutaka\nYamamoto on the Occasion of his 60th Birthday (Lecture Notes in Control and Information Sciences 398), J. C. Willems, S.\nHara, Y. Ohta and H. Fujioka, Eds. Spinger, 263-272.\n[7] Kloeden, P.E., Platen, E. (1999) Numerical Solution of Stochastic Differential Equations, Third Printing, Springer, Berlin.\n[8] Lasserre, J.B., Prieto-Rumeau, T. (2004) SDP vs. LP relaxations for the moment approach in some performance evaluation\nproblems, Stochastic Models, 20(4) 439-456.\n[9] Lasserre, J.B., Prieto-Rumeau, T., Zervos, M. (2006) Pricing a class of exotic via moments and SDP relaxations,Mathemat-\nical Finance, 16(3) 469-494.\n[10] Nishihara, M., Yagiura, M., Ibaraki, T. (2007) Duality in option pricing based on prices of other derivatives, Operations\nResearch Letters, 35(2) 165-171.\n[11] \u00d8ksendal, B., Sulem, A. (2007) Applied Stochastic Control of Jump Diffusions (2nd Edition) Springer-Verlag Berlin Heidel-\nberg.\n[12] Parrilo, P.A. (2003) Semidefinite programming relaxations for semialgebraic problems, Mathematical Programming Series\nB, 96(2) 293-320.\n[13] Prajna, S., Papachristodoulou, A., Seiler, P., Parrilo, P.A. (2004) SOS-TOOLS: Sum of squares optimization toolbox for\nMATLAB.\n[14] Primbs, J.A. (2008) Optimization based option pricing bounds via piecewise polynomial super- and sub-martingales, In:\n2008 American Control Conference.\n[15] Protter, P. Talay, D. (1997) The Euler scheme for Le\u00b4vy driven stochastic differential equations, Annals of Probability, 25,\n393-423.\n[16] Rosin\u00b4ski, J. (2001) Series representations of Le\u00b4vy processes from the perspective of point processes, In: Le\u00b4vy Processes -\nTheory and Applications, Eds. Barndorff-Nielsen, O.-E., Mikosch, T., Resnick, S.I., Birkha\u00a8user, 401-415.\n[17] Sturm, J. (2006) SeDuMi version 1.1., available at http:\/\/sedumi.ie.lehigh.edu\/\n[18] Suzuki, K., Miyoshi, N., Kojima, M. (2008) A numerical method for survival probability of diffusion processes using\nsemidefinite programming (in Japanese), Transactions of the Operations Research Society of Japan, 51(1) 25-43.\n17\n"}
{"doi":"10.1109\/ISTMWC.2007.4299327","coreId":"102394","oai":"oai:epubs.surrey.ac.uk:1853","identifiers":["oai:epubs.surrey.ac.uk:1853","10.1109\/ISTMWC.2007.4299327"],"title":"Enhancing wireless video transmissions in virtual collaboration environments","authors":["Abdul-Hameed, O","Nasir, S","Karim, H","Masterton, T","Kondoz, AM"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-01-01","abstract":"This paper introduces the virtual collaboration\\ud\nenvironment and discusses the problems encountered in wireless\\ud\nvideo transmissions of the participating users. Different schemes\\ud\nare proposed and evaluated to address various problems\\ud\nencountered in the wireless access links of the virtual\\ud\ncollaboration system for enhancing the perceived visual quality.\\ud\nThe schemes include radio network resource optimization,\\ud\noptimal joint source and channel rate allocation and error\\ud\nresilience enhancement using SVC-MDC. These schemes have\\ud\nbeen shown to offer a strong potential to be incorporated in a\\ud\nvirtual collaboration system for quality enhancement","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"IEEE","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:1853<\/identifier><datestamp>\n      2017-01-04T11:18:54Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/1853\/<\/dc:relation><dc:title>\n        Enhancing wireless video transmissions in virtual collaboration environments<\/dc:title><dc:creator>\n        Abdul-Hameed, O<\/dc:creator><dc:creator>\n        Nasir, S<\/dc:creator><dc:creator>\n        Karim, H<\/dc:creator><dc:creator>\n        Masterton, T<\/dc:creator><dc:creator>\n        Kondoz, AM<\/dc:creator><dc:description>\n        This paper introduces the virtual collaboration\\ud\nenvironment and discusses the problems encountered in wireless\\ud\nvideo transmissions of the participating users. Different schemes\\ud\nare proposed and evaluated to address various problems\\ud\nencountered in the wireless access links of the virtual\\ud\ncollaboration system for enhancing the perceived visual quality.\\ud\nThe schemes include radio network resource optimization,\\ud\noptimal joint source and channel rate allocation and error\\ud\nresilience enhancement using SVC-MDC. These schemes have\\ud\nbeen shown to offer a strong potential to be incorporated in a\\ud\nvirtual collaboration system for quality enhancement.<\/dc:description><dc:publisher>\n        IEEE<\/dc:publisher><dc:date>\n        2007-01-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/1853\/1\/fulltext.pdf<\/dc:identifier><dc:identifier>\n          Abdul-Hameed, O, Nasir, S, Karim, H, Masterton, T and Kondoz, AM  (2007) Enhancing wireless video transmissions in virtual collaboration environments   2007 PROCEEDINGS OF THE 16TH IST MOBILE AND WIRELESS COMMUNICATIONS, VOLS 1-3.  pp. 1484-1488.      <\/dc:identifier><dc:relation>\n        10.1109\/ISTMWC.2007.4299327<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/1853\/","10.1109\/ISTMWC.2007.4299327"],"year":2007,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"Enhancing Wireless Video Transmissions in\nVirtual Collaboration Environments\n0. Abdul-Hameed,\"1' S. Nasir,\"1' H. Karim,Ell T. Masterton, 21 and A. M. KondozEl1\nAbstract-This paper introduces the virtual collaboration\nenvironment and discusses the problems encountered in wireless\nvideo transmissions of the participating users. Different schemes\nare proposed and evaluated to address various problems\nencountered in the wireless access links of the virtual\ncollaboration system for enhancing the perceived visual quality.\nThe schemes include radio network resource optimization,\noptimal joint source and channel rate allocation and error\nresilience enhancement using SVC-MDC. These schemes have\nbeen shown to offer a strong potential to be incorporated in a\nvirtual collaboration system for quality enhancement.\nIndex Terms-Heterogeneous environment, rate allocation,\nSVC-MDC, virtual collaboration system.\nI. INTRODUCTION\nTHE virtual collaboration environment is a system where\nremotely located users meet in a virtual environment\ncreated by the audiovisual technologies as if they were located\nin the same room. In this paper, we focus on QoS provisioning\nin the wireless segments of the virtual collaboration\nenvironment using the Virtual Collaboration System (VCS)\ndescribed by VISNET II Network of Excellence (NoE) of the\nIST FP6 programme. The VCS is currently being used and\nimproved by the NoE partners for achieving cross theme\nintegration by bringing together the work performed in the\nthree VISNET II themes, being video coding, audiovisual\nmedia processing and security.\nCollaborative Working Environments (CWEs) are identified\neither as \"synchronous\" where both parties communicate in\nreal time to achieve a common goal or \"asynchronous\" where\nthey share common artefacts in a workspace but users may\naccess them individually at different times as defined by\nworkflow considerations. Real time audio and video\ntechnologies are required for the basic video conferencing\nelement of synchronous collaboration. Means for contact\nmanagement, link establishment, communications security,\n[1] 0. Abdul-Hameed, S. Nasir, H. Karim and A. M. Kondoz are with the\nI-Lab\/Centre for Communication Systems Research (CCSR), University of\nSurrey, Guildford GU2 7XH, UK (Tel: +44 (0) 1483 686002; Fax: +44 (0)\n1483 686011; emails: {O.Abdul-Hameed, S.Nasir, H.Karim,\nA.KondozI @surrey.ac.uk).\n[2] T. Masterton is with Thales Research and Technology (UK) Ltd.,\nWorton Drive, Worton Grange Business Park, Reading RG2 OSB, Berkshire,\nUK (Tel: +44 (0) 1189238266; Fax: +44 (0) 1189238399; email:\ntim.masterton@thalesgroup.com).\naccess control and link encryption are also required. Internet\nProtocol (IP) is the connection infrastructure of choice as it\nsupports all required types of communication and is becoming\never more widespread with high capacity. However it brings\nthe limitation of occasional unpredictability, particularly for\ndelays in real time audio and video streams. Investigation of\nthe connectivity problems that occur and Quality of Service\n(QoS) technology to ensure that the user perception is not\nunduly affected by link imperfections is necessary.\nAsynchronous collaboration adds the requirements for a\npersistent store of information that is not dependent on the\navailability of any particular user or terminal and meets certain\navailability criteria. It also requires the presence of work flow\nelements in the system for controlling access sequences,\nhandling the human factors issues of notifying changes by\nother users, maintaining efficiency, controlling release states\nand achieving transactions on the workspace.\nLarge Terminal\nGroup of co-located\nusers with large fixed\nterminal\n---\nX User\n(1 n)\nSmall Terminal\nSingle remote user with,\nsmall fixed terminal User\n(1)\nVirtual Collaboration\nSystem\nMobile terminal\nSingle remote user\nwith mobile terminal\nUser\n(1)\nFig. 1. Virtual collaboration environment diagram.\nThe rest of the paper is organized as follows: Section II\ndiscusses the problems encountered in the wireless segment of\na virtual collaboration environment. In Section III, we propose\nsolutions to these problems. Section IV concludes the paper.\nII. PROBLEM STATEMENT\nA. Heterogeneous Access Networks\nIn a virtual collaboration environment, remote users may\nparticipate in a virtual collaboration session using different\naccess links and devices. The access links can be wired or\nwireless. Considering wireless access links, different options\nare available, for example GSM, GPRS, UMTS, WLAN or\nWiMAX [13]. In video transmissions over these\nheterogeneous wireless access technologies, problems may\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 12,2010 at 08:35:40 UTC from IEEE Xplore.  Restrictions apply. \narise due to the differences in available data rates (for\nexample, up to 2 Mbps in UMTS, up to 54 Mbps in WLAN\nand up to 70 Mbps in WiMAX), QoS discrepancies and time-\nvarying transmission characteristics of the wireless channels\ndue to user mobility and interference [14]. Therefore, it is\nnecessary to setup the required resources so that the expected\nend to end QoS may be achieved by negotiating suitable traffic\nand QoS parameters and optimizing the radio network\nresources accordingly. In addition, it is also necessary to have\nthe dynamic adaptation mechanisms that take into account the\ntime-varying characteristics of the wireless channel.\nB. Source Channel Rate Allocation Optimisation\nPrioritised content adaptation can be applied for the\nefficient use of radio network resources under specific network\nconditions such as network overload situations. Certain\nregions of the input video bit stream can be assigned more\nimportance as compared to other regions of the video frame\nthat may be of less interest. A particular user for example who\nis involved in a videoconference using a mobile device may be\nmore interested in the talking person's region as compared to\nother participants. Similarly, viewers would be more interested\nin the action area of a particular news clip being aired on a\nmobile TV application. This can be achieved by prioritising\ndifferent parts of the video bit stream and sending them using\nmultiple radio bearers with different characteristics, such as\nchannel coding, modulation etc. This would essentially require\noptimally separating the encoded bit stream into a number of\nsub-streams and allocating source and channel resources to\neach stream according to the perceived importance of the\nparticular region. Joint source-channel coding approaches [1]\nhave proven to significantly enhance performances for video\napplications over practical systems. Application scenarios\nimplementing these techniques have been discussed in [2, 6]\nthat closely relate to the Virtual collaboration scenario.\nC. Scalability Issues\nIf users with various different contexts (including location,\nterminal capability, and link parameters) wish to collaborate as\nwell as possible using with their available access links, the\noverall collaboration system will be heterogeneous and so\nelements must be placed in the network to scale content\nappropriately for a range of device capabilities. For example\nsome specialist workers may need to have their hands free\nwhile collaborating, whereas others may have the luxury of\npresentation quality interfaces and vast quantities of\ninformation to analyse. This requires context detection, stream\nadaptation and scalable encoding for video, audio and data\nstreams. The scalable encoding for video data issue in VCS\nshall be well addressed by a well known technique in video\ncoding community, namely Scalable Video Coding (SVC). It\nallows the decoding of appropriate subsets of bit-stream to\ngenerate complete pictures of size and quality dependent on\nthe proportion of the total bit stream decoded. Universal media\naccess in virtual collaboration system can be made possible\nwith SVC by coding the video only once to achieve a scalable\ncoded stream. This stream can then be accessed 'anytime',\nfrom 'anywhere' using any access network such as wireless\nand Internet, and by any terminal complexity. The scalable\nproperties come at the expense of decreased coding efficiency\nas it often introduces a degree of data redundancy. In general,\nSVC can be divided into three basic types namely quality\nscalability (Signal to Noise Ratio (SNR) scalability), spatial\nscalability and temporal scalability. Combination of three\nscalable types can also be achieved to produce hybrid\nscalability [8]. SVC produces video layers which consist of a\nbase layer and a number of enhancement layers. The base layer\nis essential for the video decoder to produce a basic acceptable\noutput. The enhancement layers help to improve the visual\nquality if received by the decoder. Without the base layer,\nenhancement layers only are useless to the decoder. The video\nquality issue in virtual collaboration system is partly caused by\na packet loss problem in the main Internet. Hence, there are\ntwo issues that should be addressed in the VCS being error\nresilience and scalability aspect of the video. One of the ways\nto address these problems is by using scalable multiple\ndescription coding (SVC-MDC) to encode the video. SVC-\nMDC has been proposed to improve error resilience of the\ntransmitted video over unreliable networks and at the same\ntime provide adaptation to bandwidth variations and receiving\ndevice characteristics [9].\nIII. PROPOSED SOLUTIONS\nA. Setting up the Required Resources for Achieving the\nExpected End to End QoS\nConsidering a scenario where an emergency personnel user\nrequiring to participate in a crisis management virtual\ncollaboration session using a handheld terminal while being in\na WCDMA UMTS coverage area. If at the time of the\nconnection request the UMTS cell was overloaded, the user\nmay be denied access to the network [12] and hence to the\nvirtual collaboration session. A scheme proposed in [15] was\nmodified to produce a scheme for optimizing the radio\nnetwork resources based on users' QoS parameters (e.g. bit\nrate, blocking and dropping probabilities) and user's\npreferences (e.g. video resolution, error resilience) for\nimproving the blocking probability for high priority incoming\ncall requests that are classified into three levels being\nEnhanced, Medium and Normal according to how much the\nusers are paying for the service. Users belonging to the\nEnhanced level such as an emergency personnel user will have\nan enhanced QoS, whereas users belonging to the Medium\nlevel will have moderate QoS and users belonging to the\nNormal level will have normal QoS in terms of blocking\nprobability. The scheme is illustrated in the following\nflowchart in Fig. 2. The scheme's performance was evaluated\nusing an implemented and validated with [12] system level\nsimulator for WCDMA UMTS. Fig. 3 shows the accepted\ntraffic versus the offered traffic curves in erlangs\/cell. The top\ntwo red curves are for voice traffic at 12.2 kbps for validation.\nThe bottom three curves are for video with the top curve for\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 12,2010 at 08:35:40 UTC from IEEE Xplore.  Restrictions apply. \nvideo at 64 kbps, the bottom curve for video at 128 kbps,\nwhereas the middle curve is obtained when using the scheme\nwhich indicates improved accepted traffic (or equivalently\nlower blocking probability) for the Enhanced video users.\nFig. 2. Flow chart illustrating the radio network resource optimisation\nscheme.\n14\na) 120\na)\no 10\n8\na)\na)\n6\n- original_0.5\n-voice, SF=128, CAC thr=0.5 (validation)\n-video, SF=32, CAC thr=0.3\nvideo, SF=16, CAC thr=0.2\nvideo, SF=16 to 32, CACGthr=0.1 to 0.2 (scheme)\ndata in different video packets, which is calculated by the\nestimated perceived importance of bits at the encoder. It then\napplies differential protection by sending prioritised data over\nmultiple radio bearers. Realisation of the proposed scheme is\npresented in Fig. 4 below.\nPhSource-channel rate\nF adaptation algorithm s\nThe transmission channelis characterised bytChanne prota lty\n|Channel multiplexingl l\nPhysical channel >\nof channel bit errors and the channel bandwidth, R(h, expressed\nin terms of bits per second. Assume that the underlying\ncommunication system allows a maximum of N\ncommunication sub-channels or radio bearers for a given video\nservice. The encoded bit stream is separated into N number of\nsub-streams. R, denotes the channel bit rate on the nh sub-\nchannel, and X, is the channel coding rate on the nh sub-\nchannel. The optimum possible source rate, R, is a function of\nchannel bit rate, R, and channel coding rate, X,\nR = RI +--- +Rn +--- +RN\nRCh >Rl IX + + RnlIXn + ...+ RNIXN\nThe expected distortion due to the corruption of the n[h sub-\nstream is E(Dj). Hence the total sequence distortion E(D)\nbecomes:\nN\nE(D) = Z E(Dn)\nn=l\n(2)\n0 10 20 30 40\noffered traffic [erl\/cell]\nFig. 3. Accepted traffic versus offered traffic for different rates.\n50\nB. Optimal Joint Source Channel Bit Rate Allocation\nIn this subsection, we introduce the design of an optimal\njoint source channel bit rate allocation for video transmissions\nover wireless networks. The proposed scheme utilizes bit level\nunequal error protection (UEP) and joint source channel\ncoding to obtain optimal video quality over a wide range of\nchannel conditions. The encoded video data is separated into a\nnumber of sub-streams based on the relative importance of\nThe goal set here is to find the optimal sub-stream\nseparation and mapping of sub-stream data onto multiple radio\nbearers in such a way to maximise the received video quality\nfor video transmission over a bandwidth limited error prone\nwireless channel. The optimisation problem can formally be\nwritten as:\nN\nMinimise E(D) = Z E(D )\nn=l\n(3)\nSubject to:\nRI\/1+-...+Rnln+-...+ RN\/IN <RCh (4)\nThe proposed algorithm operates at video frame level with\nthe estimation of the source rate, R, for given channel\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 12,2010 at 08:35:40 UTC from IEEE Xplore.  Restrictions apply. \nbandwidth\/protection. After encoding the video frame with the\nestimated source rate, the expected distortion is calculated at\nvideo packet level. Based on the calculated distortion values,\ndata partition of each video packet is assigned an importance\nlevel. Data separation into N number of sub-streams is\nperformed based on the calculated importance levels.\nInstantaneous channel quality for each selected sub-channel is\npredicted. The source rates for sub-channels are calculated and\nthe channel bandwidth requirement set out in Equation 4 is\nchecked. If the bandwidth requirement is not satisfied, the data\non the highly protected sub-channels are reduced and the\nimportance levels are re-calculated. Expected frame distortion\nis calculated again and the step is repeated until the minimum\ndistortion value is obtained.\nThe distortion for current frame being encoded is estimated\nusing the model presented in [5]. Standard object segmentation\navailable in MPEG-4 is used for these experiments. The\n\"Singer\" and \"Kettle\" test sequences have been used in this\nexperiment. The \"Singer\" sequence is used as the background\nand the \"Kettle\" sequence is segmented and used in the\nforeground of the output sequence each transmitted over\ndifferent radio bearers with unequal error protection. The CIF\n(352 x 288 pixels) sequences are coded at 30 fps.\n(a) (b)\n(c)\nFig. 5. Input sequences: (a) Singer.cif, (b) Kettle.cif, (c) Output composite\nimage at decoder.\nC. Error Resilience Enhancement Using SVC-MDC\nSVC-MDC aims to combine the flexibility of scalable\ncoding with the robustness of MDC. The objective of the\nSVC-MDC scheme is to enhance error resilience of the base\nlayer of SVC using temporal MDC. The base layer is the most\nimportant part of the SVC bitstream, as all the other layers\ndepend on it. Therefore, it is important to make it error robust.\nThe temporal MDC of the base layer is produced using the\nmulti-state video coding approach as in [10] which separates\nthe even and odd frames of a sequence into two MDC streams\nas shown in Fig. 6. Streams 1 and 2 contains even and odd\nframes respectively. With this approach, MDC loses its coding\nefficiency due to the prediction from previous two frames and\nlonger motion vector need to be coded.\nEven frames: 0 2 4 6\nErrors propagate\nOdd frames: 0 1 3 5 7...\nDisplayed: 0 1 2 3\nframes\nFig. 6. MDC streams.\n5 7 9 11\nReduced frame rate\nIf both the even and the odd streams are received, the\ndecoder can reconstruct the coded sequence at full temporal\nresolution. If only one of the streams is received, the decoder\ncan still decode the received stream at half the original\ntemporal resolution. Since the even frames are predicted from\nprevious even frames (independent from odd frames), there\nwill be no mismatch if one of the streams are lost at the\ndecoder. Additionally, in the case of one stream being\nreceived, the decoder can decode at the full resolution by\ninterpolating between the received frames as in [10] or by\nrepeating the frame. If error occurs in one of the frames in the\nMDC stream (frame 4) as shown in Fig. 6, the error will\npropagate to next even frame. The MDC decoder can then\nswitch to the odd stream and display the frame at reduced\nframe rate. Alternatively, the MDC decoder can interpolate\nbetween the reduced frame rates or repeat the frame to achieve\nfull temporal resolution. The Joint Scalable Video Model\n(JSVM) software has been modified to produce the even and\nodd frame MDC scheme. The preliminary subjective result for\nerror prone is shown in Fig. 7 to simulate VCS access using\nwired Internet. 20% packet loss of Internet error pattern is\nused [11]. Interview sequence at CIF resolution and 30 fps is\ncoded using the original JSVM software (SDC) and modified\nJSVM software (MDC) to achieve the same bit rate of about\n300 kbps by varying the quantisation parameter. Table 1\nshows the quantisation parameter and the I-frame rate used to\nachieve the bit rate. In order to achieve the same bit rate as\nMDC at the same quantisation parameter, SDC used more 1-\nframes than MDC.\nTABLE I\nTERS USED FOR THE SD(\nI-frame rate\nThe 20% packet loss is only in the even stream for MDC to\nsimulate ideal MDC channel (one stream is completely lost),\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 12,2010 at 08:35:40 UTC from IEEE Xplore.  Restrictions apply. \nwhile in SDC, any frames can be subjected to the 20% packet\nloss. It is assumed that one lost corresponding of one frame\nlost. Fig. 7 shows the subjective results for frame 80 and\ncomparison between interpolate and repeat frame method of\nthe reduced frame rate. In SDC, frame copy error concealment\nis used. In the MDC simulation, if an error occurs in even\nframe, the decoder switch to odd frame and ignores the rest of\nthe even frame. It then interpolates or repeats the odd frames\nto achieve full resolution. When playing the sequence, a little\nbit of jerky motion is observed for MDC-repeat due to the\nframe repetition. It can be concluded that under ideal MDC\nchannel, MDC is very effective in combating transmission\nerrors compared to SDC.\n...........\n............\n(a) (b)\n(c)\nFig. 7. Subjective results for frame number 80 of Interview sequence, (a)\nSDC, (b) MDC-repeat, (c) MDC-interpolate when subjected to 20% packet\nloss.\nIV. CONCLUSION\nWe have introduced the virtual collaboration environment\nand the problems associated with the use of wireless access\nlinks by users participating in a virtual collaboration session.\nFor achieving the expected end to end QoS, a radio network\nresource optimisation scheme based on users' QoS and\npreferences for enhancing the quality of high priority users\nwho require to participate in a virtual collaboration session\nwas evaluated and it was shown to improve the accepted traffic\nespecially for high priority users.\nFor source channel rate optimization, a joint source-channel\nrate allocation based adaptation scheme was proposed. The\nrate allocation is based on the modelling of expected distortion\nat the video packet level. The video data can then be\nprioritised according to the relative perceived importance.\nPrioritised streams are then transmitted over the air interface\nby using multiple radio bearers with different error protection\ncapabilities.\nFor scalability issues, scalable MDC is a promising\napproach to mitigate the effect of channel errors in error prone\ntransmissions. It can provide error resilience to the base layer\nof SVC and at the same time provides scalability features. As\nfor future work, more extensive tests are needed, particularly\nfor the case if packets are lost in both of the MDC streams.\nScalable features of the scalable MDC will also be\ninvestigated. Moreover, the scalable MDC will be\nexperimented with stereoscopic video sequence for 3D virtual\ncollaboration applications.\nACKNOWLEDGEMENTS\nThe work presented was developed within VISNET II, a\nEuropean Network of Excellence (http:\/\/www.visnet-noe.org),\nfunded under the European Commission IST FP6 programme.\nAuthors would like to thank Dr Huseyin Hacihabiboglu of I-\nLab\/CCSR, University of Surrey for his review comments.\nREFERENCES\n[1] Bystrom. M., Stockhammer. T., \"Dependent source and channel rate\nallocation for video transmission, IEEE Trans. Wireless Comm., Vol.3, No.\n1, Jan.2004, pp 258-268\n[2] Cherriman. P., Kuan. E.-L., Hanzo. L., \"Burst-by-burst adaptive joint\ndetection CDMA\/H.263 based video telephony\", IEEE Trans. Circuits and\nSystemsfor Video Tech., Vol.12, No.5, May 2002, pp 342-348\n[3] Dyck. R.E.,Miller. D.J., \"Transport of wireless video using separate,\nconcatenated, and joint source-channel coding\", Proc. IEEE, Vol. 87, No. 10,\nOct. 1999, pp 1734-1750.\n[4] Gharavi, H., Alamouti, S.M., \"Video transmission for third generation\nwireless communication systems\", Journal of Research of the National\nInstitute of Standards and Technology, Vol. 106, March-April, 2001, pp 455-\n469.\n[5] Il-Min Kim; Hyung-Myung Kim; \"An optimum power management\nscheme for wireless video service in CDMA systems\", IEEE Trans. on\nWireless Comm., Vol. 2, No. 1, Jan. 2003, pp: 81 -91.\n[6] Kodikara, C., Fabri. S.N., Kondoz. A.M., \"Link adaptation for real-\ntime video communications in E-GPRS networks\", IEE Proc. Comm., Vol.\n151, No. 5, Oct. 2004, pp 438-444.\n[7] Kodikara, C., Woffall, S., Fabri, S., Kondoz, A., \"Performance\nevaluation of MPEG-4 video telephony over UMTS\", in Proceedings of\n3G2003, 25-27 June 2003, London, UK, pp. 73-77.\n[8] H. Schwarz, D. Marpe and T. Wiegand, \"Overview of the scalable\nH.264\/MPEG4-AVC extension\", in Proceedings ofInternational Conference\non Image Processing (ICIP 2006), Atlanta, GA, USA, Oct. 8-11 2006.\n[9] M. v. d. Schaar and D. S. Turaga, \"Multiple description scalable coding\nusing wavelet-based motion compensated temporal filtering\", in Proceedings\nof International Conference in Image Processing (ICIP 2003), 14-17 Sept.\n2003, pp. III-489-III-492.\n[10] J. G. Apostolopoulos, \"Error-resilient video compression via multiple\nstate streams\", in Proceedings of International Workshop on Very Low\nBitrate Video Coding, VLBV99, Kyoto, Japan, October 1999.\n[11] S. Wenger, \"Effor patterns for Internet experiments\", ITU\nTelecommunications Standardization Sector, Doc. Q15-I-16rl, Oct. 1999.\n[12] A. Capone, S. Redana, \"Call Admission Control Techniques for\nUMTS\", in Proc. ofIEEE VTC 2001 Fall, Atlantic City, NJ, Oct 2001.\n[13] Shahbaz Khan, Shoaib Khan, Sahibzada Ali Mahmud, Hamed Al-\nRaweshidy, \"Supplementary Interworking Architecture for Hybrid Data\nNetworks (UMTS-WiMAX)\", in Proc. Int. Multi-Conf. on Computing in the\nGlobal Info. Technol. (ICCGI'06), Aug. 2006, pp 57-57.\n[14] Harri Holma, Antti Toskala, WCDMA for UMTS Radio Access for\nThird Generation Mobile Communications, John Wiley & Sons Ltd., 2000.\n[15] Sund-Eun Kim, Heechang Kim, John A. Copeland, \"Dynamic Radio\nResource Allocation Considering QoS in UMTS Network\", IEEE 2002.\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 12,2010 at 08:35:40 UTC from IEEE Xplore.  Restrictions apply. \n"}
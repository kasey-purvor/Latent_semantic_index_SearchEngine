{"doi":"10.1144\/SP345.14","coreId":"52802","oai":"oai:nora.nerc.ac.uk:13849","identifiers":["oai:nora.nerc.ac.uk:13849","10.1144\/SP345.14"],"title":"Dataset acquisition to support geoscience","authors":["Giles, J.R.A.","Marsh, S.H.","Napier, B."],"enrichments":{"references":[{"id":752986,"title":"Information Liability: New Interpretations for the Electronic Age:","authors":[],"date":"1992","doi":null,"raw":null,"cites":null},{"id":752598,"title":"Product Handbook & Quick Start Guide Standard Edition 4.2, Denver","authors":[],"date":"2007","doi":null,"raw":null,"cites":null}],"documentType":{"type":1}},"contributors":["Giles, J.R.A.","Marsh, S.H.","Napier, B."],"datePublished":"2010","abstract":"Environmental scientists are both producers and consumers of data. Numerous studies have shown that significant amounts of scientists\u2019 time can be consumed in acquiring, managing and transforming data prior to their use. To facilitate the work of its scientists, the British Geological Survey (BGS) has identified a series of national datasets that are required by scientists across the organization. The BGS then seeks to acquire and manage these centrally, and to supply them to the scientists in formats that they normally use. Making these datasets readily available helps to: \\ud\n\\ud\n\u2022enhance the quality of the science;\\ud\n\\ud\n\u2022promote interdisciplinary working;\\ud\n\\ud\n\u2022reduce costs.\\ud\n\\u","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/52802.pdf","fullTextIdentifier":"http:\/\/nora.nerc.ac.uk\/13849\/1\/Dataset_Acquisition_to_Support_Geoscience_GILES_%26_MARSH%232.pdf","pdfHashValue":"ce466f2228e6905f753f67b1422a929230954412","publisher":"Geological Society of London","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:nora.nerc.ac.uk:13849<\/identifier><datestamp>\n      2012-11-22T12:19:00Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/13849\/<\/dc:relation><dc:title>\n        Dataset acquisition to support geoscience<\/dc:title><dc:creator>\n        Giles, J.R.A.<\/dc:creator><dc:creator>\n        Marsh, S.H.<\/dc:creator><dc:creator>\n        Napier, B.<\/dc:creator><dc:description>\n        Environmental scientists are both producers and consumers of data. Numerous studies have shown that significant amounts of scientists\u2019 time can be consumed in acquiring, managing and transforming data prior to their use. To facilitate the work of its scientists, the British Geological Survey (BGS) has identified a series of national datasets that are required by scientists across the organization. The BGS then seeks to acquire and manage these centrally, and to supply them to the scientists in formats that they normally use. Making these datasets readily available helps to: \\ud\n\\ud\n\u2022enhance the quality of the science;\\ud\n\\ud\n\u2022promote interdisciplinary working;\\ud\n\\ud\n\u2022reduce costs.\\ud\n\\ud\n<\/dc:description><dc:publisher>\n        Geological Society of London<\/dc:publisher><dc:contributor>\n        Giles, J.R.A.<\/dc:contributor><dc:contributor>\n        Marsh, S.H.<\/dc:contributor><dc:contributor>\n        Napier, B.<\/dc:contributor><dc:date>\n        2010<\/dc:date><dc:type>\n        Publication - Book Section<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/13849\/1\/Dataset_Acquisition_to_Support_Geoscience_GILES_%26_MARSH%232.pdf<\/dc:identifier><dc:identifier>\n         \n\n  Giles, J.R.A.; Marsh, S.H.; Napier, B..  2010  Dataset acquisition to support geoscience.    In: Giles, J.R.A.; Marsh, S.H.; Napier, B., (eds.) Elevation models for geoscience.  Geological Society of London, 135-143.  (Geological Society Special Publications, 345).      \n <\/dc:identifier><dc:relation>\n        http:\/\/sp.lyellcollection.org\/content\/345\/1<\/dc:relation><dc:relation>\n        10.1144\/SP345.14<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/nora.nerc.ac.uk\/id\/eprint\/13849\/","http:\/\/sp.lyellcollection.org\/content\/345\/1","10.1144\/SP345.14"],"year":2010,"topics":[],"subject":["Publication - Book Section","PeerReviewed"],"fullText":" 1\nDataset Acquisition to Support Geoscience \n \nJ. R. A. Giles, S. H. Marsh and B. Napier \n \nERMS ID D23155 \nERMS Title Dataset Acquisition to Support Geoscience GILES & MARSH \nERMS Version Number  8 \nLast Saved 20\/08\/2008 12:55 \nWord Count 3532 \n \nAbstract: Environmental scientists are both producers and consumers of data. Numerous studies \nhave shown that significant amounts of scientists\u2019 time can be consumed in acquiring, managing \nand transforming data prior to its use. To facilitate the work of its scientists the British Geological \nSurvey (BGS) has identified a series of national datasets that are required by scientists across the \norganisation. BGS then seeks to acquire and manage these centrally, and supply them to the \nscientists in formats that they normally use. Making these datasets readily available helps to: \n\uf0b7 Enhance the quality of the science; \n\uf0b7 Promote interdisciplinary working; and \n\uf0b7 Reduce costs. \n \nThe strategy has also enabled the development of advanced, domain-specific visualization tools, \nwhich have significantly improved the scientific output while also reducing costs. \n \nIntroduction \nA modern geological survey organisation (GSO) such as the British Geological \nSurvey (BGS),requires a wide range of digital and analogue datasets to support the \nactivities of the scientists employed to fulfil its mission. For many years GSOs \nprimarily used datasets that they had compiled internally. Typically, databases would \nbe designed in-house to meet the needs of specific geoscience communities within the \nGSO. An example of this is provided by geochemists, who analyse stream sediments \nfor a specified suite of chemical elements and visualise the data spatially to \nunderstand the distribution of those elements (Johnson et al. 2005). In addition to in-\nhouse datasets the legislation in some countries provided GSOs with ready access to \nspecified datasets produced by industry. For example, - Geoscience Australia \n(www.ga.gov.au) houses one of the worlds largest collection of petroleum data in its \nPetroleum Data Repository. This is accessible internally within the GSO and much of \nthe dataset is \u201cOpen file\u201d and available on the Internet through The Petroleum \nInformation Management System (www.ga.gov.au\/oracle\/npd\/). \n \nDuring the past decade a range of public and private sector organisations has been \ncreating national digital datasets to meet the needs of a variety of customers. Some of \nthese datasets have direct relevance to geoscience and can be readily integrated with \nthe in-house digital datasets that GSOs typically maintain. For example \nINTERMAP\u2122 Technologies (www.intermap.com) have created a range of regional \nand national datasets using airborne Interferometric Synthetic Aperture Radar \n(IFSAR). Under the brand name NEXTMap\u00ae Intermap has produced digital surface \nmodels and digital terrain models for Britain, large parts of Europe and several states \nin the USA. \n \n 2\nThe process that the BGS undertook to identify and acquire specific digital datasets to \nsupport the work of its geoscientists is described below. \nDatasets \nIn 1999 the BGS-geoIDS (BGS Geoscience Integrated Database System) and the \nSIGMA (System for Integrated Geological Mapping) projects within the BGS \nestablished a team to identify the national third-party digital spatial datasets that the \nBGS was likely to need during the next decade. The team was also tasked to identifier \npotential suppliers and put in place activities to acquire the datasets under appropriate \nterms and conditions. The team identified the following digital datasets: \n \n\uf0a7 Elevation \no Terrain and Elevation Models \no Topographical Survey Elevation \n\uf0a7 Imagery \no Aerial images \no Satellite images \n\uf0a7 Topography \no Modern topography \no Historical topography of various ages \n \nElevation \nElevation data are a fundamental tool in any geologist\u2019s toolkit; all the more so in \nGreat Britain where there is little exposure of the underlying rock over large parts of \nthe country. Commonly, the geologist must infer what lies at depth from the surface \nexpression of the lithology and structure through their effects upon the topography. In \nthe field, BGS geologists have done this for many years by employing a technique \nknown as feature mapping. This consists of careful surveying of subtle breaks of \nslope, which can then be related to particular lithologies under the superficial cover. A \nclassic example comes from the Chalk of Southern England (Fig X), where up to 12 \ndistinct units can now be recognised by the effects that they have on the surface \ntopography. Discontinuities in these surface features can commonly be related to \nfaulting and other expressions of the underlying geological structure. These features \nare characterised by changes in elevation that can be seen in digital elevation data just \nas they can in the field. The data may be generated by digitising contours acquired \nduring topographic survey; from aerial photography, either as a photogrammetric \nsource for these contours or via the photogrammetric generation of a digital elevation \nmodel; or from direct measurement techniques, such as spaceborne, airborne or \nterrestrial radar or lidar sensors. Table X details the various elevation data used in \nthe UK by the BGS over the past decade. \n \nDepending on the technique used and the desired application, such data may represent \nthe bare earth (a digital terrain model) or include the elevation of surface features such \nas vegetation (a digital elevation model or digital surface model). Geologists usually \nprefer to analyse the former, although the latter might give a more realistic \nvisualisation of landscape when used in combination with aerial photography. \n \n 3\nGeologists increasingly use elevation data, how ever it has been acquired, to help \nthem accelerate feature mapping. This has several advantages. It can be done at the \ndesktop and then checked in the field. The data are GIS-ready and their interpretation \ncan be carried out within the standard GIS and digital mapping packages. The sun \nangle and topographic exaggeration can be adjusted to emphasise subtle features. In \nfact, several other advanced image analysis techniques have been developed that can \nat least partially automate the process of interpretation (Fig X). Elevation data are \nalso used as the base on which other datasets, such as aerial photography, are \nvisualised in their landscape context as part of the digital mapping process. BGS has \npurchased national coverage of the NEXTMap\u00ae dataset from Intermap as a BGS \nBaseline Dataset. \nTerrain and Elevation Models \nGeologists are most often interested in terrain, or bare earth, models, because these \nallow them to analyse the shape of the Earth\u2019s surface rather than those things \ngrowing or built upon it. A component of the NEXTMap\u00ae Britain dataset includes a \nbare earth model, but this has been generated from the original elevation model that \nwas measured during the survey. This process involves editing the elevation data to \nremove features such as trees and buildings. Doing this for the entire country requires \nautomation and this is a considerable technical challenge. Consequently, the resulting \nbare earth model contains residual artefacts related to the features removed. Figure \nX shows a comparison between the terrain and elevation models to illustrate this. \nSmall forest stands can confuse subsequent analysis techniques such as slope angle, \ngiving apparent steep slopes at their margins. Such errors propagate through into \nderived products such as landslide hazard maps, giving erroneously high hazard \nvalues around forests. The BGS has attempted further editing of the NEXTMap\u00ae \nBritain dataset, using satellite imagery and photography to map the spatial distribution \nof vegetation on a national scale and highlight potential problem areas for further \nediting. This artefact editing problem also affects elevation data extracted from \nsatellite radar interferometry, which works on a similar basis to that from an aircraft, \nand stereo aerial photography and satellite imagery like stereo ASTER, SPOT or \nICONOS data. \n \nThere are two other ways to tackle the problem. The first is to use nationally available \ncontour data. National Mapping Agencies commonly use digital photogrammetry to \ngenerate contours from stereo aerial photography, as part of their topographic \nsurveying process. This involves the creation of a stereo model that contains an \nelevation model from the photography, from which contours can be digitised by a \nskilled analyst, who can place the cursor onto the ground even amongst tree stands. \nUnfortunately, it has been common practice not to extract and store the elevation \nmodel once the contours have been generated, otherwise this would be a valuable \nsource of national elevation data. Instead, the contours can be used to work back to \nthe elevation model by gridding and interpolation. As the contour data have already \nbeen generated in a way that avoids the recording of unwanted surface features, such \ndatasets circumvent the artefact problem efficiently. However, such models tend to \nlack topographic detail due to the degree of interpolation employed, especially in \nrelatively flat ground, where contours can be both poorly constrained and sparse. \n \n 4\nThe second approach is to use a data acquisition technique that measures the ground \nsurface directly, penetrating the tree canopy. Airborne lidar data have been used \neffectively for this purpose, even in rainforest areas. The laser in the aircraft is pulsed, \nso that every point on the ground has multiple measurements, at least some of which \npenetrate through the canopy and reflect off the land surface. Using such data, it is \npossible to extract the bare earth model from the last return, the structure of the tree \ncanopy from the intermediate returns and the top of canopy elevation model from the \nfirst return within the same dataset. Lidar data are also high resolution in x, y and z, \ncommonly in the range of centimetres rather than metres, and they make a highly \nsuitable dataset for geological terrain analysis. Their only drawback is that they are \nnot yet available on a national basis; as ad-hoc acquisition continues, the coverage in \nthe UK is increasing, to the point where national coverage has become possible to \ncontemplate. Initiatives to pursue this are under discussions and it is likely to occur in \nthe near future. \nImagery  \nAerial photography has long been used by geologists to visualise the landscape in \nthree dimensions, both in the laboratory using stereoscopes and in the field using field \npocket stereoscopesortable stereo glasses. Before the advent of elevation data, this \nwas the main way in which the topography was visualised so that feature mapping \ncould be undertaken. In addition, imagery gives useful clues about lithology and soil \ntype through the colour and texture that could be seen and associated with particular \nrock types. The patterns made by streams also vary depending upon the lithology and \nthese patterns, together with textures, provide clues about jointing and fracturing. \nMajor topographic lineaments that persist over kilometres are commonly associated \nwith significant faulting or other geological structures. \n \nThe advances in computer processing power and storage in recent years have \nrevolutionised the use of such data in geological mapping, and digital imagery is now \na key dataset in the digital mapping workflow. The change started with the advent of \nsatellite imagery in the 1970s and Landsat has become an important reconnaissance \ntool for geologists, which still has its place today, particularly in poorly mapped, well-\nexposed terrain (Fig X). But in the UK it was the widespread availability of digital \nstereo aerial photography that began to see imagery take its place in the digital \nworkflow. The geological survey has invested in national coverage from UK \nPerspectives and Getmapping, including monoscopic orthophotography for draping \non elevation data and full stereo photography for more advanced analysis. This aerial \nphotography underpins many mapping projects. Geologists interpret the landscape \nbefore going in the field and use the field time for checking and to investigate \nchallenging or interesting areas. This generates both an economic and scientific return \non the investment in the data. The national Landsat and aerial photography coverage \nform two further BGS Baseline Datasets. \nTopography \nTopography is the essential spatial back drop to GSOs outputs. Geological maps are \nultimately of little use unless they relate to an underpinning topography. It is also \nimportant in data acquisition as individual observations are referenced by the spatial \nframework provided by topographic mapping. The relationship between geological \nmapping and the topographic survey is so fundamental that the founder of the \n 5\nGeological Survey in Great Britain, Sir Henry De la Beche, was originally funded in \n1832 by the Board of the Ordnance \u201cto cover the cost of geologically colouring the \ntopographical maps of the Trigonometrical Survey\u201d. \nModern Topography \nIn Great Britain (GB) the principal supplier of modern topographic mapping is the \nOrdnance Survey (OS). The OS produces a wide range of mapping outputs at a range \nof scales down to 1:1250. The most important scales for most BGS geological \nmapping are 1:50 000 and 1:10 000. These scales are readily available in raster \nformat, which is ideal for back drops and locating observations using global \npositioning systems. The MasterMap product provides mapping at scales to 1:1250. It \nis used occasionally for specific tasks but the cost of national coverage prevents its \nroutine use by the BGS. \nHistorical Topographical Mapping \nIn Great Britain the Ordnance Survey was founded in 1747 and it has been publishing \nmaps since that date. By the 1840s systematic surveying had commenced at 1:10560-\nscale for Great Britain. Many areas have been resurveyed repeatedly, producing a \nseries of editions showing the changing landscape. This serial snapshot of the \nlandscape of Great Britain provides valuable information to geoscientists. Information \nabout the location of mine entrances, quarries and other excavations can be derived \nfrom historical topographical mapping. They also provide valuable information about \nanthropogenic landscaping. For example, consider a late 19th century mine that \nproduced a waste heap that was subsequently modified after closure of the mine, with \nassociated tree planting to stabilise the slopes. Planners of subsequent developments \nneed to be aware that the visible wooded hill is in fact composed of mine waste, with \npotential slope stability issues and the possibility that it contains toxic minerals or \nhigh-acidity materials and drainage. \nManagement and Delivery of Datasets \nOnce the datasets have been acquired they need to be managed rigorously within a \ncontrolled environment. The principal issues are: \n\uf0b7 Licensing and intellectual property rights \n\uf0b7 Long-term storage and digital preservation; \n\uf0b7 Datasets limitations; and \n\uf0b7 Communication. \n \nLicensing and Intellectual Property Rights  \nAcquired datasets commonly come with complex licensing agreements. It is essential \nthat the terms and conditions of licences are understood and communicated to data \nusers in a way that they can understand. Internal monitoring systems are required to \nensure that research outputs, derived datasets and information products do not infringe \nthird-party intellectual property rights. In the most difficult cases licensing \nagreements for a given product vary over time as the policies of the supplier change. \nThis means that a dataset used in the creation of a specific research output might no \nlonger be available for its continued use and exploitation, so the research output must \nbe withdrawn from use. BGS has found it simplest to attempt to acquire in-perpetuity \n 6\nlicences for a given dataset in exchange for a one-off payment. This simplifies licence \nmanagement and means that research outputs are more long-lived and robust. \n \nLong-term Storage and Digital Preservation \nNational digital datasets can be large, comprising multi-terabytes of data. When such \ndata are being acquired it is essential that the related storage issues are considered \nduring the acquisition process. Does the organisation have the storage and compute \npower to manipulate the datasets? Digital data formats change over relatively short \ntimescales. Plans need to be in place to ensure that the dataset continues to be \navailable, even if the original delivery format becomes obsolete. This is not simply a \nprocess of progressively migrating datasets to the current appropriate file format. The \norganisation must have a clear understanding of any information losses that might \ntake place during progressive file format changes. \n \nDataset Limitations \nNo dataset is perfect. Each has its own limitations. Nevertheless, the temptation is to \nassume that digital datasets are perfect. Tarter (1992) has noted that \u201c\u2026(the) myth of \nmachine infallibility seems to create a demand for higher standards of quality for \nmachine readable data than for traditionally distributed information.\u201d Similarly Peritz \n(1986) has suggested that \u201c\u2026the presumption of trustworthiness (of digital data) \nsimply carries too much weight...\u201d The reality is that data are not perfect, and dataset \nlimitations need to be understood and documented. The aim of the documentation is \nto ensure that a potential user can assess whether a given dataset is fit for its intended \npurpose. For example, there is a predisposition to assume that digital raster images of \nhistorical Ordnance Survey 1:10,560 topographical maps have a similar accuracy to \ntheir modern 1:10,000 counterparts. However, there are considerable differences: \n1) The original 1:10,560 maps were paper prints and they are up to 150 years old. \nUnless stored in a perfect records management environment for their entire \nlife, such paper maps can become distorted to varying degrees over time. The \nmaps might therefore be spatially inaccurate before scanning. \n2) Different generations of maps will have been surveyed using different \nmethods and\/or instruments. The same geographical object will not necessarily \nbe in the same spatial location on subsequent editions. \n3) The Ordnance Survey 1:10,560 maps are maps, not plans. They include \ncartographic generalisations that affect the spatial representation and location \nof geographical objects. \n4) Geographical objects change over 100 years. Buildings are extended or \ndemolished and rebuilt, changing their footprint in the process. Bridges and \nroads may be widened. \nThe cumulative result is that, potentially, a location determined from an historical \nmap might be tens of metres from its correct location. \n \nOther dataset limitations arise from the nature of the instrument collecting the data \nand the platform upon which the instrument was mounted. Where the platform is an \naircraft and the instrument is IFSAR, a number of \u2018IFSAR Artefacts\u2019 may be \nidentified in the final dataset. Several known artefacts can persist despite processing \nof the data during and after acquisition. One type of artefact is \u2018Motion Ripples\u2019, \nwhich are caused by atmospheric turbulence preventing the aircraft from maintaining \n 7\nlevel flight during data acquisition. They appear as height ripples in the elevation data \nand as dark bands in the imagery at rightangles to the direction of the aircraft\u2019s flight \npath. Most motion ripples are eliminated by processing, but some might persist into \nthe final dataset (Intermap Technologies 2007). The other issues primarily relate to \nthe recorded height coming from the top of the tree canopy and from buildings in \nbuilt-up areas; research is underway to improve the removal of such artefacts. \nCommunication \nThe principal way to communicate information about a dataset is through its \nassociated metadata. A rich, well maintained metadata entry can enhance user-\nunderstanding of the dataset. It is the dataset custodian\u2019s responsibility to develop and \nmaintain metadata to meet the needs of users seeking to re-use and re-purpose the \ndata. The profile and significance of metadata have risen in many countries in recent \nyears following the introduction of new laws, including data protection and freedom \nof information legislation. Within the European Union (EU), directives have been \nissued relating to the use of public sector information and a common spatial \ninfrastructure. These are being transposed into national laws by EU member states. \nAll this legislation requires or implies that accurate, well maintained metadata are in \nplace. \nThe Sum is Greater than the Parts \nOne of the underlying motivations for the selection of the BGS national baseline \ndatasets was the synergy between them. Elevation data can be analysed in their own \nright, but come to life when they are used as the backdrop for aerial imagery. Such \nimagery provides a unique view of the Earth\u2019s surface from above, but is far easier to \ninterpret when draped over an elevation dataset to create a virtual, immersive \nenvironment than it is when using traditional stereo analysis techniques. This synergy \nextends the utility of the data from the specialist analyst to geologists (and indeed \nother scientists, professionals and the public) in general. Other datasets can be \nvisualised far more clearly when viewed in their landscape context within this virtual \nenvironment.  \n \nAnother synergy between elevation data and imagery or other raster datasets involves \nthe generation of synthetic stereo from ortho-corrected mono imagery. This approach \nallows other digital geoscience datasets, such as the BGS national digital geology and \ngeochemical or geophysical datasets, to be viewed in stereo. Viewing geological map \ndata in a new perspective against the actual 3D model highlights any inconsistencies \nwithin the conceptual 3D model that underlay the original mapping, and allows for \nrapid correction or the targeting of field surveys to update maps in problem areas. \n \nElevation data have many applications in their own right, but really come into play as \nan underpinning dataset supporting the processing, display, interrogation and analysis \nof other geoscience data.  This can include: their use to orthorectify other remotely \nsensed imagery; as a base on which to display 2D geological maps in 2.5 or 3D; or \nmore complex algorithms within a model or GIS that take elevation, or a derivative \nlike slope, as one input.  The integration of elevation data into other geoscience \nworkflows delivers substantial synergy.  Satellite imagery can be placed in their real-\nworld position and features extracted that can go straight into a GIS.  Geological lines \ndrawn in a pre-digital era can be seen in 3D and obvious errors corrected, releasing \n 8\nthe potential of older datasets.  Complex problems that may require a wide range of \ninput parameters often have elevation, or a derivative, as a common thread.  The latter \npoint was illustrated during the first half of this decade when, one after the other, a \nseries of Integrated Global Observing Strategies identified improved global DEMs as \na high priority.  They covered not only the geosciences (Marsh (ed), 2004) but also \ncoastal observations, the water cycle, land observations and the cryosphere.  Elevation \ndata are one dataset that can pay dividends right across the environmental sciences. \nApplications \n \nThe applications of elevation data to the geosciences are many and varied.  In the \nfoundations of our science, the basic geological mapping requires the topography to \nbe mapped first, because the geology exerts control on the overlying landscape and an \nunderstanding of the latter helps reveal the former.  In countries like the UK, large \nareas must be mapped without seeing a single exposure and the established technique, \nfeature mapping, is essentially a detailed topographic analysis.  Digital topographic \ndata have transformed this process in the past decade, allowing much of the critical \ninformation to be captured in the office.  Fieldwork then focuses on the challenges \nand areas of particular geological interest. This has allowed BGS to re-engineer its \nmapping process into a fully integrated, digital workflow, with consequent efficiency \ngains, standardisation of approach and related cost savings. Beyond this, elevation \ndata have application in many other geoscience disciplines, at the least as a backdrop \nfor other data.  An important application area is geohazards, where slope and aspect \nare one of the key controls on ground instability.  In pollution studies, the source-\npathway \u2013 receptor model relies on topography to help determine the pathway and \nlikely area for receptors.  Applications exist in mineral, especially aggregate, \nresources and groundwater management.  In fact, it is hard to think of a geoscience \ndiscipline where these data do not apply. \n \nCase Study \u2013 Virtual Field Reconnaissance using GeoVisionary  \n \nBGS geoscientists have routinely used digital elevation models as part of their work \nfor many years, but accessing and visualising the data was often time-consuming and \nrestricted by technology limitations to either small areas or low-resolution \nrepresentations.  In order to make full use of BGS's new high-resolution baseline \ndatasets (principally NextMap Britain 5m DTM and DSM from Intermap \nTechnologies, and aerial photography from UKP\/Getmapping) a project was started in \nlate 2006 - Virtual Field Reconnaissance \u2013 that aimed to create an environment in \nwhich to visualise and interact with all of these data.  The project built on BGS links \nwith Virtalis Ltd., a British-based virtual reality company that had previously been \ncommissioned to install an immersive 3-Dimensional Visualisation Facility at two \nBGS sites and produce custom geological visualisation software. \n \nThe result of this collaboration is GeoVisionary, a software system that has built-in \nseamless, streaming of multi-resolution levels of data, merging data such as existing \ndigital geological maps, aerial photography, satellite imagery, field-slips, historical \ntopographic maps, and subsurface 3D models, cross-sections and boreholes. The \nsystem allows teams of geologists to undertake a virtual survey of an area in the office \n 9\nbefore commencing fieldwork, building an understanding of the terrain, which leads \nto a better interpretation of the geological structure. This initial assessment allows \nsurveyors to effectively target fieldwork in areas where surveying is most required. \nOn completion of fieldwork, surveyors can check their individual field interpretations \ntogether in the virtual landscape. This team approach allows colleagues to work \ntogether on both pre- and post-fieldwork studies, better enabling communication, so \nincreasing operational efficiency and enhancing scientific understanding. Whilst a \nvariety of data can be visualised in the system, the elevation data are fundamental to \nits successful operation; they provide geoscience information in their own right but \nare also the backcloth against which other data are displayed. They also provide the \ntop surface from which the subsurface models are generated and hung. \nConclusions  \nThe increasing variety and improved availability of national digital datasets are \nhelping to provide exciting new tools for geoscientists. These data products, used in \ncombination with innovative software, provide new ways for geoscientists to perceive \nand interpret the landscape. Elevation data in particular are central to this because \nthey can both be interpreted as a geoscience dataset in their own right and used to \nboth process and visualise other datasets to best advantage. \n \nBenefits from these datasets and systems include integrated digital workflows and \nshared 3D models of the surface and subsurface geology, This has led to efficiency \ngains and cost savings in mapping programmes, whilst at the same time improving \nteamwork and standardising approaches to mapping. However, for the potential \nscientific benefits of this technological development to be achieved, a range of non-\nscientific issues must be addressed. These include: \n\uf0b7 Licensing and Intellectual Property Rights management; \n\uf0b7 Management of the digital datasets; \n\uf0b7 Digital preservation of the dataset; \n\uf0b7 Understanding the limitations of the dataset; \n\uf0b7 Communication of the above to geoscientists. \n \nIt is incumbent upon GSOs to make sure that they create and maintain efficient and \nwell-supported information management systems to deal with these issues. \n \nReferences \nIntermap Technologies 2007. Product Handbook & Quick Start Guide Standard \nEdition 4.2,  Denver USA \n \nJohnson, C. C; Breward, N; Ander, E. L. Ault, L. 2005. GBASE : baseline \ngeochemical mapping of Great Britain and Northern Ireland : In: Geochemistry: \nexploration, environment, analysis Vol. 5 pt\/no 4 p. 347-357 \n \nPeritz, R., 1986, Computer Data and Reliability: North west University Law Review, \nv 80, p. 960. \n \nTarter, B., 1992, Information Liability: New Interpretations for the Electronic Age: \nComputer\/Law Journal, v. XI, p. 484. \n"}
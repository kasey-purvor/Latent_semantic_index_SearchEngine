{"doi":"10.1109\/EFTA.2007.4416933","coreId":"65085","oai":"oai:cadair.aber.ac.uk:2160\/385","identifiers":["oai:cadair.aber.ac.uk:2160\/385","10.1109\/EFTA.2007.4416933"],"title":"Accurate Range Image Registration: Eliminating or Modelling Outliers","authors":["Li, Longzhuang","Liu, Honghai","Wei, Baogang","Liu, Yonghuai"],"enrichments":{"references":[{"id":43352384,"title":"3D shape matching using collinearity constraint.","authors":[],"date":"2004","doi":"10.1109\/robot.2004.1307402","raw":"Y. Liu, L. Li, B. Wei. 3D shape matching using collinearity constraint. Proc. ICRA, 2004, pp. 2285-2290.","cites":null},{"id":43352374,"title":"A method for registration of 3D shapes.","authors":[],"date":null,"doi":"10.1117\/12.57955","raw":"P. J. Besl, N. D. McKay. A method for registration of 3D shapes. IEEE Trans. PAMI, 14(1992) 239-256.","cites":null},{"id":43352383,"title":"Automatic 3d free form shape matching using the graduated assignment algorithm.","authors":[],"date":null,"doi":"10.1016\/j.patcog.2005.01.008","raw":"Y. Liu. Automatic 3d free form shape matching using the graduated assignment algorithm. Pattern Recognition, 38(2005) 1615-1631.","cites":null},{"id":43352382,"title":"Automatic registration of overlapping 3D point clouds using closest points.","authors":[],"date":null,"doi":"10.1016\/j.imavis.2006.01.009","raw":"Y. Liu. Automatic registration of overlapping 3D point clouds using closest points. Image and Vision Computing, 24(2006) 762-781.","cites":null},{"id":43352381,"title":"Developing rigid motion constraints for the registration of free-form shapes.","authors":[],"date":"2000","doi":"10.1109\/iros.2000.895308","raw":"Y. Liu, M.A. Rodrigues, and Y. Wang. Developing rigid motion constraints for the registration of free-form shapes. Proc. IEEE\/RSJ IROS, 2000, pp. 2280-2285.","cites":null},{"id":43352376,"title":"Hand motion from 3D point trajectories and a smooth surface model.","authors":[],"date":"2004","doi":"10.1007\/978-3-540-24670-1_38","raw":"G. Dewaele, F. Devernay, and H. Horaud. Hand motion from 3D point trajectories and a smooth surface model. Proc. ECCV, 2004, pp. 495-507.","cites":null},{"id":43352377,"title":"Multi-resolution spin images.","authors":[],"date":"2006","doi":"10.1109\/cvpr.2006.197","raw":"H.Q. Dinh, S. Kropac. Multi-resolution spin images. Proc. CVPR, 2006, pp. 863-870.","cites":null},{"id":43352380,"title":"Multi-scale EMICP: a fact and robust approach for surface registration,","authors":[],"date":null,"doi":"10.1007\/3-540-47979-1_28","raw":"S. Granger and Xavier Pennec, Multi-scale EMICP: a fact and robust approach for surface registration, Proc. ECCV, 2002, LNCS, pp. 418-432.","cites":null},{"id":43352385,"title":"Multiview registration for large data sets.","authors":[],"date":"1999","doi":"10.1109\/im.1999.805346","raw":"K. Pulli. Multiview registration for large data sets. Proc. 3DIM, 1999, pp. 160-168.","cites":null},{"id":43352379,"title":"New algorithms for 2-D and 3-D point matching: pose estimation and correspondence.","authors":[],"date":null,"doi":null,"raw":"S. Gold, A. Rangarajan, et al. New algorithms for 2-D and 3-D point matching: pose estimation and correspondence. Pattern Recognition 31(1998) 1019-1031.","cites":null},{"id":43352386,"title":"Precision range image registration using a robust surface interpenetration measure and enhanced genetic algorithms.","authors":[],"date":null,"doi":"10.1109\/tpami.2005.108","raw":"L. Silva, Olga R.P. Bellon, and K.L. Boyer. Precision range image registration using a robust surface interpenetration measure and enhanced genetic algorithms. IEEE Trans. PAMI, 27(2005) 762-776.","cites":null},{"id":43352375,"title":"Using laser range data for 3D SLAM in outdoor environments.","authors":[],"date":"2006","doi":"10.1109\/robot.2006.1641929","raw":"D.M. Cole and P.M. Newman. Using laser range data for 3D SLAM in outdoor environments. Proc. ICRA, 2006, pp. 188-193.","cites":null},{"id":43352387,"title":"Zippered polygon meshes from range images.","authors":[],"date":"1994","doi":"10.1145\/192161.192241","raw":"G. Turk and M. Levoy. Zippered polygon meshes from range images. Proc. SIGGRAPH, pp. 311-318, 1994.","cites":null}],"documentType":{"type":1}},"contributors":["Department of Computer Science","Vision, Graphics and Visualisation Group"],"datePublished":"2007-09","abstract":"Liu, Yonghuai, Liu, Honghai, Li, Longzhuang, Wei, Baogang. Accurate Range Image Registration: Eliminating or Modelling Outliers. Proceedings of 12th IEEE Conference on Emerging Technologies and Factory Automation, 2007, pp. 1316-1323. Sponsorship: IEEEAutomatic and accurate range image registration is often a prerequisite step for range image analysis and interpretation. Due to occlusion, appearance and disappearance of points in different images, outliers inevitably occur. In this case, various techniques to eliminate and model outliers have been proposed for accurate range image registration. The objective of this paper is to experimentally investigate which of the outlier elimination and modelling is more effective for the evaluation of possible correspondences established, so that a deep insight into how advanced range image registration algorithms will be developed can be obtained. The experimental results based on both synthetic data and real images show that the outlier modelling often outperforms the outlier elimination in the sense of producing more accurate and robust range image registration results.preprintpreprin","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65085.pdf","fullTextIdentifier":"http:\/\/cadair.aber.ac.uk\/dspace\/bitstream\/handle\/2160\/385\/3506.pdf?sequence=3&isAllowed=y","pdfHashValue":"f0e6dad408ecdaa520caf27434bb859afb454e5e","publisher":null,"rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:cadair.aber.ac.uk:2160\/385<\/identifier><datestamp>\n                2018-01-08T20:23:16Z<\/datestamp><setSpec>\n                com_2160_5<\/setSpec><setSpec>\n                com_2160_7908<\/setSpec><setSpec>\n                col_2160_23<\/setSpec><setSpec>\n                col_2160_7909<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nAccurate Range Image Registration: Eliminating or Modelling Outliers<\/dc:title><dc:creator>\nLi, Longzhuang<\/dc:creator><dc:creator>\nLiu, Honghai<\/dc:creator><dc:creator>\nWei, Baogang<\/dc:creator><dc:creator>\nLiu, Yonghuai<\/dc:creator><dc:contributor>\nDepartment of Computer Science<\/dc:contributor><dc:contributor>\nVision, Graphics and Visualisation Group<\/dc:contributor><dc:description>\nLiu, Yonghuai, Liu, Honghai, Li, Longzhuang, Wei, Baogang. Accurate Range Image Registration: Eliminating or Modelling Outliers. Proceedings of 12th IEEE Conference on Emerging Technologies and Factory Automation, 2007, pp. 1316-1323. Sponsorship: IEEE<\/dc:description><dc:description>\nAutomatic and accurate range image registration is often a prerequisite step for range image analysis and interpretation. Due to occlusion, appearance and disappearance of points in different images, outliers inevitably occur. In this case, various techniques to eliminate and model outliers have been proposed for accurate range image registration. The objective of this paper is to experimentally investigate which of the outlier elimination and modelling is more effective for the evaluation of possible correspondences established, so that a deep insight into how advanced range image registration algorithms will be developed can be obtained. The experimental results based on both synthetic data and real images show that the outlier modelling often outperforms the outlier elimination in the sense of producing more accurate and robust range image registration results.<\/dc:description><dc:description>\npreprint<\/dc:description><dc:description>\npreprint<\/dc:description><dc:date>\n2007-12-05T12:31:05Z<\/dc:date><dc:date>\n2007-12-05T12:31:05Z<\/dc:date><dc:date>\n2007-09<\/dc:date><dc:type>\n\/dk\/atira\/pure\/researchoutput\/researchoutputtypes\/contributiontobookanthology\/conference<\/dc:type><dc:identifier>\nLi , L , Liu , H , Wei , B & Liu , Y 2007 , Accurate Range Image Registration: Eliminating or Modelling Outliers . in IEEE Conference on Emerging Technologies and Factory Automation . pp. 1316-1323 , 12th IEEE Conference on Emerging Technologies and Factory Automation , Patras , Greece , 25\/09\/2007 . DOI: 10.1109\/EFTA.2007.4416933<\/dc:identifier><dc:identifier>\nconference<\/dc:identifier><dc:identifier>\n978-1-4244-0825-2<\/dc:identifier><dc:identifier>\n978-1-4244-0826-9<\/dc:identifier><dc:identifier>\nPURE: 575575<\/dc:identifier><dc:identifier>\nPURE UUID: bc47d6ca-51a7-4434-8594-f4fa39ce741a<\/dc:identifier><dc:identifier>\ndspace: 2160\/385<\/dc:identifier><dc:identifier>\nDSpace_20121128.csv: row: 286<\/dc:identifier><dc:identifier>\nScopus: 47849126236<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2160\/385<\/dc:identifier><dc:identifier>\nhttp:\/\/ieeexplore.ieee.org\/iel5\/4296570\/4296571\/04296670.pdf<\/dc:identifier><dc:identifier>\nhttp:\/\/dx.doi.org\/10.1109\/EFTA.2007.4416933<\/dc:identifier><dc:language>\neng<\/dc:language><dc:relation>\nIEEE Conference on Emerging Technologies and Factory Automation<\/dc:relation><dc:rights>\n<\/dc:rights><dc:format>\n8<\/dc:format>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["IEEE Conference on Emerging Technologies and Factory Automation"],"year":2007,"topics":[],"subject":["\/dk\/atira\/pure\/researchoutput\/researchoutputtypes\/contributiontobookanthology\/conference"],"fullText":"Accurate Range Image Registration: Eliminating or Modelling Outliers\nYonghuai Liu\nDepartment of Computer Science\nUniversity of Wales, Aberystwyth, UK\nEmail: yyl@aber.ac.uk\nHonghai Liu\nInstitute of Industrial Research\nUniversity of Portsmouth, UK\nEmail: Honghai.Liu@port.ac.uk\nLongzhuang Li\nDepartment of Computing Sciences\nTexas A and M University, Corpus Christi, USA\nEmail: lli@sci.tamucc.edu\nBaogang Wei\nCollege of Computer Science\nZhejiang University, P.R. China\nEmail: wbg@zju.edu.cn\nAbstract\nAutomatic and accurate range image registration is often a\nprerequisite step for range image analysis and interpreta-\ntion. Due to occlusion, appearance and disappearance of\npoints in different images, outliers inevitably occur. In this\ncase, various techniques to eliminate and model outliers\nhave been proposed for accurate range image registration.\nThe objective of this paper is to experimentally investigate\nwhich of the outlier elimination and modelling is more ef-\nfective for the evaluation of possible correspondences es-\ntablished, so that a deep insight into how advanced range\nimage registration algorithms will be developed can be ob-\ntained. The experimental results based on both synthetic\ndata and real images show that the outlier modelling often\noutperforms the outlier elimination in the sense of produc-\ning more accurate and robust range image registration re-\nsults.\n1 Introduction\nThe 3D imaging geometry of laser scanning systems (range\ncameras) creates in essence a stereo vision and\/or performs\nsome function of human brains that post-process some mea-\nsures of interest and then output range images (Figure 1),\ndepicting 3D information of the objects and environment of\ninterest. It is likely in the future that laser scanning sys-\ntems become essential components of intelligent systems\ndue simply to the fact that the laser scanning systems di-\nrectly capture depth information of the objects and environ-\nment of interest and the recovery of depth information from\nprojective images is often sensitive to noise. The captured\ndata are usually described in local camera centred coordi-\nnate frames. Since the laser scanning systems have limited\nfield of view, a number of images have to be captured from\ndifferent viewpoints so that a full coverage of the object\nsurface and the environment can be obtained. To fuse the\ngeometric and optical information in these images, they of-\nten have to be aligned into a single global coordinate frame.\nThis process is called registration. Range image registration\nhas two goals: one is to establish correspondences between\noverlapping range images, the other is to estimate the cam-\nera motion parameters that bring one range image into best\npossible alignment with the other. Fixing either of these two\ngoals renders the other easier. However, they are in practice\ninterwoven, complicating the range image registration pro-\ncess.\n1.1 Previous work\nRange image registration finds numerous applications for\nintelligent robots and systems such as simultaneous local-\nization and map building (SLAM) [2]. As a result, a large\nnumber of algorithms have been developed such as tech-\nniques based on iterative closest point (ICP) [1], improved\nICP algorithms [11, 13, 2], feature extraction and matching\n[4], genetic algorithm [12], graduated assignment algorithm\n[5, 9], EM-ICP [3, 6, 8], and many others.\nThese algorithms can be classified into three main cat-\negories with regard to automatically establishing possi-\nble correspondences: (1) feature extraction and matching\n(FEM) [4]; (2) closest point criterion (CPC) [1, 11, 13]; and\n(3) an optimal combination of points (OCP) [5, 9, 3]. What-\never method is used to establish possible correspondences\nbetween two overlapping range images, it is vital to eval-\nuate these correspondences, since it cannot guarantee that\nany of these correspondences is real. Accurate evaluation of\nthese correspondences will lead to an accurate camera mo-\ntion estimation and thus range image registration. The ex-\nisting methods for possible correspondence evaluation can\nbe classified into the following four main categories or a\ncombination of them:\n1-4244-0826-1\/07\/$20.00 \u00a9 2007 IEEE 1316\n \nFigure 1: Real range images used. Top row: view1; Sec-\nond row: view2; Bottom row: view3. From left column\nto right column: tubby, lobster, frog, and duck.\n\u2022 Algorithms based on the information of the CPC [10].\nThis class of algorithms makes full use of the imaging\ngeometry that the scanning errors occur mainly along\nthe ray shooting from the range camera. This geome-\ntry implies that the possible correspondences must be\ncollinear. Otherwise, it is impossible for them to rep-\nresent real ones;\n\u2022 Algorithms based on the information estimated from\npossible correspondences [7]. This class of algorithms\nassumes that the possible correspondences must satisfy\nthe rigid motion constraints they were subject to. Oth-\nerwise, they cannot represent real ones. To eliminate\nfalse correspondences, the algorithms have to estimate\nsome motion parameters of interest from the possible\ncorrespondences using the rigid motion constraints and\nthe Monte Carlo resampling scheme;\n\u2022 Algorithms based on structural constraints [13, 11].\nThis class of algorithms assumes that the possible cor-\nrespondences must possess the same structural and op-\ntical properties. Otherwise, they cannot represent real\nones. To eliminate false correspondences, the algo-\nrithms have to extract the structural constraint on, for\nexample, the orientation of points or optical features\nabout, for example, laser reflectance strength value of\nthe object surface; and finally\n\u2022 Algorithms based on explicit outlier modelling [5, 9, 3,\n8]. This class of algorithms explicitly models outliers\nand thus equally treats all possible correspondences\nestablished in the sense of estimating their probabili-\nties of being real, resulting in the camera motion pa-\nrameters being estimated in the weighted least squares\nsense.\nWhile the former three classes of algorithms eliminate false\ncorrespondences, the last explicitly models outliers.\n1.2 Our work\nThe objective of this paper is to investigate which of the\noutlier elimination and modelling is more effective for the\nevaluation of the possible correspondences established, so\nthat a deep insight into how more accurate range image\nregistration algorithms will be developed can be obtained.\nThe investigation is conducted through a comparative study\nof different algorithms that apply various strategies for the\nevaluation of the possible correspondences established us-\ning the traditional CPC. The reason why the possible corre-\nspondences (p1,p\u20321) and (p2,p\n\u2032\n2) established using the tra-\nditional CPC are used is that (1) they satisfy an orientation\nconstraint: the dot product of two vectors R(p2 \u2212 p1) and\np\u20322\u2212p\u20321 is non-negative; (2) they satisfy a rigid distance con-\nstraint: \u22121 \u2264 ||p\u20322\u2212p\u20321||\u2212||p2\u2212p1||||p2\u2212p1|| \u2264\n2||Rp1+t\u2212p\u20321||\n||p2\u2212p1|| +1; and\n(3) as long as one of the possible correspondences (p1,p\u20321)\nhas a limited registration error (RE) ||Rp1+t\u2212p\u20321||, then all\nothers (p2,p\u20322) must also have limited REs: ||p\u20322 \u2212Rp2 \u2212\nt|| \u2264 ||Rp1+ t\u2212p\u20321||+ ||p2\u2212p1|| where R and t are the\ncamera motion parameters rotation matrix and translation\nvector respectively.\nClearly, the algorithms applicable to the evaluation of\npossible correspondences established using the traditional\nCPC are also applicable to the evaluation of possible cor-\nrespondences established using either the FEM or OCP\nmethod. Choosing the former for a comparative study is\nbecause of two factors: (1) While the CPC is easier to im-\nplement, the latter is more difficult, since it involves image\npre-processing for the suppression of imaging noise, fea-\nture extraction is sensitive to both imaging noise and res-\nolution, feature matching is inherently ambiguous, and the\noptimization of the combination of points is not always suc-\ncessful; and (2) the CPC can guarantee that the established\ncorrespondences are of high quality, when compared with\ntheir neighbours, in the sense of satisfying the constraints\noutlined above, the quality of correspondences established\nusing either the FEM or OCP method is unpredictable at all.\nFor the comparative study, four representative algo-\nrithms: collinear ICP (CICP) [10], geometric ICP (GICP)\n[7], Pulli pair-wise ICP (Pulli) [11], and SoftICP [9] are\nthus selected in this paper. Since the Pulli algorithm re-\nquires normal vector information of points which is difficult\nto estimate from point clouds, it will not be evaluated using\nsynthetic data. The selected algorithms will be compared\nusing both synthetic data with different levels of noise and\nsizes of overlap and real images with different sizes of cam-\nera motions and different orders and resolutions of images.\nThe rest of this paper is structured as follows: while Sec-\ntion 2 outlines the selected algorithms, Section 3 presents\n1317\n \nthe experimental results. Finally, Section 4 draws some con-\nclusions.\n2 Outline of relative algorithms\nThe following notations are used throughout this paper:\ncapital letters denote vectors or matrices, lower case letters\ndenote scalars, |\u00b7| denotes the absolute value of a scalar, ||\u00b7||\ndenotes the Euclidean norm of a vector, and superscript T\ndenotes the transpose of a vector.\nAssume that the two range images to be registered\nare represented as two sets of unorganised points P =\n{p1,p2, \u00b7 \u00b7 \u00b7 ,pn1} and P\u2032 = {p\u20321,p\u20322, \u00b7 \u00b7 \u00b7 ,p\u2032n2}, represent-\ning the same free form shape from two different nearby\nviewpoints with overlap in 3D space. Given that the cam-\nera motion parameters rotation matrix R and translation\nvector t have been initialised or estimated, the traditional\nICP criterion [1] can be used to establish a set of possi-\nble correspondences (pi,p\u2032c(i)) between P and P\n\u2032: p\u2032c(i) =\nargminp\u2032\u2208P\u2032 ||p\u2032 \u2212 Rpi \u2212 t||. In order to speed up the\nsearch for the closest points p\u2032c(i), the optimised K-D tree\ndata structure was employed. The selected algorithms:\nCICP, GICP, Pulli, and SoftICP are outlined as follows in\nthe sense of the evaluation of these correspondences. Please\nrefer to [10, 7, 11, 9] respectively for details.\n2.1 CICP\nGiven a possible correspondence (pi,p\u2032c(i)), its registra-\ntion error is estimated as ei = ||p\u2032c(i) \u2212 Rpi \u2212 t|| and\nits collinearity error is estimated as: ci = |p\u2032Tc(i)(Rpi +\nt)| || p\n\u2032\nc(i)\np\n\u2032T\nc(i)p\n\u2032\nc(i)\n\u2212 Rpi+t\n(Rpi+t)\nT (Rpi+t)\n||. Then the averages\ne\u00b5 and c\u00b5 and standard deviations e\u03b4 and c\u03b4 of registra-\ntion errors ei and collinearity errors ci are computed based\non those correspondences (pi,p\u2032c(i)) where neither pi nor\np\u2032c(i) is a boundary point. Finally, the following rule is\nused to reject false correspondences: if |ei \u2212 e\u00b5| < \u03bae\u03b4 ,\n|ci \u2212 c\u00b5| < \u03bac\u03b4 and neither pi nor p\u2032c(i) is a boundary\npoint, then (pi,p\u2032c(i)) is regarded as a feasible correspon-\ndence. Otherwise, it is a false one. Here \u03ba is a parameter to\nbe determined experimentally (generally, \u03ba \u2208 [1.0, 1.5]).\n2.2 Geometric ICP\nThe GICP algorithm applies the following procedure to\neliminate false correspondences:\n\u2022 Use the Monte Carlo resampling method to estimate\nthe essential point e\u02c6 as:\n\uf8eb\uf8ec\uf8ec\uf8ed\n(p1 \u2212 p\u2032\u20321 )T\n(p2 \u2212 p\u2032\u20322 )T\n(p3 \u2212 p\u2032\u20323 )T\n(p4 \u2212 p\u2032\u20324 )T\n\uf8f6\uf8f7\uf8f7\uf8f8 e\u02c6 =\n\uf8eb\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\n(pT1 p1\u2212p\n\u2032\u2032T\n1 p\n\u2032\u2032\n1 )\n2\n(pT2 p2\u2212p\n\u2032\u2032T\n2 p\n\u2032\u2032\n2 )\n2\n(pT3 p3\u2212p\n\u2032\u2032T\n3 p\n\u2032\u2032\n3 )\n2\n(pT4 p4\u2212p\n\u2032\u2032T\n4 p\n\u2032\u2032\n4 )\n2\n\uf8f6\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8\nwhere (pi,p\u2032\u2032i ) = (pi,\u2212p\u2032c(i)) (i = 1, 2, 3, 4) are\nany four possible reflected correspondences. This is a\nlinear equation group which can be solved using the\ntotal least squares method;\n\u2022 Compute the relative gaps of each possible reflected\ncorrespondence (pi,p\u2032\u2032i ):\n\u03b31 i =\n| ||pi \u2212 e\u02c6|| \u2212 ||p\u2032\u2032i \u2212 e\u02c6|| |\nmax (||pi \u2212 e\u02c6||, ||p\u2032\u2032i \u2212 e\u02c6||)\n\u03b32 i =\n| ||pi \u2212 e\u02c6|| \u2212 ||p\u2032\u2032i \u2212 e\u02c6|| |\nmax (||pi \u2212 e\u02c6||, ||p\u2032\u2032i \u2212 e\u02c6||)\nwhere pi = (I\u2212 hhT )pi, p\u2032\u2032i = (I\u2212 hhT )p\u2032\u2032i ,\ne\u02c6 = (I\u2212 hhT )e\u02c6, and h is the estimated rotation axis\nof the camera motion at the previous iteration. The\ncandidates to e\u02c6 are finally synthesized using the me-\ndian filter;\n\u2022 Compute the mean \u00b5 and standard deviation \u03c3 of the\ngaps:\n\u00b5\u03b31 =\n1\nn1\nn1\u2211\ni=1\n\u03b31 i, \u03c3\u03b31 =\n\u221a\u221a\u221a\u221a 1\nn1\nn1\u2211\ni=1\n(\u03b31 i \u2212 \u00b5\u03b31)2\n\u00b5\u03b32 =\n1\nn1\nn1\u2211\ni=1\n\u03b32 i, \u03c3\u03b32 =\n\u221a\u221a\u221a\u221a 1\nn1\nn1\u2211\ni=1\n(\u03b32 i \u2212 \u00b5\u03b32)2\n\u2022 Eliminate possible false correspondences: If |\u03b31 i \u2212\n\u00b5\u03b31 | > \u03c3\u03b31or |\u03b32 i \u2212 \u00b5\u03b32 | > \u03c3\u03b32 , then the possible\ncorrespondence (pi,p\u2032c(i)) is regarded as a false one.\n2.3 Pulli ICP\nAny possible correspondence (pi,p\u2032c(i)) cannot be real if:\n(1) either pi or p\u2032c(i) is a boundary point, (2) the includ-\ning angle between the normals at Rpi and p\n\u2032\nc(i) is larger\nthan 45\u25e6, (3) the distance between Rpi + t and p\u2032c(i)\nis larger than a threshold, which was determined as four\ntimes the resolution of the range images to be registered,\nand (4) it is ranked into the worst 10% among all possi-\nble correspondences according to their registration errors\n||Rpi + t\u2212 p\u2032c(i)||.\n1318\n \nFigure 2: The relationship between the parameters of\ninterest and the rotation angle. Top: rotation axis; Mid-\ndle: rotation angle; Bottom: translation vector.\n2.4 SoftICP\nThe following SoftICP algorithm is proposed in [9, 8] for\nautomatic 3D free form shape matching:\nInitialize R to the identity matrix, t, \u03b2 to \u03b20, m\u02c6i to\n1\/n1\nBegin A: Do A until (\u03b2 \u2265 \u03b2f )\nBegin B: Do B until the relative variations of both rota-\ntional and translational vectors at successive two iterations\nare larger than a threshold \u03c1 or # of iterations > I0\nUse the ICP criterion [1] to establish a set of possible\ncorrespondences (pi,p\u2032c(i)) between P and P\n\u2032;\nBegin C (update correspondence parameters\nby SoftAssign):\nCompute the corresponding matching error Q as:\nQi1 = ||p\u2032c(i) \u2212Rpi \u2212 t||2 (i = 1, 2, \u00b7 \u00b7 \u00b7 , n1),\nQi2 = ||p\u2032n2+1 \u2212Rpi \u2212 t||2 (i = 1, 2, \u00b7 \u00b7 \u00b7 , n1),\nQn1+1j = ||p\u2032j \u2212Rpn1+1 \u2212 t||2 (j = 1, 2, \u00b7 \u00b7 \u00b7 , n2).\nCompute the ragged matching array M as:\nmi1 = exp(\u2212\u03b2(Qi1 \u2212 \u03b1)) (i = 1, 2, \u00b7 \u00b7 \u00b7 , n1),\nmi2 = exp(\u2212\u03b20(Qi2 \u2212 \u03b1)) (i = 1, 2, \u00b7 \u00b7 \u00b7 , n1),\nmn1+1j = exp(\u2212\u03b20(Qn1+1j \u2212 \u03b1)) (j = 1, 2, \u00b7 \u00b7 \u00b7 , n2).\nBegin E: Impose the two-way constraint\nFor each row i (i = 1, 2, \u00b7 \u00b7 \u00b7 , n1), the normalisation is\nimplemented as: m\u02c61ij \u2190\nm\u02c60ij\u2211j=2\nj=1\nm\u02c60\nij\n(j=1, 2);\nInitialise the sum of matching probabilities for each\npoint in P\u2032 as: s(j) = m\u02c61n1+1j (j = 1, 2, \u00b7 \u00b7 \u00b7 , n2);\nConsider the matching probability for any point in P\u2032\nfound as a possible point correspondent by a point in P:\ns(c(i))\u2190 s(c(i)) + m\u02c61i1 (i = 1, 2, \u00b7 \u00b7 \u00b7 , n1);\nNormalise each column (with sparse elements) in M as:\nm\u02c60i1 =\nm\u02c61i1\ns(c(i)) (i = 1, 2, \u00b7 \u00b7 \u00b7 , n1), m\u02c60n1+1j =\nm\u02c61n1+1j\ns(j) (j =\n1, 2, \u00b7 \u00b7 \u00b7 , n2);\nEnd E\nEnd C\nBegin D (update camera motion parameters\nusing the quaternion method)\nUpdate R, t from the objective function: E3D(R, t) =\nminR,t\n\u2211n1\ni=1mi1||p\u2032c(i) \u2212Rpi \u2212 t||2\nEnd D\nEnd B\n\u03b2 \u2190 \u03b2r\u03b2\nEnd A\nwhere \u03b20 denotes the initial inverse temperature for de-\nterministic annealing, \u03b2r the inverse temperature increasing\nrate, \u03b2f the final inverse temperature, \u03b1 is the squared reg-\nistration error of a real correspondence, \u03c1 is the expected\nrelative camera motion estimation error, I0 is the maximum\niteration number, and pn1+1 and p\n\u2032\nn2+1 are slack variables\nfor the explicit outlier modelling.\n3 Experimental results\nIn this section, we compare four state of the art ICP vari-\nants CICP [10], GICP [7], Pulli pair-wise ICP [11] and\nthe SoftICP algorithm [9, 8] for the evaluation of possible\ncorrespondences based on both synthetic data and real im-\nages. All experiments were implemented on a Pentium IV,\n2.80GHz computer.\n1319\n \nTable 1: The average \u00b5 and standard deviation \u03c3 of the relative\ncalibration errors eh, e\u03b8 , and et in percentage of rotation axis h\u02c6,\nrotation angle \u03b8\u02c6, and translation vector t\u02c6 using synthetic data cor-\nrupted by different levels of noise.\nNoise Measure Method eh(%) e\u03b8(%) et(%)\nCICP 1.55 1.66 0.39\n\u03c31 \u00b5 GICP 1.56 4.43 0.17\nSoftICP 0.98 0.50 0.20\nCICP 0.86 1.72 0.08\n\u03c3 GICP 2.16 2.79 0.09\nSoftICP 0.74 0.45 0.00\nCICP 1.06 2.24 0.34\n\u03c32 \u00b5 GICP 0.75 4.16 0.19\nSoftICP 2.14 1.03 0.43\nCICP 0.76 1.89 0.00\n\u03c3 GICP 0.56 3.29 0.00\nSoftICP 1.61 0.94 0.01\n3.1 Synthetic data with sparse points\nFirst n points P = {p1,p2, \u00b7 \u00b7 \u00b7 ,pn} were randomly\ngenerated with uniform distribution within the 3D space\n[10, 20] \u00d7 [10, 20] \u00d7 [10, 20]. These points were then sub-\njected to a rotation angle \u03b8 around a fixed rotation axis h\n(subject to normalization) randomly generated with uniform\ndistribution within the 3D space [1, 3] \u00d7 [1, 3] \u00d7 [1, 3] fol-\nlowed by a constant translation vector t randomly generated\nwith uniform distribution within the 3D space [10, 20] \u00d7\n[10, 20] \u00d7 [10, 20]. Let the transformed points be P\u2032 =\n{p\u20321,p\u20322, \u00b7 \u00b7 \u00b7 ,p\u2032n}. Once the data were generated we thus,\nhave precise knowledge of the selected points and their cor-\nrespondents (pi,p\u2032i)(i = 1, 2, \u00b7 \u00b7 \u00b7 , n) and motion parame-\nters rotation matrix R and translation vector t to serve as\nreference for error estimation and validation of the algo-\nrithms.\nIn order to simulate real world noise contaminated data,\nGaussian white noise was added to the coordinates of each\npoint with standard deviation \u03c31 = 0.04 in one series of\nexperiments and \u03c32 = 0.08 in another. In order to simu-\nlate occlusion and appearance and disappearance of points,\nunless otherwise stated, we removed the last 25% points in\nP and the first 15% points in P\u2032. Finally we obtained two\nnew sets of points P and P\u2032 for registration with 60% over-\nlap in 3D space. The parameters of interest are the relative\nestimation errors of rotation axis h\u02c6, rotation angle \u03b8\u02c6 and\ntranslation vector t\u02c6 of the camera motion.\n3.1.1 Different levels of noise\nIn this section, we do a comparative study of performance\nof different algorithms for the evaluation of possible corre-\nspondences using data that were corrupted by different lev-\nFigure 3: The relationship between the parameters of\ninterest and the percentages of disappearing and appear-\ning points in different data sets. Top row: rotation axis;\nMiddle row: rotation angle; Bottom row: translation\nvector. Left column: CICP; Middle column: GICP;\nRight column: SoftICP.\nTable 2: The average \u00b5 and standard deviation \u03c3 of the relative\ncalibration errors eh, e\u03b8 , and et in percentage of rotation axis h\u02c6,\nrotation angle \u03b8\u02c6, and translation vector t\u02c6 using synthetic data cor-\nrupted by different levels of noise.\nMeasure Method eh(%) e\u03b8(%) et(%)\nCICP 1.27 0.59 0.40\n\u00b5 GICP 0.80 1.78 0.26\nSoftICP 0.46 0.28 0.20\nCICP 0.95 0.41 0.25\n\u03c3 GICP 0.88 1.24 0.21\nSoftICP 0.08 0.09 0.02\nels of Gaussian white noise. The experimental results are\npresented in Figure 2 and Table 1 (n=100). In the figure, the\nsolid lines correspond to the low level \u03c31 of noise, the dash\nlines correspond to the high level \u03c32 of noise, lines with\npluses correspond to the CICP algorithm, lines with crosses\ncorrespond to the GICP algorithm, and lines without any\nsigns correspond to the SoftICP algorithm.\nFrom Figure 2, it can be seen that while both the CICP\nand GICP algorithms are significantly less accurate than the\nSoftICP algorithm, the former is not stable. This is because\nthe CICP algorithm has to determine the parameter \u03ba to re-\nject false correspondences which is dependent on the cam-\nera motion, the distribution of the data points and the size\nof overlap between the data sets to be registered. In con-\ntrast, the SoftICP algorithm uniformly treats all possible\ncorrespondences in the sense of estimating their probabil-\nities of being real embedded into the powerful deterministic\n1320\n \nannealing scheme, leading the camera motion parameters to\nbe accurately estimated in the weighted least squares sense,\ninstead of in the least squares sense.\n3.1.2 Different percentages of appearing and disap-\npearing points\nFigure 4: Final registration results of images subject to\nsmall motions. Left column: CICP; Second column:\nGICP; Third column: Pulli; Right column: SoftICP.\nTop row: tubby1-2; Second row: lobster1-2; Third row:\nfrog1-2; Bottom row: duck1-2.\nIn this section, we report the experimental results about\nthe sensitivity of different algorithms to the appearance and\ndisappearance of points in different data sets. The rotation\nangle of the camera motion was fixed: \u03b8 = 25\u25e6. The exper-\nimental results are presented in Figure 3 and Table 2.\nFrom Figure 3, it can be seen that while the SoftICP al-\ngorithm produced relatively stable results, both the CICP\nand GICP algorithms perform worse with the percentages\nof appearing and disappearing points increasing. This is be-\ncause more disappearing and appearing points imply that\nmore outliers will be generated by the traditional CPC. In\nthis case, the setting of the parameter \u03ba as a constant in\nthe CICP algorithm does not reflect the percentage of ac-\ntual overlap between two point sets being registered. A\nlarge number of outliers renders the Monte Carlo resam-\npling scheme the GICP algorithm to degrade for the esti-\nmation of the essential point e\u02c6, resulting in an incomplete\nelimination of false correspondences.\n3.2 Real images with dense points\nFigure 5: Final registration results of images subject to\nlarge motions. Left column: CICP; Second column:\nGICP; Third column: Pilli; Right column: SoftICP.\nTop row: tubby1-3; Second row: lobster1-3; Third row:\nfrog1-3; Bottom row: duck-3.\nIn this section, we report the experimental results based\non real images. The real range images (Figure 1) used in\nthis paper were downloaded from a publicly available range\nimage database currently hosted by the Signal Analysis and\nMachine Perception laboratory at Ohio State University,\nwere captured using a Minolta Vivid 700 range camera, and\nare of the same size of 200 \u00d7 200 pixels. The parameters\nof interest are the average and standard deviation of regis-\ntration errors of the reciprocal correspondences (RCs), the\nestimated rotation angles of the camera motions that can\nbe derived from the image file name encoding, and the time\nfor registration. In Figures 4 and 5, yellow colour represents\nthe transformed first images, the green colour represents the\nsecond images.\n3.2.1 Small motions\nSince the ICP algorithm requires a good initialisation of\ncamera motion parameters, in this section, we report the\n1321\n \nTable 3: The average e\u00b5 and standard deviation e\u03b4 of regis-\ntration errors in millimetres based on RCs, expected rotation\nangle \u03b8 and calibrated rotation angle \u03b8\u02c6 in degrees, the num-\nber N of finally established RCs, and registration time t in\nseconds for different algorithms applied to different range\nimages.\nImage q e\u00b5 e\u03b4 \u03b8 \u03b8\u02c6 N t\n(mm) (mm) (\u25e6) (\u25e6) (s)\nCICP 0.28 0.15 18.80 3140 10\ntubby1-2 GICP 0.26 0.15 20 19.66 3092 9\nPulli 0.27 0.15 19.14 3140 16\nSoftICP 0.27 0.15 19.35 3134 16\nCICP 0.45 0.32 17.96 4469 17\nlobster1-2 GICP 0.44 0.36 20 20.94 4320 16\nPulli 0.45 0.32 17.77 4498 53\nSoftICP 0.42 0.32 18.12 4617 34\nCICP 0.30 0.30 18.48 5304 14\nfrog1-2 GICP 0.29 0.30 20 18.90 5304 18\nPulli 0.29 0.30 18.72 5313 49\nSoftICP 0.29 0.30 19.11 5343 29\nCICP 0.42 0.26 6.81 6931 19\nduck1-2 GICP 0.35 0.20 20 13.20 7147 19\nPulli 0.41 0.25 7.56 6951 79\nSoftICP 0.36 0.23 11.55 7137 40\nexperimental results for the automatic registration of over-\nlapping range images subject to relatively small motions.\nDoing so provides an ideal condition for all algorithms to\nregister overlapping range images. The experimental results\nare presented in Figure 4 and Table 3.\nFrom Figure 4, it can be seen that while all algorithms\naccurately register both the tubby and lobster images, they\ninaccurately register the duck images, especially the CICP\nand Pulli algorithms displace the wings of duck in the two\nimages. This conclusion has been clearly confirmed by the\nsmaller rotation angles of the camera motion estimated in\nTable 3. Due to the necessity to do the statistics on the aver-\nage distance between neighbouring points in images being\nregistered, the Pulli algorithm generally takes longer time\nfor registration.\n3.2.2 Large motions\nIn this section, we report the experimental results for the au-\ntomatic registration of overlapping range images subject to\nrelatively large motions with rotation angles as large as 40\u25e6.\nSince large motions violate the assumption of the ICP algo-\nrithm, it is expected that all the ICP variants will perform\npoorly. The experimental results are presented in Figure 5\nand Table 4.\nFrom Figure 5 and Table 4, it can be seen that there is\na large variation among the registration results. While the\nCICP, GICP, and Pulli algorithms all displace the hands and\nears of tubby in the images and the mouths and front legs of\nfrog in the images, the SoftICP algorithm accurately regis-\ntered all of them. When the range images are of low quality,\nas is the case for both the lobster and duck images, all al-\ngorithms performed poorly. This shows that more accurate\nand stable algorithms still need to be developed.\nTable 4: The average e\u00b5 and standard deviation e\u03b4 of regis-\ntration errors in millimetres based on RCs, expected rotation\nangle \u03b8 and calibrated rotation angle \u03b8\u02c6 in degrees, the num-\nber N of finally established RCs, and registration time t in\nseconds for different algorithms applied to different range\nimages.\nImage q e\u00b5 e\u03b4 \u03b8 \u03b8\u02c6 N t\n(mm) (mm) (\u25e6) (\u25e6) (s)\nCICP 0.54 0.33 28.61 1717 15\ntubby1-3 GICP 0.51 0.31 40 26.92 1708 13\nPulli 0.52 0.33 19.96 1771 19\nSoftICP 0.26 0.19 39.29 2068 35\nCICP 0.69 0.54 58.90 2660 37\nlobster1-3 GICP 0.65 0.49 40 54.34 2653 31\nPulli 0.70 0.52 58.00 2609 92\nSoftICP 0.63 0.60 68.91 2665 69\nCICP 0.47 0.49 26.46 2389 25\nfrog1-3 GICP 0.50 0.36 40 23.96 2193 28\nPulli 0.49 0.32 26.05 2244 54\nSoftICP 0.33 0.28 38.15 3199 38\nCICP 0.59 0.42 9.13 5108 30\nduck1-3 GICP 0.64 0.47 40 14.02 4676 32\nPulli 0.59 0.43 8.57 5167 86\nSoftICP 0.51 0.38 9.09 5349 59\nTable 5: The average e\u00b5 and standard deviation e\u03b4 of regis-\ntration errors in millimetres based on RCs, expected rotation\nangle \u03b8 and calibrated rotation angle \u03b8\u02c6 in degrees, and reg-\nistration time t in seconds for different algorithms applied\nto different range images.\nImage Algo. e\u00b5(mm) e\u03b4(mm) \u03b8(\n\u25e6) \u03b8\u02c6(\u25e6) t(s)\nCICP 0.45 0.26 32.74 16\ntubby3-1 GICP 0.44 0.26 40 32.03 13\nPulli 0.40 0.25 25.95 20\nSoftICP 0.25 0.19 39.44 32\nCICP 0.67 0.51 57.80 30\nlobster3-1 GICP 0.51 0.38 40 41.85 22\nPulli 0.67 0.47 55.86 89\nSoftICP 0.63 0.63 67.79 59\nCICP 0.66 0.53 26.39 43\nfrog3-1 GICP 0.66 0.53 40 43.79 27\nPulli 0.66 0.54 39.19 84\nSoftICP 0.55 0.49 46.56 81\nCICP 0.53 0.36 10.87 31\nduck3-1 GICP 0.56 0.37 40 10.57 32\nPulli 0.55 0.38 9.93 78\nSoftICP 0.48 0.35 15.24 52\n3.2.3 Image order\nIn this section, we reverse the image orders so that we can\ntest whether algorithms will produce different results. The\nexperimental results are presented in Table 5.\nTable 5 shows that quite different results have been pro-\nduced in the sense of average registration error and the ro-\ntation angle of the camera motion. While the SoftICP algo-\nrithm still accurately registers the tubby images, the GICP\nalgorithm produces a difference in the rotation angle of the\ncamera motion of as large as 20\u25e6 for the registration of the\nfrog images. This shows that image orders do have a subtle\neffect on the performance of the ICP algorithms.\n1322\n \nTable 6: The average e\u00b5 and standard deviation e\u03b4 of regis-\ntration errors in millimetres based on RCs, expected rotation\nangle \u03b8 and calibrated rotation angle \u03b8\u02c6 in degrees, and reg-\nistration time t in seconds for different algorithms applied\nto different range images.\nImage q e\u00b5(mm) e\u03b4(mm) \u03b8(\n\u25e6) \u03b8\u02c6(\u25e6) t(s)\nCICP 0.75 0.40 27.66 11\ntubby1-3 GICP 0.74 0.42 40 26.34 11\nPulli 0.84 0.50 5.43 9\nSoftICP 0.46 0.20 38.73 14\nCICP 1.03 0.61 60.39 14\nlobster1-3 GICP 0.95 0.54 40 52.98 11\nPulli 1.02 0.67 37.55 12\nSoftICP 1.01 0.78 68.75 16\nCICP 0.73 0.38 25.16 12\nfrog1-3 GICP 0.73 0.38 40 25.58 13\nPulli 0.76 0.41 24.26 13\nSoftICP 0.53 0.48 37.88 13\nCICP 0.83 0.47 9.14 11\nduck1-3 GICP 0.91 0.60 40 13.21 12\nPulli 0.83 0.47 9.23 13\nSoftICP 0.76 0.45 8.59 15\n3.2.4 Image resolution\nIn this section, we test different algorithms using low reso-\nlution images. Low resolution images were generated using\nthe uniform sampling: odd pixels in each row in the orig-\ninal raster file. The experimental results are presented in\nTable 6.\nTable 6 shows that except the fact that all algorithms have\nproduced larger average registration errors, as expected, the\nPulli algorithm produced a variation in the rotation angle of\nthe camera motion of as large as 15\u25e6 for the registration of\nthe tubby and lobster images. This shows that image reso-\nlutions also have a subtle effect on the registration results of\nthe ICP algorithms.\n4 Conclusions\nIn this paper, we have compared four representative ICP\nvariants using both synthetic data and real images with\nan attempt to reveal which of the outlier elimination and\nmodelling is more effective for the evaluation of the possi-\nble correspondences established. The experimental results\nshow: (1) the image quality is vital for accurate range im-\nage registration. This means that the images must be com-\nplex enough to deliver the camera motion information. Poor\nquality images like lobster and duck will present a challenge\nto any algorithm for registration and registration errors eas-\nily crop up; (2) The SoftICP algorithm usually produces the\nsmallest average registration errors. This shows that the ex-\nplicit outlier modelling often outperforms the outlier elim-\nination in the sense of achieving accurate automatic range\nimage registration results, since the classification of pos-\nsible correspondences into either real or false ones is not\nalways successful, due to the fact that the classification is\noften data dependent; and (3) While the SoftICP algorithm\noften produces better registration results, it is often more\ncomputationally expensive, since it adopts the iterative de-\nterministic annealing scheme for the optimization of the\nprobabilities of the possible correspondences established.\nFurther research is to accurately model outliers for auto-\nmatic range image registration in the process of underwater\noil pipe modelling and inspection. Research is under way\nand the results will be reported in the future.\nReferences\n[1] P. J. Besl, N. D. McKay. A method for registration of 3D\nshapes. IEEE Trans. PAMI, 14(1992) 239-256.\n[2] D.M. Cole and P.M. Newman. Using laser range data for 3D\nSLAM in outdoor environments. Proc. ICRA, 2006, pp. 188-\n193.\n[3] G. Dewaele, F. Devernay, and H. Horaud. Hand motion from\n3D point trajectories and a smooth surface model. Proc.\nECCV, 2004, pp. 495-507.\n[4] H.Q. Dinh, S. Kropac. Multi-resolution spin images. Proc.\nCVPR, 2006, pp. 863-870.\n[5] S. Gold, A. Rangarajan, et al. New algorithms for 2-D and 3-D\npoint matching: pose estimation and correspondence. Pattern\nRecognition 31(1998) 1019-1031.\n[6] S. Granger and Xavier Pennec, Multi-scale EMICP: a fact and\nrobust approach for surface registration, Proc. ECCV, 2002,\nLNCS, pp. 418-432.\n[7] Y. Liu, M.A. Rodrigues, and Y. Wang. Developing rigid mo-\ntion constraints for the registration of free-form shapes. Proc.\nIEEE\/RSJ IROS, 2000, pp. 2280-2285.\n[8] Y. Liu. Automatic registration of overlapping 3D point clouds\nusing closest points. Image and Vision Computing, 24(2006)\n762-781.\n[9] Y. Liu. Automatic 3d free form shape matching using\nthe graduated assignment algorithm. Pattern Recognition,\n38(2005) 1615-1631.\n[10] Y. Liu, L. Li, B. Wei. 3D shape matching using collinearity\nconstraint. Proc. ICRA, 2004, pp. 2285-2290.\n[11] K. Pulli. Multiview registration for large data sets. Proc.\n3DIM, 1999, pp. 160-168.\n[12] L. Silva, Olga R.P. Bellon, and K.L. Boyer. Precision\nrange image registration using a robust surface interpenetra-\ntion measure and enhanced genetic algorithms. IEEE Trans.\nPAMI, 27(2005) 762-776.\n[13] G. Turk and M. Levoy. Zippered polygon meshes from range\nimages. Proc. SIGGRAPH, pp. 311-318, 1994.\n1323\n \n"}
{"doi":"10.1109\/ISCE.2006.1689506","coreId":"69742","oai":"oai:eprints.lancs.ac.uk:22912","identifiers":["oai:eprints.lancs.ac.uk:22912","10.1109\/ISCE.2006.1689506"],"title":"C++ Optimisations for Mobile Applications.","authors":["Chehimi, Fadi","Coulton, Paul","Edwards, Reuben"],"enrichments":{"references":[{"id":1025988,"title":"Accelerating compute intensive functions using C\u201d, Dr. Dobb\u2019s Journals,","authors":[],"date":"2006","doi":null,"raw":null,"cites":null},{"id":1026283,"title":"Direct memory access: meeting system throughput demands\u201d,","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":1025704,"title":"Evolution of 3-D games on mobile phones\u201d, proceedings of the","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":1028462,"title":"Measuring inline functions\u201d,","authors":[],"date":"2004","doi":null,"raw":null,"cites":null},{"id":1027215,"title":"Optimizing you C\/C++ applications part I, II\u201d, www.devx.com, last accessed","authors":[],"date":"2006","doi":null,"raw":null,"cites":null},{"id":1026924,"title":"Performance programming applied to C++\u201d, GameDev,","authors":[],"date":"2000","doi":null,"raw":null,"cites":null},{"id":1027908,"title":"Register access in C++\u201d,","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":1026636,"title":"Symbian OS C++ for mobile phones,","authors":[],"date":"2003","doi":null,"raw":null,"cites":null},{"id":1027597,"title":"The top 20 C++ tips of all time\u201d, www.devx.com, last accessed","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":1028169,"title":"Winning the passing game\u201d, Dr. Dobbs Journals, Optimize to the max column, last accessed","authors":[],"date":"2005","doi":null,"raw":null,"cites":null}],"documentType":{"type":null}},"contributors":[],"datePublished":"2006-07","abstract":"Mobile application development requires many techniques unfamiliar to the general PC developer due to the limitations presented by the mobile platforms. Unlike the PC environment where hardware capabilities can easily be upgraded to accommodate more complex applications, in the mobile environment the onus is on the ability of the developer to produce optimized software with minimal overhead to outcome the desired results. In this paper we define generic paradigms relating to memory and code optimizations for Symbian C++ applications on mobile phones. We illustrate through testing, on an actual device, the advantages that these techniques can produce and their importance for mobile application developer","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"IEEE","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:22912<\/identifier><datestamp>\n      2018-01-16T00:05:23Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413736<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        C++ Optimisations for Mobile Applications.<\/dc:title><dc:creator>\n        Chehimi, Fadi<\/dc:creator><dc:creator>\n        Coulton, Paul<\/dc:creator><dc:creator>\n        Edwards, Reuben<\/dc:creator><dc:subject>\n        QA76 Computer software<\/dc:subject><dc:description>\n        Mobile application development requires many techniques unfamiliar to the general PC developer due to the limitations presented by the mobile platforms. Unlike the PC environment where hardware capabilities can easily be upgraded to accommodate more complex applications, in the mobile environment the onus is on the ability of the developer to produce optimized software with minimal overhead to outcome the desired results. In this paper we define generic paradigms relating to memory and code optimizations for Symbian C++ applications on mobile phones. We illustrate through testing, on an actual device, the advantages that these techniques can produce and their importance for mobile application developers<\/dc:description><dc:publisher>\n        IEEE<\/dc:publisher><dc:date>\n        2006-07<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/ISCE.2006.1689506<\/dc:relation><dc:identifier>\n        Chehimi, Fadi and Coulton, Paul and Edwards, Reuben (2006) C++ Optimisations for Mobile Applications. In: Consumer Electronics, 2006. ISCE '06. 2006 IEEE Tenth International Symposium on. IEEE. ISBN 1-4244-0216-6<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/22912\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/ISCE.2006.1689506","http:\/\/eprints.lancs.ac.uk\/22912\/"],"year":2006,"topics":["QA76 Computer software"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":" 1-4244-0216-6\/06\/$20.00 \u00a92006 IEEE \nC++ Optimizations  \nfor Mobile Applications \nFadi Chehimi, Paul Coulton and Reuben Edwards \nAbstract \u2014 Mobile application development requires many \ntechniques unfamiliar to the general PC developer due to the \nlimitations presented by the mobile platforms. Unlike the PC \nenvironment where hardware capabilities can easily be upgraded \nto accommodate more complex applications, in the mobile \nenvironment the onus is on the ability of the developer to produce \noptimized software with minimal overhead to outcome the desired \nresults. In this paper we define generic paradigms relating to \nmemory and code optimizations for Symbian C++ applications on \nmobile phones. We illustrate through testing, on an actual device, \nthe advantages that these techniques can produce and their \nimportance for mobile application developers.1. \n \nIndex Terms \u2014 Optimization, C++, mobile applications, \nSymbian OS.  \nI. INTRODUCTION \nMobile phones have evolved rapidly and are now \nrequired to perform increasing amounts of processing and \ndata usage more than their predecessors. Applications \nranging from telephony to communication to entertainment \nto commerce are all emerging for operation on this compact \nbut limited platform creating considerable demands of its \nmemory and power resources. To make sure these resources \nare not squandered programmers should guarantee efficient \nperformance of their programs by providing the optimized \nbalance of processing consumption and code size. In other \nwords they must develop designs that take proper account of \nthe platform constraints and operating parameters.   \nOptimization can occur in different stages of the \ndevelopment cycle and in different areas. For example, the \ntarget architecture can be upgraded, algorithms could be \nmodified, compilers\u2019 optimization power can be turned on, \nand coding practices might be subject to amendment. \nUpgrading the mobile architecture is not practical for the \ngeneral developer as it would generally require significant \nmodifications of internal chip architectures or device \nstructures. Algorithms on the other hand are dependent on \nthe context and field they are being used in and are therefore \noften application dependent. Compilers usage relies on \n \n1 This work was carried on in real-time hardware and software \nlaboratory in Infolab21 at Lancaster University supported by Nokia. \nF. Chehimi is a PhD student in the Department of Communication \nSystems at Lancaster University, Lancaster, LA1 4YW, UK (e-mail: \nf.chehimi@lancs.ac.uk).  \nP. Coulton is a Senior Lecturer in the Department of Communication \nSystems at Lancaster University, Lancaster, LA1 4YW, UK (e-mail: \np.coulton@lancs.ac.uk). \nR. Edwards Lecturer in the Department of Communication Systems at \nLancaster University, Lancaster, LA1 4YW, UK (e-mail: \nr.edwards@lancs.ac.uk). \nprogrammers\u2019 taste and preference. However, coding style is \ngeneric to every project and therefore is a worthy topic of \nstudy. In this paper we will address this generic issue for the \nwider benefit and improvement of most mobile application \ndevelopers. \nWhilst there is a number of software platforms for mobile \ndevelopment we shall limit our discussions to the most \npopular, the Symbian OS, which utilizes a specialized \nversion of C++. Symbian is divided into different versions to \ncover a number of user interfaces and in this paper we \nconcentrate on the most common which is Series 60, \nalthough this is for illustration and the techniques could be \napplied almost generically. We have chosen the Nokia 6680 \nas the test device to test our optimization paradigms which is \nan ARM-powered phone with 220MHz CPU.  \nIn order to test, analyze and illustrate performance \nenhancement we have developed a Symbian-based \nbenchmarking tool which we have termed Mobot. The tool \nallows us to test various code snippets and measures the time \nconsumed. The information retrieved demonstrates the \neffectiveness of the prescribed programming technique. \nBefore presenting these paradigms it is essential to \nunderstand the limitations that are critical to mobile \napplication development and in section 2 we discuss the \nmost significant of them. In section 3 we will detail the \noptimization paradigms and present their validation through \nthe use of Mobot. The techniques introduced in this section \nare categorized into object-oriented, memory and coding-\nstyle optimizations. Section 4 will analyze the improvement \nthese techniques provided and construct a recommended \ncoding pattern for developers to follow before we conclude \nin section 5. \nII. LIMITATIONS OF THE MOBILE PLATFORMS \nWhen moving from console or PC platforms to devices \nsuch as mobile phones, special care has to be taken during \nthe development process because the mobile platform is \nlimited in performance, power and memory resources. In the \nfollowing paragraphs we present some of the most \nsignificant constraints that should be considered by all \nmobile application developers. \nA. Control Processing Units (CPU) \nMany of the current high-end mobile phones operate at \nrelatively slow clock speed, typically, around 180MHz. This \nmeans that many complex calculations required by some \napplications, such as 3-D graphics, are limited in the speed \nwith which they can be performed.  Further, CPUs on mobile \nphones generally have small caches which means that \nAuthorized licensed use limited to: Lancaster University Library. Downloaded on January 7, 2009 at 04:06 from IEEE Xplore.  Restrictions apply.\n 1-4244-0216-6\/06\/$20.00 \u00a92006 IEEE \nalgorithms requiring complex data moves can also produce \nexcessive demands on the CPU. \nSome specialists expect that mobile processors with \n1GHz speed are likely to appear in the next couple of years \n[1]. However, for these processors to exist they will have to \novercome the non-trivial problems of battery life and heat \ngeneration. \nB. Low Buss Bandwidth \nIn heavy-loaded embedded applications data transferred \nbetween the CPU and memory, or I\/O peripherals, could \neasily become bottlenecked because of the low bus \nbandwidth. Too narrow or too slow bus limits have \nsignificant impact on the overall efficiency and throughput \n[2]. \nVarious mobile venders are trying to optimize bus speed \nfor better performance but developers have to be aware of \nthis limitation while programming their application by \nmeeting the critical data throughput boundaries and not \noverloading the data path [1, 3]. \nC. Memory \nThe memory space available for developers has always \nbeen an issue in mobile computing. This is no longer a \ncritical issue with the falling prices of flash memory and the \nintroduction of hard-drive-based mobile phones. However, \nmemory has to be treaded cautiously and used wisely in any \nmobile application because the sizes available are \ninsignificant in comparison to the nature of applications \nusing memory. Failing to do so might cause memory \nfragmentation, memory leaks and frequent system crashing. \nIII. OPTIMIZATION CRITERIA \nThe optimizations we will consider have been split into \nthree categories: 1) memory optimization, 2) object-oriented \noptimization and 3) coding style optimization. For each \ncategory we will describe practices that can be used to \nimprove execution performance of mobile applications. \nMobot will be used to analyze and prove this improvement. \nIt will be fed the coming testing code snippets each at a \nsingle time. It will then measure the time taken to complete \neach code under examination by iterating calling it \n100,000,000 times in a loop. The time before entering and \nafter exiting the loop will be recorded, subtracted and \nconverted to milliseconds. The pseudo-code for the \noperation of Mobot is as follows: \n \ni = 100000000;  \n \nGetTime(beforeLoop); \n \nwhile( --i >= 0) \n{ \n\/\/ Specific code to be tested \n} \nGetTime(afterLoop);  \n \nresult = ToMilliseconds(  \nafterLoop \u2013 beforeLoop);  \nTo ascertain the effects of the Mobot code itself from our \nanalysis we ran the above code without any implementation \nin the body of the loop to obtain an overall elapsed time of \n1.8125 seconds, which gives a mere 1.8125\u00d710 8\u2212  seconds \nfor each single iteration. We will base our discussions and \ncomparisons in this paper on the Total Elapse Time (TET) \nsince it is easier to deal with simple fractions.  \nA. Object-oriented optimization \nObject-orientation has introduced to software engineering \na collection of practices and methodologies that make the \nsoftware production more portable, the code more reusable, \nand the whole process less time consuming. Symbian OS is \nan object-oriented-based operating system that requires \nprogrammers to deal with objects more cautiously than what \nthey would do on PCs. There are certain hidden memory \noverheads that may inflate code caused by inefficient use of \nobjects and in the following paragraphs we address some of \nthese issues. \n1) Initialize objects at declaration time \nWhen declaring an object of a pre-defined or user-defined \nclass its initialization must occur at the time of its \ndeclaration as follows: \n \nMyClass obj = data; \n \nThis notation is cleaner and faster than \n \nMyClass obj; \nobj = data; \n \nPerforming the declaration and initialization on separate \nlines will invoke the object\u2019s default constructor then its \nassignment operator, which mean that two operations are \nrequired. However, in the first case only the copy \nconstructor of obj is called and data is constructed directly \ninto it. \n2) Use constructor initialization lists \nAlways use initialization lists with constructors, as \nillustrated below, when initializing objects\u2019 member \nvariables. This will invoke copy constructors of member \nobjects being initialized. \n \nMyClass::MyClass( MyData &data )  \n            : m_data( data ) { } \n \nUsing the normal initialization shown below follows the \nsame argument above where the objects\u2019 default constructor \nis called and them its assignment operator.  \n \nMyClass::MyClass( MyData &data )     \n{ \n   m_data = data; \n} \n \n3) Declare objects when needed \nDelay object declaration until the point they are needed. \nWhen an object is declared its constructor is called and this \nAuthorized licensed use limited to: Lancaster University Library. Downloaded on January 7, 2009 at 04:06 from IEEE Xplore.  Restrictions apply.\n 1-4244-0216-6\/06\/$20.00 \u00a92006 IEEE \nis a waste of processor cycles and memory if the object is \nnot used in the current scope of the application [4]. Further, \nremove unnecessary declarations, initializations or \ncalculations within loops such as: \n \nfor( int i = MAX; i >=0; --i ) \n{ \n   int k = var*2; \/\/unnecessary here \n   int arr[i] = k+1; \n} \n  \nDeclaring, initializing and calculating the value for k \nwhich is not influenced by the loop will be invoked in every \niteration and will eat-up dynamic memory and processor \ncycles causing excessive memory fragmentation. \n4) Pass function parameters by reference \nObjects, or structures, must not be passed by value to \nfunctions. First, memory equals to the total size of all \nmembers will be needed, which means that the whole \nstructure or object will be pushed\/pulled to\/from the small \nstack (generally 12KB on Symbian OS) [5]. Second, \nobjects\u2019 copy constructors will be invoked for initialization \ninvolving the creation of a temporary object. And third the \ndestructor will be called when the function exits. This \nimplies that the processor will involve three instructions to \nbe able to use the object [6]. Passing by reference on the \nother hand will consume none of these instructions since the \noriginal variable is referenced and no construction of a new \none is taking place.  \nB. Memory optimization \nThere are certain hidden memory overheads caused by \ninefficient variable usage and allocation that programmers \nusually force without noticing. Such practices might inflate \ncode causing slower performance and inept execution. The \nfollowing demonstrates some techniques that would treat the \nlimited memory resources on mobile phones. \n1) Use array notation for arrays rather than pointer \nnotation \nIt is hard for a compiler to optimize pointers\u2019 performance \nsince they are assumed to read\/write to any location in \nmemory. Since array notation ([]) is less ambiguous the \ncompiler may be able to optimize it more freely and \nefficiently [7]. \n2) Pass array function parameters as pointers not with \narray notation ([]) \nThe [] notation requires reserving memory equal to the \nlength of the array multiplied by its type size. For example if \nan array of integers has a length of 100 cells its total size \nwill be 400 bytes (given that the integer size on the tested \narchitecture is 4 bytes). If this array is passed as a parameter \nto a function the 400 bytes have to be reserved.  \n \nvoid DummyFunc(int arr[100]) { } \n \nIf the pointer notation is used instead then only 4 bytes, \nthe size of the integer pointer, are required. \n \nvoid DummyFunc(int *arr) { } \n \n3) Rearrange structure or class members \nThe size of a class or structure can be optimized simply \nby rearranging the order of its members\u2019 declarations. By \ntesting the following structure declaration we found out that \nthe memory required to hold an object of its type is 12 bytes, \nalthough it is expected to be 6 bytes. \n \nstruct MyStruct \n{ \n bool b1; \n int i; \n bool b2; \n}; \n \nAfter rearranging the order of the member variables the \nsize decreased to 8 bytes.  \n \nstruct MyStruct \n{ \n bool b1; \n bool b2; \n int i; \n}; \n \nThe reason for this difference in size is that compilers \nusually pad extra bytes to the smaller member data types to \nfit the size of the largest member type [8]. In the example \nabove i has 4 bytes and both b1 and b2 have 1 byte each. \nThe compiler has added 3 bytes to each of the Booleans \ngiving a total of three integer words (12 bytes).  \nWhen the second approach is used, the compiler has \nlocated the two Booleans continuously in the same word and \npadded only 2 bytes. In this case we ended up having only 2 \nwords rather than 3 (8 bytes). Note that whether the smaller \nor the largest type is on top is not important. \nC. Coding style optimization \nC and C++ are very lean and efficient programming \nlanguages as they allow the programmer to get too close to \nthe hardware as no other programming language can [9]. \nHowever, to make best use of these languages on mobile \nphones programmers have to write clean, safe and well-\ndesigned programs. Here we will illustrate and test several \ncoding techniques that can be used to leverage performance \nwith C\/C++ code (although they could equally be applied to \nother programming languages).  \n1) Always decrement the counter in a loop \nin other words, use a code like this \n \nfor( i = n-1; i >= 0; --i ) { } \n  \nrather than this \n \nfor( i = 0; i < n; ++i ) { } \n \nTesting against 0 is always faster than testing against any \nother value. As the test is performed in every iteration of the \nloop optimizing it will cause the loop to reach its end faster. \nAuthorized licensed use limited to: Lancaster University Library. Downloaded on January 7, 2009 at 04:06 from IEEE Xplore.  Restrictions apply.\n 1-4244-0216-6\/06\/$20.00 \u00a92006 IEEE \nTesting these two loops using Mobot showed that the \nincremental loop produced a 0.46875 second increase \ncompared to the decremental loop, which is approximately \nan increase of 20%.  \nFurther, post increment\/decrement operations are more \nexpensive than pre increment\/decrement. If --i and ++i were \nreplaced by i-- and i++ respectively the time consumed to \ncomplete the trip in the loop will be 2.71825 seconds in both \nsituations, instead of 1.8125. \n2) Unroll small fixed-count loops \nManual loop unrolling is practical only when the loop has \na small number of iterations (ideally 5). Loop-unrolling will \nsave the compiler from the overhead caused while jumping \nback and forth in the assembly table and changing the \ndirection of the control-flow. If the loop is large there will be \ninsufficient registers available to hold the variables\u2019 values \nwhich will force the compiler to use the disk memory which \nin return will slow down execution [2, 8]. \nTesting this technique via Mobot with a 5-count loop in \nthe initial while gave a total execution time of 10.421875 \nseconds. The time to execute the for-loop alone is TET \nsubtracted from this figure which results in 8.609375 \nseconds. \n \n\/\/ Initialization of i and array \n\/\/ outside initial while loop. \n\u2026 \nfor( i = 4 ; i >= 0; --i ) \n result += array[i]; \n \nThe unrolled version as below takes 1.8125 seconds, just \nas if there was no code implemented win the loop. \n \nresult += array[0]; \nresult += array[1]; \nresult += array[2]; \nresult += array[3]; \nresult += array[4]; \n \n3) Use registers for loop counters and frequently used \nvariables \nLoop counters are probably the best variables to use \nregisters for because they are frequently accessed. Turning a \nloop counter into a register by adding the register \nkeyword before its type eliminates the need for pushing the \nvariable from memory over the data bus into the stack [10] \nfor processing, which can be a time consuming process on \nlimited devices like mobile phones. Using registers will save \nprecious CPU cycles and will reduce pressure on the limited \nbus bandwidth since execution will take place in the internal \nCPU pipeline increasing the overall efficiency [2]. The \npotential problem here is that there might not be enough \nregisters to accommodate all values programmers may \ndefine. Therefore familiarity with the architecture of the \nplatform being targeted is essential. ARM has 16 registers \nwith three being reserved for stack operations, sub-routine \naddressing and program counter [11]. \nWhen assigning the counter in the initial while loop as a \nregister as below we noticed that TET remained the same \n(1.8125 seconds). This means that the compiler has already \nrecognized the counter and put it in a register [12]. \nHowever, not all compilers do this automatically and \nindicating this requirement to the compiler should be \nconsidered as good practice. \n \nregister long int i = 100000000; \nwhile( --i >= 0) { } \n \n4) Use dependency chains rather than single data \ndependencies in loops \nA data dependency is a process or an operation dependent \nfor its completion on the value of previous process or \noperation [7]. If such an entity exists in the body of a loop \nthe processor may waist time waiting this dependency to \ncomplete. When we considered the following code snippet \nwe found that it took 35.875 seconds to terminate after \nsubtracting the TET. \n \nint a[20];  \/\/ has some values \nint sum = 0; \n \nfor( int i = 19; i >= 0; --i ) \n{ \n   sum += a[i]; \n} \n \nHowever, if this single data dependency is broken into, \nsay 4, to form a dependency chain as in the code below the \nnumber of times the loop has to execute is reduced and \nhence the execution time will shrink to 8.625 seconds, \nalmost a quarter of initial time. \n \nfor( int i = 19; i >= 0; i -= 4  ) \n{ \n   sum += a[i]; \n   sum += a[i - 1]; \n   sum += a[i - 2]; \n   sum += a[i - 3]; \n} \n \nThe reason behind this improvement is related to the \nparallelism introduced by the dependency chain. It keeps the \nexecution pipeline full instead of being idle until the loop \nfinishes [2]. \nSimilar to the case in loop unrolling, it is vital to make \nsure that the number of dependencies does not exceed the \nnumber of registers available in the targeted architecture. If \nthat is not respected the execution will be slower due to \ncontinuous memory access. \n5) When to \u201cswitch\u201d and when to \u201cif-else\u201d \nA switch structure in general is cheaper execution-wise \nthan if-else chains. However, there are cases where a switch \ncan perform as bad as if-else. If the case expressions in a \nswitch statement are contiguous or nearly contiguous then \nthe compiler translates them into a jump table instead of a \ncomparison chain. A jump table improves performance \nbecause it reduces the number of branches to a single \nprocedure call and shrinks the size of the control-flow code \nno matter how many cases there are. It will enable the \nAuthorized licensed use limited to: Lancaster University Library. Downloaded on January 7, 2009 at 04:06 from IEEE Xplore.  Restrictions apply.\n 1-4244-0216-6\/06\/$20.00 \u00a92006 IEEE \nprocessor to perform successful branch prediction which will \nreduce the jumping time and improve performance. On the \nother hand, if the cases are not contiguous the compiler will \nspend time converting them into a comparison chain like if-\nelse statements and this uses dense sequential conditional \nbranching [7]. \nMobot proves this performance issue by testing first a \ncontiguous switch statement. The statement below requires \n1.8125 seconds to complete, the same time as TET.  \n \nswitch( cond ) \n{ \n   case \u2018A\u2019: \/*something*\/ break; \n   case \u2018B\u2019: \/*something*\/ break; \n   case \u2018C\u2019: \/*something*\/ break; \n   case \u2018D\u2019: \/*something*\/ break; \n   case \u2018E\u2019: \/*something*\/ break; \n} \n \nThe noncontiguous version below consumes surprisingly \n3.171875 seconds, almost the double. \n \nswitch( cond ) \n{ \n   case \u2018A\u2019: \/*something*\/ break; \n   case \u2018R\u2019: \/*something*\/ break; \n   case \u20181\u2019: \/*something*\/ break; \n   case \u2018%\u2019: \/*something*\/ break; \n   case \u2018*\u2019: \/*something*\/ break; \n} \n \nIn the case of using if-else, no difference is noticed \nwhether the conditional statements are contiguous or not. \nThe time consumed in both cases is 5.9375 seconds. Once \nthe compiler reaches an if-else block it directly creates a \ncomparison chain causing a branching overhead.  \n6) Arrange if-else statements or switch cases with the \nmost common appearing on top \nBy doing this the processor will save some cycles by \nminimizing jumping through all cases until it finds its target. \nPutting expected cases on top will make them faster to find \nand will reduce the time wasted by the processor checking \nand branching.  \nIf the rearrangement of the cases in a switch statement \nbreaks their continuality it is preferable to convert it into its \nif-else equivalent as the compiler is likely to do this anyway \n[4]. The programmer has to analyze situations where one \noptimization may break another and define his performance \npreference.  \n7) Inline small functions \nWhen the compiler reaches a function that is defined with \nthe inline keyword it will expand its body, in the line it is \ncalled from, as long as it is short and compact. inlining \nworks similar to C++ #define macros but it is type-safe \nand subject to further compiler optimizations [6]. \nExpanding a function will prevent the program from \nfunction-call overheads and jumping at the assembly level. \nHowever, excessive inlining may blow out the size of the \ncode and reduce performance due to the increased likelihood \nof instruction cache misses [10]. If inlining is to be used \nonly small functions with few operations should be \nconsidered.  \nIf the function being inlined is a local function then the \ninline keyword is simply added to the beginning of its \ndefinition. If it is a member function of a class then a \ndifferent approach is followed. In the object-oriented \nbehavior of C++, programmers usually split their class \ndefinitions into two files with .h and .cpp extensions. Most \ncompilers optimize code in a single module at a time. That \nmeans optimization will take place in the .h file then will \ncarry on to the .cpp file and so forth. If a function is defined \nin the header file (.h) as an inline function, the inlining \nwill occur only in that file. It will not be carried forward to \nits actual implementation in .cpp. The solution for this is to \ncode the implementation of the inlined function within the \nsame module, in this case within the header file. Although \nthis does not follow the concept of information hiding that \nobject orientation provides, it is the only way to make use of \ninlining to boost execution speed. \nTo show how inlining improves performance we need \nto examine how long calling a local function and a member \nfunction takes. From Mobot we inferred that function \nLocalFunc uses 2.71875 seconds of processing time while \nmember function MemberFunc takes 3.1875 seconds.  \n \n\/\/ Local Function \nvoid LocalFunc() {} \n \n\/\/ Member Function \nvoid CMobot::MemberFunc() {} \n \nWhen inlining both functions the execution drops to \n1.8125 seconds as if we had not called the function at all. \nNote here that if we added the inline keyword to \nMemberFunc\u2018s definition in CMobot.cpp the execution \ntime will remain 3.1875 seconds. But if we moved its \ndefinition and inlined it in CMobot.h we will get the \noptimized result. \nIt is worth noting that in addition to its large size an \ninlined function is ignored by the compiler if it contains a \nloop, recursion or calls another inlined function [6]. \n8) Declare functions as static \nAlways declare local and member functions that are not to \nbe used outside the file they are defined in as static. This will \ndeactivate the default external linkage which slows their \nexecution and forces internal linkage which will make \nfunctions invisible outside their scope. Redefining \nLocalFunc and MemberFunc as static shows that execution \ntime was reduced to 2.56725 and 2.75 respectively. \n9) Declare local variables as static \nIt is preferable to declare local variables in routines that \nare called frequently as static. This will save the compiler \nfrom declaring and initializing them every time the function \nexecutes. It will help avoiding memory fragmentation as \nwell. However, this practice can be considered bad in \nsituations like multi-threaded function calls since it violates \ncode separablility [10]. \nAuthorized licensed use limited to: Lancaster University Library. Downloaded on January 7, 2009 at 04:06 from IEEE Xplore.  Restrictions apply.\n 1-4244-0216-6\/06\/$20.00 \u00a92006 IEEE \nIV. PERFORMANCE ANALYSIS \nFrom the results given previously we can consider \nperformance improvement introduced by each specific \ntechnique as shown in the following figure. \n \nPerformance Analysis\n0 2 4 6 8\nSeconds\nStatic Member\/Local Func\nInline Member\/Local Func\nMemebr Function Call\nLocal Function Call\nNon-\/contiguou if -else\nNon-contiguou sw itch\nContiguous Sw itch\nMultiple Loop dependency\nSingle Loop Dependency\nPost Increment\/decrement\nPre Increment\/decrement\nLoop Rolled\nLoop Unrolling\nIncrementing\nDecrementing\n \nFig. 1: Optimized paradigms performance analysis \n \nOptimization might be focused on program execution \nspeed, power consumption bus bandwidth and\/or memory \nusage. These entities are not independent where one \noptimization might defect another in some way. Even if all \noptimization techniques have been used there is no \nguarantee that a program will be more efficient. Therefore, \nprogrammers have to concentrate their optimization on \noperations that are directly related to the core of their \napplications and which are called regularly and expected to \nintroduce significant improvement to performance. \nFunction-calls are of the mostly executed operations \nconstituting 50 to 80 percent of source code [10]. Hence it is \nconvenient to start optimizing the operations within these \nfunctions to prosper the deemed performance.   \nV. CONCLUSION \nProgrammers have to know the limitations of the mobile \nplatform architecture they are targeting. They have even to \nknow their tools and the facilities they provide. Only then \nprogrammers will be able to identify critical issues and \nperform best practice. \nREFERENCES \n[1] Chehimi F., Coulton P., Edwards R., \u201cEvolution of 3-D \ngames on mobile phones\u201d, proceedings of the IEEE Fourth \nInternational Conference on Mobile Business, Sydney, \nAustralia, 11-13 July 2005 \n[2] Hanson J., \u201cAccelerating compute intensive functions using \nC\u201d, Dr. Dobb\u2019s Journals, April 2006.   \n[3] Mack B., Govani P., \u201cDirect memory access: meeting system \nthroughput demands\u201d, C\/C++ Ussr January 2005. \n[4] Winter A., \u201cC++ Optimization\u201d, http:\/\/www.custard.org\/ \n~andrew\/programming\/optimize\/, last accessed April 1, 2006.  \n[5] Harrison R., Symbian OS C++ for mobile phones, John Wiley \nand Sons Ltd, 2003, pp.76 \n[6] Timmermans J., \u201cPerformance programming applied to C++\u201d, \nGameDev, July 29, 2000, www.gamedev.net, last accessed \nApril 4, 2006. \n[7] Zeicheck A., \u201cOptimizing you C\/C++ applications part I, II\u201d,  \nwww.devx.com, last accessed March 29, 2006.   \n[8] Kalev D., \u201cThe top 20 C++ tips of all time\u201d, www.devx.com, \nlast accessed October 31, 2005. \n[9] Gooliffe P., \u201cRegister access in C++\u201d, C\/C++ User Journal, \nMay 2005. \n[10] Fomitchev M., \u201cWinning the passing game\u201d, Dr. Dobbs \nJournals, Optimize to the max column, last accessed \nSeptember 14, 2005.  \n[11] ARM, Technical support, http:\/\/www.arm.com, last accessed \nApril 2, 2006. \n[12] Koeing A., Moo E. B., \u201cMeasuring inline functions\u201d, C\/C++ \nUser Journals, June, 2004. \n[13]  \n \nFadi Chehimi has received his BS. degree in Computer \nScience from the Department of Computer Science at the \nAmerican University of Beirut, Lebanon, and his MS. \ndegree in Media Production and Distribution from the \nDepartment of Communication Systems (DCS) at \nLancaster University, UK. He is currently working \ntowards a PhD degree at DCS and his research interests \ninclude 3D graphics for mobnile phones, mobile advertising and mobile \napplication optimizations.   \n \nDr. Paul Coulton, (BSc, PhD, MIEEE, IGDA) is a \nSenior Lecturer in Mobile Systems and Applications and \nwas one of fifty developers worldwide, selected from a \ncommunity of 2 million, to be a Forum Nokia \nChampions. He has over 10 years' research and \ndevelopment experience in mobile and has published \nextensively in this area, both in terms of academic publications, and a \nforthcoming book on S60 programming. The main focus of his current \nresearch surrounds innovative m-commerce solutions with a particular \nemphasis on mobile entertainment, such as games. \n \nDr. Reuben Edwards (BEng, PhD, MIEE, MIEEE) has \nbeen a member of Lancaster University since 1991, \ngraduating with a Bachelors degree in Electronic \nEngineering and a PhD in Communication Systems.  \nReuben is currently the University Dean at Lancaster \nUniversity, a lecturer in Communication Systems and \nChair of the Lancaster University Alumni Association. \nIn his spare time Reuben is an Executive Director of mobile software \ncompany m-ventions Ltd. \n \n(Every 100000000 times) \nAuthorized licensed use limited to: Lancaster University Library. Downloaded on January 7, 2009 at 04:06 from IEEE Xplore.  Restrictions apply.\n"}
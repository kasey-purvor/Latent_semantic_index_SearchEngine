{"doi":"10.1007\/s11222-007-9045-8","coreId":"71003","oai":"oai:eprints.lancs.ac.uk:8331","identifiers":["oai:eprints.lancs.ac.uk:8331","10.1007\/s11222-007-9045-8"],"title":"Computational Methods for Complex Stochastic Systems: A Review of Some Alternatives to MCMC.","authors":["Fearnhead, Paul"],"enrichments":{"references":[{"id":16372370,"title":"A Bayesian analysis of some nonparametric problems.","authors":[],"date":"1973","doi":"10.1214\/aos\/1176342360","raw":"Ferguson, T. S. (1973). A Bayesian analysis of some nonparametric problems. Annals of Statistics, 1:209\u2013230.","cites":null},{"id":16372366,"title":"A Hidden Markov Model approach to variation among sites in rate of evolution. Molecular Biology and Evolution,","authors":[],"date":"1996","doi":"10.1093\/oxfordjournals.molbev.a025575","raw":"Felsenstein, J. and Churchill, G. A. (1996). A Hidden Markov Model approach to variation among sites in rate of evolution. Molecular Biology and Evolution, 13:93\u2013104.","cites":null},{"id":16372461,"title":"A new approach to maximum likelihood estimation of stochastic di\ufb00erential equations based on discrete observations.","authors":[],"date":"1995","doi":null,"raw":"Pedersen, A. R. (1995). A new approach to maximum likelihood estimation of stochastic di\ufb00erential equations based on discrete observations. Scandinavian Journal of Statistics, 22:55\u201371.","cites":null},{"id":16372436,"title":"A randomized quasi-Monte carlo simulation method for Markov chains.","authors":[],"date":"2007","doi":"10.1287\/opre.1080.0556","raw":"L\u2019Ecuyer, P., L\u00b4 ecot, C., and Tu\ufb03n, B. (2007). A randomized quasi-Monte carlo simulation method for Markov chains. To appear in Operations Research.","cites":null},{"id":16372476,"title":"A sequential Monte Carlo method for Bayesian analysis of massive datasets. Data Mining and Knowledge Discovery,","authors":[],"date":"2003","doi":"10.1145\/775047.775049","raw":"Ridgeway, G. and Madigan, D. (2003). A sequential Monte Carlo method for Bayesian analysis of massive datasets. Data Mining and Knowledge Discovery, 7:301\u2013319.","cites":null},{"id":16372472,"title":"An introduction to hidden Markov models.","authors":[],"date":"1986","doi":"10.1109\/massp.1986.1165342","raw":"Rabiner, L. R. and Juang, B. H. (1986). An introduction to hidden Markov models. IEEE ASSP Magazine, pages 4\u201315.","cites":null},{"id":16372350,"title":"Approximate likelihood methods for estimating local recombination rates (with discussion).","authors":[],"date":"2002","doi":"10.1111\/1467-9868.00355","raw":"Fearnhead, P. and Donnelly, P. (2002). Approximate likelihood methods for estimating local recombination rates (with discussion). Journal of the Royal Statistical Society, series B, 64:657\u2013680.","cites":null},{"id":16372458,"title":"Assessing population di\ufb00erentiation and isolation from single-nucleotide polymorphism data.","authors":[],"date":"2002","doi":null,"raw":"Nicholson, G., Smith, A. V., J\u00b4 onsson, F., G\u00b4 ustafsson, O., Stef\u00b4 ansson, K., and Donnelly, P. (2002). Assessing population di\ufb00erentiation and isolation from single-nucleotide polymorphism data. Journal of the Royal Statistical Society Series B, 64:695\u2013715.","cites":null},{"id":16372469,"title":"Association mapping in structured populations.","authors":[],"date":"2000","doi":"10.1086\/302959","raw":"Pritchard, J. K., Stephens, M., Rosenberg, N. A., and Donnelly, P. (2000b). Association mapping in structured populations. American Journal of Human Genetics, 67:170\u2013181.","cites":null},{"id":16372495,"title":"Asymptotics of an e\ufb03cient Monte Carlo estimation for the transition density of di\ufb00usion processes.","authors":[],"date":"2007","doi":"10.1007\/s11009-006-9006-2","raw":"Stramer, O. and Yan, J. (2007). Asymptotics of an e\ufb03cient Monte Carlo estimation for the transition density of di\ufb00usion processes. To appear in Methodology and Computing in Applied Probability.","cites":null},{"id":16372485,"title":"Bayesian analysis of a two state Markov modulated Poisson process.","authors":[],"date":"1999","doi":"10.2307\/1390883","raw":"Scott, S. L. (1999). Bayesian analysis of a two state Markov modulated Poisson process. Journal of Computational and Graphical Statistics, 8:662\u2013670.","cites":null},{"id":16372363,"title":"Bayesian analysis of isochores.","authors":[],"date":"2007","doi":"10.1198\/jasa.2009.0009","raw":"Fearnhead, P. and Vasileiou, D. (2007). Bayesian analysis of isochores. Submitted. available from www.maths.lancs.ac.uk\/\u223cfearnhea\/publications.","cites":null},{"id":16372361,"title":"Bayesian analysis of Markov modulated Poisson processes.","authors":[],"date":"2006","doi":"10.1111\/j.1467-9868.2006.00566.x","raw":"Fearnhead, P. and Sherlock, C. (2006). Bayesian analysis of Markov modulated Poisson processes. Journal of the Royal Statistical Society, Series B, 68:767\u2013784.","cites":null},{"id":16372497,"title":"Bayesian forecasting and dynamic models.","authors":[],"date":"1989","doi":"10.1007\/978-1-4757-9365-9","raw":"West, M. and Harrison, J. (1989). Bayesian forecasting and dynamic models. Springer-Verlag, New York.","cites":null},{"id":16372383,"title":"Bayesian inference for stochastic kinetic models using a di\ufb00usion approximation.","authors":[],"date":"2005","doi":"10.1111\/j.1541-0420.2005.00345.x","raw":"Golightly, A. and Wilkinson, D. J. (2005). Bayesian inference for stochastic kinetic models using a di\ufb00usion approximation. Biometrics, 61:781\u2013788.","cites":null},{"id":16372448,"title":"Bayesian inference on biopolymer models.","authors":[],"date":"1999","doi":"10.1093\/bioinformatics\/15.1.38","raw":"Liu, J. S. and Lawrence, C. E. (1999). Bayesian inference on biopolymer models. Bioinformatics, 15:38\u201352.","cites":null},{"id":16372487,"title":"Bayesian methods for hidden Markov models: Recursive computing in the 21st century.","authors":[],"date":"2002","doi":"10.1198\/016214502753479464","raw":"Scott, S. L. (2002). Bayesian methods for hidden Markov models: Recursive computing in the 21st century. Journal of the American Statistical Association, 97:337\u2013351.","cites":null},{"id":16372388,"title":"Bayesian sequential inference for stochastic kinetic biochemical network models.","authors":[],"date":"2006","doi":"10.1089\/cmb.2006.13.838","raw":"Golightly, A. and Wilkinson, D. J. (2006). Bayesian sequential inference for stochastic kinetic biochemical network models. Journal of Computational Biology, 13:838\u2013851.","cites":null},{"id":16372316,"title":"Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids.","authors":[],"date":"1998","doi":"10.1017\/cbo9780511790492","raw":"Durbin, R., Eddy, S., Krogh, A., and Mitchison, G. (1998). Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids. Cambridge University Press.","cites":null},{"id":16372442,"title":"Blind deconvolution via sequential imputations.","authors":[],"date":"1995","doi":"10.2307\/2291068","raw":"Liu, J. S. and Chen, R. (1995). Blind deconvolution via sequential imputations. Journal of the American Statistical Association, 90:567\u2013576.","cites":null},{"id":16372503,"title":"Calibrating the rate of evolution of campylobacter.","authors":[],"date":"2007","doi":null,"raw":"Wilson, D. J. and Fearnhead, P. (2007). Calibrating the rate of evolution of campylobacter. In preparation.","cites":null},{"id":16372496,"title":"Coalescent Theory: An Introduction. Roberts and Company,","authors":[],"date":"2007","doi":"10.1086\/648146","raw":"Wakeley, J. (2007). Coalescent Theory: An Introduction. Roberts and Company, Denver, Colorado, USA.","cites":null},{"id":16372438,"title":"Combined parameter and state estimation in simulation based \ufb01ltering.","authors":[],"date":"2001","doi":"10.1007\/978-1-4757-3437-9_10","raw":"Liu, J. and West, M. (2001). Combined parameter and state estimation in simulation based \ufb01ltering. In Doucet, A., de Freitas, J. F. G., and Gordon, N. J., editors, Sequential Monte Carlo in Practice, pages 197\u2013223, New York. Springer-Verlag.","cites":null},{"id":16372434,"title":"Construction of multilocus genetic linkage maps in humans.","authors":[],"date":"1987","doi":"10.1073\/pnas.84.8.2363","raw":"Lander, E. S. and Green, P. (1987). Construction of multilocus genetic linkage maps in humans.","cites":null},{"id":16372454,"title":"Equations of state calculations by fast computing machines.","authors":[],"date":null,"doi":"10.1007\/978-3-662-10421-7_18","raw":"Equations of state calculations by fast computing machines. The Journal of Chemical Physics, 21:1087\u20131091.","cites":null},{"id":16372428,"title":"Equi-energy sampler with applications in statistical inference and statistical mechanics.","authors":[],"date":"2006","doi":"10.1214\/009053606000000515","raw":"30Kou, S. C., Zhou, Q., and Wong, W. H. (2006). Equi-energy sampler with applications in statistical inference and statistical mechanics. Annals of Statistics, 34:1581\u20131619.","cites":null},{"id":16372347,"title":"Estimating recombination rates from population genetic data.","authors":[],"date":"2001","doi":null,"raw":"Fearnhead, P. and Donnelly, P. (2001). Estimating recombination rates from population genetic data. Genetics, 159:1299\u20131318.","cites":null},{"id":16372506,"title":"Estimation of a noisy discrete-time step function: Bayes and empirical Bayes approaches. The Annals of Statistics,","authors":[],"date":"1984","doi":"10.1214\/aos\/1176346802","raw":"Yao, Y. (1984). Estimation of a noisy discrete-time step function: Bayes and empirical Bayes approaches. The Annals of Statistics, 12:1434\u20131447.","cites":null},{"id":16372341,"title":"Exact and e\ufb03cient inference for multiple changepoint problems.","authors":[],"date":"2006","doi":"10.1007\/s11222-006-8450-8","raw":"Fearnhead, P. (2006). Exact and e\ufb03cient inference for multiple changepoint problems. Statistics and Computing, 16:203\u2013213.","cites":null},{"id":16372336,"title":"Exact Bayesian curve \ufb01tting and signal segmentation.","authors":[],"date":"2005","doi":"10.1109\/tsp.2005.847844","raw":"Fearnhead, P. (2005a). Exact Bayesian curve \ufb01tting and signal segmentation. IEEE Transactions on Signal Processing, 53:2160\u20132166.","cites":null},{"id":16372356,"title":"Exact \ufb01ltering for partially-observed continuoustime Markov models.","authors":[],"date":"2004","doi":"10.1111\/j.1467-9868.2004.05561.x","raw":"Fearnhead, P. and Meligkotsidou, L. (2004). Exact \ufb01ltering for partially-observed continuoustime Markov models. Journal of the Royal Statistical Society, series B, 66:771\u2013789.","cites":null},{"id":16372430,"title":"Factor graphs and the sum-product algorithm.","authors":[],"date":"2001","doi":"10.1109\/18.910572","raw":"Kschischang, F. R., Frey, B. J., and Loeliger, H. (2001). Factor graphs and the sum-product algorithm. IEEE transactions on Information Theory, 47.","cites":null},{"id":16372465,"title":"Filtering via simulation: auxiliary particle \ufb01lters.","authors":[],"date":"1999","doi":"10.2307\/2670179","raw":"Pitt, M. K. and Shephard, N. (1999). Filtering via simulation: auxiliary particle \ufb01lters. Journal of the American Statistical Association, 94:590\u2013599.","cites":null},{"id":16372377,"title":"Following a moving target - Monte Carlo inference for dynamic Bayesian models.","authors":[],"date":"2001","doi":"10.1111\/1467-9868.00280","raw":"Gilks, W. R. and Berzuini, C. (2001). Following a moving target - Monte Carlo inference for dynamic Bayesian models. Journal of the Royal Statistical Society, Series B, 63:127\u2013146.","cites":null},{"id":16372483,"title":"Genetic structure of human populations.","authors":[],"date":"2002","doi":null,"raw":"Rosenberg, N. A., Pritchard, J. K., Weber, J. L., Cann, H. M., Kidd, K. K., Zhivotovsky, L. A., and Feldman, M. W. (2002). Genetic structure of human populations. Science, 298:2381\u2013 2385.","cites":null},{"id":16372411,"title":"Hidden Markov models for speech recognition.","authors":[],"date":"1991","doi":"10.2307\/1268779","raw":"Juang, B. H. and Rabiner, L. R. (1991). Hidden Markov models for speech recognition. Technometrics, 33:251\u2013272.","cites":null},{"id":16372492,"title":"Inference in molecular population genetics (with discussion).","authors":[],"date":"2000","doi":"10.1111\/1467-9868.00254","raw":"Stephens, M. and Donnelly, P. (2000). Inference in molecular population genetics (with discussion). Journal of the Royal Statistical Society, Series B, 62:605\u2013655.","cites":null},{"id":16372321,"title":"Inference of population structure using multilocus genotype data: Linked loci and correlated allele frequencies.","authors":[],"date":"2003","doi":"10.3410\/f.1015548.197423","raw":"28Falush, D., Stephens, M., and Pritchard, J. K. (2003). Inference of population structure using multilocus genotype data: Linked loci and correlated allele frequencies. Genetics, 164:1567\u2013 1587.","cites":null},{"id":16372467,"title":"Inference of population structure using multilocus genotype data.","authors":[],"date":"2000","doi":"10.1111\/j.1471-8286.2007.01758.x","raw":"Pritchard, J. K., Stephens, M., and Donnelly, P. (2000a). Inference of population structure using multilocus genotype data. Genetics, 155:945\u2013959.","cites":null},{"id":16372474,"title":"Joint Bayesian estimation of alignment and phylogeny. Systematic Biology,","authors":[],"date":"2005","doi":"10.1080\/10635150590947041","raw":"Redelings, B. D. and Suchard, M. A. (2005). Joint Bayesian estimation of alignment and phylogeny. Systematic Biology, 54:401\u2013418.","cites":null},{"id":16372373,"title":"Markov Chain Monte Carlo: Stochastic Simulation For Bayesian Inference.","authors":[],"date":"2006","doi":"10.1198\/tech.2008.s542","raw":"29Gamerman, D. (2006). Markov Chain Monte Carlo: Stochastic Simulation For Bayesian Inference. Taylor and Francis Ltd, UK.","cites":null},{"id":16372456,"title":"Markov chain sampling for non-linear state space models using embedded hidden Markov models. Available from http:\/\/www.cs.toronto.edu\/\u223cradford\/embhmm.abstract.html.","authors":[],"date":"2003","doi":null,"raw":"Neal, R. M. (2003). Markov chain sampling for non-linear state space models using embedded hidden Markov models. Available from http:\/\/www.cs.toronto.edu\/\u223cradford\/embhmm.abstract.html.","cites":null},{"id":16372330,"title":"MCMC, su\ufb03cient statistics and particle \ufb01lters.","authors":[],"date":"2002","doi":"10.1198\/106186002321018821","raw":"Fearnhead, P. (2002b). MCMC, su\ufb03cient statistics and particle \ufb01lters. Journal of Computational and Graphical Statistics, 11:848\u2013862.","cites":null},{"id":16372440,"title":"Metropolised independent sampling with comparisons to rejection sampling and importance sampling.","authors":[],"date":"1996","doi":"10.1007\/bf00162521","raw":"Liu, J. S. (1996). Metropolised independent sampling with comparisons to rejection sampling and importance sampling. Statistics and Computing, 6:113\u2013119.","cites":null},{"id":16372325,"title":"Mismatch induced speciation in Salmonella: model and data.","authors":[],"date":null,"doi":"10.1098\/rstb.2006.1925","raw":"Mismatch induced speciation in Salmonella: model and data. Philosophical Transactions of the Royal Society of London, series B, 361:2045\u20132053.","cites":null},{"id":16372400,"title":"Monte Carlo approximations for general state-space models.","authors":[],"date":"1998","doi":"10.2307\/1390812","raw":"Hurzeler, M. and Kunsch, H. R. (1998). Monte Carlo approximations for general state-space models. Journal of Computational and Graphical Statistics, 7:175\u2013193.","cites":null},{"id":16372423,"title":"Monte Carlo \ufb01lter and smoother for non-Gaussian nonlinear state space models.","authors":[],"date":"1996","doi":"10.2307\/1390750","raw":"Kitagawa, G. (1996). Monte Carlo \ufb01lter and smoother for non-Gaussian nonlinear state space models. Journal of Computational and Graphical Statistics, 5:1\u201325.","cites":null},{"id":16372432,"title":"Monte Carlo \ufb01lters:Algorithms and theoretical analysis.","authors":[],"date":"2005","doi":"10.1214\/009053605000000426","raw":"K\u00a8 unsch, H. R. (2005). Monte Carlo \ufb01lters:Algorithms and theoretical analysis. Annals of Statistics, 33:1983\u20132021.","cites":null},{"id":16372380,"title":"Monte Carlo smoothing for non-linear time series.","authors":[],"date":"2004","doi":"10.1198\/016214504000000151","raw":"Godsill, S. J., Doucet, A., and West, M. (2004). Monte Carlo smoothing for non-linear time series. Journal of the American Statistical Association, 99:156\u2013168.","cites":null},{"id":16372450,"title":"Multilocus sequence typing: A portable approach to the identi\ufb01cation of clones within populations of pathogenic microorganisms.","authors":[],"date":"1998","doi":"10.1073\/pnas.95.6.3140","raw":"Maiden, M. C. J., Bygraves, J. A., Feil, E., Morelli, G., Russell, J. E., Urwin, R., Zhang, Q., Zhou, J., Zurth, K., Caugant, D. A., Feavers, I. M., Achtman, M., and Spratt, B. G. (1998). Multilocus sequence typing: A portable approach to the identi\ufb01cation of clones within populations of pathogenic microorganisms. Proceedings of the National Acadamey of Science, USA, 95:3140\u20133145.","cites":null},{"id":16372415,"title":"New results in linear \ufb01ltering and prediction theory.","authors":[],"date":"1961","doi":"10.1115\/1.3658902","raw":"Kalman, R. and Bucy, R. (1961). New results in linear \ufb01ltering and prediction theory. Journal of Basic Engineering, Transacation ASME series D, 83:95\u2013108.","cites":null},{"id":16372459,"title":"Non-centred parameterisations for hierarchical models and data augmentation (with discussion).","authors":[],"date":"2003","doi":null,"raw":"31Papaspilopoulos, O., Roberts, G. O., and Sk\u00a8 old, M. (2003). Non-centred parameterisations for hierarchical models and data augmentation (with discussion). In Bernardo, J. M., Bayarri, M. J., Berger, J. O., Dawid, A. P., Heckerman, D., Smith, A. F. M., and West, M., editors, Bayesian statistics 7, London. Clarendon Press.","cites":null},{"id":16372392,"title":"Novel approach to nonlinear\/nonGaussian Bayesian state estimation.","authors":[],"date":"1993","doi":"10.1049\/ip-f-2.1993.0015","raw":"Gordon, N., Salmond, D., and Smith, A. F. M. (1993). Novel approach to nonlinear\/nonGaussian Bayesian state estimation. IEE proceedings-F, 140:107\u2013113.","cites":null},{"id":16372425,"title":"Numerical solution of stochastic di\ufb00erential equations.","authors":[],"date":"1992","doi":"10.1007\/978-3-662-12616-5","raw":"Kloeden, P. E. and Platen, E. (1992). Numerical solution of stochastic di\ufb00erential equations. Springer, New York.","cites":null},{"id":16372318,"title":"Numerical techniques for maximum likelihood estimation of continuous-time di\ufb00usion processes.","authors":[],"date":"2002","doi":"10.1198\/073500102288618397","raw":"Durham, G. B. and Gallant, A. R. (2002). Numerical techniques for maximum likelihood estimation of continuous-time di\ufb00usion processes. Journal of Business and Economic Statistics, 20:297\u2013338.","cites":null},{"id":16372480,"title":"On inference for partially observed nonlinear di\ufb00usion models using the Metropolis-Hastings algorithm.","authors":[],"date":"2001","doi":"10.1093\/biomet\/88.3.603","raw":"Roberts, G. O. and Stramer, O. (2001). On inference for partially observed nonlinear di\ufb00usion models using the Metropolis-Hastings algorithm. Biometrika, 88:603\u2013621.","cites":null},{"id":16372403,"title":"On population-based simulation for statics inference. Statistics and Computing,","authors":[],"date":"2007","doi":"10.1007\/s11222-007-9028-9","raw":"Jasra, A., Stephens, D. A., and Holmes, C. (2007). On population-based simulation for statics inference. Statistics and Computing, page To appear.","cites":null},{"id":16372489,"title":"On population-based simulation for statistical inference. Statistics and Computing.","authors":[],"date":"2007","doi":"10.1007\/s11222-007-9028-9","raw":"Stephens, D., Jasra, A., and Holmes, C. (2007). On population-based simulation for statistical inference. Statistics and Computing. To appear.","cites":null},{"id":16372494,"title":"On simulated likelihood of discretely observed di\ufb00usion processes and comparison to closed form approximation.","authors":[],"date":"2007","doi":"10.1198\/106186007x237306","raw":"Stramer, O. (2007). On simulated likelihood of discretely observed di\ufb00usion processes and comparison to closed form approximation. To appear in Journal of Computational and Graphical Statistics.","cites":null},{"id":16372345,"title":"Online inference for hidden Markov models.","authors":[],"date":"2003","doi":"10.1111\/1467-9868.00421","raw":"Fearnhead, P. and Cli\ufb00ord, P. (2003). Online inference for hidden Markov models. Journal of the Royal Statistical Society, Series B, 65:887\u2013899.","cites":null},{"id":16372352,"title":"Online inference for multiple changepoint problems.","authors":[],"date":"2007","doi":"10.1109\/nsspw.2006.4378807","raw":"Fearnhead, P. and Liu, Z. (2007). Online inference for multiple changepoint problems. To appear in Journal of the Royal Statistical Society Series B.","cites":null},{"id":16372408,"title":"Origins and a\ufb03nities of modern humans: a comparison of mitochondrial and nuclear genetic data.","authors":[],"date":"1995","doi":null,"raw":"Jorde, L. B., Bamshad, M. J., Watkins, W. S., Zenger, R., Fraley, A. E., Krakowiak, P. A., Carpenter, K. D., Soodyall, H., Jenkins, T., and Rogers, A. R. (1995). Origins and a\ufb03nities of modern humans: a comparison of mitochondrial and nuclear genetic data. American Journal of Human Genetics, 57:523\u2013538.","cites":null},{"id":16372333,"title":"Particle \ufb01lters for mixture models with an unknown number of components.","authors":[],"date":"2004","doi":"10.1023\/b:stco.0000009418.04621.cd","raw":"Fearnhead, P. (2004). Particle \ufb01lters for mixture models with an unknown number of components. Statistics and Computing, 14:11\u201321.","cites":null},{"id":16372358,"title":"Particle \ufb01lters for partiallyobserved di\ufb00usions.","authors":[],"date":"2007","doi":"10.1111\/j.1467-9868.2008.00661.x","raw":"Fearnhead, P., Papaspiliopoulos, O., and Roberts, G. O. (2007). Particle \ufb01lters for partiallyobserved di\ufb00usions. Submitted to Journal of the Royal Statistical Society Series B.","cites":null},{"id":16372493,"title":"Particle \ufb01lters for state-space models with the presence of unknown static parameters.","authors":[],"date":"2002","doi":"10.1109\/78.978383","raw":"Storvik, G. (2002). Particle \ufb01lters for state-space models with the presence of unknown static parameters. IEEE Transaction on Signal Processing, 50:281\u2013289.","cites":null},{"id":16372490,"title":"Problems with computational methods in population genetics. Contribution to the 52nd session of the International Statistical Institute.","authors":[],"date":"1999","doi":null,"raw":"Stephens, M. (1999). Problems with computational methods in population genetics. Contribution to the 52nd session of the International Statistical Institute.","cites":null},{"id":16372446,"title":"Rejection control and sequential importance sampling.","authors":[],"date":"1998","doi":"10.2307\/2669846","raw":"Liu, J. S., Chen, R., and Wong, W. H. (1998). Rejection control and sequential importance sampling. Journal of the American Statistical Society, 93:1022\u20131031.","cites":null},{"id":16372394,"title":"Reversible jump Markov chain Monte Carlo computation and Bayesian model determination.","authors":[],"date":"1995","doi":"10.2307\/2337340","raw":"Green, P. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian model determination. Biometrika, 82:711\u2013732.","cites":null},{"id":16372427,"title":"Sequential imputations and Bayesian missing data problems.","authors":[],"date":"1994","doi":"10.2307\/2291224","raw":"Kong, A., Liu, J. S., and Wong, W. H. (1994). Sequential imputations and Bayesian missing data problems. Journal of the American Statistical Association, 89:278\u2013288.","cites":null},{"id":16372444,"title":"Sequential Monte Carlo methods for dynamic systems.","authors":[],"date":"1998","doi":"10.2307\/2669847","raw":"Liu, J. S. and Chen, R. (1998). Sequential Monte Carlo methods for dynamic systems. Journal of the American Statistical Association., 93:1032\u20131044.","cites":null},{"id":16372452,"title":"Simulating ratios of normalizing constants via a simple identity: a theoretical exploration. Statistica Sinica,","authors":[],"date":"1996","doi":null,"raw":"Meng, X. and Wong, W. H. (1996). Simulating ratios of normalizing constants via a simple identity: a theoretical exploration. Statistica Sinica, 6:831\u2013860.","cites":null},{"id":16372463,"title":"Smooth particle \ufb01lters for likelihood evaluation and maximisation.","authors":[],"date":"2007","doi":"10.1016\/j.jeconom.2011.07.006","raw":"Pitt, M. (2007). Smooth particle \ufb01lters for likelihood evaluation and maximisation. Submitted. Available from http:\/\/www2.warwick.ac.uk\/fac\/soc\/economics\/staff\/faculty\/pitt\/publications\/.","cites":null},{"id":16372501,"title":"Stochastic Modelling for Systems Biology.","authors":[],"date":"2006","doi":"10.1093\/imammb\/dql028","raw":"Wilkinson, D. J. (2006). Stochastic Modelling for Systems Biology. Chapman and Hall\/CRC Press, Boca Raton, Florida.","cites":null},{"id":16372478,"title":"Stochastic Simulation.","authors":[],"date":"1987","doi":"10.1002\/9780470316726","raw":"Ripley, B. D. (1987). Stochastic Simulation. New York: Wiley and Sons.","cites":null},{"id":16372421,"title":"The coalescent. Stochastic Processes and their Applications,","authors":[],"date":"1982","doi":"10.1016\/0304-4149(82)90011-4","raw":"Kingman, J. F. C. (1982). The coalescent. Stochastic Processes and their Applications, 13:235\u2013 248.","cites":null},{"id":16372327,"title":"The common ancestor at a non-neutral locus.","authors":[],"date":"2002","doi":"10.1239\/jap\/1019737986","raw":"Fearnhead, P. (2002a). The common ancestor at a non-neutral locus. Journal of Applied Probability, 39:38\u201354.","cites":null},{"id":16372419,"title":"The number of alleles that can be maintained in a \ufb01nite population.","authors":[],"date":"1964","doi":"10.1016\/0040-5809(71)90033-5","raw":"Kimura, M. and Crow, J. (1964). The number of alleles that can be maintained in a \ufb01nite population. Genetics, 49:725\u2013738.","cites":null},{"id":16372491,"title":"Times on trees and the age of an allele. Theoretical Population Biology,","authors":[],"date":"2000","doi":"10.1006\/tpbi.1999.1442","raw":"32Stephens, M. (2000). Times on trees and the age of an allele. Theoretical Population Biology, 57:109\u2013119.","cites":null},{"id":16372397,"title":"Unrooted genealogical tree probabilities in the in\ufb01nitelymany-sites model.","authors":[],"date":"1994","doi":"10.1016\/0025-5564(94)00044-z","raw":"Gri\ufb03ths, R. C. and Tavar\u00b4 e, S. (1994). Unrooted genealogical tree probabilities in the in\ufb01nitelymany-sites model. Mathematical Biosciences, 127:77\u201398.","cites":null},{"id":16372338,"title":"Using random Quasi-Monte Carlo within particle \ufb01lters, with application to \ufb01nancial time series.","authors":[],"date":"2005","doi":"10.1198\/106186005x77243","raw":"Fearnhead, P. (2005b). Using random Quasi-Monte Carlo within particle \ufb01lters, with application to \ufb01nancial time series. Journal of Computational and Graphical Statistics, 14:751\u2013769.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-06","abstract":"We consider analysis of complex stochastic models based upon partial information. MCMC and reversible jump MCMC are often the methods of choice for such problems, but in some situations they can be difficult to implement; and suffer from problems such as poor mixing, and the difficulty of diagnosing convergence. Here we review three alternatives to MCMC methods: importance sampling, the forward-backward algorithm, and sequential Monte Carlo (SMC). We discuss how to design good proposal densities for importance sampling, show some of the range of models for which the forward-backward algorithm can be applied, and show how resampling ideas from SMC can be used to improve the efficiency of the other two methods. We demonstrate these methods on a range of examples, including estimating the transition density of a diffusion and of a discrete-state continuous-time Markov chain; inferring structure in population genetics; and segmenting genetic divergence data","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/71003.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/8331\/1\/Adams_review_final.pdf","pdfHashValue":"d9e909bfff7a13380395ac7d5187a0f6991e2fe2","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:8331<\/identifier><datestamp>\n      2018-01-24T03:17:23Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Computational Methods for Complex Stochastic Systems: A Review of Some Alternatives to MCMC.<\/dc:title><dc:creator>\n        Fearnhead, Paul<\/dc:creator><dc:subject>\n        QA Mathematics<\/dc:subject><dc:description>\n        We consider analysis of complex stochastic models based upon partial information. MCMC and reversible jump MCMC are often the methods of choice for such problems, but in some situations they can be difficult to implement; and suffer from problems such as poor mixing, and the difficulty of diagnosing convergence. Here we review three alternatives to MCMC methods: importance sampling, the forward-backward algorithm, and sequential Monte Carlo (SMC). We discuss how to design good proposal densities for importance sampling, show some of the range of models for which the forward-backward algorithm can be applied, and show how resampling ideas from SMC can be used to improve the efficiency of the other two methods. We demonstrate these methods on a range of examples, including estimating the transition density of a diffusion and of a discrete-state continuous-time Markov chain; inferring structure in population genetics; and segmenting genetic divergence data.<\/dc:description><dc:date>\n        2008-06<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/8331\/1\/Adams_review_final.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/s11222-007-9045-8<\/dc:relation><dc:identifier>\n        Fearnhead, Paul (2008) Computational Methods for Complex Stochastic Systems: A Review of Some Alternatives to MCMC. Statistics and Computing, 18 (2). pp. 151-171. ISSN 0960-3174<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/8331\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1007\/s11222-007-9045-8","http:\/\/eprints.lancs.ac.uk\/8331\/"],"year":2008,"topics":["QA Mathematics"],"subject":["Journal Article","PeerReviewed"],"fullText":"Computational Methods for Complex Stochastic Systems:\nA Review of Some Alternatives to MCMC\nPaul Fearnhead\nDepartment of Mathematics and Statistics\nLancaster University\nUK\nAbstract\nWe consider analysis of complex stochastic models based upon partial information.\nMCMC and reversible jump MCMC are often the methods of choice for such problems,\nbut in some situations they can be difficult to implement; and suffer from problems\nsuch as poor mixing, and the difficulty of diagnosing convergence. Here we review three\nalternatives to MCMC methods: importance sampling, the forward-backward algorithm,\nand sequential Monte Carlo (SMC). We discuss how to design good proposal densities for\nimportance sampling, show some of the range of models for which the forward-backward\nalgorithm can be applied, and show how resampling ideas from SMC can be used to\nimprove the efficiency of the other two methods. We demonstrate these methods on a\nrange of examples, including estimating the transition density of a diffusion and of a\ndiscrete-state continuous-time Markov chain; inferring structure in population genetics;\nand segmenting genetic divergence data.\nKeywords: Diffusions, Forward-Backward Algorithm, Importance Sampling, Missing\nData, Particle Filter, Population Genetics\n1 Introduction\nMany scientific models involve a complex latent structure. They model the latent structure via\na stochastic process, and then model how the observations relate to the value of this process.\nSuch models can be viewed as \u201cmissing data\u201d models: where it is easy to write down the\nlikelihood if our data was both the observations and the value of the latent process, but the\ndata on the latter is missing. To perform inference for parameters requires averaging over the\npossible realisation of this missing data; and often this requires the use of modern computational\nstatistical methods.\nThe models we consider consist of observations y, missing data x, and parameters, \u03b8. We\nassume that the densities p(x|\u03b8), and p(y|x, \u03b8) are available in closed form. Our interest will\nbe in inference for either \u03b8 or for x. For the former we will wish to calculate the likelihood,\np(y|\u03b8) =\n\u222b\np(x|\u03b8)p(y|x, \u03b8)d\u03b8, (1)\nand for the latter to simulate from the conditional distribution of the missing data,\np(x|y, \u03b8) \u221d p(x|\u03b8)p(y|x, \u03b8). (2)\n1\nThe normalising constant of (2) is just the likelihood, (1). We are interested in the situation\nwhere the integral in (1) is intractable, so we need to resort to Monte Carlo methods to estimate\n(1), or to sample from (2).\nA common approach to analysing such data is to use Markov chain Monte Carlo (MCMC)\nor reversible jump MCMC methods (Gamerman, 2006; Green, 1995). For example, a prior\non \u03b8 could be specified, and then we could run an MCMC algorithm which has the posterior\np(\u03b8,x|y) as its stationary distribution. The output from the MCMC algorithm can then be\nused to make inference about \u03b8, or x, or both. The popularity of MCMC methods can be seen\nby the fact that the paper that first introduces the Metropolis-Hastings algorithm (Metropolis\net al., 1953) has been cited nearly ten thousand times. Despite this popularity, there can be\nproblems with implementing MCMC methods efficiently on complex problems, as can be seen\nby the ongoing research into how to design and implement MCMC algorithms (Papaspilopoulos\net al., 2003), the use of population-based MCMC ideas (Kou et al., 2006; Stephens et al., 2007)\nand the need for tailored algorithms for many applications (e.g. Redelings and Suchard, 2005).\nIn this article we describe alternatives to MCMC methods, with a particular emphasis on\nthe author\u2019s own research. We do not attempt to compare these with MCMC methods: our\naim is primarily to show that there are non-MCMC approaches to missing data problems\nthat could be considered. However there is evidence that for some applications, non-MCMC\nmethods can be more efficient than MCMC algorithms. Example applications include: some\nmultiple changepoint models (Fearnhead, 2006); time-ordered hidden Markov models (Chopin,\n2007); some generalised linear models (Chopin, 2002); estimating recombination rates from\npopulation data (Fearnhead and Donnelly, 2001); and mixture models (Del Moral et al., 2006;\nFearnhead, 2004). For some applications of the methods described here (see Section 3) it is\npossible to get independent draws from the posterior, which avoids the problems of mixing and\ndiagnosing convergence of MCMC algorithms. Finally there can also be advantages in terms of\nimplementation when the state in the MCMC algorithm is a particularly complex object. For\nexample, for the models considered in Fearnhead and Donnelly (2001) the state of an MCMC\nalgorithm would be a variable dimensional graph, but an Importance Sampling method, which\nuses the Markov structure of the graph, needs only store a state which is vector-valued.\nThe common feature of the models we consider is that the missing data has a Markov structure.\nThus X = (X1, . . . , X\u03c4 ), where \u03c4 is a stopping time, and we can factorise\np(x|\u03b8) = p(x1|\u03b8)\n\u03c4\u220f\ni=2\np(xi|xi\u22121, \u03b8). (3)\nWe consider three approaches for analysing these models. The first considers inference based\non a single observation, and uses importance sampling (IS) to approximate (1) and get a\nweighted sample from (2). The key to efficiently implementing IS is the choice of proposal\ndensity, and for many models we can write the optimal proposal density in terms of transitions\nof a Markov process (see e.g. Stephens and Donnelly, 2000). The key idea is that it is much\neasier to construct approximations for these transitions than for the joint proposal density of\nx. We demonstrate the application of these ideas for diffusion models, continuous-time Markov\nprocesses, and for inference in population genetics.\nThe latter two approaches consider inference based on a set of observations y = (y1, . . . , yn)\nwhich can be thought of as being made over time. The first of these approaches is the Forward-\nBackward algorithm (Scott, 2002), which enables exact calculation of (1) and simulation from\n(2) when it can be applied. We show some of the range of problems for which the Forward-\nBackground algorithm can be applied, and give an example of its use for analysing a multiple\nchangepoint model of recombination in Salmonella. The last approach is that of Sequential\n2\nMonte Carlo (SMC), also know of particle filters. There is an extensive literature on SMC\nstarting with the papers of Gordon et al. (1993) and Kong et al. (1994), particularly for online\napplications (see Doucet et al., 2001, for applications). We give a brief overview of some of\nthis work, and show how ideas from SMC can be applied to both the Forward-Backward and\nIS algorithms considered previously.\nThe examples we consider are a combination of continuous and discrete time models. We have\nused subscript i in the discrete time case; and subscript t in the continuous time case. The\nexamples are included to give insight into how these methods can be applied in practice, and it\nis possible to read the paper while omitting one or more of the examples. However some of the\nexamples introduce novelty in terms of the specific area of application. In particular Example\n1 proposes a new form of proposal distribution for the evalutation of likelihood for diffusion\nmodels; while Example 2 gives the first application of IS methods to conditioned simulation\nfrom a discrete-state, continuous-time Markov process.\n2 Importance Sampling\nImportance sampling (IS) is a standard Monte Carlo technique for estimating integrals (see e.g.\nRipley, 1987). For example, consider esimating I =\n\u222b\ng(x)dx. If we have a density q(x) such\nthat q(x) > 0 whenever g(x) > 0 then\nI =\n\u222b\ng(x)\nq(x)\nq(x)dx = Eq(w(X)),\nwhere w(X) = g(X)\/q(X) and the final expectation is with respect to q(x). Thus a natural\nestimator of I is obtained by (i) samplingM iid draws from q(x), which we denote x(1), . . . ,x(M);\nand (ii) estimating I by\nI\u02c6 =\n1\nM\nM\u2211\nj=1\nw(x(j)).\nThis estimator is consistent as M \u2192 \u221e; and, assuming Eq(w(X)\n2) < \u221e, its variance is\nVarq(w(X))\/M .\nThe efficiency of the method crucially depends on the choice of q(X). For our application it is\nappropriate to assume that g(X) \u2265 0 for allX, in which case the optimal proposal distribution is\nqopt(X) = g(X)\/I and produces an estimator with zero variance. It is not normally possible to\nsimulate from qopt(X), but this result can guide the choice of proposal. Note that, particularly\nin high dimensions, it is easy to choose proposal distributions for which I\u02c6 has infinite variance.\nThis can occur if the proposal distribution has lighter tails than the optimal proposal; and for\nthis reason it is common to choose a heavy-tailed proposal distribution.\nFor our application g(x) = p(x|\u03b8)p(y|x, \u03b8), and I = p(\u03b8|y), the likelihood. Before looking at\nsome examples, and how to choose a suitable proposal distribution, we make three important\ncomments. Firstly, IS does not only produce an estimate of the likelihood, it produces a\nweighted sample, (x(1), . . . ,x(M)) with weights (w(x(1)), . . . , w(x(M))), that approximates the\nconditional distribution p(x|y, \u03b8). Thus any expectation of the form\n\u222b\nh(x)p(x|y, \u03b8)dx can be\napproximated by \u2211M\nj=1 h(x\nj)w(x(j))\u2211M\nj=1w(x\n(j))\n.\nSecondly, it is possible to use IS to produce smooth estimates of the likelihood curve as a\nfunction of \u03b8, rather than just estimate the likelihood independently at a fixed value of \u03b8 (or\n3\nindependently at a set of \u03b8 values). This can be seen by viewing the Monte Carlo estimator\nI\u02c6(\u03b8) =\n1\nM\nM\u2211\nj=1\np(x(j)|\u03b8)p(y|x(j), \u03b8)\nq(x(j))\nas a function of \u03b8. Practically this involves using the same proposal distribution and sample\nof x values to calculate the estimate of the likelihood for all \u03b8 values. There are considerable\ntheoretical and practical advantages of using such smooth estimates when estimating \u03b8 via\nmaximum likelihood (see Beskos et al., 2007; Pitt, 2007). Designing a good proposal distribution\nto estimate the likelihood at a range of \u03b8 values can be challenging (Stephens, 1999); though\nideas from bridge sampling (Meng and Wong, 1996) can be used (Fearnhead and Donnelly,\n2001).\nFinally, the accuracy of the IS estimator can itself be estimated by looking at the variability\nof the weights. A common way of doing this is to use the Effective Sample Size of Liu (1996).\nThis is defined as\nESS =\n(\u2211M\nj=1w(x\n(j))\n)2\n\u2211M\nj=1w(x\n(j))2\n,\nand its interpretation is that inference based on the weighted sample of size M , will be approx-\nimately as accurate as one based on a independent sample of size ESS. In some situations the\nestimated ESS value can be misleading: see the comments in Stephens and Donnelly (2000) for\nfurther discussion of this.\nWe now consider how to choose, or design, an efficient proposal density. We consider two\ncases, both where we have observations of a stochastic process at some time-point. In the\nfirst case, we also know the initial state of the process, and our proposal is based on forward\nsimulation of the stochastic process from this initial state to the observed state at a later time.\nFor the second case we have no initial state for the process, instead the assumption is that\nthe stochastic process is at stationarity. In this case our approach is to simulate the stochastic\nprocess backwards in time from the observed state. More specific details and examples are\nconsidered below.\n2.1 Choosing the Proposal Density: Forward Simulation\nAssume that our model for the missing data satisfies (3), and that Y depends on x just through\nthe final value x\u03c4 . We have that the optimal proposal density is\nqopt(x) = p(x1|\u03b8,y)\n\u03c4\u22121\u220f\ni=1\np(xi+1|xi, \u03b8,y), (4)\nwhere in this case p(x1|\u03b8,y) \u221d p(x1|\u03b8)p(y|x1, \u03b8) and p(xi+1|xi, \u03b8,y) \u221d p(xi+1|xi, \u03b8)p(y|xi+1, \u03b8).\n(Note that in general the optimal proposal distribution will depend on \u03b8.) Thus to design an ef-\nficient proposal distribution we only need to construct good approximations to the probabilities\np(y|xi, \u03b8).\nExample 1: Discretely observed diffusion\nConsider the problem of inference for a d-dimensional diffusion which is observed at discrete\ntime points. The dynamics of the diffusion is specified by the stochastic differential equation\ndXt = \u00b5\u03b8(Xt)dt+ \u03c3\u03b8(Xt)dBt,\n4\nwhere Bt is m-dimensional Brownian motion, the drift \u00b5\u03b8(Xt) is a d-dimensional vector and\nthe volatility \u03c3\u03b8(Xt) is a d\u00d7m dimensional matrix. In the following we consider inference for\nthe likelihood for a single value of \u03b8 and drop the dependence on \u03b8 in our notation. (Note that\nproducing smooth estimates of the likelihood curve can be non-trivial if the volatility depends\non \u03b8; we do not pursue this, but see for example Roberts and Stramer, 2001; Beskos et al.,\n2006, .)\nWe condition on x0 and consider a single observation y = xT . The likelihood is just the\ntransition density p(xT |x0). Note that extension to multiple observations is straightforward,\nas the likelihood is just a product of transition densities. In general the transition density of a\ndiffusion is intractable, and a common approach to analyse diffusions is by approximating the\ndiffusion by a discrete-time Markov process (though see Beskos et al., 2006; Fearnhead et al.,\n2007, for methods where such a time-discretisation is not necessary). Thus we choose an integer\nn, let h = T\/n, and define a process X0,Xh,X2h, . . . where\nX(i+1)h|xih = xih + \u00b5(xih)h+ h\n1\/2\u03c3(xih)Zi,\nwhere Zi is a vector of m independent standard normal random variables. These dynamics are\nobtained from an Euler approximation to the SDE for Xt (Kloeden and Platen, 1992). This is\na time-homogeneous Markov process, and we denote its transition density by ph(\u00b7|\u00b7).\nUnder this approximation, we have that x = (xh, . . . ,x(n\u22121)h) and y = xT . Furthermore\np(y|x) = ph(y|x(n\u22121)h) and p(x) =\n\u220f(n\u22121)\ni=1 ph(xih|x(i\u22121)h). We will use IS to estimate the\nlikelihood p(y|x0), and look at the effect of different proposal densities. For a proposal density\nq(x), the importance sampling weight will be p(x)p(y|x)\/q(x). In discussing and designing\nproposal densities we will work with the discrete-time Euler approximation above; however\na more rigorous approach is to design proposal laws for the continuous time-process, before\ndiscretising time to implement the method. Such an approach is possible by working with the\nconditioned SDE, which can be obtained using the theory of Doob\u2019s h-transforms (Rogers and\nWilliams, 2000).\nThe first attempt to use IS to estimate the likelihood for discretely observed diffusions was\nby Pedersen (1995), who used the proposal q(x) = p(x). More recently, Durham and Gallant\n(2002) proposed using a proposal distribution motivated by (4). The idea is to approximate\np(y|xih) using an Euler approximation to the SDE. If we let \u2206 = (T \u2212 (i + 1)h) denote the\nfurther time to T then we use\nXT |x(i+1)h,xih = x(i+1)h + \u00b5(x(i+1)h)\u2206 +\u2206\n1\/2\u03c3(xih)Zi.\nNote that this is slightly different from the Euler approximation as we have used \u03c3(xih) rather\nthan \u03c3(x(i+1)h). This is purely to simplify the resulting proposal distribution, and makes\nnegligible difference for sufficiently small h. Thus the approximation to p(y|x(i+1)h) is Gaussian,\nand it is straight forward to combine this approximation to the likelihood with the Gaussian\ntransition density ph(x(i+1)h|xih). The resulting proposal is of the form\n\u220fn\ni=0 q\u02dc(x(i+1)h|xih) where\nq\u02dc(x(i+1)h|xih) is the pdf of a Gaussian distribution with mean xih + h(xT \u2212 xih)\/(T \u2212 ih) and\nvariance h\u2206\u03c3(xih)\u03c3(xih)\nT\/(\u2206 + h).\nTo demonstrate the advantage of designing a suitable proposal distribution for this problem,\nconsider the following simple 1-dimensional diffusion:\ndXt = (5\u2212Xt)dt+X\n1\/2\nt dBt. (5)\nThis is a specific example of the CIR diffusion (Cox et al., 1985). Its transition density is\nknown, but we do not use this fact in the following. We will consider estimating the transition\ndensity with X0 = 4.9 and XT = 5.0, for a range of T and h values.\n5\n0.001 0.005 0.020 0.100\n10\n50\n10\n0\n50\n0\n10\n00\n50\n00\nh\nES\nS\n0 5 10 15 20 25\n10\n50\n10\n0\n50\n0\n10\n00\n50\n00\nT\nES\nS\nFigure 1: The efficiency of three IS proposals for estimating the transition density of a diffusion:\n(black full line) the method of Durham and Gallant;(red dashed line) the method of Pedersen;\nand (blue dotted line) the new proposal. Both figures are for XT = 5.0 and X0 = 4.9. The\nleft-hand plot shows the ESS of the proposals for T = 1 and different values of h; the right-hand\nplot shows the ESS of the proposals for h = 0.1 and different values of T .\nFirstly we fixed T = 1 and varied h in factors of 2 between 1\/1024 and 1\/8 (see left-hand plot\nin Figure 1). Here we notice that the Durham and Gallant proposal is robust to varying h,\nwhereas the method of Pedersen performs poorly when h is small. This contrasting behaviour\nof the Pedersen and Durham and Gallant method can be shown to hold generally (see Stramer\nand Yan, 2007; Stramer, 2007; Delyon and Hu, 2006).\nSecondly we fixed h = 0.1 and varied T in factors of 2 between 0.1 and 25.6 (see right-hand plot\nin Figure 1). Here we notice that the method of Pedersen is robust to increases in T , whereas\nthe ESS of the Durham and Gallant proposal decreases at an exponential rate as T increases.\nThe reason for this is that for a stationary diffusion like the CIR model, if T \u2212 t is large\nthen the dynamics of Xt conditional on XT will be close to the dynamics of the unconditioned\nprocess. The Pedersen proposal is based on simulating Xt from this unconditioned process,\nand therefore does not deteriorate as T increases. By comparison the Durham and Gallant\nproposal takes account of the XT value through an Euler approximation of p(XT |Xt), and this\nEuler approximation is poor for large T \u2212 t, and thus it gives a poor proposal for the dynamics\nof Xt when T \u2212 t is large.\nWe can improve on the Durham and Gallant proposal by obtaining a better approximation to\np(xT |xt). For a geometrically ergodic diffusion, with stationary distribution \u03c0(x), we have that\n6\n||p(xT |x0)\u2212 \u03c0(xT )|| < A exp{\u2212\u03c1T} for some constants A and \u03c1. Thus we can approximate\np\u02c6(xT |xt) = exp{\u2212\u03c1(T \u2212 t)}p\u2206(xT |xt) + (1\u2212 exp{\u2212\u03c1(T \u2212 t)})\u03c0(xT ),\nwhere p\u2206(xT |xt) is the transition density of the Euler approximation over a time-interval \u2206 =\nT\u2212t. Now whilst \u03c1 and \u03c0(XT ) are unknown, this approximation suggests a proposal distribution\nwhich is a mixture\nq(x(i+1)h|xih) \u221d exp{\u2212\u03c1\u2206}q\u02dc(x(i+1)h|xih) +B(1\u2212 exp{\u2212\u03c1\u2206})p(x(i+1)h|xih)\nwhereB and \u03c1 are constants, q\u02dc(x(i+1)h|xih) is the Durham and Gallant proposal and p(x(i+1)h|xih)\nis the transition of the unconditioned diffusion.\nWe tested this on the CIR diffusion above. We chose B = 1 and \u03c1 = 1. The results show that\nthe resulting proposal performs well for both small h and large T , and is uniformly better than\nboth alternative proposals.\nOne general lesson from this example is that while using the optimal proposal is generally\nintractable, it is possible to use knowledge about the underlying process to learn about features\nof the optimal proposal, and these can then be used to design efficient proposal densities. We\nbelieve that proposals based on the argument above will have good performance for a range of\ngeometrically ergodic diffusions.\nExample 2: Discretely Observed Lokta-Volterra Process\nWe now consider a related example, namely that of a continuous-time discrete-valued Markov\nprocess. Here we will focus on a specific example, but the ideas can be generalised. The\nexample we consider is the Lokta-Volterra process, where Xt = (X\n(1)\nt , X\n(2)\nt ) both X\n(1)\nt and\nX\n(2)\nt can take values in the non-negative integers, and they represent the number of prey and\npredator respectively.\nThe model we use comes from Boys et al. (2007). There are three possible transitions for the\nprocess. We denote \u03bb(x,x\u2032) to be the rate of transition from x to x\u2032, with\n\u03bb(x,x\u2032) =\n\uf8f1\uf8f2\n\uf8f3\n\u03b1x(1) if x\u2032(1) = x(1) + 1 and x\u2032(2) = x(2),\n\u03b2x(1)x(2) if x\u2032(1) = x(1) \u2212 1 and x\u2032(2) = x(2) + 1,\n\u03b3x(2) if x\u2032(1) = x(1) and x\u2032(2) = x(2) \u2212 1,\nwhere \u03b1, \u03b2, and \u03b3 are positive constants. (All other transitions have rate 0.) This type\nof model is used for gene regulatory networks (Boys et al., 2007; Golightly and Wilkinson,\n2005). The difficulty with analysing this model directly has led to the use of its diffusion\napproximation instead (Golightly and Wilkinson, 2005, 2006). The diffusion approximation is\na two dimensional diffusion process, X\u02dc, with drift and instantaneous variance given by(\n\u03b1X\u02dc(1) \u2212 \u03b2X\u02dc(1)X\u02dc(2)\n\u03b2X\u02dc(1)X\u02dc(2) \u2212 \u03b3X\u02dc(2)\n)\n, and\n(\n\u03b1X\u02dc(1) + \u03b2X\u02dc(1)X\u02dc(2) \u2212\u03b2X\u02dc(1)X\u02dc(2)\n\u2212\u03b2X\u02dc(1)X\u02dc(2) \u03b2X\u02dc(1)X\u02dc(2) + \u03b3X\u02dc(2)\n)\nrespectively. (6)\nSee Wilkinson (2006) for more details. The advantage of working with this approximation is\nthat the ideas discussed in Example 1 can be used. Here we see if we can perform inference\nwithout resorting to this approximation.\nWe denote the transition density of the Lokta-Volterra process over time t by pt(\u00b7|\u00b7). We\nassume we know the state of the process at time 0, x0, and that we observe the process without\nerror at time T . Thus y = xT , and the likelihood is just the transition density pT (xT |x0).\nWe estimate this using importance sampling. Our proposal process will be a continuous time\nMarkov process. Let \u2206 = T \u2212 t be the further time from t until the observation. We can\n7\ngeneralise (4), which gives that the optimal proposal has transition rates, which we denote\n\u03bbt(x,x\n\u2032), where\n\u03bbt(x,x\n\u2032) = lim\n\u03b4t\u21920\nPr(Xt+\u03b4t = x\n\u2032|Xt = x,xT )\n\u03b4t\n= lim\n\u03b4t\u21920\np\u03b4t(x\n\u2032|x)\n\u03b4t\np\u2206\u2212\u03b4t(xT |x\n\u2032)\np\u2206(xT |x)\n.\nThus we get \u03bbt(X,X\n\u2032) = \u03bb(X,X\u2032)p\u2206(xT |x\n\u2032)\/p\u2206(xT |x). Thus to get a good approximation we\nneed only get an approximation to the transition density of the process.\nOne simple idea we have tried is to approximate the transition density using the Euler ap-\nproximation to the diffusion approximation (6), which is the idea used in the Durham and\nGallant proposal in Example 1. There are two difficulties with this approach which need to be\novercome.\nThe first is simulating from the resulting time-inhomogeneous process. A simple way around\nthis is to choose a time-homogeneous proposal which approximates the above. Thus at an event,\nsay at time t, (i) we calculate our approximation to p\u2206(xT |x) for the four relevant values of x\n(namely xt, and the values of x obtained after the three possible transitions of the process); (ii)\ncalculate the resulting approximations to \u03bbt(x,x\n\u2032) that we get for the three possible transitions;\nand (iii) simulate the time and type of the next event assuming a continuous-time process with\nthese rates fixed.\nThe second is that the diffusion approximation breaks down for very small time intervals: so\nwe need a separate approximation for when \u2206(= T \u2212 t) is sufficiently small. However there\nis a simple approximation based upon (i) fixing the rates of the three events (to r1 := \u03b1x\n(1)\nt ,\nr2 := \u03b2x\n(1)\nt x\n(2)\nt and r3 := \u03b3x\n(2)\nt respectively); and (ii) summing up only the probabilities of the\npaths from xt to xT that contain the fewest number of events. Thus if (n1, n2, n3) denotes the\nnumber of events of each type in such a path (which is well-defined), then we approximate\np\u2206(xT |xt) by\n(\nn!\nn1!n2!n3!\n)[ 3\u220f\ni=1\n(\nri\nr1 + r2 + r3\n)ni]( [(r1 + r2 + r3)\u2206]n\nn!\nexp{\u2212(r1 + r2 + r3)\u2206}\n)\n,\nwhere n = n1 + n2 + n3. This equation simplifies, but here the last term is the probability\nof n events in time \u2206, the second is the conditional probability that a specific ordered set\nof n events will be of the correct type, and the first is the number of arrangements of the n\nevents. This gives a time-inhomegeous proposal process. To make this explicit we substitute\n\u2206 = T\u2212t. Under the proposal process we have that if nj > 0 then the rate of an event of type j\nis nj\/(T\u2212t); whereas if nj = 0 then the rate of an event of type j is r1r2r3(T\u2212t)\n2\/\n\u220f3\ni=1(ni+1).\nDirect simulation from this time-inhomogeneous process is straightforward. Our approach is\nto simulate from this process when \u2206 < \u01eb for a suitably chosen \u01eb. (A simple choice of \u01eb is the\ninverse of the total rate of events when the state is xT .)\nWe omit full details of the IS algorithm, though code in R implementing this procedure is\navailable from www.maths.lancs.ac.uk\/\u223cfearnhea. Our aim has been to try and show how\na suitable proposal process can be obtained. Instead we just give numerical results for one\nexample. We fixed \u03b1 = 2, \u03b2 = 1\/20 and \u03b3 = 1.5. An example simulated path is shown in\nFigure 2. We fixed x0 = (68, 7) and considered estimating pt(xt|x0), for different values of t\nbetween 0.02 and 0.64, and the values of xt used were taken from the simulated path shown in\nFigure 2.\nWe implemented our procedure using M = 1000. The ESS values of the estimates are shown in\nTable 1. We also show the gain in efficiency over a naive Monte Carlo estimate, which proposes\nfrom the prior and gives paths a weight of 1 if the value of xt corresponds to the observed\n8\n0.0 0.5 1.0 1.5 2.0\n0\n50\n10\n0\n15\n0\nTime\nSt\nat\ne\nFigure 2: Simulated path for the Lokta-Volterra model. Prey (x\n(1)\nt ) and predator (x\n(2)\nt ) paths\nare shown in black and red respectively. The time-points used in the simulation study of the\nIS estimator are shown by vertical dashed lines.\nt 0.02 0.04 0.08 0.16 0.32 0.64\nESS 340 398 380 205 9 5\nRel. Eff. 41 140 86 20 8 35\nTable 1: ESS and Relative Efficiency of the IS procedure for estimating pt(xt|x0) for different\nt for the Lokta-Volterra example of Figure 2. Results based on 1,000 samples.\nvalue, and a weight of 0 otherwise. This gain in efficiency is ESS\/(Mpt(xt,x0)), where ESS is\nthe ESS of the IS procedure, and Mpt(xt,x0) is the \u201ceffective sample size\u201d of the naive Monte\nCarlo estimator (i.e. the expected number of paths which coincide with the observed value).\nThe method has a high ESS for values of t up to t = 0.16; but the IS method\u2019s performance\ndeteriorates for larger t. This is similar to the qualitative results for the Durham and Gallant\nIS method in Example 1, and the reason will again be that the approximations used when\ndesigning the proposal density deteriorate for large t. As in Example 1, it may be possible to\nimprove the approximations so that the method can estimate the transition density for large t.\nOur new IS procedure has larger CPU cost, and for our simulations takes about 50 times\nlonger to propose a single path than the naive Monte Carlo method (though a more efficient\nimplementation of the method may reduce this). After taking this into account we see that the\nIS procedure is still more efficient for t = 0.04 and t = 0.08. The naive Monte Carlo estimator\nwill become inefficient at an exponential rate as the dimension of the state-space increases,\nwhereas the performance of the IS method should be more robust to such an increase. Thus\nwe would expect the IS procedure to become relatively more efficient for higher dimensional\nproblems.\n9\n2.2 Choosing the Proposal Density: Backward Simulation\nWe now consider inference for stochastic processes given a single observation x0. We assume\nthe underlying process is at stationarity, with stationary distribution \u03c0(\u00b7), and our interest is to\nestimate \u03c0(x0). This is a common problem, and the methods we describe below can be applied\nto a range of problems in population genetics (e.g. Griffiths and Tavare\u00b4, 1994; Stephens and\nDonnelly, 2000; Bahlo and Griffiths, 1998; Fearnhead and Donnelly, 2001, 2002) and elsewhere\n(see Chen et al., 2005, for some examples). (See Bhattacharya et al., 2007, for an alternative\napproach to this problem.)\nThe IS method we consider assumes that there is a set of values of the state \u03c7 for which x \u2208 \u03c7\nmeans that \u03c0(x) can be evaluated analytically. We will focus on discrete-time Markov processes\n(though the idea can be extended to continuous-time processes). The basic idea is to simulate\nthe path of the process back in time from x0 until the time \u03c4 when xi is first in \u03c7. (For this\nmethod to be practicable, we are implicitly assuming that the expectation of the stopping time\n\u03c4 is finite.) For notational convenience in what follows we will reverse time, so that a time\ni > 0 will relate to a time i discrete time-steps in the past.\nNow if p(x\u2032|x) denotes the transition density of the underlying stochastic process, then we have\nthat\n\u03c0(x0) =\n\u2211\n\u03c4\n\u222b\n\u03c0(x\u03c4 )\n\u03c4\u22121\u220f\ni=0\np(xi|xi+1)dx1:\u03c4 ,\nwhere x1:\u03c4 = (x1, . . . ,x\u03c4 ). The sum is over all possible values of the stopping time; and the\nintegral is over all paths that produce such a stopping time. Thus we can simulate paths x\n(j)\n1:\u03c4j\n,\nfor j = 1, . . . ,M , from a Markov proposal distribution, with transiton density q(xt+1|xt); and\nproduce an IS estimate of \u03c0(x0):\n1\nM\nM\u2211\nj=1\n\u03c0(x\u03c4j)\n(\n\u03c4j\u22121\u220f\ni=0\np(xi|xi+1)\nq(xi+1|xi)\n)\n. (7)\nStephens and Donnelly (2000) showed that the optimal proposal distribution for this class of\nproblem is\nqopt(xi+1|xi) = p(xi|xi+1)\u03c0(xi+1)\/\u03c0(xi). (8)\nSubstitution of this optimal proposal into (7) shows directly that this produces an IS estimate\nwith zero variance. Note that this optimal proposal can be interpreted as the transition for the\ntime-reversed process. The optimal proposal cannot be used directly as it requires knowledge\nof the stationary distribution, but the advantage of this formulation is that designing a good\nproposal distribution will only require approximating ratios of the form \u03c0(xi+1)\/\u03c0(xi). For\nspecific examples of how to approximate this ratio in different applications see Stephens and\nDonnelly (2000); Fearnhead and Donnelly (2001); De Iorio and Griffiths (2004a) and De Iorio\nand Griffiths (2004b).\nExample 3: Temporally-sampled data in population genetics\nThe above IS approach has proven popular within population genetics, which is from where we\ntake this example. We consider inference for data collected at a single genetic locus taken from\nrandomly sampled chromosomes. We assume a constant population size, with random-mating,\nand model the data via the coalescent (Kingman, 1982).\nThe coalescent is a stochastic process that describes the ancestry of a sample. As the process\ngoes back in time, the number of distinct ancestors of the sample decreases, until there is a\nsingle common ancestor. (For fuller details and background see Donnelly and Tavare\u00b4 (1995),\n10\nWakeley (2007) or the Introduction of Stephens and Donnelly (2000).) For most mutation\nmodels for the genetic locus, it is possible to calculate the stationary distribution of the type\nof the common ancestor of the sample, but not the distribution of a sample of size greater than\none. Thus the above IS method can be used to approximate the probability of a given sample,\nwith the underlying process being the coalescent, and the stopping time being the first time\nthere is a single ancestor for the sample.\nHere we consider the infinite alleles mutation model of Kimura and Crow (1964). This model\nassumes that each mutation produces a distinct genetic type. The data records which chromo-\nsomes are identical to each other at the locus of interest - but contains no information about\nthe degree of difference of genetically distinct chromosomes. This is an appropriate model for\nexample for MLST data for bacteria (Maiden et al., 1998). This is an example of a model for\nwhich the stationary distribution of any sample is known \u2013 but we will extend it to a more\ncomplicated situation below. The model is parameterised by a mutation rate \u03b8 and the product\nof the effective population size and generation time Neg; the latter governs the time-scale on\nwhich the population evolves.\nAssume data collected at a single time point, y0. We assume that there are K0 genetic types\nin our sample, labelled 1, . . . , K0. Our data will record how many chromosomes in the sample\ncarry each type. If we summarise our data y0 by the number of distinct genetic types K0, the\ntotal sample size n0, and the number of individuals of each type, n\nk\n0 for k = 1, . . . , K0, then the\nstationary distribution is given by\n\u03c0(y0) = \u03b8\nK0\n\u0393(\u03b8)\n\u0393(n0 + \u03b8)\nn0!\u220fK\nk=1 n\n(k)\n0\n, (9)\nNote that this does not depend on Neg.\nWe define the coalescent process in continuous time, with x0 = y0. The state of the coalescent\nat time t, xt will consist of the types of the ancestors of the sample at time t in the past. The\ndynamics of the coalescent process is given in terms of event times, and transitions at these event\ntime. We will let ti denote the time of the ith event back in time (with t0 = 0). The distribution\nof the inter-event time Ti+1 \u2212 Ti are exponentially distributed with rate ni(ni + \u03b8\u2212 1)\/(2Neg),\nwhere ni are the number of ancestors of the sample at time ti (for our application this will be\nni = n0 \u2212 i).\nAt an event time, there are two types of events, called coalescences and mutations. The former\nrefers to a pair of the ancestors at time t themselves sharing a common ancestor, and results\nin a transition to xt which removes one copy of the genetic type. The latter refer to points\nwhen an ancestor underwent a mutation. For our mutation model, we do not need to continue\nto trace the ancestry at these mutation events (see Fearnhead, 2002a), so these events will also\nlead to the removal of one copy of genetic type from xt. As mutations are unique, mutations\ncan only occur to types k for which there is just a single copy.\nWe will slightly abuse notation and define xi to be xti the state immediately after the ith event,\nand let ni denote the number of ancestors in xi, and n\n(k)\ni the number of these which are of type\nk. Then if xi differs from xi+1 just by the additition of a specific extra ancestor of type l, we\nhave that the forward transition probabilities are\np(xi|xi+1) =\n{\n(n\n(l)\ni \u22121)\n(ni\u22121+\u03b8)\nif n\n(l)\ni > 1,\n\u03b8\n(ni\u22121+\u03b8)\notherwise.\n.\nAll other transitions have probability 0.\n11\nNow if we define \u03bbi = ni(ni + \u03b8 \u2212 1)\/(2Neg), then the probability of a given path back to a\nstopping time T , during which there were \u03c4 events, is\n\u03c0(xT )\n(\n\u03c4\u22121\u220f\ni=0\np(xi|xi+1)\u03bbi exp{\u2212\u03bbi(ti+1 \u2212 ti)}\n)\nexp{\u2212\u03bb\u03c4 (T \u2212 t\u03c4 )}. (10)\nFor this model, we can calculate the optimal proposal for estimating \u03c0(y0). Using the results\nfrom Stephens and Donnelly (2000) and Stephens (2000), we have that the optimal proposal\nhas rates of transition from xt to x\n\u2032 which are\n\u03bb(x\u2032,xt) = n\n(l)\nt (nt + \u03b8 \u2212 1)\/(2Neg), (11)\nfor all transitions such that x\u2032 differs from xt by the removal of an ancestor of type l. Note that\nthese rate describe the conditional dynamics of the coalescent given y0 (Stephens and Donnelly,\n2000).\nWe now consider the extension to analysing data sampled at multiple time-points. Such data\nis informative about Neg as well as \u03b8, and the problem is motivated by the analysis of Campy-\nlobacter jejuni in Wilson and Fearnhead (2007). For work on the same problem, but assuming\ndifferent types of genetic data see Drummond et al. (2002) and Drummond et al. (2005).\nFor simplicity we consider data collected at two time-points, the current time and a time T\nin the past. We denote the data at the two time-points by y0 and yT respectively. We define\n\u03c0t(y, z) to denote the probability under stationarity of observing two samples, of types y and\nz, sampled a time interval t apart. We further denote pt(y|z) = \u03c0t(y, z)\/\u03c0(z). Our interest\nlies in estimating \u03c0T (y0,yT ). We will denote the size of the sample at time T by m, and the\nnumber of these which are of type k by m(k).\nWe will use the IS approach described above. The stopping time will be the fixed time T , as\n\u03c00(xT ,yT ) is known: it is related tothe stationary distribution of a sample of type (xT ,yT ):\n\u03c00(xT ,yT ) = \u03c0(xT ,yT )\n\u220fK\nk=1 n\n(k)\nt !m\n(k)\nt !\u220fK\nk=1(n\n(k)\nt +m\n(k)\nt )!\nwhere K is the total number of alleles in the combined sample (yT ,xt), and the final combina-\ntorial factor accounts for the knowledge of how many of each allelic type are from each of the\nyT and xT samples. The probability of a path back to time t will now be of the form (10), but\nwith \u03c0(xT ) replaced by \u03c00(xT ,yT ). The optimal proposal distribution is again the conditioned\ncoalescent process. An expression for the rates of this process are obtained by taking the rates\nconditioned just on y0, and then also conditioning on yT . By a similar argument to that of\nExample 2, at time t, for transitions which remove an ancestor of type l, the rate is\n\u03bb\u02dc\u2206(x\n\u2032,xt) =\nn\n(l)\nt (nt + \u03b8 \u2212 1)\n2Neg\np\u2206(yT |x\n\u2032)\np\u2206(yT |xt)\n,\nwhere \u2206 = T \u2212 t. Note we have parameterised this rate function in terms of \u2206 the further time\nto time T .\nThe key to approximating this, is to approximate the final ratio. One approach is to consider\nthe limiting behaviour of this. Firstly as \u2206\u2192\u221e, the ratio will tend to 1 (as the data at time\nt and T will be independent). Secondly as \u2206 \u2192 0 we get that p\u2206(yT |xt) \u2192 \u03c00(yT ,xt)\/\u03c0(xt).\nTherefore\nlim\n\u2206\u21920+\n\u03bb\u02dc\u2206(x\n\u2032,xt) =\n\uf8f1\uf8f2\n\uf8f3\nnt+m+\u03b8\u22121\n2Neg\nif n\n(l)\nt = 1 and m\n(l) = 0,\nn\n(l)\nt (nt+m+\u03b8\u22121)(n\n(l)\nt \u22121)\n2Neg(n\n(l)\nt +m\n(l)\n\u22121)\nif n\n(l)\nt > 1,\n12\nfor transitions which remove an ancestor of type l. All other transitions have rate 0; this\nincludes the removal of a ancestor of type l when n\n(l)\nt = 1 and m\n(l) \u2265 1. In this last case, the\ntransition would relate to a mutation event, yet as each mutation is unique this is not possible\nas there is at least one chromosome of type l in the sample at time T .\nThus this motivates defining a function \u03b3(\u2206) with \u03b3(0) = 1 and \u03b3(\u2206) \u2192 0 as \u2206 \u2192 \u221e, and\nproposing from a proposal with rate\n\u03bb\u02c6\u2206(x\n\u2032,xt) =\n\uf8f1\uf8f2\n\uf8f3\nnt+\u03b3(\u2206)m+\u03b8\u22121\n2Neg\nif n\n(l)\nt = 1 and m\n(l) = 0,\nn\n(l)\nt (nt+\u03b3(\u2206)m+\u03b8\u22121)(n\n(l)\nt \u22121)\n2Neg(n\n(l)\nt +\u03b3(\u2206)m\n(l)\n\u22121)\nif n\n(l)\nt > 1.\nThus \u03b3(\u2206) governs the amount of dependence that the sample at time T has on the transitions\nof the proposal at time t. As the underlying population genetic model is geometrically ergodic\n(Donnelly and Kurtz, 1996), and the time-scale on which the population evolves is proportional\nto Neg, a natural choice is \u03b3(\u2206) = exp{\u2212c\u2206\/(Neg)} for some c.\nWe evaluated the performance of this IS method on simulated data. We considered 4 scenarios,\nwhich varied the sample size at times 0 and T , n0 and m respectively, and the mutation rate,\n\u03b8. The scenarios are: (a) n0 = 100, m = 20, \u03b8 = 3; (b) n0 = 50, m = 20, \u03b8 = 3; (c) n0 = 100,\nm = 20, \u03b8 = 1; and (d) n0 = 100, m = 40, \u03b8 = 3. For each case we chose 10 values of T ,\nvarying from 0.025Neg to 2.5Neg.\nWe considered three IS approaches; which correspond to different values of c in the \u03b3(u) function\nabove. These were c = 0, the value used by Wilson and Fearnhead (2007); c = \u221e, which\ncorresponds to proposing from the distribution of the genealogy conditional just on y0, i.e. it\nignores the information in yT ; and c = 4, chosen after experimenting with a small number of\nvalues of c. Results are given in Figure 3, where we show the ESS for each IS method averaged\nacross ten simulated data sets for each combination of scenario and T .\nThe performance of the choices c = 0 and c = \u221e are intuitive: choosing c = \u221e ignores the\ninformation in yT , and so performs well for larger T . By comparison c = 0 performs well for\nsmall T , but produces a poor IS proposal for large T as it places too much weight on yT .\nOur proposal density with c = 4 gives almost uniformly better performance than both these\napproaches, and is robust for both small and larger values of T .\n3 The Forward-Backward Algorithm\nWe now change focus to situations where we observe data over time y = (y1, . . . , yn). We will\nassume a state-space model, where we have an underlying state of interest which varies over\ntime. We will let x = (x1, . . . , xn) denote the values of the state at the time-points at which the\nobservations are made. In the presentation we are assuming both scalar states and observations,\nbut the ideas apply equally to vector valued states and\/or observations. We assume that the\nstate is a Markov model, whose dynamics are governed by a transition density p(xi|xi\u22121); and\nthat conditional on xi, the observation is independent of the state and observations at other\ntimes. The likelihood of a given observation is denoted by p(yi|xi). Finally we will assume a\nknown distribution for x1, p(x1). In many applications, these densities will depend on unknown\nparameters, but we suppress this dependence here.\nA key to analysing such a model is the calculation, or estimation, of the filtering densities,\nwhich are p(xi|y1:i) for i = 1, . . . , n, where y1:i = (y1, . . . , yi). These densities are the posterior\ndistribution for xi given the data to time i. A standard recursion relates the filtering densities\n13\n0.0 0.5 1.0 1.5 2.0 2.5\n5\n10\n20\n50\n20\n0\n50\n0\n(a)\nT\/Neg\nES\nS\n0.0 0.5 1.0 1.5 2.0 2.5\n10\n20\n50\n10\n0\n50\n0\n(b)\nT\/Neg\nES\nS\n0.0 0.5 1.0 1.5 2.0 2.5\n50\n10\n0\n20\n0\n50\n0\n10\n00\n(c)\nT\/Neg\nES\nS\n0.0 0.5 1.0 1.5 2.0 2.5\n5\n10\n20\n50\n20\n0\n50\n0\n(d)\nT\/Neg\nES\nS\nFigure 3: Average ESS values over ten simulated data sets for the three IS methods: c = 0\n(black, full lines); c = 4 (red, dashed lines); and c =\u221e (green, dotted lines). Results are based\non M = 1, 000 in each case, and are shown for four scenarios (see text for details of these).\nat successive time points:\np(xi|y1:i) \u221d p(yi|xi)\n\u222b\np(xi|xi\u22121)p(xi\u22121|y1:i\u22121)dxi\u22121, (12)\nfor i = 2, . . . , n. The normalising constant of the right-hand side is just p(yi|y1:i\u22121). We further\nhave p(x1|y1) \u221d p(x1)p(y1|x1), with the normalising constant being p(y1).\nBeing able to calculate the filtering densities, and the normalising constants of these recursions,\nis sufficient to (i) being able to calculate the likelihood as p(y) = p(y1)\n\u220fn\ni=2 p(yi|y1:i\u22121); and\n(ii) being able to simulate from p(x|y), as\np(xi|y,xi+1:n) \u221d p(xi|y1:i)p(xi+1|xi),\nand thus we can simulate xn from p(xn|y) and then recursively simulate xi given x(i+1):n for\ni = n\u2212 1, . . . , 1.\nFor most models, solving (12) analytically is not possible. Two important exceptions are for\nlinear-Gaussian models when the solution is given be the Kalman Filter (Kalman and Bucy,\n1961; West and Harrison, 1989); and for discrete states which can take only a finite number of\nvalues. This latter case is what we focus on here.\nAssume that xi takes values in (1, . . . , K); then we can rewrite (12) as\np(xi = j|y1:i) \u221d p(yi|xi = j)\nK\u2211\nk=1\np(xi = j|xi\u22121 = k)p(xi\u22121 = k|y1:i\u22121), (13)\nwith\np(yi|y1:i\u22121) =\nK\u2211\nj=1\np(yi|xi = j)\nK\u2211\nk=1\np(xi = j|xi\u22121 = k)p(xi\u22121 = k|y1:i\u22121),\n14\nand p(xi = j|y, xi+1:n) \u221d p(xi = j|y1:i)p(xi+1|xi = j). All distributions are staightforward to\nsimulate from, as they are on a finite space. These recursions are often known as the Forward-\nBackward algorithm, because they involve a forward pass through the data to calculate the\nfiltering distributions and likelihood, followed by a backward simulation of the x from its\nconditional distribution.\nThe Forward-Backward algorithm has been used widely. It dates back to the work of Baum et al.\n(1970), where it is used within an EM algorithm. It has been rediscovered in various fields,\nand is known also by names such as the sum-product algorithm (Kschischang et al., 2001)\nand HMM algorithm; it is closely related to the Junction-Tree algorithm for graphical models\n(Cowell et al., 1999). It has been particularly important within speech recognition (Rabiner\nand Juang, 1986; Juang and Rabiner, 1991) and Bioinformatics (Durbin et al., 1998; Lander\nand Green, 1987; Felsenstein and Churchill, 1996). For an excellent review of the Forward-\nBackward algorithm within statistics, and in particular its use within MCMC methods, see\nScott (2002).\nIn recent years there has been much research into extending the application of the Forward-\nBackward algorithm. One specific area is to continuous time processes (Fearnhead and Meligkot-\nsidou, 2004), and in particular Markov modulated Poisson processes (Scott, 1999; Fearnhead\nand Sherlock, 2006). A second area is to that of inference for changepoint models. For the\nlatter application, the link to the Forward-Backward algorithm is made apparent in Fearnhead\n(2006), though related approaches date to the work of Yao (1984) (see also Barry and Hartigan,\n1992, 1993; Liu and Lawrence, 1999). Here we only focus on this latter application area, and\nbase our presentation on the online algorithm of Fearnhead and Liu (2007).\nThe Forward-Backward algorithm can be applied to changepoint models which have a condi-\ntional independence property: given the position of a changepoint, the data before that change-\npoint is independent of the data after the changepoint. Such a model can be constructed in a\nhierachical manner as follows.\nFirstly we model the changepoint positions via a Markov process. Here we focus on models\nwhere\nPr(next changepoint at i|changepoint at j) = g(i\u2212 j).\nThus the probability mass function g(\u00b7) specifies the distribution of the length of regions between\nsuccessive changepoints; we call these regions segments from now on.\nNext we condition on m changepoints at times \u03c41, \u03c42, . . . , \u03c4m. We let \u03c40 = 0 and \u03c4m+1 = n, so\nour changepoints define m + 1 segments, with segment k consisting of observations y\u03c4k+1:\u03c4k+1\nfor k = 0, . . . ,m. For a segment consisting of observations yj+1:i we will have a set of unknown\nparameters, \u03b2 say. We have a prior distribution, \u03c0(\u03b2) for \u03b2, but assume that the parameters\nfor this segment are independent of the parameters in other segments. Finally we define the\nmarginal likelihood as\nP (j, i) =\n\u222b\np(yj+1:i|\u03b2)\u03c0(\u03b2)d\u03b2, (14)\nand assume that these probabilities can be calculated for all j < i. This requires either conjugate\npriors for \u03b2, or the use of numerical integration.\nNow we introduce the state at time i, xi to be the time of the most recent changepoint prior\nto time i. We have that xi = i\u2212 1 or xi = xi\u22121, corresponding to the presence or absence of a\nchangepoint at time i\u2212 1. Furthermore x is a Markov process with\np(xi = i\u2212 1|xi\u22121 = j) =\ng(i\u2212 1\u2212 j)\u2211\n\u221e\nk=i\u22121 g(k \u2212 j)\n,\n15\nand p(xi = j|xi\u22121 = j) = 1\u2212 p(xi = i\u2212 1|xi\u22121 = j).\nUsing the conditional independence property, it can be shown that p(yi|xi = j,y1:i\u22121) =\nP (j, i)\/P (j, i\u22121), where P (\u00b7, \u00b7) is the marginal likelihood defined above (14). Thus (13) becomes\np(xi = j|y1:i) \u221d\nP (j, i)\nP (j, i\u2212 1)\np(xi = j|xi\u22121 = j)p(xi\u22121 = j|y1:i\u22121)\nfor j < i\u2212 1, and\np(xi = i\u2212 1|y1:i) \u221d P (i\u2212 1, i)\ni\u22122\u2211\nj=0\np(xi = i\u2212 1|xi\u22121 = j)p(xi\u22121 = j|y1:i\u22121)\nThus, the filtering densities can be calculated recursively for this class of models, as in the\nForward-Backward algorithm. The normalising constant of these equations is just p(yi|y1:i\u22121).\nFurthermore, simulating from the joint distribution of changepoints is straightforward via back-\nward simulation, with p(xi|y, xi+1 = i) = p(xi|y1:i) and xi = j if xi+1 = j for j < i.\nThe computational complexity of these recursions increases linearly with i, and thus there is\na quadratic computational cost (and storage cost) for analysing a complete data set. The\nrecursions hold conditional on knowing the hyperparameters of the distributions such as \u03c0(\u03b2)\nand g(\u00b7); though Fearnhead (2006) show how the method can be efficiently implemented within\nan MCMC algorithm when hyperparameters are unknown; and Fearnhead and Vasileiou (2007)\nconsider using an EM algorithm to estimate the hyperparameters. It is also straightforward to\nallow for model choice within segments (Fearnhead, 2005a) and also some types of dependence\nacross segments (Fearnhead and Vasileiou, 2007).\nExample 4: Analysis of Typhoid divergence\nWe demonstrate the method in an analysis of divergence data for Samonella Paratyphi A and\nSalmonella Typhi genomes. The data comes from Didelot et al. (2007), and consists of aligned\nsequences from the two genomes. In total there are 44 regions of aligned sequences, with a total\nlength of 4.6Mb. For simplicity we give results below solely for analysis of the longest region,\nwhich is 606.2kb in length. We summarise the divergence of the two genomes in this region\nby (i) splitting the data into 6062 non-overlapping windows, each 100bp in length; and (ii)\ncounting the number of nucleotide differences between the Paratyphi A and Typhi sequences\nin each window.\nAs in Didelot et al. (2007) we consider a changepoint model for the data. Such a model is\nappropriate as the divergence of the two sequences depends on how closely related the two\nstrains of Salmonella are, and this will vary along the genome due to recombination (see Falush\net al., 2006; Didelot et al., 2007, for more background). Didelot et al. (2007) performed inference\nusing reversible jump MCMC; our aim is to show how simple it is to implement the Forward-\nBackward algorithm for this data.\nWe consider a more complex model than that of Didelot et al. (2007), through the use of an\nextra hierarchy. We allow for variability in divergence within segments by assuming a model\nwhere if yj+1:i belong to a single segment then we have\nyk \u223c Poisson(\u03b8k), where \u03b8k \u223c Gamma(\u03b1, \u03b2),\nfor k = j + 1, . . . , i, with the \u03b8ks being independent of each other. The inclusion of the \u03b8\nparameters allows for extra-Poisson variation which can account for other factors that affect\nthe observed data, such as selection or variation in mutation rates.\n16\nWe assume that \u03b1 is common across segments, but that each segment has its own \u03b2 parameter.\nThus, by integrating out \u03b8k we have that\np(yk|\u03b2) =\n\u0393(\u03b1+ yk)\u03b2\n\u03b1\n\u0393(\u03b1)yk!(\u03b2 + 1)\u03b1+yk\n.\nThe conjugate prior for \u03b2 is\n\u03c00(\u03b2; a, b) =\n\u0393(a+ b)\n\u0393(a)\u0393(b)\n\u03b2a\u22121\n(1 + \u03b2)a+b\n,\nwhich depends on hyperparameters a and b, and is a scaled F (2a, 2b) random variable. If we\nignore the \u0393(\u03b1+ yk)\/(\u0393(\u03b1)yk!) in the likelihood, we get that for such a prior (14) becomes\nP0(j, i; a, b) =\n\u0393(a+ b)\u0393(a+ (i\u2212 j)\u03b1)\u0393(b+ S)\n\u0393(a)\u0393(b)\u0393(a+ b+ (i\u2212 j)\u03b1+ S)\n,\nwhere S =\n\u2211i\nk=j+1 yk, is the sum of observations in the segment.\nDidelot et al. (2007) show that the distribution of divergences across different genes is bimodal,\nand give scenarios underwhich such a bimodal distribution could arise. Therefore we use a\ntwo-component prior\n\u03c0(\u03b2) = p\u03c00(\u03b2; a1, b1) + (1\u2212 p)\u03c00(\u03b2; a2, b2).\nThis gives us that\nP (j, i) = pP0(j, i; a1, b1) + (1\u2212 p)P0(j, i; a2, b2).\nOur model is completed through a geometric distribution for the segment lengths g(\u00b7).\nWe analysed this model using the Forward-Backward algorithm above. Solving the filtering\nrecursions, with n = 6062 for one set of hyperparameter values takes about 1 minute on a\ndesktop PC (though in the next Section we show how this CPU cost can be dramatically\nreduced). We fixed \u03b1 = 5 and estimated the remaining hyperparameters via Monte Carlo EM,\nwhich took around 20 iterations to converge. Results are shown in Figure 4. The top plot\nshows the distribution of mean divergence values \u03b1\/\u03b2 across the inferred segments. We can see\na clear bi-modality, with modes close to 0.2% and 1%, as noted in Didelot et al. (2007). This\nmay be because of recent gene exchange between the two strains (see Didelot et al., 2007, for\nfuller discussion of this).\n4 Sequential Importance Sampling\nWe now consider general filtering models for which the filtering recursion (12) cannot be solved\nanalytically. A popular approach in these cases is to use sequential Monte Carlo (SMC),\nalso known as particle filters, to get approximate solutions to the filtering densities (see Liu\nand Chen, 1998; Doucet et al., 2000, 2001, for more extended reviews of these methods); our\nexposition here is based on that in Fearnhead (2005b).\nThe idea of SMC is to approximate the filtering density at time i by a set of particles {x\n(j)\ni }\nN\nj=1\nand associated weights {w\n(j)\ni }\nN\nj=1 which sum to one. The filtering distribution is approximated\nby a discrete probability mass function whose support is the set of particles, and which has\nprobability w\n(j)\ni assigned to the jth particle value.\nHistogram of alpha\/par\nPercent Divergence\nD\nen\nsi\nty\n0 1 2 3 4 5\n0.\n0\n0.\n2\n0.\n4\n0.\n6\n0.\n8\n1.\n0\n500 520 540 560 580 600\n0\n5\n10\n15\n20\nPosition (kb)\nD\niv\ner\nge\nnc\ne\nFigure 4: Results of the analysis of the divergence data between Salmonella Typhi and\nSalmonella Paratyphi A. (Top) The posterior distribution of the mean divergence \u03b1\/\u03b2 across\nthe inferred segments. (Bottom) Data from a 100kb subregion of the 606.2kb region analysed;\nbelow the axis we show the posterior probability of a changepoint.\nBy substituting this particle approximation at time i into (12) we get an approximation to the\nfiltering distribution at time i+ 1, which we denote as \u03c0\u02c6i+1(xi+1), where\n\u03c0\u02c6i+1(xi+1) \u221d\nN\u2211\nj=1\nw\n(j)\ni p(xi+1|x\n(j)\ni )p(yi+1|xi+1). (15)\nAt its simplest, the particle filter can be viewed as the following:\n1 Initiation Produce a particle approximation to the prior p(x1).\n2 Iteration (Time i + 1.) Given a particle approximation to the filtering distribution at\ntime i, calculate a new particle approximation to \u03c0\u02c6i+1(xi+1).\nThe key to an efficient algorithm is the method for generating the particle approximation to\n\u03c0\u02c6i+1(xi+1). Various approaches to this iteration have been proposed. In general the iteration\nis split into propagation, reweighting and resampling steps. The propagation step generates\nthe particles at time i + 1, and the reweighting step calculates the particles\u2019 weights. The\nresampling step is optional, and produces a set of equally weighted particles, some of which\nwill be duplicated, which can be viewed as an approximate sample from the posterior.\nThe propagation and reweighting steps are based on IS. The simplest IS approach, used in\nGordon et al. (1993), is to simulate particles from the proposal density\nq(xi+1) =\nN\u2211\nj=1\nw\n(j)\ni p(xi+1|x\n(j)\ni ), (16)\n18\nin the propagation step, and then assign a weight proportional to the likelihood of the resulting\nparticles. This approach performs well if the likelihood is not too peaked compared with the\nproposal density; but otherwise can produce highly variable weights.\nA general framework for implementing SMC, which allows for the design of good IS proposal\ndensity, is given by the ASIR filter of Pitt and Shephard (1999). This filter allows for flexibility\nin the choice of proposal density, and the proposal density can be chosen to take account of\nthe model and the information in the observation at the next time step. In the ASIR filter the\nproposal is of the form\nq(xi+1) =\nN\u2211\nj=1\n\u03b2jq(xi+1|x\n(j)\ni ). (17)\nTo simulate from this proposal we first simulate the component, k, from the discrete distribution\nwhich assigns probability \u03b2j to value j, and then simulate xi+1 from q(xi+1|x\n(j)\ni ). For a simulated\npair (k, xi+1), the new particle is xi+1, and its weight is proportional to\nw\n(k)\ni p(xi+1|x\n(k)\ni )p(yi+1|xi+1)\n\u03b2kq(xi+1|x\n(k)\ni )\n.\nIn practice q(xi+1) is chosen to be as close as possible to \u03c0\u02c6i+1(xi+1). For some problems it is\npossible to choose q(xi+1) = \u03c0\u02c6i+1(xi+1), whereas for others, approximations of \u03c0\u02c6i+1(xi+1), often\nbased on a Taylor expansion, can be used. See Pitt and Shephard (1999) for more details.\nBoth for the method of Gordon et al. (1993) and the ASIR filter, the normalising constant of the\nimportance sampling weights at one iteration can be used to estimate the likelihood p(yi+1|yi)\n(Kitagawa, 1996). The results estimator of the likelihood can be shown to be unbiased under\nquite general implementations of the algorithm (Del Moral, 2004; Del Moral and Doucet, 2004).\nAny resampling step increases the Monte Carlo variation of the filter. The reason for using\nresampling steps is linked to early particle filter algorithms (e.g. Gordon et al., 1993; Kong\net al., 1994; Liu and Chen, 1995) which only proposed one future particle for each existing\nparticle (that is they sampled a single value from each p(xi+1|x\n(j)\ni ) at the propagation step).\nFor such algorithms, resampling allows multiple particles to be generated in areas of high\nposterior probability, which can then independently explore the future of the state. There is\nstill a trade-off between this advantage, and the disadvantage of extra Monte Carlo variation,\nand the ESS of the weights is often used to guide whether and when to resample (Liu and Chen,\n1995). Furthermore there are numerous algorithms for performing resampling while introducing\nlittle Monte Carlo variation (Kitagawa, 1996; Liu and Chen, 1998; Carpenter et al., 1999).\nIt should be noted that for the ASIR framework, resampling naturally occurs within the prop-\nagation step. For example the filter of Gordon et al. (1993), which resamples particles inde-\npendently and then propagates each resampled particle once, is equivalent to the ASIR filter\nwith proposal density (16), while the algorithm of Kong et al. (1994) is equivalent to the ASIR\nfilter with stratified sampling from the proposal density,\nq(xt+1) =\nN\u2211\ni=1\n1\nN\np(xt+1|x\n(i)\nt ).\nThe advantage of viewing the resampling stage as occurring within the propagation stage is that\nit is easier to relate the stage to its reason, namely that of producing a set of particles, evenly\nspaced out in areas of high posterior probability, at the next time point. This can help with\nthe choice of when and how to perform resampling, and link this choice with the method for\npropagation and the specific model of interest. It can also help avoid unnecessary resampling\n19\nsteps, which may occur through the idea of having resampling steps at the end of each iteration\nof the particle filter. For example, the initial ASIR algorithm of Pitt and Shephard (1999)\nincluded an unnecessary resampling algorithm, which can severly reduce the accuracy of the\nfilter: Carpenter et al. (1999) give an example where this unnecessary resampling step reduced\nthe accuracy of the filter by a factor of 2.\nThere have been further suggestions for improving the efficiency of SMC methods, which include\nthe use of MCMC (Gilks and Berzuini, 2001; Fearnhead, 2002b), and he use of quasi-Monte\nCarlo methods (Fearnhead, 2005b; L\u2019Ecuyer et al., 2007). A further idea is that of marginal-\nisation (Liu and Chen, 1998; Andrieu and Doucet, 2002) which we demonstrate below on a\nspecific example.\nWe have described how SMC can be used to solve the filtering recursions. For details of exten-\nsions of SMC which are efficient for simulating from p(x|y1:n) see Kitagawa (1996); Hurzeler\nand Kunsch (1998); Doucet et al. (2000) and Godsill et al. (2004).\nWe now consider one example application of the particle filter, which is based on analysis of\nmixture models, and uses ideas from Fearnhead (2004) (see also Chopin, 2007). This example\nhas specific structure, namely a discreteness of the underlying state, that we can use to design\nan efficient SMC algorithm. For examples of the application of SMC methods more generally\nsee Liu and Chen (1998); Doucet et al. (2000); Del Moral et al. (2006) and Del Moral et al.\n(2007). We then revisit Examples 3 and 4, to look at how the resampling idea from SMC can\nbe applied to the problems studied in the earlier sections.\nExample 5: Inferring Population Structure from genetic data\nConsider genetic data from a set of diploid individuals. We assume that the data consists of\nthe genotype of the individual at L unlinked loci. Thus for each locus we have details of the\nalleles that are present on each of the two copies of the individual\u2019s genome. We further assume\nthat the individuals come from an unknown number of populations, and that there is random-\nmating within populations. Our assumption of unlinked loci will mean that, conditional on the\npopulation of an individual, data at different loci are independent of each other.\nWe model the data using the no-admixture model of Pritchard et al. (2000a). This model,\nand its extensions (see for example Pritchard et al., 2000a; Nicholson et al., 2002; Falush\net al., 2003), have been very popular for analysing population genetic data; partly because of\nthe importance of detecting and correcting for population structure when performing tests of\ngenetic association (Pritchard et al., 2000b).\nAssume that at locus l we have Kl alleles. For population j, denote the frequencies of these\nalleles as p(j,l) = p\n(j,l)\n1 , . . . , p\n(j,l)\nkl\n. Consider an individual with genotype yi = {y\n(1)\ni,l , y\n(2)\ni,l }\nL\nl=1. Let\nzi denote the population from which individual i is from. The conditional likelihood of this\ndata, given zi = j, is\np(yi|zi = j) =\nL\u220f\nl=1\np\n(j,l)\ny\n(1)\ni,l\np\n(j,l)\ny\n(2)\ni,l\n.\nConditional on the assignment of individuals to populations, the likelihood for each individual is\nindependent of each other. We further assume a set of probabilities qj such that p(zi = j) = qj.\nOur model is finalised through independent Dirichlet priors on p(j,l) for all j and l; and through\na prior on the number of populations and the probabilities qj = Pr(zi = j). Pritchard et al.\n(2000a) fix the number of populations, M , and assume a dirichlet prior on the (q1, . . . , qM).\nThey then approximate the marginal likelihood for M to make inference for the number of\npopulations. They comment on the difficulty of directly inferring M .\nWe take an alternative approach, and use a mixture Dirichlet process (MDP) model (Ferguson,\n20\n1973). Let \u03b1 be the parameter of this MDP model. One way of viewing such a model is\nthat it is the model of Pritchard et al. (2000a) where the parameters of the Dirichlet prior on\n(q1, . . . , qM) are (\u03b1\/M, . . . , \u03b1\/M), and we take the limit M \u2192\u221e. Note that of interest now is\nnot the number of underlying populations, but the number of populations that are represented\nby the sample.\nWe will use the following recursive representation of the MDP model (Blackwell and Mac-\nQueen, 1973). Let z1:i = (z1, . . . , zi) be the population of origin of the first i individuals, and\ndefine m(z1:i) to be the number of populations present in z1:i. We number these populations\n1, . . . ,m(z1:i), and let nj(z1:i) be the number of the individuals assigned to population j. Then\np(zi+1 = j|z1:i) =\n{\nnj(z1:i)\/(i+ \u03b1) if j \u2264 m(z1:i),\n\u03b1\/(i+ \u03b1) if j = m(z1:i) + 1.\nThe simplest implementation of SMC to this model is to let the state be z1:i together with\nthe allele frequencies at each locus for each of the m(z1:i) populations. However such an\nimplementation would be impracticable due to the high-dimension of the state. (For example,\nfor the data of Rosenberg et al. (2002) there are 377 loci with multiple alleles at each locus.)\nHowever we can use the idea of marginalisation (Liu and Chen, 1998; Chen and Liu, 2000a)\nto avoid this problem. The idea of marginalisation is to note that conditional on z1:i we can\nintegrate out the population allele frequencies. Thus we can calculate\np(yi+1, zi = j|z1:i,y1:i) = p(zi+1 = j|z1:i)\nL\u220f\nl=1\npl(yi+1|z1:i, zi+1 = j,y1:i),\nwhere pl(yi+1|z1:i, zi+1 = j,y1:i) is the conditional probability of the data just at the lth locus.\nThis probability is just a Dirichlet integral, and for brevity we omit details of its calculation.\nWe implement SMC with the state being xi = z1:i. The conditional distribution p(xi+1|xi) is\nnon-zero only for xi+1 and xi that agree on allocations of the first i individuals to populations.\nThus, if xi+1 = (xi, j) then p(xi+1|xi) = p(zi+1 = j|xi). Note that this distribution takes only\na small number, m(xi) + 1, of possible values; and thus given a set of particles at time i, the\napproximation of the filtering distribution at time i + 1, \u03c0\u02c6i+1(xi+1) defined in (15), can be\ncalculated exactly. If there are N particles at time i, the number of terms in \u03c0\u02c6i+1(xi+1) will be\nat least 2N , thus to avoid an exponentially increasing number of particles, we will need some\nmechanism for approximating this distribution with N particles.\nA simple, and seemingly optimal, approach is to sample N particles from \u03c0\u02c6i+1(xi+1) \u2013 this\ncorresponds to IS with the optimal proposal distribution. However, the discrete nature of the\nsupport for \u03c0\u02c6i+1(xi+1) means that there is a simple way to improve on this. Remember that\nthe aim of SMC is to construct an accurate particle approximation to (15). Now in terms of\napproximating \u03c0\u02c6i+1(xi+1) , there is no advantage in having multiple copies of the same particle\n\u2013 it will be better to have at most one copy of each particle, but allow the particles to carry\ndifferent weights. There are various approaches to doing this, and Fearnhead and Clifford\n(2003) suggest one specific approach that they show satisfies an optimality condition. If we\nassume that \u03c0\u02c6i+1(xi+1) has M terms, and the weight assigned to the kth term is w(k), then\ntheir algorithm is:\nResampling of Fearnhead and Clifford (2003)\n(1) Solve N =\n\u2211M\nk=1min(w\nk\/c, 1) for c. Simulate U \u223c Unif[0, c], and set k = 1.\n(2) If w(k) > c goto (4).\n21\n1 2 3 4 5 6 7\n0.\n0\n0.\n1\n0.\n2\n0.\n3\n0.\n4\nFigure 5: Posterior distribution of the number of populations observed in the sample.\n(3) Let U = U \u2212 w(k). If U > 0 then let w(k) = 0; else let U = U + c, and w(k) = c.\n(4) Let k = k + 1. If k \u2264M goto (2); else end.\nThe particles with zero weight are removed. The choice of c in (1) ensures that there will be\nN particles with non-zero weights.\nTo show the advantage of this approach over simulating from \u03c0\u02c6i+1(xi+1) we analysed a subset of\nthe data from Jorde et al. (1995). For simplicity we analysed a sample of 39 genotypes, sampled\nfrom 20 Europeans (all French) and 19 Africans (all Sotho). For each individual we have data\nfrom 30 biallelic loci. We analysed the data with a uniform prior on population allele frequencies\nat each locus, and the parameter of DPM was \u03b1 = 0.1. The latter parameter governs the prior\non the number of populations observed in a sample; and the mean of this is approximately\n\u03b1 log(n), for a sample of size n. Our prior thus penalises large number of populations. We ran\nthe SMC method with N = 10, 000 particles for both (i) sampling particles from \u03c0\u02c6i+1(xi+1)\nusing the stratified sampling algorithm of Carpenter et al. (1999); and (ii) using the resampling\nalgorithm described above. To compare the methods we ran each method 100 independent\ntimes on the data; and looked at the variance of the estimates of the log marginal likelihood.\nThe variance was 1.1 and 0.081 for (i) and (ii) respectively; which corresponds to a 13-fold\nreduction in the variance.\nThe posterior distribution for the number of populations observed in the sample, obtained\nfrom a single run of the SMC method, is shown in Figure 5. This posterior gives no mass to\n2 populations, which was the number of geographic populations the data was sampled from,\nand has a modal estimate of 4. The posterior distribution appears to group all the Sotho\nindividuals in a single population, but then allows for 2 or more populations for the French\nindividuals. To check whether this is an artefact of any problems with the SMC algorithm,\nwe calculated the conditional likelihood of the data given (i) assignment of individuals to their\ngeographic population of origin; (ii) assignment of individuals given by the particle with largest\nweight, which had 4 populations. The log-likelihood of the latter was 5.54 greater than the\nlog-likelihood of the former; which suggests that the model does indeed prefer more than 2\npopulations for the data.\nAs discussed by Pritchard et al. (2000a), inference for the number of populations can be sensitive\nto the priors chosen for the population allele frequencies; though it should be noted that we\nchose our priors to penalise too many populations. Alternative choices of priors we have tested\nhave produced posteriors which, if anything, tend to suggest more populations within the\nsample.\nExample 4 Revisited\n22\nWe now look at how resampling ideas can be used to improve the Forward-Backward algorithm\nfor changepoint models that was presented in Section 3. Firstly, it is easy to see the link\nbetween this Forward-Backward algorithm and the SMC algorithm described above. Within\nthe Forward-Backward algorithm, at any time i the filtering distribution p(xi|y1:i) is a discrete\ndistribution which can take i values. Thus it can be described exactly by a set of i particles,\ntaking the values 0, 1, . . . , i\u2212 1, and corresponding weight (i.e. probability). One problem with\nthe Forward-Backward algorithm is that the number of particles needed to describe the filtering\ndistribution increases linearly with i.\nFearnhead and Liu (2007) suggest approximating the filtering density at time i with fewer\nthan i particles. This will introduce approximation error, but with the gain of a reduction in\ncomputational cost, which will now be linear in the sample size. One approach to doing this\nis through resampling. One efficient resampling algorithm, called stratified rejection control,\nis the same as the resampling algorithm of Fearnhead and Clifford (2003), but with step (1)\nreplaced by\n(1\u2019) Assume we have a set of ordered particles x(1), . . . , x(M), with corresponding normalised\nweights w(1), . . . , w(M). Fix a constant c < 1, and simulate U \u223c Unif[0, c]. Set k = 1.\nThis algorithm outputs a new set of weights; the subset of particles with weight 0 can be\nremoved. The idea is that particles with large weights (as defined by the threshold c) are kept\nwithout resampling. Resampling is applied to the remaining particles. However due to ordering\nin step (1), this resampling occurs in a stratified manner such that if a particle is resampled\nthen nearby particles are less likely to be resampled.\nThe algorithm is similar to that describe in Example 5, except for the ordering of particles and\nthe definiton of c. This algorithm is also closely related to the rejection control idea of Liu et al.\n(1998). The only difference is the ordering of particles and the stratified sampling. However,\nthis stratified resampling has the nice property that the error introduced by the resampling,\nas measured by the Kolmogorov-Smirnov statistic, is bounded above by c. Thus c governs the\namount of error introduced by resampling. Note that the number of particles that are kept by\nthis algorithm will naturally vary over time \u2013 depending on how easy it is to approximate the\nfiltering distribution at different times.\nTo show the potential gains of resampling, we implemented the Forward-Backward algorithm of\nexample 4, but with resampling with c = 10\u22126. This reduced the average number of particles of\nthe algorithm by a factor of 50, and the CPU cost of approximating the filtering densities was\nless than 2 seconds. The effect of the resampling on the posterior distribution was negligible.\nIS Revisited\nIt is also possible to consider applying SMC ideas to the IS methods described in Section 2.\nRemember that the aim was to estimate a likelihood based on sampling the hidden path, x.\nThe key idea is that rather than simulating x values one at a time; they can be simulated\nconcurrently, and resampling ideas used. The first time this was suggested was in a comment\non the article of Stephens and Donnelly (2000) by Chen and Liu (Chen and Liu, 2000b).\nThe first thing to note is that while in Section 2 we gave formulae for the IS weight for a\ncomplete path; these weights factorise and can be calculated sequentially through time as we\nsimulate each component of x. Thus, given an incomplete path x1:i, it is possible to calculate\nan IS weight to associate with that path. For Example 1, this IS weight would be of the form\ni\u220f\nk=1\n(\n\u03c0(xkh|x(k\u22121)h)\nq(xkh|x(k\u22121)h)\n)\n,\n23\nwhere \u03c0(\u00b7|\u00b7) denotes the Euler approximation to the transition density of the diffusion over time\ninterval h; and q(\u00b7|\u00b7) denotes the proposal distribution.\nThe implementation of this idea involves simulating a batch of x1 values (henceforth we call\nthese particles, due to the relation to SMC\/particle filter algorithms) together with their asso-\nciated IS weights; and then from each x1 particle simulate a particle for x1:2 and the associated\nIS weight; and to repeat this recursively over time. Assume that at time i we have sampled N\nparticles for x1:i from our proposal. Denote these values by x\n(j)\n1:i , for j = 1, . . . , N ; and let w\n(j)\ni\ndenote the IS weight associated with x\n(j)\n1:i . Due to the Markov property of the models, we need\nnot store the whole path of each particle, just its current value x\n(j)\ni , as the final estimate of the\nlikelihood depends only on the current state of the particles and their associated weight.\nIf we implemented this as described, the results would be no different than standard IS \u2013 the\nonly difference is in the order in which we have done the simulation. However Chen and Liu\n(2000b) show that using resampling can improve the performance of the resulting estimate.\nThe idea is that if at time i the weights are sufficiently skewed (e.g. in terms of having a\nlow ESS), we can perform resampling to produce a set of equally weighted particles; and then\npropagate these forward. Hopefully this resampling will produce multiple copies of the \u201cgood\u201d\nparticles, and these multiple copies will be able to independently explore the future of the x\npath conditional on x1:i.\nThere are two difficulties with this idea, the first is that in some applications (e.g. Example 3),\nthe length of the x paths can be random. This makes it less clear whether it is fair to compare IS\nweights at fixed time-points i \u2013 as some particles will have almost completed paths, and others\nmay still need to be extended over a considerable number of time steps. The second problem,\nwhich is related and perhaps more fundamental, is that if we are to perform resampling, then\nwe want to resample particles with probabilities proportional to their expected final weight. In\nsome situations this may not be highly correlated with the current weight of the particle, and\nresampling will actually increase the variance of the IS estimator. This particularly occurs if we\nhave been able to use the information in the data to construct a good IS proposal distribution.\nIn these cases our proposal distribution may specfically simulate paths that initially have low\nIS weights (relative to other paths up to the same time point) because it expects the relative\nIS weight to increase as we simulate more of the path. Resampling has the potential problem\nof removing such paths.\nTo give a trivial example, consider the model in Example 3, but with data collected at a single\ntime point. As pointed out, in this case we can implement an exact IS method to calculate the\nlikelihood or simulate from the missing data. We implemented such a method for simulated data\nwith \u03b8 = 10 and a sample size of 200. We simulated 10, 000 paths from the optimal proposal,\nand in Figure 6 we show the values of the (normalised) weights of the particles through time.\nAs the IS proposal is optimal, all final IS weights are equal to the likelihood; however there\nis substantial variation in the weights through time. For example at time 150, the ESS of the\nweights is 26. However if we implement resampling at this time-point we will end up with final\nIS weights that are highly variable: one implementation of this produced final IS weight with\nESS of 22.\nThis is an extreme example, as in this case there is no correlation between a path\u2019s final IS\nweight and its weight at an earlier time i. More generally we would expect there to be correlation\nbetween these two weights, but this could be substantially less than 1; and therefore a simple\nimplementation of resampling may actually increase the variance of the IS weights.\nChen and Liu (2000b) and Chen et al. (2005) suggest a very clever way around these problems.\nTheir idea is to introduce stopping times; to simulate particles forward until these stopping\ntimes; and only consider resampling among particles at the same stopping time. The idea is\n24\n0 50 100 150 200\n1e\n\u22121\n6\n1e\n\u22120\n8\nTime\nN\nor\nm\nal\nis\ned\n w\nei\ngh\nt\nFigure 6: Normalised IS weights versus time for 100 (out of 10000) pahts. The model is\ndescribed in Example 3, but we have assumed data collected at a single time-point.\nthat if a stopping time is chosen appropriately, the weights at that stopping time will be good\npredictors of the expected final weights of the particles. In Chen et al. (2005) there are a\nnumber of examples of how this method can work well in practice.\nThere is a further approach that may be possible for this problem. This is to try and estimate\nthe expected final IS weight for the particles, and resample based on that. In Example 1, the\nexpected final IS weight for a particle x1:i with weight wi will be wip\u2206(y|xi), where p\u2206(\u00b7|\u00b7) is\nthe transition density of the diffusion over a time interval \u2206 = T \u2212 ih. This could be estimated\nvia the Euler approximation.\nWe tried this approach. We analysed the same CIR diffusion as in Example 1, with X0 = 4.9,\nXT = 5.0, T = 0.2 and h = 0.01, using the IS method of Pederson. We resampled based on\nw\u2217i = wi\u03c0\u2206(y|xi), where we approximate \u03c0\u2206(y|xi) via the Euler approximation. We compared\nno resampling, together with resampling when the ESS of the w\u2217i s was less than N\/2. Our\ncomparison was based on the variance of the estimate of the transition probability across 100\nindependent runs of the two methods. UsingN = 10, 000, we found the variance of the estimates\nwhen no resampling was used was 1.4 \u00d7 10\u22124, while using resampling reduced the variance to\n9.0 \u00d7 10\u22125. The reduction in variance was robust to the choice of threshold. However, the\nefficiency of this method depends on the accuracy of the approximation to \u03c0\u2206(y|xi), and it\nbecomes less efficient for larger T ; and for sufficiently large T resampling actually reduces the\naccuracy of the IS approach.\n5 Discussion\nWe have described a number of related approaches for analysing complex stochastic systems\nwithout resort to MCMC. The first of these was based on IS. The key to obtaining an efficient\n25\nIS algorithm is to design a good proposal distribution. We have shown the form of the optimal\nproposal distribution, and given three examples of how to use this to construct a good proposal\ndistribution in practice. A common strategy to Examples 1 and 3 was to consider the form\nof the optimal proposal distribution when the further time to the observation, \u2206 is both large\nand small. The optimal proposal can be calculated in the limits as \u2206 \u2192 \u221e and \u2206 \u2192 0, and\nthese limiting results can help guide the choice of proposal for intermediate values of \u2206.\nThe second approach was the Forward-Backward algorithm. While the application of the\nForward-Backward algorithm to hidden Markov models is both well-known, and used within\nBayesian analysis, we have highlighted some recent work which enables the Forward-Backward\nalgorithm to be applied to other models, in particular changepoint models. As can be seen by\nour Example 4, such an approach offers a simple and efficient alternative to reversible jump\nMCMC methods, and has the advantage of allowing iid draws from the posterior. The final\napproach was SMC, or particle filter algorithms. These have become very popular in recent\nyears, particularly for online problems, for which MCMC methods are not suitable. However,\nSMC methods can be competitive even for batch analysis of data (such as Example 5). This was\nfirst suggested by Chopin (2002) (see also Ridgeway and Madigan, 2003). A general framework\nfor implementing SMC methods for batch problems is described in Del Moral et al. (2006); and\nboth this paper and Del Moral et al. (2007) contain examples of the situations where SMC\nmethods are more efficient than MCMC. For an alternative approach see Cappe et al. (2004);\nCeleux et al. (2006), and see Jasra et al. (2007) for a comparison of methods with population\nMCMC.\nWe have also shown how resampling ideas from SMC can be applied to both the Forward-\nBackward algorithm and the IS approach. The resampling step with SMC is fundamental to\nthe good theoretical properties of the method, particularly for large data sets (Del Moral and\nGuionnet, 2001; Ku\u00a8nsch, 2005); as such being able to apply these ideas to the IS methods\ndiscussed earlier has the potential at least to lead to large improvements in efficiency. However,\nit is not currently clear how to implement resampling ideas for these models in any generality.\nThe methods we have been looking at produce estimates of the likelihood, and simulate from\nthe conditional distribution of the hidden data, for specified values of parameters. An open\nquestion, is how best to implement these methods when the parameters are unknown. There\nhas been research in this area for SMC methods; in particular the use of Kernel Density es-\ntimation (Liu and West, 2001) and the algorithm of Storvik (2002) (see also the related idea\nof Fearnhead, 2002b). However even these methods are known to struggle for large data sets.\nFor IS methods, there has been work on producing smooth estimates of the likelihood curve\n(e.g. Beskos et al., 2007); while the Forward-Backward algorithm has been used within MCMC\nmethods (Scott, 2002). Given the gain in computation that is possible by using resampling\nideas with the Forward-Backward algorithm (see Example 4), it would be good to be able to\nuse such approximate methods such as SMC within MCMC. Some ideas along this line can be\nfound in Neal (2003).\nAcknowledgements I thank Xavier Didelot for providing the data used in Example 4. This\nwork was supported by EPSRC grant GR\/T19698.\nReferences\nAndrieu, C. and Doucet, A. (2002). Particle filtering for partially observed Gaussian state space\nmodels. Journal of the Royal Statistical Society, Series B, 64:827\u2013836.\nBahlo, M. and Griffiths, R. C. (1998). Inference from gene trees in a subdivided population.\n26\nTheoretical Population Biology, 57:79\u201395.\nBarry, D. and Hartigan, J. A. (1992). Product partition models for change point problems.\nThe Annals of Statistics, 20:260\u2013279.\nBarry, D. and Hartigan, J. A. (1993). A Bayesian analysis for change point problems. Journal\nof the American Statistical Society, 88:309\u2013319.\nBaum, L. E., Petrie, T., Soules, G., and Weiss, N. (1970). A maximisation technique occurring\nin the statistical analysis of probabilistic functions of Markov chains. Ann. Math. Stats.,\n41:164\u2013171.\nBeskos, A., Papaspiliopoulos, O., and Roberts, G. O. (2007). Monte Carlo maximum likelihood\nestimation for discretely observed diffusion processes. Annals of Statistics.\nBeskos, A., Papaspiliopoulos, O., Roberts, G. O., and Fearnhead, P. (2006). Exact and com-\nputationally efficient likelihood-based estimation for discretely observed diffusion processes\n(with discussion). Journal of the Royal Statistical Society Series B, 68:333\u2013382.\nBhattacharya, S., Gelfand, A. E., and Holsinger, K. E. (2007). Model fitting and inference\nunder latent equilibrium processes. Statistics and Computing, 17:193\u2013208.\nBlackwell, D. and MacQueen, J. B. (1973). Ferguson distributions via Polya urn schemes.\nAnnals of Statistics, 1:353\u2013355.\nBoys, R. J., Wilkinson, D. J., and Kirkwood, T. B. L. (2007). Bayesian inference for a discretely\nobserved stochastic kinetic model. Submitted.\nCappe, O., Guillin, A., Marin, J. M., and Robert, C. P. (2004). Population monte carlo. Journal\nof Computational and Graphical Statistics (to appear), 13:907\u2013929.\nCarpenter, J., Clifford, P., and Fearnhead, P. (1999). An improved particle filter for non-linear\nproblems. IEE proceedings-Radar, Sonar and Navigation, 146:2\u20137.\nCeleux, G., Marin, J., and Robert, C. P. (2006). Iterated importance sampling in missing data\nproblems. Computational Statistics and Data Analysis, 50:3386\u20133404.\nChen, R. and Liu, J. S. (2000a). Mixture Kalman filters. Journal of the Royal Statistical\nSociety, Series B, 62:493\u2013508.\nChen, Y. and Liu, J. S. (2000b). Comment on \u2018Inference in molecular population genetics\u2019 by\nM. Stephens and P. Donnelly. Journal of the Royal Statistical Society: series B, 62:644\u2013645.\nChen, Y., Xie, J., and Liu, J. S. (2005). Stopping-time resampling for Monte Carlo methods.\nJournal of the Royal Statistical Society Series B, 67:199\u2013217.\nChopin, N. (2002). A sequential particle filter method for static models. Biometrika, 89:539\u2013\n551.\nChopin, N. (2007). Inference and model choice for time-ordered hidden markov models. Journal\nof the Royal Statistical Society, Series B, 69:269\u2013284.\nCowell, R. G., Dawid, A. P., Lauritzen, S. L., and Spiegelhalter, D. J. (1999). Probabilistic\nNetworks and Expert Systems. Springer, New York.\nCox, J. C., Ingersoll, Jr, J. E., and Ross, S. A. (1985). A theory of the term structure of interest\nrates. Econometrica, 53:385\u2013407.\n27\nDe Iorio, M. and Griffiths, R. C. (2004a). Importance sampling on coalescent histories. I.\nAdvances in Applied Probability, 36:417\u2013433.\nDe Iorio, M. and Griffiths, R. C. (2004b). Importance sampling on coalescent histories. II:\nSubdivided population models. Advances in Applied Probability, 36:434\u2013454.\nDel Moral, P. (2004). Feynman-Kac Formulae: Genealogical and Interacting Particle Systems\nWith Applications. Springer, New York.\nDel Moral, P. and Doucet, A. (2004). Particle motions in absorbing medium with hard and\nsoft obstacles. Stochastics Analysis and Applications, 22:1175\u20131207.\nDel Moral, P., Doucet, A., and Jasra, A. (2006). Sequential Monte Carlo samplers. Journal of\nthe Royal Statistical Society, Series B, 68:411\u2013436.\nDel Moral, P., Doucet, A., and Jasra, A. (2007). Sequential Monte Carlo for Bayesian com-\nputation. In Bernardo, J. M., Bayarri, M. J., Berger, J. O., Dawid, A. P., Heckerman, D.,\nSmith, A. F. M., and West, M., editors, Bayesian Statistics 8, pages 115\u2013148, Oxford. Oxford\nUniversity Press.\nDel Moral, P. and Guionnet, A. (2001). On the stability of interactin processes with applications\nto filtering and genetic algorithms. Ann. Inst. of H. Poincare\u00b4 Probab. Statist.\nDelyon, B. and Hu, Y. (2006). Simulation of conditioned diffusion and application to parameter\nestimation. Stochastic Processes and their Applications, 116:1660\u20131675.\nDidelot, X., Achtman, M., Parkhill, J., Thomson, N. R., and Falush, D. (2007). A bimodal\npattern of relatedness between the salmonella Paratyphi A and Typhi genomes: Convergence\nor divergence by homologous recombination? Genome Research, 17:61\u201368.\nDonnelly, P. and Kurtz, T. (1996). A countable representation of the Fleming-Viot measure-\nvalued diffusion. The Annals of Probability, 24:698\u2013742.\nDonnelly, P. and Tavare\u00b4, S. (1995). Coalescents and genealogical structure under neutrality.\nAnnual Review of Genetics, 29:401\u2013421.\nDoucet, A., de Freitas, J. F. G., and Gordon, N. J., editors (2001). Sequential Monte Carlo\nMethods in Practice. Springer-Verlag, New York.\nDoucet, A., Godsill, S. J., and Andrieu, C. (2000). On sequential Monte Carlo sampling\nmethods for Bayesian filtering. Statistics and Computing, 10:197\u2013208.\nDrummond, A. J., Nicholls, G. K., Rodrigo, A. G., and Solomon, W. (2002). Estimating mu-\ntation parameters, population history and genealogy simultaneously from temporally spaced\nsequence data. Genetics, 161:1307\u20131320.\nDrummond, A. J., Rambaut, A., Shapiro, B., and Pybus, O. G. (2005). Bayesian coalescent\ninference of past population dynamics from molecular sequences. Molecular Biology and\nEvolution, 22:1185\u20131192.\nDurbin, R., Eddy, S., Krogh, A., and Mitchison, G. (1998). Biological Sequence Analysis:\nProbabilistic Models of Proteins and Nucleic Acids. Cambridge University Press.\nDurham, G. B. and Gallant, A. R. (2002). Numerical techniques for maximum likelihood esti-\nmation of continuous-time diffusion processes. Journal of Business and Economic Statistics,\n20:297\u2013338.\n28\nFalush, D., Stephens, M., and Pritchard, J. K. (2003). Inference of population structure using\nmultilocus genotype data: Linked loci and correlated allele frequencies. Genetics, 164:1567\u2013\n1587.\nFalush, D., Torpdahl, M., Didelot, X., Conrad, D. F., Wilson, D. J., and Achtman, M. (2006).\nMismatch induced speciation in Salmonella: model and data. Philosophical Transactions of\nthe Royal Society of London, series B, 361:2045\u20132053.\nFearnhead, P. (2002a). The common ancestor at a non-neutral locus. Journal of Applied\nProbability, 39:38\u201354.\nFearnhead, P. (2002b). MCMC, sufficient statistics and particle filters. Journal of Computa-\ntional and Graphical Statistics, 11:848\u2013862.\nFearnhead, P. (2004). Particle filters for mixture models with an unknown number of compo-\nnents. Statistics and Computing, 14:11\u201321.\nFearnhead, P. (2005a). Exact Bayesian curve fitting and signal segmentation. IEEE Transac-\ntions on Signal Processing, 53:2160\u20132166.\nFearnhead, P. (2005b). Using random Quasi-Monte Carlo within particle filters, with applica-\ntion to financial time series. Journal of Computational and Graphical Statistics, 14:751\u2013769.\nFearnhead, P. (2006). Exact and efficient inference for multiple changepoint problems. Statistics\nand Computing, 16:203\u2013213.\nFearnhead, P. and Clifford, P. (2003). Online inference for hidden Markov models. Journal of\nthe Royal Statistical Society, Series B, 65:887\u2013899.\nFearnhead, P. and Donnelly, P. (2001). Estimating recombination rates from population genetic\ndata. Genetics, 159:1299\u20131318.\nFearnhead, P. and Donnelly, P. (2002). Approximate likelihood methods for estimating local\nrecombination rates (with discussion). Journal of the Royal Statistical Society, series B,\n64:657\u2013680.\nFearnhead, P. and Liu, Z. (2007). Online inference for multiple changepoint problems. To\nappear in Journal of the Royal Statistical Society Series B.\nFearnhead, P. and Meligkotsidou, L. (2004). Exact filtering for partially-observed continuous-\ntime Markov models. Journal of the Royal Statistical Society, series B, 66:771\u2013789.\nFearnhead, P., Papaspiliopoulos, O., and Roberts, G. O. (2007). Particle filters for partially-\nobserved diffusions. Submitted to Journal of the Royal Statistical Society Series B.\nFearnhead, P. and Sherlock, C. (2006). Bayesian analysis of Markov modulated Poisson pro-\ncesses. Journal of the Royal Statistical Society, Series B, 68:767\u2013784.\nFearnhead, P. and Vasileiou, D. (2007). Bayesian analysis of isochores. Submitted. available\nfrom www.maths.lancs.ac.uk\/\u223cfearnhea\/publications.\nFelsenstein, J. and Churchill, G. A. (1996). A Hidden Markov Model approach to variation\namong sites in rate of evolution. Molecular Biology and Evolution, 13:93\u2013104.\nFerguson, T. S. (1973). A Bayesian analysis of some nonparametric problems. Annals of\nStatistics, 1:209\u2013230.\n29\nGamerman, D. (2006). Markov Chain Monte Carlo: Stochastic Simulation For Bayesian In-\nference. Taylor and Francis Ltd, UK.\nGilks, W. R. and Berzuini, C. (2001). Following a moving target - Monte Carlo inference for\ndynamic Bayesian models. Journal of the Royal Statistical Society, Series B, 63:127\u2013146.\nGodsill, S. J., Doucet, A., and West, M. (2004). Monte Carlo smoothing for non-linear time\nseries. Journal of the American Statistical Association, 99:156\u2013168.\nGolightly, A. and Wilkinson, D. J. (2005). Bayesian inference for stochastic kinetic models\nusing a diffusion approximation. Biometrics, 61:781\u2013788.\nGolightly, A. and Wilkinson, D. J. (2006). Bayesian sequential inference for stochastic kinetic\nbiochemical network models. Journal of Computational Biology, 13:838\u2013851.\nGordon, N., Salmond, D., and Smith, A. F. M. (1993). Novel approach to nonlinear\/non-\nGaussian Bayesian state estimation. IEE proceedings-F, 140:107\u2013113.\nGreen, P. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian model\ndetermination. Biometrika, 82:711\u2013732.\nGriffiths, R. C. and Tavare\u00b4, S. (1994). Unrooted genealogical tree probabilities in the infinitely-\nmany-sites model. Mathematical Biosciences, 127:77\u201398.\nHurzeler, M. and Kunsch, H. R. (1998). Monte Carlo approximations for general state-space\nmodels. Journal of Computational and Graphical Statistics, 7:175\u2013193.\nJasra, A., Stephens, D. A., and Holmes, C. (2007). On population-based simulation for statics\ninference. Statistics and Computing, page To appear.\nJorde, L. B., Bamshad, M. J., Watkins, W. S., Zenger, R., Fraley, A. E., Krakowiak, P. A.,\nCarpenter, K. D., Soodyall, H., Jenkins, T., and Rogers, A. R. (1995). Origins and affinities of\nmodern humans: a comparison of mitochondrial and nuclear genetic data. American Journal\nof Human Genetics, 57:523\u2013538.\nJuang, B. H. and Rabiner, L. R. (1991). Hidden Markov models for speech recognition. Tech-\nnometrics, 33:251\u2013272.\nKalman, R. and Bucy, R. (1961). New results in linear filtering and prediction theory. Journal\nof Basic Engineering, Transacation ASME series D, 83:95\u2013108.\nKimura, M. and Crow, J. (1964). The number of alleles that can be maintained in a finite\npopulation. Genetics, 49:725\u2013738.\nKingman, J. F. C. (1982). The coalescent. Stochastic Processes and their Applications, 13:235\u2013\n248.\nKitagawa, G. (1996). Monte Carlo filter and smoother for non-Gaussian nonlinear state space\nmodels. Journal of Computational and Graphical Statistics, 5:1\u201325.\nKloeden, P. E. and Platen, E. (1992). Numerical solution of stochastic differential equations.\nSpringer, New York.\nKong, A., Liu, J. S., and Wong, W. H. (1994). Sequential imputations and Bayesian missing\ndata problems. Journal of the American Statistical Association, 89:278\u2013288.\n30\nKou, S. C., Zhou, Q., and Wong, W. H. (2006). Equi-energy sampler with applications in\nstatistical inference and statistical mechanics. Annals of Statistics, 34:1581\u20131619.\nKschischang, F. R., Frey, B. J., and Loeliger, H. (2001). Factor graphs and the sum-product\nalgorithm. IEEE transactions on Information Theory, 47.\nKu\u00a8nsch, H. R. (2005). Monte Carlo filters:Algorithms and theoretical analysis. Annals of\nStatistics, 33:1983\u20132021.\nLander, E. S. and Green, P. (1987). Construction of multilocus genetic linkage maps in humans.\nProceeding of the National Academy of Sciences, USA, 84:2363\u20132367.\nL\u2019Ecuyer, P., Le\u00b4cot, C., and Tuffin, B. (2007). A randomized quasi-Monte carlo simulation\nmethod for Markov chains. To appear in Operations Research.\nLiu, J. and West, M. (2001). Combined parameter and state estimation in simulation based\nfiltering. In Doucet, A., de Freitas, J. F. G., and Gordon, N. J., editors, Sequential Monte\nCarlo in Practice, pages 197\u2013223, New York. Springer-Verlag.\nLiu, J. S. (1996). Metropolised independent sampling with comparisons to rejection sampling\nand importance sampling. Statistics and Computing, 6:113\u2013119.\nLiu, J. S. and Chen, R. (1995). Blind deconvolution via sequential imputations. Journal of the\nAmerican Statistical Association, 90:567\u2013576.\nLiu, J. S. and Chen, R. (1998). Sequential Monte Carlo methods for dynamic systems. Journal\nof the American Statistical Association., 93:1032\u20131044.\nLiu, J. S., Chen, R., and Wong, W. H. (1998). Rejection control and sequential importance\nsampling. Journal of the American Statistical Society, 93:1022\u20131031.\nLiu, J. S. and Lawrence, C. E. (1999). Bayesian inference on biopolymer models. Bioinformatics,\n15:38\u201352.\nMaiden, M. C. J., Bygraves, J. A., Feil, E., Morelli, G., Russell, J. E., Urwin, R., Zhang,\nQ., Zhou, J., Zurth, K., Caugant, D. A., Feavers, I. M., Achtman, M., and Spratt, B. G.\n(1998). Multilocus sequence typing: A portable approach to the identification of clones\nwithin populations of pathogenic microorganisms. Proceedings of the National Acadamey of\nScience, USA, 95:3140\u20133145.\nMeng, X. and Wong, W. H. (1996). Simulating ratios of normalizing constants via a simple\nidentity: a theoretical exploration. Statistica Sinica, 6:831\u2013860.\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., and Teller, E. (1953).\nEquations of state calculations by fast computing machines. The Journal of Chemical Physics,\n21:1087\u20131091.\nNeal, R. M. (2003). Markov chain sampling for non-linear state space models using em-\nbedded hidden Markov models. Available from http:\/\/www.cs.toronto.edu\/\u223cradford\/emb-\nhmm.abstract.html.\nNicholson, G., Smith, A. V., Jo\u00b4nsson, F., Gu\u00b4stafsson, O., Stefa\u00b4nsson, K., and Donnelly, P.\n(2002). Assessing population differentiation and isolation from single-nucleotide polymor-\nphism data. Journal of the Royal Statistical Society Series B, 64:695\u2013715.\n31\nPapaspilopoulos, O., Roberts, G. O., and Sko\u00a8ld, M. (2003). Non-centred parameterisations for\nhierarchical models and data augmentation (with discussion). In Bernardo, J. M., Bayarri,\nM. J., Berger, J. O., Dawid, A. P., Heckerman, D., Smith, A. F. M., and West, M., editors,\nBayesian statistics 7, London. Clarendon Press.\nPedersen, A. R. (1995). A new approach to maximum likelihood estimation of stochastic\ndifferential equations based on discrete observations. Scandinavian Journal of Statistics,\n22:55\u201371.\nPitt, M. (2007). Smooth particle filters for likelihood eval-\nuation and maximisation. Submitted. Available from\nhttp:\/\/www2.warwick.ac.uk\/fac\/soc\/economics\/staff\/faculty\/pitt\/publications\/.\nPitt, M. K. and Shephard, N. (1999). Filtering via simulation: auxiliary particle filters. Journal\nof the American Statistical Association, 94:590\u2013599.\nPritchard, J. K., Stephens, M., and Donnelly, P. (2000a). Inference of population structure\nusing multilocus genotype data. Genetics, 155:945\u2013959.\nPritchard, J. K., Stephens, M., Rosenberg, N. A., and Donnelly, P. (2000b). Association\nmapping in structured populations. American Journal of Human Genetics, 67:170\u2013181.\nRabiner, L. R. and Juang, B. H. (1986). An introduction to hidden Markov models. IEEE\nASSP Magazine, pages 4\u201315.\nRedelings, B. D. and Suchard, M. A. (2005). Joint Bayesian estimation of alignment and\nphylogeny. Systematic Biology, 54:401\u2013418.\nRidgeway, G. and Madigan, D. (2003). A sequential Monte Carlo method for Bayesian analysis\nof massive datasets. Data Mining and Knowledge Discovery, 7:301\u2013319.\nRipley, B. D. (1987). Stochastic Simulation. New York: Wiley and Sons.\nRoberts, G. O. and Stramer, O. (2001). On inference for partially observed nonlinear diffusion\nmodels using the Metropolis-Hastings algorithm. Biometrika, 88:603\u2013621.\nRogers, L. C. G. and Williams, D. (2000). Diffusions, Markov processes and Martingales, Vol.\n1. Cambridge University Press, Cambridge, UK.\nRosenberg, N. A., Pritchard, J. K., Weber, J. L., Cann, H. M., Kidd, K. K., Zhivotovsky, L. A.,\nand Feldman, M. W. (2002). Genetic structure of human populations. Science, 298:2381\u2013\n2385.\nScott, S. L. (1999). Bayesian analysis of a two state Markov modulated Poisson process. Journal\nof Computational and Graphical Statistics, 8:662\u2013670.\nScott, S. L. (2002). Bayesian methods for hidden Markov models: Recursive computing in the\n21st century. Journal of the American Statistical Association, 97:337\u2013351.\nStephens, D., Jasra, A., and Holmes, C. (2007). On population-based simulation for statistical\ninference. Statistics and Computing. To appear.\nStephens, M. (1999). Problems with computational methods in population genetics. Contribu-\ntion to the 52nd session of the International Statistical Institute.\n32\nStephens, M. (2000). Times on trees and the age of an allele. Theoretical Population Biology,\n57:109\u2013119.\nStephens, M. and Donnelly, P. (2000). Inference in molecular population genetics (with discus-\nsion). Journal of the Royal Statistical Society, Series B, 62:605\u2013655.\nStorvik, G. (2002). Particle filters for state-space models with the presence of unknown static\nparameters. IEEE Transaction on Signal Processing, 50:281\u2013289.\nStramer, O. (2007). On simulated likelihood of discretely observed diffusion processes and com-\nparison to closed form approximation. To appear in Journal of Computational and Graphical\nStatistics.\nStramer, O. and Yan, J. (2007). Asymptotics of an efficient Monte Carlo estimation for the\ntransition density of diffusion processes. To appear in Methodology and Computing in Applied\nProbability.\nWakeley, J. (2007). Coalescent Theory: An Introduction. Roberts and Company, Denver,\nColorado, USA.\nWest, M. and Harrison, J. (1989). Bayesian forecasting and dynamic models. Springer-Verlag,\nNew York.\nWilkinson, D. J. (2006). Stochastic Modelling for Systems Biology. Chapman and Hall\/CRC\nPress, Boca Raton, Florida.\nWilson, D. J. and Fearnhead, P. (2007). Calibrating the rate of evolution of campylobacter. In\npreparation.\nYao, Y. (1984). Estimation of a noisy discrete-time step function: Bayes and empirical Bayes\napproaches. The Annals of Statistics, 12:1434\u20131447.\n33\n"}
{"doi":"10.1109\/VETECF.2005.1558427","coreId":"102551","oai":"oai:epubs.surrey.ac.uk:2033","identifiers":["oai:epubs.surrey.ac.uk:2033","10.1109\/VETECF.2005.1558427"],"title":"Video Traffic Model for MPEG4 Encoded Video","authors":["Liew, C H","Kodikara, C","Kondoz, A. M."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2005-09","abstract":"To date, video traffic models in the literature have\\ud\nmostly considered the autocorrelation modeling of empirical\\ud\nvideo traffic for fixed source quantization parameters. Existing models also ignore the inter-dependencies between I-, P-, and B- frame types of MPEG4 coding, which have great impact on empirical queuing performance prediction accuracy. We propose a new Video Traffic Model (VTM) that is capable of generating output video traffic for wide range of quantization parameters in real time, while at the same time capturing the inter-dependencies between different frame types. The VTM performance is evaluated by means of packet loss rate prediction accuracy. Some existing models are implemented for performance benchmark. Simulation results show that the VTM captures empirical video traffic characteristic accurately and outperforms the existing models. Simulation results also show that the models that ignore the inter-dependencies between frame types can greatly underestimate the empirical packet loss rate","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"Institute of Electrical and Electronics Engineers","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:2033<\/identifier><datestamp>\n      2017-10-31T14:04:01Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/2033\/<\/dc:relation><dc:title>\n        Video Traffic Model for MPEG4 Encoded Video<\/dc:title><dc:creator>\n        Liew, C H<\/dc:creator><dc:creator>\n        Kodikara, C<\/dc:creator><dc:creator>\n        Kondoz, A. M.<\/dc:creator><dc:description>\n        To date, video traffic models in the literature have\\ud\nmostly considered the autocorrelation modeling of empirical\\ud\nvideo traffic for fixed source quantization parameters. Existing models also ignore the inter-dependencies between I-, P-, and B- frame types of MPEG4 coding, which have great impact on empirical queuing performance prediction accuracy. We propose a new Video Traffic Model (VTM) that is capable of generating output video traffic for wide range of quantization parameters in real time, while at the same time capturing the inter-dependencies between different frame types. The VTM performance is evaluated by means of packet loss rate prediction accuracy. Some existing models are implemented for performance benchmark. Simulation results show that the VTM captures empirical video traffic characteristic accurately and outperforms the existing models. Simulation results also show that the models that ignore the inter-dependencies between frame types can greatly underestimate the empirical packet loss rate.<\/dc:description><dc:publisher>\n        Institute of Electrical and Electronics Engineers<\/dc:publisher><dc:date>\n        2005-09<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/2033\/1\/SRF002068.pdf<\/dc:identifier><dc:identifier>\n          Liew, C H, Kodikara, C and Kondoz, A. M.  (2005) Video Traffic Model for MPEG4 Encoded Video   62nd IEEE VTS Vehicle Technology Conference, 3.  pp. 1854-1858.      <\/dc:identifier><dc:relation>\n        http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1558427<\/dc:relation><dc:relation>\n        10.1109\/VETECF.2005.1558427<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/2033\/","http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1558427","10.1109\/VETECF.2005.1558427"],"year":2005,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"Video Traffic Model for MPEG4 Encoded Video\nC. H. Liew, C. Kodikara, A. M. Kondoz \nCentre for Communication Systems Research \nUniversity of Surrey \nGuildford, Surrey, GU2 7XH, UK \n{c.liew,c.kodikara,a.kondoz}@surrey.ac.uk \n \nAbstract\u2014 To date, video traffic models in the literature have \nmostly considered the autocorrelation modeling of empirical \nvideo traffic for fixed source quantization parameters. Existing \nmodels also ignore the inter-dependencies between I-, P-, and \nB- frame types of MPEG4 coding, which have great impact on \nempirical queuing performance prediction accuracy. We \npropose a new Video Traffic Model (VTM) that is capable of \ngenerating output video traffic for wide range of quantization \nparameters in real time, while at the same time capturing the \ninter-dependencies between different frame types. The VTM \nperformance is evaluated by means of packet loss rate \nprediction accuracy. Some existing models are implemented \nfor performance benchmark. Simulation results show that the \nVTM captures empirical video traffic characteristic accurately \nand outperforms the existing models.  Simulation results also \nshow that the models that ignore the inter-dependencies \nbetween frame types can greatly underestimate the empirical \npacket loss rate. \nKeywords-component; video traffic model, mpeg, wireless \nvideo communication \nI.  INTRODUCTION \nMultimedia services are seen to be the revenue \ngenerating service for current and future networks. This can \nbe observed from operator efforts to support services like \nvideo on demand and digital video broadcast (DVB-H). In \norder to study and evaluate the performance of video \napplications over wired and wireless communication \nsystems, an accurate video traffic model is required. In this \npaper, we propose a Video Traffic Model (VTM) that is \ncapable of synthetisizing MPEG4 video traffic in real time \nfor a range of quantization parameters.  This will enable use \nof VTM  for study of bandwidth adaptive video \ntransmissions such as wireless video streaming, where video \nsource rate is periodically and adaptively matched to the \ntime-varying channel bandwidth by varying the quantization \nparameters in real time. In contrast, existing models, e.g. [1-\n3], have mostly modeled the video traffic characteristic for a \nfixed set of quatisation parameters (i.e. VBR video) and do \nnot provide the adaptive capability of the proposed VTM. \nSecondly, the existing video traffic models have ignored \ninter-dependencies between I-, P-, and B- frame types of \nMPEG4 coding. Ignoring the inter-dependencies between I-, \nP- and B- frame types leads to underestimation of empirical \ntraffic burstiness, and consequently the empirical packet loss \nrate prediction accuracy. In contrast, the VTM models the \nthe inter-dependencies by using a Multinomial Method \n(MM) [4]. The inter-dependencies modeling using MM \ngreatly improves the model accuracy in predicting the \nP Frame Size\nModel\nB Frame Size\nModel\nI Frame Size\nModel\nInter-\nDependencies\nModeling\nAutocorrelation\nModeling\nMUX\nIBBPBBPBBPBB\n \nFigure 1.  The proposed Video Traffic Model (VTM) \nempirical packet loss rate as will be shown later in this paper. \nSimulation has been performed to evaluate the proposed \nVTM as well as comparing it against the existing models. \nThree existing models, GOP-method [1], Nested-AR [2], \nFARIMA [3] have been implemented for performance \ncomparisons. Nested-AR, FARIMA and GOP-method \nrepresent different cases of autocorrelation and inter-\ndependencies modeling. Simulation results show that the \nVTM captures the video traffic burstiness accurately and is \nsuperior to the existing models. \nThe proposed GVTM has three major parts as shown in \nFig. 1. The first part consists of I-, P-, and B- frame size \nmodels. The second part models the inter-dependencies \nbetween different frame types using a Multinomial Method \n(MM). The final part models the autocorrelation structure of \nvideo traffic. \nThe rest of the paper is organized as follows. In Section \nII, we describe the frame size model. In Section III and VI, \nwe discuss the inter-dependencies and autocorrelation \nmodeling techniques. The summary for video traffic \ngeneration is presented in Section V. Finally, simulation \nresults and discussions are presented in Section VI. \nII. I-, P-, B- FRAME SIZE MODEL \nIn this section, we propose a generalized frame size \nmodel that can synthesize I-, P- and B- frame sizes for a \nquantization parameter range, [1,31]Q \u2208 . First, we \nintroduce a frame activity concept. Secondly, we study the I-, \nP-, and B- frame composition and its relative importance to \nthe output frame size. We then establish a relationship \nbetween the frame activity and the output frame size for a \ngiven quantization parameter. Finally the overall frame size  \n18540-7803-9152-7\/05\/$20.00 \u00a9 2005 IEEE\nAuthorized licensed use limited to: University of Surrey. Downloaded on July 14,2010 at 10:10:09 UTC from IEEE Xplore.  Restrictions apply. \nmodel is presented. \nA. Frame Activity \nFrame activity, A , can be used to measure frame visual \ncomplexity. In general, an un-quantized and un-compressed \npicture frame with large frame activity would result in a \nlarge output frame size. In this paper, we have adopted a \nDCT method [5] for frame activity calculation. Here, we \ndenote IA , PA , and BA  as the frame activities for I-, P-, \nand B- frames calculated before the quantization process in \nan MPEG4 encoder [6].  \nB. Frame Size Composition \nThe basic I-, P-, and B- frame size compositions are shown \nin Fig. 2. The header bits contain information for frame \ndecompression and are found to be almost constant from the \nempirical trace. The texture bits contain the compressed \npixel information as a result of video coding. We jointly \nconsider the header bits and texture bits as Texture Size, T\u03c7 , \nwhere { , , }I P B\u03c7 \u2208 . The motion vector bits contain \ninformation for temporal reference and are only present in P-\n, and B- frames. The motion vector bits are denoted using \nM \u03c7 . In general T\u03c7  is found to be dependent on the \nquantization parameter of an MPEG4 encoder while M \u03c7  \ndoes not dependent on the quantization parameter. \n \nHeader Texture\nxT\n \n(a) \nHeader Texture MV\nxT xM\n \n(b) \nFigure 2. (a) I frame size composition.  (b) P and B frame size composition \n \n \n \n \n \n \nC. Relationship of Frame Activity to Texture Size \nWe have studied the relationship between the frame \nactivity, A\u03c7 , and the Texture size, T\u03c7 , for the quantization \nrange, [1,31]Q\u03c7 \u2208 , where { , , }I P B\u03c7 \u2208 . Fig. 3 portrays \nthe plots of IA  against IT . For the sake of brevity, we only \nplot curves for the quantization parameter 5, 15, and 25. We \nfound that this family of curves can be closely fitted with a \nquadratic function. The corresponding quadratic curves are \nplotted in the same graph. Thus, for a given quantization \nparameter, Q\u03c7 , the Texture size, T\u03c7  , is related to the frame \nactivity, A\u03c7 , using the following equation: \n ( ) 2 ( ) ( )0 1 2T C A C A C\n\u03c7 \u03c7 \u03c7\n\u03c7 \u03c7 \u03c7= \u00d7 + \u00d7 +  (1) \nwhere ( )0C\n\u03c7 , ( )1C\n\u03c7 , and ( )2C\n\u03c7   are the least square fitted \ncoefficients for a given Q\u03c7 . For I frame, the least square \nfitting is performed on the empirical trace for the \nquantization parameter, [1,31]Q\u03c7 \u2208 , and the calculated \n( )\n0C\n\u03c7 , ( )1C\n\u03c7 , and ( )2C\n\u03c7  are stored in an I- frame mapping \ntable, ITB . Same procedures are carried out  for calculating \nthe P and B frame mapping tables, PTB and BTB . \nD. Marginal Distribution Modeling \nThe Cumulative Distribution Functions (CDFs) of the \nframe activity, IA , PA , BA , and the motion vector size, \nPM , BM , are respectively found to be closely fitted to the \nGamma distribution. The plots of Gamma fits are shown in \nFig. 4. \nE. The Complete Frame Size Model \nIn this section, we present the complete frame size \nmodel based on the previous discussions. The frame size, \nS\u03c7 , can be represented mathematically using: \n \n \n \n \n \n \n \n \n0 1000 2000 3000 4000 5000 6000 7000 8000 9000\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nx 104\nI Frame Activity\nTe\nxt\nur\ne \nSi\nze\n (b\nits\n)\nEmpirical\nQuadratic Fitted\nQI=05 \nQI=15 \nQI=25 \n  \n0 1000 2000 3000 4000 5000 6000 7000\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nx 104\nP Frame Activity\nTe\nxt\nur\ne \nSi\nze\n (b\nits\n)\nEmpirical       \nQuadratic Fitted\nQP=05 \nQP=15 \nQP=25 \n    \n0 1000 2000 3000 4000 5000\n0\n1\n2\n3\n4\n5\n6\n7\nx 104\nEmpirical\nQuadratic Fitted\nB Frame Activity\nTe\nxt\nur\ne \nSi\nze\n (b\nits\n) QB=05 \nQB=15 \nQB=25 \n \n                         (a) I frame                                                                     (b) P frame                                                                    (c) B frame \nFigure 3.   Graphs shows the plot of frame activity against texture size and its corresponding quadratic fitting curves for different quantiser. \n1855\nAuthorized licensed use limited to: University of Surrey. Downloaded on July 14,2010 at 10:10:09 UTC from IEEE Xplore.  Restrictions apply. \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nS T I M\u03c7 \u03c7 \u03c7 \u03c7= + \u22c5  (2) \nwhere { , , }I P B\u03c7 \u2208 , and I\u03c7  is an indicator function: \n \n1 { , }\n0 { }\nP B\nI\nI\u03c7\n\u03c7\n\u03c7\n\u2208\uf8f1\n= \uf8f2\n\u2208\uf8f3  (3) \nFig. 5 shows the I-, P-, and B- frame size models graphically. \nWe use the I- frame size generation as an example to explain \nthe frame generation process. First, a random Gaussian \nvariable, 1X , is generated. Then, 1X  is mapped to IA  \nusing a probability integral transform [7]: \n 1 1( ( ))I GA F F X\n\u2212\n\u0393=  (4) \nwhere 1F \u2212\u0393  and GF  are the inverse CDF IA  and the CDF \nof and Gaussian variable respectively. Given the quantization \nparameter, IQ , IA  is then mapped to IT  using (1) and \n( )\n0\nIC , ( )1\nIC , ( )2\nIC  are obtained from the I- frame mapping \ntable ITB  (explained in Section II-C). Finally, the I- frame \nsize, IS , can be calculated using (2). P-, and B- frame size \nPS  and BS  can be calculated in a similar way. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nTABLE I.  COVARIANCE MATRIX, \u03a3  \nCovariance \nMatrix IA  PA  BA  PM  BM  \nIA  1.00 0.84 0.76 0.01 -0.17 \nPA  0.84 1.00 0.92 0.41 0.14 \nBA  0.76 0.92 1.00 0.46 0.29 \nPM  0.01 0.41 0.46 1.00 0.79 \nBM  -0.71 0.14 0.29 0.79 1.00 \nIII. INTER-DEPENDENCIES  MODELING \nThe I-, P-, and B- frame sizes of MPEG4 encoded video \nare highly inter-dependent as shown in Fig. 6. It can be \nobserved that the I-, P-, and B- frame sizes follow a same \ntrend. This represents a traffic burtiness to the network. This \nburstiness can be attributed to the inter-dependencies of \nunderlying IA , PA , BA , PM , and BM . The inter-\ndependencies can also be observed from the normalized \ncovariance matrix, \u03a3 , shown in Table I. It can be observed \nthat the normalized covariance value can be as high as 0.92. \nIn light of this observation, we have used a Multinomial \nMethod (MM) [4] for modeling the inter-dependencies \nbetween IA , PA , BA , PM , and BM . We used MM to \ngenerate 5 correlated Gaussian variables \n         \n0 1000 2000 3000 4000 5000 6000\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nFrame Activity (A)\nCu\nm\nul\nat\niv\ne \nDe\nns\nity\n F\nun\nct\nio\nn\nEmpirical\nGamma fit\nI frame activity \nP frame activity \nB frame activity \n                    \n0 1000 2000 3000 4000 5000\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nMotion Vector Size (bit)\nCu\nm\nul\nat\niv\ne \nDe\nns\nity\n F\nun\nct\nio\nn\nEmpirical\nGamma fit\nP Motion Vector Size \nB Motion Vector Size \n \n(a)                                                                                                                        (b) \nFigure 4.   (a) I-, P-, B- frame activity CDF fitting.   (b) P- and B- frame motion vector size CDF fitting \nGaussian to I frame\nactivity marginal\ndistribution mapping\nI frame activity to\nI frame size\nmapping\nQuantiser\nSelection\nGaussian\nVariable\nGenerator I frame size\n    \nGaussian to P\/B\nframe activity\nmarginal  distribution\nmapping\nP\/B frame\nactivity to P\/B\nframe size\nmapping\nQuantiser\nSelection\nGaussian\nVariable\nGenerator\nP\/B frame size\nGaussian to P\/B\nmotion vector size\nmarginal distribution\nmapping\n+\nGaussian\nVariable\nGenerator\n \n   (a)  I frame size model                                                                                 (b) P and B frame size model       \nFigure 5.  Frame size model for I-, P-, and B- frame. \n1856\nAuthorized licensed use limited to: University of Surrey. Downloaded on July 14,2010 at 10:10:09 UTC from IEEE Xplore.  Restrictions apply. \n  \n \n \n \n \n \n \n \n \n \n1 2 3 4 5( , , , , )X X X X X X= , which will respectively be \nmapped to IA , PA , BA , PM  and BM  such that they are \nalso correlated. The MM is described as follows: Let \n1 2 3 4 5( , , , , )X X X X X X=  be a correlated vector \ncalculated using \n X LZ=  (5) \nwhere L is a 5 5\u00d7 weighting matrix and \n1 2 3 4 5( , , , , )Z Z Z Z Z Z=  are zero mean and unity variance \nGaussian variables. It can be proved that X  has zero mean \nand TLL covariance  [4]. In order to generate X  with the \nsame cross correlation to the empirical trace, we equate the \ncovariance matrix, \u03a3 , from Table I to TLL  and solve for \nmatrix L  using Cholesky Decomposition [8]. The L  matrix \nis then used in (5) to generate the correlated vector X . \nIV. AUTOCORRELATION MODELING \nThe autocorrelation structures of I, P, and B frames are due \nto the autocorrelation structure of underlying IA , PA , BA , \nPM , and BM . We have used a Spatial Renewal Process \n(SRP) [9] to model the AutoCorrelation Functions (ACFs) of \nIA , PA , BA , PM , and BM . We refer the reader to [9] for \ndetail discussions of SRP. The steps utilizing SRP for ACF \nmodeling are as follows:  \n1. Calculate the background frame activity process for \nall the uncompressed raw video frames. Note that \nthis calculation is performed on unprocessed video \nframes, i.e. without motion compensation in the \nMPEG4 encoder chain [6]. \n2. Calculate the ACF of background frame activity \nprocess. Use SRP to model the ACF. \n3. Generate the sequence 1Z  using SRP. 2Z - 5Z  are \nrandomly generated as zero mean and unity \nGaussian variables. \n \n \n \n \n \n \n \n \n \n \n \n4. 1 5( ,..., )Z Z Z=  is mapped to \n1 5( ,..., )X X X=  using (5). Note that in this case \n1X  derives its ACF directly from 1Z  whereas \n2X - 5X  derive their ACFs from 1Z  by means of \ninter-dependencies modeling in (5).  \n5. Finally, 1X , 2X , 3X , 4X , and 5X  are mapped \nto IA , PA , BA , PM , BM  using (4).  \nThe ACFs modeling of IA , PA , BA , PMV , and BMV  \nare thus achieved.  \nV. SUMMARY OF VTM TRAFFIC GENERATION  \nThe traffic generation procedures are as follows: \n \n1. Decide current frame type, \u03c7 , in the GOP, \nIBBPBBPBBPBB. Decide the quantization \nparameter, Q\u03c7 , based on certain criteria, e.g. \noutput frame bit rate matching the channel \nbandwidth. \n2. Given the frame type, \u03c7 , and Q\u03c7 , initialize the \nmapping coefficients ( )0C\n\u03c7 , ( )1C\n\u03c7 , and ( )2C\n\u03c7  from \nthe \u03c7  mapping tables, TB\u03c7 , as discussed in \nSection II.C. \n3. Generate 1Z  using SRP. SRP the models \nautocorrelation structure of background frame \nactivity process (See Section IV). Generate 2Z - 5Z  \nrandomly as zero mean, unity variance Gaussian \nvariables. \n4. Map 1 5( ,..., )Z Z  to 1 5( ,..., )X X  using (5). (5) \nmodels the cross correlation structure in \n1 5( ,..., )X X . Go to Step 5 for I frame, Step 6 for \nP frame and Step 7 for B frame. \n         \n                          (a) I frame                                                                    (b) P frame                                                                   (c) B frame \nFigure 6.   The plots show the I-, P-, and B- frame inter-frame dependency (i.e. following the same trend) \n1857\nAuthorized licensed use limited to: University of Surrey. Downloaded on July 14,2010 at 10:10:09 UTC from IEEE Xplore.  Restrictions apply. \n0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5\n10\u22126\n10\u22125\n10\u22124\n10\u22123\n10\u22122\n10\u22121\n100\nBuffer Size (s)\nlo\ng 1\n0(P\nack\net \nLo\nss \nRa\ntio\n)\nFARIMA \nGVTM \nEmpirical \nGOP \nNested\u2212AR \n \nFigure 7.   Plot of empirical packet loss rate prediction of VTM and \nexisting models. \n5. Map Gaussian variable 1X  to I frame activity IA  \nusing (4). Then map I frame activity IA  to frame \nsize IS  using (1), (2) and mapping coefficients \n( )\n0\nIC , ( )1\nIC , ( )2\nIC . See Fig. 5(a). \n6. Map Gaussian variables 2X  and 4X to P frame \nactivity PA  and motion vector size PM  using (4). \nThen map P frame activity PA  to texture PT  using \n(1) and mapping coefficients ( )0\nPC , ( )1\nPC , ( )2\nPC . \nSum texture PT  and motion vector size PM  to \nobtain frame size PS . See Fig. 5(b) \n7. Map Gaussian variables 3X  and 5X  to B frame \nactivity BA  and motion vector size BM  using (4). \nThen map B frame activity BA  to texture size BT  \nusing (1) and mapping coefficients ( )0\nBC , ( )1\nBC , \n( )\n2\nBC . Sum texture size BT  and motion vector size \nBM  to obtain frame size BS . See Fig. 5(b). \n8. Repeat 1-7 for the total number of required frames. \nVI. SIMULATION RESULTS AND DISCUSSION \nWe validate the proposed VTM by means of empirical \npacket loss rate prediction accuracy. We have implemented \nNested-AR [2], FARIMA [3], GOP-method [1] for \nperformance comparisons. Nested-AR, FARIMA and GOP-\nmethod represent three different cases. Nester-AR models \nthe ACF of I frame while ignoring the ACFs of P and B \nframes. Nested-AR also ignores the inter-dependencies \nbetween different frame types. FARIMA models the ACFs \nof I-, P-, and B- frames, but ignores the inter-dependencies \nbetween different frame types. GOP-method, models the \nACFs of I, P, and B frames, and also the inter-dependencies \nbetween frame types. Several video sequences have been \ntested. However, we only include the result from film \nsequence \u201cLord of the Rings: The Two Towers\u201d due to space \nlimitation. We have set the quantization parameters of VTM \nfor the I-, P-, and B- frames to fixed values of 5, 10 and 15 \nso that it can be easily compared to the existing VBR video \ntraffic models. VTM, Nested-AR, FARIMA and GOP are \nrespectively used to generate synthetic traffic to a FIFO \nqueue at different bandwidth utilizations. The packet loss \nrate for all the models are recorded and compared to the \nempirical packet loss rate. We present the results for the \nbandwidth utilization of 40% in Fig. 7. VTM is shown to \npredict empirical packet loss rate accurately and is superior \nover the Nested-AR and FARIMA. The GOP-based method \nhas similar performance to VTM, but it lacks the flexibility \nof VTM being able to reproduce video traffic for different \nquantization parameters in real time. Fig. 7 also shows that \nthe model that ignores inter-dependencies between frame \ntypes, e.g. Nested-AR and FARIMA, can greatly \nunderestimate the empirical packet loss rate. Similar results \nare found for the bandwidth utilizations 60% and 80%. \nVII. CONCLUSION \nIn this paper, a new Video Traffic Model (VTM) that can \ngenerate video traffic for quantization parameter range [1,31] \nis proposed. This is important for study of adaptive video \ntransmission where rate adaptation is achieved by varying \nquantization parameters at the encoder. The VTM also \nconsiders inter-frame dependencies between I-, P-, and B- \nframes. Simulation results show that the VTM accurately \npredicts empirical traffic characteristics and outperform the \nexisting video traffic models that ignore the inter-frame \ndependencies. \nACKNOWLEDGMENT \nThe authors would like to acknowledge the funding from \nEU FP6 IST-NEWCOM project. \nREFERENCES \n[1] O. Rose, \"Statistical Propeties of MPEG Video Traffic and Their \nImpact on Traffic Modelling in ATM Systems\", Report No. 101, Feb \n1995.  \n[2] D. Liu, E. I. Sara, and W. Sun, \u54f2 ested auto-regressive processes for \nmpeg-encoded video traffic modeling,_ IEEE Trans. Circuits Syst., \nvol. 11, pp. 169\u2013183, Febuary 2001.  \n[3] N. Ansari, H. Liu, Q. Shi, and H. Zhao, \u201cOn modeling mpeg video \ntraffics,\u201d IEEE Trans. Broadcast., vol. 48, pp. 337\u2013347, December \n2002.  \n[4] E. M. Scheuer and Stoller, \u201cOn the generation of normal random \nvectors,\u201d Technometrics, vol. 4, pp. 278\u2013281, May 1962. \n[5] W. J. Kim, J. W. Yi, and S. D. Kim, \u201cA bit allocation method based \non picture activity for still image coding,\u201d  IEEE Trans. Image \nProcessing, vol. 8, pp. 974\u2013977, July 1999. \n[6] M. Ghanbari, Video Coding: An Introduction to Standard Codecs, 1st \ned. IEE, 1999. \n[7] A. M. Mood and A. G. Graybill, Introduction to The Theory of \nStatistics, 3rd ed. McGraw-Hill, 1974. \n[8] R. K. Bock, W. Krischer, \u201cThe Data Analysis Briefbook\u201d, Version \n16, April 1998. \n[9] T. Taralp, M. Devetsikiotis, and I. Lambadaris, \u201cEfficient fractional \ngaussian noise generation using the spatial renewal process,\u201d  in \nProc. of the IEEE International Conference on Communications, \nAtlanta, USA, June 1998, pp. 1456\u20131460. \n1858\nAuthorized licensed use limited to: University of Surrey. Downloaded on July 14,2010 at 10:10:09 UTC from IEEE Xplore.  Restrictions apply. \n"}
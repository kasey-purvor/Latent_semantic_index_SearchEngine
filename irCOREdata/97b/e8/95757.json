{"doi":"10.1080\/13600860903570145","coreId":"95757","oai":"oai:eprints.lse.ac.uk:27258","identifiers":["oai:eprints.lse.ac.uk:27258","10.1080\/13600860903570145"],"title":"Web 2.5: the symbiotic web","authors":["Bernal, P. A."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-03","abstract":"A new form of symbiosis is developing on the Web. The current ecommerce model, which relies heavily on the supply of 'free' content, has made individuals and commercial enterprises mutually dependent: enterprises have built business models reliant on a currency of personal data, while individuals expect free access to services supplied by search engines, email systems and social networking sites, and media services such as YouTube and Hulu. These 'free' services use personal data to generate revenues through targeted advertising, profile building, and the direct brokering of personal data. The symbiosis is essentially benign - it lies behind many recent positive developments. Both users and the businesses that provide online services benefit. Nevertheless, there are significant risks associated with this symbiotic nature that need to be addressed. This paper will describe the model that is the Symbiotic Web, explain the risks associated with it, and suggest possible approaches to address them","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/95757.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/27258\/1\/Web_2.5_%28LSERO%29.pdf","pdfHashValue":"84df4220911d85c7b6d519c5a9739b6a9b2b3a43","publisher":"Routledge","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:27258<\/identifier><datestamp>\n      2011-03-02T16:30:28Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D4C4C<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/27258\/<\/dc:relation><dc:title>\n        Web 2.5: the symbiotic web<\/dc:title><dc:creator>\n        Bernal, P. A.<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:subject>\n        K Law (General)<\/dc:subject><dc:description>\n        A new form of symbiosis is developing on the Web. The current ecommerce model, which relies heavily on the supply of 'free' content, has made individuals and commercial enterprises mutually dependent: enterprises have built business models reliant on a currency of personal data, while individuals expect free access to services supplied by search engines, email systems and social networking sites, and media services such as YouTube and Hulu. These 'free' services use personal data to generate revenues through targeted advertising, profile building, and the direct brokering of personal data. The symbiosis is essentially benign - it lies behind many recent positive developments. Both users and the businesses that provide online services benefit. Nevertheless, there are significant risks associated with this symbiotic nature that need to be addressed. This paper will describe the model that is the Symbiotic Web, explain the risks associated with it, and suggest possible approaches to address them.<\/dc:description><dc:publisher>\n        Routledge<\/dc:publisher><dc:date>\n        2010-03<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/27258\/1\/Web_2.5_%28LSERO%29.pdf<\/dc:identifier><dc:identifier>\n          Bernal, P. A.  (2010) Web 2.5: the symbiotic web.  International Review of Law, Computers and Technology, 24 (1).  pp. 25-37.  ISSN 1360-0869     <\/dc:identifier><dc:relation>\n        http:\/\/www.tandf.co.uk\/journals\/titles\/13600869.asp<\/dc:relation><dc:relation>\n        10.1080\/13600860903570145<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/27258\/","http:\/\/www.tandf.co.uk\/journals\/titles\/13600869.asp","10.1080\/13600860903570145"],"year":2010,"topics":["QA75 Electronic computers. Computer science","K Law (General)"],"subject":["Article","PeerReviewed"],"fullText":"  \nP. A. Bernal \nWeb 2.5: the symbiotic web \n \nArticle (Accepted version) \n(Refereed) \n \nOriginal citation: \nBernal, P. A. (2010) Web 2.5: the symbiotic web. International review of law, computers & \ntechnology, 24 (1). pp. 25-37.  \n \nDOI: 10.1080\/13600860903570145\n \n\u00a9 2010 Routledge Taylor & Francis  \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/27258\/\n \nAvailable in LSE Research Online: March 2011 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final manuscript accepted version of the journal article, \nincorporating any revisions agreed during the peer review process.  Some differences between \nthis version and the published version may remain.  You are advised to consult the publisher\u2019s \nversion if you wish to cite from it. \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \nName of paper: \u201cWeb 2.5: The Symbiotic Web\u201d \n \nAuthor: Mr Paul Bernal \n \nEmail address: p.a.bernal@lse.ac.uk\n \nSnail address: 34D Portland Rise, London N4 2PP \n \n3 Key words: Autonomy, Personal Data, Internet \n \n \n \n \nIntroduction \n \nA form of symbiosis is developing on the web. Individuals and commercial \nenterprises are becoming mutually dependent: enterprises have built business models \nreliant on the currency of personal data, while individuals depend on \u2018free\u2019 access to \nmany services, such as search engines, email systems and social networking sites, as \nwell as media services such as YouTube and Hulu \u2013 many of the services which now \nform an intrinsic part of modern life. These \u2018free\u2019 services use personal data, obtained \nthrough various overt and covert means, as their way of generating revenues \u2013 \nthrough targeted advertising, profile building, and the direct sale of personal data \namongst other things. What is more, the rest of the web appears to be following suit: \nISPs, and most commercial services have moved towards this kind of symbiotic state, \ngathering personal data in exchange for discounts for buying online or \u2018personalised \nservices\u2019, as a part of their processes. It is a significant change in the way the internet \nfunctions \u2013 this Symbiotic Web can be seen as a whole new stage in the development \nof the web \u2013 Web 2.5, a development of the much-discussed Web 2.0, the shift to \nwhich is almost as significant as the shift from Web 1.0 to Web 2.0 \n \nWhat lies behind the symbiosis is an exchange of data \u2013 users give up data in \nexchange for access to services, for convenience, and for lower prices. This symbiotic \nexchange of data is essentially benign \u2013 it lies behind many recent positive \ndevelopments in online services and has produced a massive expansion in attractive \nand productive products and services available on the internet. Both the individuals \nwho use the internet and the businesses that provide these services benefit from the \nexchange. Even so, there are significant risks associated with this symbiotic \nexchange, and there are dangers that it could develop into something malign; twisting \nthe mutually beneficial symbiosis into a harmful parasitism, producing a fractured \nweb and manipulating and controlling those who use it. The emergence of Web 2.5, \nthe Symbiotic Web, places significant doubt over the future of the web as it has often \nbeen presented. Tim Berners-Lee\u2019s benign vision of a \u2018Semantic Web\u2019, which lies \nbehind most ideas of Web 3.0, suggests an internet which grants users greater control \nas the internet becomes more personalised. The malign version of the Symbiotic Web \nsuggests precisely the opposite. Control could be being taken out of the hands of the \nusers, choices being made for them, rather than by them, and not necessarily for their \nbenefit, but rather for the benefit of those wielding that control. Ensuring that the \nsymbiosis remains benign is therefore of great importance. \n \n Page 1 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \nAn exchange of freedoms \n \nWe as individuals are sacrificing one kind of freedom \u2013 \u2018liber\u2019 freedom, our privacy \nand autonomy \u2013 for another, \u2018gratis\u2019 freedom, receiving services without having to \npay for them in the pecuniary sense. As the adage goes, there\u2019s no such thing as a free \nlunch \u2013 effectively we are paying for these services through our private information, \nand ultimately, as will be outlined below, through giving up part of our autonomy. \nConversely, enterprises are sacrificing the opportunity to make an immediate \nmonetary return for a less immediately tangible form of reward \u2013 information about \ntheir potential customers that may or may not be able to be transformed effectively \ninto financial rewards at a later date. So far, for many businesses these rewards have \nbeen substantial, helping Google to develop into one of the biggest and most powerful \ncorporations in the world, and social networking services like Facebook into multi-\nbillion dollar enterprises. Whether they continue to be so is another matter \u2013 but \nbusiness models and ways of operating have been built on the assumption that they \nwill be, models that can only effectively function if the gathering and use of personal \ndata continues unabated. Indeed, as more businesses shift into this way of being, this \ngathering and utilisation of data can only be expected to increase.  \n \nThe implications of the symbiotic exchange are significant. It helps to explain many \nof the most important things that are happening in the field. It explains why so much \npersonal data are gathered. It can help us understand what kinds of data are being \ngathered, and by whom, and the principal purposes to which such information is being \nput commercially. Understanding the nature of this symbiosis can also provide good \nindications as to the ways in which this data may be used in the future \u2013 as well as \nwhy companies are less than eager to be open about either the data gathering or its \npurposes. Significantly, it can also help us to understand the threats to our privacy and \nautonomy that are arising \u2013 and the further threats that might arise in the future \u2013 as a \nresult of the ways that data are being gathered and used. \n \n \nWeb 2.5: the evolution of the Symbiotic Web (see figure 1) \n \nIn its first form \u2013 Web 1.0 \u2013 the web was for almost all intents and purposes an \n\u2018information bank\u2019. \u2018Content providers\u2019 put information up onto the web, while \n\u2018users\u2019 accessed and downloaded that information. The flow of information was \neffectively one-way: from the content providers to the users. \n \nWeb 2.0 is characterised largely by a transformation in \u2018users\u2019. Rather than simply \naccessing information provided for them, users began to supply and maintain \ninformation themselves. This information is provided through a wide range of Web \n2.0 applications such as blogs, wikis, social networking sites like Facebook or \nMySpace and user generated media sites like YouTube. In Web 2.0, information \nflows into the web not only from the content providers, but also from the users \nthemselvesi. As Stephen Fry put it: \n \n\u201cIt\u2019s actually an idea that the reciprocity between the user and the provider is \nwhat is emphasised. In other words, genuine interactivity, if you like, simply \nbecause people can upload as well as download.\u201dii\n \n Page 2 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \nIn the shift from Web 1.0 to Web 2.0, information started to flow both ways. The shift \nfrom Web 2.0 to the Symbiotic Web, Web 2.5, is characterised by a converse \ntransformation for the erstwhile \u2018content providers\u2019. Not only do they provide \ninformation, but they extract information from the users, in a wide variety of ways \u2013 \nfrom monitoring their activities on line to persuading users to volunteer as much \npersonal information as possible. This personal information is in turn used by the \ncontent providers to tailor the information they provide to individuals. The supremely \nsuccessful business model of Google began the process. Google\u2019s use of terms \nsearched for by individuals to target specific advertising for them demonstrated the \npotential that access to personal information can provide \u2013 Google\u2019s revenue \nexceeded $5 billion for the first quarter of 2009. Online, targeted advertising is very \nbig business, and growing in relation to the real world \u2013 for example, Google is now \nthe biggest seller of advertising in the UK, overtaking ITV in recent yearsiii. \n \nThe Google business model developed powerfully, incorporating Google\u2019s many \nother services, from the various Google location-based services (Google Earth, \nGoogle Maps, Google Streetview etc) which provide relevant localised advertising, to \ngmail, which uses the contents of email messages sent and received to generate even \nmore precisely targeted advertising. Other businesses have sought to emulate their \nsuccess \u2013 most immediately the social networking sites like MySpace and Facebook, \nwhich itself is now valued in the billions of dollars. As the business models have \ndeveloped, the tailoring has expanded to individualise not just advertising but the \ncontent of websites and the suggestions given (and the options provided) as to where \nto go next. For search engines, this means that not only the \u2018sponsored links\u2019 and \nadvertisements that appear around search results can be tailored to the searcher, but \nthat the results the searcher gets when they search for a particular term could be \ndifferent, or in a different order, than those that another person might get if they \nsearch for precisely the same term. Given that this is the way that most people \nnavigate the internet, this has a huge impact on what sites people become aware of \nand actually visit. \n \nThe most direct impact of this is that it \u2018fractures\u2019 the web (as shown in figure 1), \nmaking it potentially different for each and every individual user \u2013 and different in \nways that are controlled not by the user but by the content providers. Though this \nfracturing may appear to be just a side effect of the symbiotic collection of data but it \nis not: it has a direct impact on autonomy. Moreover, it demonstrates that the \nSymbiotic Web is not simply about the gathering of data: the data is gathered in order \nto be used, and that the fracturing is one of the most important results of its use. \n \n Page 3 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \n \n Page 4 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \n \nWeb 2.5 \u2013 not Web 3.0 \n \nThis shift of control from the user to the content provider is one of the things that \nmakes the Symbiotic Web different from most of the ideas presented as Web 3.0. \nThere is a good deal of confusion as to what is meant by Web 3.0 \u2013 and a great deal of \nuncertainty about the future of the World Wide Web. From most perspectives, though, \nthe fundamental change from Web 2.0 to Web 3.0 is that it is expected to put more \npower into the hands of the individual, allowing the individual to find what they want \nor need using \u2018intelligent agents\u2019 to scour the internet \u2013 building on Berners-Lee\u2019s \nconcept of the \u2018semantic web\u2019iv. If the concept of the Symbiotic Web is understood, \nthe future of the web seems both less unclear and less \u2018liberating\u2019 than these concepts \nsuggest. Despite the appearance of the individual taking more control, the reality \ncould be the opposite. Individuals can have their choices made for them, and control \ntaken out of their hands. In general, these choices are being made for benevolent \nrather than malevolent purposes, providing services and opportunities that users want \nand appreciate but the risks to autonomy and the potential for misuse are also clear. \n \nThe Symbiotic Web is already taking shape, using existing technologies such as \ncookies rather than requiring the development of new, intelligent software that may be \nyears or even decades away from practical existence. Moreover, the move towards the \nSymbiotic Web is driven by commercial imperatives rather than by the technological \nspeculation that appears to underlie the suggestions being made about the \ndevelopment of Web 3.0. That seems likely to make the symbiotic web a more \nprobable outcome than the visions of even people as eminent as Berners-Lee. \n \n \nThe make-up of the benign symbiosis \n \n(1) Search engines \n \nPerhaps the most important element of the symbiosis is the search engine. The Google \nbusiness model played a central role in the development of the Symbiotic Web, a role \nthat is growing, as the business models of Google and the other search engines \nbecome increasingly sophisticated. They offer an excellent and crucial service to \ninternet users, and offer it for free: a key part of the benign symbiosis. The services \nprovided by search engines \u2013 and by Google in particular \u2013 are extremely good, and \nalthough the Google business model is dependent on targeted advertising it would not \nwork if Google search were not sufficiently good to command a huge user base. \n \nGoogle provides these services in exchange for gathering vast amounts of data. In \ntheir search logs search engines record not just the terms that are searched for and the \nlinks that are followed as a result of such searches, but the time and location of the \nsearch and other details. This can give a very detailed picture of the searcher\u2019s \ninterests and habits, browsing style and so forth \u2013 and can be extremely significant in \nprofiling and targeting but also in working out how best to ensure that the searcher \nreads and follows particular links. Because search engines are used by unprecedented \nnumbers of people, they are able to analyse patterns and behaviour on an unparalleled \nscale, and use it to hone their profiling. Google and others use this most directly for \ntheir targeted advertising \u2013 and as much of this advertising is paid for on a \u2018pay per \n Page 5 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \nclick\u2019 basis, where advertisers only pay for an advertisement if a user actually clicks \non it, it is in the search engine\u2019s interest to convince users to click on the \nadvertisements. Google has been extremely adept at this \u2013 which is one of the reasons \nthat it has become one of the most successful corporations in the world. \n \n(2) Communications services \n \nCommunications was one of the primary initial uses of the internet, and it remains one \nof the most important. It has become a key part of the benign symbiosis, as most of \nthe communications services are provided to the user for free. This includes the large-\nscale web-based email services such as Google-mail, Microsoft\u2019s Hotmail, Yahoo \nMail and most instant messaging systems \u2013 such as ICQ, AIM, and Yahoo Messenger \n\u2013 and internet telephony services like Skype. These services often now incorporate \ndevelopments such as video conferencing which in the past were expensive, premium \nservices, and yet they are still in general provided for free \u2013 a prime example of the \nessentially benign nature of the symbiosis. \n \nWhen people communicate over the internet, significant amounts of data are gathered \nand held about that communication. \u2018Traffic data\u2019 the record of those that a user sends \nand receives messages or makes calls to and from, is kept by all communications \nproviders, while some providers keep records of the contents of the actual \ncommunications themselves. All these data are effectively exchanged for the free \nservices provided. \n \n(3) Social networking services \n \nSocial Networking services form another key \u2013 and rapidly growing \u2013 part of the \nsymbiosis. They provide a package of communications tools (including email, instant \nmessaging and so forth), networking tools, games and other forms of entertainment, in \na user-friendly form. The services they provide would in the past have only been \navailable in highly expensive \u2018group-ware\u2019 that was effectively only accessible to big \nbusiness. It is now available to anyone, and for free. Services like Facebook, \nMySpace and Bebo are considered central to the \u2018Web 2.0 phenomena\u2019, but it might \nbe more appropriate to call them \u2018Web 2.5 applications\u2019, for the data-gathering side of \ntheir business is in many ways just as significant as the \u2018social networking\u2019 function. \nSocial networking sites are \u2018free\u2019 to the user, yet worth billions of dollars to the \nowners through their ability to advertise and through the accumulated value of the \ndata that their users supply \u2013 which makes them perfect examples of the kind of \nsymbiosis that characterises the Symbiotic Web. \n \nWhat social networking sites do, effectively, is ask their users to profile themselves. \nUsers put in biographical data, educational data, information about their careers, their \ntastes in everything from music and food to religion, politics and relationships. In \nFacebook some of the most common \u2018applications\u2019 are questionnaires and quizzes, all \nseemingly for amusement, but in reality allowing Facebook and its advertisers to put \ntogether more detailed information about the user. Further to that, Facebook knows \nwho his or her friends are, so can link these data to such friends, giving another \ndimension to the possibilities \u2013 the simplest examples include telling the user what \ntheir friends\u2019 favourite books and movies are, or informing the user that one of their \nfriends has just started playing a particular game online. The profiles generated from \n Page 6 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \nall these forms of \u2018social data\u2019 are currently used primarily for targeted advertising \u2013 \nand also to help expand the service, providing scope for further advertising, more \nusers, and ultimately to make the company itself more valuable, at least in part \nbecause of the value of the enormous amount of data that they own. \n \n(4) ISPs \n \nInternet Service Providers (\u2018ISPs\u2019) play a key part in the Symbiotic web. Though they \ndo not generally provide their services for free, prices for Internet access have \ndropped dramatically, and sometimes internet access is \u2018bundled\u2019 with other services \nin a way that can be presented as free. It may be that they are also being used as \u2018loss \nleaders\u2019 \u2013 perhaps in part because providers realise that the potential benefits from the \ndata that may be gathered outweigh the relatively small costs involved in providing \nthe service. \n \nThe most significant data type gathered by ISPs is \u2018clickstream data\u2019 \u2013 effectively the \nrecord of the clicks made when browsing the web. Just as for search data, clickstream \ndata isn\u2019t simply a record of what clicks are made but when, where from, and so forth.  \nThe economic benefits derivable from clickstream data have yet to be exploited as \nfully as Google and others have exploited search data, but the potential is clear \u2013 \nbusiness models like Phorm, which is discussed below, are just the starting point. \n \n(5) Commercial websites \n \nCommercial websites such as Amazon and eBay are some of the most successful and \nattractive sites on the Internet \u2013 and are another key element of the Symbiotic Web. \nThough they do not provide their services for free, they do usually offer significant \ndiscounts to the prices that would be paid if their products were acquired in the offline \nworld. In addition, they provide a level of convenience that would not previously have \nbeen possible. \n \nDirect shopping sites such as Amazon gather data of two distinct kinds: transaction \ndata relating to goods and services that have been bought or bid for, and \u2018interest\u2019 \ndata relating to goods and services that have been looked at or researched on their \nsites. Both are useful in determining possible future sales \u2013 and the latter can include \nclickstream data, including details like the timing between clicks and so forth, which \ncan be used for profiling and to predict behaviour. Van den Poel and Buckinx, have \nfound that detailed clickstream data was the best indicator of future online-purchasing \nbehaviourv. In particular, they found that it was a significantly better indicator than \nthe actually purchases made \u2013 the information that users might reasonably believe \nwas used by online stores. \n \nThe two types of data have very different characteristics when considering privacy \nand autonomy \u2013 it is difficult to imagine that shoppers really understand that their \nbrowsing is being monitored and recorded as closely as their actual transactions. It is \nreasonable to expect the real transactions to be recorded and used for marketing \u2013 but \nquite possibly unreasonable for the rest of the browsing to be taken into account in the \nsame way. Whether it is reasonable for either of these types of data to be passed on to \nthird parties for aggregation or other commercial use is another question entirely. \n \n Page 7 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \n(6) The rest of the web \n \nThe most significant individual elements of the Symbiotic Web have been described \nabove: the search engines, the communications providers, the social networking \nservices, the commercial websites, and the ISPs. However, to a certain extent the \nsymbiosis covers the majority of the web. The pure \u2018information providers\u2019 generally \nsupply their information for free.  There are all kinds of other free services available, \nfrom \u2018geographical\u2019 services like the google location services mentioned earlier and \nthe various street finder systems to the recreational services like YouTube and its \nequivalents. New kinds of services are evolving all the time \u2013 and a large proportion \nof them are free, built on business models using data gathering and targeted \nadvertising. \n \nThe data gathered by these services varies enormously. First of all, controllers of \nwebsites can gather the clickstream data that relates to their own sites \u2013 when people \narrive at their site, they can gather information such as where they have come to the \nsite from and all the clicks once they arrive, including where they go to next. Then \nthere are the more specific data related to the service provided \u2013 for geographical \nsites, where people are looking at; for media sites like YouTube the tastes people have \nin music and video; for sports sites what sports and teams they follow; and so forth. \nAll of these data can help in building up profiles and in targeting advertisements. \n \n \nThe risks of a malign symbiosis \n \nThe Symbiotic Web is currently an essentially positive thing, providing benefits for \nindividuals, for business, and potentially for society as a whole. Nevertheless, there \nare significant risks associated with the symbiosis. The starting point is the \nunderstanding that personal information has a commercial value, which has led \norganisations to gather more and more data, not just for specific current or planned \nuses, but speculatively, based on an assumption that new uses and new values will be \nfound for these data.  \n \nNot only are more data gathered, but there is pressure to find new and different ways \nto gather the data. As these data are gathered, the organisations are looking for more \nways to use the information they have \u2013 if a business has an asset, it will want to get \nas much commercial value from it as it can. The more competitive the market, the \nmore attempts there will be to squeeze the maximum value out of the data. New \nbusinesses are developing for aggregation of data and profile generation \u2013 not only to \nmake money from the existence of the new data, but also to find even more effective \nways of using such data for other businessesvi. \n \nBeacon and Phorm \n \nThe Facebook Beacon affair and the Phorm business concept are two examples of \nthese phenomena. They demonstrate some of the possibilities that are being explored \nby businesses to exploit not only the nature of the data that is being gathered but the \npotential that a computer network can provide for such exploitation. \n \n Page 8 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \nBeacon is an advertising system developed by Facebook, a method by which \nFacebook exploits the commercial value of the data it gathers about its users. Beacon \nallows Facebook to share personal data with a number of online retail \u2018partners\u2019 \u2013 \nreceiving the data gathered by those retailers in exchange. The Beacon system was \noriginally intended to be to all intents and purposes a covert system, and an \u2018opt out\u2019 \nsystem \u2013 all Facebook users were intended to be included unless they found out about \nit and specifically asked not to be included. That in itself raises a lot of issues \u2013 the \nthorny issue of consent to start with \u2013 but it also demonstrates how these kinds of \ncommercial alliances can be formed. Members of the alliance would quite naturally \nwish to be mutually supportive \u2013 and hence do their best to support each other to the \ndetriment or exclusion of competitors. This is just normal business practice \u2013 but if \nsimilar systems were extended onto search engines it is easy to see how conflicts of \ninterest might result in unfair or misleading search results \u2013 and consequent \nmanipulation of how people navigate the web. \n \nThe reality behind Beacon was discovered before it came into action, and the privacy \nissues surrounding it raised such a furore that Facebook was forced to change it \nsignificantly it before it was implemented, making it opt-in rather than opt-out, \namongst other things.vii The changes forced by users are revealing, in two particular \nways. Firstly, it demonstrates why companies often keep the real reasons for their data \npolicies and practices effectively secret from most of their users \u2013 for when users find \nout what is going on, they often object, and object strongly. Secondly, it suggests \nsome of the possible ways to change things \u2013 firstly by raising awareness of practices \nso there are more objections; secondly by making it harder for companies to keep \nsuch practices secret; and thirdly by making it harder for companies to use practices \nwhich do not require real express, informed consent, of an \u2018opt in\u2019 rather than \u2018opt \nout\u2019 form. \n \nPhorm is another example of how these kinds of alliances can form, and the impact \nthey can have. Through Phorm, some of the UK\u2019s biggest ISPs are effectively \nintending to analyse individuals\u2019 browsing behaviour to allow potential advertisers to \ntarget users. Effectively, Phorm is intending to harness the value of clickstream data \nPhorm raises a plethora of legal, ethical and commercial issues, as it effectively \nmonitors a user\u2019s entire online activities, and as such has been challenged as a \npossible breach of wiretapping regulations, as a breach of data protection legislation \nand as another step towards a surveillance societyviii. It is also being seen by some as \nan interference with other websites\u2019 commercial interests \u2013 it could, for example, \ngather all the search data entered into the Google search page before Google \nthemselves gather it. \n \nThe issues raised by Phorm are complex and concerning in many ways. Its \nimportance, however, is not just in its current functions but in what it implies about \nwhere the symbiotic nature of the web might cause it to go, and how, as noted above, \nthe competitive drives that underpin the Symbiotic Web will manifest themselves in \nmore and more imaginative and potentially risky ways of using \u2013 and exploiting \u2013 the \ndata that are being gathered. Phorm, however, has recently had a serious setback. BT, \none of the key ISP members of their alliance, has withdrawn from Phorm, and though \nthey suggest that their withdrawal is about other resource prioritiesix, it is difficult to \nescape the conclusion that as with Beacon there is a connection with the furore \ngenerated by the public exposure of privacy issues. \n Page 9 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \n \nTailoring and profiling \n \nAnother key set of risks arise through the process of \u2018tailoring\u2019 of web pages for \nindividuals, which is one of the fundamental features of the Symbiotic Web. As \nbusinesses learn more about their customers \u2013 and are able to derive more information \nthrough profiling and data aggregation \u2013 they are able to \u2018tailor\u2019 services even more. \nThis tailoring can include such potentially pernicious practices as price or service \ndiscrimination. If a business can learn enough about a customer to know how much \nthey might be willing to pay for something \u2013 which becomes more and more possible \nas they gather more data about that customer, then they can set prices (and display \nthose prices on their web pages) individually for that customer. With the development \nof the Symbiotic Web, companies can potentially learn much more about their \ncustomers than ever before \u2013 and not just the kind of information that the customer \nwants them to know. Information such as social class, salaries earned, home \nownership, purchasing history from other businesses and so forth can be available \nthrough data aggregation,x or via commercial alliances such as those already forming \nthrough Beacon and Phorm. Profiling techniques, together with the increase in \navailable information, can allow companies to predict with increasing accuracy not \njust what their customers might be persuaded to buy, but how much they might be \nwilling to pay for it \u2013 and this in itself has its problems. The idea of \u2018price \ndiscrimination\u2019 might just seem like good business practice \u2013 offering better prices to \nregular customers and so forth \u2013 but it has a downside as well. Raising prices for \npeople who have a more desperate need for something, or who might be more \nsusceptible to a particular form of persuasion, or simply less intelligent, is not \nnecessarily a good thing. All of this becomes possible in the Symbiotic Web \u2013 and as \nthe competition between businesses grows, and as the availability of data and the \ntechnical and technological capabilities for processing it become better and more \navailable, the drives to use it become stronger. The likelihood of this parasitic use of \npersonal data will increase if things continue along their current path. \n \nAs noted above, tailoring applies not only to content, but to links provided, which \nultimately results in the personalisation of the web experience, the \u2018fracturing\u2019 of the \nweb. This brings with it a further set of risks. The Internet that a user is \u2018exposed\u2019 to \nis becoming one that is controlled for them in ways that ensure that a user only sees \nthing that people think that they will like \u2013 they know the user\u2019s tastes, who their \nfriends are, what kind of work they do, the kind of music they like and movies they \nwatch, and present to them only those things that they think the user will be interested \nin. Personalised news pages will cover the topics the news providers \u2018know\u2019 the user \ncares about, possibly only from the news sources that they \u2018know\u2019 the user trusts. The \nproducts and services offered for the user to buy will be only those that match the \nprofile that sellers have built up of the user \u2013 from the point of view of the seller this \nmakes perfect sense, since these are the products the user is most likely to buy. The \nevents, TV shows and movies that the user is told about are similarly chosen to suit \nwhat is known about them \u2013 again, something that makes perfect sense to the \nproviders. When the user searches for something, the search results, too, are chosen \nwith what the search engine knows about the user, what the user likes and what the \nuser is interested in. \n \n Page 10 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \nThe result may be something instantly attractive to the user \u2013 and something \ncomfortable and unthreatening. We\u2019ll like almost everything we see, and never know \nwhat else we\u2019re missing. It is vastly less positive and stimulating than the current \nversion of the Internet \u2013 a \u2018sanitised\u2019 version of the Internet, where the chances of \ncoming across something surprising and really new are limited. \n \nBack-door Balkanisation \n \nOne particularly pernicious version of this kind of thing is a phenomenon that can be \ndescribed as \u2018back-door Balkanisation\u2019, to extend Sunstein\u2019s metaphor from \nRepublic.comxi. Sunstein discussed how the internet could have a tendency to \npolarize opinion and create niches with narrow and potentially extreme political views \nor interests. Whilst Sunstein writes about a phenomenon that takes place through the \nchoices made by the individuals, what could potentially happen through the \nSymbiotic Web would be without the knowledge or understanding of the user, let \nalone through any kind of conscious or even subconscious choice \u2013 Balkanisation \nthrough the back door. Effectively, if through their profile that user is deemed to hold \na particular political, religious or ideological stance, this kind of system could drive \nthat user into a more extreme version of that stance, with dangers not only for the \nindividual but also for society as a whole. The fact that it happens automatically \nmakes it even more pernicious, and potentially even more dangerous than the \nphenomenon described by Sunstein. Sunstein\u2019s theories have been much criticisedxii \u2013 \nbut as a significant part of that criticism rests on the rights of the individual to make \nhis or her own choices, the back-door Balkanisation that accompanies the Symbiotic \nWeb is something quite different, and something that needs to be considered \nseriously. Taking this a step further, there is the potential for individual service \nproviders and web providers to make conscious, pernicious choices in particular ways \n\u2013 effectively checking profiles of users before deciding what kind of information to \nprovide. Nightmare visions such as \u2018whites-only websites\u2019, which check visitors\u2019 \nprofiles to determine whether they should be allowed to see certain content, will be \nboth a technical and practical possibility in the near future \u2013 and draw a stark contrast \nwith the anonymity that used to exist in the early days of the web when, to paraphrase \nthe famous cartoon in the New Yorker \u2018nobody knew you were a dog\u2019xiii. \n \nCommunications and other risks \n \nThere are also risks associated with particular data types being gathered. \nWith communications data, for example, where data such as the content of \ncommunications are held, even if the primary use is simply for targeting advertising \nand commercial profile building, there is the potential for misuse. Wherever and \nhowever they are held, data can be vulnerable, so it is not just what the \ncommunications provider might do with that data that is of concern, but what more \nmalign potential users might do with it. Security and privacy of communications is a \nkey human right, particularly in times and places of political oppression. The well-\npublicised examples of cyberdissidents being imprisoned in China as a result of \ninformation provided by Yahoo as to their communications are just some of the \npossible problems in this area.   \n \nIt should also be remembered that whilst there are particular issues concerning each of \nthe data types discussed above, the overall effect is greater than the sum of the \n Page 11 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \nindividual parts. Google, for example, combines the information gathered by search \nwith that gathered on gmail, through Google Maps, Google StreetView, Google Earth \nand so forth. The opportunities for profiling, for aggregation and for other forms of \nresearch multiply as more data becomes available. \n \nThe burgeoning market in data \n \nPerhaps the most significant result of the Symbiotic Web, however, is simply the \nburgeoning market in data \u2013 one about which users are largely unaware. Businesses \nare becoming acutely aware of the value of gathering data, but at the same time \nevidence suggests that when customers are aware that their data are being gathered for \nsuch purposes, they don\u2019t like it \u2013 the reactions to the Facebook Beacon affair and the \nemergence of Phorm are two pieces of evidence to support this. It is often far from \nclear and even when it is clear the true uses to which the data are being put are rarely \nrevealed. \n \nThe very existence of this massive quantity of data represents a risk \u2013 digital \ninformation, wherever it is and however it is stored, is vulnerable, whether from \nhacking, inadvertent or inappropriate selling or giving away of data, hardware and \nsoftware failure, hardware theft or loss, administrative or security failures. Once the \ndata have been \u2018lost\u2019, the potential for criminal misuse is huge \u2013 already crimes like \nidentity theft and other forms of financial fraud are a significant problem. As new \nkinds of information become available \u2013 particularly profiling information \u2013 the \npotential for better-targeted and more pernicious identity-related crimes increases \ndramatically. Furthermore, the existence of the data makes it tempting for those who \nhave access to it to find new uses for it \u2013 uses that are not necessarily in character or \nproportional to those for which the data was gathered. This \u2018function creep\u2019 has been \nparticularly evident in recent years in relation to data gathered for anti-terrorism \npurposes \u2013 a notable example was the use of the Regulation of Investigatory Powers \nAct (RIPA), which was presented as a means to tackle terrorism and other serious \ncrimes, to deal with dog fouling. Function creep may come into play for commercial \nreasons even more often that it does for security or law-enforcement purposes, and is \na significant risk whenever data are held, so the more data are being held, the greater \nthe risk. \n \nRegulating the Symbiotic web \n \nIf these various risks are not addressed, many of the best features of the existing \nInternet will be lost. The idea of a common knowledge base, the idea of somewhere \nthat people can speak and act freely \u2013 a system that can support dissidents and the \noppressed, encourage community and global interaction in a positive way, all these \nthings are under threat, as well as the privacy and autonomy of individuals. It is \ntherefore important that everything is done to ensure that the positive benefits and the \nessentially benign nature of the web symbiosis be maintained, and that the risks are \naddressed appropriately. \n \nFour possible approaches \n \nThe first option would be to try to break the dependence \u2013 to make the use of personal \ninformation in this kind of way impossible through stronger, better-enforced laws. \n Page 12 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \nCurrent data protection laws should theoretically be a good start \u2013 in particular, the \nprinciples of data minimisation, of using data only for a set, lawful purpose and not \nallowing further processing, and the need for express, informed consent before data \nare gathered or processed, could potentially provide a great deal of protectionxiv. In \nreality, however, they appear to fail to live up to their promise, whether through \nweakness of implementation or through poorly resourced enforcement. If sufficiently \nstrengthened and properly enforced, they could make a significant impact. This, \nhowever, could effectively mean the end of the Symbiotic Web, as many of the \nbusiness methods that have driven its development would become effectively illegal. \nNot only might this mean giving up all the positive aspects of what is a benign \nsymbiosis, but it would mean having to come into conflict with very powerful \nbusiness interests, which would be difficult to say the least. \n \nThe second, and converse approach would be to try to change the paradigm and \u2018give \nup\u2019 on privacy to a great extent. Former Sun MicroSystems CEO Scott McNealy \nfamously said \u2018you have zero privacy, get over it\u2019 \u2013 should his advice simply be \nfollowed? It could be an option to accept the trade in personal data, encourage \npersonalisation, and deal with the consequences by penalising excessive or \ninappropriate use and encouraging understanding in the general public. Though it \nmight appear a purely pragmatic and somewhat disturbing solution, it might end up \nwith something beneficial \u2013 allowing openness and information both ways, so that \ncitizens know more about governments, and customers more about business, to \nmutual benefit, as suggested by writers such as David Brinxv. Though these ideas are \nattractive, reality, as shown by Phorm and Beacon amongst others, suggests that at \npresent people are not in general attracted by this kind of solution \u2013 and businesses do \nnot seem willing to show much transparency themselves. \n  \nThe third approach would be to do very little, and allow markets and norms to redress \nthe balance. There are some signs that this kind of approach might work \u2013 Apple\u2019s \nmovement away from the use of DRMs on iTunes and their shifts in approach for \ntheir \u2018genius\u2019 system suggest that this might be possible. The intervention of \nlawmakers, however, might be said to have produced even better results. Google has \nreduced the time that it holds onto individualised server logs of search data from an \nunlimited time first to 18 months, then to 9 months, to a great extent because of the \npressure exerted by the Article 29 Working Party. \n \nThe fourth and perhaps the best approach, is to weaken the dependence. To \u2018loosen\u2019 \nthe symbiosis and strengthen the rights of the individuals \u2013 particularly in terms of \nconsent and rights to be informed. This would alter the balance, but still allow the \nmutually beneficial symbiosis. It could be brought about through a combination of \nlegal, technological and other measures \u2013 a strengthening and rationalisation of data \nprotection as mentioned above, more \u2018privacy friendly\u2019 browsers and other software \nand so forth. \n \nNew business models \n \nThe key, however, to this fourth approach will need to come from business. Just as \nthe movement towards the Symbiotic Web was driven by a new business model \u2013 the \nGoogle personal data\/targeted advertising model \u2013 the movement to moderate it and \nkeep it benign will in all likelihood require the same. If a new business model, not \n Page 13 \nPaul Bernal Web 2.5: the Symbiotic Web October 2009 \ndependent on the gathering and use of personal data \u2013 or using it in less intrusive, less \nmanipulative ways \u2013 could be developed, that could lead us in a more positive \ndirection. This may already be happening \u2013 Google\u2019s acceptance of a reduction of \ndata retention periods might be because they\u2019re developing a different model for their \nbusiness \u2013 but pressure from lawmakers, the computer and hacker communities, and \nmost importantly from users, could make this happen faster. What is more, as Google \nand others become more aware of their place in the symbiosis, and of the way in \nwhich maintaining the benign nature of the symbiosis benefits them as well as the \nindividuals, they can become drivers towards positive solutions, rather than seeking to \ndelay or block them.  \n \n \n                                                 \ni Not all Web 2.0 sites rely upon user generated content. Sites such as Hulu supply \ncommercially produced content but still rely on what can be called Web 2.5 data \ngathering techniques.  \nii In his interview on http:\/\/www.videojug.com\/interview\/stephen-fry-web-20#can-\nyou-define-it  \niii See for example \nhttp:\/\/www.bbc.co.uk\/blogs\/technology\/2008\/04\/google_how_big_is_too_big.html  \niv See T Berners-Lee and M Fischetti, Weaving the Web: The Original Design and \nUltimate Destiny of the World Wide Web by its Inventor (1st pbk. ed edn, \nHarperCollins Publishers, New York 2000), particularly pp169-170.  \nv D Van den Poel and W Buckinx, 'Predicting online-purchasing behaviour'166 (2) \nEuropean Journal of Operational Research 557 \nvi Discussed in I Ayres, Super Crunchers: How Anything Can Be Predicted (John \nMurray, London 2007) \nvii For a summary of the reasons for the changes to the system from Facebook\u2019s \nperspective, see http:\/\/blog.facebook.com\/blog.php?post=7584397130  \nviii See http:\/\/www.phorm.com\/ and see http:\/\/www.fipr.org\/080423phormlegal.pdf \nfor the Foundation for Information Policy Research\u2019s legal analysis of the Phorm \n\u2018Webwise\u2019 system. \nix See for example http:\/\/news.bbc.co.uk\/1\/hi\/technology\/8135850.stm  \nx See Ayres pp33-34. As Ayres puts it, \u2018\u2026because of Super Crunching, firms \nsometimes may be able to make more accurate predictions about how you\u2019ll behave \nthan you could ever make yourself.\u2019 \nxi See CR Sunstein, Republic.com 2.0 (Princeton University Press, Princeton 2007) \nxii Perhaps his strongest critic is Eugene Volokh, of the Volokh Conspiracy blog \n(http:\/\/www.volokh.com\/), but there has also been criticism in print, e.g. D Hunter, \n'Philippic.com'90 California Law Review 70  \nxiii From Peter Steiner\u2019s cartoon in the New Yorker, published in 1993 \nxiv See Directive 95\/46\/EC, particularly Articles 6 and 7 \nxv Most notably in D Brin, The Transparent Society: Will Technology Force Us to \nChoose Between Privacy and Freedom? (Addison-Wesley, Reading, Mass. 1998) \n Page 14 \n"}
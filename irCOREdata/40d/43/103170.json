{"doi":"10.1016\/j.inffus.2009.04.003","coreId":"103170","oai":"oai:epubs.surrey.ac.uk:3028","identifiers":["oai:epubs.surrey.ac.uk:3028","10.1016\/j.inffus.2009.04.003"],"title":"Editorial: Special Issue on Biologically-Inspired Information Fusion","authors":["Casey, MC","Damper, RI"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-01","abstract":null,"downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"ELSEVIER SCIENCE BV","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:3028<\/identifier><datestamp>\n      2017-10-31T14:07:34Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:436F6D707574696E67<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/3028\/<\/dc:relation><dc:title>\n        Editorial: Special Issue on Biologically-Inspired Information Fusion<\/dc:title><dc:creator>\n        Casey, MC<\/dc:creator><dc:creator>\n        Damper, RI<\/dc:creator><dc:publisher>\n        ELSEVIER SCIENCE BV<\/dc:publisher><dc:date>\n        2010-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:rights>\n        attached<\/dc:rights><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/3028\/2\/Guest%20Editorial.pdf<\/dc:identifier><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/3028\/4\/licence.txt<\/dc:identifier><dc:identifier>\n          Casey, MC and Damper, RI  (2010) Editorial: Special Issue on Biologically-Inspired Information Fusion   INFORM FUSION, 11 (1).  pp. 2-3.      <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1016\/j.inffus.2009.04.003<\/dc:relation><dc:relation>\n        10.1016\/j.inffus.2009.04.003<\/dc:relation><dc:language>\n        EN<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/3028\/","http:\/\/dx.doi.org\/10.1016\/j.inffus.2009.04.003","10.1016\/j.inffus.2009.04.003"],"year":2010,"topics":[],"subject":["Article","NonPeerReviewed"],"fullText":"Guest Editorial \nSpecial Issue on Biologically-Inspired Information Fusion \nDesign, implementation and effective deployment of artificial cognitive systems is an exciting area that \nis rapidly developing into a multi-disciplinary subject with the potential for significant impact on \nscience, engineering and society in general. Since we are in a very real sense trying to mimic the \ndesirable behavior of humans and (perhaps) other animals, particularly with respect to their adaptability \nand robustness, there is considerable interest in understanding how knowledge of natural systems may \nhelp us to apply biological strategies to artificial systems. At the same time, drawing on a \ncomputational metaphor for perception and cognition, developing new computational and algorithmic \ntechniques might allow us to understand natural systems better. Of particular interest to this journal are \nnew approaches to building adaptive information fusion systems. Can knowledge of biological \nmultisensory processing help develop robust fusion schemes? Can we use biological or behavioral \nmodels to help us understand how and why multisensory integration occurs in animals and humans? \nThese ideas in part are borne out of the recent movement to bring together the life and physical \nsciences to promote cross-dissemination of ideas so as to kick-start new avenues of research (perhaps a \nreaffirmation of existing approaches). An example of this movement was the UK Government\u2019s \nForesight Cognitive Systems Project in 2002-2003, which attempted to set priorities in this area \n(summarized in [3]), focusing on four grand challenges: memories for life, localization in animals and \nartificial systems; the role of rhythmic activity in the brain; and neurocomputational approaches to \nspeech and language. One simple message from these is that both neuro- and computational scientists \nhave something to gain from working together, whether that is new tools to model biology and to test \nhypotheses not so easily tested in vivo, or knowledge of biological processing that can inform new \ncomputational paradigms. \nIn natural systems, the integration of sensory information has an effect prior to birth and remains \nimportant throughout development (see the review in [1]). Here then, through a better understanding of \nthe structures and processes involved in this natural adaptive integration, we may be able to construct a \ntruly artificial multisensory processing system. The hope is that psychological and physiological \nknowledge of multisensory processing, and particularly the low-level influence that different modalities \nhave on one another, can be used to build upon existing theoretical work on computational mechanisms \nto design and implement systems that can fuse together different information sources. \nIn August 2006, a Workshop was held on Biologically-Inspired Information Fusion at the University of \nSurrey, UK, with the aim of bringing together researchers from the different disciplines interested in \nnatural and artificial multi-sensory processing. The location was very appropriate, considering that this \nuniversity was where McGurk and MacDonald first studied the remarkable effects on speech \nperception (\u2018lip-reading\u2019) of setting audio and visual cues in opposition [2]. The Workshop focused on \nhow we can improve our understanding of sensory fusion within the context of computational systems \nthat can learn to integrate information. Here, biologists, psychologists, computer scientists and robotics \nengineers were brought together to see what could be gained from cross-dissemination, not only in \nterms of learning about current research, but also to set priorities for future work. Particular emphasis \nfor the future was laid on: \n1. Sensory fusion, disorder and clinical application: How can we develop machine aids in the \nform of implants or prosthetics to overcome or reduce the effects of disorders? \n2. Exploiting effective biological processes for sensory integration: What biological processes can \nbe exploited for improved performance by computer systems? \n3. Developing a common language for inter-disciplinary communication and collaboration. \nIn this Special Issue, based on extended versions of papers presented at the Workshop, we provide \nexamples of how work towards these priorities is already underway. By its very nature, this work is \ncross-disciplinary. As such, we present six articles, two based on psychology and four on computer \nscience. Of these, we range from a state-of-the-art review of audiovisual integration for speech \nperception, through the application of mathematical principles to improve our understanding in \npsychophysics, to the description of biologically-inspired algorithms for fusion. \n \nThe Special Issue starts with \u201cAssessing the role of attention in the audiovisual integration of speech\u201d. \nHere, Navarra et al. consider if an attentional process has a role in the audiovisual understanding of \nspeech. For example, in a film dubbed into a second language, does attention help filter out the lip \nmovements of speech in the original versus the dubbed language? If such a process does influence \nspeech recognition, then computationally this could help us develop task-based fusion schemes, as well \nas give insight into multimodal speech recognition. \nIn \u201cApplying capacity analyses to psychophysical evaluation of multisensory interactions\u201d, \nHugenschmidt et al. present a mathematical analysis of multisensory integration data obtained from \npsychophysical experiments on humans. By applying capacity analyses, they attempt to compare what \nbenefit integration can give over unisensory processing, as compared in different age groups \nperforming a simple task. The task presented a red or blue visual (colored circle) or auditory stimulus \n(spoken color word), interspersed with congruent visual and auditory multisensory stimuli. This paper \nhighlights the focus of activity in neuroscience research into multisensory stimuli\u2014we understand that \nthe integration of such stimuli is prevalent in natural cognitive systems, but not how it develops or \nchanges. \nThe article \u201cInformation Fusion for Anomaly Detection with the Dendritic Cell Algorithm\u201d by \nGreensmith et al. considers a biologically-inspired algorithm for data fusion. The authors present a \ndevelopment of the dendritic cell model, inspired from biological immune system processes. Working \ndirectly from biological data, an algorithm is developed for anomaly detection that fuses different data \nsources. As a proof-of-concept, it is applied to recognition of port scans, a key tool in initiating attacks \non computer system integrity, and frequently used in \u2018insider attacks\u2019. \nThis theme of exploiting immune system analogies to design new approaches to computer security is \ncontinued in \u201cInformation Fusion in the Immune System\u201d by Twycross and Aickelin. The paper \npresents a succinct summary of some of the biological information fusion mechanisms seen in the \nhuman immune system, and describes how these mechanisms have been implemented as artificial \nimmune systems (AISs). Twycross and Aickelin continue to describe an anomaly-based intrusion \ndetection system able to adapt to changing patterns of normal computer usage behaviour. \nIn \u201cMotion Extrapolation of Auditory-Visual Targets\u201d, Wuerger et al. undertake a psychophysical \nstudy of auditory and visual information fusion. Specifically, they investigate the extent to which the \nsimultaneous presentation of auditory and visual signals enhances the estimation of motion speed and \nprediction of instantaneous position of a target by human observers. Observers\u2019 performance is found \nto improve significantly when input from both the visual and auditory modality is available. Results are \npresented in terms of variability of arrival-time judgement and the bias in this judgement. The \nvariability observed is consistent with optimal integration of the auditory and visual speed signals, in \nthat the bimodal variability is minimal given the unimodal variances. Bias is found to be dependent on \ntarget speed and independent of modality, suggesting it is not due to motor control. \nContinuing with the emphasis on psychophysical methods, Dixon et al. employ eye-tracking measures \nto study the effectiveness of image fusion in \u201cScanpath Assessment of Multi-Sensor Video Fusion in \nComplex Scenarios\u201d. Here, the term \u201cScanpath\u201d refers to the specific sequence of eye movements \nassociated with viewing a certain visual representation. Noting that the integration of visible light and \ninfrared (IR) representations occurs naturally in some animals (e.g., the rattlesnake), the authors \nexplore different ways of fusing and presenting visible and IR information about walking human \ntargets in cluttered environments, using the scanpath technique to quantify accuracy of detection and \nreaction times. \nThe Guest Editors hope that you find reading about this mixture of disciplines interesting and helpful. \nOne of the challenges in bringing together different domains has been to unify some of the \nterminology, or at least provide explanations as required. We know there is a long way to go before life \nand physical scientists are in a position to work together seamlessly; language and cross-discipline \ntraining being just two of the barriers that need to be overcome. We would like to think that this Special \nIssue goes some way towards crossing these barriers, providing examples of how the community\u2019s \npriorities are already being addressed. \nLet us return to the two questions we asked at the beginning. First, can knowledge of biological \nmultisensory processing help develop robust fusion schemes?  Four articles in this Special Issue give \nexamples of how this is currently being achieved. Second, can we use biological or behavioral models \nto help us understand how and why multisensory integration occurs in animals and humans? More is \nyet to be done here, but two of the articles herein show how work in this area is progressing. \nMatthew C. Casey \nDepartment of Computing, \nUniversity of Surrey, Guildford, \nSurrey, GU2 7XH, UK \nE-mail address: m.casey@surrey.ac.uk \nRobert I. Damper \nSchool of Electronics and Computer Science, University of Southampton, \nSouthampton, SO17 1BJ, UK \nE-mail address: rid@ecs.soton.ac.uk \nReferences \n[1] Lickliter, R. & Bahrick, L.E. (2004).  Perceptual Development and the Origins of Multisensory \nResponsiveness.  In Calvert, G. A., Spence, C. & Stein, B. E. (Ed), The Handbook of Multisensory \nProcesses, pp. 643-654.  Cambridge, MA.: A Bradford Book, MIT Press. \n[2] McGurk, H. & MacDonald, J. (1976).  Hearing Lips and Seeing Voices.  Nature, vol. 264(5588), \npp. 746-748. \n[3] Morris, R., Tarassenko, L. & Kenward, M. (2006).  Cognitive Systems: Information Processing \nMeets Brain Science.  London: Elsevier Academic Press. \n"}
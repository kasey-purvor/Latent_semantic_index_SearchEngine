{"doi":"10.1332\/174426411X603470","coreId":"197759","oai":"oai:lra.le.ac.uk:2381\/10043","identifiers":["oai:lra.le.ac.uk:2381\/10043","10.1332\/174426411X603470"],"title":"The challenges of evaluating large-scale, multi-partner programmes: the case of NIHR CLAHRCs","authors":["Martin, Graham P.","Ward, Vicky","Hendy, Jane","Rowley, Emma","Nancarrow, Susan","Heaton, Janet","Britten, Nicky","Fielden, Sandra","Ariss, Steven"],"enrichments":{"references":[{"id":43730490,"title":"A review of UK health research funding, London: The Stationery Office.","authors":[],"date":"2006","doi":"10.1136\/bmj.39059.444120.80","raw":"Cooksey, D., 2006. A review of UK health research funding, London: The Stationery Office.","cites":null},{"id":43730519,"title":"Achieving clinical behaviour change: a case of becoming indeterminate.","authors":[],"date":"1998","doi":"10.1016\/s0277-9536(98)00250-0","raw":"Wood, M., Ferlie, E. & Fitzgerald, L., 1998. Achieving clinical behaviour change: a case of becoming indeterminate. Social Science & Medicine, 47(11), pp.1729-1738.","cites":null},{"id":43730493,"title":"Action research for the study of organizations. In","authors":[],"date":"1996","doi":"10.4135\/9781446218556.n10","raw":"Eden, C. & Huxham, C., 1996. Action research for the study of organizations. In S.R. Clegg, C. Hardy, and W.R. Nord (eds), Handbook of organization studies, London: Sage, pp.526-542.","cites":null},{"id":43730492,"title":"An implementation research agenda.","authors":[],"date":"2009","doi":"10.1186\/1748-5908-4-18","raw":"Eccles, M. et al., 2009. An implementation research agenda. Implementation Science, 4(1), p.18.","cites":null},{"id":43730491,"title":"Best research for best health: a new national research strategy,","authors":[],"date":"2006","doi":"10.7861\/clinmedicine.6-5-435","raw":"Department of Health, 2006. Best research for best health: a new national research strategy, London: Department of Health.","cites":null},{"id":43730503,"title":"Complexity of sustaining healthcare improvements: what have we learned so far, London: NHS Modernisation Agency.","authors":[],"date":"2004","doi":null,"raw":"Modernisation Agency, 2004. Complexity of sustaining healthcare improvements: what have we learned so far, London: NHS Modernisation Agency.","cites":null},{"id":43730508,"title":"Developmental evaluation: applying complexity concepts to enhance innovation and use,","authors":[],"date":"2010","doi":"10.1002\/casp.2116","raw":"Patton, M.Q., 2010. Developmental evaluation: applying complexity concepts to enhance innovation and use, New York: Guilford Press.","cites":null},{"id":43730488,"title":"Dialogues between academics and practitioners: the role of generative dialogic encounters. Organization Studies,","authors":[],"date":"2010","doi":"10.1177\/0170840610374396","raw":"Beech, N., MacIntosh, R. & MacLean, D., 2010. Dialogues between academics and practitioners: the role of generative dialogic encounters. Organization Studies, 31(9-10), pp.1341 -1367.","cites":null},{"id":43730511,"title":"Do networks really work? A framework for evaluating public-sector organizational networks.","authors":[],"date":"2001","doi":"10.1111\/0033-3352.00045","raw":"Provan, K.G. & Milward, H.B., 2001. Do networks really work? A framework for evaluating public-sector organizational networks. Public Administration Review 61(4): pp.414-423.","cites":null},{"id":43730518,"title":"Evaluation: methods for studying programs and policies,","authors":[],"date":"1998","doi":"10.1016\/s0149-7189(01)00034-9","raw":"Weiss, C.H., 1998. Evaluation: methods for studying programs and policies, New Jersey: Prentice Hall.","cites":null},{"id":43730497,"title":"Evidence-based implementation of evidence-based medicine.","authors":[],"date":"1999","doi":"10.1111\/j.1547-5069.2008.00243.x","raw":"Grol, R. & Grimshaw, J., 1999. Evidence-based implementation of evidence-based medicine. Joint Commission Journal on Quality Improvement, 25(10), pp.503-513.","cites":null},{"id":43730498,"title":"Experiential learning,","authors":[],"date":"1984","doi":"10.4135\/9781452276090.n84","raw":"Kolb, D.A., 1984. Experiential learning, Englewood Cliffs, NJ: Prentice-Hall.","cites":null},{"id":43730510,"title":"How do you evaluate a network? A Canadian child and youth health network experience.","authors":[],"date":"2005","doi":null,"raw":"Popp, J.K., L\u201fHeureux, L.N., Dolinksi, C.M., Adair, C.E., Tough, S.C., Casebeer, A.L., DouglasEngland, K.L. & Morrison, C.C., 2005. How do you evaluate a network? A Canadian child and youth health network experience. Canadian Journal of Program Evaluation 20(3): 123-150.","cites":null},{"id":43730516,"title":"How good is the quality of health care in the United States? Milbank Quarterly,","authors":[],"date":"2005","doi":"10.1111\/j.1468-0009.2005.00403.x","raw":"Schuster, M.A., McGlynn, E.A. & Brook, R.H., 2005. How good is the quality of health care in the United States? Milbank Quarterly, 83(4), pp.843-895.","cites":null},{"id":43730515,"title":"Implementing health research through academic and clinical partnerships: a realistic evaluation of the Collaborations for Leadership in Applied Health Research and Care (CLAHRC).","authors":[],"date":"2011","doi":"10.1186\/1748-5908-6-74","raw":"Rycroft-Malone, J., Wilkinson, J.E., Burton, C.R., Andrews, G., Ariss, S., Baker, R., Dopson, S., Graham, I., Harvey, G., Martin, G., McCormack, B.G., Staniszewska, S. & Thompson, C., 2011. Implementing health research through academic and clinical partnerships: a realistic evaluation of the Collaborations for Leadership in Applied Health Research and Care (CLAHRC). Implementation Science 6:74.","cites":null},{"id":43730499,"title":"Mapping new theoretical and methodological terrain for knowledge translation: contributions from critical realism and the arts.","authors":[],"date":"2009","doi":"10.1186\/1748-5908-4-1","raw":"Kontos, P. & Poland, B., 2009. Mapping new theoretical and methodological terrain for knowledge translation: contributions from critical realism and the arts. Implementation Science, 4(1), p.1. Lave, J. & Wenger, E., 1991. Situated learning: legitimate peripheral participation, Cambridge: Cambridge University Press.","cites":null},{"id":43730514,"title":"Models and frameworks for implementing evidence-based practice: linking evidence to action,","authors":[],"date":"2010","doi":"10.1111\/j.1741-6787.2010.00194.x","raw":"Rycroft-Malone, J. & Bucknall, T., 2010. Models and frameworks for implementing evidence-based practice: linking evidence to action, Chichester: Wiley.","cites":null},{"id":43730517,"title":"Nothing as practical as good theory: exploring theory-based evaluation for comprehensive community initiatives for children and families.","authors":[],"date":"1995","doi":null,"raw":"Weiss, C.H., 1995. Nothing as practical as good theory: exploring theory-based evaluation for comprehensive community initiatives for children and families. In J. P. Connell et al., eds.","cites":null},{"id":43730495,"title":"Practice-based evidence for healthcare,","authors":[],"date":"2010","doi":"10.3399\/bjgp14x679822","raw":"Gabbay, J. & le May, A., 2010. Practice-based evidence for healthcare, London: Routledge.","cites":null},{"id":43730507,"title":"Program evaluation: forms and approaches,","authors":[],"date":"2007","doi":"10.1177\/109821409401500209","raw":"Owen, J.M., 2007. Program evaluation: forms and approaches, London: Guilford Press.","cites":null},{"id":43730509,"title":"Realistic evaluation,","authors":[],"date":"1997","doi":"10.4135\/9781412950596.n474","raw":"Pawson, R. & Tilley, N., 1997. Realistic evaluation, London: Sage.","cites":null},{"id":43730505,"title":"revisited: the new production of knowledge.","authors":[],"date":"2003","doi":null,"raw":"Nowotny, H., Scott, P. & Gibbons, M., 2003. \u201cMode 2\u201d revisited: the new production of knowledge. Minerva, 41(3), pp.179-194.","cites":null},{"id":43730512,"title":"Seeking conceptual clarity in the action modalities.","authors":[],"date":"2009","doi":"10.1080\/14767330902731269","raw":"Raelin, J., 2009. Seeking conceptual clarity in the action modalities. Action Learning: Research and Practice, 6(1), pp.17-24.","cites":null},{"id":43730513,"title":"Soft networks for bridging the gap between research and practice: illuminative evaluation of CHAIN.","authors":[],"date":"2004","doi":"10.1136\/bmj.328.7449.1174","raw":"Russell, J., Greenhalgh, T., Boynton, P. & Rigby, M., 2004. Soft networks for bridging the gap between research and practice: illuminative evaluation of CHAIN. British Medical Journal 328: pp.1174-1177.","cites":null},{"id":43730504,"title":"Sustainability model and guide,","authors":[],"date":"2005","doi":null,"raw":"NHS Institute, 2005. Sustainability model and guide, Coventry: NHS Institute for Innovation and Improvement.","cites":null},{"id":43730500,"title":"The in-between world of knowledge brokering.","authors":[],"date":"2007","doi":"10.1136\/bmj.39038.593380.ae","raw":"Lomas, J., 2007. The in-between world of knowledge brokering. British Medical Journal, 334(7585), pp.129-132.","cites":null},{"id":43730502,"title":"The limitations of public management networks.","authors":[],"date":"2011","doi":"10.1111\/j.1467-9299.2011.01917.x","raw":"McGuire, M. & Agranoff, R., 2011. The limitations of public management networks. Public Administration 89(2): 265-284.","cites":null},{"id":43730487,"title":"The National Institute of Health Research (NIHR) Collaboration for Leadership in Applied Health Research and Care (CLAHRC) for Leicestershire, Northamptonshire and Rutland (LNR): a programme protocol.","authors":[],"date":"2009","doi":"10.1186\/1748-5908-4-72","raw":"Baker, R. et al., 2009. The National Institute of Health Research (NIHR) Collaboration for Leadership in Applied Health Research and Care (CLAHRC) for Leicestershire, Northamptonshire and Rutland (LNR): a programme protocol. Implementation Science, 4(1), p.72.","cites":null},{"id":43730496,"title":"The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in Evidence & Policy. The definitive publisher-authenticated version is available online at:","authors":[],"date":"2011","doi":null,"raw":"\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in Evidence & Policy. The definitive publisher-authenticated version is available online at: www.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 Graham, I.D. et al., 2006. Lost in knowledge translation: time for a map? Journal of Continuing Education in the Health Professions, 26(1), pp.13-24.","cites":null},{"id":43730501,"title":"The quality of health care delivered to adults in the United States. New England","authors":[],"date":"2003","doi":"10.1056\/nejmsa022615","raw":"McGlynn, E.A., Asch, S.M., et al., 2003. The quality of health care delivered to adults in the United States. New England Journal of Medicine, 348(26), pp.2635-2645.","cites":null},{"id":43730489,"title":"Theory-driven evaluations,","authors":[],"date":"1990","doi":null,"raw":"Chen, H.-T., 1990. Theory-driven evaluations, Newbury Park, CA: Sage.","cites":null},{"id":43730506,"title":"Using evidence,","authors":[],"date":"2007","doi":"10.1332\/policypress\/9781861346650.003.0001","raw":"Nutley, S.M., Walter, I. & Davies, H.T.O., 2007. Using evidence, Bristol: Policy Press.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-11-01","abstract":"The limited extent to which research evidence is utilised in healthcare and other public services is widely acknowledged. The United Kingdom government has attempted to address this gap by funding nine Collaborations for Leadership in Applied Health Research and Care (CLAHRCs). CLAHRCs aim to carry out health research, implement research findings in local healthcare organisations and build capacity across organisations for generating and using evidence. This wide-ranging brief requires multifaceted approaches; assessing CLAHRCs\u2019 success thus poses challenges for evaluation. This paper discusses these challenges in relation to seven CLAHRC evaluations, eliciting implications and suggestions for others evaluating similarly complex interventions with diverse objectives.Peer-reviewedPost-prin","downloadUrl":"www.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006.","fullTextIdentifier":"https:\/\/lra.le.ac.uk\/bitstream\/2381\/10043\/6\/Martin_et_al_%282011b%29%5b1%5d.pdf","pdfHashValue":"38c2fd8a4281aab8a2a7aa224c3833b8d11d1af9","publisher":"Policy Press","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:lra.le.ac.uk:2381\/10043<\/identifier><datestamp>\n                2012-11-01T02:45:05Z<\/datestamp><setSpec>\n                com_2381_57<\/setSpec><setSpec>\n                com_2381_9550<\/setSpec><setSpec>\n                col_2381_58<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nThe challenges of evaluating large-scale, multi-partner programmes: the case of NIHR CLAHRCs<\/dc:title><dc:creator>\nMartin, Graham P.<\/dc:creator><dc:creator>\nWard, Vicky<\/dc:creator><dc:creator>\nHendy, Jane<\/dc:creator><dc:creator>\nRowley, Emma<\/dc:creator><dc:creator>\nNancarrow, Susan<\/dc:creator><dc:creator>\nHeaton, Janet<\/dc:creator><dc:creator>\nBritten, Nicky<\/dc:creator><dc:creator>\nFielden, Sandra<\/dc:creator><dc:creator>\nAriss, Steven<\/dc:creator><dc:subject>\nEVIDENCE-BASED PRACTICE<\/dc:subject><dc:subject>\nEVALUATION<\/dc:subject><dc:subject>\nKNOWLEDGE TRANSLATION<\/dc:subject><dc:subject>\nMETHODOLOGY<\/dc:subject><dc:description>\nThe limited extent to which research evidence is utilised in healthcare and other public services is widely acknowledged. The United Kingdom government has attempted to address this gap by funding nine Collaborations for Leadership in Applied Health Research and Care (CLAHRCs). CLAHRCs aim to carry out health research, implement research findings in local healthcare organisations and build capacity across organisations for generating and using evidence. This wide-ranging brief requires multifaceted approaches; assessing CLAHRCs\u2019 success thus poses challenges for evaluation. This paper discusses these challenges in relation to seven CLAHRC evaluations, eliciting implications and suggestions for others evaluating similarly complex interventions with diverse objectives.<\/dc:description><dc:description>\nPeer-reviewed<\/dc:description><dc:description>\nPost-print<\/dc:description><dc:date>\n2012-01-25T14:40:32Z<\/dc:date><dc:date>\n2012-11-01T02:45:05Z<\/dc:date><dc:date>\n2011-11-01<\/dc:date><dc:type>\nJournal Article<\/dc:type><dc:type>\nArticle<\/dc:type><dc:identifier>\nEvidence & Policy, 2011, 7 (4), pp. 489-509<\/dc:identifier><dc:identifier>\n1744-2648<\/dc:identifier><dc:identifier>\nhttp:\/\/www.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2381\/10043<\/dc:identifier><dc:identifier>\n10.1332\/174426411X603470<\/dc:identifier><dc:identifier>\n1744-2656<\/dc:identifier><dc:language>\nen<\/dc:language><dc:rights>\n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in Evidence & Policy. The definitive publisher-authenticated version Evidence & Policy, 2011, 7 (4), pp. 489-509 is available online at: www.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006.  The authors' post-print version should not be cited.<\/dc:rights><dc:publisher>\nPolicy Press<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["issn:1744-2656","1744-2648","1744-2656","issn:1744-2648"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2011,"topics":["EVIDENCE-BASED PRACTICE","EVALUATION","KNOWLEDGE TRANSLATION","METHODOLOGY"],"subject":["Journal Article","Article"],"fullText":"\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n1 \nThe challenges of evaluating large-\nscale, multi-partner programmes: the \ncase of NIHR CLAHRCs \nGraham P. Martin, Vicky Ward, Jane Hendy, Emma Rowley, Susan Nancarrow, Janet \nHeaton, Nicky Britten, Sandra Fielden, Steven Ariss \nThe limited extent to which research evidence is utilised in healthcare and other public services is \nwidely acknowledged.  The UK government has attempted to address this gap by funding nine \nCollaborations for Leadership in Applied Health Research and Care (CLAHRCs).  CLAHRCs \naim to carry out health research, implement research findings in local healthcare organisations, \nand build capacity across organisations for generating and using evidence.  This wide-ranging \nbrief requires multifaceted approaches; assessing CLAHRCs\u201f success thus poses challenges for \nevaluation.  This paper discusses these challenges in relation to seven CLAHRC evaluations, \neliciting implications and suggestions for others evaluating similarly complex interventions with \ndiverse objectives. \nPublished in: Evidence & Policy 7(4): 485-509 \nhttp:\/\/www.policypress.co.uk\/journals_eap.asp \nhttp:\/\/www.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006  \ndoi: 10.1332\/174426411X603470 \nBackground \nA persistent feature of healthcare provision worldwide is the gap between evidence-based \u201ebest \npractice\u201f and what is actually delivered routinely by health practitioners.  In the United States, for \nexample, it is estimated around 45 per cent of patients receive care that deviates from current \nscientific evidence (McGlynn et al. 2003), while 20-30 per cent of care provided is unnecessary or \neven contra-indicated (Schuster et al. 2005).  In the United Kingdom, there has been growing \nawareness in policy circles of the research-practice gap, and of the associated issue of the delay \nbetween the publication of robust findings on the effectiveness and cost-effectiveness of \nhealthcare interventions and their implementation in routine clinical practice.  A review \ncommissioned by HM Treasury (Cooksey 2006) highlighted the need for concerted effort to \naddress this gap, known as the \u201esecond gap in translation\u201f1, to ensure that following robust clinical \nand health-economic appraisal, new healthcare technologies and interventions are introduced \nsystematically across the National Health Service (NHS).  It also highlighted some of the \nlimitations of traditional \u201elinear\u201f modes of research translation, noting that current predominant \nmodes of dissemination and implementation such as decision-support systems, direct marketing \nand information campaigns were \u201cunlikely to be entirely sufficient\u201d to secure changes in practice \n(Cooksey 2006, p.102). \n                                                 \n1 This is in contradistinction to the \u201efirst gap in translation\u201f, between basic and clinical research \nand its translation into ideas for products and modes of treatment (Cooksey 2006). \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n2 \nThe review made a number of recommendations about how to close the second translation \ngap, including new funding initiatives and an expansion of the NHS\u201fs Health Technology \nAssessment (HTA) programme to facilitate the provision of a high-quality and accessible \nevidence base to NHS decision makers (Cooksey 2006).  It also fed into the development of a \nrevised NHS research and development strategy (Department of Health 2006), which included a \nnumber of new initiatives focused on the translation of research into practice.  Among these were \nCollaborations for Leadership in Applied Health Research and Care (CLAHRCs).  CLAHRCs \nwere to work on \u201cthe evaluation and identification of those new interventions that are effective \nand appropriate for everyday use in the NHS, and the process of their implementation into \nroutine clinical practice,\u201d by adopting a \u201ccommunity-wide outward facing focus\u201d (Call for \nCLAHRC proposals, October 2007).  Focusing on long-term, chronic conditions (such as cancer \nand cardiovascular disease) and public health, they were both to carry out applied health-related \nresearch focused on the needs of their local populations, and to work towards implementing the \nfindings of research, by nurturing connections between those carrying out research and those \nresponsible for delivering healthcare. \nThe language used in describing the aims and objectives of CLAHRCs, and the means they \nwere to use to achieve these, mirrors the increasingly nuanced understanding of the vagaries of \nimplementing research held by academics and policymakers.  Linear, one-way models of research \nimplementation, often aimed at changing the practice of individual practitioners, through for \nexample the provision of up-to-date information on the evidence for healthcare interventions by \nthe HTA, or the imposition of clinical guidelines by agencies such as the National Institute for \nHealth and Clinical Excellence, have been successful up to a point.  However, their limitations in \nimproving the way in which individuals and organisations draw on evidence in their work are \nillustrated by the continuing prevalence of sub-optimal clinical practice, and increasingly \nacknowledged by policymakers, as noted above.  Implementation of clinical evidence is thus \nincreasingly recognised as resting not just on dissemination to and regulation of individual \npractitioners, but also on addressing social, organisational and professional impediments (Eccles \net al. 2009).  Furthermore, the linear model of research uptake constructs evidence as an inert, \napolitical entity to be implemented universally and unilaterally: it does not recognise that some \nresearch evidence\u2014especially evidence around non-pharmaceutical, social interventions\u2014may be \npartial, particular, open to adaptation and revision in the course of the implementation process \n(e.g. Nutley et al. 2007; Gabbay & le May 2010).  As collaborations between research producers in \nacademic institutions and users in the NHS deploying distributed leadership to produce evidence \nsensitive to the needs of a particular region, CLAHRCs can be seen as efforts to move beyond the \nlinear model of the research-practice relationship.  They seek to bring researchers and \npractitioners together in a productive dialogue that closes the second translation gap by altering \nthe way research is produced as well as taken up.  In doing this, they have built on more recent \nnon-linear models of research translation.  These include the Knowledge-to-Action (K2A) \nframework (Graham et al. 2006), which distinguishes between knowledge creation and action but \nwhich points out that the relationship between the two may be complex, recursive and non-\nsequential, and the Promoting Action on Research Implementation in Health Services (PARIHS) \nframework (Rycroft-Malone & Bucknall 2010), which accounts for factors such as the nature of \nthe evidence, context and facilitation processes, and which seeks to be flexible enough to be \napplied to a wide variety of clinical settings, patient groups and professional areas.  Some \nCLAHRCs have built explicitly on such models; others have incorporated non-linear ideas more \nimplicitly into their work. \nThis is reflected too in the activities CLAHRCs are undertaking.  Nine CLAHRCs were \nfunded around England, each receiving up to \u00a310 million from the National Institute for Health \nResearch (NIHR) subject to matched funding being committed by its local university and NHS \npartners, over five years.  Their high-level aims are several; the means by which they are seeking \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n3 \nto achieve these are diverse and multifaceted.  Consequently, CLAHRCs themselves might be \nviewed as complex, programmatic sets of interventions, the success or failure of which is not \namenable to straightforward, outcomes-based evaluation.  Rather, evaluating CLAHRCs requires \nattention to process, opening the \u201eblack box\u201f of what CLAHRCs are doing and how they are \ndoing it: understanding the causal mechanisms that emerge from particular configurations of \nconditions, relationships and actions, and how and why these result in specific outcomes.  What \nto evaluate, and how, therefore represents in itself a difficult question requiring extensive \nconsideration, deliberation and value judgement; furthermore the novel organisation of \nCLAHRCs, as multi-organisational partnerships cutting across sectors, gives rise to further \nchallenges for evaluation (cf. Provan & Milward 2001; Russell et al. 2004). \nThis paper explores these methodological, axiological and practical challenges.  It offers \nreflections and insights from the experiences to date of internal evaluation leads in seven of the \nnine commissioned CLAHRCs, noting some of the conceptual and practical quandaries common \nto their evaluations, and offering putative solutions to these that are likely to be of benefit to \nothers seeking to evaluate other, similar ventures with diverse aims, complex organisational \narrangements and multi-level strategies.  It is presented in two main sections.  First, we offer an \noverview of the programme of CLAHRCs, describing the features common to all nine \nCLAHRCs, and some of the particularities which make each of the seven CLAHRCs with which \nwe are working distinctive.  We also explain how our internal evaluations seek to understand and \nassess their work.  Then, in the second section, we explore some of the key challenges common \nto our evaluations, and how we are seeking to address these.  We conclude by summarising the \nkey insights into the practice of evaluation that our experiences to date have given us, with a view \nto assisting others who are charged with similar tasks. \nThe CLAHRCs and their internal evaluations \nFirst, then, we seek to describe the common and distinctive features of the CLAHRCs, and the \napproaches we are taking in evaluating them (see also Table 1). \nAn overview of the CLAHRCs \nThough the CLAHRCs vary in the manner in which they have responded to the call to close the \n\u201esecond gap in translation\u201f (Cooksey 2006), they have in common a number of features.  Some of \nthese were specific requirements of the NIHR in funding the CLAHRCs programme.  The \nmission statements of all CLAHRCs, then, are informed by the aims set out by the NIHR, \naround developing \u201can innovative model for conducting applied health research and translating research \nfindings into improved outcomes,\u201d fostering \u201ca new, distributed model\u201d that links \u201cthose who \nconduct applied health research with all those who use it in practice,\u201d and creating \u201capproaches \nto research and its dissemination that [\u2026] take account of the way that health care is increasingly \ndelivered across sectors\u201d (Call for CLAHRC proposals, October 2007; emphasis in original).  Some \nCLAHRCs have emphasised particular aspects of the brief: for example, the CLAHRC for the \nSouth-west Peninsula (PenCLAHRC) includes a particular emphasis on creating and embedding a \nresearch-receptive culture in its NHS organisations.   All CLAHRCs involve a collaboration \nbetween at least one university and several (or all) of a region\u201fs NHS organisations; some \nCLAHRCs also include other bodies, such as local authorities and third-sector organisations.  \nThey also draw on the involvement of patients and the public in their work, or on regional bodies \nrepresenting patient and public views on health research and implementation.  Also in \naccordance with the NIHR brief, all CLAHRCs are composed of a number of \u201ethemes\u201f, including \nat least one \u201eresearch theme\u201f\u2014focused primarily on carrying out applied health research that \nmeets the needs of the region\u2014and at least one \u201eimplementation theme\u201f, whose primary aim is \nthe implementation of findings across the region.  CLAHRCs have taken a variety of approaches \nin designing these themes in ways that seek to be innovative in the carrying out and application of \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in Evidence & Policy. The definitive publisher-authenticated \nversion is available online at: www.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n4 \n \nCLAHRC Greater \nManchester (GM) \nLeeds, York and \nBradford (LYB) \nLeicestershire, \nNorthamptonshire \nand Rutland (LNR) \nNorth-west \nLondon (NWL) \nNottinghamshire, \nDerbyshire and \nLincolnshire (NDL) \nSouth-west \nPeninsula \n(PenCLAHRC) \nSouth Yorkshire \n(SY) \nUniversities  1 (Manchester) 2 (Leeds; York) 1 (Leicester) 2 (Imperial College; \nLSHTM) \n1 (Nottingham) 2 (Exeter, Plymouth) 2 (Sheffield; \nSheffield Hallam) \nHealthcare \norganisations  \n20 (10 PCTs\n1\n, 6 \nacute trusts, 3 \nmental health \ntrusts, 1 ambulance \ntrust) \n6 (2 PCTs, 2 acute \ntrusts, 1 mental \nhealth trust, 1 \nSHA\n2\n) \n9 (3 PCTs, 3 acute \ntrusts, 2 mental \nhealth trusts, 1 \nSHA) \n16 (8 PCTs, 7 acute \ntrusts, 1 mental \nhealth trust) \n10 (5 PCTs, 1 acute \ntrust, 3 mental health \ntrusts, 1 SHA) \n13 (3 PCTs, 6 acute \ntrusts, 2 mental \nhealth trusts, 1 \nambulance trust, 1 \nSHA) \n12 (4 PCTs, 5 acute \ntrusts, 2 mental \nhealth trusts, 1 \nSHA) \nOther \norganisations  \n- 3 (2 LAs\n3\n, 1 private \ncompany) \n- - - 1 (South West \nPeninsula Clinical \nResearch \nCollaboration) \n2 (1 charity, 1 NHS \ninnovation hub) \nResearch \nthemes \nPeople with long-\nterm conditions; \nHealthcare \npractitioners; \nHealthcare services; \nHealth information \nsystems \n \nPhysical health and \naddiction; \nImproving \nprevention of \nvascular events in \nprimary care \n(IMPROVE-PC); \nStroke care  \nPrevention; Early \ndetection; \nEducation and \nself-management; \nRehabilitation \nAcute care; \nChronic care \nStroke rehabilitation; \nPrimary care; Mental \nhealth; Children and \nyoung people \nDiabetes and \ncardiovascular \nhealth; Mental health \nand neurology; \nDevelopment and \nageing; Environment \nand human health \nDepression; \nChronic obstructive \npulmonary disease; \nDiabetes; Stroke; \nObesity; \nTechnology; \nGenetics \nImplementation \nthemes \nHeart disease; \nDiabetes; Chronic \nkidney disease; \nStroke \nTranslating \nResearch into \npractice in Leeds \nand Bradford (TRiP-\nLaB); Maternal and \nchild health \nImplementation Collaborative \nlearning and \ndelivery; patient \nand public \ninvolvement; \nevaluation \nImplementation; \nEngagement, \nsynthesis and \ndissemination \nImplementation User-centred \nhealthcare design;  \nTranslating \nknowledge into \naction; Intelligent \ncommissioning; \nInequalities \nSummary of \nCLAHRC\u2019s \napproach \nA core team is \nresponsible for \ndeveloping and \nevaluating ways for \nthe NHS to support \npeople managing \nFocuses on: high-\nquality applied \nresearch; research-\ninformed \ncommissioning; a \nmain base, but \nAims to transform \nthe relationship \nbetween research \nand practice in the \nregion\u2019s health \nservice by creating \nA core team is \nresponsible for \nbringing research \nmore rapidly into \neveryday practice, \nutilising project \nOrganisational \nlearning (OL) \napproach, viewing \nchange as a social \nphenomenon; \ninterventions are \nBrings together NHS \nand academic \norganisations to plan \nand conduct research \ninto key local \nquestions, to \nEach of the 11 \nthemes funds or \nsupports individual \nresearch and \nimplementation \nprojects (around 80 \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in Evidence & Policy. The definitive publisher-authenticated \nversion is available online at: www.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n5 \nvascular disease,  \nimplementing these \nand other \nimprovements and \nbuilding capacity to \nplan evidence-\nbased changes to \ncare pathways. \ndistributed \nresearch settings; \nstrong public \nengagement; \naddressing \ninequalities; \ncapacity building \na research-minded \nculture and \ngreater \nreceptiveness and \ncapacity for new \nknowledge in \nhealthcare \norganisations \nfocused \nmanagement and \nrapid-cycle \nresearch, \nimprovement \nmethodologies and \nrigorous evaluation \nof clinical and cost \neffectiveness \nlocally. \ntailored to the NHS at \nan early stage of \ndevelopment and \nrefinement, rather \nthan found to be \nefficacious in \nresearch but \nunusable in practice \nat a late(r) stage. \nimplement findings, \nand to evaluate if \nand how this \n\u2018Engagement by \nDesign\u2019\u00a9 model \nleads to more \nevidence-based \npractice and better \noutcomes  \nin total). The \nCLAHRC core \nmanagement team \nsupports  \nand monitors \ntheme activities. \n \nEvaluation focus Evaluation within \nand across the \nimplementation \nthemes focuses on \nthe context of \nimplementation of \nevidence and the \nrole of change \nfacilitation. \nEvaluation \nintegrated into \neach theme. E.g. \nIMPROVE-PC \nevaluation focuses \non collaboration \nbetween \nacademics and \npractitioners in \nproducing research \nfit for use in \npractice settings. \nEvaluation of (i) \ndevelopment and \neffectiveness of \ncore CLAHRC team \nin achieving aims, \n(ii) CLAHRC Co-\nordinator role, (iii) \nresearch-\nmindedness of \nNHS culture \nSelf evaluation at \nproject level, \nsystem evaluation \nat the CLAHRC core \nteam management \nlevel \n(i) Evaluation of the \nOL approach, with \nbefore\/after \nassessment of \nimplementation; (ii) \nEvaluation of the \nDiffusion Fellow role. \nThree levels: \nevaluation of \nwhether CLAHRC \nachieves goals; \nembedded process \nevaluations by \nprojects; \nparticipatory realistic \nevaluation to \nexamine changes \nintended and realised \nSelf evaluation at \nproject level, \nsystem evaluation \nat the theme and  \nCLAHRC core team \nmanagement level  \nEvaluation \nmethods \nQualitative and \nquantitative data \ncollection \ntechniques, utilising \ninterviews, focus \ngroups, survey \nquestionnaires and \nmedical \nintervention data. \nTheory-driven: in \nIMPROVE-PC, goal \nclarification with \nstakeholders and \nproduction of a \nlogic model linking \nprocesses to goals \nto inform  further \ndata collection \n(observation, \ninterviews, docs) \nLongitudinal \ninterviews and \nsocial-network \nanalysis, \nethnographic \nstudy of Co-\nordinators; \ncontrolled before-\nand-after study of \ncontent of NHS \nstrategic docs \nAnalysis of routine \ndata; evaluation of \ndevelopment of \nCLAHRC using \nethnographic and \nquantitative \nmethods \nQualitative \ninterviews; cognitive \nmapping \nParticipatory realist \nevaluation involving \nanalysis of routine \ndata, stakeholder \ninterviews, \ndocumentary \nanalysis, participant \nobservation \nMixed-method \nrealist evaluation, \nincluding analysis \nof routine data, \ninterviews and \nfocus groups, \nintegrating a \nutilization-focused  \nevaluation \nmethodology \n1 Primary Care Trust; 2Strategic Health Authority; 3Local Authority \nTable 1: Key characteristics of seven CLAHRCs described and their evaluations\n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n6 \nhealth research.  For example, the CLAHRC for Leicestershire, Northamptonshire and Rutland \n(LNR) involves research themes that cut across chronic disease areas, aiming to facilitate \nknowledge sharing between researchers and practitioners involved in different stages of the \nchronic disease pathway, from \u201ePrevention\u201f to \u201eRehabilitation\u201f (Baker et al. 2009).  CLAHRC \nNottinghamshire, Derbyshire and Lincolnshire (NDL) includes two implementation themes, \n\u201eImplementation\u201f and \u201eEngagement, Synthesis and Dissemination\u201f, which aim, in particular, to \nfacilitate the contribution of NHS organisations and practitioners to research at all stages, and \nensure that the new approaches to care being tested are relevant and feasible in practice. \nThere are other features which many or all CLAHRCs have in common, though these were \nnot stipulated by the NIHR.  Most CLAHRCs have adopted a model for integrating the \nproduction and utilisation of research knowledge, such as the K2A framework promoted by the \nCanadian Institutes for Health Research (Graham et al. 2006).  Putting these frameworks into \npractice involves the development of a range of activities that straddle universities and NHS \norganisations, for example South Yorkshire\u201fs (SY) \u201eTranslating knowledge into action\u201f theme, \nwhich is trialling innovative strategies to implement research findings to improve patient care \nlocally, and address national priorities such as nutrition in acute care.  While all CLAHRCs \ninvolve patients and the public in their work, some have set up specific groups to ensure a high-\nlevel contribution to the management of their programmes of research and implementation, such \nas NDL\u201fs service users and carers panel, which works to ensure active patient and public \nparticipation in each of the CLAHRC\u201fs projects.  Several CLAHRCs include specific \u201eboundary-\nspanning\u201f and \u201eknowledge-brokering\u201f roles (Lomas 2007) to help ensure co-ordination and \nintegration between the research-producing and research-using sides of the collaboration.  These \ninclude CLAHRC Greater Manchester\u201fs (GM) Knowledge Transfer Agents, LNR\u201fs Co-\nordinators, and NDL\u201fs Diffusion Fellows.  These roles differ in their detail, however: where GM \nand LNR have developed new, full-time roles focused on increasing interaction between partners, \nNDL\u201fs Diffusion Fellows are seconded from health and social care provider organisations to \nwork in partnership with researchers. \nCLAHRCs also differ in the extent to which they have predefined the foci of their research \nefforts, and the extent to which they rely on stakeholder engagement to define priorities.  While \nall have included some mechanisms to ensure that NHS organisations and practitioners can feed \ninto research priorities and design, PenCLAHRC and the CLAHRC for North-west London \n(NWL) have included explicit mechanisms for scoping, prioritising and initiating research \nprojects with the input of academics, practitioners, service users and carers and others, in the \nform of their \u201eEngagement by Design\u201f\u00a9 process and \u201eCollaborative Learning and Delivery \nPathway\u201f respectively.  Just as stakeholder engagement is crucial for addressing the priorities of \nmany of the CLAHRCs in general, the effectiveness of the internal evaluations of CLAHRC \nprogrammes also relies on collaborating appropriately with a number of individuals and \norganisations.  Engagement with stakeholders is essential to ensure that evaluation priorities meet \nthe needs of a variety of sponsors and beneficiaries, and that knowledge produced through \nevaluation can be translated effectively into improved services and better ways of working across \nthe university-healthcare divide.  The various CLAHRC internal evaluation teams have thus \nsought to develop locally tailored methods of stakeholder engagement (see below). \nA common purpose across CLAHRCs, then, is accompanied by differences in the means \nby which each CLAHRC is seeking to achieve those aims, but what they all have in common is a \nmultiple set of objectives, and a multiplicity of approaches by which they are seeking to meet \nthose objectives.  While on one level CLAHRCs can be understood as (highly complex and \nmultifaceted) interventions in themselves, in order to be able to provide meaningful knowledge \nabout the variety of mechanisms they are deploying to achieve their aims, evaluations need to be \nable to consider their constituent parts, accounting for the different levels at which they might be \neffective (Provan & Milward 2001; McGuire & Agranoff 2011).  A range of evaluation activities \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n7 \nis planned to provide this understanding, including four external evaluations funded by the \nNIHR Service Delivery and Organisation (SDO) programme (e.g. Rycroft-Malone et al. 2011; see \nalso www.sdo.nihr.ac.uk\/projlisting.php?srtid=30), but here our focus is on the internal \nevaluations we are developing for our CLAHRCs.  We discuss these next. \nCLAHRC internal evaluations \nIn working with our respective CLAHRCs, each of us has sought to develop a programme of \nevaluation that is appropriate for this challenge, and which is able to account for and provide \nmeaningful understanding of the complex range of aims, means, organisations and stakeholders \nthey need to address.  Again, for brevity, we highlight here certain commonalities and differences \nbetween our evaluation approaches; more detail about each CLAHRC\u201fs evaluation is presented in \nTable 1. \nAll of our CLAHRC evaluation plans include a focus on process, but a commitment to \nconnecting this to outcomes as well.  The vascular event prevention theme of CLAHRC Leeds, \nYork and Bradford (LYB), for example, is using a theory-based evaluation following the \nmethodology developed by Carol Weiss (1995), which seeks to identify stakeholders\u201f programme \ntheories of change, link these to the specific activities being undertaken by the theme, and \nelucidate whether and how far these programme activities can be seen to have given rise to the \noutcomes intended.  CLAHRC SY and PenCLAHRC are also deploying a theory-based \nevaluation methodology, Pawson and Tilley\u201fs (1997) realist evaluation approach, to understand \nthe theories of change underpinning programme activities and how the specific contexts in which \nthese are pursued affect outcomes for certain stakeholders in certain respects.  NDL\u201fs evaluation \nputs to the test the concept of \u201eorganisational learning\u201f on which this CLAHRC is premised, \nexamining whether it represents an effective means of securing better implementation of research \nfindings.  In adopting explicitly theory-based approaches, we are seeking to find a middle ground \nbetween, on the one hand, simplistic \u201einput-outcome\u201f models of social causality in complex, real-\nlife contexts, and on the other, a nihilistic, extreme-relativistic outlook that supposes that the \nvolume of potential causal variables and the interactions between them renders any explanatory \naccount invalid.  A commitment to understanding stakeholders\u201f theories of change, and closely \nand qualitatively examining the programme activities through which they are realised, will enable \nus to produce credible accounts of whether, how and why CLAHRCs\u201f actions have worked, with \nboth local utility and wider generalisability. \nTo ensure that our work is of practical use to our CLAHRCs, all of our evaluations include \na prominent formative component.2  This implies more than merely committing to feed back \nfindings to stakeholders; rather, to ensure impact, it requires that the whole evaluation process be \noriented towards the needs and interest of (the plurality of) stakeholders.  CLAHRC SY\u201fs \nevaluation draws on the premises of Patton\u201fs (2008) \u201eutilisation-focused evaluation\u201f.  This is a 12-\nstage process which includes activities intended to help maximise the usefulness of evaluation, \nincluding assessing organisational readiness, identifying intended users, determining priorities, \nand facilitating the use of findings.  CLAHRC SY\u201fs evaluation team has carried out a stakeholder \nmapping exercise and engagement events, asking stakeholders: \u201eWhat two things do you want \nfrom this evaluation?\u201f. The information derived from this process is used to monitor changing \npriorities, refine the focus of the evaluation activities and develop dissemination and knowledge \ntranslation activities which are useful and sensitive to the setting.  CLAHRC NWL has involved \nCLAHRC partners by facilitating them in the development of their own logic model of \n                                                 \n2 By \u201eformative evaluation\u201f, we mean that our evaluations will help to shape the CLAHRCs as \nthey develop over the five-year pilot phase. This has similarities with what Patton (2008) refers to \nas \u201edevelopmental evaluation\u201f, especially in that the role of our evaluations is not specifically or \nexplicitly to help the CLAHRCs achieve a \u201esteady state\u201f that can be subjected to summative \nevaluation. \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n8 \ncollaboration, and by holding interactive sessions where they can discuss emerging findings. \nCLAHRC LYB has also worked with primary stakeholders (the core project team and those \nidentified through a network mapping exercise) to clarify project goals and uncover assumptions \nabout how they are to be achieved using interviews, online voting, and group discussion.  Other \nopportunities are being used to incorporate stakeholders\u201f views, including data gathering activities \nand project management meetings.  PenCLAHRC is using a \u201eparticipatory\u201f form of \u201erealistic \nevaluation\u201f methods (Pawson & Tilley, 1997).  This approach involves participation of NHS staff, \nacademics, and patients and the public in establishing programme theories, and in the ongoing \ndesign of the evaluation, for example, in giving advice about how to assess achievement of goals. \nThis information is used to articulate and select the programme theories to be tested, and to \nrefine evaluation strategies.  Issues raised through this process also form feedback to a range of \nstakeholders including managers, executive boards, the wider PenCLAHRC community, and \nproject leads, to inform the ongoing development of PenCLAHRC. \nOther evaluation teams have similarly sought to consult and engage with potential \nevaluation users from the start, in order both to secure influence and also to minimise overlap \nwith other evaluation activities, such as the SDO-funded external evaluations, which also include \nformative aspects.  The theme-based nature of several of our evaluations further helps to ensure \ntheir relevance and appropriateness to the range of primary stakeholders who may benefit from \nthe insights they produce, including ongoing formative lessons fed back regularly. \nOur evaluations are also characterised by a sensitivity to the particularities of the \nCLAHRCs, or even of individual themes and projects within the CLAHRCs.  The initial job of \nevaluators in several CLAHRCs is to work with stakeholders to define what the goals of projects \nare, and to clarify the means by which it is hoped these will be achieved.  Again, this is in keeping \nwith the tenets of theory-based evaluation, but it is especially important given the multifaceted \naims of CLAHRCs, and the fact that different stakeholders will prioritise and value different \nobjectives.  In order to ensure that evaluation recognises and addresses the intentions of all \nstakeholders, not just the powerful few, PenCLAHRC\u201fs evaluation team is taking an explicitly \nparticipatory approach, not just consulting stakeholders but actively involving them in the \nevaluation process, and encouraging and supporting self-evaluation of activities where possible.  \nSimilarly, the GM evaluation includes co-operative enquiry with the CLAHRC\u201fs Knowledge \nTransfer Agents, whose novel, emergent role means they are best placed to contribute to the \ndesign and development of evaluation.  In LNR, the similarly novel CLAHRC Co-ordinators are \ninvolved in writing reflective diaries, which are used to support these key CLAHRC brokers as \nwell as to provide the evaluation with something of an \u201einsider perspective\u201f on the role.  \nHowever, there are of course limits to the desirability of such joint approaches to evaluation.  \nThe evaluation at NWL, for example, involves several parallel approaches, including self-\nevaluation by projects, but also an independent team evaluating patient and public involvement \n(PPI) within the CLAHRC, where an evaluation led by those co-ordinating PPI might risk being \npartial. \nGiven the parallels between the CLAHRCs and the similarities and complementarities \nbetween our evaluations, there is also clearly scope for cross-pollination in our work, and mutual \nenrichment through joint, comparative evaluation outputs.  Several of us have already played \nimportant roles in facilitating cross-CLAHRC dialogue, notably through joint workshops at the \nCLAHRC learning events that are held quarterly: for example a recent one-day forum for those \nin boundary-spanning and knowledge-brokering roles in CLAHRC drew on early findings from \nseveral of our evaluations. Forums such as these enable us to share the learning from each of the \nCLAHRCs internal evaluations in a way that benefits all nine CLAHRCs, as well as to work \ntowards combined outputs. Already, there have been some joint presentations: for example, \nCLAHRCs GM, LYB, NDL and LNR jointly presented a paper on mediating institutional \nchallenges through change agency at the 2010 Organisational Behaviour in Health Care \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n9 \nconference, while CLAHRCs GM, NDL and LNR presented on their diverse change agent \nmodels at the 2010 HSRN\/SDO conference, and CLAHRCs SY and NWL presented on the \nutilisation focus of their evaluations at the 2011 HSRN\/SDO conference. Through these \ndiscussion and dissemination activities, we will meet the wider aim of learning from the \nCLAHRCS as a whole.  \nWhile diverse in terms of the specific approaches adopted, then, our evaluations have been \nshaped by a number of similar concerns, including fitness for the complex contexts they are \naddressing, the need to ensure that evaluation priorities are driven by a plurality of stakeholders \nand not just those most powerful, a wish to balance collaborative approaches with the distinctive \nperspective of the outsider, and a desire to ensure formative utility.  Naturally, these concerns \nbring with them a number of tensions, trade-offs and compromises, familiar to all practitioners of \nevaluation, but arguably particularly acute and contentious in the kinds of multifaceted, multi-\norganisational and multi-stakeholder enterprises that CLAHRCs represent.  In the next section, \nwe turn to consider these more explicitly.  We describe the challenges we have faced, and some \nof the potential solutions we are starting to develop, and which may be of some use to others \nseeking to evaluate similar ventures in a way that is methodologically defensible, practically useful \nand pragmatically achievable. \nChallenges in the evaluation of CLAHRCs\u2014and putative solutions \nHaving described our seven CLAHRCs and our approaches to their evaluation, in this section we \noutline under five headings some of the early theoretical, methodological and practical challenges \nthat we are facing in putting our plans into practice.  These relate to the nature of the CLAHRCs \nand their status as diffuse collaborations with multiple aims and activities, the purpose and remit \nof evaluation, and the wider health-service context in which the CLAHRCs and their evaluations \nare set. \nEvaluating disparate, developing activities \nIn seeking to evaluate any programme, the evaluator faces several choices which are constrained \nand informed by the nature of the programme itself. As we have already highlighted, CLAHRCs \nare highly ambitious, complex and innovative ventures which seek to address the gap between \nresearch and practice in a dynamic and fluid way. This poses a number of challenges for \nevaluation, from the question of how to define and evaluate impact (Provan & Milward 2001) to \nthe more prosaic issue of encouraging participation in an evaluation of an enterprise with which \nmany stakeholders may see themselves as only loosely associated (Popp et al. 2005).  Here we \ndiscuss how the developmental and experimental nature of the CLAHRCs has informed our \nevaluation choices and how we have attempted to address the challenges posed by programmes \nwhich consist of both disparate and developing activities. \nThe first choice facing the evaluator is how impact-focused their evaluation can and should \nbe. It is well recognised that evaluating the impact of a programme involves considering a range \nof outcomes which are usually linked together in a logical outcome hierarchy (Owen 2007), but it \nis also recognised that focusing on impact requires programmes to have clearly defined and stable \ngoals and activities (Patton 2008). In evaluating the CLAHRCs, focusing on impact therefore \nraises two main challenges. First, both the nature of the CLAHRCs and the range of stakeholders \ninvolved make it extremely difficult to identify a stable set of goals (cf. Provan & Milward 2001). \nSecond, in diverse programmes such as the CLAHRCs it is not always possible to place the goals \nwhich have been identified into a logical hierarchy since they are likely to be wide-ranging and \ndisparate. This makes it necessary to engage in a process of goal selection and prioritisation, \nwhich necessarily narrows the evaluation focus and heightens the political stakes by increasing \nthe risk that there will be conflicts and disagreements about the goals prioritised (Patton 2008; \nMcGuire & Agranoff 2011). Although selecting and prioritising goals can be risky, several of us \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n10 \nhave seen this process as a developmental opportunity for our CLAHRC programmes since it has \nenabled us to instigate collaboration and deliberation between project stakeholders, as discussed \nunder \u201eCLAHRC internal evaluations\u201f above.   \nOne of the major criticisms of impact-focused evaluation is that it frequently fails to \nidentify the underlying causal mechanisms that generate impact (Chen 1990). This often leads \nevaluators to choose to evaluate processes rather than outcomes, in an attempt to uncover how a \nprogramme has worked. Traditional approaches to process evaluation focus on uncovering \nwhether a programme has been implemented in the way it was designed. This is particularly \nappropriate for investigating the difficulties and complications involved in implementing complex \nsocial programmes such as CLAHRCs (Weiss 1998; Chen 1990). For instance, CLAHRC NWL is \nexamining how various management processes have been implemented to support the \ndevelopment of their CLAHRC with the aim of capturing the uncertainties and changing realities \nassociated with implementation (Patton 2010). The major challenge, however, is that the \nemergent and flexible nature of the CLAHRCs makes it difficult to examine the implementation \nprocess because it is unclear precisely what is supposed to be implemented in any given case. \nWhilst management processes and procedures may lend themselves to this type of evaluation due \nto strict governance arrangements, many of the collaborative processes in which we are interested \ncannot be fixed in the same way.  \nWe have highlighted the challenges of choosing between impact and processes in \nevaluating experimental and developmental programmes such as the CLAHRCs. These \nchallenges have led many evaluators, ourselves included, to utilise theory-driven approaches to \nevaluation. A theory-driven approach to evaluation involves uncovering the pathways by which \nprogramme activities are presumed to lead to programme goals (Weiss 1995). The approach \nenables the evaluator to focus on both outcomes and processes in an effort to understand how \nand why a programme works. In the context of the CLAHRCs, this evaluation approach can help \nto address some of the issues discussed above. For instance, by demanding that the assumptions \nof multiple stakeholders are articulated and discussed, a theory-driven approach provides \nopportunities for negotiation and collaborative goal setting, enables the evaluator to ask deeper \nquestions about what is going on and question those assumptions (Patton 2010), and links \ndisparate, developing activities together via a common theoretical framework (Chen 1990). \nAlthough a theory-driven approach is not a panacea for the challenges associated with evaluating \ncomplex, experimental and developmental programmes such as the CLAHRCs, it has \nnevertheless offered the most feasible approach for the majority of the internal evaluation teams \nacross the CLAHRCs. \nEvaluating the right things in the right ways \nOur ongoing empirical investigations into the CLAHRCs have already highlighted the challenges \nof finding an approach to evaluation that is robust, appropriate and acceptable to the range of \nstakeholders it needs to please.  In terms of our evaluations, this presents two challenges in \nparticular: (i) the criteria against which to evaluate the performance of the CLAHRCs; and (ii) \ngenerating outputs that are both acceptable and useful to the audiences being addressed. \nFirstly, then, we face the challenge of determining exactly what should be evaluated.  As \nalready noted, CLAHRCs are seeking to achieve a host of diverse outcomes, from increasing the \nvolume of applied research produced, through changing the way in which evidence is generated \nby fostering partnerships between academia and the NHS, to facilitating the implementation of \nevidence-based practice in local health economies.  Besides their diversity, many of these \nobjectives are difficult to measure, and attribution of causality is especially thorny.  Consequently, \nas noted in the previous subsection, many of us are adopting theory-based approaches to \nevaluation which pay attention to process as well as outcome, and seek to link the two. \nThis can secondly, however, give rise to its own challenges.  In moving beyond approaches \nfocused purely on outcomes, which seek to determine whether initiatives have worked and \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n11 \nattribute causality in quantitative terms, our evaluations move into methodological territory that is \nforeign to many CLAHRC stakeholders.  Attention to process, use of qualitative methods and \nshifts in mode of reasoning away from statistical-probabilistic approaches may be increasingly \naccepted in the academic literature on evaluating complex entities such as CLAHRCs (Grol & \nGrimshaw 1999; Graham et al. 2006; Kontos & Poland 2009), but for those used to traditional \nbiomedical models of evaluation, they remain contentious (Wood et al. 1998). \nThis poses challenges in terms of the questions of what the outputs of our evaluations \nshould look like, and what they should seek to provide to the CLAHRCs.  Evaluation approaches \nthat incorporate action research and models of social learning (Kolb 1984; Eden & Huxham, \n1996; Lave & Wenger 1991; Raelin 2009) are prominent in our work, with a view to ensuring \noutputs that are useful to practitioners, and embedded into real-world practice improvements.  \nThose stakeholders expecting definitive accounts of whether or not their CLAHRC has \u201eworked\u201f \nwill be disappointed.  However, the process orientation of many of our evaluations is likely to \noffer its own value.  It may also find receptive audiences among those working outside traditional \nacademic and biomedical environments, for whom definitive, universal results of evaluations are \nless useful than context-sensitive, action-oriented accounts of how combinations of mechanisms, \nactors and contexts have helped and hindered the CLAHRCs\u201f various efforts to do and \nimplement research in novel ways.  Formative outputs from our evaluations, which feed into the \nways in which our CLAHRCs develop, are thus a crucial source of their value (see next section), \neven if summative results will not offer a definitive assessment of success or failure. \nEvaluating neutrally and contributing formatively \nFor many of us, an important part of our roles is to make an ongoing contribution to the \ndevelopment of the CLAHRC by providing social-scientific perspectives on the approaches being \ntaken to their missions, the obstacles they are likely to encounter, and the ways in which they \nmight deal with these.  For those CLAHRCs which are primarily being led and run by clinicians \nand clinical academics especially, the insights provided by formative evaluation (on issues such as \nthe advantages and challenges of collaborative, networked approaches to organisational change, \nalignment of CLAHRC aims with NHS staff\u201fs incentive structures, and the art of change \nmanagement in public-service bureaucracies) are potentially of considerable utility in maximising \nCLAHRCs\u201f abilities to achieve their aims.  Through \u201egenerative dialogic encounters\u201f (Beech et al. \n2010) with key CLAHRC actors, it is possible to make general social-scientific theory, and \nspecific emergent findings from evaluation, directly relevant and instructive for those involved in \nthe day-to-day clamour of putting CLAHRCs into practice.  Formative input of this kind is a key \npart of many of our evaluations, ensuring that they make a relevant contribution in the \ndevelopment of the CLAHRCs rather than offering only the benefit of hindsight on what could \nhave been done differently.  Many of our evaluations, then, seek to embrace a dialectical \napproach that is closely tied to practice (Raelin 2009), and which draws on the ideas of authors \nsuch as Lave & Wenger (1991) by seeking to engage a wide range of practitioners in group \nlearning activities with a view to fostering a new collective identity and common purpose.  \nCLAHRC SY\u201fs evaluation, for example, included a stakeholder engagement event at which \ndifferent understandings of and work within the CLAHRC were brought together to increase \nconsensus and joint work.  In CLAHRC NWL, a dialectical, learning approach to evaluation \ntakes the form of sustainability models and Plan-Do-Study-Act (PDSA) processes that mirror the \nlearning cycles of Kolb (1984), with practitioners actively engaged in iteratively evaluating and \ninforming their learning and project progress. \nHowever, this aspect of the evaluations also brings with it challenges.  Besides the general \ndifficulty of bringing partial and limited evaluation data to bear on development at an early stage \n(considered above), there is the tension between conducting an evaluation which is even-handed \nin its treatment of issues facing CLAHRCs and providing constructive feedback and reflection on \nhow their aims might be achieved.  As with all endeavours at making organisational change, \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n12 \nCLAHRCs are often politically charged groupings, and not all actors within them will subscribe \nequally to their various aims\u2014indeed, some actors may actively resist some or all CLAHRC aims, \nseeing them as threatening or illegitimate or unachievable.  Making evaluation relevant and usable \nfor CLAHRCs may mean apparently or actually taking sides in such disputes, offering expertise \nto those on one side but not the other.  The fact that many of us are funded, directly or \nindirectly, by CLAHRC money exacerbates this threat to our neutrality. \nResolving this tension is not straightforward.  Some of us are seeking to ensure that the \nway in which we feed back is as even-handed as possible, making our services and our findings \navailable widely to try to ensure that all can draw on them as they see fit.  Others are embracing \nthe rich tradition of fields such as action research in rejecting the possibility\u2014and desirability\u2014\nof political neutrality, and instead see their formative-evaluation role as a legitimate aspect of their \nCLAHRCs\u201f strategies.  This implies making the value judgement that the aims of CLAHRCs \n(around applied health research and its implementation and uptake) are desirable ones, and \ndeploying evaluation as one means of informing the process of achieving these aims\u2014while of \ncourse conducting their evaluations ethically in terms of expectations around confidentiality, \nanonymity and rigour. \nEvaluating sustainability of change \nThe NHS Institute (2005: 2) describes sustainability of change in the following terms: \n\u201cNot only have the process and outcome changed, but the thinking and attitudes behind \nthem are fundamentally altered [\u2026 and] change has become an integrated or mainstream \nway of working rather than something \u201eadded on\u201f. [\u2026] Further, it has been able to \nwithstand challenge and variation; it has evolved alongside other changes and perhaps has \ncontinued to improve over time. Sustainability means holding the gains and evolving as \nrequired\u2014definitely not going back.\u201d \nEvaluating the sustainability of large-scale, multi-partner programmes such as the CLAHRCs \npresents the evaluator with a number of conceptual and practical considerations.  Regarding the \ndefinition above, the first major challenge is to define the ambitions of the programme \nconcerning issues of sustainability. It is not only important for evaluators to establish what is \nintended to \u201cbecome an integrated or mainstream way of working,\u201d but also to what extent these \nambitions reflect the values of the various partners.  Therefore, evaluators need to have a clear \nunderstanding of the underlying principles of the programme, and how the partner organisations \nview these principles in terms of potential benefits and conflicting pressures. \nAs with many large-scale programmes, sustainability in the context of CLAHRCs can be \ninterpreted at two levels: the project-level and the programme-level.  At the project-level the key \nconcern for evaluating sustainability is the extent to which the changes in systems, structures, and \npractices resulting from CLAHRC activities are continued within the organisations where they \nhave been implemented.  \nThe approach taken to evaluating project sustainability will depend on the details of \nspecific projects implemented within the regional programmes.  Whilst some changes, once \nmade, are self-sustaining, others will be more vulnerable to individual, organisational and \nfinancial pressures.  For instance some changes will face difficulties if they need ongoing \ncommitment of individuals or long-term additional (or redistributed) resources.  At this level \nevaluating sustainability requires assumptions to be made about long-term risks to implemented \nchanges and possible remedial actions and availability of structured support to prevent losing any \ngains made.  While some initiatives will involve a \u201estatic\u201f view of sustainability, certain initiatives \nwill require a more \u201edynamic\u201f focus on ongoing cycles of change and development \n(Modernisation Agency 2004).  In these cases sustaining organisational commitment and \nindividual responsibility for managing change will be crucial for sustaining the principles of the \nprogramme. \nThe second form of sustainability is at the programme level.  This relates to the extent to \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n13 \nwhich the CLAHRCs themselves as organisational entities continue to exist, and in what form. \nThis is likely to depend on the success of the regional programmes in demonstrating their \neffectiveness.  It is likely to be contingent on local factors, but will also depend on wider \ncontextual circumstances, in particular, policy priorities and resources.  In all cases, the \nCLAHRCs will need to generate strong partnerships, and evidence clear benefits to the NHS to \ncontinue to be sustained.  At this level evaluation activities have three potential roles: assessing \nthe likelihood of sustaining organisational integrity; contributing to development of sustainable \norganisational practices and structures; and providing evidence of effectiveness. \nGiven the limited resources of the CLAHRC evaluation activities and the size and \ncomplexity of the programmes, a key concern is the focus of evaluating sustainability.  Whilst \nsome might concentrate on evaluating the sustainability of individual projects other evaluators \nmight be more concerned with the programme-level.  Another distinction will be the extent to \nwhich the objectives of evaluations are either to assess potential for sustainability or contribute \ntowards sustainability. \nSeveral factors are likely to influence the sustainability of CLAHRCs themselves and \nthereby provide additional practical and conceptual challenges to evaluation of sustainability.  In \nparticular, the landscape of healthcare provision is changing rapidly and dramatically, so in many \ncases, the partner organisations will either cease to exist, or will look dramatically different. \nPartner organisations are likely to have less funding available to support activities not directly \nrelated to service delivery. \nThe primary concern for the CLAHRCs will be sustaining the increased collaboration \nbetween research and services they have initiated for improved healthcare in the long-term.  \nTherefore the fundamental questions concerning evaluation of sustainability of the CLAHRC \nprogramme as a whole are: can CLAHRCs achieve self-sustaining regional integration of their \ncollaborative principles into mainstream practices (i.e. can CLAHRCs make themselves \nredundant as their ethos becomes taken-for-granted by partner organisations)?  If not, what are \nthe most efficient and effective ways to organise ongoing infrastructure for collaboration? \nPractical challenges \nFinally, there are also certain mundane\u2014and unfortunately increasingly routine\u2014challenges that \npresent themselves in the course of the carrying out evaluations of this nature.  Three examples \nare briefly discussed here. \nGovernance: As evaluation teams, we have faced different experiences of working with the NHS\u201fs \nresearch governance system. Some of the evaluations have been classified as audits, thus not \nrequiring NHS research ethics, whilst others have had to obtain all the necessary clearances, even \nwhen the evaluations are researching\u2014and taking place within\u2014our own organisations. These \nexperiences highlight two issues. Firstly, this is not the type of evaluation work that NHS \norganisations are used to granting permission for. Consequently, NHS organisations are \ninconsistent in their decisions about whether NHS ethical and governance approvals are needed. \nSecondly, this has required much time and effort to secure apparently necessary governance \napprovals for evaluative research that focuses on our own daily work and talking to our own \ncolleagues!  \nOn top of everything else: Many of the internal evaluation teams have wider roles in their CLAHRCs\u201f \nprogrammes of work, or have other research and teaching responsibilities. This means that the \ninternal evaluation activities can end up being just one of the \u201eother\u201f things that need to be \ncompleted. Yet the evaluations offer the opportunity to develop a programme of implementation \nresearch about the CLAHRCs\u2014which, as we have seen, are novel, innovative means of bridging \nthe research-practice gap\u2014and so should not be sacrificed to competing interests. Rather, the \nevaluations promise considerable insight into how these collaborative endeavours actually work, \nand as we have discussed above, whether this new way of working can be sustained.   \n\u2018Another\u2019 evaluation?: CLAHRCs, as a new way of implementing research evidence, have \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n14 \n(unsurprisingly) become a topic of research in themselves. Each of the nine CLAHRCs is \nparticipating in at least one (if not several) external evaluation, funded by the NIHR\u201fs Service \nDelivery and Organisation programme. Moreover, other researchers have also taken an interest in \nthe organisation and work of CLAHRCs. Despite careful attempts to manage the involvement of \nCLAHRC study teams, CLAHRCs and their work sometimes seem overburdened and over-\nstudied. Participating in other studies has put time pressures on the work that CLAHRCs have \nbeen funded to do. It is in this context that the internal evaluations are taking place. \nConsequently, there is a risk that CLAHRCs might be prone to fatigue and that over-evaluation \nof CLAHRCs might itself skew the \u201ereality\u201f of the practice of doing and being \u201eCLAHRC\u201f. As we \nhave previously discussed, whilst our internal evaluations are being carried out in a stretched and \ncompetitive space, they offer the possibility of providing formative outcomes and learning points \nwhich can take forward and develop both the empirical work being undertaken and the \noverarching organisational structures and management of each CLAHRC, in both a localised and \nreal-time manner, rather than relying on hindsight or recommendations for change that are made \nafter the end of our funded period.  To some extent, managing the burden of evaluation will \ndepend on how far the activities of the internal and external evaluations can result in \ncollaboration and mutually beneficial and co-ordinated distribution of resources.  Difficulty in \nachieving this might lead to the question of what should take priority\u2014internal evaluations, \nsensitive to the particularities and needs of CLAHRCs, or external evaluations whose priority is \ngeneralisable theoretical knowledge? \nConclusion \nAs new models for carrying out and implementing the results of research, CLAHRCs reflect \nwider developments in the way research is produced and used, not just in bridging the \u201esecond \ntranslation gap\u201f in healthcare, but in other fields too (Nowotny et al. 2003).  The transition of \nhealthcare research and delivery towards complex networked forms requires a parallel shift in \napproaches to evaluation.  In attempting to navigate these choppy waters, there might be a \ntendency to fall back on previous thinking, and promote one dominant paradigm.  However, the \nmultiple diverse stakeholders and their associated goals involved in the nine CLAHRCs prevent \nhomogeneity of aim, approach or method in evaluation.  On the contrary, and as others have \npointed out in various contexts, the challenge for evaluation is to find a breadth of approaches \nthat addresses the breadth of activities and goals being undertaken by such enterprises (Provan & \nMilward 2001; Russell et al. 2004; Popp et al. 2005; McGuire & Agranoff 2011).  Rather, \n\u201cevaluation of a network must allow for the fact that various stakeholders involved in the \nnetwork evaluate its effectiveness using multiple criteria, and that different constituencies expect \ndifferent outcomes\u201d (McGuire & Agranoff 2011, p.274). \nIn outlining our evaluation approaches, we have highlighted areas of convergence and \nconsensus. This convergence is built on common lessons already learnt and shared as we each \nseek to construct evaluations that are achievable, rigorous and useful.  Our work so far has \nsought explicitly to account for the fact that evaluation has varied meanings for all stakeholders \ninvolved (Provan & Milward 2001), with no definitive right way ahead.  The focus of CLAHRCs \non reconstituting the link between research and practice, and their emphasis on collaboration \nbetween multiple stakeholders, makes this challenge especially pressing.  The nebulous nature of \n\u201eknowledge transfer\u201f necessitates considerable work with various stakeholders in defining what \ndesired outcomes would look like, in a similar vein to the work of other authors who have sought \nto evaluate knowledge exchange initiatives (e.g. Russell et al. 2004).  To an even greater extent \nthan in evaluating other complex interventions, then, a great deal of work has been needed in \nengaging stakeholders on this question and seeking to reach a degree of consensus about what it \nis that their CLAHRCs are seeking to achieve.  Our evaluations also seek to account for the fact \nthat the CLAHRCs\u201f work takes place at several levels, micro to macro, and through complex \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n15 \npolitical, social, professional, organisational and economic systems. Attention must be paid to the \nvagaries of these systems, to what works and how for which stakeholders as they negotiate these \nsystems, and to outcomes (and unintended consequences) at all of these levels (Provan & \nMilward 2001). Attention must be paid to both processes and outcomes, even if both of these are \nunfixed. A balance must be struck between immersion, reflection and engagement on the one \nhand, and critical distance and scientific robustness and on the other.    \nBeyond these common convergence points, there is also strength in the diversity of our \napproaches. The complexity of the CLAHRCs themselves, and disagreement over what \nconstitutes proper evaluation and useful knowledge, means that our evaluations have taken \ndiverse approaches across (and sometimes within) CLAHRCs.  In attempting to meet the plural \nobjectives of evaluation we have deployed a wide range of theoretical, methodological and \npractical approaches, and as our discussion of these suggests, for all the challenges it can present, \nthis flexibility may well be important to others facing similar evaluation quandaries.  As \nevaluation methodology develops to address increasingly multifaceted initiatives crossing \norganisations, sectors and areas of service delivery\u2014especially in the British context where an \nemphasis on public-service modernisation has been replaced by the notion of the \u201eBig Society\u201f, \nwith new scope for collaboration between the state, the private sector and civil society\u2014it is \nimportant to accept that for evaluation, \u201eone size does not fit all\u201f.  In moving beyond traditional \none-dimensional quantitative approaches to defining success, there is a wealth of approaches to \nbe taken, but these bring with them a range of challenges.  In discussing these and the attempts \nwe have made to surmount them, we hope to have provided a set of reflections and insights that \nwill be useful to others evaluating similarly complex processes, in healthcare, public services and \nbeyond.  While our paper undoubtedly raises more questions than answers, the issues it highlights \nundoubtedly extent to initiatives other than CLAHRCs, and in seeking to articulate these issues, \nwe hope that our contribution will be of value to others as they confront similar evaluation \nchallenges. \nAcknowledgements \nThe authors would like to thank their CLAHRCs for their support for this work, and two \nanonymous referees for their constructive criticism.  This article presents independent research \ncommissioned by the National Institute for Health Research (NIHR). The views expressed in this \npublication are those of the authors and not necessarily those of the NHS, the NIHR or the \nDepartment of Health. \nReferences \nBaker, R. et al., 2009. The National Institute of Health Research (NIHR) Collaboration for \nLeadership in Applied Health Research and Care (CLAHRC) for Leicestershire, \nNorthamptonshire and Rutland (LNR): a programme protocol. Implementation Science, 4(1), \np.72. \nBeech, N., MacIntosh, R. & MacLean, D., 2010. Dialogues between academics and practitioners: \nthe role of generative dialogic encounters. Organization Studies, 31(9-10), pp.1341 -1367. \nChen, H.-T., 1990. Theory-driven evaluations, Newbury Park, CA: Sage. \nCooksey, D., 2006. A review of UK health research funding, London: The Stationery Office. \nDepartment of Health, 2006. Best research for best health: a new national research strategy, London: \nDepartment of Health. \nEccles, M. et al., 2009. An implementation research agenda. Implementation Science, 4(1), p.18. \nEden, C. & Huxham, C., 1996. Action research for the study of organizations. In S.R. Clegg, C. \nHardy, and W.R. Nord (eds), Handbook of organization studies, London: Sage, pp.526-542. \nGabbay, J. & le May, A., 2010. Practice-based evidence for healthcare, London: Routledge.  \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n16 \nGraham, I.D. et al., 2006. Lost in knowledge translation: time for a map? Journal of Continuing \nEducation in the Health Professions, 26(1), pp.13-24. \nGrol, R. & Grimshaw, J., 1999. Evidence-based implementation of evidence-based medicine. Joint \nCommission Journal on Quality Improvement, 25(10), pp.503-513. \nKolb, D.A., 1984. Experiential learning, Englewood Cliffs, NJ: Prentice-Hall. \nKontos, P. & Poland, B., 2009. Mapping new theoretical and methodological terrain for \nknowledge translation: contributions from critical realism and the arts. Implementation Science, \n4(1), p.1. \nLave, J. & Wenger, E., 1991. Situated learning: legitimate peripheral participation, Cambridge: \nCambridge University Press. \nLomas, J., 2007. The in-between world of knowledge brokering. British Medical Journal, 334(7585), \npp.129-132. \nMcGlynn, E.A., Asch, S.M., et al., 2003. The quality of health care delivered to adults in the \nUnited States. New England Journal of Medicine, 348(26), pp.2635-2645. \nMcGuire, M. & Agranoff, R., 2011. The limitations of public management networks. Public \nAdministration 89(2): 265-284. \nModernisation Agency, 2004. Complexity of sustaining healthcare improvements: what have we learned so far, \nLondon: NHS Modernisation Agency. \nNHS Institute, 2005. Sustainability model and guide, Coventry: NHS Institute for Innovation and \nImprovement. \nNowotny, H., Scott, P. & Gibbons, M., 2003. \u201cMode 2\u201d revisited: the new production of \nknowledge. Minerva, 41(3), pp.179-194. \nNutley, S.M., Walter, I. & Davies, H.T.O., 2007. Using evidence, Bristol: Policy Press. \nOwen, J.M., 2007. Program evaluation: forms and approaches, London: Guilford Press. \nPatton, M.Q., 2008. Utilization-focused evaluation, Sage Publications. \nPatton, M.Q., 2010. Developmental evaluation: applying complexity concepts to enhance innovation and use, \nNew York: Guilford Press. \nPawson, R. & Tilley, N., 1997. Realistic evaluation, London: Sage. \nPopp, J.K., L\u201fHeureux, L.N., Dolinksi, C.M., Adair, C.E., Tough, S.C., Casebeer, A.L., Douglas-\nEngland, K.L. & Morrison, C.C., 2005. How do you evaluate a network? A Canadian child \nand youth health network experience. Canadian Journal of Program Evaluation 20(3): 123-150. \nProvan, K.G. & Milward, H.B., 2001. Do networks really work? A framework for evaluating \npublic-sector organizational networks. Public Administration Review 61(4): pp.414-423. \nRaelin, J., 2009. Seeking conceptual clarity in the action modalities. Action Learning: Research and \nPractice, 6(1), pp.17-24. \nRussell, J., Greenhalgh, T., Boynton, P. & Rigby, M., 2004. Soft networks for bridging the gap \nbetween research and practice: illuminative evaluation of CHAIN. British Medical Journal \n328: pp.1174-1177. \nRycroft-Malone, J. & Bucknall, T., 2010. Models and frameworks for implementing evidence-based practice: \nlinking evidence to action, Chichester: Wiley. \nRycroft-Malone, J., Wilkinson, J.E., Burton, C.R., Andrews, G., Ariss, S., Baker, R., Dopson, S., \nGraham, I., Harvey, G., Martin, G., McCormack, B.G., Staniszewska, S. & Thompson, C., \n2011. Implementing health research through academic and clinical partnerships: a realistic \nevaluation of the Collaborations for Leadership in Applied Health Research and Care \n(CLAHRC). Implementation Science 6:74. \nSchuster, M.A., McGlynn, E.A. & Brook, R.H., 2005. How good is the quality of health care in \nthe United States? Milbank Quarterly, 83(4), pp.843-895. \nWeiss, C.H., 1995. Nothing as practical as good theory: exploring theory-based evaluation for \ncomprehensive community initiatives for children and families. In J. P. Connell et al., eds. \n\u00a9 2011 The Policy Press. This is a post-peer-review, pre-copy edited version of an article published in \nEvidence & Policy. The definitive publisher-authenticated version is available online at: \nwww.ingentaconnect.com\/content\/tpp\/ep\/2011\/00000007\/00000004\/art00006 \n17 \nNew approaches to evaluating community initiatives: concepts, methods, and contexts, New York: Aspen \nInstitute. \nWeiss, C.H., 1998. Evaluation: methods for studying programs and policies, New Jersey: Prentice Hall. \nWood, M., Ferlie, E. & Fitzgerald, L., 1998. Achieving clinical behaviour change: a case of \nbecoming indeterminate. Social Science & Medicine, 47(11), pp.1729-1738. \n"}
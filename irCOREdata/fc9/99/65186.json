{"doi":"10.1613\/jair.1400","coreId":"65186","oai":"oai:dro.dur.ac.uk.OAI2:6671","identifiers":["oai:dro.dur.ac.uk.OAI2:6671","10.1613\/jair.1400"],"title":"A maximal tractable class of soft constraints.","authors":["Cohen,  D.","Cooper,  M.","Jeavons,  P.","Krokhin,  A."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2004-07-01","abstract":"Many researchers in artificial intelligence are beginning to explore the use of soft constraints to express a set of (possibly conflicting) problem requirements. A soft constraint is a function defined on a collection of variables which associates some measure of desirability with each possible combination of values for those variables. However, the crucial question of the computational complexity of finding the optimal solution to a collection of soft constraints has so far received very little attention. In this paper we identify a class of soft binary constraints for which the problem of finding the optimal solution is tractable. In other words, we show that for any given set of such constraints, there exists a polynomial time algorithm to determine the assignment having the best overall combined measure of desirability. This tractable class includes many commonly-occurring soft constraints, such as 'as near as possible' or 'as soon as possible after', as well as crisp constraints such as 'greater than'. Finally, we show that this tractable class is maximal, in the sense that adding any other form of soft binary constraint which is not in the class gives rise to a class of problems which is NP-hard.\\ud\n\\u","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65186.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/6671\/1\/6671.pdf","pdfHashValue":"b4414b702a69c8a49d60098912f686c341062132","publisher":"AI Access Foundation","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:6671<\/identifier><datestamp>\n      2011-12-14T09:50:03Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        A maximal tractable class of soft constraints.<\/dc:title><dc:creator>\n        Cohen,  D.<\/dc:creator><dc:creator>\n        Cooper,  M.<\/dc:creator><dc:creator>\n        Jeavons,  P.<\/dc:creator><dc:creator>\n        Krokhin,  A.<\/dc:creator><dc:description>\n        Many researchers in artificial intelligence are beginning to explore the use of soft constraints to express a set of (possibly conflicting) problem requirements. A soft constraint is a function defined on a collection of variables which associates some measure of desirability with each possible combination of values for those variables. However, the crucial question of the computational complexity of finding the optimal solution to a collection of soft constraints has so far received very little attention. In this paper we identify a class of soft binary constraints for which the problem of finding the optimal solution is tractable. In other words, we show that for any given set of such constraints, there exists a polynomial time algorithm to determine the assignment having the best overall combined measure of desirability. This tractable class includes many commonly-occurring soft constraints, such as 'as near as possible' or 'as soon as possible after', as well as crisp constraints such as 'greater than'. Finally, we show that this tractable class is maximal, in the sense that adding any other form of soft binary constraint which is not in the class gives rise to a class of problems which is NP-hard.\\ud\n\\ud\n<\/dc:description><dc:publisher>\n        AI Access Foundation<\/dc:publisher><dc:source>\n        Journal of artificial intelligence research, 2004, Vol.22, pp.1-22 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2004-07-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:6671<\/dc:identifier><dc:identifier>\n        issn:1076-9757<\/dc:identifier><dc:identifier>\n        doi:10.1613\/jair.1400<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6671\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1613\/jair.1400<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6671\/1\/6671.pdf<\/dc:identifier><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:1076-9757","1076-9757"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2004,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n07 April 2010\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nCohen, D. and Cooper, M. and Jeavons, P. and Krokhin, A. (2004) \u2019A maximal tractable class of soft\nconstraints.\u2019, Journal of artificial intelligence research., 22 . pp. 1-22.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1613\/jair.1400\nPublisher\u2019s copyright statement:\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n  \n \nDurham Research Online \n \nDeposited in DRO: \n07 April 2010 \n \nPeer-review status: \nPeer-reviewed \n \nPublication status: \nPublished version \n \nCitation for published item: \nCohen, D. and Cooper, M. and Jeavons, P. and Krokhin, A. (2004) 'A maximal tractable \nclass of soft constraints.', Journal of artificial intelligence research., 22 . pp. 1-22. \n \nFurther information on publisher\u2019s website: \nhttp:\/\/dx.doi.org\/10.1613\/jair.1400 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nUse policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior \npermission or charge, for personal research or study, educational, or not-for-profit purposes provided that : \n \n\uf0a7 a full bibliographic reference is made to the original source \n\uf0a7 a link is made to the metadata record in DRO \n\uf0a7 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders. \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nJournal of Arti\fcial Intelligence Research 22 (2004) 1-22 Submitted 12\/03; published 7\/04\nA Maximal Tractable Class of Soft Constraints\nDavid Cohen d.cohen@rhul.ac.uk\nComputer Science Department\nRoyal Holloway, University of London, UK\nMartin Cooper cooper@irit.fr\nIRIT\nUniversity of Toulouse III, France\nPeter Jeavons peter.jeavons@comlab.ox.ac.uk\nOUCL\nUniversity of Oxford, UK\nAndrei Krokhin ak@dcs.warwick.ac.uk\nComputer Science Department\nUniversity of Warwick, UK\nAbstract\nMany researchers in arti\fcial intelligence are beginning to explore the use of soft con-\nstraints to express a set of (possibly con\ricting) problem requirements. A soft constraint is\na function de\fned on a collection of variables which associates some measure of desirability\nwith each possible combination of values for those variables. However, the crucial question\nof the computational complexity of \fnding the optimal solution to a collection of soft con-\nstraints has so far received very little attention. In this paper we identify a class of soft\nbinary constraints for which the problem of \fnding the optimal solution is tractable. In\nother words, we show that for any given set of such constraints, there exists a polynomial\ntime algorithm to determine the assignment having the best overall combined measure of\ndesirability. This tractable class includes many commonly-occurring soft constraints, such\nas \\as near as possible\" or \\as soon as possible after\", as well as crisp constraints such as\n\\greater than\". Finally, we show that this tractable class is maximal, in the sense that\nadding any other form of soft binary constraint which is not in the class gives rise to a class\nof problems which is NP-hard.\n1. Introduction\nThe constraint satisfaction framework is widely acknowledged as a convenient and e\u00c6cient\nway to model and solve a wide variety of problems arising in Arti\fcial Intelligence, including\nplanning (Kautz & Selman, 1992) and scheduling (van Beek, 1992), image processing (Mon-\ntanari, 1974) and natural language understanding (Allen, 1995).\nIn the standard framework a constraint is usually taken to be a predicate, or relation,\nspecifying the allowed combinations of values for some \fxed collection of variables: we will\nrefer to such constraints here as crisp constraints. A number of authors have suggested\nthat the usefulness of the constraint satisfaction framework could be greatly enhanced by\nextending the de\fnition of a constraint to include also soft constraints, which allow di\u000berent\nmeasures of desirability to be associated with di\u000berent combinations of values (Bistarelli\net al., 1997, 1999). In this extended framework a constraint can be seen as a function,\nc\n\r2004 AI Access Foundation. All rights reserved.\nCohen, Cooper, Jeavons, & Krokhin\nmapping each possible combination of values to a measure of desirability or undesirability.\nFinding a solution to a set of constraints then means \fnding an assignment of values to all\nof the variables which has the best overall combined desirability measure.\nExample 1.1 Consider an optimization problem with 2n variables, v\n1\n; v\n2\n; : : : ; v\n2n\n, where\nwe wish to assign each variable an integer value in the range 1; 2; : : : ; n, subject to the\nfollowing restrictions:\n\u000f Each variable v\ni\nshould be assigned a value that is as close as possible to i=2.\n\u000f Each pair of variables v\ni\n, v\n2i\nshould be assigned a pair of values that are as close as\npossible to each other.\nTo model this situation we might impose the following soft constraints:\n\u000f A unary constraint on each v\ni\nspeci\fed by a function  \ni\n,\nwhere  \ni\n(x) = (x\u0000 i=2)\n2\n.\n\u000f A binary constraint on each pair v\ni\n; v\n2i\nspeci\fed by a function \u00c6\nr\n,\nwhere \u00c6\nr\n(x; y) = jx\u0000 yj\nr\nfor some r \u0015 1.\nWe would then seek an assignment to all of the variables which minimizes the sum of all of\nthese constraint functions,\n2n\nX\ni=1\n \ni\n(v\ni\n) +\nn\nX\ni=1\n\u00c6\nr\n(v\ni\n; v\n2i\n):\nThe cost of allowing additional \rexibility in the speci\fcation of constraints, in order to\nmodel requirements of this kind, is generally an increase in computational di\u00c6culty. In\nthe case of crisp constraints there has been considerable progress in identifying classes of\nconstraints which are tractable, in the sense that there exists a polynomial time algorithm\nto determine whether or not any collection of constraints from such a class can be simul-\ntaneously satis\fed (Bulatov, 2003; Feder & Vardi, 1998; Jeavons et al., 1997). In the case\nof soft constraints there has been a detailed investigation of the tractable cases for Boolean\nproblems (where each variable has just 2 possible values) (Creignou et al., 2001), but very\nlittle investigation of the tractable cases over larger \fnite domains, even though there are\nmany signi\fcant results in the literature on combinatorial optimization which are clearly\nrelevant to this question (Nemhauser & Wolsey, 1988).\nThe only previous work we have been able to \fnd on the complexity of non-Boolean\nsoft constraints is a paper by Khatib et al. (2001), which describes a family of tractable soft\ntemporal constraints. However, the framework for soft constraints used by Khatib et al.\n(2001) is di\u000berent from the one we use here, and the results are not directly comparable.\nWe discuss the relationship between this earlier work and ours more fully in Section 5.\nIn this paper we make use of the idea of a submodular function (Nemhauser & Wolsey,\n1988) to identify a general class of soft constraints for which there exists a polynomial time\nsolution algorithm. Submodular functions are widely used in economics and operational\nresearch (Fujishige, 1991; Nemhauser & Wolsey, 1988; Topkis, 1998), and the notion of\nsubmodularity provides a kind of discrete analogue of convexity (Lov\u0013asz, 1983).\n2\nA Maximal Tractable Class of Soft Constraints\nSubmodular functions are usually de\fned (Nemhauser & Wolsey, 1988) as real-valued\nfunctions on sets (which may be viewed as Boolean tuples), but we consider here the more\ngeneral case of functions on tuples over an arbitrary \fnite domain (as in Topkis, 1978). We\nalso allow our functions to take in\fnite values. By establishing a new decomposition result\nfor binary submodular functions of this kind, we obtain a cubic time algorithm to \fnd the\noptimal assignment for any set of soft constraints which can be de\fned using them (such as\nthe constraints in Example 1.1). Because our algorithm is specially devised for submodular\nfunctions that are expressed as a combination of binary functions, it is much more e\u00c6cient in\nthis case than existing general algorithms for submodular function minimization (Schrijver,\n2000; Iwata et al., 2001).\nWe give a number of examples to illustrate the many di\u000berent forms of soft constraint\nthat can be de\fned using binary submodular functions, and we also show that this class\nis maximal, in the sense that no other form of binary constraint can be added to the class\nwithout sacri\fcing tractability.\n2. De\fnitions\nTo identify a tractable class of soft constraints we will need to restrict the set of functions\nthat are used to specify constraints. Such a restricted set of possible functions will be called\na soft constraint language.\nDe\fnition 2.1 Let D and E be \fxed sets. A soft constraint language over D with evalu-\nations in E is de\fned to be a set of functions, \u0000, such that each \u001e 2 \u0000 is a function from\nD\nk\nto E, for some k 2 N, where k is called the arity of \u001e.\nFor any given choice of soft constraint language, \u0000, we de\fne an associated soft constraint\nsatisfaction problem, which we will call sCSP(\u0000), as follows.\nDe\fnition 2.2 Let \u0000 be a soft constraint language over D with evaluations in E. An\ninstance P of sCSP(\u0000) is a triple hV;D;Ci, where:\n\u000f V is a \fnite set of variables, which must be assigned values from the set D.\n\u000f C is a set of soft constraints. Each c 2 C is a pair h\u001b; \u001ei where: \u001b is a list of variables,\nof length j\u001bj, called the scope of c; and \u001e is an element of \u0000 of arity j\u001bj, called the\nevaluation function of c.\nThe evaluation function \u001e will be used to specify some measure of desirability or undesir-\nability associated with each possible tuple of values over \u001b.\nTo complete the de\fnition of a soft constraint satisfaction problem we need to de\fne how\nthe evaluations obtained from each evaluation function are combined and compared, in order\nto de\fne what constitutes an optimal overall solution. Several alternative mathematical\napproaches to this issue have been suggested in the literature:\n\u000f In the semiring based approach (Bistarelli et al., 1997, 1999), the set of possible\nevaluations, E, is assumed to be an algebraic structure equipped with two binary\noperations, satisfying the axioms of a semiring. One example of such a structure is\nthe real interval [0; 1], equipped with the operations min and max, which corresponds\n3\nCohen, Cooper, Jeavons, & Krokhin\nto the conjunctive fuzzy CSP framework (Rosenfeld et al., 1976; Ruttkay, 1994).\nAnother example is the set f0; 1; 2; : : :g[f1g, equipped with the operations max and\nplus, which corresponds to the weighted CSP framework (Bistarelli et al., 1999).\n\u000f In the valued CSP approach (Bistarelli et al., 1999), the set of possible evaluations E\nis assumed to be a totally ordered algebraic structure with a top and bottom element\nand a single monotonic binary operation known as aggregation. One example of such\na structure is the set of multisets over some \fnite ordered set together with a top\nelement, equipped with the operation of multiset union, which corresponds to the\nlexicographic CSP framework (Bistarelli et al., 1999).\nFor our purposes, we require the same properties as the valued CSP approach, with the\nadditional requirement that the aggregation operation has a partial inverse, such that eval-\nuations other than the top element may be \\cancelled\" when occurring on both sides of an\ninequality. For simplicity, we shall assume throughout this paper that the set of evaluations\nE is either the set of non-negative integers together with in\fnity, or else the set of non-\nnegative real numbers together with in\fnity\n1\n. Hence, throughout this paper the bottom\nelement in the evaluation structure is 0, the top element is 1, and for any two evaluations\n\u001a\n1\n; \u001a\n2\n2 E, the aggregation of \u001a\n1\nand \u001a\n2\nis given by \u001a\n1\n+ \u001a\n2\n2 E. Moreover, when \u001a\n1\n\u0015 \u001a\n2\nwe also have \u001a\n1\n\u0000 \u001a\n2\n2 E. (Note that we set 1\u00001 =1).\nThe elements of the set E are used to represent di\u000berent measure of undesirability, or\npenalties, associated with di\u000berent combinations of values. This allows us to complete the\nde\fnition of a soft constraint satisfaction problem with the following simple de\fnition of a\nsolution to an instance.\nDe\fnition 2.3 For any soft constraint satisfaction problem instance P = hV;D;Ci, an\nassignment for P is a mapping t from V to D. The evaluation of an assignment t, denoted\n\b\nP\n(t), is given by the sum (i.e., aggregation) of the evaluations for the restrictions of t\nonto each constraint scope, that is,\n\b\nP\n(t) =\nX\nhhv\n1\n; v\n2\n; : : : ; v\nk\ni; \u001ei2C\n\u001e(t(v\n1\n); t(v\n2\n); : : : ; t(v\nk\n)):\nA solution to P is an assignment with the smallest possible evaluation, and the question is\nto \fnd a solution.\nExample 2.4 For any standard constraint satisfaction problem instance P with crisp con-\nstraints, we can de\fne a corresponding soft constraint satisfaction problem instance\nb\nP in\nwhich the range of the evaluation functions of all the constraints is the set f0;1g. For each\ncrisp constraint c of P, we de\fne a corresponding soft constraint bc of\nb\nP with the same scope;\nthe evaluation function of bc maps each tuple allowed by c to 0, and each tuple disallowed\nby c to 1.\nIn this case the evaluation of an assignment t for\nb\nP equals the minimal possible evalu-\nation, 0, if and only if t satis\fes all of the crisp constraints in P .\n1. Many of our results can be extended to more general evaluation structures, such as the strictly monotonic\nstructures described by Cooper (2003), but we will not pursue this idea here.\n4\nA Maximal Tractable Class of Soft Constraints\nExample 2.5 For any standard constraint satisfaction problem instance P with crisp con-\nstraints, we can de\fne a corresponding soft constraint satisfaction problem instance P\n#\nin\nwhich the range of the evaluation functions of all the constraints is the set f0; 1g. For each\ncrisp constraint c of P , we de\fne a corresponding soft constraint c\n#\nof P\n#\nwith the same\nscope; the evaluation function of c\n#\nmaps each tuple allowed by c to 0, and each tuple\ndisallowed by c to 1.\nIn this case the evaluation of an assignment t for P\n#\nequals the number of crisp con-\nstraints in P which are violated by t. Hence a solution to P\n#\ncorresponds to an assignment\nwhich violates the minimal number of constraints of P , and hence satis\fes the maximal\nnumber of constraints of P. Finding assignments of this kind is generally referred to as\nsolving the Max-CSP problem (Freuder & Wallace, 1992; Larrosa et al., 1999).\nNote that the problem of \fnding a solution to a soft constraint satisfaction problem is an\nNP optimization problem, that is, it lies in the complexity class NPO (see Creignou et al.,\n2001 for a formal de\fnition of this class). If there exists a polynomial-time algorithm which\n\fnds a solution to all instances of sCSP(\u0000), then we shall say that sCSP(\u0000) is tractable. On\nthe other hand, if there is a polynomial-time reduction from some NP-complete problem to\nsCSP(\u0000), then we shall say that sCSP(\u0000) is NP-hard.\nExample 2.6 Let \u0000 be a soft constraint language over D, where jDj = 2. In this case\nsCSP(\u0000) is a class of Boolean soft constraint satisfaction problems.\nIf we restrict \u0000 even further, by only allowing functions with range f0;1g, as in Ex-\nample 2.4, then sCSP(\u0000) corresponds precisely to a standard Boolean crisp constraint sat-\nisfaction problem. Such problems are sometimes known as Generalized Satisfiabil-\nity problems (Schaefer, 1978). The complexity of sCSP(\u0000) for such restricted sets \u0000 has\nbeen completely characterised, and it has been shown that there are precisely six tractable\ncases (Schaefer, 1978; Creignou et al., 2001).\nAlternatively, if we restrict \u0000 by only allowing functions with range f0; 1g, as in Exam-\nple 2.5, then sCSP(\u0000) corresponds precisely to a standard Boolean maximum satis\fability\nproblem, in which the aim is to satisfy the maximum number of crisp constraints. Such\nproblems are sometimes known as Max-Sat problems (Creignou et al., 2001). The com-\nplexity of sCSP(\u0000) for such restricted sets \u0000 has been completely characterised, and it has\nbeen shown that there are precisely three tractable cases (see Theorem 7.6 of Creignou\net al., 2001).\nWe note, in particular, that when \u0000 contains just the single binary function \u001e\nXOR\nde\fned by\n\u001e\nXOR\n(x; y) =\n\u001a\n0 if x 6= y\n1 otherwise\nthen sCSP(\u0000) corresponds to the Max-Sat problem for the exclusive-or predicate, which\nis known to be NP-hard (see Lemma 7.4 of Creignou et al., 2001).\nExample 2.7 Let \u0000 be a soft constraint language over D = f1; 2; : : : ;Mg, where M \u0015 3,\nand assume that \u0000 contains just the set of all unary functions, together with the single\nbinary function \u001e\nEQ\nde\fned by\n\u001e\nEQ\n(x; y) =\n\u001a\n0 if x = y\n1 otherwise.\n5\nCohen, Cooper, Jeavons, & Krokhin\nEven in this very simple case it can be shown that sCSP(\u0000) is NP-hard, by reduction\nfrom the Minimum 3-terminal Cut problem (Dahlhaus et al., 1994). An instance of this\nproblem consists of an undirected graph (V;E) in which each edge e 2 E has an associated\nweight, together with a set of distinguished vertices, fv\n1\n; v\n2\n; v\n3\ng \u0012 V , known as terminals.\nThe problem is to \fnd a set of edges with the smallest possible total weight whose removal\ndisconnects each possible pair of terminals. Such a set is known as a minimum 3-terminal\ncut.\nTo obtain the reduction to sCSP(\u0000), let I be an instance ofMinimum 3-Terminal Cut\nconsisting of the graph hV;Ei with terminals fv\n1\n; v\n2\n; v\n3\ng. We construct a corresponding\ninstance P\nI\nof sCSP(\u0000) as follows. The variables of P\nI\ncorrespond to the set of vertices V .\nFor each edge fv\ni\n; v\nj\ng 2 E, add a binary soft constraint with scope hv\ni\n; v\nj\ni and evaluation\nfunction \u001e\nEQ\n, as above. Finally, for each terminal v\ni\n2 fv\n1\n; v\n2\n; v\n3\ng, add a unary constraint\non the variable v\ni\nwith evaluation function  \ni\n, de\fned as follows:\n \ni\n(x) =\n\u001a\n0 if x = i\njEj+ 1 otherwise\nIt is straightforward to check that the number of edges in a minimum 3-terminal cut of I\nis equal to the evaluation of a solution to P\nI\n.\nThe examples above indicate that generalizing the constraint satisfaction framework to in-\nclude soft constraints does indeed increase the computational complexity, in general. For\nexample, the standard 2-Satisfiability problem is tractable, but the soft constraint sat-\nisfaction problem involving only the single binary Boolean function, \u001e\nXOR\n, de\fned at the\nend of Example 2.6, is NP-hard. Similarly, the standard constraint satisfaction problem\ninvolving only crisp unary constraints and equality constraints is clearly trivial, but the soft\nconstraint satisfaction problem involving only soft unary constraints and a soft version of\nthe equality constraint, speci\fed by the function \u001e\nEQ\nde\fned in Example 2.7, is NP-hard.\nHowever, in the next two sections we will show that it is possible to identify a large class\nof functions for which the corresponding soft constraint satisfaction problem is tractable.\n3. Generalized Interval Functions\nWe begin with a rather restricted class of binary functions, with a very special structure.\nDe\fnition 3.1 Let D be a totally ordered set. A binary function, \u001e : D\n2\n! E will be called\na generalized interval function on D if it has the following form:\n\u001e(x; y) =\n\u001a\n0 if (x < a) _ (y > b);\n\u001a otherwise\nfor some a; b 2 D and some \u001a 2 E. Such a function will be denoted \u0011\n\u001a\n[a;b]\n.\nWe can explain the choice of name for these functions by considering the unary function\n\u0011\n\u001a\n[a;b]\n(x; x). This function returns the value \u001a if and only if its argument lies in the interval\n[a; b]; outside of this interval it returns the value 0.\nWe shall write \u0000\nGI\nto denote the set of all generalized interval functions on D, where\nD = f1; 2; : : : ;Mg with the usual ordering.\n6\nA Maximal Tractable Class of Soft Constraints\ny\n1 \u0001 \u0001 \u0001 b b+ 1 \u0001 \u0001 \u0001 M\nx\n1\n.\n.\n.\na\u0000 1\na\n.\n.\n.\nM\n0\nB\nB\nB\nB\nB\nB\nB\nB\n@\n0 \u0001 \u0001 \u0001 0 0 \u0001 \u0001 \u0001 0\n.\n.\n.\n0\n.\n.\n.\n.\n.\n.\n0\n.\n.\n.\n0 \u0001 \u0001 \u0001 0 0 \u0001 \u0001 \u0001 0\n\u001a \u0001 \u0001 \u0001 \u001a 0 \u0001 \u0001 \u0001 0\n.\n.\n.\n\u001a\n.\n.\n.\n.\n.\n.\n0\n.\n.\n.\n\u001a \u0001 \u0001 \u0001 \u001a 0 \u0001 \u0001 \u0001 0\n1\nC\nC\nC\nC\nC\nC\nC\nC\nA\nFigure 1: The table of values for the function \u0011\n\u001a\n[a;b]\nNote that the table of values for any function \u0011\n\u001a\n[a;b]\n2 \u0000\nGI\ncan be written as an M \u0002M\nmatrix in which all the entries are 0, except for the rectangular region lying between posi-\ntions ha; 1i and hM:bi, where the entries have value \u001a, as illustrated in Figure 1. Hence when\n\u001a = 1, a soft constraint with evaluation function \u0011\n\u001a\n[a;b]\nis equivalent to a crisp constraint\nwhich is a particular form of connected row-convex constraint (Deville et al., 1999).\nThe main result of this section is Corollary 3.6, which states that sCSP(\u0000\nGI\n) is tractable.\nTo establish this result we \frst de\fne a weighted directed graph\n2\nassociated with each\ninstance of sCSP(\u0000\nGI\n) (see Figure 2).\nDe\fnition 3.2 Let P = hV; f1; : : : ;Mg; Ci be an instance of sCSP(\u0000\nGI\n). We de\fne the\nweighted directed graph G\nP\nas follows.\n\u000f The vertices of G\nP\nare as follows: fS; Tg [ fv\nd\nj v 2 V; d 2 f0; 1; : : : ;Mgg:\n\u000f The edges of G\nP\nare de\fned as follows:\n{ For each v 2 V , there is an edge from S to v\nM\nwith weight 1;\n{ For each v 2 V , there is an edge from v\n0\nto T with weight 1;\n{ For each v 2 V and each d 2 f1; 2; : : : ;M \u0000 2g, there is an edge from v\nd\nto v\nd+1\nwith weight 1;\n{ For each constraint hhv; wi; \u0011\n\u001a\n[a;b]\ni 2 C, there is an edge from w\nb\nto v\na\u00001\nwith\nweight \u001a. These edges are called \\constraint edges\".\n2. This construction was inspired by a similar construction for certain Boolean constraints described\nby Khanna et al. (2000).\n7\nCohen, Cooper, Jeavons, & Krokhin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00ff\n\n\nFigure 2: The graph G\nP\nassociated with the instance P de\fned in Example 3.3.\n(Note that solid arrows indicate edges with in\fnite weight.)\nExample 3.3 Let P = hfx; y; zg; f1; 2; 3; 4g; Ci be an instance of sCSP(\u0000\nGI\n) with the\nfollowing four constraints:\nc\n1\n= hhy; xi; \u0011\n3\n[3;4]\ni\nc\n3\n= hhz; yi; \u0011\n7\n[1;3]\ni\nc\n2\n= hhy; zi; \u0011\n2\n[4;3]\ni\nc\n4\n= hhz; zi; \u0011\n1\n[2;4]\ni\nThe corresponding weighted directed graph G\nP\n, is shown in Figure 2.\nAny set of edges C in the graph G\nP\nwhose removal leaves the vertices S and T disconnected\nwill be called a cut. If C is a minimal set of edges with this property, in the sense that\nremoving any edge from C leaves a set of edges which is not a cut, then C will called a\nminimal cut. If every edge in C is a constraint edge, then C will be called a proper cut.\nThe weight of a cut C is de\fned to be the sum of the weights of all the edges in C.\nExample 3.4 Consider the graph G\nP\nshown in Figure 2. The set fhy\n3\n; z\n0\nig is a proper cut\ninG\nP\nwith weight 7, which is minimal in the sense de\fned above. The set fhx\n4\n; y\n2\ni; hz\n3\n; y\n3\nig\nis also a proper cut in G\nP\nwith weight 5, which is again minimal in the sense de\fned above.\n8\nA Maximal Tractable Class of Soft Constraints\nProposition 3.5 Let P be any instance of sCSP(\u0000\nGI\n), and let G\nP\nbe the associated\nweighted directed graph, as speci\fed in De\fnition 3.2.\n1. For each minimal proper cut in G\nP\nwith weight \b, there is an assignment for P with\nevaluation \b.\n2. For each assignment t for P with evaluation \b, there is a proper cut in G\nP\nwith\nweight \b.\nProof:\n1. Let C be any minimal proper cut of the graph G\nP\n, and let C\nS\nbe the component of\nG\nP\nnC connected to S. Since C is proper, C\nS\nalways contains v\nM\n, and never contains\nv\n0\n, so we can de\fne the assignment t\nC\nas follows:\nt\nC\n(v) = minfd j v\nd\n2 C\nS\ng\nBy the construction of G\nP\n, it follows that:\nt\nC\n(v) > d , v\nd\n62 C\nS\n(1)\nNow consider any constraint c = hhv; wi; \u0011\n\u001a\n[a;b]\ni of P , and its associated edge e in G\nP\n.\nBy De\fnition 3.1 and Equation 1, \u0011\n\u001a\n[a;b]\n(t\nC\n(v); t\nC\n(w)) = \u001a if and only if v\na\u00001\n62 C\nS\nand\nw\nb\n2 C\nS\n, and hence if and only if e joins a vertex in C\nS\nto a vertex not in C\nS\n. Since\nC is minimal, this happens if and only if e 2 C. Hence, the total weight of the cut C\nis equal to the evaluation of t\nC\n.\n2. Conversely, let t be an assignment to P, and let K be the set of constraints in P with\na non-zero evaluation on t.\nNow consider any path from S to T in G\nP\n. If we examine, in order, the constraint\nedges of this path, and assume that each of the corresponding constraints evaluates\nto 0, then we obtain a sequence of assertions of the following form:\n(v\ni\n0\n> M) _ (v\ni\n1\n< a\n1\n)\n(v\ni\n1\n> b\n2\n) _ (v\ni\n2\n< a\n2\n) for some b\n2\n\u0015 a\n1\n.\n.\n.\n(v\ni\nk\u00001\n> b\nk\n) _ (v\ni\nk\n< a\nk\n) for some b\nk\n\u0015 a\nk\u00001\n(v\ni\nk\n> b\nk+1\n) _ (v\ni\nk+1\n< 1) for some b\nk+1\n\u0015 a\nk\nSince the second disjunct of each assertion contradicts the \frst disjunct of the next,\nthese assertions cannot all hold simultaneously, so one of the corresponding constraints\nmust in fact give a non-zero evaluation on t. Hence, every path from S to T includes at\nleast one edge corresponding to a constraint from K, and so the edges corresponding\nto the set K form a cut in G\nP\n. Furthermore, by the choice of K, the weight of this\ncut is equal to the evaluation of t.\nHence, by using a standard e\u00c6cient algorithm for the Minimum Weighted Cut prob-\nlem (Goldberg & Tarjan, 1988), we can \fnd an optimal assignment in cubic time, as the\nnext result indicates.\n9\nCohen, Cooper, Jeavons, & Krokhin\nCorollary 3.6 The time complexity of sCSP(\u0000\nGI\n) is O(n\n3\njDj\n3\n), where n is the number of\nvariables.\nProof: Let P = hV;D;Ci be any instance of sCSP(\u0000\nGI\n), and let G\nP\nbe the corresponding\nweighted directed graph. If the minimum weight for a cut in G\nP\nis ! <1, then it must be\na proper cut, so P has a solution with evaluation !, by Proposition 3.5. Moreover, if the\nminimum weight for a cut in G\nP\nis1, then the evaluation of every assignment for P is1.\nHence we have established a linear-time reduction from sCSP(\u0000\nGI\n) to the Minimum\nWeighted Cut problem.\nSince G\nP\nhas v = jV j(jDj + 1) + 2 vertices, and the time complexity of Minimum\nWeighted Cut is O(v\n3\n) (Goldberg & Tarjan, 1988), the result follows.\n4. Submodular Functions\nIn this section we will consider a rather more general and useful class of functions, as\ndescribed by Topkis (1978).\nDe\fnition 4.1 Let D be a totally ordered set. A function, \u001e : D\nk\n! E is called a sub-\nmodular function on D if, for all ha\n1\n; : : : ; a\nk\ni; hb\n1\n; : : : ; b\nk\ni 2 D\nk\n, we have\n\u001e(min(a\n1\n; b\n1\n); : : : ;min(a\nk\n; b\nk\n)) + \u001e(max(a\n1\n; b\n1\n); : : : ;max(a\nk\n; b\nk\n))\n\u0014 \u001e(a\n1\n; : : : ; a\nk\n) + \u001e(b\n1\n; : : : ; b\nk\n):\nIt is easy to check that all unary functions and all generalized interval functions are submod-\nular. It also follows immediately from De\fnition 4.1 that the sum of any two submodular\nfunctions is submodular. This suggests that in some cases it may be possible to express a\nsubmodular function as a sum of simpler submodular functions. For example, for any unary\nfunction  : D ! E we have\n (x) \u0011\nX\nd2D\n\u0011\n (d)\n[d;d]\n(x; x):\nFor binary functions, the de\fnition of submodularity can be expressed in a simpli\fed form,\nas follows.\nRemark 4.2 Let D be a totally ordered set. A binary function, \u001e : D\n2\n! E is submodular\nif and only if, for all u; v; x; y 2 D, with u \u0014 x and v \u0014 y, we have:\n\u001e(u; v) + \u001e(x; y) \u0014 \u001e(u; y) + \u001e(x; v)\nNote that when u = x or v = y this inequality holds trivially, so it is su\u00c6cient to check only\nthose cases where u < x and v < y.\nExample 4.3 Let D be the set f1; 2; : : : ;Mg with the usual ordering, and consider the\nbinary function \u0019\nM\n, de\fned by \u0019\nM\n(x; y) =M\n2\n\u0000 xy.\nFor any u; v; x; y 2 D, with u < x and v < y, we have:\n\u0019\nM\n(u; v) + \u0019\nM\n(x; y) = 2M\n2\n\u0000 uv \u0000 xy\n= 2M\n2\n\u0000 uy \u0000 xv \u0000 (x\u0000 u)(y \u0000 v)\n\u0014 \u0019\nM\n(u; y) + \u0019\nM\n(x; v):\nHence, by Remark 4.2, the function \u0019\nM\nis submodular.\n10\nA Maximal Tractable Class of Soft Constraints\nA real-valued m\u0002 n matrix A with the property that\nA\nuv\n+A\nxy\n\u0014 A\nuy\n+A\nxv\n; for all 1 \u0014 u < x \u0014 m, 1 \u0014 v < y \u0014 n\nis known in operational research as a Monge matrix (for a survey of the properties of such\nmatrices and their use in optimization, see Burkard et al., 1996). It is clear from Remark 4.2\nthat the table of values for a real-valued binary submodular function is a Monge matrix,\nand conversely, every square Monge matrix can be viewed as a table of values for a binary\nsubmodular function.\nIt was shown by Rudolf and Woeginger (1995) that an arbitrary Monge matrix can be\ndecomposed as a sum of simpler matrices. We now obtain a corresponding result for binary\nsubmodular functions, by showing that any binary submodular function can be decomposed\nas a sum of generalized interval functions. (The result we obtain below is slightly more\ngeneral than the decomposition result for Monge matrices given by Rudolf and Woeginger\n(1995), because we are allowing submodular functions to take in\fnite values.) Using this\ndecomposition result, we will show that the set of unary and binary submodular functions\nis a tractable soft constraint language.\nTo obtain our decomposition result, we use the following technical lemma.\nLemma 4.4 Let D be a totally ordered set and let \u001e : D\n2\n! E be a binary submodular\nfunction. For any a; b; c 2 D such that a \u0014 b \u0014 c, if there exists e 2 D with \u001e(e; b) = 0,\nthen for all x 2 D we have \u001e(x; b) \u0014 max(\u001e(x; a); \u001e(x; c)).\nProof: Assume that \u001e(e; b) = 0.\n\u000f If x > e then, by the submodularity of \u001e, we have \u001e(x; b) \u0014 \u001e(x; b) + \u001e(e; a) \u0014\n\u001e(x; a) + \u001e(e; b) = \u001e(x; a)\n\u000f If x < e then, by the submodularity of \u001e, we have \u001e(x; b) \u0014 \u001e(x; b) + \u001e(e; c) \u0014\n\u001e(e; b) + \u001e(x; c) = \u001e(x; c).\n\u000f If e = x then \u001e(x; b) = 0.\nHence, in all cases the result holds.\nLemma 4.5 Let D be a totally ordered \fnite set. A binary function, \u001e : D\n2\n! E is\nsubmodular if and only if it can be expressed as a sum of generalized interval functions on\nD. Furthermore, a decomposition of this form can be obtained in O(jDj\n3\n) time.\nProof: By the observations already made, any function \u001e which is equal to a sum of\ngeneralized interval functions is clearly submodular.\nTo establish the converse, we use induction on the tightness of \u001e, denoted \u001c(\u001e), that is,\nthe number of pairs for which the value of \u001e is non-zero.\nAssume that \u001e is a binary submodular function. If \u001c(\u001e) = 0, then \u001e is identically zero,\nso the result holds trivially. Otherwise, by induction, we shall assume that the result holds\nfor all binary submodular functions that have a lower tightness.\nTo simplify the notation, we shall assume that D = f1; 2; : : : ;Mg, with the usual order-\ning.\n11\nCohen, Cooper, Jeavons, & Krokhin\nWe will say that a value a 2 D is inconsistent if, for all y 2 D, \u001e(a; y) = 1. If every\na 2 D is inconsistent, then all values of \u001e are 1, so it is equal to the generalized interval\nfunction \u0011\n1\n[1;M ]\n, and the result holds. Otherwise, if there exists at least one inconsistent\nvalue, then we can \fnd a pair of values a; b 2 D, with ja\u0000 bj = 1, such that a is inconsistent\nand b is not inconsistent.\nNow de\fne the function \u001e\n0\nas follows:\n\u001e\n0\n(x; y) =\n\u001a\n\u001e(x; y) if x 6= a\n\u001e(b; y) if x = a\nIt is straightforward to check that \u001e\n0\nis submodular and \u001e(x; y) = \u001e\n0\n(x; y) + \u0011\n1\n[a;a]\n(x; x).\nSince \u001c(\u001e\n0\n) \u0014 \u001c(\u001e), it now su\u00c6ces to show that the result holds for \u001e\n0\n.\nBy repeating this procedure we may assume that \u001e has no inconsistent values, and\nby symmetry, that the reversed function \u001e\nT\n, de\fned by \u001e\nT\n(x; y) = \u001e(y; x), also has no\ninconsistent values.\nWe will say that a value a 2 D is penalized if, for all y 2 D, \u001e(a; y) > 0. If a is penalized,\nthen we set \u0016\na\n= minf\u001e(a; y)jy 2 Dg. If \u0016\na\n=1, then a is inconsistent, so we may assume\nthat \u0016\na\n<1, and de\fne a new function \u001e\n0\nas follows:\n\u001e\n0\n(x; y) =\n\u001a\n\u001e(x; y) if x 6= a\n\u001e(x; y)\u0000 \u0016\na\nif x = a:\nAgain it is straightforward to check that \u001e\n0\nis submodular and \u001e(x; y) = \u001e\n0\n(x; y)+\u0011\n\u0016\na\n[a;a]\n(x; x).\nSince \u001c(\u001e\n0\n) \u0014 \u001c(\u001e), it now su\u00c6ces to show that the result holds for \u001e\n0\n.\nBy repeating this procedure we may assume that neither \u001e nor \u001e\nT\nhas any inconsistent\nor penalized values.\nNow if, for all a; b 2 D, we have \u001e(a;M) = \u001e(M; b) = 0, then, by submodularity, for\nall a; b;2 D, \u001e(a; b) = \u001e(a; b) + \u001e(M;M) \u0014 \u001e(a;M) + \u001e(M; b) = 0, so \u001e is identically 0,\nand the result holds trivially. Otherwise, by symmetry, we can choose a to be the largest\nvalue in D such that \u001e(a;M) 6= 0. Since a is not penalized, we can then choose r to be the\nlargest value in D such that \u001e(a; r) = 0. By the choice of a, we know that r < M , and so\nwe can de\fne b = r + 1. This situation is illustrated in Figure 3.\nFor any x; y 2 D such that x \u0014 a and y \u0015 b, we have:\n\u001e(x; y) = \u001e(x; y) + \u001e(a; r) (\u001e(a; r) = 0)\n\u0015 \u001e(x; r) + \u001e(a; y) (submodularity)\n= \u001e(x; r) + max(\u001e(a; y); \u001e(a; r)) (\u001e(a; r) = 0)\n\u0015 \u001e(x; r) + \u001e(a; b) (Lemma 4.4)\n\u0015 \u001e(a; b)\nHence we can now de\fne a function \u001e\n0\nas follows:\n\u001e\n0\n(x; y) =\n8\n<\n:\n\u001e(x; y) if x > a _ y < b\n0 if x = a ^ y = b\n\u001e(x; y)\u0000 \u001e(a; b) otherwise.\nIt is straightforward to check that \u001e(x; y) = \u001e\n0\n(x; y) + \u0011\n\u001e(a;b)\n[b;a]\n(y; x). Since \u001c(\u001e\n0\n) < \u001c(\u001e), it\nonly remains to show that \u001e\n0\nis submodular, and then the result follows by induction. In\n12\nA Maximal Tractable Class of Soft Constraints\nb\nr\na\nM\n11\nM\nb\nr\na\nM\n11\nM\nb\nr\na\nM\n11\nM\nb\nr\na\nM\n11\nM\nu\nx\nv\ny\nu\nv\ny\nu\nx\ny\nv\nx\n(b) (c) (d)(a)\nFigure 3: (a) The choice of a and b in the proof of Theorem 4.5. Dotted lines repre-\nsent known 0 values of \u001e. Solid lines represent values of \u001e known not to be 0.\n(b-d) Representations of the three cases for the choice of u; v; x; y. The \flled area\nrepresents the non-zero values of the generalized interval constraint subtracted\nfrom \u001e to obtain \u001e\n0\n.\nother words, it su\u00c6ces to show that for any u; v; x; y 2 D such that u < x and v < y, we\nhave:\n\u001e\n0\n(u; v) + \u001e\n0\n(x; y) \u0014 \u001e\n0\n(u; y) + \u001e\n0\n(x; v) (2)\nReplacing x with u in the inequality derived above, we have that whenever u \u0014 a and y \u0015 b,\n\u001e(u; y) \u0015 \u001e(u; r) + \u001e(a; b): (3)\nThe proof of inequality (2) may be divided into four cases, depending on the values of \u001e(a; b)\nand the choice of u; v; x; y:\n1. \u001e(a; b) =1\nIn this case, \u001e\n0\ndi\u000bers from \u001e only on the pair ha; bi (because1\u00001 =1). Since \u001e is\nsubmodular, inequality (2) can only fail to hold if either hx; vi or hu; yi equals ha; bi.\nIf hx; vi = ha; bi, then, using inequality (3), we know that \u001e(u; y) = 1, so \u001e\n0\n(u; y) =\n1\u00001 =1, and inequality (2) holds.\nIf hu; yi = ha; bi then we have, for all x > u and y > v,\n\u001e\n0\n(u; v) + \u001e\n0\n(x; y) = \u001e(u; v) + \u001e(x; y)\n\u0014 \u001e(u; v) + max(\u001e(x; r); \u001e(x;M)) (by Lemma 4.4)\n= \u001e(u; v) + \u001e(x; r) (x > a) \u001e(x;M) = 0)\n\u0014 \u001e(u; r) + \u001e(x; v) (by submodularity)\n= \u001e(x; v) (since \u001e(u; r) = 0)\n= \u001e\n0\n(x; v)\n\u0014 \u001e\n0\n(u; y) + \u001e\n0\n(x; v)\nso inequality (2) holds.\n13\nCohen, Cooper, Jeavons, & Krokhin\n2. a < u < x or v < y < b; (see Figure 3 part (b))\nIn this situation we know that inequality (2) holds because \u001e and \u001e\n0\nare identical for\nthese arguments.\n3. u < x \u0014 a or b \u0014 v < y; (see Figure 3 part (c))\nIf u < x \u0014 a, then we have:\n\u001e\n0\n(u; v) = \u001e(u; v) \u0000 \u001a\n\u001e\n0\n(x; v) = \u001e(x; v) \u0000 \u001a\n\u001e\n0\n(u; y) = \u001e(u; y)\u0000 \u001a\n0\n\u001e\n0\n(x; y) = \u001e(x; y)\u0000 \u001a\n0\nwhere \u001a and \u001a\n0\nare either 0 or \u001e(a; b), depending on whether v or y are less than b.\nInequality (2) follows trivially by cancelling \u001a or \u001a\n0\nor both.\nAn exactly similar argument holds if b \u0014 v < y.\n4. u \u0014 a < x and v < b \u0014 y; (see Figure 3 part (d))\nIf u < a, than by inequality (3) we have \u001e(u; y)\u0000\u001e(a; b) \u0015 \u001e(u; r), so \u001e\n0\n(u; y) \u0015 \u001e(u; r).\nMoreover, if u = a, then \u001e(u; r) = 0, so again \u001e\n0\n(u; y) \u0015 \u001e(u; r). Hence,\n\u001e\n0\n(u; v) + \u001e\n0\n(x; y) = \u001e(u; v) + \u001e(x; y)\n\u0014 \u001e(u; v) + max(\u001e(x; r); \u001e(x;M)) (by Lemma 4.4)\n= \u001e(u; v) + \u001e(x; r) (x > a) \u001e(x;M) = 0)\n\u0014 \u001e(u; r) + \u001e(x; v) (by submodularity)\n\u0014 \u001e\n0\n(u; y) + \u001e(x; v) (since \u001e\n0\n(u; y) \u0015 \u001e(u; r))\n\u0014 \u001e\n0\n(u; y) + \u001e\n0\n(x; v)\nso again inequality (2) holds.\nHence, in all cases inequality (2) holds, so \u001e\n0\nis submodular, and the result follows by\ninduction.\nThe number of generalized interval functions in the decomposition of a binary submod-\nular function can grow quadratically with jDj (see Example 4.6 below) and the cost of\nsubtracting one binary submodular function from another is also quadratic in jDj. Hence\na naive algorithm to obtain such a decomposition by calculating the required generalized\ninterval functions and subtracting o\u000b each one in turn from the original function will take\nO(jDj\n4\n) time. However, by taking advantage of the simple structure of generalized interval\nfunctions, it is possible to obtain a suitable decomposition in O(jDj\n3\n) time; a possible algo-\nrithm is given in Figure 4. The correctness of this algorithm follows directly from the proof\nof the decomposition result given above.\nExample 4.6 Consider the binary function \u0019\nM\non D = f1; 2; : : : ;Mg, de\fned in Exam-\nple 4.3. When M = 3, the values of \u0019\n3\nare given by the following table:\n\u0019\n3\n1 2 3\n1 8 7 6\n2 7 5 3\n3 6 3 0\n14\nA Maximal Tractable Class of Soft Constraints\nInput: A binary submodular function \u001e on the set f1,2,. . . ,Mg\nsuch that neither \u001e nor \u001e\nT\nhas any inconsistent or penalized values\nOutput: A set of generalized interval functions f\u001e\n1\n; \u001e\n2\n; : : : ; \u001e\nq\ng\nsuch that \u001e(x; y) =\nP\nq\ni=1\n\u001e\ni\n(x; y)\nAlgorithm:\nfor j = 1 to M; T [j] = 0 % Initialise list of values to be subtracted\nfor i = M downto 1 % For each row. . .\nwhile \u001e(i;M) > T [M ] do % If \u001e(i;M) not yet zero. . .\nj = M ; while \u001e(i; j) > T [j] do j = j \u0000 1 % Find maximal zero position in row i\n\u0001 = \u001e(i; j + 1)\u0000 T [j + 1] % Set new value to be subtracted\noutput \u0011\n\u0001\n[j+1;i]\n(y; x) % Output generalized interval function\nfor k = j + 1 to M; T [k] = T [k] + \u0001 % Update list of values to be subtracted\nfor j = 1 to M; \u001e(i; j) = \u001e(i; j)\u0000 T [j] % Subtract values from this row\nfor i = 1 to M; T [j] = 0 % Initialise list of values to be subtracted\nfor j = M downto 1 % For each column. . .\nwhile \u001e(M; j) > T [M ] do % If \u001e(M; j) not yet zero. . .\ni = M ; while \u001e(i; j) > T [i] do i = i\u0000 1 % Find maximal zero position in column j\n\u0001 = \u001e(i+ 1; j)\u0000 T [i+ 1] % Set new value to be subtracted\noutput \u0011\n\u0001\n[i+1;j]\n(x; y) % Output generalized interval function\nfor k = i+ 1 to M; T [k] = T [k] + \u0001 % Update list of values to be subtracted\nfor i = 1 to M; \u001e(i; j) = \u001e(i; j)\u0000 T [i] % Subtract values from this column\nFigure 4: A decomposition algorithm with time complexity O(jDj\n3\n)\nNote that:\n0\n@\n8 7 6\n7 5 3\n6 3 0\n1\nA\n=\n0\n@\n6 6 6\n0 0 0\n0 0 0\n1\nA\n+\n0\n@\n0 0 0\n3 3 3\n0 0 0\n1\nA\n+\n0\n@\n2 0 0\n2 0 0\n2 0 0\n1\nA\n+\n0\n@\n0 1 0\n0 1 0\n0 1 0\n1\nA\n+\n0\n@\n0 0 0\n1 1 0\n1 1 0\n1\nA\n+\n0\n@\n0 0 0\n0 0 0\n1 1 0\n1\nA\n+\n0\n@\n0 0 0\n1 0 0\n1 0 0\n1\nA\n+\n0\n@\n0 0 0\n0 0 0\n1 0 0\n1\nA\n:\nHence,\n\u0019\n3\n(x; y) = \u0011\n6\n[1;1]\n(x; x) + \u0011\n3\n[2;2]\n(x; x) + \u0011\n2\n[1;1]\n(y; y) + \u0011\n1\n[2;2]\n(y; y)\n+ \u0011\n1\n[2;2]\n(x; y) + \u0011\n1\n[3;2]\n(x; y) + \u0011\n1\n[2;1]\n(x; y) + \u0011\n1\n[3;1]\n(x; y):\nIn general, for arbitrary values of M , we have\n\u0019\nM\n(x; y) =\nM\u00001\nX\nd=1\n \n\u0011\nM(M\u0000d)\n[d;d]\n(x; x) + \u0011\nM\u0000d\n[d;d]\n(y; y) +\nM\u00001\nX\ne=1\n\u0011\n1\n[d+1;e]\n(x; y)\n!\n15\nCohen, Cooper, Jeavons, & Krokhin\nWe remark that this decomposition is not unique - other decompositions exist, including\nthe symmetric decomposition \u0019\nM\n(x; y) = \u0019\n0\nM\n(x; y) + \u0019\n0\nM\n(y; x), where\n\u0019\n0\nM\n(x; y) =\nM\u00001\nX\nd=1\n \n\u0011\n(M\n2\n\u0000d\n2\n)\n2\n[d;d]\n(x; x) + \u0011\n1\n2\n[d+1;d]\n(x; y) +\nd\u00001\nX\ne=1\n\u0011\n1\n[d+1;e]\n(x; y)\n!\nCombining Lemma 4.5 with Corollary 3.6, gives:\nTheorem 4.7 For any \fnite soft constraint language \u0000 on a \fnite totally ordered set D, if\n\u0000 contains only unary or binary submodular functions, then the time complexity of sCSP(\u0000)\nis O(n\n3\njDj\n3\n).\nThe next result shows that the tractable class identi\fed in Theorem 4.7 is maximal.\nTheorem 4.8 Let \u0000 be the set of all binary submodular functions on a totally ordered \fnite\nset D, with jDj \u0015 2. For any binary function  62 \u0000, sCSP(\u0000 [ f g) is NP-hard.\nProof: We shall give a reduction from sCSP(f\u001e\nXOR\ng) to sCSP(\u0000 [ f g), where \u001e\nXOR\nis the binary function de\fned in Example 2.6. It was pointed out in Example 2.6 that\nsCSP(f\u001e\nXOR\ng) corresponds to the Max-Sat problem for the exclusive-or predicate, which\nis known to be NP-hard (Creignou et al., 2001). Hence sCSP(\u0000 [ f g) is also NP-hard.\nTo simplify the notation, we shall assume that D = f1; 2; : : : ;Mg, with the usual order-\ning.\nSince  is not submodular, there exist a; b; c; d 2 D such that a < b and c < d but\n (a; c) +  (b; d) >  (a; d) +  (b; c).\nChoose an arbitrary evaluation \u000f such that 0 < \u000f <1, and de\fne \u0015 and \u0016 as follows:\n\u0015 = min( (a; c);  (a; d) +  (b; c) + \u000f)\n\u0016 = min( (b; d);  (a; d) +  (b; c) + \u000f)\nIt is straightforward to check that\n (a; d) +  (b; c) < \u0015+ \u0016 <1: (4)\nNow de\fne a binary function \u0010 as follows:\n\u0010(x; y) =\n8\n<\n:\n\u0016 if (x; y) = (1; a)\n\u0015 if (x; y) = (2; b)\n1 otherwise\nand a binary function \u001e as follows:\n\u001e(x; y) =\n8\n>\n>\n>\n<\n>\n>\n>\n:\n0 if (x; y) = (c; 1)\n (a; d) + 1 if (x; y) = (c; 2)\n (b; c) + 1 if (x; y) = (d; 1)\n0 if (x; y) = (d; 2)\n1 otherwise\n16\nA Maximal Tractable Class of Soft Constraints\n\u001e(u; y)\n\u0010(y; w)\n (w; v)\nx\ny\nt\nv\n (t; u)\n\u001e(v; x)\n\u0010(x; t)\nu\nw\nFigure 5: An instance of sCSP(\u0000 [ f g) used to construct a speci\fc soft constraint between\nvariables x and y.\nIt is straightforward to check that both \u0010 and \u001e are submodular.\nNow consider the instance P\n0\nof sCSP(\u0000 [ f g) illustrated in Figure 5. It is simple but\ntedious to verify that the combined e\u000bect of the six soft constraints shown in Figure 5 on\nthe variables x and y is equivalent to imposing a soft constraint on these variables with\nevaluation function \u001f, de\fned as follows:\n\u001f(x; y) =\n8\n<\n:\n\u0015+ \u0016+ \u0015+ \u0016 if x; y 2 f1; 2g and x = y\n\u0015+ \u0016+  (a; d) +  (b; c) if x; y 2 f1; 2g and x 6= y\n1 otherwise\nNote that, by inequality (4), we have \u0015+ \u0016+  (a; d) +  (b; c) < \u0015+ \u0016+ \u0015+ \u0016 <1.\nNow let P be any instance of sCSP(f\u001e\nXOR\ng). If we replace each constraint hhx; yi; \u001e\nXOR\ni\nin P with the set of constraints shown in Figure 5 (introducing fresh variables t; u; v; w each\ntime) then we obtain an instance P\n0\nof sCSP(\u0000 [ f g). It is straightforward to check that\nP\n0\nhas a solution involving only the values 1 and 2, and that such solutions correspond\nexactly to the solutions of P, so this construction gives a polynomial-time reduction from\nsCSP(f\u001e\nXOR\ng) to sCSP(\u0000 [ f g), as required.\n5. Applications\nIn this section we give a number of examples to illustrate the wide range of soft constraints\nwhich can be shown to be tractable using the results obtained in the previous sections.\nFirst we de\fne a standard way to associate a function with a given relation.\n17\nCohen, Cooper, Jeavons, & Krokhin\nDe\fnition 5.1 For any k-ary relation R on a set D, we de\fne an associated function,\n\u001e\nR\n: D\nk\n! E, as follows:\n\u001e\nR\n(x\n1\n; x\n2\n; : : : ; x\nk\n) =\n\u001a\n0 if hx\n1\n; x\n2\n; : : : ; x\nk\ni 2 R\n1 otherwise.\nBy Theorem 4.7, any collection of crisp constraints, where each constraint is speci\fed by a\nrelation R for which \u001e\nR\nis unary or binary submodular, can be solved in cubic time, even\nwhen combined with other soft constraints that are also unary or binary submodular.\nExample 5.2 The constraint programming language CHIP incorporates a number of con-\nstraint solving techniques for arithmetic and other constraints. In particular, it provides\na constraint solver for a restricted class of crisp constraints over natural numbers, referred\nto as basic constraints (van Hentenryck et al., 1992). These basic constraints are of two\nkinds, which are referred to as \\domain constraints\" and \\arithmetic constraints\". The\ndomain constraints described by van Hentenryck et al. (1992) are unary constraints which\nrestrict the value of a variable to some speci\fed \fnite subset of the natural numbers. The\narithmetic constraints described by van Hentenryck et al. (1992) have one of the following\nforms:\naX 6= b aX \u0014 bY + c\naX = bY + c aX \u0015 bY + c\nwhere variables are represented by upper-case letters, and constants by lower case letters,\nall constants are non-negative real numbers and a is non-zero.\nFor each of these crisp constraints the associated function given by De\fnition 5.1 is\nunary or binary submodular, hence, by Corollary 3.6, any problem involving constraints of\nthis form can be solved in cubic time. Moreover, any other soft constraints with unary or\nbinary submodular evaluation functions can be added to such problems without sacri\fcing\ntractability (including the examples below).\nNow assume, for simplicity, that D = f1; 2; : : : ;Mg.\nExample 5.3 Consider the binary linear function \u0015 de\fned by \u0015(x; y) = ax+by+c, where\na; b 2 R\n+\n.\nThis function is submodular and hence, by Corollary 3.6, any collection of such binary\nlinear soft constraints over the discrete set D can be solved in cubic time.\nExample 5.4 The Euclidean length function\np\nx\n2\n+ y\n2\nis submodular, and can be used to\nexpress the constraint that a 2-dimensional point hx; yi is \\as close to the origin as possible\".\nExample 5.5 The following functions are all submodular:\n\u000f \u00c6\nr\n(x; y) = jx\u0000 yj\nr\n, where r 2 R, r \u0015 1.\nThe function \u00c6\nr\ncan be used to express the constraint that: \\The values assigned to\nthe variables x and y should be as similar as possible\".\n\u000f \u00c6\n+\nr\n(x; y) = (max(x\u0000 y; 0))\nr\n, where r 2 R, r \u0015 1.\nThe function \u00c6\n+\nr\ncan be used to express the constraint that: \\The value of x is either\nless than or as near as possible to y\".\n18\nA Maximal Tractable Class of Soft Constraints\n\u000f \u00c6\n\u0015\nr\n(x; y) =\n\u001a\njx\u0000 yj\nr\nif x \u0015 y\n1 otherwise\nwhere r 2 R, r \u0015 1.\nThe function \u00c6\n\u0015\nr\ncan be used to express the temporal constraint that: \\x occurs as\nsoon as possible after y\".\nExample 5.6 Reconsider the optimization problem de\fned in Example 1.1. Since  \ni\nis\nunary, and \u00c6\nr\nis binary submodular (Example 5.5), this problem can be solved in cubic\ntime, using the methods developed in this paper.\nLet P be the instance with n = 3 and r = 2. The values of \u00c6\n2\nare given by the following\ntable:\n\u00c6\n2\n1 2 3\n1 0 1 4\n2 1 0 1\n3 4 1 0\nHence,\n\u00c6\n2\n(x; y) = \u0011\n1\n[3;2]\n(y; x) + \u0011\n1\n[2;1]\n(y; x) + \u0011\n2\n[3;1]\n(y; x)\n+ \u0011\n1\n[3;2]\n(x; y) + \u0011\n1\n[2;1]\n(x; y) + \u0011\n2\n[3;1]\n(x; y)\nUsing this decomposition for \u00c6\n2\n, we can construct the graph G\nP\ncorresponding to the\ninstance P , as shown in Figure 6.\nThe minimum weight of any cut in this graph is\n11\n4\n, and hence the optimal evaluation\nof any assignment for P is\n11\n4\n.\nOne of the several possible cuts with this weight is indicated by the gray line across the\ngraph, which corresponds to the solution v\n1\n= 1, v\n2\n= 1, v\n3\n= 2, v\n4\n= 2, v\n5\n= 3, v\n6\n= 3.\nNote that some of the submodular functions de\fned in this section may appear to be\nsimilar to the soft simple temporal constraints with semi-convex cost functions de\fned and\nshown to be tractable by Khatib et al. (2001). However, there are fundamental di\u000berences:\nthe constraints described by Khatib et al. (2001) are de\fned over an in\fnite set of values,\nand their tractability depends crucially on the aggregation operation used for the costs\nbeing idempotent (i.e., the operation min). In this paper we are considering soft constraints\nover \fnite sets of values, and an aggregation operation which is strictly monotonic (e.g.,\naddition of real numbers), so our results cannot be directly compared with those in the\npaper by Khatib et al. (2001).\n6. Conclusion\nAs we have shown with a number of examples, the problem of identifying an optimal as-\nsignment for an arbitrary collection of soft constraints is generally NP-hard. However, by\nmaking use of the notion of submodularity, we have identi\fed a large and expressive class\nof soft constraints for which this problem is tractable. In particular, we have shown that\nbinary soft constraints with the property of submodularity can be solved in cubic time. By\nmaking use of this result, it should be possible to extend the range of optimisation problems\nthat can be e\u000bectively solved using constraint programming.\n19\nCohen, Cooper, Jeavons, & Krokhin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: The graph G\nP\nassociated with the instance P de\fned in Example 5.6.\nFrom a theoretical perspective, this paper gives the \frst complete characterisation of a\ntractable class of soft constraints over a \fnite set of values with more than two elements. We\nare con\fdent that the methods developed here can be extended to identify other tractable\ncases, and hence to begin a systematic investigation of the computational complexity of soft\nconstraint satisfaction. A \frst step in this direction has been taken by Cohen et al. (2003).\nWe believe that this work illustrates once again the bene\ft of interaction between re-\nsearch on constraint satisfaction and more traditional research on discrete optimization\nand mathematical programming: the notion of submodularity comes from mathematical\nprogramming, but the idea of modelling problems with binary constraints over arbitrary\n\fnite domains comes from constraint programming. By combining these ideas, we obtain a\n\rexible and powerful modelling language with a provably e\u00c6cient solution strategy.\n7. Acknowledgments\nAn earlier version of this paper, omitting many of the proofs, was presented at the Inter-\nnational Joint Conference on Arti\fcial Intelligence in 2003. This research was partially\nsupported by the UK EPSRC grant GR\/R81213\/01.\n20\nA Maximal Tractable Class of Soft Constraints\nReferences\nAllen, J. (1995). Natural Language Understanding | 2nd Edition. The Ben-\njamin\/Cummings Publishing Company.\nBistarelli, S., Montanari, U., Rossi, F., Schiex, T., Verfaillie, G., & Fargier, H.(1999).\nSemiring-based CSPs and valued CSPs: Frameworks, properties, and comparison.\nConstraints, 4, 199{240.\nBulatov, A.(2003). Tractable conservative constraint satisfaction problems. In Proceedings\nof the 18th Annual IEEE Symposium on Logic in Computer Science (LICS'03), pp.\n321{330.\nBistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based constraint satisfaction and\noptimisation. Journal of the ACM, 44, 201{236.\nBurkard, R., Klinz, B., & Rudolf, R. (1996). Perspectives of Monge properties in optimiza-\ntion. Discrete Applied Mathematics, 70, 95{161.\nCohen, D., Cooper, M., Jeavons, P., & Krokhin, A. (2003). Soft constraints: Complexity and\nmultimorphisms. In Proceedings of 9th International Conference on Principles and\nPractice of Constraint Programming (CP'03), Vol. 2833 of Lecture Notes in Computer\nScience, pp. 244{258. Springer-Verlag.\nCooper, M. (2003). Reduction operations in fuzzy or valued constraint satisfaction. Fuzzy\nSets and Systems, 134, 311{342.\nCreignou, N., Khanna, S., & Sudan, M. (2001). Complexity Classi\fcations of Boolean Con-\nstraint Satisfaction Problems, Vol. 7 of SIAM Monographs on Discrete Mathematics\nand Applications.\nDahlhaus, E., Johnson, D., Papadimitriou, C., Seymour, P., & Yannakakis, M. (1994). The\ncomplexity of multiterminal cuts. SIAM Journal on Computing, 23 (4), 864{894.\nDeville, Y., Barette, O., & van Hentenryck, P. (1999). Constraint satisfaction over connected\nrow convex constraints. Arti\fcial Intelligence, 109 , 243{271.\nFeder, T., & Vardi, M. (1998). The computational structure of monotone monadic SNP and\nconstraint satisfaction: A study through Datalog and group theory. SIAM Journal of\nComputing, 28, 57{104.\nFreuder, E., & Wallace, R. (1992). Partial constraint satisfaction. Arti\fcial Intelligence,\n58, 21{70.\nFujishige, S. (1991). Submodular Functions and Optimization, Vol. 47 of Annals of Discrete\nMathematics. North-Holland, Amsterdam.\nGoldberg, A., & Tarjan, R. (1988). A new approach to the maximum \row problem. Journal\nof the ACM, 35, 921{940.\nIwata, S., Fleischer, L., & Fujishige, S. (2001). A combinatorial strongly polynomial algo-\nrithm for minimizing submodular functions. Journal of the ACM, 48, 761{777.\nJeavons, P., Cohen, D., & Gyssens, M. (1997). Closure properties of constraints. Journal\nof the ACM, 44, 527{548.\n21\nCohen, Cooper, Jeavons, & Krokhin\nKautz, H., & Selman, B. (1992). Planning as satis\fability. In Proceedings of the Tenth\nEuropean Conference on Arti\fcial Intelligence (ECAI'92), pp. 359{363.\nKhanna, S., Sudan, M., Trevisan, L., & Williamson, D. (2000). The approximability of\nconstraint satisfaction problems. SIAM Journal on Computing, 30 (6), 1863{1920.\nKhatib, L., Morris, P., Morris, R., & Rossi, F. (2001). Temporal constraint reasoning with\npreferences. In Proceedings of the 17th International Joint Conference on Arti\fcial\nIntelligence (IJCAI-01), pp. 322{327, Seattle, USA.\nLarrosa, J., Meseguer, P., & Schiex, T. (1999). Maintaining Reversible DAC for Max-CSP.\nArti\fcial Intelligence, 107(1), 149{163.\nLov\u0013asz, L. (1983). Submodular functions and convexity. In Bachem, A., Grotschel, M.,\n& Korte, B. (Eds.), Mathematical Programming { The State of the Art, pp. 235{257,\nBerlin. Springer-Verlag.\nMontanari, U. (1974). Networks of constraints: Fundamental properties and applications to\npicture processing. Information Sciences, 7, 95{132.\nNemhauser, G., & Wolsey, L. (1988). Integer and Combinatorial Optimization. John Wiley\n& Sons.\nRosenfeld, A., Hummel, R., & Zucker, S. (1976). Scene labeling by relaxation operations.\nIEEE Transactions on Systems, Man and Cybernetics, 6, 420{433.\nRudolf, R., & Woeginger, G. (1995). The cone of Monge matrices: extremal rays and\napplications. ZOR { Mathematical Methods of Operations Research, 42, 161{168.\nRuttkay, Z. (1994). Fuzzy constraint satisfaction. In Proceedings 3rd IEEE International\nConference on Fuzzy Systems, pp. 1263{1268.\nSchaefer, T. (1978). The complexity of satis\fability problems. In Proceedings 10th ACM\nSymposium on Theory of Computing, STOC'78, pp. 216{226.\nSchrijver, A. (2000). A combinatorial algorithm minimizing submodular functions in\nstrongly polynomial time. Journal of Combinatorial Theory, Series B, 80, 346{355.\nTopkis, D. (1978). Minimizing a submodular function on a lattice. Operations Research,\n26, 305{321.\nTopkis, D. (1998). Supermodularity and Complementarity. Princeton University Press.\nvan Beek, P. (1992). Reasoning about qualitative temporal information. Arti\fcial Intelli-\ngence, 58, 297{326.\nvan Hentenryck, P., Deville, Y., & Teng, C.-M. (1992). A generic arc-consistency algorithm\nand its specializations. Arti\fcial Intelligence, 57, 291{321.\n22\n"}
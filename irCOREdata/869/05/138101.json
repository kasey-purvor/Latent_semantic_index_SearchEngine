{"doi":"10.1177\/1063293X0100900404","coreId":"138101","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/1233","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/1233","10.1177\/1063293X0100900404"],"title":"Expert Judgement in Cost Estimating: Modelling the Reasoning Process.","authors":["Rush, Christopher","Rajkumar, Roy"],"enrichments":{"references":[{"id":38113547,"title":"A causal model for software cost estimating error.'","authors":[],"date":"1998","doi":"10.1109\/32.666827","raw":"Lederer, A. L., and Prassad, J. (1998). 'A causal model for software cost estimating error.' IEEE Transactions on Software Engineering, 24(2), 137-148.","cites":null},{"id":38113568,"title":"A methodology for modelling manufacturing costs at conceptual design.'","authors":[],"date":"1998","doi":"10.1016\/s0360-8352(98)00174-0","raw":"Rehman, S., and Guenov, M. D. (1998). 'A methodology for modelling manufacturing costs at conceptual design.' Computers ind. Engng, 35(3-4), 623-626.","cites":null},{"id":38113553,"title":"A Parametric Approach to Cost Estimating at the Conceptual Stage of Design.","authors":[],"date":"1993","doi":"10.1080\/09544829308914776","raw":"Mileham, R. A., Currie, C. G., Miles, A. W., Bradford, D. T. (1993). A Parametric Approach to Cost Estimating at the Conceptual Stage of Design. Journal of Engineering Design, 4(2), pp. 117-125.","cites":null},{"id":38113575,"title":"A process-oriented approach to design rationale.'","authors":[],"date":"1991","doi":"10.1207\/s15327051hci0603&4_6","raw":"Conklin, J., and Yakemovic, K. B. (1991). 'A process-oriented approach to design rationale.' Human-Computer Interaction, 6(3&4), 357-391.","cites":null},{"id":38113565,"title":"Abstraction and analogy in cognitive space: A software process model.'","authors":[],"date":"1997","doi":"10.1016\/s0950-5849(96)00008-0","raw":"Zhuge, H., Jian, M., and Xiaoqing, S. (1997). 'Abstraction and analogy in cognitive space: A software process model.' International Journal of Information and Software Technology, 39(7), 463-468.","cites":null},{"id":38113559,"title":"An analogy-based model for estimating design effort.'","authors":[],"date":"2001","doi":"10.1016\/s0142-694x(00)00015-6","raw":"Bashir, H. A., and Thompson, V. (2001). 'An analogy-based model for estimating design effort.' Design Studies, 22(2), 157-167.","cites":null},{"id":38113548,"title":"An Experimental Application of the Delphi Method to the use of Experts. Contract Number AF 49(683)-700, United States Airforce,","authors":[],"date":"1962","doi":null,"raw":"Dalkey, N., and Helmer, O. (1962). An Experimental Application of the Delphi Method to the use of Experts. Contract Number AF 49(683)-700, United States Airforce,  RAND Corporation.","cites":null},{"id":38113561,"title":"Analogy and complex software modelling.'","authors":[],"date":"1997","doi":"10.1016\/s0747-5632(97)00021-6","raw":"Tessem, B., and Modeling, S. (1997). 'Analogy and complex software modelling.' Computers in Human Behaviour, 14(4), 465-486.","cites":null},{"id":38113540,"title":"Analysis of cost estimating processes used within a concurrent engineering environment throughout a product life cycle.","authors":[],"date":"2000","doi":null,"raw":"Rush, C., and Roy, R. (2000). Analysis of cost estimating processes used within a concurrent engineering environment throughout a product life cycle. 7th ISPE International Conference on Concurrent Engineering: Research and Applications, Lyon, France, July 17th - 20th, Technomic Inc., Pennsylvania USA, 58-67.","cites":null},{"id":38113542,"title":"Beyond Parametrics: The role of subjectivity in cost models.' Elsevier: Engineering Costs and Production Economics:","authors":[],"date":"1988","doi":"10.1016\/0167-188x(90)90115-x","raw":"Beltramo, M. N. (1988). 'Beyond Parametrics: The role of subjectivity in cost models.' Elsevier: Engineering Costs and Production Economics: An International Journal for Industry, 14, 131-136.","cites":null},{"id":38113573,"title":"Capturing design rationale in concurrent engineering teams.'","authors":[],"date":"1993","doi":"10.1109\/2.179154","raw":"Klein, M. (1993). 'Capturing design rationale in concurrent engineering teams.' Computer, 26(1), 39-47.","cites":null},{"id":38113541,"title":"Capturing quantitative and qualitative knowledge for cost modelling within a concurrent engineering environment.","authors":[],"date":"2001","doi":null,"raw":"Rush, C., and Roy, R. (2001). Capturing quantitative and qualitative knowledge for cost modelling within a concurrent engineering environment. 8th ISPE International Conference on Concurrent Engineering: Research and Applications, Anaheim, California, July 29 th - August 1 st, CETEAM International, USA, 209-218.","cites":null},{"id":38113567,"title":"Cost Estimation During Design Step: Parametric Method Versus Case Based Reasoning.'","authors":[],"date":"1999","doi":"10.1007\/s001700050147","raw":"Duverlie, P., and Castelain, J. M. (1999). 'Cost Estimation During Design Step: Parametric Method Versus Case Based Reasoning.' The International Journal of Advanced Manufacturing Technology, 15, 895-906.","cites":null},{"id":38113551,"title":"Cost estimators reference manual,","authors":[],"date":"1995","doi":null,"raw":"Stewart, R. D., Wyskida, R. M., and Johannes, J. D. (1995). Cost estimators reference manual, New York: Wiley Interscience.","cites":null},{"id":38113560,"title":"Cost-estimation by analogy as a good management practice.","authors":[],"date":"1988","doi":null,"raw":"Cowderoy, A. J. C., and Jenkins, J. O. (1988). Cost-estimation by analogy as a good management practice. Software Engineering 88, Second IEE\/BCS Conference, 80 -84.","cites":null},{"id":38113572,"title":"Cutting Tool Design Knowledge Capture\u201d, Industrial Knowledge Management - A Micro Level Approach.","authors":[],"date":"2000","doi":"10.1007\/978-1-4471-0351-6_25","raw":"Bailey, J., Roy, R., Harris, R. And Tanner, A., \u201cCutting Tool Design Knowledge Capture\u201d, Industrial Knowledge Management - A Micro Level Approach. Roy, R. (Ed.), Springer-Verlag (London), ISBN 1-85233-339-1, pp. 393-411, 2000.","cites":null},{"id":38113576,"title":"Design argumentation as design rationale.'","authors":[],"date":"1996","doi":"10.1016\/j.ijhcs.2013.08.006","raw":"Shum, S. B. (1996). 'Design argumentation as design rationale.' The Encyclopaedia of Computer Science and Technology, 35(20), 95-128.","cites":null},{"id":38113558,"title":"Effort Estimation Using Analogy.","authors":[],"date":"1996","doi":"10.1109\/icse.1996.493413","raw":"Shepperd, M., Schofield, C., and Kitchenham, B. (1996). Effort Estimation Using Analogy. The 18th International Conference on Software Engineering, Berlin, 170-178.","cites":null},{"id":38113549,"title":"Empirical studies of assumptions that underlie software cost-estimation models.'","authors":[],"date":"1992","doi":"10.1016\/0950-5849(92)90077-3","raw":"Kitchenham, B. A. (1992). 'Empirical studies of assumptions that underlie software cost-estimation models.' Information and Software Technology, 34(4), 211-218.","cites":null},{"id":38113546,"title":"Estimating software project effort using analogies.","authors":[],"date":"1997","doi":"10.1109\/32.637387","raw":"Shepperd, M., and Schofield, C. (1997). Estimating software project effort using analogies. IEEE Transactions on Software Engineering, 23(12), 736-743.","cites":null},{"id":38113566,"title":"Experiences using case-based reasoning to predict software project effort.","authors":[],"date":"2000","doi":"10.1007\/3-540-44593-5_20","raw":"Kadoda,  G.,  Cartwright, M., Chen, L., and Shepperd, M. (2000). Experiences using case-based reasoning to predict software project effort. Conference on Empirical Assessment in Software Engineering (EASE), Printed by: Keele University, 1-23.","cites":null},{"id":38113545,"title":"Expert judgement as an estimating method.'","authors":[],"date":"1996","doi":"10.1016\/0950-5849(95)01045-9","raw":"Hughes, R. T. (1996). 'Expert judgement as an estimating method.' Information and Software Technology, 38, 67-75.","cites":null},{"id":38113569,"title":"Expert Systems, Design and Development.","authors":[],"date":"1994","doi":null,"raw":"Durkin, J (1994). Expert Systems, Design and Development. Macmillian Publishing Company, New York, USA, ISBN: 0-02-330970-9, 1994.","cites":null},{"id":38113543,"title":"Human performance estimating with analogy and regression models: an empirical validation.","authors":[],"date":"1998","doi":"10.1109\/metric.1998.731247","raw":"Stensrud, E., and Myrtveit, I. (1998). Human performance estimating with analogy and regression models: an empirical validation. IEEE, Proceedings from the Fifth International Software Metrics Symposium, 205-213.","cites":null},{"id":38113570,"title":"Introduction to Expert Systems.","authors":[],"date":"1986","doi":"10.1109\/mex.1986.5006506","raw":"Jackson, P (1986). Introduction to Expert Systems. Addison-Wesley Publishing Company, ISBN: 0-201-14223-6.","cites":null},{"id":38113571,"title":"Knowledge Engineering and Management: The CommonKADS Methodology. A Bradford Book,","authors":[],"date":"2000","doi":"10.1109\/64.363263","raw":"Schreiber,  G.,  Akkermans, H., Anjewierden, De Hoog, R., Shadbolt, N., Van De Velde, W., & Wielinga, B (2000). Knowledge Engineering and Management: The CommonKADS Methodology. A Bradford Book, The MIT Press, Cambridge, Massachusetts.","cites":null},{"id":38113550,"title":"Knowledge in Cost Modelling.' The Cost Engineer:","authors":[],"date":"2001","doi":"10.1177\/1063293x0100900404","raw":"Rush, C., and Roy, R. (2001). 'Knowledge in Cost Modelling.' The Cost Engineer: The Journal of the Association of Cost Engineers, 39(1), 10-12.","cites":null},{"id":38113544,"title":"Metrics for design projects: a review.'","authors":[],"date":"1997","doi":"10.1016\/s0142-694x(98)00024-6","raw":"Bashir, H. A., and Thompson, V. (1997). 'Metrics for design projects: a review.' Design Studies, 20(3), 163-277.","cites":null},{"id":38113556,"title":"New Ways of Doing Business. SSCAG's 69th meeting, European Space Agency,","authors":[],"date":"2000","doi":null,"raw":"Pine,  David  (2000).  New Ways of Doing Business. SSCAG's 69th meeting, European Space Agency, Noordwijk, the Netherlands, May 11-12 th.","cites":null},{"id":38113564,"title":"Parametric cost estimating process flow analogy approach.","authors":[],"date":"2001","doi":null,"raw":"NASA  (Accessed  July  2001).    Parametric cost estimating process flow analogy approach. http:\/\/www.jsc.nasa.gov\/bu2\/analogy.html","cites":null},{"id":38113552,"title":"Parametric Estimating Handbook,","authors":[],"date":"1999","doi":null,"raw":"Department  Of  Defence  (1999).  Parametric Estimating Handbook, 2 nd Ed., DoD, http:\/\/www.ispacost.org\/PEIWeb\/cover.htm.","cites":null},{"id":38113557,"title":"Software engineering economics,","authors":[],"date":"1981","doi":"10.1007\/978-3-642-48354-7_5","raw":"Boehm, B. W. (1981). Software engineering economics, Prentice-Hall: Englewood Cliffs, N.J.","cites":null},{"id":38113562,"title":"Sources of Power: How people make decisions.","authors":[],"date":"1998","doi":"10.1108\/ijm.2001.22.7.664.2","raw":"Klein,  G.,  (1998).  Sources of Power: How people make decisions. Massachusetts Institute of Technology, ISBN: 0-262-11227-2.","cites":null},{"id":38113563,"title":"Structure-mapping: A theoretical framework for analogy.'","authors":[],"date":"1983","doi":"10.1207\/s15516709cog0702_3","raw":"Gentner, D. (1983). 'Structure-mapping: A theoretical framework for analogy.' Cognitive Science, 7(2), 155-170.","cites":null},{"id":38113539,"title":"The Faster, Better, Cheaper Approach To Space Missions: A Cost Analysis Perspective. SSCAG's 69th meeting, European Space Agency,","authors":[],"date":"2000","doi":null,"raw":"Hammaker, Joe (2000). The Faster, Better, Cheaper Approach To Space Missions: A Cost Analysis Perspective. SSCAG's 69th meeting, European Space Agency, Noordwijk, the Netherlands, May 11-12th.","cites":null},{"id":38113574,"title":"What's in design rationale?'","authors":[],"date":"1991","doi":"10.1207\/s15327051hci0603&4_3","raw":"Lee, J., and Lai, K.-Y. (1991). 'What's in design rationale?' Human-Computer Interaction, 6(3&4), 251-280.","cites":null},{"id":38113555,"title":"Working top-down: Cost estimating before development begins.'","authors":[],"date":"1992","doi":"10.1243\/pime_proc_1992_206_251_02","raw":"Pugh, P. (1992). 'Working top-down: Cost estimating before development begins.' Proceedings from the Institution of Mechanical Engineers, 206, 143-151.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2001-01-01T00:00:00Z","abstract":"Expert Judgement (EJ) is used extensively during the generation of cost estimates. Cost estimators have to make numerous assumptions and judgements about what they think a new product will cost. However, the use of EJ is often frowned upon, not well accepted or understood by non-cost estimators within a concurrent engineering environment. Computerised cost models, in many ways, have reduced the need for EJ but by no means have they, or can they, replace it. The cost estimates produced from both algorithmic and non-algorithmic cost models can be widely inaccurate; and, as the work of this paper highlights, require extensive use of judgement in order to produce a meaningful result. Very little research tackles the issues of capturing and integrating EJ and rationale into the cost estimating process. Therefore, this paper presents a case with respect to the wide use of EJ within cost estimating. EJ is examined in terms of what thought processes are used when a judgement is made. This paper highlights that most judgements are based on the results of referring to historical costs data, and then adjusting up or down accordingly in order to predict the cost of a new project. This is often referred to as analogy. The reasoning processes of EJ are identified and an inference structure has been developed, which represents an abstraction of the reasoning steps used by an expert as they generate an estimate. This model has been validated through both literature and interviews with cost estimating experts across various industry sectors. Furthermore, the key inferences of the experts are identified. These inferences are considered as those where many of the assumptions and expert judgements are made. The thesis of this paper is that through modelling the reasoning processes of EJ, it becomes possible to capture, structure, and integrate EJ and rationale into the cost estimating process as estimates are being generated. Consequently, the rationale capture will both improve the understanding of estimates throughout a product life cycle, and improve management decisions based upon these cost estimates","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/138101.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/10.1177\/1063293X0100900404","pdfHashValue":"678dec7b34e249b1a4843386f14305a27bdc5282","publisher":"Sage Publications","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/1233<\/identifier><datestamp>2013-01-27T23:01:03Z<\/datestamp><setSpec>hdl_1826_24<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Expert Judgement in Cost Estimating: Modelling the Reasoning Process.<\/dc:title><dc:creator>Rush, Christopher<\/dc:creator><dc:creator>Rajkumar, Roy<\/dc:creator><dc:subject>Cost Estimating Rationale<\/dc:subject><dc:subject>Expert Judgement<\/dc:subject><dc:subject>Analogy based cost estimating<\/dc:subject><dc:subject>Cost Estimating Knowledge<\/dc:subject><dc:subject>Inference Modelling<\/dc:subject><dc:description>Expert Judgement (EJ) is used extensively during the generation of cost estimates. Cost estimators have to make numerous assumptions and judgements about what they think a new product will cost. However, the use of EJ is often frowned upon, not well accepted or understood by non-cost estimators within a concurrent engineering environment. Computerised cost models, in many ways, have reduced the need for EJ but by no means have they, or can they, replace it. The cost estimates produced from both algorithmic and non-algorithmic cost models can be widely inaccurate; and, as the work of this paper highlights, require extensive use of judgement in order to produce a meaningful result. Very little research tackles the issues of capturing and integrating EJ and rationale into the cost estimating process. Therefore, this paper presents a case with respect to the wide use of EJ within cost estimating. EJ is examined in terms of what thought processes are used when a judgement is made. This paper highlights that most judgements are based on the results of referring to historical costs data, and then adjusting up or down accordingly in order to predict the cost of a new project. This is often referred to as analogy. The reasoning processes of EJ are identified and an inference structure has been developed, which represents an abstraction of the reasoning steps used by an expert as they generate an estimate. This model has been validated through both literature and interviews with cost estimating experts across various industry sectors. Furthermore, the key inferences of the experts are identified. These inferences are considered as those where many of the assumptions and expert judgements are made. The thesis of this paper is that through modelling the reasoning processes of EJ, it becomes possible to capture, structure, and integrate EJ and rationale into the cost estimating process as estimates are being generated. Consequently, the rationale capture will both improve the understanding of estimates throughout a product life cycle, and improve management decisions based upon these cost estimates.<\/dc:description><dc:publisher>Sage Publications<\/dc:publisher><dc:date>2013-01-27T23:01:03Z<\/dc:date><dc:date>2013-01-27T23:01:03Z<\/dc:date><dc:date>2001-01-01T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>Rush and Roy, Expert Judgement in Cost Estimating: Modelling the Reasoning Process, Concurrent Engineering. 2001; 9: 271-284<\/dc:identifier><dc:identifier>1063-293X<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1177\/1063293X0100900404<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/1233<\/dc:identifier><dc:language>en_UK<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["1063-293x","issn:1063-293X"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2001,"topics":["Cost Estimating Rationale","Expert Judgement","Analogy based cost estimating","Cost Estimating Knowledge","Inference Modelling"],"subject":["Article"],"fullText":"Expert judgement in cost estimating: Modelling the reasoning process \n \nChristopher Rush & Rajkumar Roy \nDepartment of Enterprise Integration \nSchool of Industrial Manufacturing and Science \nCranfield University \nCranfield, Bedford, \nMK43 0AL, \nUnited Kingdom. \n \nTel: 01234 754072 \nFax: 01234 750852 \nEmail: c.rush@cranfield.ac.uk and r.roy@cranfield.ac.uk  \n \nAbstract \n \nExpert Judgement (EJ) is used extensively during the generation of cost estimates. Cost \nestimators have to make numerous assumptions and judgements about what they think a new \nproduct will cost. However, the use of EJ is often frowned upon, not well accepted or understood \nby non-cost estimators within a concurrent engineering environment. Computerised cost models, \nin many ways, have reduced the need for EJ but by no means have they, or can they, replace it. \nThe cost estimates produced from both algorithmic and non-algorithmic cost models can be \nwidely inaccurate; and, as the work of this paper highlights, require extensive use of judgement \nin order to produce a meaningful result. Very little research tackles the issues of capturing and \nintegrating EJ and rationale into the cost estimating process.  \n \nTherefore, this paper presents a case with respect to the wide use of EJ within cost estimating. EJ \nis examined in terms of what thought processes are used when a judgement is made. This paper \nhighlights that most judgements are based on the results of referring to historical costs data, and \nthen adjusting up or down accordingly in order to predict the cost of a new project. This is often \nreferred to as analogy. The reasoning processes of EJ are identified and an inference structure \nhas been developed, which represents an abstraction of the reasoning steps used by an expert as \nthey generate an estimate. This model has been validated through both literature and interviews \nwith cost estimating experts across various industry sectors. Furthermore, the key inferences of \nthe experts are identified. These inferences are considered as those where many of the \nassumptions and expert judgements are made. The thesis of this paper is that through modelling \nthe reasoning processes of EJ, it becomes possible to capture, structure, and integrate EJ and \nrationale into the cost estimating process as estimates are being generated. Consequently, the \nrationale capture will both improve the understanding of estimates throughout a product life \ncycle, and improve management decisions based upon these cost estimates.  \n \nKeywords: Cost Estimating Rationale, Expert Judgement, Analogy based cost estimating, Cost \nEstimating Knowledge, Inference Modelling.  \n \n \n \n \n \n1. Introduction \n \nIn this article, the use of Expert Judgement (EJ) is examined with respect to generating cost \nestimates. The approach taken is one of understanding the thinking and reasoning processes that \nexperts use as they refer to historical data to make judgements. Understanding the reasons and \nlogic behind estimates is not a trivial task. This is because cost-estimating knowledge is complex \nand the sources are varied, as depicted in Figure 1 below. \n \nFigure 1: Skills and knowledge of cost estimating [1] \n \nCost estimators constantly apply a combination of logic, common sense, skill, experience, and \njudgement, in order to generate a final estimate that is timely, relevant, and meaningful. It is \ndifficult for non-cost experts to understand how a final estimate is derived, and visualise the \nunderlying reasons behind the many assumptions used throughout the process. Therefore, in \norder to make tacit knowledge (hidden) more explicit and useable, the knowledge needs to be \nStatistician\nRegression Analysis \nForecasting \nSensitivity Testing \nLearning Curves \nComputer Scientist \nMathematician \nModel Development \nCER Development \nProgramming \nAnalysis of Proposals \nRisk Analysis \nEngineer \nDesign \nScheduling \nMaterials \nProduction Engineer \nPerformance parameters \n \nAccountant \nFinancial Analysis \nCost Data Analysis \nProposal Analysis \nOverhead Analysis \nBudgeting \nEconomist \nLabour Agreements \nBreak Even Analysis \nPresent Value Analysis \nSales Person\nSell Estimate \nSell Approach \nSell self as knowledgeable \nCOST \nESTIMATOR  \ncaptured as the estimate is generated. This will facilitate the understanding of cost information \nwithin a CE environment and assist concurrent cost estimating.  \n \nThe main concerns of this research are recognising the widespread use of EJ, and attempting to \nintegrate the rationale behind judgements into the cost estimating and modelling process. The \npotential benefits for capturing cost estimating rationale are manifold, some of which are \noutlined below: \n\u2022 Explicitly represented rationale can help individual estimators clarify their thinking about the \ngeneration of an estimate;  \n\u2022 The use of EJ becomes a more structured process; \n\u2022 The 'hidden knowledge' of experts is captured for future reuse by non-experts and experts; \n\u2022 The reasoning behind the decisions becomes available for others to critique and learn from, \nand; \n\u2022 Existing estimates that addressed similar requirements can be retrieved, understood more \neasily and modified to meet current estimating needs. \n \nIn order to realise these benefits; this paper presents the development of an inference model that \ndescribes the reasoning steps used by an estimator as they make comparisons or analogies. An \ninference model differs from that of a process model. A process model defines steps in a process \nwhere as an inference model describes the reasoning steps of an expert carrying out a process. \nBy understanding the reasoning patterns of cost estimators, it becomes possible to develop a \nsoftware Cost Estimating Rationale Capture (CERC) model that can guide, structure, and capture \ntheir rationale during the process of generating an estimate. This CERC model can then be \nintegrated with other cost estimating software tools.  \n \nThe remainder of this paper discusses how the inference model was developed. In section two, \nrelated research is reviewed, with particular reference to the uses of cost models, expert \njudgement, and analogy based cost estimating. Section three presents related work of the authors, \nwhich provides context, background information and knowledge to support the research \ndescribed within this paper. Section four introduces the inference model, illustrates it, and \ndescribes how it was validated through questionnaires and interviews with experts from industry. \nSection five discusses related issues, limitations and the direction of future research, before \nconcluding in section six. This paper assumes prior knowledge of cost estimating techniques and \nmethods see Rush and Roy [2] for an overview. \n \n2. Related research \n \nThe following literature survey discuses the use of EJ within the cost estimating process, with \nparticular reference to EJ and commercial cost models. It also discusses how drawing \ncomparisons or analogies are recognised as the main method used by experts as they make \npredictions. Finally, the current approaches to formalising analogical approaches are discussed.   \n \n2.1 Expert Judgement \n \nSubjectivity is an issue that surrounds the compilation of all cost estimates and the use of EJ is \nunavoidable whether complex cost models are used or simple spreadsheets [3, 4, 5, 6]. By nature, \nan estimate is a prediction of what experts think something should cost. EJ, although not a cost \nestimating technique, is widely used and acknowledged as necessary for generating estimates [6, \n7, 8]. To be successful, the expert needs to have many years of experience. This method is \nobviously prone to bias; the limitations can be summarised as: \n\u2022 Subjective; \n\u2022 Risky and prone to error; \n\u2022 Three experts with the same starting information will provide different cost estimates; \n\u2022 Use of expert judgement is not consistent and an unstructured process; \n\u2022 Prone to bias: personal experience, political aims, resources, time pressure, memory recall; \n\u2022 The reasoning is known only to the owner of the estimate; \n\u2022 Estimate reuse and modification is difficult; \n\u2022 Difficult to negotiate effectively with customers; \n\u2022 Difficult to quantify and validate the estimates; \n\u2022 Estimate depends on level of experience; \n\u2022 Experts leave the company \u2013 knowledge loss; \n\u2022 Difficult to provide an audit trail, and; \n\u2022 Estimates are black box in nature; \n \nHowever, there are advantages to using EJ, such as: \n\u2022 Quick to produce; \n\u2022 Requires little resource in terms of time and cost, and; \n\u2022 Can be as accurate as other more expensive methods [7, 9]. \n \nPerhaps the most formal and rigorous method for capturing EJ is the Delphi technique [10, 11]. \nThis method attempts to capture expert opinion through a group of experts. The major drawbacks \nare related to its practicality. The first is related to the time needed to obtain the group opinion, \nand the second is related to the number of experts required to produce worthwhile results. \nEstimators make many qualitative judgements as they generate estimates and are often under \ntime constraints and working with limited amounts of information. Furthermore, the Delphi \ntechnique does not attempt to capture the reasoning process of how an expert made their \njudgement, which is a main aim of this research. \n \n2.2. Commercial cost models and EJ \n \nExamples of widely employed cost models are: parametric or algorithmic models, and non-\nalgorithmic models, such as Fuzzy Logic (FL) and Neural Networks (NN), and Case Based \nReasoning (CBR). These tools are mostly computerised, which contain algorithms, rules, \ninferences and mappings. Once calibrated to a particular environment, it can be argued that cost \nestimating becomes more scientific because the process is more repeatable. Nonetheless, these \nmodels can only aid the cost estimator and cannot replace them [5]. Cost estimators have to use \ntheir judgement concerning the validity of calibration data, and during the input of parameter \nvalues. For example, parametric cost models are often built on underlying assumptions and \nrelationships between variables, which do not necessarily reflect reality [4, 5, 12]. Thus, it is the \ncost estimator and their expertise that ultimately controls the output of any cost model. \nFurthermore, the judgements and assumptions used can influence the results significantly. \nThrough the author\u2019s own research, concerning a commonly used cost model called PRICE H, \nthe use of expert judgement during the calibration process was extensively used [3, 13]. Thus, \nalthough cost models are designed to facilitate the generation of estimates, they can only reflect a \nrealistic cost with the input of expertise and judgement of the users. \n \nIt should be noted that companies feel more comfortable with the use of algorithmic and \ncomputerised models [14, 15, 16, 17], than they do with EJ (Hughes [7]). Despite the fact of \nenormous error ranges. For example, within the software cost estimating community errors of \nbetween 85 \u2013 770%, [7, 8, 9], are reported. Pine [18] reports on estimating errors of hardware \nprojects, although not so large, significant nonetheless. Hughes [7] argues that companies should \nnot take such a negative view with respect to the use of EJ. Rather, that companies should \nacknowledge it, and develop cost models and information systems that attempt to support it. \nHughes\u2019 work does not attempt to do this. \n \nThus, very little research discusses how an expert uses judgement or how EJ can be better \nintegrated into the cost estimating process. None of the research attempts to make this process \nexplicit or attempts to capture cost estimating rationale as an estimate is generated. The \nreasoning and rationale behind the input values into cost models is more often than not, not \nrecorded and hence is lost to other experts and non-experts alike. \n \n2.3. Analogy and expert judgement \n \nThe idea of using analogies as the basis for estimating is not new. Boehm [19] suggested the use \nof analogies as a means for estimating some 20 years ago. It is widely accepted that the most \ncommon way in which experts produce cost estimates and make judgements is through the use of \nanalogies or comparisons [7, 8, 20, 21, 22, 23, 24].  \n Within the field of cognitive science, general models of analogical reasoning are provided [23, \n25]. In broad terms, they describe how a reference product (source) of which the details are \nknown, is first identified for use as a comparison to the current product (target) of which the \ndetails are not fully known. The similarities or differences are then matched, and then transferred \nfrom the source to the target. Finally, a justification is made to explain why the source product \nwas used. This type of process has been used by the US air force for over twenty years for \npredicting the repair rates of aircraft parts [24]. NASA recognises a similar model and provides \nguidelines for using analogy as a means to estimate on their web site [26]. These models provide \nan abstraction of the process but do not describe the types of inferences and thinking processes \nused by the experts. Furthermore, these models do not describe the levels of abstraction that \nexperts use as they identify whether a case is suitable for use as a comparison or not [27]. \n \nAlmost all research with respect to the use of analogy as a basis of estimating, revolves around \nthe creation of analogy based tools i.e. Case-Based Reasoning (CBR) [8, 20, 22, 28, 29, 30]. The \nattraction being that CBR more naturally resembles the thought processes of experts. A CBR \nsystem stores and organises past situations, then chooses those similar to the problem at hand and \nadapts a solution.  \n \nBashir and Thompson 2001 [21] provide an alternative method of comparison using a more \nmanual approach. In this approach, they suggest the use of a pairwise comparison table and an \neigenvector approach. These enable the user to define a similarity measure relating to the \nproductivity of historical products to predict the design effort of new projects. Their work \ndoesn\u2019t explain the reasoning processes used by estimators but does offer a method of assessing \nhow projects are being compared. \n \nFormalising and computerising the process of analogical reasoning into a CBR system is a \ncomplex process. There are many issues concerned with the retrieval, matching and \nmeasurement of similarity between past and current cases. Furthermore, a CBR system requires a \nnumber of past cases in order to be effective. This is a problem when a company does not have \nsuch a number of past cases that can be used. For example, within the military aircraft industry, \nthis is often the case. Much of their historical data spans over 50 years and retrieving this is not a \ntrivial task. In addition, each new generation of military aircraft is often a step up in technology \nfrom its predecessor. Regression based tools are good at predicting within the bounds of similar \nprojects as are CBR tools. If a new technology is introduced, the systems fall down or are \nseverely limited in their predictive capability. In a CBR tool, a similar match is not found, and \nextrapolating beyond the range of data points in a regression-based model leads to a spurious \nestimate indeed. Thus, the use of EJ is unavoidable.  \n \nTherefore, the authors\u2019 approach to \u2018analogy\u2019 based cost estimating, is first to understand and \ncapture the reasoning processes used when experts make comparisons to generate an estimate. \nBy understanding these issues, it becomes possible to model the expert behaviour, guide the \nprocess of using EJ, and capture rationale where necessary. As mentioned previously the benefits \nof this are manifold. Before the inference model of the thought processes is presented, the related \nwork of the authors is introduced to provide context, background information and knowledge, to \nsupport the current research described later in this paper. \n 3. Challenges in cost estimating knowledge capture \n \nThe research within this paper was initiated by Cranfield University and a European Military \nAirsystem manufacturer. It is part of a three-year research project, in which the sponsoring \ncompany\u2019s cost modelling activities of new military aircraft is being examined. The main aim of \nthe project was to examine both the quantitative and qualitative issues of cost modelling with the \nobjective of integrating the two types of knowledge [3, 13]. \n\u2022 Quantitative knowledge is defined as the elements of known cost and product structures, \nwhich form the basis of a cost estimate and are measurable. For example, the product \nbreakdown structure (PBS) of an air system can be defined and decomposed into a \nhierarchical breakdown of both its major and sub structures and systems. The masses of \nparts and material types are other examples of quantitative knowledge. \n\u2022 Qualitative knowledge is defined as the assumptions and judgements that cost estimators \nand engineers make during the generation of an estimate. These assumptions and \njudgements are related to how an estimator refers to past projects to serve as the basis for \ngenerating a new estimate. \n \nNew military air systems can take as long as, and more than, twenty years to develop from the \nconcept evaluation of customer requirements through to the final production [31]. This time span \nmakes it extremely difficult to predict the cost and risk of a multi-million pound product during \nthe concept evaluation phases. Furthermore, many authors agree that 70-80% of a product cost is \ncommitted during the concept phase [14, 15, 16]. Making a wrong decision at this stage is \nextremely costly further down the development process.  \n Nonetheless, the sponsoring company's cost estimators and are required to predict the full life-\ncycle cost for such options. They need to make assumptions about future cost savings resulting \nfrom: new manufacturing processes, the use of more advanced technologies, new materials, \nexpected improvements in design and development processes, and changes within and outside \nthe business environment. To achieve this, they often make comparisons and references to \nhistorical projects in order predict the cost of the new project. Furthermore, the cost estimators \nneed to communicate and work constantly with their IPT (Integrated Project Team) members in \norder to help produce estimates that are more meaningful. \n \nThe authors discovered that as the cost models are developed, much of the reasoning and logic is \nunderstood only by the experts. Where project time scales are long, the reasoning and logic \nbehind the estimates is often lost, and it is difficult for both non-cost experts and other experts to \nunderstand how a final estimate has been derived. The underlying reasons behind the many \nassumptions used throughout the process are not visible. This fact influenced the decision to \ncapture this knowledge and rationale in order to make it more explicit; thereby, making the final \nestimate more meaningful and reusable. \n \nCapturing this rationale and identifying the knowledge intensive processes is not a trivial task. It \nis difficult for experts to explain what it is that they know [32, 33, 34]. In previous research, the \nauthors investigated the knowledge capture of experts related to the cost modelling of a new \nproduct [3, 13]. In this work, expert knowledge was captured and the knowledge intensive areas \nof a cost modelling process were identified. The cost modelling process was mapped using an \nIDEF0 approach, and the knowledge intensive areas were identified and captured through the use \nof a novel technique known as Knowledge = Expert \u2013 Novice (KEN) [35]. Within this approach, \nthe Novice (author) used the data and tools of the cost-estimating experts to produce an estimate. \nAs difficulties arose, the Novice called on the expert for the solution. As the Novice works \nthrough the required activities and tasks the knowledge requirements are documented [3, 13]. \nFigure 2 below illustrates the knowledge identification phase of this research. \n \n \n \n \n \n \n \n \n \n \n \nFigure 2: The knowledge identification methodology [3, 13] \n \nBecause of this research the knowledge intensive areas were identified, and a model depicting \nthe current AS-IS process was developed, which facilitated the development of the future, TO-\nBE cost estimating process model (see Figure 3).  \n \n \nEstimating and\nCalibration\nIDEF0 models\nInputs\nMechanisms\nConstraints\nOutputs\nKnowledge =\nExpert -\nNovice\nQuantitative\nKnowledge\nQualitative\nKnowledge\nTechnology Process Bus. Env.Product\nEssential\nKnowledge\nRequirements\n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 3: TO-BE calibration process and research focus (3) \n \nFigure 3 illustrates where changes to the existing cost model process are being introduced by the \nbold diamonds and boxes. The information described within this paper is depicted within the \narea of the dashed-bordered box. As mentioned within the introduction, the objective within the \nresearch focus area was to understand the reasoning and thought processes of the estimators as \n START\nCalibrate PRICE\nH model\nDoes PRICE H\nmatch manual\nestimates?\nNo\nYes\nAdd New Product\nData\nCategorise\nAssumptions\nProduce Manual\nestimates\n Collect Data\nAny new\ndata to add\nto model?\nProduce Estimate\nNo\nYes\nSTOP\nProduce\nEstimate\nIs Re-\nCalibration\nrequired?\nYes\nNo\nIntegrate with\nfinal estimate\nAre\nAssumptions\nstill valid?\nYes\nNo\nDefine new\nvalues for\nAssumptions\nAdd new\nAssumption(s)\nEvaluate Base\nline estimate\nAny new\nAssumptions\nrequired?\nProduce new\nAssumption set\nNo\nYes\nRe-Calibrate Model\nCurrent\nResearch\nFocus\nthey make assumptions, judgements and decisions. The remainder of this paper describes the \ninference model in more detail; also, how it was validated through semi-structured interviews \nwith cost estimating experts.  \n \n4. Developing the Inference model  \n \n4.1. Initial model development \n \n \nAfter the knowledge intensive areas of the cost modelling process had been identified, the \nauthors set about capturing the reasoning processes used by the cost estimators. An initial \ninference model was developed using the CommonKADS notation [34]. It should be noted that \nthe inference structure has not been developed to drive a knowledge-based system. Rather, to \nprovide a basis for developing a software model that mimics and guides the expert thinking \nprocess. The initial inference structure was developed based on the authors\u2019 understanding of the \ndomain in which the knowledge identification was carried out and through existing literature.  \n \n4.2. Inference structure validation \n \nIn order to validate the model a questionnaire was designed to gather further information and \nmodel the expert reasoning process more closely. In order to provide some structure to the \nquestionnaire the respondents were required to refer to an estimate they themselves generated. \nThe inference structure in Figure 5 was validated through interviews with 11 experts from \naerospace, automotive and defense industries and estimating backgrounds. Their years of \nexperience ranged from 5 to 32. The projects ranged from cost estimating new airsystem \nconcepts to the disposal of nuclear waste plants. The questionnaire is illustrated in Table 1.  \nTable 1: Semi structured interview questionnaire \nSection 1: The Context \n1. What type of product was the estimate for (mechanical, systems, etc.) \n2. What was the stage of product development? (Development, Manufacturing) \n3. What estimating techniques were you using? (e.g. parametric, detailed analysis) \n4. When was the estimate made? \n5. What was the purpose of the estimate? (e.g. ROM, Budget, detailed, fixed price etc.) \n6. How would you rate the difficulty of this task? (On a scale of 1 to 5, 1 being very easy and 5 being very difficult) \n7. How many years of cost estimating experience with respect to generating estimates had you (at the time of estimate) \n8. How often were you producing estimates? (at the time of estimate) \nSection 2: The process \n1. Where does the work request come from? \n2. What are the basic data you require, and the main things you look for? And why? \n3. What sort of constraints do you often face (example: time, etc. etc.)? \n4. At what point could you say that you understand the new product and the cost estimating requirements? Please give an example \nfrom your case study.  \n5. What tells you that you have all the requirements you need, whom would you talk to for any advice? How often do you consult \nothers? \n6. What do you do to identify and prioritise requirements? \n7. What do you have to do to organise the new product data for preparing the estimate? \n8. At what point do you begin searching for source or reference data?  \n9. What difficulties do you encounter when searching for source data? \n10. What do you look for in the source data? Please give examples from your chosen case study. \n11. What tells you that you have identified a suitable candidate to use as a comparison? \n12. What do you do to when comparing the source data and the new product data? Can you provide examples? (what criteria do \nyou use? And why?) \n13. What assumptions do you make when comparing the products? Could you please give examples? \n14. How would you use the costs from the source data?  \n15. What do you do when you make adjustments to account for the differences between the source data and the new product data? \n16. What sort of assumptions do you use when adjusting the costs? Could you please give examples? \n17. Do you record and explain the rationale for the adjustments made? If yes, can you say how? \n18. How often would you review any assumptions made? \n19. Do you understand the cost impact of a change in any of the assumptions used? \n20. What are the potential areas where your estimate may differ from another person's estimate? \n21. Could you please explain the thinking process you go through when making a comparison, as you understand it. \nSection 3: Inference model analysis \n1. In your opinion, how do the inferences match your reasoning process? Is there anything you would change? \n2. What inferences are most assumption intensive? \n \nSection 1 of the questionnaire was designed to gather information concerning the case study and \nthe context in which the estimate was made. Section 2 was designed to assess what the expert did \nas they carried out their tasks. The questions in both Sections 1 and 2 were asked without \nshowing the initial inference model to the interviewees. After the second set of questions had \nbeen answered, the inference model was presented. Section 3 of the questionnaire was designed \nto understand how the author\u2019s inference model differed from the expert\u2019s view of their \nreasoning process. Any discrepancies were highlighted and then later assessed through the \nrespondents answers to the questions posed in section 2 of the questionnaire. All the interviews \nwere recorded and later transcribed in order to assess that their answers matched the inference \nmodel.  \n4.2.1. Paper Based Validation Scenario \n \nThe scenario below describes only one of the 11 cases due to paper length limitations, which \nillustrates how the inferences were matched with the transcribed data. \n \nScenario: Two cost estimators have just received a request from their line manager asking them \nto estimate what the cost of an aircraft wing should be costing the company. The company has \nbeen building the wings for many years. There were recorded costs against the wings but the \ncompany wanted to know how much should it be costing and what target they should be aiming \nto. The information received was a verbal instruction. The time allotted for the job was one \nmonth. \nTable 2: Paper based validation of interviews \nDomain Explanation Inference \nModel \nWhere does the work request \ncome from? \nWe received a verbal request from the manager. The formal route is through the \ncontracts department from an external customer and to us from project management. \nIn this case, the managers decided that they wanted the study conducted. \nRECEIVE: From \nManager \nWhat are the basic data you \nrequire, and the main things \nyou look for? And why? \nWe needed to collect more data such as process plans, product details, drawings, and \nthrough visits to the shop manufacturing plants. This data helps us understand what \nwe are cost estimating for. \nOBTAIN: More \nData  \nWhat sort of constraints do you \noften face? \nTime and lack of information. Knowing the type of estimate affects the amount of \ndetail one will use to generate the estimate. In this case, it was a detailed estimate \nand needed to have a good degree of accuracy. Knowing this helps to identify and \nprioritise the areas of a product or estimate to focus on. In this case, the estimator \nhad one month which focuses the attention to the high cost drivers \nCONSTRAINTS: \nTime and \nInformation \nAt what point could you say \nthat you understand the new \nproduct and the cost estimating \nrequirements? Please give an \nexample from your case study. \nAfter we\u2019ve seen the product, visited the manufacturing plant for a few days, looked \nat the line, the job, spoke to guys to find out what were the issues around producing \nthe parts, and looked at drawings for particular parts. Also when you understand \nwhat sort of price or cost your expected to put together, what sort of economic \nconditions exist, and what sort of tolerances there are and how long you\u2019ve got to do \nit. \nSYNTHESISE: \nUnderstanding \nWhat tells you that you have all \nthe requirements you need, \nwhom would you talk to for \nany advice? How often do you \nconsult others? \nClarifying requirements through the more experienced staff and the managers right \nup to the senior managers. In many cases, we would also attempt to clarify \nrequirements with the customers. For advice, you would talk to the Estimating \nmanagers, commercial managers, and project managers, as and when you needed to. \nSYNTHESISE: \nClarifying \nrequirements \nWhat do you do to identify and \nprioritise requirements? \nIf time\u2019s more important than accuracy you produce as much as you can within the \ntime scale.  \nSYNTHESISE: \nPrioritise \nWhat do you have to do to We drew a product tree showing the major assemblies and all the sub-parts and how SYNTHESISE: \norganise the new product data \nfor preparing the estimate? \nthey related to each major assembly.  Organise \nAt what point do you begin \nsearching for source or \nreference data? \nThis happens as your firming up the requirements. It happens from the very start \nreally. \nSEARCH: Data \nWhat difficulties do you \nencounter when searching for \nsource data? \nFinding usable data. Interpreting data. Asking other people to find data when they \nare already busy. \nCONSTRAINTS: \nTime, people, \ninformation \nWhat do you look for in the \nsource data? Please give \nexamples from your chosen \ncase study. \nIt was the detailed planning\u2019s, materials, masses, sizes, and processes involved, plus \naccess to sub contract orders that had gone out, and access to the recorded costs for \nthe previous wings.  \nIDENTIFY: What \nthey need \n \nWhat tells you that you have \nidentified a suitable candidate \nto use as a comparison? \nIt\u2019s down to prior knowledge. Experience tells you that you can read certain things \nacross. If you know the people who done one job then a similar job done by a similar \nset of people should be done for the same amount of time and cost. Also, talking \nwith other people. \nIDENTIFY: \nUsable data \nWhat do you do to when \ncomparing the source data and \nthe new product data? Can you \nprovide examples? \nSimilar sized parts like the ribs, spares, stringers, and the method of construction. \nWe look at the mass, similar materials, similar sizes, manufacturing process, \nconstruction methods and then you would expect it to cost much the same. Previous \nestimates will also be reviewed. \nCOMPARE: \nSimilarities and \ndifferences \nWhat assumptions do you make \nwhen comparing the products? \nCould you please give \nexamples? \nIn this case, we assumed that similar sized parts and similar material parts will cost \nthe same to manufacture at the reference\/source data site as they would at new site, \nin terms of man-hours and basic costs. \nCOMPARE: \nAssumptions \nHow would you use the costs \nfrom the source data? \nA lot of the time we bridge costs from one estimate to another and then factor for the \ndifferences. We also say what data we have used to generate an estimate (JUSTIFY). \nTRANSFER: \nCosts from source \ndata to target \nproduct \nWhat do you do when you \nmake adjustments to account \nfor the differences between the \nsource data and the new \nproduct data? \nFor example, we looked at the basic assembly cost, detailed sub assembly costs \nlearning factors, errors on the previous estimates and then we would put tolerances \nand factors in for different parts. You look at the different time scales, materials, \nmasses and then identify the differences and put in an estimate for that.  \nESTIMATE: \nFactors and \ntolerances \nWhat sort of assumptions do \nyou use when adjusting the \ncosts? Could you please give \nexamples? \nYou look at things like batch size and the learning implications, second source \nlearning. For example, if a part was cost based on 400 down the line you have to \nconsider this against a part that may be made with new operatives. You have to \njudge where on the learning curve you should place the part. In addition, the sort of \nefficiencies in the work shops. \nESTIMATE: \nAssumptions \nDo you record and explain the \nrationale for the adjustments \nmade? If yes, can you say how? \nYes we do, we have to justify how we came to our cost estimate, it\u2019s part of our \nclearance procedure. This includes the detail about where you obtained the \ninformation to do the job and a bit of a critique. A list of all the assumptions you \nused, a list of source\/comparison data and how you handled this. There is no set \nformat. Risks and tolerances will also be included. This is stored on file, either \ncomputers or filing cabinets. \nJUSTIFY \nAssumptions and \nrationale \nHow often would you review \nany assumptions made? \nDepending on the scope of the job. On a longer job, the easy answer is to say all the \ntime. If you only have limited time to make the assumptions you\u2019ll make them and \nreview them before the final figure. If you have a few months, you may have made \nearlier assumptions with the expectations that you would be able to firm them up as \nyou go along, and as you obtain more information. But you do really review them all \nthe time. But definitely before you finally submit the estimate. There is nothing \nformal. Many of these things come down to good or bad working practice. \nREVIEW \nDo you understand the cost \nimpact of a change in any of \nthe assumptions used? \nMostly yes, this is one of the reasons for making the assumptions in the first place. \nAssumptions are made so that you can get on with doing the job. Process \nimprovements, or material type assumptions should be highlighted in a risk register. \nOne of the big assumptions we made related to this case was that a lot of the work \nwould be done outside the factory by sub-contractors at a cheaper rate. It ended up \nas higher rates because the jobs were more difficult than expected. So, it\u2019s important \nto recognise these sorts of assumptions and recognise them as a risk. It\u2019s impossible \nto understand everything that might happen. \nREVIEW \nWhat are the potential areas \nwhere your estimate may differ \nfrom another person's estimate? \nJust about everywhere, it\u2019s mostly related to the assumptions and factors used. \nDifferent people exercise more caution in certain areas such as error rates, broken \ntools, learning curves etc., and estimate more cost. At a higher level differences will \noccur on the number of hours people will spend per week or a month, holiday \nallowances. In addition, factors to allow for more profits. \nN\/A \nCould you please explain the \nthinking process you go \nthrough when making a \ncomparison, as you understand \nit? \nWe assess the source data and identify its suitability for costing the new project and \nthen match the costs we can, we then make estimates for the differences between the \nsource data and the new product we want to cost. \nN\/A \n Thus, through both the interviews and later analysis the inference model was developed. The \nfinal inference model depicted in Figure 5 was accepted and considered representative by all the \ninterviewees. \n \n4.3. Task: Generating an estimate \n \nBefore one can capture the reasoning processes of an expert, the task they perform needs to be \ndefined. This enables one to understand how the expert is reasoning. In this case, the task is \nrelated to what an expert does when generating an estimate, based on reference to historical \nprojects or experience. As mentioned previously this is often referred to as analogy. The task in \nthis case, is a complex reasoning process and needs to be decomposed in order that it can be \nmore clearly understood (see Figure 4).  \n \nIn Figure 4 the main task of generating an estimate is hierarchically decomposed into smaller \ntasks, this in turn is divided into even smaller tasks. The tasks in the diagram describe what the \nexpert does. The task methods describe how an estimator completes the task.  \n \nIn order to understand what the expert does, the task method needs to be further decomposed into \nsubtasks i.e. Prepare (1), Estimate (2), and Review (3). Each of these subtasks has a number of \nassociated lower level subtask methods that describe how the cost estimator completes each \nsubtask. For each subtask method, the corresponding inferences used by the estimators are \nshown. Descriptions of inferences are provided in Section 4.4. \n Figure 4: Task and inference decomposition for analogy based cost estimating \n \nThe main tasks prepare, estimate, and review describe the order of how the estimate is generated. \nFor example, before estimating, the data needs to be prepared (1) so that the expert can estimate \n(2). Then the estimate needs to be reviewed (3). However, the task decomposition does not \nillustrate how the expert reasons during the task, it simply demonstrates the \u2018what\u2019 and \u2018how\u2019 of \nthe cost estimator as they complete their tasks, and illustrates the inferences used. The shaded \nareas in Figure 4 are numbered, and correspond to the shading and numbering shown in Figure 5. \nThis helps the reader visualise how the task of \u2018generating estimates\u2019 translates into the experts\u2019 \nreasoning process. \n \n \n \nTask \nTask \nMethod \nSub \nTasks \nSub Task \nMethod \n \nPrepare, Estimate \nReview \nUnderstand \nproject  \nIdentify \ncandidate \nsolutions \nCompare \ntarget and \nsource \nJustify \nCapture \nRationale \nTransfer \nrelative \ncosts \nReview \nReview \nestimate \nTransfer Estimate \nEstimate \nnew costs \nSearch \nsource  \ndata \nGenerate \nEstimates \nPrepare Estimate Review \nIdentify Search CompareSynthesise Inferences \n21 3\n4.4. Inference Structure \n \nThe inference structure illustrated in Figure 5, is an abstract representation of the possible \nreasoning steps an estimator uses as they refer to a similar product to generate an estimate. \nTogether, these inferences form the building block of the expert reasoning process. They define \nthe basic inference actions that the expert can perform whilst executing their tasks. The \ncombined set of inferences represent the experts inference structure.  \n \nFigure 5: An inference structure for analogy based cost estimating \nReceive \nObtain \nCompare \nEstimate \nTransfer \nRelative \nCosts \nComparison  \nData \nSimilarities \n\/differences \nNew Project \nRequest \nNew Costs \nNew Product \nData (Target) \nReference \/ \nSource Data \nSearch \nReview \nIdentify Candidate \nSolutions \nJustify \nAssumptions & \nRationale \nSynthesise \nEstimated \nCosts \nConstraints \nObtain \n2\n1\n3 \nCustomer \nRequest \nWBS, Ground rules & \nassumptions, cost drivers, \nhigh-risk areas etc. \nMemory, \nPeople, \nDatabases  \nRetrieve \nPossible  \nCases \nIdentify specific \nfeatures\/attributes \nfrom identified cases  \nManufacturing, \nmaterials, \nmanagement etc.  \nMap relative \ncosts from source \nto target  \nAdjust cost to \naccount for \ndifferences  \nDocument \nand clarify  \nProduce Final \nEstimate  \n  \n \n4.4.1. Knowledge Roles, Transfer Functions and Inferences \nTo model the inference structure the authors adapted the CommonKADS notation [34].  \n\u2022 The rectangular boxes within the model are known as Knowledge Roles (KR). The KR\u2019s \ndescribe at an abstract level, the kind of data that the estimator will infer or reason with. \n\u2022 The ovals represent the Inferences (I) or the reasoning processes that the expert uses. The \narrows are used to indicate input-output dependencies between the KR\u2019s and inferences. \n\u2022 The rounded boxes represent Transfer Functions (TF). The TF\u2019s relate to the estimator \ninteracting with other agents e.g. suppliers, customers, IPT members, and collaborating \ncompanies. \n \n4.4.2. Inference structure description \n \nThe following section provides a walk through of the inference structure illustrated in Figure 5. \n \nPrepare (1): The estimators first receive information about the new project in various forms. \nThey receive a request to do the work, and data such as 3-D models, drawings and \ndocuments. From this information, the estimator deepens their understanding of \nwhat it is that needs to be cost by synthesising all the data and information. \nDuring the synthesis of data, the expert may need to obtain more data to deepen \nhis\/her understanding of the project. The estimator needs to analyse the \nrequirements, and classify the type of product and the type of estimate they are \nrequired to produce. They also need to understand the constraints in terms of time \nand resources. Once they understand what is required, they establish and \ndocument any ground rules and assumptions and identify the main cost drivers of \nthe project. A Work Breakdown Structure (WBS) is produced and used as the \nframework to cost the new product.  \n \nIn addition, during the synthesis of data and information the estimator normally \nbegins searching for more data and identifying projects that can be used for \ncomparison. For example, the search can be from memory, other people or \nexisting databases. The estimator needs to consider what elements of the \nsource\/reference data can be used as a basis for comparison. When ready the \nexpert will begin to compare the similarities and differences of source and target \nprojects and match them. The matching can be based on different levels of \nabstraction with respect to features, functionality, and project management and so \non. The level of detail searched for will depend on the time constraints and the \ntype of estimate required. The searching process will happen continuously \nthroughout the synthesis process. \n \nEstimate (2): As the estimator compares the similarities and differences, the relative costs from \nthe source product are transferred to the target product. The estimator will \ncontinuously assess the projects in order to understand what costs can be \ntransferred and those that need to be adjusted or estimated for the new project. \nWhen estimating the estimator uses their experience and judgement to predict the \ncost of the new product. The new costs need to be justified through cataloguing \nany assumptions used; however, this is not always the case. \n \nReview (3): The final part of the expert reasoning is to justify and document the assumptions \nused. As mentioned previously, this rationale is not always captured. In addition, \nthe estimator will continually review the estimate because of more information \nbeing received or obtained. Finally, the estimator may use various means to \n\u2018sanity check\u2019 the validity of their estimate. This can be through other people, or \nusing other estimating techniques and tools. \n \n4.4.3 Key inferences \n \nThe inference structure presented in Figure 5 is an abstract representation of the reasoning steps \nused by an estimator. In reality there are many more sub inferences used. However, the main aim \nof an inference structure is to get to a level of decomposition where the inferences used describe \nthe reasoning processes to a sufficient level of detail to understand the domain. The shadowed \novals (inferences) are those identified by the experts where most of the assumptions are made \nduring the process of generating an estimate. In future research, these inferences will be further \ndecomposed in order to identify the knowledge intensive areas of a specific judgement. Due to \nthe limitations of paper length, only generic descriptions of the assumption intensive inferences \nare presented below. \n \nSynthesise \nOperation: The inputs for this inference are the cost-estimating request, and the available project \ndata. Data can include drawings, process plans, work breakdown structures. The \nexperts obtain more data as required in order to understand the estimating \nrequirements.  The constraints are recognised, as are the high cost drivers, and high-\nrisk areas of the project. The output of this inference will be the new project data \nprepared for comparing with the source data, such as the WBS, assumptions and \nground rules and high cost drivers. \nExample: Here the expert analyses, clarifies, establishes, and assimilates all the information into \na format ready for comparing and producing the estimate. Typical assumptions are \nrelated to envisage process improvements, and improved communication through using \nCE principles.  \nKnowledge: The ability to identify those areas that will drive the cost, and establish the high-risk \nareas. This knowledge is dependent upon the project or product being estimated. In a \nspecific domain, the high cost drivers and risk areas may have common characteristics \nso can therefore be captured to guide the expert within the final CERC tool. \n  \nIdentify \nOperation: The inputs are the source data and the details related to the retrieved project or product. \nThe outputs are the identified features, attributes of a product, or project areas that can \nbe used for comparison.  \nExample: Example assumptions would be related to the management structure, the experience of \nthe teams, the quantity of production, the level of complexity, the functionality of the \nproduct, and the manufacturing processes used. \nKnowledge: Knowledge of historical products and those areas that are commonly used as a basis for \ncomparison would need to be identified. These would relate amongst many others to, \nspecification, materials used, mass, type of system, manufacturing processes, assembly \ntechniques, functionally, and productivity rates, whether VAT was used, economic \nconditions, and exchange rates. \n \nCompare \nOperation: The inputs for this inference are the source or reference data, and the new product data \n(target). The output of this inference process will be a measure of both the similarities \nand differences identified by the estimator. \nExample: Examples of similarity measures include: manufacturing methods of the source and \ntarget data. Assessing whether the technologies are the same, the same sorts of \nquantities being produced, the learning curves associated to volume, the processes \nrequired and so on. \nKnowledge: This relates to the types of comparisons that are often made. For example, \nmanufacturing methods, project management, materials, mass, technology, system type \netc. A full list would need to be identified and captured and related to the domain in \nwhich the comparisons are made. \n \nEstimate \nOperation: The inputs are related to the differences identified between the source and target data. \nThe outputs would result in an adjusted cost and new costs based on the assumptions \nused by the estimator. \nExample: The estimator may assume that the manufacturing processes used to produce the \nhistorical product are not representative of the manufacturing processes for the new \nproduct. And may therefore assume a saving of, for example, 40%. It is here that the \nrationale would need to be captured in order to validate the estimate. \nKnowledge: The knowledge required here would be related to the expected changes in \nmanufacturing processes and productivity. The knowledge also includes the impact of \nany changes to the cost. \n 4.4.4 Knowledge role attributes \n \nEach knowledge role is described in terms of the data and information that it contains. This is \nwhat the estimator infers or reasons with. This paper presents a description concerning one of the \ncritical knowledge roles. For example, the knowledge role for \u2018Comparison Data\u2019 would contain \nthe elements such as those described in Table 3. These are the types of data and information that \nan estimator will use to make a comparison. Not all of the attributes of a knowledge role will be \nused; the estimator will use only those that are identified as relevant to the project at hand.  \n \nTable 3: Knowledge role attributes of comparison data \n1.   Identify past cases with respect to each of the WBS elements  \n1.1. Understand and define the technical and programme details \n1.1.1. Any assumptions and ground rules used \n1.1.2. Unusual circumstances the product was produced under \n1.1.3. Operations analysis data \n1.1.3.1. Quantities \n1.1.3.2. Schedules \n1.1.4. Product attributes\/aspects\/features \n1.1.4.1. Mass \n1.1.4.2. Materials used \n1.1.4.3. Structures \n1.1.4.4. Volume \n1.1.4.5. Shape \n1.1.4.6. Dimensions \n1.1.5. Power \n1.1.6. Performance \n1.1.7. Processes \n1.1.7.1. Design process \n1.1.7.2. System development process \n1.1.7.3. Manufacturing process \n1.1.8. Specifications \n1.1.9. Levels of testing and analysis \n1.1.10. Procedures followed \n1.1.11. Constraints \n1.1.12. Limitations  \n1.1.13. Business performance \n1.1.14. Economic influences \n1.1.15. Political issues \n1.1.16. Sources of information \n1.1.17. Validity of cost information \n1.1.18. Other, please define \n \n \n \nIn summary the knowledge roles, transfer functions and inferences provide a means of \nrepresenting both the reasoning processes, and the data and information that the experts reason \nwith. This provides a base from which to develop a Cost Estimating Rationale Capture (CERC) \ntool to guide and capture expert judgement.  \n \n \n5 Discussion & Future Research \n \nThis paper began by introducing the issues related to the use of Expert Judgement (EJ) during the \nprocess of generating a cost estimate. It demonstrated that EJ is continually used throughout the \nprocess of generating estimates whether cost models are used or not. Moreover, that the use of EJ \nis unavoidable, because an estimate is a prediction about the future and judgements are \ncontinually required. The authors\u2019 presented the challenges of capturing cost estimating \nknowledge and discussed the impact EJ can have on an estimate. \n \nThe process of analogy was identified as the main method by which experts reason when \ngenerating cost estimates. Most research within the field of analogy based cost estimating \nfocuses on the development of Case Based Reasoning (CBR) tools. The issues of integrating EJ \nand rationale into the cost estimating process are rarely considered. Therefore, within this paper \nthe development of an inference structure was presented and detailed. The inference structure \nrepresents an abstract view of how an expert judgement is made when referring to historical data. \nThe research also identifies the knowledge intensive inferences for cost estimating. In addition, \nthe knowledge roles are defined for the domain. \n The inference structure presented within this paper is one possible way of representing the \nreasoning processes of an expert. The structure captures the major inferences being used during \nthe generation of cost estimates. The principle aim of an inference structure is to derive a \nstructure that represents the domain, and that is recognised by the experts. \n \nExperts seldom make judgements without some prior knowledge or expertise. Judgement will \nalways be based on some reference point or prior knowledge. The judgement may not be correct \nbut it should be possible to understand how and why it was made. Experts will often say that \ntheir estimate is based on gut feel, yet in reality this is not true [24]. What an expert considers as \n\u2018gut feel\u2019 or intuition is simply years of experience. With a few probe questions, it is possible to \nuncover the reasoning behind the estimate and capture the rationale.  \n \nTherefore, the main thesis of this research is that by first understanding the principles of how \nexperts reason, it will be possible to guide, manage and capture the estimating rationale during \nthe process of generating an estimate. This is not a wild claim as designers have been developing \ntools to capture design rationale for many years [36, 37, 38, 39]. Thus, the future research will \nfocus upon the development of a Cost Estimating Rationale Capture (CERC) software tool that \ncan be used to capture expert rationale as an estimator uses their judgement. It should be noted \nthat the CERC tool would not be an expert system.  \n \nThe CERC will facilitate concurrent cost estimating by providing a means to reuse and share \nrationale underlying cost estimates. The main issues that the research will consider are the \nrepresentation used, allowing estimators to express their reasoning in a natural way, while at the \nsame time being formal enough to support useful computational paradigms. Furthermore, that the \nprocess of describing rationale should impose minimum possible overhead on the estimating \nprocess. \n  \n5.1. Research limitations \n \nThe inference structure described within this report was validated through experts from various \nsectors of the defence and automotive industries. Therefore, it cannot be claimed that this \nreasoning model is representative of generating cost estimates across all domains. In addition, \nthe number of inferences used in the model and the level of representation has been derived \nqualitatively through interviews. Nonetheless, the model does depict the domain and the \nreasoning process to a level of detail that the cost estimators recognised.  \n \nThis inference model represents the abstract reasoning processes of an expert using a reference \nproduct on which to base an estimate. However, the model does not address the issue of an \nexpert not finding a reference product. The future CERC tool will need to consider that a \nreference product may not always be available and an estimate is much more subjectively \nderived. Nonetheless, this inference model does allow one to choose memory as the source of \nreference data. \n \nFurthermore, the abstraction level of making analogies and comparisons is not addressed in the \nmodel. For example, if an expert cannot find a comparative part at a specific level of detail they \nwill begin to search at a higher level of abstraction to find a match [27]. These issues will also be \nconsidered in the future. \n \n6 Conclusions \n \nThis paper demonstrates that the use of expert judgement within the cost estimating process can \nbe structured. Not much research is being done in this area. The authors have shown that the \nreasoning process of experts, when generating cost estimates using analogy is generic. This is \ncounter to the popular belief of the \u2018black art\u2019 or \u2018black box\u2019 nature of the cost estimating \nprocess. The inference structure presented represents the same reasoning process for cost \nestimating at different levels of product definition and detail. The same reasoning process is used \nwhether in the conceptual stages of design or whether in the disposal life cycle phase of a \nproject. The process or method by which an expert uses judgement does not change. Only the \nlevel of abstraction changes. In the conceptual stages of project development, the comparisons \nare made at a much higher level of project definition, and as the project moves into the later \nstages of development, the comparisons become increasingly detailed.  \n \nThe paper outlines the challenges in cost estimating knowledge capture. In order to aid the \nExpert Judgement Rationale capture process a generic inference model is developed for analogy \nbased cost estimating. The model is validated within three industrial sectors: aerospace, \nautomotive and defense. The model identifies the key assumption intensive inferences for the \ncost estimating. The inferences will provide the foundation for developing a Cost Estimating \nRationale Capture (CERC) tool. Capturing the cost estimating rationale will facilitate concurrent \ncost estimating through the sharing and reuse of cost estimating knowledge. \n \n \nReferences \n                                                          \n[1] Hammaker, Joe (2000). The Faster, Better, Cheaper Approach To Space Missions: A Cost Analysis Perspective. \nSSCAG's 69th meeting, European Space Agency, Noordwijk, the Netherlands, May 11-12th. \n \n[2] Rush, C., and Roy, R. (2000). Analysis of cost estimating processes used within a concurrent engineering environment \nthroughout a product life cycle. 7th ISPE International Conference on Concurrent Engineering: Research and \nApplications, Lyon, France, July 17th - 20th, Technomic Inc., Pennsylvania USA, 58-67. \n  \n[3] Rush, C., and Roy, R. (2001). Capturing quantitative and qualitative knowledge for cost modelling within a concurrent \nengineering environment. 8th ISPE International Conference on Concurrent Engineering: Research and Applications, \nAnaheim, California, July 29th - August 1st, CETEAM International, USA, 209-218.  \n \n[4] Beltramo, M. N. (1988). 'Beyond Parametrics: The role of subjectivity in cost models.' Elsevier: Engineering Costs and \nProduction Economics: An International Journal for Industry, 14, 131-136.  \n \n[5] Stensrud, E., and Myrtveit, I. (1998). Human performance estimating with analogy and regression models: an \nempirical validation. IEEE, Proceedings from the Fifth International Software Metrics Symposium, 205-213. \n  \n[6] Bashir, H. A., and Thompson, V. (1997). 'Metrics for design projects: a review.' Design Studies, 20(3), 163-277. \n  \n[7]  Hughes, R. T. (1996). 'Expert judgement as an estimating method.' Information and Software Technology, 38, 67-75. \n \n[8] Shepperd, M., and Schofield, C. (1997). Estimating software project effort using analogies. IEEE Transactions on \nSoftware Engineering, 23(12), 736-743. \n  \n[9] Lederer, A. L., and Prassad, J. (1998). 'A causal model for software cost estimating error.' IEEE Transactions on \nSoftware Engineering, 24(2), 137-148. \n  \n[10] Dalkey, N., and Helmer, O. (1962). An Experimental Application of the Delphi Method to the use of Experts. Contract \nNumber AF 49(683)-700, United States Airforce,  RAND Corporation. \n  \n[11] Dalkey, N., Brown, B., and Cochran, C. (1969). The Delphi Method, 111: Use of Self Ratings to Improve Group \nEstimates. RM-6115-PR, The RAND Corporation. \n  \n[12] Kitchenham, B. A. (1992). 'Empirical studies of assumptions that underlie software cost-estimation models.' \nInformation and Software Technology, 34(4), 211-218. \n  \n[13] Rush, C., and Roy, R. (2001). 'Knowledge in Cost Modelling.' The Cost Engineer: The Journal of the Association of \nCost Engineers, 39(1), 10-12.  \n  \n[14] Stewart, R. D., Wyskida, R. M., and Johannes, J. D. (1995). Cost estimators reference manual, New York: Wiley \nInterscience. \n  \n[15] Department Of Defence (1999). Parametric Estimating Handbook, 2nd Ed., DoD, http:\/\/www.ispa-\ncost.org\/PEIWeb\/cover.htm. \n  \n[16] Mileham, R. A., Currie, C. G., Miles, A. W., Bradford, D. T. (1993). A Parametric Approach to Cost Estimating at the \nConceptual Stage of Design. Journal of Engineering Design, 4(2), pp. 117-125. \n  \n                                                                                                                                                                                           \n[17] Pugh, P. (1992). 'Working top-down: Cost estimating before development begins.' Proceedings from the Institution of \nMechanical Engineers, 206, 143-151. \n  \n[18] Pine, David (2000). New Ways of Doing Business. SSCAG's 69th meeting, European Space Agency, Noordwijk, the \nNetherlands, May 11-12th. \n \n[19] Boehm, B. W. (1981). Software engineering economics, Prentice-Hall: Englewood Cliffs, N.J. \n  \n[20] Shepperd, M., Schofield, C., and Kitchenham, B. (1996). Effort Estimation Using Analogy. The 18th International \nConference on Software Engineering, Berlin, 170-178.  \n \n[21] Bashir, H. A., and Thompson, V. (2001). 'An analogy-based model for estimating design effort.' Design Studies, 22(2), \n157-167. \n  \n[22]  Cowderoy, A. J. C., and Jenkins, J. O. (1988). Cost-estimation by analogy as a good management practice. Software \nEngineering 88, Second IEE\/BCS Conference, 80 -84. \n \n[23] Tessem, B., and Modeling, S. (1997). 'Analogy and complex software modelling.' Computers in Human Behaviour, \n14(4), 465-486. \n  \n[24] Klein, G., (1998). Sources of Power: How people make decisions. Massachusetts Institute of Technology, ISBN: 0-\n262-11227-2. \n  \n[25] Gentner, D. (1983). 'Structure-mapping: A theoretical framework for analogy.' Cognitive Science, 7(2), 155-170.  \n  \n[26] NASA (Accessed July 2001).  Parametric cost estimating process flow analogy approach. \nhttp:\/\/www.jsc.nasa.gov\/bu2\/analogy.html \n  \n[27] Zhuge, H., Jian, M., and Xiaoqing, S. (1997). 'Abstraction and analogy in cognitive space: A software process model.' \nInternational Journal of Information and Software Technology, 39(7), 463-468. \n  \n[28] Kadoda, G., Cartwright, M., Chen, L., and Shepperd, M. (2000). Experiences using case-based reasoning to predict \nsoftware project effort. Conference on Empirical Assessment in Software Engineering (EASE), Printed by: Keele \nUniversity, 1-23. \n   \n[29] Duverlie, P., and Castelain, J. M. (1999). 'Cost Estimation During Design Step: Parametric Method Versus Case Based \nReasoning.' The International Journal of Advanced Manufacturing Technology, 15, 895-906.  \n \n[30] Rehman, S., and Guenov, M. D. (1998). 'A methodology for modelling manufacturing costs at conceptual design.' \nComputers ind. Engng, 35(3-4), 623-626. \n  \n[31] Defence Procurement Agency (Accessed July 2001). Projects: Future Offensive Air Systems (FOAS). \nhttp:\/\/www.mod.uk\/index.php3?page=1496   \n  \n[32] Durkin, J (1994). Expert Systems, Design and Development. Macmillian Publishing Company, New York, USA, ISBN: \n0-02-330970-9, 1994. \n  \n[33] Jackson, P (1986). Introduction to Expert Systems. Addison-Wesley Publishing Company, ISBN: 0-201-14223-6. \n  \n[34] Schreiber, G., Akkermans, H., Anjewierden, De Hoog, R., Shadbolt, N., Van De Velde, W., & Wielinga, B (2000). \nKnowledge Engineering and Management: The CommonKADS Methodology. A Bradford Book, The MIT Press, \nCambridge, Massachusetts. \n  \n[35] Bailey, J., Roy, R., Harris, R. And Tanner, A., \u201cCutting Tool Design Knowledge Capture\u201d, Industrial Knowledge \nManagement - A Micro Level Approach. Roy, R. (Ed.), Springer-Verlag (London), ISBN 1-85233-339-1, pp. 393-411, \n2000.  \n \n[36] Klein, M. (1993). 'Capturing design rationale in concurrent engineering teams.' Computer, 26(1), 39-47.  \n \n[37] Lee, J., and Lai, K.-Y. (1991). 'What's in design rationale?' Human-Computer Interaction, 6(3&4), 251-280.  \n \n                                                                                                                                                                                           \n[38] Conklin, J., and Yakemovic, K. B. (1991). 'A process-oriented approach to design rationale.' Human-Computer \nInteraction, 6(3&4), 357-391.  \n \n[39] Shum, S. B. (1996). 'Design argumentation as design rationale.' The Encyclopaedia of Computer Science and \nTechnology, 35(20), 95-128.  \n"}
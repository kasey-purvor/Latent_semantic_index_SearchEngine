{"doi":"10.1207\/s15326969eco1801_2","coreId":"93168","oai":"oai:eprints.lse.ac.uk:2604","identifiers":["oai:eprints.lse.ac.uk:2604","10.1207\/s15326969eco1801_2"],"title":"In defense of mechanism","authors":["Wells, Andrew J."],"enrichments":{"references":[{"id":17340985,"title":"Aristotle\u2019s Four Becauses.","authors":[],"date":"1974","doi":"10.1017\/s0031819100063324","raw":"Hocutt, M., (1974). Aristotle\u2019s Four Becauses. Philosophy, 49, 385-99.","cites":null},{"id":17340990,"title":"Essays on Life Itself.","authors":[],"date":"2000","doi":null,"raw":"Rosen, R. (2000). Essays on Life Itself. New York, NY: Columbia University Press.","cites":null},{"id":17340996,"title":"Gibson\u2019s Affordances and Turing\u2019s Theory of Computation.","authors":[],"date":"2002","doi":"10.1207\/s15326969eco1403_3","raw":"Wells, A.J. (2002). Gibson\u2019s Affordances and Turing\u2019s Theory of Computation.","cites":null},{"id":17340993,"title":"Impredicativity, dynamics, and the perception-action divide.","authors":[],"date":"2004","doi":"10.1007\/978-3-540-39676-5_1","raw":"Turvey, M.T. (2004). Impredicativity, dynamics, and the perception-action divide. In V.K. Jirsa & J.A.S. Kelso (eds), Coordination Dynamics: Issues and Trends. Vol.1 Applied Complex Systems (pp. 1-20). New York: Springer Verlag.","cites":null},{"id":17340989,"title":"Life Itself. A Comprehensive Inquiry Into the Nature, Origin, and Fabrication of Life.","authors":[],"date":"1991","doi":"10.1016\/s0092-8240(05)80312-x","raw":"Rosen, R. (1991). Life Itself. A Comprehensive Inquiry Into the Nature, Origin, and Fabrication of Life. New York, NY: Columbia University Press.","cites":null},{"id":17340987,"title":"Mind as Motion. Explorations in the Dynamics of Cognition.","authors":[],"date":"1995","doi":"10.2307\/417624","raw":"Port, R.F. & van Gelder, T. (1995). Mind as Motion. Explorations in the Dynamics of Cognition. Cambridge, MA: MIT Press.","cites":null},{"id":17340992,"title":"On Computable Numbers with an application to the Entscheidungsproblem.","authors":[],"date":"1936","doi":"10.1016\/b978-0-08-009217-1.50024-4","raw":"Turing, A.M. (1936). On Computable Numbers with an application to the Entscheidungsproblem. Proceedings of the London Mathematical Society, Series 2, 42, 230-265.","cites":null},{"id":17340983,"title":"On formally undecidable propositions of Principia Mathematica and related systems I. In Kurt G\u00f6del. Collected Works. Volume 1. Publications 1929-1936.","authors":[],"date":"1931","doi":"10.2307\/2274975","raw":"G\u00f6del, K. (1931). On formally undecidable propositions of Principia Mathematica and related systems I. In Kurt G\u00f6del. Collected Works. Volume 1. Publications 1929-1936. Oxford, UK: Oxford University Press, 144-195.","cites":null},{"id":17340984,"title":"Russell\u2019s mathematical logic. In Kurt G\u00f6del. Collected Works.","authors":[],"date":"1944","doi":"10.1017\/cbo9781139171519.024","raw":"G\u00f6del, K. (1944). Russell\u2019s mathematical logic. In Kurt G\u00f6del. Collected Works.","cites":null},{"id":17340991,"title":"The Agent-Environment Interface: Simon\u2019s Indirect or Gibson\u2019s Direct Coupling?","authors":[],"date":"2003","doi":"10.1207\/s15326969eco1501_04","raw":"Shaw, R.E. (2003). The Agent-Environment Interface: Simon\u2019s Indirect or Gibson\u2019s Direct Coupling? Ecological Psychology, 15(1), 37-106.","cites":null},{"id":17340982,"title":"The Ecological Approach to Visual Perception.","authors":[],"date":"1986","doi":"10.4324\/9780203767764","raw":"Gibson, J.J. (1986). The Ecological Approach to Visual Perception. Hillsdale, NJ: Lawrence Erlbaum Associates, Inc. (Original work published 1979).","cites":null},{"id":17340981,"title":"The Senses Considered as Perceptual Systems.","authors":[],"date":"1966","doi":"10.2307\/1571911","raw":"Gibson, J.J. (1966). The Senses Considered as Perceptual Systems. Boston, MA: Houghton Mifflin.","cites":null},{"id":17340986,"title":"Theoretical Biology: Organisms and Mechanisms.","authors":[],"date":"2002","doi":null,"raw":"49Landauer, C. & Bellman, K.L. (2002). Theoretical Biology: Organisms and Mechanisms. CP627, Computing Anticipatory Systems: CASYS 2001\u2014Fifth International Conference, 59-70.","cites":null},{"id":17340988,"title":"Theory of Recursive Functions and Effective Computability.","authors":[],"date":"1967","doi":"10.1137\/1011079","raw":"Rogers, H. Jr. (1967) Theory of Recursive Functions and Effective Computability. Cambridge, MA: MIT Press.","cites":null},{"id":17340995,"title":"Toward an Ecological Physics and a Physical Psychology. In","authors":[],"date":"1995","doi":null,"raw":"Turvey, M.T. & Shaw, R.E. (1995). Toward an Ecological Physics and a Physical Psychology. In R.L. Solso & D.W. Massaro (eds) The Science of the Mind: 2001 and Beyond. New York, NY: Oxford University Press.","cites":null}],"documentType":{"type":0.6666666667}},"contributors":[],"datePublished":"2006","abstract":"In Life Itself and in Essays on Life Itself, Robert Rosen (1991, 2000) argued that machines were, in principle, incapable of modeling the defining feature of living systems, which he claimed to be the existence of closed causal loops. Rosen's argument has been used to support critiques of computational models in ecological psychology. This article shows that Rosen's attack on mechanism is fundamentally misconceived. It is, in fact, of the essence of a mechanical system that it contains closed causal loops. Moreover, Rosen's epistemology is based on a strong form of indirect realism and his arguments, if correct, would call into question some of the fundamental principles of ecological psychology","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/93168.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/2604\/1\/In_Defence_of_Mechanism_%28LSERO%29.pdf","pdfHashValue":"7033bb02aea9e58b7d8e03c19748da4a74502d3e","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:2604<\/identifier><datestamp>\n      2016-06-20T11:18:09Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5053<\/setSpec><setSpec>\n      74797065733D4445505453:4C53452D504253<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/2604\/<\/dc:relation><dc:title>\n        In defense of mechanism<\/dc:title><dc:creator>\n        Wells, Andrew J.<\/dc:creator><dc:subject>\n        BF Psychology<\/dc:subject><dc:description>\n        In Life Itself and in Essays on Life Itself, Robert Rosen (1991, 2000) argued that machines were, in principle, incapable of modeling the defining feature of living systems, which he claimed to be the existence of closed causal loops. Rosen's argument has been used to support critiques of computational models in ecological psychology. This article shows that Rosen's attack on mechanism is fundamentally misconceived. It is, in fact, of the essence of a mechanical system that it contains closed causal loops. Moreover, Rosen's epistemology is based on a strong form of indirect realism and his arguments, if correct, would call into question some of the fundamental principles of ecological psychology.<\/dc:description><dc:date>\n        2006<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/2604\/1\/In_Defence_of_Mechanism_%28LSERO%29.pdf<\/dc:identifier><dc:identifier>\n          Wells, Andrew J.  (2006) In defense of mechanism.  Ecological Psychology, 18 (1).  pp. 39-65.  ISSN 1040-7413     <\/dc:identifier><dc:relation>\n        http:\/\/www.leaonline.com\/toc\/eco<\/dc:relation><dc:relation>\n        10.1207\/s15326969eco1801_2<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/2604\/","http:\/\/www.leaonline.com\/toc\/eco","10.1207\/s15326969eco1801_2"],"year":2006,"topics":["BF Psychology"],"subject":["Article","PeerReviewed"],"fullText":"  \nA.J. Wells\nIn defense of mechanism \n \nArticle (Accepted version) \n(Refereed) \n \nOriginal citation: \nWells, Andrew J. (2006) In defense of mechanism. Ecological psychology, 18 (1). pp. 39-65 \nDOI: 10.1207\/s15326969eco1801_2  \n \n\u00a9 2006 Lawrence Erlbaum Associates, Inc. \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/2604\/  \nAvailable in LSE Research Online: January 2010 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final manuscript accepted version of the journal article, \nincorporating any revisions agreed during the peer review process.  Some differences between \nthis version and the published version may remain.  You are advised to consult the publisher\u2019s \nversion if you wish to cite from it. \nIn Defence of Mechanism \n \n \n \n \n \nA.J. Wells \n \n \n \n \n \nInstitute of Social Psychology \nThe London School of Economics and Political Science \nLondon, United Kingdom \n 1\n Abstract \n \nIn Life Itself and in Essays on Life Itself, Robert Rosen (1991, 2000) argued that \nmachines were, in principle, incapable of modelling the defining feature of living \nsystems which he claimed to be the existence of closed causal loops. Rosen\u2019s \nargument has been used to support critiques of computational models in ecological \npsychology. This paper shows that Rosen\u2019s attack on mechanism is fundamentally \nmisconceived. It is, in fact, of the essence of a mechanical system that it contains \nclosed causal loops. Moreover, Rosen\u2019s epistemology is based on a strong form of \nindirect realism and his arguments, if correct, would call into question some of the \nfundamental principles of ecological psychology. \n 2\nIntroduction \n \nThe pregnant question \u2018What is Life?\u2019 has received many different types of answer \nderived from a variety of different research strategies. One strategy is to examine the \ndenizens of the world and to look for a common element or condition possessed by all \nliving things and by nothing else. That common element, once identified, can then be \nproclaimed as the answer to the question. There are many difficulties with this \nstrategy. One is that it is circular. It presupposes that living things can be identified in \norder that the essence of life can be extracted from them. A second difficulty is the \nessentialist assumption that there is a common thread binding all living things \ntogether. The forms of life may simply be too varied and disparate for this to be true.   \nAnother strategy is to proceed by a process of elimination. By becoming clear \nabout what life is not, one hopes to become clearer about what it is. The bio-physicist \nRobert Rosen adopted essentially this strategy in his book Life Itself, Rosen (1991). \nRosen\u2019s principal target was the idea that living things were biological machines. In \nhis note to the reader at the start of the book he said \n \nIt has turned out that, in order to be in a position to say what life is, we must \nspend a great deal of time in understanding what life is not. Thus, I will be \nspending a great deal of time with mechanisms and machines, ultimately to \nreject them, and replace them with something else. \n \n  Rosen (1991, p.xv) \n \n 3\nRosen\u2019s central argument reached the conclusion that \u2018there can be no closed path of \nefficient causation in a mechanism\u2019 (Rosen 1991, p.241). By contrast, in his view, \norganisms are characterised precisely by the presence of such paths: \u2018a material \nsystem is an organism if, and only if, it is closed to efficient causation.\u2019 (Rosen 1991, \np.244) The centrality of the argument based on causal loops can be gauged from the \nfact that it is repeatedly reasserted in Essays on Life Itself and is also a key part of \nRosen\u2019s description of Life Itself in a short paper called Autobiographical \nReminiscences which can be found on the Internet at \u2018http:\/\/www.rosen-\nenterprises.com\/RobertRosen\/RRosenautobio.html\u2019. The statement there is clear and \ntrenchant: \n \nI argue that the external, public, material world is full of closed causal loops, \njust as the internal, mathematical world is full of closed inferential ones \n(impredicativities). The \u201cworld\u201d of the mechanism, or machine (or, as I call it, \nthe simple systems), and which I believe is an artificial human limitation on \nreality, does not allow such loops. Accordingly, as a class, these simple \nsystems are extremely poor, or limited, in entailment and hence extremely \nnongeneric. \n \nRosen described the idea that science is essentially mechanistic as a prejudice and \nargued that it had \u2018disastrous consequences\u2019 (Rosen 1991, p.xvi). In particular he \nclaimed that the assumption of mechanism made it impossible to answer the question \n\u2018What is life?\u2019 This was not just dramatization for emphasis: that the charge was \nintended seriously is clear from the context.  \n \n 4\n[T]he initial presupposition that we are dealing with mechanism already \nexcludes most of what we need to arrive an answer. No amount of refinement \nor subtlety within the world of mechanism can avail; once we are in that \nworld, what we need is already gone. \n \n (Rosen 1991, p.xvi) \n \nIt is not immediately clear why the assumption of mechanism should be so damaging \nto the attempt to understand the essential characteristics of organisms. Theories are \nalways wrong in some respects but rarely make it impossible to answer core \nquestions. The explanation for the strength of Rosen\u2019s anti-mechanism is to be found \nin his conception of science and his view of the relation between minds and the \nexternal world.  \nRosen\u2019s critique of mechanistic ideas in biology has been endorsed by leading \necological psychologists including Michael Turvey and Robert Shaw (cf. Turvey and \nShaw 1995; Shaw 2003; Turvey 2004). If the critique is correct it applies, among \nother things, to computational models of psychological processes because they are \nmachine models. It thus becomes apparent that the critique is very wide ranging in its \nscope. It would show, if it were true, that the mainstream approach to cognitive \nscience must be mistaken in its foundational assumption that the mind can be \nunderstood in computational terms. It would also show that proposals to deploy \ncomputational thinking in ecological psychology, for example the modelling of \naffordances as the configurations of Turing machines by Wells (2002), must be \nflawed or, at best, radically incomplete. Fortunately, for those who value machine \nmodels in psychology, Rosen\u2019s critique is not correct. It is, in fact, fundamentally \n 5\nmisconceived because it is of the essence of a machine that it contains precisely the \nclosed causal loops that Rosen claims cannot be realised in machines.  \nThis paper defends machine models and the mechanist philosophy against \nRosen\u2019s attack. The simplest, and most obvious, way to rebut Rosen\u2019s critique is by \ndisplaying machines which exhibit closed loops. Several such machines are described \nand discussed. These machines provide conclusive counterexamples to Rosen\u2019s \ncentral argument. A rebuttal along these lines alone, however, does not address the \nquestion of how Rosen came to reach his conclusions nor does it tackle the details of \nhis arguments. These are valuable supporting exercises. The paper begins, therefore, \nwith an overview of Life Itself  (Rosen 1991). It then summarizes and offers a critique \nof Rosen\u2019s central argument. This is followed by discussion of some subsidiary \narguments which appear principally in Essays on Life Itself. Turing machines are then \nintroduced and are readily seen to exhibit closed causal loops. In the final section of \nthe paper some aspects of Rosen\u2019s philosophy and methodology are compared with \nsome of the principles and methods of ecological psychology. \n \nOverview \n \nOne of the curious features of Life Itself, which Rosen described as a book about \nbiology, is that there is rather little in it which most people would recognize as \nbiology and a great deal which looks like mathematics. Category theory, set theory \nand recursive function theory all feature in the development of the argument. The \nreason for this is that Rosen understood science in terms of a specific conception of \nNatural Law and in terms of an epistemology which laid fundamental emphasis on \nmodelling relations between natural systems and the accounts that we give of them in \n 6\nboth natural and formal languages. The first task for a student of Rosen should, \ntherefore, be to understand his epistemology and philosophy of science. \n Science, Rosen said, is built on dualities and he suggested that \u2018the most \nfundamental dualism\u2019 is that between the self and everything else. Section 3B of Life \nItself describes this dualism in Cartesian terms. According to Rosen the self \nencompasses or contains  \n \n\u2018our perceptions, our thoughts, our ideas, our imaginings, our will, and the \nactions that spring from them. This is the inner world. Everything else is \noutside.\u2019 \n \n (Rosen 1991, pp. 40-1) \n \nThat which is other than the self Rosen calls the \u2018ambience\u2019 and he thinks of science \nas a kind of relation between the self and the ambience. Science he says \n \n\u2018requires an external, objective world of phenomena, and the internal, \nsubjective world of the self, which perceives, organizes, acts, and understands. \nIndeed, science itself is a way (perhaps not the only way) of bringing the \nambience inside, in an important sense, a way of importing the external world \nof phenomena into the internal, subjective world that we apprehend so \ndirectly.\u2019 \n \n (Rosen 1991, p.41) \n \n 7\nIt is, I think, of great importance for ecological psychologists to understand, as this \nquotation shows, that Rosen\u2019s epistemology is based on a strong form of indirect \nrealism. It is a key part of the context needed to understand his attack on mechanism \nand it suggests, rather obviously, that Rosen\u2019s philosophy is much less compatible \nwith ecological psychology than some of his apologists may like to think. \nA \u2018second basic dualism\u2019 as Rosen describes it concerns how we take the \nambience to be partitioned into systems and their environments. The way that Rosen \ncharacterizes this second dualism reinforces the point just made about his indirect \nrealism. Talking about how we manage our perceptions of the external world he says,  \n \n\u2018At this level, we have no universal principles to guide us, nothing given to us, \nlike the distinction between the inner world of the self and the outer world, \nwhat we called the ambience. It rests rather on a consensus imputed to the \nambience, rather than on some objective and directly perceptible property of \nthe ambience.\u2019 \n \n (Rosen 1991, p.41) \n \nThe idea that there is a consensus that imputes or ascribes properties and meanings to \nthe external world suggests the view that everyday reality is, in part, a social \nconstruction. Notice the striking contrast here with Gibson\u2019s view of the external \nworld as the locus of ecological reality: \n \nThe world of physical reality does not consist of meaningful things. The world \nof ecological reality, as I have been trying to describe it, does. If what we \n 8\nperceived were the entities of physics and mathematics, meanings would have \nto be imposed on them. But if what we perceive are the entities of \nenvironmental science, their meanings can be discovered. \n \n (Gibson 1986, p. 33) \n \nThe significance of the partition of the ambience into systems and their environments \nlies, says Rosen, in the fact that it leads us to treat the components in fundamentally \ndifferent ways. Systems are described in terms of states and environments are \ndescribed in terms of their effects on systems. This, Rosen says, is a source of \nfundamental trouble but it is of less concern for the present paper than the first basic \ndualism between the self and the ambience. Rosen takes perception of the external \nworld to be mediated by the inner self. In section 3D of Life Itself he says that \nlanguage plays \u2018an essential role as an intermediary between the self and its \nambience\u2019 (p.43) but he does not say clearly in that section what the essential role of \nlanguage is. Instead he describes the differences between natural and formal \nlanguages and between syntax and semantics and introduces what will become a key \nidea, namely the fact that the syntactic production rules of languages, both natural and \nformal, are vehicles for inferential entailment. Further discussion of inferential \nentailment in section 3E includes a brief discussion of Aristotle\u2019s four categories of \ncausation, a topic which is treated further in due course. A key point to note about \ninferential entailment is that it can be understood in terms of causal relations between \nsyntactic elements. For example, given the rules of elementary arithmetic, the string \nof symbols 2 + 2 = ? entails, or can be said to cause, the symbol 4, whereas the string \n 9\n2 \u2013 2 = ? entails the symbol 0. In section 3G Rosen discusses entailment in the \nexternal world. The key question he asks is the following: \n \n\u2018[I]s there, in this external world, any kind of entailment, analogous to the \ninferential entailment we have seen between propositions in a language or \nformalism?\u2019 \n \n (Rosen 1991, p.55) \n \nThe discussion which follows further confirms his view of perception as indirect. \nRosen says, with explicit reference to Kant, that things in themselves are \u2018inherently \nunknowable\u2019 except through the perceptions they elicit in us and acknowledges that \nthis is a potent source for scepticism. He concludes, nonetheless, that it is reasonable \nto posit relations of entailment between phenomena in the external world because \nnatural language \u2018imputes hordes of entailments to the ambience\u2019 (p.56) without \nleading us seriously astray. These entailments are taken to be causal. Notice the \nsecond use of the term \u2018impute\u2019.  \n To summarize the discussion so far, Rosen has, before the end of chapter 3 of \nLife Itself made the following points: there is a fundamental distinction between the \ninternal world of the self which, in Cartesian fashion, is known directly and \nindubitably and the external world which is known only indirectly. The internal world \ncontains a variety of languages which instantiate systems of inferential entailment. \nSemantic projections from these inferential systems outwards onto the external world \nare generally reliable and support the assumption that the external world contains \nentities which are systematically related to one another by causal entailments. \n 10\n Building on this foundation, Rosen discusses natural law and modelling \nrelations in section 3H. The point of this section is to discuss whether, and if so how, \ninferential entailment in the inner world can be related to causal entailment in the \nexternal world. Rosen argues that they can be related by the establishment of a \nmodelling relation between them. According to his view modelling relations are \npossible by virtue of Natural Law which provides the explicit underpinning for \nscience. Natural Law, in Rosen\u2019s formulation of it, rests on two fundamental \nassertions: first, that events in the external world are ordered and exhibit systematic \ncausal relations; second that these orderly causal relations can be grasped by the \nhuman mind.  \n \n\u2018[T]he causal relations manifested by a natural system provide the orderliness \nrequired of the ambience. Inferential entailment in a formal system is a way of \nproviding the orderliness required of the self. The art of bringing the two into \ncorrespondence, through the establishment of a definite modeling relation \nbetween them, is the articulation of the former within the latter; it is in effect \nscience itself.\u2019 \n \n (Rosen 1991, p.59) \n \nA modeling relation is thus a form of congruence between entailment structures. \nCausal entailment in the external world is mapped onto inferential entailment in the \ninner world. If the mapping captures the essential features of the causal system, it will \nbe possible to use the inferential structure of the formal system to make predictions \nabout events in the external world. The discovery of the planet Pluto is a well known \n 11\nexample. Prior to its discovery, astronomers had modelled the orbits of the known \nplanets in a mathematical model of the solar system. The mathematical model was a \nsystem of inferential entailment in Rosen\u2019s terms whereas the actual orbits of the \nplanets constitute a system of causal entailment. Calculations based on the model \nallowed the astronomers to predict the future positions of the planets. Observations \nshowed that the model was faulty because the planets did not behave as the model \npredicted. Further mathematical reasoning, which can be described as the tracing of \npossible paths of entailment in a revised model, showed that the positional \ndiscrepancies of the known planets could be accounted for by the postulation of \nanother planet beyond Uranus. The revised model was used to predict the position of \nthis planet and telescopic search subsequently led to the discovery of Pluto.  \n Two points of particular importance should be noted about the modeling \nrelation. First, models are essential because they provide the means whereby we \nobtain knowledge about the external world and its future behaviour. Second, there are \ntwo-way relations between  natural systems of causal entailment (N) and formal \nsystems of inferential entailment (F). Rosen describes the situation thus: \n \n\u2018[T]he modeling process compares causal entailment in N with inferential \nentailment in F; if we are successful in establishing such a relation, then F is \nthe model; N is a realization of that model. But it is essential to note that the \nroles of N and F can be interchanged. That is, instead of starting with a natural \nsystem N, and looking in effect for a formalism F that models it, we could \nstart with a formal system F and ask for a natural system N whose causal \nentailment provides a model for inferential entailment in F.\u2019 \n \n 12\n (Rosen 1991, p.61) \n \nHere, I think, we have reached the foundation of Rosen\u2019s objections to machine \nmodels in biology and the basis for his belief that such models make it impossible to \ndiscover the causal principles governing organisms. The core problem, in his view, is \nthat mechanistic philosophy starts with a formal machine model in the inner world \nand projects this onto the outer world. It assumes, that is, that organisms are machines \nand will be found to exhibit causal entailments that are congruent to the inferential \nentailments found in machines. This is a double mistake in Rosen\u2019s view: it is wrong \nbecause, as a matter of fact, organisms exhibit patterns of causal entailment that are \nnot, and cannot be, captured by the patterns of inferential entailment available in \nmachines, and it is wrong because the strategy prevents us from understanding the \npatterns of causal entailment that do exist in organisms. Formal models are our \nwindows on the external world and the machine model is a window that makes it \nimpossible to understand how organisms work. It is this, in Rosen\u2019s view, that makes \nmechanism such a pernicious philosophy of biology. \nFrom this standpoint there are two major issues for Rosen to tackle. First, \nmachine models must be characterized and shown to be inadequate; second, an \nanalysis of the kind of modeling strategy needed to provide the theoretical foundation \nfor biology has to be given. Notice that it is not enough for Rosen simply to reject \nmechanism. On his view, models are an essential part of the process of theory \nconstruction and development. A critique of mechanism leaves a gap that has to be \nfilled by formal models of some kind. Chapters 4 to 10 of Life Itself are concerned \nwith these issues and the final chapter outlines Rosen\u2019s proposal that biology should \n 13\nbe based on relational models and compares the proposed relational biology with \nexisting theories and models. \n \nThe anti-mechanist argument of Life Itself \n \nRosen\u2019s anti-mechanist argument is complex and multi-faceted. It is also obscure in \nplaces. Even his most ardent supporters would hardly claim that Rosen\u2019s exposition is \nalways clear. I think, however, that the following list of propositions is a fair \nsummary of the principal points of the argument and, roughly, of its sequence. I have \nindicated in parentheses the primary places in Life Itself in which the points of the \nargument are presented and\/or elaborated. It should also be noted that some points \ndepend on earlier chapters of the book. Points 5-7, for example, draw on the material \nof chapter 6, and the argument in chapters 9 and 10 draws on the ideas about \nrelational modeling developed in chapter 5. \n \n1. A system, natural or formal, is a machine if it simulates, or can simulate, \nsomething else. Simulation is what machines do (7B, 7D, 7E). \n2. Simulation involves a fundamental distinction between hardware and software \n(7D, 9A, 9B, 9D). \n3. A natural system, N, is a mechanism if and only if all of its models are \nsimulable (8B). \n4. A natural system, N, is a machine if and only if it is a mechanism such that at \nleast one of its models is already a mathematical machine (8B). \n5. If N is a mechanism it has a unique largest model (8C). \n6. If N is a mechanism it has a finite set of minimal models (8D). \n 14\n7. The largest model of a mechanism is the direct sum of its minimal models and \nis therefore synthetic (8E). \n8. In mathematical machines efficient causality and material causality are \nsegregated into disjoint structures; hardware is the embodiment of efficient \ncause while material cause is embodied in software (9A, 9B). \n9. Hardware entails the flow of software states from input to output, but software \ncannot entail hardware (9B, 9D). \n10. A hardware component can only be entailed by another hardware component \n(9E).  \n11. A system S1 in which a previously unentailed hardware component is entailed \nmust have more states than S0 the system in which the component was \nunentailed (9E). \n12. The larger system S1 will itself have at least one unentailed hardware \ncomponent (9F). \n13. Only in the limit as n approaches infinity will every component in a system Sn \nbe entailed (9F). \n14. Such a system cannot be a mechanism because a mechanism has a finite \nlargest model (9F). \n15. Hardware cannot be entailed by adding further constraints to existing \ncomponents because this involves splitting states into direct summands and \nleads to an infinite regress of fractionation. Such a regress contradicts the fact \nthat a machine has a finite set of minimal models (9F). \n16. The argument of points 1 \u2013 15 shows that there can be no closed path of \nefficient causation in a mechanism (9G). \n17. Organisms exhibit closed paths of efficient causation (10A, 10C). \n 15\n18. Organisms are not machines (10B). \n \nThe argument is vulnerable to a range of criticisms and fails to establish the central \nclaim made in point 16. I shall discuss its principal weaknesses but it will be useful, \nbefore doing this, to consider briefly the distinction between efficient and material \ncauses that is mentioned in points 8 and 16.  \nThe distinction stems from Aristotle\u2019s classification of \u2018causes\u2019 into four \ntypes, material, efficient, formal and final. There is a consensus among contemporary \nscholars that the Greek word \u2018\u03b1\u03b9\u03c4\u03b9\u03bf\u03bd\u2019 which has traditionally been translated as \n\u2018cause\u2019 should, in fact, be translated as \u2018because\u2019 (Hocutt, 1974; Moravscik, 1974). \nThe four-fold distinction made by Aristotle is, therefore, best thought of as a \nclassification of different types of explanation not different types of causes. The only \ntype that would be considered causal in modern terminology is the category of \nefficient cause. Rosen uses Aristotle\u2019s terminology primarily to distinguish causal \nrelations among the hardware components of a system which he describes as instances \nof efficient causation, from causal relations in software which he describes as \ninstances of material causation (cf. Life Itself, sections 5H, 9D). Part of the reason \nwhy Rosen uses Aristotle\u2019s terminology stems, I think, from the fact that he wants to \ncompare entailment in material systems with entailment in formal systems and is able \nto do this by using Aristotle\u2019s analysis to distinguish the different types of cause in \nboth cases. The discussion in section 3G of Life Itself (p.57) seems to me to support \nthis understanding. However, given the fact that material \u2018causes\u2019 in the Aristotelian \nscheme of things are not causes as we would understand them the distinction obscures \nmore than it clarifies. It is, in any event, not a significant aspect of the argument. \nWhat is significant is Rosen\u2019s claim that the causal relations between hardware \n 16\ncomponents of a system are distinct from the causal relations embodied in software. It \nshould, of course, be remembered that in any real machine to which the \nhardware\/software distinction applies, software components are just as real and \nmaterial as hardware and, therefore, just as much subject to causal influence. The \ndistinction which Rosen marks by the use of the terms \u2018efficient\u2019 and \u2018material\u2019 is, \ntherefore, a distinction of causal role, not causal type. Provided, then, it is understood \nthat the central claim in point 16 of Rosen\u2019s argument refers to causal relations among \nthe hardware components of machines, and provided also that the causal roles of \nhardware and software are distinguished where necessary, nothing is lost by ignoring \nor eliding the distinction between so-called efficient and material causes. \nTurning now to the status of the argument itself, point 1, which takes \nsimulation to be the key criterion for distinguishing machines from other systems, is \nsimply wrong. Most machines do not simulate. Think of the functions of the everyday \nmachines which surround us: refrigerators cool things; cars transport us from place to \nplace; scissors cut things; pianos produce music; and so forth. None of these machines \nis a simulator. Machines which do simulate, of which computers are the most obvious \nexamples, are a special, highly organized class. Rosen\u2019s definition of a machine is, \ntherefore, far too narrow. However, even if it were correct, the definition does not \nestablish what he wishes to establish. Part of his reason for focusing on simulation as \nthe key activity of machines is his belief that there is a fundamental divide between \nsimulation and modelling. He claims that whereas a model lays bare the entailment \nstructure of the system it models, a simulation hides it. \n \n\u2018In causal terms, simulation involves the conversion of efficient cause, the \nhardware of that being simulated, into material cause in the simulator. In \n 17\nessence, this means that one can learn nothing about entailment by looking at a \nsimulation.\u2019 \n \n (Rosen 1991, p.193) \n \nThis is an extraordinary claim which, once again, is simply wrong. If it were true \nthere would be absolutely no point in the many computer simulations, for example of \nairflows over aircraft wings and the development of weather patterns, which are used \nto study causal relations in complex systems. Far from hiding the details of causal \ninteractions in the systems which are modelled, simulations enable them to be studied \nin great detail and at a variety of time scales. A simulation is rather like a high speed \nfilm of the impact of a bullet on a particular material in which time can be slowed \ndown on playback precisely to enable the investigator to understand better the \nextremely rapid succession of causal interactions between the bullet and the material \non which it impacts. A simulation should, if anything, be described as a kind of \n\u2018supermodel\u2019.  \n It is worth pursuing this point a little further because Rosen\u2019s claim about \nsimulation is couched in terms of the unhelpful distinction between efficient and \nmaterial causes which is a source of confusion rather than clarification. Suppose we \nwere to construct a simulation of the impact of a bullet on a sheet of glass. To do this \nwe would need, inter alia, to construct a simulation of the bullet, a simulation of the \nsheet of glass and a simulation of the dynamic relations between them. One obvious \nway to do this would be by constructing symbolic representations of the terms of the \nsimulation in a computer program. Thus the bullet might be represented as an array of \nquantities which collectively simulate its shape, mass, density, velocity and so forth \n 18\nand the glass might be represented as a lattice or similar regular structure. It is this \nprocess of translating into software the causally active components of the hardware \nsystem represented in the simulation that Rosen refers to as the conversion of efficient \ncause into material cause. It should immediately be clear that whether or not one can \nlearn anything about entailment in such a simulation depends not on the process of \nconversion but on whether one has chosen the correct aspects of the system to \nrepresent. A simulation which included only the name of the maker in the \nrepresentation of the bullet and the reflection of the external environment in the \nrepresentation of the glass would not be informative about the impact of the bullet on \nthe glass but a simulation which included detailed representations of the salient \ncharacteristics of the bullet and the glass and which modelled the changing dynamics \nof the relationship between them at a microsecond time scale might be extremely \ninformative. The quality of a simulation depends on the quality of the modelling on \nwhich it is based. It is simply incorrect to claim that the conversion of terms which a \nsimulation requires hides the entailment structures of the system simulated. \nPoint 2 of the argument is correct. There is a fundamental distinction between \nhardware and software, at least in computers that simulate. However, the distinction \ndoes not support the argument in the way that Rosen wishes to develop it in points 8 \nand 9.  \nPoints 3 and 4 of the argument inherit the deficiencies of point 1. They are \nalso rather strangely worded. One does not normally think of calling a system a \nmachine if and only if its models are of a particular kind. Rosen explains this curious \nusage in terms of Natural Law: \n \n 19\n\u2018[T]his peculiarity stems only from my expression of these concepts in terms \nof the models of N, rather than try to talk directly about N itself. This is all that \nNatural Law entitles us to do.\u2019 \n \n (Rosen 1991, p.203) \n \nThe point is interesting, not so much for what it tells us about the argument but for the \nfact that it is a further indication of the indirect realism which provides the foundation \nfor Rosen\u2019s epistemology. In his view we have to discuss natural systems in terms of \ntheir models because these are all that is directly available to us. \n Points 5, 6, and 7 are lemmas to the main argument. They are used to support \npoints 14 and 15. There are both general and specific comments to be made. The \nimportant general comment is that the arguments of points 5-7 rest on the discussion \nof models in chapter 6. I do not propose to go into the material of chapter 6 in great \ndetail but I think it is clear that it does not establish the fundamental claims about \nmodels that Rosen wants to make. The distinction between analytic and synthetic \nmodels that Rosen develops in Chapter 6 is based on equivalence relations over sets. \nAnalytic models are constructed in terms of Cartesian products and synthetic models \nin terms of direct sums of disjoint subsets. Rosen takes the analytic\/synthetic \ndistinction to be applicable to models of any kind, but it is not clear that the concept \nof an equivalence relation is a suitable tool for developing a generally applicable \ntypology of models or for exhibiting the relationship between a model and the system, \nnatural or formal, of which it is a model. In order for an equivalence relation to be \nspecified the elements of the set on which it is defined have to be known and it is \nprecisely this that is not generally known when a model of a natural system is being \n 20\ndeveloped. Rosen himself acknowledges this obvious disanalogy in his discussion of \nthe equivalence relations over a set S that he calls \u2018observables\u2019: \n \nI cannot emphasize too strongly that, in the formal world, S is already a \ndeterminate entity (in this case, a set), so that in general, looking at S as \nimaged in the spectrum f(S) of an observable inevitably \u201closes information\u201d \nabout S. In the case of a natural system, on the other hand, the counterpart of S \nis initially unknown, veiled completely in its noumenal and phenomenal \nshrouds. The whole purpose of measurement in this case is to provide \ninformation about it. \n (Rosen 1991, p.157) \n \nIt is hard to understand, given the above, why Rosen persists in using equivalence \nrelations over sets as the basis for his definition of types of models of natural systems. \nHe suggests on the page following the quotation just given that set theory provides \u2018a \nformidable battery of inferential structure\u2019 (p.158) to study a given set S but the \nvarious operations on a set, which include the generation of further sets, tell us about \nthe structure of the set not about the system which the set represents. Consider a \nsimple example to make the point clear. The Cartesian product of a set with itself, a \nstructure about which Rosen says a great deal, is the set of ordered pairs of its \nelements. Suppose, as a result of observation, we have developed a simple model of a \ncar in terms of the set CAR  = {body, wheels, engine, transmission}. This is a very \nsimple model but it is a start. The Cartesian product of the model, CAR \u00d7 CAR is the \nset of ordered pairs {(body, wheels), (body, engine), (body, transmission), (wheels, \n 21\nengine), (wheels, transmission), (engine, transmission)}. Does the Cartesian product \ntell us anything we didn\u2019t already know about the car? Rather clearly, the answer is \nno. The Cartesian product tells us something about the structure of the set but not \nabout the system of which the set is a model. The difficulty with Rosen\u2019s view is that \nhe assumes that the structures of sets like Cartesian products are somehow necessarily \ninformative about the models represented by the original sets. In general that is not \nthe case. In order to improve the model we need to make further observations of the \ncar, not engage in an analysis of the set that constitutes the original model.  \nThe more specific points to be made concern the status of the argument that \npurports to establish point 5, the claim that every machine has a unique largest model. \nThe argument in section 8C of Life Itself is faulty. It takes the form of a reductio ad \nabsurdum. Starting from the assumption that N is a mechanism but that the category \nof all its models C(N) contains no largest model, Rosen claims that we can find an \ninfinite sequence of increasingly refined models. Because N is a mechanism, all its \nmodels must be simulable and each of them must have a program of finite length. We \ncan then form the intersection of all the models and, by hypothesis, this is also a \nmodel. Unless the sequence of models terminates after a finite number of iterations, \nthe model formed from the intersection is larger than any of the other models. \nBecause it is simulable it must also have a program. The conclusion of the argument, \naccording to Rosen, is the following: \n \nWe thus end up with a countable family of distinct programs, each of which is \na distinct word of finite length on a finite alphabet. This is clearly impossible. \n \n (Rosen 1991, p.205) \n 22\n In fact it is perfectly possible. Thus even if the premises of the argument were correct, \nwhich is questionable, the conclusion would not follow. The decimal representations \nof the integers, for example, are the elements of a countably infinite set of distinct \nwords of finite length on a finite alphabet and integers are commonly used to \nrepresent programs. It is also always possible to extend a program without altering its \nfunctionality by adding new instructions which do nothing (cf. Rogers 1967, p.22, \nTheorem III ). This possibility contradicts the assertion that a machine must have a \nunique largest model. Given the failure of the argument for a largest model, the \nargument for a finite family of smallest models is of less interest because Rosen\u2019s \nargument requires both points 5 and 6. It is, however, pertinent to ask what is meant \nby a \u2018minimal\u2019 model. Various possibilities exist but it is hard to form a clear idea of \nwhat Rosen intended.  \n Points 8, 9, and 10 constitute the heart of the argument because they purport to \nshow that the distinction between hardware and software in machines entails the \nsegregation of causal factors which, ultimately, is the basis for the claim that \nmachines cannot contain closed loops of \u2018efficient\u2019 causation. There are two principal \nflaws in the argument. The first is the fact that, contrary to Rosen\u2019s view, machines \ncan and do have causal entailments flowing from software to hardware. There is no \nincompatibility between this fact and the fact that hardware and software are distinct \nparts of a machine. In consequence, there can be closed loops of entailment in \nmachines involving both hardware and software. Rosen is unable to see this because \nhe thinks of the partition between hardware and software as \u2018absolute\u2019 (cf section 9D, \np.228). The second flaw in Rosen\u2019s argument is that it simply fails to recognize the \npossibility that there can be direct causal links between the hardware components of a \n 23\nmachine, as well as links via software, and there is no reason why these links cannot \nform loops. Indeed, as I show in the discussion of Turing machines, it is of the \nessence of a Turing machine that there are such closed loops. I think the explanation \nfor Rosen\u2019s failure to see this is reasonably straightforward. In the argument presented \nin chapter 9 of Life Itself, Rosen treats hardware as whatever it is that executes a \nmapping from inputs to outputs. Given a simple function f : A \u00c6 B which Rosen \ntakes to represent a component of a machine,  f  constitutes the hardware which, as \nRosen puts it, induces the software flow from the input set A to the output set B. He is \nat pains to point out, in section 9B (p.222) that the hardware and the flows it induces \nare different things and that the essence of hardware is to generate flows (p.224). As a \nresult of this way of looking at things, when he comes to consider a system with more \nthan one component, (cf. Figure 9C.2, p.224) he assumes that all components are of \nthe same type and that the only function of the hardware is to induce flows on \nsoftware. He simply misses the possibility that there can be direct links between the \ndifferent hardware components representing other types of causal interaction than the \ngeneration of software flows. The kind of causal interaction needed can be described \nas a \u2018component-component\u2019 interaction. There is no argument in Life Itself to say \nthat such interactions cannot exist in machines and in fact they both can and do exist. \nThe combined effect of the two flaws is to make Rosen\u2019s picture of what can be done \nwith machines irretrievably narrow and limited. \n Points 11 to 18 of the argument depend entirely on the earlier points. They \ncontribute nothing extra. Since the earlier points do not in fact support the claims \nmade, the argument as a whole fails. The failure of the argument shows that machine \nmodels of organisms are perfectly possible but it also shows that Rosen\u2019s criterion, \nwhich claims that a material system is an organism if and only if it is closed to \n 24\nefficient causation, is invalid. Machines can be closed to efficient causation in just the \nsame way as organisms but are not organisms simply by virtue of that fact.  \nIt remains possible that Rosen\u2019s positive proposal, based on the concept of an \n(M,R)-system, provides a different criterion for distinguishing organisms from \nmachines. However, the description of an (M,R)-system in Life Itself is muddled and \ninconsistent and has been criticized by Landauer and Bellman (2002). In any case, the \ncrucial concept of self-replication was shown to be consistent with mechanistic \nhypotheses by John von Neumann as early as 1948. The entailment of replication by \nthe functions of metabolism and repair is, therefore, unlikely to distinguish organisms \nfrom machines. Rosen claims (p.234) that von Neumann\u2019s construction rests on an \nequivocation between software and hardware but that is not correct. Von Neumann\u2019s \ndiscussion of the logic of self-reproduction makes clear and consistent use of the \ndistinction between hardware and software. He shows that a machine can, in \nprinciple, reproduce itself if it has access to a store of elementary parts (hardware) and \ncontains a set of instructions (software) for its own construction which can be copied \nand passed to its clones. \n \nRosen\u2019s contradictory accounts of open systems \n \nThe argument of Life Itself is the major, but not the only source of Rosen\u2019s anti-\nmechanism. In Essays on Life Itself, a collection of papers written mainly after Life \nItself was published and brought to press by Rosen\u2019s daughter after his death, other \nrelated arguments can be found. One such type of argument concerns a distinction \nbetween simple and complex systems which Rosen used to argue for the fundamental \nseparation of organisms from machines. The argument is different in form from the \n 25\ncentral argument of Life Itself and is worth separate comment. It centres on the \nconcept of an open system and tackles the question of how open systems can be made \namenable to analytical study. Different versions of the argument appear in two \nchapters of Essays on Life Itself. They come to contradictory conclusions. \nIn Chapter 1 of Essays on Life Itself, Rosen discusses open systems in the \ncontext of Schr\u00f6dinger\u2019s famous essay What is Life? In the section of Chapter 1 \nentitled The Forcing of Open Systems Rosen defines an open system as follows: \n \nA system that is open in any sense is one whose behaviors depend on \nsomething outside the system itself, whereas in a closed system, there is no \noutside. \n \n Rosen (2000, p.21) \n \nRosen says that physics has typically had trouble in modelling open systems and that \none way to deal with them is to try to internalise the external influences so as to get a \nbigger system which is closed and to deal with that. However, he says, this strategy \ndoes not generally work: \n \nIndeed, what we end up with in this fashion is generally a bigger open system, \nwhich is in some sense even more open than the one we started with\u2026[W]hat \none typically ends up with after carrying out such a strategy is the entire \nuniverse, which is not very helpful. \n \n Rosen (2000, p.21-2) \n 26\n After some further discussion of other possibilities for augmenting open systems \nRosen concludes that the resulting models are still not generally stable and that further \nexpansions of the model to include more of the external forces acting on the system \nare needed. At this point, he says, \u2018we have a glimpse of an incipient infinite regress \nestablishing itself.\u2019 Rosen (2000, p.24). The regress can be avoided, Rosen says, if the \nforces internalised at stage N of an expansion process have already arisen at earlier \nstages. \n \nA source for such an Nth-stage internalised forcer is a mechanism for its \nreplication, expressed in terms of the preceding N-1 stages, and not requiring a \nnew N+1 stage. Thus replication is not just a formal means of breaking off a \ndevastating infinite regress, but it serves to stabilize the open system we \narrived at in the Nthstage. \n \n Rosen (2000, p.24) \n \nAt this point the crux of the argument has been reached. Rosen claims that the price to \nbe paid for escaping the infinite regress is that the systems thus arrived at are \ncomplex, non-computable and contain closed loops. \n \nBreaking off such an infinite regress does not come for free. For it to happen, \nthe graphs to which we have drawn attention, and which arise in successively \nmore complicated forms at each step of the process, must fold back on each \nother in unprecedented ways. In the process, we create (among other things) \n 27\nclosed loops of efficient causation. Systems of this type cannot be simulated \nby finite-state machines (e.g., Turing machines); hence they themselves are \nnot machines or mechanisms. In formal terms, they manifest impredicative \nloops. I call these systems complex. \n \n Rosen (2000, p.24) \n \nThe particular point to notice is the claim that it is the process of breaking off the \ninfinite regress of system expansions which generates complex systems.  \nThe argument in chapter 1 contradicts and is contradicted by another of \nRosen\u2019s arguments in chapter 20 of Essays on Life Itself. In chapter 20 Rosen \ndiscusses the differences between therapeutic interventions in medicine and control \nengineering. His target is the idea that an organism is a biological machine. If this \nwere so, he says, we would expect therapies to have few or no side effects whereas in \npractice side effects are the rule. To explain why this is the case Rosen constructs an \nargument which uses temperature control as an example. A room without temperature \ncontrol is an instance of an open system. If the room is large the temperature may \nappear to be constant, but it will eventually change \u2018because the room is open to \nambient influences we do not see directly.\u2019 Rosen (2000, p.299). A first level of \ncontrol over the room temperature can be achieved by installing a thermostat. \nHowever, in order to close the room to the effects of changes in the ambient \ntemperature in this way, the system as a whole has had to be enlarged.  \n \nThe thermostat itself is new material structure, which we have had to bring \ninto the system to control the effects of unpredictable temperature fluctuations. \n 28\nThe thermostat closes the room off to ambient temperature, but it itself is now \nopen to other interactions\u2014i.e., to new sources of noise. For instance, parts of \nit may corrode because of humidity and oxygen in the air in our room\u2026[W]e \nmay indeed end up with more noise than we had originally. \n \n Rosen (2000, pp.300-301) \n \nNotice the strong parallel here with the first example. In each case, the effect of \ninternalising a source of noise or openness is to produce, potentially, a more open or \nnoisier system. Rosen again explores the possibility of further expansions of the \nsystem to bring the new sources of noise under control and again the possibility of an \ninfinite regress is noted: \n \nEven in this simple example, we see an incipient and deadly infinite regress \nyawning before us\u2026The real question arising here is whether, and if so, when, \nthis potential infinite regress can be broken off. \n \n Rosen (2000, p.301) \n \nAs with the first example, Rosen says that the regress can be broken off if the system \ncan be turned back on itself. \n \n[I]t is conceivable that such a potential infinite regress actually breaks off. It \nwill do so if, and only if, we can arrange matters so that the noise arising at the \nNth step of this sequence produces consequences that are subject to controls \n 29\ninstituted at earlier stages. In such a case, the sequence breaks off at the Nth \nstage. \n \n Rosen (2000, p.303) \n \nRosen notes that the example of the thermostatically controlled room is characterised \nby a single state variable but says that the analysis can be generalised to deal with any \nfinite number of state variables. \n \nThe analysis, of course, grows increasingly complicated, but, in effect, we \nnow have a much larger family of cascading control loops, each of which \ncreates the potentiality for infinite regress. \n \n Rosen (2000, p.303) \n \nThe crux of the argument has again been reached. In the earlier example Rosen \nclaimed that the price to be paid for breaking off the infinite regress was that the \nresulting systems were complex. In the latter example, however, he reaches the \nopposite conclusion: \n \n[I]f every such cascade breaks off after a finite number of steps, then the \nsystem itself, and its environment, must both be simple. Conversely, if a \nsystem (or its environment) is not simple, then there must be at least one \ncascade of simple controls that does not break off\u2026A system that is not \nsimple in this sense (i.e., is not a mechanism) I call complex. \n 30\n  Rosen (2000, p.304) \n \nTo drive home the point, a little later in the chapter Rosen argues that \u2018[t]here is a \nsense in which complex systems are infinitely open\u2019 Rosen (2000, p.307) and it is for \nthis reason, he claims, that side effects are the norm rather than the exception in \nmedical interventions.  \n The contradictory nature of the two arguments cited is perfectly clear. In one \ncase Rosen argues that the existence of a break point that prevents an infinite regress \nof system openings leads to complex systems, in the other he argues that the break \npoint leads to simple systems. In one case he argues that complexity is the result of \nsystem closure, in the other that complex systems are \u2018infinitely open\u2019. The core \nproblem is that the distinctions he wants to insist on, between organisms and \nmachines, and between simple and complex systems are not to be had on his terms. \nBoth organisms and machines are systems with closed causal loops and the distinction \nbetween complex and simple systems, if there is one, does not demarcate organisms \nfrom other machines. \n \nRosen\u2019s subordinate arguments  \n \nLife Itself and Essays on Life Itself also contain subordinate arguments which deserve \nmention. An argument which is largely implicit in Life Itself but which is given \ngreater prominence in Essays on Life Itself claims that machines cannot contain closed \ncausal loops because such loops are \u2018impredicative\u2019 and are forbidden in formal \n 31\nsystems such as Turing\u2019s. One instance of this argument, from Rosen\u2019s \nautobiographical sketch, was mentioned in the introduction. Here is another: \n \nImpredicativity\u2026was identified as the culprit in the paradoxes springing up in \nSet Theory. Something was impredicative\u2026if it could be defined only in \nterms of a totality to which it itself had to belong\u2026Formalizations are simple \nsystems (in my sense) and, in particular, cannot manifest impredicativities or \nself-references or \u201cvicious circles\u201d. This is precisely why such a simple world \nseemed to provide a mathematical Eden, inherently free from paradox and \ninconsistency. Alas, as G\u00f6del showed, it was also free of most of mathematics. \nWe cannot dispense with impredicativity without simultaneously losing most \nof what we want to preserve. \n \n (Rosen 2000, pp.293-4)  \n \nThere are several flaws in this argument. One is the implicit claim that all closed \nloops are impredicative. They are not: the closed loops in the finite state control \nautomata of Turing machines are not necessarily defined impredicatively although \nthey may be. Thus, closed causal loops could be found in machines even if \nimpredicative loops were forbidden. Another is the claim that formalizations cannot \nmanifest self-references. They both can and do. The recursive definitions that Turing \nused in the construction of his universal machine are frequently self-referential. Third, \nit is misleading to suggest that impredicativity was identified as the culprit in the \nparadoxes identified in set theory. It is true that Bertrand Russell thought it to be the \nsource of the problem, at least with respect to the paradox that he devised, but it has \n 32\nbeen clear since the analysis of G\u00f6del (1944) that impredicative properties are \ntroublesome only under very special circumstances. The idea, therefore, that abstract \nmachines such as Turing machines cannot exhibit closed causal loops because these \nare always impredicative and hence forbidden is mistaken. \n A second argument, related to the first, is the claim that machines are, as \nRosen puts it, \u2018non-generic\u2019, exceptionally rare, and feeble in their entailment \nstructures. The point is hinted at in the quote above with the idea that formalization \nloses most of what is needed from mathematics and that formalizations cannot \n\u2018manifest\u2019 impredicative loops. In another passage from Essays on Life Itself Rosen \nsums up his view of the attempts at formalization which he attributes to Hilbert\u2019s \nprogram: \n \nThe status of all these formalizations is informative. They turn out to be \ninfinitely feeble compared with the original mathematical systems they \nattempted to objectivize. Indeed, these attempts to secure mathematics from \nparadox by invoking contructibility, or formalizability, end up by losing most \nof it. This is one of the upshots of G\u00f6del\u2019s celebrated Incompleteness Theorem \n(G\u00f6del 1931), which showed precisely that \u201cself-referential\u201d statements (e.g., \n\u201cthis proposition is unprovable in a given formalization\u201d), which are perfectly \nacceptable in the context of ordinary Number Theory, fall outside that \nformalization. \n \n (Rosen 2000, p.92) \n \n 33\nOne claim that Rosen seems to be making in this quotation is that self-referential \nstatements cannot be constructed, and hence are not expressible, in formal systems. \nThat appears to be the force of the suggestion that they \u2018fall outside\u2019 a formalization. \nThis shows a misunderstanding of what G\u00f6del achieved. The point that G\u00f6del made \nwas not that you can\u2019t express or construct a self-referential statement in a formal \nsystem. It was precisely the opposite. G\u00f6del showed that you could construct a self-\nreferential statement as a well-formed formula of any formal system powerful enough \nto contain arithmetic. In the sketch of his proof at the start of the famous 1931 paper, \nhaving explained how formulas of Russell and Whitehead\u2019s system Principia \nMathematica could be used to express metamathematical notions, G\u00f6del went on to \nexplain that the proof rested on the construction of a specific proposition using the \nformalism of PM: \n \nWe now construct an undecidable proposition of the system PM, that is, a \nproposition A for which neither A nor not-A is provable. \n \n (G\u00f6del 1931, p.147) \n \nThe crucial point was that the undecidable proposition was both syntactically well-\nformed and asserted its own unprovability. From this G\u00f6del showed that if the formal \nsystem containing the proposition was consistent the proposition had to be true and \nhence unreachable by a finite sequence of inferences from the axioms. Thus the \nformal system was incomplete. The proof rests on a fundamental distinction between \nconstructibility and provability which Rosen seems not to have fully grasped. A short \nbut telling passage from Life Itself supports this suggestion: \n 34\n [G]iven any finite set of axioms for Number Theory, there are always \npropositions that are in some sense theorems but are unprovable from those \naxioms (unless, of course, the axioms are inconsistent to begin with\u2014in which \ncase everything is a theorem). \n \n (Rosen 1991, p.35) \n \nThe crucial point, which Rosen explicitly fudges, is that unprovable propositions are \nnot theorems in any sense. They are syntactically well-formed formulas but they \ncannot be reached by finite sets of inferences from the axioms. It is precisely this \npoint that distinguishes constructible, but unprovable, propositions from theorems of \nthe system. To say, therefore, that unprovable propositions are \u2018in some sense\u2019 \ntheorems clouds exactly the distinction that needs to be kept clear. The distinction \nbetween constructibility and provability undermines the claim that closed or \nimpredicative loops cannot be expressed in formal systems. \nA second point which Rosen makes is that formalizations are in some sense \n\u2018infinitely feeble\u2019. Rosen repeatedly asserts that mechanisms are a vanishingly small \nproportion of mathematical systems. The assertion rests, I think, on the distinction \nbetween countable and uncountable infinities. This distinction was originally made by \nthe mathematician Georg Cantor in the late nineteenth century. Cantor showed, using \nthe technique of diagonalization, that, in a strictly definable sense, there are infinitely \nmany more real numbers than natural numbers even though there are infinitely many \nof these. The natural numbers are countably infinite but the real numbers are \nuncountably infinite. Turing machines can be paired one for one with the natural \n 35\nnumbers and this shows that there are countably, infinitely many of them. In \ncomparison with the uncountably infinite number of real numbers the Turing \nmachines can be said to be a vanishingly small proportion of mathematical systems \nIt is very hard, however, to know what to make of the distinction between \ncountable and uncountable infinities because the sizes, even of countably infinite \ncollections, violate our everyday intuitions about collections of things. If one thinks, \nfor example, about natural numbers, it seems to common sense that the totality of \nthem can be divided into two halves, the odd numbers and the even ones. For any \nfinite totality which is divisible into two halves, each half clearly has half as many \nmembers as the totality. If I have five green apples and five red ones I have ten apples \nin total with the green apples forming half the totality and the red ones the other half. \nBy the same token, because there are n odd numbers and n even numbers, there \nshould be 2n natural numbers in total. But it isn\u2019t so. Infinite totalities don\u2019t work like \nthat. There are exactly as many odd numbers as there are natural numbers and exactly \nas many even ones. Countably infinite totalities are all of the same size even though \nthey appear to common sense to have different numbers of elements. Given this, it is \nvery hard to know what follows from the fact that countable infinities are infinitely \nsmall compared with uncountable ones even though there is a clear mathematical \nsense in which this is so. What Rosen is suggesting seems to rely on combining this \npoint with the supposed exclusion of closed loops from the world of machines. Look, \nhe says, the collection of machines is infinitely small by comparison with the \ncollection of real numbers. Moreover, there are no closed loops in the collection of \nmachines. Thus this collection must be infinitely feeble in the properties it can \nexpress. If it really were the case that there were no closed loops in machines the \nargument might have some force. As it is, we have infinitely many machines with as \n 36\nmany closed loops as we care to define. That is a perfectly satisfactory foundation on \nwhich to construct a mathematical account of biological,  and for that matter \npsychological, systems. \n \nCausal loops in Turing machines \n \nThe principal line of defence to Rosen\u2019s anti-mechanist claim does not depend on the \nfact that Rosen\u2019s arguments about open systems are contradictory or that the central \nargument of Life Itself is unsound. The principal defence of mechanism rests on the \ndemonstration that Turing machines, which underpin mathematical and computational \nthinking about mechanisms, contain closed causal loops. This demonstration falsifies \nRosen\u2019s fundamental claim. A Turing machine is an abstract entity but one that could \nperfectly well be built. In this section I provide a very brief introduction to Turing \nmachines focused on the issue of closed loops. A full account of Turing\u2019s work and its \nplace in psychology can be found in Wells (2006). Readers are also encouraged to \nstudy Turing (1936), the seminal paper in which Turing set out his theory.  \n A Turing machine is a model of a human agent engaged in a paper and pencil \ncalculation. This simple fact is not often mentioned in psychological discussions of \ncomputational models but it is of great significance and bears consideration by \necological psychologists. I shall take a few moments to comment on it in the light of \nRosen\u2019s epistemology which constitutes the framework for his objections to machine \nmodels. Rosen says, as reported in the overview, that the primary feature of natural \nlaw is to bring systems of causal entailment in the external world into correspondence \nwith systems of inferential entailment in the inner world of the self. He also made the \nimportant point that one could start from either side. Starting from the external world \n 37\nthe primary entity is a natural system whose causal entailments one attempts to \ndiscover and model in formal terms. Starting from the internal side, the primary entity \nis a formal system for whose inferential entailments one attempts to find a matching \nnatural system. One of Rosen\u2019s principal objections to the machine metaphor, \nparticularly in the form in which it was inherited from Descartes, was precisely that it \nstarted from a formal model and attempted to force the phenomena of life to fit that \nmodel. Even worse, the Cartesian machine metaphor was incompletely specified. \nNear the beginning of Life Itself in a discussion of Descartes, Rosen says of him: \n \nWhat he had observed was simply that automata, under appropriate conditions, \ncan sometimes appear lifelike. What he concluded was, rather, that life itself \nwas automaton-like. Thus was born the machine metaphor, perhaps the major \nconceptual force in biology, even today. Descartes took this fateful step with \nonly the haziest notion of what a mechanism or automaton was (Newton was \nstill a generation away), and an even dimmer notion of what an organism was. \n \n (Rosen 1991, p.20) \n \nIt appears from what Rosen says later in the book that, at the time of writing it, he felt \nthere was still no canonical machine model on which to base his assessment. At the \nstart of chapter 7, for example, he refers to \u2018the vague concept of machine\u2019 (p.182) \nand although he refers to Turing in that chapter he does so in a way that suggests he \nwas unaware of the derivation of Turing\u2019s machine model from the example of a \nhuman calculating with paper and pencil. Had he been aware of this derivation he \nwould hardly have claimed as he did (p.185) that Turing machines are the formal \n 38\ncounterparts of clockwork, i.e. the machinery that drives the hands of a clock, and he \nwould also hardly have claimed that his quasi-Newtonian definition of an algorithm in \nsection 7C of Life Itself  \u2018is essentially a Turing machine\u2019 (p.189). Neither of these \nclaims is accurate. It is a great pity that Rosen was unaware of the origins of Turing\u2019s \nmodeling enterprise because Turing machines are exactly the kinds of models that \nRosen proposes are needed to embody natural law. Turing began by observing the \nnatural system of causal relations that is involved in a paper and pencil computation. \nFrom this he abstracted what he felt were the essential components and used these to \nconstruct his formal model. He was then able to use the model in the way Rosen says \nthat models should be used, to reflect on and reason about causal relations in the \nnatural system modelled. One important result was the construction of the universal \nmachine, which is a simulator par excellence. What the universal machine shows is \nnot, as Rosen asserts, that simulation hides the details of the modelled system from \nthe observer. Quite the contrary: a simulation makes available in an explicit symbolic \nformat the details of the entailment structures that the model expresses. Turing\u2019s \nuniversal machine also demonstrates why symbolic notations are so important for \nalmost all systematic human activities. Among other important characteristics they \nmake available, in forms that do not have to be remembered, structures of inferential \nentailment that model causal relations in the external world that we find useful or \npleasing or both. \nThe Turing machine has two primary components, a finite control automaton, \nwhich is a model of the mind of the human, and a one-dimensional tape which is a \nmodel of the paper on which a human writes out a calculation. For present purposes, \nthe structure of the finite control automaton is of particular importance. Closed causal \nloops are most evident there although they are also found in the dynamic relationship \n 39\nbetween the automaton and the tape. Turing machines were originally devised to \nexplore the issue of effectiveness in calculation and the numbers they can compute, \nwhich are called the computable numbers, are a subset of the real numbers and \ninclude irrational numbers like \u03c0 which have infinite decimal expansions. The \nopening sentence of Turing\u2019s paper makes a point which is of fundamental \nimportance in the present context. He said: \n \nThe \u201ccomputable\u201d numbers may be described briefly as the real numbers \nwhose expressions as a decimal are calculable by finite means. \n \n (Turing 1936, p.230) \n \nThe point to note is that computable numbers like \u03c0 which have indefinitely long \ndecimal expansions are nevertheless said to be calculable by \u2018finite means\u2019. What this \nmeans is that a finite structure or set of resources, the control automaton, which is \ndefined in advance of the calculation is sufficient to produce the endless sequence of \ndigits representing a number like \u03c0. The way this is done, and has to be done, is to \nbuild the finite control structure with components connected in loops whose \nprocessing can be iterated as many times as necessary. It is thus of the essence of a \nTuring machine that its fixed processing resources are structured as one or more \nclosed loops. It is precisely because this is so that infinite sequences can be produced \nby finite means. Let us consider three examples briefly. Much more extensive \ndiscussion can be found in Wells (2006). \n The first example is one of the simplest Turing machines imaginable. It was \ndefined by Turing in his 1936 paper and outputs the endless sequence 010101\u2026I shall \n 40\ncall the machine TM1. The finite control automaton of TM1 has four internal states, \nwhich we can call q1, q2, q3 and q4. These, collectively, can be described as a set Q = \n{q1, q2, q3, q4}. Internal states describe the causal relations among the parts of a \nTuring machine in an abstract way. The concept of state, as it is defined and used in \nTuring machine theory, is very different from the concept of state used by Rosen in \nLife Itself. In Turing machine theory states are relational entities, the sorts of things \nthat Rosen calls \u2018components\u2019 in Chapter 5 of Life Itself. The operations of TM1 are \ndescribed by two functions, each of which takes the \u2018configurations\u2019 of TM1 as its \narguments. A configuration is an ordered pair consisting of an internal state and an \ninput. One function determines the next state of TM1, the other its output. The next \nstate function is more important for present purposes. This function is a map from Q \nto Q and is implemented as a closed loop of entailments. The starting state of the \nmachine is q1: q1 entails q2, q2 entails q3, q3 entails q4 and q4 entails q1.  Once \nstarted, the machine cycles endlessly through this processing loop. It is precisely \nbecause the four internal states of its control automaton are structured as a closed loop \nthat the fixed, finite machine TM1 can output the infinitely long sequence 010101\u2026 \nTM1 provides a definitive and conclusive rebuttal of Rosen\u2019s lengthy and complex \nargument in Life Itself. TM1 is a machine and it has a closed causal loop of the kind \nthat Rosen says machines cannot have. The causal relations between the states which \nimplement the loop are of the type that I described as component-component \ninteractions in the discussion of points 8 \u2013 10 of Rosen\u2019s argument from Life Itself. \nTM1, by itself, is quite sufficient to rebut Rosen\u2019s argument but it is worth \nconsidering briefly two more examples. The first is a machine used to illustrate the \nargument made by Wells (2002) that the configurations of Turing machines provide \nnatural and informative models of Gibsonian affordances. The machine is called HP \n 41\nand is described in detail in Wells (2002, pp.163-7). Like TM1, HP has four internal \nstates, but whereas TM1 has a single closed loop connecting its states, HP has six \nclosed loops. In addition, it also makes use of closed loops connecting its internal \nstates with symbol structures on its tape, which is its environment. This is not a \nfeature of TM1. Most Turing machines are like HP in this respect, however, and it is \npartly because these machines have causal loops connecting their internal states to \ntheir environments that they are potentially of such interest and importance to \necological psychology. \n Finally, it is worth remarking that universal Turing machines, the abstract \nancestors of contemporary digital computers, exhibit complex patterns of closed loops \nto implement their processing. It is not possible to construct a universal machine \nwhich does not have such loops and they involve both hardware and software. Thus it \nis of the essence of Turing machines, in general, that they contain closed causal loops.  \n \nRosen and ecological psychology \n \nRosen\u2019s principal concern in Life Itself and in Essays on Life Itself was fundamental \ntheory in biology and he says relatively little which is specific to psychology. The \ngeneral thrust of his theorizing, however, appears to be antithetical to the interests and \nmotivations of ecological psychology. His epistemology, as the overview shows, \nassumes a strong form of indirect realism. He also used the (untenable) distinction \nbetween simple and complex systems to rule out at least some of the methods that \nhave been discussed favourably in the ecological psychology literature and his \nemphasis on the importance of closed loops of causation within the organism \ndownplays the significance of the environment. \n 42\n Organisms and environments \n \nRosen\u2019s epistemology is concerned with the sources of answers to \u2018why\u2019 questions \nabout systems of various kinds. He perceives a spectrum of possibilities. At one \nextreme are systems with components about which \u2018why\u2019 questions can be answered \nonly by reference to the environment within which the system is embedded. \nAccording to his view, mechanisms are systems of this kind: \n \nMost of the \u201cwhy?\u201d questions we can ask about such a system are \nunanswerable within the system, and therefore, must be referred to its \nenvironment. Put another way: most elements of an abstract block diagram \narising from a mechanism are unentailed. \n \n (Rosen 1991, pp. 248-9) \n \nRosen\u2019s view is that organisms lie at the other end of the spectrum. It is generally, he \nclaims, possible to answer \u2018why\u2019 questions about organisms from within the organism \nwithout the need to make reference to the environment: \n \nMy claim is that organisms lie at the other extreme as far as entailment is \nconcerned. Their abstract block diagrams manifest maximal entailment; in \nparticular, if f denotes a component of such a system, the question \u201cwhy f ?\u201d \nhas an answer, in terms of efficient causation, within the system. \n \n 43\n (Rosen 1991, p. 249) \n \nSetting aside for the sake of the discussion the fact that the distinction between \nmechanisms and organisms doesn\u2019t hold for the reasons discussed earlier, it is \ncurious, given Rosen\u2019s view of organisms as essentially self-contained systems, that \necological psychologists should view his work favourably. As the quotations show, \nRosen\u2019s view implies that organisms can be understood as largely independent of \ntheir environments whereas it is a fundamental principle of ecological psychology that \norganisms and their environments exist in relationships of mutuality and reciprocity \nand that each has to be understood in terms of the other. This has always been a clear \nfeature of Gibson\u2019s work: \n \nThe fact is worth remembering because it is so often neglected that the words \nanimal and environment make an inseparable pair. Each term implies the \nother. No animal could exist without an environment surrounding it. Equally, \nalthough not so obvious, an environment implies an animal (or at least an \norganism) to be surrounded. \n \n (Gibson 1979\/1986, p. 8) \n \nThe reciprocity of animals and environments implies that perception involves causal \nloops connecting the animal to the environment. Gibson was very clear about this \nwhen he developed the concept of a perceptual system: \n \n 44\nInstead of looking to the brain alone for an explanation of constant perception, \nit should be sought in the neural loops of an active perceptual system that \nincludes the adjustments of the perceptual organ. Instead of supposing that the \nbrain constructs or computes the objective information from a kaleidoscopic \ninflow of sensations, we may suppose that the orienting of the organs of \nperception is governed by the brain so that the whole system of input and \noutput resonates to the external information. \n \n (Gibson 1966, p.5) \n \nRosen, by contrast, viewed the relation between organism and environment in the \nclassical representationalist sense that ecological psychologists reject. He also, as \nreported earlier, specifically endorses the traditional view of perception as indirect: \n \nAs philosophers have pointed out for millennia, all we perceive directly are \nour selves, together with sensations and impressions that we normally interpret \nas coming from \u201coutside\u201d (i.e., from the ambience), and that we merely \nimpute, as properties and predicates, to things in that ambience. The things in \nthemselves, the noumena, as Kant calls them, are inherently unknowable \nexcept through the perceptions they elicit in us; what we observe are \nphenomena, which are to an equally unknowable extent corrupted by our \nperceptual apparatus itself (which of course also sits partly in the ambience). \n \n Rosen (1991, p.56) \n \n 45\nOne further corollary of Rosen\u2019s emphasis on the organism as an essentially self-\nexplanatory system, all of whose \u2018why\u2019 questions have intra-systemic answers, is a \ndenial of the value of evolutionary explanation.  \n \nTo me, it is easy to conceive of life, and hence biology, without evolution. But \nnot of evolution without life. Thus, evolution is a corollary of the living, the \nconsequence of specialized somatic activities, and not the other way \naround\u2026biology is wrapped up with soma and how it operates; thus we \ncannot invoke evolution as an explanatory or causal principle for these \npurposes. \n \n (Rosen 1991, p. 255) \n \nOnce again the contrast with Gibson\u2019s views is striking. The facts of evolution came \nto play a central part in the development of his ecological theory of visual perception. \n \n[T]he fact of information in the light falling upon an organism, is the situation \nto which animals have adapted in the evolution of ocular systems. The visual \norgans of the spider, the bee, the octopus, the rabbit, and man are so different \nfrom one another that it is a question whether they should all be called eyes, \nbut they share in common the ability to perceive certain features of the \nsurrounding world when it is illuminated. The realization that eyes have \nevolved to permit perception, not to induce sensations, is the clue to a new \nunderstanding of human vision itself. \n \n 46\n (Gibson 1966, p.155) \n \nMethodological issues. \n \nOne of the consequences of Rosen\u2019s mistaken supposition that machines cannot \nexhibit closed causal loops was the distinction between what he called simple and \ncomplex systems. All mechanisms and all systems that could be simulated on \ncomputers were said to be simple. A system was complex if, and only if, it had non-\ncomputable models. This claim, alone, has a consequence that ought to make \necological psychologists wary of Rosen\u2019s work. The consequence is that dynamical \nsystems theory is an inadequate theoretical basis for the study of living systems. The \nreason for this is that it is based on computable equations. Rosen was quite clear about \nits insufficiency: \n \n[T]o assert that organisms, or human systems, are thus complex, is a radical \nthing to do. For one thing, it says that differential equations, and systems of \ndifferential equations (i.e. dynamical systems), which are inherently simulable, \nmiss most of the reality of a complex system\u2026just as any attempt to \nformalize, for example, Number Theory misses most of its theorems. \n \n (Rosen 2000, p.325) \n \nMany ecological psychologists believe that dynamical systems theory offers a \nparticularly useful set of tools for studying the complex interplay of organismic and \nenvironmental variables that characterizes human situated activity. If Rosen were \n 47\ncorrect, this belief would be erroneous. I should perhaps add that the claim made by \nsome proponents of dynamical systems theory, for example Port and van Gelder \n(1995), that dynamical systems approaches are an alternative to computational ones is \nalso a mistake. Rosen was right about that. \n \nConclusion \n \nThe anti-mechanist arguments of Robert Rosen have been used by some ecological \npsychologists to support an attack on computational methods and mechanist thinking \ngenerally. Close examination of Rosen\u2019s views shows that his epistemology assumes \na strong form of indirect realism and his arguments, if valid, would constitute a denial \nof some of the fundamental principles on which ecological psychology is based. \nHowever, his arguments are not valid and do not show that organisms have properties \nwhich cannot be captured by machine models. For me this is important because I \nbelieve that anti-mechanist thinking in contemporary ecological psychology is based \non a restricted view of the possible types of computational model and is acting as a \nbarrier to the development of a genuinely ecological form of computational \npsychology. Computational thinking in psychology need not, and should not, be tied \nto models derived from stored program, serial, digital computers. A genuine \nalternative, which is distinctively ecological, can be built on the foundations laid by \nTuring in his groundbreaking paper of 1936. In recognition of the striking parallels \nbetween Turing\u2019s work and Gibson\u2019s ecological approach I have suggested that the \nalternative approach should be called \u2018ecological functionalism\u2019 (Wells, 2006). Had \nRosen been aware of the possibilities which open up when one combines Turing\u2019s \naccount of inferential entailment in the world of machines with Gibson\u2019s account of \n 48\ncausal entailment in the ecological world I think he might have reconsidered his anti-\nmechanism. \n \nAcknowledgements \n \nI am grateful to Peter Kugler and Bob Shaw for their comments on the first version of \nthis paper. Among other points they persuaded me that a discussion of Rosen\u2019s \nphilosophy was needed rather than just a rebuttal of his arguments.  I am also grateful \nto Bill Mace for his editorial sagacity.  \n \nReferences \n \nGibson, J.J. (1966). The Senses Considered as Perceptual Systems. Boston, MA: \nHoughton Mifflin. \nGibson, J.J. (1986). The Ecological Approach to Visual Perception. Hillsdale, NJ: \nLawrence Erlbaum Associates, Inc. (Original work published 1979). \nG\u00f6del, K. (1931). On formally undecidable propositions of Principia Mathematica \nand related systems I. In Kurt G\u00f6del. Collected Works. Volume 1. Publications \n1929-1936. Oxford, UK: Oxford University Press, 144-195. \nG\u00f6del, K. (1944). Russell\u2019s mathematical logic. In Kurt G\u00f6del. Collected Works. \nVolume I1. Publications 1938-1974. Oxford, UK: Oxford University Press, \n119-141. \nHocutt, M., (1974). Aristotle\u2019s Four Becauses. Philosophy, 49, 385-99. \n 49\nLandauer, C. & Bellman, K.L. (2002). Theoretical Biology: Organisms and \nMechanisms. CP627, Computing Anticipatory Systems: CASYS 2001\u2014Fifth \nInternational Conference, 59-70. \nMoravscik, J.M.E., (1974). Aristotle on Adequate Explanations, Synthese, 28, 3-17. \nPort, R.F. & van Gelder, T. (1995). Mind as Motion. Explorations in the Dynamics of \nCognition. Cambridge, MA: MIT Press. \nRogers, H. Jr. (1967) Theory of Recursive Functions and Effective Computability. \nCambridge, MA: MIT Press. \nRosen, R. (1991). Life Itself. A Comprehensive Inquiry Into the Nature, Origin, and \nFabrication of Life. New York, NY: Columbia University Press. \nRosen, R. (2000). Essays on Life Itself. New York, NY: Columbia University Press. \nShaw, R.E. (2003). The Agent-Environment Interface: Simon\u2019s Indirect or Gibson\u2019s \nDirect Coupling? Ecological Psychology, 15(1), 37-106. \nTuring, A.M. (1936). On Computable Numbers with an application to the \nEntscheidungsproblem. Proceedings of the London Mathematical Society, \nSeries 2, 42, 230-265. \nTurvey, M.T. (2004). Impredicativity, dynamics, and the perception-action divide. In \nV.K. Jirsa & J.A.S. Kelso (eds), Coordination Dynamics: Issues and Trends. \nVol.1 Applied Complex Systems (pp. 1-20). New York: Springer Verlag. \nTurvey, M.T. & Shaw, R.E. (1995). Toward an Ecological Physics and a Physical \nPsychology. In R.L. Solso & D.W. Massaro (eds) The Science of the Mind: \n2001 and Beyond. New York, NY: Oxford University Press. \nWells, A.J. (2002). Gibson\u2019s Affordances and Turing\u2019s Theory of Computation. \nEcological Psychology, 14(3), 141-180 \n 50\nWells, A.J. (2006). Rethinking Cognitive Computation. Turing and the Science of the \nMind. Basingstoke, UK: Palgrave Macmillan. \n 51\n"}
{"doi":"10.1109\/TMI.2003.823261","coreId":"56305","oai":"oai:eprints.lincoln.ac.uk:1215","identifiers":["oai:eprints.lincoln.ac.uk:1215","10.1109\/TMI.2003.823261"],"title":"Optic nerve head segmentation","authors":["Lowell, J.","Hunter, Andrew","Steel, D.","Basu, A.","Ryder, R.","Fletcher, E.","Kennedy, L."],"enrichments":{"references":[{"id":18442280,"title":"A computer method of understanding ocular fundus images,\u201d","authors":[],"date":null,"doi":"10.1016\/0031-3203(82)90022-x","raw":"K. Akita and H. Kuga, \u201cA computer method of understanding ocular fundus images,\u201d Pattern Recognition., vol. 15, pp. 431\u2013 443, 1982.","cites":null},{"id":18442288,"title":"A fast, simple active contour algorithm for biomedical images,\u201d","authors":[],"date":"1996","doi":"10.1016\/0167-8655(96)00054-2","raw":"H. Eviatar and R.L. Somorjai, \u201cA fast, simple active contour algorithm for biomedical images,\u201d Pattern Recognition Letters, pp. 969\u2013974, 1996.","cites":null},{"id":18442291,"title":"Active Contours,","authors":[],"date":"1998","doi":"10.1007\/978-1-4471-1555-7","raw":"A. Blake and M. Isard, Active Contours, Springer, 1998.","cites":null},{"id":18442275,"title":"Automated grading of venous beading,\u201d","authors":[],"date":"1995","doi":"10.1006\/cbmr.1995.1020","raw":"P.H. Gregson, Z. Shen, R.C. Scott, and V. Kozousek, \u201cAutomated grading of venous beading,\u201d Computers and Biomedical Research, vol. 28, pp. 291\u2013304, 1995.","cites":null},{"id":18442281,"title":"Automated localisation of the optic disc, fovea, and retinal blood vessels from digital colour fundus images,\u201d","authors":[],"date":"1999","doi":"10.1136\/bjo.83.8.902","raw":"C. Sinthanayothin, J.A. Boyce, H.L. Cook, and T.H. Williamson, \u201cAutomated localisation of the optic disc, fovea, and retinal blood vessels from digital colour fundus images,\u201d Br J. Ophthalmol., vol. 83, pp. 902\u2013910, 1999.","cites":null},{"id":18442276,"title":"Automatic registration of digital ocular fundus images for comparison of lesions,\u201d","authors":[],"date":"1995","doi":"10.1117\/12.147517","raw":"M.H. Goldbaum, V. Kouznetsova, B.L. Cot\u00b4 e, W.E. Hart, and M. Nelson, \u201cAutomatic registration of digital ocular fundus images for comparison of lesions,\u201d SPIE 1877, Ophthalmic Technologies III, pp. 291\u2013304, 1995.","cites":null},{"id":18442273,"title":"Characterization of the neovascularization process in diabetic retinopathy by means of fractal geometry: diagnostic implications,\u201d","authors":[],"date":"1993","doi":"10.1007\/bf00919281","raw":"A. Daxer, \u201cCharacterization of the neovascularization process in diabetic retinopathy by means of fractal geometry: diagnostic implications,\u201d Graefe\u2019s Arch. Clin. Exp. Ophthalmol., vol. 231, pp. 681\u2013686, 1993.","cites":null},{"id":18442286,"title":"Deformable template models:","authors":[],"date":"1998","doi":"10.1016\/s0165-1684(98)00139-x","raw":"A.K. Jain, Y. Zhong, and M. Dubuisson-Jolly, \u201cDeformable template models: A review,\u201d Signal Processing, vol. 71, pp. 109\u2013129, 1998.","cites":null},{"id":18442268,"title":"Diabetes and the Eye,","authors":[],"date":"1999","doi":null,"raw":"E.M. Kohner, Diabetes and the Eye, Oxford Textbook of Ophthalmology Vol. 2, Oxford University Press, 1999.","cites":null},{"id":18442266,"title":"Digital fundus imaging using a scanning laser ophthalmoscope,\u201d","authors":[],"date":"1993","doi":"10.1088\/0967-3334\/14\/1\/006","raw":"A. Manivannan, P.F. Sharp, R.P. Phillips, and J.V. Forrester, \u201cDigital fundus imaging using a scanning laser ophthalmoscope,\u201d Physiol Meas, vol. 14, pp. 43\u201356, 1993.","cites":null},{"id":18442285,"title":"Dynamic 3d models with local and global deformations: deformable superquadrics,\u201d","authors":[],"date":"1991","doi":"10.1109\/iccv.1990.139605","raw":"D. Terzopoulos and D. Metaxas, \u201cDynamic 3d models with local and global deformations: deformable superquadrics,\u201d IEEE Trans. PAMI, vol. 13, pp. 703\u2013714, 1991.","cites":null},{"id":18442278,"title":"Extraction of the optic disc boundary in digital fundus images,\u201d in","authors":[],"date":"1999","doi":"10.1109\/iembs.1999.804304","raw":"F. Mendels, C. Heneghan, P.D. Harper, R.B. Reilly, and J-Ph. Thiran, \u201cExtraction of the optic disc boundary in digital fundus images,\u201d in Proc. 1st Joint BMES\/EMBS Conf., 1999, p. 1139.","cites":null},{"id":18442282,"title":"Fast and robust optic disc detection using pyramidal decomposition and hausdor\ufb00-based template matching,\u201d","authors":[],"date":"2001","doi":"10.1109\/42.963823","raw":"M. Lalonde, M. Beaulieu, and L. Gagnon, \u201cFast and robust optic disc detection using pyramidal decomposition and hausdor\ufb00-based template matching,\u201d IEEE Trans. Medical Imaging, vol. 20, pp. 1193\u20131200, 2001.","cites":null},{"id":18442270,"title":"Locating blood vessels in retinal images by piecewise threshold probing of a matched \ufb01lter response,\u201d","authors":[],"date":"2000","doi":"10.1109\/42.845178","raw":"A. Hoover, V. Kouznetsova, and M. Goldbaum, \u201cLocating blood vessels in retinal images by piecewise threshold probing of a matched \ufb01lter response,\u201d IEEE Transactions on Medical Imaging, vol. 19, pp. 203\u2013210, 2000.","cites":null},{"id":18442274,"title":"Measurement of vessel tortuosity on fundus photographs,\u201d","authors":[],"date":"1979","doi":"10.1007\/bf00414653","raw":"W. Lotmar, A. Freiburghaus, and D. Bracher, \u201cMeasurement of vessel tortuosity on fundus photographs,\u201d Graefe\u2019s Arch. Clin. Exp. Ophthalmol., vol. 211, pp. 49\u201357, 1979.","cites":null},{"id":18442293,"title":"Neural Networks for Pattern Recognition,","authors":[],"date":"1995","doi":"10.1145\/294828.1067910","raw":"C.M. Bishop, Neural Networks for Pattern Recognition, Clarendon Press, Oxford, 1995.","cites":null},{"id":18442292,"title":"Numerical Recipes in C,","authors":[],"date":"1992","doi":"10.1016\/s0003-2670(00)82860-3","raw":"W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery, Numerical Recipes in C, 1992.","cites":null},{"id":18442272,"title":"Progress towards automated diabetic ocular screening: a review of image analysis and intelligent systems for diabetic retinopathy,\u201d","authors":[],"date":"2002","doi":"10.1007\/bf02347689","raw":"T. Teng, M. Le\ufb02ey, and D. Claremont, \u201cProgress towards automated diabetic ocular screening: a review of image analysis and intelligent systems for diabetic retinopathy,\u201d Medical and Biological Engineering and Computing, vol. 40, pp. 2\u201313, 2002.","cites":null},{"id":18442287,"title":"Robust parametric active contours: the sandwich snakes,\u201d","authors":[],"date":"2001","doi":"10.1117\/12.323175","raw":"F.A. Velasco and J.L. Marroquin, \u201cRobust parametric active contours: the sandwich snakes,\u201d Machine Vision and Applications, vol. 12, pp. 238\u2013242, 2001.","cites":null},{"id":18442267,"title":"Screening for diabetic retinopathy.,\u201d","authors":[],"date":"1992","doi":null,"raw":"D.E. Singer, D.M. Nathan, H.A. Fogel, and A.P. Schachat, \u201cScreening for diabetic retinopathy.,\u201d Ann Intern Med, vol. 116, pp. 660\u201371, 1992.","cites":null},{"id":18442283,"title":"Snakes. active contour models,\u201d","authors":[],"date":"1987","doi":"10.1007\/bf00133570","raw":"M. Kass, A. Witkin, and D. Terzopoulos, \u201cSnakes. active contour models,\u201d Int. J. Comput. Vision, vol. 1, pp. 321\u2013331, 1987.","cites":null},{"id":18442279,"title":"Software for 3-d visualization\/analysis of optic-disc images,\u201d","authors":[],"date":"1999","doi":"10.1109\/51.740963","raw":"K. Yogesan, C.J. Barry, et al., \u201cSoftware for 3-d visualization\/analysis of optic-disc images,\u201d IEEE Engineering in Medicine and Biology, vol. 18, pp. 43\u201349, 1999.","cites":null},{"id":18442294,"title":"Variable neighbourhood search for geometrically deformable templates,\u201d in","authors":[],"date":"2002","doi":"10.1109\/icpr.2002.1048395","raw":"M. Lalonde and L. Gagnon, \u201cVariable neighbourhood search for geometrically deformable templates,\u201d in Proc. Int. Conf. Patt. Rec., Qu\u00b4 ebec, Canada, 2002, pp. 689\u2013692.","cites":null},{"id":18442290,"title":"Vessel boundary extraction based on a global and local deformable physical model with variable sti\ufb00ness,\u201d","authors":[],"date":"1998","doi":"10.1016\/s0730-725x(98)00105-2","raw":"Y-L. Hu, W.J. Rogers, D.A. Coast, C.M. Kramer, and N. Reichek, \u201cVessel boundary extraction based on a global and local deformable physical model with variable sti\ufb00ness,\u201d Magnetic Resonance Imaging, vol. 16, pp. 943\u2013951, 1998.","cites":null},{"id":18442289,"title":"Visual Monitoring of Glaucoma, Ph.d.,","authors":[],"date":"1991","doi":null,"raw":"S. Lee, Visual Monitoring of Glaucoma, Ph.d., Robotics Research Group Department of Engineering Science, University of Oxford, 1991, Available on micro-\ufb01che.","cites":null},{"id":18442277,"title":"Zur bestimmung der wahren grofsse eines objektes auf dem hintergrund des lebenden auges,\u201d Klin Monastbl Augenheilkd,","authors":[],"date":null,"doi":"10.1055\/s-2008-1055068","raw":"H. Littmann, \u201cZur bestimmung der wahren grofsse eines objektes auf dem hintergrund des lebenden auges,\u201d Klin Monastbl Augenheilkd, p. 180:286, 1982.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2004-02","abstract":"Reliable and efficient optic disk localization and segmentation are important tasks in automated retinal screening. General-purpose edge detection algorithms often fail to segment the optic disk due to fuzzy boundaries, inconsistent image contrast or missing edge features. This paper presents an algorithm for the localization and segmentation of the optic nerve head boundary in low-resolution images (about 20 \/spl mu\/\/pixel). Optic disk localization is achieved using specialized template matching, and segmentation by a deformable contour model. The latter uses a global elliptical model and a local deformable model with variable edge-strength dependent stiffness. The algorithm is evaluated against a randomly selected database of 100 images from a diabetic screening programme. Ten images were classified as unusable; the others were of variable quality. The localization algorithm succeeded on all bar one usable image; the contour estimation algorithm was qualitatively assessed by an ophthalmologist as having Excellent-Fair performance in 83% of cases, and performs well even on blurred image","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/56305.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/1215\/1\/Lowell2004TMIOpticNerveHeadSegmentation.pdf","pdfHashValue":"2e153b498b756e0c6aed0c6d46c88dfd2bb6126b","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:1215<\/identifier><datestamp>\n      2013-03-13T08:25:49Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F47:6A6163735F47373430<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/1215\/<\/dc:relation><dc:title>\n        Optic nerve head segmentation<\/dc:title><dc:creator>\n        Lowell, J.<\/dc:creator><dc:creator>\n        Hunter, Andrew<\/dc:creator><dc:creator>\n        Steel, D.<\/dc:creator><dc:creator>\n        Basu, A.<\/dc:creator><dc:creator>\n        Ryder, R.<\/dc:creator><dc:creator>\n        Fletcher, E.<\/dc:creator><dc:creator>\n        Kennedy, L.<\/dc:creator><dc:subject>\n        G740 Computer Vision<\/dc:subject><dc:description>\n        Reliable and efficient optic disk localization and segmentation are important tasks in automated retinal screening. General-purpose edge detection algorithms often fail to segment the optic disk due to fuzzy boundaries, inconsistent image contrast or missing edge features. This paper presents an algorithm for the localization and segmentation of the optic nerve head boundary in low-resolution images (about 20 \/spl mu\/\/pixel). Optic disk localization is achieved using specialized template matching, and segmentation by a deformable contour model. The latter uses a global elliptical model and a local deformable model with variable edge-strength dependent stiffness. The algorithm is evaluated against a randomly selected database of 100 images from a diabetic screening programme. Ten images were classified as unusable; the others were of variable quality. The localization algorithm succeeded on all bar one usable image; the contour estimation algorithm was qualitatively assessed by an ophthalmologist as having Excellent-Fair performance in 83% of cases, and performs well even on blurred images<\/dc:description><dc:date>\n        2004-02<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/1215\/1\/Lowell2004TMIOpticNerveHeadSegmentation.pdf<\/dc:identifier><dc:identifier>\n          Lowell, J. and Hunter, Andrew and Steel, D. and Basu, A. and Ryder, R. and Fletcher, E. and Kennedy, L.  (2004) Optic nerve head segmentation.  Medical Imaging, IEEE Transactions on, 23  (2).   pp. 256-264.  ISSN UNSPECIFIED  <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/TMI.2003.823261<\/dc:relation><dc:relation>\n        10.1109\/TMI.2003.823261<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/1215\/","http:\/\/dx.doi.org\/10.1109\/TMI.2003.823261","10.1109\/TMI.2003.823261"],"year":2004,"topics":["G740 Computer Vision"],"subject":["Article","PeerReviewed"],"fullText":"1Optic Nerve Head Segmentation\nJames Lowell Andrew Hunter David Steel Ansu Basu Robert Ryder Eric Fletcher\nAbstract\u2014 Reliable and efficient optic disk localization\nand segmentation are important tasks in automated retinal\nscreening. General-purpose edge detection algorithms often\nfail to segment the optic disk due to fuzzy boundaries, incon-\nsistent image contrast or missing edge features. This paper\npresents an algorithm for the localization and segmentation\nof the optic nerve head boundary in low-resolution images\n(about 20\u00b5 per pixel). Optic disk localization is achieved\nusing specialized template matching, and segmentation by\na deformable contour model. The latter uses a global el-\nliptical model and a local deformable model with variable\nedge-strength dependent stiffness. The algorithm is eval-\nuated against a randomly-selected database of 100 images\nfrom a diabetic screening programme. Ten images were clas-\nsified as unusable; the others were of highly variable quality.\nThe localization algorithm succeeded on all bar one usable\nimage; the contour estimation algorithm was qualitatively\nassessed by an ophthalmologist as having Excellent, Good\nor Fair performance in 83% of cases, and performs well even\non blurred images.\nKeywords\u2014Optic Nerve Head, Diabetic Retinopathy, Ac-\ntive Contours, Deformable Models\nI. Introduction\nTHIS paper presents an algorithm for the automatic lo-calization and segmentation of the optic nerve head\nin retinal images. No user intervention is required: the al-\ngorithm automatically selects the general location of the\ncenter of the optic nerve head, then fits a contour to the\noptic nerve head rim. Localization is achieved using a sim-\nple but effective specialized filter; segmentation by fitting\nan active contour to the optic nerve head rim using a spe-\ncialized three phase global and local deformable model that\nexploits the specific characteristics of the optic nerve head\u2019s\nappearance. We evaluate the algorithm against alternative\napproaches using a set of 100 random images drawn from\na diabetic screening programme, and present the results.\nA. Motivation\nThe algorithm presented in this paper forms one compo-\nnent of our system for automated detection and grading of\ndiabetic retinopathy, a common complication of diabetes\nmellitus and the leading cause of blindness in the working\npopulation of Western countries [1]. If appropriate treat-\nment is given in the early stages blindness can be prevented\nin at least 60% of cases. There is a clear case for screening,\nand recently the UK National Screening Committee have\nsuggested that annual screening by digital ocular fundal\nJ. Lowell and A. Hunter, Dept. Computer Science, University\nof Durham, Science Labs, South Rd., Durham, DH1 3LE, UK. an-\ndrew1.hunter@durham.ac.uk\nD. Steel, Sunderland Eye Infirmary, Queen Alexandra Road, Sun-\nderland, SR2 9HP\nA. Basu and R. Ryder, Dept. Diabetes and Endocrinology, City\nHospital, Dudley Rd., Birmingham, B18 7QH, UK\nE. Fletcher, Dept. Computer Science, University of Sunderland,\nTyne and Wear, UK.\nphotography is the preferred modality [2]. An expert hu-\nman screener grades the images; this is a time-consuming,\nhighly skilled task, susceptible to subjective variation and\nerror. There is consequently a pressing need for reliable\nautomated analysis of digitized fundal images.\nFeatures suggestive of retinopathy include: haemor-\nrhages and microaneurysms (dark spots); cotton wool spots\nand exudates (white spots); and vascular anomalies such as\nvenous beading and neovascularisation [3] [4]. These must\nbe detected against a highly variable background retinal\nimage that includes: the optic nerve head, the vascular\nnetwork, the macular, and distractors such as choroidal\nvessels, laser scars, light artifacts, and drusen. The vari-\nability of retinal appearance argues for a structured ap-\nproach [5], where significant landmarks in the retina are\nidentified, and the relationships between them exploited to\nincrease confidence in the classification of each object.\nOptic nerve head segmentation is a necessary step in this\nstructured analysis for a number of reasons. First, the op-\ntic nerve head can itself act as a distractor: it is a large\nbright region that can be mistaken (by algorithms) for gross\ncircinate exudation; the high-contrast rim also causes false\nresponses to linear blood vessel filters [5]. Second, the ves-\nsels radiate from the optic nerve head, so vessel tracking\nalgorithms [6] may start from there. Vessels are of direct\nimportance in assessing vascular condition [7] [8] [9], and\nare useful in image registration [10]. Third, the optic nerve\nhead is important in localization of the fovea, the central\npart of the retina that subserves fine vision. This lies at\nthe center of a larger area, the macula. Retinopathy in\nthis area, maculopathy, is associated with a high risk of\nvisual loss. The macular is a dark approximately circular\narea, but the contrast is often quite small, and it may be\nobscured by exudates or blurring. Consequently a global\ncorrelational search often fails. The fovea is located ap-\nproximately 2.5 disc diameters temporal to the temporal\nedge of the optic disc and between the major temporal\nretinal vascular arcades. These positional constraints can\nbe used to identify a small search area for the macular,\nand to estimate the position if the search fails, although\nvariation in the optic disk size compromises the reliability\nof this method. Littmann [11] has developed a technique\nto explicitly determine the distance from the disk center to\nthe fovea, by correcting for the magnification factors of the\nfundus camera and the patient\u2019s eye. However, the ocular\nmagnification factor depends mainly on anterior corneal\ncurvature, refraction and axial length, which require mea-\nsuring variables on the patient\u2019s eye \u2013 an important practi-\ncal limitation in screening. The method can also give false\nvalues in the case of an abnormally high lens refractive\npower (e.g. by cataract formation) and so is not applica-\nble in aphakic or pseudophacic eyes ( 10% of our diabetic\n2Optic Cup Neuroretinal Rim\nOptic Disk\n \nPallor\nNeuroretinal rim\nBlood vessels\nTemporal\nSide\nFig. 1. The Optic Nerve Head. a) Cross Section. b) A typical\nwell-defined disk.\nscreening population). The \u201c2.5 disk diameters\u201d heuris-\ntic method is therefore more practical for our application,\nparticularly as we do not require absolute accuracy.\nWe also note that segmentation of the optic nerve head\nis relevant to other diseases of the eye (e.g. glaucoma [12]\n[13]), but we do not consider these further in this paper.\nB. Optic Nerve Head Appearance\nSuccessful segmentation of the optic nerve head requires\na careful analysis of its appearance (see figure 1 ). It is the\nextremity of the optic nerve in the interior of the eye, and\nalso the entrance and exit site of the retinal vessels [14].\nThe shape is approximately elliptical, with a vertical prin-\ncipal axis (width 1.8\u00b10.2mm, height 1.9\u00b10.2mm) [15]. As\nthe nerve fibres reach the optic nerve head they turn and\nexit through the optic nerve, leaving a small depression\n(the \u201ccup\u201d) in the center of the nerve head. There is of-\nten a brighter central region, the \u201cpallor\u201d, which if present\nusually includes the cup. The optic disc rim is judged to\nbe the inner margin of the peripapillary scleral ring, seen\nas a thin white band encircling the optic disc.\nIn fundal images, the appearance varies quite substan-\ntially. The size and shape may vary significantly. The rim\nis usually visible as a bright boundary; the nasal side is\nusually less bright than the temporal side, and sometimes\nnot visible at all. In some images the entire optic nerve\nhead is brighter than the surrounding area, so that it ap-\npears as a disk; in others the appearance is of a hollow ring.\nIn either case the pallor may appear as a smaller, brighter\ndisk within the optic disk. There may also be bright areas\njust outside the rim caused by peripapillary atrophy, either\ndistorting the shape or forming concentric elliptical arcs.\nTo complicate the issue further, departing vessels par-\ntially obscure the rim. The majority climb out on the nasal\nsize and depart vertically; a smaller number depart nasally,\nwith only a few fine vessels on the temporal side. Some-\ntimes vessels turn at the nasal rim edge and run vertically,\nobscuring portions of the rim. A consequence of the nasal\ndistribution of vessels is that the pallor, if visible, is mainly\nlocated to the temporal side.\nThe variability in appearance misleads obvious ap-\nproaches. Large areas of circinate exudates, which have\nhigh contrast, act as strong distractors for correlation-\nbased localization algorithms \u2013 algorithms that work well\non images of healthy retina may fail on a screening pop-\nulation. Similar problems arise from reflection artifacts\n(young patients) and visible choroidal vessels.\nSegmentation is complicated by the presence of strong\ndistractors along the pallor and vessel edges, weakness of\nthe rim and peripapillary atrophy [13]. However, these\nproblems can be overcome by exploiting specific aspects of\nthe appearance: the relative sharpness, reliability and lack\nof vascular intersections on the temporal side of the rim,\nand the approximately elliptical shape. The major contri-\nbution of this paper is in demonstrating how these specific\ncharacteristics of the optic nerve head may be exploited.\nC. Screening Data\nWe have tested the algorithms using a random sample of\n100 fundal images taken from 50 patients attending the dia-\nbetic retinal-screening programme at City Hospital, Birm-\ningham. Some of the patients had been referred from fam-\nily practitioners, and consequently demographic data was\nunavailable for two. The mean age of the remaining pa-\ntients was 63.7 years (s.d. 14.8 years), with 65.5% (n = 29)\nmale and 34.5% (n = 19) female. The patients were from\nvarious ethnic backgrounds (Asian 20%, Afro-Caribbean\n16%, Caucasian 50%, Unknown 14%). 19 patients had type\n2 diabetes mellitus, while the diabetes status was unavail-\nable for the remaining 31. Given the characteristics of the\nregional diabetic population, type 2 diabetes mellitus is\nlikely to predominate in this group too.\nThe images were acquired using a Canon CR6 45MNf\nfundus camera, with a field angle lens of 45 degrees, reso-\nlution 640 \u00d7 480. Images were converted to grey-scale by\nextracting the Intensity component from the HSI represen-\ntation. There is considerable variation in the images, with\nmany characteristics that can affect the algorithms; these\nare summarized in Table I.\nTABLE I\nVisual Characteristics. Characteristics that present\npotential problems are enumerated, in three categories:\nproblems rendering images poor enough to exclude;\naffecting localization; and affecting segmentation. Some\nimages have multiple characteristics.\nCharacteristic No. images\nNo detectable optic nerve head 4\nSevere Cataract 8\nModerate Cataract 2\nTotal potentially unusable 10\nExudates or laser scars 7\nLight artifacts 7\nEasily visible choroidal vessels 20\nTotal localization endangered 34\nSome of rim blurred or missing 27\nSevere peripapillary atrophy 6\nModerate peripapillary atrophy 19\nConcentric peripapillary atrophy\/artifacts 23\nStrong pallor distractor 13\nTotal segmentation endangered 58\n3D. Contents of Paper\nThis paper introduces two new algorithms. In section II\nwe discuss our optic nerve head localization algorithm, a\nsimple but effective specialized correlation filter. The main\nadvantage over previously suggested techniques is its sim-\nplicity combined with robust performance. In section III\nwe discuss our segmentation algorithm, which exploits the\noptic nerve head\u2019s structural characteristics to overcome\ndistractors. This gives it good performance, particularly\nin the critical rim search phase, which is not considered by\nsome previously published papers. In section IV we evalu-\nate this algorithm against alternatives from the literature.\nSection V concludes the paper.\nII. Optic Disk localization\nA. Overview of Optic Disk localization Algorithms\nReliable optic nerve head localization is surprisingly dif-\nficult, due to the variable appearance; na\u00a8\u0131ve approaches\nthat work well for images of healthy retinae often fail on\nscreening images. Sinthanayothin et al. [15] use the rapid\nintensity variation between the dark vessels and the bright\nnerve fibres to locate the optic disk; we found that this al-\ngorithm often failed for fundus images with a large number\nof white lesions, light artifacts or strongly visible choroidal\nvessels. Akita et al. [14], trace the parent-child relation-\nship between blood vessels segments, tracking back to the\ncenter of the optic disk; this presupposes robust detection\nof the blood vessels, which is difficult in images of diseased\nretinae where even quite sophisticated algorithms detect\nfalse positives along the edges of white lesions and along\nthe edge of the optic nerve head itself [5]. Lalonde et al.\n[16], uses pyramidal decomposition and Hausdorff-based\ntemplate matching. The template-based matching tech-\nnique is based on the edge map using a Hausdorff distance\nmeasure, guided by scale tracking of large objects using\nmultiresolution image decomposition. This method is ef-\nfective, but rather complex. We present a much simpler\nlocalization method with a detection performance of 99%\non usable images from our data set.\nB. A Correlational Filter\nOur localization algorithm uses a specialized correlation\nfilter, which matches key elements of the optic disc struc-\nture. The correlation peak gives the approximate center\nof the optic disc. The optic disc consists of a high inten-\nsity near-circular rim, with a significant vertically-oriented,\nroughly centrally located band of low intensity blood ves-\nsels; other parts of the disc (including the interior) are not\nreliable and are discounted. The template consists of a\nLaplacian of Gaussian with a vertical channel in the mid-\ndle to correspond to the major vessel band; see figure 2.\nThe size of the optic nerve head varies significantly; in\nour data set had widths from 65\u2013101 pixels (mean 78.5,\nstandard deviation 7.6). This might suggest a need for fil-\nters at different scales. In fact the single filter used suffices;\nwhere the size mismatches the maximal correlation lies on\nan annulus around the optic nerve head center; the peak is\nFig. 2. Localization filter\n \nFig. 3. Localization Algorithm. a) Gross exudation. b) Strong\npallor.\ntherefore still located within the optic nerve head, which is\nsufficient for our requirements.\nThe template is correlated with the intensity component\nof the fundus image. We use the full Pearson-R correlation,\nto account for variations in mean intensity and contrast,\ndefined by:\nCi,j =\n\u2211\nx,y(f(x, y)\u2212 f(x, y))(w(x\u2212 i, y \u2212 j)\u2212 w)\u2211\nx,y(f(x, y)\u2212 f(x, y))2\n\u2211\nx,y(w(x\u2212 i, y \u2212 j)\u2212 w)2\n(1)\nwhere w is the mean value of the template, calculated\nonce, and f is the mean value of the area covered by w.\nThe filter is prone to locate a point slightly to the temporal\nside, due to the characteristic asymmetry of the optic nerve\nhead (see figure 1), which is convenient for the next stage\nof the algorithm.\nC. Testing and Results\nPerformance is assessed against the 96 out of our 100\nfundus images that have a discernable optic disc. An oph-\nthalmologist labelled the center of each optic disc to create\na gold standard. Images are graded by distance from the\ntrue center (see table II); the algorithm usually finds the\ncenter within 15 pixels, which is acceptable as a starting\npoint for rim segmentation. The center point is within\nthe optic disk area on all usable images bar one. Figure\n3 shows some examples of its performance. This simple\napproach yields excellent results and is robust; its success\nlies in careful design of the filter.\n4TABLE II\nLocalization Performance\n0 \u2013 5 6 \u2013 15 16 \u2013 25 26+\nFundus images 42 45 8 1\nPercentage 43.8 46.9 8.3 1\nIII. Optic Disk Boundary Segmentation\nA. Overview of Deformable Contour Algorithms\nActive contours, or snakes [17], are deformable models\nthat are fit to object edges under the control of two forces:\nexternal forces that pull the model towards image features\nsuch as edges; and internal forces that act as smoothing\nconstraints or object model constraints. There are two\nmain categories: freeform and parametric snakes. Freeform\nsnakes provide many local degrees of freedom, whereas\nparametric deformable models encode a specific shape and\nits variations [18] [19]; the model can help to overcome\nproblems in the images such as boundary gaps. The optic\nnerve head is well-suited to the parametric approach, as it\nhas a simple global model and significant distractors.\nActive contours seek points with a high gradient. There\nare two main problems: noise, which may trap the model in\nlocal minima; and the domain of attraction of the edges \u2013 if\ntoo small, the snake may not find the desired solution [20].\nThese issues are addressed by pre-filtering with a low-pass\nGaussian filter [21]. Often the gradient magnitude image,\n\u2016\u2207I\u2016, is used; in gradient vector methods the direction of\nthe vector is retained to help locate edges with an expected\norientation.\nB. Optic Nerve Head Contour Algorithms\nThere are several key problems in using active contours\nfor optic nerve head segmentation. The blood vessels con-\ntribute powerful distractors along their edges, and obscure\nparts of the rim. The pallor edge may present a strong\ncontrast boundary; it may also combine with the temporal\nedge of vessels on the nasal side to form a strong ellipti-\ncal distractor. There may also be bright concentric arcs of\nperipapillary atrophy outside the rim. The rim \u2013 particu-\nlarly on the nasal side \u2013 may be blurred, hidden by vessels\nor non-detectable. Two previous authors have reported the\nuse of active contours to find the optic disk boundary.\nMendels [12] used a freeform snake, initialized as a circle\ncentered on and inside the optic nerve head. The model\ntended to fit a convoluted boundary, following vessel edge\ndistractors. Mendels addressed this problem using grey-\nscale morphological closure to remove most of the vessels.\nMendel evaluated only nine images; the image illustrated\nin Mendel\u2019s paper is of quite high quality, and it is to be ex-\npected that the algorithm would perform poorly on blurred\nimages, or images with a low intensity rim or significant\ndistractors at the pallor edge, due to the lack of a global\nmodel. Mendel used a gradient vector method, and noted\nthat this helps to avoid distractors.\nLee [22] also applied an active contour model to high\nresolution images centered on the optic nerve head. Like\nMendel, he removed vessels morphologically. The control\npoints and attractors were placed along radial spokes em-\nanating from the center, thus partially imposing a global\nmodel. Attractor points were attached to edges detected\nusing a Canny filter, which makes the system prone to com-\nplete failure where the rim is missing. Lee reported prob-\nlems caused by the boundary of the pallor and by very\nfaint or missing edges, and presented results on only four\nimages.\nThese papers indicate the significant difficulties in seg-\nmenting the optic nerve head rim. However, neither author\nfully exploited the strongly consistent overall shape of the\noptic nerve head to constrain the contour, bypass distrac-\ntors, and maintain shape where the rim is not visible. Both\nauthors assumed that the model position was initialized\nquite accurately, as in their images the optic nerve head is\nalways centered. In our less constrained problem domain\ninitialization is much less reliable, and consequently our\nsearch algorithm must be much more robust.\nHu et al. [23] recently described a method for boundary\nextraction of cross-sectional blood vessels in 3D imaging.\nA circular global model is first fit to the boundary contour,\nthen a local deformable model with variable stiffness fits\nclosely to strong edge features, while maintaining a smooth\ncontour close to the global model when edge features are\nweak or missing. There is a strong correspondence to our\nproblem domain, and this paper extends the work of Hu\net al. to optic nerve head segmentation. A number of al-\nterations were necessary, including generic improvements\n(elliptical model, use of the gradient vector, and fast opti-\nmization), and domain specific improvements (exploitation\nof the optic nerve head topology).\nIn section III-C we describe Hu\u2019s model, in section III-D\nwe describe our generic alterations, and in section III-E we\nintroduce the optic nerve head algorithm.\nC. Hu\u2019s Circular Deformable Model\nIn this section we describe Hu et al.\u2019s deformable model\n[23], with some change of variables from the original paper\nto simplify the presentation. The global model is a circle\nwith center c, and radius r. The local model is defined by\nthe center c, and S evenly-spaced radial spokes, each with\nangle \u03b8i, and direction vector si = [cos(\u03b8i), sin(\u03b8i)]. The\nmodel is defined by distances mi from c along each spoke,\nwith corresponding (x, y) location vector mi = c + misi.\nThe local model has a corresponding global model, with\nradius r = mi, the local model\u2019s mean radial displacement.\nThe normalized negative gaussian-smoothed gradient\nmagnitude image, \u0393 = \u2212\u2016\u2207I\u2016\/max(\u2016\u2207I\u2016), is sampled to\nproduce radial gradient profiles; the radial displacement of\nthe \u201cpeak gradient\u201d within a limited search range about\nmi, denoted gi, provides an external attractor point. Since\nradial lines cross image pixels in an irregular manner, non-\nuniform sampling can occur. The gradient magnitude at\ndistance \u03c1 along spoke i is determined as follows. Let\np = (px, py) = c + \u03c1si. We calculate the radial gradi-\nent \u03b3i(\u03c1) by bilinear interpolation of the image gradient\nmagnitude at the point\u2019s four neighboring pixels [24]; see\n5c\nradial line\nmodel\n(x,y)\ni i+1\nj\nj+1\n1\u03c2\n2\u03c2\n1.0\n1.0\ni\u03b30\nFig. 4. Algorithm details. a) Bilinear interpolation of gradient. b)\nStiffness factor function.\nequation 2, figure 4. The \u201cpeak,\u201d gi, is chosen so that\n\u03b3i = \u03b3i(gi) is the minimum on the spoke.\n\u03b3i(\u03c1) = \u2212\n\u2211\nx,y\nwx,y\u0393(x, y) (2)\nxd = |px \u2212 x| yd = |py \u2212 y| (3)\nwx,y =\n{\n(1\u2212 xd)(1\u2212 yd) (xd < 1) \u2227 (yd < 1)\n0 otherwise (4)\nThe contour is altered under the influence of a force,\nfi, with external and internal components; see equation\n5. All the forces work along the radial spokes. The ex-\nternal force drags the model towards the attractor points;\nsee equation 6. The internal force limits model deforma-\ntion using two components: the global force, which pulls\nthe model towards the global shape; and the local force,\nwhich smoothes the model by penalizing differences in de-\nformation between neighboring spokes. The internal force\nis modified by a stiffness factor, \u03b2i, described further below.\nfi = fexti \u2212 f inti (5)\nfexti = gi \u2212mi (6)\nf inti = \u03b2i\n(\ndinti \u2212 \u03b1\u3008dinti \u3009\n)\n(7)\nwhere dinti = mi \u2212 r is deformation of the model from the\nglobal model on spoke i, and \u3008dinti \u3009 is the mean deformation\nof neighboring spokes. The coefficient \u03b1 balances the local\nversus global internal forces.\nThe stiffness parameter, \u03b2i, controls the relative strength\nof the internal and external forces. On a strong edge a small\nstiffness value is used, the external force dominates, and\nlocalization is not unduly compromised. Where the edge is\nweak a larger stiffness value is assigned, and the contour is\nlocally smoothed and attracted to the global model.\nHu et al. used a function shaped like that in figure 4b to\ndetermine the stiffness factor, but did not give the formula;\nour stiffness function is defined as follows. Let \u03b3i be the\ngradient magnitude at point gi, (see equation 2), \u3008\u03b3i\u3009 the\nmean gradient magnitude of the neighboring spokes. Define\nthe squashing factor \u03b6 = \u03c7+\u3008\u03b3i\u3009, with \u03c7 = 1.5, which shifts\nthe function to the left or right of the middle position. Let\n\u03c8i = 1\u2212 \u03b3i; then the stiffness factor \u03b2i is given by:\n\u03b2i =\n{\n(2\u03b33i \u2212 3\u03b32i + 1)\u03b6 \u03b6 \u2265 0\n1\u2212 (2\u03c83i \u2212 3\u03c82i + 1)(1\u2212\u03b6) \u03b6 < 0\n(8)\n \nc\nellipse\nar\nr\nm4\nm3\nm2\nm1\nlinear radial search area\ng1\ng2\ng3\nd1int\nd2int\nd3int\nd4int\n \noptic cup\nmodel\nFig. 5. Model fitting. a) The deformable model. b) Locking to the\ntemporal edge\nHu et al. use the radial forces defined above to provide\na center-shifting force, a global radius force, and local de-\nformation forces. The shifting force is found by converting\nthe radial forces to vector forces in the (x, y) plane, and\naveraging (equation 9), then the radial forces are then rec-\ntified by removing the shifting force projected in the radial\ndirection (equation 10).\nf =\n1\nS\n\u2211\ni\nfisi (9)\nf\u2217i = fi \u2212 si.f (10)\nThese forces are used to iteratively adjust the model,\nby adding f to c, and f\u2217i to mi (or, if a circular model is\ndesired, f\u2217i to r).\nD. Alterations to the model\nWe introduce three modifications: an elliptical global\nmodel; the use of the vector gradient; and the use of energy\nfunctions to support fast non-linear optimization.\nOur global model is an ellipse with a vertical principal\naxis, and a fixed aspect ratio, a; see figure 5a. We re-\ntain the \u201cradius\u201d parameter, r, which is the ellipse width;\nthe height is consequently ar. The elliptical model can be\ntransformed into an equivalent circular model by scaling\nusing the spoke ratios, ai (equation 11), to \u201cnormalize\u201d\nradial distances and forces. The local model has an asso-\nciated global model, with radius defined by equation 12.\nWe introduce variables for the model and attractor points\nnormalized to the circular frame of reference, mni = mi\/ai,\ngni = gi\/ai.\nai = \u2016[cos(\u03b8i), a sin(\u03b8i)]\u2016 (11)\nr =\n1\nS\n\u2211\ni\nmi\nai\n(12)\nWe work with the smoothed normalized gradient vector\nimage, \u03a5 = \u2207I\/max(\u2016\u2207I\u2016), rather than its negative mag-\nnitude \u0393. During profiling, the dot product of the gradient\nvector and the spoke direction vector determines the gradi-\nent coincident with the spoke \u2013 see equation 13; the weights\nare determined by equation 3. This yields a direction-\nsensitive gradient which ignores distractors at most vessel\nedges.\n6\u03b3i(\u03c1) =\n(\u2211\nx,y\nwx,y\u03a5(x, y)\n)\n.si (13)\nWe use a fast non-linear optimization procedure, Quasi-\nNewton [25]. This requires an explicit energy function, in\naddition to a gradient function (the latter equivalent to\nHu et al.\u2019s forces). We define the energy functions as the\nsum-squared deformation of the model from the attractors:\nExy =\n1\n2\n\u2223\u2223\u2223\u2223\u2223\n\u2223\u2223\u2223\u2223\u2223\n(\n1\nS\n\u2211\ni\nmni \u2212 c\n)\u2223\u2223\u2223\u2223\u2223\n\u2223\u2223\u2223\u2223\u2223\n2\n(14)\nE = Eext + Eint = Eext +Eglo + Eloc (15)\nEext =\n1\n2\n\u2211\ni\n(gni \u2212mni )2 (16)\nEglo =\n1\n2\n\u2211\ni\n\u03b2i(mni \u2212 r)2 (17)\nEloc =\n1\n2\n\u2211\ni\n\u03b2i\u03b1(mni \u2212 \u3008mni \u3009)2 (18)\nDifferentiating Exy with respect to c, and E with respect\nto mni , and observing that r and \u3008mni \u3009 in equations 17 and\n18 are both dependent on mni , we obtain the gradients:\ndExy\ndc\n=\n1\nS\n\u2211\ni\nmni si (19)\ndE\ndmni\n=\ndEext\ndmni\n+\ndEglo\ndmni\n+\ndEloc\ndmni\n(20)\ndEext\ndmni\n= gni \u2212mni (21)\ndEglo\ndmni\n= \u03b2i((mni \u2212mni )\u2212 (mni \u2212mni )) (22)\ndEloc\ndmni\n= \u03b2i\u03b1 [(mni \u2212 \u3008mni \u3009)\u2212 \u3008[mni \u2212 \u3008mni \u3009]\u3009] (23)\nThe global and local gradients differ from the forces used\nby Hu et al. in the second term; they are identical at\nzero deformation, but the correct gradients are required\nfor efficient optimization.\nLet w denote a vector of model parameters, E(w) the\nerror function for these parameters, and w\u2032 the gradient of\nthe error function with respect to the parameters; w may\nbe any desired combination of model parameters (e.g. mi,\nc, r); if we wish to optimize several parameters simulta-\nneously, the appropriate parameter and gradient vectors\nmay be concatenated and the error functions summed. We\nuse standard non-linear optimization techniques to choose\nthe parameters. We used two approaches: gradient de-\nscent with momentum (for the simpler global model phase)\nand Quasi-Newton BFGS (for the local model phase); both\nproved more efficient than the direct iterative technique.\nIn gradient descent with momentum, we choose a learn-\ning rate, \u03b7, and a momentum rate, \u00b5, and update the model\nparameters w at iteration \u03c4 + 1 using:\nw\u03c4+1 = \u03b7w\u2032\u03c4 + \u00b5w\u03c4 (24)\nQuasi-Newton optimization involves generating a se-\nquence of matrices, G\u03c4 representing increasing accurate\napproximations to the inverse Hessian, H\u22121, using infor-\nmation from the first derivatives of the error function [26].\nUsing the Broyden-Fletcher-Goldfarb-Shanno (BFGS) pro-\ncedure, the approximation G\u03c4 of the inverse Hessian ma-\ntrix, is updated using equation 29.\nG0 = \u2212Iw\u20320 (25)\np = w\u03c4+1 \u2212w\u03c4 (26)\n\u03bd = w\u2032\u03c4+1 \u2212w\u2032\u03c4 (27)\nu =\np\npT\u03bd\n\u2212 G\u03c4\nT\u03bd\n\u03bdTG\u03c4T\u03bd\n(28)\nG\u03c4+1 = G\u03c4 +\npG\u03c4T\nG\u03c4T\u03bd\n\u2212 (G\u03c4\u03bd)\u03bd\nTG\u03c4\n\u03bdTG\u03c4\u03bd\n+ (\u03bdTG\u03c4\u03bd)uuT (29)\nw(\u03c4+1) = w(\u03c4) + \u03be\u03c4Gw\u2032 (30)\nThe update procedure ensures that the approximation to\nthe inverse Hessian is positive definite. The direction vector\n\u2212G\u03c4w\u2032 is guaranteed to descend, and rapidly converges\non the Newton direction. Optimization is by equation 30,\nwhere \u03be\u03c4 is found by a bracketing line search [25].\nE. Optic Nerve Head Segmentation\nOur localization and deformable model algorithms are\nvery reliable, but the latter is sensitive to poor initializa-\ntion. Hence, the most critical phase is the optimization\nof the global model; direct fitting of this proves unreli-\nable. We therefore introduce a four phase algorithm, with\nthe global fit carried out across the two middle phases.\nPhase two roughly locates the rim, by locking the global\nmodel onto the relatively reliable and distractor-free tem-\nporal rim; phase three fits it to the entire rim. Phase one\n(localization) was described in section II; phases two to\nfour are described below.\nE.1 Phase two \u2013 temporal lock\nIn this phase we define a global model using S = 9 spokes\nat angles \u221260\u25e6 to +60\u25e6 in steps of 15\u25e6, on the temporal\nedge only. The gradient image is smoothed with a gaussian\nfilter (\u03c3 = 5.0), and the radial search range for \u03b3i is set to\nmi \u00b1 6 pixels. The aspect ratio is fixed at a = 1.03 and\nthe radius at r = 40; only the model center is adjusted.\nOptimization is by gradient descent (see equation 24), with\n\u03b7 = 1, \u00b5 = 0.1, w = c, w\u2032 = dExy\/dc (see equation 19).\nThe temporal bias of the localization algorithm ensures\nthat the initial contour is usually just outside the temporal\nedge. Due to the lack of temporal vessels, their typically\nradial alignment, and the relative strength of the temporal\nedge, this phase locks on with high reliability; see figure\n5b. The fixed radius ensures that the nasal edge of the\nmodel bypasses the distractors at the pallor and central\nblood vessels. A fixed radius is necessary since fitting an\n7elliptical model to 120\u25e6 of arc on one side is prone to gross\nmis-estimation.\nE.2 Phase three \u2013 global fit\nThis phase activates the entire global model, using S =\n24 evenly-spaced spokes at 15\u25e6 spacing; the radial search\nrange is reduced to \u00b14 pixels. Other parameters are iden-\ntical to phase two. The radius of the model is now allowed\nto alter in addition to the center; the energy function be-\ncomes Exy + Eext, with the latter treated as a function of\nr; w = [c; r] . The gradient of Eext with respect to r is\ngiven by equation 31, derived from equation 21, bearing in\nmind that to enforce the global model, we set mi = air.\ndEext\ndr\n=\n\u2211\ni\ndEext\ndmni\ndmni\ndr\n=\n\u2211\ni\n(gi \u2212 r) (31)\nOptimization is by a short burst of gradient descent,\nwhich \u201ctweaks\u201d the model onto the nasal edge. The use of\nthe gradient vector (equation 13) ensures that the model is\nnot pulled onto the nasal edges of the nasal vessels, which\nhave opposite contrast direction to the rim, or the edges\nof near-orthogonal vertically-departing vessels. The only\nstrong distractors are the pallor edge and peripapillary ar-\ntifacts. The small search range usually avoids the former.\nThe fixed aspect ratio, a = 1.03 may lead to sub-optimal\nmodels (actual aspect ratios were in the range 0.94\u20131.15,\nmean 1.03, s.d. 0.038). To compensate for this, we itera-\ntively recalculate the aspect ratio from the attractor points\nat the end of the phase, and repeat the optimization (which\nis extremely fast); three iterations suffice. The aspect ratio\nis calculated using equation 32, where u and v are the unit\nvectors along the x and y axes.\na =\n\u221a\u2211\nimi(v.si)2\u2211\nimi(u.si)2\n(32)\nE.3 Phase four \u2013 local deformation\nWhen the global model reaches equilibrium the local\nmodel is activated. To improve contour localization the\ngradient image is recalculated with smoothing factor \u03c3 = 1.\nThe model points,mi, are allowed to vary in addition to the\ncenter, c; therefore, w = [c;m1, . . . ,mS ]. The full energy\nfunction from equation 15 is used, with w\u2032 composed from\nthe corresponding gradients. Local stage optimization is\nmore challenging than the global stage; we therefore use\nthe fast Quasi-Newton algorithm. The control parameter\nsettings for the energy function were, \u03b1 = 0.5.\nIV. Testing and Results\nWe tested our algorithm against a number of alternative\napproaches, describe below. We used a subset of 90 images,\nexcluding those with no discernable optic disk, or with se-\nvere enough cataract to prevent meaningful segmentation.\nTo produce a \u201cgold standard\u201d segmentation four clinicians\nmanually delimited the rim; we calculate their mean con-\ntours, and the radial standard deviations of these contours.\nLet \u00b5ji and \u03c3\nj\ni summarize the clinician\u2019s choice of rim loca-\ntion on spoke i of image j. We define the discrepancy, \u03b4j ,\non image j using equation 33. Division by \u03c3 compensates\nfor uncertainty in rim position; \u03b5 = 0.5 is a small factor to\nprevent division by zero where the clinicians are in exact\nagreement.\n\u03b4j =\n\u2211\ni\n|mji \u2212 \u00b5ji |\n\u03c3ji + \u03b5\n(33)\nThe obvious choice of overall summary statistic, the\nmean discrepancy, is uninformative as the distribution is\nheavily skewed (e.g. mean discrepancy 3.6, median 1.1 for\nthe \u201ctemporal lock\u201d algorithm). For illustrative purposes\nwe instead plot the ogive of disparity, \u03b4 on a logarithmic\nscale (i.e. the number of images with disparity less than \u03b4,\n|{j : \u03b4j < \u03b4}|, versus \u03b4). On these plots a superior model\nlies left of and above an inferior one; the number of images\nfit to any given level of accuracy can be read off the y-axis.\n.4 Parameter Settings\nWe experimented with a wide range of parameter set-\ntings, including: initial model diameter and aspect ratio,\ngaussian smoothing factors, radial profile search sizes, and\n\u03b1 in the deformable model. The values reported through-\nout the paper were heuristically selected for best perfor-\nmance. In most cases the algorithm\u2019s overall performance\nis not very sensitive to changes in these parameters.\nThe initial diameter parameter has significantly perfor-\nmance implications for a small number of optic nerves\nheads of outlying size, as pallor and peripapillary distrac-\ntors may induce errors. This might suggest running the al-\ngorithm with several initial diameters and selecting the low-\nest energy resulting contour. Unfortunately, strong distrac-\ntors may actually have lower energy than the true contour,\nand a simple geometric rule to choose between alternative\nsolutions is also elusive (pallor distractors are inside the\ntrue rim, but peripapillary distractors are outside), which\nmakes the utility of even sophisticated minima-avoidance\nalgorithms [27] questionable. We therefore use a fixed ini-\ntial diameter which functions well in the vast majority of\ncases.\nA. Performance of the algorithm\nFigure 7a shows the performance graph of our final al-\ngorithm against a simple benchmark approach (\u201cdirect\u201d)\nwhich proceeds directly from localization to local fitting\nwithout using the temporal lock or the vector gradient.\nQualitatively, we define four categories (Excellent, Good,\nFair and Poor) containing images with disparity up to one,\ntwo, five, or more, respectively. Figure 6 shows examples\nin each category. Table III summarizes performance on\nthis subjective scale. These disparity ranges correspond\nreasonably well to a subjective assessment of quality.\nB. Comparison with Alternative Algorithms\nThe temporal lock phase is a critical aspect of our al-\ngorithm that allows it to compensate for poor localization\n8Excellent (\u03b4=0.85) Good (\u03b4=1.5)\nFair (\u03b4=3.1) Poor (\u03b4=38.9)\nFig. 6. Sample Segmentations. a) Excellent. b) Good. c) Fair. d)\nPoor. Solid line: algorithm; dotted line: mean clinician boundary.\nTABLE III\nSubjective Classification of Performance\n(%) Excellent Good Fair Poor\nTemporalLock 42 31 10 17\nSimple 9 8 30 53\nDV \u2212Hough 39 22 20 19\nwhile avoiding distractors. There are alternative methods:\nwe can attempt to remove or mitigate distractors and use\nsome other method to improve localization of the rim.\nA method suggested by both Lee [22] and Mendels [12]\nto reduce distractors is to morphologically remove the ves-\nsels; we refer to this as \u201cde-vascularization\u201d, and implement\nit by grey-scale morphological closure with a disk-shaped\nstructuring element, radius 7. Mendels also noted that the\nuse of the vector gradient rather than magnitude improved\nhis algorithm. Figure 7b shows the interaction between\nde-vascularization and the gradient vector, in the absence\nof a temporal lock phase. Either technique alone is ben-\neficial, but there is no advantage in using both, as they\ncompensate for the same distractors.\nAn alternative to the temporal lock phase is to attempt\nto fit a global model to the rim non-iteratively. We have\nexperimented with the use of an elliptical Hough trans-\nform. The image is processed using a Canny edge-detector\n(upper and lower thresholds 0.2 and 0.08 respectively),\nand a Hough transform is used to locate the rim. Ves-\nsel edges provide a significant number of distractors, and\nwe found the technique worked well only in conjunction\nwith de-vascularization. We looked for ellipses of width\n56\u2013112, aspect ratio 1.03, and smoothed the Hough-space\nwith a Gaussian kernel (\u03c3 = 1.5) before peak detection\nto account for deformations. We maintained our standard\nphase one localization algorithm, and used the Hough fil-\n100 101\n20\n40\n60\n80\nNormalized Algorithm \/ Clinician Disparity\nTL\nDirect\n100 101\n20\n40\n60\n80\nVec\nDV, Vec\nDV, Mag\nMag\n100 101\n20\n40\n60\n80\nDisparity, \u03b4\nN\no.\n Im\nag\nes\n <\n \u03b4\nTL\nDV Hough\nDV\na). \nb). \nc). \nFig. 7. a). Temporal Lock (TL) versus direct algorithm. b). Inter-\naction between De-vascularization (DV) and vector (Vec)\/magnitude\n(Mag) gradient versions of direct algorithm. c). Temporal Lock\n(TL), De-vascularized Hough (DV Hough), and De-vascularized di-\nrect (DV).\nTABLE IV\nError types\nSource of error Number\nLocalization failure 3\nTemporal lock failure 5\nPallor distractor 3\nSevere peripapillary atrophy 4\nter to tune the location within a search radius of 150 pix-\nels, as we found the technique too unreliable to be used\nacross the entire image; we also accepted the Hough center\nonly if the peak in Hough space exceeded a threshold. Re-\nsults are illustrated on figure 7c. In combination with de-\nvascularization and the vector gradient, we obtain a quite\ncapable algorithm (\u201cDV-Hough\u201d), with performance close\nto that of the temporal lock algorithm. Using the one-sided\nsign test for paired medians, the difference in performance\n(temporal lock is better in 59\/90 cases) is significant at the\n0.5% level. The superiority of either algorithm over the\nsimpler alternatives is equally clear-cut.\nWe have also tried integrating de-vascularization and the\nHough search into the temporal lock algorithm, but these\ncomplications do not improve that algorithm.\nAlthough the temporal lock algorithm performs very well\nin comparison to alternatives, there is room for improve-\nment; in many cases the algorithm failed to detect the rim\nwhere it is unambiguously apparent to the human observer.\nTable IV attributes the cause of failure on the 15 \u201cpoor\u201d\nperformance images; two of the \u201ctemporal lock\u201d failures\nare difficult to attribute cleanly, as localization was rather\npoor and probably contributed to the failure. Two of the\n\u201cperipapillary atrophy\u201d failures subjectively look \u201cfair.\u201d\n9V. Conclusions and Discussion\nWe have presented algorithms for localization and seg-\nmentation of the optic nerve head, an important stage in\nstructured analysis of the retina, which can be used in di-\nagnosis of eye diseases such as diabetic retinopathy.\nAlthough a number of methods have been published for\noptic nerve head localization, many are unreliable when\nconfronted with images of diseased retinae including strong\ndistractors, and the reliable methods tend to be quite com-\nputationally complex. We have presented a simple but ef-\nfective algorithm for localization.\nOptic nerve head segmentation by active contours has\nnot been extensively examined in the past. There are sig-\nnificant problems in dealing with distractors along blood\nvessels edges and the pallor, and with the very variable\nappearance of the optic nerve head. Previously published\ntechniques require careful initialization of the model posi-\ntion, pre-processing of the image using morphological op-\nerations, and perform badly where the rim is faint or unde-\ntectable. In contrast, the algorithm presented in this paper\nexploits specific features of the optic nerve head anatomy to\nachieve good localization while avoiding distractors. The\ntemporal lock algorithm exploits the natural shape of the\nneuroretinal rim to bypass blood vessels and avoid the pal-\nlor, and the global and local deformable model deals effec-\ntively with weak areas of rim and vessel crossings. Defining\nenergy functions and using a Quasi-Newton optimization\nstrategy makes the algorithm reasonably fast.\nWe have conducted an experimental comparison with\na range of alternative approaches, using a fairly large\nrandomly-selected experimental set, and have demon-\nstrated the superiority of the proposed approach. We note\nthat the algorithm still does not have perfect performance,\nowing to the variable nature of the images and the pres-\nence of distractor boundaries concentric with the desired\nrim, which may be located either inside or outside the rim.\nFuture work to improve the algorithm to deal with these\ndistractors will require reasoning at a higher level.\nAlthough our current approach focuses on detecting the\noptic nerve head boundary as a stage in the structured\nanalysis of images for diabetic retinopathy fundus images,\nthe approach is also of relevance in diagnosis of other dis-\neases, and particularly in screening for glaucoma; in the\nfuture we will evaluate the method for use in detection of\nthe rim in glaucomatous images.\nAcknowledgments\nThis project was supported by Diabetes UK, Project Grant\nNo. BDA:RD00\/0002033.\nThe authors would like to thank the referees for their de-\ntailed and useful suggestions, which have helped to greatly\nimprove this paper.\nReferences\n[1] A. Manivannan, P.F. Sharp, R.P. Phillips, and J.V. Forrester,\n\u201cDigital fundus imaging using a scanning laser ophthalmoscope,\u201d\nPhysiol Meas, vol. 14, pp. 43\u201356, 1993.\n[2] D.E. Singer, D.M. Nathan, H.A. Fogel, and A.P. Schachat,\n\u201cScreening for diabetic retinopathy.,\u201d Ann Intern Med, vol. 116,\npp. 660\u201371, 1992.\n[3] J.J. Kanski, Clinical Ophthalmology 3rd Edition, Butterworth-\nHeinemann, 1994.\n[4] E.M. Kohner, Diabetes and the Eye, Oxford Textbook of Oph-\nthalmology Vol. 2, Oxford University Press, 1999.\n[5] A. Hoover, V. Kouznetsova, and M. Goldbaum, \u201cLocating blood\nvessels in retinal images by piecewise threshold probing of a\nmatched filter response,\u201d IEEE Transactions on Medical Imag-\ning, vol. 19, pp. 203\u2013210, 2000.\n[6] T. Teng, M. Lefley, and D. Claremont, \u201cProgress towards au-\ntomated diabetic ocular screening: a review of image analysis\nand intelligent systems for diabetic retinopathy,\u201d Medical and\nBiological Engineering and Computing, vol. 40, pp. 2\u201313, 2002.\n[7] A. Daxer, \u201cCharacterization of the neovascularization process\nin diabetic retinopathy by means of fractal geometry: diagnostic\nimplications,\u201d Graefe\u2019s Arch. Clin. Exp. Ophthalmol., vol. 231,\npp. 681\u2013686, 1993.\n[8] W. Lotmar, A. Freiburghaus, and D. Bracher, \u201cMeasurement of\nvessel tortuosity on fundus photographs,\u201d Graefe\u2019s Arch. Clin.\nExp. Ophthalmol., vol. 211, pp. 49\u201357, 1979.\n[9] P.H. Gregson, Z. Shen, R.C. Scott, and V. Kozousek, \u201cAuto-\nmated grading of venous beading,\u201d Computers and Biomedical\nResearch, vol. 28, pp. 291\u2013304, 1995.\n[10] M.H. Goldbaum, V. Kouznetsova, B.L. Cote\u00b4, W.E. Hart, and\nM. Nelson, \u201cAutomatic registration of digital ocular fundus im-\nages for comparison of lesions,\u201d SPIE 1877, Ophthalmic Tech-\nnologies III, pp. 291\u2013304, 1995.\n[11] H. Littmann, \u201cZur bestimmung der wahren gro{sse eines ob-\njektes auf dem hintergrund des lebenden auges,\u201d Klin Monastbl\nAugenheilkd, p. 180:286, 1982.\n[12] F. Mendels, C. Heneghan, P.D. Harper, R.B. Reilly, and J-Ph.\nThiran, \u201cExtraction of the optic disc boundary in digital fundus\nimages,\u201d in Proc. 1st Joint BMES\/EMBS Conf., 1999, p. 1139.\n[13] K. Yogesan, C.J. Barry, et al., \u201cSoftware for 3-d visual-\nization\/analysis of optic-disc images,\u201d IEEE Engineering in\nMedicine and Biology, vol. 18, pp. 43\u201349, 1999.\n[14] K. Akita and H. Kuga, \u201cA computer method of understanding\nocular fundus images,\u201d Pattern Recognition., vol. 15, pp. 431\u2013\n443, 1982.\n[15] C. Sinthanayothin, J.A. Boyce, H.L. Cook, and T.H. Williamson,\n\u201cAutomated localisation of the optic disc, fovea, and retinal\nblood vessels from digital colour fundus images,\u201d Br J. Oph-\nthalmol., vol. 83, pp. 902\u2013910, 1999.\n[16] M. Lalonde, M. Beaulieu, and L. Gagnon, \u201cFast and robust op-\ntic disc detection using pyramidal decomposition and hausdorff-\nbased template matching,\u201d IEEE Trans. Medical Imaging, vol.\n20, pp. 1193\u20131200, 2001.\n[17] M. Kass, A. Witkin, and D. Terzopoulos, \u201cSnakes. active contour\nmodels,\u201d Int. J. Comput. Vision, vol. 1, pp. 321\u2013331, 1987.\n[18] D. Terzopoulos and D. Metaxas, \u201cDynamic 3d models with lo-\ncal and global deformations: deformable superquadrics,\u201d IEEE\nTrans. PAMI, vol. 13, pp. 703\u2013714, 1991.\n[19] A.K. Jain, Y. Zhong, and M. Dubuisson-Jolly, \u201cDeformable\ntemplate models: A review,\u201d Signal Processing, vol. 71, pp.\n109\u2013129, 1998.\n[20] F.A. Velasco and J.L. Marroquin, \u201cRobust parametric active\ncontours: the sandwich snakes,\u201d Machine Vision and Applica-\ntions, vol. 12, pp. 238\u2013242, 2001.\n[21] H. Eviatar and R.L. Somorjai, \u201cA fast, simple active contour\nalgorithm for biomedical images,\u201d Pattern Recognition Letters,\npp. 969\u2013974, 1996.\n[22] S. Lee, Visual Monitoring of Glaucoma, Ph.d., Robotics Re-\nsearch Group Department of Engineering Science, University of\nOxford, 1991, Available on micro-fiche.\n[23] Y-L. Hu, W.J. Rogers, D.A. Coast, C.M. Kramer, and N. Re-\nichek, \u201cVessel boundary extraction based on a global and local\ndeformable physical model with variable stiffness,\u201d Magnetic\nResonance Imaging, vol. 16, pp. 943\u2013951, 1998.\n[24] A. Blake and M. Isard, Active Contours, Springer, 1998.\n[25] W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery,\nNumerical Recipes in C, 1992.\n[26] C.M. Bishop, Neural Networks for Pattern Recognition, Claren-\ndon Press, Oxford, 1995.\n[27] M. Lalonde and L. Gagnon, \u201cVariable neighbourhood search for\ngeometrically deformable templates,\u201d in Proc. Int. Conf. Patt.\nRec., Que\u00b4bec, Canada, 2002, pp. 689\u2013692.\n"}
{"doi":"10.1186\/1748-5908-2-38","coreId":"177257","oai":"oai:aura.abdn.ac.uk:2164\/2042","identifiers":["oai:aura.abdn.ac.uk:2164\/2042","10.1186\/1748-5908-2-38"],"title":"Looking inside the black box : A theory based process evaluation alongside a randomised controlled trial of printed educational materials (The Ontario Printed Educational Message (OPEM)) Trial","authors":["Zwarenstein, M.","Tetroe, J.","Godin, G.","Graham, I.","Lemyre, L.","Eccles, M.","Johnston, Marie","Francis, Jillian","Hux, J.","Legare, F.","Presseau, J."],"enrichments":{"references":[{"id":17489830,"title":"Closing the gap between research and practice: an overview of systematic reviews of interventions to promote the implementation of research findings. The Cochrane Effective Practice and Organization of Care Review Group. BMJ","authors":[],"date":"1998","doi":null,"raw":"Bero LA, Grilli R, Grimshaw JM, Harvey E, Oxman AD, Thomson MA: Closing the gap between research and practice: an overview of systematic reviews of interventions to promote the implementation of research findings. The Cochrane Effective Practice and Organization of Care Review Group.  BMJ 1998, 317:465-468.","cites":null},{"id":17489841,"title":"Constructing questionnaires based on the theory of planned behaviour. In A manual for health services researchers Centre for Health Services Research,","authors":[],"date":"2004","doi":null,"raw":"Francis JJ, Eccles MP, Johnston M, Walker AE, Grimshaw JM, Foy R, et al.:  Constructing questionnaires based on the theory of planned behaviour.  In A manual for health services researchers Centre for Health Services Research, University of Newcastle upon Tyne, UK; 2004.","cites":null},{"id":17489863,"title":"DT: Experimental and Quasi-Experimental Designs for Generalized Causal Inference Boston: Houghton-Mifflin;","authors":[],"date":"2002","doi":null,"raw":"Shadish WR, Cook TD, Campbell DT: Experimental and Quasi-Experimental Designs for Generalized Causal Inference Boston: Houghton-Mifflin; 2002.","cites":null},{"id":17489834,"title":"Effectiveness and efficiency of guideline dissemination and implementation strategies. Health Technol Assess","authors":[],"date":"2004","doi":null,"raw":"Grimshaw JM, Thomas RE, MacLennan G, Fraser C, Ramsay C, Vale L, et al.: Effectiveness and efficiency of guideline dissemination and implementation strategies.  Health Technol Assess 2004, 8:.","cites":null},{"id":17489832,"title":"for Reviews and Dissemination: Getting evidence into practice. Effective Health Care Bulletin","authors":[],"date":"1999","doi":null,"raw":"NHS Centre for Reviews and Dissemination: Getting evidence into practice.  Effective Health Care Bulletin 1999, 5:1-16.","cites":null},{"id":17489861,"title":"Higgins JP: How should meta-regression analyses be undertaken and interpreted? Stat Med","authors":[],"date":"2002","doi":null,"raw":"Thompson SG, Higgins JP: How should meta-regression analyses be undertaken and interpreted?  Stat Med 2002, 15:1559-1573.","cites":null},{"id":17489851,"title":"Horwitz RJ: Problems in the conduct and analysis of randomized clinical trials.","authors":[],"date":"1992","doi":null,"raw":"Rabaneck L, Viscole CM, Horwitz RJ: Problems in the conduct and analysis of randomized clinical trials.  Archives of Internal Medicine 1992, 152:507-512.","cites":null},{"id":17489853,"title":"Kulkin IL: Monitoring nursing interventions and data collection in a randomized clinical trial.","authors":[],"date":"1991","doi":null,"raw":"Gilliss CL, Kulkin IL: Monitoring nursing interventions and data collection in a randomized clinical trial.  Western Journal of Nursing Research 1991, 13:416-422.","cites":null},{"id":17489845,"title":"Mail and internet surveys.","authors":[],"date":"2000","doi":null,"raw":"Dillman D: Mail and internet surveys.  In The tailored design method 2nd edition. New York: John Wiley; 2000.","cites":null},{"id":17489855,"title":"Nelder JA: Generalized linear models London:","authors":[],"date":"1999","doi":null,"raw":"McCullagh P, Nelder JA: Generalized linear models London: Chapman & Hall Ltd; 1999.","cites":null},{"id":17489859,"title":"O&quot;Rourke K: Meta-Analysis. In Modern Epidemiology 3rd edition. Edited by: Rothman KJ,","authors":[],"date":"2007","doi":null,"raw":"Greenland S, O&quot;Rourke K: Meta-Analysis.  In Modern Epidemiology 3rd edition. Edited by: Rothman KJ, Greenland S, Lash T. Lippincott Williams and Wilkins; 2007 in press.","cites":null},{"id":17489836,"title":"Practice based, longitudinal, qualitative interview study of computerised evidence based guidelines in primary care. BMJ","authors":[],"date":"2003","doi":null,"raw":"Rousseau N, McColl E, Newton J, Grimshaw J, Eccles M: Practice based, longitudinal, qualitative interview study of computerised evidence based guidelines in primary care.  BMJ 2003, 326:314.","cites":null},{"id":17489837,"title":"SM: Improving the quality of health care in the United Kingdom and the United States: a framework for change. The Milbank Quarterly","authors":[],"date":"2001","doi":null,"raw":"Ferlie EB, Shortell SM: Improving the quality of health care in the United Kingdom and the United States: a framework for change.  The Milbank Quarterly 2001, 79:281-315.","cites":null},{"id":17489850,"title":"Surveying Physicians. Do components of the&quot;Total Design Approach&quot; to optimizing survey response rates apply to physicians? Med Care","authors":[],"date":"2002","doi":null,"raw":"Field JL, Cadoret CA, Brown ML, Ford M, Greene SM, Hill J, et al.: Surveying Physicians. Do components of the&quot;Total Design Approach&quot; to optimizing survey response rates apply to physicians?  Med Care 2002, 40:596-606.","cites":null},{"id":17489838,"title":"Testing a TheoRYinformed MEssage (&quot;TRY-ME&quot;): A Sub-trial Within a Randomized Controlled Trial of Printed Educational Materials (The Ontario Printed Educational Message (OPEM) Trial). Implementation Science","authors":[],"date":"2006","doi":null,"raw":"Francis J, Grimshaw JM, Zwarenstein M, Eccles MP, Shiller S, Johston M, O'Rourke K, Presseau J, Tetroe J, et al.: Testing a TheoRYinformed MEssage (&quot;TRY-ME&quot;): A Sub-trial Within a Randomized Controlled Trial of Printed Educational Materials (The Ontario Printed Educational Message (OPEM) Trial). Implementation Science 2006, 2(39):.","cites":null},{"id":17489835,"title":"The design and analysis of a randomized controlled trial to evaluate computerized decision support in primary care: the COGENT study. Fam Pract","authors":[],"date":"2000","doi":null,"raw":"Eccles M, Grimshaw J, Steen N, Parkin D, Purves I, McColl E, et al.: The design and analysis of a randomized controlled trial to evaluate computerized decision support in primary care: the COGENT study.  Fam Pract 2000, 17:180-186.","cites":null},{"id":17489843,"title":"The theory of planned behavior: a review of its applications to health-related behaviors.","authors":[],"date":"1996","doi":null,"raw":"Godin G, Kok G: The theory of planned behavior: a review of its applications to health-related behaviors.  Am J Health Promot 1996, 11:87-98.","cites":null},{"id":17489839,"title":"The theory of planned behaviour. Organizational Behaviour and Human Decision Process","authors":[],"date":"1991","doi":null,"raw":"Ajzen I: The theory of planned behaviour.  Organizational Behaviour and Human Decision Process 1991, 50:179-211.","cites":null},{"id":17489847,"title":"TR: Reported response rates to mailed physician questionnaires. Health Services Research","authors":[],"date":"2001","doi":null,"raw":"Cummings SM, Savitz LA, Konrad TR: Reported response rates to mailed physician questionnaires.  Health Services Research 2001, 35:1347-1355.","cites":null},{"id":17489856,"title":"Wermuth N: Multivariate dependencies: models, analysis, and interpretation Chapman and Hall Ltd;","authors":[],"date":"1998","doi":null,"raw":"Cox DR, Wermuth N: Multivariate dependencies: models, analysis, and interpretation Chapman and Hall Ltd; 1998.","cites":null}],"documentType":{"type":1}},"contributors":["University of Aberdeen, Medicine, Medical Sciences & Nutrition, Institute of Applied Health Sciences"],"datePublished":"2007","abstract":"Peer reviewedPublisher PD","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:aura.abdn.ac.uk:2164\/2042<\/identifier><datestamp>\n                2018-01-02T00:01:43Z<\/datestamp><setSpec>\n                com_2164_632<\/setSpec><setSpec>\n                com_2164_364<\/setSpec><setSpec>\n                com_2164_330<\/setSpec><setSpec>\n                com_2164_705<\/setSpec><setSpec>\n                col_2164_633<\/setSpec><setSpec>\n                col_2164_706<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nLooking inside the black box : A theory based process evaluation alongside a randomised controlled trial of printed educational materials (The Ontario Printed Educational Message (OPEM)) Trial<\/dc:title><dc:creator>\nZwarenstein, M.<\/dc:creator><dc:creator>\nTetroe, J.<\/dc:creator><dc:creator>\nGodin, G.<\/dc:creator><dc:creator>\nGraham, I.<\/dc:creator><dc:creator>\nLemyre, L.<\/dc:creator><dc:creator>\nEccles, M.<\/dc:creator><dc:creator>\nJohnston, Marie<\/dc:creator><dc:creator>\nFrancis, Jillian<\/dc:creator><dc:creator>\nHux, J.<\/dc:creator><dc:creator>\nLegare, F.<\/dc:creator><dc:creator>\nPresseau, J.<\/dc:creator><dc:contributor>\nUniversity of Aberdeen, Medicine, Medical Sciences & Nutrition, Institute of Applied Health Sciences<\/dc:contributor><dc:subject>\nR Medicine<\/dc:subject><dc:subject>\nR<\/dc:subject><dc:description>\nPeer reviewed<\/dc:description><dc:description>\nPublisher PDF<\/dc:description><dc:date>\n2011-04-27T12:15:01Z<\/dc:date><dc:date>\n2011-04-27T12:15:01Z<\/dc:date><dc:date>\n2007<\/dc:date><dc:type>\nJournal article<\/dc:type><dc:identifier>\nZwarenstein , M , Tetroe , J , Godin , G , Graham , I , Lemyre , L , Eccles , M , Johnston , M , Francis , J , Hux , J , Legare , F & Presseau , J 2007 , ' Looking inside the black box : A theory based process evaluation alongside a randomised controlled trial of printed educational materials (The Ontario Printed Educational Message (OPEM)) Trial ' Implementation Science , vol 2 , no. 38 , pp. 1-8 . DOI: 10.1186\/1748-5908-2-38<\/dc:identifier><dc:identifier>\n1748-5908<\/dc:identifier><dc:identifier>\nPURE: 312983<\/dc:identifier><dc:identifier>\nPURE UUID: 2e48b908-227c-49a6-9c77-e56ee1286ecc<\/dc:identifier><dc:identifier>\naberdeen_publication: 15248<\/dc:identifier><dc:identifier>\nScopus: 38749130082<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2164\/2042<\/dc:identifier><dc:identifier>\nhttp:\/\/dx.doi.org\/10.1186\/1748-5908-2-38<\/dc:identifier><dc:language>\neng<\/dc:language><dc:relation>\nImplementation Science<\/dc:relation><dc:format>\n8<\/dc:format>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["issn:1748-5908","1748-5908"]}],"language":{"code":"en","id":9,"name":"English"},"relations":["Implementation Science"],"year":2007,"topics":["R Medicine","R"],"subject":["Journal article"],"fullText":"BioMed CentralImplementation Science\nssOpen AcceStudy protocol\nLooking inside the black box: a theory-based process evaluation \nalongside a randomised controlled trial of printed educational \nmaterials (the Ontario printed educational message, OPEM) to \nimprove referral and prescribing practices in primary care in \nOntario, Canada\nJeremy M Grimshaw*\u20201,2, Merrick Zwarenstein\u20203,4, Jacqueline M Tetroe\u20201,6,12, \nGaston Godin\u20205, Ian D Graham\u20201,6,12, Louise Lemyre\u20202,7, Martin P Eccles\u20208, \nMarie Johnston\u20209, Jillian J Francis\u202010, Jan Hux\u20203, Keith O'Rourke\u20201, \nFrance L\u00e9gar\u00e9\u202011 and Justin Presseau\u20207\nAddress: 1Clinical Epidemiology Program, Ottawa Health Research Institute, Ottawa, Canada, 2Institute of Population Health, University of \nOttawa, Ottawa, Canada, 3Institute of Clinical Evaluative Sciences, Toronto, Canada, 4KT Program, University of Toronto, Canada, 5School of \nNursing, University of Laval, Quebec City, Canada, 6School of Nursing, University of Ottawa, Ottawa, Canada, 7School of Psychology, University \nof Ottawa, Ottawa, Canada, 8Centre for Health Services Research, University of Newcastle upon Tyne, Newcastle upon Tyne, UK, 9Department of \nPsychology, University of Aberdeen, Aberdeen, UK, 10Health Services Research Unit, University of Aberdeen, UK, 11Department of Family \nMedicine, University of Laval, Quebec City, Canada and 12Canadian Institute of Health Research, Ottawa, Canada\nEmail: Jeremy M Grimshaw* - jgrimshaw@ohri.ca; Merrick Zwarenstein - merrick.zwarenstein@ices.on.ca; Jacqueline M Tetroe - jtetroe@cihr-\nirsc.gc.ca; Gaston Godin - Gaston.Godin@fsi.ulaval.ca; Ian D Graham - igraham@cihr-irsc.gc.ca; Louise Lemyre - louise.lemyre@uottawa.ca; \nMartin P Eccles - martin.eccles@ncl.ac.uk; Marie Johnston - m.johnston@abdn.ac.uk; Jillian J Francis - j.francis@abdn.ac.uk; \nJan Hux - jan@ices.on.ca; Keith O'Rourke - korourke@ohri.ca; France L\u00e9gar\u00e9 - France.Legare@mfa.ulaval.ca; \nJustin Presseau - justin.presseau@alumni.uottawa.ca\n* Corresponding author    \u2020Equal contributors\nAbstract\nBackground: Randomised controlled trials of implementation strategies tell us whether (or not) an intervention results\nin changes in professional behaviour but little about the causal mechanisms that produce any change. Theory-based\nprocess evaluations collect data on theoretical constructs alongside randomised trials to explore possible causal\nmechanisms and effect modifiers. This is similar to measuring intermediate endpoints in clinical trials to further\nunderstand the biological basis of any observed effects (for example, measuring lipid profiles alongside trials of lipid\nlowering drugs where the primary endpoint could be reduction in vascular related deaths).\nThis study protocol describes a theory-based process evaluation alongside the Ontario Printed Educational Message\n(OPEM) trial. We hypothesize that the OPEM interventions are most likely to operate through changes in physicians'\nbehavioural intentions due to improved attitudes or subjective norms with little or no change in perceived behavioural\ncontrol. We will test this hypothesis using a well-validated social cognition model, the theory of planned behaviour (TPB)\nthat incorporates these constructs.\nMethods\/design: We will develop theory-based surveys using standard methods based upon the TPB for the second\nand third replications, and survey a subsample of Ontario family physicians from each arm of the trial two months before\nand six months after the dissemination of the index edition of informed, the evidence based newsletter used for the\nPublished: 26 November 2007\nImplementation Science 2007, 2:38 doi:10.1186\/1748-5908-2-38\nReceived: 30 January 2006\nAccepted: 26 November 2007\nThis article is available from: http:\/\/www.implementationscience.com\/content\/2\/1\/38\n\u00a9 2007 Grimshaw et al; licensee BioMed Central Ltd. \nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License (http:\/\/creativecommons.org\/licenses\/by\/2.0), \nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.Page 1 of 8\n(page number not for citation purposes)\nImplementation Science 2007, 2:38 http:\/\/www.implementationscience.com\/content\/2\/1\/38interventions. In the third replication, our study will converge with the \"TRY-ME\" protocol (a second study conducted\nalongside the OPEM trial), in which the content of educational messages was constructed using both standard methods\nand methods informed by psychological theory. We will modify Dillman's total design method to maximise response\nrates. Preliminary analyses will initially assess the internal reliability of the measures and use regression to explore the\nrelationships between predictor and dependent variable (intention to advise diabetic patients to have annual retinopathy\nscreening and to prescribe thiazide diuretics for first line treatment of uncomplicated hypertension). We will then\ncompare groups using methods appropriate for comparing independent samples to determine whether there have been\nchanges in the predicted constructs (attitudes, subjective norms, or intentions) across the study groups as hypothesised,\nand will assess the convergence between the process evaluation results and the main trial results.\nTrial registration number: Current controlled trial ISRCTN72772651\nBackground\nRecognition of the knowledge translation (KT) gap has led\nto increased interest in more active KT strategies. Over the\npast five years a considerable body of KT research has\ndeveloped [1,2]. This research demonstrates that profes-\nsional behaviour change interventions can be effective.\nHowever the effectiveness of interventions appears to vary\nacross different clinical problems, contexts, and organiza-\ntions, presumably due to the presence of different barriers\nand enablers to KT. Current quantitative evaluations of\nprofessional behaviour change strategies provide little\ninsight into the causal mechanisms through which inter-\nventions lead to behaviour change and how they are mod-\nerated by different barriers and enablers to KT. This limits\nthe ability to generalise from the findings of individual\nstudies to other clinical problems, contexts and organisa-\ntions. One of the challenges for KT researchers is to\ndevelop methods for exploring causal mechanisms along-\nside rigorous evaluations of different strategies.\nThe Ontario Printed Educational Materials \n(OPEM) trial\nThe OPEM trial (PI \u2013 MZ, Co-investigators JG, JH) is a\nlarge factorial cluster randomised trial [3]. Participants\nwill be randomised to one of four groups (control, short\ndirective messages only, long discursive messages only,\nand both short and long messages). The messages will be\nembedded in the informed newsletter. This is produced by\nthe Institute of Clinical Evaluative Sciences (ICES)\n(Ontario), and is a free, well regarded evidence-based\npractice synopsis, mailed quarterly since 1994 to 9,825\nsubscribers in Ontario, including all family practitioners\n(except 20 who opted to be removed from the mailing\nlist). The short directive educational messages will be pro-\nduced on a postcard-sized card stapled to the outside of\ninformed. The long educational messages will be produced\nas a two-page insert into informed (indistinguishable from\nthe rest of the periodical in size, style and editing) exclud-\ning the directive statements and including more back-\nground, an evidence-based guideline, and references.\nOPEM will involve three replicated randomized trials in\nthree successive editions of informed for three separate\ntracer conditions (assertive hypertension and cholesterol\ntreatment in diabetic patients, regular diabetic retinopa-\nthy screening, and use of thiazide diuretics in the initial\nmanagement of hypertension). Routinely collected\nadministrative data (OHIP, ODB and CIHI data) available\nwithin ICES will be used to measure changes in profes-\nsional behaviour for the four quarters before and after\neach intervention.\nProcess evaluations alongside randomized trials of \nprofessional behavior change strategies\nOPEM will be the largest and most rigorous evaluation of\nprinted educational materials to date. It will tell us\nwhether (or not) dissemination of printed educational\nmaterials results in changes in professional behaviour but\nnothing about the causal mechanisms that produce any\nchange. This would not be an issue if we expected that the\nintervention would have a uniform effect across different\nconditions that could be generalised to practitioners out-\nside of Ontario. However the current evidence base [4]\nindicates that the effects of interventions do appear to vary\nby condition, professional group, and context, presuma-\nbly because the causal mechanisms of the interventions\nare modified in the presence of different barriers and ena-\nblers. Therefore, the interpretation of the results of the\nOPEM trial and assessment of its likely generalisability\nwould be enhanced if we had additional information\nabout the causal mechanisms through which the interven-\ntion worked, and how these were modified in the pres-\nence of different barriers and enablers. There is increasing\nrecognition of the value of process evaluations alongside\ntrials of complex interventions such as professional\nbehaviour change interventions. Commonly, process\nevaluations have utilised qualitative methods to explore\nparticipants' attitudes toward and experiences of study\ninterventions. For example, ME and JMG conducted a\nnested qualitative study alongside a randomised trial of\ncomputerised decision support for chronic disease man-\nagement in UK primary care that identified that the inter-\nvention largely failed because of poor software\nimplementation that was not integrated into family prac-\ntitioners' work patterns [5,6]. Qualitative process evalua-Page 2 of 8\n(page number not for citation purposes)\nImplementation Science 2007, 2:38 http:\/\/www.implementationscience.com\/content\/2\/1\/38tions provide valuable information about context-specific\ninsights that can help interpret the results of an individual\ntrial, but may be less helpful in predicting the likely gen-\neralisability of findings due to the lack of standardised\nconstructs and measurements. In contrast, behavioural\nsciences have carefully developed and operationalised\ntheories concerning determinants of behaviour and\nbehaviour change. These standard definitions of con-\nstructs and measurement methods may be useful for\nexploring causal mechanisms of interventions and barri-\ners and enablers to knowledge translation.\nTheory-based process evaluations collect data on theoret-\nical constructs alongside randomised trials to explore pos-\nsible causal mechanisms and effect modifiers. This is akin\nto measuring intermediate endpoints in clinical trials to\nfurther understand the biological basis of any observed\neffects (for example, measuring lipid profiles alongside\ntrials of lipid lowering drugs where the primary endpoint\ncould be reduction in vascular related deaths). Ferlie and\nShortell [7] have suggested four levels at which knowledge\ntranslation interventions might operate: the individual\nhealth professional; health care groups or teams; organi-\nsations providing health care; and the larger health care\nsystem or environment in which individual organizations\nare embedded. Different types of theory will be relevant to\ninterventions at different levels. For example, psychologi-\ncal theories will be more relevant to interventions directed\nat individuals and teams, theories of organisational\nchange will be more relevant to interventions directed at\nhospitals or trusts, and so on. A full scientific rationale for\ninterventions to translate research findings into clinical\npractice requires exploration of theories relevant to each\nof these four levels.\nAims and objectives\n1. To conduct a theory-based process evaluation alongside\nthe OPEM trial.\n2. To advance the methodology of conducting theory-\nbased process evaluations alongside randomised trials of\nprofessional behaviour change strategies\nThe specific objectives of the project are:\n1. To develop theory-based survey instruments based\nupon the TPB (Phase I)\n2. To conduct pre- and post-intervention postal surveys\namong family physicians in Ontario using the survey\ninstruments for two of the OPEM study conditions (Phase\nII).\n3. To analyse whether the OPEM interventions lead to sig-\nnificant improvements in theoretical constructs of the TPB\n(intentions, attitudes, subjective norms, perceived behav-\nioural control) (Phase III).\n4. To test the convergence of the results of the OPEM main\ntrial and the theory-based process evaluation (Phase IV).\nMethods\/design\nProject overview\nAs described earlier, OPEM was originally conceived as a\ntwo-by-two factorial design. This design was modified for\nthe second and third iteration, transforming it into an\nincomplete two-by-three factorial randomised trial, for\nreasons documented in the OPEM trial protocol [3]. In\nthe second iteration, the additional two groups had a\nreminder note added to the short directive message, for-\nmatted as a pad of patient-aimed reminder slips (short\ndirective and pad, short directive and pad plus long dis-\ncursive message). In the third iteration, the additional two\ngroups had an outsert message developed based on the\nTPB, in comparison with the \"standard\" short messages\nsimilar to those developed for the first two iterations. The\ndevelopment of the psychologically informed outsert\nmessage is described in the \"TRY-ME\" Study Protocol [8].\nTable 1 describes the groups in each iteration.\nTheory-based process evaluations collect data on theoret-\nical constructs alongside randomized trials to explore\npotential causal mechanisms. We hypothesize that the\nOPEM intervention causes changes in physicians' inten-\ntions due to improved attitudes or subjective norms with\nlittle or no change in perceived behavioural control. We\nwill test this hypothesis using the TPB model that incorpo-\nrates these constructs [9]. We will develop theory-based\nsurveys using standard methods [10,11] based upon the\nTPB for the second and third replications, and survey a\nsubsample of recipients from each arm of the trial two\nmonths before and six months after the dissemination of\nthe index edition of informed (given the timing of the\nfunding application and decision, we were unable to con-\nduct a theory-based replication for the first replication of\nthe OPEM trials). We will use Dillman's total design\nmethod to maximise response rates [12]. Analysis initially\nwill assess the internal reliability of the measures, and use\nregression to explore the relationships between predictor\nand dependent variable (intention to undertake the rec-\nommended practice). We will then compare groups using\nmethods appropriate for comparing independent samples\n(t-tests to compare two groups, analysis of covariance to\ncompare groups adjusting for differences in baseline per-\nformance) to determine whether there have been changes\nin the predicted constructs (attitudes, subjective norms or\nintentions) across the study groups as hypothesised. We\nwill use the Cox-Wermuth method (described below) for\nexploring dependencies and associations within systems\nto explore whether there is convergence between the the-Page 3 of 8\n(page number not for citation purposes)\nImplementation Science 2007, 2:38 http:\/\/www.implementationscience.com\/content\/2\/1\/38ory-based process evaluation results and the main trial\nresults.\nPhase 1. Development of survey instruments\nWe will develop the survey instrument using standard\nmethods [10]. TPB instruments can be developed based\nupon direct measures of the TPB constructs, or based on\nbelief measures of the TPB constructs. The direct measures\nare relatively straightforward to develop and are relatively\nshort and easy to complete (three to five items per con-\nstruct, i.e., a total of 15\u201320 items). In contrast, belief-\nbased measures are more complex to develop, and are\nconsiderably longer and more complex to complete.\nBelief-based measures are likely to be most beneficial if\nthe aim is content-focused, that is if the goal is to identify\nspecific beliefs that could be effectively targeted by an edu-\ncational intervention. In the present study, the aim is to\nidentify the causal mechanisms through which the OPEM\ninterventions do or do not work; direct measure surveys\nare generally sufficient for this purpose and are more\nlikely to be acceptable to physicians especially for\nrepeated surveys.\nWe therefore plan to use a direct measure survey. Careful\nspecification of the behavior is essential during the devel-\nopment of TPB surveys. We will decide on the specifica-\ntion of the behavior based on drafts of the short and long\neducational messages and the primary outcome for the\nOPEM trial. The specified behavior will be defined in terms\nof the TACT (target, action, context and time) principle\n(for example, prescribing diuretics as the first line treat-\nment in newly diagnosed elderly hypertensive patients in\nthe next six months). We will measure generalized inten-\ntion via respondents' responses to three items measured\non a seven point response format (\"I will <behaviour>\", \"\nI plan to <behaviour>\", and \"I intend to <behaviour>\".\nFor example, \"I plan to prescribe thiazide diuretics in\nnewly diagnosed elderly hypertensive patients in the next\nsix months\"). Our direct measure of attitude will use a\ncommon stem (for example, \"For me, prescribing thiazide\ndiuretics in newly diagnosed elderly hypertensive patients\nin the next six months would be: ...\") and four items using\nevaluative bipolar adjectives with a seven point response\nformat (for example, \"good practice...bad practice\"). We\nwill use both instrumental items (reflecting whether the\nbehavior achieves something, for example, \"<behaviour>\nis necessary..... unnecessary\") and experiential items\n(reflecting how the respondents feel when performing the\nbehaviour, for example, \"satisfying..... not satisfying\").\nThe specification of the bipolar adjectives will be consid-\nered carefully during both the development and pilot test-\ning of the interview. Our direct measure of subjective\nnorms will involve three items with a seven point\nresponse format anchored by \"strongly agree\" to \"strongly\ndisagree\" (for example, \"Most people who are important\nto me think that <behaviour>\", \"It is expected of me that\nI <behaviour>\", and \"I feel under social pressure to\n<behaviour>\", for example, \"I think most general practi-\ntioners\/family physicians would approve of me prescrib-\ning thiazide diuretics in newly diagnosed elderly\nhypertensive patients in the next six months\"). Our direct\nmeasure of perceived behavioral control will involve four\nitems with a seven point response format. We will use\nitems relating to both difficulty (whether the respondent\nthinks that she can actually do the behavior, e.g., \"Doing\nthe <behavior> is difficult for me\",\"I am confident that I\ncould <behavior>\"), and controllability (whether the\nrespondent believes that she is in control of the behavior,\ne.g., \"There are factors outside of my control that would\nprevent me from prescribing thiazide diuretics in newly\ndiagnosed elderly hypertensive patients in the next six\nmonths\"). We will distribute items throughout the ques-\ntionnaire so that questions used to assess different meas-\nures are interspersed to avoid a response set bias. We will\nalso measure habit (past behaviour) by asking the\nrespondents: \"Thinking about your last ten elderly\nTable 1: Description of the intervention groups within the two replicates of the OPEM Trial\nREPLICATE 2: Retinal screening for patients with diabetes\nInsert No insert\nOUTSERT Patient Reminder Note 1. Insert & Outsert & Patient Reminder 2. Outsert & Patient Reminder Note\nNo Patient Reminder Note 3. Insert & Outsert 4. Outsert only\nNO OUTSERT 5. Insert Only 6. No PEM\nREPLICATE 3: Diuretics for first-line treatment of hypertension\nInsert No insert\nOUTSERT Theory-based Outsert 1. Insert & Theory-based Outsert 2. Theory-based Outsert Only\nNon-theory-based outsert 3. Insert & Non-theory-based Outsert 4. Non-theory-based Outsert only\nNO OUTSERT 5. Insert Only 6. No PEMPage 4 of 8\n(page number not for citation purposes)\nImplementation Science 2007, 2:38 http:\/\/www.implementationscience.com\/content\/2\/1\/38patients newly diagnosed with uncomplicated hyperten-\nsion, for how many of them did you prescribe thiazide\ndiuretics as a first-line drug treatment?\" The survey will\nalso include demographic questions to provide informa-\ntion about the sample.\nWe anticipate that each survey will have 15\u201320 items and\ncould be completed by practitioners in 5 \u2013 7.5 minutes.\nInitial drafts of each survey will be circulated within the\nOPEM, and OPEM theory-based process evaluation\nproject teams to ensure face and content validity. We will\npilot each survey with six family physicians using a semi-\nstructured interview format.\nScoring of measures\nMeasures of generalised intention, attitudes, subjective\nnorms and perceived behavioural controls will be calcu-\nlated as the mean of the measure item scores.\nCopies of the survey instruments are available upon\nrequest.\nPhase II. Postal survey implementation\nThe OPEM trial team will provide us with a sampling\nframe for the surveys. Physicians sampled for the first con-\ndition (regular diabetic retinopathy screening) will be\nexcluded from the sampling frame for the second condi-\ntion (diuretics for hypertension). The surveys will be\nadministered using a modification of Dillman's tailored\ndesign method for mail surveys [12]. This will involve\nsending a cover letter with the initial survey mail to\nexplain the purpose of the survey, why completing it is\nimportant, how the results might be used, and the confi-\ndentiality of survey results. A reminder post card will be\nsent at week two with a replacement questionnaire at\nweeks four and six. Respondents will be offered the\noption of faxing the survey back to us. Cummings et al\nfound an average response rate of 61% in a random sam-\nple of studies using surveys mailed to physicians [13]. To\nhelp promote an acceptable response rate, the question-\nnaire will be kept to a maximum of two pages in length.\nIn addition, we will provide $20 (CDN) to every physi-\ncian who returns a completed questionnaire in recogni-\ntion of the time required to complete the survey. Multiple\nstudies have demonstrated that financial incentives\nincrease response rates among both the public and physi-\ncians [11,13,14]. Physicians will be encouraged to return\na blank questionnaire if they do not wish to participate in\nthe study and will be deleted from the sampling frame.\nThe pre-intervention surveys will be sent eight weeks\nbefore the distribution date for the relevant informed\nnewsletter, and the post-intervention surveys will be sent\nto respondents of the pre-intervention survey six months\nafter the distribution date.\nQuality assurance procedures will be implemented to\nensure the integrity of the survey data collection [15,16].\nAll aspects of the protocol will be elaborated in a detailed\nprotocol manual for the study team. For the survey, a log\nrecord will be initiated and maintained to track the study\nstatus of participants throughout the mailings of the sur-\nvey. They will be assigned a code number to be used on all\nsubsequent study documentation to ensure confidential-\nity.\nData monitors to assess data entry accuracy will check a\nrandomly selected sample (ten percent) of surveys. An\nerror rate greater than 1% will be considered unaccepta-\nble, requiring all cases to be re-entered and rechecked.\nPhase III. Planned analyses\nWe will test internal reliability of the measures using\nCronbach's alpha. If internal consistency is <0.7, we will\nexplore whether we can improve this by omitting any\nindividual item. We will use regression to explore the rela-\ntionships between predictor (attitudes, subjective norms,\nperceived behavioural control) and dependent variable\n(intention to undertake the recommended practice). If the\ndependent variable is markedly skewed, we will use gen-\neralized linear modelling regression to allow for this [17].\nWe will then compare groups using methods appropriate\nfor comparing independent samples (t-tests to compare\ntwo groups, analysis of covariance to compare groups\nadjusting for differences in baseline performance) to\ndetermine whether there have been changes in the predic-\ntor constructs (attitudes, subjective norms, perceived\nbehavioural control or intentions) across the study groups\nas hypothesised.\nFurther analysis will be informed and guided by the\napproach developed by D.R. Cox and N. Wermuth [18].\nTheir approach is directed more at the study of dependen-\ncies and associations with the objective of \"understand-\ning\" the system under study, rather than just a \"black box\"\nempirical determination of the presence or absence of\neffects. This understanding is in the sense of gaining some\nknowledge of the underlying process, gaining some\ninsight into the ability to predict in differing contexts, and\nrelating the particular data under analysis to current\nknowledge of the field in question. The analyses proceeds\nby grouping variables into responses, intermediate\nresponses, and explanatory variables, usually in blocks\nover time, and utilizing fairly standard and well-under-\nstood statistical regression methods to investigate the\ndependencies between blocks and within blocks. If the\ndependencies within blocks can be safely ignored, the\napproach is implemented with just a number of simple\nregression analyses, all involving univariate responses. For\nexample, the regression methods can be a combination ofPage 5 of 8\n(page number not for citation purposes)\nImplementation Science 2007, 2:38 http:\/\/www.implementationscience.com\/content\/2\/1\/38linear and generalized linear regressions appropriate for\nthe various responses, and non-linear if required to prop-\nerly model the effects of various covariates. The approach\noffers an alternative to structural equations modelling\nthat allows the use of standard statistical techniques and\nthe interpretation of parameters as regression coefficients.\nAnalysis will initially use multiple regression analysis to\nexplore the relationships between predictor and depend-\nent variable (intention to undertake the recommended\npractice). This analysis will allow us to explore whether\nthere is convergence between the treatment effects of the\ntheory-based process evaluation and the main trial results.\nSample size considerations\nA simple and often used approach to calculating the\nrequired sample size for two-by-two factorial trials is to\ncalculate sample size for a two group study and then use\nthe number per group for the four groups in the two-by-\ntwo factorial trial. In our case, using standard methods for\ncontinuous outcomes, we need 63 subjects per group to\nachieve 80% power of detecting an effect size of 0.5 stand-\nard deviations using a significance level of 5%, giving a\ntotal sample size of 252 for each experiment. Assuming a\n50% response rate for each survey (pre- and post-interven-\ntion), we will mail the survey to 252 physicians per group\nto achieve this sample size (i.e. 50%, or 126 per group,\ncomplete the first survey and 50% of these, or 63 per\ngroup, complete the second survey).\nWe performed a simulation to further investigate and\ndemonstrate the appropriateness of this simple sample\nsize calculation for our study. In the simulation, we ran-\ndomly generated scores for each of the four groups,\nequally for the null hypothesis and alternatively with the\nmean of the second and fourth groups 0.5 standard devi-\nations larger (alternative hypothesis of one main effect for\nshort directive messages and no interaction). This data\nwas then analyzed as a two-by-two factorial experiment\nwhere significance first was determined for any effect\n(Global F test), and then if significant, significance for\nmain effects was determined. We simulated these trials\n10,000 times (to give a standard error less than 0.5%) and\nunder the null hypothesis the Global F test was significant\n4.97% of the simulations, while under the alternative\nhypotheses the Global F test was significant 92.45% of the\nsimulations, and the test for main effects for short direc-\ntive messages significant 99.80% of the simulations, to\nprovide an observed power for the main effect of 92.27%.\nIn an additional simulation in which the fourth group\nmean was set only 0.35 standard deviations larger (repre-\nsenting a negative interaction where 30% of the short\ndirective message effect is negated by the addition of long\ndiscursive messages), the main effect for short directive\nmessages was still significant 82.56% of the simulations.\nTo take into account the change in the OPEM trial from\nfour to six groups, the design was switched to a two-by-\nthree design (outsert, insert, post-it note\/theory-based\noutsert) that omitted observations of post-it\/theory-based\noutsert without insert (six groups observed) and the sur-\nvey was mailed to 252 physicians per group.\nEthical Approval\nThis study has received approval from the Research Ethics\nBoard at The Ottawa Hospital.\nDiscussion\nThis is one of the first prospective theory-based process\nevaluations with both baseline and post-intervention\nmeasurement; it will contribute to both theoretical and\nmethodological developments in implementation sci-\nence. The process evaluation of the OPEM trial provided\nby our TPB-based surveys will permit an analysis of the\ncausal mechanisms of any observed change in the two tar-\ngeted behaviours. We anticipate that the results will be\nprimarily of interest to KT researchers and behavioural sci-\nentists, and those in disciplines interested in the determi-\nnants of behaviour and behaviour change.\nThe major limitation of the study is our inability to link,\nat an individual health care professional level, the results\nof the theoretical measures and the clinical behaviours.\nThis is similar to the meta-analysis context, where in a\nmeta-regression the group average covariate score is\nregressed against observed group outcomes \u2013 but in our\ncase the average covariate score is not based on the whole\ngroup, but just a subset of it that may be self-selected and\nsomewhat non-representative [19,20]. This requires some\nexplicit consideration of potential biases in any formal\nmediation analysis [21] The proposed Cox and Wermuth\napproach was developed in the context of potentially\nbiased observational data with the intent of developing\ninterpretations which aim to be explanatory in as deep a\nsense as is feasible.\nWe can envisage a number of different scenarios (Table 2):\nScenario A: The OPEM trial observes improvements in \nclinical behaviours and the theory-based process \nevaluation observes improvements in our hypothesised \nmediators (attitudes, subjective norms and intentions)\nThis would suggest that the educational materials may\nhave changed behaviour through our hypothesised medi-\nators.\nScenario B: The OPEM trial observes improvements in \nclinical behaviours and the theory-based process \nevaluation observes no improvements in our hypothesised \nmediators\nThere are four possible explanations: First. that the OPEM\nintervention operated through other mediating mecha-Page 6 of 8\n(page number not for citation purposes)\nImplementation Science 2007, 2:38 http:\/\/www.implementationscience.com\/content\/2\/1\/38nisms. Second, that the theoretical measures that we used\nare not sensitive predictors of behaviour change (e.g., by\nresulting in data with limited variance). Third, that post\nintentional factors (not captured in our theoretical meas-\nures) mediated or moderated the effects of the interven-\ntion with the result that family practitioners acted even\nthough they were not distinguished by any difference in\nintentions. Fourth, that there was a selection bias in the\ntheory-based process evaluation with responders not\nbeing representative of the family practitioners in the\nOPEM trial.\nScenario C: The OPEM trial observes no improvement in \nclinical behaviours and the theory-based process \nevaluation observes improvements in our hypothesised \nmediators\nAgain, there are three possible explanations. First, the\nintervention led to changes in the mediators that were not\nsufficient to result in behaviour change (a threshold\nhypothesis). Second, that post-intentional factors (not\ncaptured in our theoretical measures, for example, envi-\nronmental or organisational barriers) mediated or moder-\nated the effects of the intervention with the result that\nfamily practitioners did not (or could not) act upon their\nimproved intentions (an intention-behaviour gap\nhypothesis). Third, there was a selection bias associated\nwith responders being non representative of the family\npractitioners in the OPEM trial.\nScenario D: The OPEM trial observes no improvement in \nclinical behaviours and the theory-based process \nevaluation observes no improvements in our hypothesis \nmediators\nThis would suggest that the intervention did not influence\neither our hypothesised mediators or the clinical behav-\niour (given available power to detect such, or the confi-\ndence interval ruling out important effects). If baseline\nmeasures of our hypothesised mediators are high, this\nmight suggest that the barriers to evidence-based practice\ndid not relate to knowledge, attitudes, and intentions, and\ntherefore the intervention was unlikely to lead to\nimprovements in clinical behaviour.\nInformation about potential barriers not relating to our\nhypothesised mediators will be captured in the open-\nended questions of the surveys, and will allow us to\nexplore whether family practitioners believe there are\nadditional factors that might mediate or moderate the\neffects of the intervention. We will explore the extent of\nselection bias in responders to the theory-based process\nevaluation using routinely available data.\nWe anticipate that scenarios A and D are most likely, and\nplan to make predictions about the expected results of the\nOPEM trial based upon the theory-based process evalua-\ntion results that will be available before the OPEM trial\nresults.\nA further potential limitation of our study is that change\nin physician behaviour via printed educational materials\nis wholly dependent upon exposure to them. Dissemina-\ntion of the inserts and outserts in informed does not guar-\nantee that physicians will read them. However, in 1997\nThe Strategic Counsel Inc. contacted 500 Ontario physi-\ncians by phone to determine recall and readership of\ninformed. They found that 71% of respondents recalled\nreceiving informed, that 89% found it useful or very use-\nful, and that 53% of those who recalled receiving it read\nmost or every issue. This has important implications for\nthis process evaluation, as potential changes on socio-cog-\nnitive constructs underlying behaviour are obviously\ndependent on exposure to and cognitive processing of the\nprinted educational materials. This potential limitation is\nrecognised in the pragmatic design of OPEM trial which is\nattempting to evaluate whether printed educational mate-\nrials are likely to be effective in real world settings.\nAbbreviations\nCIHI \u2013 Canadian Institute for Health Information\nCIHR \u2013 Canadian Institutes of Health Research\nICES \u2013 Institute for Clinical Evaluative Sciences\nODB \u2013 Ontario Drug Benefit Program\nTable 2: Possible scenarios about the congruence between the results of the OPEM trial and the theory-based process evaluation\nTheory-based process evaluation result\n+ -\nOPEM trial results + A B\n- C DPage 7 of 8\n(page number not for citation purposes)\nImplementation Science 2007, 2:38 http:\/\/www.implementationscience.com\/content\/2\/1\/38Publish with BioMed Central   and  every \nscientist can read your work free of charge\n\"BioMed Central will be the most significant development for \ndisseminating the results of biomedical research in our lifetime.\"\nSir Paul Nurse, Cancer Research UK\nYour research papers will be:\navailable free of charge to the entire biomedical community\npeer reviewed and published immediately upon acceptance\ncited in PubMed and archived on PubMed Central \nyours \u2014 you keep the copyright\nSubmit your manuscript here:\nhttp:\/\/www.biomedcentral.com\/info\/publishing_adv.asp\nBioMedcentral\nOHIP \u2013 Ontario Health Insurance Plan\nOPEM \u2013 Ontario Printed Educational Material\nTPB \u2013 Theory of Planned Behaviour\nCompeting interests\nThe author(s) declare that they have no competing inter-\nests.\nAuthors' contributions\nAll authors contributed to the development of this study.\nAll authors read and approved the final manuscript.\nAcknowledgements\nThe OPEM trial and OPEM process evaluation are funded by the Canadian \nInstitute of Health Research (CIHR). The OPEM process evaluation study \nwas developed as part of the CIHR funded interdisciplinary capacity \nenhancement team KT-ICEBeRG. Gaston Godin, Jeremy Grimshaw and \nFrance L\u00e9gar\u00e9 hold Canada Research Chairs. Louise Lemyre holds an R.S. \nMcLaughlin Research Chair.\nReferences\n1. Bero LA, Grilli R, Grimshaw JM, Harvey E, Oxman AD, Thomson MA:\nClosing the gap between research and practice: an overview\nof systematic reviews of interventions to promote the imple-\nmentation of research findings. The Cochrane Effective\nPractice and Organization of Care Review Group.  BMJ 1998,\n317:465-468.\n2. NHS Centre for Reviews and Dissemination: Getting evidence\ninto practice.  Effective Health Care Bulletin 1999, 5:1-16.\n3. Zwarenstein M, Hux JE, Kelsall DL, Paterson JM, Grimshaw JM, Davis\nDA, et al.: The Ontario Printed Educational Message Trial\n(OPEM).  Implementation Science 2005 in press.\n4. Grimshaw JM, Thomas RE, MacLennan G, Fraser C, Ramsay C, Vale\nL, et al.: Effectiveness and efficiency of guideline dissemination\nand implementation strategies.  Health Technol Assess 2004, 8:.\n5. Eccles M, Grimshaw J, Steen N, Parkin D, Purves I, McColl E, et al.:\nThe design and analysis of a randomized controlled trial to\nevaluate computerized decision support in primary care: the\nCOGENT study.  Fam Pract 2000, 17:180-186.\n6. Rousseau N, McColl E, Newton J, Grimshaw J, Eccles M: Practice\nbased, longitudinal, qualitative interview study of computer-\nised evidence based guidelines in primary care.  BMJ 2003,\n326:314.\n7. Ferlie EB, Shortell SM: Improving the quality of health care in\nthe United Kingdom and the United States: a framework for\nchange.  The Milbank Quarterly 2001, 79:281-315.\n8. Francis J, Grimshaw JM, Zwarenstein M, Eccles MP, Shiller S, Johston\nM, O'Rourke K, Presseau J, Tetroe J, et al.: Testing a TheoRY-\ninformed MEssage (\"TRY-ME\"): A Sub-trial Within a Rand-\nomized Controlled Trial of Printed Educational Materials\n(The Ontario Printed Educational Message (OPEM) Trial).\nImplementation Science 2006, 2(39):.\n9. Ajzen I: The theory of planned behaviour.  Organizational Behav-\niour and Human Decision Process 1991, 50:179-211.\n10. Francis JJ, Eccles MP, Johnston M, Walker AE, Grimshaw JM, Foy R, et\nal.: Constructing questionnaires based on the theory of\nplanned behaviour.  In A manual for health services researchers Cen-\ntre for Health Services Research, University of Newcastle upon Tyne,\nUK; 2004. \n11. Godin G, Kok G: The theory of planned behavior: a review of\nits applications to health-related behaviors.  Am J Health Promot\n1996, 11:87-98.\n12. Dillman D: Mail and internet surveys.  In The tailored design method\n2nd edition. New York: John Wiley; 2000. \n13. Cummings SM, Savitz LA, Konrad TR: Reported response rates to\nmailed physician questionnaires.  Health Services Research 2001,\n35:1347-1355.\n14. Field JL, Cadoret CA, Brown ML, Ford M, Greene SM, Hill J, et al.:\nSurveying Physicians. Do components of the\"Total Design\nApproach\" to optimizing survey response rates apply to phy-\nsicians?  Med Care 2002, 40:596-606.\n15. Rabaneck L, Viscole CM, Horwitz RJ: Problems in the conduct\nand analysis of randomized clinical trials.  Archives of Internal\nMedicine 1992, 152:507-512.\n16. Gilliss CL, Kulkin IL: Monitoring nursing interventions and data\ncollection in a randomized clinical trial.  Western Journal of Nurs-\ning Research 1991, 13:416-422.\n17. McCullagh P, Nelder JA: Generalized linear models London: Chapman\n& Hall Ltd; 1999. \n18. Cox DR, Wermuth N: Multivariate dependencies: models, analysis, and\ninterpretation Chapman and Hall Ltd; 1998. \n19. Greenland S, O\"Rourke K: Meta-Analysis.  In Modern Epidemiology\n3rd edition. Edited by: Rothman KJ, Greenland S, Lash T. Lippincott\nWilliams and Wilkins; 2007 in press. \n20. Thompson SG, Higgins JP: How should meta-regression analyses\nbe undertaken and interpreted?  Stat Med 2002, 15:1559-1573.\n21. Shadish WR, Cook TD, Campbell DT: Experimental and Quasi-Experi-\nmental Designs for Generalized Causal Inference Boston: Houghton-Mif-\nflin; 2002. Page 8 of 8\n(page number not for citation purposes)\n"}
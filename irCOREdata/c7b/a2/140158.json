{"doi":"10.1007\/s10846-010-9397-8","coreId":"140158","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/5426","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/5426","10.1007\/s10846-010-9397-8"],"title":"Multidisciplinary design optimization framework for the pre design stage","authors":["Guenov, Marin D.","Fantini, Paolo","Balachandran, Libish Kalathil","Maginot, Jeremy","Padulo, Mattia","Nunez, Marco"],"enrichments":{"references":[{"id":37965913,"title":"Computational workflow management for conceptual design of complex systems: An Air-vehicle Design Perspective. PhD Thesis,","authors":[],"date":"2007","doi":null,"raw":"Balachandran L. K.: Computational workflow management for conceptual design of complex systems: An Air-vehicle Design Perspective. PhD Thesis, Cranfield University, Cranfield, UK (2007)","cites":null},{"id":37965914,"title":"A procedure for robust design: Minimizing variations caused by noise factors and control factors.","authors":[],"date":"1996","doi":"10.1115\/1.2826915","raw":"Chen, W., Allen, J.: A procedure for robust design: Minimizing variations caused by noise factors and control factors. Journal of Mechanical Design, 118(4), pp. 478\u2013493 (1996)","cites":null},{"id":37965917,"title":"Non-Linear Sensitivity Analysis of Multi-Parameter Model Systems.","authors":[],"date":"1978","doi":"10.1016\/0021-9991(78)90097-9","raw":"Cukier, R.I., Levine, H.B., Shuler, K.E.: Non-Linear Sensitivity Analysis of Multi-Parameter Model Systems. Journal of Computational Physics, Vol. 26, No. 1, pp. 1-42 (1978)","cites":null},{"id":37965919,"title":"Normal-Boundary Intersection: A New Method for Generating the Pareto Surface in Nonlinear Multicriteria Optimization Problems.","authors":[],"date":"1998","doi":"10.1137\/s1052623496307510","raw":"Das, I., Dennis, J.E.: Normal-Boundary Intersection: A New Method for Generating the Pareto Surface in Nonlinear Multicriteria Optimization Problems. SIAM Journal of Optimization, vol. 8, pp. 631-657 (1998)","cites":null},{"id":37965920,"title":"An Improved Technique for Choosing Parameters for Pareto Surface Generation Using Normal-Boundary Intersection. In:","authors":[],"date":"1999","doi":null,"raw":"Das, I.: An Improved Technique for Choosing Parameters for Pareto Surface Generation Using Normal-Boundary Intersection. In: Proceedings of the Third World Congress of Structural and Multidisciplinary Optimization WCSMO-3, Buffalo, NY, March 1999","cites":null},{"id":37965921,"title":"Effective Multiobjective MDO for Conceptual Design - An Aircraft Design Perspective. PhD Thesis,","authors":[],"date":"2007","doi":null,"raw":"Fantini, P.:  Effective Multiobjective MDO for Conceptual Design -  An Aircraft Design Perspective. PhD Thesis, Cranfield University, Cranfield, UK (2007) 14","cites":null},{"id":37965922,"title":"M.D.: Computational Intelligence in Multi Disciplinary Optimization at Conceptual Design Stage. In:","authors":[],"date":"2007","doi":"10.1051\/ijsmdo:2008024","raw":"Fantini, P., Balachandran, L.K.,  Guenov, M.D.:  Computational Intelligence in Multi Disciplinary Optimization at Conceptual Design Stage. In:  Proceedings of the First International Conference on Multidisciplinary Design Optimization and Applications, Besancon, France, April 2007","cites":null},{"id":37965923,"title":"Computational Design Process Modelling. In:","authors":[],"date":"2006","doi":null,"raw":"Guenov, M.D., Libish, Tang, D., Lockett, H.: Computational Design Process Modelling. In: Proceedings of 25th International Council of the Aeronautical Sciences, Hamburg, Germany, September 2006","cites":null},{"id":37965924,"title":"Application of the Modified Physical Programming Method to Generating the Entire Pareto Frontier in Multiobjective Optimization. In:","authors":[],"date":"2005","doi":"10.1016\/j.cam.2008.03.011","raw":"Guenov, M.D., Utyuzhnikov, S.V.,  Fantini, P.:  Application of the Modified Physical Programming Method to Generating the Entire Pareto Frontier in Multiobjective Optimization. In: Proceedings of EUROGEN 2005, Munich, Germany, September 2005","cites":null},{"id":37965925,"title":"Sensitivity analysis for multidisciplinary design optimization.","authors":[],"date":"2007","doi":null,"raw":"Maginot, J.:  Sensitivity analysis for multidisciplinary design optimization.  PhD  Thesis, Cranfield University, Cranfield, UK (2007)","cites":null},{"id":37965926,"title":"A method for assisting the study of Pareto solutions in multi-objective optimization. In:","authors":[],"date":"2007","doi":"10.2514\/6.2007-7792","raw":"Maginot, J., Guenov, M.D., Fantini, P., Padulo, M.: A method for assisting the study of Pareto solutions in multi-objective optimization. In: Proceedings of the 7 th AIAA\/ATIO Conference, Belfast, Northern Ireland, September 2007","cites":null},{"id":37965927,"title":"A.: Minimal Representation of Multiobjective Design Space Using Smart Pareto Filter. In:","authors":[],"date":"2002","doi":"10.2514\/6.2002-5458","raw":"Mattison, C.A., Mullur, A.A., Messac, A.: Minimal Representation of Multiobjective Design Space Using Smart Pareto Filter. In:  Proceeding of the 9 th  AIAA\/ISSMO Symposium on Multidisciplinary Analysis and Optimization, Atlanta, GA, September 2002","cites":null},{"id":37965928,"title":"C.A.: Generating Well-Distributed Sets of Pareto Points for Engineering Design using Physical Programming.","authors":[],"date":"2002","doi":null,"raw":"Messac A., Mattson C.A.: Generating Well-Distributed Sets of Pareto Points for Engineering Design using Physical Programming. Optimization and Engineering, Kluwer Publishers, Vol. 3, Issue 4, pp. 431-450 (2002)","cites":null},{"id":37965929,"title":"C.A.: The Normalized Normal Constraint Method for Generating the Pareto Frontier.","authors":[],"date":"2003","doi":"10.1007\/s00158-002-0276-1","raw":"Messac, A., Ismail-Yahaya, A., Mattson, C.A.: The Normalized Normal Constraint Method for Generating the Pareto Frontier. Journal of the International Society of Structural and Multidisciplinary Optimization (ISSMO), Springer, Vol. 25, No. 2, pp. 86-98 (2003)","cites":null},{"id":37965930,"title":"Normal Constraint Method with Guarantee of Even Representation of Complete Pareto Frontier.","authors":[],"date":"2004","doi":"10.2514\/1.8977","raw":"Messac, A., Mattson, C.: Normal Constraint Method with Guarantee of Even Representation of Complete Pareto Frontier. AIAA Journal, Vol. 42, No. 10, pp. 2101-2111 (2004)","cites":null},{"id":37965931,"title":"Physical Programming: Effective Optimization for Computational Design.","authors":[],"date":"1996","doi":"10.2514\/3.13035","raw":"Messac, A.: Physical Programming: Effective Optimization for Computational Design. AIAA Journal, Vol. 34, No. 1, pp. 149-158 (1996)","cites":null},{"id":37965932,"title":"Nonlinear Multiobjective Optimization.","authors":[],"date":"1999","doi":"10.1007\/978-1-4615-5563-6","raw":"Miettinen, K.M.: Nonlinear Multiobjective Optimization. Kluwer Academic, Boston (1999)","cites":null},{"id":37965933,"title":"J.K.: A review of robust design methods for multiple responses.","authors":[],"date":"2005","doi":"10.1007\/s00163-005-0004-0","raw":"Murphy, T.E.,  Tsui, K.L., Allen  J.K.:  A review of robust design methods for multiple responses. Research in Engineering Design, 16, pp.118\u2013132 (2005)","cites":null},{"id":37965934,"title":"M.D.: Comparative Analysis of Uncertainty Propagation methods for Robust Engineering Design. In:","authors":[],"date":"2007","doi":"10.2514\/1.j050448","raw":"Padulo, M., Campobasso, M.S.,  Guenov, M.D.:  Comparative Analysis of Uncertainty Propagation methods for Robust Engineering Design. In: Proceedings of the International Conference on Engineering Design ICED07, Paris, August 2007","cites":null},{"id":37965935,"title":"K.H.: Robust Design: An Overview.","authors":[],"date":"2006","doi":"10.2514\/1.13639","raw":"Park, G.J., Lee, T.H., Hwang, K.H.: Robust Design: An Overview. AIAA Journal, 44(1), pp. 181\u2013191 (2006)","cites":null},{"id":37965936,"title":"Sensitivity Analysis.","authors":[],"date":"2000","doi":"10.2307\/1270993","raw":"Saltelli, A., Chan, K., Scott, M.: Sensitivity Analysis. John Wiley & Sons, New York (2000)","cites":null},{"id":37965937,"title":"Sensitivity Analysis in Practice: a guide to assessing scientific models.","authors":[],"date":"2004","doi":"10.1002\/0470870958","raw":"Saltelli, A., Tarantola, S., Campolongo, F., and Ratto, M.: Sensitivity Analysis in Practice: a guide to assessing scientific models. John Wiley & Sons, Chichester (2004)","cites":null},{"id":37965938,"title":"An alternative way to compute Fourier Amplitude Sensitivity Test (FAST).","authors":[],"date":"1998","doi":"10.1016\/s0167-9473(97)00043-1","raw":"Saltelli, A., Bolado, R.: An alternative way to compute Fourier Amplitude Sensitivity Test (FAST). Computational Statistics & Data Analysis, Vol. 26, No. 4, pp. 445-460 (1998)","cites":null},{"id":37965939,"title":"Sensitivity Estimates for non-linear mathematical models.","authors":[],"date":"1993","doi":null,"raw":"Sobol\u2019, I.M.:  Sensitivity Estimates for non-linear mathematical models. Mathematical Modelling & Computational Experiments, Vol. 1, No. 4, pp. 407-414 (1993) 15","cites":null},{"id":37965940,"title":"Global sensitivity indices for non-linear mathematical models and their Monte Carlo estimates.","authors":[],"date":"2001","doi":"10.1016\/s0378-4754(00)00270-6","raw":"Sobol\u2019, I.M.: Global sensitivity indices for non-linear mathematical models and their Monte Carlo estimates. Mathematics and Computers in Simulation, Vol. 55, pp. 271-280 (2001)","cites":null},{"id":37965941,"title":"M.D.: Numerical Method for Generating the Entire Pareto Frontier in Multiobjective Optimization. In:","authors":[],"date":"2005","doi":"10.1016\/j.cam.2008.03.011","raw":"Utyuzhnikov, S.V., Fantini, P., Guenov, M.D.: Numerical Method for Generating the Entire Pareto Frontier in Multiobjective Optimization. In: Proceedings of EUROGEN 2005, 12-14, Munich, Germany, September 2005","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-09-30T00:00:00Z","abstract":"Presented is a novel framework for performing flexible computational design studies at preliminary design stage. It incorporates a workflow management device (WMD) and a number of advanced numerical treatments, including multi-objective optimization, sensitivity analysis and uncertainty management with emphasis on design robustness. The WMD enables the designer to build, understand, manipulate and share complex processes and studies. Results obtained after applying the WMD on various test cases, showed a significant reduction of the iterations required for the convergence of the computational system. The tests results also demonstrated the capabilities of the advanced treatments as follows: The novel procedure for global multi-objective optimization has the unique ability to generate well-distributed Pareto points on both local and global Pareto fronts simultaneously. The global sensitivity analysis procedure is able to identify input variables whose range of variation does not have significant effect on the objectives and constraints. It was demonstrated that fixing such variables can greatly reduce the computational time while retaining a satisfactory quality of the resulting Pareto front. The novel derivative-free method for uncertainty propagation, which was proposed for enabling multi-objective robust optimization, delivers a higher accuracy compared to the one based on function linearization, without altering significantly the cost of the single optimization step","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/140158.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/10.1007\/s10846-010-9397-8","pdfHashValue":"43387c3dd463050f924941c900f2af398fa97189","publisher":"Springer Science   Business Media","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/5426<\/identifier><datestamp>2017-06-20T13:35:26Z<\/datestamp><setSpec>hdl_1826_19<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Multidisciplinary design optimization framework for the pre design stage<\/dc:title><dc:creator>Guenov, Marin D.<\/dc:creator><dc:creator>Fantini, Paolo<\/dc:creator><dc:creator>Balachandran, Libish Kalathil<\/dc:creator><dc:creator>Maginot, Jeremy<\/dc:creator><dc:creator>Padulo, Mattia<\/dc:creator><dc:creator>Nunez, Marco<\/dc:creator><dc:subject>Design computational workflow Multidisciplinary design optimisation Multiobjective optimisation Robust optimisation Sensitivity analysis Uncertainty management normal constraint method robust design pareto frontier<\/dc:subject><dc:description>Presented is a novel framework for performing flexible computational design studies at preliminary design stage. It incorporates a workflow management device (WMD) and a number of advanced numerical treatments, including multi-objective optimization, sensitivity analysis and uncertainty management with emphasis on design robustness. The WMD enables the designer to build, understand, manipulate and share complex processes and studies. Results obtained after applying the WMD on various test cases, showed a significant reduction of the iterations required for the convergence of the computational system. The tests results also demonstrated the capabilities of the advanced treatments as follows: The novel procedure for global multi-objective optimization has the unique ability to generate well-distributed Pareto points on both local and global Pareto fronts simultaneously. The global sensitivity analysis procedure is able to identify input variables whose range of variation does not have significant effect on the objectives and constraints. It was demonstrated that fixing such variables can greatly reduce the computational time while retaining a satisfactory quality of the resulting Pareto front. The novel derivative-free method for uncertainty propagation, which was proposed for enabling multi-objective robust optimization, delivers a higher accuracy compared to the one based on function linearization, without altering significantly the cost of the single optimization step.<\/dc:description><dc:publisher>Springer Science   Business Media<\/dc:publisher><dc:date>2013-01-22T23:01:30Z<\/dc:date><dc:date>2013-01-22T23:01:30Z<\/dc:date><dc:date>2010-09-30T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>M. Guenov, P. Fantini, L. Balachandran, J. Maginot, M. Padulo and M. Nunez. Multidisciplinary design optimization framework for the pre design stage. Journal of Intelligent and Robotic Systems, Volume 59, Issue 3-4, 2010, pp223-240.<\/dc:identifier><dc:identifier>0921-0296<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1007\/s10846-010-9397-8<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/5426<\/dc:identifier><dc:language>en_UK<\/dc:language><dc:rights>The original publication is available at www.springerlink.com<\/dc:rights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0921-0296","0921-0296"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2010,"topics":["Design computational workflow Multidisciplinary design optimisation Multiobjective optimisation Robust optimisation Sensitivity analysis Uncertainty management normal constraint method robust design pareto frontier"],"subject":["Article"],"fullText":"1 \nJ Intell Robot Syst \nMultidisciplinary Design Optimization Framework \nfor the Pre Design Stage \n \nM. Guenov \u2020\u2022 P. Fantini \u2022 L. Balachandran \u2022  \nJ. Maginot \u2022 M. Padulo \u2022 M. Nunez  \n \n  \n \n \nAbstract Presented is a novel framework for performing flexible computational design studies at \npreliminary design stage. It incorporates a workflow management device (WMD) and a number of \nadvanced numerical treatments, including multi-objective optimization, sensitivity analysis and \nuncertainty management with emphasis on design robustness. The WMD enables the designer to \nbuild, understand, manipulate and share complex processes and studies.  Results obtained after \napplying the WMD on various test cases, showed a significant reduction of the iterations required \nfor the convergence of the computational system. The tests results also demonstrated the \ncapabilities of the advanced treatments as follows: \n- The novel procedure for global multi-objective optimization has the unique ability to \ngenerate well-distributed Pareto points on both local and global Pareto fronts \nsimultaneously.  \n- The global sensitivity analysis procedure is able to identify input variables whose range of \nvariation does not have significant effect on the objectives and constraints. It was \ndemonstrated that fixing such variables can greatly reduce the computational time while \nretaining a satisfactory quality of the resulting Pareto front.  \n- The novel derivative-free method for uncertainty propagation, which was proposed for \nenabling multi-objective robust optimization, delivers a higher accuracy compared to the \none based on function linearization, without altering significantly the cost of the \nsingle optimization step.  \nThe work demonstrated for the first time that such capabilities can be used in a coordinated way to \nenhance the efficiency of the computational process and the effectiveness of the decision making \nat preliminary design stage. \n \nKeywords Design Computational Workflow, Multidisciplinary Design Optimisation, \nMultiobjective Optimisation, Robust Optimisation, Sensitivity Analysis, Uncertainty Management. \n                                                          \nM. Guenov (\u2020Corresponding Author)\u2022 L. Balachandran \u2022 J. Maginot \u2022 M. Padulo \u2022 M. Nunez  \nAdvanced Engineering Design Group, \nDept. of Aerospace Engineering, Cranfield University, \nMK43 0AL,Cranfield, Bedfordshire,UK \ne-mail: m.d.guenov@cranfield.ac.uk \n \nP. Fantini \nAircraft Research Association Ltd.,  \nMK41 7PF, Manton Lane, Bedford, UK \ne-mail: pfantini@ara.co.uk \n2 \n \n \n1 Introduction \n \nOur initial research, as part of the EU FP6 VIVACE project, indicated that although involving a lot \nof talent and producing great results, the existing pre design processes can be significantly \nimproved. For example, relevant process information is currently spread in tools, manuals, brains \nand sites and in many cases the procedural coding incorporates \u2018hardwired\u2019 assumptions from \nother disciplines (e.g., weight estimation procedure incorporating assumptions on aerodynamic \nloading). Thus, the result of a design study may depend on the way it was produced. On the other \nhand, innovation may be restrained by the confinement to known cases since the design starts from \nexisting configurations, implicit in the computational code. Industrial need was therefore identified \nfor a new approach, allowing to merge numeric and geometric design and to facilitate a \ncomponent-driven modularisation of the disciplines. \nIn this context, Cranfield University had the task to research and develop a prototype workflow \nmanagement device (WMD) enabling a simple formalism and easily understandable description of \nthe computational workflow which would allow to store not only the results, but also the way \nthese were computed. This means that the computational workflow should be stored in an \nexecutable format and also be editable by the user in order to develop dynamic solutions. The \nWMD should be capable of dynamic assembly of hierarchical computational processes from other \nprocesses and\/or from atomic models (i.e., equations or compiled codes referred to as black \nboxes). In addition, the WMD should enable the dynamic application of relevant treatments to the \ncomputational processes, such as multi-objective optimization, sensitivity analysis and uncertainty \nmanagement. The realisation of these treatments includes distinct research contribution which is \nalso summarised in this paper. \nThe relation of this work to the classical notion of MDO, i.e., optimization of a system consisting \nof coupled disciplines, becomes apparent when considering the objective of pre design, which is to \ndefine the characteristics on an aircraft given its properties. That is, to determine the design \nparameters, given performance and operational parameters derived from stakeholders\u2019 \nrequirements, or to modify existing aircraft for the satisfaction of a different or a stretched \nrequirement. In any case a workflow consisting of hundreds of models (black boxes) and \nthousands of variables needs to be assembled and \u201c(re)wired\u201d every time a variable is added to or \nremoved from the input set. During this process subsets of models may become coupled through \nshared variables. These coupled or strongly connected components (SCCs) correspond to the \n\u2018disciplines\u2019 in the classical MDO. The difference is that the pre-design MDO process has to be \nconfigured on the fly, with hundreds, albeit low fidelity models. \nThese problems, as part of the WMD specification are outlined in the next section. The novel \nCalculation Engine for multi-objective optimization, and in particular, for finding local and global \nPareto surfaces is described in section 3. Section 4 discusses sensitivity analysis and in particular, \nthe possibility to identify design variables whose range of variation does not have significant effect \non the objectives and constraints. This could significantly reduce the dimensionality of the design \nspace and the computational effort, respectively. Uncertainty management is discussed in section 5 \nwith emphasis on robust multi-objective optimization. In each of these sections appropriate \nreference to stat of the art in the particular field is made for completeness. The results are \npresented in section 6. Finally conclusions are drawn and future work outlined. \n \n \n2 Computational workflow management \n \nThe computational process modeller is presented in Fig. 1. A brief summary of the flow chart steps \nis given below while a detailed description of the associated techniques is presented in Guenov et \nal. [9], Balachandran et al.[1] and Balachandran [2]. \n3 \n \nFig. 1 The computational process modeller \n \nSTART \nStep 1:  Initially the designer needs to provide the system of models with a choice of independent \n(input) variables. \nStep 2: Variable flow modelling is performed using the incidence matrix method (IMM) in order \nto determine the information (data) flow between the models. All feasible variable flow models of \nthe system are explored in this step. \nStep 3: Each variable flow model generated is separated into hierarchically decomposable and \nnon-hierarchically decomposable systems of models. Non-hierarchically decomposable systems \nare also known as strongly connected components (SCC).  \nStep 4: Given a SCC, its constituent models are rearranged by means of Genetic Algorithm (GA). \nStep 5: The selection of the optimal variable flow model is based on the value of objective \nfunction which combines criteria such as number of modified models and number and length of \nthe feedback loops. \nStep 6: Each of the rearranged SCCs is regarded as a single model and is reintroduced into the \nDSM along with the remaining models.  \nStep 7: If SCCs do not exist, then the models are populated directly into a DSM based on data flow \nobtained from the variable flow model. \nStep 8: The DSM is rearranged into a lower triangular matrix based on a graph theoretical \nalgorithm. This rearrangement eliminates the feedback loops and thus the final computational plan \nof the system is obtained.  \nEND \n \n \n3 Multiobjective optimization - generating a well-distributed set of Pareto points \n \nA number of methods for obtaining an evenly distributed set of Pareto points have been developed \nin recent years. All of these are based on performing a subdivision of the criterion (objective) \nspace in a set of domains. The optimization problem is then reformulated for each domain, for \neach of which a Pareto point is generated. \nDas and Dennis [5,6] were the first to provide a method for generating well-distributed Pareto \npoints, the Normal-Boundary intersection (NBI) method. Another method is the PP-based method \ndeveloped by Messac et al. [14] as an extension of the a priori articulation of preference method \n4 \nknown as the Physical Programming (PP) [17]. The new Normal Constraint (NC) method [15, 16] \ndeveloped recently also looks very promising. \nAll of the cited methods have a clear geometrical interpretation, they are all based on the well-\nknown fact that a Pareto frontier belongs to the boundary of the feasible space towards the minima \nof the objective functions [18]. \nThe NBI, NC and PP-based methods all follow a similar approach for obtaining well-distributed \nPareto points. Anchor points ai {i = 1,\u2026, M} [13], which are the minima relative to each of the \nobjective, are obtained first. Subsequently a number of evenly distributed points belonging to the \ncriterion space, the utopia plane points p, are obtained as linear combinations of the M anchor \npoints [15]. These are used as reference points allowing the reformulation of the optimization \nproblem. Finally, for each utopia plane point p an optimization is executed in order to obtain a \nPareto point. Each of these three steps is fundamental in order to obtain a complete representation \nof the Pareto frontier. \nWhen dealing with multiobjective optimization problems, for which the number of objectives is \ngreater than two, a peripheral region exists. The peripheral region is that region of the criterion \nspace, for which the orthogonal projection of the Pareto frontier on the utopia plane is external to \nthe polygon spanned by the M anchor points ai [5, 16]. In their work Das and Dennis limit the \nimportance of the peripheral region, stating that such region will be of no interest to the designer, \nwhile Messac and Mattson are interested in obtaining a complete representation of the Pareto \nfrontier.  \nEven though Das and Dennis believe that such points might be of no interest for the designer, it \nmust be noted that the size of the peripheral region of the Pareto frontier is dependent on the \npositioning of the anchor points and can be significant. This was demonstrated by Fantini [7] who \nafter analysing the existing methods defined of a set of requirements for an effective method for \ngenerating well-distributed Pareto. These requirements state that the reformulation should avoid \nthe introduction of local minima while minimizing the possibility of the optimiser to fail. A unique \noptimization should be performed for each of the sub-problems in order to minimize the risk of \nfailure. Furthermore, the method should be independent of the number of objectives. \nThe attempt [7] at improving the reformulation of the optimization problems, in order to remove \nthe limitations associated with the existing methods has followed three consecutive stages. The \nresult of the first one is the modified PP-based method, developed through modification of the PP-\nbased method [27, 10]. The second one has taken advantage of the experience gained from the \ndevelopment of the first one and has led to the development of the Double Hyper-cone Boundary \nIntersection (DHCBI) method [7, 8]. The third and latest method developed is the NC+ method. \nThe methods follow the tracks laid by the NBI, PP-based and NC methods, combining the various \napproaches and the knowledge gained from them. Its formulation is as follows:  \n \n min f(x) \nsubject to K inequality constraints:   gk(x) \u00a3 0, k = 1,2,\u2026,K \nP equality constraints: hp(x) = 0, p = 1,2,\u2026,P \nsubject to the additional 1M \u2212  constraints: vj (pi - f) \u00a3 0, \u2200j \u00ce {1,2,\u2026,M}, j \u00b9 l \nand subject to the additional constraints: vj (f - pi  - nc vl \/ ||vl||)\u00a30, \nwith: ,L U\u2264 \u2264x x x   \n     \n \n \n(1) \n \nwhere vj = (lj \/ li) el \u2013 ej for j \u00b9 l, vl = m l el \/ ll \u2013 m, ej \u2200j are the base vectors of the coordinate \nsystem, l is the unit vector orthogonal to the utopia plane, nc is a fraction of the Euclidean distance \nbetween two contiguous utopia plane points, m \u00ce \uf0a1M is a vector such that mi = 1 \u2200i and ml = 0 \nand ,L Ux x  are the lower and upper bounds for the input variables, respectively. \nThe formulation is similar to the NC method, where M - 1 constraints are used for building M - 1 \nhyper-planes which confine the solution to a region of the criterion space. Although in the NC \nmethod these constraints are dependent on the anchor points, in the NC+ method they are build \nwith respect to the coordinate system. \nFor the solution to belong to the line orthogonal to the utopia plane, passing through a particular \nutopia plane point, all hyper-planes need to be orthogonal to the utopia plane and have to intersect \nin the utopia plane point. In the NC+ method, the hyper-planes are determined with respect to the \ncoordinate system in such a way that the orthogonality condition is always enforced [7]. In order to \nminimize the possibility of obtaining solutions not belonging to the line orthogonal to the utopia \n5 \nplane, passing through utopia plane point pi, an additional constraint is added. Constraint l is built \nin order to reduce the size of the feasible region, confining the solution in the proximity of the line \npassing through utopia plane point pi. As for the other M-1 constraints, constraint l defines a \nhyper-plane orthogonal to the utopia plane, but positioned at a distance nc in the direction of vector \nvl. Further details on the method can be found in Fantini [7]. \n \n \n4 Sensitivity analysis \n \nSensitivity analysis (SA) is the study of how changes in the outputs of a complex model can be \napportioned qualitatively or quantitatively to variations in the different inputs. Unfortunately, \ninformation on models used to describe a complex system cannot be obtained analytically because \nthe internal mechanisms are not known. This is particularly true in MDO since complicated \ncoupling between disciplines must be taken into account. In such a situation, only numerical \nresults can be obtained. A way to get a better understanding of the model is to perform a sample-\nbased sensitivity analysis. In such a procedure, the model is executed repeatedly for a set of input \nvalues. Saltelli [22] describes in detail the steps necessary to perform a sample-based sensitivity \nanalysis as summarised in Fig. 2.  \n \n \n \nFig. 2 Typical sensitivity analysis procedure \n \n4.1 Variance-based methods \n \nWhen implementation of sensitivity analysis is concerned, many different approaches can be \nfollowed. We have chosen Variance-based methods (VBM) since these are rigorous and \ntheoretically sound approaches for global sensitivity calculation [23] exhibiting desirable \nproperties for sensitivity analysis of complex models. \nVBM provide quantitative information on the influence of each input factor to help the designer \nidentify the most influential variables, on which the computational effort can be concentrated, and \nthe variables with negligible effects which can be discarded or frozen to a specific value. \nVariance-based approaches for sensitivity analysis decompose the output variance into partial \nvariances of increasing dimensionality. \n \n1,2,3,...,( ) ...i ij k\ni i j\nV Y V V V\n\u2260\n= + + +\u2211 \u2211  (2) \nIn the decomposition of the variance, the term Vij is the interaction effect between xi  and xj. Vij \nrepresents the part of the output variation due to input parameters xi and xj which cannot be \nexplained by the sum of the first order effects of parameter xi and xj. Similar considerations can be \nmade for higher order terms. \nThe two coefficients of main interest for sensitivity are: \n- The main effect index which gives the first-order contribution of Xi to the output response. \n- The total effect index which gives the total contribution of Xi to the output response. \nFor each input, the difference between its total effect and its main effect gives an indication of the \nimportance the contribution to the output due to interactions with other inputs. Therefore, both the \n6 \nmain effect indices and total effect indices are necessary to obtain information about the non-\nadditivity of the model and on the relative importance of variable interactions.  \nTwo main methods, Fourier Amplitude Sensitivity Test (FAST) [4, 24, 25, 26], have been \ndeveloped to compute the different terms of the variance decomposition and both main and total \neffect indices. \n \n4.2 Reducing the dimensionality of the optimization problem \n \nIn the context of MDO, we assume that the model, which evaluates the objectives and constraints \nof the optimization problem, can be represented as a black-box. This stands for the fact that the \ndesigner is unaware of the complex internal mechanisms of the model, which relate objectives and \nconstraints to the input variables. The methodology developed in this general case can then be \nreadily implemented for a more specific purpose. In the context of deterministic optimization, it is \nalso assumed that all variables have uniform distribution over their ranges [ , ]L Ux x . In this \napproach, it is proposed to use VBM to evaluate the global sensitivity indices of each input with \nrespect to all outputs. This allows to quantify the effect of the variations of the inputs on the \noutputs variance. Both main and total sensitivity indices are calculated. The main and total effects \nrepresent the minimum and maximum expected reduction of the output variance if the input is \nfixed to a specific value. Therefore, freezing an input variable with a negligible total sensitivity \nindex will not affect the output variance.  \nIt is proposed to remove from the original optimization formulation a variable with a negligible \neffect on all objectives and constraints. When more than one variable is non-significant, the \ndesigner should consider these as a group of variables and see whether the sensitivity of the group \nis still below the significance threshold [11, 12]. Typically, this would imply performing another \nsensitivity analysis and re-sampling the design space. Such procedure could be very expensive. \nInstead, it is recommended to make sure that the sum of the group\u2019s total indices remains below a \nparticular threshold value. Without loss of generality, let us assume that the first R variables are \nnon-significant to all objectives and constraints. The problem can be reformulated as follows: \n \n min f (xred) \nsubject to K inequality constraints:  gk (xred) \u00a3 0, k = 1,2,\u2026,K \nand P equality constraints: hp (xred) = 0, p = 1,2,\u2026,P \nwith: ,\nL Ured red red\n\u2264 \u2264x x x   \n(3) \n \nwhere xred = (xR+1,\u2026,xN). All variables with negligible effect are fixed to a value xm = xm*  for m = \n1,\u2026, R. \nThe approach is presented in the case of a multi-criteria optimization (see section 6.3), but the \nsame considerations can be made when a single objective is optimised. \n \n \n5 Design robustness \n \nA constrained robust optimization (RO) strategy can be thought of as made up of three main parts. \nThe first stage consists of identifying, qualifying and quantifying the sources of uncertainty \nassociated with the design input and the analysis modules. This is usually done by means of \nstochastic models. The second phase consists of propagating the uncertainty through the analysis \nsystem, to adequately model the probabilistic behaviour of the objective functions and constraints. \nThe obtained probabilistic quantities are hence used in the third stage of the process, during which \nthe optimization is performed. \nIn RO, the probabilistic state can be defined in terms of expectation and variance of the \ndeterministic objectives and constraints. A single-objective deterministic optimization problem \nturns then into a multi-objective robust problem if the two statistical moments are thought of as \nrepresenting, two conflicting objectives such as a suitable average of the system performance and \nits sensitivity to unforeseen variations, respectively [3]. Several approaches have been developed \nto adequately accommodate this issue, ranging from the weighted sum method to physical \nprogramming [21]. When the considered deterministic problem is multi-objective, multiple system \n7 \nperformance metrics have to be traded-off [19]. In our case, the hypothesis of independence of the \ndeterministic objectives is adopted. This leads to formulating the original bi-objective problem as a \nfour objective one in which robustness is sought for by minimizing the objectives\u2019 variances, \nwhile expectations of the performance measures are optimized according to their physical \nmeanings. To maintain design feasibility with a specific level of confidence, given the prescribed \ninput uncertainty, inequality constraints of the form ( ) 0kg \u2264x  take the following form: \n \n ( ) ( ) 0g g gk k kt\u00b5 \u03c3+ \u2264x x . \n(4) \n \nThe coefficient ( )1 ( 0)\nkg k\nt P g\u2212= \u03a6 \u2264  guarantees a prescribed level of probability P of constraint \nsatisfaction, where \u03a6-1 is the inverse of the normal cumulative distribution function. It is to be \nnoted that this formulation is only approximate for non-normal constraint functions.  Eq. (3) can \nthus be extended as follows:  \n \n min  ( ), ( )= f f\u03bcx\nF\u03bc x \u03c3 x  \nsubject to the inequality constraints: ( ) ( ) 0,\nk k kk g g g\nG t\u00b5 \u03c3= + \u2264x x             1, 2,...,k K=  \n L Ut t+ \u2264 \u2264 \u2212x x x x xx\u03c3 \u03bc x \u03c3 .  \n     \n \n(5) \n \nThe way in which mean and variance of each objective and constraint function are obtained \nstarting from the knowledge of the uncertainty affecting x turns out to be crucial both for the \nefficiency and the accuracy of the whole RO approach. If all the variables are continuous, the first \ntwo moments of ( )y f= x  are:  \n \n ( ) ( ) ( )f f p d\u00b5\n+\u221e\n\u2212\u221e\n= \u222b Xx\u03be \u03be \u03be , \n(6) \n { }22 ( ) ( )( ) ( )f ff p d\u03c3 \u00b5\n+\u221e\n\u2212\u221e\n= \u2212\u222b X\u03bex x\u03be \u03be , \n(7) \n \nwhere pX is the joint probability density function corresponding to the distributions modelling the \nuncertainty of the input variables, and is supposed not to depend on the design point x. Since a \nclosed-form solution of these integrals can be obtained only in a few cases of practical interest, \nuncertainty propagation is usually performed in an approximate fashion. As pointed out in Padulo \net al. [20], an attractive compromise between cost and accuracy of the propagation phase is offered \nby reduced quadrature methods, such as the Sigma-Point (SP) approach. This method gives mean \nand variance as follows:  \n \n 0 0\n1\n,( ) ( ) ( )\nn\nf p p p\np\nW f W f f\u00b5 + \u2212\n=\n= + \uf8ee \uf8f9+\uf8f0 \uf8fb\u2211x x x  (8) \n ( ){ }2 22 2 0\n1\n1 ( ) ( ) 2 ( ) ( ) 2 ( ) .\n2\nn\nf p p p p p p p\np\nW f f W W f f f\u03c3 + \u2212 + \u2212\n=\n\uf8ee \uf8f9 \uf8ee \uf8f9= \u2212 + \u2212 + \u2212\u2211 \uf8f0 \uf8fb \uf8f0 \uf8fbx x x x x  \n(9) \n \nThe weights are chosen as follows: \n \n \n2\n0 2\nsp\nsp\nh n\nW\nh\n\u2212\n= , (10) \n 2\n1\n2p sp\nW\nh\n= , for 1 p n\u2264 \u2264 . (11) \n \nThe sampling points are: \n \n 0 ,\u00b5= xx  (12) \n ,\npp p ph\u00b5 \u03c3\u00b1 = \u00b1x xx e  (13) \n \n8 \nwhere ep is the pth column of the identity matrix of size n and hp is equal to the square root of the \nkurtosis of the pth design variable distribution. The accuracy of the SP method, in particular for the \nmean estimate, is higher with respect to the largely adopted first order Taylor based method of \nmoments (MM). However, it requires only 2n + 1 function evaluations for each analysis, which is \nequal to the cost of linearization if function gradients are approximated by centered finite \ndifferences. When the function performing the system analysis is differentiable, this technique can \nbe efficiently used in gradient-based optimization; the computational cost of a single optimization \nstep in terms of function evaluations is \u221d  n2 by using either the SP method or MM for the \npropagation phase, if the derivatives are obtained by finite differencing. If the source code of the \nanalysis system is available and AD can be deployed, this cost decreases to \u221d n in both cases. \n \n \n6 Results \n \nThe results of the tests on the workflow manager and the coordinated application of the above \ndescribed treatments are presented in this section. The adopted test case is an Ultra Simplified \nModel of Aircraft (USMAC), which was provided by a major airframe manufacturer, in the \ncontext of the European project VIVACE. USMAC can determine performance and sizing at \nconceptual design level for a short-to-medium range commercial passenger aircraft.  The test case \ncontains 97 models and 125 variables. \n \n6.1 Computational Process Modeller Results \n \nSynthesis of an optimal computational plan has to be performed before any treatment is applied to \nthe test case. To test the capability of the computational process modeller to generate optimal \ncomputational plans for a system with suitably chosen inputs, 23 variables were chosen randomly \nas independent from the 125 variables set (Twenty three variables are required in this test case to \nensure that the system is determined). The computational process modeller generated optimal \ncomputational plans.  The computational cost of each optimal computational plan was then \ncompared with the cost of its corresponding non-optimal plans.  The computational cost \ncomparison was based on the number of calls made to the models of the SCC during solving. The \nSCCs were solved by applying a fixed point iteration method while the modified models were \nresolved by applying Gauss-Newton method. \nAfter decomposing the system, thirteen out of the 97 models were identified as strongly connected. \nThere were twelve variable flow models generated for the SCC. However, only four of these \nproduced a converged solution. The non-converged ones were those variable flow models which \nhad a higher number of modified models and feedback numbers. Fig. 3 shows an example of a \n(converged) final computational sequence. \n \n \n \n \n \n \n \n \n \n \nFig. 3 (a) DSM of the USMAC final computational plan. (b)Design Structure Matrix of the SCC \nwith the shortest feedback length \n \nTable 1 provides details of four converged models and a non-converged solution for comparison. \n9 \nVariable \nflow model nFdb nMm \nOptimal flow \nmodel  \nNumber of calls to the \nmodels in SCC \n% additional \ncomputational \n 1 3 6  117 95% more \n2 5 11  158 163% more \n3 6 3 \u25a0 60 Base \n4 5 9  198 230% more \n5 8 11  Not converged - \nTable 1 Details of computational process modelling and solving of SCC \n \nVariable flow model 3 was chosen by the computational process modeller as the optimal one, \nsince it has the smallest number of modified models. It is shown in the table that the selected \noptimal flow model has the lowest computational cost for the SCC. From Table 1 it is also clear \nthat when the number of modified models increases the computational cost for the SCC also \nincreases. However, for variable flow model 4, even though the number of modified models is less \nthan the one for the flow model 2, it has taken more calls to obtain a converged solution. This \ndiscrepancy was observed because the convergence of the SCC was not only depending on the \nnumber of modified models and the number of feedback loops, but also on other factors such as \nthe starting (iteration) point for the unknown variables, mutual sensitivity of the switched (input \nwith output) variables of the modified models and possible other factors which are yet to be \ndiscovered. Nevertheless, these and many more extensive tests conducted on the process modeller \ndemonstrated that the selections which it made were always amongst the best in terms of SCCs\u2019 \nconvergence. \n \n6.2 Multi-objective optimization results \n \nThe computational process modeller generated an optimal computational plan onto which the NC+ \nmethod was executed with the settings presented in Table 2.  Five starting points were used in \norder to determine the multiple local minima. Forty utopia plane points were generated in order to \ndetermine the Pareto front. The results obtained are shown in Fig. 4. In addition, an interactive \nvisualization interface has been developed to take into account the traditional aircraft conceptual \ndesign approach, which relies heavily on matrix and carpet plots. The proposed visualization tool \nshows graphically whether a design point meets a set of performance constraints (such as cruise \nspeed, second segment climb rate, direct climb, take-off and landing field lengths), derived from \nthe original constraint set. By clicking on a design point, the corresponding carpet plot is \nautomatically generated. An example of this visualization is shown in Fig. 5. The example also \ndemonstrates that it is possible to find out in which direction the design point under consideration \nshould be moved on the plot to obtain the desired improvements. \n \nNomenclature \nNpax number of passengers altcrz  cruise altitude [ft] \nNpaxFront number of passengers per row Machcrz  cruise mach \nNaisle number of aisles altto takeoff altitude [ft] \nFNslst sea-level static engine thrust [decaN] altapp approach altitude [ft] \nBPR engine bypass ratio MTOW  maximum take-off weight [kg] \nne number of engines RA  range [NM] \nAwing  wing area [m2] RAtime  flight time [h] \nspan  wing span [m] tofl  takeoff field length [m] \nphi  wing sweep angle [deg] vapp  approach speed [kts] \ntuc  wing thickness to chord ratio vzclb climb rate [ft\/min] \nMTOW maximum take-off weight [kg] kfncth cruise thrust coefficient \nFuel fuel weight [kg] Kff  wing fuselage fuel ratio \nConstant \n \nIndependent Variables Constraints Objectives \nNpax = 150 FNslst = [12500,13000] \n \n  \ntofl \u2264 2000 m RA [NM] \nto be maximized NpaxFront = 6 Awing = [152,158] m2 vapp \u2264 120 kts \nNaisle = 1 span = [30,38] m vzclb\u2265500 ft\/min MTOW [kg] \n to be minimized ne = 2 phi = [28,32] deg kfncth \u2264 1 \naltcrz = 35000 ft tuc = [0.07,0.1] Kff \u2265 0.75  \nMachcrz = 0.82 Fuel = [17000,18000] kg   \n10 \naltto = 0 ft BPR = [6 , 7]   \naltapp = 0 ft    \nTable 2 Set up of the multi-objective optimization problem \n \nFinally, to illustrate how integrating design computation, parametric geometry and configuration \ncan aid the designer in choosing a particular (Pareto) solution, a prototype tool, presented in Fig. 6, \nwas developed. The tool allows for browsing each of the Pareto points while showing the changes \nto the geometry and indicating (in different colour) which constrains are activate for the particular \npoint. \n \nFig. 4 USMAC test case Pareto front \n \nFig. 5 Example of the carpet plot of a design point \n11 \n \nFig. 6 Visualization of the Pareto set, including geometry and constraint activation \n \n6.3 Sensitivity analysis results \n \nFor this particular test case and the specific range of variations, it appears that the contributions to \nthe outputs variance due to interactions between inputs are very small. Therefore, one can \nconclude that contributions to the outputs are entirely due to direct effects. It is appears that \nFNslst, Span, Wing, tuc and Fuel are the most significant variables to the problem. Variable phi \nhas a smaller effect but cannot be neglected as it affects tofl and vapp. The global indices for BPR \nfor all optimization outputs are almost equal to zero and therefore BPR appears to be negligible for \nthis particular problem. The reduced optimization problem is derived by keeping all variables and \nfixing BPR to the mean value of its range of variation, i.e. BPR = 6.5.  \nThe original Pareto set and the one obtained with the reduced optimization problem are shown in \nFig. 7. The two Pareto fronts are very similar in the criterion space which indicates that a similar \nlevel of performance can be obtained by only considering variables with a real effect. Freezing \nBPR to a value resulted in a significant reduction of the computational effort: 16627 function \nevaluations were needed to obtain the Pareto front compared to 65332 when all variables are \nconsidered.  \n \nFig. 7 USMAC Pareto front for full and reduced optimization problem \n12 \n \n6.4 Robust optimization results \n \nThe robust counterpart of the deterministic optimization problem in Section 0 considers separately, \nwithout any a priori assumption on relative weights, mean and variance for the two physical \nobjectives. The problem to be solved is then a 4 objective optimization. The deterministic \nconstraints are transformed into their robust counterpart by adopting tg= tx = 1 as weighting \ncoefficients in Eq. (3), to impose the robust feasibility with a probability of approximately 84%. \nThe assumed uncertainties of input variables, in terms of standard deviation, are shown in Table 3. \n \nInput variable FNslst BPR Awing span phi tuc Fuel \nStandard deviation 100 decaN 0.2 5 m2 0.5 m 1 deg 0.02 50 kg \nTable 3 Uncertainties of input variables \n \nIt is useful to compare the deterministic with the obtained robust Pareto front, by performing an a \nposteriori uncertainty analysis on the deterministic results in order to obtain mean and variance for \neach Pareto point. The mean of the objectives for the robust optimization is then superimposed on \nthe same plot (see Fig. 8). The adopted representation is a bidimensional projection of a four \ndimensional Pareto hypersurface. It has been judged to be appropriate for the problem at hand \nsince the variation of standard deviation for both objectives is negligible with respect to their mean \nvalues. This is mainly due to the small input uncertainty considered. Thus the robust optimal \nsolutions turn out to be dominated by the deterministic ones in terms of mean values mainly as a \nresult of the imposed stricter constraints. \n \n \nFig. 8 Comparison of deterministic and robust Pareto fronts \n \n7 Conclusions \n \nPresented is a novel computational framework providing the capability for performing flexible \ndesign studies at preliminary design stage. It incorporates a workflow management device (WMD) \nand a number of advanced treatments, including multi-objective optimization, sensitivity analysis \nand uncertainty management. The WMD enables the designer to build, understand, manipulate and \nshare complex processes and studies.  Results obtained after applying the WMD on various test \ncases, showed a significant reduction of the iterations required for the convergence of the \n13 \ncomputational system. The tests also demonstrated the capabilities of the advanced treatments as \nfollows: \n \n- The novel procedure for global multi-objective optimization has the unique ability to \ngenerate well-distributed Pareto points on both local and global Pareto fronts \nsimultaneously; \n- The global sensitivity analysis procedure is able to identify input variables whose range of \nvariation does not have significant effect on the objectives and constraints. It was \ndemonstrated that fixing such variables can greatly reduce the computational time while \nretaining a satisfactory quality of the resulting Pareto front; \n- The novel derivative-free method for uncertainty propagation, which was proposed for \nenabling multi-objective robust optimization, delivers a higher accuracy compared to the \none based on function linearization, without altering significantly the cost of the \nsingle optimization step.  \n \nThis work demonstrated for the first time that such capabilities can be used in a coordinated way to \nenhance the efficiency of the computational process and the effectiveness of the decision making. \nFuture work will be concentrate on further integration of the treatments which will allow their \ndynamic application as dictated by the computational process. Also, further integration with \nparametric geometry and configuration tools is planned in order to achieve the ultimate goal of this \nwork, that is, to study unconventional new configurations with a higher level of detail and better \nrisk assessment before proceeding to the next stages of the product development process. \nAcknowledgements The research reported in this paper has been carried out within the VIVACE \nIntegrated Project (AIP3 CT-2003-502917) which is partly sponsored by the Sixth Framework \nProgramme of the European Community (2002-2006) under priority 4, \u201cAeronautics and Space\u201d. \nThe authors wish to thank our industrial partners for the fruitful discussions, constructive criticism \nand the provision of test cases. Finally we would like to thank the anonymous reviewers for their \nhelpful comments. \nReferences \n1. Balachandran L.K., Fantini, P.F., Guenov, M.D.: Computational Process Management for \nAircraft Conceptual Design. 7th AIAA Aviation Technology, Integration and Operations \nConference (ATIO), Belfast, September 2007 \n2. Balachandran L. K.: Computational workflow management for conceptual design of complex \nsystems: An Air-vehicle Design Perspective. PhD Thesis, Cranfield University, Cranfield, UK \n(2007) \n3. Chen, W., Allen, J.: A procedure for robust design: Minimizing variations caused by noise \nfactors and control factors. Journal of Mechanical Design, 118(4), pp. 478\u2013493 (1996) \n4. Cukier, R.I., Levine, H.B., Shuler, K.E.: Non-Linear Sensitivity Analysis of Multi-Parameter \nModel Systems. Journal of Computational Physics, Vol. 26, No. 1, pp. 1-42 (1978) \n5. Das, I., Dennis, J.E.: Normal-Boundary Intersection: A New Method for Generating the Pareto \nSurface in Nonlinear Multicriteria Optimization Problems. SIAM Journal of Optimization, vol. \n8, pp. 631-657 (1998) \n6. Das, I.: An Improved Technique for Choosing Parameters for Pareto Surface Generation Using \nNormal-Boundary Intersection. In: Proceedings of the Third World Congress of Structural and \nMultidisciplinary Optimization WCSMO-3, Buffalo, NY, March 1999 \n7. Fantini, P.: Effective Multiobjective MDO for Conceptual Design - An Aircraft Design \nPerspective. PhD Thesis, Cranfield University, Cranfield, UK (2007) \n14 \n8. Fantini, P., Balachandran, L.K., Guenov, M.D.: Computational Intelligence in Multi \nDisciplinary Optimization at Conceptual Design Stage. In: Proceedings of the First \nInternational Conference on Multidisciplinary Design Optimization and Applications, \nBesancon, France, April 2007 \n9. Guenov, M.D., Libish, Tang, D., Lockett, H.: Computational Design Process Modelling. In: \nProceedings of 25th International Council of the Aeronautical Sciences, Hamburg, Germany, \nSeptember 2006 \n10. Guenov, M.D., Utyuzhnikov, S.V., Fantini, P.: Application of the Modified Physical \nProgramming Method to Generating the Entire Pareto Frontier in Multiobjective Optimization. \nIn: Proceedings of EUROGEN 2005, Munich, Germany, September 2005 \n11. Maginot, J.: Sensitivity analysis for multidisciplinary design optimization. PhD Thesis, \nCranfield University, Cranfield, UK (2007) \n12. Maginot, J., Guenov, M.D., Fantini, P., Padulo, M.: A method for assisting the study of Pareto \nsolutions in multi-objective optimization. In: Proceedings of the 7th AIAA\/ATIO Conference, \nBelfast, Northern Ireland, September 2007 \n13. Mattison, C.A., Mullur, A.A., Messac, A.: Minimal Representation of Multiobjective Design \nSpace Using Smart Pareto Filter. In: Proceeding of the 9th AIAA\/ISSMO Symposium on \nMultidisciplinary Analysis and Optimization, Atlanta, GA, September 2002 \n14. Messac A., Mattson C.A.: Generating Well-Distributed Sets of Pareto Points for Engineering \nDesign using Physical Programming. Optimization and Engineering, Kluwer Publishers, Vol. \n3, Issue 4, pp. 431-450 (2002) \n15. Messac, A., Ismail-Yahaya, A., Mattson, C.A.: The Normalized Normal Constraint Method for \nGenerating the Pareto Frontier. Journal of the International Society of Structural and \nMultidisciplinary Optimization (ISSMO), Springer, Vol. 25, No. 2, pp. 86-98 (2003) \n16. Messac, A., Mattson, C.: Normal Constraint Method with Guarantee of Even Representation of \nComplete Pareto Frontier. AIAA Journal, Vol. 42, No. 10, pp. 2101-2111 (2004) \n17. Messac, A.: Physical Programming: Effective Optimization for Computational Design. AIAA \nJournal, Vol. 34, No. 1, pp. 149-158 (1996) \n18. Miettinen, K.M.: Nonlinear Multiobjective Optimization. Kluwer Academic, Boston (1999) \n 19. Murphy, T.E., Tsui, K.L., Allen J.K.: A review of robust design methods for multiple \nresponses. Research in Engineering Design, 16, pp.118\u2013132 (2005) \n20. Padulo, M., Campobasso, M.S., Guenov, M.D.: Comparative Analysis of Uncertainty \nPropagation methods for Robust Engineering Design. In: Proceedings of the International \nConference on Engineering Design ICED07, Paris, August 2007 \n21. Park, G.J., Lee, T.H., Hwang, K.H.: Robust Design: An Overview. AIAA Journal, 44(1), pp. \n181\u2013191 (2006) \n22. Saltelli, A., Chan, K., Scott, M.: Sensitivity Analysis. John Wiley & Sons, New York (2000) \n23. Saltelli, A., Tarantola, S., Campolongo, F., and Ratto, M.: Sensitivity Analysis in Practice: a \nguide to assessing scientific models. John Wiley & Sons, Chichester (2004) \n24. Saltelli, A., Bolado, R.: An alternative way to compute Fourier Amplitude Sensitivity Test \n(FAST). Computational Statistics & Data Analysis, Vol. 26, No. 4, pp. 445-460 (1998) \n25. Sobol\u2019, I.M.: Sensitivity Estimates for non-linear mathematical models. Mathematical \nModelling & Computational Experiments, Vol. 1, No. 4, pp. 407-414 (1993) \n15 \n26. Sobol\u2019, I.M.: Global sensitivity indices for non-linear mathematical models and their Monte \nCarlo estimates. Mathematics and Computers in Simulation, Vol. 55, pp. 271-280 (2001) \n27. Utyuzhnikov, S.V., Fantini, P., Guenov, M.D.: Numerical Method for Generating the Entire \nPareto Frontier in Multiobjective Optimization. In: Proceedings of EUROGEN 2005, 12-14, \nMunich, Germany, September 2005 \n"}
{"doi":"10.1109\/SSP.2005.1628625","coreId":"71274","oai":"oai:eprints.lancs.ac.uk:4367","identifiers":["oai:eprints.lancs.ac.uk:4367","10.1109\/SSP.2005.1628625"],"title":"Particle filtering with alpha-stable distributions","authors":["Mihaylova, L.","Brasnett, P.","Achim, A.","Bull, D.","Canagarajah, N."],"enrichments":{"references":[{"id":16357685,"title":"A method of simulating stable random variables.","authors":[],"date":"1976","doi":"10.1016\/0167-7152(95)00113-1","raw":"J. Chambers, C. Mallows, and B. Stuck. A method of simulating stable random variables. Journal of the American Statistical Association, 71:340\u2013344, 1976.","cites":null},{"id":16357668,"title":"A new approach to linear \ufb01ltering and prediction problem.","authors":[],"date":"1960","doi":"10.1115\/1.3662552","raw":"R. Kalman. A new approach to linear \ufb01ltering and prediction problem. Trans. ASME, Ser. D, J. Basic Eng., 82:34\u201345, 1960.","cites":null},{"id":16357680,"title":"Bayesian inference for time series with heavy-tailed symmetric \u00ae-stable noise process.","authors":[],"date":"1999","doi":null,"raw":"S. Godsill and E. E. Kuruoglu. Bayesian inference for time series with heavy-tailed symmetric \u00ae-stable noise process. Technical report, Techn. Report, 1999.","cites":null},{"id":16357674,"title":"Beyond the Kalman Filter: Particle Filters for Tracking Applications. Artech House,","authors":[],"date":"2004","doi":null,"raw":"B. Ristic, S. Arulampalam, and N. Gordon. Beyond the Kalman Filter: Particle Filters for Tracking Applications. Artech House, Feb. 2004.","cites":null},{"id":16357675,"title":"Djuri\u00b4 c. Gaussian particle \ufb01ltering.","authors":[],"date":"2003","doi":"10.1109\/tsp.2003.816758","raw":"J. H. Kotecha and P. M. Djuri\u00b4 c. Gaussian particle \ufb01ltering. IEEE Transactions on Signal Processing, 51(10):2592\u2013 2601, Oct. 2003.","cites":null},{"id":16357665,"title":"Djuri\u00b4 c. Gaussian sum particle \ufb01ltering.","authors":[],"date":"2003","doi":"10.1109\/tsp.2003.816754","raw":"J. H. Kotecha and P. M. Djuri\u00b4 c. Gaussian sum particle \ufb01ltering. IEEE Transactions on Signal Processing, 51(10):2602\u2013 2612, Oct. 2003.[2] A. Jaswinski. Stochastic Processes and Filtering Theory. New York: Academic Press, 1970.","cites":null},{"id":16357673,"title":"Eds. SequentialMonte Carlo Methods in Practice.","authors":[],"date":"2001","doi":null,"raw":"A.Doucet, N.Freitas, andN. Gordon, Eds. SequentialMonte Carlo Methods in Practice. New York: Springer-Verlag, 2001.","cites":null},{"id":16357683,"title":"Image denoising using bivariate \u00ae-stable distributions in the complex wavelet domain.","authors":[],"date":"2005","doi":"10.1109\/lsp.2004.839692","raw":"A. Achim and E. E. Kuruoglu. Image denoising using bivariate \u00ae-stable distributions in the complex wavelet domain. IEEE Signal Processing Letters, 12(1):17\u2013 20, Jan. 2005.","cites":null},{"id":16357681,"title":"MCMC and EM-based methods for inference in heavy-tailed processes with \u00ae-stable distribution.","authors":[],"date":"1999","doi":"10.1109\/host.1999.778731","raw":"S. Godsill. MCMC and EM-based methods for inference in heavy-tailed processes with \u00ae-stable distribution. In Proc. of the IEEE Signal Processing Workshop on Higher-order Statistics, 1999.","cites":null},{"id":16357677,"title":"Monte Carlo inference in econometric models with symmetric stable distributions.","authors":[],"date":"1999","doi":"10.1016\/s0304-4076(98)00039-6","raw":"E. Tsionas. Monte Carlo inference in econometric models with symmetric stable distributions. Journal of Econometrics, 88:365\u2013401, 1999.","cites":null},{"id":16357682,"title":"On-line Bayesian estimation of AR signals in symmetric alpha-stable noise.","authors":[],"date":"2004","doi":"10.1109\/tsp.2005.861886","raw":"M. Lombardi and S. Godsill. On-line Bayesian estimation of AR signals in symmetric alpha-stable noise. Technical report, 2004.","cites":null},{"id":16357686,"title":"Parameterestimationandblindchannel identi\ufb01cation in impulsive signal environment.","authors":[],"date":"1995","doi":null,"raw":"X.MaandC.Nikias. Parameterestimationandblindchannel identi\ufb01cation in impulsive signal environment. IEEE Tran. Sign. Proc., 43(12):2884\u20132897, Dec. 1995.","cites":null},{"id":16357679,"title":"SAR image denoising via Bayesian wavelet shrinkage based on heavytailed modeling.","authors":[],"date":"2003","doi":"10.1109\/tgrs.2003.813488","raw":"A. Achim, P. Tsakalides, and A. Bezerianos. SAR image denoising via Bayesian wavelet shrinkage based on heavytailed modeling. IEEE Trans. Geosci. and Remote Sensing, 41:1773\u20131784, Aug. 2003.","cites":null},{"id":16357678,"title":"Scalar quantization of heavy-tailed signals.","authors":[],"date":"2000","doi":"10.1049\/ip-vis:20000470","raw":"P. Tsakalides, P. Reveliotis, and C. L. Nikias. Scalar quantization of heavy-tailed signals. IEE Proceedings - Vision, Image and Signal Processing, 147(5):475\u2013484, Oct. 2000.","cites":null},{"id":16357676,"title":"Signal processing with fractional lower order moments: Stable processes and their applications.","authors":[],"date":"1993","doi":"10.1109\/5.231338","raw":"M. Shao and C. Nikias. Signal processing with fractional lower order moments: Stable processes and their applications. Proceedings of the IEEE, 81(7), July 1993.","cites":null},{"id":16357684,"title":"Stable Non-Gaussian Random Processes: Stochastic Models with In\ufb01nite Variance.","authors":[],"date":"1994","doi":"10.2307\/2291104","raw":"G. Samorodnitsky and M S Taqqu. Stable Non-Gaussian Random Processes: Stochastic Models with In\ufb01nite Variance. Chapman and Hall, New York, 1994.","cites":null},{"id":16357670,"title":"Unscented \ufb01ltering and nonlinear estimation.","authors":[],"date":"2004","doi":"10.1109\/jproc.2003.823141","raw":"S. Julier and J. Uhlmann. Unscented \ufb01ltering and nonlinear estimation. Proceedings of the IEEE, 92(3):401\u2013422, 2004.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2005","abstract":"In this paper we introduce a novel sequential Monte Carlo technique, which is based on the family of symmetric alpha- stable (SAS) distributions. Sequential Bayesian estimation generally involves recursive estimation of filtering and predictive distributions of unobserved signals from their noisy measurements. In our proposed algorithm, the relevant density functions are approximated by particles drawn from stable distributions. We call this novel technique SAS particle filtering (SASPF). We assess the performance of the SASPF in comparison with the Gaussian Sum particle filter (GSPF) [1] and a standard (non-parametric) particle filter (PF). Results obtained using highly nonlinear models with simulated data show that the SASPF outperforms the GSPF and compares very favorably with the PF","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/71274.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/4367\/1\/IEEE_SSP_05_A235.pdf","pdfHashValue":"44bd0533e008bd4120f539fbd2aae3e42c7eb898","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:4367<\/identifier><datestamp>\n      2018-01-24T02:11:20Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Particle filtering with alpha-stable distributions<\/dc:title><dc:creator>\n        Mihaylova, L.<\/dc:creator><dc:creator>\n        Brasnett, P.<\/dc:creator><dc:creator>\n        Achim, A.<\/dc:creator><dc:creator>\n        Bull, D.<\/dc:creator><dc:creator>\n        Canagarajah, N.<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        In this paper we introduce a novel sequential Monte Carlo technique, which is based on the family of symmetric alpha- stable (SAS) distributions. Sequential Bayesian estimation generally involves recursive estimation of filtering and predictive distributions of unobserved signals from their noisy measurements. In our proposed algorithm, the relevant density functions are approximated by particles drawn from stable distributions. We call this novel technique SAS particle filtering (SASPF). We assess the performance of the SASPF in comparison with the Gaussian Sum particle filter (GSPF) [1] and a standard (non-parametric) particle filter (PF). Results obtained using highly nonlinear models with simulated data show that the SASPF outperforms the GSPF and compares very favorably with the PF.<\/dc:description><dc:date>\n        2005<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/4367\/1\/IEEE_SSP_05_A235.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/SSP.2005.1628625<\/dc:relation><dc:identifier>\n        Mihaylova, L. and Brasnett, P. and Achim, A. and Bull, D. and Canagarajah, N. (2005) Particle filtering with alpha-stable distributions. In: Statistical Signal Processing, 2005 IEEE\/SP 13th Workshop on. , 381 - 386. ISBN 0-7803-9403-8<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/4367\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/SSP.2005.1628625","http:\/\/eprints.lancs.ac.uk\/4367\/"],"year":2005,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"PARTICLE FILTERING WITH ALPHA-STABLE DISTRIBUTIONS\nLyudmila Mihaylova, Paul Brasnett, Alin Achim, David Bull and Nishan Canagarajah\nDepartment of Electrical and Electronic Engineering, University of Bristol\nmila.mihaylova@bristol.ac.uk, paul.brasnett@bristol.ac.uk, alin.achim@bristol.ac.uk\nABSTRACT\nIn this paper we introduce a novel sequential Monte Carlo\ntechnique, which is based on the family of symmetric \u03b1-\nstable (S\u03b1S) distributions. Sequential Bayesian estimation\ngenerally involves recursive estimation of filtering and pre-\ndictive distributions of unobserved signals from their noisy\nmeasurements. In our proposed algorithm, the relevant den-\nsity functions are approximated by particles drawn from sta-\nble distributions. We call this novel technique S\u03b1S par-\nticle filtering (S\u03b1SPF). We assess the performance of the\nS\u03b1SPF in comparison with the Gaussian Sum particle filter\n(GSPF) [1] and a standard (non-parametric) particle filter\n(PF). Results obtained using highly nonlinear models with\nsimulated data show that the S\u03b1SPF outperforms the GSPF\nand compares very favorably with the PF.\n1. INTRODUCTION\nRecently, there has been considerable interest in solving the\nproblem of sequentially estimating the state of a dynamic\nsystem based on sensor measurements [2]. Among the dif-\nferent solutions, the Kalman filter [3] remains probably the\nmost well known together with its variants - the extended\nKalman filter (EKF) [2] and the unscented Kalman filter\n(UKF) [4]. However, Kalman filters are generally limited\nby the ubiquitous nonlinearity and non-Gaussianity of the\nphysical world. Particle filtering methods (sometimes also\nrefered to as Monte Carlo techniques) have been thus pro-\nposed as powerful tools, able to handle multivariate data and\nnonlinear \/ non-Gaussian processes [5, 6]. Particle filtering\nrelies on a sample-based reconstruction of probability den-\nsity functions. Multiple particles (samples) of the variables\nof interest are generated, each one associated with a weight\nthat characterises the quality of a specific particle. An esti-\nmate of the variable of interest is obtained by the weighted\nsum of particles. The different particle filters differ from\neach other in the way they propagate the probability density\nThis work has been conducted with support from the UK\nMOD Data and Information Fusion Defence Technology Centre\nunder project DIF DTC 2.2.\nfunctions. Most sequential Monte Carlo algorithms are non-\nparametric techniques, directly propagating a sample based\nrepresentation of the probability density function. However,\nsome recently developed algorithms, such as the Gaussian\nparticle filter (GPF) [7] offer a parameterised solution, i.e.\nthey use a Gaussian assumption and propagate the first two\nmoments (mean and covariance). They approximate poste-\nrior densities by single Gaussians like the EKF and its vari-\nants. The GPF has also been used as a building block for\nmore complex filters, called the Gaussian sum particle fil-\nter (GSPF) [1] that approximate the posterior densities by\nmixtures of Gaussian components.\nA more general distribution that includes the Gaussian\ndensity as a limiting case is the \u03b1-stable distribution. It has\nbeen used to model many phenomena where the Gaussian\ndistribution is not a reasonable choice, for instance, noises\nwith an impulsive nature. Signals and noises of such class\ncontain sharp spikes or occasional bursts [8]. Impulsive\nnoises, which can be modelled with \u03b1-stable distributions\ninclude atmospheric noise in radio links, ambient acoustic\nnoise in underwater sonar and submarine communications,\nas well as lightening, switching transients and accidental\nhits in telephone lines. Different phenomena have also been\nmodelled successfully with \u03b1-stable distributions in eco-\nnomics [9], physics, biology, and electrical engineering [8],\nincluding communications and image processing [10, 11].\nSo far alpha-stable distributions have not been used\nwithin the Monte Carlo framework, apart from in [12, 13,\n14, 15]. In [14] they have been applied to solve parameter\nestimation problems in time-series. A Rao-Blackwellised\nimplementation was reported without a direct evaluation of\nthe \u03b1-stable probability density function, which in general\nis unavailable in closed form. In [12, 13] a batch-based\nMarkov chain Monte Carlo (MCMC) method is proposed,\nwhilst [14] develops a sequential Monte Carlo framework\nfor on-line estimation with measurements corrupted with \u03b1-\nstable noise. Finally, in [15] Monte Carlo techniques were\nemployed in order to derive a maximum likelihood estima-\ntor for the parameters of an S\u03b1S distributed signal mixed\nwith additive Gaussian noise.\nIn this paper we develop a parameterised particle filter,\ncalled S\u03b1S particle filter. It propagates the filtering density\nthrough sequential evaluation of the parameters of the stable\ndensity. Since \u03b1-stable distributions incorporate the Gaus-\nsian distribution as a particular case, the S\u03b1S particle filter\ncan be regarded as a natural generalisation of the GPF [7]\nand of the GSPF [1].\nThe structure of the paper is as follows. Section 2 re-\ncalls the main properties of the \u03b1-stable distribution. Sec-\ntion 3 develops an \u03b1-stable particle filter. Section 4 presents\nresults with synthetic data examples and assesses the per-\nformance of the S\u03b1S particle filter in comparison with the\nstandard PF and the GSPF. Finally, conclusions and open\nissues for future research are highlighted in Section 5.\n2. BASIC PROPERTIES OF S\u03b1S DISTRIBUTIONS\nThe appeal of S\u03b1S distributions as a statistical model for\nsignals derives from some important theoretical and empiri-\ncal reasons. First, stable random variables satisfy the stabil-\nity property which states that linear combinations of jointly\nstable variables are indeed stable. Second, stable processes\narise as limiting processes of sums of independent identi-\ncally distributed (i.i.d.) random variables via the generalised\ncentral limit theorem. Actually, the only possible non-trivial\nlimit of normalised sums of i.i.d. terms is stable. On the\nother hand, strong empirical evidence suggests that many\ndata sets in several physical and economic systems exhibit\nheavy tail features that justify the use of stable models [8].\nGenerally, there is no closed-form expression for the\nprobability density function of S\u03b1S distributions. Conse-\nquently, the most convenient way to define them is by means\nof their characteristic function\n\u03d5(\u03c9) = exp(j\u03b4\u03c9 \u2212 \u03b3|\u03c9|\u03b1) (1)\nwhere\n\u2022 \u03b1 is the characteristic exponent , with values 0 <\n\u03b1 \u2264 2. It is arguably the most important parameter as\nit determines the shape of the distribution. It controls\nthe heaviness of the tails of the density function. A\nsmall positive value of \u03b1 indicates severe impulsive-\nness, and thus tails are heavier, while a value of \u03b1\nclose to 2 indicates more Gaussian type behaviour. A\nvalue of \u03b1 = 1 corresponds to Cauchy distribution.\n\u2022 \u03b3 is the dispersion parameter (\u03b3 > 0), which deter-\nmines the spread of the density around the location\nparameter. It behaves in a similar way to the variance\nof the Gaussian density, and it is, in fact, equal to half\nthe variance when \u03b1 = 2, for the Gaussian case.\n\u2022 \u03b4 is the location parameter (\u2212\u221e < \u03b4 <\u221e). It corre-\nsponds to the mean for 1 < \u03b1 \u2264 2, and to the median\nfor 0 < \u03b1 \u2264 1.\nA S\u03b1S distribution characterised by the above three param-\neters is denoted as S(\u03b1, \u03b3, \u03b4). The case \u03b1 = 2 corresponds\nto the Gaussian distribution, while \u03b1 = 1 corresponds to\nthe Cauchy distribution. The density functions in these two\ncases are given by\nf\u03b1=2(\u03b3, \u03b4;x) =\n1\u221a\n4pi\u03b3\nexp\n{\n\u2212 (x\u2212 \u03b4)\n2\n4\u03b3\n}\n, (2)\nf\u03b1=1(\u03b3, \u03b4;x) =\n\u03b3\npi[\u03b32 + (x\u2212 \u03b4)2] . (3)\nGeneral \u03b1-stable density members do not possess finite\nsecond or higher moments [16]. In particular, the variance\nof a stable distribution with \u03b1 < 2 does not exist, making\nthe use of variance as a measure of dispersion meaningless.\nHowever, the dispersion of a stable random variable plays\nan analogous role to the variance. The larger the dispersion\nof an \u03b1-stable variable is, the more spread it is around its\nlocation parameter [8].\n3. AN ALPHA-STABLE PARTICLE FILTER\nConsider a dynamic system described by the following\ndiscrete-time state-space model\nxk+1 = f(xk,vk), (4)\nyk+1 = h(xk+1,wk+1), (5)\nwhere xk \u2208 Rnx is the unobserved system state vector,\nvk \u2208 Rnv is the system noise assumed to belong to the class\nof \u03b1-stable symmetric processes; yk \u2208 Rnz is the measure-\nment vector, wk \u2208 Rnw is a white Gaussian noise, and k is\nthe discrete time. Functions f(.) and h(.) are nonlinear in\ngeneral.\nIn many statistical signal processing problems the pri-\nmary objective is the reconstruction of the filtering probabil-\nity density function p(xk|y1:k), with y0:k = {y1, . . . ,yk}\nbeing the set of all measurements available up to the mo-\nment k. Denote with N the number of particles.\nThe standard particle filtering technique is a non- para-\nmetric inference technique, whilst the \u03b1-stable particle filter\nthat we develop is a parametric technique, since it reduces\nthe uncertainty to the calculation of the parameters of the\n\u03b1-stable distribution. The \u03b1-stable particle filter represents\nan extension to the GPF and of the GSPF. The GPF is based\non the particle filtering concept, and it approximates the fil-\ntering and predictive state distributions by single Gaussians.\nThe algorithm achieves this by the propagation of the first\ntwo moments of the Gaussian distribution, namely the mean\nand covariance through particles.\nIn a similar way, the S\u03b1SPF approximates the filtering\nand predictive state densities by \u03b1-stable densities using the\nMonte Carlo methodology. It propagates the parameters of\nthe S\u03b1S distribution, \u03b1, \u03b3 and \u03b4 through particles.\nThe S\u03b1SPF algorithm is described in Table 1.\nTable 1 The symmetric \u03b1-stable particle filter\nInitialisation\nFor k = 0 draw samples from S(\u03b10,\u03b30, \u03b40) and denote them\n{x(j)0 }Nj=1, for each state vector component i = 1, . . . , nx. In\norder to sample from a stable distribution we use the method pro-\nposed by Chambers et. al [17]. Set initial weights W (j)0 = 1\/N .\nTime update\nFor k = 0, 1, 2, . . .,\n1. For j = 1, . . . , N , sample x(j)k+1 \u223c p(xk+1|x(j)k ), from\nthe motion model (4).\nMeasurement update\n2. For j = 1, . . . , N , compute the weights\nW\n(j)\nk+1 =\np(yk+1|x(j)k )S(\u03b1k, \u03b4k,\u03b3k)\nq(x\n(j)\nk |y0:k+1)\n(6)\nUnder the assumption that the importance function\nq(x\n(j)\nk |y0:k+1) = S(\u03b1k, \u03b4k,\u03b3k), then the weights are equal\nto:\nW\n(j)\nk+1 = p(yk+1|x(j)k+1).\n3. Normalise the weights W (j)k+1 =W\n(j)\nk+1\/\n\u2211N\nj=1W\n(j)\nk+1.\n4. Update the characteristic exponent \u03b1k+1, and the other\nparameters \u03b3k+1 and \u03b4k+1 from the shifted particles\nW\n(j)\nk+1x\n(j)\nk+1 using the log |S\u03b1S| method proposed in [18].\nOutput\n5. Estimate the overall state\nx\u02c6k+1 =\nN\u2211\nj=1\nW\n(j)\nk+1x\n(j)\nk+1, (7)\n6. Set k = k + 1 and return to step 2.\nAn advantage of the S\u03b1SPF compared to the PF and\nthe GSPF is that the S\u03b1SPF does not require a resampling\nprocedure. Note that the resampling step in the PF is with\nrespect to the particles, whilst in the GSPF it is applied to\nthe mixing components. The S\u03b1SPF relies on a parametric\nrepresentation of the filtering and predictive state densities,\nwhilst the PF representations of the state densities is non-\nparametric, and in this sense the PF is more general than the\nS\u03b1SPF. On the other hand, the S\u03b1SPF represents a gener-\nalisation of the GPF and GSPF.\n4. PERFORMANCE EVALUATION AND RESULTS\nThe developed S\u03b1SPF is compared to a standard PF and a\nGSPF.\nExample 1. Consider the system model given in [7, 1]\nxk+1 = 0.5xk + 25\nxk\n1 + x2k\n+ 8cos(1.2k) + vk, (8)\nwith a measurement equation\nyk+1 = xk+1 + wk+1, (9)\nwhere vk \u223c N (0, Q), wk \u223c N (0, R), with Q = 1, R =\n2.5. The S\u03b1SPF and the PF are run with N = 1000 parti-\ncles, whilst the GSPF with N = 1000 and 10 mixing com-\nponents which means that the last has 10000 particles. The\nactual state and the state estimates for a single realisation for\nall filters are given in Figure 1, the mean errors are shown\nin Figure 2 over 100 Monte Carlo runs.\n0 20 40 60 80 100\n\u221220\n\u221215\n\u221210\n\u22125\n0\n5\n10\n15\n20\nSample time k\nSt\nat\ne \nes\ntim\nat\ne\n2\n4\n1\n3\nFig. 1. State estimate from a single realisation: 1 - actual\nstate, 2 - standard PF, 3 - S\u03b1SPF, 4 - GSPF\nExample 2. This example considers a scalar system\nmodel with an additive \u03b1-stable noise,\nxk+1 = \u22122xk + 1.5x2k + vk, (10)\nand measurement equation\nyk+1 = xk+1 + wk+1, (11)\nwhere vk \u223c S(\u03b1noise, \u03b4noise, \u03b3noise). The measurement\nnoise is Gaussian wk \u223c N (0, R), with the following pa-\nrameters: \u03b1noise = 1.5, \u03b3noise = 0.5, \u03b4noise = 0, R = 1.\n0 20 40 60 80 100\n\u221214\n\u221212\n\u221210\n\u22128\n\u22126\n\u22124\n\u22122\n0\n2\n4\nSample time k\nM\nE \nof\n x\n1\n3\n2\nFig. 2. Mean error from 100 independent Monte Carlo runs:\n1 - standard PF, 2 - S\u03b1SPF, 3 - GSPF\nAs in Example 1, the S\u03b1SPF and the PF are run with\nN = 1000 particles, whilst the GSPF with N = 1000 and\n10 mixing components which means that it has 10000 par-\nticles. Since the model noise is \u03b1-stable, we draw samples\nfrom the vk \u223c S(\u03b1noise, \u03b4noise, \u03b3noise) and samples from\nxk \u223c S(\u03b1x, \u03b4x, \u03b3x).\nThe state estimate from a single realisation is presented\nin Figure 3, the corresponding mean error from 100 inde-\npendent Monte Carlo runs is shown in Figure 4. As it can\nbe seen from the figures, the standard PF and the S\u03b1SPF\noffer comparable results, while clearly outperforming the\nGSPF.\n0 5 10 15 20 25 30\n\u22123\n\u22122\n\u22121\n0\n1\n2\n3\n4\nSample time k\nSt\nat\ne \nes\ntim\nat\ne\n1\n2\n3\n4\nFig. 3. State estimate from a single realisation: 1 - actual\nstate, 2 - standard PF, 3 - S\u03b1SPF, 4 - GSPF\nThe reason for this is that a Gaussian mixture distribu-\n0 5 10 15 20 25 30\n\u22120.5\n\u22120.4\n\u22120.3\n\u22120.2\n\u22120.1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\nSample time k\nM\nE \nof\n x\n1\n2\n3\nFig. 4. Mean error from 100 independent Monte Carlo runs:\n1 - standard PF, 2 - S\u03b1SPF, 3 - GSPF\ntion with a small number of components can not accurately\nmodel heavy-tail distributions whilst S\u03b1S distributions can\nmore accurately model these heavy tail signals. Regarding\nthe computational complexity the S\u03b1SPF is more efficient\nbecause it estimates only the two parameters of the \u03b1-stable\ndistribution, whilst the GSPF approximates two moments\nper mixing component.\n5. CONCLUSIONS AND FUTURE WORK\nIn this paper we have proposed an alpha-stable particle filter\nframework and investigated its performance. It is more gen-\neral than the Gaussian sum particle filter and propagates the\nfiltering and predictive state distributions through an update\nof the parameters of the \u03b1-stable distribution. Results over\nsynthetic data examples are presented.\nSo far the iterative calculation of the parameters of the\n\u03b1-stable distribution were performed only for first-order sys-\ntems. Since the multivariate \u03b1-stable distribution has no co-\nvariance, methods to estimate its spectral measure should\nbe devised. This is an open issue for future research, as well\nas the validation of the S\u03b1SPF framework over applications\nwith real data. The developed S\u03b1SPF can be applied to dif-\nferent signal processing problems such as in queueing net-\nworks and systems with impulsive noises.\n6. REFERENCES\n[1] J. H. Kotecha and P. M. Djuric\u00b4. Gaussian sum particle filter-\ning. IEEE Transactions on Signal Processing, 51(10):2602\u2013\n2612, Oct. 2003.\n[2] A. Jaswinski. Stochastic Processes and Filtering Theory.\nNew York: Academic Press, 1970.\n[3] R. Kalman. A new approach to linear filtering and predic-\ntion problem. Trans. ASME, Ser. D, J. Basic Eng., 82:34\u201345,\n1960.\n[4] S. Julier and J. Uhlmann. Unscented filtering and nonlinear\nestimation. Proceedings of the IEEE, 92(3):401\u2013422, 2004.\n[5] A. Doucet, N. Freitas, and N. Gordon, Eds. Sequential Monte\nCarlo Methods in Practice. New York: Springer-Verlag,\n2001.\n[6] B. Ristic, S. Arulampalam, and N. Gordon. Beyond the\nKalman Filter: Particle Filters for Tracking Applications.\nArtech House, Feb. 2004.\n[7] J. H. Kotecha and P. M. Djuric\u00b4. Gaussian particle filter-\ning. IEEE Transactions on Signal Processing, 51(10):2592\u2013\n2601, Oct. 2003.\n[8] M. Shao and C. Nikias. Signal processing with fractional\nlower order moments: Stable processes and their applica-\ntions. Proceedings of the IEEE, 81(7), July 1993.\n[9] E. Tsionas. Monte Carlo inference in econometric models\nwith symmetric stable distributions. Journal of Economet-\nrics, 88:365\u2013401, 1999.\n[10] P. Tsakalides, P. Reveliotis, and C. L. Nikias. Scalar quan-\ntization of heavy-tailed signals. IEE Proceedings - Vision,\nImage and Signal Processing, 147(5):475\u2013484, Oct. 2000.\n[11] A. Achim, P. Tsakalides, and A. Bezerianos. SAR image\ndenoising via Bayesian wavelet shrinkage based on heavy-\ntailed modeling. IEEE Trans. Geosci. and Remote Sensing,\n41:1773\u20131784, Aug. 2003.\n[12] S. Godsill and E. E. Kuruoglu. Bayesian inference for time\nseries with heavy-tailed symmetric \u03b1-stable noise process.\nTechnical report, Techn. Report, 1999.\n[13] S. Godsill. MCMC and EM-based methods for inference in\nheavy-tailed processes with \u03b1-stable distribution. In Proc.\nof the IEEE Signal Processing Workshop on Higher-order\nStatistics, 1999.\n[14] M. Lombardi and S. Godsill. On-line Bayesian estimation\nof AR signals in symmetric alpha-stable noise. Technical\nreport, 2004.\n[15] A. Achim and E. E. Kuruoglu. Image denoising using bi-\nvariate \u03b1-stable distributions in the complex wavelet domain.\nIEEE Signal Processing Letters, 12(1):17\u2013 20, Jan. 2005.\n[16] G. Samorodnitsky and M S Taqqu. Stable Non-Gaussian\nRandom Processes: Stochastic Models with Infinite Vari-\nance. Chapman and Hall, New York, 1994.\n[17] J. Chambers, C. Mallows, and B. Stuck. A method of sim-\nulating stable random variables. Journal of the American\nStatistical Association, 71:340\u2013344, 1976.\n[18] X. Ma and C. Nikias. Parameter estimation and blind channel\nidentification in impulsive signal environment. IEEE Tran.\nSign. Proc., 43(12):2884\u20132897, Dec. 1995.\n"}
{"doi":"10.1109\/VETECS.2004.1391447","coreId":"102565","oai":"oai:epubs.surrey.ac.uk:2047","identifiers":["oai:epubs.surrey.ac.uk:2047","10.1109\/VETECS.2004.1391447"],"title":"A New Method of Improving SOVA Turbo Decoding\\ud\nfor AWGN, Rayleigh and Rician Fading Channels","authors":["Papaharalabos, Stylianos","Sweeney, Peter","Evans, Barry G"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2004","abstract":"e iterative soft output Viterbi algorithm (SOVA) is a\\ud\nsub-optimum algorithm when it is used to decode turbo codes. By normalizing its extrinsic information we get a performance improvement compared to the standard SOVA. In particular, if the extrinsic information is increased in the last decoding iteration, an additional coding gain improvement is noticed. For example, this is 0.25 dB for a frame length of 1000 bits in the additive white Gaussian noise (AWGN) channel as well as in an uncorrelated Rician fading channel at bit error rate (BER) of IO\". Also, this normalized SOVA is only about 0.25 dB worse than a turbo decoder using the Log-MAP algorithm, both in the AWGN channel and in an uncorrelated Rayleigh fading channel at BER of around Furthermore with an 8-state component code, a frame length of 500 hits performs 0.125 dB better than a\\ud\n16-state Bidirectional (Si)-SOVA turbo decoder at BER of IO-' in the AWGN channel","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"Institute of Electrical and Electronics Engineers","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:2047<\/identifier><datestamp>\n      2017-10-31T14:04:04Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:415449:70686F746F6E696373<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/2047\/<\/dc:relation><dc:title>\n        A New Method of Improving SOVA Turbo Decoding\\ud\nfor AWGN, Rayleigh and Rician Fading Channels<\/dc:title><dc:creator>\n        Papaharalabos, Stylianos<\/dc:creator><dc:creator>\n        Sweeney, Peter<\/dc:creator><dc:creator>\n        Evans, Barry G<\/dc:creator><dc:description>\n        e iterative soft output Viterbi algorithm (SOVA) is a\\ud\nsub-optimum algorithm when it is used to decode turbo codes. By normalizing its extrinsic information we get a performance improvement compared to the standard SOVA. In particular, if the extrinsic information is increased in the last decoding iteration, an additional coding gain improvement is noticed. For example, this is 0.25 dB for a frame length of 1000 bits in the additive white Gaussian noise (AWGN) channel as well as in an uncorrelated Rician fading channel at bit error rate (BER) of IO\". Also, this normalized SOVA is only about 0.25 dB worse than a turbo decoder using the Log-MAP algorithm, both in the AWGN channel and in an uncorrelated Rayleigh fading channel at BER of around Furthermore with an 8-state component code, a frame length of 500 hits performs 0.125 dB better than a\\ud\n16-state Bidirectional (Si)-SOVA turbo decoder at BER of IO-' in the AWGN channel.<\/dc:description><dc:publisher>\n        Institute of Electrical and Electronics Engineers<\/dc:publisher><dc:date>\n        2004<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/2047\/1\/SRF002094.pdf<\/dc:identifier><dc:identifier>\n          Papaharalabos, Stylianos, Sweeney, Peter and Evans, Barry G  (2004) A New Method of Improving SOVA Turbo Decoding for AWGN, Rayleigh and Rician Fading Channels   Proceedings of 59TH IEEE Vehicular Technology Conference, 5.  pp. 2862-2866.      <\/dc:identifier><dc:relation>\n        http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1391447<\/dc:relation><dc:relation>\n        10.1109\/VETECS.2004.1391447<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/2047\/","http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1391447","10.1109\/VETECS.2004.1391447"],"year":2004,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"A New Method of Improving SOVA Turbo Decoding \nfor AWGN, Rayleigh and Rician Fading Channels \nStylianos Papaharalabos, Peter Sweeney, Barry G. Evans \nCentre for Communication Systems Research (CCSR) \nUniversity of Surrey \nGuildford, Surrey, GU2 7XH, UK \ns.papaharalabos@surrey.ac.uk \nAbstracl-The iterative soft output Viterbi algorithm (SOVA) is a \nsub-optimum algorithm when it is used to decode turbo codes. By \nnormalizing its extrinsic information we get a performance \nimprovement compared to the standard SOVA. In particular, if \nthe extrinsic information is increased in the last decoding \niteration, an additional coding gain improvement is noticed. For \nexample, this is 0.25 dB for a frame length of 1000 bits in the \nadditive white Gaussian noise (AWGN) channel as well as in an \nuncorrelated Rician fading channel at bit error rate (BER) of \nIO\". Also, this normalized SOVA is only about 0.25 dB worse \nthan a turbo decoder using the Log-MAP algorithm, both in the \nAWGN channel and in an uncorrelated Rayleigh fading channel \nat BER of around Furthermore with an 8-state component \ncode, a frame length of 500 hits performs 0.125 dB better than a \n16-state Bidirectional (Si)-SOVA turbo decoder at BER of IO-' \nin the AWGN channel. \nKeywords-turbo codes, iterative SOVA decoder, extrinsic \ninformation \n1. INTRODUCTION \nTurbo codes are among the most powerful error correcting \ncodes approaching very close to the Shannon's limit with a \nvery large interleaver size [I] .  To decode such codes, the \nmaximum a posteriori (MAP) algorithm [2] was modified to be \nsuitable for decoding recursive systematic convolutional (RSC) \ncodes in an iterative process. \nHowever, in practice the MAP turbo decoder is too \ncomplex to be implemented due to the large number of \nmultiplications and the need of non-linear functions. For that \nreason, two simplified versions of it were proposed in the past, \nnamely Log-MAP and Max-Log-MAP [3].  The latter algorithm \nis sub-optimum in terms of bit error rate (BER) performance \nbut easier to be implemented, as it requires only additions and \nthe max operator. \nAnother sub-optimum algorithm that is suitable for turbo \ndecoding is the soft output Viterbi algorithm (SOVA). It is a \nmodified Viterbi algorithm (VA) that produces, in addition to \nthe most likely path sequence, a reliability value of each \nestimated bit [4]. It was found that the iterative SOVA is 0.7 \ndB worse than the MAP algorithm at BER of IO4 [3].  This is \nlargely because the SOVA considers only two path sequences \nto update its soft output, namely the survivor and the \nconcurrent path sequences. \nA first attempt to improve the SOVA was reported in [ 5 ]  \nwith two proposed modifications, so as to comect its soft output \nand to follow a Gaussian distribution. In the first modification, \nthe extrinsic information is normalized by multiplying with a \ncorrecting factor c that depends on the variance of the decoder \noutput, while in the second one (that is less effective) the \ncorrelation in the decoder input is eliminating by inserting two \nmore correcting coeficients. Another attempt to improve the \nSOVA was described in [6] where the reliability of the soft \noutput is limited to a small range of values. In [6] was also \ndescribed the SOVA updating soft output rule by Butfail and it \nwas later shown that this is equivalent to the Max-Log-MAP \nalgorithm [7]. Finally, the Max-Log-MAP turbo decoder was \nimproved in [SI by following a normalization method similar to \n[5 ]  hut keeping constant the correcting factor c. \nIn this paper, we propose a new normalization scheme \nbased on the observations of [SI, [6] ,  [SI using Hagenauer's \nupdaring nile (HR) [4]. We keep the same correcting factor c \nin every iteration step as in [SI, which is constant and does not \ndepend on the variance of the decoder output as it does in [ 5 ] .  \nWe refer to this as nom1 method. In addition, due to the \nobserved small average absolute reliability values after the first \niterations compared to the ones by the Battail S upduting nile \n(BR) [6] ,  we increase the correcting factor c only in the last \ndecoding iteration. This new normalization method is referred \nto as norm2. By doing this, a coding gain improvement of 0.25 \ndB at BER of around is achieved compared to the first \nnormalization scheme (norm]) for specific turbo encoding \nparameters and correcting factors. The complexity that is added \nto the turbo decoder is relatively small, just one more \nmultiplication of the extrinsic information with a constant \nfactor, per component decoder and decoding iteration. \nIn section 11 the basic procedure of the iterative SOVA is \ndescribed, followed by the proposed improving algorithm in \nthe next session. In section IV simulation results are shown and \nare compared to existing references. Finally, conclusions are \ndrawn in section V. \n0-7803-8255-2\/04P$u).00 02004 IEEE. 2862 \nAuthorized licensed use limited to: University of Surrey. Downloaded on April 27,2010 at 15:51:24 UTC from IEEE Xplore.  Restrictions apply. \n11. THE ITERATIVE SOVA \nA .  A Basic Description of the SOVA \nThe SOVA is based on the classical process of the VA, \nfollowed by an updating rule to produce soft outputs on thc \nestimated hit sequence. \nAt an instant time k the VA finds the survivor path, which \nis the path that has the smallest path metric between all the \nmetrics of paths that enter each state. The path metric is the \nsummation of all the branch metrics of a state sequence. To do \nthis, we define the branch metric between two states of a path, \nbased on the squared Euclidean distance, as \ni=n \nwhere l \/n  is the code rate, n is the codeword size, xk,; is the i-th \ntransmitted symbol (or bit assuming BPSK modulation) and \nyk,i is the corresponding received value at the receiver. \nWhen the process of the VA has finished, only two paths \nare needed for the SOVA, thc survivor or the best path and its \nstrongest competitor (concurrent) path, that is the path which \nhad diverged at a past time k-v and merged to the same state as \nthe survivor path at time k. Their path metric difference A is \nalso stored and the process of the SOVA is starting from the \nlast state of the trellis by tracing back. \nTo produce the bit Log Likelihood Ratio (LLR) values, we \nfirst initialize all the reliabilities of the survivor sequence to \nL, = + = and then we update as \nL,? = min(L, ,A), if uJ # uc (2) \nonly when the estimated bit of the survivor path sequence ( U ? )  \nand the corresponding estimated hit of the concwent path \nsequence ( U , )  at an instant time k are different each other. \nIn addition to the above rule (HR), the BR updates the \nreliability values in case of us = uc as well by \nL, =min(L,,A+L,), if., = U <  (3) \nwhere L, is another reliability value representing the concurrent \npath. That additional updating rule makes the BR superior \ncompared to the HR. \n0-7803-8255-2\/04\/$20.00 C32W IEEE. \nWe also note that the noise variance of the channel is not \nrequired when calculating the hit LLR values. That leads to a \nsimpler implementation method. \nB. The SOVA Turbo Decoder \nNormalize \n4 SOVA Y k S  \nextrinsic 22 \nextrinsic ZI \nNormalize \nFig. I .  SOVA turbo deccder block diagram \nThe basic turbo decoding process is shown in Fig. 1 where \nthe key issue is the \u2018effective\u2019 use of the extrinsic information \nthat is passed from one component decoder to the other in \nevery iteration step. \nThe concept of normalizing the extrinsic information had \nalready been introduced in [ I ]  where the MAP algorithm was \nused. In that case, the extrinsic information needed to be \ndivided by a proper number to avoid increasing BER at low \nsignal-to-noise ratio (SNR) values. This kind of normalization \ncan be avoided by passing LLR values, as opposed to channel \nvalues between the two component decoders [SI. A more \ndetailed description of the normalization of the extrinsic \ninformation when either the MAP or the SOVA iterative \ndecoding is used can be found in [lo]. \n111. IMPROVING THE SOVA \nA .  A Normalization Approach ofthe SOVA Output \nIn [6]  it was proposed to limit the reliability values of the \nSOVA to a smaller range by defining an optimum threshold \nvalue. This was observed by plotting both the average absolute \nreliability value of the soft output and the average absolute \nextrinsic information in two cases. In the first one, the BR \nupdating rule was followed, while in the second case the HR \nupdating rule was followed. \nIn more detail the BR gives better performance, as the \nreliability values are smaller than the HR during the first \niterations. That is the scope of this normalization method; to \nreduce the over-estimated reliability values of the HR that are \nobserved in the first iterations by limiting the soft output values \ninto a smaller range. \n2863 \nAuthorized licensed use limited to: University of Surrey. Downloaded on April 27,2010 at 15:51:24 UTC from IEEE Xplore.  Restrictions apply. \nB. The Proposed Method \nAssume that the total number of decoding iterations is N .  \nThe extrinsic information that is passed from the one \ncomponent decoder to the other one can be normalized, if we \nmultiply by a proper value m such that \nGenerator polynomials \n(recursive, feed-forward) \nm[i] = c, 1 5 i 5 N (4) \n(13,15)0, 8-states, 3GPP \nWe refer to this method as norml method. If we further \nincrease the normalization factor m in the last decoding \niteration, we get the norm2 method. That means \n~ \nlnterleaver type pseudo-random \nModulation type BPSK \nCode rate 1 13 \nChannel type AWGNIUncorrelated \nand \n._ \nDecoding iterations \nSOVA updating rule \nm [ i ] = c ,  I < i < N - l  ( 5 )  \nm[i] >c,  i =  N (6) \nRice fading \n8 \nHagenauer (HR) \nWhat we propose as norm2 is the inverse of the \nnormalization method that is was described in [6]. As far as \nthe ER produces soft outputs that are greater that the HR after \nthe first iterations, we can easily correct the HR soft output by \nincreasing the extrinsic information during the last decoding \niteration only. According to the plots in [6], there should he at \nleast four decoding iterations to achieve a noticeable coding \ngain improvement. \nThe search for good m values is an exhaustive process and \nit is based on computer simulation tests. They depend on the \nturbo encoding parameters such as the code memory length \nand the code rate. An example can be found in [I  I ]  where the \nnorml method was used for a specific turbo encoder. In case \nof the norm2 method, the hest m value in the last decoding \niteration had to be around twice the m value in the previous \ndecoding iterations. \nIV. SIMULATION RESULTS \nA.  The A WGN Channel \nIn this section we consider the case of the additive white \nGaussian noise (AWGN) channel. This is the case of a \ncommunication link between a fixed terminal and a satellite. \nTwo different frame lengths of bits, 500 bits and 1000 bits are \nconsidered in order to compare with existing results. In all the \nsimulations SO millions bits are transmitted, while the rest of \nthe parameters are shown in Table 1. \nE \n. . . . . . . . . . . . . . . . . . . . . . . . . . . , . . . . . . . . . . . . . . . . . . . , . . . . . . . . . . . . . . . . . \n0 0.5 1 1.5 2 2.5 3 \nE W o  (dB) \nFig. 2. Turbo cading performance with WO types of SOVA nonnaliralion \nand reference performance compaisan in the AWGN channel after 8 decoding \nitemlions and 500 bib frame. \nIn Fig. 2 is plotted the turbo coding performance \nconsidering both the norml and the norm2 methods. At BER of \nthe coding gain improvement using the norm2 instead of \nthe norml method is 0.125 dB. This was explained in the \nprevious section where the soft output decoder values in the \nnorm2 method are increased to approximate the BR updating \nrule. \nIn the same figure is also plotted the turbo coding \nperformance of the classical (37,21), , 16-state turbo encoder \nusing both the Bi-(Bidirectional) SOVA and the MAP \nalgorithm [12]. The other parameters in that reference are \nexactly the same as in Table I. It is noticed that both the nom1 \nand the norm2 methods perform better than the Bi-SOVA at \nany BER. For example the norm2 method performs 0.125 dB \nbetter than the Bi-SOVA at BER of Also, the norm2 \nmethod performs exactly the same as the MAP algorithm at \nBER lower than IO-'. When the comparison is done with the \nsame 8-state turbo encoder but with MAP iterative decoding, \nthe norm2 method is only 0.125 dB worse at BER of around \nWe also assunie a second frame length equal to 1000 bits \nand 6 decoding iterations. In this case, the norm2 method \nperforms 0.25 dB better than the norml method at BER of \n10\" (Fig. 3). \nIn the same figure it is noticed that at BER of IO-' both the \ntwo normalization schemes approach the second normalization \nmethod of Fig. 5 in [13], although in this reference a different \ninterleaver was used, namely the prime interleaver which has a \nsuperior performance compared with the pseudo-random \ninterleaver. For example it is 0.2 dB better at BER of IO\" \nusing a 1280 bits frame over a frequ7ncy selective Rayleigh \nfading channel [ 141. \n0-7803-8255-z\/wps20.00 Oux)4 IEEE. 2861 \nAuthorized licensed use limited to: University of Surrey. Downloaded on April 27,2010 at 15:51:24 UTC from IEEE Xplore.  Restrictions apply. \nI \n0 5  I 1 5  2 2 5  \nE m 0  ldBl \nFig. 3. Turbo coding performance with tho types of SOVA nomalimlion \nand reference performance comparison in the AWGN channel after 6 decoding \niterations and 1000 bis frame \nFor comparison, the turbo coding performance with \npseudo-random interleaver when using the Log-MAP \nalgorithm is also plotted. It can be seen that the norm2 method \nis 0.25 dB worse than the Log-MAP algorithm with pseudo- \nrandom intcrleaver at BER of around and 0.75 dB worse \nthan the Log-MAP algorithm with prime interleaver at the \nsame BEK, which is acceptable given the complexity savings. \nB. Uncorreluted Rayleigh Fading Channel \nThe uncorrelated (independent) Rayleigh fading channel is \nconsidered in this paragraph. This is the case of the propagation \nchannel between a mobile terminal and a base station. The \nframe length is equal to 1000 bits and the rest ofthe parameters \nare shown in Table 1. Also, no channel state information is \navailable at the decoder in order to compare with [ 151, [16]. \nThe 8-state turbo coding performance with the normalized \nSOVA (either the norml or the norm2) as well as the classical \n(37,21), 16-state turbo encoder with the standard SOVA and \nthe MAP algorithm are plotted in the same figure (Fig. 4). \nThe coding gain improvement using the norm2 instead of \nthe norm1 method is 0.25 dB at BER of around I O \u201d ,  exactly \nthe same as in the AWGN channel for the same frame length \nThat means this improvement is independent of the channel \ncharacteristics when the same weighting factors are used. \nEither the norml or the norm2 method performs 0.25 dB \nbetter than the classical (37,21), 16-state turbo encoder with \nthe standard SOVA at BER of around If the MAP \nalgorithm is considered to decode the same 16-state turbo code, \nthe normalized SOVA is 0.25 dB worse at BER of around \n10-6 \nIn order to keep the same performance improvement of the \nnormalized SOVA at lower BER, we consider the case of \nanother 16-state turbo encoder with generator polynomials \n(3 1,33), and the rest of the parameters from Table I. As can be \nseen from Fig. 3, the coding gain improvement using the \nnorm2 instead of the norml method is still 0.25 dB at BER of \naround lo-\u2018. In addition, this 16-state turbo encoder is 0.25 dB \nbetter than the 8-state turbo encoder at BER of around 10-6 \nwhen using either the norml or the norm2 methods \nrespectively. Also, it approaches to 0.25 dB of the MAP \nalgorithm of the classical (37,21), 16-state turbo encoder at \nBER of around and outperforms the SOVA algorithm of \nthe same classical turbo encoder by 0.25 dB at BER of around \nI ............. \n. . . . . . . . . .  . . . . . . . . . . . . . . . . . . . . . . .  \n. . . . . . . . . . . . . .  \n.\\ .... . \\ I .  . .: : : :.:: i : . :  :: . . . .  :... . . . . . . .  ]\nI \n2.75 3 3.25 3.5 3.75 4 \nE m 0  (dB) \nFig. 4. Turbo coding performance with hvo trpes of SOVA normalization \nand reference performance campanson in an uncorrelated Rayleigh fading \nchannel after 8 decoding iterations and 1000 bits h m e .  \nC. Uncoweluted Rician Fading Channel \nHere we extend the previous simulation results to include \nan uncorrelated (independent) Rician fading channel. This is \nthe situation of a communication link between a mobile \nterminal and a satellite. It is known that when the Rice factor k \nis zero, this is equivalent to a Rayleigh fading channel, while \nwhen the Rice factor k is infinite, this is equivalent to an \nAWGN channel. The simulation parameters are the same as in \nTable I with a 1000 bits frame and no channel state information \navailable at the decoder. \nThe 8-state turbo coding performance with the normalized \nSOVA (either the norml or the norm2) for various values of \nthe Rice factor k is plotted in Fig. 5. In the same figure is also \nshown the Log-MAP algorithm performance in the AWGN \nchannel. \nThe coding gain improvement using the norm2 instead of \nthe norml method is still 0.25 dB at BER of exactly the \nsame as in the previous types of channel for the same frame \nlength. \nWhen the Rice factor k is approaching the infinite, the turbo \ncode performance with the normalized SOVA (either the \nnorml or the norm2) is expected to require less than 1.5 dB at \nBER of IO-\u2019. This is taken account by observing the Fig. 3 \n0-7803-8255-2\/04p$20.00 OUXW IEEE. 2865 \nAuthorized licensed use limited to: University of Surrey. Downloaded on April 27,2010 at 15:51:24 UTC from IEEE Xplore.  Restrictions apply. \nwhere it is plotted the same turbo code performance\u2019but after 6 \ndecoding iterations. That means, in case of k + - ,  the \nnormalized SOVA is about 0.25 dB worse than the Log-MAP \ndecoding at BER of IO-\u2019. Also, the coding gain improvement \nwith the normalized SOVA when k -+= instead of k = I O  is \nabout 0.5 dB at BER of IO-\u2019 . \nI ... . ...;. , . . . . i . .  ... .;. .. ....:. .. ... . i  . . .. .,. .. ..... :.... ... .,..... .. 4 \nt0-71 I \n0 0.5 I 1.5 2 2.5 3 3.5 4 4.5 \nE m 0  (dB) \nFig. 5 .  Turbo coding performance with two types of SOVA nom1alization \nin an uncorrelated Rician fadinz channel and with Lae-MAP in the AWGN \nchannel afler 8 decoding iterations and 1000 bits ftame. I \nV. CONCLUTIONS \nTwo different normalization schemes were considered in \norder to correct the SOVA output that follows the HR updating \nrule. In the first normalization (norml) we multiply the \nextrinsic information by a constant factor that does not depend \non the variance of the decoder output. When we increase this \nfactor in the last decoding iteration only, we obtain a new \nnormalization scheme (norm2) so as to approach better the BR \nupdating rule. The complexity that is added to the turbo \ndecoder is relatively small, just one more multiplication of the \nextrinsic information with a constant factor, per component \ndecoder and decoding iteration. \nI t  was shown that the norm2 method performs 0.25 dB \nbetter than the norml method at BER of IO-\u2018 in the AWGN \nchannel as well as in an uncorrelated (independent) Rayleighi \nRician fading channel. This was done for specific turbo \nencoding parameters and correcting factors. When considering \na smaller frame of bits. the coding gain improvement of the \nnorm2 method compared to the norm1 method in the AWGN \nchannel was less, about 0.125 dB at BER of but the \nnom2 method of a turbo encoder that has half the number of \nstates performs 0.125 dB better than the Bi-SOVA at BER of \n&7803-8255-2J04620.W 02004 IEE. 2866 \nIO-\u2019 and exactly the same as the MAP algorithm at BER lower \nthan IO-\u2019. \nACKNOWLEDGMENT \nThe authors would like to thank Mr. Atta Quddus, Research \nFellow at CCSR, for his valuable help and discussion. \nREFERENCES \n[I] C. Berrou, C., A. Glavieux, and P. Thitimajshima, \u201cNear Shannon limit \nerror-correcting coding and decoding: Turbo-codes (I)\u201d, Proc. IEEE \nICC \u201893. Geneva. Switzerland, May 1993, pp. IOM-1070. \nL.R. Bahl, J. Cocke, F. Jelinek. and J. Raviv. \u201cOptimal decoding of \nlinear code for minimizing symbol error rate\u201d, IEEE Trans. InJbrm. \nTheon. vol. IT-20, Mar. 1974, pp. 284-287. \nP. Robertson, E. Villebmn, and P. Hoeher, \u201cA comparison of optimal \nand sub-optimal MAP decoding algorithms operating in the lag \ndomain\u201d, Pwc. IEEE ICC \u20189.5, Seattle, June 1995, pp. 1009-1013. \nJ. Hagenauer, and P. Hoeher, \u201cA Viterbi algorithm with son-decision \noutputs and its applications\u201d, Proc. IEEE CLOEECOM \u201889, Dallas, \nNov. 1989, pp. 1680-1686. \nL. Papke, and P. Robertson, \u201cImproved decoding with SOVA in parallel \nconcatenated (Turbo-code) scheme\u201d, Proc. IEEE ICC \u201896. July 1996, \npp. 102-106. \n[6] L Lin. and R. Cheng, \u201chnprovements in SOVA-based decoding for hlrbo \ncodes\u201d, Proc. IEEEICC \u2018Y7, June 1997. pp. 1473-1478. \n171 M. P. C. Fossorier, F. Burkert, S. Lin, and J. Hagenauer, \u201cOn the \nequivalence between SOVA and Max-Log-MAP decadings\u201d, IEEE \nCowmr. LeBers, vol. 2, no. 5 ,  May 1998, pp. 137-139. \nJ. Vogt, and A. Finger. \u201cImproving the max-log-MAP turbo decoder\u201d, \nIEE Elecr Lerrers, vol. 36, no. 23, Nov. 2000, pp. 1937-1939. \nP. Robertson. \u201cIlluminating the structure ofcade and decoder of parallel \nconcatenated recursive systematic (turbo) codes\u201d, Proc. Clobeconi \u201894, \nDec. 1994. pp. 1298-1303. \n[ I O ]  G. Colavolpe, G. Perran, and R. Raheli, \u201cExtensic information in \nilerative decoding: a unified view\u201d, IEEE Trans. Commun., vol. 49, no. \n12. Dec. 2001, pp. 2088-2094. \n[I I ]  S .  Papaharalabos, P. Sweeney, B.G. Evans, \u201cModification of branch \nmetric calculation to improve iterative SOVA decoding of turbo codes\u201d, \nIEE Elecr. Leners. vol. 39, no.19, Sep. ?003, pp. 1391-1392. \n[I21 W. Feng, and B. Vucetic, \u201cA list bidirectional son output decoder of \nturbo codes\u201d, I\u201d h r .  Svnip. on Turbo Codes. Brest, France, 1997. pp. \n288-292. \n[ 131 R. A. Stirling-Gallacher, \u201cPerformance of sub-optimal normalisation \nschemes for a turbo decoder using the soft output Viterbi algorithm\u201d, \nProc. IEEE Ini. Synip. on Pers ... Ind., ond Mob. Radio Comniun. \nIPIMRC) \u201800, Sep. 2000, pp. 888-892. \n[I41 A. Shibutani, H. Suda, F. Adachi, \u201cComplexity reduction of turbo \ndecoding\u201d, Proc. IEEE Veh. Tech. CO$ (VTC) \u2018YY Foll. Sep. 1999, pp. \n1570-1 574. \n[ I51 B. Vucetk, and J. Yuan, Turbo codes, principles and applicofions, \nKluwer Academic Publishen, 2000. \n[I61 I. Yuan, W. Feng. and B. Vucctic, \u201cPerformance of parallel and serial \nconcatenated codes on fading channels\u201d, IEEE Tons. Conrman., vol. 50, \nno. IO, Oct. 2002, pp. 1600-1608. \n[2] \n[ 3 ]  \n[4] \n[ S I  \n[8] \n[9] \nAuthorized licensed use limited to: University of Surrey. Downloaded on April 27,2010 at 15:51:24 UTC from IEEE Xplore.  Restrictions apply. \n"}
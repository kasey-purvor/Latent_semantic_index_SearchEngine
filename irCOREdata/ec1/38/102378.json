{"doi":"10.1109\/IAS.2007.24","coreId":"102378","oai":"oai:epubs.surrey.ac.uk:1837","identifiers":["oai:epubs.surrey.ac.uk:1837","10.1109\/IAS.2007.24"],"title":"IP protection: Detecting Email based breaches of confidence","authors":["Cooke, N","Lee, G","Kondoz, A"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2007","abstract":"In this paper we discuss the ease with which email can be used to breach confidence by the propagation of corporate secrets and intelligence, and propose an intelligent filtering system for outgoing emails aimed at preventing disclosures. We report on a number of experiments undertaken with a corpus of over half a million Enron emails and the use of a variety of techniques from the field of Corpus Linguistics for reducing the number of false alarms produced by na\u00efve keyword filtering systems, and discuss the results in detail. We also give due consideration to the danger of missing messages that should have been prevented from propagation. \u00a9 2007 IEEE","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:1837<\/identifier><datestamp>\n      2017-10-31T14:03:19Z<\/datestamp><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/1837\/<\/dc:relation><dc:title>\n        IP protection: Detecting Email based breaches of confidence<\/dc:title><dc:creator>\n        Cooke, N<\/dc:creator><dc:creator>\n        Lee, G<\/dc:creator><dc:creator>\n        Kondoz, A<\/dc:creator><dc:description>\n        In this paper we discuss the ease with which email can be used to breach confidence by the propagation of corporate secrets and intelligence, and propose an intelligent filtering system for outgoing emails aimed at preventing disclosures. We report on a number of experiments undertaken with a corpus of over half a million Enron emails and the use of a variety of techniques from the field of Corpus Linguistics for reducing the number of false alarms produced by na\u00efve keyword filtering systems, and discuss the results in detail. We also give due consideration to the danger of missing messages that should have been prevented from propagation. \u00a9 2007 IEEE.<\/dc:description><dc:date>\n        2007<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/1837\/1\/fulltext.pdf<\/dc:identifier><dc:identifier>\n          Cooke, N, Lee, G and Kondoz, A  (2007) IP protection: Detecting Email based breaches of confidence   Proceedings - IAS 2007 3rd Internationl Symposium on Information Assurance and Security.  pp. 197-202.      <\/dc:identifier><dc:relation>\n        10.1109\/IAS.2007.24<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/1837\/","10.1109\/IAS.2007.24"],"year":2007,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"IP protection: Detecting Email based breaches of confidence \n \n \nNeil Cooke Lee Gillam Ahmet Kondoz \nUniversity of Surrey University of Surrey University of Surrey \nand CESG, GCHQ \nn.cooke@surrey.ac.uk \nneil.cooke@cesg.gsi.gov.uk \nGuildford, UK \nl.gillam@surrey.ac.uk \n \nGuildford, UK \na.kondoz@surrey.ac.uk \n \n \n \nAbstract \n \nIn this paper we discuss the ease with which email \ncan be used to breach confidence by the propagation of \ncorporate secrets and intelligence, and propose an \nintelligent filtering system for outgoing emails aimed \nat preventing disclosures.  We report on a number of \nexperiments undertaken with a corpus of over half a \nmillion Enron emails and the use of a variety of \ntechniques from the field of Corpus Linguistics for \nreducing the number of false alarms produced by na\u00efve \nkeyword filtering systems, and discuss the results in \ndetail. We also give due consideration to the danger of \nmissing messages that should have been prevented \nfrom propagation.  \n \nKeywords: Intellectual property; breach of confidence; \ntext analysis; outgoing email filters  \n \n1. Introduction \n \nThe Oxford English Dictionary describes \nIntellectual Property as a \u201cgeneral name for property \n(such as patents, trademarks, and copyright material) \nwhich is the product of invention or creativity, and \nwhich does not exist in a tangible, physical form\u201d.  \nLegal protection for intellectual property or the \nexpression thereof emerges in the form of copyright, \ndesigns, patents and trade marks.  These variously \nprotect literature, music, films, the visual appearance \nof a product, technical and functional aspects, and \nsigns associated to products, goods and services.  \nFurther, lesser-known, forms of IP also exist, and \nreceive protection in some form, including plant \nvarieties.  The key to this form of protection is the \nexistence of a trace of the IP in documentary form, for \nexample the copyrighted article, or the patent \napplication.   \nEarly knowledge management literature focused on \nknowledge as processes, on the ability to convert \nbetween \u201ctacit\u201d and \u201cexplicit\u201d forms of the known, and \non storing knowledge within, and extracting \nknowledge from, corporate databases [1], [2], [3].  \nPolicies, processes, and indeed software, played \nvarious supporting roles in allowing the propagation of \n\u201cknowledge\u201d around an organization.  The intellectual \nproperty, perhaps knowledge assets, of an organization \ncould, if such claims were to be believed, be captured \nand transformed to the benefit of the business.  \nKnowledge management, it appears, was aimed at \nmanaging all of what a company \u201cknows\u201d, from client \nlists to customer relationships to business processes to \ntrade secrets.  The law of confidentiality applies to \nensuring that these high-value collections remain \nknown only to the organization, and are not disclosed \nto others in ways that would cause harm to the \norganization or benefit to its competitors.  Breach of \nconfidence tends to make headlines when a disaffected \nemployee, or ex-employee, purposely discloses such \ncorporate property to the public at large or to \ncompetitor organizations. \nIn this paper we consider the potential for breaches \nof confidence to occur rapidly and on a large scale, and \nthe difficulty of preventing such disclosures of, in \nsome cases, corporate intellectual property, by \nemployees using email systems.  If employees are \neasily able to distribute the company\u2019s secrets around \nthe world in a few seconds by email, or perhaps by \nother insecure electronic means1, all other mechanisms \nused to secure this information are immediately \nrendered redundant.  Our goal is an intelligent and \nadaptive filtering system for outgoing emails that \nprevents disclosure of information deemed confidential \nor otherwise expected to have limited distribution.  \nSuch a system should also be capable of ensuring that \noutgoing emails are unlikely to contain information \nthat would otherwise be detrimental to the \norganization, and perhaps of ensuring that corporate \n                                                        \n1 USB memory sticks, as the US military discovered, provide yet \nanother information security issue: http:\/\/tinyurl.com\/22fayq  \npolicies preventing the personal use of email are being \ncorrectly adhered to.   \nWe discuss a number of initial experiments we have \nundertaken with the University of Surrey\u2019s System \nQuirk text analysis software (Section 2.1) and the \nEnron email corpus (Section 2.2), a collection of \nemails released into the public domain by the Federal \nEnergy Regulatory Commission.  We explore the use \nof a number of analytical techniques from the field of \nCorpus Linguistics for reducing the number of false \ntriggers, with due consideration given to the truly \nharmful false negatives \u2013 messages that should be \ncaught but are not.  On the basis of our analysis, we \npropose that a system capable of capturing and \npreventing harmful disclosures would best be \nintegrated with email clients to prevent propagation to \nthe email distribution system in the first place.  \nHowever, we are aware of the risk that this poses: such \na system potentially provides an immediate back-door \nto specific knowledge, or perhaps intelligence, held \nelsewhere in the organization that the email user would \nnot normally be privileged to.  Little appears to have \nbeen published, outside of corporate pamphlets and \nlegal advice2 on this subject and available techniques \nand their accuracy, and we\u2019ve found no direct \nconsideration of the problem of false positives raised \ndue to confidentiality banners.   \n \n2. Background \n \nEmail filters are normally concerned with ensuring \nthat emails are free from viruses, worms and other \nforms of system attacks, and with preventing the \nacceptance or propagation of spam and latterly of \nphishing attacks. Secure transmission of emails to \ntrusted sites using both encryption and all of the above \nfilters has also been discussed, and even patented3.  \nThe ready accessibility of spam filtering systems \nmeans that companies are implementing them at the \nsame time that spammers are using them to create \nemails that successfully pass through the filters, and \nvariations of words that include misspellings and the \nincorporation of \u201cforeign\u201d characters or numbers can \nbe used that remain generally readable, e.g. v\u00efagara.  \nKeyword-based approaches to spam filtering are \ndefeated, also, by the incorporation of text into images \n[4].  Collaborative filtering [5], where a group of users \neffectively \u201cvote out\u201d emails as spam by adding these \nemails to a central database, have proven variously \nsuccessful.  Such techniques, combined with white-\nlists and black-lists, Bayesian filtering [6], [7], [8], and \na host of other predictive and classificatory techniques, \n                                                        \n2 http:\/\/tinyurl.com\/2spz4n  \n3 USPTO 6,609,196: http:\/\/tinyurl.com\/26koxg  \nproduce varying degrees of successes in prevention of \nincoming email.  One can but marvel at the game-\nplaying approach and the continued inventiveness of \nthe spammers.   \nFor outgoing emails, we are making an assumption \nthat users are, more often than not, only involved in \nunintentional disclosure.  Arguably, therefore a \nkeyword-based approach should be effective, and there \nare many commercial offerings which provide security \nfeatures for outgoing emails, and the majority of these \nare incoming mail guards used in a different \norientation.  However, while a simple keyword \nfiltering approach may be helpful on a small scale, the \nkeyword \u201cconfidential\u201d used as a filter will result in a \nlarge number of false triggers or false positives since \nthe advent of confidentiality banners.  These banners \nalso contain other potential triggers \u2013 privileged; \nattorney; intended recipient \u2013 and a \u201cwhole-text\u201d \nkeyword-only blocking approach becomes expensive.  \nEmail responses containing a full quote of the original \nemail, including the banner or perhaps several other \nbanners, serve only to increase the frequency catch and \ncompound the difficulty.  The human efforts involved \nin releasing all such emails captured on the basis of a \nlist of keywords alone can be substantial in large \norganizations.  This is before we consider the potential \nwaste of email archive space due to the profligate use \nof these banners.  To properly assess whether these \ncaptured emails contain confidential information, those \ninvolved in allowing their release would have to have \nextensive knowledge of, or access to, all of the \nconfidential material.  The logical conclusion would be \nthat an all-knowing group of humans would have to \nknow or have access to all of the knowledge and \nintelligence within an organization, and to read, \nunderstand and allow or deny each and every piece of \nemail traffic - a somewhat expensive, and likely error-\nprone, process and likely to lead to substantial, if not \ninsurmountable, delays in communication.  Computers \nare much faster at such processing, if the processing \nengine is well formulated and tested, however \npackaging up all of the organization\u2019s knowledge and \nintelligence into a system near the edges of the \ncompany firewall may not a desirable approach. \nWe expect our eventual solution to draw together \nwork in a variety of areas, including but not limited to \ncorpus linguistics and its subtopics of sentiment \nanalysis, text segmentation, text classification, text \nmining, topic identification and analysis of register \nvariation.   Consideration will be made, also, of \nmachine learning algorithms, feature selection and \nbinary classification tasks undertaken elsewhere.  We \nare well-placed, also, for making the all-important \nconsiderations regarding systems and security. \n \n2.1. Analytical Software: System Quirk \n \nSystem Quirk is a package of software for tasks \nsuch as text analysis, ontology learning, and \nterminology and text management.  A subset of these \napplications is freely available at the University of \nSurrey\u2019s website4.  System Quirk provides software \nthat implements a variety of analytical techniques from \nthe field of corpus linguistic analysis, from simple \nfrequency counts to keyword-in-context (KWIC) to \nstatistical analyses of distance-based co-occurrence and \nto contrastive analysis with reference corpora \nproducing so-called \u201cweirdness\u201d values [9].  In this \npaper, we demonstrate results from the use of a variety \nof these techniques, validated previously across a range \nof domains from nanotechnology to automotive \nengineering to financial trading [10], [11].  We \naugment these techniques with others developed in the \ncourse of our work and more specific to the task at \nhand. \n \n2.2. Dataset: The Enron email corpus \n \nThe Enron email dataset5 consists of the email \nfolders of 158 Enron employees, providing a total of \n619,446 emails [12].  The history of Enron and its fall \nfrom 7th largest company in the US, a highly regulated \nfinancial environment, to and \u201coff balance sheet\u201d \nlosses and bankruptcy in 2001 has been well \ndocumented.  The Enron story demonstrated, at least, \nthat having a code of ethics was one thing, but abiding \nby it was clearly another.  As part of the investigations \ninto Enron, the Federal Energy Regulatory \nCommission released a collection of 1.5m emails into \nthe public domain, reportedly so that the public would \nbe able to see the evidence forming part of the \ninvestigation. The discrepancy in number of emails is \ndown to certain \u201cdata cleansing\u201d activities undertaken \nelsewhere, including the deletion of messages \"as part \nof a redaction effort due to requests from affected \nemployees\".  The remaining dataset still demonstrates \na large range of the social interactions undertaken \nusing email, including as it does messages within the \norganization, with other organizations, with friends and \nfamily, and sometimes containing material that would \nbe unsuited for lower age groups.  It is worth \nremembering, also, that a number of these employees \nwere not complicit in the fraudulent activities of Enron. \n \n                                                        \n4 Available at: http:\/\/www.computing.surrey.ac.uk\/SystemQ\/ \n5 Available at: http:\/\/www.cs.cmu.edu\/~enron\/  \n3. Approach \n \nWith any approach to (artificially) intelligent \nprocessing, the most important factor is the choice of \nheuristic: it should represent value for information \ngain, be easy to implement and make effective use of \nthe information elements.  The intention of our present \nefforts is to construct and implement an algorithm that \nidentifies and discounts confidentiality banners.  Our \ninitial efforts, therefore, concern determining whether a \npattern of such banners can be learnt.   Our approach \ninvolves: \n1. Constructing a test dataset by \u201ceyeballing\u201d a small \nnumber of confidentiality banners and \nidentifications of confidentiality in the Enron \ncorpus  \n2. Identifying an initial set of similarities that enable \na skilled human to make a binary decision.  \n3. Using the System Quirk software to determine \nwhether the similarities have any statistical \nsignificance, using word frequency, word \nweirdness and word frequency\/proximity \nstatistical analysis on a training set \n4. Evaluating the approach against the full Enron \ncorpus. \n5. Classifying emails as containing confidentiality \nindicators in (a) unseen banners; (b) body text; (c) \nboth.  \n6. Constructing a confidentiality banner database for \nfurther evaluation. \n7. Assessing the email corpus for further features, \ne.g. personal vs. business emails as may be \ndiscernible by register variation. \nFor the purpose of this paper, we are concerned \nwith steps 1-5. The \u201cobvious\u201d human choices for \nkeywords and similarities (steps 1-2) are not \nnecessarily the best, and proper statistical analysis can \nreveal easier and better patterns to exploit, a point well \nmade elsewhere [13].   \n \n4. Experiments \n \nA training set containing 50 unique banners and 46 \nbody paragraphs (each with at least one instance of the \nword \u201cconfidential\u201d) was created manually by \n\u201ceyeballing\u201d a number of emails.  Similarities in the \nuse of words such as \u201cprivileged\u201d at a short distance \nfrom the keyword \u201cconfidential\u201d were initially noted.  \nWe performed word frequency analysis, with and \nwithout stop words, and calculated values for \n\u201cweirdness\u201d using the British National Corpus (BNC) \nto identify and contrast prevalent keywords in the \n\u201cbanner\u201d and \u201cbody\u201d test sets.  Table 1 shows the top \n10 keywords discovered for each: there are some \nindications of difference, given the spreads of \nfrequency values in these top 10s, and note that \n\u201cprivileged\u201d is shared between these sets, albeit at a \ngreater frequency in the banners. \n \nTable 1: Top 10 keywords discovered in body \nand in banner paragraphs   \nKeywords: Body Keywords: Banners \nFreq Weirdness Word Freq Weirdness Word \n64 2763 confidential 68 969 mail \n22 inf! enron 66 288 intended \n9 456 transportation 51 1925 confidential \n8 1022 confidentiality 46 1494 recipient \n8 258 agreements 32 inf! email \n8 228 privileged 32 798 privileged \n7 inf! ferc 30 1581 sender \n7 7456 ena 29 2700 prohibited \n7 677 disclosure 28 245 error \n7 20 non 27 1178 delete \n \nNext we calculated frequencies of words within a 5 \nword window of the keyword \u201cconfidential\u201d across the \nwhole Enron corpus (209,204,013 tokens, according to \nSystem Quirk computations) and compared this to the \nextracted banners.  Consider, for example, occurrences \nof \u201cprivileged\u201d within this 5 word window \u2013 in the \nEnron corpus, \u201cconfidential\u201d occurs 35621 times.  The \nword \u201cprivileged\u201d occurs 19390 times within 5 words \neither side of this.  Of these 19390 times, it occurs \n6599 times at one word separated from confidential (at \nposition 2, e.g. \u201cconfidential X privileged\u201d).  A further \n4780 occurrences are opposite to this (\u201cprivileged X \nconfidential\u201d).  See Table 2.  Further details about the \nstatistical significance of these values can be found in \n[14] \n \nTable 2: Frequencies of the word \u201cprivileged\u201d \nwithin a window of 5 words of \u201cconfidential\u201d \nPosition -5 -4 -3 -2 -1 1 2 3 4 5\nFrequency 68 13 1375 4780 1647 71 6599 2593 1398 846\n \nThe extent to which the 35621 instances of \n\u201cconfidential\u201d denote a banner can be assessed by \ncontrasting the totals of collocating frequencies with \nthe frequency analysis of the eyeballed banners (Table \n3).  The top 22 words collocating with \u201cconfidential\u201d \nare indexed by the first column.  These indexes are \nused in brackets after the identical words found in the \nlists generated by frequency and weirdness \ncalculations.  Differences in ranking due to frequency \nand weirdness calculations can be seen by alphabetic \nindexes.  According to these results, a relatively large \nproportion of the instances of \u201cconfidential\u201d appear to \nbe indicative of banners, though the true extent remains \nto be assessed.   \nTo confirm that the Enron corpus was statistically \nsimilar across email account names and that the Banner \ntraining selection was a representative sample, we \nperformed a proximity (+\/-5 words to confidential) \nfrequency analysis across 60 million tokens of the raw \ncorpus and then compared the top 22 words of the \nresults to the top 22 words from the banner training \nsample for frequency and weirdness.  The impact of \nstemming and lexical variation remains to be assessed. \n \nTable 3: Banner\/raw corpus sample \nProximity raw Corpus  \nfrequency \nBanner  \nBy Frequency \nBanner  \nBy weirdness \n1 privileged 8122 information (3) 68 email (10) inf!\n2 contain 4902 mail (a) 68 dissemination 2793\n3 information 4722 intended (8) 66 prohibited (c) 2700\n4 material 2818 message (11) 61 attachments (22) 2123\n5 affiliate 2318 recipient (19) 46 sender (b) 1581\n6 relevant 2305 please 45 disclosure (i) 1523\n7 legally 1837 email (10) 32 recipient (19) 1494\n8 intended 1594 privileged (1) 32 notify (f) 1077\n9 proprietary 1340 sender (b) 30 delete (e) 1178\n10 email 1185 received 30 mail (a) 969\n11 message 1078 prohibited (c) 29 copying (g) 945\n12 exempt 1075 error (d) 28 privileged (1) 798\n13 otherwise 952 delete (e) 27 addressee 340\n14 subject 947 immediately 27 intended (8) 288\n15 enron.com 750 notify (f) 27 error (d) 245\n16 contains 726 copying (g) 22 solely (18) 229\n17 communication 684 other 21 strictly 197\n18 solely 622 distribution 20 contained 98\n19 recipient 612 contain (2) 19 contain (2) 95\n20 protected 606 attachments (22) 19 copy 77\n21 e-mail 592 communication (17) 19 contains (16) 73\n22 attachments 589 disclosure (i) 18 named 68\n \nIn table 3 we noted that six words (in bold) were \ncommon to all columns and felt that these 6 words \nwould be a logical choice for our first keywords.  We \ndecided, also, that instances collocating within, \napproximately, one sentence of our target key word \n\u201cconfidential\u201d could be of interest, but would assign \nless importance to those at a greater distance.  Since 15 \nto 20 words is a good length for a sentence6, we \nexpanded our window of consideration to 20, without \nconsideration for sentence boundaries, and weighted \neach word inversely proportional to distance.  We \nconsidered only emails in the Enron corpus that \ncontained \u201dconfidential\u201d.  A subset of this collection, \nbased on the first 25 email account names in \nalphabetical order, was treated.  This collection was \nmanually evaluated to determine whether the instances \nof \u201cconfidential\u201d were in banners or body.  To ensure \nthat these could be treated separately, and in lieu of \nexternal annotations, each banner instance was \nreplaced with \u201czzzzzzzzzzial\u201d (3223 in total) and each \nbody instance with \u201cxxxxxxxxxxxial\u201d (2663 in total), \neffectively tagging each. \nWe computed individual weights for all \n\u201cconfidential\u201d key word instances in both banner and \nbody. The resulting graph, figure (1) shows the error % \n(1-precision) against trigger weight for body and \nbanner.  At a trigger level greater than 0.5, 46 from \n2663 instances (1.7%) false negatives would be \ngenerated, and 2737 false positives (84.9%) would now \nbe correctly filtered. \n                                                        \n6 http:\/\/www.plainenglish.co.uk\/medicalguide.pdf  \n .00%\n5.00%\n10.00%\n15.00%\n20.00%\n25.00%\n30.00%\n35.00%\n40.00%\n45.00%\n0.2 0.4 0.6 0.8 1\ntrigger weight\nbanner\nbody\n \nFigure 1 Error % against trigger weight \n \nThese initial results were encouraging, however we \nneeded a further assessment of the three key \nassumptions: (i) best distance \u2013 whether a 20 word \nwindow was a good choice; (ii) impact of weighting on \nprecision; (iii) lexical selection \u2013 quality of the chosen \nword list. \n(i) We used max distance at values of 3, 5, 10, & 20 \nand plotted the effects of max distance on precision see \nfigure (2). For body instances, no significant change in \nprecision resulted; for banners, reducing the max \ndistance caused a reduction in precision. This indicated \nthat the instance word list data in the surrounding area \nwas relatively rare in the body case.  \n(ii) We removed the discount for distance, and \nevaluated results at a maximum distance of 10 & 20.  \nResults of the effects of max distance on precision can \nbe seen in figure (3).  This showed that the attenuation \nwas actually having a detrimental effect on body \nprecision, and a beneficial effect on banner precision. \nHowever with such a small word instance list the \ngranularity may be considered crude.  \n \n.00%\n10.00%\n20.00%\n30.00%\n40.00%\n50.00%\n60.00%\n0.4 0.5 0.6 0.7 0.8 0.9 1 1.1 1.2\ntrigger weight\nbanner max dist 20\nBanner max dist 10\nBanner max dist 5\nBanner max dist 3\nBody max dist 20\nBody max dist 10\nBody max dist 5\nBody max dist 3\n \nFigure 2 Error % against maximum distance \n \n.00%\n20.00%\n40.00%\n60.00%\n80.00%\n100.00%\n120.00%\n1 2 3 4\ntrigger weight\nBanner max dist 20\nBannermax dist 10\nBody max dist 20\nBodymax dist 10\n \nFigure 3 Error % against maximum distance \n \n(iii) We ran the experiment using the three different \nkeyword sets of table 4 - see figure (4).  \n \n.00%\n10.00%\n20.00%\n30.00%\n40.00%\n50.00%\n60.00%\n1 2 3 4\ntrigger weight\nbanner (all freq)\nbanner (banner weird)  \nbanner (banner freq) \nbody     (all freq)  \nbody  (banner weird) \nbody    (banner freq)\n \nFigure 4 Error % against different word sets \n \nSurprisingly, the Proximity raw Corpus frequency \nset (all freq) out performed (banner freq), showing that \nthere was a significant pattern coming from the \nbanners in the raw Enron corpus. The most frequent \nbanner set (banner freq) did reasonably well, but not as \nwell as expected.  The most significant improvement \ncame from the weird set (Banner weird), with \nexceedingly good results.  With a trigger level set to \ngreater than 2, only 10 body confidential instances \n(0.37%) would be mis-categorized and not presented to \na human for inspection and 2752 banners (85.4%) \nwould be correctly filtered. For others to give good \nresults for Body categorization required a trigger \nweight of 4, resulting in significantly worse banner \ndiscrimination characteristics.  Following this result we \nreexamined the statistics from the training corpus and \nproduced a table in banner weirdness order against \nbody frequency (Table 4). This demonstrated that the \nweirdest words were very, or exceedingly, rare in the \nbody text. So the best way of choosing instance words \nfor the banner filter was to use some function of banner \nweirdness and body rarity, for example techniques \nfrom [9], [10], [11] in a different orientation. \n \nTable 4: Body Freq\/Banner Weirdness \nBody Word Banner Weirdness \n1 email 32 inf! \n0 dissemination 14 2793 \n0 prohibited 29 2700 \n0 attachments 19 2123 \n0 sender 30 1581 \n7 disclosure 18 1523 \n0 recipient 46 1494 \n0 delete 27 1178 \n0 notify 27 1077 \n5 mail 68 969 \n0 copying 22 945 \n8 privileged 32 798 \n0 addressee 15 340 \n1 intended 66 288 \n0 error 28 245 \n0 solely 12 229 \n0 strictly 17 197 \n1 contained 15 98 \n0 contain 19 95 \n2 copy 11 77 \n0 contains 11 73 \n0 named 13 68 \n \n5. Related Work \n \nWork on the Enron corpus elsewhere has \ninvestigated automatic classification of emails as \n\u201cBusiness\u201d or \u201cPersonal\u201d based on inter-annotator \nagreement [15].   The authors suggest that around 17% \nof a sample of around 12,500 emails were identified as \npersonal correspondence, based on 94% agreement \nbetween 4 annotators, and a probabalistic classifier \nreportedly achieves good performance against a subset \nof these documents.  This work is directly related to \nStep 7 of our approach, and it will be interesting to \nmeasure the extent to which banners might act as \nuseful classifiers for business emails. \n \n6. Conclusions \n \nIn this paper we discussed the ease with which \nemail can be used for breaches of confidence and the \npotential for harm to organizations as a result.  We \nidentified a lack of literature regarding the problem of \ncorrectly identifying such potential breaches.  We have \nproposed an intelligent filtering system for outgoing \nemails aimed at preventing such disclosures, and \ndemonstrated through a number of relatively \nstraightforward, yet encouragingly effective \nexperiments how the use of a few techniques from the \nfield of Corpus Linguistics could be used to reduce the \nnumber of false alarms \u2013 false positives - produced by \nkeyword filtering and considered the proportion of \nharmful false negatives.  These experiments were \nundertaken on the publicly accessible Enron email \ncorpus.  These early results are highly promising, and \nwork aimed at further improvements over these results \nis already in progress and will be reported when fully \nverified.   \n \n7. References \n \n[1] Leonard, D., Wellsprings of Knowledge, Harvard \nBusiness School Press, Boston MA, 1998. \n \n[2] Davenport, T.H., Prusak, L., Working Knowledge, \nHarvard Business School Press, Boston MA, 1998. \n \n[3] Nonaka, I., H. Takeuchi The Knowledge Creating \nCompany, Oxford University Press, New York, 1995. \n \n[4] G. Fumera, I. Pillai, and F. Roli, \u201cSpam Filtering Based \nOn The Analysis Of Text Information Embedded Into \nImages\u201d, Machine Learning Research 6: 2699-2720, 2006 \n \n[5] E. Damiani, S.D.C. di Vimercati, S. Paraboschi and P. \nSamarati, \u201cAn Open Digest-based Technique for Spam \nDetection\u201d.  Proc. of ISCA PDCS 2004: 559-564, 2004. \n \n[6] J. Dong, H. Cao, P. Liu, and L. Ren, \u201cBayesian Chinese \nSpam Filter Based on Crossed N-gram\u201d, Proc. of ISDA 2006 \nVolume 3, pp:103 \u2013 108, October 2006. \n \n[7] I. Androutsopoulos, I., Koutsias, J., Chandrinos, K., \nPaliouras, G., and Spyropoulos, C., An evaluation of naive \nBayesian anti-spam filtering, Proc. of ECML 2000, \nBarcelona, Spain, 9\u201417, 2000. \n \n[8] K-M. Schneider, A comparison of event models for Naive \nBayes anti-spam e-mail filtering, Proc. of ACL 2003, \nBudapest, Hungary, April 12-17, 2003.  \n \n[9] L. Gillam, Systems of concepts and their extraction from \ntext, Unpublished PhD thesis, University of Surrey, 2004. \n \n[10] L. Gillam, M. Tariq, and K. Ahmad, Terminology and \nthe construction of ontology, Application-Driven \nTerminology Engineering, John Benjamins, 2007 \n \n[11] L. Gillam and K. Ahmad, Pattern mining across domain-\nspecific text collections, LNAI 3587, 570-579, 2005 \n \n[12] B. Klimt and Y. Yang, The Enron Corpus: A New \nDataset for Email Classification Research, Language \nTechnologies Institute, Carnegie Mellon University, 2004  \n \n[13] B. Pang, L. Lee, V. Vaithyanthan, Thumbs up? \nSentiment Classification using Machine Learning \nTechniques, Proc. of EMNLP 2002. \n \n[14] F. Smadja, Retrieving collocations from text: Xtract, \nComputational Linguistics 19(1), Oxford University Press, \n2003. \n \n[15] S. Jabbari, B. Allison, D. Guthrie, L. Guthrie, Towards \nthe Orwellian Nightmare: Separation of Business and \nPersonal Emails. Proc. of ACL 2006.  \n"}
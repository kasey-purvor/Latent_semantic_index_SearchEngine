{"doi":"10.1007\/s11618-010-0155-2","coreId":"66597","oai":"oai:dro.dur.ac.uk.OAI2:8023","identifiers":["oai:dro.dur.ac.uk.OAI2:8023","10.1007\/s11618-010-0155-2"],"title":"Evidence? The impact of large-scale reform in England.","authors":["Tymms,  P."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-01-01","abstract":"England's school-based education system has been reformed massively over the last two decades. The reforms have included the introduction of a National Curriculum, national testing, a heavy inspection regime and hundreds of lesser reforms. The reforms have included the introduction of a National Curriculum, national testing, inspection regime and a heavy dog hundreds of lesser reforms. What has the impact of those reforms been? What has the impact of those reforms been? This paper draws on extensive research and concludes that one of the main aims of the reforms, to impact on basic skills in primary schools, has largely not been achieved although there has been some rise in maths test scores. This paper draws on extensive research and concludes that one of the main aims of the reforms, impact on basic skills in primary schools, has been to not Largely Achieved although there has been some rise in maths test scores. On the other hand the numbers of students gaining certificates at the age of 16 has more than doubled and more students are studying for pre-university courses and staying in education to study for a degree. On the other hand the numbers of students gaining certificates at the age of 16 has more than doubled and more students are studying for pre-university courses and staying in education to study for a degree. The rise in the numbers gaining qualifications at 16 seems to have been achieved whilst maintaining the standards of the exams at least up to 2003 although the same cannot be said of the pre-university qualifications. The rise in the numbers gaining qualifications at 16 seems to have been Achieved whilst Maintaining the standards of the exams at least up to 2003 although the same can not be said of the pre-university qualifications. \\ud\nThe paper concludes that there is a need to take much more notice of the evidence base for reform to become a learning society and to accept that we need to change policies in the light of evidence. The paper concludes that there is a need to take much more notice of the evidence base for reform to become a learning society and to accept that we need to change policies in the light of evidence","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/66597.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/8023\/1\/8023.pdf","pdfHashValue":"71cf04d25d8a801da782224c63021046e63bd488","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:8023<\/identifier><datestamp>\n      2016-07-06T13:09:08Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Evidence? The impact of large-scale reform in England.<\/dc:title><dc:creator>\n        Tymms,  P.<\/dc:creator><dc:description>\n        England's school-based education system has been reformed massively over the last two decades. The reforms have included the introduction of a National Curriculum, national testing, a heavy inspection regime and hundreds of lesser reforms. The reforms have included the introduction of a National Curriculum, national testing, inspection regime and a heavy dog hundreds of lesser reforms. What has the impact of those reforms been? What has the impact of those reforms been? This paper draws on extensive research and concludes that one of the main aims of the reforms, to impact on basic skills in primary schools, has largely not been achieved although there has been some rise in maths test scores. This paper draws on extensive research and concludes that one of the main aims of the reforms, impact on basic skills in primary schools, has been to not Largely Achieved although there has been some rise in maths test scores. On the other hand the numbers of students gaining certificates at the age of 16 has more than doubled and more students are studying for pre-university courses and staying in education to study for a degree. On the other hand the numbers of students gaining certificates at the age of 16 has more than doubled and more students are studying for pre-university courses and staying in education to study for a degree. The rise in the numbers gaining qualifications at 16 seems to have been achieved whilst maintaining the standards of the exams at least up to 2003 although the same cannot be said of the pre-university qualifications. The rise in the numbers gaining qualifications at 16 seems to have been Achieved whilst Maintaining the standards of the exams at least up to 2003 although the same can not be said of the pre-university qualifications. \\ud\nThe paper concludes that there is a need to take much more notice of the evidence base for reform to become a learning society and to accept that we need to change policies in the light of evidence. The paper concludes that there is a need to take much more notice of the evidence base for reform to become a learning society and to accept that we need to change policies in the light of evidence. <\/dc:description><dc:subject>\n        Reform<\/dc:subject><dc:subject>\n         England<\/dc:subject><dc:subject>\n         Standards<\/dc:subject><dc:subject>\n         Evidence<\/dc:subject><dc:subject>\n         Tests.<\/dc:subject><dc:publisher>\n        Springer<\/dc:publisher><dc:source>\n        Zeitschrift f\u00fcr Erziehungswissenschaft, 2011, Vol.13(S1), pp.105-115 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2011-01-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:8023<\/dc:identifier><dc:identifier>\n        issn:1434-663X<\/dc:identifier><dc:identifier>\n        issn: 1862-5215<\/dc:identifier><dc:identifier>\n        doi:10.1007\/s11618-010-0155-2<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/8023\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1007\/s11618-010-0155-2<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/8023\/1\/8023.pdf<\/dc:identifier><dc:rights>\n        The original publication is available at www.springerlink.com\\ud\n<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn: 1862-5215","issn:1434-663X"," 1862-5215","1434-663x"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2011,"topics":["Reform","England","Standards","Evidence","Tests."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n24 February 2011\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nTymms, P. (2011) \u2019Evidence ? the impact of large-scale reform in England.\u2019, Zeitschrift fr\nErziehungswissenschaft., 13 . pp. 105-115.\nFurther information on publisher\u2019s website:\nhttp:\/\/www.zfe-online.de\/e-index.htm\nPublisher\u2019s copyright statement:\nThe original publication is available at www.springerlink.com\nAdditional information:\nSpecial edition: Transforming Education = Umbau des Bildungswesens.\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\nTymms, P. (2011). \"The Impact of Large-Scale Reform in England.\" Zeitschrift \nfur Erziehungswissenschaft 13 105-116 \n  \n  \n  \n \nEvidence? The Impact of Large-Scale Reform in \nEngland \n \nPeter Tymms \n \n \nAbstract \n \nEngland\u201fs school based education system has been massively reformed over the last \ntwo decades. The reforms have included the introduction of a National Curriculum, \nnational testing, a heavy inspection regime and hundreds of lesser reforms.  \n \nWhat has the impact of those reforms been? This paper draws on extensive research \nand concludes that one of the main aims of the reforms, to impact on basic skills in \nprimary schools, has largely not be achieved although there has been some rise in \nmaths test scores. On the other hand the numbers of students gaining certificates at the \nage of 16 has more than doubled and more students are studying for pre-university \ncourses and staying in education to study for a degree. The rise in the numbers \ngaining qualifications at 16 seems to have been achieved whilst maintaining the \nstandards of the exams at least up to 2003 although the same cannot be said of the pre-\nuniversity qualifications. \n \nThe paper concludes that there is a need to take much more notice of the evidence \nbase for reform, to become a learning society and to accept that we need to change \npolicies in the light of evidence. \n \n \nKey words:  Reform, England, Standards, Evidence, Tests \n \nZusammenfassung: \nEvidenzen? Die Auswirkungen gro\u00df angelegter Reform in England \nDas englische Schulsystem ist in den vergangenen zwei Jahrzehnten m\u00e4chtig \nreformiert worden. Die Reformen beinhalteten die Einf\u00fchrung eines nationalen \nCurriculums, nationale Testverfahren, ein starkes Inspektionssystem und hunderte \nkleinerer Reformen. Was waren die Auswirkungen dieses Reformen? Mein Beitrag \nst\u00fctzt sich auf eingehende Untersuchungen und kommt zu dem Schluss, dass eines der \nHauptziele der Reformen - die Erh\u00f6hung der Leistungen in den Grundf\u00e4higkeiten im \nPrimarschulsystem - weitgehend unerreicht blieb, auch wenn es einige Steigerungen \nin den Mathematikleistungen gab. Auf der anderen Seite hat sich die Zahl der \nSch\u00fclerinnen und Sch\u00fcler, die mit 16 Jahren ein Abschlusszertifikat erreichen, mehr \nals verdoppelt, und die Zahl derjenigen, die universit\u00e4tsvorbereitende Kurse \nwahrnehmen und einen Hochschulabschluss erreichen m\u00f6chten, hat sich ebenfalls \nerh\u00f6ht. Dies scheint (zumindest bis 2003) erreicht worden zu sein, ohne dass \nStandards gelockert wurden; allerdings gilt das nicht f\u00fcr die \nHochschulzulassungsqualifikationen. \nMein Beitrag kommt zu dem Schluss, dass den Evidenzen, die Reformen zugrunde \ngelegt werden, mehr Beachtung geschenkt werden muss, um eine lernende \nGesellschaft zu werden - und dass es im Lichte der Evidenzen zu einer \u00c4nderungen \nder Politik kommen muss. \nSchl\u00fcsselw\u00f6rter: Reform, England, Standards, Evidenz, Tests \n \nIntroduction \nThis paper outlines the major reforms that have defined the major educational changes \nwithin England since the end of the 1980s until the present time. It summarises their \nimpact on attainment in state schools during that time, and some of the unintended \nconsequences of the reforms. It also notes the cost of the policies that have been put \ninto place and the recent changes that have been made to the initial reforms in the \nlight of the way things have evolved. The paper finishes up by drawing some lessons \nfrom what has happened in England, not just in terms of the reforms themselves and \ntheir impact?, but also in terms of the methodology that is used to evaluate the those \nreforms, and also the basis of the reforms themselves. \n \nJim Callaghan, the British Prime Minister 1976-1979, became alarmed when he heard \nthat his grandchild was apparently not being taught to read in primary school. He \nheard this from his daughter and it generated sufficient concern in him to alert the \nnation to what were perceived to be problems in the educational system in what is \nnow known as the Ruskin College Speech (Callaghan, 1976). As intended this \nprecipitated an extensive debate in England and as a result the Education Reform Act \nwas passed in 1988 which come into force in September 1989.. This put a National \nCurriculum in place for the first time in England and associated with that was a \nNational Testing Programme for 7, 11, and 14 year olds and the end of what were \nknow as Key Stages, as well as a very high-stakes inspection system known as Ofsted \n(the Office for Standards in Education). It not only required regular inspections but \nthe inspections themselves could not be challenged in law and their reports would be \navailable through public dissemination of the findings. The test results would also be \npublicly available and in due course appeared in the newspapers in the form of league \ntables. These were designed as high-stakes reforms and were meant to hold schools to \naccount for what they were doing after defining what they should be doing.  \n \nTests and exams \nThe statutory National Testing took some time to become established according to the \nSecretary of State for Education at the time they were officially bedded down by 1995 \nand started to come on-stream providing national test data year on year. They added to \nexisting optional assessments for children when they left school, the General \nCertificate of Secondary Education (GCSE), which had itself taken over in 1986 from \ntwo previous parallel testing systems known as GCE O-Levels (General Certificate of \nEducation \u2013 Ordinary Level), and the CSE (Certificate of Secondary Education). They \ncatered for the more and less able pupils respectively. At the time of the Education \nReform Act (1988) the GCSE was taken by about a quarter of pupils in England. Two \nyears after the GCSE students could take the pre-university assessment known as the \nA-Levels, the Advanced Level system, which had been in place since 1951. In 1987 \nan additional intermediate exam known as the AS-Level (Advanced Supplementary) \nwas introduced which was designed to represent a qualification between GCSE and \nA-Level. There was also a patchwork of assessments of children when they started \nschool using what is known as Baseline Assessment. In England typically children \nstart school in September at the age of 4 although by law they only have to start after \ntheir fifth birthday provided they are not being educated at home.  \n \nContinued reform \nThe reforms were initiated by the leader of the Labour Party, Jim Callaghan,, but \nwhen the Conservative Party gained power in 1979 they continued the reforms with \nzeal and it was the Tories who introduced the NC quite quickly after they came to \npower. Then when Labour came to office in 1997 they also extended the move for \nreforms using the mantra of Education, Education, Education. Indeed in their first few \nyears in office they put in more than 600 initiatives to do with basic skills alone in the \nprimary years (ref). They introduced the National Numeracy Strategy and the \nNational Literacy Strategy in 1998 which were later to become the National Strategy. \nThey brought in target setting, homework clubs, and a whole range of initiatives \ndesigned to raise attainment. The focus was on basic skills in primary schools.  \n \nThe reforms continue and new initiatives and major official reviews continue up to the \npoint of writing this paper. \nStandards in primary schools \nIn Figure 1 the results of the national tests for the end of primary school (age 11 years \nat the end of Key Stage (KS) 2) are shown. It gives the percentage of children \nattaining what is known as the \u201cexpected\u201d1 level, Level 4, from 1995 onwards. This \nshows a dramatic rise between 1995 and 2000 and then a flattening off. At first sight \nthis appears to be major evidence for the positive impact of the reforms, although, as \nany trained educational researcher knows, it is impossible to ascribe cause with any \ncertainty from such time series data since so many different things were happening \nsimultaneously. But it was certainly used as justification for the reforms that had been \nput in place. Indeed one high profile government adviser and architect of some of the \nreforms, Michael Barber claimed that \u201cLarge scale reform is not only possible but can \nbe achieved quickly\u201d. (Barber 2000, see also Cheek, Fitz-Gibbon and Tymms 2000). \n \nFigure 1 about here \n \nOn closer examination the test results seem a little odd. Why is it that they rise \ndramatically up to 2000 and are then more or less flat thereafter? Why is it that the \nmaths results hug the English results so tightly with a slight discrepancy in 1998 when \nan oral arithmetic test was introduced? Surely the reforms would be more effective in \neither English or mathematics. The Centre for Evaluation and Monitoring (CEM, \nwww.cemcentre.org; Tymms and Coe 2003), the largest educational research group in \na UK university, had been collecting test results on reading and mathematics over \nseveral years using the same test every year, with the same schools and they had not \nnoticed any reading test rise at all (Tymms and Fitz-Gibbon 2001). Informal \nconversations with Local Authorities that had used the same reading test over the \nyears similarly had not seen a rise but the Authority officials were wary of saying so \nin public. Clearly there was some suspicion that things were not all that they seemed \nand it was possible to investigate further (Tymms 2004). Twelve separate studies were \nidentified including one by the government\u201fs own exam body, the Qualifications and \nCurriculum Authority (QCA), which resulted in the Massey Report (Massey et al \n2003). This is distinctive because it used tests from and early date (1995 or 1996) and \nlater date (1999, 2000 or 2001) with randomly equivalent samples of pupils outside \n                                                 \n1\n It was initially thought that the \u201eaverage\u201f pupil would attain L4 but this was later changed to be \n\u201eexpected\u201f. \nEngland (Northern Ireland) to check that both tests were equivalent (a similar \nproportion of pupils reaching the required level would suggest equivalence). Massey \net al found that in the cases of both English and maths the tests were not equivalent; \nthe results for English were highly statistically significant, suggesting that the later \ntests provided an advantage over the earlier tests. Regarding KS2 English Massey et \nal write: \n\u2026 these comparisons would lead us to conclude that the standards set in \nthe 1996 and 1999 versions of the KS2 English tests were different \n(Massey et al 2003: 46) \n \nThese results and those from the other independent longitudinal studies using \nindependent instruments were brought together in Tymms (2004). The best estimate is \nthat the attainment levels in English rose very modestly from about 48% to about 57% \ndeserving a Level 4 or above between 1995 and 2000; in mathematics the rise was \nrather greater (44% to 61%). The English rise amounts to an Effect Size of about 0.25 \nand the maths rise to about 0.55. After 2000 the English results have risen by a tiny \namount (ES<0.1) and the mathematics by a small amount (ES~0.2). \n \nWe know that whenever tests are introduced on a national basis we see standards rise \n(see Koretz 2009). So it is of little surprise to educational researchers with an \ninternational perspective to see a graph with the general pattern of Figure 1. As is \ncommonly the case, politicians and advisers associated with the reform took a long \ntime to recognise that the apparent rises were illusory and some still do not accept the \nfinding despite independent confirmation that the statutory test results exaggerated the \nrise (Statistics Commission 2005). What was seen in the English results was the usual \nrise with the usual causes but this was augmented by a mistake in the standard setting \nprocedure and it is worth just noting what that error was. QCA, despite changing its \nname, has had the responsibility for the creating of new tests and to ensure that the \nstandards remain constant year on year over the period in question. This involves \nsetting cut-scores corresponding to the various levels against a political background of \nenormous pressure to see rises. Up to 2000 when the cut-scores were being fixed at \ncrucial yearly meetings it seems that decisions tended to be very slightly biased \ntowards a lower cut-score than was optimal. This amounted to an apparent slight rise \nin standards. For this to happen one year is quite understandable but the serious error \nwas that each year the intention was only to equate to the results from the last year. \nNo attempt was made to check that the standards were the same as two, three and \nmore years ago. Even though there was an anchor test it was only used to check to the \nprevious year. The consequence was that the small understandable creep in one year \nwas built on every year and this amounted to a serious misrepresentation by 2000. \nThat error was corrected in 2000 and other safeguards were put in place and as a \nresult the standard-setting procedure has been effective since then.  \n \nOn a broader note more recent work has tried to comment on standards of attainment \nin primary schools as far back as data will allow (Tymms and Merrell 2007;  Tymms, \nBolden and Merrell 2008). These studies indicate that reading levels have remained \nconstant in England since a little after the Second World War. Little is known about \nwriting levels over the same period but in mathematics the largest changes have \nhappened since the recent reforms. In science the main debate concerns the primary \ncurriculum so far as it is possible to ascertain standards have remained steady \nalthough there is a single worrying paper which suggests that the Piagetian levels of \nchildren starting secondary school has fallen (Shayer Ginsburg and Coe 2008) . The \nattitudes of pupils to subjects and to school appear to have remained pretty static over \nthe last two decades. \nStandards in secondary schools \nTurning our attention now to the results at the end of secondary school, Figure 2 \nshows the proportion of children gaining 5 passes at levels A*-C\n2\n at GCSE (Coe and \nTymms 2008). A secondary school in England is generally covers the age range 11-16 \nor 11-18 but in some the students start at 12 or 13. A common feature is that they all \ninclude the age at which the GCSE may be taken. It is clear there have been dramatic \nchanges. Around a quarter of students were attaining the 5 passes which are seen as a \nkey attainment level in 1980. Now more than half attain those passes. Independent \ninvestigations using CEM data by Robert Coe (Coe et al 2008, Coe and Tymms 2008) \nusing the same developed ability measures shows that that standards used to award \nGCSE grades has remained fairly constant up until around 2003 and that children of \nthe same ability are generally being awarded the same grades although there is some \nvariation from subject to subject over at least the last twelve years. This suggests that \nthe proportion of students being accredited at the end of compulsory education has \nmore than doubled over approximately the last 20 years whilst examination standards \nhave been maintained. An abrupt rise started in about 1987 just predating the \nEducation Reform Act and the rising curve does not show any noticeable kicks which \nmight correspond to policy or political change. More schools were entering more \npupils for the end of statutory education examinations and the proportion accredited \nfor their work is rising.  \n \nFigure 2 about here \n \nThe rising number of 16 year olds with GCSE passes has had a knock-on effect on A- \nLevel.  Figure 3 shows the measure of developed ability of those students starting \nstudy in several A-Level subjects.  The test was based on the International Test of \nDeveloped Abilities (Ottobre 1987) made available to CEM from Education Testing \nServices. The scores generally start at around 60 points and fall to around 55 then \nflattening, rising a little from 2001 onwards. Mathematics follows a similar pattern \nbut the scores are a little higher than for the other subjects. It is not surprising to see \nthis kind of pattern because as a higher proportion of the population go on to do A-\nLevels we would expect that a less and less able group appear in successive cohorts \non average. It is gratifying and unexpected to see the slight rise towards the end.  \n \nFigure 3 about here \n \nNext the A level grades of students in different subjects with the same developed \nability measures when they start are shown in Figure 4. In looking at the chart one \nneeds to recall that the nature of A-levels has changed over the years. The syllabuses \nhave changes, a half-way stage (AS) has been introduced, the nature of the exams has \nchanged and, perhaps of greatest importance, the courses have been modularised. \nNevertheless the chart shows a dramatic rise in the grades given to pupils of \napparently similar ability. The most noticeable effect is seen in mathematics where in \nabout 1988 it was clear that an E grade would be expected whereas now it is a B\/C. \n                                                 \n2\n The highest grade is and A* and this is followed by A , B, C etc \nThe changing severity of grading of the subjects has resulted in a very high proportion \nof children getting A grades at A level A2 whereas before it was a small proportion \nabout 10%. This has led to a crisis in the admission of very able students to \nuniversities where many present with straight A\u201fs and it is impossible for admissions \ntutors to differentiate at the top level. As a result we have a number of different \nindependent tests making their mark on the English educational scene at the pre-\nuniversity level. \n \nFigure 4 about here \nThe cost and impact of reforms  \nThe reforms were enormously expensive and, as noted earlier, very numerous. Four of \nthe larger ones are briefly considered below.  \n \nOfsted \nOfsted (Office for Standards in Education) in its heyday was costing \u00a3100 million a \nyear. Its creation involved reforms to the inspection system and it was a harsh regime \nwithout a solid evidence base (see for example Fitz-Gibbon 1998). Unusually the \nimpact of this reform has been well studied by Shaw, Newton, and Aitken (2003). \nThey showed that state secondary schools were getting worse results in the years \nfollowing inspection. Clearly the purpose of inspection was to raise standards and this \nis a really worrying finding. The Chancellor of the Exchequer, then Gordon Brown, \nnow Prime Minister of England, called the researchers in to his office. Doug Newton \nwas the only one of the authors available at that time. The Chancellor wanted to know \nif the methodology that they had employed could be used in other areas such as \nhealth. Very soon afterwards the enormous amount of money allocated to Ofsted was \nreduced dramatically. There is now a different form of inspection; one which is less \nfrequent and not so heavy-handed. Despite these changes there is no good \nindependent evidence for the efficacy of Ofsted as it is now constituted. Ofsted itself \ntends to rely on anecdotal evidence and data on schools with low test results showing \nimprovement. A approach which are hopelessly confounded with the inevitable \nregression to the mean making it impossible to disentangle claims from counter-\nclaims.  \nNational Numeracy Strategy \nThe National Numeracy Strategy cost about \u00a3500 million and coincided with a \nmodest rise in maths test scores. As noted above it is difficult to disentangle causal \nrelationships from time series data but it is noted that the steady rise in mathematics \nresults do not show and particular jump corresponding to the introduction of the \nNational Numeracy Strategy.  \nNational Literacy Strategy \nThe National Literacy Strategy cost \u00a3500 million and had no detectable impact on \nreading levels.  \nNational testing \nNational testing itself was costing \u00a340 per pupil per subject per year, in 2008 (figure \nreleased to the author under the Freedom of Information Act). With 600,000 pupils in \nan age cohort and 3 subjects to test at the end of Key Stages 2 and 3 the total casts can \nreadily be calculated although that does not include the expense involved within \nschool for preparation and administration. As has been noted above there have been \nsmall rises in English standards and slightly higher rises in mathematics in primary \nschool, whereas in secondary schools there have been rises in the proportion of \nstudents gaining qualifications. It is hard to gauge the extent to which these changes \ncan be said to be due to testing itself but it is at least possible that increased testing \ncontributed to the small positive change in maths attainment.   \n \nSummarising and looking forward \nIn conclusion it can be said that England has seen major reforms to its educational \nsystem worth billions of pounds over the last 20 years. These have resulted in no \nchange in the reading levels of children in English primary schools \u2013 a major intention \nof the reforms - but they are associated with modest rises in mathematics for the same \nage group. At the end of secondary education it is clear that more students are getting \nhigher qualifications at GCSE and at A-Level, more are also going to university. It is \nalso clear that the bar has been lowered for A-Level but not for GCSE at least until \naround 2003. Similar grades are being given for less able students. \n \nThe lack of any major impact on basic skills in primary schools is sobering and it is \nequally worrying that so many hundreds of initiatives were introduced without any \nscientific attempt to evaluate their impact and so we cannot learn from them. It was \nassumed that their remedies would work. Perhaps the clearest demonstration of the \nmidset associated with the reforms comes from the National Literacy Strategy which \nwas being evaluated during its development with control and experimental schools. \nBut the evaluation was cancelled on a political decision because it was thought to be \nmore important that the program was rolled out nationally. Later a one million pound \npost hoc evaluation contract was give to a Canadian group headed by Michael Fullan, \na long standing friend of Michael Barber, the architect of the strategies. The friendly \nevaluation reports failed to spot the erroneous data being generated by the national \ntests. It was all too little too late. \n \nThere is a clear need to think anew about reform and that must be guided by three key \nprinciples. The first is that evidence rather than opinion must hold sway. In England \nthere was little concern about the evidence base of reforms in the 1990s although the \n\u201cfindings\u201d of school effectiveness research, brought together in Teddlie and Reynolds \n(2000) were much quoted. But it has long been recognised that the associations touted \nas the key to reform by school effectiveness researchers were just that, associations, \nand that an evidence base needs to be founded on tight evaluations of initiatives. This \nrealisation started to gain ground and although initially only lip-service was being \npaid to such a view more effort is being taken to take notice of evidence such as it \nexits in the UK and beyond.  \n \nSecondly we should aim to become a learning society. All new initiatives and \npolicies, even those with an excellent pedigree, need to be tightly and continuously \nevaluated. It cannot be sufficient to take a well evaluated and successful reform and \nassume that it will work when it is implemented. Circumstances are always difference \nand continuous monitoring is needed. Further, we should learn from those \nevaluations. No only should policies be based on evidence but policies should be used \nto create evidence. \n \nThirdly we should not forget Campbell\u201fs paper \u201cReforms as Experiments\u201d from 1969. \nNo initiative is perfect and there are always alternatives. We should encourage \ndiversity in our educational systems and help politicians to foster diversity and \ndifferent approaches to reform. It is very unhealthy to insist that a politician should \nnot change his or her mind and perform a U-turn. The future is an unknown land and \nwe need to treat it as such trying out new routes and alerting course as need be..  \n \n \nThanks \n \nDr. David Bolden gave valuable suggestions on an earlier draft of this and thanks for \ndue to him. \n \nReferences \nBarber, M. (2000, December 13 2000: Vol XX, No 15). Education Week: American \nEducation's Newspaper of Record, p. 42 and 45. \n \nCallaghan, J. (1976) The full text of this speech can be viewed at: \nhttp:\/\/education.guardian.co.uk\/thegreatdebate\/story\/0,9860,574645,00.html \n[Accessed: 12\nth\n March 2009]. \n \nCampbell, D. T. (1969). Reforms as experiments. American Psychologist, 24, 409-\n429. \n \nCheek, D. W., Fitz-Gibbon, C. T., & Tymms, P. (2000, December 13 2000: Vol XX, \nNo 15). The English Reforms Are Not for Us. Education Week: American \nEducation's Newspaper of Record, p. 42 and 45. \n \nCoe, R., & Tymms, P. (2008). Summary of research on changes in educational \nstandards in the UK. In M. Harris (Ed.), Education Briefing Book 2008: IoD \nPolicy Paper. London: Institute of Directors. \n \nCoe, R., Serle, J., Barmby, P., Jones, K. and Higgins, S. (2008) Relative Difficulty of \nExaminations in Different Subjects Report for SCORE (Science Community \nSupporting Education) CEM  \n \nFitz-Gibbon, C. (1998). Ofsted: time to go? Managing Schools Today, 7(6), 22-25. \n \nKoretz, D. (2009) Lessons from Test-Based Education Reform in the U.S. ZfE \nBeiheft Nr. 13, vorl\u00e4ufige Gliederung \n \nMassey, A., Green, S., Dexter, T. and Hammet, L. (2003). Comparability of national \ntests over time: KS1, KS2 and KS3 standards between 1996 and 2001. Final \nReport to QCA of the Comparability Over Time Project. London: Research \nand Evaluation Division of the University of Cambridge Local Examinations \nSyndicate. \n \nOttobre, F. M., & Turnbull, W. W. (1987). The International Test of Developed \nAbilities: A report on the feasibility study. Report for the International \nAssociation for Educational Assessment Princeton New Jersey 08541. \n \nStatistics Commission (2005). Measuring Standards in English Primary Schools: \nReport by the Statistics Commission on an article by Peter Tymms (No. \nStatistics Commission Report No 23). London: Statistics Commission. \n \nShaw, I., Newton, D. P., Aitkin, M., & Darnell, R. (2003). Do OFSTED Inspections \nof Secondary Schools Make a Difference to GCSE Results? British \nEducational Research Journal, 29(1), 63-75. \n \nShayer, M., Ginsburg, D., & Coe, R. (2006). 30 Years on - an anti-'Flynn effect'? The \nPiagetian test Volume & Heaviness norms 1975-2003. British Journal of \nEducational Psychology. \n \nTeddlie, C., & Reynolds, D. (2000). The International Handbook of School \nEffectiveness Research. London: Falmer Press. \n \nTymms, P., & Fitz-Gibbon, C. (2001). Standards, Achievement and Educational \nPerformance: A Cause for Celebration? In R. Phillips & J. Furlong (Eds.), \nEducation, Reform and the State: Twenty-Five Years of Politics, Policy and \nPractice (pp. 156-173). London: Routledge Falmer. \n \nTymms, P. (2004). Are standards rising in English primary schools?, British \nEducational Research Journal (Vol. 30, pp. 477-494). \n \nTymms, P., & Merrell, C. (2007). Standards and Quality in English Primary Schools \nOver Time: the national evidence: Primary Review Research Survey 4\/1 (No. \nISBN 978-1-906478-01-8). Cambridge: University of Cambridge Faculty of \nEducation. \n \nTymms, P., & Coe, R. (2003). Celebration of the Success of Distributed Research \nwith Schools: the CEM Centre, Durham. British Educational Research \nJournal, 29(5), 639-653. \n \nTymms, P., Bolden, D., & Merrell, C. (2008). Science in English primary schools: \ntrends in attainment, attitudes and approaches. Perspectives on Education: \nPrimary Science (Wellcome Trust)(1), 19-42. \n \nCharts and Tables \n \nFigure 1 Percent of pupil gaining a Level 4 or above in the statutory tests at the end of \nprimary school \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 2 Percent of students gaining five or more good passes at GCSE in England \n \n \n \n \nFigure 3 Mean score on a measure of developed ability for students starting A level. \n \n \n \n \n \n \n \n \n \n \nChanges in proportion gaining five A*-Cs at GCSE\n1\n0\n10\n20\n30\n40\n50\n60\n19\n75\n19\n80\n19\n85\n19\n90\n19\n95\n20\n00\nP\ner\nce\nnt\nag\ne \nof\n '1\n5 \nye\nar\n o\nld\ns'\n2\n40\n50\n60\n70\n80\n90\n1995 1996 1997 1998 1999 2000 2001 2002 2003 2004\nP\ne\nrc\ne\nn\nt \nle\nv\ne\nl \n4\n a\nn\nd\n a\nb\no\nv\ne\nKS2 maths\nKS2 English\n2000\n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 4 A level grades of students with the same measured developed ability \n \n \n0\n2\n4\n6\n8\n10\n1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004\nG\nra\nd\ne\n (\no\nld\n U\nC\nA\nS\n p\no\nin\nts\n)\nBiology\nEnglish Lit\nFrench\nGeography\nHistory\nMathematics\nA\nB\nC\nD\nE\n"}
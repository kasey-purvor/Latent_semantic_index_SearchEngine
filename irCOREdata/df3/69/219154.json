{"doi":"10.1239\/jap","coreId":"219154","oai":"oai:eprints.lse.ac.uk:35942","identifiers":["oai:eprints.lse.ac.uk:35942","10.1239\/jap"],"title":"Further calculations for the McKean stochastic game for a spectrally negative levy process: from a point to an interval","authors":["Baurdoux, Erik J.","Van Schaik, K."],"enrichments":{"references":[{"id":17281447,"title":"A game-theoretic version of an optimal stopping problem.","authors":[],"date":"1969","doi":"10.1007\/978-1-4899-5591-3_3","raw":"Dynkin, E. B. (1969) A game-theoretic version of an optimal stopping problem. Dokl. Akad. Nauk. SSSR 185, 16{19.","cites":null},{"id":17281455,"title":"Appendix: A free boundary problem for the heat equation arising from a problem of mathematical economics.","authors":[],"date":"1965","doi":null,"raw":"McKean, H. (1965) Appendix: A free boundary problem for the heat equation arising from a problem of mathematical economics. Ind. Manag. Rev. 6, 32{39.","cites":null},{"id":17281440,"title":"Exit problems for spectrally negative L evy processes and applications to (Canadized) Russian options.","authors":[],"date":"2004","doi":"10.1214\/aoap\/1075828052","raw":"Avram, F. and Kyprianou, A.E. and Pistorius, M. R. (2004) Exit problems for spectrally negative L evy processes and applications to (Canadized) Russian options. Ann. Appl. Probab. 14, 215{238. 15[2] Baurdoux, E.J. and Kyprianou, A.E. (2008) The McKean stochastic game driven by a spectrally negative L evy process. Elec. J. of Probab. 8, 173{197.","cites":null},{"id":17281451,"title":"Game options.","authors":[],"date":"2000","doi":"10.1007\/pl00013527","raw":"Kifer, Y. (2000) Game options. Finance and Stochastics 4, 443{463.","cites":null},{"id":17281454,"title":"Introductory Lectures on Fluctuations of L evy processes with Applications.","authors":[],"date":"2006","doi":"10.1007\/978-3-540-31343-4","raw":"Kyprianou, A. E. (2006) Introductory Lectures on Fluctuations of L evy processes with Applications. Springer.","cites":null},{"id":17281444,"title":"L evy Processes.","authors":[],"date":"1996","doi":null,"raw":"Bertoin, J. (1996) L evy Processes. Cambridge University Press.","cites":null},{"id":17281456,"title":"Optimal stopping and perpetual options for L evy processes.","authors":[],"date":"2002","doi":"10.1007\/s007800200070","raw":"Mordecki, E. (2002) Optimal stopping and perpetual options for L evy processes. Finance Stoch. 6, 473{493.","cites":null},{"id":17281448,"title":"Optimal stopping games for Markov processes.","authors":[],"date":"2008","doi":"10.1137\/060673916","raw":"Ekstr om, E. and Peskir, G. (2008) Optimal stopping games for Markov processes. SIAM J. Control Optim. 2, 684{702.","cites":null},{"id":17281452,"title":"Option pricing under a jump-diusion model.","authors":[],"date":"2002","doi":"10.2139\/ssrn.284202","raw":"Kou, S. and Wang, H. (2002) Option pricing under a jump-diusion model. Management Science 50, 1178{1192.","cites":null},{"id":17281449,"title":"Perpetual convertible bonds in jump-diusion models.","authors":[],"date":"2005","doi":"10.1524\/stnd.2005.23.1.15","raw":"Gapeev, P. V. and K uhn, C. (2005) Perpetual convertible bonds in jump-diusion models. Statistics & Decisions 23, 15{31","cites":null},{"id":17281450,"title":"Pricing derivatives of American and game type in incomplete markets.","authors":[],"date":"2004","doi":"10.1007\/s00780-003-0110-7","raw":"Kallsen, J. and K uhn, C. (2004) Pricing derivatives of American and game type in incomplete markets. Finance and Stochastics 8, 261{284.","cites":null},{"id":17281446,"title":"Some applications of L evy processes in insurance and","authors":[],"date":"2004","doi":null,"raw":"Chan, T. (2004) Some applications of L evy processes in insurance and nance. Finance. 25, 71{94.","cites":null},{"id":17281453,"title":"Some calculations for Israeli options.","authors":[],"date":"2004","doi":"10.1007\/s00780-003-0104-5","raw":"Kyprianou, A. E. (2004) Some calculations for Israeli options. Finance and Stochastics 8, 73{86.","cites":null},{"id":17281445,"title":"Stochastic Integration with jumps.","authors":[],"date":"2002","doi":"10.1017\/cbo9780511549878","raw":"Dichteler, K. (2002) Stochastic Integration with jumps. Cambridge University Press MR1906715.","cites":null},{"id":17281443,"title":"The Gapeev-K uhn stochastic game driven by a spectrally positive L evy process.","authors":[],"date":"2009","doi":"10.1016\/j.spa.2011.02.002","raw":"Baurdoux, E.J. and Kyprianou, A.E. and Pardo, J.C. (2009) The Gapeev-K uhn stochastic game driven by a spectrally positive L evy process. Submitted.","cites":null},{"id":17281441,"title":"The Shepp-Shiryaev stochastic game driven by a spectrally negative L evy process. To appear in Theory of Probability and Its Applications.","authors":[],"date":"2008","doi":"10.1137\/s0040585x97983778","raw":"Baurdoux, E.J. and Kyprianou, A.E. (2008) The Shepp-Shiryaev stochastic game driven by a spectrally negative L evy process. To appear in Theory of Probability and Its Applications.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-03","abstract":"Following Baurdoux and Kyprianou (2008) we consider the McKean stochastic game, a game version of the McKean optimal stopping problem (American put), driven by a spectrally negative Levy process. We improve their characterisation of a saddle point for this game when the driving process has a Gaussian component and negative jumps. In particular, we show that the exercise region of the minimiser consists of a singleton when the penalty parameter is larger than some threshold and 'thickens' to a full interval when the penalty parameter drops below this threshold. Expressions in terms of scale functions for the general case and in terms of polynomials for a specific jump diffusion case are provided","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/219154.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/35942\/1\/Further_calculations_for_the_McKean%28lsero%29.pdf","pdfHashValue":"0c130fcc42a576bb30130f5b78895686fe3b79ee","publisher":"Applied Probability Trust","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:35942<\/identifier><datestamp>\n      2014-05-30T13:57:26Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5354<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/35942\/<\/dc:relation><dc:title>\n        Further calculations for the McKean stochastic game for a spectrally negative levy process: from a point to an interval<\/dc:title><dc:creator>\n        Baurdoux, Erik J.<\/dc:creator><dc:creator>\n        Van Schaik, K.<\/dc:creator><dc:subject>\n        QA Mathematics<\/dc:subject><dc:description>\n        Following Baurdoux and Kyprianou (2008) we consider the McKean stochastic game, a game version of the McKean optimal stopping problem (American put), driven by a spectrally negative Levy process. We improve their characterisation of a saddle point for this game when the driving process has a Gaussian component and negative jumps. In particular, we show that the exercise region of the minimiser consists of a singleton when the penalty parameter is larger than some threshold and 'thickens' to a full interval when the penalty parameter drops below this threshold. Expressions in terms of scale functions for the general case and in terms of polynomials for a specific jump diffusion case are provided.<\/dc:description><dc:publisher>\n        Applied Probability Trust<\/dc:publisher><dc:date>\n        2011-03<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/35942\/1\/Further_calculations_for_the_McKean%28lsero%29.pdf<\/dc:identifier><dc:identifier>\n          Baurdoux, Erik J. and Van Schaik, K.  (2011) Further calculations for the McKean stochastic game for a spectrally negative levy process: from a point to an interval.  Journal of Applied Probability, 48 (1).  pp. 200-216.  ISSN 0021-9002     <\/dc:identifier><dc:relation>\n        http:\/\/www.appliedprobability.org\/content.aspx?Group=journals&Page=apjournals<\/dc:relation><dc:relation>\n        10.1239\/jap\/1300198145<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/35942\/","http:\/\/www.appliedprobability.org\/content.aspx?Group=journals&Page=apjournals","10.1239\/jap\/1300198145"],"year":2011,"topics":["QA Mathematics"],"subject":["Article","PeerReviewed"],"fullText":"  \nErik Baurdoux and Kees Van Schaik  \nFurther calculations for the McKean \nstochastic game for a \nspectrally negative Levy process: from a \npoint to an interval \n \nArticle (Published version) \n(Refereed) \n \n \n \n \nOriginal citation: \nBaurdoux, Erik J. and Van Schaik, K. (2011) Further calculations for the McKean stochastic \ngame for a spectrally negative Levy process: from a point to an interval. Journal of applied \nprobability, 48 (1). pp. 200-216. ISSN 0021-9002 \n \nDOI: 10.1239\/jap\/1300198145 \n \n\u00a9 2011 Applied Probability Trust \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/35942  \nAvailable in LSE Research Online: November 2011 \n \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \nFurther calculations for the McKean stochastic game for a\nspectrally negative Le\u00b4vy process: from a point to an interval\nE.J. Baurdoux\u2217, K. van Schaik\u2020\nAbstract\nFollowing Baurdoux and Kyprianou [2] we consider the McKean stochastic game, a\ngame version of the McKean optimal stopping problem (American put), driven by a\nspectrally negative Le\u00b4vy process. We improve their characterisation of a saddle point for\nthis game when the driving process has a Gaussian component and negative jumps. In\nparticular we show that the exercise region of the minimiser consists of a singleton when\nthe penalty parameter is larger than some threshold and \u2019thickens\u2019 to a full interval when\nthe penalty parameter drops below this threshold. Expressions in terms of scale functions\nfor the general case and in terms of polynomials for a specific jump-diffusion case are\nprovided.\nKeywords: Stochastic games, optimal stopping, Levy processes, fluctuation theory\nMathematics Subject Classification (2000): 60G40, 91A15\n1 Introduction\nThis paper is a follow-up to the paper [2] by Baurdoux and Kyprianou (henceforth BK),\nin which the solution to the McKean stochastic game driven by a spectrally negative Le\u00b4vy\nprocess is studied. Let us introduce the setting in BK (and in this paper). Let X be a Le\u00b4vy\nprocess defined on a filtered probability space (\u2126,F ,F,P), where F = (Ft)t\u22650 is the filtration\ngenerated by X which is naturally enlarged (cf. Definition 1.3.38 in Bichteler [6]). For x \u2208 R\nwe denote by Px the law of X when it is started at x and we abbreviate P = P0. Accordingly\nwe shall write Ex and E for the associated expectation operators. We assume throughout\nthat X is spectrally negative, meaning that it has no positive jumps and that it is not the\nnegative of a subordinator.\nThe McKean stochastic game is an example of a type of stochastic games introduced by\nDynkin [8]. It is a two-player zero sum game, consisting of a maximiser aiming at maximizing\nover F-stopping times \u03c4 the expected payoff according to the (discounted) lower payoff process\ngiven by e\u2212qt(K \u2212 exp(Xt))+ for all t \u2265 0 and a minimiser aiming at minimizing over F-\nstopping times \u03c3 the expected payoff according to the (discounted) upper payoff process\ngiven by e\u2212qt((K \u2212 exp(Xt))+ + \u03b4) for all t \u2265 0, where K, \u03b4 > 0. That is, for any pair of\nstopping times (\u03c4, \u03c3) the payoff to the maximizer is\n\u2217Department of Statistics, London School of Economics. Houghton street, London, WC2A 2AE, United\nKingdom. E-mail: e.j.baurdoux@lse.ac.uk\n\u2020Department of Mathematical Sciences, University of Bath, Claverton Down, Bath, BA2 7AY, United\nKingdom. E-mail: k.van.schaik@bath.ac.uk. This author gratefully acknowledges being supported by a post-\ndoctoral grant from the AXA Research Fund\n1\nar\nX\niv\n:0\n91\n0.\n46\n21\nv1\n  [\nma\nth.\nPR\n]  \n24\n O\nct \n20\n09\nMx(\u03c4, \u03c3) := Ex[e\u2212q\u03c4 (K \u2212 eX\u03c4 )+1{\u03c4\u2264\u03c3} + e\u2212q\u03c3((K \u2212 eX\u03c3)+ + \u03b4)1{\u03c3<\u03c4}].\nWe assume throughout this paper that the discount factor q satisfies\n0 \u2264 \u03c8(1) \u2264 q and q > 0, (1)\nwhere \u03c8 denotes the Laplace exponent of X. (Note that since both payoff processes vanish a.s.\nas t\u2192\u221e, there is no ambiguity in allowing for \u03c4 and \u03c3 to be inifinitely valued as we will in\nthis paper). For any x, this game has a value if the upper and lower value, inf\u03c3 sup\u03c4 Mx(\u03c4, \u03c3)\nand sup\u03c4 inf\u03c3Mx(\u03c4, \u03c3) respectively, coincide. Even more, if a pair (\u03c4\u2217, \u03c3\u2217) exists such that\nMx(\u03c4, \u03c3\u2217) \u2264Mx(\u03c4\u2217, \u03c3\u2217) \u2264Mx(\u03c4\u2217, \u03c3) for all (\u03c4, \u03c3),\nthe value exists and equals Mx(\u03c4\u2217, \u03c3\u2217). In this case (\u03c4\u2217, \u03c3\u2217) is called a saddle point (or Nash\nequilibrium). For an account of these concepts in a general Markovian setting, see Ekstro\u00a8m\nand Peskir [9] and the references therein. For other examples of stochastic games, see e.g.\nKifer [12], Kyprianou [14], Baurdoux and Kyprianou [3], Gapeev and Ku\u00a8hn [10], Baurdoux\net al [4].\nNote that the McKean game can be seen as an extension of the classic McKean optimal\nstopping problem (cf. [16] and Theorem 1 below). In a financial interpretation, this optimal\nstopping problem is usually referred to as American put option, with K the strike price. The\nMcKean game then extends the American put option by introducing the possibility for the\nwriter of the option to cancel the contract, at the expense of paying the intrinsic value plus\nan extra constant penalty given by the penalty parameter \u03b4. Cf. e.g. Kifer [12] and Kallsen\nand Ku\u00a8hn [11] for a general account on the interpretation of stochastic games as financial\ncontracts.\nIn BK it was shown that a saddle point (\u03c4\u2217, \u03c3\u2217) indeed exists for the McKean game, so\nin particular the value function V is well defined by\nV (x) = sup\n\u03c4\ninf\n\u03c3\nEx\n[\ne\u2212q\u03c4 (K \u2212 eX\u03c4 )+1{\u03c4\u2264\u03c3} + e\u2212q\u03c3((K \u2212 eX\u03c3)+ + \u03b4)1{\u03c3<\u03c4}\n]\n= inf\n\u03c3\nsup\n\u03c4\nEx\n[\ne\u2212q\u03c4 (K \u2212 eX\u03c4 )+1{\u03c4\u2264\u03c3} + e\u2212q\u03c3((K \u2212 eX\u03c3)+ + \u03b4)1{\u03c3<\u03c4}\n]\n= Ex\n[\ne\u2212q\u03c4\n\u2217\n(K \u2212 eX\u03c4\u2217 )+1{\u03c4\u2217\u2264\u03c3\u2217} + e\u2212q\u03c3\n\u2217\n((K \u2212 eX\u03c3\u2217 )+ + \u03b4)1{\u03c3\u2217<\u03c4\u2217}\n]\n.\nThe optimal stopping time for the maximiser, \u03c4\u2217, is the first hitting time of an interval\nof the form (\u2212\u221e, x\u2217] for some x\u2217 < logK. For the minimiser the optimal stopping time\n\u03c3\u2217 is as follows. When the penalty parameter \u03b4 exceeds \u03b4\u00af := U(logK), where U denotes\nthe value function of the McKean optimal stopping problem, the minimiser never stops (i.e.\n\u03c3\u2217 =\u221e). When \u03b4 \u2264 \u03b4\u00af, the optimal stopping region for the minimizer is an interval of the form\n[logK, y\u2217]. If the Gaussian component \u03c3X of X is equal to zero (note that this corresponds to\nthe situation that X does not creep downwards), we have y\u2217 > logK. Furthermore formulae\nin terms of scale functions for x\u2217 and V on (\u2212\u221e, logK] were provided.\nHowever, two issues were left open in BK. Firstly, when X has a Gaussian component it\nwas not clear when the optimal stopping region for the minimiser consists of a point and when\nof an interval, i.e. when y\u2217 = logK and when y\u2217 > logK holds. Secondly, no characterisation\nwas given of y\u2217. In this paper we give an answer to both these issues. In particular, we show\n2\nthat when \u03c3X > 0 there exists a critical value \u03b40 \u2208 (0, \u03b4\u00af) such that the stopping region for the\nminimiser is a single point when \u03b4 \u2208 [\u03b40, \u03b4\u00af) and a full interval when \u03b4 \u2208 (0, \u03b40), cf. Theorem\n6 (see also Remark 4). Furthermore we show that y\u2217 and \u03b40 can be characterised as unique\nsolutions to functional equations using scale functions, cf. Theorem 8.\nThe rest of this paper is organised as follows. In the remainder of this introduction we\nintroduce scale functions and some notation (Subsection 1.1), and review the results from BK\nin more detail (Subsection 1.2). In Section 2 we present our new results. Finally, in Section\n3 we translate these results to a specific jump-diffusion setting, accompanied by some plots.\n1.1 Scale functions\nFirst we introduce some notation for first entry times. For a \u2264 b we write\n\u03c4+a := inf{t > 0 |Xt > a}, \u03c4\u2212a := inf{t > 0 |Xt < a} and T[a,b] := inf{t > 0 |Xt \u2208 [a, b]}.\nFurthermore we denote the often used first hitting time of logK for simplicity by TK , that is\nTK := inf{t > 0 |Xt = logK}.\nA useful class of functions when studying first exit problems driven by spectrally negative\nLe\u00b4vy processes are so-called scale functions. We shortly review some of their properties as\nthey play an important role in this paper, for a more complete overview the reader is e.g.\nreferred to Chapter VII in Bertoin [5] or Chapter 8 in Kyprianou [15]. For each q \u2265 0 the\nscale functions W (q) : R\u2192 [0,\u221e) are known to satisfy for all x \u2208 R and a \u2265 0\nEx[e\u2212q\u03c4\n+\na 1{\u03c4+a <\u03c4\u22120 }] =\nW (q)(x \u2227 a)\nW (q)(a)\n. (2)\nIn particular it is evident that W (q)(x) = 0 for all x < 0. Furthermore it is known that W (q)\nis almost everywhere differentiable on (0,\u221e), it is right continuous at zero and\u222b \u221e\n0\ne\u2212\u03b2xW (q)(x) dx =\n1\n\u03c8(\u03b2)\u2212 q (3)\nfor all \u03b2 > \u03a6(q), where \u03a6(q) is the largest root of the equation \u03c8(\u03b8) = q (of which there are\nat most two, recall that \u03c8 is the Laplace exponent of X). If X has a Gaussian component\n\u03c3X > 0 it is known that W (q) \u2208 C2(0,\u221e) with W (q)(0) = 0 and W (q)\u2032(0) = 2\/\u03c32X . We usually\nwrite W = W (0).\nAssociated to the functions W (q) are the functions Z(q) : R\u2192 [1,\u221e) defined by\nZ(q)(x) = 1 + q\n\u222b x\n0\nW (q)(y) dy (4)\nfor q \u2265 0. Together the functions W (q) and Z(q) are collectively known as scale functions\nand predominantly appear in almost all fluctuation identities for spectrally negative Le\u00b4vy\nprocesses. For example, it is also known that for all x \u2208 R and a, q \u2265 0\nEx[e\u2212q\u03c4\n\u2212\n0 1{\u03c4+a >\u03c4\u22120 }] = Z\n(q)(x \u2227 a)\u2212 Z\n(q)(a)\nW (q)(a)\nW (q)(x \u2227 a)\nand\n3\nEx[e\u2212q\u03c4\n\u2212\n0 1{\u03c4\u22120 <\u221e}] = Z\n(q)(x)\u2212 q\n\u03a6(q)\nW (q)(x), (5)\nwhere q\/\u03a6(q) is to be understood in the limiting sense \u03c8\u2032(0) \u2227 0 when q = 0.\nFor c > 0, consider the change of measure\ndPc\ndP\n\u2223\u2223\u2223\u2223\nFt\n= ecXt\u2212\u03c8(c)t. (6)\nUnder Pc, the process X is still a spectrally negative Le\u00b4vy process and we mark its Laplace\nexponent and scale functions with the subscript c. From \u03c8c(\u03bb) = \u03c8(\u03bb) \u2212 \u03c8(c) for \u03bb \u2265 0 we\nget by taking Laplace transforms\nW qc (x) = e\n\u2212xW (q+\u03c8(1))(x)\nfor all q \u2265 0.\n1.2 Reviewing the McKean stochastic game\nFirst consider the McKean optimal stopping problem (or American put option) with value\nfunction U , i.e.\nU(x) = sup\n\u03c4\nEx[e\u2212q\u03c4 (K \u2212 eX\u03c4 )+].\nWe recall the solution to this problem as it appears in [7] (see also [17]):\nTheorem 1. For the McKean optimal stopping problem under (1) we have\nU(x) = KZ(q)(x\u2212 k\u2217)\u2212 exZ(q\u2212\u03c8(1))1 (x\u2212 k\u2217),\nwhere\nek\n\u2217\n= K\nq\n\u03a6(q)\n\u03a6(q)\u2212 1\nq \u2212 \u03c8(1) ,\nwhich is to be understood in the limiting sense when q = \u03c8(1), in other words, ek\n\u2217\n=\nK\u03c8(1)\/\u03c8\u2032(1). An optimal stopping time is given by \u03c4\u2217 = inf{t > 0 : Xt < k\u2217}.\nNext we recall the main result from BK on a saddle point and the value function for the\nMcKean game:\nTheorem 2. Consider the McKean stochastic game under the assumption (1).\n(i) If \u03b4 \u2265 U(logK), then a stochastic saddle point is given by \u03c4\u2217 from Theorem 1 and\n\u03c3\u2217 =\u221e, in which case V = U.\n(ii) If \u03b4 < U(logK), a stochastic saddle point is given by the pair\n\u03c4\u2217 = inf{t > 0 : Xt < x\u2217} and \u03c3\u2217 = inf{t > 0 : Xt \u2208 [logK, y\u2217]},\nwhere x\u2217 uniquely solves\nZ(q)(logK \u2212 x)\u2212 Z(q\u2212\u03c8(1))1 (logK \u2212 x) =\n\u03b4\nK\n, (7)\n4\nx\u2217 > k\u2217 (the optimal level of the corresponding McKean optimal stopping problem in\nTheorem 1) and y\u2217 \u2265 logK.\nFurthermore,\nV (x) = KZ(q)(x\u2212 x\u2217)\u2212 exZ(q\u2212\u03c8(1))1 (x\u2212 x\u2217)\nfor x \u2264 logK and if y\u2217 = logK then for any x \u2208 R\nV (x) = KZ(q)(x\u2212 x\u2217)\u2212 exZ(q\u2212\u03c8(1))1 (x\u2212 x\u2217) + \u03b1e\u03a6(q)(logK\u2212x\n\u2217)W (q)(x\u2212 logK),\nwhere\n\u03b1 = ex\n\u2217 q \u2212 \u03c8(1)\n\u03a6(q)\u2212 1 \u2212\nqK\n\u03a6(q)\n,\nwhich is to be understood in the limiting sense when q = \u03c8(1), i.e. \u03b1 = ex\n\u2217\n\u03c8\u2032(1)\u2212K\u03c8(1).\nHence a saddle point exists, and consists of the first hitting time of (\u2212\u221e, x\u2217] for the\nmaximizer and of the first hitting time of [logK, y\u2217] for the minimizer. Furthermore equation\n(7) gives us a characterisation of x\u2217, but we know only little about y\u2217.\nThe issue of when y\u2217 = logK and when y\u2217 > logK holds was in BK only answered when\nX has no Gaussian component:\nTheorem 3. Suppose in Theorem 2 that \u03b4 < U(logK). If X has no Gaussian component,\nthen y\u2217 > logK and necessarily \u03a0(\u2212\u221e, logK \u2212 y\u2217) > 0.\nRemark 4. These results have a clear interpretation. Starting from any X0 > logK, the\nminimizer could either stop right away and pay \u03b4 to the maximizer, or wait a short \u2206t. The\nlatter decision has the advantage of profiting from the discounting, but the disadvantage of\nthe risk that a (large) negative jump could bring X (far) below logK, where a higher payoff\nthan (discounted) \u03b4 can be claimed by the maximizer. The closer X0 is chosen to logK, the\nmore dominant the disadvantage becomes, hence the exercise region for the minimiser takes\nthe form of an interval [logK, y\u2217].\nWhen X is a Brownian motion it is obvious that we have y\u2217 = logK for any \u03b4 \u2208 (0, \u03b4\u00af]\n(see also [14]). The above Theorem 3 tells us that the other extreme case, namely y\u2217 > logK\nfor any \u03b4 \u2208 (0, \u03b4\u00af], i.e. the disadvantage of waiting being dominant for the minimizer, occurs\nwhenever X has no Gaussian component. The interesting question is what happens when\nX has a Gaussian component and negative jumps. It turns out that for \u03b4 large enough,\nwhen stopping immediately is relatively expensive, the Gaussian part \u2019wins\u2019 in the sense that\ny\u2217 = logK, while for \u03b4 small enough, when stopping immediately has become cheaper, the\nnegative jumps \u2019win\u2019 in the sense that y\u2217 > logK, see Theorem 6 below.\n2 Single point or interval when X has a Gaussian part \u03c3X > 0\nThroughout this section we assume that condition (1) holds. Recall that TK := inf{t >\n0 |Xt = logK}. Consider the following function\nf\u03b4(x) = sup\n\u03c4\nEx[e\u2212q\u03c4 (K \u2212 eX\u03c4 )1{\u03c4\u2264TK} + \u03b4e\u2212qTK1{TK<\u03c4}], (8)\ni.e. the optimal value for the maximizer provided the minimiser only exercises when X hits\nlogK.\nWe first prove the following technical result.\n5\nLemma 5. Suppose \u03c3X > 0 and \u03b4 \u2208 (0, \u03b4\u00af]. The function f\u03b4 is differentiable on R\\{logK}.\nFurthermore, f\u03b4 = V on (\u2212\u221e, logK], f\u03b4 \u2265 V on R and f \u2032\u03b4(logK+) is a strictly decreasing\ncontinuous function of \u03b4.\nProof. Let \u03b4 \u2208 (0, \u03b4\u00af]. Due to Theorem 2 and the absence of positive jumps we have for\nx \u2264 logK\nV (x) = Ex[e\n\u2212q\u03c4\u2212\nx\u2217(\u03b4)(K \u2212 e\nX\n\u03c4\u2212\nx\u2217(\u03b4) )1{\u03c4\u2212\nx\u2217(\u03b4)<TK} + \u03b4e\n\u2212qTK1{TK<\u03c4\u2212x\u2217(\u03b4)}]\n= sup\n\u03c4\nEx[e\u2212q\u03c4 (K \u2212 eX\u03c4 )1{\u03c4<TK} + \u03b4e\u2212qTK1{TK<\u03c4}]\n= f\u03b4(x).\nAlso, for any x \u2208 R\nf\u03b4(x) = sup\n\u03c4\nEx[e\u2212q\u03c4 (K \u2212 eX\u03c4 )1{\u03c4\u2264TK} + \u03b4e\u2212qTK1{TK<\u03c4}]\n\u2265 inf\n\u03c3\nsup\n\u03c4\nEx[e\u2212q\u03c4 (K \u2212 eX\u03c4 )1{\u03c4\u2264\u03c3} + \u03b4e\u2212q\u03c31{\u03c3<\u03c4}]\n= V (x).\nIn fact, since stopping is not optimal on (logK,\u221e) as the lower pay-off function is zero there,\nwe deduce that we have for all x \u2208 R\nf\u03b4(x) = Ex[e\n\u2212q\u03c4\u2212\nx\u2217(\u03b4)(K \u2212 e\nX\n\u03c4\u2212\nx\u2217(\u03b4) )1{\u03c4\u2212\nx\u2217(\u03b4)\u2264TK} + \u03b4e\n\u2212qTK1{TK<\u03c4\u2212x\u2217(\u03b4)}]. (9)\nNow, let \u03b42 > \u03b41 > c for some c > 0. From the defintion of f\u03b4 in (8) we find\nf\u03b42(x)\u2212 f\u03b41(x) = sup\n\u03c4\nEx[e\u2212q\u03c4 (K \u2212 eX\u03c4 )1{\u03c4\u2264TK} + \u03b42e\u2212qTK1{TK<\u03c4}]\n\u2212 sup\n\u03c4\nEx[e\u2212q\u03c4 (K \u2212 eX\u03c4 )1{\u03c4\u2264TK} + \u03b41e\u2212qTK1{TK<\u03c4}]\n\u2264 (\u03b42 \u2212 \u03b41) sup\n\u03c4\nEx[e\u2212qTK1{TK<\u03c4}]\n\u2264 (\u03b42 \u2212 \u03b41)Ex[e\u2212q\u03c4\n\u2212\nlogK ],\nfrom which it follows that (the equality by (5))\nf\u03b42(logK + \u03b5)\u2212 \u03b42\n\u03b5\n\u2212 f\u03b41(logK + \u03b5)\u2212 \u03b41\n\u03b5\n\u2264 (\u03b42 \u2212 \u03b41)ElogK+\u03b5[e\n\u2212q\u03c4\u2212logK ]\u2212 1\n\u03b5\n= (\u03b42 \u2212 \u03b41)\n(\nZ(q)(\u03b5)\u2212 1\n\u03b5\n\u2212 q\n\u03a6(q)\nW (q)(\u03b5)\n\u03b5\n)\n.\nSince f\u03b4 is a differentiable function on [logK,\u221e) (see equation (27) in BK together with\n(9)) and using Z(q)\u2032(0) = W (q)(0) = 0, W (q)\u2032(0+) = 2\/\u03c32X we deduce that\nf \u2032\u03b42(logK+)\u2212 f \u2032\u03b41(logK+) \u2264 \u2212\n2q\n\u03c32X\u03a6(q)\n(\u03b42 \u2212 \u03b41), (10)\n6\nshowing that f \u2032\u03b4(logK+) is strictly decreasing in \u03b4. Also, using (8) and the fact that \u03c4\n\u2212\nx\u2217(\u03b41)\nis a feasible strategy also when \u03b4 = \u03b42, it holds that\nf\u03b42(x)\u2212 f\u03b41(x) \u2265 Ex[e\u2212q\u03c4\n\u2212\nx\u2217(\u03b41)(K \u2212 e\nX\n\u03c4\u2212\nx\u2217(\u03b41) )1{\u03c4\u2212\nx\u2217(\u03b41)\u2264TK}\n+ \u03b42e\u2212qTK1{TK<\u03c4\u2212x\u2217(\u03b41)}\n]\n\u2212Ex[e\u2212q\u03c4\n\u2212\nx\u2217(\u03b41)(K \u2212 e\nX\n\u03c4\u2212\nx\u2217(\u03b41) )1{\u03c4\u2212\nx\u2217(\u03b41)\u2264TK}\n+ \u03b41e\u2212qTK1{TK<\u03c4\u2212x\u2217(\u03b41)}\n]\n= (\u03b42 \u2212 \u03b41)Ex[e\u2212qTK1{TK<\u03c4\u2212x\u2217(\u03b41)}]\n\u2265 (\u03b42 \u2212 \u03b41)Ex[e\u2212qTK1{TK<\u03c4\u2212x\u2217(c)}],\nwhere the final inequality follows from the observation that x\u2217(\u03b4) is decreasing in \u03b4 and that\n\u03b41 > c. Note that x\u2217(c) < log(K \u2212 c) since V (x) is strictly decreasing in x \u2208 (\u2212\u221e, logK] for\nany \u03b4 > 0 and thus\nf\u03b42(logK + \u03b5)\u2212 \u03b42\n\u03b5\n\u2212 f\u03b41(logK + \u03b5)\u2212 \u03b41\n\u03b5\n\u2265 (\u03b42 \u2212 \u03b41)\nElogK+\u03b5[e\u2212qTK1{TK<\u03c4\u2212x\u2217(c)}]\u2212 1\n\u03b5\n= (\u03b42 \u2212 \u03b41)W\n(q)(logK + \u03b5\u2212 x\u2217(c))\u2212W (q)(logK \u2212 x\u2217(c))\n\u03b5W (q)(logK \u2212 x\u2217(c))\n\u2212(\u03b42 \u2212 \u03b41)e\u03a6(q)(logK\u2212x\u2217(c)) W\n(q)(\u03b5)\n\u03b5W (q)(logK \u2212 x\u2217(c)) .\nbecause of Lemma 12 in BK. It follows that\nf \u2032\u03b41(logK+)\u2212 f \u2032\u03b41(logK+) \u2265 (\u03b42 \u2212 \u03b41)\n\u03c32XW\n(q)\u2032(logK \u2212 x\u2217(c))\u2212 2e\u03a6(q)(logK\u2212x\u2217(c))\n\u03c32XW\n(q)(logK \u2212 x\u2217(c)) .\nSince c is arbitrary, we conclude from this inequality together with (10) that f \u2032\u03b4(logK+) is\nindeed continuous in \u03b4 for any \u03b4 > 0.\nNow we are ready to prove our main result, extending Theorem 2:\nTheorem 6. Suppose \u03c3X > 0. When \u03a0 6= 0, then there exists a unique \u03b40 \u2208 (0, \u03b4\u00af) such\nthat an optimal stopping time for the minimiser is given by TK (i.e. y\u2217(\u03b4) = logK) when\n\u03b4 \u2208 [\u03b40, \u03b4\u00af] and by T[logK,y\u2217(\u03b4)] for some y\u2217(\u03b4) > logK when \u03b4 \u2208 (0, \u03b40).\nProof. Let \u03c3X > 0 and suppose \u03a0 6= 0. We know from Theorem 2 that the stopping region\nfor the minimiser is of the form [logK, y\u2217] for some y\u2217 \u2265 logK. We claim that setting \u03b40\nequal to the unique zero of f \u2032\u03b4(logK+) on (0, \u03b4\u00af) yields the result.\nFirst let us show that this unique zero indeed exists. For \u03b4 = \u03b4\u00af it holds that f \u2032\u03b4(logK+) =\nU \u2032(logK) < 0 (cf. Theorem 1). Using Lemma 5, it suffices to show that there exists some\n\u03b4 > 0 such that f \u2032\u03b4(logK+) > 0. We argue by contradiction, so, again using Lemma 5,\nsuppose that f \u2032\u03b4(logK+) < 0 for all \u03b4 > 0. This implies that for each \u03b4 > 0 there exists some\n\u03b5 > 0 such that f\u03b4(x) < f\u03b4(logK) = \u03b4 for all x \u2208 (logK, logK + \u03b5]. Since V \u2264 f\u03b4 (Lemma 5)\nwe deduce that V (x) < \u03b4 = (K \u2212 ex)+ + \u03b4 for all x \u2208 (logK, logK + \u03b5), hence y\u2217 = logK\nand in fact V = f\u03b4 (by (8)).\n7\nBut plugging \u03c4\u2212logK\/2 in the rhs of (8) yields\nf\u03b4(x) \u2265 K\/2Ex[e\u2212q\u03c4\n\u2212\nlogK\/21{\u03c4\u2212\nlogK\/2\n<TK}].\nThis lower bound is strictly positive for x > logK since \u03a0 6= 0 and does not depend on \u03b4.\nHence for \u03b4 small enough we deduce the existence of some x > logK such that f\u03b4(x) > \u03b4,\nwhich contradicts with f\u03b4(x) = V (x) \u2264 \u03b4 on [logK,\u221e).\nNext for the optimal stopping time of the minimiser. For \u03b4 > \u03b40 the same reasoning as\nabove yields y\u2217 = logK. For the case \u03b4 = \u03b40 we note that for any fixed x the function f\u03b4(x)\nis continuous in \u03b4, as is easily seen from (8). Hence\nf\u03b40(x) = lim\n\u03b4\u2193\u03b40\nf\u03b4(x) \u2264 (K \u2212 ex)+ + \u03b40,\nfrom which we can deduce that we still have y\u2217 = logK. Finally, let \u03b4 < \u03b40. Again much\nas above, we then have that f \u2032\u03b4(logK+) > 0 and thus there exist x > logK for which\nf\u03b4(x) > \u03b4 = (K \u2212 ex)+ + \u03b4. Since trivially V is bounded above by this upper payoff function,\nit cannot be true that f\u03b4 = V and thus it can also not be true that y\u2217 = logK, so we indeed\narrive at y\u2217 > logK.\nRemark 7. It should be clear from the proof of the above Theorem 6 that this result is\nessentially due to the upper payoff function (K\u2212ex)++\u03b4 having a kink at the point where it first\ntouches the value function as \u03b4 decreases (namely logK). That is, if we would only slightly\nalter the upper payoff function on an environment of logK so it would have a continuous\nderivative, we should expect the optimal stopping time for the minimiser to be T[y\u22171 ,y\u22172 ] with\ny\u22171 < logK < y\u22172 for all \u03b4 \u2208 (0, \u03b4\u00af) and any spectrally negative Le\u00b4vy process X.\nNext we provide expressions that complement those from Theorem 2. Recall that Theorem\n2 in particular already provides us with a formula for V on (\u2212\u221e, logK], so we can make use\nof the following function:\nw\u03b4(x) =\n{\nV (x) for x < logK\n\u03b4 for x \u2265 logK. (11)\nTheorem 8. Suppose \u03a0 6= 0. We have the following.\n(i) Suppose \u03c3X > 0. Then \u03b40 is the unique solution on (0, \u03b4\u00af) to the equation in \u03b4:\u222b\nt<0\n\u222b\nu<t\n(w\u03b4(t+ logK)\u2212 \u03b4)e\u2212\u03a6(q)(t\u2212u)\u03a0(du)dt = \u03b4q\u03a6(q) .\n(ii) Suppose y\u2217 > logK (i.e. \u03c3X > 0 and \u03b4 < \u03b40, or \u03c3X = 0 and \u03b4 < \u03b4\u00af). Then y\u2217 is the\nunique solution on (logK,\u221e) to the equation in y:\u222b\nt<0\n\u222b\nu<t\n(w\u03b4(t+ y)\u2212 \u03b4)e\u2212\u03a6(q)(t\u2212u)\u03a0(du)dt = \u03b4q\u03a6(q) . (12)\nFurthermore, V (x) = \u03b4 for x \u2208 [logK, y\u2217] and for x \u2208 (y\u2217,\u221e):\nV (x) = \u03b4Z(q)(x\u2212 y\u2217)\u2212\n\u222b\nt<0\n\u222b\nu<t\n(w\u03b4(t+ y\u2217)\u2212 \u03b4)W (q)(x\u2212 y\u2217\u2212 t+u)e\u2212\u03a6(q)(t\u2212u)\u03a0(du)dt.\n(13)\n8\nProof. First we introduce the function\nh(x, y) := Ex[e\u2212q\u03c4\n\u2212\ny w\u03b4(X\u03c4\u2212y )] (14)\nfor x > y \u2265 logK. Observe that by the lack of positive jumps, h(., y) is the optimal value\nthe maximizer can obtain when the minimiser chooses as stopping region [logK, y]. Hence in\nparticular V (x) = h(x, y\u2217).\nDenote by u(q)(s, t) the resolvent density of X started at s > 0 and killed at first passage\nbelow 0. Invoking the compensation formula (see e.g. Theorem 4.4 in [15]) leads to\nh(x, y) = \u03b4Ex[e\u2212q\u03c4\n\u2212\ny ] + Ex[e\u2212q\u03c4\n\u2212\ny (w\u03b4(X\u03c4\u2212y )\u2212 \u03b4)1{X\u03c4\u2212y <logK}]\n= \u03b4Ex[e\u2212q\u03c4\n\u2212\ny ] +\n\u222b\nt<logK\u2212y\n\u222b\nu<t\n(w\u03b4(t+ y)\u2212 \u03b4)u(q)(x\u2212 y, t\u2212 u)\u03a0(du)dt\n= \u03b4Ex[e\u2212q\u03c4\n\u2212\ny ] +\n\u222b\nt<0\n\u222b\nu<t\n(w\u03b4(t+ y)\u2212 \u03b4)u(q)(x\u2212 y, t\u2212 u)\u03a0(du)dt,\nwhere the final equality is due to the fact that w\u03b4 = \u03b4 on [logK, y]. We know that (see e.g.\nTheorem 8.1 and Corollary 8.8 in [15] respectively)\nEx[e\u2212q\u03c4\n\u2212\ny ] = Z(q)(x\u2212 y)\u2212 q\n\u03a6(q)\nW (q)(x\u2212 y)\nand\nu(q)(s, t) = e\u2212\u03a6(q)tW (q)(s)\u2212W (q)(s\u2212 t),\nhence\nh(x, y) =\n\u222b\nt<0\n\u222b\nu<t\n(w\u03b4(t+ y)\u2212 \u03b4)(e\u2212\u03a6(q)(t\u2212u)W (q)(x\u2212 y)\u2212W (q)(x\u2212 y \u2212 t+ u))\u03a0(du)dt\n+\u03b4(Z(q)(x\u2212 y)\u2212 q\n\u03a6(q)\nW (q)(x\u2212 y)). (15)\nFurthermore, when X is of unbounded variation we can compute for x > y\n\u2202\n\u2202x\nh(x, y) = \u03b4(qW (q)(x\u2212 y)\u2212 q\n\u03a6(q)\nW (q)\n\u2032\n(x\u2212 y))\n+\n\u222b\nt<0\n\u222b\nu<t\n(w\u03b4(t+ y)\u2212 \u03b4)(e\u2212\u03a6(q)(t\u2212u)W (q)\u2032(x\u2212 y)\u2212W (q)\u2032(x\u2212 y \u2212 t+ u))\u03a0(du)dt.\nand we can let x \u2193 y to arrive at\n\u2202\n\u2202x\nh(y+, y) =\n(\u222b\nt<0\n\u222b\nu<t\n(w\u03b4(t+ y)\u2212 \u03b4)e\u2212\u03a6(q)(t\u2212u)\u03a0(du)dt\u2212 q\u03b4\u03a6(q)\n)\nW (q)\n\u2032\n(0+). (16)\nAd (i). Recall the function f\u03b4 as defined in (8), and recall in particular from the proof of\nLemma 5 that \u03b40 is the unique \u03b4 \u2208 (0, \u03b4\u00af) for which f \u2032\u03b4(logK+) = 0. Furthermore, note that\nf\u03b4(x) = h(x, logK) for x > logK, since both sides equal the optimal value the maximizer\ncan obtain when the minimiser only stops when X hits logK. Combining these observations\nwith (16) and W (q)\n\u2032\n(0+) = 2\/\u03c32X 6= 0 yields the result.\nAd (ii). We first consider the case when X is of bounded variation. We know from\nTheorem 4 in BK that we have continuous fit, i.e. V (y\u2217+) = \u03b4. Since the integrand in (15)\n9\nis bounded and equal to zero for t < logK \u2212 y we can take the limit inside the integrals to\ndeduce that\nh(y+, y) = \u03b4 \u2212 q\u03b4\nd\u03a6(q)\n+\n1\nd\n\u222b\nt<0\n\u222b\nu<t\n(w\u03b4(t+ y)\u2212 \u03b4)e\u2212\u03a6(q)(t\u2212u)\u03a0(du)dt,\nso using V (y\u2217+) = h(y\u2217+, y\u2217) it follows that y\u2217 indeed solves (12). For uniqueness, the\nfunction w\u03b4 = V is strictly decreasing on (\u2212\u221e, logK] and \u03b4 = V (y\u2217) = h(y\u2217+, y\u2217). Since\nq > 0, the minimiser would not stop at points in [logK,\u221e] from which the process cannot\njump into (\u2212\u221e, logK) and thus logK \u2212 y\u2217 > l := sup{x : \u03a0(\u2212\u221e, x) = 0}. Combining these\nobservations imply that h(y+, y) is a strictly decreasing function on [logK, logK \u2212 l].\nNext consider the case that X is of unbounded variation. Now Theorem 4 in BK tells us\nthat we have smooth fit, i.e. V \u2032(y\u2217+) = 0. Using V (x) = h(x, y\u2217) together with (16) yields\nagain that y\u2217 solves (12), uniqueness follows in the same way as in the previous paragraph.\nFinally, (13) is readily seen from V (x) = h(x, y\u2217), (15) and the fact that y\u2217 satisfies (12).\nWe conclude this section with some properties of y\u2217 as a function of \u03b4. Note that by\nspectral negativity, \u03a0 6= 0 implies sup{x : \u03a0(\u2212\u221e, x) = 0} < 0.\nTheorem 9. Suppose \u03a0 6= 0. Then y\u2217(\u03b4) is continuous and decreasing as a function of \u03b4, with\ny\u2217(\u03b4\u00af\u2212) = logK if \u03c3X = 0 (resp. y\u2217(\u03b40\u2212) = logK if \u03c3X > 0) and y\u2217(0+) = logK \u2212 sup{x :\n\u03a0(\u2212\u221e, x) = 0}.\nProof. We write V\u03b4 to stress the dependence of the value function on \u03b4. Continuity of y\u2217(\u03b4)\nis clear as the above Theorem 8 (ii) and the fact that w\u03b4 is continuous in \u03b4 (see the argument\nfor continuity of \u03b4 7\u2192 V\u03b4 below) allow to apply the implicit function theorem.\nTo see that it is decreasing it suffices to show that \u03b4 7\u2192 V\u03b4(x)\u2212 \u03b4 is decreasing. For this,\ntake \u03b41 < \u03b42 and let (\u03c4\u22171 , \u03c3\u22171) denote the saddle point when \u03b4 = \u03b41. Then V\u03b41 is the value when\nthe supremum over all pairs (\u03c4, \u03c3\u22171) is taken. As \u03c3\u22171 is also feasible for the minimiser when\n\u03b4 = \u03b42 we have that V\u03b42 is bounded above by the value when the supremum over the same\npairs (\u03c4, \u03c3\u22171) is taken. This yields\nV\u03b42(x)\u2212 V\u03b41(x) \u2264 sup\n\u03c4\nEx[e\u2212q\u03c3\n\u2217\n1 ((K \u2212 eX\u03c3\u22171 )+ + \u03b42)1{\u03c3\u22171<\u03c4}\n\u2212e\u2212q\u03c3\u22171 ((K \u2212 eX\u03c3\u22171 )+ + \u03b41)1{\u03c3\u22171<\u03c4}]\n\u2264 \u03b42 \u2212 \u03b41, (17)\nas required.\nNext, by the monotonicity the limits mentioned in the theorem exist. First we show\ny\u2217(0+) = logK \u2212 l, where l := sup{x : \u03a0(\u2212\u221e, x) = 0}. Suppose we had y\u2217(0+) < logK \u2212 l,\nthen for some x1 \u2208 (y\u2217(0+), logK \u2212 l) and any \u03b4 > 0 we have Px1(\u03c4\u2212logK\/2 < T[logK,y\u2217(\u03b4)]) \u2265\nPx1(\u03c4\n\u2212\nlogK\/2 < T[logK,y\u2217(0+)]) > 0. So, starting from x1, if the maximizer chooses \u03c4\n\u2212\nlogK\/2\nhe ensures a strictly positive value, independent of \u03b4. But this of course contradicts with\nV\u03b4(x1) \u2264 \u03b4 \u2193 0 as \u03b4 \u2193 0. If we had y\u2217(0+) > logK \u2212 l, then for some x2 \u2208 (logK \u2212 l, y\u2217(0+))\nwe have for \u03b4 small enough x2 \u2264 y\u2217(\u03b4) and consequently V\u03b4(x2) = \u03b4. But the minimiser\ncan do better, that is in fact we have V\u03b4(x2) < \u03b4, as is easily seen. Namely, the minimiser\ncan choose T[logK,logK\u2212l], so that starting from x2 > logK \u2212 l the maximiser can at most\n10\nget discounted \u03b4, the discount factor being strictly less than 1 since q > 0 and X is right\ncontinuous.\nNext suppose \u03c3X > 0 and let us show that y\u2217(\u03b40\u2212) = logK. Suppose we had y\u2217(\u03b40\u2212) >\nlogK. Note that for any x, \u03b4 7\u2192 V\u03b4(x) is continuous, since for \u03b41 < \u03b42 trivially V\u03b42(x) \u2265 V\u03b41(x)\nand (17). So for logK < x1 < x2 < y\u2217(\u03b40\u2212) it would follow that V\u03b4(x1) \u2212 V\u03b4(x2) \u2192\nV\u03b40(x1)\u2212 V\u03b40(x2) = \u03b40 \u2212 \u03b40 = 0 as \u03b4 \u2193 \u03b40. But the difference V\u03b4(x1)\u2212 V\u03b4(x2) does not vanish\nas \u03b4 \u2193 \u03b40, as follows easily from the homogeneity of X. More precisely, denoting by (\u03c4\u22171 , \u03c3\u22171)\nresp. (\u03c4\u22172 , \u03c3\u22172) the saddle point when starting from x1 resp. x2, similar arguments as the ones\nleading to (17) yield in this case\nV\u03b4(x1) \u2265 E[e\u2212q\u03c4\u22172 (K \u2212 ex1+X\u03c4\u22172 )+1{\u03c4\u22172\u2264\u03c3\u22171} + e\u2212q\u03c3\n\u2217\n1 ((K \u2212 ex1+X\u03c3\u22171 )+ + \u03b4)1{\u03c3\u22171<\u03c4\u22172 }]\nand\nV\u03b4(x2) \u2264 E[e\u2212q\u03c4\u22172 (K \u2212 ex2+X\u03c4\u22172 )+1{\u03c4\u22172\u2264\u03c3\u22171} + e\u2212q\u03c3\n\u2217\n1 ((K \u2212 ex2+X\u03c3\u22171 )+ + \u03b4)1{\u03c3\u22171<\u03c4\u22172 }],\nthus\nV\u03b4(x1)\u2212 V\u03b4(x2) \u2265 E[e\u2212q\u03ba((K \u2212 ex1+X\u03ba)+ \u2212 (K \u2212 ex2+X\u03ba)+)] (18)\nwhere \u03ba = \u03c3\u22171 \u2227 \u03c4\u22172 = inf{t > 0 |Xt = logK\u2212x1}\u2227 inf{t > 0 |Xt < x\u2217(\u03b4)\u2212x2}. Clearly, since\nx\u2217(\u03b4) \u2264 logK and x1 < x2 the rhs of (18) is strictly positive iff P(\u03c4\u22172 < \u03c3\u22171) > 0. Obviously\nalso after taking the limit for \u03b4 \u2193 \u03b40 this probability is positive on account of \u03a0 6= 0.\nFinally, y\u2217(\u03b4\u00af\u2212) = logK when \u03c3X = 0 can be shown by the same arguments, taking into\naccount here one has \u03c3\u2217 =\u221e for \u03b4 > \u03b4\u00af.\n3 Jump-diffusion case\nIn this section we translate the general results from the previous Section 2 to the particular\ncase of a jump-diffusion with downwards directed, exponentially distributed jumps. In this\ncase, which is quite popular in practical applications in finance e.g. due to its tractable nature,\nthe expressions become much more explicit. In particular a formula exists that expresses y\u2217\nexplicit in terms of x\u2217, cf. Proposition 12 (iv).\nFor the sequel we set\nXt = \u03c3XWt + \u00b5t\u2212\nNt\u2211\ni=1\n\u03bei, t \u2265 0, (19)\nwhere \u03c3X > 0, \u00b5 \u2208 R, N is a Poisson process with intensity \u03bb > 0 counting the jumps\nand (\u03bei)i\u22650 is an iid sequence of random variables following an exponential distribution with\nparameter \u03b8 > 0.\nThe following Proposition 10 states formulas for the scale functions in this jump-diffusion\ncase (recall Pc as defined in (6)):\nProposition 10. Let c, r \u2265 0. We have the following for X given by (19) under Pc.\n11\n(i) The Laplacian is given by\n\u03c8c(z) = \u03c8(z + c)\u2212 \u03c8(c) = \u03c3\n2\nX\n2\nz2 + (\u03c32Xc+ \u00b5)z \u2212\n\u03bb\u03b8z\n(\u03b8 + z + c)(\u03b8 + c)\n.\nThe function z 7\u2192 \u03c8c(z) \u2212 r has three zeros \u03b21(c, r) < \u2212\u03b8 \u2212 c < \u03b22(c, r) \u2264 \u03b23(c, r),\nwith \u03b22(c, r) < 0 < \u03b23(c, r) if r > 0; \u03b22(c, r) = 0 < \u03b23(c, r) if r = 0 and \u03c8\u2032c(0) \u2264 0;\n\u03b22(c, r) < 0 = \u03b23(c, r) if r = 0 and \u03c8\u2032c(0) \u2265 0.\n(ii) In particular, if r = \u03c8(1) > 0 we have\n\u03b21,2(0, r) = \u2212\n(\n\u03b8\n2\n+\nr\n\u03c32X\n+\n\u03bb\n\u03c32X(\u03b8 + 1)\n)\n\u00b1\n\u221a(\n\u03b8\n2\n+\nr\n\u03c32X\n+\n\u03bb\n\u03c32X(\u03b8 + 1)\n)2\n\u2212 2r\u03b8\n\u03c32X\nand \u03b23(0, r) = 1.\nDefine for i = 1, 2, 3 the constants\nCi(c, r) =\n2(\u03b8 + c+ \u03b2i(c, r))\n\u03c32X\n\u220f\nj 6=i(\u03b2j(c, r)\u2212 \u03b2i(c, r))\n.\nWe have the following formulas for the scale functions W (r)c and Z\n(r)\nc on [0,\u221e).\n(iii) If \u03b22(c, r) 6= 0 or \u03b23(c, r) 6= 0 we have\nW (r)c (x) =\n3\u2211\ni=1\nCi(c, r)e\u03b2i(c,r)x,\notherwise (necessarily r = 0) we have\nW (0)c (x) =\n2\n\u03c32X\u03b21(c, 0)\n(\n(1\u2212 c\u2212 \u03b8)e\u03b21(c,0)x \u2212 (\u03b8 + c)x+ \u03b8 + c\u2212 1\n)\n.\n(iv) If r > 0 we have\nZ(r)c (x) = r\n3\u2211\ni=1\nCi(c, r)\n\u03b2i(c, r)\ne\u03b2i(c,r)x,\nwhile Z(0)c (x) = 1.\nProof. Follows from the definitions (3) and (4) by some elementary calculations. Also, see\ne.g. [1].\nIn the sequel we assume for simplicity q > 0 and q = \u03c8(1), i.e. we set \u00b5 := q\u2212\u03c32X\/2+\u03bb\/(\u03b8+\n1). (Note that condition (1) is met). This means that P is a so-called risk neutral measure\nin the sense that the discounted price process (eXt\u2212qt)t\u22650 is a P-martingale, as required in a\nfinancial modelling context. (However the reader should have no difficulties translating the\nupcoming formulas to the situation for any q \u2208 [0, \u03c8(1)] if required.) Note that the above\nProposition 10 (ii) gives explicit formulas for the roots \u03b2i(0, q) in this case.\nFirst we turn to formulas for the McKean optimal stopping problem (cf. Theorem 1).\n12\nProposition 11. The value function U of the McKean optimal stopping problem is given by\nU(x) =\n{\nK \u2212 ex if x \u2264 k\u2217\nc1e\n\u03b21(0,q)(x\u2212k\u2217) + c2e\u03b22(0,q)(x\u2212k\n\u2217) if x > k\u2217,\nwhere\nc1 =\n\u03b22(0, q)K + (1\u2212 \u03b22(0, q))ek\u2217\n\u03b22(0, q)\u2212 \u03b21(0, q) , c2 =\n\u03b21(0, q)K + (1\u2212 \u03b21(0, q))ek\u2217\n\u03b21(0, q)\u2212 \u03b22(0, q)\nand ek\n\u2217\n=\nKq\n\u03c32X\/2 + q + \u03bb\/(\u03b8 + 1)2\n.\nProof. A direct derivation of these formulas can be found in [13] e.g. Alternatively, plugging\nthe formulas from Proposition 10 in the results from Theorem 1 we see that we can write\nU(x) = Kq\n3\u2211\ni=1\nCi(0, q)\n\u03b2i(0, q)\ne\u03b2i(0,q)(x\u2212k\n\u2217) \u2212 ex and ek\u2217 = K \u03c8(1)\n\u03c8\u2032(1)\n. (20)\nApplying the identity\n\u03c32X\n2\n3\u220f\ni=1\n(z \u2212 \u03b2i(c, q)) = (\u03b8 + z + c)(\u03c8c(z)\u2212 q) for z 6= \u2212\u03b8 \u2212 c (21)\nto this particular case (i.e. c = 0, q = \u03c8(1), \u03b23(0, q) = 1), dividing both sides by z \u2212 1 and\ntaking the limit for z \u2192 1 we find\n\u03c32X(1\u2212 \u03b21(0, q))(1\u2212 \u03b22(0, q)) = 2(\u03b8 + 1)\u03c8\u2032(1). (22)\nPlugging this in the equation for ek\n\u2217\nwe find ek\n\u2217\n= 2(\u03b8+1)Kq\/(\u03c32X(\u03b22(0, q)\u22121)(\u03b21(0, q)\u22121)).\nUsing this expression in (20), together with \u03b21(0, q)\u03b22(0, q) = 2q\u03b8\/\u03c32X (from (21) with z = 0),\nthe stated formula for U indeed follows.\nNow we are ready to turn to formulas for the optimal exercise levels x\u2217, y\u2217 and the value\nfunction V of the McKean game. Recall that for \u03b4 \u2265 U(logK) the game degenerates to the\nMcKean optimal stopping problem.\nProposition 12. Consider the McKean game driven by (19). Recall \u03b4\u00af = U(logK). We\nassume throughout that \u03b4 < \u03b4\u00af.\n(i) The optimal level x\u2217 = x\u2217(\u03b4) is the unique solution to the equation in x:\nq\n3\u2211\ni=1\nCi(0, q)\n\u03b2i(0, q)\nK\u03b2i(0,q)e\u2212\u03b2i(0,q)x \u2212 1 = \u03b4\nK\n.\nOn (\u2212\u221e, x\u2217] we have V (x) = K \u2212 ex and on (x\u2217, logK] we have\nV (x) = Kq\n3\u2211\ni=1\nCi(0, q)\n\u03b2i(0, q)\ne\u03b2i(0,q)(x\u2212x\n\u2217) \u2212 ex.\n13\n(ii) The threshold \u03b40 \u2208 (0, \u03b4\u00af) is the unique solution to the equation in z:\nq\n3\u2211\ni=1\nCi(0, q)K\u03b2i(0,q)\n\u03b2i(0, q)(\u03b8 + \u03b2i(0, q))\ne\u2212\u03b2i(0,q)x\n\u2217(z) \u2212 \u03bb+ (\u03b8 + 1)q\n\u03bb\u03b8K\nz =\n1\n\u03b8 + 1\n.\n(iii) Suppose \u03b4 \u2208 [\u03b40, \u03b4\u00af). We have y\u2217 = logK and on [logK,\u221e)\nV (x) = K\n2\u2211\ni=1\nCi(0, q)\n(\nqe\u2212\u03b2i(0,q)x\u2217\n\u03b2i(0, q)\n+K\u2212\u03b2i(0,q)\n(\n\u03c8\u2032(1)\u2212Kqe\u2212x\u2217\n))\ne\u03b2i(0,q)x.\n(iv) Suppose \u03b4 \u2208 (0, \u03b40). We have\ne\u03b8y\n\u2217\n=\n\u03bb\u03b8K\u03b8+1\n(\u03b8 + 1)q\u03b4\n(\nq\n3\u2211\ni=1\nCi(0, q)K\u03b2i(0,q)\n\u03b2i(0, q)(\u03b8 + \u03b2i(0, q))\ne\u2212\u03b2i(0,q)x\n\u2217 \u2212 1\n\u03b8 + 1\n\u2212 \u03b4\n\u03b8K\n)\n.\nOn [logK, y\u2217] we have V (x) = \u03b4 and on (y\u2217,\u221e) we have\nV (x) =\n\u03b4\n\u03b22(0, q)\u2212 \u03b21(0, q)\n(\n\u03b22(0, q)e\u03b21(0,q)(x\u2212y\n\u2217) \u2212 \u03b21(0, q)e\u03b22(0,q)(x\u2212y\u2217)\n)\n.\nProof. Ad (i). Apply Proposition 10 to the formulas from Theorem 2 (ii).\nAd (ii). Apply Proposition 10 to Theorem 8 (i).\nAd (iii). Apply Proposition 10 to the formula from Theorem 2 (ii) to obtain\nV (x) = K\n3\u2211\ni=1\nCi(0, q)\n(\nqe\u2212\u03b2i(0,q)x\u2217\n\u03b2i(0, q)\n+K\u2212\u03b2i(0,q)\n(\n\u03c8\u2032(1)\u2212Kqe\u2212x\u2217\n))\ne\u03b2i(0,q)x \u2212 ex\nand use (22) to see that the terms involving the exponential of a positive factor times x vanish.\n(Of course, one can also reason directly that they should cancel, since otherwise V would not\nstay bounded for large x, which it should by definition).\nAd (iv). For y\u2217, apply Proposition 10 to Theorem 8 (ii) and simplify to arrive at the\nstated formula. Note that\n3\u2211\ni=1\nCi(0, q)\n\u03b2i(0, q)(\u03b8 + \u03b2i(0, q))\n=\n2\n\u03c32X\n\u220f3\ni=1 \u03b2i(0, q)\n=\n1\n\u03b8q\n,\nthe final equality by (21).\nFor V , apply Proposition 10 to Theorem 8 (ii) and simplify, making use of the formula\nfor y\u2217 and in particular Proposition 10 (ii).\nWe conclude with two plots in this jump-diffusion setting, produced using the above\nProposition 12, to illustrate the main result from this paper.\n14\n1 2 3 4\n5\n10\n15\nFigure 1: \u03b4 \u2208 [\u03b40, \u03b4\u00af), so y\u2217 = logK. The black curves are the upper and lower payoff functions,\nthe red curve is the value function V\n1 2 3 4\n2\n4\n6\n8\n10\n12\nFigure 2: \u03b4 \u2208 (0, \u03b40), so y\u2217 > logK. The black curves are the upper and lower payoff\nfunctions, the red curve is the value function V\nReferences\n[1] Avram, F. and Kyprianou, A.E. and Pistorius, M. R. (2004) Exit problems for spectrally\nnegative Le\u00b4vy processes and applications to (Canadized) Russian options. Ann. Appl.\nProbab. 14, 215\u2013238.\n15\n[2] Baurdoux, E.J. and Kyprianou, A.E. (2008) The McKean stochastic game driven by a\nspectrally negative Le\u00b4vy process. Elec. J. of Probab. 8, 173\u2013197.\n[3] Baurdoux, E.J. and Kyprianou, A.E. (2008) The Shepp-Shiryaev stochastic game driven\nby a spectrally negative Le\u00b4vy process. To appear in Theory of Probability and Its Appli-\ncations.\n[4] Baurdoux, E.J. and Kyprianou, A.E. and Pardo, J.C. (2009) The Gapeev-Ku\u00a8hn stochas-\ntic game driven by a spectrally positive Le\u00b4vy process. Submitted.\n[5] Bertoin, J. (1996) Le\u00b4vy Processes. Cambridge University Press.\n[6] Dichteler, K. (2002) Stochastic Integration with jumps. Cambridge University Press\nMR1906715.\n[7] Chan, T. (2004) Some applications of Le\u00b4vy processes in insurance and finance. Finance.\n25, 71\u201394.\n[8] Dynkin, E. B. (1969) A game-theoretic version of an optimal stopping problem. Dokl.\nAkad. Nauk. SSSR 185, 16\u201319.\n[9] Ekstro\u00a8m, E. and Peskir, G. (2008) Optimal stopping games for Markov processes. SIAM\nJ. Control Optim. 2, 684\u2013702.\n[10] Gapeev, P. V. and Ku\u00a8hn, C. (2005) Perpetual convertible bonds in jump-diffusion models.\nStatistics & Decisions 23, 15\u201331\n[11] Kallsen, J. and Ku\u00a8hn, C. (2004) Pricing derivatives of American and game type in\nincomplete markets. Finance and Stochastics 8, 261\u2013284.\n[12] Kifer, Y. (2000) Game options. Finance and Stochastics 4, 443\u2013463.\n[13] Kou, S. and Wang, H. (2002) Option pricing under a jump-diffusion model. Management\nScience 50, 1178\u20131192.\n[14] Kyprianou, A. E. (2004) Some calculations for Israeli options. Finance and Stochastics\n8, 73\u201386.\n[15] Kyprianou, A. E. (2006) Introductory Lectures on Fluctuations of Le\u00b4vy processes with\nApplications. Springer.\n[16] McKean, H. (1965) Appendix: A free boundary problem for the heat equation arising\nfrom a problem of mathematical economics. Ind. Manag. Rev. 6, 32\u201339.\n[17] Mordecki, E. (2002) Optimal stopping and perpetual options for Le\u00b4vy processes. Finance\nStoch. 6, 473\u2013493.\n16\n"}
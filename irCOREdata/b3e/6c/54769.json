{"doi":"10.1068\/p6517","coreId":"54769","oai":"oai:eprints.lincoln.ac.uk:2422","identifiers":["oai:eprints.lincoln.ac.uk:2422","10.1068\/p6517"],"title":"Human spontaneous gaze patterns in viewing of faces of \\ud\ndifferent species","authors":["Guo, Kun","Tunnicliffe, David","Roebuck, Hettie"],"enrichments":{"references":[{"id":1024599,"title":"Eye-movement-based memory effect: A reprocessing effect in face perception\u201d","authors":[],"date":"1999","doi":"10.1037\/\/0278-7393.25.4.997","raw":"Althoff RR, Cohen NJ, 1999 \u201cEye-movement-based memory effect: A reprocessing effect in face perception\u201d Journal of Experimental Psychology: Learning, Memory, and Cognition 25 997-1010 Barton JJS, Radcliffe N, Cherkasova MV, Edelman J, Intriligator JM, 2006 \u201cInformation processing during face recognition: the effects of familiarity, inversion, and morphing on scanning fixations\u201d Perception 35 1089-1105 Bentin S, Allison T, Puce A, Perez A, McCarthy G, 1996 \u201cElectrophysiological studies of face perception in humans\u201d Journal of Cognitive Neuroscience 8 551\u2013565   18 Buchan JN, Pare M, Munhall KG, 2000 \u201cSpatial statistics of gaze fixations during dynamic face processing\u201d Social Neuroscience 2 1-13 Burt DM, Perrett DI, 1997 \u201cPerceptual asymmetries in judgements of facial attractiveness, age, gender, speech and expression\u201d Neuropsychologia 35 685-693 Butler S, Gilchrist ID, Burt DM, Perrett DI, Jones E, Harvey M, 2005 \u201cAre the perceptual biases found in chimeric face processing reflected in eye-movement patterns?\u201d Neuropsychologia 43 52-59 Campbell R, Pascalis O, Coleman M, Wallace SB, Benson PJ, 1997 \u201cAre faces of different species perceived categorically by human observers?\u201d Proceedings of the Royal Society of London, Series B 264 1429-1434 Carmel D, Bentin S, 2002 \u201cDomain specificity versus expertise: factors influencing distinct processing of faces\u201d Cognition 83 1-29 Dahl CD, Wallraven C, B\u00fclthoff HH, Logothetis NK, 2009 \u201cHumans and macaques employ similar face-processing strategies\u201d Current Biology 19 509-513 de Haan M, Pascalis O, Johnson M, 2002 \u201cSpecialization of neural mechanisms underlying face recognition in human infants\u201d Journal of Cognitive Neuroscience 14 199-209 Farah MJ, 1996 \u201cIs face recognition \u2018special\u2019? Evidence from neuropsychology\u201d Behaviour Brain Research 76 181-189 Gobbini MI, Haxby JV, 2007 \u201cNeural systems for recognition of familiar faces\u201d Neuropsychologia 45 32-41 Golby AJ, Gabrieli JDE, Chiao JY, Eberhardt JL, 2001 \u201cDifferential responses in the fusiform region to same-race and other-race faces\u201d Nature Neuroscience 4 845-850 Guo K, Robertson RG, Mahmoodi S, Tadmor Y, Young MP, 2003 \u201cHow do monkeys view faces? \u2013 A study of eye movements\u201d Experimental Brain Research 150 363-374 Guo K, Mahmoodi S, Robertson RG, Young MP, 2006 \u201cLonger fixation duration while viewing face images\u201d Experimental Brain Research 171 91-98 Guo K, 2007 \u201cInitial fixation placement in face images is driven by top-down guidance\u201d Experimental Brain Research 181 673-677 Guo K, Meints K, Hall C, Hall S, Mills D, 2009 \u201cLeft gaze bias in humans, rhesus monkeys and domestic dogs\u201d Animal Cognition 12 409-418 Heisz JJ, Shore DI, 2008 \u201cMore efficient scanning for familiar faces\u201d Journal of Vision 8 1-10 Henderson JM, 2003 \u201cHuman gaze control during real-world scene perception\u201d Trends in Cognitive Sciences 7 498-504 Hsiao JH, Cottrell GW, 2008 \u201cTwo fixations suffice in face recognition\u201d Psychological Science 9 998-1006 Itti L, Koch C, 2000 \u201cA saliency-based search mechanism for overt and covert shifts of visual attention\u201d Vision Research 40 1489-1506 Leonards U, Scott-Samuel NE, 2005 \u201cIdiosyncratic initiation of saccadic face exploration in humans\u201d Vision Research 45 2677-2684 Malcolm GL, Lanyon LJ, Fugard AJB, Barton JJS, 2008 \u201cScan patterns during the processing of facial expression versus identity: An exploration of task-driven and stimulus-driven effects\u201d Journal of Vision 8(8):2 1-9 McKone E, Kanwisher N, Duchaine BC, 2006 \u201cCan generic expertise explain special processing for faces?\u201d Trends in Cognitive Sciences 11 8-15   19 Mertens I, Siegmund H, Grusser OJ, 1993 \u201cGaze motor asymmetries in the perception of faces during a memory task\u201d Neuropsychologia 31 989-998 Mondloch CJ, Maurer D, Ahola S, 2006 \u201cBecoming a face expert\u201d Psychological Science 17 930-934 Moscovitch M, Winocur G, Behrmann M, 1997 \u201cWhat is special about face recognition? Nineteen experiments on a person with visual object agnosia and dyslexia but normal face recognition\u201d Journal of Cognitive Neuroscience 9 555-604 Nicholls MER, Roberts GR, 2002 \u201cCan free-viewing perceptual asymmetries be explained by scanning, pre-motor or attentional biases?\u201d Cortex 38 113-136 Parkhurst DJ, Niebur E, 2003 \u201cScene content selected by active vision\u201d Spatial Vision 16 125\u2013154 Pascalis O,  Tde Haan M, Nelson CA,T 2002 \u201cIs face processing species-specific during the first year of life?\u201d Science 296 1321-1323 Philips ML, David AS, 1997 \u201cViewing strategies for simple and chimeric faces: An investigation of perceptual bias in normal and schizophrenic patients using visual scan paths\u201d Brain and Cognition 32 225-238 Rhodes G, Hayward WG, Winkler C, 2006 \u201cExpert face coding: Configural and component coding of own-race and other-race faces\u201d Psychonomic Bulletin & Review 13 499-505 Rousselet GA, Mace MJM, Fabre-Thorpe M, 2004 \u201cAnimal and human faces in natural scenes: how specific to human faces is the N170 ERP component?\u201d Journal of Vision 4 13-21 HTSchyns PGTH,  HTPetro LSTH,  HTSmith MLTH, 2007 \u201cDynamics of visual information integration in the brain for categorizing facial expressions\u201d Current Biology 17 1580-1585 TStacey PC, Walker S, Underwood JDM, 2005 \u201cFace processing and familiarity: evidence from eye-movement data\u201d British Journal of Psychology 94 407-422 Tanaka J, Kiefer M, Bukach CM, 2004 \u201cA holistic account of the own-race effect in face recognition: evidence from a cross-cultural study\u201d Cognition 93 1-9 Tarr MJ, Cheng YD, 2003 \u201cLearning to see faces and objects\u201d Trends in Cognitive Sciences 7 23-30 Vaid J, Singh M, 1989 \u201cAsymmetries in the perception of facial affect: Is there an influence of reading habits?\u201d Neuropsychologia 27 1277-1287 Valentine T, 1988 \u201cUpside-down faces: a review of the effects of inversion upon face recognition\u201d British Journal of Psychology 79 471-491","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-04","abstract":"Human studies have reported clear differences in perceptual and neural processing of faces of different species, implying the contribution of visual experience to face perception. Can these differences be manifested in our eye scanning patterns while extracting salient facial information? Here we systematically compared non-pet owners\u2019 gaze patterns while exploring human, monkey, dog and cat faces in a passive viewing task. Our analysis revealed that the faces of different species induced similar patterns of fixation distribution between left and right hemi-face, and among key local facial features with the eyes attracting the highest proportion of fixations and viewing times, followed by the nose and then the mouth. Only the proportion of fixation directed at the mouth region was species-dependent and could be differentiated at the earliest stage of face viewing. It seems that our spontaneous eye scanning patterns associated with face exploration were mainly constrained by general facial configurations; the species affiliation of the inspected faces had limited impact on gaze allocation, at least under free viewing conditions","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/54769.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/2422\/1\/Perception_2010.pdf","pdfHashValue":"d76ed3308eb95e4bde70f369cdd87e4f88cf3850","publisher":"Pion","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:2422<\/identifier><datestamp>\n      2013-03-13T08:37:22Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F43:6A6163735F43383030<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F43:6A6163735F43383530<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F43:6A6163735F43383330<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/2422\/<\/dc:relation><dc:title>\n        Human spontaneous gaze patterns in viewing of faces of \\ud\ndifferent species<\/dc:title><dc:creator>\n        Guo, Kun<\/dc:creator><dc:creator>\n        Tunnicliffe, David<\/dc:creator><dc:creator>\n        Roebuck, Hettie<\/dc:creator><dc:subject>\n        C800 Psychology<\/dc:subject><dc:subject>\n        C850 Cognitive Psychology<\/dc:subject><dc:subject>\n        C830 Experimental Psychology<\/dc:subject><dc:description>\n        Human studies have reported clear differences in perceptual and neural processing of faces of different species, implying the contribution of visual experience to face perception. Can these differences be manifested in our eye scanning patterns while extracting salient facial information? Here we systematically compared non-pet owners\u2019 gaze patterns while exploring human, monkey, dog and cat faces in a passive viewing task. Our analysis revealed that the faces of different species induced similar patterns of fixation distribution between left and right hemi-face, and among key local facial features with the eyes attracting the highest proportion of fixations and viewing times, followed by the nose and then the mouth. Only the proportion of fixation directed at the mouth region was species-dependent and could be differentiated at the earliest stage of face viewing. It seems that our spontaneous eye scanning patterns associated with face exploration were mainly constrained by general facial configurations; the species affiliation of the inspected faces had limited impact on gaze allocation, at least under free viewing conditions.<\/dc:description><dc:publisher>\n        Pion<\/dc:publisher><dc:date>\n        2010-04<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/2422\/1\/Perception_2010.pdf<\/dc:identifier><dc:identifier>\n          Guo, Kun and Tunnicliffe, David and Roebuck, Hettie  (2010) Human spontaneous gaze patterns in viewing of faces of different species.  Perception, 39  (4).   pp. 533-542.  ISSN 0301-0066  <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1068\/p6517<\/dc:relation><dc:relation>\n        10.1068\/p6517<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/2422\/","http:\/\/dx.doi.org\/10.1068\/p6517","10.1068\/p6517"],"year":2010,"topics":["C800 Psychology","C850 Cognitive Psychology","C830 Experimental Psychology"],"subject":["Article","PeerReviewed"],"fullText":" 1\n \nHuman spontaneous gaze patterns in viewing of faces of  \ndifferent species \n \nKun Guo, David Tunnicliffe, Hettie Roebuck \n Research Centre for Comparative Cognition, School of Psychology,  \nUniversity of Lincoln, Lincoln LN6 7TS, UK \n \n \n \n \n \n \nCorresponding Author:  \nDr. Kun Guo \nSchool of Psychology, University of Lincoln, Lincoln, LN6 7TS, UK \nEmail address: kguo@lincoln.ac.uk  \nTel: +44-1522-886294 \n \nKeywords: Gaze pattern, Fixation, Faces, Human, Species  \n 2\nAbstract \n Human studies have reported clear differences in perceptual and neural processing \nof faces of different species, implying the contribution of visual experience to face \nperception. Can these differences be manifested in our eye scanning patterns while \nextracting salient facial information? Here we systematically compared non-pet owners\u2019 \ngaze patterns while exploring human, monkey, dog and cat faces in a passive viewing \ntask. Our analysis revealed that the faces of different species induced similar patterns of \nfixation distribution between left and right hemi-face, and among key local facial features \nwith the eyes attracting the highest proportion of fixations and viewing times, followed \nby the nose and then the mouth. Only the proportion of fixation directed at the mouth \nregion was species-dependent and could be differentiated at the earliest stage of face \nviewing. It seems that our spontaneous eye scanning patterns associated with face \nexploration were mainly constrained by general facial configurations; the species \naffiliation of the inspected faces had limited impact on gaze allocation, at least under free \nviewing conditions.  \n \nIntroduction \nHuman faces are probably the most important visual stimuli in our social \nenvironment, and the processing of faces seems to involve a face-specific cognitive and \nneural mechanism (McKone et al 2006; see also Tarr and Cheng 2003). For instance, \nbehavioural and neuropsychological studies have observed detrimental recognition \nperformance for inverted faces rather than non-face objects (face inversion effect; e.g.  \nValentine 1988), and selective impairments of face and object recognition in neurological \n 3\npatients (prosopagnosia and visual agnosia) (Farah 1996; Moscovitch et al 1997). Brain \nimaging studies further suggested a distributed network of brain structures, including the \nfusiform gyrus, associated with face processing (Gobbini and Haxby 2007).  \nThis \u2018special\u2019 processing for faces seems to be species and race-sensitive, and is \nlikely associated with our extensive experience of identifying conspecific faces. \nDevelopmental studies revealed that 6-month-old infants perform equally well at \ndiscriminating individual human or monkey faces; 9-month-olds, like adults, show better \nperformance for recognizing frequently-experienced human faces (Pascalis et al 2002), \nsuggesting a perceptual narrowing process in the development of our highly efficient face \nperception. The holistic or configural processing for faces (i.e. perceiving relations \namong facial features and integrating all features into an individual representation of the \nface as a whole. The configural processing is often assessed by face inversion effect \nwhich is defined as a larger decrease in recognition performance for faces than for other \nmono-oriented objects when they are presented upside-down) is more evident with faces \nof own species or even own race than with faces of other species or other races (McKone \net al 2006; Rhodes et al 2006; Tanaka et al 2004), implying differences in the perceptual \nprocessing of faces from different species and races. Human brain imaging studies further \nrevealed brain waveform (i.e. face-specific N170 event-related potential component) \ndifferences in latency, amplitude and distribution in response to faces of humans and \nanimals (i.e. apes, dogs, cats and birds) (Bentin et al 1996; Carmel and Bentin 2002; de \nHaan et al 2002; Rousselet et al 2004), and cortical face-selective region activation \ndifferences in amplitude in response to faces of different races (Golby et al 2001), \n 4\nsuggesting that our visual experience with different face types have profound effects on \nthe neural processing of facial information. \nCould reported differences in the perceptual and neural processing of different \nface types be manifested in our gaze patterns associated with face viewing? In other \nwords, do we employ a single\/general oculomotor strategy to extract salient\/relevant \nfacial information from faces sharing similar spatial configurations (i.e. two eyes above a \nnose and a mouth)? Given the pattern of our eye movements can be modulated by \ncognitive demands and characteristics of the observed scenes (Guo et al 2006; Henderson \n2003), it is reasonable to assume that our gaze patterns would be sensitive to the species-\nspecific facial information. Here we systematically compared human participants\u2019 gaze \npatterns while free-viewing faces of humans, monkeys, dogs and cats, and observed \nsimilar viewing patterns to different face types, suggesting the dominant role of general \nfacial configuration in shaping of face-related eye scanning patterns. The species of the \ninspected faces, on the other hand, had limited impact on gaze allocation, at least in the \nadopted free-viewing tasks.  \nWhile free-viewing conspecific faces, human adults often demonstrate a natural \ngaze bias towards the left visual field, that is, the right side of the viewee\u2019s face is often \ninspected first and\/or for longer periods (Butler et al 2005; Mertens et al 1993; Philips \nand David 1997). This left gaze bias in face exploration in healthy observers is related to \nneither handedness nor eye dominance (e.g. Leonards and Scott-Samuel 2005). Although \nhuman visuospatial attention bias is to the left visual field and in some cultures, a long \npractised left-to-right directional scanning bias (most notably, reading) may contribute to \nthis gaze asymmetry (e.g. Nicholls and Roberts 2002; Vaid and Singh 1989), it is often \n 5\nargued that a right hemisphere advantage in face processing (receiving visual input from \nleft visual field) is the likely cause of this asymmetry (Burt and Perrett 1997; Butler et al. \n2005). A recent recording of human saccadic eye movements further revealed that the \ninitial gaze bias is the most evident while exploring upright faces, and is less or not \nevident while exploring inverted faces and symmetric non-face object or landscape \nimages (Leonards and Scott-Samuel 2005), suggesting this gaze asymmetry is part of \ngaze patterns associated with face exploration.  \nInterestingly, this face-related left gaze bias is not restricted to humans, but also \noccurs in non-human species such as rhesus monkeys (Macaca mulatta) and domestic \ndogs (Canis familiaris). In some animals such gaze asymmetry is even species-sensitive. \nFor instance, domestic pet dogs only demonstrate a left gaze bias towards human faces, \nbut not towards monkey or dog faces, implying a broader adaptive value of the left gaze \nbias in social species (Guo et al 2009). Given these findings, it would be interesting to \nexamine whether we have similar pattern of gaze asymmetry while viewing faces of \ndifferent species. If the left gaze bias is \u201can automatic, internally driven initiation of the \nsaccadic exploration of faces\u201d in humans (Leonards and Scott-Samuel 2005, p2679), then \nwe are likely to demonstrate the same pattern of gaze asymmetry while exploring faces \nsharing similar spatial configurations. If, on the other hand, the left gaze bias is \nassociated with processing species-sensitive facial information (Guo et al 2009), then we \ncould show different degree of gaze asymmetry while inspecting faces of different \nspecies. In this study, our participants demonstrated a constant initial left gaze bias while \nfree-viewing human, monkey, dog and cat faces, suggesting a general oculomotor \n 6\nstrategy to sample facial information across different species, at least for those sharing \nsimilar facial configurations. \n \nMaterials and methods \n28 undergraduate psychology students (8 male, 20 female), age ranging from 19 \nto 44 years old with the mean of 22\u00b15.4 (Mean\u00b1SD), volunteered to participate in the \nstudy in return for course credit. All participants had normal visual acuity and were \nchosen from non-pet owners for monkeys, dogs and cats (to avoid potential influence of \nvisual expertise effect; e.g. Tarr and Cheng 2003). Informed consent was obtained from \neach participant, and all procedures complied with the British Psychological Society \n\u201cCode of Ethics and Conduct\u201d, and with the World Medical Association Helsinki \nDeclaration as revised in October 2008. \nDigitized grey scale face images were presented through a ViSaGe graphics \nsystem (Cambridge Research Systems) and displayed on a high frequency non-interlaced \ngamma-corrected color monitor (30.0 cd\/mP2 P background luminance, 100 Hz frame rate, \nMitsubishi Diamond Pro 2070SB) with the resolution of 1024 \u00d7 768 pixels. At a viewing \ndistance of 57 cm the monitor subtended a visual angle of 40 \u00d7 30\u00b0. \nFour different categories of unfamiliar face images with closed mouth and neutral \nfacial expressions in full frontal view were used as stimuli (see examples in Fig.1): 10 \nhuman faces, 10 monkey faces, 10 dog faces and 10 cat faces. All images shared similar \nspatial facial configurations, were gamma-corrected and displayed once in a random \norder at the centre of the screen with a resolution of 600 \u00d7 600 pixels (22 \u00d7 22\u00b0). \n 7\nDuring the experiments the participants sat in a chair with their head restrained by \na chin rest, and viewed the display binocularly. To calibrate eye movement signals, a \nsmall red fixation point (FP, 0.3\u00b0 diameter, 15 cd\/mP2 P luminance) was displayed randomly \nat one of 9 positions (3 \u00d7 3 matrix) across the monitor. The distance between adjacent FP \npositions was 10\u00b0. The participant was instructed to follow the FP and maintain fixation \nfor 1 sec. After the calibration procedure, the trial was started with a FP displayed on the \ncentre of the monitor. If the participant maintained fixation for 1sec, the FP disappeared \nand an image was presented for 3 sec. During the presentation, the participant passively \nviewed the images with the instruction of \u201cviewing the faces as you normally do\u201d. No \nreinforcement was given during this procedure. It was considered that in the absence of \ninstrumental responding, our participants\u2019 viewing behaviour should be as natural as \npossible. The inter-trial interval was set to 2 sec. \nHorizontal and vertical eye positions were measured using a Video Eyetracker \nToolbox with 50 Hz sampling frequency and up to 0.25\u00b0 accuracy (Cambridge Research \nSystems). The software developed in Matlab computed horizontal and vertical eye \ndisplacement signals as a function of time to determine eye velocity and position. \nFixation locations were then extracted from the raw eye tracking data using velocity (less \nthan 0.2\u00b0 eye displacement at a velocity of less than 20\u00b0\/s) and duration (greater than 50 \nms) criteria (Guo et al 2006).  \nWhile determining fixation allocation within key internal facial features (i.e. eyes, \nnose and mouth), we adopted the criteria from Barton et al (2006) to consistently define \nboundaries between local facial features for different faces (for an example of defining \nhuman facial regions, see HTUhttp:\/\/www.perceptionweb.com\/perception\/misc\/p5547\/f3.jpgUTH). \n 8\nSpecifically, the \u2018eye\u2019 region included the eyes, eyelids and eye brows; the \u2018nose\u2019 or \n\u2018mouth\u2019 region consist of main body of the nose (glabella, nasion, \ntip-defining points, alar-sidewall and supra-alar crease) or mouth (only lips were visible \nfor closed mouths) and immediate surrounding area (up to 0.5\u00b0 visual angle). The \ndivision line between the \u2018mouth\u2019 and \u2018nose\u2019 regions was the midline between upper lip \nand the bottom of the nose. Each fixation was then characterised by its location among \nfeature regions and its time of onset relative to the start of the trial, and the number of \nfixations directed at each facial feature was normalized to the total number of fixations \nsampled in that trial. As the same facial feature across faces of different species often \nvary in size (i.e. dogs usually have larger noses than humans), the proportion of the area \nof a particular facial feature relative to the whole image was subtracted from the \nproportion of fixations directed at that facial feature in a given trial. Any difference in \nfixation distribution from zero means that this particular facial feature attracted more or \nless fixations than predicted by a uniform looking strategy (Dahl et al 2009). \n \nResults \nFaces of different species presented in the free viewing tasks attracted similar \namount of attention from our participants. One way Trepeated measures Tanalysis of \nvariance (ANOVA) showed non-significant differences in the number of fixations per \nimage across human (7.91\u00b10.3, Mean\u00b1SEM), monkey (7.52\u00b10.33), dog (8.03\u00b10.32) and \ncat faces (7.65\u00b10.26) (F(3,108)=0.59, p=0.62).  \n--- Figure 1 about here --- \nAnalysis of fixation allocation revealed that immediately following the face \npresentation, the first saccade was directed at the eye region in 87%\u00b12 of the trials \n 9\n(averaged across participants); and during the face exploration, the vast majority of \nfixations (91%\u00b11 of overall fixations) and viewing time (91%\u00b10.4 of total face viewing \ntime within a trial) were allocated at key internal facial features, such as eyes, nose and \nmouth. We then examined whether faces of different species attracted similar distribution \nof fixation and viewing time across these local facial features (Fig. 1). As the \nexperimental design comprised four levels of face types (human, monkey, dog and cat \nfaces), three levels of local features (eyes, nose and mouth) and two dependent variables \n(distribution of fixation and viewing time within faces), two two-wayT repeated measuresT \nANOVA was carried out after averaging the proportion of fixations directed at each local \nfeature (the number of fixations within each facial feature as percentage of total number \nof fixations within whole face image subtracting the proportion of the area of each facial \nfeature relative to the whole image) for each face type and each participant, and after \naveraging the proportion of viewing time directed at each local feature (cumulative \nviewing time within each facial feature as percentage of total face viewing time \nsubtracting the proportion of the area of each facial feature relative to the whole face) for \neach face type and each participant. \nOur analysis showed that qualitatively, faces of different species attracted similar \npatterns of fixation distribution (F(3,324)=0.61, p=0.61) and viewing time distribution \n(F(3,324)=0.43, p=0.73) across local facial features with the eyes attracting the highest \nproportion of fixations (51\u250059%) and viewing time (54\u250059%), followed by the nose \n(fixation 11\u250014%, viewing time 10\u250013%) and then the mouth (fixation -1\u25007%, viewing \ntime -1\u25008%) (fixation distribution across eyes, nose and mouth: F(2,324)=742, p<0.001; \nviewing time distribution across eyes, nose and mouth: F(2,324)=781, p<0.001; Fig. 1). \n 10\nHowever, the significant interaction effect between local features and face types (fixation \nF(6,324)=3.27, p=0.004; viewing time F(6,324)=2.89, p=0.01) suggested that the \nquantitative distribution of fixations and viewing time within some facial features was \nspecies-dependent. Specifically, human observers paid the same amount of attention to \nthe eyes or nose region within faces of different species (Bonferroni correction for \nmultiple comparisons, p>0.22). They also directed indistinguishable proportions of \nfixations and viewing times at the mouth region in human and monkey faces (p>0.18), \nbut significantly less fixations and viewing times at the mouth region in dog and cat faces \nin comparison with the mouth region in both human and monkey faces (p<0.001). \n--- Figure 2 about here --- \nWe further examined when this differential gaze allocation to the mouth region of \nfaces of different species happened during face exploration. Given that local image \nregions scoring high on saliency or relevancy measures are likely to be inspected earlier \nin picture viewing (e.g. Parkhurst and Niebur HT2003TH), analyzing sequential fixation \nplacement in faces could provide valuable relevancy information about individual facial \nfeatures in the face processing. In this study the probabilities of sequential fixation \nplacement in the mouth for each of the first five fixations sampled in face viewing were \ncompared across different faces types (Fig. 2). We chose to analyze the first five \nsequential fixation placements because our participants made at least 5 fixations in the \nmajority (>92%) of the trials, and the initial time window of face viewing is critical in \nface processing (Dahl et al 2009). For example, a recent study by Hsiao and Cottrell \n(2008) revealed that the first two fixations in face viewing were sufficient to achieve \noptimal face recognition performance. \n 11\nThe 4 (face type) \u00d7 5 (fixation sequence) Trepeated measuresT ANOVA revealed a \nsignificant main effect of face type (F(3,540)=44.89, p<0.001; Fig. 2A) and fixation \nsequence (F(4,540)=16.39, p<0.001), and significant interaction effect between face type \nand fixation sequence (F(12,540)=2.37, p=0.006). Specifically, for the first fixation, the \nmouth in human faces was more likely to be inspected than the mouth in dog and cat \nfaces. For the next four fixations, the mouth in both human and monkey faces had higher \nchance to be the saccade target than that in dog and cat faces (Bonferroni correction for \nmultiple comparisons, p<0.01). Given that the variance in mouth size across different \nspecies could bias our conclusion (i.e. large mouth could have higher chance to be \nsaccade destination), we performed the same analysis after normalising the probability of \nsequential fixation placement in the mouth region according to its size proportion relative \nto the whole image. For non-human faces, the probability of the mouth to be fixated was \ndivided by the ratio of its size proportion relative to the human mouth (the size of the \nhuman month was treated as 100%, Fig. 2B).  Two way ANOVA and associated \nBonferroni post-hoc tests reached similar conclusions as the prior-normalisation analysis. \nIt seemed that gaze allocation to the mouth region was species-dependent and could \ndifferentiate at the earliest stage of face viewing. \n--- Figure 3 about here --- \nTo examine whether the faces of different species could induce different pattern \nof gaze asymmetry in humans, we also compared the probability of sequential fixations \ndirected at the left and right hemi-face of each viewed face types (all fixations to left and \nright hemi-face were included, including those outside the eye, nose and mouth regions). \nCompared with the right hemi-face, the left hemi-face (from viewer\u2019s perspective) on \n 12\naverage attracted a higher probability of the first gaze direction after image presentation \n(72-78% across face types, Fig. 3A). 2 (left and right hemi-face) \u00d7 4 (face type) Trepeated \nmeasures T ANOVA revealed a significant main effect of face side (F(1,216)=175.46, \np<0.001), but non-significant main effect of face type (F(3,216)=0, p=1) and interaction \nbetween face side and face type (F(3,216)=0.78, p=0.51). For the next four fixations, the \nleft and right hemi-face had the same probabilities to be fixated regardless of species (Fig. \n3B). 4 (face type) \u00d7 5 (fixation sequence) Trepeated measuresT ANOVA of the probability \nof sequential fixation directed at the left hemi-face revealed a significant main effect of \nfixation sequence (F(4,540)=30.47, p<0.001), but non-significant main effect of face \ntype (F(3,540)=1.35, p=0.25) and interaction between face type and fixation sequence \n(F(12,540)=0.59, p=0.85). Clearly, the left gaze bias we observed here was the most \nevident for the initial fixation, but was not species-sensitive.  \nSo far our analysis has revealed that the faces of different species induced similar \npatterns of gaze distribution. Only the proportion of fixation and viewing time directed at \nthe mouth region was species-dependent and could be differentiated at the earliest stage \nof face viewing. It could be argued that the differences in gaze allocation to the mouth \nacross face categories were driven by low-level image salience (i.e. local image contrast, \nintensity and structure) rather than anything category-specific. To examine this \npossibility, we calculated the top eight salient regions within each face image using the \nmost widely used saliency model of Itti and Koch (2000), with the authors\u2019 original \nparameters and implementation (obtained from HTUhttp:\/\/ilab.usc.eduUTH). The model compares \nlocal image intensity, colour and orientation, combines them into a single saliency map \nwith a winner-take-all network and inhibition-of-return, and then produces a sequence of \n 13\npredicted fixations that scan the scene in order of decreasing saliency. We chose to \ncalculate the first eight salient regions within the image because our participants on \naverage made between 7 and 8 fixations per images in face viewing.  \nOut of 10 images per face category, no human mouth could be classified within \nthe top eight salient image regions. The mouth in two monkey faces and one dog face \nwas ranked as the third salient region within the image, and only one cat mouth was \nranked as the eighth salient image region. If our gaze allocation to the mouth was purely \ndriven by the local image salience, then the mouth in monkey faces should attract more \nfixations than the mouth in dog and cat faces. Human mouth, on the other hand, should \nnot attract any fixations at all. As can be seen in Fig. 1A, our participants\u2019 gaze \nallocations to the mouth region in viewing faces of different species were completely \ndifferent from those predicted by the saliency map. It seems that the higher proportion of \nfixations and viewing times directed at human and monkey mouths could not be fully \naccounted for by low-level local image salience. \n \nDiscussion \n Viewing of conspecific faces in humans is associated with a stereotypical pattern \nof eye movements. Among various internal and external local facial features, eyes, nose \nand mouth attract the majority of fixations with the eye region being inspected first and \nmost frequently (Althoff and Cohen 1999; Barton et al 2006; Guo et al 2003; Heisz and \nShore 2008; Stacey et al 2005). In this study we extended this finding to faces of different \nspecies, including less frequently encountered face types (i.e. monkey faces). Our overall \nviewing patterns to human, monkey, dog and cat faces were almost identical. Regardless \n 14\nof species, the eyes were often inspected first and attracted the highest proportion of \nfixations and viewing times, followed by the nose and then the mouth region. \nFurthermore, a consistent left gaze bias was associated with the initial stage of face \nexploration irrespective of face types. It seems that under free-viewing conditions we \ntend to use a general oculomotor strategy to sample facial information across different \nspecies, at least for those sharing similar facial configurations (i.e. vertical bilateral \nsymmetry of the spatial arrangement of two eyes above a nose and a mouth). In other \nwords, human-face-like visual images would trigger stereotypical eye scanning pattern \nautomatically, regardless of observer\u2019s perceptual expertise\/experience. \nRecent behavioural and neurophysiological studies suggest a species-sensitive \nface processing. The differences in perceptual and cognitive processing of different face \ntypes, however, are more quantitative rather than qualitative. For instance, although \nhuman observers perform better at differentiating human faces which involves a more \nholistic processing strategy (i.e. more evident face inversion effect for human faces than \nmonkey faces; McKone et al 2006; Mondloch et al 2006), human and monkey faces share \nvery similar facial configurations and can be categorized into the same perceptual group \nin category identification tasks (Campbell et al 1997). Furthermore, the face-specific \nN170 ERP component elicited in humans by human faces is as large and distinctive as \nthat elicited by monkey faces, only peaks up to 10 ms earlier (Carmel and Bentin 2002; \nRousselet et al. 2004). It seems that although our face perception is species-sensitive, the \nfaces from those species sharing similar facial configurations have limited influence on \nthe face processing.   \n 15\nOur quantitative comparison of gaze allocation to individual facial features also \ndemonstrated a limited influence of face types on fixation distribution. After adjusting for \nthe variance in size of local facial features across species, our analysis revealed that the \nproportion of fixations and viewing times directed at the eyes or nose region were \nindistinguishable across human, monkey, dog and cat faces. The mouth region in human \nand monkey faces, on the other hand, attracted significantly more fixations and longer \nviewing times than that in dog and cat faces. Analysis of sequential fixation placement in \nthe mouth region further revealed that such difference in gaze allocation started to \ndifferentiate at the earliest stage of face exploration, namely from the first fixation. As \ndifferent facial features could provide different types and amounts of facial information \n(i.e. the eyes contain critical information about face identity and social attention, the \nmouth is crucial for fast detection and recognition of some facial expressions) (Heisz and \nShore 2008; HTSchyns TH et al 2007), the differential gaze allocation to the mouth could reflect \na different viewing strategy\/sensitivity to sample relevant facial information from \ndifferent species. Given the relevance and importance of the human mouth in \ntransforming a range of diagnostic expression cues in our social communication, and the \nhigh similarity in spatial configuration between human and monkey faces, it is quite \npossible that during free exploration we involuntarily direct a substantial amount of \nattention to human and monkey mouths to evaluate subtle expression and emotion cues. \nOur participants (non-pet owners) did not engage similar gaze distribution in the viewing \nof dog and cat faces as they may not have interest and\/or perceptual experience in \nprocessing subtle emotion cues from dog and cat mouths.  It would be interesting to \n 16\naddress this possibility by comparing gaze patterns in the viewing of dog\/cat faces \nbetween pet owners and non-pet owners.  \nIt could be argued that the difference in the proportion of fixations directed at the \nmouth region of different face types is due to the differences in local image structural \nproperties (i.e. size, local contrast and local image structure). Although it is difficult to \ncontrol these variables in realistic face photos, our previous studies have revealed that the \nphysical properties of local facial features cannot account for normal fixation distribution \nwithin the faces. Taking the eye region as an example, for faces used in this study the eye \nregion on average only occupied 7-9% of image size, but attracted disproportionately 58-\n68% of total fixations. Changing its location or surrounding context but keeping intact \nlocal structure and contrast (i.e. by scrambling faces) would significantly reduce the \nnumber of attracted fixations (Guo et al 2003, 2007). Furthermore, local facial regions \nwith high image salience (based on the calculation of local image physical properties) are \nnot necessarily correlated with the gaze distribution in face viewing. For example, with \nrelatively high local contrasts and complex local structures (higher spatial frequency and \nfrequent variances in local orientation\/curvature), regions of human hairline are often \nregarded as the most salient facial regions by the classical saliency models such as the \none proposed by Itti and Koch (2000), but they received few, if any fixations from our \nparticipants during face exploration. Hence the gaze distribution within a face is more \nlikely dependent upon the amount of available facial information contained within each \nfacial feature, rather than constrained by their simple physical properties. \nTaken together, it seems that our spontaneous viewing pattern in face exploration \nis largely constrained by the facial configurations. But during the course of exploration, \n 17\nthe prior knowledge\/experience about certain face types could influence the detailed \ndistribution of fixations directed at the mouth region. The study of gaze pattern, therefore, \nmay help to reveal the effect of such prior knowledge or other semantic factors on \nperceptual processing of faces.  \nIt remains to be seen to what extent our findings can be generalized to different \ntask contexts. By the presentation of static face images or dynamic video recordings, \nprevious studies have suggested a modulatory role of task-based top-down guidance in \ndetermining fixation allocation in face exploration (e.g. Buchan et al 2000; Malcolm et al \n2008). For example, while judging which of the two simultaneously presented human \nfaces was similar to a prior presented face in visual appearance, identity or expression, \nparticipants made a significant shift from more scanning of upper- than lower-face in \nidentity judgements, to more scanning of lower- than upper-face in expression \njudgements. No such shift was observed in judging appearance similarity for faces \ndiffered on identity or expression, suggesting a top-down task effect on gaze behaviour \n(Malcolm et al 2008). It will be interesting to examine whether we adopt similar task-\ndependent gaze patterns while processing specific facial information from non-human \nfaces.  \n \nReference \nAlthoff RR, Cohen NJ, 1999 \u201cEye-movement-based memory effect: A reprocessing \neffect in face perception\u201d Journal of Experimental Psychology: Learning, Memory, \nand Cognition 25 997-1010 \nBarton JJS, Radcliffe N, Cherkasova MV, Edelman J, Intriligator JM, 2006 \u201cInformation \nprocessing during face recognition: the effects of familiarity, inversion, and morphing \non scanning fixations\u201d Perception 35 1089-1105 \nBentin S, Allison T, Puce A, Perez A, McCarthy G, 1996 \u201cElectrophysiological studies of \nface perception in humans\u201d Journal of Cognitive Neuroscience 8 551\u2013565 \n 18\nBuchan JN, Pare M, Munhall KG, 2000 \u201cSpatial statistics of gaze fixations during \ndynamic face processing\u201d Social Neuroscience 2 1-13 \nBurt DM, Perrett DI, 1997 \u201cPerceptual asymmetries in judgements of facial attractiveness, \nage, gender, speech and expression\u201d Neuropsychologia 35 685-693 \nButler S, Gilchrist ID, Burt DM, Perrett DI, Jones E, Harvey M, 2005 \u201cAre the perceptual \nbiases found in chimeric face processing reflected in eye-movement patterns?\u201d \nNeuropsychologia 43 52-59 \nCampbell R, Pascalis O, Coleman M, Wallace SB, Benson PJ, 1997 \u201cAre faces of \ndifferent species perceived categorically by human observers?\u201d Proceedings of the \nRoyal Society of London, Series B 264 1429-1434 \nCarmel D, Bentin S, 2002 \u201cDomain specificity versus expertise: factors influencing \ndistinct processing of faces\u201d Cognition 83 1-29 \nDahl CD, Wallraven C, B\u00fclthoff HH, Logothetis NK, 2009 \u201cHumans and macaques \nemploy similar face-processing strategies\u201d Current Biology 19 509-513  \nde Haan M, Pascalis O, Johnson M, 2002 \u201cSpecialization of neural mechanisms \nunderlying face recognition in human infants\u201d Journal of Cognitive Neuroscience 14 \n199-209 \nFarah MJ, 1996 \u201cIs face recognition \u2018special\u2019? Evidence from neuropsychology\u201d \nBehaviour Brain Research 76 181-189 \nGobbini MI, Haxby JV, 2007 \u201cNeural systems for recognition of familiar faces\u201d \nNeuropsychologia 45 32-41 \nGolby AJ, Gabrieli JDE, Chiao JY, Eberhardt JL, 2001 \u201cDifferential responses in the \nfusiform region to same-race and other-race faces\u201d Nature Neuroscience 4 845-850 \nGuo K, Robertson RG, Mahmoodi S, Tadmor Y, Young MP, 2003 \u201cHow do monkeys \nview faces? \u2013 A study of eye movements\u201d Experimental Brain Research 150 363-374 \nGuo K, Mahmoodi S, Robertson RG, Young MP, 2006 \u201cLonger fixation duration while \nviewing face images\u201d Experimental Brain Research 171 91-98 \nGuo K, 2007 \u201cInitial fixation placement in face images is driven by top-down guidance\u201d \nExperimental Brain Research 181 673-677 \nGuo K, Meints K, Hall C, Hall S, Mills D, 2009 \u201cLeft gaze bias in humans, rhesus \nmonkeys and domestic dogs\u201d Animal Cognition 12 409-418 \nHeisz JJ, Shore DI, 2008 \u201cMore efficient scanning for familiar faces\u201d Journal of Vision 8 \n1-10 \nHenderson JM, 2003 \u201cHuman gaze control during real-world scene perception\u201d Trends in \nCognitive Sciences 7 498-504 \nHsiao JH, Cottrell GW, 2008 \u201cTwo fixations suffice in face recognition\u201d Psychological \nScience 9 998-1006 \nItti L, Koch C, 2000 \u201cA saliency-based search mechanism for overt and covert shifts of \nvisual attention\u201d Vision Research 40 1489-1506 \nLeonards U, Scott-Samuel NE, 2005 \u201cIdiosyncratic initiation of saccadic face exploration \nin humans\u201d Vision Research 45 2677-2684 \nMalcolm GL, Lanyon LJ, Fugard AJB, Barton JJS, 2008 \u201cScan patterns during the \nprocessing of facial expression versus identity: An exploration of task-driven and \nstimulus-driven effects\u201d Journal of Vision 8(8):2 1-9 \nMcKone E, Kanwisher N, Duchaine BC, 2006 \u201cCan generic expertise explain special \nprocessing for faces?\u201d Trends in Cognitive Sciences 11 8-15 \n 19\nMertens I, Siegmund H, Grusser OJ, 1993 \u201cGaze motor asymmetries in the perception of \nfaces during a memory task\u201d Neuropsychologia 31 989-998 \nMondloch CJ, Maurer D, Ahola S, 2006 \u201cBecoming a face expert\u201d Psychological Science \n17 930-934 \nMoscovitch M, Winocur G, Behrmann M, 1997 \u201cWhat is special about face recognition? \nNineteen experiments on a person with visual object agnosia and dyslexia but normal \nface recognition\u201d Journal of Cognitive Neuroscience 9 555-604 \nNicholls MER, Roberts GR, 2002 \u201cCan free-viewing perceptual asymmetries be \nexplained by scanning, pre-motor or attentional biases?\u201d Cortex 38 113-136 \nParkhurst DJ, Niebur E, 2003 \u201cScene content selected by active vision\u201d Spatial Vision 16 \n125\u2013154 \nPascalis O, Tde Haan M, Nelson CA,T 2002 \u201cIs face processing species-specific during the \nfirst year of life?\u201d Science 296 1321-1323  \nPhilips ML, David AS, 1997 \u201cViewing strategies for simple and chimeric faces: An \ninvestigation of perceptual bias in normal and schizophrenic patients using visual \nscan paths\u201d Brain and Cognition 32 225-238 \nRhodes G, Hayward WG, Winkler C, 2006 \u201cExpert face coding: Configural and \ncomponent coding of own-race and other-race faces\u201d Psychonomic Bulletin & Review \n13 499-505 \nRousselet GA, Mace MJM, Fabre-Thorpe M, 2004 \u201cAnimal and human faces in natural \nscenes: how specific to human faces is the N170 ERP component?\u201d Journal of Vision \n4 13-21 \nHTSchyns PGTH, HTPetro LSTH, HTSmith MLTH, 2007 \u201cDynamics of visual information integration in \nthe brain for categorizing facial expressions\u201d Current Biology 17 1580-1585 \nTStacey PC, Walker S, Underwood JDM, 2005 \u201cFace processing and familiarity: evidence \nfrom eye-movement data\u201d British Journal of Psychology 94 407-422 \nTanaka J, Kiefer M, Bukach CM, 2004 \u201cA holistic account of the own-race effect in face \nrecognition: evidence from a cross-cultural study\u201d Cognition 93 1-9 \nTarr MJ, Cheng YD, 2003 \u201cLearning to see faces and objects\u201d Trends in Cognitive \nSciences 7 23-30 \nVaid J, Singh M, 1989 \u201cAsymmetries in the perception of facial affect: Is there an \ninfluence of reading habits?\u201d Neuropsychologia 27 1277-1287 \nValentine T, 1988 \u201cUpside-down faces: a review of the effects of inversion upon face \nrecognition\u201d British Journal of Psychology 79 471-491 \n \n 20\nFigure 1 \n \n \n \n                 \n \n-10\n10\n30\n50\n70\nPr\nop\nor\ntio\nn \nof\n \nfix\nat\nio\nns\n (%\n)\nHuman\nMonkey\nDog\nCat\nEyes Mouth   Nose\nA\n \n-10\n10\n30\n50\n70\nPr\nop\nor\ntio\nn \nof\n \nvi\new\nin\ng \ntim\ne \n(%\n)\nEyes Mouth   Nose\nB\n \n \n \n  \n \n \nFigure 1, (A) Number of fixations directed at eyes, nose and mouth regions as percentage \nof total number of fixations within whole face image of different species (human, \nmonkey, dog and cat faces). (B) Cumulative viewing time directed at eyes, nose and \nmouth regions as percentage of total face viewing time. The proportion of the area of \neach facial region relative to the whole image was subtracted from the proportion of the \nfixations directed at each corresponding facial part. Any difference in fixation \ndistribution from zero means that this particular facial region was inspected more or less \nthan predicted by a uniform looking strategy. Errors bars indicate standard error of mean.  \n \n \n 21\nFigure 2 \n \n \n \n \n \n \n \n \n \n \n \n  A                  Original data       B             Normalized data  \n0\n10\n20\n30\n1 2 3 4 5\nFixation sequence\nPr\nob\nab\nili\nty\n o\nf m\nou\nth\n \nto\n b\ne \nfix\nat\ned\n (%\n) Human Monkey\nDog Cat\n \n0\n10\n20\n30\n1 2 3 4 5\nFixation sequence\n \n \n  \n \n \nFigure 2, (A) The probability of the mouth region as the destination of first five fixations \nwhile free-viewing faces of different species. (B) Normalised probability of sequential \nfixation placement in the mouth region according to its size proportion relative to the \nwhole image. For non-human faces, the probability of the mouth to be fixated was \ndivided by the ratio of its size proportion relative to human mouth (the size of human \nmonth was treated as 100%). Errors bars indicate standard error of mean. \n \n 22\nFigure 3 \n \n \n \n \n \n \n \n \n \n \n0\n25\n50\n75\n100\nPr\nob\nab\nili\nty\n o\nf f\nir\nst\n \n fi\nxa\ntio\nns\n (%\n)\nleft hemiface\nright hemifaceA\n0\n25\n50\n75\n100\n0 1 2 3 4 5\nFixation sequence\nP\nro\nba\nbi\nlit\ny \nof\n le\nft \nhe\nm\nifa\nce\n to\n b\ne \nfix\nat\ned\n (%\n)\nHuman Monkey\nDog Cat\nB\n \n \n \n \n \nFigure 3, (A) The probability of initial fixation directed at left and right side of presented \nfaces. Errors bars indicate standard error of mean. (B) The probability of sequential \nfixation directed at the left side of presented faces of different species. \n"}
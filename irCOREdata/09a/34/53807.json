{"doi":"10.1016\/j.cageo.2010.03.016","coreId":"53807","oai":"oai:nora.nerc.ac.uk:12867","identifiers":["oai:nora.nerc.ac.uk:12867","10.1016\/j.cageo.2010.03.016"],"title":"Fast computation of optimized electrode arrays for 2D resistivity surveys","authors":["Loke, M.H.","Wilkinson, P.","Chambers, J."],"enrichments":{"references":[{"id":872542,"title":"Signal contribution sections and their use in resistivity studies.","authors":[],"date":"1979","doi":null,"raw":null,"cites":null},{"id":872861,"title":"Depth of investigation of collinear symmetrical four-electrode arrays.","authors":[],"date":"1989","doi":null,"raw":null,"cites":null},{"id":873005,"title":"2-D resistivity surveying for hydrocarbons \u2013 A primer.","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":873540,"title":"York solid and drift (Sheet 63). 1:50 000. British Geological Survey,","authors":[],"date":"1983","doi":null,"raw":null,"cites":null},{"id":873986,"title":"Parallel Programming in OpenMP.","authors":[],"date":"2001","doi":null,"raw":null,"cites":null},{"id":874464,"title":"2D resistivity surveying for environmental and engineering applications.","authors":[],"date":"1996","doi":null,"raw":null,"cites":null},{"id":874929,"title":"Short note on electrode charge-up effects in DC resistivity data acquisition using multi-electrode arrays.","authors":[],"date":"2000","doi":null,"raw":null,"cites":null},{"id":875174,"title":"A numerical comparison of 2-D resistivity imaging with 10 electrode arrays.","authors":[],"date":"2004","doi":null,"raw":null,"cites":null},{"id":875617,"title":"Applying petrophysical models to radar travel time and electrical resistivity tomograms: Resolution-dependent limitations.","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":876057,"title":"Occam's inversion to generate smooth, two-dimensional models from magnetotelluric data.","authors":[],"date":"1990","doi":null,"raw":null,"cites":null},{"id":876473,"title":"A modified pseudosection for resistivity and induced-polarization.","authors":[],"date":"1977","doi":null,"raw":null,"cites":null},{"id":877010,"title":"Applied geophysical inversion.","authors":[],"date":"1994","doi":null,"raw":null,"cites":null},{"id":877427,"title":"Nonlinear inversion using general measures of data misfit and model structure.","authors":[],"date":"1998","doi":null,"raw":null,"cites":null},{"id":877910,"title":"Matrix computations (Third Edition).","authors":[],"date":"1996","doi":null,"raw":null,"cites":null},{"id":878415,"title":"32\/64-bit 80x86 assembly language architecture.","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":878451,"title":"A comparison of the Gauss-Newton and quasi-Newton methods in resistivity imaging inversion.","authors":[],"date":"2002","doi":null,"raw":null,"cites":null},{"id":878834,"title":"A comparison of smooth and blocky inversion methods in 2D electrical imaging surveys.","authors":[],"date":"2003","doi":null,"raw":null,"cites":null},{"id":879316,"title":"Geophysical data analysis: Discrete inverse theory (Revised Edition).","authors":[],"date":"1989","doi":null,"raw":null,"cites":null},{"id":879746,"title":"Injection electrode overprinting.","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":880207,"title":"Resolution analysis of geophysical images: Comparison between point spread function and region of influence measures.","authors":[],"date":"2007","doi":null,"raw":null,"cites":null},{"id":880681,"title":"Automated Monitoring of Coastal Aquifers with Electrical Resistivity Tomography.","authors":[],"date":"2009","doi":null,"raw":null,"cites":null},{"id":881163,"title":"Examples of resistivity imaging using ME-100 resistivity field acquisition system. In:","authors":[],"date":"1996","doi":null,"raw":null,"cites":null},{"id":881599,"title":"Lithostratigraphical nomenclature of the Lias Group in the Yorkshire basin.","authors":[],"date":"1984","doi":null,"raw":null,"cites":null},{"id":882426,"title":"Numerical Recipes in C (Second Edition).","authors":[],"date":"1992","doi":null,"raw":null,"cites":null},{"id":882855,"title":"Jurassic of the Cleveland Basin,","authors":[],"date":"1995","doi":null,"raw":null,"cites":null},{"id":883333,"title":"Aquifer characterization in the Blue Ridge Physiographic Province using resistivity profiling and borehole geophysics.","authors":[],"date":"2000","doi":null,"raw":null,"cites":null},{"id":883791,"title":"Experimental design: Electrical resistivity data sets that provide optimum subsurface information.","authors":[],"date":"2004","doi":null,"raw":null,"cites":null},{"id":884220,"title":"Improved strategies for the automatic selection of optimized sets of electrical resistivity tomography measurement configurations.","authors":[],"date":"2006","doi":null,"raw":null,"cites":null},{"id":884668,"title":"Comparison of the spatial resolution of standard and optimised electrical resistivity tomography arrays. In:","authors":[],"date":"2006","doi":null,"raw":null,"cites":null},{"id":885170,"title":"Archaeological investigations by electrical resistivity tomography: a preliminary study.","authors":[],"date":"1991","doi":null,"raw":null,"cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-11","abstract":"Four different methods to automatically select an optimal set of array configurations that gives the maximum subsurface resolution with a limited number of measurements for 2D electrical imaging surveys were tested. The first (CR) method directly calculates the change in the model resolution for each new array added to the base data set, and uses this to select array configurations that gave the maximum model resolution. However this method is the slowest. The algorithm used by the CR method for calculating rank-one updates was optimized to reduce computational time by a factor of eighty. The sequence of calculations was modified to reduce the traffic between the computer main memory and the CPU registers. Further code optimizations were made to take advantage of the parallel processing capabilities of modern CPUs. The second (ETH) and third (BGS) methods use approximations based on the sensitivity values to estimate the change in the model resolution matrix. The ETH and BGS methods, respectively, use the first and second power of the sensitivity values to calculate approximations of the model resolution. Both methods are about an order of magnitude faster than the CR method. The results obtained by the BGS method are significantly better than the ETH method, and it approaches that of the CR method. The fourth method (BGS\u2013CR) uses a combination of the BGS and CR methods. It produces results that are almost identical to the CR method but is several times faster. The different methods were tested using data from synthetic models and field surveys. The models obtained from the inversion of the data sets generated by the four different methods confirm that the models generated by the CR method have the best resolution, followed by the BGS\u2013CR, BGS and ETH methods.\\ud\n\\u","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/53807.pdf","fullTextIdentifier":"http:\/\/nora.nerc.ac.uk\/12867\/1\/FastOpt.pdf","pdfHashValue":"bbca41173bf4f37ee00c6861ac8694154765f005","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:nora.nerc.ac.uk:12867<\/identifier><datestamp>\n      2012-11-22T12:17:06Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D5338<\/setSpec><setSpec>\n      7375626A656374733D533234<\/setSpec><setSpec>\n      7375626A656374733D533130<\/setSpec><setSpec>\n      7375626A656374733D533231<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/12867\/<\/dc:relation><dc:title>\n        Fast computation of optimized electrode arrays for 2D resistivity surveys<\/dc:title><dc:creator>\n        Loke, M.H.<\/dc:creator><dc:creator>\n        Wilkinson, P.<\/dc:creator><dc:creator>\n        Chambers, J.<\/dc:creator><dc:subject>\n        Computer Science<\/dc:subject><dc:subject>\n        Physics<\/dc:subject><dc:subject>\n        Earth Sciences<\/dc:subject><dc:subject>\n        Mathematics<\/dc:subject><dc:description>\n        Four different methods to automatically select an optimal set of array configurations that gives the maximum subsurface resolution with a limited number of measurements for 2D electrical imaging surveys were tested. The first (CR) method directly calculates the change in the model resolution for each new array added to the base data set, and uses this to select array configurations that gave the maximum model resolution. However this method is the slowest. The algorithm used by the CR method for calculating rank-one updates was optimized to reduce computational time by a factor of eighty. The sequence of calculations was modified to reduce the traffic between the computer main memory and the CPU registers. Further code optimizations were made to take advantage of the parallel processing capabilities of modern CPUs. The second (ETH) and third (BGS) methods use approximations based on the sensitivity values to estimate the change in the model resolution matrix. The ETH and BGS methods, respectively, use the first and second power of the sensitivity values to calculate approximations of the model resolution. Both methods are about an order of magnitude faster than the CR method. The results obtained by the BGS method are significantly better than the ETH method, and it approaches that of the CR method. The fourth method (BGS\u2013CR) uses a combination of the BGS and CR methods. It produces results that are almost identical to the CR method but is several times faster. The different methods were tested using data from synthetic models and field surveys. The models obtained from the inversion of the data sets generated by the four different methods confirm that the models generated by the CR method have the best resolution, followed by the BGS\u2013CR, BGS and ETH methods.\\ud\n\\ud\n<\/dc:description><dc:publisher>\n        Elsevier<\/dc:publisher><dc:date>\n        2010-11<\/dc:date><dc:type>\n        Publication - Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/12867\/1\/FastOpt.pdf<\/dc:identifier><dc:identifier>\n         \n\n  Loke, M.H.; Wilkinson, P.; Chambers, J..  2010  Fast computation of optimized electrode arrays for 2D resistivity surveys.   Computers and Geosciences, 36 (11). 1414-1426.  https:\/\/doi.org\/10.1016\/j.cageo.2010.03.016 <https:\/\/doi.org\/10.1016\/j.cageo.2010.03.016>     \n <\/dc:identifier><dc:relation>\n        http:\/\/www.sciencedirect.com\/science\/journal\/00983004<\/dc:relation><dc:relation>\n        10.1016\/j.cageo.2010.03.016<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/nora.nerc.ac.uk\/id\/eprint\/12867\/","http:\/\/www.sciencedirect.com\/science\/journal\/00983004","10.1016\/j.cageo.2010.03.016"],"year":2010,"topics":["Computer Science","Physics","Earth Sciences","Mathematics"],"subject":["Publication - Article","PeerReviewed"],"fullText":" 1 \nFast computation of optimized electrode arrays for 2D resistivity surveys \nM.H.Loke1,  P. Wilkinson2,  J. Chambers2 \n1 Geotomo Software, 115 Cangkat Minden Jalan 5, Minden Heights, 11700 Gelugor, Penang, Malaysia. \nemail : drmhloke@yahoo.com, Tel : +60 4 6574525, Fax : +60 4 6588437. Corresponding author. \n2 British Geological Survey, Kingsley Dunham Centre, Keyworth, Nottingham, United Kingdom              \nNG12 5GG. email : pbw@bgs.ac.uk, jecha@bgs.ac.uk \n \nAbstract \nFour different methods to automatically select an optimal set of array configurations that gives the \nmaximum resolution of the subsurface with a limited number of measurements for 2D electrical imaging \nsurveys were tested. The first method (CR method) directly calculates the change in the model \nresolution for each new array added to the base data set, and uses this to select array configurations that \ngave the maximum model resolution. However this method is the slowest. The computer code for \ncalculating the rank one updates used by the CR method was optimized to reduce the computer time by \nabout eighty times. The sequence of calculations needed was modified to reduce the traffic between the \ncomputer main memory and the CPU registers. Further code optimizations were made to take advantage \nof the parallel processing capabilities of modern CPUs. The second (ETH) and third (BGS) methods use \napproximations based on the sensitivity values to estimate the change in the model resolution matrix. \nThe ETH and BGS methods respectively use the first and second power of the sensitivity values to \ncalculate an approximation of the model resolution. Both methods are about an order of magnitude faster \nthan the CR method. The results obtained by the BGS method are significantly better than the ETH \nmethod, and it approaches that of the CR method. The fourth method (BGS-CR) uses a combination of \nthe BGS and CR methods. It produces results that are almost identical to the CR method but it is several \ntimes faster. The different methods were tested using data from synthetic models and field surveys. The \n 2 \nmodels obtained from the inversion of the data sets generated by the four different methods confirm that \nthe models generated by the CR method have the best resolution, followed by the BGS-CR, BGS and \nETH methods.  \n \nKeywords :  resistivity; 2D; array; optimization; model; resolution \n 3 \nINTRODUCTION \n Over the last decade the resistivity method has undergone a renaissance with the development of \nmultielectrode resistivity-meter systems and efficient 2D and 3D inversion schemes. Electrical imaging \n(or tomography) surveys are now widely used in diverse engineering and environmental problems, \nhydrological, agricultural, mineral and even hydrocarbon exploration (Dahlin, 1996; Seaton and Burbey, \n2000; Bauman, 2005). Most surveys have been carried out using the traditional arrays such as the \nWenner, Schlumberger, pole-pole, dipole-dipole and pole-dipole arrays. The general characteristics in \nterms of resolution, depth of investigation and noise sensitivity of these arrays are relatively well known \n(Barker, 1979, 1989; Dahlin and Zhou, 2004). In general, the Wenner and Schlumberger arrays are less \nsensitive to noise and have better resolution for horizontal structures. The dipole-dipole and pole-dipole \narrays have lower signal-to-noise ratios and have better resolution for vertical structures. However, in \nmany survey areas, good resolution in both directions is required. Modern computer-controlled multi-\nelectrode systems can measure thousands of readings. The survey time, and thus the expense, is affected \nby the number of measurements required to meet the survey objective. Ideally, the array configurations \nused should maximize the resolution of the inversion model obtained from the field survey using a \nlimited number of measurements. An important development was made by Stummer et al. (2004) who \nproposed a fast and accurate method to automatically select the arrays that would maximize the model \nresolution. This approach used the sensitivity distribution to provide an approximation to the model \nresolution matrix. This was further improved by Wilkinson et al. (2006a) who proposed two new \nmethods to improve the quality of the optimized array configurations. One method directly recalculates \nthe model resolution (the \u2018Compare R\u2019 method) for each new array and produces array sets with the \nmaximum model resolution. However, the computer time required by this method was about two orders \nof magnitude longer that the other methods (about 6 hours on a 3Ghz PC for a survey line with 30 \nelectrodes). The second method (the \u2018Modified GF\u2019 method) used a modified estimate of the change in \n 4 \nthe model resolution for a new array. It was able to generate arrays sets that have higher model \nresolution than the original method by Stummer et al. (2004) while taking less computer time (about 3.9 \nminutes on the same computer). \n As the \u2018Compare R\u201d proved to be the optimal technique, and the standard to which other \nmethods are compared, efforts were made in this research to reduce the computer time required so that it \ncan be used for larger problems. A modification to the method proposed by Stummer et al. (2004) was \nalso made to reduce the computer time it requires. Finally, a combination of the \u2018Modified GF\u2019 and \n\u2018Compare R\u2019 methods to combine the best features of both techniques was investigated. \n The following section gives a brief review of the linearized least-squares inversion method and \nits relationship to the model resolution matrix. This is followed by a description of the four different \nmethods to automatically generate the optimized arrays, and a comparison of the results. Finally, we test \nthe optimized arrays with synthetic and field data sets. \n \nTHEORY \n In the 2D resistivity method, a large number of measurements are made using different electrode \nconfigurations in order to map the subsurface resistivity at different depths below the survey line. We \nthen attempt to determine the true resistivity of the subsurface from the apparent resistivity \nmeasurements. One method that is widely used is the linearized least-squares optimization method \n(deGroot-Hedlin and Constable, 1990; Ellis and Oldenburg, 1994) where the relationship between the \nmeasured data and model parameters is given by the following equation. \n( ) 1iTiT rCgG\u2206rCGG \u2212\u2212=+ ,        (1) \nThe Jacobian matrix G contains the logarithmic sensitivities of the measurements with respect to the \nmodel parameters. The matrix C contains the damping factors, roughness filters and other constraints, \nwhile g is the data misfit vector containing the difference between the logarithms of the measured and \n 5 \ncalculated apparent resistivity values. ri-1 is the model parameter vector (the logarithm of the model \nresistivity values) for the previous iteration, while is \u2206ri is change in the model parameters. Using linear \napproximations, it can be shown an estimate of the model resolution matrix (Menke, 1984) is given by \n( ) GGCGGR TT 1\u2212+= .         (2) \n The model resolution matrix may be viewed as a filter through which the inversion method \nattempts to resolve the subsurface resistivity (Day-Lewis et al., 2005). In the ideal case with perfect \nresolution, the elements of the main diagonal (Rjj) are 1 while the off-diagonal elements are 0. In \npractical cases, the leading diagonal elements are between 0 and 1. The array optimization methods \nattempt to select the array configurations that maximize the values of the leading diagonal elements of \nthe resolution matrix. We use the approach by Wilkinson et al. (2006a) in calculating the sensitivity \nvalues of a homogeneous model for the Jacobian matrix G, and a simple Marquardt-Levenberg \nconstraint for the C matrix (i.e. C=\u03bbI where \u03bb is a damping factor and I is the identity matrix). \n For a system with N electrodes, there are N(N-1)(N-2)(N-3)\/8 independent four-electrode \nconfigurations (Xu and Noel, 1991). This gives a total of 82215 possible configurations for a system \nwith 30 electrodes. To reduce the number of possible arrays, Stummer et al. (2004) excluded \nconfigurations that are likely to reduce the stability of the inversion. These include configurations of the \nGamma type with crossed current and potential electrodes (Figure 1), and configurations with large \ngeometric factors.  \n Carpenter and Habberjam (1956) showed that there are three possible arrangements for an \nelectrode configuration with four electrodes (Figure 1). The three arrangements are the Alpha (with the \npotential electrodes nested between the current electrodes), Beta (with separate current and potential \ndipoles) and the Gamma (with interleaved current and potential electrodes). They also showed that the \nresistance value measured by the Gamma configuration is equals to the difference of resistances \nmeasured with the Alpha and Beta configurations. Thus, in theory, the Gamma configuration is not an \n 6 \nindependent arrangement as it can be derived from the Alpha and Beta measurements. This further \njustifies the decision by Stummer et al. (2004) and Wilkinson et al. (2006a) in excluding the Gamma \nconfigurations from the arrays considered in their optimization schemes. \nFigure 1 here. \n All configurations with geometric factors larger than that for a dipole-dipole array where the \nmaximum dipole separation is greater than six times the current\/potential dipole length (i.e. with an \u2018a\u2018 \nspacing of 1 and \u2018n\u2018 level of 6) are also excluded. In some field surveys, particularly those using large \nelectrode spacings, it might be necessary reduce the maximum \u2018n\u2019 value to reduce the random noise in \nthe measurements. However, for the following tests, a maximum value of 6 was used for the \u2018n\u2019 factor. \nThe choice of this maximum geometric factor was to be consistent with earlier tests by Stummer et al. \n(2004) and Wilkinson et al. (2006a) so that the results from this paper can be directly compared. \nHowever, a larger value for the maximum geometric factor can be used in situations with sufficiently \nlow noise levels so as to include more possible array configurations. This was done in generating the \narrays configurations in the field test that is described in a later part of this paper. \n The configurations left after excluding the less stable configurations are called the \n'comprehensive' data set. The 'comprehensive' data set for a survey line with 30 electrodes has 51283 \nunique configurations (compared to 82215 in the original set). The optimization task is to select a subset \nof the comprehensive set that will maximize the model resolution subject to practical constraints (such \nas the maximum number of measurements that can be made within the available survey time). We \nfollow the approach by Wilkinson et al. (2006a) and Stummer et al. (2004) in using a local optimization \nprocedure. Initially, a small starting base data set is selected. This normally consists of the dipole-dipole \nconfigurations with an \u2018a\u2018 spacing of 1 and \u2018n\u2018 levels of 1 to 6. The change in the model resolution \nmatrix R (or some estimate of the change) for each new configuration added to the base data set is then \ncalculated. The configurations that result in the largest increase in the model resolution, and have a \n 7 \nsuitable degree of orthogonality to the existing configurations, are then added to the base data set. Three \ndifferent methods to calculate or estimate the change in the model resolution were reviewed by \nWilkinson et al. (2006a).  \n \nMETHODS OF ARRAYS SELECTION \nMethod 1 \u2013 Compare R (CR) \n This method directly recalculates the model resolution matrix when a single array configuration \nis added to the existing base data set. The Sherman-Morrison Rank-1 update is used to calculate the \nmain diagonal elements of the model resolution matrix of the base set plus the test configuration \n(Wilkinson et al., 2006a). To simplify the following discussion, we rewrite equation (2) in the following \nform. \nbbb ABR = ,           (3) \nwhere  Rb is the model resolution matrix of the base data set, GGA T= and  ( ) 1\u2212+= CGGB T . \nThe following set of updating formulae (Press et al., 1992) is used to calculate the change in R when a \nnew array configuration is added to the base data set. \n \nT\nb1b ggAA +=+  \n\u00b5+\n\u2212=+ 1\nT\nb1b\nzzBB           (4) \n1b1b1b ABR +++ =  \ng is the vector containing logarithmic sensitivity values of the test configuration, z=Bbg and \u00b5 = g.z. \nRb+1 is the resolution of the base data set plus the test configuration (Wilkinson et al., 2006a). The \nfollowing function, FCR, is used the rank the improvement in the model resolution due to the addition of \nthe test configuration. It is given by \n 8 \n\u2211\n=\n+\n=\nm\nj b\nbCR\njjR\njjR\nm\nF\n1\n1\n),(\n),(1\n         (5) \nwhere m is the number of model cells, and only the main diagonal elements of the R matrix are used. \nThis method was found to give the best results (in terms of improvement in the model resolution) but \nwas about two orders of magnitude slower than the other methods. Wilkinson et al. (2006a) reported a \ncalculation time of 6 hours for a survey system with 30 electrodes on a 3GHz desktop PC. Thus in this \nresearch efforts were made to optimize the calculations so as to reduce the computer time. \n The updating method given in equation (4) consists of three main steps; (i) update the Ab matrix \nand store the values in a temporary matrix for Ab+1, (i) update the Bb matrix and store the values in a \ntemporary matrix for Bb+1, and finally (iii) multiply the two temporary matrices Ab+1 and Bb+1. The first \nstep in reducing the computer time is to write the updated resolution matrix explicitly in a single \nequation as follows. \n ,bb1b \u2206RRR +=+  where \nT\nT\nT\nbb\nT\nb gg\nzzggBAzz\u2206R\n\u00b5\u00b5 +\n\u2212+\n+\n\u2212=\n11\n   (6) \n Note this scheme calculates the change in the resolution matrix (\u2206Rb), rather than directly \nrecalculate the updated resolution matrix Rb+1 itself as in equation (4). The change in the resolution \nvalues (in \u2206Rb) can be several orders of magnitude smaller than resolution value itself (in Rb+1). Thus \nequation (6) is less sensitive to round-off errors compared to the direct use of equation (4). The main \ndiagonal elements of the updated resolution matrix Rb+1 are calculated one by one, thus avoiding the use \nthe temporary matrices Ab+1 and Bb+1. This not only reduces the computer memory required, but also the \ncomputer time. This new scheme avoids the need to store (and later retrieve) the elements of the \ntemporary matrices. The floating point computational units in modern CPUs are so efficient that the time \ntaken to transfer data values between the CPU registers and the slower main memory can be greater than \nthe time required for the floating point multiplications and additions.  \n 9 \n The bulk of the numerical calculations involve matrix-vector multiplications of the form z=Bbg \nand y=Abz (for the first term on the left hand side of the \u2206Rb equation). In the computer program \nimplementation, the values of the z vector are initially calculated. The computer code was optimized so \nthat most of the time-consuming calculations can be carried out \u2018in situ\u2019 within the CPU floating point \nregisters. The traffic between the CPU and main memory is thus reduced to a minimum. The time \ncritical parts of code were written in assembly language so that the use of the available floating point \nCPU registers can be directly optimized (Leiterman, 2005). Each SIMD (single-instruction-multiple-\ndata) register within the CPU can store two double precision values (Gerber, 2002). The SIMD \ninstructions that can carry out two double-precision operations with a single instruction are used.  This \nallows the calculations of the elements of the z vectors for two new test configurations (each with its \nown g Jacobian vector) to be carried out simultaneously. Thus it is only necessary to move the elements \nof the Bb matrix from the computer memory to the CPU register once for two new test configurations. \nThe Intel Penryn CPU has four cores that can calculate the z vectors for four pairs of the test \nconfigurations in parallel (Chandra et al., 2001). Thus in total the calculation for eight test \nconfigurations can be made with a single transfer of the elements of the B matrix from the computer \nmemory to the CPU. A similar computer code optimization is made to reduce the calculation time for \nthe y (i.e. the Abz product) vector. The computer time required for the remaining calculations in \nequation (6) that involve vector-vector multiplications is much less than that required by the matrix-\nvector multiplications. On a 2.4 GHz Intel Penryn Quad-Core system, the computational time required \nfor a survey system with 30 electrodes was reduced to less than 5 minutes (257 seconds). This makes it \npractical to use the \u2018Compare R\u2019 method for larger survey problems. \n After calculating the ranking function in equation (5) for all the test configurations, we follow \nthe procedure used by Wilkinson et al. (2006a). Briefly, the test configuration with the highest ranking \nfunction value (denoted by the sensitivity vector g1) is added to the base set at each iteration. The next \n 10\nhighest ranked configuration, represented by g2, is only added if it had a sufficient degree of \northogonality to the first configuration added. This is done by calculating | g1. g2|\/(| g1|| g2|) and checking \nthat it is less than a specified limit (0.97). This is repeated until a sufficient number of configurations are \nadded to the base data set. Each new configuration is tested against those that had been previously added \nduring that iteration only. For each iteration, the number of new configurations added is set at 0.09nb, \nwhere nb is the number in the base set. After adding the new configurations, the model resolution of the \nnew augmented base set is recalculated using equation (2). In the following discussion, this method will \nbe referred to as the CR method. \n One minor modification was made in the addition of new arrays. A check was included to ensure \nthat the distribution of the data points in the pseudosection is symmetrical, and consequently the \ncorresponding model resolution section pattern would also be symmetrical. As an example, a survey \nwith 30 electrodes will have electrode positions numbered 1, 2, 3, 4, 5, . . . 29, 30. If an array \nconfiguration (C1-C2-P1-P2) such as 2-1-4-6 is selected, the corresponding array configuration on the \nother half of the survey line (which is 24-26-29-30) is also selected for the optimized data set. During \nsome iterations, this might result in the number of arrays selected to be one more than that would have \nbeen obtained without this check. \n \nMethod 2 \u2013 Modified GF  (BGS) \n This method was proposed by Wilkinson et al. (2006a) as an improved version of the original \nmethod by Stummer et al. (2004). The ranking function used is as follows. \n ( )\n( )\n( )\n2\/1\n1\n2\n2\n1\n\uf8f7\n\uf8f7\n\uf8f8\n\uf8f6\n\uf8ec\n\uf8ec\n\uf8ed\n\uf8eb\n\u2212=\n\u2211\n=\njR\njR\nG\nG\nF\nc\nb\nm\nj sumj\nijBGS\ni         (7) \nwhere \n\u2211\n=\n=\ncn\nk\nkj\nc\nsum\nj G\nn\nG\n1\n1\n \n 11\nnc is the number of arrays in the comprehensive data set and sumjG  is the sum of the absolute sensitivities \nfor the jth model cell for all configurations in the comprehensive set. Rb and Rc are the model resolutions \nfor base and comprehensive data sets. The bracketed term involving Rb and Rc selects configurations that \nimprove regions of the model that are poorly resolved by the base set. This equation provides a \nnormalization factor to ensure the ranking function has equal weight in improving the resolution of all \nregions regardless of the relative sensitivity.  The same method, as that described earlier for the CR \nmethod is used to test the configurations, and to add the new configurations to the base set. Following \nWilkinson et al. (2006a), we also use a limit of 0.95 for the upper limit of the orthogonality value for the \ntest configurations to be added to the base set. Some effort was made to optimize the computer code for \nthis method, mainly in utilising the parallel processing capabilities of the computer system. For the test \nproblem with 30 electrodes, this method took less than a minute (48 seconds) for 40 iterations. In the \nfollowing discussion, this method will be labelled as the BGS method. \n \nMethod 3 \u2013 Combined Modified GF and Compare R (BGS-CR) \n The CR method produced array configurations with the highest model resolution, while the BGS \nmethod is much faster but produced slightly lower model resolution values (Wilkinson et al., 2006a). \nOne possible method to combine the best features of both methods is to start the search for the optimal \nconfigurations using the BGS method and end it with a few iterations of the CR method. In this way, \nsome of the deficiencies of the BGS method can be compensated for by the CR method. The CR method \nis normally used for the final 20% of the iterations in this proposed combined method. As an example, if \nthe search process takes 40 iterations, the BGS method is used for the initial 32 iterations while the CR \nmethod is used for the final 8 iterations. For the test problem with 30 electrodes, this combined method \ntook 87 seconds (compared to 48 and 257 seconds respectively for the BGS and CR methods). \n \n 12\nMethod 4 \u2013 Original GF (ETH) \n The \u2018Original GF\u2019 method by Stummer et al. (2004) used the following ranking function. \n \n( )\n( )\u2211\n=\n\uf8f7\n\uf8f7\n\uf8f8\n\uf8f6\n\uf8ec\n\uf8ec\n\uf8ed\n\uf8eb\n\u2212=\nm\nj c\nb\nsum\nj\nijETH\ni jR\njR\nG\nG\nF\n1\n1          (8) \nIn the original implementation by Stummer et al. (2004), the orthogonality check is performed against \nthe entire base data set. Wilkinson et al. (2006a) found this criterion to be too restrictive as it discards \nmany more add-on configurations than the less severe criteria used in the CR and BGS methods \ndescribed earlier. Another disadvantage is that the calculation time is significantly longer compared to \nthe BGS method as the orthogonality check is made against the entire base set in addition to the \nconfigurations added during that iteration. Wilkinson et al. (2006a) found that the \u2018Original GF\u2019 method \ntook nearly twice as long as the \u2018Modified GF\u2019 (BGS) method. In an attempt to improve on this method, \nwe use the same formula for the ranking function, but with the more limited orthogonality check used by \nthe CR and BGS methods. We call this modification of the \u2018Original GF\u2019 method the \u2018ETH\u2019 method. \nThe time taken by this method is almost the same as that taken by the BGS method. The difference in \nthe model resolution values obtained by the \u2018Original GF\u2019 method and its modified version (ETH) is less \nthan 3% for all iterations in several tests that we have carried out. \n It is interesting to compare the ranking functions used by the BGS and ETH methods in \nequations (7) and (8). The BGS method uses the square of the ratio of the sensitivity value of the \nconfiguration tested to the normalized total sensitivity value for the same model cell (in the first term to \nthe left of the summation sign) multiplied by the square root of the ( )( )\uf8f7\uf8f7\n\uf8f8\n\uf8f6\n\uf8ec\n\uf8ec\n\uf8ed\n\uf8eb\n\u2212 jR\njR\nc\nb1  factor. In comparison, \nthe ETH method used the first power of the ratio of the sensitivity values multiplied by the first power of \nthe ( )( )\uf8f7\uf8f7\n\uf8f8\n\uf8f6\n\uf8ec\n\uf8ec\n\uf8ed\n\uf8eb\n\u2212 jR\njR\nc\nb1  factor. On the basis of numerical experiments, Wilkinson et al. (2006a) found that the \n 13\nBGS method tends to select configurations that simultaneously improve the resolution whilst \nmaintaining the orthogonality of the optimized arrays. A detailed analysis of the differences between the \ntwo methods is given in Wilkinson et al. (2006a). \n \nRESULTS \nRelative resolution tests \n The first test uses a 2.5D model similar to that used by Wilkinson et al. (2006a). Briefly, the \nsurvey line has 30 electrodes with a 1 meter spacing. The subsurface model has 16 layers starting with a \nthickness of 0.3 meter, and the thickness of each subsequent layer was increased by 10%. This results in \na model with 464 model cells. All arrays with the Gamma configurations, and geometric factors greater \nthan that for a dipole-dipole arrays with \u2018a' spacing of 1 meter and \u2018n' level of 6 were discarded. This left \na comprehensive data set with 51283 unique configurations. This is marginally less than nc=51373 used \nby Wilkinson et al. (2006a) who used a geometric factor of 1100 m (for a spacing of 1 meter) as the cut-\noff value, which is slightly more than the geometric factor of 1056 m for a dipole-dipole array with a=1 \nand n=6. We also use the same damping factor value of \u03bb=2.5 x 10-6 as that used by Wilkinson et al. \n(2006a). \n Forty iterations of each method are implemented giving a total of 4618 configurations. We show \nthe output of the different methods in terms of the relative model resolution, \nc\nb\nr R\nR\nR = . This is the model \nresolution of the optimized data set divided by the resolution of the comprehensive data set. The value of \nRr lies between 0 and 1. Figure 2 shows a plot of the average relative model resolution, \n( )\n\u2211\n=\n=\nm\nj\nrr jR\nm\nS\n1\n1\n, for each method. The CR method has the highest resolution values after the first few \niterations, while the BGS method is slightly lower. The combined BGS-CR method follows the BGS \ncurve for the first 32 iterations, and departs from it at the 33rd iteration onwards when it switches over to \n 14\nthe CR method. The model resolution value for this combined method lies in between the BGS and CR \nmethods. The ETH method achieves significantly lower resolution values compared to the other \nmethods. The relative model resolutions for the different methods at the 40th iteration are 0.956 (CR), \n0.942 (BGS-CR), 0.920 (BGS) and 0.834 (ETH). The computer times in seconds taken by the respective \nmethods are 257 (CR), 87 (BGS-CR), 48 (BGS) and 47 (ETH) seconds (Table 1). \nFigure 2 here. \n Figure 3 shows the relative model resolution sections for the initial base data set (which is the \nsame for all the methods) and for the 16th, 32nd and 40th iterations of the different methods. Note the \ninitial relative resolution sections (that use the initial base data set consisting of the 147 dipole-dipole \narray configurations) show high relative resolution values near the surface that rapidly decreases with \ndepth. Only the top 3.4 meters have relative resolution values of above 0.50. For the CR method, the \nrelative resolution values in the lower section (first column in Figure 3) rapidly increases with each \niteration, and by the 40th iteration the relative resolution values rises to above 0.95 for almost the entire \nsection. For the BGS method, the relative resolution values also increase rapidly with each iteration, but \nthe distribution of the high values (above 0.80) is less uniform compared to the CR method. There are \npatches of low values at the top left and top right regions (second column in Figure 3). These 'blind \nspots' are probably caused by the different ranking functions used by the BGS and CR methods. The \ncriteria used to assess the effectiveness of the array optimization method is the model resolution. It is not \nsurprising that the CR method performs better as it directly calculates the change in the model resolution \ndue to the addition of a new array, whereas the BGS method uses an (heuristic) approximation in the \nranking function to gauge the effect of adding a new array. \n The BGS-CR method shows identical behaviour with the BGS method until the 32nd iteration \nsince the BGS method is used. The effect of using the CR method for the last 8 iterations is to fill up the \n\u2018blind spots\u2019 left by the BGS method. This results in a more uniform distribution of the high relative \n 15\nresolution values of above 0.925 for the entire section (third column Figure 3). The results of the ETH \nmethod is similar to that found by Wilkinson et al. (2006a). There is a significant improvement in the \nrelative resolution values compared to the initial dipole-dipole base data set, but its performance is \nbelow that of the BGS method. \nFigure 3 here. \n It should be emphasized that the sections in Figure 3 show the \u2018relative model resolution\u2019, i.e. the \nratio of the model resolution of the optimized data sets with the comprehensive data set. While the \n\u2018relative model resolution\u2019 can reach high values of over 0.9 in the lower sections of the model section \n(particularly for the 40th iteration of the CR method), the \u2018model resolution\u2019 values at the lower sections \nare very low. Figure 4 shows a plot of the \u2018model resolution\u2019 values achieved by the different \noptimization methods at the 40th iteration. \nFigure 4b shows the model resolution values for the comprehensive set with 51283 arrays. The \nmodel resolution section obtained with the CR method (Figure 4c) is almost identical despite having \nonly 4618 arrays, or about 9% of the number of arrays in the comprehensive set. There are some slight \ndifferences in the sections for the BGS and ETH methods at the upper left and right sides (Figures 4d \nand 4f), although the differences are not as obvious as in the relative resolution sections (Figure 3). The \nmodel resolution set for the initial dipole-dipole array set shown in Figure 4a has very low values (less \nthan 0.05) below a depth of 5 meters. \nFigure 4 here. \n Table 1 shows the computer times required by the different optimization methods for survey \nlines with 20 to 60 electrodes. As the number of electrodes increase, the time taken by the BGS-CR \nmethod becomes increasingly dominated by the CR method used for the last 20% of the iterations. The \npractical limit for the CR method is probably about 60 electrodes with present techniques. It is for these \nlarge problems that the BGS-CR method using a small number of CR iterations might prove to be the \n 16\nmost useful. It takes advantage of the higher model resolution values achieved by the CR method while \nrequiring more modest computer times. \nTable 1 here. \n We have also carried out tests using different values of the damping factor and model section \nthickness. The damping factor value of \u03bb=2.5 x 10-6 as used by Wilkinson et al. (2006a) was chosen so \nthat the model resolution for the comprehensive data set has values of about 0.05 at a depth of about \none-fifth the survey line length. From our experience with the inversion of field data sets, much higher \nvalues of the damping factor (typically 0.001 to 0.1) are usually used due to noise in the data. Figures 5, \n6 and 7 show the results obtained when a value of 0.01 is used for the damping factor. One effect of \nusing a higher damping factor is that the relative model resolution values achieved are lower. For \nexample, after 40 iterations with the CR method, the average relative resolution is 0.872 compared to a \nvalue of 0.956 obtained with the lower damping factor. This occurs because equation (2) for the model \nresolution involves the inverse of the ( )IGG T \u03bb+  term for the Marquardt-Levenberg least-squares \nmethod. It can be shown that increasing the damping factor \u03bb in this term leads to a decrease in the \nmodel resolution values (Golub and van Loan 1996, Menke 1989). \n However, the relative performances of the different methods are generally the same. The CR \nmethod achieves the highest relative resolution values while the BGS method is close behind with an \naverage relative resolution of 0.808 at the 40th iteration. The combined BGS-CR method closes the gap \nbetween the two methods in the last 8 iterations reaching a value of 0.857. The ETH method shows a \nsteady increase up to a value of 0.688 at the 40th iteration but lags behind the BGS method (Figure 5). \nThe relative resolution sections for the initial base data set, 16th, 32nd and 40th iterations are shown in \nFigure 6. The CR method has relative resolution values of above 0.85 for almost the entire section at the \n40th iteration. The BGS method achieves values of over 0.700 for almost the entire section, but with \n 17\nsmall regions with lower values near the upper left and right of the section which are filled up by the CR \nmethod during the last 8 iterations of the combined BGS-CR method (third column in Figure 6). \nFigure 5 here. \nFigure 6 here. \n Figure 7 shows the model resolution sections for the initial base set, the comprehensive set and \nthe base set after 40 iterations obtained by the different optimization methods using a damping factor of \n0.01. The resolution sections for the comprehensive set with the lower damping factor shown in Figure \n4b has values of 0.05 reaching down to about 8 meters, while in the section with higher damping factor \nit only reaches to 6 meters (Figure 7b). \nFigure 7 here. \nTests with synthetic data \n In this section, we present results from tests with synthetic data from a user defined 2D model. \nThe results for the model with four rectangular blocks used by Wilkinson et al. (2006a) are given. We \nhave scaled the model to a unit electrode spacing of 1 meter. The model together with the pseudosection \nfor the dipole-dipole array is shown in Figure 8. The blocks of 100 \u2126.m are set at different depths in a \nmedium of 10 \u2126.m to test the depth of investigation as well as the resolution of the different arrays. The \napparent resistivity values for different types of arrays are calculated for this model using a finite-\ndifference based forward modeling program. \nFigure 8 here. \n Initially the apparent resistivity pseudosections for several conventional arrays are generated. \nThe calculated apparent resistivity data sets are then used as the input data for a 2.5D least-squares \nsmoothness-constrained optimization program to generate inversion models. The l1-norm model \nconstraint was used since the real structure is known to have sharp boundaries (Farquharson and \n 18\nOldenburg, 1998). Details on the computer program and Gauss-Newton least-squares optimization \nmethod used can be found in Loke and Dahlin (2002) and Loke et al. (2003). \n The first test is with the Wenner array using measurements with the electrode separation \u2018a\u2019 \nranging from 1 to 9 meters giving a total of 135 data points. The performance of this data set is rather \npoor (Figure 9a). The two upper blocks are reasonably well detected, but the third deepest block is rather \npoorly resolved. The next array is the Wenner-Schlumberger array (Pazdirek and Blaha, 1996) with \noverlapping data levels using the potential dipole spacing \u2018a\u2019 ranging from 1.0 to 9.0 meters, and using \n\u2018n\u2019 factor values of 1 to a maximum of 9, but only measurements where the geometric factors that do not \nexceed that for a dipole length of 1.0 meter and \u2018n\u2019 factor of 6 are selected (i.e. a maximum value of \n1055.6 m when the unit electrode spacing is 1.0 meter). This data set has a total of 383 data points. The \nthree upper blocks are better resolved (particularly the third block), but it still fails to detect the deepest \nblock (Figure 9b). The next test data set was for the dipole-dipole array with the dipole length \u2018a\u2019 fixed \nat 1 meter, and with the dipole separation factor \u2018n\u2019 varying from 1 to 6 that gives a total of 147 data \npoints (Figure 8a). The third deepest block is much better resolved compared to the Wenner and \nWenner-Schlumberger arrays (Figure 9c). However, the deepest block is not detected. In an effort to \nimprove the depth of investigation with the dipole-dipole array, measurements with different \u2018a\u2019 values \nranging from 1 to 9 meters are used, and \u2018n\u2019 values ranging from 1 to 6 (but imposing the limit that the \ngeometric factor does not exceed 1055.6 m) is next used. This data set has 395 data points. The \npseudosection for this data set is shown in Figure 8b. There is some indication of the deepest block in \nthe form of an area of slightly higher resistivity between the actual locations of the third and fourth \nblocks. However, the inversion model fails to separate the fourth block from the third deepest block. \nThere are also slights shifts in the locations of the first and third upper blocks. Note that in all the model \nsections, the thickness of the uppermost block is slightly overestimated. This could be due to the fact \n 19\nthat this block is located near the left end of the survey line, and thus there are fewer measurements that \ncover this block. \nFigure 9 here. \n Figure 10 shows the inversion models obtained using the array configurations generated by the \ndifferent optimization strategies. The data sets generated after the 40th iteration was used. As expected, \nthe best result was obtained with the CR method (with 4618 data points) where even the deepest block is \nclearly resolved. The shape and location of the deepest block is accurately reproduced, although the \nmaximum resistivity of about 25 \u2126.m is well below the true resistivity of 100 \u2126.m. This is not \nunexpected as the resolution of the resistivity method decreases exponentially with depth. The deepest \nblock is also reasonably well detected by the BGS and BGS-CR methods. \nFigure 10 here. \n It could be argued that better resolution of the optimized data set with 4618 data points is due to \nthe much greater number of data points compared to the conventional arrays. Here we show the results \nwith a much smaller optimized data set with only 413 data points (with an average relative resolution \n0.768) that is similar in size to the Wenner-Schlumberger and dipole-dipole arrays with overlapping data \nlevels (Figures 9b and 9d). It is generated using 12 iterations of the CR method. The shape of the deepest \nblock is much better resolved (Figure 11a) compared to the dipole-dipole array, although it is slightly \ntoo shallow compared to the model obtained with the larger optimized data set (Figure 10a). However, \nthe number of data points used is less than 10% of the larger optimized data set. Figure 11b shows the \nresulting inversion model obtained when a moderately larger optimized data set (824 data points) \ngenerated using 20 iterations of the CR method is used. The deepest block is much better resolved. \nFigure 11c shows the result obtained using the smaller optimized data set generated with the BGS-CR \nmethod (using 10 iterations of the BGS method followed by 2 iterations of the CR method). The deepest \nblock is just barely resolved although the result is still better than that obtained using the dipole-dipole \n 20\narray with overlapping data levels (Figure 9d). The deepest block is much better resolved with the \nmedium size optimized data set (using 16 iterations of the BGS method followed by 4 iterations of the \nCR method). In field surveys, the practical use of the optimized data set probably lies in generating such \nsmall or medium data sets using the CR or BGS-CR methods. The data sets generated have significantly \nbetter resolutions than conventional arrays but only involve a similar number of measurements.  \nFigure 11 here. \n Zhou and Dahlin (2003) demonstrated that the error in resistivity field measurements varies \ninversely with the signal strength. Thus to simulate such noise, we add Gaussian random noise (Press et \nal.,1992) to the potential values (for a current of 1 Ampere) for the different array configurations. After \nadding the noise, the potential values are converted to apparent resistivity values. The amplitude of the \npotential noise is chosen so that the readings with the lowest potential (and also the largest geometric \nfactor) have a noise level of 15 percent. The largest geometric factor is about 168 times the smallest \ngeometric factor for the arrays generated. The average percentage apparent resistivity noise depends on \nthe geometric factors of the array configurations in the data set used, but it generally gives a value of \nabout 2 to 4 percent. As an example, Figure 12a shows the dipole-dipole array data set with overlapping \ndata levels with the potential dependent noise added (Figure 8b shows the same pseudosection without \nnoise). The inversion model for this data set (Figure 12b) shows slight distortions in the upper three \nblocks, while the area of higher resistivity at the location of the deepest block is now much less \ncompared with the noise free model (Figure 9d). Figures 12c and 12d shows similar models for the large \noptimized data sets generated by the CR and BGS-CR methods.  The deepest block is still clearly visible \nin both sections, although the highest resistivity value reached is lower compared to the corresponding \nmodels without noise (Figures 10a and 10c). The noise added causes a slight reduction in the resolution \nof the deepest block. \nFigure 12 here. \n 21\nField example \n The data sets presented in this field example were acquired from an active landslide site near \nMalton, North Yorkshire, UK. The site is being monitored using an automated time-lapse electrical \nresistivity tomography (ALERT) system (Kuras et al., 2009; Ogilvy et al., 2009) to study the hydraulics \nof landslide processes. The ALERT instrument uses wireless telemetry (in this case GPRS) to \ncommunicate with an office based PC that runs control software and a database management system. \nThe control software is used to schedule data acquisition, whilst the database management system stores, \nprocesses and inverts the remotely streamed ERT data. The capability that this provides for flexible and \nremotely configurable data acquisition is ideal for testing and improving optimized command sequences \nwithout the need for repeated manual reoccupation of the site. \n The research site is located on a south facing valley side with a slope of approximately 14\u00b0. The \nbedrock geology, from the base to top of slope, comprises the Lias Group Redcar Mudstone Formation \n(RMF), Staithes Sandstone and Cleveland Ironstone Formation (SSF), and Whitby Mudstone Formation \n(WMF), which are overlain at the top of the hill by the Dogger Sandstone Formation (DF). The bedrock \nis relatively flat lying with a gentle dip of a few degrees to the north, and the strata are broadly \nconformable (British Geological Survey, 1983). Slope failure at the site is occurring in the weathered \nWMF, which is highly prone to landsliding. The landslide is characterized by shallow rotational failures \nat the top of the slope that feed into larger-scale slowly moving lobes of slumped material, which extend \napproximately 150 m down the slope. The data were collected from one of five permanently installed \nlinear electrode arrays running from the base to the top of the hill, each comprising 32 electrodes with \nalong-line spacings of 4.75 m. The selected array was installed along a gully between two active lobes. \nTwo data sets were acquired, one comprising 516 dipole-dipole measurements (a = 4.75, 9.5, 14.25 and \n19 m, and n = 1 to 8) and another with 516 optimized measurements (using the CR method). In both \ncases, the maximum allowed geometric factor was K = 32 233 m (equivalent to that for a = 14.25 m, n = \n 22\n8). The inverted images are shown in Figure 13. In both cases convergence was achieved after 7 \niterations with extremely good fits between the measured and inverted data, indicated by mean misfit \nerrors of 0.35 % (dipole-dipole) and 0.55 % (optimized).  \n During testing of the optimized command sequences, we observed that systematic polarization \neffects were being caused by the use of electrodes to measure potential that had previously been used to \npass current (Dahlin, 2000; Merriam, 2005). The optimized command sequence used in Figure 13b had \nbeen reordered so that at least 3 measurements separated instances of the same electrodes being used for \ncurrent and potential measurements. Without this reordering, the mean misfit error for the same set of \noptimized commands was 3.37 %. The remaining difference between the quality of the fits to the dipole-\ndipole and optimized data sets is probably due to random noise. Although both command sequences \nhave the same maximum geometric factor, on average the optimization process tends to select more \nmeasurements with high geometric factors. The average geometric factor for the optimized set is \n5666 m, compared to 4450 m for the dipole-dipole set. \n Both the optimized and dipole-dipole images in Figure 13 exhibit resistivity variations consistent \nwith the expected stratigraphic sequence. The sharp boundary between high and low resistivities near the \nsurface in the Staithes is interpreted as the water table, which is supported by the presence of a spring \nline downslope from the origin at x = -15 m. Within the Whitby, the higher surface resistivities in the \nvicinity of the rotational failure are most likely due to increased localized fracturing. The positions of the \nwater table and the Whitby \/ Staithes boundary have been inferred from the resistivity images, whilst the \nStaithes \/ Redcar boundary has been positioned to match the log of the auger hole at x = -6 m. From \nsynthetic studies (Wilkinson et al., 2006a; 2006b), we would expect the resolution of the optimized \nimage to be better than the dipole-dipole image at depth and towards the edges of the model. This \nappears to be supported by the field results, where the resistivity contours (especially the 23 \u2126.m \ncontour) follow the Whitby \/ Staithes boundary more closely towards the north in the optimized image \n 23\nthan in the dipole-dipole image. Near the surface and x = 0 m, the optimized image also fits the water \ntable more closely than the dipole-dipole image. The optimized image has better resolution near the ends \nof the survey line. This is demonstrated by the higher resolution values at the upper left and right corners \nof the model resolution section in Figure 4c for the CR method compared to Figure 4a for the dipole-\ndipole array. The Staithes \/ Redcar boundary is less distinct than the Whitby \/ Staithes. The reasons for \nthis are likely to be twofold. Firstly, in this region there is a gradational interface between the Redcar \nand the Staithes (Powell, 1984). Secondly, the Redcar becomes relatively silty towards the top of the \nformation (Rawson and Wright, 1995). Therefore it will be more lithologically, and hence electrically, \nsimilar to the Staithes. \nFigure 13 here. \n Figure 14 shows the distribution of the data points of the dipole-dipole array and optimized data \nsets. The horizontal location of the data point is calculated from the average horizontal position of the \nfour electrodes in the array configuration while the vertical position is calculated using the median depth \nof investigation method (Edwards, 1977; Barker, 1989). Different symbols are used for the Alpha and \nBeta type of array configurations. The optimized data set has more data points in the lower part of the \npseudosection (particularly below a pseudodepth of about 20 m.) that partly accounts for the improved \nresolution at depth. There is also a clustering of the data points near the edges of pseudosection of the \noptimized data set. This is probably caused by the program attempting to improve the resolution at the \nleft and right sides of the model section. \nFigure 14 here. \nCONCLUSION  \n The use of optimized data sets can significantly improved the resolution of 2.5D resistivity \nimaging surveys compared to conventional arrays. Among the optimization methods tested, the CR \nmethod that directly calculates the change in the resolution matrix for each new array added to the \n 24\noptimized data set gave inversion models with the highest resolution. The combined BGS-CR method \ngave results that are almost as good but required only about one-third to one-quarter the computer time \nto generate the optimized data set. The techniques described in this paper have reduced the computer \ntime required by the CR method by about 80 times. This makes it practical to use the CR method to \ngenerate optimized data sets for longer survey lines with up to about 60 electrodes positions. For even \nlonger survey lines, the BGS-CR method might prove to be the most practical alternative. Tests carried \nout with the small optimized data sets showed that they give significantly better resolution although the \nnumber of data points is comparable to that used with conventional arrays. The small and medium sized \noptimized data sets are probably the most useful in practical field surveys. \n The fast methods for calculating the updated model resolution matrix developed in this paper \nenables the use of other criteria, such as the point spread function (Miller and Routh, 2007), for finding \noptimized arrays for 2.5D surveys. This will be studied in future research. Other possible techniques for \nfurther reducing the computer time required by the CR method are being investigated as part of current \nresearch in optimized arrays for 3D surveys. \n \nAcknowledgements \nThis paper is published with the permission of the Executive Director of the British Geological Survey \n(NERC). We would like to thank two anonymous reviewers for their comments that have helped to \nimprove the paper.  \n \n \n \n \n \n 25\nTables \n \nTable 1. The times in seconds for 40 iterations (and average relative resolution ratio achieved) for the \ndifferent optimization methods. \nNumber of \nelectrodes \nCR method \nTime (Resolution) \nBGS method \nTime (Resolution) \nBGS-CR method \nTime (Resolution) \nETH method \nTime (Resolution) \n20 20 (0.992) 6 (0.979) 9 (0.991) 6 (0.960) \n30 258 (0.958) 48 (0.920) 86 (0.951) 47 (0.837) \n40 2635 (0.921) 205 (0.874) 680 (0.909) 205 (0.757) \n50 17252 (0.886) 668 (0.840) 3918 (0.867) 667 (0.683) \n60 62276 (0.858) 1745 (0.808) 13818 (0.833) 1750 (0.628) \n \n \nTable 2. Number of data points (and average relative resolution ratio) for the optimized data sets for a \nsurvey line with 30 electrodes at the 16th, 32nd and 40th iterations using a damping factor of 2.5 x 10-6. \nAll the methods start with the same initial dipole-dipole array data set with 147 data points with average \nrelative resolution ratio of 0.257. \nIteration CR method BGS method BGS-CR method ETH method \n16 585 (0.836) 584 (0.709) 584 (0.709) 584 (0.657) \n32 2318 (0.929) 2317 (0.876) 2317 (0.876) 2317 (0.779) \n40 4618 (0.958) 4618 (0.920) 4617 (0.951) 4617 (0.837) \n \n 26\nTable 3. Number of data points (and average relative resolution ratio) for the optimized data sets for a \nsurvey line with 30 electrodes at the 16th, 32nd and 40th iterations using a damping factor of 0.01. All the \nmethods start with the same initial dipole-dipole array data set with 147 data points with average relative \nresolution ratio of 0.145. \nIteration CR method BGS method BGS-CR method ETH method \n16 585 (0.625) 584 (0.494) 584 (0.494) 585 (0.454) \n32 2318 (0.802) 2317 (0.710) 2317 (0.710) 2317 (0.584) \n40 4617 (0.872) 4618 (0.808) 4618 (0.857) 4617 (0.688) \n \n 27\nReferences \nBarker, R.D., 1979. Signal contribution sections and their use in resistivity studies. Geophysical Journal \nof the Royal Astronomical Society 59, 123-129. \nBarker, R.D., 1989. Depth of investigation of collinear symmetrical four-electrode arrays. Geophysics \n54, 1031-1037. \nBauman, P., 2005. 2-D resistivity surveying for hydrocarbons \u2013 A primer. CSEG Recorder April 2005, \n25-33. \nBritish Geological Survey, 1983. York solid and drift (Sheet 63). 1:50 000. British Geological Survey, \nKeyworth, Nottingham, U.K. \nCarpenter, E.W. and Habberjam, G.M., 1956. A tri-potential method of resistivity prospecting. \nGeophysics 11, 455-469. \nChandra, R., Dagum, L., Kohr, D., Maydan, D., McDonald, J. and Menon, R., 2001. Parallel \nProgramming in OpenMP. Academic Press, San Diego, California, 230 pp. \nDahlin, T., 1996. 2D resistivity surveying for environmental and engineering applications. First Break \n14, 275-284. \nDahlin, T., 2000. Short note on electrode charge-up effects in DC resistivity data acquisition using \nmulti-electrode arrays. Geophysical Prospecting 48, 181-187. \nDahlin, T. and Zhou, B., 2004. A numerical comparison of 2-D resistivity imaging with 10 electrode \narrays. Geophysical Prospecting 52, 379-398. \nDay-Lewis, F.D., Singha, K. and Binley, A.M., 2005. Applying petrophysical models to radar travel \ntime and electrical resistivity tomograms: Resolution-dependent limitations. Journal of \nGeophysical Research 110, B08206, doi:10.1029\/2004JB003569. \ndeGroot-Hedlin, C. and Constable, S., 1990. Occam's inversion to generate smooth, two-dimensional \nmodels from magnetotelluric data. Geophysics 55, 1613-1624. \n 28\nEdwards, L.S., 1977. A modified pseudosection for resistivity and induced-polarization. Geophysics 42, \n1020-1036. \nEllis, R.G. and Oldenburg, D.W., 1994. Applied geophysical inversion. Geophysical Journal \nInternational 116, 5-11. \nFarquharson, C.G., and D.W. Oldenburg, 1998. Nonlinear inversion using general measures of data \nmisfit and model structure. Geophysical Journal International 134, 213-227 \nGerber, R., 2002. The Software Optimization Cookbook : High-performance recipes for the Intel \narchitecture. Intel Press, Hillsboro, Oregon, 279 pp.  \nGolub, G. and van Loan, C.F., 1996. Matrix computations (Third Edition). The John Hopkins University \nPress, Baltimore, Maryland, 694 pp. \nKuras, O., Pritchard, J., Meldrum, P.I., Chambers, J.E., Wilkinson, P.B., Ogilvy, R.D., and Wealthall \nG.P., 2009. Monitoring hydraulic processes with Automated time-Lapse Electrical Resistivity \nTomography (ALERT). Comptes Rendus Geosciences 341, 868-885. \nLeiterman, J.C., 2005. 32\/64-bit 80x86 assembly language architecture. Wordware Publishing Inc., \nPlano, Texas, 545 pp. \nLoke, M.H. and Dahlin, T., 2002. A comparison of the Gauss-Newton and quasi-Newton methods in \nresistivity imaging inversion. Journal of Applied Geophysics 49, 149-162. \nLoke, M.H., Acworth, I. and Dahlin, T., 2003. A comparison of smooth and blocky inversion methods in \n2D electrical imaging surveys. Exploration Geophysics 34, 182-187. \nMenke, W., 1989. Geophysical data analysis: Discrete inverse theory (Revised Edition). Academic Press \nInc., San Diego, California, 289 pp.  \nMerriam, J.B., 2005. Injection electrode overprinting. Journal of Environmental and Engineering \nGeophysics 10, 365-370. \nMiller, C.R. and Routh, P.S., 2007. Resolution analysis of geophysical images: Comparison between \n 29\npoint spread function and region of influence measures. Geophysical Prospecting 55, 835-852. \nOgilvy, R.D., Kuras, O., Meldrum, P.I., Wilkinson, P.B., Chambers, J.E., Sen, M., Pulido-Bosch, A., \nGisbert, J., Jorreto, S., Frances, I. and Tsourlos, P., 2009. Automated Monitoring of Coastal \nAquifers with Electrical Resistivity Tomography. Near Surface Geophysics 7, 367-375. \nPazdirek, O. and Blaha, V., 1996. Examples of resistivity imaging using ME-100 resistivity field \nacquisition system. In: EAGE 58th Conference and Technical Exhibition Extended Abstracts, \nAmsterdam, P050. \nPowell, J.H., 1984. Lithostratigraphical nomenclature of the Lias Group in the Yorkshire basin. \nProceedings of the Yorkshire Geological Society 45, 51-57. \nPress, W.H. , Teukolsky, S.A., Vetterling, W.T. and Flannery, B.P, 1992. Numerical Recipes in C \n(Second Edition). Cambridge University Press, Cambridge, UK, 994 pp. \nRawson, P.F. and Wright, J.K., 1995. Jurassic of the Cleveland Basin, North Yorkshire. In: Tayler, P.D. \n(Ed).  Field Geology of the British Jurassic. Geological Society, London, pp. 173-208. \nSeaton, W.J. and Burbey, T.J., 2000, Aquifer characterization in the Blue Ridge Physiographic Province \nusing resistivity profiling and borehole geophysics. Journal of Environmental and Engineering \nGeophysics 5 (3), 45-58. \nStummer, P., Maurer, H. and Green, A., 2004. Experimental design: Electrical resistivity data sets that \nprovide optimum subsurface information. Geophysics 69, 120-129. \nWilkinson, P.B., Meldrum, P.I., Chambers, J.C., Kuras, O. and Ogilvy, R.D., 2006a. Improved strategies \nfor the automatic selection of optimized sets of electrical resistivity tomography measurement \nconfigurations. Geophysical Journal International 167, 1119-1126. \nWilkinson, P. B., Kuras, O., Meldrum, P. I., Chambers, J. E. and Ogilvy, R. D. 2006b. Comparison of \nthe spatial resolution of standard and optimised electrical resistivity tomography arrays. In: \n 30\nProceedings of the 12th meeting of the EAGE Near Surface Geophysics Conference, Helsinki, \nFinland, P040. \nXu, B. and Noel, M., 1991. Archaeological investigations by electrical resistivity tomography: a \npreliminary study. Geophysical Journal International 107, 95-102. \nZhou, B. and Dahlin, T, 2003. Properties and Effects of Measurement Errors on 2D Resistivity Imaging \nSurveying. Near Surface Geophysics 1, 105-117. \n 31\n \nFigure 1. The three possible arrangements for an array with four electrodes. \n 32\n \nFigure 2. Change of the average relative model resolution with iteration number for the four array \noptimization methods. \n 33\n \nFigure 3. The top row shows the relative model resolution sections for the initial base data set with 147 \ndipole-dipole array configurations. The first column (starting from the top) shows the relative model \nresolution sections for the initial base data set, the optimized data set after the 16th iteration, 32nd and \n40th iterations obtained with the CR method. The second, third and fourth columns show similar results \nfor the BGS, BGS-CR and ETH methods. The number of data points and average relative resolution \nvalues for the different methods are listed in Table 2. \n \n 34\n \nFigure 4. Model resolution values for (a) initial dipole-dipole array base data set, (b) comprehensive data \nset, (c) CR method, (d) BGS method, (e) combined BGS-CR method and (f) ETH method. The result for \nthe base set generated at the 40th iteration is shown for the different array optimization methods. \n \n 35\n \nFigure 5. Change of the average relative model resolution with iteration number for the four array \noptimization methods when a higher damping factor of 0.01 was used. \n \n 36\n \nFigure 6. The relative model resolution sections obtained when a higher damping factor of 0.01 was \nused. The top row shows the relative model resolution sections for the initial base data set with 147 \ndipole-dipole array configurations. The first column (starting second from the top) shows the relative \nmodel resolution sections for the initial base data set, the optimized data set after the 16th iteration, 32nd \nand 40th iterations generated by the CR method. The second, third and fourth columns show similar \nresults for the BGS, BGS-CR and ETH methods. The number of data points and average relative \nresolution values for the different methods are listed in Table 3. \n \n 37\n \nFigure 7. Model resolution values for the (a) initial dipole-dipole array base set,  (b) comprehensive set, \n(c) CR method, (d) BGS method, (e) combined BGS-CR method and (f) ETH method. The result for the \nbase set generated at the 40th iteration is shown for the different array optimization methods using a \nhigher damping factor of 0.01. \n \n 38\n \nFigure 8. (a) Apparent resistivity pseudosection for the simple dipole-dipole array with a dipole length \n\u2018a\u2019 of 1.0 meter with the dipole separation factor \u2018n\u2019 of 1 to 6. (b) Apparent resistivity pseudosection for \nthe dipole-dipole array with overlapping data levels. (c) The synthetic model with 4 rectangular blocks \nof 100 \u2126.m embedded in a medium of 10 \u2126.m. as used by Wilkinson et al. (2006a).  \n \n 39\n \nFigure 9. Inversion model obtained from the inversion of different data sets for the synthetic model with \nfour blocks. (a) Wenner array with electrode spacings of 1.0 to 9.0 meters. (b) Wenner-Schlumberger \narray with overlapping data levels. (c) Simple dipole-dipole array data set with the dipole length \u2018a\u2019 \nequals to 1.0 meter, and the \u2018n\u2019 factor ranging from 1 to 6. (d) Dipole-dipole array data set with \noverlapping data levels. The outlines of the actual rectangular blocks in the synthetic model are also \nshown. \n \n 40\n \nFigure 10. Inversion model obtained from the inversion of different optimized data sets (for the synthetic \nmodel with 4 blocks) generated by the (a) CR, (b) BGS, (c) BGS-CR and (d) ETH methods. \n \n 41\n \nFigure 11. Inversion models obtained with the (a) small (413 data points) and (b) medium sized (824 \ndata points) optimized data sets produced by the CR method. Inversion models for similar (c) small and \n(d) medium sized optimized data sets produced by the BGS-CR method. \n \n 42\n \nFigure 12. (a) Apparent resistivity pseudosection for the dipole-dipole array with overlapping data levels \nafter adding the potential dependent noise. Inversion models for data sets with noise added for (b) \ndipole-dipole array, and optimized data sets generated by the (c) CR and (d) BGS-CR methods. \n \n 43\n \nFigure 13. 2D inverted images for a) the dipole-dipole and b) the optimized data sets. The inferred \nboundaries between the Whitby (WMF), Staithes (SSF) and Redcar (RMF) formations are shown by \ndotted black lines. The inferred water table is shown by the dashed white line. Stratigraphic logs of \nauger holes are shown in greyscale. A rotational failure is indicated by the black arrows. North is \ntowards the top of the slope (grey arrow). \n \n 44\n \nFigure 14. Distribution of data points for the dipole-dipole array and the optimized data sets used in the \nfield survey. \n"}
{"doi":"10.1109\/ICME.2008.4607503","coreId":"102855","oai":"oai:epubs.surrey.ac.uk:2406","identifiers":["oai:epubs.surrey.ac.uk:2406","10.1109\/ICME.2008.4607503"],"title":"JOINT SPATIAL AND TEMPORAL CORRELATION EXPLOITATION FOR WYNER-ZIV FRAMES CODING IN DVC","authors":["Adikari, ABB","Fernando, WAC","Weerakkody, WARJ","Kondoz, AM"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-01-01","abstract":null,"downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:2406<\/identifier><datestamp>\n      2017-10-31T14:05:27Z<\/datestamp><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/2406\/<\/dc:relation><dc:title>\n        JOINT SPATIAL AND TEMPORAL CORRELATION EXPLOITATION FOR WYNER-ZIV FRAMES CODING IN DVC<\/dc:title><dc:creator>\n        Adikari, ABB<\/dc:creator><dc:creator>\n        Fernando, WAC<\/dc:creator><dc:creator>\n        Weerakkody, WARJ<\/dc:creator><dc:creator>\n        Kondoz, AM<\/dc:creator><dc:date>\n        2008-01-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/2406\/1\/SRF002587.pdf<\/dc:identifier><dc:identifier>\n          Adikari, ABB, Fernando, WAC, Weerakkody, WARJ and Kondoz, AM  (2008) JOINT SPATIAL AND TEMPORAL CORRELATION EXPLOITATION FOR WYNER-ZIV FRAMES CODING IN DVC   2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4.  589-+.      <\/dc:identifier><dc:relation>\n        http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=4607503<\/dc:relation><dc:relation>\n        10.1109\/ICME.2008.4607503<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/2406\/","http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=4607503","10.1109\/ICME.2008.4607503"],"year":2008,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"JOINT SPATIAL AND TEMPORAL CORRELATION EXPLOITATION FOR \nWYNER-ZIV FRAMES CODING IN DVC \nA.B.B. Adikari, W.A.C. Fernando, W.A.R.J. Weerakkody, A.M.Kondoz \nCentre for Communication Systems Research \nUniversity of Surrey, Guildford, Surrey GU2 7XH, UK \n                          adikari@ieee.org; W.Fernando@surrey.ac.uk;  R.Weerakkody@surrey.ac.uk \n \nABSTRACT \n \nSource coding by exploiting the temporal and spatial \ncorrelations in an input video stream is well established in \nconventional video coding. However, when Distributed \nVideo Coding (DVC) is concerned, shifting the source \ncoding from the encoder to the decoder made this a more \ncomplicated and possibly a sub optimal process. Exploiting \nthe temporal correlations has so far been attempted utilizing \nthe key frames, by motion compensation using the \ninterpolated (or extrapolated) motion field. However, \nexploiting the spatial correlations within the DVC \nframework is still an unsolved problem. In this paper, we \npropose to exploit both spatial and temporal correlations to \ngenerate the side information at the decoder. The proposed \narchitecture involves a bit plane level side information \nrefinement mechanism extracting both temporal and spatial \ninformation available at the decoder. Simulation results \nshow that, the proposed coding scheme can achieve about \n40% bit rate saving over 3D refinement algorithm proposed \nin [1] which is utilized as the basis for implementing the \nproposed technique. \n \n \nKey words:  Distributed video coding, Video coding, \nDigital signal processing \n \n1. INTRODUCTION \n \nIt is reasonable to anticipate an increased demand in the \nnear future for inexpensive video capturing mechanisms \nsuch as video sensor networks for security surveillance, \nmonitoring of disaster zones, design of entertainment \nsystems and some domestic applications like monitoring \nchildren and elderly people by the guardians. The low cost \nvideo conferencing requirements in mobile communications \nare also on the rise. Traditional video coding algorithms \nsuch as H.264\/AVC, MPEG-2, and MPEG-4 are not ideal \ncandidates for such requirements due to their \ncomputationally complex encoders that results in a higher \nmanufacturing cost. \nDistributed video coding (DVC) has emerged as a \ntechnology capable of reducing the processing complexity \nof the encoder, enabling low cost implementation, while \nmajority of the computations are shifted to the decoder. \nThis is an ideal solution for the requirement of capturing \nvideo streams at multiple remote sites to be decoded at a \ncentral site as necessary in the above mentioned \napplications. The main advantages of the DVC encoder \ninclude low requirement of memory, computational capacity \nand power which are generally scarce resources at the \nremote sites. \nIn DVC, the source coding is performed in the decoder. \nThis is in contrast to other conventional video compression \nschemes where the source coding happens in the encoder. \nThe conventional approaches involve a complex encoder \nstructure and an easy to implement-low cost decoder which \nwas motivated by applications such as broadcasting, video \non demand, and video streaming. The source coding at the \ndecoder in DVC is done by means of generating a side \ninformation stream that is statistically correlated with the \noriginal data. In order to generate side information in the \ndecoder, a sequence of selected original frames is generally \npassed to the decoder over the channel using existing intra \ncoding techniques. These reference frames are called \u2018key-\nframes\u2019. The existing intra coding tools in MPEG-2[4] or \nH.264\/AVC [5] can be utilized for this. However, in one of \nour papers [6], we have proposed a Wyner-Ziv coding \nbased key frame coding scheme that exploits spatial \ncorrelations.  \nThe objective of this paper is to present an enhanced \nalgorithm for side information estimation by exploiting both \ntemporal and spatial correlations in contrast to the existing \nDVC codecs that exploit only the temporal correlations. \nRest of the paper is organized as follows. In section 2, we \nsummarize some related work on DVC. The proposed \ncoding scheme is presented in section 3.  Section 4 presents \nsimulation results and a detailed analysis. Finally, section 5 \npresents the conclusion. \n \n2. RELATED WORK \n \nDistributed source coding concept was presented by \nSlepian and Wolf in 1973 [3]. They discussed the rate \nconditions for the independent decoding and joint decoding \nof statistically dependant discrete random sequences, for the \nlossless coding. Later in 1976, Wyner and Ziv extended this \nconcept for the lossy coding scenario, presenting the \nconcept of the use of side information at the decoder [2]. \nThe side information ( mY ) is commonly modeled \n589978-1-4244-2571-6\/08\/$25.00 \u00a92008 IEEE ICME 2008\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 14:46:05 UTC from IEEE Xplore.  Restrictions apply. \nconsidering the original bit stream ( mX ) and an additive \nwhite noise term ( mn ) as, \nmmm nXY +=  \nFor most of the cases, this noise process can either be \nmodeled using a Gaussian or Laplacian probability \ndistribution.  \nBased on the above concept, a number of DVC solutions \nhave been proposed; many of them based on the most \ndominant Stanford DVC framework [7]. Introducing the \nStanford framework, Aaron et al. has proposed a Turbo \ncoding based Wyner-Ziv codec [7][8]. They proposed \nsimple frame interpolation [7] and motion interpolation and \nextrapolation techniques [8] to predict the side information. \nImproving the side information estimation has been the \nfocus of much of the subsequent research in DVC. In some \nnotable achievements, Tagliasaccchi et al. proposed a \nmotion compensated temporal filtering technique [9]. \nIshwar et al.[10] presented an information theoretic study of \nvideo codecs based on source coding with side information. \nNatario et al. proposed an algorithm to generate side \ninformation based on motion field smoothening to provide \nimproved performance [11]. Ascenso et al., presented a \nscheme using motion interpolation to derive the side \ninformation [12]. They used forward and bidirectional \nmotion estimation and a spatial motion smoothing algorithm \nto generate the side information. They also proposed a \nmotion refinement algorithm using weighted motion \nestimation to further improve the side information [13]. \nThis algorithm can be considered as the best available pixel \ndomain Wyner-Ziv codec algorithm discussed in the \nresearch literature. Later-on, we consider this algorithm to \ncompare the performance of proposed algorithm.  \nIn other related work, we have proposed a TTCM based \ncoding scheme for DVC and showed that a significant \ncoding gain can be achieved compared to the more \nconventional Turbo coding based DVC codecs [14]. \nFurthermore, we also proposed several techniques to \nimprove the performance of the DVC codec [15][16]. \n \n3. PROPOSED CODING SCHEME \n \nThe proposed DVC codec is based on the Stanford DVC \nframework in the pixel domain. The encoder structure is \nunaffected which include the qunatizer and bit plane \nextraction followed by the Turbo encoder. The parity bit \nstream produced in Turbo coding is buffered for dynamic \ntransmission to the decoder based on the closed loop parity \nrequest mechanism involving the feedback channel.  The bit \nstream is segmented to small blocks before Turbo coding to \nimprove the efficiency of parity request mechanism and also \nto help in the spatial prediction process discussed later in \nthis section. In the proposed solution, three side information \nstreams are generated at the decoder, two of which are \ngenerated using motion extrapolation and compensation \n(ME-C) as in [16] and the third stream is generated by \nmeans of spatial prediction.. Since now the decoder handles \nthree side information streams, the computational cost of \nthe decoder is increased. To compensate for the additional \ncomputational complexity, we limit the constraint length of \nthe Turbo coder to 4 whereas in [11] a length of 5 is \nproposed. Furthermore, to reduce the computational cost, \nwe have reduced the number of iterations in the Turbo \ndecoder to 3 compared to 18 iterations used in [11]. \nSpatial Prediction \nThe spatial prediction is performed by exploiting the \nspatial correlation within the partially decoded Wyner-Ziv \nframes. Since each bit plane is segmented into smaller \nblocks before Turbo coding, previously decoded blocks of \nthe current frame are available for the prediction of side \ninformation for the current block. This process is an \nextension of the spatial prediction technique proposed for \nWyner-Ziv Intra coding algorithm presented in our previous \nwork [6] \n \nDecoding the most significant bit plane \nFigure \u00031 illustrates the major functional elements of the \nproposed codec for first bitplane coding, as shown, MC-E 1 \nand MC-E 2 generate two side information streams that are \npredicted by motion extrapolating the previous two closest \nkey frames and immediate key frame and the closest \nWyner-Ziv frame. This prediction and decision criteria are \nas in [16].The third side information stream generated by \nmeans of spatial prediction and in the figure this module is \nshow as SP. It should be noted that this algorithm is \nimplemented to perform bit stream segmentation before \nturbo coding similar to WZ-I coding scheme as in [6]. \nTherefore, even in the first bitplane, after decoding at least \none block, information is available for the spatial prediction \nmodule to make a prediction to be used as side information \nfor the next decoding cycle. Similar to other parallel DVC \nresearch, we assume that the decoder is capable of \ndetermining the error probability of the decoded block. \nBased on the error probability, the turbo decoder decides \nwhich side information stream is used for decoding a given \nblock. Since the turbo decoder operates in multiple cycles \ndepending on the length of the bitstream, it decodes one \nblock of the bitstream independent of the other blocks.  \nDecoding subsequent bit planes \nFigure 2 illustrates the active functional elements of the \ncodec for decoding the higher order bitplane i.e., the \nbitplanes from the second bitplane onwards. As shown in \nthe figure MC-E 1 and MC-E 2 are now inactive but 3D \nRefinement II[1] has become active that undertakes the side \n590\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 14:46:05 UTC from IEEE Xplore.  Restrictions apply. \ninformation processing. This arrangement also uses three \nside information streams, first is the output of the 3D \nrefinement, and the second is the composite side \ninformation stream from the 2-SI as in[1]. The third side \ninformation stream is again the output of SP module. In this \nstage SP module receives more information since the first \nbitplane is already decoded and therefore, it tends to \nperform even better.  \n \n4. SIMULATION RESULTS \n \nIn all simulations presented in this paper, we used a turbo \ncoder with two rate \u00bd component encoders with a constraint \nlength (K) of 4. Turbo decoding is done for 3 iterations. All \nother simulation parameters are set as in[7]. \nThe proposed DVC codec is tested for several test video \nsequences with the spatial the resolution of 176x144 (qcif). \nAll picture parameters are set as in [7]. Results for four test \nvideo sequences are illustrated in figure 3. The illustrated \nresults are averaged over first 100 frames of the sequences. \nThe bitrate is varied by independently controlling the \ngranularity of the quantizer as in the previous sections. A \nframe rate of 15 fps used with a GOP of 2 and the results \nare shown for the Wyner-Ziv frames only. The bitrate and \nthe PSNR shown in the plot are only for Y signal of the \nsequence. Results of the proposed technique are shown \ntogether with several other techniques for the first test \nsequence. It is evident from the illustrated results that the \nproposed enhancement has resulted in a significant \nreduction of bitrate compared to the 3D refinement \ntechnique and a much higher gain can be observed \ncompared to other techniques. The bitrate saving can be \nseen in the plot as a horizontal left-ward shift of the curve. \nThe bitrate reduction is up to about 40% in some cases as it \ncan be seen in the figures. \n \n5. CONCLUSIONS \n \nIn this paper we used both temporal and spatial properties \nof the image in Wyner-Ziv frame coding in DVC. We used \nthe concept of multiple side information concept to improve \nthe performance. To maintain the computational cost at a \nsimilar level, we reduced the constraint length of the turbo \nencoder and reduced the number of iterations. Based on the \nsimulation results, it can be concluded that, the proposed \nalgorithm provides significant reduction in bit rates in pixel \nbased DVC codecs. \n \nACKNOWLEDGEMENT \n \nThe work presented was developed as a part of VISNET II, \na European Network of Excellence (http:\/\/www.visnet-\nnoe.org), funded under the European Commission IST FP6 \nprogramme. \n \nREFERENCES \n \n[1] A.B.B. Adikari, W.A.C. Fernando, W.A.R.J. Weerakkody, \u201cSide \nInformation Improvement in DVC with Two Side Information \nStreams and 3D Motion Refinement,\u201d Proc. CCECE 2007, pp.32-35, \nCanada, April 2007. \n[2] D.Wyner and J. Ziv, \u201cThe rate-distortion function for source coding \nwith side information at the decoder,\u201d IEEE Trans.on Inform. \nTheory, vol. IT-22, pp. 1\u201310, Jan. 1976. \n[3] D. Slepian and J.K. Wolf, \u201cNoiseless coding of correlated \ninformation sources,\u201d IEEE Trans. on Inform Theory, vol. IT-19, pp. \n471\u2013480, July 1973. \n[4] R. Sch\u00a8afer and T. Sikora, \u201cDigital video coding standards and their \nrole in video communications,\u201d Proc. IEEE, vol. 83, pp. 907\u2013924, \nJune 1995. \n[5] Thomas Wiegand, Gary J. Sullivan, \u201cOverview of the H.264\/AVC \nVideo Coding Standard\u201d, IEEE trans on circuits and systems for \nvideo technology, Vol.13, No.7, July 2003 \n[6] A.B.B. Adikari, W.A.C. Fernando, W.A.R.J. Weerakkody, \n\u201cIndependent Key Frame Coding Using Correlated Pixels in \nDistributed Video Coding,\u201d IEE Electronics Letters, Vol. 43, Issue 7, \npp. 387-388,  March 2007. \n[7] A. Aaron, R. Zhang and B. Girod, \"Wyner-Ziv coding of motion \nvideo,\" Proc. Asilomar Conference on Signals and Systems, Pacific \nGrove, CA, Nov. 2002. \n[8] B. Girod , A. Aaron, S. Rane and D.R. Monedero, \"Distributed \nVideo Coding,\u201d Proc. of IEEE Special Issue on Advances in Video \nCoding and Delivery, Vol.93, No. 1, pp.1-12, 2003. \n[9] M. Tagliasaccchi and S. Tubaro, \u201cA MCTF Video Coding Scheme \nBased on Distributed Source Coding Principles,\u201d Visual \nCommunication and Image Processing, July 2005. \n[10] P. Ishwar, V. Prabhakaran and  K. Ramchandran, \u201cTowards a Theory \nfor Video Coding Using Distributed Compression Principles,\u201d Proc. \nof International Conference on Image Processing, Vol.3, pp.687-690, \n2003. \n[11] L. Natario, C. Brites, J. Ascenso and F. Pereira, \u201c Extrapolating Side \nInformation for Low-Delay Pixel-Domain Distributed Video \nCoding,\u201d Int. Workshop on Very Low Bitrate Video Coding,  Sept \n2005  \n[12] J. Ascenso, C. Brites and F. Pereira, \u201cMotion Compensated \nRefinement for Low Complexity Pixel Based Distributed Video \nCoding,\u201d IEEE International Conference on Advanced Video and \nSignal Based Surveillance, Como, Italy, Sept 2005 \n[13] J. Ascenso, C. Brites and F. Pereira, \u201cImproving Frame Interpolation \nWith Spatial Motion Smoothing For Pixel domain Distributed Video \nCoding\u201d, 5th EURASIP Conference on Speech and Image \nProcessing, July 2005. \n[14] W.A.R.J. Weerakkody, W.A.C. Fernando, A.B.B. Adikari, R.M.A.P. \nRajatheva, \u201c4-PSK TTCM for Wyner-Ziv frame coding in DVC,\u201d \nIEICE ELEX Electronics Letters, Vol. 3, No 8, April, 2006. \n[15] A.B.B. Adikari, W.A.C. Fernando, H.K. Arachchi, W.A.R.J. \nWeerakkody, \u201cA Sequential Motion Estimation Based Refinement \nTechnique for Distributed video coding of Wyner-Ziv frames,\u201d IEE \nElectronics Letters, Vol. 42, Issue 7, pp 396-397, March,2006. \n[16] A.B.B. Adikari, W.A.C. Fernando, W.A.R.J. Weerakkody, \u201cMultiple \nSide Information Streams for Distributed Video Coding,\u201d IEE \nElectronics Letters, Vol. 42, Issue 25, pp. 1447-1449, December \n2006. \n \n \n \n \n591\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 14:46:05 UTC from IEEE Xplore.  Restrictions apply. \n  \n \nFigure 1: Functional elements of the algorithm for first \nbitplane coding \n \nFigure 2: Functional elements of the algorithm for higher \norder bitplane coding \n \n29\n31\n33\n35\n37\n39\n41\n43\n45\n47\n49\n0 100 200 300 400 500\nbitrate (kbps)\nPS\nNR\n \n(dB\n)\nH.264 I-P-I-P\nMC-E\n3D Ref\u2019t II\nProposed\n2-SI\n \n30\n32\n34\n36\n38\n40\n42\n0 50 100 150 200 250 300 350\nbitrate (kbps)\nPS\nNR\n (d\nB)\n3D Ref\u2019t II\nProposed\n2-SI\n \n(a) \u201cforeman\u201d (b) \u201ccarphone\u201d \n34\n36\n38\n40\n42\n44\n46\n0 20 40 60 80 100 120 140 160\nbitrate (kbps)\nPS\nNR\n \n(dB\n)\n3D Ref\u2019t II\nProposed\n2-SI\n \n41\n42\n43\n44\n45\n46\n47\n0 20 40 60 80 100 120\nbitrate (kbps)\nPS\nNR\n \n(dB\n)\n3D Ref\u2019t II\nProposed\n2-SI\n \n(c) \u201cnews\u201d (d) \u201cclaire\u201d \n \nWhere; 2-SI: Ref. [16], 3D Ref\u2019t II: Ref. [1], MC-E: Ref [11]. \n \nFigure 3: Performance comparison of the proposed algorithm  \n \n592\nAuthorized licensed use limited to: University of Surrey. Downloaded on April 19,2010 at 14:46:05 UTC from IEEE Xplore.  Restrictions apply. \n"}
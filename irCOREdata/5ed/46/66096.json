{"doi":"10.1137\/S106482750342670X","coreId":"66096","oai":"oai:dro.dur.ac.uk.OAI2:3209","identifiers":["oai:dro.dur.ac.uk.OAI2:3209","10.1137\/S106482750342670X"],"title":"Probabilistic formulations for transferring inferences from mathematical models to physical systems.","authors":["Goldstein,  M.","Rougier,  J. C."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2004-01-01","abstract":"We outline a probabilistic framework for linking mathematical models to the physical systems that they represent, taking account of all sources of uncertainty including model and simulator imperfections. This framework is a necessary precondition for making probabilistic statements about the system on the basis of evaluations of computer simulators. We distinguish simulators according to their quality and the nature of their inputs. Where necessary, we introduce further hypothetical simulators as modelling constructs to account for imperfections in the available simulators and to unify the available simulators with the underlying system","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/66096.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/3209\/1\/3209.pdf","pdfHashValue":"099629a5efb5912ef1aa8f8a77dafb325b15cb33","publisher":"Society for Industrial and Applied Mathematics","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:3209<\/identifier><datestamp>\n      2011-08-24T15:41:22Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Probabilistic formulations for transferring inferences from mathematical models to physical systems.<\/dc:title><dc:creator>\n        Goldstein,  M.<\/dc:creator><dc:creator>\n        Rougier,  J. C.<\/dc:creator><dc:description>\n        We outline a probabilistic framework for linking mathematical models to the physical systems that they represent, taking account of all sources of uncertainty including model and simulator imperfections. This framework is a necessary precondition for making probabilistic statements about the system on the basis of evaluations of computer simulators. We distinguish simulators according to their quality and the nature of their inputs. Where necessary, we introduce further hypothetical simulators as modelling constructs to account for imperfections in the available simulators and to unify the available simulators with the underlying system. <\/dc:description><dc:subject>\n        Direct simulator<\/dc:subject><dc:subject>\n         Uncertainty analysis<\/dc:subject><dc:subject>\n         Indirect simulator<\/dc:subject><dc:subject>\n         Top simulator<\/dc:subject><dc:subject>\n         Measurable inputs<\/dc:subject><dc:subject>\n         Tuning inputs<\/dc:subject><dc:subject>\n         Bayesian inference<\/dc:subject><dc:subject>\n         Calibration<\/dc:subject><dc:subject>\n         History matching<\/dc:subject><dc:subject>\n         Calibrated prediction.<\/dc:subject><dc:publisher>\n        Society for Industrial and Applied Mathematics<\/dc:publisher><dc:source>\n        SIAM journal on scientific computing, 2004, Vol.26(2), pp.467-487 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2004-01-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:3209<\/dc:identifier><dc:identifier>\n        issn:1064-8275<\/dc:identifier><dc:identifier>\n        issn: 1095-7197<\/dc:identifier><dc:identifier>\n        doi:10.1137\/S106482750342670X<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/3209\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1137\/S106482750342670X<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/3209\/1\/3209.pdf<\/dc:identifier><dc:rights>\n        \u00a9 2004 Society for Industrial and Applied Mathematics<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn: 1095-7197","issn:1064-8275","1064-8275"," 1095-7197"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2004,"topics":["Direct simulator","Uncertainty analysis","Indirect simulator","Top simulator","Measurable inputs","Tuning inputs","Bayesian inference","Calibration","History matching","Calibrated prediction."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n29 August 2008\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nGoldstein, M. and Rougier, J. C. (2004) \u2019Probabilistic formulations for transferring inferences from\nmathematical models to physical systems.\u2019, SIAM journal on scientific computing., 26 (2). pp. 467-487.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1137\/S106482750342670X\nPublisher\u2019s copyright statement:\n2004 Society for Industrial and Applied Mathematics\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n Use policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without \nprior permission or charge, for personal research or study, educational, or not-for-profit purposes \nprovided that : \n \n\u0083 a full bibliographic reference is made to the original source \n\u0083 a link is made to the metadata record in DRO \n\u0083 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright \nholders.  \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nDurham Research Online \n Deposited in DRO:\n29 August 2008\nVersion of attached file:\nPublished\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nGoldstein, M. and Rougier, J. C. (2004) 'Probabilistic formulations for transferring inferences\nfrom mathematical models to physical systems.', SIAM journal on scientific computing.,\n26 (2), pp.\u0000467-487.\nFurther information on publisher\u0000s website:\nhttp:\/\/dx.doi.org\/10.1137\/S106482750342670X\nPublisher\u0000s copyright statement:\n\u00a9 2004 Society for Industrial and Applied Mathematics\nPROBABILISTIC FORMULATIONS FOR TRANSFERRING\nINFERENCES FROM MATHEMATICAL MODELS TO PHYSICAL\nSYSTEMS\u2217\nMICHAEL GOLDSTEIN\u2020 AND JONATHAN ROUGIER\u2020\nSIAM J. SCI. COMPUT. c\u00a9 2004 Society for Industrial and Applied Mathematics\nVol. 26, No. 2, pp. 467\u2013487\nAbstract. We outline a probabilistic framework for linking mathematical models to the physical\nsystems that they represent, taking account of all sources of uncertainty including model and simu-\nlator imperfections. This framework is a necessary precondition for making probabilistic statements\nabout the system on the basis of evaluations of computer simulators. We distinguish simulators\naccording to their quality and the nature of their inputs. Where necessary, we introduce further hy-\npothetical simulators as modelling constructs to account for imperfections in the available simulators\nand to unify the available simulators with the underlying system.\nKey words. direct simulator, indirect simulator, top simulator, measurable inputs, tuning\ninputs, Bayesian inference, calibration, history matching, calibrated prediction, uncertainty analysis\nAMS subject classifications. 62F15, 62P35, 62M20, 62M40\nDOI. 10.1137\/S106482750342670X\n1. Introduction. In a computer experiment (sometimes referred to as an in sil-\nico experiment) we make inferences about a physical system using a computer simula-\ntor of that system. Such computer experiments may be used to investigate problems\nfor which it would be difficult to carry out the corresponding physical experiments.\nSometimes, the difficulty may be legal, ethical, or financial. But in other cases the\nexperiment may not be possible, usually because the system is too small or too large.\nThus in a computer experiment we can watch a single protein folding, we can watch\nthe global climate evolving, or we can watch an entire galaxy coalescing.\nWe act as though evaluations of our models are informative about the physical\nsystem. For example, the debate on global climate change, which is already having a\nprofound effect on policy, is guided by computer-based predictions of future climate,\ne.g., [9]. This is despite the problems that, in general, (i) our mathematical models\nof the underlying physical system are incomplete and often mutually inconsistent,\n(ii) the discretized solvers of these models (the simulators) are often woefully under-\nresolved, and (iii) the simulators require inputs about which we are very uncertain.\nIt is natural in these circumstances to require that model-based predictions about the\nsystem are accompanied by a careful evaluation of all sources of uncertainty. This is\nessential both for informed scientific debate, and also to assist policy makers within\na decision-theoretic framework.\nOur purpose in this paper is to construct a probabilistic framework that links\none or more computer simulators and the underlying physical system, in order that\nthe information available from evaluations of the simulators can feed through, via\nprobabilistic conditioning, using a Bayesian statistical approach, into beliefs about\nthe system. These beliefs include system properties and system behavior (e.g., system\n\u2217Received by the editors April 30, 2003; accepted for publication (in revised form) February 9,\n2004; published electronically December 22, 2004.\nhttp:\/\/www.siam.org\/journals\/sisc\/26-2\/42670.html\n\u2020Department of Mathematical Sciences, University of Durham, Durham DH1 3LE, UK (Michael.\nGoldstein@durham.ac.uk, J.C.Rougier@durman.ac.uk). The research of the second author was sup-\nported by the UK Natural Environment Research Council, grant NER\/T\/S\/2002\/00987, and by the\nTyndall Centre for Climate Change Research, grant T2\/13.\n467\n468 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\nprediction). In this paper we have described what we believe to be the minimum\namount of modelling necessary to allow us to transfer inferences from one or more\nsimulators to the underlying system.\nThe outline of the paper is as follows. Our objective is to make probabilistic\nstatements about the physical system using evaluations of our simulator and, where\navailable, data collected from the system. For this purpose we must construct a prob-\nabilistic model that links the simulator and the system. We start in section 2 by\nconsidering the simplest case, in which we have a high-quality simulator with well-\ndefined inputs. In section 3 we discuss the problem of ill-defined \u201ctuning\u201d inputs,\nand in section 4 we extend our analysis to include these and the possibility that the\nsimulator is not of high quality. In section 5 we discuss belief models for the simulator\nitself, and in section 6 we extend our analysis to include multiple simulators for the\nsame system. Section 7 concludes with a discussion. Our analysis is general, covering\na wide range of computer experiments which share certain widely occurring charac-\nteristics, but we provide illustrations from the important field of climate modelling.\nMore details of this application may be found in [3, 13] and, of particular interest to\nstatisticians, [2, 12].\n2. The direct simulator. We start by considering the best possible case for\nsimulator-based inference about a physical system. We denote the system value y,\nwhere y typically comprises a collection of space- and time-indexed physical quantities.\nThe possible values that y can take are the set Y. To model this system, we have a\ndeterministic simulator f , usually represented as computer code. For simplicity we\nwill assume throughout that the output of f also takes values in the set Y, so that\nwe can compare the output of the simulator and the actual system directly.\nWe define the inputs of the simulator at a very general level to comprise the\nnumbers used to initiate the computer code, i.e., the values that need to be speci-\nfied before the code will execute. Typically, this will comprise (i) parameters in the\nequations describing the general behavior of the system and (ii) parameters, including\nboundary values and forcing functions, that tailor the general behavior of the system\nto a specific instance. There may also be quantities that control the way in which the\nsystem of equations is solved. If we wish to model explicitly our uncertainty as to\nhow changes in such quantities would affect the quality of the computer solutions,\nthen we might also represent these quantities as functional inputs into the simulator.\nHowever, this would further complicate many aspects of the account of our modelling.\nTherefore, for clarity of exposition, we treat the different values of such quantities as\ndefining a family of different simulators. This will allow us to subsume our treatment\nof such quantities within our general treatment of families of related simulators for a\nphysical system.\nWe want to use evaluations of a computer simulator of the system to help us\nreduce uncertainty about the system itself. We shall describe an approach that we\nconsider appropriate for such an analysis. This approach will be formulated within a\nBayesian statistical framework. In this framework, all probabilities are quantifications\nof the uncertainties of experts (e.g., [1]). This approach is appropriate for making such\ninferences, as the uncertainty about the relationship between the simulator and the\nsystem can only be captured by expert judgments. In our applications, the quan-\ntifications will be based on experience with the simulator, its underlying theory, its\nhistory of application, and any other prior knowledge relevant to the physical system.\nThe quality and reliability of the inferences that we are able to make will, therefore,\ndepend on the care and effort that is taken in assessing such considerations.\nRELATING MODELS AND SYSTEMS 469\nThe Bayesian approach has been formulated to allow the expert to synthesize\nrelevant prior information with data, such data in our case comprising observations\non the physical system and evaluations of the computer simulator. Different experts\nmay make different prior judgements and, therefore, reach different conclusions as a\nresult of following this process. Therefore, there are two ways to employ the analysis\nthat we shall describe. First, an individual expert may explore the implications of his\nor her individual judgments for reducing uncertainty over the quantities of interest.\nSecond, by seeing how such prior judgments vary between experts, the analysis may\nbe used to assess the degree to which such experts may reasonably disagree in their\nposterior judgments, given empirical evidence and evaluations of the simulator.\nFirst, consider the case where the domain of f comprises only inputs that can,\nat least in principle, be determined by an experiment independent of the simulator\nitself. We call these measurable inputs and denote the space of measurable inputs as\nX , with the true input denoted x0 \u2208 X . Of particular interest is the degree to which\nf(x0) is able to represent y. We define the discrepancy to be the difference between\nthe true value y of the physical system and the value of the simulator output at the\ntrue input value x0, namely,\n\u0001 = y \u2212 f(x0).(2.1)\nIn some situations, most notably where we have a perfect simulator and our only\nuncertainty is about, say, the initial value of the state vector, we may have \u0001 = 0.\nGenerally, however, we would not expect the simulator to exactly replicate the system\nvalue at input x0, and consequently we anticipate that \u0001 \u0002= 0.\nWe are often uncertain about x0 due to our unwillingness or inability to perform\nthe experiment that would determine x0 to arbitrary accuracy. Some components of\nX are likely to be very well known, e.g., the gravitational constant or the Stefan\u2013\nBoltzmann constant, but others, e.g., \u201chistoric\u201d forcing functions or boundary con-\nditions, are only known approximately. Likewise, we are uncertain about f , in all\nbut trivial cases, due to the fact that we cannot costlessly evaluate f at every input\nvalue. We are uncertain about y in any circumstances where y may only be observed\nwith error, or has not yet been observed, e.g., future values. Finally, we are uncertain\nabout the discrepancy \u0001 whenever the reasons for the mismatch between the simulator\nand the system are not fully understood.\nWhen we assign a probability distribution for the quantities y, f , x0, and \u0001 to\naccount for this uncertainty, then this distribution is constrained by (2.1). By making\nfurther assumptions that we now describe, we may reformulate the problem so that\nour uncertainty about \u0001, f , and x0 jointly determine our uncertainty about y.\nFor this purpose we now define a certain type of simulator as follows. We say\nthat f is a direct simulator if it has two properties. First, its inputs are measurable.\nSecond, the discrepancy \u0001 is probabilistically independent of x0 and f , according to\nthe judgments of the expert. This second property corresponds to the judgment that\nevaluations of the simulator at inputs other than x0 are believed by the expert to\nconvey no information about y additional to that in f(x0). That is, given knowledge\nof f(x0), there is no additional information contained in any further simulator evalua-\ntions for the purposes of predicting y as well as possible. Further, were the true values\nof f and x0 to be revealed to the expert, then the uncertainty that the expert would\nafterwards specify for y would be the same for each possible value of f and x0 that\ncould be revealed. Thus, we exclude the kind of problem where we know, for example,\nthat the solution method used by the simulator is very reliable for some parts of the\n470 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\ninput space but much less reliable for other parts of the input space. In this case\nthe expert might want to make the predictability of the system using the simulator,\ne.g., as measured by Var[\u0001], depend on x0. Such considerations are unnecessary with\na direct simulator.\nFor a direct simulator, the relationship between f , x0, the system y, and observed\nsystem data z may be represented in the following Bayesian graphical model:\nx0\n\u0001\u0001\n\u0001\n\u0001\u0001\ne\n\u0001\u0001\nf \u0002\u0002 f(x0) \u0002\u0002 y \u0002\u0002\n\u0003\u0003\u0001\n\u0001\u0001\n\u0001\u0001\n\u0001\u0001\n\u0001 yp\n\u0002\u0002 z\nyf\n(2.2)\nA (directed) Bayesian graphical model consists of a collection of nodes, where each\nnode represents one or a collection of random quantities. The nodes are joined by arcs,\nand the construction x\u2192 y, or x is a parent of y, indicates, informally, that knowledge\nof the value of x is relevant to the specification of the probability distribution of\ny, according to the judgment of the expert. The precise property of the graph is\nthat any two nodes on the graph are conditionally independent given the values of\nall of their parent nodes. For a detailed discussion of such models, see [4, 10]. In\nparticular, graphical models are useful in displaying how the various uncertainties\nin a problem relate to each other. For example, we read from (2.2) that our model\nhas four independent sources of uncertainty, namely, f , x0, \u0001, e. We combine f and\nx0 to get f(x0); we combine f(x0) and \u0001 to get y; we split y into yp and yf and\ncombine yp with e to get z. As our models and sources of information become more\ninvolved, it becomes increasingly useful to have simple visual representations which\ndisplay qualitatively how the various aspects of uncertainty are combined.\nIn (2.2) we have partitioned the system y into (yp, yf ), heuristically \u201cpast\u201d and\n\u201cfuture,\u201d namely, those quantities for which we already have observations (yp), and\nthose whose values we would like to assess (yf ), and introduced observational data\nz, which includes measurement error e, on the \u201cpast\u201d system components. We may\nsuppose that the measurement error is additive, so that\nz = yp + e,(2.3)\nalthough other models for the statistical errors are also possible.\nThe logical basis for inference using a direct simulator is straightforward. The\nquantities x0, \u0001, and e are clearly defined, but there is uncertainty about their values.\nWe may express this uncertainty as (mutually independent) probability distributions.\nIn the general case, there may also be uncertainty about f , but for simplicity at\nthis stage we treat f as known. Using (2.1) and (2.3) we can compute a full joint\nprobabilistic specification over the collection (x0, yf , z) which can be used to answer,\nprobabilistically, questions about the system.\nFor example, we can use observed values for z to help to reduce our uncertainty\nover x0, and we can exploit this reduction in uncertainty to reduce our forecast uncer-\ntainty for yf . Reducing uncertainty over x0 is often termed (probabilistic) calibration,\nor, in the oil industry, history matching; see [16]. Reducing uncertainty over the un-\nobserved future values yf is often termed (probabilistic) prediction. Using system\nRELATING MODELS AND SYSTEMS 471\ndata to reduce uncertainty about inputs and, therefore, to help learn about the future\nvalues is often termed (probabilistic) calibrated prediction. In other cases, we have\nno system data z, and we can only learn about yf in terms of our various sources of\nuncertainty. This is known as uncertainty analysis. In many problems of uncertainty\nanalysis, the value of x0 is selected from some population for each case to which the\nmodel is applied; for example, x0 might be the unknown dose of radiation received\nby a particular patient, and the model output might be likely symptoms based on a\ncomputer model of the effects of different radiation levels on the patient.\nWe have\np (x0, yf | z) \u221d p (x0, yf , z) = p (z, yf | x0) p(x0).(2.4)\nOur model states that\n(z, yf ) = f(x0)\u2295 \u0001\u2295 (e,0),(2.5)\nwhere \u201c\u2295\u201d denotes the sum of independent vectors and (x, y) denotes the concatena-\ntion of two vectors x and y into a single vector. If we assume that \u0001 and e are both\nGaussian with mean zero, then the conditional distribution (z, yf ) | x0 is Gaussian\nwith mean f(x0) and variance Var[\u0001] + Var[(e,0)]. In this case p(z, yf | x0) has the\nsimple Gaussian functional form.\nThe practical implementation of these calculations may be complicated. In par-\nticular, the elicitation of expert knowledge about the variance structure of the discrep-\nancy \u0001 may be challenging; for example, if y is a time series, such as some important\nclimate variables aggregated on a weekly basis, then beliefs about \u0001 will reflect this\ntime structure, and modelling for the future may be based on similar considerations\nto those in Bayesian forecasting for complex time series, where, if appropriate, we\nmay use discrepancies between the model and historical data to modify beliefs about\nthe underlying parameters generating the time series. However, despite such practical\ncomplications, the way in which the overall analysis should be carried out and the\nlogical meaning of the various uncertainty statements are clear.\nSimple example. We now introduce a simple example, which we shall develop in\nthe following sections to illustrate the relevance of each of the features that we shall\nintroduce. Our simulator is\nf(x) = (apx, afx);(2.6)\ni.e., it has a single input x and two outputs, where we consider apx to be the \u201cpast\u201d\noutput and afx to be the \u201cfuture\u201d output, where ap and af are known scalars but we\nare uncertain about the true input value x0. In order to make inferences about x0 and\nyf = afx0 using the system data z we need to provide distributions for x0, \u0001, and e.\nWe might choose mean-zero Gaussian distributions for the latter two, as this simplifies\nthe inference as described above. This requires a 2 \u00d7 2 variance matrix for \u0001 and a\nvariance scalar for e. In general, there are no computational advantages that accrue\nfor particular choices for the distribution p(x0), so we will leave this undetermined.\nWith these assumptions, the calibrated prediction calculation for (2.4) is\np (x0, yf | z) \u221d N2((z, yf ) | f(x0),\u03a3)\u00d7 p (x0) ,(2.7)\nwhere \u201cN2\u201d is the bivariate Gaussian density function with given mean and variance,\nand\n\u03a3 = Var [\u0001] +\n(\nVar [e] 0\n0 0\n)\n.(2.8)\n472 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\nClearly, this calculation generalizes straightforwardly to many inputs and many out-\nputs with a known simulator, although Monte Carlo methods might be necessary in\nlarge problems; see [14] for more details.\n3. Indirect simulators. Unfortunately, very few of the simulators that we use\nin practice are direct simulators. This is because (i) they include inputs that are not\nmeasurable, and (ii) they are not sufficiently \u201cgood\u201d that we are prepared to believe\nin a single \u201cbest\u201d input value. Often both of these limitations apply.\n3.1. \u201cTuning\u201d inputs. Within the full set of inputs to the simulator we find\nit useful to distinguish two main types: those which may be measured independently\nof the simulator, and those where no such measurement is meaningful. Measurable\ninputs were introduced in section 2. We term the other inputs tuning inputs. These\nare inputs which have meaning only with reference to the simulator.\nThe classification into \u201cmeasurable\u201d and \u201ctuning\u201d inputs is not always clear-cut.\nConsider, for example, the four-compartment model of the Atlantic described in [17],\nhereafter zsr, for investigating the northward transport of heat from the tropics. We\nwill use this model to illustrate various features of our approach throughout the paper.\nIf we restrict our attention to an equilibrium analysis, then there are 18 inputs and\neight outputs, the latter comprising equilibrium temperature and salinity for each\ncompartment. Of the inputs (given in zsr Table 1), five are measurable inputs, for\nexample, the specific heat capacity and density of sea-water, and five are tuning inputs\nand are labeled as such. The remaining eight have physical analogues, for example,\nthe volume and depth of each compartment; it is not immediately clear how to classify\nthese inputs. A model of the Atlantic with four simply connected compartments is\nhighly stylized, and we may be reluctant to attach too much physical meaning to each\ncompartment. However, were we to construct a model of the Atlantic with four million\nsmall compartments arranged in a three-dimensional lattice that carefully respected\nthe ocean margins, then, arguably, we would be concerned to match depths and\nvolumes in the simulator at least approximately to their natural physical analogues.\nIn section 4.1 we will introduce the possibility of \u201clinking\u201d a measurable input with\na tuning input, which can be used to handle ambiguous cases.\nIt is important to understand the role of tuning inputs. They do not exist solely\nto permit a good fit to the system data z. Rather they make allowances for simulator\nimperfections. These imperfections are of two main types.\nPoorly understood physics. Often the underlying physics (taken in its broadest\nsense) of the system is poorly understood or understood on a scale that is not ap-\npropriate to the simulator. In studies of climate change, for example, the large-scale\nbehavior of clouds is an important determinant of the earth\u2019s albedo. However, cloud\nformation is not a well-understood process and detailed models reflecting current un-\nderstanding would require information not available in a typical climate model (e.g.,\nto account for the effect of localized \u201cseeding\u201d by the nonuniform distribution of at-\nmospheric particulate matter). The same points could be made about the oceanic\ncarbon cycle, or sea-ice. These types of subprocesses are represented in simulators\nin quite general terms, with parameters which do not relate directly to measurable\nattributes, but which attempt to compensate for aspects of the missing underlying\nphysics, for example to bridge effects assessed at different scales.\nSolver deficiencies. The second source of simulator imperfection is solver deficien-\ncies. A given physical model expressed as ordinary or partial differential equations is\nalmost invariably solved on a finite grid. Sometimes circumstances dictate that the\ngrid must be larger than the characteristic scale of important physical processes. A\nRELATING MODELS AND SYSTEMS 473\nwell-known example of this is the treatment of viscosity in large coupled ocean\/climate\nmodels. At the moment, the solution grid of these models is constrained by computing\nrequirements to have a cell-size that is too large to capture the transport of water and\nheat by turbulence, which tends to be highly localized. Consequently, this transport\nis represented in the simulator by a parameterization of local turbulence in terms of\ntuning inputs such as horizontal and vertical \u201ceddy viscosities.\u201d Experiments on the\ncurrent generation of ocean simulators find that eddy viscosities need to be orders\nof magnitude larger than underlying molecular viscosity (which is measurable). As\ncomputers become more powerful and the solver resolution improves, then we may\noften find that these types of tuning inputs tend to well-defined limits, although, for\nany particular simulator, this may be subject to a variety of complex numerical and\nmodelling issues.\nReturning to the zsr example, we may choose to treat the four-compartment vol-\numes as measurable inputs, as we could divide the Atlantic into sections by latitudes\nfrom which volumes can be inferred, as is done in the paper. In this case we might\nwant to treat the compartment depths as tuning inputs, because the appropriate av-\neraging method for each compartment will depend upon physics that we are not clear\nabout.\n3.2. Indirect simulators. If our simulator is not a direct simulator, then we\nlabel it an indirect simulator. To include the tuning inputs we write f : X \u00d7 U \u2192 Y,\nwhere X is the space of measurable inputs and U of tuning inputs; where there are\nno tuning inputs we set U = \u2205. Note that we do not have to have tuning inputs for f\nto be an indirect simulator\u2014we may simply feel that f is not good enough for us to\nwant to connect it directly with the system via the true but unknown value x0.\nThe treatment of indirect simulators, both in the literature and in practice, is\nsomewhat inconsistent, falling somewhere between the following two extremes.\n1. We pretend that the simulator really is a direct simulator with true physical\ninput value (x0, u0) and carry out the analysis just as for the direct simulator as\ndescribed above. We call this a pseudodirect analysis.\n2. We take the view that the simulator is a device for forecasting, so that inputs\n(x, u) for which \u2016z \u2212 fp(x, u)\u2016 is small are likely to give rise to a prediction error\n\u2016yf \u2212 ff (x, u)\u2016 that is also small. We call this a black-box analysis, in which we treat\nall inputs implicitly as tuning inputs.\nThe logical problems for the pseudodirect approach are clear. If there is no\ntrue value of (x, u), then there is no object over which it is meaningful to specify\nuncertainties. Further, there is no obvious way to express how much additional error\nwe are introducing by the pretense of such a precise value. The logical problems for\nthe black-box approach are even worse. If there is no physical basis for the terms of\nour model, in the sense that we do not even claim a generalized relationship between\nthe inputs and some physical counterparts in the underlying system, then it is very\ndifficult to construct a logical argument for the claim that good calibration in the past\nshould result in good forecasts for the future. For example, we may be able to achieve\nmany perfect matches using a purely statistical approach (e.g., by fitting high-order\npolynomials): are all of our predictions equally good, or equally bad?\nCurrent practice in climate research with large simulators is to perform an ensem-\nble of runs at different input values and use these as the basis of inference. Suppose\nwe are interested in the mean value of future climate, given system data z and runs\nof the simulator at (x1, u1), . . . , (xn, un). Typically, this mean value is estimated as\na weighted sum of ff (xi, ui), where the weights are determined as some function of\n474 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\n\u2016z\u2212fp(xi, ui)\u2016; the norm in this case accounts for factors such as the observation error\nvariance structure. So far, this approach is consistent with the black-box view. How-\never, the (xi, ui) are sampled from a prior distribution that reflects beliefs about the\nunderlying inputs\u2014this is more consistent with the pseudodirect view. This combined\napproach has been adopted, for example, for the innovative www.climateprediction.net\nexperiment.\nWe should add that statisticians developing methodology in this area, including\nourselves, are not exempt from criticism. Our own papers using the Bayes linear\napproach [5] propose what we now refer to as a pseudodirect analysis. The fully\nBayesian approach of Kennedy and O\u2019Hagan [11] tends toward a black-box analysis\n(see, particularly, their response to the discussion on [p. 461]).\n4. Direct analysis using an indirect simulator. We need a way to connect\nour indirect simulator to the underlying system. In particular, we need to understand\nthe precise role of the tuning inputs. This will allow us to have well-defined beliefs\nabout the tuning inputs which can be used in inference about the system. A natural\npart of the linkage between an indirect simulator and the system is an assessment\nof the degree to which the indirect simulator fails to function as a direct simulator.\nTherefore, we augment f with a description of a further direct simulator to which\nthe indirect simulator approximates. Call this hypothetical direct simulator the direct\nversion of f , denoted fD. For the moment we assume that fD has the same measurable\ninput space as f , so that fD : X \u2192 Y. We have now divided the problem of linking\nour simulator f and the system y into two parts. First, f tells us about fD; second,\nfD(x0) tells us about y. Note that in this formulation the value f(x0, u) is not\nespecially informative about the system, except insofar as it is informative about\nfD(x0).\nIn this context the role of the tuning inputs is to capture some of the difference\nbetween f and fD. There are various levels of detail to which we may describe how\ntuning works within the simulator. The simplest view (generalized in section 6.1),\nwhich is sufficient to demonstrate our general approach and will be adequate for\nmany problems, is to treat the tuning inputs in an analogous way to that in which\nwe have treated the direct simulator in section 2. Thus, we suppose that there is an\nunknown value u0 with the property that, if we knew this value, then we would only\nevaluate the function f(x, u) at u = u0 in order to learn about the form of the direct\nsimulator fD(x). This does not mean that f(x, u0) = fD(x), but rather that the\nconditional probability distribution fD(x) | u0 depends only on the function f(x, u0).\nEquivalently, the simulator provides no information about the functional discrepancy\nbetween f and fD,\n\u0001D(x) = fD(x)\u2212 f(x, u0),(4.1)\nbeyond that which may be obtained from evaluating the simulator at u0, for each\nvalue of x. In particular, we might set E[\u0001D(x)] = 0 so that E[fD(x) | u0] = f(x, u0).\nTypically, we will have some view as to the likely order of magnitude discrepancy\nbetween the tuned version of f and the value of fD for a typical input x, which will\nsuggest the variance for \u0001D(x), usually the same for each x. Similarly, an order of\nmagnitude view as to how large a change in x would be required to make a large change\nin the functional discrepancy may be used to suggest a correlation parameter for the\nprocess. More sophisticated views concerning likely differences in tuning achievable\nin different regions of the input space could similarly be introduced into the belief\nRELATING MODELS AND SYSTEMS 475\nspecification. We have, from (4.1), that\nVar [fD(x)] = Var [E [fD(x) | u0]] + E [Var [fD(x) | u0]]\n(4.2)\n= Var [f(x, u0)] + Var [\u0001D(x)] .\nThe first term in (4.2) expresses the variation in fD(x) which may be removed by\ncareful tuning, while the second term expresses the residual variation between the\ntuned version of the simulator and fD(x). Tuning inputs and the directed version of\nf are incorporated onto the graphical model as follows:\n\u0001D\n\u0004\u0004\u0002\n\u0002\u0002\n\u0002\u0002\n\u0002\u0002\n\u0002 u0\n\u0001\u0001\nx0\n\u0001\u0001\nf \u0002\u0002 fD \u0002\u0002 fD(x0) \u0002\u0002\u0003\u0003\u0003 same as (2.2)\n(4.3)\nReturning to the calibrated prediction calculation, we now add u0 to the collection of\nquantities we want to learn about using z, to get\np (x0, u0, yf | z) \u221d p (z, yf | x0, u0) p (x0) p (u0) .(4.4)\nOur model now states\n(z, yf ) = f(x0, u0)\u2295 \u0001D(x0)\u2295 \u0001\u2295 (e,0).(4.5)\nIf, in addition to our previous Gaussian assumptions, we assume that \u0001D is a Gaussian\nrandom field with zero mean, then the distribution (z, yf ) | (x0, u0) is Gaussian with\nmean f(x0, u0) and variance Var[\u0001D](x0)+Var[\u0001]+Var[(e,0)]. Once again the practical\nimplementation may be tricky, involving the elicitation of the distribution of u0 and\nthe variance kernel of \u0001D, but the procedure and the meaning of the various quantities\nare clear.\nNote that, computationally, our beliefs about fD are induced by our beliefs about\nu0 and \u0001D. This is not to say that u0 and \u0001D are necessarily the primitive quantities.\nIt may be that our beliefs about f and fD give rise to beliefs about u0 and \u0001D. We can\nalways check that our two sets of beliefs are consistent and plausible by integrating\nu0 and \u0001D out of fD explicitly.\nIn the zsr model, we are already provided with several tuning inputs. But we\nmust first consider whether the experts feel comfortable with the idea of a direct\nsimulator defined only on the five measurable inputs. For a model this simple, we\nmay suppose that the answer is almost certainly \u201cNo.\u201d Therefore, we must consider\nalternative rationales for interpreting the output of the simulator. The simplest case\nfor an indirect simulator is that there exists some unknown value u0 for the tuning\ninputs such that fD(x) = f(x, u0) + \u0001D(x), where fD is a direct simulator, so that\ny = fD(x0) + \u0001. The next simplest case is to assert that our simulator cannot be\nturned into a direct simulator by appropriate choice of u0, but that there is another\nsimulator defined on X which can, and to which our own simulator approximates.\nThis simulator, which we call the top simulator, will be introduced in section 6.1.\nBut we may not believe that any simulator defined on X alone is good enough to\nfunction as a direct simulator. Perhaps, for example, we may consider that no model\nthis highly aggregated can sufficiently account for the complex spatial patterns of\nAtlantic currents, but that a model with more compartments might. Therefore, a\nsimple approach based on (4.1) will not be acceptable, and we will have to be more\nsubtle in the way that we relate the simulator and the system. We will discuss such\nalternative relationships in section 6.3.\n476 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\nExample (cont). We will develop our example both with and without a tuning\ninput. Suppose our beliefs about fD are that it has the same functional form as f\nbut that x is likely to have a larger impact on fDp and a smaller impact on fDf . It\nmay be that this is already embodied in a tuning input for f , for example,\nf(x, u) = ((ap + u)x, (af \u2212 u\/2)x)(4.6)\nfor some tuning input u > 0. We may choose in this case to use a simple stationary\nGaussian process for \u0001D and set Var[\u0001D](x) = \u03a3\nD for all x. With these additional\nassumptions and a prior distribution for u0, the calibrated prediction calculation is\np (x0, u0, yf | z) \u221d N2((z, yf ) | f(x0, u0),\u03a3)\u00d7 p (x0)\u00d7 p (u0) ,(4.7)\nwhere\n\u03a3 = \u03a3D + Var [\u0001] +\n(\nVar [e] 0\n0 0\n)\n.(4.8)\nAlternatively, we may not have a tuning input with this feature, in which case\nour beliefs will need to be modelled by a more careful choice for \u0001D. Write fD(x) as\nfD(x) = (aDpx, aDfx)(4.9)\nfor unknown parameters aDp and aDf , so that\n\u0001D(x) = fD(x)\u2212 f(x) = ((aDp \u2212 ap)x, (aDf \u2212 af )x) = (vpx, vfx),(4.10)\nwhere vp and vf are uncertain quantities. Our beliefs about vp and vf then induce\nbeliefs about the random field \u0001D. In this case, beliefs corresponding to (4.6) would\nsuggest that E[vp] > 0 and E[vf ] < 0. We have the choice here of modelling vp and\nvf jointly (which would be a generalization of the joint model induced by the tuning\ninput u), or modelling them independently. Either way, our calibrated prediction\ncalculation would be\np (x0, yf | z) \u221d\n\u222b\u222b\nN2((z, yf ) | f(x0) + (vpx0, vfx0),\u03a3)\n(4.11) \u00d7 p (x0)\u00d7 p (vp, vf ) dvpdvf\nfor some choice of density p(vp, vf ), where (vp, vf ) are treated as nuisance parameters\nand have been integrated out; \u03a3 is as defined in (2.8).\n4.1. Linking to measurable inputs. In many cases we want to treat a mea-\nsurable input as a tuning input, usually because insight and experience combine to\nsuggest that this is predictively effective. In other words, allowing a measurable input\nto move away from its actual value can offset some of the deficiencies of the simula-\ntor. Viscosity in ocean models, as discussed in section 3.1, provides a good example.\nWhere this is the case, we suggest that the original measurable input remains in X\nbut that a tuning input is introduced into U , which modifies the impact of the mea-\nsurable input in the simulator. We term this linking to the measurable input. Thus\nX contains the original measurable input \u03bd, say, and U contains the multiplier m\u03bd ,\nand the effective value of the input in the simulator is m\u03bd \u00d7 \u03bd, or some other known\ndeterministic function of m\u03bd and \u03bd. This will require us either to modify the simula-\ntor code or to provide a wrapper to the simulator to implement the transformation.\nRELATING MODELS AND SYSTEMS 477\nWe can put our uncertainty about \u03bd into our beliefs about x0, and we can put our\nuncertainty about how the role of x differs in f and fD into our beliefs about u0.\nIn the zsr example we may choose to link to the thermal and haline expansion co-\nefficients. These enter the model on the presumption of a linear relationship between\nnorth-south temperature and salinity gradients and the meridional volume transport\n(i.e., the quantity of water flowing northward). Insofar as this relationship is ap-\nproximate, we may choose to replace measurable inputs with more adaptable tuning\ninputs. This is not necessarily the best response to functional uncertainty\u2014we could,\nfor example, use a random field with a linear mean function\u2014but it serves as a simple\n\u201cquick fix,\u201d allowing us to introduce some uncertainty attributable to the linear ap-\nproximation without disproportionate effort. Of course, linking to these measurable\ninputs does not compensate for the more fundamental problems that arise if there is\nno direct version of the simulator defined on X , as already discussed.\nExample (cont). Suppose we wanted to link to x in our example, where for sim-\nplicity we do not have the tuning input u. In this case we would create the \u201cwrapper\u201d\nfunction g(x,m) = f(mx), where m is our new tuning input, and we would have\nfD(x) = g(x,m0)\u2295 \u0001D(x) = ((apm0)x, (afm0)x)\u2295 \u0001D(x).(4.12)\nThus our beliefs about m0 induce beliefs about the parameters of fD in quite a\ndifferent way than those induced, for example, by (4.6). If we thought that aDp and\naDf were about the same as ap and af , then we might choose a gamma distribution\nfor m0 with mean 1 and small variance. For the calibrated prediction calculation we\nwould proceed in a similar way to (4.7), replacing f with g and u0 with m0.\nIn this example we have now seen three different ways to model the relationship\nbetween f and fD: through existing tuning inputs (if they are appropriate), through\na careful choice for \u0001D, and by linking to measurable inputs. They each have different\nimplications for the distribution of fD | f and so provide a range of modelling options\nfor the expert.\n5. Statistical emulators. Up until now, we have assumed that the simulator f\nis known to the analyst. In practice, our precise knowledge of f often extends only as\nfar as a finite collection of evaluations at known inputs, F = {f(x1), . . . , f(xn)}. This\nset of inputs can be very small with respect to the dimension of the input space; for\nexample, coupled ocean\/climate simulators have large input spaces but can take weeks\n(or longer) for a single run. Unless we can evaluate the simulator instantaneously, we\nwill have to treat its output at arbitrary x as uncertain for computational purposes.\nThis means that we have to add the data from the simulator evaluations to our\ngraphical model. In the simplest case of a single direct simulator, the graphical model\n(2.2) becomes\nx0\n\u0001\u0001\nf \u0002\u0002\n\u0001\u0001\nf(x0) \u0002\u0002\u0003\u0003\u0003 same as (2.2)\nF\n(5.1)\nNow we must provide a probabilistic description of our beliefs about f , which is a\nrandom field indexed by x \u2208 X , and then update those beliefs using F . The use of\n478 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\nstochastic processes to model deterministic functions such as computer simulators has\nbeen widely studied; see, for example, [15] and the more recent references in [5, 11].\nWe give here a brief outline of the approach that we have found effective in physical\nmodelling with large numbers of inputs and outputs.\nA natural and convenient way to represent beliefs about f is to represent f as\nthe sum of two components. The first component expresses our beliefs about the sys-\ntematic variation in f given x, and the second component captures residual variation\nwith local structure\nfi(x) =\n\u2211\nj\u2208Ji\n\u03b2\n(i)\nj Lj(x) + \u03b4i(x), i = 1, . . . , k = dimY,(5.2)\nwhere i indexes the components of the simulator output, Ji is a collection of indices,\nthe Lj are known functions of x, and \u03b4i is a stationary random field with zero mean,\nindependent of \u03b2 = (\u03b2(1), . . . , \u03b2(k)). The expression (5.2) is often termed a statistical\nemulator, or simply an emulator, for the function fi(x). The emulator expresses the\nbeliefs of the expert about the value of the function for each x, in a convenient and\neasily computable form. When the expert has specified probabilistic beliefs concerning\nthe coefficients \u03b2 and the parameters of the stationary field \u03b4i(x), then this automat-\nically generates probabilistic beliefs about the value of fi(x) for each x. The use of\nsuch emulators is standard within a wide range of analyses of computer experiment.\nMore details about the use of statistical emulators may be found in [6, 7].\nIt is often convenient to represent Lj as a product of polynomials in individual\ncomponents of x so that Ji comprises p-tuples of nonnegative integers (where p =\ndimX ), and\nLj(x) = Lj1(x1)Lj2(x2) \u00b7 \u00b7 \u00b7Ljp(xp),(5.3)\nwhere Lv(xk) is a polynomial of degree v in the kth component of x. For example, if\nX = [\u22121, 1]p, then the product of Legendre polynomials provides a basis for continuous\nsquared-integrable functions on X .\nThe \u03b4i field is parameterized by its covariance kernel. The choice\nCov [\u03b4i, \u03b4i\u2032 ] (x, x\n\u2032) = \u03a3\u03b4ii\u2032 exp(\u2212\u03b8 \u2016x\u2212 x\u2032\u20162), \u03b8 > 0,(5.4)\nis often used to reflect the belief that the underlying function f is very smooth, with\nderivatives of all orders everywhere in x. In geostatistics it is common to treat fi as\nstationary and model it entirely using \u03b4i and a careful choice of covariance kernel (or,\nequivalently, semivariogram; see [8]). In large problems with a relatively small number\nof evaluations we prefer to capture the main effects explicitly in a nonstationary model\nwith several carefully chosen Lj terms, using a combination of expert elicitation with a\ndetailed analysis of data from \u201ccoarsened\u201d versions of the simulator f , which run much\nfaster but are correspondingly less accurate. If \u03b4 contributes only a small amount of\nvariation to the model, our beliefs about f are driven primarily by our choices for\nL and our beliefs about the coefficients \u03b2. For simplicity we will largely ignore the\ncontribution of \u03b4 in the following discussion and treat it as a simple \u201cnugget\u201d with\ncovariance kernel\nCov [\u03b4i, \u03b4i\u2032 ] (x, x\n\u2032) =\n{\n\u03a3\u03b4ii\u2032 , x = x\n\u2032,\n0 otherwise.\n(5.5)\nRELATING MODELS AND SYSTEMS 479\nWhile we are at liberty to make any reasonable distributional assumptions for \u03b2\nand \u03b4, the inferential calculations for updating beliefs about f by the evaluations F\nare much simplified by taking \u03b2 to be Gaussian and \u03b4 to be a Gaussian random field\nindependent of \u03b2, in which case f is itself a Gaussian random field\u2014sometimes it may\nbe necessary to transform the output of the simulator to make this appropriate. In\nthis case the updating of beliefs about \u03b2 using the outcomes of the evaluations F is\nstraightforward because (F, \u03b2) is jointly Gaussian.\nFor inference, (2.5) still holds, but the distribution of (z, yf ) | x0 now has mean\n\u00b5(x0) and variance \u03ba(x0) + Var[\u0001] + Var[(e,0)], where \u00b5(x) = E[f ](x) is the mean\nfunction of f and \u03ba(x) = Var[f ](x) the variance kernel, both computed using updated\nbeliefs \u03b2 | F . This distribution is Gaussian if \u03b2, \u03b4, \u0001, and e are all Gaussian, and,\ncomputationally, this is a compelling reason for making this choice of distribution\n(perhaps after transforming the output of f) unless both the input and output spaces\nof f are small.\nThe zsr simulator provides an interesting challenge for emulation, because its\nequilibrium state may be solved analytically, while its transient behavior must be\nsolved numerically for given forcing (in this case, of environmental temperature and\nfresh-water flux through time). This is not unusual. Dynamic simulations are of-\nten started from equilibrium conditions, as a period of stability can be identified in\nthe system record (e.g., preindustrial climate) and this reduces the size of the in-\nput space. It is also quite common that we have some analytic knowledge of the\nequilibrium state (e.g., in the case of climate, from energy balance models). There-\nfore, the components of the emulator as indexed by time must make a transition\nfrom a specific functional form with well-known \u03b2 coefficients to a more generic func-\ntional form (e.g., a subset of a basis) with more uncertain \u03b2 coefficients. One way\nto achieve this is to take the collection {L1, L2, . . . } to be the union of the known\nand generic components and to arrange for the prior mean and variance of the set of\n\u03b2(i) vectors to reflect a transition from one to the other according to the time value\nof i.\nExample (cont). In our example, we have been treating f as a known function,\ne.g.,\nf(x, u) = ((ap + u)x, (af \u2212 u\/2)x).(5.6)\nIf we thought that f was only approximately of this form, then we might express this\nbelief through an emulator of the form\nf(x, u) = (ap0 + ap1x+ ap2ux+ \u03b4p, af0 + af1x+ af2ux+ \u03b4f ),(5.7)\nwhere we are uncertain about the 6-vector a = (ap, af ) = (ap0, . . . , af2). We treat\nthe 2-vector \u03b4 = (\u03b4p, \u03b4f ) as a simple nugget with variance \u03a3\n\u03b4, where the magnitudes\nof the variances quantify our beliefs about the quality of the approximation.\nTreating (5.7) as an emulator, we require prior beliefs about the quantities in a;\nwe will assume that they are jointly Gaussian, with given mean vector and variance\nmatrix, and independent of \u03b4. In our prior beliefs we might want conditions such\nas E[ap0] = E[af0] = 0, E[ap2] = 1, and af2 = \u2212ap2\/2 with probability 1. Having\nassigned the mean and variance, f(x) is a Gaussian random field with mean function\nand variance kernel\n480 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\n\u00b5(x, u) =\n(\nL(x, u)T\u00b5p\nL(x, u)T\u00b5f\n)\n,(5.8)\n\u03ba(x, u) =\n(\nL(x, u)T\u03a3ppL(x, u) L(x, u)\nT\u03a3pfL(x, u)\nL(x, u)T\u03a3fpL(x, u) L(x, u)\nT\u03a3ffL(x, u)\n)\n+\u03a3\u03b4,(5.9)\nwhere L(x, u) = (1, x, ux). Even before we evaluate the simulator we may make\ninferences about (x0, u0, yf ). Under the same assumptions as (4.7), our calibrated\nprediction calculation for the system is\np (x0, u0, yf | z) \u221d N2((z, yf ) | \u00b5(x0, u0),\u03a3(x0, u0))\u00d7 p (x0)\u00d7 p (u0) ,(5.10)\nwhere now\n\u03a3(x, u) = \u03ba(x, u) + \u03a3D + Var [\u0001] +\n(\nVar [e] 0\n0 0\n)\n.(5.11)\nThis is now a slightly more complicated calculation than (4.7), as the variance as well\nas the mean of the Gaussian density function varies with (x0, u0).\nThe only effect of performing evaluations of f in the above calculation is to change\nthe mean and variance of the vector of coefficients, a. This is because f separates F\nfrom the rest of the objects on the graph (5.1), and we have assumed a simple nugget\nform for \u03b4. Updated beliefs about a change the mean function and covariance kernel,\nand so affect the conditional distribution (x0, u0, yf ) | (z, F ), where we now add F\nto the conditioning set. Because calculations based on Gaussian emulators remain\ntractable even for large simulators we can use the emulator both in the inferential\ncalculation and also off-line, for example, to make informative choices of inputs at\nwhich to evaluate the simulator.\n6. Multiple simulators. In challenging problems we can expect there to be\nseveral different simulators for a given physical system. We have the choice of per-\nforming a rigorous probabilistic analysis for each simulator and then attempting an\ninformal synthesis at the end, or generalizing our approach outlined above to link mul-\ntiple simulators and the system within a single coherent belief model. Either way, we\nwill have to confront two questions: (i) how similar are the simulators to each other?\nand (ii) how \u201cgood\u201d is each simulator? Without answers to these questions we will\nnot know how to weigh the contribution from each simulator to our joint inference.\nThe natural and coherent approach is to link each of the simulators and the system\ntogether within a single belief model which fully accounts for the common and the\ndistinctive information about the system that is provided by each simulator.\n6.1. The \u201ctop\u201d simulator. The simplest case of multiple simulators occurs\nwhen we have only a single simulator f , but we want to weaken our assertion that\nthere exist a u0 and a \u0001D such that fD(x) = f(x, u0) \u2295 \u0001D(x). As with the direct\nsimulator and the system, this is a belief statement that f is \u201csufficiently good\u201d that\nwe can link it to fD via an unknown value u0 for u. If we do not think that f is\ntunable in this way, then we need to consider how f should be modified in order for it\nto be a tunable simulator. To make this link we introduce a second simulator which\nis sufficiently good but which we do not know. We denote this simulator the top\nRELATING MODELS AND SYSTEMS 481\nsimulator and write it f\u2217 : X \u00d7U \u2192 Y. This is represented in the following graphical\nmodel:\n\u0001D\n\u0005\u0005\u0002\n\u0002\u0002\n\u0002\u0002\n\u0002\u0002\n\u0002 u0\n\u0001\u0001\nf\n\u0001\u0001\n\u0002\u0002 f\u2217 \u0002\u0002 fD \u0002\u0002\u0003\u0003\u0003 same as (4.3)\nF\n(6.1)\nThus we use our runs F to tell us about fD, but in order to pass this information\nalong we must construct a joint model for (f, f\u2217).\nIn practice we will have described our beliefs about f in the form of an emulator\nsuch as (5.2). It is natural to describe our prior beliefs about the relationship between\nf and f\u2217 through the relationship between the emulators of the two functions. There-\nfore we construct an emulator for f\u2217 to express probabilistic beliefs about the value\nof f\u2217(x) for each x. For simplicity, at this stage, we suppose that we choose the same\nform as that of the emulator for f . This corresponds to the class of problems where\nwe have no information which would cause the expert to have qualitatively different\nbeliefs about the effects of changes of x on changes in f\u2217(x) than about the effect of\nsuch changes on f(x). If we had such information, then this would be reflected in the\nqualitative differences in the emulators that we would construct. Examples of such\nconstructions are given in section 6.3. Thus, for now, we suppose that the emulator\nis\nf\u2217i (x) =\n\u2211\nj\u2208Ji\n\u03b3\n(i)\nj Lj(x) + \u03b4\n\u2217\ni (x), i = 1, . . . , k,(6.2)\nand treat both (\u03b2, \u03b3) and (\u03b4, \u03b4\u2217) as jointly Gaussian. Then our beliefs about the\nrelationship between f and f\u2217 are described by the covariance between \u03b2 and \u03b3, and\nbetween \u03b4 and \u03b4\u2217.\nThis type of multiple-emulator construction is particularly useful when we have\nmore than one simulator for a physical system, as we will now discuss.\n6.2. Multiple simulators with the same input space. The simplest gen-\neralization to more than one actual simulator occurs for a collection of simulators\nwith the same input space. This will often happen when the solution method for\nconstructing the outputs for given inputs is very complicated and computationally\nexpensive. Consider, for example, a set of partial differential equations, to be solved\nby an implicit time-marching method. At each time point we must perform a large\n(sparse) matrix inversion. To perform the inversion we choose an iterative method.\nIt may be computationally infeasible with existing resources to iterate all the way to\nconvergence for every time-step, and, therefore, our simulator truncates the iteration\nafter a given number of steps, or when an error estimate becomes small. Hence we\ncan imagine a sequence of simulators, with different numbers of steps, all with the\nsame input space.\nLikewise, as technology improves it becomes possible to solve the same differential\nequations on a higher-resolution grid. With a careful treatment of spatial input fields\nthis can also give rise to a sequence of simulators with the same input space. In both\nof these cases it would be advantageous to combine the information from different\n482 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\nsimulators in a formal way. This would allow us to make informed choices about how\nbest to reduce our uncertainty about the system\u2014for example, by doing a few runs\nof a very expensive simulator, or many runs of a cheap one, or some combination of\nthe two. It also means that we do not have to discard or downgrade the results from\nan old simulator that becomes superseded by a better one. In weather forecasting,\nincreases in computing power have typically resulted in the construction of larger\nsimulators rather than in increased numbers of evaluations of existing simulators.\nFollowing the introduction of the top simulator, the treatment of multiple sim-\nulators with the same input space is conceptually simple. A joint model over all\navailable simulators and the top simulator allows us to pass information from each\nset of evaluations into our beliefs about fD. However, the way in which we choose to\nimplement the joint model will depend on the situation. The simplest case, and one\nthat often occurs in practice, is where there is a simple ranking across the simulators,\nso that we can easily say that simulator 2 is better than simulator 1. Both of the\nexamples given above tend to lead to rankings of this kind, with the better simulators\nhaving the greater number of iterations, or the higher spatio-temporal resolution. In\nthis case we might want to impose a Markov structure across simulators. This will\nboth reduce the number of uncertainty assessments that we need to make and also\nsimplify the computations that are required to update beliefs over the model given\nevaluations of the various simulators. Therefore, we might construct a joint model of\nthe form\n\u0001D\n\u0005\u0005\u0002\n\u0002\u0002\n\u0002\u0002\n\u0002\u0002\n\u0002 u0\n\u0001\u0001\nf1\n\u0001\u0001\n\u0002\u0002 f2\n\u0001\u0001\n\u0002\u0002 f\u2217 \u0002\u0002 fD \u0002\u0002\u0003\u0003\u0003 same as (4.3)\nF1 F2\n(6.3)\nwhere we have two simulators, and we understand the statement \u201cf2 is better than\nf1\u201d to mean that f2 separates f1 from the top simulator f\n\u2217. This Markov structure\nimposes strong restrictions on the joint distribution of the emulators\u2019 coefficients and\n\u03b4-terms, such that the emulators for f1 and f\n\u2217 are conditionally independent given\nthe emulator for f2.\nOf course, in many situations it will not be possible to give such an unambiguous\nranking. In such cases, we need to complete our specification in a way which does\nnot impose an ordering on the quality of the simulators. We now describe one such\napproach.\n6.3. General input spaces. Generally, we can expect that different simulators\nof the same physical system will not be easily rankable. Further, they may have dif-\nferent input spaces because of the different modelling assumptions and simplifications\nmade in translating the model into solvable form. In fact there can often be more\nsimulators than there are research groups. In ocean\/climate modelling a single group\nmight develop both a large-scale general circulation model and a faster but less ac-\ncurate intermediate complexity model, where the latter is not just a low-resolution\nversion of the former but incorporates a different treatment of the physics. It is also\ncommon to adopt a modular approach in the simulator options, in which subprocesses,\nRELATING MODELS AND SYSTEMS 483\nsuch as an oceanic carbon cycle, can be switched on or off. We cannot necessarily\nproceed as though the \u201coff\u201d simulator is just the \u201con\u201d simulator with some inputs set\nto zero. Integrated models, such as the Integrated Assessment Model being developed\nby the Tyndall Centre, take this a step further by defining a common interface that\nwill allow \u201cthird party\u201d modules to be linked together into a single simulator. In this\nmost general case we do not expect there to be a simple ranking across simulators,\nalthough certainly the experts will have beliefs that some simulators are better in\nsome respects than others.\nIn combining information from these simulators, the distinction between measur-\nable inputs and tuning inputs is helpful. Measurable inputs, being defined outside of\nany simulator, can be pooled across simulators. Tuning inputs, on the other hand,\nbelong to a given simulator. Consider the case of two simulators,\nfA : XA \u00d7 UA \u2192 Y, fB : XB \u00d7 UB \u2192 Y,(6.4)\nwhere XA = X 1\u00d7X 2 and XB = X 1\u00d7X 3, so that X 1 is common to both simulators.\nFollowing our previous approach, we need to consider a top simulator f\u2217 that both fA\nand fB are informative for. Its measurable input space is the union of the individual\ninput spaces, X \u2217 = XA \u222a XB = X 1 \u00d7 X 2 \u00d7 X 3, but its tuning input space is the\nproduct, U\u2217 = UA \u00d7 UB .\nIn the zsr example, we may consider that no simulator defined on the original\nmeasurable input space is sufficiently good to be treated as a direct simulator, i.e.,\nthat there is no top simulator defined on X but that a similar model with more\ncompartments might suffice. We could, for example, take each of the original four\ncompartments and subdivide them. In this way the compartment volumes and depths\nof the original model can be taken as linear combinations of those in the expanded\nmodel, so that the old input space is a subset of the new, which will simplify the\njoint statistical modelling of the two simulators. It is not necessary for us to build\nthis new simulator, but it is necessary for us to have beliefs about it, both in rela-\ntion to the original simulator and to the system, in order that we might construct\na probabilistic link between the four-compartment simulator that we have and the\nAtlantic ocean that we want to make inferences about. We consider that it is easier\nto think about the relationship between the four-compartment model and the more-\ncompartment model, and the more-compartment model and the Atlantic, than it is\nto think directly about the relationship between the four-compartment model and the\nAtlantic.\nThere is an alternative approach for the zsr example, which is to introduce a\nsecond actual simulator. The zsr paper concerns the fitting of the four-compartment\nmodel to a larger climate simulator of intermediate complexity, climber-2. It may\nbe that climber-2 is an indirect simulator for which a direct version is considered\nto exist. In this case the joint statistical modelling of the zsr model and climber-2\nis sufficient, in conjunction with beliefs about u0 and \u0001D(x) which relate climber-2\nto its directed version, and about x0 and \u0001, which relate that directed version to the\nAtlantic. Alternately, it may be that a direct version of climber-2 is not considered\nto exist, but there is a top simulator, perhaps climber-2 solved with smaller time-\nsteps. In this case the joint statistical modelling of the zsr model and climber-2\nmust be augmented with the joint statistical modelling of climber-2 and the top\nsimulator, and we may choose to impose a Markov structure on the three simulators.\nThen the top simulator must be related to the Atlantic through u0, \u0001D(x), x0, and \u0001,\nas before.\n484 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\nAnd, of course, it may be that no top simulator is thought to exist defined on the\nclimber-2 input space, in which case we must introduce a further simulator, say, an\nocean general circulation model (ogcm). In the statistical modelling of this ogcm\nand its relationship with climber-2 we may have a specific ogcm in mind, which\nwould be useful if we were able to utilize its evaluations, or we may have an ideal\nogcm in mind, which might simplify the modelling.\n6.4. Statistical modelling. Modelling the joint behavior of functions with dif-\nferent input spaces is extremely challenging. For reasons of space we can only sketch\nhere an approach based on the construction of additional emulators that are used to\nshare information across simulators. We consider two simulators\nfA : X 1 \u00d7X 2 \u2192 Y and fB : X 1 \u00d7X 3 \u2192 Y,(6.5)\nwhere, for simplicity, all inputs are measurable. We decompose each simulator into\northogonal emulators\nfA(x1, x2) = gA(x1)\u2295 gA(x1, x2),(6.6)\nfB(x1, x3) = gB(x1)\u2295 gB(x1, x3),(6.7)\nwhere gA(\u00b7) is the emulator for fA with x2 fixed at some baseline value and gA(\u00b7, \u00b7)\nis the \u201cresidual,\u201d with gA(\u00b7) independent of gA(\u00b7, \u00b7), and similarly for fB . If X 2 in\nsimulator A is providing separate information from X 3 in B, then we can express this\nin terms of orthogonality of the emulators across the two functions and take gA(\u00b7) and\ngB(\u00b7, \u00b7) to be independent; the same is true for gB(\u00b7) and gA(\u00b7, \u00b7). This belief model is\nmore easily understood in the following graphical model (where we include the input\nvalues for clarity):\nfA(x1, x2) fB(x\n\u2032\n1, x\n\u2032\n3)\ngA(x1)\n\u0006\u0006\n\u0007\u0007\ngA(x1, x2)\n\b\b\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\ngB(x\n\u2032\n1)\n\u0006\u0006\ngB(x\n\u2032\n1, x\n\u2032\n3)\n\b\b\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\u0004\n(6.8)\nThus, if we evaluate fA at (x1, x2), then this information passes through to fB at\n(x\u20321, x\n\u2032\n3) via the relationship between gA(x1) and gB(x\n\u2032\n1).\nNow we can connect both fA and fB to the top simulator f\n\u2217 after decomposing\nf\u2217 into four orthogonal emulators\nf\u2217(x1, x2, x3) = g\u2217(x1)\u2295 g\u2217(x1, x2)\u2295 g\u2217(x1, x3)\u2295 g\u2217(x1, x2, x3),(6.9)\nwhere the final term comprises information that we cannot infer from either fA or fB .\nWe connect the three functions through emulators with common input spaces to give\nthe full joint model, in which we also include evaluations FA and FB and the direct\nRELATING MODELS AND SYSTEMS 485\nsimulator fD:\nFA FB\nfA(x1, x2)\n\u0006\u0006\nfB(x\n\u2032\n1, x\n\u2032\n3)\n\u0006\u0006\ngA(x1)\n\u0006\u0006\n\t\t\n\n\n\u0005\u0005\u0005\u0005\n\u0005\u0005\u0005\u0005\u0005\n\u0005\u0005\u0005\u0005\u0005\n\u0005\u0005\u0005\u0005\u0005\n\u0005\u0005\u0005\u0005\u0005\n\u0005\u0005\u0005 gA(x1, x2)\n\u000b\u000b\u0006\u0006\u0006\u0006\u0006\u0006\u0006\u0006\u0006\u0006\u0006\n\u0001\u0001\ngB(x\n\u2032\n1)\n\u0006\u0006\n\u0001\u0001\ngB(x\n\u2032\n1, x\n\u2032\n3)\n\u000b\u000b\u0006\u0006\u0006\u0006\u0006\u0006\u0006\u0006\u0006\u0006\u0006\u0006\n\u0001\u0001\ng\u2217(x\u2032\u20321 , x\n\u2032\u2032\n2 , x\n\u2032\u2032\n3)\n\f\f\ng\u2217(x\u2032\u20321 , x\n\u2032\u2032\n2)\n\t\t\u0006\u0006\n\u0006\u0006\u0006\n\u0006\u0006\u0006\n\u0006\u0006\u0006\ng\u2217(x\u2032\u20321)\n\u0001\u0001\ng\u2217(x\u2032\u20321 , x\n\u2032\u2032\n3)\n\r\r\u0007\u0007\u0007\n\u0007\u0007\u0007\n\u0007\u0007\u0007\n\u0007\u0007\nf\u2217(x\u2032\u20321 , x\n\u2032\u2032\n2 , x\n\u2032\u2032\n3)\n\u0001\u0001\nfD\n(6.10)\nwhere the second and third rows are the same as (6.8), and the third and fourth rows\nconnect like emulators into the decomposition of f\u2217. The graphical model continues\nthrough fD in the same way as (6.3).\nIf we want to model the belief that fB is a better model than fA, we can by\nstrengthening the correlations between gB(x\n\u2032\n1) and g\n\u2217(x\u2032\u20321) and\/or between gB(x\n\u2032\n1, x\n\u2032\n3)\nand g\u2217(x\u2032\u20321 , x\n\u2032\u2032\n3) in (6.10). This kind of model gives us a high level of control in stating\nexactly how it is that B is better than A, because of the multiple but still clearly\ndelineated paths from fA and fB to f\n\u2217. For example, we could model the situation\nin which fB has a higher resolution than fA, but fA contains a subprocess that fB\nignores. This often happens in practice, where additional complexity can only be\nachieved by sacrificing resolution.\nThe inferential calculations may be computationally quite challenging, not least\nthe accounting necessary to construct and use a belief model such as (6.10). However,\nthe inferential procedure is unambiguous, and the meaning of the various uncertainty\nstatements is clear. The emulators, the top simulator, and the direct simulator form\nthe logical links that relate evaluations of our collection of actual simulators to the\nsystem and give meaning to the various uncertainties that separate our simulators\nfrom that system.\n7. Discussion. Computer simulators embodying complex mathematical models\nare increasingly the method of choice for studying large-scale physical systems. While\nthis approach offers many opportunities, it is also open to gross abuse, unless we are\nvery clear as to the limitations of such models when used as surrogates for the system\nitself. Explicit assessment of the difference between the system and models of the\nsystem is, therefore, of fundamental importance.\nIn this paper, we have outlined a general approach for structuring the uncertain-\nties which arise in transferring inferences from models, typically computer simulators,\nto physical systems. To do this, we have introduced ingredients which go substan-\ntially beyond the kinds of reasoning that are currently offered to justify the relevance\nof computer-based analyses. Does this mean that our formulation is overelaborate?\n486 MICHAEL GOLDSTEIN AND JONATHAN ROUGIER\nWe would argue quite the opposite, namely, that our specification has been stripped\ndown to the barest minimum of ingredients which must be in place before we can even\nattempt the task of relating the model to the system. It is incumbent on the analyst\neither to make use of a formulation along the lines that we have suggested or to sug-\ngest an alternative logic for developing such relationships as may exist between the\nmodel analysis and the phenomena in question. However, we know of no systematic\nalternative approach which may form the basis of such a development.\nWe consider that there are two principle advantages inherent in using our struc-\ntured uncertainty approach. The first advantage of the approach is in achieving con-\nsistency and accuracy in the specification of all the relevant aspects of uncertainty.\nIt may be daunting for the analyst even to consider how a single model, with many\nunknown inputs and many outputs, may be linked to a corresponding physical sys-\ntem. Therefore, it is helpful to separate out, for careful, individual consideration, the\nvarious aspects of the relationship between the model and the system, within a fully\ncoherent framework. Such representations are even more important for those prob-\nlems which are informed by a wide variety of computer models. Seldom do the various\nmodels represent fully independent sources of information about the system, and it\nis essential to distinguish information that is common to several of the models from\ninformation that is specific to a particular model. We know of no other formulation\nwhich will allow us to do this to a high level of generality.\nSecond, the approach helps to achieve clarity. Model-based inference is not a pri-\nvate activity, and the objective of a scientific analysis is to make a clear and convincing\ncase to the wider community concerning the behavior of the physical system to which\neach of the models relates. This is not possible unless the logic of the argument is\nmade transparent, and this can only be achieved by attaching uncertainty statements\nto well-defined quantities, so that the meaning of each part of the analysis is clear,\nand carrying out a careful sensitivity analysis over each aspect of the specification, so\nthat the degree to which the scientific conclusions depends on each of the underlying\nassumptions can be fully understood.\nIn conclusion, we would hope that forms of reasoning similar to those that we have\ndescribed will be taken up in general as part of the standard methodology for reasoning\nabout computer experiments and, in particular, in specific applications, where highly\nspecialized versions of these structures may be constructed after careful and expert\nconsideration. This points to both the need for a software interface to aid in building\nand analyzing such extended models, and also the value in developing elicitation\ntools to aid the experts in specifying beliefs over such elaborate constructions. For a\ndiscussion of aspects of the construction of such tools, see [7].\nREFERENCES\n[1] J. Bernardo and A. Smith, Bayesian Theory, John Wiley & Sons, Chichester, UK, 1994.\n[2] D. B. Chelton, Physical oceanography: A brief overview for statisticians, Statist. Sci., 9\n(1994), pp. 150\u2013166.\n[3] A. Colling, Ocean Circulation, Butterworth-Heinemann, Boston, 2001.\n[4] R. Cowell, A. Dawid, S. Lauritzen, and D. Spiegelhalter, Probabilistic Networks and\nExpert Systems, Springer-Verlag, New York, 1999.\n[5] P. Craig, M. Goldstein, J. Rougier, and A. Seheult, Bayesian forecasting for complex\nsystems using computer simulators, J. Amer. Statist. Assoc., 96 (2001), pp. 717\u2013729.\n[6] P. Craig, M. Goldstein, A. Seheult, and J. Smith, Pressure matching for hydrocarbon\nreservoirs: A case study in the use of Bayes linear strategies for large computer exper-\niments, in Case Studies in Bayesian Statistics, Vol. 3, C. Gatsonis, J. Hodges, R. Kass,\nRELATING MODELS AND SYSTEMS 487\nR. McCulloch, P. Rossi, and N. Singpurwalla, eds., Lecture Notes in Statist. 121, Springer-\nVerlag, New York, 1997, pp. 37\u201393, with discussion.\n[7] P. Craig, M. Goldstein, A. Seheult, and J. Smith, Constructing partial prior specifica-\ntions for models of complex physical systems, The Statistician, 47 (1998), pp. 37\u201353, with\ndiscussion.\n[8] N. A. C. Cressie, Statistics for Spatial Data, John Wiley & Sons, New York, 1991.\n[9] J. Houghton, Y. Ding, D. Griggs, M. Noguer, P. van de Linden, X. Dai, K. Maskell,\nand C. Johnson, eds., Climate Change 2001: The Scientific Basis. Contribution of Work-\ning Group 1 to the Third Assessment Report of the Intergovernmental Panel on Climate\nChange, Cambridge University Press, Cambridge, UK, 2001.\n[10] F. Jensen, Bayesian Networks and Decision Graphs, Springer-Verlag, New York, 2001.\n[11] M. Kennedy and A. O\u2019Hagan, Bayesian calibration of computer models, J. R. Stat. Soc. Ser.\nB Stat. Methodol., 63 (2001), pp. 425\u2013464, with discussion.\n[12] National Research Council (NRC), Report on statistics and physical oceanography, Statist.\nSci., 9 (1994), pp. 167\u2013221, with discussion.\n[13] J. Peixoto and A. Oort, Physics of Climate, Springer-Verlag, New York, 1992.\n[14] C. Robert and G. Casella, Monte Carlo Statistical Methods, Springer-Verlag, New York,\n1999.\n[15] J. Sachs, W. Welch, T. Mitchell, and H. Wynn, Design and analysis of computer experi-\nments, Statist. Sci., 4 (1989), pp. 409\u2013435, with discussion.\n[16] G. Thomas, Principles of Hydrocarbon Reservoir Simulation, International Human Resources\nDevelopment Corporation, Boston, 1982.\n[17] K. Zickfeld, T. Slawig, and S. Rahmstorf, A low-order model for the response of the\nAtlantic thermohaline circulation to climate change, Ocean Dynamics, 54 (2004), pp. 8\u2013\n26.\n"}
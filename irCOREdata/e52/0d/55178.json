{"doi":"10.1016\/j.jfoodeng.2010.01.010","coreId":"55178","oai":"oai:eprints.lincoln.ac.uk:2206","identifiers":["oai:eprints.lincoln.ac.uk:2206","10.1016\/j.jfoodeng.2010.01.010"],"title":"Visual detection of blemishes in potatoes using minimalist boosted classifiers","authors":["Barnes, Michael","Duckett, Tom","Cielniak, Grzegorz","Stroud, Graeme","Harper, Glyn"],"enrichments":{"references":[{"id":18445633,"title":"A computer vision system for appearance-based descriptive sensory evaluation of meals.","authors":[],"date":"2007","doi":"10.1016\/j.jfoodeng.2005.09.033","raw":"Munkevik, P., Hall, G., Duckett, T., 2007. A computer vision system for appearance-based descriptive sensory evaluation of meals. Journal of Food Engineering 78, 246 { 256.","cites":null},{"id":18445613,"title":"A short introduction to boosting.","authors":[],"date":"1999","doi":null,"raw":"Freund, Y., Schapire, R., September 1999. A short introduction to boosting. Journal of Japanese Society for Articial Intelligence 14 (5), 771 { 780.","cites":null},{"id":18445644,"title":"A statistical approach to texture classi from single images.","authors":[],"date":"2005","doi":"10.1007\/s11263-005-4635-4","raw":"Varma, M., Zisserman, A., 2005. A statistical approach to texture classi-cation from single images. International Journal of Computer Vision 62, 61{81.","cites":null},{"id":18445615,"title":"An automated inspection station for machine-cision grading of potatoes.","authors":[],"date":"1996","doi":"10.1007\/bf01246635","raw":"Heinemann, P. H., Pathare, N. P., Morrow, C. T., 1996. An automated inspection station for machine-cision grading of potatoes. Machine Vision and Applications 9 (1), 14{19.","cites":null},{"id":18445617,"title":"An experimental machine vision system for sorting sweet taramind.","authors":[],"date":"2008","doi":"10.1016\/j.jfoodeng.2008.05.007","raw":"Jarimopas, B., Jaisin, N., 2008. An experimental machine vision system for sorting sweet taramind. Journal of Food Engineering 89, 291 { 297.","cites":null},{"id":18445635,"title":"An improvement of AdaBoost to avoid over In:","authors":[],"date":"1998","doi":"10.1007\/978-1-4471-1599-1_26","raw":"Ratsch, G., Onoda, T., Muller, K. R., 1998. An improvement of AdaBoost to avoid overtting. In: Proceedings of the International Conference on Neural Information Processing. pp. 506{509.","cites":null},{"id":18445614,"title":"Automatic detecting and grading method of potatoes with computer vision.","authors":[],"date":"2009","doi":null,"raw":"Guannan, Z., Yuzhi, T., Junxiong, Z., Wei, L., 2009. Automatic detecting and grading method of potatoes with computer vision. Nongye Jixie Xuebao \/ Transactions of the Chinese Society of Agricultural Machinery 40 (4), 166{168+1.","cites":null},{"id":18445632,"title":"Defect and disease detection in potato tubers. In:","authors":[],"date":"1999","doi":"10.1117\/12.336883","raw":"Muir, A. J., Ross, D. W., Dewar, C. J., Kennedy, D., 1999. Defect and disease detection in potato tubers. In: Proceedings of SPIE - The International Society for Optical Engineering. Vol. 3543. pp. 199{207.","cites":null},{"id":18445639,"title":"Fourier-based separation technique for shape grading of potatoes using machine vision.","authors":[],"date":"1995","doi":"10.13031\/2013.27912","raw":"14Tao, Y., Morrow, C. T., Heinemann, P. H., 1995b. Fourier-based separation technique for shape grading of potatoes using machine vision. Transactions of the American Society of Agricultural Engineers 38 (3), 949{957.","cites":null},{"id":18445646,"title":"GML AdaBoost MATLAB Toolbox. URL http:\/\/research.graphicon.ru","authors":[],"date":"2006","doi":null,"raw":"Vezhnevets, A., 2006. GML AdaBoost MATLAB Toolbox. URL http:\/\/research.graphicon.ru Zhou, L., Chalana, V., Kim, Y., 1998. Pc-based machine vision system for real-time computer-aided potato inspection. International Journal of Imaging Systems and Technology 9 (6), 423{433.","cites":null},{"id":18445631,"title":"Guiding model search using segmentation. In:","authors":[],"date":"2005","doi":"10.1109\/iccv.2005.112","raw":"Mori, G., 2005. Guiding model search using segmentation. In: ICCV '05: Proceedings of the Tenth IEEE International Conference on Computer Vision. Vol. 2. pp. 1417 { 1423.","cites":null},{"id":18445634,"title":"Highspeed potato grading and quality inspection based on a color vision system. In:","authors":[],"date":"2000","doi":"10.1117\/12.380075","raw":"Noordam, J., Otten, G., Timmermans, T., van Zwol, B., March 2000. Highspeed potato grading and quality inspection based on a color vision system. In: Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series. Vol. 3966 of Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series. pp. 206{217.","cites":null},{"id":18445637,"title":"Improved boosting algorithms using con predictions. In:","authors":[],"date":"1998","doi":"10.1145\/279943.279960","raw":"Schapire, R., Singer, Y., 1998. Improved boosting algorithms using condence-rated predictions. In: Proceedings of the Eleventh Annual Conference on Computational Learning Theory. pp. 80{91.","cites":null},{"id":18445612,"title":"Improved diagnosis of powdery scab (spongospora subterranea f.sp. subterranea) symptoms on potato tubers (solanum tuberosum l.).","authors":[],"date":"2005","doi":"10.1007\/bf02733677","raw":"De Haan, E. G., van den Bovenkamp, G. W., 2005. Improved diagnosis of powdery scab (spongospora subterranea f.sp. subterranea) symptoms on potato tubers (solanum tuberosum l.). Potato Research 48 (1-2), 1{14.","cites":null},{"id":18445630,"title":"Inspection of the distribution and amount of ingredients in pasteurized cheese by computer vision.","authors":[],"date":"2007","doi":"10.1016\/j.jfoodeng.2006.12.020","raw":"13Jelinski, T., jin Du, C., Sun, D.-W., Fornal, J., 2007. Inspection of the distribution and amount of ingredients in pasteurized cheese by computer vision. Journal of Food Engineering 83, 3 { 9.","cites":null},{"id":18445638,"title":"Machine vision for color inspection of potatoes and apples.","authors":[],"date":"1995","doi":"10.13031\/2013.27982","raw":"Tao, Y., Heinemann, P. H., Varghese, Z., 1995a. Machine vision for color inspection of potatoes and apples. Transactions of the American Society of Agricultural Engineers 38 (5), 1555{1561.","cites":null},{"id":18445636,"title":"Meeting with representatives of R.J.","authors":[],"date":"2008","doi":null,"raw":"R.J. Herbert Engineering Ltd, October 2008. Meeting with representatives of R.J. Herbert Engineering Ltd., Marshland St. James, Cambridgeshire, UK. (http:\/\/www.rjherbert.co.uk\/).","cites":null},{"id":18445616,"title":"Omni-directional face detection based on Real AdaBoost.","authors":[],"date":"2005","doi":"10.1109\/icip.2004.1418824","raw":"Huang, C., Wu, B., Al, H., Lao, S., 2005. Omni-directional face detection based on Real AdaBoost. In: International Conference of Computer Vision.","cites":null},{"id":18445640,"title":"Rotation-invariant pattern matching with colourring projection.","authors":[],"date":"2002","doi":"10.1016\/s0031-3203(00)00180-1","raw":"Tsai, D., Tsai, Y., 2002. Rotation-invariant pattern matching with colourring projection. Pattern Recognition 35, 131{141.","cites":null},{"id":18445641,"title":"Stem and calyx recognition on 'jonagold' apples by pattern recognition.","authors":[],"date":"2006","doi":"10.1016\/j.jfoodeng.2005.10.038","raw":"Unay, D., Gosselin, B., 2006. Stem and calyx recognition on 'jonagold' apples by pattern recognition. Journal of Food Engineering 78, 597 { 605.","cites":null},{"id":18445611,"title":"Veggievision: A produce recognition system. In:","authors":[],"date":"1996","doi":"10.1109\/acv.1996.572062","raw":"Bolle, R., Connell, J., Haas, N., Mohan, R., Taubin, G., 1996. Veggievision: A produce recognition system. In: Proceedings of the 3rd IEEE Workshop on Applications of Computer Vision (WACV '96). IEEE Computer Society, Washington, DC, USA, p. 244.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-06","abstract":"This paper introduces novel methods for detecting blemishes in potatoes using machine vision. After segmentation of the potato from the background, a pixel-wise classifier is trained to detect blemishes using features extracted from the image.\\ud\nA very large set of candidate features, based on statistical information relating to the colour and texture of the region surrounding a given pixel, is first extracted.\\ud\nThen an adaptive boosting algorithm (AdaBoost) is used to automatically select the best features for discriminating between blemishes and non-blemishes.\\ud\nWith this approach, different features can be selected for different potato varieties, while also handling the natural variation in fresh produce due to different seasons, lighting conditions, etc.\\ud\nThe results show that the method is able to build ``minimalist'' classifiers that optimise detection performance at low computational cost.\\ud\nIn experiments, blemish detectors were trained for both white and red potato varieties, achieving 89.6\\% and 89.5\\% accuracy, respectively","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/55178.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/2206\/1\/barnes09visualdetection.pdf","pdfHashValue":"793aaca7c905bf72cca38caa354a4e88f090868c","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:2206<\/identifier><datestamp>\n      2013-11-18T16:09:36Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F47:6A6163735F47343030<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F44:6A6163735F44363130<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F47:6A6163735F47373430<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/2206\/<\/dc:relation><dc:title>\n        Visual detection of blemishes in potatoes using minimalist boosted classifiers<\/dc:title><dc:creator>\n        Barnes, Michael<\/dc:creator><dc:creator>\n        Duckett, Tom<\/dc:creator><dc:creator>\n        Cielniak, Grzegorz<\/dc:creator><dc:creator>\n        Stroud, Graeme<\/dc:creator><dc:creator>\n        Harper, Glyn<\/dc:creator><dc:subject>\n        G400 Computer Science<\/dc:subject><dc:subject>\n        D610 Food Science<\/dc:subject><dc:subject>\n        G740 Computer Vision<\/dc:subject><dc:description>\n        This paper introduces novel methods for detecting blemishes in potatoes using machine vision. After segmentation of the potato from the background, a pixel-wise classifier is trained to detect blemishes using features extracted from the image.\\ud\nA very large set of candidate features, based on statistical information relating to the colour and texture of the region surrounding a given pixel, is first extracted.\\ud\nThen an adaptive boosting algorithm (AdaBoost) is used to automatically select the best features for discriminating between blemishes and non-blemishes.\\ud\nWith this approach, different features can be selected for different potato varieties, while also handling the natural variation in fresh produce due to different seasons, lighting conditions, etc.\\ud\nThe results show that the method is able to build ``minimalist'' classifiers that optimise detection performance at low computational cost.\\ud\nIn experiments, blemish detectors were trained for both white and red potato varieties, achieving 89.6\\% and 89.5\\% accuracy, respectively.<\/dc:description><dc:publisher>\n        Elsevier<\/dc:publisher><dc:date>\n        2010-06<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/2206\/1\/barnes09visualdetection.pdf<\/dc:identifier><dc:identifier>\n          Barnes, Michael and Duckett, Tom and Cielniak, Grzegorz and Stroud, Graeme and Harper, Glyn  (2010) Visual detection of blemishes in potatoes using minimalist boosted classifiers.  Journal of Food Engineering, 98  (3).   pp. 339-346.  ISSN 0260-8774  <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1016\/j.jfoodeng.2010.01.010<\/dc:relation><dc:relation>\n        10.1016\/j.jfoodeng.2010.01.010<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/2206\/","http:\/\/dx.doi.org\/10.1016\/j.jfoodeng.2010.01.010","10.1016\/j.jfoodeng.2010.01.010"],"year":2010,"topics":["G400 Computer Science","D610 Food Science","G740 Computer Vision"],"subject":["Article","PeerReviewed"],"fullText":"Visual Detection of Blemishes in Potatoes using\nMinimalist Boosted Classifiers\nMichael Barnes1, Tom Duckett1, Grzegorz Cielniak1, Graeme Stroud2 and\nGlyn Harper2\n1School of Computer Science, University of Lincoln, Lincoln LN6 7TS, UK\n2Potato Council Ltd., Sutton Bridge Experimental Unit, Spalding PE12 9YD, UK.\nAbstract\nThis paper introduces novel methods for detecting blemishes in potatoes\nusing machine vision. After segmentation of the potato from the background,\na pixel-wise classifier is trained to detect blemishes using features extracted\nfrom the image. A very large set of candidate features, based on statistical\ninformation relating to the colour and texture of the region surrounding a\ngiven pixel, is first extracted. Then an adaptive boosting algorithm (Ad-\naBoost) is used to automatically select the best features for discriminating\nbetween blemishes and non-blemishes. With this approach, different features\ncan be selected for different potato varieties, while also handling the natu-\nral variation in fresh produce due to different seasons, lighting conditions,\netc. The results show that the method is able to build \u201cminimalist\u201d clas-\nsifiers that optimise detection performance at low computational cost. In\nexperiments, blemish detectors were trained for both white and red potato\nvarieties, achieving 89.6% and 89.5% accuracy, respectively.\nKey words:\n1. Introduction\nPotatoes (Solanum tuberosum), with an estimated worldwide production\nof over 300,000,000 tonnes in 2005 (Food and Agriculture Organisation,\n2005), account for 70-80% of the carbohydrate consumed in the UK with\nmillions of tons harvested worldwide. For the fresh market the main fac-\ntor affecting consumer preference is physical appearance and, to maximise\nreturn, great effort is expended ensuring that the appearance best matches\nPreprint submitted to Food Engineering January 25, 2010\na particular market. There are no current legislation standards for tuber\nblemishes but standards are driven by market forces, principally by the re-\nquirements of the larger supermarkets\u2019 customers. Most potatoes are still\nsorted by hand. Problems with manual sorting include the subjectivity, fa-\ntigue and high cost of human inspectors, while currently deployed artificial\nvision systems require manual calibration and have limited accuracy. There\nare a number of biological techniques used to identify potato diseases, includ-\ning microscopy and methods based on the recognition of proteins or DNA\nof the pathogen, e.g. De Haan and van den Bovenkamp (2005). However,\nalthough the methods are accurate and may be sensitive enough to detect\ndisease before symptoms develop, they are time-consuming and not suited\nto the individual assessment of potatoes on a commercial scale. Thus there\nis considerable motivation for automating visual inspection.\nIn typical machine vision systems for quality analysis of food products,\nthere are several major steps: after pre-processing (e.g. to segment the ob-\nject of interest from the background), image features are extracted that sum-\nmarise important qualities of the object, then a pattern recognition system\nis used to categorise the input data. For example, Bolle et al. (1996) de-\nveloped the VeggieVision system, using HSV-colour and texture histograms\nto classify different types of fruit and vegetables, with application to a su-\npermarket check-out for automatic produce recognition. Unay and Gosselin\n(2006) developed methods to distinguish between blemishes in apples and\nhealthy apples with visible stem or calyx. Images were recorded using spe-\ncial filters to restrict the observed light frequencies, then various features\nincluding statistical moments and shape features were used for pattern recog-\nnition. Jelinski et al. (2007) introduced visual inspection methods for pas-\nteurised cheese. They also used thresholding to detect ingredients such as\nchives, and developed methods to measure the distribution and quantity of\nthe detected ingredients. Munkevik et al. (2007) developed a machine vision\nsystem for automatic descriptive sensory evaluation of meals, where a neural\nnetwork was trained to mimic the opinion of human experts in describing\nthe sensory attributes of a prototypical meal. Jarimopas and Jaisin (2008)\nintroduced a system for sorting sweet tamarind, by measuring the size and\nshape of tamarind pods as well as detecting defects in the form of broken\npods. Thresholded intensity values were used to distinguish blemishes from\nnon-blemishes.\nIn the area of machine vision for potatoes, Tao et al. (1995b) used Fourier\nharmonics to describe the shapes of potatoes, forming a metric based on the\n2\nfirst ten Fourier harmonics of the potato\u2019s outline to develop a classification\nmethod which agreed with human classification 89.2% of the time. Muir\net al. (1999) used custom lighting equipment to project light at a variety\nof different wavelengths to demonstrate the different reflective properties of\nspecific blemishes at each wavelength. This work was commissioned in part\nby R.J. Herbert Engineering for use in their Upgrader product line (R.J.\nHerbert Engineering Ltd, 2008). Tao et al. (1995a) describes the use of the\nHSI colour space for identifying greened potatoes as well as yellow and green\napples. This was done by use of histograms produced from each of the HSI\nchannels. It was noted that more bins in a histogram resulted in a higher\nperformance. Heinemann et al. (1996) graded potatoes by size and shape to\nmeet United States Department of Agriculture (USDA) standards. Size was\nmeasured by the longest distance between two points on the boundary, while\nthe shape was determined using Fourier descriptors. The system achieved 97-\n98% accurracy when classifying stationary potatoes but dropped to between\n77% and 88% when tested on moving potatoes. Zhou et al. (1998) developed\na system using green levels to detect green defects (greening and sprouting)\nin individual potatoes. They also classified potatoes in terms of shape by\ncomparison to an ellipse template, and in size and weight by measuring the\nminor axis and area, respectively. These were compared to USDA standards\nwith an overall success rate of 86.5% with a false positive rate of 57.1%.\nWithout the blemish detection the results improved to 90% overall success\nrate with 17% false positives. Guannan et al. (2009) detected misshapen\npotatoes by comparing the local rate of change of the radius of a potato.\nIn addition they detected sprouting using a comparison of the green colour\nchannel with the intensity. This value at each pixel was compared to the\naverage value across the potato and if the difference was above a threshold\nthe pixel was determined to be part of a sprout. We have also investigated\nthe use of features that are summarised across the whole potato.\nA limitation of typical machine vision systems is that the set of image\nfeatures for pattern recognition has to be designed by the system engineer\nto work with a specific configuration of produce, imaging system and op-\nerating conditions. Such systems typically do not generalise well to other\nconfigurations, where the required image features may well differ from those\nused to design the original system. The novelty of the approach presented\nin this paper involves the use of an adaptive boosting algorithm called Ad-\naBoost (Freund and Schapire, 1999) to automatically select good features for\na particular pattern recognition task. A minimal set of features is selected\n3\nfrom a very large set of candidate features, which measure statistical proper-\nties of the colour and texture distribution of the image region surrounding a\ngiven pixel. Thus the selected features used to build the final pattern recog-\nnition system are optimised for a particular application by learning from\nexamples, and the system can be retrained to select a different set of features\nin order to accommodate different varieties of produce, seasonal variations,\netc.\nThe objective of this research is to introduce an automatic method for de-\ntecting blemishes in digital images of potatoes. The system developed should\nbe trainable, so that it can work with different varieties of potatoes and varia-\ntions in seasons, lighting conditions, etc. A human expert is required to mark\nup areas of blemishes and non-blemishes in a set of training images. After\ntraining, the system should be able to classify individual pixels as blemishes\nor non-blemishes with high accuracy. A further objective, with eventual de-\nployment in industrial settings in mind, is to enable real-time processing of\nimages (possibly in rapid succession) by building \u201cminimalist\u201d classifiers that\nextract a minimal subset of all features that optimise detection performance\nat the lowest possible computational cost. Finally the feature selection mech-\nanism developed should be perspicuous to human users, allowing operators\nto understand which features are important to distinguish blemishes from\nnon-blemishes for different potato varieties. The contribution of the paper\ntowards meeting these objectives is demonstrated in experiments by learn-\ning minimalist blemish detectors for both white and red potatoes, achieving\n89.6% and 89.5% accuracy, respectively.\n1.1. Potato Blemishes\nThere are a number of conditions affecting potato tubers that, although\nsuperficial and of no health consequence to humans, strongly and negatively\ninfluence consumer choice. These include black dot, silver scurf, powdery\nscab, common scab and skin spot. The fungal species of Rhizoctonia solani\nalso causes significant skin blemish as black scurf and elephant hide. The\ncauses of blemishes are known. However, customer preference may be for\nsusceptible potato varieties, and different environmental and field conditions\nduring cultivation favour different diseases. These inevitably lead to some\ncrops being infected in a generally unpredictable fashion. Other forms of\nblemish include physical damage, e.g. growth cracks, mechanical damage\nand slug damage, as well as physiological effects, e.g. greening and sprout-\ning. Figure 1 shows examples of several common blemishes. Potatoes and\n4\ntheir tubers are also susceptible to more significant diseases, in particular\nblight, and other fungal and bacterial rots that are outside the scope of\nthe work presented here. Blemish conditions present a variety of different\ncoloured, sized and textured symptoms on the skin surface. Such diverse\nvisual information provides us with a rich source of indicators that can be\nused for training an automatic blemish detector. In this paper, our collected\nimage data contained the following subset of these potato blemishes: black\ndot, silver scurf, common scab, slug damage, greening, powdery scab, ele-\nphant hide, sprouting and growth cracks. These were the blemishes present\nin the potato samples collected from the Spring 2008 harvest at the Sutton\nBridge Experimental Unit of the Potato Council Limited, UK. In this article\nour research focus is on detection of blemish versus non-blemish.\n2. Materials and methods\n2.1. Image Acquisition\nThe experimental data for this system, consisting of images of potatoes,\nwere acquired using a colour camera (Sony DSLR-A350K) fixed above the\ntubers, which in turn were placed on a white board. The camera was set\nto autofocus at a distance of 60cm from the camera objective to the base\non which the subjects were placed, with a focal length of 70 mm and an\naperture setting of F22. The resolution of the images was 1536\u00d71024 pixels.\nIn industrial settings a different camera might be used, but due to the use\nof machine learning classifiers in our approach, the system should work with\nany similar colour imaging device. A pixel in such an image covers an area\nof around 0.02 mm2. To reduce the effects of shadows and changing light\nconditions the potatoes were placed inside a white cylinder with daylight\nbulbs placed around the top. The equipment used to capture these images\nis shown in Figure 2.\n2.2. Data Sets and Ground Truth Information\nThere were two sets of data collected for white and red potatoes, respec-\ntively, including potatoes affected by different blemishes. The white potato\ndata set consisted of 102 images including 19 images containing a single blem-\nish type, 39 images with two distinct blemish types, 38 images with three\nblemish types and 6 images containing more than three blemish types. The\nmost common blemishes were black dot and silver scurf, appearing in 69 and\n53 images, respectively, while the rarest were powdery scab, elephant hide\n5\nand growth cracks, with no more than 3 images of each. The red potato data\nset consisted of 22 images with the most common blemishes again being black\ndot and silver scurf, appearing in 13 and 6 images, respectively, as well as\ncommon scab, appearing in 12 cases. 10 red potato images had 2 different\nblemish types, 3 images had 3 types, 1 image had 4 types, and the remaining\n8 images had only one blemish type.\nTo train the classifiers and test their performance, the images need to\nbe marked up by hand to provide the \u201cground truth\u201d information indicating\nthe correct class of each pixel. The mark up process begins with a semi-\nautomatic method for background removal, using the Magic Wand tool in\nAdobe Photoshop to label the image region surrounding the potato. The\npotato area is then hand labelled by an industry expert into regions corre-\nsponding to blemish and non-blemish. It is not necessary to label all pixels in\nan image: some areas of high uncertainty or ambiguity were left unmarked in\nour experiments, and these pixels are ignored during training of the classifier.\nBackground pixels are also omitted from the subsequent calculations.\nSome examples of the obtained ground truth images can be seen in the\nleft column of Figure 7.\n2.3. Feature extraction\nThe first step of the procedure is to extract different image features that\nshould indicate the presence or absence of blemishes in a potato image. The\nfeatures include statistical summaries of the whole potato and local regions\ncentred on each pixel as well as the data of the pixel itself. The statistics\nused were the mean, variance and skew of various image properties listed\nbelow. Other systems have used only the mean of the region such as Tsai\nand Tsai (2002) or histograms as in Bolle et al. (1996). The proposed system\nuses the RGB colour space, the original colour format of the camera out-\nput. An alternative solution would be to use the HSI colour space but this\nwould create an additional processing overhead including colour conversion\nand calculation of circular statistics. Other systems use more complex hard-\nware set-ups such as customised lighting, as is an option for the Maf-Roda\nAgrobotic (Maf Roda Group, 2008) or using specific colour filters as in Unay\nand Gosselin (2006). The code for the system software was implemented in\nMATLAB.\nThe image regions used for feature extraction in our experiments were\nsquares of size 33 \u00d7 33, 65 \u00d7 65, 97 \u00d7 97, 129 \u00d7 129, and 161 \u00d7 161 pixels,\nplus the whole potato, giving 6 regions in total. Our system uses seven\n6\ncolour channels; raw RGB, normalised RGB and the intensity channel I =\n1\n3\n(R+G+B). From these channels we consider the following image properties:\nColour. Intensity is especially of relevance for dark blemishes, e.g. black scurf\nor skin spot, while the most obvious blemish to be detected by other colour\nchannels would be greening. The three statistical moments collected from the\nseven colour channels represent the first 21 features for each region. Seven\nadditional features describe the colour properties of the pixel itself.\nEdges. An edge detector determines the rate of change of pixel values in a\ngiven neighbourhood in a specific direction. Some blemishes tend to coincide\nwith high rates of change, such as powdery scab when the skin splits. The\nSobel edge detector was used in this case with a standard 3 \u00d7 3 kernel size.\nThe edge detector was run on the same seven colour channels listed above.\nThese statistics provide 21 features for each region and seven for the pixel\nitself.\nRange. The range filter determines the maximum difference between pixel\nvalues in a given neighbourhood indicating the roughness of the texture.\nHigher values tend to correspond to rougher, potentially damaged areas of\nthe potato. The range filter was run on the same seven channels with a\n5 \u00d7 5 neighbourhood. The three statistical moments collected from the re-\nsulting range information provide another 21 features for each region. Seven\nadditional features describe range properties of the pixel itself.\nIn summary there are 7 colour channels \u00d7 3 feature types \u00d7 3 statistical\nmoments, making 63 features for each region and 7\u00d7 3 = 21 features for the\npixel itself. All these features are used as the candidate feature set. Since\nthere are 63 different features that can be extracted from each region, this\ngives 63 \u00d7 6 = 378 features which, with additional 21 features for the pixel\nitself, gives us Fc = 399 candidate features in total. These features were used\nas the training input to our classifier.\n2.4. Classification\nThe AdaBoost algorithm (Freund and Schapire, 1999) is used to build\na classifier, which combines results from so-called \u201cweak\u201d classifiers (each\nconstructed using one of the candidate features) into one \u201cstrong\u201d classifier\nthat performs better than any of the weak classifiers alone. It has been used\npreviously in the classification of apples to avoid falsely classifying apple\nfeatures as blemishes (Unay and Gosselin, 2006). The high performance of\n7\nthe final strong classifier is due to the emphasis put on the training examples\nwhich are most difficult to classify during the learning process. This method\nis called boosting. During training AdaBoost makes a number of passes,\ncalled rounds or iterations, through the training data. Each time it finds\nthe next best feature to improve the number of correctly classified examples,\nprioritising those examples which were misclassified previously. In each pass\none feature is selected and assigned a weight and a threshold to create a new\nweak classifier. The weak classifiers are then combined into a strong classifier\nwherein each weak classifier is given a weighted vote in the classification of\na given example.\nThe Real AdaBoost algorithm proposed by Schapire and Singer (1998) is\na generalisation of this algorithm that provides a lower error rate by allowing\nweak classifiers to vote by their individual degree of certainty instead of\nsimply voting yes or no. It is the version used in our experiments, hereafter\nreferred to simply as AdaBoost.\nIn our system the AdaBoost algorithm is used to classify individual pix-\nels of potato images into two categories: blemished potato and good potato\nbased on features defined in Section 2.3. The reduced set of selected weak\nclassifiers allows for preprocessing only the most useful features, saving con-\nsiderable computation time.\n2.4.1. Minimalist classifier\nThe AdaBoost classifier selects a set of the most useful features from\nall candidate features. If the training data is not normally distributed, Ad-\naBoost will often choose the same feature for more than one weak classifier.\nTherefore it is of interest to see how much the classification success rate would\nbe affected by the original candidate feature set being restricted to a sub-\nset of features, selected by AdaBoost itself. By doing so the total number of\nunique features required to be extracted for classification will be reduced and\ntherefore less computational time will be required by the feature extraction\nstage. We refer to this subset of features as the \u201cselected features\u201d.\nOur approach involves two stages, both incorporating the AdaBoost al-\ngorithm: the first stage selects a feature set that will be used to train an\nAdaBoost classifier in the second stage. Algorithm 1 presents the Real Ad-\naBoost algorithm as described in Huang et al. (2005), applied with our ad-\ndition of step 4, in order to limit the number of unique features used in the\nfinal classifier to a smaller number than the total number of weak classifiers\nallowed. Using MATLAB we have extended the AdaBoost implementation\n8\nwithin the GML AdaBoost Toolbox (Vezhnevets, 2006), to build the mini-\nmalist classifier.\n2.5. Evaluation metrics\nThe output of the classifier is a binary image with pixels indicating good\npotato or blemish. The performance of the system can be measured by\ncomparing the output image to the ground truth information. The following\nstatistics were collected for each output image:\n\u2022 TP - true positive, number of pixels that were classified as blemish and\nmatched ground truth;\n\u2022 FP - false positive, number of pixels that were classified as blemish but\ndid not match ground truth;\n\u2022 TN - true negative, number of pixels that were classified as good potato\nand matched ground truth;\n\u2022 FN - false negative, number of pixels that were classified as good potato\nbut did not match ground truth.\nFrom these statistics we could calculate the two following metrics:\n\u2022 sensitivity = TP\nTP+FN\n;\n\u2022 specificity = TN\nTN+FP\n.\nWe represent the performance of our binary classifier using the most common\nmethod based on ROC curves, which provide detailed information about the\nrelationship between these two metrics with respect to different parameter\nsettings of the system.\n3. Results and discussion\n3.1. Training and testing\nWhen training, the minimalist classifier first chooses a number of \u201cse-\nlected features\u201d (Fs). To investigate the impact of this parameter on the\nclassification rate we used Fs = 1, 2, 5 and 10. For comparison we also used\nFs = Fc, the equivalent of a non-minimalist method. The number of Ad-\naBoost rounds in the second stage was set to T = 40.\n9\nTests were carried out using the training data on a hold-one-out basis\nwhereby one of the images is removed from the training data and used as\ntest data instead. The testing is carried out for every image in this manner\nwith each image being tested by a classifier trained on every thousandth\npixel from the other images. The success rates of the minimalist classifier for\ndifferent potato colours and different values of Fs are presented in Table 1.\nIn addition, the performance of the classifier using ROC curves is presented\nin Figure 3 for white potatoes and in Figure 4 for red potatoes.\nTo determine the importance of different feature categories (i.e. colour,\nedge and range), the tests were carried out for different subsets of these\ncategories. The results are presented as ROC curves in Figure 5 for white\npotatoes and in Figure 6 for red potatoes.\nFigure 7 shows the output of the classifier compared to the ground truth\ninformation. Some of the disparity between the classifier output and ground\ntruth could be due to human inaccuracy at the markup stage which can be\nseen more clearly in Figure 8.\n3.2. Preferred features\nThe top ten chosen features for white potatoes can be found in Table 3\nand for red potatoes in Table 4. In the top 5 features chosen by the minimalist\nclassifier for both white and red potatoes the most prominent features were\nbased on the edge detector and range filter run on the red channel followed\nby features based on intensity. The preferred regions were the pixel itself and\nthe smallest region of size 33\u00d7 33 pixels.\n3.3. Success rates\nResults presented in Table 1 for different number of selected features indi-\ncate that using Fs = 10 features does not negatively impact the performance\nof the classifier, resulting in success rates of 89.6% and 89.5% for white and\nred potatoes, respectively. In our tests the minimalist classifier came very\nclose to or even slightly outperformed the non-minimalist classifier. Further\nreducing Fs to 5 still gives satisfactory results but the performance drops\nnoticeably below that number. The difference in performance between clas-\nsifiers using different values of Fs can also be seen clearly in ROC curves\n(Figures 3 and 4).\nThe results of using different subsets of feature categories are shown in\nTable 2. Using only colour gives a result of 86.9% accuracy for white potatoes\n10\nand 82.2% for red potatoes. Adding edge features gives an increase of classi-\nfication rate up to 87.5% and 88.2% for white and red potatoes, respectively.\nOn the other hand range features give an increase of classification rate up\nto 90.2% and 88.0% for white and red potatoes, respectively. This indicates\nthat range features provide more relevant information than edges. Including\nall features does not greatly affect the classification rates, resulting in 89.7%\nand 88.7% accuracy for white and red potatoes, respectively. The difference\nin performance between classifiers using different feature categories can also\nbe seen clearly in the ROC curves (Figure 5 and Figure 6).\nThe reduced performance when using only colour for the red potatoes\nmay be related to the importance of the red colour channel in white potatoes.\nSince red potatoes have a smaller dynamic range in this colour channel the\nclassifier may need to rely on other features. To ensure this was not simply\ndue to the smaller number of training examples, the test was re-run on white\npotatoes using only 21 images, every fifth image. This resulted in similar\nresults to before, with colour-only classification rates only dropping from\n86.9% to 86.3%, which would tend to confirm the above hypothesis.\n4. Conclusions and Further Work\nThe presented results show that an AdaBoost based system is able to\nbuild minimalist classifiers that optimise detection performance at low com-\nputational cost. A minimalist classifier using only ten selected features\nachieves success rates of 89.6% for white potatoes and 89.5% for red pota-\ntoes. The use of AdaBoost in this minimalist form provides a comparable and\nsometimes slightly better result than simply providing the whole feature set.\nThis may be related to AdaBoost\u2019s vulnerability to overfitting (Ratsch et al.,\n1998), meaning that the learned statistical model describes random error or\nnoise in the training data instead of the underlying relationship between the\nclassifier inputs and outputs.\nA number of disagreements between ground truth and classification re-\nsults were located on the edges of ground-truthed blemishes, visible in Figure\n7. Many of these disagreements may be due to human error in the markup\nstage, which can be seen as symptomatic of the problem which this research\nsets out to solve, that of human assessment of blemishes being subjective and\nprone to error. A machine vision system is likely to be more accurate than\nthe human who produces the ground truth. This is especially noticeable in\nFigure 8 where a larger area has been marked in the ground truth as being\n11\naffected by black dot than detected by the classifier. The errors are due to\nthe ground truth including an area marked as black dot, which is actually\ngood potato skin speckled with black dot blemish. The classifier is able to\ndetect the blemish pixel by pixel, so a portion of the reported error seems to\nbe caused by inaccurate ground-truthing rather than misclassification.\nThe issue of human ground-truth inaccuracy might also be addressed by a\nsemi-automatic method, e.g. by using an unsupervised method which would\ncluster similar potato features and allow the human to select clusters and\nspecify what they represent.\nThere are a number of possible improvements to the image processing\nmethod used in our system. Some initial research has suggested it might\nbe possible to replace the fixed square regions used in our experiments with\nregions from segmentation algorithms, e.g. normalised cuts (Mori, 2005).\nAlso the use of textons (Varma and Zisserman, 2005) to provide additional\ntexture information might improve results. However the processing time\nneeded to follow the method used in Varma and Zisserman (2005) made it\nunappealing to pursue. Further tests have yet to confirm a possible gain in\naccuracy or speed of these approaches. Other features that might be involved\nwould include shape features, if the boundaries of individual blemishes can\nbe located, and Fourier harmonics as in Tao et al. (1995b).\nThe proposed system estimates blemished areas of potatoes in 2D images,\nwhile a real world scenario we would have to consider the entire surface area\nof a 3D tuber. The question has been already addressed in industry, for\nexample, with the Herbert Upgrader (R.J. Herbert Engineering Ltd, 2008)\nwhich takes a selection of images of a rolling potato and averages the area\nof each. Alternatively, the Hiquip system (Noordam et al., 2000), developed\nin the Netherlands, uses a single camera to take photographs of potatoes\npassing a series of mirrors to ensure full coverage.\nIt has been shown that the smaller dataset for red potatoes does not cause\na large reduction in the classifier\u2019s performance compared to the 102 images\nused for white potatoes. Given that the minimalist classifier was intended to\nreduce the amount of data required to classify a potato, the question remains\nof how small a selection of white potatoes would be necessary to still achieve\na satisfactory classification rate.\nAn overall aim of our work is to provide improved management and con-\ntrol strategies for the individual blemish diseases. Further research is directed\nat distinguishing between blemish types, which will provide a significant tool\nto investigate, for example, trends in individual diseases across time, geo-\n12\ngraphic areas or weather.\n5. Acknowledgements\nThis work was partly funded by the Potato Council Ltd. who also pro-\nvided expert assistance in the field of potato science. Thanks especially to\nAdrian Cunnington. In addition thanks to Hongying Meng and William I.\nTyne for their help in understanding Guannan et al. (2009) and De Haan\nand van den Bovenkamp (2005), respectively.\nReferences\nBolle, R., Connell, J., Haas, N., Mohan, R., Taubin, G., 1996. Veggievision:\nA produce recognition system. In: Proceedings of the 3rd IEEE Workshop\non Applications of Computer Vision (WACV \u201996). IEEE Computer Society,\nWashington, DC, USA, p. 244.\nDe Haan, E. G., van den Bovenkamp, G. W., 2005. Improved diagnosis of\npowdery scab (spongospora subterranea f.sp. subterranea) symptoms on\npotato tubers (solanum tuberosum l.). Potato Research 48 (1-2), 1\u201314.\nFood and Agriculture Organisation, 2005. FAO Statistics. Online,\n(http:\/\/faostat.fao.org).\nFreund, Y., Schapire, R., September 1999. A short introduction to boosting.\nJournal of Japanese Society for Artificial Intelligence 14 (5), 771 \u2013 780.\nGuannan, Z., Yuzhi, T., Junxiong, Z., Wei, L., 2009. Automatic detecting\nand grading method of potatoes with computer vision. Nongye Jixie Xue-\nbao \/ Transactions of the Chinese Society of Agricultural Machinery 40 (4),\n166\u2013168+1.\nHeinemann, P. H., Pathare, N. P., Morrow, C. T., 1996. An automated\ninspection station for machine-cision grading of potatoes. Machine Vision\nand Applications 9 (1), 14\u201319.\nHuang, C., Wu, B., Al, H., Lao, S., 2005. Omni-directional face detection\nbased on Real AdaBoost. In: International Conference of Computer Vision.\nJarimopas, B., Jaisin, N., 2008. An experimental machine vision system for\nsorting sweet taramind. Journal of Food Engineering 89, 291 \u2013 297.\n13\nJelinski, T., jin Du, C., Sun, D.-W., Fornal, J., 2007. Inspection of the\ndistribution and amount of ingredients in pasteurized cheese by computer\nvision. Journal of Food Engineering 83, 3 \u2013 9.\nMaf Roda Group, October 2008. Meeting with Maf-Roda personnel.\n(http:\/\/www.maf-roda.com\/).\nMori, G., 2005. Guiding model search using segmentation. In: ICCV \u201905:\nProceedings of the Tenth IEEE International Conference on Computer\nVision. Vol. 2. pp. 1417 \u2013 1423.\nMuir, A. J., Ross, D. W., Dewar, C. J., Kennedy, D., 1999. Defect and disease\ndetection in potato tubers. In: Proceedings of SPIE - The International\nSociety for Optical Engineering. Vol. 3543. pp. 199\u2013207.\nMunkevik, P., Hall, G., Duckett, T., 2007. A computer vision system for\nappearance-based descriptive sensory evaluation of meals. Journal of Food\nEngineering 78, 246 \u2013 256.\nNoordam, J., Otten, G., Timmermans, T., van Zwol, B., March 2000. High-\nspeed potato grading and quality inspection based on a color vision system.\nIn: Society of Photo-Optical Instrumentation Engineers (SPIE) Confer-\nence Series. Vol. 3966 of Society of Photo-Optical Instrumentation Engi-\nneers (SPIE) Conference Series. pp. 206\u2013217.\nRatsch, G., Onoda, T., Muller, K. R., 1998. An improvement of AdaBoost\nto avoid overfitting. In: Proceedings of the International Conference on\nNeural Information Processing. pp. 506\u2013509.\nR.J. Herbert Engineering Ltd, October 2008. Meeting with representatives\nof R.J. Herbert Engineering Ltd., Marshland St. James, Cambridgeshire,\nUK. (http:\/\/www.rjherbert.co.uk\/).\nSchapire, R., Singer, Y., 1998. Improved boosting algorithms using\nconfidence-rated predictions. In: Proceedings of the Eleventh Annual Con-\nference on Computational Learning Theory. pp. 80\u201391.\nTao, Y., Heinemann, P. H., Varghese, Z., 1995a. Machine vision for color\ninspection of potatoes and apples. Transactions of the American Society\nof Agricultural Engineers 38 (5), 1555\u20131561.\n14\nTao, Y., Morrow, C. T., Heinemann, P. H., 1995b. Fourier-based separation\ntechnique for shape grading of potatoes using machine vision. Transactions\nof the American Society of Agricultural Engineers 38 (3), 949\u2013957.\nTsai, D., Tsai, Y., 2002. Rotation-invariant pattern matching with colour-\nring projection. Pattern Recognition 35, 131\u2013141.\nUnay, D., Gosselin, B., 2006. Stem and calyx recognition on \u2019jonagold\u2019 apples\nby pattern recognition. Journal of Food Engineering 78, 597 \u2013 605.\nVarma, M., Zisserman, A., 2005. A statistical approach to texture classifi-\ncation from single images. International Journal of Computer Vision 62,\n61\u201381.\nVezhnevets, A., 2006. GML AdaBoost MATLAB Toolbox.\nURL http:\/\/research.graphicon.ru\nZhou, L., Chalana, V., Kim, Y., 1998. Pc-based machine vision system for\nreal-time computer-aided potato inspection. International Journal of Imag-\ning Systems and Technology 9 (6), 423\u2013433.\n6. Figures and tables\n15\nAlgorithm 1 Our implementation of the Real AdaBoost learning algorithm.\nFreund and Schapire (1999); Schapire and Singer (1998)\nGiven a dataset S = {(x1, y1), ...(xm, ym)} where xi \u2208 X and yi \u2208 {\u22121,+1}, the weak classifier\npool K, containing all possible weak classifiers from Fc candidate features, a specific number of weak\nclassifiers to be chosen T and a maximum number of unique features to be used to choose these weak\nclassifiers Fs.\nInitialise the sample distribution D1(i) = 1\/m\nFor t = 1, ...T\n1. For each weak classifier h in K do:\na. Partition X into several disjoint blocks X1, ..., Xn\nb. Using the weights in distribution Dt calculate\nW jl = P (xi \u2208 Xj , yi = l) =\n\u2211\ni:xi\u2208Xj ,yi=l\nDt(i)\nWhere l = \u00b11\nc. Set the output of h on each Xj as\n\u2200x \u2208 Xj , h(x) = 1\n2\nln\n(\nW j+1 + \u000f\nW j\u22121 + \u000f\n)\nd. Calculate the normalisation factor\nZ = 2\n\u2211\nj\n\u221a\nW j+1W\nj\n\u22121\n2. Select the ht Minimising Z i.e.\nZt = min\nh\u2208K\nZ\nht = arg min\nh\u2208K\nZ\n3. Update the sample distribution\nDt+1(i) = Dt(i)exp [\u2212yiht(xi)]\nand normalise Dt+1 to give a probability distribution function.\n4. Count the number of unique features used by all weak classifiers. If the total equals Fs then\nupdate K to only contain weak classifiers pertaining to already selected features.\nThe final strong classifier H is\nH(x) = sign\n[\nT\u2211\nt=1\nht(x)\u2212 b\n]\nThe confidence of H is defined as\nConfH(x) =\n\uf8ee\uf8f0 T\u2211\nt+1\nht(x)\u2212 b\n\uf8f9\uf8fb\n16\n(a) A potato blemished by black dot. (b) A potato blemished by silver scurf.\n(c) Potatoes blemished by common scab. (d) Potato blemished by powdery scab.\n(e) Potato affected by skin spot. (f) Physiological greening of the skin of\na potato.\nFigure 1: Examples of potato blemishes\n17\nFigure 2: The camera setup for photographing the training data at a constant distance\nwith all-around lighting.\n18\nFeatures\nSuccess Rate\nWhite Potato Red Potato\nFs = 1 82.7% 84.8%\nFs = 2 87.6% 84.5%\nFs = 5 89.8% 88.7%\nFs = 10 89.6% 89.5%\nFs = Fc 89.7% 88.7%\nTable 1: Success rates for different numbers of selected features Fs\nFeatures\nSuccess Rate\nWhite Potato Red Potato\ncolour only 86.9% 82.2%\ncolour and edges 87.5% 88.2%\ncolour and range 90.2% 88.0%\ncolour, range and edges 89.7% 88.7%\nTable 2: Success rates for different subsets of feature categories (Fs = Fc)\n19\nRank Region Feature Type Statistical Moment\n1 33\u00d7 33 edge red var\n2 pixel red -\n3 33\u00d7 33 range normalised red skew\n4 pixel range red -\n5 161\u00d7 161 range red skew\n6 33\u00d7 33 range blue skew\n7 97\u00d7 97 range red mean\n8 33\u00d7 33 range green skew\n9 whole edge normalised blue var\n10 whole edge normalised red var\nTable 3: The first ten selected features for a minimalist classifier using white potatoes.\nRank Region Feature Type Statistical Moment\n1 65\u00d7 65 edge red var\n2 65\u00d7 65 normalised blue mean\n3 33\u00d7 33 range red mean\n4 33\u00d7 33 range intensity skew\n5 whole edge normalised green var\n6 pixel red -\n7 161\u00d7 161 edge normalised green var\n8 whole normalised red var\n9 pixel range red -\n10 129\u00d7 129 range blue skew\nTable 4: The first ten selected features for a minimalist classifier using red potatoes.\n20\nFigure 3: ROC curves for different numbers of selected features Fs tested on white pota-\ntoes.\nFigure 4: ROC curves for different numbers of selected features Fs tested on red potatoes.\n21\nFigure 5: ROC curves for different subsets of feature categories tested on white potatoes.\nFigure 6: ROC curves for different subsets of feature categories tested on red potatoes.\n22\nFigure 7: Example images (left to right): first an original photograph, then a ground\ntruthed image, then an error image, showing false positive results in red and false negative\nresults in green, for the detection of blemish. The final image is from the processing of\nthe entire original image without reference to ground truth, blemishes in black and good\npotato in white. Most disagreements between ground truth and classification results can\nbe seen to be around the edges of blemishes where ground-truthing is less accurate.\n23\nFigure 8: Zoomed-in view of the middle of the first image set in Figure 7 clearly showing\nthat errors are being caused by imprecise markup.\n24\n"}
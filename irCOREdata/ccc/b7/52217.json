{"doi":"10.1016\/j.jneumeth.2010.10.022","coreId":"52217","oai":"oai:eprints.lincoln.ac.uk:3673","identifiers":["oai:eprints.lincoln.ac.uk:3673","10.1016\/j.jneumeth.2010.10.022"],"title":"Development of a head-mounted, eye-tracking system for dogs","authors":["Williams, Fiona","Mills, Daniel","Guo, Kun"],"enrichments":{"references":[{"id":682661,"title":"A comparison of video and magnetic search coil recordings of mouse eye movements.","authors":[],"date":null,"doi":"10.1016\/s0165-0270(00)00218-1","raw":null,"cites":null},{"id":678147,"title":"A new surgery for congenital nystagmus: effects of tenotomy on an achiasmatic canine and the role of extraocular proprioception.","authors":[],"date":null,"doi":"10.1016\/s1091-8531(99)70063-7","raw":null,"cites":null},{"id":681018,"title":"A strong correlation exists between the distribution of retinal ganglion cells and nose length in the dog.","authors":[],"date":null,"doi":"10.1159\/000073756","raw":null,"cites":null},{"id":680209,"title":"Abnormal functional connectivity in autism spectrum disorders during face processing.","authors":[],"date":"2008","doi":"10.1093\/brain\/awm334","raw":null,"cites":null},{"id":681479,"title":"An examination of binocular reading fixations based on sentence corpus data.","authors":[],"date":null,"doi":"10.1167\/9.5.31","raw":null,"cites":null},{"id":678981,"title":"Are readers of our face readers of our minds? Dogs (Canis familiaris) show situation dependent recognition of humans\u2019 attention. Anim Cogn., 2004;7:144-53 Guo K. Initial fixation placement in face images is driven by top-down guidance.","authors":[],"date":null,"doi":"10.1007\/s10071-003-0205-8","raw":null,"cites":null},{"id":676845,"title":"Automated corneal-reflection eye tracking in infancy: methodological developments and applications to cognition.","authors":[],"date":null,"doi":"10.1207\/s15327078in0602_1","raw":null,"cites":null},{"id":681694,"title":"Discrimination of human and dog faces and inversion responses in domestic dogs (Canis familiaris).","authors":[],"date":null,"doi":"10.1007\/s10071-009-0303-3","raw":null,"cites":null},{"id":683138,"title":"Dogs respond appropriately to cues of humans\u2019 attentional focus.","authors":[],"date":null,"doi":"10.1016\/j.beproc.2004.01.012","raw":null,"cites":null},{"id":677933,"title":"Eye movement characteristics and recording techniques.","authors":[],"date":null,"doi":null,"raw":null,"cites":null},{"id":679791,"title":"Eye movement recordings as an effectiveness indicator of gene therapy in RPE65 deficient canines: implications for the ocular motor system.","authors":[],"date":null,"doi":"10.1016\/j.jaapos.2006.10.006","raw":null,"cites":null},{"id":680767,"title":"Eye movements and the control of actions in everyday life. Prog Retin Eye Res.,","authors":[],"date":null,"doi":null,"raw":null,"cites":null},{"id":681968,"title":"Eye movements in reading and information processing.","authors":[],"date":null,"doi":"10.1037\/\/0033-2909.124.3.372","raw":null,"cites":null},{"id":677817,"title":"Eye tracking during a visual paired comparison task as a predictor of early dementia.","authors":[],"date":null,"doi":"10.1177\/1533317509332093","raw":null,"cites":null},{"id":678913,"title":"Eye Tracking Methodology: Theory and Practice,","authors":[],"date":"2003","doi":"10.1007\/978-1-4471-3750-4","raw":null,"cites":null},{"id":679347,"title":"How do monkeys view faces? \u2013 A study of eye movements.","authors":[],"date":null,"doi":null,"raw":null,"cites":null},{"id":679581,"title":"Human gaze control during real world scene perception.","authors":[],"date":null,"doi":"10.1016\/j.tics.2003.09.006","raw":null,"cites":null},{"id":682619,"title":"Human-monkey gaze correlations reveal convergent and divergent patterns of movie viewing.","authors":[],"date":null,"doi":"10.1016\/j.cub.2010.02.032","raw":null,"cites":null},{"id":680027,"title":"Implantation of magnetic search coils for measurement of eye position: an improved method. Vision Res.,","authors":[],"date":"1980","doi":"10.1016\/0042-6989(80)90128-5","raw":null,"cites":null},{"id":679206,"title":"Left gaze bias in humans, rhesus monkeys and domestic dogs.","authors":[],"date":null,"doi":"10.1007\/s10071-008-0199-3","raw":null,"cites":null},{"id":682168,"title":"Local administration of dopaminergic drugs into the ventral tegmental area modulates cataplexy in the narcoleptic canine. Brain Res.,","authors":[],"date":"1996","doi":"10.1016\/0006-8993(96)00541-0","raw":null,"cites":null},{"id":682853,"title":"Monkey visual behavior falls into the uncanny valley.","authors":[],"date":null,"doi":"10.1073\/pnas.0910063106","raw":null,"cites":null},{"id":682048,"title":"Neuropharmacological characterisation of basal forebrain cholinergic stimulated cataplexy in narcoleptic canines. Exp Neurol.,","authors":[],"date":"1998","doi":"10.1006\/exnr.1998.6787","raw":null,"cites":null},{"id":680515,"title":"Non contact eye tracking on cats.","authors":[],"date":null,"doi":"10.1016\/s0165-0270(01)00423-x","raw":null,"cites":null},{"id":682397,"title":"Noninvasive telemetric gaze tracking in freely moving socially housed prosimian primates.","authors":[],"date":null,"doi":"10.1016\/j.ymeth.2005.12.003","raw":null,"cites":null},{"id":677085,"title":"Normal and pathological saccadic dysmetria.","authors":[],"date":"1993","doi":"10.1093\/brain\/116.2.337","raw":null,"cites":null},{"id":678389,"title":"Ocular motor abnormalities in achiasmatic mutant Belgian sheepdogs: unyoked eye movements in a mammal. Vision Res.,","authors":[],"date":"1995","doi":"10.1016\/0042-6989(94)e0045-m","raw":null,"cites":null},{"id":678680,"title":"The congenital and seesaw nystagmus in the prototypical achiasma of canines: comparison to the human achiasmatic prototype. Vision Res.,","authors":[],"date":"1998","doi":"10.1016\/s0042-6989(97)00337-4","raw":null,"cites":null},{"id":677334,"title":"Traffic gap judgment in people with significant peripheral field loss. Optometry Vision Sci.,","authors":[],"date":"2008","doi":"10.1097\/opx.0b013e31815ed6fd","raw":null,"cites":null},{"id":681271,"title":"Vision in Dogs.","authors":[],"date":null,"doi":null,"raw":null,"cites":null},{"id":677557,"title":"Voluntary binocular gaze-shifts in the plane of regard: dynamics of version and vergence. Vision Res.,","authors":[],"date":"1995","doi":"10.1016\/0042-6989(95)00082-p","raw":null,"cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-01-15","abstract":"Growing interest in canine cognition and visual perception has promoted research into the allocation of visual attention during free-viewing tasks in the dog. The techniques currently available to study this (i.e. preferential looking) have, however, lacked spatial accuracy, permitting only gross judgements of the location of the dog\u2019s point of gaze and are limited to a laboratory setting. Here we describe a mobile, head-mounted, video-based, eye-tracking system and a procedure for achieving standardised calibration allowing an output with accuracy of 2-3\u00ba. \\ud\n\\ud\nThe setup allows free movement of dogs; in addition the procedure does not involve extensive training skills, and is completely non-invasive. This apparatus has the potential to allow the study of gaze patterns in a variety of research applications and could enhance the study of areas such as canine vision, cognition and social interactions","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/52217.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/3673\/1\/Development_of_a_head-mounted%2C_eye-tracking_system_for_dogs.pdf","pdfHashValue":"f12b552656681d1f604a549333bc17db0105c5f6","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:3673<\/identifier><datestamp>\n      2013-12-04T14:11:42Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F43:6A6163735F43383330<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F43:6A6163735F43393030<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/3673\/<\/dc:relation><dc:title>\n        Development of a head-mounted, eye-tracking system for dogs<\/dc:title><dc:creator>\n        Williams, Fiona<\/dc:creator><dc:creator>\n        Mills, Daniel<\/dc:creator><dc:creator>\n        Guo, Kun<\/dc:creator><dc:subject>\n        C830 Experimental Psychology<\/dc:subject><dc:subject>\n        C900 Others in Biological Sciences<\/dc:subject><dc:description>\n        Growing interest in canine cognition and visual perception has promoted research into the allocation of visual attention during free-viewing tasks in the dog. The techniques currently available to study this (i.e. preferential looking) have, however, lacked spatial accuracy, permitting only gross judgements of the location of the dog\u2019s point of gaze and are limited to a laboratory setting. Here we describe a mobile, head-mounted, video-based, eye-tracking system and a procedure for achieving standardised calibration allowing an output with accuracy of 2-3\u00ba. \\ud\n\\ud\nThe setup allows free movement of dogs; in addition the procedure does not involve extensive training skills, and is completely non-invasive. This apparatus has the potential to allow the study of gaze patterns in a variety of research applications and could enhance the study of areas such as canine vision, cognition and social interactions.<\/dc:description><dc:publisher>\n        Elsevier<\/dc:publisher><dc:date>\n        2011-01-15<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/3673\/1\/Development_of_a_head-mounted%2C_eye-tracking_system_for_dogs.pdf<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/3673\/2\/Guo_-_Head_mounted_-_3673.pdf<\/dc:identifier><dc:identifier>\n          Williams, Fiona and Mills, Daniel and Guo, Kun  (2011) Development of a head-mounted, eye-tracking system for dogs.  Journal of Neuroscience Methods, 194  (2).   pp. 259-265.  ISSN 0165-0270  <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1016\/j.jneumeth.2010.10.022<\/dc:relation><dc:relation>\n        10.1016\/j.jneumeth.2010.10.022<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/3673\/","http:\/\/dx.doi.org\/10.1016\/j.jneumeth.2010.10.022","10.1016\/j.jneumeth.2010.10.022"],"year":2011,"topics":["C830 Experimental Psychology","C900 Others in Biological Sciences"],"subject":["Article","NonPeerReviewed"],"fullText":"Development of a head-mounted, eye-tracking system for dogs \n \nAbstract \n Growing interest in canine cognition and visual perception has promoted research \ninto the allocation of visual attention during free-viewing tasks in the dog.  The \ntechniques currently available to study this (i.e. preferential looking) have, however, \nlacked spatial accuracy, permitting only gross judgements of the location of the dog\u2019s \npoint of gaze and are limited to a laboratory setting.  Here we describe a mobile, head-\nmounted, video-based, eye-tracking system and a procedure for achieving \nstandardised calibration allowing an output with accuracy of 2-3\u00ba.        \n \nThe setup allows free movement of dogs; in addition the procedure does not involve \nextensive training skills, and is completely non-invasive. This apparatus has the \npotential to allow the study of gaze patterns in a variety of research applications and \ncould enhance the study of areas such as canine vision, cognition and social \ninteractions.   \n \nKeywords: Attention; dogs; eye tracking; gaze; mobility.     \n          \n1. Introduction \nVisual exploration of our environment involves a series of saccades (along with head \nand body movements, which dogs frequently make) to direct our gaze to regions \neither informative or interesting to us. The preferred regions within a scene are often \ninspected earlier and attract more fixations and longer viewing time. Gaze patterns \nhence provide a real-time behaviour index of ongoing perceptual and cognitive \n 1\nprocessing, and could be sensitive indices of our attention, motivation and preference, \nespecially when exploring scenes of high ecological validity (Rayner, 1998; \nHenderson, 2003; Land et al., 2006). \n  \nTo monitor human gaze patterns, scleral search coils, dual Purkinje image eye \ntrackers and video-based, pupil-centre\/corneal-reflection eye trackers are used in \ndifferent laboratory settings for different requirements of spatial and temporal \nresolution. Among these different eye tracking devices, only video-based, head-\nmounted systems allow free head and body movements, and can be used to study \nnaturalistic vision in everyday activities such as driving, playing sports and preparing \nfood (Land et al., 2006). \n \n The adaption of eye-tracking systems for use on non-human animals has, however, \nresulted in the use of a number of divergent techniques to measure eye movements \nvarying in invasiveness, restraint and level of training required for the use of the \napparatus.   \n  \nWith the highest spatial and temporal resolution, scleral search coils are typically \nemployed to study visual processing and eye-movement control in non-human \nprimates, such as macaque monkeys. However the protocol is invasive requiring \nsurgical implantation of a scleral magnetic search coil under the conjunctiva around \nthe eyeball (Judge et al., 1980), which can increase both cost and risk of infection as \nwell as physical discomfort to the animal. An alternative is the use of a video-based \nremote eye tracker placed close to the animal\u2019s head which allows a combination of \nthe pupil and\/ or one or more Purkinje image to be tracked, this is typically achieved \n 2\nby illuminating the eye using an infrared source, the resulting image being captured \nby the eye tracker via a camera.  Such a technique has been employed with cats \n(K\u00f6rding et al., 2001), mice (Stahl et al., 2000), dogs (Jacobs et al., 2006) and \nmacaques (Davis et al., 2009).  Whilst this technique offers some methodological \nrefinement by eliminating the need to attach apparatus to the eye, owing to the fixed \nnature of the cameras it requires the animal\u2019s body to be restrained and, often, the \nhead to be fixed, this typically necessitates the surgical insertion of implants into the \nhead which can be attached to external apparatus.  Hence whilst developments in \nhead-fixation techniques appear to have reduced the incidence of infection and \ncomplications such as bone necrosis (e.g. Davis et al., 2009), the expense, potential \nstress and possibility of harm to the animal associated with surgery cannot be \ncompletely overcome. Not only does fixation of the head and body reduce the \nopportunities for studying naturalistic behaviour, it also raises concerns over the \nwelfare of the animals used.  All scientists working with animals should show a \ncommitment to the 3 R\u2019s (Russell and Burch, 1959), and so refinement which \nimproves welfare should be considered important.   \n \nThe study of the eye movements of freely moving lemurs has been facilitated by the \nuse of a head-mounted, video-based, eye-tracking system adapted from equipment \ndesigned for human use (Shepherd and Platt, 2006).  This system comprised two small \ncameras, one recording the visual scene, the other imaging the eye via a reflection \nfrom a dichroic mirror.  Such a system, however, has currently not been successfully \nused on non-primate species.     \n \n 3\nThe dog has long been a model laboratory animal but there is a growing interest in \ncanine cognition in many other contexts.  Dogs are of particular interest in the study \nof social cognition as they are a social species, and therefore likely to be adept at \nrecognising communicative cues.  Their history of artificial selection by man and their \nopportunity for enculturation within the human environment (Vir\u00e1nyi et al., 2004) \nmake them a particularly useful model for comparative work with humans. \n \nThe study of eye movements and the allocation of visual attention in dogs allows the \ninvestigation of factors influencing the human-dog relationship, such as the saliency \nof human gestures upon dog behaviour (G\u00e1csi et al., 2004; Vir\u00e1nyi et al., 2004) and \nvisual processing biases, providing information on putative cognitive mechanisms \nunderlying canine vision (Guo et al., 2009; Racca et al., 2010).  Hence, studying gaze \npatterns has the potential to explore how visual inputs influence a dog\u2019s behaviour as \nwell as how these inputs may be processed by the visual system.  In addition, it \nprovides a valuable mechanism for studying visual attention itself, both in terms of \nhow it is deployed and also maintained in dogs, a research area that has received little \nattention.  The assessment of looking behaviour in dogs has, however, previously \nrelied largely upon techniques such as measuring the dog\u2019s head and body orientation  \n(G\u00e1csi et al., 2004; Vir\u00e1nyi et al., 2004) or change of gaze direction (preferential \nlooking) (Guo et al., 2009; Racca et al., 2010).  Using either of these methodologies, \njudgements regarding the allocation of visual attention are restricted in terms of \nspatial accuracy. Hence whilst these paradigms are useful for assessing variables such \nas whether the dog oriented their attention towards a stimulus, for example a person, \nor whether the eyes were attending to the left or right side of a stimulus, they lack \nspatial accuracy to make more detailed evaluations of the focus of attention.    \n 4\n Electrooculograms (EOG) have been used to measure cataplexy in narcoleptic dogs \n(Reid et al., 1996, 1998), however, this necessitates the surgical implantation of \nelectrodes near the orbit of the eye.  The EOG signal is also subject to drift, requiring \nregular recalibrations, this is particularly problematic when working with non-verbal \nsubjects (Aslin and McMurray, 2004).  Accuracy of EOG data may be further reduced \nby nonlinearities (Dell\u2019Osso and Daroff, 1999).  In addition, as the EOG technique \nmeasures eye movement within the head it is unsuitable for providing point of regard \ninformation unless head movement is also measured (Duchowski, 2003).  Eye \nmovements in canines have also been studied using infrared reflection tracking \nsystems in conjunction with body stabilisation and a non-invasive, head-fixation \ntechnique in order to study the effects of a new surgical treatment for infantile \nnystagmus syndrome (Dell\u2019Osso et al., 1998, 1999).    This methodology has been \nfurther advanced by the adaptation of a head-mounted, video-based tracking system, \nto assess eye movements in dogs with nystagmus (Jacobs et al., 2006).  This \nnecessitated mounting the eye cameras on a fixed frame in front of the dog, the dog\u2019s \nbody being maintained in a sling with the head manually restrained by an \nexperimenter.  Hence, both of these methodologies still limit the range of naturalistic \nbehaviours that can be performed by the subject as well as constraining the proportion \nof the visual scene which can be viewed.  \n \nThis paper describes the development and assessment of the accuracy of a head-\nmounted, video-based, eye-tracking system for use on dogs.  This equipment is \nintended to provide a more spatially accurate measure of canine looking behaviour \nthan techniques such as preferential viewing whilst allowing the subject to perform a \n 5\nfar greater behavioural repertoire than permitted by previous canine eye-tracking \nmethodologies.   \n  \n2. Methods  \n2.1 Apparatus \nWe adapted a VisionTrak head-mounted eye tracker (ISCAN ETL 500, Polhemus, \nVermont, USA) to record gaze patterns from freely moving domestic dogs. The \nsystem has a head-mounted eye and scene imager (consisting of a scene camera, an \neye camera, an infrared source and a dichroic mirror) which is connected to a host \nworkstation (comprising an RK 826PCI Pupil \/ Corneal Reflection Tracking \nProcessor and RK 630PCI Autocalibration System) through a cable 4m in length. \nWhen used on human participants, this robust eye tracker can collect pupil size, eye \nmovement, and eye point of regard data while allowing complete freedom of head \nmovement.  The system has a sampling rate of 60 Hz and can achieve spatial accuracy \nup to 0.3\u00b0 when used on humans (ISCAN, 2003).     \n \nIn order to attach a head-mounted eye and scene imager on the dog the apparatus was \nmounted on an aluminium head strap (Fig. 1). This provided the head strap with \nrigidity whilst still allowing it to be lightweight and shaped around the dog\u2019s head.  \nThe strap was attached to the top of a basket muzzle (Baskerville, size 8, The \nCompany of Animals) using a M10 \u00d7 20mm screw with M2 \u00d7 10mm screws located \neither side of it, all secured using nuts.  Three screws were used to prevent any lateral \nmovement of the strap.  The heads of the screws, which were located inside the \nmuzzle, were countersunk and concealed behind a leather strap, preventing possible \ndiscomfort or injury to the dog.  The head strap extended along the contour of the \n 6\ndog\u2019s head, and attached to the muzzle strap at the back of the head by passing \nunderneath it and folding back on top of it.  The muzzle strap was held secure within \nthis loop using a M4 \u00d710mm screw and nut positioned immediately in front of it in \nthe head strap.      \n \nFig. 1.  The eye tracking equipment in place on the dog showing scene camera (1) eye \ncamera (2) head strap (3) mirror support rod (4) mirror clamp (5) dichroic mirror (6) \nmuzzle (7) and mirror frame (8). \n \nOwing to the different head shape of dogs compared to humans it was decided to \nmount the dichroic mirror in front of the eye rather than below it, as is often the case \nwith head-mounted, eye-tracking systems designed for human use.  In addition, due to \nthe diversity of head and eye sizes amongst dog breeds it was necessary to be able to \nadjust the distance of the mirror from the eye to achieve a clear eye image.  To \naddress these issues the mirror was mounted from a square aluminium rod which ran \nperpendicular to the dog\u2019s nose: the mirror support rod.  Using a frame and clamp \n 7\ndevice, described below, the mirror could be extended from one of six holes of 2mm \ndiameter which were drilled horizontally into the mirror support rod at 7mm intervals, \nwith the first positioned 5mm from the tip of the rod.  Lateral movement of the mirror \nsupport rod was inhibited by a second rod, positioned on top of the central nut \nattaching the head strap to the muzzle, which projected outwards away from the head \nstrap.  A piece of threaded rod ran vertically through the end of the mirror support \nrod, secured by a nut above and below the rod, and located into a hole at the end of \nthis second rod, providing stabilisation.            \n \n In order to obtain a clear eye image from a dog with eyes positioned more laterally \nthan those of a human it was necessary for the dichroic mirror to move laterally and \nalso pivot in the horizontal plane, as well as retaining the ability to rotate around the \nvertical plane, so that it could be positioned parallel to the eye.   To facilitate this the \nmirror was held in an aluminium frame 3mm wide and 1mm thick which was shaped \naround its outer edge, with three aluminium supports 15mm long and 3mm wide \nlocated equidistantly around the edge of the frame.  The supports were attached to the \nframe using super glue and curved around either side of the mirror to hold it in place \nwithin the frame.  Pieces of cushioned adhesive pad were inserted between the \nsupports and the mirror in order to prevent scratching of the dichroic coating.  Both of \nthe ends of the strip of metal forming the frame were held in an aluminium block \n20mm long, 6mm wide, 6mm deep with a horizontal incision 7mm long and 3mm \nwide, the mirror clamp, and secured using a 1M \u00d7 13mm screw that passed through \nboth the frame and block.  This allowed the mirror to be pivoted towards and away \nfrom the eye and secured in position by tightening the nut which held the bolt in \nplace.  The mirror clamp was threaded onto a piece of threaded rod of 2mm diameter \n 8\nwhich passed through the 3rd hole in the mirror support rod and was held in place by \ntwo self-locking nuts positioned either side of the mirror support rod, allowing lateral \nmovement and rotation around the vertical plane.      \n \nAs the optimal eye image was obtained when the eye camera was parallel to the \ndichroic mirror, the eye camera was also manufactured to move laterally, pivot around \nthe horizontal plane and rotate around the vertical plane.   A square aluminium block \n20mm \u00d7 20mm and 10mm deep was mounted on the head strap at the highest \nposition on the dog\u2019s head.  In front of this was positioned a second aluminium block \nof the same dimensions into which were drilled 2 holes of 5mm diameter, running \nparallel through the horizontal section of the block and located 10mm apart.  Two \naluminium rods of 5mm diameter were positioned in the holes, the higher of these \npassed into the scene camera casing, the second was 100mm long and incorporated a \nswivel joint which allowed the final 15mm to pivot around the horizontal plane.  A \nthreaded rod of 2mm diameter and 20mm length was threaded into this end section of \nthe second rod and passed through a pair of locking nuts which tightened either side \nof an aluminium frame, 8mm wide and 1mm thick, shaped around the eye camera to \nsecure it in place.  The position of the two camera rods within the block was secured \nby screws which passed into the front of the block, one located 5mm \u00d7 5mm from the \ntop left corner of the block and one 5mm \u00d7 5mm from the bottom right corner.  When \ntightened, these screws exerted sufficient pressure on the rods to clamp them in place, \npermitting the eye camera to be moved laterally as well as rotated in the vertical plane \nand stabilised in the chosen position. The two aluminium blocks supporting the \ncamera rods were connected via a 1mm threaded rod, 28mm long, mounted into a \n 9\nsection of aluminium rod.  The threaded rod passed through the centre of the two \nblocks and screwed into the mirror support rod. \n \n2.2 Subject \nThe subject used for proof of principle was a male Alaskan Malamute, aged two \nyears.  \n \n2.3 Calibration \nThe calibration procedure required the dog to visually acquire five points in space, \none in each corner of the output captured by the scene camera and one in the centre of \nthe image.  In order to ensure standardisation of the calibration procedure the distance \nbetween the calibration points and the distance between the dog and the calibration \npoints was fixed.  This was achieved using a light metallic cross frame which could be \nmounted onto the headgear (Fig. 2).  The cross consisted of four aluminium rods, \n118mm long and of 6mm diameter each mounted centrally into the sides of a 20mm \n\u00d7 20mm aluminium block, 8mm deep.  An aluminium rod 6mm \u00d7 6mm and 235mm \nlong was centrally mounted into one square face of the block.  The cross could then be \nmounted to the mirror support rod in front of the cameras via a 6mm \u00d7 6mm \naluminium rod 60mm long which was tapered at the end to fit smoothly against the \nslope of the rod.  This was attached to the mirror support rod via a 2M \u00d7 23mm and a \n2M \u00d7 30mm bolt, which ran vertically through both rods.  This was connected to a \nhollow rod 8mm \u00d7 8mm and 25mm long, via a 2mm \u00d7 20mm section of threaded rod \nwhich passed vertically through both.  The calibration device could then be slotted \ninto this hollow rod and removed once calibration had been achieved.  Cardboard \nsquares 25mm \u00d7 25mm were attached to the end of each of the four rods forming the \n 10\ncross and in front of the central square.  This enabled easy identification of the four \ncorner points from the scene output monitor and provided the experimenter with clear \ntargets at which to hold stimuli during the calibration process. This device created a \nfive point calibration system with the four corner calibration points being an equal \ndistance of 25\u00b0 away from the central calibration point. \n \nFig. 2.  The calibration cross in place on the head gear showing cross mount (1) and \ncalibration cross (2). \n \n A stimulus, a treat 10mm x 10mm (2.1 \u00d7 2.1\u00ba), was held in the centre of each of the \nfive squares in turn, when the dog was judged to be fixating on the treat in any given \nlocation the calibration point was entered into the computer.  Once all five points had \nbeen acquired in this way calibration accuracy could be tested.     \n \n \n \n 11\n2.4 Training \nIn order to habituate the dog to the apparatus it was initially muzzle-trained using \nfood-based positive reinforcement.  Once the muzzle was tolerated for periods up to \n30 minutes, the head strap was added and the habituation procedure repeated, this \nprocess was repeated twice more for the addition of the cameras and the mirror. \nIn order to carry out calibration the dog was trained to visually track a treat using eye \nmovements with minimal movement of the head.  This was achieved using positive \nreinforcement; an audible click was used to mark the desired behaviour more \nprecisely.  Initially, visual following of a treat was accompanied by large head \nmovements, however, over approximately 10 training sessions head movements \nbecame minimal and eye movements increased. The same methods were used to train \nthe dog to maintain fixation on the treat when it was held stationary. The dog was then \ngradually habituated to the calibration cross being slotted into the front of the \nheadgear over approximately 5 training sessions, the cross was initially tolerated for \n10-20 seconds without behaviours which attempted to remove it, such as pawing at \nthe device, this was increased to 2-3 minutes during training. Following this the dog \nwas reinforced for fixating on treats held at the five calibration point locations.             \n \n2.5 Data collection \nThe eye tracker was calibrated as described in section 2.3.  The treat was held at each \nof the calibration point locations in such a way that the experimenter\u2019s hand and arm \ndid not enter the space between the five points in order to prevent this acting as a \ndistraction. When attracting the dog\u2019s attention towards the treat the experimenter \ncalled the dog\u2019s name and pointed to it.  If the dog continued not to look at the treat it \nwas removed from its position and then replaced. For accuracy, only footage with no \n 12\nmovement or vocalisation was coded. The order in which the treat was held at the five \nlocations was randomised between trials in order to prevent learned behaviour \ninfluencing the results.  No rewards were given during the trial; once the trial had \nended the dog received the treat.  All output from the eye tracker was recorded onto \nDVD via a Logik LDVR808 DVD recorder.  Nineteen trials were conducted of which \nfive provided codeable data for all five calibration points.            \n \n2.6 Treatment of data \nOutput from the eye tracker was coded frame by frame at a rate of 30 frames per \nsecond, using a DVD player and a 290mm \u00d7 230mm Philips LDH2114\\10 video \nmonitor.  For each of the five calibration points the distance was measured between \nthe centre of the treat when held in position and the centre of the output crosshair in a \ndirect line.  The vertical and horizontal distance between the output crosshair and the \nstimulus was also measured.  The visual angle between the treat and the crosshair was \ncalculated for each of these measurements on a frame-by-frame basis. \n \nAs previous information concerning the use of eye tracking technology on dogs is \nextremely limited there is a lack of data regarding the features of fixations in this \nspecies during visual exploration. Therefore two parameters were examined in detail: \nfirst fixation (the first set of data which matched the fixation criteria) and closest \nfixation (the dataset matching the criteria in which the output crosshair was closest to \nthe fixation point). These two sets of data were considered as eye-tracking research in \nhumans has demonstrated that first fixations on a stimulus tend to be less accurate \nthan subsequent fixations as they can be subject to overshoot and undershoot (B\u00f6tzel \net al., 1993). To qualify as a fixation the output crosshair had to fall within 30mm \n 13\n(5.8\u00ba) of the fixation point (centre of the treat) and not move around the fixation point \nat an average speed of more than 25\u00b0\/second for a given duration. The data were \nexamined using five different minimum durations for this behaviour. These were 67, \n100, 133, 167 or 200ms.  30mm (5.8\u00ba) was chosen as the maximum distance that the \noutput crosshair could fall from the fixation point, since the minimum distance \nbetween any two fixation points on the metal calibration cross was 120mm (25\u00ba) (i.e. \ndistance from centre of the cross to the centre of the cardboard squares positioned at \nthe end of the arms). Thus the distance between any two fixation points was at least \ntwice the radius around them (Fig. 3).      \n \nCardboard  \nsquare   \n30mm       \nradius\n60mm\nAluminium \nrod   \nFixation \narea\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 14\n  \n \n \nFig. 3.  Scale diagram of calibration equipment and fixation classification areas.  \nScale 1:3. \n \n Accuracy was assessed from the mean distance that the centre of the crosshair \nremained from the centre of the fixation point during a fixation. Data for each of the \nfive calibration points were averaged across the five trials, providing an overall \naccuracy level for each point. Accuracy for first and closest fixations was obtained for \neach of the fixation durations; these were then averaged across all durations to \ncalculate the overall accuracy of the system for first and closest fixations.  Horizontal \nand vertical accuracy between the crosshair and the fixation point was calculated for \neach fixation in the same manner.  \n \n2.7 Statistical Analysis \nInitial summary descriptive statistics were calculated for accuracy based on mean \ndeviation from centre of fixation point. Accuracy for first versus closest fixation for \ndifferent fixation durations was compared using a repeated measures ANOVA.  In \norder to examine the relationship between accuracy and fixation length for the closest \nfixation data, regression analysis using a quadratic equation was used following \ninspection of its graphical representation. Evaluation of these results was used to  \ndetermine the recommended optimal fixation duration to use in practice.       \n \n 15\n3. Results \nThe overall accuracy using different fixation duration criteria was around 3\u00b0 (Table \n1).   \n______________________________________________________ \nMinimum length  Accuracy (\u00ba)  Accuracy (\u00ba) \nof fixation (ms)  first fixation  closest fixation \n Mean\u00b1SD  Mean\u00b1SD \n______________________________________________________ \n67    3.76\u00b10.58  2.25\u00b10.47 \n100    3.69\u00b10.73  2.51\u00b10.6 \n133    3.48\u00b10.81  2.6\u00b10.58 \n167    3.62\u00b11.06  2.67\u00b10.62 \n200    3.41\u00b11.09  2.71\u00b10.67  \n \nTable 1: Accuracy of crosshair location on video output in relation to predetermined \nfocal points for fixations defined by varying durations.  First fixation = first dataset \nmatching fixation criteria, closest fixation = dataset matching fixation criteria during \nwhich output crosshair was closest to defined focal point.     \n \nThe mean level of accuracy for the first fixation across all durations was 3.59\u00b0 \u00b1 0.07 \n(radius\u00b1SEM). The mean level of accuracy for the closest fixation was 2.55\u00b0 \u00b1 0.08. \nClosest fixation produced a higher level of accuracy (repeated measures ANOVA: \nF(1,4) = 55.93  p = 0.002   partial \u03b72 = 0.93).  \n \n 16\nThe mean vertical and horizontal accuracy for the first fixations across all durations \nwere 2.31\u00ba \u00b1 0.09 and 2.53 \u00ba \u00b1 0.04, respectively.  The mean levels of vertical and \nhorizontal accuracy for the closest fixations were 1.63\u00ba \u00b1 0.03 and 1.85\u00ba \u00b1 0.07.  \nVertical accuracy was greater than horizontal accuracy for the closest fixations \n(repeated measures ANOVA: F(1,4) = 31.390  p = 0.005   partial \u03b72 = 0.89).  No \nsignificant differences were found between vertical and horizontal accuracy for the \nfirst fixations.  Horizontal and vertical accuracy across all fixation durations for the \nclosest durations are shown in Table 2.   \n____________________________________________________________ \nMinimum length  Vertical Horizontal  \nof fixation (ms)  accuracy (\u00ba)  accuracy (\u00ba) \n ______________________________________________________ \n67    1.51\u00b10.33  1.66\u00b10.31  \n100    1.61\u00b10.3  1.74\u00b10.44  \n133    1.65\u00b10.4  1.85\u00b10.33    \n167    1.68\u00b10.38  1.95\u00b10.41    \n200    1.69\u00b10.4  2.03\u00b10.52   \n _______________________________________________________  \n \nTable 2: Vertical and horizontal accuracy of crosshair location on video output for \nclosest fixations defined by varying durations.  Values presented in the table are \nMean\u00b1SD \n \nRegression analysis using a quadratic equation produced a model with excellent fit \n(adjusted R squared = 96.4 %) to describe the relationship between accuracy and the \n 17\nduration used to define a fixation (accuracy = 1.648 + 0.01125fixation \u2013 0.00003 \nfixation\u00b2). Visual inspection of the data, suggests that the point of maximum inflection \nof the curve occurs around 100ms (Fig. 4) and that accuracy stabilises beyond 200ms.  \nSince the apparent accuracy will be affected by both the number of frames sampled as \nwell as the reliability of the system per se, the optimal fixation duration to use in \npractice is based upon consideration of both the relationship between accuracy and \nfixation duration as well as the point at which this relationship stabilises. On this basis \nwe suggest that 100ms represents the minimum optimal fixation length to use in \npractice, since below this time, the apparently high level of accuracy may be an \nartefact of the limited data used in its determination. \n  \nData for the accuracy of individual fixation points using the closest fixation criterion \nare given in Table 3.   \n \n \n \n \n \n \n_________________________________________________________ \nCalibration point Accuracy (\u00ba) minimum Accuracy (\u00ba) minimum \n   fixation 100ms  fixation 200ms  \n Mean\u00b1SD Mean\u00b1SD \n_____________________________________________________________ \nTop left  2.84\u00b11.46   2.84\u00b11.46 \n 18\nTop right  2.84\u00b11.74   3.48\u00b12.31 \nBottom left  2.00\u00b10.80   2.32\u00b10.89 \nBottom right  1.75\u00b10.48   1.77\u00b10.51 \nCentre   3.12\u00b11.19   3.12\u00b11.19  _ \n \nTable 3: Output accuracy levels for individual calibration points \n \n \n \nFig. 4.  Accuracy (\u00ba) versus minimum fixation lengths for closest fixations with fitted \nline.  Increase in degrees indicates reduced accuracy. \n \nIt is suggested that the following definition be applied in future when using this \nequipment to determine fixations by the dog: a period of at least 100ms duration \nduring which the output crosshair falls within 6\u00ba of a region of interest and does not \n 19\nmove around the centre of the point of interest at an average speed of more than \n25\u00b0\/second. For calibration purposes it is suggested that the closest fixation be used.  \n \n 4. Discussion \nWe have developed and described a reliable head-mounted, eye-tracking system \nsuitable for use on dogs and a standardised calibration procedure for this equipment.  \nThe accuracy level of 2.25-2.71\u00b0 achieved using this system is within the bounds of \nupper accuracy levels obtained recording the eye movements of other non-human \nspecies (Shepherd and Platt, 1996; Guo et al, 2003).  We have also provided a \nsuggested definition of a fixation for future research utilising this apparatus on dogs.  \nOur mean vertical accuracy of 1.63\u00ba for closest fixations is very consistent with a \ncanine area centralis which extends \u00b1 1.5\u00ba vertically (Jacobs et al., 2006).  Greater \ndiscrepancy in horizontal accuracy between the current finding of 1.85 \u00ba and a \nreported area centralis extending \u00b1 3\u00ba (Jacobs et al., 2006) may reflect variation in the \ndistribution of retinal ganglion cells that has been noted between dogs with different \nnose lengths (McGreevy et al., 2006).  In addition, our finding that first fixations were \nless accurate than subsequent fixations is consistent with dogs employing similar eye \nmovements to humans when making saccades towards and fixations upon a stimulus \nin which the eye positions itself with greater accuracy during subsequent fixations.  \nThis also offers a possible explanation for our finding of a significant difference \nbetween vertical and horizontal accuracy for closest but not first fixations, as during \nthe first fixation the stimulus may not be positioned on the area centralis of the retina.          \n \nUse of a video-based, eye-tracking system on a non-human species without head \nrestraint does pose some logistical challenges.  In particular, the amount of training \n 20\nrequired to habituate the subject to the equipment and to teach the animal to follow \nand fixate on a stimulus with minimal head movements in order to achieve accurate \ncalibration.  However, even though the training may be time consuming, it is \nrelatively straightforward, being based on simple habituation and routinely used \npositive-reward operant procedures.  A further potential problem is the introduction of \nerror into the accuracy of data due to minor movements of the equipment on the dog\u2019s \nhead during testing.  For this reason it is suggested that output accuracy is assessed \nimmediately following calibration, using the method described in section 2.5, and \nagain at the end of each testing block.  Restricting the length of testing sessions to \ntime periods for which the dog will tolerate the equipment without becoming restless \nwould also help to overcome this issue.  As calibration is performed with the dog \nfacing the experimenter the direction of gaze can also be visually assessed as the \ncalibration points are entered into the system.   \n \nThe current study utilised a narrow-view scene camera lens intended for studying \nclose-range dog-dog and dog-human interactions, adaptations to the equipment and \ncalibration protocol may be necessary when the wide-view scene camera is used for \nstudying dog\u2019s gaze behaviour towards visual stimuli at greater distances. As the \nviewing distance of our calibration grid (approximately 30cm) is very close to dogs\u2019 \noptimal accommodation range (33\u201350cm; Miller and Murphy, 1995), it is unlikely our \ncalibration distance will induce near point of convergence in dogs. Furthermore, we \nuse dogs with reasonable binocular vision in our research as this reduces the \npossibility of convergence, due to the need to maintain binocular vision, during the \ncalibration procedure.  In addition, this measure will facilitate the comparison of \nacquired data with that from humans and non-human primates.         \n 21\n Use of a monocular eye tracker can have limitations and present challenges.  \nInformation regarding the intersection of gaze angles from both eyes is not available \nto facilitate the identification of targets at depths different to that for which the \nequipment has been calibrated.  Care must also be taken when selecting appropriate \nsubjects, for example, achiasmatic dogs have been shown to display monocular \nsaccades (Dell\u2019Osso and Williams, 1995) and hence representative eye movement \ndata could not be obtained from such animals using a monocular device.  In addition, \ndogs in general may show looser yoking of the two eyes than is found in humans and \nnon-human primates (Dell\u2019Osso and Williams, 1995).  If this is the case then the \ncurrent methodology of conducting a binocular calibration, with both eyes viewing \nthe stimuli, may result in a less accurate output than monocular calibration, in which \nonly the eye being tracked would view the calibration stimulus, ensuring that stimuli \nare fixated by the correct eye.  Binocular calibration was employed in the current \nstudy as it can be performed more quickly, is less intrusive and requires less training \nthan monocular calibration.  In addition, in some circumstances, such as our intention \nto study gaze behaviour in naturalistic settings, dogs use both eyes to view scenes.  \nTherefore, given that monocular calibration with a monocular eye-tracker would only \nallow one eye to view the calibration points, binocular calibration may be more \necologically valid and more comparable with data obtained from a dog viewing \nbinocularly.  The protocol of binocular calibration with a monocular eye-tracking \nsystem is not uncommon in studies of fixational and scene viewing gaze behaviour in \nhumans and non-human primates (e.g. Guo et al., 2003; Guo, 2007; Steckenfinger and \nGhazanfar, 2009; Shepherd et al., 2010).  Previous studies have revealed that during a \nsaccade, the eyes may initially diverge, but convergence occurs in the later part of the \n 22\nsaccade, continuing into the following fixation period (e.g. Collewijn et al., 1995), \nsuggesting that maximum disparity between the eyes occurs during saccades with \nincreased convergence during fixations.  Indeed, it has been suggested that for tasks \nthat do not require far distance or depth perception, such as reading, monocular and \nbinocular calibration produce comparable results in human adults (Nuthmann and \nKliegl, 2009). Given the relative infancy of canine eye-tracking, particularly using \nmonocular equipment, there is a lack of information regarding the effects of \nmonocular and binocular calibration; further research in this area is necessary to \ninform future calibration protocols.         \n \nDespite these caveats the monocular system employed here provides a number of \nbenefits for conducting behavioural research with dogs.  It is unobtrusive; the only \nequipment placed in front of the eye is the transparent mirror and the lack of restraint \nrequired may permit longer recording sessions than would be tolerated by a restrained \nsubject.  The equipment is relatively inexpensive and can be easily operated by a \nsingle experimenter.  In addition, calibration can be conducted quickly, which is \nhighly beneficial when working with non-verbal subjects.  Monocular systems have \nbeen commonly used to study natural vision in humans navigating through the \nenvironment (Cheong et al., 2008) and when looking at more detailed stimuli such as \nfaces (Kleinhans et al., 2008), as well as in non-human animals (Shepherd and Platt, \n2006).   \n \nThe five calibration point locations, the centre and four corners of the scene output, \nwere chosen to assess the accuracy of the system as these positions are typically used \nfor rapid calibration in head-mounted eye trackers.  Use of these positions may be \n 23\nmore susceptible to cross-talk errors between the horizontal and vertical axes \ncompared to points actually located on the two axes (i.e. left, right, top and bottom).  \nHowever, overall, the use of these corner points is likely to allow a more naturalistic \naccount of eye movements by considering non-linear interactions between the \nhorizontal and vertical planes.        \n \nOur system appears to provide a greater level of accuracy than the head-mounted \nISCAN system used with macaques by Shepard and Platt (2006), which achieved an \naccuracy of 5-10\u00b0.  This may reflect the more standardised calibration procedure \nemployed in the current study.  The calibration cross enabled standardisation of the \ndistance between both the calibration points and the subject and the distance between \nthe points themselves, whilst Shepherd and Platt (2006) calibrated their equipment \nwith a trainer holding treats entering the visual scene and standing at the five \ncalibration locations, permitting less standardisation of distances.  Whilst the current \ntechnique provides less spatial accuracy than that provided by the scleral search coil \ntechnique employed by Guo et al. (2003) in primates, which achieved an accuracy \nlevel under 1\u00b0, the current technique permits investigation in more naturalistic \nsettings, allowing movement of both head and body, as well as avoiding the surgery \nrequired to implant a coil into the eye of a non-human species.  By allowing a greater \nbehavioural repertoire including head movement, a larger proportion of the visual \nscene can be scanned by a subject wearing the current device compared to that used in \nother techniques such as that employed by Jacobs et al (2006), allowing a more \nenriched view of visual attention.  Hence, whilst not suitable for recording very \ndetailed eye movement information, it is hoped that this equipment will permit a \n 24\nnaturalistic method for studying the allocation of dogs\u2019 visual attention in nature \nvision.  \n \nIn future, the authors hope to use this system to study dogs\u2019 visual attention in a \nvariety of naturalistic settings, such as in social interactions both with members of \ntheir own species and humans.  It also has the potential to provide a measure of visual \nacuity both between dog breeds and in specific individuals.  As allocation of visual \nattention can be used to assess cognitive function (Crutcher et al., 2009), the system \ncould also be applied to the identification of cognitive changes and degeneration. \n \nIn conclusion, this system provides a non-invasive method of assessing dogs\u2019 looking \nbehaviour without restraint with a higher level of spatial accuracy than previously \navailable for this species, and has potential application in a wide variety of research \nsettings.   \n \nAcknowledgements \nThe authors wish to thank David Williams for his help and guidance with manufacture \nof the equipment, Paul Coster, George Rodis and Andrew Sherman for their technical \nsupport and Petronella Nilsson for her assistance during the training process.  \n 25\nReferences: \n \nAslin RN, McMurray B.  Automated corneal-reflection eye tracking in infancy: \nmethodological developments and applications to cognition.  Infancy, 2004;6:155-63. \nB\u00f6tzel K, Rottach K, B\u00fcttner U.  Normal and pathological saccadic dysmetria.  Brain, \n1993;116:337-53. \nCheong AMY, Geruschat DR, Congdon N.  Traffic gap judgment in people with \nsignificant peripheral field loss.  Optometry Vision Sci., 2008; 85:26-36.   \nCollewijn H, Erkelens CJ, Steinman RM.  Voluntary binocular gaze-shifts in the plane \nof regard: dynamics of version and vergence.  Vision Res., 1995;35:3335-58.   \nCrutcher MD, Calhoun-Haney R, Manzanares CM, Lah JJ, Zola SM.  Eye tracking \nduring a visual paired comparison task as a predictor of early dementia.  Am J \nAlzheimer\u2019s Dis., 2009;24:258-66 \nDavis TS, Torab K, House P, Greger B.  A minimally invasive approach to long term \nhead fixation in behaving nonhuman primates.  J Neurosci Meth., 2009;181:106-10.   \nDell'osso LF, Daroff RB. Eye movement characteristics and recording techniques. In \nGlaser JS, editor. Neuro-Ophthalmology.  Lippincott, Williams & Wilkins: \nPhiladelphia, 1999:327-43. \nDell\u2019Osso LF, Hertle RW, Williams RW, Jacobs JB.  A new surgery for congenital \nnystagmus: effects of tenotomy on an achiasmatic canine and the role of extraocular \nproprioception.  JAAPOS, 1999;3:166-82.   \nDell\u2019Osso LF, Williams RW.  Ocular motor abnormalities in achiasmatic mutant \nBelgian sheepdogs: unyoked eye movements in a mammal.  Vision Res., \n1995;35:109-16. \n 26\nDell\u2019Osso LF, Williams RW, Jacobs JB, Erchul DM.  The congenital and seesaw \nnystagmus in the prototypical achiasma of canines: comparison to the human \nachiasmatic prototype.  Vision Res., 1998;38:1629-41. \nDuchowski AT.  Eye Tracking Methodology: Theory and Practice, first ed.  Springer: \nBerlin, 2003: 56. \nG\u00e1csi M, Mikl\u03ccsi A, Varga O, Top\u00e1l J, Cs\u00e1nyi V.  Are readers of our face readers of \nour minds?  Dogs (Canis familiaris) show situation dependent recognition of humans\u2019 \nattention.  Anim Cogn., 2004;7:144-53 \nGuo K.  Initial fixation placement in face images is driven by top-down guidance.  \nExp Brain Res., 2007;181:673-77.  \nGuo K, Meints K, Hall C, Hall S, Mills D. Left gaze bias in humans, rhesus monkeys \nand domestic dogs. Anim Cogn., 2009;12:409-18.  \nGuo K, Robertson RG, Mahmoodi S, Tadmor Y, Young MP.  How do monkeys view \nfaces? \u2013 A study of eye movements. Exp Brain Res., 2003;150: 363-74. \nHenderson JM.  Human gaze control during real world scene perception.  Trends \nCogn Sci., 2003;7:498-504. \nISCAN Inc.  ISCAN ETL-500 Operating Instructions.  ISCAN Inc.: Woburn, 2003:3. \nJacobs JB, Dell\u2019Osso LF, Hertle RW, Acland GM, Bennett J.  Eye movement \nrecordings as an effectiveness indicator of gene therapy in RPE65 deficient canines: \nimplications for the ocular motor system.  Invest Opthalmol Vis Sci., 2006;47:2865-\n75.  \nJudge SJ, Richmond BJ, Chu FC.  Implantation of magnetic search coils for \nmeasurement of eye position: an improved method.  Vision Res., 1980;20:535\u201338. \n 27\nKleinhans NM, Richards T, Stirling L, Stegbauer KC, Mahurin R, Johnson LC, \nGreenson J, Dawson G, Aylward E.  Abnormal functional connectivity in autism \nspectrum disorders during face processing.  Brain, 2008; 131:1000-12.  \nK\u00f6rding KP, Kayser C, Betsch BY, K\u00f6nig P.  Non contact eye tracking on cats.  J \nNeurosci Meth., 2001;110:103-11. \nLand MF.  Eye movements and the control of actions in everyday life.  Prog Retin \nEye Res., 2006;25:296-334. \nMcGreevy PD, Grassi TD, Harman AM.  A strong correlation exists between the \ndistribution of retinal ganglion cells and nose length in the dog.  Brain Behav Evolut., \n2004;63:13-22.  \nMiller PE, Murphy CJ.  Vision in Dogs.  J Am Vet Med Assoc., 1995;207:1623-34. \nNuthmann A, Kliegl R.  An examination of binocular reading fixations based on \nsentence corpus data.  J Vision, 2009;9:1-28. \nRacca A, Amadei E, Ligout S, Guo K, Meints K, Mills D. Discrimination of human \nand dog faces and inversion responses in domestic dogs (Canis familiaris). Anim \nCogn., 2010;13:525-33. \nRayner K.  Eye movements in reading and information processing.  Psychol Bull., \n1998;124:372-422. \nReid MS, Nishino S, Tafti M, Siegel JM, Dement WC, Mignot E.  \nNeuropharmacological characterisation of basal forebrain cholinergic stimulated \ncataplexy in narcoleptic canines.  Exp Neurol., 1998;151:89-104.    \nReid MS, Tafti M, Nishino S, Sampathkumaran R, Siegel JM, Mignot E.  Local \nadministration of dopaminergic drugs into the ventral tegmental area modulates \ncataplexy in the narcoleptic canine.  Brain Res., 1996;733:83-100.     \n 28\nRussell WMS, Burch RL.  The Principles of Humane Experimental Technique, first \ned.  Methuen: London, 1959. \nShepherd SV, Platt ML.  Noninvasive telemetric gaze tracking in freely moving \nsocially housed prosimian primates.  Methods, 2006;38:185-94.  \nShepherd SV, Steckenfinger SA, Hasson U, Ghazanfar AA.  Human-monkey gaze \ncorrelations reveal convergent and divergent patterns of movie viewing.  Curr Biol., \n2010;20:649-56. \nStahl JS, van Alphen AM, De Zeeuw CI.  A comparison of video and magnetic search \ncoil recordings of mouse eye movements.  J Neurosci Meth., 2000;99:101-10. \nSteckenfinger SA, Ghazanfar AA.  Monkey visual behavior falls into the uncanny \nvalley.  P Natl Acad Sci USA, 2009;106:18362-466. \nVir\u00e1nyi Z, Top\u00e1l J, G\u00e1csi M, Mikl\u03ccsi A, Cs\u00e1nyi V.  Dogs respond appropriately to \ncues of humans\u2019 attentional focus.  Behav Process., 2004;66:161-72. \n 29\n"}
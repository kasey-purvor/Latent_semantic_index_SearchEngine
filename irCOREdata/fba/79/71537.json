{"doi":"10.1007\/s11222-006-5197-1","coreId":"71537","oai":"oai:eprints.lancs.ac.uk:741","identifiers":["oai:eprints.lancs.ac.uk:741","10.1007\/s11222-006-5197-1"],"title":"Simultaneous confidence intervals by iteratively adjusted alpha for relative effects in the one-way layout.","authors":["Wolfsegger, Martin J.","Jaki, Thomas"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2006","abstract":"A bootstrap based method to construct 1 \u00e2\ufffd\ufffd \u00ce\u00b1 simultaneous confidence intervals for relative effects in the one-way layout is presented. This procedure takes the stochastic correlation between the test statistics into account and results in narrower simultaneous confidence intervals than the application of the Bonferroni correction. Instead of using the bootstrap distribution of a maximum statistic, the coverage of the confidence intervals for the individual com- parisons are adjusted iteratively until the overall confidence level is reached. Empirical coverage and power estimates of the introduced procedure for many-to-one comparisons are presented and compared with asymptotic procedures based on the multivariate normal distribution","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/71537.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/741\/1\/ISAAhomepage.pdf","pdfHashValue":"7d089ef667d4a51ef18f1e05c510b6f2987e9f0a","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:741<\/identifier><datestamp>\n      2018-01-24T03:16:41Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Simultaneous confidence intervals by iteratively adjusted alpha for relative effects in the one-way layout.<\/dc:title><dc:creator>\n        Wolfsegger, Martin J.<\/dc:creator><dc:creator>\n        Jaki, Thomas<\/dc:creator><dc:subject>\n        QA Mathematics<\/dc:subject><dc:description>\n        A bootstrap based method to construct 1 \u00e2\ufffd\ufffd \u00ce\u00b1 simultaneous confidence intervals for relative effects in the one-way layout is presented. This procedure takes the stochastic correlation between the test statistics into account and results in narrower simultaneous confidence intervals than the application of the Bonferroni correction. Instead of using the bootstrap distribution of a maximum statistic, the coverage of the confidence intervals for the individual com- parisons are adjusted iteratively until the overall confidence level is reached. Empirical coverage and power estimates of the introduced procedure for many-to-one comparisons are presented and compared with asymptotic procedures based on the multivariate normal distribution.<\/dc:description><dc:date>\n        2006<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/741\/1\/ISAAhomepage.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/s11222-006-5197-1<\/dc:relation><dc:identifier>\n        Wolfsegger, Martin J. and Jaki, Thomas (2006) Simultaneous confidence intervals by iteratively adjusted alpha for relative effects in the one-way layout. Statistics and Computing, 16 (1). pp. 15-23. ISSN 0960-3174<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/741\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1007\/s11222-006-5197-1","http:\/\/eprints.lancs.ac.uk\/741\/"],"year":2006,"topics":["QA Mathematics"],"subject":["Journal Article","PeerReviewed"],"fullText":"Simultaneous Confidence Intervals by Iteratively\nAdjusted Alpha for Relative Effects in the\nOne-way Layout\nMartin J. Wolfsegger\nDepartment of Biostatistics, Baxter AG, Vienna, Austria\nThomas Jaki\nDepartment of Statistics, University of South Carolina, Columbia\nNovember 7, 2007\nThis article is published in Statistics and Computing, 16(1):1523, 2005.\nDOI: 10.1007\/s11222-006-5197-1. The original publication is available at\nwww.springerlink.com\nAbstract\nA bootstrap based method to construct 1\u2212\u03b1 simultaneous confidence intervals\nfor relative effects in the one-way layout is presented. This procedure takes\nthe stochastic correlation between the test statistics into account and results\nin narrower simultaneous confidence intervals than the application of the Bon-\nferroni correction. Instead of using the bootstrap distribution of a maximum\nstatistic, the coverage of the confidence intervals for the individual comparisons\nare adjusted iteratively until the overall confidence level is reached. Empiri-\ncal coverage and power estimates of the introduced procedure for many-to-one\ncomparisons are presented and compared with asymptotic procedures based on\nthe multivariate normal distribution.\nKeywords: Bootstrap; Nonparametric, Simultaneous Confidence Intervals\n1 Introduction\nConsider a control treatment labeled k and test treatments labeled 1, 2, . . . , k\u22121\nwhere k \u2265 3. Let {xij (1 \u2264 j \u2264 ni)} be a random sample of size ni from\ntreatment i (1 \u2264 i \u2264 k). We assume that the xij \u2019s come from a continuous\ndistribution Fi (1 \u2264 i \u2264 k). Relative effects can be used (e.g. Munzel and\nHothorn, 2001) to estimate effects between the control and test treatments\np\u0302ik =\n1\nni\n(\nRk \u2212 nk + 12\n)\n(1 \u2264 i \u2264 k \u2212 1) (1)\n1\nwhere Rk denotes the mean rank of the sample xk of the pooled and ranked\nsamples xi and xk.\nMunzel and Hothorn (2001) presented an asymptotic approach for relative\neffects for two types of hypothesis. Their procedures use the multivariate nor-\nmal distribution as the asymptotic distribution of a maximum statistic where\nthe exact critical values can be derived using the algorithm of Genz (1992).\nThe straightforward bootstrap version can markedly loose power in the case of\nskewed and contaminated distributions as observed in their simulation study.\nHere, a different approach is presented to construct simultaneous confidence in-\ntervals for relative effects for comparisons of k\u2212 1 treatments against a control.\n2 Multivariate Distribution of Relative Effects\nUsing complete rerandomization to estimate a multivariate distribution as pro-\nposed by Miller (1981) is not appropriate for single step procedures as pointed\nout by Petrondas and Gabriel (1983). We use the following bootstrap algorithm\nto estimate the multivariate distribution of the relative effects.\nAlgorithm 1\n1. Let x\u2217i be a bootstrap sample from xi \u2200 i = 1, . . . , k.\n2. Calculate and store p\u0302\u2217ik \u2200 i = 1, . . . , k \u2212 1.\n3. Repeat B times.\nThe whole scheme results in B points in a k\u22121 dimensional surface representing\nthe joint distribution of p\u0302\u2217 =\n(\np\u0302\u22171k, p\u0302\n\u2217\n2k, . . . , p\u0302\n\u2217\n(k\u22121)k\n)\n. The k \u2212 1 dimensional\nsampling cumulative distribution function is estimated by\nH\u0302 (t) =\n1\nB\nB\u2211\nb=1\n{\n1 if p\u0302\u2217(b)1k \u2264 t1, . . . , p\u0302\u2217(b)ik \u2264 ti, . . . , p\u0302\u2217(b)(k\u22121)k \u2264 tk\u22121\n0 otherwise\n}\n(2)\nwhere the superscript (b) refers to the bth bootstrap replication. The esti-\nmate of the cumulative distribution function H\u0302ik for the individual p\u0302\u2217ik (1 \u2264 i \u2264 k \u2212 1)\ncan be derived from H\u0302(t) to be\nH\u0302ik (ti) =\n1\nB\nB\u2211\nb=1\n{\n1 if p\u0302\u2217(b)1k <\u221e, . . . , p\u0302\u2217(b)ik \u2264 ti, . . . , p\u0302\u2217(b)(k\u22121)k <\u221e\n0 otherwise\n}\n. (3)\nThe main idea of this method is to select a k\u2212 1 dimensional subspace with\nprobability 1\u2212 \u03b1 from H\u0302(t) by solving the equation\nP\n(\nt\n(\u03b12 )\ni \u2264 p\u0302\u2217ik \u2264 t\n(1\u2212\u03b12 )\ni \u2200 i = 1, . . . , k \u2212 1\n)\n= 1\u2212 \u03b1 (4)\n2\nfor t(\n\u03b1\n2 ) =\n(\nt\n(\u03b12 )\n1 , . . . , t\n(\u03b12 )\nk\u22121\n)\nand t(1\u2212\n\u03b1\n2 ) =\n(\nt\n(1\u2212\u03b12 )\n1 , . . . , t\n(1\u2212\u03b12 )\nk\u22121\n)\n. By adding\nup all 2k\u22121 corners, the equation above can be denoted as\nG\u0302\n(\nt(\n\u03b1\n2 ), t(1\u2212\n\u03b1\n2 )\n)\n=\n\u2211\nei=t\n(\u03b12 )\ni or t\n(1\u2212\u03b12 )\ni\n(\u22121)z(e1,...,ek\u22121) H\u0302 (e1, . . . , ek\u22121) = 1\u2212 \u03b1\n(5)\nwhere z (e1, . . . , ek\u22121) represents the number of ei that equal t\n(1\u2212\u03b12 )\ni . Solving\nthis non-linear equation for 2 (k \u2212 1) parameter of interest yields at least k \u2212 1\nsolutions.\n3 Numerical Root Finding\nThe balanced tail probability criteria and the balanced coverage probability\nas mentioned by Tu and Zhou (2000) are used to find a unique solution for\nequation 4. This leads to a system of non-linear equations\nP\n(\nt\n(\u03b12 )\ni \u2264 p\u0302\u2217ik \u2264 t\n(1\u2212\u03b12 )\ni \u2200 i = 1, . . . , k \u2212 1\n)\n= 1\u2212 \u03b1 (6)\nP\n(\nt\n(\u03b12 )\ni \u2264 p\u0302\u2217ik\n)\n= P\n(\nt\n(1\u2212\u03b12 )\ni \u2265 p\u0302\u2217ik\n)\n= P\n(\nt\n(\u03b12 )\nj \u2264 p\u0302\u2217jk\n)\n= P\n(\nt\n(1\u2212\u03b12 )\nj \u2265 p\u0302\u2217jk\n)\nwhere 1 \u2264 i < j \u2264 k \u2212 1.\nSolving this system of non-linear equations for t(\n\u03b1\n2 ) and t(1\u2212\n\u03b1\n2 ) results in\nk \u2212 1 lower and upper bounds of the k \u2212 1 simultaneous bootstrap confidence\nintervals.\nFor numerical root finding of this system of non-linear equations, the well\nknown bisection method for numerical root finding in single variable non-linear\nequations can be applied. The bisection method uses two initial guesses \u03b1e\nand \u03b1s which represent the type I errors for the k \u2212 1 simultaneous confidence\nintervals. Let \u03b1s = \u03b1 and \u03b1e = \u03b1k\u22121 , the Bonferroni corrected alpha level,\nwhich is a conservative upper bound. The Bonferroni inequality is discussed in\nstandard text books, e.g. Hochberg and Tamhane (1987) and Hsu (1996). The\nk \u2212 1 \u03b1 levels for the individual simultaneous confidence intervals are adjusted\niteratively until the specified overall 1\u2212 \u03b1 level is reached.\nThe following algorithm shows how to get the k \u2212 1 dimensional upper and\nlower bounds for the simultaneous bootstrap confidence intervals at level 1\u2212\u03b1.\nAlgorithm 2\n1. Let \u03b1s = \u03b1, \u03b1e = \u03b1\/ (k \u2212 1) and \u03b1m = 12 (\u03b1s + \u03b1e).\n3\n2. Get confidence limits of the k \u2212 1 individual inferences using \u03b1s, \u03b1e and\n\u03b1m as per-comparison error rates. This can be done by calculation of\nlower\n(\n\u03b1s\n2 ,\n\u03b1e\n2 ,\n\u03b1m\n2\n)\nand upper\n(\n1\u2212 \u03b1s2 , 1\u2212 \u03b1e2 , 1\u2212 \u03b1m2\n)\nquantiles for all\nk\u22121 relative effects p\u0302ik using corresponding the one-dimensional marginal\nbootstrap distributions H\u0302ik (1 \u2264 i \u2264 k \u2212 1) .\n\u2022 t(\n\u03b1s\n2 )\ni = H\u0302\n\u22121\nik\n(\n\u03b1s\n2\n)\nand t(\n1\u2212\u03b1s2 )\ni = H\u0302\n\u22121\nik\n(\n1\u2212 \u03b1s2\n)\n.\n\u2022 t(\n\u03b1e\n2 )\ni = H\u0302\n\u22121\nik\n(\n\u03b1e\n2\n)\nand t(\n1\u2212\u03b1e2 )\ni = H\u0302\n\u22121\nik\n(\n1\u2212 \u03b1e2\n)\n.\n\u2022 t(\n\u03b1m\n2 )\ni = H\u0302\n\u22121\nik\n(\n\u03b1m\n2\n)\nand t(\n1\u2212\u03b1m2 )\ni = H\u0302\n\u22121\nik\n(\n1\u2212 \u03b1m2\n)\n.\n3. Calculate the experimental coverage of the k\u22121 comparisons under \u03b1s, \u03b1e\nand \u03b1m used as per-comparison error rates for the individual inferences.\n\u2022 Ps = G\u0302\n(\nt(\n\u03b1s\n2 ), t(1\u2212\n\u03b1s\n2 )\n)\n.\n\u2022 Pe = G\u0302\n(\nt(\n\u03b1e\n2 ), t(1\u2212\n\u03b1e\n2 )\n)\n.\n\u2022 Pm = G\u0302\n(\nt(\n\u03b1m\n2 ), t(1\u2212\n\u03b1m\n2 )\n)\n.\n4. If PsPm < 0, let \u03b1e = \u03b1m. If PePm < 0, let \u03b1s = \u03b1m.\n5. Let \u03b1m = 12 (\u03b1s + \u03b1e).\n6. Repeat 2 to 5 until \u03b1m lies within a chosen tolerance.\nThe simultaneous confidence intervals for the relative effects pik at level 1 \u2212 \u03b1\nequal\npik \u2208\n[\nt\n(\u03b1m2 )\ni ; t\n(1\u2212\u03b1m2 )\ni\n]\n(1 \u2264 i \u2264 k \u2212 1) . (7)\n4 Simulations\nSimulations were performed to study the behavior of the introduced method\nof iterative simultaneously adjusted alpha (ISAA) in the many-to-one design.\nThe Behrens-Fisher type procedure with Satterthwaite t-approximation and the\nSteel type procedures (Munzel and Hothorn, 2001) were used for comparison\nas implemented in the R package npmc Version 1.0 (Helms and Munzel, 2001).\nWith the nominal experimental error rate \u03b1 level being 0.05 (i.e. experimental\ncoverage equals 0.95) the case of k \u2212 1 = 3 is used for simplicity.\nCoverage probabilities and power estimations are reported for the general\nunbalanced design for different sample sizes. Normal distributions, log-normal\ndistributions, uniform distributions and contaminated normal distributions with\n10% one-sided or two-sided outliers were used. The term contam-one refers to\na N(0,1) distribution with 10% outliers taken from a N(3,1) distribution. The\n4\nterm contam-two refers to a N(0,1) distribution with 10% outliers taken from a\nN(-3,1) distribution and 10% outliers taken from a N(3,1) distribution.\nFor each parameter setting with preselected sample sizes, 10000 simulation\nruns were carried out. All-pairs power estimates in the case k \u2212 1 = 3 for\none selected expected value profile (0, 0, \u03b4, 0) are also reported. Within each\nsimulation four pseudo random samples from pre-specified distributions were\ngenerated. For the introduced method, 5000 bootstrap replications were used.\nTo ensure a fair comparison between the methods, coverage and power esti-\nmations were calculated on basis of the same simulation runs. All simulations\nwere performed in R.\n4.1 Experimentalwise Coverage and All-Pairs Power\nIn the balanced design with variance homogeneity the coverage probabilities of\nthe ISAA procedure are similar to the coverage probabilities of the Behrens-\nFisher type procedure which is more liberal than the Steel type procedure.\nThe Steel type procedure becomes markedly liberal and conservative in the\nbalanced design with variance heterogeneity and in the general unbalanced de-\nsign. The coverage probabilities of the Behrens-Fisher type procedure remains\nnearly constant and the ISAA procedure turns out to be more liberal than the\nBehrens-Fisher type procedure.\nIn the balanced design with variance homogeneity the ISAA procedure pro-\nvides higher power than the two asymptotic procedures in case of contaminated\nnormal distributions. For normal, uniform and log-normal distributions, the\nhighest power was observed with the Behrens-Fisher type procedure where the\nISAA procedure is still more powerful than the Steel type procedure.\nIn the balanced design with variance heterogeneity and in the general un-\nbalanced design the ISAA procedure is superior to the Behrens-Fisher type\nprocedure in terms of power. In designs with lower variability in the control\ngroup than in the treatment groups, the Steel type procedure has the highest\npower among the three procedures considered.\n4.2 Per Comparison Coverage for Individual Inferences\nStandard deviations were used to measure the balance of coverage in individual\npairs while the experimental error is controlled. Both asymptotic procedures are\nsuperior in terms of balance of coverage of individual inferences than the ISAA\nprocedure using standard normal (0.0007 with the Steel type procedure, 0.008\nwith the Behrens-Fisher type procedure and 0.0012 with the ISAA procedure)\nand log-normal distributed data (0.0007 with the Steel type procedure and the\nBehrens-Fisher type and 0.0012 with the ISAA procedure). In case of uniform\ndistributed data, the ISAA procedure turned out to be better in terms balance\nof coverage in individual pairs than both asymptotic procedures (0.0014 with\nthe Steel type procedure, 0.0011 with the Behrens-Fisher type procedure and\n0.0009 with the ISAA procedure).\n5\nTable 1: Empirical Experimentalwise Coverage and All-Pairs Power Using a\nNominal Experimental Error Rate of 0.05\nParameter Distribution Sample ISAA Behrens- Steel type\nsize procedure Fisher type procedure\nT C procedure\nExperimental- Normal\nwise coverage Std. dev.\nT C\n1 1 25 25 0.9436 0.9424 0.9512\n1 3 25 25 0.9476 0.9522 0.9564\n3 1 25 25 0.9211 0.9410 0.9154\n1 1 25 50 0.9412 0.9444 0.9520\n1 3 25 50 0.9503 0.9509 0.9817\n3 1 25 50 0.9203 0.9407 0.8560\nUniform 25 25 0.9445 0.9438 0.9532\nLog-normal 25 25 0.9423 0.9430 0.9507\ncontam.one 25 25 0.9432 0.9433 0.9518\ncontam.two 25 25 0.9444 0.9447 0.9525\nAll-pairs power Normal\nStd. dev.\nT C\n1 1 25 25 0.8614 0.8676 0.8465\n1 3 25 25 0.2394 0.2263 0.2232\n3 1 25 25 0.2394 0.1991 0.2548\n1 1 25 50 0.9419 0.9407 0.9354\n1 3 25 50 0.4016 0.3998 0.2456\n3 1 25 50 0.2526 0.2074 0.3676\nUniform 25 25 0.9143 0.9234 0.9057\nLog-normal 25 25 0.8648 0.8679 0.8487\ncontam.one 25 25 0.6950 0.6949 0.6681\ncontam.two 25 25 0.4967 0.4932 0.4724\nT...Treatment; C....Control\n6\nTable 2: Emperical Per-Comparison Coverage for Individual Inferences Using a\nNominal Experimental Error Rate of 0.05 and a Sample Size of 25 per Group\nDistribution Comparison Coverage ISAA Behrens- Steel type\nprocedure Fisher type procedure\nprocedure\nLog-normal T1 vs. C Individual 0.9773 0.9779 0.9811\nLower tail 0.4889 0.4890 0.4909\nUpper tail 0.4884 0.4889 0.4902\nT2 vs. C Individual 0.9796 0.9793 0.9825\nLower tail 0.4903 0.4904 0.4923\nUpper tail 0.4893 0.4889 0.4902\nT3 vs. C Individual 0.9785 0.9786 0.9822\nLower tail 0.4874 0.4876 0.4892\nUpper tail 0.4911 0.4910 0.4930\nStandard T1 vs. C Individual 0.9810 0.9804 0.9837\nnormal Lower tail 0.4896 0.4894 0.4912\nUpper tail 0.4914 0.4910 0.4925\nT2 vs. C Individual 0.9787 0.9793 0.9825\nLower tail 0.4894 0.4895 0.4914\nUpper tail 0.4893 0.4898 0.4911\nT3 vs. C Individual 0.9799 0.9789 0.9824\nLower tail 0.4904 0.4905 0.4917\nUpper tail 0.4895 0.4884 0.4907\nUniform T1 vs. C Individual 0.9777 0.9777 0.9808\nLower tail 0.4893 0.4891 0.4907\nUpper tail 0.4884 0.4886 0.4901\nT2 vs. C Individual 0.9793 0.9797 0.9828\nLower tail 0.4898 0.4904 0.4918\nUpper tail 0.4895 0.4893 0.4910\nT3 vs. C Individual 0.9793 0.9796 0.9834\nLower tail 0.4892 0.4897 0.4913\nUpper tail 0.4901 0.4899 0.4921\nT...Treatment; C...Control\n7\n5 Example\nWe use the data from Watson et al. (1987) discussed in Edwards and Berry\n(1987) as example to illustrate the presented approach. The full data set can\nbe found in the appendix.\nDr. Watson studied the effects of different perfusates on the permeability\nof capillary walls in cats. A measure of this called the capillary filtration co-\nefficient (CFC), reflects the rate at which liquid is taken up by the tissue via\nthe capillaries. The four treatments (the perfusates) considered are composed\nof ingredients A, B, and I in the following way\n1. A\n2. A + B\n3. A + I\n4. A + B + I.\nWe used the treatment with the single ingredient A as control and 100,000\nbootstrap replications for the ISAA method. The results were summarized in\nthe following table\nTable 3: Summary of Relative Effects of Different Perfusates\nComparison Relative 95% Simultaneous CI\u2019s\neffect for relative effects\nA + B versus A 0.800 0.638 to 0.929\nA + I versus A 0.692 0.501 to 0.863\nA + B + I versus A 0.924 0.823 to 0.991\nCI ... confidence interval\nThe probability that the capillary filtration coefficients of ingredient A were\ntendentiously larger than those of the combination of ingredients A+B was\n0.800 (95% CI: 0.638 to 0.929). Contrariwise, the probability that the capillary\nfiltration coefficients of ingredients A+B were tendentiously larger than those\nof ingredient A was 1-0.800=0.200. The increased probability of tendentiously\nlarger capillary filtration coefficients with ingredient A than with ingredients\nA+B was statistically significant at the 5% level, because the 95% confidence\ninterval did not contain the value 0.5. With a probability of 0.692 (95% CI: 0.501\nto 0.863), the CFC\u2019s were tendentiously larger with ingredient A than those of\nthe combination of ingredients A+I. This effect was statistically significant at\nthe 5% level, because the corresponding 95% confidence interval did not contain\nthe value 0.5. With a probability of 0.924 (95% CI: 0.823 to 0.991), the CFC\u2019s\nwere tendentiously larger with ingredient A than those of the combination of\ningredients A+B+I. This effect was also statistically significant at the 5% level,\nbecause the corresponding 95% confidence interval did not contain the value 0.5.\n8\n6 Discussion\nSummarizing, in case of contaminated normal distributions the ISAA procedure\nis favorable if a moderate liberality can be tolerated. In addition, we did not\nobserve a big loss in power of our bootstrap procedure in case of skewed and\ncontaminated distribution as observed in the simulations of Munzel and Hothorn\n(2001) using the straightforward bootstrap version of the maximum statistic.\nThe extension of this results for all-pairwise comparisons is still to be studied.\nThe asymptotic properties of the ISAA procedure presented and the generaliza-\ntion of these properties for the class of U-statistics are also subject to further\nresearch.\nAcknowledgement: The authors are grateful to Werner Engl, Ph. D. of\nthe Department of Biostatistics, Baxter AG, for his criticism of this note. We\nalso would like to thank the Statistics and Computing for publishing this article\nand giving helpful comments during the process of writing it.\n9\nReferences\nEdwards D. and Berry J. J. 1987. The efficiency of Simulation Based Multiple\nComparisons. Biometrics 43:913-928.\nGenz A. 1992. Numerical computation of the multivariate normal probabilities.\nJournal of Computational and Graphical Statistics, 1:141-150.\nHelms J. and Munzel U. 2001. R package npmc. http:\/\/www.cran.r-project.org,\nlast visited at 2004-03-01, Version 1.\nHochberg Y. and Tamhane A. C. 1987. Multiple Comparison Procedures. J.\nWiley and Sons, New York.\nHsu J. C. 1996. Multiple Comparison Procedures: Theory and Methods. Chap-\nman and Hall, London.\nMiller R. G. 1981. Simultaneous Statistical Inference. Springer, New York.\nMunzel U. and Hothorn L. A. 2001. A Unified Approach to Simultaneous\nRank Test Procedures in the Unbalanced One-way Layout. Biometrical Journal,\n43(5):553-569.\nPetrondas D. A. and Gabriel K. R. 1983. Multiple comparisons by randomization\ntests. Journal of the American Statistical Association, 78:949-957.\nR Development Core Team. 2004. R: A language and environment for statistical\ncomputing. R Foundation for Statistical Computing. Vienna, Austria.\nTu W. and Zhou X.-H. 2000. Pairwise multiple comparison of the means of\nskewed data. Journal of Statistical Planning and Inference, 88(1):59-74.\nWatson, P. D., Wolf, M. B., and Beck-Montgomery I. S. 1987. Blood and isopro-\nterenol reduce capillary permeability in cat hindlimbs. The American Journal\nof Physiology, 252:H47-H53.\n10\nAppendix\nFunction in R for many-to-one-comaprisons of relative effects in the one-way\nlayout using the ISAA method.\n######################################################################\n# Program name: releff.R\n# Last modification Date: 2005-07-01\n# Author: Martin J. Wolfsegger & Thomas Jaki\n# Program Version: 0.1\n# R Version: >=2.0.0\n#\n# Notes: function to calculate simultaneous confidence intervals for\n# relative effects for many-to-one comparisons in the one-way\n# layout by resampling with iteratively adjusted alpha\n#\n# Input:\n#\n# x ... a numeric vector of responses\n# g ... a vector encoded as factor containing the class-levels;\n# the lowest factor level will be used as control for\n# many-to-one comparisons\n# nsample ... number of bootstrap replications; default=1E4\n# alpha ... nominal experimental error rate; default=0.05\n# tol ... absolute error tolerance for numerical root finding;\n# default=1E-6\n#\n# Output:\n#\n# list containing of\n# estimate ... data frame of relative effects\n# conf.int ... data frame of simultaneous confidence intervals for\n# relative effects\n#\n# Version history: Inital release\n######################################################################\n# start of function\nreleff <- function(x, g, nsample=1E4, alpha=0.05, tol=1E-6){\n# function to select lower and upper bounds by ISAA method\n\"subspace\" <- function (G, alpha, tol) {\n# multivariate cumulative distribution function\n\"CDFMult\" <- function(G, border) {\nm <- ncol(G)\n11\nsim <- nrow(G)\nfor (i in 1:m) {G <- subset(G, G[, i] <= border[i])}\nreturn(nrow(G)\/sim)\n}\n# function to identify 2^m corners of m dimensional interval\n\"corners\" <- function(lb, ub) {\nm <- length(lb)\nlimit <- matrix(nrow = 2^m, ncol = m)\nindex <- 2^m\nfor (i in 1:m) {\nvalue <- lb[i]\nindex <- index\/2\ncount <- 1\nfor (j in 1:(2^m)) {\nif (count == index + 1) {\nifelse(value == lb[i],\nvalue <- ub[i],\nvalue <- lb[i])\ncount <- 1\n}\nlimit[j, i] <- value\ncount <- count + 1\n}\n}\nreturn(limit)\n}\n# function to identify algebraic sign for adding up 2^m corners\n\"sign\" <- function(limit, lb) {return((-1)^sum(lb == limit))}\n# function to calculate probability of m dimensional interval\n\"interval\" <- function(G, lb, ub) {\nm <- ncol(G)\nlimit <- corners(lb = lb, ub = ub)\nprob <- 0\nfor (i in 1:(2^m)) {\nprob <- prob + sign(limit = limit[i, ], lb = lb) *\nCDFMult(G = G, border = limit[i, ])\n}\nreturn(prob)\n}\n# define objects\nG <- as.data.frame(G)\nm <- ncol(G)\n12\nalpha.s <- alpha\/2\nalpha.e <- alpha\/(2 * m)\nalpha.m <- (alpha.s + alpha.e)\/2\nalpha.h <- alpha.m + 1\nlb <- list(e = array(1:m), s = array(1:m), m = array(1:m))\nub <- list(e = array(1:m), s = array(1:m), m = array(1:m))\n# iterative root finding\nwhile (abs(alpha.h - alpha.m) > tol) {\nalpha.h <- alpha.m\nfor (i in 1:m) {\nlb$e[i] <- as.real(quantile(G[, i], alpha.e))\nlb$s[i] <- as.real(quantile(G[, i], alpha.s))\nlb$m[i] <- as.real(quantile(G[, i], alpha.m))\nub$e[i] <- as.real(quantile(G[, i], 1 - alpha.e))\nub$s[i] <- as.real(quantile(G[, i], 1 - alpha.s))\nub$m[i] <- as.real(quantile(G[, i], 1 - alpha.m))\n}\nP.e <- interval(G = G, lb = lb$e, ub = ub$e) - (1 - alpha)\nP.s <- interval(G = G, lb = lb$s, ub = ub$s) - (1 - alpha)\nP.m <- interval(G = G, lb = lb$m, ub = ub$m) - (1 - alpha)\nif (P.s * P.m < 0) {alpha.e <- alpha.m}\nif (P.e * P.m < 0) {alpha.s <- alpha.m}\nalpha.m <- (alpha.s + alpha.e)\/2\n}\nreturn(list(lb = lb$m, ub = ub$m))\n}\n# function to calculate relative effects\n\"effects\" <- function(x, n){\nm <- length(x)-n\nx <- rank(x)\nreturn(1\/m*(mean(x[(m+1):(n+m)])-1\/2*(n+1)))\n}\n# define ojects\nk <- nlevels(g)\nvarnames <- levels(g)\nrnames <- paste(varnames[2:k], \"-\", varnames[1], sep = \"\")\nssizes <- as.vector(tapply(x, g, length))\nG <- matrix(nrow=nsample, ncol=k-1)\n# calculate relative effects\nobserved <- tapply(x, g, sample, replace=FALSE)\nobserved <- lapply(observed[2:k], append, observed[[1]])\nestimate <- as.matrix(sapply(observed, effects, ssizes[1]))\n13\n# generate joint bootstrap distribution of relative effects\nfor (i in 1:nsample){\nbootsamp <- tapply(x, g, sample, replace=TRUE)\nbootsamp <- lapply(bootsamp[2:k], append, bootsamp[[1]])\nG[i,] <- sapply(bootsamp, effects, ssizes[1])\n}\n# get bounds\nbounds <- subspace(G, alpha=alpha, tol=tol)\n# define output objects\nconf.int <- data.frame(lower=as.matrix(bounds$lb),\nupper=as.matrix(bounds$ub))\nestimate <- data.frame(estimate)\nrownames(conf.int) <- rnames\nrownames(estimate) <- rnames\nreturn(list(estimate=estimate, conf.int=conf.int))\n}\n# end of function\n## example from Watson et al. (1987)\ncfc <- c(0.0156, 0.0118, 0.0130, 0.0082, 0.0209, 0.0222, 0.0158, 0.0119,\n0.0126, 0.0200, 0.0195, 0.0185, 0.0123, 0.0162, 0.0144, 0.0100,\n0.0143, 0.0277, 0.0116, 0.0342, 0.0200, 0.0219, 0.0195, 0.0178,\n0.0181, 0.0177, 0.0088, 0.0089, 0.0094, 0.0100, 0.0104, 0.0105,\n0.0106, 0.0106, 0.0107, 0.0110, 0.0112, 0.0113, 0.0118, 0.0119,\n0.0130, 0.0132, 0.0140, 0.0140, 0.0141, 0.0145, 0.0146, 0.0148,\n0.0150, 0.0191, 0.0100, 0.0102, 0.0109, 0.0115, 0.0118, 0.0120,\n0.0124, 0.0124, 0.0129, 0.0131, 0.0132, 0.0135, 0.0140, 0.0144,\n0.0151, 0.0154, 0.0155, 0.0162, 0.0197, 0.0211, 0.0061, 0.0063,\n0.0070, 0.0073, 0.0075, 0.0078, 0.0081, 0.0081, 0.0086, 0.0086,\n0.0086, 0.0087, 0.0088, 0.0091, 0.0092, 0.0093, 0.0099, 0.0100,\n0.0102, 0.0102, 0.0106, 0.0108, 0.0108, 0.0109, 0.0109, 0.0109,\n0.0111, 0.0115, 0.0116, 0.0125, 0.0135, 0.0140, 0.0148)\ntrt <- as.factor(c(rep(1,26), rep(2,24), rep(3,20), rep(4,33)))\n# set seed for bootstrap resampling\nset.seed(12345)\n# function call and output\nres <- releff(x=cfc, g=trt, nsample=1E5)\nprint(round(res$estimate, 3))\nprint(round(res$conf.int, 3))\n14\n"}
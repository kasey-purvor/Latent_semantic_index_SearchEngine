{"doi":"10.1117\/12.706275","coreId":"65907","oai":"oai:dro.dur.ac.uk.OAI2:4174","identifiers":["oai:dro.dur.ac.uk.OAI2:4174","10.1117\/12.706275"],"title":"An application driven comparison of depth perception on desktop 3D displays.","authors":["Holliman,  N. S.","Froner,  B.","Liversedge,  S. P."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":["Woods,  A. J.","Dodgson,  N. A.","Merritt,  J. O.","Bolas,  M. T.","McDowell,  I. E."],"datePublished":"2007-01-01","abstract":"Desktop 3D displays vary in their optical design and this results in a significant variation in the way in which stereo images are physically displayed on different 3D displays. When precise depth judgements need to be made these differences may become critical to task performance. Applications where this is a particular issue include medical imaging, geoscience and scientific visualization. We investigate perceived depth thresholds for four classes of desktop 3D display; full resolution, row interleaved, column interleaved and colour-column interleaved. Given the same input image resolution we calculate the physical view resolution for each class of display to geometrically predict its minimum perceived depth threshold. To verify our geometric predictions we present the design of a task where viewers are required to judge which of two neighboring squares lies in front of the other. We report results from a trial using this task where participants are randomly asked to judge whether they can perceive one of four levels of image disparity (0,2,4 and 6 pixels) on seven different desktop 3D displays. The results show a strong effect and the task produces reliable results that are sensitive to display differences. However, we conclude that depth judgement performance cannot always be predicted from display geometry alone. Other system factors, including software drivers, electronic interfaces, and individual participant differences must also be considered when choosing a 3D display to make critical depth judgements.\\u","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65907.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/4174\/1\/4174.pdf","pdfHashValue":"f49192ac7ea8258faa922d168b8042ee49a9d653","publisher":"SPIE","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:4174<\/identifier><datestamp>\n      2017-03-10T11:20:57Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        An application driven comparison of depth perception on desktop 3D displays.<\/dc:title><dc:creator>\n         Holliman,  N. S.<\/dc:creator><dc:creator>\n         Froner,  B.<\/dc:creator><dc:creator>\n        Liversedge,  S. P.<\/dc:creator><dc:description>\n        Desktop 3D displays vary in their optical design and this results in a significant variation in the way in which stereo images are physically displayed on different 3D displays. When precise depth judgements need to be made these differences may become critical to task performance. Applications where this is a particular issue include medical imaging, geoscience and scientific visualization. We investigate perceived depth thresholds for four classes of desktop 3D display; full resolution, row interleaved, column interleaved and colour-column interleaved. Given the same input image resolution we calculate the physical view resolution for each class of display to geometrically predict its minimum perceived depth threshold. To verify our geometric predictions we present the design of a task where viewers are required to judge which of two neighboring squares lies in front of the other. We report results from a trial using this task where participants are randomly asked to judge whether they can perceive one of four levels of image disparity (0,2,4 and 6 pixels) on seven different desktop 3D displays. The results show a strong effect and the task produces reliable results that are sensitive to display differences. However, we conclude that depth judgement performance cannot always be predicted from display geometry alone. Other system factors, including software drivers, electronic interfaces, and individual participant differences must also be considered when choosing a 3D display to make critical depth judgements.\\ud\n<\/dc:description><dc:subject>\n        Interleaving patterns<\/dc:subject><dc:subject>\n         Aliasing<\/dc:subject><dc:subject>\n         Depth perception<\/dc:subject><dc:subject>\n         Empirical evaluation<\/dc:subject><dc:subject>\n         Stereoscopic displays.<\/dc:subject><dc:publisher>\n        SPIE<\/dc:publisher><dc:source>\n        Woods,  A. J. & Dodgson,  N. A. & Merritt,  J. O. & Bolas,  M. T. & McDowell,  I. E. (Eds.). (2007). Stereoscopic displays and virtual reality systems XIV. Bellingham, WA: SPIE, pp. 64900H, Proceedings of SPIE(6490)<\/dc:source><dc:contributor>\n        Woods,  A. J.<\/dc:contributor><dc:contributor>\n        Dodgson,  N. A.<\/dc:contributor><dc:contributor>\n        Merritt,  J. O.<\/dc:contributor><dc:contributor>\n        Bolas,  M. T.<\/dc:contributor><dc:contributor>\n        McDowell,  I. E.<\/dc:contributor><dc:date>\n        2007-01-01<\/dc:date><dc:type>\n        Book chapter<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:4174<\/dc:identifier><dc:identifier>\n        issn:0277-786X<\/dc:identifier><dc:identifier>\n        doi:10.1117\/12.706275<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/4174\/<\/dc:identifier><dc:identifier>\n        https:\/\/doi.org\/10.1117\/12.706275<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/4174\/1\/4174.pdf<\/dc:identifier><dc:rights>\n        N. S. Holliman, B. Froner, B and S.P. Liversedge. \u201cAn application driven comparison of depth perception on desktop 3D displays.\u201d, Proceedings of SPIE : Stereoscopic displays and virtual reality systems XIV. A. J. Woods, N. A. Dodgson, J. O. Merritt, M. T. Bolas, I. E. McDowell, Editors, 64900, 64900H, (2007).\\ud\nCopyright 2007 Society of Photo-Optical Instrumentation Engineers. One print or electronic copy may be made for personal use only. Systematic reproduction and distribution, duplication of any material in this paper for a fee or for commercial purposes, or modification of the content of the paper are prohibited.<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0277-786X","0277-786x"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2007,"topics":["Interleaving patterns","Aliasing","Depth perception","Empirical evaluation","Stereoscopic displays."],"subject":["Book chapter","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n21 August 2009\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nHolliman, N. S. and Froner, B. and Liversedge, S. P. (2007) \u2019An application driven comparison of depth\nperception on desktop 3D displays.\u2019, in Proceedings of SPIE : Stereoscopic displays and virtual reality systems\nXIV. Bellingham WA: SPIE, 64900H.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1117\/12.706275\nPublisher\u2019s copyright statement:\nN. S. Holliman, B. Froner, B and S.P. Liversedge. An application driven comparison of depth perception on desktop\n3D displays., Proceedings of SPIE : Stereoscopic displays and virtual reality systems XIV. A. J. Woods, N. A.\nDodgson, J. O. Merritt, M. T. Bolas, I. E. McDowell, Editors, 64900, 64900H, (2007). Copyright 2007 Society of\nPhoto-Optical Instrumentation Engineers. One print or electronic copy may be made for personal use only. Systematic\nreproduction and distribution, duplication of any material in this paper for a fee or for commercial purposes, or\nmodification of the content of the paper are prohibited.\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n,  \n \nDurham Research Online \n \nDeposited in DRO: \n21 August 2009 \n \nPeer-review status: \nPeer-reviewed \n \nPublication status of attached file: \nPublished version \n \nCitation for published item: \nHolliman, N. S. and Froner, B. and Liversedge, S. P. (2007) 'An application driven \ncomparison of depth perception on desktop 3D displays.', in Proceedings of SPIE : \nStereoscopic displays and virtual reality systems XIV. Bellingham WA: SPIE, 64900H. \n \nFurther information on publisher\u2019s website: \nhttp:\/\/dx.doi.org\/10.1117\/12.706275 \n \nCopyright statement: \nN. S. Holliman, B. Froner, B and S.P. Liversedge. \u201cAn application driven comparison of \ndepth perception on desktop 3D displays.\u201d, Proceedings of SPIE : Stereoscopic displays and \nvirtual reality systems XIV. A. J. Woods, N. A. Dodgson, J. O. Merritt, M. T. Bolas, I. E. \nMcDowell, Editors, 64900, 64900H, (2007). \n \nCopyright 2007 Society of Photo-Optical Instrumentation Engineers. One print or electronic \ncopy may be made for personal use only. Systematic reproduction and distribution, \nduplication of any material in this paper for a fee or for commercial purposes, or modification \nof the content of the paper are prohibited. \n \n \nUse policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior \npermission or charge, for personal research or study, educational, or not-for-profit purposes provided that : \n \n\uf0a7 a full bibliographic reference is made to the original source \n\uf0a7 a link is made to the metadata record in DRO \n\uf0a7 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders. \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nAn Application Driven Comparison of Depth Perception on\nDesktop 3D Displays\nNick Hollimana, Barbara Fronera, Simon Liversedgeb,\naDepartment of Computer Science, Durham University, United Kingdom.\nbSchool of Psychology, University of Southampton, United Kingdom.\nABSTRACT\nDesktop 3D displays vary in their optical design and this results in a significant variation in the way in which\nstereo images are physically displayed on different 3D displays. When precise depth judgements need to be made\nthese differences may become critical to task performance. Applications where this is a particular issue include\nmedical imaging, geoscience and scientific visualization.\nWe investigate perceived depth thresholds for four classes of desktop 3D display; full resolution, row inter-\nleaved, column interleaved and colour-column interleaved. Given the same input image resolution we calculate\nthe physical view resolution for each class of display to geometrically predict its minimum perceived depth\nthreshold.\nTo verify our geometric predictions we present the design of a task where viewers are required to judge\nwhich of two neighboring squares lies in front of the other. We report results from a trial using this task where\nparticipants are randomly asked to judge whether they can perceive one of four levels of image disparity (0,2,4 and\n6 pixels) on seven different desktop 3D displays. The results show a strong effect and the task produces reliable\nresults that are sensitive to display differences. However, we conclude that depth judgement performance cannot\nalways be predicted from display geometry alone. Other system factors, including software drivers, electronic\ninterfaces, and individual participant differences must also be considered when choosing a 3D display to make\ncritical depth judgements.\nKeywords: Interleaving Patterns, Aliasing, Depth Perception, Empirical Evaluation, Stereoscopic Displays\n1. INTRODUCTION\nAs 3D displays become increasingly available they are being adopted for use in applications where accurate depth\njudgements are critical to outcomes. In medicine and geo-science the ability to judge the co-location in depth of\nscene features is particularly important for operators in making domain specific judgements. For example this\nmay involve judging the depth in the retina of anomalies in the image-based diagnosis of diabetic retinopathy1\nor the interpretation of 3D fault structure using LIDAR scanned rock outcrop data.2\nOur concern in this paper is how well different 3D displays reproduce the depth present in an input image\nand particularly whether it is possible to predict human depth perception thresholds for a display from its\npublished specifications. To analyze displays we group them into four classes according to how they physically\nrepresent the input stereo image, that is; in the original full resolution, using a row-interleaved pixel pattern,\nusing a column-interleaved pixel pattern or using a colour-column interleaved pattern. We then use the display\nspecifications for each class of display to predict the threshold level of perceived depth for a specific display in\nterms of the image disparities in the input stereo image.\nWe design an empirical experiment to test these predictions using a randomized within-subjects trial where\nparticipants are required to judge which of two neighboring squares lies in front of the other as shown in Figure 5.\nOur aim is to establish a robust and sensitive methodology for detecting depth perception differences so that the\nresults can inform both display users and display designers in the choices they make.\nFurther author information: Send correspondence to Nick Holliman.\nEmail: n.s.holliman@durham.ac.uk, Telephone: +44 191 334 4287, Web: http:\/\/www.durham.ac.uk\/n.s.holliman\/\n2. BACKGROUND\n2.1. Previous Comparative Studies\nPrevious studies of human depth perception using stereoscopic displays have almost exclusively studied single\ndisplays and have investigated fusion limits, i.e. the highest levels of perceived depth a 3D display can support\nbefore fusion breaks down.\nBoth Yeh & Silverstein3 and Woods4 studied fusion limits for stereoscopic desktop 3D displays. The results\nshowed that the total range of depth comfortably viewable on a 3D display is limited. Similar results were\ndemonstrated for auto-stereoscopic displays by Jones et al5 who suggested a working perceived depth range of\nas little as 60mm behind and 50mm in-front of the display surface. Whatever the precise value of fusible range\nfor desktop 3D displays, it is clearly limited and we believe it is increasingly important to understand how this\nlimited range is represented on different 3D displays.\nPrevious investigations into the threshold limits of perceived depth6\u20138 have studied real world limits because\nthe primary interest has been to investigate the acuity of human vision rather than the minimum perceived depth\nsupported by different display technologies. One exception is Yeh & Sliverstein3 who demonstrated that subjects\ncan use minimal levels of screen disparity effectively when presented on an LC shutter glasses 3D display.\nA recent study9 compared task performance on a 2D display, a LC shutter glasses stereoscopic display, a\ntwo-view auto-stereoscopic display and a multi-view auto-stereoscopic display. This investigated interaction\nperformance in a trial where participants had to manipulate a 3D object to be in the same depth plane as a\ntarget object. The results suggest a better performance, in terms of number of correct answers, was obtained\nusing the LC shutter glasses, however the study did not provide a hypothesis predicting this nor explain why\nthis might be.\nNone of these studies attempt to quantify human depth perception threshold levels across a range of rep-\nresentative 3D displays. We believe our study is the first to do this and that this is important to investigate\nempirically because, as the analysis in the next section predicts, there are potentially significant differences\nbetween different classes of 3D displays.\n2.2. Classifying 3D Displays\nTo predict threshold values of perceived depth we classify the displays into four groups based on the physical\ninterleaving pattern of pixels presented to the viewer. This will allow us to calculate a geometric prediction of\nperformance from the published display specifications and the input image disparity.\n2.2.1. Full Resolution Displays\nThese displays show two full resolution views, one to each eye. They provide double the number of pixels of\nan equivalent 2D monitor and may be implemented using two displays or by temporal multiplexing of a single\ndisplay. We use three full resolution displays; a time sequential stereoscopic CRT display using CrystalEyes LC\nshutter glasses,10 an auto-stereoscopic Kodak11 display and an auto-stereoscopic IRIS-3D12 display all driven\nusing standard graphics card settings.\n2.2.2. Row Interleaved Displays\nThese displays spatially interleave alternate rows from left and right images. The total number of pixels seen is\nunchanged compared to an equivalent 2D display and half of the total are seen by each eye. We have a single\nexample of a row-interleaved display in this study; a ColorLink linearly polarized stereoscopic display. This is\ndriven using a graphics card with a time-sequential video signal which on-board electronics decodes interleaving\nleft and right images appropriately in alternate rows for display.\n2.2.3. Column Interleaved Displays\nThese displays spatially interleave alternate columns of pixels from left and right input images. The total\nnumber of pixels seen is unchanged compared to an equivalent 2D display and half of the total are seen by\neach eye. Two column interleaved displays are used in our study; the DTI 2018 LCD display13 and the SeeReal\nC-i display.14 The DTI is driven using a time-sequential signal and on-board electronics generate the spatial\ninterleaving required. The SeeReal display was used here with its head tracking feature switched off and driven\nwith a graphics card that interleaved the left and right images appropriately in alternate columns.\n2.2.4. Colour-column Interleaved Displays\nThese displays spatially interleave left and right pixels in alternate colour columns at a sub-pixel level. The\ntotal number of pixels seen is unchanged compared to an equivalent 2D display and half of the total are seen\nby each eye. One colour-column interleaved display is used in our study; the Sharp LL151D15 auto-stereoscopic\ndisplay. The colour-column interleaving was generated using a graphics card to interleave the left and right\nimages appropriately.\n3. GEOMETRIC PREDICTIONS\nIn this section we analyze the viewing geometry of the four classes of 3D display and from this derive a prediction\nof the performance we expect for human depth perception on each in terms of the smallest unit of input image\ndisparity that it should be possible for a human to perceive on each class of display.\nTo predict the performance of the four classes of display we will use a generic display specification for\ncalculations in this section although in practice the displays vary in resolution and size. We assume the base\ndisplays are flat panel displays with the following characteristics:\n\u2022 Screen resolution 1280x1024 pixels, SXGA resolution.\n\u2022 Screen size 17.1in; W: 337mm, H: 270mm\n\u2022 Screen pixel size 0.264mm x 0.264mm\nIn addition to simplify our comparison we will assume that each class of display display is viewed at the same\nnominal viewing distance of 650mm by a viewer with an eye separation of 65mm.\nWe define some basic terminology that we use to identify key features of the images we wish to display and\nthe displays we wish to display them on. We generally follow the terminology defined by Holliman,16 but extend\nthis to distinguish between the input stereo image pair that we wish to display on each class of display and\nthe capabilities of the displays themselves. Where we are considering the input image characteristics we use the\nprefix image, where we are considering display characteristics we use the prefix view to identify the characteristics\nof one or more viewing channels on a physical display.\n\u2022 Image pixel we use to refer to the pixels in the input image that we wish to display. We consider this as\nthe basic unit of addressable colour in one channel of the input image.\n\u2022 Image resolution the resolution of a single channel image we wish to display. We will define this in image\npixels, to be the same resolution for each channel in the input signal.\n\u2022 Image disparity the disparity in image pixels between two homologous points in the stereoscopic input\nimage we wish to display.\n\u2022 View pixel we use this to define the basic addressable unit in a single view on a specific 3D display. This\ncan have an aspect ratio and size different to the underlying display screen, for example on a column\ninterleaved display a single view pixel is effectively twice the width of the underlying physical screen pixel.\n\u2022 View resolution the resolution we can display per view on a specific 3D display. We define this in view\npixels and this varies depending on the optical design of the display.\n\u2022 View disparity the physical disparity of two homologous points shown on a 3D display. This can be\nmeasured in view pixels or, as it is a physical quantity, in mm. Because view disparity is defined in view\npixels different 3D displays will have different minimum values.\n\u2022 Geometric perceived depth (GPD) the geometrically calculated perceived depth predicted to be due to a\nspecific view disparity.16\nL0R0\nV\nie\nw\n D\nis\np\na\nri\nty\n (\nm\nm\n)\nScreen\nPlane\nR\nig\nh\nt \nL\ne\nft \nPerceived depth \n(mm)\nView Disparity \n(view pixels)0\n0\n.0\n0\n1\n2\n.6\n2\n9\n2\n5\n.2\n3\n7\n3\n7\n.8\n2\n5\nR10.264\nR20.528\nR30.792\n0.000\n0 1 2 62 63 64\nInput image pixels\nDisplayed screen pixels\nLeft\nRight\nLeft\nRight\n...R G B R G B R G B R G B R G B R G B\n...R G B R G B R G B R G B R G B R G B\n...R G B R G B R G B R G B R G B R G B\n...R G B R G B R G B R G B R G B R G B\nR0 view pixel \nL0  view pixel\nFigure 1. A full-resolution display provides a one-to-one correspondence between the input image and the view image\nshown on the display. On the right we illustrate corresponding rows of pixels from the left and right input images and\nbeneath these the pattern of view pixels physically displayed on screen. To the left is illustrated the perceived depth due\nto physical disparities of 0,1,2 and 3 view pixels.\n3.1. Full Resolution Displays\nFigure 1 illustrates the generation of the view pixel pattern and the depth reproduction capability of a full\nresolution display using the generic display specifications we gave above. The calculation for perceived depth\nuses the standard equation for geometric perceived depth with crossed disparity.16 This pre-supposes a simple\ngeometric model of binocular vision is sufficient to provide a first order approximation of actual perceived depth.\nAs is clear in Figure 1 an image disparity of 0-pixels will be reproduced as 0-pixels view disparity on full-\nresolution displays and the minimum increment of 1-pixel image disparity will be reproduced as 1-pixel view\ndisparity.\nWe predict the performance for each display in terms of which levels of input image disparity we expect to be\nreproduced as view disparity and hence perceived as depth by an observer. For the full resolution display this is\nstraight-forward as we anticipate this class of display can reproduce all input image disparities as view disparity\nand hence all image disparities will be perceived by an observer as discrete depths. We make an assumption here\nthat all the displays in the study show a minimum disparity above the visible threshold, hence if a display can\nreproduce a value of input image disparity it will be perceived as depth by an observer.\n3.2. Row Interleaved Displays\nFor the purposes of calculating geometric perceived depth we will treat row interleaved displays as identical to\nfull resolution displays since they have full horizontal resolution and it is therefore possible to display the entire\ninput image disparity range. However, it is worth noting these displays have a built-in vertical offset of one view\npixel which could alter the perceived depth in practice.\n3.3. Column Interleaved Displays\nAs is shown in Figure 2 column-interleaving can be expected to have a direct effect on view disparity as the\nhorizontal image disparity range is sub-sampled by a factor of two.\nA first result of the interleaving is that 0-pixel image disparity is shown with a physical disparity of one\nscreen pixel. The effect of this is to offset the zero disparity plane to be slightly in-front, or behind, the physical\nscreen plane. The second result is that a column-interleaved display can only present half the disparity values\nin the input image. Every alternate increment in image disparity will be removed by the sub-sampling of pixel\nV\nie\nw\n D\nis\np\na\nri\nty\n (\nm\nm\n)\nScreen\nPlane\nR\nig\nh\nt \nL\ne\nft \nPerceived depth \n(mm)\nView Disparity \n(view pixels)\nL0\nR0\nR1\nR2\nR3\n0\n2\n.6\n3\n1\n7\n.8\n2\n2\n1\n2\n.9\n4\n3\n1\n7\n.9\n7\n0.264\n0.792\n1.32\n1.848\n0 1 2 62 63 64\nLeft\nRight\nStereo\n...R G B R G B R G B R G B R G B R G B\n...R G B R G B R G B R G B R G B R G B\n...R G B R G B R G B R G B R G B R G B\nL L L R R R L L L L L L R R R L L L\nView interleaving pattern\nL0 R0 view pixels\nInput image pixels\nDisplayed screen pixels\nFigure 2. A column-interleaved display uses alternate columns of physical pixels to display the left and right images. As\nshown on the right the input image must be sub-sampled to achieve this, we assume that columns are selected alternately\nfrom left and right images. As a result a column-interleaved display can only show half the values of input disparity and\nthe zero disparity plane is not co-incident with the screen plane.\nV\nie\nw\n d\nis\np\na\nri\nty\n (\nm\nm\n)\nScreen\nplane\nR\nig\nh\nt \nL\ne\nft \nPerceived depth \n(mm)\nView disparity \n(view pixels)\nL0\nR0\nR1\nR2\nR3\n0.088\n0.616\n1.144\n1.672\n0\n0\n.8\n7\n9\n1\n6\n.1\n0\n2\n2\n1\n1\n.2\n4\n3\n1\n6\n.3\n0\n0 1 2 62 63 64\nLeft\nRight\nStereo\n...R G B R G B R G B R G B R G B R G B\n...R G B R G B R G B R G B R G B R G B\n...R G B R G B R G B R G B R G B R G B\nL R L R L R L R L L R L R L R L R L\nInput image pixels\nDisplayed screen pixels\nR0 view pixel \nL0  view pixel\nFigure 3. Colour-column interleaving samples incoming pixels at the level of sub-pixel colour components. There are\nseveral implementation choices for this sub-sampling, we assume here pixel columns are selected alternately from left and\nright images then displayed in appropriate colour-columns. A colour-column interleaved display can only show half the\ninput disparity values and the zero disparity plane is not coincident with the screen plane.\ncolumns. The interleaving example to the right in Figure 2 illustrates how 1-pixel disparity is aliased, producing\nthe same interleaved pattern as 0-pixel disparity.\nWe therefore predict that a column-interleaved display will only support perception of certain input image\ndisparities. We have assumed that even values of image disparity survive the column sub-sampling and therefore\nwe predict depth will be perceived for input image disparity values of 2,4,etc -pixels.\n3.4. Colour-column Interleaved Displays\nColour-column interleaved displays also sub-sample the input image but interleave at the granularity of sub-\npixel colour-columns rather than pixel-columns. There are several implementation choices for this; we assume\nalternate pixel columns are sampled and then displayed in appropriate colour-columns across one view pixel.\nThe result, shown in Figure 3 is that there is a 0-pixel view disparity offset of one-third of a screen pixel and\nthat only alternate values of input image disparity values can be reproduced on the display. In addition the\ncolour-column interleaving means that the red, green and blue colour components in a single view pixel are no\nlonger spatially adjacent. The interleaving example to the right in Figure 3 illustrates how 1-pixel disparity is\naliased, producing the same interleaved pattern as 0-pixel disparity.\nWe predict that a colour-column interleaving display will have the same performance as column interleaved\ndisplays; that is it will only be able to reproduce even values of image disparity.\n3.5. Hypothesis\nOur prediction is that different classes of 3D display will reproduce the disparity in the input image differently\nand that this will have a direct effect on the threshold level of image disparity for each display. We predict that\nfull-resolution and row-interleaved displays should have a threshold level of 1-pixel image disparity. Whereas for\ncolumn-interleaved and colour-column interleaved displays, which horizontally sub-sample the input image, we\npredict a threshold value of 2-pixels.\nTo begin to evaluate this hypothesis we present the experimental design below. In this experiment we\ninvestigate participant\u2019s disparity threshold using values of 0-,2-,4- and 6-pixels input image disparity, which we\nexpect all displays to be able to reproduce.\n4. METHOD\n4.1. Experimental Design\nWe designed a repeated measures trial with Display (DTI, SeeReal, ColorLink, Sharp, Iris3D, Kodak, Shutter\nGlasses) and Image Disparity (0-, 2-, 4-, 6-pixels) as within participants variables. The choice of increment of\n2-pixels image disparity ensures we have an input signal that we would expect all displays to be able to reproduce\nas visible perceived depth. The dependant variable was the proportion of trials at which participants select the\ncorrect target (Score). Each subject was asked to repeat the same condition twenty-eight times for each of four\nlevels of image disparity, giving a total of 112 conditions per display. Image disparity, and hence perceived depth,\nwas controlled in image pixels and was randomly chosen from four possible levels (0-, 2-, 4-, 6-pixel disparity),\neach of which was distributed across the trials with equal probability. The position of the square that appeared\nto be closer to the participant was counterbalanced across trials. The order in which people performed the task\non each display was also counterbalanced and followed a Latin Square design.\n4.2. Participants\nA total of 14 candidates (11 male, 3 female) were recruited within the Durham University population. Participant\nage varied between 20 and 34 while the mean age was 26 years. Participants were naive concerning the purpose\nof the experiment; they received a nominal sum of five pounds per hour, for a total of ten pounds.\n4.3. Equipment\nThe earlier classification of displays described the seven displays used in the trial. The displays were driven by\nseven independent machines that used the same kind of graphic card (nVidia Quadro FX family) and the same\nsoftware driver (nVidia ForceWare Release 80). The experiment was conducted in a dark room, with minimal\nlight levels with equipment arranged as shown in Figure 5.\n4.4. Task and Stimuli\nThe image used for the test consisted of two white squares on a black background, as shown in Figure 5.\nThe squares were centered in the middle of the screen and were positioned horizontally one next to the other.\nBetween the two squares there was a small square that marked the center of the screen and acted as fixation\npoint; participants were asked to maintain fixation on this point throughout each trial as they were performing\nthe task.\nThe square that acted as fixation point was 6 image pixels wide while the width of the other two squares\nwas 64 image pixels each. The distance between the two internal edges of the left and right square was 20 image\npixels. In each trial one square was always given 0-pixels image disparity while the position in depth of the\nFigure 4. The environment used, where possible dis-\nplays had chin-rests to guide participants to the ideal\nviewing position, the displays were placed against a\nblank background and any reflections of objects or\nlights behind participants were eliminated.\nFigure 5. The trial stimulus consisted of two neigh-\nboring squares, participants were instructed to look at\nthe fixation target between the squares and make a\nforced choice judgment about which square appeared\nto be in-front of the other.\nother square was randomly chosen among a range of four different image disparity (i.e. 0-, 2-, 4-, 6-pixel image\ndisparity).\nStimuli were presented to candidates via the stereoscopic displays at the manufacturers nominal viewing\ndistance for the Kodak and Iris3D displays and at 65cm for all other displays. Candidates were asked to identify\nwhich square was the closest to them by pressing the letter \u201dC\u201d on the keyboard if the left square appeared to be\ncloser to them or press letter \u201dM\u201d if instead the right square appeared to be closer, a choice was always required\neven if there appeared to the subject to be no difference in depth between the two squares.\n4.5. Protocol\nVolunteers were screened for stereovision prior the start of the experiment using the Titmus test. All participants\nmet the minimum criteria for selection, namely, stereo-acuity at 40 sec-arc. Participants were divided into two\ngroups of seven people each. The experiment was carried out in two separate sessions, one for each group. Prior\nto the start of the experiment, candidates reviewed instructions and completed practice trials with at least one\nof the displays.\nParticipants then completed the 112 experimental trials on each display for a total of seven experimental\nsessions. Trials started with an orthoscopic test to check that the candidates were in the correct viewing position\nand the display was presenting the left and right images correctly to the appropriate eye. During trials head\nmovements were minimized via use of chin rests on all the displays except the Kodak and Iris-3D where it was\nimpractical. Participants were instructed to be as accurate as possible in their decision but not to spend too\nmuch time on each trial, even though no time limit was imposed. Answers could not be changed and score was\nrecorded. In each trial, candidates were assigned a score of 1 if they gave the correct answer and a score of 0\nif they gave the wrong answer. In the trials where both squares had zero disparity, candidates were assigned a\nscore of 1 if they selected the square on the right and a score of 0 if they selected the square on the left.\nFinally, all candidates were debriefed and were given the chance to ask questions. The experiment lasted two\nhours including a thirty minute break half way through and small breaks at the end of each trial.\n5. RESULTS AND ANALYSIS\nWe consider results from the trial in terms of the score of participants. We report data from 12 of the 14 subjects\nas the other two had poor average task performance (average score of 49% and 52% respectively, compared\nto a minimum average of 74% for the remaining participants). Overall results showed a strong effect, when\nparticipants could detect a depth difference the average score was 94%, which is close to the ideal score of 100%.\nTable 1. Mean score (%) and standard deviation\nDisparity 0 2 4 6\nM SD M SD M SD M SD\nDTI 53.87 .31 95.83 .08 93.75 .13 95.83 .07\nSeeReal 56.84 .23 52.98 .07 88.10 .22 88.69 .23\nColorLink 61.31 .22 88.39 .28 88.39 .28 89.29 .27\nSharp 63.10 .15 95.54 .07 95.24 .07 86.61 .21\nIris3D 72.02 .14 99.11 .02 100.00 .00 99.41 .01\nKodak 52.68 .24 96.43 .07 95.54 .08 95.24 .09\nLC Glasses 60.71 .26 100.00 .00 98.51 .03 98.21 .05\nData were first subjected to Analysis Of Variance (ANOVA), with Disparity and Display as within-subjects\nindependent variables and Score as the dependent variable. The ANOVA revealed that there was a significant\neffect of both display and disparity on performance, as well as a significant interaction between the two (all F\nvalues > 6.04 and all p values < .001).\n40%\n50%\n60%\n70%\n80%\n90%\n100%\n0 2 4 6\nDisparity (pixels)\nM\nea\nn\n \nSc\no\nre\n \n(p\ner\nce\nn\nta\nge\n \nco\nrr\nec\nt a\nn\nsw\ner\ns)\nDTI\nSeeReal\nColorlink\nSharp\nIris3D\nKodak\nShutter\nGlasses\nFigure 6. Graph illustrating the mean score(%) against im-\nage disparity (image pixels). We predicted that all partici-\npants would achieve an ideal score of 100(%) when the image\ndisparity is non-zero, otherwise they should achieve a score of\n50%.\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\nKo\nda\nk\nIri\ns3\nD\nCo\nlo\nrli\nn\nk\nSh\nu\ntte\nr\nG\nla\nss\ne\ns\nSh\na\nrp\nD\nTI\nSe\ne\nR\ne\na\nl\nDisplay\nN\nu\nm\nbe\nr \no\nf p\neo\npl\ne\nSeventh (Worst)\nSixth\nFifth\nForth\nThird\nSecond\nFirst (Best)\n2.17        2.67         3.58         4.08         4.25        5.50         5.75\nFigure 7. A subjective comparison of the seven dis-\nplays. Using a post-trial questionnaire participants\nwere asked to rank the displays in order of preference.\nThe cumulative results are sorted by the average rank\nof each display.\n5.1. 0-pixel Disparity\nFigure 8 shows the mean score and standard deviation from Table 1 for each display when there was zero image\ndisparity in the input image. It is important to confirm our prediction of a performance at chance (score 50%)\ngiven an image disparity of zero. If we find a reliable detectable depth difference in the 0-pixel disparity case\nthen this may indicate problems with participants viewing position during the trial or a display problem such as\nan optical or mechanical misalignment.\nD\nTI\nSe\neR\nea\nl\nCo\nlo\nrli\nn\nk\nSh\nar\np\nIri\ns3\nD\nK\no\nda\nk\nSh\nu\ntte\nr\nG\nla\ns\nse\ns\nDisplay\n0.00%\n50.00%\n100.00%\nSc\no\nre\n(p\ner\nce\nn\nta\nge\n)\n9 9\n9 9\n9\n9\n9\n53.87% 56.84% 61.31% 63.10% 72.02% 52.68% 60.71%\nFigure 8. Mean score and standard deviation for 0-\npixel disparity.\nD\nTI\nSe\neR\nea\nl\nCo\nlo\nrli\nn\nk\nSh\nar\np\nIri\ns3\nD\nK\no\nda\nk\nSh\nu\ntte\nr\nG\nla\ns\nse\ns\nDisplay\n0.00%\n50.00%\n100.00%\nSc\no\nre\n(p\ner\nce\nn\nta\nge\n)\n9\n9\n9\n9 9 9 9\n95.83% 52.98% 88.39% 95.54% 99.11% 96.43% 100.00%\nFigure 9. Mean score and standard deviation for 2-\npixel disparity.\nTo investigate this we conducted a series of pairwise t-tests where we compared the mean score associated\nwith each display against chance (i.e. score = 50%). Even though participants seemed to be slightly biased\ntowards choosing the right square (all mean values > 50%), the tests showed that the mean scores for the first\nfive displays (DTI, ColorLink, SeeReal, Kodak and Shutter Glasses) were not significantly different from chance\n(all t(11) values < 1.77, all p values > .11). Therefore these five displays performed as we predicted.\nWhen using the Sharp display participants were significantly biased towards selecting the right square when\nno image disparity was introduced (M = 63%, t(11) = 3.04, p = .01). However, a more detailed analysis showed\nthe performance for the Sharp display was not significantly different to the performance of the first five displays\n(all t(11) values < 2.18, all p values > .05).\nThe Iris-3D also showed a performance significantly higher than chance (M = 72%, t(11) = 5.29, p < .001)\nand also reliably higher than that for the first five displays (all t(11) values > 1.99, all p values = .07 or lower).\nTherefore when using the Iris3D display, candidates were not performing by chance, but were systematically\nperceiving a difference in depth between the two squares (i.e. right square closer than left square).\n5.2. 2-pixel Disparity\nThe second aspect of the data that we considered in detail was performance at 2-pixel disparity. Mean scores and\nstandard deviation for this condition are shown in Figure 9. According to our predictions, all the displays should\nhave the capability to reproduce an image disparity of 2 pixels. In order to investigate this, we performed a series\nof paired t-tests and all the displays performed as predicted, or only marginally poorer than our prediction, with\nthe exception of the SeeReal display.\nThe t-tests revealed that the mean score for the SeeReal display (M = 53%) was significantly lower than\nthe mean score for all the other displays (all M values > 88%; all t(11) values > 4.28, all ps = .001 or lower).\nSpecifically, when using the SeeReal display, participants were performing no differently than chance (SeeReal\nvs chance: t(11) = 1.45, p > .1), which suggests that they were unable to detect any difference in depth between\nthe two squares. By contrast, when using any of the other displays, candidates were clearly able to detect depth\nand were performing significantly better than chance (all t(11) values > 4.71, all p values = .001 or lower).\nWith respect to the SeeReal display, pairwise comparisons across disparity levels also showed that at 2-pixel\ndisparity participants performed significantly worse than at 4-pixel disparity (t(11) = 5.16 and p < .001) but not\nreliably differently than at 0-pixel disparity (t(11) = 0.51 and p > .5). This suggests that with the experimental\nconditions adopted in our trials the SeeReal display does not have the predicted capability to reproduce 2-pixel\nimage disparity.\n5.3. 4- and 6-pixel Disparity\nWe predicted that all the displays in this study should be able to reproduce image disparities of 2 or more pixels.\nHowever clearly at least one display has problems reproducing 2-pixel disparity and here we investigate if high\nvalues of disparity are reliably presented on the displays. Mean task scores at 4- and 6-pixel image disparity\nlevels are shown in Figure 10 and Figure 11.\nD\nTI\nSe\neR\nea\nl\nCo\nlo\nrli\nn\nk\nSh\nar\np\nIri\ns3\nD\nK\no\nda\nk\nSh\nu\ntte\nr\nG\nla\ns\nse\ns\nDisplay\n0.00%\n50.00%\n100.00%\nSc\no\nre\n(p\ner\nce\nn\nta\nge\n)\n9\n9 9\n9 9 9 9\n93.75% 88.10% 88.39% 95.24% 100.00% 95.54% 98.51%\nFigure 10. Mean score and standard deviation for\n4-pixel image disparity.\nD\nTI\nSe\neR\nea\nl\nCo\nlo\nrli\nn\nk\nSh\nar\np\nIri\ns3\nD\nK\no\nda\nk\nSh\nu\ntte\nr\nG\nla\ns\nse\ns\nDisplay\n0.00%\n50.00%\n100.00%\nSc\no\nre\n(p\ner\nce\nn\nta\nge\n)\n9\n9 9 9\n9 9 9\n95.83% 88.69% 89.29% 86.61% 99.41% 95.24% 98.21%\nFigure 11. Mean score and standard deviation for\n6-pixel image disparity.\nWhere a 4-pixel disparity level was applied, performance for all tested displays was high (all Mean values\n= 88% or higher). There were a some marginal effects however the only notable statistically reliable difference\nwas the better performance observed for the Iris3D than for the Sharp (t(11) = 2.46 and p < .05).\nA similar situation arose in the 6-pixel disparity presentation conditions. Again there were some marginal\neffects but we only observed reliably better performance for the Iris3D than for the DTI display (t(11) = 2.25\nand p < .05).\nOn the basis of the numerical trends that we observe in the data, the Sharp display deserved particular\nattention. As the graph of Figure 6 illustrates, it is the only display that shows an apparent decrease in\nperformance with increased disparity. To be specific, the mean score for the Sharp display drops from 95% at 2-\nand 4-pixel disparity to 87% at 6-pixel disparity. Nevertheless, pairwise comparisons showed that this decrease\nin performance was not reliable (all t values < 1.70, all p values > .1).\nOverall, the data for 4-pixel and 6-pixel disparity conditions show that all the displays are performing as we\npredicted. Notably the difference in variances between scores on different displays suggests that there is scope to\nfurther investigate the possible sources and effects of this variance. For example the Iris-3D results demonstrate\nmuch lower variance than the ColorLink display.\n6. SUBJECTIVE RESULTS\nAt the end of each experimental session participants were asked to complete a detailed questionnaire relating to\nthe display they had just used (level of ease seeing 3D, disturbing factors, level of discomfort, general comments\nabout the display). They were also asked to fill in a more general survey at completion of the whole experiment.\nA cumulative comparison of participants subjective display rankings from the questionnaire is shown in Figure 7.\n7. GENERAL DISCUSSION\nOverall, the fact that participants generally had high performance is evidence that the task was appropriate\nand clearly defined. We therefore believe that the data obtained are meaningful and provide insight into the\ncharacteristics of depth perception on the different 3D displays we tested.\nThe general ANOVA reveals a strong effect of the independent variables, Display and Disparity, on partic-\nipant\u2019s score and a strong interaction between the two. In regard to disparity we have demonstrated a clear\nthreshold effect, that is we can identify at what level of image disparity perceived depth becomes visible on a\ndisplay. We also find that display has a direct influence on participant\u2019s score and additionally that within one\nclass of 3D display there are significant variations between displays.\n7.1. 0-pixel Input Image Disparity\nThe analysis of 0-pixel disparity data using t-tests revealed that performance for the DTI, SeeReal, ColorLink,\nKodak and Shutter Glasses displays was not significantly different than chance and therefore in accordance with\nour predictions. That is for these displays, when the input image disparity is zero for both squares there is no\nperceived depth difference between the left and right squares.\nWith respect to the Iris3D display task performance was significantly different from chance and in this case\nalso significantly different to any other display. We therefore need to consider why participants might be seeing\nperceived depth on this display when there is no input image disparity. We identified three possible sources\nof modification to the signal that might affect perceived depth. The first is optical, a number of participants\nreported observing a secondary peripheral reflection of the stimulus when viewing the monitor. The second is\nelectronic, one channel from the driving PC was fed to the display via a video splitter in order to simultaneously\ndrive an external 2D monitor. this could result in a delay to the signal to one eye. The third possibility is a\nmechanical component misalignment in the display itself.\nWhen we ran a similar version of this experiment using the Iris3D display in a later trial the first two\npossibilities were removed and it was found that there had been a small mechanical alignment error in the\nprototype display used in the current trial which when corrected resulted in performance as predicted for the\nIris3D. It is encouraging that our evaluative methodology is sensitive enough to detect this low level of display\nmisalignment.\n7.2. 2-pixels and above Input Image Disparity\nFrom our geometric predictions we expected all the displays in the study to show perceived depth for an input\nimage disparity of 2-pixels or above. That is we would expect all participants on all displays to achieve a score\nsignificantly higher than chance. Our analysis showed that this was the case for the ColorLink, the Iris3D, the\nKodak, the DTI, the Sharp and the Shutter Glasses displays. Participants were able perceive depth on all these\ndisplays when the input image disparity was 2-pixels or higher.\nThe results for the SeeReal display were however not consistent with our prediction. Participants were unable\nto perceive depth for 2-pixels image disparity and it was not until 4-pixels disparity and above that the score was\nreliably better than chance. Investigating this effect in detail led us to conclude that this was an effect directly\ndue to aliasing of the input image disparity. In adjusting the input image to show 2-pixels disparity we shifted\none square to the left one image pixel and the other square to the right one image pixel. The outcome was that\nboth adjustments were masked by the interleaving process shown in Figure 2 and the result was no visible view\ndisparity. Had we chosen to shift one view image by 2-pixels our investigation showed that participants would\nhave seen some view disparity. Further investigation on the other column-interleaved display in this study, the\nDTI, showed the same aliasing effect at 2-pixels disparity could be generated for the DTI simply by altering the\nstarting image position of the stimulus from even to odd pixel columns. In both cases the source of this aliasing\nis the software drivers and\/or the electronic interface rather than the display itself.\nWe would anticipate a similar aliasing artefact will be generated by the colour-column interleaving process\nused on the Sharp displays but our experiment would need to be repeated at image disparity intervals of 1-pixel\nto investigate this.\n8. CONCLUSION\nWe have investigated the quality of reproduction of image disparity as perceived depth on a range of desktop\n3D displays. Our methodology has generated statistically robust results and demonstrates significant differences\nbetween the human perception of depth on different 3D displays. It has also proved to be sensitive enough to\ndetect small display misalignments.\nFor application users the results suggest that care should be taken when selecting 3D displays for tasks where\ncritical depth judgements are made. Not all displays are capable of reproducing the same image disparity and\nthere are significant differences between displays, even between those that belong to the same class of 3D display.\nThe differences between displays belonging to the same class appear to be due to aliasing introduced by software\ndrivers and electronic interfaces rather than the display\u2019s optical design. The fact that some participants who\npassed a stereo vision test were unable to generate reliable scores in this study also suggests a need to carefully\nscreen operators using 3D displays for critical tasks.\nFinally we conclude there is a need to run this task using single pixel image disparity increments. This will\nidentify performance differences between displays in representing disparity for fine depth judgements. In addition\nit should provide a more detailed understanding of the aliasing artefacts for each class of display.\n9. ACKNOWLEDGEMENTS\nThe authors would like to thank all those who supported this work. In particular ColorLink Corp., Iris3D Ltd.,\nand Kodak Corp. for the loan of their respective display equipment and technical discussions regarding these\nsystems. The authors also thank Prof. John Findlay for his advice on the experimental design and Dr. Gustav\nKuhn for his assistance with the statistical analysis of the data. Additionally we thank the Faculty of Science\nat Durham University for support of the Durham Visualization Laboratory.\nREFERENCES\n1. M. S. Habib, J. Lowell, D. Vaideanu, N. Holliman, A.Hunter, and D. Steel, \u201cAssessment of qualitative stereo viewing\nand quantitative mapping of optic disc using polarized goggles verses autostereoscopic screen,\u201d Proceeedings of the\nAnnual Conference of the American Academy of Ophthalmology, October 2005.\n2. K.J.W.McCaffrey, R.R.Jones, R. Holdsworth, R. Wilson, P. Clegg, J. Imber, N.S.Holliman, and I. Trinks, \u201cUnlocking\nthe spatial dimension: digital technologies and the future of geoscience fieldwork,\u201d J. Geological Society 162(6),\npp. 927\u2013938, 2005. ISSN 0016-7649.\n3. Y. Yeh and L. Silverstein, \u201cLimits of fusion and depth judgements in stereoscopic color displays,\u201d Human Fac-\ntors 1(32), 1990.\n4. A. Woods, T. Docherty, and R. Koch, \u201cImage distortions in stereoscopic video systems,\u201d Proceedings of SPIE 1915,\n1993.\n5. G. Jones, D. Lee, N. Holliman, and D. Ezra, \u201cControlling perceived depth in stereoscopic images,\u201d in Stereoscopic\nDisplays and Virtual Reality Systems VIII, Proceedings of SPIE 4297A, 2001.\n6. N. Langlands, \u201cExperiments on binocular vision,\u201d Trans. Optical Soc. XXVII(2), pp. 4\u201382, 1926.\n7. B. Julesz, Foundations of cyclopean perception, The University of Chicago Press, 1971.\n8. D. Diner and D. Fender, Human engineering in stereoscopic viewing devices, Plenum Press, 1993. ISBN 0-306-44667-7.\n9. Z. Y. Alpaslan, S. Yeh, A. A. R. III, and A. A. Sawchuk, \u201cEffects of gender, application, experience, and constraints on\ninteraction performance using autostereoscopic displays,\u201d in Stereoscopic Displays and Applications XVII, Proceedings\nof SPIE 6055A, 2006.\n10. L. Lipton, \u201cLiquid crystal shutter system for stereoscopic and other applications..\u201d United States Patent, Patent No.\n4967268, 1983.\n11. J. Cobb, \u201cAutostereoscopic desktop display: an evolution of technology.,\u201d in Stereoscopic Displays and Applications\nXVI, Proceedings of SPIE 5664, pp. 139\u2013149, 2005.\n12. S. McKay, S. Mason, L. Mair, P. Waddell, and S. Fraser, \u201cStereoscopic display using a 1.2-m diameter stretchable\nmembrane mirror,\u201d Proceedings of SPIE 3639, pp. 122\u2013131, 1999.\n13. J. Eichenlaub, \u201cDevelopments in autostereoscopic technology at dimension technologies inc.,\u201d in Stereoscopic Displays\nand Applications IV, Proceedings of SPIE 1915, pp. 177\u2013186, 1993.\n14. A. Schwerdtner and H. Heidrich, \u201cOptical system for the two and three dimensional representation of information.\u201d\nUS Pat. No. 5,774,262, June 1998 (filed Germany 1993).\n15. A. Jacobs, J. Mather, R. Winlow, D. Montgomery, G. Jones, M. Willis, M. Tillin, L. Hill, M. Khazova, H. Stevenson,\nand G. Bourhill, \u201c2D\/3D switchable displays,\u201d Sharp Technical Journal (4), 2003.\n16. N. Holliman, Handbook of Opto-electronics, ch. Three-Dimensional Display Systems. Taylor and Francis, May 2006.\nISBN 0 7503 0646 7.\n"}
{"doi":"10.1007\/11863878_6","coreId":"15610","oai":"oai:eprints.erpanet.org:110","identifiers":["oai:eprints.erpanet.org:110","10.1007\/11863878_6"],"title":"Genre Classification in Automated Ingest and Appraisal Metadata","authors":["Kim, Dr Yunhyong","Ross, Seamus"],"enrichments":{"references":[{"id":9469514,"title":"A Shallow Approach To Syntactic Feature Extraction For Genre Classi\ufb01cation.","authors":[],"date":"2004","doi":null,"raw":"Santini, M.: A Shallow Approach To Syntactic Feature Extraction For Genre Classi\ufb01cation. Proceedings of the 7th Annual Colloquium for the UK Special Interest Group for Computational Linguistics (CLUK 04) (2004).","cites":null},{"id":9469505,"title":"A Toolkit for Statistical Language Modeling, Text Retrieval, Classi\ufb01cation and Clustering.","authors":[],"date":"1998","doi":null,"raw":"McCallum, A.: Bow: A Toolkit for Statistical Language Modeling, Text Retrieval, Classi\ufb01cation and Clustering. (1998) http:\/\/www.cs.cmu.edu\/ mccallum\/bow\/","cites":null},{"id":9469508,"title":"Adobe Acrobat PDF speci\ufb01cation:","authors":[],"date":null,"doi":"10.1002\/9781118255728","raw":"Adobe Acrobat PDF speci\ufb01cation: http:\/\/partners.adobe.com\/ public\/developer\/ pdf\/index reference.html","cites":null},{"id":668591,"title":"An Algorithm for Finding Maximal Whitespace Rectangles at Arbitrary Orientations for Document Layout Analysis.","authors":[],"date":"2003","doi":"10.1109\/icdar.2003.1227629","raw":"Breuel, T. M.: An Algorithm for Finding Maximal Whitespace Rectangles at Arbitrary Orientations for Document Layout Analysis. 7th International Conference for Document Analysis and Recognition (ICDAR), 66\u201370 (2003).","cites":null},{"id":668588,"title":"Automatic Categorization of Email into Folders.","authors":[],"date":"2004","doi":null,"raw":"Bekkerman, R., McCallum, A., Huang, G.: Automatic Categorization of Email into Folders. Benchmark Experiments on Enron and SRI Corpora\u2019, CIIR Technical Report, IR-418 (2004).","cites":null},{"id":671909,"title":"Automatic Detection of Text Genre.","authors":[],"date":"1997","doi":null,"raw":"Kessler, B., Nunberg, G., Schuetze, H.: Automatic Detection of Text Genre. Proc. 35th Ann. Meeting ACL (1997) 32\u201338.","cites":null},{"id":671905,"title":"Automatic Document Metadata Extraction using Support Vector Machines.","authors":[],"date":"2000","doi":"10.1109\/jcdl.2003.1204842","raw":"Han, H., Giles, L., Manavoglu, E., Zha, H., Zhang, Z., Fox, E. A.: Automatic Document Metadata Extraction using Support Vector Machines. Proc. 3rd ACM\/IEEECS conf. Digital libraries (2000) 37\u201348.","cites":null},{"id":668584,"title":"Automatic Metadata Generation:","authors":[],"date":null,"doi":"10.1007\/978-0-387-77745-0_15","raw":"Automatic Metadata Generation: http:\/\/www.cs.kuleuven.ac.be\/ \u02dc hmdb\/amg \/documentation.php","cites":null},{"id":9469519,"title":"Automating the production of bibliographic records.","authors":[],"date":"2001","doi":null,"raw":"Thoma,G.: Automating the production of bibliographic records. R&D report of the Communications Engineering Branch, Lister Hill National Center for Biomedical Communications, National Library of Medicine, 2001.","cites":null},{"id":668587,"title":"Clustering Document Images Using a Bag of Symbols Representation.","authors":[],"date":"2005","doi":"10.1109\/icdar.2005.75","raw":"Barbu, E., Heroux, P., Adam, S., Trupin, E.: Clustering Document Images Using a Bag of Symbols Representation. International Conference on Document Analysis and Recognition, (2005) 1216\u20131220.","cites":null},{"id":668592,"title":"Core metadata editor: http:\/\/www.ukoln.ac.uk\/metadata\/dcdot\/","authors":[],"date":null,"doi":null,"raw":"DC-dot, Dublin Core metadata editor: http:\/\/www.ukoln.ac.uk\/metadata\/dcdot\/","cites":null},{"id":668589,"title":"Dimensions of Register Variation:a Cross-Linguistic Comparison.","authors":[],"date":"1995","doi":"10.1017\/cbo9780511519871.010","raw":"Biber, D.: Dimensions of Register Variation:a Cross-Linguistic Comparison. Cambridge University Press (1995).","cites":null},{"id":668583,"title":"Document Understanding for a Broad Class of Documents.","authors":[],"date":"2002","doi":"10.1007\/s10032-002-0080-x","raw":"Aiello, M., Monz, C., Todoran, L., Worring, M.: Document Understanding for a Broad Class of Documents. International Journal on Document Analysis and Recognition 5(1) (2002) 1\u201316.","cites":null},{"id":668585,"title":"Domain oriented information extraction from the Internet.","authors":[],"date":"2003","doi":"10.1117\/12.476042","raw":"Arens,A., Blaesius, K. H.: Domain oriented information extraction from the Internet. Proceedings of SPIE Document Recognition and Retrieval 2003 Vol 5010 (2003) 286.","cites":null},{"id":671906,"title":"E.: Invest to Save: Report","authors":[],"date":"2003","doi":null,"raw":"Hedstrom, M., Ross, S., Ashley, K., Christensen-Dalsgaard, B., Du\ufb00, W., Gladney, H., Huc, C., Kenney, A. R., Moore, R., Neuhold, E.: Invest to Save: Report and Recommendations of the NSF-DELOS Working Group on Digital Archiving and Preservation. Report of the European Union DELOS and US National Science Foundation Workgroup on Digital Preservation and Archiving (2003) http:\/\/delos-noe.iei.pi.cnr.it\/activities\/internationalforum\/JointWGs\/digitalarchiving\/Digitalarchiving.pdf.74 Y. Kim and S. Ross","cites":null},{"id":671902,"title":"Electronic Resources Preservation Access Network (ERPANET):","authors":[],"date":null,"doi":null,"raw":"Electronic Resources Preservation Access Network (ERPANET): http:\/\/ www.erpanet.org","cites":null},{"id":671903,"title":"ERPANET: Packaged Object Ingest Project.","authors":[],"date":null,"doi":null,"raw":"ERPANET: Packaged Object Ingest Project. http:\/\/www.erpanet.org\/events\/ 2003\/rome\/presentations\/ ross rusbridge pres.pdf","cites":null},{"id":668586,"title":"Fine-Grained Document Genre Classi\ufb01cation Using First Order Random Graphs.","authors":[],"date":"2001","doi":"10.1109\/icdar.2001.953759","raw":"Bagdanov, A. D., Worring, M.: Fine-Grained Document Genre Classi\ufb01cation Using First Order Random Graphs. Proceedings of International Conference on Document Analysis and Recognition 2001 (2001) 79.","cites":null},{"id":9469518,"title":"Graphics Recognition","authors":[],"date":null,"doi":"10.1007\/11767978_21","raw":"M. Shao, M. and Futrelle, R.: Graphics Recognition in PDF document. Sixth IAPR International Workshop on Graphics Recognition (GREC2005), 218\u2013227.","cites":null},{"id":671900,"title":"Groups: Reference Models for Digital Libraries: Actors and Roles","authors":[],"date":"2003","doi":null,"raw":"DELOS\/NSF Working Groups: Reference Models for Digital Libraries: Actors and Roles (2003) http:\/\/www.dli2.nsf.gov \/internationalprojects\/ working group reports\/ actors \ufb01nal report.html","cites":null},{"id":671901,"title":"Initiative: http:\/\/dublincore.org\/tools\/#automaticextraction","authors":[],"date":null,"doi":null,"raw":"Dublin Core Initiative: http:\/\/dublincore.org\/tools\/#automaticextraction","cites":null},{"id":671904,"title":"Knowledge-based Metadata Extraction from PostScript File.","authors":[],"date":"2000","doi":"10.1145\/336597.336639","raw":"Giu\ufb00rida, G., Shek, E. Yang, J.: Knowledge-based Metadata Extraction from PostScript File. Proc. 5th ACM Intl. conf. Digital Libraries (2000) 77\u201384.","cites":null},{"id":9469512,"title":"Learning Subjective Nouns using Extraction Pattern Bootstrapping.","authors":[],"date":"2003","doi":"10.3115\/1119176.1119180","raw":"Rilo\ufb00, E., Wiebe, J., and Wilson, T.: Learning Subjective Nouns using Extraction Pattern Bootstrapping. Proc. 7th CoNLL, (2003) 25\u201332.","cites":null},{"id":9469515,"title":"Machine Learning in Automated Text Categorization\u2019,","authors":[],"date":"2002","doi":"10.1145\/505282.505283","raw":"Sebastiani F.: \u2019Machine Learning in Automated Text Categorization\u2019, ACM Computing Surveys, Vol. 34 (2002) 1-47","cites":null},{"id":9469506,"title":"National Archives UK: DROID (Digital Object Identi\ufb01cation).","authors":[],"date":null,"doi":null,"raw":"National Archives UK: DROID (Digital Object Identi\ufb01cation). http: \/\/www. nationalarchives. gov.uk\/ aboutapps\/pronom\/droid.htm","cites":null},{"id":9469507,"title":"of New Zealand: Metadata Extraction Tool.","authors":[],"date":null,"doi":null,"raw":"National Library of New Zealand: Metadata Extraction Tool. http:\/\/www. natlib. govt.nz\/en\/whatsnew\/4initiatives.html#extraction","cites":null},{"id":671908,"title":"PERC: A Personal Email Classifier.","authors":[],"date":"2006","doi":"10.1007\/11735106_41","raw":null,"cites":null},{"id":9469516,"title":"Performance Comparison of Six Algorithms for Page Segmentation\u201d,","authors":[],"date":null,"doi":"10.1007\/11669487_33","raw":"Faisal Shafait, Daniel Keysers, Thomas M. Breuel, \u201cPerformance Comparison of Six Algorithms for Page Segmentation\u201d, 7th IAPR Workshop on Document Analysis Systems (DAS) (2006).368\u2013379.","cites":null},{"id":9469511,"title":"PREMIS (PREservation Metadata: Implementation Strategy) Working Group: http:\/\/www.oclc.org\/research\/projects\/pmwg\/","authors":[],"date":null,"doi":null,"raw":"PREMIS (PREservation Metadata: Implementation Strategy) Working Group: http:\/\/www.oclc.org\/research\/projects\/pmwg\/","cites":null},{"id":9469513,"title":"Preservation Research and Sustainable Digital Libraries.","authors":[],"date":"2005","doi":"10.1007\/s00799-004-0099-3","raw":"Ross S and Hedstrom M.: Preservation Research and Sustainable Digital Libraries. International Journal of Digital Libraries (Springer) (2005) DOI: 10.1007\/s00799-004-0099-3.","cites":null},{"id":9469509,"title":"Python Imaging Library:","authors":[],"date":null,"doi":null,"raw":"Python Imaging Library: http:\/\/www.pythonware.com\/products\/pil\/","cites":null},{"id":671907,"title":"Recognizing Text Genres with Simple Metric using Discriminant Analysis.","authors":[],"date":"1994","doi":"10.3115\/991250.991324","raw":"Karlgren, J. and Cutting, D.: Recognizing Text Genres with Simple Metric using Discriminant Analysis. Proc. 15th conf. Comp. Ling. Vol 2 (1994) 1071\u20131075. 2 4 . K e ,S .W . ,B o w e r m a n ,C .O a k e s ,M .P E R C :AP e r s o n a lE m a i lC l a s s i \ufb01 e r .P r o c e e d -ings of 28th European Conference on Information Retrieval (ECIR 2006) 460\u2013463.","cites":null},{"id":668590,"title":"Stereotyping the web: genre classi\ufb01cation of web documents. Master\u2019s thesis,","authors":[],"date":"2005","doi":null,"raw":"Boese, E. S.: Stereotyping the web: genre classi\ufb01cation of web documents. Master\u2019s thesis, Colorado State University (2005).","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2006-01-01","abstract":"Metadata creation is a crucial aspect of the ingest of digital materials into digital libraries. Metadata needed to document and manage digital materials are extensive and manual creation of them expensive. The Digital Curation Centre (DCC) has undertaken research to automate this process for some classes of digital material. We have\nsegmented the problem and this paper discusses results in genre classification as a first step toward automating metadata extraction from documents. Here we propose a classification method built on looking at the documents from five directions; as an object exhibiting a specific visual\nformat, as a linear layout of strings with characteristic grammar, as an object with stylo-metric signatures, as an object with intended meaning and purpose, and as an object linked to previously classified objects and other external sources. The results of some experiments in relation to the first two directions are described here; they are meant to\nbe indicative of the promise underlying this multi-facetted approach.","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/15610.pdf","fullTextIdentifier":"http:\/\/eprints.erpanet.org\/110\/01\/genre_extraction_KIM_ROSS_2006_ECDL.pdf","pdfHashValue":"d3c904bd5124ad7f087b07b97df0bf888360fefa","publisher":null,"rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:eprints.erpanet.org:110<\/identifier><datestamp>\n      2006-10-18<\/datestamp><setSpec>\n      7374617475733D696E7072657373<\/setSpec><setSpec>\n      7375626A656374733D4375726174696F6E20497373756573<\/setSpec><setSpec>\n      7375626A656374733D45:526570726573656E746174696F6E20496E666F726D6174696F6E<\/setSpec><setSpec>\n      7375626A656374733D45:4541<\/setSpec><setSpec>\n      7375626A656374733D436F737473<\/setSpec><setSpec>\n      7375626A656374733D43:4347<\/setSpec><\/header><metadata><oai_dc:dc xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Genre Classification in Automated Ingest and Appraisal Metadata<\/dc:title><dc:creator>\n        Kim, Dr Yunhyong<\/dc:creator><dc:creator>\n        Ross, Seamus<\/dc:creator><dc:subject>\n        CG Harvesting<\/dc:subject><dc:subject>\n        P Curation Issues<\/dc:subject><dc:subject>\n        EG Representation Information<\/dc:subject><dc:subject>\n        O Costs<\/dc:subject><dc:subject>\n        EA Metadata<\/dc:subject><dc:description>\n        Metadata creation is a crucial aspect of the ingest of digital materials into digital libraries. Metadata needed to document and manage digital materials are extensive and manual creation of them expensive. The Digital Curation Centre (DCC) has undertaken research to automate this process for some classes of digital material. We have\nsegmented the problem and this paper discusses results in genre classification as a first step toward automating metadata extraction from documents. Here we propose a classification method built on looking at the documents from five directions; as an object exhibiting a specific visual\nformat, as a linear layout of strings with characteristic grammar, as an object with stylo-metric signatures, as an object with intended meaning and purpose, and as an object linked to previously classified objects and other external sources. The results of some experiments in relation to the first two directions are described here; they are meant to\nbe indicative of the promise underlying this multi-facetted approach.<\/dc:description><dc:date>\n        2006-01-01<\/dc:date><dc:type>\n        Conference Paper<\/dc:type><dc:identifier>\n        http:\/\/eprints.erpanet.org\/110\/<\/dc:identifier><dc:format>\n        pdf http:\/\/eprints.erpanet.org\/110\/01\/genre_extraction_KIM_ROSS_2006_ECDL.pdf<\/dc:format><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2006,"topics":["CG Harvesting","P Curation Issues","EG Representation Information","O Costs","EA Metadata"],"subject":["Conference Paper"],"fullText":"Genre Classi\ufb01cation in Automated Ingest and\nAppraisal Metadata\nYunhyong Kim and Seamus Ross\nDigital Curation Centre (DCC)\n&\nHumanities Adavanced Technology Information Institute (HATII)\nUniversity of Glasgow\nGlasgow, UK\nAbstract. Metadata creation is a crucial aspect of the ingest of dig-\nital materials into digital libraries. Metadata needed to document and\nmanage digital materials are extensive and manual creation of them ex-\npensive. The Digital Curation Centre (DCC) has undertaken research\nto automate this process for some classes of digital material. We have\nsegmented the problem and this paper discusses results in genre clas-\nsi\ufb01cation as a \ufb01rst step toward automating metadata extraction from\ndocuments. Here we propose a classi\ufb01cation method built on looking at\nthe documents from \ufb01ve directions; as an object exhibiting a speci\ufb01c vi-\nsual format, as a linear layout of strings with characteristic grammar,\nas an object with stylo-metric signatures, as an object with intended\nmeaning and purpose, and as an object linked to previously classi\ufb01ed\nobjects and other external sources. The results of some experiments in\nrelation to the \ufb01rst two directions are described here; they are meant to\nbe indicative of the promise underlying this multi-facetted approach.\n1 Background and Objective\nConstruction of persistent, cost-contained, manageable and accessible digital col-\nlections depends on the automation of appraisal, selection, and ingest of digital\nmaterial. Descriptive, administrative, and technical metadata play a key role in\nthe management of digital collections ([37],[21]). As DELOS\/NSF ([13],[14],[21])\nand PREMIS working groups ([34]) noted metadata are expensive to create and\nmaintain. Digital objects are not always accompanied by adequate metadata and\nthe number of digital objects being created and the variety of such objects is in-\ncreasing at an exponential rate. In response, the manual collection of metadata\ncan not keep pace with the number of digital objects that need to be docu-\nmented. It seems reasonable to conclude that automatic extraction of metadata\nwould be an invaluable step in the automation of appraisal, selection, and ingest\nof digital material. ERPANET\u2019s ([17]) Packaged Object Ingest Project ([18])\nidenti\ufb01ed only a limited number of automatic extraction tools mostly geared\nto extract technical metadata (e.g.[29],[31]), illustrating the intensive manual\nlabour required in the ingest of digital material into a repository. Subsequently\nJ. Gonzalo et al. (Eds.): ECDL 2006, LNCS 4172, pp. 63\u201374, 2006.\nc \u0002 Springer-Verlag Berlin Heidelberg 200664 Y. Kim and S. Ross\nsubstantial work on descriptive metadata extraction has emerged: e.g. extrac-\ntion from structured documents have been attempted by MetadataExtractor\nfrom University of Waterloo ([27]), Dublin Core Metadata Editor ([11]) and Au-\ntomatic Metadata Generation (AMG) at the Catholic University of Leuven([2]),\nand the extraction of bibliographic information from medical articles, based on\nthe detection of contiguous blocks and fuzzy pattern matching, is available from\nMedical Article Record System (MARS) ([42]) developed at the US National Li-\nbrary of Medicine (NLM)([30]). There have also been previous work on metadata\nextraction from scienti\ufb01c articles in postscript using a knowledge base of stylistic\ncues ([19],[20]) and, from the language processing community, there have been\nresults in automatic categorisation of emails ([6],[24]), text categorisation ([39])\nand document content summarisation ([43]). Other communities have used im-\nage analysis for information extraction from the Internet ([3]), document white\nspace analysis ([9]), graphics recognition in PDF \ufb01les ([41]), and algorithms for\npage segmentation ([40]). Despite the wealth of research being conducted, no\ngeneral tool has yet been developed which can be employed to extract meta-\ndata from digital objects of varied types and genres, nor are there dependable\nextraction tools for the extraction of deeper semantic metadata such as content\nsummary. The research in this paper is motivated by an e\ufb00ort to address this\nproblem by integrating the methods available in the area to create a prototype\ntool for automatically extracting metadata across many domains at di\ufb00erent\nsemantic levels. This would involve:\n\u2013 constructing a well-structured experimental corpus of one \ufb01le type (for use\nin this and future related research);\n\u2013 summarising and integrating existing research related to automatic metadata\nextraction;\n\u2013 determining the limit and scope of metadata that can be extracted and build-\ning a prototype descriptive and semantic metadata extraction tool applicable\nacross many domains;\n\u2013 extending the tool to cover other \ufb01le types and metadata ; and,\n\u2013 integrating it with other tools to enable automatic ingest, selection and\/or\nappraisal.\nThe initial prototype is intended to extract Genre, Author, Title, Date, Iden-\nti\ufb01er, Pagination, Size, Language, Keywords, Composition (e.g. existence and\nproportion of images, text and links) and Content Summary. In the present\npaper, we discuss genre classi\ufb01cation of digital documents represented in PDF\n([32]) as a step towards acquiring the appropriate metadata. The term genre\ndoes not always carry a clear meaning. We follow the de\ufb01nition of Kessler ([25])\nwho refers to genre as \u201cany widely recognised class of texts de\ufb01ned by some\ncommon communicative purpose or other functional traits, provided the func-\ntion is connected to some formal cues or commonalities and that the class is\nextensible\u201d. For instance, a scienti\ufb01c research article is a theoretical argument\nor communication of results relating to a scienti\ufb01c subject usually published in\na journal and often starting with a title, followed by author, abstract, and bodyGenre Classi\ufb01cation in Automated Ingest and Appraisal Metadata 65\nof text,\ufb01nally ending with a bibliography. One important aspect of genre classi-\n\ufb01cation is that it is distinct from subject classi\ufb01cation which can coincide over\nmany genres (e.g. a mathematical paper on number theory versus a news article\non the proof of Fermat\u2019s Last Theorem). The motivation for starting with genre\nclassi\ufb01cation is as follows:\n\u2013 Identifying the genre \ufb01rst will limit the scope of document forms from which\nto extract other metadata:\n\u2022 The search space for further metadata will be reduced; within a sin-\ngle genre, metadata such as author, keywords, identi\ufb01cation numbers or\nreferences can be expected to appear in a speci\ufb01c style and region.\n\u2022 A lot of independent work exists for extraction of metadata within a\nspeci\ufb01c genre which can be combined with a general genre classi\ufb01er for\nmetadata extraction over many domains (e.g. the papers listed at the\nbeginning of this section).\n\u2022 Resources available for extracting further metadata is di\ufb00erent for each\ngenre; for instance, research articles unlike newspaper articles come with\na list of reference articles closely related to the original article leading to\nbetter subject classi\ufb01cation.\n\u2013 Scoping new genres not apparent in the context of conventional libraries is\nnecessary.\n\u2013 Di\ufb00erent institutional collecting policies might focus on digital materials in\ndi\ufb00erent genres. Genre classi\ufb01cation will support automating the identi\ufb01ca-\ntion, selection, and acquisition of materials in keeping with local collecting\nguidelines.\nWe have opted to consider 60 genres (Table 1). This list is not meant to represent\na complete spectrum of possible genres; it is meant to be a starting point from\nwhich to determine what is possible.\nWe have focused our attention on di\ufb00erent genres represented in PDF \ufb01les.\nBy limiting the research to one \ufb01le type we hoped to put a boundary on the\nproblem space. The choice of PDF as the format stems from the fact that\n\u2013 PDF is a widely used format. Speci\ufb01cally, PDF is a common format for\ndigital objects ingested into digital libraries including eprint services.\n\u2013 It is a portable format, distributed over many di\ufb00erent platforms.\n\u2013 There are many tools available for conversion to and from other formats.\n\u2013 It is a versatile format which includes objects of di\ufb00erent type (e.g. images,\ntext, links) and di\ufb00erent genres (e.g. data structure, \ufb01ction, poetry, research\narticle).\nIn the experiment which follows we worked with a developmental data set col-\nlected via the Internet using a random PDF-grabber which\n1. selects a random word from a Spell Checker Oriented Word List (from source-\nforge.net),\n2. searches the Internet using Google for PDF \ufb01les containing the chosen word,66 Y. Kim and S. Ross\nTable 1. Scope of genres\nGroups Genres\nBook Academic book, Fiction(book), Poetry(book),Other book\nArticle\nScienti\ufb01c research article, Other research article, Magazine article,\nNews report\nPeriodicals Periodicals, Newsletter\nMail Email, Letter\nThesis Thesis, Business\/Operational report, Technical report, Misc report\nList List,Catalogue\nTable Calendar, Menu, Other table\nProposal Grant\/Project proposal, Legal appeal\/proposal\/order\nDescription Job\/Course\/Project description, Product\/Application description\nMinutes Minutes, Proceedings\nRules Instruction\/Guideline, Regulations\nOther\nAbstract,Advertisement, Announcement, Appeal\/Propaganda, Biogra-\nphy, Chart\/Graph,Contract, Drama, Essay, Exam\/Worksheet, Fact\nsheet,Fiction piece, Forms, Forum discussion, Image, Interview, Lec-\nture notes\/presentation, Speech transcript, Manual, Memo, Sheet mu-\nsic, Notice, Posters, Programme, Questionnaire, Q & A, Resume\/CV,\nReview, Slides, Poetry piece, Other genre not listed\n3. selects a random PDF \ufb01le from the returned list and places it in a designated\nfolder.\nWe collected over 4000 documents in this manner. Labelling of this document\ncorpus is still in progress (for genre classi\ufb01cation) and is mostly being carried\nout by one of the authors. Currently 570 are labelled with one of the 60 genres.\nA signi\ufb01cant amount of disagreement is expected in labelling genre even between\nhuman labellers; we intend to cross check the labelled data in two ways:\n\u2013 We will employ others to label the data to determine the level of disagreement\nbetween di\ufb00erent human labellers; this will enable us to analyse at what level\nof accuracy the automated system should be expected perform, while also\nproviding us with a gauge to measure the di\ufb03culty of labelling individual\ngenres.\n\u2013 We will gather PDF \ufb01les which have already been classi\ufb01ed into genres as a\nfresh test data for the classi\ufb01er; this will also serve as a means of indexing\nthe performance on well-designed classi\ufb01cation standards.\nAlong with the theoretical work of Biber ([7]) on genre structures, there have\nbeen a number of studies in automatic genre classi\ufb01cation: e.g. Karlgren and\nCutting ([23], distinguishing Press, Misc, Non-\ufb01ction and Fiction), Kessler et\nal. ([25], distinguishing Reportage, Fiction, Scitech, Non-\ufb01ction, Editorial and\nLegal; they also attempt to detect the level of readership - which is referred\nto as Brow - divided into four levels, and make a decision on whether or notGenre Classi\ufb01cation in Automated Ingest and Appraisal Metadata 67\nthe text is a narrative), Santini ([38], distinguishing Conversation, Interview,\nPublic Debate, Planned Speech, Academic prose, Advert, Biography,Instruction,\nPopular Lore and Reportage), and, Bagdannov and Worring ([4], \ufb01ne-grained\ngenre classi\ufb01cation using \ufb01rst order random graphs modeled on trade journals\nand brochures found in the Oc\u00b4 e Competitive Business Archive) not to mention\na recent MSc. dissertation written by Boese ([8], distinguishing ten genres of\nweb documents). There are also related studies in detecting document logical\nstructures ([1]) and clustering documents ([5]). Previous methods can be divided\ninto groups which look at one or more of the following:\n\u2013 Document image analysis\n\u2013 Syntactic feature analysis\n\u2013 Stylistic feature analysis\n\u2013 Semantic structure analysis\n\u2013 Domain knowledge analysis\nWe would eventually like to build a tool which looks at all of these for the\n60 genres mentioned (see Table 1). The experiments in this paper however are\nlimited to looking at the \ufb01rst two aspects of seven genres. Only looking at seven\ngenres out of 60 is a signi\ufb01cant cut back, but the fact that none of the studies\nknown to us have combined the \ufb01rst two aspects for genre classi\ufb01cation and\nthat very few studies looked at the task in the context of PDF \ufb01les makes the\nexperiments valuable as a report on the \ufb01rst steps to a general process. This\npaper is not meant to be a conclusive report, but the preliminary \ufb01ndings of an\nongoing project and is meant to show the promise of combining very di\ufb00erent\nclassifying methods in identifying the genre of a digital document. It is also\nmeant to emphasise the importance of looking at information extraction across\ngenres; genre-speci\ufb01c information extraction methods usually depend heavily\non the structures held in common by the documents in the chosen domain; by\nlooking at di\ufb00erences between genres we can determine the variety of structures\none might have to resolve in the construction of a general tool.\n2 Classi\ufb01ers\nThe experiments described in this paper require the implementation of two\nclassi\ufb01ers:\nImage classi\ufb01er: this classi\ufb01er depends on features extracted from the PDF\ndocument when handled as an image.\n\u2013 It uses the module pdftoppm from XPDF to extract the \ufb01rst page of the\ndocument as an image then employs Python\u2019s Image Library (PIL) ([35],\n[33]) to extract pixel values. This is then sectioned o\ufb00 into ten regions for\nan examination of the number of non-white pixels. Each region is rated\nas level 0, 1, 2, 3 (larger number indicating a higher density of non-white\nspace). The result is statistically modelled using the Maximum Entropy\nprinciple. The tool used for the modelling is MaxEnt for C++ developed\nby Zhang Le ([26]).68 Y. Kim and S. Ross\nLanguage model classi\ufb01er: this classi\ufb01er depends on an N-gram model on\nthe level of words, Part-of-Speech tags and Partial Parsing tags.\n\u2013 N-gram models look at the possibility of word w(N) coming after a string\nof words W(1), W(2), ..., w(N-1). A popular model is the case when N=3.\nThis model is usually constructed on the word level. In this research we\nwould eventually like to make use of the model on the level of Part-\nof-Speech (POS) tags (for instance, tags which denote whether a word\nis a verb, noun or preposition) or Partial Parsing (PP) tags (e.g. noun\nphrases, verb phrases or prepositional phrases). Initially we only work\nwith the word-level model. This has been modelled by the BOW toolkit\ndeveloped by Andrew McCallum ([28]). We used the default Naiive Bayes\nmodel without a stoplist.\nAlthough the tools for extracting the image and text of the documents used in\nthese classi\ufb01ers are speci\ufb01c to PDF \ufb01les, a comparable representation can be\nextracted in other formats by substituting these tools with corresponding tools\nfor those formats. In the worst-case scenario the process can be approximated\nby \ufb01rst converting the format to PDF, then using the the same tools; the wide\ndistribution of PDF ensures the existence of a conversion tool for most common\nformats.\nUsing the image of a text document in the classi\ufb01cation of the document has\nseveral advantages:\n\u2013 it will be possible to extract some basic information about documents with-\nout accessing content or violating password protection or copyright;\n\u2013 more likely to be able to forgo the necessity of substituting language modeling\ntools when moving between languages, i.e. it maximises the possibility of\nachieving a language independent tool;\n\u2013 the classi\ufb01cation will not be solely dependent on fussy text processors and\nlanguage tools (e.g. encoding requirements, problems relating to special char-\nacters or line-breaks);\n\u2013 it can be applied to paper documents digitally imaged (i.e. scanned) for inclu-\nsion in digital repositories without heavily relying on accuracy in character\nrecognition.\n3 Experiment Design\nThe experiments in this paper are the \ufb01rst steps towards testing the following\nhypothesis:\nHypothesis A: Given a collection of digital documents consisting of sev-\neral di\ufb00erent genres, the set of genres can be partitioned into groups such\nthat the visual characteristics concur and linguistic characteristics dif-\nfer between documents within a single group, while visual aspects di\ufb00er\nbetween the documents of two distinct groups.Genre Classi\ufb01cation in Automated Ingest and Appraisal Metadata 69\nAn assumption in the two experiments described here is that PDF documents\nare one of four categories: Business Report, Minutes, Product\/Application De-\nscription, Scienti\ufb01c Research Article. This, of course, is a false assumption and\nlimiting the scope in this way changes the meaning of the resulting statistics\nconsiderably. However, the contention of this paper is that high level perfor-\nmance on a limited data set combined with a suitable means of accurately\nnarrowing down the candidates to be labelled would achieve the end\nobjective.\nSteps for the \ufb01rst experiment\n1. take all the PDF documents belonging to the above four genres (70 docu-\nments in the current labelled data),\n2. randomly select a third of the documents in each genre as training data (27\ndocuments) and the remaining documents as test data (43 documents),\n3. train both the image classi\ufb01er and language model classi\ufb01er (on the level of\nwords) on the selected training data,\n4. examine result.\nSteps for the second experiment\n1. using the same training and test data as that for the \ufb01rst experiment,\n2. allocate the genres to two groups, each group containing two genres: Group\nI contains business reports and minutes while Group II contains scienti\ufb01c\nresearch articles and product descriptions,\n3. train the image classi\ufb01er to di\ufb00erentiate between the two groups and use\nthis to label the test data as documents of Group I or Group II,\n4. train two language model classi\ufb01ers: Classi\ufb01er I which distinguishes business\nreports from minutes and Classi\ufb01er II which labels documents as scienti\ufb01c\nresearch articles or product descriptions,\n5. take test documents which have been labelled Group I and label them with\nClassi\ufb01er I; take test documents which have been labelled Group II and label\nthem with Classi\ufb01er II,\n6. examine result.\nThe genres to be placed in Group I and Group II were selected by choosing the\npartition which showed the highest training accuracy for the image classi\ufb01er.\n4R e s u l t s\nIn the evaluation of the results to follow we will use three indices which are\nconsidered standard in a classi\ufb01cation tasks: accuracy, precision and recall. Let N\nbe the total number of documents in the test data, Nc the number of documents\nin the test data which are in class C, T the total number of correctly labelled\ndocuments in the data independent of the class, Tc the number of true positives70 Y. Kim and S. Ross\nfor class C (documents correctly labelled as class C), and Fc the number of false\npositives for class C (documents labelled incorrectly as class C). Accuracy is\nde\ufb01ned to be A = T\nN while precision and recall for each class C is de\ufb01ned to be\nPc = Tc\n(Tc+Fc) and Rc = Tc\nNc respectively.\nThe precision and recall for the \ufb01rst and second experiments are given in\nTable 2 and Table 3.\nTable 2. Result for \ufb01rst small experiment\nOverall accuracy (Language model only): 77%\nGenres Prec.(%) Rec.(%)\nBusiness Report 83 50\nSci. Res. Article 88 80\nMinutes 64 100\nProduct Desc. 90 90\nTable 3. Result for second small experiment\nOverall accuracy(Image and Language model: 87.5 %\nGenres Prec.(%) Rec(%)\nBusiness Report 83 50\nSci. Res. Article 75 90\nMinutes 71 100\nProduct Desc. 90 100\nAlthough the performance of the language model classi\ufb01er given in Table 2\nis already surprisingly high, this, to a great extent, depends on the four cate-\ngories chosen. In fact, when the classi\ufb01er was expanded to include 40 genres,\nthe classi\ufb01er performed only at an accuracy of approximately 10%. When a\ndi\ufb00erent set was employed which included Periodicals, Thesis, Minutes and In-\nstruction\/Guideline, the language model performs at an accuracy of 60.34%. It\nis clear from the two examples that such a high performance can not be expected\nfor any collection of genres.\nThe image classi\ufb01er on Group I(Periodicals) and Group II(Thesis, Minutes,\nInstruction\/Guideline) performs at an accuracy of 91.37%. The combination of\nthe two classi\ufb01ers have not been tested but even in the worst-case scenario,\nwhere we assume that the set of mislabelled documents for the two classi\ufb01ers\nhave no intersection, the combined classi\ufb01er would still show an increase in\noverall accuracy of approximately 10%.\nThe experiments show an increase in the overall accuracy when the language\nclassi\ufb01er is combined with the image classi\ufb01er. To gauge the signi\ufb01cance of the\nincrease, a statistically valid signi\ufb01cance test would be required. The experiments\nhere however are intended not to be conclusive but indicative of the promise\nunderlying the combined system.Genre Classi\ufb01cation in Automated Ingest and Appraisal Metadata 71\n5 Conclusion and Further Research\n5.1 Intended Extensions\nThe experiments show that, although there is a lot of confusion visually and\nlinguistically over all 60 genres, subgroups of the genres exhibit statistically\nwell-behaved characteristics. This encourages the search for groups which are\nsimilar or di\ufb00erent visually or linguistically to further test Hypothesis A. To\nextend the scenario in the experiment to all the genres the following steps are\nsuggested.\n1. randomly select a third of the documents in each genre as training data and\nthe remaining documents as test data,\n2. train the image and language model classi\ufb01er on the resulting and test over\nall genres,\n3. try to re-group genres so that each group contain genres resulting in a high\nlevel of cross labelling in the previous experiment,\n4. re-train and test.\n5.2 Employment of Further Classi\ufb01ers\nFurther improvement can be envisioned by integrating more classi\ufb01ers into the\ndecision process. For instance consider the following classi\ufb01ers.\nExtended image classi\ufb01er: In the experiments described in this paper the\nimage classi\ufb01er looked at only the \ufb01rst page of the document. A variation\nor extension of this classi\ufb01er to look at di\ufb00erent pages of the document or\nseveral pages of the document will be necessary for a complete image anal-\nysis. This would however involve several decisions: given that documents\nhave di\ufb00erent lengths, the optimal number of pages to be used needs to be\ndetermined, and we need to examine the best way to combine the infor-\nmation from di\ufb00erent pages (e.g. will several pages be considered to be one\nimage; if not, how will the classi\ufb01cation of synchronised pages be statistically\ncombined to give a global classi\ufb01cation).\nLanguage model classi\ufb01er on the level of POS and phrases: This is a\nN-gram language model built on the part-of-speech tags of the undelying\ntext of the document and also on partial chunks resulting from detection of\nphrases.\nStylo-metric classi\ufb01er: This classi\ufb01er takes its cue from positioning of text\nand image blocks, font styles, font size, length of the document, average\nsentence lengths and word lengths. This classi\ufb01er is expected be useful for\nboth genre classi\ufb01cation (by distinguishing linguistically similar Thesis and\nScienti\ufb01c Research Article by say the length of the document) and other\nbibliographic data extraction (by detecting which strings are the Title and\nAuthor by font style, size and position).\nSemantic classi\ufb01er: This classi\ufb01er will combine extraction of keywords, sub-\njective or objective noun phrases (e.g. using [36]). This classi\ufb01er is expected\nto play an important role in the summarisation stage if not already in the\ngenre classi\ufb01cation stage.72 Y. Kim and S. Ross\nClassi\ufb01er based on external information: When the source information of\nthe document is available, such features as name of the journal, subject\nor address of the webpage and anchor texts can be gathered for statistical\nanalysis or rule-based classi\ufb01cation.\n5.3 Labelling More Data\nTo make any reasonable conclusions with this study, further data needs to be\nlabelled for fresh experiments and also to make up for the lack of training data.\nAlthough 60 genres are in play, only 40 genres had more than 3 items in the set\nand only 27 genres had greater than or equal to 15 items available.\n6 Putting It into Context\nAssuming we are able build a reasonable extractor for genre, we will move on to\nimplementing the extraction of author, title, date, identi\ufb01er, keywords, language,\nsummarisations and other compositional properties within each speci\ufb01c genre.\nAfter this has been accomplished, we should augment the tool to handle subject\nclassi\ufb01cation and to cover other \ufb01le types.\nOnce the basic prototype for automatic semantic metadata extractionis tamed\ninto a reasonable shape, we will pass the protype to other colleagues in the\nDigital Curation Centre ([10]) to be integrated with other tools (e.g. technical\nmetadata extraction tools) and standardised frameworks (e.g. ingest or preserva-\ntion model) for the development of a larger scale ingest, selection and appraisal\napplication. Eventually, we should be able at least to semi-automate essential\nprocesses in this area.\nAcknowledgements\nThis research is being conducted as part of The Digital Curation Centre\u2019s (DCC)\n[10] research programme. The DCC is supported by a grant from the United\nKingdom\u2019s Joint Information Systems Committee (JISC) [22] and the e-Science\nCore Programme of the Engineering and Physical Sciences Research Council\n(EPSRC) [16]. The EPSRC grant (GR\/T07374\/01) provides the support for the\nresearch programme. Additional support for this research comes from the DE-\nLOS: Network of Excellence on Digital Libraries (G038-507618) funded under\nthe European Commission\u2019s IST 6th Framework Programme [12]. The authors\nwould like to thank their DCC colleague Adam Rusbridge whose work on ER-\nPANET\u2019s Packaged Object Ingest Project [18] provided a starting point for\nthe current project on automated metadata extraction. We are grateful to the\nanonymous ECDL reviewers of this paper who provided us with very helpful\ncomments, which enabled us to improve the paper.\nNote on website citations: All citations of websites were validated on 29 May\n2006.Genre Classi\ufb01cation in Automated Ingest and Appraisal Metadata 73\nReferences\n1. Aiello, M., Monz, C., Todoran, L., Worring, M.: Document Understanding for\na Broad Class of Documents. International Journal on Document Analysis and\nRecognition 5(1) (2002) 1\u201316.\n2. Automatic Metadata Generation: http:\/\/www.cs.kuleuven.ac.be\/ \u02dc hmdb\/amg \/doc-\numentation.php\n3. Arens,A., Blaesius, K. H.: Domain oriented information extraction from the In-\nternet. Proceedings of SPIE Document Recognition and Retrieval 2003 Vol 5010\n(2003) 286.\n4. Bagdanov, A. D., Worring, M.: Fine-Grained Document Genre Classi\ufb01cation Using\nFirst Order Random Graphs. Proceedings of International Conference on Docu-\nment Analysis and Recognition 2001 (2001) 79.\n5. Barbu, E., Heroux, P., Adam, S., Trupin, E.: Clustering Document Images Using\na Bag of Symbols Representation. International Conference on Document Analysis\nand Recognition, (2005) 1216\u20131220.\n6. Bekkerman, R., McCallum, A., Huang, G.: Automatic Categorization of Email\ninto Folders. Benchmark Experiments on Enron and SRI Corpora\u2019, CIIR Technical\nReport, IR-418 (2004).\n7. Biber, D.: Dimensions of Register Variation:a Cross-Linguistic Comparison. Cam-\nbridge University Press (1995).\n8. Boese, E. S.: Stereotyping the web: genre classi\ufb01cation of web documents. Master\u2019s\nthesis, Colorado State University (2005).\n9. Breuel, T. M.: An Algorithm for Finding Maximal Whitespace Rectangles at Ar-\nbitrary Orientations for Document Layout Analysis. 7th International Conference\nfor Document Analysis and Recognition (ICDAR), 66\u201370 (2003).\n10. Digital Curation Centre: http:\/\/www.dcc.ac.uk\n11. DC-dot, Dublin Core metadata editor: http:\/\/www.ukoln.ac.uk\/metadata\/dcdot\/\n12. DELOS Network of Excellence on Digital Libraries: http:\/\/www.delos.info\/\n13. NSF International Projects: http:\/\/www.dli2.nsf.gov\/ intl.html\n14. DELOS\/NSF Working Groups: Reference Models for Digital Libraries: Ac-\ntors and Roles (2003) http:\/\/www.dli2.nsf.gov \/internationalprojects\/ work-\ning group reports\/ actors \ufb01nal report.html\n15. Dublin Core Initiative: http:\/\/dublincore.org\/tools\/#automaticextraction\n16. Engineering and Physical Sciences Research Council: http:\/\/www.epsrc.ac.uk\/\n17. Electronic Resources Preservation Access Network (ERPANET): http:\/\/\nwww.erpanet.org\n18. ERPANET: Packaged Object Ingest Project. http:\/\/www.erpanet.org\/events\/\n2003\/rome\/presentations\/ ross rusbridge pres.pdf\n19. Giu\ufb00rida, G., Shek, E. Yang, J.: Knowledge-based Metadata Extraction from\nPostScript File. Proc. 5th ACM Intl. conf. Digital Libraries (2000) 77\u201384.\n20. Han, H., Giles, L., Manavoglu, E., Zha, H., Zhang, Z., Fox, E. A.: Automatic Docu-\nment Metadata Extraction using Support Vector Machines. Proc. 3rd ACM\/IEEE-\nCS conf. Digital libraries (2000) 37\u201348.\n21. Hedstrom, M., Ross, S., Ashley, K., Christensen-Dalsgaard, B., Du\ufb00, W.,\nGladney, H., Huc, C., Kenney, A. R., Moore, R., Neuhold, E.: Invest to Save:\nReport and Recommendations of the NSF-DELOS Working Group on Digital\nArchiving and Preservation. Report of the European Union DELOS and US\nNational Science Foundation Workgroup on Digital Preservation and Archiv-\ning (2003) http:\/\/delos-noe.iei.pi.cnr.it\/activities\/internationalforum\/Joint-\nWGs\/digitalarchiving\/Digitalarchiving.pdf.74 Y. Kim and S. Ross\n22. Joint Information Systems Committee: http:\/\/www.jisc.ac.uk\/\n23. Karlgren, J. and Cutting, D.: Recognizing Text Genres with Simple Metric using\nDiscriminant Analysis. Proc. 15th conf. Comp. Ling. Vol 2 (1994) 1071\u20131075.\n2 4 . K e ,S .W . ,B o w e r m a n ,C .O a k e s ,M .P E R C :AP e r s o n a lE m a i lC l a s s i \ufb01 e r .P r o c e e d -\nings of 28th European Conference on Information Retrieval (ECIR 2006) 460\u2013463.\n25. Kessler, B., Nunberg, G., Schuetze, H.: Automatic Detection of Text Genre. Proc.\n35th Ann. Meeting ACL (1997) 32\u201338.\n26. Zhang Le: Maximum Entropy Toolkit for Python and C++. LGPL license,\nhttp:\/\/homepages.inf.ed.ac.uk\/s0450736\/maxent toolkit.html\n27. MetadataExtractor: http:\/\/pami-xeon.uwaterloo.ca\/TextMiner\/ MetadataExtrac-\ntor.aspx\n28. McCallum, A.: Bow: A Toolkit for Statistical Language Modeling, Text Retrieval,\nClassi\ufb01cation and Clustering. (1998) http:\/\/www.cs.cmu.edu\/ mccallum\/bow\/\n29. National Archives UK: DROID (Digital Object Identi\ufb01cation). http: \/\/www. na-\ntionalarchives. gov.uk\/ aboutapps\/pronom\/droid.htm\n30. Natinal Library of Medicine US: http:\/\/www.nlm.nih.gov\/\n31. National Library of New Zealand: Metadata Extraction Tool. http:\/\/www. natlib.\ngovt.nz\/en\/whatsnew\/4initiatives.html#extraction\n32. Adobe Acrobat PDF speci\ufb01cation: http:\/\/partners.adobe.com\/ public\/developer\/\npdf\/index reference.html\n33. Python Imaging Library: http:\/\/www.pythonware.com\/products\/pil\/\n34. PREMIS (PREservation Metadata: Implementation Strategy) Working Group:\nhttp:\/\/www.oclc.org\/research\/projects\/pmwg\/\n35. Python: http:\/\/www.python.org\n36. Rilo\ufb00, E., Wiebe, J., and Wilson, T.: Learning Subjective Nouns using Extraction\nPattern Bootstrapping. Proc. 7th CoNLL, (2003) 25\u201332.\n37. Ross S and Hedstrom M.: Preservation Research and Sustainable Digital Libraries.\nInternational Journal of Digital Libraries (Springer) (2005) DOI: 10.1007\/s00799-\n004-0099-3.\n38. Santini, M.: A Shallow Approach To Syntactic Feature Extraction For Genre Clas-\nsi\ufb01cation. Proceedings of the 7th Annual Colloquium for the UK Special Interest\nGroup for Computational Linguistics (CLUK 04) (2004).\n39. Sebastiani F.: \u2019Machine Learning in Automated Text Categorization\u2019, ACM Com-\nputing Surveys, Vol. 34 (2002) 1-47\n40. Faisal Shafait, Daniel Keysers, Thomas M. Breuel, \u201cPerformance Comparison of Six\nAlgorithms for Page Segmentation\u201d, 7th IAPR Workshop on Document Analysis\nSystems (DAS) (2006).368\u2013379.\n41. M. Shao, M. and Futrelle, R.: Graphics Recognition in PDF document. Sixth IAPR\nInternational Workshop on Graphics Recognition (GREC2005), 218\u2013227.\n42. Thoma,G.: Automating the production of bibliographic records. R&D report of the\nCommunications Engineering Branch, Lister Hill National Center for Biomedical\nCommunications, National Library of Medicine, 2001.\n43. Witte, R., Krestel, R. and Bergler, S.: ERSS 2005:Coreference-based Summariza-\ntion Reloaded. DUC 2005 Document Understanding Workshop, Canada"}
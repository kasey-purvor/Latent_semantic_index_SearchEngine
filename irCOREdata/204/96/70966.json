{"doi":"10.1093\/biomet","coreId":"70966","oai":"oai:eprints.lancs.ac.uk:8844","identifiers":["oai:eprints.lancs.ac.uk:8844","10.1093\/biomet"],"title":"A sequential smoothing algorithm with linear computational cost.","authors":["Fearnhead, Paul","Wyncoll, David","Tawn, Jonathan"],"enrichments":{"references":[{"id":16374998,"title":"A new approach to linear \ufb01ltering and prediction problems.","authors":[],"date":"1960","doi":"10.1115\/1.3662552","raw":"Kalman, R. E. (1960). A new approach to linear \ufb01ltering and prediction problems. Journal of Basic Engineering, 82(1):35\u201345.","cites":null},{"id":16375031,"title":"A Non-Gaussian State Space Model and Application to Prediction of Records.","authors":[],"date":"1986","doi":null,"raw":"Smith, R. L. and Miller, J. E. (1986). A Non-Gaussian State Space Model and Application to Prediction of Records. Journal of the Royal Statistical Society. Series B (Methodological), 48(1):79\u201388.","cites":null},{"id":16375005,"title":"A Smoothness Priors Time-Varying AR Coe\ufb03cient Modeling of Nonstationary Covariance Time Series.","authors":[],"date":"1985","doi":"10.1109\/tac.1985.1103788","raw":"Kitagawa, G. and Gersch, W. (1985). A Smoothness Priors Time-Varying AR Coe\ufb03cient Modeling of Nonstationary Covariance Time Series. IEEE Transactions on Automatic Control, 30(1):48\u201356.","cites":null},{"id":16374963,"title":"An Introduction to Statistical Modeling of Extreme Values.","authors":[],"date":"2001","doi":"10.1007\/978-1-4471-3675-0","raw":"Coles, S. (2001). An Introduction to Statistical Modeling of Extreme Values. Springer, London.","cites":null},{"id":16375011,"title":"Blind Deconvolution Via Sequential Imputations.","authors":[],"date":"1995","doi":"10.2307\/2291068","raw":"Liu, J. S. and Chen, R. (1995). Blind Deconvolution Via Sequential Imputations. Journal of the American Statistical Association, 90(430):567\u2013576.","cites":null},{"id":16375016,"title":"Combined parameter and state estimation in simulation-based \ufb01ltering.","authors":[],"date":"2001","doi":"10.1007\/978-1-4757-3437-9_10","raw":"Liu, J. S. and West, M. (2001). Combined parameter and state estimation in simulation-based \ufb01ltering. In Doucet, A., de Freitas, N., and Gordon, N., editors, Sequential Monte Carlo Methods in Practice, pages 197\u2013224. Springer.","cites":null},{"id":16375027,"title":"Comment on \u201cStatistics for Exceptional Athletics Records\u201d, by","authors":[],"date":"1997","doi":"10.1111\/1467-9876.00051","raw":"Smith, R. L. (1997). Comment on \u201cStatistics for Exceptional Athletics Records\u201d, by Robinson, M. E. and Tawn, J. A. Applied Statistics, 46(1):123\u2013128.","cites":null},{"id":16374982,"title":"Computational Methods for Complex Stochastic Systems: A Review of Some Alternatives to MCMC.","authors":[],"date":"2008","doi":"10.1007\/s11222-007-9045-8","raw":"Fearnhead, P. (2008). Computational Methods for Complex Stochastic Systems: A Review of Some Alternatives to MCMC. To appear in Statistics and Computing.","cites":null},{"id":16374977,"title":"E\ufb03cient Block Sampling Strategies for Sequential Monte Carlo Methods.","authors":[],"date":"2006","doi":"10.1198\/106186006x142744","raw":"Doucet, A., Briers, M., and S\u00b4 en\u00b4 ecal, S. (2006). E\ufb03cient Block Sampling Strategies for Sequential Monte Carlo Methods. Journal of Computational and Graphical Statistics, 15(3):693\u2013711.","cites":null},{"id":16375019,"title":"Filtering Via Simulation: Auxiliary Particle Filters.","authors":[],"date":"1999","doi":"10.2307\/2670179","raw":"Pitt, M. K. and Shephard, N. (1999). Filtering Via Simulation: Auxiliary Particle Filters. Journal of the American Statistical Association, 94(446):590\u2013 599.","cites":null},{"id":16374960,"title":"Improved particle \ufb01lter for nonlinear problems.","authors":[],"date":"1999","doi":"10.1049\/ip-rsn:19990255","raw":"Carpenter, J., Cli\ufb00ord, P., and Fearnhead, P. (1999). Improved particle \ufb01lter for nonlinear problems. IEE Proceedings\u2013Radar, Sonar and Navigation, 146(1):2\u2013 7. Casella, G. and Robert, C. P. (2001). Rao-Blackwellisation of sampling schemes. Biometrika, 83(1):81\u201394.","cites":null},{"id":16375008,"title":"last accessed 22","authors":[],"date":"2008","doi":null,"raw":"alltime-athletics.com\/. [last accessed 22 April 2008].","cites":null},{"id":16374976,"title":"Maximum Likelihood from Incomplete Data via the EM Algorithm.","authors":[],"date":"1977","doi":null,"raw":"Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum Likelihood from Incomplete Data via the EM Algorithm. Journal of the Royal Statistical Society. Series B (Methodological), 39(1):1\u201338.","cites":null},{"id":16374994,"title":"Monte Carlo Approximations for General State-Space Models.","authors":[],"date":"1998","doi":null,"raw":"H\u00a8 urzeler, M. and K\u00a8 unsch, H. R. (1998). Monte Carlo Approximations for General State-Space Models. Journal of Computational and Graphical Statistics, 7(2):175\u2013193.","cites":null},{"id":16375001,"title":"Monte Carlo Filter and Smoother for Non-Gaussian Nonlinear State Space Models.","authors":[],"date":"1996","doi":"10.2307\/1390750","raw":"Kitagawa, G. (1996). Monte Carlo Filter and Smoother for Non-Gaussian Nonlinear State Space Models. Journal of Computational and Graphical Statistics, 5(1):1\u201325.","cites":null},{"id":16374989,"title":"Monte Carlo Smoothing for Nonlinear Time Series.","authors":[],"date":"2004","doi":"10.1198\/016214504000000151","raw":"Godsill, S. J., Doucet, A., and West, M. (2004). Monte Carlo Smoothing for Nonlinear Time Series. Journal of the American Statistical Association, 99(465):156\u2013169.","cites":null},{"id":16374990,"title":"Novel approach to nonlinear\/non-Gaussian Bayesian state estimation.","authors":[],"date":"1993","doi":"10.1049\/ip-f-2.1993.0015","raw":"23Gordon, N. J., Salmond, D. J., and Smith, A. F. M. (1993). Novel approach to nonlinear\/non-Gaussian Bayesian state estimation. Radar and Signal Processing, IEE Proceedings F, 140(2):107\u2013113.","cites":null},{"id":16374978,"title":"On sequential Monte Carlo sampling methods for Bayesian \ufb01ltering.","authors":[],"date":"2000","doi":"10.1007\/978-1-4757-3437-9_4","raw":"Doucet, A., Godsill, S., and Andrieu, C. (2000). On sequential Monte Carlo sampling methods for Bayesian \ufb01ltering. Statistics and Computing, 10(3):197\u2013 208.","cites":null},{"id":16374953,"title":"Optimal \ufb01ltering. Prentice-Hall Englewood Cli\ufb00s,","authors":[],"date":"1979","doi":"10.1177\/002194367901600208","raw":"Anderson, B. D. O. and Moore, J. B. (1979). Optimal \ufb01ltering. Prentice-Hall Englewood Cli\ufb00s, New Jersey.","cites":null},{"id":16375034,"title":"Prediction, Filtering and Smoothing in Non-Linear and Non-Normal Cases Using Monte Carlo Integration.","authors":[],"date":"1994","doi":"10.1002\/jae.3950090204","raw":"Tanizaki, H. and Mariano, R. S. (1994). Prediction, Filtering and Smoothing in Non-Linear and Non-Normal Cases Using Monte Carlo Integration. Journal of Applied Econometrics, 9(2):163\u2013179.","cites":null},{"id":16375014,"title":"Sequential Monte Carlo Methods for Dynamic Systems.","authors":[],"date":"1998","doi":"10.2307\/2669847","raw":"Liu, J. S. and Chen, R. (1998). Sequential Monte Carlo Methods for Dynamic Systems. Journal of the American Statistical Association, 93(443):1032\u20131044.","cites":null},{"id":16374956,"title":"Smoothing algorithms for statespace models.","authors":[],"date":"2004","doi":"10.1007\/s10463-009-0236-2","raw":"Briers, M., Doucet, A., and Maskell, S. (2004). Smoothing algorithms for statespace models. Submitted to IEEE Transactions on Signal Processing.","cites":null},{"id":16374985,"title":"Smoothing Sample Extremes with Dynamic Models.","authors":[],"date":"2004","doi":"10.1007\/s10687-005-6474-7","raw":"Gaetan, C. and Grigoletto, M. (2004). Smoothing Sample Extremes with Dynamic Models. Extremes, 7(3):221\u2013236.","cites":null},{"id":16375020,"title":"Statistics for Exceptional Athletics Records.","authors":[],"date":"1995","doi":"10.2307\/2986141","raw":"Robinson, M. E. and Tawn, J. A. (1995). Statistics for Exceptional Athletics Records. Applied Statistics, 44(4):499\u2013511.","cites":null},{"id":16374980,"title":"Using random Quasi-Monte Carlo within particle \ufb01lters, with application to \ufb01nancial time series.","authors":[],"date":"2005","doi":"10.1198\/106186005x77243","raw":"Fearnhead, P. (2005). Using random Quasi-Monte Carlo within particle \ufb01lters, with application to \ufb01nancial time series. Journal of Computational and Graphical Statistics, 14:751\u2013769.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-06","abstract":"In this paper we propose a new particle smoother that has a computational complexity of O(N), where N is the number of particles. This compares favourably with the O(N2) computational cost of most smoothers. The new method also overcomes some degeneracy problems in existing algorithms. Through simulation studies we show that substantial gains in efficiency are obtained for practical amounts of computational cost. It is shown both through these simulation studies, and by the analysis of an athletics dataset, that our new method also substantially outperforms the simple filter-smoother, the only other smoother with computational cost that is O(N)","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/70966.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/8844\/2\/smoothing.pdf","pdfHashValue":"42ff3a20486a9076d4d2eb1967e5c625dc9eace4","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:8844<\/identifier><datestamp>\n      2018-01-24T03:18:36Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        A sequential smoothing algorithm with linear computational cost.<\/dc:title><dc:creator>\n        Fearnhead, Paul<\/dc:creator><dc:creator>\n        Wyncoll, David<\/dc:creator><dc:creator>\n        Tawn, Jonathan<\/dc:creator><dc:subject>\n        QA Mathematics<\/dc:subject><dc:description>\n        In this paper we propose a new particle smoother that has a computational complexity of O(N), where N is the number of particles. This compares favourably with the O(N2) computational cost of most smoothers. The new method also overcomes some degeneracy problems in existing algorithms. Through simulation studies we show that substantial gains in efficiency are obtained for practical amounts of computational cost. It is shown both through these simulation studies, and by the analysis of an athletics dataset, that our new method also substantially outperforms the simple filter-smoother, the only other smoother with computational cost that is O(N).<\/dc:description><dc:date>\n        2010-06<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/8844\/2\/smoothing.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1093\/biomet\/asq013<\/dc:relation><dc:identifier>\n        Fearnhead, Paul and Wyncoll, David and Tawn, Jonathan (2010) A sequential smoothing algorithm with linear computational cost. Biometrika, 97 (2). pp. 447-464. ISSN 1464-3510<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/8844\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1093\/biomet\/asq013","http:\/\/eprints.lancs.ac.uk\/8844\/"],"year":2010,"topics":["QA Mathematics"],"subject":["Journal Article","PeerReviewed"],"fullText":"A Sequential Smoothing Algorithm with Linear\nComputational Cost\nPaul Fearnhead David Wyncoll Jonathan Tawn\nMay 9, 2008\nAbstract\nIn this paper we propose a new particle smoother that has a computa-\ntional complexity of O(N), where N is the number of particles. This com-\npares favourably with the O(N2) computational cost of most smoothers\nand will result in faster rates of convergence for fixed computational cost.\nThe new method also overcomes some of the degeneracy problems we\nidentify in many existing algorithms.\nThrough simulation studies we show that substantial gains in efficiency\nare obtained for practical amounts of computational cost. It is shown both\nthrough these simulation studies, and on the analysis of an athletics data\nset, that our new method also substantially outperforms the simple Filter-\nSmoother (the only other smoother with computational cost that is linear\nin the number of particles).\n1 Introduction\nState space models provide a flexible framework to handle non-linear time series.\nThese models assume a time-series with observations Yt that are conditionally\nindependent given a hidden Markov process Xt. Formally the model is given\nby a state equation and an observation equation, which can be represented in\nterms of conditional distributions\nXt+1|{X1:t = x1:t, Y1:t = y1:t} \u223c f(\u00b7|xt),\nYt|{X1:t = x1:t, Y1:t\u22121 = y1:t\u22121} \u223c g(\u00b7|xt),\nwhere we use the notation that x1:t = (x1, . . . , xt), and similarly for y1:t. The\nmodel is completed through specifying an initial distribution for X0.\nWhen the observations are arriving sequentially we are often interested in\nthe current value of the state Xt given all the available data. For this filtering\nproblem, interest lies in estimating the posterior distribution p(xt|y1:t). Sequen-\ntial Monte Carlo algorithms, known generically as particle filters, have recently\nemerged as a solution to this problem. These filters approximate p(xt|y1:t) by\na set of N weighted particles; and are based on steps for sequentially producing\na set of weighted particles that approximate p(xt|y1:t) given a set that approx-\nimates p(xt\u22121|y1:t\u22121). In their simplest form these algorithms produce equally\nweighted particles, and the particles can be viewed as an approximate sample\nfrom p(xt|y1:t) (see Gordon et al. (1993) or Kitagawa (1996)). The computa-\ntional complexity of particle filters is usually linear in the number of particles,\n1\nN , and as such large numbers of them can be chosen to best approximate the\ntarget posterior.\nOur interest in this paper lies in the related smoothing problem whose aim\nis to obtain estimates of previous states given a block of observations y1, . . . , yT .\nWhile this problem can be theoretically solved with a slight modification of the\nparticle filter (see Kitagawa (1996)), it is easy to show that this produces a\npoor approximation of the smoothing density p(xt|y1:T ) for t \u001c T . With this\nin mind, alternative algorithms to sequentially approximate p(xt|y1:T ) after a\nparticle filter have been developed (see for example Kitagawa (1996), Hu\u00a8rzeler\nand Ku\u00a8nsch (1998), Doucet et al. (2000), Godsill et al. (2004) and Briers et al.\n(2004)). All these methods involve a step to re-weight particles that approximate\na filter distribution so that the re-weighted particles approximate p(xt|y1:T ).\nWhile they perform comparably well for a fixed number of particles, N , these\nalgorithms have a complexity of O(N2) and therefore their use is restricted to\nsmaller N than is used for particle filtering. Also, for some state-space models,\nparticularly those for which a component of Xt is uniquely determined by the\nprevious state, xt\u22121, these alternative smoothing algorithms can degenerate;\neither they become equivalent to the O(N) smoother of Kitagawa (1996) or\ncannot be applied at all.\nWe present a new smoothing algorithm. The basic idea is to allow the\nsmoother to simulate new particles which will be used to approximate p(xt|y1:T ),\nrather than just re-weighting existing particles. This approach avoids some\nof the degeneracy issues of existing particle smoothers. However, the most\nimportant feature of our new smoothing algorithm is that there is a set of models\nfor which the computational complexity is linear in the number of particles. This\nset includes all models with a linear-Gaussian state equation, and all models for\nwhich the likelihood, g(yt|xt) is integrable in xt. This covers a wide-variety of\nmodels such as the bearings-only tracking model (Gordon et al., 1993), factor\nstochastic volatility models (Liu and West, 2001), time varying auto-regressive\ncoefficient models (Kitagawa and Gersch, 1985) and ARCH models (Fearnhead,\n2005) amongst many others.\nOur work itself was motivated by problems of non-stationarity when mod-\nelling the extremes of a time-series. For example, in Section 5, we consider data\non the fastest times for the women\u2019s 3000m (see Figure 4). Whilst up to 1982\nthere is evidence of a year-on-year improvement in times for this event, since\n1982 times have plateaued \u2013 if anything times worsened in the latter half of the\n1980s, perhaps due to increased regulation and testing for the use of perfor-\nmance enhancing drugs. It is natural to model the data from each year using\na distribution which is motivated by asymptotic extreme value theory; and we\nincorporate non-stationarity into this distribution through allowing its location\nparameter to vary in a non-parametric way. We can thus obtain a state-space\nmodel for the data, where the state is the location parameter. Standard non-\nparametric models, such as random walks and integrated random walks, can\nbe formulated as linear-Gaussian models for the location parameter. See Smith\nand Miller (1986) for an example of state space models being used to analyse\nathletics records.\nThe article is organised as follows. We begin Section 2 by describing parti-\ncle filtering and go on to review the current methods for sequential smoothing\nwhile demonstating their flaws. In Section 3 we derive our new algorithm which\nattempts to overcome these. Section 4 contains a simulation study with a mul-\n2\ntivariate Normal model, which shows the substantial improvements our new\nsmoother gives for models with a linear-Gaussian state equation. Section 5\ncompares relative efficiencies of the methods at analysing the athletics dataset,\nand addresses the question as to how extreme the 1993 world record of Wang\nJunxia was. To analyse these data, we develop an efficient EM algorithm that\nutilises our new smoother, to estimate fixed parameters in the extreme value\ndistribution. Our analysis suggests that a new world record as or more extreme\nas that of Wang Junxia\u2019s would happen less than once every 5000 years from\nthe evidence about the population of the other top athletes in this event.\n2 Current methods for particle smoothing\n2.1 Particle filtering\nThe aim of Bayesian filtering is to calculate sequentially the filter distributions\np(xt|y1:t) upon receipt of observations yt. The analytical solution to this prob-\nlem is given by\np(xt|y1:t) \u221d g(yt|xt)\n\u222b\nf(xt|xt\u22121)p(xt\u22121|y1:t\u22121) dxt\u22121, (1)\nwhich relates p(xt|y1:t) to p(xt\u22121|y1:t\u22121) and yt. This recursion is intractable in\ngeneral, although an important exception to this is when both the state f and\nthe likelihood g are linear-Gaussian densities and the prior is also Gaussian. In\nthis case the solution is given by the Kalman filter recursions of Kalman (1960).\nParticle filters aim to overcome the intractability of (1) by using potential\ndraws of the state to approximate the unknown filter distributions. In general,\nwe approximate the distribution p(xt|y1:t) by a discrete distribution with sup-\nport {x(i)t }Ni=1 and probability masses {w(i)t }Ni=1. Applying this to p(xt\u22121|y1:t\u22121)\nin (1) gives the approximation\np(xt|y1:t) ' cg(yt|xt)\nN\u2211\ni=1\nf(xt|x(i)t\u22121)w(i)t\u22121, (2)\nwhere c is a normalising constant. A particle filter algorithm gives steps for\nproducing weighted particles to approximate this. For reviews of various filter-\ning methods see for example Liu and Chen (1998), Doucet et al. (2000) and\nFearnhead (2008).\nWe focus our attention on the auxiliary particle filter of Pitt and Shephard\n(1999). This is a general method through which many simpler particle filters\ncan be defined as special cases. In this approach we aim to approximate\ncg(yt|xt)f(xt|x(i)t\u22121)w(i)t\u22121 (3)\nby\nq(xt|x(i)t\u22121, yt)\u03b2(i)t ,\nwhere q(\u00b7|x(i)t\u22121, yt) is a distribution we can sample from and {\u03b2(i)t }Ni=1 are nor-\nmalised weights which sum to 1. We then use a combination of re-sampling and\nimportance sampling to generate a weighted sample approximating (2).\n3\nAlgorithm 1 gives the general algorithm for sequentially sampling weighted\nparticles {(x(i)t , w(i)t )} approximating p(xt|y1:t). While the simplest way to ini-\ntialise the algorithm is to sample from the prior p(x0) and propagate from t = 1,\nit is usually possible and more accurate to sample from p(x1|y1) directly using\nstandard importance sampling.\nAlgorithm 1 Auxiliary particle filter of Pitt and Shephard (1999)\n1. Initialisation: Sample {x(i)0 } from the prior p(x0) and set w(i)0 = 1\/N\nfor all i.\n2. For t = 1, 2, . . .\n(a) Re-sample: Use the {\u03b2(i)t } as probabilities to sample N indices\nj1, ..., jN from {1, ..., N}.\n(b) Propagate: Sample the new particles x(i)t independently from\nq(\u00b7|x(ji)t\u22121, yt).\n(c) Re-weight: Assign each particle x(i)t the corresponding importance\nweight\nw\n(i)\nt \u221d\ng(yt|x(i)t )f(x(i)t |x(ji)t\u22121)w(ji)t\u22121\nq(x(i)t |x(ji)t\u22121, yt)\u03b2(ji)t\nand normalise them to sum to 1.\nThe efficiency of the particle filter rests primarily on the choice of proposal\ndensity q and re-sampling weights \u03b2(i)t . In the simplest case we could have\nq(xt|xt\u22121, yt) = f(xt|xt\u22121) and \u03b2(i)t = w(i)t\u22121 which is essentially the algorithm of\nGordon et al. (1993). Such a choice would place mass unevenly on the particles\nthus wasting those with small weights. To rectify this the auxiliary approach\nproduces more even weights if q and \u03b2(i)t are chosen so that (3) is well approxi-\nmated. In particular if q(xt|x(i)t\u22121, yt) = p(xt|x(i)t\u22121, yt) and \u03b2(i)t \u221d p(yt|x(i)t\u22121)w(i)t\u22121\nthen the final weights w(i)t will all equal 1\/N and we say the filter is adapted.\nIn most cases this optimal choice of q and \u03b2(i)t is not possible, but we can still\nobtain and use good approximations to them.\nMany authors have suggested further enhancements to the standard particle\nfilter. The re-sampling step is optional and can be omitted by setting ji =\ni thus propagating each particle x(i)t\u22121 once. This eliminates any extra noise\nfrom re-sampling but gives uneven weights. Liu and Chen (1995) propose a\nmeasure of the effective sample size and resample only when it falls below a\nfixed threshold. Carpenter et al. (1999) show that the re-sampling noise is\nminimised by producing a stratified sample of the indices ji and give an O(N)\nalgorithm to achieve this.\nA further enhancement which takes advantage of the linear-Gaussian state is\nRao-Blackwellisation; see Casella and Robert (2001) for an introduction to the\ntopic and Doucet et al. (2000) for an application to particle filtering. The idea is\nthat for some models it is possible to integrate out part of the state analytically.\nThis enables the integrable part of the state to be represented by a distribution\n4\nrather than a specific value. The advantage of Rao-Blackwellisation is that less\nMonte Carlo error is accrued in each update and so the variance of estimates\nis reduced. An example of the application of Rao-Blackwellisation is given in\nSection 5.\n2.2 Smoothing while filtering\nIn its simplest form, smoothing can be achieved from a simple extension to the\nparticle filter as shown by Kitagawa (1996), and we call the resulting algorithm\nthe Filter-Smoother. As with the filter distribution p(xt|y1:t) in (1), we have a\nrecursive solution for the joint smoothing distribution:\np(x1:t|y1:t) \u221d g(yt|xt)f(xt|xt\u22121)p(x1:t\u22121|y1:t\u22121). (4)\nBy comparing (1) and (4) it is easy to show that the particle filter steps can\nbe used to update weighted paths {(x(i)1:t, w(i)t )}Ni=1 approximating p(x1:t|y1:t).\nDoing so simply requires keeping track of the inheritance of the newly sampled\nparticle x(i)t by setting x\n(i)\n1:t = (x\n(ji)\n1:t\u22121, x\n(i)\nt ). This means that any filtering algo-\nrithm can be used and the method inherits the O(N) computational complexity\nof the filter making large numbers of particles feasible.\nWhile this Filter-Smoother approach can produce an accurate approximation\nof the filtering distribution p(xt|y1:t) it gives a poor representation of previous\nstates. To see this we note that whenever we resample the paths {x(i)1:t\u22121} by\nsampling the auxiliary variables {ji} we end up with multiple copies of some\npaths but lose others altogether. Therefore the number of distinct particles at\nany given time decreases monotonically the more times we resample. Also, with\nmultiple copies of some particles, their weights are effectively added together on\na single point so that marginally the weights become more uneven as we look\nback in time.\nl\nl\nl\nl\nl\nl\nl\nl\nl\n1 2 3 4 5 6\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nFigure 1: Plot showing how the simple smoother re-weights filter particles.\nThe arrows represent the dependencies between the particles at time t and t\u22121\ndue to re-sampling. The size of the particle represents its total weight as a draw\nfrom the smoothed distribution.\n5\nThis can be seen in Figure 1 which represents 10 smoothed paths x(i)1:6 showing\nhow they re-weight filter particles. As you can see, particles which are lost\ndue to re-sampling receive no weight and particles with many offspring have\nlarge weights. While the filter approximation at time 6 is good, the weights\nbecome more uneven as the number of weighted particles decreases going back\nin time. This is not surprising since the particles at times t < 6 are drawn to\napproximate p(xt|y1:t) so must be unevenly weighted if they are to represent a\ndifferent distribution.\nAs a final point we note that re-sampling more infrequently can improve\nthis method of smoothing although there is a limit to how much this can help.\nEven with no re-sampling, the approximation to p(xt|y1:T ) will deteriorate as\nT \u2212 t gets large: with the particle approximation tending to give non-negligible\nweight to all but a small subset of particles, and eventually only one particle\nhaving a non-negligible weight.\n2.3 Other smoothing algorithms\nSeveral algorithms have been proposed to improve on the simple Filter-Smoother.\nA common requirement is that a particle filter is run first to give weighted par-\nticles {(x(i)t , w(i)t )}Ni=1 approximating p(xt|y1:t) for t = 1, . . . , T .\n2.3.1 Forward-Backward smoothing\nThe Forward-Backward Smoother of Doucet et al. (2000), as well as the related\nalgorithms of Tanizaki and Mariano (1994) and Hu\u00a8rzeler and Ku\u00a8nsch (1998), is\nbased around the backwards recursion\np(xt|y1:T ) = p(xt|y1:t)\n\u222b\nf(xt+1|xt)\np(xt+1|y1:t)p(xt+1|y1:T ) dxt+1, for t < T .\nThe unknown densities can be approximated using filter particles from the cur-\nrent time t and smoother particles from t+ 1 to obtain\np(xt|y1:T ) '\nN\u2211\ni=1\n\u03b4(xt \u2212 x(i)t )w(i)t|T ,\nwhere\nw\n(i)\nt|T :=\nN\u2211\nj=1\nf(x(j)t+1|T |x(i)t )w(i)t\u2211N\nk=1 f(x\n(j)\nt+1|T |x(k)t )w(k)t\nw\n(j)\nt+1|T (5)\nand \u03b4(\u00b7) is the Dirac delta function. This approximation can be used to sequen-\ntially re-weight the filter particles backwards in time so that they represent the\nmarginal smoothing densities.\n2.3.2 Two-Filter smoothing\nThe Two-Filter Smoother of Briers et al. (2004) combines samples from a par-\nticle filter with those from a backwards information filter to produce estimates\nof p(xt|y1:T ).\n6\nThe backwards information filter produces sequential approximations of the\nlikelihood p(yt:T |xt) backwards through time and is based on the following re-\ncursion:\np(yt:T |xt) = g(yt|xt)\n\u222b\nf(xt+1|xt)p(yt+1:T |xt+1) dxt+1, for t < T . (6)\nSince p(yt:T |xt) is not a probability density function in xt it may not have a\nfinite integral over xt in which case a particle representation will not work.\nThe smoothing algorithm in Kitagawa (1996) assumes implicitly that this is\nnot the case but Briers et al. (2004) propose the following construction which\nwill always give a finite measure. They introduce an artificial prior distribution\n\u03b30(x0) which, when substituted for p(x0), yields a backwards filter density\np\u02dc(xt|yt:T ) \u221d \u03b3t(xt)p(yt:T |xt), (7)\nwhere \u03b3t(xt) =\n\u222b\nf(xt|xt\u22121)\u03b3t\u22121(xt\u22121) dxt\u22121 is derived recursively from \u03b30(x0).\nAn artificial prior is introduced so that \u03b3t(xt) is available in closed form\nwhich is only possible when the state is linear-Gaussian. If the prior p(x0) is\nalso Gaussian then this can be used instead of \u03b30(x0). If however the state is not\nlinear-Gaussian but the likelihood g(yt|xt) is integrable, we can instead propa-\ngate a particle representation of p(yt:T |xt) by assuming \u03b3t(xt) \u2261 1 throughout\nthe following derivation.\nFollowing on from (6) the backwards filter is derived from\np\u02dc(xt|yt:T ) \u221d \u03b3t(xt)g(yt|xt)\n\u222b\nf(xt+1|xt) p\u02dc(xt+1|yt+1:T )\n\u03b3t+1(xt+1)\ndxt+1\n' \u03b3t(xt)g(yt|xt)\nN\u2211\nk=1\nf(x\u02dc(k)t+1|xt)\n\u03b3t+1(x\u02dc\n(k)\nt+1)\nw\u02dc\n(k)\nt+1,\nwhere the weighted particles {(x\u02dc(k)t+1, w\u02dc(k)t+1)} approximate p\u02dc(xt+1|yt+1:T ). This\nis very similar to the derivation of the forwards filter and as such many filtering\nalgorithms and enhancements can be modified for this purpose.\nFor example, an auxiliary backwards filter in the style of Pitt and Shephard\n(1999) can be made by finding a distribution q\u02dc(\u00b7|yt, x\u02dc(k)t+1) we can sample from\nsuch that\nq\u02dc(xt|yt, x\u02dc(k)t+1)\u03b2\u02dc(k)t ' \u03b3t(xt)g(yt|xt)f(x\u02dc(k)t+1|xt)\nw\u02dc\n(k)\nt+1\n\u03b3t+1(x\u02dc\n(k)\nt+1)\n.\nWe then proceed analogously to Algorithm 1 for t = T, ..., 1 after initialising the\nalgorithm with particles drawn from \u03b3T+1(xT+1). An adapted backwards filter\ngiving even weights w\u02dc(k)t = 1\/N is achieved with q\u02dc(xt|yt, x\u02dc(k)t+1) = p(xt|yt, x\u02dc(k)t+1)\nand \u03b2\u02dc(k)t \u221d p\u02dc(yt|x\u02dc(k)t+1)w\u02dc(k)t+1 where we again use p\u02dc to denote a distribution which\nuses \u03b30(x0) as the prior instead of p(x0).\nHaving run a forwards particle filter and a backwards information filter, it\nis possible to combine the two to estimate p(xt|y1:T ). The Two-Filter Smoother\nis based upon writing the target density as\np(xt|y1:T ) \u221d p(xt|y1:t\u22121) \u00b7 p(yt:T |xt)\n\u221d\n\u222b\nf(xt|xt\u22121)p(xt\u22121|y1:t\u22121) dxt\u22121 \u00b7 p\u02dc(xt|yt:T )\n\u03b3t(xt)\n.\n7\nTherefore filter particles {(x(j)t\u22121, w(j)t\u22121)} approximating p(xt\u22121|y1:t\u22121) and back-\nwards filter particles {(x\u02dc(k)t , w\u02dc(k)t )} approximating p\u02dc(xt|yt:T ) are used to obtain\np(xt|y1:T ) '\nN\u2211\nk=1\n\u03b4(xt \u2212 x\u02dc(k)t )w\u02dc(k)t|T ,\nwhere\nw\u02dc\n(k)\nt|T :\u221d\nw\u02dc\n(k)\nt\n\u03b3t(x\u02dc\n(k)\nt )\nN\u2211\nj=1\nf(x\u02dc(k)t |x(j)t\u22121)w(j)t\u22121. (8)\nThus particles from a forwards filter are used to re-weight those from a back-\nwards filter so that they represent the target distribution.\n2.4 Comparison of current particle smoothers\nBoth the Forward-Backward and Two-Filter smoothers aim to improve on the\nsimple Filter-Smoother by removing its dependence on the inheritance paths of\nthe particle filter. Forward-Backward smoothing does this by reweighting the\nfilter particles while Two-Filter smoothing re-weights particles sampled from a\nbackwards filter. However, both algorithms are O(N2) as the calculation of each\nparticle\u2019s weight is an O(N) operation1. Thus, while variants of these particle\nsmoothers produce better estimates for a fixed particle number N , far fewer\nparticles can be used for these algorithms than can for the Filter-Smoother in\na fixed amount of time.\nAnother advantage of the Filter-Smoother is that it gives draws of the joint\nsmoothing distribution p(x1:T |y1:T ) rather than only the marginal distributions.\nIt is possible to adapt the Forward-Backward Smoother to also draw samples\nfrom the joint smoothing distribution as shown in Hu\u00a8rzeler and Ku\u00a8nsch (1998)\nand Godsill et al. (2004). Their derivation is similar to that of the Forward-\nBackward Smoother above and as such share its complexity and are determined\nby the re-sampling of the filter. They therefore achieve better samples of the\njoint distribution than the Filter-Smoother for a fixed N but give a slightly\nworse representation of the marginal distributions than the Forward-Backward\nSmoother.\nSince the Forward-Backward Smoother and the Filter-Smoother rely on the\nsupport of filter particles we may expect them to approximate p(xt|y1:T ) best\nfor t close to T where the target is most similar to p(xt|y1:t). Likewise the Two-\nFilter Smoother may do best for small t when the backwards filter distribution\np\u02dc(xt|yt:T ) is likely to be closest to our target. However when there is a large\ndiscrepancy between these distributions the particles will be weighted very un-\nevenly as they will not be located in the right position to represent the smoothed\ndistribution. Ideally we would like an algorithm which samples particles in the\ncorrect position for the smoothed distribution.\n1The overall cost of calculating the weight (5) in the Forward-Backward Smoother is O(N)\nas each of the terms in the denominator need to be calculated only once and can then be\nstored\n8\n2.5 Degeneracy of the Forward-Backward and Two-Filter\nsmoothers\nAs a final point we note that the Forward-Backward and Two-Filter smoothers\u2019\nreliance on the form of the state density causes degeneracy problems with certain\nmodels and filters. Specifically, this happens whenever f(xt|xt\u22121) is zero or\napproximately so for most combinations of possible xt and xt\u22121. As an example,\nconsider the simple AR(2) process\nzt = \u03c61zt\u22121 + \u03c62zt\u22122 + \u000ft\nwith \u000ft \u223c N (0, \u03bd2). The model can be written as a two-dimensional Markov\nprocess by defining the state as xt = (xt,1, xt,2)\n\u2032\nwhere xt,1 = zt and xt,2 = zt\u22121.\nThis gives the state transition density\nf(xt|x\u02dct\u22121) = N (xt,1|\u03c61x\u02dct\u22121,1 + \u03c62x\u02dct\u22121,2, \u03bd2) \u03b4(xt,2 \u2212 x\u02dct\u22121,1),\nwhere we write N (z|\u00b5, \u03bd2) for the density of N (\u00b5, \u03bd2) evaluated at z. This\ndensity is zero whenever the second component of xt does not equal the first\ncomponent of x\u02dct\u22121. This means that for two sets of particles {x\u02dc(j)t\u22121} and {x(i)t },\nf(x(i)t |x\u02dc(j)t\u22121) is likely to be zero unless x(i)t was generated from x\u02dc(j)t\u22121.\nSince the Forward-Backward Smoother relies on comparing particles sampled\nfrom the filter at time t with those at time t+1, it can be shown that the weight\n(5) reduces to the effective weight given to each particle by the Filter-Smoother.\nHowever the situation is worse for Two-Filter smoothing which fails completely\nas the forwards and backwards filter particles were sampled independently. With\nprobability 1, no pairs of forwards and backwards filter particles match and so\nall the weights (8) will be zero.\n3 New smoothing algorithm\nWe now describe our new smoothing algorithm which attempts to overcome the\nweaknesses of the current methods. Our primary aim is to draw new parti-\ncles from the marginal smoothing densities directly rather than re-weight those\ndrawn from another distribution. We describe the basic idea first, and then\nlook at how the smoother can be implemented so that its computational cost is\nlinear in the number of particles.\nWe start with a similar derivation to the Two-Filter Smoother which gives\np(xt|y1:T ) \u221d p(xt|y1:t\u22121) \u00b7 g(yt|xt) \u00b7 p(yt+1:T |xt)\n\u221d\n\u222b\nf(xt|xt\u22121)p(xt\u22121|y1:t\u22121) dxt\u22121 \u00b7 g(yt|xt)\u00b7\u222b\nf(xt+1|xt) p\u02dc(xt+1|yt+1:T )\n\u03b3t+1(xt+1)\ndxt+1,\nwhere we use the artificial prior and backwards filter in (7) above. These inte-\ngrals can be approximated using weighted particles from a particle filter at time\nt\u2212 1 and from a backwards information filter at time t+ 1 to obtain\np(xt|y1:T ) ' c\nN\u2211\nj=1\nN\u2211\nk=1\nf(xt|x(j)t\u22121)w(j)t\u22121 \u00b7 g(yt|xt) \u00b7\nf(x\u02dc(k)t+1|xt)\n\u03b3t+1(x\u02dc\n(k)\nt+1)\nw\u02dc\n(k)\nt+1, (9)\n9\nwhere c is a normalising constant. Though this formula can be written as the\nproduct of two sums, we write it as a double sum to emphasise that there are N2\n(j, k) pairs. We also note that any filtering algorithm can be used to generate\n{x(j)t\u22121} and {x\u02dc(k)t+1} as long as the artificial prior \u03b3t+1(xt+1) here is the same one\nused to sample {(x\u02dc(k)t+1, w\u02dc(k)t+1)} in the backwards information filter. As before\nwe assume \u03b3t+1(xt+1) \u2261 1 throughout if the backwards filter approximates\np(yt+1:T |xt+1) instead of p\u02dc(xt+1|yt+1:T ).\nTo sample from this approximation we start by mirroring the auxiliary par-\nticle filter of Pitt and Shephard (1999) by finding a sampling distribution q\u00af and\nweights \u03b2\u00af(j,k)t such that\nq\u00af(xt|x(j)t\u22121, yt, x\u02dc(k)t+1)\u03b2\u00af(j,k)t ' f(xt|x(j)t\u22121)g(yt|xt)f(x\u02dc(k)t+1|xt)\nw\n(j)\nt\u22121w\u02dc\n(k)\nt+1\n\u03b3t+1(x\u02dc\n(k)\nt+1)\n.\nAlgorithm 2 gives the algorithm that results from using the \u03b2\u00af(j,k)t s to sample\n(j, k) pairs before using q\u00af to sample new particles x\u00af(i)t .\nAlgorithm 2 New O(N2) smoothing algorithm\n1. Filter forwards: Run a particle filter to generate {(x(j)t , w(j)t )} approxi-\nmating p(xt|y1:t) for t = 0, . . . , T .\n2. Filter backwards: Run a backwards information filter to generate\n{(x\u02dc(k)t , w\u02dc(k)t )} approximating p\u02dc(xt|yt:T ) \u221d \u03b3t(xt)p(yt:T |xt) for t = T, . . . , 2.\n3. Smooth: For t = 1, . . . , T \u2212 1\n(a) Re-sample: Calculate the \u03b2\u00af(j,k)t s and use them as probabilities to\nsample N pairs {(ji, ki)}Ni=1.\n(b) Propagate: Sample the new particles x\u00af(i)t independently from\nq\u00af(\u00b7|x(ji)t\u22121, yt, x\u02dc(ki)t+1).\n(c) Re-weight: Assign each particle x\u00af(i)t the weight\nw\u00af\n(i)\nt \u221d\nf(x\u00af(i)t |x(ji)t\u22121) g(yt|x\u00af(i)t ) f(x\u02dc(ki)t+1 |x\u00af(i)t )w(ji)t\u22121 w\u02dc(ki)t+1\nq\u00af(x\u00af(i)t |x(ji)t\u22121, yt, x\u02dc(ki)t+1) \u03b2\u00af(ji,ki)t \u03b3t+1(x\u02dc(ki)t+1)\nand normalise them to sum to 1.\nNote that the output of Algorithm 2 is a set of triples, (x(ji)t\u22121, x\u00af\n(i)\nt , x\u02dc\n(ki)\nt+1),\nwith associated weights, w\u00af(i)t . These can be viewed as a particle approxima-\ntion to p(xt\u22121:t+1|y1:T ). If our interest solely lies in the marginal p(xt|y1:T )\nwe just keep the particles, x\u00af(i)t , and their associated weights, w\u00af\n(i)\nt . We note\nfurther that the optimal choice of propagation density is q\u00af(xt|x(j)t\u22121, yt, x\u02dc(k)t+1) =\np(xt|x(j)t\u22121, yt, x\u02dc(k)t+1) while the optimal re-sampling probabilities are given by\n\u03b2\u00af\n(j,k)\nt \u221d\n\u222b\nf(xt|x(j)t\u22121)g(yt|xt)f(x\u02dc(k)t+1|xt) dxt\nw\n(j)\nt\u22121w\u02dc\n(k)\nt+1\n\u03b3t+1(x\u02dc\n(k)\nt+1)\n. (10)\n10\nWe do not require our algorithm to generate samples for time T since these are\navailable from the filter. Similarly, particles for time 1 are available from the\nbackwards filter if we use \u03b30(x0) = p(x0) for the artificial prior.\nAlgorithm 2 overcomes the degeneracy problem of the Forward-Backward\nand Two-Filter smoothers when there is a deterministic relationship between\nthe states at successive time-points, as demonstrated in Section 2.5 with the\nAR(2) model. Algorithm 2 will still have degeneracy problems where there is\na deterministic relationship between components of states separated by two or\nmore time-points. However it is simple, at least in theory, to extend our method\nso that we jointly sample a block (xt, . . . , xt+n) given filter particles {x(j)t\u22121} and\nbackwards filter particles {x\u02dc(k)t+n+1} (see Doucet et al. (2006) for an example of\nblock sampling in particle filters). By choosing n sufficiently large such that\nthere is not deterministic relationship between components of xt and xt+n, our\napproach to smoothing can then be applied in these cases.\nLike the Two-Filter Smoother in Section 2, our smoothing step is not se-\nquential and can be performed independently for each time t. Also, the compu-\ntational complexity of each step is O(N2) which is comparable with all but the\nsimplest Filter-Smoother. However, as it stands we have N2 \u03b2\u00af(j,k)t s to calculate\nmaking it O(N2) in memory also which could mean that it is impractical for\neven modest sample sizes.\n3.1 Making Algorithm 2 O(N)\nThe above smoothing algorithm has a computational cost that is O(N2), that\nis quadratic in the number of particles, due to the need to calculate N2 prob-\nabilities, \u03b2\u00af(j,k)t . A simple approach to reduce the computational cost of the\nsmoothing algorithm is to choose these probabilities so that they correspond\nto choosing particles at time t \u2212 1 and backward-filter particles at time t + 1\nindependently of each other. Our algorithm will then be O(N) in computational\ncomplexity as well as memory and as such will be much faster for large N .\nNow the optimal distribution from which to choose the particles at time t\u22121\nwill be the corresponding marginal distribution of the optimal probabilities for\n\u03b2\u00af\n(j,k)\nt , given in (10). Marginalising we get:\nN\u2211\nk=1\n\u03b2\u00af\n(j,k)\nt \u221d\nN\u2211\nk=1\n\u222b\nf(xt|x(j)t\u22121)g(yt|xt)f(x\u02dc(k)t+1|xt) dxt\nw\n(j)\nt\u22121w\u02dc\n(k)\nt+1\n\u03b3t+1(x\u02dc\n(k)\nt+1)\nN\u2192\u221e\u2212\u2212\u2212\u2212\u2192\n\u222b\u222b\nf(xt|x(j)t\u22121)g(yt|xt)f(xt+1|xt) dxt\nw\n(j)\nt\u22121p\u02dc(xt+1|yt+1:T )\n\u03b3t+1(xt+1)\ndxt+1\n\u221d p(yt:T |x(j)t\u22121)w(j)t\u22121.\nCalculating this analytically will be impossible, but it suggests two simple ap-\nproximations. The first is to sample particles at time t \u2212 1 according to their\nfiltering weights w(j)t\u22121. However a better approach will be to sample according\nto an approximation of p(yt|x(j)t\u22121)w(j)t\u22121, as it includes the information in the\nobservation at time t. Now, in performing the particle filter we used the auxil-\niary filter which sampled particle x(j)t\u22121 with a probability \u03b2\n(j)\nt which is chosen\nto be an approximation to p(yt|x(j)t\u22121)w(j)t\u22121. Thus we suggest using exactly the\n11\nsame probabilities to sample the particles within one iteration of our sampling\nalgorithm.\nBy similar calculations, it can be shown that we should optimally choose\nthe backward-filter particles at time t + 1 with probability proportional to\np\u02dc(y1:t|x\u02dc(k)t+1)w\u02dc(k)t+1. Again, we cannot calculate these exactly, but a simple idea is\nto use probabilities that approximate p\u02dc(yt|x\u02dc(k)t+1)w\u02dc(k)t+1. Thus we can simply use\nthe probabilities \u03b2\u02dc(k)t that were used in the backward filter, as these were chosen\nas to be an approximation to p\u02dc(yt|x\u02dc(k)t+1)w\u02dc(k)t+1.\nWe thus obtain a similar algorithm to before, but with particles at time\nt \u2212 1 and t + 1 sampled independently, and with \u03b2\u00af(j,k)t replaced by \u03b2(j)t \u03b2\u02dc(k)t in\nthe calculation of the weight. Thus we have an O(N) version of our smoothing\nalgorithm shown in Algorithm 3. We note that we can speed up the algorithm\nfurther as the probabilities \u03b2(j)t and \u03b2\u02dc\n(k)\nt (or even the auxiliary variables {ji}\nand {ki}) can be saved from the filters to reduce the number of calculations in\nthe smoothing step.\nAlgorithm 3 New O(N) smoothing algorithm\nProceed as Algorithm 2 but substitute steps 3(a) and 3(c) for\n3. (a) Re-sample: Use {\u03b2(j)t } from the filter to sample j1, ..., jN and {\u03b2\u02dc(k)t }\nfrom the backwards filter to sample k1, ..., kN from {1, ..., N}\n(c) Re-weight: Assign each particle x\u00af(i)t the weight\nw\u00af\n(i)\nt \u221d\nf(x\u00af(i)t |x(ji)t\u22121) g(yt|x\u00af(i)t ) f(x\u02dc(ki)t+1 |x\u00af(i)t )w(ji)t\u22121 w\u02dc(ki)t+1\nq\u00af(x\u00af(i)t |x(ji)t\u22121, yt, x\u02dc(ki)t+1)\u03b2(ji)t \u03b2\u02dc(ki)t \u03b3t+1(x\u02dc(ki)t+1)\nand normalise them to sum to 1.\n4 Simulation study\nWe now compare the efficiency of our new algorithm against the currently avail-\nable methods. Our simulations are based on a model with linear-Gaussian state\nand observation models. The specific state model we used is chosen to be the\nsame as for our athletics application in Section 5. We have a chosen a linear-\nGaussian observation model so that we can compare results of different particle\nsmoothers with the true smoothing distributions obtained from the Kalman\nfilter and smoother (see Kalman (1960) and Anderson and Moore (1979)).\nFormally, we consider the model:\nXt+1|{X1:t = x1:t, Y1:t = y1:t} \u223c N (Fxt, Q),\nYt|{X1:t = x1:t, Y1:t\u22121 = y1:t\u22121} \u223c N (Gxt, R),\nX0 \u223c N (\u00b50,\u03a30),\n12\nwhere\nF =\n(\n1 1\n0 1\n)\n, Q = \u03bd2\n(\n1\n3\n1\n2\n1\n2 1\n)\n,\nG = (1, 0), R = \u03c42.\nThe state is derived from the pair of stochastic differential equations (SDEs)\ndXt,1 = Xt,2dt and dXt,2 = \u03bddBt and so the first component Xt,1 is the inte-\ngrated path of the random walk Xt,2. A noisy observation of the first component\nis made at each time step. The parameter \u03bd2 determines the smoothness of the\nstate over time. With a large value of \u03bd2 the state can move freely and thus\nfollows the observations. When \u03bd2 is small however the model makes a linear\nfit to the observations.\nWe compare the two versions of our new algorithm with the simple Filter-\nSmoother of Section 2.2, the Forward-Backward Smoother of Section 2.3.1 and\nthe Two-Filter Smoother of Section 2.3.2. We also look at how the relative\nperformance of the algorithms is affected by the ratio of the state noise \u03bd2 to\nobservation noise \u03c42. The details of our particle filter, backwards filter and\nsmoothing algorithms for this model are given in Appendix A.1.\nTo compare the accuracy of our smoothing algorithms\u2019 estimates of Xt,d we\nestimate the effective sample size Neff(Xt,d). Motivated by the fact that\nE\n(\n(X\u00af \u2212 \u00b5)2\n\u03c32\n)\n=\n1\nN\n,\nwhen X(1), . . . , X(N) iid N (\u00b5, \u03c32) and X\u00af is their sample mean, we take\nNeff(Xt,d) = E\n(\n(x\u02c6t,d \u2212 \u00b5t,d)2\n\u03c32t,d\n)\u22121\n, (11)\nwhere \u00b5t,d and \u03c32t,d are the true mean and variance ofXt,d|y1:T obtained from the\nKalman smoother and x\u02c6t,d is the random estimate from a particle smoother. We\ncan therefore crudely say that the weighted sample produced by our smoother\nis as accurate at estimating Xt,d as an independent sample of size Neff(Xt,d).\nTo estimate the expectation in (11) we use the mean value from 100 repetitions\nof each algorithm.\nWe first compare the smoothing algorithms using model parameters of \u03bd2 =\n\u03c42 = 1 with \u00b50 = (0, 0)\n\u2032\nand \u03a30 = I2 for the prior. We generated 20 datasets,\neach of length 200, and averaged the effective sample sizes to remove effects\ncaused by a single dataset.\nWe chose different numbers of particles for each algorithm to try to reflect the\nvarying complexities of each method. We started by choosing 10, 000 particles\nfor the Filter-Smoother and 3, 000 for the O(N) version of our new algorithm\nsince they then took approximately the same amount of time to run. We would\nhave liked to scale the O(N2) algorithms to take the same time to run but\ntheir speeds varied greatly. Part of this may be due to how the algorithms are\nimplemented in R. We therefore fixed the number of particles for these three\nalgorithms at 300. This made the O(N2) version of our new algorithm faster\nbut the other two methods slower than the Filter-Smoother. The average time\ntaken by each algorithm per run is shown in Table 1.\n13\nAlgorithm Filter Forward- Two-Filter New O(N2) New O(N)Backward\nN 10,000 300 300 300 3,000\nRun time (s) 224 688 358 40 255\nTable 1: Number of particles used and average run time of each algorithm.\nFigure 2 shows how the average effective number of particles for estimating\nXt,1 varies through time for the five algorithms considered. The results for Xt,2\n(not shown) are very similar.\n0 50 100 150 200\n0\n20\n0\n40\n0\n60\n0\n80\n0\nN\nef\nf\nFigure 2: Average effective sample size for each of the 200 time steps using the\nfilter (\u2014), Forward-Backward (---) and Two-Filter smoothers (\u0005 \u0005 \u0005) as well as\nthe O(N2) (\u0005\u2212) and O(N) version (\u2212\u2212) of our new algorithm.\nWe can see that the Filter-Smoother does very well for times close to T =\n200 as this filter has by far the most particles and the filter and smoothing\ndistributions are similar at this stage of the process. As predicted however this\nalgorithm gets progressively worse as it goes backwards through time. This\nis not necessarily the case with the other algorithms whose efficiencies remain\nroughly constant over time when averaged over the 20 datasets. Of the two\nO(N) algorithms we see that our new method vastly outperforms the Filter-\nSmoother for all but the final few time steps, despite taking a similar amount\nof time to run.\nFrom Figure 2 we can also see that the three O(N2) algorithms have near\nidentical efficiencies for this particular model. This may be because they are all\nderived in some way from the same formula, p(xt|y1:T ) \u221d p(xt|y1:t\u22121)p(yt:T |xt),\nand all combine filter particles with an O(N2) approximation of p(yt:T |xt). We\nrecall that these were run with the same number of particles N though in our\nimplementation our new algorithm was faster than the other two here. However,\neven with this taken into account, the O(N) version is many times more efficient\nfor even these modest sample sizes.\nTo see how these results are affected by the ratio of the state noise \u03bd2 to\nthe observation noise \u03c42, we repeat the experiment first with \u03bd2 = 100 while\nkeeping \u03c42 = 1. This gives the state freedom to follow the observations which\nhelps the algorithms to perform well. The results are shown in Figure 3a below.\n14\nThose for \u03bd2 = 1 and \u03c42 = 1\/100 gave very similar results.\n0 50 100 150 200\n0\n10\n00\n20\n00\n30\n00\nN\nef\nf\n(a) \u03bd2\/\u03c42 = 100\n0 50 100 150 200\n0\n50\n15\n0\n25\n0\nN\nef\nf\n(b) \u03bd2\/\u03c42 = 1\/100\nFigure 3: Average effective sample sizes as in Figure 2 with different ratios of\nthe state noise \u03bd2 to the observation noise \u03c42.\nWe see that the accuracy of the Filter-Smoother still diminishes as it pro-\ngresses backwards through time but all the other methods are close to their\noptimal efficiency of an effective sample size equal to N . This is particularly\nthe case with our new O(N2) algorithm which outperforms the other O(N2)\nmethods at every time step. Our new O(N) algorithm however is by far the\nfastest allowing it to have 10 times as many particles as the slower methods. Its\nefficiency also suggests that our choice of re-sampling weights is reasonable.\nWe finally repeat the experiment with \u03bd2\/\u03c42 = 1\/100 which makes the state\nhighly dependent through time and causes all the particle methods to struggle.\nThis can be seen from the low effective sample sizes in Figure 3b. Even though\nthe Filter-Smoother diminishes at a faster rate than before it does better than\nthe other algorithms for a large number of time steps. This is possibly due\nto the total accumulation of error in the filter, backwards filter and smoother,\neach of which performs badly in this case, which hinder the other methods.\nThe Filter-Smoother eventually drops below the accuracy of our O(N) method\nshowing that our O(N) algorithm can give stronger estimates of the earliest\nsmoothing densities in even the toughest situations.\n5 Athletic records\nWe use our smoothing algorithm to analyse data from the women\u2019s 3000m run-\nning event. Robinson and Tawn (1995) first studied the fastest times from 1972\nto 1992 to assess whether Wang Junxia\u2019s record in 1993 was consistent with\nthe previous data. They used an extreme value likelihood with a parametric\ntrend to conclude that cutting 16.51s off the record, though unusual, was not\nexceptionally so. Smith (1997) outlined the benefits of a Bayesian analysis for\ncalculating the probability of beating Wang Junxia\u2019s record given that a new\nrecord is set and Gaetan and Grigoletto (2004) extended this by using particle\nmethods to model a dynamic trend.\nWhile Gaetan and Grigoletto (2004) presented an attractive model for the\ndata, it is our belief that the particle methods they used for their inference are\n15\nhighly inefficient. They used the smoothing algorithm of Tanizaki and Mariano\n(1994) with an AR(2) state which causes the smoother to degrade to the Filter-\nSmoother as shown in Section 2.5. They also introduced two random walks\nwith extremely small variances to the state which causes all particle methods\nto struggle as was shown by the small effective sample sizes in Figure 3b in\nSection 4. We therefore believe that the conclusions they drew from using only\nN = 1000 particles are unreliable and we aim to produce a more robust analysis.\nWhereas Gaetan and Grigoletto (2004) used the annual minimum running\ntimes, we use the r fastest annual times following the initial analysis of Robinson\nand Tawn (1995). Large amounts of data are now available on-line (for example\nfrom Larsson (2008)) from which the five fastest times of different athletes per\nyear is shown in Figure 4. The natural choice for modelling the fastest annual\nrunning times is the generalised extreme value distribution for minima (GEVm)\nas motivated by asymptotic extreme value theory (see Coles (2001) for details\nas well as an introduction to extreme value techniques). This distribution has\nlocation and scale parameters \u00b5 \u2208 < and \u03c3 > 0 as well as a shape parameter\n\u03be \u2208 < which allows for many types of tail behaviour. Its cdf is given by\nG(y|\u00b5, \u03c3, \u03be) = 1\u2212 exp\n{\n\u2212\n[\n1\u2212 \u03be\n(\ny \u2212 \u00b5\n\u03c3\n)]\u2212 1\u03be\n+\n}\n,\nwhere we define [y]+ := max(y, 0). This distribution naturally extends to the\nr-smallest order statistic model which we use for the ith fastest records yi per\nyear. This model has a likelihood given by\ng(y1:r|\u00b5, \u03c3, \u03be) \u221d G\u00af(yr|\u00b5, \u03c3, \u03be)\nr\u220f\ni=1\ng(yi|\u00b5, \u03c3, \u03be)\nG\u00af(yi|\u00b5, \u03c3, \u03be) ,\nwhere we write G\u00af(y|\u00b5, \u03c3, \u03be) := 1\u2212G(y|\u00b5, \u03c3, \u03be) for the GEVm survivor function\nand g(y|\u00b5, \u03c3, \u03be) for the derivative of G(y|\u00b5, \u03c3, \u03be) with respect to y.\nFor the state, Gaetan and Grigoletto (2004) used independent random walks\nfor each of the three likelihood parameters. They used a second order random\nwalk for \u00b5 to model the clear trend seen in the location of the data and for \u03c3\nand \u03be they used first order random walks with extremely small state variances\nto make them roughly constant in time. Since such state variances cause poor\nperformance with the filters and smoothers, we assume for simplicity these pa-\nrameters are fixed and known. We later estimate them using an EM algorithm\nbased on our smoothing algorithm although we would have preferred to add\nthem to the state to fully account for their uncertainty.\nSince a second order AR(2) model for \u00b5 causes degeneracy problems with\nsome smoothers, we instead adopt the smooth second order random walk given\nin the earlier simulation study of Section 4. We therefore augment the state with\n\u00b5\u02d9, the velocity of \u00b5, giving us the two-dimensional state xt = (\u00b5t, \u00b5\u02d9t)\n\u2032\n. Finally,\nfor the prior we follow Gaetan and Grigoletto (2004) and use an uninformative\nnormal distribution. Since the likelihood only depends on \u00b5t and the prior is\nGaussian we used Rao-Blackwellisation to marginalise \u00b5\u02d9t thus improving the\naccuracy of the methods. Details of this step and the particle algorithms we\nused to achieve this are given in Appendix A.2.\nFor a fixed value of r and \u03bd2 we can estimate the likelihood parameters \u03c3 and\n\u03be using an EM algorithm constructed using our new smoother (see Appendix B\n16\nll\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl l l\nl l l\nl\nl\nl l\nl\nl\nl\n49\n0\n50\n0\n51\n0\n52\n0\n53\n0\n54\n0\n55\n0\nTi\nm\ne \n(s)\nl\nl\nl\nl\nl\nl\nl\nl\nl l\nl\nl\nl\nl\nl l\nl\nl\nl\nl l\nl\nl\nl\nl\nl\nl l\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl l\nl\nl\nl l\nl\nl\nl\nl\nl\nl\nl\nl l\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl l\nl\nl\nl\nl\nl\nl\nl l\nl\nl\nl\nl\nl\nl l\nl\nl\nl l\nl l l\nl\nl\nl l\nl\n1972 1977 1982 1987 1992 1997 2002 2007\nl\nFigure 4: Five fastest times for the women\u2019s 3000m race between 1972 and\n2007 with Wang Junxia\u2019s time in 1993. The two fastest annual times used for\nour fit are coloured black. Also shown is the mean and central 95% probability\ninterval of the fitted predictive distribution for the fastest time per year.\nfor details). Simultaneously estimating \u03bd2 requires particles approximating the\njoint distribution p(xt\u22121, xt|y1:T ) which is possible using our approach (as our\nalgorithm gives approximations to p(xt\u22121:t+1|y1:T ), see Section 3). It is sim-\npler however to select among a few possible \u03bd2 by maximising the model likeli-\nhood p(y1972:2007|\u03bd2), which we estimate using the following formula of Kitagawa\n(1996):\np(y1972:2007|\u03bd2) '\n2007\u220f\nt=1972\nN\u2211\ni=1\ng(yt,1:r|\u00b5(i)t|t\u22121, \u03c3, \u03be)w(i)t\u22121,\nwhere \u00b5(i)t|t\u22121 is the first component of a predictive particle sampled from the\nstate f(\u00b7|x(i)t\u22121, \u03bd2) and {(x(i)t , w(i)t )} are sampled from a particle filter given \u03bd2.\nTable 2 shows a selection of \u03bd2 values with the corresponding EM estimates of\n\u03c3 and \u03be and the model likelihood when we take r = 2.\n\u03bd2 0.5 0.75 1 1.25 1.5 1.75 2\n\u03c3 4.36 4.25 4.22 4.15 4.12 4.04 4.01\n\u03be -0.15 -0.13 -0.13 -0.11 -0.11 -0.09 -0.09\nLikelihood (\u00d710\u221283) 0.41 2.72 3.68 3.50 2.41 1.52 1.02\nTable 2: Model likelihood with \u03c3 and \u03be estimates for different values of the\nsmoothing parameter \u03bd2 and r = 2.\nTo select the number of observations r to include per year we constructed\nprobability-probability and quantile-quantile plots to assess the model fit. Look-\ning at r = 1, . . . , 5 we concluded that the best fit was obtained from only two\n17\nobservations per year. As we see from Table 2, this leads us to select \u03bd2 = 1\nand estimate \u03c3 and \u03be to be 4.22 and -0.13 respectively.\nTo estimate the probability of a new record in 1993 beating Wang Junxia\u2019s\nwe use the r = 2 fastest times from 1972 to 2007 excluding 1993, denoted\ny1972:2007, to estimate the predictive distribution of the fastest time in 1993.\nGiven the parameters \u00b51993, \u03c3 and \u03be, the probability of Y1993, a new record in\n1993, beating Wang Junxia\u2019s time of 486.11s is given by\nP{Y1993 \u2264 486.11|Y1993 \u2264 502.62, \u00b51993, \u03c3, \u03be} = G(486.11|\u00b51993, \u03c3, \u03be)\nG(502.62|\u00b51993, \u03c3, \u03be) ,\nwhere 502.62s was the world record prior to 1993. Unconditioning on \u00b51993, we\nestimate the overall probability prec with\nprec =\n\u222b\nG(486.11|\u00b51993, \u03c3, \u03be)\nG(502.62|\u00b51993, \u03c3, \u03be)p(\u00b51993|y1972:2007) d\u00b51993\n'\nN\u2211\ni=1\nG(486.11|\u00b5(i)1993, \u03c3, \u03be)\nG(502.62|\u00b5(i)1993, \u03c3, \u03be)\nw\n(i)\n1993,\nwhere we use weighted particles to approximate p(\u00b51993|y1972:2007).\nTo compare algorithms\u2019 efficiencies at approximating p(\u00b51993|y1972:2007) we\nrun a simulation to estimate the effective sample size Neff(Xt,1) as in Section 4\nusing 300 repetitions of each algorithm. However, since the true mean and\nvariance of the target density are now unknown, we first estimate the true\ndistribution using the Filter-Smoother with 750, 000 particles. Since our primary\ninterest is to estimate the probability of a new record beating Wang Junxia\u2019s, we\nalso calculate the sample variance of our estimate of this over the 300 repetitions\nused to estimate Neff .\nFor this simulation we chose to compare only the O(N) algorithms as both\nthe Forward-Backward and the Two-Filter smoothers suffer problems of degen-\neracy when applied to the Rao-Blackwellised filter described in Appendix A.2.\nThese smoothers could be applied to a non-Rao-Blackwellised filter, but given\nthe simulation results in Section 4, it appears that these smoothers would not be\ncompetitive with our new smoother. Since we only require the marginal smooth-\ning distribution for 1993, our new algorithm only requires the particle filter up\nto 1992 and the backwards filter back to 1994. We therefore chose the same\nnumber of particles, 10, 000, for both our algorithm and the Filter-Smoother\nand observed that they took roughly the same amount of time to run.\nThe results of the simulation are shown in Table 3. We can see that our\nnew algorithm has an effective sample size over 8 times as large as that of the\nFilter-Smoother giving similarly less variable estimates. Of course, to calculate\nthe marginals for every time step within the same amount of time our method\ncould only use a third of the particles, but it would still outperform the Filter-\nSmoother for the majority of estimates.\n18\nAlgorithm Neff Var(p\u02c6rec) (\u00d710\u221210)\nFilter-Smoother 130 3.616\nNew O(N) 1049 0.401\nTable 3: Comparison of the efficiencies of the Filter-Smoother and our new\nalgorithm for approximating p(\u00b51993|y1972:2007) and the probability of a new\nrecord beating Wang Junxia\u2019s time. In both cases the average probability esti-\nmate was 1.92\u00d7 10\u22124.\nOur analysis estimates the probability of a new record in 1993 beating\nWang\u2019s to be 1.92\u00d710\u22124. This conflicts with the analysis of Gaetan and Grigo-\nletto (2004) who showed Wang\u2019s record well within the reach of their boxplots\nof the conditional distribution. Apart from our doubts in the accuracy of their\nresults, the main difference in the two analyses is that Gaetan and Grigoletto\n(2004) only used data on the fastest race for years up to 1993. Thus it may\nbe the information in the extra data we use that leads us to a different conclu-\nsion about how extreme the world record of Wang is. We also admit that our\nanalysis fails to account for the uncertainty in \u03c3 and \u03be which could cause our\nestimate to be under-estimated. However, while Gaetan and Grigoletto (2004)\nattempted to account for this by augmenting the state with \u03c3 and \u03be, this leads\nto poor performance of the particle methods so a new approach is required.\nAppendix A Implementation of particle filters\nand smoothers\nA.1 Multivariate Normal model\nTo implement the various smoothing algorithms we need to choose propagation\ndensities for a particle filter, backwards information filter and the smoother it-\nself. Using auxiliary algorithms throughout, the linear-Gaussian model assump-\ntion allows us to calculate the optimal densities and re-sampling probabilities.\nUsing these we have adapted algorithms giving even weights of 1\/N whenever\nwe resample.\nWriting N (x|\u00b5, \u03c32) for the density of N (\u00b5, \u03c32) evaluated at x, it is easy to\nshow that the optimal filter is given by\nq(xt|x(j)t\u22121, yt)\u03b2(j)t = f(xt|x(j)t\u22121)g(yt|xt)w(j)t\u22121\n= N (xt|\u00b5(j)t|t\u22121,\u03a3t|t\u22121) N (yt|GFx(j)t\u22121, R+GQG\n\u2032\n)w(j)t\u22121,\nwhere \u03a3t|t\u22121 = (Q\u22121+G\n\u2032\nR\u22121G)\u22121 and \u00b5(j)t|t\u22121 = \u03a3t|t\u22121(Q\n\u22121Fx(j)t\u22121+G\n\u2032\nR\u22121yt).\nThis is used for each algorithm but we only need to keep track of our trajectories\nfor the simple Filter-Smoother.\nFor the backwards information filter we can use the actual prior \u03b3t(xt) =\np(xt) = N (xt|\u00b5t,\u03a3t), whose mean and covariance can be calculated sequentially\nusing the prediction step of the Kalman filter. This gives\np(xt|xt+1) = N (xt|F\u02dc xt+1 + Q\u02dc\u03a3\u22121t \u00b5t, Q\u02dc),\n19\nwhere we define F\u02dc := \u03a3tF\n\u2032\n\u03a3\u22121t+1 and Q\u02dc := \u03a3tF\n\u2032\n\u03a3\u22121t+1QF\n\u2032\u22121. We then obtain\nq\u02dc(xt|yt, x\u02dc(k)t+1)\u03b2\u02dc(k)t = p(xt)g(yt|xt)f(x\u02dc(k)t+1|xt)\nw\u02dc\n(k)\nt+1\np(x\u02dc(k)t+1)\n\u221dN (xt|\u00b5(k)t|t+1,\u03a3t|t+1)\u00d7\nN (yt|G(F\u02dc x(k)t+1 + Q\u02dc\u03a3\u22121t \u00b5t), R+GQ\u02dcG\n\u2032\n)w\u02dc(k)t+1,\nwhere \u03a3t|t+1 = (\u03a3\u22121t + G\n\u2032\nR\u22121G + F\n\u2032\nQ\u22121F )\u22121 and \u00b5(k)t|t+1 = \u03a3t|t+1(\u03a3\n\u22121\nt \u00b5t +\nG\n\u2032\nR\u22121yt + F\n\u2032\nQ\u22121x\u02dc(k)t+1).\nFinally, for our new smoothing algorithm we have\nq\u00af(xt|x(j)t\u22121, yt, x\u02dc(k)t+1) \u221d f(xt|x(j)t\u22121)g(yt|xt)f(x\u02dc(k)t+1, xt)\n\u221d N (xt|\u00b5(j,k)t|T ,\u03a3t|T ),\nwhere \u03a3t|T = (Q\u22121 + G\n\u2032\nR\u22121G + F\n\u2032\nQ\u22121F )\u22121 and \u00b5(j,k)t|T = \u03a3t|T (Q\n\u22121Fx(j)t\u22121 +\nG\n\u2032\nR\u22121yt + F\n\u2032\nQ\u22121x\u02dc(k)t+1). The optimal re-sampling weights can be shown to be\n\u03b2\u00af\n(j,k)\nt \u221d p(x\u02dc(k)t+1, yt|x(j)t\u22121)\nw\n(j)\nt\u22121w\u02dc\n(k)\nt+1\np(x\u02dc(k)t+1)\n= N\n((\nx\u02dc\n(k)\nt+1\nyt\n)\u2223\u2223\u2223\u2223(F 2GF\n)\nx\n(j)\nt\u22121,\n(\nQ+ FQF\n\u2032\nFQG\n\u2032\nGQF\n\u2032\nR+GQG\n\u2032\n))\nw\n(j)\nt\u22121w\u02dc\n(k)\nt+1\np(x\u02dc(k)t+1)\n,\nwhich we can see does not factorise. Therefore, for the O(N) version of our\nalgorithm we use \u03b2(j)t and \u03b2\u02dc\n(k)\nt from the filters as suggested in Section 3.1 as\nthis should be a good approximation of the optimal weights.\nA.2 Athletics records\nAdapted auxiliary algorithms for this model will not be possible as the likelihood\nin \u00b5 is very complex. We therefore approximate the log likelihood l(\u00b5t) by a\nsecond-order Taylor approximation about an estimated mode \u00b5\u02c6t which leads to\na normal approximation of the form\ng(yt,1:r|\u00b5t) ' N\n(\n\u00b5t\n\u2223\u2223\u2223\u2223 \u00b5\u02c6t \u2212 l\u2032(\u00b5\u02c6t)l\u2032\u2032(\u00b5\u02c6t) ,\u2212 1l\u2032\u2032(\u00b5\u02c6t)\n)\u2223\u2223\u2223\u2223\nAt\n, (12)\nwhere the distribution is restricted to the likelihood\u2019s support of\nAt := {\u00b5t|\u03c3 \u2212 \u03be(yt,i \u2212 \u00b5t) > 0,\u2200i} .\nIn practise, we used the optimize function in R to estimate the mode at each\ntime step.\nTo make the algorithms as efficient as possible we use Rao-Blackwellisation\nto reduce the variance of our estimates. For this we can marginalise the second\ncomponent of the state \u00b5\u02d9t as the likelihood only depends on \u00b5t so the distribution\nof \u00b5\u02d9t|\u00b5t can be updated by using only its mean and variance. This improves the\n20\noverall approximation by allowing the second component of each particle to act\nas a normal distribution rather than a point mass. We therefore have particles\nof the form x(i)t = (\u00b5\n(i)\nt , m\u02d9\n(i)\nt , \u03c4\n2(i)\nt )\n\u2032\n, where \u00b5\u02d9t|{\u00b5t = \u00b5(i)t } \u223c N (m\u02d9(i)t , \u03c42(i)t ).\nTo create a marginalised particle filter it helps to think each particle x(i)t\u22121\nas a kernel approximation to p(\u00b5t\u22121, \u00b5\u02d9t\u22121|y1:t\u22121) of the form\n\u03c6(i)(\u00b5t\u22121, \u00b5\u02d9t\u22121) := N (\u00b5t\u22121, \u00b5\u02d9t\u22121|\u03b7(i)t\u22121,K(i)t\u22121),\nwith\n\u03b7\n(i)\nt\u22121 :=\n(\n\u00b5\n(i)\nt\u22121\nm\u02d9\n(i)\nt\u22121\n)\n, K\n(i)\nt\u22121 :=\n(\n0 0\n0 \u03c42(i)t\u22121\n)\n.\nThis leads to the approximation of p(\u00b5t, \u00b5\u02d9t|y1:t\u22121) by\npi(i)(\u00b5t, \u00b5\u02d9t) :=\n\u222b\nf(\u00b5t, \u00b5\u02d9t|\u00b5t\u22121, \u00b5\u02d9t\u22121)\u03c6(i)(\u00b5t\u22121, \u00b5\u02d9t\u22121) d\u00b5t\u22121 d\u00b5\u02d9t\u22121\n= N (\u00b5t, \u00b5\u02d9t|F\u03b7(i)t\u22121, Q+ FK(i)t\u22121F\n\u2032\n).\nTo create the new particle x(i)t we therefore use standard auxiliary particle\nfiltering with target density\nqopt(\u00b5t|x(i)t\u22121, yt)\u03b2(i)t = pi(i)(\u00b5t) g(yt|\u00b5t)w(i)t\u22121\nto sample \u00b5(i)t and then update the mean and variance of \u00b5\u02d9t|{\u00b5 = \u00b5(i)t } with\nthat of pi(i)(\u00b5\u02d9t|\u00b5(i)t ). For this we replace the likelihood by the approximation\n(12) to give us a constrained normal sampling density for \u00b5(i)t and approximate\nthe optimal re-sampling weights with\n\u03b2\n(i)\nt '\npi(i)(\u00b5\u02c6t) g(yt|\u00b5\u02c6t)w(i)t\u22121\nq(\u00b5\u02c6t|x(i)t\u22121, yt)\n,\nwhere \u00b5\u02c6t is the mean of the sampling density q(\u00b5t|x(i)t\u22121, yt).\nFor the backwards filter we again start by defining F\u02dc := \u03a3tF\n\u2032\n\u03a3\u22121t+1 and\nQ\u02dc := \u03a3tF\n\u2032\n\u03a3\u22121t+1QF\n\u2032\u22121, where \u03a3t is the variance of the normal prior at time t.\nIt can then be shown that p(\u00b5t, \u00b5\u02d9t|\u00b5t+1, \u00b5\u02d9t+1) is equal to\nN\n((\n\u00b5t\n\u00b5\u02d9t\n)\u2223\u2223\u2223\u2223F\u02dc (\u00b5t+1\u00b5\u02d9t+1\n)\n+ Q\u02dc\u03a3\u22121t\n(\n\u00b5\u02c6t\n\u02c6\u02d9\u00b5t\n)\n, Q\u02dc\n)\n,\nwhere (\u00b5\u02c6t, \u02c6\u02d9\u00b5t)\n\u2032\nis the mean of the prior at time t. We then combine this with a\nkernel \u03c6(i)(\u00b5t+1, \u00b5\u02d9t+1) created from x\n(i)\nt+1 to give the density\np\u02dci(i)(\u00b5t, \u00b5\u02d9t) := N\n((\n\u00b5t\n\u00b5\u02d9t\n)\u2223\u2223\u2223\u2223F\u02dc \u03b7(i)t+1 + Q\u02dc\u03a3\u22121t (\u00b5\u02c6t\u02c6\u02d9\u00b5t\n)\n, Q\u02dc+ F\u02dcK(i)t+1F\u02dc\n\u2032\n)\n.\nWe now proceed in exactly the same way as with the forwards filter using p\u02dci\ninstead of pi to sample x(i)t .\nFinally, for our new smoothing algorithm, it can be shown that our target\nfor \u00b5(i)t in this marginalised setting is\nq\u00afopt(\u00b5t|x(j)t\u22121, yt, x(k)t+1) \u03b2\u00af(j,k)t = pi(j)(\u00b5t)w(j)t\u22121 \u00b7\ng(yy|\u00b5t)\np(\u00b5t)\n\u00b7 p\u02dci(k)(\u00b5t)w(k)t+1.\n21\nThis leads us to sample \u00b5(i)t as before using the density proportional to the\nproduct of pi(j)(\u00b5t), p\u02dci(k)(\u00b5t) and p(\u00b5t)\u22121 in place of pi(j)(\u00b5t). We can then\ncalculate the mean and variance of \u00b5\u02d9t|\u00b5(i)t from the distribution proportional to\npi(j)(\u00b5\u02d9t|\u00b5(i)t ) p\u02dci(k)(\u00b5\u02d9t|\u00b5(i)t )\np(\u00b5\u02d9t|\u00b5(i)t )\n.\nThe filter and backwards filter re-sampling weights were used again for the\nsuboptimal O(N) version of our algorithm.\nFor both the filter and the backwards filter the initial step was sampled using\nstandard importance sampling as the target density is available in closed form\nand using it rather than propagating the prior greatly improves the algorithm.\nWe also used the stratified sampling algorithm of Carpenter et al. (1999) in both\nthe filters and our new algorithm to reduce the Monte Carlo error of re-sampling.\nSince we chose not to include the data from 1993, for this time step in each\nof the above algorithms we proceed without the likelihood term g(yt|\u00b5t).\nAppendix B EM algorithm for parameter esti-\nmates\nFor our athletics model we require estimates of the fixed likelihood parameters\n\u03b8 = (\u03c3, \u03be) which we intend to obtain from the EM algorithm of Dempster et al.\n(1977). To do this we aim to maximise the likelihood p(y1:T |\u03b8) by iteratively\nmaximising\nQ(\u03b8|\u03b8(n)) := E\n(\nlog(p(X0:T , y1:T |\u03b8))\n\u2223\u2223\u2223 y1:T , \u03b8(n))\nto give \u03b8(n+1).\nSince the parameters \u03b8 do not appear in the state density, the joint log\nlikelihood can be written as\nlog(p(x0:T , y1:T |\u03b8)) = log(p(x0)) +\nT\u2211\nt=1\nlog(f(xt|xt\u22121)) +\nT\u2211\nt=1\nlog(g(yt|xt, \u03b8)).\nWe therefore have\nQ(\u03b8|\u03b8(n)) = const +\nT\u2211\nt=1\nE\n(\nlog(g(yt|Xt, \u03b8))\n\u2223\u2223\u2223 y1:T , \u03b8(n))\n' const +\nT\u2211\nt=1\nN\u2211\ni=1\nlog(g(yt|x(i)t , \u03b8))w(i)t ,\nwhere (xt, wt)(i) are weighted particles approximating p(xt|y1:T , \u03b8(n)). Thus we\nonly require particles from the marginal smoothing densities to estimate the\nexpectation so our new algorithm can be used directly. To estimate parameters\nfrom the state density with the EM algorithm, pairs of particles approximating\np(xt\u22121, xt|y1:T , \u03b8(n)) are required which we note are available from our algorithm\nas either (x\u00af(i)t\u22121, x\u02dc\n(ki)\nt ) at time t\u2212 1 or as (x(ji)t\u22121, x\u00af(i)t ) at time t.\n22\nThe EM algorithm therefore proceeds as follows. We start with an initial\nestimate of our parameters, \u03b8(0). Then, given our current estimate \u03b8(n), we\nuse our algorithm to generate particles from each marginal smoothing density\np(xt|y1:T , \u03b8(n)). Then we use numerical optimisation (such as the optim function\nin R) to maximise Q(\u03b8|\u03b8(n)) to give us a new estimate \u03b8(n+1). For our athletics\nexample we fitted a Kalman filter with the same state density but normal ob-\nservations yt to estimate the state x1:T and took maximum likelihood estimates\nof \u03c3 and \u03be using the shifted data yt \u2212 x\u02c6t to initialise the EM algorithm.\nReferences\nAnderson, B. D. O. and Moore, J. B. (1979). Optimal filtering. Prentice-Hall\nEnglewood Cliffs, New Jersey.\nBriers, M., Doucet, A., and Maskell, S. (2004). Smoothing algorithms for state-\nspace models. Submitted to IEEE Transactions on Signal Processing.\nCarpenter, J., Clifford, P., and Fearnhead, P. (1999). Improved particle filter for\nnonlinear problems. IEE Proceedings\u2013Radar, Sonar and Navigation, 146(1):2\u2013\n7.\nCasella, G. and Robert, C. P. (2001). Rao-Blackwellisation of sampling schemes.\nBiometrika, 83(1):81\u201394.\nColes, S. (2001). An Introduction to Statistical Modeling of Extreme Values.\nSpringer, London.\nDempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum Likelihood\nfrom Incomplete Data via the EM Algorithm. Journal of the Royal Statistical\nSociety. Series B (Methodological), 39(1):1\u201338.\nDoucet, A., Briers, M., and Se\u00b4ne\u00b4cal, S. (2006). Efficient Block Sampling Strate-\ngies for Sequential Monte Carlo Methods. Journal of Computational and\nGraphical Statistics, 15(3):693\u2013711.\nDoucet, A., Godsill, S., and Andrieu, C. (2000). On sequential Monte Carlo\nsampling methods for Bayesian filtering. Statistics and Computing, 10(3):197\u2013\n208.\nFearnhead, P. (2005). Using random Quasi-Monte Carlo within particle fil-\nters, with application to financial time series. Journal of Computational and\nGraphical Statistics, 14:751\u2013769.\nFearnhead, P. (2008). Computational Methods for Complex Stochastic Sys-\ntems: A Review of Some Alternatives to MCMC. To appear in Statistics and\nComputing.\nGaetan, C. and Grigoletto, M. (2004). Smoothing Sample Extremes with Dy-\nnamic Models. Extremes, 7(3):221\u2013236.\nGodsill, S. J., Doucet, A., and West, M. (2004). Monte Carlo Smoothing\nfor Nonlinear Time Series. Journal of the American Statistical Association,\n99(465):156\u2013169.\n23\nGordon, N. J., Salmond, D. J., and Smith, A. F. M. (1993). Novel approach\nto nonlinear\/non-Gaussian Bayesian state estimation. Radar and Signal Pro-\ncessing, IEE Proceedings F, 140(2):107\u2013113.\nHu\u00a8rzeler, M. and Ku\u00a8nsch, H. R. (1998). Monte Carlo Approximations for Gen-\neral State-Space Models. Journal of Computational and Graphical Statistics,\n7(2):175\u2013193.\nKalman, R. E. (1960). A new approach to linear filtering and prediction prob-\nlems. Journal of Basic Engineering, 82(1):35\u201345.\nKitagawa, G. (1996). Monte Carlo Filter and Smoother for Non-Gaussian Non-\nlinear State Space Models. Journal of Computational and Graphical Statistics,\n5(1):1\u201325.\nKitagawa, G. and Gersch, W. (1985). A Smoothness Priors Time-Varying AR\nCoefficient Modeling of Nonstationary Covariance Time Series. IEEE Trans-\nactions on Automatic Control, 30(1):48\u201356.\nLarsson, P. (2008). Track & Field all-time performances. http:\/\/www.\nalltime-athletics.com\/. [last accessed 22 April 2008].\nLiu, J. S. and Chen, R. (1995). Blind Deconvolution Via Sequential Imputations.\nJournal of the American Statistical Association, 90(430):567\u2013576.\nLiu, J. S. and Chen, R. (1998). Sequential Monte Carlo Methods for Dynamic\nSystems. Journal of the American Statistical Association, 93(443):1032\u20131044.\nLiu, J. S. and West, M. (2001). Combined parameter and state estimation\nin simulation-based filtering. In Doucet, A., de Freitas, N., and Gordon, N.,\neditors, Sequential Monte Carlo Methods in Practice, pages 197\u2013224. Springer.\nPitt, M. K. and Shephard, N. (1999). Filtering Via Simulation: Auxiliary\nParticle Filters. Journal of the American Statistical Association, 94(446):590\u2013\n599.\nRobinson, M. E. and Tawn, J. A. (1995). Statistics for Exceptional Athletics\nRecords. Applied Statistics, 44(4):499\u2013511.\nSmith, R. L. (1997). Comment on \u201cStatistics for Exceptional Athletics Records\u201d,\nby Robinson, M. E. and Tawn, J. A. Applied Statistics, 46(1):123\u2013128.\nSmith, R. L. and Miller, J. E. (1986). A Non-Gaussian State Space Model and\nApplication to Prediction of Records. Journal of the Royal Statistical Society.\nSeries B (Methodological), 48(1):79\u201388.\nTanizaki, H. and Mariano, R. S. (1994). Prediction, Filtering and Smoothing in\nNon-Linear and Non-Normal Cases Using Monte Carlo Integration. Journal\nof Applied Econometrics, 9(2):163\u2013179.\n24\n"}
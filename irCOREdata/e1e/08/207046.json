{"doi":"10.1214\/009053604000001282","coreId":"207046","oai":"oai:eprints.lse.ac.uk:16333","identifiers":["oai:eprints.lse.ac.uk:16333","10.1214\/009053604000001282"],"title":"Approximating conditional distribution functions using dimension reduction","authors":["Hall, Peter","Yao, Qiwei"],"enrichments":{"references":[{"id":17236768,"title":"a n dGANGOPADHYAY, A.K.","authors":[],"date":"1990","doi":null,"raw":"BHATTACHARYA,P .K .a n dGANGOPADHYAY, A.K. (1990). Kernel and nearest-neighbor estimation of a conditional quantile. Ann. Statist. 18 1400\u20131415.","cites":null},{"id":17236767,"title":"a n dH YNDMAN,","authors":[],"date":"2001","doi":null,"raw":"BASHTANNYK,D .M .a n dH YNDMAN, R. J. (2001). Bandwidth selection for kernel conditional density estimation. Comput. Statist. Data Anal. 36 279\u2013298.","cites":null},{"id":17236800,"title":"a n dM","authors":[],"date":"1990","doi":null,"raw":"SHEATHER,S .J .a n dM ARRON, J. S. (1990). Kernel quantile estimators. J. Amer. Statist. Assoc. 85 410\u2013416.","cites":null},{"id":17236769,"title":"a n dP ATEL, K.","authors":[],"date":"2000","doi":null,"raw":"BOND,S .A .a n dP ATEL, K. (2000). The conditional distribution of real estate returns: Relating time variation in higher moments to downside risk measurement. Technical report, Dept. Land Economy, Univ. Cambridge.","cites":null},{"id":17236793,"title":"a n dS IBSON, R.","authors":[],"date":"1987","doi":null,"raw":"JONES,M .C .a n dS IBSON, R. (1987). What is projection pursuit? (with discussion). J. Roy. Statist. S o c .S e r .A150 1\u201336.","cites":null},{"id":17236782,"title":"a n dS TUETZLE, W.","authors":[],"date":"1981","doi":null,"raw":"FRIEDMAN,J .H .a n dS TUETZLE, W. (1981). Projection pursuit regression. J. Amer. Statist. Assoc. 76 817\u2013823.","cites":null},{"id":17236801,"title":"a n dT","authors":[],"date":"1994","doi":null,"raw":"TIAO,G .C .a n dT SAY, R. S. (1994). Some advances in nonlinear and adaptive modeling in time series. J. Forecasting 13 109\u2013131.","cites":null},{"id":17236791,"title":"a n dY AO, Q.","authors":[],"date":"2002","doi":null,"raw":"HYNDMAN,R .J .a n dY AO, Q. (2002). Nonparametric estimation and symmetry tests for conditional density functions. J. Nonparametr. Statist. 14 259\u2013278.","cites":null},{"id":17236794,"title":"An ef\ufb01cient semiparametric estimator for binary response models.","authors":[],"date":"1993","doi":"10.2307\/2951556","raw":"KLEIN,R .a n dS PADY, R. (1993). An ef\ufb01cient semiparametric estimator for binary response models. Econometrica 61 387\u2013422. LI,K.-C.(1991).Slicedinverseregressionfordimensionreduction(withdiscussion).J.Amer.Statist. Assoc. 86 316\u2013342.","cites":null},{"id":17236799,"title":"Conditional probability density and regression estimators.","authors":[],"date":"1969","doi":null,"raw":"ROSENBLATT, M. (1969). Conditional probability density and regression estimators. In Multivariate Analysis II (P. Krishnaiah, ed.) 25\u201331. Academic Press, New York.","cites":null},{"id":17236803,"title":"Dimension reduction for the conditional kth moment in regression.","authors":[],"date":"2002","doi":"10.1111\/1467-9868.00330","raw":"YIN,X .a n dC OOK, R. D. (2002). Dimension reduction for the conditional kth moment in regression. J. R. Stat. Soc. Ser. B Stat. Methodol. 64 159\u2013175.","cites":null},{"id":17236790,"title":"Estimating and visualizing conditional densities.","authors":[],"date":"1996","doi":"10.1080\/10618600.1996.10474715","raw":"HYNDMAN,R .J . ,B ASHTANNYK,D .M .a n dG RUNWALD, G. K. (1996). Estimating and visualizing conditional densities. J. Comput. Graph. Statist. 5 315\u2013336.","cites":null},{"id":17236787,"title":"Estimating conditional distribution functions using dimension reduction.","authors":[],"date":"2002","doi":null,"raw":"HALL,P .a n dY AO, Q. (2002). Estimating conditional distribution functions using dimension reduction. Research Report 87, Dept. Statistics, London School of Economics. Available at www.lse.ac.uk\/collections\/statistics\/documents\/researchreport87.pdf.","cites":null},{"id":17236802,"title":"Excess kurtosis of conditional distribution for daily stock returns: The case of Japan.","authors":[],"date":"2000","doi":"10.1080\/135048500351267","raw":"WATANABE, T. (2000). Excess kurtosis of conditional distribution for daily stock returns: The case of Japan. Applied Economics Letters 7 353\u2013355.","cites":null},{"id":17236780,"title":"Exploratory projection pursuit.","authors":[],"date":"1987","doi":"10.1080\/01621459.1987.10478427","raw":"FRIEDMAN, J. H. (1987). Exploratory projection pursuit. J. Amer. Statist. Assoc. 82 249\u2013266.","cites":null},{"id":17236779,"title":"FORESI,S .a n dP ARACCHI, F.","authors":[],"date":"1992","doi":null,"raw":"FORESI,S .a n dP ARACCHI, F. (1992). The conditional distribution of excess returns: An empirical analysis. Working Paper 92-49, C. V. Starr Center, New York Univ.","cites":null},{"id":17236788,"title":"H ALL,P .a n dI CHIMURA, H.","authors":[],"date":"1993","doi":null,"raw":"H\u00c4RDLE,W . ,H ALL,P .a n dI CHIMURA, H. (1993). Optimal smoothing in single-index models. Ann. Statist. 21 157\u2013178.","cites":null},{"id":17236773,"title":"H ECKMAN,N .E .a n dW","authors":[],"date":"1995","doi":null,"raw":"FAN,J . ,H ECKMAN,N .E .a n dW AND, M. P. (1995). Local polynomial kernel regression for generalized linear models and quasi-likelihood functions. J. Amer. Statist. Assoc. 90 141\u2013150.","cites":null},{"id":17236785,"title":"HALL,P .a n dH EYDE,","authors":[],"date":"1980","doi":null,"raw":"HALL,P .a n dH EYDE, C. C. (1980). Martingale Limit Theory and Its Application. Academic Press, New York.","cites":null},{"id":17236766,"title":"L IU,X .a n dS","authors":[],"date":"1997","doi":null,"raw":"ADALI,T . ,L IU,X .a n dS ONMEZ, M. K. (1997). Conditional distribution learning with neural networks and its application to channel equalization. IEEE Trans. Signal Processing 45 1051\u20131064.","cites":null},{"id":17236804,"title":"Local linear quantile regression.","authors":[],"date":"1998","doi":"10.1080\/01621459.1998.10474104","raw":"YU,K .a n dJ ONES, M. C. (1998). Local linear quantile regression. J. Amer. Statist. Assoc. 93 228\u2013237. CENTRE FOR MATHEMATICS AND ITS APPLICATIONS AUSTRALIAN NATIONAL UNIVERSITY CANBERRA, ACT 0200 AUSTRALIA E-MAIL: Peter.Hall@maths.anu.edu.au DEPARTMENT OF STATISTICS LONDON SCHOOL OF ECONOMICS HOUGHTON STREET LONDON WC2A 2AE UNITED KINGDOM E-MAIL: Q.Yao@lse.ac.uk","cites":null},{"id":17236786,"title":"Methods for estimating a conditional distribution function.","authors":[],"date":"1999","doi":"10.2307\/2669691","raw":"HALL,P . ,W OLFF,R .C .L .a n dY AO, Q. (1999). Methods for estimating a conditional distribution function. J. Amer. Statist. Assoc. 94 154\u2013163.","cites":null},{"id":17236775,"title":"Nonlinear Time Series: Nonparametric and Parametric Methods.","authors":[],"date":"2003","doi":"10.1007\/b97702","raw":"FAN,J .a n dY AO, Q. (2003). Nonlinear Time Series: Nonparametric and Parametric Methods. Springer, New York.","cites":null},{"id":17236789,"title":"Projection pursuit (with discussion).","authors":[],"date":"1985","doi":"10.1214\/aos\/1176349519","raw":"HUBER, P. J. (1985). Projection pursuit (with discussion). Ann. Statist. 13 435\u2013525.","cites":null},{"id":17236771,"title":"Regression quantiles for time series.","authors":[],"date":"2002","doi":"10.1017\/s0266466602181096","raw":"CAI, Z. (2002). Regression quantiles for time series. Econometric Theory 18 169\u2013192.","cites":null},{"id":17236784,"title":"S TUETZLE,W .a n dS CHROEDER, A.","authors":[],"date":"1984","doi":null,"raw":"FRIEDMAN,J .H . ,S TUETZLE,W .a n dS CHROEDER, A. (1984). Projection pursuit density estimation. J. Amer. Statist. Assoc. 79 599\u2013608.","cites":null},{"id":17236798,"title":"Semiparametric estimation of index coef\ufb01cients.","authors":[],"date":"1989","doi":"10.2307\/1913713","raw":"POWELL,J .L . ,S TOCK,J .H .a n dS TOKER, T. M. (1989). Semiparametric estimation of index coef\ufb01cients. Econometrica 57 1403\u20131430.","cites":null},{"id":17236792,"title":"Semiparametric least squares (SLS) and weighted SLS estimation of singleindex models.","authors":[],"date":"1993","doi":"10.1016\/0304-4076(93)90114-k","raw":"ICHIMURA, H. (1993). Semiparametric least squares (SLS) and weighted SLS estimation of singleindex models. J. Econometrics 58 71\u2013120.","cites":null},{"id":17236796,"title":"The statistical analysis of the Canadian lynx cycle. I. Structure and prediction.","authors":[],"date":"1953","doi":"10.1071\/zo9530163","raw":"MORAN, P. A. P. (1953). The statistical analysis of the Canadian lynx cycle. I. Structure and prediction. Australian J. Zoology 1 163\u2013173.ESTIMATING CONDITIONAL DISTRIBUTIONS 1421 POSSE, C. (1995). Projection pursuit exploratory data analysis. Comput. Statist. Data Anal. 20 669\u2013687.","cites":null},{"id":17236777,"title":"Y AO,Q .a n dT","authors":[],"date":"1996","doi":null,"raw":"FAN,J . ,Y AO,Q .a n dT ONG, H. (1996). Estimation of conditional densities and sensitivity measures in nonlinear dynamical systems. Biometrika 83 189\u2013206.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2005","abstract":null,"downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/207046.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/16333\/1\/Approximating_conditional_distribution_functions_using_dimension_reduction_%28LSE_RO%29.pdf","pdfHashValue":"cd09674b72da7ee25ddb6f96a17d66c61c9883ae","publisher":"Institute of Mathematical Statistics","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:16333<\/identifier><datestamp>\n      2014-06-24T14:35:20Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5354<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/16333\/<\/dc:relation><dc:title>\n        Approximating conditional distribution functions using dimension reduction<\/dc:title><dc:creator>\n        Hall, Peter<\/dc:creator><dc:creator>\n        Yao, Qiwei<\/dc:creator><dc:subject>\n        HA Statistics<\/dc:subject><dc:publisher>\n        Institute of Mathematical Statistics<\/dc:publisher><dc:date>\n        2005<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/16333\/1\/Approximating_conditional_distribution_functions_using_dimension_reduction_%28LSE_RO%29.pdf<\/dc:identifier><dc:identifier>\n          Hall, Peter and Yao, Qiwei  (2005) Approximating conditional distribution functions using dimension reduction.  Annals of Statistics, 33 (3).  pp. 1404-1421.  ISSN 0090-5364     <\/dc:identifier><dc:relation>\n        http:\/\/www.imstat.org\/aos<\/dc:relation><dc:relation>\n        10.1214\/009053604000001282<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/16333\/","http:\/\/www.imstat.org\/aos","10.1214\/009053604000001282"],"year":2005,"topics":["HA Statistics"],"subject":["Article","PeerReviewed"],"fullText":"  \nPETER HALL, QIWEI YAO \nApproximating conditional distribution \nfunctions using dimension reduction \n \nArticle (Published version) \n(Refereed) \n \n \n Original citation: \nHall, Peter and Yao, Qiwei (2005) Approximating conditional distribution functions using \ndimension reduction. Annals of statistics, 33 (3). pp. 1404-1421. ISSN 0090-5364 \nDOI: 10.1214\/009053604000001282 \n \n\u00a9 2005 Institute of Mathematical Statistics \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/16333\/ \nAvailable in LSE Research Online: November 2011 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \nThe Annals of Statistics\n2005, Vol. 33, No. 3, 1404\u20131421\nDOI 10.1214\/009053604000001282\n\u00a9 Institute of Mathematical Statistics, 2005\nAPPROXIMATING CONDITIONAL DISTRIBUTION FUNCTIONS\nUSING DIMENSION REDUCTION\nBY PETER HALL AND QIWEI YAO\nAustralian National University and London School of Economics\nMotivated by applications to prediction and forecasting, we suggest\nmethods for approximating the conditional distribution function of a random\nvariable Y given a dependent random d-vector X. The idea is to estimate not\nthe distribution of Y |X, but that of Y |\u03b8TX, where the unit vector \u03b8 is selected\nso that the approximation is optimal under a least-squares criterion. We show\nthat \u03b8 may be estimated root-n consistently. Furthermore, estimation of the\nconditional distribution function of Y , given \u03b8TX, has the same first-order\nasymptotic properties that it would enjoy if \u03b8 were known. The proposed\nmethod is illustrated using both simulated and real-data examples, showing\nits effectiveness for both independent datasets and data from time series.\nNumerical work corroborates the theoretical result that \u03b8 can be estimated\nparticularly accurately.\n1. Introduction. Estimating a conditional distribution function is an impor-\ntant feature of many statistical problems, including, for example, regression analy-\nsis [see Yin and Cook (2002) and references therein], where a significant problem\nis prediction of a response for a given value of a multivariate explanatory variable.\nSpecific applications include those in economics and finance [e.g., Foresi and\nParacchi (1992), Bond and Patel (2000) and Watanabe (2000)], in signal process-\ning and data mining [e.g., Adali, Liu and Sonmez (1997)] and a wide range of\nproblems where forecasts are to be made from linear or nonlinear time-series [see,\ne.g., Chapter 10 of Fan and Yao (2003), and examples in Section 4 below].\nIn most of these applications one is interested in estimating the conditional\ndistribution of a scalar random variable Y , given a random d-vector X. Even\nfor small values of d \u2265 2, a conventional nonparametric estimator can suffer\npoor accuracy, reflected in slow convergence rates. We suggest a solution to\nthis difficulty, based on approximating the conditional distribution function of Y\ngiven X by that of Y given \u03b8TX, where the unit d-vector \u03b8 is selected so that the\napproximation is optimal under an appropriate least-squares criterion. In particular,\nwe avoid the problem of directly estimating the conditional distribution function\nof Y given X.\nReceived June 2002; revised July 2004.\nAMS 2000 subject classifications. Primary 62E17; secondary 62G05, 62G20.\nKey words and phrases. Conditional distribution, cross-validation, dimension reduction, kernel\nmethods, leave-one-out method, local linear regression, nonparametric regression, prediction, root-n\nconsistency, time series analysis.\n1404\nESTIMATING CONDITIONAL DISTRIBUTIONS 1405\nAlthough we are dealing with a dimension-reduction problem, the object\n(i.e., the conditional distribution function) to be estimated is a function of both\n\u03b8Tx and y, while the index \u03b8 is a global parameter. This rules out the possibility of\ndirect application of conventional dimension-reduction ideas, such as projection\npursuit [e.g., Friedman and Stuetzle (1981), Friedman, Stuetzle and Schroeder\n(1984) and Huber (1985)] and single-index modeling techniques [e.g., Powell,\nStock and Stoker (1989), H\u00e4rdle, Hall and Ichimura (1993), Ichimura (1993)\nand Klein and Spady (1993)], which would lead to an estimator of \u03b8 depending\non y. Instead we define a new criterion in terms of an accumulation of squared\ndifferences between the joint probabilities of (Y,X) and the expected conditional\nprobabilities of Y given \u03b8TX, over a large class of subsets; see (2.2) and (2.4) in\nSection 2 below. Our search for the global parameter \u03b8 is based on leave-one-out\nlocal linear regression estimators for conditional distribution functions. Under very\nmild assumptions the resulting estimator \u03b8\u02c6 is root-n consistent and asymptotically\nnormally distributed.\nOf course, our main purpose in computing \u03b8\u02c6 is so it can be used in a conditional\ndistribution estimator. The root-n convergence rate achieved by our estimator is so\nfast that the estimator of the conditional distribution function of Y , given \u03b8\u02c6TX, is\nfirst-order equivalent to its counterpart that would be used if the true value of \u03b8\nwere known.\nThe innovation and novelty of our methodology lie in the fact that we use\ndimension-reduction ideas to solve an important class of nonstandard multivariate\nnonparametric problems. We achieve this end by proposing new types of\nobjective functions, with which are associated new theoretical and numerical\nproperties. There exists an extensive literature on nonparametric estimation of\nconditional distributions. It includes work of Bhattacharya and Gangopadhyay\n(1990), Sheather and Marron (1990), Yu and Jones (1998) and Cai (2002) on\nconditional quantile regression; Rosenblatt (1969), Hyndman, Bashtannyk and\nGrunwald (1996), Fan, Yao and Tong (1996), Bashtannyk and Hyndman (2001)\nand Hyndman and Yao (2002) on conditional density estimation; and Hall, Wolff\nand Yao (1999) on estimation of conditional distribution functions. Dimension\nreduction has been discussed extensively in the context of regression and density\napproximation; in addition to the references cited earlier we mention the work of\nFriedman (1987), Jones and Sibson (1987), Li (1991) and Posse (1995).\nThis article is organized as follows. In Section 2 we introduce our method for\nestimating \u03b8 . Asymptotic properties of estimators \u03b8\u02c6 and F\u0302 (\u00b7|\u03b8TX) are presented\nin Section 3. Numerical examples involving both simulated models and a real-data\napplication are given in Section 4. Technical arguments are outlined in Section 5.\n2. Methodology.\n2.1. Motivation. Assume we observe data (Xi, Yi), for 1 \u2264 i \u2264 n, from the\ndistribution of (X,Y ). Here X is a d-vector and Y is a scalar. Let \u0002 denote the\n1406 P. HALL AND Q. YAO\nset of d-variate unit vectors \u03b8 with first nonzero component positive, write f for\nthe density of X and let FY |\u03b8TX(\u00b7|z) represent the distribution of Y conditional on\n\u03b8TX = z. Given subsets A and B of d-dimensional space and of the real line,\nrespectively, define\n\u03c0\u03b8(A,B) =\n\u222b\nA\nFY |\u03b8TX(B|\u03b8Tx)f (x) dx, \u03c0(A,B) = P(X \u2208 A, Y \u2208 B).\nIf, for some \u03b8 and all x, FY |\u03b8TX(\u00b7|\u03b8Tx) is identical to the distribution of Y given\nthat X = x, then for this \u03b8 , \u03c0\u03b8(A,B) = \u03c0(A,B) for all A,B. We suggest taking\nthe sets A to be d-variate spheres with differing centers and radii, and the sets B\nto be semi-infinite intervals.\nWe can estimate FY |\u03b8TX using nonparametric methods, permitting us to\nestimate \u03c0\u03b8(A,B). Of course, we can estimate \u03c0(A,B) as the proportion of\npairs (Xi, Yi) that lie in A\u00d7B. Hence, for each triple (\u03b8,A,B) we can estimate\n\u03c0\u03b8(A,B) and \u03c0(A,B) under minimal conditions. (We shall denote estimators of\n\u03c0\u03b8 and \u03c0 by \u03c0\u02c6\u03b8 and \u03c0\u02c6 , resp.) Therefore we can check (or, more formally, test) the\nhypothesis that FY |\u03b8TX(\u00b7|\u03b8Tx) is identical to the distribution of Y conditional on\nX = x, for all x, by examining the average value of {\u03c0\u02c6\u03b8 (A,B)\u2212 \u03c0\u02c6(A,B)}2 over\na range of sets A and B.\nAlthough exact equality of \u03c0 and \u03c0\u03b8 is unlikely in practice, the difference-\nbased criterion noted above can be used to empirically select \u03b8 such that, in a\nglobal sense, the distribution of Y given \u03b8TX = \u03b8Tx is a good approximation to the\ndistribution of Y given that X = x. Indeed, the argument in the previous paragraph\nsuggests that methodology of this type could be based on the difference measure,\nS1(\u03b8) =\n\u222b \u222b\n{\u03c0\u02c6\u03b8 (A\u03b1,B\u03b2)\u2212 \u03c0\u02c6(A\u03b1,B\u03b2)}2w(\u03b1,\u03b2)d\u03b1 d\u03b2,(2.1)\nwhere w is a weight function and the integral is taken over a parameteriza-\ntion (\u03b1,\u03b2) of (A,B).\nThe spheres A = A\u03b1 should be such that the density f\u03b8TX of \u03b8TX is\nbounded away from zero at all points \u03b8Tx with \u03b8 \u2208 \u0002 and x \u2208 A\u03b1 . Otherwise,\ndesign sparseness problems can arise when nonparametrically estimating FY |\u03b8TX .\nConsiderations of this type suggest taking the A\u03b1\u2019s to be d-variate spheres\nwhose centers confine them to lie inside a larger, bounded region where f is\nbounded away from zero. Such restrictions are unnecessary when considering the\nintervals B, except that there is little point in giving emphasis to sets for which\nP(Y \u2208 B) is low.\nFor these reasons, when permitting B\u03b2 to be the interval (\u2212\u221e, \u03b2) it is\nappropriate to take w(\u03b1,\u03b2) in (2.1) to be proportional to the density of Y at \u03b2 ,\nand to not depend on \u03b1. We shall achieve this end empirically, by replacing the\ndouble integral in (2.1) by a sum of integrals,\nS(\u03b8) =\nn\u2211\nj=1\n\u222b {\n\u03c0\u02c6\u03b8\n(\nA\u03b1,BYj\n)\u2212 \u03c0\u02c6(A\u03b1,BYj )}2 d\u03b1,(2.2)\nESTIMATING CONDITIONAL DISTRIBUTIONS 1407\nwhere B\u03b2 denotes (\u2212\u221e, \u03b2] and the integral is taken over an appropriate set of\nsphere centers and radii. In the future we shall use the notation y instead of \u03b2 .\nWhen constructing our estimator of FY |\u03b8TX , which is central to our com-\nputation of \u03c0\u02c6\u03b8 , we shall use a \u201cleave-one-out\u201d technique, or more accurately,\n\u201cleave-two-out.\u201d Our method will employ the empirical distribution of \u03b8TXi as\na surrogate for the true distribution of \u03b8TX, and so, when \u03b8TXi appears in the ar-\ngument of F\u0302Y |\u03b8TX , we shall omit Xi from the latter. The second omission occurs\nbecause, as formula (2.2) suggests, we shall validate on Yj when constructing our\nleast-squares criterion. Therefore we shall omit both the ith and the j th pairs when\ncalculating F\u0302Y |\u03b8TX; see (2.3) below.\n2.2. Estimator of \u03b8 . With these principles in mind, let h be a bandwidth and\nlet K be a kernel function, and define\nT\n[k]\n\u2212i,\u2212j (\u03b8) =\n1\n(n\u2212 2)h\n\u2211\ni1 : i1 \u0005=i,j\nK\n{\n\u03b8T(Xi \u2212Xi1)\nh\n}{\n\u03b8T(Xi \u2212Xi1)\nh\n}k\n,\nwi1;\u2212i,\u2212j (\u03b8) = K\n{\n\u03b8T(Xi \u2212Xi1)\nh\n}\n\u00d7\n{\nT\n[2]\n\u2212i,\u2212j (\u03b8)\u2212\n\u03b8T(Xi \u2212Xi1)\nh\nT\n[1]\n\u2212i,\u2212j (\u03b8)\n}\n,(2.3)\nF\u0302\u2212i,\u2212j (y|\u03b8TXi) =\n{ \u2211\ni1 : i1 \u0005=i,j\nwi1;\u2212i,\u2212j (\u03b8)I (Yi1 \u2264 y)\n}\n\u00d7\n{ \u2211\ni1 : i1 \u0005=i,j\nwi1;\u2212i,\u2212j (\u03b8)\n}\u22121\n.\nWrite simply F(y|z) for P(Y \u2264 y|\u03b8TX = z), and let A be a subset of d-variate\nspace. In this notation, F\u0302\u2212i,\u2212j (y|\u03b8TXi) is a local linear estimator of F(y|\u03b8TXi),\nbased on data pairs other than the ith and the j th; and\n1\nn\u2212 1\n\u2211\ni : i \u0005=j,Xi\u2208A\nF\u0302\u2212i,\u2212j (y|\u03b8TXi)\nis an estimator of \u03c0\u03b8(A,B) when B = (\u2212\u221e, y].\nAs a rule we take \u03b1 to be a (d + 1)-vector, its first d components denoting\nthe center of A\u03b1 and the last component, r say, its radius. We suppose that\nr \u2208 J = [r1, r2], where 0 \u2264 r1 \u2264 r2 \u2264 \u221e and not both r1 and r2 vanish. In the\ncase r1 = r2 the spheres all have the same radius, and here \u03b1 should be interpreted\nas a d-vector, with integrals over r , in our discussion below, ignored. With this\ninterpretation, our account of methodology applies to the case where r takes values\nin the continuum as well as to that where r is fixed. Clearly the latter instance can\nbe generalized to the case of a finite number of discrete radii.\n1408 P. HALL AND Q. YAO\nOne approach is to average over all spheres A\u03b1 that lie entirely within a given,\nfixed set R. With this in mind, let Q = {\u03b1 :A\u03b1 \u2286 R} be the set of sphere centers\n(and radii, if J is not degenerate). Write F\u0302\u2212j (A, y) for the proportion of the n\u2212 1\nvalues of (Xi, Yi), for i \u0005= j , that satisfy (Xi, Yi) \u2208 A\u00d7 (\u2212\u221e, y]. Put\nS(\u03b8,A) =\nn\u2211\nj=1\n{\nF\u0302\u2212j (A, Yj )\u2212 1\nn\u2212 1\n\u2211\ni : i \u0005=j,Xi\u2208A\nF\u0302\u2212i,\u2212j (Yj |\u03b8TXi)\n}2\n,\n(2.4)\nS(\u03b8) =\n\u222b\nQ\nS(\u03b8,A\u03b1) d\u03b1.\nThe latter represents a particular form of S(\u03b8) in (2.2). In practice, the integration\nover \u03b1 in (2.4) is typically replaced by a sum over a class of selected balls; see (4.1)\nbelow. In fact the asymptotic theory in Section 3 still holds with this discrete\nversion of S(\u03b8) if the same replacement is applied wherever appropriate, including\nin condition (3.3).\nWe choose \u03b8\u02c6 to minimize S(\u03b8) over \u03b8 \u2208 \u0002. Thus, \u03b8\u02c6 may be viewed as an\nestimator of \u03b80, the minimizer (over \u03b8 \u2208 \u0002) of\nS0(\u03b8) =\n\u222b\nQ\nd\u03b1\n\u222b\n{F(A\u03b1, y)\u2212G\u03b8(A\u03b1, y)}2fY (y) dy,(2.5)\nwhere F(A, y) = P {(X,Y ) \u2208 A\u00d7 (\u2212\u221e, y]}, fY denotes the density of Y and\nG\u03b8(A, y) =\n\u222b\nA\nF(y|\u03b8Tx)f (x) dx.(2.6)\nA low-dimensional approximation to FY |X(y|X = x) is therefore F\u02dc\u03b8\u02c6 (y|\u03b8\u02c6Tx),\nwhere F\u02dc\u03b8 (y|z) is an estimator of P(Y \u2264 y|\u03b8TX = \u03b8Tx). Denoting by F\u0302 a local\nlinear version of F\u02dc , we define\nF\u0302\u03b8 (y|\u03b8Tx) =\n{\nn\u2211\ni=1\nwi(x, \u03b8)I (Yi \u2264 y)\n}\/{\nn\u2211\ni=1\nwi(x, \u03b8)\n}\n,(2.7)\nwhere\nwi(x, \u03b8) = K\n{\n\u03b8T(x \u2212Xi)\nh\n}{\nT [2](x, \u03b8)\u2212 \u03b8\nT(x \u2212Xi)\nh\nT [1](x, \u03b8)\n}\n,\nT [k](x, \u03b8) = 1\nnh\nn\u2211\ni=1\nK\n{\n\u03b8T(x \u2212Xi)\nh\n}{\n\u03b8T(x \u2212Xi)\nh\n}k\n.\nOur empirical, low-dimensional approximation to FY |X(y|X = x) is taken to\nbe F\u0302\n\u03b8\u02c6\n(y|\u03b8\u02c6Tx), and is of course an estimator of P(Y \u2264 y|\u03b8T0 X = \u03b8T0 x).\nESTIMATING CONDITIONAL DISTRIBUTIONS 1409\n2.3. Empirical bandwidth choice\u2014a rule of thumb. Two bandwidths need to\nbe chosen: h for estimating \u03b8 , and H for estimating F\n\u03b8\u02c6\n(y|\u03b8\u02c6Tx) with \u03b8\u02c6 given.\nIn such nonstandard problems, conventional bandwidth selection methods for\nnonparametric regression are either tedious to apply (as in the case of plug-in\nmethods), or do not facilitate obvious analogies (e.g., cross-validation and its\nvariants). Note that with \u03b8\u02c6 given, estimation of F\n\u03b8\u02c6\n(y|\u03b8\u02c6Tx) has been investigated\nby, among others, Hall, Wolff and Yao (1999). They proposed a bootstrap method\nbased on an approximating parametric model to determine the bandwidth, which\nwe will adopt for estimating H . Furthermore, we outline a similar empirical\nprocedure below for determining h.\nFirst we fit the linear model\nYi = \u03b20 + \u03b2TXi + \u03b5i.(2.8)\nLet \u03b2\u02c70 and \u03b2\u02c7 be the estimators derived by, for example, least squares, and let\n\u03b5\u02c61, . . . , \u03b5\u02c6n denote the centered residuals. We shall compute a bootstrap sample\n{Y \u22171 , . . . , Y \u2217n } from the model\nY \u2217i = \u03b2\u02c70 + \u03b2\u02c7TXi + \u03b5\u2217i ,(2.9)\nwhere {\u03b5\u2217i } denotes a conventional bootstrap resample drawn by sampling with\nreplacement from {\u03b5\u02c6i}. Then the conditional distribution of Y \u2217i , given Xi , depends\non Xi through \u03b2\u02c7TXi alone. Let \u03b2\u02c6\u2217 = \u03b2\u02c6\u2217(h) be the estimator obtained in the\nsame manner as \u03b8\u02c6 but with the data (Xi, Yi) replaced by their resampled\ncounterparts (Xi, Y \u2217i ); see Section 2.2. We choose h to minimize\nM1(h) = E[\u2016\u03b2\u02c6\u2217 \u2212 \u03b2\u02c7\u20162|{(Xi, Yi)}].(2.10)\nIt is important that the two bandwidths h and H should be different. As we\nshall show in Section 3, optimal performance is achieved if h is of smaller order\nthan H . The simulation results reported in Section 4 indicate that the bandwidths\nselected by the bootstrap methods discussed above produce estimators with good\nperformance.\n3. Theory. For simplicity we discuss only the case where the data (Xi, Yi)\nare independent. Analogues of our main results, Theorems 3.1 and 3.2, may be\nderived for dependent data, in particular for sequences of pairs (Xi, Yi) that satisfy\nsufficiently strong mixing conditions. The case of dependence will be explored\nnumerically in Section 4.\nLet us first define the vector of derivatives, a\u02d9, of a function a of \u03b8 \u2208 \u0002.\nLet \u03c91, . . . ,\u03c9d\u22121 be orthonormal vectors all perpendicular to \u03b8 , put \u03c9i\u03b4 = (1 \u2212\n\u03b42)1\/2\u03b8 + \u03b4\u03c9i for a scalar \u03b4 and set\nbi = lim\n\u03b4\u21920 \u03b4\n\u22121{a(\u03c9i\u03b4)\u2212 a(\u03b8)},\n1410 P. HALL AND Q. YAO\nassuming the limit exists and is finite. Then\na\u02d9(\u03b8) \u2261 \u2211\n1\u2264i\u2264d\u22121\nbi\u03c9i,\na vector in the plane perpendicular to \u03b8 . Similarly we may define the matrix, a\u00a8, of\nsecond derivatives of a.\nLet (X,Y ) have the distribution of a generic pair (Xi, Yi). We shall assume that\nthe density of (X,Y ) has four bounded derivatives,\nand all moments of Y are finite.(3.1)\nThe bandwidth h will be permitted to vary within a range, effectively from n\u22121\/3\nto n\u22121\/4; see (3.4) below. If we were confining attention to the lower end of this\nrange, then we could reduce the smoothness assumption in (3.1) from four bounded\nderivatives to three derivatives plus a H\u00f6lder continuity condition. In this sense, the\nsmoothness required by (3.1) is excessive.\nRecall that if sphere radii vary in the continuum, then Q denotes a set of sphere\ncenters and radii, while if there is a single, fixed radius, then Q is a set just of\nsphere centers. In either case, all spheres in Q are completely contained within R;\nsee the definition of Q in Section 2.2. We shall suppose that\nR is an open, bounded set; the density of X is bounded\naway from zero on R; and the content of Q is nonzero.(3.2)\nIn particular, this and (3.1) ensure that the density of the distribution of \u03b8TX\nis bounded away from zero on the set of points \u03b8Tx with x \u2208 A \u2286 R.\nAssumption (3.2) may therefore be viewed as the analogue of the condition,\nimposed in more standard problems of nonparametric regression, that the design\ndensity is bounded above zero.\nConditions (3.1) and (3.2) imply a range of smoothness properties of the marg-\ninal density f\u03b8TX and the conditional distribution F(y|z) = P(Y \u2264 y|\u03b8TX = z).\nFor example, the k1th derivative with respect to \u03b8 , of the k2th derivative with\nrespect to z, of either f\u03b8TX(z) or F(y|z), is well defined and bounded in\nk1 + k2 \u2264 4, y, \u03b8 \u2208 \u0002 and z = \u03b8Tx for x \u2208 R.\nRecall the definition of G\u03b8(A, y) in (2.6), and let G\u02d9\u03b8 (A, y) and G\u00a8\u03b8 (A, y)\ndenote, respectively, the vector of first derivatives and the matrix of second\nderivatives of G\u03b8(A, y) with respect to \u03b8 , with (A, y) held fixed. Note that\n\u03b80 = arg min\u03b8 S0(\u03b8), where S0 is defined in (2.5).\nPut\nM(\u03b8) =\n\u222b\nQ\nd\u03b1\n\u222b\n[G\u02d9\u03b8 (A\u03b1, y)G\u02d9\u03b8 (A\u03b1, y)T\n\u2212 {F(A\u03b1, y)\u2212G\u03b8(A\u03b1, y)}G\u00a8\u03b8 (A\u03b1, y)]fY (y) dy,\nESTIMATING CONDITIONAL DISTRIBUTIONS 1411\na d \u00d7 d matrix. By assuming that\n\u03b8 = \u03b80 gives a unique global minimum of S0(\u03b8), and\n\u03c9TM(\u03b80)\u03c9 > 0 for each nonvanishing vector \u03c9 \u22a5 \u03b80,(3.3)\nwe require an equivalent condition that S0(\u03b8) \u2192 S0(\u03b80) at exactly the rate\n\u2016\u03b8 \u2212 \u03b80\u20162 as \u03b8 \u2192 \u03b80. Of the kernel K and bandwidth h we shall assume that\nK is nonnegative, symmetric and compactly supported, and\nhas a bounded derivative; and, for some \u03b5 > 0, h = h(n)\nsatisfies h = O(n\u2212\u03b5\u2212(1\/4)) and n\u2212(1\/3)+\u03b5 = O(h) as n \u2192 \u221e.\n(3.4)\nThe most important aspect of this assumption is that it implies h should lie\nbetween n\u22121\/3 and n\u22121\/4, and so should be an order of magnitude smaller than\na conventional bandwidth for estimating a univariate function by nonparametric\nregression. A conventional bandwidth would be of size n\u22121\/5.\nLet \u03c6\u03b8TX|A denote the density of \u03b8TX conditional on X \u2208 A, and define\n\u03c8(A, x1, y1, y, \u03b8) = {I (y1 \u2264 y)\u2212 F(y|\u03b8Tx1)}(3.5)\n\u00d7\n{\nI (x1 \u2208 A)\u2212\n\u03c6\u03b8TX|A(\u03b8Tx1)P (X \u2208 A)\nf\u03b8TX(\u03b8\nTx1)\n}\n.\n[The ratio in this definition is guaranteed well defined, since P(X \u2208 A)\u03c6\u03b8TX|A \u2264\nf\u03b8TX .] Let V denote the Gaussian d-vection with zero mean and covariance matrix\nequal to that of\nW =\n\u222b\nQ\nd\u03b1\n[\u222b\n\u03c8(A\u03b1,X,Y, y, \u03b8)G\u02d9\u03b80(A\u03b1, y)f (y) dy\n+ {F(A\u03b1,Y )\u2212G\u03b80(A\u03b1,Y )}G\u02d9\u03b80(A\u03b1,Y )]d\u03b1.\nLet \u2016 \u00b7 \u2016 denote the Euclidean metric in d-variate space, and recall that \u03b8\u02c6 is defined\nto be the global minimizer of S(\u03b8) in (2.4).\nTHEOREM 3.1. Assume conditions (3.1)\u2013(3.4). Then \u03b8\u02c6 \u2192 \u03b80 with probabil-\nity 1, and n1\/2M(\u03b80)(\u03b8\u02c6 \u2212 \u03b80) converges in distribution to V as n \u2192 \u221e.\nTo appreciate the implications of this result, let \u03b8\u02c6\u22a5 denote the projection of \u03b8\u02c6\ninto the plane \u000b\u22a5 that is perpendicular to \u03b80. (Equivalently, \u03b8\u02c6\u22a5 is the projection\nof \u03b8\u02c6 \u2212 \u03b80 into \u000b\u22a5.) The first part of Theorem 3.1 implies that \u2016\u03b8\u02c6 \u2212 \u03b80\u2016 \u2192 0 with\nprobability 1, from which it follows (since \u03b8\u02c6 and \u03b80 are both unit vectors) that\n\u03b8\u02c6 \u2212 \u03b80 = \u03b8\u02c6\u22a5 + o(\u2016\u03b8\u02c6 \u2212 \u03b80\u2016)(3.6)\nwith probability 1. That is, in first-order asymptotic terms, \u03b8\u02c6 \u2212 \u03b80 is completely\ndescribable through the projection of this vector into the plane perpendicular to \u03b80.\n1412 P. HALL AND Q. YAO\nNote that, by definition of differentiation with respect to \u03b8 , the vector G\u02d9\u03b8\nis perpendicular to \u03b8 . It therefore follows from the definition of V that, with\nprobability 1, V lies completely in \u000b\u22a5. Observe too that, in view of (3.3), there\nis a generalized inverse of M0 = M(\u03b80) (call it M\u22120 ) that is well defined in \u000b\u22a5.\nIt has the property that\nM0M\n\u2212\n0 v = M\u22120 M0v = v for all v \u2208 \u000b\u22a5.\nThese results, Theorem 3.1 and (3.6) imply that n1\/2(\u03b8\u02c6 \u2212 \u03b8) converges in\ndistribution to M\u22120 V .\nOf course, our main purpose in computing \u03b8\u02c6 is so it can be used in a conditional\ndistribution estimator, such as F\u0302\u03b8 introduced in (2.7). Theorem 3.2 below shows\nthat the root-n consistency achieved by the estimator \u03b8\u02c6 makes that quantity\nso accurate that, from the viewpoint of first-order performance, the estimator\nF\u0302\n\u03b8\u02c6\n(y|\u03b8\u02c6Tx) is equivalent to its counterpart which would be employed if the value\nof \u03b80 were known. This result has analogues for general choice of the bandwidth\nused for F\u0302\u03b8 ; they describe a range of circumstances where the leading bias and\nvariance terms do not include the effect of estimating \u03b8 . However, for the sake of\nsimplicity and brevity we shall treat only the optimal size of bandwidth.\nThe latter size is n\u22121\/5, and when that is employed, F\u0302\u03b80(y|\u03b8T0 x) converges to\nits limit at rate n\u22122\/5. We shall show in Theorem 3.2 that the difference between\nF\u0302\n\u03b8\u02c6\n(y|\u03b8\u02c6Tx) and F\u0302\u03b80(y|\u03b8T0 x) is then of strictly smaller order than n\u22122\/5.\nThese considerations motivate the following assumption:\nthe bandwidth H used to construct F\u0302\u03b8 has the property that\nn1\/5H is bounded away from zero and infinity as n \u2192 \u221e; and\nthe kernel is nonnegative, symmetric, compactly supported\nand has a bounded derivative.\n(3.7)\nNote that H and h are of different orders, the former being of size n\u22121\/5 and the\nlatter of smaller order. We shall reduce the stringency of (3.1), assuming instead\nthat\nthe density of (X,Y ) has two continuous derivatives,\nand all moments of Y are finite.(3.8)\nAs the following theorem shows, we do not need the full force of the result that\n\u03b8\u02c6 \u2212 \u03b80 = Op(n\u22121\/2); the convergence rate op(n\u22122\/5) suffices.\nTHEOREM 3.2. Assume (3.2), (3.7), (3.8), that x \u2208 R, and that \u03b8\u02c6 \u2212 \u03b80 =\nop(n\n\u22122\/5) as n \u2192 \u221e. Then for each y,\nF\u0302\n\u03b8\u02c6\n(y|\u03b8\u02c6Tx) = F\u0302\u03b80(y|\u03b8T0 x)+ op(n\u22122\/5).\nESTIMATING CONDITIONAL DISTRIBUTIONS 1413\nIt follows from the asymptotic normality of local linear regression estimation\n[see, e.g., Theorem 1 of Fan, Heckman and Wand (1995), and Remark 4 of Hall,\nWolff and Yao (1999)] that the estimator F\u0302\u03b80(y|\u03b8T0 x) is asymptotically normally\ndistributed with convergence rate n\u22122\/5. By Theorem 3.2 above, F\u0302\n\u03b8\u02c6\n(y|\u03b8\u02c6Tx)\nand F\u0302\u03b80(y|\u03b8T0 x) have the same asymptotic distribution.\n4. Numerical properties. We approximate the integral in (2.4) by a series,\nS(\u03b8) = 1\nB\nB\u2211\ni=1\nS(\u03b8,Ai),(4.1)\nwhere the Ai\u2019s are spheres of radius r contained within R. In practice one would\nselect a value of B that permitted the calculations to be completed within a\nreasonable time, and compute estimates for that value as well as for substantially\nsmaller ones, say half and three-quarters of the initial B . Provided there was little\nvariation in the results, the larger B would be appropriate. The results reported in\nthis section show that choice of B has little effect on final results.\nIn the numerical examples below we searched for \u03b8 (with h fixed) using the\ndownhill simplex method; see Section 10.4 of Press, Teukolsky, Vetterling and\nFlannery (1992). Using the Epanechnikov kernel, the bandwidths were sought\namong values hi = 0.1 \u00d7 1.2i\u22121 for i = 1, . . . ,15, based on the bootstrap methods\noutlined in Section 2.3. We used sample sizes n = 200 and 400. Each setting was\nreplicated 50 times. Throughout Examples 1 and 2 below we took Xij and \u03b5i to be\ntotally independent N(0,1) random variables.\nEXAMPLE 1. Here we consider the model\nYi = \u03b81Xi1 + \u03b82Xi2 + \u03b83Xi3 + \u03b84Xi4 + \u03b5i,\nwhere \u03b8T \u2261 (\u03b81, . . . , \u03b84) = (1,2,0,3)\/\n\u221a\n14. Thus, the conditional distribution\nof Y , given X \u2261 (X1, . . . ,X4)T, is N(\u03b8TX,1). We let the radius be r = 1, and\nsphere centers be points (x1, x2, x3, x4), where each xj ranged over either five or\nseven grid points between \u22121.5 and 1.5, with spacing 0.75 or 0.5, respectively,\nresulting in B = 625 or B = 2401.\nFigure 1(a)\u2013(c) presents boxplots of the inner product \u03b8T\u03b8\u02c6 , where, respectively,\nthe bandwidth h was computed by minimizing (2.10), or taken equal to the latter\nvalue multiplied by 1.5 or 0.7. Since both \u03b8 and \u03b8\u02c6 are unit vectors, \u03b8T\u03b8\u02c6 = 1 if\nand only if \u03b8 = \u03b8\u02c6 . We see from Figure 1(a)\u2013(c) that the estimates of \u03b8 become\nsteadily more accurate as sample size increases. Moreover, the algorithm is largely\ninsensitive to the bandwidths used in the search; the estimates of \u03b8 with the\nthree different bandwidths differ only a little. Furthermore, the algorithm is also\ninsensitive to the value of B .\n1414 P. HALL AND Q. YAO\nFIG. 1. Simulation results for Example 1. Boxplots of the inner product \u03b8\u02c6T\u03b8 , with bandwidth h\ntaken equal to (a) h\u02c6, (b) 1.5h\u02c6, and (c) 0.7h\u02c6; and of (d) h\u02c6, (e) H\u0302 , and (f ) average absolute errors of\nestimated conditional distribution of Y given \u03b8TX with either \u03b8 = \u03b8\u02c6 (denoted by \u201cE\u201d) or \u03b8 equal to\nits true value (denoted by \u201cT\u201d).\nFigure 1(d) and (e) displays boxplots of the bandwidths h, obtained by\nminimizing M1 in (2.10), and H , defined by the method of Hall, Wolff and Yao\nESTIMATING CONDITIONAL DISTRIBUTIONS 1415\n(1999). As expected, empirical bandwidth is a decreasing function of sample size.\nNote too that selected h\u2019s are in general noticeably smaller than the chosen H ,\nwhich is in agreement with the asymptotic orders of h and H .\nWe also calculated values of the local linear estimator defined in (2.7) with\nbandwidth H . Figure 1(f ) gives average absolute errors, computed using a regular\ngrid (with adjacent points distant 0.05 apart) in the (\u03b8TX,Y )-plane. For the sake of\ncomparison we also report the errors for the estimators based on the true \u03b8 . Clearly,\naccuracy increases with sample size, and estimators based on \u03b8\u02c6 are less accurate\nthan those based on the true \u03b8 . However, the deficit due to errors in estimating \u03b8\nis not great when n = 200, and is negligible when n = 400. Choice of radius r is\nnot critical either; results with r = 0.5 and 1.5 are similar to those for r = 1, and\ntherefore are not reported here.\nEXAMPLE 2. Next we consider the model\nYi = 12(sinXi1 + sinXi2 + sinXi3 + sinXi4)+ \u03b5i.\nNow the conditional distribution of Y given X = (X1, . . . ,X4)T no longer depends\non a linear combination of X. The true value of \u03b8 is (0.5,0.5,0.5,0.5)T; note the\nsymmetry of the model. We selected the spheres in the same way as in Example 1.\nThe numerical results are presented in Figure 2, which displays a similar pattern\nto Figure 1 although the estimates in general are not as accurate as in Example 1.\nThis is due to the fact that we were estimating the least-squares approximation, in\nthe sense of minimizing (4.1), of the conditional distribution of Y given X, rather\nthan the conditional distribution itself. Figure 2(a)\u2013(c) shows that the estimation\nfor \u03b8 is still accurate, even for the sample size n = 200, and is steadily improved\nwhen n is increased to 400.\nEXAMPLE 3. Finally we illustrate our method with {Yt , 1 \u2264 t \u2264 176} the\nquarterly growth rates of US real GNP between February 1947 and January 1991.\nThe data series is plotted in Figure 3. This dataset has been analyzed by, for\nexample, Tiao and Tsay (1994). Let Xt = (Yt\u22121, Yt\u22122)T. We estimated the value\nof \u03b8 = (\u03b81, \u03b82)T for which the conditional distribution of Yt , given \u03b8TXt , was the\nbest approximation for the conditional distribution of Yt given Xt , in the sense\nthat S(\u03b8), defined at (4.1), was minimized. We first standardized the data Xt .\nSphere centers were taken to be the points Xt (so that B = n), with radius r = 1.\nThe resulting estimate is \u03b8\u02c6 = (0.580,\u22120.815)T.\nOnce \u03b8\u02c6 was obtained we constructed the adjusted Nadaraya\u2013Watson es-\ntimator F\u0302 (\u00b7|z) [see Hall, Wolff and Yao (1999)] of the conditional distri-\nbution of Yt , given \u03b8\u02c6TXt = z. The resulting quantile prediction interval is\n[F\u0302\u22121(12\u03b1|z), F\u0302\u22121(1 \u2212 12\u03b1|z)], for \u03b1 \u2208 (0,1). To check on performance we used\nthe first 166 data points to estimate \u03b8\u02c6 and F\u0302 (\u00b7|z), and employed the last ten data\n1416 P. HALL AND Q. YAO\nFIG. 2. Simulation results for Example 2. Panels show the same information as in Figure 1.\npoints to validate the predicted values. Results with \u03b1 = 0.1 are reported in Table 1.\nNote that with \u03b8\u02c6 = (0.580,\u22120.815)T, the predictor is 0.580Yt\u22121 \u2212 0.815Yt\u22122. For\ncomparison we also report prediction intervals using a single predictor Yt\u22121, and\na two-dimensional predictor (Yt\u22121, Yt\u22122).\nESTIMATING CONDITIONAL DISTRIBUTIONS 1417\nFIG. 3. Prediction intervals for US quarterly GNP growth Xt based on, respectively, three different\npredictors 0.580Xt\u22121 \u2212 0.815Xt\u22122, Xt\u22121 and (Xt\u22121,Xt\u22122).\nAll the intervals in the table contain the corresponding true values. Prediction\nintervals based on two predictors Yt\u22121 and Yt\u22122 are more accurate, in general,\nthan those based on a single predictor Yt\u22121, since the average length of the\nprediction intervals is reduced from 3.51 to 3.21. It is interesting to see that\nthe average length of the prediction intervals based on the selected single\npredictor 0.580Yt\u22121 \u2212 0.815Yt\u22122 is 3.22, which is almost the same as that based\non (Yt\u22121, Yt\u22122). Note too that our method does not use multivariate smoothing\ntechniques, which are susceptible to the \u201ccurse of dimensionality.\u201d Predictions\nbased on d = 3 and 4 did not lead to significant improvements, and therefore\nare omitted. The absence of improvement is in agreement with results of Tiao\nand Tsay (1994), who proposed nonlinear, second-order autoregressive models for\nthis dataset.\nTABLE 1\nTrue value 0.580Xt\u22121 \u2212 0.815Xt\u22122 Xt\u22121 (Xt\u22121,Xt\u22122)\n0.67 [ \u22120.99,2.32] [ \u22120.99,2.32] [ \u22120.62,3.11]\n0.89 [ \u22120.91,2.32] [ \u22120.88,2.34] [ \u22120.59,2.28]\n0.40 [ \u22120.99,2.20] [ \u22121.56,2.54] [ \u22120.86,2.34]\n0.43 [ \u22120.91,2.34] [ \u22120.99,2.32] [ \u22120.62,3.11]\n0.09 [ \u22120.91,2.28] [ \u22120.88,2.34] [ \u22120.59,2.21]\n0.42 [ \u22120.99,2.20] [ \u22121.56,2.54] [ \u22121.17,2.34]\n0.11 [ \u22120.88,2.32] [ \u22120.99,2.32] [ \u22120.62,2.32]\n0.36 [ \u22120.91,2.34] [ \u22120.88,2.34] [ \u22120.59,2.12]\n\u22120.40 [ \u22120.99,2.34] [ \u22121.56,2.54] [ \u22120.86,2.54]\n\u22120.65 [ \u22120.81,2.32] [ \u22120.91,2.32] [ \u22120.91,2.32]\nAverage length 3.22 3.51 3.21\n1418 P. HALL AND Q. YAO\n5. Outlines of technical arguments.\nOUTLINE PROOF OF THEOREM 3.1. Our argument has two main stages,\nshowing, respectively, that\n\u2016\u03b8\u02c6 \u2212 \u03b80\u2016 = Op(n\u03b5\u2212(1\/2)) for each \u03b5 > 0,(5.1)\nS(\u03b8) = T + (\u03b8 \u2212 \u03b80)TM0(\u03b8 \u2212 \u03b80)\u2212 2(\u03b8 \u2212 \u03b80)T(V1 + V2)(5.2)\n+ op(\u2016\u03b8 \u2212 \u03b80\u20162)+Op\n(\u2211\u2016\u03b8 \u2212 \u03b80\u2016un\u2212v\u2212\u03b6),\nwhere T does not depend on \u03b8 , \u03b6 > 0 is fixed,\nV1 =\n\u222b\ndF\u0302 (y)\n\u222b\nRr\nG\u02d9\u03b80(A\u03b1, y)\u03ben(A\u03b1, y, \u03b80) d\u03b1,\nV2 =\n\u222b\ndF\u0302 (y)\n\u222b\nRr\nD\u03b80(\u03b1, y)G\u02d9\u03b80(A\u03b1, y) d\u03b1,\n\u03ben(A, y, \u03b8) = 1\nn\nn\u2211\ni=1\n[\u03c8(A,Xi, Yi, y, \u03b8)\u2212E{\u03c8(A,X,Y, y, \u03b8)}],\n\u03c8 is as in (3.5), and Op(\u2211\u2016\u03b8 \u2212 \u03b80\u2016un\u2212v\u2212\u03b6 ) denotes a quantity which uniformly\nin \u03b8 is of order no more than that of the sum of \u2016\u03b8 \u2212 \u03b80\u2016un\u2212v\u2212\u03b6 over a fixed, finite\nset of pairs (u, v), where in each case, u, v \u2265 0 and 12u+ v \u2265 1.\nTo give an appreciation of the origin of the terms which make up the Op(\u00b7 \u00b7 \u00b7)\nremainder in (5.2), we note that the contributions to the remainder come from\ndifferent steps in a Taylor expansion of S(\u03b8). In particular, terms of the following\norders arise in that way:\n\u2016\u03b8 \u2212 \u03b80\u2016h2, \u2016\u03b8 \u2212 \u03b80\u2016(nh3\/2)\u22121n\u03b5, \u2016\u03b8 \u2212 \u03b80\u2016n\u2212t\u2212(1\/2),(5.3)\n\u2016\u03b8 \u2212 \u03b80\u20162(nh3)\u22121, (nh3)\u03b5\u22122, n\u2212t\u22121,\nwhere in each case the bound is valid for all \u03b5 > 0 and some t > 0. Noting that,\nby (3.4), n\u03b61\u2212(1\/3) \u2264 h \u2264 n\u2212\u03b62\u2212(1\/4) for constants \u03b61, \u03b62 > 0, and using the upper\nof these bounds when h appears with a positive exponent in (5.3), and the lower\nwhen h appears with a negative exponent, we see that each of the quantities in (5.3)\nmay be written as \u2016\u03b8 \u2212 \u03b80\u2016un\u2212v\u2212\u03b6 for some \u03b6 > 0 and some (u, v) such that\n1\n2u+ v \u2265 1.\nMore detailed proofs of (5.1) and (5.2) can be found in Hall and Yao (2002). To\nillustrate the use of the regularity conditions (3.1)\u2013(3.4), we mention that (3.1)\nis employed to guarantee adequate smoothness of F when Taylor-expanding\nF(Yj |\u03b8Tx) and related functions; that (3.1) and (3.2) together ensure that the\neffective design density is bounded away from zero, which allows us to deal with\nthe denominator of F\u0302\u2212i,\u2212j (Yj |\u03b8TXi) via a stochastic Taylor expansion; that (3.3)\nguarantees that the minimum of S(\u03b8) is attained in the usual quadratic way, or\nESTIMATING CONDITIONAL DISTRIBUTIONS 1419\nequivalently that the matrix M(\u03b80) is of full rank in the (d \u2212 1)-dimensional\nspace of vectors perpendicular to \u03b80; and that one of the applications of (3.4) was\ndescribed in the previous paragraph.\nTaking \u03b8 = \u03b8\u02c6 in (5.2), and noting (5.37), we see that the remainder term\nin (5.2) may be written as Op(\u2211n\u2212(u\/2)\u2212v\u2212\u03b6 ). Since 12u + v \u2265 1 for each\npair (u, v) contributing to the series, and since \u03b6 > 0, then this Op(\u00b7 \u00b7 \u00b7) remainder\nequals op(n\u22121). Theorem 3.1 follows from this form of (5.2), and from the fact\nthat n1\/2(V1 + V2) converges in distribution to V , the latter defined a little before\nthe statement of the theorem. \u0001\nOUTLINE PROOF OF THEOREM 3.2. Let \u0002n denote the set of all \u03b8 \u2208 \u0002 that\nsatisfy \u2016\u03b8 \u2212 \u03b80\u2016 \u2264 \u03b4(n)n\u22122\/5, where \u03b4(n) \u2193 0 as n \u2192 \u221e. The theorem follows\nfrom the following result.\nLEMMA. Assume (3.2), (3.7), (3.8) and that x \u2208 R. Then for each y\nsup\n\u03b8\u2208\u0002n\n\u2223\u2223F\u0302\u03b8 (y|\u03b8Tx)\u2212 F\u0302\u03b80(y|\u03b8T0 x)\u2223\u2223= op(n\u22122\/5).\nWe outline the proof of the lemma. Treat F\u0302\u03b8 as the ratio expressed in (2.7),\nalthough multiply top and bottom there by (nh)\u22121 [here (nH)\u22121, since we take\nthe bandwidth to be H ] in order to ensure that neither the numerator nor\nthe denominator converges to zero or diverges to infinity. The numerator and\ndenominator are now each in the form T1T2 \u2212 T3T4, where each Tj is linear\nin functions of the data Xi and has a proper limit as n diverges. Additively\ndecompose each Tj into its expected value (or mean), and the difference between\nit and its mean. Each mean is of course purely deterministic. In the remainder of\nthis section we shall outline the technique, starting from this decomposition, for\ntreating T1 and T2; a similar argument may be given in the case of T3 or T4.\nThe expected value of T1 or T2 may be written as its \u201cH \u2192 0 limit,\u201d plus a term\nthat equals H 2 multiplied by a function of \u03b8 , plus a remainder that equals o(H 2)\nuniformly in \u03b8 . The \u201cH \u2192 0 limit,\u201d evaluated at \u03b8 , equals the same quantity\nevaluated at \u03b80 rather than at \u03b8 , plus a remainder of order O{\u03b4(n)n\u22122\/5} =\no(n\u22122\/5), uniformly in \u03b8 \u2208 \u0002n; and similarly, the coefficients of H 2 (for \u03b8 and \u03b80,\nresp.) are identical, up to a term that converges to 0 uniformly in \u03b8 \u2208 \u0002n as n \u2192 \u221e.\nThese arguments require only Taylor expansion, and prove that the mean of each\nof the Tj \u2019s equals its counterpart when \u03b8 is replaced by \u03b80, plus terms that are of\nsize o(n\u22122\/5) uniformly in \u03b8 \u2208 \u0002n. A longer argument [see Hall and Yao (2002)]\ncan be used to show that the same property is enjoyed by each Tj \u2212E(Tj ), not just\nby each E(Tj ). The theorem follows from these properties. \u0001\nAcknowledgments. We are grateful to an Editor and two reviewers for helpful\ncomments.\n1420 P. HALL AND Q. YAO\nREFERENCES\nADALI, T., LIU, X. and SONMEZ, M. K. (1997). Conditional distribution learning with neural\nnetworks and its application to channel equalization. IEEE Trans. Signal Processing 45\n1051\u20131064.\nBASHTANNYK, D. M. and HYNDMAN, R. J. (2001). Bandwidth selection for kernel conditional\ndensity estimation. Comput. Statist. Data Anal. 36 279\u2013298.\nBHATTACHARYA, P. K. and GANGOPADHYAY, A. K. (1990). Kernel and nearest-neighbor estimation\nof a conditional quantile. Ann. Statist. 18 1400\u20131415.\nBOND, S. A. and PATEL, K. (2000). The conditional distribution of real estate returns: Relating time\nvariation in higher moments to downside risk measurement. Technical report, Dept. Land\nEconomy, Univ. Cambridge.\nCAI, Z. (2002). Regression quantiles for time series. Econometric Theory 18 169\u2013192.\nFAN, J., HECKMAN, N. E. and WAND, M. P. (1995). Local polynomial kernel regression for\ngeneralized linear models and quasi-likelihood functions. J. Amer. Statist. Assoc. 90\n141\u2013150.\nFAN, J. and YAO, Q. (2003). Nonlinear Time Series: Nonparametric and Parametric Methods.\nSpringer, New York.\nFAN, J., YAO, Q. and TONG, H. (1996). Estimation of conditional densities and sensitivity measures\nin nonlinear dynamical systems. Biometrika 83 189\u2013206.\nFORESI, S. and PARACCHI, F. (1992). The conditional distribution of excess returns: An empirical\nanalysis. Working Paper 92-49, C. V. Starr Center, New York Univ.\nFRIEDMAN, J. H. (1987). Exploratory projection pursuit. J. Amer. Statist. Assoc. 82 249\u2013266.\nFRIEDMAN, J. H. and STUETZLE, W. (1981). Projection pursuit regression. J. Amer. Statist. Assoc.\n76 817\u2013823.\nFRIEDMAN, J. H., STUETZLE, W. and SCHROEDER, A. (1984). Projection pursuit density\nestimation. J. Amer. Statist. Assoc. 79 599\u2013608.\nHALL, P. and HEYDE, C. C. (1980). Martingale Limit Theory and Its Application. Academic Press,\nNew York.\nHALL, P., WOLFF, R. C. L. and YAO, Q. (1999). Methods for estimating a conditional distribution\nfunction. J. Amer. Statist. Assoc. 94 154\u2013163.\nHALL, P. and YAO, Q. (2002). Estimating conditional distribution functions using dimension\nreduction. Research Report 87, Dept. Statistics, London School of Economics. Available\nat www.lse.ac.uk\/collections\/statistics\/documents\/researchreport87.pdf.\nH\u00c4RDLE, W., HALL, P. and ICHIMURA, H. (1993). Optimal smoothing in single-index models. Ann.\nStatist. 21 157\u2013178.\nHUBER, P. J. (1985). Projection pursuit (with discussion). Ann. Statist. 13 435\u2013525.\nHYNDMAN, R. J., BASHTANNYK, D. M. and GRUNWALD, G. K. (1996). Estimating and visualizing\nconditional densities. J. Comput. Graph. Statist. 5 315\u2013336.\nHYNDMAN, R. J. and YAO, Q. (2002). Nonparametric estimation and symmetry tests for conditional\ndensity functions. J. Nonparametr. Statist. 14 259\u2013278.\nICHIMURA, H. (1993). Semiparametric least squares (SLS) and weighted SLS estimation of single-\nindex models. J. Econometrics 58 71\u2013120.\nJONES, M. C. and SIBSON, R. (1987). What is projection pursuit? (with discussion). J. Roy. Statist.\nSoc. Ser. A 150 1\u201336.\nKLEIN, R. and SPADY, R. (1993). An efficient semiparametric estimator for binary response models.\nEconometrica 61 387\u2013422.\nLI, K.-C. (1991). Sliced inverse regression for dimension reduction (with discussion). J. Amer. Statist.\nAssoc. 86 316\u2013342.\nMORAN, P. A. P. (1953). The statistical analysis of the Canadian lynx cycle. I. Structure and\nprediction. Australian J. Zoology 1 163\u2013173.\nESTIMATING CONDITIONAL DISTRIBUTIONS 1421\nPOSSE, C. (1995). Projection pursuit exploratory data analysis. Comput. Statist. Data Anal. 20\n669\u2013687.\nPOWELL, J. L., STOCK, J. H. and STOKER, T. M. (1989). Semiparametric estimation of index\ncoefficients. Econometrica 57 1403\u20131430.\nPRESS, W. H., TEUKOLSKY, S. A., VETTERLING, W. T. and FLANNERY, B. P. (1992). Numerical\nRecipes in C. The Art of Scientific Computing, 2nd ed. Cambridge Univ. Press.\nROSENBLATT, M. (1969). Conditional probability density and regression estimators. In Multivariate\nAnalysis II (P. Krishnaiah, ed.) 25\u201331. Academic Press, New York.\nSHEATHER, S. J. and MARRON, J. S. (1990). Kernel quantile estimators. J. Amer. Statist. Assoc. 85\n410\u2013416.\nTIAO, G. C. and TSAY, R. S. (1994). Some advances in nonlinear and adaptive modeling in time\nseries. J. Forecasting 13 109\u2013131.\nWATANABE, T. (2000). Excess kurtosis of conditional distribution for daily stock returns: The case\nof Japan. Applied Economics Letters 7 353\u2013355.\nYIN, X. and COOK, R. D. (2002). Dimension reduction for the conditional kth moment in regression.\nJ. R. Stat. Soc. Ser. B Stat. Methodol. 64 159\u2013175.\nYU, K. and JONES, M. C. (1998). Local linear quantile regression. J. Amer. Statist. Assoc. 93\n228\u2013237.\nCENTRE FOR MATHEMATICS\nAND ITS APPLICATIONS\nAUSTRALIAN NATIONAL UNIVERSITY\nCANBERRA, ACT 0200\nAUSTRALIA\nE-MAIL: Peter.Hall@maths.anu.edu.au\nDEPARTMENT OF STATISTICS\nLONDON SCHOOL OF ECONOMICS\nHOUGHTON STREET\nLONDON WC2A 2AE\nUNITED KINGDOM\nE-MAIL: Q.Yao@lse.ac.uk\n"}
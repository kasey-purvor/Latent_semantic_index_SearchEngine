{"doi":"10.1007\/978-1-4020-8919-0","coreId":"69315","oai":"oai:eprints.lancs.ac.uk:27254","identifiers":["oai:eprints.lancs.ac.uk:27254","10.1007\/978-1-4020-8919-0"],"title":"Reinforced ART (ReART) for online neural control","authors":["Ediriweera, Damjee D.","Marshall, Ian W."],"enrichments":{"references":[{"id":990284,"title":"A non-computationally-intensive neurocontroller for autonomous mobile robot navigation.","authors":[],"date":"2002","doi":null,"raw":null,"cites":null},{"id":988549,"title":"Adaptive Resonance Theory, In","authors":[],"date":"2003","doi":null,"raw":null,"cites":null},{"id":989705,"title":"ARTMAP: Supervised real-time learning and classification of nonstationary data by a self-organizing neural network,","authors":[],"date":"1991","doi":"10.1016\/0893-6080(91)90012-T","raw":null,"cites":null},{"id":989406,"title":"Chapter eight in The Neural Simulation Language,","authors":[],"date":"2002","doi":null,"raw":null,"cites":null},{"id":988312,"title":"Fuzzy ART: Fast Stable learning and categorization of analogue patterns by an Adaptive Resonance System.","authors":[],"date":"1991","doi":"10.1016\/0893-6080(91)90056-B","raw":null,"cites":null},{"id":988839,"title":"Internally self organising Neural Network for online learning of perception to action mappings in Sensor Networks,","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":990604,"title":"Neural Computing: An Introduction,","authors":[],"date":"1990","doi":null,"raw":null,"cites":null},{"id":989960,"title":"Performance-guided Neural Network for rapidly self-organising Active Network Management,","authors":[],"date":"2004","doi":"10.1016\/j.neucom.2004.03.001","raw":null,"cites":null},{"id":989072,"title":"SeMi-supervised adaptive resonance theory (SMART2), Neural Networks,","authors":[],"date":"1992","doi":null,"raw":null,"cites":null}],"documentType":{"type":null}},"contributors":[],"datePublished":"2008","abstract":"Fuzzy ART has been proposed for learning stable recognition categories for an arbitrary sequence of analogue input patterns. It uses a match based learning mechanism to categorise inputs based on similarities in their features. However, this approach does not work well for neural control, where inputs have to be categorised based on the classes which they represent, rather than by the features of the input. To address this we propose and investigate ReART, a novel extension to Fuzzy ART. ReART uses a feedback based categorisation mechanism supporting class based input categorisation, online learning, and immunity from the plasticity stability dilemma. ReART is used for online control by integrating it with a separate external function which maps each ReART category to a desired output action. We test the proposal in the context of a simulated wireless data reader intended to be carried by an autonomous mobile vehicle, and show that ReART training time and accuracy are significantly better than both Fuzzy ART and Back Propagation. ReART is also compared to a Na\u00efve Bayesian Classifier. Na\u00efve Bayesian Classification achieves faster learning, but is less accurate in testing compared to both ReART, and Bach Propagation","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:27254<\/identifier><datestamp>\n      2018-01-24T02:50:40Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Reinforced ART (ReART) for online neural control<\/dc:title><dc:creator>\n        Ediriweera, Damjee D.<\/dc:creator><dc:creator>\n        Marshall, Ian W.<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        Fuzzy ART has been proposed for learning stable recognition categories for an arbitrary sequence of analogue input patterns. It uses a match based learning mechanism to categorise inputs based on similarities in their features. However, this approach does not work well for neural control, where inputs have to be categorised based on the classes which they represent, rather than by the features of the input. To address this we propose and investigate ReART, a novel extension to Fuzzy ART. ReART uses a feedback based categorisation mechanism supporting class based input categorisation, online learning, and immunity from the plasticity stability dilemma. ReART is used for online control by integrating it with a separate external function which maps each ReART category to a desired output action. We test the proposal in the context of a simulated wireless data reader intended to be carried by an autonomous mobile vehicle, and show that ReART training time and accuracy are significantly better than both Fuzzy ART and Back Propagation. ReART is also compared to a Na\u00efve Bayesian Classifier. Na\u00efve Bayesian Classification achieves faster learning, but is less accurate in testing compared to both ReART, and Bach Propagation.<\/dc:description><dc:date>\n        2008<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/978-1-4020-8919-0<\/dc:relation><dc:identifier>\n        Ediriweera, Damjee D. and Marshall, Ian W. (2008) Reinforced ART (ReART) for online neural control. Lecture Notes in Electrical Engineering, 14 (n\/a). pp. 293-304. ISSN 1876-1100<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/27254\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1007\/978-1-4020-8919-0","http:\/\/eprints.lancs.ac.uk\/27254\/"],"year":2008,"topics":["QA75 Electronic computers. Computer science"],"subject":["Journal Article","PeerReviewed"],"fullText":" \n \n \n  \nAbstract\u2014 Fuzzy ART has been proposed for learning stable \nrecognition categories for an arbitrary sequence of analogue \ninput patterns. It uses a match based learning mechanism to \ncategorise inputs based on similarities in their features. However, \nthis approach does not work well for neural control, where inputs \nrequire to be categorised based on the classes which they \nrepresent, rather than by the features of the input. To address \nthis we propose and investigate ReART, a novel extension to \nFuzzy ART. ReART uses a feedback based categorisation \nmechanism supporting class based input categorisation, online \nlearning, and immunity from the plasticity stability dilemma. \nReART is used for online control by integrating it with a separate \nexternal function which maps each ReART category to a desired \noutput action. We test the proposal in the context of a simulated \nwireless data reader intended to be carried by an autonomous \nmobile vehicle, and show that training time and accuracy are \nsignificantly better than Fuzzy ART and Back Propagation. \n \n \nIndex Terms\u2014 Fuzzy ART, ReART, Back Propagation, Online \nNeural Control. \n \nI. INTRODUCTION \nFuzzy ART is an unsupervised Adaptive Resonance Theory \n(ART) network presented for classifying an arbitrary sequence \nof analogue input patters into stable recognition categories [1], \n[2].  In previous work the use of a standard Fuzzy ART network \nfor online neural control was investigated [3]. Further testing \nhas revealed several weaknesses which limit its potential for \nonline control applications. Therefore, ReART, a modified \nFuzzy ART network designed to address these limitations, is \npresented here. \n \nFuzzy ART is made up of two neuron layers. The first layer \nrepresents its input neurons whereas the second layer \nrepresents its output categories. Fuzzy ART performs match \nbased learning, and therefore the configuration of the output \n \nManuscript received on July 10, 2007. This work was partly funded by the \nEPSRC grant EP\/D053544\/1, and was carried out at the Lancaster University, \nLancaster, LA1 4YQ, U.K. \nD. D. Ediriweera, PhD Student, Lancaster University, Lancaster, LA1 4YQ, \nU.K. (email:damjee@gmail.com) \nI. W. Marshall, Director, Centre for Environmental Informatics, Lancaster \nEnvironment centre, Lancaster University, Lancaster, LA1 4YQ, U.K. (email: \ni.w.marshall@lancaster.ac.uk) \n \nlayer is dynamically determined based on the diversity of the \npresented inputs. The decision of creating a new output \ncategory depends on whether existing categories fail to match \nan input within a defined threshold. Resonance or learning \noccurs only when an input is successfully matched to an \nexisting category, or when a new category is created to handle a \ndistinctly new input. This approach allows Fuzzy ART to \novercome the plasticity-stability dilemma [2], meaning, it is \nable to remain stable for known inputs while being plastic \n(adaptable) towards new ones.  \n \nThe most challenging issue when applying Fuzzy ART for \nonline control is its unsupervised classification nature. Based \non previous experiments, it is revealed that Fuzzy ART often \nclassifies similar input patterns together, with no regard to the \nclass of input which they actually represent. This behaviour of \nunsupervised ART networks is verified by the work of \nChristopher and Daniel [4]. In the context of neural control this \nposes an issue since it means that a single Fuzzy ART category \ncan no longer be mapped to a single output action because a \nsingle category might actually represent many input classes. \n \nFurther, since the classification process in Fuzzy ART is \nmatch based, it can only be controlled using the vigilance \nthreshold. The vigilance value defines the level of similarity \nrequired for an input to be classified under an existing category. \nHowever, the vigilance value in Fuzzy ART is global to the \nentire network, and therefore it defines a single category size \nfor the network. It is often found that inputs in the real world \nregularly represent input classes with varying sizes.  Some \ninput classes can be quite general and large in size, whereas \nothers are quite specific and small. The mismatch between the \ncategory size of an ART network and the class sizes of inputs \nwill often result in inefficient, or inaccurate categorising. Work \npresented here demonstrates that issues outlined above can \nemerge in the form of longer convergence times, unstable \nperformance, and large than optimal neural configurations, \nwhen Fuzzy ART is used for neural control. \n \nThis paper introduces ReART which uses a feedback based \nlearning mechanism to overcome these limitations. The \nfeedback mechanism drives the categorisation process by \nmonitoring external feedback for each individual category and \nusing this information to decide when new categories are \nReinforced ART (ReART): Adapting Fuzzy ART \nfor online neural control \nDamjee D. Ediriweera, and Ian W. Marshall \n \n \n \nrequired. Under this setup the vigilance parameter is typically \nset to a low value to encourage inputs to be classified into an \nexisting category. Although this sometimes results in the \nnetwork classifying different input classes in to a single \ncategory, such misclassifications are quickly detected when a \ncategory generates negative feedback. This feedback acts as a \ntrigger for a new category to be created. This approach allows \nthe network to quickly diagnose and correct misclassifications. \nFurthermore, since the vigilance value does not play a \nprominent role in the classification process the network is able \nto efficiently support input classes of different sizes.  At the \nsame time the network is still able to effectively select the best \ncategory for each input based on the direct access theorem \nwhich guarantees that if a matching output category, U, exists \nfor an input, I, then ART would directly activate U when I is \npresented [5]. This is part of the Winner Take All (WTA) \nactivation mechanism built in to Fuzzy ART. Work presented \nhere demonstrates that the said modifications allow ReART to \nlearn faster relative to Fuzzy ART, with greater accuracy, and \nless number of internal neurons. \n \nII. RELATED WORK \nA review of existing work reveals several ART versions \nwhich have emerged since the original concept. Some of these \ninclude Fuzzy ART, ART-2, ART-3, DART, ARTMAP [6], \nECART, Semi-supervised ART (SMART2) [4], Snap Drift \nlearning (P-ART) [7], Flexible Adaptable-Size Topology \n(FAST) [8], Grow and Represent (GAR), and SF-ART.  \nAlthough a majority of ART networks remain unsupervised, \nseveral attempts have been made at designing supervised and \nreinforced ART networks to cater for different requirements. \n \nARTMAP presents a supervised ART network capable of \nincremental learning of labelled input patterns. ARTMAP \ncomprises two individual ART networks, ART1 and ART2, \nlinked by an associative learning network. Input patterns are \npresented to ART1 and their labels are sent to ART2.  When an \ninput is presented, ART1 makes a prediction which is \nconfirmed by associating it with the winning label of ART2. If a \nwrong prediction is made the network increases the vigilance \nof the winning neuron in ART1 which leads to a different \ncandidate being chosen. The process occurs until the correct \ncategory is chosen. Resonance occurs only when the correct \ncandidate is found. \n \nAnother approach to supervised ART is investigated in \nSMART2 [4]. SMART2 represents a modified ART2 network \nwith a learning mechanism which allows learning only within \nthe same class of inputs. This guarantees that similar input \npatterns from different input classes do not interfere in the \nlearning processes of each other. To complement this, \nSMART2 also incorporates a mechanism of changing the \nlearning rate depending on whether an input is classified \ncorrectly or not. The learning rate is high for inputs which are \nclassified incorrectly. Based on numerical tests SMART2 is \nclaimed to outperform ART2 for classification problems [4]. \n \nThe Snap Drift algorithm presents a feedback based \nmechanism for improving the clustering process of ART [7]. \nThis algorithm is designed for networks operating in \nnon-stationary environments where new inputs are regularly \nreceived. Snap Drift works by altering the learning rate of \nindividual ART categories depending on the feedback received \nby the system. This allows the system to snap away when \nperformance is low, and drift when performance is high, hence \nthe name Snap Drift. The literature indicates that the algorithm \nwas successfully applied for generating automated service \nresponses in a simulated active computer network [7].  \n \nA specific attempt to use an ART based neural network for \nneural control was made by Andres Perez [8]. This work \ninvestigates an approach of combining a ART based Flexible \nAdaptable Size Topology (FAST) network with a \nreinforcement based action selector.  Even though FAST does \nnot employ a supervision mechanism, this work is significant \nhere since it demonstrates the possibility of using ART for \nneural control. The literature indicates that the ART based \nneural controller was used for navigation control on a robot [8]. \n \nIII. REINFORCED ART (REART) \nIn contrast to previous work, ReART uses a new feedback \nbased mechanism to drive the entire categorisation process. \nReART architecture is similar to that of Fuzzy ART. The \nnetwork consists of two neuron fields F1 and F2 (see Fig. 1).  F1 \nconsists of the input neurons whereas F2 represents the \ndynamic category field. \ni1   .    .     .      i3    .    .     .    im     \n \ninput pattern i \nfeedback \nF1 \nF2 \noutput u \n \n  u1         uj     .   .    .    un \nadaptive weights \nW 1 . .  m, 1 . . .n \nnet activity T \nF1 output S \nFig. 1. Architecture of the ReART network \n \n \n \nThe ReART learning algorithm can be summarised as \nfollows:  \n \n\u03c1 \u2248 0 (set a low vigilance value) \nwhile (i not empty) \n{ \n    present input ic (ic = complement coded i) \n    compute activation value Ti for all categories \n    select category with max Ti as winner Uj \n    set Uj output to 1 \n    receive feedback fi \n     \n    if (fi is high)  \n         adapt weights of Uj with new input  \n         (same as Fuzzy ART, wj = U(ic,wj)) \n         update performance of Uj, Ujp = fi \n    else  \n           add 1 to Uj error count, Uje ++  \n                 if (Ujp is high and Uje is low)  \n             (means poor current performance,  \n                 good previous performance, and  \n                 a low error count)  \n                 then high probability of a new category \n           endif \n        if (Ujp is high and Uje is high) \n             (means poor current performance,  \n                 good previous performance, and  \n                 a high error count)  \n                 then high probability of removing category Uj \n         endif \n   endif \n} \n \n \nInputs presented to the network are complement coded to \navoid category proliferation [1]. A complement coded input \npattern, ic, is passed up through adaptive weights, w1...n, which \ncreates an activation value, Ti, at each output category. The \ncategory with the maximum Ti value is selected as the winner. \nFuzzy ART rules are used for the calculation of Ti.  However, \nunlike in Fuzzy ART, ReART encourages the first winner to be \nthe final selection of the network. This is enforced by selecting \na low vigilance value which discourages the network from \ninitiating a re-search for a better match. This approach allows \nReART to construct categories based on input classes rather \nthan by the similarity of input features. This is the primary \ndifference between Fuzzy ART and ReART. Furthermore, \nunlike in Fuzzy ART, ReART does not perform weight \nadaptation at this stage. Weight adaptations are only performed \nwhen external feedback is received. \n \nReART receives feedback based on the model outlined in \nFig. 2. The figure illustrates how ReART is coupled with a \nseparate map function to construct a functional neural \ncontroller, and how ReART receives feedback. The feedback \nreceived by ReART is short-term, meaning it is received on the \nbasis of each action, and therefore it can be easily associated \nwith each individual classification. This information is used for \nthree main purposes: for weight adaptation, for deciding \nwhether to create a new category, or to decide whether to \nremove an existing category. \n \nEach individual class of input generally has its own desired \noutput, and consequently a misclassified input rarely generates \nits desired output, and hence would not result in a positive \nfeedback. Therefore, ReART learning is done only when an \ninput classification receives positive feedback indicating that it \nwas classified under the correct category. This speeds up the \nlearning process by reducing the probability of inputs from \ndifferent input classes interfering with each others learning. \n \nThe process of creating a new category is triggered when \nperformance of an existing category is consistently low, or \nwhen a trend change is detected. Consistently low performance \nis a clear indicator of a single category attempting to classify \ninputs from two or more input classes. Similarly, a category \nwith a history of positive feedback unexpectedly generating \nnegative feedback normally indicates a new input class \ninterfering with the learning of an existing category. ReART \nresponds to misclassification by creating a new category tuned \nat classifying inputs which are causing the problem. This is the \nprimary growth mechanism in ReART, and it is designed to \ncreate new output categories when new input classes are \ndetected. \n \nThe decision of creating a new category is probabilistic. The \nprobability of a new category being created is greatest as soon \nas a misclassification is detected, but decreases over time. \nConversely the probability of removing a category is lowest \nwhen a misclassification is detected, but increases if \nperformance does not improve over time. This approach offers \na poorly performing category the chance to recover by \nseparating its negative feedback generators into a separate \ncategory, but if performance does not improve the probability of \nit being removed approaches a maximum over time. This \nallows ReART to permanently remove categories which are \nstruggling to improve. This is effective at removing poorly \npositioned categories which sometimes form between the \nboundaries of one or more input classes. The probabilistic \napproach for adding and removing categories is chosen to \ncompensate for noise which might temporarily influence \nfeedback. \n \nIV. NUMERICAL EVALUATION OF REART \nThe numerical evaluation of ReART was performed using \nthe control architecture illustrated in Fig. 2. The figure outlines \nhow ReART integrates with an external map function to \n \n \n \nachieve a functional neural controller. At a higher level the \nsystem works by ReART creating categories and the map \nfunction associating them with appropriate output actions. \nBoth networks are driven by external feedback, and operate \nindependently of each other. All outputs of the map function \nare either 1 or 0. The map function discovers desired output \ncombinations for each ReART category based on a trial and \nerror approach. Identical configurations of the map function \nwere used for all experiments; hence its detailed workings are \nnot discussed. Further information can be found here [3]. \n \nSeveral experiments were carried out to evaluate ReART. It \nwas compared against two other neural network architectures: \nFuzzy ART (using the same configuration as in Fig. 2); and \nBack Propagation (BP) [9]. The control problem simulated for \nthe experiments is illustrated in Fig. 3. The selected control \ntask is a neural based management of wireless communication \non a mobile data reader. The objective of the controller is to \noptimize the power consumption of the wireless reader by \nmanaging communication distance, avoiding radio \ninterference, adapting to host conditions, and by detecting \nerrors. To achieve this, the network uses four inputs, and up to \neight output combinations. The input set includes the Radio \nSignal Strength Indicator (RSSI), Bit Error Rate (BER), Data \nRate (DR), and the Transmitter Power Level (TPL); all values \nmonitored from the wireless reader. Possible output behaviours \ninclude, moving the reader closer to the transmitter, enforcing \ntemporary radio silence, staying neutral (meaning continue \ncurrent transmission), logging errors, and other possible \ncombinations of the above. \n \nA dataset of 1200 input sets was recorded form a live \nenvironment. The dataset captured five distinct input classes. \nEach input class was assigned with a desired output action \nbased on real world considerations. The desired output patterns \nwere used to generate feedback for the ReART controller, and \nto calculate the Mean Square Error for BP. Feedback for \nReART was binary, positive feedback was provided when an \naction was correct, and negative feedback otherwise. \nExperiments were run exhaustively, and all results were \naveraged over 500 independent runs. 75% of the dataset was \nused for training and 25% was reserved for testing. A 5% noise \ncomponent was introduced to both datasets. To simulate \nrealistic conditions inputs were presented to the network in \ntheir natural order, each run starting at a random point in the \ntraining dataset. \n \nV. RESULTS AND ANALYSIS \nFig. 4 compares the performance of ReART with BP and \nseveral Fuzzy ART configurations using different vigilance \nvalues. Results clearly illustrate ReART outperforming both \nBP and Fuzzy ART under tested conditions. ReART achieves \nan accuracy of over 90% within an average of 1 epoch, whereas \nto achieve the same BP requires an average 12.78 epochs, and \nthe best Fuzzy ART configuration requires an average of 17.23 \nepochs. The BP configuration used for the experiment was \nselected after testing a range of configurations and therefore is \nbelieved to be optimal for the specified problem. \ni1    .   .       .   .    im  \n \ninput pattern i \noutput action a \n \na1    .    .    .   an  \n \nReART winner Uj \nF1 \nF2 M1 \nM2 \nReART network map function \nfeedback fi  \nFig. 2. Neural controller constructed using ReART \nnet activity \nT F1 output S \nadaptive \nweights W \nTransmitter \nPower Level \nBit Error \nRate \nData \nRate \nRadio Signal \nStrength Indicator \n \n \n \nNeural \nController \n(1) Move Closer \n(0) Do Nothing \n(1) Radio Silence \n(0) Do Nothing \n \nPerformance \n  \/ Mean Square Error \n \nFeedback \nExpected \nOutput \n(1) Log Error  \n(0) Do Nothing \nFig. 3. Experiment setup \n \n \n \n \nTable. I \n \n \nNetwork Type Max \nTraining \nAccuracy \nAchieved \nWhen Max \nAccuracy \nOccurs (Avg. \nepoch) \nWhen >=90 \nAccuracy \nOccurs (Avg. \nepoch) \nWhen >=95 \nAccuracy \nOccurs (Avg. \nepoch) \nWhen \u2248100 \nAccuracy \nOccurs (Avg. \nepoch) \nTesting \nAccuracy \nAvg. No of \nCategories \nAvg. No of \nCategories with \nmultiple input \nclasses \n         \nReART 100% 71.30 1.00 2.48 11.86 98.42% 6.57 0.0 \nBP (4-5-3) 100% 1580.75 12.78 21.32 81.25 99.84% 5.00 0.0 \nFunzzy ART (0.2) 76.01% 27.88 Never Never Never 73.24% 2.97 2.3 \nFunzzy ART (0.4) 77.22% 41.61 Never Never Never 74.92% 5.75 2.9 \nFunzzy ART (0.6) 85.25% 64.28 Never Never Never 82.54% 12.42 3.7 \nFunzzy ART (0.8) 94.67% 129.59 17.23 Never Never 92.83% 31.92 4.6 \n \n \n \nThe accuracy recorded in Fig. 4 indicates the number of \ncorrect actions observed for the most recent 100 inputs. An \naccuracy of 90 literally indicates 90 correct actions and 10 \nincorrect ones within the last 100 inputs. The axis indicating \naccuracy in Fig. 4 is scaled between 70 and 100 to improve \nclarity. The notation BP (I, H, O) is used to identify a BP \nnetwork with, I, input neurons, H, hidden neurons and, O, \noutput neurons, and the notation Fuzzy ART (\u03c1) is used to \nidentify a Fuzzy ART network with a vigilance value of \u03c1.  \n \nReART, compared with BP is able to learn faster. Table. I \nreveals that both ReART and BP are able to reach a training \naccuracy near 100%, but ReART achieves this several \nmagnitudes faster than BP. The extra training allows BP to \ngeneralise better as indicated by the higher BP testing accuracy \nof 99.84%, compared to the 98.42% of ReART. BP also uses \nrelatively fewer internal neurons to achieve a similar level of \naccuracy; however, it is common knowledge that identifying \nthe correct BP configuration is not straight forward. \n \nA comprehensive comparison of ReART with Fuzzy ART is \nprovided in Table. I. Figures here demonstrate the difficulties \nin selecting a global vigilance value to fit an entire dataset. \nFour separate Fuzzy ART configurations with different \nvigilance values were tested. No configurations were \ndiscovered which were able to efficiently classify the inputs \ncorrectly. Fuzzy ART (0.8) achieves the best accuracy of \n92.83% but uses approximately 32 categories.  In contrary \nFuzzy ART (0.2) creates approximately 3 categories but fails to \nexceed an accuracy of 76.01%.  \n \nIn Fuzzy ART the lower vigilance values struggle to \nprecisely separate input patterns belonging to different input \nclasses, whereas the higher vigilance values do a better job but \nresults in multiple categories representing single input classes. \nThis is clearly indicated by column nine of Table. I which \nidentifies the number of categories which were classifying \nmultiple input classes at the end of the training. The percentage \nof such categories in the network has a direct relationship with \nthe network vigilance and its performance. Fuzzy ART (0.2) \nhad almost 77% of its clusters classifying multiple input classes \nwith a maximum accuracy of 73.24%, whereas Fuzzy ART \n(0.8) had 14% of its clusters classifying multiple input classes \nwith a maximum performance of 92.83%. Based on these \nresults it is clear that none of the tested Fuzzy ART \nconfigurations were able to match the performance of ReART \nwhich achieved a training accuracy of 100% with only 6 to 7 \ncategories. \n70\n75\n80\n85\n90\n95\n100\n5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100\nTraining epoch\nFig. 4.  Network accuracy vs. training epoch \nFuzzy ART (0.2) \nFuzzy ART (0.8) \nBP (4-5-3) \nReART \nA\ncc\nur\nac\ny \n%\n \n \n \n \nIn addition to its ability to learn quickly with high accuracy, \nthe ReART based controller is also able to address the plasticity \nstability dilemma. The plasticity stability dilemma outlines a \nproblem which prevents most neural networks from learning \nnew inputs while preserving previously gathered knowledge. \nEven a popular and robust control mechanism such as BP is \ninherently troubled by this problem. Fig. 5 illustrates a \ncomparison of BP and ReART when presented with the \nplasticity stability dilemma. Here each network was initially \nallowed to train for 100 epochs. At the 100 epoch mark 50 new \ninput patterns were introduced to the dataset. New patterns \nrepresented a new input class with its own desired output \naction. Both networks were then trained for an additional 100 \nepochs. The performance response of both networks is \npresented in Fig. 5. The axis indicating network accuracy is \nscaled between 70 and 100 to improve clarity. \n \nResults indicate ReART to handle new inputs with greater \neffectiveness than BP. The introduction of new inputs causes \nReART accuracy to temporarily drop to 97%, but recovers \nquickly within few epochs to an approximate 100%. The \nReART network responded to the new input class by creating a \nnew category to classify it. This allows it to learn a new input \nwith minimum impact on its existing knowledge and accuracy. \nBP performance under identical conditions is less effective. BP \nis able to reach an initial accuracy of 96% to 97% with 100 \nepochs of training. The introduction of new inputs to BP causes \nits accuracy to drop to 94%, but unlike in ReART the accuracy \nfails to recover beyond this during the rest of the 100 epochs of \ntraining. The BP network recovers to its original accuracy \napproximately after 175 to 195 additional epochs of training. \nThe result is as expected since BP learning does not necessarily \ncater for network adaptability. \nVI. CONCLUSION \nSeveral limitations restricting the use of Fuzzy ART and \nother unsupervised ART networks in neural control were \ndemonstrated. Fuzzy ART was modified to develop ReART, a \nfeedback based ART network capable of addressing these \nlimitations. ReART was utilized to construct a neural \ncontroller capable of online learning. The ReART based \ncontroller was compared through numerical testing with BP, \nand an identical Fuzzy ART based controller. Results indicate \nReART outperform both BP and Fuzzy ART for the presented \ncontrol problem. ReART learns several magnitudes faster than \nBP, and provides a similar level of training accuracy. Further, \nReART learns faster, with greater accuracy and less internal \ncategories than Fuzzy ART.  It also avoids the Fuzzy ART \nproblem of classifying multiple input classes under a single \ncategory.  The ReART based controller also overcomes the \nplasticity stability dilemma, and is able to learn new inputs \nwith a minimum impact on existing knowledge and accuracy.  \n \nFurther work is planned on testing ReART for classifying \nmore complex datasets to confirm whether the fast learning \nmechanism is able to cope with more subtle categorisations. In \naddition, it is also to be tested using real feedback from a live \nenvironment with potentially greater noise and feedback errors. \n \nVII. REFERENCES \n[1] G. A. Carpenter. S. Grossberg. Fuzzy ART: Fast Stable learning and \ncategorization of analogue patterns by an Adaptive Resonance System. Neural \nNetworks, Vol. 4, 1991, pp. 759-771. \n \n[2] G. A. Carpenter, S. Grossberg, Adaptive Resonance Theory, In M.A. Arbib \n(Ed.), The handbook of Brain Theory and Neural Networks, Second Edition. \nCambridge, MA: MIT Press, 2003, pp 87-90 \n \n[3] D. D. Ediriweera, I. W. Marshall, Internally self organising Neural \nNetwork for online learning of perception to action mappings in Sensor Networks, \nProceedings of London Communications Symposium, 2005, pp. 21-24. \n \n[4] C. J. Merz, D. C. St. Clair, W.E. Bond, SeMi-supervised adaptive \nresonance theory (SMART2), Neural Networks, 1992. IJCNN., International \nJoint Conference on, Vol.3, Iss., 7-11 Jun 1992, pp. 851-856. \n  \n[5] A. Weitzenfeld, M. A. Arbib, A. Alexander, Chapter eight in The Neural \nSimulation Language, MIT Press, ISBN: 0-262-73149-5, July 2002, pp 157-169. \n \n[6] G. A. Carpenter, S. Grossberg, J. H. Reynolds, ARTMAP: Supervised \nreal-time learning and classification of nonstationary data by a self-organizing \nneural network, Neural Networks (Publication), Vol 4, 1991, pp 565-588 \n \n[7] S. W. Lee. D. Palmer-Brown. C. M. Roadknight. Performance-guided \nNeural Network for rapidly self-organising Active Network Management, \nNeurocomputing, special issue on Hybrid Neurocomputing, Elsevier Science, \nNetherlands, 2004, 61C: 5 - 20. \n \n[8] A. P\u00e9rez-Uribe. A non-computationally-intensive neurocontroller for \nautonomous mobile robot navigation. Chapter 8 in Biologically inspired robot \nbehaviour engineering, Series: Studies in Fuzziness and Soft Computing. Vol. \n109, R. J. Duro, J. Santos, M. Grana (Eds.), Springer-Verlag, 2002, pp. 215-238. \n \n[9] R. Beale, T. Jackson, Neural Computing: An Introduction, ISBN: \n0852742622, Institute of Physics Publishing, 1990, pp. 63-80. \n70\n75\n80\n85\n90\n95\n100\n20 40 60 80 100 120 140 160 180 200\nTraining Epoch\nReART \nFig. 5.  Network accuracy vs. training epoch: introducing \na new input class \nBP (4-5-3) \nA\ncc\nur\nac\ny \n%\n"}
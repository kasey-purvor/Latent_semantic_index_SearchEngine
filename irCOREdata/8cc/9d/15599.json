{"doi":"10.1109\/hicss.2008.157","coreId":"15599","oai":"oai:eprints.erpanet.org:130","identifiers":["oai:eprints.erpanet.org:130","10.1109\/hicss.2008.157"],"title":"Examining Variations of Prominent Features in Genre Classification.","authors":["Kim, Dr Yunhyong","Ross, Seamus"],"enrichments":{"references":[{"id":657886,"title":"A Tutorial on support vector machines Discovery,","authors":[],"date":"1998","doi":"10.1002\/9780470503065.app2","raw":null,"cites":null},{"id":9469613,"title":"a ZerotoMultiGenre Classification pour","authors":[],"date":"2006","doi":null,"raw":"Santini, \u00a0 M.\u00a0 (2006) \u00a0Towards \u00a0 a \u00a0 Zero\u00adto\u00adMulti\u00adGenre Classification\u00a0Scheme,\u00a0Journ\u00e9e\u00a0ATALA\u00a0&quot;Typologies\u00a0de\u00a0textes pour\u00a0le\u00a0traitement\u00a0automatique&quot;,\u00a0Paris. http:\/\/www.nltg.brighton.ac.uk\/home\/Marina.Santini\/marina_san tini_ATALA2006.pdf","cites":null},{"id":9469610,"title":"Automatic","authors":[],"date":"1997","doi":null,"raw":"Kessler, \u00a0 G., \u00a0 Nunberg, \u00a0 B., \u00a0 and \u00a0 Schuetze, \u00a0 H. \u00a0 (1997) Automatic\u00a0detection\u00a0of\u00a0text\u00a0genre.\u00a0In \u00a0Proceedings\u00a035th\u00a0Ann. Meeting\u00a0ACL,\u00a032\u201338.","cites":null},{"id":657889,"title":"Automatic   text","authors":[],"date":"1997","doi":null,"raw":null,"cites":null},{"id":657883,"title":"Automatic categorization of email into folders: benchmark experiments","authors":[],"date":null,"doi":null,"raw":"Bekkerman,\u00a0R.,\u00a0McCallum,\u00a0A.,\u00a0and\u00a0Huang,\u00a0G.\u00a0 \u00a0(2004) Automatic \u00a0 categorization \u00a0 of \u00a0 email \u00a0 into \u00a0 folders: \u00a0 benchmark experiments\u00a0on\u00a0enron\u00a0and\u00a0sri\u00a0corpora.\u00a0Technical\u00a0Report\u00a0IR\u00ad418, Centre\u00a0for\u00a0Intelligent\u00a0Information\u00a0Retrieval,\u00a0UMASS. http:\/\/www.cs.umass.edu\/~mccallum\/papers\/foldering\u00adtr05.pdf","cites":null},{"id":657887,"title":"Chen, beliefs based on confusion matrix for combining multiple classifiers.","authors":[],"date":null,"doi":"10.1049\/el:20040176","raw":"Chen,\u00a0L.,\u00a0and\u00a0Tang,\u00a0H.\u00a0L.\u00a0(2004)\u00a0Improved\u00a0computation\u00a0of beliefs \u00a0 based \u00a0 on \u00a0 confusion \u00a0 matrix \u00a0 for \u00a0 combining \u00a0 multiple classifiers.\u00a0Electronic\u00a0Letters,\u00a0Vol\u00a04,\u00a0No\u00a04,\u00a0238\u00ad\u00a0239.","cites":null},{"id":657882,"title":"Clustering document images using a bag of symbols representation.","authors":[],"date":null,"doi":"10.1109\/icdar.2005.75","raw":"Barbu,\u00a0E.,\u00a0Heroux,\u00a0P.,\u00a0Adam,\u00a0S.,\u00a0and\u00a0Turpin,\u00a0E. \u00a0(2005) Clustering \u00a0 document \u00a0 images \u00a0 using \u00a0 a \u00a0 bag \u00a0 of \u00a0 symbols representation. \u00a0 In\u00a0 Proceedings \u00a0 International \u00a0 Conference \u00a0 on Document\u00a0Analysis\u00a0and\u00a0Recognition,\u00a01216\u20131220.","cites":null},{"id":657888,"title":"documents Information","authors":[],"date":null,"doi":"10.1002\/asi.20427","raw":null,"cites":null},{"id":657881,"title":"Finegrained document","authors":[],"date":null,"doi":"10.1109\/icpr.2002.1044762","raw":"Bagdanov, \u00a0 A. \u00a0 and \u00a0 Worring, \u00a0 M. \u00a0(2001) \u00a0 Fine\u00adgrained document\u00a0genre\u00a0classification\u00a0using\u00a0first\u00a0order\u00a0random\u00a0graphs. In\u00a0 Proceedings \u00a0 of \u00a0 the \u00a0 Sixth \u00a0 International \u00a0 Conference \u00a0 on Document\u00a0Analysis\u00a0and\u00a0Recognition\u00a0(ICDAR2001)\u00a0,\u00a079\u00ad90.","cites":null},{"id":9469612,"title":"Kim,  Automated","authors":[],"date":null,"doi":null,"raw":"Kim,\u00a0Y.\u00a0and\u00a0Ross,\u00a0S.\u00a0(2007) \u00a0Feature\u00a0Type\u00a0Analysis\u00a0in Automated\u00a0Genre\u00a0Classification. http:\/\/eprints.erpanet.org\/128.","cites":null},{"id":657885,"title":"Random forests.","authors":[],"date":"2001","doi":"10.1007\/0-387-21529-8_16","raw":null,"cites":null},{"id":657884,"title":"the web: genre classification","authors":[],"date":"2005","doi":"10.1145\/1099554.1099715","raw":"Boese, \u00a0 E. \u00a0 S. \u00a0 (2005) \u00a0Stereotyping \u00a0 the \u00a0 web: \u00a0 genre classification\u00a0of\u00a0web\u00a0documents.\u00a0Master\u2019s\u00a0thesis,\u00a0Colorado\u00a0State University.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-06-01","abstract":"This paper investigates the correlation between features of three types (visual, stylistic and topical types) and genre classes.  The majority of previous studies in automated genre classification have created models based on an amalgamated representation of a document using a combination of features. In these models, the inseparable roles of different features make it difficult to determine a means of improving the classifier when it exhibits poor performance in detecting selected genres.  In this paper we use classifiers independently modeled on three groups of features to examine six genre classes to show that the  strongest features for making one classification is not necessarily the best features for carrying out another classification.","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/15599.pdf","fullTextIdentifier":"http:\/\/eprints.erpanet.org\/130\/01\/ERPA_HICSS_KRYS_VSubmit.pdf","pdfHashValue":"c9fbc5b9d390b9de310aa1f693690afbb1e09c9f","publisher":null,"rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:eprints.erpanet.org:130<\/identifier><datestamp>\n      2007-06-28<\/datestamp><setSpec>\n      7374617475733D756E707562<\/setSpec><setSpec>\n      7375626A656374733D5265736F7572636520446973636F76657279<\/setSpec><setSpec>\n      7375626A656374733D546F6F6C73<\/setSpec><setSpec>\n      7375626A656374733D45:4541<\/setSpec><setSpec>\n      7375626A656374733D4469676974616C205265706F7369746F72792C204469676974616C204172636869766520616E64204469676974616C204C696272617279204D6F64656C73:496E67657374<\/setSpec><setSpec>\n      7375626A656374733D4469676974616C205265706F7369746F72792C204469676974616C204172636869766520616E64204469676974616C204C696272617279204D6F64656C73:4D616E6167656D656E74<\/setSpec><\/header><metadata><oai_dc:dc xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Examining Variations of Prominent Features in Genre Classification.<\/dc:title><dc:creator>\n        Kim, Dr Yunhyong<\/dc:creator><dc:creator>\n        Ross, Seamus<\/dc:creator><dc:subject>\n        V Tools<\/dc:subject><dc:subject>\n        M Resource Discovery<\/dc:subject><dc:subject>\n        LA Ingest<\/dc:subject><dc:subject>\n        LB Management<\/dc:subject><dc:subject>\n        EA Metadata<\/dc:subject><dc:description>\n                                                                                This paper investigates the correlation between features of three types (visual, stylistic and topical types) and genre classes.  The majority of previous studies in automated genre classification have created models based on an amalgamated representation of a document using a combination of features. In these models, the inseparable roles of different features make it difficult to determine a means of improving the classifier when it exhibits poor performance in detecting selected genres.  In this paper we use classifiers independently modeled on three groups of features to examine six genre classes to show that the  strongest features for making one classification is not necessarily the best features for carrying out another classification.\n<\/dc:description><dc:date>\n        2007-06-01<\/dc:date><dc:type>\n        Preprint<\/dc:type><dc:identifier>\n        http:\/\/eprints.erpanet.org\/130\/<\/dc:identifier><dc:format>\n        pdf http:\/\/eprints.erpanet.org\/130\/01\/ERPA_HICSS_KRYS_VSubmit.pdf<\/dc:format><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2007,"topics":["V Tools","M Resource Discovery","LA Ingest","LB Management","EA Metadata"],"subject":["Preprint"],"fullText":"Examining\u00a0Variations\u00a0of\u00a0Prominent\u00a0Features\u00a0in\u00a0Genre\u00a0Classification\u00a0\nYunhyong\u00a0Kim\u00a0and\u00a0Seamus\u00a0Ross\nDigital\u00a0Curation\u00a0Centre\n&\nHumanities\u00a0Advanced\u00a0Technology\u00a0and\u00a0Information\u00a0Institute\nUniversity\u00a0of\u00a0Glasgow,\u00a0Glasgow,\u00a0UK\n{y.kim,\u00a0s.ross}@hatii.arts.gla.ac.uk\n\u00a0\u00a0Abstract\u00a0\u00a0\u00a0\u00a0\nThis\u00a0paper\u00a0investigates\u00a0the\u00a0correlation\u00a0between\u00a0\nfeatures\u00a0of\u00a0three\u00a0types\u00a0(visual,\u00a0stylistic\u00a0and\u00a0topical\u00a0types)\u00a0\nand\u00a0genre\u00a0classes.\u00a0 \u00a0The\u00a0majority\u00a0of\u00a0previous\u00a0studies\u00a0in\u00a0\nautomated\u00a0genre\u00a0classification\u00a0have\u00a0created\u00a0models\u00a0based\u00a0\non\u00a0an\u00a0amalgamated\u00a0representation\u00a0of\u00a0a\u00a0document\u00a0using\u00a0a\u00a0\ncombination\u00a0of\u00a0features.\u00a0In\u00a0these\u00a0models,\u00a0the\u00a0inseparable\u00a0\nroles\u00a0of\u00a0different\u00a0features\u00a0make\u00a0it\u00a0difficult\u00a0to\u00a0determine\u00a0a\u00a0\nmeans\u00a0of\u00a0improving\u00a0the\u00a0classifier\u00a0when\u00a0it\u00a0exhibits\u00a0poor\u00a0\nperformance\u00a0in\u00a0detecting\u00a0selected\u00a0genres.\u00a0 \u00a0In\u00a0this\u00a0paper\u00a0\nwe\u00a0use\u00a0classifiers\u00a0independently\u00a0modeled\u00a0on\u00a0three\u00a0groups\u00a0\nof\u00a0features\u00a0to\u00a0examine\u00a0six\u00a0genre\u00a0classes\u00a0to\u00a0show\u00a0that\u00a0the\u00a0\nstrongest\u00a0features\u00a0for\u00a0making\u00a0one\u00a0classification\u00a0is\u00a0not\u00a0\nnecessarily\u00a0the\u00a0best\u00a0features\u00a0for\u00a0carrying\u00a0out\u00a0another\u00a0\nclassification.\n1.\u00a0Introduction\u00a0\nThe\u00a0research\u00a0described\u00a0in\u00a0this\u00a0paper\u00a0examines\u00a0\ngenre\u00a0classes\u00a0\u00a0of\u00a0text\u00a0documents\u00a0and\u00a0the\u00a0role\u00a0of\u00a0different\u00a0\ntypes \u00a0 of \u00a0 features \u00a0 in \u00a0 distinguishing \u00a0 these \u00a0 classes\u00a0\nautomatically. \u00a0 Automated \u00a0 genre \u00a0 classification \u00a0 (e.g.\u00a0\nclassification\u00a0into\u00a0scientific\u00a0research\u00a0articles,\u00a0news\u00a0report,\u00a0\nor\u00a0email),\u00a0which\u00a0identifies\u00a0the\u00a0function\u00a0and\u00a0structure\u00a0of\u00a0\nthe\u00a0document,\u00a0supports\u00a0metadata\u00a0extraction\u00a0([12])\u00a0and\u00a0\nother\u00a0information\u00a0extraction\u00a0by\u00a0performing\u00a0a\u00a0first\u00adlevel\u00a0\nclassification\u00a0of\u00a0documents\u00a0into\u00a0documents\u00a0of\u00a0similar\u00a0\nstructure,\u00a0facilitating\u00a0focused\u00a0search\u00a0of\u00a0information\u00a0on\u00a0\nspecific\u00a0document\u00a0types,\u00a0and\u00a0supporting\u00a0the\u00a0\u00a0integration\u00a0\nof\u00a0techniques\u00a0developed\u00a0to\u00a0work\u00a0within\u00a0selected\u00a0genres.\u00a0\u00a0\u00a0\nThe\u00a0features\u00a0which\u00a0characterise\u00a0a\u00a0text\u00a0often\u00a0fall\u00a0\ninto\u00a0well\u00addefined\u00a0groups.\u00a0For\u00a0example,\u00a0some\u00a0features\u00a0\ncapture\u00a0the\u00a0position\u00a0of\u00a0text\u00a0blocks\u00a0(visual\u00a0layout),\u00a0some\u00a0\ndescribe\u00a0indicative\u00a0vocabulary\u00a0(significant\u00a0terms)\u00a0 \u00a0and\u00a0\nothers\u00a0attempt\u00a0to\u00a0identify\u00a0the\u00a0pragmatics\u00a0of\u00a0 \u00a0selected\u00a0\nterms\u00a0or\u00a0functional\u00a0category\u00a0(style).\u00a0\u00a0In\u00a0previous\u00a0studies\u00a0\nof\u00a0automated\u00a0genre\u00a0classification\u00a0(e.g.\u00a0[4],\u00a0[5],\u00a0[9],\u00a0[11],\u00a0\n[19],\u00a0[20])\u00a0these\u00a0features\u00a0have\u00a0been\u00a0combined\u00a0to\u00a0produce\u00a0\na\u00a0single\u00a0set\u00a0of\u00a0features\u00a0to\u00a0represent\u00a0the\u00a0documents\u00a0which\u00a0\nare\u00a0to\u00a0be\u00a0classified.\u00a0This\u00a0approach\u00a0optimises\u00a0the\u00a0overall\u00a0\nperformance\u00a0of\u00a0the\u00a0classifier\u00a0on\u00a0\u00a0the\u00a0detection\u00a0of\u00a0the\u00a0pre\u00ad\ndefined\u00a0classes\u00a0but\u00a0\u00a0makes\u00a0it\u00a0difficult\u00a0to\u00a0devise\u00a0a\u00a0means\u00a0of\u00a0\nimproving \u00a0 the \u00a0 classifier \u00a0 when \u00a0 it \u00a0 \u00a0 displays \u00a0 poor\u00a0\nperformance\u00a0in\u00a0detecting\u00a0selected\u00a0genres.\u00a0It\u00a0also\u00a0takes\u00a0for\u00a0\ngranted\u00a0that\u00a0the\u00a0predefined\u00a0classes\u00a0describe\u00a0a\u00a0comparable\u00a0\nschema\u00a0of\u00a0a\u00a0single\u00a0classification\u00a0task.\n\u00a0 In \u00a0 this \u00a0 paper \u00a0 we \u00a0 give \u00a0 evidence \u00a0 that \u00a0 genre\u00a0\nclassification, \u00a0 as \u00a0 described \u00a0 in \u00a0 previous \u00a0 studies, \u00a0 may\u00a0\nactually\u00a0be\u00a0a\u00a0combination\u00a0of\u00a0several\u00a0independent\u00a0tasks.\u00a0\nFor\u00a0example,\u00a0the\u00a0 \u00a0distinction\u00a0 \u00a0between\u00a0a\u00a0Thesis\u00a0and\u00a0\nScientific \u00a0 Paper \u00a0 is \u00a0 largely \u00a0 structural, \u00a0 while \u00a0 Meeting\u00a0\nMinutes\u00a0and\u00a0Business\u00a0Reports\u00a0are\u00a0mostly\u00a0distinguished\u00a0by\u00a0\ntopic\u00a0and\u00a0style.\u00a0On\u00a0the\u00a0other\u00a0hand,\u00a0the\u00a0distinction\u00a0between\u00a0\na\u00a0Table\u00a0of\u00a0Financial\u00a0Statistics\u00a0and\u00a0a\u00a0Financial\u00a0Report\u00a0lies\u00a0\nmainly\u00a0in\u00a0the\u00a0visual\u00a0representation\u00a0and\u00a0style.\u00a0Using\u00a0the\u00a0\nsame\u00a0features\u00a0to\u00a0model\u00a0concurrently\u00a0these\u00a0different\u00a0types\u00a0\nof\u00a0classification\u00a0would\u00a0be\u00a0equivalent\u00a0to\u00a0estimating\u00a0a\u00a0\nsingle\u00a0distribution\u00a0for\u00a0items\u00a0which\u00a0belong\u00a0to\u00a0distinct\u00a0\npopulations.\u00a0If\u00a0you\u00a0examine\u00a0previous\u00a0literature\u00a0(e.g.\u00a0Table\u00a0\n5\u00a0in\u00a0[10],\u00a0 \u00a0Table\u00a03\u00a0in\u00a0[11]),\u00a0classification\u00a0errors\u00a0range\u00a0\nanywhere\u00a0from\u00a0seventeen\u00a0percent\u00a0to\u00a0seventy\u00adsix\u00a0percent\u00a0\n([10]),\u00a0and\u00a0six\u00a0percent\u00a0to\u00a0eighty\u00a0percent\u00a0([11]).\u00a0Observing\u00a0\nsuch\u00a0big\u00a0differences\u00a0in\u00a0error\u00a0rate\u00a0might\u00a0indicate\u00a0that\u00a0a\u00a0re\u00ad\nevaluation\u00a0of\u00a0the\u00a0task,\u00a0\u00a0to\u00a0determine\u00a0if\u00a0the\u00a0task\u00a0is\u00a0actually\u00a0\na\u00a0combination\u00a0of\u00a0many\u00a0tasks\u00a0disguised\u00a0by\u00a0the\u00a0single\u00a0term\u00a0\ngenre\u00a0classification,\u00a0would\u00a0be\u00a0productive.\nAnother\u00a0prevailing\u00a0notion\u00a0in\u00a0earlier\u00a0analyses\u00a0is\u00a0\nthat\u00a0genre\u00a0classification\u00a0is\u00a0orthogonal\u00a0to\u00a0topic\u00a0or\u00a0subject\u00a0\nclassification.\u00a0This\u00a0\u00a0notion\u00a0defines\u00a0genre\u00a0classification\u00a0as\u00a0\na\u00a0task\u00a0independent\u00a0from\u00a0subject\u00a0classification.\u00a0While\u00a0\nthere\u00a0may\u00a0be\u00a0a\u00a0conceptual\u00a0level\u00a0at\u00a0which\u00a0this\u00a0is\u00a0true,\u00a0\nwithin\u00a0the\u00a0probabilistic\u00a0framework\u00a0on\u00a0which\u00a0language\u00a0\nprocessing\u00a0is\u00a0highly\u00a0reliant,\u00a0there\u00a0is\u00a0reason\u00a0to\u00a0believe\u00a0that\u00a0\nthis\u00a0is\u00a0not\u00a0generally\u00a0the\u00a0case.\u00a0For\u00a0example,\u00a0consider\u00a0the\u00a0\ntopic\u00a0of\u00a0cohomology,\u00a0a\u00a0well\u00adknown\u00a0subject\u00a0area\u00a0in\u00a0higher\u00a0\nmathematics;\u00a0this\u00a0topic\u00a0would\u00a0not\u00a0be\u00a0expected\u00a0to\u00a0appear\u00a0\nas\u00a0frequently\u00a0in\u00a0the\u00a0genre\u00a0class\u00a0Reportage\u00a0as\u00a0it\u00a0would\u00a0in\u00a0\nthe\u00a0genre\u00a0class\u00a0Research\u00a0Article.\u00a0This\u00a0suggests\u00a0that,\u00a0at\u00a0least\u00a0on\u00a0a\u00a0practical\u00a0probabilistic\u00a0level,\u00a0genre\u00a0often\u00a0moves\u00a0\nin\u00a0close\u00a0proximity\u00a0to\u00a0subject.\u00a0\nThe\u00a0present\u00a0paper\u00a0reports\u00a0tests\u00a0on\u00a0two\u00a0corpora\u00a0of\u00a0\ngenre\u00adlabelled\u00a0PDF\u00a0documents\u00a0conducted\u00a0to\u00a0examine\u00a0the\u00a0\ncorrelation\u00a0between\u00a0genre\u00a0classes\u00a0and\u00a0three\u00a0feature\u00a0types,\u00a0\nto\u00a0demonstrate\u00a0that\u00a0the\u00a0best\u00a0feature\u00a0types\u00a0for\u00a0detecting\u00a0any\u00a0\none\u00a0genre\u00a0class\u00a0are\u00a0not\u00a0necessarily\u00a0the\u00a0best\u00a0for\u00a0detecting\u00a0\nother\u00a0genre\u00a0classes.\u00a0\u00a0The\u00a0feature\u00a0types\u00a0we\u00a0will\u00a0examine\u00a0\nare\u00a0visual\u00a0layout\u00a0features,\u00a0language\u00a0modeling\u00a0features\u00a0and\u00a0\nstylistic\u00a0word\u00a0frequency.\u00a0Initially\u00a0our\u00a0corpus\u00a0has\u00a0been\u00a0\nconfined\u00a0to\u00a0one\u00a0document\u00a0format\u00a0to\u00a0narrow\u00a0down\u00a0the\u00a0\nproblem\u00a0space.\u00a0We\u00a0have\u00a0chosen\u00a0PDF\u00a0as\u00a0this\u00a0format\u00a0\nbecause\u00a0a\u00a0tool\u00a0for\u00a0this\u00a0format\u00a0is\u00a0likely\u00a0to\u00a0have\u00a0immediate\u00a0\nwide \u00a0 spread \u00a0 application \u00a0 given \u00a0 its \u00a0 popularity \u00a0 across\u00a0\nlibrary,\u00a0archival,\u00a0commercial\u00a0and\u00a0private\u00a0sectors.\u00a0The\u00a0\nmethods\u00a0described\u00a0here,\u00a0however,\u00a0 \u00a0do\u00a0not\u00a0use\u00a0features\u00a0\ndependent\u00a0on\u00a0elements\u00a0available\u00a0only\u00a0in\u00a0PDF\u00a0documents.\u00a0\nThe\u00a0process\u00a0is\u00a0dependent\u00a0on\u00a0the\u00a0PDF\u00a0\u00a0only\u00a0in\u00a0so\u00a0far\u00a0as\u00a0it\u00a0\ndepends\u00a0on\u00a0PDF\u00a0tools\u00a0to\u00a0convert\u00a0the\u00a0documents\u00a0into\u00a0\nimage\u00a0and\u00a0text.\u00a0\nIt\u00a0is\u00a0not\u00a0the\u00a0intention\u00a0of\u00a0\u00a0this\u00a0paper\u00a0to\u00a0introduce\u00a0a\u00a0\nclassifier\u00a0optimised\u00a0to\u00a0perform\u00a0genre\u00a0classification\u00a0(in\u00a0\ncontrast\u00a0to\u00a0[12]).\u00a0Here\u00a0we\u00a0put\u00a0forward\u00a0evidence\u00a0that\u00a0\nestablishing\u00a0a\u00a0correlation\u00a0between\u00a0feature\u00a0types\u00a0and\u00a0genre\u00a0\nclasses\u00a0may\u00a0be\u00a0a\u00a0reasonable\u00a0step\u00a0forward\u00a0in\u00a0constructing\u00a0a\u00a0\nrobust\u00a0genre\u00a0classification\u00a0system.\u00a0\u00a0\n2.\u00a0Defining\u00a0genre\nGenre\u00a0is\u00a0a\u00a0highly\u00a0mutable\u00a0context\u00addependent\u00a0\nconcept.\u00a0Its\u00a0mutability\u00a0is\u00a0apparent\u00a0in\u00a0its\u00a0usage\u00a0across\u00a0the\u00a0\nliterature: \u00a0 Biber \u00a0 ([4]) \u00a0 characterised \u00a0 document \u00a0 genres\u00a0\nusing \u00a0 five \u00a0 dimensions \u00a0 (information, \u00a0 narration,\u00a0\nelaboration,\u00a0persuasion,\u00a0abstraction),\u00a0while\u00a0others\u00a0([10],\u00a0\n[5]) \u00a0 examined \u00a0 the \u00a0 categorisation \u00a0 of \u00a0 documents\u00a0 into\u00a0\ncommon\u00a0classes\u00a0such\u00a0as\u00a0FAQ,\u00a0Job\u00a0Description,\u00a0Editorial\u00a0\nor\u00a0Reportage.\u00a0Genre\u00a0classification\u00a0have\u00a0sometimes\u00a0been\u00a0\ndefined\u00a0as\u00a0the\u00a0analysis\u00a0of\u00a0particular\u00a0aspects\u00a0(narratives,\u00a0\nfact\u00a0versus\u00a0opinion,\u00a0intended\u00a0level\u00a0of\u00a0audience,\u00a0and,\u00a0\npositivity\u00a0or\u00a0negativity\u00a0of\u00a0opinion)\u00a0of\u00a0text\u00a0([11],\u00a0[9]),\u00a0and\u00a0\neven\u00a0used\u00a0to\u00a0describe\u00a0the\u00a0detection\u00a0of\u00a0\u00a0selected\u00a0journals\u00a0\nand\u00a0brochures\u00a0from\u00a0one\u00a0another\u00a0using\u00a0visual\u00a0layout\u00a0([1]).\u00a0\nOthers\u00a0([17],\u00a0[2])\u00a0have\u00a0clustered\u00a0documents\u00a0into\u00a0similar\u00a0\nfeature \u00a0 groups \u00a0 without \u00a0 delving \u00a0 into \u00a0 genre \u00a0 facets \u00a0 or\u00a0\nclasses,\u00a0and\u00a0some\u00a0have\u00a0championed\u00a0a\u00a0multi\u00adgenre\u00a0schema\u00a0\nfor \u00a0 web \u00a0 page \u00a0 classification \u00a0 ([19], \u00a0 [20]). \u00a0 Santini \u00a0 has\u00a0\nreviewed \u00a0 different \u00a0 approaches \u00a0 to \u00a0 genre \u00a0 classification\u00a0\n([18]).\u00a0\nWhile\u00a0the\u00a0definition\u00a0of\u00a0genre\u00a0may\u00a0not\u00a0be\u00a0easily\u00a0\npinned\u00a0down,\u00a0there\u00a0\u00a0is\u00a0general\u00a0agreement\u00a0that\u00a0genre\u00a0is\u00a0a\u00a0\nconcept\u00a0used\u00a0to\u00a0categorise\u00a0documents\u00a0by\u00a0structure\u00a0and\u00a0\nfunction.\u00a0In\u00a0fact,\u00a0the\u00a0structure\u00a0of\u00a0documents\u00a0in\u00a0the\u00a0genre\u00a0\nevolve\u00a0to\u00a0meet\u00a0the\u00a0functional\u00a0requirements\u00a0for\u00a0its\u00a0survival\u00a0\nin\u00a0the\u00a0environment\u00a0\u00a0for\u00a0which\u00a0it\u00a0was\u00a0created,\u00a0much\u00a0the\u00a0\nsame\u00a0as\u00a0the\u00a0structure\u00a0of\u00a0an\u00a0organism\u00a0evolves\u00a0to\u00a0optimise\u00a0\nits\u00a0survival\u00a0function\u00a0in\u00a0the\u00a0natural\u00a0environment\u00a0(cf.\u00a0[13]).\u00a0\nThe\u00a0accepted\u00a0layout,\u00a0language,\u00a0components\u00a0and\u00a0style\u00a0of\u00a0\nthe \u00a0 document \u00a0 change \u00a0 dynamically \u00a0 to \u00a0 maximise \u00a0 its\u00a0\nchances\u00a0of\u00a0\u00a0fulfilling\u00a0its\u00a0role\u00a0as\u00a0\n\u00a0\n\u25cf a\u00a0piece\u00a0of\u00a0communication\u00a0reflecting\u00a0the\u00a0intention\u00a0\nof\u00a0the\u00a0creator,\n\u25cf a\u00a0source\u00a0of\u00a0information\u00a0for\u00a0distribution\u00a0to\u00a0a\u00a0user\u00a0\ncommunity,\n\u25cf a \u00a0 part \u00a0 of \u00a0 a \u00a0 process \u00a0 such \u00a0 as \u00a0 publication,\u00a0\nrecruitment,\u00a0or\u00a0event,\n\u25cf a \u00a0 type \u00a0 of \u00a0 data \u00a0 structure \u00a0 for \u00a0 representing\u00a0\ninformation.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nIn\u00a0this\u00a0context,\u00a0it\u00a0seems\u00a0intuitively\u00a0clear\u00a0that\u00a0selected\u00a0\nfeatures\u00a0will\u00a0be\u00a0dependent\u00a0on\u00a0one\u00a0of\u00a0five\u00a0aspects:\u00a0visual\u00a0\nlayout,\u00a0style,\u00a0topic,\u00a0semantic\u00a0patterns,\u00a0and\u00a0 \u00a0contextual\u00a0\nelements \u00a0 which \u00a0 reflect \u00a0 the \u00a0 process \u00a0 for \u00a0 which \u00a0 the\u00a0\ndocument\u00a0was\u00a0created\u00a0and\u00a0used\u00a0(cf.\u00a0[12])\u00a0.\u00a0\nThe\u00a0proposed\u00a0objective\u00a0in\u00a0this\u00a0paper\u00a0is\u00a0to\u00a0study\u00a0\nthese \u00a0feature \u00a0 types \u00a0in \u00a0 relation \u00a0 to \u00a0 genre \u00a0 classes \u00a0 to\u00a0\ndetermine\u00a0its\u00a0effectiveness\u00a0in\u00a0the\u00a0detection\u00a0of \u00a0visual\u00a0\ngenres\u00a0(e.g.\u00a0data\u00a0structure\u00a0type),\u00a0 stylistic\u00a0genres\u00a0 (e.g.\u00a0\nprescribed \u00a0 procedural \u00a0 style) \u00a0 and \u00a0topical \u00a0 genres\u00a0 (e.g.\u00a0\nbusiness\u00a0versus\u00a0legal\u00a0briefing\u00a0paper)\u00a0independently. \u00a0To\u00a0\nthis\u00a0end,\u00a0we\u00a0first\u00a0examine\u00a0white\u00a0space\u00a0analysis,\u00a0stylistic\u00a0\nterm\u00a0frequency\u00a0and\u00a0significant\u00a0term\u00a0analysis\u00a0in\u00a0relation\u00a0to\u00a0\ngenre\u00a0classification.\u00a0Subsequently\u00a0we\u00a0will\u00a0enrich\u00a0this\u00a0\nbasic\u00a0set\u00a0to\u00a0examine\u00a0more\u00a0sophisticated\u00a0features.\u00a0It\u00a0seems\u00a0\nimportant\u00a0to\u00a0keep\u00a0a\u00a0check\u00a0on\u00a0the\u00a0number\u00a0of\u00a0parameters\u00a0\u00a0in\u00a0\nthe\u00a0first\u00a0analysis.\n3.\u00a0Data\nA\u00a0common\u00a0problem\u00a0in\u00a0the\u00a0study\u00a0of\u00a0automated\u00a0\ngenre\u00a0classification\u00a0is\u00a0the\u00a0lack\u00a0of\u00a0established\u00a0experimental\u00a0\ndata.\u00a0A\u00a0limited\u00a0classification\u00a0of\u00a0documents\u00a0into\u00a0genre\u00a0is\u00a0\navailable\u00a0in\u00a0previously\u00a0constructed\u00a0datasets,\u00a0but\u00a0none\u00a0of\u00a0\nthem\u00a0span\u00a0a\u00a0large\u00a0number\u00a0of\u00a0genres,\u00a0nor\u00a0do\u00a0they\u00a0employ\u00a0a\u00a0\nconsistent\u00a0schema.\u00a0To\u00a0alleviate\u00a0the\u00a0paucity\u00a0of\u00a0data,\u00a0we\u00a0\nhave\u00a0created\u00a0two\u00a0corpora\u00a0which\u00a0we\u00a0describe\u00a0in\u00a0this\u00a0\nsection.\u00a0\u00a0\n3.1.\u00a0Corpora\nThere\u00a0are\u00a0two\u00a0independent\u00a0corpora\u00a0which\u00a0\nhave\u00a0been\u00a0constructed\u00a0in\u00a0our\u00a0research:\nRAGGED\u00a0(RAndomly\u00a0Generated\u00a0GEnre\u00a0Data)\u00a0This\u00a0dataset\u00a0consists\u00a0of\u00a0570\u00a0PDF\u00a0documents\u00a0gathered\u00a0\nfrom\u00a0the\u00a0Internet\u00a0using\u00a0random\u00a0search\u00a0words.\u00a0 \u00a0For\u00a0the\u00a0\nretrieval\u00a0of\u00a0each\u00a0item,\u00a0the\u00a0algorithm\u00a0selects\u00a0a\u00a0random\u00a0\nword\u00a0from\u00a0SCOWL\u00a0(Spell\u00a0Checker\u00a0Oriented\u00a0Word\u00a0List\u00a0\u00ad\u00a0\navailable\u00a0from\u00a0sourceforge.net),\u00a0retrieves\u00a0a\u00a0list\u00a0of\u00a0PDFs\u00a0\ncontaining\u00a0the\u00a0search\u00a0word,\u00a0and\u00a0then\u00a0saves\u00a0a\u00a0random\u00a0\ndocument\u00a0from\u00a0the\u00a0first\u00a0hundred\u00a0documents\u00a0returned.\u00a0The\u00a0\ndata\u00a0gathered\u00a0by\u00a0this\u00a0method\u00a0was\u00a0labelled\u00a0by\u00a0one\u00a0of\u00a0the\u00a0\nauthors\u00a0of\u00a0this\u00a0paper.\nKRYS\u00a0I\u00a0\u00a0\nThis\u00a0corpus\u00a0consists\u00a0of\u00a0documents\u00a0belonging\u00a0to\u00a0one\u00a0of\u00a0the\u00a0\nseventy\u00a0genres\u00a0described\u00a0in\u00a0Table\u00a01\u00a0of\u00a0[14]\u00a0.\u00a0The\u00a0corpus\u00a0\nwas\u00a0constructed\u00a0through\u00a0a\u00a0document\u00a0retrieval\u00a0exercise\u00a0\nwhere\u00a0university\u00a0students\u00a0 were\u00a0assigned\u00a0genres\u00a0 from\u00a0\nTable\u00a01\u00a0of\u00a0[14],\u00a0and,\u00a0for\u00a0each\u00a0genre,\u00a0asked\u00a0to\u00a0retrieve\u00a0from\u00a0\nthe \u00a0 Internet \u00a0 one \u00a0 hundred \u00a0 examples \u00a0 of \u00a0 that \u00a0 genre\u00a0\nrepresented\u00a0in\u00a0PDF\u00a0and\u00a0written\u00a0in\u00a0English.\u00a0They\u00a0were\u00a0not\u00a0\ngiven\u00a0any\u00a0descriptions\u00a0of\u00a0the\u00a0genres\u00a0\u00a0apart\u00a0from\u00a0the\u00a0genre\u00a0\nlabel.\u00a0Instead,\u00a0they\u00a0were\u00a0asked\u00a0to\u00a0describe\u00a0their\u00a0reasons\u00a0\nfor\u00a0including\u00a0the\u00a0particular\u00a0example\u00a0in\u00a0the\u00a0set.\u00a0For\u00a0some\u00a0\ngenres,\u00a0the\u00a0students\u00a0were\u00a0unable\u00a0to\u00a0identify\u00a0and\u00a0acquire\u00a0\none\u00a0hundred\u00a0examples.\u00a0The\u00a0resulting\u00a0corpus\u00a0now\u00a0includes\u00a0\n6478\u00a0items.\n3.2\u00a0Experimental\u00a0data\nThe\u00a0experiments\u00a0analysed\u00a0in\u00a0Section\u00a06\u00a0have\u00a0been\u00a0\nconducted\u00a0on\u00a0two\u00a0datasets,\u00a0a\u00a0subset\u00a0of\u00a0RAGGED\u00a0(Dataset\u00a0\nI)\u00a0and\u00a0a\u00a0subset\u00a0of\u00a0KRYS\u00a0I\u00a0(Dataset\u00a0II),\u00a0consisting\u00a0of\u00a0all\u00a0\nthe\u00a0documents\u00a0in\u00a0the\u00a0corpora\u00a0initially\u00a0labelled\u00a0as\u00a0one\u00a0of\u00a0\nsix \u00a0 genres \u00a0 including \u00a0 Academic \u00a0 Monograph \u00a0 (AM),\u00a0\nBusiness\u00a0Report\u00a0(BR),\u00a0Book\u00a0of\u00a0Fiction\u00a0(BF),\u00a0Minutes\u00a0\n(M),\u00a0Periodicals\u00a0(P),\u00a0and\u00a0Thesis\u00a0(T).\u00a0The\u00a0\u00a0experimental\u00a0\nDataset\u00a0I\u00a0comprises\u00a0\u00a016\u00a0examples\u00a0of\u00a0AM,\u00a016\u00a0examples\u00a0of\u00a0\nBR,\u00a015\u00a0examples\u00a0of\u00a0BF,\u00a019\u00a0examples\u00a0of\u00a0M,\u00a019\u00a0examples\u00a0of\u00a0\nP,\u00a0and\u00a018\u00a0examples\u00a0of\u00a0T,\u00a0while\u00a0Dataset\u00a0II\u00a0comprises\u00a0\u00a099\u00a0\nexamples\u00a0of\u00a0AM,\u00a029\u00a0examples\u00a0of\u00a0BF,\u00a0100\u00a0examples\u00a0of\u00a0\nBR,\u00a099\u00a0examples\u00a0of\u00a0M,\u00a067\u00a0examples\u00a0of\u00a0P,\u00a0100\u00a0examples\u00a0of\u00a0\nT.\u00a0The\u00a0low\u00a0proportion\u00a0of\u00a0Book\u00a0of\u00a0Fiction\u00a0and\u00a0Periodicals\u00a0\nin\u00a0Dataset\u00a0II\u00a0is\u00a0due\u00a0to\u00a0the\u00a0difficulty\u00a0in\u00a0finding\u00a0publicly\u00a0\navailable\u00a0examples\u00a0of\u00a0that\u00a0genre.\u00a0\u00a0\n4.\u00a0Classifiers\nEight\u00a0classifiers\u00a0are\u00a0examined\u00a0in\u00a0this\u00a0paper.\u00a0They\u00a0\nare\u00a0trained\u00a0on\u00a0three\u00a0feature\u00a0types\u00a0and\u00a0three\u00a0statistical\u00a0\nmethods. \u00a0 The \u00a0 three \u00a0 statistical \u00a0 methods \u00a0 employed \u00a0 are\u00a0\nNa\u00efve\u00a0Bayes\u00a0(NB)\u00a0[16],\u00a0Support\u00a0Vector\u00a0Machine\u00a0(SVM)\u00a0\n[26]\u00a0and\u00a0Random\u00a0Forest\u00a0(RF)\u00a0[6].\u00a0We\u00a0have\u00a0called\u00a0the\u00a0\nthree\u00a0feature\u00a0types \u00a0\u00a0 image,\u00a0style\u00a0 and \u00a0Rainbow.\u00a0The\u00a0\nfeatures. \u00a0 image \u00a0 and \u00a0 style, \u00a0 have \u00a0 been \u00a0 modeled \u00a0 for\u00a0\ncomparison\u00a0using\u00a0all\u00a0three\u00a0statistical\u00a0methods\u00a0using\u00a0the\u00a0\nWeka \u00a0 machine \u00a0 learning \u00a0 toolkit \u00a0 ([21]). \u00a0 The \u00a0 features\u00a0\nrepresented\u00a0by\u00a0Rainbow,\u00a0on\u00a0the\u00a0other\u00a0hand,\u00a0have\u00a0been\u00a0\nmodeled\u00a0on\u00a0Na\u00efve\u00a0Bayes\u00a0and\u00a0Support\u00a0Vector\u00a0Machine.\u00a0\nThe\u00a0 features\u00a0of\u00a0 Rainbow\u00a0 are\u00a0native\u00a0 to\u00a0the\u00a0 Rainbow\u00a0\nmodule\u00a0of\u00a0the\u00a0BOW\u00a0toolkit\u00a0([15])\u00a0and\u00a0Random\u00a0Forest\u00a0\n(which\u00a0was\u00a0developed\u00a0at\u00a0a\u00a0later\u00a0date)\u00a0was\u00a0unfortunately\u00a0\nnot\u00a0built\u00a0into\u00a0the\u00a0module.\u00a0We\u00a0will\u00a0refer\u00a0to\u00a0the\u00a0eight\u00a0\nclassifiers\u00a0by\u00a0naming\u00a0them\u00a0with\u00a0the\u00a0feature\u00a0type\u00a0followed\u00a0\nby\u00a0the\u00a0abbreviation\u00a0for\u00a0the\u00a0statistical\u00a0method\u00a0(e.g.\u00a0image\u00a0\nNB \u00a0for \u00a0 image \u00a0 feature \u00a0 Na\u00efve \u00a0 Bayes \u00a0 classifier). \u00a0The\u00a0\nparameters\u00a0for\u00a0feature\u00a0selection\u00a0and\u00a0statistical\u00a0methods\u00a0\nhave\u00a0been\u00a0optimised\u00a0over\u00a0a\u00a0finite\u00a0set\u00a0of\u00a0combinations\u00a0\ntested\u00a0for\u00a0best\u00a0overall\u00a0accuracy\u00a0on\u00a0several\u00a0samples\u00a0taken\u00a0\nfrom\u00a0RAGGED.\u00a0The\u00a0final\u00a0feature\u00a0selection\u00a0method\u00a0is\u00a0\ndescribed\u00a0below.\u00a0\nImage\u00a0features:\u00a0The\u00a0first\u00a0page\u00a0of\u00a0the\u00a0document\u00a0\nwas\u00a0converted\u00a0into\u00a0a\u00a0low\u00a0resolution\u00a0grey\u00adscale\u00a0image\u00a0and\u00a0\nsectioned\u00a0into\u00a0a\u00a0N\u00a0x\u00a0N\u00a0grid.\u00a0Each\u00a0region\u00a0on\u00a0the\u00a0grid\u00a0was\u00a0\nexamined\u00a0for\u00a0non\u00adwhite\u00a0pixels.\u00a0All\u00a0regions\u00a0with\u00a0non\u00ad\nwhite\u00a0pixels\u00a0were\u00a0assigned\u00a0a\u00a0value\u00a0of\u00a01\u00a0and\u00a0all\u00a0the\u00a0other\u00a0\nregions\u00a0were\u00a0assigned\u00a0a\u00a0value\u00a0of\u00a00,\u00a0to\u00a0create\u00a0a\u00a0low\u00a0\nresolution\u00a0bit\u00a0map.\u00a0Several\u00a0grid\u00a0sizes\u00a0were\u00a0tested\u00a0on\u00a0\nsamples\u00a0taken\u00a0from\u00a0RAGGED,\u00a0but\u00a0we\u00a0found\u00a0N=62\u00a0to\u00a0\nproduce\u00a0the\u00a0best\u00a0results.\u00a0This\u00a0was\u00a0also\u00a0the\u00a0coarsest\u00a0level\u00a0\nof\u00a0granularity\u00a0at\u00a0which\u00a0human\u00a0subjects\u00a0were\u00a0able\u00a0to\u00a0\ndistinguish\u00a0particular\u00a0documents\u00a0as\u00a0members\u00a0of\u00a0specific\u00a0\ngenre\u00a0classes.\u00a0\nStyle\u00a0 features: \u00a0From\u00a0 an \u00a0 independent\u00a0 dataset\u00a0\nconsisting\u00a0of\u00a0documents\u00a0retrieved\u00a0from\u00a0the\u00a0Internet,\u00a0the\u00a0\nunion\u00a0of\u00a0all\u00a0words\u00a0found\u00a0to\u00a0be\u00a0common\u00a0amongst\u00a0the\u00a0files\u00a0\nin\u00a0each\u00a0genre\u00a0class\u00a0was\u00a0compiled\u00a0into\u00a0a\u00a0list.\u00a0The\u00a0dataset\u00a0\nused \u00a0 in \u00a0 this \u00a0 process \u00a0 consisted \u00a0 of \u00a0 190 \u00a0 documents\u00a0\nbelonging\u00a0to\u00a0nineteen\u00a0genres\u00a0inclusive\u00a0of\u00a0the\u00a0six\u00a0genres\u00a0\nbeing\u00a0examined\u00a0in\u00a0this\u00a0paper.\u00a0The\u00a0thirteen\u00a0complementary\u00a0\ngenre \u00a0 classes \u00a0 include \u00a0 Abstract, \u00a0 \u00a0 Magazine \u00a0 Article,\u00a0\nScientific\u00a0Research\u00a0Article,\u00a0Forms,\u00a0Technical\u00a0Manual,\u00a0\nTechnical\u00a0Report,\u00a0Email,\u00a0Memo,\u00a0Advertisement,\u00a0Exam\u00a0\nWorksheet,\u00a0Slides,\u00a0Speech\u00a0Transcript,\u00a0Poster.\u00a0The\u00a0test\u00a0\ndocuments\u00a0were\u00a0represented\u00a0by\u00a0a\u00a0vector\u00a0constructed\u00a0using\u00a0\nthe\u00a0frequency\u00a0of\u00a0each\u00a0word\u00a0in\u00a0the\u00a0compiled\u00a0list.\u00a0\nRainbow \u00a0 features: \u00a0This \u00a0 is \u00a0 a \u00a0 text \u00a0 classifier\u00a0\nincluded\u00a0in\u00a0the\u00a0BOW\u00a0toolkit\u00a0developed\u00a0by\u00a0McCallum\u00a0\n([15]).\u00a0This\u00a0toolkit\u00a0indexes\u00a0the\u00a0alpha\u00adnumeric\u00a0content\u00a0of\u00a0\nthe\u00a0text\u00a0for\u00a0an\u00a0analysis\u00a0of\u00a0significant\u00a0terms,\u00a0to\u00a0estimate\u00a0the\u00a0\nprobability\u00a0of\u00a0each\u00a0word\u00a0against\u00a0each\u00a0class.\u00a0We\u00a0have\u00a0\nadopted\u00a0the\u00a0default\u00a0setting\u00a0of\u00a0using\u00a0a\u00a0stop\u00adword\u00a0list\u00a0to\u00a0\ncapture \u00a0 significant \u00a0 topical \u00a0 words \u00a0 of \u00a0 documents. \u00a0 The\u00a0\nrainbow\u00a0classifier\u00a0is\u00a0popular\u00a0with\u00a0subject\u00a0classification.\n\u00a0\u00a0\u00a0\u00a0Our \u00a0 interest \u00a0 in \u00a0 image \u00a0 features \u00a0 reflects \u00a0 the\u00a0\nrecognition\u00a0that\u00a0documents\u00a0of\u00a0certain\u00a0genres\u00a0have\u00a0more\u00a0\nwhite\u00a0space\u00a0on\u00a0the\u00a0first\u00a0page\u00a0(e.g.\u00a0title\u00a0page\u00a0of\u00a0the\u00a0book),\u00a0\nare\u00a0ruled\u00a0by\u00a0formatting\u00a0conventions\u00a0(e.g.\u00a0first\u00a0slide\u00a0for\u00a0a\u00a0\nconference\u00a0presentation),\u00a0and\u00a0are\u00a0made\u00a0visually\u00a0elaborate\u00a0\nto\u00a0attract\u00a0readership\u00a0(e.g.\u00a0the\u00a0reversal\u00a0of\u00a0black\u00a0and\u00a0white\u00a0\non\u00a0a\u00a0magazine\u00a0cover).\u00a0Another\u00a0benefit\u00a0of\u00a0examining\u00a0\ndocuments\u00a0using\u00a0image\u00a0processing\u00a0methods\u00a0is\u00a0that\u00a0the\u00a0\nprocess \u00a0 does \u00a0 not \u00a0 depend \u00a0 on \u00a0 extracting \u00a0 text, \u00a0 can \u00a0 be\u00a0\nlanguage\u00a0independent,\u00a0and\u00a0supports\u00a0document\u00a0analysis\u00a0\neven\u00a0when\u00a0the\u00a0content\u00a0of\u00a0the\u00a0document\u00a0is\u00a0only\u00a0accessible\u00a0\nas\u00a0an\u00a0image.\u00a0Examples\u00a0of\u00a0the\u00a0image\u00a0representation\u00a0are\u00a0\ngiven\u00a0in\u00a0Figure\u00a01.\u00a0\nThe\u00a0features\u00a0in\u00a0style\u00a0are\u00a0intended\u00a0to\u00a0capture\u00a0\nfrequency\u00a0of\u00a0words\u00a0popular\u00a0to\u00a0all\u00a0genres\u00a0as\u00a0well\u00a0as\u00a0words\u00a0\nwhich\u00a0are\u00a0only\u00a0prolific\u00a0within\u00a0some\u00a0genres.\u00a0A\u00a0typical\u00a0\nexample\u00a0of\u00a0the\u00a0weight\u00a0of\u00a0this\u00a0feature\u00a0is\u00a0illustrated\u00a0in\u00a0the\u00a0\nfact\u00a0that\u00a0forms\u00a0or\u00a0slides\u00a0are\u00a0likely\u00a0to\u00a0contain\u00a0a\u00a0fewer\u00a0\nnumber\u00a0of\u00a0definite\u00a0or\u00a0indefinite\u00a0articles\u00a0than\u00a0flowing\u00a0text.\u00a0\nSample\u00a0average\u00a0frequencies\u00a0of\u00a0words\u00a0commonly\u00a0found\u00a0in\u00a0\nthree\u00a0of\u00a0the\u00a0genres\u00a0discussed\u00a0in\u00a0the\u00a0current\u00a0study\u00a0are\u00a0\npresented\u00a0in\u00a0Table\u00a01\u00a0 (the\u00a0 average\u00a0is\u00a0 taken\u00a0 over\u00a0ten\u00a0\ndocuments).\u00a0In\u00a0the\u00a0reported\u00a0experiment\u00a0we\u00a0have\u00a0taken\u00a0\nwords\u00a0which\u00a0were\u00a0found\u00a0in\u00a075%\u00a0of\u00a0the\u00a0files\u00a0in\u00a0each\u00a0genre.\u00a0\nWe\u00a0have\u00a0also\u00a0tried\u00a0with\u00a0a\u00a0few\u00a0other\u00a0percentages\u00a0but\u00a0found\u00a0\nthis\u00a0to\u00a0show\u00a0the\u00a0best\u00a0results.\u00a0To\u00a0compile\u00a0the\u00a0common\u00a0\nwords,\u00a0we\u00a0also\u00a0tried\u00a0a\u00a0focused\u00a0method\u00a0of\u00a0compiling\u00a0words\u00a0\nfrom\u00a0the\u00a0six\u00a0genres\u00a0under\u00a0consideration\u00a0only,\u00a0and\u00a0even\u00a0\nwords\u00a0from\u00a0a\u00a0range\u00a0of\u00a0genres\u00a0which\u00a0exclude\u00a0the\u00a0genres\u00a0of\u00a0\ninterest. \u00a0 The \u00a0 combined \u00a0 list \u00a0 was \u00a0 adopted \u00a0 in \u00a0 the \u00a0 end\u00a0\nbecause\u00a0higher\u00a0accuracies\u00a0were\u00a0consistently\u00a0observed\u00a0in\u00a0\nall\u00a0three\u00a0style\u00adbased\u00a0classifiers\u00a0when\u00a0using\u00a0this\u00a0list\u00a0in\u00a0\ncomparison\u00a0to\u00a0the\u00a0other\u00a0two\u00a0lists.\nTable\u00a01.\u00a0Average\u00a0frequency\u00a0of\u00a0words\u00a0per\u00a0document\u00a0\nacross\u00a0three\u00a0genres.\nGenre\nWord\nBusiness\u00a0\nReport\nThesis \u00a0Minutes\nhave 47 109 0\nwith 71 210 13\ndo 11 0 0\ncase 0 10 0\nmeeting 0 0 8\ninformation 12 0 0\n5.\u00a0Experiments\n5.1.\u00a0Method\nEight\u00a0classifiers\u00a0(image\u00a0NB,\u00a0image\u00a0SVM,\u00a0image\u00a0\nRF,\u00a0style\u00a0NB,\u00a0style\u00a0NB,\u00a0style\u00a0SVM,\u00a0style\u00a0RF,\u00a0Rainbow\u00a0\nNB,\u00a0Rainbow\u00a0SVM)\u00a0have\u00a0been\u00a0tested\u00a0on\u00a0Dataset\u00a0I\u00a0and\u00a0II\u00a0\nfor\u00a0their\u00a0performance\u00a0in\u00a0recognising\u00a0six\u00a0genre\u00a0classes\u00a0\nincluding \u00a0 Academic \u00a0 Monograph, \u00a0 Book \u00a0 of \u00a0 Fiction,\u00a0\nBusiness\u00a0Report,\u00a0Minutes,\u00a0Periodicals,\u00a0and\u00a0Thesis.\u00a0The\u00a0\nperformance\u00a0is\u00a0examined\u00a0using\u00a010\u00adfold\u00a0cross\u00a0validation\u00a0\nresults.\u00a0\u00a0\nThe\u00a0performances\u00a0 \u00a0of\u00a0the\u00a0eight\u00a0classifiers\u00a0are\u00a0\nfirst\u00a0evaluated\u00a0to\u00a0 identify,\u00a0 for\u00a0each\u00a0 feature\u00a0type,\u00a0 the\u00a0\nstatistical \u00a0 methods \u00a0 that \u00a0 generate \u00a0 the \u00a0 best \u00a0 overall\u00a0\nperformances\u00a0on\u00a0Dataset\u00a0I\u00a0and\u00a0II\u00a0(Section\u00a06.1).\u00a0Then,\u00a0on\u00a0\neach\u00a0dataset,\u00a0the\u00a0best\u00a0classifiers,\u00a0one\u00a0for\u00a0each\u00a0feature\u00a0type,\u00a0\nFigure\u00a01.\u00a0Examples\u00a0of\u00a0document\u00a0image\u00a0representation:\u00a0Scientific\u00a0Article\u00a0(left)\u00a0and\u00a0Magazine\u00a0(right).\u00a0are\u00a0compared\u00a0in\u00a0detail\u00a0across\u00a0the\u00a0six\u00a0genres\u00a0(Section\u00a06.2\u00a0\nand\u00a06.3).\n5.2.\u00a0Evaluation\u00a0\nThe\u00a0results,\u00a0apart\u00a0from\u00a0those\u00a0reported\u00a0in\u00a0Section\u00a0\n6.3,\u00a0\u00a0have\u00a0been\u00a0evaluated\u00a0with\u00a0three\u00a0conventional\u00a0metrics\u00a0\nfor\u00a0classification:\u00a0accuracy,\u00a0precision\u00a0and\u00a0recall.\u00a0To\u00a0make\u00a0\nprecise\u00a0what\u00a0we\u00a0mean\u00a0by\u00a0these\u00a0terms,\u00a0let\u00a0N\u00a0be\u00a0the\u00a0total\u00a0\nnumber\u00a0of\u00a0documents\u00a0in\u00a0the\u00a0test\u00a0data,\u00a0Nc \u00a0the\u00a0number\u00a0of\u00a0\ndocuments \u00a0 in \u00a0 the \u00a0 class \u00a0C, \u00a0 TP(C) \u00a0the \u00a0 number \u00a0 of\u00a0\ndocuments\u00a0correctly\u00a0predicted\u00a0to\u00a0be\u00a0a\u00a0member\u00a0of\u00a0class\u00a0C,\u00a0\nand\u00a0FP(C)\u00a0the\u00a0number\u00a0of\u00a0documents\u00a0incorrectly\u00a0predicted\u00a0\nas\u00a0belonging\u00a0to\u00a0class\u00a0C.\u00a0Accuracy\u00a0A\u00a0is\u00a0defined\u00a0to\u00a0be\u00a0\nA=\u2211TP \ue09eC \ue09f\nN ,\nprecision\u00a0P(C)\u00a0of\u00a0class\u00a0C\u00a0is\u00a0defined\u00a0to\u00a0be\nP \ue09eC \ue09f=\nTP \ue09eC\ue09f\nTP \ue09eC\ue09f+FP \ue09eC\ue09f\n,\nand,\u00a0recall,\u00a0R(C),\u00a0of\u00a0class\u00a0C\u00a0is\u00a0defined\u00a0to\u00a0be\u00a0\nR\ue09eC \ue09f=\nTP \ue09eC\ue09f\nN\nc\n.\nAlthough \u00a0 some \u00a0 debate \u00a0 surrounds \u00a0 the \u00a0 suitability \u00a0 of\u00a0\naccuracy, \u00a0 precision \u00a0 and \u00a0 recall \u00a0 as \u00a0 a \u00a0 measurement \u00a0 of\u00a0\ninformation\u00a0retrieval\u00a0tasks,\u00a0for\u00a0classification\u00a0tasks,\u00a0they\u00a0\nare\u00a0still\u00a0deemed\u00a0to\u00a0be\u00a0a\u00a0reasonable\u00a0indicator\u00a0of\u00a0classifier\u00a0\nperformance.\n6.\u00a0Results\n6.1.\u00a0Overall\u00a0accuracy\nThe\u00a0overall\u00a0accuracies\u00a0of\u00a0classifiers\u00a0built\u00a0on\u00a0each\u00a0\nfeature\u00a0type\u00a0across\u00a0statistical\u00a0methods\u00a0is\u00a0reported\u00a0in\u00a0Table\u00a0\n2\u00a0(best\u00a0performances\u00a0are\u00a0indicated\u00a0in\u00a0bold\u00adface).\u00a0\nThe \u00a0 tests \u00a0 on \u00a0 the \u00a0 two \u00a0 datasets, \u00a0 consistently\u00a0\nindicate\u00a0Na\u00efve\u00a0Bayes\u00a0as\u00a0the\u00a0best\u00a0statistical\u00a0method\u00a0for\u00a0\nimage\u00a0features.\u00a0Although\u00a0the\u00a0overall\u00a0accuracies\u00a0of\u00a0Na\u00efve\u00a0\nBayes\u00a0and\u00a0Random\u00a0Forest\u00a0are\u00a0comparable\u00a0on\u00a0the\u00a0larger\u00a0\ndataset,\u00a0averaging\u00a0(with\u00a0a\u00a0heavier\u00a0weight\u00a0on\u00a0the\u00a0larger\u00a0set)\u00a0\nthe\u00a0performances\u00a0on\u00a0the\u00a0two\u00a0datasets,\u00a0suggested\u00a0Na\u00efve\u00a0\nBayes\u00a0as\u00a0a\u00a0better\u00a0performer\u00a0for\u00a0image.\u00a0On\u00a0both\u00a0datasets,\u00a0\nSupport\u00a0Vector\u00a0Machine\u00a0and\u00a0Random\u00a0Forest\u00a0are\u00a0both\u00a0\nbetter\u00a0 than \u00a0 Na\u00efve\u00a0 Bayes \u00a0 for\u00a0 style\u00a0 features. \u00a0 Although\u00a0\nSupport\u00a0Vector\u00a0Machine\u00a0and\u00a0Random\u00a0Forest\u00a0 \u00a0performs\u00a0\ncomparably\u00a0on\u00a0the\u00a0smaller\u00a0Dataset\u00a0I,\u00a0we\u00a0have\u00a0chosen\u00a0\nRandom\u00a0Forest\u00a0as\u00a0the\u00a0better\u00a0choice\u00a0for\u00a0style,\u00a0because\u00a0the\u00a0\ndifference\u00a0was\u00a0shown\u00a0to\u00a0be\u00a0prominent\u00a0on\u00a0Dataset\u00a0II.\u00a0We\u00a0\nhave\u00a0chosen\u00a0Na\u00efve\u00a0Bayes\u00a0for\u00a0Rainbow\u00a0for\u00a0comparison\u00a0on\u00a0\nDataset\u00a0I,\u00a0\u00a0and\u00a0Support\u00a0Vector\u00a0Machine\u00a0for\u00a0Rainbow\u00a0on\u00a0\nDataset\u00a0II:\u00a0in\u00a0both\u00a0cases\u00a0the\u00a0difference\u00a0in\u00a0performance\u00a0\nwas\u00a0too\u00a0large\u00a0to\u00a0indicate\u00a0an\u00a0overall\u00a0better\u00a0method\u00a0for\u00a0\nRainbow.\u00a0\u00a0\u00a0\u00a0\u00a0\nIn\u00a0passing,\u00a0we\u00a0observe\u00a0that,\u00a0based\u00a0on\u00a0the\u00a0overall\u00a0\naccuracies\u00a0of\u00a0the\u00a0classifiers\u00a0on\u00a0the\u00a0two\u00a0datasets,\u00a0the\u00a0\nclassifiers\u00a0based\u00a0on\u00a0image\u00a0features\u00a0are\u00a0the\u00a0least\u00a0affected\u00a0\nby\u00a0training\u00a0dataset\u00a0size\u00a0(average\u00a0difference\u00a0in\u00a0accuracy\u00a0\n0.036)\u00a0and\u00a0the\u00a0classifiers\u00a0based\u00a0on\u00a0\u00a0Rainbow\u00a0are\u00a0the\u00a0most\u00a0\naffected\u00a0by\u00a0dataset\u00a0size\u00a0(average\u00a0difference\u00a0in\u00a0accuracy\u00a0\n0.328).\u00a0Also\u00a0the\u00a0results\u00a0indicate\u00a0that\u00a0Support\u00a0Vector\u00a0\nmachine\u00a0and\u00a0Random\u00a0Forest\u00a0seem\u00a0more\u00a0affected\u00a0by\u00a0\ndataset\u00a0size\u00a0than\u00a0Na\u00efve\u00a0Bayes.\n6.2.\u00a0Precision\u00a0and\u00a0recall\nIn\u00a0this\u00a0section\u00a0we\u00a0compare\u00a0the\u00a0precision\u00a0and\u00a0\nrecall\u00a0\u00a0across\u00a0genres\u00a0of\u00a0the\u00a0classifiers\u00a0for\u00a0each\u00a0feature\u00a0type\u00a0\nwhich\u00a0have\u00a0been\u00a0shown\u00a0to\u00a0have\u00a0the\u00a0best\u00a0overall\u00a0accuracies\u00a0\nin\u00a0the\u00a0previous\u00a0section\u00a0(on\u00a0Dataset\u00a0I,\u00a0image\u00a0NB,\u00a0style\u00a0RF\u00a0\nand\u00a0Rainbow\u00a0NB;\u00a0on\u00a0Dataset\u00a0II,\u00a0image\u00a0NB,\u00a0style\u00a0RF,\u00a0\nRainbow\u00a0SVM).\u00a0The\u00a0figures\u00a0in\u00a0Tables\u00a03\u00a0and\u00a04\u00a0show\u00a0the\u00a0\nprecision\u00a0and\u00a0recall\u00a0across\u00a0the\u00a0six\u00a0genres\u00a0of\u00a0each\u00a0classifier\u00a0\ntested\u00a0on\u00a0Dataset\u00a0I\u00a0and\u00a0II.\u00a0The\u00a0genres\u00a0are\u00a0indicated\u00a0in\u00a0the\u00a0\nleft\u00a0most\u00a0column\u00a0of\u00a0the\u00a0tables,\u00a0with\u00a0the\u00a0numbers\u00a0of\u00a0\ndocuments \u00a0 in \u00a0 each \u00a0 class \u00a0 noted \u00a0 in \u00a0 parenthesis. \u00a0 The\u00a0\nclassifiers\u00a0being\u00a0tested\u00a0are\u00a0indicated\u00a0in\u00a0parenthesis\u00a0at\u00a0the\u00a0\ntop\u00a0of\u00a0each\u00a0of\u00a0the\u00a0following\u00a0columns.\nTable\u00a02.\u00a0Overall\u00a0accuracy\u00a0of\u00a0feature\u00a0types\u00a0across\u00a0statistical\u00a0methods\nData\u00a0&\u00a0method\nFeature\u00a0type\nDataset\u00a0I\u00a0(103\u00a0items) Dataset\u00a0II\u00a0(494\u00a0items)\nNB SVM RF NB SVM RF\nimage 0.524 0.35 0.417 0.48 0.395 0.48\nstyle 0.505 0.573 0.641 0.63 0.724 0.828\nRainbow 0.428 0.25 N\/A 0.618 0.715 N\/ATable\u00a03.\u00a0Genre\u00a0classification\u00a0across\u00a0six\u00a0classes\u00a0on\u00a0Dataset\u00a0I,\u00a010\u00adfold\u00a0cross\u00a0validation.\nGenre\u00a0(no.\u00a0items)\nPrecision\u00a0\n(image\u00a0NB)\nRecall\u00a0\n(image\u00a0NB)\nPrecision\u00a0\n(style\u00a0RF)\nRecall\u00a0\n(style\u00a0RF)\nPrecision\u00a0\n(Rainbow\u00a0NB)\nRecall\u00a0\n(Rainbow\u00a0NB)\nAcademic\u00a0Monograph\u00a0\n(16)\n0.462 0.375 \u00a00.643 0.563 0.241 0.217\nBook\u00a0of\u00a0Fiction\u00a0(16) 0.4 0.125 0.813 0.813 0.763 0.971\nBusiness\u00a0Report\u00a0(15) 0.273 0.2 0.667 0.4 0.453 0.173\nMinutes\u00a0(19) 0.667 0.526 0.56 0.737 0.767 0.272\nPeriodicals\u00a0\n(Newspaper,\u00a0Magazine)\u00a0\n(19)\n0.773 0.895 0.565 0.684 0.232 0.570\nThesis\u00a0(19) 0.432 0.889 0.688 0.611 0.541 0.377\nTable\u00a04.\u00a0Genre\u00a0classification\u00a0across\u00a0six\u00a0genres\u00a0on\u00a0Dataset\u00a0II,\u00a010\u00adfold\u00a0cross\u00a0validation.\nGenre\u00a0\n(no.\u00a0items)\nPrecision\u00a0\n(image\u00a0NB)\nRecall\u00a0\n(image\u00a0NB)\nPrecision\u00a0\n(style\u00a0RF)\nRecall\u00a0\n(style\u00a0RF)\nPrecision\u00a0\n(Rainbow\u00a0SVM)\nRecall\u00a0\n(Rainbow\u00a0SVM)\nAcademic\u00a0Monograph\u00a0\n(99)\n0.25 0.101\u00a0\u00a0 0.718 0.747 0.74 0.411\nBook\u00a0of\u00a0Fiction\u00a0(29) 0.111 0.069 0.923 0.828 0.931 0.807\nBusiness\u00a0Report\u00a0(100) 0.385 0.05 0.825 0.85 0.797 0.609\nMinutes\u00a0(99) 0.604\u00a0 0.818\u00a0 0.913 0.949 0.91 0.874\nPeriodicals\u00a0\n(Newspaper,\u00a0Magazine)\u00a0\n(67)\n0.425\u00a0 0.716\u00a0\u00a0 0.774 0.716 0.457 0.794\nThesis\u00a0(100) 0.517 0.91 0.866 0.84 0.696 0.893\nThe\u00a0results\u00a0in\u00a0Table\u00a03\u00a0indicate\u00a0that,\u00a0on\u00a0Dataset\u00a0I,\u00a0\nboth\u00a0precision\u00a0and\u00a0recall\u00a0of \u00a0image\u00a0NB \u00a0with\u00a0respect\u00a0to\u00a0\nPeriodicals\u00a0are\u00a0much\u00a0higher\u00a0than\u00a0the\u00a0other\u00a0two\u00a0classifiers.\u00a0\nOn\u00a0the\u00a0other\u00a0hand,\u00a0 \u00a0the\u00a0results\u00a0indicate\u00a0that\u00a0academic\u00a0\nmonographs\u00a0and\u00a0business\u00a0reports\u00a0are\u00a0best\u00a0recognised\u00a0by\u00a0\nstyle\u00a0RF.\u00a0Books\u00a0\u00a0of\u00a0fiction\u00a0seem\u00a0to\u00a0be\u00a0best\u00a0distinguished\u00a0\nby\u00a0style\u00a0RF\u00a0and\u00a0Rainbow\u00a0NB,\u00a0but\u00a0we\u00a0also\u00a0observe\u00a0that\u00a0\nthe \u00a0 two \u00a0 classifiers \u00a0 seem \u00a0 to \u00a0 work \u00a0 in \u00a0 complementary\u00a0\npositions\u00a0(that\u00a0is,\u00a0where\u00a0one\u00a0has\u00a0better\u00a0recall\u00a0the\u00a0other\u00a0has\u00a0\nbetter \u00a0 precision). \u00a0 With \u00a0 the \u00a0 genre \u00a0 class \u00a0 Thesis, \u00a0 the\u00a0\ncomplementary\u00a0situation\u00a0seems\u00a0to\u00a0be\u00a0formed\u00a0between\u00a0\nimage\u00a0NB\u00a0and\u00a0style\u00a0RF.\u00a0\u00a0\nThe\u00a0performance\u00a0on\u00a0the\u00a0genre\u00a0class\u00a0Minutes\u00a0\nintroduces\u00a0some\u00a0controversy:\u00a0on\u00a0the\u00a0basis\u00a0of\u00a0precision,\u00a0\nRainbow\u00a0NB \u00a0shows\u00a0a\u00a0higher\u00a0rate\u00a0than\u00a0the\u00a0other\u00a0two\u00a0\nclassifiers,\u00a0but,\u00a0on\u00a0the\u00a0basis\u00a0of\u00a0recall, \u00a0style\u00a0RF \u00a0out\u00a0\nperforms \u00a0Rainbow \u00a0 NB. \u00a0 The \u00a0 comparison \u00a0 is \u00a0 further\u00a0\ncomplicated \u00a0 by \u00a0 the \u00a0 observation \u00a0 that \u00a0 the \u00a0 average \u00a0 of\u00a0\nprecision\u00a0and\u00a0recall\u00a0(given\u00a0equal\u00a0weight)\u00a0suggests\u00a0\u00a0image\u00a0\nNB\u00a0as\u00a0the\u00a0best\u00a0performer.\u00a0\nOn\u00a0the\u00a0basis\u00a0of\u00a0average\u00a0performance\u00a0taken\u00a0over\u00a0\nprecision\u00a0and\u00a0recall,\u00a0the\u00a0results\u00a0in\u00a0Table\u00a04\u00a0presents\u00a0style\u00a0\nRF\u00a0as\u00a0the\u00a0best\u00a0overall\u00a0performer.\u00a0The\u00a0precision\u00a0of\u00a0style\u00a0\nRF\u00a0is\u00a0better\u00a0than\u00a0\u00a0that\u00a0of\u00a0both\u00a0of\u00a0the\u00a0other\u00a0classifiers\u00a0in\u00a0\ndetecting\u00a0documents\u00a0except\u00a0academic\u00a0monographs\u00a0and\u00a0\nbooks\u00a0of\u00a0fiction,\u00a0and\u00a0recall\u00a0is\u00a0better\u00a0with\u00a0respect\u00a0to\u00a0\u00a0all\u00a0\nclasses \u00a0 except \u00a0 Periodicals \u00a0 and \u00a0 Thesis. \u00a0 The \u00a0 classifier\u00a0\nimage\u00a0NB\u00a0shows\u00a0the\u00a0best\u00a0recall\u00a0rate\u00a0for\u00a0detecting\u00a0theses\u00a0\nand \u00a0 displays \u00a0 a \u00a0 comparable \u00a0 recall \u00a0 rate \u00a0 for \u00a0 detecting\u00a0\nperiodicals.\u00a0Table\u00a05.\u00a0Confusion\u00a0matrix:\u00a0Image\u00a0NB\u00a0on\u00a0Dataset\u00a0II.\u00a0\n\u00a0classified\u00a0as\u00a0\u00ad\u00ad\u00ad> AM BF BR M P T\nAM \u00a010 4 4 20 25 36\nBF 1 2 0 4 7 15\nBR 17 9 5 16 32 21\nM 6 0 1 81 0 11\nP 5 1 3 8 48 2\nT \u00a01 2 0 5 1 91\nTable\u00a06.\u00a0Confusion\u00a0matrix:\u00a0Style\u00a0RF\u00a0on\u00a0Dataset\u00a0II.\u00a0\n\u00a0classified\u00a0as\u00a0\u00ad\u00ad\u00ad> AM BF BR M P T\nAM \u00a074 1 8 3 4 9\nBF 0 24 0 0 2 0\nBR 7 0 85 3 4 1\nM 4 0 1 94 0 0\nP 6 0 7 3 48 3\nT \u00a09 1 2 0 4 84\nTable\u00a07.\u00a0Confusion\u00a0matrix:\u00a0Rainbow\u00a0SVM\u00a0on\u00a0Dataset\u00a0II.\u00a0\n\u00a0classified\u00a0as\u00a0\u00ad\u00ad\u00ad> AM BF BR M P T\nAM \u00a041 1 8 3 18 28\nBF 0 23 1 0 4 1\nBR 6 0 61 3 28 2\nM 3 1 2 87 4 3\nP 3 0 5 3 53 3\nT \u00a02 0 1 0 8 89\nAlthough\u00a0the\u00a0results\u00a0of\u00a0the\u00a0experiments\u00a0suggest\u00a0style\u00a0RF\u00a0\nas\u00a0the\u00a0overall\u00a0best\u00a0performer\u00a0on\u00a0the\u00a0two\u00a0datasets,\u00a0they\u00a0\u00a0do\u00a0\nnot\u00a0identify\u00a0genre\u00a0classes\u00a0for\u00a0each\u00a0classifier\u00a0on\u00a0which\u00a0the\u00a0\nclassifier\u00a0consistently\u00a0outshines\u00a0the\u00a0other\u00a0two\u00a0classifiers.\u00a0\nHowever,\u00a0upon\u00a0closer\u00a0examination,\u00a0the\u00a0results\u00a0do\u00a0show\u00a0\nthat\u00a0the\u00a0binary\u00a0partition\u00a0of\u00a0the\u00a0genre\u00a0classes,\u00a0into\u00a0classes\u00a0\nwith \u00a0 the \u00a0 three \u00a0 best \u00a0 performance \u00a0 \u00a0 and \u00a0 \u00a0 three \u00a0 worst\u00a0\nperformance,\u00a0is\u00a0preserved\u00a0across\u00a0the\u00a0experiments\u00a0on\u00a0the\u00a0\ntwo\u00a0datasets:\u00a0these\u00a0partitions\u00a0are\u00a0(Minutes,\u00a0Periodicals,\u00a0\nThesis)\u00a0and\u00a0(Academic\u00a0Monograph,\u00a0Book\u00a0of\u00a0Fiction,\u00a0\nBusiness\u00a0Report)\u00a0for \u00a0image\u00a0NB,\u00a0and\u00a0 (Book\u00a0of\u00a0Fiction,\u00a0\nMinutes,\u00a0Thesis)\u00a0and\u00a0(Academic\u00a0Monograph,\u00a0Business\u00a0\nReport,\u00a0Periodicals)\u00a0for\u00a0style\u00a0RF\u00a0and\u00a0Rainbow\u00a0SVM.\nThe\u00a0general\u00a0low\u00a0level\u00a0performance\u00a0of\u00a0the\u00a0image\u00a0\nfeatures\u00a0is\u00a0partly\u00a0due\u00a0to\u00a0the\u00a0crude\u00a0image\u00a0representation.\u00a0In\u00a0\nthe\u00a0current\u00a0model,\u00a0the\u00a0image\u00a0features\u00a0only\u00a0capture\u00a0the\u00a0\nfirst\u00a0page\u00a0of\u00a0the\u00a0document,\u00a0and\u00a0each\u00a0pixel\u00a0value\u00a0is\u00a0\nstrongly\u00a0 anchored \u00a0to \u00a0its\u00a0 position. \u00a0This \u00a0representation\u00a0\ncould\u00a0be\u00a0improved\u00a0to\u00a0combine\u00a0representations\u00a0of\u00a0several\u00a0\npages \u00a0 of\u00a0 the \u00a0 document \u00a0 and \u00a0 to \u00a0 soften \u00a0 the\u00a0 positional\u00a0\ninformation\u00a0to\u00a0embody\u00a0the\u00a0general\u00a0shape\u00a0or\u00a0topology\u00a0of\u00a0\nthe\u00a0image.\u00a0Likewise,\u00a0for\u00a0style,\u00a0the\u00a0size\u00a0of\u00a0the\u00a0dataset\u00a0and\u00a0\nthe\u00a0variety\u00a0of\u00a0the\u00a0documents\u00a0in\u00a0the\u00a0 \u00a0datasets\u00a0used\u00a0for\u00a0\ntraining\u00a0and\u00a0compiling\u00a0word\u00a0lists\u00a0 \u00a0should\u00a0be\u00a0further\u00a0\nexamined\u00a0for\u00a0refinement.\u00a06.3.\u00a0Error\u00a0analysis\nIn\u00a0Section\u00a06.2\u00a0we\u00a0observed\u00a0the\u00a0style\u00a0features\u00a0as\u00a0\nthe\u00a0best\u00a0overall\u00a0indicator\u00a0for\u00a0detecting\u00a0genre,\u00a0however,\u00a0the\u00a0\nsituation\u00a0may\u00a0be\u00a0more\u00a0complicated\u00a0than\u00a0such\u00a0a\u00a0conclusion\u00a0\nmight\u00a0portend.\u00a0To\u00a0understand\u00a0fully\u00a0the\u00a0results\u00a0\u00a0in\u00a0Section\u00a0\n6.2,\u00a0a\u00a0thorough\u00a0error\u00a0analysis\u00a0is\u00a0necessary.\u00a0In\u00a0Tables\u00a05,\u00a06,\u00a0\nand \u00a0 7, \u00a0 we \u00a0 have \u00a0 displayed \u00a0 the \u00a0 errors \u00a0 as \u00a0 six\u00adby\u00adsix\u00a0\nconfusion\u00a0matrices. \u00a0The\u00a0genre\u00a0class\u00a0names\u00a0have\u00a0been\u00a0\ndenoted\u00a0by\u00a0their\u00a0abbreviated\u00a0names\u00a0to\u00a0save\u00a0space.\u00a0As\u00a0a\u00a0\nreminder,\u00a0 \u00a0AM\u00a0 stands\u00a0for\u00a0Academic\u00a0Monograph, \u00a0BF\u00a0\nstands\u00a0for\u00a0 \u00a0Book\u00a0of\u00a0Fiction, \u00a0BR\u00a0 stands\u00a0for\u00a0 \u00a0Business\u00a0\nReport,\u00a0M\u00a0stands\u00a0for\u00a0Minutes,\u00a0P\u00a0stands\u00a0for\u00a0\u00a0Periodicals,\u00a0\nand\u00a0T\u00a0stands\u00a0for\u00a0Thesis.\u00a0\nWe\u00a0have\u00a0used\u00a0two\u00a0different\u00a0measures\u00a0of\u00a0the\u00a0\nconfusion\u00a0level\u00a0displayed\u00a0by\u00a0the\u00a0classifier:\u00a0one\u00a0based\u00a0on\u00a0\nbelief\u00a0([8])\u00a0and\u00a0another\u00a0based\u00a0on\u00a0error\u00a0impact.\u00a0The\u00a0belief\u00a0\nBC(C1:C2)\u00a0of\u00a0a\u00a0classifier\u00a0C\u00a0that\u00a0class\u00a0C1\u00a0is\u00a0class\u00a0C2\u00a0is\u00a0the\u00a0\nnumber\u00a0of\u00a0documents\u00a0in\u00a0class\u00a0C1\u00a0labelled\u00a0as\u00a0being\u00a0in\u00a0C2\u00a0\ndivided\u00a0by\u00a0the\u00a0number\u00a0of\u00a0documents\u00a0in\u00a0class \u00a0C1.\u00a0The\u00a0\nerror\u00a0impact\u00a0EC(C1:C2)\u00a0of\u00a0the\u00a0class\u00a0C1\u00a0in\u00a0the\u00a0documents\u00a0\nlabelled\u00a0by\u00a0the\u00a0classifier\u00a0C\u00a0as\u00a0C2\u00a0measures\u00a0the\u00a0percentage\u00a0\nof\u00a0errors\u00a0arising\u00a0from\u00a0the\u00a0predicted\u00a0labels\u00a0of\u00a0documents\u00a0\nin\u00a0class\u00a0C1\u00a0within\u00a0the\u00a0errors\u00a0arising\u00a0from\u00a0the\u00a0classifier's\u00a0\ndecision\u00a0to\u00a0label\u00a0documents\u00a0as\u00a0belonging\u00a0to\u00a0C2.\u00a0\u00a0More\u00a0\nprecisely,\u00a0if\u00a0C1\u00a0=\u00a0C2,\u00a0EC(C1:C2)\u00a0is\u00a0defined\u00a0to\u00a0be\u00a00,\u00a0\u00a0and\u00a0\nif\u00a0C1\u00a0\u2260\u00a0C2,\u00a0EC(C1:C2)\u00a0is\u00a0defined\u00a0to\u00a0be\u00a0the\u00a0number\u00a0of\u00a0\ndocuments\u00a0of\u00a0class \u00a0C1 \u00a0which\u00a0have\u00a0been\u00a0labelled\u00a0as\u00a0\nbelonging \u00a0 to \u00a0C2 \u00a0divided \u00a0 by \u00a0 the\u00a0 total \u00a0 number \u00a0 of\u00a0\ndocuments\u00a0incorrectly\u00a0labelled\u00a0as\u00a0belonging\u00a0to\u00a0class\u00a0C2.\u00a0\nTo\u00a0compare\u00a0values\u00a0across\u00a0classes,\u00a0we\u00a0have\u00a0compensated\u00a0\nfor\u00a0different\u00a0 numbers\u00a0 of\u00a0 document\u00a0 in\u00a0each\u00a0class \u00a0by\u00a0\ndividing \u00a0BC(C1:C2)\u00a0 and \u00a0EC(C1:C2)\u00a0 with\u00a0the\u00a0sum\u00a0of\u00a0\nBC(C1:C2) \u00a0over\u00a0all \u00a0C1, \u00a0and\u00a0 EC(C1:C2) \u00a0over\u00a0all\u00a0 C2,\u00a0\nrespectively.\u00a0If\u00a0the\u00a0sum\u00a0is\u00a0zero\u00a0then\u00a0we\u00a0simply\u00a0define\u00a0the\u00a0\nbelief\u00a0and\u00a0error\u00a0impact\u00a0to\u00a0be\u00a0zero.\u00a0The\u00a0same\u00a0notation\u00a0for\u00a0\nbelief\u00a0and\u00a0error\u00a0impact\u00a0has\u00a0been\u00a0retained\u00a0to\u00a0denote\u00a0the\u00a0\nnormalised\u00a0quantity.\u00a0\nWe\u00a0have\u00a0introduced\u00a0error\u00a0impact\u00a0in\u00a0contrast\u00a0to\u00a0\nbelief\u00a0because\u00a0belief\u00a0is\u00a0heavily\u00a0influenced\u00a0by\u00a0the\u00a0overall\u00a0\nperformance\u00a0of\u00a0the\u00a0classifier\u00a0itself.\u00a0That\u00a0is,\u00a0having\u00a0a\u00a0high\u00a0\nlevel\u00a0of\u00a0correct\u00a0beliefs\u00a0greatly\u00a0reduces\u00a0the\u00a0incorrect\u00a0\nbeliefs\u00a0of\u00a0the\u00a0classifier.\u00a0In\u00a0contrast,\u00a0the\u00a0greater\u00a0or\u00a0smaller\u00a0\nnumber\u00a0of\u00a0academic\u00a0monographs\u00a0being\u00a0labelled\u00a0correctly\u00a0\nas\u00a0Academic\u00a0Monograph\u00a0does\u00a0not\u00a0have\u00a0as\u00a0predominant\u00a0an\u00a0\ninfluence\u00a0over\u00a0the\u00a0relative\u00a0distribution\u00a0of\u00a0different\u00a0classes\u00a0\namongst\u00a0the\u00a0documents\u00a0which\u00a0have\u00a0been\u00a0incorrectly\u00a0\nlabelled\u00a0Academic\u00a0Monograph.\u00a0We\u00a0deemed\u00a0error\u00a0impact\u00a0\nto\u00a0be\u00a0a\u00a0better\u00a0metric\u00a0for\u00a0accentuating\u00a0the\u00a0differences\u00a0in\u00a0\nconfusion\u00a0levels\u00a0between\u00a0classes\u00a0within\u00a0the\u00a0performance\u00a0\nof\u00a0a\u00a0single\u00a0\u00a0classifier.\u00a0\nBetween\u00a0two\u00a0different\u00a0classes \u00a0C1\u00a0 and \u00a0C2, \u00a0the\u00a0\nconfusion\u00a0level\u00a0on\u00a0the\u00a0basis\u00a0of\u00a0belief, \u00a0CB(C1:C2), \u00a0is\u00a0\ndefined\u00a0to\u00a0be\u00a0CB(C1:C2)\u00a0=\u00a0BC(C1:C2)\u00a0+\u00a0BC(C2:C1),\u00a0and\u00a0\nthe \u00a0 confusion \u00a0 level \u00a0 on \u00a0 the \u00a0 basis \u00a0 of \u00a0 error \u00a0 impact,\u00a0\nCE(C1:C2),\u00a0is\u00a0defined\u00a0to\u00a0be\u00a0CE(C1:C2)\u00a0=\u00a0EC(C1:C2)\u00a0+\u00a0\nEC(C2:C1).\u00a0\nTable\u00a08.\u00a0Feature\u00a0types\u00a0with\u00a0lowest\u00a0pairwise\u00a0confusion\u00a0\nlevel\u00a0on\u00a0two\u00a0confusion\u00a0metrics.\nMetric\nGenre\u00a0pair\nCB CE\nAM BF style,\u00a0Rainbow Rainbow\nAM BR style style\nAM M style Rainbow\nAM P style style\nAM T style image\nBF BR style,\u00a0Rainbow style\nBF M style style\nBF P style image\nBF T style,\u00a0Rainbow Rainbow\nBR M style,\u00a0Rainbow Rainbow\nBR P style style\nBR T style,\u00a0Rainbow style\nM P style image\nM T style style\nP T image image\nThe\u00a0contents\u00a0of\u00a0Table\u00a08\u00a0indicate\u00a0the\u00a0feature\u00a0type\u00a0\nof\u00a0the\u00a0classifier\u00a0exhibiting\u00a0the\u00a0lowest\u00a0confusion\u00a0level,\u00a0\nbetween\u00a0the\u00a0pair\u00a0of\u00a0genre\u00a0classes\u00a0indicated\u00a0on\u00a0the\u00a0two\u00a0left\u00a0\nmost\u00a0columns,\u00a0based\u00a0on\u00a0the\u00a0confusion\u00a0metric\u00a0noted\u00a0on\u00a0the\u00a0\ntop\u00a0most\u00a0row.\u00a0\u00a0Two\u00a0feature\u00a0types\u00a0have\u00a0been\u00a0noted\u00a0where\u00a0\nthe\u00a0confusion\u00a0levels\u00a0were\u00a0equal.\u00a0\nBoth\u00a0metrics\u00a0agree\u00a0that\u00a0style\u00a0displays\u00a0the\u00a0lowest\u00a0\nlevel\u00a0of\u00a0confusion\u00a0in\u00a0differentiating\u00a0the\u00a0pairs\u00a0 Book\u00a0of\u00a0\nFiction \u00a0and\u00a0 Minutes, \u00a0 Academic \u00a0 Monograph\u00a0 and\u00a0\nPeriodicals,\u00a0 Book\u00a0of\u00a0Fiction \u00a0and \u00a0Minutes, \u00a0Business\u00a0\nReport\u00a0 and \u00a0Periodicals \u00a0and \u00a0Minutes\u00a0 and \u00a0Thesis,\u00a0and\u00a0\nimage\u00a0 \u00a0displays\u00a0the\u00a0lowest\u00a0level\u00a0for\u00a0 \u00a0Periodicals\u00a0 and\u00a0\nThesis\u00a0(see\u00a0Table\u00a08).\u00a0However,\u00a0we\u00a0would\u00a0ideally\u00a0like\u00a0to\u00a0\nminimise\u00a0both\u00a0error\u00a0impact\u00a0and\u00a0out\u00adof\u00adclass\u00a0belief.\u00a0For\u00a0\neach\u00a0pair\u00a0of\u00a0classes\u00a0in\u00a0Table\u00a08,\u00a0if\u00a0we\u00a0combine\u00a0the\u00a0features\u00a0\nwhich\u00a0have\u00a0been\u00a0calculated\u00a0to\u00a0have\u00a0the\u00a0lowest\u00a0level\u00a0of\u00a0\nconfusion\u00a0on\u00a0the\u00a0basis\u00a0of\u00a0belief\u00a0and\u00a0error\u00a0impact,\u00a0the\u00a0\nresults\u00a0seem\u00a0to\u00a0support\u00a0our\u00a0intuition.\u00a0For\u00a0example,\u00a0style\u00a0\nand\u00a0image\u00a0would\u00a0be\u00a0estimated\u00a0as\u00a0the\u00a0best\u00a0features\u00a0to\u00a0distinguish\u00a0most\u00a0pairs\u00a0which\u00a0include\u00a0Periodicals\u00a0which\u00a0\nconforms\u00a0to\u00a0instinct,\u00a0since\u00a0periodicals\u00a0deal\u00a0with\u00a0a\u00a0wide\u00a0\nrange\u00a0of\u00a0topics,\u00a0and\u00a0we\u00a0do\u00a0not\u00a0expect\u00a0Rainbow\u00a0features\u00a0\nwhich\u00a0emphasise\u00a0topical\u00a0distinction\u00a0to\u00a0fare\u00a0well.\u00a0 \u00a0In\u00a0\nparticular,\u00a0visually\u00a0elaborate\u00a0periodicals\u00a0and\u00a0structurally\u00a0\nformal\u00a0theses\u00a0are\u00a0unsurprisingly\u00a0best\u00a0distinguished\u00a0by\u00a0\nimage\u00a0features.\u00a0\nThe \u00a0 same \u00a0 consideration \u00a0 of \u00a0 confusion \u00a0 levels\u00a0\nindicates\u00a0that\u00a0topical\u00a0features\u00a0do\u00a0little\u00a0to\u00a0distinguish\u00a0genre\u00a0\nclasses\u00a0likely\u00a0to\u00a0have\u00a0similar\u00a0topic\u00a0areas\u00a0such\u00a0as\u00a0Academic\u00a0\nMonograph\u00a0and\u00a0Thesis.\u00a0And\u00a0it\u00a0supports\u00a0the\u00a0expectation\u00a0\nthat \u00a0 distinctions \u00a0 between \u00a0 Academic \u00a0 Monographs \u00a0 and\u00a0\nBook\u00a0of\u00a0Fiction,\u00a0and\u00a0Book\u00a0of\u00a0Fiction\u00a0and\u00a0Thesis\u00a0would\u00a0be\u00a0\nhighly\u00a0topical.\nTable\u00a09.\u00a0The\u00a0difference\u00a0between\u00a0\u00a0maximum\u00a0and\u00a0\nminimum\u00a0belief\u00a0and\u00a0error\u00a0impact\u00a0confusion.\nMetric\nGenre\u00a0pair\nCB CE\nAM BF 0.25 0.01\nAM BR 0.5 0.06\nAM M 0.2 0.51\nAM P 0.2 0.08\nAM T 0.08 0.42\nBF BR 0.39 0.22\nBF M 0.08 0.54\nBF P 0.13 0.66\nBF T 0.32 0.73\nBR M 0.14 0.18\nBR P 0.37 0.09\nBR T 0.07 0.28\nM P 0.68 0.24\nM T 0.08 0.64\nP T 0.07 0.39\nThe \u00a0 difference \u00a0 between \u00a0 the \u00a0 maximum \u00a0 and\u00a0\nminimum\u00a0confusion\u00a0level\u00a0seen\u00a0across\u00a0features\u00a0between\u00a0\npairs\u00a0ranges\u00a0from\u00a00.01\u00a0to\u00a00.73\u00a0(on\u00a0the\u00a0basis\u00a0of\u00a0CE),\u00a0and,\u00a0\nfrom\u00a0\u00a0 \u00a00.07\u00a0to\u00a00.72\u00a0(on\u00a0the\u00a0basis\u00a0of\u00a0CB)\u00a0[see\u00a0Table\u00a09].\u00a0\nAlthough\u00a0the\u00a0features\u00a0indicated\u00a0in\u00a0Table\u00a08\u00a0are\u00a0the\u00a0features\u00a0\nexhibiting\u00a0the\u00a0lowest\u00a0confusion\u00a0levels,\u00a0in\u00a0some\u00a0cases,\u00a0the\u00a0\ndifference\u00a0is\u00a0very\u00a0slight\u00a0(e.g.\u00a0Academic\u00a0Monographs\u00a0and\u00a0\nBook\u00a0of\u00a0Fiction).\u00a0In\u00a0interpreting\u00a0the\u00a0information\u00a0in\u00a0Table\u00a0\n8,\u00a0it\u00a0seems\u00a0reasonable\u00a0to\u00a0take\u00a0the\u00a0differences\u00a0noted\u00a0in\u00a0\nTable\u00a09\u00a0into\u00a0consideration.\u00a0For\u00a0example,\u00a0the\u00a0pair\u00a0of\u00a0\nclasses \u00a0 Book \u00a0 of \u00a0 Fiction \u00a0 and \u00a0 Periodicals \u00a0 has \u00a0 been\u00a0\nexamined\u00a0to\u00a0be\u00a0best\u00a0distinguished\u00a0by\u00a0style\u00a0and\u00a0image\u00a0(see\u00a0\nTable\u00a08),\u00a0but\u00a0the\u00a0figures\u00a0in\u00a0Table\u00a09\u00a0seem\u00a0to\u00a0suggest\u00a0that\u00a0\nthe\u00a0weight\u00a0is\u00a0more\u00a0prominently\u00a0on\u00a0image.\u00a0Likewise,\u00a0\nAcademic \u00a0 Monographs \u00a0 and \u00a0 Minutes \u00a0 seem \u00a0 best\u00a0\ndistinguished\u00a0by\u00a0style\u00a0and\u00a0Rainbow\u00a0with\u00a0a\u00a0higher\u00a0weight\u00a0\nplaced\u00a0on\u00a0Rainbow.\u00a0\nFurther \u00a0 feature \u00a0 strengths \u00a0 across \u00a0 pairwise\u00a0\nclassification\u00a0are\u00a0observable\u00a0in\u00a0Table\u00a010,\u00a0 \u00a0where\u00a0the\u00a0\ncontents\u00a0of \u00a0Tables\u00a08\u00a0and\u00a09\u00a0have\u00a0been\u00a0merged\u00a0for\u00a0a\u00a0\nconvenient\u00a0overview.\u00a0\n\u00a0Table\u00a010.\u00a0Feature\u00a0strengths\u00a0in\u00a0pairwise\u00a0classification.\nMetric\nGenre\u00a0pair\nCB CE\nAM BF 0.25\nstyle,\u00a0Rainbow\n0.01\nRainbow\nAM BR 0.5\nstyle\n0.06\nstyle\nAM M 0.2\nstyle\n0.51\nRainbow\nAM P 0.2\nstyle\n0.08\nstyle\nAM T 0.08\nstyle\n0.42\nimage\nBF BR 0.39\nstyle,\u00a0Rainbow\n0.22\nstyle\nBF M 0.08\nstyle\n0.54\nstyle\nBF P 0.13\nstyle\n0.66\nimage\nBF T 0.32\nstyle,\u00a0Rainbow\n0.73\nRainbow\nBR M 0.14\nstyle,\u00a0Rainbow\n0.18\nRainbow\nBR P 0.37\nstyle\n0.09\nstyle\nBR T 0.07\nstyle,\u00a0Rainbow\n0.28\nstyle\nM P 0.68\nstyle\n0.24\nimage\nM T 0.08\nstyle\n0.64\nstyle\nP T 0.07\nimage\n0.39\nimage7.\u00a0Conclusions\nThe\u00a0results\u00a0in\u00a0this\u00a0paper\u00a0provide\u00a0evidence\u00a0that\u00a0\ngenre\u00a0classification\u00a0is\u00a0a\u00a0multi\u00addimensional\u00a0task\u00a0possibly\u00a0\ncomposed \u00a0 of \u00a0 several \u00a0 classification \u00a0 tasks \u00a0 involving \u00a0 a\u00a0\nvarying \u00a0 distribution \u00a0 of \u00a0 feature \u00a0 type \u00a0 strengths \u00a0 as\u00a0\ndistinguishing\u00a0factors.\nThe \u00a0 research \u00a0 proposes \u00a0 expressing \u00a0 document\u00a0\ngenre\u00a0classes\u00a0in\u00a0context\u00a0as\u00a0an\u00a0array\u00a0of\u00a0varying\u00a0strengths\u00a0\nacross\u00a0several\u00a0feature\u00a0types.\u00a0This\u00a0will\u00a0not\u00a0only\u00a0help\u00a0us\u00a0to\u00a0\ndetermine \u00a0 a \u00a0 means \u00a0 of \u00a0 supplementing \u00a0 deficiencies \u00a0 in\u00a0\ncurrent\u00a0classification\u00a0methods\u00a0by\u00a0suggesting\u00a0causes\u00a0of\u00a0\nfailure\u00a0in\u00a0detecting\u00a0selected\u00a0genres,\u00a0but\u00a0will\u00a0also\u00a0enable\u00a0us\u00a0\nto\u00a0relate\u00a0documents\u00a0classes\u00a0from\u00a0different\u00a0classification\u00a0\nschema\u00a0via\u00a0similar\u00a0or\u00a0dissimilar\u00a0distribution\u00a0patterns.\u00a0\u00a0\u00a0\u00a0\n8.\u00a0Acknowledgments\n\u00a0\nOmitted\u00a0in\u00a0the\u00a0draft.\u00a0To\u00a0be\u00a0inserted\u00a0later.\n10.\u00a0References\u00a0\n[1] \u00a0 Bagdanov, \u00a0 A. \u00a0 and \u00a0 Worring, \u00a0 M. \u00a0(2001) \u00a0 Fine\u00adgrained\u00a0\ndocument\u00a0genre\u00a0classification\u00a0using\u00a0first\u00a0order\u00a0random\u00a0graphs.\u00a0\nIn\u00a0 Proceedings \u00a0 of \u00a0 the \u00a0 Sixth \u00a0 International \u00a0 Conference \u00a0 on\u00a0\nDocument\u00a0Analysis\u00a0and\u00a0Recognition\u00a0(ICDAR2001)\u00a0,\u00a079\u00ad90.\n[2]\u00a0Barbu,\u00a0E.,\u00a0Heroux,\u00a0P.,\u00a0Adam,\u00a0S.,\u00a0and\u00a0Turpin,\u00a0E. \u00a0(2005)\u00a0\nClustering \u00a0 document \u00a0 images \u00a0 using \u00a0 a \u00a0 bag \u00a0 of \u00a0 symbols\u00a0\nrepresentation. \u00a0 In\u00a0 Proceedings \u00a0 International \u00a0 Conference \u00a0 on\u00a0\nDocument\u00a0Analysis\u00a0and\u00a0Recognition,\u00a01216\u20131220.\n[3]\u00a0Bekkerman,\u00a0R.,\u00a0McCallum,\u00a0A.,\u00a0and\u00a0Huang,\u00a0G.\u00a0 \u00a0(2004)\u00a0\nAutomatic \u00a0 categorization \u00a0 of \u00a0 email \u00a0 into \u00a0 folders: \u00a0 benchmark\u00a0\nexperiments\u00a0on\u00a0enron\u00a0and\u00a0sri\u00a0corpora.\u00a0Technical\u00a0Report\u00a0IR\u00ad418,\u00a0\nCentre\u00a0for\u00a0Intelligent\u00a0Information\u00a0Retrieval,\u00a0UMASS.\nhttp:\/\/www.cs.umass.edu\/~mccallum\/papers\/foldering\u00adtr05.pdf\n[4]\u00a0Biber,\u00a0D.\u00a0(1995)\u00a0Dimensions\u00a0of\u00a0Register\u00a0Variation:a\u00a0Cross\u00ad\nLinguistic\u00a0Comparison.\u00a0Cambridge\u00a0University\u00a0Press,\u00a0New\u00a0York,.\n[5] \u00a0 Boese, \u00a0 E. \u00a0 S. \u00a0 (2005) \u00a0Stereotyping \u00a0 the \u00a0 web: \u00a0 genre\u00a0\nclassification\u00a0of\u00a0web\u00a0documents.\u00a0Master\u2019s\u00a0thesis,\u00a0Colorado\u00a0State\u00a0\nUniversity.\n[6]\u00a0Breiman,\u00a0L.\u00a0(2001)\u00a0Random\u00a0forests. \u00a0Machine\u00a0Learning,\u00a0\n45:5\u201332.\n[26]\u00a0Burges,\u00a0C.\u00a0J.\u00a0C.\u00a0(1998)\u00a0A\u00a0Tutorial\u00a0on\u00a0support\u00a0vector\u00a0\nmachines\u00a0for\u00a0pattern\u00a0recognition.\u00a0Data\u00a0Mining\u00a0and\u00a0Knowledge\u00a0\nDiscovery,\u00a0Vol\u00a0\u00a02,\u00a0121\u00ad167.\u00a0\u00a0\n[7]\u00a0Chao,\u00a0C.,\u00a0Liaw,\u00a0A.,\u00a0and\u00a0Breiman,\u00a0L.\u00a0(2004)\u00a0Using\u00a0random\u00a0\nforest\u00a0to\u00a0learn\u00a0imbalanced\u00a0data.\nhttp:\/\/www.stat.berkeley.edu\/breiman\/RandomForests\/\u00a0\n[8]\u00a0Chen,\u00a0L.,\u00a0and\u00a0Tang,\u00a0H.\u00a0L.\u00a0(2004)\u00a0Improved\u00a0computation\u00a0of\u00a0\nbeliefs \u00a0 based \u00a0 on \u00a0 confusion \u00a0 matrix \u00a0 for \u00a0 combining \u00a0 multiple\u00a0\nclassifiers.\u00a0Electronic\u00a0Letters,\u00a0Vol\u00a04,\u00a0No\u00a04,\u00a0238\u00ad\u00a0239.\n[9]\u00a0Finn,\u00a0A.,\u00a0and\u00a0Kushmerick,\u00a0N.\u00a0(2006)\u00a0Learning\u00a0to\u00a0classify\u00a0\ndocuments\u00a0according\u00a0to\u00a0genre.\u00a0Journal\u00a0of\u00a0American\u00a0Society\u00a0for\u00a0\nInformation\u00a0Science\u00a0and\u00a0Technology,\u00a057(11),\u00a01506\u20131518.\n[10]\u00a0Karlgren,\u00a0J.,\u00a0and\u00a0Cutting,\u00a0D.\u00a0(1994)\u00a0Recognizing\u00a0text\u00a0genres\u00a0\nwith\u00a0simple\u00a0metric\u00a0using\u00a0discriminant\u00a0analysis.\u00a0In\u00a0Proceedings\u00a0\n15th\u00a0Conf.\u00a0Comp.\u00a0Ling.,\u00a0Vol\u00a02,\u00a0\u00a01071\u20131075.\n[11] \u00a0 Kessler, \u00a0 G., \u00a0 Nunberg, \u00a0 B., \u00a0 and \u00a0 Schuetze, \u00a0 H. \u00a0 (1997)\u00a0\nAutomatic\u00a0detection\u00a0of\u00a0text\u00a0genre.\u00a0In \u00a0Proceedings\u00a035th\u00a0Ann.\u00a0\nMeeting\u00a0ACL,\u00a032\u201338.\n[12]\u00a0Kim,\u00a0Y.,\u00a0and\u00a0Ross,\u00a0S.\u00a0(2006)\u00a0Genre\u00a0classification\u00a0in\u00a0\nautomated\u00a0ingest\u00a0and\u00a0appraisal\u00a0metadata.\u00a0In\u00a0J.\u00a0Gonzalo,\u00a0editor,\u00a0\nProceedings\u00a0European\u00a0Conference\u00a0on\u00a0advanced\u00a0technology\u00a0and\u00a0\nresearch \u00a0 in \u00a0 Digital \u00a0 Libraries \u00a0 (ECDL) \u00a0,\u00a0 Lecture \u00a0 Notes \u00a0 in\u00a0\nComputer\u00a0Science,\u00a0Springer\u00a0Verlag,\u00a0Vol\u00a04172,\u00a063\u201374.\n[13]\u00a0Kim,\u00a0Y.,\u00a0and\u00a0Ross,\u00a0S.\u00a0(2007)\u00a0Detecting\u00a0family\u00a0resemblance:\u00a0\nAutomated\u00a0genre\u00a0classification.\u00a0CODATA\u00a0Data\u00a0Science\u00a0Journal,\u00a0\nISSN:1683\u00ad1470,\u00a0Vol\u00a06,\u00a0,\u00a0S172\u00adS183.\n[14]\u00a0Kim,\u00a0Y.\u00a0and\u00a0Ross,\u00a0S.\u00a0(2007) \u00a0Feature\u00a0Type\u00a0Analysis\u00a0in\u00a0\nAutomated\u00a0Genre\u00a0Classification.\u00a0\nhttp:\/\/eprints.erpanet.org\/128.\n[15]\u00a0McCallum,\u00a0A.\u00a0(1996)\u00a0Bow:\u00a0A\u00a0toolkit\u00a0for\u00a0statistical\u00a0language\u00a0\nmodeling,\u00a0text\u00a0retrieval,\u00a0classification\u00a0and\u00a0clustering.\n\u00a0http:\/\/www.cs.cmu.edu\/~mccallum\/bow\n[16]\u00a0Minsky,\u00a0M.\u00a0(1961).\u00a0\"Steps\u00a0toward\u00a0Artificial\u00a0Intelligence.\"\u00a0\nProceedings\u00a0of\u00a0the\u00a0IRE\u00a049(1),\u00a08\u00ad30.\n[17] \u00a0 Rauber, \u00a0 A. \u00a0 and \u00a0 M\u00fcller\u00adK\u00f6gler, \u00a0 A. \u00a0 (2001) \u00a0 Integrating\u00a0\nautomatic\u00a0genre\u00a0analysis\u00a0into\u00a0digital\u00a0libraries.\u00a0In \u00a0Proceedings\u00a0\nACM\/IEEE\u00a0Joint\u00a0Conf.\u00a0Digital\u00a0Libraries,\u00a0Roanoke,\u00a0VA,\u00a01\u201310,\u00a0\n\u00a0http:\/\/doi.acm.org\/10.1145\/379437.379439\u00a0\n[18]\u00a0Santini,\u00a0M.\u00a0(2004)\u00a0 State\u00adof\u00adthe\u00adart\u00a0on\u00a0Automatic\u00a0Genre\u00a0\nIdentification,\u00a0Technical\u00a0Report\u00a0ITRI\u00ad04\u00ad03,\u00a0ITRI,\u00a0University\u00a0of\u00a0\nBrighton,\u00a0UK.\n[19] \u00a0 Santini, \u00a0 M.\u00a0 (2006) \u00a0Towards \u00a0 a \u00a0 Zero\u00adto\u00adMulti\u00adGenre\u00a0\nClassification\u00a0Scheme,\u00a0Journ\u00e9e\u00a0ATALA\u00a0\"Typologies\u00a0de\u00a0textes\u00a0\npour\u00a0le\u00a0traitement\u00a0automatique\",\u00a0Paris.\nhttp:\/\/www.nltg.brighton.ac.uk\/home\/Marina.Santini\/marina_san\ntini_ATALA2006.pdf\n[20]\u00a0Santini,\u00a0M.\u00a0(2007)\u00a0Characterizing\u00a0Genres\u00a0of\u00a0Web\u00a0Pages:\u00a0\nGenre\u00a0Hybridism\u00a0and\u00a0Individualization, \u00a040th\u00a0Annual\u00a0Hawaii\u00a0\nInternational\u00a0Conference\u00a0on\u00a0System\u00a0Sciences\u00a0(HICSS'07).\nhttp:\/\/csdl2.computer.org\/comp\/proceedings\/hicss\/2007\/2755\/00\/\n27550071.pdf.\n[21]\u00a0Witten,\u00a0H.\u00a0I.,\u00a0and\u00a0E.\u00a0Frank.\u00a0(2005)\u00a0Data\u00a0mining:\u00a0Practical\u00a0\nmachine\u00a0learning\u00a0tools\u00a0and\u00a0techniques.\u00a02nd\u00a0Edition,\u00a0Morgan\u00a0\nKaufmann,\u00a0San\u00a0Francisco."}
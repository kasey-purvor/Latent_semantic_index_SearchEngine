{"doi":"10.1007\/s10514-009-9157-4","coreId":"54267","oai":"oai:eprints.lincoln.ac.uk:2669","identifiers":["oai:eprints.lincoln.ac.uk:2669","10.1007\/s10514-009-9157-4"],"title":"Reactive direction control for a mobile robot: A locust-like control of escape direction emerges when a bilateral pair of model locust visual neurons are integrated","authors":["Yue, Shigang","Santer, Roger D.","Yamawaki, Yoshifumi","Rind, F. Claire"],"enrichments":{"references":[{"id":948476,"title":"A bio-inspired visual collision detection mechanism for cars: combining insect inspired neurons to create a robust system.","authors":[],"date":"2007","doi":"10.1016\/j.biosystems.2006.09.010","raw":"Stafford, R., Santer R.D. and Rind, F.C. A bio-inspired visual collision detection mechanism for cars: combining insect inspired neurons to create a robust system. BioSystems, 87, 162-169, 2007.","cites":null},{"id":949764,"title":"A bio-inspired visual collision detection mechanism for cars: optimisation of a model of a locust neuron to a novel environment.","authors":[],"date":"1591","doi":"10.1016\/j.neucom.2005.06.017","raw":"Yue, S., Rind, F.C. Keil, M.S., Cuadri, J. and Stafford, R. A bio-inspired visual collision detection mechanism for cars: optimisation of a model of a locust neuron to a novel environment.  Neurocomputing, vol.69 (13-15), 1591-1598, 2006a.","cites":null},{"id":944336,"title":"A chemical synapse between two motion detecting neurones in the locust brain.","authors":[],"date":"1984","doi":null,"raw":"Rind, F.C. A chemical synapse between two motion detecting neurones in the locust brain. J. Exp. Biol., vol.110, 143-167, 1984.","cites":null},{"id":949508,"title":"A Collision detection system for a mobile robot inspired by locust visual system.","authors":[],"date":"2005","doi":"10.1109\/robot.2005.1570705","raw":"Yue, S. and Rind, F.C.  A Collision detection system for a mobile robot inspired by locust visual system. IEEE Int. Conf. on Robotics and Automation, Spain, Barcelona, Apr.18-21, 2005, 3843-3848, 2005.","cites":null},{"id":941921,"title":"A silicon implementation of the fly's optomotor control system.","authors":[],"date":"2000","doi":"10.1162\/089976600300014944","raw":"Harrison, R.R., and Koch, C. A silicon implementation of the fly's optomotor control system. Neural Computation, vol.12, 2291-2304, 2000.","cites":null},{"id":950666,"title":"A synthetic vision system using directionally selective motion detectors to recognize collision.","authors":[],"date":"2007","doi":"10.1162\/artl.2007.13.2.93","raw":"Yue, S. and Rind, F.C. A synthetic vision system using directionally selective motion detectors to recognize collision. Artificial Life, vol.13 (2), 93-122, 2007.","cites":null},{"id":943916,"title":"Anology integrated circuit for motion detection against moving background based on the insect visual system.","authors":[],"date":"2004","doi":"10.1007\/s10043-004-0024-4","raw":"Nishio, K., Yonezu, H., Kariyawasam, A.B., Yoshikawa, Y. Sawa, S. and Furukawa, Y., Anology integrated circuit for motion detection against moving background based on the insect visual system. Optical Review, vol.11, 1, 24-33, 2004.","cites":null},{"id":945958,"title":"Bioinspired sensors: from insect eyes to robot vision. Frontiers in Neuroscience: Methods in Insect Sensory Neuroscience,","authors":[],"date":"2005","doi":"10.1201\/9781420039429.ch8","raw":"Rind, F.C. Bioinspired sensors: from insect eyes to robot vision. Frontiers in Neuroscience: Methods in Insect Sensory Neuroscience, Christensen T.A. (Eds.), CRC Press Boca Raton, London, New York, 2005.","cites":null},{"id":942915,"title":"Biologically Inspired Visual Odometer for Navigation of a Flying Robot. Robotics and Autonomous Systems,","authors":[],"date":"2003","doi":"10.1016\/s0921-8890(03)00070-8","raw":"Iida, F.  Biologically Inspired Visual Odometer for Navigation of a Flying Robot. Robotics and Autonomous Systems, vol.44\/3-4, 201-208, 2003.","cites":null},{"id":939710,"title":"Cockroaches keep predators guessing by using preferred escape trajectories.","authors":[],"date":"2008","doi":"10.1016\/j.cub.2008.09.062","raw":"Domenici, P. Booth, D. Blagburn, J.M. and Bacon J.P. Cockroaches keep predators guessing by using preferred escape trajectories. Current Biology, vol.18, 1792-1796, 2008.","cites":null},{"id":938943,"title":"Collision avoidance using a model of the locust LGMD neuron. Robotics and Automonous Systems,","authors":[],"date":"2000","doi":"10.1016\/s0921-8890(99)00063-9","raw":"Blanchard, M. Rind F.C. and Verschure, P.F.M.J. Collision avoidance using a model of the locust LGMD neuron. Robotics and Automonous Systems, vol.30, 17-38. 2000.","cites":null},{"id":950211,"title":"Collision detection in complex dynamic scenes using a LGMD based visual neural network with feature enhancement.","authors":[],"date":null,"doi":"10.1109\/TNN.2006.873286","raw":"Yue, S. and Rind, F.C. Collision detection in complex dynamic scenes using a LGMD based visual neural network with feature enhancement. IEEE Transactions on Neural Networks, May, vol.17 (3), 705-716, 2006a.","cites":null},{"id":951062,"title":"Competence comparison of collision sensitive visual neural systems during evolution in dynamic environments. Artificial Life, 2008b (under review).","authors":[],"date":null,"doi":null,"raw":"Yue. S., and Rind, F.C. Competence comparison of collision sensitive visual neural systems during evolution in dynamic environments. Artificial Life, 2008b (under review).","cites":null},{"id":940422,"title":"Computational model of the cockroach escape behaviour: winner and losers in a population code.","authors":[],"date":"2003","doi":"10.1007\/s00422-002-0343-0","raw":"Ezrachi E.A. Computational model of the cockroach escape behaviour: winner and losers in a population code. Biol. Cybern. Vol.88(1), 33-45, 2003.","cites":null},{"id":947432,"title":"Connexions between a movement-detecting visual interneurone and flight motoneurones of a locust.","authors":[],"date":null,"doi":null,"raw":"Simmons, P. J. Connexions between a movement-detecting visual interneurone and flight motoneurones of a locust. J. Exp. Biol. 86, 87-97,1980.","cites":null},{"id":948663,"title":"Data mining neural spike-trains for the identification of behavioural triggers using evolutionary algorithms,","authors":[],"date":"2007","doi":"10.1016\/j.neucom.2006.09.011","raw":"Stafford, R., and Rind, F.C. Data mining neural spike-trains for the identification of behavioural triggers using evolutionary algorithms, Neurocomputing, 70, 1079-1084, 2007.","cites":null},{"id":941674,"title":"Digger wasp vs. cricket: neuroethology of a predator-prey interaction.","authors":[],"date":"1996","doi":"10.1007\/s001140050317","raw":"Gnatzy, W. Digger wasp vs. cricket: neuroethology of a predator-prey interaction. Inform. Process Animals 10, 92, 1996.","cites":null},{"id":942164,"title":"Elementary computation of object approach by a wide-field visual neuron.","authors":[],"date":"1995","doi":"10.1126\/science.270.5238.1000","raw":"Hatsopoulos, N., Gabbiani,F., and Laurent, G. Elementary computation of object approach by a wide-field visual neuron. Science, 270: 1000-1003, 1995.","cites":null},{"id":949962,"title":"Evolutionary search for the visual-motor model determining locusts escaping direction. 2006b (technical report).","authors":[],"date":null,"doi":null,"raw":"Yue, S., Yamawaki, Y., Santer, R., and Rind, F.C. Evolutionary search for the visual-motor model determining locusts escaping direction. 2006b (technical report).","cites":null},{"id":950903,"title":"Exploring postsynaptic organizations of bio-inspired DSNs for car collision detection.","authors":[],"date":null,"doi":null,"raw":"Yue, S., and Rind, F.C. Exploring postsynaptic organizations of bio-inspired DSNs for car collision detection. IEEE Trans. on Intelligent Transport Systems, 2008a (under review).","cites":null},{"id":946561,"title":"Gliding behaviour elicited by lateral looming stimuli in flying locusts.","authors":[],"date":null,"doi":"10.1007\/s00359-004-0572-x","raw":"Santer,R.D., Simmons,P.J. and Rind, F.C. Gliding behaviour elicited by lateral looming stimuli in flying locusts. Journal of Comparative Physiology, vol.191, 61-73, 2005a.","cites":null},{"id":946164,"title":"Identification of MauthnerInitiated Response Patterns in Goldfish: Evidence from Simultaneous Cinematography and Electrophysiology,","authors":[],"date":null,"doi":"10.1007\/bf01326837","raw":"Robert, C. Eaton, William, A. Lavender, and Chris M. Wieland, Identification of MauthnerInitiated Response Patterns in Goldfish: Evidence from Simultaneous Cinematography and Electrophysiology, J. Comp. Physiol. 144: 521-531,1981.","cites":null},{"id":945701,"title":"LOCUST: Life-like object detection for collision avoidance using spatiotemporal image processing,","authors":[],"date":"2004","doi":null,"raw":"Rind, F.C., Stafford, R. and Yue, S. Technical Report D11: Biological Model Report, Project IST-2001-38097, LOCUST: Life-like object detection for collision avoidance using spatiotemporal image processing, 2004. http:\/\/www.imse.cnm.es\/locust\/main.html","cites":null},{"id":945476,"title":"Locust\u2019s looming detectors for robot sensors. Sensors and Sensing","authors":[],"date":"2003","doi":"10.1007\/978-3-7091-6025-1_17","raw":"Rind, F.C. Santer, R.D.J., Blanchard, M. and Verschure, P.F.M.J. Locust\u2019s looming detectors for robot sensors. Sensors and Sensing in Biology and Engineering, FG Barth, JAC Humphrey, and TW Secomb (Eds.), Spinger-Verlag, Wien, New York, 2003.","cites":null},{"id":945249,"title":"Motion detectors in the locust visual system: from biology to robot sensors.","authors":[],"date":"2002","doi":"10.1002\/jemt.10029","raw":"Rind, F.C. Motion detectors in the locust visual system: from biology to robot sensors. Microscopy Research and Technique, vol.56, 256-269, 2002. Page 18 of 28","cites":null},{"id":946787,"title":"Motor activity and trajectory control during escape jumping in the locust Locusta migratoria.","authors":[],"date":null,"doi":"10.1007\/s00359-005-0023-3","raw":"Santer R.D., Yamawaki, Y, Rind, F.C. and Simmons, P.J. Motor activity and trajectory control during escape jumping in the locust Locusta migratoria. Journal of Comparative Physiology, vol. 191, 965-975, 2005b.","cites":null},{"id":944501,"title":"movement sensitive neurones of the locust optic lobe.","authors":[],"date":"1987","doi":"10.1007\/bf00603973","raw":"Rind , F.C. Non-Directional, movement sensitive neurones of the locust optic lobe. J. Comp . Physiol., vol.161, 477-494, 1987.","cites":null},{"id":941409,"title":"Multiplication and stimulus invariance in a looming-sensitive neuron.","authors":[],"date":"2004","doi":"10.1016\/j.jphysparis.2004.03.001","raw":"Gabbiani, F., Krapp, H.G., Hatsopoulos, N., Mo, C-H., Koch, C., and Laurent, G. Multiplication and stimulus invariance in a looming-sensitive neuron. J. Physiology- Paris, vol.98, 19-34, 2004.","cites":null},{"id":946378,"title":"Neural mechanisms for forming a perceptual decision.","authors":[],"date":"1994","doi":"10.1126\/science.8146653","raw":"Salzman, C.D., Newsome, W.T. Neural mechanisms for forming a perceptual decision. Science 264:231\u2013237, 1994.","cites":null},{"id":944710,"title":"Neural network based on the input organization of an identified neuron signaling impending collision.","authors":[],"date":"1996","doi":null,"raw":"Rind, F.C. and Bramwell, D.I.  Neural network based on the input organization of an identified neuron signaling impending collision.  Journal of Neurophysiology, vol.75, 967\u2013 985, 1996.","cites":null},{"id":943007,"title":"Neuromorphic vision sensors.","authors":[],"date":"2000","doi":"10.3390\/s8095352","raw":"Indiveri, G. and Douglas, R. Neuromorphic vision sensors. Science, vol.288, 1189-1190, 2000.","cites":null},{"id":943672,"title":"Obstacle detection and terrain classification for autonomous off-road navigation. Autonomous Robots,","authors":[],"date":"2005","doi":"10.1023\/b:auro.0000047286.62481.1d","raw":"Manduchi, R. Castano, A. Talukder A. and Matthies, L. Obstacle detection and terrain classification for autonomous off-road navigation. Autonomous Robots, vol.18, 81-102, 2005.","cites":null},{"id":942647,"title":"On robots and flies: modelling the visual orientating behaviour of flies. Robotics and Autonomous Systems,","authors":[],"date":"1999","doi":"10.1016\/s0921-8890(99)00055-x","raw":"Huber, S.A. Franz M.O. and Buelthoff, H.H. On robots and flies: modelling the visual orientating behaviour of flies. Robotics and Autonomous Systems, vol.29, 227-242, 1999.","cites":null},{"id":944762,"title":"Orthopteran DCMD neuron: A reevaluation of responses to moving objects. I. Selective responses to approaching objects.","authors":[],"date":"1992","doi":null,"raw":"Rind, F.C. Simmons, P.J. Orthopteran DCMD neuron: A reevaluation of responses to moving objects. I. Selective responses to approaching objects. Journal of Neurophysiology, vol.68, 1654\u20131666, 1992.","cites":null},{"id":948003,"title":"Orthopteran DCMD neuron: A reevaluation of responses to moving objects. II. Critical cues for detecting approaching objects.","authors":[],"date":"1992","doi":null,"raw":"Simmons, P.J., Rind, F.C. Orthopteran DCMD neuron: A reevaluation of responses to moving objects. II. Critical cues for detecting approaching objects. Journal of Neurophysiology, vol.68, 1667\u20131682, 1992.","cites":null},{"id":943639,"title":"Population vector coding by the giant interneurons of the cockroach.","authors":[],"date":null,"doi":null,"raw":"Levi, R. Camhi, JM. Population vector coding by the giant interneurons of the cockroach. J. Neurosci. 15:20(10), 3822-3829, 2000b.","cites":null},{"id":947002,"title":"Preparing for escape: an examination of the role of the DCMD neuron in locust escape jumps.","authors":[],"date":"2008","doi":"10.1007\/s00359-007-0289-8","raw":"Santer, R. D., Yamawaki, Y, Rind, F.C., and Simmons, P.J. Preparing for escape: an examination of the role of the DCMD neuron in locust escape jumps. Journal of Comparative Physiology A 194(1):69-77, 2008.","cites":null},{"id":949308,"title":"Reafferent or redundant: integration of phonotaxis and optomotor behaviour in crickets and robots. Adaptive behaviour,","authors":[],"date":"2003","doi":"10.1177\/1059712303113001","raw":"Webb, B. and Reeve, R. Reafferent or redundant: integration of phonotaxis and optomotor behaviour in crickets and robots. Adaptive behaviour, vol.11 (3), 137-158. 2003.","cites":null},{"id":941196,"title":"Relationship between the phases of sensory and motor activity during a looming-evoked multistage escape behavior.","authors":[],"date":"2007","doi":"10.1523\/jneurosci.1515-07.2007","raw":"Fotowat, H. and Gabbiani, F. Relationship between the phases of sensory and motor activity during a looming-evoked multistage escape behavior. J Neurosci., vol.27, 10047\u201310059, 2007. Page 17 of 28","cites":null},{"id":949072,"title":"Research advances in intelligent collision avoidance and adaptive cruise control.","authors":[],"date":"2003","doi":"10.1109\/tits.2003.821292","raw":"Vahidi, A. and Eskandarian, A. Research advances in intelligent collision avoidance and adaptive cruise control. IEEE Transactions on Intelligent Transportation Systems, vol.4(3), 143-153, 2003.","cites":null},{"id":947224,"title":"Response of the locust descending contralateral movement detector neuron to rapidly approaching and withdrawing visual stimuli.","authors":[],"date":"1977","doi":"10.1139\/z77-179","raw":"Schlotterer, G.R. Response of the locust descending contralateral movement detector neuron to rapidly approaching and withdrawing visual stimuli. Canadian Journal of Zoology, vol.55, 1372\u20131376, 1977.","cites":null},{"id":943182,"title":"Response-dedicated trigger neurons as control points for behavioral actions: selective inhibition of lateral giant command neurons during feeding in crayfish.","authors":[],"date":"1988","doi":null,"raw":"Krasne, F.B., and Lee, S.C. Response-dedicated trigger neurons as control points for behavioral actions: selective inhibition of lateral giant command neurons during feeding in crayfish. J Neurosci, 8, 3703-3712, 1988.","cites":null},{"id":948261,"title":"Responses to object approach by a wide field visual neurone, the LGMD2 of the locust: Characterization and image cues.","authors":[],"date":"1997","doi":"10.1007\/s003590050041","raw":"Simmons, P.J. and Rind , F.C. Responses to object approach by a wide field visual neurone, the LGMD2 of the locust: Characterization and image cues. J. Comp . Physiol., vol.180, 203-214, 1997.","cites":null},{"id":946408,"title":"Retinally-Generated Saccadic Suppression of a Locust Looming Detector Neuron: Investigations Using a Robot Locust.","authors":[],"date":"2004","doi":"10.1098\/rsif.2004.0007","raw":"Santer, R. D., Stafford R. and Rind, F. C. Retinally-Generated Saccadic Suppression of a Locust Looming Detector Neuron: Investigations Using a Robot Locust. J.R. Soc. Lond. Interface, vol.1, 61-77, 2004.","cites":null},{"id":940678,"title":"Right-left discrimination in a biologically oriented model of the cockroach escape system.","authors":[],"date":"1999","doi":"10.1007\/s004220050546","raw":"Ezrachi E.A., Levi R., Camhi J.M. and Parnas H. Right-left discrimination in a biologically oriented model of the cockroach escape system. Biol. Cybern., vol.81(2), 89-99, 1999.","cites":null},{"id":940933,"title":"Robot navigation using panoramic tracking.","authors":[],"date":"2004","doi":"10.1016\/j.patcog.2004.02.017","raw":"Fiala, M. and Basu, A. Robot navigation using panoramic tracking. Pattern Recognition, vol.37, 2195-2215, 2004.","cites":null},{"id":939953,"title":"Role of the Mauthner cell in sensorimotor integration by the brain stem escape network. Brain Behav Evol 37:272\u2013285,","authors":[],"date":"1991","doi":"10.1159\/000114365","raw":"Eaton, R.C., DiDomenico, R., Nissanov, J., Role of the Mauthner cell in sensorimotor integration by the brain stem escape network. Brain  Behav Evol 37:272\u2013285, 1991.","cites":null},{"id":945015,"title":"Seeing what is coming: Building collision sensitive neurons. Trends in Neurosciences,","authors":[],"date":"1999","doi":"10.1016\/s0166-2236(98)01332-0","raw":"Rind, F.C. and Simmons, P.J.  Seeing what is coming: Building collision sensitive neurons. Trends in Neurosciences, vol.22, 215-220, 1999.","cites":null},{"id":938407,"title":"Sensor modelling, design and data processing for autonomous navigation. River Edge, NJ, World Scientific,","authors":[],"date":"1998","doi":"10.1142\/3814","raw":"Adams, M. D. Sensor modelling, design and data processing for autonomous navigation. River Edge, NJ, World Scientific, 1998.","cites":null},{"id":940163,"title":"Sensors for Mobile Robots: Theory and Application. AK Peters,","authors":[],"date":"1995","doi":null,"raw":"Everett, H.R. Sensors for Mobile Robots: Theory and Application. AK Peters, Wellesley, MA, 1995.","cites":null},{"id":948862,"title":"Spatial sensitivity profiles of motion sensitive neurons in the locust brain. In: K. Wiese et al. Sensory Systems of Arthropods,","authors":[],"date":"1993","doi":null,"raw":"Stern, M. and Gewecke, M. Spatial sensitivity profiles of motion sensitive neurons in the locust brain. In: K. Wiese et al. Sensory Systems of Arthropods, Birkhaeuser Verlag, Basel, pp. 184\u2013195, 1993.","cites":null},{"id":941639,"title":"Spike-frequency adaptation and intrinisic properties of an identified, looming-sensitive neuron.","authors":[],"date":"2006","doi":"10.1152\/jn.00075.2006","raw":"Gabbiani, F., and Krapp, H.G., Spike-frequency adaptation and intrinisic properties of an identified, looming-sensitive neuron. J. Neurophysiology, vol.96(6), 2951-2962, 2006.","cites":null},{"id":944140,"title":"The anatomy of a locust visual interneurone: The descending contralateral movement detector.","authors":[],"date":"1974","doi":"10.1007\/bf00698057","raw":"O\u2019Shea, M. Rowell, C.H.F., Williams, J.L.D.  The anatomy of a locust visual interneurone: The descending contralateral movement detector.  Journal of Exp. Biology, vol.60, 1\u201312, 1974.","cites":null},{"id":939212,"title":"The escape behaviour of the cockroach Periplaneta americana II. detection of natural predators by air displacement.","authors":[],"date":"1978","doi":"10.1007\/bf00656853","raw":"Camhi, J. M., Tom, W. and Volman, S. The escape behaviour of the cockroach Periplaneta americana II. detection of natural predators by air displacement. J. comp. Physiol. A 128, 203-212, 1978.","cites":null},{"id":949377,"title":"The organization of escape behavior in the crayfish,","authors":[],"date":null,"doi":"10.1007\/978-1-4684-6967-7_17","raw":"Wine, J.J. and Krasne, F.B. The organization of escape behavior in the crayfish, J. Exp. Biol. 56:1-18,1972. Page 19 of 28","cites":null},{"id":942398,"title":"The separation of visual axes in apposition compound eyes.","authors":[],"date":"1978","doi":"10.1098\/rstb.1978.0093","raw":"Horridge, G.A. The separation of visual axes in apposition compound eyes. Philos. Trans. R. Soc. London B Biol. Sci. 285, 1\u201359, 1978.","cites":null},{"id":938681,"title":"Using a mobile robot to study locust collision avoidance responses.","authors":[],"date":"1999","doi":"10.1142\/s0129065799000393","raw":"Blanchard, M. Verschure, P. F. M. J. and Rind, F. C.  Using a mobile robot to study locust collision avoidance responses. Int. Journal of Neural Systems, vol. 9, 405-410, 1999.","cites":null},{"id":951328,"title":"Variability of motor neuron spike timing maintains and shapes contractions of the accessory radula closer muscle of Aplysia.","authors":[],"date":"2006","doi":"10.1523\/JNEUROSCI.5277-05.2006","raw":"Zhurov, Y. and Brezina V. Variability of motor neuron spike timing maintains and shapes contractions of the accessory radula closer muscle of Aplysia. The Journal of Neuroscience, vol.26(2), 7056-7070, 2006. Page 20 of 28 (a)                                                                                     (b) (c)                                                                 (d)","cites":null},{"id":939474,"title":"Vision for mobile robot navigation: a survey.","authors":[],"date":"2002","doi":"10.1109\/34.982903","raw":"DeSouza, G.N. and Kak, A.C. Vision for mobile robot navigation: a survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.24 (2), 237-67, 2002.","cites":null},{"id":950470,"title":"Visual motion pattern extraction and fusion for collision detection in complex dynamic scenes. Computer Vision and Image Understanding,","authors":[],"date":null,"doi":"10.1016\/j.cviu.2006.07.002","raw":"Yue, S. and Rind, F.C. Visual motion pattern extraction and fusion for collision detection in complex dynamic scenes. Computer Vision and Image Understanding, vol.104 (1), 48-60, 2006b.","cites":null},{"id":943392,"title":"Wind direction coding in the cockroach escape response: winner does not take all.","authors":[],"date":null,"doi":null,"raw":"Levi, R. Camhi, JM. Wind direction coding in the cockroach escape response: winner does not take all. J. Neurosci., 15:20(10), 3814-3821, 2000a.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-02","abstract":"Locusts possess a bilateral pair of uniquely identifiable visual neurons that respond vigorously to\\ud\nthe image of an approaching object. These neurons are called the lobula giant movement\\ud\ndetectors (LGMDs). The locust LGMDs have been extensively studied and this has lead to the\\ud\ndevelopment of an LGMD model for use as an artificial collision detector in robotic applications.\\ud\nTo date, robots have been equipped with only a single, central artificial LGMD sensor, and this\\ud\ntriggers a non-directional stop or rotation when a potentially colliding object is detected. Clearly,\\ud\nfor a robot to behave autonomously, it must react differently to stimuli approaching from\\ud\ndifferent directions. In this study, we implement a bilateral pair of LGMD models in Khepera\\ud\nrobots equipped with normal and panoramic cameras. We integrate the responses of these LGMD\\ud\nmodels using methodologies inspired by research on escape direction control in cockroaches.\\ud\nUsing \u2018randomised winner-take-all\u2019 or \u2018steering wheel\u2019 algorithms for LGMD model integration,\\ud\nthe khepera robots could escape an approaching threat in real time and with a similar\\ud\ndistribution of escape directions as real locusts. We also found that by optimising these\\ud\nalgorithms, we could use them to integrate the left and right DCMD responses of real jumping\\ud\nlocusts offline and reproduce the actual escape directions that the locusts took in a particular\\ud\ntrial. Our results significantly advance the development of an artificial collision detection and\\ud\nevasion system based on the locust LGMD by allowing it reactive control over robot behaviour.\\ud\nThe success of this approach may also indicate some important areas to be pursued in future\\ud\nbiological research","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/54267.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/2669\/1\/YUEetal_Bio2lgmds_v321_rev4.0_final.pdf","pdfHashValue":"f04c88dfeee75ab19909062749c40d9593a0af5d","publisher":"Springer Verlag","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:2669<\/identifier><datestamp>\n      2013-12-04T15:54:51Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F43:6A6163735F43313230<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F47:6A6163735F47343030<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/2669\/<\/dc:relation><dc:title>\n        Reactive direction control for a mobile robot: A locust-like control of escape direction emerges when a bilateral pair of model locust visual neurons are integrated<\/dc:title><dc:creator>\n        Yue, Shigang<\/dc:creator><dc:creator>\n        Santer, Roger D.<\/dc:creator><dc:creator>\n        Yamawaki, Yoshifumi<\/dc:creator><dc:creator>\n        Rind, F. Claire<\/dc:creator><dc:subject>\n        C120 Behavioural Biology<\/dc:subject><dc:subject>\n        G400 Computer Science<\/dc:subject><dc:description>\n        Locusts possess a bilateral pair of uniquely identifiable visual neurons that respond vigorously to\\ud\nthe image of an approaching object. These neurons are called the lobula giant movement\\ud\ndetectors (LGMDs). The locust LGMDs have been extensively studied and this has lead to the\\ud\ndevelopment of an LGMD model for use as an artificial collision detector in robotic applications.\\ud\nTo date, robots have been equipped with only a single, central artificial LGMD sensor, and this\\ud\ntriggers a non-directional stop or rotation when a potentially colliding object is detected. Clearly,\\ud\nfor a robot to behave autonomously, it must react differently to stimuli approaching from\\ud\ndifferent directions. In this study, we implement a bilateral pair of LGMD models in Khepera\\ud\nrobots equipped with normal and panoramic cameras. We integrate the responses of these LGMD\\ud\nmodels using methodologies inspired by research on escape direction control in cockroaches.\\ud\nUsing \u2018randomised winner-take-all\u2019 or \u2018steering wheel\u2019 algorithms for LGMD model integration,\\ud\nthe khepera robots could escape an approaching threat in real time and with a similar\\ud\ndistribution of escape directions as real locusts. We also found that by optimising these\\ud\nalgorithms, we could use them to integrate the left and right DCMD responses of real jumping\\ud\nlocusts offline and reproduce the actual escape directions that the locusts took in a particular\\ud\ntrial. Our results significantly advance the development of an artificial collision detection and\\ud\nevasion system based on the locust LGMD by allowing it reactive control over robot behaviour.\\ud\nThe success of this approach may also indicate some important areas to be pursued in future\\ud\nbiological research.<\/dc:description><dc:publisher>\n        Springer Verlag<\/dc:publisher><dc:date>\n        2010-02<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/2669\/1\/YUEetal_Bio2lgmds_v321_rev4.0_final.pdf<\/dc:identifier><dc:identifier>\n          Yue, Shigang and Santer, Roger D. and Yamawaki, Yoshifumi and Rind, F. Claire  (2010) Reactive direction control for a mobile robot: A locust-like control of escape direction emerges when a bilateral pair of model locust visual neurons are integrated.  Autonomous Robots, 28  (2).   pp. 151-167.  ISSN 0929-5593  <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/s10514-009-9157-4<\/dc:relation><dc:relation>\n        10.1007\/s10514-009-9157-4<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/2669\/","http:\/\/dx.doi.org\/10.1007\/s10514-009-9157-4","10.1007\/s10514-009-9157-4"],"year":2010,"topics":["C120 Behavioural Biology","G400 Computer Science"],"subject":["Article","PeerReviewed"],"fullText":"Reactive direction control for a mobile robot: A locust-like control \nof escape direction emerges when a bilateral pair of model locust \nvisual neurons are integrated \n \n \nShigang Yue1,4\u2193  Roger D. Santer2, Yoshifumi Yamawaki3 and F. Claire Rind4 \n1Brain Mapping Unit, Sir William Hardy Building, Downing Site, University of Cambridge, CB2 3EB UK \n2School of Biological Sciences, University of Nebraska \u2013 Lincoln, Lincoln, NE 68588, USA \n3Department of Biology, Faculty of Science, Kyushu University, Fukuoka 812-8581, JAPAN \n4Ridley Building, School of Biology and Psychology, University of Newcastle upon Tyne, NE1 7RU UK \n \n \n \nAbstract   \n  \nLocusts possess a bilateral pair of uniquely identifiable visual neurons that respond vigorously to \nthe image of an approaching object. These neurons are called the lobula giant movement \ndetectors (LGMDs). The locust LGMDs have been extensively studied and this has lead to the \ndevelopment of an LGMD model for use as an artificial collision detector in robotic applications. \nTo date, robots have been equipped with only a single, central artificial LGMD sensor, and this \ntriggers a non-directional stop or rotation when a potentially colliding object is detected. Clearly, \nfor a robot to behave autonomously, it must react differently to stimuli approaching from \ndifferent directions. In this study, we implement a bilateral pair of LGMD models in Khepera \nrobots equipped with normal and panoramic cameras. We integrate the responses of these LGMD \nmodels using methodologies inspired by research on escape direction control in cockroaches. \nUsing \u2018randomised winner-take-all\u2019 or \u2018steering wheel\u2019 algorithms for LGMD model integration, \nthe khepera robots could escape an approaching threat in real time and with a similar \ndistribution of escape directions as real locusts. We also found that by optimising these \nalgorithms, we could use them to integrate the left and right DCMD responses of real jumping \nlocusts offline and reproduce the actual escape directions that the locusts took in a particular \ntrial. Our results significantly advance the development of an artificial collision detection and \nevasion system based on the locust LGMD by allowing it reactive control over robot behaviour. \nThe success of this approach may also indicate some important areas to be pursued in future \nbiological research.  \n \n \n \n \nKeywords   robots, escape, emergent properties, behaviour, visual neural network, LGMD, \nDCMD, locusts, jumping, agents, hybrid, cybernetics \n \n \n                                                 \n\u2193 Corresponding author, current address: \nSchool of Computer Science, University of Lincoln \nBrayford Pool, Lincoln, LN6 7TS  United Kingdom \nTel:  (0044)  01522 837397 \nFax: (0044)  01522 886974 \nEmail: syue@lincoln.ac.uk or shigang.yue@ieee.org \n \n \n2009 to Autonomous Robots (revised) \nPage 2 of 28 \n1. Introduction \n \n \nAnimals often possess incredible sensory systems that allow them to detect the details of \ntheir environment. These systems enable animals to react quickly and appropriately to \nany changes in the environment that their sensory systems detect. Some of the most \nimportant environmental stimuli are attacking predators and in many animal species \nsensory and motor systems have evolved to help them detect and evade these kinds of \napproaching threats (for example, Wine and Krasne 1972, Camhi et. al. 1978, Robert et. \nal. 1981, and Gnatzy 1996). \n \nThe same is not true of the artificial sensors used in robotic control. For autonomous \nmobile robots, the ability to avoid collision and interact with the dynamic environment is \nan important one and, often, several kinds of sensors - including visual, ultrasound, infra-\nred, laser, and mini-radar (for examples see Everett 1995, Adams 1998, Manduchi et. al. \n2005) \u2013 are used to mediate these interactions. Of these, vision is best able to provide a \nbroad array of environmental information simultaneously in real time, but unfortunately, \ntraditional segmentation and registration based computer vision methodologies cannot \ncope with the degree of complexity in the visual world for real time collision detection \napplications (Yue and Rind, 2006a). It is still very difficult for a robot to run \nautonomously without collision in complex, outdoor environments without human \nintervention (Indiveri and Douglas 2000, DeSouza and Kak 2002) partially because the \nrobot can\u2019t make a fast, reactive decision on how to behave when faced with a particular \nthreat  A potential solution to these shortcomings is to mimic the behaviour of animals \nwhich have relatively simple collision avoidance behaviours, but make rapid decisions on \nhow to direct them when needed.  \n \nLocusts have a finely evolved predator-evasion system, as anyone who has tried to \ncapture one will testify. One of the reasons that locusts are so difficult to catch is that \ntheir visual system contains two bilateral pairs of identified neurons that respond to the \nimage of an approaching object. These are the lobula giant movement detectors (LGMDs), \nand their postsynaptic partners, the descending contralateral movement detectors \n(DCMDs) (Schlotterer 1977, Rind and Simmons 1992, Simmons and Rind 1992, \nGabbiani et.al. 2004, 2006). Because a DCMD reproduces spikes (action potentials) from \nan LGMD on a 1:1 basis, their responses are the same. As an object approaches, these \ncells produce a train of spikes that increases in frequency (Rind and Simmons, 1992). \nThese spikes excite motor and interneurons postsynaptic to the DCMD that, in flight, can \ncause the locust to produce a pause in flight that is interpreted as an emergency escape \ndive (Simmons, 1980, Santer et. al., 2006). \n \nThe input circuitry of the LGMD neuron has been used as inspiration for an artificial \nvisual system that mediates collision avoidance in robots and, more recently, in cars \n(Blanchard et. al 1999, 2000, Rind and Bramwell 1996, Rind and Simmons 1999, Rind \n2002, 2005, Rind et. al. 2003, 2004, Santer et. al. 2004, Yue and Rind 2005, Yue et. al. \n2006a, Yue and Rind 2006a~b, 2007, 2008a~b). This LGMD-based neural network, as \nadapted for use in a VLSI circuit for use in cars, can provide a robotic vision solution in \nPage 3 of 28 \ncomplex environments and under extreme illumination conditions (Stafford et. al. 2007, \nYue et. al. 2006a). However, thus far it has been used only to trigger stereotyped motor \nresponses in a mobile robot \u2013 anti-clockwise turns or stops for example \u2013 without any \ndirectional control relative to the direction from which a threat develops. This is a useful \nand important ability in an escape system or a collision avoidance system, especially in a \nrobot that is intended to run autonomously. \n \nWhen on the ground, real locusts escape from approaching threats by jumping. Rather \nthan precisely directing these jumps, locusts have a rather coarse control over their jump \ndirection meaning that they always jump away from an approaching object, but their \nexact trajectories are highly variable (Santer et al., 2005b). In theory, this simple escape \nstrategy could be useful for a mobile robot to reactively avoid collision without taking a \nlong time to make a decision on a precise escape trajectory. In real locusts there have \nbeen no studies of the possible role for the LGMDs or DCMDs in jump direction control \nand, although there have been several on jump triggering, none has established the exact \nrole of the DCMD (Hatsopoulos et. al., 1995, Stafford and Rind 2007, Fotowat and \nGabbiani 2007, Santer et al 2008). However, in the escape responses of cockroaches to \nwind puffs, the responses of six directionally-selective wind-sensitive giant interneurons \nare integrated to give a precise control of escape direction (Levi and Camhi 2000a, 2000b, \nEzrachi et. al. 1999, Ezrachi 2003). Because locusts have a bilateral pair of LGMDs (one \nresponding to objects looming towards the left compound eye, the other to objects \nlooming towards the right compound eye, and therefore providing a coarse indication of \nthe direction from which an object is approaching), we wondered whether integrating the \nresponses of these two neurons in a similar way could result in a simple, reactive, locust-\nlike left-right control of escape direction. \nTo test the effectiveness of this method of reactive direction control, we equipped \nKhepera robots with a bilateral pair of model LGMD neurons and integrated their \nresponses using the algorithms investigated for cockroaches. We then repeated the \ninvestigation of locust escape direction of Santer et al (2005b) using our LGMD-\nequipped robots instead of real locusts. We found that, in our robots, a locust-like control \nof escape direction was an emergent property of the integration of the left and right \nLGMD model responses. We also recorded the left and right DCMD responses of a locust \nperforming real escape jumps and integrated these spike trains offline using the same \nalgorithms as in our robotic experiments (optimised for this task using a GA). Through \nthis method, we could use our algorithms to generate the jump direction that a locust took \nin a particular trial based on its computationally-integrated DCMD responses alone. \nThese results significantly advance the usefulness of the LGMD model for autonomous \nrobot control in the real world, and indicate how simple integration algorithms can \nreproduce behavioural responses. \n \n2. Methods \n \nIn this section, we describe the construction of a locust-inspired visual collision detection \nsystem with reactive escape direction control, robotic experiments, and agent experiments \nbased on spike trains recorded from the DCMDs of real locusts during escape responses. \nPage 4 of 28 \nThe reactive escape system, including the pair of LGMD models and the fusion network \nthat integrated their responses, together with the implementation of the system in mobile \nrobots, and the robotic experiments, are described in subsection 2.1; a further test of the \nfusion network using DCMD activity recorded from real locusts is reported in subsection \n2.2. \n \n2.1 The reactive escape system \n \nThe reactive escape system in this study includes a collision detection system and a \ncoarse direction control system. The collision detection system detects imminent collision \nand triggers the a reactive escape response. The coarse direction control system controls \nthe escape direction by integrating the outputs of the collision detection system. Once \nintegrated to a mobile robot, the affiliate hardware became part of the system as a whole, \nas shown in Figure 1 (a). The CCD camera of the robot captures images in real time; the \nimages are split into two halves and fed to the left and right LGMD model (Figure 1 (b)); \nthe LGMD model spikes are used to trigger escape; the outputs of LGMD model are also \nprocessed by a fusion network which integrates their responses and controls the robot\u2019s \nescape direction. \n \n2.1.1 The LGMD model \n \nThe LGMD model (Figure 1 (b)) used in this study is based on the neural network \ndescribed in Rind and Bramwell (1996), Blanchard et. al. (2000), Stafford et. al. (2004), \nand Yue and Rind (2005, 2006a). The left and right LGMD share the same \nspatiotemporal structure. A brief description of one of the LGMDs used in this study is \ngiven below, but the precise details of this model\u2019s performance in real world collision \ndetection applications can be found in the above references. \n \nThe LGMD model responds to movement in depth or \u2018looming\u2019. The network is \ncomposed of four layers of cells - photoreceptor (P), excitatory (E), inhibitory (I) and \nsumming (S), and two single cells - feed-forward inhibition (FFI) and LGMD.  \n \nIn the first layer of the neural network are the photoreceptor (P) cells which are arranged \nin a matrix. The luminance Lf of each pixel in the input image at frame f is captured by \neach photoreceptor cell. The change in luminance Pf between frames of the image \nsequence is then calculated and forms the output of this layer. The output of a cell in this \nlayer is defined by the equation: \n \n),(),(),( 1 yxLyxLyxP fff \u2212\u2212=                                                         (1) \n \nwhere Pf(x,y) is the change in luminance corresponding to pixel (x,y) at frame f; x and y \nare the pixel coordinates, Lf and Lf-1 are the luminance, subscript f denotes the current \nframe and f-1 denotes the previous frame.  \n \nThe outputs of the P cells form the inputs to two separate cell types in the next layer. One \ntype is the excitatory (E) cells, through which excitation is passed directly to the \nPage 5 of 28 \nretinotopically arranged counterpart of the cell in the third layer, the S layer. The second \ncell type are the lateral inhibition (I) cells, which pass inhibition, after a 1 image frame \ndelay, to the cells in retinotopically neighbouring positions to their own in the S layer. \nThe strength of inhibition delivered to a cell in this layer is given by: \n \n)0,(),,(),(),( 1 =\u2260++= \u2212\n\u2212= \u2212=\n\u2211 \u2211 iifjijiwjyixPyxI Ifn\nni\nn\nnj\nf\n                                     (2) \n \nwhere If(x,y) is the inhibition corresponding to pixel (x,y) at the current frame f, wI(i, j) \nare the local inhibition weights, and n defines the size of the inhibited area. In our \nexperiments, the local inhibition weights are set to 25% for the inhibition from the four \ndirectly neighbouring cells and 12.5% for the inhibition from the diagonally neighbouring \ncells; and n was set to 1. \n \nExcitation from the E cells and inhibition from the I cells are summed by the S cells in \nlayer 3 of the network using the following equation: \n \nIfff WyxIyxPyxS ),(),(),( \u2212=                                                  (3) \n \nwhere WI is the global inhibition weight and is set to 0.3 in our experiments. Excitation \nthat exceeds a threshold value is passed to the LGMD cell: \n \n\uf8f3\uf8f2\n\uf8f1\n<\n\u2265=\nrf\nrff\nf TyxSif\nTyxSifyxS\nyxS\n),(0\n),(),(\n),(~                                              (4) \n \nwhere Tr is the threshold and is set to 15 in these experiments. \n \nThe membrane potential of the LGMD cell Uf, is the summation of all the excitation in \nthe S cells as described by the following equation, \n \n\u2211\u2211\n= =\n=\nk\nx\nl\ny\nff yxSU\n1 1\n),(~(                                                          (5) \n \nThe membrane potential Uf is then transformed to a spiking output using a sigmoid \ntransformation, \n \n1)1(\n1 \u2212\u2212 \u2212+= cellf nUf eu                                                        (6) \n \nwhere ncell is the total number of cells in the S layer. Since Uf is greater than, or equal to \nzero, the sigmoid membrane potential uf varies from 0.5 to 1. A collision alarm is caused \nby spiking in the LGMD cell. If the membrane potential uf exceeds the threshold Ts, a \nspike is produced. A certain number of successive spikes, denoted by SLGMD, will trigger \nthe collision alarm. In the experiments, ncell is 8,000 and Ts is 0.75. \n \nIn the absence of feed forward inhibition (FFI), the network may produce spikes and a \nfalse collision signal when challenged by a sudden whole-field change in the visual scene, \nPage 6 of 28 \nfor example during a rapid turn (Santer et.al. 2004). The feed forward inhibition cell \nnegates such responses when a large number of photoreceptors are simultaneously \nexcited (Rind and Bramwell 1996). The FFI at a given frame is taken from the summed \noutput of the photoreceptor cells with one frame delay, \n \n1\n1 1\n1 )),((\n\u2212\n= =\n\u2212\u2211\u2211= cellk\nx\nl\ny\nff nyxPF\n                                                      (7) \n \nOnce Ff exceeds its threshold spikes in the LGMD are inhibited immediately. The \nthreshold of the FFI cell is set to 20. \n \nIn locusts, the LGMD\u2019s postsynaptic partner, the DCMD, spikes with a 1:1 relationship \nwith the LGMD and so does a pair of DCMDs in the model.  \n \nThe spikes of the pair of DCMDs are used to initiate emergent escape behaviour and are \nfed to a fusion network which integrates their responses and translates them into a motor \ncommand to control the direction of escape that the robot takes. In the next subsection we \ndescribe these fusion networks. \n \n2.1.2 Coarse direction control system \n \nIn the escape behaviour of cockroaches to wind puffs, the responses of six directionally-\nselective wind-sensitive giant interneurons are thought to be integrated to give a precise \ncontrol of escape direction (Levi and Camhi 2000a, 2000b, Ezrachi et.al. 1999, Ezrachi \n2003). Here we use similar mechanisms of integration on the left and right model LGMD \nresponses to mimic the locust\u2019s left-right control of escape direction. In this study we \nimplement two types of fusion networks to integrate the outputs from the two model \nDCMDs. \n \nOne fusion network is a winner-take-all network (Roberts, 1968, Krasne and Lee, 1988, \nEaton et. al. 1991, Salzman and Newsome, 1994, Levi and Camhi 2000a), with which the \nDCMD controlling a given direction of escape behaviour suppresses the other DCMD \nspecifying the alternative direction (Figure 1 (c)). As shown in Figure 1 (c), the spikes \nfrom the two DCMDs are first compared at cell a. The DCMD with more spikes is the \nwinner and the robot\/agent is prepared to turn in that direction. The emergent escape \nbehaviour is triggered by several (Nsp) successive spikes from either left or right DCMDs. \nIf the number of spikes from the left DCMD is SDl and from the right DCMD is SDr, the \nescape direction can be formulated as:  \n \nspDr\nn\nni\nDrDl\nspDl\nn\nni\nDrDl\nDr\nDl\ndir\nNSSSif\nNSSSif\nS\nS\nD\n>=<\n>=>\n\uf8f3\uf8f2\n\uf8f1=\n\u2211\n\u2211\n\u2212=\n\u2212=\n4\n4\n&\n&                                               (8) \n \nwhere n is an integer representing a spike at a time step, Nsp is an integer number, often \nset to 4 or 5 empirically, depending on factors such as image frame rate per second, \nPage 7 of 28 \nrobotic control system, computing power etc. Note that in the above equation, the \u2018loser\u2019 \ncontributes nothing to Ddir.   \n \nOccasionally, the left and right DCMD produced the same number of spikes. This would \nbe rare for a locust since its DCMD spikes at very high frequency, much higher than its \nmodelled counterpart. The DCMD model works at 25Hz or lower, so its left and right \nDCMD may sometimes produce the same number of spikes at the time of escape. It is \nalso obvious that a mobile robot can only move on a two dimensional surface. To initiate \na successful escape in this case, a randomised direction is more practical, \n \n)(&,)1(\n44\n0101\nspDr\nn\nni\nspDl\nn\nni\nDrDlDrDl\ndir NSorNSSSifSRSRD >=>==\u2212+= \u2211\u2211\n\u2212=\u2212=\n                (9) \n \nwhere R01 is randomly generated binary number either 1 or 0.   \n \nA transformation needs to be done to turn spike number to robotic turn time period using \nthe following equation, \ndirdir DT 1\u03bb=                                                           (10) \n \nthe unit of time Tdir is seconds, \u03bb1 is a coefficient obtained experimentally. Given the \nturning speed of a robot, the longer the Tdir, the bigger the escape angle \u0398. \n \nAccording to equation (8)-(10), if the left DCMD generates Nsp successive spikes earlier \nthan the right side LGMD, the robot will turn to the right side before escape because the \nleft DCMD is the winner. The turning angle will be decided by the time value calculated \nusing the above equations. This is supported by biological experiments in which locusts \nbegin to steer their jump with their forelegs prior to lifting off with their hindlegs (Santer \net al, 2005). In the experiments, \u03bb1 is set to 0.1 for normal vision and 0.05 for panoramic \nvision, Nsp is set to 5 for normal vision and 4 spikes for the panoramic vision because of \nthe lower frame rate resulting from panoramic image transformation.  \n \nThe second implemented fusion network is a collaborative, or steering-wheel (Levi and \nCamhi 2000b) network; this mechanism allows the two DCMD outputs to reach both \ncircuits controlling different escape directions but in an additive way, as shown in Figure \n1 (d). In this case, the final turning angle before escape is the cummulative effects of the \ntwo DCMD outputs in turn, that is to say, the turning angle is decided by: \n \n)(2\nDlDr\ndir SST \u2212= \u03bb                                                       (11) \n \nwhere \u03bb2 is also a coefficient and is set to 0.1 empirically. The same measure, i.e. \nrandomised escape direction as defined in equation (9), has been taken when the two \nDCMDs send out the same number of spikes at the time escape behaviours starts. \n \nIn some experiments we were interested to see whether additional random factors, \nrepresenting the involvement of other neurons in triggering the escape behaviour or \nmotor errors, were needed to generate variability in escape trajectory. To implement an \nPage 8 of 28 \nadditional random factor into the robotic direction control system, the Tdir has to be \nmodified as,   \n \nrdirdirR RTT 3\u03bb+=                                                          (12) \n \nwhere \u03bb3 chosen between 0-0.5 and Rr is a random real number between 0 and 1. Note \nthat if \u03bb3 is not zero, then Tdir has to be modified to maintain an equivalent length of \nturning time. For example, when \u03bb3 is 0.3, then \u03bb1 is reset to 0.04 to keep the total \nmaximum turning time 0.5s; if \u03bb3 is 0.5, then \u03bb1 is reset to 0 to keep the total maximum \nturning time 0.5s. For the robot with panoramic vision, \u03bb3 is 0.025, then \u03bb1 is reset to 0.10 \nto keep the total maximum turning time 0.25s. When the random factor is implemented, \nwe refer to the two fusion networks as \u2018randomised winner-take-all\u2019 or \u2018randomised \nsteering wheel\u2019 mechanisms. \n \n2.1.3 Implementation \n \nModel LGMD and fusion networks were written in Matlab\u00ae (the MathWorks, USA) and \nrun on a PC. Input to the paired LGMD models was from the CCD camera of a Khepera \nmobile robot (K-team, Lausanne, Switzerland) (Figure 2 a, c). We used either a normal \ngrey scale CCD camera (field of view approx. 60 degrees, Figure 2 b) or a panoramic \nvision camera (field of view is 360 degrees, Figure 2d). Communication between the PC \nand the robot was via a serial port through an RS232 cable.  \n \nImages captured by the robot\u2019s CCD camera were fed to the model LGMDs and \nprocessed in real time. For the robot with normal vision, the size of the whole image fed \nto LGMDs was 100 pixels horizontally and 80 pixels vertically. When the panoramic \nvision camera was used (Figure 2 c), images were transformed from panoramic images \n(Figure 2 d) into normal images (Figure 2 e) using programmes written in Matlab and \nthen fed to the LGMD\/DCMD model for processing. The transformation involved \nrearranging pixels to a different coordinate system, i.e., from a Polar to a Cartesian \ncoordinate system; the grey scale at each pixel remains unchanged (Figure 2 d). For the \nrobot with panoramic vision, the size of the whole image fed to the LGMDs was 360 \npixels horizontally by 42 vertically. The LGMD spiking threshold was set to 0.6 when \npanoramic vision was used. \n \nFor both camera types, the image (either directly from the camera or transformed from a \npanoramic image) was divided into two bilateral halves with a 10 degree overlap in the \ncentral region, mimicking the fields of view of insect compound eyes (Horridge 1978; \nStern and Gewecke 1993). These were each used as input to one of the LGMD models \nmaking a left right bilateral pair as in the real locust. Examples of the outputs from the \nLGMD models challenged by a rolling cylinder from two different angles are shown in \nFigure 3. The robot had panoramic vision in the examples. Note that in a real world \nexperiment (Figure 3 a), the left and right LGMD generated different numbers of spikes \nthough the cylinder rolled towards the CCD directly from behind.  \n \n2.1.4 Robotic experiments \nPage 9 of 28 \n \nUsing robotic experiments, we wanted to determine whether a coarse, locust-like control \nof escape direction could be mimicked by the integration of left-right LGMD model \nresponses and whether this could serve as a useful collision avoidance system for a robot \nrunning autonomously. We used a series of robotic experiments to address this. A \nKhepera II robot with normal vision and a Khepera II robot with 360 degree vision were \nused in these experiments. We tested the two algorithms described above (winner-take-all \nand steering wheel) for integrating its right and left model LGMD responses which have \nbeen recently investigated for the cockroach escape system (Levi and Camhi 2000a, \n2000b, Ezrachi et.al. 1999, Ezrachi 2003).  \n \nInitially we used the same rolling ball stimulus that was used to trigger directed escape \njumps in locusts by Santer et al (2005b). The ball was rolled at different angles (varying \nat 5 degrees increments) toward the normal camera of a Khepera robot. Using its paired \nmodel LGMDs and subsequent method of integration, the robot was expected to detect \nthe collision, turn to a direction, move along that direction for 3 seconds and stop. The \ndirections were then measured according to the final position of the robot to the fixed \nstart position. For each angle, 5 trials were conducted.  \n  \nThe robots\u2019 escape behaviours were triggered by several successive LGMD model spikes, \nas mentioned in the above section, e.g. 5 successive spikes for the robot with normal \nvision and 4 successive spikes for the robot with panoramic vision. An infrared sensor \nwas also used to trigger the robot\u2019s escape behaviour for one of the experiments, in order \nto investigate the possible effects of direction control by the LGMD\/DCMDs and escape \ntriggering by another mechanism. In this situation, the rolling ball hit a long curved strip \nof white paper at the end of its approach (about 10cm long and 3cm wide folded to 1.5cm \nwide cut from 8g A4 paper). This paper blocked one front infrared sensor of the robot and \nwas knocked away by the rolling ball, allowing the infrared sensor to detect the ball\u2019s \napproach. The infrared sensor worked at approximately 50 Hz.  \n \nEscape angles were largely determined by the robot\u2019s turning speed and turning time \naffected by some other minor random factors, such as internal system errors of the robot \nand mechanical characteristics of the test bed. The turning speed of the robot was \ndetermined by the speeds of its wheels. For the robot with normal vision, the left wheel \nwas set to 3.2cm\/s and the right -3.2cm\/s to allow the robot to turn around the centre \npoint between the two wheels. The turning time was set to 0.3s experimentally to ensure \nthe maximum turning angle was around 45 degrees. The robotic agent system can process \n25 images per second in the experiments.  \n \nFor the robot with 360 degrees vision, a wider range of ball approaching angles was used \nin a larger series of experiments. The turning speed of the robot was set in the same way \nas before but at 6.4cm\/s. The turning time was set to 0.2s experimentally to ensure the \nmaximum turning angle is around 45 degrees. The robotic agent with panoramic vision \ncan process approximately 11 images per second.  \n \n2.2 Computational integration of real DCMD spike trains \nPage 10 of 28 \n \nWe also wanted to know whether the above fusion mechanisms can integrate real \nrecorded left and right DCMD spikes of a real escaping locust and reproduce its actual \nescape direction. The interpretation of the real animal\u2019s visual neuron spikes into a \nmotion control signal is also an important step towards a visual neuron controlled hybrid \nrobotic system.  \n \nIn the robotic system, the maximum LGMD model spiking rate is 25 Hz for normal \nvision and 11 Hz for panoramic vision. The escape behaviour of a robot is triggered by \nseveral successive spikes. In a real locust, the maximum DCMD spiking rate is much \nhigher, for example, the peak firing rate can be >400 Hz. It is therefore biologically \nplausible for the computational models to look at excitation resulting from the left and \nright DCMDs spikes rather than counting the spikes themselves.  \n \nWe use agents to represent the systems which read spike trains and output escape \ndirections. For example, a winner-take-all agent uses the winner-take-all algorithm to \nintegrate the spike trains from left and right DCMDs to generate escape directions. \nSimilarly, a steering wheel agent uses the steering wheel algorithm. \n \n2.2.1 DCMD spike train recording \n \nIn locusts, the LGMD\u2019s postsynaptic partner, the DCMD, spikes with a 1:1 relationship \nwith the LGMD and so by recording it, we can ascertain the locust LGMD response \n(Rind, 1984). Spike trains from a real locust\u2019s left and right DCMD neurons were \nrecorded as the animal performed escape jumps in response to a rolling ball stimulus as \nused in Santer et al (2005b). Recordings were made using a pair of hook electrodes that \nwere implanted as in Santer et al (2005a). These recordings were amplified and captured \nto disc using a CED micro1401 and Spike2 v 5 for Windows (Cambridge Electronic \nDesign). In total, we made thirteen successful recordings in which left and right DCMD \nactivity was clear during the performance of an escape jump. In each case, the ball \nstimulus approached from a different direction and we high-speed filmed the jump of the \nlocust (using a Redlake, Motionscope PCI high speed camera) and recorded DCMD \nspikes simultaneously (Figure 8a). The locust\u2019s escape directions were extracted \nmanually (Figure 8b) from the recorded video clips.  \n \n2.2.2 Integration of real DCMD spike trains for escaping agents \n \nWe wanted to see if a similar integration strategy to the one we employed with bilateral \npaired model LGMDs could integrate the DCMD responses of real locusts to reproduce \nlocust escape directions. In these experiments we created computational \u2018agents\u2019 that \nintegrated the left and right DCMD responses recorded from a freely jumping locust to \ndetermine a direction of escape. These agents read the recorded left and right DCMD \nresponses as the outputs of their left and right DCMDs. They then outputted escape \ntrajectories by using (1) the winner-take-all model and (2) the steering wheel model as \ndetailed in the above section. We found that both winner-take-all model and steering-\nwheel model can produce escape directions similar to those taken by real locusts (Figure \n8c).  \nPage 11 of 28 \n \nUsing a genetic algorithm (GA) (Yue et. al, 2006b), we found that by manipulating \nparameters such as the weights, coefficients and thresholds within the integration \nalgorithms of the agents, they could reproduce the escape angles actually produced by the \nexperimental locust in a particular trial (figure 9) from its DCMD responses alone (figure \n8a). The two fine-tuned agents were able to generate escape directions with winner-take-\nall (figure 9a) and steering wheel (figure 9b) algorithms based on the recorded DCMD \nspike trains. \n \nThe visual neurons\u2019 spike train needs to be transformed into a slow time varying regime \nin order to be executed by the motor system of the robot. The following equation turns \nDCMD spikes recorded from a jumping locust into excitation of the computationally \nrealised motor system of an escape agent (Zhurov and Brezina 2006), \n \n)( )( itDLi\nt\ntti\nmexL\ndc\nn\neSM \u2212\u2212\n\u2212=\n\u2211= \u03bb\u03bb                                                (13a) \n)( )( itDRi\nt\ntti\nmexR\ndc\nn\neSM \u2212\u2212\n\u2212=\n\u2211= \u03bb\u03bb                                                (13b) \n \nwhere t is the current time, tn is the time period from the current time back tn ms, SDL are \nthe left DCMD spikes within tn to t, SDR are the right DCMD spikes within tn to t, \u03bbm is a \ncoefficient and \u03bbdc is a decay coefficient. MexL represents excitation caused by the left \nDCMD spikes and MexR represents the excitation caused by the right DCMD spikes.  \n \nFor the winner-take-all agent, excitation in its motor system resulting from the spikes of \nits left and right DCMDs are compared to decide the winner, and then the direction and \nangle of the escape behaviour is determined by the winner, i.e. the DCMD which causes \nhigher excitation in the motor system wins and decides the coarse jump direction and \nangle. The final calculation of a winner-take-all agent can be illustrated by, \n \nexRexL\nexRexL\nexRr\nexLl\ndir MMif\nMMif\nMw\nMw\nD <\n>\n\uf8f3\uf8f2\n\uf8f1=                                               (14) \n \nwhere wl and wr are weights for the left and right motor system. The time at which the \nfinal calculation is conducted is tpj ms before the real recorded locust jumps. In the \nexperiments using winner-take-all agents, tn was 22.3ms, tpj was 93ms, \u03bbm was 38 and \u03bbdc \nwas 0; threshold for the excitations are 4.45 for the right and 6.63 for the left; weights are \nwl = 0.217 for the left and wr = 0.852 for the right (Yue et.al 2006b). Ddir will be zero if \nMexL equals MexR. \n \nFor the steering-wheel agent, the excitation caused by the DCMDs are compared at tpj ms \nbefore the real recorded locust jumps and the reduction results (e.g., MexL-MexR) will \ndetermine the agent\u2019s jumping direction and angle. The final calculation of a steering-\nwheel agent before a jump can be formulated as, \n \nPage 12 of 28 \n\uf8f3\uf8f2\n\uf8f1\n<\u2212\u2212\n>\u2212\u2212=\n0)(),(\n0)(),(\nexRexLexRexLr\nexRexLexRexLl\ndir MMifMMw\nMMifMMw\nD                                       (15) \n \nIn the experiments using steering wheel agents, tn was 23.8ms, tpj was 29ms, \u03bbm was 6.7 \nand \u03bbdc was 0; threshold for the excitations are 4.11 for the right and 6.76 for the left; \nweights are wl 0.551 for the left and wr 0.722 for the right (Yue et. al. 2006b). In rare \ncases, Ddir will be zero if excitations from the two sides are equal. \n \n3. Results \n \nIn our initial experiments we tested two mechanisms of bio-inspired left and right model \nLGMD integration for the generation of locust-like escape responses. A locust\u2019s control \nof its escape direction is rather crude in that it can reliably direct its escape away from a \nlooming threat, but does not do so with a precise angle. The same angle of object \napproach can result in a wide variation in actual escape jump trajectories (Santer et al, \n2005b). Both the \u2018winner-take-all\u2019 and \u2018steering wheel\u2019 integration algorithms allowed \nthe mobile robot to direct its escape away from the same looming stimulus used to \nstimulate locusts in a previous study (Santer et al 2005b). However, the variability in the \nexact escape angles taken was very much less for the winner-take-all than steering wheel \nalgorithm (figure 4a, b). This is relatively simple to understand since the robot\u2019s escape \nitself was triggered by 5 consecutive model LGMD spikes, and these same spikes \ngenerated the escape angle and therefore resulted in little variation between trials. The \nlittle variation that did occur was likely to be a result of wheel slips and\/or other motor \nerror by the robot. In contrast, the steering wheel model produced an unpredictable \nescape angle somewhat similar to that used by the locust. \n \nTo examine whether the variation in a locust\u2019s escape jump trajectory could be achieved \nby factors external to neural image processing, we introduced a <5 degree \u2018motor error\u2019 \nto the robot\u2019s escape trajectory. This was justified since locusts often slipped when \npreparing to jump and motor activity in their hindlegs was highly variable (Santer et al, \n2005b). As expected, this modification increased the variability in the robot\u2019s escape \ntrajectory for both integration algorithms (figure 4c, d).  \n \nIn the previous experiments we assumed that the LGMD response was responsible for \ntriggering escape but, in the locust, this may not be the case (e.g. Fotowat and Gabbiani \n2007, Santer et al 2008). In our next experiments, we wanted to examine the effects of \nusing model LGMD responses to specify escape direction, whilst an additional, \nunconnected mechanism triggered the escape itself. We therefore used the model LGMD \nresponses of the robot to calculate an escape trajectory that was constantly updated \nthroughout object approach. The escape itself was then triggered by the Khepera robot\u2019s \ninfra-red sensors which we use to mimic other, unknown jump triggering mechanisms. \nHere, as in the previous experiment, variability in escape trajectory was increased for \nboth integration algorithms but most locust-like for the steering wheel algorithm (figure 4 \ne, f). \n \nPage 13 of 28 \nLocusts have very wide fields of view and their LGMDs have receptive fields that cover \nthe majority of them. In our next experiments we used a panoramic camera-equipped \nrobot to better mimic this situation. With such panoramic vision, the robot escaped from \nthe approach of a rolling ball from a wide range of angles using a very similar range of \nescape angles seen for real locusts performing escape behaviours to these stimuli (figure \n5 a, b). Example escape trajectories are illustrated in figure 6 where a rolling cylinder was \nused to trigger escape. Randomised winner-take-all integration was used in these \nexperiments but steering wheel integration should produce similar results with panoramic \nvision. As an example, the panoramic vision robot with steering wheel fusion network \ncould easily escape from an approaching human hand as shown in Figure 7. \n \nThe previous experiments indicate how an artificial agent may produce a range of locust-\nlike escape directions based on the integrated responses of its model LGMD neurons and \na motor error factor. However, we wanted to see whether the same was possible from real \nDCMD responses recorded from a jumping locust. In a real locust jumping to escape a \nball approaching from a variety of angles, we recorded 13 paired responses from the left \nand right DCMDs from which spike times were digitised to produce rasters of each \nresponse (figure 8 a). In each trial for which DCMD responses were recorded, the \napproach angle of the stimulus and the locust\u2019s jump angle were recorded (figure 8 b). \nFed with these spike trains, computational agents could produce a similar pattern of \nescape directions before fine tuning of algorithm parameters (e.g. the winner-take-all \nalgorithm, figure 8c left, the steering-wheel algorithm, figure 8c right). By fine tuning the \nparameters of the integration algorithms using a genetic algorithm, agents could produce \nthe escape directions more similar to those taken by the real locust in a particular trial \nfrom its DCMD responses (figure 9a and 9b). In both cases, the mean square errors of the \nescape angle produced by the fine tuned computational agents (using the real locust\u2019s \njumping angles as targets) were low \u2013 1.94 degree2 for the winner-take-all algorithm and \n1.82 degree2 for the steering wheel algorithm. This suggested that if these spikes were fed \nto robotic system in real time, the robotic agent could generate similar escape angles as a \nlocust did by using the above methods i.e. that these integration algorithms could \npotentially reproduce details of real behaviour from sensory neuron responses. \n \n \n \n4. Discussion \n \nHere we have shown that the integrated responses of a bilateral pair of model LGMD \nneurons can provide sufficient information about a looming object for a mobile robot to \nreactively direct its escape away from the object. The algorithms used to integrate the two \nmodel LGMD responses, can also be optimised to integrate the left and right DCMD \nresponses of a real jumping locust. In this way, these algorithms can mimic the escape \ndirections produced by a real locust on the basis of its DCMD response alone. These \nresults significantly advance the LGMD model as a control architecture enabling reactive \ncollision avoidance in an autonomous robot. They also hint at a potential role for the \nDCMD neurons in the control of a locust\u2019s escape jump direction.  \n \nPage 14 of 28 \nVariability in escape and avoidance responses is crucial for both animals and robots. \nVariability prevents predators from leaning a repeated, fixed pattern of escape directions, \nfor example, cockroaches keep escape direction unpredictable by running along one of a \nset of preferred trajectories at fixed angles from the direction of the threatening stimulus \n(Domenici et.al. 2008) and the trajectory of locust escape jumps is rather variable (Santer \net. al. 2005). Unpredictable escape behaviour is also a critical feature for autonomous \nrobots of the future such as battlefield robots or physical game playing robots. In this \nstudy, we found that integration of the model LGMD responses using a steering wheel \nalgorithm introduced a certain degree of inherent variability into robot escape directions, \neven assuming that the direction specified by this algorithm could be perfectly translated \ninto behaviour with no error. We found this variability to be somewhat similar to that \nreported for the escape jumps of real locusts (Santer et. al. 2005b). However, we found \nthat the winner-take-all algorithm did not confer any inherent variability in escape \ndirections. We introduced this variability by adding an artificial motor error to the robot\u2019s \nresponse. Potentially, a similar random factor may introduce variability into the escape \njumps of real locusts since their hindlegs can sometimes fail to grip the substrate \nadequately during a jump (Santer et.al. 2005b). The links between visual neurons and the \nmotor\/interneurons controlling the locust escape jumps are largely unknown, but both of \nour integration algorithms appear to be suitable for mimicking the locust\u2019s escape \nbehaviour and its variability for a mobile robot. They may also indicate interesting \navenues for neuroethological research into the control of escape direction in real locusts.  \n \nOur algorithms integrated left and right LGMD model responses to confer a coarse, \nlocust-like control of escape direction. These algorithms are based on those proposed for \nthe control of cockroach escape responses. Like locusts, cockroaches also direct their \nescape away from approaching threats (e.g. Levi and Camhi 2000a, 2000b, Ezrachi et.al. \n1999, Ezrachi 2003, Domenici et.al. 2008). To do this, they rely on wind movements \ndetected at the cerci and exciting three bilateral pairs of directionally-selective, wind-\nsensitive giant interneurons. These cells are each responsive to wind currents arising from \na certain area of space around the cerci, and a collaborative calculation based on the spike \nnumbers in each allows the cockroach to accurately direct its escape at a predictable \nangle away from the approaching stimulus (although it has now been reported that a \nrange of trajectories are possible; Domenici et.al. 2008). Since our robot (and real locusts) \npossessed only a single bilateral pair of LGMDs, integration of their responses as in the \ncockroach giant interneurons meant that less directional information was available for \nprecise direction control. However, this did provide sufficient information for a similar \nleft-right jump direction control as seen in real locusts escaping looming threats. If the \nDCMDs are involved in escape direction control in real locusts, this might help to explain \nwhy the locust\u2019s escape behaviour is rather coarsely directed, whilst that of the cockroach \nis more precisely and accurately directed. \n \nFor our mobile robot, the bio-inspired integration of model LGMD responses allowed \neffective escape under a diverse range of conditions that included approaching objects of \ndifferent colours, shapes and materials. This is a distinctive feature of artificial visual \nsystems based on real, motion-sensitive neurons (e.g. Yue and Rind, 2005, 2006a and \n2006b). Collision detection is a very important skill that ensures successful navigation for \nPage 15 of 28 \nmobile robots and has been a difficult task to achieve with limited computing power (e.g. \nAdams 1998, Everettt 1995, Fiala and Basu 2004, DeSouza and Kak 2002, Vahidi and \nEskandarian 2003, Manduchi et. al. 2005, and Grandchallenge 2005). Recent explorations \nof using biologically \u2013inspired neural mechanisms to achieve this provided unique and \nrobust solutions for robotic navigation (e.g. Blanchard and Rind 1999 and 2000, Harrison \nand Koch 2000, Iida 2003, Huber et. al. 1999, Webb and Reeve 2003, Nishio et. al. 2004, \nYue and Rind 2006a and 2007). The approach we tested here demonstrates the ability of \nthe bio-inspired visual neural system to trigger and direct the escape behaviours of mobile \nrobots. The reactive escape system could be easily implemented in other type of robot as \none of the basic robotic skills to allow interaction with humans and with dynamic local \nenvironments. \n \nPrevious studies have shown that lateral and feedforward inhibition are capable of \npreventing a model LGMD response to translating, rather than looming, objects (Rind \nand Bramwell 1996, Santer et.al. 2004, Yue and Rind 2006b). However, in our \nexperiments a robot escape behaviour could occasionally be triggered by fast translating \nmotion very close to the robot\u2019s camera since this generates a large amount of excitation \n(although not enough to activate feed forward inhibition). Future study will be needed to \ninvestigate the influence of fast translating motion to the escape behaviour of a robot, \nalthough we expect the ideal solution to this problem to lie within the model LGMD \narchitecture, rather than our integration algorithms.  \nUsing our integration algorithms on DCMD spike trains recorded from a real locust \nperforming escape jumps revealed that these algorithms could produce similar patterns of \nescape direction to the ones that the locust actually took before optimisation, and could \nreproduce these angles with increased accuracy afterwards. This does not mean that the \nlocust actually relies on these or similar algorithms, but does indicate that the algorithms \ncan reproduce behaviour from sensory neuron responses, and that, potentially, this would \nallow direct, real-time control of robot movements from neural activities. This has \nexciting implications for areas of cybernetic research such as prosthetic limb design \nwhere integration architectures may need to be designed to reproduce behaviour from \nrecorded nerve impulses. It is important to note, however, that although the processing \nwe describe here is a feasible way to reproduce the locust\u2019s escape direction on the basis \nof LGMD model, or real DCMD responses, it is clear that the processing occurring in the \nnervous systems of real locusts is likely more complex. Locusts also possess another pair \nof large motion-detecting neurons similar to the LGMDs \u2013 these are the LGMD2s. The \nLGMD2s are not excited by the approach of light objects but specifically respond to the \nmovement of edges in the light to dark direction (Rind 1984, Simmons & Rind 1997). \nLGMD2 may provide more information about the trajectory or orientation of an \napproaching object, and may affect the control of escape direction. Systematic \ninvestigation of the LGMD2 and its role in escape direction control will be an important \navenue for future biological and robotic research. \n \n5. Conclusion \n \nPage 16 of 28 \nIn the above sections, we demonstrated a bio-inspired escape system with an emergent \ncontrol of direction, based on the fusion of a pair of locust-inspired visual neural \nnetworks (LGMD\/DCMDs). We showed that this is a feasible and robust way for a \nmobile robot to successfully initiate visually triggered escape directed away from a \ndeveloping threat. Sharing the common distinctive robust features of motion sensitive \nneural networks, the system allows the mobile robot to run away from approaching \nobjects when collisions are imminent, regardless of the colour, shape or physical \ncharacteristics of these objects. Our experiments also show that the same integration \nmechanisms could fuse recorded real DCMD spike trains into similar pattern of escape \ndirections to the one a locust used, showing that the locust DCMD, or other neurons, \ncould be used to control a robotic system directly.  \n \n \nAcknowledgement \n \nThe first and fourth authors were supported by EU IST (FET) 2001-38097. \n \n \nReferences \n \n[1]  Adams, M. D. Sensor modelling, design and data processing for autonomous navigation. \nRiver Edge, NJ, World Scientific, 1998. \n[2]  Blanchard, M. Verschure, P. F. M. J. and Rind, F. C.  Using a mobile robot to study locust \ncollision avoidance responses. Int. Journal of Neural Systems, vol. 9, 405-410, 1999. \n[3]  Blanchard, M. Rind F.C. and Verschure, P.F.M.J. Collision avoidance using a model of the \nlocust LGMD neuron. Robotics and Automonous Systems, vol.30, 17-38. 2000. \n[4]  Camhi, J. M., Tom, W. and Volman, S. The escape behaviour of the cockroach Periplaneta \namericana II. detection of natural predators by air displacement. J. comp. Physiol. A 128, \n203-212, 1978. \n[5]  DeSouza, G.N. and Kak, A.C. Vision for mobile robot navigation: a survey. IEEE \nTransactions on Pattern Analysis and Machine Intelligence, vol.24 (2), 237-67, 2002. \n[6]  Domenici, P. Booth, D. Blagburn, J.M. and Bacon J.P. Cockroaches keep predators \nguessing by using preferred escape trajectories. Current Biology, vol.18, 1792-1796, 2008. \n[7]  Eaton, R.C., DiDomenico, R., Nissanov, J., Role of the Mauthner cell in sensorimotor \nintegration by the brain stem escape network. Brain  Behav Evol 37:272\u2013285, 1991. \n[8]  Everett, H.R. Sensors for Mobile Robots: Theory and Application. AK Peters, Wellesley, \nMA, 1995. \n[9]  Ezrachi E.A. Computational model of the cockroach escape behaviour: winner and losers in \na population code. Biol. Cybern. Vol.88(1), 33-45, 2003. \n[10]  Ezrachi E.A., Levi R., Camhi J.M. and Parnas H. Right-left discrimination in a biologically \noriented model of the cockroach escape system. Biol. Cybern., vol.81(2), 89-99, 1999. \n[11]  Fiala, M. and Basu, A. Robot navigation using panoramic tracking. Pattern Recognition, \nvol.37, 2195-2215, 2004. \n[12]  Fotowat, H. and Gabbiani, F. Relationship between the phases of sensory and motor activity \nduring a looming-evoked multistage escape behavior. J Neurosci., vol.27, 10047\u201310059, \n2007. \nPage 17 of 28 \n[13]  Gabbiani, F., Krapp, H.G., Hatsopoulos, N., Mo, C-H., Koch, C., and Laurent, G. \nMultiplication and stimulus invariance in a looming-sensitive neuron. J. Physiology- Paris, \nvol.98, 19-34, 2004. \n[14]  Gabbiani, F., and Krapp, H.G., Spike-frequency adaptation and intrinisic properties of an \nidentified, looming-sensitive neuron. J. Neurophysiology, vol.96(6), 2951-2962, 2006. \n[15]  Gnatzy, W. Digger wasp vs. cricket: neuroethology of a predator-prey interaction. Inform. \nProcess Animals 10, 92, 1996. \n[16]  Grandchallenge, http:\/\/www.darpa.mil\/grandchallenge\/index.asp, 2005. \n[17]  Harrison, R.R., and Koch, C. A silicon implementation of the fly's optomotor control \nsystem. Neural Computation, vol.12, 2291-2304, 2000. \n[18]  Hatsopoulos, N., Gabbiani,F., and Laurent, G. Elementary computation of object approach \nby a wide-field visual neuron. Science, 270: 1000-1003, 1995. \n[19]  Horridge, G.A. The separation of visual axes in apposition compound eyes. Philos. Trans. R. \nSoc. London B Biol. Sci. 285, 1\u201359, 1978. \n[20]  Huber, S.A. Franz M.O. and Buelthoff, H.H. On robots and flies: modelling the visual \norientating behaviour of flies. Robotics and Autonomous Systems, vol.29, 227-242, 1999.  \n[21]  Iida, F.  Biologically Inspired Visual Odometer for Navigation of a Flying Robot. Robotics \nand Autonomous Systems, vol.44\/3-4, 201-208, 2003. \n[22]  Indiveri, G. and Douglas, R. Neuromorphic vision sensors. Science, vol.288, 1189-1190, \n2000. \n[23]  Krasne, F.B., and Lee, S.C. Response-dedicated trigger neurons as control points for \nbehavioral actions: selective inhibition of lateral giant command neurons during feeding in \ncrayfish. J Neurosci, 8, 3703-3712, 1988. \n[24]  Levi, R. Camhi, JM. Wind direction coding in the cockroach escape response: winner does \nnot take all. J. Neurosci., 15:20(10), 3814-3821, 2000a. \n[25]  Levi, R. Camhi, JM. Population vector coding by the giant interneurons of the cockroach. J. \nNeurosci. 15:20(10), 3822-3829, 2000b. \n[26]  Manduchi, R. Castano, A. Talukder A. and Matthies, L. Obstacle detection and terrain \nclassification for autonomous off-road navigation. Autonomous Robots, vol.18, 81-102, \n2005. \n[27]  Nishio, K., Yonezu, H., Kariyawasam, A.B., Yoshikawa, Y. Sawa, S. and Furukawa, Y., \nAnology integrated circuit for motion detection against moving background based on the \ninsect visual system. Optical Review, vol.11, 1, 24-33, 2004. \n[28]  O\u2019Shea, M. Rowell, C.H.F., Williams, J.L.D.  The anatomy of a locust visual interneurone: \nThe descending contralateral movement detector.  Journal of Exp. Biology, vol.60, 1\u201312, \n1974. \n[29]  Rind, F.C. A chemical synapse between two motion detecting neurones in the locust brain. \nJ. Exp. Biol., vol.110, 143-167, 1984. \n[30]  Rind , F.C. Non-Directional, movement sensitive neurones of the locust optic lobe. J. \nComp . Physiol., vol.161, 477-494, 1987. \n[31]  Rind, F.C. and Bramwell, D.I.  Neural network based on the input organization of an \nidentified neuron signaling impending collision.  Journal of Neurophysiology, vol.75, 967\u2013 \n985, 1996. \n[32]  Rind, F.C. Simmons, P.J. Orthopteran DCMD neuron: A reevaluation of responses to \nmoving objects. I. Selective responses to approaching objects. Journal of Neurophysiology, \nvol.68, 1654\u20131666, 1992. \n[33]  Rind, F.C. and Simmons, P.J.  Seeing what is coming: Building collision sensitive neurons. \nTrends in Neurosciences, vol.22, 215-220, 1999. \n[34]  Rind, F.C. Motion detectors in the locust visual system: from biology to robot sensors. \nMicroscopy Research and Technique, vol.56, 256-269, 2002. \nPage 18 of 28 \n[35]  Rind, F.C. Santer, R.D.J., Blanchard, M. and Verschure, P.F.M.J. Locust\u2019s looming \ndetectors for robot sensors. Sensors and Sensing in Biology and Engineering, FG Barth, \nJAC Humphrey, and TW Secomb (Eds.), Spinger-Verlag, Wien, New York, 2003. \n[36]  Rind, F.C., Stafford, R. and Yue, S. Technical Report D11: Biological Model Report, \nProject IST-2001-38097, LOCUST: Life-like object detection for collision avoidance using \nspatiotemporal image processing, 2004. http:\/\/www.imse.cnm.es\/locust\/main.html  \n[37]  Rind, F.C. Bioinspired sensors: from insect eyes to robot vision. Frontiers in Neuroscience: \nMethods in Insect Sensory Neuroscience, Christensen T.A. (Eds.), CRC Press Boca Raton, \nLondon, New York, 2005. \n[38]  Robert, C. Eaton, William, A. Lavender, and Chris M. Wieland, Identification of Mauthner-\nInitiated Response Patterns in Goldfish: Evidence from Simultaneous Cinematography and \nElectrophysiology, J. Comp. Physiol. 144: 521-531,1981. \n[39]  Salzman, C.D., Newsome, W.T. Neural mechanisms for forming a perceptual decision. \nScience 264:231\u2013237, 1994. \n[40]  Santer, R. D., Stafford R. and Rind, F. C. Retinally-Generated Saccadic Suppression of a \nLocust Looming Detector Neuron: Investigations Using a Robot Locust. J.R. Soc. Lond. \nInterface, vol.1, 61-77, 2004. \n[41]  Santer,R.D., Simmons,P.J. and Rind, F.C. Gliding behaviour elicited by lateral looming \nstimuli in flying locusts. Journal of Comparative Physiology, vol.191, 61-73, 2005a. \n[42]  Santer R.D., Yamawaki, Y, Rind, F.C. and Simmons, P.J. Motor activity and trajectory \ncontrol during escape jumping in the locust Locusta migratoria. Journal of Comparative \nPhysiology, vol. 191, 965-975, 2005b. \n[43]  Santer, R. D., Yamawaki, Y, Rind, F.C., and Simmons, P.J. Preparing for escape: an \nexamination of the role of the DCMD neuron in locust escape jumps. Journal of \nComparative Physiology A 194(1):69-77, 2008. \n[44]  Schlotterer, G.R. Response of the locust descending contralateral movement detector \nneuron to rapidly approaching and withdrawing visual stimuli. Canadian Journal of \nZoology, vol.55, 1372\u20131376, 1977. \n[45]  Simmons, P. J. Connexions between a movement-detecting visual interneurone and flight \nmotoneurones of a locust. J. Exp. Biol. 86, 87-97,1980. \n[46]  Simmons, P.J., Rind, F.C. Orthopteran DCMD neuron: A reevaluation of responses to \nmoving objects. II. Critical cues for detecting approaching objects. Journal of \nNeurophysiology, vol.68, 1667\u20131682, 1992. \n[47]  Simmons, P.J. and Rind , F.C. Responses to object approach by a wide field visual neurone, \nthe LGMD2 of the locust: Characterization and image cues. J. Comp . Physiol., vol.180, \n203-214, 1997. \n[48]  Stafford, R., Santer R.D. and Rind, F.C. A bio-inspired visual collision detection \nmechanism for cars: combining insect inspired neurons to create a robust system. \nBioSystems, 87, 162-169, 2007. \n[49]  Stafford, R., and Rind, F.C. Data mining neural spike-trains for the identification of \nbehavioural triggers using evolutionary algorithms, Neurocomputing, 70, 1079-1084, 2007. \n[50]  Stern, M. and Gewecke, M. Spatial sensitivity profiles of motion sensitive neurons in the \nlocust brain. In: K. Wiese et al. Sensory Systems of Arthropods, Birkhaeuser Verlag, Basel, \npp. 184\u2013195, 1993. \n[51]  Vahidi, A. and Eskandarian, A. Research advances in intelligent collision avoidance and \nadaptive cruise control. IEEE Transactions on Intelligent Transportation Systems, vol.4(3), \n143-153, 2003. \n[52]  Webb, B. and Reeve, R. Reafferent or redundant: integration of phonotaxis and optomotor \nbehaviour in crickets and robots. Adaptive behaviour, vol.11 (3), 137-158. 2003. \n[53]  Wine, J.J. and Krasne, F.B. The organization of escape behavior in the crayfish, J. Exp. Biol. \n56:1-18,1972. \nPage 19 of 28 \n[54]  Yue, S. and Rind, F.C.  A Collision detection system for a mobile robot inspired by locust \nvisual system. IEEE Int. Conf. on Robotics and Automation, Spain, Barcelona, Apr.18-21, \n2005, 3843-3848, 2005.  \n[55]  Yue, S., Rind, F.C. Keil, M.S., Cuadri, J. and Stafford, R. A bio-inspired visual collision \ndetection mechanism for cars: optimisation of a model of a locust neuron to a novel \nenvironment.  Neurocomputing, vol.69 (13-15), 1591-1598, 2006a. \n[56]  Yue, S., Yamawaki, Y., Santer, R., and Rind, F.C. Evolutionary search for the visual-motor \nmodel determining locusts escaping direction. 2006b (technical report). \n[57]  Yue, S. and Rind, F.C. Collision detection in complex dynamic scenes using a LGMD \nbased visual neural network with feature enhancement. IEEE Transactions on Neural \nNetworks, May, vol.17 (3), 705-716, 2006a. \n[58]  Yue, S. and Rind, F.C. Visual motion pattern extraction and fusion for collision detection in \ncomplex dynamic scenes. Computer Vision and Image Understanding, vol.104 (1), 48-60, \n2006b. \n[59]  Yue, S. and Rind, F.C. A synthetic vision system using directionally selective motion \ndetectors to recognize collision. Artificial Life, vol.13 (2), 93-122, 2007.  \n[60]  Yue, S., and Rind, F.C. Exploring postsynaptic organizations of bio-inspired DSNs for car \ncollision detection. IEEE Trans. on Intelligent Transport Systems, 2008a (under review).  \n[61]  Yue. S., and Rind, F.C. Competence comparison of collision sensitive visual neural systems \nduring evolution in dynamic environments. Artificial Life, 2008b (under review). \n[62]  Zhurov, Y. and Brezina V. Variability of motor neuron spike timing maintains and shapes \ncontractions of the accessory radula closer muscle of Aplysia. The Journal of Neuroscience, \nvol.26(2), 7056-7070, 2006. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nPage 20 of 28 \n       \n(a)                                                                                     (b)  \n \n \n \n \n      \n(c)                                                                 (d) \n \n \n \nFigure 1. (a) A schematic illustration of the emergent escape direction control system of a mobile \nrobot. (b) The schematic structure of the pair of LGMD\/DCMD and the fusion network which \ncontrols the escape direction of the robot; the spikes of the DCMDs may be used to trigger escape \nand be fused to control escape direction. (c) The schematic structure of a winner-take-all fusion \nnetwork integrates the left and right DCMD\u2019s outputs and generates a preferred direction at each \ntime. The\u2019 winner\u2019 of the two DCMDs takes control of the motor system; the \u2018loser\u2019 contributes \nnothing to the coarse direction control. (d) The brief structure of a steering wheel fusion network. \nIt allows left and right DCMDs to affect the left and right motor simultaneously. Both of the two \nDCMDs contribute to the coarse direction control. \n \n \n \n \n \nPage 21 of 28 \n      \n                                                       (a)                                                    (b) \n \n                     \n20 40 60 80 100 120 140 160 180 200\n20\n40\n60\n80\n100\n120\n140\n  \n                                                    (c)                                                 (d) \n \n50 100 150 200 250 300 350\n10\n20\n30\n40\n \n(e) \n \n               \n \n(f)                                              (g) \n \nFigure 2.  (a) The Khepera II robot with normal grey scale CCD camera sitting in front of a track, \na ball with diameter at 95mm is used in this experiment. (b) An example image from the CCD \ncamera with normal vision. (c) The Khepera II robot with 360 degrees panoramic vision used in \nthe experiments. (d) An example image from the CCD camera with panoramic vision. (e) An \nexample of the transformed images from the panoramic vision camera. The black ball was \ntowards the back of the robot. (f) The defined angles for the robot with normal vision where zero \ndegrees is the front. (g) The defined angles for the robot with panoramic vision where zero \ndegrees is the front. \n \n0\u25e6\nRobot \n160\u25e6\n45\u25e6\n+180\u25e6   Robot \n0\u25e6 45\u25e6\nPage 22 of 28 \n \n \n \n \n0 10 20 30 40 50 60\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nframes\nex\nci\nta\ntio\nn\ncylinder approaches from the back\nleft LGMD\nright LGMD\n \n \n(a) \n \n \n0 10 20 30 40 50 60\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nframes\nex\nci\nta\ntio\nn\ncylinder approaches from the left back\nleft LGMD\nright LGMD\n \n(b) \n \nFigure 3. The excitation level, spikes and threshold of the left and right LGMD implemented in \nthe robotic agent\u2019s visual-motor system. Winner-take-all and panoramic vision were used in these \nexamples. (a) A cylinder approached the robot from behind. The right side LGMD reached five \nspikes early. The robot turned to its left side and moved away to the left. (b) The cylinder \napproached the robot from behind and to its left. The left LGMD responded early with five \nsuccessive spikes. The robot turned right and moved away to the right. \n \n \n \n \nPage 23 of 28 \n0 5 10 15 20 25\n-60\n-40\n-20\n0\n20\n40\nball approaching angle in degree\nro\nbo\nt e\nsc\nap\nin\ng \nan\ngl\ne \nin\n d\neg\nre\ne\nwinner take all without random factor\n0 5 10 15 20 25\n-60\n-40\n-20\n0\n20\n40\nball approaching angle in degree\nro\nbo\nt e\nsc\nap\nin\ng \nan\ngl\ne \nin\n d\neg\nre\ne\nsteering wheel without random factor\n \n(a)                                                                           (b) \n \n0 5 10 15 20 25\n-60\n-40\n-20\n0\n20\n40\nball approaching angle in degree\nro\nbo\nt e\nsc\nap\nin\ng \nan\ngl\ne \nin\n d\neg\nre\ne\nwinner take all with 0.5*rand(1)\n0 5 10 15 20 25\n-60\n-40\n-20\n0\n20\n40\nball approaching angle in degree\nro\nbo\nt e\nsc\nap\nin\ng \nan\ngl\ne \nin\n d\neg\nre\ne\nsteering wheel with 0.3*rand(1)\n \n(c)                                                                           (d) \n \n \n0 5 10 15 20 25 30\n-60\n-40\n-20\n0\n20\n40\nball approaching angle in degree\nro\nbo\nt e\nsc\nap\nin\ng \nan\ngl\ne \nin\n d\neg\nre\ne\nwinner take all triggered by infrared sensor\n0 5 10 15 20 25 30\n-60\n-40\n-20\n0\n20\n40\nball approaching angle in degree\nro\nbo\nt e\nsc\nap\nin\ng \nan\ngl\ne \nin\n d\neg\nre\ne\nsteering wheel triggered by infrared sensor\n \n(e)                                                                           (f) \n \n \nFigure 4. The robotic agent escape angle versus ball approach angle with different visual-motor \nmodels fusing the spikes from the left and right LGMD\/DCMD of the Khepera robot with normal \nvision. Six trials were conducted per angle in the above experiments. The robot had a normal \nCCD camera. The escape behaviours were triggered by LGMD\/DCMD spikes unless stated \notherwise. (a) Winner-take-all model. (b) Steering wheel model. (c). Winner-take-all model with \nartificially introduced random factor. (d) Steering wheel model with artificially introduced \nrandom factor. (e) Winner-take-all model without artificially introduced random factor; the \nescape behaviour was triggered by infrared sensors. (f) Steering wheel model without artificially \nintroduced random factor, the escape behaviour was triggered by infrared sensors. \n \nPage 24 of 28 \n-180 -135 -90 -45 0 45 90 135 180\n-45\n-30\n-15\n0\n15\n30\n45\nBall approach angle in degree\nR\nob\not\n e\nsc\nap\ne \nan\ngl\ne \nin\n d\neg\nre\ne\nRandomised winner-take-all model\n \n(a)                                                                    (b) \n \nFigure 5. (a) The escape direction of the robot when challenged with a ball approaching from \ndifferent angles. Randomised winner-take-all was used to fuse the spikes from the left and right \nDCMDs of the Khepera II robot. The robot had panoramic vision. Five trials were conducted per \nangle. (b) Locust jumping directions when challenged with rolling balls approaching at different \nangles (Santer et. al. 2004) \n \n-100 0 100\n-100\n0\n100\nx mm\ny \nm\nm\n-100 0 100\n-100\n0\n100\nx mm\ny \nm\nm\n \n(a)                                                 (b)                                                     (c)  \n-100 0 100\n-100\n0\n100\nx(mm)\ny(\nm\nm\n)\n-100 0 100\n-100\n0\n100\nx(mm)\ny(\nm\nm\n)\n-100 0 100\n-100\n0\n100\nx(mm)\ny(\nm\nm\n)\n \n(d)                                                    (e)                                                (f) \n \nFigure 6. The escape trajectory of the robotic agent when challenged with a rolling cylinder from \n45 degrees, 180 degrees and 160 degrees respectively. Winner-take-all was used in the \nexperiments. Arrows represent the approach direction of the cylinder. (a) A sample image taken \nduring the experiments. The robot was put at the centre of a Cartesian coordinate system with its \nfront aligned to the black arrow at the bottom of the image. The cylinder was covered by \nirregular textures, such as dots, stripes, and black stickers. (b) The cylinder approaching from \n180 degrees behind the robot, model with introduced random factor. (c) The cylinder \napproaching from 160 degrees, or behind and left of the robot, model with introduced random \nfactor. (d) The cylinder approached from 180 degree, behind the robot, model without random \nfactor. (e) The cylinder approached from 290 degree, or left back of the robot, model without \nrandom factor. (f) The cylinder approached from 45 degree, or left front of the robot, model \nwithout random factor.  \nPage 25 of 28 \n \n \n \n \n   \n5                                  10                                  15 \n \n \n \n \n \n \n \n \n \n \n \n   \n20                                 25                              30 \n \nFigure 7. Sample images of the robotic agent escaping from an approaching hand. The number \nunder each image is the frame number. The robotic agent used a pair of LGMD\/DCMD to extract \nvisual cues and a steering wheel model to fuse the cues. The escape behaviour was triggered by \nfive successive spikes from a DCMD (right side DCMD apparently). The escape direction was \ncontrolled by the steering wheel fusion network. The turning speed is set to 6.4cm\/s for left and -\n6.4cm\/s for the right wheel in this experiment.  \n \n \nPage 26 of 28 \n7.2 7.3 7.4 7.5 7.6 7.7\n0\n1 left DCMD\nright DCMD\n15.3 15.4 15.5 15.6 15.7 15.8\n0\n1\n7.6 7.7 7.8 7.9 8 8.1\n0\n1\n6.7 6.8 6.9 7 7.1 7.2\n0\n1\n22.1 22.2 22.3 22.4 22.5 22.6\n0\n1\n16.8 16.9 17 17.1 17.2 17.3\n0\n1\n6.3 6.4 6.5 6.6 6.7 6.8\n0\n1\n52.1 52.2 52.3 52.4 52.5 52.6\n0\n1\n4.6 4.7 4.8 4.9 5 5.1\n0\n1\n21 21.1 21.2 21.3 21.4 21.5\n0\n1\n36.8 36.9 37 37.1 37.2 37.3\n0\n1\n16.6 16.7 16.8 16.9 17 17.1\n0\n1\n65.3 65.4 65.5 65.6 65.7 65.8\n0\n1\ntiming of spikes\n \n(a) \n \n \nPage 27 of 28 \n0 50 100 150 200 250 300 350\n-30\n-20\n-10\n0\n10\n20\n30\n40\nball approaching angle in degree\nlo\ncu\nst\ns \nju\nm\npi\nng\n d\nire\nct\nio\nn \nin\n d\neg\nre\ne\nrecorded locusts jumping directions\n \n(b) \n \n0 100 200 300 400\n-30\n-20\n-10\n0\n10\n20\n30\nball approaching angle in degree\nlo\ncu\nst\ns\/\nag\nen\nt j\num\npi\nng\n a\nw\nay\n a\nng\nle\n in\n d\neg\nre\ne winner take all\nreal locust\n  \n0 100 200 300 400\n-30\n-20\n-10\n0\n10\n20\n30\nball approaching angle in degree\nlo\ncu\nst\ns\/\nag\nen\nt j\num\npi\nng\n a\nw\nay\n a\nng\nle\n in\n d\neg\nre\ne\nsteering wheel\nreal locust\n \n \n(c) \n \n \nFigure 8. (a) The left and right DCMD spikes from a locust in thirteen trials during experiments \nin which a ball was delivered along a track from different angles. Spikes were plotted within a \n600ms time window starting at the first recorded spike. The vertical green bars indicate the time \nwhen locusts jumped. The time of jump was measured from synchronised high speed video \nrecordings. The corresponding ball approach directions from top to bottom subplots in degree \nare: 77.01, 326.87, 356.91, 112.93, 281.99, 221.28, 251.19, 91.01, 228.05, 342.01, 46.09, 207.10, \nand 222.20. The corresponding jumping angles in degrees are: -16.12, 11.87, 10.94, -4.10, 0.57, -\n0.43, 0.84, -10.21, -0.71, 24.87, -13.24, 1.72, 7.69. (b) The locust jumping direction versus visual \nstimulus approach angle from the thirteen trials. (c) A winner-take-all agent generated escape \ndirection versus the real locust\u2019s before fine tune (left); a steering-wheel agent generated escape \ndirection versus the real locust\u2019s before fine tune (right). \n \n \n \n \n \n \n \n \n \n \n \nPage 28 of 28 \n \n \n \n \n \n0 100 200 300 400\n-20\n-10\n0\n10\n20\n30\nball approaching angle in degree\nlo\ncu\nst\ns\/\nag\nen\nt j\num\npi\nng\n a\nw\nay\n a\nng\nle\n in\n d\neg\nre\ne\nwinner take all\nreal locust\n0 50 100 150 200 250 300 350 400\n-20\n-15\n-10\n-5\n0\n5\n10\n15\n20\n25\n30\nball approaching angle in degree\nlo\ncu\nst\ns\/\nag\nen\nt j\num\npi\nng\n a\nw\nay\n a\nng\nle\n in\n d\neg\nre\ne\nsteering wheel\nreal locust\n \n \n(a)                                                    (b) \n \nFigure 9. A comparison of jumping directions after fine tuning. (a) A winner-take-all agent versus \nthe real locust. (b) A steering wheel agent versus the real locust. If mean square error (mse) is \nused to evaluate the difference between agent- produced jumping angles and the real locust\u2019s \njumping angles, the mse of the winner take all agent is 1.94 degree2 and the steering wheel agent \nis 1.82 degree2. \n \n \n \n \n"}
{"doi":"10.1057\/jors.2010.46","coreId":"10638","oai":"oai:dro.dur.ac.uk.OAI2:8115","identifiers":["oai:dro.dur.ac.uk.OAI2:8115","10.1057\/jors.2010.46"],"title":"Using imprecise estimates for weights.\\ud","authors":["Jessop,  A."],"enrichments":{"references":[{"id":650131,"title":"A simulation approach for handling uncertainty in the analytic hierachy process.","authors":[],"date":"1998","doi":"10.1016\/S0377-2217(97)00134-3","raw":null,"cites":null},{"id":650133,"title":"An Introduction to Risk Analysis.","authors":[],"date":"1977","doi":null,"raw":null,"cites":null},{"id":644595,"title":"Attribute conflict and preference uncertainty: the RandMAU model.","authors":[],"date":"2000","doi":"10.1287\/mnsc.46.5.669.12051","raw":null,"cites":null},{"id":650139,"title":"Consequences of uncertainty in the analytic hierarchy process: a simulation approach.","authors":[],"date":"1995","doi":"10.1016\/0377-2217(94)00044-D","raw":null,"cites":null},{"id":644603,"title":"Decomposition and the control of error in decision-analytic models.","authors":[],"date":"1990","doi":null,"raw":null,"cites":null},{"id":650136,"title":"Distribution of aggregate utility using stochastic elements of additive multiattribute utility models.","authors":[],"date":"2000","doi":"10.1111\/j.1540-5915.2000.tb01626.x","raw":null,"cites":null},{"id":644600,"title":"Eliciting probabilities from experts. In:","authors":[],"date":"2007","doi":null,"raw":null,"cites":null},{"id":650137,"title":"H\u00e4m\u00e4l\u00e4inen RP and Sahlo A","authors":[],"date":"2005","doi":null,"raw":null,"cites":null},{"id":650132,"title":"Interval estimation in the AHP.","authors":[],"date":"1999","doi":"10.1016\/S0377-2217(98)00012-5","raw":null,"cites":null},{"id":650134,"title":"Judgement estimates of the moments of PERT type distributions.","authors":[],"date":"1968","doi":"10.1287\/mnsc.15.2.B76","raw":null,"cites":null},{"id":644598,"title":"Mathematical programming approaches to sensitivity calculations in decision analysis.","authors":[],"date":"1992","doi":"10.1057\/jors.1992.120","raw":null,"cites":null},{"id":644596,"title":"Modelling, making inferences and making decisions: the roles of sensitivity analysis.","authors":[],"date":"2003","doi":"10.1007\/BF02579043","raw":null,"cites":null},{"id":650130,"title":"Multidimensiional Scaling. Sage: Newbury Park CA and London.","authors":[],"date":"1978","doi":null,"raw":null,"cites":null},{"id":644601,"title":"Prioritisation of an IT budget within a local authority.","authors":[],"date":"2002","doi":"10.1057\/palgrave.jors.2601266","raw":null,"cites":null},{"id":644594,"title":"SMARTS and SMARTER: improved simple methods for multiattribute utility measurement. Organizational Behavior and Human Decision Processes","authors":[],"date":"1994","doi":"10.1006\/obhd.1994.1087","raw":null,"cites":null},{"id":644599,"title":"The Analytic Hierarchy Process on an uncertain environment: a simulation approach.","authors":[],"date":"1996","doi":"10.1016\/S0377-2217(99)00111-3","raw":null,"cites":null},{"id":654125,"title":"The costs and benefits of vague information.","authors":[],"date":"1990","doi":null,"raw":null,"cites":null},{"id":654126,"title":"The Cult of Statistical Significance.","authors":[],"date":"2008","doi":"10.2139\/ssrn.1277322","raw":null,"cites":null},{"id":650135,"title":"The Significance Test Controversy: A Reader.","authors":[],"date":"1970","doi":"10.1525\/aa.1971.73.6.02a01130","raw":null,"cites":null},{"id":644602,"title":"Three-point approximations for continuous random variables.","authors":[],"date":"1983","doi":"10.1287\/mnsc.29.5.595","raw":null,"cites":null},{"id":644597,"title":"Uncertainty and imprecision: modelling and analysis.","authors":[],"date":"1995","doi":"10.1038\/sj\/jors\/0460108","raw":null,"cites":null},{"id":650138,"title":"Using intervals for global sensitivity and worst-case analyses in multiattribute value trees.","authors":[],"date":"2006","doi":null,"raw":null,"cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-06-01","abstract":"In multi-attribute decision problems the decision to differentiate between alternatives will be affected by the precision with which weights are specified. Specifications are imprecise because of the uncertainty characteristic of the judgements on which weights are based. Uncertainties are from two sources, the accuracy with which judgements are articulated and the inconsistency when multiple judgements are made and must be reconciled. These uncertainties are modelled using probabilistic weight estimates integrated by the Dirichlet distribution. This ensures the consistency of the estimates and leads to the calculation of significance of the differences between alternatives. A simple plot of these significant differences helps in the final decision whether this is selection or ranking. The method is used to find weight estimates in the presence of both types of uncertainty acting separately and together.\\ud\n\\u","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/10638.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/8115\/1\/8115.pdf","pdfHashValue":"fd7335e3d91e17c02c7e0fb48b2bcbf3b860db37","publisher":"Palgrave Macmillan","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:8115<\/identifier><datestamp>\n      2012-01-17T16:21:09Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Using imprecise estimates for weights.\\ud\n<\/dc:title><dc:creator>\n        Jessop,  A.<\/dc:creator><dc:description>\n        In multi-attribute decision problems the decision to differentiate between alternatives will be affected by the precision with which weights are specified. Specifications are imprecise because of the uncertainty characteristic of the judgements on which weights are based. Uncertainties are from two sources, the accuracy with which judgements are articulated and the inconsistency when multiple judgements are made and must be reconciled. These uncertainties are modelled using probabilistic weight estimates integrated by the Dirichlet distribution. This ensures the consistency of the estimates and leads to the calculation of significance of the differences between alternatives. A simple plot of these significant differences helps in the final decision whether this is selection or ranking. The method is used to find weight estimates in the presence of both types of uncertainty acting separately and together.\\ud\n\\ud\n<\/dc:description><dc:subject>\n        Multi-criteria<\/dc:subject><dc:subject>\n         Weights<\/dc:subject><dc:subject>\n         Probability<\/dc:subject><dc:subject>\n         Dirichlet. <\/dc:subject><dc:publisher>\n        Palgrave Macmillan<\/dc:publisher><dc:source>\n        Journal of the Operational Research Society, 2011, Vol.62(6), pp.1048-1055 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2011-06-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:8115<\/dc:identifier><dc:identifier>\n        issn:0160-5682<\/dc:identifier><dc:identifier>\n        issn: 1476-9360<\/dc:identifier><dc:identifier>\n        doi:10.1057\/jors.2010.46<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/8115\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1057\/jors.2010.46<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/8115\/1\/8115.pdf<\/dc:identifier><dc:rights>\n        This is a post-peer-review  pre-copyedit version of an article published in Journal of the Operational Research Society. The definitive publisher-authenticated version Jessop, A. (2011) 'Using imprecise estimates for weights.', Journal of the Operational Research Society., 62 (6). pp. 1048-1055 is available online at: http:\/\/dx.doi.org\/10.1057\/jors.2010.46<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn: 1476-9360","0160-5682"," 1476-9360","issn:0160-5682"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2011,"topics":["Multi-criteria","Weights","Probability","Dirichlet."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n01 November 2011\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nJessop, A. (2011) \u2019Using imprecise estimates for weights.\u2019, Journal of the Operational Research Society., 62\n(6). pp. 1048-1055.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1057\/jors.2010.46\nPublisher\u2019s copyright statement:\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n 1 \nUsing imprecise estimates for weights.  \n \nAlan Jessop \nDurham Business School \nMill Hill Lane \nDurham \nDH1 3LB \nUK \n \ntel: (0)191 334 5403 \n \nemail: a.t.jessop@durham.ac.uk \n \n \n \nAbstract \nIn multiattribute decision problems the decision to differentiate between alternatives \nwill be affected by the precision with which weights are specified. Specifications are \nimprecise because of the uncertainty characteristic of the judgements on which weights \nare based. Uncertainties are from two sources, the accuracy with which judgements are \narticulated and the inconsistency when multiple judgements are made and must be \nreconciled. These uncertainties are modelled using probabilistic weight estimates \nintegrated by the Dirichlet distribution. This ensures the consistency of the estimates \nand leads to the calculation of significance of the differences between alternatives. A \nsimple plot of these significant differences helps in the final decision whether this is \nselection or ranking. The method is used to find weight estimates in the presence of \nboth types of uncertainty acting seperately and together. \n \n \nKeywords:  multicriteria, weights, probability, Dirichlet \n \n \n \n \n 2 \nUsing imprecise estimates for weights.  \n \nIntroduction \nDeveloping a model to help a decision process is necessarily iterative. The forms of and \nrelations between model, data, and parameter values change as the understanding of the user \nchanges. They are also a vehicle for exploration and reflection by the user so that judgements \nare altered until the \u201cform and content [are] sufficient to solve the problem\u201d (Phillips 1984). \nThis process attempts to resolve the many uncertainties inherent in the model and its use \n(French 2003, 1995). Sometimes the problem may be such that all uncertainties must \nsomehow be resolved before a satisfactory decision is made but, equally, some residual \nuncertainty may be tolerated. For example, if the task is to make a short list of candidates for \nfurther consideration it is not necessary to discriminate between those on the short list, only to \nbelieve that they are better than the rest.  \nSome parameter values will be based in whole or in part on judgement. At any stage in \nthis process there is a need both to articulate this judgemental uncertainty and also to have a \nmeans of helping to reduce it by developing a better understanding of preferences through an \nexploration of their implications. Sensitivity analysis helps this exploration by testing the \neffects of changes in parameter values so that some reduction, perhaps resolution, of \nuncertainty may be achieved. There are many ways of structuring sensitivity analyses to help \nin this (see, for instance, French 1992; Insua and French 1991). Variations in parameter \nvalues may be considered one at a time or in combination (French 2003). For example, in \nmultiattribute problems Mustajoki, H\u00e4m\u00e4l\u00e4inen and Lindstedt (2006) describe three forms of \nsensitivity analysis. First, a single parameter test in which one weight is varied and the effect \non scores observed. The reults are easily shown in a simple diagram. Second, a \nmultiparameter test in which several weights are varied.  While this enables the effects of \nweight interactions to be explored the depiction of the results is not easy for more than two or \nthree weights. Thirdly, a global sensitivity analysis assesses the effects of imprecision in all \nweights, most often by specifying probability distributions for weights and then using Monte \nCarlo analysis, though in some cases an analytical approach may be feasible, and preferable. \nThe results of global analysis may be simply shown in two-dimensional plots (Kruskal and \nWish 1978), an idea applied to multcriteria problems by Clarke and Rivett (1978; Rivett \n1977). \nSingle parameter and global sensitivity analyses  have different puposes and languages \nand so are used in different  ways in the interaction between model and user. Considering all \nuncertainties together, whether by simulation or an anlystical model, uses probability \ndistributions for input and so also for output. While it is fairly straightforward to specify \ninputs interpreting outputs in the context of a decision problem may be more difficult. \n 3 \nStandard reports such as confidence interval estimates of differences between performance \nmeasures provide an easy summary. This may be enough: given the uncertainties in inputs it \nis possible to decide that one alternative is superior to another, even though the magnitude of \nthe difference is not known exactly. If this is not the case a modification of inputs (smaller \nvariances) will give more discrimination in the output. This process gives a sequence of \ngroups or clusters, starting with one undifferentiated group of all alternatives and producing  \nincreasingly more, and smaller, groups as uncertainties are reduced and discrimination \nincreases. \nThe purpose of this paper is to demonstrate the feasibility of a simple analytical model \nfor global sensitivity analysis for those comfortable with a probabilistic approach. The \nanalysis uses techniques seperately familiar elsewhere but brought together for this particular \napplication to the simple multiattribute scoring model. Scores are the weighted sum of \nattributes. Values for weights are inferred from preference statements and it is this source of \nuncertainty which is the object of the model. \nThis paper is organised as follows: the sources of uncertainty are outlined; a model \nincorporating uncertainty is described and an example using direct rating given. Extensions to \nother  methods involving several estimates of the same weights are shown and results \ndiscussed. \n \nUncertainty about weights \nThe multiattribute model considered is \n \n yj  =   wixij     ;   i = 1 n , j = 1 m     (1) \n                      \ni \n \nwith  wi = 1        (2)  \n              \ni \n \nand where  yj is the score for alternative j, wi is the weight attached to attribute i and xij is an \nappropriately scaled measure of the value of attribute i for alternative j. The scaling ensures \nthat for each variable either the range is [0,1] or that mean = 0 and standard deviation = 1. If \nthe unscaled ith attribute has values qij with minimum and maximum values qmin and qmax and \nmean and standard deviation q and sq then either \n \n xij  =  (qij - qmin) \/ (qmax - qmin)      (3) \n \nor xij  =  (qij - q) \/ sq       (4) \n 4 \n \nwith obvious adjustments if small values are preferred . \nThere are a number of methods which may be used to derive weights from preference \nstatements. Different methods generally give different weights, mainly because of the \ndifferent modes of elicitation (P\u00f6yh\u00f6nen and H\u00e4m\u00e4l\u00e4inen 2001). It is not the purpose in this \npaper  to compare such popular alternatives as SMART, SWING and AHP, simply to show how \nan analytical approach may be used to model uncertainty in some different methods \nSaaty and Vargas (1987) identify two types of uncertainty, that arising from uncertainty \nabout events and that about making judgemental preference statements, attributing this second \nto limits of information and understanding. Lavary and Wan (1998) describe both uncertainty \nabout the future context for the decision and of making judgements of pairwise weight ratios. \nHauser and Tadikamalla (1996) cite uncertainties about facts and also a lack of agreement \nbetween decision makers. Whatever the sources of uncertainty the effect is the same; an \ninability to provide precise estimates of weights.  \nWhat is a sensible response to these difficulties? Barron and Barrett (1996) speculate \nthat \u201cthe pursuit of precise weights may be an illusion\u201d, that trying to elicit exact weights is \nproblematic because the result is likely to depend on the method used and because the \nexactness of the weights obtained \u201cimposes a precision which may be absent in the mind of \nthe decision maker\u201d. Just what is in the mind of the decision maker is unknown and, probably, \nunknowable, perhaps even by the decision maker. Questions are asked which require answers \nbased on some mental process we call judgement. These answers are the data for a model \nwhich uses weights as a description of the judgements. \nUncertainty in judgement leads to uncertainty about weights. This may be described by \nspecifying ranges (e.g. Mustajoki, H\u00e4m\u00e4l\u00e4inen and Sahlo 2005) or probability distributions. \nProbabilistic models of imprecision in weight specification are usually found in studies which \nseek to explore the impact of uncertainty on model structure and performance (Moskowitz, \nTang and Lam 2000; Fischer, Jia and Luce 2000). Similarly probabilistic models for practical \ndecision support are harder to find, although using the cumulative probability distribution \n(risk function) for each score and the identification of stochastic dominance has been \nproposed (Moskowitz, Tang and Lam 2000) as have the modelling of a probability \ndistribution of the rank of each alternative (Ba\u00f1uelas and Antony 2007; Jessop 2002; Butler, \nJia and Dyer 1997) and the probability of rank reversal (Stam and Duarte Silva 1997; Saaty \nand Vargas 1987).  \n \nModelling uncertainty \nWhen making  probabilistic judgements about weights assesors will have in mind marginal \ndistributions. Because of (2) these distributions cannot be independent. The Dirichlet \n 5 \ndistribution provides an appropriate model of the joint distribution to integrate individual \nweight estimates (Hora 2007; Butler, Jia and Dyer 1997): \n \n f(W)  =  k  wi\nui-1   ;    0<wi<1,  wi = 1,  ui 0,   i   (5)  \n                              \ni                                                       i \n \n k  =  (  ui) \/  (ui)       (6)  \n                          \ni                 i \n  \nwhich has Beta marginal distributions with properties \n \n i  =  ui \/ v        (7) \n \n i\u00b2  =  ui(v- ui) \/ v\u00b2(v+1)       (8) \n \nand covariances \n \n ij  =  -uiuj \/ v\u00b2(v+1) ;  i\u2260j      (9) \n \nwhere v  =   ui             (10)\n  \n                                   i \n \nIn Bayesian analysis (e.g. Congdon 2001; DeGroot 1970) the Dirichlet distribution is \nthe conjugate prior for a process with a multinomial likelihood. As data are collected \nparameter values are updated, increasingly higher parameter values corresponding to more \ndata and so to reduced variance. Fischer, Jia and Luce (2000) make an analogy with respect to \nweight estimates; that decision makers who feel themselves to have greater expertise or \nfamiliarity with the assessment model may give estimates with smaller marginal variance and \nthat this may be seen as stored experience. Whether smaller variance represents greater \nexperience, technical familiarity with the model or unjustified self-assurance may not be clear \nbut, whichever it is, the effect is modelled in the same way: the smaller the variance the larger \nthe value of v. \nMarginal variances will be inconsistent with proper Dirichlet marginal probability \ndistributions in that they will not conform to (8). A reconciliation may be found by treating v \nas a parameter which controls the overall level of variance and finding a compromise value \nwhich ensures that the Dirichlet conditions are met. Using the mean and variance, ei and si\n2\n, of \neach weight estimate for i and i\u00b2 in (7) and (8) gives an estimate for v from the ith weight: \n 6 \n \n vi  =  [ei (1- ei) \/ si\n2\n] \u2013 1       (11) \n \nThe mean \n \n v  =   vi \/ n            (12) \n                                       i \n \n gives a compromise value of  v from which parameter values \n \nui = v.ei          (13) \n \ncan be used in (8) and (9) to give a variance\/covariance matrix. The less the uncertainty in the \nmarginal estimates the smaller will be the variances and so the higher the value of v, which \nmay therefore serve as an indicator for the overall uncertainty of the weight estimates. \nThe different estimates, vi , have some diagnostic value. Weights for which vi is low \ncompared to the summary v are those which contribute most to overall imprecision. The \njudgements made about these particular weights are those which might most usefully be \nreconsidered if more precision is needed.  \nUse of the Dirichlet distribution does not depend on particular procedures for weight \nelicitation. Estimates of mean and variance may be obtained from direct methods, matrices of \nweight ratios or any other means thought satisfactory for a given application. If the estimates \nare a summary of a number of different assessments, as when the judgements of a number of \nassessors are combined, marginal means and variances are available directly. If estimates are \ninferred from individual preference statements means and variances may be found using \nestimations familiar in, for example, PERT analyses. The underlying distributions are assumed \nto be Beta, which are the marginal distributions of the Dirichlet. Keefer and Verdini (1993) \nand Keefer and Bodily (1983) compare the accuracy of several estimators. The results given \nby Keefer and Bodily are used here. Low, central and high estimates (l , c , h) are given. If c is \ntaken as the mode and  l and h are percentiles an estimate for the mean is \n \ne  =  ac  + (1-a)(l + h)\/2          (14) \n \nwith a = 0.32 for a 90% interval (Perry and Greig 1975) and a = 0.16 for an 80% interval \n(Keefer and Bodily 1983). If the central estimate is interpreted as a median then a = 0.63 for a \n90% interval (Pearson and Tukey 1965) and a = 0.40 for an 80% interval (Swanson in Megill \n1977). In this paper modal estimates are used. Estimates of variance are given by \n 7 \n \n s\n2\n  =  [(h - l) \/ b]\u00b2       (15) \n \nwhere b = 3.25 for a 90% interval (Pearson and Tukey 1965)  and b = 2.65 for an 80% \ninterval (Moder and Rogers 1968 as modified by Davidson and Cooper 1976).  \n \nAn example \nData on MBA programmes are used for ranking and as an aid to selection. The data on full-\ntime MBA programmes published in the Financial Times of 29 January 2007 are used here. \nNine attributes were chosen, each given as a percentage (the percentage of the MBA cohort \nthat were women, and so on): \n \n1 Salary increase \n2 Aims achieved \n3 Employment at 3 months \n4 Women faculty \n5 Women students \n6 Women board  \n7 International faculty \n8 International students \n9 International board \n \nIn the analysis each is scaled according to (4), as was done by the newspaper. \nAn MBA alumna was asked to provide weights using the SMART method. First she \nranked the attributes then gave the most important a weight of 100. Lower ranked attributes \nwere given smaller weights. Finally, for all but the highest reference weight high and low \nestimates were given. It was explained that these limits should not be absolute and would be \ninterpreted as bounds of a 90% interval. The results are shown in Table 1. Means were \ncalculated using (14) and scaled so that  e = 1:  \n \nei  =  ci \/ ci.        (16) \n               \ni \nThe values of l and h were scaled by the same factor and were then used to calculate  standard \ndeviations s using (15). (This is also denoted by a to indicate uncertainty due to inaccuracy \nof response, as discussed in the next section.) Dirichlet scale factors v were found from (11). \nThe marginal Dirichlet standard deviations, D , from (8), are also shown and include an \nestimate for the anchor weight, w2. It is a useful characteristic of the method that what might \nbe seen as missing data, probabilistic estimates for the anchor, do not mean that uncertainty \nestimates cannot be made.  \n 8 \nFor those weights for which v < v the uncertainty after integration in the Dirichlet \ndistribution is less that that specified, D< a , and vice versa.  \nThe task in either ranking or selection is to decide, first, if it is justifiable to believe that \ntwo programmes are different and only then, second, to decide which is superior. Uncertainty \nabout the score for programme k is  \n \n var(yk)  =   ijxkixkj         (17) \n               \n         i    j \n \nwhere values of  ij  are from (8) and (9). \nThe difference in the scores of programmes k and l is statistically significant if \n \n zk,l   =  (|yk - yl|- ) \/ [var(yk)  + var(yl)]\n0.5\n  \u2265 z\u03b1\/2    (18) \n \nwhere z\u03b1\/2 is the critical value for a two-tailed significance test with significance level \u03b1. The \nparameter  is the test value of the difference. To test whether it is justifiable to believe that \nthere is some non-zero difference set =0. This is common in hypothesis testing and is used \nhere. (To identify as justifiably distinct only pairs with scores different by some larger margin \nset  >0.) Although significance testing has for long been the subject of dispute (Ziliak and \nMcCloskey 2008;  Morrison and Henkel 1970) z values usefully summarise the effect of \nuncertainty on the attribution of difference: the greater z the less the risk of unjustifiably \ndifferentiating alternatives.  \nUsing twenty US MBA programmes from the Financial Times listing and the weights \nshown in Table 1 the resultant performance differences are shown in Figure 1. The numbers \nshow programmes by rank. The plot is constructed so that the distances between pairs of \nalternatives correspond closely to their z value. This correspondence is characteristically high; \nr>0.9. The axes are arbitrary in that they are chosen just to maximise this correlation. The axis \nvalues are not shown here so that the diagram, a decision aid, has no detail not needed for this \nproblem. Links are shown to identify those pairs which cannot sensibly be differentiated. In \nFigure 1 it is easy to see that there are four clusters of programmes and that the four most \nhighly ranked are the most weakly clustered. Given the uncertainties of the weight \nassessments it may be that no more can be said. But this may be enough. If the purpose is to \nmake a short list then it seems clear that the first four alternatives are that list. If the purpose is \nto make a final selection then some discussion about the first two programmes is needed.  \n \nSources of uncertainty \n 9 \nThe example shows how three point weight estimates can be used to produce a diagram \nshowing the consequent justifiable discrimination between programmes. The same framework \ncan be used with different sources of uncertainty. In this section a typology is given showing \nthree general cases, each of which is illustrated using the same MBA data. \nThe number and type of questions asked and the style of the answers given are both \npossible sources of uncertainty in the elicitation process. Paulson and Zahir (1995) distinguish \nbetween inconsistency, when results are contradictory, and uncertainty arising \u201cfrom doubts \nexpressed by an individual decision maker as to the accuracy of his or her judgements.\u201d \nDescribe these by variances c\n2\n, for the uncertainty arising from contradictions, and  a\n2\n for \nthat resulting from imperfect accuracy of response.  \nIf the elicitation requires more than one estimate for each weight (from judgements \nmade at different times, say, or by different people) then the variance of these different \nestimates,  c\n2\n, is a measure of the uncertainty arising from contradictions between \nassessments (Kleinmuntz 1990). Alternatively, if exactly n-1 questions are asked to determine \nn weights, as in the SMART (Edwards 1977) or SWING (Edwards and Barron 1994) methods,  \nthe weight estimation problem has zero degrees of freedom and so no way of assessing c\n2\n.   \nWhatever the questions, answers may take one of two forms. If single point estimates \nare given then no estimate of the inaccuracy of  response is possible, but if answers are given \nprobabilistically a\n2\n can be found, as in the example above. \nPresuming that these two sources of uncertainty \u2013  consistency and accuracy \u2013  are \nindependent the variance of weight estimates is w\n2\n = c\n2\n + a\n2\n. Table 2 shows the situation. \nThere are three cases depending on which source or sources of uncertainty are considered. \n \nCase A: w\n2\n  =  a\n2\n           \nMost of the direct elicitation methods use a reference point or anchor based on an initial \nranking of attributes. Because these elicitatioins have zero degrees of freedom assessments \nmust be made probabilistically. The n-1 evaluations contribute to finding the mean value of v \nbut uncertainty estimates are found for all n weights. The example above using  SMART \nshowed this (Table 1). \n \nCase B: w\n2\n  =  c\n2\n   \nThe uncertainty measured by c\n2\n describes the distribution of a number of estimates provided \nby different people (Moskowitz, Tang and Lam 2000) or by different methods. There are a \nnumber of point estimates for each weight. The mean and variance of each weight estimate \ncan be found directly. For example, when a number of assesors have each provided estimates. \n 10 \nAlternatively, the same assessor may provide more than one estimate for each weight, \nas in the specification of weight ratios wi\/wj = aij. This method is closely identified with the \nAnalytic Hierrchy Process, AHP, but can be used seperately.  While symmetry is commonly \nassumed (aji = 1\/aij) it is not a requirement. Though this assumption of symmetry halves the \nwork of the assessor it may mask the full effect of uncertainty. These estimates are inevitably \ninconsistent (aikakj \u2260 aij) and so a weight set is found which is in some sense a best \ncompromise (best fit) to the pairwise comparisons. The most frequently cited method is the \neigenvector model of Saaty (1977). A number of studies have used simulation to investigate \nthe effects of uncertainty on the ranking of alternatives found in this way (Ba\u00f1uelas and \nAntony 2007;  Lipovetsky and Tishler 1999; Levary and Wan 1998; Stam and Duarte Silva \n1997; Hauser and Tadikamalla 1996;  Saaty and Vargas 1987; Vargas 1982). \nThere are a number of other methods for analysing pairwise judgements. Choo and \nWedley (2004) divide the methods into those which seek to optimise some function of the \nsum of differences (aij - wi\/wj) and those based on an aggregation of the columns of the matrix \nof a values. They recommend the use of  a normalised column sum as giving good estimates \nfor a range of problems. This simple method is found in standard management science texts \n(Albright and Winston 2007, Taylor 2007) recommended in its own right but also as a good \napproximation to Saaty\u2019s results. The method relies on the observation that each column of \nthe table of a values provides an unscaled estimate of the weight distribution. Scaling each \ncolumn  to sum to 1 gives estimates \n \n  gij  =  aij \/  aij                             (19) \n                                   \ni \nof the weight wj with wi as the reference. The mean of these values \n \n  ei  =   gij \/ n                          (20) \n                            \nj \nis a point estimate of weight wi. The estimation usually goes no further, thereby failing to \nexploit the positive degrees of freedom available. The variances of the estimates of wi , si\n2\n, \npermit the calculation of v using (11).  \nAs illustration the alumna who gave the judgements shown in Table 1 was asked to \nmake a set of paired evaluations using the familiar nine point scale for judgemental estimates \nof the ratios (e.g. Vargas 1982). She made these evaluations two weeks after the first. The \nresults are shown in Table 3 and the weight estimates in Table 4.  \nWith a greater number of attributes evaluation fatigue may result in an incomplete set of \nratios. However, the averaging used is not, in principle, affected by missing data provided that \nsuch gaps are not so numerous as to undermine the process.  \n 11 \n \nCase C: w\n2\n  =  c\n2\n  +  a\n2\n           \nThere are two circumstances where this might arise: when probabilistic estimates are made by \na number of assessors and when a number of probabilistic estimates are made by the same \nassessor.  \nFirst, consider that there are two or more assessors. Three MBA students were each \nasked to make weight assessments in the manner shown in Table 1 and to use them to make a \nranking of the US MBA programmes. Their individual estimates were modelled as in Case A \n(Table 1) and are shown in the left-hand half of Table 5. Each of the three estimates  (e1, e2 \nand e3) provides a point estimate of the weight. The mean these three values is  e and the \nstandard deviation is c,  a measure of the variation due to the different assessors.  \nThe imprecision of the assessments themselves is a\n2\n, the mean of the three variances \n(s1\n2\n, s2\n2\n, s3\n2\n), a simple yet effective aggregation (Clemen and Winkler 2007). The two \nestimates of uncertainty are summed to give w\n2\n = c\n2\n + a\n2\n which, with  e, provide the \nDirichlet parameters as before.  \nThe second case is when the same assessor  makes a number of estimates for each \nweight. This could be at different times or in different circumstances. An example is provided \nwhen weight ratios are specified not as single point estimates but as three point estimates \nincorporating uncertainty (as in, for instance, Ba\u00f1uelas and Antony 2007). The judgemental \ninputs in Table 3 were extracted from just such an evaluation, shown in full as Table 6.  \nThe resulting nine columns of three-point estimates were treated just as the different \nassessors\u2019 estimates in Table 5. The results are shown in Table 7.  \n \nDiscussion \nThis paper brings together and supplements existing methods to provide a treatment of the \nuncertainties inevitable in the statement of preferences and one which, via a simple diagram, \nprovides a guide to what discrimination between alternatives may, and may not, be justified. \nFor simple models such as this weighted sum an analytical approach is more convenient than \na simulation but otherwise plays the same role. None of the constituents is new: probabilsitic \nmodels of weights, with and without the Dirichlet distribution; the use of three point \nestimates; two dimensional plots have all been used for some years. Bringing them together in \nthis way has not been done before. The purpose is to demonstrate the feasibility of a decision \naid which uses probability to describe uncertainty. \nWallsten (1990) notes that decision makers \u201cfeel best served when representations of \nuncertainty are as precise as possible, but no more precise than warranted\u201d.  It is in this spirit \nthat a probabilistic approach is offerred. For some users the language of probability may be \n 12 \nunfamiliar and so inappropriate for them: they will prefer single parameter sensitivity tests. \nHowever, the probailistic approach takes account of all uncertainties simultaneously so that \nthe user may have confidence in the results which can convincingly be communicated to \ndecision makers (Mustajoki, H\u00e4m\u00e4l\u00e4inen and Lindstedt 2006). This communication should be \ncouched in terms of justifiable discrimination between alternatives. The simple diagram \n(Figure 1) helps.  \nThe application was illustrated using two popular methods for weight elicitation, SMART \nand weight ratios, as well as the aggregation of different judgements. There exist strongly \nheld views about the different methods used for multiattribute modelling. No such views are \nofferred in this paper. These methods were used as illustrations only. \nA number of applications of probabilistic models for weights have been concerned with \nthe likelihood of rank reversal. This occurs only if it is possible that the relative scores of two \nalternatives might be reversed. If it is unlikely that the difference between the scores is zero \nthen it is correspondingly unlikely that there will be rank reversal. In looking at significant \ndifferences, as in Figure 1,  it is implicit that the stability of the ranks is also addressed. \nIn both examples of Case C (Tables 5 and 7) it is notable that c > a. The results are \ngiven as illustrations of the feasibility of the proposed method of modelling weights and not \nas part of an argument about the relative importance of different sources of uncertainty. But if  \nit were generally the case that uncertainty in articulation was the smaller this would argue in \nfavour of elicitation methods with positive degrees of freedom. While elicitation methods \nwith no degrees of freedom (Case A) make life easier for the user they necessarily cannot \nafford the means to estimate uncertainty due to contradictions, c.  \nIt was assumed that the sources of uncertainty are independent, that the differences \nbetween assessments is unrelated to the precision with which those assessments are \nexpressed. This was certainly the case when more than one assessor was used (the correlation \nbetween c and a in Table 5 is r = 0.07) but for the multiple assessments of a single assessor \nit was not (for the results shown in Table 7 r = 0.94). Positive correlations will increase the \noverall uncertainty, w , and, were these dependencies shown to be generally characteristic, \nthe calculation of w should take them into account. \nWhile none of the constituents used in the model is problematic the use of a \nprobabilistic model for weights requires a difference in approach when compared with the use \nof single parameter sensitivity analysis. The forms of interaction are different. Whether it is \nmore difficult, and less useful, to see the effects of altering three-point estimates, even if just \none at a time, than changing point estimates is not resolved in this paper. The four MBA \nstudents (a small and particular sample, to be sure) who provided the data for the illustrations \nreported no difficulties. Global sensitivity analysis is, by definition, comprehensive. It speaks \n 13 \nprobability and so the flavour of the argument is about what level of discrimination is \njustifiable. The price paid is that some may find this a too abstract language. In that weights \nare found as much by interaction with a problem as by contemplation of some inner \ndispositions it may well be that some users will not find the global model helpful. Both the \nnature of what constitutes justification in a particular case and the differences in the language \nused in the interactions will determine which approach a user will prefer. \nIt was the object of this paper to establish the feasibility of the probablilistic model of \nuncertainty about weights and this has been done. Testing the utility of the approach on a \nwide range of problems, and users, remains to be done. \n \n \n \n \n \n 14 \nReferences \nAlbright SC and Winston WL (2007). Management Science Modeling. Thomson: Mason, OH.  \nBa\u00f1uelas R and Antony J (2007). Application of stochastic analytic hierarchy process withinn \na domestic appliance manufacturer. Journal of the Operational Research Society. 58: \n29\u201338.  \nBarron FH and Barrett BE (1996). Decision quality using ranked attribute weights. \nManagement Science 42: 1515\u20131523. \nButler J, Jia J and Dyer J (1997). Simulation techniques for the sensitivity analysis of multi-\ncriteria decision models. European Journal of Operational Research 103: 531\u2013546. \nChoo EU and Wedley WC (2004). A common framework for deriving preferences from \npairwise comparison matrices. Computers & Operations Research 31: 893\u2013908.  \nClarke D and Rivett BHP (1978). A structural mapping approach to complex decision-\nmaking. Journal of the Operational Research Society 29: 113\u2013128. \nClemen RT and Winkler RL (2007). Aggregating probability distributions. In: Edwards W, \nMiles RF and von Winterfeldt D (eds.) Advances in Decision Analysis: From \nFoundations to Applications. Cambridge University Press: New York. \nCongdon P (2001). Bayesian Statistical Modelling. Wiley: Chichester. \nDavidson LB and Cooper DO (1976). A simple way of developing a probability distribution \nof present value. Journal of Petroleum Technology (September): 1069\u20131078. \nDeGroot MH (1970). Optimal Statistical Decisions. McGraw-Hill: New York. \nEdwards W (1977). How to use multiattribute utility measurement for social decision making. \nIEEE Transactions on Systems, Man and Cybernetics SMC-7: 326\u2013340. \nEdwards W and Barron FH (1994). SMARTS and SMARTER: improved simple methods for \nmultiattribute utility measurement. Organizational Behavior and Human Decision \nProcesses 60: 306\u2013325. \nFischer GW, Jia J and Luce MF (2000). Attribute conflict and preference uncertainty: the \nRandMAU model. Management Science 46: 669\u2013684. \nFrench S (2003). Modelling, making inferences and making decisions: the roles of sensitivity \nanalysis. TOP 11: 229\u2013251. \nFrench S (1995). Uncertainty and imprecision: modelling and analysis. Journal of the \nOperational Research Society 46: 70\u201379. \nFrench S (1992). Mathematical programming approaches to sensitivity calculations in \ndecision analysis. Journal of the Operational Research Society 43: 813\u2013819. \nHauser D and Tadikamalla P (1996). The Analytic Hierarchy Process on an uncertain \nenvironment: a simulation approach. European Journal of Operational Research 91: \n27\u201337. \n 15 \nHora SC (2007). Eliciting probabilities from experts. In: Edwards W, Miles RF and von \nWinterfeldt D (eds.) Advances in Decision Analysis: From Foundations to \nApplications. Cambridge University Press: New York. \nInsua DR and French S (1991). European Journal of Operational Research. 54: 176\u2013190. \nJessop A (2002). Prioritisation of an IT budget within a local authority. Journal of the \nOperational Research Society 53: 36\u201346. \nKeefer DL and Bodily SE (1983). Three-point approximations for continuous random \nvariables. Management Science 29: 595\u2013609. \nKeefer DL and Verdini WA (1993). Better estimates of PERT activity time parameters. \nManagement Science 39: 1086\u20131091. \nKleinmuntz DA (1990). Decomposition and the control of error in decision-analytic models. \nIn: Hogarth RM (ed.) Insights in Decision Making: A Tribute to Hillel J. Einhorn. \nUniversity of Chicago Press: Chicago. \nKruskal JB and Wish M (1978). Multidimensiional Scaling. Sage: Newbury Park CA and \nLondon. \nLevary RR and Wan K (1998). A simulation approach for handling uncertainty in the analytic \nhierachy process. European Journal of Operational Research 106: 116\u2013122. \nLipovetsky S and Tishler A (1999). Interval estimation in the AHP. European Journal of \nOperational Research 114: 153\u2013164. \nMegill RE (1977). An Introduction to Risk Analysis. Petroleum Publishing Company: Tulsa. \nModer JJ and Rodgers EG (1968). Judgement estimates of the moments of PERT type \ndistributions. Management Science 15: B76\u2013B83. \nMorrison DE and Henkel RE (1970). The Significance Test Controversy: A Reader. Aldine: \nChcago. \nMoskowitz H, Tang J and Lam P (2000). Distribution of aggregate utility using stochastic \nelements of additive multiattribute utility models. Decision Sciences 31: 327\u2013360. \nMustajoki J, H\u00e4m\u00e4l\u00e4inen RP and Sahlo A (2005). Decision support by interval SMART\/SWING \n\u2013 incorporating imprecision in the SMART and SWING methods. Decision Sciences 36: \n317\u2013339.  \nMustajoki J, H\u00e4m\u00e4l\u00e4inen RP and Lindstedt MRK (2006). Using intervals for global sensitivity \nand worst-case analyses in multiattribute value trees. European Journal of Operational \nResearch 174: 278\u2013292. \nPaulson D and Zahir S (1995). Consequences of uncertainty in the analytic hierarchy process: \na simulation approach. European Journal of Operational Research 87: 45\u201356. \nPearson ES and Tukey JW (1965). Approximate means and standard deviations based on \ndistances between percentage points of frequency curves. Biometrika 52: 533\u2013546. \nPhillips LD (1984). The theory of requisite decision models. Acta Psychologica 56: 29\u201348. \n 16 \nP\u00f6yh\u00f6nen M and H\u00e4m\u00e4l\u00e4inen RP (2001). On the convergence of multiattribute weighting \nmethods. European Journal of Operational Research 129: 569\u2013585. \nPerry C and Greig ID (1975). Estimating the mean and variance of subjective distributions in \nPERT and decision analysis. Management Science 21: 1477\u20131480. \nRivett BHP (1977). Policy selection by structural mapping. Proceeding of the Royal Society A \n354: 407\u2013423. \nSaaty TL (1977). A scaling method for priorities in hierarchical structures. Journal of \nMathematical Psychology 15: 234\u2013281. \nSaaty TL and Vargas LG (1987). Uncertainty and rank order in the analytic hierarchy process. \nEuropean Journal of Operational Research 32: 107\u2013117. \nStam A and Duarte Silva AP (1997). Stochastic judgements in the AHP: the emasurement of \nrank reversal probabilities. Decision Sciences 28: 655\u2013688. \nTaylor BW (2007). Intoduction to Management Science (9th edn.). Prentice Hall: Upper \nSaddle River, NJ. \nVargas LG (1982). Reciprocal matrices with random coefficients. Mathematical Modeling 3: \n69\u201381. \nWallsten TS (1990). The costs and benefits of vague information. In: Hogarth RM (ed.) \nInsights in Decision Making: A Tribute to Hillel J. Einhorn. University of Chicago \nPress: Chicago. \nZiliak ST and McCloskey DN (2008). The Cult of Statistical Significance. University of \nMichigan Press: Ann Arbor. \n 17 \n \n13\n7\n20\n3\n17\n8\n14\n6\n16\n5\n2\n10\n11\n4\n12\n18\n15\n9\n1\n19\n \n \nFigure 1. Plot of z distances. Lines show insignificantly different pairs: \u03b1=0.05, \u03b8=0. \n \n \n \n 18 \n \n \nAttribute user estimates   scaled values     \n l c h  l e h  s = a v D \n1 70 90 95  0.144 0.175 0.196  0.016 572.4 0.020 \n2  100    0.206      0.021 \n3 70 90 100  0.144 0.179 0.206  0.019 403.4 0.020 \n4 10 40 50  0.021 0.069 0.103  0.025 97.9 0.013 \n5 40 50 60  0.083 0.103 0.124  0.013 572.7 0.016 \n6 5 10 15  0.010 0.021 0.031  0.006 500.2 0.008 \n7 10 30 40  0.021 0.055 0.083  0.019 142.0 0.012 \n8 60 80 90  0.124 0.158 0.186  0.019 365.7 0.019 \n9 5 20 25  0.010 0.034 0.052  0.013 204.1 0.010 \n \nTable 1. Case A: w\n2\n  =  a\n2\n. Explicit uncertainty estimates.  v = 357.3. \n 19 \n \n \n \n \n  type of answer \n  single point three-point \ndegrees of freedom 0 none available a\n2\n \nimplicit in questions >0 c\n2\n c\n2\n  +  a\n2\n \n \nTable 2: Classes of weight estimator and estimates of w\n2\n  \n \n \n 20 \n \nAttribute i   \n1 3 8 5 4 7 9 6   \n3 3 7 5 9 9 9 9 2  \n 3 9 6 7 5 9 9 1  \n  3 5 5 9 9 5 3  \n   3 5 5 5 5 8 j \n    4 1 5 5 5  \n     1 5 5 4  \n      3 5 7  \n       5 9  \n \nTable 3. Estimates of aij = wi\/wj (attributes ordered by importance). \n  \n 21 \n \n \nAttribute e s = a v D \n1 0.239 0.124 17.7 0.099 \n2 0.318 0.099 13.1 0.124 \n3 0.159 0.068 28.1 0.068 \n4 0.043 0.052 30.1 0.037 \n5 0.063 0.041 33.9 0.041 \n6 0.016 0.037 91.4 0.013 \n7 0.043 0.028 51.0 0.028 \n8 0.092 0.031 30.0 0.052 \n9 0.027 0.013 26.5 0.031 \n \nTable 4. Case B: w\n2\n  =  c\n2\n. Weight estimates from Table 3.  v = 41.6. \n \n 22 \n \n \n calculations as for Case  A (Table 1)  effect of        \n student 1  student 2  student 3  different assessors        \n e1 s1  e2 s2  e3 s3  e c  a   w v  D \n1 0.180 0.025  0.096 0.011  0.162 0.018  0.146 0.044  0.019  0.048 53.0  0.035 \n2 0.246 0.028  0.160 0.014  0.146 0.017  0.184 0.054  0.020  0.058 43.9  0.038 \n3 0.205 0.026  0.192 0.015  0.192 0.019  0.196 0.007  0.020  0.022 335.5  0.039 \n4 0.029 0.011  0.075 0.010  0.069 0.012  0.058 0.025  0.011  0.027 71.6  0.023 \n5 0.094 0.019  0.128 0.013  0.088 0.014  0.104 0.022  0.015  0.026 133.0  0.030 \n6 0.004 0.004  0.053 0.008  0.058 0.011  0.038 0.030  0.008  0.031 37.7  0.019 \n7 0.090 0.018  0.153 0.013  0.092 0.014  0.112 0.036  0.015  0.039 64.3  0.031 \n8 0.139 0.022  0.100 0.011  0.108 0.015  0.116 0.021  0.017  0.027 142.2  0.032 \n9 0.012 0.007  0.043 0.008  0.085 0.013  0.047 0.036  0.010  0.038 30.4  0.021 \n \nTable 5. Case C: w\n2\n  =  c\n2\n  +  a\n2\n. Estimates from three assessors.  v = 101.3. \n \n \n \n 23 \n \nAttribute  \n1 3 8 5 4 7 9 6  \n(3,3,4) (3,3,4) (7,7,9) (5,5,7) (8,9,9) (8,9,9) (8,9,9) (8,9,9) 2 \n (3,3,5) (8,9,9) (5,6,7) (7,7,9) (5,5,7) (8,9,9) (8,9,9) 1 \n  (3,3,5) (5,5,7) (5,5,7) (8,9,9) (8,9,9) (4,5,6) 3 \n   (3,3,4) (5,5,7) (5,5,7) (4,5,6) (5,5,7) 8 \n    (3,4,5) (1,1,3) (5,5,7) (4,5,6) 5 \n     (1,1,2) (5,5,7) (5,5,7) 4 \n      (3,3,5) (4,5,5) 7 \n       (5,5,6) 9 \n \nTable 6. Paired comparisons using three point estimates. \n \n \n \n 24 \n \n \n \n   standard deviation    \nAttribute e  c           a           w           v D \n1 0.236  0.099 0.031 0.104  15.8 0.076 \n2 0.319  0.137 0.029 0.140  10.1 0.083 \n3 0.155  0.068 0.016 0.070  26.1 0.065 \n4 0.047  0.042 0.007 0.043  23.3 0.038 \n5 0.064  0.042 0.012 0.044  30.6 0.044 \n6 0.016  0.014 0.001 0.014  77.6 0.023 \n7 0.040  0.029 0.007 0.029  43.7 0.035 \n8 0.096  0.059 0.013 0.061  22.6 0.053 \n9 0.027  0.033 0.002 0.033  23.0 0.029 \n \nTable 7. Case C: w\n2\n  =  c\n2\n  +  a\n2\n. Estimates from a single assessor.  v = 30.3. \n \n 25 \n \n \nFigure 1. Plot of  z distances. Lines show insignificantly different pairs: \u03b1=0.05, \u03b8=0. \n \nTable 1. Case A: w\n2\n  =  a\n2\n. Explicit uncertainty estimates.  v = 357.3. \n \nTable 1: Classes of weight estimator and estimates of w\n2\n  \n \nTable 3. Estimates of aij = wi\/wj (attributes ordered by importance). \n  \nTable 4. Case B: w\n2\n  =  c\n2\n. Weight estimates from Table 3.  v = 41.6. \n \nTable 5. Case C: w\n2\n  =  c\n2\n  +  a\n2\n. Estimates from three assessors.  v = 101.3. \n \nTable 6. Paired comparisons using three point estimates. \n \nTable 7. Case C: w\n2\n  =  c\n2\n  +  a\n2\n. Estimates from a single assessor.  v = 30.3. \n \n"}
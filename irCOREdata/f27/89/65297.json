{"doi":"10.1007\/s00236-009-0103-x","coreId":"65297","oai":"oai:dro.dur.ac.uk.OAI2:6255","identifiers":["oai:dro.dur.ac.uk.OAI2:6255","10.1007\/s00236-009-0103-x"],"title":"On the power of deep pushdown stacks.","authors":["Arratia-Quesada, A.","Stewart, I. A."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2009-11-01","abstract":"Inspired by recent work of Meduna on deep pushdown automata, we consider the computational power of a class of basic program schemes, NPSDSs, based around assignments, while-loops and non-deterministic guessing but with access to a deep pushdown stack which, apart from having the usual push and pop instructions, also has deep-push instructions which allow elements to be pushed to stack locations deep within the stack. We syntactically define sub-classes of NPSDSs by restricting the occurrences of pops, pushes and deep-pushes and capture the complexity classes NP and PSPACE. Furthermore, we show that all problems accepted by program schemes of NPSDSs are in EXPTIME.\\u","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65297.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/6255\/1\/6255.pdf","pdfHashValue":"9527a63a8f98ae36c682555517ef72d8af333bf6","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:6255<\/identifier><datestamp>\n      2011-12-06T09:33:24Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        On the power of deep pushdown stacks.<\/dc:title><dc:creator>\n        Arratia-Quesada, A.<\/dc:creator><dc:creator>\n        Stewart, I. A.<\/dc:creator><dc:description>\n        Inspired by recent work of Meduna on deep pushdown automata, we consider the computational power of a class of basic program schemes, NPSDSs, based around assignments, while-loops and non-deterministic guessing but with access to a deep pushdown stack which, apart from having the usual push and pop instructions, also has deep-push instructions which allow elements to be pushed to stack locations deep within the stack. We syntactically define sub-classes of NPSDSs by restricting the occurrences of pops, pushes and deep-pushes and capture the complexity classes NP and PSPACE. Furthermore, we show that all problems accepted by program schemes of NPSDSs are in EXPTIME.\\ud\n<\/dc:description><dc:subject>\n        Complexity theory<\/dc:subject><dc:subject>\n         Program schemes<\/dc:subject><dc:subject>\n         Stacks.<\/dc:subject><dc:publisher>\n        Springer<\/dc:publisher><dc:source>\n        Acta informatica, 2009, Vol.46(7), pp.509-531 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2009-11-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:6255<\/dc:identifier><dc:identifier>\n        issn:0001-5903<\/dc:identifier><dc:identifier>\n        issn: 1432-0525<\/dc:identifier><dc:identifier>\n        doi:10.1007\/s00236-009-0103-x<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6255\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1007\/s00236-009-0103-x<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6255\/1\/6255.pdf<\/dc:identifier><dc:rights>\n        The original publication is available at www.springerlink.com<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":[" 1432-0525","0001-5903","issn:0001-5903","issn: 1432-0525"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2009,"topics":["Complexity theory","Program schemes","Stacks."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n04 January 2010\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nArratia-Quesada, A. and Stewart, I. A. (2009) \u2019On the power of deep pushdown stacks.\u2019, Acta informatica., 46\n(7). pp. 509-531.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1007\/s00236-009-0103-x\nPublisher\u2019s copyright statement:\nThe original publication is available at www.springerlink.com\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n  \nDurham Research Online \n \nDeposited in DRO: \n04 January 2010 \n \nPeer-review status: \nPeer-reviewed \n \nPublication status: \nAccepted for publication version \n \nCitation for published item: \nArratia-Quesada, A. and Stewart, I. A. (2009) 'On the power of deep pushdown stacks.', Acta \ninfomatica., 46 (7). pp. 509-531. \n \nFurther information on publishers website: \nhttp:\/\/dx.doi.org\/10.1007\/s00236-009-0103-x \n \nPublisher\u2019s statement: \nThe original publication is available at www.springerlink.com \n \n \n \n \n \n \n \n \n \n \n \n \n \nUse policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior \npermission or charge, for personal research or study, educational, or not-for-profit purposes provided that : \n \n\uf0a7 a full bibliographic reference is made to the original source \n\uf0a7 a link is made to the metadata record in DRO \n\uf0a7 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders. \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nOn the power of deep pushdown stacks\u2217\nArgimiro Arratia Quesada\u2020\nDepartament de Llenguatges i Sistemes Informa`tics,\nUniversitat Polite`cnica de Catalunya, Barcelona, Spain\nIain A. Stewart\nDepartment of Computer Science, Durham University,\nScience Labs, South Road, Durham DH1 3LE, U.K.\nJuly 21, 2009\nAbstract\nInspired by recent work of Meduna on deep pushdown automata, we consider\nthe computational power of a class of basic program schemes, NPSDSs, based\naround assignments, while-loops and non-deterministic guessing but with access\nto a deep pushdown stack which, apart from having the usual push and pop\ninstructions, also has deep-push instructions which allow elements to be pushed\nto stack locations deep within the stack. We syntactically define sub-classes of\nNPSDSs by restricting the occurrences of pops, pushes and deep-pushes and\ncapture the complexity classes NP and PSPACE. Furthermore, we show that\nall problems accepted by program schemes of NPSDSs are in EXPTIME.\n1 Introduction\nIn automata theory, there is a variety of machine models, both restricting and en-\nhancing pushdown automata, such as finite-turn pushdown automata [7, 23] and two-\npushdown automata [13, 14] (the former accept a proper sub-class of the context-free\nlanguages and the latter are as powerful as Turing machines). However, rarely is there\na model based on modifications of pushdown automata capturing a class of languages\nlying between the classes of the context-free and the context-sensitive languages. In\nan attempt to remedy this situation, Meduna [15] recently introduced deep pushdown\nautomata and showed that these models coincide with Kasai\u2019s state grammars [11],\nand thus give rise to an infinite hierarchy of languages lying between the classes of the\ncontext-free and the context-sensitive languages. Meduna\u2019s deep pushdown automata\n\u2217An extended abstract of this paper appeared as A. Arratia-Quesada and I.A. Stewart, On the\npower of deep pushdown stacks, Proceedings of Computation and Logic in the Real World, Fourth\nConference on Computability in Europe (CiE 2008) (A. Beckmann, C. Dimitracopoulos, B. Lo\u00a8we,\neds.), Lecture Notes in Computer Science Vol. 5028, Springer, Berlin (2008) 11-21.\n\u2020Research partially supported by Spanish Government MICINN under Projects: SESAAME\n(TIN2008-06582-C03-02) and SINGACOM (MTM2007-64007). Formerly at Dept. Matema\u00b4tica Apli-\ncada, Universidad de Valladolid, Spain.\n1\npop and push items from and to their stack in the standard way; however, they also\nhave the facility to insert (but not read) strings at some position within the stack.\nInspired by Meduna\u2019s machine model, we consider in this paper the formulation\nof program schemes with access to a deep pushdown stack. Program schemes work\non arbitrary finite structures (rather than just strings) and are more computational\nin flavour than are formulae of logics studied in finite model theory and descriptive\ncomplexity, yet they remain amenable to logical manipulation. The concept of a\nprogram scheme originates from the 1970\u2019s with work of, for example, Constable\nand Gries, Friedman, and Hewitt and Paterson [2, 6, 16], and complexity-theoretic\nconsiderations of such program schemes were subsequently studied by, for example,\nHarel and Peleg, Jones and Muchnik, and Tiuryn and Urzyczyn [8, 10, 22].\nOf relevance to our work here is [1] where it was shown that a basic class of program\nschemes, in which there are assignments, while-loops and non-deterministic guessing,\nand which are augmented with access to a stack, where these program schemes work\non ordered data, is such that the class of problems accepted is P. This characterization\nshould be compared with Cook\u2019s result from [3] that a non-deterministic pushdown\nautomaton can be simulated by a deterministic pushdown automaton, with the class\nof languages accepted by such automata being P. Moreover, as with Cook\u2019s scenario,\nthe above program schemes can be simulated by (deterministic) program schemes in\nwhich guessing is not allowed. (There has also been a consideration of these program\nschemes on unordered data in [1, 20].) An interesting aspect of program schemes\nwith a stack is that there is potentially an unlimited amount of memory available\nto a computation (in the form of stack storage) yet (as the results of [1] show) the\nproblems accepted by such program schemes can all be solved in polynomial-time (on\na Turing machine; in fact, it appears that some problems in P require exponential\ntime when \u2018time\u2019 is defined to be the number of instructions executed by a program\nscheme with a stack that solves the problem [20]).\nAs mentioned above, in this paper it is our intention to consider the computational\npower of basic program schemes when augmented with a deep pushdown stack. A\ndeep pushdown stack is such that the usual pops and pushes are available, as well as\nan additional instruction which allows elements to be written to locations deep in the\nstack but only so that the depth at which such a location lies (from the top of the stack)\nis bounded by some polynomial in the size of the input structure; that is, deep-pushes\ncannot be to locations too deep within the stack. Note that we only have deep-pushes,\nnot deep-pops; for if we had both then we would have, essentially, access to a stack the\ntop (polynomial) portion of which could be used as an array (program schemes with\narrays have been considered in [19, 21]). Our goal is to classify the computational\npower of basic program schemes with deep pushdown stacks in comparison with the\nstandard complexity classes of computational complexity. Such complexity classes\nare all defined with regard to ordered data (more specifically, strings of symbols) and\nconsequently we always assume that our program schemes work on finite structures\naugmented with an ordering of the data (this statement will be made explicit in the\nsubsequent definitions).\nOf course, the results of [1] show that any problem in P can be accepted by some\nprogram scheme from our class of program schemes with access to a deep pushdown\nstack, which we call NPSDSs (non-deterministic program schemes with a deep push-\ndown stack). It turns out that we can (syntactically) define sub-classes of the class\n2\nof program schemes NPSDSs, obtained by restricting how the occurrences of pops,\npushes and deep-pushes are structured, capturing the complexity classes NP and\nPSPACE. Furthermore, we show that all problems accepted by program schemes of\nNPSDSs are in EXPTIME.\nLet us end this introduction by remarking that there do exist programming lan-\nguages with facilities for the manipulation of elements deep within a stack. One such\nis the programming language Push [17], specifically defined for use in genetic and evo-\nlutionary computational systems, where the instructions YANK and SHOVE allow\ndeep access to stack elements, by means of integer indices.\nOur basic definitions (relating to logic and program schemes) are given in Section 2\nbefore we consider some simple restrictions of our program schemes in Section 3. We\ncapture the complexity classNP with a sub-class of our program schemes in Section 4,\nand the complexity class PSPACE in Section 5. We show that any problem accepted\nby a program scheme of NPSDSs is in EXPTIME in Section 6, before presenting\nour conclusions and directions for further research in Section 7.\n2 Basic definitions\nThroughout, a signature \u03c4 is a tuple \u3008R1, . . . , Rr, C1, . . . , Cc\u3009, where each Ri is a\nrelation symbol, of arity ai, and each Cj is a constant symbol. A finite structureA over\nthe signature \u03c4 , or \u03c4-structure, consists of a universe or domain |A| = {0, 1, . . . , n\u22121},\nfor some natural number n \u2265 2, together with a relation Ri of arity ai over |A|, for\nevery relation symbol Ri of \u03c4 , and a constant Cj \u2208 |A|, for every constant symbol Cj\nof \u03c4 (by an abuse of notation, we do not distinguish between constants or relations and\nconstant or relation symbols). A finite structure A whose domain is {0, 1, . . . , n\u2212 1}\nhas size n, and we denote the size of A by |A| also (this abuse of notation does\nnot cause confusion). The set of all finite structures over the signature \u03c4 is denoted\nSTRUCT(\u03c4). A problem over some signature \u03c4 consists of a subset of STRUCT(\u03c4)\nwhich is closed under isomorphisms. Throughout, all our structures are finite. We\ninsist that the binary relation symbol succ and the two constant symbols 0 and max\nnever appear in any signature. The binary relation succ is only ever interpreted as a\nsuccessor relation, that is, as a relation of the form:\n{(u0, u1), (u1, u2), . . . , (un\u22122, un\u22121) : ui 6= uj , for i 6= j},\non some domain of size n, and 0 (resp. max) is only ever interpreted as the minimal\n(resp. maximal) element u0 (resp. un\u22121) of the successor relation succ.\nIn [1], a class of program schemes based around the usage of a stack was defined.\nA program scheme \u03c1 \u2208 NPSSs involves a finite set {x1, x2, . . . , xk} of variables , for\nsome k \u2265 1, and is over a signature \u03c4 . It consists of a finite sequence of instructions\nwhere each instruction is one of the following:\n\u2022 an assignment instruction of the form xi := y, where i \u2208 {1, 2, . . . , k} and\nwhere y is a variable from {x1, x2, . . . , xk}, a constant symbol of \u03c4 or one of the\nspecial constant symbols 0 and max (which do not appear in any signature);\n\u2022 a guess instruction of the form guess xi, where i \u2208 {1, 2, . . . , k} (execution of\nthe instruction guess xi non-deterministically assigns an element of |A| to the\nvariable xi);\n3\n\u2022 a while instruction of the form while \u03d5 do \u03b11; \u03b12; . . .; \u03b1q; od, where \u03d5 is\na quantifier-free formula over \u03c4 \u222a \u3008succ, 0,max\u3009 whose free variables are from\n{x1, x2, . . . , xk} and where each of \u03b11, \u03b12, . . . , \u03b1q is another instruction of one\nof the forms given here (note that there may be nested while instructions);\n\u2022 a push instruction of the form push xi, where i \u2208 {1, 2, . . . , k};\n\u2022 a pop instruction of the form xi := pop, where i \u2208 {1, 2, . . . , k};\n\u2022 an accept (resp. a reject) instruction accept (resp. reject).\nA program scheme \u03c1 \u2208 NPSSs over \u03c4 takes a \u03c4 -structure A as input. The program\nscheme \u03c1 computes on A in the obvious way except that:\n\u2022 the binary relation succ is taken to be any successor relation on |A|, and 0 (resp.\nmax) is the minimal (resp. maximal) element of this successor relation;\n\u2022 initially, every variable takes the value 0;\n\u2022 the pop and push instructions provide access to a stack which is initially empty;\nAn input \u03c4 -structure A, together with a chosen successor relation succ, is accepted\nby \u03c1 if there is at least one computation of \u03c1 on input A (and with regard to the\nchosen successor relation) leading to an accept instruction (if ever a pop of an empty\nstack is attempted in some computation then that computation is deemed rejecting).\nHowever, we only consider program schemes \u03c1 of NPSSs that are successor-invariant,\nwhere successor-invariant means that every input structure is either accepted no mat-\nter which successor relation is chosen or rejected no matter which successor relation is\nchosen. Such successor-invariant program schemes accept classes of structures closed\nunder isomorphisms, i.e., problems. Henceforth, we assume that all our program\nschemes are successor-invariant, and we equate (a class of) program schemes with the\n(class of) problems they accept.\nRemark 1 In finite model theory, the way a \u2018built-in\u2019 successor relation is incorpo-\nrated into a logic is exactly as we incorporate our successor relation into our program\nschemes. Essentially, having a built-in successor relation means that our data is or-\ndered (as is the case for most standard models of computation). In order to work with\nunordered data, as one does in database theory, for example, one simply omits the\ninclusion of any such built-in successor relation in one\u2019s logic. We insist that our data\nis ordered as we are interested in the computational power of our devices in relation\nto other resource-bounded models of computation (such as Turing machines, which\nwork on ordered data). The reader is referred to, for example, [5, 9, 12] for more on\nbuilt-in (successor) relations.\nRemark 2 In [1], the class of program schemes NPSSs as defined above was actually\ncalled NPSSs(1) and was the first class in an infinite hierarchy of classes of program\nschemes, the union of which was called NPSSs. However, it was shown that (in the\npresence of a built-in successor relation) this infinite hierarchy collapses to the first\nclass, NPSSs(1), and that the resulting class of program schemes accepts exactly the\nclass of polynomial-time solvable problems P; so, we omit the suffix \u2018(1)\u2019 for simplicity.\n4\nThere are also one or two purely cosmetic differences between the program schemes\nof NPSSs(1) in [1] and the program schemes of NPSSs in this paper that are of no\nrelevance whatsoever.\nWe extend our class of program schemes NPSSs to the class of program schemes\nNPSDSs by allowing deep-push instructions:\n\u2022 a deep-push instruction is of the form dpush(y,z), where y, the index , is a\ntuple of variables from {x1, x2, . . . , xk} and constant symbols from \u03c4 \u222a \u30080,max\u3009\n(with repetitions allowed) and where z is a variable from {x1, x2, . . . , xk} or a\nconstant symbol from \u03c4 \u222a \u30080,max\u3009\n(we assume that the variables appearing in our program scheme are x1, x2, . . . , xk).\nSuppose that \u03c1 is some program scheme with deep-push instructions and that A,\nof size n, is input to \u03c1, with associated successor relation succ (and constants 0 and\nmax). Suppose that dpush(y,z) is a deep-push instruction appearing in \u03c1, where y\nis an m-tuple. The m-tuples of |A|m are ordered lexicographically as\n(0, 0, . . . , 0), (0, 0, . . . , u1), (0, 0, . . . , u2), . . . , (max,max, . . . ,max),\nwhere 0, u1, u2, . . . ,max is the linear order encoded within the successor relation succ.\nAssociate these m-tuples with the integers 0, 1, . . . , nm \u2212 1, respectively. Denote the\ninteger associated with the tuple u as \u266fu, and denote the tuple of values associated\nwith the integer i \u2208 {0, 1, . . . , nm \u2212 1} as i\u266f. When the instruction dpush(y,z) is\nexecuted, the variables of y each hold a value from |A|; so, \u266fy \u2208 {0, 1, . . . , nm \u2212 1}.\nThe instruction dpush(y,z) pushes the value of z to the stack location \u266fy (the offset)\nfrom the top of the stack, with the top of the stack being the location 0 from the top\nof the stack, the next location down being the location 1 from the top of the stack and\nso on; in particular, the deep-push overwrites the value in the stack location \u266fy with\nthe value of z. Thus, the instruction has access to the top nm locations of the stack\nfor pushing but not for popping. Only pops of the top element of the stack are allowed\n(in the usual way). If ever a deep-push attempts to push a value to some location\nbelow the bottom location of the stack then that particular computation is deemed\nrejecting. As usual, we only ever work with successor-invariant program schemes of\nNPSDSs. The evolution of the stack according to the instruction dpush((y1, y2),z),\nwhere y1 = 1, y2 = 7 and z = v, for some value v, can be visualized as in Fig. 1.\nLet us illustrate deep-pushes with an example. However, before we do so, let us\nintroduce some syntactic sugar. First, we employ the usual if-then-else instructions\ndirectly, as such instructions can easily be constructed using while instructions. Sec-\nond, in describing our program schemes we use a convenient shorthand in relation to\nthe offsets and indices in deep-push instructions. According to our syntax, the offset\nof a deep-push instruction is given via a tuple of variables, the index, with the offset\nvalue calculated according to the successor relation accompanying an input structure.\nRather than include routine \u2018house-keeping\u2019 code, we allow ourselves to describe offset\nvalues in an integer-style. For example, suppose that we wished to use an offset of\n2n\u22122 in a deep-push instruction (where n is the size of the input structure). Strictly\nspeaking, we should use a pair of variables, (x1, x2), and include the following portion\nof code:\n5\nstack before\ndeep-push\n...\nstack after\ndeep-push\n...\nu0\nu1\nun-1\nun\nun+1\nun+7\nun+8\n......\n...\n...\nu0\nu1\nun-1\nun\nun+1\nun+8\nv\ndpush((y  , y  ), z)\nwhen \n y  = 1\n y  = 7\n z = v\n1 2\n1\n2\nun+6 un+6\nFigure 1. The execution of a deep-push.\nguess z; \u2217\u2217 guess z until the value is that \u2217\u2217\nwhile \u00acsucc(x1, z) do \u2217\u2217 of 1 \u2217\u2217\nguess z;\nod;\nx1 := z; \u2217\u2217 make x1 equal to 1 \u2217\u2217\nguess z; \u2217\u2217 guess z until the value is that \u2217\u2217\nwhile \u00acsucc(z,max) do \u2217\u2217 of n\u2212 2 \u2217\u2217\nguess z;\nod;\nx2 := z; \u2217\u2217 make x2 equal to n\u2212 2 \u2217\u2217\ndpush((x1,x2),y);\nHowever, we abbreviate the above with the instruction:\ndpush((2n - 2)\u266f,y);\nIn general, if i is any positive integer then we write i\u266f to denote a tuple of variables (of\nthe required length) encoding the offset of value i. All of the integer offsets appearing\nin our program schemes are such that they can easily be computed with an appropriate\nportion of code. Thus, for example, the instruction:\ndpush(((n - \u266fcount) + \u266fy)\u266f,y);\nis shorthand for a portion of code which builds values for a tuple of 2 variables which\nencodes an integer equal to nminus the integer currently encoded by the current value\nof the variable count plus the integer encoded by the current value of the variable\ny. We also use the above shorthand in assignments, e.g., (count, y) := (\u266f(count, y)\n+ 1)\u266f. Furthermore, we abuse our notation by writing, for example, count := 2n\u266f\nor while \u266fx < 2n\u2212 1 do, where what we should really write is (count1, count2) :=\n2n\u266f and while \u266f(x1, x2) < 2n\u2212 1. (As can be seen, we often use names for variables\ndifferent to x1, x2, . . .)\nExample 3 Consider the following program scheme \u03c1 of NPSDSs over the signature\n\u03c4 = \u3008E,C,D\u3009, where E is a binary relation symbol and C and D are constant symbols\n(so, an input structure can be considered as a digraph with two specified vertices):\n6\n1 guess w; \u2217\u2217 push some 0\u2019s onto the stack \u2217\u2217\n2 while w = 0 do\n3 push 0;\n4 guess w;\n5 od;\n6 count := 0; \u2217\u2217 count counts the number of guessed \u2217\u2217\n7 dpush(count,C); \u2217\u2217 vertices in a path making sure that \u2217\u2217\n8 dpush((n + \u266fC)\u266f,max); \u2217\u2217 n are guessed and registered \u2217\u2217\n9 while count 6= max do\n10 count := (\u266fcount + 1)\u266f;\n11 guess x;\n12 dpush(count,x);\n13 dpush((n + \u266fx)\u266f,max);\n14 od;\n15 count := 0; \u2217\u2217 count counts the number of vertices \u2217\u2217\n16 x := pop; \u2217\u2217 popped when checking the validity \u2217\u2217\n17 while count 6= max do \u2217\u2217 of the guessed path \u2217\u2217\n18 count := (\u266fcount + 1)\u266f;\n19 y := pop;\n20 if \u00acE(x, y) then reject; fi;\n21 x := y;\n22 od;\n23 if x 6= D then reject; fi;\n24 count := 0; \u2217\u2217 count counts the number of vertex \u2217\u2217\n25 w := pop; \u2217\u2217 registrations checked so far \u2217\u2217\n26 if w 6= max then reject; fi;\n27 while count 6= max do\n28 count := (\u266fcount + 1)\u266f;\n29 w := pop;\n30 if w 6= max then reject; fi;\n31 od;\n32 accept;\nEssentially, on an input digraph of size n, \u03c1 begins by building a stack of 0s, in lines\n1-5. In lines 6-14, a path of n vertices is guessed, starting with vertex C, and (using\ndeep-pushes) these vertices are stored in order in the top n locations in the stack\n(with C in the top location, the next vertex in the location with offset 1, and so\non). When a vertex u is guessed, this is registered by deep-pushing max to the stack\nlocation with offset n+\u266fu. After this guessing phase, in lines 15-23 the path is popped\nfrom the stack and checked as to whether it is a valid path (ending in D). If so then\nthe registrations are then checked, in lines 24-32, to confirm that all vertices appear\nonce on the path. Hence, an input structure is accepted by \u03c1 if, and only if, C 6= D\nand there is a Hamiltonian path from vertex C to vertex D. Note that the program\nscheme \u03c1 is successor-invariant.\nLet us close this section with a remark. Given our wish to augment basic program\nschemes with a deep pushdown stack, we need some mechanism for our program\nschemes to access locations within the stack. Working with ordered data and using\n7\nthe built-in successor relation and tuples of variables for constructing numeric offsets\ngives us this mechanism. This naturally gives us the limitation that deep-pushes can\nonly be \u2018polynomially-deep\u2019. An alternative would be to drop the built-in successor\nrelation and introduce an additional domain of numeric values and have variables of\ntwo sorts. We have chosen to work on ordered data as this is the norm in descriptive\ncomplexity.\n3 Sub-classes of program schemes\nWe begin by showing that restricting the values pushed by push and deep-push in-\nstructions to 0 andmax does not limit the problems accepted by our program schemes;\nwe call such program schemes boolean program schemes. Let us denote the class of\nprogram schemes where push instructions must be of the form push 0 or push max\nand where deep-push instructions must be of the form dpush(y,0) or dpush(y,max)\nby NPSDSbs (with the superscript b reflecting the boolean nature of such program\nschemes).\nProposition 4 Any problem accepted by a program scheme of NPSDSs can be ac-\ncepted by a program scheme of NPSDSbs.\nProof Let \u03c1 be a program scheme of NPSDSs. Essentially, we simulate the stack in\na computation of \u03c1 on some input of size n with a stack in a computation of a new\nprogram scheme \u03c1\u2032 so that n locations of the new stack correspond to 1 location of\nthe old stack. The values of the n stack locations of the new stack corresponding to\nthe 1 stack location of the old stack are such that all are 0 except for one which is\nmax and the stack location that is max is the ith in the batch of n stack locations\nif, and only if, the value of the corresponding old stack location is ui, where ui is\nthe ith smallest element in the ordering given by the successor relation succ. The\ninstructions of \u03c1 are adapted accordingly to obtain our program scheme \u03c1\u2032.\nSo, for example, push x in \u03c1 is simulated by:\nx\u2032 := 0;\nwhile x\u2032 6= x do\npush 0;\nx\u2032 := (\u266fx\u2032 + 1)\u266f;\nod;\npush max;\nwhile x\u2032 6= max do\npush 0;\nx\u2032 := (\u266fx\u2032 + 1)\u266f;\nod;\nThe instruction x := pop in \u03c1 is simulated by:\nx\u2032 := 0;\nx := pop;\nwhile x 6= max do\nx\u2032 := (\u266fx\u2032 + 1)\u266f;\n8\nx := pop;\nod;\nx := x\u2032;\nwhile x\u2032 6= max do\nx\u2032 := (\u266fx\u2032 + 1)\u266f;\ny := pop;\nod;\nThe instruction dpush(y,x) in \u03c1 is simulated by:\ny\u2032 := 0;\nwhile y\u2032 6= x do\ndpush((y,y\u2032),0);\ny\u2032 := (\u266fy\u2032 + 1)\u266f;\nod;\ndpush((y,y\u2032),max);\nwhile y\u2032 6= max do\ndpush((y,y\u2032),0);\ny\u2032 := (\u266fy\u2032 + 1)\u266f;\nod;\nNote how the length of the index tuple has increased by 1 in our simulation of the\ninstruction dpush(y,x). All other instructions in \u03c1 remain unaltered. It is clear that\nthe resulting program scheme \u03c1\u2032 is as required.\nWe also restrict the syntax of program schemes of NPSDSs (and NPSDS\nb\ns) by\nlimiting the usage of pops, pushes and deep-pushes in phases of a program scheme. A\nbatch of instructions is a well-formed sequence of instructions so that if one of these\ninstructions is a while-do instruction (resp. if instruction) then the corresponding\nwhile-od instruction (resp. fi instruction) must also appear in the batch. Let \u03c1 be a\nprogram scheme of NPSDSs. If \u03c1 can be written (as a concatenation of instructions)\nas a batch of instructions \u03c10, followed by a batch of instructions \u03c11, and so on,\nfinally ending with a batch of instructions \u03c1k, then we write \u03c1 = (\u03c10, \u03c11, . . . , \u03c1k). The\nallowed usage of pops, pushes and deep-pushes in any batch of instructions is signalled\nas follows:\n\u2022 if pops are allowed (resp. disallowed) then we signal this with o (resp. o);\n\u2022 if pushes are allowed (resp. disallowed) then we signal this with u (resp. u);\n\u2022 if deep-pushes are allowed (resp. disallowed) then we signal this with d (resp.\nd).\nThus, if pops and pushes are allowed in some batch of instructions \u03c1i, but not deep-\npushes, then we write \u03c1i \u2208 NPSDSs(oud). We adapt our notation to situations where\na program scheme is the concatenation of a sequence of batches of instructions by de-\ntailing the allowed usage of pops, pushes and deep-pushes in each batch by a sequence\nof parameters. So, for example, if \u03c1 = (\u03c10, \u03c11, \u03c12) where \u03c10 \u2208 NPSDSs(oud), \u03c11 \u2208\nNPSDSs(oud) and \u03c12 \u2208 NPSDSs(oud), then we write \u03c1 \u2208 NPSDSs(oud, oud, oud).\nThe above applies equally to program schemes of NPSDSbs.\n9\nNote that the proof of Proposition 4 does not alter the interleaving of pops, pushes\nand deep-pushes in the simulating program scheme. So, for example, the problem\naccepted by some program scheme of NPSDSs(oud, oud, oud) can be accepted by\nsome program scheme of NPSDSbs(oud, oud, oud).\n4 Capturing NP\nIn this section, we define a sub-class of program schemes of NPSDSs that captures\nexactly the complexity class NP.\nProposition 5 Every program scheme \u03c1 = (\u03c10, \u03c11, \u03c12) in NPSDSs(oud, oud, oud)\naccepts a problem in NP.\nProof Let \u03c1 = (\u03c10, \u03c11, \u03c12) be a program scheme of NPSDSs(oud, oud, oud) over \u03c4 .\nThus, \u03c10 and \u03c12 do not contain deep-pushes, and \u03c11 contains neither pushes nor pops.\nWe begin by deriving a program scheme \u03c1\u2032 of NPSSs from \u03c1. Essentially, the program\nscheme \u03c1\u2032 will simulate \u03c1 except that we shall replace the computation of \u03c11 with an\n\u2018oracle\u2019 and amend \u03c12 accordingly. However, because of subtleties with our simulation\n(as we shall detail soon), we also need to amend \u03c10 too.\nLet us begin by looking at the structure of a computation of \u03c1 on some input\nstructure of size n. The program scheme \u03c10 builds, using pops and pushes, a stack,\nthe height of which will, in general, vary until \u03c10 terminates. At this point, the\nprogram scheme \u03c11 begins computing and goes on to, in general, perform some deep-\npushes, with an offset of at most nk \u2212 1, for some k. Note that the height of the\nstack does not change throughout the computation of \u03c11. When \u03c11 terminates, the\nprogram scheme \u03c12 begins computing and, due to pops and pushes, the height of the\nstack, in general, varies.\nWhat we intend to do is to \u2018remove\u2019 the computation of \u03c11 from \u03c1 and replace\nit with an \u2018oracle\u2019 which supplies both the locations to which deep-pushes are made\nand the values pushed, and also the values of the variables of \u03c1 on termination of\n\u03c11. We will then amend \u03c12 so that when a pop is made of an element from the stack\nwhich might have potentially been altered by a deep-push, we consult our oracle to see\nwhether there was indeed a deep-push to this location. If there was then we take the\npopped value as the value pushed, otherwise we leave the popped value as whatever\nwas popped. We shall return to how we obtain our oracle later.\nOne can immediately see that we need to amend \u03c12 so that we keep track of the n\nk\nstack locations into which deep-pushes might have occurred. However, it may be the\ncase that \u03c12 amends the stack through popping and pushing, and this complicates\nmatters. The obvious solution is for us to maintain a \u2018counter\u2019 which keeps track\nof the highest location in the (current) stack within which a deep-push might have\noccurred (as an offset from the top of the current stack), and also the offset from this\nlocation covering all stack locations (downwards) within which a deep-push might\nhave occurred; that is, two offsets detailing the portion of the current stack into\nwhich any deep-pushes have been made. However, any counter can have a maximum\nvalue of nm, for some fixed m, and (potentially) \u03c12 might increase the height of the\nstack by an exponential (in n) number. Thus, it does not appear that we can use a\ncounter or counters to keep track of the portion of the stack as described above. The\n10\nsituation can be visualized as in Fig. 2, where the evolution of the stack during the\nexecution of \u03c12 is depicted, with the shaded portion of the stack corresponding to the\nlocations within which a deep-push might have occurred. In the right-hand stack, if\nwe keep a counter telling us how far the top shaded location (in which the value vr\nresides) is from the top of the stack then this value could be greater than nm (even\nexponential in n).\n...\n...\nstack prior \nto execution \nof \u03c12\nv0\nv1\nvn  \u22121k\nvn  k\nvn  +1k\n...\nstack during \nexecution \nof \u03c12\nvn  \u22121k\nvn  k\nvn  +1k\n...\nvr\nvr+1\n...\nstack during \nexecution \nof \u03c12\nvn  \u22121k\nvn  k\nvn  +1k\n...\nvr\nvr+1\n...\nu0\nu1\nus\nFigure 2. The evolution of the stack.\nWe get round the above difficulty by changing completely how data is stored on the\nstack. First, we rewrite \u03c1 so that every push or pop is replaced by a pair of pushes or\npops, and every deep-push is replaced by a single deep-push. In particular: we replace\nthe instruction push xi with the two instructions push xi; push 0; we replace the\ndeep-push instruction dpush(x,y) with the instruction dpush(x\u2032,y), where \u266fx\u2032 =\n2 \u00b7 \u266fx + 1; and we replace the instruction x := pop with the two instructions x :=\npop; x := pop. Note that we need to increase the index of deep-pushes to cater\nfor the increased size of stack. So, it appears that we are wasting stack locations;\nhowever, we will use the stack locations in which (seemingly redundant) 0\u2019s have\nbeen pushed as locations within which markers are held (where a marker is the value\nmax). Denote this amended version of \u03c1 = (\u03c10, \u03c11, \u03c12) by \u03c1\u02dc = (\u03c1\u02dc0, \u03c1\u02dc1, \u03c1\u02dc2).\nNow let us return to how we amend \u03c1\u02dc2 so that we can ascertain whether a stack\nlocation is a location within which a deep-push might have occurred. The first thing\nour amended version of \u03c1\u02dc2, call it \u03c1\n\u2032\n2, does is to pop the top element from the stack\nand then push onto the stack the value max. This marks the \u2018top\u2019 of the portion of\nthe stack within which a deep-push might have a occurred (that is, with reference to\nFig. 2, the highest shaded location). We also set a counter, call it the tuple of variables\ny, so that \u266fy = 0. This counter will denote the distance of the current marked stack\nlocation from the initial marked stack location; of course, as some of the values in\nthese \u2018shaded\u2019 locations are popped from the stack during an execution of \u03c1\u20322, the value\nof \u266fy will increase. So, again with reference to the right-hand stack of Fig. 2, at this\npoint \u266fy will be r to denote that r elements of the original \u2018shaded\u2019 portion of the stack\nhave been popped (as can be seen from the diagram, other elements have since been\n11\npushed onto the stack). Note that the value of \u266fy should be between 0 and 2nk \u2212 2,\nand so we never have any difficulties with this counter becoming too large (of course,\nif \u266fy assumes a value greater than 2nk \u2212 2 then this means that we have popped all\nvalues in the original \u2018shaded\u2019 locations from the stack into which a deep-push might\nhave occurred and we can stop worrying about deep-push information).\nWe also amend \u03c1\u20322 so that we replace every pair of pops xi := pop; xi := pop\n(recall, all pops come in pairs in \u03c1\u02dc2, apart from the initial pop added above) with the\nfollowing sequence of instructions:\nz := pop;\nxi := pop; (\u2217)\nif z = max then\nif \u266fy 6= 2nk then\nz := pop;\npush max;\ny := (\u266fy + 2)\u266f;\nfi;\nfi;\nIt should be clear that \u03c1\u20322 keeps track of the current stack locations within which a\ndeep-push might have occurred (during an execution of \u03c1\u02dc1).\nNow for our \u2018oracle\u2019 containing information as regards the computation of \u03c1\u02dc1. Let\nR (resp. T ) be a relation symbol (not in \u03c4) of arity (resp. one plus) the maximal\nindex, m\u2032, of any deep-push instruction in \u03c1\u02dc (recall that this index is one more than\nthe maximal index of any deep-push instruction in \u03c1). In every (new) portion of code\ncorresponding to a pair of pops, as laid out in the previous paragraph, replace the\npop in line (\u2217) with the instructions:\nxi := pop;\nif \u266fy 6= 2nk then\nw := (\u266fy + 1)\u266f;\nif R(w) then\nguess z;\nif T (w, z) holds then\nxi := z;\nelse\nreject;\nfi;\nfi;\nfi;\nThe intention is that R and T will detail the deep-push locations and the values\npushed in a specific computation of \u03c1\u02dc1 via: for every u \u2208 |A|\nm\u2032+1, R(u) holds if, and\nonly if, a deep-push occurs to the \u2018shaded\u2019 location indexed by u, and if there is a\ndeep-push to location u then T (u, v) holds if, and only if, the final value deep-pushed\nto this location is v (note that there may be multiple deep-pushes to some stack\nlocation in a computation).\nNow amend the program scheme \u03c1\u02dc1 so that all deep-push instructions are simply\nomitted, and denote this amended program scheme by \u03c1\u20321. Note that \u03c1\n\u2032\n1 \u2208 NPSSs;\n12\nin fact, \u03c1\u20321 \u2208 NPSs, the sub-class of program schemes with no stack. Let A be any\n\u03c4 -structure that is accepted by \u03c1\u02dc and suppose that the relations RA and TA are\nsuch that they detail exactly the locations where the deep-pushes were made and the\nvalues deep-pushed (during \u03c1\u02dc1) during a particular accepting execution of \u03c1\u02dc. Then\n(A, RA, TA) is accepted by the program scheme (\u03c1\u02dc0, \u03c1\n\u2032\n1, \u03c1\n\u2032\n2).\nLet us go further and omit the computation of \u03c1\u20321. In more detail, let x denote\nthe t-tuple of all variables appearing in \u03c1\u02dc0 and \u03c1\n\u2032\n1, and let c = (c1, c2, . . . , ct) and\nd = (d1, d2, . . . , dt) be t-tuples of new and distinct constant symbols. Define \u03c1\n\u2032 to be\nthe following program scheme of NPSSs:\n\u03c1\u02dc0\nif x 6= c then\nreject;\nfi;\nx := d;\n\u03c1\u20322\nLet A be any \u03c4 -structure that is accepted by \u03c1\u02dc and suppose that in a particular\naccepting computation: c details the values of the variables of x immediately after\ntermination of \u03c1\u02dc0; d details the values of the variables of x immediately after ter-\nmination of \u03c1\u20321; and the relations R\nA and TA are such that they detail exactly the\nlocations where the deep-pushes were made and values deep-pushed (during \u03c1\u02dc1) dur-\ning the execution of \u03c1\u02dc. Then (A, RA, TA, c,d) is accepted by the program scheme\n\u03c1\u2032.\nConsider the following algorithm, where the input is a \u03c4 -structure A and where\nR0 (resp. T0) is a relation of arity that of R (resp. T ) (and into which elements can\nbe inserted):\nguess a successor relation succ;\nguess relations RA and TA over |A| and tuples of constants\nc and d from |A|;\nif (A, RA, TA, c,d) 6|= \u03c1\u2032 then\nreject;\nelse\nsimulate \u03c1\u20321 on A with the variables starting with the values\ngiven by c and store all stack locations to which a deep-push\nwas made and the final values deep-pushed using RA0 and T\nA\n0 ;\nif the execution of \u03c1\u20321 does not end with the values of the\nvariables given by d then\nreject;\nelse\nif RA0 6= R\nA or TA0 6= T\nA then\nreject;\nelse\naccept;\nWe clearly have that A |= \u03c1\u02dc if, and only if, A is accepted by the above algorithm.\nMoreover, the above algorithm is a non-deterministic polynomial-time algorithm, as\n\u03c1\u2032 \u2208 NPSSs and \u03c1\n\u2032\n1 \u2208 NPSs; hence, the result follows.\n13\nDenote by NPSDS+bs the sub-class of program schemes of NPSDS\nb\ns where any\ninstruction involving a deep-push must be of the form dpush(y,max); that is, only\nthe value max can be deep-pushed to a stack location. We can use our program\nscheme for the problem HP in Example 3 to show that the class of program schemes\nNPSDS+bs (oud, oud, oud) actually contains NP.\nProposition 6 For every problem \u2126 in NP, there exists a program scheme of\nNPSDS+bs (oud, oud, oud) accepting \u2126.\nProof Recall from [4, 18] that any problem in NP, over the signature \u03c4 , say, can\nbe described by a sentence \u03a6 of the form:\nHP[\u03bbx,y\u03d5(x,y)](0,max),\nwhere: x and y arem-tuples of variables, for somem \u2265 1, with all variables distinct; \u03d5\nis a quantifier-free formula over \u03c4 \u222a \u3008succ, 0,max\u3009; and 0 (resp. max) is the constant\nsymbol 0 (resp. max) repeated m times. A \u03c4 -structure A satisfies \u03a6 if, when we\nbuild the digraph \u03d5(A) with vertex set |A|m and where there is an edge (u,v) if, and\nonly if, \u03d5A(u,v) holds, there is a Hamiltonian path in \u03d5(A) from the vertex 0 to the\nvertex max (we assume that there is a built-in successor relation).\nGiven our program scheme \u03c1 in Example 3, we begin by amending \u03c1 so that\nit is a program scheme of NPSDS+bs (oud, oud, oud). This means dealing with the\ninstructions in lines 7 and 12 where a value different frommax might be deep-pushed.\nReplace the instruction in line 7 with:\nz := 0;\nwhile z 6= C do\nz := (\u266fz + 1)\u266f;\nod;\ndpush((count,z),max);\nand the instruction in line 12 with identical code except that C is replaced by x. Also,\nreplace the instruction in line 8 with:\ndpush((n2 + \u266fC)\u266f,max);\nand the instruction in line 13 with identical code except that C is replaced by x.\nReplace the instruction in line 16 with:\nz := 0;\nw := pop;\nwhile w 6= max do\nz := (\u266fz + 1)\u266f;\nw := pop;\nod;\nx := z;\nwhile z 6= max do\nz := (\u266fz + 1)\u266f;\nw := pop;\nod;\n14\nand the instruction in line 19 with analogous code. The resulting program scheme \u03c1\u2032\nof NPSDS+bs (oud, oud, oud) is as follows, with the line numbering mirroring that of\nthe program scheme \u03c1 of Example 3:\n1 guess w;\n2 while w = 0 do\n3 push 0;\n4 guess w;\n5 od;\n6 count := 0;\n7.1 z := 0;\n7.2 while z 6= C do\n7.3 z := (\u266fz + 1)\u266f;\n7.4 od;\n7.5 dpush((count,z),max);\n8.1 dpush((n2 + \u266fC)\u266f,max);\n9 while count 6= max do\n10 count := (\u266fcount + 1)\u266f;\n11 guess x;\n12.1 z := 0;\n12.2 while z 6= x do\n12.3 z := (\u266fz + 1)\u266f;\n12.4 od;\n12.5 dpush((count,z),max);\n13.1 dpush((n2 + \u266fx)\u266f,max);\n14 od;\n15 count := 0;\n16.1 z := 0;\n16.2 w := pop;\n16.3 while w 6= max do\n16.4 z := (\u266fz + 1)\u266f;\n16.5 w := pop;\n16.6 od;\n16.7 x := z;\n16.8 while z 6= max do\n16.9 z := (\u266fz + 1)\u266f;\n16.a w := pop;\n16.b od;\n17 while count 6= max do\n18 count := (\u266fcount + 1)\u266f;\n19.1 z := 0;\n19.2 w := pop;\n19.3 while w 6= max do\n19.4 z := (\u266fz + 1)\u266f;\n19.5 w := pop;\n19.6 od;\n19.7 y := z;\n19.8 while z 6= max do\n15\n19.9 z := (\u266fz + 1)\u266f;\n19.a w := pop;\n19.b od;\n20 if \u00acE(x, y) then reject; fi;\n21 x := y;\n22 od;\n23 if x 6= D then reject; fi;\n24 count := 0;\n25 w := pop;\n26 if w 6= max then reject; fi;\n27 while count 6= max do\n28 count := (\u266fcount + 1)\u266f;\n29 w := pop;\n30 if w 6= max then reject; fi;\n31 od;\n32 accept;\nand \u03c1\u2032 accepts the same problem as that accepted by \u03c1.\nWe now amend \u03c1\u2032 so that it accepts the problem described by the sentence \u03a6.\nEssentially, all we need to do is to: replace the variables count, z, x and y with the\nm-tuples of variables count, z, x and y, respectively (we leave the variable w as it\nis); replace the n2 in lines 8.1 and 13.1 with nm+1; replace the constant symbol C\nwith the m-tuple 0, and the constant symbol D with the m-tuple max; and replace\nthe test E(x, y) with the test \u03d5(x,y) (of course, an instruction such as count := 0\nbecomes count1 := 0; count2 := 0; . . .; countm := 0, and so on). Having done\nthis, the new program scheme accepts the problem described by \u03a6 and the result\nfollows.\nPropositions 5 and 6 immediately yield the following corollary.\nCorollary 7 NPSDS+bs (oud, oud, oud) = NPSDSs(oud, oud, oud) =NP.\n5 Capturing PSPACE\nIn this section, we define a sub-class of program schemes of NPSDSs capturing the\ncomplexity class PSPACE. However, before we do this let us demonstrate the power\nof program schemes of NPSDSs and exhibit a program scheme accepting the comple-\nment of the problem in Example 3.\nExample 8 Let \u03c4 = \u3008E,C,D\u3009, with E a relation symbol of arity 2 and C and D\nconstant symbols. The problem co-HP is defined as\n{A : A is a \u03c4 -structure and there is not a Hamiltonian path in the digraph\nwith edges given by the relation EA from vertex CA to vertex DA}.\nWe shall exhibit a program scheme \u03c1 of NPSDSs accepting co-HP.\nWe outline what the program scheme \u03c1 that accepts co-HP does, in an intuitive\nsense, before presenting the actual program scheme in detail. The program scheme\n16\n\u03c1 begins by simply non-deterministically building a \u2018sufficiently tall\u2019 stack of 0\u2019s (in\nactuality, this stack should have height at least 2nn). The top n elements of the stack\n(the \u2018top batch\u2019) are regarded as the current potential Hamiltonian path of vertices in\nthe input digraph; initially, of course, this path is 0, 0, . . . , 0. The next n elements of\nthe stack (the \u2018middle batch\u2019) are regarded as work-space that will enable us to verify\nthat there are no repeated vertices in the current path. The next n elements of the\nstack (the \u2018lower batch\u2019) will be such that they will contain the lexicographically-next\npotential Hamiltonian path.\nThe top element (of the top batch) is popped from the stack and, using a deep-\npush, the name of this vertex, u, say, is registered in location \u266fu of the middle batch\nby writing max (note that the top batch of elements now consists of n\u2212 1 elements).\nA check is also made to verify that u is, in fact, the constant C. We iteratively pop\nelements from the stack and verify that the current path is indeed a path in our input\ndigraph, registering these elements, as above, as we proceed. Also, alongside our\nchecking of the current potential Hamiltonian path, we build the lexicographically-\nnext path in the lower batch of stack elements. Essentially, as we pop the vertices of\nthe current path from the top batch of the stack, we look for the location place that\nholds an element that is not equal to max but where every location in the top batch\nlower than this location place holds an element equal to max; the element in this\nlocation place is to be incremented by 1 and all elements in the top-batch at lower\nlocations are to be set to 0 to get the lexicographically-next potential Hamiltonian\npath. This is done, using deep-pushes, so that the lexicographically-next path appears\nin the lower batch. Having popped all the vertices of the current path from the\nstack, we verify that the last element popped was D and we use our registrations to\nverify that the path is indeed Hamiltonian. If not then we proceed as above except\nthat what was the lower batch is now the top batch and we are working with the\nlexicographically-next potential Hamiltonian path, as our current path.\nThe program scheme \u03c1 implementing the above procedure follows.\n1 guess x; \u2217\u2217 fill the stack with 0\u2019s \u2217\u2217\n2 while x = 0 do\n3 push x;\n4 guess x;\n5 od;\n6 done := 0; \u2217\u2217 done = 0 denotes we haven\u2019t finished \u2217\u2217\n7 while done = 0 do \u2217\u2217 checking all paths \u2217\u2217\n8 done := max;\n9 bad path := 0; \u2217\u2217 bad path = 0 means that the path is still \u2217\u2217\n10 x := pop; \u2217\u2217 potentially good \u2217\u2217\n11 count := 1\u266f; \u2217\u2217 count counts the vertices popped \u2217\u2217\n12 dpush(((n - \u266fcount) + \u266fx)\u266f,max); \u2217\u2217 register x in the \u2217\u2217\n13 if x 6= max then \u2217\u2217 middle batch \u2217\u2217\n14 store := x; \u2217\u2217 remember the last location whose contents \u2217\u2217\n15 place := (2n - 1)\u266f; \u2217\u2217 are different from max \u2217\u2217\n16 done := 0;\n17 fi;\n18 if x 6= C then \u2217\u2217 if the first vertex 6= C then the path is bad \u2217\u2217\n19 bad path := max;\n17\n20 fi;\n21 dpush((2n - 1)\u266f,x); \u2217\u2217 build the next path in the lower batch \u2217\u2217\n22 while \u266fcount < n do \u2217\u2217 iteratively pop the path vertices \u2217\u2217\n23 y := pop;\n24 count := (\u266fcount + 1)\u266f;\n25 if \u00acE(x, y) then \u2217\u2217 check that there is a path-edge from x to y \u2217\u2217\n26 bad path := max;\n27 fi;\n28 dpush(((n - \u266fcount) + \u266fy)\u266f,max); \u2217\u2217 register y \u2217\u2217\n29 if y 6= max then\n30 store := y; \u2217\u2217 remember the last location whose \u2217\u2217\n31 place := (2n - 1)\u266f; \u2217\u2217 contents are different from max \u2217\u2217\n32 done := 0;\n33 else\n34 if done = 0 then\n35 place := (\u266fplace - 1)\u266f;\n36 fi;\n37 fi;\n38 dpush((2n - 1)\u266f,y); \u2217\u2217 continue building the next path \u2217\u2217\n39 x := y;\n40 od;\n41 if done = 0 then\n42 dpush(place,(\u266fstore + 1)\u266f); \u2217\u2217 perform the final stage of \u2217\u2217\n43 place := (\u266fplace + 1)\u266f; \u2217\u2217 building the next path \u2217\u2217\n44 while \u266fplace < 2n do\n45 dpush(place,0);\n46 place := (\u266fplace + 1)\u266f;\n47 od;\n48 if x 6= D then \u2217\u2217 check that the final vertex \u2217\u2217\n49 bad path := max; \u2217\u2217 is D \u2217\u2217\n50 fi;\n51 count := 0;\n52 while \u266fcount < n do \u2217\u2217 check that the path is \u2217\u2217\n53 x := pop; \u2217\u2217 indeed Hamiltonian \u2217\u2217\n54 if x 6= max then\n55 bad path := max;\n56 fi;\n57 count := (\u266fcount + 1)\u266f;\n58 od;\n59 if bad path := 0 then \u2217\u2217 a Hamiltonian path has \u2217\u2217\n60 reject; \u2217\u2217 been found so reject \u2217\u2217\n61 fi;\n62 else\n63 accept; \u2217\u2217 we have checked all paths and no \u2217\u2217\n64 fi; \u2217\u2217 Hamiltonian path has been found \u2217\u2217\n65 od;\nGiven our intuitive description above, it should be clear that \u03c1 is an implementation of\n18\nour algorithm. The only further remark we have is that deep-pushes are parameterized\nby an offset from the top of the stack and so this offset needs to be continually\ncalculated. The offset as regards the registration of vertices found so far (in the\nmiddle batch, as undertaken in lines 12 and 28) is calculated by remembering the\nnumber of vertices currently popped from the top batch (namely the value \u266fcount).\nThe offset as regards the building of the lexicographically-next path (in the lower\nbatch, as undertaken in lines 21 and 38) is 2n \u2212 1. The final phase of building\nthe lexicographically-next path, where a path-location is incremented by 1 and all\nsubsequent path-locations set at 0, is undertaken in lines 42 and 45.\nHaving demonstrated the power of program schemes of NPSDSs, we now turn to\ncapturing the complexity class PSPACE.\nProposition 9 Any polynomial-space Turing machine can be simulated by a pro-\ngram scheme of NPSDSs(oud, oud) so that the stack of the program scheme en-\ncodes the evolution of the work-tape of the Turing machine. Thus, PSPACE \u2286\nNPSDSs(oud, oud).\nProof Let M be a Turing machine which uses nk space (we assume that all input\nstrings are of length at least 2) and which accepts the problem \u2126 over the signature\n\u03c4 (any \u03c4 -structure is encoded as a string, by assuming some successor relation on the\ndomain of the structure, and M accepts exactly those strings encoding structures of\n\u2126). We may assume that M has a one-way work-tape that is infinite to the right,\nthat the input string initially appears in cells 0, 1, . . . , n \u2212 1 of the work-tape, and\nthat the only work-tape symbols are 0, 1 and b (b is the blank symbol; it is always\nobvious as to whether we are talking about the symbol 0 of the Turing machine or\nthe constant symbol 0 of a program scheme). We now describe a program scheme \u03c1\nof NPSDSs(oud, oud) which simulates M and thus accepts \u2126.\nThe program scheme \u03c1 begins by non-deterministically pushing 0\u2019s onto the stack.\nNext, the input string corresponding to the input structure A and the given successor\nrelation succ is pushed onto the stack but in reverse order; that is, reading the stack\nfrom the top element downwards is akin to reading the tape of the Turing machine\nM as it stands initially and from left to right. However, rather than push the input\nstring onto the stack verbatim, we encode this input string as follows: if a bit of the\ninput string is a 1 then we push two max\u2019s onto the stack followed by a 0; and if a bit\nof the input string is a 0 then we push a max then a 0 then a 0 onto the stack. The\nonly exception is that if the first bit of the input string is 1 then we push three max\u2019s\nonto the stack, and if the first bit of the input string is a 0 then we push a max then\na 0 then a max onto the stack. So, for example, if the input string is 10110 then the\ntop of the stack, from the top location downwards, will read:\nmax,max,max, 0, 0,max, 0,max,max, 0,max,max, 0, 0,max.\nThe top 3nk elements of the stack encode the work-tape of M such that for every\ni = 0, 1, . . . , nk \u2212 1:\n\u2022 the location 3i from the top of the stack holds max if, and only if, the tape-head\nof M is pointing at cell i of the work-tape;\n19\n\u2022 the locations 3i+1 and 3i+2 from the top of the stack hold (max,max) (resp.\n(0,max), (0, 0)) if cell i of the work-tape holds the symbol 1 (resp. 0, b).\nThe initial state of M is encoded using a tuple of variables in \u03c1.\nIn general, a move of M is simulated within \u03c1 by popping the top 3nk elements\nfrom the stack (which always encode the contents of M \u2019s work-tape, as above, prior\nto the simulation of a move) and, using deep-pushes, copying them to the next 3nk\nelements of the stack, except that the move of M is registered in the new encoding of\nthe work-tape appropriately. Note that the move can easily be simulated (using the\nvariables of \u03c1) as the cell at which the tape-head is currently pointing can always be\nfound (as the stack is being popped) and the move ofM can be easily registered in the\nnew description of the work-tape (no matter whether the tape-head moves left, moves\nright or stays stationary). It should be clear that the program scheme \u03c1 accepts the\ninput structure if, and only if, the corresponding input string (where the successor\nrelation is taken as succ) is accepted by M .\nIn fact, more can be said. It should be clear that the proof of Proposition 9 is such\nthat the program scheme \u03c1 constructed can actually be taken to be a program scheme\nof NPSDS+bs (oud, oud). Thus, we obtain the following strengthening of Proposition 9.\nCorollary 10 Any polynomial-space Turing machine can be simulated by a pro-\ngram scheme of NPSDS+bs (oud, oud) so that the stack of the program scheme en-\ncodes the evolution of the work-tape of the Turing machine. Thus, PSPACE \u2286\nNPSDS+bs (oud, oud).\nBefore we proceed, we need some definitions.\nDefinition 11 Let \u03c1 be a program scheme of NPSDSs and letA be an input structure\nto \u03c1. An ID of \u03c1 on input A is a tuple \u03b1 consisting of values (from |A|) for the variables\nof \u03c1 together with the next instruction to be executed. A configuration of \u03c1 on input\nA is an ordered pair, written [\u03b1, s], the first component of which, \u03b1, is an ID and the\nsecond component of which, s, is a complete description of the stack.\nAny computation of \u03c1 on input A can be described as a sequence of configurations,\nwith each of these configurations having an associated ID. Of course, some IDs and\nsome configurations might not be achievable in any computation of \u03c1 on input A.\nProposition 12 Every program scheme \u03c1 in NPSDS+bs (uod, oud) accepts a problem\nin PSPACE.\nProof Let \u03c1 = (\u03c10, \u03c11) \u2208 NPSDS\n+b\ns (oud, oud). Suppose that on some input struc-\nture A of size n, \u03c11 is such that all deep-pushes occur with index at most k. We\nshall simulate the computation of \u03c1 with a Turing machine M . By amending \u03c1 simi-\nlarly to as was done in the proof of Proposition 5, we may clearly assume that every\ncomputation of \u03c10 pushes at least n\nk elements onto the stack.\nAny ID of \u03c10 on input A can be stored on M \u2019s work-tape using O(log(n)) tape-\ncells. Moreover, given any two IDs, say IDa and IDb, and an element u \u2208 |A|, M can\nclearly decide whether there is a computation of \u03c10 on input A from the configuration\n[IDa, \u01eb], i.e., the ID IDa together with an empty stack, (resp. from the configuration\n20\n[IDa, (u)], i.e., the ID IDa together with the stack consisting solely of the element\nu) to a configuration whose ID is IDb; this computation can be done by M non-\ndeterministically using O(log(n)) space.\nThe computation of M begins with M guessing a sequence:\nIDnk , unk\u22121, IDnk\u22121, . . . , u1, ID1, u0, ID0\nwhere each IDi is an ID of \u03c10 on input A and where each ui \u2208 |A|, with M then\nverifying that:\n\u2022 for every i \u2208 {1, 2, . . . , nk}, there is a computation of \u03c10 on input A from\nconfiguration [IDi, \u01eb] to configuration [IDi\u22121, (ui\u22121)];\n\u2022 for every i \u2208 {1, 2, . . . , nk}, the current instruction encoded within IDi is a push\nand the element pushed onto the stack is ui\u22121;\n\u2022 ID0 is a terminating ID of \u03c10; that is, an ID where the next instruction to be\nexecuted is the fist instruction of \u03c11.\nNote that should this verification succeed, there is a terminating computation of \u03c10\non input A starting in configuration IDnk and such that on termination the configu-\nration is (ID0, (unk\u22121, unk\u22122, . . . , u1, u0)) (the top of the stack is to the right). The\ncomputation of M always encodes the top nk stack symbols in the simulated compu-\ntation of \u03c10 on input A and also the IDs from which the stack symbols are pushed,\nas is the case above. The ID ID0 is now erased from M \u2019s work-tape.\nThe Turing machine M now simulates the computation of \u03c11 starting from the\nID ID0 and where the top n\nk stack elements are taken as (unk\u22121, unk\u22122, . . . , u1, u0).\nWhenever the top stack element is popped from the stack, this element and the ID\nfrom which this symbol is pushed are erased from M \u2019s work-tape and a new ID, ID\u2032,\nand a new element, u\u2032, are guessed. The computation of M now verifies that either:\n\u2022 the ID ID\u2032 is such that the instruction associated with ID\u2032 is a push, and the\nsymbol to be pushed is u\u2032;\n\u2022 there exists a computation of \u03c10 on input A from the configuration [ID\n\u2032, \u01eb] to\nthe configuration [IDnk\u22121, (u\n\u2032)],\nwhence M has the sequence:\nID\u2032, u\u2032, IDnk , u\n\u2032\nnk\u22121, IDnk\u22121, . . . , u\n\u2032\n1, ID1\nstored on its work-tape; or\n\u2022 the ID ID\u2032 is the initial ID of \u03c10;\n\u2022 there exists a computation of \u03c10 on input A from the configuration [ID\n\u2032, \u01eb] to\nthe configuration [IDnk\u22121, \u01eb],\nwhence M has the sequence:\nID\u2032, IDnk , u\n\u2032\nnk\u22121, IDnk\u22121, . . . , u\n\u2032\n1, ID1\n21\nstored on its work-tape. Note that in both of the above cases, we cannot assume that\nthe u\u2032i\u2019s are the same as the ui\u2019s as deep-pushes in the interim computation of \u03c11\nmight have changed some of the stack elements. In the latter case, when an element\nis popped from the stack in the computation of \u03c10, the simulation by M no longer\nguesses a new ID and a new element but just continues with the simulation until either\nan accept instruction or a reject instruction is reached (ensuring that no deep-pushes\nare made by \u03c11 to locations below the bottom of the stack). In the former case, the\nsimulation byM simply proceeds as directed above. It is easily seen thatM simulates\n\u03c1 and that the result follows.\nThe following corollary is immediate from Corollary 10 and Proposition 12.\nCorollary 13 NPSDS+bs (oud, oud) = NPSDSs(uod, oud) = PSPACE.\n6 Within EXPTIME\nHitherto, we have been focussing on specific restrictions of NPSDSs. We now examine\nthe computational complexity of problems accepted by arbitrary program schemes of\nNPSDSs. Our basic technique in the proof of Proposition 16 is inspired by that\nused in [1] to show that basic program schemes with an ordinary stack only accept\nproblems in P, which in turn was inspired by Cook\u2019s construction involving pushdown\nautomata in [3]. We require some definitions before we present our proof.\nDefinition 14 Let \u03c1 be a program scheme of NPSDSs, where all deep-pushes occur\nwith an index of at most k, and let A be an input structure of size n. An extended\nID (\u03b1, s) of \u03c1 on input A is an ID \u03b1 together with a tuple s of between 0 and nk\nelements of |A|. A pair of extended IDs, ((\u03b1, s), (\u03b2, t)), is called realizable if there is\na computation of \u03c1 on A starting in configuration [\u03b1, s] and ending in configuration\n[\u03b2, t], where |s| = |t| and the stack associated with any interim configuration has\nheight at least |s|.\nDefinition 15 Let ((\u03b1, s), (\u03b2, t)) and ((\u03b1\u2032, s\u2032), (\u03b2\u2032, t\u2032)) be two pairs of extended IDs.\nThese pairs yield the pair of extended IDs ((\u03b1, s), (\u03b2\u2032\u2032, t\u2032\u2032)) if one of the following two\nrules can be applied.\n(a) The instruction associated with \u03b2 is a push, and the execution of this instruction\ntransforms the configuration [\u03b2, t] into the configuration:\n\u2013 [\u03b1\u2032, s\u2032], if |t| < nk;\n\u2013 [\u03b1\u2032, (u0, s\n\u2032)], if |t| = nk (in which case t is a prefix of (u0, s\n\u2032)).\nThe instruction associated with \u03b2\u2032 is a pop, and the execution of this instruction\ntransforms the configuration [\u03b2\u2032, t\u2032] or [\u03b2\u2032, (u0, t\n\u2032)] (depending upon whether\n|t| < nk or |t| = nk, respectively, above) to the configuration [\u03b2\u2032\u2032, t\u2032\u2032].\n(b) (\u03b2, t) = (\u03b1\u2032, s\u2032) and either (\u03b2\u2032\u2032, t\u2032\u2032) = (\u03b2\u2032, t\u2032) or the instruction associated with\n\u03b2\u2032 is neither a pop nor a push and execution of this instruction transforms the\nconfiguration [\u03b2\u2032, t\u2032] to the configuration [\u03b2\u2032\u2032, t\u2032\u2032].\n22\nWe refer to rules (a) and (b) as the yield rules.\nWe are now in a position to prove the main result of this section.\nProposition 16 Let \u03c1 be some program scheme of NPSDSs and let A be some input\nstructure. Any pair of realizable extended IDs of \u03c1 on input A can be obtained from\nthe set Y = {((\u03b1, s), (\u03b1, s)) : (\u03b1, s) is an extended ID of \u03c1 on input A} by iteratively\napplying the yield rules.\nProof Let ((\u03b1, s), (\u03b2, t)) be a realizable pair of extended IDs where the associated\ncomputation \u03c7 (of \u03c1 on input A) from configuration [\u03b1, s] to configuration [\u03b2, t] has\nlength m. We proceed by induction on m.\nSuppose that m = 1. As ((\u03b1, s), (\u03b2, t)) is realizable, the instruction associated\nwith \u03b1 is neither a pop nor a push. Thus, ((\u03b1, s), (\u03b1, s)) and ((\u03b1, s), (\u03b1, s)) yield\n((\u03b1, s), (\u03b2, t)) by applying rule (b).\nSuppose as our induction hypothesis that whenever the associated computation\nof any realizable pair of extended IDs has length less than m, the realizable pair can\nbe obtained from Y by applying the yield rules. Let the penultimate configuration in\n\u03c7 be [\u03b2\u2032, t\u2032]. There are two cases: when the instruction associated with \u03b2\u2032 is neither\na pop nor a push; and when the instruction associated with \u03b2\u2032 is a pop (note that it\ncannot be a push as ((\u03b1, s), (\u03b2, t)) is a realizable pair).\nIn the first case, |t\u2032| = |s| = |t| and ((\u03b1, s), (\u03b2\u2032, t\u2032)) is a realizable pair (witnessed\nby the sub-computation of \u03c7). By the induction hypothesis, ((\u03b1, s), (\u03b2\u2032, t\u2032)) can be\nobtained from Y by applying the yield rules. An additional application of rule (b)\nyields that ((\u03b1, s), (\u03b2, t)) can be obtained from Y by applying the yield rules.\nSuppose that the instruction associated with \u03b2\u2032 is a pop. If |t\u2032| = nk + 1 then\ndefine t\u20320 such that t\n\u2032 = (u0, t\n\u2032\n0), otherwise define t\n\u2032\n0 = t\n\u2032 (recall, stacks are written so\nthat the head of the stack is to the right of the sequence; thus, u0 is at the bottom of\nthe stack). Let [\u03b3,w] be the (unique) configuration of \u03c7 where: |w| = |t\u2032|; the height\nof the stack associated with any configuration of \u03c7 coming after [\u03b3,w], apart from\nthe last, is at least |w|; and the height of the stack associated with the configuration\nimmediately before [\u03b3,w], namely the configuration [\u03b3\u2032,w\u2032], is |w| \u2212 1 (that is, [\u03b3,w]\nis the configuration obtained after executing the push corresponding to the final pop).\nIf |w| = nk + 1 then define w0 such that w = (u0,w0), otherwise define w0 = w.\nIn particular, ((\u03b3,w0), (\u03b2\n\u2032, t\u20320)) is a realizable pair, as is ((\u03b1, s), (\u03b3\n\u2032,w\u2032)), with the\ninduction hypothesis applying to these pairs. An additional application of rule (a)\nnow yields that ((\u03b1, s), (\u03b2, t)) can be obtained from Y by applying the yield rules.\nThe result follows by induction.\nAn instance of the path system problem consists of: a set of places P ; an initial\nsubset of places I \u2286 P ; a subset of terminal places T \u2286 P ; and a ternary relation R.\nThe relation R encodes a set of rules via: if u, v \u2208 P have already been yielded and\nR(u, v, w) holds then w becomes yielded. An instance is a yes-instance if we can show\nthat starting from the set of initial places I as our set of yielded places, iteratively\napplying the rules to yield more places results in a terminal place of T eventually\nbeing yielded. The path system problem has long been known to be complete for P,\nand can be solved by a trivial algorithm which simply iteratively computes more and\nmore yielded places.\n23\nThe complexity class EXPTIME consists of those problems solvable by a deter-\nministic algorithm running in time O(2p(n)), for some polynomial p(n).\nCorollary 17 Any problem accepted by a program scheme of NPSDSs is in EXP-\nTIME.\nProof Let \u03c1 be some program scheme of NPSDSs. By Proposition 16, the problem\nof deciding whether some input structure A, of size n, is accepted by \u03c1 can be reduced\nto an instance of the path system problem with an initial set of places {((\u03b1, s), (\u03b1, s)) :\n(\u03b1, s) is an extended ID of \u03c1 on input A}. However, this instance has size O(nn\nm\n),\nfor some constant m. Nevertheless, it is not difficult to see that we can reduce the\nproblem accepted by the program scheme \u03c1 to the path system problem and then\nsolve the path system problem so as to obtain an exponential-time algorithm.\n7 Conclusions\nIn this paper, we have initiated the study of a high-level model of computation in\nwhich there is access to a deep pushdown stack, and we have managed to capture the\ncomplexity classes NP and PSPACE by restricting our model whilst showing that\nan arbitrary program scheme accepts a problem in EXPTIME. We close with some\ndirections for further research.\nWhilst we have shown that there is a considerable increase in computational power\nobtained by replacing stacks with deep pushdown stacks in a basic class of program\nschemes (assuming P 6= PSPACE!), we have as yet been unable to ascertain ex-\nactly the computational complexity of the problems accepted by program schemes of\nNPSDSs. At the moment, all we know is that PSPACE \u2286 NPSDSs \u2286 EXPTIME.\nLooking at Example 8 where we show that the complement of the Hamiltonian\npath problem is accepted by a program scheme of NPSDSs, we can see no obvious\nrestriction of the general class of program schemes so that we capture the complexity\nclass co-NP (the complement of NP). Note that our program scheme in Exam-\nple 8 is clearly in NPSDSs(oud, oud) yet by Corollary 13, NPSDSs(oud, oud) captures\nPSPACE. It would be interesting to capture co-NP, and more generally the classes\nof the Polynomial Hierarchy, by restricting the program schemes of NPSDSs.\nLet us comment on the height of the stack in different circumstances. As can\nbe seen from the proof of Proposition 6, any problem in NP can be accepted by a\nprogram scheme of NPSDS+bs (oud, oud, oud) where the maximum height of the stack\nis only ever polynomial in the size of the input structure. From Example 8, the\nproblem co-HP can be accepted by a program scheme of NPSDSs(oud, oud) so that\nthe height of the stack is always O(nn+1). From the proof of Proposition 9, the\nproblem accepted by a Turing machine running in space O(nk) and time O(f(n))\ncan be accepted by a program scheme of NPSDSs(oud, oud) so that the height of the\nstack is always O(nk \u00b7 f(n)) = O(nk \u00b7 cn\nk\n), for some c. It would be interesting to try\nand relate the height of the stack used in a computation with the complexity of the\nproblem in hand.\nFinally, one might vary the mechanism by which locations within the stack are\naccessed. For example, one might have two sorts, a \u2018numeric sort\u2019 and an \u2018element\nsort\u2019, with values from the numeric sort being manipulable and used to access locations\n24\nwithin the stack. This set-up might allow access to locations \u2018exponentially deep\u2019\nwithin the stack (should the numeric values be such that exponential numbers can\nbe created). Also, one might allow deep-pops within the current model; thus, the top\n\u2018polynomial\u2019 portion of the stack can be used as an array. Finally, one might consider\na model where elements (or even sequences of elements) can be inserted within the\nstack at some location.\nReferences\n[1] A.A. Arratia-Quesada, S.R. Chauhan and I.A. Stewart, Hierarchies in classes of\nprogram schemes, Journal of Logic and Computation 9 (1999) 915\u2013957.\n[2] R. Constable and D. Gries, On classes of program schemata, SIAM Journal of\nComputing 1 (1972) 66\u2013118.\n[3] S.A. Cook, Characterizations of pushdown pmachines in terms of time-bounded\ncomputers, Journal of the Association for Computing Machinery 18 (1971) 4\u201318.\n[4] E. Dahlhaus, Reduction to NP-complete problems by interpretations, Proc. of\nLogic and Machines: Decision Problems and Complexity (E. Bo\u00a8rger, G. Hasen-\njaeger, D. Ro\u00a8dding, eds.), Lecture Notes in Computer Science Vol. 171, Springer\n(1984) 357\u2013365.\n[5] H.-D. Ebbinghaus and J. Flum, Finite Model Theory, Springer-Verlag (1995).\n[6] H. Friedman, Algorithmic procedures, generalized Turing algorithms and elemen-\ntary recursion theory, Logic Colloquium 1969 (R.O. Gandy, C.M.E. Yates, eds.),\nNorth-Holland (1971) 361\u2013390.\n[7] S. Ginsberg and E. Spanier, Finite-turn pushdown automata, SIAM Journal on\nControl 4 (1968) 429\u2013453.\n[8] D. Harel and D. Peleg, On static logics, dynamic logics, and complexity classes,\nInformation and Control 60 (1984) 86\u2013102.\n[9] N. Immerman, Descriptive Complexity, Springer (1999).\n[10] N.D. Jones and S.S. Muchnik, Even simple programs are hard to analyze, Journal\nof Association for Computing Machinery 24 (1977) 338\u2013350.\n[11] T. Kasai, An hierarchy between context-free and context-sensitive languages,\nJournal of Computer and System Sciences 4 (1970) 492-508.\n[12] L. Libkin, Elements of Finite Model Theory, Springer (2004).\n[13] A. Meduna, Automata and Languages : Theory and Applications , Springer\n(2000).\n[14] A. Meduna, Simultaneously one-turn two-pushdown automata, International\nJournal of Computer Mathematics 80 (2003) 679\u2013687.\n[15] A. Meduna, Deep pushdown automata, Acta Informatica 42 (2006) 541\u2013552.\n25\n[16] M. Paterson and N. Hewitt, Comparative schematology, Record of Project MAC\nConf. on Concurrent Systems and Parallel Computation, ACM Press (1970) 119\u2013\n128.\n[17] L. Spector, J. Klein and M. Keijzer, The Push3 execution stack and the evolution\nof control, Proc. of Genetic and Evolutionary Computation Conference (H.-G.\nBeyer, U.-M. O\u2019Reilly, eds.), ACM Press (2005) 1689\u20131696.\n[18] I.A. Stewart, Using the Hamiltonian path operator to capture NP, Journal of\nComputer and System Sciences 45 (1992) 127\u2013151.\n[19] I.A. Stewart, Program schemes, arrays, Lindstro\u00a8m quantifiers and zero-one laws,\nTheoretical Computer Science 275 (2002) 283\u2013310.\n[20] I.A. Stewart, Using program schemes to logically capture polynomial-time on cer-\ntain classes of structures, London Mathematical Society Journal of Computation\nand Mathematics 6 (2003) 40\u201367.\n[21] I.A. Stewart, Logical and complexity-theoretic aspects of models of computation\nwith restricted access to arrays, Journal of Logic and Computation, to appear.\n[22] J. Tiuryn and P. Urzyczyn, Some relationships between logics of programs and\ncomplexity theory, Theoretical Computer Science 60 (1988) 83\u2013108.\n[23] L.G. Valiant, The equivalence problem for deterministic finite-turn pushdown\nautomata, Information and Control 25 (1974) 123\u2013133.\n26\n"}
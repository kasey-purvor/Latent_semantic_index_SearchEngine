{"doi":"10.1007\/11758549_77","coreId":"138602","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/3150","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/3150","10.1007\/11758549_77"],"title":"Source Transformation for MATLAB Automatic Differentiation.","authors":["Kharche, Rahul V.","Forth, Shaun A."],"enrichments":{"references":[{"id":38066371,"title":"A case for source-level transformations in MATLAB. In:","authors":[],"date":"1999","doi":"10.1145\/331960.331972","raw":"Menon, V., Pingali, K.: A case for source-level transformations in MATLAB. In: PLAN \u201999: Proceedings of the 2nd conference on Domain-speci\ufb01c languages, New York, NY, USA, ACM Press (1999) 53\u201365","cites":null},{"id":38066370,"title":"A.: ADIFOR 2.0: Automatic Di\ufb00erentiation of Fortran 77 Programs.","authors":[],"date":"1996","doi":"10.1109\/99.537089","raw":"Bischof, C.H., Carle A., Khademi P., Mauer A.: ADIFOR 2.0: Automatic Di\ufb00erentiation of Fortran 77 Programs. IEEE Computational Science & Engineering 3(3) (1996) 18\u201332","cites":null},{"id":38066365,"title":"A.: ADMAT: An automatic di\ufb00erentiation toolbox for MATLAB.","authors":[],"date":"1998","doi":"10.1145\/347837.347879","raw":"Coleman, T.F., Verma, A.: ADMAT: An automatic di\ufb00erentiation toolbox for MATLAB. Technical report, Computer Science Department, Cornell University (1998)","cites":null},{"id":38066366,"title":"A.: Combining source transformation and operator overloading techniques to compute derivatives for MATLAB programs. In:","authors":[],"date":"2002","doi":"10.1109\/scam.2002.1134106","raw":"Bischof, C.H., B\u00a8 ucker, H.M., Lang, B., Rasch, A., Vehreschild, A.: Combining source transformation and operator overloading techniques to compute derivatives for MATLAB programs. In: Proceedings of the Second IEEE International Workshop on Source Code Analysis and Manipulation (SCAM 2002), Los Alamitos, CA, USA, IEEE Computer Society (2002) 65\u201372","cites":null},{"id":38066367,"title":"An e\ufb03cient overloaded implementation of forward mode automatic di\ufb00erentiation in MATLAB.","authors":[],"date":"2005","doi":"10.1145\/1141885.1141888","raw":"Forth, S.A.: An e\ufb03cient overloaded implementation of forward mode automatic di\ufb00erentiation in MATLAB. Accepted ACM Trans. Math Softw. (2005)","cites":null},{"id":38066376,"title":"An e\ufb03cient, validated implementation of the MINPACK-2 test problem collection in MATLAB.","authors":[],"date":"2005","doi":null,"raw":"Lenton, K.: An e\ufb03cient, validated implementation of the MINPACK-2 test problem collection in MATLAB. Master\u2019s thesis, Cran\ufb01eld University (Shrivenham Campus), Engineering Systems Dept., Shrivenham, Swindon SN6 8LA, UK (2005)","cites":null},{"id":38066368,"title":"ANTLR: A predicated LL(k) parser generator.","authors":[],"date":"1995","doi":"10.1002\/spe.4380250705","raw":"Parr, T., Quong R.: ANTLR: A predicated LL(k) parser generator. Software, Practice and Experience, vol. 25, p. 789, July 1995","cites":null},{"id":38066364,"title":"Evaluating Derivatives: Principles and Techniques of Algorithmic Di\ufb00erentiation.","authors":[],"date":"2000","doi":"10.1137\/1.9780898717761","raw":"Griewank, A.: Evaluating Derivatives: Principles and Techniques of Algorithmic Di\ufb00erentiation. Number 19 in Frontiers in Appl. Math. SIAM, Philadelphia, Penn. (2000)","cites":null},{"id":38066378,"title":"Newton\u2019s method for large-scale optimization.","authors":[],"date":"1997","doi":null,"raw":"Bouaricha, A., Mor\u00b4 e, J.J., Wu, Z.: Newton\u2019s method for large-scale optimization. Preprint MCS-P635-0197, Argonne National Laboratory, Argonne, Illinois (1997)","cites":null},{"id":38066373,"title":"Partial evaluation of MATLAB. In:","authors":[],"date":"2003","doi":"10.1007\/978-3-540-39815-8_21","raw":"Elphick, D., Leuschel, M., Cox, S.: Partial evaluation of MATLAB. In: GPCE \u201903: Proceedings of the second international conference on Generative programming and component engineering, New York, NY, USA, Springer-Verlag New York, Inc. (2003) 344\u2013363","cites":null},{"id":38066369,"title":"Source transformation for automatic di\ufb00erentiation in MATLAB. Master\u2019s thesis,","authors":[],"date":"2004","doi":"10.1007\/11758549_77","raw":"Kharche, R.V.: Source transformation for automatic di\ufb00erentiation in MATLAB. Master\u2019s thesis, Cran\ufb01eld University (Shrivenham Campus), Engineering Systems Dept., Shrivenham, Swindon SN6 8LA, UK (2004)","cites":null},{"id":38066377,"title":"Source transformation for MATLAB automatic di\ufb00erentiation.","authors":[],"date":"2005","doi":"10.1007\/11758549_77","raw":"Kharche, R., Forth, S.: Source transformation for MATLAB automatic di\ufb00erentiation. Applied Mathematics & Operational Research Report AMOR 2005\/1, Cran\ufb01eld University (Shrivenham Campus), Engineering Systems Dept., Shrivenham, Swindon, SN6 8LA, UK (2005)","cites":null},{"id":38066372,"title":"Techniques for the translation of MATLAB programs into Fortran 90.","authors":[],"date":"1999","doi":"10.1145\/316686.316693","raw":"Rose, L.D., Padua, D.: Techniques for the translation of MATLAB programs into Fortran 90. ACM Trans. Program. Lang. Syst. 21(2) (1999) 286\u2013323","cites":null},{"id":38066374,"title":"The MathWorks Inc. 24 Prime Park Way,","authors":[],"date":"2005","doi":null,"raw":"The MathWorks Inc. 24 Prime Park Way, Natick, MA 01760-1500: MATLAB Optimization Toolbox - User\u2019s guide. (2005)","cites":null},{"id":38066375,"title":"User guide for the MINPACK-2 test problem collection.","authors":[],"date":"1991","doi":"10.2172\/79972","raw":"Averick, B.M., Mor\u00b4 e, J.J.: User guide for the MINPACK-2 test problem collection. Technical Memorandum ANL\/MCS-TM-157, Argonne National Laboratory, Argonne, Ill. (1991) Also issued as Preprint 91-101 of the Army High Performance Computing Research Center at the University of Minnesota.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2005-12","abstract":"We present MSAD, a source transformation implementation of forward mode automatic differentiation for MATLAB. MSAD specialises and inlines operations from the fmad and derivvec classes of the MAD package. The operator overloading overheads inherent in MAD are eliminated while preserving the derivvec class's optimised derivative combination operations. Compared to MAD, results from several test cases demonstrate significant improvement in efficiency across all problem sizes","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/138602.pdf","fullTextIdentifier":"http:\/\/hdl.handle.net\/1826\/3150","pdfHashValue":"ee4abd81a59151ac48067cad31a251d4b64f8646","publisher":"Springer-Verlag","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/3150<\/identifier><datestamp>2009-02-13T12:18:22Z<\/datestamp><setSpec>hdl_1826_13<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Source Transformation for MATLAB Automatic Differentiation.<\/dc:title><dc:creator>Kharche, Rahul V.<\/dc:creator><dc:creator>Forth, Shaun A.<\/dc:creator><dc:description>We present MSAD, a source transformation implementation of forward mode automatic differentiation for MATLAB. MSAD specialises and inlines operations from the fmad and derivvec classes of the MAD package. The operator overloading overheads inherent in MAD are eliminated while preserving the derivvec class's optimised derivative combination operations. Compared to MAD, results from several test cases demonstrate significant improvement in efficiency across all problem sizes.<\/dc:description><dc:publisher>Springer-Verlag<\/dc:publisher><dc:date>2009-02-06T11:55:46Z<\/dc:date><dc:date>2009-02-06T11:55:46Z<\/dc:date><dc:date>2005-12<\/dc:date><dc:type>Postprint<\/dc:type><dc:identifier>Rahul V. Kharche & Shaun A. Forth, Source Transformation for MATLAB Automatic Differentiation, Computational Science - ICCS 2006 6th International Conference, Reading, UK, May 28-31, 2006, Proceedings, Part IV, pages 558-565.\n Editors Vassil Alexandrov, Dick van Albada, Peter Sloot and Jack Dongarra, Lecture Notes in Computer Science  3994,<\/dc:identifier><dc:identifier>3-540-34385-7<\/dc:identifier><dc:identifier>http:\/\/hdl.handle.net\/1826\/3150<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1007\/11758549_77<\/dc:identifier><dc:language>en<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2005,"topics":[],"subject":["Postprint"],"fullText":"Source Transformation for MATLAB\nAutomatic Differentiation\nRahul V. Kharche and Shaun A. Forth\nCranfield University (Shrivenham Campus), Shrivenham, Swindon SN6 8LA, UK\n{R.V.Kharche,S.A.Forth}@cranfield.ac.uk\nAbstract. We present MSAD, a source transformation implementation\nof forward mode automatic differentiation for MATLAB. MSAD spe-\ncialises and inlines operations from the fmad and derivvec classes of the\nMAD package. The operator overloading overheads inherent in MAD\nare eliminated while preserving the derivvec class\u2019s optimised deriva-\ntive combination operations. Compared to MAD, results from several\ntest cases demonstrate significant improvement in efficiency across all\nproblem sizes.\n1 Automatic Differentiation in MATLAB\nMATLAB is popular for rapid prototyping and numerical computing owing to its\nhigh-level abstraction of matrices and its rich set of function and GUI libraries.\nMATLAB\u2019s interpreted nature and high-level language make programming intu-\nitive and debugging easy. Optimised BLAS and LAPACK routines for internal\nmatrix operations facilitate good performance. MATLAB may be extended by\nfurther general purpose and application specific toolboxes (e.g., for optimisation,\npartial differential equations, control, etc.). We believe the robustness and effi-\nciency of many MATLAB toolboxes and user\u2019s applications would benefit from\nan effective automatic differentiation (AD) [1] package.\nColeman and Verma\u2019s ADMAT [2] was the first significant MATLAB AD\ntool and implemented forward and reverse mode differentiation, with support\nfor Jacobian compression, via operator overloading. The later ADiMat tool [3]\nadopted a hybrid source transformation\/operator overloading implementation\nof forward mode AD and out-performed ADMAT on several problems. Simul-\ntaneously the fmad class of MAD [4], an operator overloaded implementation\nof forward mode AD, was also shown to outperform ADMAT. MAD\u2019s efficiency\nis due to appropriate data-structures and use of high-level matrix operations\nwithin its derivvec class which holds and propagates derivatives. Use of MAT-\nLAB\u2019s sparse data-type to hold and propagate sparse derivatives enables run-\ntime sparsity exploitation \u2013 greatly enhancing performance for problems where\nsparsity is unknown or difficult to exploit via compression techniques.\nBecause there is no compilation before execution of operator-overloaded MAT-\nLAB code, performance of overloaded implementations of AD suffer due to over-\nheads from the interpreter and the type check and dispatch mechanism of over-\nloading. Note that MATLAB\u2019s recent just-in-time (JIT) compiler is restricted to\na subset of MATLAB\u2019s intrinsic classes and so is not applicable to the derivvec\nclass. Moreover, overloaded operations typically involve substantial logic and\nbranching dependent on the shape (scalar, vector, matrix, N-D array) or storage\nclass (complex, sparse) used for derivatives. For example, consider the times\noperation of the derivvec class in Fig. 1. Here .derivs refers to the operand\u2019s\nderivative matrix, and .shape to the size of the operand. We see that the test\non line 9 checks if operands have equal sizes and those of lines 15 and 17 test\nfor scalar operands. Similarly, line 10 checks for sparse storage of derivatives.\nSuch tests incur further run-time overheads. Other generic MATLAB overheads\nare described by [8] and their relevance to AD is discussed in [14].\nfunction cdv = times(a,b)\nif isa(b,\u2019derivvec\u2019)\ncdv = b; mults = a;\nelse\ncdv = a; mults = b;\nend\nssd = prod(cdv.shape); sm = size(mults); ssm = prod(sm);\nmults = mults(:);\nif ssd == ssm % line 9\nif issparse(cvd.derivs) % line 10\n% sparse mode operations omitted for brevity\nelse\ncdv.derivs = mults(:,ones(1,cdv.nderivs)).*cdv.derivs; % line 13\nend\nelseif ssd == 1 % line 15\ncdv.derivs = mults*cdv.derivs; cdv.shape = sm;\nelseif ssm == 1 % line 17\ncdv.derivs = mults.*cdv.derivs;\nend\nFig. 1. derivvec - times operation from MAD\nThe MSAD (MATLAB Source transformation AD) tool aims to demonstrate\nthe benefits obtained by combining source transformation with MAD\u2019s efficient\ndata structures. An initial, hybrid source transformation\/operator overloading\napproach, similar to that of ADiMat, showed significant speedup compared to\nMAD for smaller test cases but asymptotically reached the performance of MAD\nas the problem size increased [6]. Section 2 of this paper describes our improved\nsource transformation approach, which now specialises and inlines all required\nderivative operations. The benefits of this approach are demonstrated by the\ntest cases of Section 3. Conclusions are presented in Section 4.\n2 Source Transformation via Specialising and Inlining\nMSAD uses ANTLR-based LL(k) scanner, parser and tree parsers [5] to analyse\nand source transform MATLAB programs for AD [6]. Program transformation\nis carried out via four phases - scanning and parsing for Abstract Syntax Tree\n(AST) and symbol table generation, attribute synthesis for activity analysis [7],\nsize and class propagation, and finally derivative code generation. MSAD\u2019s parser\nrecognises the complete MATLAB (Release 14) grammar, but differentiation of\ncode involving branches, loops, structures, cells, nested functions and programs\nspanning multiple files is currently not implemented. Despite these restrictions,\nby replacing loops with array operations, many tests cases can be differentiated.\nThe attribute synthesis phase propagates flags that mark a variable\u2019s activ-\nity, class, storage type and derivative storage type. Input programs are prepared\nby using directives to indicate the active inputs and optionally sparse storage\nfor their derivatives. Users may optionally supply size information of input vari-\nables. For example, the directives in Fig. 2 indicate to MSAD that the size\nparameters (nx, ny) and the vortex parameter (vornum) are scalars. The direc-\ntives also label variable x as an active input and that its derivatives be stored as\na sparse matrix. MSAD emulates MATLAB\u2019s sparse type propagation and size\ncomputation rules for each elementary operation of the source code to deduce\nthe storage type and size of all variables. If a variable\u2019s size and storage type\ncannot be determined, MSAD marks these attributes as unknown. The sizes of\nscalar and array constants within a program are automatically propagated.\nfunction fgrad = gdgl2(nx, ny, x, vornum)\n%! size(nx) = [1, 1], size(ny) = [1, 1], size(vornum) = [1, 1]\n%! active(x), sparseDer(x)\nFig. 2. User directives used with gradient function of MINPACK DGL2 problem\nThe derivative code is generated in a final pass during which the operations\nfrom MAD\u2019s fmad and derivvec classes are specialised and inlined. Specialisa-\ntion uses a variable\u2019s size, class, storage class and activity information to resolve\ncondition checks and simplify size computations in the fmad and derivvec class\noperations. For variables with unknown size and storage attributes, MSAD con-\nservatively inlines operations involving size and storage checks.\nWe illustrate the process of specialisation and inlining by considering the FT-\nBROY function of Fig. 3 [11], specifically the subexpression (3-2*x(n)).*x(n)\nof line 8. Line 3 of the program implies n equals the length of the vector x. Al-\nthough this length can be determined only at run-time, n can safely be deduced\nto be a scalar. This further implies x(n) is a scalar, as is 3-2*x(n). MSAD au-\ntomatically carries out this size inference during the attribute synthesis phase.\nDuring specialisation, because the operands x(n) and 3-2*x(n), held in vari-\nables tmp 5 and tmp 4 in the generated code of Fig. 4, are inferred to be scalars,\nthe condition on line 9 from the derivvec-times operation in Fig. 1 is satisfied.\nAssuming derivatives are stored in their full form, only lines 8 and 13 from Fig. 1\nneed to be inserted into the generated code as seen in lines 17 to 20 of Fig. 4.\nComments in Fig. 4, and the later Fig. 5, were added by hand to indicate to the\nreader which line computes which expression or expression\u2019s derivatives; D[a]\ndenotes the derivatives of variable a.\nfunction f = ftbroy(x)\n%! active(x)\nn = length(x); % line 3\np = 7\/3; y = zeros(n,1);\ni = 2:(n-1);\ny(i) = abs((3-2*x(i)) .* x(i) - x(i-1) - x(i+1) + 1).^p; % line 6\ny(n) = abs((3-2*x(n)) .* x(n) - x(n-1) + 1).^p; % line 7\ny(1) = abs((3-2*x(1)) .* x(1) - x(2) + 1).^p; % line 8\nj = 1:(n\/2); z = zeros(length(j),1);\nz(j) = abs(x(j) + x(j+n\/2)).^p;\nf = 1 + sum(y) + sum(z);\nFig. 3. FTBROY function\ntmp 1 = x(n); % x(n)\ntmp ind = reshape((1:numel(x)), size(x));\ntmp ind = tmp ind (n);\nd tmp 1 = d x(tmp ind (:),:); % D[x(n)]\ntmp 2 = 2 .* tmp 1 ; % 2*x(n)\ntmp mults = 2;\nd tmp 2 = tmp mults (:,ones(1,res tmp1 )).*d tmp 1 ; % D[2*x(n)]\ntmp 3 = 3 - tmp 2 ; % 3-2*x(n)\nd tmp 3 = -d tmp 2 ; % D[3-2*x(n)]\ntmp 4 = tmp 3 ; % (3-2*x(n))\nd tmp 4 = d tmp 3 ; % D[(3-2*x(n))]\ntmp 5 = x(n); % x(n)\ntmp ind = reshape((1:numel(x)), size(x));\ntmp ind = tmp ind (n);\nd tmp 5 = d x(tmp ind (:),:); % D[x(n)]\ntmp 6 = tmp 4 .* tmp 5 ; % (3-2*x(n)).*x(n)\ntmp mults = tmp 5 ; % line 17\nd tmp 7 = tmp mults (:,ones(1,res tmp1 )).*d tmp 4 ; % x(n).*D[(3-2*x(n))]\ntmp mults = tmp 4 ;\nd tmp 8 = tmp mults (:,ones(1,res tmp1 )).*d tmp 5 ; % (3-2*x(n)).*D[x(n)]\nd tmp 6 = d tmp 7 + d tmp 8 ; % D[(3-2*x(n)).*x(n)]\nFig. 4. MSAD generated derivative code for the subexpression (3-2*x(n)).*x(n) of\nthe TBROY function. (Comments added for clarity)\nIn the subexpression (3-2*x(i)).*x(i) on line 6 in Fig. 3, the size of x(i)\ncannot be determined since i is a vector dependent on the value of n. MSAD\ntherefore conservatively inlines lines 7 to 19 of the derivvec-times operation.\nThe first product of D[3-2*x(i).*x(i)], analogous to lines 17 and 18 from\nFig. 4, can be seen in Fig. 5.\nd tmp 4= d tmp 3 % D[(3-2*x(i))]\ntmp mults = tmp 5 (:); % x(i)\ntmp ssa = numel(tmp mults ); % length(x(i))\ntmp ssb = numel(tmp 4 ); % length((3-2*x(i)))\nif tmp ssa == tmp ssb % equal sizes\nd tmp 7 = tmp mults (:,ones(1,res tmp1 )) .* d tmp 4 ;\nelseif tmp ssb == 1 % (3-2*x(i)) scalar\nd tmp 7 = tmp mults * d tmp 4 ;\nelseif tmp ssa == 1 % x(i) scalar\nd tmp 7 = tmp mults .* d tmp 4 ;\nend\nFig. 5. Additional checks for vector times operation in D[(3-2*x(i))].*x(i). (Com-\nments added for clarity)\n3 Test Results\nMSAD computed derivatives were tested for correctness and performance on\nseveral optimisation, BVP and ODE problems [14]. A subset of those tests,\nall performed using MATLAB Release 14 on a Linux machine with a 2.8 GHz\nPentium-4 processor and 512 MB of RAM, are presented here.\nIn Table 1 we compare use of MSAD and MAD\u2019s fmad class to compute\nderivatives by repeating the large-scale test cases from MATLAB\u2019s Optimisation\nToolbox [11] performed in [4]. The test cases are: nlsf1a\u2013 sparse Jacobian from\nvector residual; brownf, tbroyf \u2013 gradient from objective function; browng,\ntbroyg \u2013 Hessian from hand-coded gradient. Both automatic differentiation tools\nmay use Jacobian\/Hessian compression (denoted cmp) [1, Chap. 7] or sparse\nstorage (denoted spr) [1, Chap. 6] where appropriate. The only MSAD user\ndirectives required were those to specify the active input variables and use of\nsparse derivative storage. For comparison, we have included MATLAB\u2019s finite-\ndifference (sfd(nls)) evaluation of the gradient\/Jacobian\/Hessian and, where\navailable, hand-coding.\nTable 1. Ratio CPU(\u2207f + f)\/CPU(f) \u2013 Jacobian\/gradient (including function) to\nfunction CPU time ratio for given techniques on MATLAB Optimisation Toolbox large-\nscale examples. (m,n) gives the number of dependents and independents, n\u02c6 the maxi-\nmum number of non-zero entries in a row of the Jacobian and p the number of colours\nfor compression\nCPU(\u2207f + f)\/CPU(f) for\nProblem Hand- sfd- msad fmad msad fmad (m,n) n\u02c6 p\ncoded (nls) (cmp) (cmp) (spr) (spr)\nnlsf1a(Jac) 4.4 38.3 6.9 22.5 19.4 35.1 (1000,1000) 3 3\nbrownf(grad) 4.6 1064.9 \u2013 \u2013 9.3 13.7 (1,1000) 1000 \u2013\nbrowng(Jac) 5.2 9.5 4.2 8.4 15.3 19.6 (1000,1000) 3 3\ntbroyf(grad) 3.8 810.7 \u2013 \u2013 8.8 15.9 (1,800) 800 \u2013\ntbroyg(Jac) \u2013 13.8 3.3 10.1 15.8 23.5 (800,800) 6 7\nClearly, MSAD yields significant savings compared to fmad in like-for-like\ncomputation of derivatives for these moderate sized problems (n \u2248 1000). For\ncompressed derivative computation we get savings of over 50% using msad(cmp)\nand for sparse storage gains of about 30%. Compressed AD (msad(cmp), fmad(cmp))\nout-performs compressed finite-differencing (sfd(nls)). For the gradient prob-\nlems (brownf, tbroyf) sparse AD (msad(spr), fmad(spr)) is several times faster\nthan sfd(nls) because the functions brownf and tbroy are partially value sepa-\nrable [4] and the sparse derivative computation may utilise intermediate sparsity\nwhereas finite-differencing cannot. For the browng problem msad(cmp) outper-\nforms hand-coding due to the use of complicated expressions in the hand-coding.\nTable 2 lists the total optimisation run-times with derivatives supplied using\nthe methods of Table 1. Source transformed derivatives yield substantial savings\nin the total run-time compared to fmad\u2019s overloading approach and run-times\nare comparable to those using hand-coded derivatives.\nTable 2. Averaged CPU time for optimisation of the large-scale examples from the\nMATLAB Optimisation Toolbox with derivatives supplied using given techniques\nOptimisation CPU time (s) for\nProblem Hand- sfd- msad fmad msad fmad\ncoded (nls) (cmp) (cmp) (spr) (spr)\nnlsf1a 0.16 0.36 0.17 0.31 0.20 0.35\nbrownf 0.56 \u2013 \u2013 \u2013 0.7 1.25\nbrowng 0.29 0.56 0.23 0.41 0.46 0.64\ntbroyf 0.72 \u2013 \u2013 \u2013 1.29 2.89\ntbroyg \u2013 0.76 0.20 0.48 0.55 0.86\nThe 2-D Ginzburg-Landau unconstrained minimisation problem (GL2) [12,\n13] uses an nx\u00d7ny mesh with 4 variables per mesh point yielding n = 4nxny inde-\npendent variables. The objective function is again partially value separable and\nthe gradient code is supplied. The sparse Hessian is computed as the Jacobian Jg\nof the gradient g. Differentiated functions were generated using MSAD for full\nand sparse storage of derivatives; the user directives for sparse storage can be seen\nin Fig. 2. Table 3 gives the derivative computation ratio CPU(Jg + g)\/CPU(g)\nfor increasing problem size. Using compression, msad(cmp) is nearly 80% more\nefficient than fmad(cmp) for small n. With increasing problem size, the floating\npoint operation cost of the derivative computation of either method increases\nrelative to its overheads and the relative advantage of source transformation\ndecreases. However, even for n as large as 65, 536 msad(cmp) is nearly twice as\nfast as overloading. With sparse derivatives (msad(spr), fmad(spr)) we see a\nsimilar trend but smaller relative improvement due to the common overhead of\nmanipulating MATLAB\u2019s sparse data structures.\nThe total optimisation time using MATLAB\u2019s fminunc solver with the differ-\nent Hessian calculation techniques of Table 3 is shown in Table 4. The decrease\nTable 3. Ratio CPU(Jg + g)\/CPU(g) \u2013 Hessian (including gradient) to gradient func-\ntion CPU time ratio for the MINPACK 2-D Ginzburg-Landau problem using given\ntechniques; p gives the number of colours for compression. For all problem sizes, the\nmaximum number of non-zero entries in a row of the Jacobian is n\u02c6 = 14\nCPU(Jg + g)\/CPU(g) for problem size n\nMethod 64 256 1024 4096 16384 65536\nmsad(cmp) 24.72 23.69 21.84 23.31 37.95 52.16\nfmad(cmp) 115.32 105.89 89.57 72.82 72.11 90.47\nmsad(spr) 28.11 29.18 35.02 52.63 88.97 177.10\nfmad(spr) 122.80 113.84 107.73 108.72 126.45 222.81\n#colours p 20 23 25 24 25 25\nin overall computation time obtained by using MSAD\u2019s more efficient derivative\ncomputation is seen \u2013 but this is not proportional to the decrease in derivative\ncomputation time. This is because for larger problem size the number of Newton\niterations (which require a Hessian recalculation) stays fixed but the number of\nconjugate gradient iterations (which do not) increase [15].\nTable 4. Optimisation CPU time for the MINPACK Ginzburg-Landau (GL2) problem\nusing MATLAB\u2019s fminunc with derivatives supplied using given techniques\nProblem size n\n64 256 1024 4096 16384\nMethod CPU time (s) for optimisation\nmsad(cmp) 0.74 0.59 1.34 6.95 29.62\nfmad(cmp) 4.45 2.78 3.79 10.71 38.70\nmsad(spr) 1.23 1.14 2.87 13.05 61.93\nfmad(spr) 4.79 3.32 5.41 17.05 73.83\nsfd 1.41 1.29 3.60 19.91 216.30\n4 Conclusion\nThe previous, hybrid source transformation\/operator overloading implementa-\ntion of MSAD [6] gave reasonable speedup over operator overloading for small\nproblem sizes. This speedup diminished with increasing problem size. The im-\nproved implementation presented here inlines and, where possible specialises,\nthe remaining overloaded function calls. This eliminates the type check and dis-\npatch overhead of overloading, reduces logic and branching, and exposes a larger\nsection of the augmented code to MATLAB\u2019s JIT acceleration. Section 3\u2019s test\ncases clearly demonstrate these benefits. Figure 4\u2019s code indicates the scope for\nfurther performance improvements by eliminating redundant temporaries and\ncommon subexpressions. Preliminary results obtained by implementing such im-\nprovements by hand on one test case produced a 42% speedup [14] and highlight\nthe need for such compiler-like optimisations within a MATLAB AD-tool.\nReferences\n1. Griewank, A.: Evaluating Derivatives: Principles and Techniques of Algorithmic\nDifferentiation. Number 19 in Frontiers in Appl. Math. SIAM, Philadelphia, Penn.\n(2000)\n2. Coleman, T.F., Verma, A.: ADMAT: An automatic differentiation toolbox for\nMATLAB. Technical report, Computer Science Department, Cornell University\n(1998)\n3. Bischof, C.H., Bu\u00a8cker, H.M., Lang, B., Rasch, A., Vehreschild, A.: Combining\nsource transformation and operator overloading techniques to compute derivatives\nfor MATLAB programs. In: Proceedings of the Second IEEE International Work-\nshop on Source Code Analysis and Manipulation (SCAM 2002), Los Alamitos, CA,\nUSA, IEEE Computer Society (2002) 65\u201372\n4. Forth, S.A.: An efficient overloaded implementation of forward mode automatic\ndifferentiation in MATLAB. Accepted ACM Trans. Math Softw. (2005)\n5. Parr, T., Quong R.: ANTLR: A predicated LL(k) parser generator. Software,\nPractice and Experience, vol. 25, p. 789, July 1995\n6. Kharche, R.V.: Source transformation for automatic differentiation in MATLAB.\nMaster\u2019s thesis, Cranfield University (Shrivenham Campus), Engineering Systems\nDept., Shrivenham, Swindon SN6 8LA, UK (2004)\n7. Bischof, C.H., Carle A., Khademi P., Mauer A.: ADIFOR 2.0: Automatic Differen-\ntiation of Fortran 77 Programs. IEEE Computational Science & Engineering 3(3)\n(1996) 18\u201332\n8. Menon, V., Pingali, K.: A case for source-level transformations in MATLAB. In:\nPLAN \u201999: Proceedings of the 2nd conference on Domain-specific languages, New\nYork, NY, USA, ACM Press (1999) 53\u201365\n9. Rose, L.D., Padua, D.: Techniques for the translation of MATLAB programs into\nFortran 90. ACM Trans. Program. Lang. Syst. 21(2) (1999) 286\u2013323\n10. Elphick, D., Leuschel, M., Cox, S.: Partial evaluation of MATLAB. In: GPCE \u201903:\nProceedings of the second international conference on Generative programming\nand component engineering, New York, NY, USA, Springer-Verlag New York, Inc.\n(2003) 344\u2013363\n11. The MathWorks Inc. 24 Prime Park Way, Natick, MA 01760-1500: MATLAB\nOptimization Toolbox - User\u2019s guide. (2005)\n12. Averick, B.M., More\u00b4, J.J.: User guide for the MINPACK-2 test problem collec-\ntion. Technical Memorandum ANL\/MCS-TM-157, Argonne National Laboratory,\nArgonne, Ill. (1991) Also issued as Preprint 91-101 of the Army High Performance\nComputing Research Center at the University of Minnesota.\n13. Lenton, K.: An efficient, validated implementation of the MINPACK-2 test prob-\nlem collection in MATLAB. Master\u2019s thesis, Cranfield University (Shrivenham\nCampus), Engineering Systems Dept., Shrivenham, Swindon SN6 8LA, UK (2005)\n14. Kharche, R., Forth, S.: Source transformation for MATLAB automatic differen-\ntiation. Applied Mathematics & Operational Research Report AMOR 2005\/1,\nCranfield University (Shrivenham Campus), Engineering Systems Dept., Shriven-\nham, Swindon, SN6 8LA, UK (2005)\n15. Bouaricha, A., More\u00b4, J.J., Wu, Z.: Newton\u2019s method for large-scale optimization.\nPreprint MCS-P635-0197, Argonne National Laboratory, Argonne, Illinois (1997)\n"}
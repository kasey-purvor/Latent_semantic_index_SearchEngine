{"doi":"10.1016\/j.neunet.2005.06.003","coreId":"101098","oai":"oai:epubs.surrey.ac.uk:503","identifiers":["oai:epubs.surrey.ac.uk:503","10.1016\/j.neunet.2005.06.003"],"title":"A comparative study of autoregressive neural network hybrids","authors":["Taskaya-Tamizel, T","Casey, Matthew C"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2005-08-01","abstract":"<p>Many researchers have argued that combining many models for forecasting gives better estimates than single time series models. For example, a hybrid architecture comprising an autoregressive integrated moving average model (ARIMA)and a neural network is a well-known technique that has recently been shown to give better forecasts by taking advantage of each model\u2019s capabilities. However, this assumption carries the danger of underestimating the relationship between the model\u2019s linear and non-linear components, particularly by assuming that individual forecasting techniques are appropriate, say, for modeling the residuals. In this paper, we show that such combinations do not necessarily outperform individual forecasts. On the contrary, we show that the combined forecast can underperform significantly compared to its constituents\u2019 performances. We demonstrate this using nine data sets, autoregressive linear and time-delay neural network models.<\/p","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:503<\/identifier><datestamp>\n      2017-10-31T13:58:27Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:436F6D707574696E67<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/503\/<\/dc:relation><dc:title>\n        A comparative study of autoregressive neural network hybrids<\/dc:title><dc:creator>\n        Taskaya-Tamizel, T<\/dc:creator><dc:creator>\n        Casey, Matthew C<\/dc:creator><dc:description>\n        <p>Many researchers have argued that combining many models for forecasting gives better estimates than single time series models. For example, a hybrid architecture comprising an autoregressive integrated moving average model (ARIMA)and a neural network is a well-known technique that has recently been shown to give better forecasts by taking advantage of each model\u2019s capabilities. However, this assumption carries the danger of underestimating the relationship between the model\u2019s linear and non-linear components, particularly by assuming that individual forecasting techniques are appropriate, say, for modeling the residuals. In this paper, we show that such combinations do not necessarily outperform individual forecasts. On the contrary, we show that the combined forecast can underperform significantly compared to its constituents\u2019 performances. We demonstrate this using nine data sets, autoregressive linear and time-delay neural network models.<\/p><\/dc:description><dc:date>\n        2005-08-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/503\/1\/fulltext.pdf<\/dc:identifier><dc:identifier>\n          Taskaya-Tamizel, T and Casey, Matthew C  (2005) A comparative study of autoregressive neural network hybrids   Neural Networks, 18 (5-6).  pp. 781-789.      <\/dc:identifier><dc:relation>\n        10.1016\/j.neunet.2005.06.003<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/503\/","10.1016\/j.neunet.2005.06.003"],"year":2005,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"A Comparative Study of Autoregressive Neural\nNetwork Hybrids\nTugba Taskaya-Temizel, Matthew C. Casey\nUniversity of Surrey\nSchool of Electronics and Physical Sciences\nDepartment of Computing\nGuildford, UK\nE-mail: t.taskaya, m.casey@surrey.ac.uk\nAbstract\u2014 Many researchers have argued that combining\nmany models for forecasting gives better estimates than single\ntime series models. For example, a hybrid architecture compris-\ning an autoregressive integrated moving average model (ARIMA)\nand a neural network is a well-known technique that has recently\nbeen shown to give better forecasts by taking advantage of\neach model\u2019s capabilities. However, this assumption carries the\ndanger of underestimating the relationship between the model\u2019s\nlinear and non-linear components, particularly by assuming\nthat individual forecasting techniques are appropriate, say, for\nmodeling the residuals. In this paper, we show that such combina-\ntions do not necessarily outperform individual forecasts. On the\ncontrary, we show that the combined forecast can underperform\nsignificantly compared to its constituents\u2019 performances. We\ndemonstrate this using nine data sets, autoregressive linear and\ntime-delay neural network models.\nI. INTRODUCTION\nResearch in time series forecasting argues that predictive\nperformance improves in combined models (Bishop, 1994;\nClemen, 1989; Hansen & Nelson, 2003; Hibbert, Pedreira, &\nSouza, 2000; Terui & van Dijk, 2002; Tseng, Yu, & Tzeng,\n2002; Weigend, Mangeas, & Srivastava, 1995; Zhang, 2003;\nZhang & Qi, 2005). The motivation for combining models\ncomes from the assumption that either one cannot identify\nthe true data generating process (Terui & van Dijk, 2002)\nor that a single model may not be sufficient to identify\nall the characteristics of the time series (Zhang, 2003). For\nexample, a time series may exhibit both linear and non-linear\npatterns during the same time interval. In such cases, neither a\nlinear nor non-linear model is able to model both components\nsimultaneously.\nUsing a hybrid technique that decomposes a time series\ninto its linear and non-linear form has recently been shown\nto be successful for single models (Zhang, 2003; Zhang &\nQi, 2005). In particular, it has been argued that for seasonal\ntime series, the seasonal component is first required to be\nremoved by a linear model, such as a seasonal autoregressive\nprocess, before any further analysis takes place (Tseng et al.,\n2002; Zhang & Qi, 2005; Nelson, Hill, Remus, & O\u2019Connor,\n1999; Virili & Freisleben, 2000). However, this assumption\ncarries the danger of underestimating the relationship between\nthe components as there may not be any additive association\nbetween the linear and non-linear elements. In addition, one\ncannot guarantee that the residuals of the linear component\nmay comprise valid non-linear patterns. Nevertheless, a sin-\ngle component is able to model such seasonal series if the\nmodeling procedure is carried out properly. In this paper, we\npresent a comparison of the performance of these approaches,\nexpanding upon our preliminary work (Taskaya-Temizel &\nAhmad, 2005)1.\nIn Section II we first discuss the hybrid techniques designed\nfor time series analysis. In Section III we present single\nmodels to analyze seasonal time series. Section IV describes\nthe experimental model design, whilst Section V details the\nexperiments and results. Finally, we conclude this work and\ndiscuss our future work in Section VI.\nII. MODEL COMBINATION TECHNIQUES\nThere are a range of combination techniques that can be\napplied to forecasting that attempt to overcome the deficiencies\nof single models. The difference between these combination\ntechniques can be described using terminology developed\nfor the classification and neural network literature (Sharkey,\n2002). Here we focus upon cooperative ensembles and more\ngeneral cooperative and competitive architectures.\nIn an ensemble architecture, the aim is to reduce the risk\nof using an inappropriate model by combining several to\nreduce the risk of failure. Typically this is done because the\nunderlying process cannot easily be determined (Hibon &\nEvgeniou, 2005). Ensemble architectures comprise several\nredundant models designed for the same function, where the\ndiversity of the components is thought important (Brown,\nWyatt, Harris, & Yao, 2005). An overall forecast is produced\nby combining the models\u2019 outputs, say by an average or\nmajority vote. Ensemble models can be homogeneous, such\nas using differently configured neural networks (all multi-\nlayer perceptrons) (Zhang & Berardi, 2001), or heterogeneous,\nsuch as with both linear and non-linear models (Terui & van\nDijk, 2002; Wichard & Ogorzalek, 2004). However, these\narchitectures do not always lead to better estimates when\ncompared to single models. For example, it has been shown\nthat combined forecasts do not necessarily dominate for all\n1An abbreviated version of some portions of this article appeared in\nTaskaya-Temizel and Ahmad (2005), as part of the IJCNN 2005 conference\nproceedings, published under the IEEE copyright.\nseries; sometimes a linear model still produces better results\n(Terui & van Dijk, 2002).\nIn a cooperative modular combination, the aim is to fuse\nmodels to build a complete picture from a number of partial\nsolutions (Sharkey, 2002). The assumption is that a model may\nnot be sufficient to represent the complete behavior of a time\nseries, for example if the time series exhibits both linear and\nnon-linear features, neither linear models nor non-linear mod-\nels alone are capable. A good exemplar are models that fuse\nARIMA with neural networks. An ARIMA process combines\nthree different processes comprising an autoregressive (AR)\nfunction regressed on past values of the process, moving aver-\nage (MA) function regressed on a purely random process with\nmean zero and variance \u03c3t, and an integrated (I) part to make\nthe data series stationary by differencing. In such hybrids,\nwhilst the neural network model deals with non-linearity, the\nARIMA model deals with the non-stationary linear component\n(Tseng et al., 2002; Zhang, 2003; Zhang & Qi, 2005). Such\nmodels are generally constructed in a sequential manner, with\nthe ARIMA model first applied to the original time series, and\nthen its residuals modeled using neural networks.\nDifferent hybrids of ARIMA and neural networks have\nalso been constructed. For example, ARIMA parameters have\nbeen used as a window to build a neural network architecture\n(Hansen & Nelson, 2003), whereas neural networks have also\nbeen trained with past observations, comprising the original\ndata and ARMA forecasts (Hibbert et al., 2000). However, it\nis typically assumed that the residuals of a linear component\nare always going to include valid non-linear patterns that can\nbe modeled using neural networks (Zhang, 2003; Zhang &\nQi, 2005). Such assumptions are likely to lead to unwanted\ndegeneration of performance if the opposite situation occurs.\nIn a competitive architecture the aim is to build appropriate\nmodules to represent different parts of the time series, and to\nbe able to switch control to the most appropriate. For example,\na time series may exhibit non-linear behavior generally, but\nthis may change to linearity depending on the input conditions.\nEarly work on threshold autoregressive models (TAR) used\ntwo different linear AR processes, each of which change\ncontrol among themselves according to the input values (Tong,\n1990). An alternative is a mixture density model (Bishop,\n1994), also known as non-linear gated expert (Weigend et al.,\n1995), which comprises neural networks integrated with a\nfeedforward gating network. Mixture models have been also\nextended to comprise Gaussian AR components (Wong & Li,\n2000), which work in-situ and are often homogeneous. Whilst\neach mixture network learns to specialize on different proba-\nbility density functions of the targets, the gating network learns\nto switch to the appropriate component based on the input\n(Jacobs, Jordan, Nowlan, & Hinton, 1991). Such models are\nthought superior because they can model general conditional\ndensities (Bishop, 1994), whereas conventional neural network\napproaches approximate the conditional average of the target\ndata by minimizing the sum-of-squares error function. The\nmajor drawback of such architectures is that there may be un-\nwanted effects if control is switched to a less well-performing\nmodule, thus causing overall performance degeneration.\nIII. MODELS FOR SEASONAL TIME SERIES\nMany conventional statistical techniques decompose a time\nseries into trends, seasonalities, cycles and irregular fluctua-\ntions. Such decomposition facilitates forecasting by providing\ninsights regarding the nature of the time series. The decom-\nposition process comes from the idea that economic theories\nthat are relevant in the long run are different to the theory one\nwishes to apply in the short run (Harvey, 1997).\nCyclic patterns are oscillations that generally have a fixed\nperiod. Seasonality is regarded as a special case of cycles\nwhose periods are calendar fixed. In economic data, there is\nincreasing evidence that business cycles are not symmetric\n(Chatfield, 2004). Asymmetric cyclic behaviors in the econ-\nomy can be explained as the rate of change in recession, being\ndifferent to the rate of change in emerging from recession.\nWell-known data sets such as the sunspot and Canadian lynx\nseries (Rao & Sabr, 1984) show evidence of asymmetric\ncycles, with such behavior difficult to model with linear\ntechniques.\nIf the cyclic patterns are not of direct interest, one can\nremove them by seasonal differencing conditional on the\nstochastic variation present in the data. Trend and seasonality\nremoval processes are referred as pre-whitening methods. If\nthe cyclic patterns are of interest, one can apply seasonal\nmodels. In the case of cycles that are symmetric, linear\nAR model variants can be employed, whereas a time series\nthat exhibits multiplicative seasonality can be transformed\ninto additive form using functional transformations such as\nlogarithms (Box & Cox, 1996).\nNon-linear models (Kantz & Schreiber, 1999) can also\nbe used to explain, and give forecasts for, data exhibiting\nregular cyclic behaviors and are an alternative to the use of\nharmonic components, especially if the behavior is asymmetric\n(Chatfield, 2004). However, a linear AR model can be applied\nto a non-linear time series such as to the sunspot data set if the\ntime series is short (Rao & Sabr, 1984). Some empirical results\nshow that linear models dominate in the short run and non-\nlinear models perform well in the long run (Terui & van Dijk,\n2002). Moreover, some results show that seasonal series cannot\nbe modeled successfully with neural networks (Zhang & Qi,\n2005; Tseng et al., 2002; Nelson et al., 1999). However, no\nsignificant attention has been shown to model selection for\nneural networks and preprocessing in these results.\nIV. MODEL DETAILS\nIn this paper, our main aim is to investigate whether the\nperformance of hybrid models shows consistent improvement\nover single models. For this purpose, we compute linear AR,\nneural network and ARIMA neural network hybrid models,\nconstructed using a range of parameters to determine the best\narchitecture. Our main goal is to evaluate the use of hybrid\nmodels and to achieve this, we set out to answer the following\nquestions:\nA) How important is preprocessing for neural networks?\nHow does detrending affect the performance?\nB) Are neural networks able to model seasonality? If they\nare, how can we construct optimal architectures?\nC) Compared to linear autoregressive models, how success-\nful are neural networks?\nD) Are ARIMA neural network hybrids better than single\nmodels?\nIn this section, we present details of the models used to\nanswer these questions.\nA. Neural Network Design\nTemporal data can be modeled using neural networks in\ntwo ways. The first way is to provide recurrent connections\nfrom output nodes to the preceding layer (Elman, 1990). The\nsecond way is to provide buffers on the output of the nodes\n(see Haykin (1999) for a detailed survey on neural networks\nfor temporal data modeling). A time-delay neural network\n(TDNN) is a well-known exemplar for the latter models that\nhas been employed throughout our experiments. In a TDNN,\neach layer is connected to its preceding layer\u2019s buffered output,\nand is therefore able to relate current input to past values\n(Waibel, Hanazawa, Hinton, Shikano, & Lang, 1989). A subset\nof the TDNN architecture is the input delayed neural networks\n(IDNN), in which the memories are only provided in the\ninput layer (Clouse, Giles, & Horne, 1997). Their simplicity\nof implementation has made them widely used in time series\nanalysis (Zhang & Berardi, 2001; Zhang, 2003; Zhang & Qi,\n2005; Tseng et al., 2002; Weigend et al., 1995).\nThe activation function for node i at time t of a TDNN is:\nyi(t) = f\n\uf8eb\uf8ed M\u2211\nj=1\nT\u2211\nd=1\nwij(t\u2212 d)yj(t\u2212 d)\n\uf8f6\uf8f8 (1)\nwhere yi(t) is the output of node i at time t, wij(t) is the\nconnection weight between node i and j at time t, T is the\nnumber of tapped delays, M is the number of nodes connected\nto node i from preceding layer, and f is the activation function,\ntypically the logistic sigmoid. In this paper, we consider the\ncase when we have tapped delays in the input layer only.\nWe consider TDNN configurations of 2i : 2j : 1, where 1 \u2264\ni, j \u2264 16 and i, j \u2208 Z+. Each configuration was tested with 30\ndifferent random initial conditions to provide an average root\nmean square error (RMSE) on the test data. Here we focus\non RMSE only for model comparison, rather than using other\nerror criteria. Details of the training procedure used can be\nfound in Taskaya-Temizel and Ahmad (2005). Note that the\nneural networks are trained on normalized data formed using\nthe z-score of the original data.\nB. Linear Autoregressive Process Design\nA linear AR process has been employed throughout the\nexperiments. A process Xt is said to be an AR process of\norder p if:\nXt = \u00b5+ \u03b11(Xt \u2212 \u00b5) + ...+ \u03b1p(Xt\u2212p \u2212 \u00b5) + Zt (2)\nwhere \u03b1 are the AR parameters, \u00b5 is the mean of the series\nand Zt is a random process with mean 0 and variance \u03c32z .\nAs a model selection criterion, we employed Akaike\u2019s\nInformation Criterion (AIC), which takes into account the\nnumber of parameters fitted. AIC chooses the best fit, as\nmeasured by the likelihood function subject to a penalty\nterm (Chatfield, 2004). However, as AIC is biased for small\nsamples, we preferred the bias-corrected version of AICC\n(Hurvich, Simonoff, & Tsai, 1998):\nAICCp = \u22122ln(\u03c3\u02c62p) + 2p+ 2p(p+ 1)\/(T \u2212 p\u2212 1) (3)\nwhere T is the sample size, \u03c3\u02c62p = (T \u2212 p\u2212 1)\u22121\n\u2211T\nt=p \u000f\u02c6\n2\nt and\n\u000f\u02c6t are the model residuals. The AICC value was calculated for\norders between 1 and 20. Then the lowest value was selected\namong the results.\nC. Autoregressive and Neural Network Hybrid Design\nA hybrid model comprising a linear and a non-linear com-\nponent has been employed in the experiments (Zhang, 2003):\nyt = Lt +Nt (4)\nwhere Lt is the linear AR component and Nt is the non-linear\ncomponent. First, we model the linear part by fitting an AR\nfunction to the data series. Then, the residuals are modeled\nusing neural networks. Let r be the residual of the linear\ncomponent, then:\nrt = yt \u2212 L\u02c6t (5)\nwhere L\u02c6t is the estimate of the linear AR component. For\nnon-linear patterns, we use neural networks:\nr\u02c6t = f(rt\u22121, rt\u22122, ..., rt\u2212q) (6)\nwhere q is the number of input delays and f is the non-linear\nfunction. So the combined forecast will be\nyt = L\u02c6t + r\u02c6t + \u000ft (7)\nwhere \u000ft is the error of the combined model. Since linear\nAR models cannot model non-linearity, we assume that the\nresiduals of the linear component will contain non-linear\npatterns, which a non-linear component, such as a neural\nnetwork, should be able to model. In this way, the hybrid\nmodel is exploiting the strength of both components.\nV. EXPERIMENTS AND RESULTS\nIn this section, we describe the experiments and results\nundertaken to answer the questions set in Section IV. We\nselected nine monthly time series as used by Zhang and Qi\n(2005) for the experiments. Monthly series were selected as\nthey exhibit stronger seasonality than that of quarterly time\nseries. None of the series are seasonally adjusted, but do\ncomprise trends (see Table I). All data series end at December\n2001. The last 12 values have been reserved for testing, the\npreceding 12 values for validation, whilst the rest are used\nfor training. This low number of test and validation samples\nwas selected because of the small size of the data sets. It\nis recognized that this is less than ideal, but is used for\ncomparison with Zhang and Qi (2005), as is one-step-ahead\nforecasting.\nTABLE I\nDATA SETS USED IN EXPERIMENTS. THE SECOND COLUMN SHOWS THE\nSTART DATE OF THE DATA SERIES. THE LAST COLUMN SHOWS THE TOTAL\nNUMBER OF DATA POINTS IN THE DATA SETS.\nData Sets Start Date Data Points\nUSBC Retail 01\/1992 120\nUSBC Hardware 01\/1992 120\nUSBC Clothing 01\/1992 120\nUSBC Furniture 01\/1992 120\nUSBC Bookstore 01\/1992 120\nFR Durable Goods 01\/1947 660\nFR Fuels 01\/1947 576\nFR Consumer Goods 01\/1970 384\nFR Total Production 01\/1947 660\nA. Experiment 1: How does detrending affect the performance\nof neural networks?\nAlthough neural networks are said to be universal approx-\nimators, they have certain limitations. It has been shown that\nneural networks are not able to model a time series containing\ntrend, since non-linear transfer functions, such as the logistic\nsigmoid, constrain the model to the input range values (Cot-\ntrell, Girard, Girard, Mangeas, & Muller, 1995). Therefore, it\nis important to eliminate trend before training, where ideally\na stationary time series that has constant mean and variance\nshould be used for modeling. Non-stationarity in the mean\nattributed to trend can be removed either by differencing\n(stochastic trends) or polynomial fitting (deterministic trends).\nHowever, there is no successful method that determines which\ndetrending method is suitable for a given series (Zhang &\nQi, 2005). Although the importance of detrending is known\nfor neural networks, this has yet to be fully investigated.The\nforecasting ability of neural networks can be helpful in un-\nderstanding whether differencing or trend fitting can be more\nappropriate in order to make the time series stationary in the\nmean.\nTABLE II\nTDNN MEAN AND STANDARD DEVIATION RMSE FOR TESTING DATA\nSETS PREPROCESSED WITH DIFFERENCING AND TREND FITTING\nData Sets Differencing Trend Fitting\nUSBC Retail 1446.77\u00b1457.84 2177.04\u00b1542.28\nUSBC Hardware 73.26\u00b1 20.99 111.06\u00b1 31.30\nUSBC Clothing 1148.58\u00b1427.17 848.59\u00b1207.98\nUSBC Furniture 279.91\u00b1 44.20 285.97\u00b1 24.09\nUSBC Bookstore 224.86\u00b1 36.97 296.08\u00b1 38.18\nFR Durable Goods 4.31\u00b1 0.53 7.83\u00b1 1.27\nFR Fuels 2.28\u00b1 0.30 2.51\u00b1 0.54\nFR Consumer Goods 1.80\u00b1 0.22 2.58\u00b1 0.52\nFR Total Production 1.95\u00b1 0.19 3.42\u00b1 1.42\nIn the literature, both detrending techniques have been\napplied regardless of observing their performances on testing\ndata sets. For example, whilst Virili and Freisleben (2000)\nadopted differencing, Zhang and Qi (2005) employed trend\nfitting. Table II shows the TDNN testing data set RMSE when\ntrained using data preprocessed with differencing or first order\npolynomial trend fitting, as per Zhang and Qi (2005). The\nmean result is shown based on training 256 different TDNN\narchitectures for 30 trials, each starting with different random\ninitial conditions. Eight out of nine data sets preprocessed\nwith differencing performed significantly better than with trend\nfitting. However, we can conclude that one should consider\nboth detrending techniques for modeling with neural networks\nand choose the best-performing from the results because this\nwill typically depend upon the data set. For the nine data sets,\ndifferencing appears to give better results, and hence we use\nthis in the subsequent experiments.\nFor neural networks, preprocessing helps to make the data\nhave a constant mean and variance. One should expect good\nforecasts if the data set has been properly adjusted according\nto the nature of the series before training. The experiments\nindicate that the trends in the data sets cannot be adequately\ncaptured by straight lines, which means a deterministic trend is\ntoo restrictive, which is also inline with the Harvey\u2019s (1997)\nresult. However, we note that if the time series evolves in\nexponential or multiplicative form, the first step should be\nto apply transformations such as taking the logarithm of the\nseries.\nB. Experiment 2: How can we construct optimal neural net-\nwork architectures for seasonal time series?\nIn this experiment, we investigated whether neural networks\nare able to model seasonal time series. For each data set, we\nselected the TDNN configurations that produced the best mean\nperformance (lowest RMSE) out of 256 (see Table III), and\ncompared these with Zhang and Qi\u2019s (2005) TDNN model,\nwho determined the number of the input nodes and delays\naccording to the nature of the autocorrelation in the time series.\nNote that their results report the best-fit model among 5 trials\nof 98 architectures only.\nTABLE III\nCOMPARISON OF TDNN ARCHITECTURES: THE SECOND COLUMN SHOWS\nTHE BEST TDNN CONFIGURATION OBTAINED FROM 256 MODELS. THE\nTHIRD COLUMN PRESENTS THE MEAN AND STANDARD DEVIATION OF\nRMSE RESULTS OF CORRESPONDING MODELS BASED ON 30 TRIALS. THE\nLAST COLUMN (*) SHOWS THE BEST FIT RESULTS OF ZHANG AND QI\n(2005)\nData Sets Model TDNN TDNN *\nUSBC Retail 16: 2 :1 628.70\u00b128.27 1785.77\nUSBC Hardware 14: 4 :1 35.70\u00b1 6.90 105.12\nUSBC Clothing 14: 2 :1 372.50\u00b150.66 1117.72\nUSBC Furniture 16: 2 :1 173.10\u00b131.10 226.68\nUSBC Bookstore 12: 2 :1 91.51\u00b110.41 170.49\nFR Durable Goods 12:16:1 2.91\u00b1 0.34 5.98\nFR Fuels 32: 2 :1 1.64\u00b1 0.13 1.83\nFR Consumer Goods 24: 2 :1 1.07\u00b1 0.20 1.48\nFR Total Production 28: 2 :1 1.07\u00b1 0.05 1.62\nThe TDNN trained on first-order differenced data sets\nproduced lower RMSE than the TDNN* for all data sets,\nwith improvement on USBC retail (64%), hardware (66%),\nclothing (66%), furniture (24%), bookstore (46%), FR durable\ngoods (51%), fuels (10%), consumer goods (28%), and total\nproduction (34%).\nWe found that the number of input delays in optimum\nTDNN architectures shown in Table III is highly correlated\nwith the cycle information obtained from Fourier Analysis\nfor each data set. We recently reported an algorithm to\nconfigure optimum TDNN architectures for analyzing cyclic\nseries (Taskaya-Temizel, Casey, & Ahmad, 2005), finding that\nthe number of input delays should be selected by taking into\nconsideration the longest cycle information and the number\nof input weights in the network. On the five USBC data sets\nhaving size of 120, we found that there are no significant\nlonger cycles than 12. If we assume a relaxation of \u00b12\nas per Zhang and Qi (2005), we can approximate the best\nperformed TDNN input layer design in Table III. For longer\nseries such as FR total production exhibiting several cycles\nsuch as 24, 37, 42 and 63 months, we undertook a similar\nexperiment with configurations varying between 2i : 2j : 1,\nwhere 1 \u2264 i, j \u2264 33. We observed that the network gives its\nbest performance on 43 : 2 : 1, which is close to 42 periods\nobtained from Fourier Analysis, but the performance degrades\nin larger input sizes, such as in 63. In addition, the number\nof hidden layer nodes should be kept small as generalization\nperformance reduces for networks with larger hidden layers.\nThis result agrees with the application of a TDNN to S&P\nfinancial time series (Sitte & Sitte, 2000). However, in these\nexperiments the conclusion was that the input layer does not\nplay a significant role in neural network design, perhaps due\nto the selected series following a random walk, in contrast to\nour results. These results also disagree with the application of\na TDNN to the exchange rate data between British pound and\nUS dollar (Zhang & Berardi, 2001). Although the time serial\ndata exhibits a random walk, they conclude that forecasting\nability of neural networks are not sensitive to the number of\nhidden nodes but sensitive to the number of input nodes.\nIn order to investigate the effect of the input and hidden\nlayers on the overall performance of TDNNs, we calculated\nthe mean RMSE of 30 randomly initialized TDNNs for each\nconfiguration. Fig. 1 illustrates the testing set performance of\nUSBC bookstore time series. The x-axis and y-axis show the\nhidden and input layer sizes, respectively. The bar on the\nright side of the figure shows the correspondence between\nRMSE and shading, with dark depicting lower errors. It is\napparent that the RMSE is significantly large when the input\nlayer size is less than 12 (corresponds to a year) and that the\nbest fit results are obtained for a lower number of neurons\nin the hidden layer. The error surface of FR fuels (see Fig.\n2) shows similar results. In addition, the performance in the\ninput layer degrades after 14 in Fig. 1, however not as much\nas the performance variation between networks having input\nlayer with size of 12 and less. The other notable result is that\nthe neural networks give good estimates when the input layer\nsize is close to that of extracted cycle information. In Fig. 2,\nthe darkest regions are clumped around 12 and 30, which are\ntwo of the cycles found in the FR fuels data set.\n100\n120\n140\n160\n180\n200\n220\n240\n260\n280\n300\n2 6 10 14 18 22 26 30\n2\n6\n10\n14\n18\n22\n26\n30\nHidden Layer\nIn\npu\nt L\nay\ner\nUSBC Bookstore Testing Data Set Error\nFig. 1. USBC bookstore testing data set performance based on average\nRMSE. For each configuration, the mean RMSE is calculated over 30 trials.\nMean RMSE is grouped into discrete bands to show the error landscape\ncorresponding to the different layer sizes.\n1.8\n2\n2.2\n2.4\n2.6\n2.8\n3\n2 6 10 14 18 22 26 30\n2\n6\n10\n14\n18\n22\n26\n30\nHidden Layer\nIn\npu\nt L\nay\ner\nFR Fuels Testing Data Set Error\nFig. 2. FR fuels testing data set performance based on average RMSE. For\neach configuration, the mean RMSE is calculated over 30 trials. Mean RMSE\nis grouped into discrete bands to show the error landscape corresponding to\nthe different layer sizes.\nIn addition, we found that there is no significant evidence\nthat one should incorporate autocorrelation structures. Zhang\nand Qi (2005) included 10 various lag numbers of 1-4, 12-\n14, 24, 25 and 36 for the original and detrended data where\nseasonality exists. They attributed this to the observations\nbeing 12, 24 and 36 months apart, with high correlation, and\nhence it is necessary to include these lags in the input layer.\nHowever, the performances of the neural networks comprising\n24 delays in the input layer did not yield the best results in\nour experiments.\nC. Experiment 3: Performance comparison of linear autore-\ngressive and neural networks\nIn this section, we compare the performance of linear mod-\nels with neural networks. Linear AR models were constructed\nusing the AICC criteria as described in Section IV-B 2. The\nperformance of the validation set was used for model selection.\nTABLE IV\nAR MODEL PERFORMANCE: THE SECOND COLUMN SHOWS THE AR\nORDER IDENTIFIED BY AICC. THE THIRD COLUMN PRESENTS THE RMSE\nOF THE AR MODEL. THE LAST COLUMN (*) IS THE RMSE OF ZHANG\nAND QI\u2019S (2005) ARIMA MODEL\nData Set AR Order Test Error ARIMA *\nUSBC Retail 11 551.84 1005.41\nUSBC Hardware 12 25.75 100.71\nUSBC Clothing 14 350.49 519.60\nUSBC Furniture 13 179.65 124.44\nUSBC Bookstore 12 111.17 98.17\nFR Durable Goods 15 2.72 5.61\nFR Fuels 13 1.53 1.62\nFR Consumer Goods 13 0.97 3.96\nFR Total Production 15 0.85 8.94\nOur seven out of nine AR models performed considerably\nbetter than the ARIMA models constructed by Zhang and Qi\n(2005) (see Table IV). However the best fit results of the\nTDNN show a lower RMSE was obtained than AR fits of the\nUSBC retail (6%), hardware (31%), clothing (28%), furniture\n(29%), bookstore (38%), FR durable goods (28%), fuels\n(45%), and consumer goods (13%) but not on total production\n(-1%). Our results show that a TDNN can outperform a linear\nmodel if the TDNN is configured appropriately.\nD. Experiment 4: Are ARIMA neural network hybrids better\nthan single models?\nThe hybrid architectures we tested were constructed fol-\nlowing the procedure described in Section IV-C. We first\ndetrended the time series and fitted linear AR to the detrended\ndata, using the AR model orders shown in Table IV. Then\nwe modeled the residuals of AR using 256 different TDNN\narchitectures. Finally, for each data set, we selected the TDNN\nconfigurations that produced the best mean performance over\n30 trials (lowest RMSE) from the 256.\nAR hybrids performed better than single AR models on six\nout of nine data sets (compare Table IV and V). However,\nwe observed a degeneration in performance in the USBC\nretail and clothing data sets. In the hybrid model, while the\nlinear component is estimated by the AR model, the residual\nerror (that is the error between the AR estimate and the\noriginal data) is estimated by a neural network. However, this\nresidual error exhibits randomness, lacking the properties for\na successful estimate by neural networks. The residual error\nand the residual error predicted by the neural network are\nshown in Fig. 3. This plot indicates that the error between the\npredicted residuals and the original residuals is greater than the\nerror between zero (representing the case of no prediction, or\njust AR) and the residuals. This means that the neural network\n2The Matlab programs to build autoregressive models and neural networks,\nas well as the autoregressive coefficients of the models, can be obtained from\nhttp:\/\/www.computing.surrey.ac.uk\/personal\/st\/T.Taskaya\/\nadversely affects the performance of the AR estimate, resulting\nin an overall poorer performance.\nFig. 3. The residuals of the AR process and the neural network prediction on\nthe AR residuals. Although there is some correlation between the predictions,\nfor higher time indices, the prediction differs significantly to the actual\nresidual.\nIn Table V, we compared our hybrid model performances\nwith Zhang and Qi\u2019s results. In their model construction, they\nused the X-11 method (current X-12-ARIMA) developed by\nthe Bureau of the Census, which includes several seasonal\nadjustment methods. On average, we outperformed on three\nout of nine data sets. Recall that all our comparisons in the\ntables are based on mean and standard deviation of RMSE\nobtained over 30 trials, whilst Zhang and Qi\u2019s (2005) results\nare based on the best fit. Comparing our best fit results, we\noutperformed on six out of nine data sets: on the USBC\nretail (46%), hardware (63%), clothing (20%), furniture (11%),\nbookstore (22%), FR durable goods (46%), but not on fuels\n(-3%), consumer goods (-23%) and total production (-1%).\nTABLE V\nHYBRID ARCHITECTURE PERFORMANCE: THE SECOND COLUMN SHOWS\nTHE BEST TDNN MODEL ORDER IDENTIFIED FOR THE RESIDUALS OF\nLINEAR AR. THE THIRD COLUMN IS THE MEAN RMSE OF THE HYBRID\nMODEL AND THE FOURTH COLUMN (*) IS THE BEST-FIT HYBRID RESULTS\nOF ZHANG & QI (2005)\nData Sets Model AR+TDNN ARIMA+\nTDNN*\nUSBC Retail 28: 2 :1 726.56\u00b181.16 975.55\nUSBC Hardware 2:10:1 25.39\u00b1 3.80 49.17\nUSBC Clothing 2: 4 :1 381.76\u00b110.70 315.43\nUSBC Furniture 22:10:1 173.03\u00b119.55 99.45\nUSBC Bookstore 2: 6 :1 99.33\u00b1 6.99 88.74\nFR Durable Goods 2: 2 :1 2.71\u00b1 0.05 3.63\nFR Fuels 18: 4 :1 1.52\u00b1 0.12 0.81\nFR Consumer Goods 4: 2 :1 0.98\u00b1 0.03 0.68\nFR Total Production 2: 2 :1 0.83\u00b1 0.02 0.85\nAnother interesting result is that the optimum configurations\nof five out of nine of the TDNNs in the hybrid models have\nsimilar input layer sizes. The tapped delays reveal that the\nAR models successfully removed the cyclic components from\nthe differenced series, whilst the residuals appeared to follow\na non-linear random walk model. For the three sets USBC\nretail, furniture and FR fuels, the TDNN configurations show\nthat AR models could not successfully remove the long time\ncycles from the time series.\nFig. 4 shows the percentage performance improvement for\nthe mean and best fit of the TDNN, best fit of the AR neural\nnetwork hybrid and AR single models as compared to the\nmean of hybrid architecture. For four out of the nine data sets,\nthe mean hybrid outperforms the single model. However, for\nfive of the data sets, either the linear AR or TDNN model\noutperforms the hybrid. Of these improved single models,\nthree significantly outperform the hybrid. These improvements\nappear to be related to model configuration, where selection\nfor generalization performance allows for better results.\n-60 -40 -20 0 20 40 60\nUSBC Retail\nUSBC Hardware\nUSBC Clothing\nUSBC Furniture\nUSBC Bookstore\nFR Durable Goods\nFR Fuels\nFR Consumer Goods\nFR Total Production\nPercentage Performance\nH\nyb\nrid\nBest Hybrid\nBest TDNN\nMean TDNN\nLinear AR\nFig. 4. Percentage performance improvement for the mean and best fit of\nthe TDNN, best fit of the AR neural network hybrid and AR single models\nas compared to the mean for the hybrid architecture.\nVI. DISCUSSION\nIn this paper, we have attempted to understand if hybrid\nmodels really are better than single models. Our findings can\nbe summarized as follows:\nA) How important is preprocessing for neural networks?\nHow does detrending affect the performance?\nIf a given time series exhibits trend, one should employ\ndetrending. The selection of the detrending process is also vital\nfor training with neural networks. We found that differencing\ngenerally gives superior results than that of trend fitting.\nB) Are neural networks able to model seasonality? If they\nare, how can we construct optimal architectures?\nNeural networks are able to model seasonality if the neural\nnetwork architecture is properly configured. It appears that\nneural networks give better forecasts when the input layer size\nis equal to the longest cycle information obtained from Fourier\nAnalysis (Taskaya-Temizel et al., 2005) and the hidden layer\nsize is small, relating to the generalization capabilities of the\nnetwork.\nC) Compared to linear autoregressive models, how success-\nful are neural networks?\nWhen the mean RMSE of the TDNNs are compared to linear\nAR processes, they outperform in two out of the nine data sets.\nWhen the best fit results are compared, the TDNNs outperform\nthe AR processes in eight out of nine data sets. However, to\nobtain these better results requires effort in configuring the\nnetwork appropriately.\nD) Are ARIMA neural network hybrids better than single\nmodels?\nFor five of the nine data sets, the linear AR and TDNN models\noutperform the ARIMA neural network hybrids, albeit with\nsimilar levels of performance for two of these data sets. This\ndemonstrates that, despite the popularity of hybrid models,\nwhich rely upon the success of their components, single mod-\nels themselves can be sufficient. Perhaps the danger in using\nARIMA neural network hybrids is that there is an assump-\ntion that the relationship between the linear and non-linear\ncomponents is additive and this may degrade performance if\nthe relationship is different (for example multiplicative). In\naddition, one may not guarantee that the residuals of the linear\ncomponent may comprise valid non-linear patterns.\nThese results show that hybrids are not always better,\nand hence that the model selection process still remains an\nimportant step despite the popularity of hybrid models. We\nhave focused on a limited subset of hybrid models, and\ntherefore further work is required to assess the generated\nperformance of hybrid models in comparison to single models.\nFollowing on from these results, there are still some questions\nto be answered. For example, we also plan to work on model\nselection procedures for TDNN architectures. In our earlier\nwork, we found that there is a strong relationship between\nthe cycle information obtained from Fourier Analysis and the\nnumber of weights in the neural networks. We will further\ninvestigate the impact that this has on generalization capability.\nACKNOWLEDGMENTS\nWe are grateful to Fingrid project [RES-149-25-0028],\nwhich provided a Grid environment comprising 24 machines\nto run our simulations using Condor. We would like to\nthank to Dr. Anthony Browne, and Alptekin Temizel for their\nproofreading and comments.\nVII. REFERENCES\nBishop, C. (1994). Mixture density networks. Neural Com-\nputing Research Group Report: NCRG\/94\/004, 1\u201325.\nBox, G.-E.-P., & Cox, D.-R. (1996). An analysis of transfor-\nmations. JRSS B, 26, 211\u2013246.\nBrown, G., Wyatt, J., Harris, R., & Yao, X. (2005). Diversity\ncreation methods: a survey and categorisation. Information\nFusion, 6(1), 5\u201320.\nChatfield, C. (2004). The analysis of time series. Texts in\nStatistical Science. USA: Chapman & Hall, sixth edition.\nClemen, R. (1989). Combining forecasts:a review and anno-\ntated bibliography. International Journal of Forecasting, 5,\n559\u2013583.\nClouse, D., Giles, C., & Horne, G. (1997). Time delay-\nneural networks: Representation and induction of finite-\nstate machines. IEEE Transactions on Neural Networks,\n8(5), 1065\u20131070.\nCottrell, M., Girard, B., Girard, Y., Mangeas, M., & Muller,\nC. (1995). Neural modeling for time series:a statistical\nstepwise method for weight elimination. IEEE Transactions\non Neural Networks, 6(6), 1355\u20131364.\nElman, J. (1990). Finding structure in time. Cognitive Science,\n14, 179\u2013211.\nHansen, J., & Nelson, R. (2003). Time-series analysis with\nneural networks and ARIMA-neural network hybrids. Jour-\nnal of Experimental and Theoretical Artificial Intelligence,\n15(3), 315\u2013330.\nHarvey, A. (1997). Trends, cycles and autoregressions. The\nEconomic Journal, 107(1), 192\u2013201.\nHaykin, S. (1999). Neural networks: A comprehensive foun-\ndation. Prentice Hall, 2 edition.\nHibbert, H., Pedreira, C., & Souza, R. (2000). Combining\nneural networks and ARIMA models for hourly tempera-\nture forecast. Proceedings of International Conference on\nNeural Networks (IJCNN 2000) (pp. 414\u2013419). Como,Italy.\nHibon, M., & Evgeniou, T. (2005). To combine or not to\ncombine: Selecting among forecasts and their combinations.\nInternational Journal of Forecasting, 21, 15\u201324.\nHurvich, C., Simonoff, J., & Tsai, C.-L. (1998). Smoothing\nparameter selection in nonparametric regression using an\nimproved Akaike information criterion. Journal of the\nRoyal Statistical Society: Series B, 60(2), 271\u2013293.\nJacobs, R., Jordan, M., Nowlan, S., & Hinton, G. (1991).\nAdaptive mixture of local experts. Neural Computation,\n3, 79\u201387.\nKantz, H., & Schreiber, T. (1999). Non-linear time series\nanalysis. Cambridge, UK: Cambridge University Press.\nNelson, M., Hill, T., Remus, W., & O\u2019Connor, M. (1999).\nTime series forecasting using neural networks: Should the\ndata be deseasonalized first? Journal of Forecasting, 18,\n359\u2013367.\nRao, T.-S., & Sabr, M.-M. (1984). An introduction to bispec-\ntral analysis and bilinear time series models. Lecture Notes\nin Statistics, 24.\nSharkey, A. (2002). Types of multinet system. Proceedings\nof the Third International Workshop on Multiple Classifier\nSystems, Vol. 2364 of Lecture Notes in Computer Science\n(pp. 108\u2013117). London, UK: Springer-Verlag.\nSitte, R., & Sitte, J. (2000). Analysis of the predictive ability\nof time delay neural networks applied to the S&P 500\ntime series. IEEE Transactions on Systems, Man, and\nCybernetics - Part C: Applications and Reviews, 30, 568\u2013\n572.\nTaskaya-Temizel, T., & Ahmad, K. (2005). Are ARIMA neural\nnetwork hybrids better than single models? Proceedings of\nInternational Joint Conference on Neural Networks (IJCNN\n2005). July 31 - August 4, 2005, Montre\u00b4al, Canada.\nTaskaya-Temizel, T., Casey, M.-C., & Ahmad, K. (2005).\nPre-processing inputs for optimally-configured time-delay\nneural networks. IEE Electronic Letters, 41, 198\u2013200.\nTerui, N., & van Dijk, H. (2002). Combined forecasts from\nlinear and nonlinear time series models. International\nJournal of Forecasting, 18, 421\u2013438.\nTong, H. (1990). Non-linear time series: a dynamical system\napproach. Oxford University Press.\nTseng, F.-M., Yu, H.-C., & Tzeng, G.-H. (2002). Combining\nneural network model with seasonal time series ARIMA\nmodel. Technological Forecasting and Social Change, 69,\n71\u201387.\nVirili, F., & Freisleben, B. (2000). Nonstationarity and\ndata preprocessing for neural network predictions of an\neconomic time series. Proceedings of International Joint\nConference on Neural Networks (IJCNN 2000) (pp. 5129\u2013\n5136). Como, Italy.\nWaibel, A., Hanazawa, T., Hinton, G., Shikano, K., & Lang,\nK.-J. (1989). Phoneme recognition using time-delay neural\nnetworks. IEEE Transactions on Acoustics, Speech and\nSignal Processing, 37(3), 328\u2013339.\nWeigend, A.-S., Mangeas, M., & Srivastava, A.-N. (1995).\nNonlinear gated experts for time series: Discovering\nregimes and avoiding overfitting. International Journal of\nNeural Systems, 6, 373\u2013399.\nWichard, J., & Ogorzalek, M. (2004). Time series prediction\nwith ensemble models. Proceedings of International Joint\nConference on Neural Networks (IJCNN 2004) (pp. 1625\u2013\n1629). Budapest.\nWong, C., & Li, W. (2000). On a mixture autoregressive\nmodel. Journal of the Royal Statistical Society: Series B\n(Statistical Methodology), 62, 91\u2013115.\nZhang, G.-P. (2003). Time series forecasting using a hybrid\nARIMA and neural network model. Neurocomputing, 50,\n159\u2013175.\nZhang, G.-P., & Berardi, V. (2001). Time series forecasting\nwith neural network ensembles: an application for exchange\nrate prediction. Journal of the Operational Research Soci-\nety, 52, 652\u2013664.\nZhang, G.-P., & Qi, M. (2005). Neural network forecasting\nfor seasonal and trend time series. European Journal of\nOperational Research, 160(2), 501\u2013514.\n"}
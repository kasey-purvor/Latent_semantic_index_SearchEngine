{"doi":"10.1016\/S0098-3004(00)00047-9","coreId":"63406","oai":"oai:nora.nerc.ac.uk:2407","identifiers":["oai:nora.nerc.ac.uk:2407","10.1016\/S0098-3004(00)00047-9"],"title":"Geoscience after IT: Part L. Adjusting the emerging information system to new technology","authors":["Loudon, T.V."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":["Loudon, T.V."],"datePublished":"2000-04","abstract":"Coherent development depends on following widely used standards that respect our vast legacy of existing entries in the geoscience record. Middleware ensures that we see a coherent view from our desktops of diverse sources of information. Developments specific to managing the written word, map content, and structured data come together in shared metadata linking topics and information types","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/63406.pdf","fullTextIdentifier":"http:\/\/nora.nerc.ac.uk\/2407\/1\/Part_L.pdf","pdfHashValue":"334ced40f4724143d85658c284e0a8d54b5bbd7d","publisher":"Pergamon Elsevier-Science Ltd, Oxford","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:nora.nerc.ac.uk:2407<\/identifier><datestamp>\n      2012-11-22T11:48:22Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D5338<\/setSpec><setSpec>\n      7375626A656374733D5339<\/setSpec><setSpec>\n      7375626A656374733D533130<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/2407\/<\/dc:relation><dc:title>\n        Geoscience after IT: Part L. Adjusting the emerging information system to new technology<\/dc:title><dc:creator>\n        Loudon, T.V.<\/dc:creator><dc:subject>\n        Computer Science<\/dc:subject><dc:subject>\n        Data and Information<\/dc:subject><dc:subject>\n        Earth Sciences<\/dc:subject><dc:description>\n        Coherent development depends on following widely used standards that respect our vast legacy of existing entries in the geoscience record. Middleware ensures that we see a coherent view from our desktops of diverse sources of information. Developments specific to managing the written word, map content, and structured data come together in shared metadata linking topics and information types.<\/dc:description><dc:publisher>\n        Pergamon Elsevier-Science Ltd, Oxford<\/dc:publisher><dc:contributor>\n        Loudon, T.V.<\/dc:contributor><dc:date>\n        2000-04<\/dc:date><dc:type>\n        Publication - Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/nora.nerc.ac.uk\/id\/eprint\/2407\/1\/Part_L.pdf<\/dc:identifier><dc:identifier>\n         \n\n  Loudon, T.V..  2000  Geoscience after IT: Part L. Adjusting the emerging information system to new technology.   Computers & Geosciences, 26 (3, Sup). A109-A121.  https:\/\/doi.org\/10.1016\/S0098-3004(00)00047-9 <https:\/\/doi.org\/10.1016\/S0098-3004(00)00047-9>     \n <\/dc:identifier><dc:relation>\n        http:\/\/www.elsevier.com\/wps\/find\/journaldescription.cws_home\/398\/description#description<\/dc:relation><dc:relation>\n        doi:10.1016\/S0098-3004(00)00047-9<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/nora.nerc.ac.uk\/id\/eprint\/2407\/","http:\/\/www.elsevier.com\/wps\/find\/journaldescription.cws_home\/398\/description#description","doi:10.1016\/S0098-3004(00)00047-9"],"year":2000,"topics":["Computer Science","Data and Information","Earth Sciences"],"subject":["Publication - Article","PeerReviewed"],"fullText":"<<<Back to Table of Contents       \nOn to Part M: Business requirements drive the information system, and provide coherent \nframeworks>>> \n \nGeoscience after IT: Part L \n \nAdjusting the emerging information system to new technology \n \nT. V. Loudon \nBritish Geological Survey, West Mains Road, Edinburgh EH9 3LA, U.K. \ne-mail: v.loudon@bgs.ac.uk \n \n \nPostprint of article in Computers & Geosciences, 26 (3A) April 2000, pp. A109-A121 \n \nAbstract - Coherent development depends on following widely used standards that \nrespect our vast legacy of existing entries in the geoscience record. Middleware \nensures that we see a coherent view from our desktops of diverse sources of \ninformation. Developments specific to managing the written word, map content, and \nstructured data come together in shared metadata linking topics and information types. \n \nKey Words - Middleware, digital object identifier, interoperability, ontology, \nmetadata. \n \n \n1. Staying in the mainstream \n \nHaving suggested some long-term user requirements (part K, section 3), we need to \nfind a way forward which does not put earlier work at risk and leaves room to change \ncourse as future trends emerge, securing each step before taking the next. We look at \nsome work in progress that takes a long-term view, although rapid development \nmeans that it is too early to predict which ideas will eventually prevail. Indeed, by the \ntime you read this, some may have been superseded. Nevertheless, we can learn from \nthem, and with citation indexes or other tools to trace forward references, they can \nstill be a useful point to start looking for the best current solution.  \n \nTo be cost-effective, the systems must follow widely used standards. The casual user \nsimply cannot afford to learn techniques which are not of general application. An \ninformation system must be updated periodically, migrating along paths supported \nonly by established IT suppliers. For both reasons, it is better not to stray from the \nmainstream of information technology development.  \n \nIn the mainstream, we can detect the influence of three major tributaries, each from a \nseparate source. They spring from the text-based information of publishers and \nlibrarians; the images and spatial models of geographers and cartographers; and the \nstructured data of knowledge and databases. Different technical approaches \ncharacterize each tributary (L 3 - L 5). \n \n \n \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \n2. User interface and middleware  \n \nAs chronicled in Byte (see for instance, Orfali et al., 1995), it seems to be widely \naccepted that communication will continue developing within a client\/server \nframework, as this makes it possible for each user to access a wide range of \ninformation sources maintained by many providers. This applies within an \norganization where information is shared by cooperating groups through an intranet, \nas well as between organizations.  \n \nThe graphical user interface is evolving into a network user interface (Halfhill, 1997). \nThis has the potential to mediate among diverse repositories, access distributed \nobjects and assemble information from many sources. It can incorporate earlier \ndevelopments, such as SQL databases and groupware as well as document \nmanagement and geographic information systems. A layer of software, sometimes \nreferred to as middleware, can be introduced to shield the user from the complexities \nof the underlying software. It enables a consistent user interface to control a range of \ndiverse systems. Where a complex interface is needed because of the complexity of \nthe operations, the middleware may be bypassed to tackle the problem on its own \nterms. \n \nThe widely adopted point-and-click user interface to the network seems appropriate \nfor access to much geoscience information. A browser can link to narrative text, \nspatial data and interpretations, structured databases, computer models, references to \nmaterial and links to experts. However, browser software based on HTML is \ninadequate for many purposes. For example, in order to integrate narrative, spatial and \nstructured data, we might make use of separate interworking windows for the \ndifferent information types. In this way, the user could view, say, a report, map and \ndatabase side by side, or iconize a window when it is not required. The information in \nthe different windows should share definitions of objects, so that when, say, an \noutcrop is described in the text, its location can be highlighted on the map. \nDescriptions of fossils found there could be illustrated by annotated photographs. The \nwindows\u2019 contents should be synchronized, perhaps through a joint table of contents, \nso that when a new topic is introduced in the text, the map changes to match, and vice \nversa. This opens the prospect of handling compound documents with fully integrated \ninformation types (J 1.8, L 6). Web pages currently rely on HTML for most linkages. \nBecause of the need to integrate information types and maintain two-way links, it is \ntoo limited for a full geoscience network. The more versatile XML - like HTML, a \nsubset of SGML (E 6) - is an obvious future candidate for Web publication. It can \nprovide a consistent user interface, mediating among the various retrieval systems. \n \n3. Text-based information \n \nComputer-mediated communication can cost much less than conventional publication \n(B 1). The calculations take no account of the costs of computer networks, application \nsystems, and training, any more than teaching users to read is included in publication \ncosts. Potentially, however, there are also important scientific advantages. We saw \nearlier (B 1) how publishers were attempting to extend the idea of a scientific journal, \nby providing hypermedia features. Other electronic journals such as D-Lib (D-Lib, \n1995) offer more or less conventional content, but are published on the World Wide \nWeb. Some, such as Byte.com (1994), provide extracts from printed journals, and \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nmost major publishers offer at least tables of contents on the Web (H 2). Some, such \nas PROLA (described next), attempt to provide a preprint, library and archive service. \nFor obvious reasons, IT journals are in the forefront, but all scientific literature is in \nthe line of IT fire (Butler, 1999).  \n \nParts of the physics community, notably in high-energy physics, have made rapid \nprogress in moving to electronic publication. Thomas (1998a, b) reviews the progress \nof the Physical Review On-line Archives Project (PROLA), and similar activities can \nbe monitored at various Web sites.  \n \nThere are three elements to the PROLA vision. The first is the preprint server, which \nprovides rapid publication of results with open access and the opportunity for readers \nto record comments. This has now been in successful operation for some years. The \nsecond element is the peer-reviewed, edited journal. This is seen as essential for \noffering validated, certified statements of accepted progress. The authors need this as \na measure of the value of their contributions, which may determine their career \nprospects. Readers need it to reassure them that the material is of value and widely \naccepted. The edited journal can be published electronically, probably with a \ncompanion paper copy for continuity and to meet the needs of libraries.  \n \nThe third element is the electronic archive of past published papers, with facilities for \nbrowsing, searching and database retrieval. The electronic archive requires constant \nsupport and updating, partly to maintain links and references to and from older \narticles, but mostly to keep up with technical advance. Frequency of access to each \ndocument can be recorded as a useful guide to readers, and could be extended to take \ntheir evaluations into account. Logically, publication would consist of adding each \nnew article to the archive, rather than placing it in a separate electronic journal. But \nback in 1999 that stage had not been reached.  \n \nSo-called legacy information, collected in the past according to earlier standards, can \nbe converted to an electronic form. Conventional printed publications can be scanned \npage by page, and stored, transmitted and displayed or printed as an image of the \noriginal. For many purposes, this will be adequate. Full text can be searched, edited \nand formatted, if need be, by optical character recognition (OCR) from the image, \nkeyboarding from the original, or reusing the initial word processing if it is available \n(C 5). If required, the original layout can, at a cost, be preserved. Also at the cost of \nadditional human effort, the original text can be marked up (D 6) for more detailed \nreference. Well-known projects include Project_Gutenberg (1999), which stores \ndigital text of old documents and JSTOR (1995), which digitizes journals from the \nhumanities. Their methods, contents and costs are described on the Web. Copyright is \na significant constraint on these developments.  \n \nExisting publications must be preserved in their existing form, but in many cases \ncould also be reworked and included in a more comprehensive information system. \nFor example, by archiving current reports in SGML, it becomes easier to categorize \nsmall parts of a report separately, and thus to link them precisely to related documents \nand metadata. Present-day definitions and models for geoscience can only be created \nby specialists, and are likely to remain distinct from those of other disciplines. \nHowever, specialists from other subjects must be able to access and understand \ngeoscience metadata and vice versa. Procedures for recording definitions and models \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nshould therefore conform to global standards. We noted however (K 1.1) that, for \ngood reasons, meaning depends on context. The full subtleties of meaning of old \nrecords may never be translatable into modern usage, but must continue to rely on \nhuman interpretation. \n \nHaving obtained electronic documents, the next step is to consider how they can be \norganized within a repository. The technical design of a digital library is reviewed by \nArms (1995), and set out in more detail by Kahn and Wilensky (1995) and Arms et al. \n(1997). Just as a conventional research library stores more than just books, so the \ndigital library will store many types of digital material, including text, pictures, \nmusical works, computer programs, databases, models and designs, video programs \nand compound works containing many types of information. Unlike a conventional \nlibrary, the digital library can supply information which is not identical to that held in \nstore. For example, a subset of data may be retrieved from a database, or a stored \nfigure field may be supplied as a contour map or a perspective view. Because the \nlibrary functions differently, some new terms are needed. \n \nIn the Kahn-Wilensky architecture, items in the digital library are called digital \nobjects. They are stored in one or more repositories and identified by handles. \nInformation stored in a digital object is called content, which is divided into data and \ninformation about the data, known as properties or metadata. The repositories must \nhave unique names, and the digital object handles must also be unique. Their names \nmust therefore be authorized by designated naming authorities. Depositing and \naccessing objects is accomplished using a defined repository access protocol. A \ntransaction record, associated with the digital object, can record transactions, such \nas the time and date of deposit and of each request for retrieval, the identity of the \nrequesting party, and any applicable terms and conditions, including amount and \nmethod of payment. A mutable digital object, unlike an immutable one, may be \nchanged in certain ways after deposition, and may be designed to change with time. \n \nThe unique identifier or handle is itself a complex topic because, unlike the Uniform \nResource Locator (URL) for accessing Web documents (E 4), it must persist for a \nvery long period, probably much longer than the computer system or the organization \nthat created it. It must be independent of the location at which the information is \nstored, compatible with earlier identification systems such as ISBN (H 2), and capable \nof evolving to meet long-term future needs. It should be able to identify fragments, \ncomposites, copies and versions of the information. These issues are discussed by \nPaskin (1997) and Green and Bide (1998). The Association of American Publishers \nhas collaborated with the work described earlier to specify a Digital Object \nIdentifier (International DOI Foundation, 1999) in an important initiative to track \ncopyright ownership of electronic publications.  \n \nWeb search engines help the user to locate relevant documents (Lynch, 1997), but \ntend to reflect words rather than their significance. The sad tale is told of a search for \na project leader named Dr Cook (SHOE, 1999). A search for a combination of \u201cCook\u201d \nand the project name yielded nothing. Searching for \u201cCook\u201d alone provided over 200 \n000 documents covering everything from haute cuisine to a New Zealand Strait. \nUnlike libraries, the Web was not designed to support the organized publication and \nretrieval of information. A more structured search is possible using metadata to help \nusers to locate relevant information, and to assess its reliability and suitability for their \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \npurposes. An annotated list of current Web documents on metadata is available \n(IFLA, 1995).  \n \nThe Dublin Core (DCMI, 1998) is a leading candidate for recording metadata that \nhelps users to find items on the Internet - the equivalent of the rules for a library's card \nindex catalog. It is a cut-down equivalent of cataloging schemes currently used by \nlibrarians (Miller, 1996). It includes such information as subject, title, author, \npublisher, date, spatial and temporal coverage, and is intended to be simple enough \nfor the author to supply the required metadata. Links can be included to documents \nwhich define the terms used. Rust (1998) mentions some limitations. It is one of \nseveral metadata packages, for example, for terms and conditions, archival \nmanagement, administrative metadata, which will evolve to support the digital library \nas modules within the Resource Description Framework (Miller, 1998). \n \nThe G7 nations and the European Commission have organized a joint project to \nprovide an information locator service with an emphasis on global environmental \ninformation (GILS, 1997). They extended the Government Information Locator \nService, which is used in the US Federal Clearinghouses and State agencies, and \nrenamed it the Global ILS (Christian, 1996). GILS, which is built on the Z39.50 \nstandards mentioned in H 2, is designed to make it easier to find objects, in electronic \nor any other form, including documents, people and specimens. \n \nThe examples in this section suggest how geoscience can follow mainstream \ndevelopments that stem from conventional document handling. Publishers and \nlibrarians are extending the concept of a document to include electronic content, thus \naltering ideas about what constitutes publication. During the transitional period, \ngeoscientists may have to learn again how to find information and present their \nresults, not once but many times. \n \n4. Spatial information \n \nGeoscience information is generally linked to geographic location, and catalogers \nregard this as an important aspect of the metadata and an aid to retrieval. The \nlibrarians\u2019 approach has been to catalog geographical areas by name or by enclosing \nrectangles specified by maximum and minimum coordinates. Some services, such as \nthe Spatial Information Enquiry Service (SINES) run by the British Ordnance Survey, \nfollowed the same route. Although it adds value by bringing together many sources, \nthe copies of metadata supplied by the information holders soon get out of date. \n \nGeographic Information Systems (GIS) can handle the precise boundaries of spatial \nobjects. Their three-dimensional form can be interpolated and stored (Gocad, 2000) \nand made available through standard interfaces such as VRML (Moore et al., 1999; \nWeb3D Consortium, 1999; E 6). The main GIS vendors offer products that make it \npossible to visualize these objects as maps available to a Web browser. Information is \navailable on their Web sites (Culpepper, 1998). It is therefore possible to give general \noverviews of the geographical distributions of datasets on the World Wide Web, and \nfor the user to select points or objects for retrieval of additional information. It can \nalso be possible to provide more detailed information from a local GIS using the same \nuser interface. Given adequate bandwidth and an appropriate system design that \nensures that the user is not overwhelmed with needless detail, electronic delivery of \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nmaps (EDINA, 1999) and satellite imagery (Microsoft, 1999) is set to proliferate. The \nWeb sites of the geography departments of well-known universities give references to \nother examples. The illustrations (Fig. 1) from the British Geological Survey \ngeoscience index show how the user can zoom in on an area of interest, select an item \nand obtain additional data about it. \n \n \n \nFig. 1. Finding data with a spatial geoscience index. The area of interest is selected from an index map \nor a gazetteer. Specific topics, here borehole locations, are selected for display on the detailed map. \nInformation referring to an individual item, such as scanned images of a borehole log, can then be \ndisplayed in their spatial context. Extracts from the BGS Geoscience Data Index. British Geological \nSurvey \u00a9NERC. All rights reserved. Base maps reproduced by kind permission of the Ordnance \nSurvey \u00a9 Crown Copyright NC\/99\/225. \n \nUsers, however, may wish to assemble spatial information from many sources, not \njust from one proprietary system, and to manipulate that information with GIS \nfacilities on their own client computers. As with library documents, problems arise in \nfinding and assessing data because of inadequate metadata, and problems of obtaining \nand integrating datasets because of inadequate middleware and failure to conform to \nstandards. Current standards are reviewed by Albrecht (1999) and Huber and \nSchneider (1999). Standards for representing geologic map information are being \nextended through a collaborative effort led and documented by the United States \nGeological Survey (1998). \n \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nThe United States government is funding a National Spatial Data Infrastructure \n(Federal Geographic Data Committee, 1998) as part of their National Information \nInfrastructure. The creation of the National Geospatial Data Clearinghouse (1999) is \npart of this activity. Its aim is \u201cto make data easier to find by supporting the evolution \nof common means to describe and share geospatial data sets.\u201d The data sets and \nmetadata are held and maintained by those responsible for them, but accessible \nthrough the common standards. Other national counterparts, such as the UK National \nGeospatial Data Framework, propose a similar approach (NGDF, 1999). \n \nThe Open GIS Consortium (1996) is a consortium of the major GIS vendors and users \nwhich is working on the development of middleware (L 2), to isolate users from the \ndetails of lower layers of software. They aim to provide an Internet interface which is \n\u201cnot limited to the hyperlink and scrolling page mode of operation typical of \nNetscape, but supports the rich windowing graphics familiar to GIS users\u201d. They have \nprepared a detailed guide which includes a full account of the underlying concepts \n(Buehler and McKee, 1998). It sets out a framework for interoperability, defined as \n\u201ca user's or a device's ability to access a variety of heterogeneous resources [data and \nprograms] by means of a single, unchanging operational interface.\u201d The aim is that \ngeospatial objects and the computer processes to manipulate them, obtained from \nmany sources, should all work together, supplying results to any of a wide range of \ndesktop clients. They have developed the Open Geodata Interoperability Specification \n(OGIS) - \u201ca specification for object-oriented definitions of geodata that will enable \ndevelopment of true distributed geoprocessing across large networks as well as \ndevelopment of geodata interoperability solutions\u201d (Schell et al., 1995). \n \nUS Military proposals point to a significant divergence from the librarians\u2019 approach \n(Larsen, 1998; GeoWorlds, 1998).  One proposal is, for reasons of cost and efficiency, \nto replace their current huge volume of documents (maps, images and terrain models) \nwith a \u201cframework\u201d spatial database with global coverage including the ocean floor. \nThey intend that users should express their requirements in terms of area and topic, \nrather than named publications and other products. The response will provide data for \nthe required area at the resolution and for the topics required. These could include \nimagery, terrain models and \u201cfeatures\u201d traced from the original imagery, such as \nroads, rivers, and population centers. Although where possible the basic data is highly \ndetailed (up to one-meter resolution from orthorectified photography), it would \nusually be supplied in a compressed form of appropriate resolution, generated from \nthe scale-free basic data.  The database could thus no longer be regarded as a library \nof discrete documents. An example of such an approach, coping with heavy usage of a \nlarge database, can be seen in TerraServer (Microsoft, 1998). \n \nThe flexibility of handling spatial data within a GIS means that it must bulk large in \nthe future of geoscience. Internet links to Web browsers already provide worldwide \naccess to GIS systems, which are becoming more robust and easier to use. There is \nsome conflict between the discrete documents described in section 3 and the potential \nto explore spatial data across project boundaries. There are corresponding problems in \nregarding a contribution to a GIS as a publication. In principle, however, a segment of \na GIS could remain in that environment while also being published as an integral part \nof a larger text-based document. \n \n \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \n5. Structured data \n \nWithin a project, data (including quantitative and indexing information) are often \ncollected as tables. This encourages consistency, with the same variables being \nmeasured or recorded in the same way at many points. Detailed metadata, with \ndefinitions and operational procedures, can help to ensure that the data are collected \nconsistently (H 3). Each project, however, has its own business setting and \nbackground. Therefore, there may be subtle as well as major differences between \nprojects, which make it difficult to compare their results. The metadata can help to \ntranslate between alternative terms and thus aid integration of data sets, although they \ndo not provide the deeper understanding that can be gleaned from written accounts. \nGlobal projects, for instance, in seismology, geomagnetism and oceanography, rely on \ndetailed standards so that many investigators worldwide can contribute to a shared \ndatabase. \n \nWorkers in machine intelligence have carried this process further, with the aim of \ncreating large knowledge bases, which not only contain information, but also the \nmeans of making logical deductions from it. As part of this an \u201contology\u201d is prepared, \ndefined as \u201ca specification of a conceptualization\u201d (Gruber, 1997). A \nconceptualization is \u201can abstract, simplified view of the world that we wish to \nrepresent for some purpose.\u201d The ontology defines the objects, concepts and other \nentities, and the relationships between them. It is analogous to the data dictionaries \nand data models (H 3) that define the terms in a database and their relationships. In \ngeology, for example, one might expect to find a definition of, say, Millstone Grit, in \nterms that the Stratigraphic Lexicon might use, some means of defining its \nhierarchical and positional relationships within the stratigraphic column, and an \nindication of the scope, validity and provenance of the term (Fig. 2). \n \nOntologies are an experimental means of labeling Web documents, using Simple \nHTML Ontology Extensions (SHOE, 1999), in order to make searches by web robots \nand intelligent agents more effective. Ontologies also appear in ambitious schemes, \nsuch as Ontolingua, for knowledge sharing and reuse (Stanford KSL Network \nServices, 1996). A large working implementation of such an approach, involving a \nmetathesaurus giving information about specific concepts and a semantic network \ndefining relationships, is described at the US National Library of Medicine web site \n(National Library of Medicine, 1998). \n \nA less rigorous scheme for assembling definitions of concepts is the virtual \nhyperglossary advocated by Murray-Rust and West (1998). Glossaries can be \nsubmitted and revised on any subject from any source, subject to editorial scrutiny. It \nis accepted that vocabularies overlap, and words do not necessarily carry the same \nmeaning, in different subjects. The words are arranged in alphabetical lists: click on \nthe word for its definition, relationships and other relevant information and \nreferences. Its bias is towards organic chemistry, and there are many molecular \ndiagrams of nodes and links: point to the node to see the name of the component, \nclick to see its definition. There is clearly an analogy with entity-relationship \ndiagrams. \n \n \n \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \n \n \n \nFig. 2. Metadata for a stratigraphic name. British Geological Survey \u00a9NERC. All rights reserved. \nMore on the BGS Stratigraphic Lexicon at http:\/\/www.bgs.ac.uk\/scripts\/lexicon \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nThe most coherent and extensive data model to include aspects of geology and \ngeophysics is the Epicentre Model (see Fig. 5) of the Petrotechnical Open Software  \nCorporation (POSC, 1993), much of which is now available on the Web (POSC, \n1999). POSC is a consortium where major oil companies are represented, together \nwith some IT companies, surveys and other organizations. An objective is to save \nmany tens of millions of dollars every year by sharing information repositories, and \naccessing data more efficiently. This requires standards for interoperability in oil \nexploration and production data. The Epicentre Model has a number of sub-models \nfor such topics as: spatial models, geographical referencing, cartography; stratigraphy \n(litho-, chrono-, bio- and seismo-); materials and substances, rocks, minerals and \nfluids; stratigraphical and seismic interpretations; geophysics (seismic, gravity, \nmagnetic, electrical); wells, downhole logs, samples and cores; remote sensing; \norganizations, documents, personnel and activities; equipment, procedures and \ninventories; reservoir characteristics; computer facilities, software, users and data \nadministration. Data dictionaries and entity-relationship diagrams are used in all of \nthem to provide a definition of the common currency in which geologists express their \nideas. The information is also supplied on CD-ROM for those with uncomfortably \nslow Internet links. The model is compatible with more general international \nstandards, and can thus support searching and integration of data within and beyond \ngeoscience. \n \nAs with data in a GIS, quantitative measurements may be held within a rigorously \nstructured database. The database may contain contributions from many sources that \nmeet the standards defined in the metadata. They may be referenced from a text \ndocument, thus being fully reviewed and seen as part of a publication. Computer \nprograms can follow similar procedures. For example, the International Association \nfor Mathematical Geology makes the programs and data described in their \npublications freely available for downloading to the user\u2019s computer (IAMG, 1995). \nWe catch a first glimpse here of geoscience documents, published complete with links \nto their electronic appendages, placed in their business, spatial, and quantitative \ncontext through shared standards described in metadata. \n \n6. Integration \n \nFuture information technology should have no boundaries, and therefore few features \nspecific to geoscience, whose needs should be identified and met within the \nmainstream. Levels of human memory, such as semantic, episodic and short-term, \nhave their counterparts in the information system.  \n \n6.1 Sharing metadata \n \nAt a semantic level, we have seen (L 3 - L5) how metadata developed. From the \nlibrary background came the concepts of the digital library architecture and of a \nclassification of knowledge, for cataloging documents and searching by concept or \nkeyword. From geographic information systems came the spatial model for describing \nthe location of objects in space, their spatial pattern and relationships, and the active \nmap for spatial search. From database management came data dictionaries, data \nmodels, structures to reduce redundancy, and query languages for retrieval by \ncategories and quantitative values. From knowledge base work came the ontology to \n\u201cspecify a conceptualization\u201d. As each group generalizes their work into a wider IT \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \ncontext, the cataloging systems, data models, spatial models and ontologies begin to \noverlap and amalgamate. Examples, notably from POSC (1999), show how a shared \nframework can operate and how users can benefit from large-scale, collaborative \nprojects.  \n \nMetadata are concerned with standards; classification and nomenclature; patterns of \ninvestigation; and data models and definitions of object classes. Object classes (H 5) \nform a hierarchy, classes at lower levels inheriting properties from those at a higher \nlevel. A Millstone Grit object, for instance, would inherit appropriate properties that \napplied to the Carboniferous as a whole (see Fig. 2). Hierarchies of terms are familiar \nin geological classifications, for example, in paleontology, petrography, \nlithostratigraphy, chronostratigraphy, and in spatial subdivisions. Each of these can be \nregarded as a topic, and a data model (H 3) can depict the relationships of classes \nwithin that topic (see Fig. 5). At a higher hierarchical level, another data model might \nshow relationships between topics. Internationally accepted definitions of objects and \nprocesses, their relationships, and the hierarchy of object classes, are all vital to a \nwidely shared understanding of the geoscience record.  \n \nThe definitions and characteristics of geoscience object classes are (or should be) the \nsame regardless of information type or mode of representation. A formation, a fossil, \nor a logging tool, should be the same whether it is illustrated in a diagram, drawn on a \nmap, listed in a register or described in a report. Metadata should be kept distinct from \ndocuments recording scientific findings. This allows more appropriate management \nand more flexible communication and reuse. \n \n6.2 Linking topics \n \nA striking feature of the POSC Epicentre Data Model is its separation into self-\ncontained topics. Each data model represents one topic within the information base, \nand should therefore provide users with access routes to information which reflects \ntheir specific interests. For example, a spatial model might be appropriate where \ninformation was required about a particular point or area. A data model for \npaleontology would be appropriate where a particular species is of interest. The two \nmodels should be usable together where fossils of that species in a particular area are \nrequired. The business model (where business is used in the broad sense to identify \nthe objectives and procedures for a study) might also narrow the search by guiding \nusers to studies with similar objectives to their own. \n \nWithin a project, links between topics tend to involve interpretation, often by \ncomparing visualizations of spatial models, each arising from a different topic, and \nrelying on human perception, intuition and background knowledge. For example, data \nfrom a seismic survey might be assembled and processed to provide a contour map of \na seismic horizon. Downhole logs might provide a similar map of a nearby formation \ntop, and the two maps might be compared by eye. Individual seismic values, however, \nare not compared with individual well picks (G 2).  \n \nThe spatial patterns and relationships of the two topics are of interest, although \ndeciphering each pattern is a task performed largely within the topic area. \nNevertheless, the life of the geoscientist is made much easier by an interface which is \nsimilar in all topic areas and enables results from different topics to be assembled and \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \ncompared as compatible spatial models (G 2). Spatial models which describe \ngeometric forms in terms of points, lines, areas and volumes can be positioned \nrelative to the Earth. The geometric objects can then be linked to geological or other \nfeatures, so that, for example, a line represents a borehole, and surfaces represent the \nformation tops that it intersects. \n \nAn object describing a formation could be linked (with reference to a stratigraphic \nmodel) to formations above and below, and to broader, narrower and related \nstratigraphic units. It could be linked (with reference to a spatial model) to adjacent, \nsmaller and larger areas. This would make it possible to move from summary to detail \nor vice versa, on the basis of level of spatial resolution, stratigraphic discrimination or \nboth. At the cost of a more structured and therefore less flexible framework, \nrepetition, redundancy and conflict within the information can be reduced. \n \nThe tools for doing this are preliminary analysis to match the information to a \ncoherent structure, and markup languages to implement that structure. The Extensible \nMarkup Language (XML) makes it possible to categorize information, such as \nsections of a report, by tying them to metadata, thus superimposing ontological \nclassifications on the sections of text (Bosak, 1997). XML also provides a means of \nbuilding objects into more than one hierarchy, thus making the traditional concept of a \nself-contained document unnecessary. Instead, reports explaining maps, for example, \ncould avoid internal boundaries, like the seamless map (L 4), with documents created \nas required for specific areas, topics and resolutions. The Meta Content Framework \n(MCF), which uses XML, explores such a framework, aiming to structure Web \nhypermedia to make it \u201cmore like a library and less like a messy heap of books on the \nfloor\u201d. \n  \n6.3 Linking information types \n \nObvious in the user interface, but extending to processes and repositories, is another \ndistinction - by information types. Text documents dominate the literature. Maps and \nstratigraphic tables in large format are published separately and independently. Data \nthat support the written or mapped interpretation may be archived, frequently as a \ncomputer file, and made available on request, rather than appearing in full in the \nscientific literature.   \n \nFig. 1 of part I is redrawn as Fig. 3 to show these components of the information \nsystem. The user interface is divided by information type into three windows. It \nrepresents one of a large number of documents collected for different purposes, each \nheld separately in the repository. We can visualize them lying behind the \nrepresentative. In the higher levels of the repository area in the diagram are the \nmetadata and the more generalized information arising from abstraction and \nexplanation of the datasets. Beneath the repository are shown the tools for processing \nthe information, possibly learned techniques or computer programs. \n \nThe components of the system are seldom totally distinct. Data cannot be entirely \nseparated from explanation, and abstraction is an essential part of observation (B 4.2). \nOverlap is even more obvious in other cases, such as between information types. \nMaps may be published separately, but are likely to include text comments and \npossibly tables of data. Conversely, maps are included as diagrams in books and \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nreports. Processes and data are frequently inextricably joined. The picture of the \ninformation system is therefore misleading if taken too literally. It is an idealization \nthat has significant features in common with reality. It is a metaphor or model (J 2.2) \nwhich may yield useful insights. The diagram is obviously not part of a rigorous \nanalysis, but can be regarded simply as an aid to remembering the chosen components \nand their relationships. \n \n \nFig. 3. Some components of the information system. Documents containing various information types \nare stored in the repository, together with generalized summaries, and metadata which describe the \ndocument and define shared vocabulary and standards. Processes to analyze and manipulate the \ninformation are shown separately, as are the scientists\u2019 activities (see Fig. 1 in part M) which generate \nand evaluate the documents by investigation of the real world. \n \nIt should be possible to search across information types. For example, it should be \nfeasible: to define an area on an electronic map; find the formations within it; retrieve \ntext descriptions of the formations; locate boreholes intersecting them; retrieve their \nlogs from an image repository, and formation thicknesses and contouring software \nfrom a database (Fig. 4). \n \nAt the semantic level, metadata can define object classes and describe their \nrelationships. At the episodic level (I 4), occurrences (instances) of objects are linked \ntogether, along with processes, for a different purpose - to tell a story (J 1.2). They are \nlinked within a document, where \u2018document\u2019 is defined broadly to include any \ncombination of multimedia in which a collection of objects and processes are tied \ntogether for some purpose, probably referring to a single project (D 6). A sequence of \nevents linking the objects may be recorded in narrative text. The quantitative values of \ntheir properties or composition may be tabulated as datasets, analyzed statistically (F), \nvisualized graphically (Cleveland, 1993) and thus made available to accurate short-\nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nterm memory. Their location, form and spatial relationships in geological space-time \nmay be shown as three-dimensional images and maps, regarded as just another form \nof visualization (MacEachren, 1998; Kraak, 1999; Sheppard, 1999). Other forms of \nmultimedia, such as video, may identify and illustrate other characteristics. The \ncompound document may include any or all of these, possibly following different \nmodes of thought (J 1.7), in synchronized windows that can be viewed side by side. \n \n \n \nFig. 4. Retrieving data with GIS and DBMS. Some GIS systems, such as ArcView used here with the \nBGS Geoscience Data Index, make it possible to combine topic selection, spatial selection and SQL \nqueries, displaying the results on the map. British Geological Survey \u00a9NERC. All rights reserved. \nBase maps reproduced by kind permission of the Ordnance Survey \u00a9 Crown Copyright NC\/99\/225. \n \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nSeveral software systems may be needed to manage and manipulate the components \nof a compound document. For example, a document describing a geophysical survey \nmight include text held in a document management system, spatial models held in a \nGIS, and data held in a relational database. Examples of software tools that might be \nrequired include: project management software, entitlements register software, a \ndocument management system, RDBMS and ODBMS, GIS, application programs \n(maybe Java-mediated), hypermedia systems. The information types could be \nmanaged separately but linked as a single, higher-level object. This could be seen as a \ntradable object, available to others as a self-contained item, containing appropriate \napplication programs and information about charges and availability. \n \n \n \nFig. 5. Diagram from the POSC Epicentre model. Various entities, or object classes, are grouped into \ntopic diagrams. This is part of one diagram (EMG1: Geologic Features) illustrating the Epicentre 2.2 \nData Model. When you move the mouse over entity boxes or relationships, adjacent frames offer \ndefinitions, examples, and cross-references to other occurrences in the overall model and to other \nentities within the topic. You can move freely between the diagram and text accounts of the entities and \ntheir components, or to more general or more detailed documentation.  \nReproduced by permission of the Petrotechnical Open Software Corporation. More at \nhttp:\/\/www.posc.org \n \nThe future scenario that emerges is of the geoscientist working within a well-defined \nstandardized framework of concepts, terms and definitions. Documents, perhaps \nwritten in a specialized dialect of a markup language (J 1.8), weave together records \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nof observations and interpretations in the context of one or more data models. \nNarrative text, spatial data and interpretations, structured data, computer models, \nreferences to material and links to experts are handled together and the results \ncommunicated to any desktop. Hypermedia provide the flexibility for integrating \ndifferent information types and different modes of thought. The ability to follow \nthreads of reasoning through all information types in the document should be matched \nby the ability to clarify their significance by instant access to appropriate metadata. \nCitations from the metadata should provide the opportunity to follow up other \nreferences to similar objects, or to explore relationships within the metadata to \nidentify related object classes (see Fig. 5). The rapid delivery of information through \nIT allows the use of accurate short-term human memory to control computer \nprocedures by interaction, based on the user's fuzzy but extensive background \nknowledge. Use by non-specialists could be aided by access to metadata and software \nagents, possibly reducing the need to rewrite the same material for different \naudiences. \n \nUnfortunately, maintenance costs for compound documents are high, because \ntechnology is on the upward leg of an S-curve (see Fig. 1 of K). The rapid evolution \nof technology means that records must be continually modified to match new \nstandards and software. Librarians are accustomed to books and journals, printed with \nstable technology, which retain their original, usable form for many decades with \nnegligible maintenance costs. Techniques for handling electronic text are well \nestablished, but few publishers or librarians have experience of managing documents \nwhich also require support from GIS, DBMS and other software systems. Until IT \nreaches a more stable state, this must slow the acceptance of compound documents \nand make it inadvisable to rely on their retention in archives. Their initial growth may \nbe within a different framework (M 2). \n \n7. References \n \nAlbrecht, J., 1999. Geospatial information standards. A comparative study of \napproaches in the standardisation of geospatial information. Computers & \nGeosciences, 25, 9-24. \n \nButler, D., 1999. The writing is on the web for science journals in print. Nature, 397 \n(6716), 195-200. \n \nCleveland, W.S., 1993. Visualizing Data. Hobart Press, Summit, New Jersey, 360pp. \n \nHuber, M., Schneider, D., 1999. Spatial data standards in view of models of space and \nthe functions operating on them. Computers & Geosciences, 25, 25-38. \n \nKraak, M.-J., 1999. Visualization for exploration of spatial data. International Journal \nof Geographical Information Science, 13(4), 285-288. \n \nMoore, K., Dykes, J., Wood, J., 1999. Using Java to interact with geo-referenced \nVRML within a virtual field course. Computers & Geosciences, 25 (10), 1125-1136. \n \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nPOSC, 1993. Petrotechnical Open Software Corporation, Software Integration \nPlatform Specification. Epicentre Data Model, version 1. Volume 1: Tutorial. \nPrentice-Hall, Englewood Cliffs, New Jersey. \n \n7.1 Internet references \n \nArms, W.Y., Blanchi, C., Overly, E.A., 1997. An architecture for information in \ndigital libraries. D-Lib Magazine, February 1997. \nhttp:\/\/www.dlib.org\/dlib\/february97\/cnri\/02arms1.html \n \nArms, W.Y., 1995. Key concepts in the architecture of the digital library. D-Lib \nMagazine, July 1995. http:\/\/www.dlib.org\/dlib\/July95\/07arms.html \n \nBosak, J., 1997. XML, Java, and the future of the Web. \nhttp:\/\/sunsite.unc.edu\/pub\/sun-info\/standards\/xml\/why\/xmlapps.htm \n \nBray, T. and Guha, R.V., 1998. An MCF tutorial. \nhttp:\/\/www.textuality.com\/mcf\/MCF-tutorial.html \n \nBuehler, K., McKee, L. (editors), 1998. The OpenGIS guide: Introduction to \nInteroperable Geoprocessing. http:\/\/www.opengis.org\/techno\/guide.htm \n \nByte.com, 1994. Byte.com. http:\/\/www.byte.com \n \nChristian, E.J., 1996.  GILS: What is it? Where\u2019s it going? D-Lib Magazine, \nDecember 1996. http:\/\/www.dlib.org\/dlib\/december96\/12christian.html \n \nClearinghouse, 1999. Information resource page (Federal Geographic Data \nCommittee). http:\/\/www.fgdc.gov\/clearinghouse\/index.html \n \nCulpepper, R.B., 1998. Weave maps across the Web 1998 edition. \nhttp:\/\/www.geoplace.com\/gw\/1998\/1198\/1198map.asp \n \nDCMI, 1998. Dublin Core metadata initiative, home page. http:\/\/purl.oclc.org\/dc\/ \n \nD-Lib, 1995. D-Lib Magazine. The magazine of digital library research. Corporation \nfor National Research Initiatives, Reston, Virginia. http:\/\/www.dlib.org \n \nEDINA, 1999.  EDINA Digimap: Online Mapping Service. \nhttp:\/\/edina.ed.ac.uk\/digimap\/ \n \nFederal Geographic Data Committee, 1998. NSDI (National Spatial data \nInfrastructure). http:\/\/fgdc.er.usgs.gov\/nsdi\/nsdi.html \n \nGILS, 1997.  Global information locator service. http:\/\/www.g7.fed.us\/gils\/index.html \n \nGeoWorlds, 1998. GeoWorlds home page. http:\/\/lobster.isi.edu\/geoworldspubli\/ \n \nThe Gocad Consortium.  http:\/\/pangea.stanford.edu\/gocad\/gocad.html \n \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nGreen, B., Bide, M., 1998. Unique identifiers: a brief introduction. \nhttp:\/\/www.bic.org.uk\/uniquid \n \nGruber, T., 1997. What is an ontology? http:\/\/www-ksl.stanford.edu\/kst\/what-is-an-\nontology.html \n \nHalfhill, T.R., 1997. Network-centric user interfaces are coming to PCs as well as to \nnetwork computers. Byte, July 1997. http:\/\/www.byte.com\/art\/9707\/sec5\/art1.htm \n \nIAMG, 1995. Computers & Geosciences Editor\u2019s Home Page.  \nhttp:\/\/www.iamg.org\/CGEditor\/index.htm \n \nIFLA, 1995. Digital libraries: metadata resources. International Federation of Library \nAssociations and Institutions, The Hague, Netherlands. \nhttp:\/\/www.ifla.org\/II\/metadata.htm \n \nInternational DOI Foundation, 1999. The Digital Object Identifier System. \nhttp:\/\/www.doi.org\/articles.html \n \nJSTOR, 1995. Journal storage: redefining access to scholarly literature. \nhttp:\/\/www.jstor.org\/ \n \nKahn, R., Wilensky, R., 1995. A framework for distributed digital object services.  \nDocument cnri.dlib\/tn95-01, Corporation for National Research Initiatives. \nhttp:\/\/WWW.CNRI.Reston.VA.US\/home\/cstr\/arch\/k-w.html \n \nLarsen, R.L., 1998. Directions for Defense Digital Libraries. D-Lib Magazine, \nJuly\/August 1998.  http:\/\/www.dlib.org\/dlib\/july98\/07larsen.html \n \nLynch, C., 1997. Searching the Internet. Scientific American, March 1997. \nhttp:\/\/www.sciam.com\/0397issue\/0397lynch.html \n \nMacEachren, A.M., 1998. Visualization - cartography for the 21st century. \nInternational Cartographic Association Commission on Visualization conference, \nMay 1998, Warsaw, Poland. http:\/\/www.geog.psu.edu\/ica\/icavis\/poland1.html \n \nMicrosoft, 1998. Microsoft TerraServer. http:\/\/terraserver.microsoft.com\/default.asp \n \nMiller, E., 1998. An introduction to the Resource Description Framework. D-Lib \nMagazine, May 1998. http:\/\/www.dlib.org\/dlib\/may98\/miller\/05miller.html \n \nMiller, P, 1996. Metadata for the masses - describes Dublin Core and means by which \nit can be implemented. Ariadne (the Web Version) Issue 5 (ISSN: 1361-3200), \nSeptember 1996. http:\/\/www.ariadne.ac.uk\/issue5\/metadata-masses\/ \n \nNational Library of Medicine, 1998. Fact Sheet: UMLS (Unified Medical Language \nSystem) semantic network. http:\/\/www.nlm.nih.gov\/pubs\/factsheets\/umlssemn.html \n \nMurray-Rust, P., West, L., 1998. Virtual hyperglossary (VHG). \nhttp:\/\/www.vhg.org.uk\/ \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \n \nNGDF, 1999-. National Geospatial Data Framework. http:\/\/www.ngdf.org.uk\/ \n \nOpen GIS, 1996. Intergalactic geoprocessing middleware. GIS World, March 1996. \nhttp:\/\/www.opengis.org\/techno\/articles\/mdleware.htm \n \nOrfali, R., Harskey, D., Edwards, J., 1995. Intergalactic Client\/Server Computing. \nByte, April 1995. http:\/\/www.byte.com\/art\/9504\/sec11\/art1.htm \n \nPOSC, 1999. POSC Specifications - Epicentre 2.2, upgrade to version 2.2.2. \nPetrotechnical Open Software Corporation, Houston, Texas. http:\/\/www.posc.org\/ \n \nPaskin, N., 1997. Information identifiers. Learned Publishing, vol 10, no.2, pp 135-\n156 (April 1997). \nhttp:\/\/www.elsevier.com:80\/inca\/homepage\/about\/infoident\/Menu.shtml \n \nProject_Gutenberg, 1999. Sailor\u2019s Project Gutenberg Server, home page.  \nhttp:\/\/www.gutenberg.org\/ \n \nRust, G., 1998. Metadata. The right approach. An integrated model for descriptive and \nrights metadata in e-commerce. D-Lib Magazine, July\/August 1998. \nhttp:\/\/www.dlib.org\/dlib\/july98\/rust\/07rust.html \n \nSHOE, 1999. Simple HTML ontology extensions. \nhttp:\/\/www.cs.umd.edu\/projects\/plus\/SHOE\/index.html \n \nSchell, D., McKee, L. and Buehler, K., 1995. Geodata interoperability - a key NII \nrequirement. White paper submitted to NII 2000 Steering Committee, May 1995. \nhttp:\/\/www.opengis.org\/techno\/articles\/nii2000.htm \n \nSheppard, S.R.J., 1999. Visualization software brings GIS applications to life. \nGeoWorld, March 1999. http:\/\/www.geoplace.com\/gw\/1999\/0399\/399life.asp \n \nStanford KSL Network Services, 1996. Sites relevant to ontologies and knowledge \nsharing. http:\/\/ksl-web.stanford.edu\/kst\/ontology-sources.html \n \nThomas, T., 1998a. Physical Review Online Archives (PROLA). D-Lib Magazine, \nJune 1998. http:\/\/www.dlib.org\/dlib\/june98\/06thomas.html \n \nThomas, T., 1998b. Archives in a new paradigm of scientific publishing: Physical \nReview Online Archives (PROLA). D-Lib Magazine, May 1998. \nhttp:\/\/www.dlib.org\/dlib\/may98\/05thomas.html \n \nUnited States Geological Survey, 1998. Digital geologic map data model. \nhttp:\/\/geology.usgs.gov\/dm\/ \n \nWeb3D Consortium, 1999. The VRML Repository.  \nhttp:\/\/www.web3d.org\/vrml\/vrml.htm \n \n \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \nLoudon, T.V., 2000. Geoscience after IT: Part L (postprint, Computers & Geosciences, 26(3A)) \n \n \n \n \nDisclaimer: The views expressed by the author are not necessarily those of the British \nGeological Survey or any other organization. I thank those providing examples, but should \npoint out that the mention of proprietary products does not imply a recommendation or \nendorsement of the product. \n \n<<<Back to Table of Contents       \nOn to Part M: Business requirements drive the information system, and provide coherent \nframeworks>>> \n"}
{"doi":"10.1016\/j.ins.2004.02.026","coreId":"122160","oai":"oai:eprints.bbk.ac.uk.oai2:351","identifiers":["oai:eprints.bbk.ac.uk.oai2:351","10.1016\/j.ins.2004.02.026"],"title":"Neuro-fuzzy knowledge processing in intelligent learning environments for improved student diagnosis","authors":["Stathacopoulou, R.","Magoulas, George D.","Grigoriadou, M.","Samarakou, M."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2005","abstract":"In this paper, a neural network implementation for a fuzzy logic-based model of the diagnostic process is proposed as a means to achieve accurate student diagnosis and updates of the student model in Intelligent Learning Environments. The neuro-fuzzy synergy allows the diagnostic model to some extent \"imitate\" teachers in diagnosing students' characteristics, and equips the intelligent learning environment with reasoning capabilities that can be further used to drive pedagogical decisions depending on the student learning style. The neuro-fuzzy implementation helps to encode both structured and non-structured teachers' knowledge: when teachers' reasoning is available and well defined, it can be encoded in the form of fuzzy rules; when teachers' reasoning is not well defined but is available through practical examples illustrating their experience, then the networks can be trained to represent this experience. The proposed approach has been tested in diagnosing aspects of student's learning style in a discovery-learning environment that aims to help students to construct the concepts of vectors in physics and mathematics. The diagnosis outcomes of the model have been compared against the recommendations of a group of five experienced teachers, and the results produced by two alternative soft computing methods. The results of our pilot study show that the neuro-fuzzy model successfully manages the inherent uncertainty of the diagnostic process; especially for marginal cases, i.e. where it is very difficult, even for human tutors, to diagnose and accurately evaluate students by directly synthesizing subjective and, some times, conflicting judgments","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.bbk.ac.uk.oai2:351<\/identifier><datestamp>\n      2016-12-02T13:23:54Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D7363686F6F6C73:73626569:63736973<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      657072696E745F7374617475733D61726368697665<\/setSpec><\/header><metadata><rioxx xmlns=\"http:\/\/www.rioxx.net\/schema\/v2.0\/rioxx\/\" xmlns:ali=\"http:\/\/ali.niso.org\/2014\/ali\/1.0\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:dcterms=\"http:\/\/purl.org\/dc\/terms\/\" xmlns:rioxxterms=\"http:\/\/docs.rioxx.net\/schema\/v2.0\/rioxxterms\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.rioxx.net\/schema\/v2.0\/rioxx\/ http:\/\/www.rioxx.net\/schema\/v2.0\/rioxx\/rioxx.xsd\" ><ali:free_to_read>\n    \n      <\/ali:free_to_read><dc:description>In this paper, a neural network implementation for a fuzzy logic-based model of the diagnostic process is proposed as a means to achieve accurate student diagnosis and updates of the student model in Intelligent Learning Environments. The neuro-fuzzy synergy allows the diagnostic model to some extent \"imitate\" teachers in diagnosing students' characteristics, and equips the intelligent learning environment with reasoning capabilities that can be further used to drive pedagogical decisions depending on the student learning style. The neuro-fuzzy implementation helps to encode both structured and non-structured teachers' knowledge: when teachers' reasoning is available and well defined, it can be encoded in the form of fuzzy rules; when teachers' reasoning is not well defined but is available through practical examples illustrating their experience, then the networks can be trained to represent this experience. The proposed approach has been tested in diagnosing aspects of student's learning style in a discovery-learning environment that aims to help students to construct the concepts of vectors in physics and mathematics. The diagnosis outcomes of the model have been compared against the recommendations of a group of five experienced teachers, and the results produced by two alternative soft computing methods. The results of our pilot study show that the neuro-fuzzy model successfully manages the inherent uncertainty of the diagnostic process; especially for marginal cases, i.e. where it is very difficult, even for human tutors, to diagnose and accurately evaluate students by directly synthesizing subjective and, some times, conflicting judgments.<\/dc:description><dc:format>application\/pdf<\/dc:format><dc:identifier>http:\/\/eprints.bbk.ac.uk\/351\/1\/Binder1.pdf<\/dc:identifier><dc:language>en<\/dc:language><dc:publisher>Elsevier<\/dc:publisher><dc:source>0020-0255<\/dc:source><dc:subject>csis<\/dc:subject><dc:title>Neuro-fuzzy knowledge processing in intelligent learning environments for improved student diagnosis<\/dc:title><rioxxterms:author>Stathacopoulou, R.<\/rioxxterms:author><rioxxterms:author>Magoulas, George D.<\/rioxxterms:author><rioxxterms:author>Grigoriadou, M.<\/rioxxterms:author><rioxxterms:author>Samarakou, M.<\/rioxxterms:author><rioxxterms:publication_date>2005<\/rioxxterms:publication_date><rioxxterms:type>Journal Article\/Review<\/rioxxterms:type><rioxxterms:version>NA<\/rioxxterms:version><rioxxterms:version_of_record>http:\/\/dx.doi.org\/10.1016\/j.ins.2004.02.026<\/rioxxterms:version_of_record><\/rioxx><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2005,"topics":["csis"],"subject":["csis"],"fullText":" \n \nBirkbeck ePrints: an open access repository of the \nresearch output of Birkbeck College \n \nhttp:\/\/eprints.bbk.ac.uk\n \n \nStathacopoulou, Regina; Magoulas, George D.; \nGrigoriadou, Maria and Samarakou, Maria (2005). Neuro-\nfuzzy knowledge processing in intelligent learning \nenvironments for improved student diagnosis. Information \nSciences 170 (2-4) 273-307.  \n \n \nThis is an author-produced version of a paper published in Information \nSciences (ISSN 0020-0255). This version has been peer-reviewed but does \nnot include the final publisher proof corrections, published layout or \npagination.  \nAll articles available through Birkbeck ePrints are protected by intellectual \nproperty law, including copyright law. Any use made of the contents should \ncomply with the relevant law. \n \n \nCitation for this version: \nStathacopoulou, Regina; Magoulas, George D.; Grigoriadou, Maria and \nSamarakou, Maria (2005). Neuro-fuzzy knowledge processing in intelligent \nlearning environments for improved student diagnosis. London: Birkbeck \nePrints. Available at: http:\/\/eprints.bbk.ac.uk\/archive\/00000351\n \nCitation for the publisher\u2019s version:  \nStathacopoulou, Regina; Magoulas, George D.; Grigoriadou, Maria and \nSamarakou, Maria (2005). Neuro-fuzzy knowledge processing in intelligent \nlearning environments for improved student diagnosis. Information Sciences \n170 (2-4) 273-307. \n \n \nhttp:\/\/eprints.bbk.ac.uk\nContact Birkbeck ePrints at lib-eprints@bbk.ac.uk\n  \n 1\nNeuro-fuzzy Knowledge Processing in Intelligent Learning \nEnvironments for Improved Student Diagnosis \n \n1Regina Stathacopoulou*, George D. Magoulas**, Maria Grigoriadou* \nand Maria Samarakou*** \n \n*Department of Informatics and Telecommunications, University of Athens, Panepistimiopolis, \nGR-15784 Athens, Greece \n{sreg@di.uoa.gr, gregor}@di.uoa.gr  \nPhone: +30-210 7275230; Fax: +30-210 7275214 \n**School of Computer Science and Information Systems, Birkbeck College, University of London  \nMalet Street, London WC1E 7HX, United Kingdom \ng.magoulas@bbk.ac.uk \n***Department of Energy Technology, Technological Education Institute of Athens, \nAg. Spyridonos Str. GR 12210, Egaleo, Athens, Greece \nmarsam@teiath.gr \nPhone: +30-210-5385322, Fax: +30-210-5385306 \n \n1Corresponding author \n \nAbstract. In this paper, a neural network implementation for a fuzzy logic-based model of the diagnostic process \nis proposed as a means to achieve accurate student diagnosis and updates of the student model in Intelligent \nLearning Environments. The neuro-fuzzy synergy allows the diagnostic model to some extent \u0093imitate\u0094 teachers \nin diagnosing students\u0092 characteristics, and equips the intelligent learning environment with reasoning \ncapabilities that can be further user to drive pedagogical decisions depending on the student learning style. The \nneuro-fuzzy implementation helps to encode both structured and non-structured teachers\u0092 knowledge: when \nteachers\u0092 reasoning is available and well defined, it can be encoded in the form of fuzzy rules; when teachers\u0092 \nreasoning is not well defined but is available through practical examples illustrating their experience, then the \nnetworks can be trained to represent this experience. The proposed approach has been tested in diagnosing \naspects of student\u0092s learning style in a discovery-learning environment that aims to help students to construct the \nconcepts of vectors in physics and mathematics. The diagnosis outcomes of the model have been compared \nagainst the recommendations of a group of five experienced teachers, and the results produced by two alternative \nsoft computing methods. The results of our pilot study show that the neuro-fuzzy model successfully manages \nthe inherent uncertainty of the diagnostic process; especially for marginal cases, i.e. where it is very difficult, \neven for human tutors, to diagnose and accurately evaluate students by directly synthesizing subjective and, \nsome times, conflicting judgments. \n \n  \n 2\nKeywords. Student Diagnosis, Uncertainty Management, Fuzzy Logic, Neural Networks, Student modelling, \nIntelligent Learning Environments, Intelligent Tutoring Systems, Discovery Learning Environments, Learning \nStyles. \n \n1.  Introduction \nUser and student modeling is a fundamental mechanism to achieve individualized interaction \nbetween computer systems and humans [41]. It is usually concerned with modelling several \nuser related issues, such as goals, plans, preferences, attitudes, knowledge or beliefs. The most \ndifficult task in this context is the process of interpreting the information gathered during \ninteraction in order to generate hypotheses about users and students behaviour [41], and \ninvolves managing a good deal of uncertainty. Interactive computer systems deal in general \nwith more meagre and haphazardly collected users\u0092 data than it usually happens when humans \nare engaged in face-to-face interaction [26]. Thus, the gap between the nature of the available \nevidence and the conclusions that are to be drawn is often much greater [26]. Numerical \ntechniques have been employed in several cases in order to manage uncertainty, [3] [13] [22] \n[23] [24] [26] [27] [30] [42] [59], and neural networks have been used in order to add learning \nand generalization abilities in user models and draw conclusions from existing user profiles \n[10] [19] [21] [32] [36] [37] [43] [46] [53] [61]. \nAccording to Self, [50], student modelling is the process of creating and maintaining \nstudent models. It is divided into the design of two different but tightly interwoven \ncomponents [55]: (i) the student model which, in its simplest form, is a data structure that \nstores information about the student; (ii) the diagnostic module which performs the diagnostic \nprocess that updates the student model. Student models are distinguishing features of \nArtificial Intelligence, (AI), based computer-based instructional systems.  \nThis work focuses on an application of student modelling in Intelligent Learning \nEnvironments (ILE). ILEs are considered as generalization of traditional Intelligent Tutoring \n  \n 3\nsystems (ITS), which are based on objectivist epistemology, and embrace instructional \nenvironments that make use of theories on constructivism and situated cognition [1]. \nNaturally, a good background for building student models for ILEs is provided by research \nconducted in the area of ITSs [8]. ITSs make use of AI techniques to represent and process \nknowledge about the domain and the student, and usually follow a natural division of the task \nof knowledge communication into four distinct components: domain expertise, model of the \nstudent, communication strategies or pedagogical expertise, and interface with the student \n[60]. The student model-centered architecture is also proposed for ILEs in order to support \nstudent-driven learning and knowledge acquisition [8].  \nIdeally, the student model should include all the aspects of student's behaviour and \nknowledge that have repercussions for their performance and learning [60]. In practice, the \ncontents of the student model depend on the application. It includes learner goals and plans, \ncapabilities, attitudes and\/or knowledge or beliefs, and is used as a tool to adapt ILE\u0092s \nbehaviour to the individual student [25][50]. Inferring a student model is called diagnosis \nbecause it is much like a medical task of inferring a hidden physiological state from \nobservable signs [55], i.e. the ILE uncovers the hidden cognitive state (student characteristics) \nfrom observable behavior.  \nResearchers in student modelling area have used AI techniques in order to develop models \nthat provide detailed diagnosis of student's knowledge, bugs and misconceptions, and\/or \nsimulate the cognitive behaviour of a student during learning and problem solving activities \n(see [39] for reports on various approaches, and [49][51][55][60] for reviews).  \nAlong these lines, the model of the diagnostic process that is proposed in this paper aims to \ndiagnose student behaviour based on teachers\u0092 expertise for the purpose of adapting \npedagogical decisions to the individual student. Evidence shows that human teaching is not \nbased on fine-grained diagnostic behaviour [48]. In particular, studies in human tutoring have \n  \n 4\nfound little evidence to suggest that human tutors build detailed cognitive models as a basis \nfor understanding student performance and adapting their tutoring strategy [35][47]. More \nrecently, researchers have tried to identify the constructs that tutors use to classify and \ndiscriminate among different students states for the purpose of adapting tutoring to student \nindividual differences [15]. Their results have been based on the assumption that, during \ntutoring, the expert tutor gathers evidence and forms relatively general ideas of the kind of \ntutoring that might work better for each student. According to these findings, all tutors judged \nand classified students in terms of two underlying dimensions that were similarly defined, \nthrough not exactly alike, across tutors: motivation and intellectual ability.  \nThe neural network-based fuzzy model presented in this paper aims to \u0093imitate\u0094 teacher's \nknowledge acquisition procedure in evaluating student's learning characteristics, such as \ncapabilities, attitudes, knowledge level, motivation and learning style. Fuzzy logic is used to \nprovide a mode of qualitative reasoning, which is closer to human decision making since it \nhandles imprecision and vagueness by combining fuzzy facts and fuzzy relations, whilst \nneural networks provide a convenient way to achieve adaptability of the diagnostic process to \nteacher's subjective reasoning and judgments. Thus, a neuro-fuzzy implementation helps the \nsystem to encode both structured and unstructured knowledge, e.g. fuzzy rules and learning \nfrom examples, respectively. \nThe paper is organized as follows. In Section 2 we give a brief overview of fuzzy logic and \nneural network techniques in user and student modelling, and provide a general description of \nour approach explaining its differences from existing techniques. Section 3 covers several \naspects of our model: data gathering, knowledge representation and implementation details of \nthe neural-network based fuzzy model. Section 4 presents an application of the proposed \nmodel in a discovery learning environment, giving details on the environment, the aspects of \n  \n 5\nthe students\u0092 learning style diagnosed by our model, and comparative evaluation results. \nLastly, conclusions are drawn and directions for future work are presented.  \n \n2.  Fuzzy and neural approaches to user and student modelling \nAs already mentioned a variety of numerical techniques have been employed in user and \nstudent modelling systems in order to handle the imprecise information provided by the users, \nand reason under vagueness and uncertainty; a comparative review of techniques can be found \nin [26]. For example, Bayesian networks have been successfully used to relate in a \nprobabilistic way user\u0092s knowledge and characteristics with user\u0092s observable behaviour. The \nkey to success with all Bayesian network models lies in accurately representing the \nprobabilistic dependencies in the task domain [13]. Fuzzy logic techniques have also been \nused for this task effectively. When considering the use of such techniques in a user or student \nmodelling system, the addressed arguments do not concern in principle the question of \nwhether or not fuzzy logic provides accurate or useful results by rather the usability of fuzzy \nlogic techniques in the design of the specific system, in terms of knowledge engineering \nrequirements, programming effort, empirical model adjustment, computational complexity, \nhuman-likeness, interpretability and justifiability [26]. Fuzzy logic can claim advantages with \nrespect to other alternatives in several of these issues [26], as for example in computational \ncomplexity. In addition reasoning of a fuzzy logic system is considered easy for designers and \nusers to understand and\/or to modify [26]. One of the factors for this consideration is human-\nlikeness. Although, the gap between human and Bayesian inference is not as wide as is \ncommonly believed, human-likeness is much stronger associated with fuzzy logic since it can \nprovide human-like descriptions of knowledge and imitate a \u0093human\u0094 style of reasoning with \nvague concepts [26]. These are of particular interest when trying to design an interpretable \nstudent modelling system based on teacher\u0092s reasoning and conceptualization of the learner, \n  \n 6\nas in our approach. In addition, the Bayesian approach requires the determination of \nprobabilities from experts\u0092 judgments, whilst fuzzy logic provides a convenient method to \nelicit the necessary knowledge from domain experts, thus expert teachers in case of student \nmodeling, to implement the system. It is easier and more reliable to extract knowledge form \nexperts in linguistic form rather than in numbers representing this knowledge since experts \nfeels most comfortable giving the original linguistic data [28]. \nOne of the first attempts in using fuzzy student modelling has been made by Hawkes et al. \n[23]. In this context fuzzy logic has been proposed as a flexible and realistic method to easily \ncapture the way human tutors might evaluate a student and handle tutoring decisions, which \nare not clear-cut ones. Clearly, the capability to deal with such imprecision is a definite \nenhancement to both ITSs and ILEs. This approach, which has been revised some years later \n[22], was used to evaluate students in a system called TAPS, and applied degrees of \nmembership to linguistic labels that match student's solutions to \u0093acceptable\u0094 solutions with \nthe use of informal fuzzy reasoning.  \nTowards this direction, several other attempts have been proposed in the literature. In \nSherlock II [27] and in the MDF tutor [1] the uncertainty in student's performance was \nmanaged using fuzzy distributions and a set of rules for their formulation and update. Several \nother systems have been employed based on fuzzy logic concepts. In an ITS for the physics \ndomain, the, so called, \u0093Knowledge and Learning Student Model\u0094 [42] has been proposed to \ninfer student's knowledge level and cognitive abilities through processing and aggregating \nmembership functions that represent teacher's assessments. Fuzzy rules have been proposed in \nthe BSS1 tutoring system [59] to implement a general fuzzy logic engine that can better \nmanage student\u0092s learning, and in SYPROS [24] to help determine student\u0092s plans. A fuzzy \nalgebraic structure has been proposed as a dynamic model of user's states during navigation to \nmonitor cognitive variables of the user model in a multimedia tutoring system [30]. \n  \n 7\nThe development of fuzzy logic in user or student modelling systems was motivated \nlargely by the desire to make the arbitrary specification of precise numbers unnecessary [26]. \nHowever, the fuzzy approach translates and process knowledge in a numerical framework. In \naddition, although fuzzy logic allows knowledge engineers to acquire knowledge from experts \nin linguistic form, experts rarely can articulate the propositional or mathematical rules that \ndescribe their expert behaviour [28]. A complementary strategy is to employ machine learning \ntechniques for implementing the system and acquiring the necessary numbers [26]. Neural \nnetworks can serve this purpose. Both neural networks and fuzzy systems are model-free \nestimators. Unlike statistical estimators, they estimate a function without a mathematical \nmodel\/assumption of how outputs depend on inputs [28]. They can \u0093learn from experience\u0094 \nexpert\u0092s knowledge with linguistic or numerical sample data by means of specialised learning \nprocedures, and provide a robust approach to approximating real-valued, discrete-valued, and \nvector-valued target functions. For certain types of problems, such as learning to interpret \ncomplex real-world sensor data, neural networks are among the most effective learning \nmethods currently known [38]. In the user or student modelling field, neural networks have \nbeen proposed in the literature mainly due to their ability to learn from noisy or incomplete \npatterns of users\u0092 or students\u0092 behaviour, generalize over similar cases, and then use this \ngeneralized knowledge to recognize unknown sequences [10] [61]. Particularly in student \nmodelling, neural networks have been originally proposed to simulate student\u0092s cognitive \nprocess of performing subtraction with the aim to predict student's responses and errors [36]. \nA problem, which comes up when trying to apply a neural network in modelling human \nbehaviour, is knowledge representation [61]. The fact that student models need to be \ninspectable, [60], explains the small number neural network-based student models as opposed \nto symbolic approaches [51]. Neural networks and other numeric-based AI methods have \nbeen criticized as unable to support learning interactions because they only allow for implicit \n  \n 8\nunderstanding [49]. However, several attempts have been made to incorporate the powerful \nlearning abilities of neural networks in existing student modelling systems taking advantage \nof synergies with other AI methods. A hybrid approach, where each node and connection has \nsymbolic meaning, has been proposed in TAPS [46]. The back-propagation algorithm has \nbeen used to modify weights that represent importance measures of attributes associated with \nstudent's performance, in order to refine and expand incomplete expert knowledge. Another \napproach combining ideas from neuro-fuzzy systems has been proposed [19]. In [32], the \nmodel of [19] has been expanded to incorporate evaluation mechanisms that used multi-\nattribute decision making for synthesizing various judgments to estimate student's knowledge \nlevels and personal characteristics in order to plan the content of a Web based course. \nThis paper makes use of neuro-fuzzy synergism in order to infer the learning \ncharacteristics of the student in an ILE, and to create and update the student model taking into \nconsideration teacher's personal opinion\/judgment. Fuzzy logic is used to handle uncertainty \nand to express teacher\u0092s qualitative knowledge in a clearly interpretable way. The fuzzy \nmodel represents teacher\u0092s knowledge in linguistic form and infers student's characteristics \nthrough a set of fuzzy systems, realizing in this way a human-like diagnostic process, i.e. a \ndecision is made by combining fuzzy facts, each one contributing to some degree to a fuzzy \nrelation and to the final decision. Neural networks are used to equip the fuzzy model with \nlearning and generalization abilities, which are eminently useful when teacher\u0092s reasoning \nprocess cannot be defined explicitly.  \nThe new approach aims to represent human teacher\u0092s conceptualization of student during \ninstruction by modelling their reasoning process in diagnosing unobservable student's \ncharacteristics. To this end, teacher's evaluation procedure is decomposed into three \nmeaningful stages: gathering evidence during interaction; evaluating the student; reaching a \ndecision. Information of student's observable behaviour is described and processed \n  \n 9\nqualitatively with the use of fuzzy logic variables and operators. Thus, a more accurate and \nmore natural modelling of human's tutor diagnostic process is achieved. This form of \nmodelling permits to determine the specific characteristics of the diagnostic process, such as \nthe types of evidences that must be used to discriminate among students, the characteristics of \nstudents that lead to pedagogical decisions, and the rules underlying the inference process. \nFurthermore, it is able to cope with subjectivity incorporated in knowledge acquisition and \nreasoning; thus, it can be easily adapted to the lesson content according to teacher's subjective \ninferences and decisions.  \nThe proposed model allows exploiting and efficiently processing structured knowledge in \nthe form of linguistic rules. Of course it is not always possible to elicit this knowledge from \nthe teachers. Teachers, sometimes, although they can easily classify students by observing \ntheir actions, they cannot articulate rules that reproduce their decisions. In addition, teachers \nare able to classify students with respect to specific characteristics, whilst in the case of ILE-\nsupported learning students\u0092 behaviour cannot be defined accurately. To alleviate these \nproblems, a neural network-based implementation of the diagnostic process is adopted. \nSpecialized neural networks are trained through examples of existing students\u0092 profiles, or \nusing examples that represent teacher's experience. Knowledge is represented by developing \nassociation of student's behaviour patterns with particular characteristics through neural \nnetwork learning and is expressed, if necessary, with fuzzy if-then rules. Thus, it is possible to \nencode structured and non-structured knowledge.  \n \n3.  Fuzzy modelling of the diagnostic process  \n3.1.  Collecting and processing information \nStudent's observable behaviour is considered important source of diagnostic evidence to \nboth human tutors and ILEs. In the terminology of ILEs, student\u0092s behaviour refers to a \n  \n 10\nstudent's observable response to a particular stimulus in a given domain. The response, \ntogether with the stimulus, serves as the primary input to the student modelling system [51]. \nThe input can be an action or the result of that action, and can also include intermediate \nresults [51]. However, it is not generally clear what type of information is available during \ninteraction, and which features of student's behaviour should be selected as inputs to the \ndiagnostic process. Human tutors obtain diagnostic information from observing what students \nwould say and do, and how something is said and done, i.e. tone of voice, inflection, \nhesitancy, etc. [15]. Studies in human tutoring found that tutors use as diagnostic evidence \nfor adapting their tutoring not only errors and student's responses to queries, but also features \nof interaction, e.g. the timing of student responses, the way of delivering a response and \nothers [15]. ILEs are handicapped in this regard, since the communication channel between \nstudent and computer is very restricted (usually a keyboard and a mouse) [60]. However, \nsome indirect information that approximates student's unobservable behaviour can be \nobtained [55][60]. In addition, an appropriately designed interface can facilitate the process \nof collecting the best available information about what the student is doing (e.g. timing each \nkeystroke) to make diagnosis both computationally tractable and more accurate [60]. \nIn order to alleviate the problem of limited information that is caused by the restricted \ncommunication channel between student and ILE, our system implements a close monitoring \nmechanism of student's actions over time, where each response such as keystroke, mouse \nmove or drag can be timed and recorded. In this way various data can be extracted from \nstudent's records: (i) knowledge data, such as the number of correct, incorrect or almost \ncorrect answers in separate tests, and the number of student's conceptual errors; (ii) \nchronometric data, such as the time spent to read the theory, a page or a line, the time to find \nthe correct answers in a test, the total time on task, the time of idle intervals; (iii) try data, \nsuch as the number of attempts to find the correct solution, the number of times needed to \n  \n 11\nreview the theory; (iv) navigation data, such as the number of times a topic, activity, tool, or \nexercise has been selected, frequency that specific student selections occurred, the number of \ntimes the student moves to another topic without achieving a previously set goal. In this \nmanner student's observable responses are summarized into k groups. Each group contains \ninformation about student's behaviour of a specific type of knowledge data, chronometric \ndata, try data or navigation data. A teacher usually defines specific types of responses that \nenable him or her to discriminate among students with regards to a particular characteristic. \nThe set B={B1,B2,\u0085,Bi,\u0085,Bk}, where Bi (i=1,2,\u0085.,k) is a word or a sentence describing \nthe i-th type of response that is observed, describes linguistically the k aspects of student's \nobservable behaviour that will serve as inputs to the diagnostic process. The term observable, \nhere, stands for measurable. The k measured responses constitute a set of numeric \ninformation that represents student's behaviour. Each type i (i= 1,2,\u0085.,k) takes its values in a \nset of positive numbers Ui. The numerical input  },x,...,x,,{xX 1 k\u03b9K=  where    Ux \u03b9\u2208\u03b9 and \niU  is the universe of discourse of the i-th input; each \n+\u211c\u2282  U \u03af  (i= 1,2,\u0085.,k) represents the \nmeasured values of Bi and formulates an input to the diagnostic process. \nThe output of the diagnostic process updates the student model regarding L different \nstudent learning characteristics C1, C2, \u0085, CL, such as student\u0092s abilities, motivation or \nlearning style. Student\u0092s evaluation regarding each characteristic Cj (j=1,2,\u0085..L) is described \nqualitatively with the use of linguistic values. Depending on the j-th characteristic we use a \ndifferent number mj of linguistic values that describe Cj (j=1,2,\u0085..L). \nStudent\u0092s evaluation regarding each characteristic is assessed by processing the numerical \ninput  },x,...,x,...,{xX 1 ki= of student\u0092s behaviour. The process consists of three stages: \nfuzzification, inference, and defuzzification (see Figure 1). In the first stage a qualitative \ndescription of student behaviour is obtained by transforming the numeric input data into \n  \n 12\nlinguistic terms. The i\u0096th fuzzifier (i=1,2,\u0085..k) transforms the numeric input xi into \nmembership degrees of the linguistic values that describe Bi. In the second stage, the \ninference process provides a fuzzy assessment of student's characteristics, C1, C2, \u0085, CL, by \nassessing membership degrees to the linguistic terms that describe each characteristic Cj. To \nthis end, an ensemble of specialized fuzzy systems, where each system infers about a \nparticular characteristic Cj is used to make a fuzzy assessment from a fuzzy precondition. A \nfuzzy system of this type combines linguistic values and realizes fuzzy relations operated \nwith the max-min composition. These relations represent the estimation of a human tutor to \nthe degree of association between an observed input  },x,...,x,...,{xX 1 ki=  and a fuzzy \nassessment of a particular student characteristic Cj (j=1,2,\u0085..L). Finally, in the third stage, \nthe fuzzy assessments are defuzzified to non-fuzzy values, i.e. evaluation decisions for the \ncharacteristics C1, \u0085, CL by using a defuzzifier from the ensemble of the M defuzzifiers. \nEach defuzzifier has a different number of inputs. Therefore, depending on the number of \nlinguistic values mj of each characteristic Cj (j=1,2,\u0085..L) a different defuzzifier M is used in \norder to evaluate student\u0092s characteristic. \nFuzzifier 1 \nFuzzifier 2 \nFuzzifier k \nFuzzy System 1 \nFuzzy System 2 \nFuzzy System L \nx1 \nxk \nx2 \n \nC1 \ndefuzzifier 1\ndefuzzifier M\nC2 \nCL \ndefuzzification \nstage \ninference\nstage \nfuzzification \nstage \n \nFigure 1. Schematic of the diagnostic model.  \n \n  \n 13\n3.2.  A scheme for fuzzy knowledge representation \n3.2.1  Fuzzification stage \nThis stage represents in linguistic form teacher's subjective description of student's responses \nwhen acting face-to-face communication during instruction (e.g. the time needed to solve the \nexercises was short; the student answered enough questions during instruction). The types of \nresponses B1,\u0085,Bi,\u0085,Bk are treated as linguistic variables. Each variable Bi (i=1,2,\u0085..k) can \ntake a different number of linguistic values fi. The number fi of the linguistic values and their \nnames V1,V2,\u0085,Vfi are defined by the developer with the help of experts, and depend on each \nvariable. The set T(Bi)={Vi1, Vi2, \u0085, Vifi } is the term set of Bi. For example, let us consider \nthe linguistic variable Bi = \u0093time on task\u0094. The corresponding term set could be T(Bi)=T(time \non task)={Short, Normal, Long} including three (fi=3) linguistic values, or any classification \nsuch as T(Bi)=T(time on task)={Very Short, Short, Normal, Long, Very Long} including five \n(fi=5) linguistic values, depending on the required resolution. T={T(B1), \u0085,T(Bi),\u0085,T(Bk)} \nis the set of all term sets that represent the overall observable behaviour \u0392 (for all Bi; \ni=1,2,\u0085..k). Thus, the numeric input  },x,...,x,...,{xX 1 ki=  that represents the measured \nvalues of B1,\u0085,Bi,\u0085,Bk is fuzzified by means of linguistic values V11,V12\u0085..,V1f1; \nVi1,Vi2\u0085..,Vifi; Vk1,Vk2\u0085..,Vkfk. Thus, the student behaviour B is represented as a set of \nnumeric values Y={(y11, y12,\u0085y1f1),\u0085, (yi1,yi2,\u0085,yifi),\u0085, (yk1,yk2,\u0085 ,ykfk)} in [0,1], which \nrepresent the degree of membership of each numeric value xi (i=1,..k) into the term set of Bi \nwith linguistic values Vi1,Vi2\u0085..,Vifi. \n \n3.2.2 Inference stage \nThis stage represents teacher's reasoning in categorizing students qualitatively according to \ntheir abilities and personal characteristics, such as attentive, rather slow, good, etc. Teachers\u0092 \ncan provide a series of IF-THEN rules that approximates their reasoning. For example, if the \n  \n 14\ntime spent to read the theory is short and the number of correct answers is high, and few \nattempts to find the correct answers have been made then the student learning rate is fast.  \nIn our model, a qualitative description of student's characteristics C1,C2,...,CL is performed \nby treating student\u0092s characteristics as linguistic variables. Each linguistic variable Cj can take \na different number of linguistic values mj. T(Cj)={Cjl, Cj2, \u0085, Cjmj} is the term set of Cj . The \nexpert-teachers set the number mj of the linguistic values and their names Cjl, Cj2, \u0085, Cjmj  for \neach characteristic Cj according to their personal judgement. For example, if we treat the \nlinguistic variable Cj = \u0093learning rate of the student\u0094 using five linguistic values (mj =5) then \nthe term set could be: T(Cj )=T(learning rate)={ Slow, Rather Slow, Normal, Almost Fast, \nFast}. In this way, a mode of qualitative reasoning, in which the preconditions and the \nconsequents of the IF-THEN rules involve fuzzy variables [64], is used to provide an \nimprecise description of teacher's reasoning: \n\u0093IF B1 is V1I1 AND B2 is V2I2 \u0085AND Bk is VkIk  THEN C1 is C1J1  AND C2 is C2J2\u0085AND CL is CLJL.\u0094 \nwhere  I1=1,2,\u0085,f1 ;  I2=1,2,\u0085,f2 ; Ik=1,2,\u0085,fk ; J1=1,2,\u0085,m1; J2=1,2,\u0085,m2 ; JL=1,2,\u0085,mL. \nAll possible combinations in the preconditions, denoted as PCP below, are represented by \nthe Cartesian product of the sets in T={T(B1),T(B2),\u0085,T(Bk)}: PCP=T(B1)\u00d7T(B2)\u00d7...\u00d7T(Bk),  \nand the number n= f1 \u00d7 f2 \u00d7...\u00d7 fk of possible cases in the preconditions equals to the number n \nof elements of PCP. Each fuzzy system j (see Fig. 1) infers a fuzzy assessment of a different \ncharacteristic Cj (j=1,2,\u0085.,L). Within each fuzzy system, the intersection (corresponding to \nthe logical AND) between the membership functions associated with the linguistics values of \neach precondition is the min operation, and results in the numerical truth-value pn of the \nprecondition. Thus, student's current behaviour is described by a vector P = (p1, p2, \u0085, pn), \nwhere p1,p2,\u0085,pn are in the interval [0,1], representing degrees of fulfilment of preconditions. \nBy means of a fuzzy relation, [44] [45], as described below, P is translated into fuzzy \n  \n 15\nassessments by exploiting teacher\u0092s subjective judgments (denoted by the symbol Rj in the \nrelation right below) with respect to a characteristic Cj  \nP \u00b0 Rj = Cj, \nwhere Cj is an m-dimensional vector Cj = [cjl,cj2,\u0085,cjmj] with cjl, cj2, cjmj in [0,1] representing \nthe fuzzy assessment of student\u0092s characteristic Cj, i.e. an assessment with membership \ndegrees cjl, cj2, \u0085, cjmj on each linguistic value (Cjl, Cj2, \u0085, Cjmj) of the linguistic variable for \nthe characteristic Cj; Rj is a n\u00d7mj weight matrix representing teachers\u0092 estimations of the \ndegree of association between precondition P and the linguistic values of student\u0092s \ncharacteristic Cj; the symbol \u00b0 denotes the max-min composition operator. \n \n3.2.3  Defuzzification stage \nThis stage represents teacher's final decision in classifying a student in one of the \npredefined linguistic values Cjl, Cj2, \u0085, Cjmj of the characteristic Cj. This process is performed \nby weighting the fuzzy assessment. Depending on the number of linguistic values mj of each \ncharacteristic Cj, we use an appropriate defuzzifier from the ensemble, i.e. implementing a \ndifferent defuzzification procedure that \u0093imitates\u0094 a teacher's subjective decisions. Teacher\u0092s \ndecisions may be clear-cut or marginal. Decisions in marginal cases are highly subjective and, \nusually, teachers are reserving the best or the worst qualification of their students. Thus, we \nhave used a neural network-based implementation, which allows the system to adapt the \ndefuzzification procedure to individual user\u0092s (teacher) opinion by training, as will be \nexplained in the next section. \n \n  \n 16\n3.3. Neural-network based implementation of the fuzzy model \n3.3.1  Fuzzification  \nDepending on the linguistic variable Bi and the linguistic value Vi1,Vi2\u0085..,Vifi, we \nsubjectively define different membership functions, which assign to each element xi of the \nuniverse of discourse Ui (i=1,..k)  a degree of membership yifi(xi) to the linguistic value Vifi of \nBi. In this way they contribute to the semantic rule that associates each linguistic value Vifi of \nBi with its meaning [63]. In general, the form of a membership function depends experts \nopinions [62]. In our case, we have adopted an approach that simplifies the implementation by \napproximating the membership functions using a library of regular shapes and implementing \nthe fuzzifier stage as a group of fixed weight neural networks that calculate such regular \nshapes. Since membership functions are subjective and generally context-dependent, [63], a set \n}m,...,m,{mM 21 k=  of parameters that adjust the membership functions [53] is defined to \nallow a range of adaptations to teacher\u0092s subjective judgments. Thus, for each one of the \nlinguistic values of the set T={T(B1),T(B2),\u0085, T(Bk)}, the fuzzifier stage calculates the output \nY of numeric values in [0,1] based on the input vectors  },x,...,x,...,{xX 1 ki=  and \n}m,...,m,{mM 21 k= : \n{\n}.)}m,(xy, ),m,(xy),m,(x{y,)},m,(xy,),m,(xy),m,(x{y\n)},m,(xy),m,(xy),m,(x{yY\n 2\n1\n2122222222221\n11111121111\nkkkfkkkkkkf\nf\nkKKK\nK=\n \nThus, in our implementation, shown in Figure 2, we have used sigmoid functions as \nmembership functions for the extreme linguistic values V1, Vfi, and the pseudotrapezoidal \nfunction (composed of two sigmoid functions) for the intermediate values, V2, \u0085,Vfi-1; the \nadjusting parameter mi is the expected mean value of a measured value xi, as estimated by the \nteacher of the specific teaching subject.  \nEach fuzzifier i (i=1,2,\u0085.k) of Figure 1 is implemented with a network of the type shown \nin Figure 2. The network of Figure 2 is used to calculate the membership grades of the \n  \n 17\nlinguistic values fi , when xi=x and mi=m (see Figure 3 for a sample of membership functions \nused in our system). \n+ \u03b1\nm wc1 wg1 1 y1\nwc3\nwc2\n+\n+\nwg2\n\u03b1\n-1\n1\n1 y2+\n\u03b1\nwg3\nx\n\u03b1 yf1+\nwgi\nwci\n \nFigure 2. The implementation of a fuzzifier.  \n \nThe left and the right extreme fuzzy sets are given by  \nm))w(xexp(-w1\n1m)(x,y\n11\n1\ncg ++\n= , wg1<0; \nm))w(xexp(-w1\n1m)(x,y\ncigi\nf ++\n= , wgi>0; \nwhere i = 2(f-1). An intermediate set j is given by  \nm))w(xexp(-w1\n1\nm))w(xexp(-w1\n1m)(x,y\n'' cigicigi\nj ++\n\u2212\n++\n= , \nwhere j= 2,\u0085\u0085,f-1, 0w >gi ,  0w >\u2032ig (i = 2(j-1); i' = i+1). \nIn the above relations, x indicates the current measurement of the observed response; wci \nand wgi, are defined in advance according to human teachers opinions; wci\u00b7m ( )1(2.,1 \u2212= fi K ), \nis the central position of the sigmoid function; wgi, ( )1(2.,1 \u2212= fi K ) is the gradient of the \nsigmoid function.  \n  \n 18\n0.5\n1\n0\n min(x) Wc1*m\nWc2*m\nmax(x)\ny1 y2 yf\n  Wci*m\n \nFigure 3. Sample of membership functions. \n3.3.2  Inference stage \nThe preconditions P = [p1,p2,\u0085,pn] are produced by a single layer of n, n= f1 \u00d7 f2 \u00d7...\u00d7 fk, \nnodes. The network realizes the intersection by performing the min operation on the \nmembership functions ending at each node. Thus, each node is activated to the degree of the \nnumerical truth value pn of the precondition in [0,1].  \nEach fuzzy system j (see Figure 1) contains a precondition layer and realizes a fuzzy \nrelation P \u00b0 Rj = Cj which is implemented by a two layer network with n, n=f1\u00d7f2\u00d7\u2026\u00d7fk, input \nnodes and mj output nodes as shown in Figure 4. The output nodes perform the max-min \ncomposition and the synaptic weights ),,1;,,1(r jil mlni KK == are the elements of the Rj \nmatrix. \n \n \n \nmax\nmin\nmax\nmin\nmax\nmin\np1 \np2 \npn \nc1 \nc2 \ncl \nr11\nr12\nr1l\nr2 r22\nr2l\nrn2\nrn1\nrnl\n \n \nFigure 4: Network architecture for implementing the fuzzy relation. \n \n  \n 19\n3.3.3  Defuzzification  \nWe have used a neural network-based approach, which allows the system to adapt the \ndefuzzification to individual teacher's opinion by training. A three-layer neural network with \nmj input and mj output nodes and a hidden layer was trained with a modified backpropagation \nalgorithm that uses variable stepsize, called BPVS [33]. Training the network results in \nencoding teachers\u0092 unstructured knowledge, and during operation the network acts as a \n\u0093generaliser\u0094 that defuzzifies in a way that imitates teachers\u0092 decision procedure. \nIn our application, reported in the next section, the network used for defuzzification was \ntrained using the population of 200 simulated student cases and desired outputs as specified \nby a group of five expert teachers, as described in [53]. This approach allows us to capture \nsome \u0093rules\u0094 in teachers\u0092 judgements that cannot easily be captured when using a standard \ndefuzzification procedure, such as the Center-Of-Area (COA) that was used in [42]. For \nexample, we have found that students were classified according to the best fuzzy assessment \nif this is a clear decision (a fuzzy value 30% larger than all others). If this is not the case, then \nthe student is classified into an intermediate or into a more \u0093conservative\u0094 category between \ntwo of \u0093approximately equal\u0094 values (e.g. when the difference between two fuzzy values is \nless than 20% they could be considered approximately equal) for a particular student \ncharacteristic. \n \n3.4. Encoding teacher\u0092s knowledge of evaluating student's characteristics  \nDepending on the characteristic that is evaluated and the lesson content, teacher's \nsubjective reasoning is encoded in the fuzzy relation network (Figure 4). The weights ril \n(i=1,2,\u0085.n; l=1,2,\u0085,mj) are adjusted in order to relate the precondition with the consequents \nof teacher's reasoning. This form of modelling allows us to simplify the determination of the \nset of n\u00d7mj linguistic rules that describe the fuzzy system [9] to the estimation of a matrix. A \n  \n 20\nweight ril can be considered as measure of possibility of a linguistic rule relating a fuzzy input \nwith a fuzzy output [44], as a confidence measure of that rule [14], or as measure of \ncontribution of that rule in the output [9]. We interpret these weights as the degree of \nconfidence of teacher's rules. This connectionist implementation provides the ability to \nencode teacher's structured or unstructured knowledge, as will be explained below. \n \n3.4.1  Case 1: Teacher\u0092s diagnostic knowledge is available in the form of rules  \nIn the simple case, where teacher's reasoning is well defined and available in the form of \nIF-THEN rules, these rules can be encoded in the network of Figure 4. If the rules are \nprovided with certainty, denoting that the numerical truth-values of the preconditions and \nconsequents are equal to 1, a weight ril associated with a rule takes the value of 1. If \nconsequents are provided with some degree of confidence, then the weight ril. is replaced with \nthis degree i.e. with the numerical truth values of the consequents. Connections, which are not \nassociated with rules, can be pruned. \n \n3.4.2  Case 2: Teacher\u0092s diagnostic knowledge is available by means of examples \nIn case teacher\u0092s reasoning cannot be exactly described but is available in the form of \nexamples, or in case labelled patterns of students observable behaviour are available, weights \nare adjusted though learning by examples. The numeric data X of student's behaviour are \nfuzzified and combined in the precondition layer to produce the learning vectors. A variety of \nmethods have been proposed to train networks that implement fuzzy relations [45][31][14], by \nreplacing the product operation with the minimum operation and the addition operation with \nthe maximum operation. In our implementation a Hebbian-style learning approach is adopted, \nas suggested in [14]. Thus, the weights update equation at the presentation of t example is \n)()()1()( tttt liilil cp\u03c1-rr \u2297\u2295 \u22c5= , \n  \n 21\nwhere \u03c1 is a positive stepsize, \u2295  represents a maximum operator and \u2297 represents a minimum \noperator. Thus, unknown rules are encoded and the weights ),,1;,,1(r jil mlni KK ==  are \nreplaced with degrees of confidence of the rules that represent teacher\u0092s inference. \n \n4.  Application Example \n4.1. The Learning Environment \nThe Intelligent Learning Environment consists of the educational software \u0093Vectors in \nPhysics and Mathematics\u0094 [20], and the neuro-fuzzy model that we have already described in \nSection 3. The introductory menu of the educational software \u0093Vectors in Physics and \nMathematics\u0094 is shown in Figure 5. This is a discovery (exploratory) learning environment \nthat has been designed and developed according to constructivist theory of learning [20]. \nWithin this framework, the design is based on a series of principles, which emphasize the \nstudent\u0092s active involvement in authentic activities, which correspond to real world processes \n(situated\/anchored learning) [7][58]. Moreover, the software supports students\u0092 creative \nactivities, allowing them to control their own learning procedure, and providing them with \nhelp and guidance when this is necessary [16].  \nThe educational software aims to help teachers to instruct, and students to construct the \nconcepts of vectors in physics and mathematics in the secondary school. The difficulties \nstudents encounter with the conceptualisation of the various phenomena that correspond to \nphysical entities, and which can cause misconceptions and inert knowledge, [1] [17] [52], \nhave been taken into consideration during the design of the software. \n  \n 22\nPosition and Displacement\nMotion \nForces and Equilibrium \nForces and Motion \nForces and Momentum \nVectors in Physics and \nMathematics \n \nFigure 5. Introductory screen of the learning environment \u0093Vectors in Physics and \nMathematics\u0094. \n \nThe thematic units of the software are: Position and Displacement; Motion; Forces and \nEquilibrium; Forces and Motion; Forces and Momentum. Each one of these units contains \nseveral scenarios, which refer to real-life situations. The students carry out selected activities \nwithin these scenarios Examples of such scenarios are: \u0093Going fishing\u0094, \u0093planning a journey\u0094, \n\u0093which ship moves faster?\u0094, \u0093travelling in the islands\u0094, \u0093playing golf\u0094, \u0093bodies in \nequilibrium\u0094 (see Fig. 6), \u0093imaginary climbing\u0094, \u0093falling objects\u0094, \u0093away from the earth\u0094, etc. \nThe environment also includes a short presentation of the theory and a dictionary of useful \nterms and concepts.  \nThe neural network-based fuzzy model was tested in the scenario \u0093bodies in equilibrium\u0094 \n(see Fig. 6) of the unit \u0093Forces and Equilibrium\u0094. The environment resembles a simple \nmechanics-laboratory. A table appears on the screen and several objects such as boxes, cords, \na spring and a pulley are available for use by the students. The students can drag and drop \nthese objects and then use the available tools that manipulate vectors representing forces, \ncarry out measurements, etc. to compose an equilibrium experiment. In this way, student is \n  \n 23\nallowed to give their own Newtonian model by drawing the vectors that compose this model, \nobserve the behaviour of this model, and compare to the scientific model.  \n \nTool bar \n \nFigure 6. Scenario \u0093Bodies in equilibrium\u0094. \n \n \nWithin this scenario the students have the opportunity to carry out a set of 16 different \nactivities (equilibrium experiments) by selecting one or two from the available objects from \nthe object box (see Fig. 6). For example he\/she can place a single box of 20N weight or 40N \nweight on the table or he\/she can select a box and the spring or a rope and hang the box from \nthe ceiling through them, or s\/he can place a box of 20N or 40N on the table and then place \nanother box on top. S\/he can also select different worktops for the table (i.e. with different \nstatic friction coefficients) in case of experiments with the pulley and a box. Then, he has to \ndecide about the kind (gravitational\/contact) and the properties (magnitude and direction) of \nthe forces acting upon each object and draw them according to his\/her conception.  \nIn Figure 7, an example activity with two boxes on the table is shown. The student draws \nthe forces acting on the top box, according to his\/her opinion. The student can then use the \n\u0093Test\u0094 button to observe the behaviour of the model. For example, if the resultant force is not \n  \n 24\nequal to zero, the box will move towards the direction of this force. The student can also \ncheck the \u0093Reality\u0094 radio button, in order to observe the scientific model in action, i.e. the \neffect of the correct forces acting on the box. Afterwards, either s\/he can correct the forces \nacting on the box and maybe test again the effect, or s\/he can clear the screen and conduct a \nnew equilibrium experiment.  \n \n\u0093Test\u0094 button \n(Run my \nmodel) \nReality \n \nFigure 7. Activity with two boxes on the table. \n \nStudents\u0092 lack of knowledge and misconceptions associated with this scenario have been \nidentified on the basis of findings from studies in physics problem solving related to \nNewton\u0092s third Law [1][11][16][17]. For example, a student may believe that lack of motion \nimplies no force is applied on the object; s\/he may be unfamiliar with contact forces or \nunfamiliar with gravitational force; s\/he may confusing gravitational force with contact force; \ns\/he may ignore that action-reaction pairs are opposite in direction or equal in magnitude. \nStudent\u0092s actions during task execution help us to estimate student\u0092s lack of knowledge or \n  \n 25\nmisconceptions by comparing the number, the kind (gravitational\/contact) and the direction of \nthe forces acting upon an object the student chooses to draw with the respective parameters of \nthe scientific model. For example, if the student tests a model without having drawn contact \nforces we can suppose that s\/he is unfamiliar with contact forces.  \nIn our experiments, an aspect of the surface\/deep approach [6] of student's learning style, \n[6], has been evaluated in order to provide an intelligent help to the student during learning \ninteraction. Deep learners often prefer self-regulated learning; conversely, surface learners \noften prefer externally regulated learning [4]. In the learning environment \u0093Vectors in Physics \nand Mathematics\u0094 diagnosing a student as deep or surface is used to sequencing the \neducational material.  \nIn order to acquire teachers\u0092 knowledge in evaluating student\u0092s learning style, needed to \nimplement our approach, a group of five experts in teaching the subject content has been \nused: three of them were experienced in teaching physics in secondary education, one of them \nwas expert in didactics of physics, and the last one was an expert in the design of educational \nsoftware. The group has been asked, taking into account their individual experiences in \nevaluating real students interacting with the learning environment, to reach consensus on the \nfollowing aspects of student\u0092s learning style relating to our approach: the parameter k; the \nnames Bi (i=1,2,\u0085,k); the universes of discourse Ui (for each i=1,2,..,k), and the association \nbetween the universes of discourse and the linguistic values of the linguistic variables of \nstudent\u0092s observable behaviour B that will serve as input for the diagnosis. A detailed \ndescription of the group\u0092s suggestion is given below. The group was also asked to agree on a \nset of IF-THEN rules (cf. with Section 3.4.1) describing their experiences of evaluating real \nstudents when they interact with the learning environment, as well as to agree on the labelling \nof a set of simulated students that were used for off line training of the networks (cf. with \n  \n 26\nSection 3.4.2) and for testing our approach. (The procedure to generate the simulated students, \nand the training and testing of the neuro-fuzzy system are described in the next subsections.)  \nIn addition, the Learning Environment stores on a log file all the available information on \nwhat a student is doing, recording each student action with a time stamp. Typical examples of \nstudent actions include: selection of objects for experimentation, selection of available tools, \nmouse moves, mouse drags or clicks on tools or objects or mouse drags when he\/she is trying \nto draw a vector, details about the vectors (forces) that the user draws, i.e. magnitude direction \nand kind, as well as the time the action was performed. The coding of the neural network-\nbased fuzzy model and the pre-processing of the log files were developed in MATLAB \nsoftware.  \n \n4.2.The deep\/surface approach to learning \nA lot of work has been done in defining student's deep or surface learning style [6] [18] \n[34] and constructing inventories [5] [57] to identify them. All these research efforts aim to \nidentify the defining characteristics of these different approaches to learning, and to scale \nthrough questionnaires, which assess these characteristics, student's deep or surface learning \nstyle. The deep approach to learning is characterised by the following defining features: \nintention to understand vigorous interaction with content, relating new ideas to previous \nknowledge, relating concepts to everyday experience, relating evidence to conclusions, and \nexamining the logic of the argument [18]. In contrast, the surface approach includes: intention \nto complete task requirements, memorising information needed for assessments, failure to \ndistinguish principles from examples, treating task as an external imposition, focus on discrete \nelements without integrating, unreflectiveness about the purpose or strategies [18]. All the \nabove features cannot be evaluated easily through tracking of student\u0092s activities during \ninstruction. Study strategies are more easily estimated from student's activities. Study \n  \n 27\nstrategies are closely related to student's learning style, since student's learning style is defined \nas \u0093a predisposition on the part of some students to adopt a particular learning strategy \nregardless of the specific demands of the learning task\u0094 [4]. Recently, study strategies of \nstudents with deep or surface learning style have been evaluated and compared with the aid of \na computer assisted study environment for learning from text [4]. For the purpose of this \nresearch, students were classified using the Inventory of learning styles (ILS) as deep or \nsurface and pre-tested before the learning task. The study environment recorded all users\u0092 \nactions, together with a time-stamp, as well as student\u0092s reading speed, in order to identify \nstudy activities in relation to student's deep or surface learning style. According to the results \nof this research, deep learning students know more about the diagnostic study task and \ndevelop increased reading speed.  \nLearning by discovery is quite different from learning by textbook; therefore, the work \nsupported by the computer-assisted study environment cannot be easily transferred to a \ndiscovery learning environment. The educational software \u0093Vectors in Physics and \nMathematics\u0094 is designed on the basis of student\u0092s active engagement during the learning \nprocess, allowing students to control and observe the evolution of real world phenomena, take \nmeasurements, change various parameters, examine \u0093what if\u0094 scenarios etc. Within this \nframework, students\u0092 intention to understand and their vigorous interaction with the content \n(as opposed to their intention to complete task requirement and treating the task as an external \nimposition) were suggested by our group of experts, as fundamental characteristics of learning \nstyle to be evaluated. For the purpose of this experiment, the two characteristics were labelled \nas \u0093student's tendency to learn by discovery in a deep or surface way\u0094 and assessed as one \ncharacteristic by the neuro-fuzzy model. The students were classified as shallow or deep with \nrespect to their processing activities during learning by discovery.  \n  \n 28\nAnother important step is to decide what events of student's performance must be tracked \nand evaluated in order to assess this characteristic. The study activities that could help \nevaluating the learning style were suggested by the group of experts based on studies in \ncognitive psychology. Since the outcome of the deep approach to learning is a deep level of \nunderstanding of the subject matter, which is one of the evidences of expert-novice difference \nin physics, the group used information from research in expert-novice differences in physics \nin order to suggest the study activities. For example, experts tend to work forwards to a \nsolution whereas novices tend to work backwards [29]. When experts have analyzed a \nproblem, they apply the principles they have selected to the given quantities of the problem. \nIn that sense, the number of times a student tested his\/her ideas, or compared his\/her ideas \nwith the reality is taken into account in order to identify if the student is using trial and error \nstrategies. Student's activities when trying to find the correct forces, or after testing a correct \nor incorrect idea were also taken into consideration. In addition, students\u0092 problem solving \nspeed has also been taken into account. Research discovered that even though experts solve \nproblems four times faster than novices, they spent more time than novices analyzing and \nunderstanding the problems [12]. \n \n4.3.Implementing the neural network-based fuzzy model \n4.3.1 Tailoring the model  \nFollowing the discussion above, the group of experts suggested three linguistic variables \nB1, B2, B3 associated with student\u0092s actions within the 16 different activities (equilibrium \nexperiments) of the scenario \u0093Bodies in equilibrium\" that describe a subset of student's \nobservable behaviour B to be used in the diagnosis of student's tendency to learn by discovery \nin a deep or surface way. In addition the group also suggested the number and the names of \nthe linguistic values of each linguistic variable. Student\u0092s actions before trying to solve the \n  \n 29\nproblem or after making an incorrect attempt have been taken into account in B1=\u0093the \nnumber of times a student tests their ideas or compared their ideas with the reality\u0094, \ndescribed by the term set T(B1)={Seldom, Sometimes, Frequently}. Student's study activities \nduring problem solving, or after testing an incorrect idea have been taken into account in \nB2=\u0093the number of times the student consults the dictionary or reviews the theory or \ntemporarily stops to think\u0094, expressed with the term set T(B2)={Sometimes, Frequently, \nAlways}. The linguistic variable B3=\u0093problem solving speed\u0094 was described by the term set \nT(B3)={Slow, Medium, Fast}. \nThe experts took into consideration observations of students interacting with the learning \nenvironment and agreed on the ranges of the universe of discourses Uk (k=1,2,3) for each \ninput x1, x2, x3 representing the measured values of B1, B2, B3, respectively, as well as on the \nassociations between the linguistic values of each linguistic variable Bk and the universe of \ndiscourse Uk. For example, student\u0092s action \u0093temporarily stops in order to think\u0094, which is \nused in the calculations of x2, is measured from the student's idle interval between tries. For \nthe universe of discourse U2 of B2=\u0093the number of times the student consults the dictionary \nor reviews the theory or temporarily stops in order to think\u0094, a time percentage of this \ninterval is used, since it depends on the total time the student used the learning environment. \nThe linguistic variable B3=\u0093problem solving speed\u0094 is determined by computing the average \npercentage of time needed to find the correct forces of each experiment [20]. The time needed \nto find the forces applied to an object was compared against the time the group of experts \ndefined as the average time multiplied by two; thus the universe of discourse was set to [0, \n100]. In addition the group of experts also suggested to take into account student's prior \nexperience with the interface of the educational environment, as from their observations of \nstudents interacting with the software it was realised that the time a student needs to find the \ncorrect forces may also include the time needed to use the available tools that manipulate \n  \n 30\nvectors and draw these forces. Thus, the ranges can be adjusted for students with more prior \nexperience than ever expected. In the fuzzification stage, sigmoid functions for the extreme \nvalues and pseudo trapezoidal functions for the intermediate values have been used. Figure 8 \nillustrates the membership functions (continuous lines) and the adjusted membership \nfunctions (dotted lines) for the linguistic variable \u0093problem solving speed\u0094. \n2 5 5 0 7 5 1 0 0\n0\n0 . 5\n1\nF a s t M e d iu m S lo w\nU 3  \nFigure 8. Membership functions for the three linguistic terms of the \nlinguistic variable \u0093problem solving speed\u0094. \n \nThe three linguistic variables provide 27 (i.e. 3\u00d73\u00d73) possible combinations of the \nlinguistic values in the preconditions of the IF-THEN rules. The output of the diagnostic \nprocess was described with five linguistic values (mj =5) in the term set T(Cj)={Deep, Rather \nDeep, Average, Rather Shallow, Shallow}. The implemented neural network-based fuzzy \nmodel is shown in Figure 9. It associates student\u0092s observable behaviour B with student\u0092s \n\u0093deep\u0094 or \u0093shallow\u0094 tendency to learn by discovery by processing numerical input X (see \nFigure1) through a set of stages corresponding to fuzzification, inference and defuzzification, \nas described in the previous section. \n  \n 31\ndeep\nrather\ndeep\naverage\nrather\nshallow\nshallow\nfuzzifier\n  stage\ninference\n   stage\ndefuzzifier\n     stage\nm2\nm3\nm1\nx1\nx2\nx3\npreconditions layer  fuzzy relations\nthe number of times\nthe student tested his\nideas or compared\nwith the reality\nthe number of times\nthe student consulted\ndictionary or reviewed\ntheory or temporarily\nstopped to think\nproblem  solving\nspeed\n \nFigure 9. Network implemented to assess student\u0092s tendency to learn by discovery in a \ndeep or surface way. \n \n4.3.2  Generating the simulated students \nA set of simulated student has been generated in order to test our approach in case rule-\nbased diagnostic knowledge is available (Case 1; Section 3.4.1), and to represent in the neural \nnetwork teachers\u0092 diagnostic reasoning available by means of examples (Case 2; Section \n3.4.2).  \nSimulated students have been used in several ITS studies (see for example [21] [54] [56]). \nSince formative evaluation with real students is expensive, simulated students can help \nteachers and instructional developers to practice and evaluate the proposed instruction and can \nprovide an early feedback to developers in order to troubleshoot with their designs early in the \ndesign process [56].  \nIn the approach presented in this paper, we are interested to propose a convenient method \nto encode teacher\u0092s reasoning in evaluating general student\u0092s learning characteristics such as \n\u0093student's tendency to learn by discovery in a deep or surface way\u0094. The simulated students \n  \n 32\ncan provide a convenient way to obtain the large number of labelled patterns of students \nbehaviour needed to test the proposed approach in case of IF-THEN rules, or to train and test \nthe networks of the proposed approach in case where teacher\u0092s knowledge is available by \nmeans of examples, at an early stage of development.  \nIn order to construct simulated students\u0092 patterns of interaction with the learning \nenvironment that are \u0093close\u0094 to real students\u0092 behaviour patterns, we modified the underlying \nelements of patterns of a small set of real students. The real students\u0092 interaction patterns have \nbeen provided during an experiment which was carried out with the assistance of the group of \nexperts. In particular, the group identified 10 students to participate in the experiment; two \nfrom each of the five learning style categories considered in our model. During the \nexperiment participants were asked to perform the 16 different activities (equilibrium \nexperiments) of the scenario \u0093bodies in equilibrium\u0094, and their interactions were recorded in \nthe log file.  \nThe interactions data are organised in the following way: student\u0092s actions until s\/he quits \nan activity are decomposed in terms of episodes. Each episode includes a series of actions \nwhich begins or ends when the student clears the screen in order to start a new attempt on the \nsame activity, or a new equilibrium activity. Within each episode the student conducts, \nsuccessfully or unsuccessfully, an equilibrium experiment.  \nIn the experiment, students of different learning style categories exhibited different \ninteractive behaviour, giving different linguistic values for the linguistic variables B1, B2, B3 \nof their observable behaviour B and the respective measured values of the inputs {x1, x2, x3}. \nFor example, in case students patterns were classified as \u0093deep\u0094, B1={The number of times the \nstudent tests or compares ideas with the reality before trying to solve a problem, or after \nmaking an incorrect attempt} was described with the linguistic value seldom, B2 ={the \nnumber of times the student consults the dictionary or reviews the theory or temporarily stops \n  \n 33\nto think} with always, and B3={problem solving speed}with fast. In contrast, for student cases \nclassified as \u0093shallow\u0094, B1 was described with frequently, B2 with sometimes, and B3 with \nslow.  \nThe simulated students\u0092 records have been produced by modifying the number of episodes \nand by inserting, deleting or changing, at the appropriate position within each episode or \nbetween episodes, actions that are used to calculate the values of the input X={ x1, x2, x3 } \nwhich represents the measured values of B1, B2, B3. For example, inserting an action, such as \nthe use of the \u0093Test\u0094 button after an incorrect attempt, will cause an increase to the value of \nx1, which gives the measured value of B1. Deleting idle intervals between attempts will cause \na decrease to the value of x2, which gives the measured value of B2. Thus, starting with 10 \nreal students\u0092 records we can generate simulated students, altering the values of x1, x2, x3 in \nthe students\u0092 patterns by giving appropriate values within their universes of discourse U1, U2, \nU3.   \nThe first episode, showing an unsuccessful equilibrium experiment, from a series of \nepisodes of a \u0093shallow\u0094 real-student record is presented in tabular form in Figure 10. Each \nentry of the record corresponds to an action of the student together with a time-stamp showing \nminutes and seconds elapsed from the start of the activity. Words in quotes refer to \ntools\/buttons available, and pairs of unquoted numbers refer to mouse cursor positions. \nEntries in standard font refer to mouse moves or idle mouse states (e.g. the entry <\u0093test\u0094 \n3min, 0sec> denotes that the user moves the mouse over the button \u0093Test\u0094 but s\/he does not \nclick it). Entries in bold refer to particular mouse events, i.e. selecting\/clicking buttons (e.g. \nthe entry <\u201ctest\u201d 3min, 0sec> denotes that the user clicks the button \u0093Test\u0094), dragging objects \n(as for example when the student moves an object or he\/she draws a vector- a typical example \nof drawing action is shown in the third column of the table <\u201ccreate vector\u201d 1min, 10sec>. \nThe process involves mouse drag, starting in row <7335 5010 1min, 16sec> and ending in \n  \n 34\nrow <7440 6300 1min, 19sec>). Entries in bracket provide a short description of the actions \nof the real student (e.g. {Creates a gravitational force on box 40 magnitude 24 and     \ndirection -90 } is the result of the drawing action <\u201ccreate vector\u201d 1min, 10sec>). The record \nof the overall episode also reveals a misconception of the real student regarding the number of \nforces acting on the box of 40N. This is an indication of unfamiliarity with contact forces, as \nthe student draws only one contact force acting on the box of 40N whilst two forces are \nactually needed.  \nIn this particular episode, the student frequently (x1=8) uses the \u0093Test\u0094 or \u0093Reality\u0094 button \nbefore trying to solve a problem or after an incorrect attempt. No idle intervals or dictionary \nconsults (x2=0) where found on this record, regardless of student\u0092s inability to achieve a \nsuccessful equilibrium experiment. In addition the student at the end of the episode observes \nthe effect of his\/her choices on the Reality and decides to clear the screen, although the results \nobtained shown his\/her actions went wrong.  \nIn order to generate simulated students, the episode can be altered in different ways: \ndeleting some of the \u0093Test\u0094 or \u0093Reality\u0094 button selections, e.g. changing x1 values in the \ninterval [0,8] results in changing B1 to a predefined membership degree of the linguistic \nvalues seldom and sometimes; adding idle intervals and\/or \u0093dictionary\u0094 selections before \ndrawing forces, or after an incorrect \u0093Test\u0094, or at the end of the unsuccessful episode, e.g. \nchanging x2 values and membership degrees of the values of B2. Adding idle intervals will \nalso increase x2, i.e. the problem solving speed. In addition to the above alterations, we can \nalso reduce the problem solving speed of the generated simulated students by reducing the \nnumber of episodes needed to find the correct forces of a successful equilibrium experiment. \nFor example, the particular student needed 5 episodes and 18 minutes overall to produce a \ncorrect solution in this activity, i.e. the episode presented in Figure 10 lasts 5 minutes and is \njust one out of the 5 episodes needed for a successful equilibrium experiment (an overall time \n  \n 35\nof 18 minutes). As described in Subsection 4.3.1, B3=\u0093problem solving speed\u0094 is defined as a \npercentage of time, and the value of x3 is calculated by comparing the time a student needs in \norder to find the correct forces in each activity with the group\u0092s average time for finding the \ncorrect forces multiplied by two. For the particular activity that the student of Figure 2 is \nperforming using the two boxes, the group\u0092s estimated average time is 10 minutes. Thus, \ncalculating the percentage that corresponds to 10 minutes multiplied by 2 (i.e. 20 minutes), for \nthis student x3 = 90% which corresponds to the linguistic value \u0093Slow\u0094 with membership \ndegree very close to 1 (see Figure 8). By reducing the number of episodes of this activity to 4, \nthe total time of the episodes needed to find the correct forces will be 15 minutes; this \ncorresponds to a value of x3 = 75%, and the linguistic value for problem solving speed is now \n\u0093slow\u0094 with a membership degree 0.5 and \u0093Medium\u0094 with a membership degree 0.5 (see \nFigure 8).  \n \n{Begin:} \n{May 21 2001 12:15:15 PM} \n2280 2685 0min, 0sec \n4410 3420 0min, 0sec \n6480 3840 0min, 0sec \n8535 3915 0min, 0sec \n10185 6000 0min, 3sec \n\u0093attribute list\u0094 0min, 3sec \n\u0093select table\u0094 0min, 3sec \n11790 8130 0min, 3sec \n\u0093select table\u0094 0min, 3sec \n\u0093attribute list\u0094 0min, 3sec \n\u0093object list\u0094 0min, 3sec \n11775 6090 0min, 3sec \n\u201cobject list\u201d 0min, 4sec \n{opens the object list}  \n11310 4065 0min, 5sec \n11445 2025 0min, 7sec \n11415 4035 0min, 17sec \n9180 3195 0min, 25sec \n7140 3060 0min, 26sec \n9255 2625 0min, 29sec \n11340 3375 0min, 29sec \n9285 3420 0min, 31sec \n11295 4275 0min, 32sec \n11190 2250 0min, 33sec \n\u201cbox 40 N\u201d 0min, 36sec \n9795 2070 0min, 36sec  \n7785 3435 0min, 36sec \n{Puts on table box 40 N} \n7395 5160 0min, 36sec \n9630 3570 0min, 36sec \n\u201cbox 20 N\u201d 0min, 42sec \n8895 3585 0min, 42sec \n6795 4800 0min, 42sec \n{Puts on box 40 N box 20N} \n7455 4695 0min, 42sec \n9465 4725 0min, 43sec \n7305 3420 0min, 44sec \n5295 3255 0min, 45sec \n4005 1245 0min, 46sec \n\u0093useful tools\u0094 0min, 49sec \n\u201cuseful tools\u201d 0min, 50sec \n{opens the useful tools} \n\u0093goniometer\u0094 0min, 51sec \n\u0093assistant line\u0094 0min, 51sec \n\u0093spots\u0094 0min, 51sec \n\u0093axes\u0094 0min, 52sec \n\u0093spots\u0094 0min, 52sec \n\u0093clear screen\u0094 0min, 52sec \n\u201cuseful tools\u201d 0min, 53sec \n{closes the useful tools} \n\u0093clear screen\u0094 0min, 53sec \n\u0093useful tools\u0094 0min, 54sec \n\u0093axes\u0094 0min, 55sec \n6300 2025 0min, 57sec \n8460 2760 0min, 58sec \n10530 3435 0min, 58sec \n10800 5535 0min, 58sec \n\u0093object list\u0094 0min, 58sec \n\u0094attribute list\u0094 0min, 59sec \n\u201cattribute list\u201d 1min, 0sec \n{opens the attribute list} \n\u201cbox 1\u201d 1min, 5sec \n\u201cdraw forces\u201d 1min, 7sec \n\u0093gravitational forces\u0094 1min, \n8sec \n\u201cgravitational forces\u201d 1min, \n9sec \n\u0093shift direction\u0094 1min, 9sec \n\u0093change length\u0094 1min, 9sec \n\u0093move vector\u0094 1min, 10sec \n\u0093create vector\u0094 1min, 10sec \n\u201ccreate vector\u201d 1min, 10sec \n7335 5010 1min, 16sec \n7335 5070 1min, 16sec \n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.. \n            ( continued)       \n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.. \n7470 6180 1min, 18sec \n7470 6240 1min, 19sec \n7440 6300 1min, 19sec \n{Creates a gravitational force \non box 40 magnitude 24 and     \ndirection -90}  \n8460 4140 1min, 24sec \n6420 3285 1min, 25sec \n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.. \n            (continued)        \n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026. \n7485 3060 2min, 39sec \n7425 3105 2min, 40sec \n{Creates a contact force on box \n20 magnitude 17 and direction \n90} \n\u0093test\u0094 2min, 42sec  \n\u201ctest\u201d 2min, 43sec  \n5265 1950 2min, 46sec \n3210 1920 2min, 47sec \n1185 1785 2min, 48sec \n3585 1755 2min, 48sec \n5745 1830 2min, 48sec \n\u201cgravitational forces\u201d 2min, \n50sec \n\u0093shift direction\u0094 2min, 50sec \n\u0093delete vector\u0094 2min, 50sec \n\u0093shift direction\u0094 2min, 52sec \n\u0093change length\u0094 2min, 52sec \n\u0093move vector\u0094 2min, 52sec \n\u0093create vector\u0094 2min, 52sec \n\u201ccreate vector\u201d 2min, 52sec \n7410 4365 2min, 56sec \n7410 4425 2min, 56sec \n7410 4500 2min, 56sec \n7410 4560 2min, 56sec \n7410 4620 2min, 56sec \n7410 4680 2min, 56sec \n7410 4755 2min, 56sec \n7410 4815 2min, 56sec \n7410 4875 2min, 57sec \n7425 4935 2min, 57sec \n7440 4995 2min, 57sec \n7440 5055 2min, 57sec \n7425 4995 2min, 58sec \n{Creates a gravitational force \non box 20 magnitude 15 and      \ndirection -88 } \n\u0093test\u0094 3min, 0sec \n\u201ctest\u201d 3min, 0sec \n7815 2805 3min, 5sec \n5220 1140 3min, 5sec \n\u201cattribute list\u201d 3min, 9sec \n{closes the attribute list} \n\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085 \n      (continued)                \n\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085 \n7365 3495 3min, 39sec \n7365 3435 3min, 40sec \n7380 3375 3min, 40sec \n{Creates a contact force on box \n40 magnitude 28 and direction \n91} \n\u0093test\u0094 3min, 41sec \n\u201ctest\u201d 3min, 41sec \n9390 3930 3min, 48sec \n7830 1785 3min, 48sec \n\u0093reality\u0094 3min, 49sec \n\u201creality\u201d 3min, 49sec \n5775 1515 3min, 50sec \n\u0093delete vector\u0094 3min, 50sec \n\u201cattribute list\u201d 3min, 51sec \n{closes the attribute list} \n8280-210 3min, 51sec \n\u0094memo\u0094 3min, 52sec \n8130 1890 3min, 52sec \n8130 4065 3min, 53sec \n\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085. \n         (continued)          \n\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085\u0085. \n\u201cbox 2 4min, 7sec \n\u0093test\u0094 4min, 7sec \n\u201ctest\u201d 4min, 8sec \n\u0093reality\u0094 4min, 15sec \n\u201creality\u201d 4min, 16sec \n\u0093sound\u0094 4min, 21sec \n\u201cattribute list\u201d 4min, 23sec \n{closes the attribute list} \n8340 -195 4min, 23sec \n\u0093memo\u0094 4min, 23sec \n8100 2070 4min, 23sec \n8970 4365 4min, 24sec \n11010 2550 4min, 57sec \n\u0093EXIT\u0094 4min, 57sec \n11985 435 4min, 57sec \n\u0093EXIT\u0094 4min, 58sec \n\u201cclear screen\u201d 5min, 0sec \n{End:12:20:15} \n{Duration : 5 min and 0 sec} \n \n  \n 36\n \nFigure 10. An episode from a \u0093shallow\u0094 real-student record. \n \n4.3.3  Encoding rule-based diagnostic knowledge (Case 1). \nThe group of experts provided us with a series of IF-THEN rules that describe their \nreasoning in evaluating students\u0092 tendency to learn by discovery in a deep or surface way \nwhen working with the 16 different activities (equilibrium experiments) of the scenario \n\u0093bodies in equilibrium\u0094. The group\u0092s experience has been acquired through observing real-\nstudents interacting with the learning environment. Students\u0092 observable behaviour has been \ndescribed linguistically using the universes of discourse Uk , k=1,2,3, as described in previous \nsections. In order to obtain the set of rules, the groups was asked to classify students\u0092 \nbehaviour in one of the predefined linguistic values of the term set {Deep, Rather Deep, \nAverage, Rather Shallow, Shallow}, using with a combination of linguistic values of the \nlinguistic variables (this results in 27 different cases that correspond to preconditions of 27 \nrules). This allows the group to agree on a linguistic representation of the experts\u0092 individual \nreasoning (e.g. [if] the student seldom tests or compares ideas with activities of the real world \nbefore trying to solve a problem, or after an incorrect attempt, and always consults the \ndictionary or reviews the theory or temporarily stops in order to think after testing an incorrect \nidea, and their problem solving speed is high [then] the student tends to learn in a deep way). \nIn order to obtain the degree of confidence of each rule and implement the neural network that \nrealizes the fuzzy relation, as has been described in Subsection 3.4.1, the group was also \nasked to rate the confidence of their judgments using the rating scale: absolutely clear, very \nstrong, strong, rather strong, doubtful. We arbitrary adjusted the following values, dcl (l = \n1,2,\u0085,5), to each judgment dcl ={1, 0.9, 0.8, 0.7, 0.6}. In the first case, i.e. where the rule was \nprovided with the highest degree of confidence, a value of 1 was used. In all other cases, i.e. \n  \n 37\nl=2,\u0085,5, the value (1-dcl) was heuristically split over the two closest judgments (represented \nby neighbouring nodes in the network). Thus, group\u0092s diagnostic knowledge was encoded in \nthe network that realize the fuzzy relation and the following weights rij (i=1,2,\u0085.27, j=1,2,\u0085,5) \nof the matrix Ra were adjusted in the network: \n    0.1000    0.8000    0.1000         0              0 \n    0.0500    0.9000    0.0500         0              0 \n    0.8000    0.1000    0.0500    0.0500          0 \n    0.1000    0.8000    0.1000         0              0 \n    0.0500    0.9000    0.0500         0              0 \n    0.8000    0.1000    0.0500    0.0500          0 \n    0.7000    0.1500    0.1000    0.0500          0 \n    0.8000    0.1000    0.0500    0.0500          0 \n    0.9000    0.0500    0.0500         0              0 \n         0            0         0.0500    0.9000    0.0500 \n         0            0         0.1000    0.8000    0.1000 \n    0.0500    0.1000    0.7000    0.1000    0.0500 \n         0            0         0.1000    0.8000    0.1000 \n         0        0.0500    0.9000    0.0500         0 \n    0.1000    0.7000    0.1000    0.1000          0 \n         0        0.1000    0.8000    0.1000          0 \n    0.0500    0.9000    0.0500         0              0 \n    0.1000    0.8000    0.1000         0              0 \n         0            0         0.0500     0.0500    0.9000 \n         0        0.0500    0.0500     0.1000    0.8000 \n    0.0500    0.0500    0.1000     0.7000    0.1000 \n         0           0          0.1000     0.2000    0.7000 \n         0           0          0.1000     0.8000    0.1000 \n         0       0.1000     0.8000     0.1000         0 \n         0           0          0.0500     0.9000    0.0500 \n    0.0500    0.1000    0.7000     0.1000    0.0500 \n         0        0.0500    0.9000     0.0500         0 \n     R\u03b1  = \n \nEach row of matrix Ra corresponds to one of the 27 preconditions. Each column represents \none of the five learning style characterizations. Notice, for example that the last two rows of \nmatrix Ra represent in the network two, but relatively close, cases identified by the group of \nteachers: student\u0092s different learning style may be \u0093classified\u0094 as Average using different \ndegrees of confidence, i.e. 0.7 and 0.9 for the corresponding central nodes. Thus, four \nneighbouring nodes can be activated in the first case, and two nodes in the second. \n \n4.3.4 Encoding example-based diagnostic knowledge (Case 2) \nThe group of expert teachers was asked to label patterns of simulated students performing the \n16 different activities (equilibrium experiments) of the scenario \u0093bodies in equilibrium\u0094, with \nrespect to their \u0093tendency to learn in a deep or surface way\u0094. A set of 54 simulated students \nhas been generated to this end. The set included two simulated student for each one of the 27 \ncombinations of linguistic values of the linguistic variables representing student\u0092s behaviour, \nin accordance with the preconditions of the 27 rules. In addition almost clear-cut simulated \n  \n 38\nstudents cases were generated, i.e. simulated students with membership degrees to each \nlinguistic value greater than 0.7. The group classified the set of 54 (27\u00d72) simulated students \nin one of the linguistic values of the term set {Deep, Rather Deep, Average, Rather Shallow, \nShallow}. The particular input values X={x1, x2, x3} of each simulated student pattern were \nprocessed through the fuzzifier stage and the preconditions layer, in order to form together \nwith experts\u0092 classifications the input-output vectors to train the fuzzy relations network, as \ndescribed in Subsection 3.4.2. A positive stepsize \u03c1=1 was used for training. The following \nmatrix Rl was produced: \n          0       0.8800          0               0             0 \n    0.0200    0.8800          0               0             0 \n    0.8800         0              0               0             0 \n    0.1200    0.8800          0               0             0 \n    0.1200    1.0000          0               0             0 \n    0.8800    0.0200          0               0             0 \n    0.8300         0              0               0             0 \n    0.9800         0              0               0             0 \n    0.8800     0.0200         0               0             0 \n         0         0.2300         0          0.9800     0.0200 \n    0.0200     0.1200     0.0200     1.0000     0.1200 \n    0.1200         0          1.0000     0.1200         0 \n    0.0200     0.1200     0.1200     0.9800     0.1200 \n    0.0200     0.1200     0.9800     0.1200     0.0200 \n    0.1700     0.9800     0.1200     0.1200         0 \n    0.1700         0          1.0000     0.1200         0 \n    0.0200     0.9800     0.1200     0.1200         0 \n    0.2300     0.8800     0.1200     0.1200         0 \n         0            0                0              0          0.9800 \n         0            0                0         0.1200     1.0000 \n         0            0                0         0.8800     0.0200 \n         0            0           0.0200     0.1200     0.9800 \n         0         0.0200     0.1200     1.0000     0.1200 \n         0         0.0200     1.0000     0.1700     0.0200 \n         0           0            0.0200     0.8800     0.0200 \n         0         0.0200     1.0000     0.1700     0.0200 \n         0         0.0200     0.9800     0.1200         0 \n    Rl  = \n \nThe weights learned, i.e. the elements of matrix Rl, represent the degree of confidence of \nthe rules. We can find similarities between matrix Rl and matrix Ra, since the same group of \nexperts participated in both experiments. For example, the same network connections have \nweights greater than 0.8 in both matrices. In addition, connections of neighbouring nodes \nhave weights less than 0.3; thus only slightly activating the neighbour nodes, but contributing \nto the final classification. The defuzzifier was trained to produce the final decision, as \ndescribed in the previous section. \n \n  \n 39\n4.4.Evaluating the neuro-fuzzy diagnostic model \n4.4.1 Testing the rule-based diagnostic model (Case 1) \nIn order to evaluate the performance of the rule-based neuro-fuzzy model, three test sets \neach one having 62 simulated students with predefined linguistic values in the linguistic \nvariables of their observable behaviour, and predefined membership degrees to these values as \nwell, have been generated. The first set contains patterns with clear-cut descriptions of \nstudents\u0092 observable behaviour, i.e. their membership degrees in the linguistic values of each \nlinguistic variable are close to 1. The second set involves a lot of uncertainty; there are no \nclear-cut cases due to lack of well-defined boundaries in evaluating students\u0092 observable \nbehaviour. This set includes marginal cases, i.e. patterns that contain membership degrees \nclose to 0.5 in two linguistic values of one or more than one linguistic variables. This data set \nwas used to test the capability of the model in the handling of uncertainty incorporated in the \nmarginal cases of students\u0092 observable behaviour. This capability is usually not supported in a \nnon-fuzzy rule-based environment. The third set consists of special marginal cases, which are \npossible to cause conflicting judgments if they processed by classic IF-THEN rules. A typical \nexample is when two IF-THEN rules with close precondition categorize the student into two \ndifferent non-adjoining categories, as will be described below.  \nThe patterns of these data sets formulate the input values X={x1, x2, x3} of the rule-based \nneuro-fuzzy model, and are classified in one out of the five categories {Deep, Rather Deep, \nAverage, Rather Shallow, Shallow}. The three set of simulated student cases have been \npresented to the group of expert, in order to be labelled according to the term set {Deep, \nRather Deep, Average, Rather Shallow, Shallow}. The classifications of the neuro-fuzzy \nmodel were compared with experts' classifications of the same simulated students. The \naverage success in diagnosis for the first test set reached 100%. The model also provided an \nexcellent average performance, 90%, in evaluating marginal cases (second test set), in \n  \n 40\naccordance to group\u0092s judgements. In the third test set (special marginal cases) an average \nperformance of 85% was achieved. The neuro-fuzzy model showed that it is indeed capable to \nhandle these special marginal cases by fine-tuning the rules encoded in the fuzzy system \nthrough the neural network-based defuzzification procedure. \nAt this point is useful to illustrate the behaviour of our model with some examples. Let us \nconsider a student who \u0093frequently tests or compares ideas with activities of the real world \nbefore trying to solve a problem, or after an incorrect attempt, who sometimes consults the \ndictionary or reviews the theory or temporarily stops after testing an incorrect idea in order to \nthink, and has slow problem solving speed\u0094, and another student who \u0093sometimes tests or \ncompares ideas with activities of the real world, and frequently consults or reviews or thinks, \nand has medium problem solving speed\u0094. The first student\u0092s learning style has been evaluated \nby the group as \u0093Shallow\u0094, and the second student\u0092s style as \u0093Average\u0094; group\u0092s confidence \nin their judgments is in both cases \u0093Very strong\u0094. In our model, when the membership \ndegrees to the above linguistic values of student\u0092s observable behaviour are equal to 1, these \ntwo evaluation decisions provide at the output of the inference stage the following fuzzy \nassessments vectors: [0, 0, 0.05, 0.05, 0.9] and [0, 0.05, 0.9, 0.05, 0], for the first and the \nsecond case respectively. Finally, after defuzzification, the students are classified into two \nquite different non-adjoining categories.  \nLet us now consider a special marginal case where student's observable behaviour causes \ntwo rules to fire. This may be the case of a student who tests or compares ideas with activities \nof the real world frequently with a membership degree of 0.4 and sometimes with a \nmembership degree of 0.59. The student also sometimes with a membership degree of 0.4 and \nfrequently with a degree of 0.59 consults the dictionary or reviews the theory or temporality \nstops to think after testing an incorrect idea. The same student also has problem solving speed \nthat is slow with a membership degree of 0.4 and medium with a degree of 0.59. This \n  \n 41\ncomplicate case will provide at the end of the inference stage the following fuzzy assessment \nvector: [0, 0.05, 0.59, 0.4, 0.4]. The final decision at the output of the defuzzifier is that this \nstudent\u0092s learning style is \u0093Rather Shallow\u0094 a decision between the two categories, which is \nindeed consistent with group\u0092s judgments when classifying similar marginal cases of real or \nsimulated students. \nOne of the goals in our implementation is to propose a model that can be tailored to \nindividual teacher\u0092s experiences or judgment. The neuro-fuzzy implementation of the model \ncan easily handle subjectivity of teachers' suggestions and reasoning, because it allows \nteacher\u0092s rules to be encoded directly from teacher's linguistic description, creating that way a \nmodel tailored to the needs of a particular teacher in case of disagreement. That was indeed \nvery useful in our case because one of the teachers in our group of experts wanted to use the \nlearning environment in a primary school, i.e. with students of smaller age and different \nknowledge level and experience than the ones used so far. That gave us the opportunity to \nevaluate the adaptability of our model to teacher\u0092s subjective judgements following his \nsuggestions, and additional experiments have been performed.  \nWe used the same linguistic variables and the same linguistic values for student\u0092s \nobservable behaviour, as well as the same linguistic values that were suggested by our group \nof experts. To tailor the model to the teacher\u0092s suggestions, adjustments have been made in \nthe association between the linguistic values and the universes of discourse by changing the \nadjusting parameters m1, m2, m3 that represent the expected mean value of the numerical input \nX={x1, x2, x3 } (thus, slightly altering the shape of the membership functions, i.e. the degree \nof membership to each linguistic value), as well as in the IF-THEN rules by changing the \nweights in the fuzzy relations network that realizes the inference stage. Additional \nexperiments with simulated students have been performed to test the tailored model. Students' \nclassifications by the neuro-fuzzy model were compared with teacher's classifications for the \n  \n 42\nsame simulated students. The model showed was successfully adapted, classifying the \nstudents according teacher's classifications with constant classification success for each case.  \n \n4.4.2 Testing the example-based diagnostic model (Case 2) \nIn order to test our approach when the diagnostic knowledge is available by means of \nexamples, we used the same three test data sets. The input values X={x1, x2, x3} of each \npattern of the three test data sets has been processed by the trained neuro-fuzzy model and \nclassified in one of the linguistic values of the term set {Deep, Rather Deep, Average, Rather \nShallow, Shallow}. In addition, the three set of simulated student were classified in one of the \nlinguistic values of the term set {Deep, Rather Deep, Average, Rather Shallow, Shallow} by \nthe group of experts, and groups' classifications were compared against the neuro-fuzzy \nmodel classifications. The overall average success in diagnosis reached 94%, i.e. 100%, 96%, \n86% for each of the three data sets respectively; practically the same levels as in case of IF-\nTHEN rules. \nWe conducted additional experiments in order to compare the neural-network based fuzzy \nmodel proposed in this paper against two other approaches, namely a classic multilayer \nNeural Network (NN) with 3 input-10 hidden-5 output nodes trained with the \nbackpropagation algorithm with variable stepsize [33], and a Fuzzified Neural Network \n(FNN) that is based on the ANFIS architecture, [40], with pseudotrapezoidal fuzzy sets, 27 \nrules and outputs corresponding to the categories {Deep, Rather Deep, Average, Rather \nShallow, Shallow}. All methods used the same simulated students for training and were tested \non the same testing data sets (test set 1 contains clear-cut cases of simulated students; test set \n2 marginal cases; test set 3 special marginal cases)  \nFigure 11 shows the best available performance in classification achieved by each model. \nThe classic NN approach provides a diagnostic success of 84%, 82%, and 80% in the three \ndata sets. The diagnostic success of the FNN was 100%, 98%, and 63%. When we compare \n  \n 43\nthese results with the corresponding results of the neuro-fuzzy model, which represents \nknowledge with the use of fuzzy relations in addition to the fuzzified inputs and the \nprecondition layer, it is clear that the neuro-fuzzy model provides improved performance in \nclassifying the third test data set (special marginal cases).  \nTest set NN FNN neuro-fuzzy \nNo 1 84% 100% 100% \nNo 2 82% 98% 96% \nNo 3 80% 63% 86% \n \nFigure 11: Comparative results in the three test data. \nWe have further analyzed the average behaviour of the three models as they all incorporate \ntraining networks. 30 instances of each model were trained and tested on the three test sets. \nThe average classification success and standard deviation, for the three models are shown in \nTable 1.  \nTest set NN FNN neuro-fuzzy \nNo 1 78 \u00b1 3 99.7 \u00b1 0.6 99 \u00b1 3.0 \nNo 2 76 \u00b1 3 96 \u00b1 2 93.0 \u00b1 3 \nNo 3 74 \u00b1 3.5 57 \u00b1 2 84.4 \u00b1 0.8 \n \nTable 1. Average classification success and standard deviation for the three models. \n \nThe performance results were checked for statistical significance using the t-test. All \ndifferences found to be statistically significant with t values greater than 10. As we can see in \nTable 1, the FNN shows a better performance than the neuro-fuzzy model in the test set 1 \n(clear-cut cases) and the test set 2 (marginal cases). This performance of the neuro-fuzzy \nmodel is compensated from its performance in the test data 3 (special marginal cases). \nWe have also analyzed the types of classification errors the three models can produce. This \nis particularly important as the outcome of the diagnosis has an impact on the pedagogical \nstrategy adopted for each student. In our tests, we have identified three types of errors. The \ntype 1 error happens when a student has been incorrectly classified in an adjoining category, \n  \n 44\ni.e. with rank difference of one. For example, this type of error occurs when a student is \nevaluated by the group of experts as rather shallow (regarding his tendency to learn by \ndiscovery in a deep or surface way), but a model classifies him\/her in the category shallow or \naverage. On the other hand, when the student is classified as rather deep (rank difference of \ntwo), a type 2 error occurs. When the student is classified as deep (rank difference of three), a \ntype 3 error occurs. All misclassifications of the rule-based neuro-fuzzy model (Case 1), \nproduced type 1 errors, i.e. students were classified into an adjoining category compared with \nthe groups\u0092 classification. The same behaviour has been exhibited by the example-based \nneuro-fuzzy model (Case 2). This was also a significant improvement over previous work \n[53]. In contrast, as shown in Figure 12, the other models produce misclassifications of types \n2 and 3; the FNN exhibits a 4% of type 2 errors and 1% of type 3 errors; whilst the NN \nexhibits 6% of type 2 errors, and 1% of type 3 errors.  \n \nError type NN FNN neuro-fuzzy \ntype 1 93% 95% 100% \ntype 2 6% 4% 0% \ntype 3 1% 1% 0% \n \nFigure 12. Percentage of type of errors for the three models. \n \n5. Conclusions \nIn this paper a neuro-fuzzy model of the diagnostic process was proposed for inferring \nstudent characteristics. A main advantage of the new approach is that the neuro-fuzzy model \nallows creating an interpretable knowledge representation, which can be developed on the \nbasis of rules when reasoning is well defined, as well as it can be trained when the reasoning \nstrategy is purely intuitive and ill-defined. In addition the model can be easily tailored to a \nteacher's personal view. This approach can be used to implement an open student model, \nwhich will be interactively adjusted by the teacher.  \n  \n 45\nExperimental results from testing the new model in a discovery learning environment were \nparticularly encouraging, showing that this method is capable of handling uncertainty better \nthan other soft computing methods. The experiment has shown the potential of neuro-fuzzy \nsynergism, but it was only a small-scale study. Further work needs to be undertaken to fully \nexplore the benefits and limitations of this approach. Our current work targets the extraction \nof knowledge from existing student profiles to drive model\u0092s adaptation during operation with \nthe aim to adapt the feedback and pedagogical strategy to students\u0092 learning style. \n \n6. References \n[1] F. N. Akhras, J. A. Self, Beyond intelligent tutoring systems: Situations, interaction, process and \naffordances. Instructional Science 30 (2002) 1-30. \n[2] A. B. Arons, A guide to introductory physics teaching. Washington, John Wiley and Sons Inc, 1990. \n[3] J. Beck, M. Stern, B. P. Woolf, Using the Student Model to Control Problem Difficulty, in: Proceedings of \nthe Sixth International Conference on User Modeling (1997), pp. 277-289, available on-line: \nhttp:\/\/www.cs.umass.edu\/~beck\/publications.html, accessed at 31\/11\/2000. \n[4] J. J. Beshuizen, E. T. Stoutjesdijk, Study strategies in a computer assisted study environment, Learning and \nInstruction 9 (1999) 281-301. \n[5] J. Biggs, The Study Process Questionnaire (SPQ) Manual, Australian Council for Educational Research, \nMelbourne, 1987. \n[6] J. Biggs, Student approaches to learning and studying, Australian Council for Educational Research, \nHawthorn Victoria, 1987. \n[7] J. S. Brown, A. Collins, P. Duguid, Situated cognition and the culture of learning, Educational researcher \n18 (1989) 32-34. \n[8] P. Brusilovski, Student model centered architecture for intelligent learning environments. In Proc. of \nFourth International conference on User Modeling, 15-19 August, Hyannis, MA, Usa, User Modeling Inc, \n(1994), pp. 31-36. \n[9] R. J. G. B. Campello, W. C Amaral, Modeling and linguistic knowledge extraction from systems using \nrelational models, Fuzzy Sets and Systems 121 (2001) 113-126. \n  \n 46\n[10] Q. Chen, A. F. Norcio, J. Wang, Neural Network Based Stereotyping for User Profiles, Neural Computing \nand Applications 9 (2000) 259-265. \n[11] M.T.H. Chi, R. Glaser, E. Rees, Expertise in problem solving, In Sternberg R. J. (Ed): Advances in the \npsychology of human intelligence, Vol 1, Hillsdale, NJ: Erlbaum, 1982. \n[12] M. T. H. Chi, P. J. Feltovich, R. Glaser, Categorization and representation of physics problems by experts \nand novices, Cognitive Science 5 (1981) 121-152 \n[13] C. Conati, A. Gertner, K Vanlehn, Using Bayesian Networks to Manage Uncertainty in Student Modeling, \nUser Modeling and User-Adapted Interaction 12 (2002) 371 -417. \n[14] J. Dae-Sik, C Hyung-Il, Fuzzy Inference System Based on Fuzzy Associative Memory, Journal of \nIntelligent and Fuzzy Systems 5 (1997) 271-284. \n[15] S. J. Derry, M. K. Potts, How Tutors Model Students: A Study of Personal Constructs in Adaptive \nTutoring, American Educational Research Journal 35 (1) (1998) 65-99. \n[16] R. Driver, The pupil as a scientist?, Milton Keynes: Open University Press, 1983. \n[17] R. Driver, E. Guesne, A. Tiberghien, Children\u0092s Ideas in Science, Philadelphia: University Press, 1985. \n[18] N. Entwistle, A model of the teaching-learning process, in: J. T. E. Richardson M. W. Eysenck and D. \nWarren Piper (Ed), Student Learning : Research in Education and Cognitive Psychology, Milton Keynes: \nSRHE; Open University Press, 1987, pp. 13-28 \n[19] M. Grigoriadou, G. D. Magoulas, M. Panagiotou. A hybrid decision making model for intelligent tutoring \nsystems, in: Proceedings of the 5th International Conference of the Decision Sciences Institute, Athens, \nGreece, 1999, pp. 195-197.  \n[20] M. Grigoriadou, D. Mitropoulos, M. Samarakou, C. Solomonidou, E. Stavridou, Methodology for the \nDesign of Educational Software in Mathematics and Physics for Secondary Education, in: Conference \nProceedings of Computer Based Learning in Science, 1999, pB3. \n[21] S. A. Harp, T. Samad, M. Villano, Modeling student knowledge with self-organizing feature maps, IEEE \nTransactions on Systems Man and Cybernetics 25 (5) (1995) 727-737. \n[22] L. W. Hawkes, S. J. Derry, Advances in Local Student Modeling Using Informal Fuzzy Reasoning, \nInternational Journal of Human-Computer Studies 45 (1996) 697-722. \n[23] L. W. Hawkes, S. J Derry, E. A. Rundensteiner, Individualized tutoring using an intelligent fuzzy temporal \nrelational database, International Journal of Man-Machines Studies 33 (1990) 409-429 \n  \n 47\n[24] C. Herzog, Fuzzy-Techniken fur das Verstehen von Studentenlosugen in intelligenten Lehrsystemen \n[Fuzzy techniques for understanding student solutions in intelligent tutoring systems], in: R. Gunzenhauser, \nC. Mobus, and D. Rosner (Ed), Beitrage zum 7. Arbeistreffen der GI-Fachgruppe 1.1.5\/7.0.1, \u0093Intelligente \nLehr-\/Lernsysteme\u0094 [Papers for the Seventh Meeting of GI Section 1.1.5\/7.0.1, \u0093Intelligent Tutoring \nSystems\u0094], Research Institute for Application-Oriented Knowledge Processing (FAW), Germany, 1994. \n[25] P. Holt, S. Dubs, M. Jones, J. Greer, The state of student modeling, in: Proceeding of NATO advanced \nresearch workshop on \"Student Modeling: The Key to Individualized Knowledge-Based Instruction\", \nQuebec, Canada,. Springer-Verlag, 1991, pp 5-35. \n[26] A. Jameson, Numerical Uncertainty Management in User and Student Modeling: An Overview of Systems \nand Issues, User Modeling and User-Adapted Interaction 5 (1996) 193-251, available on-line: \nhttp:\/\/www.w5.cs.uni-sb.de\/amp\/home-page.html, accessed at 20\/01\/2001. \n[27] S. Katz, A. Lesgold, G. Eggan, M. Gordin, Modelling the student in Sherlock II, Journal of Artificial \nIntelligence in Education 3 (4) (1992) 495-518. \n[28] B. Kosko, Neural Networks and Fuzzy systems: A Dynamical Systems Approach to Machine Intelligence, \nPrentice-Hall, 1992.  \n[29] J. H. Larkin, J. McDermott, D. Simon, H. A. Simon, Expert and novice performance in solving physics \nproblems, Science 208 (1980) 1335-1342. \n[30] L. D. Lascio, A. Gisolfi, V. Loia, Uncertainty processing in user-modeling activity, Information Sciences \n106 (1998) 25-47.  \n[31] X. Li, D. Ruan, Novel neural algorithms based on fuzzy \u03b4 rules for solving fuzzy relation equations: Part I, \nFuzzy Sets and Systems 90 (1997) 11-23. \n[32] G .D. Magoulas, K. A. Papanikolaou, M. Grigoriadou, Neuro-fuzzy Synergism for Planning the Content in \na Web-based Course, Informatica 25 (2001) 39-48. \n[33] G. D. Magoulas, M. N. Vrahatis, G. S. Androulakis, Effective back-propagation training with variable \nstepsize, Neural Networks 10 (1997) 69-82. \n[34] F. Marton, R. Saljo, Approaches to learning, in: F. Marton, D. Hounsell and N. Entwistle (Ed.), The \nexperience of learning, Scottish Academic Press, Endinburg, 1984, pp. 36-55. \n[35] D. McArthur, C. Stasz, M. Zmuidzinas, Tutoring techniques in algebra, Cognition and Instruction 7 (1990) \n197-244. \n  \n 48\n[36] S Mengel, W Lively, Using a neural network to predict student responses, in: Proceedings of the 1992 \nACM\/SIGAPP Symposium on Applied Computing, 2, March 1-3, Kansas City, MO, 1992, pp. 669-676. \n[37] S. Mengel, W. Lively, On the use of neural networks in intelligent tutoring systems, Journal of Artificial \nIntelligence in Education 2 (1) (1990) 43-56. \n[38] T., M., Mitchell. Machine learning, McGraw-Hill, 1997. \n[39] NATO ASI Series, Proceedings of NATO advanced research workshop on \"Student Modeling: The Key to \nIndividualized Knowledge-Based Instruction\" Quebec, Canada, Springer-Verlag, 1991. \n[40] M. Negnevitsky, Artificial Intelligence: a guide to intelligent systems, Addison Wesley, 2002. \n[41] A. Paiva, About User and Learner Modeling- an Overview (1995), available on-line: \nhttp:\/\/cbl.leeds.ac.uk\/~euroaied\/papers\/Errico, accessed at 25\/01\/2001. \n[42] M. Panagiotou, M. Grigoriadou, An Application of Fuzzy Logic to Student Modeling, in: Proceedings of \nthe IFIP World conference on Computer in Education (WCCE95), Birmigham, 1995. \n[43] K. A. Papanikolaou, K. A. Magoulas, M. Grigoriadou, Computational intelligence in adaptive educational \nhypermedia, in: Proceedings of Int. Join Conf. on Neural Networks 2000 Como Italy, IEEE Press, Los \nAltamitos, 2000, pp. VI-629 \n[44] W. Pedrycz, Identification in Fuzzy Systems, IEEE Trans. on Systems Mans and Cybernetics 14 (2) (1984) \n361-366. \n[45] W. Pedrycz, Neurocomputations in Relational Systems, IEEE Transactions on Pattern Analysis and \nMachine Intelligence 13 (3) (1991) 289-296. \n[46] C. L. Posey, L. W. Hawkes, Neural Networks Applied to Knowledge Acquisition in the Student Model, \nInformation Sciences 88 (1996) 275-298. \n[47] R. T. Putman, Structuring and adjusting content for students: A study of live and simulated tutoring in \naddition, American Educational Research Journal 24 (1987) 13-48. \n[48] K. Reusser, From Cognitive Modeling to the Design of Pedagogical Tools, in: S. Vosniadou E. De Corte \nR.Glaser H. Mandl (Ed), International Perspectives on the Design of Technology-Supported Learning \nEnvironments, 1996, pp. 81-103 \n[49] J. Self, Computational Mathetics: Towards a Science of Learning Systems Design, Draft www document, \n1995, available on-line: http:\/\/cbl.leeds.ac.uk\/~jas\/cm.html, accessed at 20\/02\/2002. \n  \n 49\n[50] J. Self,. Formal Approaches to Student Modelling, in: Proceedings of NATO advanced research workshop \non \"Student Modeling: The Key to Individualized Knowledge-Based Instruction\", Quebec, Canada, \nSpringer-Verlag, 1991, pp. 295-352. \n[51] R. Sison, M. Shimura, Student Modeling and Machine Learning, International Journal of Artificial \nIntelligence in Education 9 (1998) 128-158. \n[52] C. Solomonidou, E. Stavridou, T. Christidis, The history of ideas and the students\u0092 learning difficulties \nabout force and motion as a guide for the didactic use of the software \u0093Interactive Physics\u0094 (Published in \nGreek), Paidagogiki Epitheorisi 26 (1997) 77-112. \n[53] R. Stathacopoulou, G. D. Magoulas, M. Grigoriadou, Neural Network-based Fuzzy Modeling of the \nStudent in Intelligent Tutoring Systems, in: Proceedings of Inter. Joint Conference on Neural Networks \n1999 Washington, CD-ROM proceeding, IEEE Catalog Number: 99CH36339C, 1999, paper #679. \n[54] S. Ur, K. VanLehn, STEPS: A simulated, tutorable physics student, Journal of Artificial Intelligence in \nEducation 6 (4) (1995) 405-437. \n[55] K. VanLehn, Student Modeling, in: M. C. Polson and J. J. Richardson (Ed), Foundations of Intelligent \nTutoring Systems, Lawrence Elbaum, 1988, pp.55-78. \n[56] K. Vanlehn, S. Ohlsson, R. Nason, Applications of Simulated Students: An Exploration. Journal of \nArtificial Intelligence in Education 5(2) (1994) 135-175. \n[57] J. D. H. M. Vermunt, F. A. W. M. Van Rijswijk, Inventaris Leerstijlen voor het hoger onderwijs [Inventory \nof learning styles for higher education], The Netherlands: Brabant University, Tilburg, 1987. \n[58] S. Vosniadou, From cognitive theory to educational technology, In: Vosniadou S., De Corte E., Mandl H. \n(Ed), Technology-Based Learning Environments, Psychological and Educational Foundations. NATO ASI \nSeries F, vol. 137, Berlin: Springer-Verlag, 1994, pp. 11-17. \n[59] K. Warendorf, S. J. Tsao, Application of Fuzzy Logic Techniques in the BSS1 Tutoring System, Journal of \nArtificial Intelligence in Education 8 (1) (1997) 113-146 \n[60] E. Wenger, Artificial Intelligence and Tutoring Systems: Computational and Cognitive Approaches to the \nCommunication of Knowledge, Morgan Kaufmann, 1987. \n[61] R. Yasdi, A Literature Survey on Applications of Neural Networks for Human-Computer Interaction, \nNeural Computing and Applications 9 (2000) 245-258. \n  \n 50\n[62] L. A. Zadeh, Fuzzy sets and systems (1965), in: G. J. Klir and B. Yuan (Ed), Fuzzy Sets Fuzzy Logic and \nFuzzy Systems: Selected Papers by Lofti A. Zadeh, Advances in Fuzzy Systems-Application and Theory \nVol 6, World Scientific, 1996, pp. 35-43. \n[63] L. A. Zadeh, Fuzzy Languages and their Relation to Human and Machine Intelligence(1972), in: G. J. Klir \nand B. Yuan (Ed), Fuzzy Sets Fuzzy Logic and Fuzzy Systems: Selected Papers by Lofti A. Zadeh, \nAdvances in Fuzzy Systems-Application and Theory Vol 6, World Scientific, 1996, pp. 148-179.  \n[64] L. A. Zadeh, Knowledge Representation in Fuzzy Logic(1989), in: G. J. Klir and B. Yuan (Ed), Fuzzy Sets \nFuzzy Logic and Fuzzy Systems: Selected Papers by Lofti A. Zadeh, Advances in Fuzzy Systems-\nApplication and Theory Vol 6, World Scientific, 1996, pp. 764-774.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n 51\nFigure 1: Schematic of the diagnostic model. \nFigure 2: The implementation of a fuzzifier  \nFigure 3: Sample of membership functions. \nFigure 4: Network architecture for implementing the fuzzy relation. \nFigure 5:. Introductory screen of the learning environment \"Vectors in Physics and \n                Mathematics\" \nFigure 6: Scenario \"Bodies in equilibrium\" \nFigure 7: Activity with two boxes on the table. \nFigure 8: Membership functions for the three linguistic terms of the linguistic variable \n                \u0093problem solving speed\u0094. \nFigure 9: Network implemented to assess student\u0092s tendency to learn by discovery  \n                in a deep or surface way. \nFigure 10. An episode from a \u0093shallow\u0094 real-student record \nFigure 11: Comparative results for the three test data. \nFigure 12. Percentage of type of errors for the three models. \n \nTable 1. Average classification success and standard deviation for the three models. \n \n \n"}
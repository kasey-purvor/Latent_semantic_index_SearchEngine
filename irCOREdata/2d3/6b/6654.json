{"doi":"10.1080\/0968776980060206","coreId":"6654","oai":"oai:generic.eprints.org:274\/core5","identifiers":["oai:generic.eprints.org:274\/core5","10.1080\/0968776980060206"],"title":"Computer\u2010aided assessment in statistics: The CAMPUS project","authors":["Hunt, Neville"],"enrichments":{"references":[{"id":1041866,"title":"An introduction to creating CAL courseware with Microsoft Excel 5',","authors":[],"date":"1995","doi":null,"raw":"Tidball, J. (1995), An introduction to creating CAL courseware with Microsoft Excel 5', Aberdeen: MERTaL Publications (University of Aberdeen).","cites":null},{"id":192674,"title":"Teaching statistical concepts using spreadsheets', Teaching Statistics, ASLU Supplement","authors":[],"date":"1996","doi":"10.1111\/j.1467-9639.1996.tb00849.x","raw":"Hunt, D.N. (1996), 'Teaching statistical concepts using spreadsheets', Teaching Statistics, ASLU Supplement 1996, 1-3.","cites":null},{"id":192675,"title":"Using IT to generate individualised coursework questions and solutions for an introductory course in statistics and probability',","authors":[],"date":"1998","doi":null,"raw":"Simonite, V., Ells, P. and Turner, W. (1998), 'Using IT to generate individualised coursework questions and solutions for an introductory course in statistics and probability', CTI Maths & Stats, February 1998.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"1998","abstract":"This paper describes the specification, features and implementation of computer\u2010aided assessment software designed primarily for conducting assessments in Statistics but equally applicable to other quantitative disciplines. The CAMPUS (Computer Aided Marking Program Using Spreadsheets) package has been developed in Microsoft Excel so as to provide a familiar computing environment for both assessors and students. The principal feature of CAMPUS is the facility for setting questions containing random elements (including random graphs), so that each student sits essentially the same questions but with different answers. This helps to eliminate plagiarism and allows a single test to be used many times, either for reassessment or additional practice. CAMPUS has been implemented in a higher\u2010education context but could also be used at school level","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/6654.pdf","fullTextIdentifier":"http:\/\/repository.alt.ac.uk\/274\/1\/ALT_J_Vol6_No2_1998_Computer_aided_assessment_in_s.pdf","pdfHashValue":"d13c145b7524b63f3fd1a2169721797a53d6fdb2","publisher":"University of Wales Press","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:generic.eprints.org:274<\/identifier><datestamp>\n      2011-04-04T09:19:13Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D4C:4C42<\/setSpec><setSpec>\n      7375626A656374733D4C:4C43:4C4331303232<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/repository.alt.ac.uk\/274\/<\/dc:relation><dc:title>\n        Computer\u2010aided assessment in statistics: The CAMPUS project<\/dc:title><dc:creator>\n        Hunt, Neville<\/dc:creator><dc:subject>\n        LB Theory and practice of education<\/dc:subject><dc:subject>\n        LC1022 - 1022.25 Computer-assisted Education<\/dc:subject><dc:description>\n        This paper describes the specification, features and implementation of computer\u2010aided assessment software designed primarily for conducting assessments in Statistics but equally applicable to other quantitative disciplines. The CAMPUS (Computer Aided Marking Program Using Spreadsheets) package has been developed in Microsoft Excel so as to provide a familiar computing environment for both assessors and students. The principal feature of CAMPUS is the facility for setting questions containing random elements (including random graphs), so that each student sits essentially the same questions but with different answers. This helps to eliminate plagiarism and allows a single test to be used many times, either for reassessment or additional practice. CAMPUS has been implemented in a higher\u2010education context but could also be used at school level.<\/dc:description><dc:publisher>\n        University of Wales Press<\/dc:publisher><dc:date>\n        1998<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:rights>\n        cc_by_nc_nd<\/dc:rights><dc:identifier>\n        http:\/\/repository.alt.ac.uk\/274\/1\/ALT_J_Vol6_No2_1998_Computer_aided_assessment_in_s.pdf<\/dc:identifier><dc:identifier>\n          Hunt, Neville  (1998) Computer\u2010aided assessment in statistics: The CAMPUS project.  Association for Learning Technology Journal, 6 (2).  pp. 58-67.  ISSN 0968-7769     <\/dc:identifier><dc:relation>\n        10.1080\/0968776980060206<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/repository.alt.ac.uk\/274\/","10.1080\/0968776980060206"],"year":1998,"topics":["LB Theory and practice of education","LC1022 - 1022.25 Computer-assisted Education"],"subject":["Article","PeerReviewed"],"fullText":"Computer-aided assessment in statistics:\nthe CAMPUS project\nNeville Hunt\nStatistics Group, Coventry University. Email: n.hunt@coventry.ac.uk.\nThis paper describes the specification, features and implementation of computer-\naided assessment software designed primarily for conducting assessments in Statistics\nbut equally applicable to other quantitative disciplines. The CAMPUS (Computer\nAided Marking Program Using Spreadsheets) package has been developed in\nMicrosoft Excel so as to provide a familiar computing environment for both assessors\nand students. The principal feature of CAMPUS is the facility for setting questions\ncontaining random elements (including random graphs), so that each student sits\nessentially the same questions but with different answers. This helps to eliminate\nplagiarism and allows a single test to be used many times, either for reassessment or\nadditional practice. CAMPUS has been implemented in a higher-education context\nbut could also be used at school level.\nIntroduction\nThe relentless drive for 'efficiency' in higher education, and the consequent increase in\nworkloads, has given university teachers a compelling incentive to investigate alternative\nforms of assessment. Some forms of assessment with a clear educational value can no\nlonger be entertained because of the burden placed on the teacher. An added concern is\nplagiarism, which anecdotal evidence would suggest is on the increase yet which is difficult\nto detect in large modules with more than one assessor. While computer-aided assessment\n(CAA) has an enthusiastic following, it is not clear to many teachers that it either reduces\nworkloads or reduces the risk of cheating. In an ideal world, most teachers would prefer to\ngive individual attention and personal feedback to each student when marking their work.\nIn this sense CAA must be seen as second best and will therefore be used only if it is seen to\noffer significant benefits in terms of reduced workloads or increased validity.\nThis paper describes the development of a spreadsheet-based CAA package for use in the\nteaching and learning of Statistics and other quantitative disciplines. The CAMPUS\nprogram (Computer-Aided Marking Program Using Spreadsheets) seeks to address the\nconcerns of teachers regarding workload, validity and feedback when assessing students.\n58\nALT-J Volume 6 Number 2\nRequirements of a CAA package\nA CAA package must be easy to use, both by the teacher when setting the assessment and\nby the student sitting it. If the CAA package requires a large investment of time in setting\nup the test, it will be used only by the enthusiast. Equally, the process of sitting the test\nmust be straightforward, otherwise students will quickly seize upon software difficulties as\nthe reason for their under-performance. The package should be able to accommodate a\nvariety of question types, including multiple choice, text response and numerical answer.\nThere should be a mechanism for giving informative feedback to students, not simply the\nnumber of 'right' and 'wrong' answers. An efficient and secure system for recording marks\nis required. Security devices are essential to guarantee the integrity of the test, ensuring\nthat students can neither access it before it is sat nor alter their answers or marks after\nsubmitting it for assessment.\nThe nature of Statistics as a discipline imposes additional requirements on a CAA\npackage. Many areas of Statistics involve a graphical approach, so the ability to\nincorporate graphs and charts into questions is essential. Statistical theory is quite\nmathematical, so there is a need to be able to handle symbolic notation. Most statistical\nproblems involve a mixture of calculation and interpretation. While the calculation\nelement lends itself to questions with a fixed numerical answer, assessing interpretation is\nmore difficult. Using text response is almost impossible in most cases since there are many\ndifferent forms of words that have the same essential meaning. Multiple-choice items are\nnot an entirely satisfactory solution since they may give the student ideas they may not\notherwise have had.\nMost teachers will already possess a battery of assessment items that they have\naccumulated during their career. Some of these may be paper-based, but many will be\nstored in a variety of electronic formats. For example, I have maintained a bank of some\n400 tutorial questions stored in text format on a Unix computer. It is clearly desirable that\nthese accumulated resources should be easily transferable into any CAA package the\nteacher chooses to use.\nRandom questions\nSoftware already exists which offers most if not all of the desirable features outlined above.\nFor example, Question Mark Designer (QMD) is in widespread use within UK higher-\neducation institutions. What motivated the CAMPUS project was the desire to able to set\nrandom questions. Software such as QMD offers a facility to select a certain number of\nquestions at random from a large library, but it does not allow individual questions to\ncontain random parameters. To clarify the distinction, consider a trivial item designed to\ntest students' ability to carry out simple addition. A large library of questions could be\nprepared, as in Table 1.\nTable I: Library of\nquestions\nQuestion I What is Z57 + 3.29? Ans = 5.86\nQuestion 2 What is the sum of 116 and 5.2? Ans = 17.8\nQuestion 27 What is the total of 53.1 and 31.9? Ans = 85.0\n59\nNeville Hunt Computer-aided assessment in statistics: the CAMPUS project\nThe alternative is to prepare a single question, as in Table 2, where x and y are numbers\nthat are randomly generated each time the question is loaded.\nRandom question What is [x] + [y] ? Ans=[x] + \\y] | jabk 2: Random question\nThis has several advantages:\n1. All students will tackle different questions, eliminating any possibility of copying\nanswers.\n2. Provided the random parameters are constrained to lie within reasonable limits, all\nstudents will tackle questions of virtually equal difficulty, which fairness demands.\n3. There is almost infinite opportunity for drill and practice, which many students need.\n4. Statistics is an applied subject and the vast majority of Statistics teachers would\nendeavour to set assignments and problems in a real-world context. Statistics is taught\nto students in many disciplines: biology, geography, economics, psychology, to name\nbut a few. Finding different question scenarios for each of these diverse fields of study\nis very time-consuming. The task of establishing a large library of questions of similar\ndifficulty for each application area would be enormous.\n5. With such a trivial example, there is little difference in the effort required by a lecturer\nin setting up the test. However, in more complex problems, even the task of computing\nthe answers would be very tedious (let alone the risk of occasionally getting an answer\nwrong!).\nMicrosoft Excel\nThe desire to incorporate random elements, including random graphs, leads naturally to a\nspreadsheet-based system. Microsoft Excel is the spreadsheet package supported by\nCoventry University and is widely used elsewhere. An increasing number of students have\nhome computers on which Excel is installed. As a basis for a CAA package, Excel has\nmany advantages:\n\u2022 it includes a large range of statistical functions;\n\u2022 it incorporates a random number facility;\n\u2022 the Chart Wizard offers a wide range of statistical charts and graphs;\n\u2022 charts, graphs and calculated statistics can be linked dynamically to the source data;\n\u2022 there is a limited use of symbolic notation and an ability to import Microsoft Equation\nEditor objects;\n\u2022 the Import Wizard allows a lecturer to import questions stored in a variety of\nelectronic formats;\n\u2022 the software environment is familiar to the students and will not therefore distract from\nthe test;\n\u2022 the software is familiar to staff who will therefore require little training to use the CAA\npackage;\n60\nALT-] Volume 6 Number 2\n\u2022 the user-interface can be controlled (and secured) using Visual Basic macros.\nSimonite et al (1998) have described an Excel-based system for setting personalized\ncoursework assignments for students using a randomization method. However, the\nmarking of the assignments is still carried out by hand. The CAMPUS program seeks to\nautomate the whole process of setting and marking such assignments. The use of Excel as\nan authoring tool is not.in itself novel. The CLUES project at the University of Aberdeen\n(Tidball, 1995) has led to the development of Excel-based courseware in many different\ndisciplines. Similarly, the DISCUS project (Hunt, 1996) at Coventry University has\nproduced interactive materials for teaching Statistics.\nThe CAMPUS program\nCAMPUS consists of two Microsoft Excel 5 workbooks, QUEST and TEST. The teacher\nuses QUEST to construct a test paper by either selecting questions from the existing\ndatabase, or by entering additional questions they have devised. Questions in the database\nare classified by topic (for example, NORMAL) and application area (for example,\nBUSINESS). TEST is a skeleton (template) test sheet which has already been formatted\nand equipped with various security features (described later). Once a teacher has\nVERY ELEMENTARY STATISTICS TEST\nUse TAB to move between answer boxes. Marks for each question are indicated in red.\nN a m e : |Albert Einstein Jr\n1) What is the median of the following speeds (mph)?\n42 40 31 57 52\nm Your answer here 2\n2) Ifthesumof 12 weights is 162 (kg), what is the mean weight?\n| ^ ^ | Your answer here 3\n3) If the mean and median of a set of data are the same, which of the following statements\nmust be true?\nA All the data values are the same\nB The distribution is Normal\nC The mode is also the same as the mean\nD The distribution is symmetrical\nE The standard deviation equals the interquartile range\nF None of these\n^ ^ ^ H Your answer here 2\nFigure I: Extract from a typical test\n61\nNeville Hunt Computer-aided assessment in statistics: the CAMPUS project\ncompleted the selection of questions, on the click of a button both questions and answers\nare automatically copied from QUEST and pasted into the TEST template. The answers\nare immediately hidden from view, and the TEST file is then saved under a different\nfilename specified by the teacher.\nA student sitting the test simply loads this file into Excel and follows the on-screen\ninstructions (see Figure 1). Visual Basic macros within the test file ensure that any random\nelements within the test - in both questions and answers - are recalculated on loading, so\nthat each student's test is different. Having completed the test, the student clicks a button\nto 'Submit for Marking'. A macro then checks the student's responses against the (hidden)\ngiven answers and compiles a detailed feedback sheet for the student (see Figure 2). Two\ncopies of the student's responses and feedback sheet are automatically sent to the local\nprinter. The teacher may also have opted for them to be saved electronically to a secret\nnetwork directory.\nQuestion\n1\n2\n3\n4\nMark\n0\n0\n0\n0\nTotal mark: 0\nMax mark: 10\nBegan 16\/03\/98 1E\nStudent: Albert\nSigned (lecturer):\nResponse\n31\n1944\nc\n90\nFeedback\nWrong: you forgot to sort the data\nWrong: you multiplied the sum by the sample size\nWrong: the distribution may be bimodal\nWrong: must be between -1 and 1\n':25:13; Ended 16\/03\/98 16:27:18\nEinstein Jr\nFigure 2: Typical student feedback sheet\nQuestion construction\nFive different types of question are supported by CAMPUS.\n(i) Multiple-choice\nThese are the simplest to construct. Figure 3 shows the layout of a typical question.\nThe question is constructed on the first 17 columns of a standard spreadsheet. On the first\nrow of the question, Columns 1-4 are for reference information. Each of the four lines in\nthe body of the question is actually entered into a single cell in Column 5 - in Excel, cells\nautomatically expand to accommodate up to 256 characters. The question text could be\ncopied in from a word-processed file, provided that a carriage return is inserted at the end\nof each line - if not, the whole question will be pasted into a single cell.\nThe lines immediately following the question contain the possible answers - a maximum of\nnine choices can be given. In Column 5 are the labels (A, B, C, etc.) while Column 6\ncontains the answers that students are expected to give - both correct and incorrect. In\nColumn 12 a feedback narrative is entered corresponding to each answer. This narrative\n62\nALT-J Volume 6 Number 2\n1 2 3 4 5 6 7 8 9 10 II 12 13 14 15 16 17\nPoisson General 5 A shipping company finds that the probability distribution of the number of its ships\nrunning aground in a particular period of time follows a Poisson distributioaThe mean\nnumber of its ships running aground is I every 2 years. What is the probability that 2 of\nits ships will run aground next year?\n0.184 Wrong: you used I per year on average\nB 0.076 Correct\n0.271 Wrong: you used 2 per year on average\n0.09 Wrong: this is the probability of two or\nmore\nFigure 3: A typical multiple-choice question\nappears on the student feedback and marks sheet on completion of the test. If the\nstudent's response is incorrect but not anticipated in the list of wrong answers, a default\nfeedback narrative is invoked, namely 'You made an unforeseen error!'.\n(ii) Numerical answer\nThe structure of numerical-answer questions is almost identical to that of multiple-choice\nquestions. The only modification to the layout in Figure 3 is that the letters A, B, C and D,\nlabelling the four choices, are replaced by numbers indicating the maximum acceptable\narithmetic error (either way) in the student's answer. For probabilities this might be 0.0005.\nIf omitted, these tolerances are assumed to be zero. Obviously, the four answers are not\nnow displayed to students sitting the test. However, if a student enters one of the foreseen\nwrong answers he or she still gets the corresponding feedback narrative. Once again, up to\nnine possible answers can be entered. One minor restriction is that the correct answer must\nbe listed first.\n(iii) Multi-part\nIt is quite common for Statistics questions to comprise several parts, all based on the same\nreal (or at least realistic) context. Suppose that our example question has an additional\npart: 'What is the probability of at least one of its ships running aground this year?'. The\nrevised layout is shown in Figure 4.\nEach part is effectively a separate question. The only link is via the reference numbers 5.1,\n5.2, and so on. Part (a) must be incorporated into the body of the introduction. When\nconstructing a test, the setter may omit some of the parts, provided that the labelling is\nedited accordingly.\n(iv) Random element\nThe ability to set random questions is probably the key feature of CAMPUS. These are the\nmost difficult to set and require a basic grasp of Excel functions and formula construction.\nFigure 5 shows a modification of our initial example to incorporate a random element.\nIn the original question students had to calculate the probability of two ships running\naground. Now, each student calculates the probability of x ships running aground, where x\nis randomly chosen. The critical line is the fourth line of the question. In Column 5 the\nsetter starts typing the question as normal. At the point where the setter would have typed\n63\nNeville Hunt Computer-aided assessment in statistics: the CAMPUS project\n1 2 3 4\nPoison General 5.1\nPoison General 52\n5 6 7 8 9 10 II 12 13 14 15 16 17\nA shipping company finds that the probability distribution of the number of its ships\nrunning aground in a particular period of time follows a Poisson distribution.The mean\nnumber of its ships running aground is 1 every 2 years. What is the probability that\n(a) 2 of its ships will run aground next year?\n0.0005 0.184\n0.0005 0.076\n0.0005 0.271\n0.0005 0.09\n(b) at least 1 of its ships runs aground this year?\n0.0005 0.076\n0.0005 0.271\n0.0005 0.303\nFigure 4: Layout of a muki-part question\n1 2 3 4\nPoison General 5\n5 6 7 8 9 10 II\nWrong: you used 1 per year on average\nCorrect\nWrong: you used 2 per year on average\nWrong: this is the probability of two or\nmore\nCorrect\nWrong: this is probability of 0\nWrong: this is probability of exactly 1\n12 13 14 15 16 17\nA shipping company finds that the probability distribution of the number of its ships\nrunning aground in a particular period of time follows a Poisson distributioaThe mean\nnumber of its ships running aground is 1 every 2 years. What is the probability that\n2 of its ships will run aground next year?\n0.0005 0.184\n0.0005 0.076\n0.0005 0.271\n0.0005 0.09\nWrong: you used 1 per year on average\nCorrect\nWrong: you used 2 per year on average\nWrong: this is the probability of two or\nmore\nfigure 5: Random element in a question\n'2 ships ...' he or she presses Return. In the next cell, Column 10 here, an Excel formula is\nentered. It seems reasonable for x to be 0, 1, 2, 3 or 4, so the appropriate formula is\n=INT(5*RAND()). Pressing the F9 (recalculate) key a few times acts as a useful check\nthat the formula is operating correctly.\nIt remains to sort out the answers. The first answer should be Pr(x) using mean 1, the\nfunction for which is POISSON(x,l,FALSE). The location of x must be specified relatively\nusing RC (Row and Column) notation. In the spreadsheet shown, this would be R[-1]C[4],\nmeaning back 1 row and forward 4 columns.\nSo the final formula would be:\n=POISSON(R[-1]C[4], 1 ,FALSE).\nSimilarly, the second answer would be:\n=POISSON(R[-2]C[4],0.5.FALSE),\nthe third:\n=POISSON(R[-3]C[4],2,FALSE)\n64\nALT-J Volume 6 Number 2\nand the fourth:\n=1-POISSON(R[-4]C[4]-1,0.5,TRUE).\nCurrently, CAMPUS does not allow random feedback narratives, so the fourth feedback\nnarrative would have to say, albeit rather vaguely, 'Wrong: you calculated at least not\nexactly'.\n(v) Graphic element\nProvided any graph, chart or picture is embedded into the cells containing the body of a\nquestion, it will be transferred across to the test paper in the normal way. If the chart\ncontains random elements, the source data must also be stored in the body of the question.\nSince embedded charts actually sit on top of the cells, the source data can be hidden in the\ncells behind the chart if necessary.\nUses of CAMPUS\nAt Coventry University, the CAMPUS program has been used to conduct three different\nkinds of assessment.\n(i) Supervised summative assessments\nHere, students all sit the test at the same time in a networked computer laboratory under\nthe supervision of a member of the teaching staff. The teacher responsible for the\nassessment will have previously installed the test file onto the network, which students now\nload into Excel. On completion of the test, the student feedback sheets are retrieved\nimmediately from the local printer, one copy being retained by the teacher and the other\npresented to the student. Where there is any possibility of fraud, perhaps because the local\nprinter is located in another room or some other insecure location, the teacher may cross-\ncheck the printouts against the saved electronic copy of each student's work.\n(ii) Unsupervised summative assessments\nThe system has been used for marking unsupervised homework exercises, despite the\nobvious concerns regarding cheating. A student may have attempted the test several times,\nthereby benefiting from the feedback, or sought assistance from others who have already\nobtained the correct answers. Surprisingly, experience suggests that most students are\ncontent to settle for a mark of 50 to 60 per cent at the first attempt, perhaps regarding\nrepeat attempts as a mild form of dishonesty. From an educational perspective, one would\nprefer them to take time to locate and correct their errors. Provided the homework does not\ncarry any great weight in the overall assessment, the fact that a student has gained an\ninflated mark of 90 per cent is considered a small price to pay for the reduction in the\nmarking burden. Colleagues who find this unsatisfactory simply ask for the student's hand-\nwritten solutions to be submitted with the CAMPUS printout, as an additional check that\nthe work has been done. This also enables the teacher to identify the cause of any\n'unforeseen error' feedback given by CAMPUS. Even so, the time taken to check\nhomework in this way is a small fraction of the time taken previously to mark it and give\nrelevant feedback by hand.\n(iii) Formative self-assessments\nThe teacher can use CAMPUS to provide students with random revision tests that can be\nsat time and time again, until the student achieves an adequate level of proficiency. Since\n65\nNeville Hunt Computer-aided assessment in statistics: the CAMPUS project\nevery time the test is loaded it contains different values for random elements, in this mode\nof operation students are allowed to save their test with its current values so that they can\nre-sit exactly the same test. Also in this mode of test, the electronic storage of a student's\nresponses is disabled, to avoid unnecessary file storage - the student simply retrieves the\nfeedback sheet from the local printer.\nSecurity\nIt is the responsibility of the setter to ensure that the location of the test file is not made\npublic prior to the appointed time for the test to be sat. When a student loads the test,\nseveral security devices come into operation:\n\u2022 all Excel menus and toolbars are disabled and removed from view;\n\u2022 the answers and feedback narratives are hidden from view;\n\u2022 the test worksheet is locked, protected by a password supplied by the setter, so that only\nthose cells reserved for the student's responses are accessible;\n\u2022 certain keys are disabled, most notably the '=' key, which might otherwise allow\nstudents to use Excel as a (very powerful) calculator;\n\u2022 in a Windows 3.1 environment, the Excel window is frozen so that students cannot\nswitch to other software applications (for example, electronic mail), although\nunfortunately it appears to be impossible to achieve this in a Windows 95 environment;\n\u2022 the cells for a student's responses are formatted with a black font on a red background,\nwhich is remarkably difficult to read (even from an adjacent desk!);\n\u2022 once students submit the test for marking, their mark\/feedback sheet is sent to the local\nprinter and stored in a secure directory on the network. The permissions are set on this\ndirectory to allow students to create new files but not to read, write, view or erase them.\nAs an additional level of security, an Excel facility is used which only allows the file to\nbe opened using the setter's password.\nOne weakness of CAMPUS is that although each student is required to enter a name\nbefore the test is marked, no steps are taken to confirm his\/her identity. In a supervised\ntest, it is left to the invigilator to check the identities of students sitting the test.\nConclusion\nAs more experience of running CAMPUS is gained, additional minor modifications are\nbeing made. However, the underlying simplicity of the package is its principal attraction,\nand no further major developments are planned. Work is ongoing to extend the existing\ndatabase of questions.\nAcknowledgement\nCAMPUS was produced by the author of this paper under secondment to the Coventry\nUniversity Teaching, Learning and Assessment Task Force.\n66\nALT-J Volume 6 Number 2\nReferences\nHunt, D.N. (1996), 'Teaching statistical concepts using spreadsheets', Teaching Statistics,\nASLU Supplement 1996, 1-3.\nSimonite, V., Ells, P. and Turner, W. (1998), 'Using IT to generate individualised course-\nwork questions and solutions for an introductory course in statistics and probability', CTI\nMaths & Stats, February 1998.\nTidball, J. (1995), An introduction to creating CAL courseware with Microsoft Excel 5',\nAberdeen: MERTaL Publications (University of Aberdeen).\n67\n"}
{"doi":"10.1016\/j.compind.2004.12.002","coreId":"137969","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/1049","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/1049","10.1016\/j.compind.2004.12.002"],"title":"Open standard, open source and peer-to-peer tools and methods for collaborative product development","authors":["Aziz, Hayder","Gao, James X.","Maropoulos, Paul G.","Cheung, Wai M."],"enrichments":{"references":[{"id":38116898,"title":"A design environment for product knowledge management and data exchange,","authors":[],"date":"2003","doi":"10.1007\/978-94-017-2256-8_22","raw":"Aziz, H; Gao, J; Maropoulos, P; Cheung, W, 2003, A design environment for product knowledge management and data exchange, Methods and Tools for Co-operative and Integrated Design, (ed) Serge Tichkiewitch and Daniel Brissaud (Kluwer Academic Publishers). Beckett, R, 2003, Determining the anatomy of business systems for a virtual enterprise.  Computers in Industry 51, 127-138.","cites":null},{"id":38116902,"title":"A distributed, open, intelligent product data management system.","authors":[],"date":"2001","doi":"10.1080\/09511920150216341","raw":"Kim, Y; Kang, S-H; Lee, S-H; Yoo, S-B, 2001, A distributed, open, intelligent product data management system.  International Journal of Computer Integrated Manufacturing 14, 224-235.","cites":null},{"id":38116906,"title":"A PDES\/STEP-based model and system for concurrent integrated design and assembly planning. Computer-Aided Design.","authors":[],"date":"2001","doi":"10.1016\/s0010-4485(01)00186-5","raw":"Zha, X-F; Du, H, 2001, A PDES\/STEP-based model and system for concurrent integrated design and assembly planning.  Computer-Aided Design.","cites":null},{"id":38116904,"title":"an automated manufacturing planning system,","authors":[],"date":"2003","doi":"10.1016\/s0924-0136(03)00053-0","raw":"Sharma, R; Gao J; Bowland, W, 2003, Implementation of STEP Application Protocol 224 in an automated manufacturing planning system, Journal of Engineering Manufacture (Part B).","cites":null},{"id":38116901,"title":"Application of product data management technologies for enterprise integration,","authors":[],"date":"2003","doi":"10.1080\/0951192031000115813","raw":"Gao, J; Aziz, H; Maropoulos, P; Cheung, W, 2003 Application of product data management technologies for enterprise integration, International Journal of Computer Integrated Manufacturing 16, 491-500.","cites":null},{"id":38116905,"title":"Arachne--adaptive network strategy in a business environment,","authors":[],"date":"2003","doi":"10.1016\/s0166-3615(02)00115-x","raw":"Vasara, P; Krebs, V; Peuhkuri, L; Eloranta, E, 2003, Arachne--adaptive network strategy in a business environment, Computers in Industry 50, 127-140.","cites":null},{"id":38116903,"title":"Collaborative conceptual design - state of the art and future trends,","authors":[],"date":"2002","doi":"10.1016\/s0010-4485(01)00157-9","raw":"Wang, L; Shen, WM; Xie, H; Neelamkavil, J; Pardasani, A, 2002, Collaborative conceptual design - state of the art and future trends, Computer-Aided Design,  981-996.","cites":null},{"id":38116899,"title":"Elements of a base VE infrastructure,","authors":[],"date":"2003","doi":"10.1016\/s0166-3615(03)00033-2","raw":"Camarinha-Matos, L; Afsarmanesh, H,  2003, Elements of a base VE infrastructure, Computers in Industry 51, 139-163.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2005-04","abstract":"This paper reports on a collaborative product development and knowledge management platform for small to medium enterprises. It has been recognised that current product lifecycle management (PLM) implementations are document oriented, have a non-customisable data model and inter-enterprise integration difficulties. To overcome these, an ontological knowledge management methodology utilising the semantic web initiative data formats was added to a PLM and an open source alternative. Shortcomings of centralised architectures are highlighted and a solution using a de-centralised architecture proposed. This is implementable at low cost; the scalability increases in line with user numbers. Ontologies, rules and workflows are reusable and extendable","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/137969.pdf","fullTextIdentifier":"http:\/\/hdl.handle.net\/1826\/1049","pdfHashValue":"c79558423367965d8ca2374943022b503785f0dc","publisher":"Elsevier","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/1049<\/identifier><datestamp>2010-04-29T13:57:10Z<\/datestamp><setSpec>hdl_1826_24<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>Open standard, open source and peer-to-peer tools and methods for collaborative product development<\/dc:title><dc:creator>Aziz, Hayder<\/dc:creator><dc:creator>Gao, James X.<\/dc:creator><dc:creator>Maropoulos, Paul G.<\/dc:creator><dc:creator>Cheung, Wai M.<\/dc:creator><dc:description>This paper reports on a collaborative product development and knowledge management platform for small to medium enterprises. It has been recognised that current product lifecycle management (PLM) implementations are document oriented, have a non-customisable data model and inter-enterprise integration difficulties. To overcome these, an ontological knowledge management methodology utilising the semantic web initiative data formats was added to a PLM and an open source alternative. Shortcomings of centralised architectures are highlighted and a solution using a de-centralised architecture proposed. This is implementable at low cost; the scalability increases in line with user numbers. Ontologies, rules and workflows are reusable and extendable.<\/dc:description><dc:publisher>Elsevier<\/dc:publisher><dc:date>2006-04-28T14:49:40Z<\/dc:date><dc:date>2006-04-28T14:49:40Z<\/dc:date><dc:date>2005-04<\/dc:date><dc:type>Article<\/dc:type><dc:format>171627 bytes<\/dc:format><dc:format>application\/pdf<\/dc:format><dc:identifier>Hayder Aziz, James Gao, Paul Maropoulos and Wai M. Cheung, Open standard, open source and peer-to-peer tools and methods for collaborative product development, Computers in Industry, Volume 56, Issue 3, , April 2005, Pages 260-271.<\/dc:identifier><dc:identifier>0166-3615<\/dc:identifier><dc:identifier>http:\/\/hdl.handle.net\/1826\/1049<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/doi:10.1016\/j.compind.2004.12.002<\/dc:identifier><dc:language>en<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["0166-3615","issn:0166-3615"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2005,"topics":[],"subject":["Article"],"fullText":"Open Standard, Open Source and Peer to Peer Tools \nand Methods for Collaborative Product Development \n \nHayder Aziz and James Gao, Enterprise Integration, Cranfield University \nPaul Maropoulos and Wai M. Cheung, School of Engineering, University of Durham \n \nKeywords: PLM, knowledge management, peer-to-peer, STEP, collaborative product \ndevelopment \nAbstract \nThis paper reports on a collaborative product development and knowledge \nmanagement platform for Small to Medium Enterprises. It has been recognised that \ncurrent Product Lifecycle Management (PLM) implementations are document \noriented, have a non-customisable data model and inter-enterprise integration \ndifficulties. To overcome these, an ontological knowledge management methodology \nutilising the semantic web initiative data formats was added to a PLM and an open-\nsource alternative. Shortcomings of centralised architectures are highlighted and a \nsolution using a de-centralised architecture proposed. This is implementable at low \ncost, the scalability increases in line with user numbers. Ontologies, rules and \nworkflows are reusable and extendable. \n1. Introduction \nThis paper builds on the initial work carried out by the team as per  Gao (2003), \nCheung (2003) and Aziz (2003). The topics of collaborative product development, \nvirtual enterprises (VE) and the technologies associated with implementing them have \nbeen the subject of widespread research. Some of these studies tackled problems \nwithin single enterprises, others looked at the problems associated with creating and \nmanaging of VE (Beckett 2003). Tools such as product lifecycle management (PLM) \nenable collaboration within and between enterprises. \n1.1 The Lack of Support Tools for SMEs \nThere are a number of facets that the authors consider to be basic flaws in current \nthinking on the subject. Large enterprises have invariably been the target of software \nvendors for development of such tools, resulting in centralised applications. These are \ninvariably beyond the means of small to medium enterprises (SMEs). Even after these \nefforts had been made, large enterprises face numerous difficulties with PLM. Firstly, \nenterprises evolve, and an evolving enterprise needs an evolving data management \nsystem. With large applications, such configuration changes have to be made at the \nserver level by dedicated staff. The second problem arises when enterprises wish to \ncollaborate with a large number of suppliers and original equipment manufacturer \n(OEM) customers. Current applications enable collaboration using business-to-\nbusiness (B2B) protocols. However, these do not take into account that disparate \nenterprises do not have unitary data models or workflows. This lack of standardisation \nresults in a lot of time and money spent mapping the B2B links. Within the setting of \na VE, where alliances can include dozens of enterprises and may often last for only a \nsingle project, these costs are prohibitive. This is a strong factor in reducing the \nabilities of large enterprises to participate in one-off VE partnerships, reducing agility \nand losing potential business. Other solutions include the use of application service \nproviders (ASP) and also enabling a large enterprise\u2019s data system to function as an \nASP to their collaborators. However the problem with this type of system is the \nmanagement of intellectual property of the individual enterprises and whether \nenterprises can give up control of their information to a partner, who may also be \ncollaborating with their competitors simultaneously. Such fears have hindered the \nformation of VEs. \n \nThe enterprises\u2019 prime asset, its knowledge, is not managed coherently thus \nperpetuating an \u2018invisible\u2019 limit on the company\u2019s knowledge, based on the impulse \nof knowledge workers\u2019 recollections of previous experience. In addition, the problems \nfor inter-enterprise collaboration are also inherent when enterprises with different \nlevel of detail and different nomenclature collaborate. Finally, the prime reason for \nthis investigation is that  SMEs have up to now been left out of developments in PLM, \nknowledge management and VE developments in spite of forming the majority of the \nworld\u2019s engineering community. This negatively affects the ability of SMEs to \nmanage their  knowledge, reuse existing expertise, collaborate with other SMEs in the \nvirtual enterprise settings and collaborate with the larger enterprises that form their \ncustomer base. This weakness affects not only the SMEs but also the large enterprises \nthat utilise SMEs within their supply chain or VE network. \n \nSmaller engineering enterprises lack the infrastructure and manpower for complex \nsolutions. Additionally, it was found that employees simply do not have the time or \nthe budgetary resources to learn the necessary application functionality and new \nconcepts associated with their operations. It has been observed that rigid procedures \nand centralisation do not produce the desired results. In fact adherence to the \nprocedures and workflows is generally considered to be a nuisance as knowledge \nworkers, who follow procedures, are detached both from the process of drawing up \nthese procedures and methodologies and from the running and \u201ccontrol\u201d of these \nprocesses and tools. This study has focused on the experiences of automotive and \ndiscrete machining companies in integrating their product realisation cycles with their \nsupply chains and their customers in real-time, and also to enable the companies to \nmake rapid appraisal and cost-estimation for their customers, from simple concept \ndesigns. The system has to be able to reuse the company's existing base of knowledge \nand to push the manufacturing knowledge higher up into the design chain to reduce \nthe need for costly and time consuming reworks and engineering changes. \n1.2 Specific Requirements of SMEs \nBased on the above set of problems facing industry, the authors have drawn up  three \ncore requirements to codify the needs of SMEs in managing their product and process \ninformation, i.e., \n(i) Enabling project managers and all knowledge workers to have access to the  \napplications needed to create and manage knowledge within their domain \naccording to the agreed nomenclature and ontological representation; \n(ii) Information created has to be in a form that can be queried, reused and \ntransformed into new representations through the use of rules and agents; and \n(iii) Enabling the real-time collaboration between SMEs, and larger partners, by \nfacilitating the fast and cost-less construction of VEs;  \n \nTo test the requirements and try to meet the objectives the authors took an \nevolutionary approach by assessing the current technology and methods, and then \nconstructing three new example applications. The as-is technology used was a web-\nbased commercial PLM system. The aim of the research is to solve the problems of \nthe as-is technology via three test scenarios: (1) Modification of the PLM system for \nflexible and customisable data model; (2) Implementation of a functionally equivalent \nsystem based on open source tools and (3) The implementation of a peer-to-peer \n(P2P) based system. \n1.3 Previous Work \nLihui et al (2003) wrote an extensive survey of collaborative design systems, and \nhighlighted eight areas as having scope for development including: System \narchitecture for web-based collaborative design, Collaborative Conceptual Design \nModelling and Data Sharing,  Conceptual Design Selection, Knowledge Management \nin Collaborative Environments. Beckett (2003) discussed the topic of communication \nand understanding in VEs between unfamiliar participants. He discussed the best tools \nand standards to apply in VE settings for collaboration and knowledge management \nand has an overview of various methodologies and applications. Camarinha-Matos \n(2003) on a similar note, reviewed current trends in VE developments, and conclude \nthat there is a need to develop a generalised framework for VEs, to enable \nharmonisation, international collaboration and rapid deployment.  \n \nKim (2001) developed a \u2018Distributed open-intelligent PDM\u2019 system, which adopts \nISO standard STEP, whilst offering standard PDM functions. A dynamic and flexible \nworkflow model is implemented. This could greatly enhance the flexibility of the \nsystem. Zha (2001) proposed a STEP based application to manage the entire product \nlifecycle. The information that is not already defined in STEP is modelled in \nEXPRESS. The system is focused primarily on assembly mating features and does not \nconsider the machining requirements of each component. Vasara (2003) proposes \nARACHNE, the adaptive network strategy to enable integration between 87 \nenterprises, the authors highlight the benefits of peer to peer networks to achieve \nsynergy between collaborators. Their developed methodology called RosettaStone \nenabled many-to-many integration between enterprises using a three-tier architecture. \n \n2. Knowledge Representation Methodology \nFigure 1 illustrates the data persistence problem in document oriented PLM. \nDocuments and CAD models contain the company's knowledge asset with meta-tags \nto identify the basic purpose of the file. In the figure 'Kn' denotes an item of \nknowledge. Both documents A and B within the system contain unique knowledge. \nHowever, kn-1 is stored in both documents. In this example, a user viewing or \nmodifying document A or B will need to be instinctively aware of such data \nduplication and update both documents kn-1 values. In most instances such 'simple' \nissues cause major problems for larger teams where the volume of documents \ncontained in the vault is too large for individuals to be instinctively aware of it. \nAdditionally the problem of finding knowledge, as opposed to documents, is intrinsic. \nFigure 1: Data persistence in document oriented systems \n \nThe above problem can be solved by Knowledge representation in this methodology \nis split into two identifiable components. The first one is the encoding and \nnomenclature component with the second component defining the terminology of the \nknowledge to be represented. This distinction between the encoding and terminology \n User\nPLM Query \/ browser mechanism\nMeta-data A Meta-data B\nDocument A\nKn1\nKn2\nKn3\nKn4\nDocument B\nKn1\nKn5\nKn6\nKn7\nenables the deployment of flexible knowledge bases using different industry schemas \nwhilst retaining the integration of the knowledge base. This has meant that standards \nsuch as STEP have to have their schemas translated into the encoding specifications \ncreated, as opposed to the original Express schemas. The authors define knowledge as \nthe semantically complete definition of a domain's information that is both machine \nreadable and interpretable. Thus a knowledge base contains an ontology which \ndefines the classes and their relationships, instances or objects that form the domain \n'data', meta-data that constrains the data within a particular domain (transforming it \ninto information), and Universal Resource Identifiers (URI) that allow the global \nidentification and contextual interpretation of the information. These schemas are \nshared within the collaborative environment of a project involving many parties. \n \nThe resource description framework www.w3c.org (RDF) has been used in this \napplication as the format for encoding the knowledge base, as opposed to eXtensible \nmark-up Language (XML). The reasons for this choice are the extra flexibility and \n'machine-understandable' format of RDF graph triple model as opposed to the simple \n'machine-readable' XML based mark-up vocabularies. In effect, any RDF-parser can \nderive the semantics and context from the URI and metadata attached to every \ninstance. \n \nThe STEP AP-224 feature models are defined in Prot\u00e9g\u00e9 and use the Java expert \nsystem shell (JESS) to define the rules and functions of the standard. In addition some \nof the rules have been created using the Prot\u00e9g\u00e9 Axiom Language (PAL) and the \nconstraints these impose enable error-checking for the user during the definition of \nfeatures.  However, these constraints can only be applied to individual entities within \nthe STEP model and cannot enforce any constraints between entities\/features. Due to \nthe size of the standard, only a subset of AP-224 has been translated from the original \nExpress schema. The definition of the Express (STEP) data types is also contained in \nthe Clips interface. This is very flexible as it allows for the inclusion of STEP data \ntypes to other components within the ontology on a need basis without having to have \nany expertise in Express or any other programming language. The above enables the \nmixing of feature and meta-data information in the knowledge base, meaning that \nusers can access the information stored in STEP models using queries and RDF \nparsers. This integration at low level between the geometric, feature and 'meta-data' \nwithin a single environment is intended to reduce repetition and errors, and also \nenables the reuse of all the data created during the conceptual design process. A STEP \nAP-224 based automatic process planner by Sharma (2003) generates plans from \nconcept designs. The aggregate process planning tool by Cheung (2003) generates \nassembly plans from incomplete models to enable the optimization of the design for \nassembly and manufacturing from the early stages.  \n3. Collaboration on Distributed Designs \nOne of the first problems of collaboration (both at system and at user level) is trying \nto understand what the others say and mean. The previous section showed the \nmethods used to create the data models. This development is interrelated to the \nproblem of collaboration and problems of collaborative design between enterprises of \ndifferent sizes and complexity, that is, mapping between low and high content data \nmodels which results in irretrievable loss of information from the high content data \nmodel. This problem cannot be overcome traditionally by creating a mapping from \none data model to another. Instead the authors have sought to create a project oriented \nontology that can be created, shared and used by all parties collaborating in an \nenterprise in real-time. This eliminates the problems faced when low-end suppliers \ncollaborating with advanced enterprises face integration issues. Using the building-\nblock ontologies and STEP standards to describe the terminology. There are various \ncollaboration 'enabler' methods available with different strengths and weaknesses. \nSome are centralised, controlled by a third party or de-centralised. \n3.1 B2B Integration and Application Service Providers \nBusiness to Business (B2B) integration is the traditional method for companies to \ncollaborate and create VE networks. This area includes Electronic Data Interchange, \nXML based messaging and portal solutions. Integrating 15 companies together on a \none-to-many basis where a single repository manages the project knowledge and \nworkflows would need 14 separate mappings. \n \nApplication Service Providers (ASPs) can be set up in two ways, either by a large \n\u2018controlling\u2019 enterprise, or through independent third party hosting. These services \nintend to provide the same utilities as enterprise level systems but in a non-enterprise \nspecific service. ASPs offer project and product data management vaults where the \nVE administrator can customise the third-party portal for their own use. It also offers \nopportunities to contact companies already listed on the ASP who might join the VE \nif they had required services to offer. The ASPs generally use software very similar to \nthe PLM solutions like Enovia and Windchill. However, they offer them as low cost \nsolutions to some customers with specific needs, which cannot be met by purchasing \ntheir own server software. These include: Reduced cost for the enterprise as  \nmaintenance and backup is delegated. Increased opportunities if customers and VE \ninitiating enterprises seek out partners through the portal. This is a \u201cDemocratic\u201d \nsystem where no one enterprise controls the VE server and data. It sets down de-facto \nstandards for data exchange, to which other enterprises in the same domain will \nadhere to in order to join the network of enterprises. \n \nThere are of course some fundamental disadvantages to the use of ASPs, and other \ncentralised systems, for product development, and these include: The bandwidth and \nserver bottleneck problem associated with centralised services. The security fears of \nintellectual property rights being compromised. The potential risks of downtime and \ndata losses in an \u201cuncontrollable\u201d environment and the liability issues associated with \nit. The difficulty of creating direct interfaces from the enterprise system to the ASPs \nportal. The exact functionality required for the VE may not be available from the \n\u201cgeneric\u201d ASP. \n \nThere are already some ASPs operating in the automotive and aeronautical sector \nenabling supply companies to interact and bid openly for contracts with OEMs and \nthen manage the project\/product information on the portal. However due to the \ndisadvantages highlighted above, the authors sought to find a third way. Whilst \ntraditional client-server systems can operate in a collaborative manner, for example \nover a LAN or Internet, they are not truly distributed as they are centralised. \n3.2 Peer to Peer Systems \nPeer to Peer (P2P) applications address the needs of de-centralised organisations to \ncollaborate and share knowledge regardless of geographical location. The principle of \nP2P has been around for a long time, and is today implemented in a number of \napplications such as instant messaging and file-sharing (www.GNUtela.com). There \nare already a number of P2P PLM in existence. Primarily aimed at the lower end of \nthe market. The two commercial applications are AutoManager workflow from Cyco \n(www.cyco.com) and Columbus from Oasys Software (http:\/\/www.oasys-\nsoftware.com\/). The latter is available for free, and aimed at AutoCAD users within \nthe construction sector. However they are crude solutions relying on the underlying \nfile system and adding some \"meta tags\" to files for version control. There is no \nworkflow or process management implemented and access control is via the standard \noperating system access control functions. As an example of what can be achieved, \nAlibre is a P2P CAD\/PLM and collaboration tool in one. It uses the STEP standard \nand combines low cost and fast configuration. \n \nThe advantages offered by P2P applications are (i) no single point of failure, the \nnetwork is alive as long as one peer is on-line, (ii) distributed sharing of bandwidth \nstorage and processing power, so the system becomes more powerful as more users \nattach, (iii) lower running cost due to the lack of servers or high bandwidth central \nnodes, as well as (iv) maintaining individual control of the shared knowledge. P2P \ngroups can be used to create profiles of the peer, and also more importantly of the \npeer's list of contacts within different domains. These profiles can be used within the \nnetwork to search for and assess people's competences, interests, and memberships of \ntrusted groups, and can aid in the construction of new relationships based on \ncommonalities and third party assessments.  There have been a number of issues that \nreduce the performance of the system using pure P2P architecture. The lack of \nindexing and routing services in P2P degrades the peer discovery and query functions. \nIn order to leverage the advantages of client\/server systems with the independence \nand interoperability of P2P systems a hybrid system where \u201csuper peers\u201d act as peers \nto the extended P2P network and as a server to the enterprise's internal peer network \nis used. In addition rendezvous peers can be assigned to manage some of the peer \ninformation assigned to particular peer nets or projects. This hybrid has been shown to \nhave the best potential for high-performance de-centralised services. \n3.3 Inter-enterprise Communication Architecture \nSince no two enterprises are the same, the idea of using XML based messaging for \ninter-enterprise collaboration is not easy as the two company schemas have to be \nmapped to each other. In order to achieve the speedy interoperability a standard has to \nbe set for basic messaging. There are a plethora of standards in development by \nvarious groups including RosettaNet, an endless list of XML schemas and data type \ndefinitions. These standards implement different levels of detail in the ontology. \nSome like STEP PDM attempt to implement the complete information structure of the \nengineering enterprise. Others like JuxtaPose (JXTA) implement only the \n\u201cmessaging\u201d components. The choice of standards to use depends on the level of \n\u201cstandardisation\u201d that all enterprises can adhere to. In the view of the authors only a \nvery low level subset of all enterprises can be \u201cstandardised\u201d. This small subset \nshould exist only as a medium to enable communication, identification and access \ncontrol management. All other aspects of the collaborative data environment are \nenterprise specific (although constructed from a subset of ontological components).  \nFigure 2: The 2-tier communication \n \nThis project uses the two-tier solution shown in Figure-2 which enables enterprises to \nestablish connections in real-time between them. Speeding up of the integration \nprocess is further enhanced through the use of open standard semantic web enabled \nontology formats for storing the information, plus the use of open-standards in \naddition to company ontologies to define those ontology components. \nUniquePeerId, PeerAdvertisement, Security \nOntology & Workflow layer\nInternet\n4. Case study \n4.1 Commercial PLM System \nWindchill is an out-of-the-box PLM system. It uses open source technology for some \nof its key components. A traditional document management tool, that stores all \nmanner of data and make revision controls. It does not however have an intelligent \nmethod of containing and persisting information in an object oriented format. To \nalleviate this, the functionality of the system has been extended to include the \nmanagement of knowledge in an ontology. The integration with Prot\u00e9g\u00e9 was made \nusing Windchill\u2019s bespoke but highly configurable workflow engine.  \n \n4.2 Open Standard and Open Source Tools \nThe applications used in this project are the Prot\u00e9g\u00e9 ontology editor and Sun's JXTA \npeer to peer protocol. Both of these tools offer the best usability, portability and \ncost\/performance capability within their niches, and when allied to a scalable open \nsource object\/relational database such as SAP-DB, can offer enterprise level \nperformance for zero capital expenditure, and low customisation cost. Moreover they \nfree the customer from the clutches of software vendors and the vagaries of \nobsolescence. Other open-source tools used in this work include OPEN-CASCADE, \nwhich is a native STEP solid modeller and the open-flow tool that forms the \nfoundation of the open-source PLM solution. \n \nIn the application (see Figure 3) the bottom layer consists of the database. This can be \nchosen from the range of relational databases available, and for this test case MySQL \nwas utilised due to its stability, ease of use and close integration with the PHP \nscripting language that the open source PLM was written in. On top of this layer the \ntwo open source gateways, one is Apache web server for serving static and PHP based \nweb pages and the middle tier is the Tomcat servlet engine which serves the Java \nserver pages (JSP) based applications. These three layers (database, web server and \napplication server) form the server side of the system. \nWeb Browser CADProtege\nInternet\nApache Tomcat\nPHP HTML JSP JBOSS\nMySQL \/ SAP-DB \/PostgreSQL\nClient side\nServer side\n \nFigure 3, high-level view of open source server and user interface architecture \n \nOn the client side, the user has three main applications i.e. (i) the web browser \nthrough which interactions with the PLM system are carried out, (ii) the Prot\u00e9g\u00e9 Java \napplet that allows the user to query and manage the knowledge base and (iii) a CAD \nsystem to enable the user to create and manipulate the STEP based models held in the \nPLM system. This user interface ensures ease of use for the user because the web-\nbrowser and its own cad system are already familiar to the user with the only 'new' \ntool for interaction being prot\u00e9g\u00e9. This extension also includes the management of \nSTEP entities within the PLM system in an intelligent and object oriented manner. \nKnowledge is stored as objects within the modified PLM system. This was integrated \nwith the lifecycle management and workflow functions offered by the PLM system. \n \n4.3 Peer to Peer Implementation \nThe implementation was kept as simple as possible. The simplicity of the architecture \nis itself a bonus and enabled the researchers to concentrate on the value adding \naspects of the project. As mentioned previously, the flexible Prot\u00e9g\u00e9 ontology \ndevelopment  and user interface environment is used. The back end consists of the \nopen source SAP-DB database with the Java database connectivity (JDBC) connector \nto Prot\u00e9g\u00e9. The knowledge base ontology is defined in a Clips file and the instances \nare stored in the database. Connectivity is achieved using an open source \nimplementation of JXTA open standard P2P network protocol (www.jxta.org). The \nchoice was made because JXTA implements a unique but anonymous identification \nmechanism for peers and for rendezvous peers. As well as \u201cadvertisement\u201d \nimplemented for all peers that give information on the one peer to other peers. \nRendezvous peers can act as managers for peer groups and store the peer \nadvertisements for the group for distribution to other P2P networks. Implementation \nof JXTA is in Java 2 standard edition, an extension to enable RDF queries and \nontologies to be shared over P2P is used to share the Prot\u00e9g\u00e9 knowledge base. The \nsecond window shows the user interface from where queries, project management of \ncollaborative groups and such widely used items as group chat and instant messaging \nare readily implemented by the JXTA protocol. The systems\u2019 settings enable \nenterprises and users without static addresses to collaborate using dynamic \naddressing, and this flexibility as well as the users\u2019 ability to work offline (that cannot \nbe done with web based systems) empowers users in all possible circumstances. \n \n4.4 Example data \nAs stated earlier, an automotive enterprise was used to demonstrate the application \nand collaboration methodology. When initiating a collaborative product development \nproject, a list of tasks, users, roles, responsibilities are assigned. Initially this is very \nsketchy, however the template ontology (implementing the STEP-PDM entities) as \nwell as the generic-product development ontology contains both the fuzzy early stage \nand accommodates the updates and refinements as they are entered. The enterprise\u2019s \nprocesses were split into lifecycle states and defined in workflow processes. Due to \nthe complexity of the overall processes, only the conceptual design phase was \nmodelled into the ontology and workflows. The sequence of processes for this phase \nare: \n\u2022 Customer request for quotation is submitted including requirements and associated \nverification methods; \n\u2022 Generation of specifications through analysis of earlier customer requests and \ntesting against the new verification methods; \n\u2022 Creating concept design options from the specifications by pattern matching \nagainst earlier concepts developed with similar specifications; and \n\u2022 Selection of concept and utilising the verification methods. \n \nUser interaction through the interface as shown in Figure 4 was straightforward. \nWorkflow sequences acted as widgets guiding the user through different  \nFigure 4: Prot\u00e9g\u00e9 user interface for knowledge acquisition \nconfigurations. The example in Figure 5 assigns budget and feasibility analysis to \nactors, manages release of the individual tasks, which are sent for review for approval \n\/ rejection.  \n \nThe retention plate and four item assembly for the door latch (see Figure 6) was \nmodelled for the entire lifecycle. In addition the full project data including over 300 \nparts were modelled into the Bill of Material. New components are entered \ninteractively and work seamlessly throughout the lifecycle. The application proved \nvery simple and intuitive to use. The collaboration tools use proven technologies by \nSUN and worked seamlessly for many-to-many connections.  \n Figure 5, workflow process, visualized from xpdl,  \n \nFigure 6,  Latch assembly view. (Courtesy ArvinMeritor)  \n4.5 Results \n The field for the results above were tested empirically using the data and a small \ninter-enterprise setup described previously. The server was located in Southern \nEngland, and users concurrently created the new project, generated new concepts and \noptimised the design gradually from two remote locations in addition to users at the \nmain site. \nRetention Plate \nClaw\nPawl Rivet\nClaw Rivet\nApplication ontology VE setup Deployment time Lifecycle management \nTotal cost of \nownership \nWindchill \nRDFs \nontology in \ndocument \ncontainer, \naccess via \nwindchill exp  \nB2B \nintegration via \nInfo*engine \n(one-to-many \nintegration), \nmanual \n1 month for small \nproject.  \nGraphical \nworkflow \nServer & \nclient licence, \nimplementatio\nn and \nmaintenance \nOpen PDM \nRDFs \nontology \naccessed via \nProt\u00e9g\u00e9 applet \nB2B \nintegration via \nXMLRPC \n(one-to-many  \nintegration), \nmanual \n1 week PHP workflow \nImplementatio\nn and \nmaintenance \nPure P2P \nRDFs \nontology in \njava \napplication \nPeer to peer, \nautomatic \ndiscovery \n1 day \nVersion control \nand rule based \nsystem \nTraining on \nP2P and \nknowledge \napp \nSuperPeer net \nRDFs \nontology in \njava \napplication \nSuperPeer \nautomatic \ndiscovery \n1 day \nVersion control \nand rule based \nsystem \nTraining on \nP2P and \nknowledge \napp \nTable 1 Comparison of key features of tested system \n \nTable 1 compares the key features requisite for a collaborative project environment, \nthese were:  \nOntology: how easy was it to enter, query, and reuse both the ontology and domain \nknowledge within the collaborative group? Since this is common to all the tools, the \nonly difference was the way in which the ontology was stored within the different \nsystems. \nVE setup: how rapidly could the VE be set up and start to operate on all the remote \nsites? \nDeployment time: The time to customise and deploy the entire project including the \nproject management framework (access rules, task lists, workflows), project ontology \n(sub-ontology selection from the generic ontology), and communications setup. \nLifecycle Management: The ability to control the state of a document, manage \nversioning and history of the data. \nTotal Cost of Ownership: The costs of licences, implementation, system integration, \ntraining and maintenance.  \n \nAll ontologies deployed shared a common back end. The applications were tested on \nidentical hardware with identical configurations and internet connections. The \napparatus were Dell Xeon workstations with 1GB RAM, 15K rpm disks and 1mb \ninternet connection, the operating system was Windows 2000 on all machines. \n \nDue to the small scale of the test it is impossible to gauge anything but the most \nrudimentary performance benchmarking of the systems as high loads of queries \/ \nupdates and multi-peer concurrent access could not be simulated with the available \nresources of users. However the test suffices for a small scale pilot. The test simulated \na small scale VE setup through from initiating the VE to running the system within \nthe collaborative network. This setup has a typical VE with a large number of small \nservers distributed within a common network, a small number of transactions are \nprocessed at each node.   \nChart 1. Simple query (single term search over the \nentire KB)\n0\n50\n100\n150\n200\n250\n2 nodes 4 nodes 6 nodes 8 nodes 10 nodes\nnumber of nodes \/ users\ntim\ne \n(m\ns) windchill\nOpenPDM\nPure P2P\nSuperPeer net\nChart 2. Time to update instance\n0\n20\n40\n60\n80\n100\n120\n2 nodes 4 nodes 6 nodes 8 nodes 10 nodes\nnumber of nodes \/ users\ntim\ne \n(m\ns) windchill\nOpenPDM\nPure P2P\nSuperPeer net\n \nChart 3. Complex Query (generating an inferred hierarchy of the \nKB before processing a result tree)\n0\n50\n100\n150\n200\n250\n300\n350\n400\n2 nodes 4 nodes 6 nodes 8 nodes 10\nnodes\nnumber of nodes \/ users\ntim\ne \n(m\ns) windchill\nOpenPDM\nPure P2P\nSuperPeer net\nCharts 1-3 show some performance characteristics of the systems in use, as stated \nearlier the number of users were not sufficient to fully test the scalability of the \napplications, however the distributed nature of the applications means that the number \nof concurrent transactions are much lower in P2P type applications than centralised \nprogrammes. The Peer based applications showed a base performance lag when \ncompared to the client-server applications due to routing of peer based systems \nwithout an indexing service. Otherwise the performance of the systems in practical \nuse showed no noticeable differences.  \n5. Discussion \nWindchill is inherently centralised, overly complex to set up and requires a long \nperiod of time for customisation. The system's main strengths are in the workflow \ntools. However, even here there is the problem of lock-in. The workflow and any \ncustomisation carried out cannot be reused on another system. Windchill has a \nsophisticated application layer for inter-enterprise communications, and inherent in its \nweakness is the client\/server paradigm whereby every enterprise needs to have \ncustom integration between it and its extended enterprises' systems to function. This \nhas been elaborated on in the previous sections. On another note, the RosettaNet \nstandard, implemented in Windchill, can decrease the amount of customisation \nneeded, but not eliminate it as RosettaNet only provides a subset of the messaging and \ndata models of the inter-enterprise link. In addition, unlike the ontological 2-tier \nsystem, Windchill's data models and workflows are neither portable nor standardised.  \n \nOther issues encountered were the difficulty in modifying the data models. Windchill \nhas a rather rigid data modelling interface based on the Unified Modelling Language \n(UML) to model the Java data model classes, and generate SQL scripts for the \ndatabase. It can be modified by a professional who has to model, program, compile, \nupdate the database and integrate the code into Windchill before it can be used. This \ndoes not provide for the flexibility and ease of use for modelling ontologies that the \nproject manager needs. The costs of implementation, licences and maintenance are \nvery large by themselves and only practical when the enterprises involved can share \nthe cost between each other over a long period of co-operation (as in an extended \nenterprise). However, the case with VEs, in which a partnership is valid for the \nrelatively short period of a single project, this would be unacceptable.  \n \nThe Windchill and open source systems are the evolution of product development \nmanagement systems from document centric PLM systems to knowledge centric, \nintelligent systems of the future. However, it had been discovered during the course of \nthe project that centralisation, by its very nature, is an inhibiting factor for one-off \ninter-enterprise collaboration as the only methods available for collaboration in such \nan environment are B2B schema mapping integration, centralised web-enabled system \nor use of an Application Service Provider. Portals in this instance would simply be \nclassified as B2B integrations as each data source has to be separately mapped into \nthe portal. \n \nThe requirements set out in section 1.2 are fulfilled by the new methodology thus: \nRequirement 1 is satisfied by the use of domain specific ontologies distributed to the \nclients (users) via the P2P network and open standards: Elimination of the \ninteroperability issues for product and project knowledge, enabling small enterprises \nto implement application standards that were beyond their means, such as STEP-\nPDM, and easier set up for inter-enterprise collaboration. Requirement 2, is fulfilled \nthrough the use of RDF ontologies that can be queried by agent based systems and \ntransformed by KIF based rules. The information contains the URI and meta-data \neliminating the ambiguous context of the knowledge. Efficient query and retrieval \nmechanisms, intelligent agents to function on context aware information and provides \nan object oriented representation of an enterprise's data model.. The third requirement \nis met by de-centralisation: Elimination of centralised bottlenecks in bandwidth and \nresources, empowerment of collaborators within networks to \u201ccontrol\u201d the knowledge \nthey create, solving the management of intellectual property rights within VEs, \nelimination of centralised administration that results in reduction in cost and \ncomplexity and enable domain professionals to tailor the system. This, however, has a \ncost in terms of ease of maintenance and centralised control, as well as some query \nspeed problems encountered due to the lack of a complete indexing service. \n \nIn addition the methodology described can be: \n(i) Open source: Elimination of software licence costs, a solution to the problem of \nvendor lock-in in the long term, elimination of unnecessary complexity and freedom \nto modify the application. (ii) Platform and application independence: Enable the \nenterprise to concentrate on its work and not be tied in to any vendor, the rapid and \ncomplete migration from the proposed system to future applications, empower the \nenterprise to leverage its existing investments. \n6 Conclusion \nThe methodology described is a suitable solution for collaborating enterprises \nespecially SMEs, to create manage and reuse their knowledge, collaborate within VEs \neasily and without expense. In view of the author the proposed methodology can \nachieve the ubiquity required due to the following factors. It enables enterprises to \nimplement STEP-APs. Easy to set up, modular, expandable and establishes rapid B2B \nconnections. There is a lot of work in progress, and final conclusions can only be \ndrawn once the knowledge and communication protocols are integrated more \ncompletely. \nAcknowledgements \nThe authors would like to thank the project sponsors without whom this research \nwould not be possible. Firstly the UK Engineering and Physical Science Research \nCouncil (EPSRC) for its financial support, in addition to the industrial collaborators \nArvinMeritor, LSC Group, Mabey and Johnson and PTC Corporation who provide \ntraining, software and valuable case-study material. \nReferences \nAziz, H; Gao, J; Maropoulos, P; Cheung, W, 2003, A design environment for product \nknowledge management and data exchange, Methods and Tools for Co-operative and \nIntegrated Design, (ed) Serge Tichkiewitch and Daniel Brissaud (Kluwer Academic \nPublishers). \nBeckett, R, 2003, Determining the anatomy of business systems for a virtual \nenterprise.  Computers in Industry 51, 127-138. \nCamarinha-Matos, L; Afsarmanesh, H,  2003, Elements of a base VE infrastructure, \nComputers in Industry 51, 139-163. \nCheung, W; Maropoulos, P; Gao, J; Aziz, H, 2003, Knowledge-enriched Product Data \nManagement System to Support Aggregate Process Planning, 1st International \nConference on  Manufacturing Research, Advances in Manufacturing Technology \nXVII, Ed. Y Qin and N Juster, 253-258. \nGao, J; Aziz, H; Maropoulos, P; Cheung, W, 2003 Application of product data \nmanagement technologies for enterprise integration, International Journal of \nComputer Integrated Manufacturing 16, 491-500. \nKim, Y; Kang, S-H; Lee, S-H; Yoo, S-B, 2001, A distributed, open, intelligent \nproduct data management system.  International Journal of Computer Integrated \nManufacturing 14, 224-235. \nWang, L; Shen, WM; Xie, H; Neelamkavil, J; Pardasani, A, 2002, Collaborative \nconceptual design - state of the art and future trends, Computer-Aided Design,  981-\n996. \nSharma, R; Gao J; Bowland, W, 2003, Implementation of STEP Application Protocol \n224 in an automated manufacturing planning system, Journal of Engineering \nManufacture (Part B). \nVasara, P; Krebs, V; Peuhkuri, L; Eloranta, E, 2003, Arachne--adaptive network \nstrategy in a business environment, Computers in Industry 50, 127-140. \nZha, X-F; Du, H, 2001, A PDES\/STEP-based model and system for concurrent \nintegrated design and assembly planning.  Computer-Aided Design. \n"}
{"doi":"10.1145\/1391289.1391290","coreId":"65285","oai":"oai:dro.dur.ac.uk.OAI2:6288","identifiers":["oai:dro.dur.ac.uk.OAI2:6288","10.1145\/1391289.1391290"],"title":"The approximability of MAX CSP with fixed-value constraints.","authors":["Deineko, V.","Jonsson, P.","Klasson, M.","Krokhin, A."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-09-01","abstract":"In the maximum constraint satisfaction problem (MAX CSP), one is given a finite collection of (possibly weighted) constraints on overlapping sets of variables, and the goal is to assign values from a given finite domain to the variables so as to maximize the number (or the total weight, for the weighted case) of satisfied constraints. This problem is NP-hard in general, and, therefore, it is natural to study how restricting the allowed types of constraints affects the approximability of the problem. In this article, we show that any MAX CSP problem with a finite set of allowed constraint types, which includes all fixed-value constraints (i.e., constraints of the form x &equals; a), is either solvable exactly in polynomial time or else is APX-complete, even if the number of occurrences of variables in instances is bounded. Moreover, we present a simple description of all polynomial-time solvable cases of our problem. This description relies on the well-known algebraic combinatorial property of supermodularity","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65285.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/6288\/1\/6288.pdf","pdfHashValue":"20fcc6eb3f839f0e8d51a8c570260fbbb39ae5bf","publisher":"Association for Computing Machinery","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:6288<\/identifier><datestamp>\n      2010-07-30T11:58:14Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        The approximability of MAX CSP with fixed-value constraints.<\/dc:title><dc:creator>\n        Deineko, V.<\/dc:creator><dc:creator>\n        Jonsson, P.<\/dc:creator><dc:creator>\n        Klasson, M.<\/dc:creator><dc:creator>\n        Krokhin, A.<\/dc:creator><dc:description>\n        In the maximum constraint satisfaction problem (MAX CSP), one is given a finite collection of (possibly weighted) constraints on overlapping sets of variables, and the goal is to assign values from a given finite domain to the variables so as to maximize the number (or the total weight, for the weighted case) of satisfied constraints. This problem is NP-hard in general, and, therefore, it is natural to study how restricting the allowed types of constraints affects the approximability of the problem. In this article, we show that any MAX CSP problem with a finite set of allowed constraint types, which includes all fixed-value constraints (i.e., constraints of the form x &equals; a), is either solvable exactly in polynomial time or else is APX-complete, even if the number of occurrences of variables in instances is bounded. Moreover, we present a simple description of all polynomial-time solvable cases of our problem. This description relies on the well-known algebraic combinatorial property of supermodularity.<\/dc:description><dc:publisher>\n        Association for Computing Machinery<\/dc:publisher><dc:source>\n        Journal of the ACM, 2008, Vol.55(4), pp.16 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2008-09-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:6288<\/dc:identifier><dc:identifier>\n        issn:0004-5411<\/dc:identifier><dc:identifier>\n        doi:10.1145\/1391289.1391290<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6288\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1145\/1391289.1391290<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/6288\/1\/6288.pdf<\/dc:identifier><dc:rights>\n        \u00a9 ACM 2008. This is the author's version of the work. It is posted here by permission of ACM for your personal use. Not for redistribution. The definitive version was published in Journal of the ACM,  \\ud\n{The approximability of MAX CSP with fixed-value constraints, 2008}, http:\/\/dx.doi.org\/10.1145\/1391289.1391290<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0004-5411","0004-5411"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2008,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n30 July 2010\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nDeineko, V. and Jonsson, P. and Klasson, M. and Krokhin, A. (2008) \u2019The approximability of MAX CSP with\nfixed-value constraints.\u2019, Journal of the ACM., 55 (4). p. 16.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1145\/1391289.1391290\nPublisher\u2019s copyright statement:\nACM 2008. This is the author\u2019s version of the work. It is posted here by permission of ACM for your personal use.\nNot for redistribution. The definitive version was published in Journal of the ACM, The approximability of MAX CSP\nwith fixed-value constraints, 2008, http:\/\/dx.doi.org\/10.1145\/1391289.1391290\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\nThe approximability of Max CSP with fixed-value constraints\nVladimir Deineko\nWarwick Business School\nUniversity of Warwick, UK\nVladimir.Deineko@wbs.ac.uk\nPeter Jonsson\nDep\u2019t of Computer and Information Science\nUniversity of Linko\u00a8ping, Sweden\npeter.jonsson@ida.liu.se\nMikael Klasson\nDep\u2019t of Computer and Information Science\nUniversity of Linko\u00a8ping, Sweden\nmikael.klasson@ida.liu.se\nAndrei Krokhin\nDepartment of Computer Science\nUniversity of Durham, UK\nandrei.krokhin@durham.ac.uk\nAbstract\nIn the maximum constraint satisfaction problem (Max CSP), one is given a finite collection\nof (possibly weighted) constraints on overlapping sets of variables, and the goal is to assign\nvalues from a given finite domain to the variables so as to maximize the number (or the total\nweight, for the weighted case) of satisfied constraints. This problem is NP-hard in general,\nand, therefore, it is natural to study how restricting the allowed types of constraints affects the\napproximability of the problem. In this paper, we show that any Max CSP problem with a\nfinite set of allowed constraint types, which includes all fixed-value constraints (i.e., constraints\nof the form x = a), is either solvable exactly in polynomial time or else is APX-complete, even\nif the number of occurrences of variables in instances is bounded. Moreover, we present a simple\ndescription of all polynomial-time solvable cases of our problem. This description relies on the\nwell-known algebraic combinatorial property of supermodularity.\nKeywords: maximum constraint satisfaction, complexity of approximation, dichotomy, supermod-\nularity, Monge properties\n1 Introduction and Related Work\n1.1 Background\nMany combinatorial optimization problems are NP-hard, and the use of approximation algorithms\nis one of the most prolific techniques to deal with NP-hardness. However, hard optimization\nproblems exhibit different behaviour with respect to approximability, and complexity theory for\napproximation is now a well-developed area [2].\nConstraint satisfaction problems (CSPs) have always played a central role in this direction of\nresearch, since the CSP framework contains many natural computational problems, for example,\nfrom propositional logic and graph theory (see, e.g., [13, 25]). In a CSP, informally speaking,\none is given a finite collection of constraints on overlapping sets of variables, and the goal is to\ndecide whether there is an assignment of values from a given domain to the variables satisfying all\nconstraints (decision problem) or to find an assignment satisfying maximum number of constraints\n(optimization problem). These are the main versions of the CSP, and there are many other versions\nobtained from them by modifying the objective (see, e.g., [13, 34]). In this paper, we will focus on\n1\nthe optimization problems, which are known as maximum constraint satisfaction problems, Max\nCSP for short. The most well-known examples of such problems are Max k-Sat and Max Cut.\nLet us now formally define Max CSP.\nLet D denote a finite set with |D| > 1. Let R(m)D denote the set of all m-ary predicates over D,\nthat is, functions from Dm to {0, 1}, and let RD =\n\u22c3\u221e\nm=1R\n(m)\nD . Also, let Z\n+ denote the set of all\nnon-negative integers.\nDefinition 1.1 (constraint) A constraint over a set of variables V = {x1, x2, . . . , xn} is an ex-\npression of the form f(x) where\n\u2022 f \u2208 R(m)D is called the constraint predicate; and\n\u2022 x = (xi1 , . . . , xim) is called the constraint scope.\nThe constraint f(x) is said to be satisfied on a tuple a = (ai1 , . . . , aim) \u2208 Dm if f(a) = 1.\nNote that throughout the paper the values 0 and 1 taken by any predicate will be considered\nas integers, not as Boolean values, and addition will always denote the addition of integers.\nDefinition 1.2 (Max CSP) For a finite F \u2286 RD, an instance of Max CSP(F) is a pair (V,C)\nwhere\n\u2022 V = {x1, . . . , xn} is a set of variables taking their values from the set D;\n\u2022 C is a collection of constraints f1(x1), . . . , fq(xq) over V , where fi \u2208 F for all 1 \u2264 i \u2264 q.\nThe goal is to find an assignment \u03d5 : V \u2192 D that maximizes the number of satisfied constraints,\nthat is, to maximize the function f : Dn \u2192 Z+, defined by f(x1, . . . , xn) =\n\u2211q\ni=1 fi(xi). If the\nconstraints have (positive integral) weights %i, 1 \u2264 i \u2264 q, then the goal is to maximize the total weight\nof satisfied constraints, that is, to maximize the function f : Dn \u2192 Z+, defined by f(x1, . . . , xn) =\u2211q\ni=1 %i \u00b7 fi(xi).\nComplexity classifications for various versions of constraint satisfaction problems have attracted\nmuch attention in the recent years (see survey [34]) because, as the authors of [13] nicely put it,\nthese classifications \u201cpresent a reasonably accurate bird\u2019s eye view of computational complexity and\nthe equivalence classes it has created\u201d. Classifications with respect to a set of allowed constraint\ntypes (such as F inMax CSP(F) above) have been of particular interest, e.g.,[5, 6, 8, 9, 13, 17, 24].\nBoolean constraint satisfaction problems (that is, whenD = {0, 1}) are by far better studied [13]\nthan the non-Boolean version. The main reason is, in our opinion, that Boolean constraints can be\nconveniently described by propositional formulas which provide a flexible and easily manageable\ntool, and which have been extensively used in complexity theory from its very birth. Moreover,\nBoolean CSPs suffice to represent a number of well-known problems and to obtain results clarifying\nthe structure of complexity for large classes of interesting problems [13]. In particular, Boolean\nCSPs were used to provide evidence for one of the most interesting phenomena in complexity theory,\nnamely that interesting problems belong to a small number of complexity classes [13], which cannot\nbe taken for granted due to Ladner\u2019s theorem. After the pioneering work of Schaefer [38] presenting\na tractable versus NP-complete dichotomy for Boolean decision CSPs, many classification results\nhave been obtained (see, e.g., [13]), most of which are dichotomies. In particular, a dichotomy in\ncomplexity and approximability for Boolean Max CSP has been obtained by Creignou [12], and\n2\nit was slightly refined in [31] (see also [13]). The complexity of Boolean Max CSP with arbitrary\n(i.e., not necessarily positive) weights was classified in [27].\nMany papers on various versions of Boolean CSPs mention studying non-Boolean CSPs as a\npossible direction of future research, and additional motivation for it, with an extensive discus-\nsion, was given by Feder and Vardi [17]. Dichotomy results on non-Boolean CSPs give a better\nunderstanding of what makes a computational problem tractable or hard, and they give a more\nclear picture of the structure of complexity of problems, since many facts observed in Boolean\nCSPs appear to be special cases of more general phenomena. Notably, many appropriate tools\nfor studying non-Boolean CSPs have not been discovered until recently. For example, universal\nalgebra tools have proved to be very fruitful when working with decision, counting, and quanti-\nfied CSPs [5, 6, 7, 8, 9] while ideas from lattice theory, combinatorial optimization and operations\nresearch have been recently suggested for optimization problems [11, 35].\nThe problemMax CSP is NP-hard in general (i.e., without restrictions on the type of allowed\nconstraints), and there is a significant body of results on algorithmic and complexity-theoretical\naspects of this problem, including results on superpolynomial general algorithms (e.g.,[14, 41]),\npolynomial algorithms for special cases [11, 35], explicit approximability bounds (e.g., [16, 20, 22,\n23, 32]), and complexity of approximation (e.g., [3, 13, 28]).\nThe main research problem that we will look at in this paper is the following one.\nProblem 1 Classify the problems Max CSP(F) with respect to approximability.\nWe say that a predicate is non-trivial if it is not identically 0. We will always assume that F is\nfinite and contains only non-trivial predicates. Whenever we do not specify which version (weighted\nor unweighted) we consider, we mean unweightedMax CSP. Note that the definition allows one to\nrepeat constraints in instances (we follow [13] in this), so our unweighted problem actually allows\npolynomially bounded weights. However, our tractability results will hold for the weighted version,\nwhile in our hardness results, for every F , we will use only instances where every constraint occurs\nat most kF times (where kF is a constant depending on F).\nFor the Boolean case, Problem 1 was solved in [12, 13, 31]. It appears that BooleanMax CSP(F)\nproblems exhibit a dichotomy in that such a problem is either solvable exactly in polynomial time or\nelse APX-complete, i.e., does not admit a PTAS (polynomial-time approximation scheme) unless\nP=NP. These papers also describe the boundary between the two cases. This dichotomy result\nwas extended to the case |D| = 3 in [28]. The complexity of non-BooleanMax CSP with arbitrary\n(i.e., not necessarily positive) weights was recently classified in [29].\n1.2 Results\nFor a subset D\u2032 \u2286 D, let uD\u2032 denote the predicate such that uD\u2032(x) = 1 if and only if x \u2208 D\u2032.\nLet UD = {uD\u2032 | \u2205 6= D\u2032 \u2286 D}, that is, UD is the set of all non-trivial unary predicates on D.\nFurthermore, let CD = {u{d} | d \u2208 D}. Note that predicates from CD give rise to constraints of the\nform x = d, i.e., fixed-value constraints.\nThe decision problems CSP(F) are similar to Max CSP(F), but the the task is to decide\nwhether all constraints in a given instance can be simultaneously satisfied. Problems of the\nform CSP(F \u222a UD) are known as conservative (or list) CSPs, and their complexity has been com-\npletely classified by Bulatov in [6], while a complexity classification for the problems of the form\nCSP(F \u222a CD) would imply a classification for all problems CSP(F) [9].\nIn this paper we solve the above Problem 1 for all sets of the form F \u222a CD where D is any\nfinite set. (Note that this does not necessarily imply a full solution to Problem 1, as it would\n3\nfor decision problems.) Our result is parallel to Bulatov\u2019s classification of conservative CSPs [6],\nbut our techniques are quite different from the universal-algebraic techniques used in [6]. The\nuniversal-algebraic techniques from [6, 9] cannot be applied in the optimization setting because the\nbasic properties of decision CSPs that make these techniques useful are not satisfied byMax CSP.\nIt was suggested in Section 6 of [11] that Max CSP(F \u222a CD) is solvable exactly in polynomial\ntime if and only if all predicates in F are supermodular with respect to some linear ordering on\nD (see definitions in Section 4). We prove that this is indeed the case, and that in all other\ncases the problem Max CSP(F \u222a CD) is APX-complete. Moreover, we show that every APX-\ncomplete problem of the above form is APX-complete even when we further restrict it to instances\nwhere the number of occurrences of variables is bounded by some (possibly large) constant. Note\nthat approximability properties for constraint problems with the bounded occurrence property (as\nwell as for related problems on graphs with bounded degree) have been intensively studied in the\nliterature (see, e.g., [1, 4, 21, 30]).\nOur classification result uses the combinatorial property of supermodularity which is a well-\nknown source of tractable optimization problems [10, 18, 40], and the technique of strict imple-\nmentations [13, 31] which allows one to show that an infinite family of problems can express, in a\nregular way, one of a few basic hard problems. We remark that the idea to use supermodularity\nin the analysis of the complexity of Max CSP(F) is very new, and has not been even suggested\nin the literature prior to [11]. It was shown in [11, 28] that supermodularity is the only source\nof tractability for problems of the form Max CSP(F) when D is small (i.e., |D| \u2264 3). This, to-\ngether with the results obtained in the present paper, suggests that supermodularity is indeed the\nappropriate tool for tackling Problem 1.\nSome of our technical results (those in Section 5) are of independent interest in combinatorics.\nIn [33], Klinz et al. study how one can permute rows and columns of a 0-1 matrix so as to avoid\na collection of given forbidden submatrices; some results of this nature have later been used in\nconstructing phylogenetic trees [36]. Klinz et al. obtain many results in this direction, but they\nleave open the case when matrices are square and rows and columns must be permuted by the\nsame permutation (see Section 6 of [33]). Our results clarify the situation in this special case for\none type of forbidden matrices considered in Theorem 4.5 of [33].\nThe structure of the paper is as follows: Section 2 contains definitions of approximation com-\nplexity classes and reductions. In Section 3, we describe our reduction techniques, and in Section 4\nwe give the basics of supermodularity and discuss the relevance of supermodularity in the study of\nMax CSP. Section 5 contains technical results that are used in the proof of the main classification\nresult of the paper, and this proof can be found in Section 6. Finally, In Section 7, we discuss\nan application of our results to the optimization version of the List H-colouring problem for\ndigraphs. Some of the technical proofs omitted from the main body of the paper can be found in\nAppendices.\n2 Basics of approximability\nA combinatorial optimization problem is defined over a set of instances (admissible input data);\neach instance I has a finite set sol(I) of feasible solutions associated with it. The objective function\nattributes a positive integer cost to every solution in sol(I). The goal in an optimization problem\nis, given an instance I, to find a feasible solution of optimum cost. The optimal cost is the largest\none for maximization problems and the smallest one for minimization problems. A combinatorial\noptimization problem is said to be anNP optimization (NPO) problem if its instances and solutions\ncan be recognized in polynomial time, the solutions are polynomial-bounded in the input size, and\n4\nthe objective function can be computed in polynomial time (see, e.g., [2]).\nDefinition 2.1 (performance ratio) A solution s \u2208 sol(I) to an instance I of an NPO problem\n\u03a0 is r-approximate if\nmax { cost(s)\nOpt(I) ,\nOpt(I)\ncost(s)\n} \u2264 r,\nwhere Opt(I) is the optimal cost for a solution to I. An approximation algorithm for an NPO\nproblem \u03a0 has performance ratio R(n) if, given any instance I of \u03a0 with |I| = n, it outputs an\nR(n)-approximate solution.\nDefinition 2.2 (complexity classes) PO is the class of NPO problems that can be solved (to\noptimality) in polynomial time. An NPO problem \u03a0 is in the class APX if there is a polynomial\ntime approximation algorithm for \u03a0 whose performance ratio is bounded by a constant.\nThe following result is contained in Proposition 2.3 [11] and its proof.\nLemma 2.3 Every (weighted or not) problem Max CSP(F) belongs to APX. Moreover, if a is\nthe maximum arity of any predicate in F then there is a polynomial time algorithm which, for every\ninstance I of Max CSP(F), produces a solution satisfying at least q|D|a constraints, where q is the\nnumber of constraints in I.\nCompleteness in APX is defined using an appropriate reduction, called AP -reduction. Our\ndefinition of this reduction follows [13, 31].\nDefinition 2.4 (AP -reduction, APX-completeness) An NPO problem \u03a01 is said to be AP -\nreducible to an NPO problem \u03a02 if two polynomial-time computable functions F and G and a\nconstant \u03b1 exist such that\n(a) for any instance I of \u03a01, F (I) is an instance of \u03a02;\n(b) for any instance I of \u03a01, and any feasible solution s\u2032 of F (I), G(I, s\u2032) is a feasible solution\nof I;\n(c) for any instance I of \u03a01, and any r \u2265 1, if s\u2032 is an r-approximate solution of F (I) then\nG(I, s\u2032) is an (1 + (r \u2212 1)\u03b1 + o(1))-approximate solution of I where the o-notation is with\nrespect to |I|.\nAn NPO problem \u03a0 is APX-hard if every problem in APX is AP -reducible to it. If, in\naddition, \u03a0 is in APX then \u03a0 is called APX-complete.\nIt is a well-known fact (see, e.g., Section 8.2.1 in [2]) that AP -reductions compose. We shall\nnow give an example of an APX-complete problem which will be used extensively in this paper.\nExample 2.5 Given a graph G = (V,E), the Maximum k-colourable Subgraph problem,\nk \u2265 2, is the problem of maximizing |E\u2032|, E\u2032 \u2286 E, such that the graph G\u2032 = (V,E\u2032) is k-colourable.\nThis problem is known to be APX-complete (it is Problem GT33 in [2]). Let neqk denote the binary\ndisequality predicate on D = {0, 1, . . . , k \u2212 1}, k \u2265 2, that is, neqk(x, y) = 1 \u21d4 x 6= y. Consider\nthe problem Max CSP({neqk}) restricted to instances where every pair of variables appears in the\nscope of at most one constraint. This problem is exactly the Maximum k-colourable Subgraph\nproblem. To see this, think of vertices of a given graph as of variables that take values from D, and\n5\nintroduce the constraint neqk(x, y) for every pair of variables x, y such that (x, y) is an edge in the\ngraph. It follows that the problem Max CSP({neqk}) is APX-complete.\nNote that the weighted Max CSP({neqk}) problem coincides with the well-known problemMax\nk-Cut (it is Problem ND17 in [2]). The Max 2-Cut problem is usually referred to as simply Max\nCut.\nIn some of our hardness proofs, it will be convenient for us to use another type of approximation-\npreserving reduction, called an L-reduction [2].\nDefinition 2.6 (L-reduction) AnNPO problem \u03a01 is said to be L-reducible to anNPO problem\n\u03a02 if two polynomial-time computable functions F and G and positive constants \u03b1, \u03b2 exist such that\n(a) given any instance I of \u03a01, algorithm F produces an instance I \u2032 = F (I) of \u03a02, such that the\ncost of an optimal solution for I \u2032, Opt(I \u2032), is at most \u03b1 \u00b7Opt(I);\n(b) given I, I \u2032 = F (I), and any solution s\u2032 to I \u2032, algorithm G produces a solution s to I such\nthat |cost(s)\u2212Opt(I)| \u2264 \u03b2 \u00b7 |cost(s\u2032)\u2212Opt(I \u2032)|.\nIt is well known (see, e.g., Lemma 8.2 in [2]) that, within APX, the existence of an L-reduction\nfrom \u03a01 to \u03a02 implies the existence of an AP -reduction from \u03a01 to \u03a02.\n3 Reduction techniques\nThe main reduction technique in our APX-completeness proofs is based on strict implementations,\nsee [13, 31] where this notion was introduced for the Boolean case. We will give this definition in\na slightly different form from that of [13, 31], but it can easily be checked to be equivalent to the\noriginal one (in the case |D| = 2).\nDefinition 3.1 (strict implementation) Let Y = {y1, . . . , ym} and Z = {z1, . . . , zn} be two\ndisjoint sets of variables. The variables in Y are called primary and the variables in Z auxiliary.\nThe set Z may be empty. Let g1(y1), . . . , gs(ys), s > 0, be constraints over Y \u222aZ. If g(y1, . . . , ym)\nis a predicate such that the equality\ng(y1, . . . , ym) + (\u03b1\u2212 1) = max\nZ\ns\u2211\ni=1\ngi(yi)\nholds for all y1, . . . , ym, and some fixed \u03b1 \u2208 Z+, then this equality is said to be a strict \u03b1-implementation\nof g from g1, . . . , gs.\nWe use \u03b1 \u2212 1 rather than \u03b1 in the above equality to ensure that this notion coincides with the\noriginal notion of a strict \u03b1-implementation for Boolean constraints [13, 31]. The intuition behind\nthe notion of strict implementation is that it allows one to modify instances while keeping control\nover costs of solutions. For example, assume that we have a constraint g(u, v) in an instance I\nof Max CSP, and there is a strict 2-implementation g(y1, y2) + 1 = maxz (g1(y1, z) + g2(z, y2)).\nThen the constraint g(u, v) can be replaced by two constraints g1(u, z), g2(z, v) such that z does\nnot appear in I, and we know that every solution of cost c to I can be modified (by choosing an\nappropriate value for z) to a solution of cost c+ 1 to the new instance.\nWe say that a collection of predicates F strictly implements a predicate g if, for some \u03b1 \u2208 Z+,\nthere exists a strict \u03b1-implementation of g using predicates only from F . In this case we write\n6\nF s=\u21d2\u03b1 f . We write F s=\u21d2 f if F s=\u21d2\u03b1 f for some \u03b1. It is not difficult to show that if f can\nbe obtained from F by a series of strict implementations then it can also be obtained by a single\nstrict implementation (for the Boolean case, this is shown in Lemma 5.8 [13]). In this paper, we\nwill use about 60 specific strict implementations for the case when |D| = 4. Each of them can be\nstraightforwardly verified by hand, or by a simple computer program1.\nThe following lemma is a simple (but important) example of how strict implementations work.\nLemma 3.2 CD strictly implements every predicate in UD.\nProof: It is easy to see that, for anyD\u2032 \u2286 D, uD\u2032(x) =\n\u2211\nd\u2208D\u2032 u{d}(x) is a strict 1-implementation.\n2\nIn our proofs, we will use problems with the bounded occurrence property, and we now introduce\nnotation for such problems.\nDefinition 3.3 (bounded occurrence problems) Max CSP(F) \u2212 k will denote the problem\nMax CSP(F) restricted to instances with the number of occurrences of variables is bounded by\nk. We will write that Max CSP(F) \u2212 B is APX-complete to denote that Max CSP(F) \u2212 k is\nAPX-complete for some k.\nNote that, by definition, repetitions of constraints in instances of Max CSP are allowed. If\na variable occurs t times in a constraint which appears s times in an instance, then this would\ncontribute t \u00b7 s to the number of occurrences of that variable in the instance.\nLemma 3.4 If F strictly implements a predicate f , andMax CSP(F \u222a {f})\u2212B isAPX-complete,\nthen Max CSP(F)\u2212B is APX-complete as well.\nProof: This lemma for the Boolean case, but without the assumption on bounded occurrences,\nis Lemma 5.18 in [13]. Our proof is almost identical to the proof of Lemma 5.18 in [13], and it uses\nthe same AP -reduction. Essentially, we only need to verify that the mapping F in this reduction\npreserves the bounded occurrence property.\nLet k be a number such that Max CSP(F \u222a {f}) \u2212 k is APX-complete and let \u03b1 \u2208 Z+ be\nsuch that F s=\u21d2\u03b1 f . Take an arbitrary instance I of Max CSP(F \u222a {f}) \u2212 k. Note that every\npredicate in F can be (trivially) strictly \u03b1-implemented from F in such a way that each auxiliary\nvariable appears only once in the strict implementation (simply use any satisfiable collection of \u03b1\u22121\nconstraints with no repetitions of variables); this is a small technicality which ensures uniformity\nin the following transformation of instances. Replace every constraint in I by a set of constraints\nappearing in the right-hand side of its strict \u03b1-implementation from F , keeping the same primary\nvariables and using fresh copies of auxiliary variables every time. Denote the obtained instance\nby I \u2032. The function F in this AP -reduction will be such that F (I) = I \u2032 for all I. Let t be the\nmaximum number of occurrences of a variable (primary or auxiliary) in the right-hand side of the\nstrict implementation of f from F . It is clear that I \u2032 is an instance of Max CSP(F), and that the\nnumber of occurrences of any variable in I \u2032 is bounded by k\u2032 = tk.\nLet V \u2032 be the set of variables in I \u2032. Let \u03d5\u2032 : V \u2032 \u2192 D be an r-approximate solution to I \u2032. The\nmapping G uses two possible solutions to I and takes the better of the two. The first solution is\n1An example of such a program can be obtained from the authors or be anonymously downloaded from\nhttp:\/\/www.ida.liu.se\/~petej\/supermodular.html.\n7\n\u03d5\u2032|V , while the second is a solution satisfying \u03b2 = q|D|a constraints which exists by Lemma 2.3 (here\na is the maximum arity of constraints in F \u222a {f}).\nOne can show, by literally repeating the argument in the proof of Lemma 5.18 in [13], that\nG(\u03d5\u2032) is an r\u2032-approximate solution to I where r\u2032 \u2264 1 + \u03b3(r \u2212 1) with \u03b3 = \u03b2(\u03b1\u2212 1) + 1.\nWe have constructed an AP -reduction from Max CSP(F \u222a {f}) \u2212 k to Max CSP(F) \u2212 k\u2032,\nthus proving the lemma. 2\nLemma 3.4 will be used as follows in our APX-completeness proofs: if F \u2032 is a fixed finite\ncollection of predicates each of which can be strictly implemented by F then we can assume that\nF \u2032 \u2286 F . For example, if F contains a binary predicate f then we can assume, at any time when it is\nconvenient, that F also contains f \u2032(x, y) = f(y, x), since this equality is a strict 1-implementation\nof f \u2032.\nFinally, we will use a technique based on domain restriction. For a subset D\u2032 \u2286 D, let F|D\u2032 =\n{f |D\u2032 | f \u2208 F and f |D\u2032 is non-trivial}.\nLemma 3.5 Let D\u2032 \u2286 D and uD\u2032 \u2208 F . If Max CSP(F|D\u2032) \u2212 B is APX-complete then so is\nMax CSP(F)\u2212B.\nProof: Let k be a bound on the number of occurences such that Max CSP(F|D\u2032)\u2212 k is APX-\ncomplete. We establish an L-reduction from Max CSP(F|D\u2032) \u2212 k to Max CSP(F) \u2212 k\u2032 where\nk\u2032 = 2k.\nAn instance I of Max CSP(F|D\u2032) \u2212 k corresponding to f(x1, . . . , xn) =\n\u2211q\ni=1 fi(xi) will be\nmapped to an instance I \u2032 corresponding to f \u2032(x1, . . . , xn) =\n\u2211q\ni=1 f\n\u2032\ni(xi) + k\n\u2211n\ni=1 uD\u2032(xi) where\neach f \u2032i \u2208 F is such that f \u2032i |D\u2032 = fi. We may without loss of generality assume that all n variables xi\nactually appear in constraint scopes in I. Note that I \u2032 is indeed an instance ofMax CSP(F)\u2212k\u2032.\nLet V = {x1, . . . , xn} and fix an element d \u2208 D\u2032. If \u03d5\u2032 : V \u2192 D is a solution to I \u2032, then it is\nmodified to a solution to I as follows: set \u03d5(xi) = d whenever \u03d5\u2032(xi) 6\u2208 D\u2032, and \u03d5(xi) = \u03d5\u2032(xi)\notherwise.\nWe will show that this pair of mappings is an L-reduction for suitable \u03b1 and \u03b2.\nNote that, for any solution to I \u2032, changing all values outside of D\u2032 to any values in D\u2032 can only\nincrease the cost of the solution. This follows from the fact that, by changing any value outside of\nD\u2032 to a value in D\u2032, we can lose at most k satisfied constraints, but we satisfy k constraints of the\nform uD\u2032(x). It follows that Opt(I \u2032) = Opt(I) + kn.\nLet a be the maximum arity of constraints in F|D\u2032 . Let c = 1|D|a . Then we have c \u00b7 q \u2264 Opt(I)\nby Lemma 2.3 (recall that q is the number of constraints in I). Set \u03b1 = akc + 1. Note that we\nhave n \u2264 aq because the total length of constraint scopes in I is at least n and at most aq. Since\nn \u2264 aq \u2264 aOpt(I)c , we have\nOpt(I \u2032) = Opt(I) + kn \u2264 Opt(I) + kaOpt(I)\nc\n= \u03b1 \u00b7Opt(I),\nso the first property of an L-reduction is satisfied.\nWe will now show that the second property is satisfied with \u03b2 = 1. Let \u03d5\u2032 and \u03d5 be solutions\nto I \u2032 and I, respectively, such as described above.\nLet V1 be the set of variables which \u03d5\u2032 sends to D \\ D\u2032, and V2 the variables sent to D\u2032; set\nr = |V2|. Divide all constraints in I \u2032 into three pairwise disjoint groups: C1 consists of all constraints\nfi(xi) that contain at least one variable from V1, C2 of all constraints fi(xi) that use variables only\nfrom V2, and C3 contains the kn constraints of the form uD\u2032(xi). Let q1 = |C1|. Furthermore,\n8\nlet s1 and s2 be the numbers of constraints in C1 and C2, respectively, that are satisfied by \u03d5\u2032.\nBy the bounded occurrence property, we have s1 \u2264 q1 \u2264 (n \u2212 r)k. In particular, it follows that\ns1 \u2212 nk + rk \u2264 0. Note also that cost(\u03d5\u2032) = s1 + s2 + rk and s2 \u2264 cost(\u03d5). Finally, we have\nOpt(I)\u2212 cost(\u03d5) \u2264 Opt(I)\u2212 s2 =\n[Opt(I) + nk]\u2212 [s1 + s2 + rk] + [s1 \u2212 nk + rk] \u2264 Opt(I \u2032)\u2212 cost(\u03d5\u2032).\n2\n4 Supermodularity, Monge properties, and Max CSP\n4.1 Basics of supermodularity\nIn this section we discuss the well-known combinatorial algebraic property of supermodularity [40]\nwhich will play a crucial role in classifying the approximability of Max CSP problems.\nA partial order on a set D is called a lattice order if, for every x, y \u2208 D, there exists a greatest\nlower bound xuy and a least upper bound xunionsqy. The corresponding algebra L = (D,u,unionsq) is called\na lattice. For tuples a = (a1, . . . , an), b = (b1, . . . , bn) in Dn, let a u b and a unionsq b denote the tuples\n(a1 u b1, . . . , an u bn) and (a1 unionsq b1, . . . , an unionsq bn), respectively.\nDefinition 4.1 (supermodular function) Let L be a lattice on D. A function f : Dn \u2192 Z+ is\ncalled supermodular on L if\nf(a) + f(b) \u2264 f(a u b) + f(a unionsq b) for all a,b \u2208 Dn.\nNote that predicates are functions, so it makes sense to consider supermodular predicates. We\nsay that F \u2286 RD is supermodular on L if every f \u2208 F has this property.\nA finite lattice L = (D,u,unionsq) is distributive if and only if it can be represented by subsets\nof a set A, where the operations u and unionsq are interpreted as set-theoretic intersection and union,\nrespectively. Totally ordered lattices, or chains, will be of special interest in this paper. Note that,\nfor chains, the operations u and unionsq are simply min and max. Hence, the supermodularity property\nfor an n-ary function f on a chain is expressed as follows:\nf(a1, . . . , an) + f(b1, . . . , bn) \u2264\nf(min(a1, b1), . . . ,min(an, bn)) + f(max(a1, b1), . . . ,max(a1, b1))\nfor all a1, . . . , an, b1, . . . , bn.\nExample 4.2\n1) The disequality predicate neqD is not supermodular on any chain on D. Take two elements\nd1, d2 \u2208 D such that d1 < d2. Then\nneqD(d1, d2) + neqD(d2, d1) = 2 6\u2264 0 = neqD(d1, d1) + neqD(d2, d2).\n2) Fix a chain on D and let a,b be arbitrary elements of D2. Consider the binary predicate fa,\nfb and fba defined by the rules\nfa(x, y) = 1 \u21d4 (x, y) \u2264 a,\nfb(x, y) = 1 \u21d4 (x, y) \u2265 b,\nfba (x, y) = 1 \u21d4 (x, y) \u2264 a or (x, y) \u2265 b,\n9\nwhere the order on D2 is component-wise. It is easy to check that every predicate defined above\nin this part of the example is supermodular on the chain. Note that such predicates were consid-\nered in [11] where they were called generalized 2-monotone. We will see later in this subsection\n(Lemma 4.4) that such predicates are generic supermodular binary predicates on a chain.\nWe will now make some simple, but useful, observations.\nObservation 4.3\n1. Any chain is a distributive lattice.\n2. Any unary predicate on D is supermodular on any chain on D.\n3. A predicate is supermodular on a chain if and only if it is supermodular on its dual chain\n(obtained by reversing the order).\nGiven a chain in D, any binary function f on D can be represented as a |D| \u00d7 |D| matrix M\nsuch that M(x, y) = f(x, y); here the chain indicates the order of indices of M , and M(x, y) is\nthe entry in row x and column y of M . Note that this matrix is essentially the table of values of\nthe predicate. For example, some binary predicates on D = {0, 1, 2, 3} that are supermodular on\nthe chain 0 < 1 < 2 < 3 are listed in Fig. 1 (these predicates will be used later in the proof of\nTheorem 6.3). Note that all predicates in Fig. 1 have the form described in Example 4.2(2). For\nexample, h2 is f\n(3,3)\n(0,1) and h17 is f\n(1,3)\n(2,1) .\nh1\n1000\n0000\n0000\n0001\nh2\n1100\n0000\n0000\n0001\nh3\n1110\n0000\n0000\n0001\nh4\n1100\n1100\n0000\n0001\nh5\n1110\n1110\n0000\n0001\nh6\n1110\n1110\n1110\n0001\nh7\n1100\n0000\n0001\n0001\nh8\n1110\n0000\n0001\n0001\nh9\n1000\n1000\n0001\n0001\nh10\n1100\n1100\n0001\n0001\nh11\n1110\n1110\n0001\n0001\nh12\n1110\n0001\n0001\n0001\nh13\n1000\n1001\n0001\n0001\nh14\n1100\n1101\n0001\n0001\nh15\n1000\n1001\n1001\n0001\nh16\n1100\n1100\n1101\n0001\nh17\n1100\n1101\n1101\n0001\nh18\n1100\n1100\n0011\n0011\nFigure 1: A list of predicates on {0, 1, 2, 3} which are supermodular on the chain 0 < 1 < 2 < 3.\nThe predicates are represented by tables of values.\nA square matrix M is called anti-Monge (or a-Monge, for short)2 if M(i, s) + M(r, j) \u2264\nM(i, j) + M(r, s) for all i < r and j < s. It is well known (and easy to check) that matrices\ncorresponding to binary supermodular functions on a chain are precisely the a-Monge matrices\n(see, e.g., Observation 6.1 in [10]). Hence, one can view the tables in Fig. 1 as a-Monge matrices.\nWe will be particularly interested in binary supermodular predicates on chains, and the next result\ndescribes the structure of 0-1 a-Monge square matrices.\nIn order to make the correspondence between matrices and binary functions more transparent,\nwe will use the set J = {0, . . . , n \u2212 1} to number rows and columns of an n \u00d7 n matrix. Let Lpqn\ndenote the square 0-1 matrix of size n such that Lpqn (i, j) = 1 if and only if i \u2264 p and j \u2264 q.\nSimilarly, Rstn denotes the square 0-1 matrix of size n such that R\nst\nn (i, j) = 1 if and only if i \u2265 s\nand j \u2265 t. Let U and W be two subsets of J . We denote by M [U,W ] the |U | \u00d7 |W | submatrix of\nM that is obtained by deleting all rows not contained in U and all columns not in W . Expression\nM [U,W ] = a will mean that all elements in the submatrix are equal to a.\nThe following result is a direct corollary of Lemma 2.3 of [10].\n2Other names used for such matrices are inverse Monge and dual Monge.\n10\nLemma 4.4 A non-zero 0-1 matrix M of size n \u00d7 n without all-ones rows and columns is an\na-Monge matrix if and only if one of the following holds\n\u2022 M = Lpqn , for some 0 \u2264 p, q \u2264 n\u2212 2, or\n\u2022 M = Rst, for some 1 \u2264 s, t \u2264 n\u2212 1, or\n\u2022 M = Lpqn +Rstn for some 0 \u2264 p, q \u2264 n\u2212 2 and 1 \u2264 s, t \u2264 n\u2212 1, with p < s, or q < t, or both.\nThe family of n-ary supermodular functions on a chain was also studied under the name of n-\ndimensional anti-Monge arrays [10]. As a special case of Lemma 6.3 of [10], we have the following\nresult (see also Observation 6.1 of [10]).\nLemma 4.5 An n-ary, n \u2265 2, function f is supermodular on a fixed chain if and only if the\nfollowing holds: every binary function obtained from f by replacing any given n \u2212 2 variables by\nany constants is supermodular on this chain.\n4.2 Supermodularity and Max CSP\nThe property of supermodularity has been used to classify the approximability of problemsMax CSP(F)\nfor small sets D (though, originally the classification for the case |D| = 2 was obtained and stated\nin [12, 13, 31] without using this property). To make use of results in [11, 28], we need to introduce\nsome more notation.\nDefinition 4.6 (endomorphism, core) An endomorphism of F is a unary operation \u00b5 on D\nsuch that, for all f \u2208 F and all (a1, . . . , am) \u2208 Dm, we have\nf(a1, . . . , am) = 1\u21d2 f(\u00b5(a1), . . . , \u00b5(am)) = 1.\nWe will say that F is a core if every endomorphism of F is injective (i.e., a permutation).\nIf \u00b5 is an endomorphism of F with a minimal image im(\u00b5) = D\u2032 then a core of F , denoted\ncore(F), is the set F|D\u2032.\nThe intuition here is that if F is not a core then it has a non-injective endomorphism \u00b5, which\nimplies that, for every assignment \u03d5, there is another assignment \u00b5\u03d5 that satisfies all constraints\nsatisfied by \u03d5 and uses only a restricted set of values, so the problem is equivalent to a problem\nover this smaller set. As in the case of graphs, all cores of F are isomorphic, so one can speak\nabout the core of F . Note that any set of the form F \u222a CD is a core.\nTheorem 4.7 ([11, 13, 28]) Let |D| \u2264 3 and let F \u2286 RD be a core. If F is supermodular on\nsome chain on D then weighted Max CSP(F) belongs to PO. Otherwise, Max CSP(F) is APX-\ncomplete.\nRemark 4.8 It was shown in Lemma 5.37 of [13] that, for D = {0, 1}, F \u2286 R{0,1} can strictly\nimplement neq2 whenever Max CSP(F) is APX-complete in the above theorem (i.e. whenever F\nis a core that is not supermodular on any chain). Moreover, it follows from (the proof of) Theorem\n3 of [28] that if |D| = 3 and F is not supermodular on any chain on D then F \u222a CD can express\nneq2 or neq3 by using a sequence of the following operations:\n\u2022 adding to F a predicate that can be strictly implemented from F\n\u2022 taking the core of a subset of F .\n11\nIt was shown in [1] that Max Cut remains APX-complete even when restricted to cubic\ngraphs. Since Max Cut is the same problem as Max CSP({neq2}) (see Example 2.5), it follows\nthat Max CSP({neq2})\u2212B is APX-complete. Moreover, since neqk|{0,1} = neq2, it follows from\nLemma 3.5 that Max CSP({neqk, u{0,1}})\u2212B is APX-complete for any k. Therefore, we obtain\nthe following corollary by combining Remark 4.8 with Lemmas 3.4 and 3.5.\nCorollary 4.9 Let |D| \u2264 3 and F not supermodular on any chain on D. Then the problem\nMax CSP(F \u222a UD)\u2212B is APX-complete.\nThe tractability part of our classification is contained in the following result:\nTheorem 4.10 ([11], see also [26, 39]) If F is supermodular on some distributive lattice on D,\nthen weighted Max CSP(F) is in PO.\n5 Permuted a-Monge matrices\nIn this section, we prove results about a-Monge matrices that will imply, via the correspondence\nbetween binary supermodular predicates on chains and a-Monge matrices, the following result.\nTheorem 5.1 If F is a set of binary predicates that is not supermodular on any chain on D, then\nthere exists F \u2032 \u2286 F with |F \u2032| \u2264 3 and D\u2032 \u2286 D with |D\u2032| \u2264 4 such that F \u2032|D\u2032 is not supermodular\non any chain on D\u2032.\nWe prove this theorem in two steps: the existence of D\u2032 is established in Section 5.1 (see\nCorollary 5.4) and the existence of F \u2032 in Section 5.2 (see Proposition 5.7). Our results about\nmatrices will be more general than required to prove Theorem 5.1 because we will consider general\n(i.e., not necessarily 0-1) matrices.\nFirst, we need to introduce some concepts and notation. LetM be an n\u00d7n matrix. If there is a\npermutation pi that simultaneously permutes rows and columns ofM so that the resulting matrix is\nan a-Monge matrix, then the matrix M is called a permuted a-Monge matrix and the permutation\nis called an a-Monge permutation for M . Note that we will often use the term \u2018permutation\u2019 as\na synonym for \u2018linear (re-)ordering\u2019. Given a set of indices I = {i1, . . . , ik} \u2286 J = {0, . . . , n \u2212 1},\nwe use notation M [I] for the sub-matrix M [I, I]. We say that M [I] is permuted according to a\npermutation \u3008s1, . . . , sk\u3009, where I = {s1, . . . , sk}, if row (column) s1 is the first row (column) in\nthe permuted matrix, s2 is the second row (column), and so on. If n \u2264 4 and M is not a permuted\na-Monge matrix, then M is called a bad matrix.\nA row i precedes a row j inM (i \u227a j for short), if row i occurs before row j inM . If i precedes j\nin a permutation pi, then we write i \u227api j. When the permutation pi is understood from the context,\nwe simply write i \u227a j. If pi is an a-Monge permutation for the matrix M , then the reverse of pi,\npi\u2212 defined as pi\u2212(i) = pi(n\u2212 1\u2212 i), is also an a-Monge permutation. Therefore, given two indices\ni and j, we can always assume that i precedes j in an a-Monge permutation (if there is any).\nDenote by \u2206(i, j, k, l), for i, j, k, l \u2208 J , an algebraic sum that involves four entries of the matrix\nM : \u2206(i, j, k, l) =M(i, k) +M(j, l)\u2212M(i, l)\u2212M(j, k). Given a permutation pi for permuting rows\nand columns in M , we use a similar notation for the sums in the permuted matrix: \u2206(i, j, k, l, pi) =\nM(pi(i), pi(k)) + M(pi(j), pi(l)) \u2212 M(pi(i), pi(l)) \u2212 M(pi(j), pi(k)). For k = i and l = j, we use\nsimplified notation \u2206(i, j) = \u2206(i, j, i, j), for i, j \u2208 J . Matrix M is an a-Monge matrix if and only\n12\nif \u2206(i, j, k, l) \u2265 0 for all i < j and k < l, and M is permuted a-Monge if and only if there exists a\npermutation pi such that \u2206(i, j, k, l, pi) \u2265 0 for all i < j and k < l. It is easy to check that\n\u2206(i, j, k, l) =\n\u2211\ns=i,...,j\u22121;t=k,...,l\u22121\n\u2206(s, s+ 1, t, t+ 1). (1)\nTherefore, given a permutation pi and matrix M , it can be checked in O(n2) time whether pi is an\na-Monge permutation for the matrix M .\nWe will often use the following equalities (which are direct consequences of equation (1)):\n\u2206(i, j, k, l) = \u2206(i, s, k, l) + \u2206(s, j, k, l) and \u2206(i, j, k, l) = \u2206(i, j, k, s) + \u2206(i, j, s, l)\nWe will say that row (column) s is equivalent to row (respectively, column) t, if \u2206(s, t, k, l) = 0\n(respectively, \u2206(k, l, s, t) = 0) for all k, l. It can easily be shown that if rows s and t are equivalent,\nthen M(s, i) =M(t, i) + \u03b1st, for all i and some constant \u03b1st. Hence, after subtracting \u03b1st from all\nelements in the row s (M \u2032(s, i) = M(s, i) \u2212 \u03b1st), one gets two identical rows s and t (M \u2032(s, i) =\nM \u2032(t, i) for all i). A matrix with all rows (and all columns) equivalent is called a sum matrix: It\ncan be shown that in this case M(s, t) = us + vt, for some real vectors u and v. Clearly, any sum\nmatrix is a-Monge.\n5.1 Reducing the size of matrices\nWe will first show that whenever an n \u00d7 n matrix M is not a permuted a-Monge matrix, then\nthere exists a set of indices B with |B| \u2264 4 such that M [B] is a bad matrix. Our approach to\nthe recognition of bad matrices is loosely based on the COM (Construct partial Orders and Merge\nthem) algorithm, suggested in [15]. This algorithm constitutes a general approach to deciding\nwhether a given matrix, possibly with some unknown elements, can be permuted to avoid a special\nset of 2\u00d7 2 submatrices. In our case, these are submatrices M [{i, j, k, l}] with \u2206(i, j, k, l) < 0.\nWe will use the idea of the COM algorithm, which goes as follows: given a matrix M , we\ntry to construct an a-Monge permutation for it. We start with a pair of indices (i, j) which\ncorrespond to two non-equivalent rows or columns in the matrix. We assume further that the index\ni precedes index j in an a-Monge permutation pi. The assumption i \u227api j determines the order\nof some other indices. Under the assumption that i \u227api j, the strict inequality \u2206(i, j, k, l) > 0\nindicates that k \u227api l, while the strict inequality \u2206(i, j, k, l) < 0 indicates that l \u227api k. (Note that\n\u2206(i, j, k, l) = \u2212\u2206(i, j, l, k) = \u2212\u2206(j, i, k, l) = \u2206(j, i, l, k) \u2013 this property will often be used in our\nproofs). The obtained information can be conveniently represented as a directed graph PM with\nnodes J and directed arcs corresponding to the identified precedence constraints together with the\ninitial constraint i \u227api j. We then extend PM recursively to obtain additional information about the\nordering of indices. Eventually, either PM contains an oriented cycle which signals that the matrix\nis not a permuted a-Monge matrix, or we can view PM as a partial order. This order defines a set of\npermutations (i.e., linear extensions of PM ) which are our candidates for an a-Monge permutation.\nWe illustrate the COM approach with the following example.\nExample 5.2 Consider a submatrix M [{i, k, j}]. Schematic representation of this sub-matrix and\nalgebraic sums \u2206 is shown in Fig. 2. We claim that, provided \u2206(i, j) = \u2206(i, k) = \u2206(k, j) = 0, the\nsubmatrix is either a bad matrix or a sum matrix.\nIt follows from \u2206(i, j) = \u2206(i, k) + \u2206(i, k, k, j) + \u2206(k, j, i, k) + \u2206(k, j) = 0 that \u2206(k, j, i, k) =\n\u2212\u2206(i, k, k, j). Suppose that \u2206(k, j, i, k) 6= 0 and \u2206(i, k, k, j) 6= 0. Without loss of generality,\nsuppose that i \u227a k in an a-Monge permutation and that \u2206(i, k, k, j) > 0. The assumption that row\n13\n\u2206(i, k) = 0 \u2206(i, k, k, j)\n\u2206(k, j, i, k) \u2206(k, j) = 0\ni\nk\nj\nk j\nFigure 2: Schematic representation of submatrices and algebraic sums \u2206.\ni precedes row k, together with the inequality \u2206(i, k, k, j) > 0 yields k \u227a j. The assumption that\ncolumn i precedes column k together with the inequality \u2206(k, j, i, k) < 0 yields a contradictory\nprecedence j \u227a k. Therefore M [{i, j, k}] is a bad matrix.\nIf \u2206(k, j, i, k) = 0 and \u2206(i, k, k, j) = 0, then it can easily be shown that M [{i, j, k}] is a sum\nmatrix. 2\nWe recommend the reader to use diagrams like the one in Fig. 2 in the following proof, since\nthey make arguments more transparent.\nTheorem 5.3 If an n\u00d7 n matrix M is not a permuted a-Monge matrix, then there exists a set of\nindices B with |B| \u2264 4, such that M [B] is a bad matrix.\nProof: We can without loss of generality assume that M has no pair s, t of indices such that\nboth rows s, t are equivalent and columns s, t are equivalent. Indeed, if s, t is such a pair then it is\neasy to see that M is permuted a-Monge if and only if M [J \\ {s}] is permuted a-Monge, so we can\ndelete row s and column s and continue.\nFirst note that if there exists a pair i, j such that i 6= j and \u2206(i, j) < 0, then M [{i, j}] is a bad\nmatrix, so we assume further on that \u2206(i, j) \u2265 0 for all distinct i, j.\nAssume that \u2206(i, j) = 0 for all i, j. Suppose that there exists a triple i, j, k such that\n\u2206(k, j, i, k) 6= 0 and\/or \u2206(i, k, k, j) 6= 0. Then, as shown in the example above, M [{i, j, k}] is\na bad matrix in this case. Suppose instead that \u2206(k, j, i, k) = 0 and \u2206(i, k, k, j) = 0 for all i, k, j.\nFor any s, t, k, l with s, t < k, l, we have \u2206(s, t, k, l) = \u2206(s, t, t, l) \u2212 \u2206(s, t, t, k), and therefore\n\u2206(s, t, k, l) = 0. For any s, t, k, l with s, t > k, l, we have \u2206(s, t, k, l) = \u2206(s, t, k, s) \u2212 \u2206(s, t, l, s),\nand therefore \u2206(s, t, k, l) = 0. It can be shown in a similar way that \u2206(s, t, k, l) = 0 for all s, t, k, l,\nand therefore M is a sum matrix, which is impossible because M is not permuted a-Monge.\nAssume now that maxk,l\u2206(k, l) > 0. We will try to construct an a-Monge permutation for\nM , and show that such an effort unavoidably results in the identification of a bad submatrix\nin M . If M were a permuted a-Monge matrix, then there would exist indices i?, j? and an (a-\nMonge) permutation pi with pi(i?) = 0 and pi(j?) = n \u2212 1 such that \u2206(i?, j?) = maxk,l\u2206(k, l)\n(see equation (1)), and also \u2206(i?, j?, j, j + 1, pi) \u2265 0 and \u2206(j, j + 1, i?, j?, pi) \u2265 0 for all j =\n0, 1, . . . , n \u2212 2. To simplify the presentation, we assume that i? = 0 and j? = n \u2212 1 (otherwise,\nwe renumber the rows and columns in the matrix). The above inequalities can be rewritten as\nM(0, pi(j))\u2212M(n\u22121, pi(j)) \u2265M(0, pi(j+1))\u2212M(n\u22121, pi(j+1)) andM(pi(j), 0)\u2212M(pi(j), n\u22121) \u2265\nM(pi(j + 1), 0)\u2212M(pi(j + 1), n\u2212 1) for j = 0, 1, . . . , n\u2212 2.\nSo, an a-Monge permutation pi would have to sort the differences (M(0, i)\u2212M(n\u22121, i)) and the\ndifferences (M(i, 0)\u2212M(i, n\u22121)), i 6= 0, n\u22121 in non-increasing order. If there exists no permutation\nthat sorts both sequences, then there is a pair i, j such thatM(0, i)\u2212M(n\u22121, i) < M(0, j)\u2212M(n\u2212\n14\n1, j) (which yields the precedence constraint i \u227a j) andM(i, 0)\u2212M(i, n\u22121) > M(j, 0)\u2212M(j, n\u22121)\n(which yields the precedence constraint j \u227a i). This implies that matrix M [{0, n\u2212 1, i, j}] is a bad\nmatrix.\nSuppose now that \u2206(0, n\u2212 1) = maxk,l\u2206(k, l) and there exists a permutation pi, with pi(0) = 0\nand pi(n\u22121) = n\u22121, that sorts both sequences. Fix such a permutation and permuteM according\nto it. We can without loss of generality assume thatM had this new form from the very beginning,\nthat is, both the sequence (M(0, i)\u2212M(n\u22121, i)) and the sequence (M(i, 0)\u2212M(i, n\u22121)), i 6= 0, n\u22121,\nare already in non-increasing order.\nSince M is not permuted a-Monge, we still have indices p, q, s, t such that p < q, s < t, and\n\u2206(p, q, s, t) < 0. It follows from the inequality \u2206(p, q, s, t) < 0 and from the equation (1) that\nthere exists an index i with p \u2264 i \u2264 q \u2212 1, and an index k with s \u2264 k \u2264 t \u2212 1, such that\n\u2206(i, i + 1, k, k + 1) < 0. We consider the case i < k: the case i = k is already eliminated and the\ncase i > k is symmetric.\nAssume that there exist indices i and k with i + 1 < k such that \u2206(i, i + 1, k, k + 1) < 0,\n\u2206(i, i+ 1, i+ 1, k) > 0, and \u2206(i+ 1, k, k, k + 1) > 0. We claim that M [{i, i+ 1, k, k + 1}] is a bad\nmatrix in this case. Indeed, the assumption i \u227a i+1 yields i+1 \u227a k and k+1 \u227a k, and constraint\nk + 1 \u227a k for the columns k and k + 1 yields k \u227a i+ 1. This proves the claim.\nAssume now that there is no pair of indices i, k with i+1 < k such that \u2206(i, i+1, k, k+1) < 0,\n\u2206(i, i+1, i+1, k) > 0, and \u2206(i+1, k, k, k+1) > 0. We claim that then there exists a triple of indices\ni, j, l with i < j < l such that \u2206(i, j, j, l) < 0. Indeed, we know that we have a pair of indices i, k\nwith i < k such that \u2206(i, i+1, k, k+1) < 0. If i+1 = k, then our claim trivially holds with j = k\nand l = k+1. Otherwise, we have i+1 < k with \u2206(i, i+1, i+1, k) \u2264 0 or \u2206(i+1, k, k, k+1) \u2264 0 (or\nboth). If \u2206(i, i+1, i+1, k) \u2264 0 then \u2206(i, i+1, i+1, k+1) = \u2206(i, i+1, i+1, k)+\u2206(i, i+1, k, k+1) < 0,\nso we can take j = i+ 1 and l = k + 1 in our claim. The situation when \u2206(i+ 1, k, k, k + 1) \u2264 0 is\ntreated similarly.\nWe consider two cases:\nCase 1 There exists a triple i < j < l with \u2206(i, j, j, l) < 0 such that i = 0 or l = n \u2212 1, or\nboth.\nWe consider the case with \u2206(0, j, j, l) < 0 (the case of \u2206(i, j, j, n\u2212 1) < 0 is symmetric). We\nclaim that matrix M [{0, j, l, n \u2212 1}] is a bad matrix in this case. Indeed, rows and columns\nin the matrix are sorted to guarantee, in particular, the inequalities \u2206(0, n \u2212 1, j, l) \u2265 0\nand \u2206(0, j, 0, n \u2212 1) \u2265 0. It follows from the assumption \u2206(0, j, j, l) < 0 and the equality\n\u2206(0, n \u2212 1, j, l) = \u2206(0, j, j, l) + \u2206(j, n \u2212 1, j, l) that \u2206(j, n \u2212 1, j, l) > 0. So, the assumption\n0 \u227a j yields l \u227a j, and l \u227a j yields n\u22121 \u227a j. We will show that then we have a contradiction\nwith the choice of 0 and n\u2212 1 as a pair such that \u2206(0, n\u2212 1) = maxk,l\u2206(k, l).\nIf l = n \u2212 1 then there are two permutations of {0, j, n \u2212 1} compatible with the obtained\nprecedence constraints: \u30080, n\u2212 1, j\u3009 and \u3008n\u2212 1, 0, j\u3009. If \u30080, n\u2212 1, j\u3009 is an a-Monge permuta-\ntion for M [{0, j, n \u2212 1}] then \u2206(0, j) can be represented as a sum of non-negative numbers\n(see equality (1)) which include, in particular, \u2206(0, n \u2212 1) and \u2206(n \u2212 1, j) > 0. This is\na contradiction with the choice of 0 and n \u2212 1. If \u3008n \u2212 1, 0, j\u3009 is an a-Monge permuta-\ntion for M [{0, j, n \u2212 1}] then we get a contradiction in a similar way, using the fact that\n\u2206(0, j) = \u2206(0, j, 0, n\u2212 1)\u2212\u2206(0, j, j, n\u2212 1) > 0.\nAssume now l 6= n\u2212 1. This means that \u2206(0, j, j, n\u2212 1) \u2265 0. Moreover, since \u2206(0, j, j, l) < 0\nand \u2206(0, j, j, n \u2212 1) = \u2206(0, j, j, l) + \u2206(0, j, l, n \u2212 1), we also have \u2206(0, j, l, n \u2212 1) > 0. In\naddition to the previously stated precedence constraints 0 \u227a j, l \u227a j, and n\u2212 1 \u227a j, the last\ninequality implies a new constraint l \u227a n \u2212 1. So we have three possible permutations for\n15\npermuting the submatrixM [{0, j, l, n\u22121}] to an a-Monge matrix: \u30080, l, n\u22121, j\u3009, \u3008l, 0, n\u22121, j\u3009,\nand \u3008l, n\u2212 1, 0, j\u3009.\nAssume that \u30080, l, n\u2212 1, j\u3009 is an a-Monge permutation. Then, by equation (1), we have\n\u2206(0, j) = \u2206(0, n\u2212 1) + \u2206(n\u2212 1, j, l, j) + \u2206(n\u2212 1, j, 0, l) + \u2206(0, n\u2212 1, n\u2212 1, j).\nSince the permutation is a-Monge, all numbers in the right-hand side of the above equality\nare non-negative. Moreover, we have \u2206(n\u2212 1, j, l, j) = \u2206(j, n\u2212 1, j, l) > 0. This implies that\n\u2206(0, j) > \u2206(0, n\u2212 1), which is a contradiction with the choice of 0 and n\u2212 1.\nSimilarly, if \u3008l, 0, n\u22121, j\u3009 is an a-Monge permutation, then there is a representation of \u2206(l, j)\nas a sum of non-negative numbers which again include \u2206(0, n \u2212 1) and \u2206(n \u2212 1, j, l, j) > 0.\nIf \u3008l, n \u2212 1, 0, j\u3009 is an a-Monge permutation, then there is a representation of \u2206(l, j) which\ncontains \u2206(0, n\u2212 1) and \u2206(0, j, l, n\u2212 1) > 0.\nCase 2 For any triple i, j, l, i < j < l, with \u2206(i, j, j, l) < 0, neither i = 0 nor l = n\u2212 1.\nIt is easy to see that this condition implies the following inequalities:\n\u2206(0, i, j, l) > 0 because, otherwise, \u2206(0, j, j, l) = \u2206(0, i, j, l) + \u2206(i, j, j, l) < 0;\n\u2206(i, j, l, n\u22121) > 0 because, otherwise, \u2206(i, j, j, n\u22121) = \u2206(i, j, j, l)+\u2206(i, j, l, n\u22121) < 0;\n\u2206(j, l, l, n\u2212 1) \u2265 0;\n\u2206(0, i, i, j) \u2265 0.\nWe claim that, given the above inequalities, at least one ofM [{0, i, j, l}] andM [{i, j, l, n\u22121}]\nis a bad matrix.\nWe show first that if \u2206(j, l) = 0, then M [{0, i, j, l}] is the bad matrix. Indeed, when trying\nto find an a-Monge permutation for this matrix, the assumption 0 \u227a i yields j \u227a l (since\n\u2206(0, i, j, l) > 0) and i \u227a l (since \u2206(0, i, i, l) = \u2206(0, i, i, j) + \u2206(0, i, j, l) > 0). The constraint\nj \u227a l for the columns yields the constraint j \u227a i, and, since \u2206(i, l, j, l) = \u2206(i, j, j, l)+\u2206(j, l) =\n\u2206(i, j, j, l) < 0, it also yields l \u227a i. The contradictory precedence constraints {l \u227a i, i \u227a l}\nprove that M [{0, i, j, l}] is a bad matrix. So, we assume now that \u2206(j, l) > 0 (the case\n\u2206(j, l) < 0 is already eliminated).\nBy using a similar argument for the matrix M [{i, j, l, n\u2212 1}], we see that that if \u2206(i, j) = 0\nthen this matrix is bad. So we will also assume that \u2206(i, j) > 0.\nWe now consider the submatrix M [{0, i, j, l}] and will try to permute it into an a-Monge\nmatrix. The assumption 0 \u227a i yields j \u227a l, i \u227a l, j \u227a i. Since \u2206(i, j) > 0, and so\n\u2206(0, j, i, j) = \u2206(0, i, i, j)+\u2206(i, j, i, j) > 0, we also have j \u227a 0. This shows that a permutation\nother than \u3008j, 0, i, l\u3009 cannot be an a-Monge permutation for M [{0, i, j, l}]. By analyzing the\nmatrixM [{i, j, l, n\u22121}] in a similar way, we see that the only potential a-Monge permutation\nfor it is the permutation \u3008i, l, n\u2212 1, j\u3009.\nIf \u3008j, 0, i, l\u3009 is an a-Monge permutation for M [{0, i, j, l}] then we must have \u2206(0, i, j, 0) \u2265\n0. Since \u2206(0, i, i, j) \u2265 0 by the assumption of Case 2, and also \u2206(0, i) \u2265 0, we have\n\u2206(0, i, 0, j) = \u2206(0, i, 0, i) + \u2206(0, i, i, j) \u2265 0. However, \u2206(0, i, 0, j) = \u2212\u2206(0, i, j, 0), which\nimplies that \u2206(0, i) = 0 and \u2206(0, i, i, j) = 0.\nMoreover, if \u3008j, 0, i, l\u3009 is an a-Monge permutation for M [{0, i, j, l}] then \u2206(j, i, i, l) \u2265 0. Sim-\nilarly, if \u3008i, l, n \u2212 1, j\u3009 is an a-Monge permutation for M [{i, j, l, n \u2212 1}] then \u2206(i, j, i, l) \u2265 0.\nBut \u2206(j, i, i, l) = \u2212\u2206(i, j, i, l), so both are equal to 0.\n16\nIf \u3008j, 0, i, l\u3009 is an a-Monge permutation for M [{0, i, j, l}] then we must have \u2206(j, 0, i, l) \u2265 0.\nWe can express \u2206(j, 0, i, l) as \u2206(j, 0, i, l) = \u2212\u2206(0, j, i, l) = \u2212(\u2206(0, i, i, j) + \u2206(0, i, j, l) +\n\u2206(i, j) + \u2206(i, j, j, l)). Since \u2206(0, i, i, j) = 0 and \u2206(i, j) + \u2206(i, j, j, l) = \u2206(i, j, i, l) = 0, we\nget \u2206(0, i, j, l) = \u2212\u2206(j, 0, i, l) \u2264 0. However, the inequality \u2206(0, i, j, l) > 0 is one of the\nfour inequalities (see above) directly implied by the assumption of Case 2. Hence, we get a\ncontradiction which proves that at least one of the matricesM [{0, i, j, l}] andM [{i, j, l, n\u22121}]\nis a bad matrix.\nThis completes the proof of the theorem. 2\nNote that the bound |B| \u2264 4 in the above theorem is tight. Indeed, it can be straightforwardly\nchecked that the following matrix is not permuted a-Monge, while any matrix obtained from it by\ndeleting a row and a column (with the same index) is permuted a-Monge.\uf8eb\uf8ec\uf8ec\uf8ed\n1 1 0 1\n1 1 0 0\n0 0 0 0\n1 0 0 1\n\uf8f6\uf8f7\uf8f7\uf8f8\nWe can now generalize Theorem 5.3 to the case of several matrices.\nCorollary 5.4 Let M1, . . . ,Mm be n \u00d7 n matrices. If there exists no permutation that simulta-\nneously permutes all these matrices into a-Monge matrices, then there exists a subset of indices\nB with |B| \u2264 4, such that no permutation of the indices in B simultaneously permutes matrices\nM1[B], . . . ,Mm[B] into a-Monge matrices.\nProof: Consider the matrix M =\n\u2211m\ni=1Mi. If M is not a permuted a-Monge matrix then, by\nTheorem 5.3, there exists a subset of indices B with |B| \u2264 4, such that M [B] is a bad matrix.\nConsider matrices M1[B], . . . ,Mm[B]. If there existed a permutation that permutes all these ma-\ntrices into a-Monge matrices, then the sum of the permuted matrices, which is M [B], would be a\npermuted a-Monge matrix as well. This contradiction proves that there exists no permutation that\nsimultaneously permutes matrices M1[B], . . . ,Mm[B] into a-Monge matrices.\nAssume now that M is a permuted a-Monge matrix. The corresponding a-Monge permutation\ndoes not permute all of M1, . . . ,Mm into a-Monge matrices. Hence, there exist indices i, j, k, l and\na pair of matrices, say, M1 and M2 such that M1(i, k) +M1(j, l) \u2212M1(i, l) \u2212M1(j, k) > 0 and\nM2(i, k) +M2(j, l) \u2212M2(i, l) \u2212M2(j, k) < 0. This implies that the matrices M1[{i, j, k, l}] and\nM2[{i, j, k, l}] cannot be simultaneously permuted into a-Monge matrices \u2013 this follows from the\nfact that the assumption i \u227a j implies k \u227a l for M1 and l \u227a k for M2. 2\n5.2 Reducing the number of matrices\nWe will now prove the bound |F \u2032| \u2264 3 in Theorem 5.1, again via a-Monge matrices. In the proof,\nwe will use special partial orders which we call multipartite partial orders.\nWe say that a partial order \u00b9 on a set D is multipartite if and only if there is a partition of\nD = D1 \u222a . . . \u222a Dt, t \u2265 2, such that d \u00b9 d\u2032 if and only if d = d\u2032 or else d \u2208 Di and d\u2032 \u2208 Dj\nfor some 1 \u2264 i < j \u2264 t. If P is a multipartite order, then we will call the classes D1, . . . , Dt the\ncorresponding partition classes of P .\nIt is clear that if pi is an a-Monge permutation for a matrix M then the reverse permutation\npi\u2212 is also an a-Monge permutation for M . It is also clear that if M is an a-Monge matrix with at\n17\nleast three rows, and the matrix obtained from M by simultaneously swapping rows s and t and\ncolumns s and t is again a-Monge then rows s and t are equivalent, i.e., M(s, i) = M(t, i) + \u03b1st,\nand columns s and t are equivalent as well. Note that swapping of equivalent rows and columns\ndoes not affect the property of being a-Monge. A matrix M is called Monge if \u2212M is a-Monge. It\nis shown in Observation 3.6 of [37] that ifM is Monge, i \u227a j \u227a k in M , and rows (columns) i, k are\nequivalent in M then row j is equivalent to these rows (columns). Clearly, the statement is also\ntrue for a-Monge matrices. Theorem 3.9 of [37] states that if a Monge matrix has no equivalent\nrows or columns then the only way to permute it to a Monge matrix is by using either the identity\npermutation id or its reverse id\u2212.\nThis leads to the following characterization of a-Monge permutations in terms of multipartite\norders. For every anti-Monge square matrixM , there exist two mutually reverse multipartite orders\nsuch that a permutation (i.e. ordering) of the indices of M is an a-Monge permutation if and only\nif this ordering is an extension of one of the two multipartite orders. Two indices i, j belong to the\nsame partition class of such a multipartite order if and only if both rows i, j and columns i, j are\nequivalent in M .\nWe will now prove two auxiliary lemmas about multipartite orders.\nLemma 5.5 For any two multipartite orders P \u2032 and P \u2032\u2032 on D, there are a, b \u2208 D such that a and\nb are comparable (not necessarily in the same direction) both in P \u2032 and in P \u2032\u2032.\nProof: Take a maximal chain in P \u2032. If it is not entirely contained in a class of P \u2032\u2032 then there\nare two elements in this chain belonging to two different classes of P \u2032\u2032, that is, these elements are\ncomparable both in P \u2032\u2032 and in P \u2032. If all elements in the maximal chain are contained in the same\nclass of P \u2032\u2032, then pick any element d in a different class of P \u2032\u2032. This element is comparable, in P \u2032\u2032,\nwith all elements from the chain, and, clearly, it is comparable with at least one of these elements\nin P \u2032. 2\nLet us say that a collection P = {P1, . . . , Pl} of multipartite orders is conflicting if their union\n(considered as a digraph GP) contains a directed cycle.\nLemma 5.6 If a collection P = {P1, . . . , Pl} is conflicting then the digraph GP contains arcs (a, b)\nand (b, a) for some distinct a, b.\nProof: Let a1, . . . , at, a1 be a shortest directed cycle in GP , and assume, for contradiction, that\nt > 2. Without loss of generality, let (a1, a2) \u2208 P1. In this case, (a2, a3) 6\u2208 P1, since, otherwise,\nwe would have (a1, a3) \u2208 P1 and get a shorter cycle. Without loss of generality, assume that\n(a2, a3) \u2208 P2. Since the order P1 is multipartite, we conclude that a1 and a3 are comparable in\nP1. Furthermore, since we cannot have (a1, a3) \u2208 P1, we have (a3, a1) \u2208 P1. Since (a1, a2) \u2208 P1,\nthe transitivity of P1 implies that (a3, a2) \u2208 P1, which, together with (a2, a3) \u2208 P2, gives us the\nrequired arcs. 2\nProposition 5.7 Let U = {M1, . . . ,Mm} be a set of matrices of size n\u00d7n such that no permutation\nis an a-Monge permutation for all matrices in U . Then, there is a subset U \u2032 \u2286 U such that |U \u2032| \u2264 3\nand no permutation is an a-Monge permutation for all matrices in U \u2032.\nProof: We may assume that every matrix in U is a permuted a-Monge matrix, since, otherwise,\nthe result follows immediately. Start with matrix M1 \u2208 U and choose any of the two multipartite\norders that describe the set of corresponding a-Monge permutations forM1. Call this order P1. By\n18\nLemma 5.5, there is a pair (a, b) \u2208 P1 such that a 6= b and a and b are comparable in P2, where\nP2 is the multipartite order for M2. We may assume that (a, b) \u2208 P2, since, otherwise, the other\nmultipartite order for P2 would be chosen.\nIf there is a pair of distinct elements (c, d) such that (c, d) \u2208 P1 and (d, c) \u2208 P2, then there exists\nno a-Monge permutation for M1 and M2 and the proposition is proved. So we may assume that\n{P1, P2} is not conflicting. Since P1 shares a pair of comparable elements with any multipartite\norder, we can in the same way choose a multipartite order Pi for each matrixMi. If, for some i, the\npair {P1, Pi} is conflicting, then the proposition is proved. So assume that all such pairs of orders\nare non-conflicting. Note that if we chose the other multipartite order for M1, this would have led\nto choosing the other multipartite orders for all M1, . . . ,Mm.\nSince there is no common a-Monge permutation for all of M1, . . . ,Mm, we know that the col-\nlection {P1, . . . , Pm} of orders that we have constructed is conflicting. By Lemma 5.6, there are\norders Pi and Pj such that, for some distinct e, f , we have (e, f) \u2208 Pi and (f, e) \u2208 Pj . Since both\nPi and Pj share with P1 some pairs of elements comparable in the same direction, we conclude that\nthere is no common a-Monge permutation for M1,Mi,Mj . This completes the proof. 2\nNote that the bound |U \u2032| \u2264 3 in the above proposition is tight. Indeed, each of the following three\nmatrices is permuted a-Monge, every two of them have a common a-Monge permutation, but there\nis no common a-Monge permutation for all three of them.\uf8eb\uf8ed 1 0 00 0 0\n0 0 0\n\uf8f6\uf8f8 \uf8eb\uf8ed 0 0 00 1 0\n0 0 0\n\uf8f6\uf8f8 \uf8eb\uf8ed 0 0 00 0 0\n0 0 1\n\uf8f6\uf8f8\n6 Main result\nWe will need the following two technical lemmas. They will be used in our hardness proof to\nreduce the argument to the case when all non-unary predicates are binary and their matrices do\nnot contain all-ones rows or columns.\nLemma 6.1 If F is not supermodular on any chain on D then F \u222a UD can strictly implement a\ncollection F \u2032 of binary predicates which is is not supermodular on any chain on D.\nProof: Let f \u2208 F be not supermodular on some fixed chain. By Observation 4.3(2), f is n-ary with\nn \u2265 2. By Lemma 4.5, it is possible to substitute constants for some n\u2212 2 variables of f to obtain\na binary predicate f \u2032 which is not supermodular on this chain. Assume without loss of generality\nthat these variables are the last n \u2212 2 variables, and the corresponding constants are d3, . . . , dn,\nthat is, f \u2032(x, y) = f(x, y, d3, . . . , dn). Then the following is a strict (n\u2212 1)-implementation of f \u2032:\nf \u2032(x, y) + (n\u2212 2) = max\nz3,...,zn\n[f(x, y, z3, . . . , zn) + u{d3}(z3) + . . .+ u{dn}(zn)].\nRepeating this for all chains on D, one can strictly implement a collection F \u2032 of binary predicates\nthat is not supermodular on any chain. 2\nLemma 6.2 [Lemma 3.3 [28]] Assume that h \u2208 R(2)D and there is a \u2208 D such that h(x, a) = 1 for\nall x \u2208 D. Let h\u2032(x, y) = 0 if y = a and h\u2032(x, y) = h(x, y) if y 6= a. Then the following holds:\n1. for any chain on D, h and h\u2032 are supermodular (or not supermodular) on the chain simulta-\nneously;\n19\n2. the problemsMax CSP({h} \u222a UD) andMax CSP({h\u2032} \u222a UD) are AP -reducible to each other.\nRecall that all predicates from CD are supermodular on any chain on D. Moreover, it is shown\nin (the proof of) Lemma 5.1 of [11] that all predicates from CD are supermodular on a lattice if\nand only if the lattice is a chain.\nWe will now prove our main result:\nTheorem 6.3 If F is supermodular on some chain on D then weightedMax CSP(F \u222a CD) belongs\nto PO. Otherwise, Max CSP(F \u222a CD)\u2212B is APX-complete.\nProof: The tractability part of the proof follows immediately from Theorem 4.10 (see also\nObservation 4.3(1)). By Lemmas 3.2 and 3.4, it is sufficient to prove the hardness part for sets of\nthe form F \u222a UD. We will show that {neq2} can be obtained from F \u222a UD by using the following\ntwo operations:\n1. replacing F \u222a UD by a subset of F \u222a UD \u222a {f} where f is a predicate that can be strictly\nimplemented from F \u222a UD;\n2. replacing F \u222a UD by a subset of F|D\u2032 \u222a UD\u2032 for some D\u2032.\nBy Example 2.5 and Lemmas 3.4 and 3.5, this will establish the result.\nIt follows from Lemmas 6.1 and 3.4 that it is sufficient to prove the hardness part of Theorem 6.3\nassuming that F contains only binary predicates. Now, Theorem 5.1 and Lemma 3.5 imply that, in\naddition, we can assume that |F| \u2264 3 and |D| \u2264 4. Note that the case |D| \u2264 3 is already considered\nin Corollary 4.9 (see also Remark 4.8), so it remains to consider the case |D| = 4; we can without\nloss of generality assume in the rest of the proof that D = {0, 1, 2, 3}. Moreover, due to Lemma 3.5,\nwe may consider only sets F satisfying the following condition:\nfor any proper subset D\u2032 \u2282 D, F|D\u2032 is supermodular on some chain on D\u2032. (\u2217)\nWe can assume that F is minimal with respect to inclusion, that is, every proper non-empty\nsubset of F is supermodular on some chain on D. We will consider three cases depending on the\nnumber of predicates in F . Note that, by Lemma 6.2, we can without loss of generality assume\nthat none of the predicates in F has a matrix containing an all-ones row or column (this property\ndoes not depend on the order of indices in the matrix).\nWe prove the result by using a simple computer-generated enumeration in each of the three\ncases. In each case, we first produce a list of all possible sets F with the above restrictions, then\nreduce the list by using some obvious symmetries (such as isomorphism and anti-isomorphism),\nand, finally, for each remaining set F , provide a strict implementation of a set F \u2032 that is known to\nhave an APX-hardMax CSP(F \u2032) problem. To compactly describe such symmetries, we introduce\nsome notation. Let pi be a permutation on D and f a binary predicate on D. Then, we define pi(f)\nto be the predicate such that pi(f)(a, b) = 1 if and only if f(pi(a), pi(b)) = 1 for all a, b \u2208 D; we say\nthat the predicate pi(f) is isomorphic to f . We also define the predicate f t so that f t(a, b) = 1 if\nand only if f(b, a) = 1 for all a, b \u2208 D (this corresponds to transposing the matrix of f). We say\nthat a predicate of the form pi(f t) is anti-isomorphic to f .\nCase 1. |F| = 1.\nFirst, we use exhaustive search to generate the list of all binary predicates f on D that (a) do\nnot have all-ones rows or columns, (b) are not supermodular on any chain on D, and (c) F = {f}\n20\nsatisfies condition (\u2217). Moreover, we may consider predicates only up to isomorphism and anti-\nisomorphism. Thus, this list is then processed as follows: for every predicate f in the list, in order,\nremove all predicates below f in the list that are isomorphic or anti-isomorphic to f .\nClearly, it is sufficient to prove the hardness result for all predicates that remain in the optimized\nlist. Since there are only 216 = 65536 predicates to check, it is clear that generating and optimizing\nthe list can easily be (and actually was) performed by a computer. The optimized list contains\nonly 27 predicates which are given in Fig. 3.\nh\u20321\n1000\n0110\n1000\n0000\nh\u20322\n1000\n1101\n1000\n0000\nh\u20323\n1001\n0111\n1110\n1001\nh\u20324\n1010\n0101\n1010\n1000\nh\u20325\n1010\n0110\n0000\n0000\nh\u20326\n1010\n0111\n1010\n1000\nh\u20327\n1010\n0111\n1110\n1000\nh\u20328\n1011\n0101\n1010\n0000\nh\u20329\n1011\n0111\n0010\n0000\nh\u203210\n1011\n0111\n0010\n0001\nh\u203211\n1011\n0111\n0011\n0000\nh\u203212\n1011\n0111\n0110\n1001\nh\u203213\n1011\n0111\n1010\n0000\nh\u203214\n1011\n0111\n1010\n0001\nh\u203215\n1011\n0111\n1110\n0000\nh\u203216\n1011\n0111\n1110\n0001\nh\u203217\n1011\n0111\n1110\n1001\nh\u203218\n1011\n0111\n1110\n1101\nh\u203219\n1011\n1101\n1010\n0000\nh\u203220\n1100\n1101\n1000\n0000\nh\u203221\n1101\n0110\n0110\n1001\nh\u203222\n1101\n1100\n0010\n0000\nh\u203223\n1101\n1110\n0000\n0000\nh\u203224\n1101\n1110\n0110\n1001\nh\u203225\n1110\n1100\n0000\n0000\nh\u203226\n1110\n1100\n1010\n0000\nh\u203227\n1110\n1101\n1010\n0000\nFigure 3: The optimized list of 27 predicates from the proof of Case 1. The predicates are repre-\nsented by tables of values.\nWe show, starting from h\u20321 and proceeding in order, that {h\u2032i} \u222a UD strictly implements some\nbinary predicate g such that either, for some D\u2032 \u2282 D, the predicate g|D\u2032 is not supermodular on\nany chain on D\u2032 or g is equal to h\u2032j for some j < i (up to isomorphism and anti-isomorphism).\nThese implementations can be found in Appendix A. This, together with Remark 4.8, implies that\nneq2 can be obtained from F \u222a UD.\nCase 2. |F| = 2.\nLet F = {f1, f2}. As in Case 1, we use exhaustive search to generate the list of all pairs of binary\npredicates on D such that (a) they do not have all-ones rows or columns, (b) each of the two\npredicates is supermodular on at least one chain, but there is no chain on which they are both\nsupermodular, and (c) F satisfies condition (\u2217). Without loss of generality, we can assume that f1\nis supermodular on the chain 0 < 1 < 2 < 3, that is, the matrix of f1 with this order of indices is\na-Monge. Since the matrix of f1 does not have all-ones row or column, its structure is described in\nLemma 4.4. Similarly, the matrix of f2 is a permuted a-Monge matrix, since pi(f2) is supermodular\nfor some permutation pi.\nWe can also assume that the a-Monge matrices for f1 and f2 (with respect to the orders on\nwhich the predicates are supermodular) have the third form (Lpq4 + R\nst\n4 ) from Lemma 4.4. The\nreason is that if, say, the matrix of f1 has the form L\npq\n4 for some 0 \u2264 p, q \u2264 2 then f \u20321(x, y) + 1 =\nf1(x, y)+u{p+1,...,3}(x)+u{q+1,...,3}(y) is a strict 2-implementation of the predicate f \u2032 whose matrix\nis R(p+1)(q+1)4 . Moreover, f\n\u2032\u2032\n1 (x, y) = f1(x, y) + f\n\u2032\n1(x, y) is a strict 1-implementation of a predicate\nwhose matrix is Lpq4 + R\n(p+1)(q+1)\n4 . Hence, we can replace f1 by f\n\u2032\u2032\n1 in this pair, and show the\nhardness result for {f \u2032\u20321 , f2}.\nIt is clear that if we prove the result for all pairs (f1, f2) with some fixed f1, then this also\nproves the result for all pairs with the first component f t1, or pi(f1), or pi(f\nt\n1) where pi(x) = 3 \u2212 x.\nThis implies that it is sufficient to consider only predicates from Fig. 1 as possible candidates for\nf1. Moreover, it can be straightforwardly checked by using a computer that if f1 is one of the\npredicates h1, h3, h4, h6, h7, h9, h10 from Fig. 1, then F = {f1, f2} fails to satisfy condition (\u2217).\n21\nHence, all pairs (f1, f2), where at least one of f1 and pi(f2) (for some permutation pi) coincides with\none of 7 predicates above, will not be on the list of pairs that we need to consider.\nObviously, if we prove the result for some pair (f1, f2) then this also proves the result for (f1, f t2).\nHence, provided f2 6= f t2, one of these two pairs can be excluded from the list.\nNow we show that predicates h5, h11, h12, and h17 from Fig. 1 can also be excluded from con-\nsideration because they can strictly implement some other predicates from Fig. 1. Implementations:{\nf :=\n1100\n1101\n1101\n0001\n}\n\u222a UD s=\u21d26\n1100\n0001\n0001\n0001\n=: g f = h17, g = pi(h8) where pi(x) = 3\u2212 x\ng(x, y) + 5 = maxz,w[f(z, w) + f(z, y) + f(x, z) + f(x,w) + u{0,3}(z) + u{3}(w) + u{0}(x)]{\nf :=\n1110\n1110\n0001\n0001\n}\n\u222a UD s=\u21d23\n1110\n1110\n0000\n0001\n=: g f = h11, g = h5\ng(x, y) + 2 = maxz[f(z, x) + f(z, y) + f(x, z)]{\nf :=\n1110\n1110\n0000\n0001\n}\n\u222a UD s=\u21d22\n1100\n1100\n1101\n0001\n=: g f = h5, g = h16\ng(x, y) + 1 = maxz[f(x, z) + f(y, z) + u{2}(x)]{\nf :=\n1110\n0001\n0001\n0001\n}\n\u222a UD s=\u21d24\n1000\n1001\n1001\n0001\n=: g f = h12, g = h15\ng(x, y) + 3 = maxz[f(z, x) + f(z, y) + f(x, z) + f(y, z) + u{1}(z) + u{1,2}(x)]\nAs above, all pairs (f1, f2) such that, for some permutation pi, pi(f2) or pi(f t2) is one of h5, h11, h12, h17,\ncan also be excluded from the list.\nFinally, we can exclude from the list all pairs isomorphic to some pair higher up in the list.\nThat is, we exclude pair (f1, f2) if there is a permutation pi such that either pi(f1) = f1 and the pair\n(f1, pi(f2)) is above (f1, f2) in the list or if there is a permutation pi such that the pair (pi(f2), pi(f1))\nis above (f1, f2) in the list (in the latter case, pi(f2) must be supermodular on 0 < 1 < 2 < 3).\nThe optimized list now contains 27 pairs of predicates. In Appendix B, we provide strict\nimplementations for them that show that, for each pair (f1, f2) in this list, {f1, f2}\u222aUD implements\neither a pair above it in the list or else a binary predicate g such that, for someD\u2032 \u2282 D, the predicate\ng|D\u2032 is not supermodular on any chain on D\u2032. As in Case 1, it follows that neq2 can be obtained\nfrom F \u222a UD.\nCase 3. |F| = 3.\nIt can be checked by computer-assisted exhaustive search that there does not exist such a set F .\nSimply loop through all triples of (not necessarily distinct) binary predicates on {0, 1, 2} which are\nsupermodular on the chain 0 < 1 < 2 and check that each possible extension to a triple of pairwise\ndistinct predicates on D results in a set F satisfying one of the following conditions:\n1. F is supermodular on some chain on D,\n2. for some D\u2032 \u2282 D, F|D\u2032 is not supermodular on any chain on D\u2032,\n3. some proper subset of F is not supermodular on any chain on D.\n2\n22\nRemark 6.4 There are two main ways to represent a predicate: by its complete table of values\nand by the set of tuples which satisfy the predicate. By using Lemma 4.5 and Corollary 5.4, it is\nnot hard to show that if the former representation is used or if D is fixed, then it can be checked in\npolynomial time whether a given (finite) F is supermodular on some chain on D. However, if D\nis not fixed and the latter representation is used then it is an open question whether there exists a\npolynomial-time algorithm for checking supermodularity of F on some chain on D.\n7 Application to List H-colouring optimization\nRecall that a homomorphism from a digraph G = (VG, AG) to a digraphH = (VH , AH) is a mapping\n\u03d5 : VG \u2192 VH such that (\u03d5(v), \u03d5(w)) \u2208 AH whenever (v, w) \u2208 AG. In this case, the digraph G is\nsaid to be H-colourable. The Graph H-colourability problem is, given a digraph G, to decide\nwhether it is H-colourable. This problem attracts much attention in graph theory [25].\nIn this section, we consider the case when F consists of a single binary predicate h. This\npredicate specifies a digraph H such that VH = D and (u, v) is an arc in H if and only if h(u, v) = 1.\nAny instance I = (V,C) of CSP({h}) can be associated with a digraph GI whose nodes are\nthe variables in V and whose arcs are the scopes of constraints in C. It is not difficult to see\nthat the question whether all constraints in I are simultaneously satisfiable is equivalent to the\nquestion whether GI is H-colourable. Therefore, the problem CSP({h}) is precisely the Graph H-\ncolourability problem for the digraph H. The problems CSP({h} \u222a UD) and CSP({h} \u222a CD) are\nequivalent to the List H-colouring and H-retraction problems, respectively. In the former\nproblem, every vertex of an input digraph G gets a list of allowed target vertices in H, and the\nquestion is whether G has an H-colouring subject to the list constraints. The latter problem is\nthe same except that each list contains either one vertex or all vertices of H. These problems also\nattract much attention in graph theory [25].\nThe problemMax CSP({h} \u222a UD) can then be viewed as the List H-colouring optimization\nproblem: for every vertex v of an input digraph G, there is a list Lv \u2286 VH along with a function\n\u03c1v : Lv \u2192 Z+ that indicates the \u2018score\u2019 which a mapping VG \u2192 VH gets if it sends v to a certain\nvertex (if a mapping sends v to a vertex outside of Lv then this adds nothing to the \u2018cost\u2019 of\nthis mapping). Then the goal is to maximize the combined \u2018cost\u2019 of such a mapping which is\nobtained by adding weights of preserved arcs and \u2018scores\u2019 from the lists. The \u2018score\u2019 functions \u03c1v\narise as the result of the possible presence in C of several weighted constraints of the form uD\u2032(v)\nfor different D\u2032 \u2286 D and the same v. Thus, Theorem 6.3 in the case when F = {h} presents a\ncomplexity classification of list H-colouring optimization problems. Digraphs H corresponding to\nthe tractable cases of this problem are the digraphs that have an a-Monge adjacency matrix under\nsome total ordering on VH (note that this property of digraphs can be recognised in polynomial\ntime, e.g., by using Theorem 5.3). Such matrices without all-one rows or columns are described in\nLemma 4.4. It remains to note that, as is easy to see, replacing either some all-zero row or some\nall-zero columns with all-one ones does not affect the property of being a-Monge.\nWe remark that another problem related to optimizing list homomorphisms between graphs\nwas recently considered in [19], in connection with some problems arising in defence logistics.\nAcknowledgements\nThe authors are thankful to Gerhard Woeginger for encouraging this collaboration and to Johan\nH\u02daastad for suggesting to use the bounded occurrence property in our proofs. The authors would\nalso like to thank the anonymous referees for providing useful comments on the paper.\n23\nReferences\n[1] P. Alimonti and V. Kann. Some APX-completeness results for cubic graphs. Theoretical\nComputer Science, 237(1-2):123\u2013134, 2000.\n[2] G. Ausiello, P. Creszenzi, G. Gambosi, V. Kann, A. Marchetti-Spaccamela, and M. Protasi.\nComplexity and Approximation. Springer, 1999.\n[3] C. Bazgan and M. Karpinski. On the complexity of global constraint satisfaction. In ISAAC\u201905,\npages 624\u2013633, 2005.\n[4] P. Berman and M. Karpinski. Improved approximation lower bounds on small occurrence op-\ntimization. Technical Report TR03-008, Electronic Colloquium on Computational Complexity\n(ECCC), 2003.\n[5] F. Bo\u00a8rner, A. Bulatov, P. Jeavons, and A. Krokhin. Quantified constraints: Algorithms and\ncomplexity. In CSL\u201903, volume 2803 of LNCS, pages 58\u201370, 2003.\n[6] A. Bulatov. Tractable conservative constraint satisfaction problems. In LICS\u201903, pages 321\u2013\n330, 2003.\n[7] A. Bulatov. A dichotomy theorem for constraint satisfaction problems on a 3-element set.\nJournal of the ACM, 53(1):66\u2013120, 2006.\n[8] A. Bulatov and V. Dalmau. Towards a dichotomy theorem for the counting constraint satis-\nfaction problem. Information and Computation, 205(5):651\u2013678, 2007.\n[9] A. Bulatov, P. Jeavons, and A. Krokhin. Classifying complexity of constraints using finite\nalgebras. SIAM Journal on Computing, 34(3):720\u2013742, 2005.\n[10] R.E. Burkard, B. Klinz, and R. Rudolf. Perspectives of Monge properties in optimization.\nDiscrete Applied Mathematics, 70:95\u2013161, 1996.\n[11] D. Cohen, M. Cooper, P. Jeavons, and A. Krokhin. Supermodular functions and the complexity\nof Max CSP. Discrete Applied Mathematics, 149(1-3):53\u201372, 2005.\n[12] N. Creignou. A dichotomy theorem for maximum generalized satisfiability problems. Journal\nof Computer and System Sciences, 51:511\u2013522, 1995.\n[13] N. Creignou, S. Khanna, and M. Sudan. Complexity Classifications of Boolean Constraint Sat-\nisfaction Problems, volume 7 of SIAM Monographs on Discrete Mathematics and Applications.\n2001.\n[14] M. Datar, T. Feder, A. Gionis, R. Motwani, and R. Panigrahy. A combinatorial algorithm for\nMAX CSP. Information Processing Letters, 85(6):307\u2013315, 2003.\n[15] V.G. Deineko, R. Rudolf, and G.J. Woeginger. A general approach to avoiding 2\u00d7 2 subma-\ntrices. Computing, 52:371\u2013388, 1994.\n[16] L. Engebretsen. The non-approximability of non-Boolean predicates. SIAM Journal on Dis-\ncrete Mathematics, 18(1):114\u2013129, 2004.\n24\n[17] T. Feder and M.Y. Vardi. The computational structure of monotone monadic SNP and con-\nstraint satisfaction: A study through Datalog and group theory. SIAM Journal on Computing,\n28:57\u2013104, 1998.\n[18] S. Fujishige. Submodular Functions and Optimization, volume 58 of Annals of Discrete Math-\nematics. Elsevier, 2nd edition, 2005.\n[19] G. Gutin, A. Rafiey, A. Yeo, and M. Tso. Level of repair analysis and minimum cost homo-\nmorphisms of graphs. Discrete Applied Mathematics, 154(6):881\u2013889, 2006.\n[20] G. Hast. Beating a random assignment: Approximating constraint satisfaction problems. PhD\nthesis, Royal Institute of Technology, Stockholm, 2005.\n[21] J. H\u02daastad. On bounded occurrence constraint satisfaction. Information Processing Letters,\n74(1-2):1\u20136, 2000.\n[22] J. H\u02daastad. Some optimal inapproximability results. J. ACM, 48:798\u2013859, 2001.\n[23] J. H\u02daastad. Every 2-CSP allows nontrivial approximation. In Proceedings of STOC\u201905, pages\n740\u2013746, 2005.\n[24] P. Hell. Algorithmic aspects of graph homomorphisms. In C. Wensley, editor, Surveys in\nCombinatorics 2003, volume 307 of LMS Lecture Note Series, pages 239 \u2013 276. Cambridge\nUniversity Press, 2003.\n[25] P. Hell and J. Nes\u02c7etr\u02c7il. Graphs and Homomorphisms. Oxford University Press, 2004.\n[26] S. Iwata, L. Fleischer, and S. Fujishige. A combinatorial strongly polynomial algorithm for\nminimizing submodular functions. J. ACM, 48(4):761\u2013777, 2001.\n[27] P. Jonsson. Boolean constraint satisfaction: Complexity results for optimization problems\nwith arbitrary weights. Theoretical Computer Science, 244(1-2):189\u2013203, 2000.\n[28] P. Jonsson, M. Klasson, and A. Krokhin. The approximability of three-valued Max CSP.\nSIAM Journal on Computing, 35(6):1329\u20131349, 2006.\n[29] P. Jonsson and A. Krokhin. Maximum H-colourable subdigraphs and constraint optimization\nwith arbitrary weights. Journal of Computer and System Sciences, 73(5):691\u2013702, 2007.\n[30] M. Karpinski. Approximating bounded degree instances of NP-hard problems. In Proceedings\n13th Conference on Fundamentals of Computation Theory, FCT\u201901, volume 2138 of Lecture\nNotes in Computer Science, pages 24\u201334. Springer-Verlag, 2001.\n[31] S. Khanna, M. Sudan, L. Trevisan, and D. Williamson. The approximability of constraint\nsatisfaction problems. SIAM Journal on Computing, 30(6):1863\u20131920, 2001.\n[32] S. Khot, G. Kindler, E. Mossel, and R. O\u2019Donnell. Optimal inapproximability results for\nMax-Cut and other 2-variable CSPs? SIAM Journal on Computing, 37(1):319\u2013357, 2007.\n[33] B. Klinz, R. Rudolf, and G. Woeginger. Permuting matrices to avoid forbidden submatrices.\nDiscrete Applied Mathematics, 60:223\u2013248, 1995.\n[34] A. Krokhin, A. Bulatov, and P. Jeavons. The complexity of constraint satisfaction: an algebraic\napproach. In Structural Theory of Automata, Semigroups, and Universal Algebra, volume 207\nof NATO Science Series II: Math., Phys., Chem., pages 181\u2013213. Springer Verlag, 2005.\n25\n[35] A. Krokhin and B. Larose. Maximum constraint satisfaction on diamonds. In CP\u201905, volume\n3709 of LNCS, pages 388\u2013402, 2005.\n[36] I. Pe\u2019er, T. Pupko, R. Shamir, and R. Sharan. Incomplete directed perfect phylogeny. SIAM\nJournal on Computing, 33(3):590\u2013607, 2004.\n[37] R. Rudolf. Recognition of d-dimensional Monge arrays. Discrete Applied Mathematics,\n52(1):71\u201382, 1994.\n[38] T.J. Schaefer. The complexity of satisfiability problems. In STOC\u201978, pages 216\u2013226, 1978.\n[39] A. Schrijver. A combinatorial algorithm minimizing submodular functions in polynomial time.\nJournal of Combinatorial Theory, Ser.B, 80:346\u2013355, 2000.\n[40] D. Topkis. Supermodularity and Complementarity. Princeton University Press, 1998.\n[41] R. Williams. A new algorithm for optimal 2-constraint satisfaction and its implications. The-\noretical Computer Science, 348(2-3):357\u2013365, 2005.\n26\nAppendix A: Strict implementations from Case 1\nIt is assumed throughout that D = {0, 1, 2, 3}. Implementations should be read as follows:\n\u2022 the symbol s=\u21d2\u03b1 means \u201cstrictly \u03b1-implements\u201d;\n\u2022 U always denotes UD;\n\u2022 Y = {x, y} is the set of primary variables and Z = {z, w} is the set of auxiliary variables (see\nDefinition 3.1).\nEach implementation produces some predicate g such that either g or pi(g), or pi(gc) (for some\npermutation pi) is a predicate for which a strict implementation has already been found, or else a\npredicate g such that, for some D\u2032 \u2282 D, g|D\u2032 is not supermodular on any chain on D\u2032. We will\ndescribe the latter situation by writing, for simplicity, that \u201cg|D\u2032 is bad\u201d. If |D\u2032| = 2 then one can\ndirectly verify that the corresponding matrix is not a-Monge (there is no need to permute rows and\ncolumns). For the case |D\u2032| = 3, one can use Lemma 4.4 to quickly check that the matrix of g|D\u2032\nis not a permuted a-Monge matrix.\n1.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u20321 :=\n1000\n0110\n1000\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d22\n1000\n1110\n1000\n0000\n=: g g|{0,1,3} is bad\ng(x, y) + 1 = maxz[h\u20321(z, y) + h\n\u2032\n1(x, z) + u{3}(z)]\n2.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u20322 :=\n1000\n1101\n1000\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d23\n1000\n1101\n1010\n0000\n=: g g|{0,2,3} is bad\ng(x, y) + 2 = maxz[h\u20322(z, x) + h\n\u2032\n2(z, y) + h\n\u2032\n2(x, y) + u{3}(z) + u{2}(x) + u{2}(y)]\n3.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u20323 :=\n1001\n0111\n1110\n1001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d24\n1000\n0111\n1110\n0001\n=: g g|{0,1,3} is bad\ng(x, y) + 3 = maxz[h\u20323(z, x) + h\n\u2032\n3(z, y) + h\n\u2032\n3(x, y) + u{1,2}(z)]\n4.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u20324 :=\n1010\n0101\n1010\n1000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d24\n1101\n0101\n1000\n0101\n=: g g|{0,1,2} is bad\ng(x, y) + 3 = maxz,w[h\u20324(z, w) + h\n\u2032\n4(z, y) + h\n\u2032\n4(w, x) + u{1,3}(z)]\n5.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u20325 :=\n1010\n0110\n0000\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d23\n1000\n0100\n0001\n0001\n=: g g|{0,1,3} is bad\ng(x, y) + 2 = maxz[h\u20325(x, z) + h\n\u2032\n5(x, y) + h\n\u2032\n5(y, z) + u{3}(z) + u{2,3}(x) + u{3}(y)]\n6.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u20326 :=\n1010\n0111\n1010\n1000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d24\n1010\n0111\n1010\n1001\n=: g g|{0,1,3} is bad\ng(x, y) + 3 = maxz[h\u20326(x, z) + h\n\u2032\n6(x, y) + h\n\u2032\n6(y, z) + u{2}(z) + u{3}(x) + u{3}(y)]\n27\n7.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u20327 :=\n1010\n0111\n1110\n1000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d23\n1110\n0000\n0000\n1010\n=: g g|{2,3} is bad\ng(x, y) + 2 = maxz[h\u20327(z, y) + h\n\u2032\n7(x, z) + u{0,3}(x)]\n8.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u20328 :=\n1011\n0101\n1010\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d26\n1010\n0000\n1010\n1011\n=: g g|{0,1,3} is bad\ng(x, y) + 5 = maxz,w[h\u20328(z, w) + h\n\u2032\n8(z, x) + h\n\u2032\n8(z, y) + h\n\u2032\n8(w, x) + u{2}(z) + u{0}(w) + u{1,3}(x)]\n9.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u20329 :=\n1011\n0111\n0010\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d23\n1001\n0101\n0010\n1101\n=: g g|{0,1,2} is bad\ng(x, y) + 2 = maxz[h\u20329(z, x) + h\n\u2032\n9(x, y) + h\n\u2032\n9(y, z) + u{3}(z) + u{3}(x) + u{3}(y)]\n10.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203210 :=\n1011\n0111\n0010\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d23\n1011\n0111\n0010\n0000\n=: g g = h\u20329\ng(x, y) + 2 = maxz[h\u203210(z, x) + h\n\u2032\n10(z, y) + u{2}(z) + u{0,1}(x)]\n11.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203211 :=\n1011\n0111\n0011\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d22\n1000\n0100\n0000\n1100\n=: g pi(gt) = h\u20325 where pi(0, 1, 2, 3) = (0, 1, 3, 2)\ng(x, y) + 1 = h\u203211(x, y) + u{3}(x) + u{0,1}(y)\n12.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203212 :=\n1011\n0111\n0110\n1001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d23\n0110\n0111\n0111\n0000\n=: g g|{0,1,3} is bad\ng(x, y) + 2 = maxz[h\u203212(z, y) + h\n\u2032\n12(x, z) + u{1,2}(z)]\n13.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203213 :=\n1011\n0111\n1010\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d23\n1011\n0101\n1010\n0000\n=: g g = h\u20328\ng(x, y) + 2 = maxz[h\u203213(z, x) + h\n\u2032\n13(x, y) + h\n\u2032\n13(y, z) + u{3}(z) + u{3}(y)]\n14.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203214 :=\n1011\n0111\n1010\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d23\n0001\n0111\n0000\n0001\n=: g pi(g) = h\u20322 where pi(0, 1, 2, 3) = (3, 1, 0, 2)\ng(x, y) + 2 = maxz[h\u203214(z, y) + h\n\u2032\n14(x, z) + u{1,3}(z)]\n15.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203215 :=\n1011\n0111\n1110\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d24\n1011\n0101\n1010\n0000\n=: g g = h\u20328\ng(x, y) + 3 = maxz[h\u203215(x, z) + h\n\u2032\n15(x, y) + h\n\u2032\n15(y, z) + u{0,3}(z) + u{3}(x) + u{3}(y)]\n28\n16.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203216 :=\n1011\n0111\n1110\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d24\n1011\n0000\n1011\n0001\n=: g g|{0,1,3} is bad\ng(x, y) + 3 = maxz[h\u203216(z, x) + h\n\u2032\n16(z, y) + h\n\u2032\n16(x, z) + u{0,3}(z)]\n17.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203217 :=\n1011\n0111\n1110\n1001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d24\n1010\n0111\n1110\n0001\n=: g g|{0,1,3} is bad\ng(x, y) + 3 = maxz[h\u203217(z, x) + h\n\u2032\n17(z, y) + h\n\u2032\n17(x, y) + u{1,2}(z)]\n18.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203218 :=\n1011\n0111\n1110\n1101\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d25\n1110\n0000\n1110\n1110\n=: g g|{1,3} is bad\ng(x, y) + 4 = maxz,w[h\u203218(z, w) + h\n\u2032\n18(z, y) + h\n\u2032\n18(w, x) + u{1,2}(z) + u{0}(w)]\n19.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203219 :=\n1011\n1101\n1010\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d25\n1010\n1011\n1010\n1010\n=: g g|{1,3} is bad\ng(x, y) + 4 = maxz,w[h\u203219(z, w) + h\n\u2032\n19(z, y) + h\n\u2032\n19(x, z) + u{2}(z) + u{2}(w) + u{1,3}(x)]\n20.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203220 :=\n1100\n1101\n1000\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d22\n1110\n1101\n1011\n0111\n=: g pi(g) = h\u203218 where pi(0, 1, 2, 3) = (0, 3, 1, 2)\ng(x, y) + 1 = h\u203220(x, y) + h\n\u2032\n20(y, x) + u{2,3}(x) + u{2,3}(y)\n21.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203221 :=\n1101\n0110\n0110\n1001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d26\n1001\n1101\n0000\n1001\n=: g g|{0,1,2} is bad\ng(x, y) + 5 = maxz,w[h\u203221(z, w) + h\n\u2032\n21(z, x) + h\n\u2032\n21(z, y) + h\n\u2032\n21(w, x) + u{3}(z) + u{0}(w) + u{1,2}(x)]\n22.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203222 :=\n1101\n1100\n0010\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d23\n1000\n1110\n0010\n1010\n=: g pi(gt) = h\u20329 where pi(0, 1, 2, 3) = (0, 2, 1, 3)\ng(x, y) + 2 = maxz[h\u203222(x, z) + h\n\u2032\n22(y, z) + u{2,3}(z) + u{1,3}(x)]\n23.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203223 :=\n1101\n1110\n0000\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d22\n1101\n1110\n0111\n1011\n=: g pi(g) = h\u203218 where pi(0, 1, 2, 3) = (0, 2, 1, 3)\ng(x, y) + 1 = h\u203223(x, y) + h\n\u2032\n23(y, x) + u{2,3}(x) + u{2,3}(y)\n24.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203224 :=\n1101\n1110\n0110\n1001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d26\n1001\n1101\n0000\n1001\n=: g g|{0,1,2} is bad\ng(x, y) + 5 = maxz,w[h\u203224(z, w) + h\n\u2032\n24(z, x) + h\n\u2032\n24(z, y) + h\n\u2032\n24(x, z) + u{3}(z) + u{3}(w) + u{1,2}(x)]\n29\n25.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203225 :=\n1110\n1100\n0000\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d22\n0000\n1101\n0001\n0001\n=: g pi(gt) = h\u20322 where pi(0, 1, 2, 3) = (1, 3, 0, 2)\ng(x, y) + 1 = h\u203225(x, y) + u{1,2,3}(x) + u{3}(y)\n26.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203226 :=\n1110\n1100\n1010\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d22\n0000\n1101\n1011\n0001\n=: g pi(g) = h\u20329 where pi(0, 1, 2, 3) = (1, 2, 3, 0)\ng(x, y) + 1 = h\u203226(x, y) + u{1,2,3}(x) + u{3}(y)\n27.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h\u203227 :=\n1110\n1101\n1010\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe \u222a U s=\u21d22\n0110\n0101\n0010\n0111\n=: g pi(gt) = h\u203213 where pi(0, 1, 2, 3) = (1, 2, 3, 0)\ng(x, y) + 1 = h\u203227(x, y) + u{3}(x) + u{1,2,3}(y)\nAppendix B: Strict implementations from Case 2\nThe rules for reading implementations are the same as in Appendix B. Each implementation im-\nplements some predicate g such that, for some D\u2032 \u2282 D, g|D\u2032 is bad, or else a pair for which a strict\nimplementation has already been found.\n1.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n0000\n0000\n0001\n, f :=\n1000\n0001\n0000\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d23\n1000\n1101\n0000\n0101\n=: g g|{0,1,2} is bad\ng(x, y) + 2 = maxz[f(x, z) + f(y, z) + h(z, x) + u{1}(z) + u{1,2}(x)]\n2.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n0000\n0000\n0001\n, f :=\n1110\n0001\n0000\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d23\n1000\n0001\n0000\n0001\n=: g (h, g) is Pair 1\ng(x, y) + 2 = maxz[f(x, z) + h(x, z) + h(y, z) + u{2}(z) + u{1,2}(x)]\n3.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n0000\n0000\n0001\n, f :=\n1000\n1001\n1000\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d24\n0101\n0000\n0000\n0101\n=: g g|{0,1} is bad\ng(x, y) + 3 = maxw,z[f(z, w) + f(y, w) + h(x, z) + u{2}(z) + u{3}(w)]\n4.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n0000\n0000\n0001\n, f :=\n1010\n1010\n1010\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1000\n1001\n1000\n0001\n=: g (h, g) is Pair 3\ng(x, y) + 1 = maxz[f(z, x) + h(y, z) + u{1}(x)]\n5.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n0000\n0000\n0001\n, f :=\n1010\n1011\n1010\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1000\n1001\n1000\n0001\n=: g (h, g) is Pair 3\ng(x, y) + 1 = maxz[f(x, z) + h(y, z)]\n6.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n0000\n0000\n0001\n, f :=\n1110\n0001\n1110\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d23\n1010\n1010\n1010\n0001\n=: g (h, g) is Pair 4\n30\ng(x, y) + 2 = maxz[f(z, x) + f(z, y) + f(y, z)]\n7.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n0000\n0000\n0001\n, f :=\n1010\n1011\n1011\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1000\n1001\n1000\n0001\n=: g (h, g) is Pair 3\ng(x, y) + 1 = f(y, x) + u{1}(x) + u{0,3}(y)\n8.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1110\n0000\n0001\n0001\n, f :=\n1010\n0001\n0001\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d23\n1000\n1101\n0101\n0101\n=: g g|{0,1,2} is bad\ng(x, y) + 2 = maxz[f(z, y) + f(y, z) + h(x, z) + u{1}(x) + u{1}(y)]\n9.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1110\n0000\n0001\n0001\n, f :=\n1000\n0001\n1001\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1010\n0000\n0111\n0111\n=: g g|{0,1,2} is bad\ng(x, y) + 1 = maxz[f(y, z) + h(x, z)]\n10.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1110\n0000\n0001\n0001\n, f :=\n1010\n0101\n0101\n0101\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d24\n1010\n0001\n0001\n0001\n=: g (h, g) is Pair 8\ng(x, y) + 3 = maxz[f(z, y) + f(x, z) + h(z, y) + u{0,3}(z)]\n11.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1110\n0000\n0001\n0001\n, f :=\n1000\n0101\n1101\n0101\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d23\n1010\n0000\n0111\n0111\n=: g g|{0,1,2} is bad\ng(x, y) + 2 = maxz[f(y, z) + h(x, z) + u{0,3}(z)]\n12.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1110\n0000\n0001\n0001\n, f :=\n1000\n1101\n1101\n0101\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1000\n0001\n1001\n0001\n=: g (h, g) is Pair 9\ng(x, y) + 1 = f(y, x) + u{2}(x) + u{0,3}(y)\n13.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1000\n1001\n0001\n0001\n, f :=\n1000\n1001\n1000\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d24\n1000\n1101\n0101\n0101\n=: g g|{0,1,2} is bad\ng(x, y) + 3 = maxz[f(z, y) + f(y, z) + h(x, z) + u{3}(z) + u{0,1,2}(y)]\n14.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1000\n1001\n0001\n0001\n, f :=\n1010\n1011\n1010\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d23\n1000\n1001\n1000\n0001\n=: g (h, g) is Pair 13\ng(x, y) + 2 = maxz[f(z, y) + f(x, z) + h(y, z)]\n15.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1000\n1001\n0001\n0001\n, f :=\n1010\n1011\n1011\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1000\n1001\n1000\n0001\n=: g (h, g) is Pair 13\ng(x, y) + 1 = f(y, x) + u{1}(x) + u{0,3}(y)\n16.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1101\n0001\n0001\n, f :=\n1010\n1101\n1010\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d23\n1100\n0101\n1011\n0101\n=: g g|{0,1,2} is bad\n31\ng(x, y) + 2 = maxz[f(y, x) + h(z, y) + h(x, z) + u{3}(z)]\n17.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1101\n0001\n0001\n, f :=\n1100\n1100\n1011\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d24\n1100\n0100\n0011\n0111\n=: g g|{0,1,2} is bad\ng(x, y) + 3 = maxz[f(x, y) + h(x, z) + h(y, z) + u{3}(z) + u{0,3}(x)]\n18.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1101\n0001\n0001\n, f :=\n0000\n1101\n1011\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d24\n0000\n1011\n1011\n1011\n=: g g|{0,1} is bad\ng(x, y) + 3 = maxw,z[f(w, y) + h(w, z) + h(x, z) + u{2}(w)]\n19.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1101\n0001\n0001\n, f :=\n1010\n0001\n1011\n0001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1010\n1111\n0111\n0111\n=: g g|{0,1,2} is bad\ng(x, y) + 1 = maxz[f(y, z) + h(x, z)]\n20.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1101\n0001\n0001\n, f :=\n1110\n0101\n0000\n0101\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1010\n0001\n1011\n0001\n=: g (h, g) is Pair 19\ng(x, y) + 1 = f(x, y) + u{2}(x) + u{0,2,3}(y)\n21.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1101\n0001\n0001\n, f :=\n1010\n0101\n1010\n0101\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d24\n1100\n0111\n0000\n0111\n=: g g|{0,1,2} is bad\ng(x, y) + 3 = maxz[f(z, x) + h(x, z) + h(y, z) + u{0,3}(z)]\n22.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1101\n0001\n0001\n, f :=\n0000\n0101\n1011\n0101\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1010\n1101\n1010\n0000\n=: g (h, g) is Pair 16\ng(x, y) + 1 = f(y, x) + u{0,1,2}(x) + u{0}(y)\n23.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1101\n0001\n0001\n, f :=\n0000\n1101\n0011\n0011\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d22\n1100\n1100\n1011\n0000\n=: g (h, g) is Pair 17\ng(x, y) + 1 = f(y, x) + u{0,1,2}(x) + u{0}(y)\n24.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1000\n1001\n1001\n0001\n, f :=\n0000\n1101\n1011\n0000\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d24\n0000\n1011\n1011\n1011\n=: g g|{0,1} is bad\ng(x, y) + 3 = maxw,z[f(z, w) + f(w, y) + h(x, z) + u{1,3}(z) + u{2}(w)]\n25.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1100\n1101\n0001\n, f :=\n1001\n0100\n1101\n1001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d24\n1101\n1001\n1101\n1101\n=: g g|{0,1} is bad\ng(x, y) + 3 = maxw,z[f(z, y) + f(x,w) + h(z, w) + u{0}(z) + u{3}(w)]\n32\n26.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1100\n1101\n0001\n, f :=\n1101\n0100\n1101\n1001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d23\n1001\n0100\n1101\n1001\n=: g (h, g) is Pair 25\ng(x, y) + 2 = maxz[f(z, x) + f(z, y) + u{1,3}(z) + u{2}(x)]\n27.\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3h :=\n1100\n1100\n0011\n0011\n, f :=\n1001\n0110\n0110\n1001\n\uf8fc\uf8f4\uf8fd\uf8f4\uf8fe\u222a U s=\u21d24\n1111\n1001\n1001\n1111\n=: g g|{0,1} is bad\ng(x, y) + 3 = maxw,z[f(z, y) + f(w, x) + h(z, w) + u{3}(z) + u{0}(w)]\n33\n"}
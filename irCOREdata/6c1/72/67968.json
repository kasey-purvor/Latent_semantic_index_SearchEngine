{"doi":"10.1080\/17459730701666887","coreId":"67968","oai":"oai:eprints.lancs.ac.uk:34281","identifiers":["oai:eprints.lancs.ac.uk:34281","10.1080\/17459730701666887"],"title":"Timing in music and temporal logic.","authors":["Marsden, Alan"],"enrichments":{"references":[{"id":839559,"title":"A calculus of durations.","authors":[],"date":"1991","doi":null,"raw":"Zhou, C., Hoare, C.A.R. & Ravn, A.P. (1991). A calculus of durations. Information Processing Letters, 40, 269\u2013276.","cites":null},{"id":838111,"title":"A cognitive model and a knowledge representation system for music and multimedia.","authors":[],"date":"1994","doi":"10.1080\/09298219408570663","raw":"Camurri, A., Frixione, M. & Innocenti, C. (1994). A cognitive model and a knowledge representation system for music and multimedia. Journal of New Music Research, 23, 317\u2013 347.","cites":null},{"id":840332,"title":"A concurrent constraints factor oracle model for music.","authors":[],"date":"2006","doi":null,"raw":"Rueda, C., Assayag, G. & Dubnov, S. (2006). A concurrent constraints factor oracle model for music. XXXII Conferencia Latinoamericana de Inform\u00e1tica CLEI 2006, Santiago, August 2006. http:\/\/mediatheque.ircam.fr\/articles\/textes\/Rueda06a\/, last accessed 9 May 2007.","cites":null},{"id":837478,"title":"A process model for musical listening based on DH-networks.","authors":[],"date":"1986","doi":null,"raw":"Leman, M. (1986). A process model for musical listening based on DH-networks. CC-AI, Journal for The Integrated Study of Artificial Intelligence, Cognitive Science and Applied Epistemology, 3, 225\u2013239.","cites":null},{"id":837751,"title":"Adaptive dynamics of musical listening.","authors":[],"date":"1989","doi":"10.1080\/07494468900640411","raw":"Leman, M. (1989). Adaptive dynamics of musical listening. Contemporary Music Review, 4, 347\u2013362.","cites":null},{"id":838005,"title":"Applications of artificial intelligence methodologies and tools for music description and processing.","authors":[],"date":"1993","doi":null,"raw":"Camurri, A. (1993). Applications of artificial intelligence methodologies and tools for music description and processing. In G. Haus (ed.) Music Processing, Oxford: Oxford University Press, 233\u2013266.","cites":null},{"id":842099,"title":"Automatic extraction of tempo and beat from expressive performances.","authors":[],"date":"2001","doi":"10.1076\/jnmr.30.1.39.7119","raw":"Dixon, S. (2001). Automatic extraction of tempo and beat from expressive performances. Journal of New Music Research, 30, 39\u201358.","cites":null},{"id":838377,"title":"Describing and performing musical processes by means of Petri nets.","authors":[],"date":"1986","doi":"10.1080\/09298218608570470","raw":"Camurri, A., Haus, G. & Zaccaria, R. (1986). Describing and performing musical processes by means of Petri nets. Interface, 15, 1\u201323.","cites":null},{"id":837191,"title":"Dynamical-hierarchical networks as perceptual memory representations of music.","authors":[],"date":"1985","doi":"10.1080\/09298218508570465","raw":"Leman, M. (1985). Dynamical-hierarchical networks as perceptual memory representations of music. Interface, 14, 125\u2013164.","cites":null},{"id":838661,"title":"Formal music representation; a case study: the model of Ravel\u2019s Bolero by Petri nets.","authors":[],"date":"1993","doi":null,"raw":"Haus, G. & Rodriguez, A. (1993). Formal music representation; a case study: the model of Ravel\u2019s Bolero by Petri nets. In G. Haus (ed.) Music Processing. Oxford: Oxford University Press, 165\u2013232. [11] Gabbay, D.M., Finger, M. & Reynolds, M. (2000). Temporal Logic: Mathematical Foundations and Computational Aspects (v.2). Oxford: Oxford University Press.","cites":null},{"id":840596,"title":"Interactive score: a model for specifying temporal relations between interactive and static events.","authors":[],"date":"2005","doi":null,"raw":"Desainte-Catherine, M. & Allombert, A. (2005). Interactive score: a model for specifying temporal relations between interactive and static events. Journal of New Music Research, 34, 361\u2013374.","cites":null},{"id":836651,"title":"Making Sense in Music: An Enquiry into the Formal Pragmatics of Art.","authors":[],"date":"1978","doi":null,"raw":"Kunst, J. (1978). Making Sense in Music: An Enquiry into the Formal Pragmatics of Art. Ghent: Communication & Cognition.","cites":null},{"id":841215,"title":"Modelling the perception of musical voices: a case study in rulebased systems.","authors":[],"date":"1992","doi":null,"raw":"Marsden, A. (1992). Modelling the perception of musical voices: a case study in rulebased systems. In A. Marsden & A. Pople (Eds.) Computer Representations and Models in Music, London: Academic Press, 239\u2013263.","cites":null},{"id":840049,"title":"On validity in modelization of musical problems by CCP.","authors":[],"date":"2004","doi":null,"raw":"Rueda, C. & Valencia, F. (2004). On validity in modelization of musical problems by CCP. Soft Computing, 8, 641\u2013648.","cites":null},{"id":841429,"title":"Pure Data (computer software), http:\/\/crca.ucsd.edu\/~msp\/software.html, last accessed 9","authors":[],"date":"2007","doi":null,"raw":"Puckette, M. (n.d.). Pure Data (computer software), http:\/\/crca.ucsd.edu\/~msp\/software.html, last accessed 9 May 2007.","cites":null},{"id":842437,"title":"Real-time recognition of improvisations with adaptive oscillators and a recursive Bayesian classifier.","authors":[],"date":"2001","doi":"10.1076\/jnmr.30.2.137.7112","raw":"Toiviainen, P. (2001). Real-time recognition of improvisations with adaptive oscillators and a recursive Bayesian classifier. Journal of New Music Research, 137\u2013147.","cites":null},{"id":836504,"title":"Representing Musical Time: A Temporal-Logic Approach.","authors":[],"date":"2000","doi":null,"raw":"Marsden, A. (2000). Representing Musical Time: A Temporal-Logic Approach. Lisse: Swets & Zeitlinger.","cites":null},{"id":839787,"title":"Synthesizing controllers from duration calculus. In","authors":[],"date":"1996","doi":null,"raw":"Fr\u00e4nzle, M. (1996). Synthesizing controllers from duration calculus. In B. Jonsson & J. Parrow, Formal Techniques in Real-Time Fault-Tolerant Systems (Lecture Notes in Computer Science, no. 1135), Berlin: Springer-Verlag, 168\u2013187.","cites":null},{"id":839447,"title":"Temporal logic and computer science; an overview.","authors":[],"date":"1987","doi":null,"raw":"Galton, A. (1987). Temporal logic and computer science; an overview. In A. Galton (ed.) Temporal Logics and their Applications. London: Academic Press, 1-52.","cites":null},{"id":838894,"title":"Temporal Logic.","authors":[],"date":"1971","doi":"10.2307\/2218321","raw":"Rescher, N. & Urquhart, A. (1971). Temporal Logic. Vienna & New York: Springer.","cites":null},{"id":836935,"title":"The analysis of musical meaning: a theory and an experiment.","authors":[],"date":"1984","doi":"10.1080\/09298218408570443","raw":"Kunst, J. & Van den Bergh, H. (1984). The analysis of musical meaning: a theory and an experiment. Interface, 13, 75\u2013106.","cites":null},{"id":840950,"title":"The declarative past and imperative future.","authors":[],"date":"1987","doi":null,"raw":"Gabbay, D.M. (1987). The declarative past and imperative future. In Temporal Logic in Specification, Berlin: Springer-Verlag, 407\u2013448.","cites":null},{"id":842598,"title":"The learning and transfer of multifrequency patterns.","authors":[],"date":"2000","doi":null,"raw":"Summers, J.J. (2000). The learning and transfer of multifrequency patterns. In P. Desain & L. Windsor (eds.), Rhythm Perception and Production, Lisse: Swets & Zeitlinger, 69\u201380.","cites":null},{"id":839186,"title":"The Logic of Time.","authors":[],"date":"1983","doi":null,"raw":"Van Benthem, J.F.A.K. (1983). The Logic of Time. Dordrecht: D.Reidel.","cites":null},{"id":841842,"title":"Timekeepers versus nonlinear oscillators: how the approaches differ. In","authors":[],"date":"2000","doi":null,"raw":"Beek, P.J., Peper, C.E. & Daffertshofer, A. (2000). Timekeepers versus nonlinear oscillators: how the approaches differ. In P. Desain & L. Windsor (eds.), Rhythm Perception and Production, Lisse: Swets & Zeitlinger, 9\u201333.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2007","abstract":"'In-time' representations of music in which the time represented is the same time as inhabited by the agent making or using the representation are contrasted with 'out-of-time' representations. Temporal logics with a similar 'in-time' perspective, and in particular those using operators S and U for 'since' and 'until', are explored as a means of representing musical situations, with particular reference to a paradigm 'triangle-player problem'. Illustrative implementations are given in the music software Pd. New versions of the operators S and U are defined to accommodate the musically important phenomena of regularly occurring events associated with metre, and to allow representations to reflect actual timings rather than relations of temporal order. Nesting of out-of-time representations within in-time representations then becomes possible and arises naturally as a way of representing certain kinds of musical situation","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/67968.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/34281\/1\/JMMforEprints.pdf","pdfHashValue":"c71e732a513ff9eb5757fac32d60978e4bd06ca3","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:34281<\/identifier><datestamp>\n      2017-11-18T11:26:53Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D4D:4D31<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Timing in music and temporal logic.<\/dc:title><dc:creator>\n        Marsden, Alan<\/dc:creator><dc:subject>\n        M Music<\/dc:subject><dc:description>\n        'In-time' representations of music in which the time represented is the same time as inhabited by the agent making or using the representation are contrasted with 'out-of-time' representations. Temporal logics with a similar 'in-time' perspective, and in particular those using operators S and U for 'since' and 'until', are explored as a means of representing musical situations, with particular reference to a paradigm 'triangle-player problem'. Illustrative implementations are given in the music software Pd. New versions of the operators S and U are defined to accommodate the musically important phenomena of regularly occurring events associated with metre, and to allow representations to reflect actual timings rather than relations of temporal order. Nesting of out-of-time representations within in-time representations then becomes possible and arises naturally as a way of representing certain kinds of musical situation.<\/dc:description><dc:date>\n        2007<\/dc:date><dc:type>\n        Journal Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/34281\/1\/JMMforEprints.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1080\/17459730701666887<\/dc:relation><dc:identifier>\n        Marsden, Alan (2007) Timing in music and temporal logic. Journal of Mathematics and Music, 1 (3). pp. 173-189. ISSN 1745-9737<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/34281\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1080\/17459730701666887","http:\/\/eprints.lancs.ac.uk\/34281\/"],"year":2007,"topics":["M Music"],"subject":["Journal Article","PeerReviewed"],"fullText":"Timing in music and modal temporal logic \nALAN MARSDEN \nLancaster Institute for the Contemporary Arts, Lancaster University \n \nThis is a post-print (author\u2019s final draft) of an article published in Journal of Mathematics and \nMusic, vol.1 no.3 (2007) 173\u2013189. Details of the definitive version are available at \nwww.informaworld.com. \n \n \u2018In-time\u2019 representations of music in which the time represented is the same \ntime as inhabited by the agent making or using the representation are \ncontrasted with \u2018out-of-time\u2019 representations. Temporal logics with a similar \n\u2018in-time\u2019 perspective, and in particular those using operators S and U for \n\u2018since\u2019 and \u2018until\u2019, are explored as a means of representing musical situations, \nwith particular reference to a paradigm \u2018triangle-player problem\u2019. Illustrative \nimplementations are given in the music software Pd. New versions of the \noperators S and U are defined to accommodate the musically important \nphenomena of regularly occurring events associated with metre, and to allow \nrepresentations to reflect actual timings rather than relations of temporal order. \nNesting of out-of-time representations within in-time representations then \nbecomes possible and arises naturally as a way of representing certain kinds of \nmusical situation.  \nKeywords: Representation; Musical time; Co-ordination; Temporal logic \nAMS Subject Classification Codes: 03B44; 68N30; 91F99 \n1 Introduction \nThe representation of time in music is clearly important, but turns out often not to be simple. \nDifferent situations require different kinds of representations, discussed by a number of \nresearchers in previous publications (for a summary, see [1]). Here consideration is given \nonly to the situation where the representing agent inhabits the same flow of time as the music \nrepresented. This kind of representation is crucial in the modelling of listening processes, and \nin the design of automata to perform or create music in real-time set-ups. Relevant previous \nwork exists in the theoretical formulations of Kunst [2\u20133] and Leman [4\u20136], with respect to \nthe modelling of the listening experience, and in real-time software systems with a strong \ntheoretical base such as HARP [7\u20138] and various systems based on Petri nets [9\u201310]. The \nobjective of this paper is to enhance the mathematical rigour underlying such work by \nformulating concepts based on temporal logic which might provide for musical systems the \nkind of basis for proof and formal design which it provides for computer science (see [11]).  \n When one listens to a live performance, one must make some kind of mental \nrepresentation of the music performed; otherwise one could not recognise a recurrence of a \npassage heard before. But, unlike someone transcribing a recorded performance, it is not \nCorrespondence: Alan Marsden. Lancaster Institute for the Contemporary Arts, Lancaster University, \nLA1 4YW, UK; \nTel. +44 1524 593774; Fax. +44 1524 593939; E-mail: A.Marsden@lancaster.ac.uk \n \npossible for the listener to actually review some earlier stage in the performance to check that \nit is indeed the same passage of music as just heard; the only information the listener has \nabout earlier occurrences is in the representation he or she has already made and is currently \nadding to. Similarly, one\u2019s representation of the future can only be in anticipations of events \nand plans for actions. A musician playing from a score operates simultaneously with two \nkinds of temporal representations. The score represents temporal relations in an abstract time \nwhich can be related differently to actual times in different actual performances. The \nperformer\u2019s memory and anticipation, on the other hand, on which her or his performance \nrelies, refers implicitly to the time in which the performer lives. These two kinds of temporal \nrepresentation are referred to as \u2018in-time\u2019 representations for those cases where reference is \nmade only through memory and anticipation, and \u2018out-of-time\u2019 representations for cases like a \nmusical score. \n These considerations apply not only to (human) musicians, but also to musical \nautomata. An automaton behaving in a musical fashion can make use of one or more out-of-\ntime representations, similarly to a musician making use of a score, but it must also have an \nin-time representation of its own past and, possibly, its own future. This representation of past \nand future need not be explicit in the automaton, and indeed it is common for it to be implicit \nin its structure and internal state. However, explicit representation of temporal relations is \nnecessary for reasoning about them, such as in the design and proofs of correctness of \ncomputer software, and the task of this paper is to begin to identify which kinds of in-time \ntemporal representations are suitable for music. \n1.1 Paradigmatic triangle-player problem \nTo focus the discussion, a paradigmatic problem is proposed. Consider a triangle player who \nhas one note x to play in a piece of music. This note must occur at the same time as another \nnote y played by another performer in the ensemble. The triangle player has information \nabout some of the notes a, b, c \u2026 the other player is to play before the note y. (See Figure 1.) \nThe essential requirement of the problem, that when y is sounded x should also be sounded, Y \n\uf0ae X, suggests a solution of a sort\u2014wait until y and immediately play x\u2014but this is clearly \nnot satisfactory in either of the scenarios suggested above. It takes time to hit a triangle, and \nto recognise that a note has been played. A proper solution requires the triangle player to \nrecognise that the other player has reached a point in his or her part sufficiently before the \nnote y in time to initiate the playing of note x so that it sounds at the same time as y. On the \nother hand, the triangle player must be able to respond to changes in timing by the other \nplayer which will affect the timing of note y, and so must leave initiation of the process of \nplaying note x as late as possible. \n \n\uf02f \uf0c0 \n\uf026 \uf0cf \uf0cf \uf0cf \uf0cf \nx \ny \n\u2026 \n\u2026 \na b c \n  Figure 1. The \u2018triangle-player problem\u2019; note x must be played at the same time as note y, using the timing \ninformation conveyed by the preceding notes a, b, c, \u2026. \n1.2 Modal temporal logic \nTemporal logics which are here called \u2018modal\u2019 introduce into classical logic new connectives \nwith an explicitly temporal meaning. Sometimes they re-use the modal connectives \u25a1 \n(necessity) and \u25ca (possibility), to which can be added \u25cb for \u2018next\u2019 (or \u2018previous\u2019), but since \nthese can be variously used to refer to the past or the future, and since other connectives with \nno modal equivalent can be used (such as those for \u2018since\u2019 and \u2018until\u2019), it is common to use \nupper case letters for the temporal connectives. (Descriptions of temporal logic can be found \nin [12\u201315].) Common connectives, including those used in this paper, are given in Table 1, \ntogether with their definitions in English and in first-order predicate logic. These definitions \nuse a special term now, which functions like a constant but is properly an indexical, to refer to \nthe time at which the truth-value of the statement is evaluated. The term x < y is true when x \nprecedes y, and vice versa for x > y. Precise definitions of the temporal connectives vary from \none temporal logic to another, and logics vary in the ontology of time assumed (see [1] pp.23\u2013\n53). For now, it is sufficient to note that the connectives Y and T are only valid in the case of \ntime with discrete steps and t + 1 is the time immediately following time t, and that a logic \nwith S and U (in terms of which the other connectives can be defined) is expressively \ncomplete and decidable for linear time (except in certain ontologies, see [11]). \n \nPast Modal Future \nPA =def \uf024t((t < now) \uf0d9 A(t)) P \u25ca F FA =def \uf024t((t > now) \uf0d9 A(t)) \nA was true at some time in the Past.  A will be true at some time in the Future. \nHA =def \uf022t((t < now) \uf0ae A(t)) H \u25a1 G GA =def \uf022t((t > now) \uf0ae A(t)) \nA always Has been true.  A is always Going to be true \nYA =def \uf024t((t = now \u2013 1) \uf0d9 A(t)) Y \u25cb T TA =def \uf024t((t = now + 1) \uf0d9 A(t)) \nA was true Yesterday.  A will be true Tomorrow. \nS(A, B) =def \uf024t((t < now) \uf0d9 A(t) \uf0d9  \n \uf022s((t < s < now) \uf0ae B(s))) \nS  U U(A, B) =def \uf024t((t > now) \uf0d9 A(t) \uf0d9  \n\uf022s((t > s > now) \uf0ae B(s))) \nB has been true Since A.  B will be true Until A. \nTable 1. Common temporal-logic connectives. \n \n Temporal logic can function not only as quasi-mathematical problem-solving device, \nbut also as a language for the description and design of automata and computer systems. \nIndeed, there have been substantial research efforts to develop temporal logics for use in the \nspecification and design of real-time systems, especially where proof is required that the \nsystem will work safely. One of the best known is the Duration Calculus [16], a logic which is \nnot always decidable, but which has been demonstrated to be decidable in likely realistic \nimplementation scenarios [17]. While we can expect, therefore, that Duration Calculus could \nbe used to specify a solution to the triangle-player problem, it is more general in its scope than \nis necessary for music-specific problems. An alternative approach is to use a concurrent \nprocess calculus, such as in [18\u201319]. This works well for situations where there is a \u2018bird\u2019s-\neye view\u2019 of interacting agents, but the intention here is to model the processing of a single \nagent whose only knowledge of the past is through memories of sensed events, and whose \nonly control over the future is through its own behaviour. Such an agent is modelled in a \nnetwork system capable of realising a \u2018score\u2019 in interaction with live events in [20].  \n My intention here, however, is not so much to design a comprehensive \nimplementation logic, but rather to make a conceptual exploration of formalising the \nrequirements of automata capable of musical timing. For this the simplicity of classical modal \ntemporal logic is sufficient, and so it will be the basis of the formulations used here. A \ncommon approach when using temporal logic to define the behaviour of an automaton has \nbeen described as \u2018declarative past, imperative future\u2019 [21]: statements referring to the past \nrecognise that a particular situation has occurred, and these imply statements referring to the \nfuture which are taken as a prescription of actions to perform in order to make certain \npropositions become true. For example, the basic functionality of a burglar alarm can be \nrepresented by the following two statements. \nS(A \uf0d9 B, A) \uf0ae U(~A, X) (1) \n~A \uf0ae ~X (2) \nA is true when the alarm is set, B when there is an intrusion, and X when the alarm sounds. \nFormula (1) states that when there has been an intrusion at a time when the alarm is set, then \nthroughout the time when the alarm remains set, the bell will sound. Formula (2) ensures that \nthe bell does not sound when the alarm is turned off. Note the importance of using S formula \n(1): if on the left-hand side it had simply P(A \uf0d9 B), then, after turning off the alarm, it would \nstart to sound as soon as it was set again. Using S ensures that the alarm will sound only if it \nhas been set continuously since the last intrusion. A mechanism which was certain to behave \naccording to these formulae would be suitable as a burglar-alarm controller. \n2 Representing a sequence in temporal logic \nTo sketch a similar logical description of a solution to the triangle-player problem, we begin \nby exploring the representation of events in the past in a temporal logic using the connectives \ndescribed above. In these representations, logical propositions such as A will be considered \ntrue at all times that the note a is sounding. Conversely, ~A will be considered true at all \ntimes that the note a is not sounding. We will take the situation leading up to the triangle note \nto be as illustrated in Figure 2. \n \n\uf026 \uf0cf \uf0cf \uf0cf \na b c  \nFigure 2. Simple sequence of notes. \n \n We can represent situation in which the notes a, b, and c have occurred in that order \nby the statement \nP(P(PA \uf0d9 B) \uf0d9 C) (3) \nbut this only requires that at some time in the past note c was sounding and in the past relative \nto that time note b was sounding, and in the past relative to that time note a was sounding. \nThis is not a sufficient characterisation of the situation in Figure 2 for three reasons: \n(a) Any time interval between a, b, and c is acceptable, but the notation in Figure 2 requires \nthe intervals to be at least approximately equal, and in most contexts to be within a certain \nrange. \n(b) The formula does not require b to immediately follow a nor c to immediately follow b. \nSilences, other notes or even other occurrences of a, b, or c could occur in between and the \nformula would still be true. \n(c) The formula does not preclude the possibility of other notes occurring in addition to a, b, \nand c. \n Problem (c) raises the biggest questions. The universe of the formula should \ncorrespond to the focus of the triangle player, which will generally be on just a part of the \nscore where a single line or voice of music is represented. Note occurring in other voices \nshould not matter, but other notes in that voice should falsify the formula. Unfortunately, how \nmusical voices are defined in relation to a whole piece remains the real mystery of music and \ntemporal structures (see [22] for some discussion), and for the remainder of this paper it will \nbe assumed that the notes of the voice in question can be unequivocally distinguished from \nother notes.  \n2.1 Representation in discrete time \nTo solve problem (a) requires some form of measurement or at least comparison of time \nintervals. In discrete domains this is easy to achieve by using the connective Y to effectively \ncount the number of time quanta between an event in the past and the present. If the notes of \nFigure 2 are to be four quanta long, for example, and the triangle player needs two time \nquanta to prepare to strike the triangle, a solution to the triangle-player problem could be \nrepresented by formula (4). \nYY(YYYY(YYYYA \uf0d9 B) \uf0d9 C) \uf0ae TT(X \uf0d9 Y) \uf0d9 INITIATE_STRIKE (4) \nHowever, this leaves problem (b) unsolved, allowing gaps and intervening notes. Formula (5) \nremedies this by requiring notes a, b, and c to sound in each time quantum. \nY(Y(Y(Y(Y(Y(Y(Y(Y(YA \uf0d9 A) \uf0d9 A) \uf0d9 A) \uf0d9 B) \uf0d9 B) \uf0d9 B) \uf0d9 B) \uf0d9 C) \uf0d9 C) \uf0ae  \nTT(X \uf0d9 Y) \uf0d9 INITIATE_STRIKE (5) \n However, this is still not an acceptable solution to the problem because it requires \ntiming more precise than is generally produced in actual performance situations. This is \nillustrated by example software\n*\n, shown in Figure 3, written in Pd [23], a free graphical data-\nflow language for MIDI and audio similar to Max\/MSP. To emphasise the anticipation time \nrequired, the \u2018triangle\u2019 object here actually plays a roll with a crescendo culminating in a final \nstrike at the required time. The length of this roll is here set to 250 milliseconds. The \n\u2018noteInput\u2019 object causes the software to listen for input on MIDI channel 1, also requested \nfor the three \u2018note\u2019 objects which detect the notes A, B, and C (MIDI numbers 69, 71 and 72). \nThese emit 1 when a note starts, and 0 when it is replaced by another note on the same \nchannel or if it has been silent for at least a second. (This is to accommodate the realities of \nkeyboard playing: players often play notes shorter than their notated duration, in a detached or \nstaccato style of playing, or, when playing legato, hold a note for longer than its notated \nduration so that it actually overlaps the following note.) The \u2018Y\u2019 object emits 1 or 0 at each \ntick (sent on a background channel by the \u2018ticker\u2019 object), according to whether or not it last \nreceived 1 or 0 on its inlet. Pd objects normally emit output on receiving input on the left \ninlet, but the \u2018and\u2019 object (and a corresponding \u2018or\u2019 object) have been written to emit output \nwhenever input is received on either inlet. (These objects are shown in Figure 5.) The output \nis 1 whenever the input is 1 and the previous input on the other inlet was also 1. The object \n\u2018select 1\u2019 effectively listens for a 1 on its inlet, and when it is received (i.e., the preconditions \nfor the triangle note are true), it sends a \u2018bang\u2019 to cause the triangle to sound. The \n\u2018metronome\u2019 object causes a click to sound every four ticks, allowing the user to hear the time \ninterval expected between notes for the triangle to sound. It is quite difficult to play the notes \nA, B and C at just the right tempo and evenly enough to make the triangle sound, even with a \ntime quantum as coarse as 125 milliseconds (one eighth of a second). \n This can be remedied by altering the specification of the preconditions to allow some \nflexibility in timing, as in formula (6) and Figure 4. With this version of the software, it is \npossible to play away in approximately the right tempo, and whenever the notes A, B and C \nare played as approximately crotchets, the triangle will sound.  \nY(Y(( \nY(Y(Y((Y(Y(YA \uf0d9 A) \uf0d9 A) \uf0da Y(Y(Y(YA \uf0d9 A) \uf0d9 A) \uf0d9 A) \uf0da Y(Y(Y(Y(YA \uf0d9 A) \uf0d9 A) \n\uf0d9 A) \uf0d9 A)) \uf0d9 B) \uf0d9 B) \uf0d9 B) \uf0da  \nY(Y(Y(Y((Y(Y(YA \uf0d9 A) \uf0d9 A) \uf0da Y(Y(Y(Y(YA \uf0d9 A) \uf0d9 A) \uf0d9 A) \uf0da Y(Y(Y(Y(Y(YA \uf0d9 \nA) \uf0d9 A) \uf0d9 A) \uf0d9 A)) \uf0d9 B) \uf0d9 B) \uf0d9 B) \uf0d9 B) \uf0da  \nY(Y(Y(Y(Y((Y(Y(YA \uf0d9 A) \uf0d9 A) \uf0da Y(Y(Y(Y(YA \uf0d9 A) \uf0d9 A) \uf0d9 A) \uf0da Y(Y(Y(Y(Y(YA \uf0d9 \nA) \uf0d9 A) \uf0d9 A) \uf0d9 A)) \uf0d9 B) \uf0d9 B) \uf0d9 B) \uf0d9 B) \uf0d9 B) \n                                                 \n*\n The software examples may be downloaded from http:\/\/www.lancs.ac.uk\/staff\/marsdena\/software\/timing2007 \n) \uf0d9 C) \uf0d9 C) \uf0ae TT(X \uf0d9 Y) \uf0d9 INITIATE_STRIKE (6) \n \n \n \nFigure 3. Pd implementation of the strict solution using Y. \n \n \nFigure 4. Pd implementation of a more realistic solution using Y. \n \n \nFigure 5. Pd implementations of Y, \u2018and\u2019, \u2018or\u2019 and S. \n \n There remain three reasons, however, why this is not a good model of a general \nsolution to the triangle-player problem. \n(a) A specific solution must be related to a specific granularity of discrete time. \n(b) Since timings are effectively specifically built into a solution, a complex set of \ndisjunctions is required to mimic a realistic situation when the timings of the triangle player \nadapt to the timings used by the player of the other part, effectively building into the solution \nevery possible specific timing that the triangle player has to respond to. \n(c) A solution of this sort only requires the time intervals between the notes a, b, and c to be \nequal and to be within a certain range. In general, music notation also specifies that the notes \nmust occur close to one of a certain set of times, corresponding to the beats of a piece of \nmusic. The notes a, b, and c, for example, might all occur between beats, which would not \nmatch the notation of Figure 2 as normally interpreted, but the triangle will still sound \naccording to formula (6) and in the software of Figure 4. \nIn any case, it is preferable to express a solution in a logic of dense time and to leave the \ntranslation to the discrete time within which computer systems generally operate as an \nimplementation issue. \n2.2 Representation in dense time \nIn dense time, the operator Y is not available, but a continuous sequence of notes can be \nrepresented using the operator S, as in formula (7). \nS(S(A, B), C) (7) \nThe implementation of this operator in Pd is simple (shown in Figure 5), because of the way \nin which Pd reads inlets in a fixed order. The S object emits 1 whenever 1 is received on the \nleft inlet and the value last received on the right inlet was also 1. Otherwise it emits 0 \nwhenever any input is received on the left inlet. \n More complex configurations of notes can also be represented using the S operator. \n(Indeed, the expressive completeness of the S and U operators implies that any configuration \nof notes could be represented.) A configuration in which b has followed a after an overlap \n(Figure 6A) could be represented as \nS(S(A, A \uf0d9 B), B) (8) \nOne might represent a situation in which note d is heard after the sequence a, b has been \nheard sounding together with the note c (Figure 6B), for example, might be represented as \nS(S(A, B) \uf0d9 C, D) (9) \nbut this formula is also satisfied in situations when note a has stopped before note c begins. \nThe situation is more properly represented as \nS(S(A \uf0d9 C, B \uf0d9 C), D) (10) \nSimilarly, a configuration consisting of notes a, b, c, d, e, and f with the sequence b, c \noccurring in parallel with the sequence d, e, both following a and preceding f (Figure 6C), \nmight be represented by \nS(S(S(A, B), C) \uf0d9 S(S(A, D), E), F) (11) \nbut once again this representation is too loose. As with a and c in (9), it does not require b and \nd to sound together, and there could even be two occurrences of the note a. The solution to \nthis is even more complex than (10) because it requires each alternative to be explicitly stated \nin a disjunction: \nS(S(S(S(A, B \uf0d9 D), C \uf0d9 D), C \uf0d9 E) \uf0da S(S(A, B \uf0d9 D), C \uf0d9 E) \uf0da  \nS(S(S(A, B \uf0d9 D), B \uf0d9 E), C \uf0d9 E), F) (12) \nFurthermore, the complexity of a formula like this would increase exponentially with \nincreasing numbers of notes in indeterminate parallel sequences. \nA: \n \n\uf026 \uf0fa \n\uf0ce \uf0fa \na \n \nb \n \n\uf0ce \n \nB: \n \n\uf026 \uf0cf \uf0fa \n\uf0cf \uf0cf a b \nc \n \nd \n  \nC: \n \n\uf026 \uf0cf \uf0cf \uf06a \n\uf0cf \uf04a \n\uf0cf \uf06a \uf0cf \uf0cf \uf04a \nf \nb c \n \na \nd e \n \n \nFigure 6. More complex patterns of notes. \n \n Essentially, this kind of representation is capable only of representing sequences of \nevents leading up to the present, where each event is a note, or a number of notes or segments \nof notes sounding together. It is possible for there to be branching of sequences in the past, as \nfor example when two sequences occur in parallel and terminate at a common point (either \nnow or in the past), but these branches cannot rejoin at some point in the past, and so nothing \ncan be inferred about the co-ordination of events between such branching sequences. This is \nadequate for representing the past of a musical automaton\u2014it might have reached this point \nby any one of a number of possible paths\u2014and maybe it is entirely appropriate that where it \nis required that simultaneous sounding of notes has occurred, these should be represented \nexplicitly as simultaneously-sounding-notes events with the form A \uf0d9 B. When looking to the \nfuture, however, the situation is more complex. It might well be that we want to represent an \nindeterminate but constrained future in which diverging branches do rejoin at some specified \nevent in the future: after first co-ordinating with another player, the triangle player might have \na sequence of notes to play which terminate at some defined co-ordinating point with the part \nof the other player, but that player\u2019s part might involve some indeterminate ornamentation or \nimprovisation in between. \n2.3 S and U representations and \u2018nested-branching\u2019 representations \nThe nesting of S (or U) operators in representations of the kind exemplified above suggest a \npossible parallel with the class of representations described as \u2018nested-branching\u2019 in [1]. It \nwas demonstrated there that fully indeterminate representations using time periods are \nintractable for such tasks as determining consistency. Some other representations, while \ntractable, are still too complex for use in real-time performance. For this, it is essential that \nthe complexity of the performance task is linear in the size of the passage of music to be \nperformed, otherwise there must inevitably be a size of passage which is too large for the \nperformance task to keep up with the time of performance. Nested-branching representations \ncan be sequences of symbols with nested occurrences of brackets { and } to indicate the \ndivergence and convergence of branches respectively, with parallel sequences within brackets \ndivided by slashes \/. (The configuration of Figure 6C, for example, could be represented as a \n{b c \/ d e} f.) This kind of representation allows for some indeterminacy (e.g., in the co-\nordination of notes b, c, d and e in the example above), of a kind commonly found in music, \nbut can nevertheless be performed through an algorithm of linear complexity ([1] pp.214\u2013\n215). As indicated above, the situation of hearing the note x in a sequence \u2026 v w x y z \u2026 can \nbe represented as \nS(S(S(\u2026, V), W), X) \uf0d9 U(U(U(\u2026, Z), Y), X) (13) \nbut the power of nesting in the nested-branching representation, which allows us to replace a \nsingle event with a configuration of events, which might be a sequence or a set of parallel \nsequences, is not actually available here. It is possible to replace the first event with a \nsequence (e.g., the first ellipsis (\u2026) in (13) could be replace by S(A, B)), and similarly the \nlast event. Furthermore, the first or last event could be replaced by a parallel sequence of \nevents represented as a conjunction of S terms (e.g., S(A, B) \uf0d9 S(C, D)), and similarly for the \nlast event. Other events, however, can only be replaced by sets of single coinciding events. \nFor example, W could be replaced by A \uf0d9 B, to mean that notes a and b both follow v and \nprecede x. However, to replace W by S(A, B) does not characterise a situation in which the \nsequence a, b follows v and precedes x. The formula S(V, S(A, B)) states that since V was \ntrue, S(A, B) has been true, but S(A, B) is true only at times when B has been true since A \nwas true. If the sequence v, a, b has been heard, there have been times since v when b has not \nbeen sounding (i.e., while a was sounding), and hence S(A, B) has been false. We might try to \nredeem the situation by replacing W not by S(A, B) but by S(A, B) \uf0da U(B, A). While this \nformula is continuously true since v until the end of the sequence v, a, b, the formula S(V, \nS(A, B) \uf0da U(B, A)) does not properly characterise the situation of being at the end of the \nsequence v, a, b, because it is also true before the end (while a is sounding) and true at the \nend of the configuration {v \/ a} b (i.e., with v and a sounding together). \n The essential problem is that we cannot define a formula using S and U which \ncharacterises a sequence of events and yet is continuously true throughout the interval of time \noccupied by that sequence. In fact, this is as it should be, because the idea of temporal logic \nformulae using S and U is that they should characterise a particular situation in time. The \nessence of a sequence of events is that the situation at the end of the sequence is not the same \nas the situation at the beginning, so we cannot expect a single formula with S and U to both \ncharacterise a sequence and to be true at both its end and its beginning. If we want to replace a \nsingle term in an in-time temporal-logic formula with a term representing a complete \nsequence of events, then that term must be an out-of-time representation. To stand as a single \nterm, the change which constitutes the sequence of events cannot be reflected in a change in \nthe truth value of the term, and so the time of the sequence is not the same as the time of the \nrepresentation. \n3 Temporal measurement in dense time \nModern approaches to human temporal behaviour (see [24], for example) favour models \nbased on oscillators. The same idea can be incorporated into the definition of temporal \nconnectives to add a dimension of measurement to the kinds of representations seen in \nformulae (7) to (12). It is assumed that there is a single oscillator, whose phase at time t is \ngiven by \uf061(t) (0 \uf0a3 \uf061(t) < 1). A new connective SY is like S in the sense that its second \nargument must have been continuously true since its first, and like Y in that this first \nargument must have been true in the previous time unit. \nSY(A, B) =def \uf024t((t < now) \uf0d9 ((\uf061(t) \uf0b3 p1) \uf0da (\uf061(t) < p2)) \uf0d9  \n \uf024s((s < t) \uf0d9 (\uf061(s) < p1) \uf0d9 \uf022u((s \uf0a3  u \uf0a3 t) \uf0ae A(u))) \uf0d9  \n \uf022v(((t < v < now) \uf0ae \uf061(v) \u2260 p1) \uf0da  \n   \uf024w(((t < v < w) \uf0ae \uf061(v) \u2260 p1) \uf0d9 ((w \uf0a3 v < now) \uf0ae \uf061(v) \u2260 p2))) \uf0d9  \n  ((t < v < now) \uf0ae B(v)))) (14) \nThe basic idea is that the oscillator marks the beats of a piece of music. Ideally a beat occurs \neach time the phase is 0, but practically the beat, or notes intended to co-ordinate with the \nbeat, will fall within a range of phase about 0, determined by the constants p1 and p2 (0 < p2 < \np1 < 1). The definition states that SY(A, B) is true if, at the last time when the oscillator was at \na phase between p1 and p2, A was true, and since then B has been continuously true. The \ndefinition for UT(A, B) is similar but looking into the future. \n Now the behaviour of the triangle player required to play a note directly after the cue \nin Figure 2 can be defined by \nSY(SY(SY(A, true), B), C) \uf0ae UT(X \uf0d9 STRIKE \uf0d9 Y, C) (15) \n(Here true effectively stands for \u2018don\u2019t care what event happens\u2019.) \n The period of the oscillator marking the beats should be determined by the playing of \nthe part(s) with which the triangle player must co-ordinate, or by a conductor, who can be \nconsidered to be another player whose \u2018playing\u2019 is silent but which still consists of events \nwith which the triangle player must co-ordinate. An implementation of formula (15) in Pd \nwhich takes the beat from the length of the note A is given in Figure 7, and the objects SY, \nSY1 and UT in Figure 8. The innermost SY is represented by SY1 to fix the period of the \noscillator from the length of the note A. The oscillator is implemented by the \u2018timerOsc\u2019 \nobject, which sends 1 on a background \u2018beat\u2019 channel when the phase passes p1 (here set to \n0.8) and then 0 when it passes p2 (here set to 0.2). It also regularly sends its current phase on \nanother channel (used by the UT object). When the SY object receives 0 on its left inlet, it \nemits 0. If it receives 1, it emits 1 if the right inlet had previously received 1 and if this inlet \nhad received 1 before the last beat (i.e., the previous note had to be sounding before the last \nbeat) and if the beat channel has not received 0 since the last 1 (i.e., the beat has not \u2018passed\u2019). \nIf these conditions are not met, it emits 0. If they are met, it will emit 0 when the next beat \npasses (unless all the conditions are true once again on the next beat; note that these objects \ndo not handle repeated notes well\u2014to do so requires dealing not just with concepts of notes \nsounding but also of notes beginning).  \n \n \nFigure 7. Pd implementation of a solution using SY and an oscillator. \n  \n \nFigure 8. Pd implementations of SY, SY1, and UT. \n \n The UT object takes an argument to specify the amount of anticipation time required \non its output (here 250 milliseconds, to match the 250 milliseconds of roll of the \u2018triangle\u2019 \nobject). It listens for a 1 on its inlet, computes the phase of the oscillator at which to trigger \noutput so that it will co-ordinate with the next occurrence of phase 0 (i.e., the ideal beat), and, \nprovided that the inlet has not received 0, sends a bang when the phase of the oscillator passes \nthe required value. \n Unlike Figure 4, the software in Figure 7 does not require precise playing: the triangle \nsounds whenever the notes A, B and C are played in order and with approximately equal \nduration. However, this is not the behaviour normally required of a triangle player to sound \nthe triangle after the cue in Figure 2. It might be, for example, that the other player sounds A, \nB and C as quavers (i.e., half the length of the beat), or that they are the correct duration but \noff the beat (i.e., syncopated). The mistake is in causing the period of the oscillator to be \ndefined by the duration of the note A. If Figure 2 occurs at the beginning of the piece, one has \nno alternative, but if Figure 2 instead occurs later in the piece, the period of the beat will have \nalready been established earlier. The events of notes a, b and c should influence the beat (the \nother player might be speeding up, for example), but they should not necessarily define it. In a \nmore realistic implementation, the oscillator which models the beat of a performance will pick \nup its period from the playing (or conducting, if there is any, but recall that a conductor is \neffectively just like another player) and then adapt that period to changes in the course of the \nplaying.  \n Software to model this process has been a topic of research for some decades (see \n[25]), and different models perform well in different situations. The example Pd software \nassociated with this article\n*\n includes a crude beat tracker based on the basic idea of [26]. \nWhen used in place of the \u2018timerOsc\u2019 object in Figure 7, and when \u2018SY1\u2019 is replaced by \u2018SY\u2019, \nthe result is the most satisfactory implementation of the solutions to the triangle-player \nproblem offered here. It is not ideal, but the problems which remain are in the beat tracker \n(which can easily lose track of the proper beat) and in the degree of looseness or precision in \nwhere the beat falls (the triangle sometimes sounds when rhythms which clearly deviate from \neven crotchets have been played, but shortening the critical interval of the \u2018beat\u2019 requires the \nplayer to be unnaturally precise in timing). The software thus illustrates that the logic of SY \nassociated with an adaptive beat tracker does allow a specification of a solution to the \ntriangle-player problem. \n3.1 Completeness and decidability of SY and UT \nIt is obvious from inspection of the definitions that SY(A, B) implies S(A, B), and UT(A, B) \nimplies U(A, B). The opposite is not true, however, and indeed the whole point of introducing \nSY and UT was to restrict the truth of statements with these operators to situations where \nnotes were co-ordinated with a beat. If one can know that every note starts and stops within a \nbeat and no note extends over more than one beat, then SY does indeed become equivalent to \nS. The condition can be stated as follows: \n\uf022X\uf024s\uf024t\uf024u((s < t < u) \uf0d9 ((\uf061(s) \u2265 p1) \uf0da (\uf061(s) \u2264 p2)) \uf0d9 (p2 < \uf061(t) < p1)  \uf0d9  \n  ((\uf061(u) \u2265 p1) \uf0da (\uf061(u) \u2264 p2)) \uf0d9 ~X(s) \uf0d9  \n \uf022v(((s < v \u2264 t) \uf0ae ((\uf061(v) \u2260 p1) \uf0d9 X(v))) \uf0d9 ((t \u2264 v < u) \uf0ae ((\uf061(v) \u2260 p2) \uf0d9 X(v)))) \uf0d9 ~X(u))(16) \nSubject to this condition, the completeness results for logics with S and U apply also to a \nlogic with SY and UT also. Its decidability is also similarly contingent on the decidability of \nthe condition. The condition quantifies over notes, but the number of notes in any finite \nformula of SY and UT will be finite and a decision procedure which examines each in turn is \nfeasible. If the starting and finishing time of each note can be determined, then this condition \nis decidable in an ontology of linear time, and so is the entire logic. (Actually, for true \nequivalence to S\/U, the condition needs to be weaker for notes which are referred to only in \nthe first or second argument of an operator, restricting only the end or start time of those \nnotes.) \n                                                 \n*\n Downloadable from http:\/\/www.lancs.ac.uk\/staff\/marsdena\/software\/timing2007 \n SY and UT can also be related to Y and T. If the discrete times of the ontology for \nY\/T are associated with the time intervals between consecutive beats in SY\/UT, then, subject \nto the same condition, SY implies Y and UT implies UT. The reverse is true also if we ensure \nthat there are no gaps between notes at each beat. \n In real music, notes do extend over more than one beat, and they do not all start and \nstop on a beat. The first of these situations can be accommodated by representing single notes \nas a sequence of separate tied notes, each lasting a beat. The second can be accommodated as \ndescribed below, allowing a sequence of notes to occur between two beats. \n4 Metre-based representations and nesting out-of-time representations \nThe problem identified in section 2.3 about incorporating nested-branching representations \neasily into this kind of modal framework can be solved in an ontology of time periods rather \nthan time points. As before, the truth value of propositions depends on the time with respect \nto which they are evaluated, but this time is now a period rather than a point, and intuitively \nwe can think of the situation described by the proposition holding over a period rather than \napplying at a point in time. The special time now must also be conceived as a period rather \nthan a point, and we might think of it being short or long depending on how closely we wish \nto focus on the detail of events. Relations between time periods are more complex than those \nbetween points (which consist only of <, = and > and their disjunctions \uf0a3, \uf0b3 and \uf0b9). In the \ndefinitions below, a symbolic notation for period relations is used ([1], pp.58\u201360), but each \ncase is explained as necessary. \n The operators SY and UT can be redefined with reference to a set of periods M which \nidentifies a continuous sequence of (at least notionally) equal-duration beats. These periods \nare analogous to the intervals between successive instants when the oscillator of the definition \n(14) is at phase 0 (i.e., the periods of the oscillation), or to the beats of a piece of music. \nSY(A, B) =def \uf024s\uf024t\uf024m((m \uf0ce M) \uf0d9 (m -<=-< now) \uf0d9 A(s) \uf0d9 (s <<>> m) \uf0d9 B(t) \uf0d9  \n(t =>- m) \uf0d9 (t -<= now)) (17) \nPeriod relations used in these definitions have the following meanings: x -<=-< y is true when \ny occurs wholly within x, or when x and y are equal; x <<>> y is true if y follows x without a \nbreak; x =>- y is true if x and y start together but y does not end before x; and x -<= y (the \nreverse of x =>- y) is true if x and y end together but x does not start after y. For SY(A, B) to \nbe true at the period now, first we must identify the period m, which we will call the \u2018current \nbeat\u2019, which is the member of the set of periods M which covers now. Then there must be a \nperiod s at which A is true, meeting m, and a period t at which B is true, starting or equal to m \n(=>-) and ending with or equal to now (-<=). UT(A, B) is similar, but s is met by m and t \nstarts with or is equal to now and ends or is equal to m. A diagrammatic representation of \nthese relations is given in Figure 9. \n The period now must not coincide with more than one of the periods in the set M of \nperiods representing beats, otherwise the first part of the definition in (17) above can never be \ntrue: there will not exist a period m which is a member of M within which now is wholly \ncontained. We must assume, therefore, that when the end of a beat occurs, the now period \njumps to the beginning of the following beat. Indeed, the neatest interpretations will arise \nwhen the now periods coincide exactly with beats or subdivisions of beats (a topic discussed \nbriefly below). \n \n \nm \nB \nA \nnow \nM: \nm \nA \nB \nnow \nM: \nSY(A, B) \nUT(A, B) \n \nFigure 9. Diagrammatic representation of the relations SY(A, B) and UT(A, B) in period time. \n \n For SY(A, B) to be true with respect to a time period now which is at the end of a beat \nm, then B must be true throughout that beat (and similarly if now is at the beginning of a beat \nin the case of UT(A, B)). This will always be the case for nested instances such as the inner \nterm SY(A, B) in SY(SY(A, B), C) because, by definition (17), for SY(SY(A, B), C) to be true \nat time now, there must exist a time period s meeting the current beat m at which SY(A, B) is \ntrue. Since the set of beat-periods M is continuous, there must exist a beat immediately before \nm (let us call it m1) whose end (at least) coincides with the end of s, so, by the observation \nabove, SY(A, B) must be true throughout the beat m1.  \n This is particularly important when it comes to nesting out-of-time representations \nwithin SY and UT operators because the nesting means that the truth of these nested \nrepresentations is always evaluated with respect to a period which is an entire beat, \nfacilitating the definition of the meaning of out-of-time representations in logical terms. In the \ndefinitions below, a propositional variable such as A can take a value which is either a simple \nproposition representing an event (such as the sounding of a note), a compound proposition \nusing SY and\/or UT, or an out-of-time representation with enclosing curly brackets {} \n(equivalent to the \u2018metrical event structures\u2019 described in [1] pp.99\u2013100). In the case of a \nnote-like event, it is natural to think that if a proposition is true with respect to a particular \nperiod, then it is also true with respect to each of its subperiods. The same is true of \ncompound propositions whose last term is a simple proposition. The purpose of nested out-of-\ntime representations, however, is precisely to represent situations which do not persist \nthroughout a period but in which truth varies through the period. Thus a term \u2018simple(A)\u2019 is \nemployed in the first definition below which identifies either propositions which represent a \nsingle event or compound propositions whose last term is simple. (Recall that A(t) means \u2018A \nevaluated with respect to time t\u2019.) \nsimple(A) \uf0ae (A(t) \uf0ab \uf022s((t -<=-< s) \uf0ae A(s))) (18) \n{A}(t) \uf0ab A(t) (19) \n{A \/ B}(t) \uf0ab {A}(t) \uf0d9 {B}(t) (20) \n{A B}(t) \uf0ab \uf024r\uf024s((t =<< r) \uf0d9 (r <<>> s) \uf0d9 (t <<= s) \uf0d9 (r =d s) \uf0d9 A(r) \uf0d9 B(s)) (21) \n{A B C}(t) \uf0ab \uf024q\uf024r\uf024s((t =<< q) \uf0d9 (q <<>> r) \uf0d9 (r <<>> s) \uf0d9 (t <<= s) \uf0d9 (q =d r =d s) \uf0d9  \nA(q) \uf0d9 B(r) \uf0d9 C(s)) (22) \n\u2026 \nFormula (18) defines the condition of persistence: if A is a simple proposition true at time t, \nthen it is true at all subperiods of t, and inversely if it is true at all subperiods of a period t, \nthen it is true at t. Formula (19) handles the redundant case of a single event (whether \ncomplex or simple). Formula (20) covers cases of events occurring in parallel. (It can be \napplied recursively for more than two events or sequences occurring in parallel.) Formulae \n(21), (22) and the ellipsis cover the cases of successive events. Time periods for each \nconstituent event are identified which follow each other immediately (identified by the \n\u2018<<>>\u2019 relations) and of which the first starts (\u2018=<<\u2019) and the last finishes (\u2018<<=\u2019) the period \nof the overall sequence (period t), and which are all of equal duration (indicated by the \nrelation \u2018=d\u2019). Since, by the argument above, any representation of this type nested within the \nfirst argument of an operator SY or UT will be evaluated with reference to a beat-period in \nplace of t, the effect of these definitions is that the interpretation is indeed equivalent to that of \nthe metrical event structures described in [1]: each top level structure enclosed within brackets \n{} corresponds to a beat, and sequences of events or structures with brackets correspond to \nequal subdivisions of the beat. \n With SY, UT and the definitions of out-of-time structures, we can now neatly \nrepresent situations in which notes are not all of the same duration. For example, x and y \ntogether following the sequence a, b, c, d, with the rhythm \uf0b1 \uf0d6\uf0b5 \uf0b1 \uf0b1) can be represented by the \nformula \nSY(SY(SY(A, true), {B C}), D) \uf0ae UT(X \uf0d9 STRIKE \uf0d9 Y, D) (23) \n On the other hand, a situation where notes c and d are the shorter notes (and the \nrhythm is \uf0b1 \uf0b1 \uf0d6\uf0b5 \uf0b1), should be defined without an out-of-time representation, since now falls \nwithin the subdivided period, and so we cannot assume that the left-hand side will be \nevaluated with respect to a period equivalent to an entire beat. The solution is to adapt the SY \noperator so that it can use not just the set of periods representing beats, but also sets of periods \nwhich represent subdivisions of beats. Thus a superscript is introduced to the SY (and UT) \noperators to represent by how much the period should be subdivided. This models the \nbehaviour of a triangle player who, in a situation like this, directs attention not at the beats but \nat half beats. In the case of SY\nn\n (or UT\nn\n), the period of the oscillator is divided by n, or the \nperiods of M are each subdivided into n equal-duration periods. SY\n1\n (or UT\n1\n) is thus \nequivalent to SY (or UT). (n must be a constant and a natural number and will normally only \nhave the value 1, 2, 3, or their multiples.) Requiring a triangle strike and the note y following \nthe sequence a, b, c, d, with the rhythm \uf0b1 \uf0b1 \uf0d6\uf0b5 \uf0b1 can now be represented by \nSY\n2\n(SY\n2\n(SY(SY(A, true), B), C), D) \uf0ae UT2(X \uf0d9 STRIKE \uf0d9 Y, D) (24) \nNote that formula (24), and others like it, can be translated to involve only one value of \nsuperscript by splitting events occurring within the scope of operators: \nSY\n2\n(SY\n2\n(SY\n2\n(SY\n2\n(SY\n2\n(SY\n2\n(A, true), A), B), B), C), D) \uf0ae UT2(X \uf0d9 STRIKE \uf0d9 Y, D) (25) \n In fact, it will always be possible to express the equivalent of any formula by using as \nsuperscript to SY and UT the least common multiple of all the superscripts used in that \nformula. If one ignores ornaments (on which players are not generally required to co-\nordinate), music notation always expresses durations in integer multiples and divisions \n(modulated by changes in tempo). Thus a lowest common multiple can always be determined \nfrom a pre-existing score, and so the completeness and decidability results adumbrated in \nsection 3.1 above apply here also. \n5 Conclusion \nThree different levels of logical description of musical timing requirements have been \nproposed: one assuming discrete time determined by the representing mechanism, one using \ndense time and assuming the existence of an oscillator to mark out phases of time passing, \nand one using an ontology of time periods and assuming the existence of a set of beat periods \nwith which events are coordinated. The three levels correspond to different levels of focus. \nThe lowest is appropriate for the low-level design of musical automata where the mechanism \nimposes some quantisation of time (e.g., in the rate of an analogue-to-digital converter). The \ndense-time oscillator level is appropriate for higher-level implementation in, perhaps, a class \nof automata which operate with different actual quantisations of time. The period-time metre \nlevel is appropriate for describing human cognition of timing. The differences in complexity \nare seen where the most complex formulae are required at the lowest, discrete, level of \nrepresentation, but the least needs to be assumed in the implementation mechanism. At the \nintermediate level, an oscillator mechanism is required for implementation, and at the highest \nlevel this mechanism needs to be very much more complex in a satisfactory implementation, \nbut the representation formulae can be simplest. Translations between the levels of \nrepresentation are defined, and they come eventually full circle where the metre-based \nrepresentation can be seen to be equivalent to a discrete-time representation with a long time \nquantum. \n Metre has not been demonstrated to be essential for coordination in music, but these \nformulations do suggest its significance in facilitating coordination. Perhaps this is why it is \ncommon in many kinds of music to have a layer of music which clearly defines the beat (e.g., \na drum part). It is possible for timings in ensemble performance to be determined by other \nmeans. In Lutos\u0142awski\u2019s Preludes and Fugue for 13 Solo Strings, for example, players watch \na conductor for a signal to stop repeating a segment of music. In Cage\u2019s Two2 for two pianos, \nthe pianists must wait for each other to complete one segment before they start another. \nHowever, I do not know of any case where two musicians are required to cause sounds to \nhappen at the same time without using metre to facilitate co-ordination. Furthermore, the data \non production of polyrhythms (patterns of note occurring at more than one regular interval) \n[27] suggests that musicians produce such rhythms by subdividing a single beat, and that only \nsimple subdivisions can be reliably produced. \nReferences \n[1] Marsden, A. (2000). Representing Musical Time: A Temporal-Logic Approach. Lisse: \nSwets & Zeitlinger. \n[2] Kunst, J. (1978). Making Sense in Music: An Enquiry into the Formal Pragmatics of Art. \nGhent: Communication & Cognition. \n[3] Kunst, J. & Van den Bergh, H. (1984). The analysis of musical meaning: a theory and an \nexperiment. Interface, 13, 75\u2013106. \n[4] Leman, M. (1985). Dynamical-hierarchical networks as perceptual memory \nrepresentations of music. Interface, 14, 125\u2013164. \n[5] Leman, M. (1986). A process model for musical listening based on DH-networks. CC-AI, \nJournal for The Integrated Study of Artificial Intelligence, Cognitive Science and Applied \nEpistemology, 3, 225\u2013239. \n[6] Leman, M. (1989). Adaptive dynamics of musical listening. Contemporary Music Review, \n4, 347\u2013362. \n[7] Camurri, A. (1993). Applications of artificial intelligence methodologies and tools for \nmusic description and processing. In G. Haus (ed.) Music Processing, Oxford: Oxford \nUniversity Press, 233\u2013266. \n[8] Camurri, A., Frixione, M. & Innocenti, C. (1994). A cognitive model and a knowledge \nrepresentation system for music and multimedia. Journal of New Music Research, 23, 317\u2013\n347. \n[9] Camurri, A., Haus, G. & Zaccaria, R. (1986). Describing and performing musical \nprocesses by means of Petri nets. Interface, 15, 1\u201323. \n[10] Haus, G. & Rodriguez, A. (1993). Formal music representation; a case study: the model \nof Ravel\u2019s Bolero by Petri nets. In G. Haus (ed.) Music Processing. Oxford: Oxford \nUniversity Press, 165\u2013232. \n[11] Gabbay, D.M., Finger, M. & Reynolds, M. (2000). Temporal Logic: Mathematical \nFoundations and Computational Aspects (v.2). Oxford: Oxford University Press. \n[12] Rescher, N. & Urquhart, A. (1971). Temporal Logic. Vienna & New York: Springer. \n[13] Van Benthem, J.F.A.K. (1983). The Logic of Time. Dordrecht: D.Reidel. \n[14] Galton, A. (1987). Temporal logic and computer science; an overview. In A. Galton (ed.) \nTemporal Logics and their Applications. London: Academic Press, 1-52. \n[15] Gabbay, D.M., Hodkinson, I. & Reynolds, M. (1994). Temporal Logic: Mathematical \nFoundations and Computational Aspects (v.1). Oxford: Oxford University Press. \n[16] Zhou, C., Hoare, C.A.R. & Ravn, A.P. (1991). A calculus of durations. Information \nProcessing Letters, 40, 269\u2013276. \n[17] Fr\u00e4nzle, M. (1996). Synthesizing controllers from duration calculus. In B. Jonsson & J. \nParrow, Formal Techniques in Real-Time Fault-Tolerant Systems (Lecture Notes in Computer \nScience, no. 1135), Berlin: Springer-Verlag, 168\u2013187. \n[18] Rueda, C. & Valencia, F. (2004). On validity in modelization of musical problems by \nCCP. Soft Computing, 8, 641\u2013648. \n[19] Rueda, C., Assayag, G. & Dubnov, S. (2006). A concurrent constraints factor oracle \nmodel for music. XXXII Conferencia Latinoamericana de Inform\u00e1tica CLEI 2006, Santiago, \nAugust 2006. http:\/\/mediatheque.ircam.fr\/articles\/textes\/Rueda06a\/, last accessed 9 May \n2007. \n[20] Desainte-Catherine, M. & Allombert, A. (2005). Interactive score: a model for specifying \ntemporal relations between interactive and static events. Journal of New Music Research, \n34, 361\u2013374. \n[21] Gabbay, D.M. (1987). The declarative past and imperative future. In Temporal Logic in \nSpecification, Berlin: Springer-Verlag, 407\u2013448. \n[22] Marsden, A. (1992). Modelling the perception of musical voices: a case study in rule-\nbased systems. In A. Marsden & A. Pople (Eds.) Computer Representations and Models in \nMusic, London: Academic Press, 239\u2013263. \n[23] Puckette, M. (n.d.). Pure Data (computer software), \nhttp:\/\/crca.ucsd.edu\/~msp\/software.html, last accessed 9 May 2007. \n[24] Beek, P.J., Peper, C.E. & Daffertshofer, A. (2000). Timekeepers versus nonlinear \noscillators: how the approaches differ. In P. Desain & L. Windsor (eds.), Rhythm \nPerception and Production, Lisse: Swets & Zeitlinger, 9\u201333. \n[25] Dixon, S. (2001). Automatic extraction of tempo and beat from expressive performances. \nJournal of New Music Research, 30, 39\u201358. \n[26] Toiviainen, P. (2001). Real-time recognition of improvisations with adaptive oscillators \nand a recursive Bayesian classifier. Journal of New Music Research, 137\u2013147. \n[27] Summers, J.J. (2000). The learning and transfer of multifrequency patterns. In P. Desain \n& L. Windsor (eds.), Rhythm Perception and Production, Lisse: Swets & Zeitlinger, 69\u201380. \n \n"}
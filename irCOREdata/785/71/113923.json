{"doi":"10.1080\/0954009021000039639","coreId":"113923","oai":"oai:epubs.surrey.ac.uk:3021","identifiers":["oai:epubs.surrey.ac.uk:3021","10.1080\/0954009021000039639"],"title":"Connectionist simulation of quantification skills","authors":["Ahmad, K","Casey, M","Bale, T"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2002-09-01","abstract":null,"downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"TAYLOR & FRANCIS LTD","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:3021<\/identifier><datestamp>\n      2017-10-31T14:07:32Z<\/datestamp><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:436F6D707574696E67<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/3021\/<\/dc:relation><dc:title>\n        Connectionist simulation of quantification skills<\/dc:title><dc:creator>\n        Ahmad, K<\/dc:creator><dc:creator>\n        Casey, M<\/dc:creator><dc:creator>\n        Bale, T<\/dc:creator><dc:publisher>\n        TAYLOR & FRANCIS LTD<\/dc:publisher><dc:date>\n        2002-09-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:rights>\n        attached<\/dc:rights><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/3021\/2\/2002_ahmad_casey_bale_connectionist_simulation_of_quantification_skills.pdf<\/dc:identifier><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/3021\/4\/licence.txt<\/dc:identifier><dc:identifier>\n          Ahmad, K, Casey, M and Bale, T  (2002) Connectionist simulation of quantification skills   CONNECTION SCIENCE, 14 (3).  pp. 165-201.      <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1080\/0954009021000039639<\/dc:relation><dc:relation>\n        10.1080\/0954009021000039639<\/dc:relation><dc:language>\n        English<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/3021\/","http:\/\/dx.doi.org\/10.1080\/0954009021000039639","10.1080\/0954009021000039639"],"year":2002,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"Connectionist Simulation of Quantification Skills \nKhurshid Ahmad, Matthew Casey and Tracey Bale \nCentre for Knowledge Management, Department of Computing, School of Electronics \nand Physical Sciences, University of Surrey, Guildford, Surrey, GU2 7XH, UK. \nCorrespondence and offprint requests to: Professor K. Ahmad, Centre for Knowledge \nManagement, Department of Computing, School of Electronics and Physical \nSciences, University of Surrey, Guildford, Surrey, GU2 7XH, UK.  Tel:  01483 \n689322.  Fax: 01483 686051.  E-mail: k.ahmad@surrey.ac.uk. \nRunning head: Multi-net Simulation of Quantification \nKeywords: Multi-net, modularity, mixture-of-experts, gating neural networks, \nrecurrence, quantification, numerosity discrimination, subitizing, counting. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 2 of 42 \nContents \nCONNECTIONIST SIMULATION OF QUANTIFICATION SKILLS ............................................1 \nCONTENTS .................................................................................................................................................2 \nABSTRACT .................................................................................................................................................3 \n1 INTRODUCTION...............................................................................................................................3 \n1.1 SUBITIZING: NUMERICAL DISCRIMINATION AND VISUAL ENUMERATION ....................................4 \n1.2 COUNTING: RECURRENCE AND THE IMPOSITION OF ORDER ..........................................................5 \n1.3 MULTI-NET ARCHITECTURES ..........................................................................................................6 \n2 \u2018NEURONAL\u2019 SIMULATIONS OF SUBITIZATION AND COUNTING................................7 \n2.1 SIMULATING SUBITIZATION ............................................................................................................9 \n2.1.1 Learning Internal Representation........................................................................................9 \n2.1.2 A Connectionist Approach to Children\u2019s Seriation...........................................................10 \n2.1.3 SUBIT-PDP: \u2018Subitizing Phenomenon as an Emergent Property of the Human Cognitive \nArchitecture\u2019........................................................................................................................................12 \n2.1.4 A Neuronal Model of Elementary Numerical Abilities .....................................................13 \n2.2 SIMULATING COUNTING................................................................................................................14 \n2.2.1 Counting Chimes ................................................................................................................14 \n2.2.2 Ma and Hirai\u2019s Heteroassociative Network ......................................................................14 \n2.2.3 A Recurrent Neural Network that Learns to Count...........................................................15 \n3 SSUBSYST: A NEURAL SIMULATION OF SUBITIZATION ...............................................15 \n3.1 SSUBSYST ARCHITECTURE ........................................................................................................16 \n3.1.1 Mapping Module.................................................................................................................17 \n3.1.2 Magnitude Representation Module....................................................................................18 \n3.1.3 Output Module ....................................................................................................................18 \n3.2 SSUBSYST TRAINING .................................................................................................................19 \n3.2.1 Scale Invariant Network .....................................................................................................19 \n3.2.2 Translation Invariant Network...........................................................................................19 \n3.2.3 Magnitude Representation Network ..................................................................................20 \n3.2.4 Verbal Output Module........................................................................................................21 \n3.2.5 Multi-net Training ..............................................................................................................21 \n3.3 SSUBSYST TESTING ...................................................................................................................22 \n3.3.1 Testing Strategy ..................................................................................................................22 \n3.3.2 Validating SSUBSYST ........................................................................................................22 \n4 SCOUSYST: A NEURAL SIMULATION OF COUNTING......................................................25 \n4.1 SCOUSYST ARCHITECTURE .......................................................................................................26 \n4.1.1 Mapping Module.................................................................................................................28 \n4.1.2 Counting Module ................................................................................................................28 \n4.1.3 Output Module ....................................................................................................................29 \n4.2 SCOUSYST TRAINING.................................................................................................................29 \n4.2.1 Scale Invariant Network .....................................................................................................29 \n4.2.2 Counting Module: Training the Gated \u2018Word\u2019 and \u2018Next-Object\u2019 Subsystems...............30 \n4.2.3 Output Network...................................................................................................................30 \n4.3 SCOUSYST TESTING...................................................................................................................31 \n4.3.1 Testing Strategy ..................................................................................................................31 \n4.3.2 Comparison of SCOUSYST\u2019s Output with Child Development Data...............................31 \n4.3.3 Generalisation in SCOUSYST............................................................................................34 \n5 CONCLUSIONS ...............................................................................................................................35 \nREFERENCES ..........................................................................................................................................38 \nMulti-net Simulation of Quantification \n27\/02\/04 Page 3 of 42 \nAbstract \nThe study of numerical abilities, and how they are acquired, is being used to explore \nthe continuity between ontogenesis and environmental learning.  One technique that \nproves useful in this exploration is the artificial simulation of numerical abilities with \nneural networks, using different learning paradigms to explore development.  A neural \nnetwork simulation of subitization, sometimes referred to as visual enumeration, and \nof counting, a recurrent operation, has been developed using the so-called multi-net \narchitecture.  Our numerical ability simulations use two or more neural networks \ncombining supervised and unsupervised learning techniques to model subitization and \ncounting.  Subitization has been simulated using networks employing unsupervised \nself-organising learning, the results of which agree with infant subitization \nexperiments and are comparable with supervised neural network simulations of \nsubitization reported in the literature.  Counting has been simulated using a multi-net \nsystem of supervised static and recurrent backpropagation networks that learn their \nindividual tasks within an unsupervised, competitive framework.  The developmental \nprofile of the counting simulation shows similarities to that of children learning to \ncount and demonstrates how neural networks can learn how to be combined together \nin a process modelling development. \n1 Introduction \nThere is considerable discussion in the literature about how human knowledge of \nnumbers and number systems develops and to what extent such knowledge is, in some \nways, innate.  Brannon (2002), in her review of the development of \u201cnumerical \nknowledge\u201d, argues that such development shows evolutionary and ontogenetic \ncontinuity; the latter being the more controversial proposal.  Evolutionary continuity \nrelates to the literature on how number systems are represented by adult humans and \nanimals whereas ontogenetic continuity deals with the numerical abilities of infants \nand how these abilities grow into a numerate adult (2002:223-224). \nBrannon concentrates upon ordinal numerical knowledge, including ordinal relations \nbetween numerical values.  Here, the distinction is drawn between ordinal relations \nwhich allow an understanding that, for example, 16 is numerically more than 8, but \nthat ordinal numerical knowledge is required to understand the ordinal direction of a \nsequence of ordered numbers.  Her findings suggest that infants as young as 11 \nmonths of age are sensitive to ordinal relations but that this does not necessitate \nordinal numerical knowledge.  This is in contrast to Dehaene and Changeux\u2019s (1993) \nprediction, based on an artificial neural network (ANN), which suggests that such \nknowledge develops between 9 and 11 months of age. \nThe use of ANNs to model numerical abilities allows psychologists to explore models \nof numerical processing systems in comparison with observational data, especially \nfrom developmental and disability data related to numerical evolution and ontogenesis \n(see Nye et al 1995, Butterworth 1999 and Dehaene 2000).  Mareschal and Johnson \ncite the use of such computational models to \u2018provide rigorous and tangible accounts \nof development\u2019 (2002:154).  Here \u2018the modeler is forced to make explicit what is \nmeant by \u2018representation\u2019, \u2018acquired knowledge\u2019 [and] \u2018innate knowledge\u2019\u2019, to \nprovide \u2018a set of possible solutions\u2019 (2002:154-155).  These possible solutions are also \nthemselves the cause of debate and can sometimes cloud the core issues, as noted by \nMulti-net Simulation of Quantification \n27\/02\/04 Page 4 of 42 \nCohen and Chaput who \u2018admit that [their] own attempts [to model cognitive \ndevelopment] influence [the] view of other models\u2019 (2002:173). \nDespite the apparent problems, modelling numerical abilities is important.  For \ninstance, ANNs have been used extensively to model quantification skills, including \nsubitization, the so-called phenomenon of the discrimination of visual number, and \ncounting, the ability to impose order on a set of objects by virtue of an abstract \nnumber system.  However, whilst these models have generated a number of different \navenues of research (see, for example, Dehaene 2000), they have not tended to \ndirectly address an understanding of the continuity between ontogenesis and \nenvironmental learning.  Instead, the majority have either modelled innateness by \nignoring learning (Dehaene and Changeux, 1993) or have allowed systems to develop \nthrough a process of external tutoring, a supervised learning technique that can be \nlikened to environmental learning (Mareschal and Shultz 1999, Rodriguez et al 1999, \nPeterson and Simon 2000).  Earlier on, Dehaene suggested that experiments on \nchildren have shown that \u2018the truth [\u2026] seems to stand somewhere between the \u201call \ninnate\u201d and \u201call acquired\u201d extremes\u2019 (1997:119), but there has been little done to \nexplore this with ANNs.  These relationships can be explored through ANN \ntechniques such as unsupervised learning, where a system can undergo a process of \nlearning without a teacher.  Furthermore, a combination of both supervised and \nunsupervised techniques can be achieved through multi-net systems, allowing further \nexploration of the continuity between ontogenesis and environmental learning. \nIn this paper, we review different models of subitization and counting, from earlier \nexperiments that explored numerically related abilities through to models that deal \ndirectly with specific numerical processing.  The majority of these models either deal \nwith development through hard-wired connections or through learning with a teacher.  \nWe conclude that techniques using unsupervised learning warrant investigation, and \ngo on to discuss two models that we have developed as a consequence of this: one \nsimulates aspects of subitization and one counting.  Both use unsupervised learning \nwithin multi-net systems to demonstrate how different types of learning can be used to \nexplore the relationship between ontogenesis and environmental learning.  Our \nsystems perform as well as, if not marginally better than, other reported simulations, \nsuch as Peterson and Simon (2000), Amit (1988) and Dehaene and Changeux\u2019s \n(1993), with our results comparing favourably with that observed in children. \n1.1 Subitizing: Numerical Discrimination and Visual Enumeration \nTwo early studies throw some light on the phenomenon of subitization:  Jevons \nsuggested that subitization is related to \u2018the power of numerical discrimination\u2019 \n(1871); Kaufman et al talked about discrimination of visual number (1949).  More \nrecently, Peterson and Simon define subitizing as \u2018the process associated with \nenumeration of small collections\u2019 (2000:94).  The results of systematic observations \non humans suggest that whilst the time it takes to visually enumerate objects \nlengthens as the number of objects in a typical visual scene increases, there is a \ndiscontinuity in the rate of change of reaction time with the number of objects \u2013 up to \n50 msec\/object for scenes containing up to three objects rising to 250-300 msec\/object \nfor scenes containing four or more objects (see, for example, Trick and Pylyshyn \n1994).  Furthermore, the accuracy of visual enumeration or subitization decreases as \nthe number of objects increases, and again the decrease is accelerated for higher \nnumerosities.  This suggests that the subitization task is subject to a \u2018subitizing limit,\u2019 \nMulti-net Simulation of Quantification \n27\/02\/04 Page 5 of 42 \nthat is visual enumeration is limited to smaller numerosities of up to three or four, and \nthat \u2018subitizing slope\u2019 shows a marked change for higher numerosities. \nThere are two major strands of thought in psychology about the nature and function of \nsubitization.  The first strand can be dated to the publication of a paper by Kaufman et \nal (1949) who suggested that subitizing is the apprehension of numerosity \nimmediately upon presentation, without the need to resort to any form of counting.  \nThis view has been criticised by Gelman and Gallistel (1978) who argued that \nsubitization is a form of preverbal counting.  The second strand of thought has its \norigins in the work of Mandler and Shebo (1982).  They have argued that adults learn \nto subitize through the recognition of canonical patterns.  There is substantial \nopposition to this view.  For example, Wynn (1995) has argued that the ability to \nsubitize is inborn and hence independent of any number system (see also, Strauss and \nCurtis, 1984; Sophian and Adams, 1987; Fuson, 1988; Wynn 1992a, b; Kirby, 1992 \nand Spelke, 1994).   \n1.2 Counting: Recurrence and the Imposition of Order \nCounting requires an analysis of the visual scene to ascertain the presence or absence \nof objects irrespective of their size.  Once a size invariance has been established, \ncounting requires some other capabilities of a numerosity system in contrast to \nsubitization.  This difference can be elaborated by the earlier observations of Donald \nHebb, and their more recent refinement by Daniel Amit (1989), on the topic of \ncounting identical chimes to tell the hour; identical chimes are the acoustic equivalent \nof size invariant objects abstracted from a visual scene.  According to Amit such \ncounting has \u2018several dimensions\u2019 (Amit 1989:241-245) which will form the basis of \na \u2018connectionist\u2019 counting system:  (i) the system should be able to recognise the \narrival of several identical stimuli through \u2018some short term memory mechanism that \ndoes not transform into long term memory\u2019; (ii) the system should be able to identify \n\u2018a generic chime in order to provoke counting\u2019; and,  (iii) the system should be able to \ndiscriminate \u2018between different temporal sequences of chimes, according [to] the \nabstract property which is their cardinal number\u2019 (Amit 1989:241).  There is a \nsuggestion that in order to recognise the \u2018several identical stimuli\u2019 one needs to \nemploy recurrent networks.  The ability to identify and discriminate are learnt with \nthe help of a tutor who can provide training in how to start and to continue counting \nand how to assign the cardinality to the visual scene (or acoustic input) as a whole.   \nFor some authors, counting is a learnt process by which an accurate value for the \nnumerosity of a set of items can be determined through the use of a serial set of rules \nand short-term memory, allowing a pairing of objects with numeric labels from a \nnumber system.  Gelman and Gallistel (1978) proposed the five \u2018how-to-count\u2019 \nprinciples by which counting can be defined: one-to-one correspondence, stable order, \ncardinality, abstraction and order irrelevance.  Gelman and Meck (1983) identified the \nfirst three of these principles as the counting procedure, the fourth as to which types \nof set counting can be applied, and the fifth distinguishes counting from labelling.  \nFuson et al (1982) and Fuson (1988) investigated the types of errors that are made by \nchildren when counting.  Word errors produced during the counting sequence are \ncharacterised within three sections: stable and conventional, stable and non-\nconventional, and unstable and non-conventional.  Additional word errors concern the \nreduced frequency of production of irregular number words, and the strong \nassociation between a number word and the two previous words.  Fuson also \nidentified the two main pointing errors made by children as \u2018object skipped\u2019, where a \nMulti-net Simulation of Quantification \n27\/02\/04 Page 6 of 42 \nchild will miss pointing at an object, and \u2018multiple count\u2019, where a child will point at \nan object more than once. \n1.3 Multi-net Architectures \nThe simulation of the development of numerosity in humans, from subitizing in \ninfancy, through to counting in childhood, and the retention of both abilities in later \nlife, appears an important challenge for modular artificial neural network systems.  \nThe challenge lies in the selection, training and the subsequent testing of the different \nmethods of combining artificial neural network modules; these multi-net methods \ninclude the four proposed by Sharkey (1999): co-operative, competitive, sequential \nand supervisory. \nCo-operative systems allow a group of networks to co-operate to produce an output, \nfor example through the averaging of all the outputs.  Competitive systems allow \ngroups of networks to compete for the right to process a particular input signal, and \ncan subsequently be trained to better respond to that signal in a winner-take-all \nfashion.  Sequential systems allow the output of one network to become the input to \nanother, allowing a chain of processing to be performed.  Supervisory systems look at \nhow learning can be improved through the use of a network that can be taught \noptimum learning parameters, which can then be applied to improve learning in \ndifferent networks. \nWe propose that the constituent networks of a modular ANN may have to be trained \nusing algorithms for unsupervised learning, particularly for simulating subitizing, and \nusing algorithms for supervised or reinforcement learning, especially for simulating \ncounting.  Supervised learning can be compared with the effects of the environment \nover the organism, where environmental input supervises learning.  Unsupervised \nlearning can be compared with an organism\u2019s built-in self-motivation.  Within the \nmulti-net methods described by Sharkey, networks employing both unsupervised and \nsupervised learning in a modular system can be used in competitive and sequential \nconfigurations.  Relating this to the simulations presented in this paper, we can see \nthat counting involves learning a number system and associated number words, with \nsome sense of addition and subtraction.  The number system is not acquired \nspontaneously but appears to be taught.  Conversely, it is not intuitively possible to \nthink that subitization could be taught.  These contrasting approaches helped us to \ndefine a simulation framework in which both supervised and unsupervised techniques \nare important. \nWe start this paper with a review of the different simulations of numerical abilities \nthat have been performed, both using single network systems and multi-nets (section \n2).  Next we describe how modular multi-net neural systems can be trained to \nsimulate subitization and to simulate counting.  The subitizing system (section 3) can \napprehend numerosity of up to 5 objects fairly accurately; this system uses a \nsequential multi-net system including two Kohonen (1997) Self Organising Maps \n(SOMs), one for representing magnitude of numbers and the second to articulate \nnumerosity \u2013 the two SOMs are linked to each other through a Hebbian network.  Our \nsystem performs as well as, if not marginally better than, other reported simulations of \nsubitization by Peterson and Simon (2000) who used a backpropagation network.  Our \ncounting system (section 4) is a competitive gated multi-net system that uses a \nrecurrent backpropagation network for learning, using a short-term memory to keep \ntrack of counting without transforming this information into a long-term memory.  \nMulti-net Simulation of Quantification \n27\/02\/04 Page 7 of 42 \nThe counting system uses two gates: one feedforward network to point to the next \nobject and the other to articulate the count.  The system performs as well as Amit\u2019s \nneural attractor system (1988) for counting chimes and as well as Dehaene and \nChangeux\u2019s (1993) for counting objects in a visual scene.  Section 5 presents the \nconclusions.  First, the our simulations show that if there are dedicated \u2018cortical \nterritories\u2019 in the brain for apprehending numerosity, they might comprise a \ndistributed system whose components deploy a range of learning algorithms.  Second, \nwe show that one artefact of artificial neural simulation of subitization is the so-called \nedge effect: the lowest and highest numerals in a sequence of displays with different \nnumerosities are learnt more accurately than all others.  Third, we show that better \nmethods are required to deal with the visual scene particularly the way in which the \nscene is abstracted into a collection of objects independent of the size and location of \nthe object.   \n2  \u2018Neuronal\u2019 Simulations of Subitization and Counting \nStudies on both animals and humans have attempted to demonstrate that basic \nnumerical abilities are biologically based and consequent of evolutionary processes \n(see, for example, Thompson et al 1970, Meck and Church 1983, Wynn 1995, \nBrannon and Terrace 1998).  Dehaene\u2019s experiments (2000, 1997) highlight that when \ncomparing the numerosity of sets of objects, both humans and animals encounter \ndistance and magnitude effect phenomena.  The fact that the greater occurrence of \nerrors found when comparing numbers that are close together in magnitude as \nopposed to further apart is known as the distance effect, and the magnitude effect is \nthe drop in performance observed when comparing numbers that are equal in distance, \nbut have larger magnitudes.  In addition, Fechner\u2019s law states that the perceived \nintensity of a number stimulus is proportional to the logarithm of the actual intensity, \nhence the internal representation of number is compressed at higher magnitudes. \nNumerical processing has also been studied by comparing the behaviour of randomly \nselected persons with those of brain-damaged patients (see Dehaene 2000; \nButterworth 1999 and references therein for details).  These neuro-cognitive and \nneuro-biological studies have lead to the formulation of several models of processing \nbasic numerical ability.  Such abilities include quantification, transcoding and \ncalculation, and require different representations of number for different tasks, \nincluding abstract, written and auditory.  From these contrastive studies one is led to \nconclude that numerical processing takes place in specific areas in the parietal and \ntemporal lobes of the brain.  In the parietal lobe there is a cluster of neurons that is \nused to represent the magnitude of quantities observed.  The magnitude representation \ncluster or network interacts with another distinct cluster that is used to store (and \nretrieve) the visual number form; this network is located in the temporal lobe.  The \narithmetic facts are articulated through the use of yet another cluster in the left \nhemisphere \u2013 the so-called verbal system.  This tripartite model, also referred to as the \ntriple code model, comprising networks for representing magnitude, encoding visual \nnumber form and for articulating arithmetic facts, is originally due to Dehaene (1997). \nA number of other models have been proposed for understanding numerical \nprocessing in the human brain.  Different areas have been suggested where the \nwritten, auditory and abstract forms of cardinal numbers are represented (see, for \ninstance, McCloskey et al, 1985; and Cipolotti and Butterworth, 1995).  Whilst it is \nimportant to investigate further these claims about this specific brain-areas hypothesis, \nsuch an assumption is of significant import for simulations of numerical processing.  \nMulti-net Simulation of Quantification \n27\/02\/04 Page 8 of 42 \nThese models propose how the quantification tasks of subitizing and counting might \nbe split into simpler subtasks.  For example, Dehaene (1992) encapsulates subitizing \nwithin the abstract number module, and counting within the verbal module. \nThere have been a number of neural network based simulations of arithmetic fact \nlearning reported in the early 1990s.  The factor common to a significant number of \nstudies was that numbers were shown using an analogue number representation; there \nwere reports of systems that used a hybrid system, including analogue and symbolic \nforms.  Table 1 briefly describes the architecture of these systems together with the \nlearning algorithm that was used.  McCloskey and Lindemann (1992) and Dallaway \n(1994) used an analogue representation of number, whereas Anderson et al (1994) \nused a hybrid approach with both an analogue and symbolic representation together.  \nAnderson et al argue that this permits a simple shift between the symbolic patterns \nand their corresponding magnitudes, since the two become associated with each other.  \nThe use of a recurrent network for a system that learns to count appears intuitively \nsuited to the task: counting involves the use of local memory and recurrent systems \ninclude such concepts. \nTable 1: Models of arithmetic fact learning and performance showing the learning \nsystems and number representations they employed. \nSystem Task Learning System Number \nRepresentation \nReference \n  Supervised Systems   \nMATHNET Learning Backpropagation Analogue McCloskey and \nLindemann (1992) \nDallaway Learning and \nPerformance \nBackpropagation \n(with output activation equation) \nAnalogue Dallaway (1994) \n  Unsupervised Systems   \nHybrid Learning Brain-State-in-a-Box \n(recurrence) \nAnalogue and \nsymbolic \nAnderson, Spoehr \nand Bennett (1994) \nIn the following sections we describe neural network based simulations of subitization \n(section 2.1) and of counting (section 2.2) to examine whether, and to what extent, \nneural network based simulations of subitization and counting have a modular \nstructure as proposed by other connectionist modellers.  This review will help in the \nspecification of a modular neural network system for subitization and counting \n(sections 3 and 4). \nMulti-net Simulation of Quantification \n27\/02\/04 Page 9 of 42 \n2.1 Simulating Subitization \n2.1.1 Learning Internal Representation \nIn their major paper describing the utility of error back-propagation networks \nRumelhart et al (1986) solved a number of problems to prove the efficacy of the \nmulti-layer back-propagation network.  A number of these examples were problems \nthat related to a network\u2019s ability to learn how to quantify, and are listed in Table 2.  \nThe emphasis here is on the ability to learn how to quantify, something that we have \nhighlighted as being important in quantification skills, especially counting.  For \nsubitization, our interest in whether this ability can be learnt stems from the argument \nthat (possibly) innate skills develop through a process of self-organisation, something \nthat can be compared with learning algorithms in ANNs. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 10 of 42 \nTable 2: Internal representations learnt by a multi-layer perceptron (Rumelhart et al, \n1986).  Network topology is indicated by input dimension and number of units in each \nlayer.  For example \u2018N-N-1\u2019 indicates a network with an input dimension of N units, a \nhidden layer consisting of N units, and an output layer consisting of 1 unit. \nProblem Architecture Notes Training \/ Performance \nParity N-N-1 \nN-hidden units to solve parity problems \nwith patterns of length N. \n2825 presentations required for recognising \n16 patterns comprising 0s and 1s. \nEncoding N-log2N-N \nNetwork for encoding an N-bit pattern onto \nlog2N pattern (hidden units) and then \nproducing an output based on the encoding. \nDistributed to Local Representation: m input \npatterns mapped onto 2m output patterns. \nSymmetry N-2-1 \nProblem can usually solved by a 2-hidden \nunit network. \n1208 presentations of a six bit pattern.  The \ntrained network has symmetric distribution of \nweights between input and hidden units.   \nBinary Addition 2N-N-(N+1) \nOutput patterns represent sum of two two-\nbit number inputs. \n3020 presentations of input patterns (e.g. \n00+00, 11+11) helped to learn the addition of \n16 input patterns on a 4x3x3 network.   \nIn the solution of the parity and encoding problems, the emphasis was also on the \nposition invariance of the input units, which meant that the system learnt to generate a \nparity signal or an encoding irrespective of whichever input units were on or off. \nThis invariance of the quantification process is fundamental to the nature of the task: \nquantification of a set of objects is independent of their physical attributes of location \nand dimension.  Rumelhart et al have demonstrated this point by suggesting that this \ninvariance is somehow internalised during the training of their networks \u2013 and in their \ncase it was through the adjustment of the weights in the hidden units by the \nbackpropagation algorithm.  This is remarkably similar to the accumulator mechanism \nsuggested by Gallistel and Gelman (1992) \u2013 but more of this later.  This invariance is \ndemonstrated further by Rumelhart et al when they turn \u2018to a more geometric problem \n\u2013 that of discriminating between a T and a C \u2013 independent of translation and rotation\u2019 \n(Rumelhart et al 1986:348).  This problem again has the same essence \u2013 similar \npatterns require greater discrimination, as their solutions are radically different. \n2.1.2 A Connectionist Approach to Children\u2019s Seriation \nMareschal and Shultz (1999) demonstrated a connectionist model of seriation \n(sorting) that explored how neural networks could be used to simulate the \ndevelopment of psychological abilities in children.  Seriation requires an \nunderstanding of magnitude and order, and can therefore be linked to an \nunderstanding of number.  According to Piaget (1952), the development of seriation \npasses through four stages, which can be identified through the sorting moves made \nby children and the final configuration of the sorted items.  Mareschal and Shultz also \nsummarise the six seriation phenomena that any model must exhibit: periods of \nconstant stage-like behaviour, correct ordering of the four seriation stages, transition \nbetween successive stages, better performance with increasing size differences, \nvariation in emergent strategies and gradual stage transitions. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 11 of 42 \nTo demonstrate development in a neural network simulation, Mareschal and Shultz \nused two cascade-correlation networks (Fahlman and Lebiere, 1990), one trained on \nthe \u2018which\u2019 task and the other on the \u2018where\u2019 task.  The input to both cascade-\ncorrelation networks was formed by a six-dimensional vector consisting of a rank \nvalue for each of the six \u2018sticks\u2019 that were to be sorted, with the order detailing the \ncurrent positioning of the \u2018sticks\u2019, the rank equivalent to stick length.  The output of \nboth networks was also a six-dimensional vector; the \u2018which\u2019 network\u2019s output was \nused to indicate which \u2018stick\u2019 was to be moved by activating just one of the six \noutputs; the \u2018where\u2019 network\u2019s output identified the \u2018sticks\u2019 new position. \nCascade-correlation uses an initial network topology without any hidden units, adding \nhidden units algorithmically if learning does not improve by a given amount within a \ncertain number of epochs of training.  Mareschal and Shultz argue that the algorithmic \naddition of hidden units in the cascade-correlation network during training can be \nseen as development, more so than connection weight adjustments, even though the \ntraining algorithm operates in batch mode differing somewhat from the perceived \nlearning in children. \nAfter testing their network, the authors determined that a bias in the training set was \nrequired to ensure that all four stages of development in seriation were simulated.  \nThey determined that a higher proportion of less disordered data, as suggested from \nchild psychological data, was required.  This was achieved by randomly selecting 50 \n(out of a possible 720) \u2018stick\u2019 configuration inputs that had a sum-of-squares distance \nfrom the fully ordered set of less than or equal to 20, and a further 50 with a sum-of-\nsquares distance greater than 20.  Matched with each selected input pattern were the \ntarget outputs formed as two vectors for \u2018stick\u2019 identification and move (complete sets \nof moves were not used as it was suggested that children learn to sort by witnessing \nonly incomplete sequences).  Training proceeded with the selected patterns separately \nfor each network until they were determined to have achieved the fourth \ndevelopmental stage of seriation by producing four consecutive epochs of output with \nthe required criteria. \nThe first three experiments performed explored the learning capabilities of the \nnetworks with differing ranks (\u2018stick\u2019 lengths).  For each experiment 20 pairs of the \n\u2018which\u2019 and \u2018where\u2019 networks were trained, and the stages of development that they \nachieved and the number of epochs required, recorded.  Disappointing results lead to \nthe modification of the training set to include an additional 20 randomly selected \ninput-output pairs drawn from the 24 possible three element series.  Of the 20 \nnetworks that were subsequently trained, all achieved the desired fourth stage of \ndevelopment. \nWith these experiments, Mareschal and Shultz demonstrated that a connectionist \nmodel could demonstrate the four stages of development in seriation, with the stages \nand the six associated seriation phenomena emerging as a consequence of learning \nalone.  Furthermore, they suggested that the failures observed with children \nperforming seriation tasks can be attributed to their inability to sort less and less \ndisordered sets, as with the experiments they performed subsequently, exploring the \nbiasing of the input data. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 12 of 42 \n2.1.3 SUBIT-PDP: \u2018Subitizing Phenomenon as an Emergent Property of the Human \nCognitive Architecture\u2019 \nPeterson and Simon (2000) have compared and contrasted the performance of a \ntypical rule based simulation of subitization with that of a feedforward, fully \nconnected, three layer neural network that learnt to subitize.  The rule-based \nsimulation was based on John Anderson\u2019s ACT-R system (Anderson, 1993) and \nincorporates the use of \u2018counting\u2019, using a number system, and \u2018recognition\u2019, based on \nthe strength of the \u2018trace\u2019 left in the memory proportional to the frequency of the \nstimulus (Anderson, 1993).  The rule-based system has a conflict resolution strategy \nthat mediates between the use of the two procedures, a strategy that can be compared \nwithin neural computing to a gating network.  This type of gated architecture has been \nimplemented by Ahmad and Bale (2001).  \nPeterson and Simon\u2019s SUBIT-PDP system uses the backpropagation algorithm, \ninvestigating the effect of the number of nodes in the hidden layer of their network \nand its effect on the system\u2019s ability to subitize.  The network comprises 16 input and \n6 output units and the number of hidden units ranged from 3 to 5.  SUBIT-PDP was \ntrained and tested for its ability to subitize up to \u20186\u2019.  The test results were positive in \nthat SUBIT-PDP can subitize up to \u20184\u2019, a result which corroborates with observations \non humans discussed above.  However, the performance of the system depends on the \nnumber of hidden nodes and on the maximum numerosity the system has been trained \nto subitize.  The performance of SUBIT-PDP suggested that \u2018subitizing emerges \nthrough experience in this domain rather than being the result of a hardwired \nstructural limit on the representational capacities of the architecture [SUBIT-R]\u2019 \n(Peterson and Simon, 2000:102).   \nFor SUBIT-PDP, the numerosity of a set of objects, irrespective of their size and \nlocation, is represented on a \u2018hypothetical 4 by 4 grid of locations\u2019.  The input vector \ncomprises 16 elements, each corresponding to a cell on the 4 by 4 grid: the binary \ndigits, 1 and 0, indicate the presence or absence of an object.  The desired output is \nrepresented by a 6 element vector to represent numbers 1 to 6.  For example, a group \nof 5 objects can be represented as \u20180100110000010010\u2019.  The desired vector for \u20185\u2019 \nmay be represented by a sequence of binary digits: for example, \u2018000010\u2019.  In this \nrepresentation scheme, there are only 16 patterns for numerosity \u20181\u2019, 120 for \u20182\u2019, 560 \npatterns for \u20183\u2019, 1820 for \u20184\u2019, 4368 for \u20185\u2019 and 8008 for the numerosity \u20186\u2019.  \nSUBIT-PDP was trained on 50000 random patterns and was tested on 25 for each of \nthe six numerosities \u2013 making a total of 150 patterns that were presented to the \nnetwork.  At the onset of training all connection weights (input-to-hidden units and \nhidden-to-output units) are given a random value.  Table 3 shows how the learning \nproceeds for the six numerosities for a 16-3-6 network during a 15000 cycle training \nregimen observed at every 3000 cycles.  The learning threshold, that is the minimum \nactivation level of the output unit above which the network is deemed to have learnt a \ngiven numerosity, was set by the authors at 0.75.  The table shows that whilst the \nsystem had no problem in learning the numerosities \u20181\u2019, \u20182\u2019, \u20184\u2019 and \u20186\u2019, there were \nproblems with \u20183\u2019, learnt only after 9000 cycles of training, and the system could not \nlearn \u20185\u2019 in the 15000 cycles.   \nMulti-net Simulation of Quantification \n27\/02\/04 Page 13 of 42 \nTable 3: Subitization learning in a 16-3-6 network.  If the activation level was above 0.75, \nthen the network is deemed to have successfully learnt and recognised the pattern and \nthis is denoted by a \u221a.  Otherwise learning is deemed to have been unsuccessful and this \nis denoted by an \u00d7.  Note the early \u2018learning\u2019 of the largest numerosity \u20186\u2019.  This persists \nwhenever the numerosity of the training set is increased \u2013 the so-called end effect. \nActivation After Number of Cycles Numerosity \n3000 6000 9000 12000 15000 \n\u20181\u2019 \u221a \u221a \u221a \u221a \u221a \n\u20182\u2019 \u00d7 \u221a \u221a \u221a \u221a \n\u20183\u2019 \u00d7 \u00d7 \u221a \u221a \u221a \n\u20184\u2019 \u00d7 \u221a \u221a \u221a \u221a \n\u20185\u2019 \u00d7 \u00d7 \u00d7 \u00d7 \u00d7 \n\u20186\u2019 \u00d7 \u221a \u221a \u221a \u221a \nPeterson and Simon explain this apparent anomaly by arguing that the numerosity of \n\u20186\u2019 is merely reflecting the \u2018end effect\u2019; note that \u20186\u2019 is the highest possible \nnumerosity for the simulation discussed above and as such the system needs to \ndistinguish \u20185\u2019 from both the numerosities \u20184\u2019 and \u20186\u2019, but \u20186\u2019 needs to be \ndistinguished from \u20185\u2019 only.  Such an observation is in line with the experiments on \nhuman subitization where participants appear to have learned the higher numerosities \nfaster than other numerosities in a given counting range (Mandler and Shebo, 1982).  \nThey argued that the end effect could be rectified by increasing the number of hidden \nunits in the SUBIT-PDP network, which they demonstrated by further experiments.  \nHere, increasing the number of hidden units seems to merely expedite the learning of \nall other numerosities, with training taking a larger number of cycles to complete.  \nThe results show how the end effect shifts to numerosity \u20187\u2019, which SUBIT-PDP fails \nto learn in its modified form, despite having a significantly larger number of hidden \nunits.  However, rather than confirming their argument, the experiments seem to \nsuggest that the subitization limit is not only related to the number of hidden units \nused in the neural network, but also to the highest numerosity present in the training \nset.  \nThe desired vector used by Peterson and Simon to train the network is also quite \ninteresting and relates well to the observations of Gallistel and Gelman\u2019s speculation \nthat numbers are represented through the so-called accumulator mechanism.  Recall \nthe representation used in SUBIT-PDP.  The numerosity of one object or a collection \nof objects is represented by a two component vector.  The first component helps to \nrepresent the physical location of the object or objects in the hypothetical grid.  The \nsecond component emphasises the numerosity by a unique code: \u20181\u2019 by \u2018100000\u2019, \u20182\u2019 \nby \u2018010000\u2019, \u20183\u2019 by \u2018001000\u2019, \u20184\u2019 by \u2018000100\u2019, \u20185\u2019 by \u2018000010\u2019 and \u20186\u2019 by \u2018000001\u2019.  \nThe unique coding is reminiscent of an accumulator filling up (Gallistel and Gelman \n1978, 1992).  This kind of mechanism ensures that smaller numerosities are encoded \nmore distinctly than higher numerosities. \n2.1.4 A Neuronal Model of Elementary Numerical Abilities \nDehaene and Changeux (1993) used an understanding of numerical psychology in \norder to construct a series of networks that could convert a visual scene input into an \nMulti-net Simulation of Quantification \n27\/02\/04 Page 14 of 42 \ninternal, abstract representation of numerosity.  Their goal in constructing the model \nwas to concentrate upon observed subitization characteristics in order to provide \nfeedback to the understanding of how subitization and internal representation operate \nwithin humans and animals. \nThey used a series of four networks: visual input clusters, an object location and \nnormalisation network, summation clusters and a topographic set of numerosity \nclusters.  Within these networks no learning was used, rather different sets of \nparameters were chosen at network initialisation.  Testing proceeded with 2500 sets of \nup to 5 objects (500 sets for each number), presented at random locations and with \nrandom size on the visual scene.  The topographic numerosity clusters resulted in \nnumerosities ordered into a number line, demonstrating both Fechner\u2019s law and the \ndistance effect. \nDehaene and Changeux concluded that this representation provided evidence for \nsubitization as an immediate apprehension of numerosity, and not as a process of \npreverbal counting, as suggested by Gelman and Gallistel (1978).  Furthermore, this \napprehension was achieved without resorting to the recognition of canonical visual \npatterns as has been suggested as a suitable mechanism for subitization (Mandler and \nShebo, 1982).  The limit of 5 objects for subitization was attributed to both the \nrepresentation of numerosity internally and accuracy of the visual normalisation, \nleading to the conclusion that the limit may vary between both individuals and \nspecies. \n2.2 Simulating Counting \n2.2.1 Counting Chimes \nConnectionist models that have attempted to imitate the numerical competence of \ncounting have focused on either responding to individual items (Amit 1988, 1989, \nHoekstra 1992), or the acquisition of the number word sequence (Ma and Hirai 1989). \nDaniel Amit\u2019s chime-counting modular network has demonstrated how to represent \nthe abstract concept of number, as well as that of the counting task, in a neural \ncomputing system employing a recurrent network.  There are two modules in Amit\u2019s \nnetwork: the first converts an input chime into a proto-chime; the second uses the \nproto-chime to update the state of the network (cf. Dehaene\u2019s accumulator) and \nproduces the tally, after detecting a predefined period of silence (no chimes). \nThe presence of the initial pre-processing of a chime into a proto-chime demonstrates \nhow such a system can be applied to the counting of any type of object or event by \nabstraction.  For Amit, this \u2018universal counting network\u2019 (1989:243), provides a \nblack-box counting mechanism capable of discriminating between different counting \nsequences and recognising objects within a sequence in a robust way. \n2.2.2 Ma and Hirai\u2019s Heteroassociative Network \nMa and Hirai (1989) demonstrated how the development of the number word \nsequence in children could be simulated.  They used the combination of a \nheteroassociative network and a recurrent inhibitory network to simulate the \nproduction of the number word sequence as observed from children (Fuson et al, \n1982), including stable conventional, stable unconventional and unstable elements.  In \naddition, they demonstrated how learning associations for lower numbers ('4', '5', '6', \nMulti-net Simulation of Quantification \n27\/02\/04 Page 15 of 42 \n'7') could influence the production of higher sequences of numbers ('14', '15', '16', '17') \nand lower incidence of irregular numbers during learning ('15'). \n2.2.3 A Recurrent Neural Network that Learns to Count \nRodriguez et al (1999) concentrated upon teaching a recurrent neural network to \nunderstand a deterministic context free language (DCFL).  In this case, the language \nconsisted of a string of \u2018a\u2019s followed by the same number of \u2018b\u2019s, with each letter \npresented to the network individually.  The task of the network was to predict both the \nnext letter when presented with a \u2018b\u2019 and when the string of \u2018b\u2019s would finish.  In this \nway, the network was taught to count the number of \u2018a\u2019s presented, in order to predict \nthe number of \u2018b\u2019s.  This was achieved with a backpropagation through time network \ntrained on sequences consisting of up to 11 \u2018a\u2019s (and hence followed by 11 \u2018b\u2019s).  The \nnetwork was tested with successively longer strings until it failed to correctly predict \nthe required number, and hence demonstrating how capable it was of generalising.  \nOver 50 trials, they found that 8 networks successfully learnt to predict the correct \nnumber of \u2018b\u2019s, with one of the networks capable of generalising up to 25.  This sort \nof counting network demonstrates how Gelman and Gallistel\u2019s (1978) concept of \nsubitizing as a form of preverbal counting may be implemented, since counting is not \nbased upon a number word sequence, but only on an abstract understanding of the \nnumber of objects presented sequentially. \n3 SSUBSYST: A Neural Simulation of Subitization \nThe presence of subitization, or more accurately the presence of the subitization limit, \nsuggests that \u2018many animal taxa [\u2026] have a natural ability to discriminate \nnumerosity\u2019 (Brannon and Terrace 1998:747).  Peterson and Simon (2000) \nsuccessfully showed how a neural network could be tutored to learn subitization, in \ncontrast to Dehaene and Changeux\u2019s (1993) hardwiring.  From their simulations it is \ndifficult to argue that subitization is a natural ability, in light of the success of the \ntutoring, despite somewhat intuitive evidence that infants or primates do not have \naccess to and\/or understand a tutor in their immediate environment.  This suggests \nthat subitization is environmentally inspired. \nDehaene\u2019s latest writing suggests that the \u2018human mind starts in life with a rich \nknowledge about objects, colours, numbers, faces and language\u2019 (2000:42) and that \nthe brain has an \u2018internalised representation of numerical quantities\u2019 (Dehaene \n2000:43).  Ontogenesis plays a key role in the development and maturation of the \nanimal brain; could ontogenesis lead to internalised representations of numerical \nquantities?  We explore this possibility through the use of unsupervised, self-\norganising neural networks in a multi-net system for simulating subitization.  Our \nsystem is essentially a sequential multi-net system with two major subsystems: first, a \nmagnitude representation based on Kohonen\u2019s SOM (1997) bi-directionally connected \nto a verbal SOM; a Hebbian link is used to link the two SOMs.  Second, a mapping \nsubsystem which processes a visual scene, comprising objects to be subitized, to map \nthe information in a scale and translation invariant manner onto the magnitude \nrepresentation SOM. \nThe sequential multi-net system SSUBSYST (Surrey Subitization System) was trained \nto subitize up to five.  The performance of the system during testing suggests that it \nperforms just as well as SUBIT-PDP (Peterson and Simon\u2019s system).  The \nperformance for lower numerosities is very similar for both the systems; both systems \nMulti-net Simulation of Quantification \n27\/02\/04 Page 16 of 42 \nshow the idiosyncratic edge effect.  The key differences between the two systems are \n(a) that the sequential system has been trained using unsupervised learning algorithms \nand (b) the edge effect in our system can be partially attributed to the architecture \ndesign of the SOMs in general. \n3.1 SSUBSYST Architecture \nThe architecture comprises three major modules: one module, comprising two \nnetworks, for mapping the visual scene onto the magnitude representation network; a \nsecond module, comprising one network, for representing the numerosity of objects as \nmagnitudes; and a final module to translate the magnitude representation into an \noutput (see Figure 1 and Table 4). \n \nNumber \nOutput \nVisual \nScene \n648-d \nVector \n15-d to \n36-d \nVector \nTranslation Invariant \nWeight-sharing \nNetwork \n72-15 \nScale Invariant \nSecond-order \nNetwork \n648:72 \n72-d \nVector \nMapping \nModule \nMagnitude \nKohonen SOM \n36-d \nVector \nBi-directional \nHebbian \nNetwork \n64-d \nVector \n36-36 x 1 36-64 16-8 x 8 \nVerbal \nKohonen SOM \nMagnitude \nRepresentation Module \n64-d \nVector \nOutput \nModule \n \nFigure 1: Architecture of SSUBSYST, comprising a mapping, magnitude representation \nand output module.  Constituent network types are shown with relevant vector and \nnetwork dimensions. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 17 of 42 \nTable 4: Network topology is indicated by input dimension and number of units in each \nlayer.  For example \u2018648-72\u2019 indicates a network with an input dimension of 648 \nelements with a single (output) layer consisting of 72 units.  For the Kohonen SOM the \noutput layer is represented as a two-dimensional grid of units, for example \u201836 x 1\u2019 \nindicates a map of 36 by 1 units. \nTask Network Topology Input \nScale invariance Second order 648-72 Visual scene consisting of a 36 by 18 \ngrid.  Each 3 by 3 section of the grid \nrepresents an object. \nTranslation \ninvariance \nWeight-sharing 72-15 Scale invariant visual scene consisting \nof a 12 by 6 grid.  Each element within \nthe grid represents an object. \nMagnitude SOM 36-36 x 1 Scale and translation invariant visual \nscene represented as a 36 dimensional \nvector.  The 15-dimensional output from \nthe visual scene is padded to 36 \ndimensions. \nBi-directional \nlinkage \nHebbian 36:64 For magnitude to verbal mapping, input \nis the activation of the Magnitude map \nas a 36 dimensional vector. \nFor verbal to magnitude mapping, input \nis the activation of the Verbal map as a \n64 dimensional vector. \nVerbal SOM 16:8 x 8 Phonetic representation of 22 numbers \nas a 16 dimensional vector. \n3.1.1 Mapping Module \nThe visual scene consists of a 36 by 18 node \u2018retina\u2019, divided into receptive fields of \nsize 3 by 3, on which several objects can be represented simultaneously.  Consider the \nexample of three objects of random shapes, sizes and positions spatially distributed \nacross a portion of the retina (as in Figure 1), albeit restricted to a single row.  The \nmapping module consists of networks for representing the objects independent of their \nsizes and for representing the objects independently of their positions. \nA second-order network receives input taken from the visual scene (Giles & Maxwell \n1987).  The network consists of groups of nodes each responsible for a 3 by 3 grid of \nelements.  Each node ignores the scale of the object detailed in the 3 by 3 grid by \nproviding a single activation if any two of the elements represent an object.  For \nsimplicity it is ensured that a single and entire object is positioned within a receptive \nfield.  There is much literature on the subject of visual scene interpretation \n(Humphreys 1998) and complex connectionist models have been proposed, such as \nthe Neocognitron (Fukushima and Miyake 1982).  We employ second-order neural \nnetworks to execute the subtask of responding to the presence of objects, with levels \nof activation that are independent of the sizes of the objects or their positions within \nthe receptive fields.  A weight-sharing network is then used to map from a spatial \narrangement onto a representation that is independent of the positions of the objects \nacross the entire retina.  Since the visual scene is not the focus of this study, we use a \nsimple mapping module, capable of distinguishing between the \u2018what\u2019 and \u2018where\u2019 \ninformation of simple objects only. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 18 of 42 \n3.1.2 Magnitude Representation Module \nThe key component of the numerosity detection system is a mechanism for \nrepresenting small numerosities as magnitudes along a number line.  For this, a self-\norganising neural network, which develops spatially ordered feature extractors, is \nemployed.  The module takes an accumulator representation as its input and learns to \nrepresent and organise these patterns of activity according to the distance effect and \nFechner\u2019s law for numbers.  Whilst Anderson (1995) has shown that nodes in a two-\ndimensional Kohonen SOM are capable of representing magnitudes of number, we \ndemonstrate that a self-organising map can represent number magnitude in \naccordance with the distance effect.  This could be modelled as a spatial arrangement \nin which adjacent regions along a single row of nodes represent consecutive \nmagnitudes. \nOur model concentrates on the abstract representation of magnitude on a number line \nand hence we chose to use a one-dimensional SOM with 15 nodes, with 15-\ndimensional input.  Table 5 shows a set of idealised training patterns where, instead of \na shifting pattern of activations as in McCloskey and Lindemann\u2019s (1992) and \nDallaway\u2019s (1994) models, a cumulative pattern of activation is used.  Here, because \nof the way in which the SOM algorithm organises patterns, each pattern must contain \nsome similarity in order for each to be distinguished in relation to all others.  For \nexample, the pattern for two (first six dimensions active) contains within it the pattern \nfor one (first three dimensions active). \nTable 5: Training vectors used in the Kohonen SOM magnitude representation \nsimulation. \nNumerosity Input Vector \nOne [ 1,1,1,0,0,0,0,0,0,0,0,0,0,0,0 ] \nTwo [ 1,1,1,1,1,1,0,0,0,0,0,0,0,0,0 ] \nThree [ 1,1,1,1,1,1,1,1,1,0,0,0,0,0,0 ] \nFour [ 1,1,1,1,1,1,1,1,1,1,1,1,0,0,0 ] \nFive [ 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1 ] \n3.1.3 Output Module \nFollowing on from the magnitude representation of number, output is required as a \nresponse formed as a verbal representation.  To achieve this a verbal representation of \nnumber is used to describe the magnitude of the numerosity detected in the visual \nscene connected to the magnitude representing SOM by an intermediate network (as \nsuggested by Gallistel and Gelman 1992 and Dehaene 1992).  The learning of bi-\ndirectional mappings was modelled by a neural network which linked the SOM \nrepresenting number as magnitudes, to a further SOM which represented number \nverbally. \nIt has been suggested that neural network architectures can be used to generate a \ntopographic map from a pre-synaptic two-dimensional array in a post-synaptic two-\ndimensional array (see, for example, Willshaw and Malsburg 1976 and Amari 1980).  \nThe neurons in the pre-synaptic layer (input) layer are connected to the post-synaptic \n(output) layer through the use of the Hebbian rule.  Our architecture is based upon \nconnecting a Hebbian network between the magnitude representing SOM and the \nverbal representing SOM; this tripartite network, two SOMs connected with a \nMulti-net Simulation of Quantification \n27\/02\/04 Page 19 of 42 \nHebbian link, was originally used by Abidi and Ahmad (1997) in their simulation of \nlanguage development in children.  Here the two SOMs can be compared to Willshaw \nand Malsburg\u2019s pre- and post-synaptic sheets. \nHebbian links strengthen the connections linking the most highly activated regions in \neach SOM.  The effect during the training process is the gradual establishment, over \ntime, of associations between magnitude and verbal representations of number.  Since \nHebbian connections are bi-directional the verbal representation can also be \ntransformed into a magnitude representation, demonstrating how elements of \nDehaene\u2019s (1992) triple-code model may be constructed.  The key element of this \nmulti-net arrangement is that the associations between the different representations is \nunsupervised and based upon positive feedback from patterns of activation.  Therefore \na feature map has been used to map an abstract number representation into a symbolic \nverbal output, as well as being used to form the representations themselves.  \n3.2 SSUBSYST Training \nThe various constituents of SSUBSYST were trained individually. \n3.2.1 Scale Invariant Network \nThe scale invariant network consists of a second-order network that also employs \nweight sharing to duplicate processing over the 3 by 3 receptive fields (Giles & \nMaxwell 1987).  The input is the visual scene represented as a 648-dimensional \nvector.  Each of the 72 nodes within the network is trained to recognise the presence \nor absence of an object within a 3 by 3 receptive field.  The network uses second-\norder techniques in order to achieve scale invariance.  This means that the inputs to \neach node are first multiplied together before being weighted and then passed through \nthe activation function, which in this case was a hard threshold (or Heaviside) \nfunction.  As the operation of each node is the same for all of the 72 grouped inputs \nonly one node need be trained.  Consequently, a single node was trained using the \nHebbian learning rule extended for second-order networks described by Giles & \nMaxwell (1987) on a set of 8 example inputs representing all possible gradients \nwithin the grid (for example, objects lying horizontally, vertically or diagonally).  \nTraining proceeded with a learning rate of 0.5 for 20 epochs and the resultant node \nreplicated to cover the 72 required grids and therefore producing a 72-dimensional \noutput representing a grid of 12 by 6. \n3.2.2 Translation Invariant Network \nThe translation invariant network consists of a single layer of 15 nodes.  Each of the \nnodes is connected to all of the inputs, which are formed by a scale invariant \nrepresentation of objects in a grid of 12 by 6.  A weighted summation is calculated \nusing all of the inputs and the weights associated with a node, which is then passed \nthrough a hard threshold (or Heaviside) activation function.  Translational invariance \nis obtained by training the weights to require a higher input activation to result in an \nincreased number of nodes activated in the output.  This is achieved through the \nsharing of the weights of one of the nodes with all others within the network, \nessentially only requiring one node to be trained.  A selection of training patterns was \nused to represent a random set of objects within the visual scene and training \nproceeded with only one pass of the training data required for one of the nodes to \nMulti-net Simulation of Quantification \n27\/02\/04 Page 20 of 42 \nlearn the required representation.  A Hebbian learning rule was used, as with the scale \ninvariant network, with learning rate set to 1.0. \n3.2.3 Magnitude Representation Network \nThe magnitude representing network is formed by a Kohonen SOM which obtains \ninput from the translation invariant expert.  The nodes within the SOM were arranged \nin a 36 by 1 grid representing a number line.  Input to the network is a 36-dimensional \nvector formed as a scale and translation invariant visual scene.  Idealised training \npatterns, (shown in Table 5) representing accumulated activity over the visual scene, \nact as the inputs to the map.  Hence, the sum of activity over the first layer is \ncomparable to a numerosity of between one and five, which the network learns to \nrepresent in the second layer. \nInitially, the weight vectors are assigned random values so that the competitive nodes \nthat are most closely associated with each input pattern are randomly arranged across \nthe map, reflecting the fact that the map has no knowledge prior to training (as shown \nin Figure 2a). \n1, 4 2, 3, 5\na) Before training\n1 2 3 4 5\nb) After training\n \nFigure 2: The winning nodes for the representations of five numerosities are randomly \npositioned a) before training and b) topologically ordered after training of 100 cycles. \nThe training process causes specific regions of the grid to become associated with \nparticular input patterns by gradually transforming weight vectors towards the input \npattern representations.  Training proceeded for 150 epochs for each of the training \ninputs in random order.  Initially the learning rate of the algorithm was set to 0.5, and \nthe square neighbourhood size 15.  After every 8 epochs, the learning rate was \ndecreased to 85% of its previous value, until a value of less than 0.05 was reached at \nwhich point it remained static.  The neighbourhood size was also decreased every 8 \nepochs, with the value reduced by 2 if it was larger than 10, by 1 if it was larger than \n5 and by 0.5 if larger than 0.  The resulting SOM was found to be capable of \nrecognising the five patterns, each of which represented a numerosity.  Figure 2 shows \nthose nodes with the highest activation in response to each input pattern before and \nafter training.  Two observations can be made from the trained network: \nDistance effect: the winning nodes for each input pattern, which represent \nnumerosities one to five, are ordered topologically after training has taken place; the \nlarger the numerical difference between two numerosities, the further apart on the \nSOM their representations are positioned (see Figure 2).  For example, consider the \nwinning node for an input pattern corresponding to the numerosity of \u2018one\u2019 being \nMulti-net Simulation of Quantification \n27\/02\/04 Page 21 of 42 \nsituated in closer proximity to the winning node for an input pattern for a numerosity \nof \u2018two\u2019 than that for \u2018three\u2019.  This is compatible with the distance effect, a feature of \nthe brain where two numbers become easier to distinguish the greater their numerical \ndifference.  The effect is displayed in this simulation due to the manner in which the \nfeature map learns. \nFechner\u2019s law: The SOM learns to organise the representations of numerosities in a \ncompressive manner that obeys Fechner\u2019s law; it is an outcome of the training \nprocedure that the locations of the winning nodes are positioned in closer proximity to \neach other as the numerosities they represent increase. \n3.2.4 Verbal Output Module \nIn order to translate this internal, abstract representation of magnitude into a number \nresponse, the next element to be trained was the SOM used to represent the verbal \noutput of the model.  This is formed as a map of 8 by 8 nodes, with input taken from a \n16-dimensional vector.  Training the network involved presenting a set of 22 \nnormalised vectors forming the numbers phonetically from 1 to 22.  Each element \nwithin the input vector represented a phoneme needed for all 22 numbers, and was \npopulated with a value of 1.0 if it was required within the number, 0.0 otherwise.  \nTraining proceeded for 100 epochs for each of the training inputs in random order.  \nInitially the learning rate of the algorithm was set to 0.3, and the square \nneighbourhood size 6.  After every 10 epochs, the learning rate was decreased to 85% \nof its previous value, until a value of less than 0.05 was reached at which point it \nremained static.  The neighbourhood size was also decreased every 10 epochs, with \nthe value reduced by 1 if it was larger than 0. \n3.2.5 Multi-net Training \nWith these two representations in place, they were connected together by a Hebbian \nnetwork consisting of a fully connected network with 36 inputs and 64 outputs, \nmatching the 36 magnitude network units and 64 verbal units, respectively.  To train \nthe network, inputs were provided to both SOMs, reportedly as encountered by infants \n(cf. Brown\u2019s or Bloom\u2019s corpus: MacWhinney 1991), representing environmental \nexamples of conceptual and language-dependent information concerning number.  For \ninstance, an experience may involve the caretaker of the child pointing towards two \ntoys whilst saying to the child \u2018there are two of them\u2019.  This was simulated during one \ntraining iteration by randomly positioning two objects in the visual scene and \nallowing the scale and translation invariant networks to provide an input to the \nmagnitude representing SOM.  Corresponding to this input, the phonological \nrepresentation of the number of objects in the scene (the number word) was presented \nto the verbal SOM.  These two SOM activations were then used to train the Hebbian \nlinks, which had initial random weight values.  A Hebbian learning rule with a \nlearning rate of 0.2 was applied for 50 epochs, strengthening the connections between \nthe most highly activated regions in the maps, with the number of objects and \ncorresponding number word presented in random order. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 22 of 42 \n3.3 SSUBSYST Testing \n3.3.1 Testing Strategy \nHaving individually trained and tested the component networks comprising the \nmapping module and the magnitude representation network, the SSUBSYST \nnumerosity detection system was constructed by linking the networks together in \nseries.  Testing of the numerosity detection system involved presenting novel input \npatterns by introducing Gaussian random noise (with \u00b5 = 0, \u03c3 = 0.1) to the input \nnodes in each receptive field occupied by an object.  In response to this input, the \nmapping module generated patterns representing accumulated activity over the visual \nscene.  The magnitude representation network then received these noisy versions of \nthe representations on which it had been trained.  To suppress noise in the output of \nthe system, the winning neuron was depicted with peak activation surrounded by \nneurons with decreasing activation.  This took the form of the winning node being \nallocated an activation level of 1, whilst its neighbours received activation in \nproportion to their distance from the winner, according to a Gaussian distribution. \nIt was found that presenting a specific number of objects in the visual scene caused an \nappropriate magnitude representation to be activated, as in Thompson et al\u2019s (1970) \nobservations on cat neurons.  The activation of the magnitude representation was then \nused to activate the verbal representation (magnitude to verbal mapping) via the \nHebbian connections.  The property of bi-directionality in the Hebbian links enables \nmagnitude representations to be retrieved in response to an input of a number word \nrepresentation; by having as input a verbal representation of number to the relevant \nSOM, a specific region on the map with a magnitude representation for number is \ncaused to become activated (verbal to magnitude mapping). \n3.3.2 Validating SSUBSYST \nSince Dehaene and Changeux\u2019s (1993) model has a number of similar attributes to \nSSUBSYST, namely visual scene transformation and topographic numerosity \nrepresentation, and also provided a viable simulation of the proposed subitizing \nmechanisms, we compared Dehaene and Changeux\u2019s results with those obtained from \nSSUBSYST. \nTo achieve this, our system was presented with 500 examples of objects of random \nshapes, sizes and locations across the visual scene for each of the numerosities one to \nfive.  To allow comparison of the internal representation of magnitude, the output \nfrom the magnitude SOM was recorded, rather than passing activation through to the \nverbal map.  Table 6 shows a representation of activations output by our simulation \nand those reported by Dehaene and Changeux.  Specific, yet overlapping, regions of \nthe output layers of both models respond to the number of objects represented on the \nretina.  As seen from the table, the distance between two regions decreases with an \nincrease in numerosity (cf. Fechner\u2019s law).  In Dehaene and Changeux\u2019s system, the \neffect of Fechner\u2019s law is a result of the representations of the numerosities, along a \nlinear number line, having increasing variability as the magnitudes of the numerosities \nincrease (cf. scalar variability assumption).  This can be seen by the increasingly \nwider curves for larger numerosities.  In our system, however, there is little difference \nin the variability across numerosities.  The effect of Fechner\u2019s law holds here due to \nthe numerosities being represented along a compressive number line (cf. compressive \nmapping assumption).  Fechner\u2019s law states that the perceived intensity of a number \nMulti-net Simulation of Quantification \n27\/02\/04 Page 23 of 42 \nstimulus is proportional to the logarithm of the actual intensity, hence the internal \nrepresentation of number is compressed at higher magnitudes.  Looking at the pattern \nof activation for successive numerosities, we can see that each activated region \noverlaps more and more as the numerosity increases, hence the higher numerosities \nseem to be compressed and is logarithmic in nature. \nTable 6: Representation of the activities output in response to 1 to 5 objects presented in \nthe visual scene of our system and that of Dehaene and Changeux\u2019s (1993).  An activity \nvalue over 0.75 was used to indicate a cluster response for our system, and a value over \n0.4 in Dehaene and Changeux\u2019s due to the lower levels of activity for higher cluster \nnumbers. \nClusters Numerosity \n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \nOur Results \n\u20181\u2019 \u221a \u221a              \n\u20182\u2019       \u221a \u221a \u221a       \n\u20183\u2019          \u221a \u221a \u221a    \n\u20184\u2019            \u221a \u221a \u221a  \n\u20185\u2019              \u221a \u221a \nDehaene and Changeux\u2019s Results \n\u20181\u2019  \u221a              \n\u20182\u2019     \u221a           \n\u20183\u2019       \u221a \u221a        \n\u20184\u2019          \u221a      \n\u20185\u2019            \u221a    \nIn summary, the results of the two systems are similar; in both numerosity detection \nsystems, the representations of numerosities obey the distance effect and Fechner\u2019s \nLaw for numbers.  The difference is that, in ours, these are side effects that have \narisen as a direct consequence of the training procedure employed, whilst these effects \nwere obtained in Dehaene\u2019s model through the hard wiring of the connection \nstrengths.  For us, the change of weights of the nodes of an interconnected system \nensures that it has learnt.  The organisation of these patterns is as a result of the way in \nwhich the SOM algorithm has organised similar patterns together on the one-\ndimensional map, looking at similarities in the input data and using the Euclidean \ndistance to cluster like representations. \nThe comparison of the unsupervised SSUBSYST with Peterson and Simon\u2019s \nsupervised network shows interesting similarities and differences.  In order to \ncompare the two networks, SSUBSYST was trained to recognise numerosities of up \nto six and then trained again (independently) to recognise numerosities of up to eight \n(see Figure 3a and Figure 3b respectively). \nMulti-net Simulation of Quantification \n27\/02\/04 Page 24 of 42 \n \nOne\nTw o Three\nFour\nFive\nSix\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18\nKohonen Layer Node Number\nAv\ne\nra\nge\n \nAc\ntiv\na\ntio\nn\nOne\nTwo\nThree\nFour\nFive Six\nSeven\nEight\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\nKohonen Layer Node Number\nA\nv\ner\nag\ne \nA\nct\niv\nat\nio\nn\na) Results of training up to six \nb) Results of training up to eight \n \nFigure 3: Results of SSUBSYST trained up to the numerosities: a) six, b) eight. \nSimilarities (cf. Peterson and Simon 2000): \n(i) Both networks learn numerosities, numbers \u20181\u2019-\u20183\u2019 easily in their own way.  \nPeterson and Simon\u2019s 16-3-6 network needs 6000 cycles of training to \nrecognise \u20181\u2019 and \u20182\u2019 and by the 9000th cycle, the network has learnt \u20183\u2019 as \nwell.  If the hidden nodes are increased by one (16-3-6 to 16-4-6) then the \nthree numerosities are learnt in the first 3000 cycles by training.  The final \nactivation level for \u20183\u2019 is the same.  Much the same is true when Peterson and \nSimon trained their network for higher numerosities of up to eight using a 36-\n5-8 network. \nSSUBSYST learns numerosities 1-3 in 150 epochs of training (as it does with \n4 and 5) and makes a clear distinction between the three in terms of allocating \nunique (sets of) nodes in the output layer. \n(ii) Both networks show an edge effect for the lowest and the highest numerosities.  \nFor example, numerosities \u20181\u2019 and \u20186\u2019 show the highest activation level in both \nnetworks and are learnt quickly by Peterson and Simon\u2019s network (within \nMulti-net Simulation of Quantification \n27\/02\/04 Page 25 of 42 \n6000 training cycles) and uniquely by SSUBSYST.  If the networks are trained \nto subitize higher numerosities, of up to 8, again both learn the numerosities \n\u20181\u2019 and \u20188\u2019 quickly. \n(iii) Intermediate numerosities, for example, \u20183\u2019 and \u20185\u2019 for networks trained to \nlearn up to \u20186\u2019, and \u20185\u2019 and \u20187\u2019 for networks trained to learn up to \u20188\u2019, are \nlearnt over a larger number of training cycles by Peterson and Simon\u2019s \nnetwork.  In SSUBSYST there is a similar phenomenon observed in that the \nactivation level of nodes that learn intermediate numerosities is lower than that \nof nodes that recognise \u20181\u2019 and the highest numerosity (either \u20186\u2019 or \u20188\u2019). \nDifferences (cf. Peterson and Simon 2000): \n(i) In one sense one cannot compare the performance of a supervised network \nwith that of an unsupervised network in that the basic learning mechanism is \ndifferent.  Nevertheless, like all backpropagation networks, Peterson and \nSimon can always improve the performance of their networks by adding yet \nanother hidden node.  Such incremental addition may lead to an over-\ndetermination of the solution.  In unsupervised networks there is no such \n\u2018tweaking\u2019 mechanism available, except perhaps for the neighbourhood size \nand learning rate. \n(ii) SSUBSYST simulates subitization more intuitively; were it not for the paucity \nof experimental or observational data, a situation which may improve through \nthe efforts of Dehaene and his colleagues, one could argue that SSUBSYST \nagrees with the observational\/experimental data better than Peterson and \nSimon\u2019s network. \nSSUBSYST\u2019s performance simulates subitization in that SSUBSYST\u2019s output \nconforms to the observations of Fuson, as stated under the rubric of distance \neffect, and that of Fechner, as implied in his eponymous law; lower \nnumerosities are discriminated whilst higher numerosities cannot be \ndistinguished easily.  The activation level for nodes that \u2018win-over\u2019 lower \nnumerosities is typically higher than that of nodes that had \u2018won-over\u2019 higher \nnumerosities.  This discrimination prevails despite the edge effect. \n4 SCOUSYST: A Neural Simulation of Counting \nCounting involves the imposition of order on a collection to allow each item within \nthe collection to be tallied one by one.  This order is imposed in a stimulus \nindependent manner: whether the stimulus is acoustic, presented for example as \nchimes emanating from a bell one at a time, or the stimulus is visual, for instance a \ncollection of individuals presented all at once; counting involves keeping track of how \nmany individuals or chimes have been taken into account thus far and to ascertain that \nthe stimulus has ceased. \nCounting is also a learnt process: in order to count one has to have some knowledge \nof a number system, something that is taught.  During counting the labels have to be \nrecited such that they match the ascendancy of the numerical sequence and hence \nthere is some association and storage of a number word with an object within the \ncollection.  Whilst there may be many different ways in which counting may take \nplace, for example listening for chimes or counting objects in a row, we take a \nsomewhat simplistic approach by assuming we have a visual scene in which objects \nare presented within a single row.  We also assume that there is an indication within \nMulti-net Simulation of Quantification \n27\/02\/04 Page 26 of 42 \nthe visual scene as to the next object to be counted, much like a pointing finger.  With \nthis simplified view, we can determine that the association and storage of a number \nword within the sequence is dynamic, since an internal representation needs to be kept \nof the current number word, whereas the identification of the next object is static \nbecause our visual scene contains this information, which only needs to be updated. \nWithin these simplified bounds we have developed a system that uses both sequential \nand competitive multi-net processing to simulate counting.  The system comprises \ntwo major sub-systems: the first sub-system transforms a visual scene into a scale \ninvariant output for the second system where the counting takes place; the same scale \ninvariant network used for our subitization system SSUBSYST was used here.  The \ncounting sub-system comprises a recurrent backpropagation network for articulating \nthe numerosity of the individuals (counted thus far) in the collection, and a static \nbackpropagation network for the next-object task, operating in competition so that \ndifferent modules perform word-articulation and next-object pointing independently.  \nThe output of the two sub-systems is controlled, or rather gated, by two feedforward \nnetworks: one is the number word gate and the other is a next-object gate.  The gated \noutput is passed onto a Madaline network, which produces the number output of the \ncollection presented in the visual scene.   \nThe sequential multi-net system, SCOUSYST (Surrey Counting System), was initially \ntrained to count up to 5 objects, and then re-trained on larger numbers of objects.  The \nlongest row of objects presented to the model was 22 under training, and 29 for \ntesting the model\u2019s capacity for generalisation.  These numbers correspond closely to \nthe numbers of objects counted by children aged 3\u00bd to 6 in Fuson\u2019s (1988) study \nwhere the longest rows ranged from 22 to 31 objects.  SCOUSYST was trained to \ncount by decomposing the counting task into that of number word update\/storage \nfrom the next-object pointing task.  In this respect, we believe that SCOUSYST is \ndifferent from other neural counting systems reported in the literature. \n4.1 SCOUSYST Architecture \nThe architecture for SCOUSYST comprises three major modules: one module, \ncomprising one network, for mapping the visual scene onto the counting module; a \nfurther module, comprising four networks, for counting; and a final module for \noutputting a response (see Figure 4 and Table 7).  \nMulti-net Simulation of Quantification \n27\/02\/04 Page 27 of 42 \n \nNumber \nOutput \nVisual \nScene \n648-d \nVector \n64-d \nVector \n72-d to \n44-d \nVector \nScale Invariant \nSecond-order \nNetwork \n648:72 \nMapping \nModule \n \n19-64 \nNumber \nMadaline \n \n \n \n 0-2 \n0-2 \n89-20-63 \n89-9-63,18 \nNext Object Gate \nFeedforward Network \nNumber Word Gate \nFeedforward Network \nWord \nRecurrent \nBackpropagation Network \nNext Object \nBackpropagation \nNetwork \n19-d \nCombined \nVector \n45-d \nVector \n1-d \nVector \n18-d \nVector \n89-d \nVector \nCounting \nModule \nOutput \nModule \n \nFigure 4: Architecture of SCOUSYST, comprising a mapping, counting and output \nmodule.  Constituent network types are shown with relevant vector and network \ndimensions. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 28 of 42 \nTable 7: Details of system employed in modelling verbal counting.  Network topology \nindicated by input dimension, number of units in each layer and number of state units.  \nFor example \u201889-9-63, 18\u2019 indicates a network with an input dimension of 89 elements \nwith two layers of 9 and 63 units with 18 state units appended to the first layer of the \nnetwork. \nTask Network Topology Input \nScale invariance Second order 648-72 Visual scene consisting of a 36 by 18 grid.  Each \n3 by 3 section of the grid represents an object. \nNext object Backpropagation 89-20-63 \nNumber word Recurrent \nbackpropagation \n89-9-63, 18 \nCombination of visual scene and \u2018next-object\u2019 \noutput as an 89-dimensional vector.  Visual scene \nis converted from a 72-dimensional vector to a \n44-dimensional vector with spaces between \nobjects.  Initial \u2018next-object\u2019 feedback has no \nobjects being pointed at. \nNext object gate Feedforward 0-2 None. \nNumber word gate Feedforward 0-2 None. \nNumber output Madaline 19-64 Counting network response 19-dimensional \nvector constructed as an 18-dimensional number \nword subtask output combined with the 1-\ndimensional \u2018no object\u2019 subtask output. \n4.1.1 Mapping Module \nThe architecture of the scale invariant sub-system for visual scene analysis in \nSCOUSYST is identical to the scale invariant element of the subitization system \nreported above (section 3.1.1).  The former does not have a translation invariant sub-\nsystem.  Since the scale invariant visual scene outputs objects within a receptive field, \nwith no gaps between objects, this was modified before presentation to the counting \nmodule to include gaps at appropriate points.  The output of the mapping module was \nfurther reduced in dimension to match the total number of objects that the counting \nroute was capable of detecting.  The remaining input nodes represented the object \ncurrently being pointed to, with the activation of the final node representing a \u2018no \npoint\u2019 action.  Of these, an input node took an activation value of 0.9 to represent a \npointing action and a value of 0.1 otherwise (see example in Table 8). \nTable 8: Example inputs to the counting module for three objects, with each object being \nselected as the next-object until the end.  Total input vector dimension is 44 for the object \npositions, 44 pointing positions and 1 for \u2018no point\u2019. \n Input Vector  Number Word \nObjects (44) Pointing Position (44) No Point Output \n[1,0,1,0,1,0,0...0, 0.1,0.1,0.1,0.1,0.1,0.1,0.1...0.1 0.1] - \n[1,0,1,0,1,0,0...0, 0.9,0.1,0.1,0.1,0.1,0.1,0.1...0.1 0.1] One \n[1,0,1,0,1,0,0...0, 0.1,0.1,0.9,0.1,0.1,0.1,0.1...0.1 0.1] Two \n[1,0,1,0,1,0,0...0, 0.1,0.1,0.1,0.1,0.9,0.1,0.1...0.1 0.1] Three \n[1,0,1,0,1,0,0...0, 0.1,0.1,0.1,0.1,0.1,0.1,0.1...0.1 0.9] - \n4.1.2 Counting Module \nThe counting system comprises a multi-net architecture formed from three sub-\nsystems: \u2018word\u2019, \u2018next-object\u2019 and a set of decision gates mediating output.  The \nMulti-net Simulation of Quantification \n27\/02\/04 Page 29 of 42 \nmulti-net system is based upon the mixture-of-experts (ME) architecture defined by \nJacobs et al (1991).  Here, expert networks are trained in-situ with gating networks \nthat learn how to decompose tasks to each of the experts.  The ME architecture \nemploys a supervised learning algorithm, but crucially the gating networks use an \nunsupervised learning algorithm to ensure that the task decomposition is competitive \nand influenced only by the performance of each individual expert.  In this way, \nexperts are selected to perform subtasks and then promoted to perform them better \nwith training. \nThe counting system employs two expert networks for the \u2018word\u2019 and \u2018next-object\u2019 \nsubtasks, together with two gating networks that mediate production of the \u2018word\u2019 and \n\u2018next-object\u2019 outputs.  Here each of the gates selects an expert network that is optimal \nfor the designated subtask. \n4.1.3 Output Module \nThe output from the counting system forms a combination of \u2018number word\u2019 and \n\u2018next-object\u2019 representation, including \u2018no-object\u2019 within the response.  In order to \nconvert this to a number response, where a number word response is only produced \nonce all objects have been counted, the output was fed into a Madaline network. \nThe Madaline network, using a Signum activation function, has a single layer of 64 \nnodes taking input of the 18 possible number word phonemes, together with input \nrepresenting \u2018no point\u2019.  The output layer of nodes consisted of two subsets; one \nsubset representing a possible verbal response and the other describing the object to \nwhich the next pointing action was to be applied.  Each of the 18 output nodes in the \n\u2018word\u2019 subset were associated with either an entire number word or part of a number \nword as follows [\u2018-teen\u2019, \u2018-ty\u2019, \u2018one\u2019, \u2018two\u2019, \u2018three\u2019, \u2018four\u2019, \u2018five\u2019, \u2018six\u2019, \u2018seven\u2019, \n\u2018eight\u2019, \u2018nine\u2019, \u2018ten\u2019, \u2018eleven\u2019, \u2018twelve\u2019, \u2018twen-\u2018, \u2018thir-\u2018, \u2018fif-\u2018].  The \u2018next-object\u2019 \noutput nodes described the object to which the next pointing action was to be applied, \nwith the final node indicating the end of the counting task.  The largest number of \nobjects being presented in the visual scene determined the total number of output \nnodes in this subset. \n4.2 SCOUSYST Training \nBoth the feedforward and recurrent networks were updated according to the \nbackpropagation algorithm, however the recurrent network utilised state units to \nprovide internal memory (Elman 1990).  The weights of the recurrent links connecting \nthe output nodes to the state units were set to values of 1, whilst the weights of the \nself-recurrent links to the state units were assumed to be 0.  A method of teacher \nforcing for training the recurrent expert was employed, in which the output units send \nthe ideal outputs supplied in the training data set to the state units.  We incorporated a \nfurther set of recurrent links that connected the output nodes of the \u2018next-object\u2019 \nsubtask with the input visual scene.  These links, with pre-set weight values of 1, fed \nthe model\u2019s decision of which object to next point at back into the visual scene, and \nhence updated the input layer for the subsequent time-step. \n4.2.1 Scale Invariant Network \nOn separate runs of SCOUSYST the sizes of the layers of the network were modified \naccording to the size of the problem task.  The size of the part of the visual scene for \nrepresenting objects was set to be twice the size of the maximum number of objects \nMulti-net Simulation of Quantification \n27\/02\/04 Page 30 of 42 \nbeing counted, allowing for spaces to be included between neighbouring objects.  \nOtherwise, training proceeded as for the scale invariant network within SSUBSYST \n(section 3.2.1). \n4.2.2 Counting Module: Training the Gated \u2018Word\u2019 and \u2018Next-Object\u2019 Subsystems \nThe training data set comprised 50 examples of counting various sized sets of objects, \ntotalling 700 training patterns.  Because this training set consists of examples that \ncount through the objects starting at one, there is a bias towards the lower numbers.  \nFor instance, for two example visual scenes, one of three objects and one of four \nobjects, the training sets would consist of data counting through \u2018one\u2019, \u2018two\u2019 and \n\u2018three\u2019 and \u2018one\u2019, \u2018two\u2019, \u2018three\u2019 and \u2018four\u2019, respectively.  Thus in this example, the \nrepresentations for \u2018one\u2019, \u2018two\u2019 and \u2018three\u2019 are presented more often than \u2018four\u2019.  \nTraining proceeded for 400 epochs with a learning rate of 0.95 for the recurrent and \nfeedforward experts, and 0.05 for the gating networks. \nThe ability of the model, not only to learn but also to decompose the counting task, \ninvolved examining the behaviour of the individual experts and the gating networks, \nin addition to the model as a whole.  We discuss each of these below. \n4.2.2.1 Learning \nSCOUSYST was trained to output a verbal response if a subset of the nodes \nresembling a number word took a high activation value (greater than 0.6), whilst the \nremainder had low activation levels.  Under a teacher forced training procedure, the \nmodel was found to have correctly decomposed the counting task into the two \nsubtasks 96% of the time over 25 trials.  For the successful trials, the proportions of \ncorrect responses of the model over 400 training epochs for each of the two subtasks \nwere recorded, in addition to the overall counting task itself.  The counting task \nperformed only as well as the least successful of its subtasks, which is the \u2018next-\nobject\u2019 subtask at all epochs. \n4.2.2.2 Task Decomposition \nThroughout the training process, the behaviour of each gating network was studied to \nconfirm that an efficient decomposition of the counting task took place.  The two \nnetworks are responsible for gating different sets of components\u2019 output by the expert \nnetworks.  The most efficient solution is then for the gate responsible for the patterns \ndescribing the \u2018word\u2019 subtask to switch on the output of the recurrent expert and to \nswitch off the output of the feedforward expert and vice versa for the second gate, \nwhich is responsible for the \u2018next-object\u2019 patterns.  During training it was found that \nboth experts initially favouring the recurrent expert accounted for 36% of the trials.  \nAlternatively, on 12% of the trials, both gates displayed an initial preference for the \nfeedforward expert.  On a single trial (4%), the gates chose the most unsuitable \ncombination of experts but they permanently swapped choices after a few epochs.  \nCases in which the two gates made the most efficient choices from the start of training \naccount for the remaining 48% trials. \n4.2.3 Output Network \nThe produced output indicates the number of items generated by the counting \nresponse.  The form of this matches the output of the SSUBSYST\u2019s verbal SOM \n(section 3.1.3), namely a 64-dimensional vector with 1-dimension each representing \nMulti-net Simulation of Quantification \n27\/02\/04 Page 31 of 42 \nthe numbers from 1 to 22.  A set of 44 training patterns was used to train the network \nover 50 epochs with a learning rate of 0.2.  The network was trained to output a \nnumber word when the \u2018no point\u2019 input was highly activated, with the output \ncorresponding to the input number word.  Otherwise, the output represented a \u2018no \noutput\u2019. \n4.3 SCOUSYST Testing \n4.3.1 Testing Strategy \nOnce all networks had been successfully trained, they were connected together to \nallow testing of SCOUSYST.  Following the testing procedure established in testing \nSSUBSYST (section 3.3.1) visual scenes were presented to the system and activation \nallowed to propagate through the constituent networks.  The result of each time-step \nof the counting process was recorded, together with the final number response.  As \nused for the subitizing system, random visual scenes were presented and activation \nallowed to propagate through the constituent networks.  The result of each time-step \nof the counting process was recorded, together with the final number response. \nTesting of the counting model involved feeding back the actual output of the recurrent \nexpert network into the state units, rather than the ideal output (which was the method \nused under the teacher forced training method).  In other words, the recurrent expert \nprocessed the information it fed back to itself regardless of whether a correct or \nincorrect number word had been generated on the previous time-step.  Another way in \nwhich the testing method differed from the training one was that whichever object the \nmodel chose to point to next was reflected in the visual scene on the following time-\nstep.  This contrasted with the training process in that when the incorrect object was \nselected, the input on the next time-step was modified to display the object that should \nhave been pointed to. \n4.3.2 Comparison of SCOUSYST\u2019s Output with Child Development Data \nSCOUSYST\u2019s output was compared to the observations of counting errors made by \nchildren between the ages of 3\u00bd years and 5\u00bd years (Fuson et al. 1982).  For \nexample, Table 9 shows two sets of responses provided by one run of the model after \n40 epochs, and one after 120 epochs. \nTable 9: Production of the number word sequence by the model at stages throughout the \ntraining process.  Incorrect values in the sequence are shown in bold. \nAfter 40 Epochs After 120 Epochs \n1, 2, 3, 4, 5, 6, 7, 8, 8 1, 2, 3, 4, 5, 6, 7, 8, 8 \n1, 2, 3, 4, 5, 6, 7, 8, 9, 8 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 9 \n1, 2, 3, 4, 6, 7, 8, 19, 13, 18, 19 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 8 \n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 8 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 8 \n1, 2, 3, 4, 6, 17, 18, 19, 20, 1, 8, 19, 20 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 6, 7, 8, 9, 8, 9 \n1, 2, 3, 4, 5, 6, 17, 18, 19, 8, 19, 20, 8 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 8, 9 \nReferring to Fuson et al\u2019s categories, we have: a conventional portion; a stable, non-\nconventional portion; and an unstable, non-conventional portion.  Our simulation \nseems to produce corresponding results: \nMulti-net Simulation of Quantification \n27\/02\/04 Page 32 of 42 \n1. Conventional portion: numbers early in the sequence are generated correctly.  For \nexample, after 40 epochs a minimum of the numbers \u2018one\u2019 to \u2018four\u2019 are produced \ncorrectly.  After 120 epochs this increases to the numbers \u2018one\u2019 to \u2018eight\u2019. \n2. Stable, non-conventional: some numbers are inaccurately repeated consistently out \nof order.  For example, after both 40 and 120 epochs \u20188\u2019 appears in a nearly all \nsequences at a higher position.  The numbers \u2018seventeen\u2019, \u2018eighteen\u2019, \u2018nineteen\u2019 \nand \u2018twenty\u2019 also exhibit some stability in the 40 epoch sequences. \n3. Unstable, non-conventional: somewhat random use of numbers inaccurately, with \ndifferent numbers used in different sequences.  The sequences for 40 epochs alone \nexhibit these characteristics (for example, \u2018thirteen\u2019), showing that further cycles \nof training reduce this occurrence. \nThe reason that the model is able to consistently and correctly produce the lower end \nof the number word sequence, and not the remainder, is the imposition of a domain-\nspecific constraint upon the inputs to the model.  As discussed, this constraint took the \nform of a bias in the training data set whereby number words earlier in the sequence \noccur more frequently than later ones.  It has been argued whether certain number \nwords are more frequent in our vocabulary than others (for example, Dehaene and \nMehler 1992) but since counting even small sets always includes the number words \nearlier in the sequence, that is, \u2018one\u2019, \u2018two\u2019 etc., we assume a child being taught to \ncount has an increased exposure to these.  SCOUSYST experiences examples of the \nnumber word sequence in precisely this manner.  By comparing the number word \nsequences produced by the model at the two stages of training in Table 9, the size of \nthe stable, conventional portion can be seen to increase whilst the other portions \ndecline.  Learning of the correct association between neighbouring number words for \nthe higher numbers is a result of further experience with those words. \nThe second observation by Fuson et al. (1982) concerns the less frequent occurrence \nof irregular number words in the child\u2019s number word output.  Similarly, the model \nwas found to have more difficulty in producing an irregular number word such as \n\u2018fifteen\u2019.  This may be explained by considering the representations of neighbouring \nnumber words.  Learning to associate regular pairs of number words is aided by past \nexperience of learning other neighbouring number words that share part of their \nrepresentations.  For example, knowing that \u2018six\u2019 precedes \u2018seven\u2019 helps learning that \n\u2018seventeen\u2019 follows \u2018sixteen\u2019.  Meanwhile, learning that \u2018five\u2019 follows \u2018four\u2019 hinders \nthe task of learning that \u2018fourteen\u2019 is followed by the irregular \u2018fifteen\u2019 rather than \n\u2018five-teen\u2019. \nIn examining pointing errors the aim of the analysis of error production was not only \nto investigate whether the model gave similar types of errors to those found in \nchildren; in addition, we examined whether the proportions of those errors were \ncomparable and whether those proportions decreased over time at a similar rate, \nreflecting the improvement in counting experienced by children.  In order to simulate \nthis developmental progression, training was stopped at regular intervals at which \nsnapshots of the model were recorded before training resumed.  The snapshots of the \nmodel were tested to see whether they corresponded to specific stages in the child\u2019s \ndevelopment regarding counting. \nTo assess the \u2018next-object\u2019 errors made by the model, the 50 examples of rows of \nobjects that acted as input during training were presented to the model again.  This \nwas repeated for each snapshot recorded at intervals of 40 training epochs.  On each \nMulti-net Simulation of Quantification \n27\/02\/04 Page 33 of 42 \ntime-step the actual output of the pointing task fell into four categories: firstly, an \nobject selected, represented by a node with an activation level over 0.6 and all other \nnodes with activation below 0.4; secondly, a \u2018no point\u2019 output, with the \u2018no point\u2019 \nnode activated over 0.6 and all others below 0.4; thirdly, a \u2018best guess\u2019 output \ndescribing a category which includes all poorly represented responses.  Here an object \nselected or \u2018no point\u2019 output was determined by the node with maximum activation \nabove a threshold of 0.3; and, finally, \u2018no output\u2019 indicated by all nodes being \nactivated below 0.3. \nIf the output on a particular time-step was incorrect, it was classified as falling into \none of the following error types: an \u2018object skipped\u2019 error occurred if any number of \nobjects were skipped over; a \u2018multiple count\u2019 error was recorded whenever the object \ncurrently being pointed to was selected again; a \u2018no object\u2019 error occurred if the \nmodel selected a space between objects; and, a \u2018stopped early\u2019 error was considered to \ntake place if objects to the right of the last one being pointed to were not included in \nthe counting procedure.  The condition that indicated that the counting task had \nstopped early was either an incorrect \u2018no point\u2019 output or a \u2018no output\u2019 (this may be \ninterpreted as a child refusing to continue with the counting procedure).  Additionally, \na \u2018stopped early\u2019 error was recorded whenever the model starting re-counting objects.  \nOften this was accompanied by the number word sequence starting from \u2018one\u2019, \nindicating that the model was attempting to carry out a new counting task.  The last \nerror type identified in our model may be interpreted as the end of the current \ncounting task. \nAccording to Fuson (1988) \u2018object skipped\u2019 and \u2018multiple count\u2019 are the main two \npoint-object error types made by children.  Since developmental data is available for \neach of these error types, they were compared to the proportions of errors generated \nby the simulation.  In Figure 5 the error rates made by the simulation for each problem \ntype are plotted together with Fuson\u2019s data.  The number of training epochs \ncorresponding to each of four age ranges, 3\u00bd-4, 4-4\u00bd, 4\u00bd-5 and 5-5\u00bd are chosen to \nbe evenly distanced.  Referring to Figure 5, the skipped error rate at 120 epochs can \nbe seen to most closely resemble the data of the first age range 3\u00bd-4 and at 200 \nepochs for the second age range 4-4\u00bd.  The interval of 80 epochs is then applied in \npositioning the subsequent children\u2019s data points.  By ensuring that the length of \ntraining of the network between the points matched is constant, there is an underlying \nassumption that children are exposed to equal amounts of counting examples between \n3\u00bd and 5\u00bd years of age.  It can be seen that the proportions of errors for both data sets \nare fairly similar and both decrease in a comparable manner.  The same intervals \nbetween epochs were used in plotting the children\u2019s multiple count error rates.  Here, \nthe proportions of errors are lower for both data sets and for neither do the rates \nsmoothly decrease with time. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 34 of 42 \n \n0\n2\n4\n6\n8\n10\n12\n14\n1 2 3 4 5 6 7 8\nEpoch\nO\nbje\nct\n \nSk\nip\npe\nd \nEr\nro\nr \nRa\nte\n0\n0.5\n1\n1.5\n2\n2.5\n3\u00bd - 4 4 - 4\u00bd 4\u00bd - 5 5 - 5\u00bd\nAge\nM\nu\nlti\npl\ne \nCo\nu\nn\nt E\nrr\no\nr \nRa\nte\nNo Object Errors\n(Simulation)\nObject Skipped Errors\n(Simulation)\nObject Skipped Errors\n(Children)\nMultiple Count Errors\n(Simulation)\nMultiple Count Errors\n(Children)\n \nFigure 5: Relationship between proportions of object skipped and multiple count errors \nby children and by our counting simulation.  No object errors are also shown. \nComparison of error types confirms, to some extent, that the model is good for \nsimulating the learning of the next-object subtask.  Moreover, the proportions of \nskipped and multiple count errors found in the model closely correspond to children\u2019s \ndevelopmental data.  The network, however, appears to frequently make what can be \ncalled a \u2018no object\u2019 error (see Figure 5); according to Fuson (1988) children rarely \nappear to commit this kind of a mistake (and hence there is no comparative data).  \nThis indicates one of the limitations of this model compared to human ability; it \nreflects the improved ability of a human in distinguishing objects from spaces over \nthat of the model\u2019s.  Whilst the model lacks knowledge of objects in spatial \narrangements, it has been reported that infants are capable of interpreting the physical \nworld in terms of individual entities from an early age (Spelke 1994).  This may be \naccounted for by the simplistic treatment of the visual scene used in constructing this \nsimulation. \n4.3.3 Generalisation in SCOUSYST \nSCOUSYST was trained with a maximum of 22 individuals in a visual scene.  If the \nsystem has learnt to count, then perhaps it could cope with a larger number of \nindividuals.  The system was tested on visual scenes comprising up to 29 objects. \nFor the \u2018word\u2019 subtask, verbal responses of number words higher than \u2018twenty-two\u2019 \nhad not been encountered during training.  Despite this, the counting model attempted \nto represent number words according to the limited experience it had gained.  \nRepresentations for number words output by the model during testing were \u2018one\u2019 \nthrough to \u2018nineteen\u2019, \u2018twenty\u2019, \u2018twenty-one\u2019, \u2018twenty-two\u2019, \u2018three\u2019, \u2018twenty-four\u2019, \n\u2018five\u2019, no output, \u2018twenty\u2019, no output and \u2018nine\u2019.  It is not surprising that the first three \nnumber words in this list are correct since they formed part of the training set.  \nAlthough the representation of the next number word, \u2018twenty-three\u2019 was not \nachieved, the model did output a number word by using its experience in associating \nMulti-net Simulation of Quantification \n27\/02\/04 Page 35 of 42 \n\u2018two\u2019 with \u2018three\u2019.  On the following time-step, the number word \u2018twenty-four\u2019 was \nsuccessfully represented by activation levels over 0.5 in the elements of the vector \nsymbolising the syllables \u2018twen-\u2019, \u2018-ty\u2019 and \u2018four\u2019, and by activation values less than \n0.5 elsewhere.  Even though higher number words were poorly represented by the \nmodel, the correct output of \u2018twenty-four\u2019 is indicative of some capacity of the model \nto generalise. \nSimulation of the production of the number word \u2018twenty-four\u2019 was possible, despite \nfailing to produce the number word of \u2018twenty-three\u2019, through the teacher forced \nmethod of correcting the actual output of the model from the previous time-step.  This \nsimulates prompting a child with a correct number word once he or she has generated \nan incorrect one, in order to assist in the retrieval of the succeeding word in the \nsequence.  Perhaps like children, the model was able to use experience of associations \nbetween neighbouring number words to generate a number word that it had not \nencountered previously.  However, there is a limit for such a model to generate \nunseen number words.  The production of irregular terms in the number word \nsequence, such as \u2018thirty\u2019, would require explicit teaching, in the form of training on a \nlarger data set.  This is perhaps demonstrated for the training of the numbers \u2018eleven\u2019 \nand \u2018twelve\u2019, as they do not form a \u2018teen\u2019 value (see Butterworth 1999, for a \ndiscussion on a child\u2019s learning of the English number words). \nA limitation of the model in pointing to objects at unseen locations was also \nidentified.  The response of the \u2018next-object\u2019 subtask was to point to each object \ncorrectly in turn when the locations of objects were exemplified during training.  \nUnder a localist representation scheme, individual positions of objects are denoted by \nparticular elements of the input vector.  If the training data set lacks an example of an \nobject being located in, say, the 14th position, then the corresponding input node \nwould not have experienced an update in its connection weights during the training \nprocess.  Although this may be solved by ensuring a complete set of training patterns, \nthe network would still not be able to generalise in pointing to a larger number of \nobjects than the maximum sized set presented in training.  Two ways in which this \nmight be overcome concern: first, the weight-sharing of connections linking nodes \nwhich were involved in the learning process with nodes whose weights had not been; \nand, second, the use of explicit rules which, McClelland (1995) has proposed, might \ncombine with implicit strategies to direct children\u2019s behaviour. \nThe model presented here is only a first step in attempting to model the co-ordination \nof the two subtasks involved in counting.  Two limitations faced by this model are \nthat firstly, the work deals with one of the less complicated forms of counting \nwhereby the objects are immovable and positioned only in a row and secondly, both \nsubtasks are assumed to be learnt simultaneously whereas children are exposed to, and \ncan recite, the number word sequence before applying it in a counting procedure.  \nHowever, there is no reason why prior domain knowledge regarding either of the \nsubtasks cannot be incorporated into the relevant expert network in a mixture-of-\nexperts model, for example, through the initial set of weights. \n5 Conclusions \nIn this paper we have reported on two manifestations of numerosity, subitizing and \ncounting.  We have reviewed past simulations of these and related abilities, \nconcluding that the majority use either hard wiring of connections or supervised \nlearning techniques.  As a consequence, we examined the role of unsupervised \nMulti-net Simulation of Quantification \n27\/02\/04 Page 36 of 42 \nlearning as a way of modelling these two abilities and presented: a) a collaborative \nneural network for subitizing, and b) a collaborative neural network for counting. \nSubitization is regarded by some as a form of preverbal counting and by others as an \ninnate \u2018number sense\u2019; the fact that other animals appear to subitize makes the \nphenomenon interesting for brain sciences in general.  From a multi-net perspective, \nsubitizing appears to involve collaboration between modules, or specialised areas in \nthe brain, that perform visual object recognition, magnitude representation and sound \nor gesture generation, implying subitization of the number (of objects).  \nSSUBSYST, a modular unsupervised neural network system, performs as well as, and \nmarginally better than, the single network neural computing system developed by \nPeterson and Simon (2000): SUBIT-PDP.  It also compares well to Dehaene and \nChangeux\u2019s (1993) model, in which the origin of the modules is clouded.  For \nexample, the SUBIT-PDP system shows that the numerosities \u20181\u2019 to \u20183\u2019 are learnt \neasily.  Furthermore, both SSUBSYST and SUBIT-PDP exhibit an edge effect, having \ndifficulty learning intermediate numerosities in the range above \u20183\u2019.  This comparison \nshows that our unsupervised network appears to learn as well as or better than \nPeterson and Simon\u2019s.  However, the similarity between the occurrences of the edge \neffect are superficial; Peterson and Simon attempt to explain that the edge effect is \ndependent upon the input data, with larger numerosities being more infrequent in \nsubitization than smaller numerosities.  In contrast, because the SSUBSYST network \nuses the unsupervised learning paradigm, the edge effect can be explained because of \nidiosyncrasies in Kohonen\u2019s SOM learning algorithm. \nPeterson and Simon also appear to improve their network\u2019s performance by adding \nmore hidden layer elements, affecting the highest learnable numerosity and the range \nof intermediate values that suffer from poor learning.  Whereas the highest learnable \nnumerosity in SSUBSYST can be increased by making the size of the Kohonen map \nlarger, the overall performance is still subject to the self-organisation of the different \nmagnitudes into a number line, with higher numerosities being closer and closer \ntogether, comparing well the observations of child numerosity, namely Fechner\u2019s law \nand the distance effect.  Because of this self-organisation phenomenon the use of \nKohonen maps, or more particularly unsupervised learning, makes SSUBSYST more \nplausible than the supervised architecture used by Peterson and Simon.  Our argument \nof plausibility, how ever weak, relies on the fact that it is nearly impossible to teach a \nneonate the difference between quantities. \nAbove all, for us it is the modular nature of our network that provides a more \nplausible simulation of cognitive abilities, and perhaps contributes to the more \nambitious projects of Dehaene, who focuses on \u201ccharting meaning in the human brain \n[which] requires [..] discovering whether and how some of these features [of a number \nsystem] have been extracted in the course of cerebral evolution and have been \ninternalized in the brains of infants and animals\u201d (2000:42). \nIt is worth noting here that our agreement with Dehaene (2000) on subitization is \ngratifying in that his triple-code model comprises modules for analogue magnitude, \nvisual Arabic, and auditory verbal processing.  Subitization is understood to be \nperformed within the analogue magnitude module, in which an internal representation \nof numerosity is thought to reside, as we have simulated within SSUBSYST.  In \ncontrast, the rote learning of counting is associated with the auditory verbal module, \nwhich we simulate with SCOUSYST. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 37 of 42 \nCounting can be viewed as an inherently recursive task; as one counts a set of objects, \nthat is, makes a progression along a line, one has to refer back to the last object one \nhas counted.  Also, if one has to articulate the quantity counted thus far, one has to \ninterpret the recurrence in order to articulate.  Thus, counting involves two processes \nidentified in different neuronal architectures: recurrence and gating.  Counting, like \nsubitization, appears to involve a number of specialised areas in the brain.  In \ncounting we have a visual object recognition module, a cardinality representation \nmodule and a word-association module for verbal output.  In addition, these modules \ninteract with a short-term memory (module) to keep track of the counting process. \nRecurrence involves a small amount of transient memory in the system.  Gating is \nrequired for a system to learn which of the two networks is allowed to output.  In \nSCOUSYST we use both recurrence and gating to show how objects arranged in a \nline may be counted through both an indication act and articulation.  There is no direct \ncomparison of our work in existing neural network literature; Amit\u2019s (1989) work is \non number comprehension, but not number articulation, as with the majority of other \nworks reported in this paper, whereas Ma and Hirai\u2019s (1989) work concentrates on \nnumber articulation, but not counting.  Again, we have shown in SCOUSYST that by \nhaving a multi-net architecture one can simulate aspects of children\u2019s counting such \nas errors, and show how the errors decrease with age. \nFinally, it is important to remember that whatever the origin of knowledge in the \nhuman brain, whether innate or learnt, subitization exists in adults and is used for \nnumerical processing when time is short, even though the alternate counting \nmechanism is also present.  It appears that both processes, subitization and counting, \ncompete to process numbers, but that the human brain has learnt to gate the output of \none of the networks depending upon the amount of time available to do the numerical \nprocessing.  This concept is the focus of future work, whereby both SSUBSYST and \nSCOUSYST are to be combined into a single coherent multi-net system for \nquantification where the choice of processing path \u2013 to subitize or to count \u2013 is \nselected by time constraints imposed upon the simulation. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 38 of 42 \nReferences \nAbidi, S.S.R. & Ahmad, K. (1997).  Conglomerate Neural Network Architectures: \nThe Way Ahead for Simulating Early Language Development.  Journal of \nInformation Systems Engineering, vol. 13(2), pp. 235-266. \nAhmad, K., & Bale, T.A, (2001) Simulation of Quantification Abilities Using a \nModular Neural Network Approach.  Neural Computing and Applications, vol. \n10(1), pp. 77-88. \nAmari, S. (1980).  Topographic Organization of Nerve Fields.  Bulletin of \nMathematical Biology, vol. 42, pp. 339-364. \nAmit, D.J. (1989).  Modelling Brain Function: The World of Attractor Neural \nNetworks.  Cambridge, UK: Cambridge University Press. \nAmit, D.J. (1988).  Neural Networks Counting Chimes.  Proceedings of the National \nAcademy of Sciences, USA, vol. 85, pp. 2141-2145. \nAnderson, J.A. (1995).  An Introduction to Neural Networks.  Cambridge, MA.: MIT \nPress. \nAnderson, J.R. (1993).  Rules of the Mind.  Hillsdale, New Jersey: Lawrence Erlbaum \nAssociates. \nAnderson, J.A., Spoehr, K.T. & Bennett, D.J. (1994).  A Study in Numerical \nPerversity: Teaching Arithmetic to a Neural Network.  In Levine, D.S. & Aparicio, \nM. (Eds), Neural Networks for Knowledge Representation and Inference, pp 311-\n335.  Hillsdale, New Jersey: Lawrence Erlbaum Associates. \nBrannon, E.M. (2002).  The Development of Ordinal Numerical Knowledge in \nInfancy.  Cognition, vol. 83, pp. 223-240. \nBrannon, E.M. & Terrace, H.S. (1998).  Ordering of the Numerosities 1-9 by \nMonkeys.  Science, vol. 282, pp. 746-749. \nButterworth, B. (1999).  The Mathematical Brain.  London: Macmillan. \nCipolotti, L. & Butterworth, B. (1995).  Toward a Multiroute Model of Number \nProcessing: Impaired Number Transcoding with Preserved of Calculation Skills.  \nJournal of Experimental Psychology: General, vol. 124(4), pp. 375-390. \nCohen, L.B. & Chaput, H.H. (2002).  Connectionist Models of Infant Perceptual and \nCognitive Development.  Developmental Science, vol. 5(2), pp. 173-174. \nDallaway, R. (1994).  Dynamics of Arithmetic: A Connectionist View of Arithmetic \nSkills.  Cognitive Science Research Papers 306.  Brighton, UK: University of \nSussex. \nDehaene, S. (2000).  The Cognitive Neuroscience of Numeracy: Exploring the \nCerebral Substrate, the Development, and the Pathologies of Number Sense.  In \nFitzpatrick, S.M. & Bruer, J.T. (Eds), Carving Our Destiny: Scientific Research \nfaces a New Millennium, pp. 41-76.  Washington: Joseph Henry Press. \nDehaene, S. (1997).  The Number Sense: How the Mind Creates Mathematics.  \nLondon: Allen Lane, The Penguin Press. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 39 of 42 \nDehaene, S. (1992).  Varieties of Numerical Abilities.  In Dehaene, S. (Ed), \nNumerical Cognition (1993), pp. 1-42.  Cambridge, MA.: Blackwell Publishers. \nDehaene, S. & Changeux, J.P. (1993).  Development of Elementary Numerical \nAbilities: A Neuronal Model.  Journal of Cognitive Neuroscience, vol. 5(4), pp. \n390-407. \nDehaene, S. & Mehler, J. (1992).  Cross-Linguistic Regularities in the Frequency of \nNumber Words.  Cognition, vol. 43, pp. 1-29. \nElman, J. (1990).  Finding Structure in Time.  Cognitive Science, vol. 14, pp. 179-211. \nFahlman, S.E. & Lebiere, C. (1990).  The Cascade-Correlation Learning Architecture.  \nIn Touretzky, D.S. (Ed).  Advances in Neural Information Processing Systems, vol. \n2, pp.524-532.  San Mateo, CA.: Morgan Kaufmann. \nFukushima, K. and Miyake, S. (1982).  Neocognitron: A New Algorithm for Pattern \nRecognition Tolerant of Deformations and Shifts in Position.  Pattern Recognition, \nvol. 15(6), pp. 455-469. \nFuson, K.C. (1988).  Children\u2019s Counting and Concepts of Number.  Berlin, \nHeidelberg, New York: Springer-Verlag. \nFuson, K.C., Richards, J. & Briars, D.J. (1982).  The Acquisition and Elaboration of \nthe Number Word Sequence.  In Brainerd, C.J. (Ed), Children\u2019s Logical and \nMathematical Cognition: Progress in Cognitive Development Research, pp. 33-92.  \nBerlin, Heidelberg, New York: Springer-Verlag. \nGallistel, C.R. & Gelman, R. (1992).  Preverbal and Verbal Counting and \nComputation.  In Dehaene, S. (Ed), Numerical Cognition (1993), pp. 43-74.  \nCambridge, MA.: Blackwell Publishers. \nGelman, R. & Gallistel, C.R. (1978).  The Child\u2019s Understanding of Number.  \nCambridge, MA.: Harvard University Press. \nGelman, R. & Meck, E. (1983).  Preschoolers\u2019 Counting: Principles Before Skill.  \nCognition, vol. 13, pp. 343-359. \nGiles, C. L. & Maxwell, T. (1987).  Learning, Invariance, and Generalization in \nHigh-order Neural Networks.  Applied Optics, vol. 26(23), pp. 4972-4978. \nHoekstra, J. (1992).  Counting with Artificial Neural Networks: An Experiment.  In \nAleksander, I. & Taylor, J. (Eds.), Artificial Neural Networks, vol. 2, pp. \n1311-1314. \nHumphreys, G.W. (1998).  Neural Representation of Objects in Space: A Dual \nCoding Account.  Philosophical Transactions of the Royal Society of London, \nSeries B-Biological Sciences, vol. 353(1373), pp. 1341-1351. \nJacobs, R.A., Jordan, M.I. & Barto, A.G. (1991).  Task Decomposition through \nCompetition in a Modular Connectionist Architecture: The What and Where \nVision Tasks.  Cognitive Science, vol. 15, pp. 219-250. \nJevons, W.S. (1871).  The Power of Numerical Discrimination.  Nature, vol. 3, pp. \n44-64. \nKaufman, E.L., Lord, M.W., Reese, T.W. & Volkmann, J. (1949).  The \nDiscrimination of Visual Number.  American Journal of Psychology, vol. 62, pp. \n498-525. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 40 of 42 \nKirby, K.N. (1992).  Intensity of Stimulation, Necessary Truths, and the Acquisition \nof Numeracy.  Mind and Language, vol. 7(4), pp. 359-363. \nKohonen, T. (1997).  Self-Organizing Maps.  2nd Ed.  Berlin, Heidelberg, New York: \nSpringer-Verlag. \nMa, Q. & Hirai, Y. (1989).  Modeling the Acquisition of Counting with an \nAssociative Network.  Biological Cybernetics, vol. 61, pp. 271-278. \nMacWhinney, B. (1991).  The CHILDES Project: Tools for Analysing Talk.  \nHillsdale, New Jersey: Lawrence Erlbaum Associates.  \nMandler, G. & Shebo, B.J. (1982).  Subitizing: An Analysis of its Component \nProcesses.  Journal of Experimental Psychology: General, vol. 111, pp. 1 \u201322. \nMareschal, D. & Johnson, S.P. (2002).  Learning to Perceive Object Unity: A \nConnectionist Account.  Developmental Science, vol. 5(2), pp. 151-172. \nMareschal, D. & Shultz, T.R. (1999).  Development of Children's Seriation: A \nConnectionist Approach.  Connection Science, vol. 11(2), pp. 149-186. \nMcClelland, J.L. (1995).  A Connectionist Perspective on Knowledge and \nDevelopment.  In Simon, T.J. & Halford, G.S. (Eds).  Developing Cognitive \nCompetence: New Approaches to Process Modelling, pp. 157-204.  Hillsdale, New \nJersey: Lawrence Erlbaum Associates. \nMcCloskey, M., Caramazza, A. & Basili, A. (1985).  Cognitive Mechanisms in \nNumber Processing and Calculation: Evidence from Dyscalculia.  Brain and \nCognition, vol. 4, pp. 171-196. \nMcCloskey, M. & Lindemann, A.M. (1992).  MATHNET: Preliminary Results from a \nDistributed Model of Arithmetic Fact Retrieval.  In Campbell, J.I.D. (Ed).  The \nNature and Origins of Mathematical Skills, pp. 365-409.  North Holland: Elsevier \nScience Publishers B-V. \nMeck, W.H. & Church, R.M. (1983).  A Mode Control Model of Counting and \nTiming Processes.  Journal of Experimental Psychology: Animal Behavior \nProcesses, vol. 9(3), pp. 320-334. \nNye, J., Clibbens, J. & Bird, G. (1995).  Numerical Ability, General Ability and \nLanguage in Children with Down\u2019s Syndrome. Down's Syndrome: Research and \nPractice, vol. 3, pp. 92-102. \nPeterson, S.A. & Simon, T.J. (2000).  Computational Evidence for the Subitizing \nPhenomenon as an Emergent Property of the Human Cognitive Architecture.  \nCognitive Science, vol. 24(1), pp. 93-122. \nPiaget, J. (1952).  The Child\u2019s Conception of Number.  London: Routledge & Kegan \nPaul Limited. \nRodriguez, P., Wiles, J., Elman, J.L. (1999).  A Recurrent Neural Network that Learns \nto Count.  Connection Science, vol. 11(1), pp. 5-40. \nRumelhart, D.E., Hinton, G.E. & Williams, R.J. (1986).  Learning Internal \nRepresentations by Error Propagation.  In Rumelhart, D.E. & McClelland J.L. \n(Eds) (1986).  Parallel Distributed Processing: Explorations in the Microstructure \nof Cognition, Vol. 1: Foundations, pp. 318-362.  Cambridge, MA.: MIT Press. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 41 of 42 \nSharkey, A.J.C. (Ed) (1999).  Combining Artificial Neural Nets: Ensemble and \nModular Multi-Net Systems.  Berlin, Heidelberg, New York: Springer-Verlag. \nSophian, C. & Adams, N. (1987).  Infants\u2019 Understanding of Numerical \nTransformations.  British Journal of Developmental Psychology, vol. 5, pp. 257-\n264. \nSpelke, E. (1994).  Initial Knowledge: Six Suggestions.  Cognition, vol. 50, pp. 431-\n445. \nStrauss, M.S. & Curtis, L.E. (1984).  Development of Numerical Concepts in Infancy.  \nIn Sophian, C. (Ed).  Origins of Cognitive Skills, pp. 131-155.  Hillsdale, NJ: \nErlbaum. \nThompson, R.F., Mayers, K.S., Robertson, R.T. and Patterson, C.J. (1970).  Number \nCoding in Association Cortex of the Cat.  Science, vol. 168, pp. 271-273. \nTrick, L., & Pylyshyn, Z. (1994).  Why are Small and Large Numbers Enumerated \nDifferently?  A Limited-capacity Preattentive Stage in Vision.  Psychological \nReview, vol. 101, pp. 80-102. \nWillshaw, D.J. & von der Malsburg, C. (1976).  How Patterned Neural Connections \ncan be set up by Self-Organization.  Proceedings of the Royal Society, Series B, \nvol. 194, pp. 431-445. \nWynn, K. (1995).  Origins of Numerical Knowledge.  Mathematical Cognition, vol. \n1(1), pp. 35-60. \nWynn, K. (1992a).  Evidence Against Empiricist Accounts of the Origins of \nNumerical Knowledge.  Mind and Language, vol. 7(4), pp. 315-332. \nWynn, K. (1992b).  Issues Concerning a Nativist Theory of Numerical Knowledge.  \nMind and Language, vol. 7(4), pp. 367-381. \nMulti-net Simulation of Quantification \n27\/02\/04 Page 42 of 42 \nAcknowledgements \nTracey Bale gratefully acknowledges the support of UK Engineering and Physical \nSciences Council in terms of a PhD Studentship (1994-97) and that of the EU \nsponsored ACE Project (ESPRIT Project No. 22271, 1995-1998) from February to \nDecember 1998.  The authors would also like to thank the three anonymous reviewers \nof this article for their comments. \n"}
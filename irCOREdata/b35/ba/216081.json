{"doi":"10.1111\/j.1467-8292.2010.00422.x","coreId":"216081","oai":"oai:eprints.lse.ac.uk:30137","identifiers":["oai:eprints.lse.ac.uk:30137","10.1111\/j.1467-8292.2010.00422.x"],"title":"Measuring quality in social care services: theory and practice","authors":["Malley, Juliette","Fern\u00e1ndez, Jos\u00e9-Luis"],"enrichments":{"references":[{"id":17333803,"title":"A conceptual framework for the OECD Health Care Quality Indicators Project.","authors":[],"date":"2006","doi":"10.1093\/intqhc\/mzl024","raw":"ARAH, O. A., WESTERT, G. P., HURST, J. & KLAZINGA, N. S. (2006) A conceptual framework for the OECD Health Care Quality Indicators Project. Int J Qual Health Care, 18, 5-13.","cites":null},{"id":17333865,"title":"A conceptual model of service quality and its implications for future research.","authors":[],"date":"1985","doi":"10.2307\/1251430","raw":"PARASURAMAN, A., ZEITHMAL, V. & BERRY, L. (1985) A conceptual model of service quality and its implications for future research. Journal of Marketing, 49, 41-50.   25 PICKARD, L., WITTENBERG, R., COMAS-HERRERA, A., KING, D. & MALLEY, J.","cites":null},{"id":17333881,"title":"A framework for analysing the measurement of outcome. IN","authors":[],"date":"1996","doi":null,"raw":"SMITH, P. C. (1996) A framework for analysing the measurement of outcome. IN SMITH, P. C. (Ed.) Measuring outcome in the Public Sector. London, Taylor and Francis.","cites":null},{"id":17333868,"title":"A new conception of social care outcomes and its practical use in assessment with older people.","authors":[],"date":"2001","doi":null,"raw":"York, Joseph Rowntree Foundation QURESHI, H. & NICHOLAS, E. (2001) A new conception of social care outcomes and its practical use in assessment with older people. Research, Policy and Planning, 19, 11-26.","cites":null},{"id":17333857,"title":"A positive choice. Report of the independent review of residential care. Chaired by Gillian Wagner.","authors":[],"date":"1988","doi":"10.1017\/s0047279400017566","raw":"NATIONAL INSTITUTE FOR SOCIAL WORK (1988) A positive choice. Report of the independent review of residential care. Chaired by Gillian Wagner. London, HMSO.","cites":null},{"id":17333850,"title":"A Report on the Development Studies for the National Adult Social Care User Experience Survey, Discussion Paper 2721. Canterbury, Personal Social Services Research Unit.","authors":[],"date":"2010","doi":null,"raw":"MALLEY, J., CAIELS, J., FOX, D., MCCARTHY, M., SMITH, N., BEADLEBROWN, J., NETTEN, A. & TOWERS, A.-M. (2010) A Report on the Development Studies for the National Adult Social Care User Experience Survey, Discussion Paper 2721. Canterbury, Personal Social Services Research Unit.","cites":null},{"id":17333883,"title":"Accurate performance measure but meaningless ranking exercise? An analysis of the English school league tables.","authors":[],"date":"2008","doi":"10.1080\/10967490802301336","raw":"WILSON, D. & PIEBALGA, A. (2008) Accurate performance measure but meaningless ranking exercise? An analysis of the English school league tables. CMPO Working Paper No. 07\/176. Bristol, CMPO WOLFF, N. (2000) Using randomized controlled trials to evaluate socially complex services: problems, challenges and recommendations. The Journal of Mental Health Policy and Economics, 3, 97-109.","cites":null},{"id":17333818,"title":"Advancing Public Accountability? The Social Services 'Star' Ratings.","authors":[],"date":"2003","doi":"10.1111\/1467-9302.00356","raw":"CUTLER, T. & WAINE, B. (2003) Advancing Public Accountability? The Social Services 'Star' Ratings. Public Money & Management, 23, 125-128.","cites":null},{"id":17333843,"title":"Building the National Care Service, CM7854, London, The Stationery Office.","authors":[],"date":"2010","doi":null,"raw":"HM GOVERNMENT (2010) Building the National Care Service, CM7854, London, The Stationery Office.","cites":null},{"id":17333866,"title":"Care by Spouses, Care by Children: Projections of Informal Care for Older People in England to 2031. Social Policy and","authors":[],"date":"2007","doi":"10.1017\/s1474746407003685","raw":"(2007) Care by Spouses, Care by Children: Projections of Informal Care for Older People in England to 2031. Social Policy and Society, 6, 353-366.","cites":null},{"id":17333811,"title":"Caring for and caring about: Disentangling the caregiver effect and the family effect.","authors":[],"date":"2010","doi":"10.1016\/j.jhealeco.2010.05.003","raw":"BOBINAC, A., VAN EXEL, N. J. A., RUTTEN, F. F. H. & BROUWER, W. B. F. (2010) Caring for and caring about: Disentangling the caregiver effect and the family effect. Journal of Health Economics, 29, 549-556.","cites":null},{"id":17333878,"title":"Challenges in Measuring Nursing Home and Home Health Quality: Lessons From the First National Healthcare Quality Report.","authors":[],"date":"2005","doi":"10.1097\/00005650-200503001-00005","raw":"SANGL, J., SALIBA, D., GIFFORD, D. R. & HITTLE, D. F. (2005) Challenges in Measuring Nursing Home and Home Health Quality: Lessons From the First National Healthcare Quality Report. Medical Care, 43, I-24-I-32.","cites":null},{"id":17333844,"title":"Choices, Policy Logics and Problems in the Design of Long\u2013term Care Systems. Social Policy and","authors":[],"date":"2003","doi":"10.1111\/1467-9515.t01-1-00313","raw":"IKEGAMI, N. & CAMPBELL, J. C. (2003) Choices, Policy Logics and Problems in the Design of Long\u2013term Care Systems. Social Policy and Administration, 36, 719 -734.   23 INFORMATION CENTRE (2007) Personal Social Services Survey of Home Care Users in England aged 65 and over, 2005-06. Information Centre.","cites":null},{"id":17333831,"title":"Competition in the mixed economy of care.","authors":[],"date":"1996","doi":"10.1017\/s0047279400000313","raw":"FORDER, J., KNAPP, M. R. & WISTOW, G. (1996) Competition in the mixed economy of care. Journal of Social Policy, 25, 201-21.","cites":null},{"id":17333812,"title":"Concepts and Indicators of Local Authority Performance: An Evaluation of the Statutory Frameworks in England and Wales.","authors":[],"date":"2002","doi":"10.1111\/1467-9302.00303","raw":"BOYNE, G. A. (2002) Concepts and Indicators of Local Authority Performance: An Evaluation of the Statutory Frameworks in England and Wales. Public Money and Management, 22, 17-24.","cites":null},{"id":17333847,"title":"Cost functions for care services for the elderly.","authors":[],"date":"1978","doi":"10.1093\/geront\/18.1.30","raw":"KNAPP, M. (1978a) Cost functions for care services for the elderly. Gerontologist, 18, 30-36.","cites":null},{"id":17333876,"title":"Defining quality of care: mission impossible?","authors":[],"date":"1990","doi":"10.1093\/intqhc\/2.3-4.197","raw":"REERINK, E. (1990) Defining quality of care: mission impossible? Quality Assurance in Health Care, 2, 197-202.","cites":null},{"id":17333848,"title":"Economies of scale in residential care.","authors":[],"date":"1978","doi":"10.1108\/eb013822","raw":"KNAPP, M. (1978b) Economies of scale in residential care. International Journal of Social Economics, 5, 81-92.","cites":null},{"id":17333821,"title":"Equity and Efficiency Policy in Community Care,","authors":[],"date":"2000","doi":null,"raw":"DAVIES, B., FERN\u00c1NDEZ, J. L. & NOMER, B. (2000b) Equity and Efficiency Policy in Community Care, Aldershot, Ashgate.","cites":null},{"id":17333820,"title":"Equity and Efficiency Policy in Community Care.,","authors":[],"date":"2000","doi":null,"raw":"DAVIES, B., FERN\u00c1NDEZ, J.-L. & NOMER, B. (2000a) Equity and Efficiency Policy in Community Care., Aldershot, Ashgate.","cites":null},{"id":17333841,"title":"Governance and performance: New perspectives,","authors":[],"date":"2000","doi":"10.2307\/3094831","raw":"HEINRICH, C. J. & LYNN, L. (Eds.) (2000) Governance and performance: New perspectives, Washington D.C., Georgetown University Press.","cites":null},{"id":17333834,"title":"Helping the Aged, London, George Allen and Unwin.","authors":[],"date":"1970","doi":"10.1017\/s0033291700045049","raw":"GOLDBERG, E. M. (1970) Helping the Aged, London, George Allen and Unwin.","cites":null},{"id":17333845,"title":"How Do Performance Indicators Add Up? An Examination of Composite Indicators in Public Services.","authors":[],"date":"2007","doi":"10.1111\/j.1467-9302.2007.00565.x","raw":"JACOBS, R. & GODDARD, M. (2007) How Do Performance Indicators Add Up? An Examination of Composite Indicators in Public Services. Public Money and Management, 27, 103-110.","cites":null},{"id":17333829,"title":"How elderly people rank order the quality characteristics of home services.","authors":[],"date":"1995","doi":"10.1017\/s0144686x00002130","raw":"EDEBALK, P., SAMUELSSON, G. & INGVAD, B. (1995) How elderly people rank order the quality characteristics of home services. Ageing and Society, 15, 83\u2013 102.","cites":null},{"id":17333808,"title":"Income and health: the time dimension.","authors":[],"date":"2001","doi":"10.1016\/s0277-9536(00)00244-6","raw":"BENZEVAL, M. & JUDGE, K. (2001) Income and health: the time dimension. Social Science and Medicine, 52, 1371-90.","cites":null},{"id":17333842,"title":"Listening to Users of Domiciliary Care Services Leeds,","authors":[],"date":"1998","doi":null,"raw":"HENWOOD, M., LEWIS, H. & WADDINGTON, E. (1998) Listening to Users of Domiciliary Care Services Leeds, University of Leeds, Nuffield Institute for Health, Community Care Division.","cites":null},{"id":17333824,"title":"Making policy count:Developing performance indicators for health and social care partnerships. Position Paper Social Care.","authors":[],"date":"2009","doi":null,"raw":"DEPARTMENT FOR HEALTH (2009) Making policy count:Developing performance indicators for health and social care partnerships. Position Paper Social Care. IN DEPARTMENT FOR HEALTH (Ed.). London.","cites":null},{"id":17333840,"title":"Measuring public sector performance.","authors":[],"date":"2003","doi":"10.4135\/9781848608214.n3","raw":"HEINRICH, C. J. (2003) Measuring public sector performance. IN PETERS, B. G. & PIERRE, J. (Eds.) Handbook of public administration. London, Sage.","cites":null},{"id":17333859,"title":"Measuring the outcomes of care homes: Final report. Discussion Paper 2696\/2.","authors":[],"date":"2010","doi":null,"raw":"NETTEN, A., BEADLE-BROWN, J., TRUKESCHITZ, B., TOWERS, A.-M., WELCH, E., FORDER, J., SMITH, J. & ALDEN, E. (2010) Measuring the outcomes of care homes: Final report.  Discussion Paper 2696\/2. Canterbury, Kent, Personal Social Services Research Unit.","cites":null},{"id":17333851,"title":"Measuring User Experience of Social Care Services: A Discussion of Three Approaches. A Report to the Department of Health. Discusssion Paper 2529. Canterbury, Personal Social Services Research Unit.","authors":[],"date":"2008","doi":null,"raw":"MALLEY, J. & NETTEN, A. (2008) Measuring User Experience of Social Care Services: A Discussion of Three Approaches. A Report to the Department of Health. Discusssion Paper 2529. Canterbury, Personal Social Services Research Unit.","cites":null},{"id":17333836,"title":"Modelling the effect of pupil mobility on school differences in educational achievement.","authors":[],"date":"2007","doi":"10.1111\/j.1467-985x.2007.00491.x","raw":"GOLDSTEIN, H., SIMON, B. & MCCONNELL, B. (2007) Modelling the effect of pupil mobility on school differences in educational achievement. Journal of the Royal Statistical Society: Series A (Statistics in Society), 170, 941-954.","cites":null},{"id":17333825,"title":"Modernising Social Services: promoting independence, improving protection, raising standards.","authors":[],"date":"1998","doi":null,"raw":"DEPARTMENT OF HEALTH (1998) Modernising Social Services: promoting independence, improving protection, raising standards. CM 4169 ed., TSO.","cites":null},{"id":17333822,"title":"Old People's Homes and the Production of Welfare,","authors":[],"date":"1981","doi":null,"raw":"DAVIES, B. & KNAPP, M. (1981) Old People's Homes and the Production of Welfare, London, Routledge and Keegan Paul.","cites":null},{"id":17333867,"title":"Older people's definitions of quality services.","authors":[],"date":"2000","doi":null,"raw":"QURESHI, H. & HENWOOD, M. (2000) Older people's definitions of quality services.","cites":null},{"id":17333826,"title":"Our health, our care, our say: a new direction for community services,","authors":[],"date":"2006","doi":"10.1037\/e607972007-001","raw":"DEPARTMENT OF HEALTH (2006) Our health, our care, our say: a new direction for community services, Cm6737. IN DEPARTMENT FOR HEALTH (Ed.). London, TSO.","cites":null},{"id":17333854,"title":"Outcomes Important to People With Intellectual Disabilities.","authors":[],"date":"2008","doi":"10.1111\/j.1741-1130.2008.00167.x","raw":"MILLER, E., COOPER, S.-A., COOK, A. & PETCH, A. (2008) Outcomes Important to People With Intellectual Disabilities. Journal of Policy and Practice in Intellectual Disabilities, 5, 150-158.   24 MINISTERS, LOCAL GOVERNMENT, NHS, SOCIAL CARE & PROFESSIONAL AND REGULATORY ORGANISATIONS (2007) Putting people first: a shared vision and commitment to the transformation of adult social care. London, The Stationery Office.","cites":null},{"id":17333860,"title":"Outcomes of Social Care for Adults (OSCA). Interim findings. Discussion Paper 2648. Canterbury, Personal Social Services Research Unit.","authors":[],"date":"2009","doi":null,"raw":"NETTEN, A., BURGE, P., MALLEY, J., POTOGLOU, D., BRAZIER, J., FLYNN, T. & FORDER, J. (2009) Outcomes of Social Care for Adults (OSCA). Interim findings.  Discussion Paper 2648. Canterbury, Personal Social Services Research Unit.","cites":null},{"id":17333805,"title":"Outcomes of Social Care for Disabled People and Carers.","authors":[],"date":"1999","doi":null,"raw":"BAMFORD, C. H., QURESHI, H., NICHOLAS, E. & VERNON, A. (1999) Outcomes of Social Care for Disabled People and Carers. IN SOCIAL POLICY   20 RESEARCH UNIT (Ed.) Outcomes in Community Care Practice. York, Social Policy Research Unit.","cites":null},{"id":17333838,"title":"Outcomes-Based Performance Management in the Public Sector: Implications for Government Accountability and Effectiveness.","authors":[],"date":"2002","doi":"10.1111\/1540-6210.00253","raw":"HEINRICH, C. J. (2002) Outcomes-Based Performance Management in the Public Sector:  Implications for Government Accountability and Effectiveness. Public Administration Review, 62, 712-725.","cites":null},{"id":17333870,"title":"Overview: Outcomes of Social Care for Older People. Outcomes in Community Care Practice Series. York, Social Policy Research Unit.","authors":[],"date":"1998","doi":null,"raw":"QURESHI, H., PATMORE, C., NICHOLAS, E. & BAMFORD, C. H. (1998) Overview: Outcomes of Social Care for Older People. Outcomes in Community Care Practice Series. York, Social Policy Research Unit.","cites":null},{"id":17333816,"title":"Performance Assessment Handbook 2006-07. Adult Social Care Services. London, Commission for Social Care Inspection.","authors":[],"date":"2007","doi":null,"raw":"COMMISSION FOR SOCIAL CARE INSPECTION (2007) Performance Assessment Handbook 2006-07. Adult Social Care Services. London, Commission for Social Care Inspection.","cites":null},{"id":17333814,"title":"Performance Indicators in Social Care for Older People,","authors":[],"date":"2006","doi":"10.1017\/s0144686x08007101","raw":"CHALLIS, D., CLARKSON, P. & WARBURTON, R. (2006) Performance Indicators in Social Care for Older People, Aldershot, Ashgate.","cites":null},{"id":17333882,"title":"Performance Ratings for Social Services in England,","authors":[],"date":"2002","doi":null,"raw":"SOCIAL SERVICES INSPECTORATE (2002) Performance Ratings for Social Services in England, November 2002. London, Department of Health,.   26 STEEL, N., MELZER, D., SHEKELLE, P. G., WENGER, N. S., FORSYTH, D. & MCWILLIAMS, B. C. (2004) Developing quality indicators for older adults: transfer from the USA to the UK is feasible. Quality and Safety in Health Care, 13:, 260-264.","cites":null},{"id":17333819,"title":"Production of Welfare Approach. Discussion Paper 400. Canterbury, Personal Social Services Research Unit.","authors":[],"date":"1985","doi":null,"raw":"DAVIES, B. (1985) Production of Welfare Approach. Discussion Paper 400. Canterbury, Personal Social Services Research Unit.   21 DAVIES, B. & CHALLIS, D. (1986) Matching Resources to Needs in Community Care, Aldershot, Gower.","cites":null},{"id":17333862,"title":"Provider and care workforce influences in quality of home care services in England.","authors":[],"date":"2007","doi":"10.1300\/j031v19n03_06","raw":"NETTEN, A., JONES, K. & SANDHU, S. (2007) Provider and care workforce influences in quality of home care services in England. Journal of Aging and Social Policy, 19, 81-97.","cites":null},{"id":17333852,"title":"Putting People First: Development of the Putting People First User Experience Survey. Discussion Paper 2637. Canterbury, Personal Social Services Research Unit.","authors":[],"date":"2009","doi":null,"raw":"MALLEY, J. & NETTEN, A. (2009) Putting People First: Development of the Putting People First User Experience Survey.  Discussion Paper 2637. Canterbury, Personal Social Services Research Unit.","cites":null},{"id":17333872,"title":"Quality at home for older people. Involving Service users in defining home care specifications, York, The Policy press and Joseph rowntree Foundation.","authors":[],"date":"2001","doi":"10.1017\/s0144686x03211405","raw":"RAYNES, N., TEMPLE, B., GLENISTER, C. & COULTHARD, L. (2001) Quality at home for older people.  Involving Service users in defining home care specifications, York, The Policy press and Joseph rowntree Foundation.","cites":null},{"id":17333874,"title":"Quality of life. In National Care Homes Research Forum. My Home Life Report.","authors":[],"date":"2007","doi":null,"raw":"REED, J. (2007) Quality of life. In National Care Homes Research Forum. My Home Life Report. N.","cites":null},{"id":17333832,"title":"Raising the quality of home care: a study of service users' views. Social policy and administration,","authors":[],"date":"2004","doi":"10.1111\/j.1467-9515.2004.00391.x","raw":"FRANCIS, J. & NETTEN, A. (2004 ) Raising the quality of home care: a study of service users' views. Social policy and administration, 38, 290-305.","cites":null},{"id":17333830,"title":"Regional variability in public long-term care expenditure in England: the significance of local autonomy, exogenous influences and local spillovers. PSSRU Discussion Papers.","authors":[],"date":"2006","doi":null,"raw":"FERNANDEZ, J.-L. & FORDER, J. (2006) Regional variability in public long-term care expenditure in England: the significance of local autonomy, exogenous influences and local spillovers. PSSRU Discussion Papers.   22 FERNANDEZ, J.-L., KENDALL, J., DAVEY, V. & KNAPP, M. (2007) Direct payments in England: factors linked to variations in local provision. Journal of Social Policy, 36, 97\u2013121.","cites":null},{"id":17333863,"title":"Securing better outcomes: developing a new performance framework.","authors":[],"date":"2005","doi":null,"raw":"OFFICE OF THE DEPUTY PRIME MINISTER (2005) Securing better outcomes: developing a new performance framework. IN MINISTER, O. O. T. D. P. (Ed.). The Stationery Office.","cites":null},{"id":17333804,"title":"Social Care in Old Age: More Than a Funding Problem.","authors":[],"date":"1997","doi":"10.1111\/1467-9515.00039","raw":"BALDOCK, J. (1997) Social Care in Old Age: More Than a Funding Problem. Social Policy & Administration, 31, 73-89.","cites":null},{"id":17333810,"title":"Social determinants of health - socioeconomic status, social class, and ethnicity.","authors":[],"date":"1995","doi":"10.2105\/ajph.85.7.903","raw":"BLANE, D. (1995) Social determinants of health - socioeconomic status, social class, and ethnicity. American Journal of Public Health, 85, 903-5.","cites":null},{"id":17333833,"title":"Social Work and Direct Payments,","authors":[],"date":"2002","doi":"10.1017\/s0047279403337092","raw":"GLASBY, J. & LITTLECHILD, R. (2002) Social Work and Direct Payments, Bristol, Policy Press.","cites":null},{"id":17333809,"title":"Structure and logic of regulation and governance of quality of health care: was OFSTED a model for the Commission for Health Improvement? Health Economics,","authors":[],"date":"2006","doi":"10.1017\/s1744133106005020","raw":"BEVAN, G. & CORNWELL, J. (2006) Structure and logic of regulation and governance of quality of health care: was OFSTED a model for the Commission for Health Improvement? Health Economics, Policy and Law, 1, 343-370.","cites":null},{"id":17333879,"title":"The concept of quality of life: what we know and do not know.","authors":[],"date":"2004","doi":"10.1111\/j.1365-2788.2003.00558.x","raw":"SCHALOCK, R. L. (2004) The concept of quality of life: what we know and do not know. Journal of Intellectual Disability Research, 48, 203-216.","cites":null},{"id":17333846,"title":"The Dilemma of the unsatisfied customer in a market model of public administration.","authors":[],"date":"2005","doi":"10.1111\/j.1540-6210.2005.00432.x","raw":"KELLY, J. M. (2005) The Dilemma of the unsatisfied customer in a market model of public administration. Public Administration Review, 65, 76-84.","cites":null},{"id":17333849,"title":"The economics of social care,","authors":[],"date":"1984","doi":"10.1017\/s0047279400015099","raw":"KNAPP, M. (1984) The economics of social care, Basingstoke, Macmillan.","cites":null},{"id":17333880,"title":"The management and effectiveness of the home care service.","authors":[],"date":"2000","doi":null,"raw":"SINCLAIR, I., GIBBS, I. & HICKS, L. (2000) The management and effectiveness of the home care service. York, Social Work Research and Development Unit,.","cites":null},{"id":17333813,"title":"The measurement of outcome in social care of the elderly.","authors":[],"date":"1981","doi":"10.1017\/s004727940001062x","raw":"CHALLIS, D. (1981) The measurement of outcome in social care of the elderly. Journal of social policy, 10, 179-208.","cites":null},{"id":17333817,"title":"The new performance framework for local authorities and local authority partnerships: single set of national indicators.","authors":[],"date":"2007","doi":null,"raw":"COMMUNITIES AND LOCAL GOVERNMENT (2007) The new performance framework for local authorities and local authority partnerships: single set of national indicators. IN COMMUNITIES AND LOCAL GOVERNMENT (Ed.). TSO.","cites":null},{"id":17333864,"title":"The Quality Dimension. Evaluating Quality of Service and Quality of Life in Human Services.","authors":[],"date":"1992","doi":null,"raw":"OSBORNE, S. P. (1992) The Quality Dimension. Evaluating Quality of Service and Quality of Life in Human Services. Br J Soc Work, 22, 437-453.","cites":null},{"id":17333828,"title":"The quality of care. How can it be assessed?","authors":[],"date":"1988","doi":"10.1001\/jama.1988.03410120089033","raw":"DONABEDIAN, A. (1988) The quality of care. How can it be assessed? JAMA, 260, 1743-1748.","cites":null},{"id":17333855,"title":"The Quality of Quality Measurement in U.S. Nursing Homes.","authors":[],"date":"2003","doi":null,"raw":"MOR, V., BERG, K., ANGELELLI, J., GIFFORD, D., MORRIS, J. & MOORE, T. (2003) The Quality of Quality Measurement in U.S. Nursing Homes. The Gerontologist, 43, 37-46.","cites":null},{"id":17333837,"title":"The Standards we Expect: what services users and carers want from social services workers, London, The National Instiute for Social Work.","authors":[],"date":"1996","doi":null,"raw":"HARDING, T. & BERESFORD, P. (1996) The Standards we Expect: what services users and carers want from social services workers, London, The National Instiute for Social Work.","cites":null},{"id":17333827,"title":"TRANSFORMING SOCIAL CARE, Local Authority Circular LAC (DH)","authors":[],"date":"2008","doi":null,"raw":"DEPARTMENT OF HEALTH (2008) TRANSFORMING SOCIAL CARE, Local Authority Circular LAC (DH) (2008) 1. IN HEALTH, D. O. (Ed.). DONABEDIAN, A. (1980) Explorations on Quality Assessment and Monitoring. The Definition of Quality and Approaches to its Assessment, Michigan, Ann Arbor.","cites":null},{"id":17333823,"title":"University Costs and Outputs,","authors":[],"date":"1976","doi":"10.1017\/s0047279400005237","raw":"DAVIES, B. & VERRY, D. (1976) University Costs and Outputs, Amsterdam, Elsevier.","cites":null},{"id":17333853,"title":"Younger Adults\u2019 Understanding of Questions for a Service User Experience Survey: A Report to the Information Centre for Health and Social Care. PSSRU Discussion Paper 2360. Canterbury, Personal Social Services Research Unit.","authors":[],"date":"2006","doi":null,"raw":"MALLEY, J., SANDHU, S. & NETTEN, A. (2006) Younger Adults\u2019 Understanding of Questions for a Service User Experience Survey: A Report to the Information Centre for Health and Social Care. PSSRU Discussion Paper 2360. Canterbury, Personal Social Services Research Unit.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2010","abstract":"Measuring and assessing service quality in the social care sector presents distinct challenges. The 'experience' good properties of social care, for instance, and the large influence played by subjective judgements about the quality of personal relationships between carer and user and of process-related service characteristics make it difficult to develop indicators of service quality, including those of service impact on final outcomes. Using some of the key features of the 'Production of Welfare' approach, the paper discusses recent developments in the UK of the theoretical and practical frameworks used for assessing quality in social care and for understanding the final impact of services on the wellbeing of their recipients. Key current and future challenges to the development of such frameworks include difficulties in disentangling the impact of social care services on final outcomes from the often dominating effects of other, non-service related factors, and the generalization of consumer-directed care models and of the 'personalization' of care services. These challenges are discussed in the context of the different possible applications of quality indicators, including their role as supporting the service commissioning process and their use for assessing the performance of service providers","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/216081.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/30137\/1\/Measuring%20quality%20in%20social%20care%20services%20%28LSERO%29.pdf","pdfHashValue":"572a7082bd6e00c7593085a464243ca546faaaaf","publisher":"Blackwell Publishing on behalf of the International Centre of Research and Information on the Public, Social and Cooperative Economy (CIRIEC)","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:30137<\/identifier><datestamp>\n      2012-05-23T09:41:05Z<\/datestamp><setSpec>\n      74797065733D43454E54524553:4C53455F52435F3536<\/setSpec><setSpec>\n      74797065733D43454E54524553:4C53455F52435F3839<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/30137\/<\/dc:relation><dc:title>\n        Measuring quality in social care services: theory and practice<\/dc:title><dc:creator>\n        Malley, Juliette<\/dc:creator><dc:creator>\n        Fern\u00e1ndez, Jos\u00e9-Luis<\/dc:creator><dc:subject>\n        HV Social pathology. Social and public welfare. Criminology<\/dc:subject><dc:subject>\n        RA Public aspects of medicine<\/dc:subject><dc:description>\n        Measuring and assessing service quality in the social care sector presents distinct challenges. The 'experience' good properties of social care, for instance, and the large influence played by subjective judgements about the quality of personal relationships between carer and user and of process-related service characteristics make it difficult to develop indicators of service quality, including those of service impact on final outcomes. Using some of the key features of the 'Production of Welfare' approach, the paper discusses recent developments in the UK of the theoretical and practical frameworks used for assessing quality in social care and for understanding the final impact of services on the wellbeing of their recipients. Key current and future challenges to the development of such frameworks include difficulties in disentangling the impact of social care services on final outcomes from the often dominating effects of other, non-service related factors, and the generalization of consumer-directed care models and of the 'personalization' of care services. These challenges are discussed in the context of the different possible applications of quality indicators, including their role as supporting the service commissioning process and their use for assessing the performance of service providers.<\/dc:description><dc:publisher>\n        Blackwell Publishing on behalf of the International Centre of Research and Information on the Public, Social and Cooperative Economy (CIRIEC)<\/dc:publisher><dc:date>\n        2010<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/30137\/1\/Measuring%20quality%20in%20social%20care%20services%20%28LSERO%29.pdf<\/dc:identifier><dc:identifier>\n          Malley, Juliette and Fern\u00e1ndez, Jos\u00e9-Luis  (2010) Measuring quality in social care services: theory and practice.  Annals of Public and Cooperative Economics, 81 (4).  pp. 559-582.  ISSN 1370-4788     <\/dc:identifier><dc:relation>\n        http:\/\/www.wiley.com\/bw\/journal.asp?ref=1370-4788<\/dc:relation><dc:relation>\n        10.1111\/j.1467-8292.2010.00422.x<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/30137\/","http:\/\/www.wiley.com\/bw\/journal.asp?ref=1370-4788","10.1111\/j.1467-8292.2010.00422.x"],"year":2010,"topics":["HV Social pathology. Social and public welfare. Criminology","RA Public aspects of medicine"],"subject":["Article","PeerReviewed"],"fullText":"  \nJuliette Malley and Jos\u00e9-Luis Fern\u00e1ndez \nMeasuring quality in social care services: \ntheory and practice \n \nArticle (Accepted version) \n(Refereed) \n \n \n \nOriginal citation: \nMalley, Juliette and Fern\u00e1ndez, Jos\u00e9-Luis (2010) Measuring quality in social care services: \ntheory and practice. Annals of public and cooperative economics, 81 (4). pp. 559-582. ISSN \n1370-4788 \nDOI: 10.1111\/j.1467-8292.2010.00422.x  \n \n\u00a9 2010 the authors \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/30137\/ \nAvailable in LSE Research Online: May 2012 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final manuscript accepted version of the journal article, \nincorporating any revisions agreed during the peer review process.  Some differences between \nthis version and the published version may remain.  You are advised to consult the publisher\u2019s \nversion if you wish to cite from it. \n \n \n 1 \nMeasuring quality in social care services: theory and \npractice \nJuliette Malley and Jos\u00e9-Luis Fern\u00e1ndez \nPSSRU, London School of Economics and Political Science \n \n \nABSTRACT  \nMeasuring and assessing service quality in the social care sector presents distinct \nchallenges. The \u2018experience\u2019 good properties of social care, for instance, and the large \ninfluence played by subjective judgements about the quality of personal relationships \nbetween carer and user and of process-related service characteristics make it difficult to \ndevelop indicators of service quality, including those of service impact on final outcomes. \nUsing some of the key features of the \u2018Production of Welfare\u2019 approach, the paper \ndiscusses recent developments in the UK of the theoretical and practical frameworks used \nfor assessing quality in social care and for understanding the final impact of services on \nthe wellbeing of their recipients. Key current and future challenges to the development of \nsuch frameworks include difficulties in disentangling the impact of social care services \non final outcomes from the often dominating effects of other, non-service related factors, \nand the generalisation of consumer-directed care models and of the \u2018personalisation\u2019 of \ncare services. These challenges are discussed in the context of the different possible \napplications of quality indicators, including their role as supporting the service \ncommissioning process and their use for assessing the performance of service providers. \n \n 2 \n1 INTRODUCTION \nGovernments across the world have introduced reforms to social care services to \ndiversify provider markets, for example allowing (and in some cases exhorting) \nauthorities with responsibility for provision of social care to purchase services from \nindependent for-profit and not for-profit firms (Forder et al., 1996, Ikegami and \nCampbell, 2003).  Alongside these provider-side reforms there have also been attempts to \ndiversify purchaser markets and give service users more choice and control over their \ncare, through the introduction of consumer-directed care reforms (Glasby and Littlechild, \n2002).  The resulting increased separation between service commissioners and providers \nhas led to information problems, notably around the ability of service commissioners to \njudge the quality of services.  Quality measures are required by purchasers to aid them in \ntheir commissioning decisions and to contribute to the monitoring of aspects of \nperformance, such as efficiency and effectiveness.  In times of fiscal austerity and \nretrenchment in public services it is all the more important to measure quality to ensure \nthat quality does not suffer unduly at the expense of initiatives to save costs. The present \narticle discusses the particular theoretical and practical challenges presented by the \nmeasurement of service quality in social care.   \nWe first provide a discussion of the conceptual issues and analytical problems involved \nin the measurement and operationalisation of the concept of service quality in social care.  \nIn particular we consider the specific characteristics of social care which make quality \ndifficult to define and to measure and argue that the focus of quality measurement should \nbe on measuring outcomes.  We discuss some of the analytical problems inherent in this \nchoice of focus and illustrate, using key features of the \u2018Production of Welfare\u2019 approach, \nhow some of these difficulties could be conceptualised and overcome.  Finally, we \nreview some of the challenges for quality measurement likely to emerge in the future, \ngiven the evolving nature and context of the social care system.  Although the paper is \nframed around English examples, its central messages are relevant to policy discussions \nin the majority of developed countries. \n \n 3 \n2 MEASURING THE QUALITY OF SOCIAL CARE SERVICES \nMeasuring the quality of social care presents distinct conceptual and analytical \nchallenges, not least because of its complex multi-dimensionality and the different \nmeanings attached to the quality by alternative social care stakeholders.  Overall, users of \nsocial care services have tended to perceive service quality in terms of either aspects of \n\u2018quality of care\u2019 or of \u2018quality of life\u2019 (Reed, 2007, Osborne, 1992).  Frequently cited \naspects of quality of care include service accessibility, accountability, attitudes and \nbehaviour of staff, continuity of care workers, fluid communication of changes in care, \nflexibility of the service to meet changing needs, privacy and dignity, reliability and \nresponsiveness of care workers, and skills, knowledge and trustworthiness of staff \n(Qureshi and Henwood, 2000, Edebalk et al., 1995, Harding and Beresford, 1996, \nQureshi et al., 1998, Henwood et al., 1998, Sinclair et al., 2000, Francis and Netten, 2004 \n, Malley et al., 2006, Raynes et al., 2001).  Aspects of quality of life associated with \nservices include the extent to which they help improve users' health and physical \nfunctioning, they meet basic physical needs with activities of daily living, they guarantee \npersonal safety and security, ensure a clean and tidy environment, help users stay alert \nand active, provide access to social contact, ensure users are in control of their life, \nmaximise autonomy, skills, morale and self confidence, and assist users coming to terms \nwith impairment (Bamford et al., 1999, Qureshi et al., 1998, Miller et al., 2008).  In \naddition to these items, service managers and policy makers frequently include additional \naspects such as efficiency and equity as essential components of a high quality service \n(Donabedian, 1980).   \n \nSocial care services provide help with intimate tasks such as washing and dressing, which \nrequire the \u2018consumer\u2019 of care to act as a co-producer of their own care and to interact \nclosely with the service provider.  Understanding this collaborative aspect of social care, \nand the central role of the carer-service user relationship in defining the unit of \nproduction and consumption of care is therefore fundamental to assessing effectively \nservice quality (Donabedian, 1988).  By focusing on this relationship as the object of \n 4 \nquality measurement, we ensure that assessments of quality are not divorced from the \npractice of caring, which has been a critique of some early quality assessment systems for \nsocial care (National Institute for Social Work, 1988).  This focus also excludes from \nquality assessment aspects such as equity, efficiency and accessibility which are perhaps \nbetter considered as indicators of 'aggregate' performance of the support system in \ngeneral, rather than defining the quality of the care worker-service user relationship \n(Reerink, 1990).  These service-related aspects can be used therefore to evaluate the \nservice rather than assess the quality of social care (Arah et al., 2006, Schalock, 2004, \nDonabedian, 1980).   \n2.1 Identifying indicators of quality: structure, process or outcomes? \nThe assessment in practice of quality requires the identification of indicators which are \nsufficiently sensitive to variations in the key aspects of quality outlined above.  In this \ncontext, it is useful to distinguish between indicators that focuss on structure, process and \noutcomes. Structural indicators refer to the \u201crelatively stable characteristics of the \nproviders of care, of the tools and resources they have at their disposal, and of the \nphysical and organizational settings in which they work\u201d (Donabedian, 1980, p. 81); \nprocess indicators refer to the activities that go on within and between care workers and \nservice users; and outcome indicators to the desired (and undesired) results of the care \nactivity.   \n \nIdentifying good quality indicators (QIs) in social care pertaining to any of the three \ngroups is a complex task.  Like all service goods, social care services possess three \ncharacteristics which make quality difficult to assess (Parasuraman et al., 1985).  First, \nservices are best described as 'performances', so their products are intangible and cannot \nbe easily measured, counted, tested or verified; rather they are 'experienced' goods, which \nrequire first-hand contact to establish some of its most valued characteristics.  Second, \nsocial care services are labour intensive, which can lead to a high degree of service \nheterogeneity. As a result, service performance can vary significantly from producer to \n 5 \nproducer, by producer from day to day, and by producer from consumer to consumer.  \nThird, consumption and production of service goods is simultaneous and inseparable, and \nit is therefore difficult to disentangle the providers' influence on the quality of the service \nfrom that of users (Baldock, 1997).  Overall, these features of the social care 'good' mean \nthat social care services have few \u2018search\u2019 properties identifying core aspects of quality \nthat can be easily observed, measured and therefore known ex ante.   \n \nAvailable search properties tend to be associated with structural quality indicators.  \nRelevant examples include for instance whether residential care homes offer single-\noccupancy rooms, the size of rooms and the range of facilities available in a care home.  \nWhere the service does not have physical attributes, for instance in the case of home care \nsupport with activities of daily living such as dressing, feeding and going to the toilet \nwithin the person\u2019s own home, it is very difficult to identify search properties.  In this \ncase, potentially searchable properties relate to relatively stable characteristics of the care \nworker that can be known prior to purchase, such as their qualifications and employment \nexperience.  These characteristics, however, are often poor predictors of overall \nsatisfaction with services. \n \nStructural quality indicators present a series of limitations.  Because they concentrate on \nrelatively stable properties of the service, they are relatively insensitive to changes in \nquality through time. They are also, by definition, removed from the core focus of quality \nassessment \u2013 the care worker-service user relationship.  In this respect, structural \nindicators are only indirect measures of quality; they are a necessary but not sufficient \ncondition for quality. Although, there is some evidence from the US to suggest that \ncertain structural features of nursing homes (such as the nurse-patient ratio) are highly \nassociated with good quality care (Sangl et al., 2005), evidence from England has found \nthat features such as care worker qualifications and hours of training have a complex and \nnot unequivocally positive relationship with user\u2019s perceptions of home care service \n 6 \nquality (Netten et al., 2007).  The appropriateness of structural indicators as QIs remains \ntherefore questionable, with further research required to establish the detailed nature of \ntheir link to the concept of social care quality. \n \nIn contrast with 'search' properties, \u2018experience\u2019 properties relate directly to the care \nperformance, and can only be determined subsequent to purchasing the good or during \nconsumption (Parasuraman et al., 1985).  For social care, examples would include many \nof the aspects of quality of care as stated by service users, such as flexibility, the degree \nof empathetic behaviour displayed by the care worker, the way the care worker \ncommunicates to the care consumer and other \u2018softer\u2019 caring abilities.  Experience \nproperties would also include aspects of quality of life, such as feelings of safety, control \nover daily life, and improvements in physical functioning.  \u2018Credence\u2019 properties differ \nfrom search and experience properties in that consumers are likely to find them difficult \nto evaluate even after purchase.  These properties are largely associated with the technical \naspects of services, where the consumer does not have the knowledge to assess the skill \nwith which the activities are carried out.  Although social care does have a \u2018technical\u2019 \ncomponent (for example, the skill and knowledge required to lift and transfer frail older \npeople), in general it requires a relatively low level of technical know-how to administer \nsocial care interventions (c.f. Donabedian, 1988).  Most formal social care is provided by \npara-professionals, such as home care assistants, rather than professionals like social care \nworkers and nurses.  A very large amount of care is also provided by often untrained \nfamily, friends and volunteers.  In England, for instance, it is estimated that \napproximately 85 per cent of older people with functional disabilities living in private \nhouseholds receive \u2018informal\u2019 care (Pickard et al., 2007).  Experience properties therefore \ndominate the assessment of social care service quality, and are the basis for the \nconstruction of process and outcome quality indicators.   \n \n 7 \nThere is some debate as to the relative merits of focussing on process or outcome \nindicators of quality.  Although both are direct measures of the care performance, process \nindicators focus on the way the service is delivered and outcome indicators focus on the \nresult of care activity.  In part, the choice between process and outcome indicators \ndepends on the purpose of measurement.  Process quality indicators, for instance, are \noften used by service managers as tools for service improvement, as they are more \namenable to direct managerial intervention (Steel et al., 2004).   \nThe continuous and long term nature of much social care service use means that the way \ncare is delivered, the process aspects, become an integral part of the service user\u2019s life.  \nFor this reason, and despite not being directly related to the purpose of the intervention, \nprocess indicators may be of interest in their own right.  For instance, \u201cprocess\u201d \ncharacteristics such as having a say in what is provided, when and how service are \ndelivered, being valued and treated with respect, and being treated as an individual have \nbeen identified as key determinants of social care quality (Qureshi and Nicholas, 2001, \nBamford et al., 1999, Sangl et al., 2005).  Health economists in the UK have begun to \nincorporate aspects of process into health care valuation tools in an attempt to recognise \nthat intrinsic value associated with the way care is delivered (Kelly, 2005). Similar steps \nhave been made in measures designed specifically to value social care services (Netten et \nal., 2009).  \nOutcome indicators, as direct indicators of the final impact of the service, are preferable \nfor the purpose of comparing quality across different types of services (process related \nquality indicators, in contrast, tend to be highly service-specific).  However, some \ncommentators have doubted the feasibility of the systematic measurement of final \noutcomes in a timely and accurate manner \u2013 and in particular our ability to identify the \nspecific contribution of services to outcomes (Donabedian, 1988).  Whilst recognising \nthese difficulties, a growing consensus is emerging which views outcomes as the ultimate \nmeasures of quality due to their direct relationship with the final aims of the care activity, \nand the problems in establishing an unequivocal link between service process indicators \nand service quality (Mor et al., 2003, Reed, 2007).   \n 8 \n \n2.2 Measuring social care outcomes \nFrom an economic perspective, outcomes are not just defined in terms of the positive (or \nnegative) effect of services, but also in terms of the value of the effect.  They are \ntherefore indicative of the benefit accrued from the intervention (Smith, 1996).  In social \ncare assessing, benefit (and indeed effect) is complicated by the co-production and co-\nconsumption of care and by the presence of caring externalities.  Since care is co-\nproduced and co-consumed by both care worker and service user, benefits (and \ndisbenefits) from care can accrue to either party.  In addition, formal services can have \npositive (as well as negative) externalities.  Social care, particularly when it is \ncommunity-based, is often provided by a mixture of formal services and informal help \nfrom a wider care network composed of family members, neighbours and friends.  \nFormal support can enhance the well-being of the wider care network, by giving them a \n\u2018break\u2019 from the often very significant demands of caring.  Poor social care, in contrast, \ncan also harm the well-being of the same network when poorly organised or ineffective.  \n \nIdeally, the assessment of service quality should capture outcomes for everyone involved \neither directly or indirectly in the care intervention.  However, in spite of emerging \nresearch in the area (see for instance Bobinac et al., 2010), it is rarely possible to measure \noutcomes for the entire care network.  As a result, in the public sector, recent efforts for \nmeasuring service outcomes have focused on user outcomes for the purpose of service \nquality assessment (Heinrich, 2002, Heinrich, 2003, Department of Health, 2006).  In the \nEnglish context, for instance, recent government policy has promoted the following user-\nrelated outcomes for social care services: \u201cimproved health and emotional well-being\u201d; \n\u201cimproved quality of life\u201d; \u201cmaking a positive contribution\u201d; \u201cchoice and control\u201d; \n\u201cfreedom from discrimination\u201d; \u201ceconomic well-being\u201d; \u201cpersonal dignity\u201d (Department \nof Health, 2006).  This focus on care recipients implicitly assumes that the impact of the \nintervention on the wider care network and care staff is of lesser consequence.  Too sharp \n 9 \na focus on recipients clearly has the potential to \u2018miss\u2019 important impacts of social care \nand provide a one-sided view (Challis, 1981).   \n \nSocial care services attempt to maximise the quality of life of individuals who are not \nfully capable of long-term self-care.  Importantly, their aim is generally not to improve or \nremediate the underlying impairment (as is often the aim of medical care) but to \ncompensate the person for the impact of their impairments on their physical and mental \nfunctioning.  As suggested by Qureshi and Nicholas (2001), social care is therefore low \nin \u201cchange\u201d outcomes, which aim to lessen the person\u2019s underlying level of impairment, \nand high in \u201cmaintenance\u201d outcomes, where the aim is to maintain the person\u2019s quality of \nlife or physical and mental functioning.   \n \nIt is relatively straightforward, in theory at least, to assess the outcomes of interventions \naiming to produce change outcomes. Typically, these interventions (such as rehabilitation \nservices) are provided for a defined period of time, and outcomes can be measured in \nterms of changes in quality of life (or physical functioning state) before and after the \nintervention.  However, services producing maintenance outcomes are much more \ndifficult to assess.  First, such services tend to be provided continuously, often on a daily \nbasis until a person dies, in the context of an unavoidable deterioration in the physical \nand mental functioning of the service user.  As a result service inputs may actually \nincrease over time, as the service has to do more to compensate the person for the effect \ntheir worsening impairments have on their quality of life.  Second, the capacity of the \nservice to compensate a person for their impairment may also decline over time, as it may \nbecome harder to maintain some aspects of quality of life.  The assessment of the impact \nof the service on quality of life or functioning is therefore hampered by a natural \ndeterioration through time in the state of most social care users.  For example, as a person \nmoves from moderate to severe cognitive impairment it may be more difficult to maintain \n 10 \naspects of quality of life related to self-determination, as the person simply no longer has \ncapability in this dimension.   \n \n2.3 Attribution and the \u2018Production of Welfare\u2019 framework \nRegardless of the particular quality indicator chosen, observed outcome levels will be \nproduct of the joint influence of service related factors, and of factors outside of the \ninfluence of the service, such as the level of need of the service user (Goldberg, 1970).  In \nfact, decades of research in human services \u2013 for instance, in education, health and social \ncare \u2013 confirm that variations in the quantities of a service (e.g. class size in schools, or \nhours of home care) have a smaller impact on outcomes than the personal circumstances \nof the individuals involved, including material, psychological, social and cultural \ninfluences (Davies and Verry, 1976, Davies and Challis, 1986, Wolff, 2000, Benzeval \nand Judge, 2001, Blane, 1995, Goldstein et al., 2007, Knapp, 1978a, Knapp, 1978b, \nDavies et al., 2000b, Fernandez et al., 2007, Fernandez and Forder, 2006).  Measuring \nservice quality requires being able to apportion the relative contributions to outcomes of \nservices and non-service factors. To this we refer as the 'attribution problem'. \n \nTo address the attribution problem we draw on an analytical framework known as the \n\u2018Production of Welfare\u2019 (POW) approach, which has been applied in English academic \nstudies to the analysis of equity and efficiency in social care services and provides a \nframework with which to isolate the contribution of the service to the outcome state of \nindividuals (Davies and Knapp, 1981, Davies, 1985, Knapp, 1984).  Figure 1, adapted \nfrom Knapp (1984, p. 26), summarises the set of factors relevant to the production of \nwelfare in social care, together with the main relationships between them, as postulated \nby the POW approach.  Inputs comprise all the resource (such as staffing), and non-\nresource factors (such as characteristics of users, type of building) which go to make up a \nservice.  Outputs comprise the actual service (such as the number of hours of care).  Final \noutcomes are the longer-term impacts upon the wellbeing of service users (and of their \n 11 \ncare network).  It follows from this framework that in order to develop a good \nunderstanding of the contribution of services to users\u2019 outcomes, one needs to gather \ncomprehensive information about a wide range of variables.     \n \nFigure 1 The production of welfare framework \n \nStudies that use the POW approach have used regression models to specify the nature of \nthe relationships outlined in Figure 1 and to estimate outcomes after \u2018controlling\u2019 for the \neffect of factors that are not related to the service, such as service user and carer \ncharacteristics (Davies et al., 2000a).  An accurate estimation of the contribution of social \ncare services to final outcomes relies on the capacity of the model used to capture all of \nthe non-service-related factors that have an influence over outcomes.  The measurement \nproblem can have important implications for the statistical techniques used in the \nNon resource inputs\nUser and carer characteristics\n-Living circumstances\n-Dependency\n-Mental and physical Health problems\n-Informal care support\nSupply side factors\n-Attitudes of staff\nResource inputs\n-Buildings\n-Human resources\n-Transport\nCosts\nUnits of Service \n(intermediate outputs)\n-Home care hours\n-Day care sessions\n-Meals on wheels\nFinal outcomes\n-Reduction in caregiver stress\n-SCRQOL\n 12 \nestimation of the contribution of services to outcomes. The difficulties involved in \ncontrolling for all the relevant non-service related factors influencing outcomes can lead \nto unobserved heterogeneity and to biases in the estimates of quality.  The fact that higher \nlevels of services are provided to individuals with greater needs (and thus with the worst \nraw outcomes), for instance, means that failing to control fully for differences in need in \nthe analysis will lead to a positive bias in the estimates of the social care  quality (c.f. \nDavies et al., 2000a).   \n \n3 THE ENGLISH QUALITY ASSESSMENT SYSTEM: CURRENT \nDEVELOPMENTS AND KEY CHALLENGES  \nThe discussion above has outlined a theoretical framework to aid the measurement of \nsocial care quality and described some of the difficulties that are involved in this process \ndue to the special and complex nature of social care.  In this section we examine the \nEnglish approach to quality measurement in more detail.  We consider the extent to \nwhich the measures used address the challenges to measurement raised and also their \nsuitability for performance management, quality assurance activities and commissioning, \nparticularly in light of current policies to create more personalised services.   \n3.1 Recent developments in England in quality measurement \nIn the last ten to 15 years there have been great advances in England in terms of quality \nmeasurement (Boyne, 2002).  Prior to 1997, few attempts were made to measure directly \nquality in social care; measurement tended to focus on activity, expenditure and costs \n(Challis et al., 2006).  Under the Labour government a new data collection, the \nPerformance Assessment Framework (PAF), was introduced and a concerted effort was \nmade to increase the number of QIs.  Around the same time a mandatory annual user \nexperience survey (UES) was introduced to collect information on state funded social \ncare users' experiences of and satisfaction with their care.   \n \n 13 \nThe QIs introduced under PAF have focussed on care structures and processes.  Hence, \nthe indicators introduced related to issues such as the time taken to set-up the care \npackage, and to aspects relating to the infrastructure and adherence to procedures (e.g. \npercentage of people going into nursing and residential care who are allocated single \nrooms; adult and older clients receiving a review as a percentage).  The QIs based on \nquestions from the User Experience Survey questions have tended to focus on aspects \nassociated with the quality of care, such as whether care workers come at suitable times \nor overall satisfaction with services, rather than with quality of life per se.   \nOver time, the focus of the assessment of quality in public social care has become more \noutcomes-focused, with ministers stating that the objective of services is to provide \n\u201cbetter outcomes for all\u201d (Office of the Deputy Prime Minister, 2005, Communities and \nLocal Government, 2007).  As a result, the PAF framework was criticised for focusing on \nwhat was easily measurable, and for providing a very limited picture of quality and of \nwhether people\u2019s lives were actually improved as a result of service intervention \n(Department for Health, 2009).  In the last few years, policy-makers have therefore \ndeveloped a revised, outcomes-focussed, QI data collection system for social care.  Much \neffort has been invested in the development of patient-reported outcome measures.  The \nUser Experience Survey has been redeveloped specifically for this purpose (Malley et al., \n2010, Department for Health, 2009).  This direction of travel towards outcomes focussed \nquality indicators looks set to continue under the new Conservative-Liberal Democrat \nCoalition government.   \nHowever, the increased emphasis on the use of user surveys for assessing service quality \nadvocated in England poses considerable practical challenges, not least of which is the \nexpense and burden on the bodies in charge of carrying out and analysing the survey.  \nThere are also difficulties associated with conducting surveys with social care clients, \nmany of whom require help to answer questionnaires due to their impairments. This may \nlead to high rates of non response among certain sub-sections of the population, which \ncould lead to bias in the results obtained.  So far, analyses in England have tended to be \nrelatively simple, and to involve the reporting of raw percentages with little detailed \nanalysis of the effect of non response (see e.g. Information Centre, 2007).  Detailed \n 14 \nanalysis requires good data on the population characteristics of service users in each \ncommissioning area.  Improving the availability of such data will be a major challenge \nfor improving future survey-based QIs. \n \n3.2 Uses of quality measures for assessing service commissioners \nIn England the QIs described above have mainly been used for monitoring the \nperformance of commissioning organisations and assuring the quality of the services \npurchased by these organisations (Department of Health, 1998).  Since the focus has been \non the commissioning organisations, QIs have generally been reported at the level of the \norganisation, by aggregating the individual-level quality measures.  The QIs therefore \nmeasure the average quality of social care purchased by an authority, which, to the extent \nthat commissioners have control over the quality of social care, reflects the performance \nof the organisation.  The QI is also a good indicator of the quality of care that people \nliving in that area could expect to receive if they were ever to need social care1.  \nImportantly, the QI is not a complete measure of the quality of the commissioning \norganisation, since other factors such as accessibility and equity are likely to be important \nto such an assessment. \n \nThe use of QIs for assessing the commissioning organisation is subject to the attribution \nproblem highlighted above. Typically, service use is found to be negatively related to raw \noutcomes states, because people with higher levels of need tend to require more services \nbut to show worse outcomes overall (in spite of higher service contributions to their \noutcomes) (Davies et al., 2000a).  Not controlling for differences in local case-mix is \ntherefore likely to bias the assessment of local performance. \n                                                 \n1 Although this does depend on the variance associated with each point estimate.  If the \nmeasure has a large variance then the average quality may not be a terribly good \nindicator of the quality of social care people in the area can expect. \n 15 \n \nOverall, deciding which factors should be controlled for during the assessment process is \nnot always straightforward. In addition to need related factors, aspects such as local \nservice supply can constrain the ability of local commissioners to achieve improvements \nin outcomes for their local population, other things equal. Overall, the analysis should \nattempt to control for those factors which lie outside the control of services, in this case \nthe commissioning organisation (c.f. Heinrich and Lynn, 2000).   \nDeciding which factors are beyond the control of service commissioners is often not easy \n(Wilson and Piebalga, 2008).  Deprivation, for instance, has been argued to undermine \nthe capacity of local authorities to achieve good outcomes.  As a result, the English \nresource allocation system in charge of transferring tax-payers money to local \ngovernment makes an adjustment for deprivation so that more deprived areas receive \nadditional resources.  \n \nFurther work is being carried out to identify the range of non-service-related factors \naffecting social care outcomes (Malley and Netten, 2009, Malley and Netten, 2008). \nCollecting the data required to adequately and accurately \u2018control\u2019 for factors beyond the \ncontrol of commissioning organisation, however, is a resource intensive task. It seems \nunlikely in the current fiscal climate that organisations will be mandated to collect more \ninformation.  Furthermore, the need for sophisticated analytical techniques to determine \nthe contribution of social care services to local outcomes puts a further burden on the \nprocess of performance assessment, and can delay the production of national adjusted \nscores. \n 16 \n3.3 Measuring the quality of provider organisations \nIn England, the QIs are not reported at the level of providers, so these measures are not \nroutinely used to inform commissioning decisions2.  A different measurement system has \nbeen developed to assess the quality of providers by the social care regulator.  As part of \nits role as regulator, the Commission for Social Care Inspection developed a \u2018star rating\u2019 \nsystem for commissioners, which it later extended to providers, as a \u2018quality rating\u2019 \nsystem.  These ratings are composite measures \u2018calculated\u2019 by combining data from a \nvariety of sources, including inspection fieldwork data, data from ongoing performance \nmanagement meetings, data from the PAF and any other sources including complaints.  \nIn line with the policy focus on outcomes described above, much of the data gathered by \nthe regulator is used to assess user outcomes.  The regulator also gathers data about the \nmanagement of the service and includes aspects which focus on staff, such as investment \nin staff training.  The information from all of these areas is organised following guidance \nand combined together using rules to form a single composite measure of provider \nquality on a zero (poor) to three (excellent) scale (Commission for Social Care \nInspection, 2007). \n \nThe quality rating is designed to be easy to understand.  Star ratings were initially \nintroduced as a response to the perception that the QIs in the PAF were complex to \ninterpret, so limiting their usefulness as tools for public accountability.  Star ratings were \ndesigned to be more user-friendly versions of the QIs (Social Services Inspectorate, 2002, \nCutler and Waine, 2003).  The move towards developing provider-level ratings arose \nfrom a desire to help commissioners make good purchasing choices, in part driven by \nfindings that some local authorities were purchasing services from unregistered \nproviders.  In recent times, provider quality ratings have been promoted as tools to \n                                                 \n2 There are, however, some examples of commissioners investing resources to collect \nand report, in particular, the UES data at the level of provider organisations to inform \ntheir commissioning decisions. \n 17 \nimprove market efficiency and correct information asymmetries, by providing \ncommissioning organisations and prospective users of services with straightforward \ninformation about the quality of care providers (HM Government, 2010).  The regulator \nhas developed various tools to help commissioners and prospective users make use of the \nquality ratings and other inspection information, including a care provider directory on its \nwebsite which is searchable by quality rating. \n \nWhether the quality ratings system is perceived as valuable in helping potential service \nusers to choose the best provider for them, and help commissioners to make good \npurchasing decisions, depends on the accuracy and reliability of the ratings.  There has \nbeen quite a lot of criticism of composite measures; a variety of evidence has been \npresented to demonstrate that such measures are sensitive to the interpretation of \nguidance (Cutler and Waine, 2003, Jacobs and Goddard, 2007).  The lack of sufficient \nresources to continuously monitor all services providers also has consequences for the \nreliability of ratings.  To minimise the administrative burden associated with inspections \nand reduce the cost, the ratings are not updated annually for the best performing \norganisations; rather resources are focused on those with the poorest ratings.  This system \nrelies on stability.  However, work in other areas of the public sector has demonstrated \nthat service quality has the potential to change rapidly (Bevan and Cornwell, 2006).  In \nEngland, provider organisations in the social care sector are in a constant state of flux, \nwith frequent mergers and changes in management that are likely to have an impact on \nquality.  Very recent work looking specifically at the care home providers seems to \nsupport these concerns, with researchers able to demonstrate that provider quality ratings \nwere relatively insensitive to variations in quality as measured using an observational \noutcome tool (Netten et al., 2010).  The future of the quality ratings system is uncertain.  \nIt is currently being revised and it remains to be seen whether its successor will be able to \naddress any of the criticisms made of the current ratings.    \n 18 \n3.4 Personalised services and consumer-directed support \nThe current developments in quality measurement come at a time of profound change in \nthe delivery of social care services, with the introduction of new forms of consumer-\ndirected support and the transformation of adult social care around the personalisation \nagenda (Ministers et al., 2007, Department of Health, 2008, Department of Health, 2006).  \nDespite a relatively low take-up currently, consumer-directed care continues to receive \nsupport from policy-makers and is expected to become the main mechanism for \ncommissioning services in the coming years.   \n \nIn a world of consumer-directed care, QIs are also needed to inform service users in their \nrole as purchasers, by providing evidence about the quality of the different services \navailable.  And yet, presenting the information in a format that makes sense to \nprospective users and is at the same time accurate and sensitive to variations in quality is \nnot straightforward.  Providing information for many QIs is arguably more accurate, but \nmore complicated to absorb. In contrast, composite measures of quality are easy to \nunderstand, but have limited sensitivity to variations in quality.  Survey-based indicators \nhave not been explored as measures of provider quality, but could be useful measures for \nthis purpose.  In as far as they are based on the views of other service users, they resonate \nwith and be more easily understood by prospective service users.  \n \nA policy emphasis on consumer-directed care creates further difficulties for quality \nmeasurement.  The notion of provider quality developed for the regulator\u2019s quality rating \nsystem seems inappropriate for this type of care.  Consumer-directed care forms blur our \nunderstanding of the concept of the service, since many of the functions of the service, in \nparticular those related to the organisation of care and responsibilities for employee \nwelfare, are taken on by the service user.  Consequently, where people have consumer-\ndirected support any attempts by the regulator to judge the care these people receive by, \n 19 \nfor example, examining the way they treat their staff or organise their care are likely to be \ntreated with suspicion.     \n \n4 CONCLUSION \nThere are many challenges associated with measuring the quality of social care.  \nHowever, significant advances have been made in recent years, particularly in the \ndevelopment of instruments and frameworks, such as POW to aid measurement.  In \nEngland, political will has resulted in significant investment in quality measurement with \ntangible results.  There are now a variety of social care quality measures, both at the level \nof provider and commissioning organisations.  There are still important measurement \nissues that need to be addressed to improve the current set of quality measures, \nparticularly around the attribution of variations in outcomes to service and non service \nrelated factors.  It is likely that over the next few years, tighter public spending budgets \nwill encourage the further development of quality measures both in England and in other \ncountries, as governments are challenged to prove to tax-payers that they can do more \nwith fewer resources.  \n \n5 REFERENCES \n \nARAH, O. A., WESTERT, G. P., HURST, J. & KLAZINGA, N. S. (2006) A conceptual \nframework for the OECD Health Care Quality Indicators Project. Int J Qual \nHealth Care, 18, 5-13. \nBALDOCK, J. (1997) Social Care in Old Age: More Than a Funding Problem. Social \nPolicy & Administration, 31, 73-89. \nBAMFORD, C. H., QURESHI, H., NICHOLAS, E. & VERNON, A. (1999) Outcomes \nof Social Care for Disabled People and Carers. IN SOCIAL POLICY \n 20 \nRESEARCH UNIT (Ed.) Outcomes in Community Care Practice. York, Social \nPolicy Research Unit. \nBENZEVAL, M. & JUDGE, K. (2001) Income and health: the time dimension. Social \nScience and Medicine, 52, 1371-90. \nBEVAN, G. & CORNWELL, J. (2006) Structure and logic of regulation and governance \nof quality of health care: was OFSTED a model for the Commission for Health \nImprovement? Health Economics, Policy and Law, 1, 343-370. \nBLANE, D. (1995) Social determinants of health - socioeconomic status, social class, and \nethnicity. American Journal of Public Health, 85, 903-5. \nBOBINAC, A., VAN EXEL, N. J. A., RUTTEN, F. F. H. & BROUWER, W. B. F. \n(2010) Caring for and caring about: Disentangling the caregiver effect and the \nfamily effect. Journal of Health Economics, 29, 549-556. \nBOYNE, G. A. (2002) Concepts and Indicators of Local Authority Performance: An \nEvaluation of the Statutory Frameworks in England and Wales. Public Money and \nManagement, 22, 17-24. \nCHALLIS, D. (1981) The measurement of outcome in social care of the elderly. Journal \nof social policy, 10, 179-208. \nCHALLIS, D., CLARKSON, P. & WARBURTON, R. (2006) Performance Indicators in \nSocial Care for Older People, Aldershot, Ashgate. \nCOMMISSION FOR SOCIAL CARE INSPECTION (2007) Performance Assessment \nHandbook 2006-07. Adult Social Care Services. London, Commission for Social \nCare Inspection. \nCOMMUNITIES AND LOCAL GOVERNMENT (2007) The new performance \nframework for local authorities and local authority partnerships: single set of \nnational indicators. IN COMMUNITIES AND LOCAL GOVERNMENT (Ed.). \nTSO. \nCUTLER, T. & WAINE, B. (2003) Advancing Public Accountability? The Social \nServices 'Star' Ratings. Public Money & Management, 23, 125-128. \nDAVIES, B. (1985) Production of Welfare Approach. Discussion Paper 400. Canterbury, \nPersonal Social Services Research Unit. \n 21 \nDAVIES, B. & CHALLIS, D. (1986) Matching Resources to Needs in Community Care, \nAldershot, Gower. \nDAVIES, B., FERN\u00c1NDEZ, J.-L. & NOMER, B. (2000a) Equity and Efficiency Policy \nin Community Care., Aldershot, Ashgate. \nDAVIES, B., FERN\u00c1NDEZ, J. L. & NOMER, B. (2000b) Equity and Efficiency Policy \nin Community Care, Aldershot, Ashgate. \nDAVIES, B. & KNAPP, M. (1981) Old People's Homes and the Production of Welfare, \nLondon, Routledge and Keegan Paul. \nDAVIES, B. & VERRY, D. (1976) University Costs and Outputs, Amsterdam, Elsevier. \nDEPARTMENT FOR HEALTH (2009) Making policy count:Developing performance \nindicators for health and social care partnerships. Position Paper Social Care. IN \nDEPARTMENT FOR HEALTH (Ed.). London. \nDEPARTMENT OF HEALTH (1998) Modernising Social Services: promoting \nindependence, improving protection, raising standards. CM 4169 ed., TSO. \nDEPARTMENT OF HEALTH (2006) Our health, our care, our say: a new direction for \ncommunity services, Cm6737. IN DEPARTMENT FOR HEALTH (Ed.). \nLondon, TSO. \nDEPARTMENT OF HEALTH (2008) TRANSFORMING SOCIAL CARE, Local \nAuthority Circular LAC (DH) (2008) 1. IN HEALTH, D. O. (Ed.). \nDONABEDIAN, A. (1980) Explorations on Quality Assessment and Monitoring. The \nDefinition of Quality and Approaches to its Assessment, Michigan, Ann Arbor. \nDONABEDIAN, A. (1988) The quality of care. How can it be assessed? JAMA, 260, \n1743-1748. \nEDEBALK, P., SAMUELSSON, G. & INGVAD, B. (1995) How elderly people rank \norder the quality characteristics of home services. Ageing and Society, 15, 83\u2013\n102. \nFERNANDEZ, J.-L. & FORDER, J. (2006) Regional variability in public long-term care \nexpenditure in England: the significance of local autonomy, exogenous influences \nand local spillovers. PSSRU Discussion Papers. \n 22 \nFERNANDEZ, J.-L., KENDALL, J., DAVEY, V. & KNAPP, M. (2007) Direct \npayments in England: factors linked to variations in local provision. Journal of \nSocial Policy, 36, 97\u2013121. \nFORDER, J., KNAPP, M. R. & WISTOW, G. (1996) Competition in the mixed economy \nof care. Journal of Social Policy, 25, 201-21. \nFRANCIS, J. & NETTEN, A. (2004 ) Raising the quality of home care: a study of service \nusers' views. Social policy and administration, 38, 290-305. \nGLASBY, J. & LITTLECHILD, R. (2002) Social Work and Direct Payments, Bristol, \nPolicy Press. \nGOLDBERG, E. M. (1970) Helping the Aged, London, George Allen and Unwin. \nGOLDSTEIN, H., SIMON, B. & MCCONNELL, B. (2007) Modelling the effect of pupil \nmobility on school differences in educational achievement. Journal of the Royal \nStatistical Society: Series A (Statistics in Society), 170, 941-954. \nHARDING, T. & BERESFORD, P. (1996) The Standards we Expect: what services users \nand carers want from social services workers, London, The National Instiute for \nSocial Work. \nHEINRICH, C. J. (2002) Outcomes-Based Performance Management in the Public \nSector: Implications for Government Accountability and Effectiveness. Public \nAdministration Review, 62, 712-725. \nHEINRICH, C. J. (2003) Measuring public sector performance. IN PETERS, B. G. & \nPIERRE, J. (Eds.) Handbook of public administration. London, Sage. \nHEINRICH, C. J. & LYNN, L. (Eds.) (2000) Governance and performance: New \nperspectives, Washington D.C., Georgetown University Press. \nHENWOOD, M., LEWIS, H. & WADDINGTON, E. (1998) Listening to Users of \nDomiciliary Care Services Leeds, University of Leeds, Nuffield Institute for \nHealth, Community Care Division. \nHM GOVERNMENT (2010) Building the National Care Service, CM7854, London, The \nStationery Office. \nIKEGAMI, N. & CAMPBELL, J. C. (2003) Choices, Policy Logics and Problems in the \nDesign of Long\u2013term Care Systems. Social Policy and Administration, 36, 719 - \n734. \n 23 \nINFORMATION CENTRE (2007) Personal Social Services Survey of Home Care Users \nin England aged 65 and over, 2005-06. Information Centre. \nJACOBS, R. & GODDARD, M. (2007) How Do Performance Indicators Add Up? An \nExamination of Composite Indicators in Public Services. Public Money and \nManagement, 27, 103-110. \nKELLY, J. M. (2005) The Dilemma of the unsatisfied customer in a market model of \npublic administration. Public Administration Review, 65, 76-84. \nKNAPP, M. (1978a) Cost functions for care services for the elderly. Gerontologist, 18, \n30-36. \nKNAPP, M. (1978b) Economies of scale in residential care. International Journal of \nSocial Economics, 5, 81-92. \nKNAPP, M. (1984) The economics of social care, Basingstoke, Macmillan. \nMALLEY, J., CAIELS, J., FOX, D., MCCARTHY, M., SMITH, N., BEADLE-\nBROWN, J., NETTEN, A. & TOWERS, A.-M. (2010) A Report on the \nDevelopment Studies for the National Adult Social Care User Experience Survey, \nDiscussion Paper 2721. Canterbury, Personal Social Services Research Unit. \nMALLEY, J. & NETTEN, A. (2008) Measuring User Experience of Social Care \nServices: A Discussion of Three Approaches. A Report to the Department of \nHealth. Discusssion Paper 2529. Canterbury, Personal Social Services Research \nUnit. \nMALLEY, J. & NETTEN, A. (2009) Putting People First: Development of the Putting \nPeople First User Experience Survey.  Discussion Paper 2637. Canterbury, \nPersonal Social Services Research Unit. \nMALLEY, J., SANDHU, S. & NETTEN, A. (2006) Younger Adults\u2019 Understanding of \nQuestions for a Service User Experience Survey: A Report to the Information \nCentre for Health and Social Care. PSSRU Discussion Paper 2360. Canterbury, \nPersonal Social Services Research Unit. \nMILLER, E., COOPER, S.-A., COOK, A. & PETCH, A. (2008) Outcomes Important to \nPeople With Intellectual Disabilities. Journal of Policy and Practice in \nIntellectual Disabilities, 5, 150-158. \n 24 \nMINISTERS, LOCAL GOVERNMENT, NHS, SOCIAL CARE & PROFESSIONAL \nAND REGULATORY ORGANISATIONS (2007) Putting people first: a shared \nvision and commitment to the transformation of adult social care. London, The \nStationery Office. \nMOR, V., BERG, K., ANGELELLI, J., GIFFORD, D., MORRIS, J. & MOORE, T. \n(2003) The Quality of Quality Measurement in U.S. Nursing Homes. The \nGerontologist, 43, 37-46. \nNATIONAL INSTITUTE FOR SOCIAL WORK (1988) A positive choice. Report of the \nindependent review of residential care. Chaired by Gillian Wagner. London, \nHMSO. \nNETTEN, A., BEADLE-BROWN, J., TRUKESCHITZ, B., TOWERS, A.-M., WELCH, \nE., FORDER, J., SMITH, J. & ALDEN, E. (2010) Measuring the outcomes of \ncare homes: Final report.  Discussion Paper 2696\/2. Canterbury, Kent, Personal \nSocial Services Research Unit. \nNETTEN, A., BURGE, P., MALLEY, J., POTOGLOU, D., BRAZIER, J., FLYNN, T. & \nFORDER, J. (2009) Outcomes of Social Care for Adults (OSCA). Interim \nfindings.  Discussion Paper 2648. Canterbury, Personal Social Services Research \nUnit. \nNETTEN, A., JONES, K. & SANDHU, S. (2007) Provider and care workforce \ninfluences in quality of home care services in England. Journal of Aging and \nSocial Policy, 19, 81-97. \nOFFICE OF THE DEPUTY PRIME MINISTER (2005) Securing better outcomes: \ndeveloping a new performance framework. IN MINISTER, O. O. T. D. P. (Ed.). \nThe Stationery Office. \nOSBORNE, S. P. (1992) The Quality Dimension. Evaluating Quality of Service and \nQuality of Life in Human Services. Br J Soc Work, 22, 437-453. \nPARASURAMAN, A., ZEITHMAL, V. & BERRY, L. (1985) A conceptual model of \nservice quality and its implications for future research. Journal of Marketing, 49, \n41-50. \n 25 \nPICKARD, L., WITTENBERG, R., COMAS-HERRERA, A., KING, D. & MALLEY, J. \n(2007) Care by Spouses, Care by Children: Projections of Informal Care for Older \nPeople in England to 2031. Social Policy and Society, 6, 353-366. \nQURESHI, H. & HENWOOD, M. (2000) Older people's definitions of quality services. \nYork, Joseph Rowntree Foundation  \nQURESHI, H. & NICHOLAS, E. (2001) A new conception of social care outcomes and \nits practical use in assessment with older people. Research, Policy and Planning, \n19, 11-26. \nQURESHI, H., PATMORE, C., NICHOLAS, E. & BAMFORD, C. H. (1998) Overview: \nOutcomes of Social Care for Older People. Outcomes in Community Care \nPractice Series. York, Social Policy Research Unit. \nRAYNES, N., TEMPLE, B., GLENISTER, C. & COULTHARD, L. (2001) Quality at \nhome for older people.  Involving Service users in defining home care \nspecifications, York, The Policy press and Joseph rowntree Foundation. \nREED, J. (2007) Quality of life. In National Care Homes Research Forum. My Home \nLife Report. N. \nREERINK, E. (1990) Defining quality of care: mission impossible? Quality Assurance in \nHealth Care, 2, 197-202. \nSANGL, J., SALIBA, D., GIFFORD, D. R. & HITTLE, D. F. (2005) Challenges in \nMeasuring Nursing Home and Home Health Quality: Lessons From the First \nNational Healthcare Quality Report. Medical Care, 43, I-24-I-32. \nSCHALOCK, R. L. (2004) The concept of quality of life: what we know and do not \nknow. Journal of Intellectual Disability Research, 48, 203-216. \nSINCLAIR, I., GIBBS, I. & HICKS, L. (2000) The management and effectiveness of the \nhome care service. York, Social Work Research and Development Unit,. \nSMITH, P. C. (1996) A framework for analysing the measurement of outcome. IN \nSMITH, P. C. (Ed.) Measuring outcome in the Public Sector. London, Taylor and \nFrancis. \nSOCIAL SERVICES INSPECTORATE (2002) Performance Ratings for Social Services \nin England, November 2002. London, Department of Health,. \n 26 \nSTEEL, N., MELZER, D., SHEKELLE, P. G., WENGER, N. S., FORSYTH, D. & \nMCWILLIAMS, B. C. (2004) Developing quality indicators for older adults: \ntransfer from the USA to the UK is feasible. Quality and Safety in Health Care, \n13:, 260-264. \nWILSON, D. & PIEBALGA, A. (2008) Accurate performance measure but meaningless \nranking exercise? An analysis of the English school league tables. CMPO \nWorking Paper No. 07\/176. Bristol, CMPO  \nWOLFF, N. (2000) Using randomized controlled trials to evaluate socially complex \nservices: problems, challenges and recommendations. The Journal of Mental \nHealth Policy and Economics, 3, 97-109. \n \n \n"}
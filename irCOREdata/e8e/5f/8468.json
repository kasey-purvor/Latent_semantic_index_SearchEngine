{"doi":"10.1017\/S1351324904003511","coreId":"8468","oai":"oai:eprints.brighton.ac.uk:3100","identifiers":["oai:eprints.brighton.ac.uk:3100","10.1017\/S1351324904003511"],"title":"Implementation architectures for natural language generation","authors":["Mellish, C.","Evans, Roger"],"enrichments":{"references":[{"id":42748771,"title":"A fast and portable realiser for text generation.","authors":[],"date":"1997","doi":"10.3115\/974557.974596","raw":"22 Mellish and Evans Lavoie, B. and O. Rambow. (1997) A fast and portable realiser for text generation. Procs of the Fifth Conference on Applied Natural Language Processing (ANLP-97), Washington, pages 265-268.","cites":null},{"id":42748769,"title":"A Practical Introduction to ATLAS.","authors":[],"date":"2002","doi":"10.3115\/1289189.1289209","raw":"Laprun, C., J. Fiscus, J. Garafolo and S. Pajot. (2002) A Practical Introduction to ATLAS. Procs of the Third International Conference on Language Resources and Evaluation (LREC-02), Las Palmas.","cites":null},{"id":42748777,"title":"A Reference Architecture for Generation Systems. Natural Language Engineering, this issue.","authors":[],"date":"2004","doi":"10.1017\/s1351324904003456","raw":"Mellish, C., D. Scott, L. Cahill, R. Evans, D. Paiva and M. Reape. (2004) A Reference Architecture for Generation Systems. Natural Language Engineering, this issue.","cites":null},{"id":42748776,"title":"A representation for complex and evolving data dependencies in generation.","authors":[],"date":"2000","doi":"10.3115\/974147.974164","raw":"Mellish, C., R. Evans, L. Cahill, C. Doran, D. Paiva, M. Reape, D. Scott, and N. Tipper. (2000) A representation for complex and evolving data dependencies in generation. Procs of the Language Technology Joint Conference, ANLP-NAACL2000, Seattle.","cites":null},{"id":42748735,"title":"An efficient chart generator for (semi-)lexicalist grammars.","authors":[],"date":"1999","doi":null,"raw":"Carroll, J., A. Copestake, D. Flickinger and V. Poznanski. (1999) An efficient chart generator for (semi-)lexicalist grammars. Procs of the 7th European Workshop on Natural Language Generation (EWNLG\u201999), pages 86\u201395, Toulouse.","cites":null},{"id":42748766,"title":"An Empirical Verification of Coverage and Correctness for a General-Purpose Sentence Generator.","authors":[],"date":"2002","doi":null,"raw":"Langkilde-Geary, I. (2002) An Empirical Verification of Coverage and Correctness for a General-Purpose Sentence Generator. Procs of the Second International Conference on Natural Language Generation (INLG-02), New York, pages 17\u201324.","cites":null},{"id":42748739,"title":"Architectures for Natural Language Generation: Problems and Perspectives.","authors":[],"date":"1996","doi":"10.1007\/3-540-60800-1_22","raw":"De Smedt, K., H. Horacek, and M. Zock. (1996) Architectures for Natural Language Generation: Problems and Perspectives. In G. Adorni and M. Zock, (Eds) Trends in Natural Language Generation, Springer Verlag, pages 17\u201346.","cites":null},{"id":42748728,"title":"Cascading XSL Filters for Content Selection","authors":[],"date":"2002","doi":"10.3115\/1118808.1118810","raw":"Barrutieta, G., J. Abaitua and J. Diaz. (2002) Cascading XSL Filters for Content Selection in Multilingual Document Generation. Procs of the Second Workshop on NLP and XML, Taipei.","cites":null},{"id":42748732,"title":"Component tasks in applied NLG systems.","authors":[],"date":"1999","doi":null,"raw":"Natural Language Generation 21 Cahill, L. and M. Reape. (1999) Component tasks in applied NLG systems. Technical Report ITRI-99-05, ITRI, University of Brighton. obtainable at http:\/\/www.itri.brighton.ac.uk\/rags\/.","cites":null},{"id":42748737,"title":"Conceptual and Linguistic Decisions","authors":[],"date":"1984","doi":"10.3115\/980431.980598","raw":"Danlos, L. (1984) Conceptual and Linguistic Decisions in Generation. Procs of the 10th International Conference on Computational Linguistics (COLING\u201984), Stanford.","cites":null},{"id":42748778,"title":"Controlling a Language Generation Planner.","authors":[],"date":"1989","doi":null,"raw":"Nirenburg, S., V. Lesser and E. Nyberg. (1989) Controlling a Language Generation Planner. Procs of the 11th International Joint Conference on Artificial Intelligence (IJCAI-89), Detroit, pages 1524\u20131530.","cites":null},{"id":42748740,"title":"Controlling content realization with functional unification grammars. In","authors":[],"date":"1992","doi":"10.1007\/3-540-55399-1_7","raw":"Elhadad, M. and J. Robin. (1992) Controlling content realization with functional unification grammars. In R. Dale, E. Hovy, D. Roesner and O. Stock (Eds) Aspects of Automated Natural Language Generation, Lecture Notes in Artificial Intelligence, 587. Springer-Verlag, pages 89\u2013104.","cites":null},{"id":42748730,"title":"De-Constraining Text Generation.","authors":[],"date":"1998","doi":null,"raw":"Beale, S., S. Nirenburg, E. Viegas and L. Wanner. (1998) De-Constraining Text Generation. Procs of the Ninth International Workshop on Natural Language Generation, Niagara-on-the-Lake.","cites":null},{"id":42748781,"title":"DSML: A Proposal for XML Standards for Messaging Between Components of a Natural Language Dialogue System.","authors":[],"date":"1999","doi":null,"raw":"Radev, D., N. Kambhatla, Y. Ye, C. Wolf and Z. Wlodek. (1999) DSML: A Proposal for XML Standards for Messaging Between Components of a Natural Language Dialogue System. Procs of the AISB\u201999 Workshop on Reference Architectures and Data Standards for NLP, Edinburgh.","cites":null},{"id":42748793,"title":"Empirically designing and evaluating a new revisionbased model for summary generation.","authors":[],"date":"1996","doi":"10.1016\/0004-3702(96)81365-8","raw":"Robin, J. and K. McKeown. (1996) Empirically designing and evaluating a new revisionbased model for summary generation. Artificial Intelligence, 85(1-2).","cites":null},{"id":42748729,"title":"Enabling Technology for Multilingual Natural Language Generation: The KPML Development Environment.","authors":[],"date":"1997","doi":"10.1017\/s1351324997001514","raw":"Bateman, J. (1997) Enabling Technology for Multilingual Natural Language Generation: The KPML Development Environment. Natural Language Engineering, 3(1):15\u201355.","cites":null},{"id":42748775,"title":"Experiments using Stochastic Search for Text Planning.","authors":[],"date":"1998","doi":null,"raw":"Mellish, C., A. Knott, J. Oberlander and M. O\u2019Donnell. (1998) Experiments using Stochastic Search for Text Planning. Procs of the Ninth International Workshop on Natural Language Generation (INLG-98), Niagara-on-the-Lake, pages 98\u2013107.","cites":null},{"id":42748733,"title":"From RAGS to RICHES: exploiting the potential of a flexible generation architecture.","authors":[],"date":"2001","doi":"10.3115\/1073012.1073027","raw":"Cahill, L., J. Carroll, R. Evans, D. Paiva, R. Power, D. Scott, and K. van Deemter. (2001) From RAGS to RICHES: exploiting the potential of a flexible generation architecture. Procs of the 39th Annual Meeting of the Association for Computational Linguistics (ACL-01), pages 98\u2013105, Toulouse, France.","cites":null},{"id":42748736,"title":"GATE - a general architecture for text engineering.","authors":[],"date":"1996","doi":"10.3115\/993268.993365","raw":"Cunningham, H., Y. Wilks, and R. Gaizauskas. (1996) GATE - a general architecture for text engineering. Procs of the 16th International Conference on Computational Linguistics (COLING\u201996), volume 2, pages 1057\u20131060, Copenhagen.","cites":null},{"id":42748763,"title":"Generation that Exploits Corpus-based Statistical Knowledge.","authors":[],"date":"1998","doi":"10.3115\/980451.980963","raw":"Langkilde, I. and K. Knight. (1998) Generation that Exploits Corpus-based Statistical Knowledge. Procs of the Conference of the Association for Computational Linguistics (COLING\/ACL-98).","cites":null},{"id":42748790,"title":"Has a consensus NL generation architecture appeared and is it psycholinguistically plausible?","authors":[],"date":"1994","doi":"10.3115\/1641417.1641436","raw":"Reiter, E. (1994) Has a consensus NL generation architecture appeared and is it psycholinguistically plausible? Procs of the 8th International Workshop on Natural Language Generation (INLG-94), Kennebunkport, pages 163\u2013170.","cites":null},{"id":42748779,"title":"ILEX: The architecture of a dynamic hypertext generation system.","authors":[],"date":"2001","doi":"10.1017\/s1351324901002698","raw":"O\u2019Donnell, M., A. Knott, C. Mellish, and J. Oberlander. (2001) ILEX: The architecture of a dynamic hypertext generation system. Natural Language Engineering, 7:225\u2013250.","cites":null},{"id":42748794,"title":"Integrating Text Planning and Linguistic Choice by Annotating Linguistic Structures. In","authors":[],"date":"1992","doi":"10.1007\/3-540-55399-1_4","raw":"Rubinoff, R. (1992) Integrating Text Planning and Linguistic Choice by Annotating Linguistic Structures. In R. Dale, E. Hovy, D. Roesner and O. Stock (Eds) Aspects of Automated Natural Language Generation, Springer Verlag, pages 45\u201356.","cites":null},{"id":42748761,"title":"International Standard for a Linguistic Annotation Framework. Natural Language Engineering, this issue.","authors":[],"date":"2004","doi":"10.1017\/s135132490400350x","raw":"Ide, N. and L. Romary. (2004) International Standard for a Linguistic Annotation Framework. Natural Language Engineering, this issue.","cites":null},{"id":42748747,"title":"LargeScale Software Integration for Spoken Language and Multimodal Dialog Systems. Natural Language Engineering, this issue.","authors":[],"date":"2004","doi":"10.1017\/s1351324904003444","raw":"Herzog, G., A. Ndiaye, S. Merten, H. Kirchmann, T. Becker and P. Poller. (2004) LargeScale Software Integration for Spoken Language and Multimodal Dialog Systems. Natural Language Engineering, this issue.","cites":null},{"id":42748731,"title":"Lexicalisation in Applied NLG Systems.","authors":[],"date":"1999","doi":null,"raw":"Cahill, L. (1999) Lexicalisation in Applied NLG Systems. Technical Report ITRI-99-04, ITRI, University of Brighton. obtainable at http:\/\/www.itri.brighton.ac.uk\/rags\/.","cites":null},{"id":42748774,"title":"MUMBLE: A Flexible System for Language Production.","authors":[],"date":"1981","doi":null,"raw":"McDonald, D. (1981) MUMBLE: A Flexible System for Language Production. Procs of the Seventh International Joint Conference on Artificial Intelligence (IJCAI-81), Vancouver, page 1062.","cites":null},{"id":42748749,"title":"Natural Language Question Answering: the view from here.","authors":[],"date":"2001","doi":"10.1017\/s1351324901002807","raw":"Hirschman, L. and R. Gaizauskas. (2001) Natural Language Question Answering: the view from here. Natural Language Engineering, 7(4):275\u2013300.","cites":null},{"id":42748738,"title":"Parallelism in Incremental Sentence Generation.","authors":[],"date":"1994","doi":"10.1007\/978-94-009-3645-4_23","raw":"De Smedt, K. (1994) Parallelism in Incremental Sentence Generation. In G. Adriaens and U. Hahn (Eds) Parallel Natural Language Processing, Ablex, pages 421\u2013447.","cites":null},{"id":42748792,"title":"Pipelines and Size Constraints.","authors":[],"date":"2001","doi":"10.1162\/089120100561692","raw":"Reiter, E. (2001) Pipelines and Size Constraints. Computational Linguistics 26:251-259.","cites":null},{"id":42748797,"title":"Pipelines, Templates and Transformations: XML for Natural Language Generation.","authors":[],"date":"2001","doi":null,"raw":"Wilcock, G. (2001) Pipelines, Templates and Transformations: XML for Natural Language Generation. Procs of the first NLP and XML Workshop, Tokyo, pages 1\u20138.","cites":null},{"id":42748780,"title":"Planning texts by constraint satisfaction.","authors":[],"date":"2000","doi":"10.3115\/992730.992739","raw":"Power, R. (2000) Planning texts by constraint satisfaction. Procs of the 18th International Conference on Computational Linguistics (COLING-2000), Saabruecken, pages 642-648.","cites":null},{"id":42748796,"title":"Robust Translation of Spontaneous Speech: A Multi-Engine Approach.","authors":[],"date":"2001","doi":null,"raw":"Wahlster, W. (2001) Robust Translation of Spontaneous Speech: A Multi-Engine Approach. Procs of the Seventeenth International Joint Conference on Artificial Intelligence (IJCAI-2001), Seattle.","cites":null},{"id":42748752,"title":"The generic information extraction system.","authors":[],"date":"1993","doi":"10.3115\/1072017.1072029","raw":"Hobbs, J. (1993) The generic information extraction system. Procs of the fifth Message Understanding Conference (MUC-5), Morgan Kaufman.","cites":null},{"id":42748734,"title":"The RAGS Reference Manual .","authors":[],"date":"2001","doi":"10.1017\/s1351324904003456","raw":"Cahill, L., R. Evans, C. Mellish, D. Paiva, M. Reape, and D. Scott. (2001) The RAGS Reference Manual . Technical Report ITRI-01-08, ITRI, University of Brighton. Available at http:\/\/www.itri.brighton.ac.uk\/rags.","cites":null},{"id":42748745,"title":"TIPSTER Phase II Architecture Design Document Version 1.52.","authors":[],"date":"1995","doi":"10.3115\/1119018.1119066","raw":"Grishman, R. (1995) TIPSTER Phase II Architecture Design Document Version 1.52. Technical Report, Dept of Computer Science, New York University.","cites":null},{"id":42748741,"title":"What is NLG?","authors":[],"date":"2002","doi":null,"raw":"Evans R., P. Piwek and L. Cahill. (2002) What is NLG? In Procs of the Second International Conference on Natural Language Generation (INLG-02), New York, pages 144\u2013151.","cites":null},{"id":42748795,"title":"XML Transformation-based three-stage pipelined Natural Language Generation System. Procs of the Sixth Natural Language Processing Pacific Rim Symposium (NLPRS","authors":[],"date":"2001","doi":null,"raw":"Seki, Y. (2001) XML Transformation-based three-stage pipelined Natural Language Generation System. Procs of the Sixth Natural Language Processing Pacific Rim Symposium (NLPRS 2001), Tokyo, pages 767\u2013768. Text Encoding Initiative. See http:\/\/www.tei-c.org\/.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2004-09","abstract":"Generic software architectures aim to support re-use of components, focusing of research and development effort, and evaluation and comparison of approaches. In the field of natural language processing, generic frameworks for understanding have been successfully deployed to meet all of these aims, but nothing comparable yet exists for generation. The nature of the task itself, and the current methodologies available to research it, seem to make it more difficult to reach the necessary level of consensus to support generic proposals. Recent work has made progress towards establishing a generic framework for generation at the functional level, but left open the issue of actual implementation. In this paper, we discuss the requirements for such an implementation layer for generation systems, drawing on two initial attempts to implement it. We argue that it is possible and useful to distinguish \u201cfunctional architecture\u201d from \u201cimplementation architecture\u201d for generation systems","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"Cambridge University Press","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.brighton.ac.uk:3100<\/identifier><datestamp>\n      2015-03-18T09:05:36Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51303030:51313030<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.brighton.ac.uk\/3100\/<\/dc:relation><dc:title>\n        Implementation architectures for natural language generation<\/dc:title><dc:creator>\n        Mellish, C.<\/dc:creator><dc:creator>\n        Evans, Roger<\/dc:creator><dc:subject>\n        Q100 Linguistics<\/dc:subject><dc:description>\n        Generic software architectures aim to support re-use of components, focusing of research and development effort, and evaluation and comparison of approaches. In the field of natural language processing, generic frameworks for understanding have been successfully deployed to meet all of these aims, but nothing comparable yet exists for generation. The nature of the task itself, and the current methodologies available to research it, seem to make it more difficult to reach the necessary level of consensus to support generic proposals. Recent work has made progress towards establishing a generic framework for generation at the functional level, but left open the issue of actual implementation. In this paper, we discuss the requirements for such an implementation layer for generation systems, drawing on two initial attempts to implement it. We argue that it is possible and useful to distinguish \u201cfunctional architecture\u201d from \u201cimplementation architecture\u201d for generation systems.<\/dc:description><dc:publisher>\n        Cambridge University Press<\/dc:publisher><dc:date>\n        2004-09<\/dc:date><dc:type>\n        Journal article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:rights>\n        <\/dc:rights><dc:identifier>\n        http:\/\/eprints.brighton.ac.uk\/3100\/1\/imparch-jnle.pdf<\/dc:identifier><dc:identifier>\n          Mellish, C. and Evans, Roger  (2004) Implementation architectures for natural language generation  Natural Language Engineering, 10 (3-4).  pp. 261-282.  ISSN 1469-8110     <\/dc:identifier><dc:relation>\n        10.1017\/S1351324904003511<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.brighton.ac.uk\/3100\/","10.1017\/S1351324904003511"],"year":2004,"topics":["Q100 Linguistics"],"subject":["Journal article","PeerReviewed"],"fullText":"Natural Language Engineering 1 (1): 000\u2013000. Printed in the United Kingdom\nc\u00a9 1998 Cambridge University Press\n1\nImplementation Architectures\nfor\nNatural Language Generation\nChris Mellish\nDepartment of Computing Science\nUniversity of Aberdeen,\nKing\u2019s College Aberdeen AB24 3UE, UK\ncmellish@csd.abdn.ac.uk\nRoger Evans\nInformation Technology Research Institute,\nUniversity of Brighton,\nBrighton, BN2 4GJ, UK\nRoger.Evans@itri.brighton.ac.uk\n(Received 17 February 2004 )\nAbstract\nGeneric software architectures aim to support re-use of components, focusing of research\nand development effort, and evaluation and comparison of approaches. In the field of\nnatural language processing, generic frameworks for understanding have been successfully\ndeployed to meet all of these aims, but nothing comparable yet exists for generation. The\nnature of the task itself, and the current methodologies available to research it, seem\nto make it more difficult to reach the necessary level of consensus to support generic\nproposals. Recent work has made progress towards establishing a generic framework for\ngeneration at the functional level, but left open the issue of actual implementation. In\nthis paper, we discuss the requirements for such an implementation layer for generation\nsystems, drawing on two initial attempts to implement it. We argue that it is possible\nand useful to distinguish \u201cfunctional architecture\u201d from \u201cimplementation architecture\u201d\nfor generation systems.\n1 The Case for a Generic Software Architecture for NLG\nMost natural language generation (NLG) systems have some kind of modular struc-\nture. The individual modules may differ in complex ways, according to whether they\nare based on symbolic or statistical models, what particular linguistic theories they\nembrace and so on. Ideally, such modules could be reused in other NLG systems.\nThis would avoid duplication of work, allow realistic research specialisation and\nallow empirical comparison of different approaches. Examples of ideas that might\ngive rise to reusable modules include:\n2 Mellish and Evans\nA program for generating referring expressions based on statistical analy-\nsis of a significant corpus of human-written text (Cheng et al. 2001)\nA surface realiser based on one of the most comprehensive generation grammars\nof English (Elhadad and Robin 1992)\nA text planner using stochastic search (Mellish et al. 1998) or constraint satis-\nfaction (Power 2000)\nAlthough conceptually such modules could work together in one system (re-\nsearchers at the international NLG meetings are basically speaking the same lan-\nguage at some level), in practice it is far from easy to build an NLG system using\nthe best modules around. This is because today\u2019s modules are written in different\nprogramming languages, assume different representations for data, are described in\nterms of theory-dependent terminology and are designed to run in many different\noverall NLG architectures. In fact, many important ideas are not even made avail-\nable in software form, simply because there is no obvious single way to package\nsuch software so as to be useful to others.\nAn agreed NLG software architecture would provide a framework for building\nmodules that were compatible and facilities to aid in the construction, operation and\nevaluation of modular NLG systems. Although such software architectures exist for\ntasks in natural language understanding (NLU) (e.g. GATE (Cunningham, Wilks,\nand Gaizauskas 1996)), there is as yet nothing similar for generation. There are\nsuccess stories of reuse of NLG modules (usually involving realisation components\nsuch as MUMBLE (McDonald 1981), FUF\/Surge (Elhadad and Robin 1992) and\nREALPRO (Lavoie and Rambow 1997)), though often the reuse involves a lot of\nwork and fails to fully exploit strengths. There are also examples of mature and\ncomplex software systems for building NLG systems which have been used for\nmultiple projects (e.g. KPML (Bateman 1997)), but these require one to embrace\na particular theoretical outlook and express one\u2019s whole system in terms of it. We\ndo not believe that the NLG field is mature enough yet to opt for a single linguistic\ntheory or programming strategy to take precedence at the expense of other ideas1.\nIt is important to recognise that existing architectural proposals for natural lan-\nguage processing (NLP) tasks fall into two broad kinds. The first kind primarily\nprovides a functional specification of the underlying data representations and\/or\nmodule definitions. Those architectures aimed at supporting the annotation of cor-\npora (for instance, ATLAS (Laprun et al. 2002), the Linguistic Annotation Frame-\nwork (Ide and Romary 2004) and the Text Encoding Initiative are of this nature, as\nare the \u201cgeneric architectures\u201d for information extraction (Hobbs 1993) or question-\nanswering (Hirschman and Gaizauskas 2001) systems. We shall refer to such pro-\nposals as functional architectures. The second kind of architecture provides direct\nsupport for the development of software systems by providing underlying software\nservices, such as optimised data storage, inter-process communication facilities and\na repertoire of control structures (Cunningham, Wilks, and Gaizauskas 1996; Brew\n1 We do not believe this for NLU either, but the nature of the understanding task, and\nthe dependence of the dominant methodology on training from pre-existing test sets,\ninduces greater alignment of approaches than seems to have occurred for NLG to date.\nNatural Language Generation 3\net al. 2000; Bayer et al. 2001; Herzog et al. 2004). We shall refer to such archi-\ntectures as implementation architectures. Implementation architectures necessarily\npresuppose some (often quite small) degree of functional specification, and hence\nsome functional architecture. The combination of functional and implementation\narchitectures into a single framework is what we take to be a software architecture\n(although we acknowledge that not all software architectures make such a clean\ninternal distinction).\nThis distinction is relevant here, because while no viable complete software archi-\ntecture exists for NLG, there has been recent progress on a functional architecture\nfor NLG, notably the RAGS proposal (Cahill et al. 2001b; Mellish et al. 2004).\nRAGS establishes inter alia some quite demanding requirements for the implemen-\ntation layer, but provides no proposal for it. This paper concentrates on the question\nof what an implementation architecture for NLG could and should be like.\n2 The Scope of an NLG Software Architecture\nA candidate \u2018generic\u2019 NLG software architecture has to be broadly compatible with\nmost work in the field and attractive to enough researchers that it will be used. In\nthe end, the architecture will survive only if on the one hand researchers contribute\ngood-quality modules in a form compatible with it and on the other hand other\nresearchers actually reuse these modules using it. It is important, therefore, to\nlimit what the architecture tries to do, in order not to stray beyond this fragile\n\u201cconsensus\u201d. There is a tradeoff here between the number of potential users and\nthe amount of support it can give. The more theory-dependent the architecture is,\nthe fewer the people that can benefit from it, but the more it can help those people.\nSo what do current NLG researchers agree and not agree on? Some of the things\non which there doesn\u2019t seem to be a consensus include:\nThe individual modules making up an NLG system. Just about every NLG\nsystem divides the task differently. The different modules proposed do not\neven seem to group consistently into larger components (Cahill and Reape\n1999).\nHow the modules are organised and controlled. There have been a number\nof different architectures used (De Smedt et al. 1996). Often a pipeline archi-\ntecture is used (Reiter 1994), though it is well-known that there are funda-\nmental problems with such an architecture (Danlos 1984).\nThe input to NLG. Because of the range of applications considered, different\nNLG systems do not agree about the original conceptual input (e.g. on the\namount of linguistically-relevant structure it has) or the role of goals or user\nmodels in the generation process (Evans et al. 2002).\nThe absence of agreement about what modules are involved in NLG means that a\ngenerally useful software architecture must allow people to define their own modules\nin a flexible way. Hopefully, the most useful modules will become widely used and\nhence achieve prominence, but it should be the users that make this happen, not\nthe software architecture. Similarly a useful architecture should allow people to\n4 Mellish and Evans\n\u201cplug together\u201d modules in many ways. It should not legislate unnecessarily on the\noverall control regime. Finally, the problem of saying something general about the\ninput of NLG means that the architecture can make few assumptions about this.\n\u00bfFrom the above, one might take the view that the only useful generic software\narchitecture for NLG would be something like a programming language. Such a\nconclusion would, however, be overly pessimistic. Although NLG systems all have\nunique problems because of idiosyncrasies in their input, all of them have to produce\nbroadly the same kind of output, i.e. natural language. All NLG systems have\nto represent their output at various levels, and many NLG modules are defined\nprimarily in terms of the manipulations they perform on linguistic representations\nof some kind. A wide range of linguistic theories have been used as the basis of NLG\nsystems\u2019 representations, but underneath the differences, there are often striking\nsimilarities \u2014 for example many semantic representation schemes are basically\nversions of the Predicate Calculus \u2014 and in general distinctions between syntax,\nsemantics, rhetoric etc. are widely agreed. It is on the representation of linguistic\ndata that NLG systems agree most, and this is the most promising aspect of NLG\nto be built into and supported by a software architecture.\nSimilarly, although the overall picture of modules and their relationship to each\nother in actual systems is confused, researchers are strongly wedded to the exis-\ntence of particular functionalities within the NLG process, such as text structuring,\nreferring expression generation or lexical choice. This fact may also provide some\nleverage in the development of a software architecture for NLG. The problem is that\nthese functionalities do not seem to map into localised processing in a clean way \u2014\nthere is no clear mapping from logical functions to actual modules in implemented\nsystems. But an architecture that allows some flexibility in this mapping, for exam-\nple by separating the logical grouping of code implementing particular functionality\nfrom its deployment during the generation process, may be better able to support\nre-use of functional components.\n3 A Functional Architecture for NLG\nIt is interesting how the above arguments about the scope of a software architecture\nfor NLG recapitulate similar arguments made to motivate the GATE architecture\nfor NLU (Cunningham, Wilks, and Gaizauskas 1996). The success of GATE is due\nto a large extent to the fact that it has not tried to do too much. Yet it supports key\naspects of current NLU research methodology (corpus storage, annotation, evalua-\ntion) that all researchers must face to some extent. To put it another way, GATE\ncombines a lightweight functional architecture, whose focus is on data interchange,\nwith a powerful implementation architecture. A similar approach applied to NLG\nmight have similar success. The key differences appear to be:\n\u2022 The range and complexity of data structures presupposed by NLG systems.\n\u2022 The subtleties of interaction between module and control structure.\nThe GATE functional architecture is based on an underlying theory of the na-\nture of the data involved, as embodied in the TIPSTER architecture (Grishman\nNatural Language Generation 5\n1995). TIPSTER specifies the relevant attributes of stored text and the kinds of\nannotations that can be attached to it. This \u201cbackbone\u201d (honoured by the GATE\nimplementations) is then the basis for individual researchers defining their own\nmodules in a compatible way \u2014 the functional architecture requires modules to\nbe indivisible processing units but does not constrain their organisation relative\nto each other. It is then the GATE user who chooses from the available modules\nand decides how to plug the chosen modules together in a specific order. If such\na functional model existed for NLG, it could be the basis for a similar sort of\narchitecture.\nThe RAGS architecture (Cahill et al. 2001b; Mellish et al. 2004) is an initial\nattempt to be such a functional architecture specification. It defines abstractly six\nlevels of linguistic representation relevant to NLG (conceptual, document, rhetori-\ncal, semantic, syntactic and quote2), together with an underlying model, the \u201cOb-\njects and Arrows\u201d model, to support data manipulation3. It also identifies seven\nfunctional modules which make up the core of an NLG application (lexicalisation,\naggregation, rhetorical structuring, referring expression generation, ordering, seg-\nmentation and coherence maintenance (Cahill and Reape 1999)), but specifies no\ncontrol constraints, not even that each module is indivisible.\nThe advantages of RAGS are that:\n\u2022 It is based on substantial work attempting to understand current practice in\nNLG.\n\u2022 It is very general, allowing for instance for the definition of datasets that mix\nthe different levels of representation, provide partial information, use (acyclic)\nnon-tree-shaped structures, etc.\n\u2022 The data proposal is precisely defined and includes an XML \u201cinterchange\nformat\u201d for data.\nOn the other hand, RAGS is still relatively untried by the NLG community\nas a whole. It is also relatively complex, and as a functional architecture it lacks\nimplementation-level detail. The rest of this paper assumes that something like\nRAGS will be needed for an NLG functional architecture, though it may well have to\ndiffer from RAGS in significant ways. The discussion will attempt to be independent\nof particular details of RAGS (though the two prototype implementations described\nare both based on RAGS).\n2 Quote representations are used to allow data to include pieces of fixed material which\ncan be incorporated unchanged in the generator\u2019s output.\n3 The Objects and Arrows model is a formal definition of a well-formed RAGS dataset\n(what it can and cannot express; what distinctions are meaningful and what distinctions\nare not). It describes possible data of the six linguistic types in terms of a common low-\nlevel representation as directed acyclic graphs. Implementations following RAGS can\nrepresent this graph structure directly or they can use any other data format that\npreserves the relevant distinctions.\n6 Mellish and Evans\n4 Choices for an Implementation Architecture\nOne possible approach to developing an NLG software architecture would be to take\nan architecture for NLU and \u201csimply\u201d replace the functional architecture by one\ndeveloped with generation in mind. For instance, one could take GATE and reim-\nplement the central database to store datasets in the manner suggested by RAGS\ninstead of TIPSTER. Or one could take the idea of cascaded XML transducers sug-\ngested by the LT XML framework (Brew et al. 2000) and require that the format\nof XML transduced be that specified by RAGS. This latter approach gains some\nsupport from the existing examples of modular NLG systems that are implemented\nusing XML pipelines (e.g. using XSLT) (Wilcock 2001; Seki 2001; Barrutieta et al.\n2002). However, such an approach risks losing functionality in the NLG functional\nmodel (if it is not supported by the NLU implementation model) and limits the\nsupport provided by the implementation model to a NLU-oriented view of what\nmay be useful.\nAlternatively, instead of adapting an NLU architecture, one could devise a com-\npletely new architecture of some kind. In order to see what kind of architecture\nwould be most useful, it is necessary to have a better understanding of NLG and\ncurrent NLG practice than is probably readily available. The following are some\nfeatures that an NLG implementation architecture could be expected to support in\napplications. According to one\u2019s conclusions about the importance of these, differ-\nent architectures may be suggested. The best implementation architecture for NLG\nwill support a combination of features which takes into account that an architecture\nthat is unnecessarily general may also be one that is unnecessarily hard to use.\nNon-determinism. NLG is a search problem. NLG modules themselves may or\nmay not implement searches and may or may not wish to produce several\nanswers. The architecture can choose to support modules producing multi-\nple alternative results (non-determinism), or it can choose to require unique\nresults (determinism). As an extreme case, \u201covergeneration\u201d approaches to\nNLG require the production and storage of a very large number of alterna-\ntives (Langkilde and Knight 1998; Langkilde-Geary 2002). The NLG systems\ncited above that use XML pipelines are deterministic, and this is reflected in\ntheir use of XML. If the XML represents a sequential structure (a bit like a\ntext) then alternatives tend to give rise to overlapping elements. These can\u2019t\nbe represented in a single XML document, though they can be handled using\nstand-off annotation or a chart-like database as in GATE. NLG has to be able\nto generate alternative results, if only to achieve stylistic goals that cannot be\nchecked until the surface is reached (Reiter 2000), and so simple uses of XML\nand XSLT are not theoretically adequate for all NLG tasks. The RAGS data\nmodel is able to represent alternatives, but the result is increased complexity,\nand it remains to be seen how practical transformations based, say, on XSLT\nare for this use of XML.\nNon-monotonicity. Within one particular generation alternative, an architecture\ncan require that over time the system only ever adds information about this\nalternative (monotonic), or it could also permit changes and deletions of infor-\nNatural Language Generation 7\nmation (non-monotonic). Many NLG systems have components that repeat-\nedly revise and optimise structures to be generated (e.g. performing types\nof aggregation), and indeed some NLG systems are fundamentally based on\nthe notion of revision (which is inherently non-monotonic) (Robin and McK-\neown 1996). On the other hand, GATE assumes that NLU happens through\na monotonic accumulation of information about the text. A monotonic NLG\narchitecture is possible if revision processes in an NLG system can be in-\nternalised within individual modules, or if there is a fixed number of revision\nstages (each with its own separate representation). Alternatively, the approach\ntaken in RAGS is to allow revisions to be represented explicitly in an evolv-\ning dataset (Mellish et al. 2000), This provides another way of doing NLG in\na monotonic architecture, though at the expense of complexity in the data\nrepresentation.\nEclecticism. An NLG system builder may want to make use of modules that\nmake alternative (even incompatible) representation assumptions in different\nparts of the system. For instance, representation of syntactic structures may\nbe necessary for both a referring expression generation module and a sur-\nface realisation module, but the two desired modules may do this in different\nways. The system may be able to handle this by building multiple representa-\ntions and\/or translating between different representations. The architecture\ncan support this kind of eclecticism by allowing the two kinds of syntactic\nrepresentation to be kept separate and to have separate roles in the system\nas a whole. Or it can make this sort of activity difficult by forcing global\nconsistency of the representations.\nFlexibility of roles. The modules of an NLG system play particular roles within\nthe system as a whole. The calling pattern of the modules (when they are\ncalled and what for) reflects this. An architecture can support very flexible\nroles (exactly when a module is called is determined at runtime according\nto the particular circumstances prevailing), or it can be very inflexible (the\nsequence of calls is laid down in advance). The need for flexible roles has been\nargued by those NLG researchers who doubt the adequacy of pipelines for\nNLG (Danlos 1984) and those who have used blackboards of various kinds\n(Wanner and Hovy 1996; Rubinoff 1992; Nirenburg et al. 1989). One argu-\nment is that making the decisions to produce an optimal text requires different\nsources of information to be taken into account in unpredictable orders (or\nsuffers severe efficiency problems). Another argument is that language is re-\ncursive in structure and that the calling patterns will reflect this. For instance,\ntext planning may take place before referring expression generation, but re-\nferring expression generation (if it decides to introduce a relative clause) will\nneed to invoke more text planning and recursively more referring expression\ngeneration. The depth of this process cannot be predicted in advance, and so\nsome flexibility has to be left in the pattern of module invocation.\nParallelism. For real-time NLG, one might require an architecture to support par-\nallelism where different NLG tasks are more or less independent. Indeed, one\nmight rely on this in a multi-engine approach that tries out different possible\n8 Mellish and Evans\napproaches and takes the first answer available or the best answer, such as\nVERBMOBIL (Wahlster 2001). Certain kinds of models of human language\nproduction may also require support for parallelism (De Smedt 1994).\nCentral controllability. In a modular system, each module may be largely in\ncontrol of its own operation and deciding when it communicates with other\nmodules. On the other hand, there will be at least some element of central\ncontrol, in that the system as a whole has to start up and close down (al-\nthough in web- or grid-based approaches, modules may exists independently\nas persistent services). Central controllability here refers to the ability of some\ncentral process to impose a complex algorithm on the operation of the mod-\nules (rather than there being a fixed algorithm). This might be implemented\nvia a dedicated control module of some kind. An architecture will be thought\nof as supporting central controllability if it is possible to \u201cprogram\u201d it so as\nto produce behaviour such as global backtracking or constraint satisfaction.\nIn a centrally controlled system, the individual modules need have little idea of\nhow and when they are to be used, or of the significance of their results. On the\nother hand, in an architecture which is not centrally controllable, the overall\nbehaviour will emerge from that of the individual modules with no central\nconductor. The possibility to have central controllability is motivated if one\nmight want to implement NLG based on, for instance, constraint-satisfaction\nalgorithms (Beale et al. 1998).\nModules with state. Some NLG modules probably are not naturally thought of\nin terms of \u201cone shot\u201d operations that are performed independently. Such\nmodules require a notion of internal state that is maintained between invoca-\ntions. For example, a lexical choice module might want to maintain a memory\nof previous words used in order to achieve elegant variation. A referring ex-\npression generation module might want to maintain its own internal model of\nthe discourse and to generate referring expressions in sequential activations,\none phrase at a time, rather than to be provided with a complete discourse\nto work on. Although there are ways to work around this, XSLT pipelines do\nnot naturally allow modules to maintain internal state.\nComplex modules. Some NLG modules may wish to bring together multiple\nfunctionalities in a single unit. For example, lexical choice takes place in two\ndistinct phases in many NLG systems (early lexicalisation of semantic pred-\nicates and late lexicalisation as syntactic structure is built up \u2013 see (Cahill\n1999)), but may be implemented by a single logical module, which maintains\nstate across all the lexicalisation decisions of the system, whenever they are\nneeded.\nThe choice of a software architecture also depends on the set of services it is to\nprovide. It is unclear at present whether an NLG system needs fundamentally dif-\nferent services from NLU. Certainly some aspects are likely to be broadly similar\n\u2013 tracing of system operation, data import\/export, corpus-based evaluation and\nstatistical analysis and visualisation of results, for instance.\nNatural Language Generation 9\n5 Two Prototype Implementation Architectures\nIn this section we briefly present two prototype implementation architectures for\nNLG that have arisen from the RAGS project. Both of these are still only research\nprototypes (and in particular have hardly addressed user interface issues), but they\nhave been used to construct non-trivial NLG systems. Both architectures in fact\nmake use of the RAGS data model, but both could easily be adapted to handle\ndata according to another agreed data model with a similar nature to RAGS.\n5.1 RAGSOCKS\n5.1.1 Basic Mechanisms\nThe RAGSOCKS architecture implements a method of indirect point-to-point com-\nmunication between software modules which makes use of a central server to process\nall communications. In some ways, this makes it similar to the DARPA Communica-\ntor architecture (Bayer et al. 2001), a distributed hub-and-spoke architecture based\non message passing. However, whereas in Communicator the hub is a programmable\nresource that runs a tailored script to control the overall message traffic, in RAG-\nSOCKS the central \u201chub\u201d is supposed to be invisible, modules communicating as if\nthey had direct access to one another. The presence of the central server limits the\nknowledge that modules need to have of one another. This makes it easy to unplug\na module and plug in a replacement. The underlying communication mechanism\nis sockets, which connect modules running concurrently, on the same machine or\non different machines connected by a network. Code for the central server and to\nsupport the writing of RAGSOCKS modules in Java, LISP and Prolog is freely\navailable from the RAGS website http:\/\/www.itri.brighton.ac.uk\/rags\/.\n5.1.2 Module Conception\nEach RAGSOCKS module has a name, the process name, which identifies its role\nin the overall system and it also has names for (any number of, unidirectional)\nlogical communication channels that it will use. It needs to have no knowledge of\nthe names or whereabouts of other modules. A module sends and receives RAGS\nrepresentations via the central server (identifying itself by its process name and\nspecifying the relevant logical communication channel) using facilities in its own\nprogramming language (Prolog, Java or LISP). It is assumed that the module is\nrepresenting RAGS-compatible data in either one of the native programming lan-\nguage formats supported or in some other native format that it can translate into\none of the supported formats. The actual communication of data is done via sock-\nets, using XML as an interchange language, with the translation to and from XML\nhappening invisibly. The communication model is a simple one \u2013 the sender sends a\ncomplete set of RAGS representations into the channel as its half of the transaction\n(sending data cannot be interleaved with other processing). These can be represen-\ntations of any size or type, as long as they are legal RAGS representations. The\nsender need not wait for the data to be received before then doing something else\n10 Mellish and Evans\n(which could include sending data in a new transaction). The receiver, on deciding\nthat it is time for an input, hangs until all the data has been transferred and then\nis able to process that data. If data has been sent in several different transactions,\nthe receiver will get the first set when it first looks, the second set when it next\nlooks, etc. It needs to know when to look for input data (for instance, when it has\nnothing else to do).\n5.1.3 Central Control\nA single configuration file describes the desired configuration of modules, indicating\nhow the communication channels are plugged together (\u201cprocess A\u2019s channel with\nname NA plugs into process B\u2019s channel with name NB\u201d). The configuration file\nis interpreted by the central server to allow the actual communication to happen.\nThe server does not need to know the nature of the actual modules \u2013 any process\ncan connect to the server, claiming a process name that is present in the config-\nuration file, and it can then use the logical channels associated with that process.\nOf course, the person constructing the configuration file has to know enough about\nthe modules to ensure that output channels are connected to input channels, that\nthe types of information provided at an output correspond to what is required at\nthe corresponding input and that any synchronisation requirements between the\ncommunications are met by the modules (e.g. \u201cwhenever module A gets an input\non channel 1, it produces an output on either channel 2 or channel 3\u201d).\nThe central server has no control over the operation of the modules, which are\nstarted up and closed down by the user independently of it.\n5.1.4 Services\nThe existence of a central server through which all communications pass means that\nthere is a straightforward way to watch what is happening in the system. The server\nprovides a display which shows the state of play for all the connections listed in the\nconfiguration file. This indicates by colours which modules are waiting for input,\nwhich are producing output and what communication is currently taking place via\nthe server. Because the display can change quickly, one has the option to temporarily\n\u201cfreeze\u201d the system (i.e. the server, which means that no new communications can\nbe initiated; the modules will continue running until they need the server) and then\nlet it continue again. If one is interested in a particular connection in the system,\nit is possible via the server\u2019s display panel to initiate tracing, which means that all\ntraffic along the connection is displayed in a dedicated window (in raw XML form).\nA connection can also be reset (if there is an error) via the display. The only direct\nglobal user control is over the server and its connections, though the user also starts\nand stops the modules and may interact with them individually in whatever ways\nthey allow.\nJust as a module can send and receive RAGS representations via logical channels\nconnected to other modules, facilities are provided so that they can be loaded and\nstored from disc files. This must, however, be programmed within the individual\nNatural Language Generation 11\nKB\nREFEXPR\nREALISER\nPLANNER\nCLIENT\nFig. 1. The architecture of a RAGSOCKS system\nmodules, and there is no special support for the organisation of o\ufb04ine data, batch\nprocessing of multiple datasets or collation of results.\n5.1.5 Example System\nRAGSOCKS has been used to implement a simple reconstruction of the ILEX\nsystem (O\u2019Donnell et al. 2001) using some pre-existing generation components.\nThe architecture of this system is shown in figure 1. Dashed lines indicate the\ncommunication channels between modules. All of these in fact go via the central\nserver, which is not shown. The following briefly describes the modules and their\ninteraction.\nclient - A central module implemented in LISP that communicates with the other\nmodules (which essentially act as servers) as required. This module has logical\nchannels for output to the other modules (tokb, toplanner, torealiser,\ntorefexpr) and for input from the other modules (fromkb, fromplanner,\nfromrealiser, fromrefexpr).\nkb - The domain knowledge base required for content determination and certain\nlinguistic decisions (in fact, a reformulation of the ILEX knowledge base as a\nProlog database). This acts a server implementing the RAGS API for knowl-\nedge bases, with logical channels in (for queries) and out (for responses).\nplanner - A text planner that assembles a set of facts and possible rhetorical\nrelations into an overall text plan (in fact, a Prolog implementation of a\nstochastic text planner (Mellish et al. 1998)). This has logical channels in\nand out.\nrealiser - A surface realiser for mixed syntactic and semantic representations which\nreturns strings ready for output (in fact, the LISP implementation of the\nFUF\/Surge system (Elhadad and Robin 1992)). Again with logical channels\nin and out.\n12 Mellish and Evans\nrefexpr - A module for generating referring expressions (various possibilities have\nbeen implemented in LISP and Java). This module also needs to access the\nkb module. It has logical channels in and out (for the main input\/output),\nas well as kbin and kbout (for the communications with the KB).\nIn this case, RAGSOCKS has been used to implement a Communicator-like sys-\ntem, where client is the hub, performing some generation tasks (e.g. content de-\ntermination) and orchestrating the operation of the other main modules (planner,\nrealiser and refexpr). However, refexpr, as well as client, has direct access to\nthe knowledge base module, which diverges from the hub-and-spoke pattern.\n5.2 OASYS\n5.2.1 Basic Mechanisms\nOASYS (\u201cObject and Arrows SYStem\u201d) provides a blackboard architecture sup-\nporting event-driven activation of software modules. A \u201cblackboard\u201d is a monoton-\nically increasing set of data items, and the principal event type is publication of\ndata items on a blackboard. Multiple blackboards are supported to allow shared\nor private communication between modules. Modules are implemented as event\nhandlers, registering interest in particular event patterns with the central OASYS\nserver, and processing event instances as they occur, generally resulting in new pub-\nlication events which other modules may respond to. In general, modules need have\nno knowledge of other modules \u2013 their interfaces can be defined solely in terms of the\nevents they respond to and produce. However, OASYS does provide mechanisms for\nmodules to communicate more directly: as well as \u201cpublish\u201d events, OASYS sup-\nports \u201clifecycle\u201d events, indicating when component modules start up or terminate,\nand \u201csynthetic\u201d events, containing arbitrary content negotiated between modules4\nAn application is constructed and coordinated by the central server. Modules are\n\u201cplumbed together\u201d using one or more blackboards, then each is sent an \u201cinitialise\u201d\n(lifecycle) event. The server then enters an event processing loop until all generated\nevents have been dispatched, and then the application exits. The current imple-\nmentation runs as a single Prolog process, although the architecture is potentially\nextendable to multi-process\/multi-language scenarios.\n5.2.2 Module Conception\nIndividual modules are implemented as event handlers, that is, code to process each\nsingle event as it occurs. Initially, a module is registered to receive just lifecycle\nevents. It is guaranteed to receive an \u201cinitialise\u201d event before anything else and will\ntypically handle this by registering interest in \u201cpublish\u201d and \u201csynthetic\u201d events it is\n4 Synthetic events have no meaning to the OASYS server \u2013 it merely receives them and\ndispatches them to any module which has registered interest in them. They can be used\nby cooperating modules to pass messages which do not correspond to creation of new\nblackboard data or module lifecycle events.\nNatural Language Generation 13\ninterested in. In addition, each module has a name and a type which other modules\ncan use to locate a particular component of a system, and private global state data\nwhich the OASYS server maintains between calls to the module handler.\nThere is no formal requirement that modules have any particular functionality\nor even that they do just one thing - in principle a single module could service\nmultiple kinds of events. Module granularity and functionality is a matter for the\nuser community of OASYS modules, not a requirement of OASYS itself.\nModules run asynchronously and independently: the only guarantee the system\noffers is that a module will receive events it is interested in only once, and in the\nsame order as the events were generated. There is no guarantee that another module\nwill or will not have run beforehand, nor that another module may or may not have\nprocessed exactly the same event. All such coordination is achieved by explicit\ncooperation between modules. For example, one way to implement a strict pipeline\nis using lifecycle events: module N in the pipeline is activated by the \u201cterminate\u201d\nevent of module N \u2212 1.\nOASYS blackboards are strictly monotonically increasing: it is only possible to\nadd information to a blackboard, and the only way to do so is via a \u201cpublish\u201d event.\nThus items in a blackboard are ground terms (so that they cannot be further in-\nstantiated indirectly, i.e. without explicit publication), and cannot be changed or\nremoved once added. A module which wishes to \u201crevise\u201d a data structure must use\nadditional meta-data protocols to indicate the relationship between the original and\nthe revised version in the blackboard, which the other modules in the application\nmust respect when accessing the data. The OASYS implementation provides spe-\ncific support for this using the RAGS \u201cObjects and Arrows\u201d representation, which\nincludes \u201crevised-to\u201d arrows to represent changes, but other approaches are also\npossible.\n5.2.3 Central Control\nIn an OASYS-based application, the central OASYS server module is firmly \u201cin\ncontrol\u201d: the application is built by registering modules (event handlers) with the\nserver, and then control passes to the OASYS mainloop and stays there, typically\nuntil the application completes (i.e. no further events are generated). The server\ncreates and manages blackboards; registers modules, and events they are interested\nin; generates lifecycle events; dispatches events to relevant module handlers and\nreceives back new events to be processed; and handles error conditions. However,\nthe support for module configuration and event dispatching is completely generic,\ndeclarative and essentially non-deterministic (although the actual Prolog imple-\nmentation will follow its usual deterministic depth-first backtracking search). This\nallows for maximum flexibility over control at the application level, but with the\ninevitable overhead that modules which want to impose control constraints need to\nknow more about each other and agree protocols for doing so. The OASYS imple-\nmentation provides additional support functions to achieve this, such as a utility\nto construct a simple pipeline architecture, and libraries to interface correctly to\n\u201cObjects and Arrows\u201d data representations in the blackboard. In principal, the\n14 Mellish and Evans\nOASYS server module could be replaced with a variant using a different control\nstrategy, but the underlying assumption in OASYS is that control at this level is\nnot important.\n5.2.4 Services\nAs with RAGSOCKS, the central server architecture readily supports centralised\nmonitoring of system activity. Indeed it is possible to monitor event activity entirely\ntransparently, by adding a module interested in every event that occurs. In addition\nthe use of declarative blackboards makes it possible to consider off-line storage of\nsystem state, for example using an XML representation. This allows snapshots\nof system activity to be stored and examined, and the creation of complex test\nenvironments for individual modules.\nHowever, because the central server is so neutral with regard to control issues,\ncentralised management of processing is not possible without the explicit coop-\neration of modules, except at a very crude stop\/go level. For example adding a\nmodule which seeks to pause another module when a particular event occurs may\nnot succeed, as there is no way of knowing which of the two modules will run first.\n5.2.5 Example System\nTEXT\nEXPRESSIONS\nREFERRING\nDOCUMENT\nLEXICON\nRENDERER\nLINGO\nOASYS\nPICTURE\nLIBRARY\nLEXICAL\nCHOICESELECTION\nMEDIUM\nSENTENCE\nFINALISER\nFLO\nRHETORICAL \nORACLE PLANNER\nFig. 2. The architecture of the RICHES system\nOASYS has been used in the construction of the RICHES generator (Cahill et\nal. 2001a). The architecture of RICHES is shown in figure 2. Here the dashed lines\nindicate flow of information between the individual modules and the OASYS server,\nusing a single shared blackboard. The solid arrows indicate approximately flow of\ncontrol between modules. The following briefly describes the modules and their\ninteraction \u2013 see (Cahill et al. 2001a) for further information.\nNatural Language Generation 15\nRhetorical Oracle - The input to the system, a rhetorical structure, is simply\naccessed from a data file and published to initialise the OASYS database.\nMedia Selection - As soon as the rhetorical representation becomes available,\nthis module examines it and decides whether parts can be illustrated. If so,\nit creates document structure elements to link in the pictures.\nDocument Planner - The Document Planner, based on the iconoclast text\nplanner (Power 2000) takes the rhetorical representation, and produces a doc-\nument structure. This module is pipelined after Media Selection, so it can take\naccount of any picture elements already on the blackboard.\nLexical Choice - Lexical choice happens in two stages, both handled by a single\nlogical module. In the first stage, lexical items are chosen for each predicate\nspecified by the document structure. This fixes the basic syntactic structure\nof the proposition, and provides enough information for the Renderer and\nSentence Planner to start processing. The second phase of lexical choice is\ninterleaved with Referring Expression generation, lexicalising noun-phrases as\nthey are generated. As each whole sentence is completed, the Lexical Choice\nmodule passes it on to FLO for final realisation.\nReferring Expressions - The Referring Expression module adds information on\nthe form of each noun phrase, deciding whether it should be a pronoun, a\ndefinite noun phrase or an indefinite noun phrase.\nSentence Finaliser - The Sentence Finaliser completes the high level sentential\norganisation combining the lexicalised predicates and noun phrases according\nto the specified rhetorical and document structure specifications.\nFinalise Lexical Output (FLO) - FLO provides an interface between the RAGS\nrepresentation on the blackboard and the external sentence realiser, LinGo\n(Carroll et al. 1999),\nRenderer - The Renderer puts the concrete document together. Guided by the\ndocument structure, it produces HTML formatting for the text and posi-\ntions and references the pictures. Individual sentences are produced for it by\nLinGO, via the FLO interface, asynchronously.\nThis example demonstrates a range of different control strategies \u2014 an initial\nthree-stage pipeline is followed a complex set of interactions between modules build-\ning different parts of the final output document. It would be possible to impose more\ncontrol structure on the architecture, for example the Renderer could in this exam-\nple run after everything else has finished, but we note that (a) this is an additional\nconstraint, not a simplification (b) more complex generators might require earlier\nrendering, for example in order to include document deixis (reference to page or\nsection numbers etc.).\n6 Discussion and Open Issues\nRAGSOCKS and OASYS are just two of many possible generic implementation ar-\nchitectures for supporting the building of NLG systems. In this section, we compare\nthem and reflect on wider issues that they raise.\n16 Mellish and Evans\n6.1 Comparison of Prototypes\nTable 1 presents a comparison of RAGSOCKS and OASYS according to the features\npreviously identified. For reference, the capabilities of XSLT pipelines have also\nbeen included in the table. In the table, \u201cY\u201d indicates a feature supported, \u201cN\u201d\nXSLT pipelines RAGSOCKS OASYS\nNon-determinism Maybe Y Y\nNon-monotonicity Y Y S\nEclecticism Y Y S\nRole flexibility N Some Y\nParallelism N Y N\nCentral Controllability N N Some\nModules with state N Y Y\nComplex modules N N Y\nTable 1. Comparison of Features Supported by Architectures\na feature not supported and \u201cS\u201d a feature not directly supported but which can\nbe simulated. The sequence XSLT pipelines \u2013 RAGSOCKS \u2013 OASYS is in order of\nincreasing complexity, where each member of the sequence can in principle simulate\nthe behaviour of its predecessors. Thus a choice between these architectures is really\na decision about the tradeoff between ease of use (simplicity) and flexibility.\nInterestingly, although both RAGSOCKS and OASYS support non-determinism,\nneither architecture has used this significantly in the systems discussed. It remains\nto be seen how these will cope with large-scale non-determinism, and indeed this\nmay require special support well beyond what these implementations currently offer.\nFor non-monotonicity and eclecticism, RAGSOCKS gives direct support. OASYS\nalso supports these via its meta-data protocols and multiple blackboards, though\nthese facilities make the architecture complex and lose something of the elegance\nof the basic model.\nXSLT pipelines offer no flexibility in the roles of the modules \u2013 the exact sequence\nof operations must be specified in advance. In RAGSOCKS, a module will, however,\nbe called (by giving it an input) when it is needed at runtime. This means that the\nnumber of times a module is called can vary, for instance. However, it has to be\ncalled via a request from another module and has to yield results as expected by\nthat module. In OASYS, on the other hand, a module runs when it wants to and\nproduces the kinds of results it decides. Although this only works well when there\nare some conventions about how material will appear in the blackboard, nevertheless\nit seems to represent the ultimate in role flexibility.\nParallelism is not supported by the current OASYS implementation, though there\nis nothing in the model to prevent an implementation using genuine parallelism\n(indeed, in some ways this would be more faithful to the underlying model than\nthe current implementation, which imposes arbitrary serialisation on an essentially\nnon-deterministic dispatching algorithm).\nNatural Language Generation 17\nOASYS is the only one of these architectures that has significant central con-\ntrollability. The range of possible control options is very large, though the modules\ndefinitely have to cooperate in any centrally-imposed control strategy. The manner\nof \u201cprogramming\u201d central control may be somewhat unfamiliar to many users, and\nin the current OASYS implementation, the assumption is that control at this level\nis not required.\n6.2 What is a module?\nThe three different architectures differ in the notion of \u201cmodule\u201d that they support\nand assume. In an XSLT pipeline, a module is a process that is called exactly once,\nhas a single input and output and is responsible for acting over the whole of the text\nto be generated. In RAGSOCKS and OASYS, however, a module can have internal\nstate and be invoked a variable number of times during generation. Thus a module\ncan act to deal with just a local part of the generation process. In addition OASYS\nmodules can implement multiple functions, with no formal requirement that they\nare related to each other at all. This allows OASYS to support applications where\nthe functional and control modules do not correlate elegantly (cf. the discussion at\nthe end of section 2 above). An OASYS module is responsible for knowing when it\nneeds to be activated (which events to register interest in), whereas a RAGSOCKS\nmodule is responsible for producing an appropriate result when it is activated.\nXSLT modules have a responsibility to retain information from previous modules\nthat will be needed later. RAGSOCKS modules have no such obligation, whereas\nOASYS modules have no choice but to leave what other modules have placed in\nthe blackboard (monotonicity).\nIt follows from the above that the definitions of modules are likely to look very\ndifferent in the different architectures. Indeed, the architecture adopted may have\na significant impact on the way one sets about creating modules (i.e. what modules\none thinks of and what their scope is). These observations suggest that there is\nno architecture that does not limit to some extent what one considers natural or\npossible, although in general, the more powerful architectures can simulate the less\npowerful ones with sufficient effort.\n6.3 The Central Server\nBoth RAGSOCKS and OASYS make use of central servers, and indeed this fea-\nture is probably essential for the kinds of services one would like to have provided\n(e.g. tracing, state saving, overall control). However, they take radically different\nviews of the activeness of the server. The RAGSOCKS server is essentially a pas-\nsive telephone exchange, whereas the OASYS server has key control over the data\navailable to the modules (which means that it is constantly consulted) and can to\nsome extent impose global control strategies.\nA key decision in choosing an architecture seems to be how active the central\nserver should be. Having an active server lessens the amount the programmer needs\n18 Mellish and Evans\nto worry about control within the modules. The modules then become more like\ndeclarative rules, whose operation is separately scheduled.\n6.4 Roles of Data\nThe OASYS use of a shared, monotonic, blackboard is very similar in spirit to\nthe central database in GATE. Assuming that only a single blackboard is used,\nan OASYS module is then accessing the current description of the state of the\ngeneration process. XSLT pipelines take a similar view, although the current state\nis passed from module to module, rather than being shared. The RAGSOCKS\napproach, however, allows new information to be created and discarded on the fly.\nIt takes a more anarchic view that data structures exist purely for the convenience\nof allowing pairs of modules to communicate (hence eclecticism) and that they need\nhave no further significance.\nIn the end, the choice of an architecture then implies a view about how \u201cor-\nganised\u201d the NLG process is. Are the modules indeed cooperating on fleshing out\nthe true picture (OASYS), or does generation emerge as a result of more complex\ninteractions or even competition?\n6.5 \u201cPlug and play\u201d\nA crucial role of a generic software architecture is to support the plugging in of\nalternative versions of a module. \u201cPlug and play\u201d will however only happen signif-\nicantly if in practice different researchers end up defining compatible versions of a\nparticular module, even when they perhaps disagree about other modules or about\nthe order of execution of modules. To support this, the architecture must:\n\u2022 have a sufficiently general notion of module that modules can be implemented\nindependently of the exact context in which they are to be used,\n\u2022 minimise the extent to which the programmer of a module needs to worry\nabout context beyond the immediate focus of the module.\nWhether this can be achieved depends to a large extent on the underlying data\nmodel, which we do not consider here. There may also be a tradeoff between these\ntwo goals \u2013 an architecture with a very general notion of module may be harder to\nprogram modules for.\nLet us consider first the issue of module generality. An XSLT pipeline module\nis designed to be run at a particular point in a pipeline. It must be aware of all\nthe information produced previously in order to preserve it or alter it as necessary\nfor subsequent stages of the pipeline. Its definition may thus be very specific to its\nposition in the pipeline, which means that someone else would have to be working\nwith a near identical pipeline in order to come up with an alternative version\nof the module. A RAGSOCKS module, on the other hand, is defined in terms\nof the inputs it is given and the outputs it produces. It only needs to consider\ninformation that is part of these, which makes it independent of manipulations\nof data that are not its primary business. This should increase the chance that\nNatural Language Generation 19\nsomeone else may want to define a module with exactly the same specification. But\nhow can one be sure that other modules will indeed package up exactly the right\ndata (all at once) to provide its inputs and that other modules will exist that can\nmake sense of the particular combinations of structures that are in its outputs?\nA module will only be reusable if other systems provide these contexts correctly.\nFinally, an OASYS module does not rely on its input all at once and can produce\nits output incrementally as its input appears. If written well, it can act effectively\nin many situations, regardless of exactly how or when the necessary information\nappears. There are some constraints on the context. For instance there should be no\ndeadlocks possible in the blackboard and the scheduling of modules should be fair.\nThese are, however, probably relatively frequently satisfied and cheaply checked.\nTo what extent does the module programmer have to worry about context in the\ndifferent architectures? In an XSLT pipeline, a module definition must necessarily\nbe concerned with the preservation\/updating of the relevant context, and the pro-\ngrammer must deal with this explicitly. In RAGSOCKS, however, a module is only\nresponsible for producing its specified output. Irrelevant contextual information can\nbe excluded from its input or can simply be ignored by the module. Thus the mod-\nule programmer hardly needs to be concerned about what else is going on in the\ngeneration process. The situation in OASYS is more variable. If a module produces\noutput in batches, when complete inputs are available, then the situation is similar\nto that in RAGSOCKS. However, if the output is to be produced incrementally\nthen the module programmer must explicitly cater for variations in the order in\nwhich the input may become available. This could potentially be complex. Thus\nthere is a programming overhead associated with the extra generality that OASYS\nbrings (if it is used).\nThe above discussion suggests that OASYS may be the most promising of the ar-\nchitectures discussed in terms of allowing for the reuse and comparison of modules\nin a way that is compatible with NLG practice. Paradoxically, however, OASYS is\nalso the architecture that deviates most obviously from mainstream software engi-\nneering paradigms used in current NLG. And the extra generality over RAGSOCKS\nis bought at the expense of some programming and data management complexity.\nJust as RAGS offers a functional architecture for NLG but only through the effort\nof abstracting away from some current practice, OASYS may offer a similar trade-\noff of implementation benefits if implementors make the effort to work in a more\ngeneral setting.\n7 Conclusions and further work\nIn this paper we have sought to make a distinction between functional and imple-\nmentation aspects of generic software architecture proposals, in particular in the\ncontext of NLG. We have done so in part as an attempt to take the RAGS pro-\nposal for an NLG architecture one step closer to a complete software architecture,\nand in part as a way of thinking about software architectures more generally. The\nNLG scenario is challenging for any notion of a generic software architecture, be-\ncause of the complexity of the task and the corresponding range of existing work to\n20 Mellish and Evans\ntake into consideration. The partial functional characterisation of NLG offered by\nRAGS provides a foundation to think about implementation issues somewhat inde-\npendently and we contend that this is useful: explicit separation of the functional\nand implementation structure of architectures is a valuable aid to developing and\nunderstanding complex tasks such as NLG. By comparing different implementation\napproaches we can gain a better understanding of the tradeoffs between simplic-\nity and re-usability, and gain insight into the best ways to conceive of functional\nmodule definition and its relationship to implementation in general.\nFuture directions for this work can be considered at both the specific and gen-\neral levels. The RAGSOCKS implementation for RAGS is available on the RAGS\nwebsite, together with a range of support interfaces. Public release of OASYS is an-\nticipated soon, together with additional support to promote take-up in the context\nof RAGS. Together, these resources will help take the RAGS initiative forward to\na stage where a range of re-usable modules, created by a range of practioners, are\navailable for the NLG community, and the fine details of a generic architecture be-\ncome more evident. More generally, we believe that the overall framework we have\ndescribed here has wider applicability to other NLP tasks, perhaps based broadly on\nthe RAGS analysis, and more generally to other complex and \u2018intelligent\u2019 systems.\n8 Acknowledgements\nThis work was partly supported by two research grants from the EPSRC (RAGS \u2014\nReference Architecture for Generation Systems: grant GR\/L77102 to University of\nBrighton, grant GR\/L77041 to University of Edinburgh). We also acknowledge the\ncontribution of colleagues on the RAGS project: Donia Scott, Lynne Cahill, Mike\nReape, Daniel Paiva, Christy Doran, Neil Tipper and Rodger Kibble, as well as the\nsupport and interest of other colleagues at Brighton, Edinburgh and Aberdeen.\nReferences\nBarrutieta, G., J. Abaitua and J. Diaz. (2002) Cascading XSL Filters for Content Selection\nin Multilingual Document Generation. Procs of the Second Workshop on NLP and XML,\nTaipei.\nBateman, J. (1997) Enabling Technology for Multilingual Natural Language Generation:\nThe KPML Development Environment. Natural Language Engineering, 3(1):15\u201355.\nBayer, S., C. Doran and B. George. (2001) Dialogue Interaction with the DARPA Com-\nmunicator Infrastructure: The Development of Useful Software. Poster presentation,\nHLT 2001.\nBeale, S., S. Nirenburg, E. Viegas and L. Wanner. (1998) De-Constraining Text Gen-\neration. Procs of the Ninth International Workshop on Natural Language Generation,\nNiagara-on-the-Lake.\nBrew, C., D. McKelvie, R. Tobin, H. Thompson and A. Mikheev. (2000) The XML\nLibrary LT XML version 1.2. Obtainable at\nhttp:\/\/www.ltg.ed.ac.uk\/software\/xml\/xmldoc\/xmldoc.html.\nCahill, L. (1999) Lexicalisation in Applied NLG Systems. Technical Report ITRI-99-04,\nITRI, University of Brighton. obtainable at http:\/\/www.itri.brighton.ac.uk\/rags\/.\nNatural Language Generation 21\nCahill, L. and M. Reape. (1999) Component tasks in applied NLG sys-\ntems. Technical Report ITRI-99-05, ITRI, University of Brighton. obtainable at\nhttp:\/\/www.itri.brighton.ac.uk\/rags\/.\nCahill, L., J. Carroll, R. Evans, D. Paiva, R. Power, D. Scott, and K. van Deemter. (2001)\nFrom RAGS to RICHES: exploiting the potential of a flexible generation architecture.\nProcs of the 39th Annual Meeting of the Association for Computational Linguistics\n(ACL-01), pages 98\u2013105, Toulouse, France.\nCahill, L., R. Evans, C. Mellish, D. Paiva, M. Reape, and D. Scott. (2001) The RAGS Ref-\nerence Manual . Technical Report ITRI-01-08, ITRI, University of Brighton. Available\nat http:\/\/www.itri.brighton.ac.uk\/rags.\nCarroll, J., A. Copestake, D. Flickinger and V. Poznanski. (1999) An efficient chart gen-\nerator for (semi-)lexicalist grammars. Procs of the 7th European Workshop on Natural\nLanguage Generation (EWNLG\u201999), pages 86\u201395, Toulouse.\nCheng, H., M. Poesio, R. Henschel and C. Mellish. (2001) Corpus-based NP Modifier Gen-\neration. Procs of the Second Meeting of the North American Chapter of the Association\nfor Computational Linguistics (NAACL-01), Pittsburgh.\nCunningham, H., Y. Wilks, and R. Gaizauskas. (1996) GATE - a general architecture\nfor text engineering. Procs of the 16th International Conference on Computational\nLinguistics (COLING\u201996), volume 2, pages 1057\u20131060, Copenhagen.\nDanlos, L. (1984) Conceptual and Linguistic Decisions in Generation. Procs of the 10th\nInternational Conference on Computational Linguistics (COLING\u201984), Stanford.\nDe Smedt, K. (1994) Parallelism in Incremental Sentence Generation. In G. Adriaens\nand U. Hahn (Eds) Parallel Natural Language Processing, Ablex, pages 421\u2013447.\nDe Smedt, K., H. Horacek, and M. Zock. (1996) Architectures for Natural Language\nGeneration: Problems and Perspectives. In G. Adorni and M. Zock, (Eds) Trends in\nNatural Language Generation, Springer Verlag, pages 17\u201346.\nElhadad, M. and J. Robin. (1992) Controlling content realization with functional uni-\nfication grammars. In R. Dale, E. Hovy, D. Roesner and O. Stock (Eds) Aspects of\nAutomated Natural Language Generation, Lecture Notes in Artificial Intelligence, 587.\nSpringer-Verlag, pages 89\u2013104.\nEvans R., P. Piwek and L. Cahill. (2002) What is NLG? In Procs of the Second In-\nternational Conference on Natural Language Generation (INLG-02), New York, pages\n144\u2013151.\nGrishman, R. (1995) TIPSTER Phase II Architecture Design Document Version 1.52.\nTechnical Report, Dept of Computer Science, New York University.\nHerzog, G., A. Ndiaye, S. Merten, H. Kirchmann, T. Becker and P. Poller. (2004) Large-\nScale Software Integration for Spoken Language and Multimodal Dialog Systems. Nat-\nural Language Engineering, this issue.\nHirschman, L. and R. Gaizauskas. (2001) Natural Language Question Answering: the\nview from here. Natural Language Engineering, 7(4):275\u2013300.\nHobbs, J. (1993) The generic information extraction system. Procs of the fifth Message\nUnderstanding Conference (MUC-5), Morgan Kaufman.\nIde, N. and L. Romary. (2004) International Standard for a Linguistic Annotation Frame-\nwork. Natural Language Engineering, this issue.\nLangkilde, I. and K. Knight. (1998) Generation that Exploits Corpus-based Statistical\nKnowledge. Procs of the Conference of the Association for Computational Linguistics\n(COLING\/ACL-98).\nLangkilde-Geary, I. (2002) An Empirical Verification of Coverage and Correctness for a\nGeneral-Purpose Sentence Generator. Procs of the Second International Conference on\nNatural Language Generation (INLG-02), New York, pages 17\u201324.\nLaprun, C., J. Fiscus, J. Garafolo and S. Pajot. (2002) A Practical Introduction to ATLAS.\nProcs of the Third International Conference on Language Resources and Evaluation\n(LREC-02), Las Palmas.\n22 Mellish and Evans\nLavoie, B. and O. Rambow. (1997) A fast and portable realiser for text generation. Procs of\nthe Fifth Conference on Applied Natural Language Processing (ANLP-97), Washington,\npages 265-268.\nMcDonald, D. (1981) MUMBLE: A Flexible System for Language Production. Procs\nof the Seventh International Joint Conference on Artificial Intelligence (IJCAI-81),\nVancouver, page 1062.\nMellish, C., A. Knott, J. Oberlander and M. O\u2019Donnell. (1998) Experiments using Stochas-\ntic Search for Text Planning. Procs of the Ninth International Workshop on Natural\nLanguage Generation (INLG-98), Niagara-on-the-Lake, pages 98\u2013107.\nMellish, C., R. Evans, L. Cahill, C. Doran, D. Paiva, M. Reape, D. Scott, and N. Tipper.\n(2000) A representation for complex and evolving data dependencies in generation.\nProcs of the Language Technology Joint Conference, ANLP-NAACL2000, Seattle.\nMellish, C., D. Scott, L. Cahill, R. Evans, D. Paiva and M. Reape. (2004) A Reference\nArchitecture for Generation Systems. Natural Language Engineering, this issue.\nNirenburg, S., V. Lesser and E. Nyberg. (1989) Controlling a Language Generation\nPlanner. Procs of the 11th International Joint Conference on Artificial Intelligence\n(IJCAI-89), Detroit, pages 1524\u20131530.\nO\u2019Donnell, M., A. Knott, C. Mellish, and J. Oberlander. (2001) ILEX: The architecture\nof a dynamic hypertext generation system. Natural Language Engineering, 7:225\u2013250.\nPower, R. (2000) Planning texts by constraint satisfaction. Procs of the 18th International\nConference on Computational Linguistics (COLING-2000), Saabruecken, pages 642-\n648.\nRadev, D., N. Kambhatla, Y. Ye, C. Wolf and Z. Wlodek. (1999) DSML: A Proposal for\nXML Standards for Messaging Between Components of a Natural Language Dialogue\nSystem. Procs of the AISB\u201999 Workshop on Reference Architectures and Data Standards\nfor NLP, Edinburgh.\nReiter, E. (1994) Has a consensus NL generation architecture appeared and is it psycholin-\nguistically plausible? Procs of the 8th International Workshop on Natural Language\nGeneration (INLG-94), Kennebunkport, pages 163\u2013170.\nReiter, E. (2001) Pipelines and Size Constraints. Computational Linguistics 26:251-259.\nRobin, J. and K. McKeown. (1996) Empirically designing and evaluating a new revision-\nbased model for summary generation. Artificial Intelligence, 85(1-2).\nRubinoff, R. (1992) Integrating Text Planning and Linguistic Choice by Annotating\nLinguistic Structures. In R. Dale, E. Hovy, D. Roesner and O. Stock (Eds) Aspects of\nAutomated Natural Language Generation, Springer Verlag, pages 45\u201356.\nSeki, Y. (2001) XML Transformation-based three-stage pipelined Natural Language Gen-\neration System. Procs of the Sixth Natural Language Processing Pacific Rim Symposium\n(NLPRS 2001), Tokyo, pages 767\u2013768.\nText Encoding Initiative. See http:\/\/www.tei-c.org\/.\nWahlster, W. (2001) Robust Translation of Spontaneous Speech: A Multi-Engine Ap-\nproach. Procs of the Seventeenth International Joint Conference on Artificial Intelli-\ngence (IJCAI-2001), Seattle.\nWanner, L. and E. Hovy. (1996) The HealthDoc Sentence Planner Procs of the Eighth\nInternational Natural Language Generation Workshop (INLG-96), Herstmonceux, pages\n1\u201310.\nWilcock, G. (2001) Pipelines, Templates and Transformations: XML for Natural Language\nGeneration. Procs of the first NLP and XML Workshop, Tokyo, pages 1\u20138.\n"}
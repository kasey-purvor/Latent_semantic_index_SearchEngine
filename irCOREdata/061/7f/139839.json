{"doi":"10.1016\/j.future.2010.07.004","coreId":"139839","oai":"oai:dspace.lib.cranfield.ac.uk:1826\/4766","identifiers":["oai:dspace.lib.cranfield.ac.uk:1826\/4766","10.1016\/j.future.2010.07.004"],"title":"LAG: Achieving transparent access to legacy data by leveraging grid environment","authors":["Deng, Yuhui","Wang, Frank Zhigang"],"enrichments":{"references":[{"id":37954494,"title":"A heterogeneous storage grid enabled by grid service.","authors":[],"date":"2007","doi":"10.1145\/1228291.1228296","raw":"Y. Deng, F. Wang. A heterogeneous storage grid enabled by grid service. ACM SIGOPS Operating Systems Review. Special Issue: File and Storage Systems 41(1) (2007), pp.7-13.","cites":null},{"id":37954508,"title":"A standards based approach to enabling legacy applications on the Grid,","authors":[],"date":"2008","doi":"10.1016\/j.future.2008.02.004","raw":"A. S. McGough, W. Lee, S. Das, A standards based approach to enabling legacy applications on the Grid, Future Generation Computer Systems 24(7) (2008), pp.731-743.","cites":null},{"id":37954521,"title":"Adapting legacy applications as Web services,","authors":[],"date":"2002","doi":null,"raw":"D.  Kuebler,  W.  Eibach,  Adapting  legacy  applications  as  Web  services,  2002. http:\/\/www.ibm.com\/developerworks\/library\/ws-legacy\/?n-ws-1312 ACCEPTED MANUSCRIPT ACCEPTED MANUSCRIPT","cites":null},{"id":37954490,"title":"An XML approach for legacy code reuse,","authors":[],"date":"2002","doi":"10.1016\/s0164-1212(01)00104-2","raw":"Y. Bi, M.E.C. Hull, P.N.Nicholl, An XML approach for legacy code reuse, Journal of Systems and Software 61(2) (2002), pp.77-89.","cites":null},{"id":37954497,"title":"Ant colony optimization inspired resource discovery in P2P Grid systems,","authors":[],"date":"2009","doi":"10.1007\/s11227-008-0214-0","raw":"Y. Deng, F. Wang, A. Ciura, Ant colony optimization inspired resource discovery in P2P Grid systems, Journal of Supercomputing 49(1) (2009), pp.4-21.","cites":null},{"id":37954488,"title":"B.Wu, J.Grimson, Legacy information systems: issues and directions,","authors":[],"date":"1999","doi":"10.1109\/52.795108","raw":"J.Bisbal,  D.Lawless,  B.Wu,  J.Grimson,  Legacy  information  systems:  issues  and  directions,  IEEE Software 16 (5) (1999), pp.103\u2013111. ACCEPTED MANUSCRIPT ACCEPTED MANUSCRIPT","cites":null},{"id":37954495,"title":"Dynamic and scalable storage management architecture for Grid Oriented Storage devices,","authors":[],"date":"2008","doi":"10.1016\/j.parco.2007.10.003","raw":"Y. Deng, F. Wang, N. Helian, S. Wu, C. Liao, Dynamic and scalable storage management architecture for Grid Oriented Storage devices, Parallel Computing 34(1) (2008), pp.17-31.","cites":null},{"id":37954485,"title":"Extensible Markup Language.","authors":[],"date":null,"doi":"10.1007\/springerreference_64920","raw":"Extensible Markup Language. http:\/\/www.w3.org\/XML\/.","cites":null},{"id":37954505,"title":"GEMLCA: grid execution management for legacy code architecture design, in:","authors":[],"date":"2004","doi":"10.1109\/eurmic.2004.1333409","raw":"T. Delaitre, A. Goyeneche, P. Kacsuk, T. Kiss, G.Z.Terstyanszky and S.C. Winter, GEMLCA: grid execution management for legacy code architecture design, in: Proceedings of the 30th Euromicro Conference (EUROMICRO04), 2004. pp. 477-483.","cites":null},{"id":37954506,"title":"Generalizing the data management of three community grids,","authors":[],"date":"2009","doi":"10.1016\/j.future.2008.05.001","raw":"S. Plantikow, K. Peter, M. H\u00f6gqvist, C. Grimme, A. Papaspyrou, Generalizing the data management of three community grids, Future Generation Computer Systems 25 (3) (2009), pp.281-289.","cites":null},{"id":37954520,"title":"Globus Toolkit version 4 grid security infrastructure: a standards perspective.","authors":[],"date":"2004","doi":null,"raw":"V.  Welch.  Globus  Toolkit  version  4  grid  security  infrastructure:  a  standards  perspective.  2004. http:\/\/www.globus.org\/toolkit\/docs\/4.0\/security\/GT4-GSIOverview.Pdf.","cites":null},{"id":37954516,"title":"Globus toolkit version 4: software for service-oriented systems,","authors":[],"date":null,"doi":"10.1007\/s11390-006-0513-y","raw":"I.  Foster,  Globus  toolkit  version  4:  software  for  service-oriented  systems,  IFIP  International Conference on Network and Parallel Computing, Springer-Verlag LNCS 3779, 2006,pp.2-13.","cites":null},{"id":37954522,"title":"GT4 GRAM: a functionality and performance study, in:","authors":[],"date":"2007","doi":"10.4016\/3366.01","raw":"M. Feller, I. Foster, S. Martin. GT4 GRAM: a functionality and performance study, in: Proceedings of the 2007 TeraGrid Conference, 2007.","cites":null},{"id":37954499,"title":"High-level grid application environment to use legacy codes as OGSA grid services, in:","authors":[],"date":"2004","doi":"10.1109\/grid.2004.37","raw":"P.  Kacsuk,  A.  Goyeneche,  T.Delaitre,  T.  Kiss,  Z.  Farkas,  T.  Boczko,  High-level  grid  application environment to use legacy codes as OGSA grid services, in: Proceedings of the Fifth IEEE\/ACM International Workshop on Grid Computing (2004), pp.428-435.","cites":null},{"id":37954489,"title":"How to evaluate legacy system maintenance?","authors":[],"date":"1998","doi":"10.1109\/52.687942","raw":"N. F. Schneidewind, How to evaluate legacy system  maintenance? IEEE Software 12 (1) (1998), pp.34\u201342.","cites":null},{"id":37954501,"title":"I.Taylor, D.W.Walker, R.Davies, Wrapping legacy codes for grid-based applications, in:","authors":[],"date":"2003","doi":"10.1109\/ipdps.2003.1213268","raw":"Y. Huang, I.Taylor, D.W.Walker, R.Davies, Wrapping legacy codes for grid-based applications, in: Proceedings of International Parallel and Distributed Processing Symposium, 2003.","cites":null},{"id":37954507,"title":"LGF: A flexible framework for exposing legacy codes as services,","authors":[],"date":"2008","doi":"10.1016\/j.future.2007.12.001","raw":"B. Bali, M. Bubaka, M. Wegiel, LGF: A flexible framework for exposing legacy codes as services, Future Generation Computer Systems 24 (7) (2008), pp.711-719.","cites":null},{"id":37954517,"title":"Monitoring and Discovery System,","authors":[],"date":null,"doi":"10.1109\/cyberc.2010.19","raw":"Monitoring and Discovery System, http:\/\/www.globus.org\/toolkit\/mds\/.","cites":null},{"id":37954482,"title":"Opportunities and challenges of storage grid enabled by grid service,","authors":[],"date":"2007","doi":"10.1145\/1278901.1278915","raw":"Y.  Deng,  F.  Wang,  Opportunities  and  challenges  of  storage  grid  enabled  by  grid  service,  ACM SIGOPS Operating Systems Review 41(4) (2007), pp.79-82.","cites":null},{"id":37954525,"title":"performance considerations for mobile web services,","authors":[],"date":"2004","doi":"10.1016\/j.comcom.2004.01.015","raw":"M. Tian, T. Voigt, T. Naumowicz, H. Ritter, J. Schiller, performance considerations for mobile web services, Computer Communications 27(11) (2004), pp.1097-1105.","cites":null},{"id":37954481,"title":"Semantic Information Brokering: How Can a Multi-agent Approach Help? in:","authors":[],"date":"1999","doi":"10.1007\/3-540-48414-0_21","raw":"A. P. Sheth, V. Kashyap, T. Lima, Semantic Information Brokering: How Can a Multi-agent Approach Help? in: Proceedings of the Third International Workshop on Cooperative Information Agents III, 1999, pp.303-322.","cites":null},{"id":37954523,"title":"Services Description Language.","authors":[],"date":null,"doi":"10.1007\/978-3-8274-2550-8_6","raw":"Web Services Description Language. http:\/\/www.w3.org\/TR\/wsdl.","cites":null},{"id":37954524,"title":"Simple Object Access Protocol.","authors":[],"date":null,"doi":"10.1007\/springerreference_62870","raw":"Simple Object Access Protocol. http:\/\/www.w3.org\/TR\/soap\/.","cites":null},{"id":37954486,"title":"Supervised learning for the legacy document conversion, in:","authors":[],"date":"2004","doi":"10.1145\/1030397.1030439","raw":"B. Chidlovskii, J.Fuselier, Supervised learning for the legacy document conversion, in: Proceedings of the 2004 ACM symposium on Document engineering, 2004, pp.220-228.","cites":null},{"id":37954493,"title":"The anatomy of the Grid: enabling scalable virtual organizations,","authors":[],"date":"2001","doi":"10.1109\/ccgrid.2001.923162","raw":"I.Foster, C. Kesselman, S. Tuecke, The anatomy of the Grid: enabling scalable virtual organizations, International Journal of High Performance Computing Applications 15(3) (2001), pp.200-222.","cites":null},{"id":37954480,"title":"The Expanding Digital Universe: A Forecast of Worldwide Information Growth Through","authors":[],"date":"2010","doi":null,"raw":"The Expanding Digital Universe: A Forecast of Worldwide Information Growth Through 2010. IDC white  paper\u2014Sponsored  by  EMC.  March,  2007. http:\/\/www.emc.com\/about\/destination\/digital_universe\/.","cites":null},{"id":37954519,"title":"The x window system,","authors":[],"date":"1986","doi":"10.1145\/22949.24053","raw":"R.  W.  Scheifler\uff0cJ.  Gettys,  The  x  window  system,  ACM  Transactions  on  Graphics  5(2)  (1986), pp.79-109.","cites":null},{"id":37954487,"title":"Towards automating of document structure transformations, in:","authors":[],"date":"2002","doi":"10.1145\/585058.585078","raw":"E. Kuikka, P. Leinonen, and M. Penttonen, Towards automating of document structure transformations, in: Proceedings of ACM Symposium on Document Engineering, 2002, pp. 103\u2013110.","cites":null},{"id":37954526,"title":"Understanding Quality of Service for Web services,","authors":[],"date":"2002","doi":null,"raw":"A.  Mani,  A.  Nagarajan,  Understanding  Quality  of  Service  for  Web  services,  January,  2002. http:\/\/www-106.ibm.com\/developerworks\/library\/ws-quality.html.","cites":null},{"id":37954527,"title":"Usability engineering,","authors":[],"date":"1993","doi":"10.1016\/b978-0-08-052029-2.50008-5","raw":"J. Nielsen, Usability engineering, Morgan Kaufmann, San Francisco, 1993. Dr. Yuhui Deng is a professor at the computer science department of Jinan University. Before joined Jinan University, he worked at EMC Corporation as a senior research scientist from 2008 to 2009. He worked as a research officer at Cranfield University in United Kingdom from 2005 to 2008. He received his Ph.D. degree in computer architecture from Huazhong University of Science and Technology in 2004. He has authored and co-authored two book chapters, more than 20 refereed academic papers. He is on the editorial board  of  International  Journal  of  Grid  and  High  Performance  Computing  and  a  book  titled  Grid Technologies and Utility Computing: Concepts for Managing Large-Scale Applications. He has served as committee members for several professional conferences in the field. He is also a reviewer of several academic journals. His research interests cover green computing, data storage, computer architecture, Grid Computing, performance evaluation, etc. Prof. Frank Wang is the director of Centre for Grid Computing, Cambridge-Cranfield High Performance Computing Facility (CCHPCF), Cranfield University. He is Chair in e-Science and Grid Computing. He is on  the  editorial  board  of  IEEE  Distributed  Systems  Online,  International  Journal  of  Grid  and  Utility Computing,  International  Journal  of  High  Performance  Computing  and  Networking,  and  International Journal  on  Multiagent  and  Grid  Systems.  He  is  on  the  High  End  Computing  Panel  for  the  Science Foundation Ireland (SFI). He is the Chair (UK & Republic of Ireland Chapter) of the IEEE Computer Society. ACCEPTED MANUSCRIPT ACCEPTED MANUSCRIPT Dr. Yuhui Deng is a professor at the computer science department of Jinan University. Before joined Jinan University, he worked at EMC Corporation as a senior research scientist from 2008 to 2009. He worked as a research officer at Cranfield University in United Kingdom from 2005 to 2008. He received his Ph.D. degree in computer architecture from Huazhong University of Science and Technology in 2004. He has authored and co-authored two book chapters, more than 20 refereed academic papers. He is on the editorial board of International Journal of Grid and High Performance Computing and a book titled Grid Technologies and Utility Computing: Concepts for Managing Large-Scale Applications. He has served as committee members for several professional conferences in the field. He is also a reviewer of several academic journals. His research interests cover green computing, data storage, computer architecture, Grid Computing, performance evaluation, etc. Prof. Frank Wang is the director of Centre for Grid Computing, Cambridge-Cranfield High Performance Computing Facility (CCHPCF), Cranfield University. He is Chair in e-Science and Grid Computing. He is on the editorial board of IEEE Distributed Systems Online, International Journal of Grid and Utility Computing, International Journal of High Performance Computing and Networking, and International Journal on Multiagent and Grid Systems. He is on the High End Computing Panel for the Science Foundation Ireland (SFI). He is the Chair (UK & Republic of Ireland Chapter) of the IEEE Computer Society. *Biographies (Text)ACCEPTED MANUSCRIPT ACCEPTED MANUSCRIPT Yuhui Deng Frank Wang *Biographies (Photograph)","cites":null},{"id":37954503,"title":"Using grid technologies for web-enabling legacy systems, in:","authors":[],"date":"2003","doi":"10.1109\/step.2003.37","raw":"T. Bodhuin, M. Tortorella, Using grid technologies for web-enabling legacy systems, in: Proceedings of the Eleventh Annual International Workshop on Software Technology and Engineering Practice, 2003, pp.186-195.","cites":null},{"id":37954518,"title":"Virtual network computing.","authors":[],"date":"1998","doi":"10.1109\/4236.656066","raw":"T. Richardson, Q. Stafford-Fraser, K. R. Wood, A. Hopper, Virtual network computing. IEEE Internet Computing 2 (1) (1998), pp.33-38.","cites":null},{"id":37954483,"title":"Warning of data ticking time bomb.","authors":[],"date":"2007","doi":"10.1002\/9780470692486.ch2","raw":"Warning of data ticking time bomb. July, 2007.    http:\/\/news.bbc.co.uk\/1\/hi\/technology\/6265976.stm.","cites":null},{"id":37954484,"title":"Word works with open file styles.","authors":[],"date":"2007","doi":null,"raw":"Word works with open file styles. February, 2007, http:\/\/news.bbc.co.uk\/1\/hi\/technology\/6323575.stm.","cites":null},{"id":37954491,"title":"Wrapper-based evolution of legacy information systems,","authors":[],"date":"2006","doi":"10.1145\/1178625.1178626","raw":"P. Thiran, J.  Hainaut, G. Houben, D.  Benslimane, Wrapper-based evolution of legacy  information systems, ACM Transactions on Software Engineering and Methodology 15(4) (2006), pp.329-359.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2011-01-31T00:00:00Z","abstract":"The world today is experiencing an explosive growth of data generated by\ninformation digitization. Due to the unprecedented advance in software and\nhardware, large amounts of data gradually becomes legacy data and inaccessible.\nThis is building a digital black hole, and it is becoming a big challenge to\naccess, process, and preserve the legacy data. Grid provides flexible, secure,\nand coordinated resource sharing among dynamic collections of individuals,\ninstitutions, and resources. It allows users and applications to access the\naggregated resources in a transparent manner. This paper proposes a Legacy\nApplication Grid (LAG) architecture. This architecture deploys diverse legacy\napplications in a grid environment and provides a transparent access to the\nremote LAG users who want to access the legacy data. In contrast to the existing\nmethods which attempt to tackle legacy data and legacy applications, we wrap a\ndisplay protocol into grid services. The service provider, who wants to deploy\nany legacy applications, just needs to deploy the protocol based grid service,\ndescribe and pass the parameters of those legacy applications to the service.\nCompared with the traditional approaches, the method proposed in this paper is\nvery cost-effective because it avoids converting legacy data from one format to\nanother format or upgrading legacy applications one by one. An implemented\nprototype validates that the LAG architecture trades acceptable performance\ndegradation for a transparent and remote access to legacy data. (C) 2010\nElsevier B.V. All rights reserved","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/139839.pdf","fullTextIdentifier":"http:\/\/dx.doi.org\/10.1016\/j.future.2010.07.004","pdfHashValue":"84ab1ed84cdac622d4053eaa72079941f395dab1","publisher":"Elsevier Science B.V., Amsterdam.","rawRecordXml":"<record><header><identifier>\noai:dspace.lib.cranfield.ac.uk:1826\/4766<\/identifier><datestamp>2011-01-27T12:00:47Z<\/datestamp><setSpec>hdl_1826_19<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>LAG: Achieving transparent access to legacy data by leveraging grid environment<\/dc:title><dc:creator>Deng, Yuhui<\/dc:creator><dc:creator>Wang, Frank Zhigang<\/dc:creator><dc:subject>Legacy data Grid Architecture Grid service Web service information-systems management services<\/dc:subject><dc:description>The world today is experiencing an explosive growth of data generated by\ninformation digitization. Due to the unprecedented advance in software and\nhardware, large amounts of data gradually becomes legacy data and inaccessible.\nThis is building a digital black hole, and it is becoming a big challenge to\naccess, process, and preserve the legacy data. Grid provides flexible, secure,\nand coordinated resource sharing among dynamic collections of individuals,\ninstitutions, and resources. It allows users and applications to access the\naggregated resources in a transparent manner. This paper proposes a Legacy\nApplication Grid (LAG) architecture. This architecture deploys diverse legacy\napplications in a grid environment and provides a transparent access to the\nremote LAG users who want to access the legacy data. In contrast to the existing\nmethods which attempt to tackle legacy data and legacy applications, we wrap a\ndisplay protocol into grid services. The service provider, who wants to deploy\nany legacy applications, just needs to deploy the protocol based grid service,\ndescribe and pass the parameters of those legacy applications to the service.\nCompared with the traditional approaches, the method proposed in this paper is\nvery cost-effective because it avoids converting legacy data from one format to\nanother format or upgrading legacy applications one by one. An implemented\nprototype validates that the LAG architecture trades acceptable performance\ndegradation for a transparent and remote access to legacy data. (C) 2010\nElsevier B.V. All rights reserved.<\/dc:description><dc:publisher>Elsevier Science B.V., Amsterdam.<\/dc:publisher><dc:date>2011-01-25T23:00:18Z<\/dc:date><dc:date>2011-01-25T23:00:18Z<\/dc:date><dc:date>2011-01-31T00:00:00Z<\/dc:date><dc:type>Article<\/dc:type><dc:identifier>Yuhui Deng, Frank Wang; LAG: Achieving transparent access to legacy data by leveraging grid environment, Future Generation Computer Systems, Volume 27, Issue 1, January 2011, Pages 32-39<\/dc:identifier><dc:identifier>0167-739X<\/dc:identifier><dc:identifier>http:\/\/dx.doi.org\/10.1016\/j.future.2010.07.004<\/dc:identifier><dc:identifier>http:\/\/dspace.lib.cranfield.ac.uk\/handle\/1826\/4766<\/dc:identifier><dc:language>en_UK<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0167-739X","0167-739x"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2011,"topics":["Legacy data Grid Architecture Grid service Web service information-systems management services"],"subject":["Article"],"fullText":"Accepted Manuscript\nLAG: Achieving transparent access to legacy data by leveraging grid\nenvironment\nYuhui Deng, Frank Wang\nPII: S0167-739X(10)00126-3\nDOI: 10.1016\/j.future.2010.07.004\nReference: FUTURE 1913\nTo appear in: Future Generation Computer Systems\nReceived date: 30 September 2007\nRevised date: 2 July 2010\nAccepted date: 10 July 2010\nPlease cite this article as: Y. Deng, F. Wang, LAG: Achieving transparent access to legacy data\nby leveraging grid environment, Future Generation Computer Systems (2010),\ndoi:10.1016\/j.future.2010.07.004\nThis is a PDF file of an unedited manuscript that has been accepted for publication. As a\nservice to our customers we are providing this early version of the manuscript. The manuscript\nwill undergo copyediting, typesetting, and review of the resulting proof before it is published in\nits final form. Please note that during the production process errors may be discovered which\ncould affect the content, and all legal disclaimers that apply to the journal pertain.\nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\nThis paper builds a legacy application grid architecture (LAG) and proposes to wrap a display \nprotocol as a legacy grid service. The legacy service enables service providers to deploy any \napplications on heterogeneous platforms and operating systems. Therefore, the LAG users can \nleverage this legacy service to locate and use those required legacy applications to handle legacy \ndata. In contrast to the traditional methods, this approach is very cost-effective because it avoids \nconverting legacy data from one format to another format or upgrading legacy applications one by \none. Since this is a real implementation, detailed evaluation is also performed to explore the \nperformance behaviour of LAG. We believe the method proposed in this paper is a new way to \ntackle the increasing legacy data besides the traditional approaches discussed in the introduction \nSection. \n \n \n \n \n*Research Highlights\nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 1 \nLAG: Achieving Transparent  \nAccess to Legacy Data by Leveraging Grid Environment \n \nYuhui Deng \nDepartment of Computer Science,  \nJinan University, Guangzhou, 510632, P. R. China \nEmail:  tyhdeng@jnu.edu.cn    or   yuhuid@hotmail.com \n \nFrank Wang \nCambridge-Cranfield High Performance Computing Facility, \n Cranfield University Campus, Bedfordshire MK430AL, United Kingdom \n \n \nThe world today is experiencing an explosive growth of data generated by information digitization. Due to \nthe unprecedented advance in software and hardware, large amounts of data gradually becomes legacy data \nand inaccessible. This is building a digital black hole, and becoming a big challenge to access, process, and \npreserve the legacy data. Grid provides flexible, secure, and coordinated resource sharing among dynamic \ncollections of individuals, institutions, and resources. It allows users and applications to access the \naggregated resources in a transparent manner. This paper proposes a Legacy Application Grid (LAG) \narchitecture. This architecture deploys diverse legacy applications in a grid environment and provides a \ntransparent access to the remote LAG users who want to access the legacy data. In contrast to the existing \nmethods which attempt to tackle legacy data and legacy applications, we wrap a display protocol into grid \nservices. The service provider, who wants to deploy any legacy applications, just needs to deploy the \nprotocol based grid service, describe and pass the parameters of those legacy applications to the service. \nCompared with the traditional approaches, the method proposed in this paper is very cost-effective because \nit avoids converting legacy data from one format to another format or upgrading legacy applications one by \none. An implemented prototype validates that the LAG architecture trades acceptable performance \ndegradation for a transparent and remote access to legacy data. \n \nKeywords: Legacy data, grid, architecture, grid service, web service \n \n1. Introduction \n According to a new report from IDC, 161 exabytes of digital information were created and copied in \n2006. The growth will continue to increase exponentially. The amount of information in 2010 will surge \nmore than six fold to 988 exabytes which amounts to a compound annual growth rate of 57% [1]. The \nexplosive data is normally stored in autonomous repositories distributed across the Internet and varies in \nrepresentation from structured (e.g. relational database) to semi-structured (e.g. e-mail and HTML pages) \nand unstructured formats (e.g. image and video) [2]. The ubiquitous Internet has provided an easy access to \na large number of autonomous and heterogeneous information sources [3]. However, due to the \nunprecedented development of software and hardware, large amounts of legacy data is becoming a big \nchallenge which we have to face when accessing the digital information (Legacy data is the data which has \nbeen inherited from applications, software, languages, platforms, and techniques earlier than current \n*Manuscript\nClick here to view linked References\nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 2 \ntechnology). The National Archives of United Kingdom, which holds 900 years of written material, has \nmore than 580 terabytes of data in legacy data formats that are no longer commercially available. Some \ndigital documents held by the national archives had already been lost forever, because the programs which \ncould access them no longer existed [4]. There are two reasons which cause the problem. The first one is \nthe range of proprietarily data formats that are proliferated during the early digital revolution. The different \ndata formats do no work together, which makes the interoperability become a big problem. The second one \nis that the data formats employed by software companies are not only incompatible with that of the rival \ncompanies, but also between different generations of the same program (e.g. Microsoft) [4, 5]. \n The growing legacy data has propelled the research on how to access, process, and preserve the legacy \ndata. Some research efforts have been invested in tackling the growing challenge. Saving data in one format \nwith one program makes it difficult to open in another program without sacrificing some information. \nExtensible Markup Language (XML) [6] offers portability and ease of machine processing. The wide \nspread and growing maturity of XML technologies bring new opportunities to tackle the legacy data. \nChidlovskii and Fuselier [7] investigated data conversion from the rendering-oriented HTML markup into a \nsemantic-oriented XML annotation defined by user-specific DTDs or XML Schema descriptions. They \napplied a supervised learning framework to the conversion task according to which the transformations are \nlearned from a set of training examples. The data which are in proprietary formats such as PDF, MS Word, \netc have to be first converted to a standard format like HTML, and then the layout HTML annotations will \nbe converted to the semantic XML. Kuikka et al. [8] developed a syntax directed approach to transform the \nXML documents from one structure to another. The aim is to automate a transformation between two \ngrammars that have common parts, although the grammars and names of elements may differ. Other \ndriving forces for the research on the legacy data are from industry. Open XML is a data format developed \nby Microsoft. This format can be adopted to save files from programs such as Word, Excel and Powerpoint. \nThe open XML is an open international standard under independent control and are free for access [4]. \nWorking with three partners, Microsoft also released a translation program which allows users to save \nWord documents in the ODF format favoured by the free Open Office application [5]. With the support \nfrom Microsoft, the National Archive of United Kingdom will be able to read older data formats in the \nformat they were originally saved by running emulated versions of the older Windows operating systems on \nmodern PCs. For example, if a Word document was saved using Office 97 under Windows 95, then the \nNational Archives will be able to open that document by emulating the operating system and the \ncorresponding software on a modern machine [4].  \n The legacy data and legacy application is normally one to one correspondence, which indicates that a \nspecific legacy data format can only be accessed by the corresponding legacy application. If the legacy \napplications can be upgraded, the corresponding legacy data will be solved as well. A lot of research efforts \nhave been invested in tackling the legacy applications. Generally, the existing solutions can be classified \ninto three categories [9]. The first one is redevelopment. This method rewrites or reconstructs the existing \nlegacy applications. The common activities include parsing the system and analyzing its syntax to obtain an \nabstract syntax tree representation of the source code, extracting the interface fragments from the system, \nand performing control flow analysis [10, 11]. The redeployment method requires shutting down the legacy \napplications either during development or during the replacement [9]. The second one is wrapping. This \napproach surrounds the legacy component with a new interface. Thiran et al. [12] proposed and designed a \ngeneric and technology independent R\/W wrapper architecture. The wrapper allows a smooth transition \nfrom the legacy and deficient databases to modern architectures, and makes the integration of a legacy \ndatabase into current large applications easier. The third one is migration. This solution moves legacy \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 3 \napplications to a new environment, while retaining the original system\u2019s data and functionality. Wrapping \nand migration are normally employed to reuse legacy applications. One or more approaches could be \ninvolved when tackling the legacy applications. Bi et al. [11] investigated a hybrid approach of wrapping \nand migration for the reuse of legacy applications from its original environment to the Internet-based \nplatform based on a thin client using Java RMI. \n However, for the companies and organizations those have a large number of diverse and legacy data, \nthe conversion of all legacy data or the upgrading of all legacy applications could take a lot of time and \nmoney, and raise many technical problems. For the personal users who have a little legacy data or just want \nto use the legacy data temporarily, it is not cost-effective to buy a software package to convert the data or \nupgrade the corresponding legacy application. \n Grid is a flexible, secure, coordinated resource sharing among dynamic collections of individuals, \ninstitutions, and resources [13, 14, 15, 16]. The objective is to virtualize resources, and allow users and \napplications to access shared resources in a transparent manner. In recent years, the research community \nhas been very active in the area of investigating techniques in tackling the legacy applications in a grid \nenvironment. Kacsuk et al. [17] proposed a new approach to deploy legacy codes as grid services without \nmodifying the original code. A workflow oriented grid portal is designed to apply the legacy code based \ngrid services to complex business processes. Huang et al. [18] designed a wrapping and data mapping \ntechnique for converting the existing legacy code (e.g. libraries of scientific and mathematical software \nwritten in C language) into composing computational services within a grid environment. Bodhuin and \nTortorella [19] designed a tool which can automatically transform the source code of legacy applications \nand make them compatible with the web or grid technologies. GEMLCA [20] is a front end OGSI grid \nservice layer which surrounds the target host environment and executes legacy applications through the \nOGSI grid service. Plantikow[21] proposed a data management system architecture and discussed \napproaches for the integration of legacy applications and grid scheduling with the proposed architecture. An \nintegrator is designed to instruct the VFS driver to add a new logical file system view. Such views are used \nto provide the legacy applications with input data and to collect the results. Each legacy program is run \ninside a jail\/sandbox such that it only accesses its logical view. LGF [22] is a two-tier architecture in which \nthe interface layer is decoupled from the legacy layer. This enables many benefits that surpass the \nperformance penalty due to the additional interposition layer. The LGF enables semi-automatic \nvirtualization of legacy codes as grid services. McGough et al. [23] proposed the use of a standards based \njob submission and monitoring system. This approach enables us to deploy legacy applications into the \nexisting resources within a Grid, to map applications into Grid applications, and to use a web based portal \nto expose these applications to the end users. \nIn this paper, we propose a Legacy Application Grid (LAG) which is based on an existing grid \nenvironment (GT4) [15, 24] consisting of a Monitoring and Discovery System (MDS) [25], a certificate \nauthentication centre and several grid service providers. In contrast to the existing methods, we wrap a \ndisplay protocol into grid service, which is registered in a MDS, instead of directly putting legacy \napplications into grid service or converting the legacy data from one format to another format. The service \nprovider who wants to deploy any legacy applications just need to deploy the protocol based grid service, \ndescribe and pass the parameters (e.g. application name) of those legacy applications to the grid service. \nTherefore, all kinds of legacy applications can be deployed in the LAG without modifying the source code \nand the GUI. LAG users who want to access any legacy data can locate and discovery the required legacy \napplication in LAG, and then employ the application to access the corresponding legacy data transparently. \nThe LAG can be maintained by companies or organizations. Thus, the method is very cost-effective for \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 4 \nboth the companies and personal users who want to access legacy data, because they just need to pay what \nthey use. A system prototype is constructed to investigate the overhead involved in the data access in LAG. \nThe experimental results illustrate that the LAG can provide transparent access to the legacy data with \nacceptable performance degradation. \nThe remainder of the paper is organized as follows. Section 2 gives a brief description about the \nbackground knowledge of display protocols. Overview of the LAG architecture and workflow are \nintroduced in Section 2. Section 4 describes how to build a legacy service, manage lifecycle and state, and \nservice registration. Section 5 illustrates the prototype system and evaluates the system performance. \nSection 6 concludes the paper with remarks on the contributions of the paper. There is also a brief \ndiscussion in Section 6. \n \n2. Background \nGenerally, there are two major display protocols which offer graphics sharing and guarantee network \ntransparency: Virtual Networking Computing (VNC) [26] and X Window System (X11). VNC system is a \nsimple protocol working in a client\/server model. This protocol offers remote accesses to graphical user \ninterfaces (GUI) and works at frame buffer level. The key point at the display side is putting a rectangle of \npixel data at a given x, y position. Therefore, the encoding is simply an x, y coordinate. This gives a \nposition in the frame buffer from which the client can copy the rectangle of pixel data. This encoding is \ntypically used when the user moves a window across the screen or scrolls a window\u2019s contents. VNC sends \ncompressed bitmaps across the network. X11 is a display protocol which provides a standard toolkit to \nbuild GUI for network computers. As a user application on top of operating systems, X11 is network \ntransparent and operating system independent. X11 also adopts a client\/server model which can be run on \nthe same computer or on different ones with different architectures and operating systems [27, 28]. X11 \nserver provides display and I\/O services (e.g. keyboard and mouse) to applications. X11 client leverages \nthese services to manipulate applications. Therefore, the X11 server sends user input to and accepts output \nrequests from client programs through communication channels. The X11 server machine can run a small \nprogram that makes a connection to the remote client machine and starts the client applications. \nAlternatively, the remote X11 client is also able to connect to an X11 server. Manipulating graphics in X11 \nis at relatively high-level elements including lines, rectangles, curves, and fonts. This is different to the \nsystems which read and write individual pixels. X11 can direct graphics to windows or pixmaps which \nwork in different ways. Drawing to a window generates a visible result, while drawing to a pixmap simply \nupdates the pixmap memory which is invisible. Pixmaps can be used to store frequently drawn images and \nas temporary backing-store for pop-up menus. Furthermore, it can animate a series of images by placing the \nimages into pixmap memory and then sequentially copying them to a visible window [27]. \n \n3. System overview  \n3.1 Architecture of LAG  \n A grid environment may consist of hundreds or even thousands of geographically distributed and \nheterogeneous resources to match the requirements imposed by all kinds of grid applications [14,16]. Grid \nis a Virtual Organization (VO) consisting of cooperating geographically distributed and diverse resources \nthat combine into a logical community with only minimal administrative requirements. LAG is based on an \nexisting Grid environment GT4. Therefore, LAG inherits the characteristics of GT4. The main goal of LAG \nis providing legacy applications as resources which can be located and employed by LAG users to access \nthe legacy data transparently.  \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 5 \n \nFig.1. Architecture of the legacy application grid \n \n LAG is composed of Service Providers (SPs) which offer diverse legacy applications, MDS, CA \ncentre, and LAG users. The Grid Security Infrastructure (GSI) [29] provides security functions including \nsingle or mutual authentication, confidential communication, authorization, and delegation. The security of \nLAG is within the GSI framework of GT4. Each service provider has to request and receive a host \ncertificate from the CA, thus allowing joining the LAG. In order to access the legacy applications in LAG, a \nuser has to request and receive a user certificate from the CA as well. Fig. 1 illustrates the architecture of \nLAG which consists of three sub-VOs. The three sub-VOs are connected with each other through three \nMDSs. A downstream and upstream mechanism is employed by the MDSs to exchange information \nautomatically and efficiently. The interaction between LAG users and the LAG is mediated through a LAG \nservice published on the Internet. When a user wants to access the LAG, firstly, it sends a request to the \nLAG service with its requirements. Secondly, the LAG service redirects the request to a MDS which is \nclose to the user. Within the LAG environment, the users can achieve the following functions through the \nVO interface: (1) obtain a security certificate from the certificate authority. (2) With the help of MDS, \nsearch and discovery appropriate legacy applications in terms of their requirements. (3) Employ the located \nlegacy application to access the legacy data transparently and remotely. \n \n3.2 Workflow of LAG \n \n Recently, some research efforts have been invested in solving the legacy applications in gird \nenvironment or service oriented architecture [17,18,19, 20,21,22,23,30]. However, the methods are either \ncostly or inflexible (e.g. converting the legacy data from one format to another format, wrapping or \nmodifying the legacy application one by one). The main goal of LAG is allowing users to locate and \nemploy an appropriate legacy application to access the corresponding legacy data transparently and \nremotely without modifying the source code and GUI of the legacy applications. Therefore, we do not use \nthe traditional methods including redeployment, wrapping, and migration. We develop a display protocol \nbased grid service which is called as legacy service in the remaining discussion of this paper. The legacy \nservice can be deployed in the LAG at the service provider side. The protocol can be adopted by LAG users \nto launch an application remotely and redirect the original GUI of the legacy applications to the users. \nLAG Users \nVO1  \nMDS3 \nMDS1 \nMDS2 \nVO2  VO3  \nService providers which \noffer legacy applications \nCA Centre \nLAG service \npublished on the \nInternet \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 6 \nSome parameters such as application name of the legacy applications are passed to the legacy service, \nwhich enables the LAG users to locate the legacy applications. \n \n \nFig.2 X11 server and client deployed on LAG user and service provider \n \n In a typical grid environment especially the LAG, the service providers could have diverse and \nheterogeneous platforms and operating systems. The X11 offers a very good opportunity to access the \nheterogeneous service providers which provide legacy applications in LAG, because almost all modern \noperating systems and architectures support X11. Unfortunately, the network traffic between the X11 client \nand X11 server is not secured, whereas grid environment requires high security due to its geographic \ndistribution and crossing domains. The data traffic between the X11 server and X11 client is secured by \nsecure shell and GSI protocol in our implementation. Fig.2 illustrates that the X11 server and X11 client are \ndeployed on LAG user and service provider, respectively. Service is becoming a basic application pattern of \ngrid because the service offers a standard means of interoperating between different applications running on \na variety of platforms. The X11 client is wrapped in a legacy service. Each service provider in the LAG has \nto lunch the legacy service which is registered in a MDS. The available legacy applications are published in \nthe legacy service by setting the application related parameters. The LAG users can locate the published \nlegacy applications through the legacy service with the help of MDS. When a user submits a request with \ncorresponding requirements to the MDS, the MDS will return a list of all matched legacy applications \nassociated with their Universal Resource Identifier (URI) by querying the available legacy service. The \nlegacy applications can be geographically distributed and transparent to the user. If the user chooses a \nlegacy application from the list, the remained steps are labelled with a sequence number as defined in the \nfollowing descriptions (see Fig.2). (1) The URI is employed by the user to locate the service provider \nwhich offers the legacy application chosen by the user. A connection between the service provider and the \nuser will be initialized and established. The user then sends a command to request the legacy application \nwhich is published with the legacy service. (2) When the legacy service receives the command, it will \nlaunch the requested legacy application. (3) The requested application creates a new process and registers \nitself with the X11 client to display its GUI. (4) The X11 client sends the GUI stream to the user with \nsecured network connection. The LAG user can then display the GUI on its screen as if it is processed \nlocally.  \nThere are two major jobs in a typical Grid environment. The first one is a batch job which stores \noutput\/error streams into remote files. The files can be retrieved after the job is completed. Batch jobs are \nnormally adopted when multiple jobs are launched in parallel, or when the execution time is expected to be \nvery large. The second one is an interactive job which provides immediate feedback to Grid users. A Grid \njob submission normally involves a client, a gatekeeper, and a job manager. The gatekeeper is a remote \nNetwork \nLAG user Service Provider \nKeyboard Mouse \nX11 Server \n \nScreen \nX11  \nClient \n Legacy \nservice \n(4)  \nLegacy application \n(1)  \n(2) \n(3) \nAccess \nInterface \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 7 \nservice that receives requests from clients, and performs mutual authentication with the clients. After \nauthenticating and authorizing, it starts a job manager running under the credentials of the authenticated \nuser. Therefore, a job manager is spawned by the gatekeeper upon receiving each request. The job manager \nprocesses job specifications sent by the clients, most of which result in a job submission to a local scheduler. \nIt also provides a mechanism through which the client can check the status of a job or cancel it [31]. The \nkey point of job submission in Grids is sending programs to the resources to execute. LAG works in a \ndifferent way. The reason is because legacy applications sometimes are tightly coupled with the running \nenvironment. It would be a challenge to decouple the legacy applications from its hardware platform and \nswitch to a new platform where the legacy data residing. As mentioned before, LAG users leverage the \nlegacy service to locate the published legacy applications with the help of MDS. After this is done, the \nusers who have legacy data to process will send a request to the legacy service to start the corresponding \nlegacy application. When the application is launched, X11 protocol will take over the whole process. \nTherefore, in contrast to the Grid job submission, it is unnecessary for LAG to send the programs (legacy \napplications) to the resources to execute.  \n \n4. Legacy Service \n \n4.1 Building a legacy service \n \n \nFig.3 Components and workflow of the legacy service \n \n As discussed in section 3.1, the LAG user locates the available legacy applications through a legacy \nservice with the help of MDS. The legacy service consists of four parts that are implemented by four \nclasses: A legacy service factory, a legacy service instance, a legacy service home, and the X11 protocol \n(see Fig. 3). When dealing with multiple resources, the WSRF specifications recommend employing the \nfactory\/instance pattern that is a well-known design pattern in software design, and especially in object \noriented languages. The factory\/instance pattern adopts one service (the service factory) in charge of \ncreating the resources and another one (the service instance) to actually access the information contained in \nthe resources. Because the SPs offer resources for hundreds of thousands of LAG users with different \nrequirements, the factory\/instance pattern is employed in the legacy service. The resource home is \nresponsible for registering and updating the MDS when it is necessary (e.g. When a new legacy application \nis added to the legacy service, the resource information in the SP has to be updated in MDS.). \nFig.3 illustrates the components and workflow of the legacy service. When a LAG user obtains the URI \nof a requested legacy application through MDS, the major steps are defined in the following descriptions. \nManage \n(1) \n(2) \n(3) (4) \n(5) \n(5) \nService  \nFactory \nResource  \nHome \nLAG  \nUser \nService  \nInstance \nX11 \nProtocol \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 8 \n(1) The URI is employed by the LAG user to locate the legacy service factory of the SP chosen by the user. \n(2) The legacy service factory invokes a createResource method to create and initialize a new resource \nassigned with a unique ID through the legacy resource home. (3) The legacy resource home which is \nresponsible for all the legacy resources (X11 protocol) will create a new legacy service instance associated \nwith an URI. (4) Once the createResource call finishes, a WS-Addressing EndPointReference (EPR) [32] \ncontaining the URI of the created legacy service instance and the ID of the allocated legacy resource (X11 \nprotocol) will be sent to the user. (5) The legacy service instance will employ the legacy resource home to \nfind the exact legacy resource (X11 protocol) and provide methods to operate the newly created legacy \nresource.  \n \n4.2 State and lifecycle management of the legacy service \n \n Grid service must provide their users with the ability to access and manipulate state. WSRF adopts \nWeb Service Resource (WS-Resource) consisting of a resource document and a corresponding web service \nto implement a stateful service. Because web service is stateless, the resource document employs an XML \nschema to capture state information for a WS-Resource due to the portability and ease in machine \nprocessing. The web service can check and alter states contained in the resource document.  \n The WS-Resource is adopted in the legacy service to describe and access any state of the legacy \nresources. Two kinds of important state information are managed by the legacy service. The first one is the \ninformation of the resource utilization. A service provider in the LAG is supposed to provide legacy \napplications for hundreds of LAG users. The service provider could become a system bottleneck due to the \noverload data traffic. Therefore, the service provider monitors the utilization of the hardware resources \nperiodically and stores the state. The stored state will be accessed by MDSs when the MDSs locate the \navailable legacy applications in terms of the query requirements. The applications residing in the service \nproviders which could be overloaded will be filtered by the MDS and are invisible to the LAG users. \nBecause each instance of the legacy service corresponds to a process of legacy application, the second state \ninformation is the process. A launched process in operating system is identified by a unique number called \nProcess ID (PID). The legacy service tracks the PID and records the corresponding information for three \nreasons. The first, the service provider is able to monitor which user is running which process. When it is \nnecessary, the process can be killed due to some reasons (e.g. security). The second, the service can \ncalculate which user used which legacy application and how long the user used. The information is \nimportant for charging the user appropriately. The third, the service provider is able to calculate how many \nusers are currently using the licensed legacy application, thus limiting the simultaneously running \nprocesses. \n WSRF lifetime management is employed to describe the resources that are destroyable via grid \nservices interfaces. The lifecycle management of the legacy service is composed of two cases. An instance \nof legacy service is created every time when a LAG user initiates a connection with a service provider. In \nthe first case, a legacy service instance allocated for a specific user can be destroyed immediately by means \nof the user\u2019s requirement. For example, when a user finishes data access or wants to terminate the data \naccess immediately. In the second case, when a user requests some legacy resources with specified time \nperiod, a scheduled destruction is adopted to calculate the destruction time. If the termination time is \narrived, a message will be sent to the user. If the user does not want to renew the legacy service instance, \nthe instance will be destroyed and the allocated resources will be reclaimed. \n \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 9 \n4.3 Legacy service registration \n \n A typical grid environment (e.g. GT4) is a VO. The interaction between the VO and grid users is \nmediated through MDS which provides a virtual interface between the diverse resources and maintains a \nsingle logical view. Therefore, all grid services have to be registered in the MDS. There is typically one \nMDS per VO, but in a large VO, several MDSs are normally organized in a hierarchy. MDS provides \nservice discovery, execution supervision, and monitoring of resource status information. A very important \nobjective of LAG is enabling authorized LAG users to locate the required legacy applications across the \ngeographically distributed service providers in LAG, and then employ the legacy applications to access the \ncorresponding legacy data. Therefore, In order to discover the legacy applications which are published in \nthe legacy service, the legacy service has to be registered in MDS. \n The purpose of service container is to shield the application from environment specific run-time \nsettings, control the lifecycle of services, and dispatch of remote requests to service instances. A grid \nservice provided by a service provider is first registered in the local service container, and then registered in \nthe MDS container. There are two important services which are employed by a container to monitor and \ndiscovery resources in grid environment. One is container registry service which keeps tracks of all \nservices running in the local container. Another one is default index service which can collect local resource \ninformation and remote resource information with the help of the upstream and downstream mechanism. \n After the X11 protocol is wrapped as a legacy service, it is important to register the service in MDS to \nmake it available to the users. The registration process can be divided into four steps: (1) Creating a default \ninstance for service provider. (2) Updating the instance by including the newly added legacy service. (3) \nRegistering the instance in the default index service of the local service container of service provider. (4) \nThe MDS container receives information from the registered downstream or upstream connection and \nregisters the default instance of the new service provider. Finally, the LAG users can discovery all available \nresources by querying the MDS.  \n \n5. Performance evaluation \n \nTable 1. System configurations of the testbed \n Computer1 Computer2 Computer3 \nCPU Intel 550MHz Intel 1.6 GHz Centrino duo 1.66 GHz \nMemory 128MB 256MB 1GB \nNetwork 100 Mbit\/s 100 Mbit\/s 100 Mbit\/s \nOS Red Hat( Kernel 2.4.21) Red Hat( Kernel 2.4.21) Red Hat( Kernel 2.4.21) \nMiddleware Globus Toolkit 4 Globus Toolkit 4 Globus Toolkit 4 \n \n We constructed a system prototype with three computers which were connected through a 100M \nswitch. All computers were installed with Redhat and Golbus Toolkit 4. Table 1 shows the system \nconfigurations of the three computers. All the performances reported in this paper are based on the average \nof 100 measurements. \n \n5.1 Evaluation of service registration \n \n In the test of this section, the three computers all play the role of service provides to investigate the \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 10 \nimpact on the registration process of the different computer platforms. The legacy service can be registered \nin the service provider locally or remotely by the clients who want to deploy legacy applications in LAG. \nWe will explore the exact overheads involved in the registration process by registering locally which \nexcludes the network overhead. \n As discussed in section 3.3, the registration process can be divided into 4 steps. We will investigate the \noverheads of the first three steps. The fourth step actually depends on the poll interval of MDS. We set the \npoll interval as 60 seconds which indicate that the MDS checks the downstream or upstream connections \nevery 60 seconds. There are four legacy applications which were updated in the second step of our test. \nFig.4 illustrates the average registration overheads of the three steps on three computers, respectively. Fig.5 \nshows the processing power consumed by the three steps on three different computers. The above tests \ndemonstrate that the registration is very resource consumption (e.g. the CPU utilization of computer1 and \ncomputer2 both reach 100% when dealing with the step1 and step3.) which is mainly caused by the SOAP \nmessages. \n \n1\n10\n100\n1000\n10000\n100000\nComputer 1 Computer 2 Computer 3\nT\nim\ne \n(m\ns)\nStep 1 Step 2 Step 3\n  \n0 %\n2 0 %\n4 0 %\n6 0 %\n8 0 %\n1 0 0 %\nC o m p u t e r  1C o m p u t e r  2C o m p u t e r  3\nC\nP\nU\n \nu\nt\ni\nl\ni\nz\na\nt\ni\no\nn\n \n(\n%\n)\nS t e p  1 S t e p  2 S t e p  3\n \n        Fig.4 Average registration overhead                   Fig.5 CPU utilization \n \n By using grid service, it is easy to construct a heterogeneous and Internet-scale system which \nguarantees interoperability. The core of grid service is Extensible Markup Language (XML) [6] which \noffers portability and ease of machine processing, because both the Web Services Description Language \n(WSDL) [33] and Simple Object Access Protocol (SOAP) [34] are based on XML. Due to the involved \nXML, requests and replies become much larger and parsing the XML messages on both the sender and the \nreceiver side incurs additional overhead. Tian et al. [35] discovered that sending 589 bytes of content \ninvolves additional 3363 bytes by using web service. Mani and Nagarajan [36] reported that XML\u2019s way of \nrepresenting data takes more than 400% overhead compared with the way adopted by binary. Therefore, it \nis very important to explore the exact overheads involved in the processing of XML. \n \nFig.6 Test scenario of a grid service invocation \n \nTable 2.Registration overheads and the corresponding SOAP overheads \n Step 1 (ms) Step 2 (ms) Step 3 (ms) \nOverall SOAP Overall SOAP Overall SOAP \nNetwork \nClient \nS\nO\nA\nP\n \n(1) \nS\nO\nA\nP\n (4) \n(2) \n(3) \nService Provider \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 11 \nComputer1 10140 10131 533 532 522 466 \nComputer2 8110 8106 331 330 195 160 \nComputer3 1063 1061 68.2 68 51 33 \n \n Fig.6 shows the test scenario of a typical grid service invocation. When a client needs to invoke a grid \nservice, it wraps the required data into SOAP messages and sends the messages with HTTP protocol \nthrough network to the service provider. The service provider then analyzes the SOAP messages, extracts \nthe data, and uses the data to invoke the corresponding service. The results of the invocation are transferred \nback to the client with SOAP messages through the network. Finally, the client extracts the response data \nfrom the SOAP messages. In our experiment, in order to eliminate the network overhead, the client \nsoftware which is used to deploy legacy service is located in the same computer with service provider. The \noverheads involved in the three steps of the registration is measured by two fine granularity timers (Timer1 \nand Timer2) which reside in the source code of the client software and service provider. \n The major steps of test are labelled with the sequence number as defined in the following descriptions \n(See Fig.6). (1) Timer1 in the source code of client software is started when the client starts executing a \nfunction provided by the service provider. (2) When the service provider obtains the data from the SOAP \nmessages which are from client and begin to invoke the required service, the Timer2 stars to work. (3) \nWhen the service provider finishes the required operation and starts to wrap the information into SOAP \nmessages, the Timer2 stops working. (4) After extracting the data from the SOAP messages sent by the \nservice provider, the Timer1 is stopped. According to the above descriptions, it is easy to calculate the \noverheads of processing the SOAP messages at the client side and the service provider side as \n((4)-(1))-((3)-(2)). \n Table 2 shows the overall overheads and the corresponding SOAP overheads involved in the three \nsteps of the registration. Basically, the processing overhead of SOAP messages is a big portion of the \noverall overhead ranging from 64.7% to 99.9%. Table 2 also depicts that the overheads are decreased with \nthe increase in performance of different hardware platforms. The above tests demonstrate that the \nregistration is resource consumption. Fortunately, the overhead is transparent to the LAG users, and the \nregistration does not happen frequently. It may delay the registration process when the service is available, \nbut it is unlikely to interfere with the users. \n \n5.2 Evaluation of service query \n \nTable 3. Query overhead of a single request submitted to MDS \n Query time (ms) CPU utilization \nComputer1 1460 62% \nComputer2 1105 34% \nComputer3 821 8% \n \nThe query response time seen by the LAG users is an important metric in evaluating the performance of \nresource discovery of the LAG. The measured query time is the time between when a user submits a query \nrequest to the LAG through network and when the last byte of the response is delivered to the user. We \nemployed average query time to measure the performance.  \n We employed the three computers listed in Table 1 as MDS and used another computer to investigate \nthe query overhead, respectively. Table 3 shows the query overhead of a single request to the MDS. The \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 12 \nfirst column illustrates the query time with different computers. The second column depicts the CPU \nutilization of the three MDSs when they are processing the query request. The trend is that the query time \nseen by the user and the CPU utilization of MDS is decreased with the improvement of the hardware \nplatform of computers. According to Table 3, we believe that to a great extent, the query time is determined \nby the processing power of MDS. The reason is that the large processing overhead of the query request is \ncaused by the SOAP messages sent by the users. \n0\n20\n40\n60\n80\n100\n10 50 100 500 1000\nNumber of users\nR\ne\nsp\no\nn\nse\n T\nim\ne\n (\nse\nc\no\nn\nd\ns)\n \n0%\n20%\n40%\n60%\n80%\n100%\n10 50 100 500 1000\nNumber of users\nU\nti\nli\nz\na\nti\no\nn\nCPU utilization Network utilization\n \n         Fig.7 Average query time                       Fig.8 CPU and network utilization \n \n The LAG is designed to support hundreds of thousands of users. However, if hundreds of thousands \nquery requests go to a particular MDS simultaneously, the MDS could become a potential system \nbottleneck. The I\/O traffic travelling network and LAG is also a big concern. Therefore, it is important to \ninvestigate how many simultaneous query requests a MDS can support, and the corresponding network \noverhead involved in the query process. We used computer3 which has the highest performance as the \nMDS and other computers as client machines. In the experiment, each client machine can simulate many \ndifferent users with different connections to the MDS.  \n Fig.7 illustrates that the average query time of 10, 50, 100, 500, and 1000 users are 1.5, 5.2, 9.8, 39.8, \nand 86.5 seconds, respectively. The query time here is the time between when the first user submits a query \nrequest and when the last user receives the query result. Fig.8 depicts the CPU utilization of the MDS and \nthe network utilization when 10, 50, 100, 500, and 1000 users simultaneously send query requests to the \nMDS, respectively. It shows that 10, 50, 100, 500, and 1000 simultaneous query users incur 41%, 61%, \n79%, 82%, 85% CPU utilization of the MDS. The 85% CPU utilization of MDS results in a significant \nperformance penalty, i.e., 86.5 seconds of query time. Fig.7 also illustrates that the network is not a \nperformance bottleneck. Even when 1000 users send query requests to the MDS simultaneously, the \nnetwork utilization is about 3%. The reason is that the query requests are all small messages. The above \ntests illustrate that the potential performance bottleneck of LAG is the processing power of MDS.  \n Nielsen [37] presented that 10 seconds is the limit for users to keep their attention on the task. \nAnything slower than 10 seconds needs a percent-done indicator as well as a clearly signposted way for the \nuser to interrupt the operation. Delays of longer than 10 seconds are only acceptable during natural breaks \nin the user\u2019s work, for example when switching tasks. Therefore, the 86.5 seconds of query time is \nunacceptable when the MDS serves 1000 users. A solution to tackle the potential performance bottleneck is \ndistributing the query requests across multiple MDSs (see Fig.1). Therefore, the query traffic taken over by \neach MDS will be decreased with the increase in number of MDS. \n \n5.3 Evaluation of service access \nThe objective of LAG is achieving transparent access to the legacy data by leveraging a grid \nenvironment. Therefore, it is very important to measure the performance between starting an application \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 13 \nlocally and in the LAG environment. The launch time of an application which is employed to access the \ncorresponding legacy data is a very important metric to measure the performance of LAG. Local launch \ntime denotes the time spent starting an application locally in the service provider. Remote launch time \nmeasures the time between when a user submits a request to a service provider to launch an application and \nwhen the application is successfully displayed on the screen of the client machine. Local launch time is \nmeasured as a baseline performance. Remote launch time is the performance of the LAG.  \n \n1\n10\n100\n1000\n10000\n100000\nXclock Firefox Gimp OpenOffice\nApplications\nR\nes\np\no\nn\nse\n T\nim\ne \n(m\ns)\nLocal launch Remote launch\n \nFig.9 local and remote launch time of different applications \n \nIn our experiment, we employed the computer3 as a service provider and the computer2 as a client \nmachine. Four different applications were launched from the service provider locally and remotely. The \nthree applications including Firefox, Gimp, and Openoffice are normally adopted to access three typical \ndata format, i.e., web pages, pictures, and documents. The Xclock which is a simple application (timer) is \nemployed to evaluate the overhead of very light applications involved in the LAG. Fig.9 shows the local \nand remote launch time of the four different applications, where the Y axis is in logarithmic scale. As \nexpected, launching applications in the LAG environment is longer than launching them locally. Compared \nwith the local launch time, the remote launch times of the four different applications are increased 2610%, \n103%, 83.2%, and 21.2%, respectively. The leftmost bar of Fig.9 illustrates that the performance of Xclock \nis degraded significantly. The reason is that the local launch time of Xclock is too small, which makes the \nnetwork transfer time become relatively big (e.g. The network transfer time of Xclock takes 96% of the \nremote launch time.). It is very interesting to observe that the performance degradation of heavy \napplications is alleviated. It is because that the network overhead is relatively small compared with the \nlarge local launch time (e.g. The Openoffice spends only 17.5% of the remote launch time on network \ntransfer).   \n The legacy service introduces a fixed amount of overhead on each instance. The less data being \ntransferred, the higher this overhead is relative to the data transfer portion of the legacy application. The \ntest results demonstrate that it is more interesting to deploy heavy applications than light applications with \nthe legacy service since the involved overhead is relatively too high for light applications \n \n6. Discussions and Conclusions \n \nThe legacy data is growing explosively due to the rapid development of software and hardware. The \nlegacy data and legacy program is normally one to one correspondence, which indicates that a specific data \nformat can only be accessed by the corresponding program. In contrast to the traditional approaches, this \npaper proposed and designed a LAG architecture which can deploy diverse legacy applications in it. By \nemploying the legacy applications deployed in LAG, the LAG users can access the legacy data like local \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 14 \naccess. A salient feature is that a display protocol is wrapped as a legacy service which could enable service \nproviders to deploy any applications on heterogeneous platforms and operating systems. This approach \navoid converting the legacy data from one format to another format or wrapping the legacy application in \ngrid service one by one, because it is not cost-effective. Furthermore, the LAG is a win-win design, because \nsome out of data computers can be used to host some old legacy applications which can be adopted by \nusers to access the corresponding legacy data. \n A prototype was constructed and evaluated. The experimental results demonstrate that it is feasible to \nbuild such a LAG architecture in terms of the required network bandwidth and processing power. The main \ngoal of LAG is to make the software functionality available to all people who need it and who are \nauthorized to use it at anytime and anywhere. Please note that the LAG is a generally architecture, the \ncurrent applications can also be deployed in LAG besides the legacy applications. By taking advantage of \nthe LAG, the LAG users do not have to pay a full licence for a specific software package if they just need to \nuse the software to access or process some data temporarily. \nService composition can significantly accelerate rapid application development, service reuse, and \ncomplex service consummation. Multiple atomic services can also be automatically combined together as a \ncomposite service in terms of requirements. If the legacy service is designed as an atomic service, the \nintegration of legacy applications would not be a problem. This will be explored in our future work.  \n \nAcknowledgements \nWe would like to thank the anonymous reviewers whose insightful and constructive comments have \nsignificantly enhanced this paper. Thanks also to Adrian Ciura who constructed the initial platform used in \nthis work. In addition, we are grateful to Prof. Peter Sloot for giving us the opportunity to clarify our \nthoughts. \n \n \n7. References \n \n[1] The Expanding Digital Universe: A Forecast of Worldwide Information Growth Through 2010. IDC \nwhite paper\u2014Sponsored by EMC. March, 2007. \nhttp:\/\/www.emc.com\/about\/destination\/digital_universe\/. \n[2] A. P. Sheth, V. Kashyap, T. Lima, Semantic Information Brokering: How Can a Multi-agent Approach \nHelp? in: Proceedings of the Third International Workshop on Cooperative Information Agents III, \n1999, pp.303-322. \n[3] Y. Deng, F. Wang, Opportunities and challenges of storage grid enabled by grid service, ACM \nSIGOPS Operating Systems Review 41(4) (2007), pp.79-82. \n[4] Warning of data ticking time bomb. July, 2007.  http:\/\/news.bbc.co.uk\/1\/hi\/technology\/6265976.stm. \n[5] Word works with open file styles. February, 2007, http:\/\/news.bbc.co.uk\/1\/hi\/technology\/6323575.stm. \n[6] Extensible Markup Language. http:\/\/www.w3.org\/XML\/.  \n[7] B. Chidlovskii, J.Fuselier, Supervised learning for the legacy document conversion, in: Proceedings of \nthe 2004 ACM symposium on Document engineering, 2004, pp.220-228.   \n[8] E. Kuikka, P. Leinonen, and M. Penttonen, Towards automating of document structure transformations, \nin: Proceedings of ACM Symposium on Document Engineering, 2002, pp. 103\u2013110. \n[9] J.Bisbal, D.Lawless, B.Wu, J.Grimson, Legacy information systems: issues and directions, IEEE \nSoftware 16 (5) (1999), pp.103\u2013111. \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 15 \n[10] N. F. Schneidewind, How to evaluate legacy system maintenance? IEEE Software 12 (1) (1998), \npp.34\u201342. \n[11] Y. Bi, M.E.C. Hull, P.N.Nicholl, An XML approach for legacy code reuse, Journal of Systems and \nSoftware 61(2) (2002), pp.77-89. \n[12] P. Thiran, J. Hainaut, G. Houben, D. Benslimane, Wrapper-based evolution of legacy information \nsystems, ACM Transactions on Software Engineering and Methodology 15(4) (2006), pp.329-359. \n[13] I.Foster, C. Kesselman, S. Tuecke, The anatomy of the Grid: enabling scalable virtual organizations, \nInternational Journal of High Performance Computing Applications 15(3) (2001), pp.200-222. \n[14] Y. Deng, F. Wang. A heterogeneous storage grid enabled by grid service. ACM SIGOPS Operating \nSystems Review. Special Issue: File and Storage Systems 41(1) (2007), pp.7-13.  \n[15] Y. Deng, F. Wang, N. Helian, S. Wu, C. Liao, Dynamic and scalable storage management architecture \nfor Grid Oriented Storage devices, Parallel Computing 34(1) (2008), pp.17-31. \n[16] Y. Deng, F. Wang, A. Ciura, Ant colony optimization inspired resource discovery in P2P Grid systems, \nJournal of Supercomputing 49(1) (2009), pp.4-21. \n[17] P. Kacsuk, A. Goyeneche, T.Delaitre, T. Kiss, Z. Farkas, T. Boczko, High-level grid application \nenvironment to use legacy codes as OGSA grid services, in: Proceedings of the Fifth IEEE\/ACM \nInternational Workshop on Grid Computing (2004), pp.428-435. \n[18] Y. Huang, I.Taylor, D.W.Walker, R.Davies, Wrapping legacy codes for grid-based applications, in: \nProceedings of International Parallel and Distributed Processing Symposium, 2003. \n[19] T. Bodhuin, M. Tortorella, Using grid technologies for web-enabling legacy systems, in: Proceedings \nof the Eleventh Annual International Workshop on Software Technology and Engineering Practice, \n2003, pp.186-195. \n[20] T. Delaitre, A. Goyeneche, P. Kacsuk, T. Kiss, G.Z.Terstyanszky and S.C. Winter, GEMLCA: grid \nexecution management for legacy code architecture design, in: Proceedings of the 30th Euromicro \nConference (EUROMICRO04), 2004. pp. 477-483. \n[21] S. Plantikow, K. Peter, M. H\u00f6gqvist, C. Grimme, A. Papaspyrou, Generalizing the data management of \nthree community grids, Future Generation Computer Systems 25 (3) (2009), pp.281-289. \n[22] B. Bali, M. Bubaka, M. Wegiel, LGF: A flexible framework for exposing legacy codes as services, \nFuture Generation Computer Systems 24 (7) (2008), pp.711-719. \n[23] A. S. McGough, W. Lee, S. Das, A standards based approach to enabling legacy applications on the \nGrid, Future Generation Computer Systems 24(7) (2008), pp.731-743. \n[24] I. Foster, Globus toolkit version 4: software for service-oriented systems, IFIP International \nConference on Network and Parallel Computing, Springer-Verlag LNCS 3779, 2006,pp.2-13.  \n[25] Monitoring and Discovery System, http:\/\/www.globus.org\/toolkit\/mds\/.  \n[26] T. Richardson, Q. Stafford-Fraser, K. R. Wood, A. Hopper, Virtual network computing. IEEE Internet \nComputing 2 (1) (1998), pp.33-38. \n[27] R. W. Scheifler\uff0cJ. Gettys, The x window system, ACM Transactions on Graphics 5(2) (1986), \npp.79-109. \n[28] X Window System. http:\/\/www.x.org\/wiki\/ \n[29] V. Welch. Globus Toolkit version 4 grid security infrastructure: a standards perspective. 2004. \nhttp:\/\/www.globus.org\/toolkit\/docs\/4.0\/security\/GT4-GSIOverview.Pdf. \n[30] D. Kuebler, W. Eibach, Adapting legacy applications as Web services, 2002. \nhttp:\/\/www.ibm.com\/developerworks\/library\/ws-legacy\/?n-ws-1312 \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n 16 \n[31] M. Feller, I. Foster, S. Martin. GT4 GRAM: a functionality and performance study, in: Proceedings of \nthe 2007 TeraGrid Conference, 2007. \n[32] WS-Addressing, http:\/\/msdn2.microsoft.com\/enus\/library\/ms951225.aspx. \n[33] Web Services Description Language. http:\/\/www.w3.org\/TR\/wsdl. \n[34] Simple Object Access Protocol. http:\/\/www.w3.org\/TR\/soap\/. \n[35] M. Tian, T. Voigt, T. Naumowicz, H. Ritter, J. Schiller, performance considerations for mobile web \nservices, Computer Communications 27(11) (2004), pp.1097-1105. \n[36] A. Mani, A. Nagarajan, Understanding Quality of Service for Web services, January, 2002. \nhttp:\/\/www-106.ibm.com\/developerworks\/library\/ws-quality.html. \n[37] J. Nielsen, Usability engineering, Morgan Kaufmann, San Francisco, 1993. \n \n \n \n \n \n \nDr. Yuhui Deng is a professor at the computer science department of Jinan University. Before joined Jinan \nUniversity, he worked at EMC Corporation as a senior research scientist from 2008 to 2009. He worked as \na research officer at Cranfield University in United Kingdom from 2005 to 2008. He received his Ph.D. \ndegree in computer architecture from Huazhong University of Science and Technology in 2004. He has \nauthored and co-authored two book chapters, more than 20 refereed academic papers. He is on the editorial \nboard of International Journal of Grid and High Performance Computing and a book titled Grid \nTechnologies and Utility Computing: Concepts for Managing Large-Scale Applications. He has served as \ncommittee members for several professional conferences in the field. He is also a reviewer of several \nacademic journals. His research interests cover green computing, data storage, computer architecture, Grid \nComputing, performance evaluation, etc. \n \n \n \n \nProf. Frank Wang is the director of Centre for Grid Computing, Cambridge-Cranfield High Performance \nComputing Facility (CCHPCF), Cranfield University. He is Chair in e-Science and Grid Computing. He is \non the editorial board of IEEE Distributed Systems Online, International Journal of Grid and Utility \nComputing, International Journal of High Performance Computing and Networking, and International \nJournal on Multiagent and Grid Systems. He is on the High End Computing Panel for the Science \nFoundation Ireland (SFI). He is the Chair (UK & Republic of Ireland Chapter) of the IEEE Computer \nSociety. \n \n \nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\nDr. Yuhui Deng is a professor at the computer science department of Jinan University. Before joined \nJinan University, he worked at EMC Corporation as a senior research scientist from 2008 to 2009. He \nworked as a research officer at Cranfield University in United Kingdom from 2005 to 2008. He received \nhis Ph.D. degree in computer architecture from Huazhong University of Science and Technology in \n2004. He has authored and co-authored two book chapters, more than 20 refereed academic papers. \nHe is on the editorial board of International Journal of Grid and High Performance Computing and a \nbook titled Grid Technologies and Utility Computing: Concepts for Managing Large-Scale Applications. \nHe has served as committee members for several professional conferences in the field. He is also a \nreviewer of several academic journals. His research interests cover green computing, data storage, \ncomputer architecture, Grid Computing, performance evaluation, etc. \n \n \n \nProf. Frank Wang is the director of Centre for Grid Computing, Cambridge-Cranfield High Performance \nComputing Facility (CCHPCF), Cranfield University. He is Chair in e-Science and Grid Computing. He is \non the editorial board of IEEE Distributed Systems Online, International Journal of Grid and Utility \nComputing, International Journal of High Performance Computing and Networking, and International \nJournal on Multiagent and Grid Systems. He is on the High End Computing Panel for the Science \nFoundation Ireland (SFI). He is the Chair (UK & Republic of Ireland Chapter) of the IEEE Computer \nSociety. \n*Biographies (Text)\nAC\nC\nEP\nTE\nD\nM\nAN\nU\nSC\nR\nIP\nT\nACCEPTED MANUSCRIPT\n \nYuhui Deng \n \n \n \n \n \n \n \n \n \n \nFrank Wang \n*Biographies (Photograph)\n"}
{"doi":"10.1109\/TCE.2006.1649687","coreId":"102585","oai":"oai:epubs.surrey.ac.uk:2073","identifiers":["oai:epubs.surrey.ac.uk:2073","10.1109\/TCE.2006.1649687"],"title":"Mesh-based video coding for low bit-rate communications","authors":["Kocharoen, P","Ahmed, KM","Rajatheva, RMAP","Fernando, WAC"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2006-05-01","abstract":null,"downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:2073<\/identifier><datestamp>\n      2017-10-31T14:04:09Z<\/datestamp><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/2073\/<\/dc:relation><dc:title>\n        Mesh-based video coding for low bit-rate communications<\/dc:title><dc:creator>\n        Kocharoen, P<\/dc:creator><dc:creator>\n        Ahmed, KM<\/dc:creator><dc:creator>\n        Rajatheva, RMAP<\/dc:creator><dc:creator>\n        Fernando, WAC<\/dc:creator><dc:publisher>\n        IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC<\/dc:publisher><dc:date>\n        2006-05-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/2073\/1\/SRF002633.pdf<\/dc:identifier><dc:identifier>\n          Kocharoen, P, Ahmed, KM, Rajatheva, RMAP and Fernando, WAC  (2006) Mesh-based video coding for low bit-rate communications   IEEE TRANSACTIONS ON CONSUMER ELECTRONICS, 52 (2).  pp. 611-620.      <\/dc:identifier><dc:relation>\n        http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1649687<\/dc:relation><dc:relation>\n        10.1109\/TCE.2006.1649687<\/dc:relation><dc:language>\n        English<\/dc:language><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/2073\/","http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=1649687","10.1109\/TCE.2006.1649687"],"year":2006,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"P. Kocharoen et al.:  Mesh-Based Video Coding For Low Bit-rate Communications \nContributed Paper \nManuscript received February 21, 2006                                     0098 3063\/06\/$20.00 \u00a9 2006 IEEE \n611\nMesh-Based Video Coding For Low Bit-rate Communications \nP. Kocharoen, Student Member, IEEE, K. M. Ahmed, R.M.A.P. Rajatheva,  \nand W.A.C. Fernando, Member, IEEE \n \nAbstract \u2014 In this paper, a new method for low bit-rate \ncontent-adaptive mesh-based video coding is proposed.  Intra-\nframe coding of this method employs feature map extraction \nfor node distribution at specific threshold levels to achieve \nhigher density placement of initial nodes for regions that \ncontain high frequency features and conversely sparse \nplacement of initial nodes for smooth regions.  Insignificant \nnodes are largely removed using a subsequent node \nelimination scheme.  The Hilbert scan is then applied before \nquantization and entropy coding to reduce amount of \ntransmitted information.  For moving images, both node \nposition and color parameters of only a subset of nodes may \nchange from frame to frame.  It is sufficient to transmit only \nthese changed parameters.  The proposed method is well-\nsuited for video coding at very low bit rates, as processing \nresults demonstrate that it provides good subjective and \nobjective image quality at a lower number of required bits1. \n \nIndex Terms \u2014 Video Coding, Mesh Generation, \nMultimedia Communications.  \nI. INTRODUCTION \nToday, there is an ever increasing demand for multimedia \nconsumer devices for mobile and home use.  Due to the rapid \nadvances in video products such as digital cameras, camcorders, \nstorage devices (DVDs) and the explosion of the internet, the \ndigital video \u201cfor every one\u201d is now becoming a reality.  Many \nconsumers want to have digital video where ever they go and \nwhere ever they are.  The main business motivation of \nbroadcasting and telecommunications organizations is to \nachieve the highest possible user-perceived added value to \nterminals with the lowest possible resources, particularly the \nbandwidth.  Therefore, video compression has become an \nimportant area of research and enabled a variety of consumer \napplications including video storage on DVD and video CD's, \ndigital video broadcast over cable, satellite and terrestrial digital \ntelevision and video conferencing and videophone.  \nOver the last ten years, mesh-based coding schemes have \nachieved excellent results in image coding [1]-[9].  Mesh-\nbased coding of image deals with dividing the image domain \ninto a total of M non-overlapping mesh elements and then \nusing a two-dimensional interpolation to reconstruct the \nintensity over each element.  Mesh generation is a significant \ncomponent of mesh-based coding.  Available methods such as \n[5] provide an accurate node placement mechanism to \n \n1P. Kocharoen, K. M. Ahmed and R.M.A.P. Rajatheva are with the \nTelecommunications Program, Asian Institute of Technology, Thailand.       \n(e-mail: preecha.kocharoen@ait.ac.th). \nW.A.C. Fernando is with the Department of Electronic and Computer \nEngineering, Brunel University, UK. (e-mail: anil.fernando@brunel.ac.uk). \nrepresent high quality reconstructed images, but the required \nnumber of nodes is still high.  If this number is reduced, the \nquality deteriorates rapidly with these techniques. \nFor moving images, the waveform-based coding reduces \nthe redundant information between inter-frames by using \nmotion estimation and compensation.  Many motion \nestimation techniques are introduced.  The commonly used \nmotion estimation technique in all standard video codecs is the \nblock matching algorithm (BMA) where an MxN pixels sized \nblock of the reference frame is searched in the current frame \nby minimizing the mean square error (MSE) over all positions \nwithin the search range [12].  Tekalp [1], [10] introduced a \nmesh-based motion model which is used the polygonal \npatches, triangles or quadrangles, for inter-frame coding \ninstead of block matching model.  Mesh-based modeling can \ndeform the polygon patches by the movements of the nodes \nfrom the current frame into the reference frame and the texture \ninside each patch is warped using the affine transform.  \nOn the other hand, a picture in the mesh-based interpolative \nimage coding is represented by a number of nodes with \nparameters of position and color [2]-[9].  The basic principle \nof mesh-based interpolative coding is different from the well-\nknown waveform-based coding techniques, i.e. DCT and \nwavelet transform which form the most image and video \ncoding standards [11].  For moving pictures, both node \nposition and color parameters of only a subset of nodes may \nchange from frame to frame.  Therefore the coder transmits \nonly these changes to the decoder.  At the receiver, the \nreceived node movement and color modification parameters \nare employed then the images can be reconstructed.  There are \nmany publications in mesh-based image coding, e.g. [2]-[9] \nbut only a few present the method of mesh-based inter-frame \nvideo coding.  Baum presents an optimization method for \ninter-frame coding which is called node tracking [2].  The \nnode tracking method optimizes the mesh structure of \nconsequent frames by adding, removing and insertion of \nnodes in the reference frame.  The node tracking method can \nbe used in the sequences with moderate object movement but \nif new objects occur or if there is any foreground change, this \nmethod could face difficulties. \nIn this paper, we propose a low bit-rate mesh-based video \ncoding method.  This method reduces the required number of \nnodes in intra-frame coding while maintaining image quality.  \nIn addition, the proposed inter-frame coding method is able to \ndeal with the occurrence of new objects and also with major \nforeground scene changes.  The paper is organized as follows.  \nThe proposed methods and the system are described in \nSection II, III.  Processing results of intra- and inter-frame are \npresented in Section IV. \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \nIEEE Transactions on Consumer Electronics, Vol. 52, No. 2, MAY 2006 612 \nII. INTRA-FRAME CODING \nWe use the same image function and notations as given in \n[6]. Let D denote the non-overlapping Delaunay triangles \ndivided into M elements Dm, m=1,2,3,\u2026,M over the image \narea. The represented image over each Dm is approximated by \ntwo-dimensional linear interpolation function T over Dm. The \nimage function over each Dm is defined as follows: \n ( ) ( )( )mnm xfxg D,T=  (1) \n \nwhere f(xn) is location and intensity of xn. \nxn are vertices n=1,2,3 of Dm.  \ngm(x) is the interpolated intensity value of the missing \npixels within the triangle Dm. \n \nThe reconstructed image is : \n \n( ) ( )\u2211\n=\n=\nM\nm\nm xgxf\n1\n\u02c6  (2) \n \nIn natural pictures, many areas show a flat color or smooth \ntexture known as a low-frequency feature [6].  The intensity \nof pixels in such areas is similar, and thus only a few sparsely \nplaced nodes are sufficient to construct the mesh elements in \nthese regions.  On the other hand, in areas containing such \nhigh-frequency features as object edges, a dense distribution \nof nodes is required.  The proposed method also applies a \nLaplacian filter [13] to extract a feature map from the image \nspace.  A novel node elimination technique [4] is then applied \nto remove the nodes without significantly affecting image \nquality. \nThe proposed method is described briefly as follows.  The \ninitial nodes are located from the crowded sampling points by \nintensity feature filtering method which is based on theoretical \nerror bound of a mesh representation [5].  Insignificant nodes \nare then removed using a node elimination technique, which is \ndescribed in detail in section II-B.  As a result of node \nelimination, the number of nodes is drastically reduced and \nthere remain only a few samples to be coded.  Next, Hilbert \nscan, node color quantization and Huffman encoding are \napplied to reduce the amount of transmitted information [14]. \nAfter which, all nodes are triangulated in order to be \nconnected by the meshes using a number of non-overlapping \ntriangles.  The reproduced image is constructed from the \ninterpolated intensity of the pixels within a triangle by a linear \ncombination of the three vertices of the triangle [15].  In order \nto achieve a unique triangular mesh without transmitting side \ninformation about the mesh topology, the Delaunay mesh is \nused [16], [17]. \nA. Image Intensity Feature-Map Extraction \nThe second derivative of the intensity distribution of pixels \nprovides a zero value in the middle of a double, bi-directional \npeak for either type of transition - light to dark or dark to \nlight.  These can be used to identify the position of the edge \n[13], [18].  The usual way of looking for intensity \ndiscontinuities is to run a special mask or window over the \nimage.  The Laplacian operator is a second-order derivative \nthat can also be used for detecting intensity changes.  This \noperator is defined as follows: \n \n2\n2\n2\n2\n2\ny\nf\nx\nff \u2202\n\u2202+\u2202\n\u2202=\u2207  (3) \n \nThe mask of the two-dimensional Laplacian operator at \neach pixel (i,j) is computed as follows: \n \n),1(),(),1(),( 212\n3\n2\n12 jifjifjifjifxx \u2212+\u2212+=\u2207 , \n\u23ad\u23ac\n\u23ab\n\u23a9\u23a8\n\u23a7\n\u2212\u2212++\u2212+\n\u2212++++=\u2207\n)1,1()1,1(\n)1,1()1,1(\n),( 41\n2\njifjif\njifjif\njifxy , (4) \n)1,(),()1,(),( 212\n3\n2\n12 \u2212+\u2212+=\u2207 jifjifjifjifyy . \n \nIn order to extract the intensity feature from the image, we \nadopted the Laplacian filter in [5], [13].  For some specific \nimage, such as a high contrast image or a bi-level intensity \nimage, a single threshold level may not give a satisfying \nresult.  The bi-level intensity image gives ambiguous \nsignificant nodes when the intensity feature filtering with a \nsingle threshold is applied.  This leads to ineffective node \nremoval in the node elimination procedure.  The method could \nremove incorrect nodes and resulting in low quality \nreconstructed image.  Therefore, a more complex threshold is \nintroduced where the intensity feature-map ( )ii yx ,\u03b2\u03a6 can be \nexpressed as: \n \n( ) 02\n2\nmax\n, \u03c4\n\u03b3\n\u03b1 >\u2207\n\u2207= \u03a6\n)I(\n)I(\nii\nii\nii ,yx\n,yx\nyx  (5) \n( ) ( ) 21 ,, \u03c4\u03c4 \u03b1\u03b2 <\u03a6<=\u03a6 iiii yxyx  (6) \n \nwhere \n\u2207   = the Laplacian operator, \nI(xi,yi) = the image intensity at (xi,yi), \n\u03b3   = the parameter for adjust the sensitivity of the  \nimage feature-map.  Normally, \u03b3 = 1, \n\u03c40,\u03c41,\u03c42 = the predefined threshold level, normally \n12\n3\n80 \u2212=\u03c4 , 12\n22\/2\n8\n8\n1 \u2212\n\u2212=\u03c4 ,\n12\n22\/2\n8\n8\n1 \u2212\n+=\u03c4 . \nB. Node Elimination Procedure \nNode elimination is the major component of adaptive mesh \ngeneration [4].  The concept of a node elimination procedure \nis simple and straightforward.  First, we calculate the mean \nsquare error (MSE) between the values of intensity within the \nconvex hull of the original image and the reconstructed image \nafter removal of a node.  If the MSE exceeds a predefined \nthreshold, the removed node is recovered; otherwise, the node \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \nP. Kocharoen et al.:  Mesh-Based Video Coding For Low Bit-rate Communications 613\nremains eliminated.  Every node, from first to last, is \nexamined. \nThe initial node locations XN are identified using the result \nof (6).  Let xi = (xi,yi) \u2208  XN  where the set of node points \nXN=[x1, x2,...,xn].  For any xi \u2208 XN, XN\\xi indicates removing \nnode xi from the total set of nodes XN.  After that the \nDelaunay triangles have to be \u2018locally\u2019 re-triangulated or \nupdated.  The node elimination procedure can be represented \nas follows: \n \n( ) NXX mm D,DNe-N ,1,2,;\\   ~~ 2 \u2026== < i\u03bc\u03b7ix  (7) \n \nwhere \nDelaunay triangles Dm=D(X), \nthe eliminated xi triangles = D(X\\xi), \n\u03bc = the pre-defined threshold level, \ne = number of removed nodes. \n \nThe reconstructed image can be represented using (1) as: \n \n( ) ( )( )mnxT D~,~ fxgm =  (8) \n \nThe difference between the reconstructed and the original \nimage is measured using the mean square error ( )( )mm D,D ~:MSE 2\u03b7 .  The measurement is formulated as: \n \n( ) ( )\nN\nXIx\\XI\nD,D X\ni\u2211 \u2208 \u2212= ix\n2\n2\n~\n)~( mm\u03b7  (9) \n \nwhere \n( )ix\\XI~  = the reconstructed image, \nI(X)   = the original image, \nN    = total number of pixel within the convex hull. \n \nThe peak signal to noise ratio (PSNR) can be calculated \nusing the result of (8): \n\u239f\u239f\u23a0\n\u239e\n\u239c\u239c\u239d\n\u239b \u2212=\n)~(\n12log 10PSNR\n2\n8\n10\nmm D,D\u03b7\n (10) \n \nIf either the number of existing nodes or the PSNR of the \nimage is not satisfied by the first removal pass, more loops are \nexecuted with an adjustable error threshold in order to reach \nthe desired number of nodes or the PSNR. \nC. Delaunay Triangulation \nDelaunay triangulation, D, exists and is unique for V, if V \nis a set of vertices (nodes) in a general position, i.e., no three \nnodes are on the same line and no extra node is on the circle \nwhich is constructed from the three vertices, for a two-\ndimensional set of nodes.  Delaunay triangulation D of V, was \nfirst introduced by Delaunay [19].  Any circle in the plane is \nsaid to be empty if it contains no extra vertex of V in its \ninterior (Vertices are permitted on the circle).  A triangle is \nsaid to be Delaunay if and only if its circumcircle is empty.  \nThe Delaunay mesh is used in order to achieve a unique \ntriangular mesh without transmitting side information about \nthe mesh topology [17]. \nD. Interpolation \nThe values for color intensity, which are within the triangle \nobtained by the three nodes, are reconstructed by interpolation \n[20].  Interpolation is one of the most important aspects of the \nmesh-based coding as it is used both in the node elimination \nprocedure and in the image reconstruction procedure. Let T(xi, \nyi) be an interpolated function and ns be the number of node \npoints where si = (pi, ci), i \u2208{1, 2, \u2026, ns}, with positions of \nnodes pi = (xi, yi) and nodes colors ci.  The color intensity \ninside the triangular region can be calculated by the equations \nintroduced in [2]. \nE. Hilbert Scanning \nHilbert curve scanning is used because the path scan order \nof this method starts from one local area to another local area \nuntil a two-dimensional space is filled up.  This has an \nadvantage if the neighboring nodes have similar positions and \nsimilar colors, as it can be performed effectively when \ndifferential coding is applied.  An example with a description \nof Hilbert scanning can be found in [21]. \nF. Quantization and Entropy Coding \nIt was demonstrated in [22], that the color quantization of \nnodes is less critical than the quantization of the node path \nscan order.  Small modifications in the node locations can \nhave a significant effect on the mesh structure and this results \nin a degradation of image quality.  Therefore, only the node \ncolors are quantized in order to increase the coding efficiency.  \nAfter quantization of the node colors, the differential encoding \nis applied followed by Huffman encoding in the final step to \ncompact the information before transmission. \nG. Computational Complexity \nIn this section, the computational complexity of the \nproposed node elimination procedure is analyzed. The \ncomputational complexity can be determined from several \nparts. The construction of the Delaunay triangle from initial \nnodes XN results in a complexity of O(XN log XN). Node \nelimination requires updating only the local triangles, thus \nonly local nodes xlocal are used for calculation where xlocal << \nXN. Then the complexity of local retriangulation is O(xlocal log \nxlocal) where O(xlocal log xlocal) << O(XN log XN). The nodes are \nexecuted from the first to the last node, hence the complexity \nbecomes XN O(xlocal log xlocal). \nAltogether, this shows that the asymptotic complexity is at \nmost: \n \nXN O(xlocal log xlocal)+O(XN log XN) = O(XN log XN) (11) \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \nIEEE Transactions on Consumer Electronics, Vol. 52, No. 2, MAY 2006 614 \nFinally, the node elimination loop is executed R times in \norder to reach the desired number of nodes or PSNR therefore \nthe asymptotic complexity becomes at most: \n \nR(O(XN log XN)) = O(XN log XN) (12) \n \nIII. INTER-FRAME CODING \nA. Inter-frame Mesh Generation \nTwo methods of the inter-frame mesh generation, brute \nforce and feature filtering method are described next.  Brute \nforce method is based on the node tracking method in [2] \nwhereas the feature filtering method is based on the adaptive \nmesh generation in [4]. \n1) Brute Force Method \nHere the node generation is carried out for inter-frames in \ntwo steps.  First, motion estimation determines a coarse \nmotion vector for each node of the reference frame, using a \nblock matching algorithm [12], [23].  A 15x15 pixel sized \nblock of the reference frame, with the node as the center, is \nsearched in the current frame by minimizing the mean square \nerror (MSE) over all positions within the search range.  \nApplying these motion vectors to the node positions of the \nprevious frame, the node generator creates an initial mesh.  \nStarting from this mesh, the final node positions are \ndetermined by an iterative node movement procedure.  The \nnodes are repeatedly moved by one pixel in any direction, at a \ntime, to find the optimum position.  The steps for these \nmethods are shown next. \na) Block Matching Motion Estimation (BMA) \nThe principle of the BMA is to apply a translational motion \nmodel to subblocks of the image.  For every block, the \nmatching measure is based on the Displaced Frame Difference \n(DFD) [24].  The DFD expresses the difference between the \nluminance of the image at current frame (t) and the luminance \nof the image at reference frame (t-dt).  The displacement \nvector in x and y direction are dx and dy respectively. \n \nDFD(x,y,dx,dy,t) = I(x+dx,y+dy,t-dt) - I(x,y,t) (13) \n \nwhere I(x+dx,y+dy,t-dt) and I(x,y,t) describe the reference \nand current image plane respectively. \nThe aim of the motion estimation is to determine the vector \nthat minimizes the DFD. The criteria that is used in this \ncontext to compute the value of the DFD over a precise region \nis called the mean square error ( )( )DFD:MSE 2\u03b7 .  Equation \n(8) can be used for calculation the MSE. \nThe implementation of block matching motion estimation to \nthe mesh-based video coding is described below: \ni. The image I(t-dt) is partitioned to a set of subblocks of \nsize (i by j) with nodes as the center of the subblocks. \nii. All subblocks in the current image I(t) are moved to all \npossible locations and MSE within the blocks is \ncalculated. \niii. The motion vectors corresponding to the positions \nwith the lowest MSE are obtained. \nb) Brute-force inter-frame mesh generation method \nThe procedure of brute-force inter-frame mesh generation \nmethod is described below: \ni. Determine a coarse motion vector of each node using a \n15x15 pixel sized block matching whose center is the \nposition of the node. \nii. Applying the motion vectors to the node positions of \nthe previous frame to generate initial nodes. \niii. Let \u03c1r= \u03c11, \u03c12,\u2026, \u03c1R where \u03c1r= iteration loop number \niv. For r=1,\u2026,R \n\u2022 Let xi =(xi, yi)\u2208 XN and xi,non-zero vector=(xi,yi)|non-zero \nvector nodes \u2208 XN where set of node points XN = [x1, \nx2,\u2026,xn]. \n\u2022 Move xi,non-zero vector by one pixel in any direction, at a \ntime. \n\u2022 Locally update triangle and check whether PSNR is \nequal a target PSNR. The condition is then satisfied \nand the procedure ends. \nThis method generates high correlation among new nodes \nand reference nodes and thus can achieve efficient entropy \ncoding in the following step.  On the other hand, the technique \nalso needs several node movement iterations, which causes the \nmethod to be slow. \n2) Feature Filtering Method \nFeature filtering method obtains new node locations for \ninter frames in three steps.  First, motion estimation \ndetermines coarse static nodes by using a block matching \nalgorithm.  Applying these results, i.e., motion vectors from \nthe block matching algorithm to the node positions of the \nprevious frame, initial coarse nodes of the current frame are \ncreated.  The new nodes which have no motion are then \nclassified to be static nodes.  Second, a triangular mesh and \nimage are constructed from new nodes and MSE of each local \ntriangle within the image is calculated.  The nodes of the \ntriangles which have MSE above the predefined threshold are \nthen removed from the static nodes list.  Then triangular mesh \nfrom the static nodes is constructed and the sampling points \nthat are located inside the static triangle areas are filtered out.  \nThe sampling points which are located outside the static \ntriangle are then defined to be dynamic nodes.  Finally, the \nnode elimination method [4] is applied to the dynamic nodes \nto remove the insignificant sampling points. \nFurthermore, this method locates new nodes from the \ncrowded sampling points by intensity feature filtering method \n[14] which is based on theoretical error bound of a mesh \nrepresentation [5].  Hence the unpredicted objects in the image \ncan be handled automatically.  The details of this procedure \nare given below. \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \nP. Kocharoen et al.:  Mesh-Based Video Coding For Low Bit-rate Communications 615\na) Static and Dynamic nodes Registration \nLet xi=(xi,yi) \u2208 XN where set of node points XN = [x1, x2,\u2026, \nxn] and motion vector mv=(dxi,dyi). In addition, D denotes \nnon-overlapping Delaunay triangles which are divided into M \nelements Dm, m=1,2,3,\u2026, M over image area. Two types of \nnodes registration are described next. \nStatic nodes registration: \nThe initial static nodes can be obtained using the following \nequation. \n( )\n0Nticn,init.sta\n, == mvmvixXX  (14) \n \nThe initial static nodes are used to construct the triangular \nmesh and an initial image.  The nodes within the triangles \nwhich have MSE above the predefined threshold are then \nremoved from the static nodes list. \n ( )\nS\u03bc\u03b7\n\u03b7\n>\n=\n)~(\n2\nNovern, 2)\n~(,\nmm ,\nmmi ,x DDDDX X  (15) \novern,ticn,init.stan,static X\\XX =  (16) \n \nwhere \n\u03bcs= the predefined threshold, normally \u03bcs=30 \n \nEquation (9) is used to calculate MSE of each local triangle \nwithin the image. \nDynamic nodes registration: \nEquation (6) is used to extract the feature map from the \nimage and to locate initial sampling points.  After that, \ntriangular mesh from the static nodes using (2) is constructed \nand the sampling points that are located inside the static \ntriangle areas are filtered out.  Then, the sampling points \nwhich are located outside the static triangle are defined to be \ndynamic nodes. \n \n( ) ( ) staticn,,  of area triangle,dynamicn, XX \u2209\u03a6\u03a6= iyixii yx \u03b2\u03b2  (17) \nb) Node Elimination \nThe node elimination method is finally applied to the \ndynamic nodes to remove the insignificant sampling points.  \n(Xn,dynamic\\xi) is described as removing node xi from the total \nset of nodes Xn,dynamic where the Delaunay triangles have to be \n\u2018locally\u2019 updated.  The node elimination procedure can be \nrepresented as follows. \n \n( ) ( ) d\u03bc\u03b7   ~dynamicn,e -  dynamicn 2\\ <= mm D,D, XX ix  (18) \n \nwhere \nDelaunay triangules Dm=D(Xn,dynamic), \nthe eliminated xi triangles = D(Xn,dynamic \\xi), \n\u03bcd = the pre-defined threshold level, normally \u03bcd = 30, \ni=1,2,..., max(Xn,dynamic), \ne = number of removed nodes. \nThis technique produces low correlation among new nodes \nand reference nodes and thus a higher number bits are \nrequired for entropy coding in the next step.  On the other \nhand, the unpredicted objects in the image can be handled by \nusing this method. \nB. Mesh Based Inter-Frame Coding \nBased on the results of the previous section, we introduce a \ntechnique that can benefit from the correlation of successive \nframes in the image sequences.  In mesh based video coding, \nthe difference of image frames is represented by the number \nof changed nodes with node position and color parameters.  \nOnly the changes in partial nodes from frame to frame are \ncoded in order to benefit from the interframe coding.  The \ncharacteristic of scene transition affects the method of coding \nthe interframe.  In low bit-rate video communication such as \nvideoconference or video on mobile phone, the scene is \nmostly on human face and shoulders with only some motion.  \nTherefore, the proposed method is limited to the scenes that \nhave modulated object movements located in the center of the \nscene.  We classify types of the limited condition scene \nchange into four categories which are: 1) High DFD motion, \n2) Low DFD motion, 3) Occurrence of new objects, and 4) \nMajor foreground change.  Different types of interframes are \ncoded by different techniques with respect to rate and \ndistortion. \n1) High DFD motion \nHigh DFD motion vector is coded by brute force method. \n2) Low DFD motion \nLow DFD motion vector is coded by modifying the brute \nforce method.  The block-matching algorithm is applied to all \nnodes in the reference frame in order to find the initial motion \nvectors.  After that an iterative node movement procedure is \napplied on the nodes which contain non-zero motion vector \nuntil the optimum node positions are determined. \n3) Occurrence of new objects \nOccurrence of new objects is handled by inserting extra \nnodes.  First, modified brute-force or brute-force method is \napplied.  Then, the image is reconstructed with some areas \ncontaining high error values.  These areas correspond to the \noccurrence of new objects.  Extra nodes are then inserted to \nhandle the new object areas. \n4) Major foreground change \nMajor foreground change is coded by using the intensity \nfeature filtering method.  The feature filtering method \nachieves new node locations for inter frames in three steps.  \nFirst, motion estimation determines coarse static nodes by \nusing a block-matching algorithm for generating the static \nnodes.  Second, the dynamic nodes located within the high \nMSE triangles are identified.  Finally, the node elimination \nmethod is applied to the dynamic nodes to remove the \ninsignificant nodes. \n \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \nIEEE Transactions on Consumer Electronics, Vol. 52, No. 2, MAY 2006 616 \nIV. RESULTS OF VIDEO PROCESSING \nA. Results of Intra-frame Mesh Generation \nFirst frame of many QCIF video sequences was used as test \nimages.  The mesh generation method was applied to the first \nframes of many standard test QCIF video sequences \u2013\u2018Akiyo\u2019, \n\u2018Carphone\u2019, \u2018Claire\u2019, \u2018Foreman\u2019, \u2018Grandma\u2019, \u2018Miss America\u2019, \n\u2018Mother and Daughter\u2019, \u2018Salesman\u2019, and \u2018Suzie\u2019.  These \nsequences are in format YUV 4:2:0 in which Y, U, and V are \nprocessed separately.  Most significant information is in the \nLuminance (Y) part thus the results focus only on this part.  \nThe first step in the proposed method is to create the image \nfeature maps, which are obtained from the first frame of each \nsequence.  The standard mask, which is used in this operation, \nwas implemented in (4).  Image feature map are extracted and \nthe initial nodes are placed by screening the feature map with \na specific threshold level (i.e. \u03c4 = 3).  Then the node \nelimination procedure is applied.  Using three-passes of node \nelimination with the reference MSE set to 30, the remaining \nnodes are obtained (see Table I).  These nodes are used to \nconstruct the image mesh structures.  An example of a mesh \nstructure is shown in Fig. 1(b).  A two-dimensional linear \ninterpolation is used to produce the reconstructed images.  An \nexample of the first frame of Akiyo reconstructed image is \nillustrated in Fig. 1(d) with PSNR=33.07dB. \n \nFig. 1.  The subjective results of the test image \n \nTABLE I \nTHE NUMERICAL RESULTS OF QCIF TEST IMAGES \nImage No. of nodes No. of bits PSNR(dB) \nAkiyo 1330 12624 33.07 \nCarphone 2065 18776 32.72 \nClaire   809   8224 34.96 \nForeman 2063 18792 32.64 \nGrandma 1711 15448 33.03 \nMiss America   552   5560 35.30 \nMother 1234 11848 33.44 \nSalesman 3104 26424 31.58 \nSuzie 1266 12048 33.03 \n \nB. Comparison with the results from other mesh generation \nmethods \nThe proposed method is compared with the results of three \nsub-optimum methods taken from [5] which are: 1) adaptive \nsampling by Yang's method; 2) adaptive sampling by Garcia's \nmethod; 3) a quadtree method.  In addition, it is also compared \nto a mesh optimization by Baum's method [2].  The \ncomparison is based on a 128x128 \u2018Peppers\u2019 standard test \nimage where the mesh generation methods are implemented \non a 2.8GHz Pentium-4 computer.  The numerical results are \nshown in Table II.  The Yang's method performs best among \nthe existing sub-optimum methods, which uses 4081 nodes to \nreconstruct the image with PSNR=28.94dB.  However, the \nresults as presented in Table II show that the proposed method \nis better than all existing sub-optimum schemes.  Even though \nthe numbers of nodes is half that of Yang's method, PSNR of \nthe proposed method is 31.70 dB, which is 2.76dB more than \nthe Yang's method.  In addition, as the PSNR values of the \nreconstructed images are approximately the same, the \nproposed method performs well even when it uses only 1302 \nnodes. \nTABLE II \nTHE NUMERICAL RESULTS COMPARISON WITH OTHER METHODS \nMethod PSNR(dB) No. of nodes Processing time (s) \nThe proposed  31.70 2005   78.29 \nmethod 28.45 1302 187.46 \nYang\u2019s 28.94 4081 < 1 \nGarcia\u2019s 26.88 4152 < 1 \nQuadtree 26.16 4037   10.50 \nOptimization 32.11 1302    4905 \n \nThe mesh optimization method in [2] performs well but the \nprocessing time is very long because each node is moved, \ndeleted and inserted in all directions in many iteration steps in \norder to obtain the optimum solution.  The number of \noperations in [2] at each node point can be found as follows: \nmove 8 times, add 8 times, and remove 1 times.  The total \nnumber of operations for a single iteration is 17 times with \naround 10 such loops required.  Therefore, the number of \noperations is at most 170N times, where N = total number of \nnodes. \nThe number of operations in our method at each node point \nis only removing 1 times and requiring 3 loops.  Thus, the \nnumber of operations is at most 3N times. \nThe proposed method reduces the processing steps from \n170N times to 3N times.  Thus the processing time is expected \nto be much less than that in [2].  Simulation results in table I \nshow that this method can reduce the processing time from \nmore than an hour to only 3 minutes.  On the other hand, the \nreconstructed image quality of the proposed method is worse \nthan the optimum method in [2], but it still performs the best \namong all sub-optimum methods as shown in Table II. \nThe results show that the proposed mesh generation method \noutperforms the existing sub-optimum methods.  It works well \nfor all kinds of natural images, i.e., textures, smooth \nbackground, sharp edges, and smooth\/sharp transitional \n  \n(a) 1st frame of \u2018Akiyo\u2019 (b) mesh structure \n  \n(c) no quantization (d) 5-bit quantization \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \nP. Kocharoen et al.:  Mesh-Based Video Coding For Low Bit-rate Communications 617\nregions.  The proposed scheme is suitable for videophone \napplications, e.g. \u2018Claire\u2019, \u2018Miss America\u2019, and \u2018Mother\u2019, \nwhose scenes contain the human face with a smooth \nbackground.  In these cases the reconstructed images require a \nsmall number of nodes while preserving good PSNR values.  \nHowever, for images which have finer details or a \ncomplicated background, the proposed scheme requires a \nhigher number of nodes for the reconstruction of the images, \ne.g., \u2018Baboon\u2019 and \u2018Barbara\u2019.  Therefore, the mesh-based \nimage coding is excellent for applications which have objects \nwith smooth background. \nC. Results of Intra-frame Coding \nA test of image compression was carried out for the first \nframe of many grayscale standard test QCIF video sequences.  \nSome of the test images have the property of a smooth \nbackground, e.g. \u2018Claire\u2019, \u2018Mother\u2019, \u2018Miss America\u2019, and \n\u2018Suzie\u2019.  The others have more complex information in the \nbackground, e.g., \u2018Akiyo\u2019, \u2018Carphone\u2019, \u2018Foreman\u2019, \n\u2018Grandma\u2019, and \u2018Salesman\u2019. \nThe first step of the proposed image compression method is \nto generate adaptive meshes which are obtained from the first \nframe of the test sequences.  The remaining node positions are \ndescribed in path scan order using Hilbert scan.  Node colors \nare quantized.  Then both node positions and colors are \ndifferentially encoded.  The information is then entropy \nencoded using the Huffman code.  The numerical results of \nencoding images are given in Table I.  The encoding is based \non 5-bit quantization so the quantized symbols are {0, \n1,...,31}.  In the image reconstruction, the received node \npositions and colors are used to produce the mesh structure.  \nThe image is then reconstructed from a two-dimensional \nlinear interpolation. \nD. The Effect of Node Eliminating Order \nNode elimination is a local procedure.  Once a node is \neliminated, the following examinations take the previous \nremovals into account.  Therefore, the order of examination \nmay affect the performance of the algorithm.  Three types of \nnode eliminating order; normal, reverse, and random, are \ntested.  The normal node eliminating order is processed start \nfrom the first to last node whereas the reverse node \nelimination order is processed from the last to first node.  In \naddition, a binary pseudonoise sequence (or maximum length \nsequence) [25] is used to generate the random node \neliminating order.  The results are plotted and shown in Fig. 2.  \nThe results show that the order of examinations affects the \nperformance of the algorithm and the sequential eliminating \norder, normal and reverse, performs better than the random \neliminating order. \n \n \n(a) Claire : number of nodes \n \n \n(b) Claire : PSNR (dB) \nFig. 2.  The effect of node eliminating order \nE. Comparison with Other Image Compression Schemes \nThe proposed method is compared here with DCT and \nWavelet compression scheme which are implemented by \nJPEG and JPEG2000 image compression standards \nrespectively.  The comparison is based on the first frame of \nthe grayscale \u2018Claire\u2019 standard test sequence and implemented \non a 2.8GHz Pentium-4 computer.  The \u2018nconvert\u2019 [26] and \n\u2018jasper\u2019 [27] software are used to convert the test images into \nJPEG and JPEG2000 format correspondingly.  The subjective \nresults are shown in Fig.3 and the numerical results are \npresented in Fig.4.  The subjective results show that the \nproposed method performs the best among the existing \nmethods, representing sharp edges without ringing and \nblocking artifacts.  The numerical results presented in Fig.4 \nshow that the proposed method is slightly worse than the \nWavelet schemes in terms of the higher number of bits used \nper picture.  However, both the visual quality and the object \nquality of the proposed method are much better than those of \nthe others without producing ringing and blocking artifacts. \n \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \nIEEE Transactions on Consumer Electronics, Vol. 52, No. 2, MAY 2006 618 \n  \n(a) a 176x144 \u2018Claire\u2019 \noriginal image \n(b) Mesh: 0.2923bpp, \nPSNR=33.8974dB \n  \n(c)JPEG: 0.2958bpp, \nPSNR=28.6485dB \n(d)JPEG2000: 0.2914bpp, \nPSNR=33.1224dB \nFig. 3.  The subjective results comparison of the test images with other \nmethods \n \n \nFig. 4.  The numerical results comparison with other image \ncompression standards \nF. Results of Inter-Frame Processing \nThis section implements a mesh based interframe coding \nmethod to compress video sequences.  Standard QCIF \nsequences \u2018Akiyo\u2019, \u2018Claire\u2019, \u2018Grandma\u2019, \u2018Miss America\u2019, and \n\u2018Mother\u2019 are used as test sequences.  The test sequences are \ncoded at 10 frames per second, i.e. each third frame of the \noriginal sequence is processed and only the Luminance parts \nare shown.  The interframe coder is run without rate control. \nThe initial task of the proposed method is to create a coarse \nmotion vector for each node of the reference frame, using a \nblock matching algorithm and to check the types of scene \ntransition.  A suitable method is selected for each type of the \nscene change with respect to rate and distortion.  Only the \nnode color is quantized before applying differential and \nHuffman coding, in order to increase the coding efficiency.  \nThe quantization is based on 5 bits so the quantized symbols \nare {0, 1,\u2026, 31}.  The proposed method compresses the node \nparameters which are locations, motion vectors and colors, \nwith differential and Huffman coding.  The merit factor is \nmeasured by their PSNR values, while the compression rate is \nkilo bits per second (kbps). \nThe sample frames of the \u2018Akiyo\u2019 and \u2018Claire\u2019 test \nsequence are displayed in Fig.5.  The numerical results of the \ntest sequences are shown in Table III.  From Table III, the \naverage PSNR of the \u2018Claire\u2019 reconstructed sequence is \n32.96dB.  It can be seen that, the number of average nodes \nchanged per frame for interframe coding is only 50.70 nodes, \nwhich is 6.22% of the number of the nodes in the intra frame. \n \n  \n(a) Original \u2018Akiyo\u2019 frame 60th  (b) Reconstructed at PSNR=31.67dB \n  \n(c) Original \u2018Claire\u2019 frame 27th  (b) Reconstructed at PSNR=32.94dB \nFig. 5.  The samples subjective results of the QCIF test sequences \n \nTABLE III \nTHE NUMERICAL RESULTS OF QCIF TEST SEQUENCES \nImage PSNR (dB) \nBit rate \n(kbps) \nTotal \nnodes \nMoved \nnodes \nAvg. bits \nper node \nAkiyo 31.52 7.61 1329 47.36 16.08 \nClaire 32.96 7.89   814 50.70 15.56 \nGrandma 31.50 5.49 1663 33.30 16.50 \nMiss Am. 32.43 9.63   565 65.52 14.70 \nMother 31.17 7.10 1221 44.33 16.01 \n \nG. Comparison to the Existing Low Bit-rate Video Coding \nStandard \nThis section compares the proposed method with the \nexisting low bit-rate video coding standard.  The color QCIF-\nsized of Claire sequence is used as a test sequence.  The test \nsequence is coded at 10 frames per second, i.e. Each third \nframe of the original sequence is processed.  The interframe \ncoders are run without rate control.  The PSNR of each frames \nare calculated by average all PSNR in R, G, and B color \nspace.  Figure 6 shows results of the comparison.  The average \nPSNR of the test sequence from frame 0 to 99 of mesh-based \ncoding, H.263 and H.264 are 32.20, 31.77 and 34.49 dB at \nbit-rate 6.29 kbps, 6.30 kbps, and 6.36 kbps respectively. \nFor the comparison results, the performance of the \nproposed mesh-based coding is better than the H.263 video \ncoding standard whereas it is worse than the H.264 video \ncoding standard by about 2 dB.  The Figure 7 shows the \nsample pictures of the test sequence encoded with Mesh-based \ncoding, H.263, and H.264 respectively.  Comparing the \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \nP. Kocharoen et al.:  Mesh-Based Video Coding For Low Bit-rate Communications 619\nobjective quality of the proposed mesh-based coding method \nwith the H.263 and H.264 standard, it is observed that the \nproposed mesh-based method provides sharp edges without \nringing and blocking artifacts whereas the H.263 provides \nboth ringing and blocking artifacts. \n \n \nFig. 6.  The comparison between the proposed method and the standard \nvideo coding of the Claire test sequences \n \n  \n(a) Mesh: frame 51st, \nPSNR=32.29dB \n(b) Mesh: frame 93rd, \nPSNR=31.65dB \n  \n(c) H.263: frame 51st, \nPSNR=31.89dB \n(d) H.263: frame 93rd, \nPSNR=31.59dB \n  \n(e) H.264: frame 51st, \nPSNR=34.18dB \n(f) H.264: frame 93rd, \nPSNR=33.69dB \nFig. 7.  The samples subjective results of the Claire test sequence \n \nV. CONCLUSIONS \nMesh based coding for image and video compression have \nbeen previously presented by many researchers, e.g. [1]-[9].  \nThe proposed node elimination method with a feature map \nextraction for intra-frame coding aims to improve the mesh \ngeneration efficiency which constitute: \n\u2022 Fast generating mesh structure. \n\u2022 Adaptive mesh structure on the video scene contents. \n\u2022 Constructing the triangular mesh with low number of \nnodes. \n \nThree techniques are presented to code difference scene \nchanges in inter-frame coding which are the brute-force, the \nmodified brute-force and the feature filtering method.  The \nbrute-force and the modified brute-force inter frame coding \nperforms well but the processing takes long time.  On the \nother hand, the feature filtering method can reduce the \nprocessing steps for constructing interframes.  It is also \ncapable to handling the new objects in the scene or a \nsignificant change in foreground.  However, the correlation \nbetween the reference nodes and the new nodes of the feature \nfiltering method is lower than the brute-force method which \nleads to inefficient entropy encoding.  Therefore, different \ntypes of interframes are coded by different techniques or they \ncan be combined with respect to rate and distortion. \nThe processing results show that in the scenes containing \nobjects with smooth background, the proposed method \nprovides a good subjective and objective image quality.  It \nalso provides objective image quality comparable to the DCT \nand wavelet schemes in intra-frame coding.  In addition, it \nprovides much better visual quality than the other methods \nwithout producing ringing and blocking artifacts.  However, \nin the images that have fine details or complicated \nbackground, the proposed method requires a higher number of \nnodes to reconstruct the images.  Therefore the wavelet \nscheme is better than the mesh-based coding in this aspect.  \nFor moving images, the results show that the proposed method \nis better than the H.263 low bit-rate video coding whereas it is \nworse than that H.264 standard.   The processing results show \nthat the proposed method is suitable for low bit-rate video \napplications.  For example, the results of the human face with \nsmooth background, i.e. Claire, Miss America, and Mother \npreserve good PSNR values while requiring a small amount of \nbits, less than 10kbps. \nThe major drawback of the proposed method is that it \nrequires iterations in the encoder side hence the increase in \ncoding time is significant.  Because of this reason, the \nproposed technique is not suitable for real-time applications.  \nHowever at the decoder side, the picture can be reconstructed \nsimply by constructing the mesh structure and interpolating \ntheir node colors.  This could be applied to mobile video \nbroadcasting for low-cost mobile handsets as the proposed \nmethod has a low computation complexity at the decoder \nwhich leads to low battery consumption.  \nREFERENCES \n[1] A.M. Tekalp, P. Van Beek, C. Toklu and G. Unsel, \u201cTwo-Dimensional \nMesh-Based Visual-Object Representation for Interactive \nSynthetic\/Natural Digital Video,\u201d Proceedings of the IEEE, Vol.86, \nNo.6, pp. 1029-1051, June 1998. \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \nIEEE Transactions on Consumer Electronics, Vol. 52, No. 2, MAY 2006 620 \n[2] E. Baum and J. Speidel, \u201cNovel Video Coding Scheme Using Adaptive \nMesh-Based Interpolation And Node Tracking,\u201d Proc. SPIE, Visual \nCommunications and Image Processing 2000, Vol. 4067, pp.200-208, \n2000. \n[3] C.L. Huang and C.Y. Hsu, \u201cA New Motion Compensation Method For \nImage Sequence Coding Using Hierarchical Grid Interpolation,\u201d IEEE \nTrans. Circuits Syst. Video Technol., Vol.4, No.1 pp.42-52, 1994. \n[4] P. Kocharoen, K. M. Ahmed, R.M.A.P. Rajatheva and W.A.C. \nFernando, \u201cAdaptive Mesh Generation For Mesh-Based Image Coding \nUsing Node Elimination Approach,\u201d The IEEE International Conference \non Communications, ICC05, Vol.3, Seoul, Korea, pp.2052-2056, 16-20 \nMay 2005. \n[5] Y. Yang, J.G. Brankov and M.N. Wernick, \u201cA Fast Approach for \nAccurate Content-Adaptive Mesh Generation,\u201d IEEE Trans. on Image \nprocessing, Vol.12, No.8, pp.866-881, August 2003. \n[6] Y. Yang, J.G. Brankov and M.N. Wernick, \u201cTomographic Image \nReconstruction Based on a Content-Adaptive Mesh Model,\u201d IEEE \nTrans. on Medical Imaging, Vol.23, No.2, pp.202-212, February 2004. \n[7] L. Demaret, N. Dyn, A. Iske and M. Floater, \u201cAdaptive Thinning with \nApplication to Terrain Modelling and Image Compression,\u201d Advances in \nMultiresolution for Geometric Modelling, N.A. Dodgson, M.S. Floater, \nand M.A. Sabin(eds.), Spinger-Verlag, Heidelberg, pp.321-340, 2004. \n[8] M.A. Garcia, B. Vintimilla and A. Sappa, \u201cEfficient Approximation of \nGray-Scale Images through Bounded Error Triangular Meshes,\u201d IEEE \nInt. Conf. on Image Processing, Kobe, Japan, pp.168-170, October 1999. \n[9] M.A. Garcia and B. Vintimilla, \u201cAcceleration of Filtering and \nEnhancement Operations Through Geometric Processing of Gray-Level \nImages,\u201d IEEE Int. Conf. on Image Processing, September 2000, \nVancouver, Canada, Vol.1, pp.97-100. \n[10] A. Altunbasak and A.M. Tekalp, \u201cOcclusion-Adaptive, Content-Based \nMesh Design and Forward Tracking,\u201d IEEE Transactions on Image \nProcessing, Vol. 6, No. 9, pp.1270-1280, September 1997. \n[11] H. Li, A. Lundmark and R. Forchheimer, \u201cImage Sequence Coding At \nVery Low Bitrates: A Review,\u201d IEEE Transactions on Image \nProcessing, Vol. 3, No. 5, pp. 589-609, September 1994. \n[12] M. Ghanbari, Video Coding: an Introduction to Standard Codecs, The \nInstitution of Electrical Engineers, London,pp.27-32, UK, 1999. \n[13] C.G. Rafael, E.W. Richard, Digital Image Processing, Addison-Wesley \nPublishing Company, New Jersey, pp.147-214, 1993. \n[14] P. Kocharoen, K. M. Ahmed, R.M.A.P. Rajatheva and W.A.C. \nFernando, \u201cIntensity Feature Filtering With Node Elimination Approach \nFor Low Bit-Rate Mesh-Based Image Coding,\u201d The IASTED \nInternational Conference on Networks and Communication Systems, \nNCS2005, Krabi, Thailand, pp. 161-166, 18-20 April 2005. \n[15] R.J. Renka, \u201cTriangulation and Interpolation at Arbitrarily Distributed \nPoints in the Plane,\u201d ACM Transactions on Mathematical \nSoftware(TOMS), Vol. 10, No. 4, pp. 440-442, Dec 1984. \n[16] A. Bowyer, \u201cComputing Dirichlet tessellations,\u201d The Computer Journal, \nVol.24, No.2, pp. 162-166, 1981. \n[17] S. Rebay, \u201cEfficient Unstructured Mesh Generation By Means Of \nDelaunay Triangulation And Bowyer-Watson Algorithm,\u201d Journal of \nComputational Physics, Vol.106, pp.125-138, 1993. \n[18] G.J. Awcock and R. Thomas, Applied Image Processing, McGraw-Hill, \nInc., pp.126-146, 1996. \n[19] J.O. Rourke, Computational Geometry in C, 2nd edition, Cambridge \nUniversity Press, pp.155-192, 1998. \n[20] I. Amidror, \u201cScattered Data Interpolation Methods for Electronic \nImaging Systems: A Survey,\u201d Journal of Electronic Imaging, Vol. 11 \nNo. 2, pp. 157-176, April 2002. \n[21] Z. Song and N. Roussopoulos, \u201cUsing Hilbert Curve In Image Storing \nAnd Retrieving,\u201d International Multimedia Conference Proceedings of \nthe 2000 ACM workshops on Multimedia, California, USA, pp. 167-170, \n2000. \n[22] P. Kocharoen, Internal project report, Telecommunication Program, \nAsian Institute of Technology, Jan. 2004, unpublished. \n[23] J.R. Jain and A.K. Jain, \u201cDisplacement Measurement and Its Application \nin Interframe Image Coding,\u201d IEEE Trans. Comm., Vol. COM-29, no. \n12, pp.1799-1808, December 1981. \n[24] C.S. Fuh and P. Maragos, \u201cAffine Models for Image Matching and \nMotion Detection,\u201d Proc. IEEE Int. Conf. on ASSP, Toronto, pp. 2409-\n2412, 14-17 May 1991. \n[25] W.W. Peterson and E.J. Weldon, Jr., Error-Correcting Codes, 2nd \nedition, Halliday Lithograph Corporation, tenth printing, pp.170-203, \n1990. \n[26] P.E. Gougelet, The XnView website. [Online]. \nAvailable: http:\/\/www.xnview.com \n[27] M.D. Adams, The JasPer Project Home Page, Department of Electrical \nand Computer Engineering, University of Victoria, [Online].  Available: \nhttp:\/\/www.ece.uvic.ca\/~mdadams\/jasper\/ \n \n \n \nPreecha Kocharoen received the Bachelor degree in \nElectrical Engineering from Sripatum University, \nThailand, in 1997, and Master degree in Communication \nEngineering from University of Manchester Institute of \nScience and Technology (UMIST), UK, in 1998.  Since \n1999 he has been with Sripatum University, Thailand. \nHis current position is Lecturer in Department of \nElectrical Engineering, Faculty of Engineering.  He is currently a doctoral \nstudent in the Telecommunications program School of Advanced \nTechnologies, Asian Institute of Technology (AIT).  His current research \ninterests include: digital image and video processing and intelligent video \nencoding.  \n \nDr. Kazi M. Ahmed is currently a Professor at Asian \nInstitute of Technology (AIT).  He received the M.Sc. \nEng. Degree in Electrical Engineering from Institute of \nCommunications, Leningrad, USSR; 1978.  He has \ncompleted his Ph.D. at the University of Newcastle, \nNSW, Australia; 1983.  His current research interests \ninclude: digital signal processing, antenna array \nprocessing, tropospheric and ionospheric propagation \nstudies for microwave, VHF-UHF communications, satellite communication \nand radar problems. \n \nDr. R.M.A.P. Rajatheva is with Telecommunications \nprogram School of Advanced Technologies, Asian \nInstitute of Technology (AIT) from Dec. 2004 as an \nAssosiate Professor.  He was with the University of \nMoratuwa, Sri Lanka  before joining AIT where he was \npromoted to Professor in Electronic & \nTelecommunication Engineering in June 2003.  He also \nhad been previously with TC-SAT from May 1996 to \nDec.2001, as an Associate Professor from January 2001.  He is a Senior \nMember of the IEEE.  Dr. Rajatheva graduated with the first class honors in \nB.Sc.(Eng.) from the University of Moratuwa in 1987 and obtained both \nM.Sc., Ph.D. from the University of Manitoba, Canada in 1991 and 1995 \nrespectively.  His research interests include: Mobile and Wireless \nCommunications, Coding and Modulation Techniques, Space Time \nProcessing for MIMO Systems and Communication Theory. \n \nDr. W.A.C. Fernando is currently a Lecturer in signal \nprocessing at the Brunel University, U.K.  Prior to that, \nhe was an Assistant Professor in AIT.  He received the \nB.Sc. Engineering degree (First class) in Electronic and \nTelecommunications Engineering from the University of \nMoratuwa in 1995 and the M.Eng. degree (Distinction) in \nTelecommunications from AIT in 1997.  He has \ncompleted his Ph.D. at the Department of Electrical and Electronic \nEngineering, University of Bristol, UK.  His current research includes: digital \nimage and video processing, stereo and multi-view video coding, rate \ncontrolling, OFDM and CDMA for wireless channels, combined source and \nchannel coding for video communications over wireless channels. \n \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 07,2010 at 10:43:22 UTC from IEEE Xplore.  Restrictions apply. \n"}
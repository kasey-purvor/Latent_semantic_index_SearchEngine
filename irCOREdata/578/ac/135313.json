{"doi":"10.1002\/ima.20053","coreId":"135313","oai":"oai:bradscholars.brad.ac.uk:10454\/2682","identifiers":["oai:bradscholars.brad.ac.uk:10454\/2682","10.1002\/ima.20053"],"title":"Automatic Detection and Verification of Solar Features","authors":["Qahwaji, Rami S.R.","Colak, Tufan"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2006","abstract":"YesA fast hybrid system for the automated detection and verification of active regions (plages) and filaments in solar images is presented in this paper. The system combines automated image processing with machine learning. The imaging part consists of five major stages. The solar disk is detected in the first stage, using a morphological hit-miss transform, watershed transform and Filling algorithm. An image-enhancement technique is introduced to remove the limb-darkening effect and intensity filtering is implemented followed by a modified region-growing technique to detect the regions of interest (RoI). The algorithms are tested on H- and CA II K3-line solar images that are obtained from Meudon Observatory, covering the period from July 2, 2001 till August 4, 2001. The detection algorithm is fast and it achieves false acceptance rate (FAR) error rate of 67% and false rejection rate (FRR) error rate of 3% for active regions, and FAR error rate of 19% and FRR error rate of 14% for filaments, when compared with the manually detected filaments in the synoptic maps. The detection performance is enhanced further using a neural network (NN), which is trained on statistical features extracted from the RoI and non-RoI. With the use of this combination the FAR has dropped to 2% for active regions and 4% for filaments.\u00a9 2006 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 15, 199-210, 200","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/135313.pdf","fullTextIdentifier":"https:\/\/bradscholars.brad.ac.uk\/bitstream\/10454\/2682\/1\/qahwaji_paper.pdf","pdfHashValue":"1eb5558ee6159bbd488474f7f9063167697c1785","publisher":null,"rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:bradscholars.brad.ac.uk:10454\/2682<\/identifier><datestamp>\n                2016-09-09T14:52:54Z<\/datestamp><setSpec>\n                com_10454_413<\/setSpec><setSpec>\n                col_10454_6345<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nAutomatic Detection and Verification of Solar Features<\/dc:title><dc:creator>\nQahwaji, Rami S.R.<\/dc:creator><dc:creator>\nColak, Tufan<\/dc:creator><dc:subject>\nImage processing; Solar imaging; Morphological transforms; Neural networks<\/dc:subject><dc:description>\nYes<\/dc:description><dc:description>\nA fast hybrid system for the automated detection and verification of active regions (plages) and filaments in solar images is presented in this paper. The system combines automated image processing with machine learning. The imaging part consists of five major stages. The solar disk is detected in the first stage, using a morphological hit-miss transform, watershed transform and Filling algorithm. An image-enhancement technique is introduced to remove the limb-darkening effect and intensity filtering is implemented followed by a modified region-growing technique to detect the regions of interest (RoI). The algorithms are tested on H- and CA II K3-line solar images that are obtained from Meudon Observatory, covering the period from July 2, 2001 till August 4, 2001. The detection algorithm is fast and it achieves false acceptance rate (FAR) error rate of 67% and false rejection rate (FRR) error rate of 3% for active regions, and FAR error rate of 19% and FRR error rate of 14% for filaments, when compared with the manually detected filaments in the synoptic maps. The detection performance is enhanced further using a neural network (NN), which is trained on statistical features extracted from the RoI and non-RoI. With the use of this combination the FAR has dropped to 2% for active regions and 4% for filaments.\u00a9 2006 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 15, 199-210, 2005<\/dc:description><dc:date>\n2009-05-20T16:07:47Z<\/dc:date><dc:date>\n2009-05-20T16:07:47Z<\/dc:date><dc:date>\n2006<\/dc:date><dc:type>\nArticle<\/dc:type><dc:type>\nAccepted Manuscript<\/dc:type><dc:identifier>\nQahwaji RSR and Colak T (2005) Automatic Detection and Verification of Solar Features. International Journal of Imaging Systems and Technology. 15(4):199-210.<\/dc:identifier><dc:identifier>\n90001377<\/dc:identifier><dc:identifier>\n90014848<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/10454\/2682<\/dc:identifier><dc:language>\nen<\/dc:language><dc:relation>\nhttp:\/\/dx.doi.org\/10.1002\/ima.20053<\/dc:relation>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":null,"language":null,"relations":["http:\/\/dx.doi.org\/10.1002\/ima.20053"],"year":2006,"topics":["Image processing; Solar imaging; Morphological transforms; Neural networks"],"subject":["Article","Accepted Manuscript"],"fullText":" The University of Bradford Institutional \nRepository \nhttp:\/\/bradscholars.brad.ac.uk \nThis work is made available online in accordance with publisher policies. Please refer to the \nrepository record for this item and our Policy Document available from the repository home \npage for further information. \nTo see the final version of this work please visit the publisher\u2019s website. Access to the \npublished online version may require a subscription. \nLink to original published version: http:\/\/dx.doi.org\/10.1002\/ima.20053 \nCitation: Qahwaji RSR and Colak T (2006) Automatic detection and verification of solar features. \nInternational Journal of Imaging Systems and Technology. 15(4): 199-210. \nCopyright statement: \u00a9 2006 Wiley Periodicals Inc. Full-text reproduced in accordance with the \npublisher\u2019s self-archiving policy. \n \nAutomatic Detection and Verification of Solar Features \nR. S. Qahwaji \nDepartment of Electronic Imaging and Media Communications, University of Bradford, Bradford BD7 1DP, UK. \nE-mail: r.s.r.qahwaji@brad.ac.uk Tel. +44(0) 1274 236078 \nT. Colak \nDepartment of Electronic Imaging and Media Communications, University of Bradford, Bradford BD7 1DP, UK. \nE-mail: t.colak@brad.ac.uk Tel. +44(0) 1274 235749 \nAbstract \nA fast hybrid system for the automated detection and verification of active regions (plages) and filaments in solar images is \npresented in this paper. The system combines automated image processing with machine learning. The imaging part consists of \nfive major stages. The solar disk is detected in the first stage using a morphological hit-miss transform, watershed transform and \nFilling algorithm. An image enhancement technique is introduced to remove the limb darkening effect and intensity filtering is \nimplemented followed by a modified region growing technique to detect the regions of interest (RoI). The algorithms are tested on \nH-alpha and CA II K3 line solar images that are obtained from Meudon observatory, covering the period from 2nd July 2001 till 4th \nAugust 2001. The detection algorithm is fast and it achieves FAR error rate of 67% and FRR error rate of 3% for active regions, \nand FAR error rate of 19% and FRR error rate of 14% for filaments, when compared with the manually detected filaments in the \nsynoptic maps. The detection performance is enhanced further using a neural network (NN) which is trained on statistical features \nextracted from the RoI and non-RoI. Using this combination the FAR has dropped to 2% for active regions, and 4% for filaments. \nKeywords: Image Processing; Solar Imaging; Morphological Transforms; Neural Networks. \n1 Introduction \nObservatories and satellites provide continuous automated monitoring of the sun. In general, the solar images are subject to various \ndistortions caused by the conditions of observations and instrumentation errors. These distortions must be corrected, in order to \nallow automated image processing [Zharkova et al, 2002]. In addition, regions located near the limb are viewed obliquely and may \ncontain incomplete features. The substantial information about different solar features contained in these images cannot be fully \nprocessed manually and require tools developed for the automated recognition of the features of interests.  \nSolar filaments are one of the features whose detection is very important for understanding solar activity. Evolution and \ndisappearance of filaments are highly associated with Coronal Mass Ejections (CME) [Webb 2000, Gopalswamy 2003] which can \nexcite geomagnetic storms that cause electrical power outages and damages to satellites. On the solar disk filaments look like a \ndark elongated features on brighter background and can have a lifetime from one to three solar rotations. Although their \nheliocentric location and their shape do not change grossly there are still visible changes seen in their elongation, position with \nrespect to an active region and magnetic field configuration. Active regions are regions on the solar disk with a very strong \nmagnetic field that is able to confine high temperature gas. Flares are very large explosive events that could occur when the \nmagnetic flux tubes of the active regions are moved around interacting with each other [Harra et al, 2003] \nThe key to space weather prediction is the accurate detection and monitoring of the evolution of solar features affecting space \nweather (i.e., Flares, Coronal Mass Ejections (CMEs), etc.). Detecting filaments and active regions can be a precursor for flares or \nCMEs, which are very energetic phenomena and can cause severe problems for space industry; earth based electromagnetic \ncommunications and power systems, radio transmission, space industry and so on. The accurate detection of active regions can \nprovide more insight into the formation, support and disruptions of flares and CMEs [Benkhalil et al, 2003].  \nThere have been previous attempts to apply imaging algorithms to detect solar features. In Gao et al. (2002), local thresholding and \nregion-growing methods were used to detect filament disappearances. In Benkhalil et al. (2003), active regions were detected based \non region growing. Filaments were detected in H-alpha images in Shih et al. (2003) using morphological closing operations with \nmulti-directional linear structuring elements to extract elongated shapes. The Singular Spectrum Analysis of signals was used to \ndetect active regions on solar disk, in Lefebvre et al. (2004). In addition, Neural Networks were used in Zharkova et al. (2003) for \nfilament recognition in solar images and in Borda et al. (2002) for flare detection. Qu et al. (2003) experimented and compared \nMulti-Layer Perceptron (MLP), Radial Basis Function (RBF), and Support Vector Machine (SVM) classifiers for solar flare \ndetection on the solar H-alpha images obtained from the Big Bear Solar Observatory (BBSO). The algorithm introduced here is \nfast compared to other algorithms and is capable of detecting more than one type of solar features. \nIn this paper, the aim is to provide robust, fast and accurate automated detection for solar features. In addition, we aim to simplify \nthe detection process, so that the same algorithm can be applied for the detection of different features, with very minimal changes. \nThe detection algorithm is coupled with machine learning to increase the accuracy of detection. \nThis paper is organised as follows: Section 2 provides information about solar images used in this paper (H-alpha and Calcium II \nK). The detection of the solar region using the Filling algorithm is described in Section 3. Section 4 is devoted to the limb \ndarkening removal. The initial detection of RoI using the intensity filtering and the modified region growing algorithm is provided \nin section 5. The practical implementation is reported in Section 6 and the verification stage is given in Section 7. Finally, the \nconcluding remarks are provided in Section 8. \n2 H-alpha and Calcium II K-line Images \nH-alpha images (Fig. 1) are captured by observing light from a particular line in the hydrogen spectrum at 6563 \u00c5 (red light) \n[NASA, 2005]. The core of the line is formed between 1200 and 1800 km above the visible surface. The presence of interacting \nmagnetic fields in the chromosphere generates an enormous amount of heat. The heated regions are represented by brighter pixels \nin the captured H-alpha images. H-alpha images also show many dark filamentary structures on the solar disk, which correspond to \nmagnetic loops reaching up into the solar corona. These features tend to be cooler than the surrounding corona and permit H-alpha \nabsorption to take place, hence their dark appearance [Poppe, 2005].  \nFull disk images of the Sun at the H-alpha wavelength have been made from the ground since 1926 and have become an integral \npart of the space weather forecasting effort. In this paper, H-alpha images were obtained from Meudon observatory-France \n(http:\/\/bass2000.obspm.fr). In addition, H-alpha images can be captured using satellites, which would achieve near 100% temporal \ncoverage [Eparvier, 2001]. H-alpha images can be used for examining solar active regions, chromospheric features like filaments \nsunspots, and flares. \nThe Calcium II K-line images are important for solar feature analysis. Singly ionized calcium atoms in the solar chromosphere and \nupper photosphere form the Calcium II K-line, which is a very broad absorption line at 3933 angstroms (violet light) [UoM, 2005]. \nThe K3 feature, which is the central minimum, is formed at about 2000 km above the visible surface. The two maxima on either \nside of the K3 minimum are referred to as the K2 peaks and they are formed at height from about 600 to 1500 km above the visible \nsurface. The K1 minima, just outside of the K2 peaks, are formed at about 500 km above the visible surface. In these images (Fig. \n1.b), the brighter regions correspond to regions of strong magnetic field [NSO, 2005]. Dark sunspots and filaments are also visible \nin these images [UoM, 2005]. \n3 The detection of the solar region \nThe solar disk is detected using a combination of morphological features. The Filling algorithm [Qahwaji et al, 2001] is designed \nto detect closed shape objects in digital images. It is based on the morphological hit-miss transform (HMT) [Sonka et al, 1999], \nused for the edge detection and noise removal, and the morphological watershed transform (WST) used for image analysis. In this \nwork, the Filling algorithm is used to detect the largest closed shape object in the image, which is the solar disk. Detecting the solar \ndisk is important because it eliminates textual and non-solar information that are contained in the image. \nThe Filling algorithm was designed to distinguish between the background region that lies outside the object and the region that \nlies within the object. The algorithm depends on understanding the behaviour of HMT edges and WST lines inside closed and open \nshape objects.  Closed regions have WST lines that divide them into two parts or more. Every WST pixel is surrounded by two \nhorizontal edge pixels, one pixel from the right and one from the left. In addition, the WST lines in closed regions, starts from an \nedge pixel and ends in an edge pixel [Qahwaji et al, 2001]. These findings can be examined in Fig. 2, where WST is applied to the \nHMT image of a solar image. \nThese characteristics are represented in terms of a detection algorithm that starts by finding all the horizontal edges that have WST \nlines emerging from them. Every WST line that is vertically continuous and ends in another horizontal edge is highlighted, as it \nmay exist inside an object. The Filling algorithm provides valuable information about the shape, size and location of all objects in \nthe image. This information is used to isolate the regions of interest (RoIs). The longest highlighted WST line corresponds to the \nedges of the solar disk, which is the largest object in these images. The detailed implementation of the algorithm is shown in Fig. 3. \nFor more details on the implementation, the reader can refer to Qahwaji et al.  (2001). \n4 Limb darkening removal  \nAfter the solar disk is detected, limb darkening removal followed by intensity filtering is applied to the H-alpha images in order to \ndetect the candidate pixels for the filaments. Limb darkening removal is important because the limb darkening effect causes the \nsolar background to become darker, which increases the detection of filaments detection. However, this is not a problem for the \ndetection of active regions. Hence, the intensity filtering stage is applied for CA II K3 images without limb darkening removal.  \nMost solar images suffer from limb darkening which is the gradual decrease in brightness of the disk of the Sun as observed from \nits centre to its edge, or limb. This phenomenon is readily apparent in photographs of the Sun. Limb darkening occurs because the \nsolar atmosphere increases in temperature with depth. At the centre of the solar disk, an observer sees the deepest and warmest \nlayers that emit the most light. At the limb, only the upper, cooler layers that produce less light can be seen [Encyclop\u00e6dia \nBritannica, 2005]. Equation (1) is introduced in Allen (1976) and is used in this paper to remove the limb darkening effect. The \nSolar limb darkening function is: \n0\n2\n( , )\n( , )\n1-[u (1-cos )]-[v (1- cos )]\nPixel x y\nPixel x y\n\uf071 \uf071\n\uf03d\n\uf0e9 \uf0f9\uf0b4 \uf0b4\uf0eb \uf0fb\n  (1) \nWhere \u03b8 represents the angle between Sun\u2019s radius vector and the line of sight through the centre of the disk and u and v are \nconstants calculated by using the observation wavelength, in a manner similar to Freeland (2004). Pixel0 (x,y) is the initial grey \nscale value of the processed pixel and Pixel (x,y) is the new grey scale value for the same pixel.  \nIn order to find the angle \u03b8, the centre of the solar disk and its radius (R) must be determined. The centre of the solar disk can be \ndetermined easily using the centre of mass (centroid) method [Baxes, 1994]. The radius (R) is determined by finding the horizontal \nand vertical distances towards north, south, west and east separating the centre from the solar limb. The average of these distances \nis taken to be the radius. The average of the four distances is considered because the shape of the solar disk is not always exactly \ncircular.  Angle \u03b8 is calculated using Equation (2), which depends on distance D and the radius of the solar disk R, where D is the \nshortest distance between the centroid and the processed pixel. \n = arcsin( \/ )D R\uf071  (2) \nAfterwards, the new grey-scale value is calculated for the processed pixel using Equation (1). The contrast enhanced difference \nbetween the original and the enhanced image is shown in Fig. 4 to illustrate the effect of removing the limb darkening effect.  \n5 Initial detection of regions of interest \nAfter removing the limb darkening, intensity filtering is applied in order to detect the seeds (candidate pixels) for the desired solar \nfeatures.  \n5.1 Seed Selection Using Intensity Filtering \nThe filaments are darker in colour, which enables an intensity filter with a low threshold to indicate their positions and to eliminate \nthe background and active regions. For the brighter coloured active regions an intensity filter with a high threshold value is used to \nindicate their positions. The grey scale value of every pixel in the enhanced image is compared against a detection threshold and \nreplaced by a white pixel only if its initial value is smaller than the intensity threshold for filaments and larger than the intensity \nthreshold for active regions. The filtering stage provides two images; the first contains the seeds for active regions while the second \ncontains the seeds for filaments. In Fig. 5, intensity filtering results for a single H-alpha and CA II K3 images are shown. In this \npaper H-alpha images are used for the detection of filaments while CA II K3 images are used for the detection of active regions.  \nThe threshold value for each image is found automatically using Equation (3), where, \uf06d is the mean, \uf073  represents the standard \ndeviation, and \uf061 is a constant that is determined based on the type of the features to be detected. \nThreshold = ( (1 ) )\n\uf073\n\uf06d \uf061 \uf073\n\uf06d\n\uf0b1 \uf02b \uf02d \uf0b4  (3) \nFor filaments, constant \uf061 is calculated using Equation (4) and (-) sign is used in Equation (3). \n8\nf\n\uf06d\n\uf061 \uf03d  (4) \nFor active regions, constant \uf061 is calculated using Equation (5) and (+) sign is used in Equation (3). \n255\n5\na\n\uf06d\n\uf061\n\uf02d\n\uf03d  (5) \nEquations (4) and (5) are found empirically by taking into account the variance of greyscale values of the solar features in different \ntypes of solar images. It is worth mentioning that a thresholding technique is introduced in Gao et al. (2002). For this work, this \ntechnique has failed to give good candidates especially for the images that suffer from distortions. The formula introduced in this \npaper is more complicated but provides better performance. The strength of Equation (3) is that it can be applied to both active \nregions and filaments just by changing the constant.  In the next stages, a region-growing algorithm is modified and compared with \nthat in Benkhalil et al. (2003) and Gao et al. (2002) and  is followed by a group detection algorithm that is applied to detect the \nsolar features.  \n5.2 Modified Region Growing Algorithm \nThe modified region growing technique is applied in order to detect pixels that are regions of interest but have not been detected by \nintensity filtering. Region growing was applied for the detection of solar regions in Gao et al. (2002) and Benkhalil et al. (2003). \nOur technique combines the region growing techniques suggested by Gao et al. (2002) and Benkhalil et al. (2003). It is applied to \nbinary images that result from the intensity filtering stage, where the seeds are simply the white pixels. It is a combination of two \nmajor stages: First the adjacent seeds are combined and second unwanted seeds are eliminated. This algorithm provides further \nfiltering for the unwanted seeds that were detected during the intensity filtering. The intensity filtering detects the seeds after \ncomparing them with a threshold. It does not take into account other seeds (pixels) that were not detected but belong to RoI. The \nmodified region growing is applied to overcome this problem.  \n5.2.1 Pseudo-Code of the Modified Region Growing Algorithm \n1. The percentage of the number of seeds to the total number of pixels in the image is found. The variable size windows and \nthe threshold value are based on the percentage, and are determined by the value of X, which is found empirically, as shown in \nTable I.  After X is found, the size of the corresponding window and thresholds are calculated. Window (1) is equal to (2X+1) \u00d7 \n(2X+1), window (2) is equal to (2X+7) \u00d7 (2X+7) and the threshold value is equal to X2\/2. \n2. The area around the seed is scanned for other white pixels. If another white pixel is found in this area, it is connected to \nthe central seed with a straight line as shown in Fig. 6. The details of this procedure are as follows:  \na.  In order to connect seeds, a window (Table I \u2013Column (III)) is centred on each seed and the search for other marked \npixels within this window is carried out. A simple first-degree polynomial is created to connect the seed to the marked pixel \nusing a false colour. The equation (y=ax+b) is used to find the coordinates of the connecting seeds, with a being the slope of \nthe straight line and b being the y-intercept. \nb. This process continues for all of the seeds. The newly marked false coloured pixels are not taken into account. \n3. For all the seeds, the resulting image is processed again with a larger window. This time, another window (Table I \u2013 \nColumn (IV)) is centred on the seed and all other pixels (false coloured or not) within this window are counted. If the total number \nof the pixels inside this area is smaller than the corresponding threshold value (Table I \u2013 Column (V)), then the seed in the centre \nof the window is deleted otherwise all the pixels within the window are marked. This process continues for all the seeds.  \n5.3 Selection of the Regions of Interest  \nThis stage aims to detect the locations of the desired features after the application of the modified region-growing algorithm. The \nalgorithm starts by detecting the adjacent seeds in each row, as shown in Fig. 7. The row number, the starting column and the \nending column are recorded for these pixels. Afterwards, all the vertically adjacent rows are detected and considered as one group \n(whole feature).  \n5.3.1 Pseudo-Code for the detection of groups  \n1. The adjacent seeds in each row are recorded using their row number, the starting column and the ending column number. \n2. Each recorded row is highlighted and given index 0 in the beginning of this stage. \n3. Before processing each recorded row, if its index is 0 it is given a number starting from 1, which is increased every time this row \nis processed.  \n4. All the pixels of the processed row are compared with pixels of other rows to find whether they are vertically adjacent or not. If \nthe rows are vertically adjacent, then the index number of the detected row is examined. \n\uf0b7 If its index number is 0, then it is replaced with the index number of the main row. \n\uf0b7 If its index number is nonzero, then this indicates that this row was processed before. Hence, its number is assigned to the \nmain row and to all the rows that have the same index number as the main row. \n5. The 3rd and 4th steps are repeated until all the rows are recursively checked. \n6. After all the rows are processed; the rows are checked for their final index numbers. All rows that share the same index number \nare assumed to be vertically adjacent, and are treated as groups that represent a feature.  \n7. The locations of the pixels belonging to the detected groups are found and stored in multiple size arrays. The generated arrays \ncontain the detected solar features.  \nThe detection algorithm presented here can be used to process CA II K3 and H-alpha images to provide the exact positions for \nactive regions and filaments. It can be used to detect other solar features (such as sunspots) just by modifying the intensity filtering \nstage to produce the candidates for this new feature. Examples of the complete implementation of the detection algorithm are \nshown in Fig. 8 and Fig. 9.  \n6 The evaluation of performance  \nThe detection algorithm was implemented on solar images obtained from the Meudon observatory-France (Fig. 10 and Fig. 11). \nThese images and a manually constructed synoptic map that contains the locations of solar RoI for any given day can  be obtained \nfrom http:\/\/bass2000.obspm.fr. These synoptic maps were obtained using the subjective analysis of a solar observer. Subjective \nanalysis depends mainly of the experience of the human operator, but it is also affected by fatigue and other human-related factors. \nOn the other hand, the objective analysis of solar images, which is carried out by the automated detection system, provides \nconsistent performance but its accuracy is usually lower. The detection algorithm finds both solar filaments and active regions in a \n1024 \u00d7 1024 image in less than three seconds using P4-2.4 G Hz PC with 512 Mbyte RAM. In order to evaluate the detection \nperformance, the following two error rates are introduced [Hong et al, 1997]:  \n\uf0b7 The false acceptance rate (FAR), which is the probability of a non-RoI being detected as a RoI.  \n\uf0b7 The false rejection rate (FRR), which is the probability of a RoI not being detected because it is considered to be a non-RoI. \nThe H-alpha and CA II K3 images available (depending on observing conditions) for the period from 2nd July 2001 till 4th August \n2001 were used to evaluate the detection performances for filaments and active regions respectively. The FAR and FRR error \nparameters are established by comparing the detected RoI, which are generated using the current detection algorithms, with those \ndetected manually and recorded in the synoptic maps.  \nThe results for the detection of active regions are shown in Table II. The first column shows the date for every CA II K3 Line \nimage, while the total number of active regions that are manually detected is indicated in Column II. The FAR and FRR error rates \nare shown in Columns III and IV, respectively. The FAR error rate represents the percentage of the detected regions that do not \ncontain real active regions. On the other hand, the FRR error rate is the percentage of the active regions that are not detected in the \nresulting image. The average FAR error rate for all the images of Table II is found to be 67% while the average FRR error rate is \n3%.   \nThe results for the detection of filaments are shown in Table III. The first column shows the date of every H-alpha image, while the \ntotal number of filaments that are manually detected is indicated in Column II. The FAR and FRR error rates are shown in \nColumns III and IV, respectively. The average FAR error rate for all the images of Table III is found to be 19% while the average \nFRR error rate is 26%.   \nApplying the detection algorithm for the detection of filaments and active regions has resulted in high FAR, which is caused \nmainly by the threshold of the intensity filtering stage. However, choosing lower thresholds for filaments and higher thresholds for \nactive regions will reduce the FAR but will increase the FRR. To overcome this, machine learning is used to reduce the FAR error \nrate. Hence, a new stage called the verification stage is added.  \n7 Verification of solar features using Neural Networks \nA verification stage is implemented to enhance the accuracy of the detection. The verification is carried out using a Neural \nNetwork (NN) with back propagation training algorithm. The NN training vector is constructed by extracting statistical features \ncharacterising RoI and non-RoI. The extracted statistical features are: Mean, standard deviation, range of grey-scale intensities, \nratio of dark regions, ratio of bright regions, skew and kurtosis. Calculating the mean and standard deviation is a straight forward \nprocess, while other features can be calculated as follow: \n\uf0b7 Skewness, which is a data distribution measurement that shows distortion in a positive or negative direction and can be \ncalculated using Equation (8): \n\uf05b \uf05d\n3\n0\n3\nX(n) - \nN\nnSkew\nN\n\uf06d\n\uf073\n\uf03d\uf03d\n\uf0e5\n (8) \n\uf0b7 Kurtosis, which is a measure of the peakedness (broad or narrow) of a distribution and can be calculated using Equation (9): \n\uf05b \uf05d\n4\n0\n4\nX(n) - \n3\nN\nnKurtosis\nN\n\uf06d\n\uf073\n\uf03d\uf03d \uf02d\n\uf0e5\n     (9) \n\uf0b7 Ratio of the bright regions, which is the ratio of the total number of pixels above a defined threshold value divided by the total \nnumber of pixels. The threshold value is equal to the +25% of the calculated mean. \n\uf0b7 Ratio of the dark regions, which is the ratio of the total number of pixels below a defined threshold value divided by the total \nnumber of pixels. The threshold is equal to -25% of the calculated mean. \n\uf0b7 Range of grey scale intensities, which is the difference between the maximum grey-scale value and the minimum grey-scale \nvalue, divided (normalized) by 255.  \nThe features for the RoI are extracted from the detected regions after being verified manually with the synoptic maps. The features \nfor the non-RoI are extracted manually and they represent the background regions that contain no RoI (i.e., no filaments or active \nregions) (Fig. 12). Several experiments are carried out and it was found empirically that the best learning performance is obtained \nusing the following NN topology: 7 input nodes, one hidden layer with 9 nodes and two output nodes. The output nodes indicate \nwhether the detected region is a RoI or not.  \nThe training of the NN is considered to be successful when the NN manages to converge to the normalized system error, which is \n0.001. Feature extraction is applied to every region that is detected by the detection algorithm. The seven statistical features are \ncalculated and fed to the NN to determine whether the detected region represents a RoI or not. This approach is implemented on \nthe entire test data and it is found that the average FAR for the detection of active regions has dropped from 67% to 2% and the \naverage FRR has increased to 15% as shown in Table II column V and VI. The average FAR for the detection of filaments has \ndropped from 19% to 4% and the average FRR has increased to 36% as shown in Table III column V and VI.  The increases in \nFRRs are not desired but acceptable when compared with the great reduction in FARs. These rates can be improved by further \ntraining of NN. \n8 Conclusions \nIn this paper, a fast algorithm for the detection of active regions in CA II K3 Line images and filaments in H-alpha images is \npresented. The detection process consists of five major stages: the detection of the solar region, limb darkening removal, initial \ndetection of regions of interest using intensity filtering, modified region growing and selection of solar features.   \nThe algorithms are tested on solar images that are obtained from the Meudon observatory, covering the period from 2nd July 2001 \ntill 4th August 2001. The detection algorithm is fast and it achieves a FAR error rate of 67% and a FRR error rate of 3%, when \ncompared with the manually detected active regions in the corresponding synoptic maps. In the same manner, applying the \ndetection algorithm on H-alpha images for the same period achieves a FAR error rate of 19% and a FRR error rate of 14%, when \ncompared with the manually detected filaments in the synoptic maps. \nThe FAR is very high for both cases and a verification stage is added to the current detection technique, to increase the accuracy of \nthe detection process. A Neural Network (NN) is trained on statistical features extracted from the active regions and non-active \nregions. Using this combination the FAR has dropped to 2%. Another NN is trained on statistical features extracted from filament \nregions and non-filament regions. Using this combination the FAR has dropped to 4%. \nThe system introduced in this paper can detect various solar features simultaneously. It takes less than three seconds to detect all \nthe solar features in a 1024 \u00d7 1024 image using P4-2.4 G Hz PC with 512 Mbyte RAM. All the imaging stages are shared for the \nfilaments and active regions, except the limb darkening removal. This portability makes the algorithms quite useful and fast for the \ndetection of various types of solar features in different solar images. \nIn the Future, we would like to modify the existing algorithm to accept different types of solar images (e.g. SOHO MDI \nMagnetograms and White light images), to detect sunspots and to track solar features over consecutive days. We believe that \nmodifying the detection algorithm to process various types of solar images and comparing the characteristics of the detected and \ntracked features with recent and historical data can be an important tool for the prediction of space weather activities (i.e., flares \nand CMEs). These suggestions are supported by the findings in previous research. In Zhou et al. (2003), it was found that 88% of \nhalo CMEs were associated with flares and more than 94% were associated with eruptive prominences\/filaments, while 79% of the \nCMEs were initiated from active regions. This study was conducted on SOHO\/LASCO images taken between 1997 and 2001. \nMore recently, Jing et al. (2004) performed a statistical study of 106 filament eruptions taken from BBSO from 1999 to 2003 and \ntheir relations to flares and CMEs. It was found that 56% of the filament eruptions were associated with CMEs and active region \nfilament eruptions have a higher flare association.  \n  \n References \n \nC.W. Allen, Astrophysical quantities, 3rd edition, Athlone Press, London, England, 1976. \nG. A. Baxes, Digital image processing: principles and applications, John Wiley & Sons, Inc., New York, USA, 1994. \nA. Benkhalil, V. Zharkova, S. Ipson, and S. Zharkov, automatic identification of active regions (plages) in the full-disk solar \nimages using local thresholding and region growing techniques\", Proc AISB'03 Symposium on Biologically-inspired Machine \nVision, Theory and Application, 2003, pp. 66-73.  \nR. F. Borda, P. Mininni, C. Mandrini, D. G\u00f3mez, O. Bauer, and M. Rovira, automatic solar flare detection using neural network \ntechniques, Solar Physics 206 (2002), 347 \u2013 357. \nEncyclop\u00e6dia Britannica, limb darkening, http:\/\/www.britannica.com\/eb\/article?tocId=9048283, last accessed: 2005.   \nF. G. Eparvier, solar imaging needs for the space environment monitor on the Geostationary Operational Environmental Satellites \n(GOES R+), report of the GOES R Solar Imager Workshop, Laboratory for Atmospheric & Space Physics, University of Colorado, \nU.S.A., 2001. \nS. L. Freeland, SolarSoft, http:\/\/sohowww.nascom.nasa.gov\/solarsoft\/, last accessed: 2004. \nJ. Gao, H. Wang, and M. Zhou, development of an automatic filament disappearance detection system, Solar Physics 205 (2002), \n93 \u2013 103. \nN. Gopalswamy, M. Shimojo, W. Lu, S. Yashiro, K. Shibasaki and R.A. Howard, prominence eruptions and coronal mass ejection: \na statistical study using microwave observations, Astrophysical Journal 586(1)(2003), 562-578. \n  \nL. Harra, S. Matthews, and L. van Driel-Gesztelyi, evidence of flaring in a transequatorial loop on the Sun, The Astrophysical \nJournal 598 (2003), L59-L62. \nL. Hong and A.  Jain, integrating faces and fingerprints for personal identification, IEEE Transactions on Pattern Analysis and \nMachine Intelligence 20(12) (1997), 1295-1307. \nJ. Jing, V. B. Yurchyshyn, G. Yang, Y. Xu, and H. M. Wang, on the relation between filament eruptions, flares, and coronal mass \nejections, Astrophysical Journal, 614(2)(2004), 1054-1062 \nS. Lefebvre, and J. P. Rozelot, a new method to detect active features at the solar limb,  \nSolar Physics 219 (2004), 25-37. \nNASA, how do we observe the Sun, http:\/\/soho.nascom.nasa.gov\/explore\/Sun_Obs.html, SOHO, last accessed: 2005. \nNational Solar Observatory Sacramento Peak (NSO), Ca K and H-alpha solar images, \nhttp:\/\/www.sunspot.noao.edu\/sunspot\/images\/cak_ha.html, last accessed: 2005.  \nB. Poppe, a primer on space weather, http:\/\/gopher.sel.noaa.gov\/primer\/primer.html, last accessed: 2005. \nR. Qahwaji and R. Green, detection of closed-shape objects, Journal of Information 4 (2001), 429-434. \nR. Qahwaji, detecting edges in noisy face database images, International Journal of Computers and Their Applications 10 (3) \n(2003), 185-197. \nM. Qu, F. Y. Shih, J. Jing, H. M. Wang, automatic solar flare detection using MLP, RBF, and SVM, Solar Physics 217 (2003), \n157-172. \n \nF. Y. Shih, and A. J. Kowalski, automatic extraction of filaments in H-alpha Solar images, Solar Physics 218 (2003), 99 \u2013 122. \nUniversity of Michigan (UoM), windows to the universe, just above the Sun's visible surface - Ca II K, \nhttp:\/\/www.windows.ucar.edu\/spaceweather\/suntoday3.html, University Corporation for Atmospheric Research, last accessed: \n2005. \nM. Sonka, V. Hlavac and R. Boyle, Image processing analysis and machine vision, s.e., PWS Publishing, London, England, 1999. \n \nD. F. Webb, coronal mass ejections: origins, evolution, and role in space weather, IEEE Transactions on Plasma Science 28(6) \n(2000), pp.1795-1806 \nV. Zharkova, S. Ipson, S. Zharkov,A. Benkhalil  and J. Aboudarham, full disk image standardisation of the synoptic solar \nobservations at the Meudon Observatory, Solar Variability: From the Core to Outer Frontiers, Proc 10th European Solar Physics \nMeeting, 2002, sp. 506.  \nV. Zharkova and V.Schetinin, a neural network technique for recognition of filaments in solar images, Proc KES\u201903 the seventh  \nInternational Conference on Knowledge-Based Intelligent Information and Engineering Systems, 2003, pp. 148-154. \nG. P. Zhou, J. X. Wang, and Z. L. Cao, correlation between halo coronal mass ejections and solar surface activity, Astronomy & \nAstrophysics, 397(3)(2003), 1057-1067. \n \n \n \n  \n \n \n \nTable I: The window sizes and threshold values used for the modified Region Growing. \n% X Window (1) Window (2) Threshold \n<1 5 11x11 17x17 32 \n<3 6 9x9 15x15 25 \n=>3 7 7x7 13x13 18 \n \nTable II: The false acceptance rate (FAR) and the false rejection rate (FRR) values for selected solar images, representing active \nregion detection (D) and verification (V) processes. \nDate Active R. FAR(D) FRR(D) FAR (V) FRR(V) \n02\/07\/2001 21  76% 0% 5% 0% \n03\/07\/2001 21  52% 0% 5% 5% \n04\/07\/2001 20  44% 0% 10% 10% \n06\/07\/2001 16  59% 0% 12% 6% \n09\/07\/2001 16  52% 0% 0% 13% \n10\/07\/2001 19  63% 0% 0% 5% \n11\/07\/2001 21  75% 0% 0% 14% \n15\/07\/2001 16  46% 6% 0% 25% \n16\/07\/2001 16  71% 0% 0% 0% \n17\/07\/2001 18  67% 6% 0% 11% \n19\/07\/2001 19  62% 0% 0% 11% \n20\/07\/2001 18  68% 6% 0% 11% \n21\/07\/2001 16  78% 0% 0% 13% \n22\/07\/2001 16  80% 6% 0% 13% \n23\/07\/2001 14  54% 7% 0% 14% \n24\/07\/2001 16  79% 6% 6% 6% \n25\/07\/2001 16  41% 0% 0% 25% \n26\/07\/2001 16  80% 6% 0% 6% \n27\/07\/2001 15  76% 7% 0% 20% \n28\/07\/2001 15  85% 13% 0% 20% \n29\/07\/2001 12  67% 8% 0% 58% \n30\/07\/2001 12  74% 0% 0% 25% \n31\/07\/2001 15  83% 0% 13% 7% \n03\/08\/2001 15  77% 0% 0% 20% \n04\/08\/2001 16  59% 13% 0% 31% \nAverage 17  67% 3% 2% 15% \n \n \n Table III: The false acceptance rate (FAR) and the false rejection rate (FRR) values for selected solar images, representing \nfilament detection (D) and verification (V) processes. \nDate Filaments FAR(D) FRR(D) FAR (V) FRR(V) \n02\/07\/2001 44  15% 25% 3% 34% \n03\/07\/2001 45  5% 18% 0% 31% \n04\/07\/2001 38  3% 26% 0% 39% \n06\/07\/2001 50  18% 18% 0% 22% \n09\/07\/2001 41  12% 10% 3% 29% \n10\/07\/2001 39  15% 28% 4% 31% \n11\/07\/2001 32  7% 19% 4% 28% \n15\/07\/2001 32  31% 38% 5% 41% \n16\/07\/2001 26  36% 31% 6% 42% \n17\/07\/2001 34  31% 26% 9% 41% \n19\/07\/2001 41  27% 34% 9% 49% \n20\/07\/2001 36  24% 31% 8% 39% \n21\/07\/2001 36  4% 39% 5% 44% \n22\/07\/2001 40  21% 23% 6% 28% \n23\/07\/2001 45  15% 38% 0% 47% \n24\/07\/2001 50  11% 32% 7% 44% \n25\/07\/2001 34  18% 32% 0% 50% \n26\/07\/2001 37  9% 22% 3% 24% \n27\/07\/2001 40  20% 20% 0% 30% \n28\/07\/2001 44  48% 27% 7% 36% \n29\/07\/2001 38  11% 18% 0% 37% \n30\/07\/2001 52  18% 10% 2% 19% \n31\/07\/2001 43  21% 23% 3% 35% \n03\/08\/2001 46  29% 41% 0% 48% \n04\/08\/2001 37  33% 22% 7% 27% \nAverage 40  19% 26% 4% 36% \n \n \n"}
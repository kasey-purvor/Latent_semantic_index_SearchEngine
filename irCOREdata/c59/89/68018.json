{"doi":"10.1007\/978-3-642-14058-7_4","coreId":"68018","oai":"oai:eprints.lancs.ac.uk:33822","identifiers":["oai:eprints.lancs.ac.uk:33822","10.1007\/978-3-642-14058-7_4"],"title":"A Fast Recursive Approach to Autonomous Detection, Identification and Tracking of Multiple Objects in Video Streams under Uncertainties","authors":["Sadeghi-Tehran, Pouria","Angelov, Plamen","Ramezani, Ramin"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":["H\u00fcllermeier, Eyke","Kruse, Rudolf","Hoffmann, Frank"],"datePublished":"2010-07","abstract":"Real-time processing the information coming form video, infra-red or electro-optical sources is a challenging task due the uncertainties such as noise and clutter, but also due to the large dimensionalities of the problem and the demand for fast and efficient algorithms. This paper details an approach for automatic detection, single and multiple objects identification and tracking in video streams with applications to surveillance, security and autonomous systems. It is based on a method that provides recursive density estimation (RDE) using a Cauchy type of kernel. The main advantage of the RDE approach as compared to other traditional methods (e.g. KDE) is the low computational and memory storage cost since it works on a frame-by-frame basis; the lack of thresholds, and applicability to multiple objects identification and tracking. A robust to noise and clutter technique based on spatial density is also proposed to autonomously identify the targets location in the frame","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"Springer","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:33822<\/identifier><datestamp>\n      2018-01-24T02:05:29Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        A Fast Recursive Approach to Autonomous Detection, Identification and Tracking of Multiple Objects in Video Streams under Uncertainties<\/dc:title><dc:creator>\n        Sadeghi-Tehran, Pouria<\/dc:creator><dc:creator>\n        Angelov, Plamen<\/dc:creator><dc:creator>\n        Ramezani, Ramin<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        Real-time processing the information coming form video, infra-red or electro-optical sources is a challenging task due the uncertainties such as noise and clutter, but also due to the large dimensionalities of the problem and the demand for fast and efficient algorithms. This paper details an approach for automatic detection, single and multiple objects identification and tracking in video streams with applications to surveillance, security and autonomous systems. It is based on a method that provides recursive density estimation (RDE) using a Cauchy type of kernel. The main advantage of the RDE approach as compared to other traditional methods (e.g. KDE) is the low computational and memory storage cost since it works on a frame-by-frame basis; the lack of thresholds, and applicability to multiple objects identification and tracking. A robust to noise and clutter technique based on spatial density is also proposed to autonomously identify the targets location in the frame.<\/dc:description><dc:publisher>\n        Springer<\/dc:publisher><dc:contributor>\n        H\u00fcllermeier, Eyke<\/dc:contributor><dc:contributor>\n        Kruse, Rudolf<\/dc:contributor><dc:contributor>\n        Hoffmann, Frank<\/dc:contributor><dc:date>\n        2010-07<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/978-3-642-14058-7_4<\/dc:relation><dc:identifier>\n        Sadeghi-Tehran, Pouria and Angelov, Plamen and Ramezani, Ramin (2010) A Fast Recursive Approach to Autonomous Detection, Identification and Tracking of Multiple Objects in Video Streams under Uncertainties. In: Information Processing and Management of Uncertainty in Knowledge-Based Systems. Applications. Communications in Computer and Information Science . Springer, Berlin, pp. 30-43. ISBN 978-3-642-14057-0<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/33822\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":null,"relations":["http:\/\/dx.doi.org\/10.1007\/978-3-642-14058-7_4","http:\/\/eprints.lancs.ac.uk\/33822\/"],"year":2010,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"A Fast Recursive Approach to Autonomous\nDetection, Identi\ufb01cation and Tracking of\nMultiple Objects in Video Streams under\nUncertainties\nPouria Sadeghi-Tehran1, Plamen Angelov1, and Ramin Ramezani2\n1 Department of Communication Systems, Infolab21,\nLancaster University Lancaster, LA1 4WA, United Kingdom\np.sadeghi-tehran@lancaster.ac.uk, p.angelov@lancs.ac.uk\n2 Department of Computing, Imperial College London, United Kingdom\nraminr@doc.ic.ac.uk\nAbstract. Real-time processing the information coming form video,\ninfra-red or electro-optical sources is a challenging task due the uncer-\ntainties such as noise and clutter, but also due to the large dimensionali-\nties of the problem and the demand for fast and e\ufb03cient algorithms. This\npaper details an approach for automatic detection, single and multiple\nobjects identi\ufb01cation and tracking in video streams with applications to\nsurveillance, security and autonomous systems. It is based on a method\nthat provides recursive density estimation (RDE) using a Cauchy type of\nkernel. The main advantage of the RDE approach as compared to other\ntraditional methods (e.g. KDE) is the low computational and memory\nstorage cost since it works on a frame-by-frame basis; the lack of thresh-\nolds, and applicability to multiple objects identi\ufb01cation and tracking. A\nrobust to noise and clutter technique based on spatial density is also\nproposed to autonomously identify the targets location in the frame.\n1 Introduction\nUncertainties are inherently related to video streams and can broadly be cate-\ngorised as;\ni) noise (rather probabilistic disturbances and errors);\nii) clutter (correctly identifying objects that are however of no interest to the\nobserver \u2013 e.g. not a target that we want to track etc.).\nProcessing in real-time information that is coming form image, infra-red (IR) or\nelectro-optical (EO) sources is a challenging task due to these uncertainties, but\nalso due to the large dimensionalities of the problem (the resolution nowadays\nallow having millions of pixels and the rates of collecting information in order of\ndozens or more frames per second). At the same time the demand from applica-\ntions that are related to surveillance, security and autonomous systems require\nfast and e\ufb03cient algorithms. Recently, the use of security and surveillance sys-\ntems is the centre of attention due to growing insecurity and terrorism activities\nE. Hu\u00a8llermeier, R. Kruse, and F. Ho\ufb00mann (Eds.): IPMU 2010, Part II, CCIS 81, pp. 30\u201343, 2010.\nc\u00a9 Springer-Verlag Berlin Heidelberg 2010\nA Fast Recursive Approach to Autonomous Detection 31\naround the world. A pressing demand is the problem of automating the video\nanalytical processes which require short processing time and low memory and\nstorage requirement to enable real-time autonomous applications.\nTraditional visual surveillance systems are not very e\ufb03cient since they require\na large amount of computer storage to archive video streams for further batch\nmode processing [1-3, 16]. They also often rely on manual (as opposed to au-\ntomatic) and o\ufb00-line target\/object identi\ufb01cation. One of the most widely used\napproaches for novelty detection is based on so called background subtraction\n[4-7]. This approach is based on building a representation of the scene back-\nground and compares new frames with this representation to detect unusual\nmotions [4] . Instead of using window of consecutive frames to build background\nand keep them in the memory for o\ufb00-line processing [4, 5], we propose a fully\nautonomous analysis on a per frame basis which is using recursive calculations\nand removes the need of computer storage to archive video frames. Additionally,\nthe introduced approach is threshold-independent and minimises the processing\ntime by discarding the unnecessary data. The main idea of the proposed ap-\nproach is to approximate the probability density function (pdf) using a Cauchy\ntype of kernel (as opposed to Gaussian one used in KDE technique), and then\nin order to update this estimation we apply a recursive expression using the\ncolour intensity of each pixel. In this manner, only the accumulated information\nwhich represents the colour intensity of each pixel is stored in the memory and\nthere is no need to keep huge volumes of data in the memory. As a result, the\nproposed technique is considerably (in an order of magnitude) faster and more\ncomputationally e\ufb03cient.\nThe second innovation that is introduced in this paper is the automatic single\nand multiple object(s) identi\ufb01cation in the frame. For the newly proposed multi-\nobject detection we use a novel clustering technique to group the foreground\npixels which represents objects\/targets and distinguish them from the noise (due\nto luminance variation) and clutter. The proposed approach can be extended\nfor tracking objects using Kalman Filter (KF) or evolving Takagi-Sugeno fuzzy\nmodel [8] , and landmark detection used in robotics [9, 10].\nThe remainder of the paper is organised as follows. In section two, the RDE\nnovelty detection in video streams method is introduced. First, the widely used\nmethod KDE is explained and then its recursive version, RDE is introduced. The\nproblem of single and multi-objects tracking and the mechanism for approaching\nthis problem is explained in section 3. Section 4 represents the tracking technique\nbased on eTS fuzzy system. Section 5 displays the experimental results. At the\nend, section 6 provides conclusion and discussion.\n2 Novelty Detection in Video Streams through Recursive\nDensirty Estimation\n2.1 Background Subtraction\nOne of the most popular and widely used methods for visual novelty detec-\ntion in video stream is background subtraction method (BS) [4, 7]. Background\n32 P. Sadeghi-Tehran, P. Angelov, and R. Ramezani\nsubtraction is a method used to detect unusual motion in the scene by compar-\ning each new frame to a model of the scene background. It is based on statistical\nmodelling the background of the scene to achieve a high sensitivity to detect\na moving object and robust to the noise. Robustness is required to distinguish\n\ufb02uctuations in the statistical characteristic due to non-rigid objects and noise,\nsuch as tree branches and bushes movements, luminance change, etc.\nIn [6] the absolute di\ufb00erence between every two frames is calculated and a\nthreshold is used for decision making and model a foreground. As result, this\nmethod has low robustness to noise (e.g. luminance, variations, movement of\ntree branches, etc.) and clutter.\nIn order to cope with this problem a window of frames with length N (usually\nN > 10 is de\ufb01ned and analyzed in an o\ufb00-line mode. Each pixel in the video frame\nis modelled separately as a random variable in a particular feature space and\nestimates its probability density function (pdf) across the window of N frames [4,\n5] (Fig. 1). The pdf is usually modelled as Gaussian. A more advanced approach\nis based on mixture of Gaussian (rather than a simple Gaussian) which is more\nrealistic [11]. A drawback of this method is also using a threshold to selecting\nthe proper distribution as a background model.\nFig. 1. Window of N frames used in KDE approach, H denotes the number of pixel\nin the horizontal and V \u2013 the number of pixels in the vertical\n2.2 Kernel Density Estimation\nSome of the most common techniques for modelling the background in video\nstream processing are non-parametric techniques such as the well known Kernel\nDensity Estimation (KDE) [4]. Di\ufb00erent types of kernels can be used to rep-\nresent the pdf of each pixel of the frame each one having di\ufb00erent properties.\nTypically, the Gaussian kernel is used for its continuity, di\ufb00erentiability, and\nlocality properties [4].\n\u00a6\u220f\n= =\n\u2212=\nN\nr\nn\nl\nij\nrl\nij\ntl\nij\nt zzkN\nzp\n1 1\n)(1)( \u03c3 (1)\nA Fast Recursive Approach to Autonomous Detection 33\nwhere k\u03c3 denotes the kernel function (sometimes called a \u201cwindow\u201d function) with\nbandwidth (scale) \u03c3; n denotes the colour channel (R,G,B orH,S,V ) or,more gen-\nerally, the number of input features; [ ] nTijNijtijijij Rzzzzzz \u2208= ;,...,,...,, 21 denotes\nthe colour intensity values of N consecutive frames of a video stream that have\na speci\ufb01c (i,j)th position in each frame (Fig. 1); i=[1,H]; j=[1,V]. If Gaussian is\nchosen to be a kernel function k\u03c3, then the colour intensity can be estimated as:\n\u00a6\u220f\n=\n\u2212\n\u2212\n=\n=\nN\nr\nzz\nn\nl l\nij\nt\nl\nij\nrl\nij\ntl\ne\nN\nzp\n1\n)(\n2\n1\n1\n2\n2\n2\n2\n11)( \u03c3\n\u03c0\u03c3\n(2)\nThis can be simpli\ufb01ed as:\n\u00a6\n=\n\u2212\n\u2212\u00a6\n=\n=\nN\nr\nzz\nl\nij\nt\nn\nl l\nij\nrl\nij\ntl\ne\nN\nzp\n1\n2\n)(\n2\n1\n2\n2\n2\n1)( \u03c3\n\u03c0\u03c3\n(3)\nOnce the pdf is estimated by calculating the kernel function, it should be classi-\n\ufb01ed as a background (BG) or foreground (FG) by comparing to the pre-de\ufb01ned\nthreshold [4].\nIF ( )( ijtzp < threshold) THEN ( ijtz is foreground) ELSE ( ijtz is background) (4)\nAlthough non-parametric kernel density estimation is very accurate, it is com-\nputationally expensive and the signi\ufb01cant disadvantage of this method is the\nneed to use a threshold. A wrong choice of the value of the threshold may cause\na low performance of the whole system in di\ufb00erence outdoor environment. An-\nother major problem\/di\ufb03culty is to de\ufb01ne a proper bandwidth for the kernel\nfunction. Practically, since only a \ufb01nite number of samples are used and the\ncomputation must be performed in real time, the choice of suitable bandwidth\nis essential. Too small value of the bandwidth may lead the density estimation\nto be over-sensitive, while a wide bandwidth may cause the density estimation\nto be over-smoothed.\n2.3 The Concept of the Proposed RDE Approach\nThe main idea of the proposed RDE approach is to estimate the pdf of the\ncolour intensity given by equation (1)-(3) using a Cauchy type kernel (instead\nof Gaussian kernel) and calculate it recursively [12]. Such a recursive technique\nremoves the dependence of a threshold and parameters (such as bandwidth) and\nallows the image frame to be discarded once they have been processed and not to\nbe kept in the memory. Instead, information concerning the colour intensity per\npixel is accumulated and is being kept in the memory. In this way, the amount\nof information kept in the memory is signi\ufb01cantly smaller than original KDE\n34 P. Sadeghi-Tehran, P. Angelov, and R. Ramezani\napproach, namely (n+1)*H *V or (n+1) per pixel compare to KDE which needs\n(n*N*H*V) data stored in the memory.\nThe Gaussian kernel can be approximated by a Cauchy function since the\nCauchy function has the same basic properties as the Gaussian [13]. a) It is\nmonotonic; b) its maximum is unique and of value 1; c) it asymptotically tends\nto zero when the argument tends to plus or minus in\ufb01nity.\nIn RDE approach with using Cauchy type function the density of a certain\n(ijth) pixel is estimated based on the similarity to all previously image frames\n(unless some requirements impose this to be limited to a potentially large win-\ndow, N) at the same ijth position.\n\u00a6\u00a6\n= =\n\u2212\n+\n= N\nl\nn\nr r\nij\nrl\nij\ntl\nij\nt zz\nzD\n1 1\n2\n2\n2\n)(1\n1)(\n\u03c3\n(5)\nIt is very important that the density, D can be calculated recursively as demon-\nstrated for other types of problems in [12, 13]. In a vector form (for all pixels in\nthe frame) we have:\nttt\nT\nt\ntl bczzt\nt\nzD\n+\u2212+\u2212\n\u2212\n=\n2)1)(1(\n1)( (6)\nValue ct can be calculated from the current image frame only:\nt\nT\ntt dzc = (7)\nwhere dt is calculated recursively:\n0; 1)1()1( =+= \u2212\u2212 dzdd ttt (8)\nThe value bt is also accumulated during the processing of the frames one by one\nas given by the following recursive expression:\n0; 1\n2\n11 =+= \u2212\u2212 bzbb ttt (9)\nAs mentioned earlier, to identify a foreground (novelty) the density of each ijth\npixel of the image frame is compared to pixels at the same ijth position in all\nprevious frames. In this way, the expression (10) should be applied for each\npixel, (Fig. 2). It should be highlighted that in RDE approach there is no need\nto pre-de\ufb01ne any threshold since we estimate the statistical properties of the\ndensity:\n\u239f\u23a0\n\u239e\u239c\u239d\n\u239b\n\u2212<\n=\n))(((min)(\n1\nij\nl\nij\nl\nt\nl\nij\nt zDstdzDzDIF THEN (\nij\nlz is FG) ELSE ( ijlz is BG)  i=[1,H];j=[1,V] \n(10)\nwhere ( )( )ijlzDstd is the standard deviation of the densities of image frames seen\nso far.\nA Fast Recursive Approach to Autonomous Detection 35\nFig. 2. The frames for which the value of the density drops below the value of meanD-\nstd(D) are denoted by red circle and a novelty is detected there\n3 Single\/Multi Object(S) Identi\ufb01cation Using RDE\n3.1 Single Object Identi\ufb01cation\nAfter applying condition (11) to each pixel and detecting a novelty at a pixel\nlevel, the standard way to identify the object for tracking purposes is to \ufb01nd the\nspatial mean value of all pixels that have been identi\ufb01ed to be background [5].\nThe drawback of this technique is the in\ufb02uence of the noise caused by change of\nillumination, move of tree branches and bushes, clutter, etc. This may lead to\nlocating the object in a wrong position which might be misleading for the track-\ning. An alternative that is also often used for target tracking in video streams\nis the manual identi\ufb01cation of the target\/object which is obviously an o\ufb00-line\nprocess [5]. In this paper we propose two alternative techniques to cope with\nthis problem:\na) Based on the minimum density in the feature (colour) space.\nb) Based on maximum value of the density inside the current frame.\nIn the \ufb01rst proposed technique, the same colour density which is calculated recur-\nsively by equation (6) is used to identify a novel object. In this technique, out of\nthe Ft pixels identi\ufb01ed as a foreground in the current frame, t the one, ],[ *** ttt vhO =\nwhich has minimum density (D), will be the most di\ufb00erent from the background\nand most likely to represent the novel object\/target on the image frame:\n)(minarg\n;;\n1,1,1\n* ij\nt\nVHN\njit\nt zDO\n===\n= (11)\nIt is a very fast technique and free of computational complexity. It is also guar-\nantees a better lock on the object for tracking purposes (Fig. 3).\n36 P. Sadeghi-Tehran, P. Angelov, and R. Ramezani\nIn the second alternative technique, we use again the density, but this time in\nterms of the spatial position of the pixels inside the current frame (for i=1,2,. . . ,H;\nj=1,2,. . . ,V ) which were identi\ufb01ed already to be susceptive foreground, Ft. The\npixel with maximum value of the density inside the current frame can be chosen\nto represent the novel object\/target on the scene.\n{ },maxarg\n1,\n* ij\nt\nF\nji\nt DO\n=\n= ],[ *** ttt vhO = (12)\nwhere *tO denotes the vector of the object position in the current frame with its\nhorizontal and vertical components. F denoted the number of pixels in a frame\nclassi\ufb01ed as foreground (F<<H*V ).\nThe rationale of this technique is that this point represents the pixel that has\nhigher spatial density if only foreground (Ft) pixels are taken into account in\nthe frame (Fig. 3).\nThe spatial density can be calculated recursively in a vector form similarly to\n(6)-(9):\n;\n2)1)(1(\n1)( * \u03b2\u03b3 +\u2212+\u2212\n\u2212\n= ffl\nlOD Tt l=[1,F] (13)\n\u03b4\u03b3 Tf= (14)\n;)1()1()( 2\u2212+\u2212= lfll \u03b2\u03b2 0)1( =\u03b2 (15)\n;)1()1()( \u2212+\u2212= lfll \u03b4\u03b4 0)1( =\u03b4 (16)\nwhere f\u2208 RF denotes the vector of the foreground pixels in a frame\nThis method can be extended for image segmentation [14] , and landmark\ndetection [9] used in self-localisation in robotics [10] . As result it is more robust\nto locate the position of the object in the current image frame compare to the\nstandard mean value technique (Fig. 3).\n3.2 A New Method for Multiple Objects Identi\ufb01cation in Video\nFrames by Real-Time Clustering\nMultiple objects tracking always has been a challenging part in computer vision.\nSeveral methods are used to identify and track the \ufb01xed number of objects [17].\nMany of them are only applicable to tracking humans or vehicles [18-20]. The\nmethod that is proposed in this paper can be applied to tracking multiple objects\nwhose number is unknown and varies during tracking. The proposal is for real-\ntime on-line fast non-iterative clustering that does not require the number of\nclusters to be speci\ufb01ed beforehand. This clustering approach is applied only to\nthose pixels (Ft) in a frame that were identi\ufb01ed as a novelty\/foreground. In this\napproach the number of the clusters is not pre-speci\ufb01ed and generated based on\nthe position of the novelties in each frame. Each novelty\/foreground is assigned\nA Fast Recursive Approach to Autonomous Detection 37\nFig. 3. Pixels detected as novelty; left hand side of the scene are due to noise and\nclutter; right hand side is modelled one. Note the pixels on the left hand side of the\nmodelled scene are due to noise and clutter. The green and red square denotes the\ncentre of the target as identi\ufb01ed by the proposed techniques a) and b). Brown square\ndenotes the centre as identi\ufb01ed by the mean.\nFig. 4. Multi objects identi\ufb01cation. Right hand side scenes are original frames; left\nhand side scenes are modelled ones. The red square denotes the focal point of the\nforeground.\nto the cluster with the nearest mean. Initially a single cluster (object) is formed\naround the pixel identi\ufb01ed as described in the previous section. Its radius, r1=\u03c31\nis determined based on the spatial variance of the positions of the pixels that are\nassociated to it. After that, if the distance between the pixels that is a susceptive\nnovelty\/foreground and the centre of the cluster that is already formed is less\nthan r1, then a new cluster\/target is created. At the same time in a pursuit\nto avoid noise and clutter we ignore the new clusters that are formed around\na small number of pixels, s . This number is determined in such a way that\nthe size of an object\/target that is expected to be detected to be comparable\nwith the size of a regular (square) blob formed by s pixels. If any of the newly\nformed clusters has less than s pixels as members, it will be not speci\ufb01ed as an\nobject\/target and will be ignored, see Fig. 4.\n38 P. Sadeghi-Tehran, P. Angelov, and R. Ramezani\n4 Real-Time Tracking Using Evolving Takagi-Sugeno eTS\nFuzzy Systems\nAfter detecting all the foreground pixels in an image frame and identifying the\nobject\/target often the problem is to track it. Therefore, the e\ufb03cient track-\ning algorithm can be vital. In this paper we propose to use evolving Takagi-\nSugeno (eTS) fuzzy model [12, 22] which represents a fuzzy mixture of locally\nactive Kalman Filter (KF) [21] where the number of the local regions is not\npre-speci\ufb01ed and \ufb01xed. eTS is an on-line self-developing version of the widely\nused Takagi-Sugeno fuzzy systems [23] which combine a linguistic fuzzy IF part\nand a functional\/linear THEN consequents part.\nThe proposed algorithm is non-linear with an evolving structure. This means\nthat the number of local regions can grow or be reduced, the eTS structure \u2013\nfuzzy rules, input variables\/features, fuzzy sets \u2013 can expand or shrink according\nto the data pattern in the joint input-output (current \u2013 next frame) data space.\nIn a nutshell, learning eTS consists of two stages [24]:\n1) Decomposing the data (pixel locations in the current and next\/predicted\nimages) space into local sub-areas.\n2) Adapting the parameter of the consequent parts of the fuzzy rules.\nBoth stages are performed in real-time for an interval of time shorter than the\ntime of arrival of the next image frame (less than 40ms if assume 25fps rate of\nthe video).\nIn the tracking problem the aim is to predict the position of the object\/target\nin the next, (t+1)th frame:\n)( *\n*\n1\n^\ntt OeTSO =+ (17)\nwhere )( *\n*\n1\n^\ntt OeTSO =+ is the predicted position of the target in the (t+1)th frame.\nAnother advantage of eTS is that it can be represented by linguistically\ntractable fuzzy rules of the following type:\n\u00b0\u00af\n\u00b0\n\u00ae\n\u00ad\n++=\n++=\n+\n+\nttt\nttt\ntt\nvbhbbv\nvahaah\nTHENwaboutisvANDaboutishIFRule\n2101\n^\n2101\n^\n**** )()(: \u03c7 (18)\nwhere\n*\u03c7 , *w are the prototypes (centres of the membership functions); a and b\nare the parameters of the (linear) consequents.\nThe fuzzy sets can de\ufb01ned by their membership functions, e.g. of a Gaussian\ntype:\nl\nt\nl\nth\nl eh \u03c3\n\u03c7\n\u03c7\u03bc 2\n*\n)(\n\u2212\n= (19)\nA Fast Recursive Approach to Autonomous Detection 39\nwhere )(hl\u03c7\u03bc denotes the membership to the fuzzy set )( ** \u03c7aboutisht form the lth\nfuzzy rule.\nSimilar membership functions can be de\ufb01ned for the vertical component, v\nfor each fuzzy rule, l=[1,R]. The overall prediction of the position of the target\nin the next frame is produced using centre of gravity type defuzzi\ufb01cation:\n\u00a6\n=\n+ =\nR\nl\nl\nt\nl\nt OO\n1\n*\n*\n1\n^\n\u03bb (20)\nwhere\n\u00a6\n=\n= R\nr\nrr\nll\nl\nvh\nvh\n1\n)()(\n)()(\n\u03c9\u03c7\n\u03c9\u03c7\n\u03bc\u03bc\n\u03bc\u03bc\u03bb is the normalized \ufb01ring level of the\nthl rule;\n*l\ntT is the\nprediction by the thl rule.\nSince eTS (same as TS) is linear in the consequents part it renders the use of\nwell established learning approaches such as RLS. In fact, this is partially correct,\nbecause the linearity is correct only locally and eTS (same as TS) is non-linear\nas a whole. Therefore a fuzzily weighted version of RLS (wRLS) [24] is necessary\nto be applied, not the standard RLS. wRLS can be applied locally (per fuzzy\nrule and per cluster) or globally [13] . The local implementation has a number\nof advantages, including better convergence properties, better interpretability,\nsmaller computational demands etc. [13] and is described as:\n0; 11\n^\n*\n1\n**\n111\n^^\n=\u00b8\u00b8\u00b9\n\u00b7\n\u00a8\u00a8\u00a9\n\u00a7\n\u2212+=\n\u2212\n\u2212\u2212\u2212\n\u2212\nl\nl\nt\nT\ntt\nl\nt\nl\nt\nl\nt\nl\nt aaCaa \u03c4\u03c4\u03bb\u03c4 (21)\nIC\nC\nCCCC l\nt\nl\nt\nT\ntti\nl\nt\nT\ntt\nl\nttil\nt\nl\nt \u03a9=\n+\n\u2212=\n\u2212\u2212\u2212\u2212\n\u2212\u2212\u2212\u2212\u2212\n\u2212 1\n*\n11\n*\n1\n*\n1\n1\n*\n1\n*\n111\n1 ;)(1\n)(\n\u03c4\u03bb\u03c4\u03bb\n\u03c4\u03c4\u03c4\u03bb\n(22)\nwhere TT ];1[ *=\u03c4 denotes the extended position vector; C is the co-variance ma-\ntrix, \u03bb is the normalized \ufb01ring strength of the lth fuzzy rule; \u03a9 is a large value\nand Iis an identity matrix.\n5 Experimental Results\nIn this section, we present some real-time novelty detection results using the\nproposed RDE method. The RDE approach is applied to two video streams\nin di\ufb00erent environment and illumination conditions (Fig. 5). The results are\ncomparedwith the well known KDE approach in Table 1. Note that, the proposed\nalgorithm is implemented in MATLAB, however the time can be signi\ufb01cantly\nreduced using C language.\nThe \ufb01rst video sequence has 237 frames of size 176\u00d7144 while the second\none is 320\u00d7240 with 195 frames. In both clips, the RDE method is applied for\n40 P. Sadeghi-Tehran, P. Angelov, and R. Ramezani\nFig. 5. Background Subtraction using the proposed RDE method, Left hand side scenes\nare original frames; right hand side scenes are modelled ones. The red square denotes\nthe focal point of the foreground.\nautonomous novelty detection. After novelty\/foreground of the image frame is\ndetermined, two alternative novelty techniques known as minimum density in\ncolour space and maximum spatial density (explained in section 3) are used\nto identify the single target, while the real-time clustering is implemented for\nautomatic identi\ufb01cation of multiple targets.\nDespite the noise caused by illumination and camera oscillation in both video\nstreams, the proposed approach (RDE) has a superior performance as compared\nto the original KDE approach. As opposed to KDE, the proposed algorithm\nis signi\ufb01cantly faster and requires signi\ufb01cantly less memory storage (Table 1).\nIt should be stressed that RDE approach can be applied in real-time; while\nKDE approach is limited by the size of the window. If the size of the window\nis too large the sensitivity of the approach diminishes, on the contrary if the\nwindow size is too short it may lead to an oversensitive realization. Also, it is\nimportant to note that RDE can be realised on hardware (an n-line clustering\napproach using recursive Cauchy formula was implemented on FPGA [15] and\nproved to work extremely fast) which paves the way to various practical real-time\nimplementations.\nFor tracking part, eTS was applied to predict the position of the target in the\nnext tth frame. At the end, the performance of the eTS was compared with KF in\nterms of two dimensions, h and v. Table 2 displays that eTS provides the smaller\nroot mean error (RMSE) and non-dimensional index (NDEI) in estimating the\ntrue location of the target and overall has a better performance than KF.\nIn addition eTS provides the closer predicted values to the actual values com-\nparing to KF (Fig. 6)\nA Fast Recursive Approach to Autonomous Detection 41\nTable 1. Comparison of the performance of RDE and KDE in two di\ufb00erent video\nstreams\nTable 2. Tracking precision using eTS vs. KF\nFig. 6. Tracking performance of eTS vs. KF (Left plot \u2013 vertical component, Right\nplot \u2013 horizontal component)\n6 Conclusion and Discussion\nIn this paper, we introduced novel techniques for detection and automatic ob-\nject\/target identi\ufb01cation and tracking in video streams under uncertainties. We\ncompared the results with the best known used methods such as kernel den-\nsity estimation (KDE) for novelty detection and Kalman \ufb01lter for tracking. The\nkey innovation of the proposed approach is the use of a recursively calculated\nCauchy type of kernel for the density estimation (as opposed to widely used\nGaussian one) and in the tracking part of the problem \u2013 the use of evolving\nfuzzy Takagi-Sugeno model. The proposed approach is particularly suitable for\nreal-time autonomous applications and is very fast and robust to uncertainties\nin the video stream (it does not need to be tuned to di\ufb00erent environments and\nhas built-in robustness to noise and clutter.\n42 P. Sadeghi-Tehran, P. Angelov, and R. Ramezani\nFor single object\/target identi\ufb01cation, two alternative techniques based on\nminimum density in the colour across the video stream and the maximum spatial\ndensity inside the current frame was introduced and compared with are used and\ncompared with spatial mean method. The results show a better lock on the target\nand more robust recognition comparing to the standard spatial mean technique.\nTo autonomously identify multiple objects in a frame we proposed a real-time\non-line clustering method which is computationally fast and the number of the\nclusters does not need to be pre-de\ufb01ned. For tracking autonomously identi\ufb01ed\nobjects\/targets we proposed to use evolving Takagi-Sugeno fuzzy model (eTS)\nwhich provides real-time high prediction, is fast and human-interpretable. The\noverall proposed approach is fully autonomous and suitable for video-analytical\ntasks in surveillance and autonomous systems design.\nReferences\n1. Hampapur, A.: Smart Video Surveillance, Exploring the concept of multi-scale\nspatiotemporal tracking. IEEE Signal Processing Magazine, 38\u201351 (2005)\n2. Han, B., Comaniciu, D., Davis, L.: Sequential kernel density approximation through\nmode propagation: applications to background modeling. In: Proc. ACCV - Asian\nConf. on Computer Vision (2004)\n3. Gonzalez, R.C., Woods, R.E.: Digital Image Processing, 2nd edn. Prentice Hall,\nEnglewood Cli\ufb00s (2002) ISBN: 0201180758\n4. Elgammal, A., Duraiswami, R., Harwood, D., Davis, L.: Background and Fore-\nground modeling using nonparametric Kernel Density Estimation for visual surveil-\nlance KDE. Proc. 2002 IEEE 90(7), 1151\u20131163 (2002)\n5. Cheung, S.-C., Kamath, C.: Robust techniques for background subtraction in urban\ntra\ufb03c video. In: Proc. SPIE, Electronic Imaging Video Comm. and Image Proc.,\nSan Jose, pp. 881\u2013892 (2004)\n6. Cucchiara, R., Grana, C., Piccardi, M., Prati, A.: Detecting moving objects, ghosts\nand shadows in video streams. IEEE Trans. on Pattern Analysis and Machine\nIntelligence, 1337\u20131342 (2003)\n7. Han, B., Comaniciu, D., Davis, L.: Sequential kernel density approximation through\nmode propagation: applications to background modeling. In: Proc. ACCV - Asian\nConf. on Computer Vision (2004)\n8. Memon, A., Angelov, P., Ahmed, H.: An Approach to Real-Time Color-based Ob-\nject Tracking. In: Proc. 2006 Intern. Symp. on Evolving Fuzzy Systems, Ambleside,\nLake District, UK, pp. 81\u201387. IEEE Press, Los Alamitos (2006)\n9. Zhou, X., Angelov, P.: Real-Time joint Landmark Recognition and Classi\ufb01er Gen-\neration by an Evolving Fuzzy System. In: Proc. 2006 World Congress on Compu-\ntational Intelligence, Vancouver, Canada, pp. 6314\u20136321 (2006)\n10. Zhou, X., Angelov, P.: Autonomous Visual Self-localization in Completely Un-\nknown Environment using Evolving Fuzzy Rule-based Classi\ufb01er. In: Proc. IEEE\nIntern. Conf. on Comp. Intel. Applic. for Defense and Security, Honolulu, USA,\npp. 131\u2013138 (2007)\n11. Zhivkovic, Z., Van der Heijden, F.: E\ufb03cient adaptive density estimation per image\npixel for the task of background subtraction. Pattern Recognition Letters, 773\u2013780\n(2006)\n12. Angelov, P.: An Approach for Fuzzy Rule-base Adaptation using On-line Cluster-\ning. Intern. Journal of Approximate Reasoning, 275\u2013289 (2004)\nA Fast Recursive Approach to Autonomous Detection 43\n13. Angelov, P., Filev, D.: An Approach to On-line Identi\ufb01cation of Takagi-Sugeno\nFuzzy Models. IEEE Trans. on System, Man, and Cybernetics, part B - Cybernet-\nics, 484\u2013498 (2004)\n14. Alzate, C., Suykens, J.: Image segmentation using Weighted Kernel PCA Approach\nto Spectral Clustering. In: Proc. IEEE Intern. Conf. on Comp. Intell. Applicat. for\nImage and Signal Processing, CIISP 2007, Honolulu, HI, USA, pp. 220\u2013225 (2007)\n15. Everett, M., Angelov, P.: EvoMap: On-Chip Implementation of Intelligent Informa-\ntion Modelling using EVOlving MAPping. Technical Report, Lancaster University,\nUK, pp. 1\u201315 (2005)\n16. Cucchiara, R., Grana, C., Piccardi, M., Prati, A.: Detecting moving objects, ghosts\nand shadows in video streams. IEEE Trans. on Patt. Anal. and Machine Intell. 25,\n1337\u20131342 (2003)\n17. MacCormick, P.J., Blake, A.: A probabilistic exclusion principle for tracking mul-\ntiple objects. In: ICCV 1999, pp. 572\u2013578 (1999)\n18. Mao, X., Qi, F., Zhu, W.: Multiple-part based Pedestrian Detection using Interfer-\ning Object Detection. In: Third International Conference on Natural Computation,\npp. 165\u2013169 (2007)\n19. Cai, Q., Aggarwal, J.K.: Tracking human motion using multiple cameras. In: 13th\nInternational Conference on Pattern Recognition, pp. 68\u201372 (1996)\n20. Yang, L., Johnstone, J., Zhang, C.: A Multi-camera Approach to Vehicle Tracking\nBased on Features. In: IEEE International Symposium on Multimedia, pp. 79\u201380\n(2007)\n21. Kalman, R.E.: A New Approach to linear \ufb01ltering and prediction problem. Trans.\nof the ASME, Ser. D, Journal of Basic Engineering, 34\u201345 (1960)\n22. Angelov, P., Zhou, X.: Evolving fuzzy systems from data streams in Real time.\nIn: Proc. 2006 Intern. Symp. on Evolving Fuzzy Systems, Ambleside, Lake District,\nUK, pp. 29\u201335. IEEE Press, Los Alamitos (2006)\n23. Takagi, T., Sugeno, M.: Fuzzy identi\ufb01cation of systems and its application to mod-\nelling and control. IEEE Trans. on Systems, Man and Cybernetics, 116\u2013132 (1985)\n24. Angelov, P.: Evolving Rule-based Models: A Tool for Design of Flexible Adaptive\nSystems. Springer, Heidelberg (2002)\n"}
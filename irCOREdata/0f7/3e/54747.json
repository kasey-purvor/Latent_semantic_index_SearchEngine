{"doi":"10.1007\/s10071-009-0303-3","coreId":"54747","oai":"oai:eprints.lincoln.ac.uk:2430","identifiers":["oai:eprints.lincoln.ac.uk:2430","10.1007\/s10071-009-0303-3"],"title":"Discrimination of human and dog faces and inversion responses in domestic dogs (Canis familiaris)","authors":["Racca, Ana\u00efs","Amadei, Eleonora","Ligout, S\u00e9verine","Guo, Kun","Meints, Kerstin","Mills, Daniel"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2010-05","abstract":"Although domestic dogs can respond to many facial cues displayed by other dogs and humans, it remains unclear whether they can differentiate individual dogs or humans based on facial cues alone and, if so, whether they would demonstrate the face inversion effect, a behavioural hallmark commonly used in primates to differentiate face processing from object processing. In this study we first established the applicability of the Visual Paired Comparison (VPC or preferential looking) procedure for dogs using a simple object discrimination task with 2D pictures. The animals demonstrated a clear looking preference for novel objects when simultaneously presented with prior-exposed familiar objects. We then adopted this VPC procedure to assess their face discrimination and inversion responses. Dogs showed a deviation from random behaviour, indicating discrimination capability when inspecting upright dog faces, human faces and object images; but the pattern of viewing preference was dependent upon image category. They directed longer viewing time at novel (vs. familiar) human faces and objects, but not at dog faces, instead, a longer viewing time at familiar (vs. novel) dog faces was observed. No significant looking preference was detected for inverted images regardless of image category. Our results indicate that domestic dogs can use facial cues alone to differentiate individual dogs and humans, and that they exhibit a non-specific inversion response. In addition, the discrimination response by dogs of human and dog faces appears to differ with the type of face involved","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/54747.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/2430\/1\/Racca_et_al._2010.pdf","pdfHashValue":"24c30a797fed3a6677700ddf93c38a5061923e8c","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:2430<\/identifier><datestamp>\n      2013-11-18T15:17:31Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F43:6A6163735F43383030<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F43:6A6163735F43383530<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F43:6A6163735F43383330<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/2430\/<\/dc:relation><dc:title>\n        Discrimination of human and dog faces and inversion responses in domestic dogs (Canis familiaris)<\/dc:title><dc:creator>\n        Racca, Ana\u00efs<\/dc:creator><dc:creator>\n        Amadei, Eleonora<\/dc:creator><dc:creator>\n        Ligout, S\u00e9verine<\/dc:creator><dc:creator>\n        Guo, Kun<\/dc:creator><dc:creator>\n        Meints, Kerstin<\/dc:creator><dc:creator>\n        Mills, Daniel<\/dc:creator><dc:subject>\n        C800 Psychology<\/dc:subject><dc:subject>\n        C850 Cognitive Psychology<\/dc:subject><dc:subject>\n        C830 Experimental Psychology<\/dc:subject><dc:description>\n        Although domestic dogs can respond to many facial cues displayed by other dogs and humans, it remains unclear whether they can differentiate individual dogs or humans based on facial cues alone and, if so, whether they would demonstrate the face inversion effect, a behavioural hallmark commonly used in primates to differentiate face processing from object processing. In this study we first established the applicability of the Visual Paired Comparison (VPC or preferential looking) procedure for dogs using a simple object discrimination task with 2D pictures. The animals demonstrated a clear looking preference for novel objects when simultaneously presented with prior-exposed familiar objects. We then adopted this VPC procedure to assess their face discrimination and inversion responses. Dogs showed a deviation from random behaviour, indicating discrimination capability when inspecting upright dog faces, human faces and object images; but the pattern of viewing preference was dependent upon image category. They directed longer viewing time at novel (vs. familiar) human faces and objects, but not at dog faces, instead, a longer viewing time at familiar (vs. novel) dog faces was observed. No significant looking preference was detected for inverted images regardless of image category. Our results indicate that domestic dogs can use facial cues alone to differentiate individual dogs and humans, and that they exhibit a non-specific inversion response. In addition, the discrimination response by dogs of human and dog faces appears to differ with the type of face involved.<\/dc:description><dc:publisher>\n        Springer<\/dc:publisher><dc:date>\n        2010-05<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/2430\/1\/Racca_et_al._2010.pdf<\/dc:identifier><dc:identifier>\n          Racca, Ana\u00efs and Amadei, Eleonora and Ligout, S\u00e9verine and Guo, Kun and Meints, Kerstin and Mills, Daniel  (2010) Discrimination of human and dog faces and inversion responses in domestic dogs (Canis familiaris).  Animal Cognition, 13  (3).   pp. 525-533.  ISSN 1435-9448  <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/s10071-009-0303-3<\/dc:relation><dc:relation>\n        10.1007\/s10071-009-0303-3<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/2430\/","http:\/\/dx.doi.org\/10.1007\/s10071-009-0303-3","10.1007\/s10071-009-0303-3"],"year":2010,"topics":["C800 Psychology","C850 Cognitive Psychology","C830 Experimental Psychology"],"subject":["Article","PeerReviewed"],"fullText":" 1\nDiscrimination of human and dog faces and inversion responses in 1 \ndomestic dogs (Canis familiaris) 2 \n 3 \nAna\u00efs Racca1,2, Eleonora Amadei1,3, S\u00e9verine Ligout1, Kun Guo2, 4 \n Kerstin Meints2, Daniel Mills1 5 \n 6 \n1Department of Biological Sciences, University of Lincoln, UK 7 \n2Department of Psychology, University of Lincoln, UK 8 \n3Dipartimento di Morfofisiologia Veterinaria e Produzioni Animali, Universit\u00e0 degli 9 \nStudi di Bologna, Italy 10 \n 11 \n 12 \nCorresponding author: 13 \nAna\u00efs Racca 14 \naracca@lincoln.ac.uk 15 \n+44(0)1522 895453     16 \n 17 \n 2\nAbstract 18 \nAlthough domestic dogs can respond to many facial cues displayed by other 19 \ndogs and humans, it remains unclear whether they can differentiate individual dogs or 20 \nhumans based on facial cues alone and, if so, whether they would demonstrate the face 21 \ninversion effect, a behavioural hallmark commonly used in primates to differentiate face 22 \nprocessing from object processing. In this study we first established the applicability of 23 \nthe Visual Paired Comparison (VPC or preferential looking) procedure for dogs using a 24 \nsimple object discrimination task with 2D pictures. The animals demonstrated a clear 25 \nlooking preference for novel objects when simultaneously presented with prior-exposed 26 \nfamiliar objects. We then adopted this VPC procedure to assess their face discrimination 27 \nand inversion responses. Dogs showed a deviation from random behaviour, indicating 28 \ndiscrimination capability when inspecting upright dog faces, human faces and object 29 \nimages; but the pattern of viewing preference was dependent upon image category. 30 \nThey directed longer viewing time at novel (vs. familiar) human faces and objects, but 31 \nnot at dog faces, instead, a longer viewing time at familiar (vs. novel) dog faces was 32 \nobserved. No significant looking preference was detected for inverted images regardless 33 \nof image category. Our results indicate that domestic dogs can use facial cues alone to 34 \ndifferentiate individual dogs and humans, and that they exhibit a non-specific inversion 35 \nresponse. In addition, the discrimination response by dogs of human and dog faces 36 \nappears to differ with the type of face involved.  37 \n 38 \nKeywords:  Preferential looking, Visual paired comparison, Face discrimination, 39 \nInversion effect, Dogs 40 \n 3\nIntroduction 41 \nFaces convey visual information about an individual\u2019s gender, age, familiarity, intention 42 \nand mental state, and so it is not surprising that the ability to recognize these cues and to 43 \nrespond accordingly plays an important role in social communication, at least in humans 44 \n(Bruce and Young 1998). Numerous studies have demonstrated our superior efficiency 45 \nin differentiating and recognizing faces compared with non-face objects, and have 46 \nsuggested a face-specific cognitive and neural mechanism involved in face processing 47 \n(e.g. Farah et al. 1998; McKone et al. 2006; see also Tarr and Cheng 2003). For 48 \ninstance, neuropsychological studies have reported selective impairments of face and 49 \nobject recognition in neurological patients (prosopagnosia and visual agnosia) (Farah 50 \n1996; Moscovitch et al. 1997), and brain imaging studies have revealed distinct 51 \nneuroanatomical regions in the cerebral cortex, such as the fusiform gyrus, associated 52 \nwith face processing (McCarthy et al. 1997; Tsao et al. 2006). Likewise, 53 \nbehavioural\/perceptual studies show that inversion (presentation of a stimulus upside-54 \ndown) results in a larger decrease in recognition performance for faces than for other 55 \nmono-oriented objects (e.g. Yin, 1969; Valentine 1988; Rossion and Gauthier 2002). 56 \nAlthough the precise cause of this so called \u2018face inversion effect\u2019 is still source of 57 \ndebate (qualitative vs. quantitative difference between the processing of upright and 58 \ninverted faces; e.g. Sekuler et al. 2004; Rossion 2008, 2009; Riesenhuber and Wolff 59 \n2009; Yovel 2009); it is generally associated with a more holistic processing for faces 60 \n(both the shape of the local features (i.e. eyes, nose, mouth) and their spatial 61 \narrangement are integrated into a single representation of the face) than other objects. 62 \nThe face inversion effect is therefore considered as a hallmark for differentiating face 63 \nfrom object processing.  64 \nThe capacity for differentiating individuals based on facial cues is not restricted 65 \nto humans. Using match-to-sample or visual paired comparison tasks, previous studies 66 \n 4\nhave found that non-human primates (e.g. chimpanzees (Pan troglodytes): Parr et al. 67 \n1998, 2000, 2006; and monkeys (Macaca mulatta, Macaca tonkeana, Cebus apella): 68 \nPascalis and Bachevalier 1998; Parr et al. 2000, 2008; Gothard et al. 2003, 2009; 69 \nDufour et al. 2006; Parr and Heinz 2008) other mammals (e.g. sheep (Ovis aries): 70 \nKendricks et al. 1996; heifers (Bos Taurus): Coulon et al. 2009)), birds (e.g. budgerigars 71 \n(Melopsittacus undulatus): Brown and Dooling, 1992), and even insects (e.g. paper 72 \nwasps (Poliste fuscatus): Tibbetts 2002) could discriminate the faces of their own 73 \nspecies (conspecifics), based on visual cues. Although it is not clear whether face 74 \nprocessing in non-human animals share a similar neural mechanism as that in humans, 75 \nsome behavioural studies have noticed a face inversion effect, at least towards 76 \nconspecific faces in chimpanzees (e.g. Parr et al. 1998), monkeys (e.g. Parr et al. 2008; 77 \nParr and Heinz 2008; Neiworth 2007; see also Parr et al. 1999) and sheep (Kendrick et 78 \nal. 1996), suggesting that a similar holistic process may be used for face perception by 79 \nthese species. 80 \nMany studies have suggested that the development of a face-specific cognitive 81 \nprocess relies heavily on the animal\u2019s extensive experience with certain type of faces. 82 \nFor instance, human adults have difficulties at recognizing faces from a different ethnic 83 \ngroup and demonstrate weaker holistic processing towards these faces (O\u2019Toole et al. 84 \n1994; Tanaka et al. 2004). This so called \u2018other-race effect\u2019 can decrease and even 85 \nreverse by experiencing another ethnic face type (e.g. Elliott et al. 1973; Brigham et al. 86 \n1982; Sangrigoli et al. 2004). Furthermore, humans and some non-human primates 87 \npresent abilities of discrimination and\/or an inversion effect toward faces of other 88 \nspecies, provided that they have been frequently exposed to them (generally tested with 89 \nother-primate species) (Parr et al. 1998, 1999; Martin-Malivel and Fagot 2001; Pascalis 90 \net al. 2005; Martin-Malivel and Okada 2007; Neiworth et al. 2007; Parr and Heinz 91 \n 5\n2008; Sugita 2008). Finally, human performances in simple human-face identification 92 \ntask are known to depend primarily on the amount of preceding practice (Hussain et al. 93 \n2009). Taken together, exposure seems to be an important determinant for holistic face 94 \nprocessing.  95 \nGiven their long history of domestication (estimated at 12,000-100,000 years 96 \nago, Davis and Valla 1978; Vil\u00e0 et al. 1997) and intensive daily interaction with humans, 97 \npet domestic dogs could be a unique animal model for the comparative study of face 98 \nprocessing. Despite their extraordinary capacity for discriminating olfactory cues (e.g. 99 \nSchoon 1997; Furton and Myers 2001), domestic dogs also process visual inputs 100 \nefficiently. Although they could have less binocular overlap, less range of 101 \naccommodation and colour sensitivity, and lower visual acuity (20\/50 to 20\/100 with 102 \nthe Snellen chart) compared with humans, they in general have a larger visual field and 103 \nhigher sensitivity to motion signals (for a review see Miller and Murphy 1995). 104 \nGrowing evidence has revealed that they can rely on facial cues for social 105 \ncommunication. They can display a range of facial expressions and these are believed to 106 \nbe important in intraspecific communication (e.g. Feddersen-Petersen 2005). They also 107 \nattend to and use human facial cues. For instance, they attend to human faces to assess 108 \ntheir attentional state (Call et al. 2003; G\u00e1csi et al. 2004; Viranyi et al. 2004) or in 109 \nproblem solving situations (Top\u00e1l et al. 1997; Mikl\u00f3si et al. 2003). They are particularly 110 \nefficient at reading and understanding some human directional communicative cues, 111 \nsuch as following human eye\/head direction to find hidden food (e.g. Mikl\u00f3si et al. 112 \n1998; Soproni et al. 2001), and even exceed the ability of some non-human primates in 113 \nsuch tasks (e.g. Povinelli et al. 1999; Soproni et al. 2001; Hare et al. 2002). In a recent 114 \nstudy, Marinelli and colleagues (2009) observed the apparent attention of dogs while 115 \nlooking at their owner and a stranger entering and leaving a room. They showed that the 116 \n 6\ndogs\u2019 attention towards their owner decreased if both the owner and the stranger were 117 \nwearing hoods covering their heads. This could suggest that dogs use the face as a cue 118 \nto recognize their owners. Moreover, another study suggests dogs may even have an 119 \ninternal representation of their owner\u2019s face, and can correlate visual inputs (i.e. 120 \nowner\u2019s face) with auditory inputs (i.e. owner\u2019s voice) (Adachi et al. 2007). Finally, our 121 \nrecent behavioural study (Guo et al. 2009) revealed that when exploring faces of 122 \ndifferent species, domestic dogs demonstrated a human-like left gaze bias (i.e. the right 123 \nside of the viewer\u2019s face is inspected first and for longer periods) towards human faces 124 \nbut not towards monkey or dog faces, suggesting that they may use a human-like gaze 125 \nstrategy for the processing of human facial information but not conspecifics. 126 \nIn this study, we examined whether domestic dogs (Canis familiaris) could 127 \ndiscriminate faces based on visual cues alone, whether they demonstrate a face 128 \ninversion effect, and to what extent these behaviour responses were influenced by the 129 \nspecies viewed (i.e. human faces vs. dog faces), given their high level of natural 130 \nexposure to both species.  131 \n 132 \nExperiment 1:  Object discrimination in domestic dogs measured by a visual 133 \npaired comparison task  134 \nCompared with other methodologies such as match-to-sample task, the visual 135 \npaired comparison (VPC or preferential looking) task does not involve intensive 136 \ntraining, is rapid to perform and is naturalistic. Consequently, it is commonly used in 137 \nthe study of visual discrimination performance in human infants (e.g. Fantz 1964; Fagan 138 \n1973; Pascalis et al. 2002) and non-human primates (e.g. Pascalis and Bachevalier 139 \n1998; Gothard et al. 2003, 2009; Dufour et al. 2006). It is based on behavioural changes 140 \nstemming from biases in attention towards novelty. In this task, a single stimulus is 141 \n 7\npresented to the participant in a first presentation phase (familiarisation phase), followed 142 \nby the simultaneous presentation of the same stimulus and a novel stimulus in the 143 \nsecond presentation phase (test phase). It is assumed that if the individual can 144 \ndiscriminate between the familiar and the novel stimulus, there will be increased 145 \nattention shown towards the novel stimulus, which is evident from a longer viewing 146 \ntime. 147 \n To our knowledge, the VPC task has not been applied in the controlled testing of 148 \nthe perceptual ability of domestic dogs. Therefore, in the first experiment, we employed 149 \nan object discrimination task to establish whether the domestic dog could fulfil the 150 \nnecessary criteria for using the VPC task in such studies.  151 \n 152 \nMethod 153 \nAnimals 154 \nSeven adult domestic pet dogs (Canis familiaris, 5.6\u00b12.8 (mean\u00b1SD) years old; 155 \n1 miniature Dachshund, 2 Lurchers, and 4 cross-breeds; 2 males and 5 females) were 156 \nrecruited from university staff and students for this experiment. The study was carried 157 \nout at the University of Lincoln (UK) from May to June 2008. 158 \nVisual stimuli  159 \nEighteen gray-scale digitized common object pictures (subtending a visual angle 160 \nof 34\u00d743\u00b0) were used in this experiment. The pictures were taken using a Nikon D70 161 \ndigital camera and further processed in Adobe Photoshop. Specifically, a single object 162 \nwas cropped from the original picture and was then resized (to ensure a similar height 163 \nbetween objects) and overlapped with a homogenous white background to create object 164 \nimage used in the study. The object pictures were then paired according to similarity of 165 \ntheir general shape, and each trial contained two different images of the same object 166 \n(first picture and familiar picture) and one image of a different object (novel picture) 167 \n 8\n(see Fig.1 for an example).  All visual stimuli were back-projected on the centre of a 168 \n\u2018dark\u2019 projection screen using customized presentation software (Meints and Woodford 169 \n2008). 170 \nTo reduce the chance of discriminating objects using a low level cognitive 171 \nprocess, such as detecting differences in contrast or brightness, two precautions were 172 \ntaken: (1) for each trial the first and familiar images were two different images of the 173 \nsame object with a slight difference in the perspective to avoid repetition of the contrast 174 \nand brightness distribution in the pictures; (2) the contrast and brightness of the three 175 \npictures forming each trial were visually adjusted to appear as similar as possible. 176 \nTherefore, the dogs could not rely on the immediate change of contrast or brightness to 177 \ndifferentiate the familiar and novel stimulus presented simultaneously in the test phase. 178 \nExperimental protocol  179 \nDuring the experiment, the dog was familiarised with a quiet, dim-lit test room 180 \nand then sat about 60cm in front of the projection screen. A researcher stood behind the 181 \ndog, put her hands on the shoulders or under the head of the dog but did not interfere 182 \nwith it during the image presentation or force it to watch the screen. The small dogs 183 \nwere sat on the lap of the researcher. A CCTV camera (SONY SSC-M388CE, 184 \nresolution: 380 horizontal lines) placed in front of the dog was used to monitor and 185 \nrecord the dog\u2019s eye and head movements. Once the dog\u2019s attention had been attracted 186 \ntowards the screen using a sound stimulus behind it (e.g. a call to the dog, tap on the 187 \nscreen), the trial was started with a small yellow fixation point (FP) presented in the 188 \ncentre of the screen at the dog\u2019s eye level (also the centre of the project stimulus). The 189 \ndiameter of the FP was changed dynamically by expanding and contracting (ranging 190 \nbetween 2.8 and 6.6\u00b0) to attract and maintain the dog\u2019s attention. The dog\u2019s head and 191 \neye positions were monitored on-line by a second researcher, in an annexe room, 192 \nthrough CCTV. Once the dog\u2019s gaze was oriented towards the FP a visual stimulus was 193 \n 9\nthen presented. During the presentation, the dog passively viewed the images. No 194 \nreinforcement was given during this procedure, neither were the dogs trained on any 195 \nother task with these stimuli.  196 \nIn total, 6 trials were tested in a random order for each dog, and 3 pre-test trials 197 \nwere used to familiarise the dog with the general procedure. A typical trial consisted of 198 \ntwo presentations (or phases). The first familiarisation phase had a single first picture 199 \npresented at the centre of the screen for 5 seconds, and the second test phase had the 200 \nfamiliar and novel pictures presented also for 5 seconds side-by-side with a 35\u00b0 spatial 201 \ngap between them (distance between the inner edges of two simultaneously presented 202 \npictures). The side location (left or right) of the novel picture was randomised and 203 \ncounterbalanced. The time between the familiarisation phase and the test phase (inter-204 \nphase interval) varied between 1 and 4 seconds, depending on the time needed to re-205 \nattract the attention of the dog towards the FP. A trial was aborted if the dog spent less 206 \nthan 1 second exploring the first picture during the familiarisation phase or if the 207 \nresearcher failed to re-attract dog\u2019s attention towards the FP within a maximum of 4 208 \nseconds during the inter-phase interval. The dogs were allowed short breaks when 209 \nneeded and were given treats during the breaks. All of the dogs tested successfully 210 \ncompleted at least 67% of the trials (81%\u00b111). Two dogs needed an extra session to 211 \nretest missed trials to reach this criterion. 212 \nThe dog\u2019s eyes and head movements were recorded and then digitised with a 213 \nsampling frequency of 60 Hz. The image was replayed off-line frame by frame for 214 \naccurate analysis by one researcher and the direction of the dog\u2019s gaze toward the 215 \nscreen was manually classified as \u2018left\u2019, \u2018right\u2019, \u2018central\u2019 and \u2018out\u2019 looking accordingly 216 \n(see Fig. 2 for an example). The coding of each trial was started with a \u201ccentral\u201d gaze 217 \n(direct gaze towards the central FP) which was used as a reference position for the 218 \nentire trial. The gaze direction was then coded as \u2018left\u2019 or \u2018right\u2019 once the dog\u2019s eye 219 \n 10\ndeviated from this reference position, assessed by a change of pupil position. The 220 \nmovement of head and\/or eyebrows were also used to facilitate the coding. Establishing 221 \nif a subject was looking \u2018out\u2019 was accomplished by training the observers. This 222 \ninvolved repeatedly presenting them with video sequences in which a human subject 223 \noscillated her gaze between the outer edge of the image and beyond. The \u2018out\u2019 looking 224 \nwas always chosen when in doubt. 225 \nThe researcher was blind about the side location of the pictures on the screen 226 \nduring the test phase for each trial when performing off-line data analysis. 227 \nData analysis and statistics 228 \nFor each trial, the viewing time of gaze direction classified as \u2018left\u2019, \u2018right\u2019, \u2018central\u2019 229 \nand \u2018out\u2019 was calculated separately. As the amount of time spent looking at the pictures 230 \nvaried widely between subjects we calculated the proportion of \u2018left\u2019 and \u2018right\u2019 231 \nviewing time as a proportion of cumulative viewing time allocated within the screen 232 \n(i.e. right+left+central) in order to normalize our data. The data were then unblinded so 233 \nthat the proportion of \u2018left\u2019 and \u2018right\u2019 viewing time could be contextualised according 234 \nto the position of the familiar and novel pictures, and was averaged across trials for each 235 \ndog. A two-tailed paired t-test was used to compare viewing time between two pictures 236 \nfor all the tested dogs.  237 \n 238 \nResults and Discussion 239 \nWithin a 5-second presentation time, the dogs spent on average 4.0s\u00b10.6 looking 240 \nat the first picture in the familiarisation phase, and 4.4s\u00b10.48 looking at the familiar and 241 \nnovel pictures in the test phase. The two tailed paired t-test showed that the novel 242 \npicture attracted a significantly longer viewing time than the familiar picture 243 \n(41.1%\u00b111.2 vs. 26.8%\u00b17.2, t6=4.83, P=0.003), suggesting that the dogs demonstrated a 244 \nclear preference for novelty and could differentiate two objects presented 245 \n 11\nsimultaneously in the test phase. The VPC task, therefore, can be used for investigating 246 \nface discrimination and inversion performance in domestic dogs. We should, however, 247 \nacknowledge that the researcher stood behind the dog during the study was not blind 248 \ntowards the stimuli presented. As subtle unconscious cues may have been transmitted to 249 \nthe dogs by the experimenter, this potential factor was eliminated in our second 250 \nexperiment.  251 \n 252 \nExperiment 2: Face discrimination and inversion performance in the viewing of 253 \nhuman and dog faces  254 \n In the second experiment, we employed VPC tasks to examine (1) whether 255 \ndomestic dogs could discriminate individual faces based on visual cues alone; (2) 256 \nwhether they show a face inversion effect as seen in human and non-human primates; 257 \nand (3) to what extent their face discrimination and inversion performance were 258 \ninfluenced by the species of viewed faces (i.e. human faces vs. dog faces). 259 \n 260 \nMethod 261 \nTwenty-six adult domestic pet dogs were recruited from university staff and 262 \nstudents for this experiment, with fifteen of them successfully completing the 263 \nexperiment. The reasons for failure to complete were mainly due to a lack of attention, 264 \nrestlessness or distress. One of the fifteen dogs was also excluded from the data analysis 265 \nbecause of producing scores above 2.5 standard deviations from the mean, and so was 266 \nrejected as an outlier. The final sample contained fourteen dogs (4.3\u00b13.2 (mean\u00b1SD) 267 \nyears old; 1 Alaskan Malamute, 1 miniature Dachshund, 2 Jack Russells, 2 Labradors, 3 268 \nLurchers and 5 cross-breeds; 6 males and 8 females). Four of them had also participated 269 \nin the first experiment. All dogs were well socialised to humans and other dogs. The 270 \nstudy took place at the University of Lincoln (UK) from October to December 2008. 271 \n 12\nA total of seventy-two gray scale digitized unfamiliar human face, unfamiliar 272 \ndog face and common object images (24 images per category; 36\u00d745 cm) were used in 273 \nthis experiment (see Fig.3 for examples). The human faces were taken from Caucasian 274 \nstudents at the University of Lincoln (aged between 19 and 26 years old; 8 women and 275 \n8 men) who did not present any distinctive facial marks, facial jewelleries and make-up. 276 \nThe faces of adult dogs (aged between 2 and 7 years old; 8 males and 8 females) were 277 \nobtained from pedigree dog breeders (Poodle, miniature Dachshund, Spaniel and Border 278 \nTerrier). All face images were judged to have neutral facial expressions with a straight 279 \ngaze. The common object images contained pictures of generally seen upright items: 280 \ntable, lamp, chair and car. 281 \nEight trials were used for each image category to test discrimination 282 \nperformance (24 trials in total for each dog). Four of them were upright trials where all 283 \nthe pictures were presented in an upright orientation. The other 4 trials were inverted 284 \ntrials where the first picture was presented upright during the familiarisation phase but 285 \nthe familiar and the novel pictures were presented upside-down (180\u00b0 rotation) during 286 \nthe test phase. For a given trial, the stimuli used as familiar or novel items were 287 \nrandomly determined. The human faces were paired by gender and age, the dog faces 288 \nwere paired by gender, age and breed, and the object pictures were paired by category 289 \ntype. The gender of human faces, the breed of dog faces and the type of objects were 290 \nbalanced between upright and inverted trials. Each pair of human and dog faces was 291 \nalso assessed as more similar or different based on hair\/fur colour and facial marking, 292 \nand was then balanced between upright and inverted trials. Furthermore, all the pictures 293 \npresented within a given trial were digitally processed in the same way as described in 294 \nExperiment 1 to control for some low-level image properties (i.e. background colour, 295 \nsize, contrast and brightness of the stimuli); the overall brightness (stimulus + 296 \n 13\nbackground) of the first picture presented in the familiarisation phase was also set as the 297 \nmean brightness of the novel and familiar pictures presented in the test phase. The dogs, 298 \ntherefore, had to rely on differences in the face\/object contained in the picture, rather 299 \nthan differences in overall picture brightness, to differentiate familiar and novel 300 \npictures. 301 \nThe experimental procedure and data analysis were identical to those described 302 \nin Experiment 1. An additional precaution was, however, used here: the researcher 303 \nbehind the dog was instructed not to look at the pictures by keeping her head down 304 \nduring the trial to avoid potential influence on the dog\u2019s viewing behaviour. The 15 305 \ndogs tested successfully completed at least 75% of the trials (92%\u00b15), and needed extra 306 \nsessions to retest missed trials to reach this criterion (the dogs did not miss more trials 307 \nwith regards to one stimulus category than another, ANOVA, P>0.05). Two researchers 308 \ncoded the direction of the dog\u2019s gaze in the same way as in experiment 1, and without 309 \nprior knowledge about the side location of the familiar and novel pictures presented. 310 \nThe inter-rater reliability measures yielded correlations of 0.94 between the two 311 \nresearchers after coding data independently. 312 \nData analysis and statistics 313 \nAs in experiment 1, the cumulative viewing time directed at the \u2018left\u2019, \u2018right\u2019, \u2018central\u2019 314 \nand \u2018out\u2019 of the screen was calculated separately for each trial. We then calculated the 315 \nproportion of \u2018left\u2019 and \u2018right\u2019 viewing time as a proportion of cumulative viewing time 316 \nallocated within the screen in order to normalize our data. The proportion of \u2018left\u2019 and 317 \n\u2018right\u2019 viewing time was then referenced to the viewing time directed at the familiar and 318 \nnovel pictures and averaged between trials and across image categories for each dog. 319 \nData were checked for normality using a Kolmogorov-Smirnov test (P>0.05), therefore, 320 \nanalyses of variance with repeated measures were conducted on the proportion of 321 \nviewing time at the stimuli considering the following factors: Stimulus Type (dog face 322 \n 14\nvs. human face vs. object), Orientation (upright vs. inverted) and Image novelty (novel 323 \nvs. familiar assessed by gaze direction). We then used planned comparisons, run within 324 \nthe ANOVA, to determine if there was a significant attraction towards the novel 325 \nstimulus in the different type of stimuli and in the different orientation.  326 \n 327 \nResults and Discussion 328 \nDuring the familiarisation phase, the dogs spent on average 4.1s\u00b10.7, 4.1s\u00b10.8 329 \nand 4.2s\u00b10.7 viewing dog faces, human faces and object pictures. During the test phase, 330 \nthey spent 4.3s\u00b10.78, 4.2s\u00b10.8 and 4.3s\u00b10.6 looking at the familiar and novel images of 331 \ndog faces, human faces and objects. We did not observe a significant difference in 332 \nviewing time across image categories or presented orientations (ANOVA, P>0.05). The 333 \naveraged cumulative viewing time, in milliseconds, directed at the novel picture 334 \n(looking \u2018left\u2019 or \u2018right\u2019 depending on the side location of the stimuli), \u2018familiar\u2019 picture 335 \n(looking \u2018right\u2019 or \u2018left\u2019), \u2018central\u2019 and \u2018out\u2019 of the screen are presented in Table 1. 336 \nOur ANOVA analysis conducted on the proportion of viewing time allocated to 337 \nthe stimuli revealed no significant effect for Image novelty (F1,13=3.84; P=0.0717) but a  338 \nsignificant interaction between Stimulus Type and Image novelty (F2,26=5.98; 339 \nP=0.0073). Planned comparisons show that during the test phase with the upright 340 \nimages, the novel object and novel human face picture attracted a significantly longer 341 \nviewing time than the familiar object and familiar human face (object: F1=8.15, 342 \nP=0.0135; human face: F1=7.09, P=0.0195), and that the familiar dog face attracted a 343 \nsignificantly longer viewing time than the novel dog face (F1=5.43, P=0.037) (Figure 344 \n4.A). For inverted stimuli, the novel and familiar pictures in the test phase resulted in no 345 \nsignificant difference in the viewing time for each image category (object: F1=1.08, 346 \nP=0.32; human face: F1=1.13, P=0.31; dog face: F1=0.005, P=0.94) suggesting that the 347 \n 15\ndogs did not reliably differentiate between the two inverted pictures presented 348 \nsimultaneously (Fig 4.B). 349 \nThe absence of an interaction between Stimulus Type and Orientation suggests 350 \nthat the observed inversion effect was neither face-specific nor species-specific. 351 \n 352 \nGeneral Discussion 353 \nIn this study we first demonstrated that the Visual Paired Comparison (VPC) 354 \nprocedure can be successfully applied to domestic dogs for the study of visual 355 \ndiscrimination. To the authors\u2019 knowledge, this is the first report of the use of VPC in 356 \nnon-primate animals. 357 \nUsing a VPC task, we observed a clear difference between the proportion of 358 \nviewing time directed at a simultaneously presented novel image and prior-exposed 359 \nfamiliar image, suggesting the dogs could make a within-category discrimination 360 \nbetween upright dog faces, human faces and object images. Therefore, the capacity for 361 \ndifferentiating individual faces based on visual cues alone, which is evident in humans 362 \nand non-human primates (e.g. Bruce and Young 1998; Pascalis and Bachevalier 1998; 363 \nParr et al. 2000; Dufour et al. 2006), extends to domestic dogs. Interestingly, their 364 \nviewing preferences seemed to differ for the processing of faces of different species. 365 \nThe dogs demonstrated a preference for the novel face when presented with human 366 \nfaces, but a preference for the familiar face when presented with dog faces. This 367 \ndiscrepancy may reflect different cognitive processes in the initial perception of dog and 368 \nhuman faces. 369 \nWhen applying a VPC task in infant studies, a preference for novelty has been 370 \nreported frequently and used as the criterion for determining discrimination abilities 371 \n(e.g. Fantz 1964; Fagan 1973; Pascalis et al. 2002). However, cases of preference for 372 \nfamiliarity have also been observed (for a review see Pascalis and de Haan 2003). The 373 \n 16\ncompleteness of the encoding has been identified as a major factor influencing 374 \nchildren\u2019s viewing preferences. In general, a well-encoded stimulus will tend to result in 375 \na preference for novelty and an incomplete encoding of a stimulus will tend to result in 376 \na preference for familiarity in order to complete the encoding of the stimulus (e.g. 377 \nWagner and Sakovits 1986; Hunter and Ames 1988). Incomplete encoding is generally 378 \ndue to a lack of familiarisation time compared to the complexity of the stimulus (the 379 \nmore complex the stimulus is, the more familiarisation time is needed). In our study, 5 380 \nseconds were given to the dogs as a familiarisation time and, in average, dogs paid 381 \nattention to the stimuli for 4.1 seconds, whatever the stimulus type. A possible 382 \nexplanation of our results could therefore be that dog faces are more complex than 383 \nhuman faces to encode for dog observers. Alternatively, our results could also be due to 384 \nour methodology. Indeed, some cases of preference for familiarity in children have been 385 \nobserved when the familiar stimulus was similar, but not identical to the stimulus 386 \npreviously seen (Gibson and Walker 1984). In our study, the first stimulus presented in 387 \nthe familiarisation phase and the familiar stimulus presented in the test phase were not 388 \nidentical (same face\/object but different picture) in order to avoid a discrimination based 389 \nsimply on contrast\/brightness similarities. Thus, it could be possible that dogs detected 390 \nthe difference between the first and the familiar stimulus for dog faces but not for 391 \nhuman faces. Finally, the discrepancy of dog preferences between dog and human faces 392 \ncould also correspond to a different social response towards conspecifics versus humans 393 \nin dogs or to differential exposure to conspecifics and humans. These possibilities 394 \nwarrant future research in the area. 395 \nIn this study we also observed that the dogs did not make reliable within-396 \ncategory discriminations once the images were inverted. The inversion of dog faces, 397 \nhuman faces and object images had a similar deteriorative effect on their discriminative 398 \nresponses. If we apply the same arguments as have been used in human studies, then we 399 \n 17\nmight be tempted to conclude that there is a similar cognitive strategy in processing of 400 \ndog faces, human faces and common objects in domestic dogs. However, our previous 401 \nstudy suggests this is not the case as dogs seem to present a different gaze strategy 402 \nwhile viewing human faces (left gaze bias) compared to dog faces and objects (no bias) 403 \n(Guo et al. 2009). Using both face and non-face stimuli, a face-specific inversion effect 404 \nhas been observed in some non-human primates, such as chimpanzees (e.g. Parr et al. 405 \n1998), rhesus monkeys (Parr et al. 2008; Parr and Heinz 2008) and cotton-top tamarins 406 \n(Neiworth et al. 2007), but other studies have failed to observe this effect in rhesus 407 \nmonkeys (Parr et al. 1999). In this latter experiment, Parr and her colleagues found a 408 \nnon-face-specific inversion effect: i.e. monkeys demonstrated an inversion effect 409 \ntowards faces of different species (rhesus monkey and capuchin) and objects 410 \n(automobile). Our study produces similar results for domestic dogs, i.e. a more general 411 \ninversion effect toward faces and objects. However, it should be noted that our 412 \nmethodology for assessing the inversion effect was very conservative. As the first 413 \npicture in the familiarisation phase was presented upright to show normal configuration, 414 \na mental rotation was needed to compare the inverted familiar picture with the encoded 415 \nupright first picture during the test phase. If dogs have a poor capacity for mental 416 \nrotation, then they would treat both the inverted familiar picture and inverted novel 417 \npicture as new pictures, and not present any gaze preference. It would be worthwhile to 418 \nrevisit this face inversion response with different methodologies (e.g. present inverted 419 \nstimuli in both the familiarisation and test phases) in future research. 420 \n 421 \nIn conclusion, a Visual Paired Comparison (VPC) procedure can be used successfully to 422 \nstudy discrimination abilities of dogs and thus can provide an effective tool to study 423 \ncanine cognition. Furthermore, we found no evidence that domestic dogs show a face-424 \nspecific inversion response, but they do have the ability to discriminate both individual 425 \nhuman and dog faces using 2-dimensional visual information only. These images do not 426 \n 18\nappear to be processed equivalently, with the looking response differing according to 427 \nthe type of face involved. 428 \nAcknowledgments 429 \nWe thank Dr. Olivier Pascalis for advice on experimental design and comments on the 430 \nmanuscript, Fiona Williams for helping data collection, and Sylvia Sizer, Szymon 431 \nBurzynski and Angela Fieldsend for providing dog pictures. We also thank three 432 \nanonymous reviewers for their helpful comments and suggestions on the manuscript. 433 \nEthical approval had been granted for the University of Lincoln (UK) and all procedures 434 \ncomplied with the ethical guidance of the International Society for Applied Ethology. 435 \n 436 \nReferences 437 \nAdachi I, Kuwahata H, Fujita K (2007) Dogs recall their owner's face upon hearing the 438 \nowner's voice. Anim Cogn 10:17-21  439 \nBrigham JC, Maass A, Snyder LD, Spaulding K (1982) Accuracy of eyewitness 440 \nidentifications in a field setting. J Personal Soc Psychol 42:673-681  441 \nBrown SD, Dooling RJ (1992) Perception of conspecific faces by budgerigars 442 \n(Melopsittacus undulatus): I. Natural faces. J Comp Psychol 106:203-216  443 \nBruce V, Young AW (1998) In the Eye of the Beholder: The Science of Face 444 \nPerception. University Press, Oxford.  445 \nCall J, Brauer J, Kaminski J, Tomasello M (2003) Domestic dogs (Canis familiaris) are 446 \nsensitive to the attentional state of humans. J Comp Psychol 117:257-263  447 \nCoulon M, Deputte BL, Baudoin C (2009) Individual Recognition in Domestic Cattle 448 \n(Bos taurus): Evidence from 2D-Images of Heads from Different Breeds. PLoS 449 \nONE 4: e4441 450 \nDavis SJM, Valla FR (1978) Evidence for domestication of the dog 12,000 years ago in 451 \nthe Natufian of Israel. Nature 276:608-610 452 \nDufour V, Pascalis O, Petit O (2006) Face processing limitation to own species in 453 \nprimates: A comparative study in brown capuchins, Tonkean macaques and 454 \nhumans. Behav Process 73:107-113  455 \nElliott ES, Wills EJ, Goldstein AG (1973) The effects of discrimination training on the 456 \nrecognition of white and oriental faces. Bull Psychon Soc 2:71-73  457 \nFagan JF (1973) Infants' delayed recognition memory and forgetting. J Exp Child 458 \nPsychol 16:424-450  459 \n 19\nFantz RL (1964) Visual Experience in Infants: Decreased Attention to Familiar Patterns 460 \nRelative to Novel Ones. Science 146:668-670 461 \nFarah MJ (1996) Is face recognition \u2018special\u2019? Evidence from neuropsychology. Behav 462 \nBrain Res 76:181-189 463 \nFarah MJ, Wilson KD, Drain M, Tanaka JN (1998) What Is\" Special\" About Face 464 \nPerception? Psychol Rev 105:482-498 465 \nFeddersen-Petersen DU (2005) Communication in Wolves and Dogs. In: Bekoff M (ed) 466 \nEncyclopedia of Animal Behavior, Vol. I, Greenwood Publishing Group, Inc., 467 \nWestport, pp 385-394 468 \nFurton KG, Myers LJ (2001) The scientific foundation and efficacy of the use of 469 \ncanines as chemical detectors for explosives. Talanta 54: 487-500 470 \nG\u00e1csi M, Mikl\u00f3si \u00c1, Varga O, Top\u00e1l J, Cs\u00e1nyi V (2004) Are readers of our face readers 471 \nof our minds? Dogs (Canis familiaris) show situation-dependent recognition of 472 \nhuman\u2019s attention. Anim Cogn 7:144-153  473 \nGibson EJ, Walker AS (1984) Development of knowledge of visual-tactual affordances 474 \nof substance. Child Dev 55: 453-60 475 \nGothard KM, Erickson CA, Amaral DG (2004) How do rhesus monkeys (Macaca 476 \nmulatta) scan faces in a visual paired comparison task? Anim Cogn 7:25-36  477 \nGothard KM, Brooks KN, Peterson MA (2009) Multiple percetual strategies used by 478 \nmacaque monkeys for face recognition. Anim Cogn 12:155-167  479 \nGuo K, Meints K, Hall C, Hall S, Mills D (2009) Left gaze bias in humans, rhesus 480 \nmonkeys and domestic dogs. Anim Cogn 12:409-418  481 \nHare B, Brown M, Williamson C, Tomasello M (2002) The Domestication of Social 482 \nCognition in Dogs. Science 298:1634-1636  483 \nHarris A, Aguirre GK (2008) The representation of parts and wholes in face-selective 484 \ncortex. J Cogn Neurosci 20:863-878 485 \nHunter MA, Ames EW (1988) A multifactor model of infant preferences for novel and 486 \nfamiliar stimuli. Adv Infancy Res 5:69-95 487 \nHussain Z, Sekuler AB, Bennett PJ (2009) How much practice is needed to produce 488 \nperceptual learning ? Vis Res 21:2624-2634 489 \nKendrick KM, Atkins K, Hinton MR, Heavens P, Keverne B (1996) Are faces special 490 \nfor sheep? Evidence from facial and object discrimination learning tests showing 491 \neffects of inversion and social familiarity. Behav Process 38:19-35.  492 \nMarinelli L, Mongillo P, Zebele A, Bono G (2009) Measuring social attention skills in 493 \npet dogs. J Veterinary Behavior: Clin Appl Res, 4: 46-47  494 \n 20\nMartin-Malivel J, Fagot J (2001) Perception of pictorial human faces by baboons: 495 \nEffects of stimulus orientation on discrimination performance. Anim Learn Behav 496 \n29:10-20  497 \nMartin-Malivel J, Okada K (2007) Human and Chimpanzee Face Recognition in 498 \nChimpanzees (Pan troglodytes): Role of Exposure and Impact on Categorical 499 \nPerception. Behav Neurosci 121:1145-1155  500 \nMaurer D, Grand RL, Mondloch CJ (2002) The many faces of configural processing. 501 \nTrends Cogn Sci 6:255-260  502 \nMcCarthy G, Puce A, Gore JC, Allison T (1997) Face-Specific Processing in the 503 \nHuman Fusiform Gyrus. J Cogn Neurosci 9:605-610 504 \nMcKone E, Kanwisher N, Duchaine BC (2006) Can generic expertise explain special 505 \nprocessing for faces? Trends Cogn Sci 11:8-15  506 \nMeints K, Woodford A (2008) Lincoln Infant Lab Package 2008: A new 507 \nprogramme package for IPL, Preferential Listening, Habituation and 508 \nEyetracking [WWW document: Computer software & manual]. URL: 509 \nhttp:\/\/www.lincoln.ac.uk\/psychology\/babylab.htm. 510 \nMichel C, Rossion B, Han J, Chung CS, Caldara R (2006) Holistic processing is finely 511 \ntuned for faces of one\u2019s own race. Psychol Sci 17:608-615 512 \nMikl\u00f3si \u00c1, Kubinyi E, Top\u00e1l J, G\u00e1csi M, Vir\u00e1nyi Z, Cs\u00e1nyi V (2003) A Simple Reason 513 \nfor a Big Difference Wolves Do Not Look Back at Humans, but Dogs Do. Curr 514 \nBiol 13:763-766 515 \nMikl\u00f3si \u00c1, Polg\u00e1rdi R, Top\u00e1l J, Cs\u00e1nyi V. (1998) Use of experimenter-given cues in 516 \ndogs. Anim Cogn 1:113-121  517 \nMiller PE, Murphy CJ (1995) Vision in dogs. J Am Vet Med Assoc 207:1623-34  518 \nMoscovitch M (1997) What Is Special about Face Recognition?: Nineteen Experiments 519 \non a Person with Visual Object Agnosia and Dyslexia but Normal Face 520 \nRecognition. J Cogn Neurosci 9:555-604  521 \nNeiworth JJ, Hassett JM, Sylvester CJ (2007) Face processing in humans and new 522 \nworld monkeys: the influence of experiential and ecological factors. Anim Cogn 523 \n10:125-134  524 \nO'Toole AJ, Deffenbacher KA, Valentin D, Abdi H (1994) Structural aspects of face 525 \nrecognition and the other-race effect. Mem Cogn 22:208-224  526 \nOverman WH, Doty RW (1982) Hemispheric specialization displayed by man but not 527 \nmacaques for analysis of faces. Neuropsychologia 20:113-128  528 \nParr LA, Dove T, Hopkins WD (1998) Why Faces May Be Special: Evidence of the 529 \nInversion Effect in Chimpanzees. J Cogn Neurosci 10 615-622  530 \n 21\nParr LA, Heintz M, Akamagwuna U (2006) Three studies on configural face processing 531 \nby chimpanzees. Brain Cogn 62:30-42 532 \nParr LA, Winslow JT, Hopkins WD (1999) Is the inversion effect in rhesus monkeys 533 \nface-specific? Anim Cogn 2:123-129  534 \nParr LA, Winslow  JT, Hopkins  WD, de Waal FBM (2000) Recognizing Facial Cues: 535 \nIndividual Discrimination by Chimpanzees (Pan troglodytes) and Rhesus Monkeys 536 \n(Macaca mulatta). J Comp Psychol 114:47-60  537 \nParr LA, Heintz M, Pradhan G (2008) Rhesus monkeys (Macaca mulatta) lack 538 \nexpertise in face processing. J Comp Psychol 122:390-402  539 \nParr LA, Heintz M (2008) Discrimination of faces and houses by rhesus monkeys: the 540 \nrole of stimulus expertise and rotation angle.  Anim Cogn 11:467-474  541 \nPascalis O,  Bachevalier J (1998) Face recognition in primates: a cross-species study. 542 \nBehav Process 43:87-96  543 \nPascalis O, Scott LS, Kelly DJ, Shannon RW, Nicholson E, Coleman N, Nelson CA 544 \n(2005) Plasticity of face processing in infancy. Proc Natl Acad Sci 102:5297-5300 545 \nPascalis O, de Haan M (2003) Recognition memory and novelty preference: what a 546 \nmodel? In Hayne H, Fagen J (Eds) Progress in Infancy Research, Vol3, Lawrence 547 \nErlbaum Associates, New Jersey, pp 95-120 548 \nPascalis O, de Haan M, Nelson CA (2002) Is Face Processing Species-Specific During 549 \nthe First Year of Life? Science 296:1321-1323  550 \nPovinelli DJ, Bierschwale DT, Cech CG (1999) Comprehension of seeing as a 551 \nreferential act in young children, but not juvenile chimpanzees. Br J Dev Psychol 552 \n17:37-60  553 \nRiesenhuber M, Wolff BF (2009) Task effects, performance levels, features, 554 \nconfigurations, and holistic face processing: A reply to Rossion. Acta Psychol 555 \n102:286-292 556 \nRossion B, Gauthier I (2002) How Does the Brain Process Upright and Inverted Faces? 557 \nBehav Cogn Neurosci Rev 1:62-74  558 \nRossion B (2008) Picture-plane inversion leads to qualitative changes of face 559 \nperception. Acta Psychol 128 : 274-289 560 \n 561 \nRossion B (2009) Distinguishing the cause and consequence of face inversion: The 562 \nperceptual field hypothesis Acta Psychol 132:300-312 563 \nSangrigoli S, Pallier C, Argenti AM, Ventureyra VAG, de Schonen S (2005) 564 \nReversibility of the Other-Race Effect in Face Recognition During Childhood. 565 \nPsychol Sci 16:440-444 566 \n 22\nSchoon A (1997) The performance of dogs in identifying humans by scent. Ph.D. 567 \nDissertation, Rijksuniveristeit, Leiden. 568 \n 569 \nSekuler AB, Gaspar CM, Gold JM, Bennett PJ (2004) Inversion leads to quantitative, 570 \nnot qualitative, changes in face processing. Curr Biol 14:391-396 571 \nSoproni K, Mikl\u00f3si A, Top\u00e1l J, Cs\u00e1nyi V (2001) Comprehension of human 572 \ncommunicative signs in pet dogs (Canis familiaris). J Comp Psychol 115:122-126 573 \nSugita Y (2008) Face perception in monkeys reared with no exposure to faces. Proc 574 \nNatl Acad Sci 105:394-398 575 \n 576 \nTanaka JW, Farah MJ (1993) Parts and wholes in face recognition. Q J Exp Psychol  577 \n46:225-245 578 \nTanaka JW, Kiefer M, Bukach CM (2004) A holistic account of the own-race effect in 579 \nface recognition: evidence from a cross-cultural study. Cogn 93:1-9  580 \nTarr MJ, Cheng YD (2003) Learning to see faces and objects. Trends Cogn Sci 7:23-30  581 \nTibbetts EA (2002) Visual signals of individual identity in the wasp Polistes fuscatus. 582 \nProc R Soc Lond, Ser B: Biol Sci 269:1423-1428  583 \nTop\u00e1l J, Mikl\u00f3si \u00c1, Cs\u00e1nyi V (1997) Dog-Human Relationship Affects Problem-584 \nSolving Behavior in the Dog. Anthrozoos 10:214-224 585 \nTsao DY, Freiwald WA, Tootell RBH, Livingstone MS (2006) A Cortical Region 586 \nConsisting Entirely of Face-Selective Cells. Science 311:670-674 587 \nValentine T (1988) Upside-down faces: a review of the effect of inversion upon face 588 \nrecognition. Br J Psychol 79:471-491  589 \nVila C, Savolainen P, Maldonado JE, Amorim IR, Rice JE, Honeycutt RL, Crandall 590 \nKA, Lundeberg J, Wayne RK (1997) Multiple and Ancient Origins of the Domestic 591 \nDog. Science 276:1687-1689  592 \nVir\u00e1nyi Z, Top\u00e1l J, G\u00e1csi M, Mikl\u00f3si \u00c1, Cs\u00e1nyi V (2004) Dogs respond appropriately 593 \nto cues of humans\u2019 attentional focus. Behav Process 66:161-172  594 \nWagner SH, Sakovits LJ (1986) A process analysis of infant visual and cross-modal 595 \nrecognition memory: Implications for an amodal code. Adv Infancy Res 4:195\u2013217  596 \nYin RK (1969) Looking at upside-down faces. J Comp Psychol 81:141-145  597 \nYovel (2009) The shape of facial features and the spacing among them generate similar 598 \ninversion effects: A reply to Rossion (2008) Acta Psychol 132:293-299 599 \n 600 \n 601 \n 602 \n 23\nFigure and Table Legends 603 \n 604 \n 605 \n 606 \nFigure 1.  Demonstration of visual stimuli used in a trial. 607 \n 608 \n 609 \n 610 \n 611 \nFigure 2. Example of gaze direction sampled from a dog while viewing the visual 612 \npresentation. 613 \n 614 \n 615 \n 616 \n 617 \n 618 \n 619 \n 24\nFigure 3.  Example of human faces, dog faces and object images used in the testing of   620 \nface discrimination and inversion performance in dogs.  621 \n 622 \n 623 \n 624 \n 625 \n 626 \n 627 \n 628 \n 629 \n 630 \n 631 \n 632 \n 633 \n 634 \n 25\nFigure 4.  Mean percentage and standard deviation of time spent looking at the novel 635 \nand the familiar picture in experiment 2 for each image category (object, 636 \nhuman faces and dog faces) in A upright trials and B inverted trials. 637 \n*Significant difference between the novel and the familiar picture (two tailed 638 \npaired t-test, P<0.05).  639 \n 640 \n 641 \n 642 \n 643 \n 644 \n 645 \n 646 \n 26\nTable 1.   Mean time and standard deviation (mean\u00b1SD), in seconds, spent looking at the 647 \nnovel picture, the familiar picture, \u2018central\u2019 and \u2018out\u2019 of the screen for each 648 \nimage category in upright and inverted trials in experiment 2.  649 \n 650 \n  Novel Familiar Central Out \nUpright 1.73 \u00b1 0.64 1.12 \u00b1 1.80 1.49 \u00b1 0.94 0.92 \u00b1 0.13 Object \nInverted 1.58 \u00b1 0.90 1.34 \u00b1 0.58 1441 \u00b1 731 911 \u00b1 0.13 \nUpright 1.48 \u00b1 0.75 0.99 \u00b1 0.60 1.55 \u00b1 0.89 1.31 \u00b1 0.15 Human face \nInverted 1.53 \u00b1 0.81 1.28 \u00b1 0.68 1.62 \u00b1 0.67 1.84 \u00b1 0.15 \nUpright 1.14 \u00b1 0.55 1.73 \u00b1 0.56 1.49 \u00b1 0.59 0.74 \u00b1 0.71 Dog face \nInverted 1.46 \u00b1 0.77 1.33 \u00b1 0.89 1.56 \u00b1 0.73 0.87 \u00b1 1.20 \n 651 \n 652 \n 653 \n 654 \n 655 \n 656 \n 657 \n 658 \n 659 \n 660 \n 661 \n"}
{"doi":"10.1109\/TMM.2003.814795","coreId":"66648","oai":"oai:dro.dur.ac.uk.OAI2:623","identifiers":["oai:dro.dur.ac.uk.OAI2:623","10.1109\/TMM.2003.814795"],"title":"VSculpt : a distributed virtual sculpting environment for collaborative design.","authors":["Li, F.","Lau, R. W. H.","Ng, F."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2003-12","abstract":"A collaborative virtual sculpting system supports a\\ud\nteam of geographically separated designers\/engineers connected\\ud\nby networks to participate in designing three-dimensional (3-D)\\ud\nvirtual engineering tools or sculptures. It encourages international\\ud\ncollaboration at a minimal cost. However, in order for the system\\ud\nto be useful, two factors need to be addressed: intuitiveness and\\ud\nreal-time interaction. Although a lot of effort has been put into\\ud\ndeveloping virtual sculpting environments, only limited work addresses\\ud\ncollaborative virtual sculpting. This is because in order\\ud\nto support real-time collaborative virtual sculpting, many challenging\\ud\nissues need to be addressed. In this paper, we propose a collaborative\\ud\nvirtual sculpting framework, called VSculpt. Through\\ud\nadapting some techniques we developed earlier and integrating\\ud\nthem with some techniques developed here, the proposed framework\\ud\nprovides a real-time intuitive environment for collaborative\\ud\ndesign. In particular, it addresses issues on efficient rendering and\\ud\ntransmission of deformable objects, intuitive object deformation\\ud\nusing the CyberGlove and concurrent object deformation by multiple\\ud\nclients. We demonstrate and evaluate the performance of the\\ud\nproposed framework through a number of experiments","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/66648.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/623\/1\/623.pdf","pdfHashValue":"b19d34884efe424deb4743739ed7779c63c29fb8","publisher":"IEEE","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:623<\/identifier><datestamp>\n      2011-06-15T15:53:28Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        VSculpt : a distributed virtual sculpting environment for collaborative design.<\/dc:title><dc:creator>\n        Li, F.<\/dc:creator><dc:creator>\n        Lau, R. W. H.<\/dc:creator><dc:creator>\n        Ng, F.<\/dc:creator><dc:description>\n        A collaborative virtual sculpting system supports a\\ud\nteam of geographically separated designers\/engineers connected\\ud\nby networks to participate in designing three-dimensional (3-D)\\ud\nvirtual engineering tools or sculptures. It encourages international\\ud\ncollaboration at a minimal cost. However, in order for the system\\ud\nto be useful, two factors need to be addressed: intuitiveness and\\ud\nreal-time interaction. Although a lot of effort has been put into\\ud\ndeveloping virtual sculpting environments, only limited work addresses\\ud\ncollaborative virtual sculpting. This is because in order\\ud\nto support real-time collaborative virtual sculpting, many challenging\\ud\nissues need to be addressed. In this paper, we propose a collaborative\\ud\nvirtual sculpting framework, called VSculpt. Through\\ud\nadapting some techniques we developed earlier and integrating\\ud\nthem with some techniques developed here, the proposed framework\\ud\nprovides a real-time intuitive environment for collaborative\\ud\ndesign. In particular, it addresses issues on efficient rendering and\\ud\ntransmission of deformable objects, intuitive object deformation\\ud\nusing the CyberGlove and concurrent object deformation by multiple\\ud\nclients. We demonstrate and evaluate the performance of the\\ud\nproposed framework through a number of experiments.<\/dc:description><dc:subject>\n        Collaborative environments<\/dc:subject><dc:subject>\n         Deformable object<\/dc:subject><dc:subject>\n         Rendering<\/dc:subject><dc:subject>\n         Distributed collaboration.<\/dc:subject><dc:publisher>\n        IEEE<\/dc:publisher><dc:source>\n         [Conference proceedings]<\/dc:source><dc:date>\n        2003-12<\/dc:date><dc:type>\n        Conference item<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:623<\/dc:identifier><dc:identifier>\n        issn:1520-9210<\/dc:identifier><dc:identifier>\n        doi:10.1109\/TMM.2003.814795<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/623\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1109\/TMM.2003.814795<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/623\/1\/623.pdf<\/dc:identifier><dc:rights>\n        \u00ae 2003 IEEE. Personal use of this material is permitted. However, permission to reprint\/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE.\\ud\n<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:1520-9210","1520-9210"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2003,"topics":["Collaborative environments","Deformable object","Rendering","Distributed collaboration."],"subject":["Conference item","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n27 May 2008\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nLi, F. and Lau, R. W. H. and Ng, F. (2003) \u2019VSculpt : a distributed virtual sculpting environment for\ncollaborative design.\u2019, UNSPECIFIED.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1109\/TMM.2003.814795\nPublisher\u2019s copyright statement:\n2003 IEEE. Personal use of this material is permitted. However, permission to reprint\/republish this material for\nadvertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists,\nor to reuse any copyrighted component of this work in other works must be obtained from the IEEE.\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n570 IEEE TRANSACTIONS ON MULTIMEDIA, VOL. 5, NO. 4, DECEMBER 2003\nVSculpt: A Distributed Virtual Sculpting\nEnvironment for Collaborative Design\nFrederick W. B. Li, Rynson W. H. Lau, Member, IEEE, and Frederick F. C. Ng\nAbstract\u2014A collaborative virtual sculpting system supports a\nteam of geographically separated designers\/engineers connected\nby networks to participate in designing three-dimensional (3-D)\nvirtual engineering tools or sculptures. It encourages international\ncollaboration at a minimal cost. However, in order for the system\nto be useful, two factors need to be addressed: intuitiveness and\nreal-time interaction. Although a lot of effort has been put into\ndeveloping virtual sculpting environments, only limited work ad-\ndresses collaborative virtual sculpting. This is because in order\nto support real-time collaborative virtual sculpting, many chal-\nlenging issues need to be addressed. In this paper, we propose a col-\nlaborative virtual sculpting framework, called VSculpt. Through\nadapting some techniques we developed earlier and integrating\nthem with some techniques developed here, the proposed frame-\nwork provides a real-time intuitive environment for collaborative\ndesign. In particular, it addresses issues on efficient rendering and\ntransmission of deformable objects, intuitive object deformation\nusing the CyberGlove and concurrent object deformation by mul-\ntiple clients. We demonstrate and evaluate the performance of the\nproposed framework through a number of experiments.\nIndex Terms\u2014Collaborative environments, deformable object\nrendering, distributed collaboration, virtual sculpting.\nI. INTRODUCTION\nWITH THE introduction of distributed virtual environ-ments, we may now interact and work with each other\nvia a local network or through the internet, without physically\ntravel. This encourages collaborative work from international\nparticipants living at different geographical locations. In [1]\nand [2], we proposed a framework to support distributed\nvirtual walkthrough over the Internet, in which progressive\nmultiresolution modeling, caching and prefetching mecha-\nnisms were used to minimize the amount of data sent over the\nnetwork. However, the system does not support collaboration\nnor interaction among the participants.\nIn this paper, we present a framework for distributed vir-\ntual sculpting, called VSculpt. The objective of this work\nis to develop a distributed design environment in which a\ngeographically separated team can manipulate and visualize\ncomplex sculpting work together through the internet. The\nproposed framework will reduce the cost and turnaround time\nof the product design process in manufacturing or in sculpting\nManuscript received August 4, 2001; revised July 17, 2002. This work was\nsupported in part by a DAG grant from City University of Hong Kong under\nProject 7100153 and by a CERG grant from the Research Grants Council of\nHong Kong under Project CityU 1080\/00E). The associate editor coordinating\nthe review of this paper and approving it for publication was Prof. Ryoichi\nKomiya.\nThe authors are with the Department of Computer Science, City University\nof Hong Kong, Kowloon, Hong Kong (e-mail: rynson@cs.cityu.edu.hk).\nDigital Object Identifier 10.1109\/TMM.2003.814795\nartwork. However, in order to develop such a collaborative\nenvironment, many challenging issues need to be addressed,\nincluding real-time processing, rendering, and efficient trans-\nmission of deformable objects. An intuitive sculpting method\nis also needed to allow the user to deform an object with hands.\nIn addition, synchronization techniques and control mecha-\nnisms are needed so that multiple clients may perform object\nsculpting simultaneously. As will be discussed in Section II,\nresearch work on collaborative virtual sculpting is very limited,\ndue to the many unsolved issues. In fact, we are not aware of\nany systems that support interactive collaborative sculpting.\nWe develop VSculpt to address the above issues. The main\ncontributions of this paper include\n\u2022 a framework to support interactive collaborative sculpting\nin a distributed environment, by adapting some of the tech-\nniques we developed earlier and integrating them with\ntechniques proposed here;\n\u2022 a data structure for progressive transmission of de-\nformable objects.\n\u2022 a technique to support concurrent editing of a virtual ob-\nject by multiple clients;\n\u2022 a communication protocol to support synchronized trans-\nmission and object deformation.\nThe rest of this paper is organized as follows. Section II\ngives a survey on related work. Section III gives an overview\nof VSculpt and its architecture. Section IV summarizes our\ndeformable NURBS rendering method. Section V shows how\nthe data structures of a deformable object may be organized\nfor progressive transmission. Section VI introduces the idea of\nediting region and proposes a locking mechanism to support\ncollaborative sculpting. It also shows the client\u2013server and the\nclient\u2013client interactions. Section VII presents some perfor-\nmance results of our prototype system and evaluates the new\nmethod. Finally, Section VIII briefly concludes the paper.\nII. RELATED WORK\nSeveral frameworks and application systems have been\nproposed to support distributed virtual environments. They\ninclude DIVE [3], SIMNET [4], NPSNET [5], MASSIVE [6],\nVLNET [7], and COVEN [8]. These systems mainly address\nissues on user interaction, data replication and optimization\nof data transmission in order to support various applications\nincluding visualization, simulation, training and entertainment.\nSystems developed to support virtual sculpting are mainly\nfor use in a single user environment. Galyean and Hughes\ndeveloped a voxel based technique for virtual sculpting [9].\nUsing a three-dimensional (3-D) tracker, a user may edit a\n1520-9210\/03$17.00 \u00a9 2003 IEEE\nLI et al.: VSculpt: DISTRIBUTED VIRTUAL SCULPTING ENVIRONMENT 571\nvolumetric object by removing\/clearing some voxels. The\nresultant voxel data is then converted to a polygon mesh using\nthe marching-cube algorithm. Another system is THRED\n(Two Handed Refining Editor) [10] developed by Shaw et al.\nto incorporate both hands, each tracked by a 3-D tracker, in\nediting polygonal surfaces. While the dominant hand selects\nand manipulates vertices, the less dominant hand sets the posi-\ntion and orientation of the scene and the level of subdivision of\nthe surface. Kameyama [11] proposed a Virtual Clay Modeling\nSystem. The system uses a special input device with a 3-D\ntracker and a tactile sensor. The tactile sensor is made of arrays\nof pressure sensors and is covered by a soft rubber pad. By\npushing at the tactile sensor, the user may deform an object\nusing his\/her hands. Because the resulting object is in the form\nof grid surface data, it must be converted to a solid model\nbefore it can be used in a design or manufacturing system. The\n3DIVS [12] and the two-handed direct manipulation interface\n[13] are design environments that allow a user, when wearing a\npair of PINCH gloves, to use both hands to manipulate virtual\nobjects. Users can perform a variety of actions by applying\ndifferent PINCH gestures.\nEffort to develop distributed systems for collaborative virtual\nsculpting is very limited. In [14], Nishino et al. proposed a\nmethod for sharing interactive deformation in collaborative\n3-D modeling. In the method, the object for virtual sculpting\nis modeled by implicit surfaces. Each client has its own\nreplica of the object. A client can edit the object only if\nit can obtain an update right of the object from a central\nserver. While a client is sculpting the object, it broadcasts the\nupdate parameters to all the participating clients to update their\ncopies of the object. However, due to the cost of tessellation,\nthe object is not retessellated as it is deforming. After the\nclient finishes the sculpting, it releases the update right by\nacknowledging the server. In [15], Anupam and Bajaj proposed\na collaborative geometric and scientific design environment\ncalled Shastra. Each participant works on a shared hierarchical\ndesign graph of objects. This method enables direct collaboration\nby partitioning the design graph into zones. In regulated mode,\nwhen a particular user is responsible for a zone, other users\nare denied to access that zone. In unregulated mode, a user\ncan manipulate a \u201chot spot\u201d in the design graph by gaining\na prior exclusive control on a FIFO manner. In COVEN\n[8], the concept of \u201cinteraction agent\u201d is introduced, which\nis shared by several participants to manage a collaborative\ninteraction situation. However, it is only a conceptual idea\nand no concrete solution is available.\nThere are several limitations in existing distributed sculpting\nsystems. First, they use a central server to control and grant the\nediting right to the clients. This central server may become a\nbottleneck and degrade both the performance and the interac-\ntivity of the whole sculpting environment. Second, they do not\nsupport concurrent sculpting of the same object. However, in\nsome design applications, it is desirable for multiple users to\nedit the same object together. Finally, these systems totally rely\non the client machines to perform the rendering task. Although\nit can save both the workload of the server and the amount of\ndata transmitted through the network, the expensive retessella-\ntion process may seriously affect the performance of the system.\nAlternatively, some systems simply do not perform the retessel-\nlation process, sacrificing the quality of the output images.\nVSculpt addresses these three problems through the intro-\nduction of a distributed object locking mechanism, the editing\nregion, and a distributed rendering and transmission technique\nfor deformable objects. We will describe these in details later in\nthe paper.\nIII. ARCHITECTURAL OVERVIEW OF VSculpt\nA. Overview of VSculpt\nIn VSculpt, each object is modeled using NURBS surfaces.\nAlthough polygon meshes are widely used in object modeling,\nthe vertex data is very often large in size and therefore time con-\nsuming for transmission. This reduces the interactivity of col-\nlaborative sculpting where model updates are sent over the net-\nwork frequently. NURBS surfaces, however, can be represented\nin a much more compact form, and they can be deformed simply\nby changing the positions of the control points. However, as a\nNURBS surface deforms, we need to retessellate it into poly-\ngons for rendering. Because retessellation is a very expensive\ntask, we adapt our real-time NURBS rendering method [16],\n[17] here to accelerate the rendering of deforming objects in the\nclient machines. Initially, we tessellate the NURBS surfaces of\neach object into a polygon model and compute all the defor-\nmation coefficients. These data structures are then packed into\na linear data structure, called NURBS stream, to facilitate effi-\ncient rendering and progressive transmission. Details of this can\nbe found in Sections IV and V.\nWhen some users want to initiate collaborative sculpting, they\nfirst identify the object for sculpting and the corresponding ob-\nject server will distribute the object to all the relevant client ma-\nchines in the form of a NURBS stream. In order for the user to\nbe able to sculpt the object in an intuitive manner, we adapt our\nvirtual sculpting technique here [18] to allow direct object mod-\nification with the user\u2019s own hands. Each user participate in the\ncollaborative sculpting will wear one or a pair of CyberGloves.\nEach CyberGlove1 is basically an electronic glove that captures\nthe user\u2019s hand and finger gesture. The system will map the Cy-\nberGlove to the object for sculpting, so that the user may deform\nthe object by flexing the hand(s). In order to provide a more\nflexible environment for sculpting, a ray-projection technique is\nused to allow the user to dynamically change the mapping be-\ntween the CyberGlove and the object surface. The CyberGlove\ncan be mapped to the whole object to allow coarse deformation\nor to only a small region of the object to allow fine deformation.\nDetails of this can be found in Section VI.\nWhen a user selects a region of the object for deformation, the\ncontrol points that affect the shape of this region are determined.\nAs the user flexes the hand(s) to deform the region, the new posi-\ntions of the control points will be distributed to all participating\nclients in the form of update messages. When a client receives\nan update message, it can update the data structures to reflect\nthe change in object shape. In the case when a NURBS surface\n1CyberGlove is a trademark of Immersion Corporation, San Jose, CA 95131\nUSA.\n572 IEEE TRANSACTIONS ON MULTIMEDIA, VOL. 5, NO. 4, DECEMBER 2003\nFig. 1. Main components of VSculpt.\nneeds to be refined and the refinement information is not avail-\nable locally, the client may either compute it locally or request\nthe server for it. Details of the client\u2013server and client\u2013client\ncommunications can be found in Sections VI-B and VI-C.\nB. Architecture of VSculpt\nVSculpt is based on a hybrid model which merges the\nclient\u2013server and the peer-to-peer architectures. Every par-\nticipant can be a server or a client. An object server is the\nowner of deformable objects for sculpting. It is responsible\nfor constructing the NURBS stream of each object. A client\nequipped with a CyberGlove may modify the shape of an object\nand broadcasts the updated control points to all the clients\nincluding the object server. Fig. 1 shows the main components\nof VSculpt.\nThe server module consists of four main processes. The\nServer Manager coordinates all other components at the server\nand handles all clients\u2019 requests and updates. The Model Pre-\nprocessor computes a polygon model and a set of deformation\ncoefficients for each deformable object. The data are then sent\nto the Model Serializer, which constructs a NURBS stream\nfrom the polygon model and the set of deformation coefficients.\nThe NURBS stream is then stored in the database for later\ntransmission to the clients upon their requests. Finally, the\nNetwork Agent handles all the communications between the\nserver and the clients, including object requests and object\nupdates.\nThe client also consists of four main processes. The Client\nManager coordinates all components at the client and handles\nall user inputs. It is responsible for requesting the NURBS\nstreams from the server to construct the relevant data structures\nand then passes the information to the graphics engine to be\nmaintained there. The Virtual Sculpting Manager generates\na parametric hand surface for the CyberGlove and performs\nvirtual sculpting based on the user\u2019s hand gesture. The updated\ncontrol points of the deforming object are then sent to the\ngraphics engine via the client manager. The Network Agent\nhandles all the communications between the client and the\nserver, including object requests and object updates. It also\nsends update messages to other clients. Finally, the Graphics\nEngine is responsible for maintaining and updating all the\nobject models downloaded, including deformable models. It\ngenerates output images for display in every frame.\nIV. RENDERING OF DEFORMING OBJECTS\nIn our earlier work, we developed a technique for efficient\nrendering of deformable NURBS surfaces [16], [17]. The basic\nidea of this method is to maintain two data structures of each\nsurface, the surface model and a polygon model representing\nthe surface model. As the surface deforms, the polygon model is\nnot regenerated through tessellation. Instead, it is incrementally\nupdated to represent the deforming surface. There are two tech-\nniques fundamental to our method: incremental polygon model\nupdating and resolution refinement.\nA. Incremental Polygon Model Updating\nIn this technique, we incrementally update a precomputed\npolygon model to represent each deforming surface. To show\nhow it works, we consider the polygonal representation of a sur-\nface obtained by evaluating the surface equation with some dis-\ncrete parametric values. If a control point is moved to\nwith a displacement vector , the incremental\ndifference between the two polygonal representations of the sur-\nface before and after the control point movement is as follows:\n(1)\nwhere and are the polygon models of the sur-\nface before and after the control point movement, respectively.\nis called the deformation coefficient defined as follows:\n(2)\nThe deformation coefficient is a constant for each par-\nticular pair of . Hence, if the resolution of the polygon\nmodel representing the surface remains unchanged before and\nLI et al.: VSculpt: DISTRIBUTED VIRTUAL SCULPTING ENVIRONMENT 573\nafter the deformation, we may precompute the deformation co-\nefficients and update the polygon model incrementally as shown\nin (1). This technique is very efficient since we need to perform\nonly one vector addition and one scalar-vector multiplication on\neach affected vertex of the polygon model. Another advantage\nis that the performance of the method is independent of the sur-\nface complexity.\nB. Resolution Refinement\nWhen a surface deforms, its curvature is also changed. If the\ncurvature is increased or decreased by a large amount during the\ndeformation, the resolution of the polygon model may become\ntoo coarse or higher than necessary to represent the deforming\nsurface, respectively. To overcome this problem, we proposed\na resolution refinement technique to refine the resolution of the\npolygon model and to compute new deformation coefficients\nincrementally according to the change in the surface curvature.\nA NURBS surface is first converted into a set of B\u00e9zier\npatches using knot insertion [19]. Each B\u00e9zier patch is then\nsubdivided into a polygon model by applying the de Casteljau\nsubdivision formula [20] to the Bernstein polynomials in both\nand directions. For example, in , we have\n(3)\nwhere and ,\n. are the homogeneous B\u00e9zier\npoints with , are the weights, and is the degree of\nthe surface. The direction has similar recursion.\nIf we compute the difference of (3) before and after the de-\nformation and then simplify it, we get a de Casteljau formula as\nfollows:\n(4)\nfor , . Equation (4) indicates that\nthe deformation coefficients can be generated incrementally by\nthe de Casteljau subdivision formula.\nHence, if the resolution of the polygon model needs to be\nincreased, the new deformation coefficients can be calculated\nfrom adjacent deformation coefficients stored at existing ver-\ntices using the de Casteljau formula. To achieve a better perfor-\nmance, we implemented this based on the Horner\u2019s formula, of\naverage complexity as opposed to when based on\nthe de Casteljau\u2019s formula.\nV. DEFORMABLE OBJECT TRANSMISSION\nIn our deformable NURBS rendering method, we maintain a\npolygon model of each deformable object in a quadtree struc-\nture. The algorithms for this pointer-based tree structure are re-\ncursive in nature. In addition, the navigation methods associated\nwith these algorithms are often restricted to preorder, inorder\nor postorder tree traversal. If an operation, such as the crack\nprevention process in our rendering method, requires informa-\ntion from neighboring nodes for the comparison of subdivision\nlevels, an additional tree traversal operation is needed to locate\nFig. 2. Z-ordering indexing scheme.\nthe neighboring node starting from the root node, unless extra\npointers are provided to link each node to its neighboring nodes.\nTo overcome this limitation, we propose a new linear data struc-\nture, called NURBS streams, which are used to maintain and\ntransmit the precomputed polygon models of the NURBS sur-\nfaces.\nA NURBS stream is based on the linear quadtree structure\nproposed by [21] using the z-ordering indexing scheme [22].\nIt allows constant navigation time between any node pairs and\nsupports progressive transmission. Fig. 2 illustrates the z-or-\ndering indexing scheme for a linear quadtree. It shows a top view\nof the two possible spatial organizations of a parent node with\nits child nodes , , and . A quadtree is\nassumed to start from level 1, i.e., the root node. Each quadtree\nnode is assigned with an unique index. When assigning an index\nto a node, if the child node is residing at an odd level, we apply\nthe spatial organization shown in Fig. 2(a); otherwise, we apply\nthe one shown in Fig. 2(b).\nA. Indexing Scheme\nA linear quadtree is a pointerless scheme to store a generic\nquadtree in the form of a linear array of nodes. The quadtree\nnodes are ordered by both the z-ordering indexing scheme and\ntheir residing quadtree levels. Each potential node, whether it\nexists or not, is assigned with a static and unique index. For\nexample, the index of the root node is \u201c0\u201d and a node residing at\na deeper quadtree level has a greater index value. Given a node\nof index , we can determine the following:\nParent node index (5)\nChild node indices (6)\nNode level (7)\nWestern neighbor (8)\nEastern neighbor (9)\nNorthern neighbor (10)\nSouthern neighbor (11)\nwhere is the 2D location of the node in the grid of\nnodes at a particular level. and are the precomputed\nlists, called distance vectors, that give the horizontal and ver-\ntical index differences for pairs of neighboring nodes at level ,\nrespectively.\n574 IEEE TRANSACTIONS ON MULTIMEDIA, VOL. 5, NO. 4, DECEMBER 2003\nFig. 3. Structure of a NURBS stream.\nThey are defined as follows:\n(12)\n(13)\nwhere and give the horizontal and vertical index\ndifferences for pairs of neighboring nodes having a relative level\ndistance . and perform similar calculations on\nneighboring nodes in toroidal quadtrees.\nB. The Structure of a NURBS Stream\nUnlike the linear quadtree suggested by Balmelli et al. [22],\na NURBS stream does not consume extra spaces to hold empty\nnodes. This is very important since most quadtrees are likely\nunbalanced. Fig. 3 shows the structure of a NURBS stream. It\nconsists of a header and a sequence of progressive records. The\nheader consists of a surface definition, a node presence list, and a\nroot record. The surface definition consists of the degrees, knots\nand control points of a NURBS surface. In particular, the control\npoints provide an aid for the client to modify the shape of the\nNURBS surface. The degrees and knots help the client determine\nthe deformation region of each control point. The node presence\nlist is an array of Boolean values encoding the presence of nodes\nin the linear quadtree using Balmelli\u2019s index scheme. The root\nrecord stores information of the root quadtree node. Each of the\nprogressive records stores information of a single quadtree node.\nIt consists a set of vertices and a set of deformation coefficients\nassociated with the vertices. The vertices are the list of\ncoordinates of the vertices in the quadtree node. The progressive\nrecords are arranged in ascending order of node indices.\nWhen transmitting a NURBS stream to the client, the server\nfirst sends the header to the client followed by the progressive\nrecords. As the client receives the progressive records, it may\nbegin to refine as well as render the polygon model of the de-\nforming NURBS surface.\nVI. COLLABORATIVE VIRTUAL SCULPTING\nTo provide an intuitive interface for the user, our sculpting\nmethod uses the CyberGlove as an input device for object\nmodification. Our idea is to create a hand surface using the\nbicubic tensor product B-spline interpolating all key data points\nof the CyberGlove [18]. These data points indicate the finger\njoint positions of the user\u2019s hand. The object to be deformed\nis then mapped to the hand surface by ray-projection. With\nray-projection, the user manually specifies the location of a\ncenter of projection, . A set of rays are then projected from\nthrough individual object vertices onto the hand surface to\nestablish a mapping. We refer to the region of the object mapped\nto the hand surface as the Editing Region. Once the mapping is\nestablished, the user may deform the object model simply by\nchanging the hand gesture. During the sculpting process, the user\nmay adjust the location of interactively to change the size of\nthe editing region.\nIn order to support multiuser collaborative virtual sculpting\nin a distributed environment, we need to incorporate a flexible\nlocking mechanism that allows any participant to define and\nlock a region of the object for sculpting. This locking mecha-\nnism must make sure that no other users are editing a region\nbefore locking it for a user and that there are no data inconsisten-\ncies among the participating machines. We present here a simple\nlocking mechanism to do this. We also present the client\u2013server\nand client\u2013client interactions during a sculpting section.\nA. Determining and Locking an Editing Region\nMost earlier systems for distributed virtual environments,\nsuch as SIMNET [4] and MASSIVE-2 [23], do not provide an\nexplicit locking mechanism as they do not consider collabo-\nration. Systems that consider collaboration, such as DIVE [3]\nand PaRADE [24], employ a conservative concurrency control\nto prevent concurrent modification of distributed objects. This\ntype of concurrency control mechanisms, however, does not\nprovide the required interactivity for virtual sculpting.\nIn a collaborative environment, multiple clients may some-\ntimes want to edit the same object simultaneously. If we allow\na client to lock the entire object for sculpting, other clients may\nnot be able to participate. This leads to a bottleneck in collabo-\nrative sculpting. To enhance the collaboration, we allow a client\nto lock only the editing region(s) that he\/she is sculpting, in-\nstead of the whole object. When a client manipulates an editing\nregion of a deformable object, the rest of the object will not be\naffected by this manipulation and can thus be edited by other\nclients concurrently. A client may modify one or more editing\nregion(s) if the regions are available.\nTo determine the boundary of an editing region, we consider\nthe local modification property of NURBS surfaces. If the po-\nsition of a control point is changed, only the shape of the\nsurface within the parameter region\nLI et al.: VSculpt: DISTRIBUTED VIRTUAL SCULPTING ENVIRONMENT 575\n(a)\n(b)\nFig. 4. Virtual sculpting of a human head model.\nis affected, where and are the degrees of the NURBS sur-\nfaces along and parameter directions, respectively. We refer\nto this region as the deformation region. An editing region is the\nunion of deformation regions of all the control points that fall\ninside the hand surface. Fig. 4 shows the sculpting of a human\nhead model with the CyberGlove using our prototype system\ndescribed here. The 6 6 polygon mesh associated with the\nvirtual hand represents the hand surface. The grey region on the\nhuman head model is the editing region.\nTo implement the locking mechanism for sculpting, we main-\ntain at each client an editing list containing a set of Boolean\nflags, each corresponding to a parameter region\nof the object for sculpting. A bit is set to 1 if the cor-\nresponding parameter region is currently manipulated by one of\nthe participants. When a client wants to modify the shape of an\nobject, it first determines the editing region that it is interested in\nand compares the set of parameter regions in the editing region\nwith the editing list. If all parameter regions in the editing list\nare currently set to 0 (i.e., they are all available), the client will\nbe granted the right to sculpt the region and a locking message\nwill be broadcasted to all clients to update the corresponding\nbits of their editing lists.\nHowever, if two clients request for the same editing region at\nnearly thesametime,bothclientsmayfindfromtheir localediting\nliststhattheregionisavailableandstart tosculptthelocalcopiesof\nthe object. This may cause inconsistency. To solve this problem,\nwe introduce a timeout period. After a client has sent a locking\nmessage, it needs to wait for the timeout period. If it does not re-\nceive any locking messages with an earlier timestamp from other\nclients when this period expires, it may start to sculpt. However,\nif the client receives a locking message with an earlier timestamp\nafter this period has already expired, it will then need to roll back\nthe sculpting work to avoid inconsistency.\nThe reason for the introduction of the timeout period is that\nmost users in general do not like the roll-back experience. The\ntimeout period helps resolve most of the concurrent requests and\nhence significantly reduce the number of roll-backs required. To\ndetermine the timeout period, , we need to consider the\ntime needed for a client to send a locking message and for this\nmessage to be received by another client. Hence,\nwhere is the network latency\nbetween the two clients and is the time taken to send\nthe message. is a tolerant factor to compensate for the fluc-\ntuation in the network performance.\nWhen the client finishes the sculpting, it broadcasts a lock\nrelease message to all clients to clear the appropriate bits of the\nediting lists. On the other hand, if a client wants to modify the\nshape of an object and finds that part of or the whole editing\nregion is locked, the client may need to wait until the region is\nreleased. We adopt this distributed locking scheme to eliminate\nthe need for a central server, which may become the bottleneck\ndue to the large number of editing requests.\nB. Client\u2013Server Interactions\nThe distributed virtual sculpting process consists of two\nstages, the preprocessing stage and the run-time stage. The\npreprocessing stage involves only client\u2013server interactions, in\nwhich the client requests the server for objects. The run-time\nstage involves both client\u2013server interactions, in which the\nclient may occasionally request the server for object refinement\ninformation, and client\u2013client interactions, in which a client\nmay frequently send locking messages, update messages, and\nlock release messages to other clients. Fig. 5 shows the major\noperations in the client\u2013server interactions. In the prepro-\ncessing stage, the server constructs a NURBS stream for each\ndeformable object. Upon a client\u2019s request, the server sends the\nNURBS stream to the client as described in Section V. After the\nclient has received the NURBS stream, it refines the polygon\n576 IEEE TRANSACTIONS ON MULTIMEDIA, VOL. 5, NO. 4, DECEMBER 2003\nFig. 5. Client\u2013Server interactions.\nFig. 6. Client\u2013client interactions.\nmodel for rendering according to its own view parameters, such\nas object distance, object moving speed and the viewer\u2019s line\nof sight [25].\nAlthough the advantage of using NURBS surfaces is that they\ncan be infinitely refined, it is not feasible to generate a very high\nresolution NURBS stream to cater for any possible view condi-\ntions as it will be very costly in terms of memory and trans-\nmission cost. Hence, during the preprocessing stage, we may\nonly need to transmit each NURBS stream up to a resolution\nhigh enough for most view conditions. During run-time, a client\nmay occasionally needs to refine a deformable object beyond\nthe resolution of its local NURBS stream, it will then need to\nrequest the server for more refinement information (i.e., pro-\ngressive records) of the NURBS stream.\nC. Client\u2013Client Interactions\nDuring run-time, if a client is sculpting an object, it is re-\nsponsible for broadcasting update messages to all the partici-\npating clients. Each update message contains the ID\u2019s of the set\nof moving control points within the editing region and the up-\ndated positions of these control points.\nWhen a participating client receives an update message, it\nperforms the incremental polygon model updating and resolu-\ntion refinement according to its current view parameters, and\nrenders the resulting polygon model. Fig. 6 shows the main pro-\ncesses and the broadcast messages involved in the client\u2013client\ninteractions.\nVII. RESULTS AND DISCUSSIONS\nWe have implemented various components of the system in\nC++. The server and the client modules communicate using\nTCP\/IP with the BSD Sockets Library. The virtual sculpting\nmanager was implemented with the VirtualHand Library and\nthe GesturePlus Library from Virtual Technology. The graphics\nengine is written in OpenGL and OpenInventor. We tested\nthe system on a SGI Onyx machine with eight 195 MHz\nR10000 processors and a SGI Octane machine with two 250\nMHz R10000 processors, each with only one CPU activated.\nLI et al.: VSculpt: DISTRIBUTED VIRTUAL SCULPTING ENVIRONMENT 577\nTABLE I\nSIZES OF NURBS STREAMS FOR VARIOUS TEST MODELS\nThe Onyx machine was set up as a server while the Octane\nmachine was set up as a client. These machines are physically\nconnected to our university network through 10 Mbps Ethernet\nconnections. At the time of our experiments, the bandwidth\navailable to us was about 2 Mbps.\nA. Experiment 1\nIn this experiment, we perform a number of tests to study the\nperformance in constructing and transmitting NURBS streams.\nThe models used in our experiments are NURBS surfaces with\ndifferent numbers of control points. We apply knot insertion [26]\nto subdivide each object into B\u00e9zier surface patches and con-\nstruct a hierarchical surface on these patches to form a single\nquadtree structure. Table I shows information of each of the test\nmodels, including the number of NURBS control points, the size\nof the NURBS stream and the number of progressive records in\nthe NURBS stream.\nFig. 7 compares the processing time for constructing the\nNURBS streams of the test models. The operations involved\nin constructing a NURBS stream include the generation of an\ninitial polygon model, the construction of a hierarchical surface\nand the computation of the deformation coefficients. From\nthe result, it is found that the construction time of a NURBS\nstream is approximately a polynomial function of the number\nof NURBS control points in the model, i.e., the complexity of\nthe model. In addition, this construction time is generally too\nlong for the NURBS stream to be constructed in real-time. If\nwe let the client handle this process, the user may then need\nto wait for a long time before he\/she may start visualizing or\nmanipulating the object. The situation may be worse if the user\nneeds to simultaneously work on more than one deformable\nobject. Hence, in VSculpt, the server is responsible for\nconstructing the NURBS streams and distributes them to the\nclients progressively to allow efficient model replication.\nFig. 8 compares the time for transmitting the NURBS streams\nof the test models. Results show that the deformable models can\nbe transmitted to the clients in a very short time, and the trans-\nmission time is approximately proportional to the size of the\nNURBS streams. In addition, since NURBS streams support\nprogressive reconstruction, even if the client needs to handle\nmany deformable objects at the same time, it may still be able\nto visualize all the objects. This is because the client may first\nrender the deformable objects in low resolutions and then pro-\ngressively refine their resolutions as more progressive records\nare being received.\nFinally, we would like to study the detailed transmission\nperformance of a NURBS stream. In this test, we used a human\nhead model (Model B) as shown in Fig. 4. The human head\nmodel is a NURBS model with 400 control points. We apply\nknot insertion [26] to subdivide it into 289 B\u00e9zier surface\npatches and then construct a hierarchical surface on these\npatches to form the polygon model for transmission. Table II\nshows the size and the transmission time of the NURBS stream.\nThe NURBS stream is 65.93 Kbytes in size and transmitted in\n0.0772 s. We have also measured the size and the transmission\ntime of the header and of each single progressive record. The\nheader is 5491 bytes in size and takes 6.184 ms to transmit\nto the client. A single progressive record is 152 bytes in size\nand takes 0.174 ms to transmit to the client. If we assume that\nthe Internet bandwidth is about one-tenth of the LAN, i.e.,\nroughly 0.2 Mbps, it will take 0.772 s to transmit the whole\nNURBS stream. However, since the NURBS stream supports\nprogressive reconstruction, the client is expected to be able to\nvisualize a coarse model of the deformable object in a time less\nthan this transmission time.\nB. Experiment 2\nThere are two ways to handle model refinement when a\ndeformable object is undergoing deformation at the client. The\nclient may either perform the resolution refinement process\n(Section IV-B) itself or request the server to transmit more\nprogressive records of the corresponding NURBS stream to the\nclient. In this experiment, we would look at the costs of them.\nTable III shows the computational cost of performing a single\nsubdivision, i.e., from one parent node to produce four child\nnodes, and the transmission cost if the client requests the server\nto transmit the four progressive records of the four child nodes\nto the client. Results show that with the current configuration, it\nis cheaper for the client to simply request the server to transmit\nthe progressive records than to compute them locally. This\nwill also save the CPU time of the client for other time critical\noperations. However, if the client CPU becomes more powerful\nor the network bandwidth becomes too small, at some point, it\nmay be cheaper to perform the resolution refinement locally.\nC. Experiment 3\nExperiment 3 evaluates the transmission performance of dif-\nferent kinds of messages in the client\u2013client interactions as de-\nscribed in Section VI-C. They are the locking messages, lock re-\nlease messages and update messages. Each locking message or\nlock release message contains the editing list. An update mes-\nsage contains the ID\u2019s and the updated positions of the set of\nmoving control points.\nWe perform the experiment with the human head model as\nshown in Fig. 4. The model contains 529 parameter regions. For\nthis model, each locking message or lock release message uses\n4 bytes to store the timestamp and 67 bytes to store the editing\nlist. In our measurement, it took 0.081 ms to transmit through\nour LAN. If we use our default assumption that the Internet is\nabout one-tenth the bandwidth of our LAN, it will takes about\n0.81 ms to transmit a locking message through the Internet.\nTo determine the timeout period, , described in Sec-\ntion VI-A, we need to determine the latency of the network,\n. To do this, we can measure the round-trip time, ,\nof the network using the ping system program. This program\n578 IEEE TRANSACTIONS ON MULTIMEDIA, VOL. 5, NO. 4, DECEMBER 2003\nFig. 7. Processing times for constructing the NURBS streams of the test models.\nFig. 8. Times for transmitting the NURBS streams of the test models.\nTABLE II\nRECORD SIZES AND TRANSMISSION TIMES OF DIFFERENT PARTS OF THE NURBS STREAM\nsends a small packet to a specified host and times the duration\ntaken for this packet to bounce back. is approximately\nequal to half of . Table IV shows some example round-trip\ntimes for different network connections.\nAs an example, if one client is in Hong Kong and the other is\nin the US, is 80 ms. To send a locking message,\nis 0.81 ms. If we set the tolerant factor, , to 1.5, the timeout\nperiod, , will be 121 ms. If both clients are within Hong\nKong, will be 16.2 ms.\nFor the update messages described in Section VI-C, we use\n2 bytes to store each control point ID and 3 bytes to store each\ncoordinate component of the updated positions. In typical situ-\nations, the number of control points simultaneously affected by\nthe sculpting process is no more than 50. Thus, a typical update\nmessage will be no more than 550 bytes in size. In our measure-\nment, it took 0.63 ms to transmit through our LAN. Hence, we\nexpect that it will take about 6.3 ms to transmit an update mes-\nsage through the Internet, which is a very short time. However,\nif there is a need to reduce the size of the update messages, ge-\nometry compression techniques [27], [28] can be applied, which\nwill reduce the size to less than one-third of the current one. On\nthe other hand, if we compare the transmission time of an up-\ndate message with the roundtrip time presented in Table IV, the\nmajor source of delay in transmitting the update message is the\nLI et al.: VSculpt: DISTRIBUTED VIRTUAL SCULPTING ENVIRONMENT 579\nTABLE III\nPERFORMANCE COMPARISON OF DIFFERENT METHODS FOR OBTAINING THE\nREFINEMENT INFORMATION\nTABLE IV\nEXAMPLE ROUND-TRIP TIMES FOR DIFFERENT NETWORK CONNECTIONS\nnetwork latency rather then the size of the message, especially\nif the message is to be sent to an overseas client.\nD. Additional Comments on the Editing List\nIn our method, we use a distributed editing list instead of a\ncentral server to control simultaneous editing of the same object.\nThis can prevent creating a bottleneck at the server and reduce\nthe network latency when the clients raise their requests con-\ntinuously. This method can also be applied in the object level,\nwith a separate editing list to indicate the availability of indi-\nvidual objects. If an object is available for editing, the corre-\nsponding bit of this editing list is clear; otherwise, it is set to\n1. With this locking method, whenever a client raises a request,\nit only needs to lookup its local copy of the editing list. The\nlocking message is sent only if the requested object and editing\nregion are available. Hence, unlike Nishino\u2019s method [14], our\nmethod generates network traffics for successful requests only.\nFor the tessellation process, Nishino\u2019s method does not perform\nretessellation and the model is fixed at a resolution. In our case,\nwe adapt our real-time NURBS rendering technique to allow\nreal-time resolution refinement at the client, optimizing the ren-\ndering performance and improving the output quality.\nE. User Experience\nTo obtain some user experience on the system, we have\nconducted a very preliminary experiment. We have invited two\ngroups of users to test our prototype system. One group of users\nare novice users, who do not have any experience in using the\nCyberGlove. The other group of users are experienced users,\nwho do not only have experience in using the CyberGlove, but\nalso have certain knowledge on geometric modeling. We give\nboth groups of users a short briefing session, but without any\nformal training, on how to operate our prototype system.\nInitially, some of the novice users have some difficulties in\nusing the CyberGlove to change the shape of the object model.\nHowever, they generally can operate our system smoothly after\npracticing for about 10 min or so. Another problem that the\nnovice users encountered is that they get tired with using the Cy-\nberGlove after 20\u201330 min. This is probably because they tend\nto move their arms a lot when they are editing an object. On\nthe other hand, most of the experienced users can operate our\nsystem smoothly in a very short period of time. They gener-\nally find our prototype system much easier to edit objects than\nthe commercial modeling packages. From the feedback of both\ngroups of users, our prototype system is in general very intuitive\nand easy to use. The CyberGlove provides a very natural inter-\nface for editing object models.\nHowever, some of the users have commented that as they are\nediting an object model, they may also want to look around\nthe object to inspect its shape from time to time. Unfortunately,\nsince both of their hands are already occupied, there is no mech-\nanism for them to rotate their view. At one point, we thought\nof attaching a 3-D tracker to the user\u2019s head, but this require\nthe user to wear a head mounted display in order to be useful.\nHowever, existing head mounted displays have their own lim-\nitations too. Our temporarily solution to this problem is from\nobserving how we would do in our daily life when we are phys-\nically changing the shape of an object. When we are molding\nan object, if we need to use both hands to do it, we would fix\nthe object to a device. On the other hand, if we would like to be\nable to inspect the overall shape of an object as we edit it, we\nwould use one hand to hold the object and the other hand to edit\nit. Hence, in our system, if a user wants to be able to inspect an\nobject as he\/she is editing it, then he\/she can only use one hand\nto do the editing, freeing the other hand for controlling the view\npoint.\nVIII. CONCLUSION\nIn this paper, we have presented a framework for real-time\ndistributed virtual sculpting. The framework extends our ear-\nlier work on distributed virtual environment [1], [2] to support\ncollaborative sculpting. To do this, we adapt our real-time tech-\nniques for rendering deformable NURBS surfaces [16], [17] and\nfor virtual sculpting [18] into the new framework. We have intro-\nduced the NURBS streams for transmitting deforming objects\nthrough the network. We have also presented the idea of editing\nregion and the corresponding locking mechanism to allow si-\nmultaneous object sculpting by multiple users. Results show\nthat our method can support interactive collaborative virtual\nsculpting over the Internet.\nREFERENCES\n[1] J. Chim, M. Green, R. Lau, H. Leong, and A. Si, \u201cOn caching and\nprefetching of virtual objects in distributed virtual environments,\u201d Proc.\nACM Multimedia, pp. 171\u2013180, Sept. 1998.\n[2] J. Chim, R. W. H. Lau, H. V. Leong, and A. Si, \u201cCyberWalk: A web-\nbased distributed virtual walkthrough environment,\u201d IEEE Trans. Mul-\ntimedia, vol. 5, pp. 503\u2013515, Dec. 2003.\n[3] C. Carlsson and O. Hagsand, \u201cDIVE\u2014A multi-user virtual reality\nsystem,\u201d in Proc. IEEE VRAIS, 1993, pp. 394\u2013400.\n[4] J. Calvin, A. Dicken, B. Gaines, P. Metzger, D. Miller, and D. Owen,\n\u201cThe SIMNET virtual world architecture,\u201d in Proc. IEEE VRAIS, 1993,\npp. 450\u2013455.\n[5] M. Macedonia, M. Zyda, D. Pratt, P. Barham, and S. Zeswitz, \u201cNPSNET:\nA network software architecture for large scale virtual environments,\u201d\nPresence: Teleop. Virtual Environ., vol. 3, no. 4, pp. 265\u2013287, 1994.\n[6] S. Benford, J. Bowers, L. Fahlen, and C. Greenhalgh, \u201cManaging mutual\nawareness in collaborative virtual environments,\u201d in Proc. ACM VRST,\n1994, pp. 223\u2013236.\n580 IEEE TRANSACTIONS ON MULTIMEDIA, VOL. 5, NO. 4, DECEMBER 2003\n[7] I. Pandzic, T. Capin, E. Lee, N. Thalmann, and D. Thalmann, \u201cA flexible\narchitecture for virtual humans in networked collaborative virtual envi-\nronments,\u201d in Proc. Eurographics\u201997, vol. 16, Sept. 1997, pp. 177\u2013188.\n[8] C. Babski et al., \u201cThe COVEN Project: Exploring applicative, technical\nand usage dimensions of collaborative virtual environments,\u201d Presence:\nTeleop. Virtual Environ., vol. 8, no. 2, pp. 218\u2013236, 1999.\n[9] T. Galyean and J. Hughes, \u201cSculpting: An interactive volumetric\nmodeling technique,\u201d in Proc. ACM SIGGRAPH\u201991, vol. 25, 1991, pp.\n267\u2013274.\n[10] C. Shaw and M. Green, \u201cTHRED: A two-handed design system,\u201d Mul-\ntimedia Syst. J., vol. 5, pp. 126\u2013139, Mar. 1997.\n[11] K. Kameyama, \u201cVirtual clay modeling system,\u201d in Proc. ACM VRST,\nSept. 1997, pp. 197\u2013200.\n[12] F. Kuester, M. Duchaineau, B. Hamann, K. Joy, and A. Uva, \u201c3DIVS:\n3-dimensional immersive virtual sculpting,\u201d in Proc. Workshop on New\nParadigms in Information Visualization and Manipulation, Nov. 1999,\npp. 92\u201396.\n[13] L. Cutler, B. Fr\u00f6hlich, and P. Hanrahan, \u201cTwo-handed direct manipula-\ntion on the responsive workbench,\u201d in Proc. ACM Symp. Interactive 3D\nGraphics, Apr. 1997, pp. 107\u2013114.\n[14] H. Nishino, K. Utsumiya, A. Sakamoto, K. Yoshida, and K. Korida, \u201cA\nmethod for sharing interactive deformations in collaborative 3D mod-\neling,\u201d in Proc. ACM VRST, Dec. 1999, pp. 116\u2013123.\n[15] V. Anupam and C. Bajaj, \u201cShastra: Multimedia collaborative design en-\nvironment,\u201d IEEE Multimedia, vol. 1, no. 2, pp. 39\u201349, 1994.\n[16] F. Li, R. Lau, and M. Green, \u201cInteractive rendering of deforming\nNURBS surfaces,\u201d in Proc. Eurographics\u201997, vol. 16, Sept. 1997, pp.\n47\u201356.\n[17] F. Li and R. Lau, \u201cIncremental polygonization of deforming NURBS\nsurfaces,\u201d J. Graph. Tools, vol. 4, no. 4, pp. 37\u201350, 1999.\n[18] J. Wong, R. Lau, and L. Ma, \u201cVirtual 3D sculpting,\u201d J. Visualization\nComput. Animation, vol. 11, no. 3, pp. 155\u2013166, 2000.\n[19] E. Cohen, T. Lyche, and R. Riesenfeld, \u201cDiscrete B-splines and sub-\ndivision techniques in computer-aided geometric design and computer\ngraphics,\u201d Comput. Graph. Image Process., vol. 14, Oct. 1980.\n[20] P. de Casteljau, \u201cCourbes et surfaces \u00e0 p\u00f4les,\u201d S. A. Andr\u00e9 Citroen, 1959.\n[21] I. Gargantini, \u201cAn effective way to represent quadtrees,\u201d Commun.\nACM, vol. 25, pp. 905\u2013910, Dec. 1982.\n[22] L. Balmelli, J. Kovac\u02c7evic\u00b4, and M. Vetterli, \u201cQuadtrees for embedded\nsurface visualization: Constraints and efficient data structures,\u201d in Proc.\nIEEE ICIP, vol. 2, Oct. 1999, pp. 487\u2013491.\n[23] C. Greenhalgh and S. Benford, \u201cA multicast network architecture for\nlarge scale collaborative virtual environments,\u201d in Proc. . Eur. Conf.\nMultimedia Applications, Services and Techniques (ECMAST \u201997), May\n1997, pp. 113\u2013128.\n[24] D. Roberts and P. Sharkey, \u201cMaximizing concurrency and scalability in\na consistent, causal, distributed virtual reality system, whilst minimizing\nthe effect of network delays,\u201d in Proc. IEEE Workshop on Enabling\nTechnology: Infrastructure for Collaborative Enterprise (WETICE \u201997),\n1997, pp. 161\u2013166.\n[25] R. Lau, D. To, and M. Green, \u201cAn adaptive multi-resolution modeling\ntechnique based on viewing and animation parameters,\u201d Proc. IEEE\nVRAIS, pp. 20\u201327, 1997.\n[26] L. Piegl and W. Tiller, The NURBS Book. Berlin, Germany: Springer-\nVerlag, 1995.\n[27] P. Alliez and M. Desbrun, \u201cProgressive compression for lossless trans-\nmission of triangle meshes,\u201d in Proc. ACM SIGGRAPH\u201901, Aug. 2001,\npp. 195\u2013202.\n[28] A. Khodakovsky, P. Schr\u00f6der, and W. Sweldens, \u201cProgressive geometry\ncompression,\u201d in Proc. ACM SIGGRAPH\u201900, July 2000, pp. 271\u2013278.\nFrederick W. B. Li received both the B.A. (Honors)\nin Computing Studies and M.Phil. degrees from\nthe Hong Kong Polytechnic University in 1994 and\n1998, respectively, and the Ph.D. degree in computer\ngraphics from the City University of Hong Kong in\n2001.\nHe is currently the Research Manager of the\n\u201cWeb-based 3D collaborative engine\u201d project funded\nby the Hong Kong Government Innovation and\nTechnology Fund, Pacific Century CyberWorks\n(PCCW), and Sun Microsystems. His research\ninterests include surface modeling, virtual reality, computer animation and\ncomputer networking.\nRynson W. H. Lau (M\u201988) received a (top) first class\nhonors degree in computer systems engineering in\n1988 from the University of Kent, Canterbury, U.K.,\nand the Ph.D. degree in computer graphics in 1992\nfrom the University of Cambridge, U.K.\nHe is currently an Associate Professor at the City\nUniversity of Hong Kong. Prior to joining the uni-\nversity in 1998, he taught at the Hong Kong Poly-\ntechnic University. From 1992 to 1993, he worked at\nthe University of York, U.K., on a defense project on\nimage processing. His research interests are in com-\nputer graphics, virtual reality and multimedia systems.\nDr. Lau is a member of the IEEE Computer Society and the ACM.\nFrederick F. C. Ng received the B.A. degree\n(Honors) in computing studies from the Hong Kong\nPolytechnic University in 1998.\nHe is currently a Research Student with the\nComputer Science Department, City University of\nHong Kong. His research interests include computer\ngraphics and distributed virtual environments.\n"}
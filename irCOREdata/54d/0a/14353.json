{"doi":"10.1080\/0968776950030118","coreId":"14353","oai":"oai:generic.eprints.org:181\/core5","identifiers":["oai:generic.eprints.org:181\/core5","10.1080\/0968776950030118"],"title":"Multimedia courseware: Never mind the quality how much will it cost to develop?","authors":["Marshall, I. M.","Samson, W. B.","Dugard, P. I."],"enrichments":{"references":[{"id":1043389,"title":"An Inquiry of Time and Cost Estimating for Computer-based Training Courseware Design and Development as Determined by Modified Delphi Method,","authors":[],"date":"1991","doi":null,"raw":"Senbetta, G. (1991) An Inquiry of Time and Cost Estimating for Computer-based Training Courseware Design and Development as Determined by Modified Delphi Method, PhD thesis, Purdue University.","cites":null},{"id":1043388,"title":"Computer-based training (CBT) cost estimating algorithm for courseware (CEAC)',","authors":[],"date":"1988","doi":null,"raw":"Schooley, R. E. (1988), 'Computer-based training (CBT) cost estimating algorithm for courseware (CEAC)', Proceedings of the Interservices Industry Training Systems Conference, 319-28.","cites":null},{"id":201165,"title":"Empirical studies of assumptions that underlie software costestimation models',","authors":[],"date":"1992","doi":"10.1016\/0950-5849(92)90077-3","raw":"116Aa-j Volume 3 Number I Kitchenham, B. A. (1992), 'Empirical studies of assumptions that underlie software costestimation models', Information and Software Technology, 34, 4, 211-18.","cites":null},{"id":201163,"title":"Estimating Computer-based Training Development Times","authors":[],"date":"1987","doi":null,"raw":"Jay, J., Bernstein, K., & Gunderson, S. (1987), Estimating Computer-based Training Development Times (ARI Technical Report No. 765), Research Institute for Behavioural and Social Sciences.","cites":null},{"id":201162,"title":"Estimating time to develop interactive courseware in the 1990s', paper presented at the Interservices Industry Training and Education Conference,","authors":[],"date":"1993","doi":null,"raw":"Golas, K. C. (1993), 'Estimating time to develop interactive courseware in the 1990s', paper presented at the Interservices Industry Training and Education Conference, Orlando FL.","cites":null},{"id":201161,"title":"One man and his dog',","authors":[],"date":"1994","doi":null,"raw":"Baker, J. (1994), 'One man and his dog', Interact, 1, 3, 16-17. Gery, G. (1987). Making CBT Happen: Prescriptions for Successful Implementation of Computer-based Training in your Organisation, Boston, MA, Weingarten.","cites":null},{"id":1043387,"title":"Predicting the development effort of multimedia courseware'","authors":[],"date":"1994","doi":"10.1016\/0950-5849(94)90080-9","raw":"Marshall, I. M., Samson, W. B., Dugard, P. I., & Scott, W. A. (1994), 'Predicting the development effort of multimedia courseware' Information and Software Technology, 36, 5, 251-8.","cites":null},{"id":201164,"title":"The CBT advisor: an expert system program for making decisions about CBT',","authors":[],"date":"1985","doi":"10.1002\/pfi.4150240906","raw":"Kearsley, G. (1985), 'The CBT advisor: an expert system program for making decisions about CBT', Performance and Instruction, 24, 9, 15-17.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"1995","abstract":"This paper evaluates multimedia courseware costing techniques such as the US Airforce Interactive Courseware Method (Golas, 1993), CBT Analyst (Kearsley, 1985), CEAC (Schooley, 1988) and MEEM (Marshall, Samson, Dugard, & Scott, 1994) against the data from ten multimedia courseware developments. The Relative Error and Mean Absolute Relative Error (MARE) are calculated to allow comparison of the different methods","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/14353.pdf","fullTextIdentifier":"http:\/\/repository.alt.ac.uk\/181\/1\/ALT_J_Vol3_No1_1995_Multimedia%20courseware_%20Never%20m.pdf","pdfHashValue":"d9633a63174dfcd025168669784745c5904d112b","publisher":"Universit of Wales Press","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:generic.eprints.org:181<\/identifier><datestamp>\n      2011-04-04T08:49:06Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D4C:4C42<\/setSpec><setSpec>\n      7375626A656374733D4C:4C43:4C4331303232<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/repository.alt.ac.uk\/181\/<\/dc:relation><dc:title>\n        Multimedia courseware: Never mind the quality how much will it cost to develop?<\/dc:title><dc:creator>\n        Marshall, I. M.<\/dc:creator><dc:creator>\n        Samson, W. B.<\/dc:creator><dc:creator>\n        Dugard, P. I.<\/dc:creator><dc:subject>\n        LB Theory and practice of education<\/dc:subject><dc:subject>\n        LC1022 - 1022.25 Computer-assisted Education<\/dc:subject><dc:description>\n        This paper evaluates multimedia courseware costing techniques such as the US Airforce Interactive Courseware Method (Golas, 1993), CBT Analyst (Kearsley, 1985), CEAC (Schooley, 1988) and MEEM (Marshall, Samson, Dugard, & Scott, 1994) against the data from ten multimedia courseware developments. The Relative Error and Mean Absolute Relative Error (MARE) are calculated to allow comparison of the different methods.<\/dc:description><dc:publisher>\n        Universit of Wales Press<\/dc:publisher><dc:date>\n        1995<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:rights>\n        cc_by_nc_nd<\/dc:rights><dc:identifier>\n        http:\/\/repository.alt.ac.uk\/181\/1\/ALT_J_Vol3_No1_1995_Multimedia%20courseware_%20Never%20m.pdf<\/dc:identifier><dc:identifier>\n          Marshall, I. M. and Samson, W. B. and Dugard, P. I.  (1995) Multimedia courseware: Never mind the quality how much will it cost to develop?  Association for Learning Technology Journal, 3 (1).  pp. 110-117.  ISSN 0968-7769     <\/dc:identifier><dc:relation>\n        10.1080\/0968776950030118<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/repository.alt.ac.uk\/181\/","10.1080\/0968776950030118"],"year":1995,"topics":["LB Theory and practice of education","LC1022 - 1022.25 Computer-assisted Education"],"subject":["Article","PeerReviewed"],"fullText":"Multimedia courseware:\nnever mind the quality how much will it cost to develop?\nI. M. Marshall, W. B. Samson and P. I. Dugard\nSoftware Quality Group, Department of Mathematical & Computer Sciences,\nUniversity of Abertay, Dundee\nThis paper evaluates multimedia courseware costing techniques such as the US Airforce\nInteractive Courseware Method (Golas, 1993), CBT Analyst (Kearsley, 1985), CEAC\n(Schooley, 1988) and MEEM (Marshall, Samson, Dugard, & Scott, 1994) against the data\nfrom ten multimedia courseware developments. The Relative Error and Mean Absolute Relative\nError (MARE) are calculated to allow comparison of the different methods.\nIntroduction\nBaker (1994) humorously described the failure of teachers, companies, organizations and\ngovernments over the last twenty-five years to deliver the volume of courseware which\nwould spark the active-learning revolution. Hardware now exists to deliver multimedia,\nbut the cost of developing quality courseware remains high. What chance does\nmultimedia-based active learning have of widespread adoption if developers cannot\nreliably estimate the development effort of multimedia courseware? This paper presents\nexpert estimation of development effort to learner time ratios found in the literature,\nbefore investigating four alternative methods for estimating multimedia development\neffort. The results of the estimates are then compared against the actual project data.\nEstimation of development effort\nThe range of development efforts reported in the literature to produce one learner-hour of\nmultimedia courseware is presented in Table 1.\nAnalysis of the projects included in Table 1 indicates that the values cover a wide range of\ndifferent types of courseware from simple drill and practice exercises (Jay et al, 1987)\nthrough to high-fidelity multimedia simulations (Golas, 1993). This range is reflected in\nthe range of estimates Senbetta (1991) found when experts were asked to estimate\nno\nALT-J Volume 3 Number I\nTable I: Estimates of courseware development effort\nData collection method\nAnecdotal evidence\nAuthor experience\nExpert estimation\nExpert estimation\nDevelopment effort required to\ndeliver one hour of learner time\nLowest\n50\n85\n30\n1:1\nHighest\n350\n300\n1380\n4000\nAuthor\n(Jay, Bernstein, & Gunderson, 1987)\n(Gery, 1987)\n(Golas, 1993)\n(Jay, Bernstein, & Gunderson, 1987)\ndifferent courseware-development effort from detailed specifications. The development\neffort estimates varied by up to 500% from the minimum to the maximum estimate for the\nsame specification.\nUS Airforce Interactive Courseware Method (USAF ICW)\nGolas (1993) developed an Interactive Courseware Estimation Method for the US Air\nForce based on expert opinion of the factors which affect development effort. The\nstarting point is a best-case estimate which is made for the level of course and type of\nbehaviour to be delivered using the criteria listed in Table 2.\nThese values are best-case estimates which are then increased by the appropriate number\nof developer-hours for each factor described in Table 3.\nTable 2: Best cose estimate for interactive courseware\nType of training\nLevel of presentation Knowledge Skill Attitude\nI Basic 30 75 200\nII Medium 75 125 250\nIII High 200 400 600\nThe model has been reviewed and revised using expert opinion but unfortunately no\ninformation exists about external validation using real courseware data.\nTable 3: Factors affecting best case estimates\nFactor\n1 No 'in-house' subject matter experts; must rely solely on the use of customer\nsubject matter expertise\n2 Subject matter is highly complex\n3 Instructional content is unstable. Systems for which interactive courseware is being\ndeveloped are emerging. Tasks for interactive courseware are constantly changing\nIncrease effort for\neach learner hour\n35\n100\n\u2022\n100\nI I I\n\/. M. Marshall et al. Multimedia courseware\nFactor Increase effort for\neach learner hour\n4 Inadequate documentation. No training needs assessment was performed. No task\nanalysisor learning analysis data. Technical manuals are non-existent or are not helpful 20\n5 Total interactive courseware length less than 100 learner hours 20\n6 Interactive courseware developer is not familiar with interactive courseware\nsoftware\/authoring systems 15\n7 Interactive courseware developer is not familiar with target audience 10\n8 Best commercial practices are not acceptable for video, graphics production and\nsoftware development 50\n9 Inexperienced project team:\nInteractive courseware designer inexperienced 80\nInteractive courseware manager inexperienced 100\nInteractive courseware programmer inexperienced 60\n10 Using a beta version of interactive courseware software 80\n11 No prototype exists, no agreement 'up front' on design strategy, no standardized\ndevelopment process followed 50\n12 Customer is not using objective and consistent acceptance criteria. Customer unsure\nof what is wanted and does not communicate with developer 50\n13 Required resources are not in place at start of project 20\nCBT Analyst\nKearsley's (1985) CBT Analyst estimates development effort by asking questions about\nthe courseware to be developed. Based on the answers to twenty-two questions, the\nsoftware produces approximate development effort per learner-hour. Table 4 shows the\ntwenty-two questions asked to estimate the courseware development effort. This result is\nthen modified by the three composite rules described in Table 5.\nTable 4: CBT Analyst's base constraints questions\nQuestion\n1\n2\n3\n4\n5\n6\n7\n8\nWhat type of CBT do you plan to develop? (tutorial,\nsimulation, testing or embedded)\nHow complex is the learning task the CBT course is to be\ndeveloped for?\nWill colour graphics be used?\nWill interactive video or audio be used?\nHow will the courseware be developed?\nDoes a library of CBT routines and graphics exist or\ndoes all programming have to be done from scratch?\nHow much CBT experience does the designer or design\nteam have?\nHow much experience does the developer\/programmer have\nwith the authoring language or system being used?\nLowest value\n0\n0\n0\n0\n0\n-5\n+1\n-5\nHighest value\n+5\n+2\n+5\n+5\n+3\n0\n+5\n0\n112\nALT-J Volume 3 Number I\nQuestion\n9 Is this a new or existing course?\n10. Is the subject matter for the course available or is\nit in the process of being developed?\n11. Is the CBT course being developed for internal use\nor will it be sold commercially?\n12. What kind of branching will the course involve?\n13. Will the answer analysis be simple or complex?\n14. What kind of response will the course involve?\n15. How much learner control will the program have?\n16. What percentage of the course do you anticipate\nhaving to revise each year?\n17. Does a well defined storyboard exist for the CBT\ncourse to be developed?\n18. If the CBT is to be developed by a team, does this team\nhave previous experience developing CBT courses together?\n19. Do written standards, guidelines, or procedures exist for\nCBT development and are they followed?\n20. Is the development effort being managed by an individual\nwith past experience of managing CBT projects?\n21. Is there a single individual responsible for approving\nthe course and revisions to be made?\n22. How would you describe the motivational level of\nthe designer\/developer?\nLowest Value\n0\n0\n0\n0\n0\n0\n0\n0\n-5\n0\n0\n0\n0\n-10\nHighest Value\n+5\n+5\n+5\n+5\n+5\n+5\n+5\n+3\n0\n+5\n+5\n+5\n+5\n0\nTable 5: C\u00dfT Analyst's composite rules\nComposite rule 'Unknown' rating in questions New score\nRule 32 - Inadequate CBT specification 1,13 and 15\nRule 33 - Human factors unknown 20,21 and 22\nRule 34 - Experience unknown 7 and 8\n+10\n+10\n+5\nCBT Analyst then uses this result to select an estimated development effort using the\nvalues in Table 6.\nTable 6: CBT analyst's threshold values and development effort\nThreshold values\n-9999 to 0\n1 to 20\n21 to 50\n51 to 9999\nDevelopment effort per hour of learner time\nUnder 100\n100-200\n200-400\n500+\n113\n\/. M. Marshall et al. Multimedia courseware\nThe upper limit of 500+ developer hours limits the usefulness of the estimate produced,\nbut it does provide a consistent method which is simple to use.\nCost Estimating Algorithm for Courseware (CEAC)\nCEAC (Schooley, 1988) estimates both courseware development effort and cost.\nEstimates are based on project and organization specific inputs as well as an internal\ndatabase of courseware development data. The software uses the following equation to\ncalculate the development effort by summing the contribution of tutorial, drill and\npractice, simulation and certification test elements to the project.\nCertification Test\nDevelopment time = X (CFx CAxLT)x(TMxEFxSFxDVx(l -LSF))\nTutorial\nWhere:\nCF =\nCA =\nLT =\nTM =\nCourseware fraction\nCBT advantage\nLecture equivalent time\nTeaming multiplier\nEF =\nSF =\nDV -\nLSF =\nExperience factor\nSophistication factor\nDatabase values\nLibrary saving fraction\nSchooley found that estimates were within 20% of the actual figure on six of the twelve\nprojects evaluated. CEAC's main strength is the range of factors which contribute to the\nestimate of development effort. However, the internal database is constructed from linear\nprojections of a limited number of data points.\nMultimedia Effort Estimation Model (MEEM)\nThe authors of this paper are currently involved in a project to develop a multimedia cost-\nestimation model. Using courseware-development data from fourteen projects has\nallowed 85% of the variation in development effort to be explained by the use of four\ngrouped cost drivers (Marshall et al, 1994). The model involves rating individual cost\ndrivers under the following groups:\n\u2022 Course Difficulty (CD)\n\u2022 Interactivity (IN)\n\u2022 Development Environment (DE)\n\u2022 Subject Expertise (SE)\nThe individual cost driver is based on expert opinion of key factors which contribute to\ndevelopment effort. At present there are too few projects to generalize these results, but it\ndoes indicate that statistical analysis of development data can form the basis of a cost-\nestimation model.\n114\nVolume 3 Number I\nComparison of Estimates\nThe data from ten of the MEEM projects were used with the three courseware-estimation\nmethods previously described. Table 7 presents the estimates produced by each model,\nalong with the actual development effort and the results from MEEM. The ten projects\nselected each had an estimated learner-time of one hour.\nTable 7: Comparison of estimates and actual development effort\nProject\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nActual\ndevelopment\neffort\n80\n100\n100\n180\n200\n220\n250\n320\n400\n500\nUSAFICW\n165\n420\n50\n85\n420\n165\n120\n120\n420\n590\nCEAC\n349\n319\n174\n137\n879\n172\n191\n174\n319\n3199\nCBT Analyst\n100-200\n200-400\n100-200\n100-200\n2O\u00cdW0O\n100-200\n200-400\n200-400\n20\u00cdM00\n500+\nMEEM\n128\n186\n97\n125\n247\n128\n275\n306\n367\n487\nSchooley (1988) used a measure called relative error to determine the accuracy of the\nCEAC estimation method. The following equation shows the relative error for\ndevelopment effort.\nRelativee =\nActual Effort - Estimated Effort\nActual Effort\nThe relative errors for the four estimation methods for the ten projects are shown in Table\n8. CBT Analyst's results are divided into low and high values to indicate the range of\nvalues produced by this tool.\nBecause the relative error can be greater or less than zero, Mean Relative Error (MRE)\nwould no be a useful summary. Taking the absolute value provides a more useful\nsummary measure. Table 8 shows the Mean Relative Error (MRE) in addition to the\nrelative error for each projects. MEEM produces a MARE of 37%, but this is not\nsurprising because the same data was used in the statistical analysis. CBT Analyst (Low)\nproduces a MARE of 43% with the ten projects used. Despite its relative age, it produces\non average more accurate results than the other newer estimation models with this data\nset.\n115\n\/. M. Marshall et al. Multimedia courseware\nTable 8: Relative error of estimated development effort\nProject\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nMARE\nUSAFICW\n%\n106\n5\n-50\n-53\n320\n-25\n-52\n-62\n110\n18\n79\nCEAC\n%\n336\n-20\n74\n-17\n219\n-21\n-23\n-45\n340\n540\n164\nCBT Analyst\n(Low)\n125\n-50\n0\n^44\n100\n-55\n-20\n-37\n0\n0\n43\nCBT Analyst\n(High)\n150\n0\n100\n11\n300\n-9\n60\n25\n100\n?\n83\nMEEM\nv .\n-60\n8\n3\n30\n187\n42\n-10\n4\n-24\n3\n37\nConclusion\nThe four models used to estimate the development cost of multimedia courseware\nproduced MARE results which range from 37 to 164%. These results support\nKitchenham's (1992) concerns about general software cost-estimation models, and\nindicate the need for specialist models related to the development environment. Further\nresearch is underway to collect data to assist in the development of multimedia cost-\nestimation models, and the rigorous validation of existing models. It is only with the\ndevelopment of a reliable method of estimating development effort that multimedia\ncourseware can hope to sustain the active learning revolution.\nReferences\nBaker, J. (1994), 'One man and his dog', Interact, 1, 3, 16-17.\nGery, G. (1987). Making CBT Happen: Prescriptions for Successful Implementation of\nComputer-based Training in your Organisation, Boston, MA, Weingarten.\nGolas, K. C. (1993), 'Estimating time to develop interactive courseware in the 1990s',\npaper presented at the Interservices Industry Training and Education Conference,\nOrlando FL.\nJay, J., Bernstein, K., & Gunderson, S. (1987), Estimating Computer-based Training\nDevelopment Times (ARI Technical Report No. 765), Research Institute for Behavioural\nand Social Sciences.\nKearsley, G. (1985), 'The CBT advisor: an expert system program for making decisions\nabout CBT', Performance and Instruction, 24, 9, 15-17.\n116\nAa-j Volume 3 Number I\nKitchenham, B. A. (1992), 'Empirical studies of assumptions that underlie software cost-\nestimation models', Information and Software Technology, 34, 4, 211-18.\nMarshall, I. M., Samson, W. B., Dugard, P. I., & Scott, W. A. (1994), 'Predicting the\ndevelopment effort of multimedia courseware' Information and Software Technology, 36,\n5, 251-8.\nSchooley, R. E. (1988), 'Computer-based training (CBT) cost estimating algorithm for\ncourseware (CEAC)', Proceedings of the Interservices Industry Training Systems\nConference, 319-28.\nSenbetta, G. (1991) An Inquiry of Time and Cost Estimating for Computer-based Training\nCourseware Design and Development as Determined by Modified Delphi Method, PhD\nthesis, Purdue University.\n117\n"}
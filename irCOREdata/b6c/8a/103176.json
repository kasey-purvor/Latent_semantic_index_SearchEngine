{"doi":"10.1109\/IJCNN.2009.5178718","coreId":"103176","oai":"oai:epubs.surrey.ac.uk:3034","identifiers":["oai:epubs.surrey.ac.uk:3034","10.1109\/IJCNN.2009.5178718"],"title":"A Computational Platform for Visual Fear Conditioning","authors":["Pavlou, A","Casey, M"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2009","abstract":"Computational models of fear conditioning help us understand the sensory pathways and neural structures underlying fear elicitation in the brain. The majority of the existing models have focused on conditioning on auditory stimuli by simulating the processing of the amygdala, which is the main brain structure implicated in processing fearful stimuli. However, there is now a growing understanding of how fear is elicited from visual stimuli, but as yet we do not have sufficiently capable techniques that can be used to model visual fear conditioning. Masking experiments are a key psychophysics technique that can help us understand these pathways by observing the behavior of the amygdala when presented with visual input that is not consciously perceived (masked). The amygdala's response is indicative of whether it is influenced more by the proposed sub-cortical pathway, than by the cortical pathway. In this paper, we present a computational platform for visual fear conditioning. We use the platform to model the visual pathways leading to the amygdala and with them simulate masking experiments to explore the hypothesis that a sub-cortical pathway exists. The platform uses a modularized Hebbian learning architecture that can organize inputs topographically and condition on multiple stimuli representing visual inputs. We evaluate the properties and behavior of the platform and its capability in simulating masking experiments by comparing our simulation results with those observed for human behavior. Our results provide computational evidence for the influence the sub-cortical pathway has on the amygdala","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:3034<\/identifier><datestamp>\n      2017-10-31T14:07:36Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D636F6E666572656E63655F6974656D<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:436F6D707574696E67<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/3034\/<\/dc:relation><dc:title>\n        A Computational Platform for Visual Fear Conditioning<\/dc:title><dc:creator>\n        Pavlou, A<\/dc:creator><dc:creator>\n        Casey, M<\/dc:creator><dc:description>\n        Computational models of fear conditioning help us understand the sensory pathways and neural structures underlying fear elicitation in the brain. The majority of the existing models have focused on conditioning on auditory stimuli by simulating the processing of the amygdala, which is the main brain structure implicated in processing fearful stimuli. However, there is now a growing understanding of how fear is elicited from visual stimuli, but as yet we do not have sufficiently capable techniques that can be used to model visual fear conditioning. Masking experiments are a key psychophysics technique that can help us understand these pathways by observing the behavior of the amygdala when presented with visual input that is not consciously perceived (masked). The amygdala's response is indicative of whether it is influenced more by the proposed sub-cortical pathway, than by the cortical pathway. In this paper, we present a computational platform for visual fear conditioning. We use the platform to model the visual pathways leading to the amygdala and with them simulate masking experiments to explore the hypothesis that a sub-cortical pathway exists. The platform uses a modularized Hebbian learning architecture that can organize inputs topographically and condition on multiple stimuli representing visual inputs. We evaluate the properties and behavior of the platform and its capability in simulating masking experiments by comparing our simulation results with those observed for human behavior. Our results provide computational evidence for the influence the sub-cortical pathway has on the amygdala.<\/dc:description><dc:date>\n        2009<\/dc:date><dc:type>\n        Conference or Workshop Item<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:rights>\n        attached<\/dc:rights><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/3034\/2\/2009_pavlou_casey_computational_platform.pdf<\/dc:identifier><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/3034\/4\/licence.txt<\/dc:identifier><dc:identifier>\n          Pavlou, A and Casey, M  (2009) A Computational Platform for Visual Fear Conditioning  In: International Joint Conference on Neural Networks, 2009-06-14 - 2009-06-19, Atlanta, GA.     <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/ 10.1109\/IJCNN.2009.5178718<\/dc:relation><dc:relation>\n        10.1109\/IJCNN.2009.5178718<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/3034\/","http:\/\/dx.doi.org\/ 10.1109\/IJCNN.2009.5178718","10.1109\/IJCNN.2009.5178718"],"year":2009,"topics":[],"subject":["Conference or Workshop Item","PeerReviewed"],"fullText":"A Computational Platform for Visual Fear Conditioning\nAthanasios Pavlou and Matthew Casey\nAbstract\u2014 Computational models of fear conditioning help\nus understand the sensory pathways and neural structures\nunderlying fear elicitation in the brain. The majority of the\nexisting models have focused on conditioning on auditory stimuli\nby simulating the processing of the amygdala, which is the\nmain brain structure implicated in processing fearful stimuli.\nHowever, there is now a growing understanding of how fear\nis elicited from visual stimuli, but as yet we do not have\nsufficiently capable techniques that can be used to model visual\nfear conditioning. Masking experiments are a key psychophysics\ntechnique that can help us understand these pathways by\nobserving the behavior of the amygdala when presented with\nvisual input that is not consciously perceived (masked). The\namygdala\u2019s response is indicative of whether it is influenced\nmore by the proposed sub-cortical pathway, than by the cortical\npathway. In this paper, we present a computational platform\nfor visual fear conditioning. We use the platform to model\nthe visual pathways leading to the amygdala and with them\nsimulate masking experiments to explore the hypothesis that\na sub-cortical pathway exists. The platform uses a modular-\nized Hebbian learning architecture that can organize inputs\ntopographically and condition on multiple stimuli representing\nvisual inputs. We evaluate the properties and behavior of the\nplatform and its capability in simulating masking experiments\nby comparing our simulation results with those observed for\nhuman behavior. Our results provide computational evidence\nfor the influence the sub-cortical pathway has on the amygdala.\nI. INTRODUCTION\nFEAR is an innate defense mechanism that preparesorganisms to deal with a potential threat [1]. It is\nnot surprising that the expression of fear is observed in\nanimals and humans alike [2], since ensuring survival is a\nmatter of crucial importance for any organism. The universal\ncharacter of fear has enabled scientists to perform a variety\nof experiments ranging from behavioral studies on animals\n[3] to human brain lesion and functional magnetic resonance\nimaging (fMRI) studies [4] to understand fear. From these\nwe have developed a good understanding of the underly-\ning mechanisms, particularly for the auditory system [3],\n[5]. Computational models have helped us understand the\nauditory fear mechanism [6], however, similar models for\nthe visual pathways have not been developed despite the\nimportance of visual stimuli in provoking fear responses [7],\n[8].\nOur understanding of fear originally came from Pavlovian\n(or classical) conditioning experiments [1]. In these exper-\niments, an otherwise neutral input, called the conditioned\nstimulus (CS) is temporally paired with an aversive input,\ncalled the unconditioned stimulus (US). The US may have\nAthanasios Pavlou and Matthew Casey are with the Department of\nComputing, University of Surrey, Guildford, Surrey, GU2 7XH, UK (phone:\n+44 (0) 1483 689635; fax: +44 (0) 1483 686051 email: {a.pavlou,\nm.casey}@surrey.ac.uk).\nFig. 1. Visual fear conditioning pathways as described in [5], showing\nthe Lateral Geniculate Nucleus (LGN), Lateral Posterior Nucleus (LP),\nBasolateral Amygdala Complex (BLA), Central Amygdaloid Nucleus (Ce),\nPrimary (V1) and Secondary (V2) Visual Cortices, Temporal Cortical Areas\n(TE2), and Perirhinal Cortex (PR).\nthe form of a loud burst of white noise or a foot shock,\nwhile the CS has varied from seeing food [1], lights [3] or\nemotional faces [9]. What these studies have shown is that\nthe evaluation of potentially threatening stimuli is performed\nby a neural structure called the amygdala, located in the\ntelenchephalon.\nThe amygdala appears to receive input from two distinct\nvisual pathways (Fig. 1). The cortical pathway for the visual\nmodality follows the route of the lateral geniculate nucleus\n(LGN) of the thalamus, to visual cortical areas and extras-\ntriate regions. The sub-cortical (direct) pathway is proposed\nto go through the lateral posterior nucleus (LP) (in particular\nthrough the superior colliculus and pulvinar) of the thalamus\nto the amygdala [5], [10]. Although the existence of the\ncortical pathway has been established [3] there is still some\ndebate as to whether the sub-cortical pathway exists [11]. A\ntypical approach to exploring this issue is through masking\nexperiments, which use short presentations of stimuli to\ncontrol conscious versus sub-conscious perception and reveal\nthe participating neural structures, through imaging of active\nbrain areas [4], [9].\nMorris, O\u00a8hman and Dolan [9] conducted a series of\nmasking experiments to explore the existence of the visual\nsub-cortical pathway. In the first phase of their experiments,\nthe subjects were habituated on a number of stimuli (in this\ncase random, sequential presentations of two neutral and\ntwo angry faces at intervals of 15-20 seconds). Second, the\nsubjects were presented with the same stimuli, but with one\nselected as the CS (one of the angry faces), which they were\nthen conditioned on (using 100-dB of white noise). Third,\nall possible pairings of the four inputs were presented to\nthe subjects at 5 second intervals. The first image in a pair\n(the target) was presented for 30ms, followed by the second\nimage immediately (the mask) for 45ms. The aim of this\napproach was to block the conscious perception of the target.\nIn this way the effect of the target would be restricted to\nthe proposed sub-cortical pathway, since the cortical pathway\nrequires longer for the signals to propagate. Although such\npsychophysics experiments provide important evidence on\nthe participating brain structures, it is harder to gain further\nevidence without more invasive or lesioning studies. Here,\ncomputational modeling can help by allowing us to test, for\nexample, the influence of connectivity in an abstract model\nunder controlled conditions.\nIn this paper we present a computational model of visual\nfear conditioning that includes both a cortical and sub-\ncortical pathway to the amygdala. We build directly upon\nthe model used by Armony et al, who used a competitive\nalgorithm to explore auditory fear conditioning [6]. In their\nmodel, Armony et al used a series of interconnected modules,\neach consisting of a single layer of neurons, which were\ncapable of exhibiting simple receptive field properties for\nstimuli representing single auditory frequencies. We first ex-\ntended this model by incorporating topographic organization,\nwhich is a property met in thalamic and early cortical areas\nboth for the visual and auditory modalities (a preliminary\nevaluation of this modified model was reported in [12]). In\nthe work we report here, we have further modified the model\nto change the input to represent the presentation of a target\nand a mask and then evaluated this as a suitable platform\nfor masking experiments. Whereas Armony et al\u2019s work\nreproduced the required conditioning behavior for abstract\nauditory stimuli represented in one dimension, conditioning\non just one example, our extended model can cope with more\ncomplex two-dimensional representations of the visual space\nand condition on multiple stimuli. This increase in capability\nis needed to represent visual processing.\nIn our experiments, we first demonstrate the basic prop-\nerties of our model, such as developing topographic orga-\nnization, conditioning on multiple stimuli, and performing\ncoordinate alignment of the outputs from thalamic modules\nin higher layers. Second, we conduct simulated masking\nexperiments to explore the difference in activation observed\nbetween our model of cortical processing and that of the\namygdala upon presentation of a mask-target pair. In partic-\nular our experiments show that the model can capture some\nof the basic characteristics of the masking experiments such\nas non-conscious perception of target stimuli as well as a\ndependence of the amygdala activations upon thalamic input.\nAlthough our findings are not enough to claim computational\nverification of the visual sub-cortical pathway, our results\ndemonstrate its potential importance, while the model pro-\nvides a computational platform for further experimentation\nof visual fear conditioning.\nII. METHOD\nThe modeling approach followed in this study provides\nan abstract representation of the anatomical structures par-\nticipating in visual fear conditioning (Fig. 3). We note that\nour model does not deal with visual pathway development\nas other models have provided such studies (such as for the\nvisual cortex [13], [14]). Synaptic plasticity between these\nstructures is a property theoretically formulated by Hebb\n[15]. Many studies [16], [17], [18] used variations of synaptic\nplasticity rules in order to study structural and behavioral\nproperties of humans and animals alike. Such a model\nwas developed by Armony et al [6], drawing inspiration\nfrom Rumelhart and Zipser\u2019s competitive algorithm [16],\nand working on similar principals to other Hebbian learning\nmodels [13], [14]. Armony et al\u2019s model explicitly deals with\nfear conditioning of the auditory modality. For this reason our\nwork extends this for visual fear conditioning by introducing\ntopographic representations of the input corresponding to\nfeatures in an abstract visual space. We draw inspiration\nfor topographic organization from Kohonen\u2019s Self-organizing\nMap (SOM) [18], which uses the concept of a neighborhood\nto represent lateral inhibition between neurons. Our extension\nof Armony et al\u2019s model implements a competitive neighbor-\nhood in which a set of winning neurons are rewarded with\na higher degree of weight change compared to those outside\nthe neighborhood, the activations of which are inhibited.\nA. Input Representation\nWe use an abstract representation of visual input for our\nmodel. In developing a model of visual fear conditioning, we\nare attempting to determine whether it can topographically\norganize distinct stimuli, and then condition on one or more\nof these. During initial training, our input representation\nmust therefore aid the establishment of topographic maps.\nThe input must then still be sufficiently flexible to be used\nto test conditioning and at the same time allow us to\ndraw clear conclusions of the model\u2019s properties. Our input\nrepresents a simple visual scene corresponding to a series\nof spatial locations with azimuth [-90, 90] and elevation [-\n65, 65], corresponding approximately to a human\u2019s visual\nfield. Within this, we allow the positioning of an object at\na discrete interval of 10, so that we can encode 19 different\npositions for azimuth and 14 for elevation (Fig. 2a), so for\nexample an input at azimuth -90 and elevation 25 is encoded\nas the co-ordinates (1, 10).\nTo represent a stimulus at each location, we use a simple\nGaussian pattern of activity, such that each stimulus overlaps.\nFor a stimulus at azimuth p and elevation q, we have:\nxpq = \u03bbe\u2212(\np2\u2212q2\n\u03c32 ) (1)\nwhere \u03bb is the maximum amplitude and \u03c3 the radius. Here\nwe use \u03bb = 1 and \u03c3 = 10.\nB. Simulating Masking\nFor the simulation of the masking experiments, we present\nthe model with a pair of inputs at the same time. Since our\nmodel is rate-coded, it assumes the synchronous presentation\nof input for a feedforward pass of the network. In order\nto encode a change in stimulus temporally, such that the\npropagation of activity for one input is still ongoing whilst a\nnew input is presented, we use a simple time delay technique\na) b)\nFig. 2. The representation of a) a single input at (1, 10), and b) a\nmasking input, mask (10, 8) and target (18, 1). Note, during habituation\nand conditioning, the pair of inputs are the same.\nwhereby two inputs from different time steps are presented\nat the same time (Fig. 2b and Fig. 3b).\nThese pairs of images represent the target, which in the\npsychophysics experiments is only presented for 30ms so\nthat it is not consciously perceived, and the mask, which\nis presented for 45ms to allow for conscious perception.\nTherefore the distinct states of our input consist of a) the\npresentation of an identical pair (mask, mask) and b) the\nintroduction of the target which is then masked (mask,\ntarget). During habituation we have a continuous presentation\nof stimuli without masking, and therefore we show pairs of\nidentical inputs (mask, mask). During conditioning the same\nsituation applies, except that one of the stimuli (presented as\na pair) is conditioned on by turning on the US for that input\nonly. Having conditioned, we explore masking by presenting\ntwo different stimuli (mask, target). For example in Fig. 2b,\nthe mask is an input with stimulus at location (10, 8), whereas\nthe target is (18, 1).\nC. Cortical and Sub-cortical Pathway Representation\nThe model is formed from a series of feedforward neural\nmodules that are trained using a competitive learning algo-\nrithm. Fig. 3a) and b) show a schematic of the model, which\nconsists of four modules representing the LGN, LP, early\nvisual cortices (VC) and the amygdala (AM). The cortical\npathway is represented as connections from the LGN and\nLP to the VC, which then feed to the AM. The sub-cortical\npathway feeds the output of the LP direct to the AM. The\nvisual stimulus is input to the LGN and LP. To condition the\nmodel on a stimulus, we use an additional input to the LP\nand AM (equivalent to the US). When conditioning on the\nCS, the value of the US is set to 1 just for this input, and\nat all other times the US is set to 0. The US always has a\nfixed weight value associated with it, which for us is 0.7.\nEach module consists of a lattice of neurons that are fully\nconnected to the input, such that a neuron (i, j) has an output\ny corresponding to an m-dimensional input x:\nuij =\nm\u2211\nk=1\nxkwkij(t) (2)\nyij =\n{\nf(uij) if \u2016cij \u2212 cwin\u2016 < h(t)\nf(uij \u2212 ywin) otherwise (3)\nf(u) =\n\uf8f1\uf8f2\uf8f3 1 u \u2265 1u 0 < u < 10 u \u2264 0 (4)\na) b)\nFig. 3. Schematic of the model showing the Lateral Geniculate Nucleus\n(LGN), Lateral Posterior Nucleus (LP), early visual cortices (VC) and the\namygdala (AM) for a) a single Gaussian input, and b) the mask-target paired\nGaussian input. Note that the masking experiments are conducted on a model\nwith and without the connection from the LP to the AM (red arrow).\nwhere wkij(t) is the weight from input k for neuron (i, j)\nin the lattice at time step t \u2265 0, initialized with uniformly\ndistributed small random values. Note in equation 3 that a\nneuron is considered to be in the winner area if the distance\nfrom the neuron (i, j) to the winner in the lattice is less\nthan the current radius value h(t). Here we use cij and cwin\nto denote the lattice co-ordinates of the two neurons. All\nneurons outside this area are inhibited by the activation value\nof the winning neuron ywin = maxijf(uij).\nThe output y from a module (consisting of the values yij\nfor each neuron) can then be fed into another module directly\nas input. If the output from several modules is combined\n(such as to the VC) or if a module output is combined with\nan input (such as to the AM with the US input), then the\nvectors are concatenated together.\nCompetitive learning in a module is achieved by updat-\ning each weight, except those fixed for the US, and then\nnormalizing all weights to prevent exponential growth:\nw\u2032kij(t+ 1) = wkij(t) + \u000f(t)xkyij (5)\nwkij(t+ 1) =\nw\u2032kij(t+ 1)\u2211m\nl=1 w\n\u2032\nlij(t+ 1)\n(6)\nwhere \u000f(t) is the learning rate at time step t, corresponding to\nthe presentation of a single input. This not only differs from\nArmony et al [6] in the use of a lattice and a neighborhood,\nbut also in equation 5 with all weights being updated, and\nnot just those that have an input that is above average.\nIII. EXPERIMENTS AND EVALUATION\nWe evaluate our model in two ways. First, we evaluate\nwhether the model is adequate at simulating the basic proper-\nties of the neural pathways through its capability in capturing\nthe topographic relationships amongst the input data and\nconditioning on an arbitrary stimulus. Second, we use this\ncomputational platform to simulate the masking experiments\nconducted by Morris et al [9] and record the behavior of\nthe modules both when our simulated sub-cortical pathway\nis connected or not.\nA. Topographic Organization and Conditioning on a Single\nStimulus\nIn this section we evaluate the model\u2019s behavior in orga-\nnizing and conditioning on the abstract visual stimuli being\nused. This evaluation is conducted in two phases. In the\nfirst phase, we train the model on the full set of inputs\nto determine whether each module develops an appropriate\ntopographic organization. The data used for this training\nare the 266 single Gaussian activation patterns described in\nsection II-A.\nTraining of the model takes place in a layered fashion\nso that each module is allowed to develop a topographic\norganization before training the modules it feeds input to.\nThe LGN and LP modules are trained first and then their\noutputs are used to train the VC. Finally, the LP and VC\noutputs feed in, and are used to train, the AM.\nA 10 by 10 lattice of neurons was used for the LGN, LP\nand VC modules, while a 5 by 5 lattice was used for AM.\nThese sizes were chosen because they can adequately repre-\nsent the inputs, without being too computationally expensive,\nwith the smaller map size used for the AM corresponding\nwith studies that attribute a lesser processing capability in\nthe amygdala [6]. We use a Gaussian neighborhood radius\nand an exponential learning rate function that both decrease\nper epoch in a similar way as typically used for SOM (cf.\n[19]):\nh(t) = rmin + (rmax \u2212 rmin)e\u2212(\n(t\/te)\n2\n2r2s\n)\n(7)\n\u000f(t) = lmin + (lmax \u2212 lmin)e\u2212(\n(t\/te)\n2l2s\n)\n(8)\nwhere rmin and rmax are the minimum and maximum radii\nfor the neighborhood and rs is the bandwidth; similarly, lmin,\nlmax and ls for the learning rate. Since the values only vary\nper epoch, te defines the number of time steps per epoch\n(266). Values for these parameters were selected to produce\nstability in the organization over the required number of\nepochs. The same values for these parameters were used\nfor each of the modules except the minimum neighborhood\nradius. Here, rmax was equal to the lattice width (10 or 5),\nrmin was 2 for the LGN, 3 for the LP, 1 for the VC and 4\nfor the AM corresponding to the differing coarseness in each\nmodule, while rs = 300, lmax = 0.1, lmin = 0.001 and\nls = 13. Training lasted for 700 epochs, with each epoch\npresenting all 266 inputs in uniformly random order. This\nwas sufficient for the modules to develop a stable topographic\norganization.\nFig. 4 shows the outputs from each module for stimuli (9,\n1) to (9, 14), which form a strip along the middle of the\ninput space. We observe that the data has been successfully\norganized topographically so that the selected strip of inputs\nis arranged within the map along one orientation. The spread\nof activation for a module for each input corresponds to the\ndifferent neighborhood radii used. For example, the VC has\na very narrow pattern of activation compared to the AM, in\nwhich a large radius was used. Here, the large radius for\nthe AM was selected deliberately to ensure that topographic\na) VC b) AM\nc) LGN d) LP\nFig. 4. Topographic representation of stimuli from (9, 1) to (9, 14) for the\na) VC, b) AM, c) LGN and d) LP. Note the different orientations within\nthe maps of the LGN and LP combined successfully in the VC.\norganization did not occur, so that each neuron\u2019s weights\nwould be updated at each time step. This corresponds to the\nbiological view that the amygdala itself is not topographically\norganized. Note also that the LGN and LP have developed\ndifferent orientations for the same inputs since no such\norientation preference is imposed by the learning algorithm\n(such as through seeding the weights). However, when these\noutputs are merged by the VC module, we notice that both\nrepresentations have been successfully combined.\nHaving successfully trained the model to stability with\nthe desired topographic organization, we now explore what\neffect conditioning has on learning in the maps. Starting\nfrom the pre-conditioning model, we train the model for a\nfurther 530 epochs until the pattern of activation was again\nstable. Here, training is performed on one input feeding\nthrough each module concurrently, rather than sequentially\nas before. All the parameters are the same as at the end\nof the pre-conditioning phase so that the radii of the winner\nareas have all reached their minimum values and the learning\nrate continues to drop with each epoch (continuing on from\n700). For conditioning, we randomly chose one input as the\nconditioned stimulus (CS). For just this one CS input, the\nUS was set to 1, but was 0 for all other inputs.\nOnce training was complete, we observed again the outputs\nfrom each map for each of the 266 inputs (Fig. 5). The CS re-\nsulted in increased activations from all three modules affected\nby conditioning (LP, VC and AM), but without effecting\nthe topographic organization. This topographic representation\ntherefore resulted in the activation of inputs close to the CS\nbeing increased. For example, Fig. 5 shows that the Gaussian\nactivation pattern of the LP module is still preserved, while\nthe VC activation for the conditioned stimulus (6, 7) is\nthe highest, with similar inputs also highly activated: (5,6),\n(5,7), (7,7) and (7,8). The model therefore successfully\na) VC b) AM\nc) LGN d) LP\nFig. 5. Activation values from all 266 inputs for the a) VC, b) AM, c)\nLGN and d) LP. The red dots show the activation values of the selected CS;\nthe blue dots show the neighboring stimuli activation values (for the VC\nonly for comparison); the green dots show the activations of the remaining\ninputs. Note that for any given input only a few neurons are active per\nmodule (for example, the CS in the VC has 1 active neuron, the AM 14,\nthe LGN 5 and the LP 13) while the rest have zero activation. The number\nof neurons active per input depends upon the minimum neighborhood radii\nselected for each module.\ndemonstrates that it can represent our abstract visual stimuli\nappropriately, while demonstrating an increased pattern of\nactivation for an arbitrary conditioned stimulus, which is our\ndesired pattern of behavior from the neural structures that\nare being represented.\nB. Simulation of Masking Experiments\nHaving established a model that appears to have the\nappropriate properties we need, we now use this platform\nto simulate the masking experiments. These experiments\nwere conducted on humans to help provide evidence for\nthe existence of the visual sub-cortical pathway leading to\nthe amygdala, and in this paper we explore our proposed\nmodel as a computational platform for such experiments.\nThis approach offers us the advantage that we can modify\nthe connectivity of the neural structures being simulated to\ntest which are necessary to reproduce the required behavior,\nalbeit constrained by the abstractions we must make to\nestablish the model. Here, we make the assumption that\nour platform sufficiently models the basic behavior of the\nstructures having already observed the ability of the model\nto form topographic maps and appropriately respond to\nconditioning.\nOur computational masking experiments focus on one\naspect of the Morris et al experiments [9]. Here, we are\ninterested particularly in determining whether the model can\nreproduce the increased pattern of activation seen in the\namygdala, but not in the visual cortex, when a target and\nthen a mask are presented to a subject. Using our model,\nwe can test whether the required behavior occurs both with\na) VC b) AM\nc) LGN d) LP\nFig. 6. The maximum activation values for each of the 266 input stimuli\nfollowing habituation in the a) VC, b) AM, c) LGN and d) LP. The\nactivations from stimuli that will be selected as CS are shown in red.\nand without a direct connection from the LP to the AM \u2013\nthe sub-cortical pathway. To achieve this, we follow a similar\npattern of training and testing conducted by Morris et al. First\nwe go through a period of habituation in which the model\nis trained on all the inputs (in identical pairs). Second, we\ncondition the model on a subset of the habituated inputs (CS)\nby continuing training but with the US turned on (1) for the\nselected CS and off (0) for all other inputs. Third, we test the\nmodel using the masking scenarios. Our experiments differ\nin scale to that of the human experiments, with an increased\nnumber of stimuli (4 for Morris et al versus 266) and an\nincreased number of conditioned stimuli (1 versus 14). Apart\nfrom it being easier to use a larger number of stimuli with a\ncomputational model, these increases allow us to determine\nhow robust the results are through exploring generalization\nover a wider range of responses.\nFor our CS stimuli, we choose a strip of 14 inputs\n(18, 1) to (18, 14) near to the edge of the visual space.\nThis selection is deliberately near the edge so that we can\npair these targets with inputs that are distinct for masking\n(a strip over the center of the space). Our input to the\nmodel then comprises a pair of stimuli, as described in\nsection II-B. All of model parameters remain the same as\nbefore, including map sizes, neighborhood and learning rate\nparameters. During habituation, the model was trained on\nall 266 stimuli presented as identical pairs of inputs, and\nreached stability after 700 epochs. For conditioning, all 266\nstimuli were again presented in identical pairs, but with the\nconditioning signal turned on for the CS, reaching stability\nafter 530 epochs. To test the model, we present a mask with\neach of the 14 conditioned targets to the model, where each\nmask follows consecutively. During testing, the conditioning\nsignal is turned off.\na) VC b) AM\nc) LGN d) LP\nFig. 7. The maximum activation values for each of the 266 input stimuli\nfollowing conditioning on the CS in the a) VC, b) AM, c) LGN and d) LP.\nThe activations from the CS stimuli are shown in red.\nFig. 6 shows the maximum activation value from each\nmodule for each of the inputs after habituation. These show\na similar level of activation compared to the results obtained\nfrom just a single input (section III-A), despite the presenta-\ntion of stimuli pairs. No significant differences in activation\nvalues are observed between the stimuli that are chosen to act\nas CS and the rest of the input examples in any of the four\nmodules. In particular, the AM shows the lowest activations\nof all the modules with the CS stimuli showing activations\nwithin the range of 0.02 to 0.06.\nFollowing conditioning on the selected CS stimuli, we\nobserve that the LP, VC and AM show increased activations\nfor the CS (Fig. 7), while the LGN activations remain at the\nsame levels as before (no conditioning signal is applied to the\nLGN). Also, the breadth of the input activations affected by\nconditioning is much larger in the LP because of the different\nminimum radius applied compared to the LGN and VC in\norder to get a different level of map specificity. This time\nthe CS activations of the AM have significantly increased\ncompared to before, and now range from 0.05 to 0.29.\nThe results so far are consistent with the observations\nmade when using single Gaussian activation patterns, and\nshow that the model can adequately handle paired represen-\ntations. Furthermore, we note that the model is also able to\ncondition appropriately on multiple inputs, with all the 14\nCS stimuli provoking a higher response in the LP, VC and\nAM.\nHaving established the trained model, we now simulate\nmasking. Here we present a mask and a target as the pair of\nstimuli and observe the resulting maximum activation values\nin each module. We choose unique mask-target pairings, so\nthat we present the pairs (10, 1) and (18, 1), through to (10,\n14) and (18, 14).\na) VC b) AM\nc) LGN d) LP\nFig. 8. The maximum activation values for the mask-target pairs compared\nto the habituation and conditioning maximum activations for the masks and\nthe targets in the a) VC, b) AM, c) LGN and d) LP. The results are obtained\nfrom a model with a direct LP to AM connection.\nFirst, we assume that there is a connection between the\nLP and the AM: that the sub-cortical pathway influences\nthe amygdala. Fig. 8 shows the maximum activations in\neach module when presented with the mask-target pairs.\nNote that for comparison we show activations obtained after\nhabituation and conditioning for both the 14 masks and the\n14 targets on their own (identical pairs of inputs). In the\nLP, we observe that the activations for the presentation of\nthe mask-target pair (black line) do not differ significantly\nfrom the post habituation responses to either the mask or\nthe target, and hence are not as high as for conditioned\nresponses to the target (red line). In the LGN, the mask-target\nresponses are lower than all other responses; recall that the\nLGN does not receive the US input (is not conditioned). In\nthe VC, the responses for the mask-target inputs are again\nnot significantly different to the post habituation responses\nto either the mask or the target. Since these values are lower\nthan the conditioned responses of the target in the VC, we\nnote that the VC is therefore not responding as if these were\nconditioned responses, and hence is simulating the lack of\na conscious perception of the targets. In contrast, the AM\nshows a mask-target response that is higher than the mask\nconditioned responses in the majority of cases, although\nlower than the activations for the conditioned target. An\nanalysis of variance confirms these observations for the AM\nwith the mask-target response (mean 0.0681) differing with\nstatistical significance to the habituation mask (mean 0.0221,\np < 0.0005) and target (mean 0.0247, p < 0.0009), and\nconditioned mask (mean 0.0100, p < 0.0001), but not sig-\nnificantly different to the target (mean 0.0137, p < 0.0112).\nThese results therefore show that the AM is responding to\nthe target even though the VC is not.\nSecond, we assume that there is no connection between\nthe LP and AM: that the sub-cortical pathway does not\ninfluence the amygdala. To achieve this we re-trained the\nmodel (habituation and conditioning) exactly as before, but\nwithout a connection from the LP to the AM. Fig. 9 shows\nthe maximum activations in each module when presented\nwith the mask-target pairs. Here we note no significant\ndifference between the results for the LP, LGN and VC\ncompared to Fig. 8, since these are connected and trained\nin the same way as before. However, the results for the AM\ndiffer in that they are far lower in value for all responses (with\nonly one set of inputs from the VC, the cumulative input is\nlower), and crucially, do not show any significant difference\nto the conditioned mask response. An analysis of variance\nconfirms these observations with the mask-target response in\nthe AM (mean 0.0027) differing with statistical significance\nto the habituation mask (mean 0.0020, p < 0.0096) and\nconditioned target (mean 0.0061, p < 0.0000002), but not\ndiffering significantly to the habituation target (mean 0.0030,\np < 0.5569) and conditioned mask (mean 0.0023, p <\n0.1957). These results therefore show that the AM is not\nresponding to the target.\nWith the AM responding as expected when the LP is\nconnected to it, but not when this connection is absent, the\nlink between the LP and AM therefore appears necessary\nfor the required behavior to occur. This provides evidence of\nthe influence of the sub-cortical pathway on the amygdala to\nmatch with the human observational data [9]. Although this\nevidence is derived from an abstract, computational model,\nsuch evidence is important in that it can be used to predict\nbehavior and help design new psychophysics experiments,\nsuch as those conducted for auditory stimuli [20].\nIV. CONCLUSION\nThe model presented in this paper supplements and ex-\ntends the work of Armony et al [6] that computationally\nmodeled auditory fear conditioning. It provides an abstract\nrepresentation of the cortical and sub-cortical visual path-\nways leading to the amygdala. To achieve this we modified\nArmony et al\u2019s algorithm to incorporate topographic neigh-\nborhoods into the neural modules, while testing the model\non its capability to condition on multiple two-dimensional\nstimuli.\nHaving defined and evaluated this model, we use it as\na computational platform to simulate masking experiments.\nHere we include a time-delay like second input to the model\nto simulate the presentation of a mask immediately after the\npresentation of a target. This simple extension allows us to\nreproduce behavior observed in human studies, suggesting\nthat this approach provides a suitable platform upon which\nfurther experiments can be conducted.\na) VC b) AM\nc) LGN d) LP\nFig. 9. The maximum activation values for the mask-target pairs compared\nto the habituation and conditioning maximum activations for the masks and\nthe targets in the a) VC, b) AM, c) LGN and d) LP. The results are obtained\nfrom a model that has no direct LP to AM connection.\nAs a concrete example of how the platform can be used,\nwe tested the hypothesis that the sub-cortical visual pathway\nis crucial in provoking a higher level of activation from the\namygdala when a particular target image is processed, but\nnot consciously perceived in the visual cortex. We evaluated\nthe behavior of the model both with and without this sub-\ncortical connection and compared the results. When either\nthe sub-cortical pathway is connected or not, the LP, VC\nand AM show significantly higher levels of activation in\nresponse to the CS compared to the non-conditioned stimuli,\nwhen each stimulus is presented as an identical pair of\nimages to the model (not masking); the LGN in contrast\nshows no such difference because it is not conditioned. This\nmeans that the model is correctly responding to conditioning.\nWhen simulating masking, both whether the sub-cortical\npathway influences the AM or not, the VC shows levels of\nactivation that are commensurate with the target not being\nconsciously perceived (lower levels of activation compared to\nthe conditioned responses) demonstrating that the platform is\nsimulating the required masking effects. However, only when\nthe sub-cortical pathway is connected does the AM have the\nhigher levels of activation associated with the conditioned\nresponses when masking. Without this connection, the AM\nresponds with low activation levels, despite being capable\nof responding correctly when only the target is presented\nwithout the mask. This example provides computational\nevidence of the effect that the sub-cortical pathway has on\nthe behavior of the amygdala, and therefore provides an\nindication that the pathway exists.\nAs an abstraction, our platform has two key limitations\nthat need further work. First, the model uses a simple rate\ncoding scheme that assumes the synchronous presentation of\nsignals. Although our masking experiments overcome this\nthrough a time delay, a pulse coded model may offer a\nbetter way of simulating masking, provided an appropriate\nadaptive modular architecture could be developed that can\nsimulate conditioning. Second, for this evaluation we have\nused abstract input representations that have enabled us to\ntest the capabilities of the model to simulate conditioning\nand masking. Preliminary work has shown that the model can\ncondition and classify upon presentation of more complex\ninputs, such as emotional face images [12], but we now\nneed to explore more realistic data with masking. To achieve\nthis a better understanding of the processing in the retina\nand thalamus is required to develop better approaches to\nlow level visual processing. This may need us to consider\nfeedback connections between and within modules beyond\nthat simulated with neighborhoods.\nACKNOWLEDGMENT\nWe would like to thank the four anonymous reviewers for\ntheir helpful comments and suggestions.\nREFERENCES\n[1] I. P. Pavlov, Conditioned Reflexes: An Investigation of the Physiologi-\ncal Activity of the Cerebral Cortex. London: Oxford University Press,\n1927.\n[2] J. E. LeDoux, \u201cEmotion circuits in the brain,\u201d Annual Reviews Neu-\nroscience, vol. 23, pp. 155\u2013184, 2000.\n[3] \u2014\u2014, \u201cEmotion, memory and the brain,\u201d Scientific American Special\nEdition, vol. 12, no. 1, pp. 62\u201371, 2002.\n[4] K. S. Labar, J. C. Gatenby, J. C. Gore, J. E. LeDoux, and E. A. Phelps,\n\u201cHuman amygdala activation during conditioned fear acquisition and\nextinction: a mixed-trial fmri study,\u201d Neuron, vol. 20, pp. 937\u2013945,\n1998.\n[5] C. Shi and M. Davis, \u201cVisual pathways involved in fear conditioning\nmeasured with fear-potentiated startle: Behavioral and anatomic stud-\nies,\u201d The Journal of Neuroscience, vol. 21, no. 24, pp. 9844\u20139855,\n2001.\n[6] J. L. Armony, D. Servan-Schreiber, J. D. Cohen, and J. E. LeDoux, \u201cAn\nanatomically constrained neural network model of fear conditioning,\u201d\nBehavioral Neuroscience, vol. 109, no. 2, pp. 246\u2013257, 1995.\n[7] A. O\u00a8hman, D. Lundgvist, and F. Esteves, \u201cThe face in the crowd\nrevisited: A threat advantage with schematic stimuli,\u201d Journal of\nPersonality and Social Psychology, vol. 80, no. 3, pp. 381\u2013396, 2001.\n[8] A. O\u00a8hman, A. Flykt, and F. Esteves, \u201cEmotion drives attention:\nDetecting the snake in the grass,\u201d Journal of Experimental Psychology:\nGeneral, vol. 130, no. 3, pp. 466\u2013478, 2001.\n[9] J. S. Morris, A. O\u00a8hman, and R. J. Dolan, \u201cA subcortical pathway to the\nright amygdala mediating \u201cunseen\u201d fear,\u201d Proceedings of the National\nAcademy of Sciences, vol. 96, pp. 1680\u20131685, 1999.\n[10] N. N. Doron and J. E. LeDoux, \u201cOrganization of projections to the\nlateral amygdala from auditory and visual areas of the thalamus in the\nrat,\u201d The Journal of Comparative Neurology, vol. 412, pp. 383\u2013409,\n1999.\n[11] L. Pessoa, \u201cTo what extent are emotional visual stimuli processed\nwithout attention and awareness,\u201d Current Opinion in Neurobiology,\nvol. 15, pp. 188\u2013196, 2005.\n[12] A. Pavlou and M. C. Casey, \u201cIdentifying emotions using topographic\nconditioning maps,\u201d in Proceedings of the International Neural Net-\nwork Society - New Directions in Neural Networks Symposia (INNS-\nNNN 2008). Springer-Verlag, in press.\n[13] R. Linsker, \u201cSelf-organization in a perceptual network,\u201d Computer,\nvol. 21, no. 3, pp. 105\u2013117, 1988.\n[14] R. Miikkulainen, J. A. Bednar, Y. Choe, and J. Sirosh, Computational\nMaps in the Visual Cortex. New York: Springer Science+Business\nMedia, 2005.\n[15] D. O. Hebb, The Organization of Behavior: A Neuropsychological\nTheory. New York: John Wiley & Sons, 1949.\n[16] D. E. Rumelhart and D. Zipser, \u201cFeature discovery by competitive\nlearning,\u201d in Parallel Distributed Processing: Explorations in the\nMicrostructure of Cognition, D. E. Rumelhart and J. L. McClelland,\nEds. MIT Press, 1986, vol. Volume 1: Foundations, book chapter 5,\npp. 151\u2013193.\n[17] C. von der Malsburg, \u201cSelf-organization of orientation sensitive cells\nin the striate cortex,\u201d Kybernetik, vol. 14, no. 2, pp. 85\u2013100, 1973.\n[18] T. Kohonen, \u201cSelf-organized formation of topologically correct feature\nmaps,\u201d Biological Cybernetics, vol. 43, pp. 59\u201369, 1982.\n[19] \u2014\u2014, Self-Organizing Maps, 2nd ed. Berlin, Heidelberg, New York:\nSpringer-Verlag, 1997.\n[20] J. L. Armony, D. Servan-Schreiber, L. M. Romanski, J. D. Cohen, and\nJ. E. LeDoux, \u201cStimulus generalization of fear responses: Effects of\nauditory cortex lesions in a computational model and in rats,\u201d Cerebral\nCortex, vol. 7, no. 2, pp. 157\u2013165, 1997.\n"}
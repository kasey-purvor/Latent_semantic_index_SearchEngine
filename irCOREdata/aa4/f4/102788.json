{"doi":"10.1109\/ISTMWC.2007.4299326","coreId":"102788","oai":"oai:epubs.surrey.ac.uk:2326","identifiers":["oai:epubs.surrey.ac.uk:2326","10.1109\/ISTMWC.2007.4299326"],"title":"Content adaptation for virtual office environment using scalable video coding","authors":["Hewage, CTER","Arachchi, HK","Masterton, T","Yu, AC","Uzuner, H","Dogan, S","Kondoz, AM"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-01-01","abstract":"Virtual collaboration concept allows remotely located partners to meet in a virtual environment using the state of the art communication and digital multimedia technologies. A virtual collaboration system is being developed under VISNET II network of excellence of the IST FP6 programme. This paper elaborates on a virtual collaboration scenario and proposes content adaptation technologies to fulfil needs of all participants. The proposed content adaptation techniques are based on scalable video coding. The content adaptation based on user preferences, profiles for usage, terminal and network capabilities are discussed. Initial experimental results have been proved to be effective and productive for a virtual office environment","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":"IEEE","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:2326<\/identifier><datestamp>\n      2017-01-04T11:37:32Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:656C656374726F6E6963656E67696E656572696E67:63637372<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/2326\/<\/dc:relation><dc:title>\n        Content adaptation for virtual office environment using scalable video coding<\/dc:title><dc:creator>\n        Hewage, CTER<\/dc:creator><dc:creator>\n        Arachchi, HK<\/dc:creator><dc:creator>\n        Masterton, T<\/dc:creator><dc:creator>\n        Yu, AC<\/dc:creator><dc:creator>\n        Uzuner, H<\/dc:creator><dc:creator>\n        Dogan, S<\/dc:creator><dc:creator>\n        Kondoz, AM<\/dc:creator><dc:description>\n        Virtual collaboration concept allows remotely located partners to meet in a virtual environment using the state of the art communication and digital multimedia technologies. A virtual collaboration system is being developed under VISNET II network of excellence of the IST FP6 programme. This paper elaborates on a virtual collaboration scenario and proposes content adaptation technologies to fulfil needs of all participants. The proposed content adaptation techniques are based on scalable video coding. The content adaptation based on user preferences, profiles for usage, terminal and network capabilities are discussed. Initial experimental results have been proved to be effective and productive for a virtual office environment.<\/dc:description><dc:publisher>\n        IEEE<\/dc:publisher><dc:date>\n        2007-01-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/2326\/1\/SRF002305.pdf<\/dc:identifier><dc:identifier>\n          Hewage, CTER, Arachchi, HK, Masterton, T, Yu, AC, Uzuner, H, Dogan, S and Kondoz, AM  (2007) Content adaptation for virtual office environment using scalable video coding   2007 PROCEEDINGS OF THE 16TH IST MOBILE AND WIRELESS COMMUNICATIONS, VOLS 1-3.  pp. 1479-1483.      <\/dc:identifier><dc:relation>\n        http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=4299326<\/dc:relation><dc:relation>\n        10.1109\/ISTMWC.2007.4299326<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/2326\/","http:\/\/ieeexplore.ieee.org\/xpls\/abs_all.jsp?arnumber=4299326","10.1109\/ISTMWC.2007.4299326"],"year":2007,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"   \nAbstract\u2014Virtual collaboration concept allows remotely \nlocated partners to meet in a virtual environment using the state \nof the art communication and digital multimedia technologies. A \nvirtual collaboration system is being developed under VISNET II \nNetwork of Excellence of the IST FP6 programme. This paper \nelaborates on a virtual collaboration scenario and proposes \ncontent adaptation technologies to fulfil needs of all participants. \nThe proposed content adaptation techniques are based on scalable \nvideo coding. The content adaptation based on user preferences, \nprofiles for usage, terminal and network capabilities are \ndiscussed. Initial experimental results have been proved to be \neffective and productive for a virtual office environment. \n \nIndex Terms\u2014Virtual Collaboration, Content Adaptation, \nScalable Video Coding, H.264.  \nI. INTRODUCTION \nHE success of the Internet and mobile systems has \nmotivated the development of various enhanced-capacity \nfixed and wireless networking technologies (e.g., 3G, WLAN, \nWiMAX, broadband Internet etc). The services supported by \nsuch networks help foster the vision of being connected at \nanywhere, anytime and with any device for pervasive media \napplications. Virtual collaboration system (VCS) allows \nremotely located partners to meet in a virtual environment \nusing the state of the art communication and audiovisual \ntechnologies. In a virtual office environment, all remotely \nlocated partners will feel the sensation of being in a single \nroom regardless of their true geographical location. Fig. 1 \ndemonstrates a context diagram of a virtual collaboration \nscenario.  \nThis paper presents content adaptation mechanisms for the \nVCS described by VISNET II Network of Excellence (NoE) \n[1] of the IST FP6 programme. The VCS is currently being \ndesigned by the NoE partners in order to achieve cross-theme \nintegration by bringing together the work performed in the \n \n[1]\n C. T. E. R. Hewage, H. Kodikara Arachchi, A. C. Yu, H. Uzuner, S. \nDogan, and A. M. Kondoz are with the I-Lab\/Centre for Communication \nSystems Research (CCSR), University of Surrey, Guildford GU2 7XH, \nSurrey, UK (Tel: +44 (0) 1483 686002; Fax: +44 (0)1483 686011; e-mails: \n{E.Thushara, H.Kodikaraarachchi, C.Yu, H.Uzuner, S.Dogan, \nA.Kondoz}@surrey.ac.uk). \n[2]\n T. Masterton is with Thales Research and Technology (UK) Ltd., \nWorton Drive, Worton Grange Business Park, Reading RG2 0SB, Berkshire, \nUK (Tel: +44 (0) 1189 238266; Fax: +44 (0) 1189 238399; e-mail: \ntim.masterton@thalesgroup.com). \nthree VISNET II themes, namely video coding, audiovisual \nmedia processing and security, using Virtual Collaboration as \nan integration driver. In the following sections, the discussion \nwill focus on the content adaptation as applicable to virtual \ncollaboration scenarios. \n \nFig. 1: Virtual collaboration context diagram \n \nIn the virtual collaboration scenario as shown in Fig. 1, \nlarge fixed-terminal acts as the main control\/command point \nand serves for group of co-located users. This may be the \nheadquarters of the organization and consists of \ncommunication terminals, shared desk spaces, displays and \nvarious user interaction devices to collaborate with remotely \nlocated partners. The remotely located users with a small, \nfixed terminal will act as the local contact and provide the \nlocal information. Mobile units (distribution, surveying, \nmarketing, patrolling, etc) of the organization will use mobile \nterminals such as mobile phones and PDAs to collaborate with \nthe headquarters. The top level system decomposition of the \nVCS with a terminal for each group of co-located users is \ngiven in Fig. 2. The gateway associated with each terminal \nmay be a part of the terminal or the interconnection depending \non the implementation. For example, it is likely to be included \nin the large multi-user terminal but separated by a wireless link \nfrom the small mobile terminal. Remote services provide \npersistent storage and workflows, authorization and awareness \nof other users\u2019 connectivity. \nAll remotely located collaborators use range of terminal \ndevices with different capabilities. For example small mobile \nterminals may have different display sizes, stream handling \ncapabilities (speech, video, scalable video, etc), processing \nContent Adaptation for Virtual Office \nEnvironment Using Scalable Video Coding \nC. T. E. R. Hewage,[1] H. Kodikara Arachchi,[1] T. Masterton,[2] A. C. Yu,[1] H. Uzuner,[1] S. Dogan,[1] \nand A. M. Kondoz[1] \nT \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 12,2010 at 16:28:32 UTC from IEEE Xplore.  Restrictions apply. \n power and memory capacity compared to large fixed terminals \nin the headquarters, which provides rich multimedia in an \nunrestricted environment (large displays, broadband \ncommunication links with high processing power). \n \n User (1..n) \nLarge \nmulti-user \nTerminal \nUser \nSmall \nsingle-user \nTerminal \nSmall \nsingle-user \nGateway \nInternet \n \nAuthorisation \nService \nPresence \nService \nPersistence \nService \nWireless \nGateway \nUser \nSmall \nmobile \nTerminal \nLarge \nmulti-user \nGateway \n \nFig. 2: Virtual collaboration functional decomposition \n \nFurthermore, the coexistence of the different networking \ninfrastructures and services has also led to an increased \nheterogeneity of compressed video communication systems in \na virtual office scenario, in which a wide range of user-\nterminals with various capabilities access multimedia content \nover a multitude of access networks with different \ncharacteristics. \nNot only do the network and\/or user terminal based \ncharacteristics, but also users themselves play a major role in \nchoosing the way content is distributed. A remote collaborator \nmay have the interest of a particular area of the collaborative \nvideo and VCS should be able to provide the region of interest \n(ROI). In order to improve the quality of service (QoS), \ncontent adaptation mechanisms need to be implemented in this \ndiverse multimedia distribution and consumption environment.  \nA. Content Adaptation \nThe mismatches between the content properties and several \nnetwork and\/or device-centric features, as well as diverse user \npreferences in a virtual collaboration scenario call for efficient \nmultimedia delivery systems, featuring effective content \nadaptation mechanisms [2]. The content adaptation \nmechanisms will improve the subjective quality of the user \nexperience in a virtual office scenario. Furthermore, this \nimproves the effectiveness and overall productivity of the \ncollaborated activities. In general, content adaptation concept \nhas been addressed in literature with the theme of the universal \nmultimedia access (UMA) [3][4]. Several strategies have been \ndeveloped for UMA, which are based on the multimedia \ncontent adaptation techniques using the context specifications \nand descriptions defined in Part-7: Digital Item Adaptation \n(DIA) of the MPEG-21 standard [5][6][7]. \nAn effective way of performing content adaptation is to \nutilise transcoding operations in the networks. Transcoding is \nparticularly needed when compressed media streams traverse \nheterogeneous networks. In such cases, a number of content-\nspecific properties of the coded multimedia information \nrequire adaptation to new conditions imposed by the different \nnetworks and\/or terminals to retain an acceptable level of \nservice quality. Network based adaptation mechanisms can be \nemployed at the edges or other strategic locations of different \nnetworks (at terminal gateways, see Fig. 2), using a fixed-\nlocation content adaptation gateway, node or proxy as in \nconventional networking strategies ([8][9]). Alternatively, \ncontent adaptation through transcoding can be performed \ndynamically where and whenever needed using active \nnetworking technologies [10]. In a virtual collaboration \nscenario, content can be adapted using transcoding based on \ntwo main approaches depending on the scalability of the \nmultimedia content. If the original content is scalable, a sub-\nstream can be extracted depending on the terminal\/network \ncapabilities and user preference. In the second approach, the \nnon-scalable content will be reprocessed to suit user \npreferences and capabilities. However, transcoding of non-\nscalable content requires high computational power at network \nnodes and incurs heavy delays. Therefore, this approach is not \nconsidered for the VCS. Hence, the rest of the paper focuses \non transcoding of scalable content in a virtual collaboration \nscenario.       \nThis paper proposes content adaptation mechanisms to be \nused in a virtual collaboration scenario based on scalable \nvideo coding (SVC) approach. SVC is a feasible video \nadaptation technique that fits within the MPEG-21 DIA \narchitecture. The scalable video coding in a VCS allows \nencoding the content in several scalable layers. Number of \nlayers is dependent on the scalability space required by the \napplication scenario. SVC approach provides backward \ncompatibility for conventional multimedia such as speech and \nvideo, while providing the adaptation for different networks \nand\/or terminal capabilities and different user preferences. \nHence, the heterogeneity of multimedia communication using \ndifferent terminals in a virtual office environment can be \naddressed using this proposed SVC based content adaptation \nmechanism. The emerging of real-time scalable video codecs \nwith high compression efficiency, availability of high \nprocessing power and ever increasing network bandwidth will \nfacilitate real-time content generation and adaptation based on \nthis proposed SVC approach.   \nThe proposed SVC based adaptation for the VCS is \ndescribed in Section II. Section III elaborates on adaptation \nmechanisms based on the conditions imposed by user \npreferences, profiles for usage, terminal and network \ncapabilities. Furthermore the same section provides examples \nof application specific scenarios such as bitrate and user \npreference based adaptations. Section IV concludes the paper.  \nII. CONTENT ADAPTATION USING SVC APPROACH \nFig. 3 describes the virtual collaboration scenario \nincorporating the proposed SVC based content adaptation \nscheme. The content adaptation based on SVC approach \nconsists of two main modules namely SVC codec for scalable \ncontent generation and the adaptation module as shown in Fig. \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 12,2010 at 16:28:32 UTC from IEEE Xplore.  Restrictions apply. \n 3. The adaptation module consists of an adaptation decision \nengine (ADE) and adaptation engine (AE). The ADE will take \nall decisions based on the network capacity, terminal \ncapabilities and user preferences and use the scalable content \navailable at the gateway. The AE implements the decision \nmade by ADE. The SVC codec resides in major user terminals \n(large user terminals with co-located users and other fixed user \nterminals with single users). Even mobile user terminals will \njoin to provide scalable multimedia content, depending on \ntheir terminal capabilities. The adaptation module is residing \nin the terminal gateway of the particular user or the terminal \nitself. \n \nFig. 3: Integration of content adaptation methodology in VCS \n \n \n \nFig. 4: Interaction between the SVC and the adaptation module \n \nThe interaction of the SVC codec and the terminal gateway \nis demonstrated in Fig. 4. The required scalability space is \ndependent on the application scenario, terminal capabilities of \nremotely located users, user preferences and the type of access \nnetwork, where remote uses are connected. After in-depth \nanalysis of the heterogeneity of the prevailing virtual \ncollaboration scenario, appropriate scalable content can be \ngenerated using the SVC codec available at fixed terminal with \nsingle\/multiple users. All or part of the generated scalable \nmultimedia content will be transferred to the terminal gateway \ndepending on the capacity of the network (see Fig. 3). The rest \nof the paper discusses the functionalities of the adaptation \nmodule with respect to network\/terminal capabilities and user \npreferences. \nIII. CONTENT ADAPTATION FOR VIRTUAL OFFICE \nENVIRONMENT \nVirtual collaboration is an application which relies heavily \non digital media. Therefore, the effectiveness of this \napplication can be enhanced by adapting the relevant media \nitems for the usage environment. Adaptation possibilities \nspread across whole spectrum of digital media items that are \nutilised during a virtual collaboration session, including \naudio\/video and documents. The objective of this section is to \ndiscuss video adaptation mechanisms proposed for virtual \ncollaboration application to cater for the heterogeneity of the \nchannel conditions, user preferences and terminal capabilities. \nA. Adaptation Based on User Preferences and Profiles \nIt is more likely that each user of virtual collaboration \nsystem would have own audio and video preferences. For \ninstance, a user may wish to select a specific area which draws \nhis\/her main attention in visual content. Thus, he or she may \nwant to access a part of the video scene based on his\/her \nselection. In addition to this or in a totally isolated situation, \nthe terminal that the user is using may have a restricted display \ncapability with lower resolution than that of the originally \nencoded content. Moreover, the access network that the user is \nconnected to may not be able to support elaborate visual \ninformation transfer due to bandwidth limitations and\/or other \nchannel specific characteristics.  \nAll of these add up to the profiling of a use case for this \nparticular user, and the different display capabilities, attention \narea selection preferences, access network based features etc \nprovide the necessary context elements for this use case. \nTherefore, more user centric adaptation options must be \navailable for serving each individual\u2019s requirements. \n \n \n \n \n \n  \n \n \n \nFig. 5. User centric adaptation mechanism for virtual collaboration \napplication \n \nIn the virtual office application, one of the more demanding \nuser centric adaptation scenarios is delivering a cropped view \nof a particular attention area selected by the user. This area is \nmore subjective and situation driven than an automatic \nattention area detection technique may be able to detect. In \norder to address these conditions, the adaptation technique \nillustrated in Fig. 5 is proposed. Unique to the proposed \nadaptation mechanism is the provision of a user interaction \nservice, through which the user can specify a selected ROI. \nThis information is sent in an ROI Selection message to the \nADE which is implemented as a part of the relevant gateway \nas shown in the Fig. 5 or as a stand-alone network element. \nBased on the ROI definition and other context information \nInternet \nUser \nUser \nLarge multi user gateway + \nAdaptation Module (ADE \n& AE) \nSmall single user gateway \n+ Adaptation Module \n(ADE & AE) \n \nMobile gateway + \nAdaptation Module \n(ADE & AE) \nUser (1..n) \nSVC Codec SVC Codec \nLarge Terminal \nGroup of co-located \nusers with large fixed \nterminal \nSmall Terminal \nSingle user with \nsmall fixed \nterminal \nMobile Terminal \nSingle remote user \nwith small mobile \nterminal \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 12,2010 at 16:28:32 UTC from IEEE Xplore.  Restrictions apply. \n defining the capabilities of network and terminal etc., the ADE \ndetermines the nature of adaptation needed after processing the \nROI descriptor. This adaptation decision is used for \nconfiguring the Adaptation Engine (AE) which performs actual \nadaptation. \nThe AE utilises the provisions provided by H.264 SVC [11] \nextension for ROI based adaptation using Flexible Macroblock \nOrdering (FMO). This technique is formally identified as \ninteractive ROI (IROI) scalability [12][13]. An AE can utilise \nthe IROI scalability to extract a sub-stream that defines the \nROI [14]. Fig. 6 illustrates the perceptual quality comparison \nof downsampling and IROI based adaptation of CIF sequences \nto match QCIF resolution. It is clearly evident that cropping \nbased adaptation is more attractive when the preservation of \nfine details of the attention area is more important. \n \nParis News \n \n \n(a) CIF Down Sampled to QCIF \n  \n(b) CIF Cropped to QCIF with a focus on the 1st ROI \n \n \n(c) CIF Cropped to QCIF with a focus on the 2nd ROI \nFig. 6. Compassion of subjective quality enhancement by using IROI \nadaptation \n \nIn addition to the user driven ROI feedback signalling, the \nROI information is used when there is a necessity of adapting \nthe content to meet usage environment constraints. For \nexample, if there is a need to reduce the aspect ratio, then the \nadaptation operation can be performed taking the ROI \ninformation into consideration; or if it is necessary to reduce \nthe bitrate, the ADE may decide that the best way of achieving \nthat is by cropping the image according to the ROI \ninformation. All of these are determined after processing a \nnumber of context descriptors, which in return describe the \nuser defined ROI and other constraints, such as QoS, terminal \ncapabilities, access network capabilities, usage environment \netc. \nB. Adaptation Based on Terminal and Network Capabilities \nThe use of various devices (e.g., PCs, PDAs, laptops, other \nlarge\/small scale fixed\/mobile collaboration terminals etc) in a \nvirtual collaboration system often demands the adaptation of \ncontent format during the exchange of information between \ncollaborating partners due to their diverse terminal \ncapabilities. These capabilities may sometimes vary from one \nterminal to another vastly, in terms of the type of the codec \nused, amount of memory storage, supported processing power, \navailable communication and\/or user-interface modules (e.g., \nvideo, speech, audio, text facilities etc), the size of display etc. \nIn most cases, adaptation needs to be performed during the \naccess of rich content information. It is evident that the user \nterminal with the least number of capabilities will be the \nlimiting factor on others' communication and collaboration \nactivities. To avoid the fact that such limitation affects the \noverall QoS assured and the quality of user experience (QoE) \nexpected from this scenario, a content adaptation engine can \nbe deployed to act as a guarantee of interoperability between \nvarious user terminals with diverse capabilities. In such a \nscenario for instance, a mobile terminal can be regarded as a \npower-limited device due to battery life and processing power \nrestrictions, and hence is conventionally built with a small \n(low-resolution) screen. The high resolution of video can thus \nbe re-sized to fit adequately on such a terminal with small \ndisplay size without any information loss, which in return will \nenhance both the QoS and QoE. If reducing the original size of \nvideo is not providing the best results, then selecting a \nparticular attention area of user's choice (i.e., ROI selection) \ncan be a suitable way of adapting the content for improved \ninteroperability.  \nThere can also be potential occasions where the user \nterminal does not support, say the video element or it cannot \nmatch the format of the originally compressed video and\/or \naudio. In such situations, adaptation can take place to provide \nconversions between different content coding standards as well \nas selecting one and dropping the other content item or \nperform mode exchanging (i.e., transmoding) based on the \nsupported feature. Transmoding engines can perform video to \nsound\/text, to images and\/or to graphic conversions [15]. \nThe availability of network bandwidth for different users is \nnot fixed in a virtual office scenario. For example, a PDA user \nmay need to access the interaction through a wireless \nconnection. The bandwidth availability over a wireless \nnetwork is limited and time varying. Hence the user can \nrequest low bitrate content from the adaptation module located \nin the terminal gateway. The adaptation module can decide \nand deliver a down-sampled version of the collaborated \ncontent using available scalable multimedia content. The \nspatially or temporally down-sampled content can be extracted \nfrom the scalable stream to obtain low bitrate streams. \nFurthermore incremental refinement nature of the fidelity \nscalability tools supports termination of enhancement layer \npackets at supported rate points [16]. Therefore, this serves as \na powerful tool to adjust the bitrate by truncating an \nenhancement layer packet. A different approach of achieving \nbitrate adoption is to use the SVC\u2019s ROI scalability feature. \nThe advantage of this technique is that the quality of the \nattention area can be preserved while easing the channel bitrate \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 12,2010 at 16:28:32 UTC from IEEE Xplore.  Restrictions apply. \n constraints. This feature can also be combined with other \nscalability to cater for extremely limited bandwidth \nconstraints. \nThis section analyses a scenario of bitrate adaptation based \non several spatial layers. This experiment used the test \nsequences, namely \u2018Orbi\u2019 and \u2018Interview\u2019 obtained using the \ndepth-range camera. Both sequences contain a colour sequence \nand associated per-pixel depth information. This depth image \nin conjunction with the colour image can be used to render \nstereoscopic video material at the receiver side [17]. These \nsequences were selected to represent a use case, where \nstereoscopic video can be generated at terminals with high \ncapacity fixed terminals including stereoscopic capture and \ndisplay devices. In general the use of stereoscopic video will \nenhance the effectiveness of the collaboration activity between \nthe partners. The H.264\/SVC codec (JSVM 7.12.1) was used \nto obtain a scalable video bit-stream. The H.264\/SVC supports \nspatial, temporal and quality scalability for video [11]. The \ncolour sequences of different formats: QCIF, CIF and 4CIF \nwere coded at three different layers using the H.264\/SVC \nlayered architecture. The corresponding depth image, which is \nin 4CIF format was coded as the forth layer [18]. The basic \nencoding parameters are: 125 frames, IPPP\u2026 sequence \nformat, 30 frames\/s original frame rate, a single reference \nframe, variable length coding (VLC), 32 pixel search range \nand no error resilience. The QP value of 30 was used at each \nlayer for encoding. In order to remove the redundancies \nbetween inter views inter layer prediction was enabled among \nthe layers. Table 1 shows the resultant bitrates for each coded \nlayer.  \nTABLE I \nSPATIAL SCALABILITY FOR BITRATE ADAPTATION \nOrbi Interview \nSequence & \nFormat Bitrate (kbits\/s) \nPSNR \n(dB) \nBitrate \n(kbits\/s) \nPSNR \n(dB) \nColour: QCIF 80 35.79 67 34.35 \nColour: CIF 296 37.66 241 35.46 \nColour: 4CIF 1078 37.99 777 37.13 \nDepth: 4CIF 1655 40.05 1220 42.30 \n \nAccording to Table 1, a QCIF format video, which has the \nlowest bitrate can be adapted to collaborate with a mobile user \nconnected via a UMTS link (384 kbits\/s), whereas a user with \nlaptop with WLAN connectivity may access the 4CIF format \nvideo. The fixed terminal users with wired connectivity may \naccess the overall bit-stream and even experience stereoscopic \nvideo if compatible displays and synthesizers are available. \nIV. CONCLUSION \nThis paper elaborates on a Virtual Collaboration System \n(VCS) which is being developed under VISNET II and the \ncomplexity arises with the heterogeneity of the system due to \nuse of various terminals, different access networks with \ndiverse characteristics, user preferences and profiles. In order \nto address diverse perspectives of the system, we also propose \ncontent adaptation methodologies. The objective of the \nproposed adaptation mechanisms is to maximise the \neffectiveness of collaboration sessions by fulfilling the needs \nof all collaborators. The content adaptation based on user \npreferences, profiles for usage, terminal and network \ncapabilities are described and results are presented for specific \nadaptation scenarios. Initial experimental results have been \nproved to be effective and productive for a virtual office \nenvironment. Most of the presented tools are still being \ndeveloped and will be tested in the VCS.   \nACKNOWLEDGEMENTS \nThe work presented was developed within VISNET II, a \nEuropean Network of Excellence (http:\/\/www.visnet-noe.org), \nfunded under the European Commission IST FP6 programme. \nAuthors would like to thank Dr Banu Gunel of I-Lab\/CCSR, \nUniversity of Surrey for her review comments. \nREFERENCES \n[1]  VISNET II - a network of excellence, http:\/\/www.visnet-noe.org\/ \n[2]  S.-F. Chang and A. Vetro, \u201cVideo adaptation: Concepts, technologies, \nand open issues\u201d, Proc. IEEE, vol. 93, no. 1, pp. 148-158, Jan. 2005. \n[3]  M. Soleimanipour, W. Zhuang, and G.H. Freeman, \u201cModeling and \nresource allocation in wireless multimedia CDMA systems\u201d, in Proc. \n48th IEEE Vehicular Technology Conference. (VTC\u201998), vol.2, no. 18-\n21, pp. 1279-1283, May 1998. \n[4]  Special Issue on Universal Multimedia Access, IEEE Signal Processing \nMag., vol. 20, no. 2, Mar. 2003 \n[5]  MPEG-21 Part-7: ISO\/IEC 21000-7, \u201cInformation technology - \nMultimedia Framework - Part 7: Digital Item Adaptation\u201d, October \n2004. \n[6]  A. Vetro, \u201cMPEG-21 digital item adaptation: Enabling universal \nmultimedia access\u201d, IEEE Multimedia Journal, January 2004. \n[7]  I. Burnett, R. Van de Walle, K. Hill, J. Bormans, and F. Pereira, \n\u201cMPEG-21: Goals and achievements\u201d, IEEE Multimedia, vol. 10, no. 4, \npp. 60-70, Oct.-Dec. 2003. \n[8] Z. Lei and N.D. Georganas, \u201cVideo transcoding gateway for wireless \nvideo access\u201d, in Proc. IEEE Canadian Conf. Electrical and \nComputing Engineering (CCECE\u20192003), vol. 3, Montreal, Canada, pp. \n1775-1778, 4-7 May 2003. \n[9]  T. Warabino, S. Ota, D. Morikawa et al., \u201cVideo transcoding proxy for \n3Gwireless mobile Internet access\u201d, IEEE Commun. Mag., vol. 38, no. \n10, pp. 66-71, Oct. 2000. \n[10] M. Ott, G. Welling, S. Mathur, D. Reininger, and R. Izmailov, \u201cThe \nJOURNEY, active network model\u201d, IEEE J. Select. Areas Commun., \nvol.19, no.3, pp. 527-536, Mar. 2001. \n[11] T. Wiegand, G. Sullivan, J. Reichel, H. Schwarz, and M. Wien, \u201cJoint \ndraft 8 of SVC amendment\u201d, ISO\/IEC JTC1\/SC29\/WG11 and ITU-T \nSG16 Q.6 9 (JVT-U201), 21st Meeting, Hangzhou, China, Oct. 2006. \n[12] M.H. Lee, H.W. Sun, D. Ichimura, Y. Honda, and S.M. Shen, \u201cROI \nslice SEI message\u201d, JVT-S054, Input Document Joint Video Team \n(JVT), Geneva, Switzerland, Apr. 2006. \n[13] ISO\/IEC JTC\/SC29\/WG11, \u201cApplications and requirements for Scalable \nVideo Coding\u201d, N6880, Jan. 2005. \n[14] D. De Schrijver, W. De Neve, D. Van Deursen, S. De Bruyne, and R. \nVan de Walle, \u201cExploitation of interactive region of interest scalability \nin scalable video coding by using an XML-driven adaptation \nframework\u201d, in Proc AXMEDIS\u20192006, Leeds, UK, Dec. 2006. \n[15] T.C. Thang, Y.J. Jung, and Y.M. Ro, \u201cModality conversion for QoS \nmanagement in universal multimedia access\u201d, IEE Proc. VISP, vol. 152, \nno. 3, pp. 374-384, Jun. 2005. \n[16] H. Schwarz, D. Marpe, and T. Wiegand, \u201cOverview of the scalable \nvideo coding extension of the H.264\/AVC standard,\u201d Input Doc. to the \n23rd Joint Video Team (JVT) meeting, San Jose, CA, USA, Apr., 2007. \n[17] C. Fehn, \u201cA 3D-TV Approach using Depth-Image-Based Rendering \n(DIBR)\u201d, in Proc. VIIP\u20192003, Sep. 2003.  \n[18] C.T.E.R. Hewage, H.A. Karim, S. Worrall, S. Dogan, and A.M. Kondoz, \n\u201cComparison of stereoscopic video coding using MPEG-4 MAC, \nH.264\/AVC and H.264\/SVC,\u201d to appear in Proc. VIE\u20192007, Jul. 2007. \nAuthorized licensed use limited to: University of Surrey. Downloaded on May 12,2010 at 16:28:32 UTC from IEEE Xplore.  Restrictions apply. \n"}
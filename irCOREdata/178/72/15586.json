{"doi":"10.1007\/978-90-481-9178-9_6","coreId":"15586","oai":"oai:eprints.erpanet.org:154","identifiers":["oai:eprints.erpanet.org:154","10.1007\/978-90-481-9178-9_6"],"title":"Formulating representative features with respect to document genre classification","authors":["Kim, Dr Yunhyong","Ross, Seamus"],"enrichments":{"references":[{"id":642793,"title":"A scalability analysis of classi\ufb01ers in text categorization.","authors":[],"date":null,"doi":"10.1145\/860435.860455","raw":"Yang, Y., Zhang, J. and Kisiel, B. A scalability analysis of classi\ufb01ers in text categorization. In Proceedings 26th annual international ACM SIGIR conference on research and development information retrieval, 96-103. ISBN: 1-58113-646-3, 96-","cites":null},{"id":636319,"title":"A toolkit for statistical language modeling, text retrieval, classi\ufb01cation and clustering.","authors":[],"date":"1996","doi":null,"raw":"McCallum,A. Bow: A toolkit for statistical language modeling, text retrieval, classi\ufb01cation and clustering. (1996) http:\/\/www.cs.cmu.edu\/~1mccallum\/bow","cites":null},{"id":9469547,"title":"An Examination of Genre Attributes for Web Page Classi\ufb01cation.","authors":[],"date":"2008","doi":"10.1109\/hicss.2008.53","raw":"Dong, L., Watters, C., Du\ufb00y, J. and Shepherd, M. An Examination of Genre Attributes for Web Page Classi\ufb01cation. In Proceedings 41st Hawaiian International Conference on System Sciences, IEEE Computer Society Press, ISBN-13: 978-0-7695-3075-8, ISBN-10: 0-7695-3075-3, ISSN: 1530-1605. (2008)","cites":null},{"id":9469541,"title":"Automatic categorization of email into folders: benchmark experiments on enron and sri corpora.","authors":[],"date":"2004","doi":null,"raw":"Bekkerman, R., McCallum, A. and Huang, G. Automatic categorization of email into folders: benchmark experiments on enron and sri corpora. Technical Report IR418, Center for Intelligent Information Retrieval, UMASS. (2004) http:\/\/www.cs.umass.edu\/ \u02dc mccallum\/papers\/folderingtr05.pdf","cites":null},{"id":636315,"title":"Automatic detection of text genre.","authors":[],"date":"1997","doi":null,"raw":"Kessler, G., Nunberg, B. and Schuetze, H. 1997. Automatic detection of text genre. In Proceedings 35th Annual Meeting ACL, 32-38.","cites":null},{"id":9469552,"title":"Automatic document metadata extraction using support vector machines.","authors":[],"date":"2003","doi":"10.1109\/jcdl.2003.1204842","raw":"Han, H., Giles, L., Manavoglu, E., Zha, H., Zhang, Z. and Fox, E.A. Automatic document metadata extraction using support vector machines. In Proceedings 3rd ACM\/IEEE-CS Conference on Digital Libraries, 37-48. (2003)","cites":null},{"id":642792,"title":"Automating the production of bibliographic records.","authors":[],"date":"2001","doi":null,"raw":"Thoma, G. Automating the production of bibliographic records. Technical report, Lister Hill National Center for Biomedical Communication, US National Library of Medicine. (2001) http:\/\/archive.nlm.nih.gov\/pubs\/thoma\/mars2001.php","cites":null},{"id":9469543,"title":"Clumping properties of content-bearing words.","authors":[],"date":"1998","doi":"10.1002\/(sici)1097-4571(199802)49:2<102::aid-asi2>3.0.co;2-5","raw":"Bookstein, A., Klein, S.T. and Raita, T. Clumping properties of content-bearing words. Journal of the American Society of Information Science, 1998, 49(2): 102-114.(1998)","cites":null},{"id":9469540,"title":"Clustering document images using a bag of symbols representation.","authors":[],"date":null,"doi":"10.1109\/icdar.2005.75","raw":"Barbu, E., Heroux, P., Adam, S. and Turpin, E. Clustering document images using a bag of symbols representation. In Proceedings International Conference on Document Analysis and Recognition, 1216-1220.(2005)","cites":null},{"id":642794,"title":"Data mining: Practical machine learning tools and techniques. 2nd edition,","authors":[],"date":"2005","doi":"10.1016\/b978-0-12-374856-0.00005-5","raw":"Witten, H.I. and Frank, E. Data mining: Practical machine learning tools and techniques. 2nd edition, Morgan Kaufmann, San Francisco. (2005)","cites":null},{"id":636316,"title":"Detecting family resemblance: Automated genre classi\ufb01cation.","authors":[],"date":"2007","doi":"10.2481\/dsj.6.s172","raw":"Kim, Y. and Ross, S. Detecting family resemblance: Automated genre classi\ufb01cation. CODATA Data Science Journal, 6: S172-S183. ISSN: 1683-1470. (2007)","cites":null},{"id":9469542,"title":"Dimensions of Register Variation: a Cross-Linguistic Comparison.","authors":[],"date":"1995","doi":"10.1017\/cbo9780511519871.010","raw":"Biber, D. Dimensions of Register Variation: a Cross-Linguistic Comparison. Cambridge University Press, New York. (1995)","cites":null},{"id":9469539,"title":"Fine-grained document genre classi\ufb01cation using \ufb01rst order random graphs.","authors":[],"date":"2001","doi":"10.1109\/icdar.2001.953759","raw":"Bagdanov, A. and Worring, M. Fine-grained document genre classi\ufb01cation using \ufb01rst order random graphs. In Proceedings Sixth International Conference on Document Analysis and Recognition (ICDAR2001), 79-90. (2001)","cites":null},{"id":636318,"title":"Foundations of Statistical Language Processing,","authors":[],"date":"1999","doi":"10.1017\/s1351324902212851","raw":"Manning, C. and Schutze, H. Foundations of Statistical Language Processing, MIT Press. Cambridge, MA. (1999)","cites":null},{"id":9469545,"title":"Frequent Term Distribution Measures for Dataset Pro\ufb01ling.","authors":[],"date":"2004","doi":null,"raw":"De Roeck, A., Sarkar, A. and Garthwaite, P. Frequent Term Distribution Measures for Dataset Pro\ufb01ling. Technical Report 2004\/06. Faculty of Mathematics and Computing, Open 1 http:\/\/www.delos.info 2 http:\/\/www.dcc.ac.uk 3 http:\/\/www.jisc.ac.uk 4 http:\/\/www.epsrc.ac.uk University. Milton Keynes, UK. (2004) http:\/\/computingreports.open.ac.uk\/index.php\/","cites":null},{"id":636320,"title":"Integrating automatic genre analysis into digital libraries.","authors":[],"date":"2001","doi":"10.1145\/379437.379439","raw":"Rauber, A. and Muller-Kogler, A. Integrating automatic genre analysis into digital libraries. In Proceedings ACM\/IEEE Joint Conference on Digital Libraries, 1-10, Roanoke, VA. (2001) http:\/\/doi.acm.org\/10.1145\/379437.379439","cites":null},{"id":9469551,"title":"Knowledge-based metadata extraction from postscript \ufb01le.","authors":[],"date":"2000","doi":"10.1145\/336597.336639","raw":"Giu\ufb00rida, G., Shek, E. and Yang, J. Knowledge-based metadata extraction from postscript \ufb01le. In Proceedings 5th ACM International Conference on Digital Libraries, 77-84. (2000)","cites":null},{"id":9469549,"title":"Learning to classify documents according to genre.","authors":[],"date":"2006","doi":"10.1002\/asi.20427","raw":"Finn, A. and Kushmerick, N. Learning to classify documents according to genre. Journal of American Society for Information Science and Technology, 57(11): 1506-1518. (2006)","cites":null},{"id":636314,"title":"Perc: A personal email classi\ufb01er.","authors":[],"date":"2006","doi":"10.1007\/11735106_41","raw":"Ke, S.W. and Bowerman, C. Perc: A personal email classi\ufb01er. In Proceedings 28th European Conference on Information Retrieval (ECIR 2006), 460-463. (2006)","cites":null},{"id":636322,"title":"PhD thesis,","authors":[],"date":"2007","doi":"10.1111\/j.1467-8462.2007.00485.x","raw":"Santini, M. PhD thesis, University of Brighton, Brighton (UK). (2007) http:\/\/www.itri.brighton.ac.uk\/~Marina.Santini\/MSantini PhD Thesis.zip","cites":null},{"id":636321,"title":"Preservation research and sustainable digital libraries.","authors":[],"date":"2005","doi":"10.1007\/s00799-004-0099-3","raw":"Ross, S. and Hedstrom, M. Preservation research and sustainable digital libraries. International Journal of Digital Libraries, v 5.4, 317-325. DOI: 10.1007\/s00799-004-0099-3. (2005) http:\/\/eprints.erpanet.org\/archive\/00000095\/","cites":null},{"id":636313,"title":"Recognizing text genres with simple metric using discriminant analysis.","authors":[],"date":"1994","doi":"10.3115\/991250.991324","raw":"Karlgren, J. and Cutting, D. Recognizing text genres with simple metric using discriminant analysis. In Proceedings 15th Conference on Computational Linguistics, 2: 1071-1075. (1994)","cites":null},{"id":636317,"title":"Searching for Ground truth: a stepping stone in automated genre classi\ufb01cation.","authors":[],"date":"2007","doi":"10.1007\/978-3-540-77088-6_24","raw":"Kim, Y. and Ross, S. Searching for Ground truth: a stepping stone in automated genre classi\ufb01cation. LNCS 4877, 248-261, Springer. DOI: 10.1007\/978-3-540-77088-6 (2007) http:\/\/www.springerlink.com\/content\/lt760613m2731723\/ fulltext.pdf","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-01-01","abstract":"Genre classification (e.g. whether a document\nis a scientific article or magazine article) is closely\nbound to the physical and conceptual structure of document\nas well as the level of depth involved in the text.\nHence, it provides a means of ranking documents retrieved\nby search tools according to metrics other than\ntopical similarity. Moreover, the structural information\nderived from genre classification can be used to locate\ntarget information within the text. In previous studies,\nthe detection of genre classes has been attempted\nby using some normalised frequency of terms or combinations\nof terms in the document (here, we are using\nterm as a reference to words, phrases, syntactic\nunits, sentences and paragraphs, as well as other patterns\nderived from deeper linguistic or semantic analysis).\nThese approaches largely neglect how the term is\ndistributed throughout the document. Here, we report\nthe results of automated experiments based on distributive\nstatistics of words in order to present evidence that\nterm distribution pattern is a better indicator of genre\nclass than term frequency.","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/15586.pdf","fullTextIdentifier":"http:\/\/eprints.erpanet.org\/154\/01\/LDVForum_GSI_YKSR2008V2.pdf","pdfHashValue":"76cfdc942bcf740a288b7d367643ea6453c6384f","publisher":null,"rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:eprints.erpanet.org:154<\/identifier><datestamp>\n      2008-11-19<\/datestamp><setSpec>\n      7374617475733D696E7072657373<\/setSpec><setSpec>\n      7375626A656374733D5265736F7572636520446973636F76657279<\/setSpec><setSpec>\n      7375626A656374733D45:4541<\/setSpec><setSpec>\n      7375626A656374733D4469676974616C205265706F7369746F72792C204469676974616C204172636869766520616E64204469676974616C204C696272617279204D6F64656C73:496E67657374<\/setSpec><\/header><metadata><oai_dc:dc xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Formulating representative features with respect to document genre classification<\/dc:title><dc:creator>\n        Kim, Dr Yunhyong<\/dc:creator><dc:creator>\n        Ross, Seamus<\/dc:creator><dc:subject>\n        M Resource Discovery<\/dc:subject><dc:subject>\n        LA Ingest<\/dc:subject><dc:subject>\n        EA Metadata<\/dc:subject><dc:description>\n        Genre classification (e.g. whether a document\nis a scientific article or magazine article) is closely\nbound to the physical and conceptual structure of document\nas well as the level of depth involved in the text.\nHence, it provides a means of ranking documents retrieved\nby search tools according to metrics other than\ntopical similarity. Moreover, the structural information\nderived from genre classification can be used to locate\ntarget information within the text. In previous studies,\nthe detection of genre classes has been attempted\nby using some normalised frequency of terms or combinations\nof terms in the document (here, we are using\nterm as a reference to words, phrases, syntactic\nunits, sentences and paragraphs, as well as other patterns\nderived from deeper linguistic or semantic analysis).\nThese approaches largely neglect how the term is\ndistributed throughout the document. Here, we report\nthe results of automated experiments based on distributive\nstatistics of words in order to present evidence that\nterm distribution pattern is a better indicator of genre\nclass than term frequency.<\/dc:description><dc:date>\n        2008-01-01<\/dc:date><dc:type>\n        Journal (On-line\/Unpaginated)<\/dc:type><dc:identifier>\n        http:\/\/eprints.erpanet.org\/154\/<\/dc:identifier><dc:format>\n        pdf http:\/\/eprints.erpanet.org\/154\/01\/LDVForum_GSI_YKSR2008V2.pdf<\/dc:format><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2008,"topics":["M Resource Discovery","LA Ingest","EA Metadata"],"subject":["Journal (On-line\/Unpaginated)"],"fullText":"LDV Forum manuscript No.\n(will be inserted by the editor)\nFormulating representative features with respect to\ndocument genre classi\ufb01cation\nYunhyong Kim \u00b7 Seamus Ross\nReceived: date \/ Accepted: date\nAbstract Genre classi\ufb01cation (e.g. whether a docu-\nment is a scienti\ufb01c article or magazine article) is closely\nbound to the physical and conceptual structure of doc-\nument as well as the level of depth involved in the text.\nHence, it provides a means of ranking documents re-\ntrieved by search tools according to metrics other than\ntopical similarity. Moreover, the structural information\nderived from genre classi\ufb01cation can be used to locate\ntarget information within the text. In previous stud-\nies, the detection of genre classes has been attempted\nby using some normalised frequency of terms or com-\nbinations of terms in the document (here, we are us-\ning term as a reference to words, phrases, syntactic\nunits, sentences and paragraphs, as well as other pat-\nterns derived from deeper linguistic or semantic analy-\nsis). These approaches largely neglect how the term is\ndistributed throughout the document. Here, we report\nthe results of automated experiments based on distribu-\ntive statistics of words in order to present evidence that\nterm distribution pattern is a better indicator of genre\nclass than term frequency.\nKeywords document classi\ufb01cation \u00b7 genre \u00b7 document\nrepresentation \u00b7 word distribution\nY. Kim\nHATII, 11 University Gardens, Glasgow, G12 8QH, UK\nTel.: +44-141-3308594\nFax: +44-141-3303788\nE-mail: y.kim@hatii.arts.gla.ac.uk\nS. Ross\nSame institute as above\nTel.: +44-141-3303635\nFax: +44-141-3303788\nE-mail: s.ross@hatii.arts.gla.ac.uk\n1 Introduction\nThis paper examines the role of word distribution in\nclassifying documents according to genre. Document\nclassi\ufb01cation is one of the most fundamental steps in\nenabling the search, selection, and ranking of digital\nmaterial according to its relevance in answering a prede-\n\ufb01ned search. As such it is a valuable means of knowledge\ndiscovery and an essential part of the e\ufb00ective and e\ufb03-\ncient management of digital documents in a repository,\nlibrary, or archive. Document classi\ufb01cation has previ-\nously been dominated by the classi\ufb01cation of documents\naccording to topic. Recently, however, there has been a\ngrowing interest in the classi\ufb01cation of documents with\nrespect to factors other than topic, for example, genre\n(e.g. scienti\ufb01c papers, emails and news reports). The in-\nterest in the genre of documents re\ufb02ects the limitations\nof relevance measurements based on topic. Topic alone\ndoes not provide insight into whether or not a retrieved\ndocument is appropriate for your purpose; a document\nwith the same topic may be created with di\ufb00erent ob-\njectives resulting in di\ufb00erent levels of usefulness as a\nsource of information (e.g. compare an advertisement\nabout a camera to a product review of the same cam-\nera). The objectives of document creation de\ufb01ne the\nfunctional requirements of the document (e.g. to nar-\nrate, to argue against, to argue for, to present research\nresults) that characterise its genre, and the structures\nfound within the document are designed to meet these\nfunctional requirements. Therefore, the structural clas-\nsi\ufb01cation of documents is a fundamental component in\ndetecting genre. Classical models of document classi-\n\ufb01cation largely depend on term frequency weighting\nand counting instances of speci\ufb01ed linguistic constructs.\nThe former does not re\ufb02ect much document structure\nand the latter results in a highly language dependent2\nmodel that incorporates some local conceptual struc-\nture but largely disregards the global conceptual or\nphysical structure of the document and its components.\nIn this paper,\n\u2013 we describe an approach to document representa-\ntion that incorporates more document structure by\nconsidering how strings are distributed throughout\nthe document (Section 2.2), and,\n\u2013 give evidence that this approach is better than the\nbag-of-words approach by comparing it against the\nrainbow classi\ufb01er [18] (Section 5.2).\nBeing able to bind together tools trained to retrieve\ninformation within selected structural domains is cru-\ncial to automating the ingest, management and preser-\nvation of material in digital repositories [20]. This is es-\npecially true where metadata describing the technical\ncharacteristics, function, source and content of digital\nmaterial play a core role in the e\ufb03cient and e\ufb00ective\nmanagement and re-use of the same (cf. [20]). As we\nhave discussed in earlier papers (e.g. [25]), the manual\ncollection of metadata is labour-intensive, costly and\nsusceptible to variation in quality and precision across\ndi\ufb00erent actors; automating the process of semantic\nmetadata extraction is, therefore, essential. Past e\ufb00orts\n(e.g. [3], [6], [10], [11], [13], [22]) to extract metadata\nautomatically from digital documents have relied heav-\nily on the structure that characterises the genre class to\nwhich the document under consideration belongs. The\nreliance of these methods on document structure em-\nphasises the bene\ufb01ts of constructing a tool that enables\nautomated genre classi\ufb01cation. An e\ufb00ective automated\ngenre classi\ufb01er would function as an overarching tool for\nintegrating genre-speci\ufb01c tools and, in any case, provide\na \ufb01rst-level classi\ufb01cation of documents into those of a\nsimilar structure, which would facilitate the extraction\nof further information.\nThe vast number of di\ufb00erent contexts in which genre\nhave emerged across classi\ufb01cation attempts illustrate\nthat genre is a high-level, context-dependent concept\n(cf. literature review in [21]). Genre has been referred to\nas aspects of the text described by level of information\nor degree of elaboration, persuasion and abstraction [4],\nas well as, to common document forms such as FAQ,\nJob Description, Editorial or Reportage [12], [14]. In\nsome cases, genre has been used to describe the classi\ufb01-\ncation of a document according to whether or not it is a\nnarrative and whether it is intended for an audience of\nspecialists [14], and whether it is fact or opinion, and, in\nthe case of opinion, whether it is positive or negative [9].\nOn occasion it has been used to describe membership\nto selected journals and brochures [1], and, to denote\nsimilar feature cluster groups ([2], [19]).\nA prevailing notion in earlier analyses is that genre\nclassi\ufb01cation is a task independent from subject classi-\n\ufb01cation. While this may be true on a conceptual level,\nthere is reason to believe that this may not be a sta-\ntistically sound approach. For example, the topic of\nalgebraic variety, a well-known subject area in higher\nmathematics, would not be expected to appear as fre-\nquently in the genre class Reportage as it would in the\ngenre class Research Article. In fact, preliminary re-\nsults from a recent experiment, classifying documents\nbelonging to ten genre classes into twenty newsgroup\ntopic classes, shows that, while there are genre classes\nwhose documents are randomly distributed across the\ntwenty topics (e.g. Poem), there are also genres 95%\nof whose documents are classi\ufb01ed into only four news-\ngroup topics (e.g. Minutes).\nGiven these examples where genre is interactively\nintertwined with topic, it would seem bene\ufb01cial to build\na general classi\ufb01cation model that encompasses both\ntasks. With this in mind, in Section 2, we would like\nto introduce genre classi\ufb01cation, not as a classi\ufb01cation\ntask distinct from topic classi\ufb01cation, but as a point in\na continuum of classi\ufb01cations, emphasising both genre\nclassi\ufb01cation and topic classi\ufb01cation as a special case of\na general abstract classi\ufb01cation model.\nIn Section 4, we introduce the dataset and investi-\ngate the agreement between human labellers in classi-\nfying the data, a discussion that demonstrates the com-\nplexity of genre classi\ufb01cation and leads to a measure-\nment of the cleanliness of the dataset which helps to set\nthe standards against which to compare the automated\nexperiments. We further compare the support vector\nmachine classi\ufb01cation based on the document represen-\ntation introduced in Section 2.2 to the baseline support\nvector machine rainbow classi\ufb01er [18]. This compari-\nson, using our abstract classi\ufb01cation model, will show\nits e\ufb00ectiveness in performing automated classi\ufb01cation.\nThe discussion here is a result of examining PDF\ndocuments. The study was limited to PDF documents\nbecause of the popularity this format has across library,\narchival, commercial and private sectors. This popu-\nlarity implies that a classi\ufb01cation tool developed for\nthis format is likely to have widespread immediate use-\nfulness. Although the study is of PDF documents, the\nmethods described here do not use features dependent\non elements available only in PDF documents. The pro-\ncess is dependent on the PDF only in so far as it de-\npends on PDF tools to convert the documents into text.3\n2 De\ufb01ning genre classi\ufb01cation\n2.1 Document representation in conventional text\nclassi\ufb01cation\nThe conventional method of text classi\ufb01cation can be\ncontracted to a formula for the weight of a term T\nwithin a document expressed by:\nTF \u00d7 IDF \u00d7 N (1)\nwhere TF denotes the frequency of the term in the doc-\nument, IDF denotes the number of documents in the\ncollection containing the term, and N denotes a nor-\nmalisation factor dependent on the length of the doc-\nument. The calculation method of each of these terms\ndi\ufb00ers according to the research or application in ques-\ntion. This model is based on the notion that: if a term\nappears frequently in a document, it is likely to be a\ncharacterising feature of the document; if a term ap-\npears across several documents, then it is not likely to\nbe a strong feature in distinguishing any one of those\ndocuments from the others; and if the same term ap-\npears in equal numbers within a short document and\na long one, then it is likely to be a stronger feature\nof the short document. While it may be considered a\ngross simpli\ufb01cation to represent all the various classi-\n\ufb01cation methods by this one description, it still seems\ntrue that the basic principles that drive various text\nclassi\ufb01cation methods are closely related to this model.\nIn a subject classi\ufb01cation task, the term may surface as\nwords or N-grams (N consecutive words or characters),\nwhile in other classi\ufb01cation tasks term may manifest\nitself also as functional groups of words (e.g. verb) or\ncombinations of such words and phrases and groups.\nNevertheless, the mechanism driving the classi\ufb01cation\nis largely dependent on counting patterns, and weighing\nthe number against the pattern count throughout the\ncollection being examined. The location of patterns, the\nrelationship between instances of the patterns, and the\ninterplay between di\ufb00erent types of patterns are largely\nbypassed and only represented implicitly through the\nsame counting process.\n2.2 Harmonic descriptor representation (HDR) of\ndocuments\nA document can be described as a sequence of symbols.\nSymbols should not be confused with the alphabet of a\nnatural language, although they may take the form of\nalpha-numeric characters in some cases. In the present\nterminology, each symbol may form any group of these\ncharacters or a much larger set of characters (e.g. white\nspace, %, + and ?) and could also refer only to the\nfunctional category of a group of characters (e.g. the\npart-of-speech).\nBecause of its static appearance, a document is of-\nten misunderstood to be time independent, but the in-\nterpretation of each symbol is possible only as a conse-\nquence of its temporal relationship to other symbols. In\nthis light, document classi\ufb01cation can be considered to\nbe a subtask of signal processing. Viewed in this way,\nan accurate measure of term frequency is expressed by\nhow many times a symbol occurs with respect to time.\nThe term weight calculated in Section 2.1 presents no\nawareness of the role of temporal progression in the se-\nmantic analysis of the document. That is, if the word\n\u201cclock\u201d were to appear in two documents ten times,\nthen the weight of this word would be equal with re-\nspect to both documents: the fact that the word appears\nonly in the \ufb01rst half of the document with respect to\none of the documents in contrast to being evenly dis-\ntributed throughout the document (which may be the\ncase with respect to the other document) would be dis-\nregarded. A proper consideration of the time dimension\nwould suggest \u201cclock\u201d in the \ufb01rst document as a signal\nhaving twice the frequency of that of the second doc-\nument, but lasting only half the length of time. Time\nshould not be taken to be the length of the text. Al-\nthough the two are closely related, the length of the text\nis not equivalent to the tempo of the piece of writing,\nbeginning with an introduction and ending with a con-\nclusion. To understand the notion of time, we will com-\npare a document to a string of a musical instrument.\nAn occurrence of a symbol within the document parti-\ntions the document into two parts. If the two partitions\nare equal in length, then the phase division is akin to\na harmonic with twice the frequency of the fundamen-\ntal of the string (the document with zero occurrence of\nthe symbol). If the division is not equal, then the fre-\nquency can not be considered to be uniform throughout\nthe document.\nIn the case of topic detection, a loose application of\ntime (e.g. taking the frequency to be uniform through-\nout the document) may be su\ufb03cient to capture salient\nvocabulary, but in other types of classi\ufb01cation, where\nthe main interest lies in the physical or conceptual struc-\nture of the object, the lack of temporal and relational\nplacement of symbols contributes to a considerable loss\nof information. To \ufb01ll this gap, we propose incorporat-\ning the symbols range and period as an e\ufb00ective means\nof characterising the symbol with respect to document\nstructure. We de\ufb01ne range as the interval between the\ninitial and ultimate occurrence of the symbol, and pe-\nriod as the time duration between two consecutive oc-\ncurrences of the symbol. When the symbol occurs at\nregular intervals, the resulting signal in the document4\nis akin to a harmonic of the document as a wave. Brook-\nstein, Klein and Raita [5] observed that content-bearing\nwords would clump together and therefore result in\nnon-harmonic behaviour. In contrast to the content-\nbearing words that they discuss, our research focuses\non words that may be indicative of style and struc-\nture. We observe that document structure is captured\nby words displaying both harmonic and non-harmonic\nbehaviour; harmonic words de\ufb01ne the physical struc-\nture of the document, while non-harmonic words de\ufb01ne\nconceptual landmarks or structure. In our description,\nwe attempt to capture the degree of non-harmonic be-\nhaviour using three quantities derived from the range\nand period of each symbol:\n1. The time duration before the \ufb01rst occurrence within\nthe document of the symbol (FP), measured by the\nnumber of characters (including white space) before\nthe symbol, divided by the number of characters in\nthe entire document.\n2. The average period ratio (AP), de\ufb01ned as 1 if all the\nperiods between two consecutive occurrences of the\nsymbol are zero, and, otherwise, as T\/(N \u00d7 MP),\nwhere:\n\u2013 T is the number of characters in the entire doc-\nument minus the total number of times the sym-\nbol occurred within the document;;\n\u2013 N is the total number of occurrences of the sym-\nbol plus one; and\n\u2013 MP is the maximum number of characters found\nbetween two consecutive occurrences of the sym-\nbol.\n3. The time duration after the last occurrence of the\nsymbol to the end of the document (LP), measured\nby the number of characters after the last symbol\ndivided by the number of characters in the entire\ndocument.\nThe more harmonic the behaviour of a symbol, the\ncloser AP will be to 1. In Figure 1, we display an ex-\nample of six documents (D1 to D6) of di\ufb00erent lengths,\nportrayed as blue strips where the top of the strip is the\nbeginning of the document. Occurrences of symbols in\nthe documents (s1 to s7) have been represented as hor-\nizontal lines across the strips. The period between two\nconsecutive occurrences have been indicated to be x.\nThis example will be used in Figures 2, 3, and 4 to\ndemonstrate how FP, LP, and AP change under di\ufb00er-\nent conditions.\nWe present in Figure 2, a graph illustrating how\nFP,LP and AP change as the position of a symbol oc-\ncurring once in D1 (see Figure 1) changes from s1 to s7.\nIn Figure 3, we show how FP,LP and AP for a symbol\noccurring twice in D1 change with respect to the period\nbetween the two instances, as the second occurrence of\nFig. 1 Example of symbol occurrence in six documents of dif-\nferent lengths.\nFig. 2 FP, LP, and AP with respect to the position (X-axis) of\na single occurrence of a symbol in D1.\nthe symbol moves away from the \ufb01rst occurrence. Fi-\nnally, the graph in Figure 4 presents how FP,LP and\nAP, for a symbol occurring once halfway between s1\nand s2, change as the document length varies.\nGiven a document, each word or symbol in the doc-\nument is associated to their FP, LP and AP values. By\ntaking all the words in a collection or by using a pre-\ncompiled list of indicative words (say, in either case,\nthe resulting word list is of size N), each document\ncan be represented as a vector of dimension 3N, where\neach term in the vector is the FP, LP, or AP value of\neach word. In our model we pre-compiled a list of words\nfrom a sample dataset (which is discarded from the test\ndataset after the words are collected) by aggregating a\nlist of words that appear in 75% of all the documents\nin at least one genre class in the sample dataset.5\nFig. 3 FP, LP, and AP for a symbol occurring twice in D1 as\nthe period between the two instances become larger.\nFig. 4 FP, LP, and AP for a symbol occurring once in the same\nposition relative to the beginning of di\ufb00erent length documents.\nThe relevance of term distribution has been men-\ntioned by others including Manning et al. [17], and,\nmore recently, by De Roeck et al. [7] who carried out\na study of pro\ufb01ling datasets to determine the degree of\nhomogeneity or heterogeneity in the distribution of fre-\nquent terms. However, there have only been few explicit\nimplementations of the measurement for the purpose\nof automated classi\ufb01cation, and most of these previous\nanalyses have been based on a count of words in selected\nchunks of the texts. The model presented here compares\nrelative distances between term instances. The latter\napproach views the entire document as a time depen-\ndent whole, and does not involve arbitrary choices of\nchunk sizes.\n2.3 Genre classi\ufb01cation\nWhile the de\ufb01nition of genre may not be easily pinned\ndown, there is general agreement that genre is a concept\nthat can be used to categorise documents by structure\nand function. In fact, the structural properties (e.g. the\nexistence of a title page, chapter, section, the number\nof columns, use of diagrams, and font variations) evolve\nin ways that are designed to optimise the document\u2019s\ncapability to ful\ufb01l its functional intention(s) (e.g. to de-\nscribe, to inform and to argue, to advertise) within its\ntarget environment (e.g. the user community, publisher\nand creator), much the same as the structure of an or-\nganism evolves to optimise its survival function in the\nnatural environment (cf. [16]). As a consequence, genre\nre\ufb02ects one or more of the following:\n\u2013 the intention of the creator (e.g. to inform, to argue,\nto instruct);\n\u2013 the interpretation of the user community (e.g. as a\ncollection of facts, an expression of opinion, a piece\nof research);\n\u2013 the prescription of a process (e.g. article for journal\npublication, job description for recruitment, min-\nutes of a meeting); and\n\u2013 the type of data structure (e.g. table, graph, chart,\nlist).\nThe model described in Section 2.1, while e\ufb00ective\nin distinguishing some intentional and interpretive as-\npects of genre, seems insu\ufb03cient to capture distinguish-\ning features in the case of prescriptive, conceptual or\nphysical structure. Such structure can be characterised\neven by low frequency terms of the class (e.g. single\noccurrence of \u201cminutes\u201d in the title of meeting min-\nutes, or headings in a curriculum vitae), and the dis-\ntributional pattern of words throughout the document\n(variation of density) is often bound to its class (e.g.\nthe even distribution of wh-words in a FAQ sheet). The\nlast observation is a generalisation of the observation by\nBrookstein, Klein and Raita [5], who noted the clump-\ning properties of content-bearing words and their role\nin text classi\ufb01cation. In contrast to the content-bearing\nwords that they discuss, we are interested also in words\nindicative of style and structure. These words can ex-\nhibit both clumping and uniform distribution proper-\nties. We present evidence that documents of each genre\nclass display distinctive distributional characteristics.\nHere we have adopted the genre schema of seventy\nclasses (KRYS I corpus)introduced in Kim and Ross\n[15], [16], constructed to represent these aspects from\ndi\ufb00erent perspectives, as well as Santini\u2019s data set ([21])\nconsisting of seven webpage classes. We use twenty four\nclasses from KRYS I and Santini\u2019s dataset as a sam-\nple testbed, altogether consisting of 3,452 documents\nin thirty-one genres, to test the harmonic descriptor\nrepresentation of documents described above. The test\nwas initially con\ufb01ned to thirty-one genres in order to\nlimit the computation time. The twenty-four classes\nfrom KRYS I were selected more or less at random6\nTable 1 Number of words found in seven out of ten documents\nbelonging to three genres (top row) with respect to word type (left\ncolumn). Median length of documents in each genre are expressed\nin the parentheses next to the genre label as number of bytes.\nPoem\n(1718)\nLetter\n(4265)\nThesis\n(132993)\nArticle 2 2 3\nWh-word 0 0 6\nModal 0 1 9\nHave Verb 0 1 3\nBe Verb 1 3 7\nVerb 0 0 29\nNoun 0 0 46\nSubject Pronoun 2 1 4\nObject Pronoun 0 0 1\nPossessive Pronoun 0 0 0\nPossessive Adjective 0 0 2\nAdjective 1 1 43\nAdverb 0 1 29\nQuanti\ufb01er 0 1 9\nDemonstrative 1 2 6\nConjunction 1 3 9\nPreposition 5 8 20\nPunctuation 2 3 4\nOther 1 1 12\napart from an e\ufb00ort to select a porportion of classes\nfrom each of the ten genre groups presented in [16].\nIn Section 5, we will compare support vector ma-\nchine (SVM) classi\ufb01cation using the harmonic descrip-\ntor representation of documents (this is modelled using\nWeka machine learning software [24]) against the SVM\nclassi\ufb01cation performed using the Bow Toolkit rainbow\ntext classi\ufb01er developed by MacCallum [18], and the\nclassi\ufb01cation attempts of Santini [21], to show that the\nperformance is consistently better when using the new\ndescription. The reason we have selected SVM as the\nclassi\ufb01cation method is that it showed the best results\nfor rainbow when compared with Rocchio\/TFIDF and\nNaive Bayes.\nThe symbols (selected to be words in the experi-\nments here) we will examine with respect to SVM HDR\nin the experiments were compiled by examining a sam-\nple dataset, a small slice of the corpus set aside, for\nwords that appear in a large number of documents (but\nnot necessarily frequently in any one document) in each\ngenre. The list is intended to represent a set of words\nproli\ufb01c within at least one genre in the collection. The\nwords collected are expected to include stop words and\nhmtl tags. As a sample, we present the number of words\nfound to be proli\ufb01c in the genre classes Poem, Letter\nand Thesis with respect to word type (WT), after ex-\namining ten random documents in each class (Table 1).\nMost of the numbers in Table 1 are not very illuminat-\ning by itself in that the median lengths of documents\nbelonging to Poem, Letter and Thesis are 1718, 4265,\nand 132994, respectively (in bytes), that is, we expect\nthe numbers to be increasing in that oder for each type\nof word. However, we immediately notice an exception\nin this pattern with respect to subject pronouns, and,\ncloser examination of the actual words show that at\nleast one of the two subject pronouns found to be pro-\nli\ufb01c in poems (i.e. \u201cyou\u201d and \u201cI\u201d) is not found to be as\nproli\ufb01c in letters (i.e. \u201cit\u201d) and theses (i.e. \u201cI\u201d, \u201cwe\u201d,\n\u201cthey\u201d, \u201cit\u201d). Further, the word \u201cDear\u201d is only found\nto be proli\ufb01c within letters.\nTo illustrate how the FP, LP and AP of the HDR\ndescription varies across documents of the same genre\nwe present a snapshot of these values with respect to\nthe word \u201cwhose\u201d across 90 poems, 100 theses, 91 let-\nters and 91 technical reports in Figure 5. The segments\ncorresponding to the documents belonging each genre\nare indicated at the bottom of the \ufb01gure. The \ufb01gure\nshows that FP, LP, and AP are similar for documents\nbelonging to the same genre but diverge as we move\nacross documents belonging to di\ufb00erent genres.\n3 Classi\ufb01ers\nWe used two di\ufb00erent classi\ufb01ers in the experiments de-\nscribed in Section 5: the support vector machine (SVM)\nrainbow text classi\ufb01er [18] and the SVM harmonic de-\nscriptor representation (HDR) classi\ufb01er modelled using\nthe Weka machine learning toolkit [24]. The rainbow\ntext classi\ufb01er, included in the BOW toolkit developed\nby Andrew McCallum [18], indexes the alpha-numeric\ncontent of the text for an analysis of signi\ufb01cant term\nfrequencies. It supports several statistical methods for\nevaluation. We have used the SVM, which has been\nproven to be e\ufb00ective in other text classi\ufb01cation tasks\n[23]. As we mentioned at the end of Section 2.2, in\nour model, the HDR uses a pre-compiled list of words.\nFor the experiments reported in Section 5, we set aside\nten random documents from each of the genres in the\ndataset and collected all the words that appear in more\nthan 75% of the documents in each genre. This list con-\nsists of 2,477 words.\n4 Datasets\nA comparison of automated classi\ufb01cation methods on a\ndataset that has not been tested for human agreement\ncan give misleading information as human agreement\nanalysis conveys to us how clean the dataset is and the\nnature of the genre class schema of the dataset. The ex-\nperiments reported here were carried out on a collection\nconsisting of the genres in Table 2 (numbers of docu-\nments in each genre, excluding those used to construct\nthe word list in the previous section, are indicated in7\nFig. 5 Example of FP (top), LP (middle), and AP (bottom) values with respect to the word \u201cwhose\u201d across documents belonging to\nfour distinct genres (the documents corresponding to each of these genres are noted by segmentation indicated at the bottom of the\n\ufb01gure).\nparentheses). The dataset for the twenty-four document\ngenres were collected by:\n1. assigning genres to collectors (in this case students)\nwho retrieved from the Internet as many PDF \ufb01les\nas they could \ufb01nd in English; and\n2. having two classi\ufb01ers (in this case secretaries) reclas-\nsify the PDF documents using the initial schema but\nwithout the knowledge of the initial label for each\ndocument.\nNone of the labellers were given a de\ufb01nition for the gen-\nres in the schema. This was partly to establish whether\nthere was already a well understood genre vocabulary.\nThe human performance was examined by taking the\nnumber of labels given by a single labeller in agreement\nwith the other two labellers over the total number of\ndocuments on which the other two labellers agreed. The\nthree numbers obtained in this way are 0.675, 0.73 and\n0.829. Although the di\ufb00erence between the lowest and\nthe highest recall is a noticeable 14 per cent, this should\nbe viewed with the knowledge that the highest recall is\nthe result of student classi\ufb01cation while the lowest re-\ncall is that of secretary classi\ufb01cation.\nThe dataset for the seven webpage genres was ob-\ntained from Santini\u2019s collection available at her web-\nsite([21]).\n5 Results\nThe performance will be evaluated using one or more\nof three conventional metrics: accuracy, precision and\nrecall. To re-visit the de\ufb01nition for these terms, let N\nbe the total number of documents in the test data, Nc8\nTable 2 Scope of genres\nCreative Book of Fiction(29)\nPoem(90)\nDetermined by user con-\ntext\nEmail(90)\nExam\/Worksheet (90)\nForm (90)\nHandbook (90)\nLetter (91)\nMinutes (99)\nResum\u00b4 e\/CV\nSheet Music (90)\nSpeech Transcript (91)\nTechnical Manual (90)\nDetermined by organisa-\ntional prescription\nAbstract (89)\nAcademic Monograph (99)\nAdvertisement (90)\nBusiness Report (100)\nMagazine Article (90)\nScienti\ufb01c Article (90)\nMemo (90)\nPeriodicals (67)\nPoster (90)\nSlides (90)\nTechnical Report (91)\nThesis (100)\nWebpage genres Blog (190)\nEshop (190)\nFAQ (190)\nFront Page (190)\nList (190)\nPersonal Home Page (190)\nSearch Page (190)\nthe number of documents in the class C, TP(C) the\nnumber of documents correctly predicted to be a mem-\nber of class C, and FP(C) the number of documents\nincorrectly predicted as belonging to class C. Accuracy,\nA, is de\ufb01ned to be:\nA =\nP\nTP(C)\nN\n, (2)\nprecision, P(C), of class C is de\ufb01ned to be:\nP(C) =\nTP(C)\nTP(C) + FP(C)\n, (3)\nand recall, R(C), of class C is de\ufb01ned to be:\nR(C) =\nTP(C)\nNc\n. (4)\nIn addition we also examine the average of P(C)\nand R(C) expressed as the F-measure F(C) de\ufb01ned as\nF(C) = 2 \u2217 (P(C) \u2217 R(C))\/(P(C) + R(C)). Although\nsome debate surrounds the suitability of accuracy, pre-\ncision and recall as a measurement of information re-\ntrieval tasks, for classi\ufb01cation tasks they are still deemed\nto be a reasonable indicator of classi\ufb01er performance.\nIt should also be mentioned here that all the results\nreported in this section are based on the average taken\non ten-fold cross validation.\n5.1 Overall accuracy\nThe \ufb01gures in Table 3 are the overall accuracies of the\nsupport vector machine rainbow classi\ufb01er (SVM rain-\nbow), the support vector HDR classi\ufb01er (SVM HDR)\nand average human agreement. The classi\ufb01er we are\nconsidering to be a baseline classi\ufb01er in this comparison\nis the SVM rainbow classi\ufb01er. The human agreement is\nincluded to indicate the cleanliness level of the dataset\nbeing used.\nTable 3 Overall accuracy across all the genre classes.\nClassi\ufb01er SVM rainbow SVM HDR Human\nOverall accuracy 0.73 0.80 0.74\nThe numbers in Table 3 suggest that the perfor-\nmance level of the SVM rainbow classi\ufb01er is already\ncomparable to the average performance of three human\nlabellers, and shows that the SVM HDR improves on\nthe SVM rainbow classi\ufb01er by 7%.\nTo test the limits on a cleaner dataset, we analysed\nthe classi\ufb01cation results with respect to Santini\u2019s web-\npage corpus. This is the overall accuracy of the classi-\n\ufb01cation when the recall of the documents belonging to\nthe webpage genre classes is calculated upon the clas-\nsi\ufb01cation of the entire dataset into thirty-one classes.\nThere is a slight increase of 0.002 when the webpage\nclasses are classi\ufb01ed on their own. The results are shown\nin Table 4: the numbers suggest that SVM HDR is a\nstrong contender in webpage genre classi\ufb01cation.\nTable 4 Overall accuracy of classi\ufb01ers across webpage genres\n(Blog, Personal Home Page, FAQ, List, Search Page, EShop,\nFront Page).\nClassi\ufb01er SVM rainbow Santini\u2019s result SVM HDR\nAccuracy 0.92 0.89 0.96\n5.2 Precision and recall\nThe challenge in document classi\ufb01cation is to improve\nthe overall accuracy of the classi\ufb01cation without com-\npromising the performance with respect to any one class\nin the schema. In this section we will show that SVM\nHDR meets this challenge.\nIn Figures 6 and 7, we present the recall and pre-\ncision of SVM rainbow and SVM HDR with respect\nto each of our classes. The graphs show that SVM\nHDR outperforms SVM rainbow with respect to most\nof the classes in both recall and precision. The recall9\nFig. 6 Recall: a comparison, SVM rainbow and SVM HDR.\nFig. 7 Precision: a comparison, SVM rainbow and SVM HDR.\nof SVM rainbow with respect to Academic Monograph,\nBook of Fiction, Front Page (of a website), Minutes,\nperiodicals, Technical Manual and Thesis is Marginally\nhigher than SVM HDR and the precision of SVM rain-\nbow with respect to Abstract, Exam\/Worksheet, Home\nPage, Poem, and Slides is somewhat higher than that\nof SVM HDR. However, with respect to the majority\nof the classes, SVM HDR outperforms SVM rainbow.\nThe graphs also demonstrates that SVM rainbow\u2019s\nperformance varies widely across di\ufb00erent genres, while\nthe deviation of performance is much more con\ufb01ned in\nthe case of SVM HDR. The recall (resp. precision) of\nSVM rainbow ranges from 0.08 to 1 (resp. 0.24 to 0.99),\nwhile recall (resp. precision) of SVM HDR ranges from\n0.42 to 1 (resp. 0.38 to 0.99). The di\ufb00erence between\nprecision and recall with respect to each class is also\nnotable: the maximum absolute di\ufb00erence between pre-\ncision and recall across the genre classes for SVM HDR\nis observed at approximately 0.24, while the same for\nSVM rainbow is observed at 0.46. The small deviation\nof performance across classes and the comparability of\nprecision and recall with respect to each class seems to\nsuggest that HDR is more successful in characterising\nthe genre classes.\nThe graph in Figure 8 presents the F-measures of\nSVM rainbow and SVM HDR with respect to each\nclass. This graph shows that the F-measures of SVM\nHDR are greater than those of SVM rainbow with re-\nspect to every class except the class Memo. With re-\nspect to Memo, the di\ufb00erence is 0.02 in favour of SVM10\nFig. 8 F-measure: a comparison, SVM rainbow and SVM HDR.\nrainbow. Latest experiments using HDR to analyse a\nnewgroup dataset of 19597 documents in twenty topi-\ncal classes (obtained from McCallum\u2019s website1), show\nthat the same SVM HDR model is also promising in\ntopic classi\ufb01cation, with an overall accuracy of over 95%\n(detailed report of this experiment available shortly). A\nlist of eighty-two words was compiled from 400 docu-\nments (20 documents from each genre) set aside from\nthe original 19997 documents for this experiment. We\nhave also calculated the F-measures of SVM HDR with\nrespect to the classes in this dataset to \ufb01nd them all\ngreater than the best results (overall accuracy 93.7%)\nof the rainbow classi\ufb01er. The details of this experiment\nwill be published shortly.\nIn the HDR of documents we have presented here,\nwe have measured FP, LP and APR with respect to\nthe length of the whole document. Just as perform-\ning discrete Fourier transform to obtain the harmonics\nof waves in signal processes involves sampling the sig-\nnal, documents can also be examined at di\ufb00erent res-\nolutions by varying the range in which harmonic be-\nhaviour is examined (e.g. when examining the string\n\u201caxbxcxdefghixjklmn\u201d, and examining the occurrences\nof \u201cx\u201d throughout the string, it does not seem to exhibit\nharmonic behaviour but, if you select the \ufb01rst seven\nletters \u201caxbxcxd\u201d, it is perfectly harmonic). It is likely\nthat shorter windows of examination will produce in-\nteresting comparisons.\n6 Conclusions\nThe results of automated experiments described in this\npaper provide evidence that the overall accuracy of the\nsupport vector machine rainbow text classi\ufb01er is al-\nready comparable to that of an average human clas-\nsi\ufb01er in genre classi\ufb01cation. Here we have shown that\nthe SVM HDR, which uses the layout of words in the\ndocument, outperforms the SVM rainbow text classi-\n\ufb01er. This makes it a promising candidate for further\nstudy. In particular, a comparison of the SVM HDR\nclassi\ufb01er against classi\ufb01ers other than SVM rainbow is\nrequired for fuller analysis. It would also be interesting\nto make direct comparisons of LP, FP and AP across\ngenre classes. This was omitted in this paper due to\ntime and space restrictions, but we are hoping to pub-\nlish a subsequent paper inclusive of this analysis.\nThe results with respect to Santini\u2019s dataset present\nevidence that SVM HDR might be superior to classi\ufb01ers\nthat rely on counts of terms or patterns. This conjec-\nture is again supported by comparing the result with\na recent report by Dong et al. [8] on the classi\ufb01cation\nof Santini\u2019s data belonging to four genres (best overall\naccuracy approximately 96 per cent). Although their\nnumbers are similar to ours, it must be noted that the\naccuracy presented in our paper is that obtained from a\nclassi\ufb01cation across seven webpage genres not classi\ufb01ed\nin isolation but classi\ufb01ed when accompanied by a clas-\nsi\ufb01cation of twenty-four additional document genres.\nPrevious text classi\ufb01cation methods actively inte-\ngrate mathematical methods in feature selection, sta-\ntistical modelling and error analysis, but the concept\nwe are trying to capture is still only described through\nexamples in the domain. This leads to a semantic gap\n(especially with high-level concepts such as those rep-\nresented by genre classes) not dissimilar to that en-\ncountered in image retrieval. A more rigorous study of11\ngenre is required to re\ufb02ect two considerations: \ufb01rst, we\nneed to scope di\ufb00erent communities for potentially use-\nful genre classes that can support other applications\nand, second, we need to incorporate basic mathemati-\ncal concepts into the actual description of the identi\ufb01ed\ngenres. Hence, future e\ufb00orts in this \ufb01eld should not only\nstudy the implication of term distribution versus term\nfrequency further by:\n\u2013 examining the resolution mentioned at the end of\nSection 5.2;\n\u2013 looking at, and comparing, other forms of symbols\napart from words; and\n\u2013 considering ways in which the two approaches might\nbe integrated\nbut also include user studies of genres to identify the\npossible applications to direct genre classi\ufb01cation work,\nand isolate base mathematical concepts that can be\nused to build the concepts gradually to describe higher-\nlevel concepts of genre.\nAcknowledgements The work presented in this paper was sup-\nported by DELOS: Network of Excellence on Digital Libraries1\n(G038-507618), funded under the European Commissions IST\nSixth Framework Programme,and the UK\u2019s Digital Curation Cen-\ntre (DCC)2, funded by the Joint Information Systems Committee\n(JISC)3 and the e-Science Core Programme of the Engineering\nand Physical Sciences Research Council (EPSRC)4[GR\/T07374\/01].\nReferences\n1. Bagdanov, A. and Worring, M. Fine-grained document genre\nclassi\ufb01cation using \ufb01rst order random graphs. In Proceed-\nings Sixth International Conference on Document Analysis and\nRecognition (ICDAR2001), 79-90. (2001)\n2. Barbu, E., Heroux, P., Adam, S. and Turpin, E. Clustering\ndocument images using a bag of symbols representation. In\nProceedings International Conference on Document Analysis\nand Recognition, 1216-1220.(2005)\n3. Bekkerman, R., McCallum, A. and Huang, G. Auto-\nmatic categorization of email into folders: benchmark ex-\nperiments on enron and sri corpora. Technical Report IR-\n418, Center for Intelligent Information Retrieval, UMASS.\n(2004) http:\/\/www.cs.umass.edu\/ \u02dc mccallum\/papers\/foldering-\ntr05.pdf\n4. Biber, D. Dimensions of Register Variation: a Cross-Linguistic\nComparison. Cambridge University Press, New York. (1995)\n5. Bookstein, A., Klein, S.T. and Raita, T. Clumping properties\nof content-bearing words. Journal of the American Society of\nInformation Science, 1998, 49(2): 102-114.(1998)\n6. dc-dot, UKOLN Dublin Core metadata editor.\nhttp:\/\/www.ukoln.ac.uk\/metadata\/dcdot\/\n7. De Roeck, A., Sarkar, A. and Garthwaite, P. Frequent Term\nDistribution Measures for Dataset Pro\ufb01ling. Technical Re-\nport 2004\/06. Faculty of Mathematics and Computing, Open\n1 http:\/\/www.delos.info\n2 http:\/\/www.dcc.ac.uk\n3 http:\/\/www.jisc.ac.uk\n4 http:\/\/www.epsrc.ac.uk\nUniversity. Milton Keynes, UK. (2004) http:\/\/computing-\nreports.open.ac.uk\/index.php\/\n8. Dong, L., Watters, C., Du\ufb00y, J. and Shepherd, M. An Ex-\namination of Genre Attributes for Web Page Classi\ufb01cation. In\nProceedings 41st Hawaiian International Conference on System\nSciences, IEEE Computer Society Press, ISBN-13: 978-0-7695-\n3075-8, ISBN-10: 0-7695-3075-3, ISSN: 1530-1605. (2008)\n9. Finn, A. and Kushmerick, N. Learning to classify documents\naccording to genre. Journal of American Society for Information\nScience and Technology, 57(11): 1506-1518. (2006)\n10. Giu\ufb00rida, G., Shek, E. and Yang, J. Knowledge-based meta-\ndata extraction from postscript \ufb01le. In Proceedings 5th ACM\nInternational Conference on Digital Libraries, 77-84. (2000)\n11. Han, H., Giles, L., Manavoglu, E., Zha, H., Zhang, Z. and\nFox, E.A. Automatic document metadata extraction using sup-\nport vector machines. In Proceedings 3rd ACM\/IEEE-CS Con-\nference on Digital Libraries, 37-48. (2003)\n12. Karlgren, J. and Cutting, D. Recognizing text genres with\nsimple metric using discriminant analysis. In Proceedings 15th\nConference on Computational Linguistics, 2: 1071-1075. (1994)\n13. Ke, S.W. and Bowerman, C. Perc: A personal email classi-\n\ufb01er. In Proceedings 28th European Conference on Information\nRetrieval (ECIR 2006), 460-463. (2006)\n14. Kessler, G., Nunberg, B. and Schuetze, H. 1997. Automatic\ndetection of text genre. In Proceedings 35th Annual Meeting\nACL, 32-38.\n15. Kim, Y. and Ross, S. Detecting family resemblance: Auto-\nmated genre classi\ufb01cation. CODATA Data Science Journal, 6:\nS172-S183. ISSN: 1683-1470. (2007)\n16. Kim, Y. and Ross, S. Searching for Ground truth: a step-\nping stone in automated genre classi\ufb01cation. LNCS 4877,\n248-261, Springer. DOI: 10.1007\/978-3-540-77088-6 (2007)\nhttp:\/\/www.springerlink.com\/content\/lt760613m2731723\/\nfulltext.pdf\n17. Manning, C. and Schutze, H. Foundations of Statistical Lan-\nguage Processing, MIT Press. Cambridge, MA. (1999)\n18. McCallum,A. Bow: A toolkit for statistical language mod-\neling, text retrieval, classi\ufb01cation and clustering. (1996)\nhttp:\/\/www.cs.cmu.edu\/~1mccallum\/bow\n19. Rauber, A. and Muller-Kogler, A. Integrating automatic\ngenre analysis into digital libraries. In Proceedings ACM\/IEEE\nJoint Conference on Digital Libraries, 1-10, Roanoke, VA.\n(2001) http:\/\/doi.acm.org\/10.1145\/379437.379439\n20. Ross, S. and Hedstrom, M. Preservation research and sus-\ntainable digital libraries. International Journal of Digital Li-\nbraries, v 5.4, 317-325. DOI: 10.1007\/s00799-004-0099-3. (2005)\nhttp:\/\/eprints.erpanet.org\/archive\/00000095\/\n21. Santini, M. PhD thesis, Univer-\nsity of Brighton, Brighton (UK). (2007)\nhttp:\/\/www.itri.brighton.ac.uk\/~Marina.Santini\/MSantini PhD\nThesis.zip\n22. Thoma, G. Automating the production of bibliographic\nrecords. Technical report, Lister Hill National Center for\nBiomedical Communication, US National Library of Medicine.\n(2001) http:\/\/archive.nlm.nih.gov\/pubs\/thoma\/mars2001.php\n23. Yang, Y., Zhang, J. and Kisiel, B. A scalability analysis of\nclassi\ufb01ers in text categorization. In Proceedings 26th annual\ninternational ACM SIGIR conference on research and develop-\nment information retrieval, 96-103. ISBN: 1-58113-646-3, 96-\n103. (2003)\n24. Witten, H.I. and Frank, E. Data mining: Practical machine\nlearning tools and techniques. 2nd edition, Morgan Kaufmann,\nSan Francisco. (2005)\n25. Details omitted to anonymise paper."}
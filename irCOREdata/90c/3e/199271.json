{"doi":"10.1086\/338940","coreId":"199271","oai":"oai:eprints.lse.ac.uk:2717","identifiers":["oai:eprints.lse.ac.uk:2717","10.1086\/338940"],"title":"Bayesian networks and the problem of unreliable instruments","authors":["Bovens, Luc","Hartmann, Stephan"],"enrichments":{"references":[{"id":17324408,"title":"An Introduction to Bayesian Networks.","authors":[],"date":"1996","doi":"10.2307\/1271143","raw":"Jensen, Finn V. (1996), An Introduction to Bayesian Networks. Berlin: Springer.","cites":null},{"id":17324410,"title":"Bayesian Networks and Decision Graphs.","authors":[],"date":"2001","doi":"10.1007\/978-1-4757-3502-4","raw":"(2001), Bayesian Networks and Decision Graphs. Berlin: Springer.","cites":null},{"id":17324423,"title":"Bayesianism and Diverse Evidence\u201d,","authors":[],"date":"1995","doi":"10.1086\/289842","raw":"Wayne, Andrew (1995), \u201cBayesianism and Diverse Evidence\u201d, Philosophy of Science 62: 111\u2013121.","cites":null},{"id":17324397,"title":"Comments on Stephan Hartmann and Luc Bovens, \u201cThe Import of Auxiliary Theories of the Instruments: a Bayesian-Network Approach\u201d,presented at the Paci\ufb01c APA.","authors":[],"date":"2001","doi":null,"raw":"Alexander, J. McKenzie (2001), Comments on Stephan Hartmann and Luc Bovens, \u201cThe Import of Auxiliary Theories of the Instruments: a Bayesian-Network Approach\u201d,presented at the Paci\ufb01c APA.","cites":null},{"id":17324412,"title":"Comments on Stephan Hartmann and Luc Bovens, \u201cThe Varietyof-Evidence Thesis and the Reliability of Instruments: a Bayesian Network Approach\u2019\u201d, presented at the Central APA.","authors":[],"date":"2001","doi":null,"raw":"Maher, Patrick (2001), \u2018Comments on Stephan Hartmann and Luc Bovens, \u201cThe Varietyof-Evidence Thesis and the Reliability of Instruments: a Bayesian Network Approach\u2019\u201d, presented at the Central APA.","cites":null},{"id":17324399,"title":"Conditional Independence in Statistical Theory\u201d,","authors":[],"date":"1979","doi":"10.1002\/0471667196.ess0618.pub2","raw":"Dawid, A. Philip (1979), \u201cConditional Independence in Statistical Theory\u201d, Journal of the Royal Statistical Society A41: 1\u201331.","cites":null},{"id":17324414,"title":"Dynamic Belief Networks for Discrete Monitoring\u201d,","authors":[],"date":"1994","doi":"10.1109\/21.328910","raw":"Nicholson, Ann E. and J.M. Brady (1994), \u201cDynamic Belief Networks for Discrete Monitoring\u201d, IEEE Systems, Man and Cybernetics 24: 1593\u20131610.","cites":null},{"id":17324402,"title":"Further Illustrations of the Bayesian Solution of Duhem\u2019s Problem\u201d, http:\/\/www.princeton.edu\/\u02dcbayesway\/Dorling\/dorling.html Earman,","authors":[],"date":"1996","doi":null,"raw":"Dorling, Jon (1996), \u201cFurther Illustrations of the Bayesian Solution of Duhem\u2019s Problem\u201d, http:\/\/www.princeton.edu\/\u02dcbayesway\/Dorling\/dorling.html Earman, John (1992), Bayes or Bust? A Critical Examination of Bayesian Con\ufb01rmation Theory. Cambridge MA: MIT Press.","cites":null},{"id":17324405,"title":"It Probably is a Valid Experimental Result: a Bayesian Approach to the Epistemology of Experiment\u201d,","authors":[],"date":"1988","doi":"10.1016\/0039-3681(88)90009-x","raw":"Franklin, Allan and Colin Howson (1988), \u201cIt Probably is a Valid Experimental Result: a Bayesian Approach to the Epistemology of Experiment\u201d, Studies in History and Philosophy of Science 19: 419\u2013427.","cites":null},{"id":17324398,"title":"Measuring Con\ufb01rmation\u201d,","authors":[],"date":"1999","doi":"10.2307\/2564707","raw":"Christensen, David (1999), \u201cMeasuring Con\ufb01rmation\u201d, Journal of Philosophy 96: 437\u201361.","cites":null},{"id":17324417,"title":"Novelty, Severity and History in the Testing of Hypothesis:","authors":[],"date":"1996","doi":"10.1086\/289958","raw":"Staley, Kent W. (1996), \u201cNovelty, Severity and History in the Testing of Hypothesis: the Case of the Top Quark\u201d, Philosophy of Science 93 (Proceedings) S248\u201355.","cites":null},{"id":17324413,"title":"Probabilistic Reasoning in Expert Systems.","authors":[],"date":"1990","doi":"10.2307\/1269559","raw":"Neapolitan, Richard E. (1990), Probabilistic Reasoning in Expert Systems. New York: Wiley.","cites":null},{"id":17324415,"title":"Probabilistic Reasoning in Intelligent Systems.","authors":[],"date":"1988","doi":"10.1016\/b978-0-08-051489-5.50007-2","raw":"Pearl, Judea (1988), Probabilistic Reasoning in Intelligent Systems. San Mateo, CA.: Morgan Kaufmann.","cites":null},{"id":17324411,"title":"Recent Work in Inductive Logic\u201d,","authors":[],"date":"1983","doi":"10.1017\/cbo9780511814273.017","raw":"Kyburg, Henry Jr. (1983), \u201cRecent Work in Inductive Logic\u201d, in Kenneth G. Lucey and Tibor R. Machan (eds.), Recent Work in Philosophy. Totowa, NJ: Rowman and Allenheld.","cites":null},{"id":17324407,"title":"Scienti\ufb01c Reasoning\u2014The Bayesian Approach. (2nd ed.) Chicago:","authors":[],"date":"1989","doi":"10.2307\/2348232","raw":"Howson, Colin and Peter Urbach ([1989] 1993), Scienti\ufb01c Reasoning\u2014The Bayesian Approach. (2nd ed.) Chicago: Open Court.","cites":null},{"id":17324416,"title":"Stochastic Independence, Causal Independence, and Shieldability\u201d,","authors":[],"date":"1980","doi":"10.1007\/bf00258078","raw":"Spohn, Wolfgang (1980), \u201cStochastic Independence, Causal Independence, and Shieldability\u201d, Journal of Philosophical Logic 9: 73\u201399.","cites":null},{"id":17324404,"title":"The Neglect of Experiment. Cambridge: Cambridge UniversityPress.","authors":[],"date":"1986","doi":"10.1017\/cbo9780511624896","raw":"Franklin, Allan (1986), The Neglect of Experiment. Cambridge: Cambridge UniversityPress.","cites":null},{"id":17324403,"title":"The Plurality of Bayesian Measures of Con\ufb01rmation and the problem of measure sensitivity\u201d,","authors":[],"date":"1999","doi":"10.1086\/392738","raw":"(1999), \u201cThe Plurality of Bayesian Measures of Con\ufb01rmation and the problem of measure sensitivity\u201d, Philosophy of Science 63: 652\u2013660.","cites":null},{"id":17324406,"title":"The Variety-of-Evidence Thesis and the Reliability of Instruments: A Bayesian-Network Approach\u201d, (forthcoming) http:\/\/philsci-archive.pitt.edu\/documents\/disk0\/00\/00\/02\/35\/index.html","authors":[],"date":"2001","doi":null,"raw":"Hartmann, Stephan and Luc Bovens (2001), \u201cThe Variety-of-Evidence Thesis and the Reliability of Instruments: A Bayesian-Network Approach\u201d, (forthcoming) http:\/\/philsci-archive.pitt.edu\/documents\/disk0\/00\/00\/02\/35\/index.html Horwich, Paul (1982), Probability and Evidence. Princeton: Princeton University Press.","cites":null},{"id":17324425,"title":"This content downloaded from 158.143.197.56 on Wed,","authors":[],"date":"2013","doi":null,"raw":"This content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM All use subject to JSTOR Terms and Conditions","cites":null},{"id":17324400,"title":"Uni\ufb01ed Prediction and Diagnosis in Engineering Systems by Means of This content downloaded from 158.143.197.56 on Wed,","authors":[],"date":"1999","doi":null,"raw":"Dodier, Robert (1999), Uni\ufb01ed Prediction and Diagnosis in Engineering Systems by Means of This content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM All use subject to JSTOR Terms and Conditions\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e 72 Distributed Belief Systems. Ph.D. Dissertation\u2014Department of Civil, Environmental and Architectural Engineering, Boulder, CO: University of Colorado.","cites":null},{"id":17324420,"title":"What Experiment Did We just Do? Counterfactual Error Statistics and Uncertainties about the Reference Class\u201d, Talk presented at PSA","authors":[],"date":"2000","doi":"10.1086\/341054","raw":"(2000), \u201cWhat Experiment Did We just Do? Counterfactual Error Statistics and Uncertainties about the Reference Class\u201d, Talk presented at PSA 2000, Vancouver, BC, Canada.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2002","abstract":"We appeal to the theory of Bayesian Networks to model different strategies for obtaining confirmation for a hypothesis from experimental test results provided by less than fully reliable instruments. In particular, we consider (i) repeated measurements of a single test consequence of the hypothesis, (ii) measurements of multiple test consequences of the hypothesis, (iii) theoretical support for the reliability of the instrument, and (iv) calibration procedures. We evaluate these strategies on their relative merits under idealized conditions and show some surprising repercussions on the variety-of-evidence thesis and the Duhem-Quine thesis","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/199271.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/2717\/1\/Bovens_Bayesian_Networks_Problem_2002.pdf","pdfHashValue":"6ac2a7b7c1f864db5e0768fdec457b2f94299ee6","publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:2717<\/identifier><datestamp>\n      2013-05-09T13:19:26Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D5048<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/2717\/<\/dc:relation><dc:title>\n        Bayesian networks and the problem of unreliable instruments<\/dc:title><dc:creator>\n        Bovens, Luc<\/dc:creator><dc:creator>\n        Hartmann, Stephan<\/dc:creator><dc:subject>\n        B Philosophy (General)<\/dc:subject><dc:description>\n        We appeal to the theory of Bayesian Networks to model different strategies for obtaining confirmation for a hypothesis from experimental test results provided by less than fully reliable instruments. In particular, we consider (i) repeated measurements of a single test consequence of the hypothesis, (ii) measurements of multiple test consequences of the hypothesis, (iii) theoretical support for the reliability of the instrument, and (iv) calibration procedures. We evaluate these strategies on their relative merits under idealized conditions and show some surprising repercussions on the variety-of-evidence thesis and the Duhem-Quine thesis.<\/dc:description><dc:date>\n        2002<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/2717\/1\/Bovens_Bayesian_Networks_Problem_2002.pdf<\/dc:identifier><dc:identifier>\n          Bovens, Luc and Hartmann, Stephan  (2002) Bayesian networks and the problem of unreliable instruments.  Philosophy of Science, 69 (1).  pp. 29-72.  ISSN 0031-8248     <\/dc:identifier><dc:relation>\n        http:\/\/www.journals.uchicago.edu\/PHILSCI\/<\/dc:relation><dc:relation>\n        10.1086\/338940<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lse.ac.uk\/2717\/","http:\/\/www.journals.uchicago.edu\/PHILSCI\/","10.1086\/338940"],"year":2002,"topics":["B Philosophy (General)"],"subject":["Article","PeerReviewed"],"fullText":"  \nLuc Bovens and Stephan Hartmann \nBayesian networks and the problem of \nunreliable instruments  \n \nArticle (Published version) \n(Refereed) \n \n \n \n \nOriginal citation: \nBovens, Luc and Hartmann, Stephan (2002) Bayesian networks and the problem of unreliable \ninstruments. Philosophy of science, 69 (1). pp. 29-72. \nDOI: 10.1086\/338940  \n \n\u00a9 2005 University of Chicago Press \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/2717\/ \nAvailable in LSE Research Online: May 2013 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \nBayesian Networks and the Problem of Unreliable Instruments\nAuthor(s): Luc\u00a0Bovens and Stephan\u00a0Hartmann\nSource: Philosophy of Science, Vol. 69, No. 1 (March 2002), pp. 29-72\nPublished by: The University of Chicago Press on behalf of the Philosophy of Science Association\nStable URL: http:\/\/www.jstor.org\/stable\/10.1086\/338940 .\nAccessed: 08\/05\/2013 12:12\nYour use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at .\nhttp:\/\/www.jstor.org\/page\/info\/about\/policies\/terms.jsp\n .\nJSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of\ncontent in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms\nof scholarship. For more information about JSTOR, please contact support@jstor.org.\n .\nThe University of Chicago Press and Philosophy of Science Association are collaborating with JSTOR to\ndigitize, preserve and extend access to Philosophy of Science.\nhttp:\/\/www.jstor.org \nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n29\n*Received January 2000; revised June 2001.\n\u2020Send reprint requests to Luc Bovens, University of Colorado at Boulder, Dept. of\nPhilosophy, CB 232, Boulder, CO 80309\u2014e-mail: bovens@spot.colorado.edu or to Ste-\nphan Hartmann, University of Konstanz, Dept. of Philosophy, 78457 Konstanz\u2014\ne-mail: Stephan.Hartmann@uni-konstanz.de\n\u2021We are grateful for comments from J. McKenzie Alexander, David R. Cox, Robert\nDodier, Malcolm Forster, Branden Fitelson, Allan Franklin, Patrick Maher, Iain Mar-\ntel, Frantis\u02c7ek Matus\u02c7, Theo Kuipers, Richard Scheines, Kent Staley and an anonymous\nreferee of this journal. The research was supported by the Alexander von Humboldt\nFoundation, the Federal Ministry of Education and Research, and the Program for\nInvestment in the Future (ZIP) of the German Government, by the National Science\nFoundation, Science and Technology Studies (SES 00-80580) and by the Transcoop\nProgram and the Feodor Lynen Program of the Alexander von Humboldt Foundation.\nStephan Hartmann also thanks Jim Lennox and the Center for Philosophy of Science\nat the University of Pittsburgh for their hospitality.\nPhilosophy of Science, 69 (March 2002) pp. 29\u201372. 0031-8248\/2002\/6901-0002$10.00\nCopyright 2002 by the Philosophy of Science Association. All rights reserved.\nBayesian Networks and the Problem\nof Unreliable Instruments*\nLuc Bovens and Stephan Hartmann\u2020\u2021\nUniversity of Colorado at Boulder and University of Konstanz\nWe appeal to the theory of Bayesian Networks to model different strategies for ob-\ntaining confirmation for a hypothesis from experimental test results provided by less\nthan fully reliable instruments. In particular, we consider (i) repeated measurements of\na single test consequence of the hypothesis, (ii) measurements of multiple test conse-\nquences of the hypothesis, (iii) theoretical support for the reliability of the instrument,\nand (iv) calibration procedures. We evaluate these strategies on their relative merits\nunder idealized conditions and show some surprising repercussions on the variety-of-\nevidence thesis and the Duhem-Quine thesis.\n1. Introduction. How can experimental test results from less than fully\nreliable instruments (LTFR instruments) provide confirmation for a sci-\nentific hypothesis? A range of strategies has been discussed in the litera-\nture, but only a few attempts have been made to give a Bayesian analysis\nof these strategies (Franklin 1986, 165\u2013191; Franklin and Howson 1988).\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e30\nThis is unfortunate, since such an analysis proves to be rewarding in many\nrespects. First, it enables us to construct a taxonomy of strategies. In sci-\nentific practice, these strategies often occur in mixed forms. The models\npermit us to isolate certain general strategies and to draw some perspic-\nuous analytical distinctions within each genus. Second, it shows that under\ncertain constraints these strategies are indeed legitimate strategies: it is\npossible for a hypothesis to receive strong confirmation, even when sci-\nentific instruments to test them are less than fully reliable. Third, it yields\nrather surprising claims about the conditions under which specific strate-\ngies for dealing with LTFR instruments are more and less successful.\nWhy has there been so little interest within Bayesian circles in the status\nof experimental reports from LTFR instruments? The task of modeling\neven the simplest strategies is daunting. We need more powerful tools to\ndo the job: here is where Bayesian Networks come in handy. Over the last\ntwo decades, the theory of Bayesian Networks has been developed in ar-\ntificial intelligence on the dual pillars of graph theory and the theory of\nconditional independence structures. Although the theory certainly has\nsome philosophical roots, philosophers of science have done little to har-\nvest its fruits. This is what we intend to do in addressing the questions at\nhand.\nWe will investigate the following types of strategies for obtaining a\nrespectable degree of confirmation with LTFR instruments by modeling\nthese strategies under certain idealizations:\n\u2022 Strategy 1. Repeated measurements with a single LTFR instrument\nor single measurements with multiple independent LTFR instru-\nments of a single test consequence of a hypothesis yielding the same\ntest results.\n\u2022 Strategy 2. Repeated measurements with a single instrument or sin-\ngle measurements with multiple independent LTFR instruments of\nmultiple test consequences of a hypothesis yielding coherent test re-\nsults.\n\u2022 Strategy 3. We find support for the LTFR instrument in an auxiliary\ntheory which may or may not be dependent on the hypothesis under\ninvestigation.\n\u2022 Strategy 4. The LTFR instrument is calibrated against the test re-\nsults of a single or of multiple independent instruments that are\nmore reliable than the LTFR instrument.\n2. Modeling Confirmation with a LTFR Instrument. Consider a very simple\nscenario. Let there be a hypothesis, a test consequence of the hypothesis,\na LTFR instrument and a report from the LTFR instrument to the effect\nthat the test consequence holds or not. To model this scenario, we need\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 31\nfour propositional variables (written in italic script) and their values (writ-\nten in roman script):\n\u2022 HYP can take on two values: HYP, i.e. the hypothesis is true and\n, i.e. the hypothesis is false;HYP\n\u2022 CON can take on two values: CON, i.e. the test consequence holds\nand , i.e. the test consequence does not hold;CON\n\u2022 REL can take on two values: REL, i.e. the instrument is reliable\nand , i.e. the instrument is not reliable;REL\n\u2022 REP can take on two values: REP, i.e. there is a positive report, or,\nin other words, a report to the effect that the test consequence holds\nand , i.e. there is a negative report, or, in other words, a reportREP\nto the effect that the test consequence does not hold.\nA probability distribution over these variables contains 24 entries. The\nnumber of entries will grow exponentially with the number of proposi-\ntional variables. To represent the information in a more parsimonious\nformat, we construct a Bayesian Network.\nA Bayesian Network organizes the variables into a Directed Acyclical\nGraph (DAG), which encodes a range of (conditional) independences. A\nDAG is a set of nodes and a set of arrows between the nodes under the\nconstraint that one does not run into a cycle by following the direction of\nthe arrows. Each node represents a propositional variable. Consider a\nnode at the tail of an arrow and a node at the head of an arrow. We say\nthat the node at the tail is the parent node of the node at the head and that\nthe node at the head is the child node of the node at the tail. There is a\ncertain heuristic that governs the construction of the graph: there is an\narrow between two nodes if the variable in the parent node has a direct\ninfluence on the variable in the child node.\nIn the case at hand, whether the test consequence holds is directly in-\nfluenced by and only by whether the hypothesis is true or not; whether\nthere is a report to the effect that the test consequence holds is directly\ninfluenced by and only by whether the test consequence holds or not and\nby whether the instrument is reliable or not. Hence, we construct the basic\ngraph in Figure 2.1 in which the node with the variable HYP is a parent\nnode to the node with the variable CON and the nodes with the variables\nCON and REL are in turn parent nodes to the node with the variable\nREP. Furthermore, root nodes are unparented nodes and descendant nodes\nare child nodes, or child nodes of child nodes etc. E.g., HYP and REL are\nroot nodes and CON and REP are descendant nodes of HYP in our graph.\nFrom DAG to Bayesian Network, one more step is required. We need\nto stipulate a probability distribution for the variables in the root nodes\nof the graph and a conditional probability distribution for the variables\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e32\n  HYP\n  CON   REL\n  REP\nP(HYP)=h\nP(CON|HYP)=p\nP(CON|HYP )=q\nP(REL)=r\nP(REP|CON,REL)=1\nP(REP|CON ,REL)=0\nP(REP|CON,REL )=a\nP(REP|CON ,REL )=a\nFigure 2.1 The basic model for testing with a LTFR instrument.\nin the other nodes given any combination of values of the variables in their\nrespective parent nodes.\nLet us turn to our example. First, we take care of the root nodes, i.e.\nwe assign a prior probability to the hypothesis and to the reliability of the\ninstrument:\n(1)P(HYP) \u0002 h with 0 \u0001 h \u0001 1\n(2)P(REL) \u0002 r with 0 \u0001 r \u0001 1\nSecond, consider the node with the variable CON which is a child node\nto the node with the variable HYP. We take a broad view of what con-\nstitutes a test consequence, that is, we do not require that the truth of the\nhypothesis is either a necessary or a sufficient condition for the truth of\nthe test consequence. Rather, a test consequence is to be understood as\nfollows: the probability of the consequence given that the hypothesis is\ntrue is greater than the probability of the consequence given that the hy-\npothesis is false:\n(3)P(CON|HYP) \u0002 p \u0002 q \u0002 P(CON| )HYP\nThird, consider the node with the variable REP, which is a child node to\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 33\nthe nodes with the variables CON and REL. How can we model the work-\nings of an unreliable instrument? Let us make an idealization: we suppose\nthat we do not know whether the instrument is reliable or not, but if it is\nreliable, then it is fully reliable and if it is not reliable, then it is fully\nunreliable. Let a fully reliable instrument be an instrument that provides\nmaximal information: it is an instrument that says of what is that it is,\nand of what is not that it is not:\n(4)P(REP|REL, CON) \u0002 1\n(5)P(REP|REL, ) \u0002 0CON\nLet a fully unreliable instrument be an instrument that provides minimal\ninformation: it is an instrument that is no better than a randomizer:\n(6)P(REP| , CON) \u0002 P(REP| , ) \u0002 a with 0 \u0001 a \u0001 1REL REL CON\nLet us call a the randomization parameter. (Compare Bovens and Olsson\n2000, 701\u2013703 for this construction.) We can now construct the Bayesian\nNetwork by adding the probability values to the graph in Figure 2.1.\nThe arrows in a Bayesian Network have a precise probabilistic mean-\ning: they carry information about the independence relations between the\nvariables in the Bayesian Network. This information is expressed by the\nParental Markov Condition:\n(PMC) A variable represented by a node in the Bayesian Network is\nindependent of all variables represented by its non-descendant\nnodes in the Bayesian Network, conditional on all variables\nrepresented by its parent nodes.\nHence, our Bayesian Network is constructed on grounds of the following\n(conditional) independences:\n(7)HYP \u0001 REL\n(8)CON \u0001 REL|HYP\n(9)REP \u0001 HYP|REL, CON\n(7) says that if one does not know any values of the variables, then coming\nto learn that the instrument is reliable or that the instrument is unreliable\ndoes not alter the prior probability that the hypothesis is true. This is a\nplausible assumption as long as one\u2019s reasons for believing that the in-\nstrument is reliable are independent of the truth of the hypothesis. In\nSection 5, we will investigate what happens when this assumption is vio-\nlated. (8) says that if one knows no more than that the hypothesis is true\nor that the hypothesis is false, then coming to learn in addition that the\ninstrument is reliable or that it is unreliable does not alter the probability\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e34\n1. The axioms for semi-graphoids are presented in Pearl (1988, 82\u201390). They first occur\nin Dawid (1979) and Spohn (1980). For details on the d-separation criterion, see Pearl\n(1988, 117\u2013118), Neapolitan (1990, 202\u2013207) and Jensen (1996, 12\u201314).\nthat the test consequence holds: as long as one does not know what report\nthe instrument provides, coming to learn about its reliability teaches us\nnothing about the test consequence. (9) says that if one knows no more\nthan that some definite values of REL and CON are instantiated, then\ncoming to learn in addition that some definite value of HYP is instantiated\ndoes not alter the probability of REP: the chance that the instrument will\nyield a positive or a negative report is fully determined by whether the\ninstrument is reliable and whether the test consequence holds or not; once\nthis information is known, the truth or falsity of the hypothesis itself be-\ncomes irrelevant. The latter two assumptions seem beyond reproach.\nThe Bayesian Network also represents a series of other conditional\nindependences, e.g. REP \u0001 HYP|CON. These independences can be de-\nrived by means of the semi-graphoid axioms, which are a set of axioms of\nconditional independence, from the conditional independences that can be\nread off the diagram by applying the (PMC). There is also a convenient\ncriterion, viz. the d-separation criterion, which permits us to read these\nsame conditional independences directly off of the graph. For the details,\nwe refer to the relevant literature.1\nWhat\u2019s so great about Bayesian Networks? A Bayesian Network con-\ntains information about the independence relations between the variables,\nprior probability assignments for each root node and conditional proba-\nbility assignments for each child node given its parent nodes. A central\ntheorem in the theory of Bayesian Networks states that a joint probability\ndistribution over any combination of values of the variables in the network\nis equal to the product of the prior probabilities and conditional proba-\nbilities for these values as expressed in the network (Neapolitan 1990, 162\u2013\n164). For example, suppose we are interested in the joint probability of\nHYP, , REP and . We can read the joint probability directly offCON REL\nFigure 2.1:\n(10)P(HYP, , REP, ) \u0002CON REL\nP(HYP)P( )P( |HYP)P(REP| , ) \u0002 h(1 \u0003 r)(1 \u0003 p)aREL CON CON REL\nStandard probability calculus teaches us how to construct marginal dis-\ntributions out of joint distributions and subsequently conditional distri-\nbutions out of marginal distributions.\nWe are interested in the probability of the hypothesis given that there\nis a report from a LTFR instrument that the test consequence holds. This\nprobability is P*(HYP) \u0002 P(HYP|REP) \u0002 P(HYP, REP)\/P(REP). For\nease of representation, we will abbreviate (1 \u0003 x) as x\u00af.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 35\n(11)P*(HYP) \u0002\nP(HYP)P(REL)P(CON|HYP)P(REP|CON,REL)\u0001\nCON,REL\nP(HYP)P(REL)P(CON|HYP)P(REP|CON,REL)\u0001\nHYP,CON,REL\nh(pr \u0004 ar\u00af)\n\u0002\n\u00af(hp \u0004 hq)r \u0004 ar\u00af\nWe measure the degree of confirmation that the hypothesis receives from\na positive report by the difference:\n\u00afhh(p\u0003 q)r\nP*(HYP) \u0003 P(HYP) \u0002 (12)\n\u00af(hp \u0004 hq)r \u0004 ar\u00af\nNote that P*(HYP) \u0003 P(HYP) \u0002 0 iff p\u0002q. To have some numerical\ndata, let h \u0002 r \u0002 a \u0002 1\/2 and let p \u0002 3\/4 and q \u0002 1\/4. Then P*(HYP)\n\u0002 5\/8 and P*(HYP) \u0003 P(HYP) \u0002 1\/8.\nWe know now how to model the degree of confirmation that a hypoth-\nesis receives from a single positive report concerning a single test conse-\nquence of the hypothesis by means of a single LTFR instrument. This\nbasic model will be the paradigm for modelling complex strategies to im-\nprove the degree of confirmation that can be obtained from LTFR instru-\nments.\n3. Same Test Results. Suppose that we have tested a single test consequence\nof the hypothesis by means of a single LTFR instrument. We have received\na positive report, but we want to have additional confirmation for our\nhypothesis. We might want to run more tests of the very same test con-\nsequence. Now there are two possibilities. Either we can take our old\nLTFR instrument and run the test a couple more times. Or we can choose\nnew and independent LTFR instruments and test the very same test con-\nsequence with these new instruments. First, we will show that both of these\nsubstrategies can be successful: if we receive more reports to the effect that\nthe test consequence holds, either from our old instrument or from new\nand independent instruments, then the hypothesis does indeed receive ad-\nditional confirmation. Second, we are curious to know which substrategy\nis the better strategy assuming that we do indeed receive more reports to\nthe effect that the test consequence holds. In other words, which substra-\ntegy yields a higher degree of confirmation? Is there an univocal answer\nto this question, or is one substrategy more successful under certain con-\nditions, while the other strategy is more successful under other conditions?\nTo keep things simple, we will present our analysis for one additional test\nreport, either from the same or from different LTFR instruments.\nLet us first model the degree of confirmation that the hypothesis re-\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e36\n  HYP\n  CON\n REP 1 REP 2\n   REL\nFigure 3.1 Multiple measurements with a single instrument of a single consequence.\nceives from an additional positive report from the same LTFR instrument.\nIn Figure 3.1, we add a node to our basic graph to represent the binary\nvariable REP2 and substitute REP1 for REP. Just like REP1, REP2 is\ndirectly influenced by REL and CON and so two more arrows are drawn\nin. We impose a condition of symmetry on the probability distribution P\nfor this graph and also require, for this second report, that the instrument\nis either fully reliable or it is fully unreliable with the same randomization\nparameter a.\nSecondly, we model the degree of confirmation that the hypothesis re-\nceives from an additional confirming report from a second independent\nLTFR instrument. In Figure 3.2, we add a node to our basic graph for\nthe variable REL2 which expresses whether the second instrument is re-\nliable or not and add a node for the variable REP2 which expresses\nwhether the second instrument provides a report to the effect that the test\nconsequence holds or not. REP2 is directly influenced by REL2 and CON:\nwe draw in two more arrows. To keep matters simple, we impose a con-\ndition of symmetry on the probability distribution P\u0005 for this graph: there\nis an equal chance r that both instruments are reliable and if the instru-\nments are unreliable then they randomize at the same level a. To compare\nthe scenario with one instrument to the scenario with two instruments we\nneed to impose a ceteris paribus condition: for this reason we postulate\nthe same values h, p, q, r and a for the probability distributions P and P\u0005.\nThe instruments are independent of one another. What this means is\nthat\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 37\n    HYP\n    CON\n  REP 2  REP 1\n  REL 2  REL 1\nFigure 3.2 Measurements with multiple instruments of a single consequence.\n(13)REPi \u0001 REPj|CON \u2200i,j \u0002 1,2 and i\u0001j.\nSuppose that we know that the consequence holds or we know that the\nconsequence does not hold. Then there is a certain chance that we will\nreceive a report to the effect that the consequence holds. Now whether we\nreceive another report to this effect or not, does not affect this chance. An\nindependent instrument may not always provide us with an accurate re-\nport, but it is not influenced by what other instruments report. It can be\nshown that (13) is a conditional independence that can be read off from\nthe graph in Figure 3.2.\nAre these strategies successful? The strategy of searching out an addi-\ntional report from the same LTFR instrument about the same test con-\nsequence always provides additional confirmation to the hypothesis:\nTheorem 1. DP \u0002 P(HYP|REP1,REP2) \u0003P(HYP|REP1) \u0002 0.\n(All theorems are proven in the appendix.) The strategy of searching out\nan additional report from a different LTFR instrument about the same\ntest consequence always provides additional confirmation to the hypoth-\nesis:\nTheorem 2. DP \u0002 P\u0005(HYP|REP1,REP2) \u0003 P\u0005(HYP|REP1) \u0002 0.\nWe turn to the question whether, ceteris paribus, the hypothesis receives\nmore confirmation from a second positive report from one and the same\nLTFR instrument or from independent LTFR instruments. We show in\nthe appendix that\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e38\nFigure 3.3 DP \u0002 0 iff positive reports from two instruments testing the same consequence\nyield more confirmation to the hypothesis than from a single instrument.\nTheorem 3. DP \u0002 P\u0005(HYP|REP1,REP2) \u0003P(HYP|REP1,REP2) iff\n1 \u0003 2a\u00afr\u00af \u0002 0.\nThe graph in Figure 3.3 represents this inequality. For values of (a,r)\nabove the phase curve, DP \u0002 0, i.e. it is better to receive reports from two\ninstruments; for values of (a,r) on the phase curve, DP \u0002 0, i.e. it does\nnot make any difference whether we receive reports from one or two in-\nstruments; for values of (a,r) below the phase curve, DP\u0001 0, i.e. it is better\nto receive reports from one instrument than from two instruments.\nDo these results seem plausible at an intuitive level? There are two\nconflicting intuitions at work here. On the one hand, we are tempted to\nsay that confirming results from two instruments is the better way to go,\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 39\n   HYP\nCON 1 CON 2\n REP 1\n \nREP 2\n   REL\nFigure 4.1 Measurements with a single instrument of multiple consequences.\nsince independence is a good thing. On the other hand, if we receive con-\nsistent positive reports from a single instrument, then we feel more con-\nfident that the instrument is not a randomizer and this increase in confi-\ndence in the reliability of the instrument supports the confirmation of the\nhypothesis. For higher values of r, the former consideration becomes more\nweighty than the latter: there is not much gain to be made anymore in our\nconfidence in the reliability of the instrument(s) and we might as well enjoy\nthe benefits of independence. For lower values of a, the latter considera-\ntion becomes more weighty: if we are working with an instrument which,\nif unreliable, has a low chance of providing positive reports, then consis-\ntent positive reports constitute a substantial gain in our confidence in its\nreliability, which in turn supports the confirmation of the hypothesis.\n4. Coherent Test Results. The second strategy to raise the degree of con-\nfirmation for a hypothesis is to identify a range of test consequences which\ncan all be assessed by a single or by multiple independent LTFR instru-\nments. Let us draw the graphs for two test consequences. Following our\nheuristic, the hypothesis (HYP) directly influences the test consequences\n(CONi for i \u0002 1,2). Figure 4.1 represents the scenario in which there is a\nsingle instrument: each test consequence (CONi) conjoint with the reli-\nability of the single instrument (REL) directly influences the report about\nthe consequence in question (REPi). Figure 4.2 represents the scenario in\nwhich there are two independent instruments: each test consequence\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e40\n  HYP\n CON 1 CON 2\n  REP 1  REP 2\n  REL 1   REL 2\nFigure 4.2 Measurements with multiple instruments of multiple consequences.\n(CONi) conjoint with the reliability of the instrument that tests this con-\nsequence (RELi) directly influences the report about the consequence in\nquestion (REPi). We define a probability distribution P for the DAG in\nFigure 4.1 and a probability distribution P\u0005 for the DAG in Figure 4.2.\nWe impose the symmetry condition within each distribution and the ceteris\nparibus condition between distributions for all the relevant parameters.\nWe can now check whether our strategies are successful. It turns out\nthat the strategy is always successful with multiple instruments:\nTheorem 4. DP \u0002 P\u0005(HYP|REP1, REP2) \u0003 P\u0005(HYP|REP1) \u0002 0.\nBut with a single instrument, the strategy is not always successful:\nTheorem 5. DP \u0002 P(HYP|REP1, REP2) \u0003 P(HYP|REP1) \u0002 0 iff pqr \u0004\nar\u00af(p \u0004 q \u0003 a) \u0002 0.\nIn Figure 4.3, we fix a \u0002 .5 and construct phase curves for high, medium\nand low range values of the reliability parameter r. In Figure 4.4, we fix r\n\u0002 .5 and construct phase curves for high, medium and low range values\nof the randomization parameter a. Since we have stipulated that p \u0002 q,\nwe are only interested in the areas below the straight line for p \u0002 q in\nboth figures.\nThe areas in these graphs in which DP \u0001 0 are certainly curious: for\ncertain values of p, q, a and r, we test a first consequence of a hypothesis,\nreceive a positive report and are more confident that the hypothesis is true;\nthen we test a second consequence of the hypothesis with the very same\ninstrument, receive once again a positive report . . . but this time around\nour degree of confidence in the hypothesis drops! How can we interpret\nthese results? Notice that the effect is most widespread for (i) lower values\nof r, (ii) higher values of a and (iii) lower values of p. To get a feeling for\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 41\nFigure 4.3 DP \u0002 0 iff two positive reports from a single instrument testing two conse-\nquences yield more confirmation to the hypothesis than one positive report testing a single\nconsequence for a \u0002 .5. The relevant region is the region where p \u0002 q.\nthe magic of the numbers, let us look at this range of values, where the\neffect occurs par excellence. Hence, let us consider instruments which are\nnot likely to be reliable, and, if unreliable, have a high chance of providing\na positive report, and test consequences which are unlikely to occur when\nthe hypothesis is true (though of course the test consequences are still more\nlikely to occur than when the hypothesis is false). Considering (i), we do\nnot have much trust in the instrument to begin with. Now it gives us\nnothing but positive reports: considering (ii), the instrument is likely to be\na randomizer and so we become even more confident that the instrument\nis unreliable. But should this not be offset by the fact that we receive\ncoherent test results in support of our hypothesis? No, since considering\n(iii), our tests are rather weak and these coherence effects count for little.\nHence, when we get a second positive report, we become very confident\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e42\nFigure 4.4 DP \u0002 0 iff two positive reports from a single instrument testing two conse-\nquences yield more confirmation to the hypothesis than one positive report testing a single\nconsequence for r \u0002 .5. The relevant region is the region where p \u0002 q.\n2. Note that by introducing scaled parameters, p\u0005 \u0002 p\/a and q\u0005 \u0002 q\/a, the parameter\na can be eliminated from theorems 5 and 6.\nthat the instrument is unreliable and consequently our confidence in the\nhypothesis drops.\nWe turn to the question whether, ceteris paribus, the hypothesis receives\nmore confirmation from a second positive report from one and the same\nLTFR instrument or from independent LTFR instruments. We have\nshown that\nTheorem 6. DP \u0002 P\u0005(HYP|REP1,REP2) \u0003 P(HYP|REP1,REP2) \u0002 0 iff\n(2a \u0003 p \u0003 q)a \u0003 2(a \u0003 p)(a \u0003 q) r \u0002 0.2\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 43\nFigure 4.5 DP\u0002 0 iff positive reports from two instruments testing two consequences yield\nmore confirmation to the hypothesis than positive reports from a single instrument testing\ntwo consequences for p \u0002 .9 and q \u0002 .1.\nTo evaluate this expression, we assume that the tests are reasonably strong\nby fixing p \u0002 .9 and q \u0002 .1 and construct a phase curve for values of (a,r)\nin Figure 4.5. If the randomization parameter and the reliability parameter\nare set low, then one instrument tends to do better than two. Subsequently\nwe assume mid-range values for the randomization and the reliability pa-\nrameters (a \u0002 .5 and r \u0002 .5) and construct a phase curve for values of\n(p,q) in Figure 4.6. We are interested in the area below the straight line\nwhere p \u0002 q. If the q-value is set high, i.e. if the test consequences occur\nfrequently also when the hypothesis is false, then one instrument tends to\ndo better than two.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e44\nFigure 4.6 DP\u0002 0 iff positive reports from two instruments testing two consequences yield\nmore confirmation to the hypothesis than positive reports from a single instrument testing\ntwo consequences for a \u0002 .5 and r \u0002 .5. The relevant region is the region where p \u0002 q.\nIn the previous section, we explained why the consideration that our\nconfidence in the reliability of a single instrument is boosted by coherent\npositive reports outweighs the consideration of the independence of mul-\ntiple instruments for lower values of a and r. The same explanation can\nbe repeated here. But why is this effect amplified for higher q-values? The\nhigher the q-values, the more likely the test consequences will hold true\nand so coherent positive reports will boost our confidence in the reliability\nof a single instrument even more. Hence higher q-values tend to favor a\nsingle over multiple instruments.\nIt is one of the textbook Bayesian success stories that an account can\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 45\n3. It is easy to prove that the ceteris paribus clause is respected in (i), (ii) and (iii) below.\nbe provided of why variety of evidence is a good thing: it is shown that\nthe increment of confirmation that the hypothesis receives from confirming\ntest results becomes smaller and smaller as we run the same old test over\nand again. (E.g. Earman 1992, 77\u201379 and Howson and Urbach 1993, 119\u2013\n123.) But what does it mean to run the same old test over and over again?\nWe could take it to mean that we check the same old test consequences\nrather than checking independent test consequences of the hypothesis. Or\nwe could take it to mean that we do our testing with the same old instru-\nment rather than with independent instruments. Presumably variety of\nevidence refers to multiple consequences as well as to multiple instruments.\nWe have in effect tested the variety-of-evidence thesis under this par-\nticular interpretation. There are two sets of evidence, one containing a less\nvaried pair and one containing a more varied pair of positive test reports.\nTo respect the ceteris paribus clause, we assume that each item of evidence\ni \u0002 1,2 within these sets j \u0002 1,2 has the same evidential strength, as\nexpressed by the likelihood ratio P(REPij|HYP)\/P(REPij| ). ThisHYP\nceteris paribus clause can be justified by means of the following analogy.\nSuppose one wants to test the claim that a varied set of investments prom-\nises a greater yield than a non-varied set. Then it would clearly be wrong\nto compare a varied set of investments that each have a high rating and a\nnon-varied set of investments that each have a low rating, or vice versa:\nthe ceteris paribus clause require that each investment within the respective\nsets has the same rating. Similarly, the ceteris paribus clause in this context\nrequires that each item of evidence within the respective sets has the same\nevidential strength.3 Given this the variety-of-evidence thesis implies that\na hypothesis receives more confirmation from a more varied set of evi-\ndence than a less varied set of evidence, ceteris paribus, in which more\nvaried evidence is taken to mean evidence that is obtained from multiple\ninstruments rather than a single instrument or evidence that reports on\nmultiple consequences rather than a single consequence.\nHowever, our investigation permits us to impose the following caveats\nconcerning this interpretation of the thesis. We argued in Section 3 that,\n(i) if we are testing a single consequence, it is sometimes more bene-\nficial for the confirmation of the hypothesis to receive positive re-\nports from the same instrument than from different instruments,\nceteris paribus.\nWhat we have seen in this section is that,\n(ii) if we are testing different consequences, it is sometimes more ben-\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e46\neficial for the confirmation of the hypothesis to receive positive\nreports from the same instrument than from different instruments,\nceteris paribus.\nAnd there is still another conclusion to be drawn from our results. We\nsaw in the previous section that it is always a good thing for the confir-\nmation of the hypothesis to receive a second positive report from the same\ninstrument about the same test consequence. In this section, we saw that\nour confidence in the hypothesis may decrease as we receive a second\npositive report from the same instrument about a different test conse-\nquence. Hence, we can add a third caveat:\n(iii) If we are testing with a single instrument, it is sometimes more\nbeneficial for the confirmation of the hypothesis to receive posi-\ntive reports about the same consequence rather than about dif-\nferent consequences, ceteris paribus.\nThere are two Bayesian approaches to the problem of the variety of\nevidence present in the literature (Wayne 1995). On the correlation ap-\nproach, the items of evidence E1, . . . , En are less varied the greater the\nrate of increase in the probability values P(E1), P(E2|E1), . . . , P(En|E1,\n. . . ,En\u00031) (Howson and Urbach 1993, 119\u2013123; Earman 1992, 77\u201379). On\nthe eliminative approach, a set of evidence E in support of the hypothesis\nHi is more varied, the lower the likelihoods P(E|Hj) for j \u0002 1, . . . , i\u00031,\ni\u00041, . . . , n: varied evidence is evidence that permits us to exclude more\ncompeting hypotheses (Horwich 1982, 118\u2013122 and Wayne 1995, 116).\nEach of these approaches starts from a particular pretheoretical intuition\nabout diversity. Our approach does no less: the pretheoretical intuition\nthat we start with is that evidence that proceeds from multiple instruments\nand that addresses multiple test consequences is more varied than evidence\nthat proceeds from a single instrument or that addresses a single test con-\nsequence.\nHow does our analysis compare to the correlation approach? It can\neasily be shown that P(REP1)\u0002P\u0005(REP1) in all of our comparative cases.\nHence, a set of evidence is the less varied on the correlation approach, the\nmore P(REP2|REP1) exceeds P(REP2) for P\u0002 P, P\u0005, which is indeed the\ncase for single (as opposed to multiple) instruments and for single (as\nopposed to multiple) test consequences. However, what our analysis shows\nis that this is no guarantee that the confirmation that the hypothesis re-\nceives will be smaller. For instance, consider the cases that are modeled\nby the Figures 3.1 and 3.2. Set h \u0002 .5, p \u0002 .9, q \u0002 .1, a \u0002 .2 and r \u0002 .2\nin both distributions. Then the prior probability P(REP1) \u0002 P\u0005(REP2)\n\u0002 .26 is the same, but there is a stricter correlation and hence less variety\nof evidence when the reports come from a single instrument than from\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 47\n4. We are grateful to Patrick Maher (2001) for forcing us to spell out our notion of\nvariety of evidence in comparison to the eliminative approach and to lay out the ceteris\nparibus clause that needs to be respected on our approach.\ntwo independent instruments, viz. P(REP2|REP1) \u0003 .51 \u0002 .30 \u0003\nP\u0005(REP2|REP1). However, the hypothesis receives more confirmation\nwhen the reports come from a single rather than from one instrument, viz.\nP(HYP|REP1,REP2) \u0003 .80 \u0002 .77 \u0003 P\u0005(HYP|REP1,REP2). Then how is\nit that formal results were established in the correlation approach? This\napproach makes the assumption that the evidence is strictly entailed by\nthe hypothesis, viz. P(E|H) \u0002 1. This is a restrictive constraint on the\nnotion of evidence and quite unrealistic in many contexts, e.g. in the con-\ntext of the diagnosis of disease. What our examples show is that less varied\nevidence may indeed provide more confirmation to the hypothesis, if we\nwork with a looser notion of evidence and relax the assumption to P(E|H)\n\u0002 p \u0002 q \u0002 P(E|H\u00af).\nLet us turn to the eliminative approach. Fitelson (1996, 654\u2013656) argues\nthat the eliminative approach requires the additional ceteris paribus as-\nsumption that the likelihoods of both sets of evidence on the hypothesis i\nmust be identical. What is the import of the eliminative approach when\nthere are only two hypotheses, viz. H and H\u00af, as is the case in our examples?\nSuppose that we want to ascertain whether a patient in a hospital has\nLyme disease (H). One set of evidence E contains vomiting, fever, . . .\nAnother set of evidence E\u0005 contains a recent tick bite, a characteristic rash,\n. . . It is plausible to set P(E|H) \u0002 P(E\u0005|H) and P(E|H\u00af) \u0002 P(E\u0005|H\u00af). Then\non the eliminative approach, E\u0005 is more varied than E. Fitelson\u2019s ceteris\nparibus condition is not satisfied, since P(REP1,REP2|HYP) \u0001\nP\u0005(REP1,REP2|HYP) in any of the cases that we are comparing. We do\nnot find this disconcerting, since the eliminative notion of variety of evi-\ndence is really a stretch of the ordinary notion. Certainly E\u0005 has more\ndiagnostic value than E, but is this due to it being more diverse? Note\nthat, on the eliminative approach, a single item of evidence could be more\nvaried than some other single item of evidence, which seems somewhat\nodd. What the eliminative approach seems to capture is how \u2018diversifying\u2019\nthe evidence is, i.e. what its capability is to distinguish between competing\nhypotheses. Furthermore, even if a case can be made that this notion\ncorresponds to an intuitively plausible notion of variety of evidence, the\nnotion we are trying to capture is still very different from the notion that\nis sought after in the eliminative approach.4\n5. Auxiliary Theories. Let us return to our basic model from Section 2. In\nthis model, the variable REL is a root node and we have assigned a prob-\nability value r which expresses the chance that the instrument is reliable.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e48\n  HYP\n  CON\n AUX\n   REL\n  REP\nP(AUX)=t\nP(REL|AUX)=1\nP(REL|AUX )=0\nP(CON|HYP)=1\nP(CON|HYP )=0\nFigure 5.1 The reliability of the instrument is supported by an independent auxiliary theory.\nIt is a common theme in contemporary philosophy of science that the\nworkings of the instrument are themselves supported by an auxiliary the-\nory of the instrument. If this is the case, then we should not model REL\nas a root node: whether the instrument is reliable or not is directly influ-\nenced by whether the auxiliary theory (AUX) holds or not. Just as we\nassigned a prior probability to the hypothesis, we also assign a prior prob-\nability t to the auxiliary theory. To keep matters simple, let us assume in\nthis section that the instrument is reliable just in case the auxiliary theory\nis correct and that the test consequence holds just in case the hypothesis\nis true. Our basic model is then expanded to the Bayesian Network in\nFigure 5.1. In this Bayesian Network, AUX and HYP are still independent.\nThis may or may not be a realistic assumption. Sometimes the auxiliary\ntheory has no relation whatsoever to the hypothesis under test. But some-\ntimes they are quite closely tied to each other: for instance, they may both\nbe parts of a broader theory. We can model this positive relevance between\nAUX and HYP by connecting both variables in the Bayesian Network and\nby setting P\u0005(AUX|HYP) \u0002 th \u0002 th \u0002 P\u0005(AUX| ) as in Figure 5.2.HYP\nHere are some questions:\n(i) Ceteris paribus, does the hypothesis receive more or less confir-\nmation if the auxiliary theory that supports the reliability of the\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 49\n   HYP\n   CON\n   AUX\n   REL\n   REP\nP\u00b4(CON|HYP)=1\nP\u00b4(CON|HYP )=0\nP\u00b4(REL|AUX)=1\nP\u00b4(REL|AUX )=0\nP\u00b4(AUX|HYP)=ht\nP\u00b4(AUX|HYP )= ht\nFigure 5.2 The reliability of the instrument is supported by a positively relevant auxiliary\ntheory.\ninstrument is independent rather than positively relevant to the\nhypothesis under test?\n(ii) Suppose that we receive a report from a LTFR instrument which\nprovides confirmation for the hypothesis. We now appeal to an\nauxiliary theory which provides support for the reliability of the\ninstruments, i.e. by bringing in an auxiliary theory we succeed in\nraising the reliability parameter r. Our question is the following:\nis this, ceteris paribus, a successful strategy for increasing the de-\ngree of confirmation of the hypothesis,\n(a) if the auxiliary theory is independent of the hypothesis;\n(b) if the auxiliary thesis is positively relevant to the hypothesis?\nLet us first take up question (i). To respect the ceteris paribus clause\nwe must make sure that the randomization parameter, the reliability pa-\nrameter and the prior probability of the hypothesis are fixed across both\nscenarios. To fix the reliability parameter, we must make sure t \u0002 thh \u0004\nthh, since the instrument is reliable just in case the auxiliary theory is true.\nWe have shown that:\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e50\nFigure 5.3 DP \u0002 0 iff the hypothesis receives additional confirmation when the reliability\nof the instrument is supported by an independent rather than a positively relevant auxiliary\ntheory with th \u0002 .8 and t \u0002 .2.h\u00af\nTheorem 7. DP \u0002 P(HYP|REP) \u0003 P\u0005(HYP|REP) \u0002 0 iff h \u0004 a\u00af(hth \u0004 hth\n\u0003 1) \u0002 0.\nTo evaluate this expression, we construct two graphs: in Figure 5.3, we\nset th \u0002 .8 and th \u0002 .2 and construct a phase curve for (a,h); in Figure\n5.4, we set a \u0002 1\/3 and h \u0002 1\/3 and construct a phase curve for (th,th).\nWhat we see in Figure 5.3 is that a positively relevant auxiliary theory\nprovides more of a boost to the degree of confirmation that the hypothesis\nreceives from a positive test report than an independent auxiliary theory\nfor lower prior probability values of the hypothesis and for lower values\nof the randomization parameter. In Figure 5.4 we are only interested in\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 51\nFigure 5.4 DP \u0002 0 iff the hypothesis receives more confirmation when the reliability of the\ninstrument is supported by an independent rather than a positively relevant auxiliary theory\nwith a \u0002 1\/3 and h \u0002 1\/3. The relevant region is the region where th\u0002 t .h\u00af\nthe area below the line where th \u0002 th. What we see is that for th \u0001 1\/2, a\npositively relevant auxiliary theory always provides more of a boost to the\ndegree of confirmation of the hypothesis, while for th \u0002 1\/2, a positively\nrelevant auxiliary theory provides more of a boost for and only for values\nof th that are sufficiently smaller than th, in other words, for a theory that\nis sufficiently positively relevant to the hypothesis.\nCan an intuitive account be given of these results? Why does a positively\nrelevant auxiliary yield a higher degree of confirmation for an implausible\nhypothesis than an independent auxiliary, as we can read off of Figure\n5.3? If h is low, say h \u0002 .1, then a positively relevant auxiliary has a low\nprior probability t \u0002 (.8)(.1) \u0004 (.2)(.9) \u0002 .26. The ceteris paribus clause\nrequires that we set the prior probability of an independent auxiliary at\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e52\n.26 as well. Since the hypothesis is improbable, it is likely that a positive\nreport is due to the unreliability of the instrument and hence the falsity of\nthe auxiliary: e.g. for a \u0002 .5, the posterior probability of the auxiliary\nslides below .26. However, the blame falls much more heavily on the in-\ndependent auxiliary than on the positively relevant auxiliary, because the\nprobability of the latter is tied to the probability of the hypothesis: actu-\nally, the posterior probability of the independent auxiliary goes into free\nfall to \u0003.07 while the posterior probability of the positively relevant aux-\niliary remains at a respectable .17. With this distrust in the auxiliary and\nhence in the instrument it is understandable that the hypothesis will receive\nless confirmation from a positive report when the instrument is supported\nby an independent auxiliary than when it is supported by a positively\nrelevant auxiliary: actually, the posterior probability of the hypothesis is\n.20 with a positively relevant auxiliary as opposed to \u0003.16 with an inde-\npendent auxiliary. Furthermore, this argument will take effect when the\nauxiliary is sufficiently positively relevant to the hypothesis, which we can\nread off Figure 5.4.\nLet us now turn to our next question (ii.a). We have received a report\nfrom a LTFR instrument to the effect that some test consequence is true.\nSubsequently, we increase our confidence in the reliability of the instru-\nment by appealing to an auxiliary theory that is independent of the hy-\npothesis under test. Is this a successful strategy for increasing the degree\nof confirmation of our hypothesis?\nIt is easy to see that the answer to this question is univocally positive.\nOur basic model in Figure 2.1 captures the situation before some auxiliary\ntheory in support of our hypothesis has been spotted. The model in Figure\n5.1 captures the situation after some auxiliary theory has been spotted.\nWe specify a probability distribution P for the Bayesian Network in Fig-\nure 2.1 and P\u0005 for the Bayesian Network in Figure 5.1. To respect the\nceteris paribus clause, we specify the same values a, h, p, and q for both\ndistributions, but we choose r for P and t for P\u0005 so that P(REL) \u0001\nP\u0005(REL). Then the following theorem holds:\nTheorem 8. DP \u0002 P\u0005(HYP|REP) \u0003 P(HYP|REP) \u0002 0.\nMatters are not as simple when we turn our attention to the last question\n(ii.b). What happens if we increase our confidence in the reliability of the\ninstrument by appealing to an auxiliary theory and the auxiliary theory\nand the hypothesis are positively relevant to one another? To investigate\nthis question, we raise the reliability of the instrument by bringing in a\npositively relevant auxiliary theory: we construct a probability distribution\nP for our basic model in Figure 2.1 and a probability distribution P\u0005 for\nthe Bayesian Network in Figure 5.2, carefully picking r, th and th, so that\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 53\nFigure 5.5 DP \u0002 0 iff the hypothesis receives more confirmation when we increase the\nreliability of the instrument by means of a positively relevant auxiliary theory. The relevant\nregion is ther region where r* \u0002 r.\nr \u0002 P(REL) \u0001 P\u0005(REL) \u0002 r* and, to respect the ceteris paribus clause,\nso that (ii) P(HYP) \u0002 P\u0005(HYP). We have shown that:\nTheorem 9. DP \u0002 P\u0005(HYP|REP) \u0003 P(HYP|REP) \u0002 0 iff (a\u00afr\u00af \u0003 h)th \u0004\n(a \u0004 a\u00afr) r* \u0003 hr \u0002 0.\nIn Figure 5.5, we set the values at h\u0002 .5, a\u0002 .4 and th \u0002 .8 and construct\na phase curve for values of (r, r*). The part of the graph that interests us\nis the area above the line where r* \u0002 r. In the area above the phase curve\na positively relevant auxiliary theory increases the degree of confirmation\nfor the hypothesis. In the area underneath the phase curve a positively\nrelevant auxiliary theory decreases the degree of confirmation for the hy-\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e54\npothesis. Notice that there exists a region underneath the phase curve\nwhere r* \u0002 r. This is curious. Here is how the story goes for this region.\nWe are about to test a hypothesis, but are not confident about the reli-\nability of our instrument: we realize that our confidence in the hypothesis\nwould not increase drastically even if we were to receive a positive report.\nWe try to boost our confidence in the reliability of the instrument and\nconsult an expert. The expert provides us with an auxiliary theory. The\nauxiliary theory is uncertain, but still boosts our confidence in the reli-\nability of the instrument. It is positively relevant to the hypothesis, but\nthe relevant probability values are such that the prior probability of the\nhypothesis remains unaffected. It turns out that we will now be less con-\nfident that the hypothesis is true after a positive test report comes in than\nhad we not consulted the expert!\nThe phenomenon is definitely curious, but a moment\u2019s reflection will\nshow that it was to be expected given our discussion of question (i) and\nquestion (ii.a). Suppose that we have no theoretical support for the reli-\nability of our instrument and that the reliability parameter is set at r.\nClearly, the hypothesis receives precisely the same degree of confirmation\nwhen the reliability parameter has the same value r but rests on the support\nof some independent auxiliary theory. From our discussion of question\n(i), we also know that support from an independent as opposed to a de-\npendent auxiliary theory can be better or worse for the degree of confir-\nmation of a hypothesis, depending on the values of h, a, th and th. So let\nus assume that an independent auxiliary theory raises the reliability pa-\nrameter from r to r\u0004 e, for some small e. From our discussion of question\n(ii.a) we know that this increase will slightly raise the degree of confir-\nmation for the hypothesis. But it is to be expected that this small raise\nwould have been offset, if support had been sought from a dependent\nauxiliary theory yielding a reliability value of r \u0004 e, at least for particular\nvalues of the relevant parameters. Hence, finding support in a dependent\nauxiliary theory for the reliability of the instrument may lower the degree\nof confirmation for the hypothesis.\nThe Duhem-Quine thesis notoriously states that if our experimental\nresults are not in accordance with the hypothesis under investigation, there\nis no compelling reason to reject the hypothesis, since the blame could just\nas well fall on the auxiliary theories. One virtue of our model is that it\ngives a precise Bayesian account of how experimental results affect our\nconfidence in the hypothesis and our confidence in the auxiliary theory.\nBut there is also a more important lesson to be learned. In discussing the\nDuhem-Quine thesis, Bayesians typically assume that the auxiliary theory\nand the hypothesis are independent (cf. Howson and Urbach 1993, 139),\nalthough there is some cursory discussion of dependence between the hy-\npothesis and the auxiliary theory in Dorling (1996). The assumption of\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 55\nindependence certainly makes the calculations more manageable, but it\ndoes not square with the holism that is the inspiration for the Duhem-\nQuine thesis. Not only are experimental results determined by a hypothesis\nand auxiliary theories, they are determined by a hypothesis and auxiliary\ntheories that are often hopelessly interconnected with each other. And\nthese interconnections raise havoc in assessing the value of experimental\nresults in testing hypotheses. There is always the fear that the hypothesis\nand the auxiliary theory really come out of the same deceitful family and\nthat the lies of one reinforce the lies of the others. What our results show\nis that this fear is not entirely ungrounded: for hypotheses with a high\nprior probability, it is definitely better that the reliability of the instrument\nbe supported by an independent auxiliary theory. But on the other hand,\nfor hypotheses with a low prior probability, we should cast off such fears:\nhypotheses and auxiliary theories from the same family are very welcome,\nsince positive test reports provide stronger confirmation of the hypothesis\nunder consideration.\n6. Calibration. To raise the degree of confirmation of the hypothesis that\na particular test result from a LTFR instrument has provided, we can try\nto increase our confidence in the LTFR instrument by calibrating it. Con-\nsider an example: we have a test result in our hands from a LTFR tech-\nnique for dating artifacts in archeology. A simple form of calibration is\nto set the technique to work on some artifacts that have their dates chiseled\ninto them (by a reliable stone mason) and to check whether the technique\nindeed provides the correct output. If so, then we can feel more confident\nthat the technique is indeed reliable and subsequently that the test result\nand the hypothesis are correct. Let us model this simple form of calibration\nin a Bayesian Network before moving on to the more complex form in\nwhich the LTFR instrument is calibrated against test results from other\nLTFR instruments.\nSuppose that we have a single report from a LTFR instrument and that\nthe content of this report is a test consequence of some hypothesis. This\nset up is captured by our basic model in Section 2. Subsequently, we iden-\ntify a series of data that are roughly of the same nature as the test con-\nsequence in question but which we are confident are true. The LTFR\ninstrument is then calibrated by examining whether it yields correct values\nfor these data. To keep things simple, we will model a case with two data\n(DAT1 and DAT2). Following our heuristic, the reports about these data\n(REPDAT1 and REPDAT2) are directly influenced by the reliability of\nthe instrument in question and by whether the data are true or not. This\nyields the graph in Figure 6.1.\nWe assign a probability value of 1 to DAT1 and DAT2 in line with our\nstipulation that we have chosen certain data. Nothing would prevent us\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e56\n    HYP\n    \nCON\n    REP\n    REL   DAT1\nREPDAT1\nREPDAT2\n  DAT2\nFigure 6.1 Calibrating the instrument against certain data.\nof course from inserting lower degrees of confidence into our model. The\ngraph displays a series of independences. One such independence is worth\nfocusing on, since it does reflect a substantial simplification:\n(14)DATi \u0001 CON, DATj \u2200i,j \u0002 1,2 and i\u0001j\nThe data are independent of the test consequence and are independent of\none another. This is a plausible assumption for artifacts that are suffi-\nciently heterogeneous: say, if they are not found on the same site, are not\nsimilar in style etc.\nWe can now turn to a more complex form of calibration which pre-\nserves the independences of Figure 6.1. Quite often there are no clean data\navailable against which to calibrate our instruments. Rather, we can do\nno better than calibrate our instrument against reports from a single or\nfrom multiple LTFR instruments about uncertain data. Let the LTFR\ninstrument that is to be calibrated be the calibratee and the single or mul-\ntiple LTFR instruments against whose reports the calibration takes place\nbe the calibrator(s). If the calibratee yields the same reports as the cali-\nbrator(s) about these uncertain data, then we may be more confident that\nthe calibratee is reliable and consequently that the test consequence and\nthe hypothesis is correct. We will model this more complex form of cali-\nbration for two uncertain data DAT1 and DAT2. We receive test reports\nabout these uncertain data from the calibratee (REPEEDAT1 and RE-\nPEEDAT2) and from the calibrator(s) (REPORDAT1 and REPOR-\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 57\nDAT2). Now we draw the following distinction: either we calibrate against\nthe reports from a single calibrator, or we calibrate against the reports\nfrom multiple calibrators, one for each datum. In accordance with this\ndistinction, we can draw two graphs. The variable RELCAL expresses the\nreliability of the single calibrator in the graph in Figure 6.2, while the\nvariables RELCAL1 and RELCAL2 express the reliability of the respec-\ntive calibrators in the graph in Figure 6.3.\nWe can read off a series of independences from these graphs. As before,\nwe have made the simplifying assumption that all the instruments are\nindependent:\n(15)REPEEDATi \u0001 REPORDATi|DATi for i \u0002 1,2\nWe define a probability distribution over each graph and impose our usual\nsymmetry conditions (within each distribution) and ceteris paribus con-\nditions (between distributions). We assume that the calibrators are either\nfully reliable or fully unreliable; if they are fully unreliable, then they all\nare no better than randomizers with a common parameter a, which equals\nthe parameter of the instrument to be tested. Let us also assume that we\nhave the same degree of confidence in all the calibrators and the same\ndegree of confidence in the data. P is the probability distribution for the\ngraph in Figure 6.2 and P\u0005 is the probability distribution for the graph in\nFigure 6.3. Then, for i \u0002 1,2\n(16)\nP(REPORDATi|RELCAL, DATi) \u0002 1 and\nP(REPORDATi|RELCAL, DATi) \u0002 0\nP(REPORDATi|RELCAL, DATi) \u0002 a for both values of DATi\nP\u0005(REPORDATi|RELCALi, DATi) \u0002 1\nand P\u0005(REPORDATi|RELCAL, DATi) \u0002 0\nP\u0005(REPORDATi|RELCALi, DATi) \u0002 a for both values of DATi\nP(REPEEDATi|REL, DATi) \u0002 1\nand P(REPDATi|RELCAL, DATi) \u0002 0 for P \u0002 P, P\u0005\nP(REPEEDATi|REL, DATi) \u0002 a for both values of DATi\nand for P \u0002 P, P\u0005\nP(RELCAL) \u0002 P\u0005(RELCALi) \u0002 s\nP(DATi) \u0002 P\u0005(DATi) \u0002 f.\nIt is reasonable to assume that if we are out to calibrate a LTFR instru-\nment, then we will pick calibrators that we take to be more reliable than\nthe calibratee, i.e. P(REL) \u0002 P\u0005(REL) \u0002 r \u0001 s.\nWhat needs to be investigated is under what conditions the strategy of\ncalibrating against data from a single more reliable instrument as well as\nthe strategy of calibrating against data from multiple more reliable instru-\nments are successful strategies. We consider the point in time at which the\nhypothesis has received confirmation from a report about the test conse-\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n \n \n \n \n \n \n \nH\nYP\n \n \n \n \n \n \n \nCO\nN\n \n \n \n \n \n \nRE\nL\n \n \n \n \nD\nAT\n 1\n \n \n \n \nRE\nLC\nAL\n \n \n \n \n \n \n \nRE\nP\nRE\nPE\nED\nAT\n 1\nRE\nPO\nRD\nAT\n 1\n \n \n \n \n \nD\nAT\n 1\nRE\nPE\nED\nAT\n 2\nRE\nPO\nRD\nAT\n 2\n \n \n \n \nD\nAT\n 2\nF\nig\nur\ne\n6.\n2\nC\nal\nib\nra\nti\nng\nth\ne\nin\nst\nru\nm\nen\nt\nag\nai\nns\nt\nun\nce\nrt\nai\nn\nda\nta\nw\nit\nh\na\nsi\nng\nle\nca\nlib\nra\nti\nng\nin\nst\nru\nm\nen\nt.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n \n \n \n \n \n \n \nH\nYP\n \n \n \n \n \n \n \nCO\nN\n \n \n \n \n \n \nRE\nL\n \n \n \n \nD\nAT\n 1\n \n \nRE\nLC\nAL\n 1\n \n \n \n \n \n \n \nRE\nP\nRE\nPE\nED\nAT\n 1\nRE\nPO\nRD\nAT\n 1\n \n \n \n \n \nD\nAT\n 1\nRE\nPE\nED\nAT\n 2\nRE\nPO\nRD\nAT\n 2\n \n \n \n \nD\nAT\n 2\n \n \n \nRE\nLC\nAL\n 2\nF\nig\nur\ne\n6.\n3\nC\nal\nib\nra\nti\nng\nth\ne\nin\nst\nru\nm\nen\nt\nag\nai\nns\nt\nun\nce\nrt\nai\nn\nda\nta\nw\nit\nh\nm\nul\nti\npl\ne\nca\nlib\nra\nti\nng\nin\nst\nru\nm\nen\nts\n.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e60\nquence from the calibratee. Subsequently, we receive the additional infor-\nmation that the calibrator(s) provided the same reports about both data\nas the calibratee. Theorem 10 shows under what conditions the additional\ninformation from a single calibrator raises the degree of confirmation for\nthe hypothesis:\nTheorem 10. DP \u0002 P(HYP|REP,REPEEDAT1,REPEEDAT2,\nREPORDAT1,REPORDAT2) \u0003 P(HYP|REP) \u0002 0 iff a2(f2 \u0003 a2)s\u00af \u0004\n(1 \u0003 a2)f2s \u0002 0.\nand Theorem 11 shows under what conditions the additional information\nfrom multiple calibrators raises the degree of confirmation for the hy-\npothesis:\nTheorem 11. DP \u0002 P\u0005(HYP|REP,REPEEDAT1,REPEEDAT2,\nREPORDAT1,REPORDAT2) \u0003 P\u0005(HYP|REP) \u0002 0 iff a(f \u0003 a)s\u00af \u0004\na\u00affs \u0002 0.\nWe plot phase curves for different values of the randomization param-\neter in the single-calibrator case in Figure 6.4. What is going on here?\nFocus on the area where the data are improbable (i.e. where f is low) and\nthe reliability parameter for the calibrator is low (i.e. where s is low): in\nthis area DP \u0001 0, i.e. calibration decreases the degree of confirmation that\nthe hypothesis receives. This is to be expected: when we get calibration\nresults from a calibrator that is likely to be unreliable and that in addition\nprovides positive reports about implausible data, then we become even\nmore suspicuous of the calibratee, since it yields the same odd results as\nthe calibrator that is likely to be unreliable. And the more suspicuous we\nare of the calibratee, the less confirmation the hypothesis receives. Fur-\nthermore the higher we set the randomization parameter a, the stronger\nthis effect will become, since positive reports are the more likely to come\nfor unreliable instruments. Figure 6.5 presents the phase curves for the\ncase of multiple calibrators. The interpretation is similar to the case for a\nsingle calibrator.\nSubsequently, we are curious to know whether, ceteris paribus, the hy-\npothesis receives more or less confirmation if we calibrate against data\nfrom a single rather than from multiple calibrators. Is there a general\nanswer, or are there specific conditions under which it is better to calibrate\nagainst a single instrument and under which it is better to calibrate against\nmultiple instruments? We have shown that,\nTheorem 12. DP \u0002 P(HYP|REP,REPEEDAT1,REPEEDAT2,\nREPORDAT1,REPORDAT2) \u0003 P\u0005(HYP|REP,REPEEDAT1,\nREPEEDAT2,REPORDAT1,REPORDAT2) \u0002 0 iff (2a\u00afs \u0004 a)(f\u0003 a)\n\u0004 aa\u00af \u0002 0.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 61\nFigure 6.4 DP \u0002 0 iff the hypothesis receives additional confirmation from matching re-\nports from a single calibrating instrument.\nWe plot phase curves for different values of the randomization parameter\nin Figure 6.6. For all the values of s and f above these curves, DP\u0002 0 and\nfor all values of s and f underneath these curves, DP \u0001 0. We see that for\nlower f, higher s and higher a, it is better to calibrate against two rather\nthan one calibrator. In other words, as the data become less likely, as the\ncalibrator(s) are more likely to be reliable and as the randomization pa-\nrameter grows, it is better to calibrate against two rather than one cali-\nbrator.\nHow are we to interpret these results? There are two conflicting con-\nsiderations at work in determining whether it is better to calibrate against\na single as opposed to against multiple calibrators. On the one hand, we\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e62\nFigure 6.5 DP \u0002 0 iff the hypothesis receives additional confirmation from matching re-\nports from two calibrating instruments.\nlike to raise the probability that the calibrator is reliable by getting co-\nherent reports from a single instrument. This effect will assert itself when\nwe can assess highly plausible data, when the prior probability that the\ncalibrator is reliable is still low, so that there is much to be gained from\nthe coherence of the reports, and when the randomization parameter is\nlow, so that positive reports are unlikely to come from unreliable instru-\nments. On the other hand, there is something to be gained from having\nindependent calibrators to improve the reliability of the calibratee. This\nlatter consideration gains the upper hand as the conditions which were\nfavorable to the former consideration wear off: coherent positive reports\nabout implausible facts do not do much to boost the reliability of a single\ncalibrator; if the single calibrator is already very likely to be reliable, then\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 63\nFigure 6.6 DP \u0002 0 iff the hypothesis receives more confirmation from matching reports\nfrom a single calibrating instrument than from two calibrating instruments.\nthere is little to be gained anymore from coherent positive reports; and if\nthe randomization parameter is set high, then coherent positive reports do\nnot do much to convince us that the single calibrator is reliable, since they\nare likely to come from unreliable instruments. At this point more is to\nbe gained from receiving independent reports from multiple calibrators.\nCompare Figures 3.3, 4.5 and 4.6 on the one hand with Figure 6.6 on\nthe other hand. In the former figures we compared whether it was better\nfor the confirmation of the hypothesis to receive positive reports from one\nor from two instruments. Two instruments do better than a single instru-\nment for run-of-the-mill values, such as a \u0002 r \u0002 .5, p \u0002 .8 and q \u0002 .2.\nIn the latter figure we compared whether it was better for the confirmation\nof the hypothesis to obtain agreement between the test instrument and a\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e64\nsingle or multiple calibrators. One calibrator does better than two cali-\nbrators for run-of-the-mill values such as a \u0002 f \u0002 .5 and s \u0002 .8 (which\nexceeds r), one calibrator does better than two calibrators. In modeling\nstrategies to receive confirmation from unreliable instruments with Bayes-\nian Networks, it was this curious difference that first sparked our interest.\n7. Concluding Remarks and Future Directions. Let us list some of the more\nstriking results of our investigation:\n(i) The standard strategies to deal with unreliable instruments are\nnot always successful: for specific values of the relevant param-\neters, the degree of confirmation will drop rather than rise when\nwe obtain (a) a positive report about an additional test con-\nsequence from the same LTFR instrument, (b) support for our\nLTFR instrument from a dependent auxiliary theory, or\n(c) matching reports from the LTFR instrument and the cali-\nbrating instrument(s).\n(ii) The variety-of-evidence thesis is not sacrosanct on a plausible\nreading of this thesis: positive reports from single rather than\nfrom multiple LTFR instruments and positive reports about a\nsingle rather than about multiple consequences will for certain\nvalues of the relevant parameters provide more confirmation to\na hypothesis, ceteris paribus. These results play havoc with the\ncorrelation approach to the variety-of-evidence thesis.\n(iii) The Duhem-Quine thesis is no reason to despair about confir-\nmation. An appeal to an auxiliary theory in support of a LTFR\ninstrument can improve the degree of confirmation for the hy-\npothesis and the interdependency between the auxiliary theory\nand the hypothesis tends to favor the confirmation of initially less\nplausible hypotheses.\n(iv) For run-of-the-mill values, positive reports from multiple instru-\nments raise the degree of confirmation more than similar reports\nfrom a single instrument in repeated testing, while matching re-\nports from a single calibrating instrument raise the degree of con-\nfirmation more than equivalent reports from multiple calibrating\ninstruments.\nWe have taken the first steps in developing a new approach to thinking\nabout confirmation and unreliable instruments. There are many directions\nto be explored. We conclude with some open questions and suggestions\nfor further research.\n(I) We have made a range of idealizations that may strike one as\nunrealistic. At the same time, the networks often point out the\nway to relax these idealizations: by importing additional param-\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 65\n7. We owe this suggestion to Robert Dodier.\n8. We owe this suggestion to Frantis\u02c7ek Matus\u02c7 and Theo Kuipers.\neters, one can break through the symmetry and ceteris paribus\nassumptions; by adding additional arrows to the network, one\ncan model relaxing certain independencies. In particular, we\ngrant that the idealization that the instrument is either fully re-\nliable or a randomizer is indeed somewhat implausible.5 Here\nare some thoughts on the subject. First, in the spirit of our earlier\nremarks, the framework is there to lay out alternative charac-\nterizations in the model: e.g. J. McKenzie Alexander (2001) has\ninvestigated how robust the results are in Figure 5.5, by setting\nP(REP|CON,REL) \u0002 x and P(REP| , REL) \u0002 y for 0 \u0001CON\ny \u0001 x \u0001 1. Or alternatively, we could relax the randomization\nassumption by setting 1 \u0002 P(REP|CON, ) \u0002 a\u0005 \u0002 a \u0002REL\nP(REP| , ) \u0002 0.6 Second, we have restricted our atten-CON REL\ntion to discrete binary variables, and since scientific experimen-\ntation more often than not deals with continuous variables, re-\nlaxations of our idealization will involve constructing networks\nwith continuous variables. In assessing the nature of the instru-\nment\u2019s unreliability we need to construct prior probability func-\ntions for the bias and for the variance of the instrument. Dy-\nnamic Belief Networks in sensor theory (e.g. Nicholson and\nBrady 1994 and Dodier 1999, Ch. 6) operate with structures that\ncontain continuous variables and that explicitly model the re-\nported values of a variable as a function of the true values of\nthe variable and the reliability of the instrument in a diachronic\nsetting.7 Third, we grant that there is a common scenario that\nviolates the independence assumptions in our models for re-\npeated testing with the same test instrument: the coherence of\ntest results counts for nothing when the instrument is less than\nfully reliable in the sense that it provides accurate measurements\nof other features than the features it is supposed to measure.\n(II) We have restricted our attention to two reports in our discussion\nof strategy 1 and 2. Similarly we have restricted our attention to\ntwo calibrating reports on data in strategy 4. How does a series\nof positive reports from single versus multiple LTFR instru-\nments affect the confirmation of the hypothesis? How does a\nseries of matching reports from single versus multiple calibrators\naffect the confirmation of the hypothesis? Do we reach conver-\ngence and can a general characterization be given of the paths\nthat lead towards convergence?8 We have made some progress\ntowards this question in Hartmann and Bovens (2001).\n5. This was pointed out by Kent Staley.\n6. We owe this suggestion to Richard Scheines.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e66\n9. This case is discussed in an error-statistical framework in Staly (1996, 2000).\n10. We owe the suggestion to investigate different measures of confirmation to Branden\nFitelson.\n11. We owe this suggestion to David R. Cox.\n(III) In highly developed fields of science, there is often an intricate\nrelationship between the hypothesis under investigation and the\nauxiliary theories. Consider the recent discovery of the top\nquark. This fundamental particle is suggested by the Standard\nModel of particle physics. But certain elements of this model\nalso come in in the methods that were used to analyze the data\ncollected by the instruments. These interrelationships are ex-\ntremely complex and our model in strategy 3 is highly idealized.\nA case study in which a Bayesian Network is constructed that\nmodels the scientific process would lend support to our analysis.9\n(IV) There are a range of measures for the degree of confirmation\n(Eells and Fitelson 2001; Fitelson 1999 and 2001; Kyburg 1983).\nIn effect, we are using the difference measure, i.e. P*(H)\u0003 P(H)\nwith P*(H) \u0002 P(H|E), to measure the degree of confirmation.\nIt can be shown that our results remain unaffected when using\nthe log-ratio-measure (or any ordinally equivalent measure), or\nwhen using the log-likelihood-ratio (or any ordinally equivalent\nmeasure), but are affected when using the Carnap measure or\nthe Christensen measure. A proof of this statement is contained\nin the appendix. Whether they will be affected in interesting ways\nremains an open question.10\n(V) We have investigated how positive reports from LTFR instru-\nments affect the degree of confirmation for the hypothesis under\nvarious strategies. But of course, at the beginning of the day, a\nresearcher does not know whether positive or negative reports\nwill be forthcoming.11 Even so, our approach can be turned into\na decision procedure as to what strategy is to be preferred in a\nparticular context. Consider a hypothesis which states that a\npatient has a particular disease and a policy that treatment will\nbe started just in case the posterior probability of the hypothesis\nexceeds some critical value. We specify the utility values of treat-\nment and abstention from treatment when the patient actually\ndoes and does not have the disease. We can then calculate the\nexpected utility of a particular strategy of dealing with LTFR\ninstruments at the beginning of the day and make recommen-\ndations accordingly. Leaning on decision-theoretic work in the\ntheory of Bayesian Networks (e.g. Jensen 2001), a systematic\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 67\nstudy in a particular context may give rise to genuine practical\napplications.\nAppendix\nA. Proof of Theorem 1\nWe will follow the standard procedure laid out in Section 2. Let P0 be the prob-\nability distribution for the Bayesian Network in Figure 2.1. We can write P (HYP)*0\n\u0002 P0(HYP|REP) in formula (11) more concisely:\nh(pr \u0004 ar\u00af)\n*P (HYP) \u0002 ,0 c r \u0004 ar\u00af1\nwith c1 \u0002 P(CON) \u0002 hp \u0004 hq.\nLet P1 be the probability distribution for the Bayesian Network in Figure 3.1. We\ncalculate:\n2h(pr \u0004 a r\u00af)\n*P (HYP) :\u0002 P (HYP|REP1, REP2) \u00021 1 2c r \u0004 a r\u00af1\nSince P1(HYP|REP1) \u0002 P (HYP), DP \u0002 P (HYP) \u0003 P (HYP) is* * *0 1 0\n\u00afaa\u00afhhrr\u00af(p \u0003 q)\nDP \u0002 .\n2(c r \u0004 a r\u00af)(c r \u0004 ar\u00af)1 1\nSince 0 \u0001 a,h,r \u0001 1 and p \u0002 q, the expression is clearly greater than 0.\nB. Proof of Theorem 2\nLet P2 be the probability distribution for the Bayesian Network in Figure 3.2. We\ncalculate:\n2 2 2h(p(r \u0004 ar\u00af) \u0004 p\u00afa r\u00af )\n*P (HYP) :\u0002 P (HYP|REP1,REP2) \u00022 2 2 2 2c (r \u0004 ar\u00af) \u0004 c\u00af a r\u00af1 1\nSince P2(HYP|REP1) \u0002 P (HYP), DP \u0002 P (HYP) \u0003 P (HYP) is* * *0 2 0\n\u00afaa\u00afhhrr\u00af(ar\u00af \u0004 r)(p \u0003 q)\nDP \u0002 .\n2 2 2(c (r \u0004 ar\u00af) \u0004 c\u00af a r\u00af )(c r \u0004 ar\u00af)1 1 1\nSince 0 \u0001 a,h,r \u0001 1 and p \u0002 q, the expression is clearly greater than 0.\nC. Proof of Theorem 3\nWith the results of the last two appendices, we can calculate the difference DP \u0002\nP (HYP) \u0003 P (HYP):* *2 1\n2 \u00afa hhrr\u00af(p \u0003 q)(1 \u0003 2a\u00afr\u00af)\nDP \u0002\n2 2 2 2(c r \u0004 a r\u00af)(c (r \u0004 ar\u00af) \u0004 c\u00af a r\u00af )1 1 1\nSince 0 \u0001 a,h,r \u0001 1 and p \u0002 q, DP \u0002 0 iff 1 \u0003 2a\u00afr\u00af \u0002 0.\nD. Proof of Theorem 4\nLet P3 be the probability distribution for the Bayesian Network in Figure 4.2. We\ncalculate:\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e68\n2h(pr \u0004 ar\u00af)\n*P (HYP) :\u0002 P (HYP|REP1,REP2) \u0002 .3 3 2 2 2a r\u00af \u0004 2ac rr\u00af \u0004 c r1 2\nSince P3(HYP|REP1) \u0002 (HYP), DP \u0002 P (HYP) \u0003 P (HYP) is* * *P0 3 0\n\u00afhhr(p \u0003 q)(rp \u0004 ar\u00af)(rq \u0004 ar\u00af)\nDP \u0002 .\n2 2 2(a r\u00af \u0004 2ac rr\u00af \u0004 c r )(c r \u0004 ar\u00af)1 2 1\nSince 0 \u0001 a,h,r \u0001 1 and p \u0002 q, the expression is clearly greater than 0.\nE. Proof of Theorem 5\nLet P4 be the probability distribution for the Bayesian Network in Figure 4.1. We\ncalculate:\n2 2h(p r \u0004 a r\u00af)\n*P (HYP) :\u0002 P (HYP|REP1,REP2) \u0002 ,4 4 2c r \u0004 a r\u00af2\nwith c2 \u0002 P(CON1, CON2) \u0002 hp2 \u0004 hq2.\nSince P4(HYP|REP1) \u0002 P (HYP), DP \u0002 P (HYP) \u0003 P (HYP) is* * *0 4 0\n\u00afhh(p \u0003 q)r [pqr \u0004 ar\u00af(p \u0004 q \u0003 a)]\n* *DP \u0002 P (HYP) \u0003 P (HYP) \u0002 .4 0 2(c r \u0004 a r\u00af)(c r \u0004 ar\u00af)2 1\nSince 0 \u0001 a,h,r \u0001 1 and p \u0002 q,DP \u0002 0 iff pqr \u0004 a r\u00af (p \u0004 q \u0003 a) \u0002 0. Note that\np \u0004 q \u0002 a is a sufficient condition for DP \u0002 0.\nF. Proof of Theorem 6\nWith the results of the last two appendices, we can calculate the difference DP \u0002\nP (HYP) \u0003 P (HYP):* *3 4\n\u00afahh(p \u0003 q)r\u00af [(2a \u0003 p \u0003 q)a \u0003 2(a \u0003 p)(a \u0003 q)r]\nDP \u0002\n2 2 2 2 2 2(a r\u00af \u0004 c r )(a r\u00af \u0004 2ac rr\u00af \u0004 c r )2 1 2\nSince 0 \u0001 a,h,r \u0001 1 and p \u0002 q,DP \u0002 0 iff (2a \u0003 p \u0003 q)a \u0003 2(a \u0003 p)(a \u0003 q)r\u0002 0.\nG. Proof of Theorem 7\nLet P5 be the probability distribution for the Bayesian Network in Figure 5.1. Add\nan arrow from HYP to AUX and define a new probability distribution P# over\nthis new Bayesian Network. Since AUX is no longer a root node, we delete\nP5(AUX) \u0002 t and fill in P#(AUX|HYP) \u0002 th \u0002 t and P#(AUX| )\u0002 th \u0002 t.HYP\nFor all other probability values in the Bayesian Network, P5 \u0002 P#. It is easy to\nshow that this adapted Bayesian Network expresses precisely the same probability\ndistribution as the Bayesian Network in Figure 5.1. We follow the standard pro-\ncedure for the adapted Bayesian Network and calculate P#(HYP|REP) which is\nequal to P5(HYP|REP). Subsequently we follow the standard procedure for the\nBayesian Network in Figure 5.2 and calculate P\u0005(HYP|REP). We now construct\nthe difference DP \u0002 P(HYP|REP) \u0003 P\u0005(HYP|REP):\n\u00af \u00afahh(t \u0003 t ) [h \u0004 a\u00af(ht \u0004 ht \u0003 1)]\u00af \u00afh h h hDP \u0002 \u00af(aht \u0004 a\u00afht \u0004 at\u00af )(a \u0004 (h \u0003 a)(ht \u0004 ht ))\u00af \u00af \u00afh h h h h\nSince 0 \u0001 a,h \u0001 1 and th \u0002 th, DP \u0002 0 iff h \u0004 a\u00af(hth \u0004 hth \u0003 1) \u0002 0.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 69\nH. Proof of Theorem 8\nFor any probability distribution P for the Bayesian Network in Figure 5.1 and P0\nfor the Bayesian Network in Figure 2.1 with the same parameters a,h,p,q and\nP(AUX) \u0002 P0(REL), note that P*(HYP) \u0002 P (HYP). Hence to prove the theo-*0\nrem, it is sufficient to show that P (HYP) is a positively increasing function of r.*0\nDifferentiating equation (11) with respect to r yields:\n\u00af\u0004 ahh(p \u0003 q)\n*P (HYP) \u00020 2\u0004r (c r\u00af \u0004 hr)1\nSince 0 \u0001 a,h \u0001 1 and p \u0002 q, this expression is greater than 0 and hence P (HYP)*0\nis a positively increasing function of r.\nI. Proof of Theorem 9\nBy our standard procedure, we calculate P (HYP) for the Bayesian Network in*0\nFigure 2.1 and P6(HYP|REP) for the Bayesian Network in Figure 5.2. Since rt \u0002\n1 and rt\u00af \u0002 0, r* \u0002 hth \u0004 hth. Hence we can replace th by (r* \u0003 hth)\/h in\nP6(HYP|REP). We calculate DP \u0002 P6(HYP|REP) \u0003 P (HYP):*0\n\u00afah [(a\u00afr\u00af \u0003 h)t \u0004 (a \u0004 a\u00afr)r* \u0003 hr]hDP \u0002\n(ar\u00af \u0004 hr)(ar\u00af* \u0004 ht )h\nSince 0 \u0001 a,h,r,r* \u0001 1, DP \u0002 0 iff (a\u00afr\u00af \u0003 h)th \u0004 (a \u0004 a\u00afr)r* \u0003 hr \u0002 0.\nJ. Proof of Theorem 10\nLet P7 be the probability distribution for the Bayesian Network in Figure 6.2.\nWe calculate P (HYP) :\u0002 P7(HYP|REP,REPEEDAT1,REPEEDAT2,*7\nREPORDAT1,REPORDAT2):\n2 2 2 3 2 5h ( f rs \u0004 a f rs\u00af \u0004 a f r\u00afs \u0004 a r\u00afs\u00af)\n*P (HYP) \u00027 2 2 2 3 2 5h( f rs \u0004 a f rs\u00af) \u0004 a f r\u00afs \u0004 a r\u00afs\u00af\nSince P7(HYP|REP) \u0002 (HYP), DP \u0002 P (HYP) \u0003 P (HYP) is* * *P0 7 0\n2 2 2 2 2\u00afahhrr\u00af [a ( f \u0003 a )s\u00af \u0004 (1 \u0003 a ) f s]\nDP \u0002 .\n2 2 2 3 2 5(hr \u0004 ar\u00af)(h( f rs \u0004 a f rs\u00af) \u0004 a f r\u00afs \u0004 a r\u00afs\u00af)\nSince 0 \u0001 a,f,h,r,s \u0001 1 and p \u0002 q, DP \u0002 0 iff a2(f2 \u0003a2)s\u00af \u0004 (1\u0003a2)f2s \u0002 0.\nNote that a \u0001 f is a sufficient condition for DP \u0002 0.\nK. Proof of Theorem 11\nLet P8 be the probability distribution for the Bayesian Network in Figure 6.3.\nWe calculate P (HYP) :\u0002 P8(HYP|REP,REPEEDAT1,REPEEDAT2,*8\nREPORDAT1,REPORDAT2):\n2 2 3 2h( f r(s \u0004 as\u00af) \u0004 a r\u00af( fs \u0004 as\u00af) )\n*P (HYP) \u00028 2 2 3 2hf r(s \u0004 as\u00af) \u0004 a r\u00af( fs \u0004 as\u00af)\nSince P8(HYP|REP) \u0002 P (HYP), DP \u0002 P (HYP) \u0003 P (HYP) is* * *0 8 0\n2\u00afahhrr\u00af(a s\u00af \u0004 af \u0004 fs)[a( f \u0003 a)s\u00af \u0004 a\u00affs]\nDP \u0002 .\n2 2 3 2(hr \u0004 ar\u00af)(hf r(s \u0004 as\u00af) \u0004 a r\u00af( fs \u0004 as\u00af) )\nSince 0 \u0001 a,f,h,r,s \u0001 1,DP \u0002 0 iff a( f \u0003 a)s\u00af \u0004 a\u00affs \u0002 0. Note that a \u0001 f is a\nsufficient condition for DP \u0002 0.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e70\n1. In this appendix, we use the short-hand notation H for HYP and E for the evidence\nrepresented by the (conjunction of) report variable(s).\n2. We follow the list of measures presented in Eells and Fitelson (2001) and Fitelson\n(1999, 2001).\nL. Proof of Theorem 12\nWith the results of the last two appendices, we can calculate the difference DP \u0002\nP (HYP) \u0003 P (HYP):* *8 7\n4 2\u00af \u00afa f fhhrr\u00afss\u00af [(2a\u00afs \u0004 a)( f \u0003 a) \u0004 aa\u00af]\nDP \u0002\n2 2 2 3 2 5 2 2 3 2(h( f rs \u0004 a f rs\u00af) \u0004 a f r\u00afs \u0004 a r\u00afs\u00af)(hf r(s \u0004 as\u00af) \u0004 a r\u00af( fs \u0004 as\u00af) )\nSince 0 \u0001 a,f,h,r,s \u00011, DP \u0002 0 iff (2a\u00afs \u0004 a) (f \u0003 a) \u0004 aa\u00af \u0002 0. Note that a \u0001 f is\na sufficient condition for DP \u0002 0.\nM. Different Measures of Confirmation\nThe phase curves we constructed in this paper separate a two-dimensional subspace\nof the parameter space into two parts. Above the phase curve in the corresponding\ndiagram, DP \u0002 P(H|E) \u0003 P\u0005(H|E) is larger than zero, below the phase curve DP\nis smaller than zero.1 This analysis is compatible with invoking the difference mea-\nsure d(H,E) \u0002 df P(H|E) \u0003 P(H) as a measure for the degree of confirmation. The\nfollowing theorem holds:\nP(H|E) \u0001 P\u0005(H|E) iff d(H|E) \u0001 d\u0005(H|E)\nProof:\nd(H,E) \u0003 d\u0005(H,E) \u0002 (P(H|E) \u0003 P(H)) \u0003 (P\u0005(H|E) \u0003 P\u0005H))\n\u0002 P(H|E) \u0003 (P\u0005(H|E)\nThe last line follows since we assume throughout this section the ceteris paribus\nclause P(H) \u0002 P\u0005(H) \u0002 h.\nThe difference measure is not the only confirmation measure discussed in the lit-\nerature. There is the log-ratio measure r, the log-likelihood ratio measure l, Car-\nnap\u2019s relevance measure \u0001, and Christensen\u2019s measure s. These measures are de-\nfined as follows:2\nP(H|E)\nr(H, E) \u0002 logdf \u0002 \u0003P(H)\nP(E|H)\nl(H, E) \u0002 logdf \u0002 \u0003\u00afP(E|H)\n\u0001(H, E) \u0002 P(H,E) \u0003 P(H)P(E)df\n\u0002 P(E)d(H,E)\n\u00afs(H, E) \u0002 P(H|E) \u0003 P(H|E)df\n\u00af\u0002 d(H,E)\/P(E)\nThe following theorems hold:\nP(H|E) \u0001 P\u0005(H|E) iff r(H,E) \u0001 r\u0005(H,E)\nP(H|E) \u0001 P\u0005(H|E) iff l(H,E) \u0001 l\u0005(H,E)\nProof: Let\u2019s start with the log-ratio measure:\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf762\uf761\uf779\uf765\uf773\uf769\uf761\uf76e \uf76e\uf765\uf774\uf777\uf76f\uf772\uf76b\uf773 \uf761\uf76e\uf764 \uf775\uf76e\uf772\uf765\uf76c\uf769\uf761\uf762\uf76c\uf765 \uf769\uf76e\uf773\uf774\uf772\uf775\uf76d\uf765\uf76e\uf774\uf773 71\nP(H|E) P\u0005(H|E)\nr(H,E) \u0003 r\u0005(H,E) \u0002 log \u0003 log\u0002 \u0003 \u0002 \u0003P(H) P\u0005(H)\nP(H|E)\n\u0002 log \u0002 \u0003P\u0005(H|E)\nHence,\nP(H|E)\nr(H,E) \u0001 r\u0005(H,E) iff log \u0001 0 iff P(H|E) \u0001 P\u0005(H|E).\u0002 \u0003P\u0005(H|E)\nSimilarly, for the log-likelihood-ratio measure, one obtains:\nP(E|H) P\u0005(E|H)\nl(H,E) \u0003 l\u0005(H,E) \u0002 log \u0003 log\u0002 \u0003 \u0002 \u0003\u00af \u00afP(E|H) P\u0005(E|H)\n\u00afP(E|H)P\u0005(E|H)\n\u0002 log \u0002 \u0003\u00afP\u0005(E|H)P(E|H)\n\u00af \u00afP(H|E)P(E)P\u0005(H|E)P\u0005(E)P(H)P\u0005(H)\n\u0002 log \u0002 \u0003\u00af \u00af \u00afP(H)P\u0005(H)P(H|E)P(E)P\u0005(H|E)P\u0005(E)\n\u00afP(H|E)P\u0005(H|E)\n\u0002 log \u0002 \u0003\u00afP\u0005(H|E)P(H|E)\nP(H|E)(1 \u0003 P\u0005(H|E))\n\u0002 log ,\u0002 \u0003P\u0005(H|E)(1 \u0003 P(H|E))\nusing Bayes\u2019 theorem in the third line.\nHence,\nP(H|E)(1 \u0003 P\u0005(H|E))\nl(H,E) \u0001 l\u0005(H,E) iff \u0001 1.\nP\u0005(H|E)(1 \u0003 P(H|E))\nThis can be shown to be equivalent to\nl(H,E) \u0001 l\u0005(H,E) iff P(H|E) \u0001 P\u0005(H|E).\nSimilar theorems do not hold for the measure \u0001 and s. It can be shown that\n\u0001(H,E) \u0003 \u0001\u0005(H,E) \u0002 P(E)(d(H,E) \u0003 d\u0005(H,E)) \u0004 (P(E) \u0003 P\u0005(E))d\u0005(H,E)\nP(E)(d(H,E) \u0003 d\u0005(H,E)) \u0004 (P(E) \u0003 P\u0005(E))d(H,E)\ns(H,E) \u0003 s\u0005(H,E) \u0002 .\n\u00af \u00afP(E)P\u0005(E)\nIt is evident from these equations (which also hold if P(H) \u0001 P\u0005(H)) that d(H,E)\n\u0002 d\u0005(H,E) (i.e. P(H|E) \u0002 P\u0005(H|E)) does not imply r(H,E) \u0002 r\u0005(H,E) and s(H,E)\n\u0002 s\u0005(H,E). d(H,E) \u0002 d\u0005(H|E) implies \u0001(H,E) \u0002 \u0001(H,E) and s(H,E) \u0002 s\u0005(H,E) iff\nP(E) \u0002 P\u0005(E) or d(H,E) \u0002 d\u0005(H,E) \u0002 0. We leave open the exploration of the\nphase curves corresponding to these measures.\nREFERENCES\nAlexander, J. McKenzie (2001), Comments on Stephan Hartmann and Luc Bovens, \u201cThe\nImport of Auxiliary Theories of the Instruments: a Bayesian-Network Approach\u201d, pre-\nsented at the Pacific APA.\nBovens, Luc and Erik J. Olsson (2000), \u201cCoherentism, Reliability and Bayesian Networks\u201d,\nMind 109: 685\u2013719.\nChristensen, David (1999), \u201cMeasuring Confirmation\u201d, Journal of Philosophy 96: 437\u201361.\nDawid, A. Philip (1979), \u201cConditional Independence in Statistical Theory\u201d, Journal of the\nRoyal Statistical Society A41: 1\u201331.\nDodier, Robert (1999), Unified Prediction and Diagnosis in Engineering Systems by Means of\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n\uf76c\uf775\uf763 \uf762\uf76f\uf776\uf765\uf76e\uf773 \uf761\uf76e\uf764 \uf773\uf774\uf765\uf770\uf768\uf761\uf76e \uf768\uf761\uf772\uf774\uf76d\uf761\uf76e\uf76e72\nDistributed Belief Systems. Ph.D. Dissertation\u2014Department of Civil, Environmental\nand Architectural Engineering, Boulder, CO: University of Colorado.\nDorling, Jon (1996), \u201cFurther Illustrations of the Bayesian Solution of Duhem\u2019s Problem\u201d,\nhttp:\/\/www.princeton.edu\/\u02dcbayesway\/Dorling\/dorling.html\nEarman, John (1992), Bayes or Bust? A Critical Examination of Bayesian Confirmation The-\nory. Cambridge MA: MIT Press.\nEells, Ellery, and Branden Fitelson (2002), \u201cSymmetries and Asymmetries in Evidential Sup-\nport\u201d, Philosophical Studies (forthcoming).\nFitelson, Branden (1996), \u201cWayne, Horwich and Evidential Diversity\u201d, Philosophy of Science\n63: 652\u2013660.\n(1999), \u201cThe Plurality of Bayesian Measures of Confirmation and the problem of\nmeasure sensitivity\u201d, Philosophy of Science 63: 652\u2013660.\n(2001), Studies in Bayesian Confirmation Theory. Ph.D. Dissertation in Philosophy,\nMadison, WI: University of Wisconsin.\nFranklin, Allan (1986), The Neglect of Experiment. Cambridge: Cambridge University Press.\nFranklin, Allan and Colin Howson (1988), \u201cIt Probably is a Valid Experimental Result: a\nBayesian Approach to the Epistemology of Experiment\u201d, Studies in History and Phi-\nlosophy of Science 19: 419\u2013427.\nHartmann, Stephan and Luc Bovens (2001), \u201cThe Variety-of-Evidence Thesis and the\nReliability of Instruments: A Bayesian-Network Approach\u201d, (forthcoming)\nhttp:\/\/philsci-archive.pitt.edu\/documents\/disk0\/00\/00\/02\/35\/index.html\nHorwich, Paul (1982), Probability and Evidence. Princeton: Princeton University Press.\nHowson, Colin and Peter Urbach ([1989] 1993), Scientific Reasoning\u2014The Bayesian Ap-\nproach. (2nd ed.) Chicago: Open Court.\nJensen, Finn V. (1996), An Introduction to Bayesian Networks. Berlin: Springer.\n(2001), Bayesian Networks and Decision Graphs. Berlin: Springer.\nKyburg, Henry Jr. (1983), \u201cRecent Work in Inductive Logic\u201d, in Kenneth G. Lucey and\nTibor R. Machan (eds.), Recent Work in Philosophy. Totowa, NJ: Rowman and Allen-\nheld.\nMaher, Patrick (2001), \u2018Comments on Stephan Hartmann and Luc Bovens, \u201cThe Variety-\nof-Evidence Thesis and the Reliability of Instruments: a Bayesian Network Ap-\nproach\u2019\u201d, presented at the Central APA.\nNeapolitan, Richard E. (1990), Probabilistic Reasoning in Expert Systems. New York: Wiley.\nNicholson, Ann E. and J.M. Brady (1994), \u201cDynamic Belief Networks for Discrete Moni-\ntoring\u201d, IEEE Systems, Man and Cybernetics 24: 1593\u20131610.\nPearl, Judea (1988), Probabilistic Reasoning in Intelligent Systems. San Mateo, CA.: Morgan\nKaufmann.\nSpohn, Wolfgang (1980), \u201cStochastic Independence, Causal Independence, and Shieldabil-\nity\u201d, Journal of Philosophical Logic 9: 73\u201399.\nStaley, Kent W. (1996), \u201cNovelty, Severity and History in the Testing of Hypothesis: the\nCase of the Top Quark\u201d, Philosophy of Science 93 (Proceedings) S248\u201355.\n(2000), \u201cWhat Experiment Did We just Do? Counterfactual Error Statistics and\nUncertainties about the Reference Class\u201d, Talk presented at PSA 2000, Vancouver,\nBC, Canada.\nWayne, Andrew (1995), \u201cBayesianism and Diverse Evidence\u201d, Philosophy of Science 62:\n111\u2013121.\nThis content downloaded from 158.143.197.56 on Wed, 8 May 2013 12:12:38 PM\nAll use subject to JSTOR Terms and Conditions\n"}
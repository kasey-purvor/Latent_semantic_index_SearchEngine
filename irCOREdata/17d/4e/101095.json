{"doi":"10.1016\/j.neucom.2007.05.008","coreId":"101095","oai":"oai:epubs.surrey.ac.uk:500","identifiers":["oai:epubs.surrey.ac.uk:500","10.1016\/j.neucom.2007.05.008"],"title":"A Theoretical Framework for Multiple Neural Network Systems","authors":["Shields, Mike W","Casey, Matthew C"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2008-03-01","abstract":"<p>Multiple neural network systems have become popular techniques for tackling complex tasks, often giving improved performance compared to single network systems. For example, modular systems can provide improvements in generalisation through task decomposition, whereas multiple classifier and regressor systems typically improve generalisation through the ensemble combination of redundant networks. Whilst there has been significant focus on understanding the theoretical properties of some of these multi-net systems, particularly ensemble systems, there has been little theoretical work on understanding the properties of the generic combination of networks, important in developing more complex systems, perhaps even those a step closer to their biological counterparts. In this article, we provide a formal framework in which the generic combination of neural networks can be described, and in which the properties of the system can be rigorously analysed. We achieve this by describing multi-net systems in terms of partially ordered sets and state transition systems. By way of example, we explore an abstract version of learning applied to a generic multi-net system that can combine an arbitrary number of networks in sequence and in parallel. By using the framework we show with a constructive proof that, under specific conditions, if it is possible to train the generic system, then training can be achieved by the abstract technique described.<\/p","downloadUrl":"","fullTextIdentifier":null,"pdfHashValue":null,"publisher":null,"rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:epubs.surrey.ac.uk:500<\/identifier><datestamp>\n      2017-10-31T13:58:26Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><setSpec>\n      6469766973696F6E733D656E67616E64706879736963616C736369656E636573:436F6D707574696E67<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/epubs.surrey.ac.uk\/500\/<\/dc:relation><dc:title>\n        A Theoretical Framework for Multiple Neural Network Systems<\/dc:title><dc:creator>\n        Shields, Mike W<\/dc:creator><dc:creator>\n        Casey, Matthew C<\/dc:creator><dc:description>\n        <p>Multiple neural network systems have become popular techniques for tackling complex tasks, often giving improved performance compared to single network systems. For example, modular systems can provide improvements in generalisation through task decomposition, whereas multiple classifier and regressor systems typically improve generalisation through the ensemble combination of redundant networks. Whilst there has been significant focus on understanding the theoretical properties of some of these multi-net systems, particularly ensemble systems, there has been little theoretical work on understanding the properties of the generic combination of networks, important in developing more complex systems, perhaps even those a step closer to their biological counterparts. In this article, we provide a formal framework in which the generic combination of neural networks can be described, and in which the properties of the system can be rigorously analysed. We achieve this by describing multi-net systems in terms of partially ordered sets and state transition systems. By way of example, we explore an abstract version of learning applied to a generic multi-net system that can combine an arbitrary number of networks in sequence and in parallel. By using the framework we show with a constructive proof that, under specific conditions, if it is possible to train the generic system, then training can be achieved by the abstract technique described.<\/p><\/dc:description><dc:date>\n        2008-03-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        text<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/epubs.surrey.ac.uk\/500\/1\/fulltext.pdf<\/dc:identifier><dc:identifier>\n          Shields, Mike W and Casey, Matthew C  (2008) A Theoretical Framework for Multiple Neural Network Systems   Neurocomputing, 71 (7-9).  pp. 1462-1476.      <\/dc:identifier><dc:relation>\n        10.1016\/j.neucom.2007.05.008<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/epubs.surrey.ac.uk\/500\/","10.1016\/j.neucom.2007.05.008"],"year":2008,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"A theoretical framework for multiple neural network systems \nMike W. Shields, Matthew C. Casey* \nDepartment of Computing, School of Electronics and Physical Sciences, University of Surrey, \nGuildford, Surrey, GU2 7XH, UK \n \nAbstract \nMultiple neural network systems have become popular techniques for tackling complex tasks, often giving improved \nperformance compared to single network systems.  For example, modular systems can provide improvements in generalisation \nthrough task decomposition, whereas multiple classifier and regressor systems typically improve generalisation through the \nensemble combination of redundant networks.  Whilst there has been significant focus on understanding the theoretical properties \nof some of these multi-net systems, particularly ensemble systems, there has been little theoretical work on understanding the \nproperties of the generic combination of networks, important in developing more complex systems, perhaps even those a step \ncloser to their biological counterparts.  In this paper we provide a formal framework in which the generic combination of neural \nnetworks can be described, and in which the properties of the system can be rigorously analyzed.  We achieve this by describing \nmulti-net systems in terms of partially ordered sets and state transition systems.  By way of example, we explore an abstract \nversion of learning applied to a generic multi-net system that can combine an arbitrary number of networks in sequence and in \nparallel.  By using the framework we show with a constructive proof that, under specific conditions, if it is possible to train the \ngeneric system, then training can be achieved by the abstract technique described. \nKeywords: Multi-net systems; ensembles; multiple classifier systems; partially ordered sets; state transition systems \n \n \n \n* Corresponding author. Tel.\/fax: +44 (0) 1483 689635. \nE-mail addresses: m.casey@surrey.ac.uk (Matthew Casey), myramike@gmail.com (Mike Shields) \n1. Introduction \nNeural network research has reached the stage where we \nhave at least a good understanding of the most popular \narchitectures and algorithms (cf. [4]), and yet there remains \na significant gap between the capabilities of such networks \ncompared to the capability, say, of the human brain.  Whilst \nimproved learning algorithms allow us to achieve good \nlevels of performance on tasks such as regression or \nclassification, neural networks fall short of the equivalent \ncomplexity of biological systems.  One way in which the \nperformance and capability of artificial neural systems has \nbeen improved is through the combination of multiple \nnetworks [26,31].  These multi-net systems [43] are simply \nways in which networks can be combined into a cohesive \narchitecture, often with a specific learning algorithm (for \nexample [6,18,27]), and whilst they still fall short of \nbiological complexity, they have been used to demonstrate \nimproved performance and capability in a number of areas, \nincluding regression [39], classification [31] and, perhaps \nmore relevantly, computational modelling [23,26]. \nWhilst these combined systems have proven popular, our \nformal understanding of their properties and capabilities is \nnot complete.  For ensembles, our understanding depends \nupon the task; we have a relatively good understanding of \nregression, but not for classification [8].  Other \narchitectures require a more specific configuration of the \ncomponents and choice of learning algorithm [29].  In \ngeneral this means that the choice of an optimum topology \nand parameterization is a matter for trial-and-error, often \nwithout knowing if convergence to a stable solution is \npossible, or whether a simpler solution is better.  To \novercome this, a formal understanding of these systems is \ntherefore desirable to remove such uncertainties.  Whilst \nstatistical analysis is proving useful for specific \narchitectures [7,19,22,44,47], there has been little work on \nexpanding this to a generic framework in which all such \nmulti-net systems may be described. \nIn this paper we provide an abstract, general theory of \nmulti-net systems using a framework in which the generic \ncombination of networks can be described, and in which \nthe properties of the system can be rigorously analyzed.  To \nachieve this we use partially ordered sets to describe the \ntopology of multi-net systems, abstract sets to represent \nweights and other parameters, abstract functions to \nrepresent the activation function and combinations, and \ntransition systems to model the dynamics of activation and \nlearning.  The use of transition systems builds upon their \nwide use in concurrency theory to provide interleaving \noperation semantics (cf. [30,37]). This novel application of \nset theory provides a framework in which we can prove \nproperties of combined systems.  In particular, we provide \na constructive characterisation of a supervised learning \nalgorithm that can be synthesised by an abstract scheme, the \nlatter motivated by the ideas of gradient descent learning, \nwhich can be used to train a generic multi-net system, such \n* Manuscript\n2 \n \n \nthat the parameters of the system converge to meet a \nspecific criterion function.  Importantly, this is achieved \nwithout resorting to specific details of the components \ninvolved, and especially without relying upon computing \ngradients and the constraints this brings.  It should be \nstressed, however, that the algorithm in question is \ncompletely abstract, involving no numerical data, and hence \nwithout immediate application. \nIn section 2 of this paper we provide a background to \nmulti-net systems and existing work on formalism.  In \nsection 3 we provide the framework to formally define the \ntopology, parameterization and learning algorithm of a \nmulti-net system and in section 4 we consider how an \nabstract formulation of supervised learning using a \nbackward pass can be used to train a generic multi-net \nsystem.  We spend considerable effort in these two sections \nto ensure that the formal foundation of the framework is \nrigorous to allow it to be applied successfully to multi-net \nsystems in general.  In section 5 we conclude with a \ndiscussion on the limitations of the proposed framework \nand consider future work. \n2. Multi-net systems \nThe idea of combining components together to form a \ncohesive system which is more capable than its individual \nparts is not new, even for neural networks.  For example, \nHebb\u2019s discussion on learning includes the concept of \n\u2018superordinate\u2019 systems built from integrating cell \nassemblies [25].  This idea of a combination of neural \ncomponents has been used successfully for computational \nmodels of cognitive abilities (for example, [23,41]), and \nappears to be a natural extension of the neural modelling \nparadigm, building from neurons, to layers, to networks \n[26], with some architectures even linked to functional \nspecialism in the brain [20]. \nParticular multi-net architectures, or in general \ncombinations of machine learning techniques, have \ndemonstrated tangible performance improvement on tasks \nsuch as regression [39] and classification [31].  Broad \ntypes of combination include ensemble, modular and hybrid \nsystems [43], but more detailed taxonomy do not recognize \nsuch clear divisions, with the behaviour of parallel, \nsequential and hybrid types of architecture dependent upon \nthe process of learning [38].  Here, the choice of learning \nalgorithm can make such systems co-operative (typically \nensembles), competitive (modular), static (pre-configured \nprior to combination) or dynamic (configured in-situ), for \nthe same or similar configurations [42]. \nExemplars of modular systems are the mixture-of-experts \n(ME) and the hierarchical mixture-of-experts (HME) \narchitectures [27,28], in which a task is automatically \ndecomposed into sub-tasks solved by individual expert \nnetworks using a competitive algorithm, essentially \nallocating input patterns to each expert.  With a particular \nconfiguration and algorithm, convergence properties are \nknown [29,36], yet such a specific result does not apply to \nthe more general use of ME, which has proven of benefit \nfor different cognitive simulations [14,15,26]. \nEnsemble systems have also proven popular with the \ndevelopment of algorithms such as AdaBoost [18] and \nnegative correlation (NC) learning [34].  Whilst properties \nof ensembles for regression problems are mostly well \nunderstood [7,39] (especially with the recent linkage of the \nAmbiguity [32] and the bias-variance-covariance [45] \ndecompositions to learning in NC, which results in being \nable to understand how to construct an accurate regressor, \ngiven the use of a quadratic error function [9]) there is only \nlimited theory [19,22,44] for ensembles of classifiers \n(multiple classifier systems) with no complete \nunderstanding of how accurate ensemble classifiers can be \nconstructed, but which is focused on the notion of diversity \n[33]. \nWhilst there is a good theoretical understanding of ME \nand HME, and a developing understanding of ensembles, \nthere is no such theory for other types of multi-net system.  \nExamples include sequential systems [13,35], adaptive \nparallel combinations of networks [10,46] or ad-hoc \nsystems, popular in computational models of brain function \nand behaviour, such as aspects of human vision [11], \nnumerical abilities [14,17] and emotion [3], to name but \nsome.  Yet despite a lack of understanding of the properties \nof the combined system, we know significantly more about \nthe individual components, which it would be useful to \napply to the combined system.  \nAttempts have been made to define a theoretical \nframework that can be used to describe a more general \nclass of multi-net system.  Parallel (cf. ensembles) and \nsequential combinations of networks were formalized by \nBottou and Gallinari [5], in which they explored ways in \nwhich combinations of learning algorithms could be \ndefined.  Amari [2] defined a stochastic model of neural \nnetworks that was used to describe both single network and \nmulti-net systems (the ME architecture), and which could \nbe extended to other types of combination.  In a similar \nway, the formal definition of the HME architecture and \nalgorithm [28] could also be extended to more general \ntypes of multi-net system.  Kittler, Hatef, Duin and Matas \n[31] also recognized the need for a theoretical framework \nfor describing combinations of classifiers, but their work \nwas restricted to a particular configuration, namely the \nparallel combination of classifiers (or networks), as used \nin an ensemble.  Similarly, Giacinto and Roli [22] used a \nstatistical framework to demonstrate how an optimal Bayes \nclassifier can be constructed theoretically from a dynamic \nclassifier selection (DCS) system [21].  Whilst each of \nthese have abstracted some of the properties of the \ncomponents, for example the types of component [31], none \nconsider how properties of the whole system might be \nrigorously analyzed.  If we are to understand such \nproperties of a more general class of multi-net system, \nimportant perhaps for the construction of improved models \nof the brain and other more complex systems, then we must \ndevelop a generic formal understanding of these systems \n3 \n \n \nand use knowledge of the components to infer properties of \nthe whole \u2013 something that can only be achieved in a \nrigorous formal framework. \nIn this paper, we present an abstract, set-based model of \nmulti-net systems.  The starting point for the work reported \nhere is Casey [12].  He used directed trees to define a \ngeneric architecture of multi-net systems, together with a \nframework for the description of the associated learning \nalgorithm.  However, like previous work, this lacked \nsufficient rigor to explore the properties of the systems.  In \nthis paper we build upon this work by considering \ncombined systems generically by developing an abstract \nmodel of multi-nets.  The model is abstract in that it \nrepresents multi-net topologies in terms of partially ordered \nsets, with weights considered non-numerically in \ncombination with abstract functions.  We also formalize the \nnotion of a feedforward state of the system (the production \nof an output given a set of inputs), and the concept of \nlearning as a strategy to change the parameterization of the \nsystem to one that satisfies a predicate function, modelling \nconvergence to some defined state.  We provide this formal \ndescription so that the abstract properties of the generic \nclass of multi-net systems can be analyzed. \nWhilst providing a formal framework is useful to \nconsistently define multi-net architectures, it is only really \nuseful when used to discover properties of the combined \nsystem that were not previously known.  Consequently, in \nthis paper we present results from the application of the \nformalism to understand how supervised learning can be \nachieved in a generic system.  The system is generic in the \nsense that we do not specify topological constraints on the \ncomponents, such as the type of network or neurons.  In \nparticular, we define an abstract form of supervised \nlearning for this generic system, motivated by the backward \ntraining pass of algorithms such as backpropagation [40] \nand other gradient descent learners.  We then prove that, if \nwe have any type of feedforward multi-net system used for \na supervised learning task, if we can precisely define the \nconvergence predicate, then there exists a learning \nalgorithm, based upon the abstract form described, that can \nbe used to train the system.  Whilst this is perhaps intuitive, \nthe significance is in the generality of the result: we do not \nrequire that the system consists of neurons, perceptrons or \nindeed, any other type of network, rather, our constraint lies \nin being able to describe the system using the formalism \nonly.  The limitation is that, whilst this is a demonstration \nof the usefulness of abstracting combinations of networks, \nin order to be practical, the detail of the strategy and \nassociated predicate must be provided, something that we \ndo not deal with in this paper. \n3. From multi-nets to state transition systems \nIn this section we present the basic mathematical \nconcepts underlying the work presented here.  The first of \nthese is that of a partially ordered set, which we use instead \nof directed trees to describe the topology of a multi-net \nsystem (and visually via a Hasse diagram) [16].  The \nsecond is that of a transition system, which provides us \nwith the means to model dynamical aspects of these systems \n(both feedforward and feedback). \n3.1. Partial orders \nCasey [12] pictures multi-nets as directed trees, but we \nshall find it convenient to treat these from the point of view \nof partially ordered sets.  A partially ordered set consists \nof a set V  and a relation on V , which we shall denote by \n\u2264 .  If Vvu \u2208, , then we shall interpret vu \u2264  to mean that \nu  is either equal to or lies below v , where the root of the \ntree lies above all other nodes.  In general, the relation \u2264  \nsatisfies three conditions; if Vwvu \u2208,, , then: \n1) uu \u2264  ( \u2264  is reflexive); \n2) If vu \u2264  and uv \u2264 , then vu =  ( \u2264  is antisymmetric); \n3) If vu \u2264  and wv \u2264 , then wu \u2264  ( \u2264  is transitive). \nWe write vu <  if vu \u2264 and vu \u2260 , and we write vu \u2264\/ if \nvu \u2264  is false.  We add an additional constraint to this \nformulation to avoid two separate branches of the tree from \nbeing connected1.  For Vwvu \u2208,, : \nIf wvu ,\u2264 , then either wv \u2264  or vw \u2264  (1) \nFinite partial orders (that is to say, partial orders where \nV  is a finite set) may be represented pictorially by a Hasse \ndiagram, in which elements of the set are represented by \nnodes, and the existence of a sequence of arrows from, say, \na  to b  indicates ba > .  Fig. 1b) shows a Hasse diagram \nfor an ensemble },,,{ wvutVens =  where three networks are \ncombined in parallel.  In this diagram tu < , tv < , tw < , \nbut, wv \u2264\/ , etc.  In general, we say that Va \u22080  is a root \nnode if 0aa \u2264  for all Va\u2208 , so that t  is a root node of \nensV .  Observe that if Vb \u22080  is also a root node, then \n00 ba \u2264  and 00 ab \u2264 , but then 00 ba =  by antisymmetry, so \nroot nodes, if they exist, are unique.  We write )(Vroot  for \nthe root of V . \nDefinition 1. A framework is a finite, non-empty partially \nordered set with a root node, satisfying  (1).  We also define \na relation <  on V  by: \nba <  iff ba < , bca << , for no Vc\u2208  (2) \nba <  means that there is an arrow in the Hasse diagram \nfrom b  to a . \nFig. 1d) shows a framework hmeV .  Here, for example, \nwe have tu <  and vx < , but not ty < , since tvy << .  \nDefine }:{ abVba <\u2208=\u2022 .  We call elements of a\u2022  the \nchildren of a .  For example, in hmeV , },,{ wvut =\n\u2022  and \n \n1 This is not used in any of the proofs given in this paper, but serves to \nidentify these partial orders with a tree-like Hasse diagram, such as that shown \nin Fig. 1c). \n4 \n \n \n\u2205=\u2022 z .  Note that z  is a leaf of hmeV  and in general, we \ndefine: \n{ }\u2205=\u2208= \u2022aVaVleaf :)(  (3) \nSo far we have provided a formal notation and informal \ndepictions (via a Hasse diagram) of how we can describe a \nmulti-net system.  Indeed, this description is quite generic \nand does not yet constrain the characteristics of the nodes \nthemselves.  We next look at how the dynamics of a multi-\nnet system can be described. \n3.2. Transition systems \nIn our discussion of the dynamics of feedforward multi-\nnet systems, we shall use the language of transition systems \n(cf. [1]). \nA transition system T  is composed of a non-empty set \nQ  of states, a non-empty set A  of actions and a relation \nQAQ \u00d7\u00d7\u2286\u2192 , the transition relation of T .  The \nelements of \u2192  are ordered triples ),,( qaq \u2032 , where \nQqq \u2208\u2032,  and Aa\u2208 .  We shall write qq a \u2032\u2192  to indicate \nthat \u2192\u2208\u2032),,( qaq .  Intuitively, qq a \u2032\u2192  means that if the \nsystem is in state q , then the action a  may take place, after \nwhich the system is in state q\u2032 .  For finite ( Q  finite) \ntransition systems, there is a graphical representation in \nwhich elements of Q  are nodes and qq a \u2032\u2192  is indicated \nby an arrow from q  to q\u2032  labelled a . \nIf we consider a feedforward multi-net system, such as \nan ensemble, then states describe static conditions of the \nmulti-net, and actions transform one static situation into \nanother.  Such an action occurs when an individual node \ntakes the values on its inputs, evaluates the output, which \nwill also depend on its current local parameterization, and \ntransmits it, either to a parent node or to the output of the \nentire multi-net.  In this way the networks within the system \ntake input, change state and pass on their output. \nAt the beginning of the feedforward sweep, the inputs to \nthe nodes and the local parameterizations have specific \nvalues (for example, the weights).  Changes to this state as \na result of applying the input depend upon these parameters \nand the node functions.  A state, therefore, is embodied by a \nfunction associating nodes with values and \nparameterizations.  An action involves an activation of a \nnode, altering the value at its output.  These dynamics may \nbe described by execution sequences. \nIf x  is a sequence of actions and Qqq \u2208\u2032, , then we \ndefine qq x \u2032\u2192 , providing that: \n1) If \u039b=x  (the empty sequence), then qq x \u2032\u2192  iff \nqq \u2032= ; \n2) If naax L1= , where Aaa n \u2208,,1 L , then qq x \u2032\u2192  iff \nthere exists Qqq n \u2208,,1 L  such that \nqqqq n\naa n \u2032=\u2192\u2192\u2192 L11 . \nWe shall say that an execution qq x \u2032\u2192  is maximal from \nq  if and only if qq a \u2032\u2032\u2192\u2032  for no Aa\u2208  and Qq \u2208\u2032\u2032 , such \nthat q\u2032  is the maximal state from q .  We shall prove \n(Theorem 1) that from any state 0\u03c3  in a given multi-net \nwith a given parameterization: \n1) There exists a maximal execution \u03c3\u03c3 x\u21920 ; (A) \n2) If \u03c3\u03c3 x\u21920  and \u03c3\u03c3 \u2032\u2192\ny\n0  are maximal executions, \nthen \u03c3\u03c3 \u2032= . (B) \nThe practical consequence of this is that there is a \nfunction OIG \u2192:\u03b8 , where I  is the set of all input values \nthat can be applied to the leaves of the multi-net; O  is the \nset of all values that can appear as an output at the root of \nthe multi-net, such that if 0\u03c3  is a state in which \u03b8  is the \nparameterization and Ix\u2208 gives the values on the leaves of \nthe multi-net in state 0\u03c3 , then )(xG\u03b8  is the value of the \noutput at the root in state \u03c3  where \u03c3\u03c3 x\u21920  is any \nmaximal execution.  If \u03b8  is the parameterization of the \nmulti-net after training, then \u03b8G  describes its functionality.  \nThe consequence of this is that we can describe an arbitrary \ncomplex neural model (or any other combination of \nfunctions) precisely in terms of its inputs, operations and \noutputs, parameters and functions and know that such a \ndescription guarantees the system can produce an output \n(A) deterministically (B).  We shall refer to (A) and (B) \nagain later. \n3.3. Multi-net systems: feedforward state \nWe now use the idea of a framework and of a transition \nsystem to define a feedforward multi-net system. \nOne of the points of this paper is that many aspects of the \ncombination of networks can be described and analyzed \nwith no reference to numerical issues.  For example, \nTheorem 2 (section  4.3) shows that any reasonable training \nscheme can be achieved by an abstract backward pass of \nparameter (weight) modification instructions.  The proof \nwould be much more complicated if we focussed on the \nnumerical properties and such systems (for example, \ncomputing gradients).  However, once the existence of the \nproof is established, it is necessary to make it more \nconcrete to be of use. \nOur abstract view of a multi-net system explores the \ntopology of the network, represented by a framework \n(Definition 1) of nodes.  We abstract the weights, biases, \netc. by associating each node Vv\u2208  with an abstract set \nv\u0398  of parameters.  Likewise, we do not refer to an \n5 \n \n \nactivation function, but that each node Vv\u2208  is associated \nwith a function v\u03c6  that takes the values on the node\u2019s inputs \nand calculates an output, depending on the current value of \nits local parameters. We shall also assume that each node \nVv\u2208  is associated with a non-empty set vO  of output \nvalues. \nTo be specific, suppose that Vv\u2208 .  If v  is not a leaf \nnode, then there are distinct nodes nvv ,,1 L  such that \nvvi < , for each so that vvv n \u2022=},,{ 1 L .  We can therefore \nconsider inputs to v  to be vectors with coordinates \nnvv ,,1 L .  Technically, an input vector to v  is a function \nthat maps the children of v  to the union of the outputs of \neach child: \nU\nvw\nwOvx\n\u2022\u2208\n\u2022 \u2192:  (4) \nwith the property that wOwx \u2208)(  for each vw\n\u2022\u2208 .  Note \nthat this is equivalent to, say, describing the connections a \nneuron has from a previous network layer; each connection \nprovides part of the input to the neuron. \nWe shall write wx  for )(wx .  The set of all such \nvectors x  constitutes the input space of v  in V  and will \nbe denoted by vI .  For uniformity, in the case of nodes \n)(Vleafv\u2208 , we shall define }{ vv \u22a5=\n\u2022 , so that the inputs \nto v  will belong to a set \nv\nO\u22a5 , which is the set of all valid \ninputs to leaf v  from the environment.  The input space of \n)(Vleafv\u2208  may now be defined as for non-root nodes. \nWe are now in a position to give a formal definition of a \nmulti-net. \nDefinition 2. A multi-net is defined to be a triple \n),,(N \u03a6\u0398= F , where: \n1) ),( \u2264= VF  is a multi-net framework (Definition 1); \n2) \u0398  is an indexed family of non-empty sets v\u0398 , Vv\u2208 , \nthe parameterization sets of N ; \n3) \u03a6  is an indexed family of node functions v\u03c6 , Vv\u2208 , \nwhere: \nvvvv OI \u2192\u00d7\u0398:\u03c6  (5) \nWe shall now describe the feedforward dynamics of the \nsystem.  If we consider the parameterization of the multi-net \nto be fixed (learning will be dealt with later), then what \nchanges during the feedforward sweep are the values on the \noutputs of the nodes.  We assume for the moment that the \nexternal inputs to the multi-net remain unchanged.  We may \ntherefore define a feedforward state to be a function that \nmaps the framework to the union of the outputs of each node \nfeeding the system output: \nU\n+\n\u2208\n+ \u2192\nVv\nvOV:\u03c3  (6) \nwhere )}(:{ VleafvVV v \u2208\u22a5\u222a=\n+  and vOv \u2208)(\u03c3 , for each \n+\u2208Vv .  )(v\u03c3  gives the value residing on the output of the \nnode v  input to its parent, whilst )( v\u22a5\u03c3  gives the value on \nthe input to the leaf v , the notional parent of v\u22a5 .  \n+V  is \ntherefore the set of all nodes that provide output used by the \nsystem (including the output of the input layer). \nLet N\u03a3  denote the set of all feedforward states of the \nmulti-net N .  What will change a state is the activation of \nsome node, as it computes its output from the current input.  \nWe may therefore consider V  as the set of actions.  The \ntransition relation for these states will depend on the \nparameterization of the multi-net. We may represent a \nparameterization by a function that maps the framework to \nthe union of all the node parameterizations: \nU\nVv\nvV\n\u2208\n\u0398\u2192:\u03b8  (7) \nsatisfying vv \u0398\u2208)(\u03b8 , for all Vv\u2208 . We denote the set of \nall parameterisations of N  by N\u0398 . \nWe are now interested in describing relations \nNN \u03a3\u00d7\u00d7\u03a3\u2286\u2192 V\u03b8 , which for a given parameterization \u03b8  \ndescribes the possible set of state transitions for the system. \nIn any state N\u03a3\u2208\u03c3 , the inputs to Vv\u2208 , that is the \nvalues lying on the outputs to the elements vw \u2022\u2208 , will \nhave values )(w\u03c3  and so we can define a vector \nvv Iz \u2208,\u03c3  by  \n)()(, wwz v \u03c3\u03c3 = , vw\n\u2022\u2208  (8) \nvz ,\u03c3  is the vector of inputs to node v  in state \u03c3 . \nWhat we are interested in is the output of the system for a \ngiven state, defined as the feedforward state of each \ncomponent node \u2013 we give inputs to the system and \npropagate these through to the output in a single pass.  To \nachieve this, we define the notion of stability.  Let us say \nthat a node Vv\u2208  is stable in state N\u03a3\u2208\u03c3  with respect to \nN\u0398\u2208\u03b8  if )()),(( , vzv vv \u03c3\u03b8\u03c6 \u03c3 = , otherwise, it is unstable.  \nA node is stable in a given state with respect to a given \nparameterization if its output equals the value computed by \nthe node from its inputs in that state and its local \nparameters. \nWe may now define \u03c3\u03c3 \u03b8 \u2032\u2192\nv  iff v  is not stable at \u03c3  \nwith respect to \u03b8  \n)],(\/[ ,vvv zv \u03c3\u03b8\u03c6\u03c3\u03c3 =\u2032  (9) \nwhich is the operation of the action v\u03b8\u2192  that moves the \n6 \n \n \nnode v  from state \u03c3  to state \u03c3 \u2032 , where \n\uf8f3\uf8f2\n\uf8f1 \u2260\n=\notherwise\nif\na\nvww\nwav\n)(\n)](\/[\n\u03c3\n\u03c3  (10) \nSo \u03c3\u03c3 \u03b8 \u2032\u2192\nv  when the output to v  at \u03c3  with respect to \n\u03b8  does not match the inputs.  The effect of the transition is \nto update this output according to the node function v\u03c6 . \nWe say that \u03c3  is stable w.r.t. to \u03b8  if every Vv\u2208  is \nstable at \u03c3  with respect to \u03b8 .  By definition, if \u2217\u2208Vx  \nand \u03c3 \u2032  is stable, then for every N\u03a3\u2208\u03c3 , \u03c3\u03c3 \u03b8 \u2032\u2192\nx   is a \nmaximal execution (cf. section  3.2) and ))(( Vroot\u03c3 \u2032  is the \nfinal stable output.  Write )( N\u03a3\u03b8Stbl  for the set of all \nstates N\u03a3\u2208\u03c3  stable with respect to \u03b8 . \nDefinition 3. If N  is a multi-net then define the input space \nof N  to be the set of all functions \nU\n)(\n)(:\nVleafv\nv\nOVleafx\n\u2208\n\u22a5\u2192  (11) \nsuch that \nv\nOvx \u22a5\u2208)(  for each )(Vleafv\u2208 .  Define the \noutput space of N to be )(N VrootOO = . If )( N\u03a3\u2208 \u03b8\u03c3 Stbl , \nthen define NIx \u2208\u03c3  by )()( vvx \u22a5=\u22a5 \u03c3\u03c3 , for all \n)(Vleafv\u2208 , and NOy \u2208\u03c3  by )(rootVy \u03c3\u03c3 = . \nWe have explained in section  3.2, in general terms, how \nwe may use transition systems to describe the dynamics of \nsystems as sequences of state-transforming actions.  We \nhave now defined \u2018state\u2019 and \u2018transition\u2019 for multi-net \nsystems.  The following result establishes (A) \u2013 that we can \ndescribe the output of the system given an input and \nparameterization. \nProposition 1. For every N\u03a3\u2208\u03c3  and N\u0398\u2208\u03b8  , there exists \na maximal execution \u03c3\u03c3 \u03b8 \u2032\u2192\nx . \nProof.  Define \n} w.r.t.stableis:{, \u03b8\u03b8\u03c3 vwvVwL \u21d2\u2264\u2208=  (12) \nwhich is the set of nodes w , such that all are stable.  We \nmay readily verify: \n1) )( N\u03a3\u2208 \u03b8\u03c3 Stbl  iff VL =\u03b8\u03c3 , ; \n2) If w  is minimal in the set \u03b8\u03c3 ,\\ LV , then there exists \n\u03c3 \u2032  such that \u03c3\u03c3 \u03b8 \u2032\u2192\nw  and \u03b8\u03c3\u03b8\u03c3 ,, }{ \u2032\u2286\u222a LwL . \nHere, if VX \u2286 , then v  is minimal in X  if Xv\u2208 and \nXw\u2209 , for vw < .  If A  and B  are sets then: \n}:{\\ BaAaBA \u2209\u2208=  (13) \nSo to say that w  is minimal in \u03b8\u03c3 ,\\ LV  is to say that w  is \nnot stable w.r.t. \u03b8 , but all its children are. \nWe may now argue by induction on \u03b8\u03c3 ,\\ LV  (the \ncardinality of \u03b8\u03c3 ,\\ LV ).  If 0\\ , =\u03b8\u03c3LV , then VL =\u03b8\u03c3 , , \nso \u03c3  is stable, from  1), and \u03c3\u03c3 \u03b8 \u2032\u2192\n\u039b  is a maximal \nexecution.  If 0\\ , >\u03b8\u03c3LV , then let w  be minimal in the \nset \u03b8\u03c3 ,\\ LV .  w  cannot be stable, since if it were, then as \n\u03b8\u03c3 ,Lv\u2208  for all wv \u2264  it would follow that \u03b8\u03c3 ,Lw\u2208 , a \ncontradiction.  So \u03c3\u03c3 \u03b8 \u2032\u2032\u2192\nw  for some N\u03a3\u2208\u2032\u2032\u03c3 .  But by \n2), \u03b8\u03c3\u03b8\u03c3 ,, }{ \u2032\u2032\u2286\u222a LwL , so \u03b8\u03c3\u03b8\u03c3 ,, \\\\ LVLV <\u2032\u2032 . \nBy induction, there exists a maximal execution \n\u03c3\u03c3 \u03b8 \u2032\u2192\u2032\u2032\nx , but now \u03c3\u03c3 \u03b8 \u2032\u2192\nxw.  is a maximal execution. \n\u25a1  \nWe also need to know that the system is deterministic, \nthat is any given input and set of parameters, there is a \nunique output.  The next result establishes (B). \nProposition 2. Suppose that )(, 21 N\u03a3\u2208 \u03b8\u03c3\u03c3 Stbl  such that \n21 \u03c3\u03c3\nxx = , then 21 \u03c3\u03c3 = . \nProof.  Define \n)}()(:{ 21,, 21 vvwvVwT \u03c3\u03c3\u03b8\u03c3\u03c3 =\u21d2\u2264\u2208= +  (14) \nwhich is the set of nodes w , such that all the outputs of the \nnodes from the two states are equal.  We observe that \n21,, 21 \u03c3\u03c3\u03b8\u03c3\u03c3 =\u21d4=\n+VT . It is also the case that for all \n)(Vleafv\u2208 , \u03b8\u03c3\u03c3 ,, 21Tv\u2208\u22a5 , by hypothesis, so \u2205\u2260\u03b8\u03c3\u03c3 ,, 21T .  \nWe shall assume that +\u2260VT \u03b8\u03c3\u03c3 ,, 21  and obtain a \ncontradiction. Suppose that w  is minimal in \u03b8\u03c3\u03c3 ,, 21\\ TV\n+ , \nthen \u03b8\u03c3\u03c3 ,, 21Tv\u2208  for all wv <  and in particular, \n\u03b8\u03c3\u03c3 ,, 21Tw\u2286\n\u2022 .  From the stability definition \n)(),(),()( 2,,1 21 wzzw ww \u03c3\u03b8\u03c6\u03b8\u03c6\u03c3 \u03b8\u03c3\u03b8\u03c3 ===  (15) \nBut \u03b8\u03c3\u03c3 ,, 21Tv\u2208  for all wv < , so \u03b8\u03c3\u03c3 ,, 21Tw\u2208 , the \nrequired contradiction. \u25a1  \nGiven the two propositions and the definition of input \nand output, we may now describe the function computed by \na multi-net in a given configuration. \nTheorem 1. Suppose that N  is a multi-net and that \nN\u0398\u2208\u03b8 , then there is a total function \nNN,N : OIG \u2192\u03b8  (16) \nsuch that if )( N\u03a3\u2208 \u03b8\u03c3 Stbl , then \n7 \n \n \n\u03c3\u03c3\u03b8 yxG =)(,N  (17) \nProof. The function \u03b8,NG  is well defined because if \n)(, N21 \u03a3\u2208 \u03b8\u03c3\u03c3 Stbl  and 21 \u03c3\u03c3 xx = , then by Proposition \n2, 21 \u03c3\u03c3 =  and in particular, 21 \u03c3\u03c3 yy = . \nThe function is total because if NIx\u2208  and N\u03a3\u2208\u03c3  is \nany state such that xx =\u03c3 , then by Proposition 1, there \nexists a maximal execution, \u03c3\u03c3 \u03b8 \u2032\u2192\nx  and clearly \nxxx ==\n\u2032 \u03c3\u03c3 , since no transition alters the values on the \ninputs to the multi-net. Hence, )(,N xG \u03b8  is defined and \nequal to \u03c3 \u2032y . \u25a1 \nIf all the sets \nivI  are equal to some set I , then we say \nthat N  is uniform and in such cases, we have a function \nN,N :\u02c6 OIG \u2192\u03b8  defined by \n)()(\u02c6 ,N,N xGxG \u03b8\u03b8 =  (18) \nwhere xx v =\u22a5 )( , for each )(Vleafv\u2208 . \n3.4. Multi-net systems: strategies for learning \nWe now turn to the training of multi-nets, and \nspecifically to systems governed by some criterion function \nthat can be used to measure the convergence of the system \nto the criterion.  The criterion is liberal in the sense that it \ncan specify any required stopping condition.  For example, \nwe might treat such criterion functions as error functions \nused in supervised learning systems, where the error is \nsome measure of the difference between the desired and \nactual output of the system.  However, this does not exclude \nother criteria or types of learning, such as unsupervised \nlearning systems, in which our criterion may be measured \nin a way not necessarily related to a target response, for \nexample through a simple number of learning cycles. \nTaking our abstract view, we consider training to be the \napplication of an operator S  to parameterizations. Thus, \nfor a given (uniform) multi-net N , a parameterization \n\u0398\u2208\u03b8 , an input NIx\u2208  and an output NIy\u2208 , the operator \nwill generate a new parameterization \u0398\u2208\u2032\u03b8 . \nWe may therefore identify a strategy with a function: \nNNNN: \u0398\u2192\u0398\u00d7\u00d7OIT  (19) \nso that with the notation of the previous paragraph, \n),,( \u03b8\u03b8 yxT=\u2032 .  In fact, as the strategy will only be applied \nwhen the multi-net has attained a stable state following a \nfeedforward pass, we may consider a strategy to be defined \nby a function \nNNN \u0398\u2192\u0398\u00d7IS :  (20) \nwhere )),(,(),( , \u03b8\u03b8 \u03b8 xGxTxS N= . \nLet us consider this in connection with the whole training \nprocess.  We fix NIx\u2208  and suppose that N  has an initial \nparameterization N\u0398\u22080\u03b8 .  Repeated application of a \nfeedforward pass, together with the application of the \nstrategy as embodied by S  gives us a sequence of \nparameterizations ,...,...,0 r\u03b8\u03b8 , where for each 0\u2265r , \n),(1 rr xS \u03b8\u03b8 =+ .  We note that if rr \u03b8\u03b8 =+1 , then \n112 ),(),( +++ === rrrr xSxS \u03b8\u03b8\u03b8\u03b8  (21) \nand by induction this gives: \nLemma 1. If rr \u03b8\u03b8 =+1 , then for all ri \u2265 , ri \u03b8\u03b8 = .\u25a1 \nIf rr \u03b8\u03b8 =+1 , for all ri \u2265 , then we say that S  converges \nfor x  from 0\u03b8 . \nTraining will have some form of goal, of course, and we \nshall suppose that this is expressed by a set; strictly \nspeaking, the extension of a predicate: \nNN OIP \u00d7\u2286  (22) \nP  expresses a goal in the sense that training has \nsucceeded if ( ) PxGx \u2208)(, ,N \u03b8 ; P  may be considered as the \nextension of a predicate defining successful training. \nWe shall say that S  is a strategy for N  with respect to \ncriterion P  if and only if  \nPxGxxS \u2208\u21d4= ))(,(),( ,N \u03b8\u03b8\u03b8  (23) \nLemma 1 tells us that \u03b8\u03b8 =),(xS  precisely when S  \nconverges to \u03b8  from some initial parameterization, so S  is \na strategy with respect to P  precisely when it converges to \na parameterization satisfying P . \nIn the previous section we defined the feedforward \noperation of a multi-net system using partially ordered sets \nand state transitions.  Along the way we have had to \nprovide formal proof of certain properties of these systems \nto ensure completeness and rigor (such as the stable and \ndeterministic output of the system).  Whilst this is perhaps \nlengthy, this formal approach is necessary in order to \nprovide a solid foundation for the exploration of multi-net \nsystem properties.  Lastly, we have provided a way of \ndescribing the learning process within the system.  \nHowever, as yet we have provided no implementation \ndetail using the framework, or exploited the mathematical \nproperties of the definitions.  In the next section we start to \ndo this by exploring a supervised learning strategy for the \ngeneric class of multi-net systems. \n4. Supervised learning for multi-net systems \nSo far we have provided a formal definition of a multi-\nnet system and its associated learning algorithm.  The most \nimportant aspect of this approach is that it does not \nconstrain the type of networks that can be combined.  All \nthat is required is a suitable topology, set of feedforward \nfunctions, parameters and learning strategy functions.  \nHowever, whilst this definition is perhaps interesting, to be \nuseful we need to consider example systems in which we \ncan start to use this formal foundation to infer properties of \n8 \n \n \nthe combined system. \nIn this section we first motivate our discussion on \nlearning by considering an arbitrary multi-layer perceptron \n(MLP) trained using a supervised learning technique, such \nas the host of gradient descent algorithms.  However, we do \nthis only to abstract the notion of a backward training pass, \nwithout constraining ourselves with unnecessary details, \nsuch as requiring the computation of gradients.  By treating \nthe MLP as a series of individual layers that are themselves \nseparate networks, we generalize the notion of an arbitrary \nfeedforward network to a generic sequential and parallel \ncombination of networks that can be trained using an \nabstract algorithm.  Such a definition can already \nencompass a wide range of techniques, including partially \nconnected feedforward networks, in-situ trained ensembles \nand ME. \n4.1. System definition \nWe start by considering the simple MLP as shown in Fig. \n2, which, without loss of generality, we have considered as \na two-layer network with an arbitrary number of inputs, \nhidden layer neurons ( n ) and outputs ( m ).  Each unit \noperates using a combination of inputs, together with an \nactivation function. \nWe define ),,(N mlpmlpmlpmlp F \u03a6\u0398=  as a multi-net, by \n1) ),( \u2264= mlpmlp VF , with },{ utVmlp =  and tu < ; \n2) },{ utmlp \u0398\u0398=\u0398 , nR=\u0398u  and mR=\u0398t  where R  \ndenotes the set of real numbers; \n3) },{ utmlp \u03c6\u03c6=\u03a6 . \n4.2. Learning as a backward pass \nWe now consider how this simple system is trained using \na backward pass of adjustments to parameters, before \nextending this to the concept of a multi-net system.  In such \nbackward propagating techniques, each node receives some \nform of instruction from its parent in order to update its \nweights.  Depending upon this instruction, and its current \nparameterization and output, it will modify its parameters \nand propagate an instruction down to its children.  A simple \nexample of this is the basic backpropagation algorithm [40] \nin which the notional error of each hidden neuron is \ncalculated using the error on the output.  This suggests that \nat each node v  we have a non-empty set vA  of instructions \ntogether with an adjustment function \nvvvvv OAj \u0398\u2192\u0398\u00d7\u00d7: , (24) \nand a family of instruction propagation functions \nuvvvuv AOAa \u2192\u0398\u00d7\u00d7:, , vu \u2022\u2208  (25) \nAn application of vj  adjusts the parameters at node v  \naccording to an instruction a  received, the current value y  \non v  and the current parameter \u03b8  of v , giving a new \nparameter ),,( \u03b8yajv .  Each child vu \u2022\u2208  of v  will then \nreceive one instruction ),,(, \u03b8yaa uv . \nWe assume that each set vA  contains an instruction to do \nnothing, which we denote by v0 , so that we have: \n\u03b8\u03b8 =),,0( yj vv , uvuv ya 0),,0(, =\u03b8  (26) \nfor all vOy\u2208 , v\u0398\u2208\u03b8 . We shall require further that only a \nzero instruction can keep the parameter at the root node \nfixed, that is: \n)()( 0),,( VrootVroot ayaj =\u21d2= \u03b8\u03b8 . (27) \nWe shall refer to this as the strictness condition. \nAt this point we note that none of these definitions \nconstrains the topology of the system, except that it can be \ndescribed using a partially ordered set with a maximal \nelement.  Furthermore, our description of the adjustment \nfunctions are only motivated by algorithms such as \nbackpropagation, without having to define what adjustments \nare made, or indeed whether they are consequent from \nsupervised learning or otherwise.  As such, we have \ntherefore abstracted the notion of an MLP to the generic \nclass of multi-net systems being trained using an abstract \nlearning algorithm. \nAs with the feedforward sweep, we adopt a state-based \napproach to the description of the backward pass. That is to \nsay, we conceive of the multi-net going through a series of \nchanges as the adjustments sweep down from the root. \nA state is an instantaneous snapshot of the system. Given \nthe purpose of the vj  and uva ,  functions, we see that what \nthe state must record are the instructions, outputs and \nparameters currently at each node. Consequently, we define \na feedback state to be a function that maps the nodes to the \nunion of instructions, outputs and parameterizations for \neach node: \nUUU\nVv\nv\nVv\nv\nVv\nv OAV\n\u2208\u2208\u2208\n\u0398\u00d7\u00d7\u2192:\u03c1  (28) \nsuch that for each Vv\u2208 , vvv OAv \u0398\u00d7\u00d7\u2208)(\u03c1 . If \n),,()( \u03b8\u03c1 yav = , then we define aa v =)(\u03c1 , yy v =)(\u03c1  \nand \u03b8\u03b8\u03c1 =)(v . Thus )(va\u03c1  gives the instruction considered \nby v  in state \u03c1  and similarly for the current output and \ncurrent parameter.  Let N\u03a8  denote the set of all feedback \nstates. \nWe also have a notion of state transition, the expression \n\u03c1\u03c1 \u2032\u2192v  says that if the algorithm is applied locally at \nnode v  in state \u03c1 , then the state will be transformed to \n\u03c1\u2032 . \u03c1\u03c1 \u2032\u2192v  holds precisely when for all Vw\u2208 : \n9 \n \n \n\uf8f4\uf8f3\n\uf8f4\uf8f2\n\uf8f1 \/\n=\u2032 otherwise\nif\n),,( )()()(,\n)(\n)(\nvvvwv\nw\nw yaa\nvwa\na\n\u03c1\u03c1\u03c1\n\u03c1\n\u03c1 \u03b8\n<\n (29) \n)()( ww yy \u03c1\u03c1 =\u2032  (30) \n\uf8f4\uf8f3\n\uf8f4\uf8f2\n\uf8f1 \u2260\n=\u2032 otherwise\nif\n),,( )()()(\n)(\n)(\nvvvv\nw\nw yaj\nvw\n\u03c1\u03c1\u03c1\n\u03c1\n\u03c1 \u03b8\n\u03b8\n\u03b8  (31) \nSo the application of the algorithm at node v  propagates \nan instruction down to each of the children of v  according \nthe functions uva , , leaving everything else unchanged.  \n(Outputs at nodes only change in the feedforward pass.)  \nFinally, the application of the algorithm at v  will change \nits own local parameters, leaving all others unchanged. \nPutting together the node modifications together in the \ncase of a backward pass is not quite as simple as in the \ncase of the feedforward formalism, since there is no \nconcept corresponding to a stable state, which guarantees \nthat each node is only modified once during a sweep. We \nhave to impose this explicitly here. Essentially, the idea is \nthat no node v  should be modified until every node vw\u2265  \nhas been modified. We should therefore consider sequences \nof the form \nn\nvv n \u03c1\u03c1\u03c1 \u2192\u2192 L11  (32) \nsuch that jivv ji <\u21d2> . Note that this means \n)(1 Vrootv = . Any such sequence nvv L1  is called a \ntopological sort of V  and we denote the set of all \ntopological sorts of V  by )(VTS . We now have a \nfunction: \nNN)(: \u03a8\u2192\u03a8\u00d7VTSR  (33) \ngiven by \n\u21d4\u2032= \u03c1\u03c1 ),( 1 nvvR L \u03c1\u03c1\u03c1\u03c1 \u2032=\u2192\u2192 n\nvv nL\n1\n1  (34) \nOn the face of it, it would seem that the application of the \nalgorithm depends on the order in which it is applied to the \nnodes. Fortunately, this is not the case, as the following \nresult shows. \nProposition 3. With the above notation, if )(, VTS\u2208\u2032\u03b1\u03b1 , \nthen ),(),( \u03c1\u03b1\u03c1\u03b1 \u2032= RR , for all N\u03a8\u2208\u03c1 . \nProof.  Let Vvv \u2208\u2032,  and define vvvvvv \u2264\/\u2032\u2227\u2032\u2264\/\u21d4\u2032\u03b9 . \nIf \u2217\u2208\u2032 V\u03b1\u03b1 , , then define \u03b1\u03b1 \u2032\u2261 )1(  if and only if there \nexists \u2217\u2208\u2032\u2032 V\u03b2\u03b2 ,  and Vvv \u2208\u2032,  such that \u03b2\u03b2\u03b1 \u2032\u2032\u2032= vv , \n\u03b2\u03b2\u03b1 \u2032\u2032\u2032=\u2032 vv  and vv \u2032\u03b9 .  Now define \u03b1\u03b1 \u2032\u2261  if and only if \neither \u03b1\u03b1 \u2032=  or there exists )(,...,1 VTSn \u2208\u03b1\u03b1 , such that \n\u03b1\u03b1\u03b1\u03b1 ==\u2261\u2261= n\n)1()1(\n1 ... .  First, we show: \n1) If )(VTS\u2208\u03b1  and \u03b1\u03b1 \u2032\u2261 , then )(VTS\u2208\u2032\u03b1  and \n),(),( \u03c1\u03b1\u03c1\u03b1 \u2032= RR ; \nIn view of the definition of \u2261 , in order to prove 1) it \nsuffices to prove that \n2) If )(VTS\u2208\u03b1  and \u03b1\u03b1 \u2032\u2261 )1( , then )(VTS\u2208\u2032\u03b1  and \n),(),( \u03c1\u03b1\u03c1\u03b1 \u2032= RR ; \nNext we prove \n3) If )(, VTS\u2208\u2032\u03b1\u03b1 , then \u03b1\u03b1 \u2032\u2261 . \nThe proof of the proposition now proceeds as follows.  If \n)(, VTS\u2208\u2032\u03b1\u03b1 , then \u03b1\u03b1 \u2032\u2261  by 3), and so \n),(),( \u03c1\u03b1\u03c1\u03b1 \u2032= RR  by 1). We prove (2) and (3). \nFor 2), suppose that nrr vvvvvv LL 11 +\u2032=\u03b1  and \nnrr vvvvvv LL 11 +\u2032=\u2032\u03b1  with vv \u2032\u03b9 , so that \u03b1\u03b1 \u2032\u2261 )1( . If \n)(VTS\u2209\u2032\u03b1 , then we would have to have vv \u2032\u2264 . But, this \nwould contradict vv \u2032\u03b9 . Hence, )(VTS\u2208\u2032\u03b1 . We also note \nthat if \u03c1\u03c1\u03c1 \u02c6vv \u2032\u2192\u2032\u2192 , \u03c1\u03c1\u03c1 \u2032\u2192\u2032\u2032\u2192 \u2032\u2032 \u02c6vv  and vv \u2032\u03b9 , then a \nsimple calculation shows that \u03c1\u03c1 \u2032= \u02c6\u02c6 . Hence, \n),(),( \u03c1\u03b1\u03c1\u03b1 \u2032= RR . We have argued that  if )(VTS\u2208\u03b1  \nand \u03b1\u03b1 \u2032\u2261 )1( , then )(VTS\u2208\u2032\u03b1  and ),(),( \u03c1\u03b1\u03c1\u03b1 \u2032= RR .  \nNow 1) follows, as we have already explained. \nFor 3), suppose that )(, VTS\u2208\u2032\u03b1\u03b1 . We argue by \ninduction on )()( \u03b1\u03b1\u03b1 \u2032\u2227\u2212=\u2032 lVn , where \u03b1\u03b1 \u2032\u2227  denotes \nthe longest common prefix of \u03b1  and \u03b1\u2032 , and in general \n)(\u03b2l  denotes the length of \u03b2 .  For example, if \n},,,{ dcbaV = , abcd=\u03b1 , abdc=\u2032\u03b1 , then 4=V , \nab=\u2032\u2227\u03b1\u03b1 , and so 2)(4)( =\u2212=\u2032\u2227\u2212 abV ll \u03b1\u03b1 . \nIn the base case of the induction, 0)( =\u2032\u03b1n , so that  \n)( \u03b1\u03b1 \u2032\u2227= lV . But )()( \u03b1\u03b1 \u2032== llV , so in this case \n\u03b1\u03b1 \u2032=  and so \u03b1\u03b1 \u2032\u2261  by definition of \u2261 .  For the \ninduction step, we show that there exists )(VTS\u2208\u2032\u2032\u03b1  such \nthat \u03b1\u03b1 \u2032\u2032=\u2032  and )()( \u03b1\u03b1 \u2032<\u2032\u2032 nn .  By induction, \u03b1\u03b1 \u2032\u2032= , \nbut \u2261  is an equivalence relation, so \u03b1\u03b1 \u2032\u2261 , as required. \nSuppose that 0)( >\u2032\u2227\u2212 \u03b1\u03b1lV  and suppose that \n\u03b3\u03b2\u03b1 v= , \u03b3\u03b2\u03b1 \u2032=\u2032 vvv rL1 , Vvvv r \u2208,,,1 L , \u2217\u2208\u2032 V\u03b3\u03b3\u03b2 ,,  \nwith vv ,\u2260 , so that \u03b1\u03b1\u03b2 \u2032\u2227= . As )(1 VTSvvv r \u2208\u2032\u03b3\u03b2 L , \nivv \u2264\/ , ri \u2264\u22641 , and as all the iv  occur in \u03b3  and \n)(VTSv \u2208\u03b3\u03b2 , vvi \u2264\/ , ri \u2264\u22641 , hence, vvi \u03b9 , ri \u2264\u22641 , \nand so \n\u03b1\u03b3\u03b2\u03b3\n\u03b2\u03b3\u03b2\u03b1\n\u2032\u2032=\u2032\u2261\u2261\u2032\u2261\n\u2261\u2032=\u2032\n\u2212 rrr\nr\nvvvvvv\nvvvv\nLLL\nLL\n1\n)1()1(\n1\n1\n)1(\n1 , (35) \nHence \u03b1\u03b1 \u2032\u2032\u2261\u2032 . But now )(VTS\u2208\u2032\u2032\u03b1 , by the first part of \n10 \n \n \nthe proof, and \u03b1\u03b1\u03b2 \u2032\u2032\u2264 ,v , so that )()( \u03b1\u03b1\u03b1\u03b1 \u2032\u2227>\u2032\u2032\u2227 ll  \nand hence )()( \u03b1\u03b1 \u2032<\u2032\u2032 nn  By induction \u03b1\u03b1 \u2032\u2032\u2261 , and as \n\u03b1\u03b1 \u2032\u2032\u2261\u2032 , \u03b1\u03b1 \u2032\u2261 , by transitivity. \u25a1 \nAs a result, we have a function NN: \u03a8\u2192\u03a8B  given by \n),()( \u03c1\u03b1\u03c1 RB =  for any )(VTS\u2208\u03b1 . )(\u03c1B  is the new \nfeedback state following one sweep of the algorithm. \nThere is one further matter to consider and that is how \nthe backward pass is initiated. We propose that this \ndepends on a function \n)(NN: VrootAOIQ \u2192\u00d7  (36) \nwhich compares the input with the output and issues an \ninstruction to the root node.  Note that, in line with our aim \nof maximal generality, we have not specified how the input \nand output are compared here. \n4.3. Abstract training strategy \nLet us now see how our abstract scheme determines a \nstrategy \u2013 does it lead to convergence?  Let NIx\u2208  and \nN\u0398\u2208\u03b8 .  We know from Propositions 1 and 2 that there \nexists a unique )( N\u03a3\u2208 \u03b8\u03c3 Stbl  such that x\u03c3\u03c3 = .  We \ndefine N\u03a8\u2208),( \u03b8\u03c1 x  as follows, for each Vv\u2208  \n\uf8f4\uf8f3\n\uf8f4\uf8f2\uf8f1 ==\notherwise\nif\nv\nvx\nVrootvxGxQ\na\n0\n)())(,( ,N\n))(,(\n\u03b8\n\u03b8\u03c1  (37) \nvvx yy =))(,( \u03b8\u03c1  (38) \nvvx \u03b8\u03b8 \u03b8\u03c1 =))(,(  (39) \nIn words, ),( \u03b8\u03c1 x  represents the situation in which a \nfeedforward pass has just completed with parameterization \n\u03b8 , no node except the root is being instructed to change and \nthe root is to receive the instruction computed by Q  on the \nbasis of the current input and output of the multi-net. \nDefinition 4 An abstract backward pass learning scheme \nfor a multi-net N  is a triple )J,A,(B Q= , where \n1) )(NN: VrootAOIQ \u2192\u00d7 ; \n2) A  is an indexed family of instruction propagation \nfunctions v,ua , Vv\u2208 , vu\n\u2022\u2208 ; \n3) J  is an indexed family of adjustment functions vj , \nVv\u2208 . \nLet us now see how our scheme determines a strategy.  \nGiven NIx\u2208  and N\u0398\u2208\u03b8 , we construct ),( \u03b8\u03c1 x .  We \nnow appeal to Proposition 3, which asserts the existence of \na feedback state N)),(( \u03a8\u2208\u03b8\u03c1 xB .  To obtain ),( \u03b8xS , we \nsimply extract the parameters from )),(( \u03b8\u03c1 xB , that is, for \neach Vv\u2208 , define \n)))(,((),( vxBvB xS \u03b8\u03c1\u03b8\u03b8 =  (40) \nProposition 4. Suppose that )J,A,(B Q=  is an abstract \nscheme, then BS  is a training strategy with respect to the \npredicate BP  given by \n)(0),(),( VrootB yxQPyx =\u21d4\u2208 . (41) \nProof. If )(, 0)),(,( VrootxGxQ =\u03b8\u03b8N , then vvxa 0))(,( =\u03b8\u03c1 , \nfor all Vv\u2208 , by  (37) and hence \u03b8\u03b8 =),(xSB . \nConversely, if \u03b8\u03b8 =),(xSB , then in particular, \n)),()),(,((\n),(\n)(,,)(\n)()(\nVrootVroot\nVrootBVroot\nxGxGxQj\nxS\n\u03b8\n\u03b8\u03b8\n\u03b8\u03b8 NN=\n=\n (42) \nso that )(, 0)),(,( VrootxGxQ =\u03b8\u03b8N , by  (27). Now apply \n (23). \u25a1 \nWe know that every abstract scheme determines a \nstrategy. Not all strategies may so be determined; \nProposition 5 will show that such strategies must be \nregular, in the sense defined by Definition 5.  Broadly \nspeaking, regularity reflects the manner in which abstract \nschemes generate strategies. For example, a strategy BS  \nwill make the same alterations at the root node given the \nsame pair ),( yx  and parameterization. This is one aspect \nof 1) of Definition 5. Indeed, if N\u0398\u2208\u2032\u03b8\u03b8 ,  agree on all \nnodes above a node Vv\u2208 , then BS  will have the same \neffect on their parameters. We capture these ideas using the \nrelations vx,\u2261 , defined below. \nFirst, if Vv\u2208 , then define }:{ vwVwv \u2265\u2208=\u2191 .  \nSuppose NN \u0398\u00d7\u2208 Ix ),( \u03b8 , then by Propositions 1 and 2, \nthere exists a unique )( N\u03a3\u2208 Stbl\u03c3  such that, x\u03c3\u03c3 = . We \nshall name this state ),( \u03b8\u03c3 x . Note that \n)(, ),()( VrootxxG \u03b8\u03c3\u03b8 =N .  Now, for each Vv\u2208  \nand NIx \u2208, , we define a relation vx,\u2261  over N\u0398  by \nwwwwvx xxvw ),(),(., \u03b8\u03c3\u03b8\u03c3\u03b8\u03b8\u03b8\u03b8 \u2032=\u2227\u2032=\u2208\u2191\u2200\u21d4\u2032\u2261  (43) \nOf course, vx,\u2261  is an equivalence relation. \nThe following definition lists those properties of \nstrategies BS  which, as we shall see later, in Theorem 2, \nprecisely characterise them. \nDefinition 5. We shall define a strategy S  to be regular, if \nand only if for each Vv\u2208 , N\u0398\u2208\u2032\u03b8\u03b8 ,  and NIx\u2208 , \n1) uuvx xSxSvu ),(),(., \u03b8\u03b8\u03b8\u03b8 \u2032=\u2265\u2200\u21d2\u2032\u2261 ; \n2) \u03b8\u03b8\u03b8\u03b8 \u03b8\u03b8 \u2032=\u2032\u21d2=\u2227= \u2032 ),()()(),( ,, xSxGxGxS NN ; \n3) \u03b8\u03b8\u03b8\u03b8 =\u21d2= ),(),( )()( xSxS VrootVroot . \nProposition 5. Suppose that B  is an abstract scheme, then \nBS  is regular. \n11 \n \n \nProof. Let Vv\u2208 , N\u0398\u2208\u2032\u03b8\u03b8 ,  and NIx\u2208 .We establish the \nconditions of definition 5. \n1) Suppose that \u03b8\u03b8 \u2032\u2261 vx,  and let suppose that \n)(1 VTSvv n \u2208L . Let n\nvv nx \u03c1\u03c1\u03b8\u03c1\u03c1 \u2192\u2192= L\n10\n1),(  and \nn\nvv nx \u03c1\u03c1\u03b8\u03c1\u03c1 \u2032\u2192\u2032\u2192\u2032=\u2032 L\n10\n1),( .  We observe that \n\uf8f4\uf8f3\n\uf8f4\uf8f2\n\uf8f1 <\n=\notherwise\nif\nj\nj\nji vB\nv\nv xS\nji\n),()( \u03b8\n\u03b8\n\u03b8 \u03c1  (44) \n\uf8f4\uf8f3\n\uf8f4\uf8f2\n\uf8f1\n\u2032\n<\u2032\n=\n\u2032 otherwise\nif\nj\nj\nji vB\nv\nv xS\nji\n),()( \u03b8\n\u03b8\n\u03b8 \u03c1  (45) \nNow, rvv = , for some nr \u2264\u22641  and by the definition of \ntopological sort, if vu\u2208\u2191 , then ivu = for some ri \u2264 . \nHence, for all ri \u2264 , \nii vv \u03b8\u03b8 \u2032= and ii vv xx ),(),( \u03b8\u03c3\u03b8\u03c3 \u2032= . \n By (37) and the fact that \n1\n),()(, vxxG \u03b8\u03c3\u03b8 \u2032=N , \n)()( 111111\n)),(,()),(,( vvvv axxQxxQa \u03c1\u03c1 \u03b8\u03c3\u03b8\u03c3 \u2032=\u2032==  (46) \n)(\n)(\n111111\n111111\n)),),(),),(,((\n)),),(),),(,((\nvvvvv\nvvvvv\nxxxQj\nxxxQj\n\u03c1\n\u03c1\n\u03b8\u03b8\u03b8\u03c3\u03b8\u03c3\n\u03b8\u03b8\u03c3\u03b8\u03c3\u03b8\n\u2032\n=\u2032\u2032\u2032=\n=\n \nWe now assume that if ri < , then for all ij \u2264 , then \n)()()()( jijijiji vvvv\naa \u03c1\u03c1\u03c1\u03c1 \u03b8\u03b8 \u2032\u2032 =\u2227=  (47) \nAnd prove that this holds for 1+i . The proof of 1) now \nfollows by induction. We have already established the base \ncase 1=i . \nLet 1+\u2264 ij . If ij \u2264 , then  \n)()()()(\n11 jijijiji\nvvvv aaaa\n++\n\u2032\u2032\n=== \u03c1\u03c1\u03c1\u03c1  (48) \n \nwhereas if 1+= ij , then by the property of topological \nsorts, kj vv\n\u2022\u2208  for ik \u2264 , and so \n)(),(,\n),(,)(\n1\n1\n),),((\n),),((\njikkkkjk\nkkkkjkji\nvvvvvv\nvvvvvv\naxaa\nxaaa\n+\n+\n\u2032\u2032\n=\u2032\u2032=\n=\n\u03c1\u03c1\n\u03c1\u03c1\n\u03b8\u03b8\u03c3\n\u03b8\u03b8\u03c3\n (49) \nSimilarly, if ij \u2264 , then  \n)()()()(\n11 jijijiji\nvvvv\n++\n\u2032\u2032\n=== \u03c1\u03c1\u03c1\u03c1 \u03b8\u03b8\u03b8\u03b8  (50) \nwhere if 1+= ij  and kj vv\n\u2022\u2208  for ik \u2264 , then  \n)()(\n)()(\n111111\n111111\n),)),(,(\n),)),(,(\njiiiiii\niiiiiji\nvvvvv\nvvvvv\nxaj\nxaj\n++++++\n++++++\n\u2032\u2032\n=\u2032\u2032=\n=\n\u03c1\u03c1\n\u03c1\u03c1\n\u03b8\u03b8\u03b8\u03c3\n\u03b8\u03b8\u03c3\u03b8\n(51) \nThis completes the induction step.  Next, we prove 2). We \nhave, using  (23) \n\u03b8\u03b8\n\u03b8\u03b8\n\u03b8\u03b8\n\u03b8\u03b8\n\u2032=\u2032\u21d2\n==\u21d2\n=\u2227=\n\u2032\n\u2032\n),(\n0))(,())(,(\n)()(),(\n)(,,\n,,\nxS\nxGxQxGxQ\nxGxGxS\nVroot\nB\nNN\nNN\n (52) \nFinally, we show 3). Using  (27) and  (31), we have \n\u03b8\u03b8\n\u03b8\u03b8\n\u03b8\u03b8\n\u03b8\n\u03b8\u03b8\n=\u21d2=\u21d2\n=\u21d2\n=\n),(0))(,(\n)),()),(,((\n),(\n)(,\n)()(,,)(\n)()(\nxSxGxQ\nxGxGxQj\nxS\nVroot\nVrootVrootVroot\nVrootVroot\nN\nNN (53) \n\u25a1 \nAs we have pointed out, regularity characterises \nprecisely those strategies which are determined by abstract \nschemes. The proof of this is by construction, so that we \nneed to define the various sets and functions that make up \nan abstract scheme. \nUnlike a strategy, an abstract scheme does not \u2018know\u2019 in \nadvance the parameterizations and outputs at the nodes. \nHowever, as it percolates through the multi-net, it acquires \nknowledge of the values at the nodes it has already \u2018met\u2019. \nThe point of regularity is that this is all the information it \nneeds to replicate the local effect of a strategy. The \n\u2018instruction\u2019 values will be records of such information, \ntogether with that of the current input. This information is \nencapsulated in the triples ),,( x\u03b2\u03b1 . \nIf Vv\u2208 , then we define }{\\ vvv =\u2191\u2191  and we define vU  \nto be the set of all functions \nU\nvw\nwv\n\u2191\u2208\n\u0398\u2192\u2191:\u03b1  (54) \nsuch that ww \u0398\u2208)(\u03b1  for all vw \u2191\u2208 . We also define vV  to \nbe the set of all functions \nU\nvw\nwOv\n\u2191\u2208\n\u2192\u2191:\u03b2  (55) \nsuch that ww \u0398\u2208)(\u03b2  for all vw \u2191\u2208 . If )}({\\ VrootVv\u2208 , \nthen we define \nNIVUE vvv \u00d7\u00d7=  and }0{ vvv EA \u222a=  (56) \n}0{)( )()( VrootVroot OIA \u222a\u00d7= NN , (57) \nwhere we assume that v0  is some element not appearing in \nvE  and that )(0 Vroot  is some element not appearing in \nNN OI \u00d7 . \nAs the \u2018instruction\u2019 values are records of the values \nalready encountered, a new instruction should be generated \nfrom an old one by an augmentation by an extra pair of \nvalues. This is the point of the s  function below. \nIf )}({\\ VrootVv\u2208  and vAx \u2208),,( \u03b2\u03b1  and \nvv Oy \u00d7\u0398\u2208)\u02c6,\u02c6(\u03b8 , then we define \n),,()\u02c6,\u02c6),,,(( xyxs \u03b2\u03b1\u03b8\u03b2\u03b1 \u2032\u2032= , where \n\uf8f4\uf8f3\n\uf8f4\uf8f2\uf8f1\n=\n\u2191\u2208\n=\u2032\nvu\nvuu\nu\nif\nif\n\u03b8\n\u03b1\n\u03b1 \u02c6\n)(\n)(  (58) \n12 \n \n \n\uf8f3\uf8f2\n\uf8f1\n=\n\u2191\u2208\n=\u2032\nvuy\nvuu\nu\nif\nif\n\u02c6\n)(\n)(\n\u03b2\u03b2  (59) \nWe can easily check that if vAa\u2208  and vv Oy \u00d7\u0398\u2208)\u02c6,\u02c6(\u03b8 , \nthen uAyas \u2208)\u02c6,\u02c6,( \u03b8  for every vu \u2022\u2208 . We use this fact \nwithout further comment in the definition of the uva ,  \nfunctions. \nWe also define ),,()\u02c6,\u02c6),,(( xyyxs \u03b2\u03b1\u03b8 \u2032\u2032= , where \n\u03b8\u03b1 \u02c6))(( =\u2032 Vroot  and yVroot \u02c6))(( =\u2032\u03b2 . Of course, \n)()\u02c6,\u02c6),,(( VrootAyyxs \u2208\u03b8 . \nGiven NN \u0398\u00d7\u2208 Ix ),( \u03b8 , we have values u\u03b8 and uxs ),( \u03b8 . \nThe function va  below selects those values sitting on \nnodes above v , which are precisely those encountered by \nthe algorithm before reaching that node. \nFor each )}({\\ VrootVv\u2208 , define a function \nvv Aa \u2192\u0398N:  by \nww\nv\nxwwvw\nxa\n),()()(.\n),,()(\n\u03b8\u03c3\u03b2\u03b8\u03b1\n\u03b2\u03b1\u03b8\n=\u2227=\u2191\u2208\u2200\n\u21d4=\n (60) \nIt is an immediate consequence of the definition that for \nall )}({\\ VrootVv\u2208  and vu \u2022\u2208  \n),),(),(()( vvvu xasa \u03b8\u03b8\u03c3\u03b8\u03b8 =  (61) \nThe idea behind this construction is that vAa\u2208  records \nthose parts of \u03b8  and ),( \u03b8\u03c3 x  that the algorithm has \nencountered on the way to node v  and that regularity \nensures that this information is enough to determine how it \nshould modify the parameter at v , as the next lemma makes \nclear. \nLemma 2: Suppose that S  is a regular strategy NIx\u2208  and \nN, \u0398\u2208\u2032\u03b8\u03b8 , then \n1) If )()( VrootVroot \u03b8\u03b8 \u2032=  and )()( ,, xGxG NN \u03b8\u03b8 \u2032= , then \n)()( ),(),( VrootVroot xSxS \u03b8\u03b8 \u2032= ; \n2) If )()( \u03b8\u03b8 \u2032= vv aa , vv \u03b8\u03b8 \u2032=  and \nvv xx ),(),( \u03b8\u03c3\u03b8\u03c3 \u2032= , then vv xSxS ),(),( \u03b8\u03b8 \u2032= . \nProof. \n1) The hypothesis translates as \u03b8\u03b8 \u2032\u2261 )(, Vrootx  and the \nconclusion follows from 1) of Definition 5. \n2) Let vw \u2191\u2208  so by (61),  ),,()()( xaa ww \u03b2\u03b1\u03b8\u03b8 =\u2032= , \nsay. So, ww w \u03b8\u03b1\u03b8 \u2032== )(  and \nww xwx ),()(),( \u03b8\u03c3\u03b2\u03b8\u03c3 \u2032== .  As  vv \u03b8\u03b8 \u2032=  and \nvv xx ),(),( \u03b8\u03c3\u03b8\u03c3 \u2032= , it follows that \u03b8\u03b8 \u2032\u2261 vx, .  By \nregularity, vv xSxS ),(),( \u03b8\u03b8 \u2032= . \u25a1 \nWe next observe that if 1)( =\u0398 Vroot , then we will \nalways have )()(),( VrootVrootxS \u03b8\u03b8 = , whence \u03b8\u03b8 =),(xS , \nby 3) of Definition 5. If \u03b8\u03b8 =),(xS , then BSS = , where \n)(0),( Vroot\nS yxQ = , for all NN OIyx \u00d7\u2208),( . We shall \ntherefore assume that 1)( >\u0398 Vroot , so that by the axiom of \nchoice there exists a bijective function \n)()(: VrootVroot \u0398\u2192\u0398\u03c4  (62) \nsuch that \u03b8\u03b8\u03c4 \u2260)(  for each )(Vroot\u0398\u2208\u03b8 . Fix such a \nfunction for the purpose of the following construction. \nWe now pass to the construction; we \ndefine ),,( SSSS QB JA= , where  \n\uf8f4\uf8f3\n\uf8f4\uf8f2\n\uf8f1\n=\u2227\n=\u0398\u2208\u2203\n=\notherwise\nif\n),(\n)(\n),(.0\n),( ,\n)(\nyx\nyxG\nxS\nyxQ\nVroot\nS\n\u03b8\n\u03b8\u03b8\u03b8\nN\nN\n (63) \nTo repeat an earlier observation, an abstract scheme \nknows only x  and y . However, if we know that \n\u03b8\u03b8 \u02c6)\u02c6,( =xS  for any parameterization \u03b8\u02c6 , then Pyx \u2208),( , \nwhere S  is a strategy for P , so that in such a case we must \nhave )(0),( VrootyxQ = . Otherwise, we just pass the \ninformation ),( yx  down to the children of the root node. \nSA  is an indexed family of functions S\nuv\na\n,\n, Vv\u2208 , \nvu \u2022\u2208 , given by \nuVroot\nS ya\nuVroot\n0)\u02c6,\u02c6,0( )(),( =\u03b8  (64) \n)()\u02c6,\u02c6),,((\n),(\n\u03b8\u03b8 u\nS ayyxa\nuVroot\n=  (65) \nuv\nS ya\nuv\n0)\u02c6,\u02c6,0(\n,\n=\u03b8  (66) \n)\u02c6,\u02c6,()\u02c6,\u02c6,(\n,\nyasyaaS\nuv\n\u03b8\u03b8 =  (67) \nwhere yx VrootVroot \u02c6),(\u02c6 )()( =\u2227= \u03b8\u03c3\u03b8\u03b8 . \nSJ  is an indexed family of functions Svj , Vv\u2208 , given \nby  \n\u03b8\u03b8 \u02c6)\u02c6,\u02c6,0( )()( =yj Vroot\nS\nVroot\n (68) \n\uf8f4\uf8f4\n\uf8f4\n\uf8f3\n\uf8f4\uf8f4\n\uf8f4\n\uf8f2\n\uf8f1\n\u2260\u2227\n=\u2227\n=\n=\notherwise\nif\n)\u02c6(\n\u02c6),(\n\u02c6\n\u02c6),(\n)\u02c6,\u02c6),,((\n)(\n)(\n)(\n)(\n\u03b8\u03c4\n\u03b8\u03b8\n\u03b8\u03b8\n\u03b8\n\u03b8\nVroot\nVroot\nVroot\nS\nxS\nyyxS\nyyxj\nVroot\n (69) \n\u03b8\u03b8 \u02c6)\u02c6,\u02c6,0( =yj vSv  (70) \n\uf8f4\uf8f3\n\uf8f4\uf8f2\n\uf8f1 \u2194\n=\notherwise\nif\n\u03b8\n\u03b8\u03b8\u03b8\n\u03b8\n\u02c6\n)\u02c6,\u02c6,(),(\n)\u02c6,\u02c6,(\nyasxS\nyaj vS\nv\n (71) \nwhere, if vAa\u2208 , then \n13 \n \n \naaa v =\u21d4\u2194 )(\u03b8\u03b8  (72) \nProposition 6: SB  is an abstract scheme. \nProof. The functions S\nv\nj  are well defined by Lemma 2. It \nremains to establish  (26) and the strictness condition  (27). \n\u03b8\u03b8 \u02c6)\u02c6,\u02c6,0( =yj vSv  and uv\nS ya\nuv\n0)\u02c6,\u02c6,0(\n,\n=\u03b8  holds by  (64), \n (66),  (68) and  (70). It remains to be shown \nthat \u03b8\u03b8 \u02c6)\u02c6,\u02c6),,(( \u2260yyxj S\nv\n, which gives  (27). \nSuppose than that \u03b8\u03b8 \u02c6)\u02c6,\u02c6),,((\n)(\n=yyxj S\nVroot\n, then \n)\u02c6()\u02c6,\u02c6),,,(( )()( \u03b8\u03c4\u03b8\u03b2\u03b1 VrootS yxj Vroot \u2260 , so \nthat \u03b8\u03b8\u03b8\u03b8 \u02c6),()\u02c6,\u02c6),,((\u02c6 )()( \u2260== Vroot\nS xSyyxj\nVroot\n, by (69), a \ncontradiction. \u25a1 \nTheorem 2.  Suppose that S  is a strategy, then S  is \nregular if and only if there exists an abstract scheme B  such \nthat BSS = . Furthermore, if S  is a strategy with respect to \na criterion P , then PP SB = . \nProof. If BSS =  for some abstract scheme B , then S  is \nregular , by Proposition 5. Conversely, suppose that S  is \nregular. SB  is an abstract scheme by Proposition 6. We \nshall prove that SBSS = . \nLet NN \u0398\u00d7\u2208 Ix ),( \u03b8 .  Suppose first that S  is a strategy \nwith respect to a criterion P , then by  (23),  \n}),(:))(,{(( , \u03b8\u03b8\u03b8\u03b8 =\u2227\u0398\u2208= xSxGxP NN . (73) \nBy Proposition 4, SBS  is a strategy with respect to \n}0),(:),{(( )(Vroot\nS\nB yxQOIyxP S =\u00d7\u2208= NN . (74) \nBut, by  (63) and  (73), \nPyxyxG\nxSyxQ Vroot\nS\n\u2208\u21d4=\u21d4\n=\u0398\u2208\u2203\u21d4=\n),()(\n),(.0),(\n,\n)(\n\u03b8\n\u03b8\u03b8\u03b8\nN\nN , (75) \nso that PP SB = . \nFrom this, we deduce that \n)(\n,\n,\n0),(\n))(,(\n))(,(),(\nVroot\nS\nB\nyxQ\nPxGx\nPxGxxS\nS\n=\u21d2\n\u2208\u21d2\n\u2208\u21d2=\n\u03b8\n\u03b8\u03b8\u03b8\nN\nN\n. (76) \nHence, by  (37), vvxa 0))(,( =\u03b8\u03c1  for all Vv\u2208 , and so \n),(),( \u03b8\u03b8\u03b8 xSxS SB == . \nIt remains to be shown that ),(),( \u03b8\u03b8 xSxS SB =  when \n\u03b8\u03b8 \u2260),(xS . \nWe first show that ))(,( ,))()(,( xGxa Vrootx \u03b8\u03b8\u03c1 N= . Indeed, \nif, ))(,( ,))()(,( xGxa Vrootx \u03b8\u03b8\u03c1 N\u2260 , then \n)(, 0))(,( Vroot\nS xGxQ =\u03b8N  and hence there exists N\u0398\u2208\u03b8\u02c6  \nsuch that \u03b8\u03b8 \u02c6)\u02c6,( =xS  and )()( ,\u02c6, xGyxG \u03b8\u03b8 NN == . By 2) of \nDefinition 5, \u03b8\u03b8 =),(xS , a contradiction. \nLet ),(:\n0\n\u03b8\u03c1\u03c1 x=  and )(1 VTSvv n \u2208L  and suppose that \nn\nvv n \u03c1\u03c1\u03c1 \u2192\u2192 L\n10\n1 .  We shall argue by induction that \nfor all ni <\u22641  \njji\nvv xS ),()( \u03b8\u03b8\u03c1 = , ij \u2264\u22641  (77) \n)()( \u03b8\u03c1 jji vv aa = , 11 +\u2264< ij  (78) \nFor the base case,  \n111\n1111111\n),()),()),(,((\n),),(,(\n,,\n)()(\nvvv\nvvvvv\nxSxGxGxj\nxaj\n\u03b8\u03b8\n\u03b8\u03b8\u03c3\u03b8\n\u03b8\u03b8\n\u03c1\u03c1\n==\n=\nNN\n (79) \nsince \u03b8\u03b8 \u2260),(xS  and hence \n11\n),( vvxS \u03b8\u03b8 \u2260 , by 1) of \nDefinition 5, while by  (29),  (65) and  (61) \n)(\n)()(),(\n)),()),(,((\n2\n112\n12121\n,,\n,,,)(\n\u03b8\n\u03b8\u03b8\u03b8\n\u03b8\n\u03b8\u03b8\n\u03b8\u03b8\u03c1\nv\nvvv\nvvvv\na\nxGxGa\nxGxGxaa\n=\n=\u2227=\u2032\u2032=\n=\n\u2032 NN\nNN\nwhere (80) \nFinally, suppose that the induction hypothesis holds \nfor nr <\u22641 ; we show that it holds for 1+r . We have, by \n (71) and induction \njjjr\nvvv xS ),()()(\n1\n\u03b8\u03b8\u03b8 \u03c1\u03c1 ==\n+\n if rj \u2264  (81) \nj\njjrr\njjrrrrr\nv\nvvvv\nvvvvv\nxS\nxaj\nxaj\n),(\n),),(),((\n),),(,(\n11\n11111\n)()(\n\u03b8\n\u03b8\u03b8\u03c3\u03b8\n\u03b8\u03b8\u03c3\u03b8 \u03c1\u03c1\n=\n=\n=\n++\n+++++\n (82) \nas \u03b8\u03b8\u03b8\u03c3\u03b8 \u2194\n+\n),),(),((\n1 jjr vvv\nxas , by  (61). Similarly \n)()()(\n1\n\u03b8\u03c1\u03c1 jjjr vvv aaa ==+  if 1+\u2264 rj  (83) \nand by the property of topological sorts kr vv\n\u2022\n+ \u22082  for \nsome 1+\u2264 rk  and so, using induction  (61) and  (66) \n)(\n),),(),((\n),),(,(\n2\n2\n2221\n,\n)(,)(\n\u03b8\n\u03b8\u03b8\u03c3\u03b8\n\u03b8\u03b8\u03c3\u03c1\u03c1\n+\n+\n++++\n=\n=\n=\nr\nkkkrk\njkrkrkrr\nv\nvvvvv\nvvvvvv\na\nxaa\nxaaa\n (84) \ncompleting the proof. \u25a1 \n4.4. Discussion \nThe significance of this result is as follows. If it is \npossible to express precisely the aims of training a multi-\nnet, that is, as an extension to a predicate, then if training is \npossible at all, it may be achieved somehow by the abstract \nscheme we describe. \nHere then, we have described a generic feedforward \nmulti-net system in order to consider how a backward \n14 \n \n \ntraining pass of adjustments can be used to modify the \nparameters of the system corresponding to some \nconvergence predicate.  We have considered, without loss \nof generality, a system in which there are two components \n(the hidden layer and the output layer), with the leaf nodes \nfeeding sequentially the root node.  Because of the \ngenerality of this situation, we could consider a similar \nsystem in which there are two or more leaf nodes feeding \nthe root.  This corresponds to the class of MLPs that consist \nof partial connections between the hidden and output layers.  \nFurthermore, since we have not constrained the operation \nof the root node in terms of how it combines the outputs of \nthe leaves, this may be achieved simply via a weighted \ncombination without activation, or indeed weight \nadjustment during learning.  Such a combination also \ndescribes a simple ensemble.  Further suitable definitions \nof the functions associated with each node can then \ndescribe more complex combination techniques, such as the \nmajority voting scheme, or the competitive combination in \nME.  Indeed, because we have abstracted the parameters \nand functions, we are not constrained in how the networks \nare combined, provided we can describe them using the \nframework. \nA similar exercise of comparing theoretically combined \nsystems was considered by Brown [7] when he proposed \nthe linkage between NC learning [34], Dyn-Co [24] and \nME [27].  Whilst this only considered a related set of \nsystems, the benefit of such an approach is apparent: we \ncan consider a larger class of systems abstractly and \nexplore their properties collectively.  In the first instance \nwe have provided one such analysis by defining an abstract \nsupervised learning algorithm for the generic class of multi-\nnet systems.  By providing the algorithm, we have exploited \nthe mathematical framework to give a constructive proof of \nthe existence of such a convergent scheme. \nWhilst this can help to unify theoretical notions of neural \nsystems, for example our demonstration that there exists a \nsupervised training scheme for this general class of \nfeedforward multi-net systems, we have not made this \nconcrete in any way.  The proof of existence is powerful, \nbut consequently limited.  To be of use, making such an \nalgorithm concrete is essential, but obviously relies upon \nthe ability of defining appropriate functions and parameters, \nsomething which is not trivial in itself. \n5. Conclusion \nIn this paper we have provided a formal framework in \nwhich the general class of multi-net systems can be \ndescribed and rigorously analyzed.  Furthermore, we have \nproven that, given an appropriately constructed partially \nordered set, that there exists a learning algorithm that can \nbe used to train the system to a given criterion, although we \ndo not know what this algorithm might be. \nWe feel that a key contribution of this paper is that it \ntakes a formal, abstract view of the area; abstract in that no \nreference is made in the model to numbers.  By doing this \nwe have made a start at unifying the different types of multi-\nnet system in a way that can be used to infer properties of \nthe whole from the component properties, together with \nother, more specific theories.  Of course, in practical \napplications we need to make this concrete, but we believe \nthat a considerable amount of neural network theory can be \nelucidated in its absence.  Essentially, we are offering a \ndifferent, and we believe novel, perspective on the problem \narea.  This poses an interesting mathematical problem.  \nGiven an abstract multi-net system and criterion, is it \npossible to encode the various parameters and functions so \nthat the latter are computable, that is recursive, and that the \nresulting system is isomorphic (does exactly the same thing \nas the abstract system)?  A positive result would enhance \nthe consequences of Theorem 2. \nThe next stages of this research are to consider what \nimplications this has on existing multi-net architectures, and \nin particular whether this helps us to understand better \nmultiple classifier systems, as well as exploring what \nproperties of individual system components can be used to \ninform us about properties of the system as a whole.  In the \nfirst instance this means looking at the properties of the \ncombined system in order to systematically break them \ndown to their component parts (sub-multi-nets), so that \nthese can then be put back together to infer properties of the \nwhole once again.  This will allow us to consider the \nimpact of each component on the overall system, something \nthat is important in understanding and quantifying the notion \nof diversity in ensemble classifiers, but which requires \nrelating the abstract system to the concrete.  For example, \nby being able to relate component performance to system \nperformance, it may be possible to determine the maximum \ncapability of a given system and compare that with other \nconfigurations. \nAcknowledgments \nWe would like to thank David Pitt for suggesting that we \nshould work together, marrying theoretical computer \nscience to multi-net systems \u2013 not as far apart as we first \nthought.  We would also like to thank Gavin Brown for \nproviding comments on an early draft of the paper, and the \ntwo anonymous reviewers for their comments and helpful \nsuggestions. \nReferences \n[1] S.Abramsky, D.M.Gabbay and T.S.E.Maibaum, Handbook of Logic in \nComputer Science, Volume 1. Background: Mathematical Structures \n(Clarendon Press, Oxford, UK, 1992). \n[2] S.-I.Amari, Information Geometry of the EM and em Algorithms for \nNeural Networks, Neural Networks 8 (9) (1995) 1379-1408. \n[3] J.L.Armony, D.Servan-Schreiber, J.D.Cohen and J.E.LeDoux, \nComputational Modeling of Emotion: Explorations Through the Anatomy \nand Physiology of Fear Conditioning, Trends in Cognitive Sciences 1 (1) \n(1997) 28-34. \n[4] C.M.Bishop, Neural Networks for Pattern Recognition (Clarendon \nPress, Oxford, UK, 1995). \n15 \n \n \n[5] L.Bottou and P.Gallinari, A Framework for the Cooperation of Learning \nAlgorithms, in: R.P.Lippmann, J.E.Moody, and D.S.Touretzky, ed., \nAdvances in Neural Information Processing Systems (1991) 781-788. \n[6] L.Breiman, Bagging Predictors, Machine Learning 24 (2) (1996) 123-\n140. \n[7] G.Brown, Diversity in Neural Network Ensembles, Unpublished doctoral \nthesis, University of Birmingham, Birmingham, UK, 2004. \n[8] G.Brown, J.L.Wyatt, R.Harris and X.Yao, Diversity Creation Methods: \nA Survey and Categorisation, Information Fusion 6 (1) (2005) 5-20. \n[9] G.Brown, J.L.Wyatt and P.Tino, Managing Diversity in Regression \nEnsembles, Journal of Machine Learning Research 6 (2005) 1621-1650. \n[10] J.L.Buessler, J.P.Urban and J.Gresser, Additive Composition of \nSupervised Self-organizing Maps, Neural Processing Letters 15 (1) \n(2002) 9-20. \n[11] S.Cameron, S.Grossberg and F.H.Guenther, A Self-organizing Neural \nNetwork Architecture for Navigation Using Optic Flow, Neural \nComputation 10 (2) (1998) 313-352. \n[12] M.C.Casey, Integrated Learning in Multi-net Systems, Unpublished \ndoctoral thesis, University of Surrey, Guildford, UK, 2004. \n[13] M.C.Casey and K.Ahmad, In-situ Learning in Multi-net Systems, in: \nZ.R.Yang, R.Everson, and H.Yin, ed., Proceedings of the 5th \nInternational Conference on Intelligent Data Engineering and Automated \nLearning (IDEAL 2004), Lecture Notes in Computer Science 3177 \n(Springer-Verlag, Heidelberg, 2004) 752-757. \n[14] M.C.Casey and K.Ahmad, A Competitive Neural Model of Small \nNumber Detection, Neural Networks 19 (10) (2006) 1475-1489. \n[15] M.N.Dailey and G.W.Cottrell, Organization of Face and Object \nRecognition in Modular Neural Network Models, Neural Networks 12 \n(7-8) (1999) 1053-1073. \n[16] B.A.Davey and H.A.Priestley, Introduction to Lattices and Order \n(Cambridge University Press, Cambridge, UK, 1990). \n[17] S.Dehaene and J.P.Changeux, Development of Elementary Numerical \nAbilities: A Neuronal Model, Journal of Cognitive Neuroscience 5 (4) \n(1993) 390-407. \n[18] Y.Freund and R.E.Schapire, Experiments with a New Boosting \nAlgorithm, in: Machine Learning: Proceedings of the 13th International \nConference (Morgan Kaufmann, 1996) 148-156. \n[19] G.Fumera and F.Roli, A Theoretical and Experimental Analysis of Linear \nCombiners for Multiple Classifier Systems, IEEE Transations on Pattern \nAnalysis and Machine Intelligence 27 (6) (2005) 942-956. \n[20] M.S.Gazzaniga, Organization of the Human Brain, Science 245 (1989) \n947-952. \n[21] G.Giacinto and F.Roli, Dynamic Classifier Selection Based on Multiple \nClassifier Behaviour, Pattern Recognition 34 (9) (2001) 1879-1881. \n[22] G.Giacinto and F.Roli, A Theoretical Framework for Dynamic Classifier \nSelection, in: Proceedings of the 15th International Conference on \nPattern Recognition (2000) 8-11. \n[23] S.Grossberg and D.V.Repin, A Neural Model of How the Brain \nRepresents and Compares Multi-digit Numbers: Spatial and Categorical \nProcesses, Neural Networks 16 (8) (2003) 1107-1140. \n[24] J.V.Hansen, Combining Predictors: Meta Machine Learning Methods \nand Bias\/Variance & Ambiguity Decompositions, University of Aarhus, \nAarhus, Denmark, 2000. \n[25] D.O.Hebb, The Organization of Behavior: A Neuropsychological Theory \n(John Wiley & Sons, New York, 1949). \n[26] R.A.Jacobs, M.I.Jordan and A.G.Barto, Task Decomposition through \nCompetition in a Modular Connectionist Architecture: The What and \nWhere Vision Tasks, Cognitive Science 15 (1991) 219-250. \n[27] R.A.Jacobs, M.I.Jordan, S.J.Nowlan and G.E.Hinton, Adaptive \nMixtures of Local Experts, Neural Computation 3 (1) (1991) 79-87. \n[28] M.I.Jordan and R.A.Jacobs, Hierarchical Mixtures of Experts and the \nEM Algorithm, Neural Computation 6 (2) (1994) 181-214. \n[29] M.I.Jordan and L.Xu, Convergence Results for the EM Approach to \nMixtures of Experts Architectures, Neural Networks 8 (1995) 1409-\n1431. \n[30] R.M.Keller, Formal Verification of Parallel Programs, Communications \nof the ACM 19 (7) (1976) 371-384. \n[31] J.Kittler, M.Hatef, R.P.W.Duin and J.Matas, On Combining Classifiers, \nIEEE Transactions on Pattern Analysis and Machine Intelligence 20 (3) \n(1998) 226-239. \n[32] A.Krogh and J.Vedelsby, Neural Network Ensembles, Cross Validation, \nand Active Learning, in: G.Tesauro, D.S.Touretzky, and T.K.Leen, ed., \nAdvances in Neural Information Processing Systems (1995) 231-238. \n[33] L.I.Kuncheva and C.J.Whitaker, Measures of Diversity in Classifier \nEnsembles, Machine Learning 51 (2) (2003) 181-207. \n[34] Y.Liu and X.Yao, Ensemble Learning via Negative Correlation, Neural \nNetworks 12 (10) (1999) 1399-1404. \n[35] B.Lu and M.Ito, Task Decomposition and Module Combination Based \non Class Relations: A Modular Neural Network for Pattern \nClassification, IEEE Transactions on Neural Networks 10 (5) (1999) \n1244-1256. \n[36] J.Ma, L.Xu and M.I.Jordan, Asymptotic Convergence Rate of the EM \nAlgorithm for Gaussian Mixtures, Neural Computation 12 (12) (2000) \n2881-2908. \n[37] R.Milner, A Calculus of Communicating Systems, Lecture Notes in \nComputer Science 92 (Springer-Verlag, Heidelberg, 1980). \n[38] D.Partridge and N.Griffith, Multiple Classifier Systems: Software \nEngineered, Automatically Modular Leading to a Taxonomic Overview, \nPattern Analysis and Applications 5 (2) (2002) 180-188. \n[39] M.P.Perrone, Improving Regression Estimation: Averaging Methods for \nVariance Reduction with Extensions to  General Convex Measure \nOptimization, Unpublished doctoral thesis, Brown University, \nProvidence, RI, 1993. \n[40] D.E.Rumelhart, G.E.Hinton and R.J.Williams, Learning Internal \nRepresentations by Error Propagation, in: D.E.Rumelhart and \nJ.L.McClelland, ed., Parallel Distributed Processing: Explorations in the \nMicrostructure of Cognition, Volume 1: Foundations (MIT Press, \nCambridge, MA., 1986) 318-362. \n[41] D.E.Rumelhart and D.Zipser, Feature Discovery by Competitive \nLearning, in: D.E.Rumelhart and J.L.McClelland, ed., Parallel Distributed \nProcessing: Explorations in the Microstructure of Cognition, Volume 1: \nFoundations (MIT Press, Cambridge, MA., 1986) 151-193. \n[42] A.J.C.Sharkey, Types of Multinet System, in: F.Roli and J.Kittler, ed., \nProceedings of the Third International Workshop on Multiple Classifier \nSystems (MCS 2002) (Springer-Verlag, Berlin, Heidelberg, New York, \n2002) 108-117. \n[43] A.J.C.Sharkey, Multi-Net Systems, in: A.J.C.Sharkey, ed., Combining \nArtificial Neural Nets: Ensemble and Modular Multi-Net Systems \n(Springer-Verlag, London, 1999) 1-30. \n[44] K.Tumer and J.Ghosh, Analysis of Decision Boundaries in Linearly \nCombined Neural Classifiers, Pattern Recognition 29 (2) (1996) 341-\n348. \n[45] N.Ueda and R.Nakano, Generalization Error of Ensemble Estimators, in: \nProceedings of the IEEE International Conference on Neural Networks \n(1996) 90-95. \n[46] N.M.Wanas, L.Hodge and M.S.Kamel, Adaptive Training Algorithm for \nan Ensemble of Networks, in: Proceedings of the 2001 International Joint \nConference on Neural Networks (IJCNN'01) (IEEE Computer Society \nPress, Los Alamitos, CA., 2001) 2590-2595. \n[47] L.Xu and M.I.Jordan, On Convergence Properties of the EM Algorithm \nfor Gaussian Mixtures, Neural Computation 8 (1) (1996) 129-151. \n \n \n16 \n \n \nFigure Captions \nFig. 1.  a) an ensemble system where the output of three \ncomponents (u, v, and w) are combined, say, using a \nweighted average; b) the Hasse diagram for the equivalent \nsystem ( ensV ), with the addition of a root node (t) in place \nof the weighted summation; c) a HME system consisting of \ntwo levels of experts (u, x, y), combined by two gating \nnetworks (w, z); d) the Hasse diagram for the equivalent \nsystem ( hmeV ), with the addition of two nodes (t, v) in \nplace of the combinations. \nFig. 2.  a) an arbitrary two layer MLP; b) the same MLP \ndepicted with each layer as a node; c) the Hasse diagram \nfor the equivalent system ( mlpV ). \n \n  \n \n  \nt \nu v w \nb) \nd) \na) c) \nt \nu v w \nx y z \nu \nw \nx y \nz \n\u2211  \n\u2211  \nv u w \n\u2211  \n \nFig. 1. \nFigure\n  \na) \nb) \nc) \nt \nu \nt \nu \nt1 t2 tm \nun u2 u1 \n \nFig. 2. \n  \n \nFigure\nBiosketches \n \nMike Shields received his BA in 1971 from Warwick in \npure mathematics and his PhD from Leeds in 1975 in \ncomputer science.  From 1990 to 2005 he worked as a \nlecturer, later reader in the Department of Computing at the \nUniversity of Surrey, becoming a visiting reader in 2006.  \nHis research interests are in theoretical computer science, \nparticularly concurrency and formal semantics. \n \n \n \nMatthew Casey received his BSc in Mathematics and \nComputer Science from the University of Kent in 1992.  He \nthen spent 10 years in industry, working for Data Sciences, \nIBM and Anite Telecoms before studying part-time for his \nPhD from the University of Surrey, awarded in 2004.  In \n2002 he was appointed a lecturer in the Department of \nComputing.  His research interests are in the theory and \napplication of multiple neural networks, especially for \ncomputational neuroscience in modelling vision and \nmultisensory processing. \n \n \nBiography of the author(s)\nClick here to download Biography of the author(s): 09-07-02 Shields Casey Biosketches.doc\nPhotographs \n \n \n \n \nMike Shields \n \n \n \n \n \n \n \n \nMatthew Casey \n* Photo of the author(s)\nClick here to download Photo of the author(s): 09-07-02 Shields Casey Photographs.doc\n"}
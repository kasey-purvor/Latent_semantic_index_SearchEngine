{"doi":"10.1080\/09500690600909091","coreId":"65751","oai":"oai:dro.dur.ac.uk.OAI2:4908","identifiers":["oai:dro.dur.ac.uk.OAI2:4908","10.1080\/09500690600909091"],"title":"Developing attitudes towards science measures.","authors":["Kind,  P. M.","Jones,  K.","Barmby,  P."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-06-01","abstract":"In this study, we describe the development of measures used to examine pupils' attitudes towards science. In particular, separate measures for attitudes towards the following areas were developed: learning science in school, practical work in science, science outside of school, importance of science, self-concept in science, and future participation in science. In developing these measures, criticisms of previous attitude studies in science education were noted. In particular, care was taken over the definition of each of the attitude constructs, and also ensuring that each of the constructs was unidimensional. Following an initial piloting process, pupils aged 11-14 from five secondary schools throughout England completed questionnaires containing the attitude measures. These questionnaires were completed twice by pupils in these schools, with a gap of four weeks between the first and second measurements. Altogether, 932 pupils completed the first questionnaire and 668 pupils completed the second one. Factor analysis carried out on the resulting data confirmed the unidimensionality of the separate attitude constructs. Also, it was found that three of the constructs - learning science in school, science outside of school, and future participation in science - loaded on one general attitude towards science factor. Further analysis showed that all the measures showed high internal reliability (Cronbach's a > 0.7). A particular strength of the approach used in this study was that it allowed for attitude measures to be built up step-by-step, therefore allowing for the future consideration of other relevant constructs","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65751.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/4908\/1\/4908.pdf","pdfHashValue":"e54af7270ab4f5ccf5eb6b8426a31ee33eb54d46","publisher":"Routledge","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:4908<\/identifier><datestamp>\n      2016-07-06T10:48:35Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Developing attitudes towards science measures.<\/dc:title><dc:creator>\n        Kind,  P. M.<\/dc:creator><dc:creator>\n        Jones,  K.<\/dc:creator><dc:creator>\n        Barmby,  P.<\/dc:creator><dc:description>\n        In this study, we describe the development of measures used to examine pupils' attitudes towards science. In particular, separate measures for attitudes towards the following areas were developed: learning science in school, practical work in science, science outside of school, importance of science, self-concept in science, and future participation in science. In developing these measures, criticisms of previous attitude studies in science education were noted. In particular, care was taken over the definition of each of the attitude constructs, and also ensuring that each of the constructs was unidimensional. Following an initial piloting process, pupils aged 11-14 from five secondary schools throughout England completed questionnaires containing the attitude measures. These questionnaires were completed twice by pupils in these schools, with a gap of four weeks between the first and second measurements. Altogether, 932 pupils completed the first questionnaire and 668 pupils completed the second one. Factor analysis carried out on the resulting data confirmed the unidimensionality of the separate attitude constructs. Also, it was found that three of the constructs - learning science in school, science outside of school, and future participation in science - loaded on one general attitude towards science factor. Further analysis showed that all the measures showed high internal reliability (Cronbach's a > 0.7). A particular strength of the approach used in this study was that it allowed for attitude measures to be built up step-by-step, therefore allowing for the future consideration of other relevant constructs.<\/dc:description><dc:publisher>\n        Routledge<\/dc:publisher><dc:source>\n        International journal of science education, 2007, Vol.29(7), pp.871-893 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2007-06-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:4908<\/dc:identifier><dc:identifier>\n        issn:0950-0693<\/dc:identifier><dc:identifier>\n        issn: 1464-5289<\/dc:identifier><dc:identifier>\n        doi:10.1080\/09500690600909091<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/4908\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1080\/09500690600909091<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/4908\/1\/4908.pdf<\/dc:identifier><dc:rights>\n        This is an Accepted Manuscript of an article published by Taylor & Francis Group in International Journal of Science Education on 11\/05\/2007, available online at: http:\/\/www.tandfonline.com\/10.1080\/09500690600909091.<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0950-0693","0950-0693"," 1464-5289","issn: 1464-5289"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2007,"topics":[],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n04 February 2009\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nKind, P. M. and Jones, K. and Barmby, P. (2007) \u2019Developing attitudes towards science measures.\u2019,\nInternational journal of science education., 29 (7). pp. 871-893.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1080\/09500690600909091\nPublisher\u2019s copyright statement:\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n Use policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without \nprior permission or charge, for personal research or study, educational, or not-for-profit purposes \nprovided that : \n \n\u0083 a full bibliographic reference is made to the original source \n\u0083 a link is made to the metadata record in DRO \n\u0083 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright \nholders.  \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nDurham Research Online \n Deposited in DRO:\n04 February 2009\nVersion of attached file:\nAccepted\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nKind, P. M. and Jones, K. and Barmby, P. (2007) 'Developing attitudes towards science measures.', International\njournal of science education., 29 (7), pp.\u0000871-893.\nFurther information on publishers website:\nhttp:\/\/dx.doi.org\/10.1080\/09500690600909091\nDeveloping attitudes towards science measures  \n \nPer Kind, Karen Jones and Partick Barmby* \nDurham University, UK \n \n*Corresponding author. CEM Centre, Durham University, Mountjoy Research \nCentre, 4 Stockton Road, Durham DH1 3UZ, UK. Email: \npatrick.barmby@cem.dur.ac.uk \n \nAbstract \n \nIn this study, we describe the development of measures used to examine pupils\u2019 \nattitudes towards science. In particular, separate measures for attitudes towards the \nfollowing areas were developed: learning science in school, practical work in science, \nscience outside of school, importance of science, self-concept in science and future \nparticipation in science. In developing these measures, criticisms of previous attitude \nstudies in science education were noted. In particular, care was taken over the \ndefinition of each of the attitude constructs, and also ensuring that each of the \nconstructs was unidimensional. Following an initial piloting process, pupils aged 11 \nto 14 from five secondary schools throughout England completed questionnaires \ncontaining the attitude measures. These questionnaires were completed twice by \npupils in these schools, with a gap of four weeks between the first and second \nmeasurements. Altogether, 932 pupils completed the first questionnaire and 668 \npupils completed the second one. Factor analysis carried out on the resulting data \nconfirmed the unidimensionality of the separate attitude constructs. Also, it was found \nthat three of the constructs, learning science in school, science outside of school and \nfuture participation in science, loaded on one general attitude towards science factor. \nFurther analysis showed that all the measures showed high internal reliability \n(Cronbach \u03b1 > 0.7). A particular strength of the approach used in this study was that it \nallowed for attitude measures to be built up step-by-step, therefore allowing for the \nfuture consideration of other relevant constructs. \n \nIntroduction  \n \nOsborne et al. (2003) characterised students\u2019 attitudes towards studying science as an \n\u2018urgent agenda for research\u2019. The main problem is a well-documented gap between \nneeds and reality for the discipline of science. The needs relate to society having a \ngreater requirement than ever for highly educated people in science to meet economic, \nenvironmental and technological challenges. The reality is a falling number of \nstudents choosing to pursue the study of science. This problem is a worry for \ngovernments all over the world and questions have been raised about what can be \ndone to increase students\u2019 interest in science (for example, the consideration of the \nsituation for physics in the European Union, Coughlan, 2000). Another problem, \nwhich is perhaps more relevant for science teachers on an everyday basis, is the \nrelationship between attitudes and learning (Schibeci, 1984). Learning clearly has an \naffective component and developing positive attitudes is important for students\u2019 \nachievement.  \n \nWorking with these problems requires a wide range of research. The contribution \nfrom the present study is the development of an instrument for measuring students\u2019 \n 1\nattitudes towards science. Several such instruments exist already (see for example the \nreferences given in the discussion), but with two serious constraints. First of all, as \nOsborne et al. (2003) have pointed out, the concept of attitudes is often poorly \narticulated and not well understood. Secondly, as has been a main concern for Munby \n(1982, 1997) and Gardner (1975, 1995, and 1996), attitude measures often have poor \npsychometric quality. The problem, it seems, results from a tradition for measuring \nthat is rather \u2018pragmatic\u2019, not taking into account the difficulty of understanding a \ncomplicated psychological construct. Science educators often develop measures for a \ndifferent purpose than for exploring the constructs themselves, and validation of the \ntest often becomes a subordinate matter. We discuss each of these problems in more \ndetail below. \n \n \nDefining attitudes towards science \n \nA problem that has been raised by those studying attitudes towards science (e.g. \nGermann, 1988; Francis & Greer, 1999; Osborne et al., 2003) is the definition of \nattitude itself. There seems to be many concepts that relate to attitudes that may or \nmay not be included in their definition; e.g. feelings, motivation, enjoyment, affects, \nself-esteem etc. A common definition has involved describing attitudes as including \nthe three components of cognition, affect and behaviour (e.g. Rajecki, 1990; Bagozzi \n& Burnkrant, 1979; McGuire, 1985). Reid (2006) provides a clear definition of these \ncomponents: \n \n\u2018(1) a knowledge about the object, the beliefs, ideas component (Cognitive); \n(2) a feeling about the object, like or dislike component (Affective); and \n(3) a tendency-towards-action, the objective component (Behavioural).\u2019 \n \nIn many ways, this seems a sensible view of attitudes because these components are \nso closely linked together. For example, we know about science and therefore have a \nfeeling or an opinion about it that may cause us to take some actions.  \n \nOther researchers have suggested that the three components should be treated more \nindependently, and that attitudes should be viewed in a narrower way, as the basis for \n\u2018evaluative judgements\u2019 (Ajzen, 2001; Crano & Prislin, 2006). When we have an \nattitude, we judge something along emotional dimensions, such as good or bad, \nharmful or beneficial, pleasant or unpleasant, important or unimportant. It is important \nto notice that these evaluative judgements are always towards something, often called \nthe attitude object (Crano & Prislin, 2006).  \n \nThis narrower conceptualisation can be used to clarify the definition of attitude. For \nexample, asking about someone\u2019s attitude towards an object is, in principle, to ask \nhow they judge the object. This definition makes clear that we are looking for \nsomething different from general affects, such as moods (e.g. being sad or happy) and \nemotions (e.g. fear and anger) (Ajzen, 2001). It also makes clear the distinction \nbetween attitude and behaviour. It is perhaps more difficult to separate the other \naffective and cognitive concepts. Although some researchers have defined attitude \nsolely in terms the affective component (Germann, 1988; George, 2000), Fishbein & \nAjzen (1975) viewed attitudes as being formed spontaneously and inevitably as \nindividuals form beliefs about the attributes of an object. Attitudes, or the affective \n 2\ncomponent of attitudes, are therefore linked to these beliefs that a person holds. \nTherefore, the definition for attitude that we use for this study is that it is the feelings \nthat a person has about an object, based on their beliefs about that object. \n \nFollowing this definition of attitudes, we can view an attitude towards science \nmeasure as a way of mapping students\u2019 cognitive and emotional opinions about \nvarious aspects of science. A necessary starting point is then to identify what objects \nwe are focusing on. Commonly, distinctions are made between science at school, \n\u2018real\u2019 science and science in society. Each of these may be split into more detailed \nobjects, which again may be characterised with a range of attributes. For example, \nschool science includes sub-objects such as the science teacher, the science classroom \nand the science content. Each of these objects has attributes that may be judged along \nvarious dimensions. The science teacher, for example, may be characterised by ways \nof teaching or ways of relating to children and these may be something the students \nthink of as good or bad, pleasant or unpleasant, interesting or uninteresting. Attitude \ntheory (Ajzen 2001; Crano & Prislin, 2006) claims that attitudes about an object may \nbe added up, based on attitudes towards the various attributes. In measuring attitudes \ntherefore, we need to decide on what \u2018level\u2019 we are operating at. Is it meaningful for \nus to make one attitude scale towards science, or should this be broken down to \nseveral sub-scales? An answer to this must be based not only on our own \nunderstanding and conceptualisation of science, but also on pupil data, i.e. how the \nconcepts associated with attitudes towards science are organised in the pupils\u2019 mind.  \n \n \nAttitude measures and their problems \n \nTypes of attitude measures  \n \nOsborne et al. (2003) and Gardner (1975) reviewed the numerous approaches to the \nmeasurement of attitudes, listing the following five main methods: \n \nPreference ranking: This is an easy-to-use method where students simply rank their \nliking of school subjects. It is effective for answering the question \u2018How popular is \nscience compared to other subjects?\u2019, but as it is a relative scale, is unsuitable for \nmeasuring attitude change. \n \nAttitude scales: This is probably the most common method of measuring attitudes and \noccurs in a variety of forms. Differential (Thurstone-type) scales involve students \nchoosing statements on a continuum that best reflect their attitudes. Semantic \ndifferential scales require students to rate a particular object (e.g. science lessons) \naccording to a number of bipolar adjectives (e.g. good\/bad, interesting\/dull). More \ncommonly, summated rating scales are used which consist of Likert scale items. \nStudents respond to a number of statements that relate to the same construct (usually \nchoosing from a five-point score such as \u2018strongly agree, agree, neither agree nor \ndisagree, disagree, strongly disagree). The use of more than one response for the same \nconstruct greatly increases the reliability of the summated rating scores. However, \nthere are many potential weaknesses with attitude scales which are discussed later on \nin this paper. \n \n 3\nInterest inventories: This method requires students to choose the items that they are \ninterested in from a list. Osborne et al. (2003) commented that \u2018such inventories are \ngenerally restricted to their specific focus, yielding only a limited view of what may \nor may not be formative on attitudes to science.\u2019 \n \nSubject enrolment: This method involves the collection of data on enrolment in \nvarious subjects. Both Osborne et al. (2003) and Gardner (1975) comment on the \nlimitations of this method as a measure of interest in science, as subject choice can be \ninfluenced by a number of other factors including gender identity and economic \nfactors. \n \nQualitative methods: Although limited in number, a few studies explore attitudes \nusing student interviews and focus group interviews. What these methods lack in the \nability to generalise the findings, they make up for in the richness of understanding \nthat they offer. \n \nIn the present study, we developed and used attitude scales to measure pupils\u2019 \nattitudes towards science. As mentioned above, a major justification for using an \nattitude scale is the use of more than one question to measure the same construct to \ngreatly increase reliability (Gardner, 1996). In addition, such scales are relatively \nsimple to use, in terms of using them in questionnaires and distributing them to \nrespondents. Many attitude scales have been used in the past for research on science \neducation, and we discuss at the end of the paper whether some of these existing \nmeasures would have been suitable for our use. \n \n \nAttitude scales in science education: a critique \n \nAlthough there are advantages to using attitude scales to examine attitudes towards \nscience, various studies have identified problems and weaknesses with many existing \nattitude measurements (for example Germann, 1988; Gardner, 1996; Munby, 1997; \nFrancis & Greer, 1999; Bennett, 2001; Osborne et al., 2003; Reid, 2006). Firstly, \nthere has been a lack of clarity over the last thirty years about what is actually being \nmeasured when we measure attitude towards science (Osborne et al., 2003). As \ndiscussed in the previous section, there is lack of clarity over the term attitude. The \nterm science is a little less problematic but there is still a need to define whether we \nare looking at, for example, students\u2019 attitudes towards science in schools, students\u2019 \nattitudes towards science outside of school or students\u2019 attitudes towards scientists, all \nof which may vary considerably (Ramsden, 1998).  \n \nThe lack of clarity and definition of what is being measured is therefore likely to lead \nto problems. When there is no clear definition of the underlying construct that is being \nmeasured, it is likely that disparate items may be put together in the attitude scale. \nThey may display a common theme (e.g. attitudes towards science) but not a common \nconstruct (e.g. someone\u2019s attitude towards science in school may be very different to \ntheir attitude towards scientists outside school; Gardner, 1996). It would therefore be \nincorrect to include items from different constructs in the same scale, however \nGardner (1996) cites cases where this has indeed been done. Similarly, Gardner also \ncites cases where researchers have clearly defined individual constructs but have \nadded the scores from the individual constructs together, \u2018breaking a fundamental \n 4\nprinciple of psychometrics \u2026 people with the same score on a scale ought to be \npsychologically similar to each other\u2019 (Gardner, 1996). A neutral score from two \ncombined constructs could be produced from a positive score on one and a negative \nscore on the other or a neutral score on both. The lack of clarity and definition of \nconstructs may also lead to a lack of consistency between the many instruments that \nexist to measure attitudes towards science, making comparison between studies \nimpossible (Germann, 1988; Bennett, 2001).  \n \nA related criticism that is highlighted in the literature (Gardner, 1975 and 1995; \nMunby, 1983; Schibeci, 1984; Osborne et al., 2003; Bennett, 2001; Germann, 1988) \nis that attitude measures can in fact be of poor psychometric quality. In order to \ndemonstrate this quality, an instrument needs to be statistically internally consistent \nand unidimensional. Many studies fail to provide evidence of these psychometric \ntraits or wrongly assume that internal consistency implies unidimensionality (Gardner, \n1995). Cronbach \u03b1 is commonly used as a measure of internal consistency. By \ndefinition the items in a unidimensional scale all measure the same construct so it \nfollows that they will be internally consistent. However, it does not follow that \ninternally consistent scales are unidimensional, as they may consist of more than one \nfactor. It is therefore important to use a technique such as factor analysis to confirm \nthe unidimensionality of a scale. \n \nFailure to properly address construct validity (the extent to which a scale represents \nwhat it claims to represent) is also a threat to good psychometric quality and there is a \ndanger of ignoring validity in light of support from high consistency or reliability. \nThere are no set techniques to follow in order to demonstrate validity, but rather it is a \ncase of amassing evidence from a selection of available techniques (Henerson et al., \n1987 and Munby, 1997). Munby (1997) takes this further by stressing the importance \nof including psychometric evidence of validity in addition to non-psychometric \nevidence. There appears to be some lack of consensus over the ways in which we \nmight demonstrate good validity. A common method employed is the panel method, \nwhere a panel of judges judge the validity of each item. Munby (1983 and 1997), \nhowever questions the assumption held in this technique that the meaning of the items \nfor the judges is the same as it is for the respondents. Osbourne et al (2003), \nOppenheim (1992) and Bennett (2001) suggest that validity can be obtained by \nderiving items from students\u2019 answers to free response questions. Validity can also be \ndemonstrated by asking staff who know the students and\/or the students themselves to \ncomment on the results of an attitudinal scale, to see if they match their own opinions \n(Bennett, 2001). An alternative method is to seek construct validity through \ntheoretical foundation, i.e. to use relevant theory as a base for developing and \nevaluating the test. \n \nPsychometric approaches to validity include the calculation of correlation coefficients \nin order to demonstrate convergent and divergent validity (i.e. theoretically similar \nitems should converge and theoretically dissimilar constructs and items should be \ndiscriminating) (Henerson, 1987; Trochim, 2002). Similarly Munby (1997) suggests \nusing factor analysis to show that conceptually formed scales do in fact match with \nempirically produced factors and that when a scale has been used in more than one \nstudy, a repeated factor analysis on the new data can be used to confirm validity. \nConcurrent validity can be demonstrated by confirming whether the results of the \nscale in question correlate with a well established scale that claims to represent the \n 5\nsame construct (Henerson, 1987), also giving additional evidence of construct \nvalidity. If it is important that a scale predicts future behaviour, then it is also \nimportant to demonstrate predictive validity by demonstrating that a scale that claims \nto predict a particular behaviour does in fact do that (for example does a scale that \nclaims to measure future participation in science actually correlate with reality in the \nfuture?). \n \nTherefore, from the above critique, we can put forward the following guidelines on \nhow best to formulate an attitude measure: \n \n\u2022 Clear descriptions need to be put forward for the constructs that one wishes to \nmeasure. \n\u2022 Care needs to be taken when separate constructs are combined to form one \nscale, with justification that these constructs are closely related. \n\u2022 Reliability of the measure needs to be demonstrated by confirming the internal \nconsistency of the construct (e.g. by use of Cronbach alpha) and by confirming \nunidimensionality (e.g. by using factor analysis). \n\u2022 Validity needs to be demonstrated by the use of more than one method, \nincluding the use of psychometric techniques. \n \nWe will refer to these guidelines as we describe the development of attitudes to \nscience measures that we carried out in this study. \n \n \nDeveloping attitudes to science measures \n \nThe attitudes to science measures described in this paper were developed for a study \ncarried out on behalf of the Institute of Physics in the UK. This study involved \nevaluating the impact of \u2018Lab in a Lorry\u2019, a mobile laboratory that visited schools and \nused to demonstrate a series of experiments to pupils aged 11 to 14. The aim of this \ninitiative was to encourage future participation of pupils in the sciences1.  \n \nAs part of this study, the following areas of attitudes to science were focussed upon as \nbeing important: Learning science in school, Practical work in science, Science \noutside of school, Importance of science, Self-concept in science, and Future \nparticipation in science.  In addition, attitude to school generally was included, in \norder to find out how variations in the above science-related attitudes were related to \nthis more general attitude. All the attitude areas listed, with the exceptions of attitude \ntowards school, were chosen as areas that could possibly be affected by an initiative \nsuch as Lab in a Lorry. As a result, other possible influences on attitude to science \nwere not included as part of this study, for example the influence of teachers as \nhighlighted by Osborne et al. (2003).  \n \nAt this point, as suggested by the above guidelines, let us be more specific about what \nwe meant by the above constructs. The first three constructs aimed to examine pupils\u2019 \nattitudes towards science learning activities in different contexts (in the classroom, \nmore specifically in practicals, and outside the classroom). It was believed that each \nof these contexts represented meaningful \u2018objects\u2019 that students were likely to have \n                                                 \n1 Further information of Lab in a Lorry can be obtained from the website www.labinalorry.org.uk \n 6\nformed beliefs about. The next construct aimed to examine pupils\u2019 belief in the value \nof science in a wider social context. The last two constructs differed somewhat from \nthe others in that the pupil themselves were part of the attitude-object. Self-concept is \nbased on beliefs about one\u2019s own ability to master school science, which in turn is \nbelieved to form attitudes towards the subject. Future participation is similarly \nregarded as the students\u2019 attitude towards engaging more with science in the future.  \n \nHaving defined the areas of attitude to science to be included in our study, the next \nstep was to put together suitable measures for the above constructs. We adopted a \nLikert scale format, with each measure being made up of a series of statements \nrelating to the above constructs. Respondents would be asked to state their level of \nagreement to the statements by choosing one response from a number of alternatives. \nAt the pilot stage of the development of the attitude measures, a choice from the \nfollowing four responses was given for each statement: \u2018Strongly agree\u2019, \u2018Agree\u2019, \n\u2018Disagree\u2019 and \u2018Strongly disagree\u2019. For the actual statements making up each \nmeasure, they were made to capture various attributes of the attitude object and \nexpress different evaluative dimensions. Having a limited set of meaningful (to the \npupils) statements was regarded as crucial. Some statements were therefore adopted \nfrom existing questionnaires which have been proven to work with pupils. These \nincluded some items from the Relevance of Science Education (ROSE) questionnaire, \nthe 2003 PISA questionnaire and items from the attitude to science for 5 to 11 year \nolds, developed by Pell & Jarvis (2001). All statements were assessed by use of \ncriteria suggested by Crocker & Algina (1986). \n \n \nFollowing this formulation of the items for the attitude measures, we needed to pilot \nthe attitude measures to check (i) the internal statistical reliability of the different \nmeasures, and (ii) use factor analysis to check whether the measures themselves \nwould in fact be unidimensional, that the items that we had put together would \nactually measure the same thing. Therefore, the constructed measures were put \ntogether into a paper questionnaire, which in turn was given out to 44 Year 8 and Year \n9 pupils (12 to 14 year olds) from the same secondary school in the North East of \nEngland. Using the statistical package SPSS to carry out reliability calculations and \nfactor analysis on the data collected, items that reduced the internal reliability of \nattitude measures or did not group together with other items were identified. These \nitems were either removed from the measures, or their wording was modified. In \naddition, it was found during this trial that pupils sometimes tried to provide an \nanswer between \u2018Agree\u2019 and \u2018Disagree\u2019 (e.g. ticking both responses, or placing a tick \nbetween the two responses). Therefore, following this trial, the possible responses \nwere extended to a five-point scale, including \u2018Neither agree nor disagree\u2019 as the \nmiddle response. \n \n \nAnalysing the results from the attitude to science measures \n \nIn describing the trialling of the attitude measures in the previous section, we did not \nprovide any details of the results of the reliability calculations and the factor analysis. \nRather we will establish the reliability and unidimensionality of the measures in the \ncontext of the larger study that was carried out following this initial trial. \n \n 7\nThis larger study was part of the evaluation of Lab in a Lorry, described in the \nprevious section. This involved measuring the attitudes of Year 7, Year 8 and Year 92 \npupils in five different secondary schools, prior to the visit of Lab in a Lorry to their \nschool. Three of these schools were located in the North East of England (but \ndifferent to the school used in the trialling of the measures), one school located in the \nSouth West of England and one school in the South East.  \n \nA paper questionnaire with the attitudes to science measures, modified as a result of \nthe trial, was given out to pupils in these schools. This questionnaire was given out \ntwice to pupils, two weeks before the visit of Lab in a Lorry, and two weeks after. \nTeachers were asked to give out questionnaires to both pupils who would visit the \nlorry, and to those that would not. Therefore, pre- and post-measures of attitudes to \nscience for two groups of pupils were obtained. Altogether, 932 pupils completed the \nquestionnaire for the pre-measure, and 668 pupils completed it for the post-measure.  \n \nPrior to the analysis of the attitude data, all the responses were coded numerically. \nInitially, the responses were coded as \u2018Strongly agree\u2019 = 5, \u2018Agree\u2019 = 4, \u2018Neither \nagree nor disagree\u2019 = 3, \u2018Disagree\u2019 = 2 and \u2018Strongly disagree\u2019 = 1. Subsequently, \nprior to the reliability analysis of the data, the responses were reverse coded for \nnegatively phrased items. \n \n \n(a) Factor analysis of the attitude measures \u2013 pre-measure data \n \nWe began the analysis of the data obtained from this larger study by examining the \ndimensions obtained from factor analysis of the data. First of all, we used principle \ncomponents factor analysis on all the data in order to extract the appropriate number \nof factors. Eight factors were obtained with eigenvalues greater than 1. However, \nKline (1994) highlighted that this method of determining the number of factors can \noverestimate the number of factors. An alternative approach to determine the \nappropriate number of factors is to examine the scree plot produced by the analysis. \nThe corresponding scree plot from the pre-measure data suggested an extraction of \nsomething like four factors, although this was not so clear from the plot (Figure 1).  \n \n[Insert Figure 1 about here]  \n \nTherefore, based on our theoretical starting point of seven areas of attitude, we \nactually started with principle axis factoring using oblique Direct Oblimin rotation on \nseven factors. These results, with loading less than 0.3 not being shown, are given in \nTable 1. The items making up the various attitude measures are given in the left-hand \ncolumn of the table. The items pertaining to each attitude construct were grouped \ntogether in the original questionnaire, and the order of the items given in Table 1 is in \nthe same order that they appeared in the questionnaire. The ordering of the attitude \nconstructs in Table 1 is Learning science in school, Self-concept in science, Practical \nwork in science, Science outside of school, Future participation in science, \nImportance of science, and General attitude towards school. The items in Table 1 are \nseparated out accordingly into these constructs. \n \n                                                 \n2 These are the first three years of secondary schooling in England. \n 8\n[Insert Table 1 about here] \n \nIn the seven-factor solution to the analysis, the extracted factors did indeed \ncorrespond to the seven areas of attitudes to science that we introduced at the \nbeginning of the study. This provided some confirmation that we were dealing with \ndistinct areas of attitude, and each of these areas was unidimensional. However, one \npossible problem was with the item \u2018Scientists have exciting jobs\u2019 from the \nImportance of science group of statements, which did not load on any of the factors. It \nseemed reasonable from the wording of the statement that this item was not actually \nabout importance of science. Therefore, this item was removed from our list of \nstatements. \n \nTo provide further confirmation of the unidimensionality of each attitude measure, \nprinciple components factor analysis was carried out on each group of statements \nseparately. In each case, only one factor was extracted. Once again, this provided \nconfirmation that each set of attitude statements was measuring one attitude construct \nonly. \n \nAs we identified above though, the scree plot identified around four factors to extract, \nrather than seven. Repeating the principle axis factoring with oblique Direct Oblimin \nrotation on four factors, it was found that three areas of attitude, Learning science in \nschool, Science outside of school and Future participation in science, were placed in \none factor. In addition, the group of statements pertaining to Importance of Science \ndid not load on any of the four factors. The other three areas of attitude were still \nidentified as individual factors. These results for the four-factor solution suggested \nthat the three areas of attitude that were grouped together were in fact closely \ncorrelated, and perhaps make up a more general attitude measure pertaining to an \ninterest in science. To confirm this, principle components factor analysis was carried \nout on the data from these three areas of attitude only. The scree plot obtained (Figure \n2) did indeed suggest a single overall factor. \n \n[Insert Figure 2 about here] \n \n(b) Factor analysis of the attitude measures \u2013 post-measure data \n \nTo confirm the results obtained from the pre-measure data, factor analysis was also \ncarried out on the post-measure data. Principle components analysis of all the post-\nmeasure data gave eight factors with eigenvalues greater than 1, and provided the \nscree plot shown in Figure 3.  \n \n[Insert Figure 3 about here] \n \nOnce again, the plot suggested the extraction of four factors. However, we again \nstarted with an extraction of seven factors. The results of principle axis factoring with \noblique Direct Oblimin rotation on these seven factors are shown in Table 2. \n \n[Insert Table 2 about here] \n \nAlthough the seven-factor solution identified the seven theoretical constructs that we \nstarted off with, the loadings on the Importance of Science factor were relatively \n 9\nsmall. This indicated that this factor was not well defined as an individual construct. \nThe results also showed that in this case, some of the Future participation in science \nitems loaded more on the Science outside school factor. Again, this might have \nindicated that these two areas of attitude to science were quite closely related. \nCarrying out principle components factor analysis on each of the attitude areas \nseparately, we once again found that only one factor was extracted in each case. This \nonce again confirmed that each of our theoretical constructs were unidimensional. \n \nWe now carried out principle axis factor analysis with oblique Direct Oblimin \nrotation, this time with four factors. We found that similar results were obtained as for \nthe pre-measure data, with the three areas of attitude Learning science in school, \nScience outside of school and Future participation in science, being placed in one \nfactor. Once again, principle components factor analysis was carried out on the data \nfrom these three areas of attitude only. The scree plot obtained (Figure 4) did again \nsuggest a single overall factor incorporating these areas of attitude. \n \n[Insert Figure 4 about here] \n \nIn addition, two of the Importance of Science statements loaded on this combined \nfactor, although one of these loadings was relatively weak at around 0.3.  Therefore, \nas for the pre-measure data, we considered the Importance of Science factor to be \nseparate to this combined attitude factor. The other three areas of attitude were again \nidentified as individual factors.  \n \nTherefore, from this part of the study concerning the factor analysis of the attitude \ndata, we drew the following conclusions: \n \n\u2022 The statements of attitude in each of our seven constructs were each found to \nbe unidimensional in each case. \n\u2022 Principle component factor analysis suggested that three of the factors, \nLearning science in school, Science outside of school and Future participation \nin science, combined to form a more general factor, which we called the \nCombined interest in science factor. \n \n \n(c) Reliability analysis of the attitude measures \n \nHaving established the unidimensionality of the various attitudes to science measures, \nwe now examined the internal reliability of these measures. Table 3 below gives the \nCronbach \u03b1 values for each measure, both for the pre- and post-measure data. Prior to \ncarrying out the reliability calculations, all negatively worded items were reverse \ncoded. \n \n[Insert Table 3 about here] \n \nThe Combined interest in science measure (incorporating the Learning science in \nschool, Science outside of school and Future participation in science measures) is also \nincluded in the above table. For all the attitudes to science measures, the internal \nreliability was calculated to be above the threshold of 0.7 for both the pre- and post-\nmeasure data. However, we can see that the reliability was lowest for the Importance \n 10\nof Science measure. This indicated that improvements to this measure (e.g. modifying \nitems or adding new ones) would perhaps be required in the future. \n \nIn addition to examining the internal reliability of each measure, we also checked the \nspread of each measure in terms of mean values and standard deviations. These results \nare summarised in Table 4 below. \n \n[Insert Table 4 about here] \n \nFrom these results, we identified that the Practical work in science measure had the \nhighest average of around 4 on the five-point scale. The fact that this measure was \ncloser to the maximum value of the scale, and that this measure had lower standard \ndeviations than most of the other measures, indicated that a ceiling effect might be \nacting on this measure. Plotting histograms of this measure\u2019s data confirmed this. \nTherefore, another future improvement that we would suggest would be to add other \nitems to this particular measure, lowering this mean score and thus reduce the ceiling \neffect. \n \n \n(d) Correlation of attitude measures \n \nWe conclude this analysis of the attitude measures by examining the correlations \nbetween the different constructs. The Pearson correlation coefficients between each of \nthe seven individual measures are given in Tables 5 and 6 for pre- and post-measure \ndata respectively. The Combined interest in science measure is not included, as we \nknow that this will correlate highly with the individual measures that comprise it. \n \n[Insert Table 5 about here] \n[Insert Table 6 about here] \n \nIn both tables, the correlations between the Learning science in school, Science \noutside of school and Future participation in science measures were amongst the \nhighest in the tables, being in the range of 0.6 to 0.7. These high correlations \nconfirmed our previous conclusions that these three measures were closely related, \nand could in fact be combined into one Combined interest in science measure.  \n \n \nDiscussion \n \nThe main aim of this study was to describe the development of measures for attitudes \ntowards science. In doing so, we defined in advance the constructs to be measured, \nand outlined clearly the process of validating the measures, in this case using factor \nanalysis. Of course, a question we needed to ask was whether there were already \nsuitable attitude measures, with well defined and validated constructs, that we could \nhave used instead of developing our own. Therefore, we begin this discussion by \nlooking at the suitability of some other published attitudes to science measures. \n 11\n \nAs discussed at the beginning of the paper, problems with some existing attitude \nmeasures have been raised in the literature. Munby (1983 and 1997) has criticised the \nScience Attitude Instrument developed by Moore & Sutman (1970) and Moore & Foy \n(1997) in terms of the validity of its underlying constructs. Gardner (1996) has also \nprovided examples of attitudes towards science measures that do not define the \nunderlying concepts, or examine the unidimensionality of the constructs. One \nexample that he does provide for good practice in developing such measures is that of \nCoulson (1992), although this measure was developed for early childhood educators \nrather than for school pupils. \n \nNapier & Riley (1985) used existing items from the National Assessment of \nEducational Progress survey in the United States to develop attitude towards science \nmeasures. They did carry out factor analysis to obtain a number of unidimensional \nmeasures for a number of science-related attitudes. These included science enjoyment \nin the classroom and anxiety in the science classroom, which could perhaps have been \nappropriate for our use. However, the wording of some of the items involved (e.g. \n\u2018How often do you like to go to science class\u2019) did not appear to be appropriate for \nuse with younger, non-American school pupils. \n \nGermann (1988) also developed a reliable, unidimensional measure for attitudes \ntowards science in school. With Cronbach \u03b1 reliability values of 0.95 and above, this \nmeasure would certainly seem to be an appropriate measure that we could have used. \nThe only reason that it was inappropriate for our particular use was that we wanted to \nseparate the constructs of attitude towards science in and out of school. Some of \nGermann\u2019s items (e.g. \u2018Science is interesting to me and I enjoy it\u2019, \u2018When I hear the \nword science, I have a feeling of dislike\u2019) seemed not to be specific enough in this \nrespect. \n \nThe Attitudes towards Science Inventory, developed by Gogolin & Swartz (1992), \nonce again examined relevant constructs such as enjoyment of science, self-concept in \nscience and value of science in society. In this case however, although reliability \nmeasures and item-to-scale correlations were given for each construct, no checks of \nunidimensionality of the scales were provided in their paper. Pell & Jarvis (2001) did \ncheck for unidimensionality in their development of attitudes towards science \nmeasures for children aged 5 to 11 years. They identified three constructs: a science \nenthusiasm scale, a social context of science scale and science is a difficult subject \nscale. Because of the suitability of the items for younger school pupils, some of Pell \nand Jarvis\u2019 items were used in the present study, in particular for our Science outside \nof school measure. However, we chose not to use all of their items, firstly because we \nwanted once again to separate out items pertaining to science in and out of school, and \nsecondly because the reliability values for their scales were close to or below the \nthreshold of \u03b1 = 0.7. \n \nFinally, Francis & Greer (1999) developed a measure to particularly examine the \naffective domain of attitude towards science. They used factor analysis to establish a \nunidimensional measure which gave high reliability values (\u03b1 \u2248 0.9). However, the \nunderlying constructs making up this measure were not defined, and appeared in fact \nto be a mix of what we have termed as importance of science, attitude towards science \n 12\nin school, future intentions in science and self-concept in science. Therefore, once \nagain, we chose not to use this measure for our particular study. \n \nOur reasons for not using available measures for attitudes towards science were \ntherefore just as much to do with our specific requirements in using these measures, as \nwell as drawbacks in the development of some of these. Our wish to examine specific \nconstructs associated with attitudes towards science, rather to examine a general \nattitude towards science, necessitated the development of our particular measures. \n \nIn fact, we view this approach of starting with particular constructs as a strength of \nthis study. Not only are we dealing with the concern of Gardner (1996) that different \nconstructs are being mixed together in the same attitude scale, but it also allows us to \nbuild up the attitude scales step by step. It may perhaps be that separate constructs are \nclosely correlated and are effectively part of a more general attitude scale, but we only \ncombine the constructs when this has been validated through responses to the scales. \nThe approach also allows us to identify particular weaknesses and gaps in the attitude \nscales. By dealing with the constructs separately, we could see that there were \nweaknesses in our Importance of science measure. We have also acknowledged that \nwe have not examined other important influences on pupil attitudes towards science, \nsuch as their views on their science teachers. We can therefore include these as other \nseparate constructs in our studies in the future. \n \nA possible weakness that can be put forward with the present study is that further \nvalidation of the various attitude measures could be carried out. Demonstrating \nconcurrent validity would have further strengthened the validity of the measures but \nin this instance we did not wish to overload the pupils with a lengthy questionnaire. \nThis is something that we can address in future studies. The criteria that we put \nforward for developing attitude measures suggested that different methods of \nvalidation be used. The results of the factor analyses in Tables 2 and 3 confirmed that \nour conceptually formed factors matched with empirically produced scales (i.e. the \ncomponents formed in the way we would have expected). These results also \nconfirmed convergent and divergent validity at item level (items that belonged to the \nsame scale are highly correlated with themselves and divergent from those in different \nscales). \n \nHowever, we could have also examined whether the attitude measures had predictive \nvalidity in describing expected behaviour from pupils. For example, commonly \nobserved patterns in pupils\u2019 attitudes towards science are that they decline over the \nperiod of their schooling, and that the attitudes of female pupils are less positive than \nthose of the male pupils. Having developed our attitudes towards science measures in \nthis paper, we will explore in a future publication whether these patterns are \nhighlighted by our measures.   \n \n \nAcknowledgements \n \nThe authors would like to thank the Institute of Physics for funding the original study \nwhich produced these results. \n \n 13\nFor copies of the questionnaires used in this research, please contact Dr Patrick \nBarmby at the corresponding address or e-mail provided. \n \n \nReferences \n \nAjzen, I. (2001). Nature and operation of attitudes. Annual Review of Psychology, 52, \n27-58.  \n Bagozzi, R. P., & Burnkrant, R. E. (1979). Attitude Organization and the Attitude-\nBehavior Relationship. Journal of Personality and Social Psychology, 37, 913-\n929. \nBennett, J. (2001). The development and use of an instrument to assess students\u2019 \nattitude to the study of chenistry. International Journal of Science Education, \n23(8), 833-845 \nCoughlan, R. (2000). European Union Physics Colloquium, Physics Education, 35(4), \n287-292 \nCoulson, R. (1992). Development of an instrument for mesuring sttitudes of early \nchildhood educators towards science. Research in Science Education, 22, 101-\n105 \nCrano, W. D., & Prislin, R. (2006). Attitudes and persuasion. Annual Review of \nPsychology, 57, 345-374 \nCrocker, L., & Algina, J. (1986). Introduction to classical and modern test theory. \nNew York: CBS College Publishing \nFishbein, M., & Ajzen, I. (1975). Belief, Attitude, Intention and Behaviour: an \nintroduction to theory and research. Reading, MA: Addison-Wesley \nFrancis, L. J., & Greer, J. E. (1999). Measuring attitude towards science among \nsecondary school students: the affective domain. Research in Science and \nTechnological Education, 17(2), 219-226 \nGardner, P. L. (1975). Attitudes to science: A Review. Studies in Science Education, \n2, 1\u201341 \nGardner, P. L. (1995). The dimensionality of attitude scales: a widely misunderstood \nidea. International Journal of Science Education, 18(8), 913-919 \nGardner, P. L. (1996). Measuring attitudes to science. Research in Science Education, \n25, 283\u2013289 \nGeorge, R. (2000). Measuring Change in Students\u2019 Attitudes Toward Science Over \nTime: An Application of Latent Variable Growth Modelling. Journal of Science \nEducation and Technology, 9(3), 213-225 \nGermann, P. J. (1988). Development of the attitude toward science in school \nassessment and its use to investigate the relationship between science \nachievement and attitude toward science in school. Journal of Research in \nScience Teaching, 25(8), 689-703 \n 14\nGogolin, L., & Swartz, F. (1992). A Quantitative and Qualitative Inquiry into the \nAttitudes toward Science of Nonscience College Students. Journal of Research \nin Science Teaching, 29(5), 487-504 \nHenerson, M. E., Lyons Morris, L. and Taylor Fitz-Gibbon, C. (1987). How to \nMeasure Attitudes. California: SAGE Publications \nKline, P. (1994). An Easy Guide to Factor Analysis. London: Routledge \nMcGuire, W. J. (1985). Attitude and Attitude Change. In Lindzey, G. and Aronson, E. \n(eds.) Handbook of Social Psychology (pp. 233-346). New York, NY: Random \nHouse \nMoore, R., & Foy, R. L. H. (1997). The Scientific Attitude Inventory: A revision (SAI \nII). Journal of Research in Science Teaching, 34(4), 327-336 \nMoore, R., & Sutman, F. (1970). The development, field test and validation of an \ninventory of scientific attitudes. Journal of Research in Science Teaching, 7, 85-\n94 \nMunby, H. (1982). The impropriety of \u2018panel of judges\u2019 validation in science attitude \nscales: a research comment. Journal of Research in Science Teaching, 19(7), \n617-619. \nMunby, H. (1983). Thirty studies involving the \u2018Scientific Attitude Inventory\u2019: What \nconfidence can we have in this instrument? Journal of Research in Science \nTeaching, 20(2), 141-162 \nMunby, H. (1997). Issues of validity in science attitude measurement. Journal of \nResearch in Science Teaching, 34(4), 337-341 \nNapier, J. D., & Riley, J. P. (1985). Relationship between affective determinants and \nachievement in science for seventeen-year-olds. Journal of Research in Science \nTeaching, 22(4), 365-383 \nOppenheim, A. N. (1992). Questionnaire Design, Interviewing and Attitude \nMeasurement. London: Pinter \nOsborne, J., Simon, S., & Collins, S. (2003). Attitudes towards science: a review of \nthe literature and its implication. International Journal of Science Education, \n25(9), 1049-1079 \nPell, T., & Jarvis, T. (2001). Developing attitude to science scales for use with \nchildren of ages from five to eleven years. International Journal of Science \nEducation, 23(8), 847-862 \nRajecki, D. W. (1990). Attitudes. Sunderland, MA: Sinauer \nRamsden, J. M. (1998). Mission impossible?: Can anything be done about attitudes to \nscience? International Journal of Science Education, 20(2), 125-137 \nReid, N. (2006). Thoughts on Attitude Measurement. Research in Science & \nTechnological Education, 24(1), 3-27 \nSchibeci, R. A. (1984). Attitudes to Science: an update. Studies in Science Education, \n11, 26-59 \nTrochim, W. M. K. (2002). Convergent and Discriminant Validity [online]. Cornell \nUniversity. Available from www.socialresearchmethods.net\/kb\/convdisc.htm \n[Accessed 22 April 2006] \n 15\nScree Plot\nComponent Number\n46434037343128252219161310741\nE\nig\nen\nva\nlu\ne\n16\n14\n12\n10\n8\n6\n4\n2\n0\n \nFigure 1. Scree plot from the factor analysis of the pre-measure data \n \nScree Plot\nComponent Number\n1716151413121110987654321\nE\nig\nen\nva\nlu\ne\n10\n8\n6\n4\n2\n0\n \nFigure 2. Scree plot for factor analysis on of pre-measure data: Three areas of attitude \nonly \n 16\nTable 1. Factor analysis results for the pre-measure data \nComponents \nAttitude Statements 1 2 3 4 5 6 7 \nWe learn interesting things in science \nlessons.     -0.580   \nI look forward to my science lessons.     -0.629   \nScience lessons are exciting.     -0.553   \nI would like to do more science at \nschool.     -0.450   \nI like Science better than most other \nsubjects at school.     -0.481  0.308\nScience is boring.     0.522   \nI find science difficult.     0.749    \nI am just not good at Science.      0.722    \nI get good marks in Science.      -0.670    \nI learn Science quickly.     -0.593    \nScience is one of my best subjects.     -0.429 -0.364   \nI feel helpless when doing Science.     0.555    \nIn my Science class, I understand \neverything.     -0.541    \nPractical work in science is exciting.   0.632      \nI like science practical work because \nyou don\u2019t know what will happen.   0.542      \nPractical work in science is good \nbecause I can work with my friends.   0.411      \nI like practical work in science \nbecause I can decide what to do \nmyself.   0.394      \nI would like more practical work in \nmy science lessons.  0.819      \nWe learn science better when we do \npractical work.   0.692      \nI look forward to doing science \npracticals.   0.778      \nPractical work in science is boring.  -0.666      \nI would like to join a science club.  0.449       \nI like watching science programmes \non TV.  0.622       \nI like to visit science museums.  0.637       \nI would like to do more science \nactivities outside school.  0.615       \nI like reading science magazines and \nbooks.  0.619       \nIt is exciting to learn about new things \nhappening in science.  0.443    -0.304   \n \n 17\nTable 1. Factor analysis results for the pre-measure data continued \nComponents \nAttitude Statements 1 2 3 4 5 6 7 \nI would like to study more science in \nthe future.        0.396\nI would like to study science at \nuniversity.        0.620\nI would like to have a job working \nwith science.        0.799\nI would like to become a science \nteacher.        0.577\nI would like to become a scientist.        0.731\nScience and technology is important \nfor society.       0.707  \nScience and technology makes our \nlives easier and more comfortable.        0.769  \nThe benefits of science are greater \nthan the harmful effects.       0.550  \nScience and technology are helping \nthe poor.        0.481  \nThere are many exciting things \nhappening in science and technology.      0.485  \nScientists have exciting jobs.         \nI really like school.    0.805     \nI would recommend this school.    0.673     \nI find school boring.    -0.719     \nI feel that I belong in this school.    0.532     \nMost of the time I wish I wasn\u2019t in \nschool at all.    -0.572     \nI get on well with most of my \nteachers.    0.591     \nI am normally happy when I am in \nschool.    0.724     \nI work as hard as I can in school.    0.388     \n \n 18\nScree Plot\nComponent Number\n434037343128252219161310741\nE\nig\nen\nva\nlu\ne\n16\n14\n12\n10\n8\n6\n4\n2\n0\n \nFigure 3. Scree plot for factor analysis of post-measure data \n \nScree Plot\nComponent Number\n1716151413121110987654321\nE\nig\nen\nva\nlu\ne\n10\n8\n6\n4\n2\n0\n \nFigure 4. Scree plot for factor analysis on of post-measure data: Three areas of \nattitude only \n 19\nTable 2. Factor analysis results for the post-measure data \nComponents \nAttitude Statements 1 2 3 4 5 6 7 \nWe learn interesting things in science \nlessons.         -0.589     \nI look forward to my science lessons.         -0.845     \nScience lessons are exciting.         -0.767     \nI would like to do more science at \nschool.         -0.745     \nI like Science better than most other \nsubjects at school.         -0.726     \nScience is boring.         0.577     \nI find science difficult.        0.694       \nI am just not good at Science.         0.744       \nI get good marks in Science.         -0.641       \nI learn Science quickly.        -0.670       \nScience is one of my best subjects.        -0.370 -0.481     \nI feel helpless when doing Science.        0.506       \nIn my Science class, I understand \neverything.        -0.572       \nPractical work in science is exciting.    0.675           \nI like science practical work because \nyou don\u2019t know what will happen.    0.693           \nPractical work in science is good \nbecause I can work with my friends.    0.540           \nI like practical work in science \nbecause I can decide what to do \nmyself.    0.542           \nI would like more practical work in \nmy science lessons.   0.845           \nWe learn science better when we do \npractical work.    0.774           \nI look forward to doing science \npracticals.    0.810           \nPractical work in science is boring.    -0.763           \nI would like to join a science club.  0.711             \nI like watching science programmes \non TV.  0.579             \nI like to visit science museums.  0.573             \nI would like to do more science \nactivities outside school.  0.638             \nI like reading science magazines and \nbooks.  0.704             \nIt is exciting to learn about new things \nhappening in science.  0.445             \n \n 20\nTable 2. Factor analysis results for the post-measure data continued \nComponents \nAttitude Statements 1 2 3 4 5 6 7 \nI would like to study more science in \nthe future.        -0.614\nI would like to study science at \nuniversity.        -0.774\nI would like to have a job working \nwith science.        -0.778\nI would like to become a science \nteacher.  0.400       \nI would like to become a scientist.  0.440      -0.452\nScience and technology is important \nfor society.       0.405  \nScience and technology makes our \nlives easier and more comfortable.        0.329  \nThe benefits of science are greater \nthan the harmful effects.       0.346  \nScience and technology are helping \nthe poor.          \nThere are many exciting things \nhappening in science and technology.     -0.353   \nI really like school.    0.772     \nI would recommend this school.    0.627     \nI find school boring.    -0.683     \nI feel that I belong in this school.    0.597     \nMost of the time I wish I wasn\u2019t in \nschool at all.    -0.592     \nI get on well with most of my \nteachers.    0.503     \nI am normally happy when I am in \nschool.    0.766     \nI work as hard as I can in school.    0.377     \n \n 21\nTable 3. Cronbach \u03b1 reliability values for each attitude measure \nMeasure \nCronbach \u03b1 \n(pre-measure) \nCronbach \u03b1 \n(post-measure) \nLearning science in school (6 items) 0.89 0.92 \nSelf-concept in science (7 items) 0.85 0.85 \nPractical work in science (8 items) 0.85 0.89 \nScience outside of school (6 items) 0.88 0.87 \nFuture participation in science (5 items) 0.86 0.88 \nImportance of science (5 items) 0.77 0.72 \nGeneral attitude towards school (8 items) 0.85 0.85 \nCombined interest in science (17 items) 0.93 0.94 \n \n \nTable 4. Mean values and standard deviation of each attitude measure \n Pre-measure  Post-measure \nMeasure Mean SD  Mean SD \nLearning science in school  3.38 0.82  3.06 0.97 \nSelf-concept in science 3.41 0.70  3.24 0.75 \nPractical work in science 4.05 0.64  3.95 0.77 \nScience outside of school  2.75 0.93  2.64 0.92 \nFuture participation in science 2.57 0.85  2.38 0.89 \nImportance of science 3.58 0.67  3.50 0.65 \nGeneral attitude towards school 3.40 0.76  3.32 0.77 \nCombined interest in science 2.92 0.76  2.71 0.83 \n \n 22\n 23\nTable 5. Correlations between each attitude to science measure \u2013 pre-measure data \nMeasure \nSelf-\nconcept \nin \nscience \nPractical \nwork in \nscience \nScience \noutside \nof \nschool \nFuture \nparticipation \nin science \nImportance \nof science \nGeneral \nattitude \ntowards \nschool \nLearning \nscience in \nschool  \n0.616 0.402 0.669 0.598 0.476 0.425 \nSelf-concept \nin science  0.322 0.464 0.499 0.391 0.327 \nPractical \nwork in \nscience \n  0.336 0.312 0.455 0.283 \nScience \noutside of \nschool  \n   0.661 0.463 0.446 \nFuture \nparticipation \nin science \n    0.477 0.341 \nImportance \nof science      0.390 \n \nTable 6. Correlations between each attitude to science measure \u2013 post-measure data \nMeasure \nSelf-\nconcept \nin \nscience \nPractical \nwork in \nscience \nScience \noutside \nof \nschool \nFuture \nparticipation \nin science \nImportance \nof science \nGeneral \nattitude \ntowards \nschool \nLearning \nscience in \nschool  \n0.574 0.458 0.696 0.662 0.558 0.426 \nSelf-concept \nin science  0.323 0.439 0.467 0.368 0.304 \nPractical \nwork in \nscience \n  0.401 0.337 0.488 0.291 \nScience \noutside of \nschool  \n   0.691 0.512 0.414 \nFuture \nparticipation \nin science \n    0.468 0.303 \nImportance \nof science      0.351 \n \n"}
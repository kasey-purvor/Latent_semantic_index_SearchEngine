{"doi":"10.1007\/978-3-540-30473-9_20","coreId":"70156","oai":"oai:eprints.lancs.ac.uk:13017","identifiers":["oai:eprints.lancs.ac.uk:13017","10.1007\/978-3-540-30473-9_20"],"title":"Towards a Playful User Interface for Home Entertainment Systems","authors":["Block, Florian","Schmidt, Albrecht","Villar, Nicolas","Gellersen, Hans"],"enrichments":{"references":[{"id":16309829,"title":"Building Intelligent Environments with Smart-Its.","authors":[],"date":"2004","doi":"10.1109\/mcg.2004.1255810","raw":"L. E. Holmquist, H.-W. Gellersen, A. Schmidt, M. Strohbach, G. Kortuem, S. Antifakos, F. Michahelles, B. Schiele, M. Beigl, R. Maz\u00e9. Building Intelligent Environments with Smart-Its. IEEE Computer Graphics & Applications. January\/February 2004 (Vol. 24, No. 1), pp. 56-64.","cites":null},{"id":16309840,"title":"Design optimization of three-axis accelerometers based on four seismic masses.","authors":[],"date":"2002","doi":"10.1109\/icsens.2002.1037267","raw":"H. Rodjegard, G. Andersson. Design optimization of three-axis accelerometers based on four seismic masses. Proceedings of IEEE Sensors, 2002. Vol 2. Pages: 1099- 1104","cites":null},{"id":16309819,"title":"Designing for Ludic Aspects of Everyday Life.","authors":[],"date":"2001","doi":null,"raw":"Bill Gaver. Designing for Ludic Aspects of Everyday Life. Special Issue on Ambient Intelligence. ERCIM News No.47, October 2001.","cites":null},{"id":16309822,"title":"Markus Gro\u00df and Antonio Kr\u00fcger: &quot;TUISTER: a Tangible UI for Hierarchical Structures&quot;,","authors":[],"date":"2004","doi":"10.1145\/964482.964486","raw":"Andreas Butz, Markus Gro\u00df and Antonio Kr\u00fcger: &quot;TUISTER: a Tangible UI for Hierarchical Structures&quot;, in Proceedings of IUI 2004, January 13-16, 2004, Madeira, Funchal, Portugal.","cites":null},{"id":16309826,"title":"Physical Prototyping with Smart-Its.","authors":[],"date":"2004","doi":"10.1109\/mprv.2004.1321032","raw":"H. Gellersen, G. Kortuem, M. Beigl and A. Schmidt. Physical Prototyping with Smart-Its. IEEE Pervasive Computing Magazin (2004, accepted for publication).","cites":null},{"id":16309833,"title":"Responsive Environments Group. 3X Inertial Measurement Unit Project. http:\/\/www.media.mit.edu\/resenv\/imu\/ (page visited","authors":[],"date":"2004","doi":null,"raw":"MIT Media lab. Responsive Environments Group. 3X Inertial Measurement Unit Project. http:\/\/www.media.mit.edu\/resenv\/imu\/ (page visited May 2004).","cites":null},{"id":16309816,"title":"Roni Rosenfeld, Mathilde Pignol. &quot;Generating Remote Control Interfaces for Complex Appliances.&quot;","authors":[],"date":"2002","doi":"10.1145\/571985.572008","raw":"Jeffrey Nichols, Brad A. Myers, Michael Higgins, Joe Hughes, Thomas K. Harris, Roni Rosenfeld, Mathilde Pignol. &quot;Generating Remote Control Interfaces for Complex Appliances.&quot; CHI Letters: ACM Symposium on User Interface Software and Technology, UIST'02, 27-30 Oct. 2002, Paris, France. pp. 161-170.","cites":null},{"id":16309837,"title":"Smart-Its technical information.","authors":[],"date":"2005","doi":null,"raw":"Lancaster University. Smart-Its technical information. Wiki-Web. Page visited May 2005. http:\/\/ubicomp.lancs.ac.uk\/twiki\/bin\/viewauth\/Smartits\/WebHome (anonymous login as user TWikiGuest with password guest).","cites":null},{"id":16309813,"title":"The Context Aware Personal Remote Control: A Case Study on Context Awareness.","authors":[],"date":null,"doi":"10.1109\/icdcsw.2003.1203574","raw":"T. Lashina, F. Vignoli, V. Buil, S. van de Wijdeven, G. Hollemans, J. Hoonhout. The Context Aware Personal Remote Control: A Case Study on Context Awareness. 23rd International Conference on Distributed Computing Systems Workshops (ICDCSW'03).","cites":null},{"id":16309843,"title":"Using an Autonomous Cube for Basic Navigation and Input. ICMI\/PUI","authors":[],"date":"2003","doi":"10.1145\/958432.958472","raw":"K. Van Laerhoven, N. Villar, A. Schmidt, G. Kortuem and H.-W. Gellersen. Using an Autonomous Cube for Basic Navigation and Input. ICMI\/PUI 2003. ACM Press. Vancouver, Canada. November 2003, pp. 203-211.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2004","abstract":"In this paper we propose a tangible cube as an input device for playfully changing between different TV-channels. First we consider several design approaches and compare them. Based on a cube that has embedded gravity sensing and wireless communication capabilities a prototype is implemented. A 3D graphical representation of the cube is shown on the television screen. On each face of the cube a TV stream is rendered. The motion of the cube on the screen is connected to the rotation the user performs using the real tangible cube. Our hypotheses is that users can use the cube to browse between channels and to zap intuitively and playfully gaining a improved user experience even if the efficiency is limited compared to a remote control. We report on initial user feedback testing our hypothesis in witch we found out that users can easily use the cube without instructions and, despite technical limitations, see it as an improvement of current systems. Finally we discuss the issues that emerged from user's feedback","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/70156.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/13017\/1\/2004%2DTowards%2DPlayful%2DUI.pdf","pdfHashValue":"1c185ee321744482a479cd35a060c9f9021a7ce6","publisher":"Springer-Verlag,","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:13017<\/identifier><datestamp>\n      2018-01-24T02:09:42Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Towards a Playful User Interface for Home Entertainment Systems<\/dc:title><dc:creator>\n        Block, Florian<\/dc:creator><dc:creator>\n        Schmidt, Albrecht<\/dc:creator><dc:creator>\n        Villar, Nicolas<\/dc:creator><dc:creator>\n        Gellersen, Hans<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        In this paper we propose a tangible cube as an input device for playfully changing between different TV-channels. First we consider several design approaches and compare them. Based on a cube that has embedded gravity sensing and wireless communication capabilities a prototype is implemented. A 3D graphical representation of the cube is shown on the television screen. On each face of the cube a TV stream is rendered. The motion of the cube on the screen is connected to the rotation the user performs using the real tangible cube. Our hypotheses is that users can use the cube to browse between channels and to zap intuitively and playfully gaining a improved user experience even if the efficiency is limited compared to a remote control. We report on initial user feedback testing our hypothesis in witch we found out that users can easily use the cube without instructions and, despite technical limitations, see it as an improvement of current systems. Finally we discuss the issues that emerged from user's feedback.<\/dc:description><dc:publisher>\n        Springer-Verlag,<\/dc:publisher><dc:date>\n        2004<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/13017\/1\/2004%2DTowards%2DPlayful%2DUI.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/978-3-540-30473-9_20<\/dc:relation><dc:identifier>\n        Block, Florian and Schmidt, Albrecht and Villar, Nicolas and Gellersen, Hans (2004) Towards a Playful User Interface for Home Entertainment Systems. In: Proceedings of the European Symposium on Ambient Intelligence 2004. Springer-Verlag,, pp. 207-217.<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/13017\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1007\/978-3-540-30473-9_20","http:\/\/eprints.lancs.ac.uk\/13017\/"],"year":2004,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"P. Markopoulos et al. (Eds.): EUSAI 2004, LNCS 3295, pp. 207\u2013217, 2004.\n\u00a9 Springer-Verlag Berlin Heidelberg 2004\nTowards a Playful User Interface for Home\nEntertainment Systems\nFlorian Block1,2, Albrecht Schmidt1, Nicolas Villar2, and Hans W. Gellersen2\n1\n Embedded Interaction Group, University of Munich, Germany,\nblock@informatik.uni-muenchen.de,\nalbrecht.schmidt@ifi.lmu.de\nhttp:\/\/www.medien.ifi.lmu.de\/ei\/\n2\n Computing Department, Lancaster University, UK\n{villar,hwg}@comp.lancs.ac.uk\nAbstract. In this paper we propose a tangible cube as an input device for play-\nfully changing between different TV-channels. First we consider several design\napproaches and compare them. Based on a cube that has embedded gravity\nsensing and wireless communication capabilities a prototype is implemented. A\n3D graphical representation of the cube is shown on the television screen. On\neach face of the cube a TV stream is rendered. The motion of the cube on the\nscreen is connected to the rotation the user performs using the real tangible\ncube. Our hypotheses is that users can use the cube to browse between channels\nand to zap intuitively and playfully gaining a improved user experience even if\nthe efficiency is limited compared to a remote control. We report on initial user\nfeedback testing our hypothesis in witch we found out that users can easily use\nthe cube without instructions and, despite technical limitations, see it as an im-\nprovement of current systems. Finally we discuss the issues that emerged from\nuser\u2019s feedback.\n1   Introduction\nCurrent home entertainment products show a wide range of user interfaces and inter-\naction styles. In particular remote controls of users \u2013 if well designed \u2013 an efficient\nmeans to operate such devices. Recent trends in mobile devices and networking show\na development towards universal remote controls based on web technology and mo-\nbile devices, such as PDAs and mobile phones [1,2]. These approaches can offer a\nvery efficient way for controlling and manipulation functions, however considering\nthe situations in which home entertainment is used efficiency is not the only goal. In\n[3] Bill Gaver explains the concept of the Homo-Ludens and that design has to take\nthis into account. Humans are described as playful and creative explorers of their\nenvironment and hence good design has to address these basic needs, too \u2013 without\ncompromising the effectiveness of a tool.\nWe looked at the domain of controlling a television set (TV). From informal ob-\nservations and reports we can conclude that changing channels is the predominant\nactions users are taking. The goal when users who change channels are manifold:\n208         F. Block et al.\n\u2022 switching to a specific channel\n\u2022 browse the program, getting an overview of \u201cwhat is on\u201d at the moment\n\u2022 zapping (looking at various channels one after another for a short time)\nIn the case where the users browse or zap the efficiency of selecting a specific chan-\nnel is a minor concern. Here the overall experience in using the device is at the centre.\nThere are further functions where efficiency plays a more dominant role, e.g. switch-\ning on and of the TV, controlling volume, and switching views (television and\nteletext). Most other functions are to our knowledge used rarely in daily use.\nIn this paper we report on a project where we explore a specific design option that\nintroduces a playful element to controlling channels on a TV. Our focus was on pro-\nviding means for changing a channel in a playful and pleasant, but hence effective\nway. Other functions could be included in the interface but this is not discussed fur-\nther in this paper. In the next section we briefly explain the idea how we assessed the\nconcept by talking to users. This is followed by a detailed description of the imple-\nmentation. We discuss then our use experience and initial user feedback. Finally this\nis concluded with a discussion showing general issues for building tangible user inter-\nfaces for this domain.\n2   Idea and Initial User Feedback\nThe basic idea for a new user interfaces for changing TV channels resulted of infor-\nmal observations of people watching television. Browsing and zapping is with many\npeople by now a common way of using these systems. Our experience form the UK\nand Germany suggests that breaks for advertising and a fairly large number of chan-\nnels available are factors that enforce this way of using a TV. When browsing and\nzapping it can be observed that people use the \u201cnext-channel\u201d and step through all\nprograms rather than selecting a specific channel. These observations lead to the idea\nto create a playful interface for channel selection.\nThe basic concept is to use a handy cube that allows changing the channels on TV\nby physical movement in a 3D-space. More specific a virtual version of the cube is\nshown on the television screen. On each phase of the cube a TV stream is rendered.\nThe motion of the cube on the screen is connected to the rotation the user performs\nusing the real cube. The user now can rotate the real cube in order to see the different\nsides and the TV channels respectively. If the cube is put down and not moved any-\nmore the TV channel currently facing the user on the virtual cube is enlarged to cover\nthe full screen. As soon as the user picks the cube up again the currently showing\nchannel is resized back to the facing site of the virtual cube. Other channels are\nshown on the other sides of the cube.\nBefore implementing the system we talked to potential users to get an initial feed-\nback. In particular we were interested in the following two issues:\n\u2022 Is the idea of the interface intuitive and easy to understand?\n\u2022 Do people like the idea of a playful interface for a TV even if it reduces effi-\nciency?\nTowards a Playful User Interface for Home Entertainment Systems         209\nThe first question we approached showing people a sketch with a cube on a TV\n(which channel names on the sides) and a cube in a hand and asking how they think\nthis UI works and how they would explore it. See figure 1 for a sample sketch. In this\ndiscussions we potential users we gained evidence that they could easily understand\nthe concept and that they would do the right things to explore the interface.\nAfter people understood the user interface we asked how they felt about draw-\nbacks, especially with regard efficiency of direct channel select. For people this\nseems to be a minor concern as they generally do not find the task of selecting the\nchannel time critical. One even mentioned that when zapping \u2013 the idea is to spend\ntime \u2013 and hence playfulness is more important efficiency.\nBased on this feedback we explored options for implementing such a system and to\nexplore its usefulness and usability.\nFig. 1. To give users an idea what we would like to build we used a simple sketch that explains\nthe basic concept. After people got the idea we asked initial user feedback.\n3    Exploring the Design Space\nBefore implementing a full prototype we explored several design options. The first\nissue was related to finding a tangible object that is the physical manipulator and has\na visual counterpart on the screen. A cube offered the affordances that proved to be\nmost interesting. It can be easily handled by people, the manipulations (picking it up,\nputting it down, rotation and translation) are intuitive and it can be placed on any\nhorizontal surface. Furthermore a cube offers clear faces to place the information (TV\nchannels) on.\nWe explored further geometrical shapes, such as a hexagon, a cylinder, and a\nsphere. The hexagon seems an interesting object, this is as also explored by Butz et al.\nin [4], however we found the manipulations less intuitive. The hexagon also offers an\neasy way for presenting information on it. The sphere and the cylinder are very play-\nful to use, however put them down a surface is a problem (the role away). Addition-\nally visualization is discrete information units (such as separate TV streams) is more\n210         F. Block et al.\ndifficult and there is no clear natural mapping. In figure 2 a sphere and a cube are\nshown next to the prototypical hardware that was used for sensing in the initial test.\nThe prototyping tool is based on a Smart-Its hardware [5, 6]. Similar systems have\nbeen used in other projects, e.g. [7].\n    \nFig. 2. In the initial design phase we explored different physical manipulation devices. The\nexamples shown here are a sphere (left) and a cube (middle). These devices are built based on \u2013\nSmart-Its - a platform for prototyping ubicomp applications.\nFor implementing the visualisation we chose to present a 3D model of the physical\nobject manipulated by the user. For the representation of the TV channels we consid-\nered several options. The low fidelity would present only names and logos of the\nchannels on the object. The high fidelity version should render continuously the cur-\nrent life TV stream on each face of the cube. An option in between is to have screen\nshots of all channels as representations. Given the aim to create a playful experience it\nappeared important to seek a high fidelity solution, even if this requires a number of\nreceivers providing the TV feeds.\n4    Implementation\nTo further explore this type of user interface we build a fully functional prototype of\nthe system.\n4.1   System Architecture\nThe overall system consists of two main components. The cube as tangible user inter-\nface is one component and the visual representation of the cube on the screen is the\nother. This is very similar to the sketch in figure 1. To make the system functional\nfurther components are required: the RF-receiver linking the tangible UI to the sys-\ntem, the driver code converting the sensor information into meaningful geometrical\ninformation, and the video source that can be mapped to the faces of the cube. In the\nfollowing we explain these components in more detail.\nTowards a Playful User Interface for Home Entertainment Systems         211\n4.2   Tangible UI and Receiver Unit\nThe hardware customized for the project is based on two Smart-Its that are wirelessly\nlinked. The communication is via short range RF (up to 30m, FM) using a simple\nbroadcast protocol. Full technical details can be found at [8].\nAttached to the Smart-It included in the cube is a sensor board which is equipped\nwith two accelerometers that are orthogonally adjusted. Each accelerometer includes\n2 orthogonal adjusted sensors. The sensors used are accelerometers by Analog De-\nvices (ADXL311) offering a measuring range of +\/-2g. By using this arrangement,\nalso depicted in figure 3, we get acceleration in three dimensions (X-Y and X-Z). The\nfour resulting raw-data streams are constantly transmitted at a rate of about 30Hz per\nchannel. The raw values are received by a second Smart-It which forwards the data\nover a standard RS-232 serial line to the computer running the visualization. Con-\ncepts for optimizing the design of a three-axis accelerometer are discussed in [9].\nThe raw values are collected by the input handling of the driver unit and passed to\nthe data analysing unit. As one of the original four data streams is redundant only\nthree of them are taken into account. To deal with inaccuracies several values are\nrecorded over a short time and smoothened by applying a running average. The pre-\nprocessing causes a delay of about 50ms, but improves the data significantly.\nFig. 3. On the left the physical arrangement of the two sensor devices inside the cube is de-\npicted. On the right the abstracted view is shown.\nAfterwards for each sensor orientation values are linearly converted to a floating\npoint in the interval [-1.0, 1.0]. The minimum and maximum values are calibrated to\nthe accelerometer\u2019s two extreme values caused by gravity (see Figure 3). The final\nresolution achieved is sensor-dependent approximately limited to resolution of 0.02\nconsequently to a total amount of 100 steps over the total calibrated range ([-\n1.0;+1.0]). The three converted values are paired in three different groups each with\ntwo elements (X and Y, X and Z, Y and Z). For each group it is now possible to cal-\nculate the angle between the gravity vector and one of the vectors in the group. This\nis achieved by applying the arctan function on the individual group quotients:\n212         F. Block et al.\nz\ny\nz\nx\ny\nx\narctan,arctan,arctan === \u03b3\u03b2\u03b1\nAs x, y and z are values between -1.0 and 1.0 the arctan delivers angles between -\n180\u00b0 and 180\u00b0 giving a full 360\u00b0 range, see Figure 4. In theory this results in 3 angles\nbetween gravity and one vector in each group.\nFig. 4. If the components of the gravity vector are known the angle of the cube related to the\ngravity vector can be calculated.\nUnlike the angles related to gravity, the rotation around the worlds Y-Axis (that is\nperpendicular to the floor) can not be measured by the sensors used in the prototype\nand is therefore simulated by a state machine. Once calibrated it keeps track of the\naccording Y-rotation and can consequently decide which side of the real cube is cur-\nrently facing the user. Based on that information the current world\u2019s Y Angle can be\nset in 90\u00b0 steps. For details on the state machine algorithm see [10]. Analysing the\ngravity-related values gives the result that, depending on the side that is up, always\none angle seems to have a very low resolution and in the worst case flicker in steps of\nup to 180\u00b0. Logically this is no problem as only 2 gravity related angles are needed.\nHowever, practically it has to be decided which of the three angles we employ in the\nfinal transformation and also to avoid using the flickering angle. Before defining an\nefficient selection strategy we need to explain the observed behaviour.\nThe effect is due to a simple mathematical relation of the x, y and z values. As\nlong as the cube is not being translated, the three components together always form\nthe g-vector which is, like mentioned earlier, calibrated to the absolute value of 1.0\n( 1222 =++ zyx ). Looking at 222 1 zyx \u2212=+  the geometrically interpretation\nwould be that all x-y value pairs, plotted in a Cartesian coordinate system, lie on a\ncircle with radius 21 z\u2212 . The closer the value for z is to the absolute value of 1 the\nsmaller the radius for the value pairs of the X-Y group becomes. As sensor data has a\nlimited resolution and is not optimal this cases problems. Consequently this means the\nresolution decreases to 0 with z increasing to the absolute value of 1. Figure 5 shows\nTowards a Playful User Interface for Home Entertainment Systems         213\nan illustration for an example resolution. Considering the angles \u2013 a lower resolution\nin values causes a lower resolution in angles and this explains the formerly mentioned\nflickering as the resolution is nearly 0.\nFig. 5. The XY resolution decreases to 0 with z increasing to the absolute value of 1. The\nimage shows an example with a decrease of resolution with a base resolution of 10 by 10.\nFor finding a strategy to employ the calculated angles correctly, we look at two\ndifferent resolutions during a transition. We can approximate the resolution of a\ngroup with the current radius r by using the formula for the circumference:\nvapprox resrres \u22c5= \u03c02 , where resv is the value resolution\n(in our case resv = 100).\nLooking at the approximated resolutions of the XY and XZ group in dependency\nof the z value (this corresponds to a rotation around the X-Axis, see fig 3 for illustra-\ntion) gives the following progression of resolution, depicted in figure 6.:\n0\n100\n200\n300\n400\n500\n600\n700\n0 0,25 0,5 0,75 1\nz\nre\ns(\nap\np\nro\nx)\nres(xy)\nres(xz)\nFig. 6. Plotting the resolution of the of XY and XZ groups in dependency of the z-values.\n214         F. Block et al.\nCalculating the corresponding YZ-angle at the point of intersection delivers a\nvalue of exactly 45\u00b0. Repeating this procedure with all different values and cube\nstates gives the significant transition angles of -135\u00b0, -45\u00b0, 45\u00b0 and 135\u00b0. In the ex-\nample depicted we exchange the XY-angle with the XZ angle, as soon as the YZ-\nangle crosses one of the given values.\nThis results in the following algorithm for handling the validity of the three angles.\nAssuming that there are three groups g1, g2, g3. Then the following two rules apply:\nI) Exactly 2 groups must always be valid.\nII) If a valid group\u2019s angle crosses -135\u00b0, -45\u00b0, 45\u00b0 or 135\u00b0 switch the valid-\nity state of the other two groups.\nNow you always have two valid angles to mount on the worlds X and Z rotations\nand a Y angle given by the state machine. The state machine now sets up a basic\ntransformation matrix bringing the cube its current state. After that the state machines\ndecides on how to additionally apply the current valid angels on the worlds X and Z\nrotations. This matrix, applied to an arbitrary geometry would now transform the\nstructure according to the real cube\u2019s rotation state. Eventually the final transforma-\ntion matrix, the underlying raw and the average arrays are offered via the driver inter-\nface. Additional an event engine analyses the average history and calculates noise-\nlevel over a range of one hundred values. By also considering the calibrated sensor\ndata it can decide, if the cube is lying on a plain object and fire the according events\nwhen it enters or leaves this state.\n4.3   Screen Interface and Visualization\nThe Screen Interface generally consists of three software parts and a screen device.\nThe input module access the data provided by the driver and forwards it to the pro-\ngram logic. Depending on the occurred events it chooses either full screen or zapping\nmode and additionally updates a global transformation matrix that is later used by the\ngraphics engine to calculate the virtual cube. The program logic also assigns the six\nvideo sources that are for now just static.\nA parallel thread renders the videos in the background and derives ready textures\nto be used in the final scene. To perform the final drawing we rely on the graphics\nengines 3D capabilities. It uses the transformation matrix, updated by the data acqui-\nsition thread, to calculate the virtual cube\u2019s geometry. Finally the different textures\nare accordingly projected onto the different sides. This is rendered into a three-\ndimensional environment covered by a two-dimensional descriptive layer containing\ninstructional information.\nAdditional, each sign of the cube is numbered according to the real cubes enu-\nmeration. This is a helpful tool for recalibration as it shows the Y-rotation the state\nmachine is currently assuming. An aberration of the real cube and the virtual cube\nthus indicates a mis-calibration.\nThe graphics engine uses Microsoft\u2019s DirectX because it supports existing hard-\nware accelerators as well as various types of audio and video formats. Possible video-\nsources are all Windows-Media supported local or streamed file types like .AVI,\nTowards a Playful User Interface for Home Entertainment Systems         215\n.MPEG, .ASF or .WMV. To provide TV life feed we have one stream available for\neach channel. Depending on the used graphics hardware, the final presentation can be\noutput to all supported display types and resolutions.\n4.4   Usage of the System\nThe user interaction with the interface is quite simple: The TV is turned on and as\nusual a channel is showing. The cube is lying next to the device and can be picked up\nat any time. As soon as this happens, the currently showing channel is scaled down\nrevealing the three-dimensional environment including the virtual cube and after-\nwards snaps on the side that it is assigned to. Now the screen of Figure 7 is showing\nand the cube is reaction on the user\u2019s input. As the user rotates the real cube to a new\nposition new live streams are shown. By this she is able to see up to three videos at\nthe same time. The user is has the option to preview the adjoining sides by navigating\nto the next destination. Assuming that the user\u2019s goal is to bring her favoured media\nto the front position (which is the best visible one) the program-logic considers it as\nthe user\u2019s selection. There is also no change of that side if the user lies the cube down,\nconsequently the selected media stays in focus. Based on that assumption the applica-\ntion chooses the front media to be enlarged to full screen as soon as the user puts the\ncube back on a surface. The user can repeat they this procedure as often as she wants.\nFig. 7. A user exploring the cube interface by interacting with a large screen television.\n216         F. Block et al.\n5    User Feedback on the Prototype and Discussion\nAfter finalizing the prototype we asked 6 users to casually explore the system. In this\nphase we were in particular interested in potential problems that occur when using the\nsystem.\nOne problem that became quickly obvious is the missing capability to sense the\nthird angle due to the sensor system used and due to the fact that the sensing is related\nto gravity. The experience for the user is significantly different for motions in differ-\nent direction. In two directions the reaction of the virtual counterpart is very direct\nand immediate, whereas the coupling in the third dimension is very rough (as de-\nscribed above). This different behaviour conflicts with the user\u2019s intuitive under-\nstanding of the connection between the real and the virtual cube.\nHowever having one dimension that does not respond immediate also introduced a\ncertain degree of freedom to the usage. In our sessions we recognized that users fa-\ncilitate this as a feature. By relying on the system to ignore a limited Y roation the\nuser can reset a position \u2013 this is similar to lifting a mouse for readjusting it into a\nmore comfortable place without manipulation in the virtual space.\nA further issue that we investigated was the fact that we had to decide what infor-\nmation (channels) to put on the limited number of faces on the cube. There was not\nfinal conclusion but several options seem appropriate depending on the user and the\nenvironment. One approach is to give the user the opportunity to freely assign the\nsites with her favourite channels. Another strategy would be to randomly assign TV-\nChannels to the sides and exchanging them on the fly as soon as they are rotated to a\nnon-visible state. This is more related to the idea of a playful interaction.\nSimilar to the feature image-in-image the cube shows more than one stream at the\ntime. This is similar to a feature more and more TV-devices have namely the possi-\nbility to add a little window of another channel in one of the full screen\u2019s corners and\nbe able to quickly switch between them. In this respect the cube interface offers more\noptions as there are up to 3 channels on at once and further 3 are quickly available.\nThe overall user feedback was that the user interface provides a intuitive and more\nplayful user interface to a TV, even with the limitations mentioned above.\n6    Conclusion\nIn this paper we presented the idea, the concept, implementation, and initial user\nfeedback on a new interface for a TV. We explored different types of potential de-\nvices that can be used as a tangible UI and decided to use a cube because of the affor-\ndances given and the clear mapping to visualization.\nThe implementation consists of several parts: a tangible UI that is wirelessly con-\nnected to the system on which the visualization is realized. To acquire information\nabout the user\u2019s manipulation of the interface a unit sensing four axis of acceleration\nis used. The acceleration values are converted and used to move the visual represen-\ntation of the screen.\nInitial user feedback suggests that having user interfaces that are effective and\nplayful can create a good user experience. In cases such as watching TV providing a\nTowards a Playful User Interface for Home Entertainment Systems         217\nplayful experience can be more important than pure efficiency. Currently we are\nimproving the sensor system based on the initial feedback and plan for a larger user\nstudy.\nAcknowledgement. The research presented in this paper is joint work between the\nEmbedded Interaction Group at University of Munich and the Computing Department\nat Lancaster University. The work at Munich is funded by the German Research\nFoundation (DFG). The Lancaster contribution is supported by the EPSRC as part of\nthe Equator IRC.\nReferences\n1. T. Lashina, F. Vignoli, V. Buil, S. van de Wijdeven, G. Hollemans, J. Hoonhout. The\nContext Aware Personal Remote Control: A Case Study on Context Awareness. 23rd In-\nternational Conference on Distributed Computing Systems Workshops (ICDCSW'03).\n2. Jeffrey Nichols, Brad A. Myers, Michael Higgins, Joe Hughes, Thomas K. Harris, Roni\nRosenfeld, Mathilde Pignol. \"Generating Remote Control Interfaces for Complex Appli-\nances.\" CHI Letters: ACM Symposium on User Interface Software and Technology,\nUIST'02, 27-30 Oct. 2002, Paris, France. pp. 161-170.\n3. Bill Gaver. Designing for Ludic Aspects of Everyday Life. Special Issue on Ambient\nIntelligence. ERCIM News No.47, October 2001.\n4. Andreas Butz, Markus Gro\u00df and Antonio Kr\u00fcger: \"TUISTER: a Tangible UI for Hierar-\nchical Structures\", in Proceedings of IUI 2004, January 13-16, 2004, Madeira, Funchal,\nPortugal.\n5. H. Gellersen, G. Kortuem, M. Beigl and A. Schmidt. Physical Prototyping with Smart-Its.\nIEEE Pervasive Computing Magazin (2004, accepted for publication).\n6. L. E. Holmquist, H.-W. Gellersen, A. Schmidt, M. Strohbach, G. Kortuem, S. Antifakos,\nF. Michahelles, B. Schiele, M. Beigl, R. Maz\u00e9. Building Intelligent Environments with\nSmart-Its. IEEE Computer Graphics & Applications. January\/February 2004 (Vol. 24, No.\n1), pp. 56-64.\n7. MIT Media lab. Responsive Environments Group. 3X Inertial Measurement Unit Project.\nhttp:\/\/www.media.mit.edu\/resenv\/imu\/ (page visited May 2004).\n8. Lancaster University. Smart-Its technical information. Wiki-Web. Page visited May 2005.\nhttp:\/\/ubicomp.lancs.ac.uk\/twiki\/bin\/viewauth\/Smartits\/WebHome (anonymous login as\nuser TWikiGuest with password guest).\n9. H. Rodjegard, G. Andersson. Design optimization of three-axis accelerometers based on\nfour seismic masses. Proceedings of IEEE Sensors, 2002. Vol 2. Pages: 1099- 1104\n10. K. Van Laerhoven, N. Villar, A. Schmidt, G. Kortuem and H.-W. Gellersen. Using an\nAutonomous Cube for Basic Navigation and Input. ICMI\/PUI 2003. ACM Press. Van-\ncouver, Canada. November 2003, pp. 203-211.\n"}
{"doi":"10.1515\/MCMA.2011.012","coreId":"197716","oai":"oai:lra.le.ac.uk:2381\/9974","identifiers":["oai:lra.le.ac.uk:2381\/9974","10.1515\/MCMA.2011.012"],"title":"Exact discrete sampling of finite variation tempered stable Ornstein-Uhlenbeck processes","authors":["Kawai, Reiichiro","Masuda, Hiroki"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2011","abstract":"Exact yet simple simulation algorithms are developed for a wide class of Ornstein\u2013Uhlenbeck processes with tempered stable stationary distribution of finite variation with the help of their exact transition probability between consecutive time points. Random elements involved can be divided into independent tempered stable and compound Poisson distributions, each of which can be simulated in the exact sense through acceptance-rejection sampling, respectively, with stable and gamma proposal distributions. We discuss various alternative simulation methods within our algorithms on the basis of acceptance rate in acceptance-rejection sampling for both high- and low-frequency sampling. Numerical results illustrate their advantage relative to the existing approximative simulation method based on infinite shot noise series representation.Peer-reviewedPublisher Versio","downloadUrl":"http:\/\/hdl.handle.net\/2381\/9973","fullTextIdentifier":"https:\/\/lra.le.ac.uk\/bitstream\/2381\/9974\/2\/tsousim_publish.pdf","pdfHashValue":"1742aee358436df827c96dfb1b341297557468a1","publisher":"de Gruyter","rawRecordXml":"<record><header><identifier>\n        \n            \n                oai:lra.le.ac.uk:2381\/9974<\/identifier><datestamp>\n                2012-08-29T01:45:05Z<\/datestamp><setSpec>\n                com_2381_445<\/setSpec><setSpec>\n                com_2381_9549<\/setSpec><setSpec>\n                col_2381_3823<\/setSpec>\n            <\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:doc=\"http:\/\/www.lyncode.com\/xoai\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n            \nExact discrete sampling of finite variation tempered stable Ornstein-Uhlenbeck processes<\/dc:title><dc:creator>\nKawai, Reiichiro<\/dc:creator><dc:creator>\nMasuda, Hiroki<\/dc:creator><dc:subject>\nAcceptance-rejection sampling<\/dc:subject><dc:subject>\nhigh-frequency sampling<\/dc:subject><dc:subject>\nL\u00e9vy process<\/dc:subject><dc:subject>\nOrnstein\u2013Uhlenbeck process<\/dc:subject><dc:subject>\ntransition probability<\/dc:subject><dc:subject>\ntempered stable process<\/dc:subject><dc:subject>\nsubordinator<\/dc:subject><dc:description>\nExact yet simple simulation algorithms are developed for a wide class of Ornstein\u2013Uhlenbeck processes with tempered stable stationary distribution of finite variation with the help of their exact transition probability between consecutive time points. Random elements involved can be divided into independent tempered stable and compound Poisson distributions, each of which can be simulated in the exact sense through acceptance-rejection sampling, respectively, with stable and gamma proposal distributions. We discuss various alternative simulation methods within our algorithms on the basis of acceptance rate in acceptance-rejection sampling for both high- and low-frequency sampling. Numerical results illustrate their advantage relative to the existing approximative simulation method based on infinite shot noise series representation.<\/dc:description><dc:description>\nPeer-reviewed<\/dc:description><dc:description>\nPublisher Version<\/dc:description><dc:date>\n2011-12-19T10:24:44Z<\/dc:date><dc:date>\n2011-12-19T10:57:09Z<\/dc:date><dc:date>\n2012-08-29T01:45:05Z<\/dc:date><dc:date>\n2011<\/dc:date><dc:type>\nJournal Article<\/dc:type><dc:type>\nArticle<\/dc:type><dc:identifier>\nMonte Carlo Methods and Applications, 2011, 17 (3), pp. 279-300.<\/dc:identifier><dc:identifier>\n0929-9629<\/dc:identifier><dc:identifier>\nhttp:\/\/www.reference-global.com\/loi\/mcma<\/dc:identifier><dc:identifier>\nhttp:\/\/hdl.handle.net\/2381\/9974<\/dc:identifier><dc:identifier>\n10.1515\/MCMA.2011.012<\/dc:identifier><dc:identifier>\n1569-3961<\/dc:identifier><dc:language>\nen<\/dc:language><dc:relation>\nhttp:\/\/hdl.handle.net\/2381\/9973<\/dc:relation><dc:relation>\n2381\/9973<\/dc:relation><dc:rights>\nCopyright \u00a9 de Gruyter 2011.<\/dc:rights><dc:publisher>\nde Gruyter<\/dc:publisher>\n<\/oai_dc:dc>\n<\/metadata>\n        <\/record>","journals":[{"title":null,"identifiers":["issn:1569-3961","0929-9629","1569-3961","issn:0929-9629"]}],"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/hdl.handle.net\/2381\/9973","2381\/9973"],"year":2011,"topics":["Acceptance-rejection sampling","high-frequency sampling","L\u00e9vy process","Ornstein\u2013Uhlenbeck process","transition probability","tempered stable process","subordinator"],"subject":["Journal Article","Article"],"fullText":"Monte Carlo Methods Appl. 17 (2011), 279\u2013300\nDOI 10.1515\/MCMA.2011.012 \u00a9 de Gruyter 2011\nExact discrete sampling of finite variation tempered\nstable Ornstein\u2013Uhlenbeck processes\nReiichiro Kawai and Hiroki Masuda\nAbstract. Exact yet simple simulation algorithms are developed for a wide class of Orn-\nstein\u2013Uhlenbeck processes with tempered stable stationary distribution of finite varia-\ntion with the help of their exact transition probability between consecutive time points.\nRandom elements involved can be divided into independent tempered stable and com-\npound Poisson distributions, each of which can be simulated in the exact sense through\nacceptance-rejection sampling, respectively, with stable and gamma proposal distribu-\ntions. We discuss various alternative simulation methods within our algorithms on the ba-\nsis of acceptance rate in acceptance-rejection sampling for both high- and low-frequency\nsampling. Numerical results illustrate their advantage relative to the existing approxima-\ntive simulation method based on infinite shot noise series representation.\nKeywords. Acceptance-rejection sampling, high-frequency sampling, L\u00e9vy process, Orn-\nstein\u2013Uhlenbeck process, subordinator, transition probability, tempered stable process.\n2010 Mathematics Subject Classification. 68U20, 62E15, 65C10, 60E07.\n1 Introduction\nThe class of non-Gaussian Ornstein\u2013Uhlenbeck processes has long been of both\ntheoretical and practical interest. From a theoretical point of view, on one hand,\nthis class is closely related to the self-decomposable infinitely divisible distribu-\ntion. Several interesting properties are known, such as the explicit relation between\nthe L\u00e9vy measures of the stationary distribution and the underlying L\u00e9vy process\nand the representation of entire trajectory using the series representation of under-\nlying L\u00e9vy process, to mention just a few. (For details, see Section 17 of Sato [21],\nMasuda [18] and references therein.) On the other hand, in practice, non-Gaussian\nOrnstein\u2013Uhlenbeck processes have been used in mathematical physics under the\nname of exponentially correlated colored noise, and more recently in financial\neconomics and mathematical finance (for example, Barndorff-Nielsen and Shep-\nhard [3,4] and Benth et al. [5]). Due to the growing practical interest, many authors\nhave proposed statistical inference methods for non-Gaussian Ornstein\u2013Uhlenbeck\nprocesses. (See, for example, Brockwell et al. [7] and Jongbloed et al. [13].)\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n280 R. Kawai and H. Masuda\nThe main purpose of this paper is to develop and investigate exact simulation\nalgorithms for a wide class of Ornstein\u2013Uhlenbeck processes of finite variation\nwith tempered stable stationary laws. In particular, the flexibility and mathemati-\ncal tractability of the tempered stable distribution makes this class more attractive\nthan the other classes of Ornstein\u2013Uhlenbeck processes. It is well known that the\nexact simulation of its entire trajectory over a finite horizon is only possible, in\nprinciple, with the infinite series representation of tempered stable L\u00e9vy processes.\n(See, for example, Barndorff-Nielsen and Shephard [3,4] and Rosin\u00b4ski [20].) This\nmethod often requires extremely expensive computing effort, especially when the\nconvergence of the infinite series is very slow. In addition, simulation via the se-\nries representation is no longer an exact method as soon as the infinite sum is\ntruncated. The exact simulation algorithm we develop in this paper is designed\nto generate arbitrary discrete time skeleton of the trajectory. Thanks to the homo-\ngeneous Markovian autoregressive structure of Ornstein\u2013Uhlenbeck processes, its\ntransition probability between consecutive times can be derived in closed form,\nin a similar manner to Zhang and Zhang [23, 24]. Random elements involved can\nbe divided into independent tempered stable and compound Poisson components,\neach of which can be simulated exactly with acceptance-rejection sampling, re-\nspectively, with non-tempered stable and gamma proposal distributions. It turns\nout that our approach is easily applicable to the settings of bilateral tempered\nstable Ornstein\u2013Uhlenbeck processes of finite variation and of normal tempered\nstable processes as well.\nThe rest of this paper is organized as follows. Section 2 summarizes back-\nground material on stable and tempered stable subordinators and on tempered\nstable Ornstein\u2013Uhlenbeck processes. In Section 3, we derive the exact transi-\ntion probability consisting of independent tempered stable and compound Poisson\ncomponents. In Section 4, acceptance-rejection sampling methods are discussed\nfor tempered stable and compound Poisson distributions for different sampling fre-\nquencies. In particular, we discuss various alternative simulation methods within\nour algorithms on the basis of acceptance rate in acceptance-rejection sampling.\nWe provide in Section 5 numerical results to illustrate the effectiveness of our ex-\nact simulation algorithms relative to the existing approximative method based on\ninfinite series representation. Finally, Section 6 concludes.\n2 Preliminaries\nLet us begin this preliminary section with the notation which will be used through-\nout the paper. We denote by R the one dimensional Euclidean space with the norm\nj \u0001 j, RC WD .0;C1\/ and R\u0000 WD .\u00001; 0\/. Let N be the collection of positive\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 281\nintegers with N0 WD N [ \u00b90\u00ba. We denote by L.X\/ and LD, respectively, the law\nof random variable X and identity in law. We denote by \u0080.a; b\/ the gamma dis-\ntribution with density ba=\u0080.a\/xa\u00001e\u0000bx . We fix .;F ;P \/ as our underlying\nprobability space. We say that the stochastic process \u00b9Yt W t \u0015 0\u00ba in R is a sub-\nordinator (without drift) if it is a non-decreasing L\u00e9vy process with characteristic\nfunction\nE\nh\neiyYt\ni\nD exp\n\"\nt\nZ\nRC\n\u0010\neiyz \u0000 1\n\u0011\n\u0017.dz\/\n#\n; (2.1)\nwhere \u0017 is a L\u00e9vy measure defined on RC satisfying\nR 1\n0 z\u0017.dz\/ < C1. Finally,\nlet us note that \u0080.\u0000s\/ < 0 for s 2 .0; 1\/.\n2.1 Stable subordinator\nLet \u00b9L.s\/t W t \u0015 0\u00ba be a stable subordinator with characteristic function\nE\nh\neiyL\n.s\/\nt\ni\nD exp\n\"\nt\nZ\nRC\n\u0010\neiyz \u0000 1\n\u0011 a\nz\u02dbC1\ndz\n#\nD exp\nh\nta\u0080.\u0000\u02db\/ cos\n\u0010\u0019\u02db\n2\n\u0011\njyj\u02db\n\u0010\n1\u0000 i tan \u0019\u02db\n2\nsgn.y\/\n\u0011i\n;\n(2.2)\nwith \u02db 2 .0; 1\/ and a > 0. Note that a only acts as a scale parameter. For each\nt > 0, the marginal L.s\/t has a stable distribution on RC and E\u0152.L\n.s\/\nt \/\n\u0012 \u008d is finite if\n\u0012 2 .0; \u02db\/, while is infinite if \u0012 \u0015 \u02db. Throughout this paper, we denote by S.\u02db; a\/\nthe distribution of L.s\/1 when (2.2) is satisfied. Clearly, it holds that for each t > 0,\nL.L\n.s\/\nt \/ D S.\u02db; ta\/. The distribution S.\u02db; a\/ can be simulated in the exact sense\nthrough the well known representation, due to Kanter [14] and Chambers et al. [8],\nS.\u02db; a\/\nLD\n\u0012\na\u0080.1 \u0000 \u02db\/\n\u02db cos.V \/\n\u0013 1\n\u02db\nsin.\u02db.V C \u0019=2\/\/\n\u0012\ncos .V \u0000 \u02db .V C \u0019=2\/\/\nE\n\u0013 1\u0000\u02db\n\u02db\n;\n(2.3)\nwhere V is a uniform random variable on .\u0000\u0019=2; \u0019=2\/ and E is a standard expo-\nnential random variable independent of V . The distribution S.\u02db; a\/ admits C1-\ndensity on RC given in form of convergent series\nfS.\u02db;a\/.x\/ WD\n1\n\u0019.\u0000a\u0080.\u0000\u02db\/\/1=\u02db\n\u0002\nC1X\nkD1\n.\u00001\/k\u00001 sin.k\u0019\u02db\/\u0080.k\u02db C 1\/\nk\u0160\n\u0012\nx\n.\u0000a\u0080.\u0000\u02db\/\/1=\u02db\n\u0013\u0000k\u02db\u00001\n:\n(2.4)\nSee Zolotarev [25] for more details on the stable distribution.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n282 R. Kawai and H. Masuda\n2.2 Tempered stable subordinator\nConsider the exponentially tempered stable L\u00e9vy density\nv.z\/ D a e\n\u0000bz\nz\u02dbC1\n; z 2 RC; (2.5)\nwhere a > 0, b > 0 and \u02db 2 .0; 1\/. The associated subordinator\n\u00b9L.ts\/t W t \u0015 0\u00ba\n(without drift) is often called the tempered stable subordinator, with characteristic\nfunction\nE\nh\neiyL\n.ts\/\nt\ni\nD exp\n\"\nt\nZ\nRC\n\u0010\neiyz \u0000 1\n\u0011\nv.z\/dz\n#\nD exp \u0002ta\u0080.\u0000\u02db\/ \u0000.b \u0000 iy\/\u02db \u0000 b\u02db\u0001\u0003 : (2.6)\nThroughout this paper, we denote by TS.\u02db; a; b\/ the distribution of L.ts\/1 defined\non RC, which we call tempered stable distribution, when (2.6) is satisfied. Clearly,\nit holds that for each t > 0,\nL.L\n.ts\/\nt \/ D TS.\u02db; ta; b\/:\nThe tempered stable distribution admits C1-density on RC as well, with a simple\nyet very insightful relation to the density of its non-tempered stable distribution\nfTS.\u02db;a;b\/.x\/ WD e\u0000bx\u0000a\u0080.\u0000\u02db\/b\n\u02db\nfS.\u02db;a\/.x\/: (2.7)\nThis property acts as a key building block later. The class of tempered stable dis-\ntributions is first proposed by Tweedie [22]. Barndorff-Nielsen and Shephard [4]\nstudies the tempered stable subordinator and the so-called normal tempered stable\nlaw, that is, a normal variance-mean mixture of the positive tempered stable dis-\ntribution, with a view towards financial economics. Various featuring properties of\ntempered stable processes are revealed by Rosin\u00b4ski [20], such as a stable-like be-\nhavior over short intervals, the absolute continuity with respect to its short-range\nlimiting stable subordinator (Proposition 4.1), aggregational Gaussianity and an\ninfinite series representation in closed form\u00b0\nL\n.ts\/\nt W t 2 \u01520; T \u008d\n\u00b1\nLD\n\u00b4C1X\nkD1\n\"\u0012\n\u02db\u0080k\naT\n\u0013\u00001=\u02db\n^ VkU\n1=\u02db\nk\nb\n#\n1.Tk 2 \u01520; t \u008d\/ W t 2 \u01520; T \u008d\n\u00b5\n;\n(2.8)\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 283\nwhich was first introduced by Rosin\u00b4ski in the discussion part of Barndorff-Nielsen\nand Shephard [3]. Here, \u00b9\u0080k\u00bak2N denotes a sequence of standard Poisson arrivals,\n\u00b9Tk\u00bak2N is a sequence of iid uniform random variables on \u01520; T \u008d, \u00b9Vk\u00bak2N is a\nsequence of iid standard exponential random variables and \u00b9Uk\u00bak2N is a sequence\nof iid uniform random variables on \u01520; 1\u008d. All those random sequences are mutually\nindependent. Note that the kernel of series representation is not unique. (See Imai\nand Kawai [11, 12] for different representations and numerical issues.)\n2.3 Ornstein\u2013Uhlenbeck Processes with tempered stable\nstationary distribution\nConsider the stochastic process \u00b9Yt W t \u0015 0\u00ba defined in form of stochastic differ-\nential equation\ndYt D \u0000\u0015Ytdt C dZ\u0015t ; (2.9)\nwhere \u0015 > 0 and \u00b9Zt W t \u0015 0\u00ba is a subordinator, or in canonical form\nYt D e\u0000\u0015tY0 C e\u0000\u0015t\nZ \u0015t\n0\nesdZs : (2.10)\nThe process of this type is called a L\u00e9vy-driven Ornstein\u2013Uhlenbeck process and\nis used, for example, to model the squared volatility in a stochastic volatility model\n(Barndorff-Nielsen and Shephard [3]).\nThe L\u00e9vy density (2.5) forms a self-decomposable L\u00e9vy measure. By the ar-\nguments in Section 17 of Sato [21], there exists an Ornstein\u2013Uhlenbeck process\n\u00b9Yt W t \u0015 0\u00ba whose marginal has the infinitely divisible distribution with the tem-\npered stable L\u00e9vy density (2.5), if the initial state Y0 is chosen to have the same\ndistribution to the stationary infinitely divisible distribution. In particular, the Orn-\nstein\u2013Uhlenbeck process with inverse Gaussian stationary marginal (\u02db D 1=2)\nis often abbreviated to IG-OU and is applied in Benth [5] to stochastic volatility\nmodeling of [3] for volatility and variance swap valuations.\nLet w.z\/ be the L\u00e9vy density of the marginal Z1 and let u.z\/ be the L\u00e9vy den-\nsity of the stationary marginal Y1. If u.z\/ is differentiable, then the L\u00e9vy densities\nw.z\/ and u.z\/ are related as\nw.z\/ D \u0000u.z\/ \u0000 z @\n@z\nu.z\/ D a\n\u0010\u02db\nz\nC b\n\u0011 e\u0000bz\nz\u02db\n: (2.11)\nThis implies that the underlying subordinator \u00b9Zt W t \u0015 0\u00ba is the superposition of\na tempered stable subordinator and a compound Poisson process. With the help of\nthe infinite shot noise series representation (2.8) of tempered stable subordinators,\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n284 R. Kawai and H. Masuda\nwe can formulate sample paths as\n\u00b9Yt W t 2 \u01520; T \u008d\u00ba\nLD\n\u00b4\ne\u0000\u0015tY0 C\nC1X\nkD1\ne\u0015.Tk\u0000t\/\n\"\u0012\n\u0080k\naT\n\u0013\u00001=\u02db\n^ VkU\n1=\u02db\nk\nb\n#\n1 .Tk 2 \u01520; t \u008d\/\nC\nC1X\nkD1\ne\ne\u0080k\u0000\u0015tGk1 \u0000e\u0080k 2 \u01520; \u0015t \u008d\u0001 W t 2 \u01520; T \u008d\n\u00b5\n;\n(2.12)\nwhere \u00b9e\u0080k\u00bak2N is a sequence of Poisson arrivals with intensity a\u0080.1 \u0000 \u02db\/b\u02db,\nindependent of \u00b9\u0080k\u00bak2N , and \u00b9Gk\u00bak2N is a sequence of iid random variables with\ngamma distribution \u0080.1 \u0000 \u02db; b\/.\nIn fact, we can readily extend to the bilateral finite variation setting by super-\npositioning two independent subordinators in the opposite directions, by setting\nZt WD ZCt \u0000 Z\u0000t in the definition (2.9) or (2.10), where \u00b9Z t\u02d9 W t \u0015 0\u00ba are inde-\npendent subordinators with suitable laws. This setting will be considered in Corol-\nlary 3.2.\n3 Exact transition probability\nThe main purpose of this paper is to develop an exact simulation algorithm for\narbitrary discrete time skeleton\nY0; Y\u0081; Y2\u0081; : : : ;\nof the tempered stable Ornstein\u2013Uhlenbeck process (2.9), with a positive step-\nsize \u0081. (In principle, discrete observations do not need to be equidistant. Stepsizes\ncan be set different positive values for different steps.) To this end, we first provide\nthe exact transition probability of the random sequence \u00b9Yk\u0081\u00bak2N0 , due to Zhang\nand Zhang [24]. For completeness, we also outline its proof.\nTheorem 3.1. For each n 2 N0, it holds that given Yn\u0081,\nY.nC1\/\u0081\nLD e\u0000\u0015\u0081Yn\u0081 C \u00110.\u0081\/C\nN.\u0081\/X\nkD1\n\u0011k.\u0081\/;\nwhere N.\u0081\/ and \u00110.\u0081\/; \u00111.\u0081\/; : : : are independent random variables specified\nas follows:\n\u000f \u00110.\u0081\/ \u0018 TS.\u02db; a.1 \u0000 e\u0000\u02db\u0015\u0081\/; b\/.\n\u000f N.\u0081\/ denotes the Poisson random variable with intensity\n\u0000a.1 \u0000 e\u0000\u02db\u0015\u0081\/\u0080.\u0000\u02db\/b\u02db :\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 285\n\u000f \u00b9\u0011k.\u0081\/\u00bak2N is a sequence of iid random variables with common probability\ndensity\nv\u0081.x\/ WD\n1\n.1 \u0000 e\u02db\u0015\u0081\/\u0080.\u0000\u02db\/b\u02db x\n\u00001\u0000\u02db\n\u0010\ne\u0000bx \u0000 e\u0000be\u0015\u0081x\n\u0011\n; x 2 RC: (3.1)\nProof. By the homogeneous Markovian autoregressive structure of (2.10), it holds\nthat for each n 2 N0,\nY.nC1\/\u0081 D e\u0000\u0015\u0081Yn\u0081 C\nZ .nC1\/\u0081\nn\u0081\ne\u0000\u0015..nC1\/\u0081\u0000s\/dZ\u0015s\nDW e\u0000\u0015\u0081Yn\u0081 C \u000f\u0081;nC1\nLD e\u0000\u0015\u0081Yn\u0081 C\nZ \u0015\u0081\n0\ne\u0000\u0015\u0081CsdZs ;\nwhere the identity in law holds by independence and stationarity of increments of\nthe underlying subordinator \u00b9Zt W t \u0015 0\u00ba. This implies that \u00b9\u000f\u0081;k\u00bak2N is simply\na sequence of iid random variables with common distribution\nF\u0081 WD L\n\u0012Z \u0015\u0081\n0\ne\u0000\u0015\u0081CsdZs\n\u0013\n:\nIt thus suffices to investigate the conditional distribution L.Y\u0081jY0\/ of the first\nincrement. Note that by definition, this distribution is infinitely divisible.\nLet w.z\/ be the L\u00e9vy density of Z1 given by (2.11). By the L\u00e9vy-integral trans-\nform of the characteristic function, we get\nln E\nh\neiy\u000f\u0081;1\ni\nD\nZ \u0015\u0081\n0\nln E\nh\neiye\n\u0000\u0015\u0081CsZ1\ni\nds\nD\nZ\nRC\n\u0010\neiyz \u0000 1\n\u0011\u0012Z \u0015\u0081\n0\nesw\n\u0000\nesz\n\u0001\nds\n\u0013\ndz\nDW\nZ\nRC\n\u0010\neiyz \u0000 1\n\u0011\nw\u0081.z\/dz:\nNote that w\u0081.z\/ indicates the L\u00e9vy density of the distribution F\u0081. Observe that\nfor each z 2 RC,\nw\u0081.z\/ D az\u00001\u0000\u02db\nZ \u0015\u0081\n0\n\u0000\n\u02db C besz\u0001 e\u0000\u02dbse\u0000beszds\nD az\u00001\u0000\u02db\n\u0010\ne\u0000bz \u0000 e\u0000\u02db\u0015\u0081e\u0000be\u0015\u0081z\n\u0011\nD a\n\u0010\n1\u0000 e\u0000\u02db\u0015\u0081\n\u0011\nz\u00001\u0000\u02dbe\u0000bz C ae\u0000\u02db\u0015\u0081z\u00001\u0000\u02db\n\u0010\ne\u0000bz \u0000 e\u0000be\u0015\u0081z\n\u0011\nDW w\u0081;1.z\/C w\u0081;2.z\/;\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n286 R. Kawai and H. Masuda\nwhere the second equality holds by\n.@=@s\/.\u0000e\u0000\u02dbse\u0000besz\/ D .\u02db C besz\/e\u0000\u02dbse\u0000besz :\nClearly, the function w\u0081;1.z\/ is the L\u00e9vy density of TS.\u02db; a.1\u0000e\u0000\u02db\u0015\u0081\/; b\/. More-\nover, since Z\nRC\nw\u0081;2.z\/dz D a\n\u0010\ne\u0000\u02db\u0015\u0081 \u0000 1\n\u0011\n\u0080.\u0000\u02db\/b\u02db < C1;\nthe function w\u0081;2.z\/ acts as the L\u00e9vy density of the compound Poisson compo-\nnent. This completes the proof.\nLet us below describe a direct extension to the bilateral finite variation setting.\nWe omit the proof to avoid overloading the paper with lengthy details of routine\nnature.\nCorollary 3.2. For each n 2 N0, it holds that given Yn\u0081,\nY.nC1\/\u0081\nLD e\u0000\u0015\u0081Yn\u0081 C \u0011C0 .\u0081\/C\nNC.\u0081\/X\nkD1\n\u0011C\nk\n.\u0081\/\u0000 \u0011\u00000 .\u0081\/C\nN\u0000.\u0081\/X\nkD1\n\u0011\u0000k .\u0081\/;\nwhere NC.\u0081\/, N\u0000.\u0081\/, \u0011C0 .\u0081\/; \u0011\nC\n1 .\u0081\/; : : : , \u0011\n\u0000\n0 .\u0081\/; \u0011\n\u0000\n1 .\u0081\/; : : : are mutually in-\ndependent random variables specified as follows:\n\u000f we have\n\u0011C0 .\u0081\/ \u0018 TS.\u02dbC; aC.1\u0000 e\u0000\u02dbC\u0015\u0081\/; bC\/\nand\n\u0011\u00000 .\u0081\/ \u0018 TS.\u02db\u0000; a\u0000.1 \u0000 e\u0000\u02db\u0000\u0015\u0081\/; b\u0000\/:\n\u000f NC.\u0081\/ and N\u0000.\u0081\/ are Poisson random variables with intensities\naC.e\u0000\u02dbC\u0015\u0081 \u0000 1\/\u0080.\u0000\u02dbC\/b\u02dbCC and a\u0000.e\u0000\u02db\u0000\u0015\u0081 \u0000 1\/\u0080.\u0000\u02db\u0000\/b\u02db\u0000\u0000 ;\nrespectively.\n\u000f \u00b9\u0011C\nk\n.\u0081\/\u00bak2N and \u00b9\u0011\u0000k .\u0081\/\u00bak2N are sequences of iid random variables with\ncommon probability densities\nvC\u0081.x\/ WD\n1\n.1 \u0000 e\u02dbC\u0015\u0081\/\u0080.\u0000\u02dbC\/b\u02dbCC\nx\u00001\u0000\u02dbC\n\u0010\ne\u0000bCx \u0000 e\u0000bCe\u0015\u0081x\n\u0011\nfor x 2 RC, and\nv\u0000\u0081.x\/ WD\n1\n.1 \u0000 e\u02db\u0000\u0015\u0081\/\u0080.\u0000\u02db\u0000\/b\u02db\u0000\u0000\njxj\u00001\u0000\u02db\u0000\n\u0010\ne\u0000b\u0000jxj \u0000 e\u0000b\u0000e\u0015\u0081jxj\n\u0011\nfor x 2 R\u0000, respectively.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 287\n4 Exact simulation using acceptance-rejection sampling\nDue to the exact transitions of Theorem 3.1 and Corollary 3.2, the exact simulation\nof random elements involved enables one to simulate exactly the discrete time\nskeleton \u00b9Yk\u0081\u00bak2N in a recursive manner. Random elements to be generated are\nthe tempered stable random variable \u00110.\u0081\/ and the random variables N.\u0081\/ and\n\u00b9\u0011k.\u0081\/\u00bak2N in the compound Poisson component.\nLet us begin with the exact simulation of \u00110.\u0081\/ \u0018 TS.\u02db; a.1 \u0000 e\u0000\u02db\u0015\u0081\/; b\/.\nAn efficient exact simulation method for the case \u02db D 0:5, that is the inverse\nGaussian, is well known due to Michael et al. [19]. For the general case \u02db 2 .0; 1\/,\na straightforward approach would be to apply acceptance-rejection sampling based\non the representation (2.3) of the stable distribution and the ratio (2.7) of the two\ndensities, that is, for each x 2 RC,\nfTS.\u02db;a;b\/.x\/\nfS.\u02db;a\/.x\/\nD e\u0000bx\u0000a\u0080.\u0000\u02db\/b\u02db \u0014 e\u0000a\u0080.\u0000\u02db\/b\u02db : (4.1)\n(See, for example, Brix [6].) The acceptance-rejection sampling algorithm for gen-\neration of the random variable \u00110.\u0081\/ is then as simple as\nAlgorithm 1.\nStep 1 Generate U as uniform .0; 1\/ and V as S.\u02db; a.1\u0000 e\u0000\u02db\u0015\u0081\/\/ through (2.3).\nStep 2 If U \u0014 e\u0000bV , let \u00110.\u0081\/ V . Otherwise, return to Step 1.\nNote that this algorithm clearly works more efficiently when the acceptance\nrate ea.1\u0000e\u0000\u02db\u0015\u0081\/\u0080.\u0000\u02db\/b\u02db at Step 2 is closer to 1. This happens when b # 0 and\/or\n\u0081 # 0. The case b # 0 is obvious since then the tempered stable distribution ap-\nproaches to its stable proposal distribution. In practice, we only have control on\nthe time interval \u0081. To account for the case \u0081 # 0, we employ the short-range\nbehavior of tempered stable subordinators, which is rigorously proved first by\nRosin\u00b4ski [20].\nProposition 4.1. Let \u00b9L.s\/t W t \u0015 0\u00ba and \u00b9L.ts\/t W t \u0015 0\u00ba be L\u00e9vy processes respec-\ntively with S.\u02db; a\/ and TS.\u02db; a; b\/. It holds that as h # 0, h > 0,\u00b0\nh\u00001=\u02dbL.ts\/\nht\nW t \u0015 0\n\u00b1\n!\n\u00b0\nL\n.s\/\nt W t \u0015 0\n\u00b1\n;\nwhere the convergence of random processes holds in the weak sense in the space\nD.\u01520;C1\/I RC\/ of c\u00e0dl\u00e0g functions equipped with the Skorohod topology.\nThis convergence result implies that a tempered stable marginal over a very\nshort time is very close to a stable distribution. The acceptance rate thus tends\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n288 R. Kawai and H. Masuda\nto 1 as well. To illustrate this phenomenon, we compare in Table 1 percentiles\nof a tempered stable marginal and its stable proposal marginal at time t D 0:1,\n0:01 and 0:001. The percentiles are estimated by Monte Carlo methods based on\n3000000 iid replications. Acceptance rates of acceptance-rejection sampling are\nrespectively 0:7192, 0:9676 and 0:9967. Clearly, the tempered stable distribution\ntends to the stable proposal distribution as t is smaller. It is worth pointing out\nan obvious merit of Algorithm 1 in the implementation of the Euler\u2013Maruyama\nscheme for more general stochastic differential equations driven by a tempered sta-\nble subordinator, in which stepsize \u0081 is often desired to be taken arbitrarily small.\n20% 40% 60% 80% 90% 95% 97% 98% 99%\nL\n.s\/\n1 5.25 6.77 9.29 16.43 31.51 65.17 115.65 186.04 425.94\nh\n\u00001=\u02db\n1 L\n.ts\/\nh1\n5.25 6.76 9.27 16.31 30.92 62.44 107.76 167.31 350.53\nh\n\u00001=\u02db\n2 L\n.ts\/\nh2\n5.22 6.68 9.05 15.36 27.07 48.73 74.51 103.28 172.17\nh\n\u00001=\u02db\n3 L\n.ts\/\nh3\n5.00 6.19 7.89 11.47 16.33 22.76 28.52 33.73 44.02\nTable 1. Percentile comparison of scaled marginals h\u00001=\u02dbL.ts\/\nh\nof TS.0:8; 1:0; 0:5\/\nand the 0.8-stable proposal distribution L.s\/1 for .h1; h2; h3\/ D .1e-3, 1e-2, 1e-1\/.\nUnlike in the high-frequency sampling framework, however, Algorithm 1 may\nbe inefficient when \u0081 is large, with the worst acceptance rate being eab\u02db\u0080.\u0000\u02db\/.\nIt is worth comparing Algorithm 1 with the double rejection sampling algorithm\nrecently developed in Devroye [10], in expected time not depending upon all the\nmodel parameters.\nAlgorithm 2.\nStep 1 Set\n\u00181  a\n\u0010\n1 \u0000 e\u0000\u02db\u0015\u0081\n\u0011\nb\u02db\u0080.2 \u0000 \u02db\/;\n\u00182  1C\n2C\np\n\u0019=2\n\u0019\np\n2\u00181;\n\u00183  \nr\n\u0019\n2\ne\u0000\n\u00181\u0019\n2\n8 .\u00182 \u0000 1\/:\nStep 2 Generate U1 and U2 as independent uniform .0; 1\/. If \u00181 < 1, then go to\nStep 4.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 289\nStep 3 IfU1 < \u00182\u00182C2\np\n2\u00181\u00183\n, then generateZ1 as N .0; 1\/ and set V  jZ1j=\np\n\u00181.\nOtherwise, set V  \u0019.1 \u0000 U 22 \/. Go to Step 5.\nStep 4 If U1 <\np\n\u0019\u00182p\n\u0019\u00182C2\u00183 , then set V  \u0019U2. Otherwise, set V  \u0019.1 \u0000 U\n2\n2 \/.\nStep 5 Set\n\u00184  \ns\nsin.V \/\n\u0012\n\u02db\nsin.\u02dbV \/\n\u0013\u02db \u0012 .1 \u0000 \u02db\/\nsin..1 \u0000 \u02db\/V \/\n\u00131\u0000\u02db\n;\n\u00185  \n\u0010p\n\u00181 C \u02db\u00184\n\u0011 1\n\u02db\n;\n\u00186  \n\u00185\n\u00185 \u0000 2\np\u02db\n\u00181\n;\n\u00187  \n\u0019e\u0000\n\u00181.1\u0000\u0018\n\u00002\n4\n\/\n\u02db.1\u0000\u02db\/\u0010\n1C\nq\n\u0019\n2\n\u0011p\n\u00181=\u00184 C \u00186\n\u0014\n\u00182e\n\u0000 \u00181V2\n2 1.V \u0015 0; \u00181 \u0015 1\/\nC \u00183p\n\u0019 \u0000 V\n1.V 2 .0; \u0019\/\/C \u001821.V 2 \u01520; \u0019\u008d; \u00181 < 1\/\n\u0015\n:\nStep 6 Generate U3 as uniform .0; 1\/. If V < \u0019 and \u00187U3 \u0014 1, then go to Step 7.\nOtherwise, go to Step 2.\nStep 7 Generate U4 as uniform .0; 1\/ and set\n\u00188  \u0018\n2\n\u02db\u00001\n4 \u02db\n\u02db\n1\u0000\u02db .1 \u0000 \u02db\/; \u00189  \n.1 \u0000 \u02db\/\u02db\u00001\u00181\n\u02db\u02dbC1\u0018\u02db8\n;\n\u001810  \np\n\u02db\u00189=\u00188; \u001811  \u001810\np\n\u0019=2;\n\u001812  \u00186=\u00188; \u001813  \u001810 C \u001811 C \u001812:\nStep 8 If U4 < \u001811=\u001813, then generate Z2 as N .0; 1\/, set X  \u00189\u0000 \u001810jZ2j, and\ngo to Step 11.\nStep 9 If U4 < .\u001810 C \u001811\/=\u001813, then generate U5 as uniform \u0152\u00189; \u00189 C \u001810\u008d, set\nX  U5, and go to Step 11.\nStep 10 Generate E1 as Exp.1\/ and set X  \u00189 C \u001810 C \u001812E1.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n290 R. Kawai and H. Masuda\nStep 11 Generate E2 as Exp.1\/. If X \u0015 0 and\n\u00188.X \u0000 \u00189\/C\n\u0012\n\u00181\n\u02db.1 \u0000 \u02db\/\n\u0013 1\n\u02db\n\u0012\nX\n\u02db\u00001\n\u02db \u0000 \u0018\n\u02db\u00001\n\u02db\n9\n\u0013\n\u0000 Z\n2\n2\n2\n1.X < \u00189\/\u0000E11.X > \u00189 C \u001810\/ \u0014 E2;\nthen exit with X \u02db\u00001\u02db . Otherwise, go to Step 2.\nThe algorithm possesses a surprising feature; if \u00181 \u0015 1, then the expected num-\nber of iterations is uniformly bounded as\n\u00182\nr\n\u0019\n2\u00181\nC 2\u00183\np\n\u0019 \u0014\nr\n1\n2\u0019\nC 2p\n\u0019\nC 1p\n2\nC 8\n\u0019\np\ne\nC\nr\n8\n\u0019e\n\u0019 4:7468288;\nwhile if \u00181 \u0014 1, then\n2\u00183\np\n\u0019 C \u00182\u0019 \u0014\n8\n\u0019\np\ne\nC\nr\n8\n\u0019e\nC\np\n8Cp\u0019 C 1 \u0019 8:1132815;\nthe upper bounds being valid regardless of the model parameters .\u02db; a; b; \u0015;\u0081\/.\nIn the case Algorithm 1 is less efficient, that is, when in terms of acceptance rates,\nexp\nh\na.1 \u0000 e\u0000\u02db\u0015\u0081\/\u0080.\u0000\u02db\/b\u02db\ni\nD exp\n\u0014\n\u0000 \u00181\n\u02db.1\u0000 \u02db\/\n\u0015\n<\n8<:\n\u0010\n\u00182\nq\n\u0019\n2\u00181\nC 2\u00183\np\n\u0019\n\u0011\u00001\n; if \u00181 \u0015 1;\u0000\n2\u00183\np\n\u0019 C \u00182\u0019\n\u0001\u00001\n; if \u00181 \u0014 1;\n(4.2)\nit is worth employing Algorithm 2. To be more illustrative, we provide Figure 1\nto compare acceptance rates of Algorithm 1 and 2 against sampling frequency \u0081,\nwhere the model parameters are fixed .a; b; \u0015\/ D .1:0; 1:0; 0:5\/. (This parame-\nter setting will be used for numerical illustrations shortly in Section 5.) Accep-\ntance rates of Algorithm 1 increases to 1 as \u0081 # 0 and decreases to eab\u02db\u0080.\u0000\u02db\/\nas \u0081 \" C1. In those parameter settings, Algorithm 2 outperforms when step-\nsize \u0081 is roughly greater than 4:0, 2:5, 1:0, respectively, for \u02db D 0:4; 0:6; 0:8.\nIn any event, a decision can be made between Algorithm 1 and 2 simply based on\n(4.2) prior to implementation.\nStraightforward decompositions of the random variable \u00110.\u0081\/ may do the job\nas well. Observe that its L\u00e9vy measure can be decomposed, for example, as\nw\u0081;1.z\/ D\nnX\nkD1\na\nn\n\u0010\n1 \u0000 e\u0000\u02db\u0015\u0081\n\u0011\nz\u00001\u0000\u02dbe\u0000bz ; n 2 N; (4.3)\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 291\n\u02db D 0:4 \u02db D 0:6\n\u02db D 0:8\nFigure 1. Acceptance rate (y-axis) against sampling frequency \u0081 (x-axis) of Algo-\nrithm 1 (solid lines) and Algorithm 2 (dotted lines). The model parameters are set\n.a; b; \u0015\/ D .1:0; 1:0; 0:5\/.\nthat is, decomposing \u00110.\u0081\/ into n iid random variables, due to its infinite divisi-\nbility. The decomposition (4.3) induces an algorithm consisting of n independent\nruns of Algorithm 1 with a different parameter set, which results in the expected\nnumber ne\u0000a.1\u0000e\u0000\u02db\u0015\u0081\/\u0080.\u0000\u02db\/b\u02db=n.DW nen\u0003=n DW H.n\/\/ of loops in total, relative\nto the original expected number en\u0003 of Algorithm 1. Considering that n is an in-\nteger, we can show that if both n\u0003 > 1 and H.bn\u0003c\/ ^H.dn\u0003e\/ < en\u0003 hold true,\nthen the decomposition (4.3) provides a more efficient algorithm with n D dn\u0003e if\nH.dn\u0003e\/ < H.bn\u0003c\/ or with n D bn\u0003c otherwise. The criterion can be checked\nprior to implementation and tends to hold in the low-frequency sampling frame-\nwork. It is noteworthy that various different decompositions are certainly available,\nsuch as\nw\u0081;1.z\/ D\nnX\nkD1\nae\u0000\u02db\u0015.k\u00001\/=n\n\u0010\n1\u0000 e\u0000\u02db\u0015\u0081=n\n\u0011\nz\u00001\u0000\u02dbe\u0000bz ;\nwhile the above simplest one (4.3) seems most effective for our purpose.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n292 R. Kawai and H. Masuda\nRemark 4.2. Let XS and XTS be random variables respectively with distributions\nS.\u02db; a\/ under the probability measure Q and TS.\u02db; a; b\/ under P . It is a straight-\nforward application of Theorem 33.3 of Sato [21] to evaluate an expected value\nrelated to tempered stable random variables by the density transform\nEP \u0152\u02c6 .XTS\/\u008d D EQ\n\u0014\ndP\ndQ\n\u02c7\u02c7\nG\n\u02c6.XS \/\n\u0015\n;\nwith \u02c6 W RC ! R such that EP \u0152j\u02c6.XTS\/j\u008d < C1. Here, the Radon\u2013Nykodym\nderivative is given in closed form .dP=dQ\/jG D e\u0000bXS =EQ\u0152e\u0000bXS \u008d, Q-a.s.,\nwhere G is the minimal \u001b -field generated by the random variable XS . (This den-\nsity transform formulation is found useful in the computation of Greeks under an\nasset price model driven by tempered stable processes. See Kawai\u2013Takeuchi [17]\nfor details.) This method does not employ acceptance-rejection sampling. (In fact,\nthe tempered stable random variable XTS is not even generated in this framework.)\nHowever, this is only valid for the evaluation of expectations, and the estima-\ntor variance VarQ..dP=dQ\/jG\u02c6.XS \/\/ is typically greater than the original one\nVarP .\u02c6.XTS\/\/, provided that both variances are well defined, due to\nEQ\u0152e\n\u0000bXTS \u008d\u001c EP \u0152e\u0000bXS \u008d:\nThose observations discourage the use of this approach in the Monte Carlo frame-\nwork.\nWe next consider simulation of the compound Poisson component. (We do not\nconsider generation of the Poisson random variable N.\u0081\/ here since its random\nnumber generator is available in most mathematical tools. See, for example, [1] for\nefficient Poisson generators.) Recall that \u00b9\u0011k.\u0081\/\u00bak2N has a common probability\ndensity v\u0081.x\/ given by (3.1). In a similar manner to Lemma 1 of [23], observe\nthat\nv\u0081.x\/ \u0014 \u02db\ne\u0015\u0081 \u0000 1\ne\u02db\u0015\u0081 \u0000 1\n\u0012\nb1\u0000\u02db\n\u0080.1 \u0000 \u02db\/x\n.1\u0000\u02db\/\u00001e\u0000bx\n\u0013\nDW C.\u0081\/g1.x\/; x 2 RC;\nwhere C.\u0081\/ WD \u02db.e\u0015\u0081\u00001\/=.e\u02db\u0015\u0081\u00001\/ \u0015 1 and g.x\/ is the density of the gamma\ndistribution \u0080.1 \u0000 \u02db; b\/. Also, it holds that\nv\u0081.x\/\nC.\u0081\/g1.x\/\nD 1\u0000 e\nb.1\u0000e\u0015\u0081\/x\nbx\nDW g2;\u0081.x\/; x 2 RC:\nThis suggests the following acceptance-rejection sampling algorithm for the sim-\nulation of the random variable \u00111.\u0081\/.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 293\nAlgorithm 3.\nStep 1 Generate U as uniform .0; 1\/ and V as \u0080.1 \u0000 \u02db; b\/.\nStep 2 If U \u0014 g2;\u0081.V \/, let \u00111.\u0081\/ V . Otherwise, return to Step 1.\nAcceptance rate here is 1=C.\u0081\/ and is close to 1 when \u0081 is very small. In other\nwords, Algorithm 3 is efficient in the high-frequency sampling framework. The ac-\nceptance rate may be small, however, when the stability index \u02db is extremely close\nto zero along with a large stepsize \u0081. To address this issue, we can apply a sim-\nple yet very efficient improvement, due to [23], based on the composition method\n(see, for example, Devroye [9]) and the decomposition of the density function\nv\u0081.x\/ into an arbitrary number of density functions within the same class; for\neach n 2 N,\nv\u0081.x\/ D\nn\u00001X\nkD0\npn.k\/\n\u0010\ne\u0015\u0081k=nv\u0081=n\n\u0010\ne\u0015\u0081k=nx\n\u0011\u0011\n;\nwhere\npn.k\/ WD\n.e\u02db\u0015\u0081=n \u0000 1\/e\u02db\u0015\u0081k=n\ne\u02db\u0015\u0081 \u0000 1 ; k D 0; : : : ; n \u0000 1:\nNote that pn.k\/ > 0 and\nPn\u00001\nkD0 pn.k\/ D 1 and that e\u0015\u0081k=nv\u0081=n.e\u0015\u0081k=nx\/ in the\nabove summand acts as probability density function of e\u0000\u0015\u0081k=n\u00111.\u0081=n\/, which\ncan be generated exactly by Algorithm 3. The improved algorithm is as follows.\nAlgorithm 4.\nStep 1 Generate U as uniform .0; 1\/ and find the index\nj D min\n\u00b4\nl W\nlX\nkD0\npn.k\/ \u0015 U\n\u00b5\n:\nStep 2 Generate a random variable \u00111.\u0081=n\/ by Algorithm 3.\nStep 3 Return e\u0000\u0015\u0081j=n\u00111.\u0081=n\/.\nRelative to Algorithm 3, acceptance rate increases to 1=C.\u0081=n\/ from 1=C.\u0081\/.\nIt can be made as close to 1 as one wishes by increasing n at almost no cost;\nadditional computing effort is required at Step 1, while this is a minor increase.\nRemark 4.3. With those exact simulation methods for the tempered stable distri-\nbution, we can readily derive an exact simulation algorithm for the multivariate,\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n294 R. Kawai and H. Masuda\npossibly skewed, normal tempered stable L\u00e9vy process [4]. To be precise, the nor-\nmal tempered stable L\u00e9vy process \u00b9Yt W t \u0015 0\u00ba in Rd is defined by\nYt D \u0016t C \u02c7\u0192L.ts\/t C\u01921=2BL.ts\/t ;\nwhere\u0016, \u02c7 2 Rd , the matrix\u0192 2 R1\u0002d is symmetric positive definite and has unit\ndeterminant, and \u00b9Bt W t \u0015 0\u00ba is a standard Brownian motion in Rd (see [2, 4] for\ndetails.) That is to say, the law L.Yt\/ can be simulated immediately from the law\nL.L\n.ts\/\nt \/ and the standard normal distribution in Rd . To the best of our knowledge,\nsimulation of normal tempered stable L\u00e9vy processes has been discussed solely\nthrough infinite series representations, such as (2.8).\nWe close this section with discussing simulation of random elements arising\nin Corollary 3.2 above. In principle, the recipe is almost the same, that is, Al-\ngorithm 1 is applicable to \u0011C0 .\u0081\/ and \u0011\u00000 .\u0081\/, while Algorithm 3 to \u00b9\u0011Ck .\u0081\/\u00bak2N\nand \u00b9\u0011\u0000\nk\n.\u0081\/\u00bak2N . When \u02dbC D \u02db\u0000 DW \u02db, however, we can go a little further. The\nproposal distribution for \u0011C0 .\u0081\/C\u0011\u00000 .\u0081\/ is then again a stable distribution, which\ncan be simulated as a single stable random variable. Write\n\u0011.\u0081\/ WD \u0011C0 .\u0081\/C \u0011\u00000 .\u0081\/;\nwhere \u0011\u02d90 .\u0081\/ \u0018 TS.\u02db;ea\u02d9; b\u02d9\/,ea\u02d9 WD a\u02d9.1 \u0000 e\u0000\u02db\u0015\u0081\/, and moreover\nc WD e\u0000\u0080.\u0000\u02db\/.1\u0000e\u0000\u02db\u0015\u0081\/.aCb\u02dbCCa\u0000b\u02db\u0000\/:\nThe density f\u0011.\u0081\/.x\/ of the random variable \u0011.\u0081\/ has a upper bound as\nf\u0011.\u0081\/.x\/ D\nZ\nR\nfTS.\u02db;eaC;bC\/.x \u0000 y\/fTS.\u02db;ea\u0000;b\u0000\/.\u0000y\/dy\nD c\nZ x^0\n\u00001\ne\u0000bC.x\u0000y\/eb\u0000yfS.\u02db;eaC\/.x \u0000 y\/fS.\u02db;ea\u0000\/.\u0000y\/dy\n\u0014 ce\u0000bCxe.bCCb\u0000\/.x^0\/\nZ x^0\n\u00001\nfS.\u02db;eaC\/.x \u0000 y\/fS.\u02db;ea\u0000\/.\u0000y\/dy\nD c\n\u0010\ne\u0000bCx1.x > 0\/C e\u0000b\u0000 jxj1.x < 0\/\n\u0011\n\u0002\nZ\nR\nfS.\u02db;eaC\/.x \u0000 y\/fS.\u02db;ea\u0000\/.\u0000y\/dy\nDW c g3.x\/\nZ\nR\nfS.\u02db;eaC\/.x \u0000 y\/fS.\u02db;ea\u0000\/.\u0000y\/dy;\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 295\nwhere the last integral is the density of the (bilateral) stable distribution with no\ndrift, S.\u02db;eaC;ea\u0000\/ say, with L\u00e9vy densityeaC\nz1C\u02db\n1.z > 0\/C ea\u0000jzj1C\u02db 1.z < 0\/:\nThis stable proposal distribution can be simulated in a similar manner to (2.3):\nS .\u02db;eaC;ea\u0000\/ LD \u0012 \u0000.eaC Cea\u0000\/\u0080.\u0000\u02db\/ cos.\u0019\u02db=2\/\ncos.V \/.1C .\u02c7 tan.\u0019\u02db=2\/\/2\/\u00001=2\n\u0013 1\n\u02db\n\u0002 sin .\u02db.V C \u0012\/\/\n\u0012\ncos.V \u0000 \u02db.V C \u0012\/\/\nE\n\u0013 1\u0000\u02db\n\u02db\n;\nwhere V is a uniform random variable on the interval .\u0000\u0019=2; \u0019=2\/, E is a standard\nexponential random variable independent of V , \u02c7 WD .eaC \u0000ea\u0000\/=.eaC Cea\u0000\/ and\n\u0012 WD arctan.\u02c7 tan.\u0019\u02db=2\/\/=\u02db. (See Chambers et al. [8] for details.) In that case,\nwe can apply the following acceptance-rejection sampling algorithm, similar to\nAlgorithm 1 above, to generate \u0011.\u0081\/ with the bilateral stable proposal distribution\nS.\u02db;eaC;ea\u0000\/.\nAlgorithm 5.\nStep 1 Generate U as uniform .0; 1\/ and V as S.\u02db;eaC;ea\u0000\/.\nStep 2 If U \u0014 g3.V \/, let \u0011.\u0081\/ V . Otherwise, return to Step 1.\nThe acceptance rate at Step 2 is c\u00001 D e\u0080.\u0000\u02db\/.1\u0000e\u0000\u02db\u0015\u0081\/.aCb\u02dbCCa\u0000b\u02db\u0000\/, which\nincreases to 1 as \u0081 tends to zero. An important remark here is that generation of\n\u0011.\u0081\/ by Algorithm 5 above may not always outperform that of \u0011C.\u0081\/ and \u0011\u0000.\u0081\/\nthrough implementation of Algorithm 1 twice. To describe this, fix\n\u02db\u02d9 D \u02db 2 .0; 1\/ and a\u02d9 D b\u02d9 D 1;\nfor simplicity. Also, let N1.\u0015\u0081\/ and N5.\u0015\u0081\/ be the expected loop numbers re-\nquired, respectively, for generation of \u0011C.\u0081\/ and \u0011\u0000.\u0081\/ by Algorithm 1 twice and\nfor generation of \u0011.\u0081\/ by Algorithm 5 once, where N1.s\/ WD 2e\u0000.1\u0000e\u0000\u02dbs \/\u0080.\u0000\u02db\/\nand N5.s\/ WD e\u00002.1\u0000e\u0000\u02dbs \/\u0080.\u0000\u02db\/. Then, observe that\nN1.s\/\u0000N5.s\/\n\u00b4\n\u0015 0; if s 2\nh\n0; \u0000 1\n\u02db\nln\n\u0010\n1C ln2\n\u0080.\u0000\u02db\/\n\u0011i\n;\n< 0; otherwise:\nHence, Algorithm 5 is of practical use when \u0081 \u0014 \u0000.\u0015\u02db\/\u00001 ln.1C ln 2=\u0080.\u0000\u02db\/\/\nand is preferable for small \u02db since the boundary point is strictly decreasing in \u02db\ntowards zero.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n296 R. Kawai and H. Masuda\n5 Numerical illustration\nWe provide in Figure 2 typical sample paths of finite variation tempered stable\nOrnstein\u2013Uhlenbeck processes in the high-frequency sampling framework, based\non the exact transitions given in Theorem 3.1 and the acceptance-rejection sam-\npling methods described in Algorithms 1 and 3 above. The model parameters are\nset .a; b; \u0015\/ D .1:0; 1:0; 0:5\/ and \u02db D 0:4, 0:6 and 0:8, the same setting for Fig-\nure 1. For simplicity, we set the initial state\nY0 D a\u0080.1 \u0000 \u02db\/b\u02db\u00001 D lim\nt\"C1\nE\u0152Yt \u008d;\nthat is the mean of the stationary distribution TS.\u02db; a; b\/. Sample paths are gen-\nerated over time intervals \u01520; 100\u008d and \u01520; 200\u008d, where stepsize is \u0081 D 0:1. Hence,\n1000 and 2000 recursive increments are needed, respectively, for the intervals\n\u01520; 100\u008d and \u01520; 200\u008d. In the context of asymptotic statistics for discretely observed\nOrnstein\u2013Uhlenbeck processes, it is often preferable to take \u0081 small and T large,\nas in this setting. (See, for example, [7, 13].)\nComputing times required for an implementation of 2000 recursive increments\nby R software are 0:20, 0:25 and 0:34 seconds, respectively, for \u02db D 0:4; 0:6 and\n0:8, on a typical desktop PC. (Computing times can be reduced much further by\nusing a low-level language such as C, rather than high-level ones such as R and\nMATLAB.) In principle, the difference in computing time comes from acceptance\nrates in Algorithms 1 and 3. In our parameter setting, acceptance rates in Algo-\nrithm 1 (one sample from L.\u00110.\u0081\/\/) are 0:929, 0:896 and 0:800, respectively,\nwhile in Algorithm 3 (one sample from L.\u00111.\u0081\/\/), the acceptance rates are, re-\nspectively, 0:985, 0:990 and 0:995. Clearly, acceptance rate for \u00110.\u0081\/ virtually\ndominates that for \u00111.\u0081\/, due to very small means 0:074, 0:109 and 0:225 of the\nPoisson random variable N.\u0081\/.\nFinally, let us comment in brief on the existing simulation method based on the\ninfinite shot noise series representation (2.12) for comparison. The simulation use\nof infinite series representations entails a finite truncation of infinite sum. (See Imai\nand Kawai [11].) We have observed through numerical experiments that under the\nsame parameter setting as above, approximately 4000 summands are needed to\nobtain sensible sample paths over time interval \u01520; 200\u008d. (Our observation here is\nbased upon Monte Carlo estimation of the mean E\u0152Y200\u008d \u0019 Y0 and the variance\nVar.Y200\/ \u0019 a\u0080.2 \u0000 \u02db\/b\u02db\u00002.) Although results are different for different param-\neter settings and for different criteria and although generalizing solely based on\nnumerical experiments is somewhat risky, it seems fair to claim that our exact sim-\nulation algorithm outperforms, considering many kinds of random sequences to be\ngenerated and all the other operations such as taking minimum, sorting the series\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 297\n0 20 40 60 80 100\n0\n1\n2\n3\n4\n5\n6\n0 50 100 150 200\n0\n1\n2\n3\n4\n5\n6\n\u02db D 0:4, t 2 \u01520; 100\u008d \u02db D 0:4, t 2 \u01520; 200\u008d\n0 20 40 60 80 100\n1\n2\n3\n4\n5\n6\n7\n0 50 100 150 200\n1\n2\n3\n4\n5\n6\n7\n\u02db D 0:6, t 2 \u01520; 100\u008d \u02db D 0:6, t 2 \u01520; 200\u008d\n0 20 40 60 80 100\n3\n4\n5\n6\n7\n8\n9\n0 50 100 150 200\n3\n4\n5\n6\n7\n8\n9\n\u02db D 0:8, t 2 \u01520; 100\u008d \u02db D 0:8, t 2 \u01520; 200\u008d\nFigure 2. The figures show typical sample paths of tempered stable Ornstein\u2013Uhlen-\nbeck processes through exact simulation algorithm. The model parameters are set\nY0 D a\u0080.1\u0000\u02db\/b\u02db\u00001.D limt\"C1 E\u0152Yt \u008d\/, .a; b; \u0015\/ D .1:0; 1:0; 0:5\/. The horizontal\ndashed lines indicate the initial state Y0.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n298 R. Kawai and H. Masuda\nby \u00b9Tk\u00bak2N , counting arrivals \u00b9e\u0080k\u00bak2N and monitoring at every discrete time\npoint in the representation (2.12). In particular, some of those operations may re-\nquire a tremendous amount of computing time in high-level languages based on\nmatrix operations.\n6 Concluding remarks\nIn this paper, we have discussed exact simulation algorithms for a wide class of\nOrnstein\u2013Uhlenbeck processes of finite variation tempered stable stationary laws\nbased on the exact transition probability between consecutive observations. We\nhave adopted acceptance-rejection sampling to simulate tempered stable and com-\npound Poisson distributions, respectively, with stable and gamma proposal distri-\nbution. We have shown that Algorithms 1, 3 and 5 approach to perfect acceptance-\nrejection sampling as stepsize tends to zero. This fact supports the proposed\nmethod for validation and estimation purposes under high-frequency sampling.\nWe have also addressed the issue of their inefficient functionality when sampling\nfrequency is very low. Our algorithms prove applicable to simulations of bilateral\nfinite variation tempered stable Ornstein\u2013Uhlenbeck processes and normal tem-\npered stable processes as well. Our exact simulation algorithms work more effi-\nciently relative to the existing approximative simulation method based on infinite\nseries representation of sample paths. It is of practical interest to extend to the infi-\nnite variation setting, in which no practical exact simulation method is known yet.\nThose topics are addressed in subsequent papers [15,16]. It would also be an inter-\nesting future research topic to improve Algorithm 5 to a uniformly fast algorithm,\nin a similar spirit to Algorithm 3.\nBibliography\n[1] J. H. Ahrens and U. Dieter, Computer generation of Poisson deviates from modified\nnormal distributions, ACM Trans. Math. Software 8 (1982) no. 2, 163\u2013179.\n[2] O. E. Barndorff-Nielsen, J. Kent and M. S\u00f8rensen, Normal variance-mean mixtures\nand z-distributions, Int. Stat. Rev. 50 (1982), 145\u2013159.\n[3] O. E. Barndorff-Nielsen and N. Shephard, Non-Gaussian Ornstein\u2013Uhlenbeck-based\nmodels and some of their uses in financial economics (with discussion), J. R. Stat.\nSoc. Ser. B Stat. Methodol. 63 (2001), no. 2, 167\u2013241.\n[4] O. E. Barndorff-Nielsen and N. Shephard, Normal modified stable processes, Theory\nProbab. Math. Statist. 65 (2002), 1\u201319.\n[5] F. E. Benth, M. Gorth and R. Kufakunesu, Valuing volatility and variance swaps for a\nnon-Gaussian Ornstein\u2013Uhlenbeck stochastic volatility model, Appl. Math. Finance\n14 (2007), no. 4, 347\u2013363.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nExact discrete sampling of Ornstein\u2013Uhlenbeck processes 299\n[6] A. Brix, Generalized Gamma measures and shot-noise Cox processes, Adv. in Appl.\nProbab. 31 (1999), no. 4, 929\u2013953.\n[7] P. J. Brockwell, R. A. Davis and Y. Yang, Estimation for nonnegative L\u00e9vy-driven\nOrnstein\u2013Uhlenbeck processes, J. Appl. Probab. 44 (2007), no. 4, 977\u2013989.\n[8] J. M. Chambers, C. L. Mallows and B. W. Stuck, A method for simulating stable\nrandom variables, J. Amer. Statist. Assoc. 71(354) (1976), 340\u2013344.\n[9] L. Devroye, Non-Uniform Random Variate Generation, Springer-Verlag, New York,\n1986.\n[10] L. Devroye, Random variate generation for exponential and polynomially tilted\nstable distributions, ACM Trans. Model. Comput. Simul. 19 (2009), no. 4, Article\nNo. 18.\n[11] J. Imai and R. Kawai, On finite truncation of infinite shot noise series representation\nof tempered stable laws, to appear in Phys. A, DOI:10.1016\/j.physa.2011.07.028.\n[12] J. Imai and R. Kawai, Numerical inverse L\u00e9vy measure method for infinite shot noise\nseries representation, preprint.\n[13] G. Jongbloed, F. H. van der Meulen and A. W. van der Vaart, Nonparametric in-\nference for L\u00e9vy-driven Ornstein\u2013Uhlenbeck processes, Bernoulli 11 (2005), no. 5,\n759\u2013791.\n[14] M. Kanter, Stable densities under change of scale and total variation inequalities,\nAnn. Probab. 3 (1975), no. 4, 697\u2013707.\n[15] R. Kawai and H. Masuda, Infinite variation tempered stable Ornstein\u2013Uhlenbeck\nprocesses with discrete observations, to appear in Comm. Statist. Simulation Com-\nput., DOI:10.1080\/03610918.2011.582561.\n[16] R. Kawai and H. Masuda, On simulation of tempered stable random variates, J. Com-\nput. Appl. Math. 235 (2011), no. 8, 2873\u20132887.\n[17] R. Kawai and A. Takeuchi, Computation of Greeks for asset price dynamics driven\nby stable and tempered stable processes, to appear in Quant. Finance, DOI:10.1080\/\n14697688.2011.589403.\n[18] H. Masuda, On multidimensional Ornstein\u2013Uhlenbeck processes driven by a general\nL\u00e9vy process, Bernoulli 10 (2004), no. 1, 1\u201324.\n[19] J. R. Michael, W. R. Schucany and R. W. Haas, Generating random variates using\ntransformations with multiple roots, Amer. Statist. 30 (1976), 88\u201390.\n[20] J. Rosin\u00b4ski, Tempering stable processes, Stochastic Process. Appl. 117 (2007), no. 6,\n677\u2013707.\n[21] K. Sato, L\u00e9vy Processes and Infinitely Divisible Distributions, Cambridge University\nPress, Cambridge, 1999.\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n300 R. Kawai and H. Masuda\n[22] M. C. K. Tweedie, An index which distinguishes between some important exponen-\ntial families, in: Statistics: Applications and New Directions, Proceedings of the\nIndian Statistical Institute Golden Jubilee International Conference, pp. 579\u2013604,\nedited by J. Ghosh and J. Roy, Indian Statistical Institute, Calcutta, 1984.\n[23] S. Zhang and X. Zhang, Exact simulation of IG-OU processes, Methodol. Comput.\nAppl. Probab. 10 (2008), no. 3, 337\u2013355.\n[24] S. Zhang and X. Zhang, On the transition law of tempered stable Ornstein\u2013Uhlen-\nbeck processes, J. Appl. Probab. 46 (2009), no. 3, 721\u2013731.\n[25] V. M. Zolotarev, One-Dimensional Stable Distributions, American Mathematical So-\nciety, Providence, RI, 1986.\nReceived January 26, 2011; revised August 10, 2011.\nAuthor information\nReiichiro Kawai, Department of Mathematics, University of Leicester,\nLeicester LE1 7RH, UK.\nE-mail: reiichiro.kawai@le.ac.uk\nHiroki Masuda, Institute of Mathematics for Industry, Kyushu University,\nFukuoka 819-0395, Japan.\nE-mail: hiroki@imi.kyushu-u.ac.jp\nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \nAUTHOR\u2019S COPY | AUTORENEXEMPLAR \n"}
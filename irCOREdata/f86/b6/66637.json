{"doi":"10.1137\/060660345","coreId":"66637","oai":"oai:dro.dur.ac.uk.OAI2:649","identifiers":["oai:dro.dur.ac.uk.OAI2:649","10.1137\/060660345"],"title":"Distributed selfish load balancing.","authors":["Berenbrink,  P.","Friedetzky,  T.","Goldberg,  L. A.","Goldberg,  P.","Hu,  Z.","Martin,  R."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-11","abstract":"Suppose that a set of m tasks are to be shared as equally as possible amongst a set of n resources. A game-theoretic mechanism to find a suitable allocation is to associate each task with a \"selfish agent\", and require each agent to select a resource, with the cost of a resource being the number of agents to select it. Agents would then be expected to migrate from overloaded to underloaded resources, until the allocation becomes balanced.Recent work has studied the question of how this can take place within a distributed setting in which agents migrate selfishly without any centralized control. In this paper we discuss a natural protocol for the agents which combines the following desirable features: It can be implemented in a strongly distributed setting, uses no central control, and has good convergence properties. For m &Gt; n, the system becomes approximately balanced (an \u03b5-Nash equilibrium) in expected time O(log log m). We show using a martingale technique that the process converges to a perfectly balanced allocation in expected time O(log log m + n4). We also give a lower bound of \u03a9 (max{log log m, n}) for the convergence time","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/66637.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/649\/1\/649.pdf","pdfHashValue":"1a8824530f87753edf79587ecd1b817b7d30ee0f","publisher":"Society for Industrial and Applied Mathematics","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:649<\/identifier><datestamp>\n      2011-06-15T15:57:50Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Distributed selfish load balancing.<\/dc:title><dc:creator>\n        Berenbrink,  P.<\/dc:creator><dc:creator>\n        Friedetzky,  T.<\/dc:creator><dc:creator>\n        Goldberg,  L. A.<\/dc:creator><dc:creator>\n        Goldberg,  P.<\/dc:creator><dc:creator>\n        Hu,  Z.<\/dc:creator><dc:creator>\n        Martin,  R.<\/dc:creator><dc:description>\n        Suppose that a set of m tasks are to be shared as equally as possible amongst a set of n resources. A game-theoretic mechanism to find a suitable allocation is to associate each task with a \"selfish agent\", and require each agent to select a resource, with the cost of a resource being the number of agents to select it. Agents would then be expected to migrate from overloaded to underloaded resources, until the allocation becomes balanced.Recent work has studied the question of how this can take place within a distributed setting in which agents migrate selfishly without any centralized control. In this paper we discuss a natural protocol for the agents which combines the following desirable features: It can be implemented in a strongly distributed setting, uses no central control, and has good convergence properties. For m &Gt; n, the system becomes approximately balanced (an \u03b5-Nash equilibrium) in expected time O(log log m). We show using a martingale technique that the process converges to a perfectly balanced allocation in expected time O(log log m + n4). We also give a lower bound of \u03a9 (max{log log m, n}) for the convergence time. <\/dc:description><dc:subject>\n        Task allocation<\/dc:subject><dc:subject>\n         Nash equilibrium.<\/dc:subject><dc:publisher>\n        Society for Industrial and Applied Mathematics <\/dc:publisher><dc:source>\n        SIAM journal on computing, 2007, Vol.37(4), pp.1163-1181 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2007-11<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:649<\/dc:identifier><dc:identifier>\n        issn:0097-5397<\/dc:identifier><dc:identifier>\n        issn: 1095-7111<\/dc:identifier><dc:identifier>\n        doi:10.1137\/060660345<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/649\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1137\/060660345<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/649\/1\/649.pdf<\/dc:identifier><dc:rights>\n        Copyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited.<\/dc:rights><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn:0097-5397","0097-5397","issn: 1095-7111"," 1095-7111"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2007,"topics":["Task allocation","Nash equilibrium."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n27 October 2008\nVersion of attached file:\nPublished Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nBerenbrink, P. and Friedetzky, T. and Goldberg, L. A. and Goldberg, P. and Hu, Z. and Martin, R. (2007)\n\u2019Distributed selfish load balancing.\u2019, SIAM journal on computing., 37 (4). pp. 1163-1181.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1137\/060660345\nPublisher\u2019s copyright statement:\nCopyright by SIAM. Unauthorized reproduction of this article is prohibited.\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nSIAM J. COMPUT. c\u00a9 2007 Society for Industrial and Applied Mathematics\nVol. 37, No. 4, pp. 1163\u20131181\nDISTRIBUTED SELFISH LOAD BALANCING\u2217\nPETRA BERENBRINK\u2020 , TOM FRIEDETZKY\u2021 , LESLIE ANN GOLDBERG\u00a7 ,\nPAUL W. GOLDBERG\u00a7 , ZENGJIAN HU\u2020 , AND RUSSELL MARTIN\u00a7\nAbstract. Suppose that a set of m tasks are to be shared as equally as possible among a set of n\nresources. A game-theoretic mechanism to find a suitable allocation is to associate each task with a\n\u201cselfish agent\u201d and require each agent to select a resource, with the cost of a resource being the number\nof agents that select it. Agents would then be expected to migrate from overloaded to underloaded\nresources, until the allocation becomes balanced. Recent work has studied the question of how this\ncan take place within a distributed setting in which agents migrate selfishly without any centralized\ncontrol. In this paper we discuss a natural protocol for the agents which combines the following\ndesirable features: It can be implemented in a strongly distributed setting, uses no central control,\nand has good convergence properties. For m\u0002 n, the system becomes approximately balanced (an\n\u0002-Nash equilibrium) in expected time O(log logm). We show using a martingale technique that the\nprocess converges to a perfectly balanced allocation in expected time O(log logm+n4). We also give\na lower bound of \u03a9(max{log logm,n}) for the convergence time.\nKey words. load balancing, reallocation, equilibrium, convergence\nAMS subject classifications. 68Q25, 68W20, 68W15, 91A80\nDOI. 10.1137\/060660345\n1. Introduction. Suppose a consumer learns the price she would be charged by\nsome domestic power supplier other than the one she is currently using. It is plausible\nthat if the alternative price is lower than the price she is currently paying, then there\nis some possibility that she will switch to the new power supplier. Furthermore, she\nis more likely to switch if the ratio of the current price to the new price is large. If\nthere is only a small savings, then it becomes unattractive to make the switch, since\nan influx of new business (hers and that of other consumers) may drive up the price\nof the new power supplier and make it no longer competitive.\nWe study a simple mathematical model of the above natural rule, in the context of\na load balancing (or task allocation) scenario that has received a lot of recent attention.\nWe assume the presence of many individual users who may assign their tasks to chosen\nresources. The users are selfish in the sense that they attempt to optimize their own\nsituation, i.e., try to assign their tasks to minimally loaded resources, without trying\nto optimize the global situation. In general, a Nash equilibrium (NE) among a set\nof selfish users is a state in which no user has the incentive to change her current\ndecision. In our setting, this corresponds to no user having an incentive to reallocate\n\u2217Received by the editors May 19, 2006; accepted for publication (in revised form) April 23,\n2007; published electronically November 21, 2007. A preliminary version appeared in Proceedings of\nthe Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2006, pp. 354\u2013\n363. This work was partially supported by the EPSRC grants \u201cDiscontinuous Behaviour in the\nComplexity of Randomized Algorithms\u201d and \u201cAlgorithmics of Network-sharing Games,\u201d and by the\nNatural Sciences and Engineering Research Council of Canada (NSERC) discovery grant 250284-\n2002.\nhttp:\/\/www.siam.org\/journals\/sicomp\/37-4\/66034.html\n\u2020School of Computing Science, Simon Fraser University, 8888 University Drive, Burnaby V5A\n1S6, BC, Canada (petra@cs.sfu.ca, zhu@cs.sfu.ca).\n\u2021Department of Computer Science, Durham University, Science Labs, South Road, Durham, DH1\n3LE, UK (tom.friedetzky@dur.ac.uk).\n\u00a7Department of Computer Science, University of Liverpool, Ashton Building, Liverpool, L69 3BX,\nUK (l.a.goldberg@liverpool.ac.uk, pwg@csc.liv.ac.uk, r.martin@csc.liv.ac.uk).\n1163\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \n1164 BERENBRINK ET AL.\nher task to some other resource. An \u0002-Nash equilibrium (\u0002-NE) is a standard notion\nof an approximate NE, and is a state in which no user can reduce her cost by a\nmultiplicative factor of less than 1 \u2212 \u0002 by changing action. Here we do not focus\non the quality of equilibria but rather on the (perhaps more algorithmic) question of\nconvergence time to such a state.\nWe assume a strongly distributed and concurrent setting; i.e., there is no central-\nized control mechanism whatsoever, and all users may choose to reallocate their tasks\nat the same time. Thus, we do not (and cannot) use the elementary step system [25]\n(discussed in more detail in the next section), where the assumption is that at most\none user may reallocate her task at any given stage.\nThroughout we let m denote the number of tasks (in the above discussion, cus-\ntomers) and n denote the number of resources (power suppliers). As hinted at in the\nabove discussion, we assume that typically m \u0002 n. In a single time step (or round)\neach task does the following: Let i be the resource currently being used by the task.\nSelect j uniformly at random from {1, . . . , n} and find the load of resource j. Let\nXi and Xj be the loads of resources i and j, respectively. If Xj < Xi, migrate from\ni to j with a probability of 1 \u2212 Xj\/Xi; the transition from round t to round t + 1\nis given in Figure 1.1. Notice that if we had unconditional migrations, i.e., without\nan additional coin flip (move only with probability 1\u2212Xj(t)\/Xi(t)), then this might\nlead to an unstable system; consider, for example, the case m = 2 with initially most\ntasks assigned to one of the resources. The overload would oscillate between the two\nresources, with a load ratio tending towards 2:1. (This observation about the risk of\noscillation has also been made in similar contexts in [12, 11], and we will not elaborate\non it further.)\nFor each task b do in parallel\nLet ib be the current resource of task b\nChoose resource jb uniformly at random\nLet Xib(t) be the current load of resource i\nLet Xjb(t) be the current load of resource j\nIf Xib(t) > Xjb(t) then\nMove task b from resource ib to jb with probability 1\u2212Xjb(t)\/Xib(t)\nFig. 1.1. The protocol with \u201cneutral moves\u201d allowed.\nIt can easily be seen that if all tasks use the above policy, then the expected load\nof every resource at the next step is m\/n.\nObservation 1.1. Regardless of the load distribution at time step t, the expected\nload of every resource at the next step is m\/n.\nProof. To see this, assume that the loads Xi(t) are arranged in descending order\nso that Xj(t) \u2265 Xj+1(t) and note that\nE[Xi(t+ 1)] = Xi(t) +\ni\u22121\u2211\n\u0002=1\n1\nn\nX\u0002(t)\n(\n1\u2212 Xi(t)\nX\u0002(t)\n)\n\u2212\nn\u2211\n\u0002=i+1\n1\nn\nXi(t)\n(\n1\u2212 X\u0002(t)\nXi(t)\n)\n= Xi(t) +\n1\nn\ni\u22121\u2211\n\u0002=1\n(X\u0002(t)\u2212Xi(t))\u2212 1\nn\nn\u2211\n\u0002=i+1\n(Xi(t)\u2212X\u0002(t))\n= Xi(t) +\n1\nn\nn\u2211\n\u0002=1\n(X\u0002(t)\u2212Xi(t)) = 1\nn\nn\u2211\n\u0002=1\nX\u0002(t) =\nm\nn\n.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nDISTRIBUTED SELFISH LOAD BALANCING 1165\nThis provides a compelling motivation for the policy, which is that as a result,\nno task has an incentive to deviate unilaterally from this policy. This implies that\nin the terminology of [8] it is a Nash rerouting policy. It is also a simple regret-\nminimizing policy in the sense of [2] since the average cost of resources used by an\nagent is no higher than the best choice of a single resource to be used repeatedly.\nAlthough the above rule is very natural and has the nice properties described above,\nwe show that it may take a long time to converge to a perfectly balanced allocation\nof tasks to resources. We address this problem as follows. Define a neutral move to\nbe a task migration from a resource with load \u0003 at time t to a resource with load\n\u0003 \u2212 1 at time t (so, if no other task migrates, then the cost to the migrating task\nis unchanged). We consider a modification in which neutral moves are specifically\ndisallowed (see Figure 2.1). That seemingly minor change ensures fast convergence\nfrom an almost balanced state to a perfectly balanced state. To summarize, here are\nthe most important features of the modified protocol:\n\u2022 We do not need any global information whatsoever (apart from the number\nof available resources); in particular, a task does not need to know the total\nnumber of tasks in the system. Also, it is strongly distributed and concurrent.\nIf additional tasks were to enter the system, it would rapidly converge once\nagain, with no outside intervention.\n\u2022 A migrating task needs to query the load of only one other resource (thus,\ndoing a constant amount of work in each round).\n\u2022 When a task finds a resource with a significantly smaller load (that is, a load\nthat is smaller by at least two), the migration policy is exactly the same as\nthat used by the Nash rerouting policy of Figure 1.1, so the incentive is to\nuse that probability.\n\u2022 When a task finds a resource with a load that is smaller by exactly one unit,\nthe migration policy is sufficiently close to the Nash rerouting policy that\nthe difference in expected load is at most one, and there is little incentive to\ndeviate.\n\u2022 The protocol is simple (as well as provably efficient) enough to convince users\nto actually stick to it.\n1.1. Related work. We are studying a simple kind of congestion game. In their\ngeneral form, congestion games specify a set of agents, a set of resources, and, for each\nagent, a set of allowed strategies, where a strategy is the selection of a subset of the\nresources (in this paper, any singleton subset is allowed). The cost of a resource is\na nondecreasing function of the number of agents using it, and the cost for an agent\nis the sum of the costs of resources it uses. A classical result due to Rosenthal [26]\nis that pure Nash equilibria (NEs) always exist for congestion games, and this is\nshown by exhibiting a potential function; they are a type of potential game [24].\nThe potential function also establishes that pure NEs can be found via sequences of\n\u201cbetter-response\u201d moves, in which agents repeatedly switch to lower-cost strategies.\nThe potential function we use later in this paper is that of [26], modulo a linear\nrescaling.\nThese results do not show how to find NEs efficiently, the problem being that in\nthe worst case, sequences of these self-improving moves may be exponentially long.\nThe following questions arise: When can NEs be found by any efficient algorithm,\nand if so, can they be found via an algorithm that purports to be a realistic model\nof agents\u2019 behavior? Regarding the first of these questions, the answer is no in the\ngeneral setting (the problem is PLS-complete for general congestion games [9]; see\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \n1166 BERENBRINK ET AL.\nalso [1, 3]). PLS-completeness (introduced in [17]) is a generally accepted criterion\nfor intractability of computational problems in which we seek a local optimum of a\ngiven objective function.\nHowever, due to the basic fact of [26, 24] that pure NEs are sure to result from a\nsufficiently long better-response sequence, many algorithms for finding them are based\non such sequences. An important subclass is the elementary step system (ESS), pro-\nposed in Orda, Rom, and Shimkin [25], which consists of best-response moves (where a\nmigrating agent switches not to any improved choice but to one that is optimal at the\ntime of migration). For matroid games (a class of congestion games that includes the\nones we consider here), Ackermann, Ro\u00a8glin, and Vo\u00a8cking [1] show that best-response\nsequences must have length polynomial in the number of players, resources, and max-\nimal rank of the matroids. In this paper we consider the special case of singleton\ncongestion games (where players\u2019 strategies are always single resources, and thus the\nranks of the matroids is 1). For these games, Ieong et al. [16] give polynomial bounds\nfor best-response and better-response sequences. Chien and Sinclair [3] study a ver-\nsion of the ESS in the context of approximate NEs, and show that in some cases\nthe \u0002-Nash dynamics may find an \u0002-NE where finding an exact NE is PLS-complete.\nMirrokni and Vetta [22] study the convergence rate of the ESS to solutions, and the\nquality of the approximation after limited iterations.\nWhile best- and better-response dynamics are a plausible model of selfish behav-\nior, the associated algorithms typically require that migrations be done one-by-one,\nand another common assumption is that best- (not better-) responses are always se-\nlected. This means that to some extent, agents are being assumed to be governed\nby a centralized algorithm that finds an NE, raising the question of what sort of dis-\ntributed algorithms can do so, especially if agents have limited information about the\nstate of the system (and so may not be able to find best responses). That issue is of\ncentral importance to us in this paper. Goldberg [14] studied situations where simple\nbetter-response approaches can be realized as weakly distributed algorithms (where\neach agent looks for moves independently of the others, but it is assumed that moves\ntake place consecutively, not simultaneously). In a strongly distributed setting (as we\nstudy here), where moves may occur simultaneously, we need to address the possibility\nthat a change of strategy may increase an agent\u2019s cost. It may happen that after a best\nresponse has been identified, it is not optimal at the time it is executed. Even-Dar\nand Mansour [8] consider concurrent, independent rerouting decisions where tasks\nare allowed to migrate from overloaded to underloaded resources. Their rerouting\nprocess terminates in expected O(log logm + log n) rounds when the system reaches\nan NE. Note that their convergence rate as a function of the number n of resources\nis faster than the one we obtain in this paper. The reason is that it requires agents\nto have a certain amount of global knowledge. A task is required to know whether\nits resource is overloaded (having above-average load), and tasks on underloaded re-\nsources do not migrate at all. Our rerouting policy does not require that agents know\nanything other than their current resource load and the load of a randomly chosen\nalternative. Even-Dar and Mansour also present a general framework that can be\nused to show a logarithmic convergence rate for a wide class of rerouting strategies.\nOur protocol does not fall into that class, since we do not require migrations to occur\nonly from overloaded resources. Note that our lower bound is linear in n (thus, more\nthan logarithmic).\nDistributed algorithms have been studied in the Wardrop setting (the limit of\ninfinitely many agents), for which recent work has also extensively studied the coor-\ndination ratio [28, 27]. Fischer, Ra\u00a8cke, and Vo\u00a8cking [11] investigate convergence to\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nDISTRIBUTED SELFISH LOAD BALANCING 1167\nWardrop equilibria for games where agents select paths through a shared network to\nroute their traffic. (Singleton games correspond to a network of parallel links.) Their\nrerouting strategies are slightly different to ours\u2014they assume that in each round,\nan agent queries a path with probability proportional to the traffic on that path.\nHere we assume that paths (individual elements of a set of parallel links) are queried\nuniformly at random, so that agents can be assumed to have minimal knowledge. As\nin this paper, the probability of switching to a better path depends on the latency\ndifference, and care has to be taken to avoid oscillation. Also in the Wardrop setting,\nBlum, Even-Dar, and Ligett [2] show that approximate NE is the outcome of regret-\nminimizing rerouting strategies, in which an agent\u2019s cost, averaged over time, should\napproximate the cost of the best individual link available to that agent.\nCertain generalizations of singleton games have also been considered. These gen-\neralizations are not strictly congestion games according to the standard definition we\ngave above, but many ideas carry over. One version introduced by Koutsoupias and\nPapadimitriou [18] has been studied extensively in different contexts (for example,\n[20, 6, 13, 4, 28]). In this generalization, each task may have a numerical weight\n(sometimes called traffic, or demand), and each resource has a speed (or capacity).\nThe cost of using a resource is the total weight of tasks using it, divided by its speed.\nEven-Dar, Kesselman, and Mansour [7] give a generalized version of the potential\nfunction of [26] that applies to these games and which was subsequently used in [14].\nFor these games, however, it seems harder to find polynomial-length best-response\nsequences. Feldman et al. [10] show how a sequence of steps may lead to NEs, under\nthe weaker condition that the maximal cost experienced by agents must not increase,\nbut individual steps need not necessarily be \u201cselfish.\u201d They also note that poorly\nchosen better-response moves may lead to an exponential convergence rate. Another\ngeneralization of singleton games is player-specific cost functions [21], which allow\ndifferent agents to have different cost functions for the same resource. In this setting\nthere is no potential function, and better-response dynamics may cycle, although it\nremains the case that pure NEs always exist.\nOur rerouting strategy is also related to reallocation processes for balls-into-bins\ngames. The goal of a balls-into-bins game is to allocate m balls as evenly as possible\ninto n bins. It is well known that a fairly even distribution can be achieved if every ball\nis allowed to randomly choose d bins and then the ball is allocated to the least loaded\namong the chosen bins (see [23] for an overview). Czumaj, Riley, and Scheideler [5]\nconsider such an allocation where each ball initially chooses two bins. They show\nthat, in a polynomial number of steps, the reallocation process ends up in a state\nwith maximum load at most \u0004m\/n\u0005 + 1. Sanders, Egner, and Korst [29] show that\na maximum load of \u0004m\/n\u0005 + 1 is optimal if every ball is restricted to two random\nchoices.\nIn conclusion, this paper sits at one end of a spectrum in which we study a very\nsimple load-balancing game, but we seek solutions in a very adverse setting in which\nagents have, at any point in time, a minimal amount of information about the state\nof their environment and carry out actions simultaneously in a strongly distributed\nsense.\n1.2. Overview of our results. Section 3 deals with upper bounds on conver-\ngence time. The main result, Theorem 3.1, is that the protocol of Figure 2.1 converges\nto an NE within expected time O(log logm+ n4).\nThe proof of Theorem 3.1 shows that the system becomes approximately balanced\nvery rapidly. Specifically, Corollary 3.11 shows that if n \u2264 m1\/3, then for all \u0002, either\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \n1168 BERENBRINK ET AL.\nversion of the distributed protocol (with or without neutral moves allowed) attains an\n\u0002-NE (where all load ratios are within [1\u2212 \u0002, 1+ \u0002]; we use \u0002 to denote a multiplicative\nfactor as in [3]) in expected O(log logm) rounds. The rest of section 3 analyzes the\nprotocol of Figure 2.1. It is shown that within an additional O(n4) rounds the system\nbecomes optimally balanced.\nIn section 4, we provide two lower bound results. The first one, Theorem 4.1,\nshows that the first protocol (of Figure 1.1, including moves that do not necessarily\nyield a strict improvement for an individual task but allow for simply \u201cneutral\u201d moves\nas well) results in exponential (in n) expected convergence time. Finally, in Theo-\nrem 4.2 we provide a general lower bound (regardless of which of the two protocols\nis being used) on the expected convergence time of \u03a9(log logm). This lower bound\nmatches the upper bound as a function of m.\n2. Notation. There are m tasks and n resources. An assignment of tasks to\nresources is represented as a vector (x1, . . . , xn) in which xi denotes the number of\ntasks that are assigned to resource i. In the remainder of this paper, [n] denotes\n{1, . . . , n}. The assignment is an NE if for all i \u2208 [n] and j \u2208 [n], |xi \u2212 xj | \u2264 1.\nWe study a distributed process for constructing an NE. The states of the process,\nX(0), X(1), . . . , are assignments. The transition from state X(t) = (X1(t), . . . , Xn(t))\nto state X(t+ 1) is given by the greedy distributed protocol in Figure 2.1.\nFor each task b do in parallel\nLet ib be the current resource of task b\nChoose resource jb uniformly at random\nLet Xib(t) be the current load of resource i\nLet Xjb(t) be the current load of resource j\nIf Xib(t) > Xjb(t) + 1 then\nMove task b from resource ib to jb with probability 1\u2212Xjb(t)\/Xib(t)\nFig. 2.1. The modified protocol, with \u201cneutral moves\u201d disallowed.\nNote that ifX(t) is an NE, thenX(t+1) = X(t) so the assignment stops changing.\nHere is a formal description of the transition from a stateX(t) = x. Independently, for\nevery i \u2208 [n], let (Yi,1(x), . . . , Yi,n(x)) be a random variable drawn from a multinomial\ndistribution with the constraint\n\u2211n\nj=1 Yi,j(x) = xi. (Yij represents the number of mi-\ngrations from i to j in a round.) The corresponding probabilities (pi,1(x), . . . , pi,n(x))\nare given by\npi,j(x) =\n\u23a7\u23aa\u23a8\n\u23aa\u23a9\n1\nn\n(\n1\u2212 xjxi\n)\nif xi > xj + 1,\n0 if i \b= j but xi \u2264 xj + 1,\n1\u2212\u2211j \u0004=i pi,j(x) if i = j.\nThen Xi(t+ 1) =\n\u2211n\n\u0002=1 Y\u0002,i(x).\nFor any assignment x = (x1, . . . , xn), let x =\n1\nn\n\u2211n\ni=1 xi. We define the potential\nfunction \u03a6(x) =\n\u2211n\ni=1 (xi \u2212 x)2. Note that \u03a6(x) =\n\u2211n\ni=1 x\n2\ni \u2212 nx2 and that a single\nselfish move reduces the potential.\n3. Upper bound on convergence time. Our main result is the following.\nTheorem 3.1. Let T be the number of rounds taken by the protocol of Figure 2.1\nto reach an NE for the first time. Then E[T ] = O(log logm+ n4).\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nDISTRIBUTED SELFISH LOAD BALANCING 1169\nThe proof of this theorem proceeds as follows. First (Lemma 3.6) we give an upper\nbound on E[\u03a6(X(t))] which implies (Corollary 3.10) that there is a \u03c4 = O(log logm)\nsuch that, with high probability, \u03a6(X(\u03c4)) = O(n). We also show (Observation 3.5\nand Corollary 3.14) that \u03a6(X(t)) is a supermartingale and (Lemma 3.15) that it has\nenough variance. Using these facts, we obtain the upper bound on the convergence\ntime.\nDefinition. Let Si(x) = {j | xj < xi \u2212 1}. Si(x) is the set of resources that are\nsignificantly smaller than resource i in state x (in the sense that their loads are at least\ntwo tasks smaller than the load of resource i). Similarly, let Li(x) = {j | xj > xi+1}\nand let di(x) =\n1\nn\n\u2211\nj:|xi\u2212xj |\u22641(xi \u2212 xj).\nObservation 3.2. E[Xi(t+ 1) | X(t) = x] = x+ di(x).\nProof.\nE[Xi(t+ 1) | X(t) = x] =\nn\u2211\n\u0002=1\nE[Y\u0002,i(x)] =\nn\u2211\n\u0002=1\nx\u0002p\u0002,i(x)\n=\n\u2211\n\u0002\u2208Li(x)\nx\u0002\n1\nn\n(\n1\u2212 xi\nx\u0002\n)\n+ xi\n\u239b\n\u239d1\u2212 \u2211\nj\u2208Si(x)\n1\nn\n(\n1\u2212 xj\nxi\n)\u239e\u23a0\n= xi +\n1\nn\n\u239b\n\u239d \u2211\n\u0002\u2208Li(x)\n(x\u0002 \u2212 xi)\u2212\n\u2211\nj\u2208Si(x)\n(xi \u2212 xj)\n\u239e\n\u23a0\n= xi +\n1\nn\n\u2211\n\u0002\u2208Li(x)\u222aSi(x)\n(x\u0002 \u2212 xi)\n= xi +\n1\nn\nn\u2211\n\u0002=1\n(x\u0002 \u2212 xi)\u2212 1\nn\n\u2211\n\u0002 \u0004\u2208Li(x)\u222aSi(x)\n(x\u0002 \u2212 xi)\n= x\u2212 1\nn\n\u2211\n\u0002 \u0004\u2208Li(x)\u222aSi(x)\n(x\u0002 \u2212 xi)\n= x+\n1\nn\n\u2211\n\u0002 \u0004\u2208Li(x)\u222aSi(x)\n(xi \u2212 x\u0002).\nObservation 3.3.\n\u2211n\ni=1(E[Xi(t+ 1) | X(t) = x])2 = nx2 +\n\u2211n\ni=1 di(x)\n2.\nProof. Using Observation 3.2,\nn\u2211\ni=1\n(E[Xi(t+ 1) | X(t) = x])2 =\nn\u2211\ni=1\n(x+ di(x))\n2 = nx2 + 2x\nn\u2211\ni=1\ndi(x) +\nn\u2211\ni=1\ndi(x)\n2,\nand the second term is zero since di(x) = E[Xi(t+ 1) | X(t) = x]\u2212 x.\nObservation 3.4. var[Xi(t+1) | X(t) = x] \u2264 1n\n\u2211\n\u0002\u2208Li(x) (x\u0002\u2212xi)+ 1n\n\u2211\nj\u2208Si(x) (xi\u2212\nxj).\nProof.\nvar(Xi(t+ 1) | X(t) = x) =\nn\u2211\n\u0002=1\nvar(Y\u0002,i(x)) =\nn\u2211\n\u0002=1\nx\u0002p\u0002,i(x)(1\u2212 p\u0002,i(x))\n=\n\u2211\n\u0002\u2208Li(x)\nx\u0002\n1\nn\n(\n1\u2212 xi\nx\u0002\n)\n(1\u2212 p\u0002,i(x))\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \n1170 BERENBRINK ET AL.\n+ xipi,i(x)\n\u239b\n\u239d \u2211\nj\u2208Si(x)\n1\nn\n(\n1\u2212 xj\nxi\n)\u239e\u23a0\n=\n1\nn\n\u2211\n\u0002\u2208Li(x)\n(x\u0002 \u2212 xi)(1\u2212 p\u0002,i(x)) + pi,i(x) 1\nn\n\u2211\nj\u2208Si(x)\n(xi \u2212 xj)\n\u2264 1\nn\n\u2211\n\u0002\u2208Li(x)\n(x\u0002 \u2212 xi) + 1\nn\n\u2211\nj\u2208Si(x)\n(xi \u2212 xj).\nDefinition. For any assignment x, let si(x) = |{j | xj = xi \u2212 1}| and li(x) =\n|{j | xj = xi + 1}|. Let u1(x) =\n\u2211n\ni=1\n\u2211\nj\u2208[n]:|xi\u2212xj |>1 |xi \u2212 xj | and u2(x) =\u2211n\ni=1(si(x) \u2212 li(x))2. Let u(x) = u1(x)\/n + u2(x)\/n2. We will show that u(x) is\nan upper bound on the expected potential after one step, starting from state x. The\nquantity u1(x) corresponds to the contribution arising from the sum of the variances\nof the individual loads, and u2(x) corresponds to the rest.\nObservation 3.5. E[\u03a6(X(t+ 1)) | X(t) = x] \u2264 u(x).\nProof.\nE[\u03a6(X(t+ 1)) | X(t) = x] + nx2 =\nn\u2211\ni=1\nE[Xi(t+ 1)\n2 | X(t) = x]\n=\nn\u2211\ni=1\n(E[Xi(t+ 1) | X(t) = x])2\n+\nn\u2211\ni=1\nvar(Xi(t+ 1) | X(t) = x).\nUsing Observations 3.3 and 3.4, this is at most nx2 +\n\u2211n\ni=1 di(x)\n2 + u1(x)\/n. But\ndi(x) =\n1\nn\n\u2211\nj:|xi\u2212xj |\u22641\n(xi \u2212 xj) = 1\nn\n(si(x)\u2212 \u0003i(x)),\nso the result follows.\nLemma 3.6. E[\u03a6(X(t+ 1)) | X(t) = x] \u2264 n+ 2n1\/2\u03a6(x)1\/2.\nProof. In the proof of Observation 3.5, we established that E[\u03a6(X(t+1)) | X(t) =\nx] \u2264\u2211ni=1 di(x)2 + u1(x)\/n. Upper-bounding u1(x) and using di(x) \u2264 1, we have\nE[\u03a6(X(t+ 1)) | X(t) = x] \u2264 n+ 1\nn\nn\u2211\ni=1\nn\u2211\nj=1\n|xi \u2212 xj |,\nand since |xi \u2212 xj | \u2264 |xi \u2212 x| + |xj \u2212 x|, this is at most n + 2\n\u2211n\ni=1 |xi \u2212 x|. By\nCauchy\u2013Schwarz, (\n\u2211\ni |xi \u2212 x| \u00b7 1)2 \u2264\n\u2211\ni |xi \u2212 x|2\n\u2211\ni 1; thus\nE[\u03a6(X(t+ 1)) | X(t) = x] \u2264 n+ 2\n(\nn\nn\u2211\ni=1\n|xi \u2212 x|2\n)1\/2\n.\nCorollary 3.7. E[\u03a6(X(t+ 1))] \u2264 n+ 2n1\/2(E[\u03a6(X(t))])1\/2.\nProof. Using Lemma 3.6, E[\u03a6(X(t + 1))] \u2264 n + 2n1\/2E[f1\/2], where f denotes\nthe random variable \u03a6(X(t)). By Jensen\u2019s inequality E[f1\/2] \u2264 (E[f ])1\/2 since the\nsquare-root function is concave, so we get E[\u03a6(X(t+ 1))] \u2264 n+ 2n1\/2(E[f ])1\/2.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nDISTRIBUTED SELFISH LOAD BALANCING 1171\nLemma 3.8. Either there is a t\u2032 < t such that E[\u03a6(X(t\u2032))] \u2264 18n or E[\u03a6(X(t))] \u2264\n91\u22122\n\u2212t\nn1\u22122\n\u2212t\n\u03a6(X(0))2\n\u2212t\n.\nProof. The proof is by induction on t. The base case is t = 0. For the inductive\nstep, note that 1 \u2212 2\u2212t = \u2211tk=1 2\u2212k. Suppose that for all t\u2032 < t, E[\u03a6(X(t\u2032))] > 18n\n(otherwise we are finished). Then by Corollary 3.7,\nE[\u03a6(X(t))] = n+ 2n1\/2(E[\u03a6(X(t\u2212 1))])1\/2 \u2264 3n1\/2(E[\u03a6(X(t\u2212 1))])1\/2.\nApplying the inductive hypothesis,\nE[\u03a6(X(t))] \u2264 3n1\/2(32(1\u22122\u2212(t\u22121))n1\u22122\u2212(t\u22121)\u03a6(X(0))2\u2212(t\u22121))\n1\/2\n.\nCorollary 3.9. There is a \u03c4 \u2264 \u0004lg lg \u03a6(X(0))\u0005 such that E[\u03a6(X(\u03c4))] \u2264 18n.\nProof. Take t = \u0004lg lg \u03a6(X(0))\u0005. Either there is a \u03c4 < t with E[\u03a6(X(\u03c4))] \u2264 18n\nor, by the lemma,\nE[\u03a6(X(t))] \u2264 9n\u03a6(X(0))2\u2212t \u2264 18n.\nCorollary 3.10. There is a \u03c4 \u2264 \u0004lg lg \u03a6(X(0))\u0005 such that Pr(\u03a6(X(\u03c4)) >\n720n) \u2264 1\/40.\nProof. Consider the (nonnegative) random variable Y = \u03a6(X(\u03c4)), where \u03c4 is the\nquantity from Corollary 3.9. Markov\u2019s inequality says that for any a > 0, Pr(Y \u2265\na) \u2264 E[Y ]\/a. Now use Corollary 3.9 with a = 720n.\nCorollary 3.11. For all \u0002 > 0, provided that n < m1\/3, the expected time to\nreach an \u0002-NE is O(log logm).\nProof. Since the bound is asymptotic as a function of m for fixed \u0002, we can\nassume without loss of generality that m > (60\/\u0002)2 and that \u0002m\/(2n) is an integer.\nWe show that for any starting assignment X(0), there exists \u03c4 \u2264 log log(m2) such that\nPr(X(\u03c4) is \u0002-Nash) > 3940 . This implies the statement of the result since the number\nof blocks of \u03c4 steps needed to reach an \u0002-NE is at most\n1 +\n(\n1\n40\n)\n+\n(\n1\n40\n)2\n+ \u00b7 \u00b7 \u00b7 = 40\n39\n< 2.\nSuppose assignment x is not \u0002-Nash. If X(t) = x, there exist resources i, j with\nXi(t) \u2212 Xj(t) > \u0002m\/n. We use the following notation. Let \u0394 = \u0002m\/(2n). Let\n\u03b2 = Xi(t)\u2212Xj(t)\u22122\u0394. Note \u03b2 > 0. If X(t+1) is obtained from X(t) by transferring\n\u0394 tasks from i to j, then\n\u03a6(X(t))\u2212 \u03a6(X(t+ 1))\n= Xi(t)\n2 +Xj(t)\n2 \u2212Xi(t+ 1)2 \u2212Xj(t+ 1)2\n= (2\u0394 + \u03b2 +Xj(t))\n2 +Xj(t)\n2 \u2212 (\u0394 + \u03b2 +Xj(t))2 \u2212 (\u0394 +Xj(t))2\n= 2\u0394(\u0394 + \u03b2 +Xj(t)) + \u0394\n2 \u2212 (2\u0394Xj(t) + \u03942)\n= 2\u0394(\u0394 + \u03b2) \u2265 \u03942 = (\u0002m\/2n)2.\nIt follows that \u03a6(X(t)) \u2265 (\u0002m\/2n)2. From Corollary 3.10, Pr(\u03a6(X(\u03c4)) < 720n) > 3940 ,\nfor \u03c4 = log log(\u03a6(0)) = O(log logm).\nAn assignment X(\u03c4) with \u03a6(X(\u03c4)) \u2264 720n must be \u0002-Nash if (\u0002m\/2n)2 > 720n.\nNote that m > n3 and m > (60\/\u0002)2. Hence, from \u00022(60\/\u0002)2n3 > 4.720.n3, we can\ndeduce \u00022m2 > 4.720.n3; hence (\u0002m\/2n)2 > 720n.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \n1172 BERENBRINK ET AL.\nCorollary 3.10 tells us that \u03a6(X(\u03c4)) is likely to be O(n). We want to show that\n\u03a6(X(t)) quickly gets even smaller (all the way to an NE) and to this end, we show that\n\u03a6(X(t)) is a supermartingale. By Observation 3.5, it suffices to show u(x) \u2264 \u03a6(x),\nand we proceed with this. In the following, we shall consider the cases |xi \u2212 x| < 2.5\nfor all i \u2208 [n] (Lemma 3.12) and \u2203i \u2208 [n] : |xi \u2212 x| \u2265 2.5 (Lemma 3.13) separately.\nLemma 3.12. Suppose that assignment x = (x1, . . . , xn) satisfies |xi \u2212 x| < 2.5\nfor all i \u2208 [n]. Then u(x) \u2264 \u03a6(x).\nProof. For all i \u2208 [n] and j \u2208 [n] we have |xi \u2212 xj | \u2264 |xi \u2212 x|+ |xj \u2212 x| < 5. Let\nz = mini xi so that every xi \u2208 {z, . . . , z + 4}. Let ni = |{j | xj = z + i}|. Then\nn2\u03a6(x) = n2\nn\u2211\ni=1\nx2i \u2212 n\n(\nn\u2211\ni=1\nxi\n)2\n= n2\n\u239b\n\u239d 4\u2211\nj=0\nnj(z + j)\n2\n\u239e\n\u23a0\u2212\n\u239b\n\u239d 4\u2211\nj=0\nnj(z + j)\n\u239e\n\u23a0\n2\n.\nAlso, n2u(x) = nu1(x) + u2(x), where\nu1(x) = n0(2n2 + 3n3 + 4n4) + n1(2n3 + 3n4)\n+ n2(2n0 + 2n4) + n3(3n0 + 2n1) + n4(4n0 + 3n1 + 2n2)\nand\nu2(x) = n0n\n2\n1 + n1(n0 \u2212 n2)2 + n2(n1 \u2212 n3)2 + n3(n2 \u2212 n4)2 + n4n23.\nPlugging in these expressions and simplifying, we get\nn2\u03a6(x)\u2212 n2u(x)\n= 4n0n1n2 + 3n\n2\n0n3 + 4n0n1n3 + 4n0n2n3 + 4n1n2n3 + 3n0n\n2\n3\n+ 8n20n4 + 12n0n1n4 + 3n\n2\n1n4 + 8n0n2n4 + 4n1n2n4 + 12n0n3n4\n+ 4n1n3n4 + 4n2n3n4 + 8n0n\n2\n4 + 3n1n\n2\n4,\nwhich is clearly nonnegative since all coefficients are positive.\nLemma 3.13. Suppose that assignment x = (x1, . . . , xn) satisfies |xn \u2212 x| \u2265 2.5\nand, for all i \u2208 [n], |xi \u2212 x| \u2264 |xn \u2212 x|. Let w = (w1, . . . , wn\u22121) be the assignment\nwith wi = xi for i \u2208 [n \u2212 1]. Then \u03a6(x) \u2212 u(x) \u2265 \u03a6(w) \u2212 u(w); that is, the lower\nbound on the potential drop for x is at least as big as that for w.\nProof. Let k = |xn \u2212 x|. We will show that\n(1) \u03a6(x)\u2212 \u03a6(w) \u2265 k2 and\n(2) u(x)\u2212 u(w) \u2264 2k + 1.\nThen\n\u03a6(x)\u2212 u(x)\u2212 (\u03a6(w)\u2212 u(w)) \u2265 k2 \u2212 (2k + 1),\nwhich is nonnegative since k \u2265 2.5 \u2265 1 +\u221a2.\nFirst, we prove (1). Let f(z) =\n\u2211n\u22121\ni=1 (xi \u2212 z)2. Note that the derivative of f(z)\nis\nf \u2032(z) = 2(n\u2212 1)z \u2212 2\nn\u22121\u2211\ni=1\nxi = 2(n\u2212 1)z \u2212 2(n\u2212 1)w.\nFurthermore, the second derivative is f \u2032\u2032(z) = 2(n\u2212 1) \u2265 0. Thus, f(z) is minimized\nat z = w. Now note that\n\u03a6(x)\u2212 \u03a6(w) = k2 +\nn\u22121\u2211\ni=1\n(xi \u2212 x)2 \u2212\nn\u22121\u2211\ni=1\n(xi \u2212 w)2 \u2265 k2.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nDISTRIBUTED SELFISH LOAD BALANCING 1173\nNow we finish the proof by proving (2). Assume first that xn = x+ k. Then\nu1(x)\u2212 u1(w) = 2\n\u2211\ni\u2208[n]:|xi\u2212xn|>1\n|xi \u2212 xn| \u2264 2\nn\u2211\ni=1\n|xi \u2212 xn| = 2\nn\u2211\ni=1\n(xn \u2212 xi) = 2nk.\nLet zj = |{\u0003 | x\u0002 = j}|. Clearly zj = 0 for j > xn. Let \u03be = \u0004xn \u2212 2k\u0005. For \u0003 \u2208 [n] we\nhave x\u0002 \u2265 x\u2212 k = xn \u2212 2k, so zj = 0 for j < \u03be. Now u2(x) =\n\u2211xn\nj=\u03be zj(zj\u22121 \u2212 zj+1)2.\nThe representation of w in terms of zjs is the same as the representation of x except\nthat zxn is reduced by one. Therefore,\nu2(x)\u2212 u2(w) = zxn\u22121\n(\n(zxn\u22122 \u2212 zxn)2 \u2212 (zxn\u22122 \u2212 zxn + 1)2\n)\n+ (zxn\u22121 \u2212 zxn+1)2\n= zxn\u22121(\u22122zxn\u22122 + 2zxn + zxn\u22121 \u2212 1) \u2264 zxn\u22121(2zxn + zxn\u22121).\nBut since zxn \u2264 n\u2212 zxn\u22121, the upper bound on the right-hand side is at most\nzxn\u22121(2n\u2212 2zxn\u22121 + zxn\u22121) = 2zxn\u22121(n\u2212 zxn\u22121\/2),\nwhich is at most n2 since the right-hand side is maximized at zxn\u22121 = n. To finish\nthe proof of (2), use the definition of u to deduce that\nu(x)\u2212 u(w) \u2264 u1(x)\u2212 u1(w)\nn\n+\nu2(x)\u2212 u2(w)\nn2\n.\nThe proof of (2) when xn = x\u2212 k is similar.\nCorollary 3.14. For any assignment x = (x1, . . . , xn), \u03a6(x)\u2212 u(x) \u2265 0.\nProof. The proof is by induction on n. The base case, n = 1, follows from\nLemma 3.12. Suppose n > 1. Neither \u03a6(x) nor u(x) depends upon the order of the\ncomponents in x, so assume without loss of generality that |xi \u2212 x| \u2264 |xn \u2212 x| for\nall i. If |xn \u2212 x| < 2.5, then apply Lemma 3.12. Otherwise, use Lemma 3.13 to find\nan assignment w = (w1, . . . , wn\u22121) such that \u03a6(x) \u2212 u(x) \u2265 \u03a6(w) \u2212 u(w). By the\ninductive hypothesis, \u03a6(w)\u2212 u(w) \u2265 0.\nTogether, Observation 3.5 and Corollary 3.14 tell us that E[\u03a6(X(t+1)) | X(t) =\nx] \u2264 \u03a6(x). The next lemma will be used to give a lower bound on the variance of the\nprocess. Let V = 0.4n\u22122.\nLemma 3.15. Suppose that X(t) = x and that x is not an NE. Then\nPr(\u03a6(X(t+ 1)) \b= \u03a6(x) | X(t) = x) \u2265 V.\nProof. Choose s and \u0003 such that for all i \u2208 [n], xs \u2264 xi \u2264 x\u0002. Since x is not an\nNE, x\u0002 > xs +1. Assuming X(t) = x, consider the following experiment for choosing\nX(t+ 1).\nThe intuition behind the experiment is as follows. We wish to show that the\ntransition from X(t) to X(t + 1) has some variance in the sense that \u03a6(X(t + 1)) is\nsufficiently likely to differ from \u03a6(X(t)). To do this, we single out a \u201cleast loaded\u201d\nresource s and a \u201cmost loaded\u201d resource \u0003 as above. In the transition from X(t) to\nX(t + 1) we make transitions from resources other than resource \u0003 in the usual way.\nWe pay special attention to transitions from resource \u0003 (and particular attention to\ntransitions from resource \u0003 which could either go to resource s or stay at resource \u0003).\nIt helps to be very precise about how the random decisions involving tasks that start\nat resource \u0003 are made. In particular, for each task b that starts at resource \u0003, we\nfirst make a decision about whether b would accept the transition from resource \u0003 to\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \n1174 BERENBRINK ET AL.\nresource s if b happened to choose resource s. Then we make the decision about which\nresource task b should choose. Of course, we cannot cheat and we have to sample\nfrom the original required distribution. Here are the details.\nIndependently, for every i \b= \u0003, choose (Yi,1(x), . . . , Yi,n(x)) from the multinomial\ndistribution described in section 2. (In the informal description above, this corre-\nsponds to making transitions from resources other than resource \u0003 in the usual way.)\nNow, for every task b \u2208 x\u0002, let zb = 1 with probability 1 \u2212 xs\/x\u0002 and zb = 0 oth-\nerwise. (In the informal description above, this corresponds to deciding whether b\nwould accept the transition to s if resource s were (later) chosen.) Let x+\u0002 be the\nnumber of tasks b with zb = 1 and let x\n\u2212\n\u0002 be the number of tasks b with zb = 0.\nChoose (Y +\u0002,1(x), . . . , Y\n+\n\u0002,n(x)) from a multinomial distribution with the constraint\u2211n\nj=1 Y\n+\n\u0002,j(x) = x\n+\n\u0002 and probabilities given by\np+\u0002,j(x) =\n\u23a7\u23aa\u23aa\u23aa\u23a8\n\u23aa\u23aa\u23aa\u23a9\n1\nn if j = s,\n1\nn\n(\n1\u2212 xjx\u0002\n)\nif j \b= s and x\u0002 > xj + 1,\n0 if \u0003 \b= j but x\u0002 \u2264 xj + 1,\n1\u2212\u2211j \u0004=\u0002 p\u0002,j(x) if \u0003 = j.\nSimilarly, choose (Y \u2212\u0002,1(x), . . . , Y\n\u2212\n\u0002,n(x)) from a multinomial distribution with the con-\nstraint\n\u2211n\nj=1 Y\n\u2212\n\u0002,j(x) = x\n\u2212\n\u0002 and probabilities given by\np\u2212\u0002,j(x) =\n\u23a7\u23aa\u23aa\u23aa\u23a8\n\u23aa\u23aa\u23aa\u23a9\n0 if j = s,\n1\nn\n(\n1\u2212 xjx\u0002\n)\nif j \b= s and x\u0002 > xj + 1,\n0 if \u0003 \b= j but x\u0002 \u2264 xj + 1,\n1\u2212\u2211j \u0004=\u0002 p\u0002,j(x) if \u0003 = j.\nFor all j, let Y\u0002,j(x) = Y\n+\n\u0002,j(x) + Y\n\u2212\n\u0002,j(x). Informally, the p\n+\n\u0002,j transition probabilities\nare set up so that packets which decided that they would accept a transition to s\nbehave appropriately, and the p\u2212\u0002,j transition probabilities are set up so that packets\nwhich decided that they would not accept a transition to s behave appropriately. By\ncombining the probabilities, we see thatX(t+1) is chosen from the correct distribution\nin this way.\nNow, consider the transition from x to X(t + 1). Condition on the choice for\n(Yi,1(x), . . . , Yi,n(x)) for all i \b= \u0003. Suppose x+\u0002 > 2. Condition on the choice for\n(Y \u2212\u0002,1(x), . . . , Y\n\u2212\n\u0002,n(x)). Flip a coin for each of the first x\n+\nb \u2212 2 tasks with zb = 1 to\ndetermine which of Y +\u0002,1(x), . . . , Y\n+\n\u0002,n(x) the task contributes to. Condition on these\nchoices. Consider the following options:\n(1) Let x1 be the resulting value of X(t + 1) when we add both of the last two\ntasks to Y +\u0002,\u0002(x).\n(2) Let x2 be the resulting value of X(t + 1) when we add one of the last two\ntasks to Y +\u0002,\u0002(x) and the other to Y\n+\n\u0002,s(x).\n(3) Let x3 be the resulting value of X(t + 1) when we add both of the last two\ntasks to Y +s,s(x).\nNote that, given the conditioning, each of these choices occurs with probability at\nleast n\u22122. Also, \u03a6(x1), \u03a6(x2), and \u03a6(x3) are not all the same. Thus, Pr(\u03a6(X(t+1) \b=\n\u03a6(x) | X(t) = x, x+\u0002 > 2) \u2265 n\u22122. Also,\nPr(x+\u0002 > 2) = 1\u2212\n(\nxs\nx\u0002\n)x\u0002\n\u2212 x\u0002\n(\n1\u2212 xs\nx\u0002\n)(\nxs\nx\u0002\n)x\u0002\u22121\n.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nDISTRIBUTED SELFISH LOAD BALANCING 1175\nSince the derivative with respect to xs is negative, this is minimized by taking xs as\nlarge as possible, namely x\u0002 \u2212 2; thus Pr(x+\u0002 > 2) \u2265 1 \u2212 7e\u22122 \u2265 0.4, and the result\nfollows.\nIn order to finish our proof of convergence, we need the following observation\nabout \u03a6(x).\nObservation 3.16. For any assignment x, \u03a6(x) \u2264 m2. Let r = m mod n. Then\n\u03a6(x) \u2265 r(1\u2212 r\/n), with equality if and only if x is an NE.\nProof. Suppose that in assignment x there are resources i and j such that xi\u2212xj \u2265\n2. Let x\u2032 be the assignment constructed from x by transferring a task from resource\ni to resource j. Then\n\u03a6(x)\u2212 \u03a6(x\u2032) = x2i \u2212 x\u2032i2 + x2j \u2212 x\u2032j2 = x2i \u2212 (x2i \u2212 2xi + 1) + x2j \u2212 (x2j + 2xj + 1)\n= 2xi \u2212 2xj \u2212 2 = 2(xi \u2212 xj)\u2212 2 > 0.\nNow suppose that, in some assignment x\u2032, resources i and j satisfy x\u2032i \u2265 x\u2032j > 0. Let\nx be the assignment constructed from x\u2032 by transferring a task from resource j to\nresource i. Since (x\u2032i +1)\u2212 (x\u2032j \u2212 1) \u2265 2, the above argument gives \u03a6(x) > \u03a6(x\u2032). We\nconclude that an assignment x with maximum \u03a6(x) must have all of the tasks in the\nsame resource, with \u03a6(x) = m2.\nFurthermore, an assignment x with minimum \u03a6(x) must have |xi \u2212 xj | \u2264 1 for\nall i, j. In this case there must be r resources with loads of q + 1 and n\u2212 r resources\nwith loads of q, where m = qn+ r. So\n\u03a6(x) = r(q + 1\u2212 x\u00af)2 + (n\u2212 r)(q \u2212 x\u00af)2 = r\n(\n1\u2212 r\nn\n)2\n+ (n\u2212 r)\n( r\nn\n)2\n= r\n(\n1\u2212 r\nn\n)\n.\nNote that x is a Nash assignment if and only if |xi \u2212 xj | \u2264 1 for all i and j.\nCombining Observation 3.16 and Corollary 3.10, we find that there is a \u03c4 \u2264\n\u0004lg lgm2\u0005 such that Pr(\u03a6(X(\u03c4)) > 720n) \u2264 1\/40. Let B = 7200n+\n\u2308\nm2\nn\n\u2309\n\u2212 m2n . Let\nt\u2032 = \u03c4 + \u000410B2\/V \u0005.\nLemma 3.17. Given any starting state X(0) = x, the probability that X(t\u2032) is an\nNE is at least 3\/4.\nProof. The proof is based on a standard martingale argument; see [19]. Suppose\nthat \u03a6(X(\u03c4)) \u2264 720n. Let Wt = \u03a6(X(t+ \u03c4))\u2212 r(1\u2212 r\/n) and let Dt = min(Wt, B).\nNote that D0 \u2264 720n. Together, Observation 3.5 and Corollary 3.14 tell us that Wt\nis a supermartingale. This implies that Dt is also a supermartingale since\nE[Dt+1 | Dt = x < B] \u2264 E[Wt+1 |Wt = x < B] \u2264Wt = Dt,\nand\nE[Dt+1 | Dt = B] \u2264 B = Dt.\nTogether, Lemma 3.15 and Observation 3.16 tell us that if x > 0, Pr(Wt+1 \b= Wt |\nWt = x) \u2265 V . Thus, if 0 < x < B,\nPr(Dt+1 \b= Dt | Dt = x) = Pr(min(Wt+1, B) \b= Wt |Wt = x)\n\u2265 Pr(Wt+1 \b= Wt \u2227B \b= Wt |Wt = x)\n= Pr(Wt+1 \b= Wt |Wt = x) \u2265 V.\nSince Dt+1 \u2212 Dt is an integer, E[(Dt+1 \u2212 Dt)2 | 0 < Dt < B] \u2265 V . Let T be the\nfirst time at which either (a) Dt = 0 (i.e., X(t + \u03c4) is an NE), or (b) Dt = B.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \n1176 BERENBRINK ET AL.\nNote that T is a stopping time. Define Zt = (B \u2212 Dt)2 \u2212 V t, and observe that\nZt\u2227T is a submartingale, where t \u2227 T denotes the minimum of t and T . Let p be\nthe probability that (a) occurs. By the optional stopping theorem E[DT ] \u2264 D0; thus\n(1 \u2212 p)B = E[DT ] \u2264 D0 and p \u2265 1 \u2212 D0\/B \u2265 910 . Also, by the optional stopping\ntheorem\npB2 \u2212 V E[T ] = E[(B \u2212DT )2]\u2212 V E[T ] = E[ZT ] \u2265 Z0 = (B \u2212D0)2 > 0,\nand thus E[T ] \u2264 pB2\/V . Conditioning on the occurrence of (a), it follows that\nE[T | DT = 0] \u2264 B2\/V . Hence Pr(T > 10B2\/V | DT = 0) \u2264 110 . So, if we now\nrun for 10B2\/V steps, then the probability that we do not reach an NE is at most\n1\n40 + 2 \u00b7 110 < 1\/4.\nNow we can give the proof of Theorem 3.1.\nProof. Subdivide time into intervals of t\u2032 steps. The probability that the process\nhas not reached an NE before the (j + 1)st interval is at most (1\/4)\u2212j .\n4. Lower bounds. In this section we prove the lower bound results stated in\nthe introduction. We will use the following Chernoff bound which can be found, for\nexample, in [15]. Let N \u2265 1 and let pi \u2208 [0, 1] for i = 1, . . . , N . Let X1, X2, . . . , XN\nbe independent Bernoulli random variables with Pr(Xi = 1) = pi for i = 1, . . . , N\nand let X = X1 + \u00b7 \u00b7 \u00b7+XN . Then we have E[X] =\n\u2211N\ni=1 pi and for 0 \u2264 \u0002 \u2264 1,\n(4.1) Pr(X \u2264 (1\u2212 \u0002) \u00b7 E[X]) \u2264 exp\n(\n\u2212\u0002\n2 \u00b7 E[X]\n3\n)\n.\nThe following theorem gives an exponential lower bound for the expected conver-\ngence time of the process in Figure 1.1.\nTheorem 4.1. Let X(t) be the process in Figure 1.1 with m = n. Let X(0) be\nthe assignment given by X(0) = (n, 0, . . . , 0). Let T be the first time at which X(t) is\nan NE. Then E[T ] = exp(\u0398(\n\u221a\nn)).\nProof. For an assignment x, let n0(x) denote the number of resources i with\nxi = 0. Thus, n0(X(0)) = n \u2212 1. The (unique) NE x assigns one task to each\nresource; thus n0(x) = 0. Let k = \f\n\u221a\nn\r. We will show that for any assignment x\nwith n0(x) \u2265 k,\nPr(n0(X(t)) < k | X(t\u2212 1) = x) \u2264 exp(\u2212\u0398(\n\u221a\nn)).\nThis implies the result.\nSuppose X(t\u2212 1) = x with n0(x) \u2265 k. For convenience, let n0 denote n0(x). Let\nx\u2032 denote X(t), and let n\u20320 denote n0(x\n\u2032). We will show that, with probability at least\n1 \u2212 exp(\u2212\u0398(\u221an)), n\u20320 \u2265 k. During the course of the proof, we will assume, where\nnecessary, that n is sufficiently large. This is without loss of generality given the \u0398\nnotation in the statement of the result.\nCase 1. n0 > 8k.\nConsider the protocol in Figure 1.1. Let U = {b | xjb = 0}. E[|U |] = n0, so by\nthe Chernoff bound (4.1), Pr(|U | \u2264 \u0004n02 \u0005+ \u0004 3n08 \u0005) \u2264 Pr(|U | \u2264 89n0) = exp (\u2212\u0398(\n\u221a\nn)).\nThus, |U | \u2265 \u0004n0\/2\u0005 + \u00043n0\/8\u0005 with probability at least 1 \u2212 exp(\u2212\u0398(\n\u221a\nn)). Suppose\nthis is the case. Partition U into U1 and U2 with |U1| = \u0004n0\/2\u0005. Let W = \u222ab\u2208U1{jb}.\nFirst, suppose |W | \u2264 38n0. In that case\n|{j | x\u2032j > 0}| \u2264 n\u2212 |U1|+\n3\n8\nn0 = n\u2212 \u0004n0\/2\u0005+ 3\n8\nn0 \u2264 n\u2212 k,\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nDISTRIBUTED SELFISH LOAD BALANCING 1177\nso n\u20320 \u2265 k. Otherwise, let U \u2032 = {b \u2208 U2 | jb \u2208W}. Since\nE[|U \u2032|] = |U2| |W |\nn0\n\u2265 9\n64\nn0 >\n9\n8\nk,\nby the Chernoff bound (4.1), Pr(|U \u2032| \u2264 k) = Pr(|U \u2032| \u2264 (1\u2212 19 )E[|U \u2032|]) = exp (\u2212\u0398(\n\u221a\nn)),\nrecalling that k = \f\u221an\r. Thus |U \u2032| \u2265 k with probability at least 1 \u2212 exp(\u2212\u0398(\u221an)),\nwhich implies n\u20320 \u2265 k.\nCase 2. k \u2264 n0 \u2264 8k.\nConsider the protocol in Figure 1.1. Let L be the set of \u201cloners\u201d defined by\nL = {i | xi = 1} and let \u0003 = |L|. The number of resources i with xi > 1 is n\u2212 n0 \u2212 \u0003,\nand this is at most half as many as the number of tasks assigned to such resources\n(which is n \u2212 \u0003), so \u0003 \u2265 n \u2212 2n0. Let U = {b | ib \u2208 L and xjb = 0}. E[|U |] =\n\u0003n0n \u2265 (n\u22122n0)n0n = \u0398(\n\u221a\nn), so by the Chernoff bound (4.1), Pr(|U | \u2264 2\u0004 14\u0003n0n \u0005) \u2264\nPr(|U | \u2264 23E[|U |]) \u2264 exp (\u2212\u0398(\n\u221a\nn)). Thus, |U | \u2265 2\u0004 14\u0003n0n \u0005 with probability at least\n1 \u2212 exp(\u2212\u0398(\u221an)). Suppose this is the case. Let U1 and U2 be disjoint subsets of\nU of size \u0004 14\u0003n0n \u0005. Order tasks in U arbitrarily and let S = {b \u2208 U | for some\nb\u2032 \u2208 U with b\u2032 < b, jb\u2032 = jb.}. (Note that |S| does not depend on the ordering.) Let\nW = \u222ab\u2208U1{jb}.\nNote that if |W | \u2264 15\u0003n0n , then |S| \u2265 120\u0003n0n > n040\n(\n\u0002\nn\n)2\n. Otherwise, let U \u2032 = {b \u2208\nU2 | jb \u2208W}. Since\nE[|U \u2032|] = |U2| |W |\nn0\n\u2265 n0\n20\n(\n\u0003\nn\n)2\n,\nby the Chernoff bound (4.1), Pr(|U \u2032| \u2264 12 n020\n(\n\u0002\nn\n)2\n) \u2264 exp (\u2212\u0398(\u221an)) (recall that\nn0\n(\n\u0002\nn\n)2 \u2265 n0 (n\u22122n0n )2 \u2265 k (n\u221216kn )2 = \u0398(\u221an)), and thus |U \u2032| \u2265 n040 ( \u0002n)2 with prob-\nability at least 1\u2212 exp(\u2212\u0398(\u221an)); hence |S| \u2265 n040\n(\n\u0002\nn\n)2\n.\nSuppose then that |S| \u2265 n040\n(\n\u0002\nn\n)2\n. Assuming that n is sufficiently large, |S| \u2265\nk\/41. Let B0 = \u222ab\u2208U{jb} and B1 = \u222ab\u2208L\u2212U{ib}. Note that every resource in B0\u222aB1\nis used in x\u2032 for some task b \u2208 L. Thus, |B0 \u222a B1| \u2264 \u0003 \u2212 |S|. Let R = {i | xi =\n0} \u222a L\u2212B0 \u2212B1. Then |R| \u2265 n0 + \u0003\u2212 (\u0003\u2212 |S|) \u2265 n0 + |S| \u2265 (1 + 141 )k.\nLet T = {b | ib \b\u2208 L, jb \u2208 R}. E[T ] = (n\u2212 \u0003) |R|n , and\nPr\n(\nT \u2265 |R|\n100\n)\n\u2264\n(\nn\u2212 \u0003\n|R|\n100\n)( |R|\nn\n)|R|\/100\n\u2264\n(\n2n0e100\nn\n)|R|\/100\n;\nthus with probability at least 1 \u2212 exp(\u2212\u0398(\u221an)), T < |R|\/100. In that case, n\u20320 \u2265\n|R|(1\u2212 1100 ) \u2265 k.\nThe following theorem provides a lower bound on the expected convergence time\nregardless of which of the two protocols is being used.\nTheorem 4.2. Suppose that m is even. Let X(t) be the process in Figure 2.1\nwith n = 2. Let X(0) be the assignment given by X(0) = (m, 0). Let T be the first\ntime at which X(t) is an NE. Then E[T ] = \u03a9(log logm). The same result holds for\nthe process in Figure 1.1.\nProof. Note that both protocols have the same behavior since m is even, and,\ntherefore, the situation x1 = x2 + 1 cannot arise. For concreteness, focus on the\nprotocol in Figure 2.1.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \n1178 BERENBRINK ET AL.\nLet y(x) = maxi xi\u2212m\/2 and let yt = y(X(t)); thus y0 = m\/2 and, for an NE x,\ny(x) = 0. We will show that for any assignment x, Pr(yt+1 > y(x)\n1\/10 | X(t) = x) \u2265\n1 \u2212 y\u22121\/4t . (There is nothing very special about the exact value \u201c1\/10\u201d\u2014this value\nis being used as part of an explicit \u201clack of concentration\u201d inequality in the proof,\nnoting that for a lower bound we essentially want to lower-bound the variances of the\nload distributions. This seems to require a somewhat ad hoc approach, in contrast\nwith the usage of concentration inequalities.)\nSuppose X(t) = x is an assignment with x1 \u2265 x2. As we have seen in section 2,\nY1,2(x) (the number of migrations from resource 1 to resource 2 in the round) is a\nbinomial random variable\nB\n(\nx1,\n1\n2\n(\n1\u2212 x2\nx1\n))\n= B\n(\nm\n2\n+ yt,\n2yt\nm+ 2yt\n)\n.\nIn general, let Tt be the number of migrations from the most-loaded resource in X(t)\nto the least-loaded resource and note that the distribution of Tt is B\n(\nm\n2 + yt,\n2yt\nm+2yt\n)\nwith mean yt. If Tt = yt + \u0003 or Tt = yt \u2212 \u0003, then yt+1 = \u0003. Thus Pr(yt+1 > y1\/10t ) =\nPr(|Tt \u2212 E[Tt]| > y1\/10t ). We continue by showing that this binomial distribution is\nsufficiently \u201cspread out\u201d in the region of its mode that we can find an upper bound\non Pr(yt+1 \u2264 y1\/10t ). This will lead to our lower bound on the expected time for (yt)t\nto decrease below some constant (we use the constant 16):\nPr(Tt = yt) =\n( 1\n2m+ yt\nyt\n)(\n2yt\nm+ 2yt\n)yt ( m\nm+ 2yt\n) 1\n2m\n,\nPr(Tt = yt + j) =\n( 1\n2m+ yt\nyt + j\n)( 2yt\nm+ 2yt\n)yt+j( m\nm+ 2yt\n) 1\n2m\u2212j\n.\nSuppose j > 0. Then\nPr(Tt = yt + j)\nPr(Tt = yt)\n=\n( 2yt\nm+ 2yt\n)j( m\nm+ 2yt\n)\u2212j ( yt!( 12m)!\n(yt + j)!(\n1\n2m+ yt \u2212 (yt + j))!\n)\n=\n(2yt\nm\n)j ( j\u220f\n\u0002=1\n1\n2m+ 1\u2212 \u0003\nyt + \u0003\n)\n=\n(2yt\nm\n)j ( j\u220f\n\u0002=1\nm+ 2\u2212 2\u0003\n2yt + 2\u0003\n)\n>\n(2yt\nm\n)j ( j\u220f\n\u0002=1\nm\u2212 2j\n2yt + 2j\n)\n=\n[(2yt\nm\n)( m\u2212 2j\n2yt + 2j\n)]j\n.\nSimilarly, for j < 0,\nPr(Tt = yt + j)\nPr(Tt = yt)\n=\n(2yt\nm\n)j\u239b\u239d |j|\u220f\n\u0002=1\nyt + 1\u2212 \u0003\n1\n2m+ \u0003\n\u239e\n\u23a0 = ( m\n2yt\n)|j|\u239b\u239d |j|\u220f\n\u0002=1\n2yt + 2\u2212 2\u0003\nm+ 2\u0003\n\u239e\n\u23a0\n>\n( m\n2yt\n)|j|(2yt \u2212 2|j|\nm+ 2|j|\n)|j|\n=\n[( m\n2yt\n)(2yt \u2212 2|j|\nm+ 2|j|\n)]|j|\n=\n[(2yt\nm\n)( m\u2212 2j\n2yt + 2j\n)]j\n.\nThus for all j,\nPr(Tt = yt + j)\nPr(Tt = yt)\n>\n[(2yt\nm\n)( m\u2212 2j\n2yt + 2j\n)]j\n=\n[( yt\nyt + j\n)(m\u2212 2j\nm\n)]j\n.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nDISTRIBUTED SELFISH LOAD BALANCING 1179\nThus for all j with |j| \u2264 y1\/4t , where y1\/4t is the positive fourth root of yt, this is\nat least(\nyt\nyt + y\n1\/4\nt\n)y1\/4t (m\u2212 2y1\/4t\nm\n)y1\/4t\n\u2265\n(\nyt\nyt + y\n1\/4\nt\n)y1\/4t (2yt \u2212 2y1\/4t\n2yt\n)y1\/4t\n=\n(\nyt \u2212 y1\/4t\nyt + y\n1\/4\nt\n)y1\/4t\n=\n(\nyt + y\n1\/4\nt \u2212 2y1\/4t\nyt + y\n1\/4\nt\n)y1\/4t\n=\n(\n1\u2212 2y\n1\/4\nt\nyt + y\n1\/4\nt\n)y1\/4t\n\u2265\n(\n1\u2212 2y\n1\/4\nt\nyt\n)y1\/4t\n=\n(\n1\u2212 2y\u22123\/4t\n)y1\/4t\n\u2265 1\u2212 2y\u22123\/4t y1\/4t = 1\u2212 2y\u22121\/2t \u2265\n1\n2\n,\nwhere the last inequality just requires yt \u2265 16.\nNote that the mode of a binomial distribution is one or both of the integers\nclosest to the expectation, and the distribution is monotonically decreasing as one\nmoves away from the mode. But, for |j| \u2264 y1\/4t , Pr(Tt = yt + j) \u2265 12 Pr(Tt = yt);\nhence Pr(Tt = yt) \u2264 2\/(1 + 2y1\/4t ). Since Pr(Tt = yt + j) \u2264 Pr(Tt = yt), it follows\nthat\nPr(Tt \u2208 [yt \u2212 y1\/10t , yt + y1\/10t ]) \u2264 (2y1\/10t + 1)Pr(Tt = yt) < 3y\u22123\/20t .\nWe say that the transition from yt to yt+1 is a \u201cfast round\u201d if yt+1 \u2264 y1\/10t\n(equivalently, it is a fast round if Tt \u2208 [yt \u2212 y1\/10t , yt + y1\/10t ]). Otherwise it is a slow\nround. Recall that y0 = m\/2. Let\nr =\n\u230a\nlog10\n(\nlog(y0)\nlog(1220\/3)\n)\u230b\n.\nIf the first j rounds are slow, then yj \u2265 y10\u2212j0 . If j \u2264 r, then y10\n\u2212j\n0 \u2265 1220\/3; thus\nthe probability that the transition from yj to yj+1 is the first fast round is at most\n3\n(\ny10\n\u2212j\n0\n)\u22123\/20 \u2264 1\/4.\nAlso, if j < r, then these probabilities increase geometrically so that the ratio of\nthe probability that the transition to yj+1 is the first fast round and the probability\nthat the transition to yj is the first fast round is\n3\n(\ny10\n\u2212(j+1)\n0\n)\u22123\/20\n3\n(\ny10\n\u2212j\n0\n)\u22123\/20 =\n(\ny10\n\u2212j\u221210\u2212(j+1)\n0\n)3\/20\n\u2265\n(\ny10\n\u2212(j+1)\n0\n)3\/20\n\u2265 12 \u2265 2;\nthus\n\u2211r\u22121\nj=0 Pr(transition from yj to yj+1 is the first fast round) \u2264 2 \u00b7 1\/4 = 12 . There-\nfore, with probability at least 1\/2, all of the first r rounds are slow. In this case,\nargmint(yt \u2264 16) = \u03a9(log log(m)), which proves the theorem.\nWe also have the following observation.\nObservation 4.3. Let X(t) be the process in Figure 2.1 with m = n. Let X(0)\nbe the assignment given by X(0) = (2, 0, 1, . . . , 1). Let T be the first time at which\nX(t) is an NE. Then E[T ] = \u03a9(n).\nThe observation follows from the fact that the state does not change until one of\nthe two tasks assigned to the first resource chooses the second resource.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \n1180 BERENBRINK ET AL.\n5. Summary. We have analyzed a very simple, strongly distributed rerouting\nprotocol form tasks on n resources. We have proved an upper bound of (log logm+n4)\non the expected convergence time (convergence to an NE), and for m > n3 an upper\nbound of O(log logm) on the time to reach an approximate NE. Our lower bound of\n\u03a9(log logm+n) matches the upper bound as a function of m. We have also shown an\nexponential lower bound on the convergence time for a related protocol that allows\n\u201cneutral moves.\u201d\nREFERENCES\n[1] H. Ackermann, H. Ro\u00a8glin, and B. Vo\u00a8cking, On the impact of combinatorial structure on\ncongestion games, in Proceedings of the 47th Annual IEEE Symposium on Foundations of\nComputer Science (FOCS), 2006, pp. 613\u2013622.\n[2] A. Blum, E. Even-Dar, and K. Ligett, Routing without regret: On convergence to Nash\nequilibria of regret-minimizing algorithms in routing games, in Proceedings of the 25th\nAnnual ACM Symposium on Principles of Distributed Computing, 2006, pp. 45\u201352.\n[3] S. Chien and A. Sinclair, Convergence to approximate Nash equilibria in congestion games,\nin Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms\n(SODA), New Orleans, LA, 2007, pp. 169\u2013178.\n[4] A. Czumaj, P. Krysta, and B. Vo\u00a8cking, Selfish traffic allocation for server farms, in Pro-\nceedings of the 34th Annual ACM Symposium on Theory of Computing (STOC), Montreal,\n2002, pp. 287\u2013296.\n[5] A. Czumaj, C. Riley, and C. Scheideler, Perfectly balanced allocation, in Proceedings of the\n7th Annual International Workshop on Randomization and Approximation Techniques in\nComputer Science (RANDOM-APPROX), Princeton, NJ, Lecture Notes in Comput. Sci.\n2764, Springer-Verlag, Berlin, 2003, pp. 240\u2013251.\n[6] A. Czumaj and B. Vo\u00a8cking, Tight bounds for worst-case equilibria, in Proceedings of the\nThirteenth Annual ACM-SIAM Symposium on Discrete Algorithms, San Francisco, CA,\n2002, pp. 413\u2013420.\n[7] E. Even-Dar, A. Kesselman, and Y. Mansour, Convergence time to Nash equilibria, in Pro-\nceedings of the 30th International Colloquium on Automata, Languages and Programming\n(ICALP), Eindhoven, The Netherlands, 2003, pp. 502\u2013513.\n[8] E. Even-Dar and Y. Mansour, Fast convergence of selfish rerouting, in Proceedings of the\nSixteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), Vancouver,\nBC, 2005, pp. 772\u2013781.\n[9] A. Fabrikant, C. H. Papadimitriou, and K. Talwar, The complexity of pure Nash equilibria,\nin Proceedings of the 36th Annual ACM Symposium on Theory of Computing (STOC),\n2004, pp. 604\u2013612.\n[10] R. Feldman, M. Gairing, T. Lu\u00a8cking, B. Monien, and M. Rode, Nashification and the\ncoordination ratio for a selfish routing game, in Proceedings of the 30th Annual Interna-\ntional Colloquium on Automata, Languages and Programming (ICALP 30), Lecture Notes\nin Comput. Sci. 2719, Springer-Verlag, Berlin, 2003, pp. 514\u2013526.\n[11] S. Fischer, H. Ra\u00a8cke, and B. Vo\u00a8cking, Fast convergence to Wardrop equilibria by adaptive\nsampling methods, in Proceedings of the 38th Annual ACM Symposium on Theory of\nComputing (STOC), Seattle, WA, 2006, pp. 53\u2013662.\n[12] S. Fischer and B. Vo\u00a8cking, Adaptive routing with stale information, in Proceedings of the\n24th Annual ACM SIGACT\/SIGOPS Symposium on Principles of Distributed Computing\n(PODC), 2005, pp. 276\u2013283.\n[13] D. Fotakis, S. Kontogiannis, E. Koutsoupias, M. Mavronicolas, and P. Spirakis, The\nstructure and complexity of Nash equilibria for a selfish routing game, in Proceedings of\nthe 29th International Colloquium on Automata, Languages, and Programming (ICALP),\nMalaga, Spain, 2002, pp. 123\u2013134.\n[14] P. Goldberg, Bounds for the convergence rate of randomized local search in a multiplayer load-\nbalancing game, in Proceedings of the 23rd Annual ACM SIGACT\/SIGOPS Symposium\non Principles of Distributed Computing (PODC), St. John\u2019s, Newfoundland, 2004, pp.\n131\u2013140.\n[15] T. Hagerup and C. Ru\u00a8b, A guided tour of Chernoff bounds, Inform. Process. Lett., 33 (1989),\npp. 305\u2013308.\n[16] S. Ieong, R. McGrew, E. Nudelman, Y. Shoham, and Q. Sun, Fast and compact: A sim-\nple class of congestion games, in Proceedings of the Twentieth National Conference on\nArtificial Intelligence (AAAI), 2005, pp. 489\u2013494.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCopyright \u00a9 by SIAM. Unauthorized reproduction of this article is prohibited. \nDISTRIBUTED SELFISH LOAD BALANCING 1181\n[17] D. S. Johnson, C. H. Papadimitriou, and M. Yannakakis, How easy is local search?, J.\nComput. System Sci., 37 (1988), pp. 79\u2013100.\n[18] E. Koutsoupias and C. H. Papadimitriou, Worst-case equilibria, in Proceedings of the 16th\nAnnual Symposium on Theoretical Aspects of Computer Science (STACS), Trier, Germany,\n1999, pp. 404\u2013413.\n[19] M. Luby, D. Randall, and A. Sinclair, Markov chain algorithms for planar lattice structures,\nSIAM J. Comput., 31 (2001), pp. 167\u2013192.\n[20] M. Mavronicolas and P. Spirakis, The price of selfish routing, in Proceedings of the 33rd\nAnnual ACM Symposium on Theory of Computing (STOC), Crete, Greece, 2001, pp.\n510\u2013519.\n[21] I. Milchtaich, Congestion games with player-specific payoff functions, Games Econom. Be-\nhav., 13 (1996), pp. 111\u2013124.\n[22] V. S. Mirrokni and A. Vetta, Convergence issues in competitive games, in APPROX-\nRANDOM, Lecture Notes in Comput. Sci. 3122, Springer-Verlag, Berlin, 2004, pp. 183\u2013194.\n[23] M. Mitzenmacher, A. Richa, and R. Sitaraman, The power of two random choices: A\nsurvey of techniques and results, in Handbook of Randomized Computing, P. Pardalos,\nS. Rajasekaran, and J. Rolim, eds., Kluwer Academic Publishers, Dordrecht, The Nether-\nlands, 2000, pp. 255\u2013312.\n[24] D. Monderer and L. S. Shapley, Potential games, Games Econom. Behav., 14 (1996), pp.\n124\u2013143.\n[25] A. Orda, R. Rom, and N. Shimkin, Competitive routing in multi-user communication net-\nworks, IEEE\/ACM Trans. Networking, 1 (1993), pp. 510\u2013521.\n[26] R. W. Rosenthal, A class of games possessing pure-strategy Nash equilibria, Internat. J.\nGame Theory, 2 (1973), pp. 65\u201367.\n[27] T. Roughgarden, Selfish Routing and the Price of Anarchy, MIT Press, Cambridge, MA,\n2005.\n[28] T. Roughgarden and E\u00b4. Tardos, How bad is selfish routing?, J. ACM, 49 (2002), pp. 236\u2013259.\n[29] P. Sanders, S. Egner, and J. Korst, Fast concurrent access to parallel disks, in Proceedings\nof the Eleventh Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), San\nFrancisco, CA, 2000, pp. 849\u2013858.\n"}
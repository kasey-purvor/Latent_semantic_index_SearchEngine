{"doi":"10.1007\/s00224-005-1230-6","coreId":"65473","oai":"oai:dro.dur.ac.uk.OAI2:5740","identifiers":["oai:dro.dur.ac.uk.OAI2:5740","10.1007\/s00224-005-1230-6"],"title":"An infinite hierarchy in a class of polynomial-time program schemes.","authors":["Gault,  R. L.","Stewart,  I. A."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2006-04-01","abstract":"We define a class of program schemes RFDPS constructed around notions of forall-loops, repeat-loops, arrays and if-then-else instructions, and which take finite structures as inputs, and we examine the class of problems, denoted RFDPS also, accepted by such program schemes. The class of program schemes RFDPS is a logic, in Gurevich's sense, in that: every program scheme accepts an isomorphism-closed class of finite structures; we can recursively check whether a given finite structure is accepted by a given program scheme; and we can recursively enumerate the program schemes of RFDPS. We show that the class of problems RFDPS properly contains the class of problems definable in inductive fixed-point logic (for example, the well-known problem Parity is in RFDPS) and that there is a strict, infinite hierarchy of classes of problems within RFDPS (the union of which is RFDPS) parameterized by the depth of nesting of forall-loops in our program schemes. This is the first strict, infinite hierarchy in any polynomial-time logic properly extending inductive fixed-point logic (with the property that the union of the classes in the hierarchy consists of all problems definable in the logic). The fact that there are problems (like Parity) in RFDPS which cannot be defined in many of the more traditional logics of finite model theory (which often have zero-one laws) essentially means that existing tools, techniques and logical hierarchy results are of limited use to us","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65473.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/5740\/1\/5740.pdf","pdfHashValue":"f5dcd8ad2609f3224417393d2e1be0f5866650c7","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:5740<\/identifier><datestamp>\n      2011-11-10T11:07:37Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        An infinite hierarchy in a class of polynomial-time program schemes.<\/dc:title><dc:creator>\n        Gault,  R. L.<\/dc:creator><dc:creator>\n        Stewart,  I. A.<\/dc:creator><dc:description>\n        We define a class of program schemes RFDPS constructed around notions of forall-loops, repeat-loops, arrays and if-then-else instructions, and which take finite structures as inputs, and we examine the class of problems, denoted RFDPS also, accepted by such program schemes. The class of program schemes RFDPS is a logic, in Gurevich's sense, in that: every program scheme accepts an isomorphism-closed class of finite structures; we can recursively check whether a given finite structure is accepted by a given program scheme; and we can recursively enumerate the program schemes of RFDPS. We show that the class of problems RFDPS properly contains the class of problems definable in inductive fixed-point logic (for example, the well-known problem Parity is in RFDPS) and that there is a strict, infinite hierarchy of classes of problems within RFDPS (the union of which is RFDPS) parameterized by the depth of nesting of forall-loops in our program schemes. This is the first strict, infinite hierarchy in any polynomial-time logic properly extending inductive fixed-point logic (with the property that the union of the classes in the hierarchy consists of all problems definable in the logic). The fact that there are problems (like Parity) in RFDPS which cannot be defined in many of the more traditional logics of finite model theory (which often have zero-one laws) essentially means that existing tools, techniques and logical hierarchy results are of limited use to us.<\/dc:description><dc:subject>\n        Finite model theory<\/dc:subject><dc:subject>\n         Descriptive complexity<\/dc:subject><dc:subject>\n         Least-fixed point logic<\/dc:subject><dc:subject>\n         Logics for P<\/dc:subject><dc:subject>\n         Program schemes.<\/dc:subject><dc:publisher>\n        Springer<\/dc:publisher><dc:source>\n        Theory of computing systems, 2006, Vol.39(5), pp.753-783 [Peer Reviewed Journal]<\/dc:source><dc:date>\n        2006-04-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:5740<\/dc:identifier><dc:identifier>\n        issn:1432-4350<\/dc:identifier><dc:identifier>\n        issn: 1433-0490<\/dc:identifier><dc:identifier>\n        doi:10.1007\/s00224-005-1230-6<\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/5740\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1007\/s00224-005-1230-6<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/5740\/1\/5740.pdf<\/dc:identifier><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn: 1433-0490","issn:1432-4350","1432-4350"," 1433-0490"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2006,"topics":["Finite model theory","Descriptive complexity","Least-fixed point logic","Logics for P","Program schemes."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n01 July 2009\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nGault, R. L. and Stewart, I. A. (2006) \u2019An infinite hierarchy in a class of polynomial-time program schemes.\u2019,\nTheory of computing systems., 39 (5). pp. 753-783.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1007\/s00224-005-1230-6\nPublisher\u2019s copyright statement:\nAdditional information:\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n  \nDurham Research Online \n \nDeposited in DRO: \n01 July 2009 \n \nPeer-review status: \nPeer-reviewed \n \nPublication status of attached file: \nAccepted for publication \n \nCitation for published item: \nGault, R. L. and Stewart, I. A. (2006) 'An infinite hierarchy in a class of polynomial-time \nprogram schemes.', Theory of computing systems., 39 (5). pp. 753-783. \n \nFurther information on publisher\u2019s website: \nhttp:\/\/dx.doi.org\/10.1007\/s00224-005-1230-6 \n \nPublisher\u2019s statement: \nThe original publication is available at www.springerlink.com \n \n \n \n \n \n \n \n \n \n \n \n \n \nUse policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior \npermission or charge, for personal research or study, educational, or not-for-profit purposes provided that : \n \n\uf0a7 a full bibliographic reference is made to the original source \n\uf0a7 a link is made to the metadata record in DRO \n\uf0a7 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders. \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nAn infinite hierarchy in a class of\npolynomial-time program schemes\nRichard L. Gault\u2217,\nOxford University Computing Laboratory,\nWolfson Building, Parks Road, Oxford OX1 3QD, U.K.\nIain A. Stewart\u2217,\nDepartment of Computer Science, University of Durham,\nScience Labs, South Road, Durham DH1 3LE, U.K.\nAbstract\nWe define a class of program schemes RFDPS constructed around notions of forall-loops,\nrepeat-loops, arrays and if-then-else instructions, and which take finite structures as inputs,\nand we examine the class of problems, denoted RFDPS also, accepted by such program\nschemes. The class of program schemes RFDPS is a logic, in Gurevich\u2019s sense, in that: every\nprogram scheme accepts an isomorphism-closed class of finite structures; we can recursively\ncheck whether a given finite structure is accepted by a given program scheme; and we can\nrecursively enumerate the program schemes of RFDPS. We show that the class of problems\nRFDPS properly contains the class of problems definable in inflationary fixed-point logic (for\nexample, the well-known problem Parity is in RFDPS) and that there is a strict, infinite\nhierarchy of classes of problems within RFDPS (the union of which is RFDPS) parameterized\nby the depth of nesting of forall-loops in our program schemes. This is the first strict, infinite\nhierarchy in any polynomial-time logic properly extending inflationary fixed-point logic (with\nthe property that the union of the classes in the hierarchy consists of all problems definable\nin the logic). The fact that there are problems (like Parity) in RFDPS which cannot be\ndefined in many of the more traditional logics of finite model theory (which often have zero-\none laws) essentially means that existing tools, techniques and logical hierarchy results are\nof limited use to us.\n1 Introduction\nOne of the central open problems of finite model theory is whether there is a logic\ncapturing P. That is, does there exist a logic whose sentences define exactly the prob-\nlems (the encodings of which are) recognizable by polynomial-time Turing machines?\nOf course, in order to make sense of this question, one needs to say exactly what one\n\u2217Supported by EPSRC Grant GR\/M 12933. Most of the research in this paper was completed\nwhilst the authors were at the University of Leicester.\n1\nmeans by a \u2018logic\u2019. This has been done by Gurevich [10] who formulated a very liberal\ndefinition which encompasses many different \u2018traditional\u2019 logics as well as a variety of\ncomputational models. Over the years, a number of contenders have been suggested\nas logics which might capture P but so far all such logics, whilst only defining prob-\nlems in P, have subsequently been shown not to have the expressive power to define\nevery problem in P. Perhaps the best-known contender was inflationary fixed-point\nlogic with counting (see, for example, [5]). Immerman had suggested that this logic\nmight capture P, but this was later shown not to be the case by Cai, Fu\u00a8rer and\nImmerman [4].\nIn this paper we introduce a new logic (in the sense of Gurevich) which defines\nonly problems in P. Whilst our logic is strictly more expressive than, for example,\ninflationary fixed-point logic and can define problems such as Parity (the problem\nconsisting of all finite structures of even size over the empty signature), there are,\nhowever, problems in P which are not definable in our logic. This comes as no\nsurprise to us as (intuitively) our logic lacks the sophistication we feel any such logic\nmust have were it to capture P. In any case, it is not our real aim here to develop a\nlogic which might capture P (though we feel that our logic might provide a stepping-\noff point in the search for such a logic, as we mention in the Conclusion): our primary\nmotivation for introducing our logic is because such a logic arises naturally within\nour ongoing systematic study of the expressive power of classes of program schemes.\nBroadly speaking, program schemes are models of computation which are amenable to\nlogical analysis yet closer to the general notion of programs than logical formulae are.\nProgram schemes were extensively studied in the seventies, without much regard being\npaid to an analysis of resources, before a closer complexity analysis was undertaken\nin, mainly, the eighties. There are connections between program schemes and logics\nof programs, especially dynamic logic. (The reader is referred to [2] for references\nrelating to the research mentioned in the preceding two sentences.)\nWe define our program schemes around \u2018high-level\u2019 programming constructs such\nas arrays, while-loops, assignments, non-determinism, and so on, but so that the input\ncomes in the form of a finite structure and, in general, there is no access to a linear\nordering of the elements of the input structure. The program schemes defined in [16,\n18] all involve arrays, while-loops and non-determinism. Allowing unrestricted access\nto arrays enables one to accept PSPACE-complete problems, whilst by restricting\naccess to arrays (to be, in a sense, \u2018write-once\u2019), one can limit oneself to accept\nonly problems in NP (although there is still sufficient power to accept NP-complete\nproblems). Furthermore, classes of program schemes were defined in [2, 17] whereby\nevery problem accepted by such a program scheme is in P and, additionally, there\nare such program schemes accepting P-complete problems. These program schemes\ninvolve while-loops, a stack and non-determinism. So as to emphasise that these\nmodels of computation are not given an ordering on the elements of an input structure,\namongst the results in the aforementioned papers are that the class of problems\naccepted by any of the above classes of program schemes has a zero-one law (but,\ninterestingly, not necessarily because the problems can be defined in bounded-variable\ninfinitary logic as is often the case in finite model theory). On ordered structures, our\nclasses of program schemes capture the complexity classes P, NP and PSPACE as\nappropriate (see also [15]).\nIn this paper, we introduce a class of program schemes RFDPS based on ar-\n2\nrays, if-then-else instructions and forall-loops, where our forall-loops result in parallel\nexecutions of a portion of code, with one execution for each element of the input\nstructure. So as to provide a means for iteration, we allow portions of code to be\nrepeatedly executed n times, where n is the size of the input structure. The class of\nprogram schemes RFDPS arose through our efforts to replace the notion of a while-\nloop in earlier classes of program schemes with one of a forall-loop. Note that unlike\nthe program schemes mentioned in the previous paragraph, our program schemes are\ndeterministic (and every problem accepted by such a program scheme is in P).\nAnother \u2018polynomial-time\u2019 model of computation has recently been examined by\nBlass, Gurevich and Shelah1. In [3], Blass, Gurevich and Shelah introduced a model\nof computation C\u02dcPTime, Choiceless Polynomial-Time, a program (\u03c1, p(n), q(n)) of\nwhich is an adapted Abstract State Machine \u03c1 (see [11, 12]) augmented with two\npolynomial bounds, p(n) and q(n), with p(n) bounding the length of any run of\nthe machine on any input and q(n) bounding the number of \u2018parallel executions\u2019\nin one of their forall-loops, where these polynomial bounds are in terms of the size\nn of the finite input structure upon which the program works. Although such a\nprogram takes a finite structure (over some relational signature) as input, it treats\nthe elements of this finite structure as atoms and has the potential to build certain sets\nover these atoms and use these sets as new \u2018elements\u2019 in its \u2018computational domain\u2019.\nConsequently, without restricting the run-time and the number of parallel executions,\nthe program would have the capacity to build a computational domain of arbitrary\nsize; indeed, it is not difficult to show that such an unrestricted program can simulate\nan arbitrary Turing machine. The instructions, or rules in the terminology of [3],\nof the programs of C\u02dcPTime have similarities with those of the program schemes of\nthis paper. For example: there are dynamic function symbols and assignments via\nupdate rules, whereas our program schemes have arrays and assignment-blocks; there\nare conditional rules, whereas our program schemes have if-then-fi-blocks; and there\nare do-forall rules, whereas our program schemes have forall-do-od-blocks. However,\nthere are a number of important differences between the computational model of Blass,\nGurevich and Shelah and ours, including the following. Their computational domain\nfluctuates, whereas ours is fixed and is always the domain of the input structure.\nViewed as a logic, C\u02dcPTime is three-valued (a program may accept, reject or neither\naccept nor reject), whereas our program schemes always either accept or reject. A\nprogram of C\u02dcPTime has no access to the cardinality of the input structure, and\nthe problem Parity cannot be accepted by a program of C\u02dcPTime (furthermore, it\nhas been reported in [3] that Shelah has shown that C\u02dcPTime has a zero-one law),\nwhereas our program schemes have access to the size of the input structure and there\nis such a program scheme accepting Parity . In order to force the abstract state\nmachine to accept polynomial-time solvable problems, the polynomial bounds p(n)\nand q(n) must be imposed from without, whereas no such bounds need be imposed\nupon our program schemes: our program schemes naturally accept only polynomial-\ntime solvable problems.\nThe motivation for the research in [3] was the search for an answer to the ques-\ntion, stated earlier, of whether there is a logic capturing P. In turn, this question\n1Actually, although their work was published before this paper was written, the actual research\nwas undertaken simultaneously and independently. The writing of our paper was delayed due to the\nwriting of the Ph.D. thesis of Gault within which the research presented here is included.\n3\nhas motivated a search for logics capturing an increasing sub-class of the class of\npolynomial-time solvable problems. The main results of [3] are that the class of prob-\nlems accepted by the progams of C\u02dcPTime properly contains the class of problems\naccepted by Abiteboul and Vianu\u2019s class of polynomial-time relational machines [1]\nbut that there are polynomial-time solvable problems, in particular Parity and the\nproblem Bipartite Matching (consisting of those bipartite undirected graphs whose\ntwo sets in the partition have equal size for which there exists a perfect matching),\nthat are not accepted by any program of C\u02dcPTime. In fact, it is also shown in [3]\nthat Bipartite Matching is not accepted by any program of C\u02dcPTime+, an extension\nof C\u02dcPTime which allows access to a constant fixed at the size of the input structure\n(however, Parity is accepted by a program of C\u02dcPTime+). It is also claimed in [3] that\nthe class of problems accepted by the programs of C\u02dcPTime includes any problem de-\nfinable in any other \u2018polynomial-time logic\u2019 in the literature (the authors presumably\nmean only \u2018natural polynomial-time logics\u2019 and not augmentations of such by, for\nexample, counting quantifiers or Lindstro\u00a8m quantifiers).\nOur results are of a somewhat different flavour to those of [3] and, in a sense, are\nmore refined. We obtain a strong result which provides limitations on the problems\naccepted by our program schemes, and we use this result to obtain a strict, infinite\nhierarchy of classes of problems within the class of problems accepted by the program\nschemes of RFDPS. These classes are parameterized by the depth of nesting of forall-\nloops allowed in the defining program schemes, and the union of these classes is the\nclass of problems accepted by the program schemes of RFDPS. Consequently, each\nclass of problems in the hierarchy is definable by a logic in Gurevich\u2019s sense. To our\nknowledge, this is the first strict, infinite hierarchy in a polynomial-time logic properly\nextending inflationary fixed-point logic (with the property that the union of the classes\nof the hierarchy consists of the class of problems definable in the polynomial-time\nlogic). Our results are obtained by a direct analysis of computations of our program\nschemes. Note that the existing hierarchy theorems of finite model theory, such as\nthose in [7, 8, 9], are of no use to us here given that all of these hierarchy results are\nfor explicit fragments of bounded-variable infinitary logic (which has a zero-one law),\nwhereas our computational model is, first, not defined in terms of traditional logics\nand, second, is complicated by its ability to accept problems not having a zero-one\nlaw.\nLike the Choiceless Polynomial-Time model of Blass, Gurevich and Shelah, our\nprogram schemes are different from other (polynomial-time) models of computation\nmore prevalent in database theory, such as the relational machines of Abiteboul and\nVianu [1], the extension of inflationary fixed-point logic with a symmetry-based choice\noperator proposed by Gire and Hoang [6] and the extension of first-order logic with for-\nloops proposed by Neven, Otto, Tyszkiewicz and Van den Bussche [14]. The models\nof computation proposed by these researchers (and others) allow the construction of\nwhole relations as an atomic operation, whereas our construction of relations (stored\nin arrays) is, in a sense, \u2018one element at a time\u2019. Some of these models are more\nexpressive than our class of program schemes but, unlike our class of program schemes,\nno hierarchy results have been established. Hence, we do not discuss these models\nfurther here (although the reader is referred to our comments in the Conclusion).\nThis paper is organized as follows. In Section 2, we detail the basic definitions\nfrom finite model theory required throughout, and in Section 3 we define our class of\n4\nprogram schemes RFDPS and prove some lower bound results for RFDPS. In Section\n4, we give a more formal semantics for our class of program schemes before proving\nsome limitations of the program schemes of RFDPS in Section 5. We present our\nconclusions in Section 6.\n2 Basic notions\nThroughout, a signature \u03c3 is a tuple \u3008R1, . . . , Rr, C1, . . . , Cc\u3009, where each Ri is a\nrelation symbol, of arity ai, and each Cj is a constant symbol: in the case that \u03c3\nconsists only of relation symbols, we say that \u03c3 is relational . First-order logic over\nsome signature \u03c3, FO(\u03c3), consists of those formulae built from atomic formulae over\n\u03c3 using \u2227, \u2228, \u00ac, \u2200 and \u2203; and FO = \u222a{FO(\u03c3) : \u03c3 is some signature}.\nA finite structure A over the signature \u03c3, or \u03c3-structure, consists of a finite uni-\nverse or domain |A|, together with a relation RAi of arity ai for every relation symbol\nRi of \u03c3, and a constant CAj \u2208 |A| for every constant symbol Cj (by an abuse of\nnotation, we often do not distinguish between constants or relations and constant or\nrelation symbols). A finite structure A whose domain has size n is said to have size n,\nand we denote the size of A by |A| also (this does not cause confusion). The class of\nall finite structures over the signature \u03c3 is denoted STRUCT(\u03c3). A problem over some\nsignature \u03c3 consists of a subset of STRUCT(\u03c3) which is closed under isomorphism.\nClearly, we can consider the classes of problems definable by the sentences of FO. We\ndenote this class of problems by FO also and do likewise with other logics and classes\nof problems.\nLet \u03d5(x,y) \u2208 FO(\u03c3 \u222a \u3008R\u3009), for some signature \u03c3 and some relation symbol R, of\narity k, say, not in \u03c3, be such that the free variables of \u03d5 are those of the k-tuple x\nand the m-tuple y, where m \u2265 0 (with all variables distinct). Then\nIFP[\u03bbx, R, \u03d5(x,y, R)]\ndenotes the inflationary fixed-point relation of \u03d5(x,y, R) with respect to R and x.\nThat is, for any \u03c3-structure A and for any v \u2208 |A|m,\nIFP[\u03bbx, R, \u03d5A(x,v, R)] =\n\u221e\u22c3\ni=0\nRAi ,\nwhere RA0 is the empty relation and where for each i \u2265 0,\nRAi+1 = {u \u2208 |A|k : A |= RAi (u) \u2228 \u03d5(u,v, RAi )}.\nInflationary fixed-point logic, denoted (\u00b1IFP)\u2217[FO], is the closure of first-order logic\nwith the operator IFP.\nWe denote by L\u221e\u03c9 the infinitary logic built as is first-order logic except that we\nallow conjunctions and disjunctions of arbitrary (and not just finite) sets of formulae.\nObviously, any problem can be defined in L\u221e\u03c9. So, let us turn to the bounded-\nvariable fragment. Let Ld\u221e\u03c9 be the fragment of L\u221e\u03c9 where the only variables we\nallow, free or bound, are x1, x2, . . . , xd; and define bounded-variable infinitary logic,\nL\u03c9\u221e\u03c9, as \u222a\u221ed=1Ld\u221e\u03c9. Let A and B be \u03c3-structures, for some \u03c3; let e be such that\n5\n0 \u2264 e \u2264 d; and let u \u2208 |A|e and v \u2208 |B|e. If for all \u03d5 \u2208 Ld\u221e\u03c9 with free variables\nx1, x2, . . . , xe,\nA |= \u03d5(u1, u2, . . . , ue) \u21d4 B |= \u03d5(v1, v2, . . . , ve)\nthen we write\n(A, u1, u2, . . . , ue) \u2261Ld\u221e\u03c9 (B, v1, v2, . . . , ve).\nThere is a well-known game-theoretic characterization of definability in Ld\u221e\u03c9. Two\nplayers, Spoiler (who is male) and Duplicator (who is female), play the following\ngame on two structures A and B, over the same signature, where the game involves\nd pairs of pebbles {(p1, q1), (p2, q2), . . . , (pd, qd)}. Each move of the game consists of\nSpoiler placing some pebble pi or qi on some element of |A| or |B|, respectively, with\nDuplicator replying by placing the other pebble of the pair on some element of the\nother domain as appropriate (note that a pebble can be removed from one element of\na structure and placed on another element of that structure in a move of the game).\nConsider some play of the game which is a (possibly infinite) set of moves. If after some\nmove the map |A| \u2192 |B| given by {pi \u000f\u2192 qi : pebble pi is in play} does not induce a\npartial isomorphism from A to B then Spoiler wins the play of the game. If there is\nno such move then Duplicator wins (when the play is necessarily of infinite length).\nDuplicator has a winning strategy on A and B if she has a strategy by which she can\nwin every play of the game, i.e., a strategy by which she can continually maintain a\npartial isomorphism between the pebbled elements no matter what Spoiler does. Let\nu \u2208 |A|e and v \u2208 |B|e, where 0 \u2264 e \u2264 d. If Duplicator has a winning strategy in the\nabove d-pebble game when the pebbles p1, p2, . . . , pe start on u1, u2, . . . , ue and the\npebbles q1, q2, . . . , qe start on v1, v2, . . . , ve then we say that Duplicator wins the d-\npebble game on (A,u) and (B,v). The game-theoretic characterization of definability\nin Ld\u221e\u03c9, due to Barwise, Immerman and Poizat (see [5]), can be stated as follows.\nTheorem 1 Let A and B be two structures over the same signature and let u \u2208 |A|e\nand v \u2208 |B|e, where 0 \u2264 e \u2264 d. The following are equivalent.\n(i) (A, u1, u2, . . . , ue) \u2261Ld\u221e\u03c9 (B, v1, v2, . . . , ve).\n(ii) Duplicator wins the d-pebble game on (A,u) and (B,v).\nWe do not actually use the above characterization result in its full generality, only\nthe notion of Duplicator winning the d-pebble game on (A,u) and (B,v). However,\nit is useful for the reader to know the logical significance of the Duplicator winning\nthis game. We refer the reader to [5] for more details on the above definitions and\nresults, and for more results involving the above logics and notions.\n3 A class of program schemes\nWe now define a class of program schemes based around a notion of a forall-loop,\nrather than a while-loop (as was the case in [2, 16, 17, 18]), and where we disallow\nnon-determinism. We compensate for this lack of non-determinism by interpreting\nour for-loops as the parallel execution(s) of a portion of code with one execution for\neach element of the input structure.\n6\nDefinition 2 (The syntax of our program schemes.) A program scheme \u03c1 of RFDPS:\nis over a signature \u03c3; involves a finite set of variables {x1, x2, . . . , xk}, for some k \u2265 1;\nand involves a finite set of array symbols {A1, A2, . . . , Ag}, for some g \u2265 0, where the\narray symbol Ai has an associated arity ai \u2265 1.\nThe set of terms consists of: the variables {x1, x2, . . . , xk}; the constant symbols of\n\u03c3 and the constant symbols 0 and max, which never appear in any signature; and the\narray terms {Ai[\u03c41, \u03c42, . . . , \u03c4ai ] : each \u03c4j is a variable or a constant symbol, and 1 \u2264\ni \u2264 g} (note that we do not allow array terms to be nested).\nA program scheme \u03c1 consists of a finite sequence of blocks of instructions, the\nconstituent blocks, sandwiched between the input-instruction, INPUT(x1, x2, . . . , xk),\nand the output-instruction, OUTPUT(x1, x2, . . . , xk), where each block is as follows.\n\u2022 An assignment-block \u03b1 is simply an instruction of the form\n\u03c4 := \u03c4 \u2032 assignment-instruction\nwhere \u03c4 is a variable or an array term and \u03c4 \u2032 is a variable, a constant symbol or\nan array term. The scope of \u03b1 is the actual assignment-instruction constituting\nthe block.\n\u2022 An if-then-fi-block \u03b1 is a sequence of instructions of the form\nIF \u03d5 THEN if-instruction\n\u03b11 block of instructions\n\u03b12 block of instructions\n. . .\n\u03b1l block of instructions\nFI fi-instruction\nfor some l \u2265 1, where \u03d5 is a quantifier-free first-order formula over \u03c3\u222a{0,max}\nwhose free variables come from {x1, x2, . . . , xk} (note that we do not allow array\nterms in \u03d5). The scope of \u03b1 is the union of the if-instruction, the fi-instruction\nand the scopes of the blocks \u03b11, \u03b12, . . . , \u03b1l.\n\u2022 A repeat-do-od-block \u03b1 is a sequence of instructions of the form\nREPEAT DO repeat-do-instruction\n\u03b11 block of instructions\n\u03b12 block of instructions\n. . .\n\u03b1l block of instructions\nOD repeat-od-instruction\nfor some l \u2265 1. The scope of \u03b1 is the union of the repeat-do-instruction, the\nrepeat-od-instruction and the scopes of the blocks \u03b11, \u03b12, . . . , \u03b1l.\n\u2022 A forall-do-od-block \u03b1 is a sequence of instructions of the form\n7\nFORALL xp WITH A\nj\ni DO forall-do-instruction\n\u03b11 block of instructions\n\u03b12 block of instructions\n. . .\n\u03b1l block of instructions\nOD forall-od-instruction\nfor some l \u2265 1, where 1 \u2264 p \u2264 k, 1 \u2264 i \u2264 g and 1 \u2264 j \u2264 ai. The variable xp is\nthe control variable and the array symbol Ai is the control array symbol of the\nforall-do-od-block. We say that the control variable xp is active in Ai in \u03b1 at\nindex j (we shall define forall-do-od-blocks where the control variable is inactive\nin a moment). The scope of \u03b1 is the union of the forall-do-instruction, the forall-\nod-instruction and the scopes of the blocks \u03b11, \u03b12, . . . , \u03b1l. Furthermore, there\nare some additional constraints on \u03b1.\n\u2013 There must exist at least one assignment-instruction in the scope of \u03b1\nwhere the term on the left-hand side of the assignment is an array term\ninvolving Ai.\n\u2013 Any array term Ai[\u03c41, \u03c42, . . . , \u03c4ai ] appearing in any assignment-instruction\n(on the left or on the right) in the scope of \u03b1 must be such that the term\n\u03c4j is xp (the control variable).\n\u2013 No array symbol apart from the array control symbol may appear in a\nterm on the left-hand side of any assignment-instruction in the scope of \u03b1.\n\u2013 The control variable xp must not appear (as a solitary variable) on the\nleft-hand side of any assignment-instruction in the scope of \u03b1.\n\u2013 Any other forall-do-od-block (with either an active or an inactive control\nvariable) whose instructions are in the scope of \u03b1 must not have xp as its\ncontrol variable.\n\u2022 We also allow forall-do-od-blocks \u03b1 of the form\nFORALL xp DO forall-do-instruction\n\u03b11 block of instructions\n\u03b12 block of instructions\n. . .\n\u03b1l block of instructions\nOD forall-od-instruction\nfor some l \u2265 1, where 1 \u2264 p \u2264 k. The control variable xp is said to be inactive\nin \u03b1. The scope of \u03b1 is the union of the forall-do-instruction, the forall-od-\ninstruction and the scopes of the blocks \u03b11, \u03b12, . . . , \u03b1l. The constraints on \u03b1 are\nas follows.\n\u2013 No array term appears on the left-hand side of any assignment-instruction\nin the scope of \u03b1.\n\u2013 The control variable xp must not appear (as a solitary variable) on the\nleft-hand side of any assignment-instruction in the scope of \u03b1.\n8\n\u2013 Any other forall-do-od-block (with either an active or an inactive control\nvariable) whose instructions are in the scope of \u03b1 must not have xp as its\ncontrol variable.\nThe scope of the program scheme \u03c1 consists of the union of the input-instruction, the\noutput-instruction and the scopes of the blocks forming \u03c1. A block appears in \u03c1 if it\nis used somewhere in the iterative process of building \u03c1; and we say that a block \u03b1\nappears in the scope of another block \u03b1\u2032 if the instructions in the scope of \u03b1 are in\nthe scope of \u03b1\u2032. The depth of nesting of an instruction in the scope of \u03c1 or of a block\nappearing in \u03c1 is the number of forall-do-od-blocks in whose scope the instruction\nor the block appears; and the depth of nesting of \u03c1 is the maximum of the depth of\nnesting of all instructions of \u03c1.\nWe can clearly write any program scheme as a sequence of instructions, start-\ning from the input-instruction and ending in the output-instruction, so that these\ninstructions are numbered consecutively.\nOur name for our class of program schemes, RFDPS, is an acronym for \u2018Repeat\nForall Deterministic Program Schemes\u2019.\nNow is an apposite time to make some observations as regards control variables\nand control array symbols. Suppose that a forall-do-od-block \u03b1 appears in the scope\nof a forall-do-od-block \u03b2 where the control variable of \u03b1 is xi and the control variable\nof \u03b2 is xj (note that necessarily i \u0010= j).\n\u2022 If xi is active in \u03b1 then xj is active in \u03b2 and the control array symbols of \u03b1 and\n\u03b2 are identical.\n\u2022 If xj is inactive in \u03b2 then xi is inactive in \u03b1.\nTwo forall-do-od-blocks can have the same control variable but if they do then neither\nwill appear in the scope of the other. As to why we impose the restrictions that we\ndo in Definition 2 will become clearer when we define the semantics of our program\nschemes (essentially, our restrictions mean that we can treat control array variables\nas \u2018partitioned shared memory\u2019).\nLet us now explain how our program schemes compute (a more rigorous semantics\nwill be forthcoming in the next section).\nDefinition 3 (How our program schemes compute.) Any program scheme \u03c1, as in\nDefinition 2, takes a \u03c3-structure A, of size n, say, as input. The variables and array\nelements all take values from |A| with array elements indexed by tuples of elements\nof the input structure (where the length of the tuple is the arity of the array symbol).\nThe program scheme \u03c1 computes on input A in the obvious way except with the\nfollowing provisos.\n\u2022 Prior to the computation, the constant symbols 0 and max are given arbitrary\ndistinct values from |A|. Initially, all variables and array elements are made\nequal to 0.\n\u2022 A repeat-do-od-block \u03b1 of the form\n9\nREPEAT DO repeat-do-instruction\n\u03b11 block of instructions\n\u03b12 block of instructions\n. . .\n\u03b1l block of instructions\nOD repeat-od-instruction\niteratively executes the blocks of instructions \u03b11;\u03b12; . . . ;\u03b1l in this order exactly\nn times. The effect is precisely that of writing\n\u03b11;\u03b12; . . . ;\u03b1l;\u03b11;\u03b12; . . . ;\u03b1l; . . . ;\u03b11;\u03b12; . . . ;\u03b1l (n repetitions)\nwhich, of course, is impossible within our syntax as the value of n depends upon\nthe input structure.\n\u2022 A forall-do-od-block \u03b1 of the form\nFORALL xp WITH A\nj\ni DO forall-do-instruction\n\u03b11 block of instructions\n\u03b12 block of instructions\n. . .\n\u03b1l block of instructions\nOD forall-od-instruction\ncauses a \u2018multi-way split\u2019 in the computation so that n \u2018child processes\u2019 are set\noff in parallel, each executing the blocks of instructions \u03b11;\u03b12; . . . ;\u03b1l and each\nwith its own \u2018local copy\u2019 of the variables of \u03c1 (thus, the processes cannot use\nthese variables to somehow communicate with each other). The only difference\nbetween the processes is that the variable xp takes a different value in each; that\nis, for each u \u2208 |A|, there is exactly one process in which the variable xp has\nthe value u. Whilst the value of xp does not change throughout any process (as\na consequence of our syntactic constraints), the values of other variables might\nchange within a process (so that the same variable has a different value in two\ndifferent processes).\nHowever, the arrays are not local to the individual processes: each process\nmakes use of exactly the same arrays. Our syntactic conditions on forall-do-od-\nblocks ensure that two different processes never have access to the same array\nelement of the array Ai (which is the only array whose values may change in any\nprocess). Exclusive access is ensured because the only array terms involving Ai\nallowed in assignment-instructions in the scope of \u03b1 are those where the control\nvariable xp is the jth array index. Hence, in the child process corresponding\nto the control variable xp having the value u \u2208 |A|, the only elements of Ai to\nwhich this process has (either read or write) access are elements of the form\nAi[u1, . . . , uj\u22121, u, uj+1, . . . , uai ], where u1, . . . , uj\u22121, uj+1, . . . , uai \u2208 |A|. Note\nthat two processes might have read-access to the same array elements of other\narrays but no process has write-access to these arrays. The arrays can be con-\nsidered as a form of \u2018partitioned shared-memory\u2019 where access is controlled so\nthat non-deterministic behaviour, such as races, does not occur (a race occurs\n10\nwhen two computational processes have access to the same variable and differ-\nent relative execution speeds of the processes can result in different values for\nthe variable).\nWhen all child processes have reached the forall-od-instruction, they terminate\nand the results of these child processes are registered as follows. Call those vari-\nables appearing on the left-hand side of an assignment-instruction in the scope\nof \u03b1 the local variables (note that there may be no local variables). The main\ncomputation resumes at the instruction of \u03c1 following the forall-od-instruction.\nAt this point, the value of xp is set to max if, in every child process, the values\nof the local variables of \u03b1 are all set at max on termination of the process;\notherwise the value of xp is set at 0. If \u03b1 has no local variables then xp is always\nset to max. The values of all variables apart from xp now take their original\nvalues held immediately prior to the execution of the forall-do-od-block. The\nvalues of the arrays stay as they are when all child processes have finished (as\nwe have described above, these array values are consistent). So, execution of a\nforall-do-od-block: leaves all the values of variables, except possibly the control\nvariable, unchanged; has an effect which is signalled by the resulting value of\nthe control variable; and might change the values of some of the control ar-\nray elements but no other array elements. A forall-do-od-block in which the\ncontrol variable is inactive computes in exactly the same way as we have just\ndescribed (obviously, the situation is more straight-forward as no value of any\narray element is changed due to the execution of such a forall-do-od-block).\nThe structure A is accepted by \u03c1 if, and only if, there exist distinct values for 0 and\nmax for which the computation of \u03c1 on input A reaches the output-instruction with\nall variables set at max.\nEssentially, what we are doing is \u2018building in\u2019 two distinct constants 0 and max\nto our program schemes so that we might use these constants for initialization and\nacceptance purposes. However, our definition of how we build the constants 0 and\nmax into our program schemes is slightly different to how we usually build constants\nand relations into logics in finite model theory. For example, any problem in P can be\ndefined in inflationary fixed-point logic in the presence of a built-in successor relation\n(a result due to Immerman and Vardi: see [5]). That is, for any problem \u03a9 in P,\nover some signature \u03c3, there is a sentence \u03d5 of inflationary fixed-point logic over\nthe signature \u03c3 \u222a {succ, 0,max}, where succ is a binary relation and 0 and max are\nconstant symbols not in \u03c3, such that for every \u03c3-structure A:\n(a) if A \u2208 \u03a9 then (A, succA, 0A,maxA) |= \u03d5, for all successor relations succA over\nA with minimum 0A and maximum maxA; and\n(b) if A \u0010\u2208 \u03a9 then (A, succA, 0A,maxA) \u0010|= \u03d5, for all successor relations succA over\nA with minimum 0A and maximum maxA,\nwhere a successor relation over A is a binary relation of the form {(u0, u1), (u1, u2),\n. . . , (un\u22122, un\u22121)}, where |A| = {u0, u1, . . . , un\u22121}, and the minimum element is u0 =\n0A and the maximum element is un\u22121 = maxA.\nOne might be tempted to regard inflationary fixed-point logic with a built-in\nsuccessor relation as a logic. However, the problem of deciding whether a sentence \u03d5\n11\nof inflationary fixed-point logic (and even first-order logic) with a built-in successor\nrelation is well-formed, in that it obeys (a) and (b), above, is undecidable (this follows\nfrom Trakhtenbrot\u2019s Theorem: see [5]), and it is reasonable to insist that any logic\nshould have a recursive syntax.\nThis motivated Gurevich to define what it means to be a logic (in the context of\ncapturing complexity classes). A logic L is given by a pair of functions (Sen, Sat)\nsatisfying the following conditions. The function Sen associates with every signature\n\u03c3 a recursive set Sen(\u03c3) whose elements are called L-sentences over \u03c3. The function\nSat associates with every signature a recursive relation Sat\u03c3(A, \u03d5), where A is a \u03c3-\nstructure and \u03d5 is a sentence of L. We say that A satisfies \u03d5 (and write A |= \u03d5) if\nSat\u03c3(A, \u03d5) holds. Furthermore, we require that Sat\u03c3(A, \u03d5) if, and only if, Sat\u03c3(B, \u03d5)\nwhen A and B are isomorphic.\nIf we were to build our constant symbols 0 and max into the program schemes of\nRFDPS as is usually done in finite model theory then we would only be interested\nin program schemes for which acceptance of an input structure is independent of the\nparticular pair of (distinct) values chosen for 0 and max. That is, not every program\nscheme of RFDPS would accept an isomorphism-closed class of structures, and so not\nevery program scheme of RFDPS would be well-formed. However, with our notion of\nacceptance, every program scheme of RFDPS is automatically well-formed (in fact,\nthe classes of problems accepted by the program schemes of RFDPS under the two\ndifferent notions of acceptance are identical but we do not prove this result here)\nand this obviates the need to check that RFDPS is a logic. Also, with our notion of\nacceptance, some fragments of RFDPS, to be defined later, are also logics (this fact\nis not so clear if we adopt the alternative semantics). Note that whichever semantics\none adopts, we obtain a class of problems solvable in polynomial-time. However, if we\nwere to build a successor relation into a polynomial-time logic and adopt our semantics\nthen (assuming that the polynomial-time logic is rich enough) we could accept NP-\ncomplete problems (such as the problem of deciding whether a given digraph has a\nHamiltonian cycle).\nRemark 4 We make the following two comments.\n(i) We can clearly simulate if-then-else-fi-blocks (with the obvious semantics) within\nthe program schemes of RFDPS.\n(ii) We refer to \u2018the\u2019 computation of a program scheme on some input structure\nas we assume that 0 and max have been fixed as two arbitrary but distinct\nelements.\nWe phrase the following trivial observations in the form of a lemma.\nLemma 5 The computation of a program scheme \u03c1 \u2208 RFDPS on some input struc-\nture terminates; and every problem in RFDPS can be solved in polynomial-time.\nIn the next section, we provide a more formal semantics for our program schemes.\nHowever, our definitions above are sufficiently detailed for us to now give examples\nof some program schemes and the problems they accept, and also to obtain some\nlower bounds on the computational power of the program schemes of RFDPS. To aid\nreadability: we allow our variables and array symbols to have different names from\n12\nxi and Ai; we assume that we are allowed to use if-then-else-blocks; and we indent in\ntypical programming style.\nExample 6 Let \u03c32 = \u3008E\u3009, where E is a binary relation symbol. Consider the fol-\nlowing program scheme \u03c1 of RFDPS where A and B are array symbols of arity 2.\n1 INPUT(x, y, z, u, v)\n2 FORALL x WITH A1 DO make A the input digraph adjacency\n3 FORALL y WITH A2 DO matrix with 1\u2019s on the leading diagonal\n4 IF E(x, y) \u2228 x = y THEN\n5 A[x, y] := max\n6 FI\n7 OD\n8 OD compute the transitive closure of the\n9 REPEAT DO input digraph by iteratively multiplying\n10 FORALL x WITH B1 DO the adjacency matrix by itself\n11 FORALL y WITH B2 DO\n12 B[x, y] := A[x, y] copy the array A into B\n13 OD\n14 OD\n15 FORALL x WITH A1 DO\n16 FORALL y WITH A2 DO\n17 FORALL z DO\n18 u := B[x, z]\n19 v := B[z, y]\n20 IF u = max \u2227 v = max THEN\n21 u := 0\n22 v := 0\n23 ELSE\n24 u := max\n25 v := max\n26 FI\n27 OD\n28 IF z = 0 THEN\n29 A[x, y] := max\n30 FI\n31 OD\n32 OD\n33 OD\n34 FORALL x WITH A1 DO check that every pair appears in the\n35 FORALL y WITH A2 DO transitive closure of the input digraph\n36 z := A[x, y]\n37 OD\n38 z := y\n39 OD\n40 IF x = max THEN signal acceptance or rejection\n41 y := max\n42 z := max\n13\n43 u := max\n44 v := max\n45 FI\n46 OUTPUT(x, y, z, u, v)\nIt is worthwhile noting how we simulate existential quantification in the above pro-\ngram scheme. Essentially, we have a forall-do-od-block with inactive control variable\nz (in line 17). Consequently, we have a child process for every possible value of z. An\naffirmative answer to our check as to whether there are edges (x, z) and (z, y) results\nin the local variables u and v being set to 0, otherwise they are set to max. Hence, at\nthe corresponding forall-od-instruction (at line 27), the value of z is set to 0 if, and\nonly if, two edges (x, z) and (z, y) exist, for some z. This is noted in lines 28-30.\nThis program scheme is such that acceptance and rejection is actually independent\nof the particular distinct values chosen for 0 and max (a stronger condition than we\nrequire); and a \u03c32-structure is accepted by \u03c1 if, and only if, when considered as a\ndigraph, it is strongly connected.\nExample 7 Let \u03c3 be any signature. Consider the following program scheme \u03c1 of\nRFDPS.\n1 INPUT(x)\n2 REPEAT DO\n3 IF x = 0 THEN\n4 x := max\n5 ELSE\n6 x := 0\n7 FI\n8 OD\n9 OUTPUT(x)\nThis program scheme is such that acceptance and rejection is actually independent\nof the particular distinct values chosen for 0 and max; and a \u03c3-structure is accepted\nby \u03c1 if, and only if, it has odd size.\nWe now exhibit some lower bounds on the class of problems accepted by the\nprogram schemes of RFDPS.\nTheorem 8 There is a program scheme of RFDPS accepting any first-order definable\nproblem.\nProof We shall prove the result by induction on the quantifier-rank d of any first-\norder formula where our induction hypothesis is: \u2018Let \u03c3 be some signature and \u03c3\u2032 be\nthe expansion of \u03c3 with m additional constant symbols. For any first-order formula\n\u03c8 of quantifier-rank r less than d \u2265 1 over \u03c3 and with free variables x1, x2, . . . , xm,\nsay, there exists a program scheme \u03c1\u2032 \u2208 RFDPS over \u03c3\u2032 such that if \u03c8 is considered\nas a sentence over \u03c3\u2032 then for every \u03c3\u2032-structure A\u2032:\n\u2022 if A\u2032 |= \u03c8 then A\u2032 |= \u03c1\u2032; and\n14\n\u2022 if A\u2032 \u0010|= \u03c8 then the computation of \u03c1\u2032 on input A\u2032 (no matter what the distinct\nvalues given to 0 and max are) is such that the output-instruction is reached\nwith all variables involved in \u03c1\u2032 having the value 0.\nMoreover, \u03c1\u2032 does not involve any array symbols and has depth of nesting r.\u2019\nFirst, the base case of the induction. Let \u03c8 be quantifier-free. The following\nprogram scheme suffices.\nINPUT(y)\nIF \u03c8 THEN\ny := max\nELSE\ny := 0\nFI\nOUTPUT(x)\nNow, suppose that the inductive hypothesis holds for all formulae of quantifier-\nrank less than d. Let \u03d5 be a first-order formula of quantifier-rank d \u2265 1 of the\nform \u2203xm\u03c8(x1, x2, . . . , xm), where x1, x2, . . . , xm are the free variables of \u03c8. By the\ninduction hypothesis, there exists a program scheme \u03c1\u2032 over \u03c3\u2032, the expansion of \u03c3\nwith m additional constant symbols, such that for every \u03c3\u2032-structure A\u2032:\n\u2022 if A\u2032 |= \u03c8 then A\u2032 |= \u03c1\u2032; and\n\u2022 if A\u2032 \u0010|= \u03c8 then the computation of \u03c1\u2032 on input A\u2032 is such that the output-\ninstruction is reached with all variables involved in \u03c1\u2032 having the value 0.\nMoreover, \u03c1\u2032 does not involve any array symbols and has depth of nesting d\u22121. Let \u03c1\ndenote the program scheme \u03c1\u2032 with the input- and output-instructions stripped away;\nand suppose that the variables involved in \u03c1\u2032 are those of the tuple y. Also, regard\nxm now as a variable (not in y) as opposed to a constant symbol (we have assumed\nthat the name of the constant symbol of \u03c3\u2032 corresponding to the variable xm is xm\nalso). Define the program scheme \u03c1\u2032\u2032 over \u03c3\u2032\u2032, the expansion of \u03c3 with a constant\nsymbol for each of the variables x1, x2, . . . , xm\u22121, as follows.\nINPUT(y, xm)\nFORALL xm DO\n\u03c1\u2032\nIF y = 0 THEN\ny := max\nELSE\ny := 0\nFI\nOD\nIF xm = max THEN\n(y, xm) := (0, 0)\nELSE\n(y, xm) := (max,max)\nFI\nOUTPUT(y, xm)\n15\nThe shorthand used above should be obvious (except that 0 and max denote tu-\nples of the constant symbols 0 and max, respectively, of the appropriate lengths).\nThe program scheme \u03c1\u2032\u2032 is clearly as required. The case where \u03d5 is of the form\n\u2200xm\u03c8(x1, x2, . . . , xm) is similar. The result follows by induction.\nTheorem 9 There is a program scheme of RFDPS accepting any problem definable\nin inflationary fixed-point logic.\nProof Let \u03d5(y, z) be a formula of inflationary fixed-point logic of the form\nIFP[\u03bbx, R, \u03c8(x,y, R)](z),\nwhere: |x| = |z| = k; R is a relation symbol of arity k, not in the underlying signature\n\u03c3; and \u03c8 is a formula with free variables those of the k-tuple x and the m-tuple y\nsuch that there exists a program scheme \u03c1\u2032 over \u03c3\u2032, the extension of \u03c3 with k + m\nadditional constant symbols called x1, x2, . . . , xk, y1, y2, . . . , ym, with the following\nproperties. Involved in \u03c1\u2032 is an array symbol B of arity k such that B does not\nappear on the left-hand side of an assignment-instruction. We shall regard the array\nsymbol B as being \u2018free\u2019 in the sense that we shall set the values of its elements from\nwithout; and we shall only be interested in valuations of B for which every element is\neither 0 or max. In this way, B models a k-ary relation over the elements of the input\nstructure. Furthermore, the program scheme \u03c1\u2032 is such that for every \u03c3-structure\nA, for every k-tuple u and m-tuple v over |A| and for every array valuation val(B)\nmodelling the k-ary relation R, as above,\n((A,u,v), val(B)) |= \u03c1\u2032 if, and only if, \u03c8A(u,v, R)\n(of course, (A,u,v) is the \u03c3\u2032-structure obtained from A by augmenting A with the\nk + m constants (u,v)).\nSuppose that the variables involved in the program scheme \u03c1\u2032 are those of the\ntuple w, and regard the additional constant symbols x1, x2, . . . , xk now as variables.\nConsider the program scheme \u03c1 over \u03c3\u2032\u2032, the extension of \u03c3 with m additional constant\nsymbols y1, y2, . . . , ym, built as follows (where A is another array symbol of arity k).\nINPUT(w, x)\nFORALL x1 WITH A1 DO initialize A to 0\nFORALL x2 WITH A2 DO\n. . .\nFORALL xk WITH Ak DO\nA[x1, x2, . . . , xk] := 0\nOD\n. . .\nOD\nOD\nREPEAT DO k nested repeat-do-od-\nREPEAT DO blocks\n. . .\nREPEAT DO\nFORALL x1 WITH B1 DO copy A to B\n16\nFORALL x2 WITH B2 DO\n. . .\nFORALL xk WITH Bk DO\nB[x1, x2, . . . , xk] := A[x1, x2, . . . , xk]\nOD\n. . .\nOD\nOD\nFORALL x1 WITH A1 DO\nFORALL x2 WITH A2 DO\n. . .\nFORALL xk WITH Ak DO\nw := 0 \u03c1\u2032 has its input- and\n\u03c1\u2032 output-instructions\nIF w = max THEN stripped away\nA[x1, x2, . . . , xk] := max\nFI\nOD\n. . .\nOD\nOD\nOD\n. . .\nOD\nOD\n(w,x) := (max,max)\nOUTPUT(w, x)\nThe program scheme \u03c1 is such that for every \u03c3-structure A and for every m-tuple u\nover |A|, (A,u) |= \u03c1 and on termination, the array element A[z] encodes \u03d5A(u, z),\nthe inflationary fixed point of \u03c8A(x,u, R).\nImmerman [13] proved that every problem definable in inflationary fixed-point\nlogic can be defined by a sentence of the form\n\u2203z1\u2203z2 . . . \u2203zkIFP[\u03bbx, R, \u03c8(x, R)](z1, z2, . . . , zk),\nwhere \u03c8 is first-order. A combination of the above construction and that of Theorem 8\nyields the required result.\n4 A more formal semantics\nHaving introduced the program schemes of RFDPS, let us now give a more formal\ndescription of a computation of a program scheme on some finite structure. This\nmore formal description will be necessary when we come to prove some (very refined)\nlimitations of our program schemes.\nLet the program scheme \u03c1 \u2208 RFDPS be over the signature \u03c3, and involve the\nvariables of {x1, x2, . . . , xk} and have h instructions. Let A be a \u03c3-structure of size\nn. An instantaneous description (ID) of \u03c1 on A is a tuple (V,A, I,R) consisting of:\n17\n\u2022 a tuple V which contains a value of |A| for every variable of {x1, x2, . . . , xk}\n(with the components ordered in some canonical fashion);\n\u2022 a tuple A which contains a value of |A| for every array element of\n{A[u1, u2, . . . , ua] : A is an array symbol in \u03c1, of arity a, and\nu1, u2, . . . , ua \u2208 |A|}\n(with the components ordered in some canonical fashion);\n\u2022 a number I \u2208 {1, 2, . . . , h}; and\n\u2022 if instruction I of \u03c1 is within the scope of r repeat-do-od-blocks then an r-tuple\nR of numbers from the set {1, 2, . . . , n}.\nWe can represent a computation of \u03c1 on A as a labelled acyclic digraph G(\u03c1A),\nwhose vertices are labelled with IDs of \u03c1 on input A, built as follows. Start with two\nvertices q0 and q1, and an edge (q0, q1). Label the vertex q0 with the ID (V,A, I,R) =\n(0,0, 1, \n) (this represents the values of the variables and the array elements and the\ninstruction about to be executed in the computation of \u03c1 on input A initially, where \n\ndenotes the empty tuple). If the second instruction is not a repeat-do-instruction then\nlabel the vertex q1 with the ID (0,0, 2, \n), otherwise label q1 with the ID (0,0, 2, (1))\n(this represents the values of the variables and the array elements and the instruction\nabout to be executed after execution of the first instruction, the input-instruction,\nof \u03c1 on input A). Now apply the following rules until these rules can no longer be\napplied.\n\u2022 If the instruction associated with (the ID labelling a) vertex q is an assignment-\ninstruction of the form \u03c4 := \u03c4 \u2032, where \u03c4 and \u03c4 \u2032 are terms, then create a new\nvertex q\u2032 and include the edge (q, q\u2032). Label the vertex q\u2032 with the same ID as\nthat labelling vertex q except:\n\u2013 with the value of the term \u03c4 altered so that it is made equal to the value\nof the term \u03c4 \u2032 (where value means according to the ID labelling vertex q);\n\u2013 with the value of I increased by 1; and\n\u2013 if the instruction whose number is the new value of I is a repeat-do-\ninstruction then tag an extra component onto the tuple R and give this\ncomponent the value 1.\n\u2022 If the instruction associated with vertex q is an if-instruction, involving some\ntest \u03d5, then create a new vertex q\u2032 and include the edge (q, q\u2032). Label the vertex\nq\u2032 with the same ID as that labelling vertex q except:\n\u2013 with the value of I increased by 1 if the test \u03d5 holds in A when the values\nof any terms in \u03d5 are taken according to the ID labelling vertex q;\n\u2013 with the value of I made equal to 1 plus the number of the fi-instruction\ncorresponding to the if-instruction if the test \u03d5 does not hold; and\n\u2013 if the instruction whose number is the new value of I is a repeat-do-\ninstruction then tag an extra component onto the tuple R and give this\ncomponent the value 1.\n18\n\u2022 If the instruction associated with vertex q is a fi-instruction then create a new\nvertex q\u2032 and include the edge (q, q\u2032). Label the vertex q\u2032 with the same ID as\nthat labelling vertex q except:\n\u2013 with the value of I increased by 1; and\n\u2013 if the instruction whose number is the new value of I is a repeat-do-\ninstruction then tag an extra component onto the tuple R and give this\ncomponent the value 1.\n\u2022 If the instruction associated with vertex q is a repeat-do-instruction then create\na new vertex q\u2032 and include the edge (q, q\u2032). Label the vertex q\u2032 with the same\nID as that labelling vertex q except:\n\u2013 with the value of I increased by 1; and\n\u2013 if the instruction whose number is the new value of I is a repeat-do-\ninstruction then tag an extra component onto the tuple R and give this\ncomponent the value 1.\n\u2022 If the instruction associated with vertex q is a repeat-od-instruction then create\na new vertex q\u2032 and include the edge (q, q\u2032). Label the vertex q\u2032 with the same\nID as that labelling vertex q except:\n\u2013 if the value of the final component of R is not equal to n then increase\nthis value by 1 and set the value of I to be the value of the corresponding\nrepeat-do-instruction; or\n\u2013 if the value of the final component of R is equal to n then remove the final\ncomponent from R and increase the value of I by 1, unless the instruction\nwhose number is the new value of I is a repeat-do-instruction when we do\nnot remove this final component but simply reset it to 1.\n\u2022 If the instruction associated with vertex q is a forall-do-instruction, for which\nthe control variable is xp, then create n new vertices q0, q1, . . . , qn\u22121 and include\nedges (q, q0), (q, q1), . . . , (q, qn\u22121). Label the vertices of {q0, q1, . . . , qn\u22121} with\nthe same ID as that labelling vertex q except:\n\u2013 with the values of xp (in V) in each of the IDs set at a unique value of |A|;\n\u2013 with the value of I increased by 1; and\n\u2013 if the instruction whose number is the new value of I is a repeat-do-\ninstruction then tag an extra component onto the tuple R and give this\ncomponent the value 1.\n\u2022 If the instruction associated with vertex q is a forall-od-instruction of a forall-\ndo-od-block \u03b1, where the control variable corresponding to this instruction is\nxp, then find the (unique) first ancestor q\u2032\u2032 of q (working backwards up the\nalready constructed acyclic digraph) for which the instruction associated with\nq\u2032\u2032 is the forall-do-instruction corresponding to our forall-od-instruction. Let\nQ be the set of leaves, i.e., vertices of out-degree 0, of the already constructed\nacyclic digraph that are descendants of q\u2032\u2032. If the instruction associated with\nevery vertex of Q is our forall-od-instruction then create a new vertex q\u2032 and\ninclude edges {(q, q\u2032) : q \u2208 Q}. Label the vertex q\u2032 with the following ID.\n19\n\u2013 The value of V is the same as the value of V in the ID labelling vertex\nq\u2032\u2032 except if the values of the local variables of \u03b1 in the IDs labelling the\nvertices of Q are all max then the value of xp is made equal to max;\notherwise it is made equal to 0. If \u03b1 has no local variables then the value\nof xp is made equal to max.\n\u2013 The values of the array elements of A are as they are in the ID labelling\nvertex q\u2032\u2032 except that if any of these array elements has a different value in\nany of the IDs labelling vertices of Q then the value of the array element\nin the ID labelling the vertex q\u2032 is the new value at this vertex of Q (note\nthat because of our syntactic restrictions on forall-do-od-blocks, all array\nelements in the ID labelling q\u2032 are well defined).\n\u2013 The value of I is increased by 1.\n\u2013 The values of R are the same as in the ID labelling vertex q\u2032\u2032, unless the\ninstruction whose number is the new value of I is a repeat-do-instruction\nwhen we tag an extra component onto the tupleR and give this component\nthe value 1.\nFor any block \u03b1 appearing in \u03c1, there might be a number of connected components\nof G(\u03c1A) corresponding to \u03b1 (where by \u2018connected\u2019 we mean with respect to the\nunderlying undirected graph obtained from G(\u03c1A) by replacing all directed edges with\nundirected ones): this is because the block \u03b1 might appear in the scope of a repeat-\ndo-od-block or a forall-do-od-block. We call the subgraphs of G(\u03c1A) corresponding\nto these connected components images of \u03b1 in G(\u03c1A), and we denote an image by\nImA(\u03b1) (it is always clear as to which image of \u03b1 we are referring). Note that every\nimage has a source, the unique vertex of in-degree 0, and a sink , the unique vertex\nof out-degree 0. Note also that the sink of one image will generally be the source of\nanother image, and that the digraph G(\u03c1A) is formed by gluing together images of\nblocks by identifying sources and sinks. The source of G(\u03c1A) is the unique vertex of\nin-degree 0, and the sink of G(\u03c1A) is the unique vertex of out-degree 0. We can clearly\ntalk of a child and a parent of a vertex of G(\u03c1A) (indeed, we have already spoken of\nancestors and descendants).\nLet q be a vertex of G(\u03c1A) and let \u03c4 be some term. We denote by q(\u03c4) the value\nof the term \u03c4 in the ID labelling the vertex q (note that if \u03c4 is an array term then\nwe must instantiate the appropriate values for the index terms). The input structure\nA is accepted by \u03c1 if, and only if, the ID labelling the sink, s, of G(\u03c1A) is such that\ns(x1) = max, s(x2) = max, . . ., s(xk) = max.\nA cut in G(\u03c1A) is a set U of vertices such that the source of G(\u03c1A) is in U and\nthe vertices of U form a connected component (in the above sense). A vertex q of\nG(\u03c1A) \\U is a successor vertex of the cut U if there exists an edge from a vertex of U\nto q. A leaf of U is a vertex of U from which there is no edge to another vertex of U .\n5 Some limitations of our program schemes\nWe begin by proving some limitations on the actual values held by variables and array\nelements throughout a computation of a program scheme of RFDPS on some input\nstructure. Essentially, Lemma 10\u2019s intuitive interpretation is as follows.\n20\n\u2022 A non-control variable can only ever assume a value equal to a constant or that\nof a control variable within whose associated block the non-control variable\nappears.\n\u2022 An array value can only ever be equal to a constant or that of one of the variables\nused to index it.\nWe use the following shorthand in what follows: we denote the set of constant symbols\nfrom a signature \u03c3 in union with the set {0,max} by \u03ba\u03c3.\nLemma 10 Let \u03c1 \u2208 RFDPS involve the variables x1, x2, . . . , xk (and no others) and\nbe over the signature \u03c3. Let A be some \u03c3-structure and let q be some vertex of G(\u03c1A)\nfor which the associated instruction I is in the scope of forall-do-od-blocks in \u03c1 whose\ncontrol variables are (w.l.o.g.) x1, x2, . . . , xm, for some m \u2265 0.\n(i) If I is not a forall-do-instruction then\n{q(xm+1), q(xm+2), . . . , q(xk)} \u2286 \u03ba\u03c3 \u222a {q(x1), q(x2), . . . , q(xm)};\nand if I is a forall-do-instruction, with control variable xm, say, then\n{q(xm), q(xm+1), . . . , q(xk)} \u2286 \u03ba\u03c3 \u222a {q(x1), q(x2), . . . , q(xm\u22121)}.\n(ii) Let A be any array symbol, of arity a, say, and let (u1, u2, . . . , ua) \u2208 |A|a. Then\nq(A[u1, u2, . . . , ua]) \u2208 \u03ba\u03c3 \u222a {u1, u2, . . . , ua}.\nProof We shall show that if (i) and (ii) hold for all vertices in a cut of G(\u03c1A) then\nthey hold for any successor vertex of this cut. As the statement trivially holds for\nthe source of G(\u03c1A), the result will follow by induction. There are a number of cases,\ndepending upon the type of the instruction associated with a leaf or leaves of our cut.\nSuppose that the instruction associated with a leaf q of our cut is a repeat-do-\ninstruction, a repeat-od-instruction, an if-instruction, a fi-instruction or a forall-do-\ninstruction. Then (i) and (ii) trivially hold for any successor vertex of q in G(\u03c1A).\n(Let us remark that if the instruction associated with a successor vertex of q is a\nforall-do-instruction then we have another control variable to contend with. However,\nnote that this control variable was not a control variable at q and so (i) still holds at\na successor vertex of q . This remark applies throughout.)\nSuppose that the instruction I associated with a leaf q of our cut is an assignment-\ninstruction and let the successor vertex of q in G(\u03c1A) be q\u2032.\n\u2022 If I is of the form xi := \u03c4 , for some variable or constant symbol \u03c4 , then (i) and\n(ii) can easily be seen to hold for q\u2032 (note that i \u0010\u2208 {1, 2, . . . ,m}).\n\u2022 If I is of the form xi := B[\u03c4 \u20321, \u03c4 \u20322, . . . , \u03c4 \u2032b], for some array symbol B, of ar-\nity b, say, then q(B[\u03c4 \u20321, \u03c4\n\u2032\n2, . . . , \u03c4\n\u2032\nb]) \u2208 \u03ba\u03c3 \u222a {q(\u03c4 \u20321), q(\u03c4 \u20322), . . . , q(\u03c4 \u2032b)} and q(\u03c4 \u2032j) \u2208\n\u03ba\u03c3 \u222a {q(x1), q(x2), . . . , q(xm)}, for each j \u2208 {1, 2, . . . , b}. So, q\u2032(xi) \u2208 \u03ba\u03c3 \u222a\n{q(x1), q(x2), . . . , q(xm)} and q(xj) = q\u2032(xj), for each j \u2208 {1, 2, . . . ,m} (again,\nnote that i \u0010\u2208 {1, 2, . . . ,m}). Hence, (i) and (ii) hold for q\u2032.\n21\n\u2022 If I is of the form A[\u03c41, \u03c42, . . . , \u03c4a] := \u03c4 , where A is an array symbol, of arity a,\nsay, and where \u03c4 is a variable or a constant symbol, then q\u2032(A[\u03c41, \u03c42, . . . , \u03c4a]) \u2208\n\u03ba\u03c3 \u222a {q(x1), q(x2), . . . , q(xm)} = \u03ba\u03c3 \u222a {q\u2032(x1), q\u2032(x2), . . . , q\u2032(xm)}. However, as\nI is in the scope of forall-do-od-blocks with control variables x1, x2, . . . , xm,\nwe have that {x1, x2, . . . , xm} \u2286 {\u03c41, \u03c42, . . . , \u03c4a}. Hence, q\u2032(A[\u03c41, \u03c42, . . . , \u03c4a]) \u2208\n\u03ba\u03c3 \u222a {q\u2032(\u03c41), q\u2032(\u03c42), . . . , q\u2032(\u03c4a)}, and (i) and (ii) hold for q\u2032.\n\u2022 If I is of the form A[\u03c41, \u03c42, . . . , \u03c4a] := B[\u03c4 \u20321, \u03c4 \u20322, . . . , \u03c4 \u2032b], where A and B are array\nsymbols, of arities a and b, say, then q\u2032(A[\u03c41, \u03c42, . . . , \u03c4a]) \u2208 \u03ba\u03c3\u222a{q(\u03c4 \u20321), q(\u03c4 \u20322), . . . ,\nq(\u03c4 \u2032b)}. Also, q(\u03c4 \u2032j) \u2208 \u03ba\u03c3 \u222a {q(x1), q(x2), . . . , q(xm)}, for each j \u2208 {1, 2, . . . , b}.\nHowever, because I is in the scope of forall-do-od-blocks with control vari-\nables x1, x2, . . . , xm, we have that {x1, x2, . . . , xm} \u2286 {\u03c41, \u03c42, . . . , \u03c4a}. Hence, as\nq(xj) = q\u2032(xj), for each j \u2208 {1, 2, . . . ,m}, we have that (i) and (ii) hold for q\u2032.\nLet \u03b1 be a forall-do-od-block, with control variable xm, say, and let ImA(\u03b1)\nbe an image of \u03b1 in G(\u03c1A) so that every vertex of ImA(\u03b1) apart from the sink\nis in our cut. Denote the sink of ImA(\u03b1) by q\u2032 and the source by p. Consider\nq\u2032(A[u1, u2, . . . , ua]), where A is some array symbol of arity a, say, and u1, u2, . . . , ua \u2208\n|A|. As (i) and (ii) hold for p and every parent of q\u2032 in ImA(\u03b1), we have that\n(ii) also holds for q\u2032. It is also the case that q\u2032(xm) \u2208 {0,max} and q\u2032(xj) =\np(xj) \u2208 \u03ba\u03c3 \u222a {p(x1), p(x2), . . . , p(xm\u22121)} = \u03ba\u03c3 \u222a {q\u2032(x1), q\u2032(x2), . . . , q\u2032(xm\u22121)}, for\neach j \u2208 {m + 1,m + 2, . . . , k}. Hence, (i) holds for vertex q\u2032. The result follows by\ninduction.\nWe now turn to our main result (note that, by Theorem 1, we think of A \u2261Ld\u221e\u03c9 B\nin game-theoretic terms). We emphasise that the following theorem only holds for\nstructures of equal size.\nTheorem 11 Let \u03c1 \u2208 RFDPS be over the signature \u03c3 and have depth of nesting\nd \u2265 0. Let A and B be \u03c3 \u222a {0,max}-structures of equal size such that 0A \u0010= maxA,\n0B \u0010= maxB and A \u2261Ld\u221e\u03c9 B. Then\nA |= \u03c1 if, and only if, B |= \u03c1.\nProof We begin with some definitions and notation before we outline the structure\nof the proof.\nLet the variables involved in \u03c1 be x1, x2, . . . , xk and let the constant symbols of\n\u03c3 be C1, C2, . . . , Cc, where c \u2265 0. Let \u03b1 be any block of instructions appearing in\n\u03c1. Suppose that \u03b1 is in the scope of forall-do-od-blocks \u03b21, \u03b22, . . . , \u03b2m with control\nvariables x1, x2, . . . , xm, respectively, for some m \u2265 0, and suppose further that block\n\u03b2i+1 is in the scope of block \u03b2i, for each i \u2208 {1, 2, . . . ,m\u2212 1}.\nLet ImA(\u03b1) and ImB(\u03b1) be images of \u03b1 in G(\u03c1A) and G(\u03c1B), respectively, and let\nsA and tA be the source and the sink of ImA(\u03b1), and sB and tB the source and sink of\nImB(\u03b1). Write \u03ba\u03c3(A) for {0A,maxA, CA1 , CA2 , . . . , CAc }, with \u03ba\u03c3(B) defined similarly.\nDefinition 12 We write As \u2261Ld\u221e\u03c9 Bs to denote that the following two conditions\nhold:\n(i) (A, sA(x1), sA(x2), . . . , sA(xm)) \u2261Ld\u221e\u03c9 (B, sB(x1), sB(x2), . . . , sB(xm));\n22\n(ii) for each i \u2208 {m + 1,m + 2, . . . , k}, one of the following is true:\n\u2013 sA(xi) = sA(xj) and sB(xi) = sB(xj), for some j \u2208 {1, 2, . . . ,m},\nor\n\u2013 sA(xi) = CA and sB(xi) = CB, for some C \u2208 \u03ba\u03c3.\nLet us reiterate the comment made after Definition 2 but in the present context.\nConsider the forall-do-od-blocks \u03b21, \u03b22, . . . , \u03b2m. Note that if xi is active in the array\nsymbol A in \u03b2i then xj is active in (the same array symbol) A in \u03b2j , for each j \u2208\n{1, 2, . . . , i \u2212 1}; and if xi is inactive in \u03b2i then xj is inactive in \u03b2j , for each j \u2208\n{i + 1, i + 2, . . . ,m}. In particular: either there exists a unique array symbol A so\nthat xi is active in A in \u03b2i, for at least one i \u2208 {1, 2, . . . ,m}, when we say that A is\nthe array symbol associated with \u03b1; or xi is not active in \u03b2i, for each i \u2208 {1, 2, . . . ,m},\nwhen we say that \u03b1 has no associated array symbol. Whenever \u03b1 has an associated\narray symbol, which we always take to be the array symbol A, of arity a, say, and\nf \u2208 {1, 2, . . . ,m} is the maximal such element for which xf is active in A in \u03b2f then\nw.l.o.g. we assume that xi is active in A in \u03b2i at index i, for every i \u2208 {1, 2, . . . , f}\n(throughout, f always refers to this particular index if \u03b1 has an associated array\nsymbol).\nDefinition 13 Suppose that As \u2261Ld\u221e\u03c9 Bs. Let um+1, um+2, . . . , ud \u2208 |A| and let\nvm+1, vm+2, . . . , vd \u2208 |B| be such that\n(A, sA(x1), . . . , sA(xm), um+1, . . . , ud) \u2261Ld\u221e\u03c9 (B, sB(x1), . . . , sB(xm), vm+1, . . . , vd).\nDefine \u03c0s to be the natural map from \u03ba\u03c3(A) \u222a {sA(x1), . . . , sA(xm), um+1, . . . , ud}\nto \u03ba\u03c3(B) \u222a {sB(x1), . . . , sB(xm), vm+1, . . . , vd} (note that this map is well-defined\nand depends upon um+1, um+2, . . . , ud, but we have suppressed this fact in the no-\ntation). We say that sA and sB are array-consistent at (um+1, um+2, . . . , ud) and\n(vm+1, vm+2, . . . , vd) if\n\u03c0s(sA(B[w])) = sB(B[\u03c0s(w)])\n(with \u03c0s applied point-wise) whenever w \u2208 (\u03ba\u03c3(A)\u222a {sA(x1), . . . , sA(xm), um+1, . . . ,\nud})b and either\n\u2022 B is an array symbol, of arity b, say, and different from the associated array\nsymbol of \u03b1, if there is one\nor\n\u2022 there is an associated array symbol A of \u03b1, B = A and wi = sA(xi), for each\ni \u2208 {1, 2, . . . , f}\n(note that, by Lemma 10, \u03c0s(sA(B[w])) is always well-defined). If sA and sB are\narray-consistent at (um+1, um+2, . . . , ud) and (vm+1, vm+2, . . . , vd), for every um+1,\num+2, . . . , ud \u2208 |A| and vm+1, vm+2, . . . , vd \u2208 |B| for which\n(A, sA(x1), . . . , sA(xm), um+1, . . . , ud) \u2261Ld\u221e\u03c9 (B, sB(x1), . . . , sB(xm), vm+1, . . . , vd)\nthen we say that sA and sB are array-consistent (note that the notion of array-\nconsistency is symmetric).\n23\nWe shall proceed by induction on the building process for the constituent blocks\nof \u03c1. The following will be our induction hypothesis: \u2018For all images ImA(\u03b1) and\nImB(\u03b1), if As \u2261Ld\u221e\u03c9 Bs and sA and sB are array-consistent then At \u2261Ld\u221e\u03c9 Bt and tA\nand tB are array-consistent \u2019. If we can prove our induction hypothesis then, as \u03c1 is\nessentially a finite sequence of blocks of instructions, we can apply it to the program\nscheme \u03c1 on input A and B as follows. If sA and sB are the sources of the (unique)\nimages of the first block of \u03c1 and tA and tB are the sinks of the (unique) images of the\nlast block of \u03c1 then the facts that As \u2261Ld\u221e\u03c9 Bs and sA and sB are array-consistent\nimplies that, in particular, At \u2261Ld\u221e\u03c9 Bt, with all variables of \u03c1 on input A being set\nat max on termination if, and only if, all variables of \u03c1 on input B are set at max on\ntermination.\nBase Case The block \u03b1 is an assignment-block.\nLet ImA(\u03b1) and ImB(\u03b1) be such that As \u2261Ld\u221e\u03c9 Bs and sA and sB are array-\nconsistent.\nBase Case (a) Suppose that \u03b1 consists of an instruction of the form xi := \u03c4 , for some\nterm \u03c4 (note that m + 1 \u2264 i \u2264 k).\nWe begin by proving that At \u2261Ld\u221e\u03c9 Bt. If \u03c4 is a variable or a constant symbol\nthen trivially At \u2261Ld\u221e\u03c9 Bt. Hence, we suppose that \u03c4 is an array term of the form\nB[\u03c41, \u03c42, . . . , \u03c4b]. As tA(xj) = sA(xj) and tB(xj) = sB(xj), for each j \u2208 {1, 2, . . . ,m},\nwe have that\n(A, tA(x1), tA(x2), . . . , tA(xm)) \u2261Ld\u221e\u03c9 (B, tB(x1), tB(x2), . . . , tB(xm)).\nHence, we need to show that\n\u2022 tA(xi) = tA(xj) and tB(xi) = tB(xj), for some j \u2208 {1, 2, . . . ,m}\nor\n\u2022 tA(xi) = CA and tB(xi) = CB, for some C \u2208 \u03ba\u03c3.\nAs sA and sB are array-consistent,\n\u03c0s(sA(B[sA(\u03c41), sA(\u03c42), . . . , sA(\u03c4b)]))\n= sB(B[\u03c0s(sA(\u03c41)), \u03c0s(sA(\u03c42)), . . . , \u03c0s(sA(\u03c4b))])\n(use Lemma 10 and the fact that As \u2261Ld\u221e\u03c9 Bs). Again, by Lemma 10 and the fact\nthat As \u2261Ld\u221e\u03c9 Bs, we have that\n\u03c0s(sA(B[sA(\u03c41), sA(\u03c42), . . . , sA(\u03c4b)])) = sB(B[sB(\u03c41), sB(\u03c42), . . . , sB(\u03c4b)]),\nthus\n\u03c0s(tA(xi)) = tB(xi)\nas required (note that, as remarked in Definition 13, Lemma 10 results in our state-\nments being well defined).\nWe now show that tA and tB are array-consistent. Suppose that um+1, um+2, . . . ,\nud \u2208 |A| and vm+1, vm+2, . . . , vd \u2208 |B| are such that\n(A, tA(x1), . . . , tA(xm), um+1, . . . , ud) \u2261Ld\u221e\u03c9 (B, tB(x1), . . . , tB(xm), vm+1, . . . , vd),\n24\nand let \u03c0t be the natural map from \u03ba\u03c3(A) \u222a {tA(x1), . . . , tA(xm), um+1, . . . , ud} to\n\u03ba\u03c3(B) \u222a {tB(x1), . . . , tB(xm), vm+1, . . . , vd}. As it is the case that sA(xj) = tA(xj),\nfor all j \u2208 {1, 2, . . . ,m}, we have that\n(A, sA(x1), . . . , sA(xm), um+1, . . . , ud) \u2261Ld\u221e\u03c9 (B, sB(x1), . . . , sB(xm), vm+1, . . . , vd)\nand \u03c0t is identical to \u03c0s. The fact that no value of any array element changes in the\ntransitions from sA to tA and from sB to tB makes it routine to check that tA and tB\nare array-consistent.\nBase Case (b) Suppose that \u03b1 consists of an instruction of the form A[\u03c41, \u03c42, . . . , \u03c4a] :=\n\u03c4 , for some terms \u03c41, \u03c42, . . . , \u03c4a, \u03c4 , and where A is the associated array symbol of \u03b1.\nAs no variable value has changed in the transitions from sA to tA and from sB to\ntB, we trivially have that At \u2261Ld\u221e\u03c9 Bt.\nWe now show that tA and tB are array-consistent. By arguing as in Base Case\n(a), above, the only array element we need to consider is A[\u03c41, \u03c42, . . . , \u03c4a] in tA\nand tB. Let \u03c0s be the natural map from \u03ba\u03c3(A) \u222a {sA(x1), . . . , sA(xm)} to \u03ba\u03c3(B) \u222a\n{sB(x1), . . . , sB(xm)}, with \u03c0t defined similarly. We have that\n\u03c0t(tA(A[sA(\u03c41), sA(\u03c42), . . . , sA(\u03c4a)]))\n= \u03c0t(sA(\u03c4))\n= \u03c0s(sA(\u03c4))\n= sB(\u03c4) (as As \u2261Ld\u221e\u03c9 Bs and sA and sB are array-consistent)\n= tB(A[sB(\u03c41), sB(\u03c42), . . . , sB(\u03c4a)])\n= tB(A[\u03c0s(sA(\u03c41)), \u03c0s(sA(\u03c42)), . . . , \u03c0s(sA(\u03c4a)])) (as As \u2261Ld\u221e\u03c9 Bs)\nas required.\nThus, whatever the form of the assignment-block \u03b1, we have that At \u2261Ld\u221e\u03c9 Bt\nand tA and tB are array-consistent.\nInductive Case (i) Let \u03b1 be a forall-do-od-block of the form\nFORALL xm+1 WITH Ap DO forall-do-instruction\n\u03b11 block of instructions\n\u03b12 block of instructions\n. . .\n\u03b1l block of instructions\nOD forall-od-instruction\nwhere our induction hypothesis holds for the blocks \u03b11, \u03b12, . . . , \u03b1l. Let ImA(\u03b1) and\nImB(\u03b1) be images of \u03b1 such that As \u2261Ld\u221e\u03c9 Bs and sA and sB are array-consistent.\nNote that A is the associated array symbol of \u03b1 and that we may assume that xi is\nactive in A for \u03b2i at index i, for each i \u2208 {1, 2, . . . ,m + 1} (renaming \u03b1 as \u03b2m+1).\nWe begin by showing that At \u2261Ld\u221e\u03c9 Bt. Pick some um+1 \u2208 |A| and let sAm+1 be\nthe child of sA in G(\u03c1A) for which sAm+1(xm+1) = um+1. Let vm+1 \u2208 |B| be such that\n(A, sA(x1), sA(x2), . . . , sA(xm), um+1) \u2261Ld\u221e\u03c9 (B, sB(x1), sB(x2), . . . , sB(xm), vm+1)\n25\n(at least one such vm+1 exists since m < d) and let sBm+1 be the son of s\nB in G(\u03c1B)\nfor which sBm+1(xm+1) = vm+1. Rewriting, we obtain that\n(A, sAm+1(x1), s\nA\nm+1(x2), . . . , s\nA\nm+1(xm+1))\n\u2261Ld\u221e\u03c9 (B, sBm+1(x1), sBm+1(x2), . . . , sBm+1(xm+1))\nand so Asm+1 \u2261L\nd\n\u221e\u03c9 Bsm+1 .\nNow we turn to the array-consistency of sAm+1 and s\nB\nm+1. Let um+2, um+3, . . . , ud \u2208\n|A| and vm+2, vm+3, . . . , vd \u2208 |B| be such that\n(A, sAm+1(x1), . . . , sAm+1(xm+1), um+2, . . . , ud)\n\u2261Ld\u221e\u03c9 (B, sBm+1(x1), . . . , sBm+1(xm+1), vm+2, . . . , vd).\nRewriting, we obtain that\n(A, sA(x1), . . . , sA(xm), um+1, . . . , ud) \u2261Ld\u221e\u03c9 (B, sB(x1), . . . , sB(xm), vm+1, . . . , vd),\nand the corresponding maps \u03c0sm+1 and \u03c0s are identical. By assumption, s\nA and\nsB are array-consistent at (um+1, um+2, . . . , ud) and (vm+1, vm+2, . . . , vd). As the\ntransitions from sA to sAm+1 and from s\nB to sBm+1 cause no array element to change\nvalue, we must have that sAm+1 and s\nB\nm+1 are array-consistent at (um+2, um+3, . . . , ud)\nand (vm+2, vm+3, . . . , vd). That is, sAm+1 and s\nB\nm+1 are array-consistent.\nBy the induction hypothesis applied to \u03b11, \u03b12, . . . , \u03b1l, we have that Atm+1 \u2261L\nd\n\u221e\u03c9\nBtm+1 and tAm+1 and tBm+1 are array-consistent, where tAm+1 (resp. tBm+1) is the parent\nof tA (resp. tB) for which tAm+1(xm+1) = um+1 (resp. t\nB\nm+1(xm+1) = vm+1).\nWe have just proved that for every \u2018child process\u2019 in the image ImA(\u03b1), there is a\n\u2018similar\u2019 process in ImB(\u03b1). Now we must show that the converse is true. Pick some\nvm+1 \u2208 |B| and let sBm+1 be the child of sB in G(\u03c1B) for which sBm+1(xm+1) = vm+1.\nLet um+1 \u2208 |A| be such that\n(B, sB(x1), . . . , sB(xm), vm+1) \u2261Ld\u221e\u03c9 (A, sA(x1), . . . , sA(xm), um+1).\nAn identical argument to the above yields that Btm+1 \u2261L\nd\n\u221e\u03c9 Atm+1 and t\nB\nm+1 and\ntAm+1 are array-consistent (where the notation is as above). Consequently, either\n\u2022 tA(xm+1) = 0 and tB(xm+1) = 0\nor\n\u2022 tA(xm+1) = max and tB(xm+1) = max;\nso At \u2261Ld\u221e\u03c9 Bt.\nWhat remains to be shown is that tA and tB are array-consistent. Let um+1, um+2,\n. . . , ud \u2208 |A| and vm+1, vm+2, . . . , vd \u2208 |B| be such that\n(A, tA(x1), . . . , tA(xm), um+1, . . . , ud) \u2261Ld\u221e\u03c9 (B, tB(x1), . . . , tB(xm), vm+1, . . . , vd),\nwith \u03c0t defined as usual. There are two cases, according to the definition of array-\nconsistency and the array symbol involved.\n26\nInductive Case (i)(a) Let B be an array symbol, of arity b, say, and different from\nA, and let w \u2208 (\u03ba\u03c3(A) \u222a {tA(x1), . . . , tA(xm), um+1, . . . , ud})b. Rewriting, we obtain\nthat\n(A, sA(x1), . . . , sA(xm), um+1, . . . , ud) \u2261Ld\u221e\u03c9 (B, sB(x1), . . . , sB(xm), vm+1, . . . , vd)\nand, with \u03c0s defined as usual, \u03c0s is identical to \u03c0t. Consequently, by assumption,\n\u03c0s(sA(B[w])) = sB(B[\u03c0s(w)]).\nNote that no transition from sA to tA and from sB to tB causes an array element of\nB to change value and so\n\u03c0t(tA(B[w])) = tB(B[\u03c0t(w)]).\nInductive Case (i)(b) Let w \u2208 (\u03ba\u03c3(A) \u222a {tA(x1), . . . , tA(xm), um+1, . . . , ud})a with\nwi = tA(xi), for each i \u2208 {1, 2, . . . ,m}. Note that the value of A[w] at tA (resp.\nA[\u03c0t(w)] at tB) is identical to the value of A[w] at tAm+1 (resp. A[\u03c0t(w)] at t\nB\nm+1),\nwhere tAm+1 (resp. t\nB\nm+1) is the parent of t\nA (resp. tB) for which tAm+1(xm+1) = wm+1\n(resp. tBm+1(xm+1) = \u03c0t(wm+1)).\nIn particular, as wm+1 \u2208 \u03ba\u03c3(A) \u222a {tA(x1), . . . , tA(xm), um+1, . . . , ud},\n(A, tA(x1), . . . , tA(xm), wm+1, um+2, . . . , ud)\n\u2261Ld\u221e\u03c9 (B, tB(x1), . . . , tB(xm), \u03c0t(wm+1), vm+2, . . . , vd).\nRewriting yields that\n(A, tAm+1(x1), . . . , tAm+1(xm), tAm+1(xm+1), um+2, . . . , ud)\n\u2261Ld\u221e\u03c9 (B, tBm+1(x1), . . . , tBm+1(xm), tBm+1(xm+1), vm+2, . . . , vd).\nFurthermore, \u03c0tm+1 is either identical to \u03c0t or a restriction of \u03c0t; either way, \u03c0tm+1 is\nidentical to \u03c0t on the domain of \u03c0tm+1 . Thus\n\u03c0t(tA(A[w]))\n= \u03c0t(tAm+1(A[w]))\n= \u03c0tm+1(t\nA\nm+1(A[w])) (by Lemma 10)\n= tBm+1(A[\u03c0tm+1(w)])\n= tBm+1(A[\u03c0t(w)])\n= tB(A[\u03c0t(w)]).\nThus, we have that At \u2261Ld\u221e\u03c9 Bt and tA and tB are array-consistent.\nInductive Case (ii) Let \u03b1 be a forall-do-od-block of the form\nFORALL xm+1 DO forall-do-instruction\n\u03b11 block of instructions\n\u03b12 block of instructions\n. . .\n\u03b1l block of instructions\nOD forall-od-instruction\n27\nwhere our induction hypothesis holds for the blocks \u03b11, \u03b12, . . . , \u03b1l. Let ImA(\u03b1) and\nImB(\u03b1) be images of \u03b1 such that As \u2261Ld\u221e\u03c9 Bs and sA and sB are array-consistent.\nThe proof of Case (i) can be applied when some \u03b2i, for i \u2208 {1, 2, . . . ,m} has an active\ncontrol variable and also when no such \u03b2i has an active control variable. (Note that\nso far in the proof of the theorem we have not needed to use the fact that |A| = |B|.)\nInductive Case (iii) Let \u03b1 be a repeat-do-od-block or an if-then-fi-block. In both\ncases, immediate applications of the induction hypothesis yield the required result.\nNote that we require for the case when \u03b1 is a repeat-do-od-block that |A| = |B| as\nin order for our reasoning to hold, the number of iterations of \u03b1 in the corresponding\ncomputations must be identical.\nConsequently, we have that the induction hypothesis holds for every constituent\nblock of \u03c1. Let sA and tA be the source and the sink of G(\u03c1A), with sB and tBS\nthe source and the sink of G(\u03c1B). Clearly, As \u2261Ld\u221e\u03c9 Bs and sA and sB are array-\nconsistent. Hence, At \u2261Ld\u221e\u03c9 Bt and tA and tB are array-consistent, and our result\nfollows.\nLet RFDPSd be those program schemes of RFDPS with depth of nesting at most\nd (and also the class of problems definable by such program schemes). Note that\nRFDPSd is a logic (in Gurevich\u2019s sense).\nCorollary 14\nRFDPS0 \u2282 RFDPS1 \u2282 . . . \u2282 RFDPSd \u2282 RFDPSd+1 \u2282 . . .\nProof Let \u03c3 = \u3008E,C,D\u3009, where E is a binary relation symbol and C and D are\nconstant symbols. Hence, a \u03c3-structure can be thought of as a directed graph with\ntwo distinguished vertices. Fix d \u2265 1. Define the \u03c3-structure Ad+1 as follows. The\nvertices CAd+1 and DAd+1 are distinct vertices of in-degree 0 and out-degree d + 3\nso that they have no neighbour in common (this constitutes all vertices and edges of\nAd+1). Define the \u03c3-structure Bd+1 as follows. The vertices CBd+1 and DBd+1 are\ndistinct vertices of in-degree 0 and out-degree d + 2 and d + 4, respectively, so that\nthey have no neighbour in common (this constitutes all vertices and edges of Bd+1).\nConsider the following program scheme \u03c1d+1 of RFDPSd+1.\nINPUT(x1, x2, . . ., xd+1, y)\nFORALL x1 DO\nFORALL x2 DO\n. . .\nFORALL xd+1 DO\ny := max\nIF\n\u2227\ni\u0005=j xi \u0010= xj \u2227\n\u2227\ni(xi \u0010= 0 \u2227 xi \u0010= max) \u2227\n\u2227\ni E(C, xi)\n\u2227E(C, 0) \u2227 E(C,max) THEN\ny := 0\nFI\nOD\n. . .\nOD\n28\nOD\nIF x1 = 0 THEN\n(x,y) = (max, max)\nELSE\n(x,y) = (0, 0)\nFI\nOUTPUT(x1, x2, . . ., xd+1, y)\nClearly, Ad+1 is accepted by \u03c1d+1 but Bd+1 is not. Suppose that the problem accepted\nby \u03c1d+1 is accepted by some program scheme \u03c1 of RFDPSd. As Duplicator clearly\nhas a winning strategy in the d-pebble game on Ad+1 and Bd+1, by Theorem 1\nAd+1 \u2261Ld\u221e\u03c9 Bd+1. Hence, Theorem 11 yields a contradiction. The result follows (as\nclearly RFDPS0 \u2282 RFDPS1).\nNote that the proof of Corollary 14 can be used to show that the problem consisting\nof all those digraphs for which every vertex has even out-degree is not in RFDPS.\nCorollary 15 There are problems in P which are not in RFDPS.\nLet \u03d5 be a formula of inflationary fixed-point logic. The quantifier-rank q.r.(\u03d5) of\n\u03d5 is defined inductively as follows.\n\u2022 If \u03d5 is first-order quantifier-free then q.r.(\u03d5) = 0.\n\u2022 If \u03d5 is of the form \u00ac\u03c8 then q.r.(\u03d5) = q.r.(\u03c8).\n\u2022 If \u03d5 is of the form \u03c81 \u2228 \u03c82 or \u03c81 \u2227 \u03c82 then q.r.(\u03d5) = max{q.r.(\u03c81), q.r.(\u03c82)}.\n\u2022 If \u03d5 is of the form \u2203\u03c8 or \u2200\u03c8 then q.r.(\u03d5) = 1 + q.r.(\u03c8).\n\u2022 If \u03d5 is of the form IFP[\u03bbx, R, \u03c8(x,y, R)](z) then q.r.(\u03d5) = |x|+ q.r.(\u03c8).\nLet IFPd be those formulae of inflationary fixed-point logic with quantifier rank at\nmost d (and also the class of problems definable by such sentences). The proof of\nCorollary 14 suffices to prove the following.\nCorollary 16 IFP0 \u2282 IFP1 \u2282 . . . \u2282 IFPd \u2282 IFPd+1 \u2282 . . .\nThe above corollary has not been studied before but, as pointed out by Martin\nGrohe in a personal communication, it follows quite easily from known results. The\nfragment IFPd is contained in Ld\u221e\u03c9. This implies that the problem consisting of\nall those structures over the empty signature having at least d + 1 elements is not\nexpressible in IFPd; but it clearly is in IFPd+1 (actually in FOd+1). We remark that\nour proof of Corollary 16 relies on no existing results from finite model theory (and\nnot even on an understanding and appreciation of bounded-variable infinitary logic).\n29\n6 Conclusion\nWhilst our concerns in this paper have been the development of the class of program\nschemes RFDPS and an investigation of its refined structure, we feel that RFDPS\nwill make a good stepping-off point in the quest for a logic for P, as we now explain.\nThroughout any computation by a program scheme of RFDPS, we construct arrays of\nvalues. It will be relatively straightforward to incorporate Lindstro\u00a8m quantifiers (see\n[5]) into the program schemes of RFDPS by extending if-instructions so that the test\ncan be an application of some Lindstro\u00a8m quantifier to some arrays, the values of whose\nelements are either 0 or max (so that the arrays model relations as in the proof of\nTheorem 9). It will also be entirely natural to include variables of a different type. For\ninstance, one might allow an additional universe {0, 1, . . . , n\u2212 1}, when the input to\nsome program scheme is a structure of size n, with some appropriate numeric relations\nand a mechanism for \u2018tying\u2019 the two universes together; for example, an instruction\nx := \r\u03d5(y), where x has numeric type and \u03d5 is first-order, whose semantics are such\nthat the number of values of y for which \u03d5(y) holds is assigned to the variable x. We\nshall pursue such extensions in future work.\nA natural question to consider is how the class of problems accepted by the pro-\ngram schemes of RFDPS (and any extensions we might developed, as in the preceding\nparagraph) compares with those accepted by the programs of C\u02dcPTime and by other\nmodels more prevalent in database theory. We have not so far considered this ques-\ntion: however, let us remark that the problem consisting of those digraphs for which\nevery vertex has even out-degree is not accepted by any program scheme of RFDPS\nyet can be accepted by a program of [14].\nWhereas we feel that it will be fruitful to extend the program schemes of RFDPS,\nas hinted above, and investigate the expressive power of any resulting class of program\nschemes, there are still questions to be asked of RFDPS. For example, as was the case\nfor the program schemes NPS, NPSS and NPSA of [2, 16, 18], can the class of problems\naccepted by the program schemes of RFDPS be realized as a vectorized Lindstro\u00a8m\nlogic? Does this class of problems have a complete member (via some suitable logical\ntranslation)? Is this class of problems nothing other than an extension of inflationary\nfixed-point logic?\nAcknowledgement The authors are extremely grateful to an anonymous referee for\nhis or her excellent remarks as regards an earlier draft of this paper.\nReferences\n[1] S. Abiteboul and V. Vianu, Generic computation and its complexity, Proceedings\nof ACM Symposium on Theory of Computing , ACM Press (1991) 209\u2013219.\n[2] A.A. Arratia-Quesada, S.R. Chauhan and I.A. Stewart, Hierarchies in classes of\nprogram schemes, Journal of Logic and Computation 9 (1999) 915\u2013957.\n[3] A. Blass, Y. Gurevich and S. Shelah, Choiceless polynomial time, Annals of Pure\nand Applied Logic 100 (1999) 141\u2013187.\n[4] J. Cai, M. Fu\u00a8rer and N. Immerman, An optimal lower bound on the number of\nvariables for graph identification, Combinatorica 12 (1992) 389\u2013410.\n30\n[5] H.-D. Ebbinghaus and J. Flum, Finite Model Theory , Springer-Verlag (1995).\n[6] F. Gire and H.K. Hoang, An extension of fixpoint logic with a symmetry-based\nchoice construct, Information and Computation 144 (1998) 40\u201365.\n[7] M. Grohe, Bounded-arity hierarchies in fixed-point logics, Proceedings of Com-\nputer Science Logic (ed. E. Bo\u00a8rger, Y. Gurevich, K. Meinke), Lecture Notes in\nComputer Science Vol. 832, Springer-Verlag (1994) 150\u2013164.\n[8] M. Grohe, Arity hierarchies, Annals of Pure and Applied Logic 82 (1996) 103\u2013\n163.\n[9] M. Grohe and L. Hella, A double arity hierarchy theorem for transitive closure\nlogic, Archive for Mathematical Logic 35 (1996) 157\u2013171.\n[10] Y. Gurevich, Logic and the challenge of computer science, Current Trends in\nTheoretical Computer Science (ed. E. Bo\u00a8rger), Computer Science Press (1988)\n1\u201357.\n[11] Y. Gurevich, Evolving algebras 1993: Lipari guide, Specification and Validation\n(ed. E. Bo\u00a8rger), Oxford University Press (1995) 9\u201336.\n[12] Y. Gurevich, May 1997 Draft of the ASM Guide, Technical Report, EECS De-\npartment, University of Michigan (1997).\n[13] N. Immerman, Relational queries computable in polynomial time, Information\nand Control 68 (1986) 86\u2013104.\n[14] F. Neven, M. Otto, J. Tyszkiewicz, and J. Van den Bussche, Adding for-loops to\nfirst-order logic, Information and Computation 168 (2001) 156\u2013186.\n[15] I.A. Stewart, Logical and schematic characterization of complexity classes, Acta\nInformatica 30 (1993) 61\u201387.\n[16] I.A. Stewart, Program schemes, arrays, Lindstro\u00a8m quantifiers and zero-one laws,\nTheoretical Computer Science 275 (2002) 283\u2013310.\n[17] I.A. Stewart, Using program schemes to logically capture polynomial-time on cer-\ntain classes of structures, London Mathematical Society Journal of Computation\nand Mathematics 6 (2003) 40\u201367.\n[18] I.A. Stewart, Program schemes with binary write-once arrays and the complexity\nclasses they capture, submitted for publication.\n31\n"}
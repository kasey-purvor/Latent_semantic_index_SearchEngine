{"doi":"10.1007\/3-540-36487-0_35","coreId":"71425","oai":"oai:eprints.lancs.ac.uk:994","identifiers":["oai:eprints.lancs.ac.uk:994","10.1007\/3-540-36487-0_35"],"title":"A comparison of decision making criteria and optimization methods for active robotic sensing","authors":["Mihaylova, Lyudmila","Lefebvre, Tine","Bryunincks, Herman","Gadeyne, Klaas","De Schutter, Joris"],"enrichments":{"references":[{"id":16347911,"title":"Tolerance-weighted L-optimal experiment design: a new approach to task-directed sensing,&quot;","authors":[],"date":"1999","doi":"10.1163\/156855399x00252","raw":"J. D. Geeter, J. De Schutter, H. Bruyninckx, H. V. Brussel, and M. Decrton, \\Tolerance-weighted L-optimal experiment design: a new approach to task-directed sensing,&quot; Advanced Robotics, vol. 13, no. 4, pp. 401{416, 1999.","cites":null},{"id":16347913,"title":"Coastal navigation - mobile robot navigation with uncertainty in dynamic environments,&quot; in","authors":[],"date":"1999","doi":"10.1109\/robot.1999.769927","raw":"N. Roy, W. Burgard, D. Fox, and S. Thrun, \\Coastal navigation - mobile robot navigation with uncertainty in dynamic environments,&quot; in Proc. of ICRA, 1999.","cites":null},{"id":16347916,"title":"Acting under uncertainty: Discrete Bayesian models for mobile robot navigation,&quot;","authors":[],"date":"1996","doi":"10.1109\/iros.1996.571080","raw":"A. Cassandra, L. Kaelbling, and J. Kurien, \\Acting under uncertainty: Discrete Bayesian models for mobile robot navigation,&quot; in Proc. of the IEEE\/RSJ Int. Conf. on Intelligent Robots and Systems, 1996.","cites":null},{"id":16347919,"title":"Vision for mobile robot navigation: A survey,&quot;","authors":[],"date":"2002","doi":"10.1109\/34.982903","raw":"G. N. DeSouza and A. Kak, \\Vision for mobile robot navigation: A survey,&quot; IEEE Trans. on Pattern Analysis and Machine Intel., vol. 24, no. 2, pp. 237{267, 2002.","cites":null},{"id":16347920,"title":"Information theoretic sensor data selection for active object recognition and state estimation,&quot;","authors":[],"date":"2002","doi":"10.1109\/34.982896","raw":"J. Denzler and C. Brown, \\Information theoretic sensor data selection for active object recognition and state estimation,&quot; IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 24, pp. 145{157, February 2002.","cites":null},{"id":16347923,"title":"Reinforcement Learning, An introduction.","authors":[],"date":"1998","doi":"10.1109\/tnn.1998.712192","raw":"R. Sutton and A. Barto, Reinforcement Learning, An introduction. MIT, 1998.","cites":null},{"id":16347925,"title":"A tutorial on particle \u00aflters for online nonlinear\/non-Gaussian Bayesian tracking,&quot;","authors":[],"date":"2002","doi":"10.1109\/78.978374","raw":"M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp, \\A tutorial on particle \u00aflters for online nonlinear\/non-Gaussian Bayesian tracking,&quot; IEEE Trans. on Signal Proc., vol. 50, no. 2, pp. 174{188, 2002.","cites":null},{"id":16347930,"title":"Robot Motion Planning and Control. Guidelines in Nonholonomic Motion Planning for Mobile Robots,","authors":[],"date":"1998","doi":"10.1007\/bfb0036070","raw":"J.-P. Laumond, Robot Motion Planning and Control. Guidelines in Nonholonomic Motion Planning for Mobile Robots, by J.-P, Laumond, S. Sekhavat, and F. Lamiraux, available at http:\/\/www.laas.fr\/~jpl\/book.html: Springer-Verlag, 1998.","cites":null},{"id":16347935,"title":"Elastic strips: A framework for integrated planning and execution,&quot; in","authors":[],"date":"1999","doi":"10.1007\/bfb0119411","raw":"O. Brock and O. Khatib, \\Elastic strips: A framework for integrated planning and execution,&quot; in Proc. of 1999 Int. Symp. of Experim. Robotics, pp. 245{254, 1999.","cites":null},{"id":16347938,"title":"On the mathematical foundations of theoretical statistics,&quot;","authors":[],"date":"1922","doi":"10.1007\/978-1-4612-0919-5_1","raw":"R. Fisher, \\On the mathematical foundations of theoretical statistics,&quot; Phylosophical Trans. of the Royal Society of London, Series A, vol. 222, pp. 309{368, 1922.","cites":null},{"id":16347941,"title":"Theory of optimal experiments.","authors":[],"date":"1972","doi":"10.2307\/2334826","raw":"V. Fedorov, Theory of optimal experiments. Academic press, New York ed., 1972.","cites":null},{"id":16347943,"title":"A mathematical theory of communication, I and II,&quot;","authors":[],"date":"1948","doi":null,"raw":"C. Shannon, \\A mathematical theory of communication, I and II,&quot; The Bell System Technical Journal, vol. 27, pp. 379{423 and 623{656, July and October 1948.","cites":null},{"id":16347945,"title":"On information and su\u00b1ciency,&quot;","authors":[],"date":"1951","doi":null,"raw":"S. Kullback, \\On information and su\u00b1ciency,&quot; Annals of mathematical Statistics, vol. 22, pp. 79{86, 1951.","cites":null},{"id":16347947,"title":"A multisine approach for trajectory optimization based on information gain,&quot;","authors":[],"date":"2002","doi":"10.1109\/irds.2002.1041467","raw":"L. Mihaylova, J. De Schutter, and H. Bruyninckx, \\A multisine approach for trajectory optimization based on information gain,&quot; in Proc. of IROS Conf., 2002.","cites":null},{"id":16347948,"title":"A new method for the transformation of means and covariances in \u00aflters and estimators,&quot;","authors":[],"date":"2000","doi":"10.1109\/9.847726","raw":"S. Julier, J. Uhlman, and H. Durrant-Whyte, \\A new method for the transformation of means and covariances in \u00aflters and estimators,&quot; IEEE Trans. on AC, vol. 45, no. 3, pp. 477{482, 2000.","cites":null},{"id":16347949,"title":"Argonne national laboratory and northwestern university, optimization technology center,&quot; http:\/\/www-fp.mcs.anl.gov\/otc\/Guide\/.","authors":[],"date":null,"doi":null,"raw":"NEOS, \\Argonne national laboratory and northwestern university, optimization technology center,&quot; http:\/\/www-fp.mcs.anl.gov\/otc\/Guide\/.","cites":null},{"id":16347950,"title":"Optimal robot excitation and identi\u00afcation,&quot;","authors":[],"date":"1997","doi":"10.1109\/70.631234","raw":"J. Swevers, C. Ganseman, D. Tukel, J. De Schutter, and H. V. Brussel, \\Optimal robot excitation and identi\u00afcation,&quot; IEEE Trans. on AC, vol. 13, no. 5, pp. 730{ 740, 1997.","cites":null},{"id":16347951,"title":"Dynamic Programming.","authors":[],"date":"1957","doi":"10.1073\/pnas.43.10.927","raw":"R. Bellman, Dynamic Programming. New Jersey: Princeton Univ. Press, 1957.","cites":null},{"id":16347953,"title":"Dynamic Programming and Markov Processes.","authors":[],"date":"1960","doi":"10.2307\/1266484","raw":"R. A. Howard, Dynamic Programming and Markov Processes. MIT Press, 1960.","cites":null},{"id":16347955,"title":"Generalized polynomial approximations in Markovian decision processes,&quot;","authors":[],"date":"1985","doi":"10.1016\/0022-247x(85)90317-8","raw":"P. Schweitzer and A. Seidmann, \\Generalized polynomial approximations in Markovian decision processes,&quot; J. of MA and Appl., vol. 110, pp. 568{582, 1985.","cites":null},{"id":16347957,"title":"Decision-theoretic planning: Structural assumptions and computational leverage,&quot;","authors":[],"date":"1999","doi":null,"raw":"C. Boutilier, T. Dean, and S. Hanks, \\Decision-theoretic planning: Structural assumptions and computational leverage,&quot; J. of AI Research, vol. 11, pp. 1{94, 1999.","cites":null},{"id":16347959,"title":"A survey of algorithmic methods for partially observed Markov decision processes,&quot;","authors":[],"date":"1991","doi":"10.1007\/bf02055574","raw":"W. S. Lovenjoy, \\A survey of algorithmic methods for partially observed Markov decision processes,&quot; Annals of Operations Research, vol. 18, pp. 47{66, 1991.","cites":null}],"documentType":{"type":1}},"contributors":["Dimov, Ivan","Lirkov, Ivan","Margenov, Svetozar","Zlatev, Zahari"],"datePublished":"2003","abstract":"This work presents a comparison of decision making criteria and optimization methods for active sensing in robotics. Active sensing incorporates the following aspects: (i ) where to position sensors, and (ii ) how to make decisions for next actions, in order to maximize information gain and minimize costs. We concentrate on the second aspect: \u201cWhere should the robot move at the next time step?\u201d. Pros and cons of the most often used statistical decision making strategies are discussed. Simulation results from a new multisine approach for active sensing of a nonholonomic mobile robot are given","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/71425.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/994\/2\/nma2002.pdf","pdfHashValue":"483582abfcade658caeeb329df7bff893bb8f8e6","publisher":"Springer","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:994<\/identifier><datestamp>\n      2018-01-24T05:59:36Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        A comparison of decision making criteria and optimization methods for active robotic sensing<\/dc:title><dc:creator>\n        Mihaylova, Lyudmila<\/dc:creator><dc:creator>\n        Lefebvre, Tine<\/dc:creator><dc:creator>\n        Bryunincks, Herman<\/dc:creator><dc:creator>\n        Gadeyne, Klaas<\/dc:creator><dc:creator>\n        De Schutter, Joris<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        This work presents a comparison of decision making criteria and optimization methods for active sensing in robotics. Active sensing incorporates the following aspects: (i ) where to position sensors, and (ii ) how to make decisions for next actions, in order to maximize information gain and minimize costs. We concentrate on the second aspect: \u201cWhere should the robot move at the next time step?\u201d. Pros and cons of the most often used statistical decision making strategies are discussed. Simulation results from a new multisine approach for active sensing of a nonholonomic mobile robot are given.<\/dc:description><dc:publisher>\n        Springer<\/dc:publisher><dc:contributor>\n        Dimov, Ivan<\/dc:contributor><dc:contributor>\n        Lirkov, Ivan<\/dc:contributor><dc:contributor>\n        Margenov, Svetozar<\/dc:contributor><dc:contributor>\n        Zlatev, Zahari<\/dc:contributor><dc:date>\n        2003<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/994\/2\/nma2002.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1007\/3-540-36487-0_35<\/dc:relation><dc:identifier>\n        Mihaylova, Lyudmila and Lefebvre, Tine and Bryunincks, Herman and Gadeyne, Klaas and De Schutter, Joris (2003) A comparison of decision making criteria and optimization methods for active robotic sensing. In: Numerical Methods and Applications. Lecture Notes in Computer Science . Springer, Berlin, pp. 316-324. ISBN 9783540006084<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/994\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1007\/3-540-36487-0_35","http:\/\/eprints.lancs.ac.uk\/994\/"],"year":2003,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"A Comparison of Decision Making Criteria and\nOptimization Methods for Active Robotic\nSensing\nL. Mihaylova, T. Lefebvre, H. Bruyninckx, K. Gadeyne and J. De Schutter\nKatholieke Universiteit Leuven, Celestijnenlaan 300B, B-3001 Heverlee Belgium,\nE-mail: Lyudmila.Mihaylova@mech.kuleuven.ac.be\nAbstract. This work presents a comparison of decision making criteria\nand optimization methods for active sensing in robotics. Active sensing\nincorporates the following aspects: (i) where to position sensors, and\n(ii) how to make decisions for next actions, in order to maximize infor-\nmation gain and minimize costs. We concentrate on the second aspect:\n\u201cWhere should the robot move at the next time step?\u201d. Pros and cons of\nthe most often used statistical decision making strategies are discussed.\nSimulation results from a new multisine approach for active sensing of a\nnonholonomic mobile robot are given.\n1 Introduction\nOne of the features of robot intelligence is to deal robustly with uncertainties.\nThis is only possible when the robot is equipped with sensors, e.g., contact sen-\nsors, force sensors, distance sensors, cameras, encoders, gyroscopes. To perform\na task, the robot first needs to know: \u201cWhere am I now ?\u201d. After that the robot\nneeds to decide \u201cWhat to do next ?\u201d, weighting future information gain and\ncosts. The latter decision making process is called active sensing. Distinction is\nmade sometimes between active sensing and active localization. \u201cActive local-\nization\u201d refers to robot motion decisions (e.g. velocity inputs), \u201cactive sensing\u201d\nto sensing decisions (e.g. when a robot is allowed to use only one sensor at a\ntime). In this paper we refer to both strategies as \u201cactive sensing\u201d. Choosing\nactions requires to trade off the immediate with the long-term effects: the robot\nshould take both actions to bring itself closer to its task completion (e.g. reach-\ning a goal position within a certain tolerance) and actions for the purpose of\ngathering information, such as searching for a landmark, surrounding obstacles,\nreading signs in a room, in order to keep the uncertainty small enough at each\ntime instant and assure a good task execution. Typical tasks where active sens-\ning is useful are performed in less structured environments. The uncertainties\nare so important that they influence the task execution: industrial robot tasks in\nwhich the robot is uncertain about the configuration (positions and orientation)\nof its tool and work pieces [1]; mobile robot navigation in a known map (indoor\nand outdoor) [2, 3] where starting from an uncertain initial configuration the\nrobot has to move to a desired goal configuration within a preset time; vision\n2applications with active selection of camera parameters such as focal length and\nviewing angle to improve the object recognition procedures [4, 5]; reinforcement\nlearning [6]: the robot needs to choose a balance between its localization (exploit-\ning) and the new information it can gather about the environment (exploring).\nEstimation, control and active sensing. Next to an active sensing module,\nintelligent robots should also include an estimator and a controller:\n\u2013 Estimation. To overcome the uncertainty in the robot and environment mod-\nels, as well as the sensor data, estimation techniques [7, 8] compute the\nsystem state after fusing the data in an optimal way.\n\u2013 Control. Knowing the desired task, the controller is charged with following\nthe task execution as closely as possible. Motion execution can be achieved\neither by feedforward, feedback control or a combination of both [9].\n\u2013 Active sensing is the process of determining the inputs by optimizing a\nfunction of costs and utilities. These inputs are then sent to the controller.\nActive sensing is challenging for various reasons: (i) The robot and sensor mod-\nels are nonlinear. Some methods linearize these models, but many nonlinear\nproblems cannot be treated this way and impose the necessity to develop special\ntechniques for action generation. (ii) The task solution depends on an optimal-\nity criterion which is a multi-objective function weighting the information gain\nand some costs. It is related to the computational load especially important for\non-line task execution. (iii) Uncertainties in the robot and environment models,\nthe sensor data need to be dealt with. (iv) Often measurements do not supply\ninformation about all variables, i.e. the system is partially observable.\nThe remainder of the paper is organized as follows. In Section 2, the active\nsensing problem is described. The most often used decision making criteria are\ncompared and results for active sensing of a nonholonomic mobile robot are\npresented. Section 3 gives the main groups of optimization algorithms for active\nsensing. Section 4 terminates with the conclusions.\n2 Active sensing : problem formulation\nActive sensing can be considered as a trajectory generation for a stochastic dy-\nnamic system described by the model\nxk+1 = f(xk,uk,\u03b7k) (1)\nzk+1 = h(xk+1, sk+1, \u03bek+1) (2)\nwhere x is the system state vector, f and h nonlinear system and measurement\nfunctions, z is the measurement vector, \u03b7 and \u03be are respectively system and mea-\nsurement noises. u stands for the input vector of the state function, s stands for\na sensor parameter vector as input of the measurement function (an example is\nthe focal length of a camera). The subscript k denotes discrete time. The sys-\ntem\u2019s states and measurements are influenced by the inputs u and s. Further,\nwe make no distinction and denote both inputs to the system with a (actions).\nConventional systems consisting only of control and estimation components as-\nsume that these inputs are given and known. Intelligent systems should be able\n3to adapt the inputs in a way to get the \u201cbest\u201d estimates and in the meanwhile\nto perform the active sensing task \u201cas good as possible\u201d.\nSo, an appropriate multi-objective performance criterion (often called value\nfunction) is needed to quantify for each sequence of actions a1, . . . ,aN (also\ncalled policy) both the information gain and the gain in task execution:\nJ = min\na1,...,aN\n{\n\u2211\nj\n\u03b1jUj +\n\u2211\nl\n\u03b2lCl} (3)\nThis criterion is composed by a weighted sum of rewards: (i) j terms Uj char-\nacterizing the minimization of expected uncertainties (maximization of expected\ninformation extraction) and (ii) l terms Cl specifying other expected costs and\nutilities, e.g. travel distance, time, energy, distances to obstacles. Both Uj and\nCk are function of the policy a1, . . . ,aN . The weighting coefficients \u03b1j and \u03b2l\ngive different impact to the two parts, and are arbitrarily chosen by the designer.\nWhen the state at the goal configuration fully determines the rewards, the terms\nUj and Cl are computed based on this state only. When attention is paid to both\nthe goal configuration and the intermediate time evolution, the terms Uj and Cl\nare a function of the Uj,k and Cl,k at different time steps k. Criterion (3) is to\nbe minimized with respect to the sequence of actions under constraints\nc(x1, . . . ,xN ,a1, . . . ,aN ) \u2264 cthr. (4)\nc is a vector of physical variables that can not exceed some threshold values cthr.\nThe thresholds express for instance maximal allowed velocities and acceleration,\nmaximal steering angle, minimum distance to obstacles, etc.\n2.1 Action sequence\nThe description of the sequence of actions a1, . . . ,aN can be done in different\nways and has a major impact on the optimization problem that needs to be\nsolved afterwards (Section 3).\n\u2013 The actions can be described as lying on a reference trajectory plus a parame-\nterized deviation of it (e.g. by a finite sine\/cosine series, or by an elastic band\nor elastic strip formulation, [9, 10]). In this way, the optimization problem is\nreduced to a finite-dimensional optimization problem on the parameters.\n\u2013 The most general way to present the policy is a sequence of freely chosen\nactions, not restricted to a certain form of trajectory. Constraints, such as\nmaximal acceleration and maximal velocity, can be added to produce exe-\ncutable trajectories. This active sensing problem is called a Markov Decision\nProcess (MDP) for systems with fully observable states and Partially Observ-\nable Markov Decision Process (POMDP) for systems where measurements\ndo not fully observe the states or for systems with measurement noise.\n2.2 Performance criteria related to uncertainty\nThe terms Uj represent (i) the expected uncertainty of the system about its\nstate; or (ii) this uncertainty compared to the accuracy needed for the task\n4completion. In a Bayesian framework, the characterization of the uncertainty of\nthe estimate is based on a scalar loss function of its probability density function.\nSince no scalar function can capture all aspects of a matrix, no function suits\nthe needs of every experiment. Common used functions are:\n\u2013 based on the covariance matrix : The covariance matrix P of the prob-\nability distribution of state x is a measure for the uncertainty on the es-\ntimate. Minimizing P corresponds to minimizing the uncertainty. Active\nsensing is looking for actions which minimize the posterior covariance ma-\ntrix P = P post or the inverse of the Fisher information matrix I [11] which\ndescribes the posterior covariance matrix of an efficient estimator P = I\u22121.\nSeveral scalar functions of P can be applied [12] :\n\u2022 D-optimal design: minimizes the matrix determinant, det(P ), or the log-\narithm of it, log(det(P )). The minimum is invariant to any transforma-\ntion of the state vector x with a non-singular Jacobian such as scaling.\nUnfortunately, this measure does not allow to verify task completion: the\ndeterminant of the matrix being smaller than a certain value does not\nimpose any of the covariances of the state variables to be smaller than\ntheir toleranced value.\n\u2022 A-optimal design: minimizes the trace tr(P ). Unlike D-optimal design,\nA-optimal design does not have the invariance property. The measure\ndoes not even make sense physically if the target states have inconsistent\nunits. On the other hand, this measure allows to verify task completion.\n\u2022 L-optimal design: minimizes the weighted trace tr(WP ). A proper choice\nof the weighting matrix W can render the L-optimal design criterion\ninvariant to transformations of the variables x with a non-singular Ja-\ncobian:W has units and is also transformed. A special case of L-optimal\ndesign is the tolerance-weighted L-optimal design [1], which proposes a\nnatural choice of W depending on the desired standard deviations (tol-\nerances) at task completion. The value of this scalar function has a direct\nrelation to the task completion.\n\u2022 E-optimal design: minimizes the maximum eigenvalue \u03bbmax(P ). Like A-\noptimal design, this is not invariant to transformations of x, nor does\nthe measure makes sense physically if the target states have inconsistent\nunits, but the measure allows to verify task completion.\n\u2013 based on the probability density function : Entropy [13] is a measure of\nthe uncertainty of a state estimate containing more information about the\nprobability distribution than the covariance matrix, at the expense of more\ncomputational costs. The entropy based performance criteria are:\n\u2022 the entropy of the posterior distribution: E[\u2212 log ppost(x)]. E[.] indicates\nthe expected value.\n\u2022 the change in entropy between two distributions p1(x) and p2(x):\nE[\u2212 log p2(x)]\u2212E[\u2212 log p1(x)]. For active sensing, p1(x) and p2(x) can\nbe the prior and posterior or the posterior and the goal distribution.\n\u2022 the Kullback-Leibler distance or relative entropy [14] is a measure for\nthe goodness of fit or closeness of two distributions: E[log p2(x)\np1(x)\n]. The\n5expected value is calculated with respect to p2(x). The relative entropy\nand the change in the entropy are different measures. The change in\nentropy only quantifies how much the form of the probability distribu-\ntions changes whereas the relative entropy also represents a measure of\nhow much the distribution has moved. If p1(x) and p2(x) are the same\ndistributions, translated by different mean values, the change in entropy\nis zero, while the relative entropy is not.\nExample. Distance and orientation sensing of a mobile robot to known bea-\ncons is considered. The sequence of motions of a nonholonomic wheeled mobile\nrobot (WMR) [15], moving from a starting to a goal configuration, is restricted\nto a parameterized trajectory. The optimal trajectory is searched in the class\nQ = Q(p),p \u2208 P, of harmonic functions, where p is a vector of parameters\nobeying to preset physical constraints. With N the number of functions, the\nnew (modified) robot trajectory is generated on the basis of a reference one by\nthe lateral deviation lk (lateral is called the orthogonal robot motion deviation\nfrom a straight line reference trajectory in y direction) as a linear superposition\nlk =\nN\u2211\ni=1\nAisin(ipi\nsr,k\nsr,total\n), (5)\nof sinusoids, with constant amplitudes Ai, sr,k is the path length up to instant\nk, sr,total is the total path length, and r refers to the reference trajectory. In this\nformulation active sensing is a global optimization problem (on the whole robot\ntrajectory) with a criterion to be minimized\nJ = min\nAi,k\n{\u03b11U + \u03b12C} (6)\nunder constraints (for the robot velocity, steering and orientation angles). \u03b11\nand \u03b12 are dimensionless positive weighting coefficients. Here U is in the form\nU = tr(WP ), (7)\nwhere P is the covariance matrix of the estimated states (at the goal config-\nuration), computed by an Unscented Kalman filter [16] and W is a weighting\nmatrix). The cost term C is assumed to be the relative time C = ttotal\/tr,total,\nwhere ttotal is the total time for reaching the goal configuration on the modified\ntrajectory, tr,total the respective time over the reference trajectory. The weighting\nmatrixW represents a product of a normalizing matrixN , and a scaling matrix\nM , W = M N . The matrix N = diag{1\/\u03c321 , 1\/\u03c3\n2\n2 , . . . , \u03c3\n2\nn}. \u03c3i, i = 1, . . . , n,\nare assumed here to be the standard deviations at the goal configuration on the\nreference trajectory. Depending on the task, they could be chosen otherwise. The\nscaling matrix M here is the identity matrix. Simulation results obtained both\nwith (7), and with the averaged criterion Ua =\n1\nkb\u2212ka\n\u2211kb\nk=ka\ntr(WkPk) with\noptimization over the interval [ka, kb] = [30sec, 100sec] are given on Figs. 1, 2.\nThe modified trajectory, generated with different number of sinusoids N (in ac-\ncordance with (5)), and the reference trajectory are plotted together with the\n60 2 4 6 8 10 12\n14\n14.5\n15\n15.5\n16\n16.5\n17\n17.5\n18\n18.5\n19\nN=0\nBeacon\ny \npo\nsi\ntio\nn,\n [m\n]\nx position, [m]\nN=2\nN=3\nN=5\n0 2 4 6 8 10 12\n14\n14.5\n15\n15.5\n16\n16.5\n17\n17.5\n18\n18.5\n19\nN=0\nBeacon\ny \npo\nsi\ntio\nn,\n [m\n]\nx position, [m]\nN=2\nN=3\nN=5\nFig. 1. Trajectories, generated with : (a) U = tr(WP ) (b) the averaged criterion\nUa =\n1\nkb\u2212ka\n\u2211\nkb\nk=ka\ntr(WkPk)\nuncertainty ellipses Figs. 1,2. As it is seen from Figs. 1,2 the most accurate results\nat the goal configuration for U and J are obtained with N = 5 sinusoids. Better\naccuracy is provided with bigger N , at the cost of increased computational load.\nThrough active sensing the robot is approaching to the beacons (Fig. 1), that is\na distinction from a movement over a reference trajectory. Faster increase of the\ninformation at the beginning of the modified trajectories and higher accuracy, is\nobtained than those on the straight-line. From other side, trajectories generated\nby the averaged criterion Ua are characterized with better general performance\nthen those generated with (7) (Fig. 2).\n20 30 40 50 60 70 80 90 100\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\n4.5\n5\n5.5\ntr\n(W\nP)\ntime, [sec]\nN=0\nN=2\nN=3 N=5\n20 30 40 50 60 70 80 90 100\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\n4.5\n5\n5.5\ntime, [sec]\nN=0\nN=2\nN=3 N=5\n \na\nv\ne\nra\nge\n tr\n(W\nP)\nFig. 2. Performance criteria: (a) U = tr(WP ), (b) Ua =\n1\nkb\u2212ka\n\u2211\nkb\nk=ka\ntr(WkPk)\n3 Optimization algorithms for active sensing\nActive sensing corresponds to a constraint optimization of J with respect to\nthe policy a1, . . .aN . Depending on the robot task, sensors and uncertainties,\ndifferent constraint optimization problems arise:\n7\u2013 If the sequence of actions a1, . . .aN is restricted to a parameterized tra-\njectory, the optimization can have different forms: linear programming, con-\nstrained nonlinear least squares methods, convex optimization [17]. Example\nis the dynamical robot identification [18].\n\u2013 If the sequence of actions a1, . . .aN is not restricted to a parameterized\ntrajectory, then the (PO)MDP optimization problem has a different struc-\nture. This could be a finite-horizon, i.e. over a fixed finite number of time\nsteps (N is finite), or an infinite-horizon problem (N =\u221e). For every state\nit is rather straightforward to know the immediate reward being associated\nto every action (1 step policy). The goal however is to find the policy that\nmaximizes the reward over a long term (N steps). Different optimization\nprocedures exist for this kind of problems, examples are:\n\u2022 Value iteration: due to the sequential structure of the problem, the op-\ntimization can be performed as subsequent solution of problems with\nonly 1 (of the N) variables ai. The value iteration algorithm, a dynamic\nprogramming algorithm, calculate recursively the optimal value function\nand policy [19] for finite and infinite horizon problems.\n\u2022 Policy iteration: an iterative technique similar to dynamic programming,\nis introduced by Howard [20] for infinite horizon systems.\n\u2022 Linear programming: an infinite horizon problem can be represented and\nsolved as a linear program [21].\n\u2022 State based search methods represent the system as a graph whose nodes\ncorrespond to states and can handle finite and infinite horizon problems\n[22]. Tree search algorithms search for the optimal path in the graph.\nUnfortunately, exact solutions can only be found for (PO)MDPs with a small\nnumber of (discretized) states. For larger problems approximate solutions are\nneeded [22, 23].\n4 Conclusions\nThis paper addresses the main issues of active sensing in robotics. Multi-objective\ncriteria are used to determine if the result of an action is better than the result\nof another action. These criteria are composed of two terms: a term characteriz-\ning the uncertainty minimization (maximization of information extraction) and\na term representing other utilities or costs, such as traveled path or total time.\nThe features of the basic criteria for uncertainty minimization and the optimiza-\ntion procedures are outlined. Simulation results for active sensing of a wheeled\nmobile robot with a parameterized sequence of actions are presented.\nAcknowledgments. Herman Bruyninckx and Tine Lefebvre are, respectively, Post-\ndoctoral and Doctoral Fellows of the Fund for Scientific Research-Flanders (F.W.O\u2013\nVlaanderen) in Belgium. Lyudmila Mihaylova is a Postdoctoral Fellow at Katholieke\nUniversiteit Leuven, on leave from the Bulgarian Academy of Sciences. Financial sup-\nport by the Center of Excellence BIS21 grant ICA1-2000-70016 and the K. U. Leuven\u2019s\nConcerted Research Action GOA\/99\/04 are gratefully acknowledged.\n8References\n1. J. D. Geeter, J. De Schutter, H. Bruyninckx, H. V. Brussel, and M. Decrton,\n\u201cTolerance-weighted L-optimal experiment design: a new approach to task-directed\nsensing,\u201d Advanced Robotics, vol. 13, no. 4, pp. 401\u2013416, 1999.\n2. N. Roy, W. Burgard, D. Fox, and S. Thrun, \u201cCoastal navigation - mobile robot\nnavigation with uncertainty in dynamic environments,\u201d in Proc. of ICRA, 1999.\n3. A. Cassandra, L. Kaelbling, and J. Kurien, \u201cActing under uncertainty: Discrete\nBayesian models for mobile robot navigation,\u201d in Proc. of the IEEE\/RSJ Int. Conf.\non Intelligent Robots and Systems, 1996.\n4. G. N. DeSouza and A. Kak, \u201cVision for mobile robot navigation: A survey,\u201d IEEE\nTrans. on Pattern Analysis and Machine Intel., vol. 24, no. 2, pp. 237\u2013267, 2002.\n5. J. Denzler and C. Brown, \u201cInformation theoretic sensor data selection for active\nobject recognition and state estimation,\u201d IEEE Transactions on Pattern Analysis\nand Machine Intelligence, vol. 24, pp. 145\u2013157, February 2002.\n6. R. Sutton and A. Barto, Reinforcement Learning, An introduction. MIT, 1998.\n7. M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp, \u201cA tutorial on particle fil-\nters for online nonlinear\/non-Gaussian Bayesian tracking,\u201d IEEE Trans. on Signal\nProc., vol. 50, no. 2, pp. 174\u2013188, 2002.\n8. Y. Bar-Shalom and X. Li, Estimation and Tracking: Principles, Techniques and\nSoftware. Artech House, 1993.\n9. J.-P. Laumond, Robot Motion Planning and Control. Guidelines in Nonholonomic\nMotion Planning for Mobile Robots, by J.-P, Laumond, S. Sekhavat, and F. Lami-\nraux, available at http:\/\/www.laas.fr\/\u02dcjpl\/book.html: Springer-Verlag, 1998.\n10. O. Brock and O. Khatib, \u201cElastic strips: A framework for integrated planning and\nexecution,\u201d in Proc. of 1999 Int. Symp. of Experim. Robotics, pp. 245\u2013254, 1999.\n11. R. Fisher, \u201cOn the mathematical foundations of theoretical statistics,\u201d Phylosoph-\nical Trans. of the Royal Society of London, Series A, vol. 222, pp. 309\u2013368, 1922.\n12. V. Fedorov, Theory of optimal experiments. Academic press, New York ed., 1972.\n13. C. Shannon, \u201cA mathematical theory of communication, I and II,\u201d The Bell System\nTechnical Journal, vol. 27, pp. 379\u2013423 and 623\u2013656, July and October 1948.\n14. S. Kullback, \u201cOn information and sufficiency,\u201d Annals of mathematical Statistics,\nvol. 22, pp. 79\u201386, 1951.\n15. L. Mihaylova, J. De Schutter, and H. Bruyninckx, \u201cA multisine approach for tra-\njectory optimization based on information gain,\u201d in Proc. of IROS Conf., 2002.\n16. S. Julier, J. Uhlman, and H. Durrant-Whyte, \u201cA new method for the transfor-\nmation of means and covariances in filters and estimators,\u201d IEEE Trans. on AC,\nvol. 45, no. 3, pp. 477\u2013482, 2000.\n17. NEOS, \u201cArgonne national laboratory and northwestern university, optimization\ntechnology center,\u201d http:\/\/www-fp.mcs.anl.gov\/otc\/Guide\/.\n18. J. Swevers, C. Ganseman, D. Tukel, J. De Schutter, and H. V. Brussel, \u201cOptimal\nrobot excitation and identification,\u201d IEEE Trans. on AC, vol. 13, no. 5, pp. 730\u2013\n740, 1997.\n19. R. Bellman, Dynamic Programming. New Jersey: Princeton Univ. Press, 1957.\n20. R. A. Howard, Dynamic Programming and Markov Processes. MIT Press, 1960.\n21. P. Schweitzer and A. Seidmann, \u201cGeneralized polynomial approximations in\nMarkovian decision processes,\u201d J. of MA and Appl., vol. 110, pp. 568\u2013582, 1985.\n22. C. Boutilier, T. Dean, and S. Hanks, \u201cDecision-theoretic planning: Structural as-\nsumptions and computational leverage,\u201d J. of AI Research, vol. 11, pp. 1\u201394, 1999.\n23. W. S. Lovenjoy, \u201cA survey of algorithmic methods for partially observed Markov\ndecision processes,\u201d Annals of Operations Research, vol. 18, pp. 47\u201366, 1991.\n"}
{"doi":"10.1007\/s11229-008-9424-5","coreId":"213806","oai":"oai:eprints.lse.ac.uk:26739","identifiers":["oai:eprints.lse.ac.uk:26739","10.1007\/s11229-008-9424-5"],"title":"Sort out your neighbourhood: public good games on dynamic networks","authors":["Spiekermann, Kai"],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":[],"datePublished":"2009","abstract":"Axelrod (The evolution of cooperation, 1984) and others explain how cooperation can emerge in repeated 2-person prisoner\u2019s dilemmas. But in public good games with anonymous contributions, we expect a breakdown of cooperation because direct reciprocity fails. However, if agents are situated in a social network determining which agents interact, and if they can influence the network, then cooperation can be a viable strategy. Social networks are modelled as graphs. Agents play public good games with their neighbours. After each game, they can terminate connections to others, and new connections are created. Cooperative agents do well because they manage to cluster with cooperators and avoid defectors. Computer simulations demonstrate that group formation and exclusion are powerful mechanisms to promote cooperation in dilemma situations. This explains why social dilemmas can often be solved if agents can choose with whom they interact","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/213806.pdf","fullTextIdentifier":"http:\/\/eprints.lse.ac.uk\/26739\/1\/Spiekermann_Sort-out-your-neighbourhood_2009.pdf","pdfHashValue":"0ed08276324810cb40396bc0f4d99374bada1ad9","publisher":"Springer Healthcare Communications","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lse.ac.uk:26739<\/identifier><datestamp>\n      2014-07-17T16:03:31Z<\/datestamp><setSpec>\n      74797065733D4445505453:4C53452D4756<\/setSpec><setSpec>\n      74797065733D434F4C4C53:4C53455F435F454F<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lse.ac.uk\/26739\/<\/dc:relation><dc:title>\n        Sort out your neighbourhood: public good games on dynamic networks<\/dc:title><dc:creator>\n        Spiekermann, Kai<\/dc:creator><dc:subject>\n        HT Communities. Classes. Races<\/dc:subject><dc:subject>\n        HB Economic Theory<\/dc:subject><dc:description>\n        Axelrod (The evolution of cooperation, 1984) and others explain how cooperation can emerge in repeated 2-person prisoner\u2019s dilemmas. But in public good games with anonymous contributions, we expect a breakdown of cooperation because direct reciprocity fails. However, if agents are situated in a social network determining which agents interact, and if they can influence the network, then cooperation can be a viable strategy. Social networks are modelled as graphs. Agents play public good games with their neighbours. After each game, they can terminate connections to others, and new connections are created. Cooperative agents do well because they manage to cluster with cooperators and avoid defectors. Computer simulations demonstrate that group formation and exclusion are powerful mechanisms to promote cooperation in dilemma situations. This explains why social dilemmas can often be solved if agents can choose with whom they interact.<\/dc:description><dc:publisher>\n        Springer Healthcare Communications<\/dc:publisher><dc:date>\n        2009<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lse.ac.uk\/26739\/1\/Spiekermann_Sort-out-your-neighbourhood_2009.pdf<\/dc:identifier><dc:identifier>\n          Spiekermann, Kai  (2009) Sort out your neighbourhood: public good games on dynamic networks.  Synthese, 168 (2).  pp. 273-294.  ISSN 1573-0964     <\/dc:identifier><dc:relation>\n        http:\/\/www.springer.com\/philosophy\/philosophy+of+sciences\/journal\/11229<\/dc:relation><dc:relation>\n        10.1007\/s11229-008-9424-5<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":null,"relations":["http:\/\/eprints.lse.ac.uk\/26739\/","http:\/\/www.springer.com\/philosophy\/philosophy+of+sciences\/journal\/11229","10.1007\/s11229-008-9424-5"],"year":2009,"topics":["HT Communities. Classes. Races","HB Economic Theory"],"subject":["Article","PeerReviewed"],"fullText":"  \nKai Spiekermann \nSort out your neighbourhood: public good \ngames on dynamic networks \n \nArticle (Accepted version) \n(Refereed) \n \n \n \nOriginal citation: \nSpiekermann, Kai (2009) Sort out your neighbourhood: public good games on dynamic \nnetworks. Synthese, 168 (2). pp. 273-294. ISSN 1573-0964 DOI: 10.1007\/s11229-008-9424-5  \n \n\u00a9 2009 Springer Science+Business Media B.V. \n \nThis version available at: http:\/\/eprints.lse.ac.uk\/26739\/ \nAvailable in LSE Research Online: July 2014 \n \nLSE has developed LSE Research Online so that users may access research output of the \nSchool. Copyright \u00a9 and Moral Rights for the papers on this site are retained by the individual \nauthors and\/or other copyright owners. Users may download and\/or print one copy of any \narticle(s) in LSE Research Online to facilitate their private study or for non-commercial research. \nYou may not engage in further distribution of the material or use it for any profit-making activities \nor any commercial gain. You may freely distribute the URL (http:\/\/eprints.lse.ac.uk) of the LSE \nResearch Online website.  \n \nThis document is the author\u2019s final accepted version of the journal article. There may be \ndifferences between this version and the published version.  You are advised to consult the \npublisher\u2019s version if you wish to cite from it. \n \n \n \nSort out Your Neighbourhood: Public Good\nGames on Dynamic Networks\nKai Spiekermann\nAbstract\nAxelrod (1984) and others explain how cooperation can emerge in\nrepeated 2-person prisoner's dilemmas. But in public good games with\nanonymous contributions, we expect a breakdown of cooperation because\ndirect reciprocity fails. However, if agents are situated in a social network\ndetermining which agents interact, and if they can influence the network,\nthen cooperation can be a viable strategy. Social networks are modelled\nas graphs. Agents play public good games with their neighbours. After\neach game, they can terminate connections to others, and new connections\nare created. Cooperative agents do well because they manage to cluster\nwith cooperators and avoid defectors. Computer simulations demonstrate\nthat group formation and exclusion are powerful mechanisms to promote\ncooperation in dilemma situations. This explains why social dilemmas\ncan often be solved if agents can choose with whom they interact.\nMore than 20 years after Axelrod's seminal computer tournaments and the\ndiscussion about direct reciprocity in repeated games [Axelrod1984], we still\nhaven't understood all mechanisms leading to sustained cooperation. Most\nsettings researchers have looked at are based on two unrealistic assumptions.\nFirstly, most models to explain cooperation comprise games with two players.\n2-person prisoner's dilemmas, in particular, have received much attention. But\nmore realistic settings involve more than two persons. Cooperation becomes\nmuch harder in multi-person dilemmas. Under realistic assumptions, it breaks\ndown because targeted reciprocation against defectors is not possible. Secondly,\nmost models do not take the effects of social structure into account. They as-\nsume random matching of strategies or a tournament of pairwise matching. But\nthe reality of human interaction looks quite different: People are situated in a\nsocial network. They meet some people much more often than others. More-\nover, people can influence with whom they interact, thereby changing the social\nstructure that determines who interacts with whom.\nOn the one hand, moving from 2-person to multi-person games makes the\nemergence and maintenance of cooperation harder. On the other hand, social\nstructure often makes it easier. When we allow agents to change the social net-\nwork, cooperation can emerge, even in settings quite hostile to cooperation. In\nthis paper I present a model where agents are situated in a network they are\nable to change over time. They play public good games with their neighbours,\n1\nand they cannot observe who of their neighbours defect. This is not an environ-\nment where one would expect cooperators to thrive. Nevertheless, simulations\nshow that cooperators can do well because they change the social structure of\ninteraction over time.\nThis paper is in 6 parts. In section 1 I introduce dynamic networks and\ndiscuss how the notion of social structure has influenced recent models of co-\noperation. This leads to a preliminary, simple model where 2-person prisoner's\ndilemmas are played on a dynamic network in section 2. Section 3 presents the\ncore model and the simulation results. I discuss the robustness of the model in\nsection 4. Section 5 extends the robustness analysis by taking scale-free network\ntopologies into account. Section 6 draws conclusions.\n1 Dynamic Networks\nAxelrod himself noted that the feasibility of cooperation increases when the en-\ncounter of strategies is positively correlated, that is when cooperators are more\nlikely to meet cooperators [Axelrod1984, pp. 63\u001569; 158\u0015168]. He considered\n\u0010clustering\u0011 and \u0010territoriality\u0011 as possible solutions to the problem that cooper-\native strategies cannot invade a population of defectors individually. At about\nthe same time, and referring to earlier work from [Axelrod & Hamilton1982],\n[Eshel & Cavalli-Sforza1982] discussed \u0010assortment\u0011 as an important factor to\nexplain how cooperation can be initiated in an evolutionary process when the\ndefault behaviour is defection. [Hirshleifer & Rasmusen1989] introduced the\nidea of ostracism into the economics literature, but they did not explicitly dis-\ncuss the spatial dimension. In a first wave of literature, with contributions\nfrom mathematicians, computer scientists, theoretical biologists, economists,\nand from other fields, researchers demonstrated the importance of spatial struc-\nture for the emergence of cooperation. [Lindgren and Nordahl1994a] discuss\niterated prisoner's dilemmas on a lattice to model cooperation in biological\nsystems (see also [Lindgren & Nordahl1994]). Cellular automata with differ-\nent strategies evolve and spatial structure supports the coexistence of coopera-\ntive and non-cooperative strategies. A similar approach by [Ashlock et al.1996]\nleads to the conclusion that partner selection is an important mechanism for\nthe emergence and stability of cooperation in spatially structured ecologies.\n[Nowak et al.1994] also analyse the success of cooperative strategies if evolution-\nary games are played on lattices. Of particular interest for my own approach\nare papers that incorporate dynamic spatial structures. [Tesfatsion1997] analy-\nses the formation of trade networks where trade interactions resemble iterated\nprisoner's dilemmas and agents can accept or refuse trading partners. Where\npartner selection takes place, payoffs are higher, compared to random partner\nmatching.\nMore recently, a second wave of literature on the connection between spa-\ntial structure and cooperation has emerged. This second wave is informed by\nrecent advances in network theory (see for example [Strogatz2001]). Influential\npapers on the formation of networks in general are [Skyrms & Pemantle2000,\n2\nBala & Goyal2000]. Philosophical applications regarding the problem of co-\noperation on networks can be found in [Alexander2003, Alexander2007] and\n[Vanderschraaf2006, Vanderschraaf2007]. Both authors argue that social struc-\nture is crucial to explain human cooperation in cooperation dilemmas. Many\nnew contributions in theoretical biology systematically explore the impact of dif-\nferent network topologies [Lieberman et al.2005, Ohtsuki & Nowak2006, Ohtsuki & Nowak2006a,\nOhtsuki et al.2006, Santos & Pacheco2006, Hauert & Szabo2003, and further\nreferences in these papers]. Of particular interest for this paper is [Santos et al.2008]\nbecause they model public good games on networks.\nIn the aforementioned models the structure of the network remains static.\nThe network structure influences the agents' behaviour and payoffs, but agents\nare not able to change the structure. This paper, by contrast, implements dy-\nnamic network structures, similar to [Pacheco et al.2006] and [Pacheco et al.2008].\nThe latter offer an analytical treatment of the co-evolution of network structure\nfor a system of direct reciprocity. [Zimmerman et al.2004] have a related discus-\nsion for 2-person prisoner's dilemmas. In contrast to these papers, my analysis\nis concerned with public good games on dynamic networks. Agents can influ-\nence the agents they have contact with and thereby shape their neighbourhood.\nThis mirrors the nature of social structure in reality: We have some, but not\ncomplete control over the set of people we interact with. We can cut ties with\nthose who cheat us and establish ties with those who seem trustworthy. Such\nnetworks can be of a professional (trade networks, academic collaborations, etc.)\nor a private nature (networks of acquaintance, social networks in virtual worlds,\netc.). The approach taken here assumes that the change of network structure\nhappens fast, while the strategies of agents remain unchanged, ruling out the\nco-evolution of structure and strategy.\nSocial structure regulates who interacts with whom, and it provides opportu-\nnities for agents to change their interaction partners. One typical way to imple-\nment the notion of structure is to use grids or\u0016less technically\u0016checkerboards.\nEach agent inhabits one field on a checkerboard and has a limited number of\nneighbours. The disadvantage of modeling social structure as a checkerboard\nis its rigidity: Every field on the board has a fixed number of neighbours in\nits immediate local neighbourhood. Real social networks look different: Firstly,\nagents can differ in their number of social contacts; secondly, these contacts are\nnot necessarily local (think of online communities); and thirdly, real agents have\nthe chance to influence the network structure by making and breaking social re-\nlations. To incorporate these properties of real social networks, I model social\nstructure as a graph.\nA graph consists of vertices and edges. When drawing a graph, vertices are\nrepresented as points, and edges as lines connecting these points. Each edge\nconnects two vertices. I take a vertex to represent an agent, and an edge to\nrepresent a social relation between two agents. The network in the model is\ndynamic. It changes its structure because agents can choose to delete edges and\nnew edges are created. This represents the fact that agents have a choice with\nwhom they have social relations.\nAnalytical solutions to repeated games on dynamic networks are difficult\n3\nto find. The space of possible strategies is enormous and the relation between\nnetwork structure and game strategies is difficult to capture. If there is a large\nnumber of agents and a large number of rounds, it is almost impossible to derive\nan extended game form and \u0010solve\u0011 the game. In any case, it is quite implausible\nto assume that agents have common knowledge of the complete history of game\noutcomes and network topology. Also, the complex dynamics of repeated games\nin networks, especially if multi-person games are played, are difficult to tackle\nanalytically. The upshot is that an analytical solution to these complex games\nis practically impossible and would have to rest on knowledge and rationality\nassumptions that would render the model unrealistic. Still, these games can be\nanalysed in greater detail. For complex and dynamic games we need to replace\ndeductive analysis with computational modelling.\n2 2-Person Prisoner's Dilemmas\nI start with a very simple model to introduce the modelling approach. In the\nbeginning, agents are situated in a social network, with random social structure,\nconstrained by a fixed number of edges (I use different initial network topologies\nin section 5). For instance, in figure 1, panel a, we see a randomly structured\nnetwork with 50 agents, with 25 cooperators (white) and 25 defectors (black),\nconnected by 100 randomly drawn edges. Each pair of connected agents plays\na 2-person game with payoffs as stated in table 1.\nTable 1: Game form with prisoner's dilemma payoffs.\ncooperate defect\ncooperate 2, 2 -1, 3\ndefect 3, -1 0, 0\nFor payoff maximising agents these payoffs constitute a prisoner's dilemma.1\nHowever, not all agents are immediate payoff maximisers in this model: I as-\nsume that \u0010cooperators\u0011 always cooperate, even though cooperation is not a\nNash equilibrium for payoff maximisers. \u0010Defectors\u0011, by contrast, always defect.\nDefectors do better than cooperators in each single game in terms of payoff.\nHowever, agents are allowed to sever ties. Deleted ties are replaced by new\nrandom ties. Agents can try to sever ties with defectors, hoping that they get\nconnected to cooperators instead. Cooperators aim to cluster with their own\nkind and avoid defectors, defectors aim to connect to cooperators to exploit\nthem.\nMore technically speaking, a network is represented by a graph with n ver-\ntices and k edges. Let the edges be non-directional. Self-loops (a vertex con-\nnected by an edge to itself) are ruled out. Each vertex represents an agent.\n1For simplicity, I will occasionally call a game with the payoffs of a prisoner's dilemma a\nprisoner's dilemma, even though cooperators do not play a prisoner's dilemma in their own\nperception, all things considered.\n4\nVertices can be of two types: Cooperators (C) and defectors (D). The edges\nrepresent interaction relations between agents such that two connected agents\ninteract with each other in each round of the game. In the beginning, the\nedges randomly connect vertices.2 The type of each vertex is also determined\nat random with the condition that there be x cooperators and y defectors.\nIn each round, every pair of agents connected by an edge plays a prisoner's\ndilemma (in terms of monetary payoff).3 Cooperators always cooperate, defec-\ntors always defect. The payoffs for the prisoner's dilemma are as stated in table\n1. After playing the game agents can choose to delete one of \u0010their\u0011 edges, i.e.\nthey can choose to delete one of the ties4 connecting them to other agents. They\ncan also choose not to delete any edge. This means if an agent i has d edges, i\nhas d + 1 alternatives: Delete one of the d edges, or delete no edge.\nDifferent deletion strategies are conceivable. I explore two simple strategies:\nzealous and inert. In the first simulation I assume that cooperators are zealous.\nThis means they sever ties with defectors whenever they can. Defectors are\ninert, i. e. they never delete connections to other agents, because they benefit\nfrom having ties with cooperators and are not harmed by other defectors. After\nall agents had the option to delete one edge, the number of deleted edges is\nreplaced by new random edges.5 This procedure is repeated for many rounds.\nFigure 1 shows the effect of repeated play. White vertices represent coopera-\ntors, black defectors. In the beginning (panel a) players are randomly connected.\nAfter 100 rounds (panel b), the network has changed its structure. Coopera-\ntors are only connected to other cooperators, defectors only to defectors. The\nsituation depicted in 1b is stable with the strategies described. Neither cooper-\nators nor defectors have reason to sever any ties, given the strategies zealous for\ncooperators and inert for defectors. Since new ties are only established when\nold ties are deleted, no change in the network structure takes place once coop-\nerators and defectors are completely separated. The payoffs for defectors are\nhigher than for cooperators in the beginning, but separation of the two soon\nputs cooperators in a better position. In figure 1b defectors receive zero payoff,\nwhile cooperators receive payoff 2 for each tie to another cooperator.\nWith a slight modification the effect becomes even more dramatic. Assume\nthat defectors are zealous, too, i. e. they sever ties to other defectors if they\ncan. Figure 2 shows the result. Since defectors no longer keep their edges to\nother defectors, the cooperators get all edges in the network, and defectors are\nisolated with no ties to other agents. I have included pseudo-code for this model\nin the appendix.\nEven though the model is simple, it already provides some useful insights.\n2Note that the graph is not a complete graph, i. e. typically many pairs of vertices are not\ndirectly connected.\n3If there are multiple edges between two agents, they play the game as often as there are\nedges between them. Multiple edges can be interpreted as representing a particularly intensive\ninteraction.\n4I use the terms \u0010edge\u0011 and \u0010tie\u0011 interchangeably throughout the paper.\n5For simplicity, I assume that the new random edge can also be the old, deleted edge. This,\nof course, is very unlikely for a sufficiently large network. When adding edges, multiple edges\nbetween the same agents are allowed.\n5\nFigure 1: Complete assortation for 2-person prisoner's dilemmas with coopera-\ntors severing ties to defectors. Cooperators are white, defectors black. (a) is the\ninitial setting with 50 vertices and 100 edges, (b) the network structure after\n100 rounds.\na b\nFirstly, it shows that network dynamics are a powerful mechanism to enforce\ncooperation. Without network dynamics, the best cooperators can do is to play\na conditional strategy like Axelrod's TIT-FOR-TAT. Such strategies `punish'\ndefectors with defection. These punishments are costly. By contrast, moving\naway is a cheap but highly effective punishment, because it imposes future\nlosses on the defector, while giving the punisher a chance to increase payoffs\nby finding a better partner. Secondly, despite its simplicity, the model gives us\na good idea of how some social interactions work. Buyer-seller relations often\nresemble 2-person prisoner's dilemmas: The buyer can refuse to pay, the seller\ncan refuse to send the goods (or send faulty goods). If an agent finds that\nher business partner has cheated her, she stops dealing with him and finds new\npartners (similar results were reported by [Tesfatsion1997]). In this way business\nnetworks of reliable traders emerge even though other enforcement mechanisms\nare missing (proceeding against someone in a different country is often not worth\nthe effort). However, this will only work if both sides expect future interactions.\nWithout a shadow of the future, neither side has an incentive to cooperate.\n3 Multi-Person Public Good Games\nMore interesting questions arise when cutting ties to defectors is not that easy.\nMany real social dilemmas involve more than two persons. The paradigmatic\ncases are collective action and public good problems. When many persons are\ninvolved, it is often difficult or impossible to determine who has cooperated or\ndefected. People can get away with free-riding, because there are no effective\nways to monitor behaviour and punish defectors. The more anonymous inter-\nactions are, the easier free-riding gets. For instance, it is often convenient to\n6\nFigure 2: Complete assortation for 2-person prisoner's dilemmas with cooper-\nators and defectors severing ties to defectors. (a) is the initial setting with 50\nvertices and 100 edges, (b) the network structure after 100 rounds.\na b\ndump one's rubbish into the street in a moonless night (defect), rather than\nseparating it and carrying it to the next recycling center (cooperate). If no one\nis watching, or if people do not know each other well enough to identify offend-\ners (think of large anonymous blocks of flats), free-riding remains undetected\nor unpunished. Therefore, I assume that the behaviour of other agents is not\ndirectly observable, i. e. contributions are anonymous. This means that agents\nonly know how many players play and how the outcome differs from the ideal\noutcome of universal cooperation. They do not learn who has defected, unless\nthis can be inferred indirectly. Rather than cutting specific ties to defectors,\ncooperators can only try to gradually \u0010move away\u0011 if they are caught in a neigh-\nbourhood with high levels of defection. Surprisingly, cooperators can do well\neven in public good games with anonymous contributions. People observe how\nwell the production of public goods is going on the aggregate level, and change\nthe social network accordingly. This is the idea for the next model.\nI describe the core features of the model here; pseudo-code is provided in the\nappendix, and some details of the model are explained in the notes. The model\nis initialised by creating a graph with vertices and edges. Vertices represent\nagents, edges relations between agents. Each round in the model has three\nstages: a playing stage, an edge deletion stage, and an edge replacement stage.\nI begin by describing the playing stage. There are two types of agents,\ncooperators (or contributors) and defectors (free-riders). Agents are again rep-\nresented by vertices in a network. Following Alexander's (2007) terminology, let\nthe associated group of an agent i be all directly connected neighbours of i and\ni himself. If a neighbour is multiply connected to i the neighbour features in the\nassociated group as often as he is connected.6 In each round, each agent plays\n6One could say that the multiply connected agent has a higher stake in the game. Also,\nwhen agents delete an edge to another agent with whom they are multiply connected, this\n7\na public good game with the agent's associated group. The associated group of\ni is denoted Hi, and |Hi| is the cardinality of the associated group. Each agent\ni makes a contribution ci \u2208 {0, 1} to the public good. For notational simplicity,\nI use superscripts to indicate which agent initiates the game, and subscripts to\ndenote who receives the payoff. The net payoff pim for each participant m in the\ngame initiated by i is\npim =\n\uf8f1\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f3\nr\n\u2211\nk\u2208Hi\nck\n|Hi| \u2212 cm for |Hi| \u2265 2\n0 for |Hi| < 2.\n(1)\nThe enhancement factor r is a parameter with 1 < r < 2. For convenience,\nI assume r = 1.5. If all agents contribute, each agent receives a net payoff\nr \u2212 1, provided there are at least 2 players.7 Defection is the strictly dominant\nstrategy for payoff maximisers. However, cooperation can be a viable strategy if\ncooperators manage to play the game only or primarily with other cooperators.\nFigure 3 gives an example. Agent m has edges with agents a, b, and c,\nwho again have edges with other agents. Remember that all agents play the\npublic good game with their associated group. Here m plays one game with\n{a, b, c}, but m also participates in the games initiated by all direct neighbours.\nTherefore, m participates in four games.\nFigure 3: A network constellation. Grey circles are defectors, white circles\ncooperators.\nIn general terms, the payoff pm for an agent m is determined by adding the\npayoffs from all the public good games m is playing, similar to the model of\noverlapping neighbourhoods proposed by [Santos et al.2008]. This results in\nreduces the number of edges between them by 1, rather than deleting all edges.\n7If agent m is c times (multiply) connected to i, m plays the game as often as he is\nconnected and his net payoff is cpim. This means he contributes c times and gets the payoffs\nfor playing c times.\n8\npm =\n\u2211\ni\u2208Hm\npim. (2)\nIn the edge deletion stage agents can influence their network by severing\nties. The edge deletion proceeds asynchronously in random order. Each agent\nhas the opportunity to delete one edge to one neighbour, or do nothing. After\nthe edge deletion stage is over, the number of deleted edges is replaced by new\nrandom edges in the network.8\nI now turn to possible strategies in the edge deletion stage. Agents are able\nto gradually change their neighbourhood when the level of cooperation is un-\nsatisfactory. The question is whether cooperators manage to find cooperative\nneighbourhoods given that they cannot identify defectors directly.9 Agents need\na criterion to decide if and which ties they should cut. Rational agents should\ntry to determine this criterion by calculating the expected utility gain or loss\nfrom severing a tie. To undertake this task it is necessary to understand the\ninformation available to an agent after the playing stage is over and before the\nnetwork change stage begins. The agent does not receive information about\nwho among the neighbours and the neighbours's neighbours is a defector or\ncooperator, unless this can be inferred from the information described. How-\never, the agent is aware of the network topology in his first and second degree\nneighbourhood.\nAfter playing in the constellation as shown in figure 3, the following infor-\nmation is available to agent m:\n1. Agent m knows the rate of defection in his neighbourhood H\u2212m (H\u2212m is\nthe neighbourhood of m without agent m himself, that is Hm\/{m}).\n2. Agent m knows the rates of defection in the groups Ha,\u2212m, Hb,\u2212m, and\nHc,\u2212m.\nIn the example, m knows from the game initiated bym that there is one defector\nin the immediate neighbourhood. From the other games m knows that a and\na's neighbour are cooperators. He infers that in the set of b and b's neighbours\nwithout m (denoted as Hb,\u2212m) are 1 defector and 2 cooperators. In addition,\nm knows that c and his two neighbours are defectors. This in turn also leads to\nthe conclusion that b is a cooperator.\nThe example demonstrates that agent m is not only interested in the type\nof the immediate neighbours. Since m is involved in 4 games (one initiated\nby himself, three others initiated by a, b, and c), m cares about the types of\nhis second degree neighbours as well. In the example, m should delete the edge\nwith agent c, as cooperating with c and her neighbours leads to negative payoffs.\nHowever, in general it is not trivial to see whether an agent should sever ties\n8Again, it is possible that the new random edges replace edges that have just been deleted.\nMultiple edges are allowed.\n9Except for the special case that a cooperator has only one neighbour, or is able to make\ninferences from the games played.\n9\nand to which neighbour. To answer this question it is necessary to calculate\nthe expected10 payoff change from round t to round t + 1 caused by severing\nan edge {m,x}. When severing a tie to an agent x \u2208 H\u2212m the expected payoff\nchanges in two ways. Firstly, x no longer participates in the game initiated by\nm. Secondly, m no longer participates in the game initiated by x. The expected\npayoff change \u2206E(pm) is\n\u2206E(pm) = [p\nm\nm,\u2212x \u2212 pmm]\u2212 pxm (3)\nwith pmm,\u2212x being the payoff m receives from the game initiated by m but\nplayed without agent x.11 The value of the term pmm,\u2212x\u2212pmm depends on whether\nx is a cooperator or a defector. In most cases m does not know the types of his\nneighbours. However m is able to estimate the probabilities that a neighbour\nis a defector based on the outcomes of previous games. The complexity of\nthese calculations depends on the sophistication of the agents. With perfect\nmemory and assuming that agents are able to start with suitable prior beliefs,\na Bayesian treatment would be possible. A Bayesian agent uses all information\nthat becomes available during the course of the game and updates her beliefs\nabout the types of all other agents. In this paper I restrict myself to much\nsimpler and arguably more realistic heuristics.\nThere are two reasons why a Bayesian calculation of the expected utility\nchange is of little practical relevance. Firstly, it is unlikely that agents individ-\nually or on average behave like perfectly rational Bayesian agents, as the level\nof computational effort is enormous.12 Agents have incomplete information and\nlimited cognitive abilities. Therefore they have to use simplifying heuristics\nto make decisions. Secondly, it is more interesting to show that even rather\nunsophisticated agents can reach structures where cooperators keep defectors\nin check. In realistic settings, agents use simple heuristics, and it is of little\ninterpretative interest to model agents as much more sophisticated than they\nactually are.\nTo explore the ensuing dynamics, it is a good idea to run computer simu-\nlations with some plausible strategies. The estimation heuristic underlying all\nmy strategies assumes that agents base their network choice exclusively on the\noutcome of the games they have played in the current round. The rule I propose\nis simple: If an agent wants to sever a tie, the agent severs the tie to the agent\nwhose game had the highest rate of defection in the current round (ties are\nbroken with a random choice among those with the highest rate). In the case of\nfigure 3, this choice is obvious: In the game initiated by m himself, m infers that\nthere is one defector in the immediate neighbourhood. When playing the game\n10The change is expected because it rests on the assumption that the rest of the network\nremains unchanged, which is usually not the case.\n11In the special case of multiple edges, the expected payoff must be calculated such that\none of the multiple edges is deleted. This means that x participates in one game less initiated\nby m, and m participates in one game less initiated by x.\n12Note that if the game is played over many rounds with a limited number of agents,\nthe evidence gathered in the current game should lead to a revision of all earlier reasoning\nprocesses based on earlier evidence. This is computationally very demanding.\n10\n20 40 60 80 100\nround\n-0.5\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\naverage payoff\na b\nFigure 4: Panel a shows complete assortation for a public good game with\ndefectors playing inert and cooperators playing zealous after 100 rounds. There\nare 25 cooperators and 25 defectors, connected by 100 edges. Panel b shows\nthe average payoff per agent per round over time for cooperators (dashed) and\ndefectors (solid).\ninitiated by a, b, and c, m realises that c's neighbourhood has the highest rate\nof defection (here, without m it is 100%). m infers that c must be the defector.\nBut even if no certain inference can be drawn, it makes sense to assume that\nthe neighbour with the highest defection rate in the neighbourhood is the most\nlikely defector.13\nTo understand the basic dynamics of the game, I analyse two simple strate-\ngies already familiar from the 2-person prisoner's dilemma. The zealous strategy\nmeans that an agent severs one tie to a neighbour if the agent experienced a\nnon-zero rate of defection in his own neighbourhood. The agent deletes the\ntie to the neighbour with the highest rate of defection.14 The inert strategy\nmeans that agents never sever a tie to another agent. From a myopic perspec-\ntive (looking only one round ahead), defectors should play inert, since they are\nnever harmed by any tie to other agents, and severing ties reduces their chances\nto exploit cooperators. Cooperators, by contrast, should play a less tolerant\nstrategy, and zealous is a strategy trying to get rid of ties to defectors.\nFigure 4 shows a typical result when 25 zealous cooperators play against\n25 inert defectors, connected by 100 edges, over 100 rounds. Figure 4a reveals\nthat cooperators and defectors are completely separated after 100 rounds, and\ngiven the strategies zealous and inert this is a stable state, i. e. the network\nwill not change any further. We can see in figure 4b that defectors have higher\npayoffs in the beginning, but cooperators soon do much better than defectors.\n13Bear in mind, though, that this reasoning is based on the assumption thatm can remember\nnothing but the last round.\n14If there are several agents with the maximum rate of defection, one of them is picked\nrandomly.\n11\nSince defectors do not have any connections to cooperators once the network\nreaches a stable state, their payoffs in all further rounds will be 0. The assor-\ntation procedure has led to mutually beneficial ties between cooperators, while\nthe ties between defectors do not benefit the defectors. I ran this simulation\n100 times with different random networks as initial setting, and in each simula-\ntion complete separation was reached after 100 rounds. The average payoff for\ncooperators was 2.05, for defectors 0.16.\nDefectors \u0010lose\u0011 this game because they always end up without any connec-\ntion to cooperators, that is with zero payoff for all rounds after the assortation\nis complete and the network is in stable state. The myopic inert strategy led\nto the complete separation of cooperators from defectors. However, if defectors\nadopt a less tolerant strategy they might be able to avoid a network stable state\nwith complete separation of cooperators and defectors. Can defectors have a\nbetter strategy than inert against zealous? To describe the development of the\nnetwork, it is useful to distinguish three different types of edges. CC edges con-\nnect cooperator to cooperator, DD defector to defector, and CD cooperator to\ndefector (and vice versa). Thinking about the dynamics of the game analysed\nso far, it is obvious that defectors should sever DD edges because this creates\na chance for new CD edges, i. e. opportunities for the exploitation of coopera-\ntors. Therefore, defectors should not accept all connections to fellow defectors.\nRather they should keep the dynamics in the network going and try to avoid\nsettlement into a stable state with full assortation. To do this, defectors must\ndelete some or all connections with other defectors. I run simulations where\ndefectors do not accept defectors in their neighbourhood to test this intuition.\nLet us assume that that all cooperators and defectors play zealous. However,\nwith the given parameters (25 cooperators, 25 defectors, 100 edges, 100 rounds)\na stable state with complete separation still emerges in all run simulations.\nFigure 5 shows a typical result after 100 rounds. The zealous strategy has\nnot only led to a complete separation of defectors and cooperators, it also left\nall defectors without any connection to other agents. The average payoffs for\ncooperators are much better than for defectors, but defectors tend to hold out\nfor longer with zealous and have better payoffs before the separation kicks in,\nindicating that zealous at least delays the settlement into complete separation.\nAfter the network is in a stable state, however, zealous\/zealous leads to higher\npayoffs for cooperators compared to zealous\/inert, because there are now more\nedges between cooperators in the stable state. The graph in 5b suggests that\ncooperators earn a payoff of 4.5 per round. This is what we should expect:\nAssume by stipulation that all 25 cooperators have at least one edge when the\nnetwork is in stable state. This is not an unreasonable assumption, given that\nthe average cooperator has 8 edges with the given parameters in stable state.\nWe can then calculate the average payoff by computing all contributions to\nthe public goods games: Each cooperator contributes in the game initiated by\nherself. Also, each of the 100 edges induces two further contributions. Therefore,\nwe have 225 contributions. Each contribution yields payoff 0.5 (because everyone\ncooperates). Thus the average payoff is 225 \u2217 0.5\/25 = 4.5.\nI ran this simulation 100 times (with different random networks as starting\n12\n20 40 60 80 100\nround\n1\n2\n3\n4\naverage payoff\na b\nFigure 5: Complete assortation if both cooperators and defectors play zealous\nwith 25 cooperators, 25 defectors and 100 edges. Panel b shows the average\npayoff over time for cooperators (dashed) and defectors (solid).\npoints), and in all simulations complete separation obtained after 100 rounds.\nThe average payoff for cooperators per round was 3.66, for defectors 0.53.\nThese results are a powerful demonstration that cooperaters can fare very\nwell when they have a chance to cluster. Note that the situation is very hostile\nto cooperation. Cooperative strategies are usually outcompeted by defectors in\nrepeated anonymous public good games. By providing agents with very limited\nlevels of information, and\u0016crucially\u0016with the option to shape the interaction\nenvironment, it is possible for cooperators to cluster and do well.\nAs pointed out above, the game described is too complex to be analysed\nanalytically, but some observations can still be made. Firstly, with the strategies\nfor cooperators as described above (both zealous, or cooperators zealous and\ndefectors inert) the network will always reach a stable state eventually, even if\nagents were to use a zero-intelligence strategy for edge deletion and simply chose\nedges at random. I do not offer a a formal proof for this conjecture, but the\ngist of the argument can easily be seen: There is a small non-zero probability\nfor a transition path from any transient state to a stable state. Therefore the\nnetwork will eventually end up in a stable state through random drift, certainly\nin infinite, perhaps in (a very long) finite time. Secondly, the fact that many\nsimulations end up in stable states very fast cannot be explained by random\ndrift alone. The reason for these fast settlements is that cooperators delete CD\nedges more often and CC edges less often than with the zero-intelligence random\nedge deletion strategy, thereby pushing the network toward an absorbing stable\nstate. The success of cooperators to reach complete separation from defectors\ndepends on their ability to work towards transitions that are beneficial to them.\nThe results obtained so far demonstrate that a process of assortation is\nfeasible under specific sets of parameters. Do the specific results hold more\ngenerally? Until now the number of agents was assumed to be small, and the\n13\nnumber of edges was limited. Also, it would be important to see how the\nmodel behaves if the rate of cooperators to defectors is changed. I turn to these\nquestions in the next section.\n4 Parameter Variations and Robustness\nTo assess the relevance of my model, it is important to show the robustness\nof its behaviour with different parameter values. A full exploration of the pa-\nrameter space is infeasible, given the restrictions in computing power and the\ndifficulty to derive analytical results for dynamic models. Nonetheless, it is\npossible to consider at least some sensible parameter constellations to gain a\nbetter understanding of the model's behaviour. I begin with variations in the\nrate of defectors. I also explore settings with larger networks and networks with\nincreased interconnectivity.\nWhen there are more cooperators than defectors, the network dynamic still\nleads to complete separation. With 40 cooperators and 10 defectors, both play-\ning zealous, and 100 edges in the network, a stable state of complete separation\noccured in all 100 simulations after fewer than 100 rounds. Cooperators fared\nwell with an average payoff per round of 2.92, defectors badly (0.14). What\nhappens when there is a rather small group of cooperators playing against a\nlarge group of defectors? In 100 simulations with 10 cooperators and 40 de-\nfectors, with both types of agents playing zealous, no separation occured after\n100 rounds. Figure 6 shows some constellations after 100 rounds. There are\nstill many defectors connected to cooperators, and exploitation of cooperators\nis widespread. It is also interesting to see that some defectors tend to connect\nwith many cooperators. One can interpret this as a \u0010camouflage\u0011 effect. A de-\nfector connected to many cooperators is less likely to be identified as a defector.\nI increased the number of rounds to 1000. The network settled into a stable\nstate in 32 out of 100 simulations. Cooperators experienced low payoffs (0.60),\nwhile defectors did better (1.34). For small groups of cooperators it is harder\nto separate within a reasonable number of rounds.\nLarger networks do not differ substantively in their behaviour from the re-\nsults observed so far. 100 cooperators and 100 defectors, linked by 400 edges,\nwith both types playing zealous, behave almost identical to the smaller model:\nIn 20 simulations over 100 rounds, complete separation was always reached and\nthe average payoff for cooperators was 3.80, compared to 0.44 for defectors.\nA higher number of edges per vertex can pose a problem for cooperators.\nIn a graph with high connectivity, it is more difficult to distinguish between\ncooperators and defectors. This is bad for cooperators and good for defectors.\nTwo simulations suggests that it takes more time for the model to settle into a\nstable state of separation. In simulations with 25 cooperators, 25 defectors, 200\nedges, and 100 rounds, with both types playing zealous, complete separation\nwas reached in 47 games out of 100. Cooperators had an average payoff of\n2.98, defectors 3.67. Longer play turns around the results to the advantage of\ncooperators: With 1000 rounds, all 100 simulations reached a stable state and\n14\nFigure 6: Network constellations after 100 rounds with 10 cooperators and 40\ndefectors and 100 edges. Both cooperators and defectors play zealous.\nTable 2: A summary of all simulation results with random initial network and\nrandom edge replacement.\ncoop\n(x)\ndef\n(y)\nstrategy coop,\ndef\nedges\n(k)\nrounds simu-\nlations\n% stable\nstate\npayoff\ncoop\npayoff\ndef\n25 25 zealous, inert 100 100 100 100 2.05 0.16\n25 25 zealous, zealous 100 100 100 100 3.66 0.53\n40 10 zealous, zealous 100 100 100 100 2.92 0.14\n10 40 zealous, zealous 100 100 100 0 \u22121.81 1.60\n10 40 zealous, zealous 100 1000 100 32 0.60 1.34\n100 100 zealous, zealous 400 100 20 100 3.80 0.44\n25 25 zealous, zealous 200 100 100 47 2.98 3.67\n25 25 zealous, zealous 200 1000 100 100 7.56 0.62\ncooperators had an average payoff of 7.56, defectors 0.62. This result of delayed\nseparation is plausible: Since the number of deleted and replaced edges per\nround does not increase, more rounds are needed to shift the edges. In addition,\nin a network with large associated groups, the information derived from the\ndefection rates in the neighbourhood has lower quality, compared to networks\nwith smaller associated groups. With the given, limited information it is harder\nto identify defectors in large groups rather than in small groups. However, in\nthe next section I describe a different edge replacement rule that mitigates this\nscaling problem regarding connectivity.\nTable 2 gives a summary of all my simulations so far. Taking stock, the\nmodel displays robustness against most variations. A complete and stable sep-\naration of cooperators from defectors is independent of the number of agents.\nHowever, if the rate of cooperators is low, separation slows down. Also, a higher\nconnectedness of the network delays the process towards a stable state of sepa-\nration.\n15\n5 Scale-Free Networks and Preferential Attach-\nment\nIn the last section I tested the robustness of the model under different parameter\nvalues. In this section I want to cast the net wider and test the robustness of\nthe result with a different network topology. I distinguish between two different\naspects: initial network topology and rules for replacing edges. The simulations\nconsidered above were initialised with random networks. Deleted edges were\nreplaced with random edges between any two non-identical agents. These as-\nsumptions can be changed, leading to a huge space of possible models. Here I\nlook at least at some plausible assumptions.\nApart from testing the robustness of the results, there are other reasons\nwhy different network topologies and rules for changing the topology are worth-\nwhile to consider. While random networks have the merit of theoretical sim-\nplicity, they do not seem to be the typical form of real social contact networks.\n[Newman2003], reviewing empirical results of network research, shows that most\nsocial networks have at least two properties: First, many social networks are\nso-called \u0010small-world networks\u0011; second, the distribution of vertex degrees often\nfollows a power law.\nA network is a small-world network if the average path between any two\nvertices is short, compared to the overall size of the network. The famous (but\nnot necessarily true) hypothesis that any two persons are separated by only \u0010six\ndegrees of separation\u0011 is based on the assumption that social contact networks\nare small-world networks. One simple way to create a small-world network is\nto start with a \u0010large-world\u0011 network, a lattice structure for instance. In a\nlattice, vertices are only connected to other adjacent vertices. Paths from one\npoint of the lattice to another point can be long. The lattice can be turned\ninto a small-world network by adding a few shortcuts. This reduces the av-\nerage path length dramatically, because paths between two formerly distant\nvertices are now shorter due to the shortcuts. Random graphs, as used above,\nare small-world networks because there are many shortcuts available in the net-\nwork. Another structural feature that can induce the small-world property is\nthe existence of \u0010superhubs\u0011. A superhub is a vertex with a very high degree\n(the degree of a vertex is the number of edges connected to a vertex). In a\nsocial contact network, a superhub is a person who knows more people than\nmost other persons. For instance, teachers are often superhubs because they\ninteract with hundreds of students. If superhubs exist, the network is usually a\nsmall-world network, because each vertex is close to a superhub, and any two\nvertices can be connected with a short path through the superhub.\nEmpirical studies suggest that many social networks have a degree distribu-\ntion that follows a power law in its tail. This is in contrast to random networks,\nwhose degree distribution is binomial. Let pd be the fraction of vertices with\ndegree d, which is equivalent to the probability of picking a vertex of degree d\nif one chooses a vertex randomly. If the distribution of probabilities pd follows\na power law, pd \u223c d\u2212\u03b1, we call the network a scale-free network. The difference\n16\n10.05.0 20.03.0 15.07.0\ndegree\n1.00\n0.50\n0.20\n0.10\n0.05\n0.02\ncumul. distribution\na b\nFigure 7: Panel a shows a preferential attachment graph with m0 = m = 2,\n50 vertices (25 cooperators, 25 defectors), and 97 edges. Panel b shows the\ncumulative degree distribution function for this graph on a log-log scale. The\nline-shaped, downward-sloping curve indicates an approximate power-law degree\ndistribution.\nbetween scale-free networks and random networks is that there are typically\nmore superhubs in a scale-free network than in a random network. Scale-free\nnetworks are also small-world networks because of the superhubs.\nWhy are so many networks scale-free? It is likely that the answer lies in\nthe growth process of networks. If there is a widely shared growth process that\nproduces scale-free networks, this would explain their frequent occurance. One\nsuch growth mechanism is preferential attachment [Barabasi & Albert1999]. It\nproceeds as follows: Start with a small complete graph with m0 vertices. For\neach time step, add a vertex and connect it to m existing vertices. For pref-\nerential attachment, assume that the probability \u03a0 that a new vertex will be\nconnected to an old vertex i depends on the degree of the old vertex, so that\n\u03a0(di) = di\/\n\u2211\nj dj . This growth process leads to a scale-free network for large\nn [Barabasi & Albert1999, p. 511]. Figure 7 shows one preferential attachment\ngraph and its cumulative degree distribution function. One can see a few su-\nperhubs and many peripheral vertices. The line-shaped cumulative distribution\nfunction indicates that the degree distribution follows approximately a power-\nlaw.\nSince many social networks are approximately scale-free, it makes sense to\ntest my models on scale-free network topologies for a more realistic setting. I\nstart this exploration by using preferential attachment graphs as initial network\ntopology, but leave the rest of the model unchanged. The graphs are created by\nstarting with 2 vertices, connected by one edge. Then vertices are added, where\neach connects to 2 existing vertices according to the preferential attachment rule\ndescribed. The types of vertices are determined randomly such that there are\n25 cooperators and 25 defectors. I ran 100 simulations, connected by 97 edges\n17\n(1 edge from the starting constellation, 96 edges from the 48 added vertices),\nall agents playing zealous, with 100 iterations each. Each simulation started\nwith a different preferential attachment graph. All networks quickly reached\na complete separation of cooperators and defectors, and cooperators did well\n(100% stable state, cooperator payoff 3.67, defector payoff 0.47), similar to\nthe results with random initial topologies. This is not surprising: Since deleted\nedges are replaced by random edges, the network transforms into a near-random\nnetwork after a few rounds, and therefore the simulation results should be very\nsimilar to those with random networks as initial topology.\nA more interesting question is how the model behaves when the replacement\nof edges follows a preferential attachment mechanism. As before, deleted edges\nare replaced by new edges, but this time the random choice of two non-identical\nvertices is weighted according to the degrees of the existing vertices. A vertex\nwith degree d gets a weight of d + 1. I introduce the fixed component 1 to\ngive agents with degree 0 a positive probability to be reconnected again. The\nprobability of a new edge between vertices a and b with degrees da and db is\nP ({a, b}) = da + 1\u2211\nj (dj + 1)\n\u00b7 db + 1\u2211\nj, j 6=a (dj + 1)\n+\ndb + 1\u2211\nj (dj + 1)\n\u00b7 da + 1\u2211\nj, j 6=b (dj + 1)\n.\nCall this method preferential edge replacement. It models the phenomenon that\nagents who already know many people are more likely to meet. This is a more\nrealistic connection mechanism than random connections.\nThe simulation results confirm the robustness of the model. Again, I start\nwith preferential attachment graphs, but now use the preferential edge replace-\nment mechanism. In 100 simulations with 25 cooperators, 25 defectors, 97 edges,\nand 100 iterations, the network reached a stable state in all simulations, with\nhigh payoffs for cooperators (3.77, compared to 0.37 for defectors). The model\nis robust regarding the change of edge replacement mechanism. Interestingly,\nthe model with preferential edge replacement also scales better regarding more\nhighly connected networks, compared to non-preferential edge replacement.15\nIn 100 simulations with 25 cooperators, 25 defectors, 190 edges (m0 = m = 4),\nand 100 iterations, a stable state was reached in 79% of the simulations. The\naverage payoffs were 4.78 for cooperators and 2.06 for defectors. This com-\npares to 49% stable states and payoffs 2.71 (cooperators) and 3.57 (defectors)\nfor a random graph model without preferential edge replacement and otherwise\nsimilar parameters. For 279 edges (m0 = m = 6), the difference is even more\npronounced, as table 3 shows. The preferential edge replacement speeds up\nthe separation of cooperators and defectors, compared to random edge replace-\nment. This shows that cooperators can do well after a few dozen rounds, even\nin networks with relatively high connectivity. All simulations with preferential\nattachment graphs are summarised in table 3.\n15I would like to thank one of my anonymous referees for pointing out to me that scale-free\nnetworks might scale better in this regard.\n18\nTable 3: A summary of simulation results with preferential attachment net-\nworks. All simulations are based on the strategy zealous for both cooperators\nand defectors. (PA: preferential attachment).\ncoop\n(x)\ndef\n(y)\ninitial\nnetwork\nedge\nreplace\nedges\n(k)\nrounds simul-\nations\n%\nstable\nstate\npayoff\ncoop\npayoff\ndef\n25 25 PA random 97 100 100 100 3.67 0.47\n25 25 PA PA 97 100 100 100 3.77 0.37\n25 25 PA PA 190 100 100 79 4.78 2.06\n25 25 random random 190 100 100 49 2.71 3.57\n25 25 PA PA 279 200 100 90 7.83 2.42\n25 25 random random 279 200 100 35 3.30 5.31\n100 100 PA PA 397 100 20 100 3.83 0.39\n6 Conclusion\nThe agents in this model operate in a setting that is usually rather hostile to\ncooperation. While repeated 2-person prisoner's dilemmas can lead to coop-\neration under suitable conditions, this is not likely in anonymous public good\ngames for two reasons: Firstly, in n-person settings it is not possible to punish\nspecific agents with reciprocal defection. Secondly, if the setting is anonymous,\nit is not even possible to identify defectors, rendering punishment impossible.\nThe model I propose enables cooperators to do well because it introduces social\nstructure. The key to successful cooperation is a clustering of cooperators and\nan exclusion of defectors.\nThe model proposed is simple. It admits only two basic fixed strategies for\nthe playing stage. Future work could consider more advanced strategies that\nreact to previous outcomes. Also, since the playing stage strategies are fixed,\nthe model does not allow for the coevolution of strategies and network structure.\nThis assumption makes sense if strategies are based on dispositions that cannot\neasily be changed. Nevertheless, it would be interesting to relax this restriction.\nMoreover, the current model has a fixed number of edges. Several extensions are\nconceivable where the number of edges changes over time. This would require\nthe introduction of a more sophisticated decision process for the creation and\ndeletion of edges.\nThe problems of collective action and public good provision have concerned\npolitical philosophers and economists for a long time. A lot of energy has been\ninvested into explaining why, empirically, much more cooperation occurs than\nstandard rational choice theory predicts. A focus on repeated games surely\npoints in the right direction, but it only goes half the way. To explain the\npossibility of cooperation in n-person games with anonymous contributions, one\noption is to add social structure. This move is particularly attractive because it\nmakes social structure endogenous. Therefore, the model captures an important\naspect of social interaction in reality: Social structure and the success of social\n19\ninteractions are in a dynamic relation with each other. Mutually beneficial\ninteraction reinforces social relations, exploitation weakens them.\nThis phenomenon is well-known from real settings. For instance, when peo-\nple venture into joint projects (founding a company, sharing a flat, writing a\npaper together, etc.), each participant can either contribute or free-ride. It is\noften difficult to detect free-riding, and even if it can be detected, it is difficult to\npunish the defector efficiently. Rather, people choose not to continue interaction\nin groups where the outcome is disappointing. Learning from experience, agents\nchange the social structure of the environment by sticking with groups where\nfree-riding is rare, and staying away from groups where free-riding is common.\nIndividuals willing to cooperate try to cluster in groups with other cooperators,\nand try to exclude those who defect. What is remarkable about the simulation\nresults is the success of this strategy, even if the information available to the\nagents is very limited. It is not necessary to track down specific defectors, it\nsuffices to observe the collective outcome and change ties to other agents in\nresponse.\nI have mentioned mundane examples of cooperation such as flatsharing, co-\nauthoring papers, or running a company as a group of shareholders. However,\nperhaps the most fundamental problem of cooperation is about life and death:\nThe problem of providing security to live peacefully with each other. In a state\nof anarchy, where a central provision of policing and security is not possible,\nsecurity becomes a public good problem. Hobbes reminds us that everyone can\nkill everyone in a (Hobbesian) state of nature:\n\u0010NATURE hath made men so equal in the faculties of body and\nmind as that, though there be found one man sometimes manifestly\nstronger in body or of quicker mind than another, yet when all is\nreckoned together the difference between man and man is not so\nconsiderable as that one man can thereupon claim to himself any\nbenefit to which another may not pretend as well as he. For as\nto the strength of body, the weakest has strength enough to kill the\nstrongest, either by secret machination or by confederacy with others\nthat are in the same danger with himself.\u0011 [Hobbes1996[1651], ch.\n13]\nWhen government fails, murderers are no longer kept in check by the threat of\npunishment. Everyone has to fight for himself, and the public good of peace\ncan no longer be provided. In these situations, fleeing to safer areas is often the\nonly option. The large-scale move of refugees in civil wars or failed states can\nbe understood as the attempt to find a safe haven of mutual cooperation in the\nmost basic sense of cooperation: not killing each other. The model discussed in\nthis paper is certainly much too simple to be applied to such complex problems,\nbut with some caveats one could draw the conclusion that overcoming a state\nof anarchy requires a formation of new local \u0010clusters\u0011 of cooperation based on\nprocesses of inclusion and exclusion. The model could suggest that states of\nprolonged anarchy are likely to be followed by a phase of localisation, where\n20\nvillages or clans form cores of cooperation. Clearly, much more methodological,\ntheoretical, and empirical work is needed to apply computational models to\nsuch complex problems. Nevertheless, the example suggests the potential areas\nof application.\nModelling public good problems with anonymous contributions on dynamic\nnetworks shows that cooperation can be maintained, and cooperative agents\ncan do well, if they choose with whom they interact. Cooperators can find each\nother and build groups of cooperation. Endogenous, dynamic social structure\nis one important approach to understand the emergence of cooperation.\nPseudo Code for 2-Person Model\nThe model was coded in Mathematica. I include pseudo code for the all\nzealous strategy for one iteration to describe the central routines of the program\nused.\n\/\/ INITIALISATION\nCreate network topology.\nSet budget of all agents to 0.\nSet status of agents to cooperator or defector.\n\/\/MAIN ROUTINE\n\/\/GAME\nFor each edge in network:\nPlay prisoner's dilemma with agents connected by edge\naccording to their status and change budgets.\nEnd For.\n\/\/DELETE EDGES\nSet deletedEdges = 0.\nFor each vertex in network in random order:\nIf vertex currently has one or more neighbors\nAND one or more of neighbors is defector then:\nSet cutoffAgent = one of the defectors in neighborhood chosen randomly.\nChange network by deleting one edge from vertex to cutoffAgent.\nSet deletedEdges = deletedEdges+ 1.\nEnd if.\nEnd for.\n\/\/REPLACE EDGES\nFor each edge from 1 to deletedEdges:\nAdd random edge (no self-loops) to network.\nEnd for.\nPseudo-Code for Public Good Model\nThis is pseudo-code for one iteration, assuming that both types play strategy\nzealous.\n\/\/ INITIALISATION\nCreate network topology.\nSet budget of all agents to 0.\nSet status of agents to cooperator or defector.\n\/\/MAIN ROUTINE\n\/\/GAME\nFor each vertex in network:\nSet associatedGroup(vertex) = all agents connected to vertex incl. vertex.\n\/\/agents multiply connected to vertex are counted multiply.\nPlay public goods game in associatedGroup and change budgets.\nEnd For.\n\/\/RECORD DEFECTION RATES\nFor each vertex in network:\n21\nneighbors(vertex) = all agents connected to vertex excl. vertex.\nFor each nb in neighbors(vertex):\nSet otherP layers = associatedGroup(nb)\/{vertex}.\nSet defRates(vertex, nb) = |all defectors in otherP layers|\/|otherP layers|.\nEnd For.\nEnd For.\n\/\/DELETE EDGES\nSet deletedEdges = 0.\nFor each vertex in network in random order:\nIf vertex currently has one or more neighbors\nAND |defectors in neighbors(vertex)| > 0 then:\nSet maxdefector = agent with highest rate in defRates(vertex)\nof those currently connected to vertex. \/\/random choice if tied\nIf defRates(maxdefector) > 0 then:\nDelete one edge from vertex to maxdefector in network.\nSet deletedEdges = deletedEdges+ 1.\nEnd if.\nEnd if.\nEnd for.\n\/\/REPLACE EDGES\nFor each edge from 1 to deletedEdges:\nAdd random edge (no self-loops) to network.\nEnd for.\nReferences\n[Alexander2003] Alexander, J. M. (2003). Random Boolean Net-\nworks and Evolutionary Game Theory. Philosophy\nof Science, 70, 1289\u00151304.\n[Alexander2007] Alexander, J. M. (2007). The structural evolution\nof morality. Cambridge et al.: Cambridge Univer-\nsity Press.\n[Ashlock et al.1996] Ashlock, D., Smucker, M. D., Stanley, E. A.,\nand Tesfatsion, L. (1996). Preferential partner\nselection in an evolutionary study of prisoner's\ndilemma. BioSystems, 37, 99\u0015125.\n[Axelrod1984] Axelrod, R. M. (1984). The Evolution of Cooper-\nation. New York: Basic Books.\n[Axelrod & Hamilton1982] Axelrod, R. M. and Hamilton, W. D. (1982). The\nEvolution of Cooperation. Science, 211, 1390\u0015\n1396.\n[Bala & Goyal2000] Bala, V. and Goyal, S. (2000). A noncooperative\nmodel of network formation. Econometrica, 68(5),\n1181\u00151229.\n[Barabasi & Albert1999] Barabasi, A.-L. and Albert, R. (1999). Emergence\nof scaling in random networks. Science, 286, 509\u0015\n512.\n22\n[Eshel & Cavalli-Sforza1982] Eshel, I. and Cavalli-Sforza, L. L. (1982). Assort-\nment of encounters and evolution of cooperative-\nness. PNAS, 79(4), 1331\u00151335.\n[Hauert & Szabo2003] Hauert, C. and Szabo, G. (2003). Prisoner's\ndilemma and public goods games in different ge-\nometries: compulsory versus voluntary interac-\ntions. Complexity, 4(4), 31\u001538.\n[Hirshleifer & Rasmusen1989] Hirshleifer, D. and Rasmusen, E. (1989). Coop-\neration in a repeated prisoners' dilemma with os-\ntracism. Journal of Economic Behavior and Orga-\nnization, 12, 87\u0015106.\n[Hobbes1996[1651]] Hobbes, T. (1996). Leviathan. Rev. ed. Cam-\nbridge: Cambridge University Press. First pub-\nlished 1651.\n[Lieberman et al.2005] Lieberman, E., Hauert, C., and Nowak, M. A.\n(2005). Evolutionary dynamics on graphs. Nature,\n433(7023), 312\u0015316.\n[Lindgren & Nordahl1994] Lindgren, K. and Nordahl, M. G. (1994). Cooper-\nation and community structure in artifical ecosys-\ntems. Artificial Life, 1, 15\u001537.\n[Lindgren and Nordahl1994a] Lindgren, K. and Nordahl, M. G. (1994). Evolu-\ntionary dynamics of spatial games. Physica D, 75,\n292\u0015309.\n[Nowak et al.1994] Nowak, M. A., Bonhoeffer, S., and May R. M.\n(1994). Spatial games and the maintenance of co-\noperation. PNAS, 91(11), 4877\u00154881.\n[Newman2003] Newman, M. E. J. (2003). The structure and func-\ntion of complex networks. SIAM Review, 45(2),\n167\u0015256.\n[Ohtsuki et al.2006] Ohtsuki, H., Hauert, C., Lieberman, E., and\nNowak, M. A. (2006). A simple rule for the evolu-\ntion of cooperation on graphs and social networks.\nNature, 441, 502\u0015505.\n[Ohtsuki & Nowak2006] Ohtsuki, H. and Nowak, M. A. (2006). Evolution-\nary games on cycles. Proceedings of the Royal So-\nciety B, 273, 2249\u00152256.\n[Ohtsuki & Nowak2006a] Ohtsuki, H. and Nowak, M. A. (2006a). The repli-\ncator equation on graphs. Journal of Theoretical\nBiology, 243, 86\u001597.\n23\n[Pacheco et al.2006] Pacheco, J. M., Traulsen, A., and Nowak, M. A.\n(2006). Social diversity promotes the emergence\nof cooperation in public good games. Nature, 454,\n213\u0015217.\n[Pacheco et al.2008] Pacheco, J. M., Traulsen, A., Ohtsuki, H., and\nNowak, M. A. (2008). Repeated games and direct\nreciprocity under active linking. Journal of Theo-\nretical Biology, 250, 723\u0015731.\n[Santos et al.2008] Santos, F. C., Santos, M. D., and Pacheco, J. M.\n(2008). Social diversity promotes the emergence of\ncooperation in public goods games. Nature, 454,\n213\u0015216.\n[Santos & Pacheco2006] Santos, F. C. and Pacheco, J. M. (2006). A new\nroute to the evolution of cooperation. European\nSociety for Evolutionary Biology, 19, 726\u0015733.\n[Skyrms & Pemantle2000] Skyrms, V. and Pemantle, R. (2000). A dynamic\nmodel of social network formation. PNAS, 97(16),\n9340\u00159346.\n[Strogatz2001] Strogatz, S. (2001). Exploring complex networks.\nNature, 410, 268\u0015276.\n[Tesfatsion1997] Tesfatsion, L. (1997). \"A Trade Network Game\nwith Endogenous Partner Selection.\" In: H. M.\nAmman, B. Rustem, and A. B. Whinston (eds.),\nComputational Approaches to Economic Prob-\nlems, Kluwer, 249\u0015269.\n[Vanderschraaf2006] Vanderschraaf, P. (2006). War or peace?: a dy-\nnamical analysis of anarchy. Economics and Phi-\nlosophy, 22, 243\u0015279.\n[Vanderschraaf2007] Vanderschraaf, P. (2007). Covenants and reputa-\ntions. Synthese, 157, 167\u0015195.\n[Zimmerman et al.2004] Zimmermann, M. G., J. M., Egu\u00edluz, V. M., and\nSan Miguel, M. (2004). Coevolution of dynami-\ncal states and interactions in dynamic networks.\nPhysical Review E, 69, 065102(R).\n24\n"}
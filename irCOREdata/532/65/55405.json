{"doi":"10.1177\/0278364908096286","coreId":"55405","oai":"oai:eprints.lincoln.ac.uk:2095","identifiers":["oai:eprints.lincoln.ac.uk:2095","10.1177\/0278364908096286"],"title":"Experimental analysis of sample-based maps for long-term SLAM","authors":["Biber, Peter","Duckett, Tom"],"enrichments":{"references":[{"id":18435426,"title":"Concurrent map building and localization in indoor dynamic environments,&quot;","authors":[],"date":"2002","doi":"10.1142\/s0218001402001745","raw":"J. Andrade-Cetto and A. Sanfeliu, \\Concurrent map building and localization in indoor dynamic environments,&quot; International Journal of Pattern Recognition and Arti\u00afcial Intelligence, vol. 16, no. 3, pp. 361{374, 2002.","cites":null},{"id":18435428,"title":"Learning hierachical objects maps of non-stationary environments with mobile robots,&quot;","authors":[],"date":"2002","doi":"10.1109\/irds.2002.1041523","raw":"D. Anguelov, R. Biswas, D. Koller, B. Limketkai, S. Sanner, and S. Thrun, \\Learning hierachical objects maps of non-stationary environments with mobile robots,&quot; in Proceedings of the 17th Annual Conference on Uncertainty in AI (UAI), 2002. 25[3] P. Biber, \\Map building and localization for long-term operation of mobile robots in dynamic environments,&quot; Ph.D. dissertation, Wilhelm-SchickardInstitut, University of T\u00c4 ubingen, Germany, 2007.","cites":null},{"id":18435429,"title":"The normal distributions transform: A new approach to laser scan matching,&quot;","authors":[],"date":"2003","doi":"10.1109\/iros.2003.1249285","raw":"P. Biber and W. Stra\u00bcer, \\The normal distributions transform: A new approach to laser scan matching,&quot; in International Conference on Intelligent Robots and Systems (IROS), 2003.","cites":null},{"id":18435430,"title":"Dynamic maps for long-term operation of mobile service robots,&quot;","authors":[],"date":"2005","doi":null,"raw":"P. Biber and T. Duckett, \\Dynamic maps for long-term operation of mobile service robots,&quot; in Proceedings of Robotics: Science and Systems I, Cambridge, MA, USA, June 8-11 2005.","cites":null},{"id":18435432,"title":"Experiences with an interactive museum tour-guide robot,&quot;","authors":[],"date":"1999","doi":"10.1016\/s0004-3702(99)00070-3","raw":"W. Burgard, A. Cremers, D. Fox, D. H\u00c4 ahnel, G. Lakemeyer, W. Steiner, and S. Thrun, \\Experiences with an interactive museum tour-guide robot,&quot; Arti\u00afcial Intelligence, vol. 114, no. 1-2, pp. 3{55, 1999.","cites":null},{"id":18435434,"title":"Numerical Methods for Unconstrained Optimization and Nonlinear Equations. SIAM Classics in Applied Mathematics,&quot;","authors":[],"date":"1996","doi":"10.1137\/1.9781611971200","raw":"J. Dennis and R. B. Schnabel, \\Numerical Methods for Unconstrained Optimization and Nonlinear Equations. SIAM Classics in Applied Mathematics,&quot; 1996.","cites":null},{"id":18435446,"title":"Pattern Classi\u00afcation.","authors":[],"date":"2001","doi":null,"raw":"R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classi\u00afcation. Wiley, Second Edition 2001.","cites":null},{"id":18435448,"title":"The Adaptive Brain.","authors":[],"date":"1988","doi":"10.1016\/b978-0-444-70414-6.50004-2","raw":"S. Grossberg, The Adaptive Brain. North Holland, 1988.","cites":null},{"id":18435450,"title":"Map building with mobile robots in dynamic environments,&quot; in ICRA,","authors":[],"date":"2003","doi":null,"raw":"D. H\u00c4 ahnel, R. Triebbel, W. Burgard, and S. Thrun, \\Map building with mobile robots in dynamic environments,&quot; in ICRA, 2003.","cites":null},{"id":18435452,"title":"Robust Statistics.","authors":[],"date":"1981","doi":"10.1002\/0471725250","raw":"P. J. Huber, Robust Statistics. New York: Wiley, 1981.","cites":null},{"id":18435454,"title":"Globally consistent range scan alignment for environment mapping,&quot;","authors":[],"date":"1997","doi":null,"raw":"F. Lu and E. Milios, \\Globally consistent range scan alignment for environment mapping,&quot; Autonomous Robots, vol. 4, pp. 333{349, 1997.","cites":null},{"id":18435456,"title":"Mobile robot mapping and localization in non-static environments,&quot;","authors":[],"date":"2005","doi":null,"raw":"C. Stachniss and W. Burgard, \\Mobile robot mapping and localization in non-static environments,&quot; in Proc. of the National Conference on Arti\u00afcial Intelligence (AAAI)&quot;, Pittsburgh, PA, USA, 2005.","cites":null},{"id":18435458,"title":"Reinforcement Learning: An Introduction.","authors":[],"date":"1998","doi":"10.1109\/tnn.1998.712192","raw":"R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction. MIT Press, Cambridge, MA, 1998.","cites":null},{"id":18435460,"title":"MINERVA: A second generation mobile tour-guide robot,&quot; in ICRA,","authors":[],"date":"1999","doi":"10.1109\/robot.1999.770401","raw":"S. Thrun, M. Bennewitz, W. Burgard, A. Cremers, F. Dellaert, D. Fox, D. H\u00c4 ahnel, C. Rosenberg, N. Roy, J. Schulte, and D. Schulz, \\MINERVA: A second generation mobile tour-guide robot,&quot; in ICRA, 1999.","cites":null},{"id":18435462,"title":"Online simultaneous localization and mapping with detection and tracking if moving objects: Theory and results from a ground vehicle in crowded urban areas,&quot; in ICRA,","authors":[],"date":"2003","doi":"10.1109\/robot.2003.1241698","raw":"C.-W. Wang, C. Thorpe, and S. Thrun, \\Online simultaneous localization and mapping with detection and tracking if moving objects: Theory and results from a ground vehicle in crowded urban areas,&quot; in ICRA, 2003.","cites":null},{"id":18435463,"title":"Spatial learning for navigation in dynamic environments,&quot;","authors":[],"date":"1996","doi":"10.1109\/3477.499799","raw":"B. Yamauchi and R. Beer, \\Spatial learning for navigation in dynamic environments,&quot; IEEE Transactions on Systems, Man and Cybernetics, Special Issue of Learning Autonomous Robots, vol. 26, no. 3, pp. 496{505, 1996. 26[18] U. Zimmer, \\Adaptive approaches to basic mobile robot tasks,&quot; Ph.D. dissertation, University of Kaiserslautern, 1995.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2009-08","abstract":"This paper presents a system for long-term SLAM (simultaneous localization and mapping) by mobile service robots and its experimental evaluation in a real dynamic environment. To deal with the stability-plasticity dilemma (the trade-off between adaptation to new patterns and preservation of old patterns), the environment is represented at multiple timescales simultaneously (5 in our experiments). A sample-based representation is\\ud\nproposed, where older memories fade at different rates depending on the timescale, and robust statistics are used to interpret the samples. The dynamics of this representation are analysed in a five week experiment, measuring the relative influence of short- and long-term memories over time, and further demonstrating the robustness of the approach","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/55405.pdf","fullTextIdentifier":"http:\/\/eprints.lincoln.ac.uk\/2095\/1\/Biber-Duckett-IJRR-2009.pdf","pdfHashValue":"6bf6f9a4ebc013fd7e5308f3a926cb6d83b00d49","publisher":"SAGE","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lincoln.ac.uk:2095<\/identifier><datestamp>\n      2013-12-04T16:07:29Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D6A6163735F47:6A6163735F47373030<\/setSpec><setSpec>\n      74797065733D61727469636C65<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:relation>\n    \n      \n        http:\/\/eprints.lincoln.ac.uk\/2095\/<\/dc:relation><dc:title>\n        Experimental analysis of sample-based maps for long-term SLAM<\/dc:title><dc:creator>\n        Biber, Peter<\/dc:creator><dc:creator>\n        Duckett, Tom<\/dc:creator><dc:subject>\n        G700 Artificial Intelligence<\/dc:subject><dc:description>\n        This paper presents a system for long-term SLAM (simultaneous localization and mapping) by mobile service robots and its experimental evaluation in a real dynamic environment. To deal with the stability-plasticity dilemma (the trade-off between adaptation to new patterns and preservation of old patterns), the environment is represented at multiple timescales simultaneously (5 in our experiments). A sample-based representation is\\ud\nproposed, where older memories fade at different rates depending on the timescale, and robust statistics are used to interpret the samples. The dynamics of this representation are analysed in a five week experiment, measuring the relative influence of short- and long-term memories over time, and further demonstrating the robustness of the approach.<\/dc:description><dc:publisher>\n        SAGE<\/dc:publisher><dc:date>\n        2009-08<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:language>\n        en<\/dc:language><dc:identifier>\n        http:\/\/eprints.lincoln.ac.uk\/2095\/1\/Biber-Duckett-IJRR-2009.pdf<\/dc:identifier><dc:identifier>\n          Biber, Peter and Duckett, Tom  (2009) Experimental analysis of sample-based maps for long-term SLAM.  International Journal of Robotics Research, 28  (1).   pp. 20-33.  ISSN 0278-3649  <\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1177\/0278364908096286<\/dc:relation><dc:relation>\n        10.1177\/0278364908096286<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/eprints.lincoln.ac.uk\/2095\/","http:\/\/dx.doi.org\/10.1177\/0278364908096286","10.1177\/0278364908096286"],"year":2009,"topics":["G700 Artificial Intelligence"],"subject":["Article","PeerReviewed"],"fullText":"Experimental Analysis of Sample-Based\nMaps for Long-Term SLAM\nPeter Biber1 and Tom Duckett2\n1Dept. of Computer Science, WSI-GRIS\nUniversity of Tu\u00a8bingen\nTu\u00a8bingen, Germany\nEmail: biber@wsi-gris.uni-tuebingen.de\n2Dept. of Computing and Informatics\nUniversity of Lincoln\nLincoln LN6 7TS, UK\nEmail: tduckett@lincoln.ac.uk\nMarch 17, 2008\nAbstract\nThis paper presents a system for long-term SLAM (simultaneous local-\nization and mapping) by mobile service robots and its experimental evalu-\nation in a real dynamic environment. To deal with the stability-plasticity\ndilemma (the trade-off between adaptation to new patterns and preserva-\ntion of old patterns), the environment is represented at multiple timescales\nsimultaneously (5 in our experiments). A sample-based representation is\nproposed, where older memories fade at different rates depending on the\ntimescale, and robust statistics are used to interpret the samples. The\ndynamics of this representation are analysed in a five week experiment,\nmeasuring the relative influence of short- and long-term memories over\ntime, and further demonstrating the robustness of the approach.\n1 Introduction\nFuture service robots will be required to run autonomously in dynamic envi-\nronments for really long periods of time. These robots will be required to live\ntogether with people and adapt to the changes that people make to the world.\nThe first excursion of a mobile service robot in a new environment will prob-\nably be guided by a human or other intelligent system, for example, to explain\nthe meaning of different places, as a human employee would be introduced to\n1\na new workplace. A basic problem for the robot here is static SLAM: simulta-\nneous localization and mapping given one set of data. Most previous work on\nrobotic map learning addresses this problem. However, this phase will only be\na short moment in the lifetime of a service robot that is expected to operate\nfor years. For a robot to survive in a dynamic and ever-changing world, lifelong\nlearning is essential.\nThis paper addresses the problem of long-term SLAM: simultaneous localiza-\ntion and mapping in dynamic environments over possibly unlimited periods of\ntime. A major challenge for long-term SLAM is that environments can change\nat different rates, and the changes can be gradual or abrupt. Changes may not\nbe permanent: an object may have been moved, a package may have been left\nfor a while, etc. It is therefore desirable for the robot to remember the old\nstate too in case the change is only temporary. At the same time, there may\nbe slow but inexorable changes such as plants growing or coloured paint fading.\nThis challenge is related to a more general and well-known problem confronting\nevery lifelong learning system, namely the stability-plasticity dilemma described\nby Grossberg [9]. Lifelong learning demands both adaption to new patterns and\npreservation of old patterns at the same time.\nThis work makes several contributions:\n\u2022 We propose sample-based maps for mobile robots, using the sensor data\nthemselves as primitives of the representation (\u201cusing the data as its own\nbest model\u201d). A novel representation based on dynamic sample sets en-\nables adaptation of the map in a changing world. We show that this rep-\nresentation has a well-defined semantics and a probabilistic interpretation\nusing robust statistics.\n\u2022 To deal with the stability-plasticity dilemma, we propose simultaneous\nrepresentation of the world at multiple timescales, using multiple maps\nwith a spectrum of learning rates. This allows the robot to maintain mul-\ntiple hypotheses in time about the state of the environment, for example,\nrepresenting the world before, during and after a temporary object is left\nin a particular place.\n\u2022 Based on these concepts, a complete system for long-term SLAM is pre-\nsented. During localization the robot compares its current sensor data\nto all timescales in the map and chooses the timescale that best fits the\ndata. In turn, the results of localization are used directly to adapt the\nmap. Consequently localization is more robust and the map does not go\nout of date.\nFurther to our previously published results [5], this paper analyses the dy-\nnamics of the map representation in a long-term experiment using sensor data\nrecorded by a mobile robot in a busy indoor environment over a period of five\nweeks. We measure the relative influence of short-term and longer-term memo-\nries over time, and further demonstrate the long-term stability and performance\nof the approach.\n2\n1.1 Related work\nTraditional mapping and localization algorithms model the world as being static\nand try at most to detect and filter out moving objects such as people. Previous\napproaches to robotic mapping of dynamic environments can be grouped into\nthree categories.\nFirst, some approaches attempt to discriminate \u201cdynamic\u201d from \u201cstatic\u201d\nelements of the environment [6, 15, 16, 10]. For example, the RHINO tour guide\nrobot [6] used an entropy filter to separate sensor readings corresponding to\nknown objects such as walls from readings caused by dynamic obstacles such as\npeople. A fixed pre-installed map was used for localization, while an occupancy\ngrid was built on the fly to model dynamic objects and combined with the static\nmap for path planning. However, in general, this approach cannot handle long-\nterm changes to the environment. By contrast our work uses a spectrum of\nlearning rates to handle changes occurring at different timescales.\nSecond, several authors have investigated aging of the map using some form\nof recency weighted averaging. Zimmer [18] presented a system that dynami-\ncally learns and updates the topology of a map during runtime and showed the\nability of his model to adapt to changes. Yamauchi and Beer [17] developed a\nso-called adaptive place network, where a confidence value for each link in the\nnetwork was updated in a recency-based manner based on successful or non-\nunsuccessful attempts to traverse the link, and links with low confidence were\ndeleted. Andrade-Cetto and Senafeliu [1] developed an EKF-based map learn-\ning system that is able to forget landmarks that have disappeared, where an\nexistence state associated with each landmark measures how often it has been\nseen.\nThird, some authors propose richer world models, e.g. with semantics based\non explicit identification of objects. Anguelov et al. [2] divide the environment\ninto a static part and objects that can move such as chairs. However, these\nefforts are decoupled from map building and localization, and it is assumed that\nthese parts work independently and perfectly. The aim of Anguelov\u2019s work is\nmore on obtaining one higher level map, and not to adapt the map continuously\nas in this work. Stachniss and Burgard [13] proposed an approach to modeling\ndynamic environments by representing typical configurations or possible states\nin a local area, e.g. corresponding to open and closed doors. In our experiments,\nhowever, we found that such repeated configurations were rare compared to\nunexpected changes: most of the changes in our environment resulted in new\nconfigurations that had not been seen before.\nIn contrast to all these systems our dynamic map addresses the stability-\nplasticity dilemma. We do not consider autonomous navigation or topological\nchanges, rather our focus is on seeing self-localization and map learning as a\nnever-ending cycle.\n3\n\u0000\u0000\n\u0000\nFigure 1: A simple example environment. After some time a cupboard is put in\nfront of one wall, and some time later it is removed. The example map consists\nonly of the distance d.\n2 Motivation for Sample-Based Maps\nTo motivate the map representations proposed in this paper a simple toy en-\nvironment is considered as shown in Fig. 1. The example environment is an\nempty room and the map to be learned is the distance from an arbitrary point\nto the nearest wall or object in a given direction. If the environment were static\nthen learning would be simple: all deviations from the true value would be due\nto Gaussian measurement noise, and therefore the map would be perfectly rep-\nresented by the sample mean and sample variance. For stationary distributions\nthese statistics are sufficient (Duda et al. [8], chapter 3.6), i.e. they store the\ninformation content of all measurements, and it is not necessary to keep past\nmeasurements in memory.\nAssume now that the environment is dynamic. After some time somebody\nputs a cupboard in front of the wall. The above method is not well-suited to\nthis challenge. The time needed for the sample mean to approach the new true\nvalue would be proportional to the time spent measuring the wall in the old\nposition. Such behaviour is not desired.\nRequirement 1: The time taken by the map to adapt to a change should not\ndepend on how much time has passed in absolute terms. Also, the initial state\nshould have no special status or rank.\nRecency weighted averaging is a solution to this problem from the field of\nreinforcement learning that is especially suited to non-stationary tracking prob-\nlems (Sutton and Barto [14], chapter 2.6). Here the estimate for the distance d\nis updated after a new measurement according to:\ndnew = (1\u2212 \u03b1) \u2217 dold + \u03b1 \u2217 dmeasured (1)\nEffectively this methods calculates a weighted sample average. The weight wt\n4\nof a sample is thus dependent on its age t as\nwt = \u03b1 \u2217 e\u2212\u03bbt with \u03bb = \u2212 ln(1\u2212 \u03b1), (2)\nassuming that measurements are made at regular intervals. So the influence\nof old measurements decays according to a well-known law that governs many\ngrowing and decaying processes in nature, where a parameter \u03bb determines the\nspeed of adaption or learning rate.\nImagine that the cupboard is removed after a few days. If \u03bb is small (e.g.\n1 year\u22121) only a small change in the map will occur. On the other hand for\nlarge \u03bbs (e.g. 1 s\u22121) the map will converge to the new value immediately. In the\nfirst case the cupboard can be seen as an outlier and the quality of the distance\nestimate to the wall should not get worse. This reminds us of the notorious\nproblem that statistics derived from least square formulations are not robust to\noutliers.\nRequirement 2: Map learning should be robust to outliers.\nThe proposed solution of a sample-based representation can also be justified\nby another observation that lies in the nature of the problem: actual changes\nin the environment appear in the first instance as outliers. At the moment a\nmeasurement is made it is not possible to determine whether it is an outlier or\nnot. Only after more time has passed and more measurements have been made\ncan outliers be identified. Therefore any method that tries to identify outliers\nimmediately after measurement is, in principle, not well-suited to map learning\nin dynamic environments.\nRequirement 3: The map representation should be able to track multiple hy-\npotheses until it can be determined whether a change has really happened or\nonly outliers were measured.\nThus any method that represents the environment by a unimodal distribution\ncannot be considered an adequate solution.\nOutliers aside, there is a further problem with recency weighted averaging:\nduring learning in the example scenario the distance estimate would change\ngradually from \u201cwall\u201d to \u201ccupboard\u201d, but none of these in-between estimates\nwould correspond to any physical reality. In contrast to many other dynamic\nprocesses, the environmental changes considered here are not necessarily contin-\nuous but more often discrete and rapid. In the example it would be more natural\nfor the estimate to represent either the distance to the wall or the distance to\nthe cupboard.\nRequirement 4: The map should yield only values that have actually been\nmeasured and should not create interpolated values that do not correspond to\nany past or current reality.\nThe following section describes the map representation developed in order\nto meet these requirements.\n5\n3 Sample-based representation\nThe classical answer to the above requirements is to apply robust statistics [11].\nThe median of a set of samples fulfils requests 2 (it ignores up to 50 percent\nof outliers) and 4. But there are no sufficient statistics to describe the median.\nSufficient statistics preserve the information content of the whole data set, so\nthe data itself can be discarded. But to calculate robust statistics we always\nneed a full set of data. It is of course impossible to save all data ever recorded.\nOur solution here is a sample-based representation: we maintain a set of sam-\nples drawn from the data that approximates all recent data, thus also fulfilling\nrequirements 1 and 3.\n3.1 Dynamic sample sets\nThe state of the map is represented at discrete time steps ti. The basic repre-\nsentation of the dynamic map is a set S(ti) of n samples. A sample is just a\nmeasurement that has been recorded before time step ti. A sample set is a func-\ntion of time and is therefore the central concept that makes the map dynamic.\nIts temporal evolution is calculated using an update rule and measurements.\nLet M be the set of measurements that have been made between two sub-\nsequent time steps ti and ti+1. S(ti+1) is then calculated by an update rule\ndependent on an update rate 0 \u2264 u \u2264 1 as follows:\n\u2022 Remove u \u2217 n randomly chosen samples from S(ti).\n\u2022 Replace them by u \u2217 n randomly chosen samples from M to get S(ti+1).\nThis algorithm is applied if the sample set is already full (that is, it contains\nthe maximum number n of samples). Initially a sample set is empty and until\nit is full an update just consists of adding u \u2217 n randomly chosen samples.\n3.2 Semantics of a sample set\nLet s be a sample that has been added at time step ti. The probability that a\nrandomly chosen sample from the sample set S(ti) has just been added like s\nis u \u2217 n\/n = u. In each subsequent time step the probability of s remaining in\nthe sample set is given by 1 \u2212 u. So at time step tj > ti the probability for s\nto be still in S(tj) is given by (1 \u2212 u)(tj\u2212ti). Thus we can make the following\nstatement about the distribution of ages in a sample set:\nAt any time the probability for a sample to have been added to the sample\nset t time steps before is given by:\np(t) = u \u2217 eln(1\u2212u)\u2217t (3)\nThus the age of the samples is distributed just like the weights in recency\nweighted averaging. The distribution is dependent on a timescale parameter\n\u03bb = \u2212 ln(1\u2212 u), and has the following well-known properties: the mean life\n6\ntime \u03c4 of a sample is given by: \u03c4 = \u03bb\u22121, and the half-life is given by t1\/2 = ln 2\u03bb .\nThis means that one half of the sample set is expected to be younger than the\nhalf-life and the other half older.\n3.3 Probabilistic interpretation of a sample set\nTo actually use the map at a time step t a normal distribution N (\u03c1, \u03c32) can\nbe robustly estimated from the samples using the median and the median of\nabsolute deviations:\n\u03c1\u02c6 = median(S(t)) (4)\n\u03c3\u02c6 = 1.48 median(|x\u2212 \u03c1\u02c6|, x \u2208 S(t)) (5)\nAdditionally an outlier ratio can be estimated by declaring all samples within\nan interval of 3\u03c3 around \u03c1 as inliers (99.7 % confidence level) and all others as\noutliers.\nThe representation and interpretation of a dynamic sample set are thus\nseparated. This allows use of the map by techniques with simple low-dimensional\nmeasurement models like the unimodal model applied here. In our application\nthis model is used for localization, so the localization module need not worry\nabout more complicated multimodal probability density functions. But full\ninformation about the distribution of the map data is retained in the sample\nset, where it is really needed to represent multiple hypotheses.\n3.4 Representation using multiple timescales\nThe obvious question at this point is \u201cwhich timescale to choose?\u201d As with\nspatial filtering the answer is \u201cit depends.\u201d For the above toy example it may\nbe useful to maintain two estimates, a more long-term one and a more short-term\none. Accordingly, we propose to maintain the dynamic map simultaneously for\nseveral timescale parameters to cover the whole spectrum of possible changes.\nIn this context the relationship of the timescale parameter to actual time\nshould also be discussed. In the toy example the sensor is stationary and samples\nat regular intervals. It is therefore easy to relate update ratios to hours or days.\nFor an arbitrarily moving robot the situation is different. It cannot be said how\nlong it will stay in a room or whether it will return to the same room in the same\nday. To relate an update ratio to the absolute time, we must wait in the order of\nthe timescale to know how many measurements have been recorded during that\ntime. Only then can samples be picked from the measurements according to the\nupdate ratio. Accordingly in our system the large timescale maps are updated\nonly after a run or once a day and are called long-term memory maps. There is\nalso a short-term memory map that is updated after each sensor reading. This\nmap is characterized by a short half-life, short enough that the assumption of\nregular sampling is valid as long as the robot stays within a certain area.\nAs discussed in the introduction, simultaneous tracking of different timescales\nis intended to tackle the stability-plasticity dilemma. Each timescale corre-\nsponds to a position on an imaginary stability-plasticity scale. Maintaining\n7\nseveral timescales simultaneously is thus a way to be everywhere on that scale\nat the same time, allowing a map both to preserve old patterns and to adapt to\nnew patterns.\n3.5 Simulation of the toy example\nThe behaviour of a sample-based dynamic map is demonstrated and compared\nto recency-weighted averaging in a simulation of the toy example.\nIn this simulation the distance to the wall is 2 meters and the distance to\nthe cupboard 1 meter. Measurements are simulated assuming normal noise\nwith a standard deviation of 10 cm. At time t = 10 the cupboard is placed in\nfront of the wall and at time t = 20 it is removed. Between two time-steps 20\nmeasurements are made. The sample set consists of 20 samples and is initialized\nusing the measurements of the first time-step. The recency-weighted estimate is\ninitialized by the mean of these first 20 measurements. The algorithm is tested\nusing three different update ratios: u = 0.75, u = 0.25 and u = 0.05. The\nupdate of the sample set takes place after each time-step. The recency-weighted\naverage is updated directly after each measurement; the step-size parameter \u03b1\nis determined to correspond to the respective update ratio.\nFig. 2 shows the results of both algorithms. Recency weighted averaging\nappears to work well for large update rates like u = 0.75 when old samples are\nforgotten rapidly. For smaller values of u it interpolates as expected towards\nthe new value and introduces values that have never been measured. After the\ncupboard has been placed against the wall, the estimate using the smallest u\n(corresponding to a large timescale) is practically useless, since it represents\nneither of the two objects for the whole considered time.\nThe behaviour of the sample-based dynamic map mirrors our requests much\nbetter. The estimates for u = 0.75 and u = 0.25 switch almost during one\ntime step from the wall to the cupboard and vice versa, where the values of u\ndetermine the delay for that switch. The long-term component is unaffected by\nthe events, since the period during which the cupboard appeared was too short\nfor it to be registered.\nNote that the above toy example assumed that the position of the robot\nis exactly the same during updates to the map. In practice, in a real SLAM\nscenario the position of the robot will vary between visits to the same mapped\nlocation. Therefore it is necessary to project observations (laser scans) to the\nsame local coordinate system before updates are carried out: this aspect is\ndescribed in Section 4.1.\n4 A complete system for long-term SLAM\nThis section describes the localization and mapping system developed using\nthe above map representation. The learning system and the representation of\nthe map is exactly as described in the toy example. Around it a localization\nand mapping system for a real robot equipped with laser range scanner and\n8\n\u0000 \u0001\u0000 \u0002\u0000 \u0003\u0000\n\u0001\u0000\u0000\n\u0002\u0000\u0000\n\u0004\u0005\n\u0006\u0007\n\b\t \n\n\u000b \f\n\r\u000e\n\u000f\n\u0010\n\u000e\n\u0011\n\u0012\n\u0013\n\u0007\u0014\u0007\u0015\u0014\n\u0016\u0017\n\u0007\n\u0005\u0018\u0019\u0004\n\u0007\u001a ff\nfi\n\u0007flff\n\u0018\u0005\n\u0015\n\u0018\nffi\n\u001f\n\u0000\n !\n\"\nffi\n\u001f\n\u0000\n \n\u0002\n\"\nffi\n\u001f\n\u0000\n \n\u0000\n\"\n#\nffi$\n%\n&fffl\u001a ff\u001a\u001a\u0007\u001a\n#\nffi$\n%\n&fffl\u001a fl\u0007\u0006&\nfi\n\u0007\u001a\n\u0000 \u0001\u0000 \u0002\u0000 \u0003\u0000\n\u0001\u0000\u0000\n\u0002\u0000\u0000\n\u0004\u0005\n\u0006\u0007\n\b\t \n\n\u000b \f\n\r\u000e\n\u000f\n\u0010\n\u000e\n\u0011\n\u0012\n\u0013\n\u0007\u0014\n\u0005\n\u0015\u0016 \u0017\u0018 \u0019\u0007\u001a\u0007\u0016\u001aff fi\u0015\u0006flffi\u0007\u0014 fi\u0015\u0006flffi\u0007 fi\u0007\n\u0004\n\u001f \n\u0000 !\n\"#\n\u001f \n\u0000 !\u0002\n#\n\u001f \n\u0000 !\u0000\n#\n$%\n&\n'(\n)*+ )++,+\n$%\n&\n'(\n)*+ *,-\n(\n.\n,+\nFigure 2: Using recency weighted averaging on toy example (top) and sample-\nbased dynamic map (bottom) for three different timescales.\n9\n\u0000\u0001\u0002 \u0001\n\u0003\u0004\u0003\n\u0005\n\u0006 \u0007\n\b\t\n\n\u0003\n\u000b\n\f\r\u0005\u000e\u000f \u0005\n\u0010\n\u0005\n\u0003\n\u0005\n\u0004\n\u000e \u0011\n\u0004\u0012\n\u0007\n\u0013\n\u000b\u0014\n\u0003\n\u0015\n\u0016\u0002\n\u0014\n\u0011 \n\u0002\u0011\n\u000b\u0014\n\u0017\n\u0018\n\u000e\n\u000b\u0006\n\u0004\n\u000e \u0011\n\u0004\u0012\n\u0001\u0019\n\b\n\u000b\u0010\u001a\n\u0015\n\u0016\u0002\n\u0014\n\u0011 \n\u0002\u0011\n\u000b\u0014\n\u0017\n\u0018\n\u000e\n\u000b\u0006\n\u0004\n\u000e \u0011\n\u0004\u0012\n\u0001\u0019\n\u000e\n\u000b\u0006\n\u0004\n\u000e \u0011\n\u0004\u0012\n\u0001 ff\n\u001a\n\u000e\n\u000b\n\f\n\u0004\n\u000e\n\u0012\n\u000b\n\u0001\u0005\n\u0003\n\u0005\n\u000b\u0010\n\u0001\nFigure 3: An overview of the whole localization and learning system. The\ndynamic map is both updated online during a run and offline after each run.\n10\nodometry has been built that has been shown to work robustly in extensive\nlong-term experiments.\nThe data flow of the whole system is depicted in Fig. 3. First, an initial map\nis built from the first run through the new environment. This map is build by\na classical static SLAM algorithm using laser scans and odometry as input and\nis based on scan matching [4]. The output is a set of selected laser scans with\nrelations between them [12]. These laser scans form the initial set of local maps.\nFor localization the robot selects local maps near to its current position. One\ntimescale within each local map is selected in a data-driven way: the timescale\nis selected that best explains the sensor data according to its learned perceptual\nmodel. The selected local maps are then converted into a point set called the\ncurrent map and the current laser scan is then matched to this current map.\nOdometry information is used as a prior and as a bound to ensure robustness\nof matching.\nAfter each localization step the short-term maps are updated online. The\nlong-term maps are updated offline after each robot run or after each day. The\nupdate processes the data in a run based on the estimated robot trajectory.\nPre-processing of the sensor data before map updating includes conversion of\nlaser observations to the local coordinate systems of the nearby local maps. In\nthe following subsections we provide technical details of the representation, local\nmap selection, self-localization using scan matching, and learning.\n4.1 Local maps\nIn our approach a local map is a generalization of a laser range scan and is\nlinked to the global map by a position in global coordinates (see Fig. 4). A local\nmap stores several sub-maps each corresponding to a different timescale. Each\nsub-map is like a 360 degree range scan from a constant position or reference\npoint: it quantizes the continuous space of emanating rays from that position\ninto a number of discrete bins. Finally each ray maintains a set of range val-\nues, corresponding to measured distances to objects, using the sample-based\nrepresentation described in Section 3.\nTo use this representation in an actual SLAM implementation, it is necessary\nto project laser measurements from nearby positions (using the vehicle pose\nestimates from self-localization) to one position (i.e. the centre of the local\nmap) and obtain all observations (rays) from there. An arbitrary 2-D point is\nmapped to a ray number and range value by finding the closest ray and taking\nthe distance from the position of the local map to that point as the range value.\nThis definition allows the representation of a local map by a one-dimensional\nparameterization. Observations recorded near to a local map\u2019s position can be\neasily converted into this representation and the learning scheme introduced\nwith the toy example can then be applied.\nTable 1 shows the different timescales used in our experiments. The number\nof timescales and their properties were chosen according to the following consid-\nerations: short-term memory should react quickly to changes, so only a few data\nsamples should be enough. Therefore the number of samples per ray should be\n11\np i \u0001 k d ,d ,...1 2\nLocal\nMaps\nTime-\nScales\nSamples\n... ... ...\n... ... ...\nGlobal\nPositions\n\u0002 j\nRays\nAnglesUpdate\npolicies\/\nratios\nDistance\nvalues\n...\n...\nFigure 4: Internal map representation. The dynamic map consists of a set of\nlocal maps. Each local map maintains several sub-maps representing different\ntimescale parameters. Each sub-map is represented by a set of samples for each\nangle.\n12\nsmall and the update ratio high. This, in turn, entails a relatively low accuracy.\nBy contrast, long-term memory should not react to temporary variations, and\nadapt only if something has changed consistently. At the same time the static\nparts of the environment should be modeled with increased accuracy. This is\nachieved by decreasing the update ratio and increasing both the spatial reso-\nlution (number of rays per degree) and number of samples for the longer-term\ntimescales. The use of robust statistics in combination with the large number\nof samples then provides both accuracy and robustness against outliers.\n4.2 Perceptual model for local map selection\nThe sample sets are used to derive a perceptual model for the sensor input, that\nis to estimate the probability of a laser scan given a pose and a local map at a\ncertain timescale (i.e., a set of samples). As outlined in Section 3.1 we derive a\nmixture model from the sample set. The probability of a range value measured\nat the position of a local map for any ray is estimated as\np(d) = (1\u2212 poutlier)pnormal(d) + poutlier \u2217 puniform(d), (6)\nwhere\npnormal \u223c N (\u03c1, \u03c32) (7)\npuniform \u223c U(0,maxRange) (8)\nThat is, pnormal is normally distributed and puniform uniformly distributed\nwith parameters and mixture factor determined as in Section 3.3 from the sam-\nples of the ray considered (see Fig. 5). The log-likelihood of a whole scan is\ncalculated by adding the logarithms of p for each range scan reading. To cal-\nculate the likelihood of a scan taken near the position of a local map the scan\nreadings are transformed as if taken from that position.\n4.3 Localization\nThe localization algorithm tracks the position of the robot over time. There\nis always only one single estimate for the robot\u2019s position and it is assumed\nthat the starting position is known. The problem of global localization or robot\nkidnapping is not addressed here.\nA single localization step consists of two main parts. A point set called\nthe current map is synthesized by selecting those timescales that best fit the\ndata according to the perceptual model and the current position estimate. The\ncurrent map is then used to localize the robot at the next time step based on a\nscan matching scheme that incorporates odometry information [3]. After scan\nmatching, a new current map is built using the resulting position estimate and\nso on. The central interaction between map and localization occurs here: the\nsensor data is used to select the most likely model of the current environment\nfrom the available timescales.\n13\n5 4 3 2 1 0 1 2 3 4 5\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\nx\np(x\n)\nFigure 5: The perceptual model used to a interpret a sample set: a mixture of a\nnormal distribution and an uniformly distributed outlier distribution (Gaus-\nsian+Offset). The model is determined by the mean \u03c1 and variance \u03c3 of\nthe Gaussian, the mixture weight (that is, the estimated outlier ratio) and a\nbounded domain (the compact support) for the outlier distribution. The result-\ning model is shown here for \u03c1 = 0, \u03c3 = 1 and [\u22125..5] as support. For the laser\nscanner the bounded domain is [0..maxRange] where maxRange is the maximum\nrange of the laser scanner that is considered to be a valid measurement.\n14\nFor a more formal description the following notation is used in the remainder:\nx\u02c6t is the posterior estimate of the robot\u2019s pose (x, y, \u03c6) and x\u02c6\u2212t is the prior\nestimate at time t. The laser measurements at time step t are denoted by zt.\nThe current map for time t + 1 is built after the posterior estimate x\u02c6t has\nbeen calculated, using the following steps:\n1. Local maps within a pre-specified Euclidean distance (4 meters in our\nexperiments) of the robot\u2019s pose x\u02c6t are determined to form the set of\nnearby local maps.\n2. For all local maps in the set of nearby local maps and for all timescales:\ncalculate log-likelihood according to the perceptual model for range scan\nzt.\n3. Select the local map timescale with best log-likelihood and add it to the\nset of current local maps. The chosen timescale is marked as selected in\nthat local map and the local map is removed from the set of nearby local\nmaps.\n4. Remove those range readings from zt that have a high likelihood according\nto the selected model. A threshold is used here.\n5. Go to 2 until the number of range readings in zt is larger than a pre-\nspecified size (20 in our experiments) and the set of nearby local maps is\nnot empty.\n6. Transform the selected local maps into a set of points, using the median\nas a range value. Only readings with an estimated variance no larger than\na threshold (5 cm in our experiments) are converted to points.\nIf after this process more than half of the range scan readings have a low\nlikelihood (same threshold as in step 4), the system switches into a safe mode,\nwhere all nearby local maps with the most long-term timescale are used to derive\nthe current map. If this happens the localization algorithm may have lost its\nposition or the environment may have changed too much to be represented\naccurately by any of the timescales. Using long-term maps in such situations is\na safe fallback as they will be affected much less by temporary localization errors\nthan the short-term memory maps (because they have the greater plasticity).\nThe choice of long-term maps in such situations can also be motivated by the\nfact that they have lower learning rates. Since higher learning values tend to\nresult in faster learning but greater later variability and thus lower long-term\nperformance, small learning rates promise the best long-term performance [14].\nIn our experiments this mode was activated in approximately 0.5 percent of all\ncases.\nThe actual localization step then uses this current map in an approach that\nfuses scan matching and odometry. After the current map is built the prior\nestimate x\u02c6\u2212t+1 is obtained by projecting forward the old posterior estimate x\u02c6t\naccording to the odometry. The uncertainty of the odometry prediction is given\n15\nby a covariance matrix that was acquired experimentally in this work. Scan\nmatching is then performed by minimizing an energy function ES as described\nin [4]. The a priori estimate x\u02c6\u2212t+1 and its estimated uncertainty (given by the\ncovariance matrix) is incorporated as a prior EO. This odometry prior is defined\nas EO(x) = (x\u2212 x\u02c6\u2212t+1)tC\u22121O (x\u2212 x\u02c6\u2212t+1), where CO is the covariance matrix of the\nodometry estimate. So finally a term\nES + \u03ba \u2217 EO (9)\nis minimized.\nInstead of determining a constant value for \u03ba we employ an adaptive scheme\nfor the following reason: In most cases the result from scan matching is so much\nmore exact than odometry that incorporation of the prior EO would only worsen\nthe result, as is confirmed by the relation between the covariance matrices of\nscan matching and odometry. But, scan matching could also converge to a\nwrong solution (for example, it could match two doors with different opening\nangles instead of matching the walls if the robot is very close to the door).\nSuch a case would also result in a well-conditioned covariance matrix. So the\nuncertainty of the scan matching result is not described well by the unimodal\nGaussian associated with the covariance matrix for such cases. In conclusion it\ncan be said that the scan match estimate is very accurate but can converge to\nthe wrong solution. On the other hand the odometry is not very accurate but\nthe description of its uncertainty by a covariance matrix models the reality well\nover the short distances considered here.\nThe sensor fusion scheme we use therefore forces the scan matching algo-\nrithm to converge to a solution within a region given by the uncertainty of the\nodometry as follows:\n1. Set \u03ba = 0.\n2. Minimize ES + \u03ba \u2217 EO.\n3. If result within two standard deviations according to odometry then finish.\n4. \u03ba = \u03ba \u2217 2 and goto 2.\nThis scheme is reminiscent of the Levenberg-Marquardt algorithm (e.g. [7])\nand was indeed inspired by it.\n4.4 Learning: online and offline updates\nAgain, Table 1 shows the different timescales used in our experiments. The\nshort-term memory map (\u03bb1) is updated after each localization step. All local\nmaps whose centres are near (< 2.5 m) to the current position are considered\nfor update. The range-finder readings are converted to polar coordinates, as\ndescribed in Section 4.1, and then used to update the sample sets of the local\nmaps, as described in Section 3.1. The robust estimates for the perceptual model\nparameters are then updated online. If there is no local map within 2.5 m of the\n16\nUpdate ratio (u) Timescale (t1\/2) nRays nSamples\n\/interval (t1\/2)\n\u03bb1 0.2 \/ always \u2248 3.1 360 5\n\u03bb2 0.8 \/ per run \u2248 0.43 runs 360 10\n\u03bb3 0.8 \/ daily \u2248 0.43 days 720 50\n\u03bb4 0.2 \/ daily \u2248 3.1 days 1440 100\n\u03bb5 0.05 \/ daily \u2248 13.5 days 1440 100\nTable 1: The different timescales of the sub-maps contained in one local map.\n\u03bb1 is the short-term memory map, \u03bb2-\u03bb5 are the long-term memory maps. The\nhalf-life for \u03bb1 is given in terms of the sensor\u2019s scanning frequency, that is 3.1\nis the time needed to record 3.1 laser scans.\ncurrent position estimate, then a new local map is added at that position and\ninitialized using the values of the current scan. For the long-term memory maps\n(\u03bb2-\u03bb5) the information (triples of local map, range scan and pose estimate) is\nstored and evaluated offline after a run (\u03bb2) or after a day (\u03bb3-\u03bb5), as indicated\nin the table, but with exactly the same method otherwise.\n5 Experimental evaluation\n5.1 Experimental Setup\nThe complete map learning system was tested extensively in an indoor envi-\nronment consisting of a robotics laboratory with three rooms, a corridor with\nPh.D. students\u2019 offices and a hallway containing stairs, chairs and tables. Over\na period of five weeks the robot was steered manually through this environment\nfrom a constant start position. Typically three runs per day were performed;\none in the morning, one after lunch and one in the early evening. A SICK LMS\n200 laser scanner was used, and a total of around 100000 laser scans together\nwith odometry data were recorded in 75 runs with a total distance of 9.6 km.\nThe environment was not prepared in any way nor were people instructed some-\nhow (that would have been impossible due to the heavy traffic of students in\nthe hallway especially around lunchtime). The initial map built by the static\nSLAM algorithm comprising 76 local maps is shown in Fig. 6. Over 90 local\nmaps were used in total, since the number of local map grows with time as new\nareas are visited, as described in Section 4.4. Referring to Table 1, each local\nmap in our chosen representation needs to store 329 400 samples, meaning a\ntotal memory requirement of around 0.63 MB per local map if two bytes are\nused per sample, or approximately 60 MB in total for our setup.\n17\nFigure 6: The initial map of the environment (obtained by a static SLAM\napproach) in which the experiment was conducted. The filled circles mark the\npositions of local maps.\n18\n5.2 Qualitative results\nThe most important result is that the dynamic map was stable over time and did\nnot diverge. The accuracy of its local maps increased over time; this could be\nverified visually, for example, by looking at the straightness of walls. In parts of\nthe environment where changes often occur, static parts like walls emerge while\nmoving objects like chairs that could be observed in the initial map disappear.\nThis could be observed, for example, in the robot lab. Figure 7 shows the most\nlong term map (\u03bb5) of the middle room of the lab on three different days (Oct\n18, Nov 1 and Nov 19) along with the local map that is updated after each run\n(\u03bb2) on Nov 19. It can be seen that the static aspects improve, although on\nNov 19, for example, the lab looks quite different in some parts, as can be seen\non the rightmost map. For visualization only points are shown for which the\nprobabilistic model yields a standard deviation estimate smaller than 10 cm.\nMajor structural changes happened rarely as one might expect in this kind\nof environment, but one such change and the reaction of the dynamic map is\nshown in Figs. 8 and 9. Another structural change was the installation of new\nradiators in the hallway where some tables were also moved. Many changes on\na smaller timescale (a few days or less) occurred frequently in the robotics lab,\nwhere movable \u201cwalls\u201d and other robots often appeared at different positions as\nother researchers performed their experiments. Other frequent changes occurred\nin the hallway, e.g. chairs were often moved. These challenges were handled well\nby the dynamic map, with the short-term map adapting quickly to the changes.\nOct 18 \/ \u03bb5 Nov 1 \/ \u03bb5 Nov 19 \/ \u03bb5 Nov 19\/ \u03bb2\nFigure 7: The most long-term submaps (\u03bb5 in Table 1) of an example local\nmap (the middle room of the robot lab). The circle marks the centre of the\nlocal map. It can be seen that static aspects improve over time, although the\nenvironment sometimes looks quite different, e.g. on the last day as can be seen\nin the rightmost submap (which is a local map with a small half time, \u03bb2 in\nTable 1)\n5.3 Quantitative performance measures\nWhile these results may be satisfying enough from a theoretical point of view,\na practitioner may still doubt whether such a technology is really needed, as\n19\nFigure 8: A major change occurred on day 4 of the experiments. The design\nclass attendees presented their work (designs for toasters) in a small exhibition.\nFigure 9: Evolution of a local map after a major change has occurred (the toaster\nexhibition). Shown are the long-term memory maps \u03bb2-\u03bb5 on four different days.\n20\nit makes the already difficult problem of simultaneous localization and map-\nping even more complex and might lead to a less robust and slower solution.\nTherefore we conducted an experimental comparison of the localization algo-\nrithm using the dynamic map against the same localization algorithm using the\nmap created at the end of the first day as a static map. Additionally this static\nmap was tested in two variations: with and without short-term memory (\u03bb1 in\nTable 1 activated). A general result is that in all cases there was no serious\nlocalization error that the robot could not recover from, so global localization\nwas never required (the start position was always the same). In the absence of\nground truth data, the following performance measures were selected:\n1. The average likelihood of a range scan reading given the probabilistic\nmodel explained in Section 4.2. This measure gives an indication of how\nexpected a scan is.\n2. The smallest eigenvalue of the inverse of the covariance matrix that re-\nsults from scan matching. This measure gives an indication of localization\naccuracy: if that value is large the corresponding uncertainty is small.\nFigs. 10 and 11 show the evolution of these measures. In both cases there is\na clear benefit in using the dynamic map. Also, using the short-term memory\nmap alone improves the performance. But the long-term memory map improves\nthe results even more, especially regarding localization accuracy. Both figures\nalso show an expected effect: the static map performs better at the beginning\nthan at the end, while the dynamic map improves performance with time.\n5.4 Usage of the different timescales\nWhile the above \u201cblack-box\u201d measures characterize the performance of the\nwhole system, they do not show how the internal components of the dynamic\nmap behaved. The exact number of timescales we used (5) was a more or less\narbitrary decision, and more timescales would perhaps further improve the over-\nall performance. But the main idea was to cover the full spectrum of possible\ntimescales and the order of the longest timescale (\u03bb2 \u2248 13.5 days) relates to\nthe duration of the experiment, so for an experiment lasting a year we would\nprobably choose a maximum timescale with a half-life of two or three months.\nTo determine whether all of the timescales applied were really useful, we\nrecorded how often each timescale was selected by the localization algorithm,\nwith the result shown in Fig. 12. Clearly each timescale was actually used, and\nthe relative frequencies are distributed relatively evenly among the long-term\nmemory maps, but with noticably higher usage of the short-term component.\nA definite temporal trend was also observed: Fig. 13 shows relative usage fre-\nquencies for the short-term memory map (\u03bb1) and the most long-term memory\nmap (\u03bb5) against time. The usage of the short-term memory map decreased\nwith time, while usage of the long-term memory map increased. An explana-\ntion for this behaviour is that the long-term map models the static parts of the\nscene with increasing reliability over time. With more measurements it becomes\n21\n0 5 10 15 20 25\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\nAverage Likelihood\n \n \nStatic Map\nWith STM\nDynamic Map (STM+LTM)\nFigure 10: The average likelihood of a measured range value according to the\nlearned perceptual model (Section 4.2). The dynamic map, consisting of a short-\nterm memory map (STM) and long-term memory maps (LTM), is compared to\na static map and a static map with added short-term memory. The static map\nis a snapshot of the dynamic map after the first day.\nincreasingly unlikely that outliers (e.g. caused by moving people or temporary\nlocalization errors) will be used in the local maps. In addition, the median fil-\nter becomes more precise as the number of samples in the long-term memory\nmap increases, which also means that the corresponding standard deviation will\ntypically become smaller as the estimate becomes more certain. The localiza-\ntion algorithm will then prefer the long-term memory map if the corresponding\npart of the environment has really remained static, due to its higher likelihood\naccording to the perceptual model. This result provides compelling evidence\nthat the dynamic map was not only successful in reacting to changes in the\nenvironment, but also that it was successful in improving map quality for the\nstatic parts of the environment.\n6 Conclusion\nThis paper presented an experimental analysis of sample-based maps for long-\nterm SLAM in dynamic environments. The approach is based on two novel, sim-\n22\n0 5 10 15 20 25\n0\n0.5\n1\n1.5\n2\n2.5\n3\nday\nSm\nall\nes\nt E\nV \nof\n \nin\nve\nrs\ne \nof\n \nlo\nca\nliz\nat\nio\nn\n \nco\nva\nria\nn\nce\n \nm\nat\nrix\nCertainty of localization\n \n \nStatic Map\nWith STM\nDynamic Map (STM+LTM)\nFigure 11: The certainty of the localization estimate. This certainty is mea-\nsured by the value of the smallest eigenvalue of the inverse of the localization\ncovariance matrix. If that value is large the corresponding uncertainty is small.\nple and powerful ideas: (1) representing the environment at different timescales,\nwith older memories fading at different rates, and (2) using samples and ro-\nbust statistics to handle contradicting measurements produced by environmental\nchanges. Large amounts of memory are required for the proposed representa-\ntion, but are available today on standard computers. A further contribution was\nmade at a more abstract level: we investigated the general problems of life-long\nmap learning in dynamic environments and identified the stability-plasticity\ndilemma as the most important problem. Our solution to the dilemma is to\ntrack the state of the world at several timescales simultaneously, and then to\nlet the sensor data select the most appropriate timescale for a given situation.\nWith this approach, the robot can simultaneously represent the world before,\nduring and after changes to the configuration of an environment.\nThese concepts were verified through a long-term experiment over a pe-\nriod of 5 weeks (one of longest robotic mapping experiments performed), where\nchanges to the environment included the installation and deinstallation of a\nsmall exhibition inside the mapped area. Our proposed method separates the\nwell-known problems of static SLAM (error-backpropagation, loop closing) from\nthe dynamic problems, handling the first by a classical SLAM algorithm. This\nis advantageous, because the difficulty of both parts adds but does not multiply.\n23\n00.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n\u03bb1 \u03bb2 \u03bb3 \u03bb4 \u03bb5\nFigure 12: The relative frequency with which each submap was selected.\nThereby \u03bb1 is the short-term memory and \u03bb2-\u03bb5 are the long-term memory\nmaps (with update ratios as given in Table 1 ).\nFigure 13: Evolution of usage frequencies for timescales \u03bb1 and \u03bb5.\n24\nA key idea to make this possible is to represent the map as a collection of \u201c360\ndegree scans\u201d relative to global reference points. Thereby the classical SLAM\nproblems such as error propagation and loop closing affect only the reference\npoints and are solved by a classical SLAM algorithm. The dynamical effects af-\nfect the individual rays of the 360 degree scans only and are solved by applying\n1-D robust statistics (median, median of absolute differences) to each ray. This\nis crucial, because robust statistics are much harder to generalize to multiple\ndimensions than least square statistics.\nIn this paper, we did not consider the problems of \u201ckidnapping\u201d or global\nlocalization. Although serious localization errors were never observed in our\nexperiments, this does not guarantee that such errors would never occur in\ngeneral. In the case of small localization errors or temporary loss of position,\nwrong samples would be added to the dynamic map, but would then be treated\nas outliers. In the case of non-recoverable localization error, it would be nec-\nessary to switch to global localization and switch off map learning until the\nrobot\u2019s position had been recovered. In our system, this could be detected us-\ning the perceptual model together with a suitable likelihood threshold to declare\npossible localization failures.\nFuture work would also include investigation of other sensor modalities such\nas vision instead of range-finder sensors. Rather than using a normal distribu-\ntion in the perceptual model for each angle-bin and timescale, as in this work,\na multi-modal distribution estimated from all timescales per bin might remove\nthe need for search over timescales in the localization process. Our experiment\nin this work covered a five week period in a real environment: further work\nwould still be needed to determine how to scale the approach to operation of\nservice robots for a potentially undetermined period of time, e.g. many years.\nThis would include further analysis on how to choose the timescales and their\nmemory requirements, update ratios, etc. The problem of selecting a minimal\nset of local maps also remains an open topic for future research. In conclu-\nsion, while this work demonstrates a basic solution to the problem of long-term\nSLAM, it also opens up many interesting avenues for future work on lifelong\noperation of mobile service robots.\nReferences\n[1] J. Andrade-Cetto and A. Sanfeliu, \u201cConcurrent map building and local-\nization in indoor dynamic environments,\u201d International Journal of Pattern\nRecognition and Artificial Intelligence, vol. 16, no. 3, pp. 361\u2013374, 2002.\n[2] D. Anguelov, R. Biswas, D. Koller, B. Limketkai, S. Sanner, and S. Thrun,\n\u201cLearning hierachical objects maps of non-stationary environments with\nmobile robots,\u201d in Proceedings of the 17th Annual Conference on Uncer-\ntainty in AI (UAI), 2002.\n25\n[3] P. Biber, \u201cMap building and localization for long-term operation of mobile\nrobots in dynamic environments,\u201d Ph.D. dissertation, Wilhelm-Schickard-\nInstitut, University of Tu\u00a8bingen, Germany, 2007.\n[4] P. Biber and W. Stra\u00dfer, \u201cThe normal distributions transform: A new ap-\nproach to laser scan matching,\u201d in International Conference on Intelligent\nRobots and Systems (IROS), 2003.\n[5] P. Biber and T. Duckett, \u201cDynamic maps for long-term operation of mo-\nbile service robots,\u201d in Proceedings of Robotics: Science and Systems I,\nCambridge, MA, USA, June 8-11 2005.\n[6] W. Burgard, A. Cremers, D. Fox, D. Ha\u00a8hnel, G. Lakemeyer, W. Steiner,\nand S. Thrun, \u201cExperiences with an interactive museum tour-guide robot,\u201d\nArtificial Intelligence, vol. 114, no. 1-2, pp. 3\u201355, 1999.\n[7] J. Dennis and R. B. Schnabel, \u201cNumerical Methods for Unconstrained Op-\ntimization and Nonlinear Equations. SIAM Classics in Applied Mathemat-\nics,\u201d 1996.\n[8] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classification. Wiley,\nSecond Edition 2001.\n[9] S. Grossberg, The Adaptive Brain. North Holland, 1988.\n[10] D. Ha\u00a8hnel, R. Triebbel, W. Burgard, and S. Thrun, \u201cMap building with\nmobile robots in dynamic environments,\u201d in ICRA, 2003.\n[11] P. J. Huber, Robust Statistics. New York: Wiley, 1981.\n[12] F. Lu and E. Milios, \u201cGlobally consistent range scan alignment for envi-\nronment mapping,\u201d Autonomous Robots, vol. 4, pp. 333\u2013349, 1997.\n[13] C. Stachniss and W. Burgard, \u201cMobile robot mapping and localization in\nnon-static environments,\u201d in Proc. of the National Conference on Artificial\nIntelligence (AAAI)\u201d, Pittsburgh, PA, USA, 2005.\n[14] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction.\nMIT Press, Cambridge, MA, 1998.\n[15] S. Thrun, M. Bennewitz, W. Burgard, A. Cremers, F. Dellaert, D. Fox,\nD. Ha\u00a8hnel, C. Rosenberg, N. Roy, J. Schulte, and D. Schulz, \u201cMINERVA:\nA second generation mobile tour-guide robot,\u201d in ICRA, 1999.\n[16] C.-W. Wang, C. Thorpe, and S. Thrun, \u201cOnline simultaneous localization\nand mapping with detection and tracking if moving objects: Theory and\nresults from a ground vehicle in crowded urban areas,\u201d in ICRA, 2003.\n[17] B. Yamauchi and R. Beer, \u201cSpatial learning for navigation in dynamic envi-\nronments,\u201d IEEE Transactions on Systems, Man and Cybernetics, Special\nIssue of Learning Autonomous Robots, vol. 26, no. 3, pp. 496\u2013505, 1996.\n26\n[18] U. Zimmer, \u201cAdaptive approaches to basic mobile robot tasks,\u201d Ph.D. dis-\nsertation, University of Kaiserslautern, 1995.\n27\n"}
{"doi":"10.1007\/978-3-540-77088-6_24","coreId":"15596","oai":"oai:eprints.erpanet.org:135","identifiers":["oai:eprints.erpanet.org:135","10.1007\/978-3-540-77088-6_24"],"title":"Searching for Ground Truth: a stepping stone in automating genre classification","authors":["Kim, Dr Yunhyong","Ross, Seamus"],"enrichments":{"references":[{"id":645929,"title":"Automatic categorization of email into folders. benchmark experiments on enron and sri corpora.","authors":[],"date":"2004","doi":null,"raw":"Bekkerman, R., McCallum, A., Huang, G.: Automatic categorization of email into folders. benchmark experiments on enron and sri corpora. Technical Report IR-418, Centre for Intelligent Information Retrieval, UMASS. (2004).","cites":null},{"id":9469569,"title":"Automatic detection of text genre.","authors":[],"date":"1997","doi":null,"raw":"Kessler, G., Nunberg, B., Schuetze, H.: Automatic detection of text genre. In Proceedings 35th Ann. Meeting ACL (1997) 32-38.","cites":null},{"id":9469565,"title":"Automatic document metadata extraction using support vector machines.","authors":[],"date":"2003","doi":"10.1109\/jcdl.2003.1204842","raw":"Han, H., Giles, L., Manavoglu, E., Zha, H., Zhang, Z., Fox, E. A.: Automatic document metadata extraction using support vector machines. In 3rd ACM\/IEEECS Conf. Digital Libraries. (2003) 37-48.","cites":null},{"id":9469578,"title":"Automating the production of bibliographic records.","authors":[],"date":"2001","doi":null,"raw":"Thoma, G.: Automating the production of bibliographic records. Technical report, Lister Hill National Center for Biomedical Communication, US National Library of Medicine (2001).","cites":null},{"id":9469574,"title":"Building a large annotated corpus of English: the Penn Treebank.","authors":[],"date":"1994","doi":null,"raw":"Marcus, M. P., Santorini, B., Mareinkiewicz, M. A.: Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics 19(2) (1994) 313-","cites":null},{"id":9469572,"title":"Detecting family resemblance: Automated genre classi\ufb01cation.","authors":[],"date":"2007","doi":"10.2481\/dsj.6.s172","raw":"Kim, Y., Ross, S.: Detecting family resemblance: Automated genre classi\ufb01cation. Data Science Journal 6 ISSN 1683-1470 (2007) S172-S183. http:\/\/www.jstage.jst.go.jp\/article\/dsj\/6\/0\/s172\/ pdf","cites":null},{"id":645931,"title":"Dimensions of Register Variation:a Cross-Linguistic Comparison.","authors":[],"date":"1995","doi":"10.2307\/417491","raw":"Biber, D.: Dimensions of Register Variation:a Cross-Linguistic Comparison. Cambridge University Press, New York, (1995).","cites":null},{"id":645928,"title":"E.: Clustering document images using a bag of symbols representation.","authors":[],"date":"2005","doi":"10.1109\/icdar.2005.75","raw":"Barbu, E., Heroux P., Adam, S., Turpin, E.: Clustering document images using a bag of symbols representation. In Proceedings 8th International Conference on Document Analysis and Recognition ISBN ISSN 1520-5263 (2005) 1216-1220.","cites":null},{"id":9469579,"title":"E.: Data mining: Practical machine learning tools and techniques. 2nd Edition,","authors":[],"date":"2005","doi":"10.1016\/b978-0-12-374856-0.00005-5","raw":"Witten, H. I., Frank, E.: Data mining: Practical machine learning tools and techniques. 2nd Edition, Morgan Kaufmann, San Francisco (2005).","cites":null},{"id":645927,"title":"Fine-grained document genre classi\ufb01cation using \ufb01rst order random graphs.","authors":[],"date":"2001","doi":"10.1109\/icdar.2001.953759","raw":"Bagdanov, A., Worring, M.: Fine-grained document genre classi\ufb01cation using \ufb01rst order random graphs. In Proceedings 6th International Conference on Document Analysis and Recognition ISBN 0-7695-1263-1 (2001) 79-83.","cites":null},{"id":9469570,"title":"Genre classi\ufb01cation in automated ingest and appraisal metadata.","authors":[],"date":"2006","doi":"10.1007\/11863878_6","raw":"Kim, Y., Ross, S.: Genre classi\ufb01cation in automated ingest and appraisal metadata. In J. Gonzalo, editor, Proceedings European Conf. on advanced technology and research in Digital Libraries 4172 LNCS (2006) 63-74.","cites":null},{"id":9469571,"title":"Implicit reference to citations: A study of astronomy papers.","authors":[],"date":"2006","doi":null,"raw":"Kim, Y., Webber, B.: Implicit reference to citations: A study of astronomy papers. Presentation at the 20th CODATA international Conference, Beijing, China. (2006). http:\/\/eprints.erpanet.org\/ paper id 115","cites":null},{"id":9469575,"title":"Integrating automatic genre analysis into digital libraries.","authors":[],"date":"2001","doi":"10.1145\/379437.379439","raw":"Rauber, A., Mller-Kgler, A.: Integrating automatic genre analysis into digital libraries. In Proceedings ACM\/IEEE Joint Conf. Digital Libraries, Roanoke, VA (2001) 1-10.","cites":null},{"id":645935,"title":"Investigating GIS and Smoothing for Maximum Entropy Taggers.","authors":[],"date":"2003","doi":"10.3115\/1067807.1067821","raw":"Curran, J., Clark, S.: Investigating GIS and Smoothing for Maximum Entropy Taggers. In Proceedings Aunnual Meeting European Chapter of the Assoc. of Computational Linguistics (2003) 91-98.","cites":null},{"id":9469564,"title":"Knowledge-based metadata extraction from postscript \ufb01le.","authors":[],"date":"2000","doi":"10.1145\/336597.336639","raw":"Giu\ufb00rida, G., Shek, E., Yang, J.: Knowledge-based metadata extraction from postscript \ufb01le. In Proceedings 5th ACM Intl. Conf. Digital Libraries. (2000) 77-","cites":null},{"id":645936,"title":"Learning to classify documents according to genre.","authors":[],"date":"2006","doi":"10.1002\/asi.20427","raw":"Finn, A., Kushmerick. N.: Learning to classify documents according to genre. Journal of American Society for Information Science and Technology 57(11) (2006) 1506-","cites":null},{"id":9469567,"title":"Perc: A personal email classi\ufb01er.","authors":[],"date":"2006","doi":"10.1007\/11735106_41","raw":"Ke, S. W., Bowerman, C.: Perc: A personal email classi\ufb01er. In Proceedings 28th European Conf. Information Retrieval (ECIR 2006) (2006) 460-463.","cites":null},{"id":9469577,"title":"Preservation research and sustainable digital libraries.","authors":[],"date":"2005","doi":"10.1007\/s00799-004-0099-3","raw":"Ross, S., Hedstrom, M.: Preservation research and sustainable digital libraries. International Journal of Digital Libraries. DOI: 10.1007\/s00799-004-0099-3 (2005).","cites":null},{"id":645933,"title":"Random forests.","authors":[],"date":"2001","doi":"10.1007\/0-387-21529-8_16","raw":"Breiman, L.: Random forests. Machine Learning, 45 (2001) 5-32. 3 http:\/\/www.delos.info 4 http:\/\/www.dcc.ac.uk 5 http:\/\/www.jisc.ac.uk 6 http:\/\/www.epsrc.ac.uk8. Chao, C., Liaw, A., Breiman, L.: Using random forest to learn imbalanced data. http:\/\/www.stat.berkeley.edu\/ breiman\/RandomForests\/ (2004).","cites":null},{"id":9469566,"title":"Recognizing text genres with simple metric using discriminant analysis.","authors":[],"date":"1994","doi":"10.3115\/991250.991324","raw":"Karlgren, J., Cutting, D.: Recognizing text genres with simple metric using discriminant analysis. In Proceedings 15th Conf. Comp. Ling. 2 (1994) 1071-1075.","cites":null},{"id":645930,"title":"Representativeness","authors":[],"date":"1993","doi":"10.1093\/llc\/8.4.243","raw":"Biber, D.: Representativeness in Corpus Design. Literary and Linguistic Computing 8(4) doi:10.1093\/llc\/8.4.243 (1993) 243-257","cites":null},{"id":645932,"title":"Stereotyping the web: genre classi\ufb01cation of web documents. Master\u2019s thesis,","authors":[],"date":"2005","doi":null,"raw":"Boese, E. S.: Stereotyping the web: genre classi\ufb01cation of web documents. Master\u2019s thesis, Colorado State University (2005).","cites":null},{"id":9469573,"title":"The Naming of Cats: Automated genre classi\ufb01cation.","authors":[],"date":null,"doi":"10.2218\/ijdc.v2i1.13","raw":"Kim Y., Ross, S.: The Naming of Cats: Automated genre classi\ufb01cation. International Journal for Digital Curation 2(1)(2007). http:\/\/www.ijdc.net\/.\/ijdc\/article\/view\/24","cites":null},{"id":645934,"title":"Using random forest to learn imbalanced data. http:\/\/www.stat.berkeley.edu\/ breiman\/RandomForests\/","authors":[],"date":"2004","doi":null,"raw":null,"cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2007-01-01","abstract":"This paper examines genre classification of documents and\nits role in enabling the effective automated management of digital documents by digital libraries and other repositories. We have previously presented genre classification as a valuable step toward achieving automated extraction of descriptive metadata for digital material. Here, we present results from experiments using human labellers, conducted to assist in genre characterisation and the prediction of obstacles which need to be overcome by an automated system, and to contribute to the process of creating a solid testbed corpus for extending automated genre classification and testing metadata extraction tools across genres. We also describe the performance of two classifiers based on image and stylistic modeling features in labelling the data resulting from the agreement of three human labellers across fifteen genre classes.","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/15596.pdf","fullTextIdentifier":"http:\/\/eprints.erpanet.org\/135\/01\/ykim_sross_DELOS2007FebConfFinal.pdf","pdfHashValue":"528ff084c073bda64e42933915095426c2315359","publisher":null,"rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:eprints.erpanet.org:135<\/identifier><datestamp>\n      2007-11-19<\/datestamp><setSpec>\n      7374617475733D696E7072657373<\/setSpec><setSpec>\n      7375626A656374733D45:4465736372697074696F6E<\/setSpec><setSpec>\n      7375626A656374733D45:436174616C6F6775696E67<\/setSpec><setSpec>\n      7375626A656374733D45:4964656E74696669636174696F6E<\/setSpec><setSpec>\n      7375626A656374733D45:4541<\/setSpec><setSpec>\n      7375626A656374733D4469676974616C205265706F7369746F72792C204469676974616C204172636869766520616E64204469676974616C204C696272617279204D6F64656C73:496E67657374<\/setSpec><setSpec>\n      7375626A656374733D4469676974616C205265706F7369746F72792C204469676974616C204172636869766520616E64204469676974616C204C696272617279204D6F64656C73:4D616E6167656D656E74<\/setSpec><\/header><metadata><oai_dc:dc xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Searching for Ground Truth: a stepping stone in automating genre classification<\/dc:title><dc:creator>\n        Kim, Dr Yunhyong<\/dc:creator><dc:creator>\n        Ross, Seamus<\/dc:creator><dc:subject>\n        EE Description<\/dc:subject><dc:subject>\n        EB Identification<\/dc:subject><dc:subject>\n        LA Ingest<\/dc:subject><dc:subject>\n        EC Cataloguing<\/dc:subject><dc:subject>\n        LB Management<\/dc:subject><dc:subject>\n        EA Metadata<\/dc:subject><dc:description>\n        This paper examines genre classification of documents and\nits role in enabling the effective automated management of digital documents by digital libraries and other repositories. We have previously presented genre classification as a valuable step toward achieving automated extraction of descriptive metadata for digital material. Here, we present results from experiments using human labellers, conducted to assist in genre characterisation and the prediction of obstacles which need to be overcome by an automated system, and to contribute to the process of creating a solid testbed corpus for extending automated genre classification and testing metadata extraction tools across genres. We also describe the performance of two classifiers based on image and stylistic modeling features in labelling the data resulting from the agreement of three human labellers across fifteen genre classes.<\/dc:description><dc:date>\n        2007-01-01<\/dc:date><dc:type>\n        Conference Paper<\/dc:type><dc:identifier>\n        http:\/\/eprints.erpanet.org\/135\/<\/dc:identifier><dc:format>\n        pdf http:\/\/eprints.erpanet.org\/135\/01\/ykim_sross_DELOS2007FebConfFinal.pdf<\/dc:format><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2007,"topics":["EE Description","EB Identification","LA Ingest","EC Cataloguing","LB Management","EA Metadata"],"subject":["Conference Paper"],"fullText":"Searching for Ground Truth: a stepping stone in\nautomating genre classi\ufb01cation\nYunhyong Kim and Seamus Ross\nDigital Curation Centre (DCC)\n&\nHumanities Adavanced Technology Information Institute (HATII)\nUniversity of Glasgow\nGlasgow, UK\nemail: y.kim, s.ross@hatii.arts.gla.ac.uk\nAbstract. This paper examines genre classi\ufb01cation of documents and\nits role in enabling the e\ufb00ective automated management of digital doc-\numents by digital libraries and other repositories. We have previously\npresented genre classi\ufb01cation as a valuable step toward achieving auto-\nmated extraction of descriptive metadata for digital material. Here, we\npresent results from experiments using human labellers, conducted to as-\nsist in genre characterisation and the prediction of obstacles which need\nto be overcome by an automated system, and to contribute to the process\nof creating a solid testbed corpus for extending automated genre clas-\nsi\ufb01cation and testing metadata extraction tools across genres. We also\ndescribe the performance of two classi\ufb01ers based on image and stylistic\nmodeling features in labelling the data resulting from the agreement of\nthree human labellers across \ufb01fteen genre classes.\nKeywords: information extraction, genre classi\ufb01cation, automated metadata\nextraction, metadata, digital library, data management\n1 Introduction\nAs digital resources become increasingly common as a form of information in\nour everyday life, the task of storing, managing, and utilising this information\nbecomes increasingly important. Managing digital objects not only involves stor-\nage, e\ufb03cient search, and retrieval of objects - tasks already expected by tradi-\ntional libraries - but also involves ensuring the continuation of technological\nrequirements, tracking of versions, linking and networking of independently pro-\nduced objects, and selecting objects and resources for retention from a deluge\nof objects being created and distributed. Knowledge representation, embodying\nthe core information about an object, e.g. metadata summarising the technical\nrequirements, function, source, and content of data, play a crucial role in the\ne\ufb03cient and e\ufb00ective management and use of digital materials (cf. [22]), mak-\ning it easier to tame the resources within. It has been noted that the manualcollection of such information is costly and labour-intensive and that a collab-\norative e\ufb00ort to automate the extraction or creation of such information would\nbe undoubtedly necessary1.\nThere have been several e\ufb00orts (e.g. [11], [12], [23], DC-dot metadata ed-\nitor2, [3] and [14]) to automatically extract relevant metadata from selected\ngenres (e.g. scienti\ufb01c articles, webpages and emails). These often play heavily\non the structure of the document, which characterises the genre to which the\ndocument belongs. It seems, therefore, reasonable to employ automated genre\nclassi\ufb01cation to bind these genre-dependent tools. However, there is a distinct\nlack of consolidated corpora on which automated genre classi\ufb01cation and the\ntransferability or integrability of tools across genres can be tested. One of the\nreasons such corpora have not yet been constructed relates to the elusive nature\nof genre classi\ufb01cation, which seems to take on a di\ufb00erent guise in independent\nresearches. Biber\u2019s analysis ([5]) tried to capture \ufb01ve genre dimensions (informa-\ntion, narration, elaboration, persuasion, abstraction) of text, while others ([13],\n[6]) examined popularly recognised genre classes such as FAQ, Job Description,\nEditorial or Reportage. Genre has been used to describe stylistic aspects (ob-\njectivity, intended level of audience, positive or negative opinion, whether it is\na narrative) of a document ([10], [15]), or even to describe selected journal and\nbrochure titles ([1]). Others ([21], [2]) have clustered documents into similar\nfeature groups, without attempting to label the samples with genre facets or\nclasses.\nThe di\ufb03culty of de\ufb01ning genre is already emphasised in the literature, and\nmany proposals have been reasonably suggested. However, very little active\nsearch for ground truth in human agreement over genre classi\ufb01cation has been\nconducted to scope for a useful genre schema and corpus. To shed some light on\nthe situation, we have undertaken experiments to analyse human agreement over\ngenre classi\ufb01cation: the agreement analysis will establish the degree of agreement\nthat can be reached by several human labellers in genre classi\ufb01cation, isolate the\nconditions that give meaning to genre classi\ufb01cation, and provide a statistically\nwell understood corpus. The corpus will also function as a testbed for examining\ntransferability of tools tailored to work in a small number of genres to other gen-\nres, and constructing metadata extraction tools which integrate tools developed\nindependently for di\ufb00erent genres. In addition, a study of human performance in\ngenre classi\ufb01cation provides a means of scoping new emerging genres, and helps\nus to grasp the history of genre development. To this end, we have constructed a\nschema of seventy genres (Section 2) and present results in document collection\nand categorisation by human labellers in Section 3.\nGenre classi\ufb01cation, in its most general understanding, is the categorisation\nof documents according to their structural (e.g. the existence of a title page,\nchapter, section) and functional (e.g. to record, to inform) properties. The two\n1 Issues addressed in The Cedars Project at the University of Leeds:\nhttp:\/\/www.leeds.ac.uk\/cedars\/guideto\/collmanagemnet\/guidetocolman.pdf\n2 dc-dot, UKOLN Dublin Core Metadata Editor,\nhttp:\/\/www.ukoln.ac.uk\/metadata\/dcdot\/are, however, not divorced from each other: the structure evolves to optimise the\nfunctional requirements of the document within the environment (e.g. the target\ncommunity, publisher and creator), just as the structure of organisms evolves\nto meet their survival functions within the natural environment. And, just as\nthe functional aspect of an organism is central to its survival, the functional\nproperties of a digital object is the crucial driving force of document genre.\nThe functional aspect of the document, however, is a high level concept which\nis inferred from selected structural aspects of the document, and, in turn, the\nstructural aspects are de\ufb01ned by lower level features which constitute genes\nin the DNA of the document. Unlike organisms, we have not even come close\nto identifying the DNA sequence of a digital document, let alone parsing the\nsequence into genes to understand how they are expressed to create semantic\ninformation (e.g. genre or subject). Accordingly, automated classi\ufb01cation has\ntraditionally taken to examining a large pot of related and unrelated features,\nto be re\ufb01ned by selection or creation algorithms to distinguish between a small\nnumber of prede\ufb01ned classes. This method might result in three immediately\nnoticeable problems:\n\u2013 The reason for speci\ufb01c selections and creations of features remains opaque.\n\u2013 Features will be selected to conform to the unavoidable bias in the training\ndata.\n\u2013 The performance of the tool on a new set of classes is unpredictable, and\nmost likely, the tool will have to be reconstructed by re-running feature\nselection over new data.\nTo address these points, we propose grouping features according to similar\ntype (e.g. those which come together to describe a well-de\ufb01ned aspect of docu-\nment structure) in analogy to genes. This makes it easier to identify the reasons\nbehind errors and see if success is an artefact of unrepresentative data. We also\npropose that a study of a wider variety of genre classes may be necessary. A\nclassi\ufb01er which performs well to distinguish three classes can be expected to\nperform well to distinguish two of the three classes; whereas the behaviour of a\nclassi\ufb01er which recognises two classes in distinguishing three classes is less pre-\ndictable. The amount of information the class of a document encompasses is in\ndirect relationship to the number of other classes to which it could belong. By\nbuilding a system which can detect selected genre classes from a vast range of\nclasses, we are building a better informed system.\nWe have previously identi\ufb01ed ([16]) \ufb01ve feature types: image features (e.g\nwhite space analysis; cf. [1]), stylistic features (e.g. word, sentence, block statis-\ntics; cf. [21]), language modelling features (e.g. Bag-of-Words and N-gram mod-\nels), semantic features (e.g. number of subjective noun phrases) and source or\ndomain knowledge features (e.g. \ufb01le name, journal name, web address, techni-\ncal format structures, institutional a\ufb03liations, other works by the author). We\nreported preliminary results of classi\ufb01ers built on two or more of the \ufb01rst three\nfeature types on a privately labelled corpus ([16], [18],[19]). In this paper, we\nlook at the performance of a classi\ufb01er modeled on the \ufb01rst two types of featureson new data labelled by three human labellers, as further study of the correlation\nbetween genres and feature types.\nTable 1. Genre schema (numbers in parentheses are assigned database IDs)\nBook\nAcademic Monograph (2) Book of Poetry (4) Other Book (6)\nBook of Fiction (3) Handbook (5)\nArticle\nAbstract (8) Other Research (10) News Report (12)\nScienti\ufb01c Article (9) Magazine Article (11)\nShort Composition\nFictional Piece (14) Dramatic Script (16) Short Biographical Sketch (18)\nPoems (15) Essay (17) Review (19)\nSerial\nPeriodicals (News, Mag) (21) Conference Proceeding (23)\nJournals (22) Newsletter (24)\nCorrespondence\nEmail (26) Memo (29)\nLetter (27) Telegram (30)\nTreatise\nThesis (32) Technical Report (34) Technical Manual (36)\nBusiness\/Operational Rept (33) Miscellaneous Report (35)\nInformation Structure\nList (38) Table (41) Programme (44)\nCatalogue (39) Menu (42) Questionnaire (45)\nRaw Data (40) Form (43) FAQ (46)\nEvidential Document\nMinutes (48) Financial Record (50) Slip (52)\nLegal Proceedings (49) Receipt (51) Contract (53)\nVisual Document\nArtwork (55) Graph (58) Poster (61)\nCard (56) Diagram (59) Comics (62)\nChart (57) Sheet Music (60)\nOther Functional Document\nGuideline (64) Product Description (70) Forum Discussion (76)\nRegulations (65) Advertisement (71) Interview (77)\nManual (66) Announcement (72) Notice (78)\nGrant\/Project Proposal (67) Appeal\/Propaganda (73) Resume\/ CV (79)\nLegal Proposal\/Order (68) Exam or Worksheet (74) Slides (80)\nJob\/Course\/Project Desc. (69) Factsheet (75) Speech Transcript (81)\n2 Genre schema\nIn this paper we are working with seventy genres which have been organised\ninto ten groups (Table 1). The schema was constructed from an examination of\nPDF documents gathered from the internet using a list of random search words.\nThe schema captures a wide range of commonly used genres. The aim is to\ninitially vie for a coverage of as many genres as possible rather than to employ\na well established structure. In response, certain distinctions may seem at \ufb01rst\ninconsistent or ambiguous: for instance, Legal Proceedings versus Legal Order,\nor Technical Manual versus Manual. However, the hope is that when you view\nthe entire path as genres, e.g. Evidential Document - Legal Proceedings versus\nOther Functional Document Legal Order, the distinction will become clearer.\nThe schema will form a fundamental \ufb01eld to be harvested for further re\ufb01nement.It will be adjusted to exclude ill-de\ufb01ned genres depending on emerging results\nof the human labelling experiments described in Section 3.\n3 Human labelling experiment\nWe have undertaken two human document genre classi\ufb01cation experiments in\nthis research. First we had students retrieve sample documents of the seventy\ngenres in Table 1 (Document Retrieval Exercise), and subsequently had them\nre-assigned with genres from the same schema (Reclassi\ufb01cation) to validate,\nquantify, or examine agreement over its membership to any one genre.\nDocument Retrieval Exercise: In this experiment, university students\nwere assigned genres and asked to retrieve 100 samples of PDF \ufb01les belonging\nto their assigned genre written in English. They were also asked to give reasons\nfor including the particular sample in the set and asked not to retrieve more\nthan one document from each source. They were not introduced to pre-de\ufb01ned\nnotions of the genre before retrieval.\nReclassi\ufb01cation: Two people from a secretarial background were employed\nto reclassify the retrieved documents. They were not allowed to confer, and\nthe documents, without their original label, were presented in a random order\nfrom the database to each labeller. The secretaries were not given descriptions of\ngenres. They were expected to use their own training in record-keeping to classify\nthe documents. The number of items which have been stored in the database is\ndescribed in Table 2.\nAt \ufb01rst, it may seem odd not to provide de\ufb01nitions for the genres in the\nschema. However, note that it is not true that every genre class requires the\nsame amount of detail in its de\ufb01nition to achieve the same level of precision. In\nfact, as we will see, the level of agreement on some genres is high regardless of\nthe lack of de\ufb01nition.\nTable 2. Database composition (left) and Agreement of Labellers (right)\nTotal with three labels with two labels damaged\n5485 5373 103 9\nLabellers Agreed\nstudent & secretary A 2745\nstudent & secretary B 2974\nsecretary A & B 2422\nall labellers 2008\nSome of the collected data can not be considered to be examples of the genre.\nFor instance, some students introduced articles about email into the database as\nsamples of the genre Email. Others submitted empty receipt forms as samples of\nthe genre Receipt. The genre Card was also heavily populated with forms (e.g.\nun\ufb01lled identity cards). While the \ufb01rst set of errorsare due to a misunderstanding\nof the instructions and stems from the fact that emails are hard to \ufb01nd in\nPDF format, the latter sets of errors are due to di\ufb00ering opinions of the genre\nde\ufb01nition. These items were not removed from the database because:\u2013 this would introduce the bias of the remover into the database; and,\n\u2013 documents which have been included erroneously will be automatically \ufb01l-\ntered out of the collection once reclassi\ufb01cation labels and agreement data\nare acquired.\nFull analysis of these errors will be carried out before the release of the corpus,\nat which time, the rationale presented by students to justify the inclusion of\nparticular items will also be analysed for elements that might characterise genres.\nIn Figure 1, we have presented the numbers of documents in each of the seventy\ngenres on which labellers have agreed. The graph exhibiting higher numbers\npresents the number of documents on which at least two labellers have assigned\nthe same label, and the lower level graph displays the number of documents\non which all three labellers have assigned the same label. The genre classes are\nindicated as numbers (to save space) along the bottom of the graph, indicating\nthe assigned genre IDs given in Table 1. Note that there is a large discrepancy\n2 3 4 5 6 8 9 1\n0\n1\n1\n1\n2\n1\n4\n1\n5\n1\n6\n1\n7\n1\n8\n1\n9\n2\n1\n2\n2\n2\n3\n2\n4\n2\n6\n2\n7\n2\n9\n3\n0\n3\n2\n3\n3\n3\n4\n3\n5\n3\n6\n3\n8\n3\n9\n4\n0\n4\n1\n4\n2\n4\n3\n4\n4\n4\n5\n4\n6\n4\n8\n4\n9\n5\n0\n5\n1\n5\n2\n5\n3\n5\n5\n5\n6\n5\n7\n5\n8\n5\n9\n6\n0\n6\n1\n6\n2\n6\n4\n6\n5\n6\n6\n6\n7\n6\n8\n6\n9\n7\n0\n7\n1\n7\n2\n7\n3\n7\n4\n7\n5\n7\n6\n7\n7\n7\n8\n7\n9\n8\n0\n8\n1\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n110\n120\n130\n140\n150\nFig.1. Two labeller agreement (top graph) versus three labeller agreement (bottom\ngraph)\nbetween the agreement with respect to the genre Form (43), but that selected\ngenres such as Handbook (5), Minutes (48) and Resume\/CV(79) show little\ndi\ufb00erence between the two labeller agreement and the three labeller agreement,\nsuggesting the latter genres as less context-dependent genres.\n4 Case study\nIn this section we will look at the student performance on documents for which\nsecretaries have given the same label. There are 2422 items on which the de-\ncision of the secretaries concurred. The \ufb01gures in Table 2 show the number\nof documents on which di\ufb00erent groups of labellers have agreed. The statistics\nin Table 2 show that there is more agreement between the student and either\nof the secretaries than between the two secretaries. A possible explanation for\nthe discrepancy could be that secretaries are trained to identify strictly de\ufb01ned\nproperties of a limited number of genres, while students detect broadly de\ufb01ned\nproperties of a vast range of genres. Further labellers and studies will be required\nto make any decisive conclusions.Table 3. Human Labelling: Overall accuracy:82.9%\nGenre group Genre no. of items Recall(%) Precision(%)\nBook Academic Monograph 3 0 0\nBook of Fiction 8 37 100\nBook of Poetry 12 67 23\nHandbook 105 88 100\nOther Book 0 0 0\nArticle Abstract 1 100 8\nScientific Research Article 15 47 32\nOther Research Article 36 50 69\nMagazine Article 40 50 61\nNews Report 9 89 89\nShort Composition Fictional Piece 1 100 33\nPoems 37 78 91\nDramatic Script 43 98 100\nEssay 59 68 89\nShort Biographical Sketch 46 100 98\nReview 46 85 83\nSerial Periodicals (Newspaper, Magazine) 21 29 100\nJournals 34 91 86\nConference Proceedings 76 96 99\nNewsletter 28 71 80\nCorrespondence Email 21 90 70\nLetter 67 93 100\nMemo 29 93 71\nTelegram 7 100 78\nTreatise Thesis 66 89 98\nBusiness\/Operational Report 12 75 36\nTechnical Report 52 88 94\nMiscellaneous Report 38 34 81\nTechnical Manual 7 86 27\nInformation Structure List 26 73 86\nCatalogue 51 90 90\nRaw Data 40 73 91\nTable Calendar 30 93 68\nMenu 52 100 96\nForm 114 53 100\nProgramme 29 66 100\nQuestionnaire 61 98 91\nFAQ 71 90 98\nEvidential Document Minutes 94 97 100\nLegal Proceedings 36 50 58\nFinancial Record 7 86 75\nReceipt 8 100 21\nSlips 0 0 0\nContract 10 90 82\nVisual Document Artwork 2 100 13\nCard 9 100 35\nChart 39 82 74\nGraph 14 71 48\nDiagram 6 33 18\nSheet Music 37 100 100\nPoster 23 48 85\nComics 7 100 27\nOther Functional Document Guideline 48 58 93\nRegulations 53 94 91\nManual 43 60 96\nGrantor Project Proposal 45 98 81\nLegal Appeal\/Proposal\/Order 0 0 0\nJob\/Course\/Project Description 62 89 96\nProduct\/Application Description 56 100 89\nAdvertisement 6 33 25\nAnnouncement 12 83 56\nAppeal\/Propaganda 1 100 25\nExam\/Worksheet 22 81 90\nFactsheet 80 86 93\nForum Discussion 38 97 79\nInterview 64 98 97\nNotice 9 89 89\nResume\/CV 100 98 100\nSlides 27 85 92\nSpeech Transcript 71 97 96\n4.1 Precision versus recall\nIn this section we present the recall and precision of student classi\ufb01cation on the\ndata which was given the same label by the secretaries. The results are shown\nin Table 3. Compared to some other classi\ufb01cation tasks (e.g. classi\ufb01cation of\npronouns in [17]), the overall accuracy of 82.9% is a low percentage. However, as\ngenre classi\ufb01cation is a task involving high level conceptual analysis, this seemsa reasonable ageement level. Having said this, the agreement within Scienti\ufb01c\nResearch Article is unexpectedly low. There could be at least two reasons for\nsuch discord between the labellers. For example, there might have been a misun-\nderstanding which caused poor quality in the initial document retrieval exercise,\nor certain genres might inherently be dependent on experience or training and\nare not clearly recognisable by members of other communities. Upon examina-\ntion of the documents, it seems to be that both reasons are in play. For instance,\nnumerous forms were labelled as receipts by students, under the impression that\nreceipts which have not been \ufb01lled are still receipts. Those with a secretarial\nbackground did not share this notion. Likewise, some articles on the subject of\nemail were retrieved as samples of the class Email by the students. On the other\nhand, there was only a single example out of one hundred abstracts collected\nby students which the secretaries, who are not necessarily academically inclined,\nagreed as being an abstract. Nevertheless, the results are encouraging in that\nan 82.9% overall agreement along with the high precision rate of many genres\nsuggest that, even without giving extensive de\ufb01nitions of each genre class, a\nreasonable agreement is already achieved with common genre terms. It should\nbe mentioned, however, that each secretary\u2019s overall accuracy on the agreement\ndata of the other two labellers was also examined and found to be lower at 73.2%\nand 67.5%.\n4.2 Disagreement analysis\nThe groups in Table 4 represent cluster of genres for which frequent cross la-\nbelling was observed. The groups in Table 4 are not exclusive of other confusion.\nThe table is meant to convey the clusters of the most confused genre classes. It\nshould also be noted that two genres may be included in the same cluster, but the\nfrequency at which one is labelled as the other may not be comparable in both\ndirections. For instance, Manual was often given the label Technical Manual but\nnot vice versa. The confusion between Receipt and Form is due to perceiving a\nreceipt form prior to its completion as a sample of Receipt. The groups in Table\n4 suggest that most of the confusion arises within the genre groups (cf. Table\n1), which seems to add partial value to our genre schema.\nTable 4. Genre cross-labelling cluster groups\nGroup Genres\nGroup A Book of Fiction, Poetry Book, Fictional Piece, Poems\nGroup B Magazine Article, Scienti\ufb01c Research Article, Other Research Article\nGroup C Technical Report, Business\/Operational Report, Miscellaneous Report\nGroup D Posters, Artwork, Advertisement\nGroup E Diagram, Graph, Chart\nGroup F Form, Receipt\nGroup G Handbook, Technical Manual, Manual\nGroup H List, Catalogue, Raw Data, Table\nGroup I Legal Proceedings, Legal Appeal\/Proposal\/Order4.3 Improving the corpus\nAcquiring a representative corpus is di\ufb03cult ([4]). Part of the reason for this\nis because representativeness is meaningful only within the context of the task\nto be performed. For example, a well known part-of-speech tagger ([9]), trained\non the well-designed Penn Treebank Wall Street Journal corpus ([20]), fails to\ntag instances of He (Helium) in Astronomy articles correctly ([17]) because the\ntraining data failed to be representative of astronomy articles - the task do-\nmain. As purposes and domains change, we propose that a well-designed corpus\nshould not emphasise representativeness but be based on the level of annotation,\nquali\ufb01cations, and consolidation. Most existing corpora are designed to hold a\nnumber of selected categories populated by samples from well-de\ufb01ned sources,\nupon the agreement of expert knowledge of the categories. Here we would like to\npropose the construction of a di\ufb00erent type of corpus. We set forth the following\nprinciples:\n\u2013 every member of the database must be accompanied by a vector of dimension\nN (the size of the \ufb01nal genre schema) indicating the number of times each\ngenre was assigned to the item by human labellers, and,\n\u2013 labellers from a selected number of characterising groups should be employed\nto label the data, and each instance of a genre assignment should be quali\ufb01ed\nby the group of the labeller.\nThe selection of labellers determines the classi\ufb01cation standard or the policy\none wishes to represent in an automated classi\ufb01cation. If the objective is to\nmodel genre classi\ufb01cation based on common sense, a large number of labellers\nfrom a diverse set of backgrounds should be represented. But, if the objective is\nto design a classi\ufb01er for specialists of a selected domain, this corpus is likely to\nprove inadequate for representing the domain population. A corpus built on the\nabove principles would provide us with greater scope for analysis, for achieving\nrepresentativeness of di\ufb00erent populations, and for \ufb01ne tuning an automated\nsystem, by making transparent:\n\u2013 the con\ufb01dence level of each item\u2019s membership in each genre class,\n\u2013 the labeller\u2019s possible bias by indicating the labeller background, and,\n\u2013 the fact that classi\ufb01cation is not a binary decision (deciding whether or not\nan item is a sample of a class) but a selection of several probable options.\n5 Experiments\n5.1 Data\nThe dataset used in this sections\u2019s experiments consists of the data on which all\nlabellers have agreed in the human labelling experiment described in Section 3.\nThe experiment was conducted over only sixteen of the seventy genres presented\nin Table 1. The range of genres was limited to be more easily comparable to\nearlier experiments in [16], [18], [19]. The results of experiments on the full\nrange of genres will be available after further analysis of the human experiments\nhave been carried out.5.2 Classi\ufb01ers\nIn [16], we reported results on using the Nave Bayes model to detect instances\nof Periodicals, Scienti\ufb01c Research Article, Thesis, Business Report, and Forms\nfrom a pool of documents belonging to nineteen genres. In this paper we have\nabandoned the Nave Bayes Model. The Nave Bayes Model was only chosen as\na preliminary testing ground as it is one of the most basic probabilistic models\navailable. In reality, Nave Bayes is well known to have problems when dealing\nwith features which are not independent and, in the current context, we want to\nidentify features of one genetic feature type, i.e. features which are dependent\non each other, which makes Nave Bayes an inappropriate choice. In its place\nwe have chosen the Random Forest method ([7]), which has been presented as\nbeing e\ufb00ective when dealing with imbalanced data ([8]). We have examined two\nclassi\ufb01ers in this paper:\nImage classi\ufb01er: The \ufb01rst page of the document was sectioned into a sixty-\ntwo by sixty-two grid. Each region on the grid is examined for non-white pixels,\nwhere non-white pixel is de\ufb01ned to be those of a value less than 245. All regions\nwith non-white pixels are labelled 1, while those which are completely white are\nlabelled 0. The choice of sixty-two to de\ufb01ne the size of the grid re\ufb02ects the fact\nthat the level of granularity seemed to be the coarsest level at which some of the\ndocuments were recognisable as belonging to speci\ufb01c genres even by the human\neye. The resulting vector was then probabilistically modeled via the Random\nForrest Decision method, with nineteen trees using the Weka Machine Learning\nToolkit([24]). The motivation for this classi\ufb01er comes from the recognition that\ncertain genres have more (or less) white space in the \ufb01rst page (e.g. the title page\nof the book), and that the page is often more strictly formatted (e.g. slides for\na conference presentation) to catch the attention of the reader (e.g. the reverse\ncolouring on a magazine cover) and introduce them to the type of document at\nhand without detailed examination of the content. Note that another advantage\nof white space analysis is that it is easily applicable to documents of any lan-\nguage and does not depend heavily on character encoding and the accessibility\nof content.\nStyle classi\ufb01er: From a previously collected data set, the union of all words\nfound in the \ufb01rst page, of half or more of the \ufb01les in each genre, was retrieved\nand compiled into a list. For each document a vector is constructed using the\nfrequency of each word in the compiled list. The collection of vectors is modeled\nagain via the Random Forrest Decision method with nineteen trees using the\nWeka toolkit([24]). The feature are di\ufb00erent from the classi\ufb01ers in [16] and [17]\nwhich also incorporated the number of words, font sizes and variations. This\nclassi\ufb01er is intended to capture frequency of words common to all genres as well\nas words which only appear in some genres. The contention of this paper is that\neven words which appear in a wide variety of genres may be a signi\ufb01cant metric,\nwhen the frequency is also taken into consideration. A typical example of its\nweight is embodied in the fact that forms are less likely to contain as many\nde\ufb01nite or inde\ufb01nite articles as theses. The two classi\ufb01ers were used to predictthe genres of documents spanning over sixteen genres. The genres that were\nexamined and the results are given in Section 6.\nTable 5. Image classi\ufb01er: overall accuracy 38.37%\nGroup Genre no. of items Recall (%) Precision(%)\nArticle Magazine Article 20 5 17\nScienti\ufb01c Research Article 7 0 0\nOther Research Article 18 67 50\nBook Book of Fiction 3 25 18\nInformation Structure Form 60 50 40\nList 19 0 0\nSerial Periodicals (Newspaper,Magazine) 6 14 33\nNewsletter 20 6 13\nTreatise Technical report 46 11 19\nBusiness\/Operational Report 9 0 0\nThesis 59 84 56\nEvidential Document Minutes 91 77 47\nOther Functional Document Slides 23 73 94\nProduct\/Application Description 56 10 14\nGuideline 28 0 0\nFactsheet 69 33 25\nTable 6. Style classi\ufb01er: overall accuracy 69.96%\nGroup Genre no. of items Recall (%) Precision (%)\nArticle Magazine Article 20 47 82\nScienti\ufb01c Research Article 7 0 0\nOther Research Article 18 39 56\nBook Book of Fiction 3 0 0\nInformation Structure Form 60 88 69\nList 10 47 57\nSerial Periodicals (Newspaper, Magazine) 6 0 0\nNewsletter 20 18 100\nTreatise Technical Report 46 73 74\nBusiness\/OperationalReport 9 25 67\nThesis 59 86 72\nEvidential Document Minutes 91 99 99\nOther Functional Document Slides 23 27 40\nProduct\/Application Description 56 80 62\nGuideline 28 25 35\nFactsheet 69 62 67\n6 Results\nThe results of the image classi\ufb01er in Table 5 do not show the same level of\naccuracy level as the results previously given in [19]. However, the results in\nour previous work was of binary classi\ufb01cation. As distinctions between larger\nnumber of genres have to be made in the current context, it is more likely that\nany single class resembles another without sharing its identity.\nThe style classi\ufb01er (cf. Table 6) shows a surprisingly high level of accuracy\non the new data, suggesting that the frequency of words may be a key feature indetecting genres. The prediction of Minutes is particularly noticeable. Parallel\nto the results in [16] and [19], Periodicals are better recognised by the image\nclassi\ufb01er than the style classi\ufb01er. Slides also seem to show the same tendency. As\nmight be expected, genres which depend heavily on the content such as Technical\nReport fare much better with the word frequency model. Another observation\nto be made from the results of Tables 5 and 6 is that the image classi\ufb01er seems\nto fare better on a small amount of data (e.g. periodicals, book of \ufb01ction).\n7 Error analysis\nFor a thorough error analysis, a well-designed experimental corpus is required.\nUntil the human labelling experiment in Section 3 is taken forward to include\nsu\ufb03cient data and labels from more labellers for in-depth analysis, we can not\nclaim to have the necessary corpus. Nevertheless, many of the errors can already\nseen to be due to a lack of data (e.g. Book of Fiction), while others seem inex-\norably linked to the fact that semantic content plays a heavier role than surface\nstyles and structure (e.g. Guideline). An immediately recognisable \ufb02aw in the\nimage representation of the document is that it is too strictly dependent on the\nexact location of non-white space. Ideally, we would like to detect the topol-\nogy of the image representation such as the existence of lines, closed loops and\nother shapes. The location is only loosely relevant. The current representation is\ntoo rigid and should be modi\ufb01ed to represent the general topology, rather than\npoint-\ufb01xed pixel values. Also, more sophisticated linguistic pattern analysis is\nenvisioned to be necessary for the next stage of the stylistic word frequency\nmodel.\n8 Conclusions\nThe results in this paper can be summarised by the following:\n\u2013 Genre classi\ufb01cation as an abstract task is ill-de\ufb01ned: there is much disagree-\nment even between human labellers and a detailed study of further human\nexperiments are required to determine conditions which make the task mean-\ningful.\n\u2013 A fair amount of automated genre classi\ufb01cation can be achieved by examin-\ning the frequency of genre words.\n\u2013 The image of the \ufb01rst page alone seems to perform better classi\ufb01cation than\nstyle, when only a small amount of training data is availabble.\n\u2013 The performance of the image classi\ufb01er appears to complement the perfor-\nmance of the style classi\ufb01er.\nIt is evident that research in this area is still in its infancy. There is much to\ndo. As we have noted elsewhere, the other classi\ufb01ers based on language modeling,\nsemantic analysis and domain knowledge should be tested for further compari-\nson. Furthermore, proper error analysis and further gathering of documents andhuman labelling analysis is required to establish a well designed corpus. To max-\nimise sustainability in an environment where technology changes at a rapid rate,\nthe technical format information (e.g. PDF speci\ufb01cation, or metadata extracted\nby pd\ufb01nfo) should only be included in the extraction tool algorithm at the last\nstage of improvement. The classi\ufb01cation of documents into a small number of\ntypes has its limits. To be able to utilise these classi\ufb01ers constructed under dif-\nferent conditions in the larger context of information management, we need to\nbe able to construct systems that can group classi\ufb01ers into clusters of similar\ntasks, or more speci\ufb01cally, into clusters of co-dependent classi\ufb01ers.\n9 Acknowledgments\nThis research is collaborative. DELOS: Network of Excellence on Digital Li-\nbraries (G038-507618)3 funded under the European Commissions IST 6th Frame-\nwork Programmeprovides a key framework and support, as does the UK\u2019s Digital\nCuration Centre. The DCC4 is supported by a grant from the Joint Information\nSystems Committee (JISC)5 and the e-Science Core Programme of the Engineer-\ning and Physical Sciences Research Council (EPSRC)6. The EPSRC supports\n(GR\/T07374\/01) the DCCs research programme. We would also like to thank\nAndrew McHugh, Adam Rusbridge, and Laura Brouard, who organised the web\nsupport and supervised the administrative process for the human labelling ex-\nperiments.\nReferences\n1. Bagdanov, A., Worring, M.: Fine-grained document genre classi\ufb01cation using \ufb01rst\norder random graphs. In Proceedings 6th International Conference on Document\nAnalysis and Recognition ISBN 0-7695-1263-1 (2001) 79-83.\n2. Barbu, E., Heroux P., Adam, S., Turpin, E.: Clustering document images using\na bag of symbols representation. In Proceedings 8th International Conference on\nDocument Analysis and Recognition ISBN ISSN 1520-5263 (2005) 1216-1220.\n3. Bekkerman, R., McCallum, A., Huang, G.: Automatic categorization of email into\nfolders. benchmark experiments on enron and sri corpora. Technical Report IR-418,\nCentre for Intelligent Information Retrieval, UMASS. (2004).\n4. Biber, D.: Representativeness in Corpus Design. Literary and Linguistic Computing\n8(4) doi:10.1093\/llc\/8.4.243 (1993) 243-257\n5. Biber, D.: Dimensions of Register Variation:a Cross-Linguistic Comparison. Cam-\nbridge University Press, New York, (1995).\n6. Boese, E. S.: Stereotyping the web: genre classi\ufb01cation of web documents. Master\u2019s\nthesis, Colorado State University (2005).\n7. Breiman, L.: Random forests. Machine Learning, 45 (2001) 5-32.\n3 http:\/\/www.delos.info\n4 http:\/\/www.dcc.ac.uk\n5 http:\/\/www.jisc.ac.uk\n6 http:\/\/www.epsrc.ac.uk8. Chao, C., Liaw, A., Breiman, L.: Using random forest to learn imbalanced data.\nhttp:\/\/www.stat.berkeley.edu\/ breiman\/RandomForests\/ (2004).\n9. Curran, J., Clark, S.: Investigating GIS and Smoothing for Maximum Entropy Tag-\ngers. In Proceedings Aunnual Meeting European Chapter of the Assoc. of Compu-\ntational Linguistics (2003) 91-98.\n10. Finn, A., Kushmerick. N.: Learning to classify documents according to genre. Jour-\nnal of American Society for Information Science and Technology 57(11) (2006) 1506-\n1518.\n11. Giu\ufb00rida, G., Shek, E., Yang, J.: Knowledge-based metadata extraction from\npostscript \ufb01le. In Proceedings 5th ACM Intl. Conf. Digital Libraries. (2000) 77-\n84.\n12. Han, H., Giles, L., Manavoglu, E., Zha, H., Zhang, Z., Fox, E. A.: Automatic doc-\nument metadata extraction using support vector machines. In 3rd ACM\/IEEECS\nConf. Digital Libraries. (2003) 37-48.\n13. Karlgren, J., Cutting, D.: Recognizing text genres with simple metric using dis-\ncriminant analysis. In Proceedings 15th Conf. Comp. Ling. 2 (1994) 1071-1075.\n14. Ke, S. W., Bowerman, C.: Perc: A personal email classi\ufb01er. In Proceedings 28th\nEuropean Conf. Information Retrieval (ECIR 2006) (2006) 460-463.\n15. Kessler, G., Nunberg, B., Schuetze, H.: Automatic detection of text genre. In Pro-\nceedings 35th Ann. Meeting ACL (1997) 32-38.\n16. Kim, Y., Ross, S.: Genre classi\ufb01cation in automated ingest and appraisal metadata.\nIn J. Gonzalo, editor, Proceedings European Conf. on advanced technology and\nresearch in Digital Libraries 4172 LNCS (2006) 63-74.\n17. Kim, Y., Webber, B.: Implicit reference to citations: A study of astronomy papers.\nPresentation at the 20th CODATA international Conference, Beijing, China. (2006).\nhttp:\/\/eprints.erpanet.org\/ paper id 115\n18. Kim, Y., Ross, S.: Detecting family resemblance: Automated genre clas-\nsi\ufb01cation. Data Science Journal 6 ISSN 1683-1470 (2007) S172-S183.\nhttp:\/\/www.jstage.jst.go.jp\/article\/dsj\/6\/0\/s172\/ pdf\n19. Kim Y., Ross, S.: The Naming of Cats: Automated genre clas-\nsi\ufb01cation. International Journal for Digital Curation 2(1)(2007).\nhttp:\/\/www.ijdc.net\/.\/ijdc\/article\/view\/24\n20. Marcus, M. P., Santorini, B., Mareinkiewicz, M. A.: Building a large annotated\ncorpus of English: the Penn Treebank. Computational Linguistics 19(2) (1994) 313-\n330.\n21. Rauber, A., Mller-Kgler, A.: Integrating automatic genre analysis into digital li-\nbraries. In Proceedings ACM\/IEEE Joint Conf. Digital Libraries, Roanoke, VA\n(2001) 1-10.\n22. Ross, S., Hedstrom, M.: Preservation research and sustainable digital libraries.\nInternational Journal of Digital Libraries. DOI: 10.1007\/s00799-004-0099-3 (2005).\n23. Thoma, G.: Automating the production of bibliographic records. Technical report,\nLister Hill National Center for Biomedical Communication, US National Library of\nMedicine (2001).\n24. Witten, H. I., Frank, E.: Data mining: Practical machine learning tools and tech-\nniques. 2nd Edition, Morgan Kaufmann, San Francisco (2005)."}
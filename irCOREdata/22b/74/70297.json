{"doi":"10.1109\/ISWC.2004.40","coreId":"70297","oai":"oai:eprints.lancs.ac.uk:12528","identifiers":["oai:eprints.lancs.ac.uk:12528","10.1109\/ISWC.2004.40"],"title":"Spine versus Porcupine: a Study in Distributed Wearable Activity Recognition","authors":["Van Laerhoven, Kristof","Gellersen, Hans"],"enrichments":{"references":[{"id":16313821,"title":"A Decision-Theoretic Generalisation of On-line Learning and an Application to Boosting\u201d. In","authors":[],"date":"1997","doi":"10.1006\/jcss.1997.1504","raw":"Y. Freund and R. E. Schapire. \u201cA Decision-Theoretic Generalisation of On-line Learning and an Application to Boosting\u201d. In Journal of Computer and System Sciences, 55(1), pp.119-139, August 1997.","cites":null},{"id":16313839,"title":"D\u00e9tection des activit\u00e9s quotidiennes \u00e0 l'aide des s\u00e9parateurs \u00e0 Vaste Marge.","authors":[],"date":"2003","doi":null,"raw":"G. Loosli, Canu, S. and Rakotomamonjy, A. 2003. D\u00e9tection des activit\u00e9s quotidiennes \u00e0 l'aide des s\u00e9parateurs \u00e0 Vaste Marge. RJCIA, France, pp. 139-152.","cites":null},{"id":16313815,"title":"Fiber Computing\u201d.","authors":[],"date":null,"doi":"10.4028\/www.scientific.net\/kem.206-213.937","raw":"O. Cakmakci, M. Koyuncu and M. Eber-Koyuncu. \u201cFiber Computing\u201d. In Proc. of the Workshop on Distributed and Disappearing User Interfaces in Ubiquitous Computing, CHI 2001, Seattle, WA, USA.","cites":null},{"id":16313827,"title":"Indoor navigation using a diverse set of cheap, wearable sensors\u201d.","authors":[],"date":"1999","doi":"10.1109\/iswc.1999.806640","raw":"A. R. Golding and N. Lesh, \u201cIndoor navigation using a diverse set of cheap, wearable sensors\u201d. In Proceedings of the third International Symposium on Wearable Computers, pp. 29-36. 1999.","cites":null},{"id":16313858,"title":"Kinetic Energy Powered Computing \u2013 an Experimental Feasibility Study\u201d.","authors":[],"date":"2003","doi":"10.1109\/iswc.2003.1241389","raw":"T. von B\u00fcren, P. Lukowicz, and G. Tr\u00f6ster. \u201cKinetic Energy Powered Computing \u2013 an Experimental Feasibility Study\u201d.  In Proceedings of the Seventh International Symposium on Wearable Computers (ISWC\u201903), pp. 22-24. New York, 2003.","cites":null},{"id":16313831,"title":"Multi-Sensor Activity Context Detection for Wearable Computing\u201d. In","authors":[],"date":"2003","doi":"10.1007\/978-3-540-39863-9_17","raw":"N. Kern and B. Schiele. \u201cMulti-Sensor Activity Context Detection for Wearable Computing\u201d. In Proc. Of European Symposium on Ambient Intelligence, 2003, Eindhoven, The Netherlands.","cites":null},{"id":16313855,"title":"Multi-Sensor Context Aware Clothing\u201d.","authors":[],"date":"2002","doi":"10.1109\/iswc.2002.1167218","raw":"K. Van Laerhoven, A. Schmidt and H.-W. Gellersen \u201cMulti-Sensor Context Aware Clothing\u201d. In Proceedings of the Sixth International Symposium on Wearable Computers (ISWC\u201902), Seattle, 2002.","cites":null},{"id":16313842,"title":"Pulsed Neural Networks\u201d.","authors":[],"date":"2001","doi":null,"raw":"W. Maass and C. M. Bishop. \u201cPulsed Neural Networks\u201d. The MIT Press. 2001.","cites":null},{"id":16313888,"title":"Resistive Fibre-Meshed Transducers\u201d.","authors":[],"date":"2003","doi":"10.1109\/iswc.2003.1241412","raw":"R. Wijesiriwardana, T. Dias and S. Mukhopadhyay. \u201cResistive Fibre-Meshed Transducers\u201d. In Proceedings of the Seventh International Symposium on Wearable Computers (ISWC\u201903), pp.200-209. New York, 2003.","cites":null},{"id":16313824,"title":"Spiking Neuron Models\u201d.","authors":[],"date":"2002","doi":"10.1017\/cbo9780511815706.005","raw":"W. Gerstner, and W. Kistler. \u201cSpiking Neuron Models\u201d. Cambridge University Press. 2002.","cites":null},{"id":16313844,"title":"The \u2018Porcupine\u2019 prototype building instructions: http:\/\/ubicomp.lancs.ac.uk\/~kristof\/research\/notes\/porcup","authors":[],"date":null,"doi":null,"raw":"The \u2018Porcupine\u2019 prototype building instructions: http:\/\/ubicomp.lancs.ac.uk\/~kristof\/research\/notes\/porcup","cites":null},{"id":16313850,"title":"The \u2018Spine\u2019 prototype building instructions: http:\/\/ubicomp.lancs.ac.uk\/~kristof\/research\/notes\/spine","authors":[],"date":null,"doi":null,"raw":"The \u2018Spine\u2019 prototype building instructions: http:\/\/ubicomp.lancs.ac.uk\/~kristof\/research\/notes\/spine","cites":null},{"id":16313836,"title":"The Design and Implementation of Electrically Heated Clothing.\u201d","authors":[],"date":"2001","doi":"10.1109\/iswc.2001.962136","raw":"K. Kukkonen, T. Vuorela, J. Rantanen, O. Ryyn\u00e4nen, A. Siili, and J. Vanhala. \u201cThe Design and Implementation of Electrically Heated Clothing.\u201d In Proceedings of the Fifth International Symposium on Wearable Computers (ISWC\u201901), Zurich, 2001.","cites":null},{"id":16313847,"title":"Towards Detection of Human Motion\u201d.","authors":[],"date":"2000","doi":"10.1109\/cvpr.2000.855904","raw":"Y. Song, X. Feng and P. Perona. \u201cTowards Detection of Human Motion\u201d. In IEEE  Proc. of Conf. Computer Vision and Pattern Recognition, vol I, pp. 810-817, Hilton Head Island, South Carolina, June, 2000.","cites":null},{"id":16313833,"title":"Wearable Sensing to Annotate Meeting Recordings\u201d.","authors":[],"date":"2002","doi":"10.1109\/iswc.2002.1167247","raw":"N. Kern, B. Schiele, H. Junker, P. Lukowicz, and G. Tr\u00f6ster. \u201cWearable Sensing to Annotate Meeting Recordings\u201d. In Proceedings of the Sixth International Symposium on Wearable Computers (ISWC\u201902), pp. 186-196, Seattle, 2002.","cites":null},{"id":16313818,"title":"Wearable Sensor Badge & Sensor Jacket for Context Awareness\u201d.","authors":[],"date":null,"doi":"10.1109\/iswc.1999.806681","raw":"J. Farringdon, A. Moore, N. Tilbury, J. Church and P. Biemond. \u201cWearable Sensor Badge & Sensor Jacket for Context Awareness\u201d. In Proceedings of the Third International Symposium on Wearable Computers (ISWC\u201999), San Francisco, pp.107-113.","cites":null},{"id":16313852,"title":"What Shall We Teach Our Pants?\u201d.","authors":[],"date":"2000","doi":"10.1109\/iswc.2000.888468","raw":"K. Van Laerhoven and O. Cakmakci, \u201cWhat Shall We Teach Our Pants?\u201d. In Proceedings of the Fourth International Symposium on Wearable Computers (ISWC 2000), Atlanta, 2000.","cites":null}],"documentType":{"type":1}},"contributors":[],"datePublished":"2004-11","abstract":"This paper seeks to explore an alternative and more embedded-oriented approach to the recognition of a person\u2019s motion and pose, using sensor types that can easily be distributed in clothing. A large proportion of this type of research so far has been carried out with carefully positioned accelerometers, resulting in fairly good recognition rates. An alternative approach targets a more pervasive sensing vision where the clothing is saturated with small, embedded sensors. By increasing the quantity of sensors, while decreasing their individual information quality, a preliminary comparative study between the two approaches looks at the pros, cons, and differences in algorithm requirements","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/70297.pdf","fullTextIdentifier":"http:\/\/eprints.lancs.ac.uk\/12528\/1\/iswc_2004.pdf","pdfHashValue":"7b09cae9a0a36c4f5e262832f38cf14bc069afdc","publisher":"IEEE Press","rawRecordXml":"<record><header><identifier>\n    \n    \n      oai:eprints.lancs.ac.uk:12528<\/identifier><datestamp>\n      2018-01-24T02:09:45Z<\/datestamp><setSpec>\n      7374617475733D707562<\/setSpec><setSpec>\n      7375626A656374733D51:5141:51413735<\/setSpec><setSpec>\n      74797065733D626F6F6B5F73656374696F6E<\/setSpec><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Spine versus Porcupine: a Study in Distributed Wearable Activity Recognition<\/dc:title><dc:creator>\n        Van Laerhoven, Kristof<\/dc:creator><dc:creator>\n        Gellersen, Hans<\/dc:creator><dc:subject>\n        QA75 Electronic computers. Computer science<\/dc:subject><dc:description>\n        This paper seeks to explore an alternative and more embedded-oriented approach to the recognition of a person\u2019s motion and pose, using sensor types that can easily be distributed in clothing. A large proportion of this type of research so far has been carried out with carefully positioned accelerometers, resulting in fairly good recognition rates. An alternative approach targets a more pervasive sensing vision where the clothing is saturated with small, embedded sensors. By increasing the quantity of sensors, while decreasing their individual information quality, a preliminary comparative study between the two approaches looks at the pros, cons, and differences in algorithm requirements.<\/dc:description><dc:publisher>\n        IEEE Press<\/dc:publisher><dc:date>\n        2004-11<\/dc:date><dc:type>\n        Contribution in Book\/Report\/Proceedings<\/dc:type><dc:type>\n        NonPeerReviewed<\/dc:type><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/eprints.lancs.ac.uk\/12528\/1\/iswc_2004.pdf<\/dc:identifier><dc:relation>\n        http:\/\/dx.doi.org\/10.1109\/ISWC.2004.40<\/dc:relation><dc:identifier>\n        Van Laerhoven, Kristof and Gellersen, Hans (2004) Spine versus Porcupine: a Study in Distributed Wearable Activity Recognition. In: Eighth International Symposium on Wearable Computers ISWC 2004. IEEE Press, pp. 142-150.<\/dc:identifier><dc:relation>\n        http:\/\/eprints.lancs.ac.uk\/12528\/<\/dc:relation><\/oai_dc:dc><\/metadata><\/record>","journals":null,"language":{"code":"en","id":9,"name":"English"},"relations":["http:\/\/dx.doi.org\/10.1109\/ISWC.2004.40","http:\/\/eprints.lancs.ac.uk\/12528\/"],"year":2004,"topics":["QA75 Electronic computers. Computer science"],"subject":["Contribution in Book\/Report\/Proceedings","NonPeerReviewed"],"fullText":"Spine versus Porcupine: a Study in Distributed Wearable Activity Recognition \n \nKristof Van Laerhoven and Hans-Werner Gellersen \nComputing Department \nLancaster University \nLA1 4YR Lancaster, United Kingdom \n \n{kristof, hwg}@comp.lancs.ac.uk \n \n \nAbstract \n \nThis paper seeks to explore an alternative and more \nembedded-oriented approach to the recognition of a \nperson\u2019s motion and pose, using sensor types that can \neasily be distributed in clothing. A large proportion of \nthis type of research so far has been carried out with \ncarefully positioned accelerometers, resulting in fairly \ngood recognition rates. An alternative approach targets \na more pervasive sensing vision where the clothing is \nsaturated with small, embedded sensors. By increasing \nthe quantity of sensors, while decreasing their individual \ninformation quality, a preliminary comparative study \nbetween the two approaches looks at the pros, cons, and \ndifferences in algorithm requirements. \n1. Introduction \nThe most popular approach for determining a person\u2019s \nposture, motions, and activity is to use external tracking \nmethods that employ cameras, RF beacons, or similar \nsensors that monitor the body [14] or markers on the \nbody [1]. This method is fairly precise, but also most \ndemanding in terms of setting up the infrastructure, \nmaintaining the hardware and algorithm complexity. \n \nThis has especially consequences for the cost and the \napplicability of such systems: motion capture and \ntracking platforms are rarely used beyond CAD \nanimation or medical purposes, where precision and \nabsolute position is required. Despite a large interest in \ntracking people and their activities through distributed \nsensors, the complexity and reliance on fixed sensors in \nthe environment makes it fairly impractical for daily use. \n \nNomadic, body worn systems have, in reaction, \nextensively been researched and argued for in the last \ndecade [7][16]. Having a wearable-only monitoring \nsystem that recognizes and records a wearer\u2019s daily \nactivities is of substantial value: for instance cross-\nchecking activity patterns versus ECG readings from \nimplanted sensors for wearable monitoring of heart \npatients [19], automatic creation of diaries listing what \nthe person was doing when and for how long [16], or \nactivity-driven temperature regulation for \u2018smart\u2019 \nclothing [10]. In general, activity is a valuable \ncomponent in context aware systems. \n \nFrom early research prototypes, strapped accelerometers \nhave been used to monitor the motion and orientation of \n\u2018points of interest\u2019 on the body and to correlate this to \nactivities. Only recently, \u2018smart textiles\u2019-focused research \nin wearable computing (e.g., [20]) has offered an \nalternative vision featuring miniature sensors that are \ndistributed and integrated in clothing, using weaving \nstructure or the very fibers in the textile as sensors. \n \nThis paper argues that embedding and distributing \nsensors in clothing could be more practical than using \nstrapped-on sensors, and assumes that scores of sensors \nproviding simply binary information could be \nincorporated and interfaced in clothing. We aim to \ninvestigate how the data from such binary, but highly \ndistributed sensors would perform in an activity \nrecognition scenario. \n2. A Comparison in Hardware \nThe two sensor types that were used in this study are \naccelerometers (or acceleration sensors) and ball switches \n(a.k.a. tilt switches). This section introduces both, and \ncompares the requirements and consequences of choosing \neither sensor as far as the cost in hardware resources is \nconcerned.  \n2.1. The Accelerometer  \nAside from automotive applications (e.g., shock and \nimpact detection for airbag deployment), accelerometers \ncan be found in portable and wearable input devices, as \nwell as in a large proportion of wearable sensing \nresearch. This sensor can be thought of as a ball that is \nattached to two springs on opposite sides, and which is \nplaced in a cylinder to limit its movement in two \ndirections, as depicted in Figure 1a. The output of the \naccelerometer is in this metaphor the ball\u2019s position \nwithin the cylinder: shaking the cylinder to the left and \nright will move the ball\u2019s position, but tilting it will do so \nas well (to a lesser extent). These two effects are referred \nto as dynamic and static acceleration respectively.   \n2.2. The Ball Switch  \nThe ball switch or tilt switch has historically been \npopular in pinball and arcade machines as a simple way \nto prevent players from cheating; the sensor contains a \nconductive roller ball that closes a switch inside a hollow \ncylinder when the machine is tilted over a certain \nthreshold (see Figure 1b). The information that this \nbinary sensor provides in terms of orientation and motion \nis very minimal, but combining several ball switches may \nboost this sensor\u2019s output. Many variations on this type of \nsensor exist, using gas, mercury or having a slightly \ndifferent switch mechanism (e.g., a mechanical \u2018toggle\u2019). \n \n \n2.3. Specific Implementations and Comparison  \nThe scope of this paper is not wide enough to perform an \nabsolute assessment into various types of accelerometers \nand binary tilt sensors. Instead, we offer two prototype \nsensor-platforms that should be sufficiently characteristic \nto indicate where the two correspond and differ. \n2.3.1. Accelerometers: The Spine \nThe Spine is a progression of a 30-accelerometer outfit \nconstructed earlier [17], and uses the same sensor \nmodules. The new PIC microcontroller (an 18F452 from \nMicrochip) is pin-compatible with the previous 16F877, \nbut operates at twice the clock speed (40Mhz) and has \nmore memory. The number of sensors has been reduced \nto 20 to allow a faster and more reliable throughput of \nsensor data. The 2D acceleration sensors (ADXL202JE \nfrom Analog Devices) are placed at approximately 10 cm \ndistances from each other, making a total length of the \nspine around one meter, sufficient to strap to an average \narm or leg. The core unit is able to read all accelerometer \nvalues at least 50 times per second via the serial port, \nwhich should be more than enough for our purposes; \nhigher speeds can be obtained by changing the serial \noutput modus (i.e., in binary) or the individual \naccelerometers. The origin of the name should become \nobvious looking at the two spines in Figure 2 below. \n \n \nFigure 2. Two Spines with their main units open to reveal \nbattery and processing board, straps in the background.  \n2.3.2. Ball Switches: The Porcupine \nThe ball switch is mainly used independently to reveal \nwhether the object it is attached to is tilted over a certain \nangle or not. As a switch, it can easily be implemented in \ncircuits to wake up a processor whenever it changes its \nstate, and it needs only a tiny proportion of the \naccelerometer\u2019s power. Size-wise, the classic ball switch \nis large compared to most accelerometers, but it requires \nless additional components and could potentially be \nshrunk to a size below that of the accelerometer.  \n \n \nFigure 3. One of the first prototypes of the Porcupine, \nshowing how each of the nine ball switches is positioned.  \n \nThe prototype that was built for this paper\u2019s experiment \ncontains nine ball switches that have been placed in 45 \ndegree increments of each other in three perpendicular \nplanes (see Figure 3): in the first plane (X), four ball \nswitches are enough to cover 45 degree increments in all \ndirections (see Figure 4), the second plane (Y) needs only \nSprings \nTube Ball \nFigure 1. The abstract diagrams for the respective \nmodels of a) an accelerometer and b) a ball switch. \nConductive \nBall Tube \na) b) \nx\ny \nz\nthree additional ones, and the third plane (Z) only two \n(as the planes overlap). The result is a collection of tilt \nswitches that provide coarse-grained orientation; it is \nharder to determine whether they are any good at the \ndetection of motion from just the hardware description \u2013 \nthis will be part of the investigation in the algorithms \nsection.  \n \n \n \nThe Porcupine (Figure 3, left) is driven by a \nmicrocontroller board (running a PIC16F876 from \nMicrochip) with serial and RF communication (BIM2 \nfrom Radiometrix) capabilities. In the experiment, the \nPorcupines were connected to a serial bus running at \n115200 baud, through which all sensor data was \ncommunicated since mid-air packet collisions limited the \nwireless output in earlier trials. One acted as master, \npolling for 3-byte\n1\n data packets from each of the other \nnine Porcupines, and forwarding it wirelessly to an RF \nbase station in the immediate area of the experiments.  \n2.3.3. Measurements and Summary \nA basic comparison between 1 Spine (20 accelerometers) \nand 10 Porcupines (90 ball switches) is summarized in \nTable 1. Advantages of the ball switches lie in their \nsimplicity: they are easy to interface with low-cost \nmicrocontrollers and do not need A\/D conversions, their \npower requirements are much lower, and the speeds at \nwhich their states can be read on microcontroller level \nare faster. Moreover, they are often used to \u2018wake up\u2019 \nmicrocontrollers in a \u2018sleeping\u2019 mode where it only \nrequires a fraction of its normal power. Accelerometers \non the other hand, have a higher resolution for \n                                               \n1\n The nine output bits were encoded in twos complement \nto keep the eventual packet balanced, a necessity in RF \ncommunication to guarantee a \u2018DC free\u2019 transmission. \norientation and their signals produce direct motion \npatterns. Reproducing these numbers can be done with \nthe online building descriptions provided at [15] and \n[13]. \n \nTable 1. Basic implementation characteristics and \ncomparison between sensors from Spine and Porcupine.  \nSensing Platform: \nSpine \n20 accelerometers \n10 Porcupines \n90 ball switches  \nMaximal current 40 mA 22 mA \n.. for one sensor 400 uA 1 uA \nBattery type 9V NiMH 2x 1.5V AA  \nBattery lifetime 4.3 hours 2-3 days \nTime to read all ~2 ms ~2 ms \nCost (per sensor) 8 USD 0.2 USD \nSize (per sensor) 50 mm\n3\n 83 mm\n3\n \nExtra components 20 C, 10 R 90 R \n \nBoth prototype sensing platforms were created \nspecifically for this study, but have since then been used \nfor other studies as well [19]. Although it is not this \npaper\u2019s goal to investigate how both methods perform in \nterms of implementation, it is interesting to point out that \na combination of ball switches might be competitive with \naccelerometers, especially regarding power consumption.  \n3. A Comparison in Algorithms \nIn machine learning terms, this paper\u2019s main ambition is \nto balance and analyze the information from a set of \nscalar sensors and that from a larger set of binary \nsensors. This will be studied in particular in a scenario of \nbody-centric activity recognition by motion- and \norientation sensors.  \n3.1. Experiment Setup \nData from both sensing platforms was logged for a \nvariety of activities. As the experiments are meant to be \npart of only an indicative study, specifically designed \nscripts were followed (i.e., no real-life monitoring was \ndone) and only basic activities were considered. Four of \nthe activities were static: Lying, Kneeling, Sitting, \nStanding, and the other six: Walking, Running, \nClimbing Stairs, Descending Stairs, Bicycling and \nJumping, had typical short patterns of movement.  \n \nThese activities were chosen because of (1) their presence \nin related work (e.g., [4][7][9][16]) and (2) their \nrepetitive nature. The former motivation hints at the \nproposed scenario where these types of activities might \nbe valuable, whereas the latter aims towards a particular \ndesign of algorithms, where prototypical data to be \n0000 1000 1100 1110 \n1111 0111 \nFigure 4. How a combination of four tilt switches can \ngive a coarse (45 degree) indication of tilt in one plane; \nthe switch outputs are depicted below the graphs. \n0011 0001 \nclassified is expected to be temporally simple and \nrepetitive, but complex in dimension (multiple sensors \ncontributing to the classification). All sensors were \nstrapped to the legs of the test subjects, primarily because \nthe size of the utilised prototypes did not allow any \nembedding into clothes; we argue that this has little \neffect for these early studies. \n \n  \nFigure 5. Test subjects were asked to perform certain \nbasic activities from a set script, such as climbing stairs \nor bicycling - scenes from the Spines\u2019 data logging.  \n \nTo create a generic dataset (i.e., one that can also be used \nfor future experiments), test subjects were asked to wear \nthe two platforms, and follow the experiment\u2019s script \nseveral times per platform in order to have sufficient data \n(especially for the Porcupines\u2019 switches). Figure 5 \nillustrates how the data was captured, using two Spines \nin a strapped-on setup similar to previous studies. Figure \n6 shows similar scenes using Porcupines. \n \n  \nFigure 6. The activities were chosen so that their data \nwas either practically static (e.g., standing), or contained \nrepetitive patterns (e.g., walking) - scenes from the \nPorcupines\u2019 data logging.  \nThe next sections will explore whether the logged sensor \ndata contains enough information to distinguish these \nactivities and, if so, how easy it is to extract them using \nalgorithms.  \n3.2. Algorithm Overview \nThe algorithms in this section will be grouped per type, \nand more attention will be given to algorithms that might \npossibly perform better for the high-dimensional binary \ndata that the Porcupines\u2019 ball switches produce.  \n \nBefore going into specific algorithm descriptions, \nthough, it is already possible to describe some issues and \ncharacteristics we can expect regarding the ball switches\u2019 \ndata. Ball switches first of all tend to show \u2018bouncing\u2019 \nbehaviour when they are about to tilt: although a \nPorcupine may be perfectly still, some of the switches \ncould still alternate between the zero- and one states, \nproviding possibly serious noise. This problem extends to \nany binary sensor: noise has a more damaging effect on a \nper sensor basis. Figure 7 shows example data from one \nPorcupine to illustrate this. \nA second issue is the lack of characteristic peaks or other \nfeatures that can easily be extracted from the Porcupine \ndata. Figure 8 shows a typical set of acceleration time \nseries from \u2018climbing stairs\u2019, which is almost trivial to \nclassify when certain characteristic peaks are extracted \nfor this activity. This type of pre-processing is less \nobvious with binary data. Take the clustering of sensor \ndata for instance: calculating an average position \nbetween binary objects is rarely done. Rather than \ncalculating centroids, a bit string that minimizes the sum \nof the distance to all objects, called medoid, is used.  \n \n0\n1\nX\n1\n0\n1\nX\n2\n0\n1\nX\n3\n0\n1\nX\n4\n0\n1\nY\n1\n0\n1\nY\n3\n0\n1\nY\n4\n0\n1\nZ\n1\n0 5000 10000 150\n0\n1\nZ\n3\nsitting standing walking running \n \nFigure 7. Example data from a knee-worn Porcupine: \noutput values (Y axes) versus samples (X axis,~50 Hz). \nNotice the noise during the sitting and standing contexts.  \n1\n51\n101\n151\n201\nS\n1\n0\n5\n0\n1\n0\n0\n1\n5\n0\n2\n0\n0\n2\n5\n0\n3\n0\n0\na\nc\nc\ne\nle\nra\nti\no\nn\n (\nP\nW\n)\nsam ples (50 Hz)\ns\ne\nn\ns\no\nrs\n \nFigure 8. Example data from the right-leg Spine for \nclimbing stairs: output values (Y axes) versus samples (X \naxis,~50 Hz) for all sensors (Z axis). Note the \ncharacteristic \u2018step-up\u2019 peaks for the first sensors (S1). \n3.2.1. Topographic Mapping-based classification \nFor accelerometer-based platforms such as the Spine \ndiscussed in this paper, previous research has been \nfocused on testing machine learning strategies on their \ndata. The proposed algorithms include Gaussian \nmodelling [7], Support Vector Machines [11], Bayesian \nClassifiers [8], and Kohonen Self-Organising Maps [16], \nto name but a few. The preparation and choice of features \nis often a significant part of these studies.  \n \nWe will confine the accelerometer side of the comparison \nto an algorithm based on that discussed in [16], using a \nhierarchical topographic mapping approach (the \nKohonen Self-Organising Map) with basic statistics and \npeak set descriptors as features. This method has shown \nits merit before, and will serve as a typical algorithm \ndeveloped for a potentially large amount of accelerometer \ndata.   \n3.2.2. Spiking Neural Nets, Pulsed Neural Nets \nSpiking [6] or pulsed [12] neural networks are using one \nof the most recent, and more biologically plausible, \nmodels of artificial neurons, working with action \npotentials, or spikes, and their timings, rather than scalar \nvalues. Whereas earlier artificial neurons (often based on \nthe traditional McCulloch-Pitts model) combine \ncontinuous inputs in a weighted sum and activation \nfunction, spiking neurons use a so-called leaky integrator \nthat decreases with time, and increases when it receives a \npulse (see Figure 9 for an illustration). \nIt is our hypothesis that for the last six dynamic activities \n(those with recurring motion patterns) the temporal \npatterns of the switching itself and the knowledge of \nwhich ball switch was triggered are enough to \ncharacterise the activities \u2013 if the distribution and data \nacquisition of the ball switches are sufficient. This \nscheme, where a spike is created each time a binary \nsensor\u2019s state switches, connects seamlessly to a spiking \nneural network\u2019s architecture.  \n \nFigure 9. Typical leaky-integrate-and-fire behaviour of a \nspiking neuron: the action potential increases each time a \nspike arrives, and \u2018fires\u2019 when a certain threshold is met. \nThe time series plot the growing potential p over time for \nthe two inputs below the graph (spiking 3 times in total). \nIn particular, we have used an unsupervised learning rule \nfor these neurons that modifies the weights that connect \nthe inputs to neurons in a single output layer, slightly \nsimilar to the Topographic Self-Organising Map \nimplementation in 2.3.1.  \n3.2.3. Boosting, AdaBoost \nBoosting is a type of learning strategy that fits very well \nwith data coming from a distributed sensing system: It \nconcentrates on combining weak classifiers to come to a \nclassification scheme that usually has a better \nperformance than each of the classifiers individually. \nInstead of trying to design a learning algorithm that is \naccurate over the entire classification space, the focus is \nmore on finding weak \u2018rule of thumb\u2019 type of algorithms \nthat need only to be better than random.  \n \nWe applied a multiclass generalisation of AdaBoost, one \nof the most popular implementations for boosting [5] that \nis traditionally restricted to binary classification, by \ntraining for each activity separately. The boosting \napproach is appealing in our case since we can distribute \nthe weak classifiers locally (i.e., on the Porcupines), and \nhave them send their classification hypotheses, rather \nthan the sensor data, to a central post. We therefore chose \n10 classifiers that estimated the overall activity from the \n9 local ball switches only. In brief, our AdaBoost \nimplementation assigns and updates weights to each \nclassifier per activity, and the final verdict is gotten \nthrough a vote amongst the weighted results. \np\ntt1,1 t1,2 \nt2,1\n3.3. Results \nThe logged data was manually annotated in two passes: \none for marking the data that would be applicable for \nproviding the ground truth, and a second time for \nextracting ground truth data that would be used for \ntraining the classifiers. The latter set was about 25 \npercent of the initial ground truth set. \n \nThe first results are from accelerometer data analysed by \nthe method described in 2.3.1. The results are plotted in \nthe first confusion matrix in Figure 10. It is not \nsurprising to see that the classifier performs well on all \nactivities, given the amount of pre-processing (especially \nthe peak extraction) that evolved from previous research. \nThe merit of these features becomes clearer when \ncharacteristic peak sequences for particular sensors are \nplotted against each other for the more complicated \nactivities (see Figure 11): though close, they are \ndistinctive enough to end up in different clusters, and \nthus in different classes.  \n \n1793 2 1 3 0 1 0 0 0\n19 1128 20 21 3 0 1 2 6\n2 2 1188 5 0 0 0 0 3\n0 1 0 1198 0 0 0 0 1\n2 6 2 1 1012 51 61 40 25\n0 3 0 0 49 877 37 25 9\n7 4 2 0 47 49 1364 19 8\n3 3 0 0 12 9 20 849 4\n9 11 0 0 5 8 4 11 952\nClassification rate: 93.88%\nstanding \nlying down\nkneeling \nsitting \nupstairs \ndownstairs \nw alking \nrunning \nbicycling \n \n728 7 9 10 11 7 9 10 9\n27 562 11 21 18 14 17 15 15\n32 24 490 19 24 27 31 18 35\n11 9 8 622 14 10 10 9 7\n8 6 9 8 498 260 116 140 55\n15 13 11 22 209 539 97 55 39\n14 6 5 13 117 119 771 107 68\n15 11 9 11 132 99 120 349 54\n9 9 3 11 152 89 99 93 485\nClassification rate: 65.24%\nstanding \nlying down\nkneeling \nsitting \nupstairs \ndownstairs \nwalking \nrunning \nbicycling \n \nFigure 10. Confusion matrices for the Spine (left) and \nPorcupine (right) datasets. The cells show the amount of \npositives per activity (with the true positives diagonally), \nthe classification rates show the rate of true positives \nover all activities.  \n \nL2 L2 \nclimbing stairs descending stairs \n1127 49 94 -145 327 -67  82  -288\n1012 52 68 -190 384 -117 110 -255\n1016 51 53 -176 315 -215 82 -114 47\n1024 50 42 -165 305 -194 92 -152 66\n \n786 53 47 -225 247 -88  59 -80 40\n880 60 17 -234 305 -121 117 -85 0 \nL2 \nwalk ing \n \nL2 \nbicycling \n \nFigure 11. Peak characterisation for one accelerometer \n(L2): the numbers underneath the graphs represent the \ntotal area, the length, and the areas of the individual \npeaks of the last two detected peak sets. None were \ndetected for bicycling in this case. The underlined areas \nmark the last two candidate peak sets. \nThe results from the proposed spiking neural network \n(see Figure 10, second confusion matrix) show potential \nfor improvement, but they are reminiscent of early work \non accelerometer-based platforms. Keeping in mind that \nno special features were calculated, and that the raw \nswitches were fused straight into the algorithm, we \nbelieve that this approach could have benefits in on-line \nand embedded algorithms. Especially for the static poses, \nit performs adequately, given the amount of noise present \nfor individual ball switches (e.g., as in Figures 7 and 12). \n \nAfter a more thorough inspection of the data, however, it \nwas noticed that no particular characteristic spike trains \nwere generated: deciding factors seemed rather to be \ndown to simple variance in the on-off switching. This \nindicates that even between our dataset\u2019s more complex \nactivities, such as climbing or descending the stairs, \ndifferent ball switches were triggered, or they were \ntriggered at distinct enough speeds for most of the time.  \n \nTo make this more apparent, a second test with the same \ntopographic map algorithm as for the accelerometers was \nperformed, but with just the average and variance over \nthe last 30 samples as features. Remarkably, the results \nwere comparable to those from the spiking neural net. \nThe results from the AdaBoost approach were also in line \nwith these observations, with an overall classification \nrate of 62%, using the binary variant of distance-\nweighted k nearest neighbours as classifiers. The features \nused were as close as possible to the average (the state \nmost frequently occurring, 0 or 1, during the past 100 \nvalues) and the variance (a counter of all the 1s of the \npast 100 values) per sensor. \n \nThe time complexities and algorithm requirements for \nboth approaches were not really investigated here. It is \nobvious that the performance of the algorithms is \nsufficiently affordable for the high-dimensional binary \ndata in terms of time-complexity and memory \nrequirements: one sample in both cases takes 90 bits for \nthe ball switches, while it requires at least 400 bits for the \naccelerometers. Since the individual channels that need \nto be fused contain low-resolution data, algorithms need \nless memory and time: the algorithms that worked on the \naccelerometer datasets required significantly more time, \nmainly due to the pre-processing.  \n \nOne key disadvantage for the balls switches\u2019 approach \nthat became obvious during the analysis of the \nexperimental data was the lack of visualisation. Just \nhaving binary states makes inspection and manual post-\nannotation of datasets a challenging task (as for example \nin Figure 12).  \n 4. Applications and Outlook \nThe main objective of this work was to investigate the \nconsequences of taking distribution of \u2018dumb\u2019 sensors a \nstep further. It is in that sense important to stress that one \nshould not over-interpret this study as an advocacy for \nthe use of ball switches in activity recognition. Likewise, \nbinary sensors may indeed have practical applications in \nintegrated fabric sensing, but our core motivation for \nchoosing binary sensors was the consequences their data \nhave for sensor fusion algorithms. \nFuture plans do include extended hardware prototypes \nthat combine low-power microcontrollers with miniature \nball switches, reducing the overall size of the Porcupines, \nand enabling embedding in clothing and scaled-up \ndistributed networks; a next version is set to be almost a \ntenth smaller than the current prototype. Simultaneously, \nmicrocontroller implementations for the discussed \nalgorithms are underway as well.   \nGiven that both types of sensors are similar in concept, it \ncould be argued that the ball switches could have been \nsimulated from accelerometer data. This is not entirely \ncertain, however, and simulation of the ball switches \nwould have weakened effectively any data comparison. \nThe most interesting outcome of the experiments was the \napparent lack of need for complex pre-processing or \nalgorithms for the Porcupines\u2019 dataset. Although it was \nhypothesised that feature information could be hidden in \npatterns of the switch signals, no evidence for this was \nfound in our dataset; a higher sampling rate or different \ntypes of ball switches might be required to confirm this.  \n \nIt also has to be stressed that this first dataset is too small \nto be dependable. In order to generalise from this study, \nmore and longer-term datasets need to be recorded. It is \nin this regard also interesting to speculate how well \nalgorithms and such a large distribution of binary sensors \nwould cope with problems such as concept drift, where \nthe activities would slowly change with relation to the \nsensors (due to tiredness, shifting clothes, etc.): a wide \ndistribution might be an advantage in this case.  \n \nThere are a number of other ways to advance this study. \nWe are exploring scalability issues for classification \nalgorithms and cross-usage of training data over multiple \npeople (i.e., generalisation concerns). Widening the study \nto other classification problems, such as explicit gesture \nrecognition or activity prediction, would be a further area \nof future work. The datasets that this research has been \n(and will be) generating are available for download via \nthe CommonSense website [3].  F\nig\nu\nre\n 1\n2\n. \nV\nis\nu\na\nlis\na\nti\no\nn\n f\no\nr \na\nn\nn\no\nta\nte\nd\n d\na\nta\n f\nro\nm\n t\nh\ne\n t\no\np\n (\nh\nip\n-w\no\nrn\n) \nP\no\nrc\nu\np\nin\ne\n, \np\nlo\ntt\ne\nd\n a\ns\n s\nw\nit\nc\nh\n s\nta\nte\n (\no\nn\n\/o\nff\n) \nv\ne\nrs\nu\ns\n t\nim\ne\n. \nA\nll \nfo\nu\nr \ns\nw\nit\nc\nh\ne\ns\n p\ne\nr \np\nla\nn\ne\n a\nre\n \nin\nc\nlu\nd\ne\nd\n t\no\n f\na\nc\nili\nta\nte\n b\na\nc\nk\ntr\na\nc\nk\nin\ng\n o\nf \ns\ne\nn\ns\no\nrs\n f\nro\nm\n s\nig\nn\na\nls\n. \n(N\no\nte\n t\nh\na\nt \nth\nis\n l\ne\na\nd\ns\n t\no\n r\ne\nd\nu\nn\nd\na\nn\nc\ny\n f\no\nr \nX\n2\n a\nn\nd\n Y\n2\n, \nX\n4\n a\nn\nd\n Z\n2\n, \na\nn\nd\n Y\n4\n a\nn\nd\n Z\n4\n).\n \n0\n1\n0\n0\n \n2\n0\n0\n \n3\n0\n0\n \n4\n0\n0\n \n5\n0\n0\n6\n0\n0\nX\n1\nX\n2\nX\n3\nX\n4\nY\n1\nY\n2\nY\n3\nY\n4\nZ\n1\nZ\n2\nZ\n3\nZ\n4\nti\nm\ne\n (\ns\ne\nc\no\nn\nd\ns\n)\nPorcupine 1 (top)\nw\nal\nki\nng\nw\nal\nki\nng\n d\now\nns\nta\nirs\n \nw\nal\nki\nng\n u\nps\nta\nirs\n \nru\nnn\nin\ng\nbi\ncy\ncl\nin\ng\nly\nin\ng \ndo\nw\nn\nkn\nee\nlin\ng\nsi\ntti\nng\nst\nan\ndi\nng\n u\npr\nig\nht\nst\nan\ndi\nng\n u\npr\nig\nht\nst\nan\ndi\nng\n u\npr\nig\nht\nst\nan\ndi\nng\n u\npr\nig\nht\nan\nno\nta\ntio\nn \n5. Conclusions \nOur aim was to study an approach towards activity \nrecognition inspired by the \u2018smart clothing\u2019 paradigm, \ni.e., under the assumption that the sensors are high in \nnumber and heavily distributed throughout the fabric, yet \nindividually providing only a tiny chunk of information. \nCompared to the more classic methods of placing sensors \nwhere they are absolutely needed, we argue that this \napproach would be more suitable for scenarios where \nstrapped sensors might be obtrusive, or where optimal \nsensor location is hard to discover beforehand (e.g., in \nskirts or dresses).  \nTwo experimental prototypes were introduced to \ndemonstrate and compare the traditional and proposed \napproaches. Although the experiments do not constitute \nany actual proof of theory, they do indicate that \ndistributing sensors - even while heavily neglecting their \naccuracy - could be valuable and that more, distinctive, \nresearch is needed in algorithms for simple sensor fusion.  \nAcknowledgements \nThis work is supported by the UbiMon [19] and \nCommonSense [3] projects, funded by the UK\u2019s \nDepartment of Trade and Industry (DTI), and the \nEngineering and Physics Science Research Council \n(EPSCR) respectively. The DIY Smart-Its hardware \nplatforms used for the ball switch experiments were \nprovided with the help of Albrecht Schmidt, Martin \nStrohbach, and Nicolas Villar and were in part built by \nTara Matthews; Contributions of David Molyneaux and \nDikaios Papadogkonas were also vital in the preparation \nof the data logging. \nReferences \n[1] 3DEqualizer: http:\/\/www.3dequalizer.com\/  \n[2] O. Cakmakci, M. Koyuncu and M. Eber-Koyuncu. \u201cFiber \nComputing\u201d. In Proc. of the Workshop on Distributed \nand Disappearing User Interfaces in Ubiquitous \nComputing, CHI 2001, Seattle, WA, USA. \n[3] CommonSense: http:\/\/ubicomp.lancs.ac.uk\/commonsense  \n[4] J. Farringdon, A. Moore, N. Tilbury, J. Church and P. \nBiemond. \u201cWearable Sensor Badge & Sensor Jacket for \nContext Awareness\u201d. In Proceedings of the Third \nInternational Symposium on Wearable Computers \n(ISWC\u201999), San Francisco, pp.107-113. \n[5] Y. Freund and R. E. Schapire. \u201cA Decision-Theoretic \nGeneralisation of On-line Learning and an Application to \nBoosting\u201d. In Journal of Computer and System Sciences, \n55(1), pp.119-139, August 1997.  \n[6] W. Gerstner, and W. Kistler. \u201cSpiking Neuron Models\u201d. \nCambridge University Press. 2002. \n[7] A. R. Golding and N. Lesh, \u201cIndoor navigation using a \ndiverse set of cheap, wearable sensors\u201d. In Proceedings of \nthe third International Symposium on Wearable \nComputers, pp. 29-36. 1999. \n[8] N. Kern and B. Schiele. \u201cMulti-Sensor Activity Context \nDetection for Wearable Computing\u201d. In Proc. Of \nEuropean Symposium on Ambient Intelligence, 2003, \nEindhoven, The Netherlands. \n[9] N. Kern, B. Schiele, H. Junker, P. Lukowicz, and G. \nTr\u00f6ster. \u201cWearable Sensing to Annotate Meeting \nRecordings\u201d. In Proceedings of the Sixth International \nSymposium on Wearable Computers (ISWC\u201902), pp. 186-\n196, Seattle, 2002. \n[10] K. Kukkonen, T. Vuorela, J. Rantanen, O. Ryyn\u00e4nen, A. \nSiili, and J. Vanhala. \u201cThe Design and Implementation of \nElectrically Heated Clothing.\u201d In Proceedings of the Fifth \nInternational Symposium on Wearable Computers \n(ISWC\u201901), Zurich, 2001. \n[11] G. Loosli, Canu, S. and Rakotomamonjy, A. 2003.  \nD\u00e9tection des activit\u00e9s quotidiennes \u00e0 l'aide des \ns\u00e9parateurs \u00e0 Vaste Marge. RJCIA, France, pp. 139-152. \n[12] W. Maass and C. M. Bishop. \u201cPulsed Neural Networks\u201d. \nThe MIT Press. 2001.  \n[13] The \u2018Porcupine\u2019 prototype building instructions: \nhttp:\/\/ubicomp.lancs.ac.uk\/~kristof\/research\/notes\/porcup   \n[14] Y. Song, X. Feng and P. Perona. \u201cTowards Detection of \nHuman Motion\u201d. In IEEE Proc. of Conf. Computer \nVision and Pattern Recognition, vol I, pp. 810-817, \nHilton Head Island, South Carolina, June, 2000.  \n[15] The \u2018Spine\u2019 prototype building instructions: \nhttp:\/\/ubicomp.lancs.ac.uk\/~kristof\/research\/notes\/spine   \n[16] K. Van Laerhoven and O. Cakmakci, \u201cWhat Shall We \nTeach Our Pants?\u201d. In Proceedings of the Fourth \nInternational Symposium on Wearable Computers (ISWC \n2000), Atlanta, 2000. \n[17] K. Van Laerhoven, A. Schmidt and H.-W. Gellersen \n\u201cMulti-Sensor Context Aware Clothing\u201d. In Proceedings \nof the Sixth International Symposium on Wearable \nComputers (ISWC\u201902), Seattle, 2002. \n[18] T. von B\u00fcren, P. Lukowicz, and G. Tr\u00f6ster. \u201cKinetic \nEnergy Powered Computing \u2013 an Experimental \nFeasibility Study\u201d.  In Proceedings of the Seventh \nInternational Symposium on Wearable Computers \n(ISWC\u201903), pp. 22-24. New York, 2003. \n[19] UbiMon: http:\/\/www.ubicare.org\/projects-ubimon.shtml  \n[20] R. Wijesiriwardana, T. Dias and S. Mukhopadhyay. \n\u201cResistive Fibre-Meshed Transducers\u201d. In Proceedings of \nthe Seventh International Symposium on Wearable \nComputers (ISWC\u201903), pp.200-209. New York, 2003. \n"}
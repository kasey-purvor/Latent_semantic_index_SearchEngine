{"doi":"10.1093\/logcom","coreId":"65468","oai":"oai:dro.dur.ac.uk.OAI2:5745","identifiers":["oai:dro.dur.ac.uk.OAI2:5745","10.1093\/logcom"],"title":"Logical and complexity-theoretic aspects of models of computation with restricted access to arrays.","authors":["Stewart,  I. A."],"enrichments":{"references":[],"documentType":{"type":1}},"contributors":["Cooper,  S.B.","Kent,  T.F.","L&#246;we,  B.","Sorbi,  A."],"datePublished":"2009-02-01","abstract":"We study a class of program schemes, NPSB, in which, aside from basic assignments, non-deterministic guessing and while loops, we have access to arrays; but where these arrays are binary write-once in that they are initialized to 'zero' and can only ever be set to 'one'. We show, amongst other results, that: NPSB can be realized as a vectorized Lindstr\\\"{o}m logic; there are problems accepted by program schemes of NPSB that are not definable in the bounded-variable infinitary logic $\\mathcal{L}^\\omega_{\\infty\\omega}$; all problems accepted by the program schemes of NPSB have asymptotic probability $1$; and on ordered structures, NPSB captures the complexity class $\\mbox{{\\bf L}}^{\\mbox{\\scriptsize{\\bf NP}\\normalsize}}$. We give equivalences (on the class of all finite structures) of the complexity-theoretic question 'Does $\\mathbf{NP}$ equal $\\mathbf{PSPACE}$?', where the logics and classes of program schemes involved in the equivalent statements define or accept only problems with asymptotic probability $0$ or $1$ and so do not cover many computationally trivial problems. The class of program schemes NPSB is actually the union of an infinite hierarchy of classes of program schemes. Finally, when we amend the semantics of our program schemes slightly, we find that the classes of the resulting hierarchy capture the complexity classes $\\Sigma^p_i$ (where $i\\geq 2$) of the Polynomial Hierarchy {\\bf PH}","downloadUrl":"https:\/\/core.ac.uk\/download\/pdf\/65468.pdf","fullTextIdentifier":"http:\/\/dro.dur.ac.uk\/5745\/1\/5745.pdf","pdfHashValue":"be2f8954215905b5de644b37cf791e91123035b6","publisher":"Oxford University Press","rawRecordXml":"<record><header><identifier>\n  \n    \n      oai:dro.dur.ac.uk.OAI2:5745<\/identifier><datestamp>\n      2011-11-10T11:15:24Z<\/datestamp><\/header><metadata><oai_dc:dc xmlns:oai_dc=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/\" xmlns:dc=\"http:\/\/purl.org\/dc\/elements\/1.1\/\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc\/ http:\/\/www.openarchives.org\/OAI\/2.0\/oai_dc.xsd\" ><dc:title>\n    \n      \n        Logical and complexity-theoretic aspects of models of computation with restricted access to arrays.<\/dc:title><dc:creator>\n        Stewart,  I. A.<\/dc:creator><dc:description>\n        We study a class of program schemes, NPSB, in which, aside from basic assignments, non-deterministic guessing and while loops, we have access to arrays; but where these arrays are binary write-once in that they are initialized to 'zero' and can only ever be set to 'one'. We show, amongst other results, that: NPSB can be realized as a vectorized Lindstr\\\"{o}m logic; there are problems accepted by program schemes of NPSB that are not definable in the bounded-variable infinitary logic $\\mathcal{L}^\\omega_{\\infty\\omega}$; all problems accepted by the program schemes of NPSB have asymptotic probability $1$; and on ordered structures, NPSB captures the complexity class $\\mbox{{\\bf L}}^{\\mbox{\\scriptsize{\\bf NP}\\normalsize}}$. We give equivalences (on the class of all finite structures) of the complexity-theoretic question 'Does $\\mathbf{NP}$ equal $\\mathbf{PSPACE}$?', where the logics and classes of program schemes involved in the equivalent statements define or accept only problems with asymptotic probability $0$ or $1$ and so do not cover many computationally trivial problems. The class of program schemes NPSB is actually the union of an infinite hierarchy of classes of program schemes. Finally, when we amend the semantics of our program schemes slightly, we find that the classes of the resulting hierarchy capture the complexity classes $\\Sigma^p_i$ (where $i\\geq 2$) of the Polynomial Hierarchy {\\bf PH}.<\/dc:description><dc:subject>\n        Finite model theory<\/dc:subject><dc:subject>\n         Descriptive complexity<\/dc:subject><dc:subject>\n         Program schemes.<\/dc:subject><dc:publisher>\n        Oxford University Press<\/dc:publisher><dc:source>\n        Journal of logic and computation, 2009, Vol.19(1), pp.217-242 [Peer Reviewed Journal]<\/dc:source><dc:contributor>\n        Cooper,  S.B.<\/dc:contributor><dc:contributor>\n        Kent,  T.F.<\/dc:contributor><dc:contributor>\n        L&#246;we,  B.<\/dc:contributor><dc:contributor>\n        Sorbi,  A.<\/dc:contributor><dc:date>\n        2009-02-01<\/dc:date><dc:type>\n        Article<\/dc:type><dc:type>\n        PeerReviewed<\/dc:type><dc:identifier>\n        dro:5745<\/dc:identifier><dc:identifier>\n        issn:0955-792X<\/dc:identifier><dc:identifier>\n        issn: 1465-363X<\/dc:identifier><dc:identifier>\n        doi:10.1093\/logcom\/exn025 <\/dc:identifier><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/5745\/<\/dc:identifier><dc:identifier>\n        http:\/\/dx.doi.org\/10.1093\/logcom\/exn025<\/dc:identifier><dc:format>\n        application\/pdf<\/dc:format><dc:identifier>\n        http:\/\/dro.dur.ac.uk\/5745\/1\/5745.pdf<\/dc:identifier><dc:accessRights>\n        info:en-repo\/semantics\/openAccess<\/dc:accessRights><\/oai_dc:dc><\/metadata><\/record>","journals":[{"title":null,"identifiers":["issn: 1465-363X"," 1465-363x","issn:0955-792X","0955-792x"]}],"language":{"code":"en","id":9,"name":"English"},"relations":[],"year":2009,"topics":["Finite model theory","Descriptive complexity","Program schemes."],"subject":["Article","PeerReviewed"],"fullText":"Durham Research Online\nDeposited in DRO:\n29 June 2009\nVersion of attached file:\nAccepted Version\nPeer-review status of attached file:\nPeer-reviewed\nCitation for published item:\nStewart, I. A. (2009) \u2019Logical and complexity-theoretic aspects of models of computation with restricted\naccess to arrays.\u2019, Journal of logic and computation., 19 (1). pp. 217-242.\nFurther information on publisher\u2019s website:\nhttp:\/\/dx.doi.org\/10.1093\/logcom\/exn025\nPublisher\u2019s copyright statement:\nAdditional information:\nAn extended abstract of this paper appeared in: Proc. of Computation and Logic in the Real World, Third Conference\non Computability in Europe (CiE 2007) (ed. S.B. Cooper, T.F. Kent, B. Lwe, A. Sorbi) (2007) 324-331.\nUse policy\nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior permission or charge, for\npersonal research or study, educational, or not-for-profit purposes provided that:\n\u2022 a full bibliographic reference is made to the original source\n\u2022 a link is made to the metadata record in DRO\n\u2022 the full-text is not changed in any way\nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders.\nPlease consult the full DRO policy for further details.\nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom\nTel : +44 (0)191 334 3042 \u2014 Fax : +44 (0)191 334 2971\nhttp:\/\/dro.dur.ac.uk\n  \nDurham Research Online \n \nDeposited in DRO: \n29 June 2009 \n \nPeer-review status: \nPeer-reviewed \n \nPublication status of attached file: \nAccepted for publication \n \nCitation for published item: \nStewart, I. A. (2009) 'Logical and complexity-theoretic aspects of models of computation with \nrestricted access to arrays.', Journal of logic and computation., 19 (1). pp. 217-242. \n \nFurther information on publisher\u2019s website: \nhttp:\/\/dx.doi.org\/10.1093\/logcom\/exn025 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nUse policy \n \nThe full-text may be used and\/or reproduced, and given to third parties in any format or medium, without prior \npermission or charge, for personal research or study, educational, or not-for-profit purposes provided that : \n \n\uf0a7 a full bibliographic reference is made to the original source \n\uf0a7 a link is made to the metadata record in DRO \n\uf0a7 the full-text is not changed in any way \n \nThe full-text must not be sold in any format or medium without the formal permission of the copyright holders. \n \nPlease consult the full DRO policy for further details. \n \nDurham University Library, Stockton Road, Durham DH1 3LY, United Kingdom \nTel : +44 (0)191 334 2975 | Fax : +44 (0)191 334 2971 \nhttp:\/\/dro.dur.ac.uk \nLogical and complexity-theoretic aspects of models of\ncomputation with restricted access to arrays\nIain A. Stewart\nDepartment of Computer Science, University of Durham,\nScience Labs, South Road, Durham DH1 3LE, U.K.\ne-mail: i.a.stewart@durham.ac.uk\nMay 17, 2008\nAbstract\nWe study a class of program schemes, NPSB, in which, aside from basic assignments, non-\ndeterministic guessing and while loops, we have access to arrays; but where these arrays\nare binary write-once in that they are initialized to \u2018zero\u2019 and can only ever be set to \u2018one\u2019.\nWe show, amongst other results, that: NPSB can be realized as a vectorized Lindstro\u00a8m\nlogic; there are problems accepted by program schemes of NPSB that are not definable in\nthe bounded-variable infinitary logic L\u03c9\n\u221e\u03c9; all problems accepted by the program schemes\nof NPSB have asymptotic probability 1; and on ordered structures, NPSB captures the\ncomplexity class LNP. We give equivalences (on the class of all finite structures) of the\ncomplexity-theoretic question \u2018Does NP equal PSPACE?\u2019, where the logics and classes of\nprogram schemes involved in the equivalent statements define or accept only problems with\nasymptotic probability 0 or 1 and so do not cover many computationally trivial problems.\nThe class of program schemes NPSB is actually the union of an infinite hierarchy of classes\nof program schemes. Finally, when we amend the semantics of our program schemes slightly,\nwe find that the classes of the resulting hierarchy capture the complexity classes \u03a3pi (where\ni \u2265 2) of the Polynomial Hierarchy PH.\nkeywords: finite model theory; descriptive complexity; program schemes.\n1 Introduction\nFinite model theory is essentially the study of logical definability over finite struc-\ntures. An important sub-area of finite model theory is the relationship between the\nlogical definability of classes of finite structures and computational complexity the-\nory; that is, descriptive complexity. This relationship is best exemplified by Fagin\u2019s\nseminal result that a problem, i.e., a class of finite structures over the same signa-\nture, can be defined by a sentence of existential second-order logic if, and only if, the\nproblem (or, to be more precise, an encoding of it) can be accepted by a polynomial-\ntime non-deterministic Turing machine [14]. Not only does this \u2018logical approach\u2019 to\ncomputational complexity benefit from years of research in model theory which have\nprovided new tools and methods not obviously available if one restricts oneself to the\n1\nTuring-based world of computation, but it has provoked a reexamination of logical\nquestions and a development of new tools and methods specifically related to and\ndesigned for finite structures.\nLogical characterizations of complexity classes in descriptive complexity tend to\nassume that there is an underlying built-in ordering of the data. This ordering is gen-\nerally used to simulate (the tape-head movements of) an appropriate Turing machine.\nPerhaps the most compelling open problem in descriptive complexity is whether there\nexists a logic capturing P on unordered data (that is, on the class of all finite struc-\ntures) or whether one must always assume that the data is ordered (as is the case in,\nfor example, the Immerman-Vardi-Sazonov characterization of P as the class of prob-\nlems definable in first-order logic extended with an inflationary fixed-point operator\nand with a built-in successor relation [22, 30, 42]).\nAn advantage of adopting a logical framework for the study of computational com-\nplexity is that one can delineate fundamental issues, like whether the data is ordered,\nwhich is extremely difficult in traditional complexity theory where the Turing ma-\nchine model, working on strings as it does, insists that the data be ordered. Nowhere\nis this delineation more necessary than in database theory where the data indepen-\ndence principle means that database query languages can not assume any underlying\nordering of the data. It is probably in the realm of query languages where finite\nmodel theory and database theory interact most. There are numerous paradigms for\nthe design of database query languages including: logic, where the query languages\nare nothing other than logics, often the same logics as studied in finite model the-\nory, such as first-order logic extended with an inflationary [8] or a least fixed-point\n[20] operator; programming languages , where there are variables taking relations as\ntheir values, where variables can take values derived from first-order combinations of\nexisting variables, i.e., relations, and where there is some mechanism for iteration,\nsuch as the while language [8], the while+ language [3] and the languages of [27] ob-\ntained by extending first-order logic with for-loops; and logic programming, where\nnew relation variables are available, where there are rules to change the values of the\nnew relation variables and where there is an appropriate semantics so as to explain\npotential anomalies in the applications of the rules, such as Datalog\u00ac with stratified\nsemantics [9], well-founded semantics [18] and inflationary fixed-point semantics [1].\nIt turns out that many of the resulting query languages are equivalent. For example,\nthe following query languages are all equivalent (on unordered data): first-order logic\nextended with an inflationary or a least fixed-point operator; the while+ programming\nlanguage; and Datalog\u00ac with either well-founded or fixed-point semantics (on ordered\ndata, these query languages all capture the complexity class P). We refer the reader\nto [43] for more on this and for an excellent discussion of the general relationship\nbetween database theory and finite model theory.\nAbiteboul and Vianu [4, 5] initiated an attempt to deal with the difficulty, men-\ntioned above, that Turing machines work on ordered data and remain the mainstay\nof computational complexity theory yet database theory insists that all of its query\nlanguages must necessarily work on unordered data. Their work was subsequently de-\nveloped in [6], in collaboration with Vardi, where the relational machine was defined.\nA relational machine works directly on an input structure (and not its encoding as a\nstring) and has both a traditional Turing machine component and a facility to manip-\nulate relations using relational algebra operations. Abiteboul, Vianu and Vardi used\n2\ntheir machines to define relational complexity classes and proved that their class Pr ,\nnamely relational polynomial-time, is nothing other than first-order logic extended\nwith an inflationary fixed-point operator, and that their class PSPACEr, namely\nrelational polynomial-space, is nothing other than first-order logic extended with a\npartial fixed-point operator (we reiterate that these equivalences are on unordered\ndata). Moreover, they also showed the remarkable equivalence that Pr = PSPACEr\nif, and only if, P = PSPACE.\nIn recent papers, we have developed new programming languages (for unordered\ndata) based around the paradigm of a program scheme. Program schemes are more\ncomputational in flavour than are formulae of traditional logics yet they remain\namenable to logical manipulation. The concept of a program scheme originates from\nthe 1970\u2019s with work of, for example, Constable and Gries, Friedman, and Hewitt\nand Paterson [10, 15, 29], and complexity-theoretic considerations of such program\nschemes were subsequently studied by, for example, Harel and Peleg, Jones and Much-\nnik, and Tiuryn and Urzyczyn [21, 25, 41]. Our analysis of program schemes differs\nfrom what has gone before in that we are always concerned with finite structures\n(and not infinite ones as was often the case previously) and we do not assume that\nthe elements of our finite structures are necessarily linearly ordered. Our program\nschemes differ from the programming languages of database theory in that variables\ntake elements of the input structure as values and not relations. Working with such\na \u2018low-level\u2019 computational device allows us to incorporate well-known programming\nconstructs such as stacks, arrays, queues, non-determinism, while-loops, for-loops,\nand so on, in our programming languages. Furthermore, as the computations of our\ndevices manipulate the values of variables, i.e., elements of the input structure, in a\nprecise and well-defined way, we have managed to obviate the need to use existing,\nmore established paradigms; for example, we do not need to have any experience of\nbounded-variable logics and their relationship with various pebble games in order to\nperform our analysis.\nLet us summarize some of the results we have so far established (all results men-\ntioned below are on the class of all finite structures, except where explicitly stated\notherwise). In [7], we considered a hierarchy of classes of program schemes, NPSS,\nwhere these program schemes involve assignments, while-loops and non-deterministic\nguessing and have access to a stack, and showed that this hierarchy is proper and (the\nunion of it) has exactly the same expressive power as stratified fixed-point logic and\nstratified Datalog (and so on ordered structures captures P). On the class of strongly-\nconnected locally-ordered digraphs, the class of connected planar embeddings and\nthe class of triangulations, NPSS still captures exactly the polynomial-time solvable\nproblems [40]. If we remove access to the stack then the resulting class of program\nschemes, NPS, is equivalent to Immerman\u2019s transitive closure logic. In [39], we show\nthat the class of program schemes NPS augmented with arrays, NPSA, captures the\nclass of problems defined by the sentences of a logic formed by extending first-order\nlogic with a particular uniform (or vectorized) sequence of Lindstro\u00a8m quantifiers, and\nthat this logic has a zero-one law. However, we show that there are problems defin-\nable in a basic fragment of this logic which are not definable in the bounded-variable\ninfinitary logic L\u03c9\u221e\u03c9. As a consequence, the class of problems (accepted by the pro-\ngram schemes of) NPSA is not contained in the class of problems defined by the\nsentences of partial fixed-point logic, even though in the presence of a built-in suc-\n3\ncessor relation, both NPSA and partial fixed-point logic capture the complexity class\nPSPACE. In [38], we prove that a basic class of program schemes augmented with\naccess to a queue, NPSQ(1), is exactly the class of recursively enumerable problems\nthat are closed under extensions. We define an infinite hierarchy of classes of program\nschemes for which NPSQ(1) is the first class and the union of the classes of which\nis the class NPSQ. We show that the class of problems NPSQ is the union of the\nclasses of problems defined by the sentences of all vectorized Lindstro\u00a8m logics formed\nusing operators whose corresponding problems are recursively enumerable and closed\nunder extensions; as a result, every problem in this class has asymptotic probability\n0 or 1. Finally, in [17], we define a (deterministic) class of program schemes RFDPS\nconstructed around notions of forall-loops, repeat-loops and arrays. We show that the\nclass of problems RFDPS properly contains the class of problems definable in infla-\ntionary fixed-point logic (for example, the well-known problem Parity is in RFDPS)\nand that there is a strict, infinite hierarchy of classes of problems within RFDPS (the\nunion of which is RFDPS) parameterized by the depth of nesting of forall-loops in\nour program schemes. Suffice it to say, examining classes of program schemes formed\nusing well understood programming constructs has resulted in new, natural \u2018logics\u2019\nthat seemingly have hitherto arisen in neither in finite model theory nor database\ntheory.\nIn this paper, in an attempt to \u2018bridge the gap\u2019 between the polynomial-time\nworld of NPSS and the polynomial-space world of NPSA, we modify the program\nschemes of NPSA so that all arrays are \u2018binary write-once\u2019 in the sense that all array\nelements are initially set at \u2018zero\u2019 and the only modification to any array element\nallowed is to set it to \u2018one\u2019. The resulting class of program schemes is denoted NPSB,\nwith the levels of the underlying hierarchy being NPSB(i), for i \u2265 1. We show that\nNPSB retains some of the properties of NPSA: like NPSA, NPSB can be realized\nas a vectorized Lindstro\u00a8m logic, and NPSB(1) contains problems not definable in\nL\u03c9\u221e\u03c9 (every problem accepted by a program scheme of NPSB trivially has asymptotic\nprobability 0 or 1 as NPSB is a sub-class of NPSA); but whereas both NPSA and\nNPSA(1) capture PSPACE on ordered structures, NPSB(1) capturesNP and NPSB\ncaptures LNP, with the NPSB hierarchy collapsing to NPSB(3). We compare the\nrelative expressibilities of the classes of program schemes NPSA(1) and NPSB(1).\nWe show that NPSA(1) = PSPACE \u2229 EXT and NPSB(1) = NP \u2229 EXT , where\nEXT is the class of problems closed under extensions (and hence every non-trivial\nproblem in EXT has asymptotic probability 1); thus, the question of whether NP is\nequal to PSPACE is equivalent to the question of whether the two classes of program\nschemes NPSB(1) and NPSA(1) accept the same class of problems on the class of all\nfinite structures (of course, NPSB(1) and NPSA(1) also coincide with fragments of\nthe Lindstro\u00a8m logics mentioned above).\nFinally, we amend the semantics of the class of program schemes NPSB in that\nwe allow the current values of arrays to be \u2018passed across\u2019 to other program schemes\n(appearing as, what amounts to, subroutines in the main program scheme) in a com-\nputation (hitherto, the semantics has only allowed the current values of variables to\nbe passed across). We denote the class of program schemes with this amended seman-\ntics as NPSBp (the subscript reflects the polynomially many values passed across to\nthe component program schemes). We show that on the class of all finite structures,\nNPSBp(2i \u2212 1) = NPSBp(2i) and captures \u03a3pi , i.e., the ith level of the Polynomial\n4\nHierarchy PH, for i \u2265 2, and so NPSBp captures PH itself.\nThis paper is structured as follows. In the next section, we outline the definitions\nrelating to this paper before we define our classes of program schemes in Section\n3. In Section 4, we identify the class of program schemes NPSB with a vectorized\nLindstro\u00a8m logic. In Section 5, we consider our program schemes and logics on ordered\nstructures and compare the relative computational power of the classes of program\nschemes NPSB(1) and NPSA(1) (on the class of all finite structures). We amend the\nsemantics of our program schemes in Section 6 before presenting our conclusions and\ndirections for further research in Section 7.\n2 Preliminaries and program schemes\nThe main reference texts for the basic concepts, notions and results of finite model\ntheory are [12, 24, 26] and it is to these books that we refer the reader for such\ninformation. Ordinarily, a signature \u03c3 is a tuple \u3008R1, . . . , Rr, C1, . . . , Cc\u3009, where each\nRi is a relation symbol, of arity ai, and each Cj is a constant symbol. First-order logic\nover the signature \u03c3, FO(\u03c3), consists of those formulae built from atomic formulae\nover \u03c3 using \u2227, \u2228, \u00ac, \u2200 and \u2203; and FO = \u222a{FO(\u03c3) : \u03c3 is some signature}.\nA finite structure A over the signature \u03c3, or \u03c3-structure, consists of a finite uni-\nverse or domain |A| together with a relation Ri of arity ai, for every relation symbol\nRi of \u03c3, and a constant Cj \u2208 |A|, for every constant symbol Cj (by an abuse of\nnotation, we do not usually distinguish between constants and relations, CAj and R\nA\ni ,\nand constant and relation symbols, Cj and Ri). A finite structure A whose domain\nconsists of n distinct elements has size n, and we denote the size of A by |A| also\n(this does not cause confusion). We only ever consider finite structures of size at least\n2, and the set of all finite structures of size at least 2 over the signature \u03c3 is denoted\nSTRUCT(\u03c3). A problem over some signature \u03c3 consists of a subset of STRUCT(\u03c3)\nthat is closed under isomorphism; that is, if A is in the problem then so is every\nisomorphic copy of A. Throughout, all our structures are finite.\nThe class of problems defined by the sentences of FO is denoted by FO also,\nand we do likewise for other logics. It is widely acknowledged that, as a means for\ndefining problems, first-order logic leaves a lot to be desired; especially when we\nhave in mind developing a relationship between computational complexity and logical\ndefinability. For example, every first-order definable problem can be accepted by a\nlog-space deterministic Turing machine (where structures are encoded as strings) yet\nthere are problems in the complexity class L (log-space) which can not be defined in\nfirst-order logic (one such being the problem consisting of all those structures, over\nany signature, that have even size). Consequently, a number of methods have been\ndeveloped so as to increase definability.\nOne method is to extend first-order logic using a vectorized sequence of Lindstro\u00a8m\nquantifiers corresponding to some problem \u2126; or, as we prefer, an operator \u2126 for short.\nSuppose that \u2126 is over the signature \u03c3, where \u03c3 = \u3008R1, . . . , Rr, C1, . . . , Cc\u3009, as above.\nThe logic (\u00b1\u2126)\u2217[FO] consists of those formulae built using the usual constructs of\nfirst-order logic and also the operator \u2126, where the operator \u2126 is applied as follows.\n\u2022 Suppose that \u03c81(x1,y), . . . , \u03c8r(xr ,y) are formulae of (\u00b1\u2126)\n\u2217[FO] such that:\n\u2013 each xi is a kai-tuple of distinct variables, for some fixed k \u2265 1;\n5\n\u2013 y is an m-tuple of distinct variables, for some m \u2265 0, each of which is\ndifferent from any variable of x1, . . . ,xr; and\n\u2013 all free variables of any \u03c8i are contained in either xi or y.\n\u2022 Suppose that d1, . . . ,dc are k-tuples of variables and constants (which need not\nbe distinct).\n\u2022 Then:\n\u2126[\u03bbx1\u03c8(x1,y), . . . ,xr\u03c8r(xr,y)](d1, . . . ,dc)\nis a formula of (\u00b1\u2126)\u2217[FO] whose free variables are the variables of y together\nwith any other variables appearing in d1, . . . ,dc.\nIf \u03a6 is a sentence of the form \u2126[\u03bbx1\u03c81(x1), . . . ,xr\u03c8r(xr)](d1, . . . ,dc), as above, over\nsome signature \u03c3\u2032 then we interpret \u03a6 in a \u03c3\u2032-structure A as follows (note that as \u03a6\nis a sentence, the variables of y are absent and the tuples d1, . . . ,dc, which are only\nthere if there are constant symbols in \u03c3, consist entirely of constant symbols of \u03c3\u2032).\n\u2022 The domain of the \u03c3-structure \u03a6(A) is |A|k.\n\u2022 The relation Ri of \u03a6(A) is defined via:\n\u2013 for any u \u2208 |\u03a6(A)|ai = |A|kai , Ri(u) holds in \u03a6(A) if, and only if, \u03c8i(u)\nholds in A.\n\u2022 The constant Cj of \u03a6(A) is defined via:\n\u2013 Cj is the interpretation of the tuple of constants dj in A.\nWe define that A |= \u03a6 if, and only if, \u03a6(A) \u2208 \u2126 (the situation where \u03a6 has free\nvariables is similar except that \u03a6 is interpreted in expansions of \u03c3\u2032-structures by\nan appropriate number of constants). We call logics such as (\u00b1\u2126)\u2217[FO] vectorized\nLindstro\u00a8m logics . We shall also be interested in fragments of vectorized Lindstro\u00a8m\nlogics where: the formulae are such that the operator \u2126 does not appear within the\nscope of a negation sign, namely \u2126\u2217[FO] (the positive fragment of (\u00b1\u2126)\u2217[FO]); and\nfurther the formulae are such that there are no nestings of the operator \u2126, namely\n\u21261[FO] (the positive unnested fragment of (\u00b1\u2126)\u2217[FO]).\nIt can be the case that (a fragment of) a vectorized Lindstro\u00a8m logic (\u00b1\u2126)\u2217[FO]\nhas a very straightforward normal form; a normal form which obviates the need to\nnest applications of the operator \u2126 and which tells us something about the \u2018degree of\ndifficulty\u2019 of the particular problem \u2126 with respect to the class of problems defined by\nthe sentences of the logic. For example, suppose that every problem in (a fragment of)\n(\u00b1\u2126)\u2217[FO] can be defined by a sentence of the form \u2126[\u03bbx1\u03c81(x1), . . . ,xr\u03c8r(xr)](d1,\n. . . ,dc), as above, except where each \u03c8i is quantifier-free first-order. Then we say that\nthe problem \u2126 is complete for (the fragment of) (\u00b1\u2126)\u2217[FO] via quantifier-free first-\norder translations . This is directly analogous to completeness for some complexity\nclass via some resource-bounded reduction; in fact, as we shall see, such normal forms\ncan often yield very strong complexity-theoretic completeness results.\nVectorized Lindstro\u00a8m logics have been studied quite extensively in finite model\ntheory and a whole range of complexity classes have been captured , i.e., characterized,\nby vectorized Lindstro\u00a8m logics (see, for example, [19, 23, 31, 32] and the references\n6\ntherein). However, some (though not all) of these characterizations only hold in the\npresence of a built-in successor relation. Consider some vectorized Lindstro\u00a8m logic\n(\u00b1\u2126)\u2217[FO]. To say that this logic has a built-in successor relation, which we denote\nby (\u00b1\u2126)\u2217[FOs], means that no matter which signature \u03c3\n\u2032 we are working over, there is\nalways a binary relation symbol succ and two constant symbols 0 and max available\n(none of which is in \u03c3\u2032) such that succ is always interpreted as a successor relation\nwith least element 0 and greatest element max in any \u03c3\u2032-structure. That is, for any\n\u03c3\u2032-structure of size n, succ is always of the form {(0, u1), (u1, u2), . . . , (un\u22122,max)},\nwhere the elements of {0, u1, u2, . . . , un\u22122,max} are distinct. However, there is a\nfurther semantic stipulation on the sentences of (\u00b1\u2126)\u2217[FOs]: we only consider as well-\nformed those sentences for which the interpretation in any structure is independent\nof the particular successor relation chosen. For example, define the problem TC over\nthe signature \u03c32++ = \u3008E,C,D\u3009, where E is a binary relation symbol and C and\nD are constant symbols, as consisting of all those \u03c32++-structures for which, when\nconsidered as digraphs in the natural way, there is a directed path from the vertex C to\nthe vertex D. Then the following sentence is a well-formed sentence of (\u00b1TC)\u2217[FOs]\n(as satisfiability in a given structure is invariant with respect to succ):\nTC[\u03bb(x1, x2), (y1, y2)(x1 = 0 \u2227 y1 = max \u2227 succ(x2, y2))\n\u2228(x1 = max \u2227 y1 = 0 \u2227 succ(x2, y2))](0, 0,max,max),\nand it defines the problem over the empty signature consisting of those structures\nof even size. (Note that in [12], the mechanism by which a successor relation is\nintroduced into a logic is slightly different from how we have described here in that\nonly problems on ordered structures are ever considered: see [12]. Nevertheless, the\ntwo approaches essentially amount to the same thing and we shall refer to the two\nmechanisms interchangeably. Note also that other relations can be built into logics\nin the same way as is a successor relation; or even just two distinct constants can be\nbuilt in.)\nFrom a logical perspective, there is a problem with our built-in successor relation in\nthe following sense. Given a sentence of first-order logic in which the relation symbol\nsucc appears (and in which other constant and relation symbols might appear), it\nis actually undecidable as to whether the sentence is invariant with respect to succ.\nThat is, there does not exist an effective enumeration of the well-formed sentences\nof FOs. Given this fact, it is highly debatable as to whether any \u2018logic\u2019 (\u00b1\u2126)\n\u2217[FOs]\nshould really be called a logic; and it is an open question currently occupying much\nresearch activity as to whether there actually exists a logic capturing the complexity\nclass P (polynomial-time), or indeed any complexity class contained in NP (non-\ndeterministic polynomial-time), where by \u2018contained in\u2019 we really mean \u2018contained in\nbut expected to be different from\u2019 (as NP itself can be captured by a logic, one such\nbeing existential second-order logic). The reader is referred to [28] for more details\non this and related points. (Notwithstanding the above discussion, we still refer to\n(\u00b1\u2126)\u2217[FOs] as a logic on the grounds of convenience.)\nTheorem 1, below, is an example of a normal form result. Define the problem\nCUB, over the signature \u03c32 = \u3008E\u3009, where E is a binary relation symbol, as follows.\nCUB = {G \u2208 STRUCT(\u03c32) : the graph G has a subset of edges inducing a\nregular subgraph of degree 3}\n7\n(think of a \u03c32-structure G as encoding an undirected graph via: \u2018there is an edge\n(u, v) if, and only if, u 6= v and E(u, v) \u2228 E(v, u) holds in G\u2019). We shall need the\nfollowing result later on.\nTheorem 1 [36] The complexity class NP is identical to the class of problems defined\nby the sentences of CUB\u2217[FOs]; and any problem in NP can be defined by a sentence\nof CUB1[FOs] of the form:\nCUB [\u03bbx,y\u03c8(x,y)],\nwhere |x| = |y| = k, for some k \u2265 1, and \u03c8 is a quantifier-free formula of FOs. Hence,\nCUB\u2217[FOs] = CUB\n1[FOs] = NP and CUB is complete for NP via quantifier-free\nfirst-order translations with successor.\nNote that Theorem 1 subsumes the \u2018traditional\u2019 known complexity-theoretic result\nthat CUB is complete for NP via log-space reductions (a result attributed to Chva`tal\nin [16]).\n3 Program schemes\nProgram schemes are more \u2018computational\u2019 means for defining classes of problems\nthan are logical formulae. A program scheme \u03c1 \u2208 NPSA(1) involves a finite set\n{x1, x2, . . . , xk} of variables , for some k \u2265 1, and is over a signature \u03c3. It consists of\na finite sequence of instructions where each instruction, apart from the first and the\nlast, is one of the following:\n\u2022 an assignment instruction of the form \u2018xi := y\u2019, where i \u2208 {1, 2, . . . , k} and\nwhere y is a variable from {x1, x2, . . . , xk}, a constant symbol of \u03c3 or one of the\nspecial constant symbols 0 and max which do not appear in any signature;\n\u2022 an assignment instruction of the form \u2018xi := A[y1, y2, . . . , yd]\u2019 or \u2018A[y1, y2, . . . ,\nyd] := y0\u2019, for some i \u2208 {1, 2, . . . , k}, where each yj is a variable from {x1, x2,\n. . . , xk}, a constant symbol of \u03c3 or one of the special constant symbols 0 and\nmax which do not appear in any signature, and where A is an array symbol of\ndimension d;\n\u2022 a guess instruction of the form \u2018guess xi\u2019, where i \u2208 {1, 2, . . . , k}; or\n\u2022 a while instruction of the form \u2018while \u03d5 do \u03b11;\u03b12; . . . ;\u03b1q od\u2019, where \u03d5 is\na quantifier-free formula of FO(\u03c3 \u222a {0,max}) whose free variables are from\n{x1, x2, . . . , xk}, and where each of \u03b11, \u03b12, . . . , \u03b1q is another instruction of one\nof the forms given here (note that there may be nested while instructions).\nThe first instruction of \u03c1 is \u2018input(x1, x2, . . . , xl)\u2019 and the last instruction is \u2018output\n(x1, x2, . . . , xl)\u2019, for some l where 1 \u2264 l \u2264 k. The variables x1, x2, . . . , xl are the input-\noutput variables of \u03c1, the variables xl+1, xl+2, . . . , xk are the free variables of \u03c1 and,\nfurther, any free variable of \u03c1 never appears on the left-hand side of an assignment\ninstruction nor in a guess instruction. Essentially, free variables appear in \u03c1 as if they\nwere constant symbols.\nA program scheme \u03c1 \u2208 NPSA(1) over \u03c3 with t free variables, say, takes a \u03c3-\nstructure A and t additional values from |A|, one for each free variable of \u03c1, as input;\n8\nthat is, an expansion A\u2032 of A by adjoining t additional constants. The program\nscheme \u03c1 computes on A\u2032 in the obvious way except that:\n\u2022 execution of the instruction \u2018guess xi\u2019 non-deterministically assigns an element\nof |A| to the variable xi;\n\u2022 the constants 0 and max are interpreted as two arbitrary but distinct elements\nof |A|; and\n\u2022 initially, every input-output variable and every array element is assumed to have\nthe value 0.\nNote that throughout a computation of \u03c1, the value of any free variable does not\nchange. The expansion A\u2032 of the structure A is accepted by \u03c1, and we write A\u2032 |=\n\u03c1, if, and only if, there exists a computation of \u03c1 on this expansion such that the\noutput-instruction is reached with all input-output variables having the value max\n(in particular, some computations might not be terminating). We can easily build\nthe usual \u2018if\u2019 and \u2018if-then-else\u2019 instructions using while instructions (see, for example,\n[33]). Henceforth, we shall assume that these instructions are at our disposal.\nWe want the sets of structures accepted by our program schemes to be problems,\ni.e., closed under isomorphism, and so we only ever consider program schemes \u03c1 where\na structure is accepted by \u03c1 when 0 and max are given two distinct values from the\nuniverse of the structure if, and only if, it is accepted no matter which pair of distinct\nvalues is chosen for 0 and max. This is analogous to how we build two constant\nsymbols into a logic. Furthermore, we can build a successor relation into the program\nschemes of NPSA(1) so as to obtain the class of program schemes NPSAs(1). As with\nour logics, we write NPSA(1) and NPSAs(1) to also denote the class of problems\naccepted by the program schemes of NPSA(1) and NPSAs(1), respectively (and do\nlikewise with other classes of program schemes).\nWe have two remarks. First, our notation NPSA(1) reflects the fact that NPSA(1)\nis the first level of an infinite hierarchy of classes of program schemes, as we shall\nsee presently. Second, as the definition of our class of program schemes NPSA(1)\nstands, we do not know whether the program schemes in this class can be recursively\nenumerated. However, we are prepared to live with this (possible) inconvenience\nfor the following reasons. We could amend our definition of a program scheme of\nNPSA(1) and dispense with the constant symbols 0 andmax but insist that the syntax\nwas such that the first instructions are always guess x0; guess xmax; while x0 =\nxmax do guess x0 od. Consequently, every program scheme begins by assigning two\ndistinct values from the domain of the input structure to the variables x0 and xmax.\nThese values would then be used as the constants 0 and max, and acceptance would\nbe signalled by any execution reaching the instruction output. With this amended\nsyntax and definition of acceptance, the class of structures accepted by any program\nscheme is trivially closed under isomorphism and the class of program schemes is\nrecursively enumerable; moreover, all the results in this paper would apply with our\nclass of program schemes NPSA(1) so defined (as readers can easily verify as they\nread through the forthcoming proofs). The essential reason for this is that all our\nconstructions are such that they never use any \u2018semantic\u2019 information relating to 0\nand max, just the fact that they are distinct elements of the input structure. We\nshall remark upon forthcoming definitions and results in relation to this amended\n9\ndefinition of NPSA(1) as we proceed. However, there are four real reasons for having\nthe constant symbols 0 andmax in our program schemes, with all of the reasons more\nto do with clarity and pragmatism than anything else. First, we can use 0 to cleanly\ninitialize all variables and arrays, with the result that we never have to worry about\nwhether an assignment involves an uninitialized variable or array element. Second,\nhaving two distinct constants around is useful when it comes to programming. Third,\nwe shall soon use the constant symbol max to enable us to study \u2018binary write-once\u2019\narrays (that is, arrays where the elements can only be set to max and thereafter\nremain unchanged). Fourth, were we to include a built-in successor relation then\nhaving the constant symbols 0 and max available enables us to do this in a consistent\nfashion.\nHenceforth, we think of our program schemes as being written in the style of\na computer program. That is, each instruction is written on one line and while\ninstructions (and, similarly, if and if-then-else instructions) are split so that \u2018while\n\u03d5 do\u2019 appears on one line, \u2018\u03b11\u2019 appears on the next, \u2018\u03b12\u2019 on the next, and so on (of\ncourse, if any \u03b1i is a while, if or if-then-else instruction then it is split over a number of\nlines in the same way). The instructions are labelled 1, 2, and so on, according to the\nline they appear on. In particular, every instruction is considered to be an assignment,\na guess or a test. An instantaneous description (ID) of a program scheme on some\ninput consists of a value for each variable, the number of the instruction about to be\nexecuted and values for all array elements. A partial ID consists of just a value for\neach variable and the number of the instruction about to be executed. One step in a\nprogram scheme computation is the execution of one instruction, which takes one ID\nto another, and we say that a program scheme can move from one ID to another if\nthere exists a sequence of steps taking the former ID to the latter.\nAs we hinted at above, the class of program schemes NPSA(1) is but the first level\nof an infinite hierarchy of program schemes. Suppose that we have defined a class of\nprogram schemes NPSA(2m\u2212 1), for some m \u2265 1, and that any program scheme has\nassociated with it: a set of input-output variables; a set of free variables; and a set of\nbound variables (this is certainly the case when m = 1, where the associated set of\nbound variables is empty).\nDefinition 2 Let the program scheme \u03c1 \u2208 NPSA(2m \u2212 1) be over the signature \u03c3.\nSuppose that \u03c1 has: input-output variables x1, x2, . . . , xk; free variables xk+1, xk+2,\n. . . , xk+s; and bound variables xk+s+1, xk+s+2, . . . , xk+s+t. Let xi1 , xi2 , . . . , xip be\nfree variables of \u03c1, for some p (and so k + 1 \u2264 i1 < i2 < . . . < ip \u2264 k + s). Then:\n\u2200xi1\u2200xi2 . . . \u2200xip\u03c1\nis a program scheme of NPSA(2m), which we denote by \u03c1\u2032, with: no input-output\nvariables; free variables those of {xk+1, xk+2, . . . , xk+s} \\ {xi1 , xi2 , . . . , xip}; and the\nremaining variables of {x1, x2, . . . , xk+s+t} as its bound variables.\nA program scheme such as \u03c1\u2032 takes expansions A\u2032 of \u03c3-structures A by adjoining\ns\u2212p constants as input (one for each free variable), and \u03c1\u2032 accepts such an expansion\nA\u2032 if, and only if, for every expansion A\u2032\u2032 of A\u2032 by p additional constants (one for each\nvariable xij , for j \u2208 {1, 2, . . . , p}), A\n\u2032\u2032 |= \u03c1 (the computation on such an expansion\nA\u2032\u2032 always starts with the arrays initialised to 0).\n10\nDefinition 3 A program scheme \u03c1\u2032 \u2208 NPSA(2m \u2212 1), for some m \u2265 2, over the\nsignature \u03c3, is defined exactly as is a program scheme of NPSA(1) except that the\ntest in any while instruction is a program scheme \u03c1 \u2208 NPSA(2m \u2212 2). The bound\nvariables of \u03c1\u2032 consist of the bound variables of any test in any while instruction; all\nfree variables in any test in any while instruction are input-output or free variables of\n\u03c1\u2032; and there may be other free and input-output variables (appearing in \u03c1\u2032 at the \u2018top\nlevel\u2019 but not in any test). Of course, any free variable never appears on the left-hand\nside of an assignment instruction or in a guess instruction (at the \u2018top level\u2019).\nSuppose that a program scheme \u03c1\u2032 \u2208 NPSA(2m \u2212 1) has s free variables. Then\nit takes an expansion A\u2032 of a \u03c3-structure A by adjoining s constants as input and\ncomputes on A\u2032 in the obvious way; except that when some while instruction is en-\ncountered, the test, which is a program scheme \u03c1 \u2208 NPSA(2m \u2212 2), is evaluated\naccording to the expansion of A\u2032 by the current values of any relevant input-output\nvariables of \u03c1\u2032 (which may be free in \u03c1). In order to evaluate this test, the arrays\nassociated with \u03c1 are initialized at 0 and when the test has been evaluated the com-\nputation of \u03c1\u2032 resumes accordingly with the values of its arrays and input-output and\nfree variables being exactly as they were immediately prior to the test being evalu-\nated. In particular, array values can not be \u2018passed across\u2019 in the evaluation of tests:\nthe values of variables can be but they are never amended in the process.\nConsequently, we obtain a hierarchy of classes of problems:\nNPSA(1) \u2286 NPSA(2) \u2286 . . . \u2286 \u222a{NPSA(i) : i = 1, 2, . . .} = NPSA\n(we use the inclusion relation between consecutive classes because this is how they\nare related as classes of problems). It is easy to see that, for one thing, FO \u2286 NPSA.\nIn this paper, we are primarily interested in some sub-classes of program schemes\nof NPSA, namely the sub-classes NPSB(i), for i = 1, 2, . . ., and the union of these\nclasses NPSB, where the only allowed assignment instructions with an array element\non the left-hand side are of the form A[x1, x2, . . . , xk] := max; that is, the only values\narray elements can have are 0 and max, and once an array element is set to max then\nit remains at max thereafter (the notation reflects the binary nature of these arrays).\nObviously, NPSB(i) \u2286 NPSA(i), for all i = 1, 2, . . .; and NPSB \u2286 NPSA.\nRemark 4 We note that were we to define our program schemes of NPSA(1) without\nusing the constant symbols 0 and max, as hinted at previously, then we could adapt\nDefinitions 2 and 3 accordingly by never quantifying the variables x0 and xmax. Also,\nthe program schemes of NPSB would be defined by x0 and xmax replacing 0 andmax.\nResults concerning the program schemes of NPSA have already been obtained,\nand some of these results relevant to this paper are stated below. A problem \u2126, over\nsome signature \u03c3 and where the domain of any \u03c3-structure of size n is taken to be\n{1, 2, . . . , n}, for which the function f(n), defined as the number of structures in \u2126\nof size n divided by the number of \u03c3-structures of size n, is such that the limit as n\ntends to infinity exists and is r is said to have asymptotic probability r. For us, r will\nalways be 0 or 1. We say that a logic has a zero-one law if every problem definable\nin that logic has asymptotic probability 0 or 1.\nTheorem 5 [39]\n11\n(i) There exists a problem \u2126a, involving reachability in Petri nets, for which\nNPSA = (\u00b1\u2126a)\n\u2217[FO],\nand every problem in NPSA has asymptotic probability 0 or 1.\n(ii) There is a quantifier-free first-order translation with 2 constants from any prob-\nlem in NPSA(1) to the problem \u2126a; and so \u2126a is complete for NPSA(1) via\nquantifier-free first-order translations with 2 constants.\n(iii) The problem CUB is in NPSA(1) but not definable in the logic L\u03c9\u221e\u03c9.\n(iv) In the presence of a built-in successor relation, the hierarchy NPSAs collapses\nto the first level, NPSAs(1), and captures the complexity class PSPACE.\nIt is worth mentioning the role of the logic L\u03c9\u221e\u03c9 in finite model theory. This\nlogic is an important logic for a number of reasons, one of which is that it subsumes\nmany of the logics from finite model theory (including transitive-closure logic, least\nfixed point logic and partial fixed point logic) in that these logics can be realized as\nfragments of L\u03c9\u221e\u03c9. Furthermore, L\n\u03c9\n\u221e\u03c9 has a zero-one law and so any logic subsumed\nby L\u03c9\u221e\u03c9 has a zero-one law. It is particularly interesting that NPSA(1) (and so also\nNPSA) can not be realized as a fragment of L\u03c9\u221e\u03c9 (as CUB is a problem in NPSA(1)\nthat is not in L\u03c9\u221e\u03c9, a result proven in [37]).\nIn the absence of arrays, when the resulting class of program schemes is denoted\nNPS, and additionally in the presence of a stack, when the resulting class of program\nschemes is denoted NPSS, there are results analogous to parts (i), (ii) and (iv)\nof Theorem 5 (see [7]) in that: both NPS and NPSS can be realized as vectorized\nLindstro\u00a8m logics so that the problems corresponding to the operators involved in these\nlogics are complete for NPS(1) and NPSS(1) via quantifier-free first-order translations\nwith 2 constants; and on ordered structures, the complexity classes captured are\nNL (non-deterministic log-space) and P, respectively. However, unlike NPSA, both\nNPS and NPSS can be realized as fragments of L\u03c9\u221e\u03c9. Furthermore, the underlying\nhierarchies of NPS and NPSS are proper at every level (even if we restrict to problems\nonly involving trees) whereas, as we shall affirm later, all that is known as regards\nNPSA is that NPSA(1) \u2282 NPSA(2) \u2282 NPSA(3).\n4 Partitioned Petri nets\nWe begin by describing a generalization of the digraph reachability problem to a\nscenario where the moves between nodes depend upon the availability and utilization\nof external resources. We first describe the basic decision problem in an everyday\nfashion before we consider a manifestation of it as a class of structures over a given\nsignature and see how this problem is related to computation in the program schemes\nof NPSB(1).\nConsider the following scenario. We are given a directed graph G = (V,E), where\n|V | = n, with a source vertex source and a sink vertex sink, but where each edge\nis labelled with a (possibly empty) set of labels with each label being of one of the\nfollowing forms:\n12\n\u2022 \u2018user resource ri is unused\u2019;\n\u2022 \u2018system resource sj is available\u2019;\n\u2022 \u2018user resource ri is unused and this move uses this resource but makes the system\nresource sj available (if it wasn\u2019t available previously)\u2019.\nThere is a polynomial number of different user resources {ri : i = 1, 2, . . . , p(n)},\nwhich are either in the state \u2018used\u2019 or the state \u2018unused\u2019; and a polynomial number of\nsystem resources {si : i = 1, 2, . . . , q(n)}, which are either in the state \u2018available\u2019 or\nthe state \u2018unavailable\u2019 (for some polynomials p and q). A move in the digraph from\nvertex u to vertex v via the edge (u, v) can only be made if either no labels label\nthe edge (u, v) or at least one of the labels labelling the edge (u, v) is satisfied (with\na resulting change in the state of a user resource, and possibly a system resource, if\nthe label is of the third type). The question we ask is, given the initial state where\nall user resources are unused and no system resources are available, is it possible to\nmove from source to sink in our given environment? That is, can the user use his or\nher resources wisely so as to enable a traversal in the digraph from the source to the\nsink?\nNote that whether a move can be made depends only on certain predicates involv-\ning the states of the resources: for example, there are no moves dependent upon the\nstate of a user resource being \u2018used\u2019 or of a system resource being \u2018unavailable\u2019. The\nsituation is as it is as this decision problem arises naturally from our consideration of\nour program schemes; but we comment further on this problem and related problems\nin the Conclusion.\nWe encode the above decision problem as a problem, i.e., class of finite structures,\ninvolving Petri nets. Our encoding is natural and has certain properties which we shall\nutilize later. The reader is referred to [13] for the basic notions and concepts relating\nto Petri nets (this reference also gives details of numerous complexity-theoretic results\nconcerning fundamental problems in Petri nets).\nDefinition 6 Define \u03c3b = \u3008P,Q, T1, T2, T3, C,D\u3009 where P , Q, T1, T2 and T3 are\nrelation symbols of arities 1, 1, 2, 3 and 4, respectively, and C and D are constant\nsymbols. Let P be a \u03c3b-structure. We can think of the elements of |P| as being the\nplaces of a Petri net and the relations P and Q as describing two partitions of these\nplaces. We can think of:\n\u2022 the relation T1 as describing the set of transitions\n{({u}, {v}) : u, v \u2208 P and T1(u, v) holds};\n\u2022 the relation T2 as describing the set of transitions\n{({u, i}, {v, i}) : u, v \u2208 P, i 6\u2208 P, i \u2208 Q and T2(u, v, i) holds}\n\u222a{({u, j}, {v, j}) : u, v \u2208 P, j 6\u2208 P,Q and T2(u, v, j) holds};\nand\n\u2022 the relation T3 as describing the set of transitions\n{({u, i}, {v, j}) : u, v \u2208 P, i, j 6\u2208 P, i \u2208 Q, j 6\u2208 Q and T3(u, v, i, j) holds}.\n13\nFurthermore, the initial marking of our Petri consists of the place C and the places\nnot in P but in Q. We define the problem \u2126b as\n{P \u2208 STRUCT(\u03c3b) : there is a marking reachable from the initial marking\nin which there is at least one token on the place D}.\nNote that the transitions encoded within a \u03c3b-structure P are of one of four types,\nas depicted in Fig. 1, and that the relations T1, T2 and T3 of P might have additional\ntuples in them that do not affect how we think of P as a Petri net.\nWith reference to our decision problem presented earlier, it should be clear that:\nthe places in P correspond to the vertices V of our digraph G = (V,E), with C\ncorresponding to the source vertex and D the sink vertex; the places not in P but in\nQ correspond to the user resources; and the places not in P and not in Q correspond\nto the system resources (henceforth, we shall use this terminology to describe the\nplaces of our Petri net). Additionally, the transitions described by T1 correspond to\nedges of E with no labels; the transitions described by T2 yield edges labelled with\nlabels of the form \u2018user resource ri is unused\u2019 and \u2018system resource sj is available\u2019;\nand the transitions described by T3 yield edges labelled with labels of the form \u2018user\nresource ri is unused and this move uses this resource but makes the system resource\nsj available\u2019. We interpret a user resource as being in the state \u2018unused\u2019, if there is a\ntoken on it, and as being in the state \u2018used\u2019 otherwise (such places only ever have at\nmost one token on them). It may be the case, in a reachable marking, that a system\nresource has more than one token on it. However, tokens can not be removed from\nsuch places. Thus, it is only ever important as to whether a system resource has no\ntokens on it, when we think of it being in the state \u2018unavailable\u2019, or at least one token\non it when, we think of it being in the state \u2018available\u2019.\nP to P\no\nn\nn t Q\nQ\non t P\nP to P\no\nn\nn t Q\nQ\non t P\nP to P\no\nn\nn t Q\nQ\non t P\nP to P\no\nn\nn t Q\nQ\non t P\nT1 transitions T3 transitionsT2 transitions\nFigure 1. The different types of transitions.\nThe proof of the following theorem is similar to those in [39] although there are\nadditional complications caused by only having assignments which set array values to\nmax.\n14\nTheorem 7 There is a quantifier-free first-order translation with 2 constants from\nany problem in NPSB(1) to the problem \u2126b. Hence, \u2126b is complete for NPSB(1) via\nquantifier-free first-order translations with 2 constants.\nProof Let \u03c1 be a program scheme of NPSB(1) over some signature \u03c3 in which if\nand if-then-else instructions might occur. W.l.o.g., we may assume that array symbols\nonly appear in assignment instructions, that there is only one array symbol, B, and\nthat this array symbol has dimension d \u2265 1. We assume that the variables involved\nin \u03c1 are x1, x2, . . . , xk.\nLet A be a \u03c3-structure of size n \u2265 2. An element u = (u0, u1, . . . , uk) of\n{1, 2, . . . , l} \u00d7 |A|k encodes a partial ID of \u03c1 on input A via: a computation of \u03c1\non A is about to execute instruction u0 and the variables x1, x2, . . . , xk currently\nhave the values u1, u2, . . . , uk, respectively. Henceforth, we identify partial IDs of \u03c1\nand the elements of {1, 2, . . . , l} \u00d7 |A|k.\nWe now build a Petri net P , as in Definition 6, using \u03c1 and A. Our Petri net\nP has a set of places consisting of the set {1, 2, . . . , l} \u00d7 |A|k in union with the set\n{w0,wm : w \u2208 |A|\nd}. The sets of places P and Q are\nP = {1, 2, . . . , l} \u00d7 |A|k and Q = {w0 : w \u2208 |A|\nd},\nrespectively. Hence, the user resources are {w0 : w \u2208 |A|\nd} and the system resources\n{wm : w \u2208 |A|\nd}. We shall use a token on the user resource (w1, w2, . . . , wd)0 to\nsignify that the current value of B[w1, w2, . . . , wd] is 0; and a token on the system re-\nsource (w1, w2, . . . , wd)m to signify that the current value of B[w1, w2, . . . , wd] is max.\nObviously, we have to take care to ensure that a marking does not yield contradictory\ninterpretations.\nLet u \u2208 {1, 2, . . . , l} \u00d7 |A|k.\nSuppose that the instruction u0 does not involve the array symbol B and it is\npossible for \u03c1 on input A to move from any ID whose partial ID is u to an ID whose\npartial ID is v in one step. Then the transition ({u}, {v}) is in T1 (more precisely,\nthe pair (u,v) is in T1).\nSuppose that the instruction u0 is of the form xj := B[xi1 , xi2 , . . . , xid ] and it is\npossible for \u03c1 on input A to move from any ID whose partial ID is u to an ID whose\npartial ID is v in one step (because the value of B[xi1 , xi2 , . . . , xid ] is such that \u03c1 on in-\nput A can move from an ID whose partial ID is u to an ID whose partial ID is v in one\nstep). Then both of the transitions ({u, (ui1 , ui2 , . . . , uid)0}, {v, (ui1 , ui2 , . . . , uid)0})\nand ({u, (ui1 , ui2 , . . . , uid)m}, {v, (ui1 , ui2 , . . . , uid)m}) are in T2 (of course, in the for-\nmer transition, vj is 0, and in the latter vj is max, with ui = vi, for all i = 1, 2, . . . , k\ndifferent from j).\nSuppose that the instruction u0 is of the form B[xi1 , xi2 , . . . , xid ] := max and it is\npossible for \u03c1 on input A to move from an ID whose partial ID is u to an ID whose par-\ntial ID is v in one step. Then the transition ({u, (ui1 , ui2 , . . . , uid)m}, {v, (ui1 , ui2 , . . . ,\nuid)m}) is in T2 and the transition ({u, (ui1 , ui2 , . . . , uid)0}, {v, (ui1 , ui2 , . . . , uid)m})\nis in T3 (of course, in both transitions ui = vi, for i = 1, 2, . . . , k).\nOur initial marking of P is such that there is one token on each place of {w0 :\nw \u2208 |A|d} and one token on the place (1,0) \u2208 {1, 2, . . . , l} \u00d7 |A|k, which we define to\nbe C; and we define D as the place (l,max) \u2208 {1, 2, . . . , l} \u00d7 |A|k.\nIt is not difficult to see that our Petri net P (that is, our \u03c3b-structure P) can be\ndescribed in terms of the \u03c3-structure A using quantifier-free first-order formulae (in\n15\nwhich 0 and max appear: explicit descriptions of structures by quantifier-free first-\norder formulae are given in, for example, [34]). Consequently, in order for the result to\nfollow we need to show that: A |= \u03c1 if, and only if, P \u2208 \u2126b; and that \u2126b \u2208 NPSB(1).\nSuppose that A |= \u03c1. Then there is a sequence pi of (full, not partial) IDs starting\nat the initial ID (where all variables have the value 0, where the instruction to be\nexecuted is instruction 1 and where the array B has the value 0 throughout) and\nending in a final ID (where all variables have the valuemax and where the instruction\nto be executed is instruction l) such that \u03c1 moves from one ID in pi to the next in one\nstep. As hinted earlier, we can mirror any ID with a set of markings of our Petri net\nP as follows. If the ID consists of the partial ID u \u2208 {1, 2, . . . , l}\u00d7 |A|k together with\nsome valuation on the array B then the place u is marked with one token as are the\nplaces of {w0 : w \u2208 |A|\nd, B[w] = 0}, and the places of {wm : w \u2208 |A|\nd, B[w] = max}\nare marked with at least one token. This accounts for all tokens. Note that the initial\nID of \u03c1 corresponds to the initial marking of P . A simple analysis yields that if \u03c1\non input A moves from one ID to another in one step then the Petri net can fire\na transition to move from the marking corresponding to the first ID to a marking\ncorresponding to the subsequent ID; and conversely (as remarked earlier, as regards\nthe system resources, it does not matter how many tokens reside on them but only\nwhether or not at least one token resides). Hence, A |= \u03c1 if, and only if, P \u2208 \u2126b.\nAll that remains is to show that \u2126b \u2208 NPSB(1). There are two essential difficulties\nin deriving a program scheme to accept \u2126b. First, a \u03c3b-structure P might be such\nthat a reachable marking involves more than one token on some system resource; and\nwe need to cater for this event when we simulate a sequence of transitions in P by\nan execution of a program scheme on input P . Second, we need to keep track of\nwhere tokens are in a way which avoids us modelling the fact that a token is on a\nplace simply by using an array indexed by the place names; for we are not allowed\nto register that a token has moved from a place by assigning some array element the\nvalue 0 (recall, the only assignment instruction allowed on an array element is to set\nthat element to max).\nOur Petri net P is such that initially there is one token, call it t, on the place C\nof P and there is one token on every user resource (we assume that the place C is\nindeed in P : otherwise, our program scheme simply rejects the input P). No other\ntokens are involved in the initial marking. Also, transitions are such that we can\nimagine the token t as being moved from place to place amongst the places of P , and\nwe can imagine every other token either staying where it is, after some transition, or\nbeing moved from user resource to a system resource, and then staying where it is\nthereafter.\nAs regards our first difficulty, we do not need to actually monitor how many tokens\nlie on any system resource but only whether there is at least one token such a place.\nThis obviates the need to count tokens. As regards our second difficulty, in order to\ndecide whether (at least) one token lies on some system resource s, we use a dedicated\narray B1, of dimension 1, so that whenever a token is placed on such a s then B1[s]\nis set at max: once B1[s] has been set to max we know that there will be a token\non s thereafter. In order to decide whether a token lies on some user resource r, we\nuse an array B2, of dimension 1, to register when the token originally on the place\nr is first moved from r by setting B2[r] equal to max at this point. Consequently, if\nwe wish to know whether there is a token on such a place r, we test to see whether\n16\nB2[r] = 0 holds. Finally, we model the movement of the solitary token t by using a\ndedicated variable, x say: that is, the token t is on place p if, and only if, x has the\nvalue p. Given the above discussion, it is straightforward to see that the problem \u2126b\ncan be accepted by a program scheme of NPSB(1), and so the result follows.\nIn essence, Theorem 7 tells us that any problem accepted by a program scheme of\nNPSB(1) can be described by a sentence of the form\n\u2126b[\u03bbx\u03c8P (x),x\u03c8Q(x),x,y\u03c81(x,y),x,y, z\u03c82(x,y, z),\nx,y, z,w\u03c83(x,y, z,w)](u,v),\nwhere: |x| = |y| = |z| = |w| = k, for some k \u2265 1, and all variables are distinct; \u03c8P ,\n\u03c8Q, \u03c81, \u03c82 and \u03c83 are quantifier-free first-order formulae over \u03c3b \u222a {0,max}; and\nu and v are k-tuples of constant symbols (in fact, we can actually take u to be 0\nrepeated k times and v to be max repeated k times: moreover, the sentence is such\nthat whether it is true in some given structure is independent of the distinct values\nchosen for 0 and max).\nSimilarly to as in [39], Theorem 7 allows us to relate the class of problems accepted\nby the program schemes of NPSB with the class of problems defined by the sentences of\nthe logic (\u00b1\u2126b)\n\u2217[FO]. For eachm \u2265 1, we define the fragment \u00b1\u2126b(m) of (\u00b1\u2126b)\n\u2217[FO]\nas follows.\n\u2022 \u00b1\u2126b(1) consists of all formulae of the form\n\u2126b[\u03bbx\u03c8P ,x\u03c8Q,x,y\u03c81,x,y, z\u03c82,x,y, z,w\u03c83](u,v),\nwhere: \u03c8P , \u03c8Q, \u03c81, \u03c82 and \u03c83 are quantifier-free first-order formulae over\n\u03c3b \u222a{0,max}; u and v are k-tuples of constant symbols or variables; there may\nbe other free variables; and the truth of any interpretation of the formula (over\na relevant structure and with values given for any free variables) is independent\nof the pair of distinct values chosen for 0 and max.\n\u2022 \u00b1\u2126b(m+1), for odd m \u2265 1, consists of the universal closure of \u00b1\u2126b(m); that is,\nthe set of formulae of the form \u2200z1\u2200z2 . . .\u2200zk\u03c8, where \u03c8 is a formula of \u00b1\u2126b(m).\n\u2022 \u00b1\u2126b(m+ 1), for even m \u2265 2, consists of the set of formulae of the form\n\u2126b[\u03bbx(\u03c8\n1\nP \u2228 \u00ac\u03c8\n2\nP ),x(\u03c8\n1\nQ \u2228 \u00ac\u03c8\n2\nQ),x,y(\u03c8\n1\n1 \u2228 \u00ac\u03c8\n2\n1),x,y, z(\u03c8\n1\n2 \u2228 \u00ac\u03c8\n2\n2),\nx,y, z,w(\u03c813 \u2228 \u00ac\u03c8\n2\n3)](u,v),\nwhere: \u03c81P , \u03c8\n2\nP , \u03c8\n1\nQ, \u03c8\n2\nQ, \u03c8\n1\n1 , \u03c8\n2\n1 , \u03c8\n1\n2 , \u03c8\n2\n2 , \u03c8\n1\n3 and \u03c8\n2\n3 are formulae of \u00b1\u2126b(m);\nu and v are tuples of constant symbols or variables; there may be other free\nvariables; and the truth of any interpretation of the formula (over a relevant\nstructure and with values given for any free variables) is independent of the\npair of distinct values chosen for 0 and max.\nAs in [36], a straightforward induction yields that:\n\u2022 for every odd m \u2265 1, every formula in the closure of \u00b1\u2126b(m) under \u2227, \u2228 and \u2203\nis logically equivalent to a formula of \u00b1\u2126b(m); and\n17\n\u2022 for every even m \u2265 1, every formula in the closure of \u00b1\u2126b(m) under \u2227, \u2228 and\n\u2200 is logically equivalent to a formula of \u00b1\u2126b(m).\nConsequently, (\u00b1\u2126b)\n\u2217[FO] = \u222a{\u2126b(m) : m \u2265 1}.\nCorollary 8 In the presence of 2 built-in constant symbols, \u00b1\u2126b(m) = NPSB(m),\nfor each m \u2265 1; and so (\u00b1\u2126b)\n\u2217[FO ] = NPSB.\nProof We proceed by induction on m almost identically to the proof of Corollary\n10 from [39]. The base case, when m = 1, follows by Theorem 7.\nNote that (\u00b1\u2126b)\n\u2217[FO] = NPSB even in the absence of our 2 built-in constant\nsymbols as we can \u2018build them ourselves\u2019 using existential quantification.\nWe end this section by showing that NPSB can not be realized as a fragment of\nL\u03c9\u221e\u03c9 (unlike NPS and NPSS).\nLemma 9 The problem CUB can be accepted by a program scheme of NPSB(1).\nProof It was shown in [39] that CUB is in NPSA(1): however, the program scheme\nused there to accept CUB is not in NPSB(1). Nevertheless, the basic approach can\nbe amended to yield a program scheme of NPSB(1).\nLet G be a \u03c32-structure. We begin by \u2018guessing\u2019 a set of distinct edges in the\ngraph G. We use two 3-dimensional array symbols, B1 and B2, to store these guessed\nedges. In particular, if our first guessed edge is (u1, v1), having checked that (u1, v1)\nis indeed an edge of G, we set B1[0, 0, u1] = max and B2[0, 0, v1] = max. Next,\nwe guess an edge (u2, v2), check to see whether this edge is indeed an edge of G\nand then check to see whether this edge is different from (u1, v1). If so then we set\nB1[u1, v1, u2] = max and B2[u1, v1, v2] = max: otherwise, we set B1[u1, v1,max] =\nmax and B2[u1, v1,max] = max and stop guessing. We continue in this fashion until\nthe guessing stage stops whence we have a list of distinct edges of G.\nFinally, we check to see whether the guessed set of edges induces a regular subgraph\nof G of degree 3. It is clear that this whole process can be implemented by a program\nscheme of NPSB(1): hence, the result follows.\nThe facts that the problem CUB can not be defined in L\u03c9\u221e\u03c9 (see [37]) and that non-\nrecursive problems can be defined in L\u03c9\u221e\u03c9 (see [12]) immediately yield the following\nresult.\nCorollary 10 There are problems definable in NPSB(1) (and so NPSB) which are\nnot definable in L\u03c9\u221e\u03c9; and there are problems definable in L\n\u03c9\n\u221e\u03c9 which are not definable\nin NPSB.\nLet us remark that Lemma 9 is subsumed by a later result; nevertheless, we include\nit here in order to show that NPSB(1) can not be regarded as a fragment of L\u03c9\u221e\u03c9\n(which is our concern at the moment).\n18\n5 Ordered structures\nGiven our characterization of the class of problems accepted by the program schemes\nof NPSB, we now consider the class of problems accepted by these program schemes\nwhen we restrict ourselves to ordered structures.\nUsing Theorem 1, we can easily modify the program scheme implicit in the proof\nof Lemma 9 so that, in the presence of a built-in successor relation, it accepts any\ngiven problem in NP. Conversely, any problem in NPSBs(1) is in NP. Theorem 7\nthen yields the following result.\nCorollary 11 As classes of problems, NP = NPSBs(1); and \u2126b is complete for NP\nvia quantifier-free first-order translations with successor.\nBy Corollary 8, NPSBs = (\u00b1\u2126b)\n\u2217[FOs]; and by Corollary 5.5 of [32] and Corol-\nlary 11, (\u00b1\u2126b)\n\u2217[FOs] = (\u00b1HP)\n\u2217[FOs], where HP is the problem over the signature\n\u03c32++ consisting of all those \u03c32++-structures A which, when considered as digraphs\nwith edge relation EA and two given vertices CA and DA, are such that there\nis a Hamiltonian path from CA to DA. Furthermore, by Corollary 3.2.2 of [35],\n(\u00b1HP)\u2217[FOs] = L\nNP (the class or problems accepted by a log-space deterministic or-\nacle Turing machine with access to anNP oracle), and every problem in (\u00b1HP)\u2217[FOs]\ncan be defined by a sentence of the form:\n\u2203z1\u2203z2 . . .\u2203zm(HP[\u03bbx,y\u03c8(x,y, z)](0,max) \u2227 \u00acHP[\u03bbx,y\u03d5(x,y, z)](0,max)),\nwhere: x and y are k-tuples of variables, for some k; \u03c8 and \u03d5 are quantifier-free first-\norder formulae (with successor); and 0 (resp. max) is the constant symbol 0 (resp.\nmax) repeated k times. Hence, translating this normal form into a program scheme\nyields that any problem in NPSBs can actually be accepted by a program scheme of\nNPSBs(3). Furthermore, any problem accepted by a program scheme \u2200z1\u2200z2 . . . \u2200zm\u03c1\nof NPSBs(2) can be accepted by a program scheme of NPSBs(1): we simply replace\nthe universal quantification by code within a program scheme of NPSBs(1) which\nuses a while instruction and the successor relation to check whether a structure is\naccepted by \u03c1 for every valuation of the free variables z1, z2, . . . , zm. Hence, we have\nthe following result.\nTheorem 12 NPSBs(1) = NPSBs(2) = NP and NPSBs(3) = NPSBs = L\nNP.\nWe now turn to the relative computational capabilities of the classes of program\nschemes NPSB(1) and NPSA(1) on the class of all finite structures (we have more to\nsay about comparing the classes NPSB and NPSA in the Conclusion).\nThe following definitions are essential to what follows. Let \u03c3 be some signature\nand let A and B be \u03c3-structures. If |A| \u2286 |B| and:\n\u2022 for every relation symbol R of \u03c3, RA is RB restricted to |A|; and\n\u2022 for every constant symbol C of \u03c3, CA = CB,\nthen we say that A is a sub-structure of B and write A \u2286 B. If the problem \u2126 over \u03c3\nis such that for all \u03c3-structures A and B for which A \u2286 B, it is necessarily the case\nthat A \u2208 \u2126 implies B \u2208 \u2126, then we say that \u2126 is closed under extensions . Let EXT\nbe the class of all problems that are closed under extensions.\n19\nLemma 13 Every problem in NPSA(1) is closed under extensions.\nProof Let \u2126 be a problem over the signature \u03c3 accepted by the program scheme \u03c1\nof NPSA(1). Let A and B be \u03c3-structures such that A \u2286 B, and suppose that A |= \u03c1.\nConsider the program scheme \u03c1 on input B where 0 and max are chosen to be distinct\nelements of |A|. By \u2018mirroring\u2019 an accepting computation of \u03c1 on input A, with the\nchosen 0 and max, we obtain an accepting computation of \u03c1 on input B (the fact that\nall tests in while, if and if-then-else instructions are quantifier-free first-order enables\nus to do this). Hence, B \u2208 \u2126.\nTheorem 14 PSPACE \u2229 EXT = NPSA(1) and NP \u2229 EXT = NPSB(1).\nProof Let \u2126 be some problem in PSPACE\u2229EXT . By [33], there exists a program\nscheme \u03c1 \u2208 NPSAs(1) accepting \u2126. Modify \u03c1 to obtain the program scheme \u03c1\n\u2032 \u2208\nNPSA(1) as follows. In \u03c1\u2032, begin by guessing a successor relation; that is, when A is\nsome input structure, guess elements u1, u2, . . . , um \u2208 |A| so that\nM [0] = u1,M [u1] = u2, . . . ,M [um] = max,\nwhereM is a new one-dimensional array symbol and where the elements of {0, u1, u2,\n. . . , um,max} are distinct (this latter condition can be checked as we guess). Replace\nany atomic relation of the form succ(x, y) in \u03c1 with the formula y =M [x], and replace\nany instruction of the form guess x with the following fragment of code:\nguess x\ngoodx := 0\nok := 0\nwhile ok = 0 do\nif (x = goodx \u2228 goodx = max) then\nok := max\nelse\ngoodx := M [goodx]\nfi\nod\nif x 6= goodx then \u2018loop forever\u2019 fi\n(where goodx and ok are new variables). Note that this fragment of code essentially\nlimits our guesses to elements appearing in the domain of our guessed successor rela-\ntion. We need to show that acceptance by the program scheme \u03c1\u2032 is invariant with\nrespect to 0 and max and that it accepts the problem \u2126.\nSuppose that A \u2208 \u2126. Then A is accepted by \u03c1 no matter which successor relation\nis chosen for succ in \u03c1. Choose distinct 0\u2032 and max\u2032 in |A| and a successor relation\nsucc\u2032 on |A| (with minimal and maximal elements the chosen elements 0\u2032 and max\u2032).\nIn particular, \u03c1 accepts A with these constants and this successor relation. Consider\na computation of \u03c1\u2032 on input A where the guessed successor relation is succ\u2032. Then\nthere exists a computation of \u03c1\u2032 mirroring any accepting computation of \u03c1 on input\nA with this particular successor relation. That is, A is accepted by \u03c1\u2032 and acceptance\ndoes not depend upon the chosen constants 0 and max.\nConversely, suppose that there is a guessed successor relation, call it succ\u2032 (whose\ndomain need not be all of |A|), with minimal and maximal elements 0\u2032 and max\u2032,\n20\nyielding an accepting computation of \u03c1\u2032 on input A. Let B \u2286 |A| be the domain of\nthis successor relation and let B be the restriction of A to B. Then B is accepted\nby \u03c1 when the successor relation is taken as succ\u2032 (note that the domain of succ\u2032\nis the whole of |B|). Hence, B \u2208 \u2126. However, \u2126 is closed under extensions and so\nA \u2208 \u2126. But we have seen from above that if A \u2208 \u2126 then A is accepted by \u03c1\u2032 and\nacceptance does not depend upon the chosen constants 0 and max. Thus, acceptance\nby \u03c1\u2032 is invariant with respect to 0 and max; and PSPACE\u2229EXT \u2286 NPSA(1). The\nfact that every problem in NPSA(1) can be solved by a polynomial-space algorithm\nis straight-forward; and every problem in NPSA(1) is closed under extensions by\nLemma 13.\nNow consider a problem \u2126 \u2208 NP \u2229 EXT accepted by the program scheme \u03c1 \u2208\nNPSBs(1). We proceed as above, and define a program scheme \u03c1\n\u2032 \u2208 NPSB(1), except\nwith the following amendment. In NPSB(1), we are only allowed assignments to array\nelements of the formM [x1, x2, . . . , xk] := max and so we need some way of encoding\nour guessed successor relation. We encode our relation as:\nM [0, u1] = max,M [u1, u2] = max, . . . ,M [um,max] = max,\nwhereM is a new array symbol of dimension 2. Of course, we ensure that the elements\nof {0, u1, u2, . . . , um,max} are distinct as we guess. Note that we need to remember\nthe previously guessed element, ui, so that we know to set M [ui, ui+1] equal to max.\nWe also need to modify our code so that an atomic relation of the form succ(x, y) is\nreplaced by the formula M [x, y] = max. Arguing as above yields the result.\nNote that the construction used in the proofs of Lemma 9 and Theorem 14 (right at\nthe end) can easily be generalized to show that the \u2018logic\u2019 formed by allowing any pro-\ngram scheme \u03c1 of NPSB(1) to be prefixed with a sequence of existentially-quantified\nrelation symbols (where these relation symbols do not appear in the underlying sig-\nnature of the problem in hand but do appear in the program scheme \u03c1) captures the\nclass of problems NPSB(1). To see this, we simply \u2018guess\u2019 relations for these quan-\ntified relation symbols and \u2018string\u2019 each relation together using an appropriate array\nin the style of a linked list. Should we need to check whether some tuple of values is\nin the relation in some computation of the program scheme then we work down the\nlinked list looking for this tuple. Consequently, we have the following result, which\ngives some idea as to the power of NPSB(1).\nCorollary 15 NPSB(1) is closed under existential quantification.\nOne view of Theorem 14 is that it provides syntactic characterizations (via the\nthe classes of program schemes NPSA(1) and NPSB(1)) of semantically defined com-\nplexity classes (namely, PSPACE \u2229 EXT and NP \u2229 EXT ). Actually, we make this\nremark modulo our earlier discussion where we mention that we can indeed obtain a\ntrue \u2018syntactic\u2019 characterization by working with variables x0 and xmax rather than\nusing built-in constant symbols 0 and max.\nCorollary 16 NP = PSPACE if, and only if, NPSA(1) = NPSB(1).\nProof IfNP = PSPACE thenNP\u2229EXT = PSPACE\u2229EXT ; and so NPSA(1) =\nNPSB(1) by Theorem 14. Conversely, if NPSA(1) = NPSB(1) then NPSAs(1) =\nNPSBs(1); and so NP = PSPACE by [33] and Corollary 11.\n21\nCorollary 16 relates an open complexity-theoretic question with a question in-\nvolving two classes of problems, each problem of which has asymptotic probability\n1. This result could easily have been obtained simply by observing that there are\nPSPACE-complete that are closed under extensions. Nevertheless, we include it here\nto emphasise the relationship between standard complexity classes and our classes of\nprogram schemes.\nCorollary 16 can be extended slightly in that we can obtain some additional equiv-\nalences involving fragments of certain vectorized Lindstro\u00a8m logics. Referring back to\nTheorem 5, the problem mentioned in that theorem is actually defined as follows.\nDefinition 17 Let the signature \u03c3a = \u3008T1, T3,M,C\u3009, where M is a unary relation\nsymbol, T1 is a binary relation symbol, T3 is a relation symbol of arity 4 and C is a\nconstant symbol. We can envisage a \u03c3a-structure A as a Petri net whose places are\ngiven by |A| and whose transitions are given by T1 and T2 via:\n\u2022 there is a transition ({x}, {y}) whose input place is {x} and whose output place\nis {y} if, and only if, T1(x, y) holds; and\n\u2022 there is a transition ({x1, x2}, {y1, y2}) whose input places are {x1, x2} and\nwhose output places are {y1, y2} if, and only if, T3(x1, x2, y1, y2) holds, where\nx1 6= x2 and y1 6= y2.\nThe relationM can be seen as providing an initial marking (with one token on place p\nif, and only if,M(p) holds) and the constant C as providing a final marking (consisting\nof one token on the place C).\nA \u03c3a-structure A, i.e., a Petri net, complete with inital and final markings, where\nevery transition has either 2 input places and 2 output places or 1 input place and 1\noutput place, is in the problem \u2126a if, and only if, there is a marking covering the final\nmarking that is reachable from the initial marking, i.e., there is a reachable marking\nin which there is at least one token on the place C.\nCorollary 18 The following are equivalent.\n(a) NP = PSPACE.\n(b) NPSB(1) = NPSA(1).\n(c) \u21261b [FO ] = \u2126\n1\na[FO ].\n(d) The problems \u2126b and \u2126a are equivalent via quantifier-free first-order translations\nwith 2 constants.\nProof Corollary 16 implies (a) \u21d4 (b). Theorems 5 and 7 imply (b) \u21d4 (d). It is\ntrivially the case that (c) \u21d2 (a) and that (d) \u21d2 (c).\nWe end by returning to an earlier remark concerning the NPSB hierarchy on the\nclass of all finite structures. We include the following result here as we can utilize\nresults of this section, and this result also applies to the NPSA hierarchy.\nProposition 19 On the class of all finite structures,\nNPSB(1) \u2282 NPSB(2) \u2282 NPSB(3).\n22\nProof By Lemma 13, every problem in NPSB(1) is closed under extensions; and so,\ntrivially, NPSB(1) \u2282 NPSB(2).\nConsider the following first-order sentence over the signature \u03c32 = \u3008E,C\u3009, where\nE is a binary relation symbol and C is a constant symbol:\n\u2203x(E(C, x) \u2227 \u2203y(E(x, y) \u2227 \u2200z(E(x, z)\u21d2 z = y))).\nThere is clearly a program scheme of NPSB(3) accepting the problem \u2126 defined by this\nsentence. For any k \u2265 1, consider the digraphs, Ak and Bk, depicted in Fig. 2 (note\nthat Bk only differs from Ak by having an extra vertex and edge). No matter what\nthe value of k, Ak \u2208 \u2126 but Bk 6\u2208 \u2126. We shall show that for any program scheme \u03c1 of\nNPSB(2), there exists some k such that Ak |= \u03c1 implies that Bk |= \u03c1. This will yield\nour result.\n...\nC\nk copies\nA\nk\n...\nC\nk copies\nB\nk\nFigure 2. The digraphs Ak and Bk.\nLet \u03c1 be a program scheme of NPSB(2) of the form \u2200xk\u2200x2 . . . \u2200xk\u03c1\n\u2032, for some\nprogram scheme \u03c1\u2032 of NPSB(1), and let B\u02dck be an extension of Bk by k constants\n(one for each variable xi). There is an extension of Ak, denote it A\u02dck, such that A\u02dck is\nembeddable into B\u02dck via a one-to-one mapping: call the mapping pi. Suppose that there\nis an accepting computation of \u03c1\u2032 on input A\u02dck. We can \u2018mirror\u2019 this computation by a\ncomputation of \u03c1\u2032 on B\u02dck by making guesses according to the mapping pi (after having\nchosen our constants 0 and max, again according to pi). The two computations of \u03c1\u2032,\non A\u02dck and B\u02dck, proceed in tandem (in that their flows of control are identical) and\nbecause the computation of \u03c1\u2032 on A\u02dck leads to acceptance, so must the computation\nof \u03c1\u2032 on B\u02dck (recall, any tests are quantifier-free first-order and so only ever refer to\nthe current values of variables). Our result follows.\nWe add that the proof of Proposition 19 suffices to show that, on the class of all\nfinite structures, NPSA(1) \u2282 NPSA(2) \u2282 NPSA(3).\n6 Amended semantics\nFinally, let us amend our semantics of the program schemes of NPSB.When we defined\nthe semantics of a program scheme \u03c1 of NSPB(2i + 1), for some i > 0, we insisted\nthat when a test in some if-then-else or while instruction is evaluated (recall, such a\ntest is a program scheme of NSPB(2i)), the only values used in this evaluation are the\ncurrent values of the variables of \u03c1. In particular, all arrays involved in the evaluation\n23\nare initialized to 0 prior to the evaluation. Suppose that we now insist that arrays\nused in the evaluation are initialized to their current values prior to the evaluation.\nConsequently, not only can we pass the current values of the variables across to an\nevaluation, we can pass the current values of the arrays across too (or course, when\nthe program scheme \u03c1 resumes after evaluation of the test, the values of the arrays are\nwhat they were prior to the evaluation of the test). We denote the program schemes\nof NPSB with this semantics as NPSBp to reflect the fact that a polynomial number\nof values is passed across in an evaluation (rather than just a constant number in the\nstandard semantics). Allowing a polynomial number of values to be passed across to\nan evaluation drastically changes the expressibility of the resulting class of program\nschemes (modulo the usual complexity-theoretic qualifications). The complexity class\nPH is the Polynomial Hierarchy; that is, PH = \u222a\u221ei=1\u03a3\np\ni , where \u03a3\np\n1 = NP and where,\nfor each i \u2265 2, \u03a3pi = NP\n\u03a3\np\ni\u22121 (the class of problems accepted by a polynomial-time\nnon-deterministic oracle Turing machine with access to a \u03a3pi\u22121 oracle).\nTheorem 20 NPSBp(1) = NPSB(1), NPSBp(2) = NPSB(2) and for every i \u2265 2,\nNPSBp(2i\u2212 1) = NPSBp(2i) = \u03a3pi . Consequently, NPSB\np = PH.\nProof Similarly to the proof (elucidated immediately prior to Theorem 12) that\nNPSBs(1) = NPSBs(2), so we can show that NPSB\np(2i \u2212 1) = NPSBp(2i), for all\ni \u2265 2. Obviously, NPSBp(1) = NPSB(1) and NPSBp(2) = NPSB(2) (as our original\nsemantics and our amended semantics do not differ in these cases).\nWe now show how to build our own successor relation using a program scheme of\nNPSBp(3). Essentially, we guess a successor relation and store it in the array S, of\ndimension 2, via the following code:\nx := 0\nwhile x 6= max do\nguess y\nif x 6= y then\nS[x, y] := max\nx := y\nfi\nod\nThen we check, using an if-then-else instruction with the test a program scheme of\nNPSBp(2), that every value appears in the guessed relation S and that no value\nappears more than once. Consequently, by Corollary 11, any problem in NP can be\naccepted by some program scheme of NPSBp(3).\nNot withstanding the above remark, we would like to explicitly simulate a non-\ndeterministic polynomial-time Turing machine computation using a program scheme\nof NPSBp(3). We can use arrays to store the work-tape of any such Turing machine\nand our successor relation, held in S, to mirror the movement of the tape heads. Our\nonly restriction to this simulation is that we can only set array values at max: we\ncan not reset them to 0. Hence, the obvious means of simulation is doomed to failure\ngiven that, in general, the contents of a cell of a Turing machine work-tape fluctuate\nand that if we simulate a cell of the work tape using a fixed number of array elements\nthen we can only register a constant number of changes to the cell contents. However,\n24\nwe can get round this difficulty by using the fact that any (accepting) computation of\nour Turing machine has length polynomial in the size of the input structure: hence,\nwe can use an array to store the complete history of changes to the contents of a\nTuring machine work-tape cell as follows.\nFor simplicity, assume that we wish to hold the contents of n Turing machine\nwork-tape cells (where the input structure has size n) using some arrays and that\nthese contents are only ever 0 or 1. Furthermore, assume that the time taken by our\nTuring machine to accept (if it does) is n. The general case where a cell can contain\nmore symbols, where there is a polynomial number of work-tape cells to deal with and\nwhere the Turing machine accepts in a polynomial number of steps can be handled\nsimilarly by increasing the dimensions of our arrays. Let A and B be array symbols\nof dimension 2. Using our successor relation (constructed earlier), we use the array\ncells A[u, 1], A[u, 2], . . . , A[u, n] (we think of the elements of our input structure as\nbeing named {1, 2, . . . , n} with the names reflecting our successor relation) to register\nthe first change of the contents of the work-tape cell u, the second change of the\nwork-tape cell u, the third change of the work-tape cell u, and so on; and the array\ncells B[u, 1], B[u, 2], . . . , B[u, n] to register the value of work-tape cell u after the first\nchange, the value of work-tape cell u after the second change, the value of work-tape\ncell u after the third change, and so on.\nIf A[u, i] = max then this is interpreted as meaning that there have been at least\ni changes of contents; and if B[u, i] = 0 (resp. B[u, i] = max) then this is interpreted\nas meaning that after the ith change, the contents of work-tape cell u is 0 (resp. 1).\nNote that when the work-tape cell u changes from 1 to 0, on the ith change, say, in\norder to register this change we need only set A[u, i] = max and leave B[u, i] alone\n(as it has been initialized to 0). Furthermore, with this representation, and using\nour successor relation, we can easily determine the current contents of any work-tape\ncell: we simply cycle down the array A to find the last change of contents and then\nascertain the current contents using B. Thus, it should be clear how we can explicitly\nsimulate our Turing machine computation using a program scheme of NPSBp(3).\nNow, consider a polynomial-time non-deterministic oracle Turing machineM con-\nsulting an NP oracle. By Corollary 11, and using an array to hold the contents of\nthe oracle tape, we can simulate an oracle call of M by an if-then-else instruction\nwhere the test is a program scheme of NPSBp(2) (exactly because we are allowed, in\nour modified semantics, to pass the values of arrays over to the evaluation of a test).\nHence, we have essentially proven that any problem in NPNP can be accepted by a\nprogram scheme of NPSBp(3). Conversely, it is straightforward to see that any prob-\nlem accepted by a program scheme of NPSBp(3) can be accepted by a polynomial-time\nnon-deterministic oracle Turing machine with an oracle in NP (the only point worthy\nof note in this regard is that we must ensure that the contents of all arrays in the\nprogram scheme are written on the simulating Turing machine\u2019s oracle tape). Hence,\nNPSBp(3) = NPNP.\nThe general result now follows by a simple induction: for example, any polynomial-\ntime non-deterministic oracle Turing machine consulting an oracle in NPNP can be\nexplicitly simulated; and by above the oracle calls can be simulated by if-then-else\ninstructions where the tests are program schemes from NPSBp(4).\n25\n7 Conclusions\nIn this paper, we have examined the computational capabilities of different classes of\nprogram schemes, based around \u2018binary write-once arrays\u2019, on the class of finite struc-\ntures, the class of ordered finite structures and with respect to different semantics.\nWe now discuss some potential directions for future research.\nPerhaps the most obvious unanswered question is as regards the NPSB hierarchy:\n\u2018Is it the case that, like the NPS and NPSS hierarchies, the NPSB hierarchy is proper\nat every level?\u2019 (the same question can be asked for the NPSA hierarchy). So far,\nwe have not been able to answer this question (beyond Proposition 19). The main\nreason for the lack of progress is that whereas in [7] we were able to \u2018re-use\u2019 domain\nelements so as to \u2018mirror\u2019 computations of program scheme of NPS and NPSS (in\nthe style of the proof of Proposition 19), the existence of arrays means that we can\n\u2018remember the values already used\u2019 in a computation and consequently it is not clear\nthat domain elements can be re-used in a suitably anonymous fashion (the reader is\nreferred to [7], and the proofs therein, in order to make more sense of this remark).\nThe fact that working with program schemes of NPSB takes us outside the \u2018bounded-\nvariable world\u2019 of the logic L\u03c9\u221e\u03c9 (see Corollary 10), whereas this is not the case with\nthe program schemes of NPS and NPSS, is particularly intriguing in this respect.\nIn relation to the above comments (and as suggested by an anonymous referee),\nit would be interesting to further examine the relationship between the classes of\nprogram schemes in this paper and (fragments of) the more standard logics from\nfinite model theory and descriptive complexity, such as bounded-variable infinitary\nlogic and second-order logic. For example, how does the class of existential second-\norder formulae in which the first-order matrix is purely existential compare with the\nclass of program schemes NPSB(1)? Also, can we translate program schemes into\nrestricted infinitary formulae (not necessarily involving a finite number of variables)\nand apply known results concerning such formulae with certain quantifier alternations\nto obtain proper hierarchies of program schemes?\nThe results in Section 6, relating the computational capabilities of the classes of\nprogram schemes NPSB(1) and NPSA(1), are in the style of Abiteboul and Vianu\n[2, 4], Abiteboul, Vianu and Vardi [6] and Dawar [11]. However, we would prefer\nto have determined similar results but regarding the classes NPSB and NPSA (or,\nequivalently, the logics (\u00b1\u2126b)\n\u2217[FO] and (\u00b1\u2126a)\n\u2217[FO]). So far, we have been unable to\nextend the results of Section 6 to these classes of programs schemes. There are some\nvery straightforward implications to be made however. For instance (on the class of\nall finite structures):\n\u2022 by Corollary 18, if NP = PSPACE then NPSB = NPSA (and, equivalently,\n(\u00b1\u2126b)\n\u2217[FO] = (\u00b1\u2126a)\n\u2217[FO]);\n\u2022 by Theorems 5 and 12, if NPSB = NPSA (or, equivalently, (\u00b1\u2126b)\n\u2217[FO] =\n(\u00b1\u2126a)\n\u2217[FO]) then LNP = PSPACE; and\n\u2022 by Theorems 5 and 12, if \u2126\u2217b [FO] = \u2126\n\u2217\na[FO] then NP = PSPACE (as any\nproblem in \u2126\u2217b [FO] can easily be seen to be in NP).\nWe would like to be able to equate the questions: \u2018Is LNP equal to PSPACE?\u2019, \u2018Is\nNPSB equal to NPSA?\u2019 and \u2018Is (\u00b1\u2126b)\n\u2217[FO] equal to (\u00b1\u2126a)\n\u2217[FO]?\u2019; as well as the\n26\nquestions: \u2018Is NP equal to PSPACE?\u2019 and \u2018Is \u2126\u2217b [FO] equal to \u2126\n\u2217\na[FO]?\u2019. As yet, we\nhave been unable to do so.\nFinally, let us return to the decision problem described at the beginning of Section\n4 involving the traversal of a digraph subject to the utilization of user and system\nresources. We feel that this problem, and its variations, are very relevant in the\nstudy of the complexity of agent-based systems . Essentially, an agent-based system is\nan environment within which an agent must successfully accomplish a task. Agents\ninteract with the environment by performing actions and these actions can result in a\nchange of state of the environment. Our resource-dependent digraph traversal problem\ncan easily be viewed as an agent-based system, and we intend to investigate exactly\nhow the study of program schemes and logics can impact upon that of agent-based\nsystems in a future paper.\nAcknowledgement We are very grateful to the insightful comments of a referee\nwhich significantly improved the clarity and rigour of this paper.\nReferences\n[1] S. Abiteboul and V. Vianu, Procedural and declarative database update lan-\nguages, Proc. of ACM Symp. on Principles of Database Systems, ACM Press\n(1988) 240\u2013250.\n[2] S. Abiteboul and V. Vianu, Fixpoint extensions of first-order logic and Datalog-\nlike languages, Proc. of 4th Ann. IEEE Symp. on Logic in Computer Science,\nIEEE Press (1989) 71\u201379.\n[3] S. Abiteboul and V. Vianu, Procedural languages for database queries and up-\ndates, Journal of Computer and System Sciences 41 (1990) 181\u2013229.\n[4] S. Abiteboul and V. Vianu, Generic computation and its complexity, Proceedings\nof the 23rd Ann. ACM Symp. on Theory of Computing, ACM Press (1991) 209\u2013\n219.\n[5] S. Abiteboul and V. Vianu, Computing with first-order logic, Journal of Com-\nputer and System Sciences 50 (1995) 309\u2013335.\n[6] S. Abiteboul, M.Y. Vardi and V. Vianu, Fixpoint logics, relational machines and\ncomputational complexity, Journal of the Association for Computing Machinery\n44 (1997) 30\u201356.\n[7] A.A. Arratia-Quesada, S.R. Chauhan and I.A. Stewart, Hierarchies in classes of\nprogram schemes, Journal of Logic and Computation 9 (1999) 915\u2013957.\n[8] A.K. Chandra and D. Harel, Structure and complexity of relational queries, Jour-\nnal of Computer and System Sciences 25 (1982) 99\u2013128.\n[9] A.K. Chandra and D. Harel, Horn clause queries and generalizations, Journal of\nLogic Programming 2 (1985) 1\u201315.\n[10] R. Constable and D. Gries, On classes of program schemata, SIAM Journal of\nComputing 1 (1972) 66\u2013118.\n27\n[11] A. Dawar, A restricted second-order logic for finite structures, Information and\nComputation 143 (1998) 154\u2013174.\n[12] H.D. Ebbinghaus and J. Flum, Finite Model Theory, Springer-Verlag (1995).\n[13] J. Esparza and M. Nielsen, Decidability issues for Petri nets \u2013 a survey, Journal\nof Information Processing and Cybernetics 30 (1994) 143\u2013160.\n[14] R. Fagin, Generalized first-order spectra and polynomial-time recognizable sets,\nin: Complexity of Computation (ed. R.M. Karp), SIAM-AMS Proceedings 7\n(1974) 43\u201373.\n[15] H. Friedman, Algorithmic procedures, generalized Turing algorithms and ele-\nmentary recursion theory, in: Logic Colloquium 1969 (ed. R.O. Gandy, C.M.E.\nYates), North-Holland (1971) 361\u2013390.\n[16] M. Garey and D.S. Johnson, Computers and Intractability: A Guide to the The-\nory of NP-Completeness , Freeman (1979).\n[17] R.L. Gault and I.A. Stewart, An infinite hierarchy in a class of polynomial-time\nprogram schemes, Theory of Computing Systems 39 (2006) 753\u2013783.\n[18] A. van Gelder, K.A. Ross and J.S. Schlipf, The well-founded semantics for general\nlogic programs, Proc. of ACM Symp. on Principles of Database Systems, ACM\nPress (1988) 221\u2013230.\n[19] G. Gottlob, Relativized logspace and generalized quantifiers over finite ordered\nstructures, Journal of Symbolic Logic 62 (1997) 545\u2013574.\n[20] Y. Gurevich and S. Shelah, Fixed-point extensions of first-order logic, Annals of\nPure and Applied Logic 32 (1986) 265\u2013280.\n[21] D. Harel and D. Peleg, On static logics, dynamic logics, and complexity classes,\nInformation and Control 60 (1984) 86\u2013102.\n[22] N. Immerman, Relational queries computable in polynomial time, Information\nand control 69 (1986) 86\u2013104.\n[23] N. Immerman, Languages that capture complexity classes, SIAM Journal of\nComputing 16 (1987) 760\u2013778.\n[24] N. Immerman, Descriptive Complexity, Springer-Verlag (1998).\n[25] N.D. Jones and S.S. Muchnik, Even simple programs are hard to analyze, Journal\nof Association for Computing Machinery 24 (1977) 338\u2013350.\n[26] L. Libkin, Elements of Finite Model Theory, Springer-Verlag, Berlin (2004).\n[27] F. Neven, M. Otto, J. Tyszkiewicz and J. van den Bussche, Adding for-loops to\nfirst-order logic, Information and Computation 168 (2001) 156\u2013186.\n[28] M. Otto, Bounded Variable Logics and Counting, Lecture Notes in Logic Volume\n9, Springer-Verlag (1997).\n28\n[29] M. Paterson and N. Hewitt, Comparative schematology, Record of Project MAC\nConf. on Concurrent Systems and Parallel Computation, ACM Press (1970) 119\u2013\n128.\n[30] V. Sazonov, Polynomial computability and recursivity in finite domains, Elek-\ntronische Informationsverarbeitung und Kybernetik 60 (1980) 319\u2013323.\n[31] I.A. Stewart, Complete problems involving boolean labelled structures and pro-\njection translations, Journal of Logic and Computation 1 (1991) 861\u2013882.\n[32] I.A. Stewart, Using the Hamiltonian path operator to capture NP, Journal of\nComputer and System Sciences 45 (1992) 127\u2013151.\n[33] I.A. Stewart, Logical and schematic characterization of complexity classes, Acta\nInformatica 30 (1993) 61\u201387.\n[34] I.A. Stewart, Methods for proving completeness via logical translations, Theo-\nretical Computer Science 118 (1993) 193\u2013229.\n[35] I.A. Stewart, Logical characterizations of bounded query classes II: polynomial-\ntime oracle machines, Fundamenta Informaticae 18 (1993) 93\u2013105.\n[36] I.A. Stewart, Complete problems for monotone NP, Theoretical Computer Sci-\nence 145 (1995) 147\u2013157.\n[37] I.A. Stewart, Logics with zero-one laws that are not fragments of bounded-\nvariable infinitary logic, Mathematical Logic Quarterly 41 (1997) 158\u2013178.\n[38] I.A. Stewart, Program schemes, queues, the recursive spectrum and zero-one\nlaws, Proc. of 7th Ann. Int. Computing and Combinatorics Conference (ed. J.\nWang), Lecture Notes in Computer Science Vol. 2108, Springer-Verlag, Berlin\n(2001) 39\u201348.\n[39] I.A. Stewart, Program schemes, arrays, Lindstro\u00a8m quantifiers and zero-one laws,\nTheoretical Computer Science 275 (2002) 283\u2013310.\n[40] I.A. Stewart, Using program schemes to logically capture polynomial-time on cer-\ntain classes of structures, London Mathematical Society Journal of Computation\nand Mathematics 6 (2003) 40\u201367.\n[41] J. Tiuryn and P. Urzyczyn, Some relationships between logics of programs and\ncomplexity theory, Theoretical Computer Science 60 (1988) 83\u2013108.\n[42] M. Vardi, The complexity of relational query languages, Proc. of 14th Ann. ACM\nSymp.on Theory of Computing, ACM Press (1982) 137\u2013146.\n[43] V. Vianu, Databases and finite-model theory, in Descriptive Complexity and\nFinite Models (ed. N. Immerman and P. Kolaitis), DIMACS Series in Discrete\nMathematics and Theoretical Computer Science Vol. 31, American Mathematical\nSociety (1996), 97\u2013148.\n29\n"}